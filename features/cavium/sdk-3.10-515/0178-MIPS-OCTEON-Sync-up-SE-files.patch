From c8e2e9cf9176dc682154535e0cb0d9f6bbde30cd Mon Sep 17 00:00:00 2001
From: Chandrakala Chavva <cchavva@caviumnetworks.com>
Date: Mon, 29 Jul 2013 14:53:36 -0700
Subject: [PATCH 178/382] MIPS:OCTEON: Sync up SE files.

Based on SDK octeon3_3.10.

Signed-off-by: Chandrakala Chavva <cchavva@caviumnetworks.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/cavium-octeon/executive/Makefile         |    3 +-
 arch/mips/cavium-octeon/executive/cvmx-agl.c       |   15 +-
 arch/mips/cavium-octeon/executive/cvmx-bch.c       |  300 ++
 arch/mips/cavium-octeon/executive/cvmx-bgx.c       |  255 +
 arch/mips/cavium-octeon/executive/cvmx-clock.c     |   22 +-
 arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c |   18 +-
 .../cavium-octeon/executive/cvmx-debug-handler.S   |   25 +-
 arch/mips/cavium-octeon/executive/cvmx-debug.c     |  247 +-
 .../cavium-octeon/executive/cvmx-error-trees.c     |  983 ++++-
 .../cavium-octeon/executive/cvmx-fpa-resource.c    |   12 +-
 .../executive/cvmx-global-resources.c              |    9 +-
 arch/mips/cavium-octeon/executive/cvmx-gser.c      |  277 ++
 .../mips/cavium-octeon/executive/cvmx-helper-agl.c |   50 +-
 .../cavium-octeon/executive/cvmx-helper-board.c    |   92 +-
 .../mips/cavium-octeon/executive/cvmx-helper-cfg.c |  118 +-
 .../mips/cavium-octeon/executive/cvmx-helper-ilk.c |  265 +-
 .../mips/cavium-octeon/executive/cvmx-helper-npi.c |    4 +-
 .../cavium-octeon/executive/cvmx-helper-rgmii.c    |   29 +-
 .../cavium-octeon/executive/cvmx-helper-sgmii.c    |  284 +-
 .../cavium-octeon/executive/cvmx-helper-util.c     |  190 +-
 .../cavium-octeon/executive/cvmx-helper-xaui.c     |  156 +-
 arch/mips/cavium-octeon/executive/cvmx-helper.c    |  936 +++--
 arch/mips/cavium-octeon/executive/cvmx-ilk.c       |  355 +--
 arch/mips/cavium-octeon/executive/cvmx-l2c.c       |   78 +-
 arch/mips/cavium-octeon/executive/cvmx-nand.c      |  438 ++-
 arch/mips/cavium-octeon/executive/cvmx-pcie.c      |  133 +-
 .../cavium-octeon/executive/cvmx-pki-resources.c   |  278 ++
 arch/mips/cavium-octeon/executive/cvmx-pki.c       |  772 +++-
 arch/mips/cavium-octeon/executive/cvmx-qlm.c       |  557 ++--
 arch/mips/cavium-octeon/executive/cvmx-srio.c      |    4 +-
 arch/mips/cavium-octeon/executive/cvmx-usb.c       | 1231 ++++--
 arch/mips/cavium-octeon/executive/octeon-feature.c |    7 +-
 arch/mips/cavium-octeon/octeon-error-tree.c        |    1 +
 arch/mips/include/asm/octeon/cvmx-agl-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-app-hotplug.h    |    2 +-
 arch/mips/include/asm/octeon/cvmx-app-init.h       |   10 +-
 arch/mips/include/asm/octeon/cvmx-ase-defs.h       |  790 ++--
 arch/mips/include/asm/octeon/cvmx-asm.h            |   10 +-
 arch/mips/include/asm/octeon/cvmx-asxx-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-bch-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-bch.h            |  368 ++
 arch/mips/include/asm/octeon/cvmx-bgx.h            |   64 +
 arch/mips/include/asm/octeon/cvmx-bgxx-defs.h      | 3866 +++++++--------
 arch/mips/include/asm/octeon/cvmx-ciu-defs.h       |   46 +-
 arch/mips/include/asm/octeon/cvmx-ciu2-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-ciu3-defs.h      |  125 +-
 arch/mips/include/asm/octeon/cvmx-clock.h          |    3 +-
 arch/mips/include/asm/octeon/cvmx-cmd-queue.h      |   63 +-
 arch/mips/include/asm/octeon/cvmx-core.h           |   29 +-
 arch/mips/include/asm/octeon/cvmx-coremask.h       |   35 +-
 arch/mips/include/asm/octeon/cvmx-dbg-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-debug.h          |   30 +-
 arch/mips/include/asm/octeon/cvmx-dpi-defs.h       |  138 +-
 arch/mips/include/asm/octeon/cvmx-fpa-defs.h       |   12 +-
 arch/mips/include/asm/octeon/cvmx-fpa.h            |   28 +-
 .../include/asm/octeon/cvmx-global-resources.h     |   21 +-
 arch/mips/include/asm/octeon/cvmx-gmxx-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-gpio-defs.h      |   27 +-
 arch/mips/include/asm/octeon/cvmx-gser.h           |   63 +
 arch/mips/include/asm/octeon/cvmx-gserx-defs.h     | 1845 ++++++--
 arch/mips/include/asm/octeon/cvmx-helper-board.h   |    4 +-
 arch/mips/include/asm/octeon/cvmx-helper-cfg.h     |   74 +-
 arch/mips/include/asm/octeon/cvmx-helper-ilk.h     |   31 +
 arch/mips/include/asm/octeon/cvmx-helper-rgmii.h   |   15 +-
 arch/mips/include/asm/octeon/cvmx-helper-sgmii.h   |   77 +-
 arch/mips/include/asm/octeon/cvmx-helper-util.h    |   26 +-
 arch/mips/include/asm/octeon/cvmx-helper-xaui.h    |   73 +-
 arch/mips/include/asm/octeon/cvmx-helper.h         |   15 +-
 arch/mips/include/asm/octeon/cvmx-hna-defs.h       | 1389 ++++---
 arch/mips/include/asm/octeon/cvmx-ila-defs.h       |  131 +-
 arch/mips/include/asm/octeon/cvmx-ilk-defs.h       |  208 +-
 arch/mips/include/asm/octeon/cvmx-ilk.h            |    7 +-
 arch/mips/include/asm/octeon/cvmx-iob-defs.h       |   75 +-
 arch/mips/include/asm/octeon/cvmx-iobn-defs.h      |   75 +-
 arch/mips/include/asm/octeon/cvmx-iobp-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-ipd-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-l2c-defs.h       |  802 +++-
 arch/mips/include/asm/octeon/cvmx-l2c.h            |   24 +-
 arch/mips/include/asm/octeon/cvmx-l2d-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-l2t-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-lapx-defs.h      |   83 +-
 arch/mips/include/asm/octeon/cvmx-lbk-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-led-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-lmcx-defs.h      | 1251 +++---
 arch/mips/include/asm/octeon/cvmx-mio-defs.h       |  263 +-
 arch/mips/include/asm/octeon/cvmx-mixx-defs.h      |  166 +-
 arch/mips/include/asm/octeon/cvmx-mpi-defs.h       |   14 +-
 arch/mips/include/asm/octeon/cvmx-ndf-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-npei-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-npi-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-oclax-defs.h     |   40 +-
 arch/mips/include/asm/octeon/cvmx-ocx-defs.h       |  418 ++-
 arch/mips/include/asm/octeon/cvmx-osm-defs.h       |  169 +-
 arch/mips/include/asm/octeon/cvmx-pci-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-pcie.h           |   13 +-
 arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h |   57 +-
 arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h   |  378 ++-
 arch/mips/include/asm/octeon/cvmx-pciercx-defs.h   |  453 ++-
 arch/mips/include/asm/octeon/cvmx-pcsx-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h     |  158 +-
 arch/mips/include/asm/octeon/cvmx-pemx-defs.h      |  974 ++--
 arch/mips/include/asm/octeon/cvmx-pescx-defs.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-pexp-defs.h      |    7 +-
 arch/mips/include/asm/octeon/cvmx-pip-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-pki-cluster.h    |  636 +++
 arch/mips/include/asm/octeon/cvmx-pki-defs.h       |  421 ++-
 arch/mips/include/asm/octeon/cvmx-pki-resources.h  |  112 +
 arch/mips/include/asm/octeon/cvmx-pki.h            |  549 ++-
 arch/mips/include/asm/octeon/cvmx-pko-defs.h       | 5005 ++++++++++++++++----
 arch/mips/include/asm/octeon/cvmx-pow-defs.h       |   65 +-
 arch/mips/include/asm/octeon/cvmx-pow.h            |  219 +-
 arch/mips/include/asm/octeon/cvmx-qlm.h            |   62 +-
 arch/mips/include/asm/octeon/cvmx-rnm-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-rst-defs.h       |   26 +-
 arch/mips/include/asm/octeon/cvmx-sli-defs.h       |  101 +-
 arch/mips/include/asm/octeon/cvmx-smix-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-spxx-defs.h      |    2 +-
 .../mips/include/asm/octeon/cvmx-sriomaintx-defs.h |    2 +-
 arch/mips/include/asm/octeon/cvmx-sriox-defs.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-srxx-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-sso-defs.h       |   78 +-
 arch/mips/include/asm/octeon/cvmx-stxx-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-sysinfo.h        |   33 +-
 arch/mips/include/asm/octeon/cvmx-uctlx-defs.h     |  293 +-
 arch/mips/include/asm/octeon/cvmx-usbcx-defs.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-usbnx-defs.h     |    2 +-
 arch/mips/include/asm/octeon/octeon-boot-info.h    |    4 +-
 arch/mips/include/asm/octeon/octeon-feature.h      |   25 +-
 arch/mips/include/asm/octeon/octeon-model.h        |    3 +-
 129 files changed, 21648 insertions(+), 9229 deletions(-)
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-bch.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-bgx.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-gser.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
 create mode 100644 arch/mips/include/asm/octeon/cvmx-bch.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-bgx.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-gser.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-pki-cluster.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-pki-resources.h

diff --git a/arch/mips/cavium-octeon/executive/Makefile b/arch/mips/cavium-octeon/executive/Makefile
index a3b60fc..97bf781 100644
--- a/arch/mips/cavium-octeon/executive/Makefile
+++ b/arch/mips/cavium-octeon/executive/Makefile
@@ -19,7 +19,8 @@ obj-y += cvmx-pko.o cvmx-spi.o cvmx-cmd-queue.o cvmx-helper-cfg.o	\
 	cvmx-pko-internal-ports-range.o cvmx-helper-agl.o \
 	cvmx-helper-board.o cvmx-helper.o cvmx-helper-xaui.o \
 	cvmx-helper-rgmii.o cvmx-helper-sgmii.o cvmx-helper-npi.o \
-	cvmx-helper-loop.o cvmx-helper-spi.o cvmx-helper-util.o
+	cvmx-helper-loop.o cvmx-helper-spi.o cvmx-helper-util.o	\
+	cvmx-pki-resources.o cvmx-gser.o cvmx-bgx.o
 
 obj-y += cvmx-helper-errata.o cvmx-helper-jtag.o
 obj-y += cvmx-pcie.o
diff --git a/arch/mips/cavium-octeon/executive/cvmx-agl.c b/arch/mips/cavium-octeon/executive/cvmx-agl.c
index ba46b94..c8d8884 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-agl.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-agl.c
@@ -193,7 +193,7 @@ int cvmx_agl_link_set(int port, cvmx_helper_link_info_t link_info, int mode)
 		/* MII (both speeds) and RGMII 1000 setting */
 		agl_clk.s.clk_cnt = 1;
 		/* Check other speeds for RGMII mode */
-		if (mode == CVMX_MGMT_PORT_RGMII_MODE) {
+		if ((mode == CVMX_MGMT_PORT_RGMII_MODE) || OCTEON_IS_OCTEON3()) {
 			if (link_info.s.speed == 10)
 				agl_clk.s.clk_cnt = 50;
 			else if (link_info.s.speed == 100)
@@ -211,5 +211,18 @@ int cvmx_agl_link_set(int port, cvmx_helper_link_info_t link_info, int mode)
 	agl_gmx_prtx.s.en = 1;
 	cvmx_write_csr(CVMX_AGL_GMX_PRTX_CFG(port), agl_gmx_prtx.u64);
 
+	if (OCTEON_IS_OCTEON3()) {
+		union cvmx_agl_prtx_ctl agl_prtx_ctl;
+		/* Enable the interface, set clkrst */
+		agl_prtx_ctl.u64 = cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
+		agl_prtx_ctl.s.clkrst = 1;
+		cvmx_write_csr(CVMX_AGL_PRTX_CTL(port), agl_prtx_ctl.u64);
+		cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
+		agl_prtx_ctl.s.enable = 1;
+		cvmx_write_csr(CVMX_AGL_PRTX_CTL(port), agl_prtx_ctl.u64);
+		/* Read the value back to force the previous write */
+		cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
+	}
+
 	return 0;
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-bch.c b/arch/mips/cavium-octeon/executive/cvmx-bch.c
new file mode 100644
index 0000000..6a515fc
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-bch.c
@@ -0,0 +1,300 @@
+/***********************license start***************
+ * Copyright (c) 2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+ *
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+ *
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+ *
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Interface to the CN70XX, CN78XX hardware BCH engine.
+ *
+ * <hr>$Revision: 79788 $<hr>
+ */
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+# include <asm/octeon/cvmx.h>
+# include <asm/octeon/cvmx-config.h>
+# include <asm/octeon/cvmx-bch-defs.h>
+# include <asm/octeon/cvmx-bch.h>
+# include <asm/octeon/cvmx-fpa.h>
+# include <asm/octeon/cvmx-helper-fpa.h>
+# include <asm/octeon/cvmx-cmd-queue.h>
+#elif defined(CVMX_BUILD_FOR_UBOOT)
+# include <common.h>
+# include <asm/arch/cvmx.h>
+# include <asm/arch/cvmx-bch-defs.h>
+# include <asm/arch/cvmx-bch.h>
+# include <asm/arch/cvmx-fpa.h>
+# include <asm/arch/cvmx-helper-fpa.h>
+# include <asm/arch/cvmx-cmd-queue.h>
+#else
+# include "cvmx.h"
+# include "cvmx-bch-defs.h"
+# include "cvmx-bch.h"
+# include "cvmx-fpa.h"
+# include "cvmx-helper-fpa.h"
+# include "cvmx-cmd-queue.h"
+#endif
+
+#ifndef CVMX_BUILD_FOR_UBOOT
+# ifdef DEBUG
+#  define debug(fmt, args...)	cvmx_dprintf(fmt, ##args)
+# else
+#  define debug(fmt, args...)
+# endif
+#endif
+
+CVMX_SHARED cvmx_bch_app_config_t bch_config = {
+	.command_queue_pool = {6, 1024, 0},
+	.aura = 6
+};
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+extern int cvm_oct_mem_fill_fpa(int pool, int elements);
+extern int cvm_oct_alloc_fpa_pool(int pool, int size);
+#endif
+
+/**
+ * Initialize the BCH block
+ *
+ * @return Zero on success, negative on failure
+ */
+int cvmx_bch_initialize(void)
+{
+	cvmx_bch_cmd_buf_t bch_cmd_buf;
+	cvmx_bch_ctl_t bch_ctl;
+	cvmx_cmd_queue_result_t result;
+	int bch_pool;
+	uint64_t bch_pool_size;
+
+	/* Initialize FPA pool for BCH pool buffers */
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+	bch_pool = CVMX_FPA_OUTPUT_BUFFER_POOL;
+	bch_pool_size = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE;
+
+	debug("pool: %d, pool size: %llu\n", bch_pool, bch_pool_size);
+	/* Setup the FPA */
+	cvmx_fpa_enable();
+
+	bch_pool = cvm_oct_alloc_fpa_pool(bch_pool, bch_pool_size);
+	if (bch_pool < 0) {
+		pr_err("cvm_oct_alloc_fpa_pool(%d, %lld)\n", bch_pool, bch_pool_size);
+		return -ENOMEM;
+	}
+	cvm_oct_mem_fill_fpa(bch_pool, 128);
+#else
+	bch_pool = (int)cvmx_fpa_get_bch_pool();
+	bch_pool_size = cvmx_fpa_get_bch_pool_block_size();
+
+	debug("%s: pool: %d, pool size: %llu, buffer count: %llu\n", __func__,
+	      bch_pool, bch_pool_size,
+	      bch_config.command_queue_pool.buffer_count);
+
+	cvmx_fpa_global_initialize();
+
+	if (bch_config.command_queue_pool.buffer_count != 0)
+		__cvmx_helper_initialize_fpa_pool(bch_pool, bch_pool_size,
+			bch_config.command_queue_pool.buffer_count,
+			"BCH Buffers");
+
+#endif
+	result = cvmx_cmd_queue_initialize(CVMX_CMD_QUEUE_BCH, 0, bch_pool,
+					   bch_pool_size);
+
+	if (result != CVMX_CMD_QUEUE_SUCCESS) {
+		cvmx_dprintf("%s: Error %d initializing command queue for BCH "
+			     "pool: %d, size: %llu\n",
+			     __func__, result, bch_pool,
+			     (unsigned long long)bch_pool_size);
+		return -1;
+	}
+
+	bch_cmd_buf.u64 = 0;
+	bch_cmd_buf.s.dwb = bch_pool_size / 128;
+	bch_cmd_buf.s.pool = bch_pool;
+	bch_cmd_buf.s.size = bch_pool_size / 8;
+	bch_cmd_buf.s.ptr =
+		cvmx_ptr_to_phys(cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_BCH)) >> 7;
+	cvmx_write_csr(CVMX_BCH_CMD_BUF, bch_cmd_buf.u64);
+	cvmx_write_csr(CVMX_BCH_GEN_INT, 7);
+	cvmx_write_csr(CVMX_BCH_GEN_INT_EN, 0);
+	bch_ctl.u64 = cvmx_read_csr(CVMX_BCH_CTL);
+	bch_ctl.s.free_ena = 1;
+	bch_ctl.s.one_cmd = 0;
+	bch_ctl.s.erase_disable = 0;
+	cvmx_write_csr(CVMX_BCH_CTL, bch_ctl.u64);
+	cvmx_read_csr(CVMX_BCH_CMD_BUF);
+	return 0;
+}
+
+/**
+ * Shutdown the BCH block
+ *
+ * @return Zero on success, negative on failure
+ */
+int cvmx_bch_shutdown(void)
+{
+	cvmx_bch_ctl_t bch_ctl;
+
+	debug("%s: ENTER\n", __func__);
+	bch_ctl.u64 = cvmx_read_csr(CVMX_BCH_CTL);
+	bch_ctl.s.reset = 1;
+	cvmx_write_csr(CVMX_BCH_CTL, bch_ctl.u64);
+	cvmx_wait(4);
+
+	cvmx_cmd_queue_shutdown(CVMX_CMD_QUEUE_BCH);
+
+	return 0;
+}
+
+/**
+ * Sets the internal FPA pool data structure for bch pool.
+ * @param pool	fpa pool number to use
+ * @param buffer_size	buffer size of pool
+ * @param buffer_count	number of buffers to allocate to pool
+ */
+void cvmx_bch_set_cmd_que_pool_config (int64_t pool, uint64_t buffer_size,
+				       uint64_t buffer_count)
+{
+	bch_config.command_queue_pool.pool_num = pool;
+	bch_config.command_queue_pool.buffer_size = buffer_size;
+	bch_config.command_queue_pool.buffer_count = buffer_count;
+}
+
+/**
+ * Gets the FPA pool data from internal data structure
+ * @param bch_pool pointer to the fpa data structure to copy data
+ */
+void cvmx_bch_get_cmd_que_pool_config(cvmx_fpa_pool_config_t *bch_pool)
+{
+	*bch_pool = bch_config.command_queue_pool;
+}
+
+/**
+ * Given a data block calculate the ecc data and fill in the response
+ *
+ * @param[in] block	8-byte aligned pointer to data block to calculate ECC
+ * @param block_size	Size of block in bytes, must be a multiple of two.
+ * @param ecc_level	Number of errors that must be corrected.  The number of
+ * 			parity bytes is equal to ((15 * ecc_level) + 7) / 8.
+ * 			Must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
+ * @param[out] ecc	8-byte aligned pointer to where ecc data should go
+ * @param[in] response	pointer to where responses will be written.
+ *
+ * @return Zero on success, negative on failure.
+ */
+int cvmx_bch_encode(const void *block, uint16_t block_size,
+		    uint8_t ecc_level, void *ecc,
+		    volatile cvmx_bch_response_t *response)
+{
+	cvmx_bch_command_t command;
+	cvmx_cmd_queue_result_t result;
+
+	debug("%s(%p, %u, %u, %p, %p) ENTRY\n", __func__, block, block_size,
+	      ecc_level, ecc, response);
+	memset(&result, 0, sizeof(result));
+	memset(&command, 0, sizeof(command));
+	command.s.cword.ecc_gen = CVMX_BCH_INST_ECC_GENERATION;
+	command.s.cword.ecc_level = ecc_level;
+	command.s.cword.size = block_size;
+
+	command.s.oword.ptr = cvmx_ptr_to_phys(ecc);
+	command.s.iword.ptr = cvmx_ptr_to_phys((void *)block);
+	command.s.resp.ptr = cvmx_ptr_to_phys((void *)response);
+	debug("Command: cword: 0x%llx, oword: 0x%llx, iword: 0x%llx, resp: 0x%llx\n",
+	      command.u64[0], command.u64[1], command.u64[2], command.u64[3]);
+	result = cvmx_cmd_queue_write(CVMX_CMD_QUEUE_BCH, 1,
+				      sizeof(command) / sizeof(uint64_t),
+				      command.u64);
+	if (result != CVMX_CMD_QUEUE_SUCCESS) {
+		cvmx_dprintf("%s: Error writing to queue\n", __func__);
+		return -1;
+	}
+
+	cvmx_bch_write_doorbell(1);
+
+	return 0;
+}
+
+/**
+ * Given a data block and ecc data correct the data block
+ *
+ * @param[in] block_ecc_in	8-byte aligned pointer to data block with ECC
+ *				data concatenated to the end to correct
+ * @param block_size		Size of block in bytes, must be a multiple of
+ *				two.
+ * @param ecc_level		Number of errors that must be corrected.  The
+ *				number of parity bytes is equal to
+ *				((15 * ecc_level) + 7) / 8.
+ * 				Must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
+ * @param[out] block_out	8-byte aligned pointer to corrected data buffer.
+ * 				This should not be the same as block_ecc_in.
+ * @param[in] response		pointer to where responses will be written.
+ *
+ * @return Zero on success, negative on failure.
+ */
+int cvmx_bch_decode(const void *block_ecc_in, uint16_t block_size,
+		    uint8_t ecc_level, volatile void *block_out,
+		    volatile cvmx_bch_response_t *response)
+{
+	cvmx_bch_command_t command;
+	cvmx_cmd_queue_result_t result;
+
+	debug("%s(%p, %u, %u, %p, %p) ENTRY\n", __func__, block_ecc_in,
+	      block_size, ecc_level, block_out, response);
+	memset(&result, 0, sizeof(result));
+	memset(&command, 0, sizeof(command));
+	command.s.cword.ecc_gen = CVMX_BCH_INST_BLOCK_CORRECTION;
+	command.s.cword.ecc_level = ecc_level;
+	command.s.cword.size = block_size;
+
+	command.s.oword.ptr = cvmx_ptr_to_phys((void *)block_out);
+ 	command.s.iword.ptr = cvmx_ptr_to_phys((void *)block_ecc_in);
+	command.s.resp.ptr = cvmx_ptr_to_phys((void *)response);
+	debug("Command: cword: 0x%llx, oword: 0x%llx, iword: 0x%llx, resp: 0x%llx\n",
+	      command.u64[0], command.u64[1], command.u64[2], command.u64[3]);
+	result = cvmx_cmd_queue_write(CVMX_CMD_QUEUE_BCH, 1,
+				      sizeof(command) / sizeof(uint64_t),
+				      command.u64);
+	if (result != CVMX_CMD_QUEUE_SUCCESS) {
+		cvmx_dprintf("%s: Error writing to queue\n", __func__);
+		return -1;
+	}
+
+	cvmx_bch_write_doorbell(1);
+	return 0;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-bgx.c
new file mode 100644
index 0000000..8e3f6e1
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-bgx.c
@@ -0,0 +1,255 @@
+/***********************license start***************
+ * Copyright (c) 2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Functions to configure the BGX MAC.
+ *
+ * <hr>$Revision$<hr>
+ */
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-helper.h>
+#include <asm/octeon/cvmx-qlm.h>
+#include <asm/octeon/cvmx-bgxx-defs.h>
+#else
+#include "cvmx.h"
+#include "cvmx-helper.h"
+#include "cvmx-qlm.h"
+#endif
+
+
+/**
+ * @INTERNAL
+ * Configure the bgx mac for xaui.
+ *
+ * @param interface Interface to initialize
+ *
+ * @param num_ports Number of ports on interface
+ *
+ * @return Zero on success, negative on failure
+ */
+static int bgx_xaui_init(int 	interface,
+			 int	num_ports)
+{
+	cvmx_bgxx_smux_tx_thresh_t	smu_tx_thresh;
+	cvmx_bgxx_spux_control1_t	spu_control1;
+	cvmx_bgxx_spux_misc_control_t	spu_misc_control;
+	cvmx_bgxx_cmrx_config_t		cmr_config;
+	int				val;
+	int				i;
+
+	smu_tx_thresh.u64 = 0;
+	smu_tx_thresh.s.cnt = 0x30;
+	cvmx_write_csr(CVMX_BGXX_SMUX_TX_THRESH(0, interface),
+		       smu_tx_thresh.u64);
+
+	spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(0, interface));
+	spu_control1.s.lo_pwr = 0;
+	cvmx_write_csr(CVMX_BGXX_SPUX_CONTROL1(0, interface), spu_control1.u64);
+
+	spu_misc_control.u64 =
+		cvmx_read_csr(CVMX_BGXX_SPUX_MISC_CONTROL(0, interface));
+	spu_misc_control.s.rx_packet_dis = 0;
+	cvmx_write_csr(CVMX_BGXX_SPUX_MISC_CONTROL(0, interface),
+		       spu_misc_control.u64);
+
+	/* Check if interface 0 or 1 must be routed to the mix */
+	if ((interface == 0 && MUX_78XX_IFACE0) ||
+	    (interface == 1 && MUX_78XX_IFACE1))
+		val = 1;
+	else
+		val = 0;
+
+	/* Enable bgx */
+	for (i = 0; i < num_ports; i++) {
+		cmr_config.u64 =
+			cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(i, interface));
+		cmr_config.s.lmac_type = 1;
+		cmr_config.s.mix_en = val;
+		cmr_config.s.lane_to_sds = 0xe4;
+		cmr_config.s.data_pkt_rx_en = 1;
+		cmr_config.s.data_pkt_tx_en = 1;
+		cmr_config.s.enable = 1;
+		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(i, interface),
+			       cmr_config.u64);
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Configure the bgx mac for sgmii.
+ *
+ * @param interface Interface to initialize
+ *
+ * @param num_ports Number of ports on interface
+ *
+ * @return Zero on success, negative on failure
+ */
+static int bgx_sgmii_init(int 	interface,
+			  int	num_ports)
+{
+	cvmx_bgxx_gmp_gmi_txx_thresh_t	gmp_gmi_tx_thresh;
+	cvmx_bgxx_gmp_gmi_prtx_cfg_t	gmp_gmi_prt_cfg;
+	cvmx_bgxx_gmp_pcs_mrx_control_t	gmp_pcs_mr_control;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t	gmp_pcs_misc_ctl;
+	cvmx_bgxx_cmrx_config_t		cmr_config;
+	int				val;
+	int				i;
+
+	for (i = 0; i < num_ports; i++) {
+		/* Configure gmp */
+		gmp_gmi_tx_thresh.u64 = 0;
+		gmp_gmi_tx_thresh.s.cnt = 0x30;
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_THRESH(i, interface),
+			       gmp_gmi_tx_thresh.u64);
+
+		gmp_gmi_prt_cfg.u64 = 0;
+		gmp_gmi_prt_cfg.s.speed = 1;
+		gmp_gmi_prt_cfg.s.speed_msb = 0;
+		gmp_gmi_prt_cfg.s.duplex = 1;
+		gmp_gmi_prt_cfg.s.slottime = 1;
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_PRTX_CFG(i, interface),
+			       gmp_gmi_prt_cfg.u64);
+
+		gmp_pcs_mr_control.u64 = 
+			cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(i, interface));
+		gmp_pcs_mr_control.s.pwr_dn = 0;
+		cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(i, interface),
+			       gmp_pcs_mr_control.u64);
+
+		gmp_pcs_misc_ctl.u64 = 
+			cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(i, interface));
+		gmp_pcs_misc_ctl.s.gmxeno = 0;
+		gmp_pcs_misc_ctl.s.mac_phy = 0;
+		gmp_pcs_misc_ctl.s.mode = 0;
+		cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(i, interface),
+			       gmp_pcs_misc_ctl.u64);
+	}
+
+	/* Check if interface 0 or 1 must be routed to the mix */
+	if ((interface == 0 && MUX_78XX_IFACE0) ||
+	    (interface == 1 && MUX_78XX_IFACE1))
+		val = 1;
+	else
+		val = 0;
+
+	/* Enable bgx */
+	for (i = 0; i < num_ports; i++) {
+		cmr_config.u64 =
+			cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(i, interface));
+		cmr_config.s.lmac_type = 0;
+		cmr_config.s.mix_en = val;
+		cmr_config.s.lane_to_sds = i;
+		cmr_config.s.data_pkt_rx_en = 1;
+		cmr_config.s.data_pkt_tx_en = 1;
+		cmr_config.s.enable = 1;
+		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(i, interface),
+			       cmr_config.u64);
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Configure the bgx mac.
+ *
+ * @param interface Interface to bring up
+ *
+ * @param mode      Mode to configure the bgx mac as
+ *
+ * @return Zero on success, negative on failure
+ */
+int bgx_init(int				interface,
+	     cvmx_helper_interface_mode_t	mode)
+{
+	cvmx_bgxx_cmrx_config_t		cmr_config;
+	cvmx_bgxx_cmr_rx_lmacs_t	bgx_cmr_rx_lmacs;
+	cvmx_bgxx_cmr_tx_lmacs_t	bgx_cmr_tx_lmacs;
+	cvmx_bgxx_cmr_global_config_t	bgx_cmr_global_config;
+	int				num_ports;
+	int				val;
+	int				i;
+
+	num_ports = cvmx_helper_ports_on_interface(interface);
+
+	/* Disable cmr for all interface ports */
+	for (i = 0; i < num_ports; i++) {
+		cmr_config.u64 =
+			cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(i, interface));
+		cmr_config.s.enable = 0;
+		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(i, interface),
+			       cmr_config.u64);
+	}
+
+	bgx_cmr_rx_lmacs.u64 = 0;
+	bgx_cmr_rx_lmacs.s.lmacs = num_ports;
+	cvmx_write_csr(CVMX_BGXX_CMR_RX_LMACS(interface),
+		       bgx_cmr_rx_lmacs.u64);
+
+	bgx_cmr_tx_lmacs.u64 = 0;
+	bgx_cmr_tx_lmacs.s.lmacs = num_ports;
+	cvmx_write_csr(CVMX_BGXX_CMR_TX_LMACS(interface),
+		       bgx_cmr_tx_lmacs.u64);
+
+	/* Check if interface 0 or 1 must be routed to the mix */
+	if ((interface == 0 && MUX_78XX_IFACE0) ||
+	    (interface == 1 && MUX_78XX_IFACE1))
+		val = 1;
+	else
+		val = 0;
+
+	bgx_cmr_global_config.u64 = 0;
+	bgx_cmr_global_config.s.pmux_sds_sel = val;
+	cvmx_write_csr(CVMX_BGXX_CMR_GLOBAL_CONFIG(interface),
+		       bgx_cmr_global_config.u64);
+
+	if (mode == CVMX_HELPER_INTERFACE_MODE_XAUI)
+		bgx_xaui_init(interface, num_ports);
+	else if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII)
+		bgx_sgmii_init(interface, num_ports);
+	else
+		return -1;
+
+	return 0;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-clock.c b/arch/mips/cavium-octeon/executive/cvmx-clock.c
index aebb4a5..a5d484c 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-clock.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-clock.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -53,8 +53,12 @@
 #include <asm/octeon/cvmx-pexp-defs.h>
 #include <asm/octeon/cvmx-dbg-defs.h>
 #include <asm/octeon/cvmx-rst-defs.h>
+#elif defined(CVMX_BUILD_FOR_UBOOT)
+#include <asm/arch/cvmx.h>
+#include <asm/arch/cvmx-access.h>
 #else
 #include "cvmx.h"
+#include "cvmx-access.h"
 #endif
 
 #ifndef CVMX_BUILD_FOR_UBOOT
@@ -66,10 +70,11 @@ static uint64_t rate_dclk = 0;
 /**
  * Get clock rate based on the clock type.
  *
+ * @param node  - CPU node number
  * @param clock - Enumeration of the clock type.
  * @return      - return the clock rate.
  */
-uint64_t cvmx_clock_get_rate(cvmx_clock_t clock)
+uint64_t cvmx_clock_get_rate_node(int node, cvmx_clock_t clock)
 {
 	const uint64_t REF_CLOCK = 50000000;
 
@@ -90,7 +95,7 @@ uint64_t cvmx_clock_get_rate(cvmx_clock_t clock)
 			rate_sclk = rate_eclk;
 		} else if (OCTEON_IS_OCTEON3()) {
 			cvmx_rst_boot_t rst_boot;
-			rst_boot.u64 = cvmx_read_csr(CVMX_RST_BOOT);
+			rst_boot.u64 = cvmx_read_csr_node(node, CVMX_RST_BOOT);
 			rate_eclk = REF_CLOCK * rst_boot.s.c_mul;
 			rate_sclk = REF_CLOCK * rst_boot.s.pnr_mul;
 		} else if (octeon_has_feature(OCTEON_FEATURE_PCIE)) {
@@ -128,4 +133,15 @@ uint64_t cvmx_clock_get_rate(cvmx_clock_t clock)
 	return 0;
 }
 
+EXPORT_SYMBOL(cvmx_clock_get_rate_node);
+
+uint64_t cvmx_clock_get_rate(cvmx_clock_t clock)
+{
+#if !defined(CVMX_BUILD_FOR_LINUX_HOST)
+	return cvmx_clock_get_rate_node(cvmx_get_node_num(), clock);
+#else
+	return cvmx_clock_get_rate_node(0, clock);
+#endif
+}
+
 EXPORT_SYMBOL(cvmx_clock_get_rate);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c b/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
index 0ab102b..8d98a6a 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -43,7 +43,7 @@
  * Support functions for managing command queues used for
  * various hardware blocks.
  *
- * <hr>$Revision: 78972 $<hr>
+ * <hr>$Revision: 91009 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
@@ -175,10 +175,13 @@ cvmx_cmd_queue_result_t cvmx_cmd_queue_initialize(cvmx_cmd_queue_id_t queue_id,
 		union cvmx_fpa_ctl_status status;
 		void *buffer;
 
-		status.u64 = cvmx_read_csr(CVMX_FPA_CTL_STATUS);
-		if (!status.s.enb) {
-			cvmx_dprintf("ERROR: cvmx_cmd_queue_initialize: FPA is not enabled.\n");
-			return CVMX_CMD_QUEUE_NO_MEMORY;
+		if (!(octeon_has_feature(OCTEON_FEATURE_FPA3))) {
+			status.u64 = cvmx_read_csr(CVMX_FPA_CTL_STATUS);
+			if (!status.s.enb) {
+				cvmx_dprintf("ERROR: cvmx_cmd_queue_initialize:"
+					     " FPA is not enabled.\n");
+				return CVMX_CMD_QUEUE_NO_MEMORY;
+			}
 		}
 		buffer = cvmx_fpa_alloc(fpa_pool);
 		if (buffer == NULL) {
@@ -289,6 +292,9 @@ int cvmx_cmd_queue_length(cvmx_cmd_queue_id_t queue_id)
 			dmax_counts.u64 = cvmx_read_csr(CVMX_DPI_DMAX_COUNTS(queue_id & 0x7));
 			return dmax_counts.s.dbell;
 		}
+	case CVMX_CMD_QUEUE_BCH:
+		/* Not available */
+		return 0;
 	case CVMX_CMD_QUEUE_END:
 		return CVMX_CMD_QUEUE_INVALID_PARAM;
 	}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-debug-handler.S b/arch/mips/cavium-octeon/executive/cvmx-debug-handler.S
index e67164d..c6bf91d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-debug-handler.S
+++ b/arch/mips/cavium-octeon/executive/cvmx-debug-handler.S
@@ -144,7 +144,7 @@ __cvmx_debug_handler_stage2:
 	// Use reserved space in kseg0 to save off some temp regs
         mfc0    k0, $15, 1  // read exception base reg.
         andi    k0, 0xff    // mask off core ID
-        sll     k0, 12      // multiply by 4096 (512 dwords) DEBUG_NUMREGS
+        sll     k0, 4      // multiply by 16 (2 dwords) DEBUG_NUMREGS
 
         addiu   k0,  REG_SAVE_BASE_DIV_8
         addiu   k0,  REG_SAVE_BASE_DIV_8
@@ -162,8 +162,8 @@ __cvmx_debug_handler_stage2:
 
 	// save off k1 and at ($1) off to the bootloader reg save area
 	// at is used by dla
-	sd      $1, 8(k0)	// save at for temp usage
-	sd      k1, 216(k0)	// save k1 for temp usage
+	sd      $1, 0(k0)	// save at for temp usage
+	sd      k1, 8(k0)	// save k1 for temp usage
 
 
 	// Detect debug-mode exception.
@@ -204,8 +204,8 @@ __cvmx_debug_handler_stage2:
 	nop
 
 	// Restore k1 and at from the bootloader reg save area
-	ld      $1, 8(k0)	// save at for temp usage
-	ld      k1, 216(k0)	// save k1 for temp usage
+	ld      $1, 0(k0)	// save at for temp usage
+	ld      k1, 8(k0)	// save k1 for temp usage
 
 	dmfc0	k0, COP0_DEPC
 	// Skip the faulting instruction.
@@ -218,7 +218,7 @@ noexc:
 	loadaddr (k1, __cvmx_debug_save_regs_area, 8)
 
 	// Restore at
-	ld      $1, 8(k0)	// restore at for temp usage
+	ld      $1, 0(k0)	// restore at for temp usage
 
 	.irp	n, REGS0
 	sd	$\n, 0(k1)
@@ -226,7 +226,7 @@ noexc:
 	.endr
 
 	move	$25, k1
-	ld      k1, 216(k0)	// restore k1 for temp usage
+	ld      k1, 8(k0)	// restore k1 for temp usage
 	move	k0, $25
 
 	// Store out k0, we can use $25 here because we just saved it
@@ -239,6 +239,11 @@ noexc:
 	addiu	k0, 8
 	.endr
 	
+	dla k1, __cvmx_debug_has_wide_mult
+	lw k1, 0(k1)
+	blez k1, cvmx_mpy_save_finish
+	nop
+
 	dla k1, __cvmx_debug_is_octeon3
 	lw k1, 0(k1)
 	blez k1, not_oct3_save
@@ -291,6 +296,7 @@ not_oct3_save:
 	sd $2, 32(k1)
 	sd $3, 40(k1)
 cvmx_mpy_save_finish:
+
 	//Save fp registers in OCTEON3
 	dmfc0 k0, COP0_CONFIG1
 	bbit0 k0,0, fpu_nonexist
@@ -368,6 +374,11 @@ fpu_nonexist:
 	.set pop
 fpu_nonexist_restore:
 
+	dla k1, __cvmx_debug_has_wide_mult
+	lw k1, 0(k1)
+	blez k1, cvmx_mpy_restore_finish
+	nop
+
 	dla k1, __cvmx_debug_is_octeon3
 	lw k1, 0(k1)
 	blez k1, not_oct3_restore
diff --git a/arch/mips/cavium-octeon/executive/cvmx-debug.c b/arch/mips/cavium-octeon/executive/cvmx-debug.c
index 51e25e6..548d2ae 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-debug.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-debug.c
@@ -143,8 +143,10 @@ char *__cvmx_debug_stack_top_all[CVMX_MAX_CORES];
 #define cvmx_interrupt_in_isr 0
 
 #endif
-/* This variable is used in assembly to determine if the target is Octeon3 or not */
+/* This variable is used in the assembly to determine if the target is Octeon3 or not. */
 uint32_t __cvmx_debug_is_octeon3;
+/* This variable is used in the assembly to determine if the core has wide multiply or not. */
+uint32_t __cvmx_debug_has_wide_mult;
 
 static size_t cvmx_debug_strlen(const char *str)
 {
@@ -172,7 +174,7 @@ static void cvmx_debug_memcpy_align(void *dest, const void *src, int size)
 	long long *dest1 = (long long *)dest;
 	const long long *src1 = (const long long *)src;
 	int i;
-	if (size == 40) {
+	if (size == 80) {
 		long long a0, a1, a2, a3, a4;
 		a0 = src1[0];
 		a1 = src1[1];
@@ -184,6 +186,16 @@ static void cvmx_debug_memcpy_align(void *dest, const void *src, int size)
 		dest1[2] = a2;
 		dest1[3] = a3;
 		dest1[4] = a4;
+		a0 = src1[5 + 0];
+		a1 = src1[5 + 1];
+		a2 = src1[5 + 2];
+		a3 = src1[5 + 3];
+		a4 = src1[5 + 4];
+		dest1[5 + 0] = a0;
+		dest1[5 + 1] = a1;
+		dest1[5 + 2] = a2;
+		dest1[5 + 3] = a3;
+		dest1[5 + 4] = a4;
 		return;
 	}
 	for (i = 0; i < size; i += 8) {
@@ -203,16 +215,14 @@ static inline cvmx_coremask_t *cvmx_debug_core_mask(void)
 #endif
 }
 
-static inline void cvmx_debug_update_state(cvmx_debug_state_t state)
+static inline void cvmx_debug_update_state(cvmx_debug_state_t *state)
 {
-	cvmx_debug_memcpy_align(cvmx_debug_globals->state, &state, sizeof(cvmx_debug_state_t));
+	cvmx_debug_memcpy_align(cvmx_debug_globals->state, state, sizeof(cvmx_debug_state_t));
 }
 
-static inline cvmx_debug_state_t cvmx_debug_get_state(void)
+static inline void cvmx_debug_get_state(cvmx_debug_state_t *state)
 {
-	cvmx_debug_state_t state;
-	cvmx_debug_memcpy_align(&state, cvmx_debug_globals->state, sizeof(cvmx_debug_state_t));
-	return state;
+	cvmx_debug_memcpy_align(state, cvmx_debug_globals->state, sizeof(cvmx_debug_state_t));
 }
 
 static void cvmx_debug_printf(char *format, ...) __attribute__ ((format(__printf__, 1, 2)));
@@ -228,9 +238,9 @@ static void cvmx_debug_printf(char *format, ...)
 	va_end(ap);
 }
 
-static inline int __cvmx_debug_in_focus(cvmx_debug_state_t state, unsigned core)
+static inline int __cvmx_debug_in_focus(cvmx_debug_state_t *state, unsigned core)
 {
-	return state.focus_core == core;
+	return state->focus_core == core;
 }
 
 static void cvmx_debug_install_handler(unsigned core)
@@ -319,13 +329,20 @@ void cvmx_debug_init(void)
 	if (!cvmx_debug_enabled())
 		return;
 
-	/*Set this flag so that it can be checked in assembly while saving wide multiply registers*/
-	__cvmx_debug_is_octeon3=OCTEON_IS_OCTEON3();
+	/* Set this flag so that it can be checked in assembly while saving wide multiply registers. */
+	__cvmx_debug_is_octeon3 = OCTEON_IS_OCTEON3();
+	{
+		uint64_t t;
+		CVMX_MF_CVM_CTL(t);
+		/* Wide mult is enabled when CvmCtl[NOMUL] is cleared. */
+		__cvmx_debug_has_wide_mult = !(t & (1ull << 27));
+	}
 
 	cvmx_debug_init_globals();
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	// Put a barrier until all cores have got to this point.
+	/* Put a barrier until all cores have got to this point.
+	   Except the linux kernel as it is only called once.  */
 	cvmx_coremask_barrier_sync(pcm);
 #endif
 	cvmx_debug_globals_check_version();
@@ -335,7 +352,7 @@ void cvmx_debug_init(void)
 
 	core = cvmx_get_core_num();
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	/*  Install the debugger handler on the cores. */
+	/*  Install the debugger handler on all of the cores. */
 	{
 		int core1 = 0;
 		cvmx_coremask_for_each_core(core1, pcm) {
@@ -351,41 +368,43 @@ void cvmx_debug_init(void)
 
 	{
 		cvmx_spinlock_lock(lock);
-		state = cvmx_debug_get_state();
+		cvmx_debug_get_state(&state);
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+		/* The Linux kernel only calls this once for the init core,
+		   setup the known cores to be all of the cores that Linux knows about. */
 		{
-		uint32_t coremask = cvmx_coremask_get32(pcm);
-		state.known_cores |= coremask;
-		state.core_finished &= ~coremask;
+			uint64_t coremask = cvmx_coremask_get64(pcm);
+			state.known_cores |= coremask;
+			state.core_finished &= ~coremask;
 		}
 #else
-		state.known_cores |= (1u << core);
-		state.core_finished &= ~(1u << core);
+		state.known_cores |= (1ull << core);
+		state.core_finished &= ~(1ull << core);
 #endif
-		cvmx_debug_update_state(state);
+		cvmx_debug_update_state(&state);
 		cvmx_spinlock_unlock(lock);
 	}
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	// Put a barrier until all cores have got to this point.
+	/* Put a barrier until all cores have got to this point. */
 	cvmx_coremask_barrier_sync(pcm);
 
-	if (cvmx_coremask_is_first_core(pcm))
+	if (cvmx_is_init_core())
 #endif
 	{
 		cvmx_debug_printf("cvmx_debug_init core: %d\n", core);
-		state = cvmx_debug_get_state();
+		cvmx_debug_get_state(&state);
 		state.focus_core = core;
 		state.active_cores = state.known_cores;
 		state.focus_switch = 1;
 		state.step_isr = 1;
 		/* COMMAND_NOP might not be 0. */
 		state.command = COMMAND_NOP;
-		cvmx_debug_printf("Known cores at init: 0x%x\n", (int)state.known_cores);
-		cvmx_debug_update_state(state);
+		cvmx_debug_printf("Known cores at init: 0x%llx\n", (long long)state.known_cores);
+		cvmx_debug_update_state(&state);
 
-		/* Initialize __cvmx_debug_stack_top_all. */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+		/* Initialize __cvmx_debug_stack_top_all for Linux kernel, all cores share the same address space. */
 		{
 			int i;
 			for (i = 0; i < CVMX_MAX_CORES; i++)
@@ -405,7 +424,7 @@ void cvmx_debug_init(void)
 
 	/*  Install the break handler after might tripper the debugger exception. */
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	if (cvmx_coremask_is_first_core(pcm))
+	if (cvmx_is_init_core())
 #endif
 	{
 		if (comm->install_break_handler)
@@ -485,9 +504,9 @@ static int cvmx_debug_putpacket_hexint(char *buf, uint64_t value)
 	return cvmx_debug_putpacket_noformat(packet);
 }
 
-static int cvmx_debug_active_core(cvmx_debug_state_t state, unsigned core)
+static int cvmx_debug_active_core(cvmx_debug_state_t *state, unsigned core)
 {
-	return state.active_cores & (1u << core);
+	return state->active_cores & (1ull << core);
 }
 
 static volatile cvmx_debug_core_context_t *cvmx_debug_core_context(void)
@@ -500,7 +519,7 @@ static volatile uint64_t *cvmx_debug_regnum_to_context_ref(int regnum, volatile
 	/* Must be kept in sync with mips_octeon_reg_names in gdb/mips-tdep.c. */
 	if (regnum < 32)
 		return &context->regs[regnum];
-/* Return fp registers in OCTEON3 */
+	/* Return fp registers for Octeon 3*/
 	if(37 < regnum && regnum < 70)
 		return &context->fp_regs[regnum-38];
 
@@ -531,23 +550,21 @@ static int cvmx_debug_probe_load(unsigned char *ptr, unsigned char *result)
 	volatile unsigned char *p = ptr;
 	int ok;
 	unsigned char tem;
+	__cvmx_debug_mode_exception_ignore = 1;
+	__cvmx_debug_mode_exception_occured = 0;
+	/* Force a byte load so that it will not be in a delay slot */
+	asm volatile (".set push	\n\t"
+		      ".set noreorder	\n\t"
+		      "nop		\n\t"
+		      "lbu %0, %1	\n\t"
+		      "nop		\n\t"
+		      ".set pop"
+		      : "=r" (tem) : "m"(*p));
+	ok = __cvmx_debug_mode_exception_occured == 0;
+	__cvmx_debug_mode_exception_ignore = 0;
+	__cvmx_debug_mode_exception_occured = 0;
+	*result = tem;
 
-	{
-		__cvmx_debug_mode_exception_ignore = 1;
-		__cvmx_debug_mode_exception_occured = 0;
-		/* We don't handle debug-mode exceptions in delay slots.  Avoid them.  */
-		asm volatile (".set push	\n\t"
-			      ".set noreorder	\n\t"
-			      "nop		\n\t"
-			      "lbu %0, %1	\n\t"
-			      "nop		\n\t"
-			      ".set pop"
-			      : "=r" (tem) : "m"(*p));
-		ok = __cvmx_debug_mode_exception_occured == 0;
-		__cvmx_debug_mode_exception_ignore = 0;
-		__cvmx_debug_mode_exception_occured = 0;
-		*result = tem;
-	}
 	return ok;
 }
 
@@ -558,7 +575,7 @@ static int cvmx_debug_probe_store(unsigned char *ptr)
 
 	__cvmx_debug_mode_exception_ignore = 1;
 	__cvmx_debug_mode_exception_occured = 0;
-	/* We don't handle debug-mode exceptions in delay slots.  Avoid them.  */
+	/* Force a byte store so that it will not be in a delay slot */
 	asm volatile (".set push	\n\t"
 		      ".set noreorder	\n\t"
 		      "nop		\n\t"
@@ -642,7 +659,8 @@ static cvmx_debug_command_t cvmx_debug_process_packet(const char *packet)
 {
 	const char *buf = packet;
 	cvmx_debug_command_t result = COMMAND_NOP;
-	cvmx_debug_state_t state = cvmx_debug_get_state();
+	cvmx_debug_state_t state;
+	cvmx_debug_get_state(&state);
 
 	/* A one letter command code represents what to do.  */
 	switch (*buf++) {
@@ -663,14 +681,14 @@ static cvmx_debug_command_t cvmx_debug_process_packet(const char *packet)
 			/* Only cores in the exception handler may become the focus.
 			   If a core not in the exception handler got focus the
 			   debugger would hang since nobody would talk to it.  */
-			else if (state.handler_cores & (1u << core)) {
+			else if (state.handler_cores & (1ull << core)) {
 				/* Focus change reply must be sent before the focus
 				   changes. Otherwise the new focus core will eat our ACK
 				   from the debugger.  */
 				cvmx_debug_putpacket_hexint("F", core);
 				cvmx_debug_comms[cvmx_debug_globals->comm_type]->change_core(state.focus_core, core);
 				state.focus_core = core;
-				cvmx_debug_update_state(state);
+				cvmx_debug_update_state(&state);
 				break;
 			} else
 				cvmx_debug_putpacket_noformat("!Core is not in the exception handler. Focus not changed.");
@@ -687,7 +705,7 @@ static cvmx_debug_command_t cvmx_debug_process_packet(const char *packet)
 				state.step_isr = 1;	/* Step in ISR */
 			else
 				state.step_isr = 0;	/* Step over ISR */
-			cvmx_debug_update_state(state);
+			cvmx_debug_update_state(&state);
 		}
 		/* Fall through. The reply to the set step-isr command is the
 		   same as the get step-isr command */
@@ -709,12 +727,12 @@ static cvmx_debug_command_t cvmx_debug_process_packet(const char *packet)
 				state.active_cores = state.known_cores;
 
 			/* The focus core must be in the active_cores mask */
-			if ((state.active_cores & (1u << state.focus_core)) == 0) {
+			if ((state.active_cores & (1ull << state.focus_core)) == 0) {
 				cvmx_debug_putpacket_noformat("!Focus core was added to the masked.");
-				state.active_cores |= 1u << state.focus_core;
+				state.active_cores |= 1ull << state.focus_core;
 			}
 
-			cvmx_debug_update_state(state);
+			cvmx_debug_update_state(&state);
 		}
 		/* Fall through. The reply to the set active cores command is the
 		   same as the get active cores command */
@@ -729,7 +747,7 @@ static cvmx_debug_command_t cvmx_debug_process_packet(const char *packet)
 				state.step_all = 1;	/* A step or continue will start all cores */
 			else
 				state.step_all = 0;	/* A step or continue only affects the focus core */
-			cvmx_debug_update_state(state);
+			cvmx_debug_update_state(&state);
 		}
 		/* Fall through. The reply to the set step-all command is the
 		   same as the get step-all command */
@@ -1056,14 +1074,15 @@ static cvmx_debug_command_t cvmx_debug_process_next_packet(int needs_proxy, vola
    that when the cores in active core mask are done executing the program, the
    focus will not be transfered to this core.  */
 
-static int cvmx_debug_stop_core(cvmx_debug_state_t state, unsigned core, cvmx_debug_register_t * debug_reg, int proxy)
+static int cvmx_debug_stop_core(cvmx_debug_state_t *state, unsigned core,
+		 cvmx_debug_register_t *debug_reg, int proxy)
 {
 	if (!cvmx_debug_active_core(state, core) && !debug_reg->s.dbp && !debug_reg->s.dss && (debug_reg->s.dint != 1)) {
 		debug_reg->s.sst = 0;
 		cvmx_debug_printf("Core #%d not in active cores, continuing.\n", core);
 		return 0;
 	}
-	if ((state.core_finished & (1u << core)) && proxy)
+	if ((state->core_finished & (1ull << core)) && proxy)
 		return 0;
 	return 1;
 }
@@ -1088,7 +1107,7 @@ static void cvmx_debug_set_focus_core(cvmx_debug_state_t * state, int core)
 static void cvmx_debug_may_elect_as_focus_core(cvmx_debug_state_t * state, int core, cvmx_debug_register_t * debug_reg)
 {
 	/* If another core has already elected itself as the focus core, we're late.  */
-	if (state->handler_cores & (1u << state->focus_core))
+	if (state->handler_cores & (1ull << state->focus_core))
 		return;
 
 	/* If we hit a breakpoint, elect ourselves.  */
@@ -1098,7 +1117,7 @@ static void cvmx_debug_may_elect_as_focus_core(cvmx_debug_state_t * state, int c
 	/* It is possible the focus core has completed processing and exited the
 	   program. When this happens the focus core will not be in
 	   known_cores. If this is the case we need to elect a new focus. */
-	if ((state->known_cores & (1u << state->focus_core)) == 0)
+	if ((state->known_cores & (1ull << state->focus_core)) == 0)
 		cvmx_debug_set_focus_core(state, core);
 }
 
@@ -1132,18 +1151,18 @@ static void cvmx_debug_sync_up_cores(void)
 	/* NOTE this reads directly from the state array for speed reasons
 	   and we don't change the array. */
 	do {
-asm("": : :	"memory");
-	} while (cvmx_debug_globals->state[offsetof(cvmx_debug_state_t, step_all) / sizeof(uint32_t)]
-		 && cvmx_debug_globals->state[offsetof(cvmx_debug_state_t, handler_cores) / sizeof(uint32_t)] != 0);
+		asm("" : : : "memory");
+	} while (cvmx_debug_globals->state[offsetof(cvmx_debug_state_t, step_all) / sizeof(uint64_t)]
+		 && cvmx_debug_globals->state[offsetof(cvmx_debug_state_t, handler_cores) / sizeof(uint64_t)] != 0);
 }
 
 /* Delay the focus core a little if it is likely another core needs to steal
    focus. Once we enter the main loop focus can't be stolen */
-static void cvmx_debug_delay_focus_core(cvmx_debug_state_t state, unsigned core, cvmx_debug_register_t * debug_reg)
+static void cvmx_debug_delay_focus_core(cvmx_debug_state_t *state, unsigned core, cvmx_debug_register_t *debug_reg)
 {
 	volatile int i;
 	/* Don't delay for single stepping or a breakpoint was hit.  */
-	if (debug_reg->s.dss || debug_reg->s.dbp || core != state.focus_core)
+	if (debug_reg->s.dss || debug_reg->s.dbp || core != state->focus_core)
 		return;
 
 	for (i = 0; i < 4800; i++) {
@@ -1162,19 +1181,19 @@ static void cvmx_debug_delay_focus_core(cvmx_debug_state_t state, unsigned core,
    && it was not the last focus-core,
    && last focus-core happens to be inside an ISR, blocking focus-switch
    then burn some cycles, to avoid unnecessary focus toggles. */
-static void cvmx_debug_delay_isr_core(unsigned core, uint32_t depc, int single_stepped_exc_only, cvmx_debug_state_t state)
+static void cvmx_debug_delay_isr_core(unsigned core, uint32_t depc, int single_stepped_exc_only, cvmx_debug_state_t *state)
 {
 	volatile uint64_t i;
-	if (!single_stepped_exc_only || state.step_isr || core == state.focus_core || state.focus_switch)
+	if (!single_stepped_exc_only || state->step_isr || core == state->focus_core || state->focus_switch)
 		return;
 
 	cvmx_debug_printf("Core #%u spinning for focus at 0x%x\n", core, (unsigned int)depc);
 
 	for (i = ISR_DELAY_COUNTER; i > 0; i--) {
-		state = cvmx_debug_get_state();
+		cvmx_debug_get_state(state);
 		/* Spin giving the focus core time to service ISR */
 		/* But cut short the loop, if we can.  Shrink down i, only once. */
-		if (i > 600000 && state.focus_switch)
+		if (i > 600000 && state->focus_switch)
 			i = 500000;
 	}
 
@@ -1183,10 +1202,12 @@ static void cvmx_debug_delay_isr_core(unsigned core, uint32_t depc, int single_s
 static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvmx_debug_core_context_t * context, int needs_proxy)
 {
 	unsigned core = cvmx_get_core_num();
-	cvmx_debug_state_t state = cvmx_debug_get_state();
+	cvmx_debug_state_t state;
 	cvmx_debug_command_t command = COMMAND_NOP;
 	int single_stepped_exc_only = cvmx_debug_single_step_exc(debug_reg);
 
+	cvmx_debug_get_state(&state);
+
 	/* All cores should respect the focus core if it has to
 	   stop focus switching while servicing an interrupt.
 	   If the system is single-stepping, then the following
@@ -1197,7 +1218,7 @@ static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvm
 	   the debugger exception stub fully. */
 	if (!state.step_isr && (cvmx_interrupt_in_isr || (context->cop0.status & 0x2ULL)) && single_stepped_exc_only) {
 		cvmx_spinlock_lock(&cvmx_debug_globals->lock);
-		state = cvmx_debug_get_state();
+		cvmx_debug_get_state(&state);
 		/* If this is the focus core, switch off focus switching
 		   till ISR_DELAY_COUNTER. This will let focus core
 		   keep the focus until the ISR is completed. */
@@ -1213,7 +1234,7 @@ static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvm
 					  (unsigned long long)context->cop0.depc);
 			state.focus_switch = 1;
 		}
-		cvmx_debug_update_state(state);
+		cvmx_debug_update_state(&state);
 		cvmx_spinlock_unlock(&cvmx_debug_globals->lock);
 		cvmx_debug_printf("Core #%u resumed skipping isr.\n", core);
 		return 0;
@@ -1221,9 +1242,9 @@ static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvm
 
 	/* Delay the focus core a little if it is likely another core needs to
 	   steal focus. Once we enter the main loop focus can't be stolen */
-	cvmx_debug_delay_focus_core(state, core, debug_reg);
+	cvmx_debug_delay_focus_core(&state, core, debug_reg);
 
-	cvmx_debug_delay_isr_core(core, context->cop0.depc, single_stepped_exc_only, state);
+	cvmx_debug_delay_isr_core(core, context->cop0.depc, single_stepped_exc_only, &state);
 
 	/* The following section of code does two critical things. First, it
 	   populates the handler_cores bitmask of all cores in the exception
@@ -1232,36 +1253,38 @@ static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvm
 	{
 		cvmx_debug_printf("Core #%d stopped\n", core);
 		cvmx_spinlock_lock(&cvmx_debug_globals->lock);
-		state = cvmx_debug_get_state();
+		cvmx_debug_get_state(&state);
 
-		state.handler_cores |= (1u << core);
+		state.handler_cores |= (1ull << core);
 		cvmx_debug_may_elect_as_focus_core(&state, core, debug_reg);
 
-/* Push all updates before exiting the critical section */
+		/* Push all updates before exiting the critical section */
 		state.focus_switch = 1;
-		cvmx_debug_update_state(state);
+		cvmx_debug_update_state(&state);
 		cvmx_spinlock_unlock(&cvmx_debug_globals->lock);
 	}
-	if (__cvmx_debug_in_focus(state, core))
+	if (__cvmx_debug_in_focus(&state, core))
 		cvmx_debug_send_stop_reason(debug_reg, context);
 
 	do {
 		unsigned oldfocus = state.focus_core;
-		state = cvmx_debug_get_state();
+		cvmx_debug_get_state(&state);
 		/* Note the focus core can change in this loop. */
-		if (__cvmx_debug_in_focus(state, core)) {
+		if (__cvmx_debug_in_focus(&state, core)) {
 			if (context->remote_controlled == COMMAND_NOT_FOCUS && !needs_proxy)
 				context->remote_controlled = COMMAND_NOP;
 			CVMX_SYNCW;
 
 			/* If the focus has changed and the old focus has exited, then send a signal
 			   that we should stop if step_all is off.  */
-			if (oldfocus != state.focus_core && ((1u << oldfocus) & state.core_finished)
+			if (oldfocus != state.focus_core && ((1ull << oldfocus) & state.core_finished)
 			    && !state.step_all)
 				cvmx_debug_send_stop_reason(debug_reg, context);
 
 			command = cvmx_debug_process_next_packet(needs_proxy, context);
-			state = cvmx_debug_get_state();
+
+			cvmx_spinlock_lock(&cvmx_debug_globals->lock);
+			cvmx_debug_get_state(&state);
 			if (command == COMMAND_NOT_FOCUS && state.focus_core != core) {
 				cvmx_debug_printf("change focus recieved to %d.\n", (int)state.focus_core);
 				command = COMMAND_NOP;
@@ -1270,11 +1293,12 @@ static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvm
 			   step-all.  */
 			if (command != COMMAND_NOP && state.step_all) {
 				state.command = command;
-				cvmx_debug_update_state(state);
+				cvmx_debug_update_state(&state);
 			}
+			cvmx_spinlock_unlock(&cvmx_debug_globals->lock);
 		} else {
 			volatile int i;
-			/* Do a small sleep just so there is some time to process a focus change. */
+			/* Do a small sleep (around 2000 cycles) just so there is some time to process a focus change. */
 			for (i = 0; i < 240; i++)
 				asm volatile (".set push	\n\t"
 					      ".set noreorder	\n\t"
@@ -1291,10 +1315,14 @@ static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvm
 		/* If we did not get a command and the communication changed return,
 		   we are changing the communications. */
 		if (command == COMMAND_NOP && cvmx_debug_globals->comm_changed) {
-			/* FIXME, this should a sync not based on cvmx_coremask_barrier_sync.  */
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+			cvmx_coremask_t cm = CVMX_COREMASK_EMPTY;
+
+			/* FIXME: Debugger is limited at 64 cores */
+			cvmx_coremask_set64(&cm, state.handler_cores);
+			/* FIXME, this should a sync not based on cvmx_coremask_barrier_sync.  */
 			/* Sync up.  */
-			cvmx_coremask_barrier_sync(state.handler_cores);
+			cvmx_coremask_barrier_sync(&cm);
 #endif
 			return 1;
 		}
@@ -1305,19 +1333,19 @@ static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvm
 
 	{
 		cvmx_spinlock_lock(&cvmx_debug_globals->lock);
-		state = cvmx_debug_get_state();
-		state.handler_cores ^= (1u << core);
-		cvmx_debug_update_state(state);
+		cvmx_debug_get_state(&state);
+		state.handler_cores ^= (1ull << core);
+		cvmx_debug_update_state(&state);
 		cvmx_spinlock_unlock(&cvmx_debug_globals->lock);
 	}
 
 	cvmx_debug_sync_up_cores();
 	/* Now that all cores are out, reset the command.  */
-	if (__cvmx_debug_in_focus(state, core)) {
+	if (__cvmx_debug_in_focus(&state, core)) {
 		cvmx_spinlock_lock(&cvmx_debug_globals->lock);
-		state = cvmx_debug_get_state();
+		cvmx_debug_get_state(&state);
 		state.command = COMMAND_NOP;
-		cvmx_debug_update_state(state);
+		cvmx_debug_update_state(&state);
 		cvmx_spinlock_unlock(&cvmx_debug_globals->lock);
 	}
 	return 0;
@@ -1483,9 +1511,9 @@ void __cvmx_debug_handler_stage3(uint64_t lo, uint64_t hi)
 	{
 		cvmx_debug_state_t state;
 		cvmx_spinlock_lock(&cvmx_debug_globals->lock);
-		state = cvmx_debug_get_state();
+		cvmx_debug_get_state(&state);
 		state.ever_been_in_debug = 1;
-		cvmx_debug_update_state(state);
+		cvmx_debug_update_state(&state);
 		cvmx_spinlock_unlock(&cvmx_debug_globals->lock);
 	}
 	cvmx_debug_print_cause(context);
@@ -1520,12 +1548,12 @@ void __cvmx_debug_handler_stage3(uint64_t lo, uint64_t hi)
 			cvmx_debug_state_t state;
 			unsigned core = cvmx_get_core_num();
 
-			state = cvmx_debug_get_state();
+			cvmx_debug_get_state(&state);
 			debug_reg.u64 = context->cop0.debug;
 			/* All cores stop on any exception.  See if we want nothing from this and
 			   it should resume.  This needs to be done for non proxy based debugging
 			   so that some non active-cores can control the other cores.  */
-			if (!cvmx_debug_stop_core(state, core, &debug_reg, needs_proxy)) {
+			if (!cvmx_debug_stop_core(&state, core, &debug_reg, needs_proxy)) {
 				context->cop0.debug = debug_reg.u64;
 				break;
 			}
@@ -1549,7 +1577,7 @@ void __cvmx_debug_handler_stage3(uint64_t lo, uint64_t hi)
 void cvmx_debug_trigger_exception(void)
 {
 	/* Set CVMX_CIU_DINT to enter debug exception handler.  */
-	cvmx_write_csr(CVMX_CIU_DINT, 1u << cvmx_get_core_num());
+	cvmx_write_csr(CVMX_CIU_DINT, 1ull << cvmx_get_core_num());
 	/* Perform an immediate read after every write to an RSL register to force
 	   the write to complete. It doesn't matter what RSL read we do, so we
 	   choose CVMX_MIO_BOOT_BIST_STAT because it is fast and harmless */
@@ -1566,6 +1594,8 @@ void cvmx_debug_finish(void)
 	unsigned coreid = cvmx_get_core_num();
 	cvmx_debug_state_t state;
 
+	cvmx_coremask_t cm = CVMX_COREMASK_EMPTY;
+
 	if (!cvmx_debug_globals)
 		return;
 	cvmx_debug_printf("Debug _exit reached!, core %d, cvmx_debug_globals = %p\n", coreid, cvmx_debug_globals);
@@ -1576,19 +1606,20 @@ void cvmx_debug_finish(void)
 #endif
 
 	cvmx_spinlock_lock(&cvmx_debug_globals->lock);
-	state = cvmx_debug_get_state();
-	state.known_cores ^= (1u << coreid);
-	state.core_finished |= (1u << coreid);
-	cvmx_debug_update_state(state);
+	cvmx_debug_get_state(&state);
+	state.known_cores ^= (1ull << coreid);
+	state.core_finished |= (1ull << coreid);
+	cvmx_debug_update_state(&state);
 
 	/* Tell the user the core has finished. */
 	if (state.ever_been_in_debug)
 		cvmx_debug_putcorepacket("finished.", coreid);
 
+	/* FIXME: Debugger is limited at 64 cores */
+	cvmx_coremask_set64(&cm, state.core_finished);
+
 	/* Notify the debugger if all cores have completed the program */
-#if 0
-	/* FIXME: coremask is not done correctly for core_finished. */
-	if (cvmx_coremask_is_subset(cvmx_debug_core_mask(), (&state)->core_finished)) {
+	if (cvmx_coremask_cmp(cvmx_debug_core_mask(), &cm) == 0) {
 		cvmx_debug_printf("All cores done!\n");
 		if (state.ever_been_in_debug)
 			cvmx_debug_putpacket_noformat("D0");
@@ -1599,16 +1630,14 @@ void cvmx_debug_finish(void)
 		   should always find a core */
 		unsigned newcore;
 		for (newcore = 0; newcore < CVMX_MAX_CORES; newcore++) {
-			if (cvmx_coremask_is_core_set(&state.known_cores,
-						      newcore)) {
+			if (state.known_cores & (1ull << newcore)) {
 				cvmx_debug_printf("Routing uart interrupts to Core #%u.\n", newcore);
 				cvmx_debug_set_focus_core(&state, newcore);
-				cvmx_debug_update_state(state);
+				cvmx_debug_update_state(&state);
 				break;
 			}
 		}
 	}
-#endif
 	cvmx_spinlock_unlock(&cvmx_debug_globals->lock);
 
 	/* If we ever been in the debug, report to it that we have exited the core. */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-error-trees.c b/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
index 074cec2..32aeaab 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
@@ -1985,14 +1985,6 @@ static struct cvmx_error_muxchild error_tree_cn63xxp1 =
 							{0}},
 						NULL /*cvmx_error_childbit*/
 					},
-					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
 					{0}}},
 				{1, 19 /* nand */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x0001070001000020ull) /* CVMX_NDF_INT */, CVMX_ADD_IO_SEG(0x0001070001000028ull) /* CVMX_NDF_INT_EN */, (struct cvmx_error_regbit[]){
@@ -2039,6 +2031,16 @@ static struct cvmx_error_muxchild error_tree_cn63xxp1 =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
+				{1, 63 /* rst */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
 				{1, 21 /* iob */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x00011800F0000058ull) /* CVMX_IOB_INT_SUM */, CVMX_ADD_IO_SEG(0x00011800F0000060ull) /* CVMX_IOB_INT_ENB */, (struct cvmx_error_regbit[]){
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "IOB_INT_SUM[NP_SOP]"},
@@ -3682,6 +3684,846 @@ static struct cvmx_error_muxchild error_tree_cn56xx =
 			{0}}},
 		{0}}
 	};
+static struct cvmx_error_muxchild error_tree_cn70xx =
+	{0x0000000000000000ull /* CVMX_ROOT */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
+		{1, 0 /* root */, (struct cvmx_error_muxchild[]){
+			{CVMX_ADD_IO_SEG(0x0001070000000000ull) + ((0) & 63) * 8 /* CVMX_CIU_INTX_SUM0(0) */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
+				{1, 60 /* powiq */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001670000000238ull) /* CVMX_POW_IQ_INT */, CVMX_ADD_IO_SEG(0x0001670000000240ull) /* CVMX_POW_IQ_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "POW_IQ_INT[IQ_INT]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 57 /* pcm */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_ENA(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(0)[FSYNCMISSED]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(0)[FSYNCEXTRA]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(0)[TXEMPTY]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(0)[RXOVF]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_ENA(1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(1)[FSYNCMISSED]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(1)[FSYNCEXTRA]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(1)[TXEMPTY]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(1)[RXOVF]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_ENA(2) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(2)[FSYNCMISSED]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(2)[FSYNCEXTRA]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(2)[TXEMPTY]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(2)[RXOVF]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_SUM(3) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_ENA(3) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(3)[FSYNCMISSED]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(3)[FSYNCEXTRA]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(3)[TXEMPTY]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(3)[RXOVF]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{0}}
+			},
+			{CVMX_ADD_IO_SEG(0x0001070000000108ull) /* CVMX_CIU_INT_SUM1 */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
+				{1, 24 /* l2c */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x000107000000E000ull) /* CVMX_CIU_CIB_L2C_RAWX(0) */, CVMX_ADD_IO_SEG(0x000107000000E100ull) /* CVMX_CIU_CIB_L2C_ENX(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_L2C, 0, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_L2DSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 1, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_L2DDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 2, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_SBFSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 3, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_SBFDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 4, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_FBFSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 5, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_FBFDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 6, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_TAGSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 7, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_TAGDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 8, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_NOWAY]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 9, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_HOLEWR]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 10, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_HOLERD]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 11, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_BIGWR]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 12, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_BIGRD]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 13, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_WRDISLMC]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 14, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_RDDISLMC]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 15, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_RTGSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 16, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_RTGDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 17, 0, "CIU_CIB_L2C_RAWX(0)[MCIX_INT_VBFSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 18, 0, "CIU_CIB_L2C_RAWX(0)[MCIX_INT_VBFDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 19, 0, "CIU_CIB_L2C_RAWX(0)[CBCX_INT_RSDSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 20, 0, "CIU_CIB_L2C_RAWX(0)[CBCX_INT_RSDDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 21, 0, "CIU_CIB_L2C_RAWX(0)[CBCX_INT_IOCCMDSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 22, 0, "CIU_CIB_L2C_RAWX(0)[CBCX_INT_IOCCMDDBE]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 25 /* ipd */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00014F0000000168ull) /* CVMX_IPD_INT_SUM */, CVMX_ADD_IO_SEG(0x00014F0000000160ull) /* CVMX_IPD_INT_ENB */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "IPD_INT_SUM[PRC_PAR0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "IPD_INT_SUM[PRC_PAR1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "IPD_INT_SUM[PRC_PAR2]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "IPD_INT_SUM[PRC_PAR3]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "IPD_INT_SUM[BP_SUB]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "IPD_INT_SUM[DC_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "IPD_INT_SUM[CC_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "IPD_INT_SUM[C_COLL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "IPD_INT_SUM[D_COLL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "IPD_INT_SUM[BC_OVR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 23 /* pow */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001670000000218ull) /* CVMX_POW_ECC_ERR */, CVMX_ADD_IO_SEG(0x0001670000000218ull) /* CVMX_POW_ECC_ERR */, (struct cvmx_error_regbit[]){
+							{1, 0, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "POW_ECC_ERR[SBE]"},
+							{1, 0, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "POW_ECC_ERR[DBE]"},
+							{1, 0, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "POW_ECC_ERR[RPE]"},
+							{1, 0, CVMX_ERROR_GROUP_INTERNAL, 16, 0, "POW_ECC_ERR[IOP]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 30 /* rad */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180070000088ull) /* CVMX_RAD_REG_ERROR */, CVMX_ADD_IO_SEG(0x0001180070000090ull) /* CVMX_RAD_REG_INT_MASK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "RAD_REG_ERROR[DOORBELL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 26 /* pip */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800A0000008ull) /* CVMX_PIP_INT_REG */, CVMX_ADD_IO_SEG(0x00011800A0000010ull) /* CVMX_PIP_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "PIP_INT_REG[PRTNXA]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "PIP_INT_REG[BADTAG]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "PIP_INT_REG[SKPRUNT]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PIP_INT_REG[TODOOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PIP_INT_REG[FEPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "PIP_INT_REG[BEPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "PIP_INT_REG[PUNYERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 27 /* pko */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180050000088ull) /* CVMX_PKO_REG_ERROR */, CVMX_ADD_IO_SEG(0x0001180050000090ull) /* CVMX_PKO_REG_INT_MASK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PKO_REG_ERROR[PARITY]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PKO_REG_ERROR[DOORBELL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "PKO_REG_ERROR[CURRZERO]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 50 /* pem2 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800C0000428ull) + ((2) & 3) * 0x1000000ull /* CVMX_PEMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x00011800C0000430ull) + ((2) & 3) * 0x1000000ull /* CVMX_PEMX_INT_ENB(2) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_PCI, 1, 2, "PEMX_INT_SUM(2)[SE]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 4, 2, "PEMX_INT_SUM(2)[UP_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 5, 2, "PEMX_INT_SUM(2)[UP_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 6, 2, "PEMX_INT_SUM(2)[UP_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 7, 2, "PEMX_INT_SUM(2)[UN_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 8, 2, "PEMX_INT_SUM(2)[UN_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 9, 2, "PEMX_INT_SUM(2)[UN_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 11, 2, "PEMX_INT_SUM(2)[RDLK]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 12, 2, "PEMX_INT_SUM(2)[CRS_ER]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 13, 2, "PEMX_INT_SUM(2)[CRS_DR]"},
+							{0}},
+						(struct cvmx_error_childbit[]){
+						{1, 10 /* exc */, (struct cvmx_error_muxchild[]){
+							{CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + ((2) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO(2) */, CVMX_ADD_IO_SEG(0x00011800C00000A0ull) + ((2) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO_EN(2) */, (struct cvmx_error_regbit[]){
+									{1, 1, CVMX_ERROR_GROUP_PCI, 0, 2, "PEMX_DBG_INFO(2)[SPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 2, 2, "PEMX_DBG_INFO(2)[RTLPLLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 3, 2, "PEMX_DBG_INFO(2)[RECRCE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 4, 2, "PEMX_DBG_INFO(2)[RPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 5, 2, "PEMX_DBG_INFO(2)[RCEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 6, 2, "PEMX_DBG_INFO(2)[RNFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 7, 2, "PEMX_DBG_INFO(2)[RFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 8, 2, "PEMX_DBG_INFO(2)[RPMERC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 9, 2, "PEMX_DBG_INFO(2)[RPTAMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 10, 2, "PEMX_DBG_INFO(2)[RUMEP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 11, 2, "PEMX_DBG_INFO(2)[RVDM]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 12, 2, "PEMX_DBG_INFO(2)[ACTO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 13, 2, "PEMX_DBG_INFO(2)[RTE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 14, 2, "PEMX_DBG_INFO(2)[MRE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 15, 2, "PEMX_DBG_INFO(2)[RDWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 16, 2, "PEMX_DBG_INFO(2)[RTWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 17, 2, "PEMX_DBG_INFO(2)[DPEOOSD]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 18, 2, "PEMX_DBG_INFO(2)[FCPVWT]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 19, 2, "PEMX_DBG_INFO(2)[RPE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 20, 2, "PEMX_DBG_INFO(2)[FCUV]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 21, 2, "PEMX_DBG_INFO(2)[RQO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 22, 2, "PEMX_DBG_INFO(2)[RAUC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 23, 2, "PEMX_DBG_INFO(2)[RACUR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 24, 2, "PEMX_DBG_INFO(2)[RACCA]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 25, 2, "PEMX_DBG_INFO(2)[CAAR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 26, 2, "PEMX_DBG_INFO(2)[RARWDNS]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 27, 2, "PEMX_DBG_INFO(2)[RAMTLP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 28, 2, "PEMX_DBG_INFO(2)[RACPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 29, 2, "PEMX_DBG_INFO(2)[RAWWPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 30, 2, "PEMX_DBG_INFO(2)[ECRC_E]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 31, 2, "PEMX_DBG_INFO(2)[RTRY_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 32, 2, "PEMX_DBG_INFO(2)[HDRQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 33, 2, "PEMX_DBG_INFO(2)[DATQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 34, 2, "PEMX_DBG_INFO(2)[P_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 35, 2, "PEMX_DBG_INFO(2)[P_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 36, 2, "PEMX_DBG_INFO(2)[P_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 37, 2, "PEMX_DBG_INFO(2)[P_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 38, 2, "PEMX_DBG_INFO(2)[N_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 39, 2, "PEMX_DBG_INFO(2)[N_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 40, 2, "PEMX_DBG_INFO(2)[N_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 41, 2, "PEMX_DBG_INFO(2)[N_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 42, 2, "PEMX_DBG_INFO(2)[C_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 43, 2, "PEMX_DBG_INFO(2)[C_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 44, 2, "PEMX_DBG_INFO(2)[C_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 45, 2, "PEMX_DBG_INFO(2)[C_C_DBE]"},
+									{0}},
+								NULL /*cvmx_error_childbit*/
+							},
+							{0}}},
+						{0}}
+					},
+					{0}}},
+				{1, 48 /* pem0 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800C0000428ull) + ((0) & 3) * 0x1000000ull /* CVMX_PEMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x00011800C0000430ull) + ((0) & 3) * 0x1000000ull /* CVMX_PEMX_INT_ENB(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_PCI, 1, 0, "PEMX_INT_SUM(0)[SE]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 4, 0, "PEMX_INT_SUM(0)[UP_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 5, 0, "PEMX_INT_SUM(0)[UP_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 6, 0, "PEMX_INT_SUM(0)[UP_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 7, 0, "PEMX_INT_SUM(0)[UN_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 8, 0, "PEMX_INT_SUM(0)[UN_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 9, 0, "PEMX_INT_SUM(0)[UN_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 11, 0, "PEMX_INT_SUM(0)[RDLK]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 12, 0, "PEMX_INT_SUM(0)[CRS_ER]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 13, 0, "PEMX_INT_SUM(0)[CRS_DR]"},
+							{0}},
+						(struct cvmx_error_childbit[]){
+						{1, 10 /* exc */, (struct cvmx_error_muxchild[]){
+							{CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + ((0) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO(0) */, CVMX_ADD_IO_SEG(0x00011800C00000A0ull) + ((0) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO_EN(0) */, (struct cvmx_error_regbit[]){
+									{1, 1, CVMX_ERROR_GROUP_PCI, 0, 0, "PEMX_DBG_INFO(0)[SPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 2, 0, "PEMX_DBG_INFO(0)[RTLPLLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 3, 0, "PEMX_DBG_INFO(0)[RECRCE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 4, 0, "PEMX_DBG_INFO(0)[RPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 5, 0, "PEMX_DBG_INFO(0)[RCEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 6, 0, "PEMX_DBG_INFO(0)[RNFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 7, 0, "PEMX_DBG_INFO(0)[RFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 8, 0, "PEMX_DBG_INFO(0)[RPMERC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 9, 0, "PEMX_DBG_INFO(0)[RPTAMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 10, 0, "PEMX_DBG_INFO(0)[RUMEP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 11, 0, "PEMX_DBG_INFO(0)[RVDM]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 12, 0, "PEMX_DBG_INFO(0)[ACTO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 13, 0, "PEMX_DBG_INFO(0)[RTE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 14, 0, "PEMX_DBG_INFO(0)[MRE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 15, 0, "PEMX_DBG_INFO(0)[RDWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 16, 0, "PEMX_DBG_INFO(0)[RTWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 17, 0, "PEMX_DBG_INFO(0)[DPEOOSD]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 18, 0, "PEMX_DBG_INFO(0)[FCPVWT]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 19, 0, "PEMX_DBG_INFO(0)[RPE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 20, 0, "PEMX_DBG_INFO(0)[FCUV]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 21, 0, "PEMX_DBG_INFO(0)[RQO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 22, 0, "PEMX_DBG_INFO(0)[RAUC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 23, 0, "PEMX_DBG_INFO(0)[RACUR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 24, 0, "PEMX_DBG_INFO(0)[RACCA]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 25, 0, "PEMX_DBG_INFO(0)[CAAR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 26, 0, "PEMX_DBG_INFO(0)[RARWDNS]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 27, 0, "PEMX_DBG_INFO(0)[RAMTLP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 28, 0, "PEMX_DBG_INFO(0)[RACPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 29, 0, "PEMX_DBG_INFO(0)[RAWWPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 30, 0, "PEMX_DBG_INFO(0)[ECRC_E]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 31, 0, "PEMX_DBG_INFO(0)[RTRY_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 32, 0, "PEMX_DBG_INFO(0)[HDRQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 33, 0, "PEMX_DBG_INFO(0)[DATQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 34, 0, "PEMX_DBG_INFO(0)[P_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 35, 0, "PEMX_DBG_INFO(0)[P_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 36, 0, "PEMX_DBG_INFO(0)[P_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 37, 0, "PEMX_DBG_INFO(0)[P_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 38, 0, "PEMX_DBG_INFO(0)[N_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 39, 0, "PEMX_DBG_INFO(0)[N_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 40, 0, "PEMX_DBG_INFO(0)[N_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 41, 0, "PEMX_DBG_INFO(0)[N_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 42, 0, "PEMX_DBG_INFO(0)[C_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 43, 0, "PEMX_DBG_INFO(0)[C_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 44, 0, "PEMX_DBG_INFO(0)[C_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 45, 0, "PEMX_DBG_INFO(0)[C_C_DBE]"},
+									{0}},
+								NULL /*cvmx_error_childbit*/
+							},
+							{0}}},
+						{0}}
+					},
+					{0}}},
+				{1, 49 /* pem1 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800C0000428ull) + ((1) & 3) * 0x1000000ull /* CVMX_PEMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x00011800C0000430ull) + ((1) & 3) * 0x1000000ull /* CVMX_PEMX_INT_ENB(1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_PCI, 1, 1, "PEMX_INT_SUM(1)[SE]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 4, 1, "PEMX_INT_SUM(1)[UP_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 5, 1, "PEMX_INT_SUM(1)[UP_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 6, 1, "PEMX_INT_SUM(1)[UP_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 7, 1, "PEMX_INT_SUM(1)[UN_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 8, 1, "PEMX_INT_SUM(1)[UN_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 9, 1, "PEMX_INT_SUM(1)[UN_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 11, 1, "PEMX_INT_SUM(1)[RDLK]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 12, 1, "PEMX_INT_SUM(1)[CRS_ER]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 13, 1, "PEMX_INT_SUM(1)[CRS_DR]"},
+							{0}},
+						(struct cvmx_error_childbit[]){
+						{1, 10 /* exc */, (struct cvmx_error_muxchild[]){
+							{CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + ((1) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO(1) */, CVMX_ADD_IO_SEG(0x00011800C00000A0ull) + ((1) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO_EN(1) */, (struct cvmx_error_regbit[]){
+									{1, 1, CVMX_ERROR_GROUP_PCI, 0, 1, "PEMX_DBG_INFO(1)[SPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 2, 1, "PEMX_DBG_INFO(1)[RTLPLLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 3, 1, "PEMX_DBG_INFO(1)[RECRCE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 4, 1, "PEMX_DBG_INFO(1)[RPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 5, 1, "PEMX_DBG_INFO(1)[RCEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 6, 1, "PEMX_DBG_INFO(1)[RNFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 7, 1, "PEMX_DBG_INFO(1)[RFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 8, 1, "PEMX_DBG_INFO(1)[RPMERC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 9, 1, "PEMX_DBG_INFO(1)[RPTAMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 10, 1, "PEMX_DBG_INFO(1)[RUMEP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 11, 1, "PEMX_DBG_INFO(1)[RVDM]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 12, 1, "PEMX_DBG_INFO(1)[ACTO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 13, 1, "PEMX_DBG_INFO(1)[RTE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 14, 1, "PEMX_DBG_INFO(1)[MRE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 15, 1, "PEMX_DBG_INFO(1)[RDWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 16, 1, "PEMX_DBG_INFO(1)[RTWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 17, 1, "PEMX_DBG_INFO(1)[DPEOOSD]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 18, 1, "PEMX_DBG_INFO(1)[FCPVWT]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 19, 1, "PEMX_DBG_INFO(1)[RPE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 20, 1, "PEMX_DBG_INFO(1)[FCUV]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 21, 1, "PEMX_DBG_INFO(1)[RQO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 22, 1, "PEMX_DBG_INFO(1)[RAUC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 23, 1, "PEMX_DBG_INFO(1)[RACUR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 24, 1, "PEMX_DBG_INFO(1)[RACCA]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 25, 1, "PEMX_DBG_INFO(1)[CAAR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 26, 1, "PEMX_DBG_INFO(1)[RARWDNS]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 27, 1, "PEMX_DBG_INFO(1)[RAMTLP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 28, 1, "PEMX_DBG_INFO(1)[RACPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 29, 1, "PEMX_DBG_INFO(1)[RAWWPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 30, 1, "PEMX_DBG_INFO(1)[ECRC_E]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 31, 1, "PEMX_DBG_INFO(1)[RTRY_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 32, 1, "PEMX_DBG_INFO(1)[HDRQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 33, 1, "PEMX_DBG_INFO(1)[DATQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 34, 1, "PEMX_DBG_INFO(1)[P_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 35, 1, "PEMX_DBG_INFO(1)[P_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 36, 1, "PEMX_DBG_INFO(1)[P_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 37, 1, "PEMX_DBG_INFO(1)[P_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 38, 1, "PEMX_DBG_INFO(1)[N_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 39, 1, "PEMX_DBG_INFO(1)[N_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 40, 1, "PEMX_DBG_INFO(1)[N_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 41, 1, "PEMX_DBG_INFO(1)[N_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 42, 1, "PEMX_DBG_INFO(1)[C_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 43, 1, "PEMX_DBG_INFO(1)[C_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 44, 1, "PEMX_DBG_INFO(1)[C_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 45, 1, "PEMX_DBG_INFO(1)[C_C_DBE]"},
+									{0}},
+								NULL /*cvmx_error_childbit*/
+							},
+							{0}}},
+						{0}}
+					},
+					{0}}},
+				{1, 22 /* fpa */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180028000040ull) /* CVMX_FPA_INT_SUM */, CVMX_ADD_IO_SEG(0x0001180028000048ull) /* CVMX_FPA_INT_ENB */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "FPA_INT_SUM[FED0_SBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "FPA_INT_SUM[FED0_DBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "FPA_INT_SUM[FED1_SBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "FPA_INT_SUM[FED1_DBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "FPA_INT_SUM[Q0_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "FPA_INT_SUM[Q0_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "FPA_INT_SUM[Q0_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "FPA_INT_SUM[Q1_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "FPA_INT_SUM[Q1_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "FPA_INT_SUM[Q1_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 10, 0, "FPA_INT_SUM[Q2_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 11, 0, "FPA_INT_SUM[Q2_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "FPA_INT_SUM[Q2_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 13, 0, "FPA_INT_SUM[Q3_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 14, 0, "FPA_INT_SUM[Q3_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 15, 0, "FPA_INT_SUM[Q3_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 16, 0, "FPA_INT_SUM[Q4_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 17, 0, "FPA_INT_SUM[Q4_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 18, 0, "FPA_INT_SUM[Q4_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 19, 0, "FPA_INT_SUM[Q5_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 20, 0, "FPA_INT_SUM[Q5_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 21, 0, "FPA_INT_SUM[Q5_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 22, 0, "FPA_INT_SUM[Q6_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 23, 0, "FPA_INT_SUM[Q6_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 24, 0, "FPA_INT_SUM[Q6_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 25, 0, "FPA_INT_SUM[Q7_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 26, 0, "FPA_INT_SUM[Q7_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 27, 0, "FPA_INT_SUM[Q7_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 28, 0, "FPA_INT_SUM[POOL0TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 29, 0, "FPA_INT_SUM[POOL1TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 30, 0, "FPA_INT_SUM[POOL2TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 31, 0, "FPA_INT_SUM[POOL3TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 32, 0, "FPA_INT_SUM[POOL4TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 33, 0, "FPA_INT_SUM[POOL5TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 34, 0, "FPA_INT_SUM[POOL6TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 35, 0, "FPA_INT_SUM[POOL7TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 36, 0, "FPA_INT_SUM[FREE0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 37, 0, "FPA_INT_SUM[FREE1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 38, 0, "FPA_INT_SUM[FREE2]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 39, 0, "FPA_INT_SUM[FREE3]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 40, 0, "FPA_INT_SUM[FREE4]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 41, 0, "FPA_INT_SUM[FREE5]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 42, 0, "FPA_INT_SUM[FREE6]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 43, 0, "FPA_INT_SUM[FREE7]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 49, 0, "FPA_INT_SUM[PADDR_E]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 20 /* mio */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800000000A0ull) /* CVMX_MIO_BOOT_ERR */, CVMX_ADD_IO_SEG(0x00011800000000A8ull) /* CVMX_MIO_BOOT_INT */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_BOOT_ERR[ADR_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_BOOT_ERR[WAIT_ERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 32 /* dfa */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180037000028ull) /* CVMX_DFA_ERROR */, CVMX_ADD_IO_SEG(0x0001180037000030ull) /* CVMX_DFA_INTMSK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DFA_ERROR[DBLOVF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "DFA_ERROR[DC0PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 13, 0, "DFA_ERROR[DLC0_OVFERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 17, 0, "DFA_ERROR[DFANXM]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 18, 0, "DFA_ERROR[REPLERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 29 /* tim */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180058000088ull) /* CVMX_TIM_REG_ERROR */, CVMX_ADD_IO_SEG(0x0001180058000090ull) /* CVMX_TIM_REG_INT_MASK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "TIM_REG_ERROR[MASK]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 52 /* lmc0 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x000107000000E200ull) /* CVMX_CIU_CIB_LMCX_RAWX(0,0) */, CVMX_ADD_IO_SEG(0x000107000000E300ull) /* CVMX_CIU_CIB_LMCX_ENX(0,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_LMC, 1, 0, "CIU_CIB_LMCX_RAWX(0,0)[INT_SEC_ERRX]"},
+							{1, 1, CVMX_ERROR_GROUP_LMC, 5, 0, "CIU_CIB_LMCX_RAWX(0,0)[INT_DED_ERRX]"},
+							{1, 1, CVMX_ERROR_GROUP_LMC, 0, 0, "CIU_CIB_LMCX_RAWX(0,0)[INT_NXM_WR_ERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 31 /* key */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180020000000ull) /* CVMX_KEY_INT_SUM */, CVMX_ADD_IO_SEG(0x0001180020000008ull) /* CVMX_KEY_INT_ENB */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "KEY_INT_SUM[KEY_SBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "KEY_INT_SUM[KEY_DBE]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 63 /* rst */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x000107000000E400ull) /* CVMX_CIU_CIB_RST_RAWX(0) */, CVMX_ADD_IO_SEG(0x000107000000E500ull) /* CVMX_CIU_CIB_RST_ENX(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "CIU_CIB_RST_RAWX(0)[INT_LINKX]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "CIU_CIB_RST_RAWX(0)[INT_PERSTX]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 21 /* iob */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800F0000058ull) /* CVMX_IOB_INT_SUM */, CVMX_ADD_IO_SEG(0x00011800F0000060ull) /* CVMX_IOB_INT_ENB */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "IOB_INT_SUM[NP_SOP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "IOB_INT_SUM[NP_EOP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "IOB_INT_SUM[P_SOP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "IOB_INT_SUM[P_EOP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "IOB_INT_SUM[NP_DAT]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "IOB_INT_SUM[P_DAT]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "IOB_INT_SUM[INB_MAT]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "IOB_INT_SUM[OUTB_MAT]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 46 /* agl */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800E0000518ull) /* CVMX_AGL_GMX_BAD_REG */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 32, 0, "AGL_GMX_BAD_REG[OVRFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 33, 0, "AGL_GMX_BAD_REG[TXPOP]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 34, 0, "AGL_GMX_BAD_REG[TXPSH]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 2, 0, "AGL_GMX_BAD_REG[OUT_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 22, 0, "AGL_GMX_BAD_REG[LOSTSTAT]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800E0000000ull) + ((0) & 0) * 2048 /* CVMX_AGL_GMX_RXX_INT_REG(0) */, CVMX_ADD_IO_SEG(0x00011800E0000008ull) + ((0) & 0) * 2048 /* CVMX_AGL_GMX_RXX_INT_EN(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 8, 0, "AGL_GMX_RXX_INT_REG(0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 10, 0, "AGL_GMX_RXX_INT_REG(0)[OVRERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800E0000500ull) /* CVMX_AGL_GMX_TX_INT_REG */, CVMX_ADD_IO_SEG(0x00011800E0000508ull) /* CVMX_AGL_GMX_TX_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 0, 0, "AGL_GMX_TX_INT_REG[PKO_NXA]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 2, 0, "AGL_GMX_TX_INT_REG[UNDFLW]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 36 /* agx0 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180008000518ull) + ((0) & 1) * 0x8000000ull /* CVMX_GMXX_BAD_REG(0) */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "GMXX_BAD_REG(0)[OUT_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 0, "GMXX_BAD_REG(0)[LOSTSTAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 0, "GMXX_BAD_REG(0)[STATOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 0, "GMXX_BAD_REG(0)[INB_NXA]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((0) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(0,0) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((0) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(0,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 0, "GMXX_RXX_INT_REG(0,0)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 0, "GMXX_RXX_INT_REG(0,0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 0, "GMXX_RXX_INT_REG(0,0)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 0, "GMXX_RXX_INT_REG(0,0)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 0, "GMXX_RXX_INT_REG(0,0)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 0, "GMXX_RXX_INT_REG(0,0)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 0, "GMXX_RXX_INT_REG(0,0)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 0, "GMXX_RXX_INT_REG(0,0)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 0, "GMXX_RXX_INT_REG(0,0)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 0, "GMXX_RXX_INT_REG(0,0)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 0, "GMXX_RXX_INT_REG(0,0)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 0, "GMXX_RXX_INT_REG(0,0)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 0, "GMXX_RXX_INT_REG(0,0)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((1) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(1,0) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((1) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(1,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 1, "GMXX_RXX_INT_REG(1,0)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 1, "GMXX_RXX_INT_REG(1,0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 1, "GMXX_RXX_INT_REG(1,0)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 1, "GMXX_RXX_INT_REG(1,0)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 1, "GMXX_RXX_INT_REG(1,0)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 1, "GMXX_RXX_INT_REG(1,0)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 1, "GMXX_RXX_INT_REG(1,0)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 1, "GMXX_RXX_INT_REG(1,0)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 1, "GMXX_RXX_INT_REG(1,0)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 1, "GMXX_RXX_INT_REG(1,0)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 1, "GMXX_RXX_INT_REG(1,0)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 1, "GMXX_RXX_INT_REG(1,0)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 1, "GMXX_RXX_INT_REG(1,0)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((2) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(2,0) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((2) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(2,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 2, "GMXX_RXX_INT_REG(2,0)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 2, "GMXX_RXX_INT_REG(2,0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 2, "GMXX_RXX_INT_REG(2,0)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 2, "GMXX_RXX_INT_REG(2,0)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 2, "GMXX_RXX_INT_REG(2,0)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 2, "GMXX_RXX_INT_REG(2,0)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 2, "GMXX_RXX_INT_REG(2,0)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 2, "GMXX_RXX_INT_REG(2,0)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 2, "GMXX_RXX_INT_REG(2,0)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 2, "GMXX_RXX_INT_REG(2,0)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 2, "GMXX_RXX_INT_REG(2,0)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 2, "GMXX_RXX_INT_REG(2,0)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 2, "GMXX_RXX_INT_REG(2,0)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((3) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(3,0) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((3) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(3,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 3, "GMXX_RXX_INT_REG(3,0)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 3, "GMXX_RXX_INT_REG(3,0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 3, "GMXX_RXX_INT_REG(3,0)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 3, "GMXX_RXX_INT_REG(3,0)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 3, "GMXX_RXX_INT_REG(3,0)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 3, "GMXX_RXX_INT_REG(3,0)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 3, "GMXX_RXX_INT_REG(3,0)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 3, "GMXX_RXX_INT_REG(3,0)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 3, "GMXX_RXX_INT_REG(3,0)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 3, "GMXX_RXX_INT_REG(3,0)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 3, "GMXX_RXX_INT_REG(3,0)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 3, "GMXX_RXX_INT_REG(3,0)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 3, "GMXX_RXX_INT_REG(3,0)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000500ull) + ((0) & 1) * 0x8000000ull /* CVMX_GMXX_TX_INT_REG(0) */, CVMX_ADD_IO_SEG(0x0001180008000508ull) + ((0) & 1) * 0x8000000ull /* CVMX_GMXX_TX_INT_EN(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 0, 0, "GMXX_TX_INT_REG(0)[PKO_NXA]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "GMXX_TX_INT_REG(0)[UNDFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 0, "GMXX_TX_INT_REG(0)[PTP_LOST]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((0) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(0,0) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((0) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(0,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "PCSX_INTX_REG(0,0)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 0, "PCSX_INTX_REG(0,0)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 0, "PCSX_INTX_REG(0,0)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 0, "PCSX_INTX_REG(0,0)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 0, "PCSX_INTX_REG(0,0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 0, "PCSX_INTX_REG(0,0)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 0, "PCSX_INTX_REG(0,0)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 0, "PCSX_INTX_REG(0,0)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 0, "PCSX_INTX_REG(0,0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((1) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(1,0) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((1) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(1,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 1, "PCSX_INTX_REG(1,0)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 1, "PCSX_INTX_REG(1,0)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 1, "PCSX_INTX_REG(1,0)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 1, "PCSX_INTX_REG(1,0)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 1, "PCSX_INTX_REG(1,0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 1, "PCSX_INTX_REG(1,0)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 1, "PCSX_INTX_REG(1,0)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 1, "PCSX_INTX_REG(1,0)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 1, "PCSX_INTX_REG(1,0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((2) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(2,0) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((2) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(2,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 2, "PCSX_INTX_REG(2,0)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 2, "PCSX_INTX_REG(2,0)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 2, "PCSX_INTX_REG(2,0)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 2, "PCSX_INTX_REG(2,0)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 2, "PCSX_INTX_REG(2,0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 2, "PCSX_INTX_REG(2,0)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 2, "PCSX_INTX_REG(2,0)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 2, "PCSX_INTX_REG(2,0)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 2, "PCSX_INTX_REG(2,0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((3) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(3,0) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((3) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(3,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 3, "PCSX_INTX_REG(3,0)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 3, "PCSX_INTX_REG(3,0)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 3, "PCSX_INTX_REG(3,0)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 3, "PCSX_INTX_REG(3,0)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 3, "PCSX_INTX_REG(3,0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 3, "PCSX_INTX_REG(3,0)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 3, "PCSX_INTX_REG(3,0)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 3, "PCSX_INTX_REG(3,0)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 3, "PCSX_INTX_REG(3,0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0000858ull) + ((0) & 0) * 0x8000000ull /* CVMX_PCSXX_INT_REG(0) */, CVMX_ADD_IO_SEG(0x00011800B0000860ull) + ((0) & 0) * 0x8000000ull /* CVMX_PCSXX_INT_EN_REG(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 0, 0, "PCSXX_INT_REG(0)[TXFLT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 0, "PCSXX_INT_REG(0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "PCSXX_INT_REG(0)[RXSYNBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 0, "PCSXX_INT_REG(0)[BITLCKLS]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 0, "PCSXX_INT_REG(0)[SYNLOS]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 0, "PCSXX_INT_REG(0)[ALGNLOS]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 6, 0, "PCSXX_INT_REG(0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 37 /* agx1 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180008000518ull) + ((1) & 1) * 0x8000000ull /* CVMX_GMXX_BAD_REG(1) */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 16, "GMXX_BAD_REG(1)[OUT_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 16, "GMXX_BAD_REG(1)[LOSTSTAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 16, "GMXX_BAD_REG(1)[STATOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 16, "GMXX_BAD_REG(1)[INB_NXA]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((0) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(0,1) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((0) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(0,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 16, "GMXX_RXX_INT_REG(0,1)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 16, "GMXX_RXX_INT_REG(0,1)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 16, "GMXX_RXX_INT_REG(0,1)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 16, "GMXX_RXX_INT_REG(0,1)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 16, "GMXX_RXX_INT_REG(0,1)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 16, "GMXX_RXX_INT_REG(0,1)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 16, "GMXX_RXX_INT_REG(0,1)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 16, "GMXX_RXX_INT_REG(0,1)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 16, "GMXX_RXX_INT_REG(0,1)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 16, "GMXX_RXX_INT_REG(0,1)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 16, "GMXX_RXX_INT_REG(0,1)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 16, "GMXX_RXX_INT_REG(0,1)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 16, "GMXX_RXX_INT_REG(0,1)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((1) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(1,1) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((1) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(1,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 17, "GMXX_RXX_INT_REG(1,1)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 17, "GMXX_RXX_INT_REG(1,1)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 17, "GMXX_RXX_INT_REG(1,1)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 17, "GMXX_RXX_INT_REG(1,1)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 17, "GMXX_RXX_INT_REG(1,1)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 17, "GMXX_RXX_INT_REG(1,1)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 17, "GMXX_RXX_INT_REG(1,1)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 17, "GMXX_RXX_INT_REG(1,1)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 17, "GMXX_RXX_INT_REG(1,1)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 17, "GMXX_RXX_INT_REG(1,1)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 17, "GMXX_RXX_INT_REG(1,1)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 17, "GMXX_RXX_INT_REG(1,1)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 17, "GMXX_RXX_INT_REG(1,1)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((2) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(2,1) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((2) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(2,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 18, "GMXX_RXX_INT_REG(2,1)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 18, "GMXX_RXX_INT_REG(2,1)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 18, "GMXX_RXX_INT_REG(2,1)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 18, "GMXX_RXX_INT_REG(2,1)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 18, "GMXX_RXX_INT_REG(2,1)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 18, "GMXX_RXX_INT_REG(2,1)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 18, "GMXX_RXX_INT_REG(2,1)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 18, "GMXX_RXX_INT_REG(2,1)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 18, "GMXX_RXX_INT_REG(2,1)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 18, "GMXX_RXX_INT_REG(2,1)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 18, "GMXX_RXX_INT_REG(2,1)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 18, "GMXX_RXX_INT_REG(2,1)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 18, "GMXX_RXX_INT_REG(2,1)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((3) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(3,1) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((3) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(3,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 19, "GMXX_RXX_INT_REG(3,1)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 19, "GMXX_RXX_INT_REG(3,1)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 19, "GMXX_RXX_INT_REG(3,1)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 19, "GMXX_RXX_INT_REG(3,1)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 19, "GMXX_RXX_INT_REG(3,1)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 19, "GMXX_RXX_INT_REG(3,1)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 19, "GMXX_RXX_INT_REG(3,1)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 19, "GMXX_RXX_INT_REG(3,1)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 19, "GMXX_RXX_INT_REG(3,1)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 19, "GMXX_RXX_INT_REG(3,1)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 19, "GMXX_RXX_INT_REG(3,1)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 19, "GMXX_RXX_INT_REG(3,1)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 19, "GMXX_RXX_INT_REG(3,1)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000500ull) + ((1) & 1) * 0x8000000ull /* CVMX_GMXX_TX_INT_REG(1) */, CVMX_ADD_IO_SEG(0x0001180008000508ull) + ((1) & 1) * 0x8000000ull /* CVMX_GMXX_TX_INT_EN(1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 0, 16, "GMXX_TX_INT_REG(1)[PKO_NXA]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 16, "GMXX_TX_INT_REG(1)[UNDFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 16, "GMXX_TX_INT_REG(1)[PTP_LOST]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((0) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(0,1) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((0) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(0,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 16, "PCSX_INTX_REG(0,1)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 16, "PCSX_INTX_REG(0,1)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 16, "PCSX_INTX_REG(0,1)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 16, "PCSX_INTX_REG(0,1)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 16, "PCSX_INTX_REG(0,1)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 16, "PCSX_INTX_REG(0,1)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 16, "PCSX_INTX_REG(0,1)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 16, "PCSX_INTX_REG(0,1)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 16, "PCSX_INTX_REG(0,1)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((1) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(1,1) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((1) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(1,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 17, "PCSX_INTX_REG(1,1)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 17, "PCSX_INTX_REG(1,1)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 17, "PCSX_INTX_REG(1,1)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 17, "PCSX_INTX_REG(1,1)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 17, "PCSX_INTX_REG(1,1)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 17, "PCSX_INTX_REG(1,1)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 17, "PCSX_INTX_REG(1,1)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 17, "PCSX_INTX_REG(1,1)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 17, "PCSX_INTX_REG(1,1)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((2) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(2,1) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((2) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(2,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 18, "PCSX_INTX_REG(2,1)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 18, "PCSX_INTX_REG(2,1)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 18, "PCSX_INTX_REG(2,1)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 18, "PCSX_INTX_REG(2,1)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 18, "PCSX_INTX_REG(2,1)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 18, "PCSX_INTX_REG(2,1)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 18, "PCSX_INTX_REG(2,1)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 18, "PCSX_INTX_REG(2,1)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 18, "PCSX_INTX_REG(2,1)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((3) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(3,1) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((3) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(3,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 19, "PCSX_INTX_REG(3,1)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 19, "PCSX_INTX_REG(3,1)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 19, "PCSX_INTX_REG(3,1)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 19, "PCSX_INTX_REG(3,1)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 19, "PCSX_INTX_REG(3,1)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 19, "PCSX_INTX_REG(3,1)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 19, "PCSX_INTX_REG(3,1)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 19, "PCSX_INTX_REG(3,1)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 19, "PCSX_INTX_REG(3,1)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 34 /* sli */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011F0000010330ull) /* CVMX_PEXP_SLI_INT_SUM */, CVMX_ADD_IO_SEG(0x00011F0000013CD0ull) /* CVMX_PEXP_SLI_INT_ENB_CIU */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PEXP_SLI_INT_SUM[RML_TO]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, NULL},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "PEXP_SLI_INT_SUM[BAR0_TO]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "PEXP_SLI_INT_SUM[IOB2BIG]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, NULL},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "PEXP_SLI_INT_SUM[M0_UP_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "PEXP_SLI_INT_SUM[M0_UP_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 10, 0, "PEXP_SLI_INT_SUM[M0_UN_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 11, 0, "PEXP_SLI_INT_SUM[M0_UN_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "PEXP_SLI_INT_SUM[M1_UP_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 13, 0, "PEXP_SLI_INT_SUM[M1_UP_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 14, 0, "PEXP_SLI_INT_SUM[M1_UN_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 15, 0, "PEXP_SLI_INT_SUM[M1_UN_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 20, 0, "PEXP_SLI_INT_SUM[M2_UP_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 21, 0, "PEXP_SLI_INT_SUM[M2_UP_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 22, 0, "PEXP_SLI_INT_SUM[M2_UN_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 23, 0, "PEXP_SLI_INT_SUM[M2_UN_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 24, 0, "PEXP_SLI_INT_SUM[M3_UP_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 25, 0, "PEXP_SLI_INT_SUM[M3_UP_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 26, 0, "PEXP_SLI_INT_SUM[M3_UN_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 27, 0, "PEXP_SLI_INT_SUM[M3_UN_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 48, 0, "PEXP_SLI_INT_SUM[PIDBOF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 49, 0, "PEXP_SLI_INT_SUM[PSLDBOF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 50, 0, "PEXP_SLI_INT_SUM[POUT_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 51, 0, "PEXP_SLI_INT_SUM[PIN_BP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 52, 0, "PEXP_SLI_INT_SUM[PGL_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 53, 0, "PEXP_SLI_INT_SUM[PDI_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 54, 0, "PEXP_SLI_INT_SUM[POP_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 55, 0, "PEXP_SLI_INT_SUM[PINS_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 56, 0, "PEXP_SLI_INT_SUM[SPRT0_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 57, 0, "PEXP_SLI_INT_SUM[SPRT1_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 58, 0, "PEXP_SLI_INT_SUM[SPRT2_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 59, 0, "PEXP_SLI_INT_SUM[SPRT3_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 60, 0, "PEXP_SLI_INT_SUM[ILL_PAD]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 35 /* dpi */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001DF0000000008ull) /* CVMX_DPI_INT_REG */, CVMX_ADD_IO_SEG(0x0001DF0000000010ull) /* CVMX_DPI_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DPI_INT_REG[NDERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "DPI_INT_REG[NFOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "DPI_INT_REG[DMADBO]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 16, 0, "DPI_INT_REG[REQ_BADADR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 17, 0, "DPI_INT_REG[REQ_BADLEN]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 18, 0, "DPI_INT_REG[REQ_OVRFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 19, 0, "DPI_INT_REG[REQ_UNDFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 20, 0, "DPI_INT_REG[REQ_ANULL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 21, 0, "DPI_INT_REG[REQ_INULL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 22, 0, "DPI_INT_REG[REQ_BADFIL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 24, 0, "DPI_INT_REG[SPRT0_RST]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 25, 0, "DPI_INT_REG[SPRT1_RST]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 26, 0, "DPI_INT_REG[SPRT2_RST]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 27, 0, "DPI_INT_REG[SPRT3_RST]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001DF0000000078ull) /* CVMX_DPI_PKT_ERR_RSP */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DPI_PKT_ERR_RSP[PKTERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001DF0000000058ull) /* CVMX_DPI_REQ_ERR_RSP */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DPI_REQ_ERR_RSP[QERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001DF0000000060ull) /* CVMX_DPI_REQ_ERR_RST */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DPI_REQ_ERR_RST[QERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{0}}
+			},
+			{0}}},
+		{0}}
+	};
 static struct cvmx_error_muxchild error_tree_cn52xxp1 =
 	{0x0000000000000000ull /* CVMX_ROOT */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
 		{1, 0 /* root */, (struct cvmx_error_muxchild[]){
@@ -6886,16 +7728,6 @@ static struct cvmx_error_muxchild error_tree_cn66xx =
 							{0}},
 						NULL /*cvmx_error_childbit*/
 					},
-					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "MIO_RST_INT[RST_LINK2]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "MIO_RST_INT[RST_LINK3]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
 					{0}}},
 				{1, 32 /* dfa */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x0001180037000028ull) /* CVMX_DFA_ERROR */, CVMX_ADD_IO_SEG(0x0001180037000030ull) /* CVMX_DFA_INTMSK */, (struct cvmx_error_regbit[]){
@@ -6950,6 +7782,18 @@ static struct cvmx_error_muxchild error_tree_cn66xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
+				{1, 63 /* rst */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "MIO_RST_INT[RST_LINK2]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "MIO_RST_INT[RST_LINK3]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
 				{1, 21 /* iob */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x00011800F0000058ull) /* CVMX_IOB_INT_SUM */, CVMX_ADD_IO_SEG(0x00011800F0000060ull) /* CVMX_IOB_INT_ENB */, (struct cvmx_error_regbit[]){
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "IOB_INT_SUM[NP_SOP]"},
@@ -7942,10 +8786,7 @@ static struct cvmx_error_muxchild error_tree_cn52xx =
 static struct cvmx_error_muxchild error_tree_cn61xx =
 	{0x0000000000000000ull /* CVMX_ROOT */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
 		{1, 0 /* root */, (struct cvmx_error_muxchild[]){
-			{CVMX_ADD_IO_SEG(0x0001070000000000ull) + ((0) & 63) * 8 /* CVMX_CIU_INTX_SUM0(0) */, 0, (struct cvmx_error_regbit[]){
-					{1, 1, CVMX_ERROR_GROUP_INTERNAL, 16, 0, "CIU_INTX_SUM0(0)[GPIO]"},
-					{0}},
-				(struct cvmx_error_childbit[]){
+			{CVMX_ADD_IO_SEG(0x0001070000000000ull) + ((0) & 63) * 8 /* CVMX_CIU_INTX_SUM0(0) */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
 				{1, 60 /* powiq */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x0001670000000238ull) /* CVMX_POW_IQ_INT */, CVMX_ADD_IO_SEG(0x0001670000000240ull) /* CVMX_POW_IQ_INT_EN */, (struct cvmx_error_regbit[]){
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "POW_IQ_INT[IQ_INT]"},
@@ -8261,9 +9102,10 @@ static struct cvmx_error_muxchild error_tree_cn61xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
-				{1, 28 /* zip */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x0001180038000088ull) /* CVMX_ZIP_ERROR */, CVMX_ADD_IO_SEG(0x0001180038000090ull) /* CVMX_ZIP_INT_MASK */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "ZIP_ERROR[DOORBELL]"},
+				{1, 20 /* mio */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800000000A0ull) /* CVMX_MIO_BOOT_ERR */, CVMX_ADD_IO_SEG(0x00011800000000A8ull) /* CVMX_MIO_BOOT_INT */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_BOOT_ERR[ADR_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_BOOT_ERR[WAIT_ERR]"},
 							{0}},
 						NULL /*cvmx_error_childbit*/
 					},
@@ -8305,6 +9147,16 @@ static struct cvmx_error_muxchild error_tree_cn61xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
+				{1, 63 /* rst */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
 				{1, 21 /* iob */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x00011800F0000058ull) /* CVMX_IOB_INT_SUM */, CVMX_ADD_IO_SEG(0x00011800F0000060ull) /* CVMX_IOB_INT_ENB */, (struct cvmx_error_regbit[]){
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "IOB_INT_SUM[NP_SOP]"},
@@ -8349,18 +9201,9 @@ static struct cvmx_error_muxchild error_tree_cn61xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
-				{1, 20 /* mio */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x00011800000000A0ull) /* CVMX_MIO_BOOT_ERR */, CVMX_ADD_IO_SEG(0x00011800000000A8ull) /* CVMX_MIO_BOOT_INT */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_BOOT_ERR[ADR_ERR]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_BOOT_ERR[WAIT_ERR]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
+				{1, 28 /* zip */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180038000088ull) /* CVMX_ZIP_ERROR */, CVMX_ADD_IO_SEG(0x0001180038000090ull) /* CVMX_ZIP_INT_MASK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "ZIP_ERROR[DOORBELL]"},
 							{0}},
 						NULL /*cvmx_error_childbit*/
 					},
@@ -8736,10 +9579,7 @@ static struct cvmx_error_muxchild error_tree_cn61xx =
 static struct cvmx_error_muxchild error_tree_cnf71xx =
 	{0x0000000000000000ull /* CVMX_ROOT */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
 		{1, 0 /* root */, (struct cvmx_error_muxchild[]){
-			{CVMX_ADD_IO_SEG(0x0001070000000000ull) + ((0) & 63) * 8 /* CVMX_CIU_INTX_SUM0(0) */, 0, (struct cvmx_error_regbit[]){
-					{1, 1, CVMX_ERROR_GROUP_INTERNAL, 16, 0, "CIU_INTX_SUM0(0)[GPIO]"},
-					{0}},
-				(struct cvmx_error_childbit[]){
+			{CVMX_ADD_IO_SEG(0x0001070000000000ull) + ((0) & 63) * 8 /* CVMX_CIU_INTX_SUM0(0) */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
 				{1, 60 /* powiq */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x0001670000000238ull) /* CVMX_POW_IQ_INT */, CVMX_ADD_IO_SEG(0x0001670000000240ull) /* CVMX_POW_IQ_INT_EN */, (struct cvmx_error_regbit[]){
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "POW_IQ_INT[IQ_INT]"},
@@ -8940,14 +9780,6 @@ static struct cvmx_error_muxchild error_tree_cnf71xx =
 							{0}},
 						NULL /*cvmx_error_childbit*/
 					},
-					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
 					{0}}},
 				{1, 25 /* ipd */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x00014F0000000168ull) /* CVMX_IPD_INT_SUM */, CVMX_ADD_IO_SEG(0x00014F0000000160ull) /* CVMX_IPD_INT_ENB */, (struct cvmx_error_regbit[]){
@@ -8965,6 +9797,13 @@ static struct cvmx_error_muxchild error_tree_cnf71xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
+				{1, 29 /* tim */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180058000088ull) /* CVMX_TIM_REG_ERROR */, CVMX_ADD_IO_SEG(0x0001180058000090ull) /* CVMX_TIM_REG_INT_MASK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "TIM_REG_ERROR[MASK]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
 				{1, 36 /* agx0 */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x0001180008000518ull) + ((0) & 0) * 0x8000000ull /* CVMX_GMXX_BAD_REG(0) */, 0, (struct cvmx_error_regbit[]){
 							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "GMXX_BAD_REG(0)[OUT_OVR]"},
@@ -9112,9 +9951,15 @@ static struct cvmx_error_muxchild error_tree_cnf71xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
-				{1, 29 /* tim */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x0001180058000088ull) /* CVMX_TIM_REG_ERROR */, CVMX_ADD_IO_SEG(0x0001180058000090ull) /* CVMX_TIM_REG_INT_MASK */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "TIM_REG_ERROR[MASK]"},
+				{1, 26 /* pip */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800A0000008ull) /* CVMX_PIP_INT_REG */, CVMX_ADD_IO_SEG(0x00011800A0000010ull) /* CVMX_PIP_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "PIP_INT_REG[PRTNXA]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "PIP_INT_REG[BADTAG]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "PIP_INT_REG[SKPRUNT]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PIP_INT_REG[TODOOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PIP_INT_REG[FEPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "PIP_INT_REG[BEPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "PIP_INT_REG[PUNYERR]"},
 							{0}},
 						NULL /*cvmx_error_childbit*/
 					},
@@ -9183,15 +10028,12 @@ static struct cvmx_error_muxchild error_tree_cnf71xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
-				{1, 26 /* pip */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x00011800A0000008ull) /* CVMX_PIP_INT_REG */, CVMX_ADD_IO_SEG(0x00011800A0000010ull) /* CVMX_PIP_INT_EN */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "PIP_INT_REG[PRTNXA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "PIP_INT_REG[BADTAG]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "PIP_INT_REG[SKPRUNT]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PIP_INT_REG[TODOOVR]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PIP_INT_REG[FEPERR]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "PIP_INT_REG[BEPERR]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "PIP_INT_REG[PUNYERR]"},
+				{1, 63 /* rst */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
 							{0}},
 						NULL /*cvmx_error_childbit*/
 					},
@@ -9540,14 +10382,6 @@ static struct cvmx_error_muxchild error_tree_cn63xx =
 							{0}},
 						NULL /*cvmx_error_childbit*/
 					},
-					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
 					{0}}},
 				{1, 19 /* nand */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x0001070001000020ull) /* CVMX_NDF_INT */, CVMX_ADD_IO_SEG(0x0001070001000028ull) /* CVMX_NDF_INT_EN */, (struct cvmx_error_regbit[]){
@@ -9594,6 +10428,16 @@ static struct cvmx_error_muxchild error_tree_cn63xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
+				{1, 63 /* rst */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180000001628ull) /* CVMX_MIO_RST_INT */, CVMX_ADD_IO_SEG(0x0001180000001630ull) /* CVMX_MIO_RST_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_RST_INT[RST_LINK0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_RST_INT[RST_LINK1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "MIO_RST_INT[PERST0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "MIO_RST_INT[PERST1]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
 				{1, 21 /* iob */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x00011800F0000058ull) /* CVMX_IOB_INT_SUM */, CVMX_ADD_IO_SEG(0x00011800F0000060ull) /* CVMX_IOB_INT_ENB */, (struct cvmx_error_regbit[]){
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "IOB_INT_SUM[NP_SOP]"},
@@ -11173,6 +12017,7 @@ struct cvmx_error_tree octeon_error_trees[] = {
    {&error_tree_cn56xxp1, 0xfff8, 0x0400},
    {&error_tree_cn52xxp1, 0xfff8, 0x0700},
    {&error_tree_cnf71xx, 0xff00, 0x9400},
+   {&error_tree_cn70xx, 0xff00, 0x9600},
    {&error_tree_cn68xx, 0xff00, 0x9100},
    {&error_tree_cn66xx, 0xff00, 0x9200},
    {&error_tree_cn63xx, 0xff00, 0x9000},
diff --git a/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c b/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
index 8b67bce..30ba22f 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
@@ -136,9 +136,9 @@ int cvmx_fpa_allocate_fpa_pools(int node, int pools_allocated[], int count)
 			     " node=%d\n", node);
 		return -1;
 	}
-	rv = cvmx_allocate_global_resource_range_non_contiguous(tag, owner,
-							       count,
-							       pools_allocated);
+	rv = cvmx_resource_alloc_many(tag, owner,
+				      count,
+				      pools_allocated);
 	return rv;
 }
 
@@ -173,9 +173,9 @@ int cvmx_fpa_allocate_auras(int node, int auras_allocated[], int count)
 			     " node=%d\n", node);
 		return -1;
 	}
-	rv = cvmx_allocate_global_resource_range_non_contiguous(tag, owner,
-							       count,
-							       auras_allocated);
+	rv = cvmx_resource_alloc_many(tag, owner,
+				      count,
+				      auras_allocated);
 	return rv;
 
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-global-resources.c b/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
index 153a42c..7f08f55 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
@@ -415,10 +415,10 @@ int cvmx_allocate_global_resource_range(struct global_resource_tag tag, uint64_t
 	return base;
 }
 
-int cvmx_allocate_global_resource_range_non_contiguous(struct global_resource_tag tag,
-						      uint64_t owner,
-						      int nelements,
-						      int allocated_elements[]) {
+int cvmx_resource_alloc_many(struct global_resource_tag tag,
+			     uint64_t owner,
+			     int nelements,
+			     int allocated_elements[]) {
 	uint64_t addr = cvmx_get_global_resource(tag,1);
 	int rv;
 
@@ -432,7 +432,6 @@ int cvmx_allocate_global_resource_range_non_contiguous(struct global_resource_ta
 	rv = cvmx_range_alloc_non_contiguos(addr, owner, nelements, allocated_elements);
 	__cvmx_global_resource_unlock();
 	return rv;
-
 }
 
 int cvmx_reserve_global_resource_range(struct global_resource_tag tag,
diff --git a/arch/mips/cavium-octeon/executive/cvmx-gser.c b/arch/mips/cavium-octeon/executive/cvmx-gser.c
new file mode 100644
index 0000000..89fafcf
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-gser.c
@@ -0,0 +1,277 @@
+/***********************license start***************
+ * Copyright (c) 2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Helper utilities for qlm.
+ *
+ * <hr>$Revision$<hr>
+ */
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-helper.h>
+#include <asm/octeon/cvmx-qlm.h>
+#include <asm/octeon/cvmx-gserx-defs.h>
+#else
+#include "cvmx.h"
+#include "cvmx-helper.h"
+#include "cvmx-qlm.h"
+#endif
+
+
+/**
+ * @INTERNAL
+ * Configure the gser pll registers.
+ *
+ * @param interface Interface to bring up
+ *
+ * @param mode      Mode to configure the gser as
+ *
+ * @param qlm       QLM attached to this interface
+ *
+ * @parma num_ports Number of ports on this interface
+ *
+ * @return Zero on success, negative on failure
+ */
+static int gser_pll_init(int				interface,
+			 cvmx_helper_interface_mode_t	mode,
+			 int				qlm,
+			 int				num_ports)
+{
+	cvmx_gserx_pll_px_mode_0_t	gser_pll_p_mode_0;
+	cvmx_gserx_pll_px_mode_1_t	gser_pll_p_mode_1;
+	cvmx_gserx_lanex_px_mode_0_t	gser_lane_p_mode_0;
+	int				lane_mode;
+	int				i;
+
+	/* Figure out the lane mode */
+	switch (mode) {
+	case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		lane_mode = 0x6;
+		break;
+
+	case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		lane_mode = 0x4;
+		break;
+
+	default:
+		lane_mode = 0;
+		break;
+	}
+
+	/* Configure pll_p_mode_0 */
+	gser_pll_p_mode_0.u64 = 0;
+	switch (mode) {
+	case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		gser_pll_p_mode_0.s.pll_icp = 1;
+		gser_pll_p_mode_0.s.pll_rloop = 3;
+		gser_pll_p_mode_0.s.pll_pcs_div = 0x28;
+		break;
+
+	case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		gser_pll_p_mode_0.s.pll_icp = 1;
+		gser_pll_p_mode_0.s.pll_rloop = 3;
+		gser_pll_p_mode_0.s.pll_pcs_div = 0x24;
+		break;
+
+	default:
+		break;
+	}
+	cvmx_write_csr(CVMX_GSERX_PLL_PX_MODE_0(qlm, lane_mode),
+		       gser_pll_p_mode_0.u64);
+
+	/* Configure pll_p_mode_1 */
+	gser_pll_p_mode_1.u64 = 0;
+	switch (mode) {
+	case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		gser_pll_p_mode_1.s.pll_div = 16;
+		gser_pll_p_mode_1.s.pll_opr = 0;
+		gser_pll_p_mode_1.s.pll_pcie3en = 0;
+		gser_pll_p_mode_1.s.pll_cpadj = 3;
+		gser_pll_p_mode_1.s.pll_16p5en = 1;
+		break;
+
+	case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		gser_pll_p_mode_1.s.pll_div = 20;
+		gser_pll_p_mode_1.s.pll_opr = 0;
+		gser_pll_p_mode_1.s.pll_pcie3en = 0;
+		gser_pll_p_mode_1.s.pll_cpadj = 2;
+		gser_pll_p_mode_1.s.pll_16p5en = 1;
+		break;
+
+	default:
+		break;
+	}
+	cvmx_write_csr(CVMX_GSERX_PLL_PX_MODE_1(qlm, lane_mode),
+		       gser_pll_p_mode_1.u64);
+
+	/* Configure lane_p_mode */
+	for (i = 0; i < num_ports; i++) {
+		gser_lane_p_mode_0.u64 = 0;
+		gser_lane_p_mode_0.s.srate = 0;
+		gser_lane_p_mode_0.s.rx_mode = 3;
+		gser_lane_p_mode_0.s.tx_mode = 3;
+
+		switch (mode) {
+		case CVMX_HELPER_INTERFACE_MODE_SGMII:
+			gser_lane_p_mode_0.s.ctle = 0;
+			gser_lane_p_mode_0.s.pcie = 0;
+			gser_lane_p_mode_0.s.tx_ldiv = 2;
+			gser_lane_p_mode_0.s.rx_ldiv = 2;
+			break;
+
+		case CVMX_HELPER_INTERFACE_MODE_XAUI:
+			gser_lane_p_mode_0.s.ctle = 0;
+			gser_lane_p_mode_0.s.pcie = 0;
+			gser_lane_p_mode_0.s.tx_ldiv = 2;
+			gser_lane_p_mode_0.s.rx_ldiv = 2;
+			break;
+
+		default:
+			break;
+		}
+		cvmx_write_csr(CVMX_GSERX_LANEX_PX_MODE_0(qlm, i, lane_mode),
+			       gser_lane_p_mode_0.u64);
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Configure the gser.
+ *
+ * @param interface Interface to bring up
+ *
+ * @param mode      Mode to configure the gser as
+ *
+ * @return Zero on success, negative on failure
+ */
+int gser_init(int				interface,
+	      cvmx_helper_interface_mode_t	mode)
+{
+	cvmx_gserx_phy_ctl_t		gser_phy_ctl;
+	cvmx_gserx_cfg_t		gser_cfg;
+	cvmx_gserx_rx_coast_t		gser_rx_coast;
+	cvmx_gserx_rx_eie_deten_t	gser_rx_eie_deten;
+	cvmx_gserx_lane_mode_t		gser_lane_mode;
+	cvmx_gserx_qlm_stat_t		gser_qlm_stat;
+	cvmx_gserx_pll_stat_t		gser_pll_stat;
+	cvmx_gserx_rx_eie_detsts_t	gser_rx_eie_detsts;
+	int				lane_mode;
+	int				qlm;
+	int				num_ports;
+
+	qlm = cvmx_qlm_interface(interface);
+	num_ports = cvmx_helper_ports_on_interface(interface);
+
+	/* Figure out the lane mode */
+	switch (mode) {
+	case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		lane_mode = 0x6;
+		break;
+
+	case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		lane_mode = 0x4;
+		break;
+
+	default:
+		lane_mode = 0;
+		break;
+	}
+
+	/* Power up phy, but keek it in reset */
+	gser_phy_ctl.u64 = 0;
+	gser_phy_ctl.s.phy_pd = 0;
+	gser_phy_ctl.s.phy_reset = 1;
+	cvmx_write_csr(CVMX_GSERX_PHY_CTL(qlm), gser_phy_ctl.u64);
+
+	/* Set gser for the interface mode */
+	gser_cfg.u64 = 0;
+	gser_cfg.s.ila = mode == CVMX_HELPER_INTERFACE_MODE_ILK ? 1 : 0;
+	gser_cfg.s.bgx = mode == CVMX_HELPER_INTERFACE_MODE_ILK ? 0 : 1;
+	gser_cfg.s.bgx_quad = mode == CVMX_HELPER_INTERFACE_MODE_XAUI ? 1 : 0;
+	gser_cfg.s.bgx_dual = 0;
+	gser_cfg.s.pcie = 0;
+	cvmx_write_csr(CVMX_GSERX_CFG(qlm), gser_cfg.u64);
+
+	/* Enable the port lanes */
+	gser_rx_coast.u64 = cvmx_read_csr(CVMX_GSERX_RX_COAST(qlm));
+	gser_rx_coast.s.coast |= ((1 << num_ports) - 1);
+	cvmx_write_csr(CVMX_GSERX_RX_COAST(qlm), gser_rx_coast.u64);
+
+	gser_rx_eie_deten.u64 = cvmx_read_csr(CVMX_GSERX_RX_EIE_DETEN(qlm));
+	gser_rx_eie_deten.s.eiede |= ((1 << num_ports) - 1);
+	cvmx_write_csr(CVMX_GSERX_RX_EIE_DETEN(qlm), gser_rx_eie_deten.u64);
+
+	/* Lane mode */
+	gser_lane_mode.u64 = 0;
+	gser_lane_mode.s.lmode = lane_mode;
+	cvmx_write_csr(CVMX_GSERX_LANE_MODE(qlm), gser_lane_mode.u64);
+
+	/* Bring phy out of reset */
+	gser_phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
+	gser_phy_ctl.s.phy_reset = 0;
+	cvmx_write_csr(CVMX_GSERX_PHY_CTL(qlm), gser_phy_ctl.u64);
+	gser_phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
+
+	/*
+	 * Wait 250 ns until the managment interface is ready to accept
+	 * read/write commands.
+	 */
+	cvmx_wait_usec(3);
+
+	/* Configure the gser pll */
+	gser_pll_init(interface, mode, qlm, num_ports);
+
+	/* Wait for reset to complete and the PLL to lock */
+	do {
+		gser_qlm_stat.u64 = cvmx_read_csr(CVMX_GSERX_QLM_STAT(qlm));
+		gser_pll_stat.u64 = cvmx_read_csr(CVMX_GSERX_PLL_STAT(qlm));
+	} while(!gser_qlm_stat.s.rst_rdy || !gser_pll_stat.s.pll_lock);
+
+	/* Wait for cdrlock */
+	do {
+		gser_rx_eie_detsts.u64 =
+			cvmx_read_csr(CVMX_GSERX_RX_EIE_DETSTS(qlm));
+	} while((gser_rx_eie_detsts.s.cdrlock & 0xf) != 0xf);
+
+	return 0;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c b/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
index 45a7bb3..cc81ac9 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
@@ -100,7 +100,7 @@ int __cvmx_helper_agl_probe(int interface)
 {
 	int port = cvmx_helper_agl_get_port(interface);
 	union cvmx_agl_gmx_bist gmx_bist;
-	union cvmx_agl_gmx_prtx_cfg gmx_prtx_cfg;	
+	union cvmx_agl_gmx_prtx_cfg gmx_prtx_cfg;
 	union cvmx_agl_prtx_ctl agl_prtx_ctl;
 	uint64_t clock_scale;
 	int result;
@@ -120,7 +120,7 @@ int __cvmx_helper_agl_probe(int interface)
         gmx_prtx_cfg.s.en = 0;
 	cvmx_write_csr(CVMX_AGL_GMX_PRTX_CFG(port), gmx_prtx_cfg.u64);
 
-	/* Set the rgx_ref_clk MUX with AGL_PRTx_CTL[REFCLK_SEL]. Default value 
+	/* Set the rgx_ref_clk MUX with AGL_PRTx_CTL[REFCLK_SEL]. Default value
 	   is 0 (RGMII REFCLK). Recommended to use RGMII RXC(1) or sclk/4 (2)
 	   to save cost.
 	 */
@@ -136,10 +136,19 @@ int __cvmx_helper_agl_probe(int interface)
 	agl_prtx_ctl.s.clkrst = 0;
 	agl_prtx_ctl.s.dllrst = 0;
 	agl_prtx_ctl.s.clktx_byp = 0;
+
+
+	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
+		agl_prtx_ctl.s.refclk_sel = 0;
+		agl_prtx_ctl.s.clkrx_set =
+			cvmx_helper_get_agl_rx_clock_skew(interface, port);
+		agl_prtx_ctl.s.clkrx_byp =
+			cvmx_helper_get_agl_rx_clock_delay_bypass(interface,
+								  port);
+	}
 	cvmx_write_csr(CVMX_AGL_PRTX_CTL(port), agl_prtx_ctl.u64);
 	/* Force write out before wait */
 	cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
-
 	/*
 	 * Wait for the DLL to lock. External 125 MHz reference clock must be
 	 * stable at this point.
@@ -153,12 +162,14 @@ int __cvmx_helper_agl_probe(int interface)
 	/* Force write out before wait */
 	cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
 
-	/* Enable the interface */
-	agl_prtx_ctl.u64 = cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
-	agl_prtx_ctl.s.enable = 1;
-	cvmx_write_csr(CVMX_AGL_PRTX_CTL(port), agl_prtx_ctl.u64);
-	/* Read the value back to force the previous write */
-	agl_prtx_ctl.u64 = cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
+	if (!OCTEON_IS_OCTEON3()) {
+		/* Enable the interface */
+		agl_prtx_ctl.u64 = cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
+		agl_prtx_ctl.s.enable = 1;
+		cvmx_write_csr(CVMX_AGL_PRTX_CTL(port), agl_prtx_ctl.u64);
+		/* Read the value back to force the previous write */
+		agl_prtx_ctl.u64 = cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
+	}
 
 	/* Enable the compensation controller */
 	agl_prtx_ctl.u64 = cvmx_read_csr(CVMX_AGL_PRTX_CTL(port));
@@ -186,8 +197,10 @@ int __cvmx_helper_agl_probe(int interface)
 int __cvmx_helper_agl_enable(int interface)
 {
 	int port = cvmx_helper_agl_get_port(interface);
+	int ipd_port = cvmx_helper_get_ipd_port(interface, port);
 	union cvmx_pko_mem_port_ptrs pko_mem_port_ptrs;
 	union cvmx_pko_reg_read_idx read_idx;
+	int do_link_set = 1;
 	int i;
 
 	/* Setup PKO for AGL interface. Back pressure is not supported. */
@@ -200,14 +213,25 @@ int __cvmx_helper_agl_enable(int interface)
 		pko_mem_port_ptrs.u64 = cvmx_read_csr(CVMX_PKO_MEM_PORT_PTRS);
 		if (pko_mem_port_ptrs.s.pid == 24) {
 			pko_mem_port_ptrs.s.eid = 10;
-			pko_mem_port_ptrs.s.bp_port = 63;
+			pko_mem_port_ptrs.s.bp_port = 40;
 			cvmx_write_csr(CVMX_PKO_MEM_PORT_PTRS, pko_mem_port_ptrs.u64);
 			break;
 		}
 	}
 
 	cvmx_agl_enable(port);
-	cvmx_agl_link_set(port, cvmx_agl_link_get(port), 1);
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+	/*
+	 * Linux kernel driver will call ....link_set with the
+	 * proper link state. In the simulator there is no
+	 * link state polling and hence it is set from
+	 * here.
+	 */
+	if (!(cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM))
+		do_link_set = 0;
+#endif
+	if (do_link_set)
+		cvmx_agl_link_set(port, cvmx_agl_link_get(ipd_port), 1);
 
 	return 0;
 }
@@ -243,5 +267,7 @@ cvmx_helper_link_info_t __cvmx_helper_agl_link_get(int ipd_port)
  */
 int __cvmx_helper_agl_link_set(int ipd_port, cvmx_helper_link_info_t link_info)
 {
-	return cvmx_agl_link_set(ipd_port, link_info, 1);	
+	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int port = cvmx_helper_agl_get_port(interface);
+	return cvmx_agl_link_set(port, link_info, 1);
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
index 84f5085..fdf89c5 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2011  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -56,6 +56,7 @@
 #include <asm/octeon/cvmx-helper.h>
 #include <asm/octeon/cvmx-helper-util.h>
 #include <asm/octeon/cvmx-helper-board.h>
+#include <asm/octeon/cvmx-helper-cfg.h>
 #include <asm/octeon/cvmx-twsi.h>
 #else
 #include "cvmx.h"
@@ -66,6 +67,7 @@
 #include "cvmx-helper.h"
 #include "cvmx-helper-util.h"
 #include "cvmx-helper-board.h"
+#include "cvmx-helper-cfg.h"
 #include "cvmx-gpio.h"
 #include "octeon_mem_map.h"
 #include "cvmx-bootmem.h"
@@ -124,16 +126,16 @@ int __pip_eth_node(const void *fdt_addr, int aliases, int ipd_port)
 
 	/* The following are not found in the device tree */
 	switch (interface_mode) {
-		case CVMX_HELPER_INTERFACE_MODE_ILK:
-		case CVMX_HELPER_INTERFACE_MODE_LOOP:
-		case CVMX_HELPER_INTERFACE_MODE_SRIO:
-			cvmx_dprintf("ERROR: No node expected for interface: %d, port: %d, mode: %s\n",
-				     interface_index,
-				     ipd_port,
-				     cvmx_helper_interface_mode_to_string(interface_mode));
-			return -1;
-		default:
-			break;
+	case CVMX_HELPER_INTERFACE_MODE_ILK:
+	case CVMX_HELPER_INTERFACE_MODE_LOOP:
+	case CVMX_HELPER_INTERFACE_MODE_SRIO:
+		cvmx_dprintf("ERROR: No node expected for interface: %d, port: %d, mode: %s\n",
+			     interface_index,
+			     ipd_port,
+			     cvmx_helper_interface_mode_to_string(interface_mode));
+		return -1;
+	default:
+		break;
 	}
 	pip_path = fdt_getprop(fdt_addr, aliases, "pip", NULL);
 	if (!pip_path) {
@@ -384,6 +386,7 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
         case CVMX_HELPER_INTERFACE_MODE_SPI:
         case CVMX_HELPER_INTERFACE_MODE_XAUI:
         case CVMX_HELPER_INTERFACE_MODE_SGMII:
+	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
         case CVMX_HELPER_INTERFACE_MODE_RXAUI:
 		aliases = 1;
 		break;
@@ -426,6 +429,20 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 	if (dbg)
 		cvmx_dprintf("%s: eth subnode offset %d from %s\n",
 			     __func__, eth, name_buffer);
+
+	if (eth < 0) 
+		return -1;
+
+	if (fdt_getprop(fdt_addr, eth, "cavium,sgmii-mac-phy-mode", NULL))
+		cvmx_helper_set_mac_phy_mode(interface_num, port_index, true);
+	else
+		cvmx_helper_set_mac_phy_mode(interface_num, port_index, false);
+
+	if (fdt_getprop(fdt_addr, eth, "cavium,sgmii-mac-1000x-mode", NULL))
+		cvmx_helper_set_1000x_mode(interface_num, port_index, true);
+	else
+		cvmx_helper_set_1000x_mode(interface_num, port_index, false);
+
 	return (eth >= 0);
 }
 
@@ -457,6 +474,7 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 	uint64_t *smi_addrp;
 	uint64_t smi_addr = 0;
 	int dbg = device_tree_dbg;
+	int interface;
 
 	phy_info->phy_addr = -1;
 	phy_info->direct_connect = -1;
@@ -490,15 +508,15 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 				     "ipd_port=%d\n", ipd_port);
 		return -1;
 	}
+
+	interface = cvmx_helper_get_interface_num(ipd_port);
 	/* Get handle to phy */
 	phy_handle = (uint32_t *) fdt_getprop(fdt_addr, eth, "phy-handle", NULL);
 	if (!phy_handle) {
-		int interface;
 		cvmx_helper_interface_mode_t if_mode;
 		/* Note that it's OK for RXAUI and ILK to not have a PHY
 		 * connected (i.e. EBB boards in loopback).
 		 */
-		interface = cvmx_helper_get_interface_num(ipd_port);
 		if_mode = cvmx_helper_interface_get_mode(interface);
 		if (if_mode != CVMX_HELPER_INTERFACE_MODE_RXAUI &&
 		    if_mode != CVMX_HELPER_INTERFACE_MODE_ILK) {
@@ -546,6 +564,10 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 			phy_info->host_mode = CVMX_PHY_HOST_MODE_XAUI;
 		} else if (strcmp(host_mode_str, "sgmii") == 0) {
 			phy_info->host_mode = CVMX_PHY_HOST_MODE_SGMII;
+		} else if (strcmp(host_mode_str, "qsgmii") == 0) {
+			phy_info->host_mode = CVMX_PHY_HOST_MODE_QSGMII;
+		} else {
+			cvmx_dprintf("Unknown PHY host mode\n");
 		}
 	}
 
@@ -553,7 +575,8 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 	   though a MUX and for them direct_connect_to_phy will be 0 */
 	phy_parent = fdt_parent_offset(fdt_addr, phy);
 	if (phy_parent < 0) {
-		cvmx_dprintf("ERROR : cannot find phy parent for ipd_port=%d ret=%d\n", ipd_port, phy_parent);
+		cvmx_dprintf("ERROR : cannot find phy parent for ipd_port=%d ret=%d\n",
+			     ipd_port, phy_parent);
 		return -1;
 	}
 	/* For multi-phy devices and devices on a MUX, go to the parent */
@@ -944,6 +967,11 @@ int cvmx_helper_board_get_mii_address(int ipd_port)
 			return ipd_port - 16 + 4;
 		else
 			return -1;
+	case CVMX_BOARD_TYPE_UBNT_E100:
+		if (ipd_port >= 0 && ipd_port <= 2)
+			return 7 - ipd_port;
+		else
+			return -1;
 	}
 
 	/* Some unknown board. Somebody forgot to update this function... */
@@ -1310,8 +1338,17 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 	}
 
 	if (__get_phy_info_from_dt(&phy_info, ipd_port) < 0) {
-		cvmx_dprintf("%s: Failed to get phy info for ipd port %d\n",
-			     __func__, ipd_port);
+		/* If we can't get the PHY info from the device tree then try
+		 * the inband state.
+		 */
+		if (OCTEON_IS_OCTEON1() || OCTEON_IS_MODEL(OCTEON_CN58XX) ||
+		    OCTEON_IS_MODEL(OCTEON_CN50XX)) {
+			result = __get_inband_link_state(ipd_port);
+		} else {
+			result.s.full_duplex = 1;
+			result.s.link_up = 1;
+			result.s.speed = 1000;
+		}
 		return result;
 	}
 
@@ -1342,8 +1379,21 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 	case CORTINA_PHY:
 		result = __cvmx_get_cortina_phy_link_state(phy_info.phy_addr);
 		break;
+	case INBAND_PHY:
 	default:
-		result = __get_inband_link_state(ipd_port);
+		if (OCTEON_IS_OCTEON1() ||
+		    OCTEON_IS_MODEL(OCTEON_CN58XX) ||
+		    OCTEON_IS_MODEL(OCTEON_CN50XX))
+			/*
+			 * We don't have a PHY address, so attempt to use
+			 * in-band status. It is really important that boards
+			 * not supporting in-band status never get
+			 * here. Reading broken in-band status tends to do bad
+			 * things.
+			 */
+			result = __get_inband_link_state(ipd_port);
+		else
+			return cvmx_helper_link_get(ipd_port);
 	}
 	return result;
 
@@ -1772,6 +1822,13 @@ int __cvmx_helper_board_hardware_enable(int interface)
 				}
 			}
 		}
+	} else if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_UBNT_E100) {
+		cvmx_write_csr(CVMX_ASXX_RX_CLK_SETX(0, interface), 0);
+		cvmx_write_csr(CVMX_ASXX_TX_CLK_SETX(0, interface), 0x10);
+		cvmx_write_csr(CVMX_ASXX_RX_CLK_SETX(1, interface), 0);
+		cvmx_write_csr(CVMX_ASXX_TX_CLK_SETX(1, interface), 0x10);
+		cvmx_write_csr(CVMX_ASXX_RX_CLK_SETX(2, interface), 0);
+		cvmx_write_csr(CVMX_ASXX_TX_CLK_SETX(2, interface), 0x10);
 	}
 	return 0;
 }
@@ -1838,6 +1895,7 @@ cvmx_helper_board_usb_clock_types_t __cvmx_helper_board_usb_get_clock_type(void)
 	case CVMX_BOARD_TYPE_LANAI2_U:
 	case CVMX_BOARD_TYPE_LANAI2_G:
 	case CVMX_BOARD_TYPE_NIC10E_66:
+	case CVMX_BOARD_TYPE_UBNT_E100:
 		return USB_CLOCK_TYPE_CRYSTAL_12;
 	case CVMX_BOARD_TYPE_NIC10E:
 		return USB_CLOCK_TYPE_REF_12;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
index ea92c52..ca9dbeb 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -81,8 +81,11 @@
 
 CVMX_SHARED struct cvmx_cfg_port_param cvmx_cfg_port[CVMX_HELPER_MAX_IFACE][CVMX_HELPER_CFG_MAX_PORT_PER_IFACE] =
 	{[0 ... CVMX_HELPER_MAX_IFACE - 1] = {[0 ... CVMX_HELPER_CFG_MAX_PORT_PER_IFACE - 1] =
-					      { CVMX_HELPER_CFG_INVALID_VALUE, CVMX_HELPER_CFG_INVALID_VALUE,
-						CVMX_HELPER_CFG_INVALID_VALUE, CVMX_HELPER_CFG_INVALID_VALUE}}};
+				      	      { CVMX_HELPER_CFG_INVALID_VALUE, CVMX_HELPER_CFG_INVALID_VALUE,
+				                CVMX_HELPER_CFG_INVALID_VALUE, CVMX_HELPER_CFG_INVALID_VALUE,
+	                                        CVMX_HELPER_CFG_INVALID_VALUE, 0,
+	                                        0}}};
+
 /*
  * Indexed by the pko_port number
  */
@@ -478,6 +481,7 @@ void cvmx_helper_cfg_set_jabber_and_frame_max()
 
 		switch (imode) {
 		case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		case CVMX_HELPER_INTERFACE_MODE_QSGMII:
 		case CVMX_HELPER_INTERFACE_MODE_XAUI:
 		case CVMX_HELPER_INTERFACE_MODE_RXAUI:
 			for (port = 0; port < num_ports; port++)
@@ -501,7 +505,7 @@ void cvmx_helper_cfg_set_jabber_and_frame_max()
 			cvmx_pip_set_frame_check(interface, -1);
 			for (port = 0; port < num_ports; port++) {
 				int ipd_port = cvmx_helper_get_ipd_port(interface, port);
-				cvmx_ilk_enable_la_header(ipd_port, 1);
+				cvmx_ilk_enable_la_header(ipd_port, 0);
 			}
 			break;
 		case CVMX_HELPER_INTERFACE_MODE_SRIO:
@@ -524,19 +528,21 @@ void cvmx_helper_cfg_store_short_packets_in_wqe()
 {
 	int interface, port;
 
-	for (interface = 0; interface < cvmx_helper_get_number_of_interfaces(); interface++) {
-		int num_ports = cvmx_helper_ports_on_interface(interface);
-		/* Enable storing short packets only in the WQE */
-		for (port = 0; port < num_ports; port++) {
-			cvmx_pip_port_cfg_t port_cfg;
-			int pknd = port;
-			if (octeon_has_feature(OCTEON_FEATURE_PKND))
-				pknd = cvmx_helper_get_pknd(interface, port);
-			else
-				pknd = cvmx_helper_get_ipd_port(interface, port);
-			port_cfg.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(pknd));
-			port_cfg.s.dyn_rs = 1;
-			cvmx_write_csr(CVMX_PIP_PRT_CFGX(pknd), port_cfg.u64);
+	if (!OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		for (interface = 0; interface < cvmx_helper_get_number_of_interfaces(); interface++) {
+			int num_ports = cvmx_helper_ports_on_interface(interface);
+			/* Enable storing short packets only in the WQE */
+			for (port = 0; port < num_ports; port++) {
+				cvmx_pip_port_cfg_t port_cfg;
+				int pknd = port;
+				if (octeon_has_feature(OCTEON_FEATURE_PKND))
+					pknd = cvmx_helper_get_pknd(interface, port);
+				else
+					pknd = cvmx_helper_get_ipd_port(interface, port);
+				port_cfg.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(pknd));
+				port_cfg.s.dyn_rs = 1;
+				cvmx_write_csr(CVMX_PIP_PRT_CFGX(pknd), port_cfg.u64);
+			}
 		}
 	}
 }
@@ -677,10 +683,80 @@ static int cvmx_helper_cfg_init_pko_iports_and_queues_using_static_config(void)
 	return rv;
 }
 
+/**
+ * Returns if port is valid for a given interface
+ *
+ * @param interface  interface to check
+ * @param index      port index in the interface
+ *
+ * @return status of the port present or not.
+ */
+int cvmx_helper_is_port_valid(int interface, int index)
+{
+	return  cvmx_cfg_port[interface][index].valid;
+}
+EXPORT_SYMBOL(cvmx_helper_is_port_valid);
+
+void cvmx_helper_set_port_valid(int interface, int index, bool valid)
+{
+	cvmx_cfg_port[interface][index].valid = valid;
+}
+EXPORT_SYMBOL(cvmx_helper_set_port_valid);
+
+void cvmx_helper_set_mac_phy_mode(int interface, int index, bool valid)
+{
+	cvmx_cfg_port[interface][index].sgmii_phy_mode = valid;
+}
+EXPORT_SYMBOL(cvmx_helper_set_mac_phy_mode);
+
+bool cvmx_helper_get_mac_phy_mode(int interface, int index)
+{
+	return cvmx_cfg_port[interface][index].sgmii_phy_mode;
+}
+EXPORT_SYMBOL(cvmx_helper_get_mac_phy_mode);
+
+void cvmx_helper_set_1000x_mode(int interface, int index, bool valid)
+{
+	cvmx_cfg_port[interface][index].sgmii_1000x_mode = valid;
+}
+EXPORT_SYMBOL(cvmx_helper_set_1000x_mode);
+
+bool cvmx_helper_get_1000x_mode(int interface, int index)
+{
+	return cvmx_cfg_port[interface][index].sgmii_1000x_mode;
+}
+EXPORT_SYMBOL(cvmx_helper_get_1000x_mode);
+
+void cvmx_helper_set_agl_rx_clock_delay_bypass(int interface, int index,
+					       bool valid)
+{
+	cvmx_cfg_port[interface][index].agl_rx_clk_delay_bypass = valid;
+}
+EXPORT_SYMBOL(cvmx_helper_set_agl_rx_clock_delay_bypass);
+
+bool cvmx_helper_get_agl_rx_clock_delay_bypass(int interface, int index)
+{
+	return cvmx_cfg_port[interface][index].agl_rx_clk_delay_bypass;
+}
+EXPORT_SYMBOL(cvmx_helper_get_agl_rx_clock_delay_bypass);
+
+void cvmx_helper_set_agl_rx_clock_skew(int interface, int index, uint8_t value)
+{
+	cvmx_cfg_port[interface][index].agl_rx_clk_skew = value;
+}
+EXPORT_SYMBOL(cvmx_helper_set_agl_rx_clock_skew);
+
+uint8_t cvmx_helper_get_agl_rx_clock_skew(int interface, int index)
+{
+	return cvmx_cfg_port[interface][index].agl_rx_clk_skew;
+}
+EXPORT_SYMBOL(cvmx_helper_get_agl_rx_clock_skew);
+
 int __cvmx_helper_init_port_valid(void)
 {
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 	int i, j, n;
+	bool valid;
 
 	for (i = 0; i < cvmx_helper_get_number_of_interfaces(); i++) {
 		static void *fdt_addr = 0;
@@ -691,10 +767,9 @@ int __cvmx_helper_init_port_valid(void)
 		n = cvmx_helper_interface_enumerate(i);
 		for (j = 0; j < n; j++) {
 			int ipd_port = cvmx_helper_get_ipd_port(i, j);
-			if (__cvmx_helper_board_get_port_from_dt(fdt_addr, ipd_port) == 1)
-				cvmx_helper_set_port_valid(i, j, true);
-			else
-				cvmx_helper_set_port_valid(i, j, false);
+			valid = (__cvmx_helper_board_get_port_from_dt(fdt_addr,
+								      ipd_port) == 1);
+			cvmx_helper_set_port_valid(i, j, valid);
 		}
 	}
 #endif
@@ -819,6 +894,7 @@ int __cvmx_helper_init_port_config_data(void)
 
 		for (port = 0; port < num_ports; port++) {
 			bool init_req = false;
+
 			if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 				port_base = __cvmx_helper_cfg_pko_port_base(interface, port);
 				if (port_base == CVMX_HELPER_CFG_INVALID_VALUE)
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
index 8a417bb..5950725 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
@@ -78,6 +78,266 @@ int __cvmx_helper_ilk_enumerate(int interface)
 
 /**
  * @INTERNAL
+ * Initialize all calendar entries to the xoff state. This
+ * means no data is sent or received.
+ *
+ * @param interface Interface whose calendar are to be initialized.
+ */
+void __cvmx_ilk_init_cal(int interface)
+{
+	cvmx_ilk_txx_idx_cal_t	tx_idx;
+	cvmx_ilk_txx_mem_cal0_t tx_cal0;
+	cvmx_ilk_txx_mem_cal1_t tx_cal1;
+	cvmx_ilk_rxx_idx_cal_t	rx_idx;
+	cvmx_ilk_rxx_mem_cal0_t rx_cal0;
+	cvmx_ilk_rxx_mem_cal1_t rx_cal1;
+	int			i;
+
+	/*
+	 * First we initialize the tx calendar starting from entry 0,
+	 * incrementing the entry with every write.
+	 */
+	tx_idx.u64 = 0;
+	tx_idx.s.inc = 1;
+	cvmx_write_csr(CVMX_ILK_TXX_IDX_CAL(interface), tx_idx.u64);
+
+	/* Set state to xoff for all entries */
+	tx_cal0.u64 = 0;
+	tx_cal0.s.entry_ctl0 = XOFF;
+	tx_cal0.s.entry_ctl1 = XOFF;
+	tx_cal0.s.entry_ctl2 = XOFF;
+	tx_cal0.s.entry_ctl3 = XOFF;
+
+	tx_cal1.u64 = 0;
+	tx_cal1.s.entry_ctl4 = XOFF;
+	tx_cal1.s.entry_ctl5 = XOFF;
+	tx_cal1.s.entry_ctl6 = XOFF;
+	tx_cal1.s.entry_ctl7 = XOFF;
+
+	/* Write all 288 entries */
+	for (i = 0; i < CVMX_ILK_MAX_CAL_IDX; i++) {
+		cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL0(interface), tx_cal0.u64);
+		cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL1(interface), tx_cal1.u64);
+	}
+
+	/*
+	 * Next we initialize the rx calendar starting from entry 0,
+	 * incrementing the entry with every write.
+	 */
+	rx_idx.u64 = 0;
+	rx_idx.s.inc = 1;
+	cvmx_write_csr(CVMX_ILK_RXX_IDX_CAL(interface), rx_idx.u64);
+
+	/* Set state to xoff for all entries */
+	rx_cal0.u64 = 0;
+	rx_cal0.s.entry_ctl0 = XON;
+	rx_cal0.s.entry_ctl1 = XON;
+	rx_cal0.s.entry_ctl2 = XON;
+	rx_cal0.s.entry_ctl3 = XON;
+
+	rx_cal1.u64 = 0;
+	rx_cal1.s.entry_ctl4 = XON;
+	rx_cal1.s.entry_ctl5 = XON;
+	rx_cal1.s.entry_ctl6 = XON;
+	rx_cal1.s.entry_ctl7 = XON;
+
+	/* Write all 288 entries */
+	for (i = 0; i < CVMX_ILK_MAX_CAL_IDX; i++) {
+		cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL0(interface), rx_cal0.u64);
+		cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL1(interface), rx_cal1.u64);
+	}
+}
+
+/**
+ * @INTERNAL
+ * Setup the channel's tx calendar entry.
+ *
+ * @param interface Interface channel belongs to
+ * @param channel Channel whose calendar entry is to be updated
+ * @param bpid Bpid assigned to the channel
+ */
+void __cvmx_ilk_write_tx_cal_entry(int			interface,
+				   int			channel,
+				   unsigned char	bpid)
+{
+	cvmx_ilk_txx_idx_cal_t	tx_idx;
+	cvmx_ilk_txx_mem_cal0_t	tx_cal0;
+	cvmx_ilk_txx_mem_cal1_t	tx_cal1;
+	int			entry;
+	int			window;
+	int			window_entry;
+
+	/*
+	 * The calendar has 288 entries. Each calendar entry represents a
+	 * channel's flow control state or the link flow control state.
+	 * Starting with the first entry, every sixteenth entry is used for the
+	 * link flow control state. The other 15 entries are used for the
+	 * channels flow control state:
+	 * entry 0   ----> link flow control state
+	 * entry 1   ----> channel 0 flow control state
+	 * entry 2   ----> channel 1 flow control state
+	 * ...
+	 * entry 15  ----> channel 14 flow control state
+	 * entry 16  ----> link flow control state
+	 * entry 17  ----> channel 15 flow control state
+	 *
+	 * Also, the calendar is accessed via windows into it. Each window maps
+	 * to 8 entries.
+	 */
+	entry = 1 + channel + (channel / 15);
+	window = entry / 8;
+	window_entry = entry % 8;
+
+	/* Indicate the window we need to access */
+	tx_idx.u64 = 0;
+	tx_idx.s.index = window;
+	cvmx_write_csr(CVMX_ILK_TXX_IDX_CAL(interface), tx_idx.u64);
+
+	/* Get the window's current value */
+	tx_cal0.u64 = cvmx_read_csr(CVMX_ILK_TXX_MEM_CAL0(interface));
+	tx_cal1.u64 = cvmx_read_csr(CVMX_ILK_TXX_MEM_CAL1(interface));
+
+	/* Force every sixteenth entry as link flow control state */
+	if ((window & 1) == 0)
+		tx_cal0.s.entry_ctl0 = LINK;
+
+	/* Update the entry */
+	switch (window_entry) {
+	case 0:
+		tx_cal0.s.entry_ctl0 = 0;
+		tx_cal0.s.bpid0 = bpid;
+		break;
+	case 1:
+		tx_cal0.s.entry_ctl1 = 0;
+		tx_cal0.s.bpid1 = bpid;
+		break;
+	case 2:
+		tx_cal0.s.entry_ctl2 = 0;
+		tx_cal0.s.bpid2 = bpid;
+		break;
+	case 3:
+		tx_cal0.s.entry_ctl3 = 0;
+		tx_cal0.s.bpid3 = bpid;
+		break;
+	case 4:
+		tx_cal1.s.entry_ctl4 = 0;
+		tx_cal1.s.bpid4 = bpid;
+		break;
+	case 5:
+		tx_cal1.s.entry_ctl5 = 0;
+		tx_cal1.s.bpid5 = bpid;
+		break;
+	case 6:
+		tx_cal1.s.entry_ctl6 = 0;
+		tx_cal1.s.bpid6 = bpid;
+		break;
+	case 7:
+		tx_cal1.s.entry_ctl7 = 0;
+		tx_cal1.s.bpid7 = bpid;
+		break;
+	}
+
+	/* Write the window new value */
+	cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL0(interface), tx_cal0.u64);
+	cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL1(interface), tx_cal1.u64);
+}
+
+/**
+ * @INTERNAL
+ * Setup the channel's rx calendar entry.
+ *
+ * @param interface Interface channel belongs to
+ * @param channel Channel whose calendar entry is to be updated
+ * @param pipe PKO assigned to the channel
+ */
+void __cvmx_ilk_write_rx_cal_entry(int			interface,
+				   int			channel,
+				   unsigned char	pipe)
+{
+	cvmx_ilk_rxx_idx_cal_t	rx_idx;
+	cvmx_ilk_rxx_mem_cal0_t	rx_cal0;
+	cvmx_ilk_rxx_mem_cal1_t	rx_cal1;
+	int			entry;
+	int			window;
+	int			window_entry;
+
+	/*
+	 * The calendar has 288 entries. Each calendar entry represents a
+	 * channel's flow control state or the link flow control state.
+	 * Starting with the first entry, every sixteenth entry is used for the
+	 * link flow control state. The other 15 entries are used for the
+	 * channels flow control state:
+	 * entry 0   ----> link flow control state
+	 * entry 1   ----> channel 0 flow control state
+	 * entry 2   ----> channel 1 flow control state
+	 * ...
+	 * entry 15  ----> channel 14 flow control state
+	 * entry 16  ----> link flow control state
+	 * entry 17  ----> channel 15 flow control state
+	 *
+	 * Also, the calendar is accessed via windows into it. Each window maps
+	 * to 8 entries.
+	 */
+	entry = 1 + channel + (channel / 15);
+	window = entry / 8;
+	window_entry = entry % 8;
+
+	/* Indicate the window we need to access */
+	rx_idx.u64 = 0;
+	rx_idx.s.index = window;
+	cvmx_write_csr(CVMX_ILK_RXX_IDX_CAL(interface), rx_idx.u64);
+
+	/* Get the window's current value */
+	rx_cal0.u64 = cvmx_read_csr(CVMX_ILK_RXX_MEM_CAL0(interface));
+	rx_cal1.u64 = cvmx_read_csr(CVMX_ILK_RXX_MEM_CAL1(interface));
+
+	/* Force every sixteenth entry as link flow control state */
+	if ((window & 1) == 0)
+		rx_cal0.s.entry_ctl0 = LINK;
+
+	/* Update the entry */
+	switch (window_entry) {
+	case 0:
+		rx_cal0.s.entry_ctl0 = 0;
+		rx_cal0.s.port_pipe0 = pipe;
+		break;
+	case 1:
+		rx_cal0.s.entry_ctl1 = 0;
+		rx_cal0.s.port_pipe1 = pipe;
+		break;
+	case 2:
+		rx_cal0.s.entry_ctl2 = 0;
+		rx_cal0.s.port_pipe2 = pipe;
+		break;
+	case 3:
+		rx_cal0.s.entry_ctl3 = 0;
+		rx_cal0.s.port_pipe3 = pipe;
+		break;
+	case 4:
+		rx_cal1.s.entry_ctl4 = 0;
+		rx_cal1.s.port_pipe4 = pipe;
+		break;
+	case 5:
+		rx_cal1.s.entry_ctl5 = 0;
+		rx_cal1.s.port_pipe5 = pipe;
+		break;
+	case 6:
+		rx_cal1.s.entry_ctl6 = 0;
+		rx_cal1.s.port_pipe6 = pipe;
+		break;
+	case 7:
+		rx_cal1.s.entry_ctl7 = 0;
+		rx_cal1.s.port_pipe7 = pipe;
+		break;
+	}
+
+	/* Write the window new value */
+	cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL0(interface), rx_cal0.u64);
+	cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL1(interface), rx_cal1.u64);
+}
+
+/**
+ * @INTERNAL
  * Probe a ILK interface and determine the number of ports
  * connected to it. The ILK interface should still be down
  * after this call.
@@ -114,7 +374,7 @@ int __cvmx_helper_ilk_probe(int interface)
 
 static int __cvmx_helper_ilk_init_port(int interface)
 {
-	int i, j, num_pknd, res = -1;
+	int i, j, res = -1;
 	static int pipe_base = 0, pknd_base = 0;
 	static cvmx_ilk_pipe_chan_t *pch = NULL, *tmp;
 	static cvmx_ilk_chan_pknd_t *chpknd = NULL, *tmp1;
@@ -203,8 +463,7 @@ static int __cvmx_helper_ilk_init_port(int interface)
 		tmp1++;
 	}
 
-	num_pknd = cvmx_ilk_chans[interface];
-	res = cvmx_ilk_rx_set_pknd(interface, chpknd, num_pknd);
+	res = cvmx_ilk_rx_set_pknd(interface, chpknd, cvmx_ilk_chans[interface]);
 	if (res < 0) {
 		pipe_base -= cvmx_ilk_chans[interface];
 		res = 0;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c b/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
index a8d5f33..d26f3d6 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
@@ -43,7 +43,7 @@
  * Functions for NPI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 78654 $<hr>
+ * <hr>$Revision: 88039 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -73,7 +73,6 @@ int __cvmx_helper_npi_probe(int interface)
 {
 	/* TODO: When using config language what do we return? */
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
-		if (__cvmx_pko_queue_static_config.pknd.pko_queues_per_port_pci > 0)
 			return 32;
 	}
 	else if (!(OCTEON_IS_MODEL(OCTEON_CN52XX_PASS1_X) ||
@@ -82,7 +81,6 @@ int __cvmx_helper_npi_probe(int interface)
 		   OCTEON_IS_MODEL(OCTEON_CN50XX) ||
 		   OCTEON_IS_MODEL(OCTEON_CN30XX))) {
 		/* The packet engines didn't exist before cn56xx pass 2 */
-		if (__cvmx_pko_queue_static_config.non_pknd.pko_queues_per_port_pci > 0)
 			return 4;
 	}
 	return 0;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
index 27e5e23..f02873d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
@@ -43,7 +43,7 @@
  * Functions for RGMII/GMII/MII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 75409 $<hr>
+ * <hr>$Revision: 86586 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -255,6 +255,33 @@ cvmx_helper_link_info_t __cvmx_helper_rgmii_link_get(int ipd_port)
 
 /**
  * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set().
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
+cvmx_helper_link_info_t __cvmx_helper_gmii_link_get(int ipd_port)
+{
+	cvmx_helper_link_info_t result;
+	int index = cvmx_helper_get_interface_index_num(ipd_port);
+
+	if (index == 0)
+		result = __cvmx_helper_rgmii_link_get(ipd_port);
+	else {
+		result.s.full_duplex = 1;
+		result.s.link_up = 1;
+		result.s.speed = 1000;
+	}
+
+	return result;
+}
+
+/**
+ * @INTERNAL
  * Configure an IPD/PKO port for the specified link state. This
  * function does not influence auto negotiation at the PHY level.
  * The passed link state must always match the link state returned
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
index c747423..dac8e71 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 84582 $<hr>
+ * <hr>$Revision: 89030 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -52,9 +52,14 @@
 #include <asm/octeon/cvmx-helper.h>
 #include <asm/octeon/cvmx-helper-board.h>
 #include <asm/octeon/cvmx-helper-cfg.h>
+#include <asm/octeon/cvmx-bgxx-defs.h>
+#include <asm/octeon/cvmx-gserx-defs.h>
 #include <asm/octeon/cvmx-pcsx-defs.h>
 #include <asm/octeon/cvmx-gmxx-defs.h>
 #include <asm/octeon/cvmx-ciu-defs.h>
+#include <asm/octeon/cvmx-bgxx-defs.h>
+#include <asm/octeon/cvmx-gser.h>
+#include <asm/octeon/cvmx-bgx.h>
 #else
 
 #include "cvmx.h"
@@ -64,6 +69,8 @@
 #include "cvmx-helper-board.h"
 #include "cvmx-helper-cfg.h"
 #include "cvmx-qlm.h"
+#include "cvmx-gser.h"
+#include "cvmx-bgx.h"
 #endif
 
 
@@ -91,26 +98,21 @@ static int __cvmx_helper_sgmii_hardware_init_one_time(int interface, int index)
 	gmxx_prtx_cfg.s.en = 0;
 	cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmxx_prtx_cfg.u64);
 
-#if 0
-	/* This really should be called here but it doesn't work for some reason
-	 */
-	/* The Cortina PHY runs in 1000base-X mode */
-	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_NIC68_4) {
-		union cvmx_pcsx_miscx_ctl_reg pcsx_miscx_ctl_reg;
-
-		pcsx_miscx_ctl_reg.u64 =
-			 cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
-		pcsx_miscx_ctl_reg.s.mode = 1;
-		cvmx_write_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface),
-			       pcsx_miscx_ctl_reg.u64);
-	}
-#endif
 	/*
 	 * Write PCS*_LINK*_TIMER_COUNT_REG[COUNT] with the
 	 * appropriate value. 1000BASE-X specifies a 10ms
 	 * interval. SGMII specifies a 1.6ms interval.
 	 */
-	pcsx_miscx_ctl_reg.u64 = cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
+	pcsx_miscx_ctl_reg.u64 = cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index,
+								       interface));
+	/* Adjust the MAC mode if requested by device tree */
+	pcsx_miscx_ctl_reg.s.mac_phy =
+		cvmx_helper_get_mac_phy_mode(interface, index);
+	pcsx_miscx_ctl_reg.s.mode =
+		cvmx_helper_get_1000x_mode(interface, index);
+	cvmx_write_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface),
+		       pcsx_miscx_ctl_reg.u64);
+
 	pcsx_linkx_timer_count_reg.u64 = cvmx_read_csr(CVMX_PCSX_LINKX_TIMER_COUNT_REG(index, interface));
 	if (pcsx_miscx_ctl_reg.s.mode)
 		/* 1000BASE-X */
@@ -142,19 +144,6 @@ static int __cvmx_helper_sgmii_hardware_init_one_time(int interface, int index)
 		cvmx_write_csr(CVMX_PCSX_ANX_ADV_REG(index, interface),
 			       pcsx_anx_adv_reg.u64);
 	} else {
-#ifdef CVMX_HELPER_CONFIG_NO_PHY
-		/*
-		 * If the interface does not have PHY, then set
-		 * explicitly in PHY mode so that link will be set
-		 * during auto negotiation.
-		 */
-		if (!pcsx_miscx_ctl_reg.s.mac_phy) {
-			cvmx_dprintf("SGMII%d%d: Forcing PHY mode as PHY address is not set\n",
-				     interface, index);
-			pcsx_miscx_ctl_reg.s.mac_phy = 1;
-			cvmx_write_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface), pcsx_miscx_ctl_reg.u64);
-		}
-#endif
 		if (pcsx_miscx_ctl_reg.s.mac_phy) {
 			/* PHY Mode */
 			union cvmx_pcsx_sgmx_an_adv_reg pcsx_sgmx_an_adv_reg;
@@ -196,9 +185,13 @@ static int __cvmx_helper_need_g15618(void)
 static int __cvmx_helper_sgmii_hardware_init_link(int interface, int index)
 {
 	union cvmx_pcsx_mrx_control_reg control_reg;
+	union cvmx_pcsx_miscx_ctl_reg pcsx_miscx_ctl_reg;
+	bool phy_mode;
+	bool mode_1000x;
 
 	if (!cvmx_helper_is_port_valid(interface, index))
 		return 0;
+
 	/*
 	 * Take PCS through a reset sequence.
 	 * PCS*_MR*_CONTROL_REG[PWR_DN] should be cleared to zero.
@@ -232,15 +225,19 @@ static int __cvmx_helper_sgmii_hardware_init_link(int interface, int index)
 		       control_reg.u64);
 
 	/* The Cortina PHY runs in 1000base-X mode */
-	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_NIC68_4) {
-		union cvmx_pcsx_miscx_ctl_reg pcsx_miscx_ctl_reg;
+	phy_mode = cvmx_helper_get_mac_phy_mode(interface, index);
+	mode_1000x = cvmx_helper_get_1000x_mode(interface, index);
+	pcsx_miscx_ctl_reg.u64 =
+		cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
+	pcsx_miscx_ctl_reg.s.mode = mode_1000x;
+	pcsx_miscx_ctl_reg.s.mac_phy = phy_mode;
+	cvmx_write_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface), pcsx_miscx_ctl_reg.u64);
+	if (phy_mode)
+		/* In PHY mode we can't query the link status so we just
+		 * assume that the link is up.
+		 */
+		return 0;
 
-		pcsx_miscx_ctl_reg.u64 =
-			 cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
-		pcsx_miscx_ctl_reg.s.mode = 1;
-		cvmx_write_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface),
-			       pcsx_miscx_ctl_reg.u64);
-	}
 	/*
 	 * Wait for PCS*_MR*_STATUS_REG[AN_CPT] to be set, indicating
 	 * that sgmii autonegotiation is complete. In MAC mode this
@@ -251,7 +248,7 @@ static int __cvmx_helper_sgmii_hardware_init_link(int interface, int index)
 	    CVMX_WAIT_FOR_FIELD64(CVMX_PCSX_MRX_STATUS_REG(index, interface),
 				  union cvmx_pcsx_mrx_status_reg, an_cpt, ==, 1,
 				  10000)) {
-		/* cvmx_dprintf("SGMII%d: Port %d link timeout\n", interface, index); */
+		cvmx_dprintf("SGMII%d: Port %d link timeout\n", interface, index);
 		return -1;
 	}
 	return 0;
@@ -434,7 +431,7 @@ static int __cvmx_helper_sgmii_hardware_init(int interface, int num_ports)
 #endif
 		if (do_link_set)
 			__cvmx_helper_sgmii_link_set(ipd_port,
-						     __cvmx_helper_sgmii_link_get(ipd_port));
+					__cvmx_helper_sgmii_link_get(ipd_port));
 	}
 
 	return 0;
@@ -445,14 +442,13 @@ int __cvmx_helper_sgmii_enumerate(int interface)
 	if (OCTEON_IS_MODEL(OCTEON_CNF71XX))
 		return 2;
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
-		cvmx_gmxx_inf_mode_t inf_mode;
-		inf_mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
-		if (inf_mode.s.mode == 1)	/* SGMII */
+		enum cvmx_qlm_mode qlm_mode = cvmx_qlm_get_dlm_mode(0, interface);
+
+		if (qlm_mode == CVMX_QLM_MODE_SGMII)
 			return 1;
-		else if (inf_mode.s.mode == 2)	/* QSGMII */
+		else if (qlm_mode == CVMX_QLM_MODE_QSGMII)
 			return 4;
-		else
-			return 0;
+		return 0;
 	}
 	return 4;
 }
@@ -470,6 +466,7 @@ int __cvmx_helper_sgmii_enumerate(int interface)
 int __cvmx_helper_sgmii_probe(int interface)
 {
 	union cvmx_gmxx_inf_mode mode;
+	int ports;
 
 	/*
 	 * Check if QLM is configured correct for SGMII, verify the
@@ -481,6 +478,13 @@ int __cvmx_helper_sgmii_probe(int interface)
 		if (cvmx_qlm_get_mode(qlm) != CVMX_QLM_MODE_SGMII)
 			return 0;
 	}
+
+	/* Do not enable the interface if is not in SGMII mode */
+	ports = __cvmx_helper_sgmii_enumerate(interface);
+
+	if (ports <= 0)
+		return 0;
+
 	/*
 	 * Due to errata GMX-700 on CN56XXp1.x and CN52XXp1.x, the
 	 * interface needs to be enabled before IPD otherwise per port
@@ -490,7 +494,7 @@ int __cvmx_helper_sgmii_probe(int interface)
 	mode.s.en = 1;
 	cvmx_write_csr(CVMX_GMXX_INF_MODE(interface), mode.u64);
 
-	return __cvmx_helper_sgmii_enumerate(interface);
+	return ports;
 }
 
 /**
@@ -556,7 +560,7 @@ int __cvmx_helper_sgmii_enable(int interface)
 		union cvmx_gmxx_qsgmii_ctl qsgmii_ctl;
 		qsgmii_ctl.u64 = 0;
 		qsgmii_ctl.s.disparity = 1;
-		cvmx_write_csr(CVMX_GMXX_QSGMII_CTL(interface), qsgmii_ctl.u64);	
+		cvmx_write_csr(CVMX_GMXX_QSGMII_CTL(interface), qsgmii_ctl.u64);
 	}
 
 	for (index = 0; index < num_ports; index++) {
@@ -600,7 +604,6 @@ cvmx_helper_link_info_t __cvmx_helper_sgmii_link_get(int ipd_port)
 	int interface = cvmx_helper_get_interface_num(ipd_port);
 	int index = cvmx_helper_get_interface_index_num(ipd_port);
 	union cvmx_pcsx_mrx_control_reg pcsx_mrx_control_reg;
-	union cvmx_pcsx_mrx_status_reg pcsx_mrx_status_reg;
 	int speed = 1000;
 	int qlm;
 
@@ -617,7 +620,7 @@ cvmx_helper_link_info_t __cvmx_helper_sgmii_link_get(int ipd_port)
 		return result;
 	}
 
-	if (OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN70XX)) {
+	if (OCTEON_IS_MODEL(OCTEON_CN66XX)) {
 		union cvmx_gmxx_inf_mode inf_mode;
 		inf_mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
 		if (inf_mode.s.rate & (1 << index))
@@ -629,6 +632,9 @@ cvmx_helper_link_info_t __cvmx_helper_sgmii_link_get(int ipd_port)
 		speed = cvmx_qlm_get_gbaud_mhz(qlm) * 8 / 10;
 	} else if (OCTEON_IS_MODEL(OCTEON_CNF71XX)) {
 		speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
+	} else if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
+		speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
+		speed >>= 2;
 	}
 
 	pcsx_mrx_control_reg.u64 = cvmx_read_csr(CVMX_PCSX_MRX_CONTROL_REG(index, interface));
@@ -640,53 +646,16 @@ cvmx_helper_link_info_t __cvmx_helper_sgmii_link_get(int ipd_port)
 		return result;
 	}
 
-	pcsx_miscx_ctl_reg.u64 = cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
+	pcsx_miscx_ctl_reg.u64 =
+		cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
 	if (pcsx_miscx_ctl_reg.s.mac_phy) {
 		/* PHY Mode */
 		/* Note that this also works for 1000base-X mode */
-		union cvmx_pcsx_anx_results_reg pcsx_anx_results_reg;
 
-		/*
-		 * Don't bother continuing if the SERTES low
-		 * level link is down.
-		 */
-		pcsx_mrx_status_reg.u64 = cvmx_read_csr(CVMX_PCSX_MRX_STATUS_REG(index, interface));
-		if (pcsx_mrx_status_reg.s.lnk_st == 0)
-			if (__cvmx_helper_sgmii_hardware_init_link(interface, index) != 0)
-				return result;
-
-		/* Read the autoneg results */
-		pcsx_anx_results_reg.u64 = cvmx_read_csr(CVMX_PCSX_ANX_RESULTS_REG(index, interface));
-		if (pcsx_anx_results_reg.s.an_cpt) {
-			/*
-			 * Auto negotiation is complete. Set
-			 * status accordingly.
-			 */
-			result.s.full_duplex = pcsx_anx_results_reg.s.dup;
-			result.s.link_up = pcsx_anx_results_reg.s.link_ok;
-			switch (pcsx_anx_results_reg.s.spd) {
-			case 0:
-				result.s.speed = speed / 100;
-				break;
-			case 1:
-				result.s.speed = speed / 10;
-				break;
-			case 2:
-				result.s.speed = speed;
-				break;
-			default:
-				result.s.speed = 0;
-				result.s.link_up = 0;
-				break;
-			}
-		} else {
-			/*
-			 * Auto negotiation isn't
-			 * complete. Return link down.
-			 */
-			result.s.speed = 0;
-			result.s.link_up = 0;
-		}
+		result.s.speed = speed;
+		result.s.full_duplex = 1;
+		result.s.link_up = 1;
+		return result;
 	} else {
 		/* MAC Mode */
 		result = __cvmx_helper_board_link_get(ipd_port);
@@ -786,3 +755,132 @@ int __cvmx_helper_sgmii_configure_loopback(int ipd_port, int enable_internal,
 	__cvmx_helper_sgmii_hardware_init_link(interface, index);
 	return 0;
 }
+
+/**
+ * @INTERNAL
+ * Probe a SGMII interface and determine the number of ports
+ * connected to it. The SGMII interface should still be down after
+ * this call. This is used by interfaces using the bgx mac.
+ *
+ * @param interface Interface to probe
+ *
+ * @return Number of ports on the interface. Zero to disable.
+ */
+int __cvmx_helper_bgx_sgmii_probe(int interface)
+{
+	int	qlm;
+
+	/*
+	 * Check the QLM is configured correctly for SGMII, verify the
+	 * speed as well as the mode.
+	 */
+	qlm = cvmx_qlm_interface(interface);
+	if (cvmx_qlm_get_mode(qlm) != CVMX_QLM_MODE_SGMII)
+		return 0;
+
+	return __cvmx_helper_sgmii_enumerate(interface);
+}
+
+/**
+ * @INTERNAL
+ * Bringup and enable a SGMII interface. After this call packet
+ * I/O should be fully functional. This is called with IPD
+ * enabled but PKO disabled. This is used by interfaces using
+ * the bgx mac.
+ *
+ * @param interface Interface to bring up
+ *
+ * @return Zero on success, negative on failure
+ */
+int __cvmx_helper_bgx_sgmii_enable(int interface)
+{
+	cvmx_bgxx_cmrx_rx_id_map_t	bgx_cmr_rx_id_map;
+	int				num_ports;
+	int				pknd;
+	int				i;
+
+	num_ports = cvmx_helper_ports_on_interface(interface);
+
+	/* Configure the gser */
+	gser_init(interface, CVMX_HELPER_INTERFACE_MODE_SGMII);
+
+	/* Configure the bgx mac */
+	bgx_init(interface, CVMX_HELPER_INTERFACE_MODE_SGMII);
+
+	/* Setup pkind */
+	for (i = 0; i < num_ports; i++) {
+		pknd = cvmx_helper_get_pknd(interface, i);
+		bgx_cmr_rx_id_map.u64 = 0;
+		bgx_cmr_rx_id_map.s.rid = 2 + i;
+		bgx_cmr_rx_id_map.s.pknd = pknd;
+		cvmx_write_csr(CVMX_BGXX_CMRX_RX_ID_MAP(i, interface),
+			       bgx_cmr_rx_id_map.u64);
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set(). This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
+cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port)
+{
+	cvmx_helper_link_info_t result;
+
+	/* Hardcoded for now. TODO */
+	result.s.link_up = 1;
+	result.s.full_duplex = 1;
+	result.s.speed = 1000;
+
+	return result;
+}
+
+/**
+ * @INTERNAL
+ * Configure an IPD/PKO port for the specified link state. This
+ * function does not influence auto negotiation at the PHY level.
+ * The passed link state must always match the link state returned
+ * by cvmx_helper_link_get(). It is normally best to use
+ * cvmx_helper_link_autoconf() instead. This is used by interfaces
+ * using the bgx mac.
+ *
+ * @param ipd_port  IPD/PKO port to configure
+ * @param link_info The new link state
+ *
+ * @return Zero on success, negative on failure
+ */
+int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
+				 cvmx_helper_link_info_t link_info)
+{
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Configure a port for internal and/or external loopback. Internal loopback
+ * causes packets sent by the port to be received by Octeon. External loopback
+ * causes packets received from the wire to sent out again. This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to loopback.
+ * @param enable_internal
+ *                 Non zero if you want internal loopback
+ * @param enable_external
+ *                 Non zero if you want external loopback
+ *
+ * @return Zero on success, negative on failure.
+ */
+int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port, int enable_internal,
+					   int enable_external)
+{
+	return 0;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
index bc0277e..911fe20 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
@@ -78,6 +78,82 @@
 #endif
 
 
+/**
+ * @INTERNAL
+ * These are the interface types needed to convert interface numbers to ipd
+ * ports.
+ *
+ * @param GMII
+ *	This type is used for sgmii, rgmii, xaui and rxaui interfaces.
+ * @param ILK
+ *	This type is used for ilk interfaces.
+ * @param NPI
+ *	This type is used for npi interfaces.
+ * @param LB
+ *	This type is used for loopback interfaces.
+ */
+typedef enum {
+	GMII,
+	ILK,
+	NPI,
+	LB
+} port_map_if_type_t;
+
+/**
+ * @INTERNAL
+ * This structure is used to map interface numbers to ipd ports.
+ *
+ * @param type
+ *	Interface type
+ * @param first_ipd_port
+ *	First IPD port number assigned to this interface.
+ * @param last_ipd_port
+ *	Last IPD port number assigned to this interface.
+ * @param ipd_port_adj
+ *	Different octeon chips require different ipd ports for the 
+ *	same interface port/mode configuration. This value is used
+ *	to account for that difference.
+ */
+struct ipd_port_map {
+	port_map_if_type_t	type;
+	int			first_ipd_port;
+	int			last_ipd_port;
+	int			ipd_port_adj;
+};
+
+/**
+ * @INTERNAL
+ * Interface number to ipd port map for the octeon 68xx.
+ */
+static const struct ipd_port_map ipd_port_map_68xx[CVMX_HELPER_MAX_IFACE] = {
+	{GMII,	0x800,	0x8ff,	0x40},		/* Interface 0 */
+	{GMII,	0x900,	0x9ff,	0x40},		/* Interface 1 */
+	{GMII,	0xa00,	0xaff,	0x40},		/* Interface 2 */
+	{GMII,	0xb00,	0xbff,	0x40},		/* Interface 3 */
+	{GMII,	0xc00,	0xcff,	0x40},		/* Interface 4 */
+	{ILK,	0x400,	0x4ff,	0x00},		/* Interface 5 */
+	{ILK,	0x500,	0x5ff,	0x00},		/* Interface 6 */
+	{NPI,	0x100,	0x120,	0x00},		/* Interface 7 */
+	{LB,	0x000,	0x008,	0x00},		/* Interface 8 */
+};
+
+/**
+ * @INTERNAL
+ * Interface number to ipd port map for the octeon 78xx.
+ */
+static const struct ipd_port_map ipd_port_map_78xx[CVMX_HELPER_MAX_IFACE] = {
+	{GMII,	0x800,	0x8ff,	0x00},		/* Interface 0 */
+	{GMII,	0x900,	0x9ff,	0x00},		/* Interface 1 */
+	{GMII,	0xa00,	0xaff,	0x00},		/* Interface 2 */
+	{GMII,	0xb00,	0xbff,	0x00},		/* Interface 3 */
+	{GMII,	0xc00,	0xcff,	0x00},		/* Interface 4 */
+	{GMII,	0xd00,	0xdff,	0x00},		/* Interface 5 */
+	{ILK,	0x400,	0x4ff,	0x00},		/* Interface 6 */
+	{ILK,	0x500,	0x5ff,	0x00},		/* Interface 7 */
+	{NPI,	0x100,	0x120,	0x00},		/* Interface 8 */
+	{LB,	0x000,	0x008,	0x00},		/* Interface 9 */
+};
+
 struct cvmx_iface {
 	int cvif_ipd_nports;
 	int cvif_has_fcs;	/* PKO fcs for this interface. */
@@ -91,11 +167,6 @@ struct cvmx_iface {
  */
 static CVMX_SHARED struct cvmx_iface cvmx_interfaces[CVMX_HELPER_MAX_IFACE];
 
-CVMX_SHARED bool __cvmx_helper_port_invalid[CVMX_HELPER_MAX_IFACE][CVMX_HELPER_MAX_PORTS] = {[0 ... (CVMX_HELPER_MAX_IFACE - 1)] = {[0 ... (CVMX_HELPER_MAX_PORTS - 1)] = 1}};
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-EXPORT_SYMBOL(__cvmx_helper_port_invalid);
-#endif
-
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 /**
  * Get the version of the CVMX libraries.
@@ -496,11 +567,13 @@ int __cvmx_helper_setup_gmx(int interface, int num_ports)
 	 * Tell GMX the number of RX ports on this interface.  This only applies
 	 * to *GMII and XAUI ports.
 	 */
-	if (cvmx_helper_interface_get_mode(interface) == CVMX_HELPER_INTERFACE_MODE_RGMII ||
-	    cvmx_helper_interface_get_mode(interface) == CVMX_HELPER_INTERFACE_MODE_SGMII ||
-	    cvmx_helper_interface_get_mode(interface) == CVMX_HELPER_INTERFACE_MODE_GMII ||
-	    cvmx_helper_interface_get_mode(interface) == CVMX_HELPER_INTERFACE_MODE_XAUI ||
-	    cvmx_helper_interface_get_mode(interface) == CVMX_HELPER_INTERFACE_MODE_RXAUI) {
+	switch (cvmx_helper_interface_get_mode(interface)) {
+	case CVMX_HELPER_INTERFACE_MODE_RGMII:
+	case CVMX_HELPER_INTERFACE_MODE_SGMII:
+	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
+	case CVMX_HELPER_INTERFACE_MODE_GMII:
+	case CVMX_HELPER_INTERFACE_MODE_XAUI:
+	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
 		if (num_ports > 4) {
 			cvmx_dprintf("__cvmx_helper_setup_gmx: Illegal num_ports\n");
 			return -1;
@@ -509,6 +582,10 @@ int __cvmx_helper_setup_gmx(int interface, int num_ports)
 		gmx_rx_prts.u64 = cvmx_read_csr(CVMX_GMXX_RX_PRTS(interface));
 		gmx_rx_prts.s.prts = num_ports;
 		cvmx_write_csr(CVMX_GMXX_RX_PRTS(interface), gmx_rx_prts.u64);
+		break;
+
+	default:
+		break;
 	}
 
 	/*
@@ -611,21 +688,36 @@ EXPORT_SYMBOL(cvmx_helper_get_pko_port);
 int cvmx_helper_get_ipd_port(int interface, int port)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		if (interface >= 0 && interface <= 4) {
-			cvmx_helper_interface_mode_t mode = cvmx_helper_interface_get_mode(interface);
+		const struct ipd_port_map	*port_map;
+		int				ipd_port;
+
+		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+			port_map = ipd_port_map_68xx;
+		else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+			port_map = ipd_port_map_78xx;
+		else
+			return -1;
+
+		ipd_port = port_map[interface].first_ipd_port;
+		if (port_map[interface].type == GMII) {
+			cvmx_helper_interface_mode_t mode =
+				cvmx_helper_interface_get_mode(interface);
 			if (mode == CVMX_HELPER_INTERFACE_MODE_XAUI ||
-			    mode == CVMX_HELPER_INTERFACE_MODE_RXAUI)
-				return 0x840 + (interface * 0x100);
+			    mode == CVMX_HELPER_INTERFACE_MODE_RXAUI) {
+				ipd_port += port_map[interface].ipd_port_adj;
+				return ipd_port;
+			}
 			else
-				return 0x800 + (interface * 0x100) + (port * 16);
-		} else if (interface == 5 || interface == 6)
-			return 0x400 + (interface - 5) * 0x100 + port;
-		else if (interface == 7)
-			return 0x100 + port;
-		else if (interface == 8)
-			return port;
+				return ipd_port + (port * 16);
+		} else if (port_map[interface].type == ILK)
+			return ipd_port + port;
+		else if (port_map[interface].type == NPI)
+			return ipd_port + port;
+		else if (port_map[interface].type == LB)
+			return ipd_port + port;
 		else
 			return -1;
+
 	} else if (cvmx_helper_interface_get_mode(interface) ==
 			CVMX_HELPER_INTERFACE_MODE_AGL) {
 		return 24;
@@ -865,24 +957,24 @@ void cvmx_helper_show_stats(int port)
 int cvmx_helper_get_interface_num(int ipd_port)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		if (ipd_port >= 0x800 && ipd_port < 0x900)
-			return 0;
-		else if (ipd_port >= 0x900 && ipd_port < 0xa00)
-			return 1;
-		else if (ipd_port >= 0xa00 && ipd_port < 0xb00)
-			return 2;
-		else if (ipd_port >= 0xb00 && ipd_port < 0xc00)
-			return 3;
-		else if (ipd_port >= 0xc00 && ipd_port < 0xd00)
-			return 4;
-		else if (ipd_port >= 0x400 && ipd_port < 0x500)
-			return 5;
-		else if (ipd_port >= 0x500 && ipd_port < 0x600)
-			return 6;
-		else if (ipd_port >= 0x100 && ipd_port < 0x120)
-			return 7;
-		else if (ipd_port < 8)
-			return 8;
+		const struct ipd_port_map	*port_map;
+		int				i;
+
+		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+			port_map = ipd_port_map_68xx;
+		else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+			port_map = ipd_port_map_78xx;
+		else
+			return -1;
+
+		for (i = 0; i < CVMX_HELPER_MAX_IFACE; i++) {
+			if (ipd_port >= port_map[i].first_ipd_port &&
+			    ipd_port <= port_map[i].last_ipd_port)
+				return i;
+		}
+
+		return -1;
+
 	} else if (OCTEON_IS_MODEL(OCTEON_CN70XX) && ipd_port == 24) {
 		return 4;
 	} else {
@@ -948,23 +1040,3 @@ int cvmx_helper_get_interface_index_num(int ipd_port)
 	return -1;
 }
 EXPORT_SYMBOL(cvmx_helper_get_interface_index_num);
-
-/**
- * Returns if port is valid for a given interface
- *
- * @param interface  interface to check
- * @param index      port index in the interface
- *
- * @return status of the port present or not.
- */
-int cvmx_helper_is_port_valid(int interface, int index)
-{
-	return  !__cvmx_helper_port_invalid[interface][index];
-}
-EXPORT_SYMBOL(cvmx_helper_is_port_valid);
-
-void cvmx_helper_set_port_valid(int interface, int index, bool valid)
-{
-	__cvmx_helper_port_invalid[interface][index] = !valid;
-}
-EXPORT_SYMBOL(cvmx_helper_set_port_valid);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
index ee77ae9..a355e03 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 83639 $<hr>
+ * <hr>$Revision: 88172 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -55,12 +55,17 @@
 #include <asm/octeon/cvmx-pcsx-defs.h>
 #include <asm/octeon/cvmx-pcsxx-defs.h>
 #include <asm/octeon/cvmx-ciu-defs.h>
+#include <asm/octeon/cvmx-bgxx-defs.h>
+#include <asm/octeon/cvmx-gser.h>
+#include <asm/octeon/cvmx-bgx.h>
 #else
 
 #include "cvmx.h"
 #include "cvmx-helper.h"
 #include "cvmx-helper-cfg.h"
 #include "cvmx-qlm.h"
+#include "cvmx-gser.h"
+#include "cvmx-bgx.h"
 #endif
 
 
@@ -69,12 +74,14 @@ int __cvmx_helper_xaui_enumerate(int interface)
 	union cvmx_gmxx_hg2_control gmx_hg2_control;
 
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
-		cvmx_gmxx_inf_mode_t inf_mode;
-		inf_mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(0));
-		if (inf_mode.s.mode == 3)	/* RXAUI */
+		enum cvmx_qlm_mode qlm_mode = cvmx_qlm_get_dlm_mode(0, interface);
+
+		if (qlm_mode == CVMX_QLM_MODE_RXAUI)
 			return 1;
 		return 0;
 		/* FIXME for higig2 */
+	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		return 1;
 	}
 	/* If HiGig2 is enabled return 16 ports, otherwise return 1 port */
 	gmx_hg2_control.u64 = cvmx_read_csr(CVMX_GMXX_HG2_CONTROL(interface));
@@ -96,7 +103,7 @@ int __cvmx_helper_xaui_enumerate(int interface)
  */
 int __cvmx_helper_xaui_probe(int interface)
 {
-	int i;
+	int i, ports;
 	union cvmx_gmxx_inf_mode mode;
 
 	/*
@@ -144,6 +151,11 @@ int __cvmx_helper_xaui_probe(int interface)
 			return 0;
 	}
 
+	ports =  __cvmx_helper_xaui_enumerate(interface);
+
+	if (ports <= 0)
+		return 0;
+
 	/*
 	 * Due to errata GMX-700 on CN56XXp1.x and CN52XXp1.x, the
 	 * interface needs to be enabled before IPD otherwise per port
@@ -155,7 +167,7 @@ int __cvmx_helper_xaui_probe(int interface)
 
 	__cvmx_helper_setup_gmx(interface, 1);
 
-	if (!OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+	if (!OCTEON_IS_MODEL(OCTEON_CN68XX) && !OCTEON_IS_MODEL(OCTEON_CN70XX)) {
 		/*
 		 * Setup PKO to support 16 ports for HiGig2 virtual
 		 * ports. We're pointing all of the PKO packet ports
@@ -180,7 +192,7 @@ int __cvmx_helper_xaui_probe(int interface)
 		}
 	}
 
-	return __cvmx_helper_xaui_enumerate(interface);
+	return ports;
 }
 
 /**
@@ -512,3 +524,133 @@ extern int __cvmx_helper_xaui_configure_loopback(int ipd_port,
 	/* Take the link through a reset */
 	return __cvmx_helper_xaui_link_init(interface);
 }
+
+/**
+ * @INTERNAL
+ * Probe a XAUI interface and determine the number of ports
+ * connected to it. The XAUI interface should still be down
+ * after this call.
+ *
+ * @param interface Interface to probe
+ *
+ * @return Number of ports on the interface. Zero to disable.
+ */
+int __cvmx_helper_bgx_xaui_probe(int interface)
+{
+	int	qlm;
+
+	/*
+	 * Check the QLM is configured correctly for XAUI, verify the
+	 * speed as well as the mode.
+	 */
+	qlm = cvmx_qlm_interface(interface);
+	if (cvmx_qlm_get_mode(qlm) != CVMX_QLM_MODE_XAUI)
+		return 0;
+
+	return __cvmx_helper_xaui_enumerate(interface);
+}
+
+/**
+ * @INTERNAL
+ * Bringup and enable a XAUI interface. After this call packet
+ * I/O should be fully functional. This is called with IPD
+ * enabled but PKO disabled.
+ *
+ * @param interface Interface to bring up
+ *
+ * @return Zero on success, negative on failure
+ */
+int __cvmx_helper_bgx_xaui_enable(int interface)
+{
+	cvmx_bgxx_cmrx_rx_id_map_t	bgx_cmr_rx_id_map;
+	int				num_ports;
+	int				pknd;
+	int				i;
+
+	num_ports = cvmx_helper_ports_on_interface(interface);
+
+	/* Configure the gser */
+	gser_init(interface, CVMX_HELPER_INTERFACE_MODE_XAUI);
+
+	/* Configure the bgx mac */
+	bgx_init(interface, CVMX_HELPER_INTERFACE_MODE_XAUI);
+
+	/*
+	 * Must hardcode the port kind here until the pko initializion is
+	 * complete. This must be removed once the pko initialization is
+	 * working. TODO
+	 */
+	pknd = 50 + (num_ports * interface);
+	for (i = 0; i < num_ports; i++) {
+		bgx_cmr_rx_id_map.u64 = 0;
+		bgx_cmr_rx_id_map.s.rid = 2 + i;
+		bgx_cmr_rx_id_map.s.pknd = pknd + i;
+		cvmx_write_csr(CVMX_BGXX_CMRX_RX_ID_MAP(i, interface),
+			       bgx_cmr_rx_id_map.u64);
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set().
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
+cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port)
+{
+	cvmx_helper_link_info_t result;
+
+	/* Hardcoded for now. TODO */
+	result.s.link_up = 1;
+	result.s.full_duplex = 1;
+	result.s.speed = 10000;
+
+	return result;
+}
+
+/**
+ * @INTERNAL
+ * Configure an IPD/PKO port for the specified link state. This
+ * function does not influence auto negotiation at the PHY level.
+ * The passed link state must always match the link state returned
+ * by cvmx_helper_link_get(). It is normally best to use
+ * cvmx_helper_link_autoconf() instead.
+ *
+ * @param ipd_port  IPD/PKO port to configure
+ * @param link_info The new link state
+ *
+ * @return Zero on success, negative on failure
+ */
+int __cvmx_helper_bgx_xaui_link_set(int				ipd_port,
+				    cvmx_helper_link_info_t	link_info)
+{
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Configure a port for internal and/or external loopback. Internal loopback
+ * causes packets sent by the port to be received by Octeon. External loopback
+ * causes packets received from the wire to sent out again.
+ *
+ * @param ipd_port IPD/PKO port to loopback.
+ * @param enable_internal
+ *                 Non zero if you want internal loopback
+ * @param enable_external
+ *                 Non zero if you want external loopback
+ *
+ * @return Zero on success, negative on failure.
+ */
+extern int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port,
+						     int enable_internal,
+						     int enable_external)
+{
+	return 0;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper.c b/arch/mips/cavium-octeon/executive/cvmx-helper.c
index 2239409..6afe4ef 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper.c
@@ -64,6 +64,7 @@
 #include <asm/octeon/cvmx-pip.h>
 #include <asm/octeon/cvmx-pko.h>
 #include <asm/octeon/cvmx-ipd.h>
+#include <asm/octeon/cvmx-qlm.h>
 #include <asm/octeon/cvmx-spi.h>
 #include <asm/octeon/cvmx-clock.h>
 #include <asm/octeon/cvmx-helper.h>
@@ -82,6 +83,7 @@
 #include "cvmx-pip.h"
 #include "cvmx-pko.h"
 #include "cvmx-ipd.h"
+#include "cvmx-qlm.h"
 #include "cvmx-spi.h"
 #include "cvmx-helper.h"
 #include "cvmx-helper-board.h"
@@ -90,6 +92,264 @@
 #endif
 
 
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by an interface.
+ *
+ * @param mode		Interface mode.
+ *
+ * @param enumerate	Method the get number of interface ports.
+ *
+ * @param probe		Method to probe an interface to get the number of
+ *			connected ports.
+ *
+ * @param enable	Method to enable an interface
+ *
+ * @param link_get	Method to get the state of an interface link.
+ *
+ * @param link_set	Method to configure an interface link to the specified
+ *			state.
+ *
+ * @param loopback	Method to configure a port in loopback.
+ */
+struct iface_ops_s {
+	cvmx_helper_interface_mode_t	mode;
+	int				(*enumerate)(int interface);
+	int				(*probe)(int interface);
+	int				(*enable)(int interface);
+	cvmx_helper_link_info_t		(*link_get)(int ipd_port);
+	int				(*link_set)(int ipd_port,
+					     cvmx_helper_link_info_t link_info);
+	int				(*loopback)(int ipd_port,
+						    int en_in, int en_ex);
+};
+
+/**
+ * @INTERNAL
+ * This structure is used by disabled interfaces.
+ */
+static const struct iface_ops_s iface_ops_dis = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_DISABLED,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as gmii.
+ */
+static const struct iface_ops_s iface_ops_gmii = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_GMII,
+	.enumerate	= __cvmx_helper_rgmii_enumerate,
+	.probe		= __cvmx_helper_rgmii_probe,
+	.enable		= __cvmx_helper_rgmii_enable,
+	.link_get	= __cvmx_helper_gmii_link_get,
+	.link_set	= __cvmx_helper_rgmii_link_set,
+	.loopback	= __cvmx_helper_rgmii_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as rgmii.
+ */
+static const struct iface_ops_s iface_ops_rgmii = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_RGMII,
+	.enumerate	= __cvmx_helper_rgmii_enumerate,
+	.probe		= __cvmx_helper_rgmii_probe,
+	.enable		= __cvmx_helper_rgmii_enable,
+	.link_get	= __cvmx_helper_rgmii_link_get,
+	.link_set	= __cvmx_helper_rgmii_link_set,
+	.loopback	= __cvmx_helper_rgmii_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as sgmii that use the gmx mac.
+ */
+static const struct iface_ops_s iface_ops_sgmii = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_SGMII,
+	.enumerate	= __cvmx_helper_sgmii_enumerate,
+	.probe		= __cvmx_helper_sgmii_probe,
+	.enable		= __cvmx_helper_sgmii_enable,
+	.link_get	= __cvmx_helper_sgmii_link_get,
+	.link_set	= __cvmx_helper_sgmii_link_set,
+	.loopback	= __cvmx_helper_sgmii_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as sgmii that use the bgx mac.
+ */
+static const struct iface_ops_s iface_ops_bgx_sgmii = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_SGMII,
+	.enumerate	= __cvmx_helper_sgmii_enumerate,
+	.probe		= __cvmx_helper_bgx_sgmii_probe,
+	.enable		= __cvmx_helper_bgx_sgmii_enable,
+	.link_get	= __cvmx_helper_bgx_sgmii_link_get,
+	.link_set	= __cvmx_helper_bgx_sgmii_link_set,
+	.loopback	= __cvmx_helper_bgx_sgmii_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as qsgmii.
+ */
+static const struct iface_ops_s iface_ops_qsgmii = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_QSGMII,
+	.enumerate	= __cvmx_helper_sgmii_enumerate,
+	.probe		= __cvmx_helper_sgmii_probe,
+	.enable		= __cvmx_helper_sgmii_enable,
+	.link_get	= __cvmx_helper_sgmii_link_get,
+	.link_set	= __cvmx_helper_sgmii_link_set,
+	.loopback	= __cvmx_helper_sgmii_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as xaui using the gmx mac.
+ */
+static const struct iface_ops_s iface_ops_xaui = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_XAUI,
+	.enumerate	= __cvmx_helper_xaui_enumerate,
+	.probe		= __cvmx_helper_xaui_probe,
+	.enable		= __cvmx_helper_xaui_enable,
+	.link_get	= __cvmx_helper_xaui_link_get,
+	.link_set	= __cvmx_helper_xaui_link_set,
+	.loopback	= __cvmx_helper_xaui_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as xaui using the bgx mac.
+ */
+static const struct iface_ops_s iface_ops_bgx_xaui = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_XAUI,
+	.enumerate	= __cvmx_helper_xaui_enumerate,
+	.probe		= __cvmx_helper_bgx_xaui_probe,
+	.enable		= __cvmx_helper_bgx_xaui_enable,
+	.link_get	= __cvmx_helper_bgx_xaui_link_get,
+	.link_set	= __cvmx_helper_bgx_xaui_link_set,
+	.loopback	= __cvmx_helper_bgx_xaui_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as rxaui.
+ */
+static const struct iface_ops_s iface_ops_rxaui = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_RXAUI,
+	.enumerate	= __cvmx_helper_xaui_enumerate,
+	.probe		= __cvmx_helper_xaui_probe,
+	.enable		= __cvmx_helper_xaui_enable,
+	.link_get	= __cvmx_helper_xaui_link_get,
+	.link_set	= __cvmx_helper_xaui_link_set,
+	.loopback	= __cvmx_helper_xaui_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as ilk.
+ */
+static const struct iface_ops_s iface_ops_ilk = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_ILK,
+	.enumerate	= __cvmx_helper_ilk_enumerate,
+	.probe		= __cvmx_helper_ilk_probe,
+	.enable		= __cvmx_helper_ilk_enable,
+	.link_get	= __cvmx_helper_ilk_link_get,
+	.link_set	= __cvmx_helper_ilk_link_set,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as npi.
+ */
+static const struct iface_ops_s iface_ops_npi = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_NPI,
+	.enumerate	= __cvmx_helper_npi_enumerate,
+	.probe		= __cvmx_helper_npi_probe,
+	.enable		= __cvmx_helper_npi_enable,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as srio.
+ */
+static const struct iface_ops_s iface_ops_srio = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_SRIO,
+	.enumerate	= __cvmx_helper_srio_enumerate,
+	.probe		= __cvmx_helper_srio_probe,
+	.enable		= __cvmx_helper_srio_enable,
+	.link_get	= __cvmx_helper_srio_link_get,
+	.link_set	= __cvmx_helper_srio_link_set,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as agl.
+ */
+static const struct iface_ops_s iface_ops_agl = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_AGL,
+	.enumerate	= __cvmx_helper_agl_enumerate,
+	.probe		= __cvmx_helper_agl_probe,
+	.enable		= __cvmx_helper_agl_enable,
+	.link_get	= __cvmx_helper_agl_link_get,
+	.link_set	= __cvmx_helper_agl_link_set,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as picmg.
+ */
+static const struct iface_ops_s iface_ops_picmg = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_PICMG,
+	.enumerate	= __cvmx_helper_sgmii_enumerate,
+	.probe		= __cvmx_helper_sgmii_probe,
+	.enable		= __cvmx_helper_sgmii_enable,
+	.link_get	= __cvmx_helper_sgmii_link_get,
+	.link_set	= __cvmx_helper_sgmii_link_set,
+	.loopback	= __cvmx_helper_sgmii_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as spi.
+ */
+static const struct iface_ops_s iface_ops_spi = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_SPI,
+	.enumerate	= __cvmx_helper_spi_enumerate,
+	.probe		= __cvmx_helper_spi_probe,
+	.enable		= __cvmx_helper_spi_enable,
+	.link_get	= __cvmx_helper_spi_link_get,
+	.link_set	= __cvmx_helper_spi_link_set,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as loop.
+ */
+static const struct iface_ops_s iface_ops_loop = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_LOOP,
+	.enumerate	= __cvmx_helper_loop_enumerate,
+	.probe		= __cvmx_helper_loop_probe,
+};
+
+CVMX_SHARED const struct iface_ops_s *iface_ops[CVMX_HELPER_MAX_IFACE] = {
+	[0 ... CVMX_HELPER_MAX_IFACE - 1] = NULL
+};
+
 CVMX_SHARED uint64_t  cvmx_rgmii_backpressure_dis=1;
 
 typedef int (*cvmx_export_config_t)(void);
@@ -118,6 +378,17 @@ CVMX_SHARED void (*cvmx_override_pko_queue_priority) (int ipd_port, uint64_t *pr
 EXPORT_SYMBOL(cvmx_override_pko_queue_priority);
 
 /**
+ * cvmx_override_iface_phy_mode(int interface, int index) is a function pointer.
+ * It is meant to allow customization of interfaces which do not have a PHY.
+ *
+ * @returns 0 if MAC decides TX_CONFIG_REG or 1 if PHY decides  TX_CONFIG_REG.
+ *
+ * If this function pointer is NULL then it defaults to the MAC.
+ */
+CVMX_SHARED int (*cvmx_override_iface_phy_mode) (int interface, int index);
+EXPORT_SYMBOL(cvmx_override_iface_phy_mode);
+
+/**
  * cvmx_override_ipd_port_setup(int ipd_port) is a function
  * pointer. It is meant to allow customization of the IPD
  * port/port kind setup before packet input/output comes online.
@@ -155,7 +426,7 @@ int cvmx_helper_get_number_of_interfaces(void)
 	else if (OCTEON_IS_MODEL(OCTEON_CN70XX))
 		return 5;
 	else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-		return 9;
+		return 10;
 	else
 		return 3;
 }
@@ -197,46 +468,35 @@ EXPORT_SYMBOL(cvmx_helper_ports_on_interface);
  */
 static cvmx_helper_interface_mode_t __cvmx_get_mode_cn70xx(int interface)
 {
-	union cvmx_gmxx_inf_mode inf_mode;
-	static int first_time = 1;
-
-	/* Hack for SGMII interface to work on simulator. Will remove it
-	   once DLM is configured properly.
-	 */
-	if (first_time) {
-		inf_mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
-		inf_mode.s.mode = 1;
-		inf_mode.s.en = 0;
-		cvmx_write_csr(CVMX_GMXX_INF_MODE(interface), inf_mode.u64);
-		first_time = 0;
-	}
-
-	/* SGMII/XAUI/QSGMII */
+	/* SGMII/RXAUI/QSGMII */
 	if (interface < 2) {
-		inf_mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
-
-		switch(inf_mode.s.mode) {
-		case 1:	
-			return CVMX_HELPER_INTERFACE_MODE_SGMII;
-		case 2:	
-			return CVMX_HELPER_INTERFACE_MODE_QSGMII;
-		case 3:	
-			return CVMX_HELPER_INTERFACE_MODE_RXAUI;
-		default:
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-		}
+		enum cvmx_qlm_mode qlm_mode = cvmx_qlm_get_dlm_mode(0, interface);
+
+		if (qlm_mode == CVMX_QLM_MODE_SGMII)
+			iface_ops[interface] = &iface_ops_sgmii;
+		else if (qlm_mode == CVMX_QLM_MODE_QSGMII)
+			iface_ops[interface] = &iface_ops_qsgmii;
+		else if (qlm_mode == CVMX_QLM_MODE_RXAUI)
+			iface_ops[interface] = &iface_ops_rxaui;
+		else
+			iface_ops[interface] = &iface_ops_dis;
 	}
-	if (interface == 2) /* DPI */
-		return CVMX_HELPER_INTERFACE_MODE_NPI;
+	else if (interface == 2) /* DPI */
+		iface_ops[interface] = &iface_ops_npi;
 	else if (interface == 3) /* LOOP */
-		return CVMX_HELPER_INTERFACE_MODE_LOOP;
+		iface_ops[interface] = &iface_ops_loop;
 	else if (interface == 4) { /* RGMII (AGL) */
 		cvmx_agl_prtx_ctl_t prtx_ctl;
 		prtx_ctl.u64 = cvmx_read_csr(CVMX_AGL_PRTX_CTL(0));
 		if (prtx_ctl.s.mode == 0)
-			return CVMX_HELPER_INTERFACE_MODE_AGL;
+			iface_ops[interface] = &iface_ops_agl;
+		else 
+			iface_ops[interface] = &iface_ops_dis;
 	}
-	return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+	else
+		iface_ops[interface] = &iface_ops_dis;
+
+	return iface_ops[interface]->mode;
 }
 
 /**
@@ -245,27 +505,51 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn70xx(int interface)
  */
 static cvmx_helper_interface_mode_t __cvmx_get_mode_cn78xx(int interface)
 {
+	/*
+	 * Until gser configuration is in place, we hard code the interface
+	 * mode here. This means that for the time being, this function and 
+	 * cvmx_qlm_get_mode() have to be in sync since they are both hard
+	 * coded.
+	 */
 	switch (interface) {
 	case 0:
 	case 1:
+		iface_ops[interface] = &iface_ops_bgx_sgmii;
+		break;
+
 	case 2:
+		/*
+		 * Interface 2's qlm is used by ilk so it can never be
+		 * connected to a bgx mac. Disable it for now.
+		 */
+		iface_ops[interface] = &iface_ops_dis;
+		break;
+
 	case 3:
 	case 4:
-		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-
 	case 5:
-	case 6:
-		return CVMX_HELPER_INTERFACE_MODE_ILK;
+		iface_ops[interface] = &iface_ops_bgx_xaui;
+		break;
 
+	case 6:
 	case 7:
-		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		iface_ops[interface] = &iface_ops_ilk;
+		break;
 
 	case 8:
-		return CVMX_HELPER_INTERFACE_MODE_LOOP;
+		iface_ops[interface] = &iface_ops_dis;
+		break;
+
+	case 9:
+		iface_ops[interface] = &iface_ops_loop;
+		break;
 
 	default:
-		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		iface_ops[interface] = &iface_ops_dis;
+		break;
 	}
+
+	return iface_ops[interface]->mode;
 }
 
 /**
@@ -275,72 +559,87 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn78xx(int interface)
 static cvmx_helper_interface_mode_t __cvmx_get_mode_cn68xx(int interface)
 {
 	union cvmx_mio_qlmx_cfg qlm_cfg;
+
 	switch (interface) {
 	case 0:
 		qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(0));
 		/* QLM is disabled when QLM SPD is 15. */
 		if (qlm_cfg.s.qlm_spd == 15)
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-
-		if (qlm_cfg.s.qlm_cfg == 7)
-			return CVMX_HELPER_INTERFACE_MODE_RXAUI;
+			iface_ops[interface] = &iface_ops_dis;
+		else if (qlm_cfg.s.qlm_cfg == 7)
+			iface_ops[interface] = &iface_ops_rxaui;
 		else if (qlm_cfg.s.qlm_cfg == 2)
-			return CVMX_HELPER_INTERFACE_MODE_SGMII;
+			iface_ops[interface] = &iface_ops_sgmii;
 		else if (qlm_cfg.s.qlm_cfg == 3)
-			return CVMX_HELPER_INTERFACE_MODE_XAUI;
+			iface_ops[interface] = &iface_ops_xaui;
 		else
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			iface_ops[interface] = &iface_ops_dis;
+		break;
+
 	case 1:
 		qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(0));
 		/* QLM is disabled when QLM SPD is 15. */
 		if (qlm_cfg.s.qlm_spd == 15)
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-
-		if (qlm_cfg.s.qlm_cfg == 7)
-			return CVMX_HELPER_INTERFACE_MODE_RXAUI;
+			iface_ops[interface] = &iface_ops_dis;
+		else if (qlm_cfg.s.qlm_cfg == 7)
+			iface_ops[interface] = &iface_ops_rxaui;
 		else
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			iface_ops[interface] = &iface_ops_dis;
+		break;
+
 	case 2:
 	case 3:
 	case 4:
 		qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(interface));
 		/* QLM is disabled when QLM SPD is 15. */
 		if (qlm_cfg.s.qlm_spd == 15)
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-
-		if (qlm_cfg.s.qlm_cfg == 2)
-			return CVMX_HELPER_INTERFACE_MODE_SGMII;
+			iface_ops[interface] = &iface_ops_dis;
+		else if (qlm_cfg.s.qlm_cfg == 2)
+			iface_ops[interface] = &iface_ops_sgmii;
 		else if (qlm_cfg.s.qlm_cfg == 3)
-			return CVMX_HELPER_INTERFACE_MODE_XAUI;
+			iface_ops[interface] = &iface_ops_xaui;
 		else
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			iface_ops[interface] = &iface_ops_dis;
+		break;
+
 	case 5:
 	case 6:
 		qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(interface - 4));
 		/* QLM is disabled when QLM SPD is 15. */
 		if (qlm_cfg.s.qlm_spd == 15)
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-
-		if (qlm_cfg.s.qlm_cfg == 1)
-			return CVMX_HELPER_INTERFACE_MODE_ILK;
+			iface_ops[interface] = &iface_ops_dis;
+		else if (qlm_cfg.s.qlm_cfg == 1)
+			iface_ops[interface] = &iface_ops_ilk;
 		else
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			iface_ops[interface] = &iface_ops_dis;
+		break;
+
 	case 7:
 		qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(3));
 		/* QLM is disabled when QLM SPD is 15. */
 		if (qlm_cfg.s.qlm_spd == 15) {
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			iface_ops[interface] = &iface_ops_dis;
 		} else if (qlm_cfg.s.qlm_cfg != 0) {
 			qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(1));
 			if (qlm_cfg.s.qlm_cfg != 0)
-				return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+				iface_ops[interface] = &iface_ops_dis;
+			else
+				iface_ops[interface] = &iface_ops_npi;
 		}
-		return CVMX_HELPER_INTERFACE_MODE_NPI;
+		else
+			iface_ops[interface] = &iface_ops_npi;
+		break;
+
 	case 8:
-		return CVMX_HELPER_INTERFACE_MODE_LOOP;
+		iface_ops[interface] = &iface_ops_loop;
+		break;
+
 	default:
-		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		iface_ops[interface] = &iface_ops_dis;
+		break;
 	}
+
+	return iface_ops[interface]->mode;
 }
 
 /**
@@ -355,37 +654,36 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_octeon2(int interface)
 		return __cvmx_get_mode_cn68xx(interface);
 
 	if (interface == 2)
-		return CVMX_HELPER_INTERFACE_MODE_NPI;
-
-	if (interface == 3)
-		return CVMX_HELPER_INTERFACE_MODE_LOOP;
-
-	/* Only present in CN63XX & CN66XX Octeon model */
-	if ((OCTEON_IS_MODEL(OCTEON_CN63XX) &&
-	     (interface == 4 || interface == 5)) ||
-	    (OCTEON_IS_MODEL(OCTEON_CN66XX) &&
-	     interface >= 4 && interface <= 7)) {
+		iface_ops[interface] = &iface_ops_npi;
+	else if (interface == 3)
+		iface_ops[interface] = &iface_ops_loop;
+	else if ((OCTEON_IS_MODEL(OCTEON_CN63XX) &&
+		  (interface == 4 || interface == 5)) ||
+		 (OCTEON_IS_MODEL(OCTEON_CN66XX) &&
+		  interface >= 4 && interface <= 7)) {
+		/* Only present in CN63XX & CN66XX Octeon model */
 		union cvmx_sriox_status_reg sriox_status_reg;
 
 		/* cn66xx pass1.0 has only 2 SRIO interfaces. */
 		if ((interface == 5 || interface == 7) &&
 		    OCTEON_IS_MODEL(OCTEON_CN66XX_PASS1_0))
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-		/*
-		 * Later passes of cn66xx support SRIO0 - x4/x2/x1,
-		 * SRIO2 - x2/x1, SRIO3 - x1
-		 */
+			iface_ops[interface] = &iface_ops_dis;
 		else if (interface == 5 && OCTEON_IS_MODEL(OCTEON_CN66XX))
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-
-		sriox_status_reg.u64 = cvmx_read_csr(CVMX_SRIOX_STATUS_REG(interface - 4));
-		if (sriox_status_reg.s.srio)
-			return CVMX_HELPER_INTERFACE_MODE_SRIO;
-		else
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			/*
+			 * Later passes of cn66xx support SRIO0 - x4/x2/x1,
+			 * SRIO2 - x2/x1, SRIO3 - x1
+			 */
+			iface_ops[interface] = &iface_ops_dis;
+		else {
+			sriox_status_reg.u64 = 
+				cvmx_read_csr(CVMX_SRIOX_STATUS_REG(interface - 4));
+			if (sriox_status_reg.s.srio)
+				iface_ops[interface] = &iface_ops_srio;
+			else
+				iface_ops[interface] = &iface_ops_dis;
+		}
 	}
-
-	if (OCTEON_IS_MODEL(OCTEON_CN66XX)) {
+	else if (OCTEON_IS_MODEL(OCTEON_CN66XX)) {
 		union cvmx_mio_qlmx_cfg mio_qlm_cfg;
 
 		/* QLM2 is SGMII0 and QLM1 is SGMII1 */
@@ -393,71 +691,81 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_octeon2(int interface)
 			mio_qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(2));
 		else if (interface == 1)
 			mio_qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(1));
-		else
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		else {
+			iface_ops[interface] = &iface_ops_dis;
+			return iface_ops[interface]->mode;
+		}
 
 		if (mio_qlm_cfg.s.qlm_spd == 15)
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-
-		if (mio_qlm_cfg.s.qlm_cfg == 9)
-			return CVMX_HELPER_INTERFACE_MODE_SGMII;
+			iface_ops[interface] = &iface_ops_dis;
+		else if (mio_qlm_cfg.s.qlm_cfg == 9)
+			iface_ops[interface] = &iface_ops_sgmii;
 		else if (mio_qlm_cfg.s.qlm_cfg == 11)
-			return CVMX_HELPER_INTERFACE_MODE_XAUI;
+			iface_ops[interface] = &iface_ops_xaui;
 		else
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			iface_ops[interface] = &iface_ops_dis;
 	} else if (OCTEON_IS_MODEL(OCTEON_CN61XX)) {
 		union cvmx_mio_qlmx_cfg qlm_cfg;
 
-		if (interface == 0) {
+		if (interface == 0)
 			qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(2));
-			if (qlm_cfg.s.qlm_cfg == 2)
-				return CVMX_HELPER_INTERFACE_MODE_SGMII;
-			else if (qlm_cfg.s.qlm_cfg == 3)
-				return CVMX_HELPER_INTERFACE_MODE_XAUI;
-			else
-				return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-		} else if (interface == 1) {
+		else if (interface == 1)
 			qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(0));
-			if (qlm_cfg.s.qlm_cfg == 2)
-				return CVMX_HELPER_INTERFACE_MODE_SGMII;
-			else if (qlm_cfg.s.qlm_cfg == 3)
-				return CVMX_HELPER_INTERFACE_MODE_XAUI;
-			else
-				return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		else {
+			iface_ops[interface] = &iface_ops_dis;
+			return iface_ops[interface]->mode;
 		}
+
+		if (qlm_cfg.s.qlm_spd == 15)
+			iface_ops[interface] = &iface_ops_dis;
+		else if (qlm_cfg.s.qlm_cfg == 2)
+			iface_ops[interface] = &iface_ops_sgmii;
+		else if (qlm_cfg.s.qlm_cfg == 3)
+			iface_ops[interface] = &iface_ops_xaui;
+		else
+			iface_ops[interface] = &iface_ops_dis;
 	} else if (OCTEON_IS_MODEL(OCTEON_CNF71XX)) {
 		if (interface == 0) {
 			union cvmx_mio_qlmx_cfg qlm_cfg;
 			qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(0));
 			if (qlm_cfg.s.qlm_cfg == 2)
-				return CVMX_HELPER_INTERFACE_MODE_SGMII;
+				iface_ops[interface] = &iface_ops_sgmii;
+			else
+				iface_ops[interface] = &iface_ops_dis;
 		}
-		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		else
+			iface_ops[interface] = &iface_ops_dis;
 	}
+	else if (interface == 1 && OCTEON_IS_MODEL(OCTEON_CN63XX))
+		iface_ops[interface] = &iface_ops_dis;
+	else {
+		mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
 
-	if (interface == 1 && OCTEON_IS_MODEL(OCTEON_CN63XX))
-		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		if (OCTEON_IS_MODEL(OCTEON_CN63XX)) {
+			switch (mode.cn63xx.mode) {
+			case 0:
+				iface_ops[interface] = &iface_ops_sgmii;
+				break;
 
-	mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
+			case 1:
+				iface_ops[interface] = &iface_ops_xaui;
+				break;
 
-	if (OCTEON_IS_MODEL(OCTEON_CN63XX)) {
-		switch (mode.cn63xx.mode) {
-		case 0:
-			return CVMX_HELPER_INTERFACE_MODE_SGMII;
-		case 1:
-			return CVMX_HELPER_INTERFACE_MODE_XAUI;
-		default:
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			default:
+				iface_ops[interface] = &iface_ops_dis;
+				break;
+			}
+		} else {
+			if (!mode.s.en)
+				iface_ops[interface] = &iface_ops_dis;
+			else if (mode.s.type)
+				iface_ops[interface] = &iface_ops_gmii;
+			else
+				iface_ops[interface] = &iface_ops_rgmii;
 		}
-	} else {
-		if (!mode.s.en)
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-
-		if (mode.s.type)
-			return CVMX_HELPER_INTERFACE_MODE_GMII;
-		else
-			return CVMX_HELPER_INTERFACE_MODE_RGMII;
 	}
+
+	return iface_ops[interface]->mode;
 }
 
 /**
@@ -479,6 +787,14 @@ cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int interface)
 		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
 
 	/*
+	 * Check if the interface mode has been already cached. If it has,
+	 * simply return it. Otherwise, fall through the rest of the code to
+	 * determine the interface mode and cache it in iface_ops.
+	 */
+	if (iface_ops[interface] != NULL)
+		return iface_ops[interface]->mode;
+
+	/*
 	 * OCTEON III models
 	 */
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX))
@@ -497,17 +813,15 @@ cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int interface)
 	 * Octeon and Octeon Plus models
 	 */
 	if (interface == 2)
-		return CVMX_HELPER_INTERFACE_MODE_NPI;
-
-	if (interface == 3) {
+		iface_ops[interface] = &iface_ops_npi;
+	else if (interface == 3) {
 		if (OCTEON_IS_MODEL(OCTEON_CN56XX)
 		    || OCTEON_IS_MODEL(OCTEON_CN52XX))
-			return CVMX_HELPER_INTERFACE_MODE_LOOP;
+			iface_ops[interface] = &iface_ops_loop;
 		else
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			iface_ops[interface] = &iface_ops_dis;
 	}
-
-	if (interface == 0 &&
+	else if (interface == 0 &&
 	    cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_CN3005_EVB_HS5 &&
 	    cvmx_sysinfo_get()->board_rev_major == 1) {
 		/*
@@ -520,45 +834,56 @@ cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int interface)
 		 * output of this function) there is no difference in
 		 * setup between GMII and RGMII modes.
 		 */
-		return CVMX_HELPER_INTERFACE_MODE_GMII;
+		iface_ops[interface] = &iface_ops_gmii;
 	}
-
-	/* Interface 1 is always disabled on CN31XX and CN30XX */
-	if ((interface == 1)
+	else if ((interface == 1)
 	    && (OCTEON_IS_MODEL(OCTEON_CN31XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN30XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN50XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN52XX)))
-		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		/* Interface 1 is always disabled on CN31XX and CN30XX */
+		iface_ops[interface] = &iface_ops_dis;
+	else {
+		mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
 
-	mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
-
-	if (OCTEON_IS_MODEL(OCTEON_CN56XX) || OCTEON_IS_MODEL(OCTEON_CN52XX)) {
-		switch (mode.cn56xx.mode) {
-		case 0:
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-		case 1:
-			return CVMX_HELPER_INTERFACE_MODE_XAUI;
-		case 2:
-			return CVMX_HELPER_INTERFACE_MODE_SGMII;
-		case 3:
-			return CVMX_HELPER_INTERFACE_MODE_PICMG;
-		default:
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
-		}
-	} else {
-		if (!mode.s.en)
-			return CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		if (OCTEON_IS_MODEL(OCTEON_CN56XX) ||
+		    OCTEON_IS_MODEL(OCTEON_CN52XX)) {
+			switch (mode.cn56xx.mode) {
+			case 0:
+				iface_ops[interface] = &iface_ops_dis;
+				break;
 
-		if (mode.s.type) {
-			if (OCTEON_IS_MODEL(OCTEON_CN38XX) ||
-			    OCTEON_IS_MODEL(OCTEON_CN58XX))
-				return CVMX_HELPER_INTERFACE_MODE_SPI;
-			else
-				return CVMX_HELPER_INTERFACE_MODE_GMII;
-		} else
-			return CVMX_HELPER_INTERFACE_MODE_RGMII;
+			case 1:
+				iface_ops[interface] = &iface_ops_xaui;
+				break;
+
+			case 2:
+				iface_ops[interface] = &iface_ops_sgmii;
+				break;
+
+			case 3:
+				iface_ops[interface] = &iface_ops_picmg;
+				break;
+
+			default:
+				iface_ops[interface] = &iface_ops_dis;
+				break;
+			}
+		} else {
+			if (!mode.s.en)
+				iface_ops[interface] = &iface_ops_dis;
+			else if (mode.s.type) {
+				if (OCTEON_IS_MODEL(OCTEON_CN38XX) ||
+				    OCTEON_IS_MODEL(OCTEON_CN58XX))
+					iface_ops[interface] = &iface_ops_spi;
+				else
+					iface_ops[interface] = &iface_ops_gmii;
+			} else
+				iface_ops[interface] = &iface_ops_rgmii;
+		}
 	}
+
+	return iface_ops[interface]->mode;
 }
 EXPORT_SYMBOL(cvmx_helper_interface_get_mode);
 
@@ -686,56 +1011,13 @@ static int cvmx_helper_fcs_op(int interface, int nports, int has_fcs)
  */
 int cvmx_helper_interface_enumerate(int interface)
 {
-	switch (cvmx_helper_interface_get_mode(interface)) {
-		/* XAUI is a single high speed port */
-	case CVMX_HELPER_INTERFACE_MODE_XAUI:
-	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-		return __cvmx_helper_xaui_enumerate(interface);
-		/*
-		 * RGMII/GMII/MII are all treated about the same. Most
-		 * functions refer to these ports as RGMII
-		 */
-	case CVMX_HELPER_INTERFACE_MODE_RGMII:
-	case CVMX_HELPER_INTERFACE_MODE_GMII:
-		return __cvmx_helper_rgmii_enumerate(interface);
-		/*
-		 * SPI4 can have 1-16 ports depending on the device at
-		 * the other end.
-		 */
-	case CVMX_HELPER_INTERFACE_MODE_SPI:
-		return __cvmx_helper_spi_enumerate(interface);
-		/*
-		 * SGMII can have 1-4 ports depending on how many are
-		 * hooked up.
-		 */
-	case CVMX_HELPER_INTERFACE_MODE_SGMII:
-	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
-	case CVMX_HELPER_INTERFACE_MODE_PICMG:
-		return __cvmx_helper_sgmii_enumerate(interface);
-		/* PCI target Network Packet Interface */
-	case CVMX_HELPER_INTERFACE_MODE_NPI:
-		return __cvmx_helper_npi_enumerate(interface);
-		/*
-		 * Special loopback only ports. These are not the same
-		 * as other ports in loopback mode.
-		 */
-	case CVMX_HELPER_INTERFACE_MODE_LOOP:
-		return __cvmx_helper_loop_enumerate(interface);
-		/* SRIO has 2^N ports, where N is number of interfaces */
-	case CVMX_HELPER_INTERFACE_MODE_SRIO:
-		return __cvmx_helper_srio_enumerate(interface);
+	int	result = 0;
 
-	case CVMX_HELPER_INTERFACE_MODE_ILK:
-		return __cvmx_helper_ilk_enumerate(interface);
+	cvmx_helper_interface_get_mode(interface);
+	if (iface_ops[interface]->enumerate)
+		result = iface_ops[interface]->enumerate(interface);
 
-	case CVMX_HELPER_INTERFACE_MODE_AGL:
-		return __cvmx_helper_agl_enumerate(interface);
-		/* These types don't support ports to IPD/PKO */
-	case CVMX_HELPER_INTERFACE_MODE_DISABLED:
-	case CVMX_HELPER_INTERFACE_MODE_PCIE:
-	default:
-		return 0;
-	}
+	return result;
 }
 EXPORT_SYMBOL(cvmx_helper_interface_enumerate);
 
@@ -764,7 +1046,12 @@ int cvmx_helper_interface_probe(int interface)
 
 	nports = -1;
 	has_fcs = 0;
-	switch (cvmx_helper_interface_get_mode(interface)) {
+
+	cvmx_helper_interface_get_mode(interface);
+	if (iface_ops[interface]->probe)
+		nports = iface_ops[interface]->probe(interface);
+
+	switch (iface_ops[interface]->mode) {
 		/* These types don't support ports to IPD/PKO */
 	case CVMX_HELPER_INTERFACE_MODE_DISABLED:
 	case CVMX_HELPER_INTERFACE_MODE_PCIE:
@@ -773,7 +1060,6 @@ int cvmx_helper_interface_probe(int interface)
 		/* XAUI is a single high speed port */
 	case CVMX_HELPER_INTERFACE_MODE_XAUI:
 	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-		nports = __cvmx_helper_xaui_probe(interface);
 		has_fcs = 1;
 		padding = CVMX_PKO_PADDING_60;
 		break;
@@ -783,7 +1069,6 @@ int cvmx_helper_interface_probe(int interface)
 		 */
 	case CVMX_HELPER_INTERFACE_MODE_RGMII:
 	case CVMX_HELPER_INTERFACE_MODE_GMII:
-		nports = __cvmx_helper_rgmii_probe(interface);
 		padding = CVMX_PKO_PADDING_60;
 		break;
 		/*
@@ -791,7 +1076,6 @@ int cvmx_helper_interface_probe(int interface)
 		 * the other end.
 		 */
 	case CVMX_HELPER_INTERFACE_MODE_SPI:
-		nports = __cvmx_helper_spi_probe(interface);
 		padding = CVMX_PKO_PADDING_60;
 		break;
 		/*
@@ -802,31 +1086,25 @@ int cvmx_helper_interface_probe(int interface)
 	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
 		padding = CVMX_PKO_PADDING_60;
 	case CVMX_HELPER_INTERFACE_MODE_PICMG:
-		nports = __cvmx_helper_sgmii_probe(interface);
 		has_fcs = 1;
 		break;
 		/* PCI target Network Packet Interface */
 	case CVMX_HELPER_INTERFACE_MODE_NPI:
-		nports = __cvmx_helper_npi_probe(interface);
 		break;
 		/*
 		 * Special loopback only ports. These are not the same
 		 * as other ports in loopback mode.
 		 */
 	case CVMX_HELPER_INTERFACE_MODE_LOOP:
-		nports = __cvmx_helper_loop_probe(interface);
 		break;
 		/* SRIO has 2^N ports, where N is number of interfaces */
 	case CVMX_HELPER_INTERFACE_MODE_SRIO:
-		nports = __cvmx_helper_srio_probe(interface);
 		break;
 	case CVMX_HELPER_INTERFACE_MODE_ILK:
-		nports = __cvmx_helper_ilk_probe(interface);
 		padding = CVMX_PKO_PADDING_60;
 		has_fcs = 1;
 		break;
 	case CVMX_HELPER_INTERFACE_MODE_AGL:
-		nports = __cvmx_helper_agl_probe(interface);
 		has_fcs = 1;
 		break;
 	}
@@ -1190,63 +1468,18 @@ int __cvmx_helper_backpressure_is_misaligned(void)
  * aren't sent out partially setup hardware.
  *
  * @param interface Interface to enable
+ * @param iflags Interface flags
+ * @param pflags Array of flags, one per port on the interface
  *
  * @return Zero on success, negative on failure
  */
 static int __cvmx_helper_packet_hardware_enable(int interface)
 {
 	int result = 0;
-	switch (cvmx_helper_interface_get_mode(interface)) {
-		/* These types don't support ports to IPD/PKO */
-	case CVMX_HELPER_INTERFACE_MODE_DISABLED:
-	case CVMX_HELPER_INTERFACE_MODE_PCIE:
-	case CVMX_HELPER_INTERFACE_MODE_LOOP:
-		/* Nothing to do */
-		break;
-		/* XAUI is a single high speed port */
-	case CVMX_HELPER_INTERFACE_MODE_XAUI:
-	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-		result = __cvmx_helper_xaui_enable(interface);
-		break;
-		/*
-		 * RGMII/GMII/MII are all treated about the same. Most
-		 * functions refer to these ports as RGMII.
-		 */
-	case CVMX_HELPER_INTERFACE_MODE_RGMII:
-	case CVMX_HELPER_INTERFACE_MODE_GMII:
-		result = __cvmx_helper_rgmii_enable(interface);
-		break;
-		/*
-		 * SPI4 can have 1-16 ports depending on the device at
-		 * the other end.
-		 */
-	case CVMX_HELPER_INTERFACE_MODE_SPI:
-		result = __cvmx_helper_spi_enable(interface);
-		break;
-		/*
-		 * SGMII can have 1-4 ports depending on how many are
-		 * hooked up.
-		 */
-	case CVMX_HELPER_INTERFACE_MODE_SGMII:
-	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
-	case CVMX_HELPER_INTERFACE_MODE_PICMG:
-		result = __cvmx_helper_sgmii_enable(interface);
-		break;
-		/* PCI target Network Packet Interface */
-	case CVMX_HELPER_INTERFACE_MODE_NPI:
-		result = __cvmx_helper_npi_enable(interface);
-		break;
-		/* SRIO has 2^N ports, where N is number of interfaces */
-	case CVMX_HELPER_INTERFACE_MODE_SRIO:
-		result = __cvmx_helper_srio_enable(interface);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_ILK:
-		result = __cvmx_helper_ilk_enable(interface);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_AGL:
-		result = __cvmx_helper_agl_enable(interface);
-		break;
-	}
+
+	cvmx_helper_interface_get_mode(interface);
+	if (iface_ops[interface]->enable)
+		result = iface_ops[interface]->enable(interface);
 	result |= __cvmx_helper_board_hardware_enable(interface);
 	return result;
 }
@@ -1261,6 +1494,7 @@ int cvmx_helper_ipd_and_packet_input_enable(void)
 {
 	int num_interfaces;
 	int interface;
+	int num_ports;
 
 	/* Enable IPD */
 	cvmx_ipd_enable();
@@ -1272,7 +1506,8 @@ int cvmx_helper_ipd_and_packet_input_enable(void)
 	 */
 	num_interfaces = cvmx_helper_get_number_of_interfaces();
 	for (interface = 0; interface < num_interfaces; interface++) {
-		if (cvmx_helper_ports_on_interface(interface) > 0)
+		num_ports = cvmx_helper_ports_on_interface(interface);
+		if (num_ports > 0)
 			__cvmx_helper_packet_hardware_enable(interface);
 	}
 
@@ -1304,10 +1539,10 @@ int cvmx_initialize_sso_78xx(void)
 	cvmx_sso_nw_tim_t nw_tim;
 	cvmx_sso_aw_cfg_t aw_cfg;
 
-	cvmx_fpa_pool_stack_init(node, SSO_POOL_NUM, 0, MAX_SSO_ENTRIES,
-				 FPA_NATURAL_ALIGNMENT, 4096);
+	cvmx_fpa_pool_stack_init(node, SSO_POOL_NUM, "SSO Pool", 0,
+			MAX_SSO_ENTRIES, FPA_NATURAL_ALIGNMENT, 4096);
 	cvmx_fpa_assign_aura(node, SSO_AURA_NUM, SSO_POOL_NUM);
-	cvmx_fpa_aura_init(node, aura, 0, num_blocks, 0);
+	cvmx_fpa_aura_init(node, aura, "SSO Aura", 0, num_blocks, 0);
 
 	/* Initialize the 256 group/qos queues */
 	for (grp=0; grp<256; grp++)
@@ -1439,7 +1674,6 @@ int cvmx_helper_uninitialize_sso(void)
 	cvmx_sso_rwq_psh_fptr_t fptr;
 	cvmx_sso_fpage_cnt_t fpage_cnt;
 	int num_to_transfer, i;
-	char *mem;
 
 	if (!OCTEON_IS_MODEL(OCTEON_CN68XX))
 		return 0;
@@ -1485,7 +1719,7 @@ int cvmx_helper_uninitialize_sso(void)
 			cvmx_dprintf("head_ptr.s.ptr != tail_ptr.s.ptr, idx: %d\n", i);
 		}
 
-		mem = cvmx_phys_to_ptr(((uint64_t) head_ptr.s.ptr) << 7);
+		cvmx_phys_to_ptr(((uint64_t) head_ptr.s.ptr) << 7);
 		/* Leak the memory */
 	}
 
@@ -1493,7 +1727,7 @@ int cvmx_helper_uninitialize_sso(void)
 		do {
 			pop_fptr.u64 = cvmx_read_csr(CVMX_SSO_RWQ_POP_FPTR);
 			if (pop_fptr.s.val) {
-				mem = cvmx_phys_to_ptr(((uint64_t) pop_fptr.s.fptr) << 7);
+				cvmx_phys_to_ptr(((uint64_t) pop_fptr.s.fptr) << 7);
 				/* Leak the memory */
 			}
 		} while (pop_fptr.s.val);
@@ -2195,49 +2429,10 @@ cvmx_helper_link_info_t cvmx_helper_link_get(int ipd_port)
 	    index >= cvmx_helper_ports_on_interface(interface))
 		return result;
 
-	switch (cvmx_helper_interface_get_mode(interface)) {
-	case CVMX_HELPER_INTERFACE_MODE_DISABLED:
-	case CVMX_HELPER_INTERFACE_MODE_PCIE:
-		/* Network links are not supported */
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_XAUI:
-	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-		result = __cvmx_helper_xaui_link_get(ipd_port);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_GMII:
-		if (index == 0)
-			result = __cvmx_helper_rgmii_link_get(ipd_port);
-		else {
-			result.s.full_duplex = 1;
-			result.s.link_up = 1;
-			result.s.speed = 1000;
-		}
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_RGMII:
-		result = __cvmx_helper_rgmii_link_get(ipd_port);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_SPI:
-		result = __cvmx_helper_spi_link_get(ipd_port);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_SGMII:
-	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
-	case CVMX_HELPER_INTERFACE_MODE_PICMG:
-		result = __cvmx_helper_sgmii_link_get(ipd_port);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_SRIO:
-		result = __cvmx_helper_srio_link_get(ipd_port);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_ILK:
-		result = __cvmx_helper_ilk_link_get(ipd_port);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_AGL:
-		result = __cvmx_helper_agl_link_get(ipd_port);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_NPI:
-	case CVMX_HELPER_INTERFACE_MODE_LOOP:
-		/* Network links are not supported */
-		break;
-	}
+	cvmx_helper_interface_get_mode(interface);
+	if (iface_ops[interface]->link_get)
+		result = iface_ops[interface]->link_get(ipd_port);
+
 	return result;
 }
 EXPORT_SYMBOL(cvmx_helper_link_get);
@@ -2264,43 +2459,10 @@ int cvmx_helper_link_set(int ipd_port, cvmx_helper_link_info_t link_info)
 	    index >= cvmx_helper_ports_on_interface(interface))
 		return -1;
 
-	switch (cvmx_helper_interface_get_mode(interface)) {
-	case CVMX_HELPER_INTERFACE_MODE_DISABLED:
-	case CVMX_HELPER_INTERFACE_MODE_PCIE:
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_XAUI:
-	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-		result = __cvmx_helper_xaui_link_set(ipd_port, link_info);
-		break;
-		/*
-		 * RGMII/GMII/MII are all treated about the same. Most
-		 * functions refer to these ports as RGMII.
-		 */
-	case CVMX_HELPER_INTERFACE_MODE_RGMII:
-	case CVMX_HELPER_INTERFACE_MODE_GMII:
-		result = __cvmx_helper_rgmii_link_set(ipd_port, link_info);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_SPI:
-		result = __cvmx_helper_spi_link_set(ipd_port, link_info);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_SGMII:
-	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
-	case CVMX_HELPER_INTERFACE_MODE_PICMG:
-		result = __cvmx_helper_sgmii_link_set(ipd_port, link_info);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_SRIO:
-		result = __cvmx_helper_srio_link_set(ipd_port, link_info);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_ILK:
-		result = __cvmx_helper_ilk_link_set(ipd_port, link_info);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_AGL:
-		result = __cvmx_helper_agl_link_set(ipd_port, link_info);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_NPI:
-	case CVMX_HELPER_INTERFACE_MODE_LOOP:
-		break;
-	}
+	cvmx_helper_interface_get_mode(interface);
+	if (iface_ops[interface]->link_set)
+		result = iface_ops[interface]->link_set(ipd_port, link_info);
+
 	/*
 	 * Set the port_link_info here so that the link status is
 	 * updated no matter how cvmx_helper_link_set is called. We
@@ -2335,36 +2497,12 @@ int cvmx_helper_configure_loopback(int ipd_port, int enable_internal,
 	if (index >= cvmx_helper_ports_on_interface(interface))
 		return -1;
 
-	switch (cvmx_helper_interface_get_mode(interface)) {
-	case CVMX_HELPER_INTERFACE_MODE_DISABLED:
-	case CVMX_HELPER_INTERFACE_MODE_PCIE:
-	case CVMX_HELPER_INTERFACE_MODE_SRIO:
-	case CVMX_HELPER_INTERFACE_MODE_ILK:
-	case CVMX_HELPER_INTERFACE_MODE_SPI:
-	case CVMX_HELPER_INTERFACE_MODE_NPI:
-	case CVMX_HELPER_INTERFACE_MODE_LOOP:
-	case CVMX_HELPER_INTERFACE_MODE_AGL:
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_XAUI:
-	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-		result = __cvmx_helper_xaui_configure_loopback(ipd_port,
-							       enable_internal,
-							       enable_external);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_RGMII:
-	case CVMX_HELPER_INTERFACE_MODE_GMII:
-		result = __cvmx_helper_rgmii_configure_loopback(ipd_port,
-								enable_internal,
-								enable_external);
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_SGMII:
-	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
-	case CVMX_HELPER_INTERFACE_MODE_PICMG:
-		result = __cvmx_helper_sgmii_configure_loopback(ipd_port,
-								enable_internal,
-								enable_external);
-		break;
-	}
+	cvmx_helper_interface_get_mode(interface);
+	if (iface_ops[interface]->loopback)
+		result = iface_ops[interface]->loopback(ipd_port,
+							enable_internal,
+							enable_external);
+
 	return result;
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
index 7f9348c..e924068 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
@@ -54,6 +54,7 @@
 #include <asm/octeon/cvmx-ilk-defs.h>
 #include <asm/octeon/cvmx-helper-util.h>
 #include <asm/octeon/cvmx-helper-ilk.h>
+#include <asm/octeon/cvmx-gserx-defs.h>
 #include <asm/octeon/cvmx-pip-defs.h>
 #else
 #include "cvmx.h"
@@ -91,7 +92,7 @@ CVMX_SHARED cvmx_ilk_LA_mode_t cvmx_ilk_LA_mode[CVMX_NUM_ILK_INTF] = {{0, 0},
 
 void cvmx_ilk_config_set_LA_mode(int interface, int mode)
 {
-	if(interface > CVMX_NUM_ILK_INTF || interface < 0)
+	if(interface >= CVMX_NUM_ILK_INTF || interface < 0)
 		cvmx_dprintf("ERROR: Invalid interface=%d in cvmx_ilk_config_set_LA_mode\n",
 			     interface);
 	else
@@ -100,7 +101,7 @@ void cvmx_ilk_config_set_LA_mode(int interface, int mode)
 
 void cvmx_ilk_config_set_LA_mode_cal(int interface, int mode)
 {
-	if(interface > CVMX_NUM_ILK_INTF || interface < 0)
+	if(interface >= CVMX_NUM_ILK_INTF || interface < 0)
 		cvmx_dprintf("ERROR: Invalid interface=%d in cvmx_ilk_config_set_LA_mode_cal\n",
 			     interface);
 	else
@@ -109,7 +110,7 @@ void cvmx_ilk_config_set_LA_mode_cal(int interface, int mode)
 
 void cvmx_ilk_config_set_lane_mask(int interface, unsigned char mask)
 {
-	if(interface > CVMX_NUM_ILK_INTF || interface < 0)
+	if(interface >= CVMX_NUM_ILK_INTF || interface < 0)
 		cvmx_dprintf("ERROR: Invalid interface=%d in cvmx_ilk_set_lane_mask\n",
 			     interface);
 	else
@@ -118,7 +119,7 @@ void cvmx_ilk_config_set_lane_mask(int interface, unsigned char mask)
 
 void cvmx_ilk_config_set_max_channels(int interface, unsigned char channels)
 {
-	if(interface > CVMX_NUM_ILK_INTF || interface < 0) {
+	if(interface >= CVMX_NUM_ILK_INTF || interface < 0) {
 		cvmx_dprintf("ERROR: Invalid interface=%d in cvmx_ilk_config_set_max_channels\n",
 			     interface);
 		return;
@@ -249,8 +250,11 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 		}
 	}
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		uint8_t qlm, i;
-		cvmx_mio_qlmx_cfg_t mio_qlmx_cfg[4];
+		uint8_t 		qlm, i;
+		cvmx_mio_qlmx_cfg_t 	mio_qlmx_cfg[4];
+		cvmx_gserx_cfg_t	cvmx_gserx_cfg;
+		cvmx_gserx_phy_ctl_t	cvmx_gserx_phy_ctl;
+
 		for (i = 0, qlm = CVMX_ILK_QLM_BASE(); i < 4; i++, qlm++)
 			mio_qlmx_cfg[i].u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(qlm));
 
@@ -279,6 +283,25 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 				return res;
 			} 
 		}
+
+		/*
+		 * Configure the GSER.
+		 * For now, we configured the minimum needed to work with the
+		 * simulator. TODO
+		 */
+		qlm = CVMX_ILK_QLM_BASE() + interface;
+		cvmx_gserx_phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
+		cvmx_gserx_phy_ctl.s.phy_pd = 0;
+		cvmx_gserx_phy_ctl.s.phy_reset = 1;
+		cvmx_write_csr(CVMX_GSERX_PHY_CTL(qlm), cvmx_gserx_phy_ctl.u64);
+
+		cvmx_gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
+		cvmx_gserx_cfg.s.ila = 1;
+		cvmx_write_csr(CVMX_GSERX_CFG(qlm), cvmx_gserx_cfg.u64);
+
+		cvmx_gserx_phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
+		cvmx_gserx_phy_ctl.s.phy_reset = 0;
+		cvmx_write_csr(CVMX_GSERX_PHY_CTL(qlm), cvmx_gserx_phy_ctl.u64);
 	}
 
 	/* power up the serdes */
@@ -339,6 +362,9 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 		}
 	}
 
+	/* Initialize all calendar entries to xoff state */
+	__cvmx_ilk_init_cal(interface);
+
 	/* Enable ILK LA mode if configured. */
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		if (cvmx_ilk_use_la_mode(interface, 0)) {
@@ -532,12 +558,9 @@ int cvmx_ilk_rx_set_pknd(int interface, cvmx_ilk_chan_pknd_t * chpknd, unsigned
  */
 int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent)
 {
-	int res = -1, num_grp, num_rest, i, j;
+	int res = -1, i;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
-	cvmx_ilk_rxx_idx_cal_t ilk_rxx_idx_cal;
-	cvmx_ilk_rxx_mem_cal0_t ilk_rxx_mem_cal0;
-	cvmx_ilk_rxx_mem_cal1_t ilk_rxx_mem_cal1;
-	unsigned long int tmp;
+	int num_entries;
 
 	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
 	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
@@ -557,132 +580,29 @@ int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 			pent->ent_ctrl = LINK;
 #endif
 
-	/* set the depth */
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+		/* Update the calendar for each channel */
+		if ((cvmx_ilk_use_la_mode(interface, 0) == 0) ||
+		    (cvmx_ilk_use_la_mode(interface, 0) && 
+		     cvmx_ilk_la_mode_enable_rx_calendar(interface))) {
+			for (i = 0; i < cal_depth; i++) {
+				__cvmx_ilk_write_rx_cal_entry(interface, i,
+							     pent[i].pipe_bpid);
+			}
+		}
+
+		/* Update the depth */
 		ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+		num_entries = 1 + cal_depth + (cal_depth - 1) / 15;
+		ilk_rxx_cfg0.s.cal_depth = num_entries;
 		if (cvmx_ilk_use_la_mode(interface, 0)) {
 			ilk_rxx_cfg0.s.mproto_ign = 1;
 			ilk_rxx_cfg0.s.lnk_stats_ena = 1;
 			ilk_rxx_cfg0.s.lnk_stats_wrap = 1;
-			if (cvmx_ilk_la_mode_enable_rx_calendar(interface)) {
-				ilk_rxx_cfg0.s.cal_depth = cvmx_ilk_use_la_mode(interface, 1) ? 2 : 1;
-				ilk_rxx_cfg0.s.cal_ena = 1;
-			} else {
-				ilk_rxx_cfg0.s.cal_depth = 0;
-				ilk_rxx_cfg0.s.cal_ena = 0;
-			}
-		} else
-			ilk_rxx_cfg0.s.cal_depth = cal_depth;
-	
-		cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
-	
-		/* set the calendar index */
-		num_grp = cal_depth / CVMX_ILK_CAL_GRP_SZ;
-		num_rest = cal_depth % CVMX_ILK_CAL_GRP_SZ;
-		ilk_rxx_idx_cal.u64 = 0;
-		ilk_rxx_idx_cal.s.inc = 1;
-		cvmx_write_csr(CVMX_ILK_RXX_IDX_CAL(interface), ilk_rxx_idx_cal.u64);
-	
-		/* Note that calendar support is somewhat broken through pass 2.0 */
-		if (cvmx_ilk_use_la_mode(interface, 0)) {
-			ilk_rxx_mem_cal0.u64 = 0;
-			ilk_rxx_mem_cal1.u64 = 0;
-	
-			if (cvmx_ilk_la_mode_enable_rx_calendar(interface)) {
-				ilk_rxx_mem_cal0.s.entry_ctl0 = pent->ent_ctrl;
-				ilk_rxx_mem_cal0.s.port_pipe0 = pent->pipe_bpid;
-				pent++;
-	
-				if (cvmx_ilk_use_la_mode(interface, 1)) {
-					ilk_rxx_mem_cal0.s.entry_ctl1 = pent->ent_ctrl;
-					ilk_rxx_mem_cal0.s.port_pipe1 = pent->pipe_bpid;
-				} else
-					ilk_rxx_mem_cal0.s.entry_ctl1 = XOFF;
-				pent++;
-	
-				ilk_rxx_mem_cal0.s.entry_ctl2 = XOFF;
-				ilk_rxx_mem_cal0.s.entry_ctl3 = XOFF;
-				ilk_rxx_mem_cal1.s.entry_ctl4 = XOFF;
-				ilk_rxx_mem_cal1.s.entry_ctl5 = XOFF;
-				ilk_rxx_mem_cal1.s.entry_ctl6 = XOFF;
-				ilk_rxx_mem_cal1.s.entry_ctl7 = XOFF;
-			}
-			cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL0(interface), ilk_rxx_mem_cal0.u64);
-			cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL1(interface), ilk_rxx_mem_cal1.u64);
-			cvmx_read_csr(CVMX_ILK_RXX_MEM_CAL1(interface));
-			ilk_rxx_idx_cal.u64 = cvmx_read_csr(CVMX_ILK_RXX_IDX_CAL(interface));
-	
-			return 0;
 		}
-	
-		/* set the calendar entries. each group has both cal0 and cal1 registers */
-		for (i = 0; i < num_grp; i++) {
-			ilk_rxx_mem_cal0.u64 = 0;
-			for (j = 0; j < CVMX_ILK_CAL_GRP_SZ / 2; j++) {
-				tmp = 0;
-				tmp = pent->pipe_bpid & ~(~tmp << CVMX_ILK_PIPE_BPID_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * j;
-				ilk_rxx_mem_cal0.u64 |= tmp;
-	
-				tmp = 0;
-				tmp = pent->ent_ctrl & ~(~tmp << CVMX_ILK_ENT_CTRL_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * j + CVMX_ILK_PIPE_BPID_SZ;
-				ilk_rxx_mem_cal0.u64 |= tmp;
-				pent++;
-			}
-			cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL0(interface), ilk_rxx_mem_cal0.u64);
-	
-			ilk_rxx_mem_cal1.u64 = 0;
-			for (j = 0; j < CVMX_ILK_CAL_GRP_SZ / 2; j++) {
-				tmp = 0;
-				tmp = pent->pipe_bpid & ~(~tmp << CVMX_ILK_PIPE_BPID_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * j;
-				ilk_rxx_mem_cal1.u64 |= tmp;
-	
-				tmp = 0;
-				tmp = pent->ent_ctrl & ~(~tmp << CVMX_ILK_ENT_CTRL_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * j + CVMX_ILK_PIPE_BPID_SZ;
-				ilk_rxx_mem_cal1.u64 |= tmp;
-				pent++;
-			}
-			cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL1(interface), ilk_rxx_mem_cal1.u64);
-		}
-	
-		/* set the calendar entries, the fraction of a group. but both cal0 and
-		 * cal1 must be written */
-		ilk_rxx_mem_cal0.u64 = 0;
-		ilk_rxx_mem_cal1.u64 = 0;
-		for (i = 0; i < num_rest; i++) {
-			if (i < CVMX_ILK_CAL_GRP_SZ / 2) {
-				tmp = 0;
-				tmp = pent->pipe_bpid & ~(~tmp << CVMX_ILK_PIPE_BPID_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * i;
-				ilk_rxx_mem_cal0.u64 |= tmp;
-	
-				tmp = 0;
-				tmp = pent->ent_ctrl & ~(~tmp << CVMX_ILK_ENT_CTRL_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * i + CVMX_ILK_PIPE_BPID_SZ;
-				ilk_rxx_mem_cal0.u64 |= tmp;
-				pent++;
-			}
-	
-			if (i >= CVMX_ILK_CAL_GRP_SZ / 2) {
-				tmp = 0;
-				tmp = pent->pipe_bpid & ~(~tmp << CVMX_ILK_PIPE_BPID_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * (i - CVMX_ILK_CAL_GRP_SZ / 2);
-				ilk_rxx_mem_cal1.u64 |= tmp;
-	
-				tmp = 0;
-				tmp = pent->ent_ctrl & ~(~tmp << CVMX_ILK_ENT_CTRL_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * (i - CVMX_ILK_CAL_GRP_SZ / 2) + CVMX_ILK_PIPE_BPID_SZ;
-				ilk_rxx_mem_cal1.u64 |= tmp;
-				pent++;
-			}
-		}
-		cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL0(interface), ilk_rxx_mem_cal0.u64);
-		cvmx_write_csr(CVMX_ILK_RXX_MEM_CAL1(interface), ilk_rxx_mem_cal1.u64);
-		cvmx_read_csr(CVMX_ILK_RXX_MEM_CAL1(interface));
+		cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 	}
+
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		cvmx_ilk_rxx_cal_entryx_t rxx_cal_entryx;
 
@@ -827,13 +747,9 @@ EXPORT_SYMBOL(cvmx_ilk_cal_setup_rx);
  */
 int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent)
 {
-	int res = -1, num_grp, num_rest, i, j;
+	int res = -1, i;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
-	cvmx_ilk_txx_idx_cal_t ilk_txx_idx_cal;
-	cvmx_ilk_txx_mem_cal0_t ilk_txx_mem_cal0;
-	cvmx_ilk_txx_mem_cal1_t ilk_txx_mem_cal1;
-	unsigned long int tmp;
-	cvmx_ilk_cal_entry_t *ent_tmp;
+	int num_entries;
 
 	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
 	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
@@ -854,100 +770,19 @@ int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 #endif
 
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
-		if (cvmx_ilk_use_la_mode(interface, 0)) {
-			ilk_txx_idx_cal.u64 = cvmx_read_csr(CVMX_ILK_TXX_IDX_CAL(interface));
-			ilk_txx_idx_cal.s.inc = 1;
-			ilk_txx_idx_cal.s.index = 0;	/* channel */
-			cvmx_write_csr(CVMX_ILK_TXX_IDX_CAL(interface), ilk_txx_idx_cal.u64);
-	
-			ilk_txx_mem_cal0.u64 = 0;
-			ilk_txx_mem_cal1.u64 = 0;
-			ilk_txx_mem_cal0.s.entry_ctl0 = pent->ent_ctrl;
-			ilk_txx_mem_cal0.s.bpid0 = pent->pipe_bpid;
-	
-			pent++;
-			if (cvmx_ilk_use_la_mode(interface, 1)) {
-				ilk_txx_mem_cal0.s.entry_ctl1 = pent->ent_ctrl;
-				ilk_txx_mem_cal0.s.bpid1 = pent->pipe_bpid;
-			} else {
-				ilk_txx_mem_cal0.s.entry_ctl1 = XOFF;
-			}
-			pent++;
-			ilk_txx_mem_cal0.s.entry_ctl2 = XOFF;
-			ilk_txx_mem_cal0.s.entry_ctl3 = XOFF;
-			ilk_txx_mem_cal1.s.entry_ctl4 = XOFF;
-			ilk_txx_mem_cal1.s.entry_ctl5 = XOFF;
-			ilk_txx_mem_cal1.s.entry_ctl6 = XOFF;
-			ilk_txx_mem_cal1.s.entry_ctl7 = XOFF;
-	
-			cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL0(interface), ilk_txx_mem_cal0.u64);
-			cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL1(interface), ilk_txx_mem_cal1.u64);
-			cvmx_read_csr(CVMX_ILK_TXX_MEM_CAL1(interface));
-	
-			ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
-			ilk_txx_cfg0.s.cal_depth = 8;
-			ilk_txx_cfg0.s.lnk_stats_ena = 1;
-			cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
-	
-			return 0;
-		}
-	
-		/* tx calendar depth must be a multiple of 8 */
-		num_grp = (cal_depth - 1) / CVMX_ILK_CAL_GRP_SZ + 1;
-		num_rest = cal_depth % CVMX_ILK_CAL_GRP_SZ;
-		if (num_rest != 0) {
-			ent_tmp = pent + cal_depth;
-			for (i = num_rest; i < 8; i++, ent_tmp++) {
-				ent_tmp->pipe_bpid = 0;
-				ent_tmp->ent_ctrl = XOFF;
-			}
+		/* Update the calendar for each channel */
+		for (i = 0; i < cal_depth; i++) {
+			__cvmx_ilk_write_tx_cal_entry(interface, i,
+						      pent[i].pipe_bpid);
 		}
-		cal_depth = num_grp * 8;
-	
-		/* set the depth */
+
+		/* Set the depth (must be multiple of 8)*/
 		ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
-		ilk_txx_cfg0.s.cal_depth = cal_depth;
+		num_entries = 1 + cal_depth + (cal_depth - 1) / 15;
+		ilk_txx_cfg0.s.cal_depth = (num_entries + 7) & ~7;
 		cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
-	
-		/* set the calendar index */
-		ilk_txx_idx_cal.u64 = 0;
-		ilk_txx_idx_cal.s.inc = 1;
-		cvmx_write_csr(CVMX_ILK_TXX_IDX_CAL(interface), ilk_txx_idx_cal.u64);
-	
-		/* set the calendar entries. each group has both cal0 and cal1 registers */
-		for (i = 0; i < num_grp; i++) {
-			ilk_txx_mem_cal0.u64 = 0;
-			for (j = 0; j < CVMX_ILK_CAL_GRP_SZ / 2; j++) {
-				tmp = 0;
-				tmp = pent->pipe_bpid & ~(~tmp << CVMX_ILK_PIPE_BPID_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * j;
-				ilk_txx_mem_cal0.u64 |= tmp;
-	
-				tmp = 0;
-				tmp = pent->ent_ctrl & ~(~tmp << CVMX_ILK_ENT_CTRL_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * j + CVMX_ILK_PIPE_BPID_SZ;
-				ilk_txx_mem_cal0.u64 |= tmp;
-				pent++;
-			}
-			cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL0(interface), ilk_txx_mem_cal0.u64);
-	
-			ilk_txx_mem_cal1.u64 = 0;
-			for (j = 0; j < CVMX_ILK_CAL_GRP_SZ / 2; j++) {
-				tmp = 0;
-				tmp = pent->pipe_bpid & ~(~tmp << CVMX_ILK_PIPE_BPID_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * j;
-				ilk_txx_mem_cal1.u64 |= tmp;
-	
-				tmp = 0;
-				tmp = pent->ent_ctrl & ~(~tmp << CVMX_ILK_ENT_CTRL_SZ);
-				tmp <<= (CVMX_ILK_PIPE_BPID_SZ + CVMX_ILK_ENT_CTRL_SZ) * j + CVMX_ILK_PIPE_BPID_SZ;
-				ilk_txx_mem_cal1.u64 |= tmp;
-				pent++;
-			}
-			cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL1(interface), ilk_txx_mem_cal1.u64);
-		}
-		cvmx_read_csr(CVMX_ILK_TXX_MEM_CAL1(interface));
 	}
+
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		cvmx_ilk_txx_cal_entryx_t txx_cal_entryx;
 
@@ -969,49 +804,6 @@ int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 }
 
 /**
- * configure backpressure for tx
- *
- * @param interface The identifier of the packet interface to configure and
- *                  use as a ILK interface. cn68xx has 2 interfaces: ilk0 and
- *                  ilk1.
- *
- * @param cal_depth the number of calendar entries
- * @param pent      pointer to calendar entries
- *
- * @return Zero on success, negative on failure.
- */
-int cvmx_ilk_bp_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent)
-{
-	int res = -1, i;
-	cvmx_ipd_ctl_status_t ipd_ctl_status;
-	cvmx_ilk_cal_entry_t *tmp;
-	unsigned char bpid;
-	cvmx_ipd_bpidx_mbuf_th_t ipd_bpidx_mbuf_th;
-
-	/* enable bp for the interface */
-	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
-		ipd_ctl_status.u64 = cvmx_read_csr(CVMX_IPD_CTL_STATUS);
-		ipd_ctl_status.s.pbp_en = 1;
-		cvmx_write_csr(CVMX_IPD_CTL_STATUS, ipd_ctl_status.u64);
-	
-		/* enable bp for each id */
-		for (i = 0, tmp = pent; i < cal_depth; i++, tmp++) {
-			bpid = tmp->pipe_bpid;
-			ipd_bpidx_mbuf_th.u64 = cvmx_read_csr(CVMX_IPD_BPIDX_MBUF_TH(bpid));
-			ipd_bpidx_mbuf_th.s.page_cnt = 1;	/* 256 buffers */
-			ipd_bpidx_mbuf_th.s.bp_enb = 1;
-			cvmx_write_csr(CVMX_IPD_BPIDX_MBUF_TH(bpid), ipd_bpidx_mbuf_th.u64);
-		}
-		res = 0;
-	}
-	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		/* TODO: need to add this one */
-	}
-
-	return res;
-}
-
-/**
  * enable calendar for tx
  *
  * @param interface The identifier of the packet interface to configure and
@@ -1072,18 +864,13 @@ int cvmx_ilk_cal_setup_tx(int interface, int cal_depth, cvmx_ilk_cal_entry_t * p
 	if (res < 0)
 		return res;
 
-#ifdef CVMX_ILK_BP_CONF_ENA
-	res = cvmx_ilk_bp_conf(interface, cal_depth, pent);
-	if (res < 0)
-		return res;
-#endif
-
 	res = cvmx_ilk_tx_cal_ena(interface, cal_ena);
 	return res;
 }
 
 EXPORT_SYMBOL(cvmx_ilk_cal_setup_tx);
 
+//#define CVMX_ILK_STATS_ENA 1
 #ifdef CVMX_ILK_STATS_ENA
 static void cvmx_ilk_reg_dump_rx(int interface)
 {
@@ -1149,7 +936,7 @@ static void cvmx_ilk_reg_dump_rx(int interface)
 
 		for (i = 0; i < CHAN_NUM_DBG; i++) {
 			rxx_chax.u64 = cvmx_read_csr(CVMX_ILK_RXX_CHAX(i, interface));
-			cvmx_dprintf("ilk chan: %d  pki chan: 0x%x\n", i, rxx_chax.port_kind);
+			cvmx_dprintf("ilk chan: %d  pki chan: 0x%x\n", i, rxx_chax.s.port_kind);
 		}
 	}
 
@@ -1330,7 +1117,6 @@ void cvmx_ilk_runtime_status(int interface)
  *
  * @return Zero on success, negative on failure.
  */
-//#define CVMX_ILK_STATS_ENA 1
 int cvmx_ilk_enable(int interface)
 {
 	int res = -1;
@@ -1370,7 +1156,6 @@ int cvmx_ilk_enable(int interface)
 			ilk_txx_cfg1.s.tx_link_fc_jam = 1;
 		}
 	}
-	ilk_txx_cfg1.s.rx_link_fc_ign = 1;	/* cannot use link fc workaround */
 	cvmx_write_csr(CVMX_ILK_TXX_CFG1(interface), ilk_txx_cfg1.u64);
 	cvmx_read_csr(CVMX_ILK_TXX_CFG1(interface));
 
@@ -1434,7 +1219,7 @@ int cvmx_ilk_disable(int interface)
 #endif
 
 	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN68XX)))
+	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -1652,7 +1437,9 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 				rxx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_PKT_CNTX(*pstats->chan_list, interface));
 				rxx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_BYTE_CNTX(*pstats->chan_list, interface));
 				cvmx_dprintf("ILK%d Channel%d Rx: %llu packets %llu bytes\n", interface,
-					     *pstats->chan_list, (uint64_t)rxx_pkt_cntx.s.rx_pkt, (uint64_t)rxx_byte_cntx.s.rx_bytes);
+					     *pstats->chan_list, 
+					     (unsigned long long)rxx_pkt_cntx.s.rx_pkt,
+					     (unsigned long long)rxx_byte_cntx.s.rx_bytes);
 			}
 
 			if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
@@ -1680,7 +1467,9 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 				txx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_PKT_CNTX(*pstats->chan_list, interface));
 				txx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_BYTE_CNTX(*pstats->chan_list, interface));
 				cvmx_dprintf("ILK%d Channel%d Tx: %llu packets %llu bytes\n", interface,
-					     *pstats->chan_list, (uint64_t)txx_pkt_cntx.s.tx_pkt, (uint64_t)txx_byte_cntx.s.tx_bytes);
+					     *pstats->chan_list,
+					     (unsigned long long)txx_pkt_cntx.s.tx_pkt,
+					     (unsigned long long)txx_byte_cntx.s.tx_bytes);
 			}
 
 			pstats++;
@@ -1734,12 +1523,14 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 			rxx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_PKT_CNTX(i, interface));
 			rxx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_BYTE_CNTX(i, interface));
 			cvmx_dprintf("ILK%d Channel%d Rx: %llu packets %llu bytes\n", interface,
-				     i, (uint64_t)rxx_pkt_cntx.s.rx_pkt, (uint64_t)rxx_byte_cntx.s.rx_bytes);
+				     i, (unsigned long long)rxx_pkt_cntx.s.rx_pkt,
+				     (unsigned long long)rxx_byte_cntx.s.rx_bytes);
 
 			txx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_PKT_CNTX(i, interface));
 			txx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_BYTE_CNTX(i, interface));
 			cvmx_dprintf("ILK%d Channel%d Tx: %llu packets %llu bytes\n", interface,
-				     i, (uint64_t)txx_pkt_cntx.s.tx_pkt, (uint64_t)txx_byte_cntx.s.tx_bytes);
+				     i, (unsigned long long)txx_pkt_cntx.s.tx_pkt,
+				     (unsigned long long)txx_byte_cntx.s.tx_bytes);
 		}
 	}
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-l2c.c b/arch/mips/cavium-octeon/executive/cvmx-l2c.c
index 5b496de..9c4706d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-l2c.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-l2c.c
@@ -43,7 +43,7 @@
  * Implementation of the Level 2 Cache (L2C) control,
  * measurement, and debugging facilities.
  *
- * <hr>$Revision: 85169 $<hr>
+ * <hr>$Revision: 89166 $<hr>
  *
  */
 
@@ -383,15 +383,15 @@ int cvmx_l2c_lock_line(uint64_t addr)
 			/* make sure CVMX_L2C_TADX_TAG is updated */
 			CVMX_SYNC;
 			l2c_tadx_tag.u64 = cvmx_read_csr(CVMX_L2C_TADX_TAG(tad));
-			if (OCTEON_IS_OCTEON2() && l2c_tadx_tag.s.valid &&
+			if (OCTEON_IS_OCTEON2() && l2c_tadx_tag.cn61xx.valid &&
 			    l2c_tadx_tag.cn61xx.tag == tag)
 				break;
 			else if (OCTEON_IS_MODEL(OCTEON_CN70XX)
 				 && l2c_tadx_tag.cn70xx.valid
 				 && l2c_tadx_tag.cn70xx.tag == tag)
 				break;
-			else if (l2c_tadx_tag.s.valid &&
-			    l2c_tadx_tag.cn78xx.tag == tag)
+			else if (l2c_tadx_tag.cn78xx.ts == 0
+				 && l2c_tadx_tag.cn78xx.tag == tag)
 			        break;
 
 			/* cvmx_dprintf("caddr=%lx tad=%d tagu64=%lx valid=%x tag=%x \n", caddr,
@@ -771,15 +771,22 @@ union cvmx_l2c_tag cvmx_l2c_get_tag_v2(uint32_t association, uint32_t index, uin
 		CVMX_SYNC;	/* make sure CVMX_L2C_TADX_TAG is updated */
 		l2c_tadx_tag.u64 = cvmx_read_csr(CVMX_L2C_TADX_TAG(tad));
 
-		tag.s.V = l2c_tadx_tag.s.valid;
-		tag.s.D = l2c_tadx_tag.s.dirty;
-		tag.s.L = l2c_tadx_tag.s.lock;
-		tag.s.U = l2c_tadx_tag.cn61xx.use;
-		tag.s.addr = (OCTEON_IS_MODEL(OCTEON_CN70XX) 
+		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+			if (l2c_tadx_tag.cn78xx.ts == 0)
+				tag.s.V = 1;
+			tag.s.D = l2c_tadx_tag.cn78xx.sblkdty; /* FIXME */
+			tag.s.L = l2c_tadx_tag.cn78xx.lock;
+			tag.s.U = l2c_tadx_tag.cn78xx.used;
+			tag.s.addr = l2c_tadx_tag.cn78xx.tag;
+		} else {
+			tag.s.V = l2c_tadx_tag.cn61xx.valid;
+			tag.s.D = l2c_tadx_tag.cn61xx.dirty;
+			tag.s.L = l2c_tadx_tag.cn61xx.lock;
+			tag.s.U = l2c_tadx_tag.cn61xx.use;
+			tag.s.addr = (OCTEON_IS_MODEL(OCTEON_CN70XX)
 				? l2c_tadx_tag.cn70xx.tag
-				: (OCTEON_IS_MODEL(OCTEON_CN78XX)
-				   ? l2c_tadx_tag.cn78xx.tag
-				   : l2c_tadx_tag.cn61xx.tag));
+				   : l2c_tadx_tag.cn61xx.tag);
+		}
 	} else {
 		union __cvmx_l2c_tag tmp_tag;
 		/* __read_l2_tag is intended for internal use only */
@@ -857,15 +864,22 @@ union cvmx_l2c_tag cvmx_l2c_get_tag(uint32_t association, uint32_t index)
 		CVMX_SYNC;	/* make sure CVMX_L2C_TADX_TAG is updated */
 		l2c_tadx_tag.u64 = cvmx_read_csr(CVMX_L2C_TADX_TAG(0));
 
-		tag.s.V = l2c_tadx_tag.s.valid;
-		tag.s.D = l2c_tadx_tag.s.dirty;
-		tag.s.L = l2c_tadx_tag.s.lock;
-		tag.s.U = l2c_tadx_tag.cn61xx.use;
-		tag.s.addr = (OCTEON_IS_MODEL(OCTEON_CN70XX) 
+		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+			if (l2c_tadx_tag.cn78xx.ts == 0)
+				tag.s.V = 1;
+			tag.s.D = l2c_tadx_tag.cn78xx.sblkdty; /* FIXME */
+			tag.s.L = l2c_tadx_tag.cn78xx.lock;
+			tag.s.U = l2c_tadx_tag.cn78xx.used;
+			tag.s.addr = l2c_tadx_tag.cn78xx.tag;
+		} else {
+			tag.s.V = l2c_tadx_tag.cn61xx.valid;
+			tag.s.D = l2c_tadx_tag.cn61xx.dirty;
+			tag.s.L = l2c_tadx_tag.cn61xx.lock;
+			tag.s.U = l2c_tadx_tag.cn61xx.use;
+			tag.s.addr = (OCTEON_IS_MODEL(OCTEON_CN70XX)
 				? l2c_tadx_tag.cn70xx.tag
-				: (OCTEON_IS_MODEL(OCTEON_CN78XX)
-				   ? l2c_tadx_tag.cn78xx.tag
-				   : l2c_tadx_tag.cn61xx.tag));
+				   : l2c_tadx_tag.cn61xx.tag);
+		}
 	} else {
 		union __cvmx_l2c_tag tmp_tag;
 		/* __read_l2_tag is intended for internal use only */
@@ -1041,9 +1055,27 @@ int cvmx_l2c_get_num_assoc(void)
 	else if (OCTEON_IS_MODEL(OCTEON_CN31XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN30XX))
 		l2_assoc = 4;
-	else if (OCTEON_IS_MODEL(OCTEON_CN70XX))
-		return 4;
-	else {
+	else if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
+		union cvmx_mio_fus_dat3 mio_fus_dat3;
+
+		mio_fus_dat3.u64 = cvmx_read_csr(CVMX_MIO_FUS_DAT3);
+
+		switch (mio_fus_dat3.s.l2c_crip) {
+		case 3:  /* 1/4 size */
+			l2_assoc = 1;
+			break;
+		case 2:  /* 1/2 size */
+			l2_assoc = 2;
+			break; 
+		case 1:  /* 3/4 size */
+			l2_assoc = 3;
+			break;
+		default: /* Full size */
+			l2_assoc = 4;
+			break;
+		}
+		return l2_assoc;
+	} else {
 		cvmx_dprintf("Unsupported OCTEON Model in %s\n", __func__);
 		l2_assoc = 8;
 	}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-nand.c b/arch/mips/cavium-octeon/executive/cvmx-nand.c
index 2861015..c576582 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-nand.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-nand.c
@@ -216,6 +216,13 @@ static CVMX_SHARED const char *cvmx_nand_opcode_labels[] = {
 	"Bus Aquire / Release"	/* 15 */
 };
 
+#ifndef CVMX_BUILD_FOR_UBOOT
+# define	nand_debug(format, args...)	cvmx_dprintf(format, ##args)
+#else
+# define	nand_debug(format, args...)	debug(format, ##args)
+#endif
+
+#ifdef CVMX_NAND_RUNTIME_DEBUG
 /* This macro logs out whenever a function is called if debugging is on */
 #define CVMX_NAND_LOG_CALLED() \
 	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
@@ -229,7 +236,7 @@ static CVMX_SHARED const char *cvmx_nand_opcode_labels[] = {
 	} while(0)
 
 /* This macro logs out when a function returns a value */
-#define CVMX_NAND_RETURN(v)                                              \
+#define CVMX_NAND_RETURN(v)						\
 	do {								\
 		typeof(v) r = v;					\
 		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
@@ -238,14 +245,40 @@ static CVMX_SHARED const char *cvmx_nand_opcode_labels[] = {
 	} while (0)
 
 /* This macro logs out when a function doesn't return a value */
-#define CVMX_NAND_RETURN_NOTHING()                                      \
+#define CVMX_NAND_RETURN_NOTHING()					\
+	do {								\
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
+			nand_debug("%*s%s: returned\n", 2*--debug_indent, "", __func__); \
+		return;							\
+	} while (0)
+#else
+#define CVMX_NAND_LOG_CALLED()	{ \
+	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
+		nand_debug("%*s%s: called\n", 2*debug_indent++, "", __func__); \
+	}
+
+#define CVMX_NAND_LOG_PARAM(format, param) \
 	do {								\
 		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
-			cvmx_dprintf("%*s%s: returned\n", 2*--debug_indent, "", __func__); \
+			nand_debug("%*s%s: param %s = " format "\n", 2*debug_indent, "", __func__, #param, param); \
+	} while (0)
+
+#define CVMX_NAND_RETURN(v)						\
+	do {								\
+		typeof(v) r = v;					\
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
+			nand_debug("%*s%s: returned %s(%d)\n", 2*--debug_indent, "", __func__, #v, r); \
+		return r;						\
+	} while (0)
+
+#define CVMX_NAND_RETURN_NOTHING()					\
+	do {								\
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
+			nand_debug("%*s%s: returned\n", 2*--debug_indent, "", __func__); \
 		return;							\
 	} while (0)
+#endif
 
-	
 static void __cvmx_nand_hex_dump(uint64_t buffer_address, int buffer_length);
 
 /* Compute the CRC for the ONFI parameter page.  Adapted from sample code
@@ -275,18 +308,38 @@ static uint16_t __onfi_parameter_crc_compute(uint8_t *data)
 }
 
 /**
+ * For OCTEON III there can be only one controller for the boot bus.  This
+ * function selects NAND to be the controller and returns the old controller;
+ *
+ * @param select	Set to 1 to select NAND or 0 for eMMC/SD
+ *
+ * @return Previously selected controller
+ */
+static inline int __cvmx_nand_select(int select)
+{
+	cvmx_mio_boot_ctl_t mio_boot_ctl;
+
+	if (OCTEON_IS_OCTEON3()) {
+		mio_boot_ctl.u64 = cvmx_read_csr(CVMX_MIO_BOOT_CTL);
+		cvmx_write_csr(CVMX_MIO_BOOT_CTL, !!select);
+		return mio_boot_ctl.s.sel;
+	}
+	return 0;
+}
+
+/**
  * Adjust the NAND address for 16-bit NAND parts
- * 
+ *
  * @param chip	chip ID
  * @param nand_address	NAND address to adjust
- * 
+ *
  * @return adjusted nand address
  */
 static inline uint64_t __cvmx_nand_adjust_address(int chip,
 						  uint64_t nand_address)
 {
 	uint64_t page_mask = cvmx_nand_state[chip].page_size - 1;
-	
+
 	/* For 16 bit mode, addresses within a page are word address, rather
 	 * than byte addresses
 	 */
@@ -368,7 +421,7 @@ cvmx_nand_onfi_process(cvmx_nand_onfi_param_page_t param_page[3])
 		if (crc == cvmx_le16_to_cpu(param_page[index].crc))
 			break;
 		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-			cvmx_dprintf("%s: Paramter page %d is corrupt. (Expected CRC: 0x%04x, computed: 0x%04x)\n",
+			nand_debug("%s: Paramter page %d is corrupt. (Expected CRC: 0x%04x, computed: 0x%04x)\n",
 				     __func__, index,
 				     cvmx_le16_to_cpu(param_page[index].crc),
 				     crc);
@@ -376,7 +429,7 @@ cvmx_nand_onfi_process(cvmx_nand_onfi_param_page_t param_page[3])
 
 	if (index == 3) {
 		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-			cvmx_dprintf("%s: All parameter pages fail CRC check.  Checking to see if any look sane.\n",
+			nand_debug("%s: All parameter pages fail CRC check.  Checking to see if any look sane.\n",
 				     __func__);
 
 		if (!memcmp(param_page, param_page + 1, 256)) {
@@ -393,7 +446,7 @@ cvmx_nand_onfi_process(cvmx_nand_onfi_param_page_t param_page[3])
 			    && param_page[0].timing_mode != 0xFFFF) {
 				/* Looks like we have enough values to use */
 				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-					cvmx_dprintf("%s: Page 0 looks sane, using even though CRC fails.\n",
+					nand_debug("%s: Page 0 looks sane, using even though CRC fails.\n",
 						     __func__);
 				index = 0;
 			}
@@ -401,54 +454,54 @@ cvmx_nand_onfi_process(cvmx_nand_onfi_param_page_t param_page[3])
 	}
 
 	if (index == 3) {
-		cvmx_dprintf("%s: WARNING: ONFI part but no valid ONFI parameter pages found.\n",
+		nand_debug("%s: WARNING: ONFI part but no valid ONFI parameter pages found.\n",
 			     __func__);
 		return NULL;
 	}
 
 	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
-		cvmx_dprintf("%*sONFI Information (from copy %d in param page)\n", 2 * debug_indent, "", index);
+		nand_debug("%*sONFI Information (from copy %d in param page)\n", 2 * debug_indent, "", index);
 		debug_indent++;
-		cvmx_dprintf("%*sonfi = %c%c%c%c\n", 2 * debug_indent, "", param_page[index].onfi[0], param_page[index].onfi[1],
+		nand_debug("%*sonfi = %c%c%c%c\n", 2 * debug_indent, "", param_page[index].onfi[0], param_page[index].onfi[1],
 			     param_page[index].onfi[2], param_page[index].onfi[3]);
-		cvmx_dprintf("%*srevision_number = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].revision_number));
-		cvmx_dprintf("%*sfeatures = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].features));
-		cvmx_dprintf("%*soptional_commands = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].optional_commands));
-
-		cvmx_dprintf("%*smanufacturer = %12.12s\n", 2 * debug_indent, "", param_page[index].manufacturer);
-		cvmx_dprintf("%*smodel = %20.20s\n", 2 * debug_indent, "", param_page[index].model);
-		cvmx_dprintf("%*sjedec_id = 0x%x\n", 2 * debug_indent, "", param_page[index].jedec_id);
-		cvmx_dprintf("%*sdate_code = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].date_code));
-
-		cvmx_dprintf("%*spage_data_bytes = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].page_data_bytes));
-		cvmx_dprintf("%*spage_spare_bytes = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].page_spare_bytes));
-		cvmx_dprintf("%*spartial_page_data_bytes = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].partial_page_data_bytes));
-		cvmx_dprintf("%*spartial_page_spare_bytes = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].partial_page_spare_bytes));
-		cvmx_dprintf("%*spages_per_block = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].pages_per_block));
-		cvmx_dprintf("%*sblocks_per_lun = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].blocks_per_lun));
-		cvmx_dprintf("%*snumber_lun = %u\n", 2 * debug_indent, "", param_page[index].number_lun);
-		cvmx_dprintf("%*saddress_cycles = 0x%x\n", 2 * debug_indent, "", param_page[index].address_cycles);
-		cvmx_dprintf("%*sbits_per_cell = %u\n", 2 * debug_indent, "", param_page[index].bits_per_cell);
-		cvmx_dprintf("%*sbad_block_per_lun = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].bad_block_per_lun));
-		cvmx_dprintf("%*sblock_endurance = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].block_endurance));
-		cvmx_dprintf("%*sgood_blocks = %u\n", 2 * debug_indent, "", param_page[index].good_blocks);
-		cvmx_dprintf("%*sgood_block_endurance = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].good_block_endurance));
-		cvmx_dprintf("%*sprograms_per_page = %u\n", 2 * debug_indent, "", param_page[index].programs_per_page);
-		cvmx_dprintf("%*spartial_program_attrib = 0x%x\n", 2 * debug_indent, "", param_page[index].partial_program_attrib);
-		cvmx_dprintf("%*sbits_ecc = %u\n", 2 * debug_indent, "", param_page[index].bits_ecc);
-		cvmx_dprintf("%*sinterleaved_address_bits = 0x%x\n", 2 * debug_indent, "", param_page[index].interleaved_address_bits);
-		cvmx_dprintf("%*sinterleaved_attrib = 0x%x\n", 2 * debug_indent, "", param_page[index].interleaved_attrib);
-
-		cvmx_dprintf("%*spin_capacitance = %u\n", 2 * debug_indent, "", param_page[index].pin_capacitance);
-		cvmx_dprintf("%*stiming_mode = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].timing_mode));
-		cvmx_dprintf("%*scache_timing_mode = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].cache_timing_mode));
-		cvmx_dprintf("%*st_prog = %d us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_prog));
-		cvmx_dprintf("%*st_bers = %u us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_bers));
-		cvmx_dprintf("%*st_r = %u us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_r));
-		cvmx_dprintf("%*st_ccs = %u ns\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_ccs));
-		cvmx_dprintf("%*svendor_revision = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].vendor_revision));
+		nand_debug("%*srevision_number = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].revision_number));
+		nand_debug("%*sfeatures = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].features));
+		nand_debug("%*soptional_commands = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].optional_commands));
+
+		nand_debug("%*smanufacturer = %12.12s\n", 2 * debug_indent, "", param_page[index].manufacturer);
+		nand_debug("%*smodel = %20.20s\n", 2 * debug_indent, "", param_page[index].model);
+		nand_debug("%*sjedec_id = 0x%x\n", 2 * debug_indent, "", param_page[index].jedec_id);
+		nand_debug("%*sdate_code = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].date_code));
+
+		nand_debug("%*spage_data_bytes = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].page_data_bytes));
+		nand_debug("%*spage_spare_bytes = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].page_spare_bytes));
+		nand_debug("%*spartial_page_data_bytes = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].partial_page_data_bytes));
+		nand_debug("%*spartial_page_spare_bytes = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].partial_page_spare_bytes));
+		nand_debug("%*spages_per_block = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].pages_per_block));
+		nand_debug("%*sblocks_per_lun = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].blocks_per_lun));
+		nand_debug("%*snumber_lun = %u\n", 2 * debug_indent, "", param_page[index].number_lun);
+		nand_debug("%*saddress_cycles = 0x%x\n", 2 * debug_indent, "", param_page[index].address_cycles);
+		nand_debug("%*sbits_per_cell = %u\n", 2 * debug_indent, "", param_page[index].bits_per_cell);
+		nand_debug("%*sbad_block_per_lun = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].bad_block_per_lun));
+		nand_debug("%*sblock_endurance = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].block_endurance));
+		nand_debug("%*sgood_blocks = %u\n", 2 * debug_indent, "", param_page[index].good_blocks);
+		nand_debug("%*sgood_block_endurance = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].good_block_endurance));
+		nand_debug("%*sprograms_per_page = %u\n", 2 * debug_indent, "", param_page[index].programs_per_page);
+		nand_debug("%*spartial_program_attrib = 0x%x\n", 2 * debug_indent, "", param_page[index].partial_program_attrib);
+		nand_debug("%*sbits_ecc = %u\n", 2 * debug_indent, "", param_page[index].bits_ecc);
+		nand_debug("%*sinterleaved_address_bits = 0x%x\n", 2 * debug_indent, "", param_page[index].interleaved_address_bits);
+		nand_debug("%*sinterleaved_attrib = 0x%x\n", 2 * debug_indent, "", param_page[index].interleaved_attrib);
+
+		nand_debug("%*spin_capacitance = %u\n", 2 * debug_indent, "", param_page[index].pin_capacitance);
+		nand_debug("%*stiming_mode = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].timing_mode));
+		nand_debug("%*scache_timing_mode = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].cache_timing_mode));
+		nand_debug("%*st_prog = %d us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_prog));
+		nand_debug("%*st_bers = %u us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_bers));
+		nand_debug("%*st_r = %u us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_r));
+		nand_debug("%*st_ccs = %u ns\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_ccs));
+		nand_debug("%*svendor_revision = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].vendor_revision));
 		/* uint8_t vendor_specific[88];    */ /**< Byte 166-253: Vendor specific */
-		cvmx_dprintf("%*scrc = 0x%x\n", 2 * debug_indent, "", param_page[index].crc);
+		nand_debug("%*scrc = 0x%x\n", 2 * debug_indent, "", param_page[index].crc);
 		debug_indent--;
 	}
 	return param_page + index;
@@ -462,7 +515,7 @@ void __set_onfi_timing_mode(int *tim_par, int clocks_us, int mode)
 	int pulse_adjust;
 
 	if ((unsigned)mode >= sizeof(onfi_speed_modes)/sizeof(onfi_speed_modes[0])) {
-		cvmx_dprintf("%s: invalid ONFI timing mode: %d\n",
+		nand_debug("%s: invalid ONFI timing mode: %d\n",
 			     __func__, mode);
 		return;
 	}
@@ -500,8 +553,8 @@ static void __set_chip_defaults(int chip, int clocks_us)
 			       cvmx_nand_state[chip].onfi_timing);
 	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
 
-		cvmx_dprintf("%s: Using default NAND parameters.\n", __func__);
-		cvmx_dprintf("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, blocks: %d, timing mode: %d\n",
+		nand_debug("%s: Using default NAND parameters.\n", __func__);
+		nand_debug("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, blocks: %d, timing mode: %d\n",
 			     __func__, cvmx_nand_state[chip].page_size,
 			     cvmx_nand_state[chip].oob_size,
 			     cvmx_nand_state[chip].pages_per_block,
@@ -579,6 +632,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 	uint64_t clocks_us;
 	union cvmx_ndf_misc ndf_misc;
 	uint8_t nand_id_buffer[16];
+	int nand_selected;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_NAND))
 		CVMX_NAND_RETURN(CVMX_NAND_NO_DEVICE);
@@ -609,6 +663,8 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
 #endif
 
+	nand_selected = __cvmx_nand_select(1);
+
 	/* Disable boot mode and reset the fifo */
 	ndf_misc.u64 = cvmx_read_csr(CVMX_NDF_MISC);
 	ndf_misc.s.rd_cmd = 0;
@@ -665,6 +721,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 				__set_chip_defaults(chip, clocks_us);
 			}
 		}
+		__cvmx_nand_select(nand_selected);
 		CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
 	}
 
@@ -736,7 +793,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 					      cvmx_ptr_to_phys(cvmx_nand_buffer),
 					      16) < 16) {
 				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-					cvmx_dprintf("%s: Failed to probe chip %d\n",
+					nand_debug("%s: Failed to probe chip %d\n",
 						     __func__, chip);
 				probe_failed = 1;
 
@@ -744,7 +801,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 			if (*(uint32_t *) cvmx_nand_buffer == 0xffffffff
 			    || *(uint32_t *) cvmx_nand_buffer == 0x0) {
 				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-					cvmx_dprintf("%s: Probe returned nothing for chip %d\n",
+					nand_debug("%s: Probe returned nothing for chip %d\n",
 						     __func__, chip);
 				probe_failed = 1;
 			}
@@ -757,7 +814,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 		memcpy(nand_id_buffer, cvmx_nand_buffer, sizeof(nand_id_buffer));
 
 		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-			cvmx_dprintf("%s: NAND chip %d has ID 0x%08llx\n",
+			nand_debug("%s: NAND chip %d has ID 0x%08llx\n",
 				     __func__, chip,
 				     (unsigned long long int)*(uint64_t *)cvmx_nand_buffer);
 					cvmx_nand_reset(chip);
@@ -769,7 +826,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 				      cvmx_ptr_to_phys(cvmx_nand_buffer),
 				      8) < 8) {
 			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-				cvmx_dprintf("%s: Failed to probe chip %d\n",
+				nand_debug("%s: Failed to probe chip %d\n",
 					     __func__, chip);
 			continue;
 		}
@@ -780,7 +837,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 		    (cvmx_nand_buffer[3] == 'I')) {
 			/* We have an ONFI part, so read the parameter page */
 			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-				cvmx_dprintf("%s: NAND chip %d is ONFI\n",
+				nand_debug("%s: NAND chip %d is ONFI\n",
 					     __func__, chip);
 
 
@@ -788,7 +845,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 						  cvmx_ptr_to_phys(cvmx_nand_buffer),
 						  256 * 3);
 			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
-				cvmx_dprintf("%s: NAND chip %d is ONFI\n",
+				nand_debug("%s: NAND chip %d is ONFI\n",
 					     __func__, chip);
 				__cvmx_nand_hex_dump(cvmx_ptr_to_phys(cvmx_nand_buffer),
 						     256 * 3);
@@ -823,14 +880,14 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 					mode = 0;
 					cvmx_nand_state[chip].onfi_timing = mode;
 				} else {
-					cvmx_dprintf("%s: Invalid timing mode (%d) in ONFI parameter page, ignoring\n",
+					nand_debug("%s: Invalid timing mode (%d) in ONFI parameter page, ignoring\n",
 						     __func__,
 						     cvmx_nand_state[chip].onfi_timing);
 					cvmx_nand_state[chip].onfi_timing = 0;
 
 				}
 				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-					cvmx_dprintf("%s: Using ONFI timing mode: %d\n",
+					nand_debug("%s: Using ONFI timing mode: %d\n",
 						     __func__,
 						     cvmx_nand_state[chip].onfi_timing);
 
@@ -838,7 +895,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 				 * to put the chip into the mode.
 				 */
 				if (cvmx_le16_to_cpu(onfi_param_page->optional_commands) & 4) {
-					cvmx_dprintf("%s: Setting timing parameter mode to %d\n",
+					nand_debug("%s: Setting timing parameter mode to %d\n",
 						     __func__,
 						     cvmx_nand_state[chip].onfi_timing);
 					memset(features, 0, sizeof(features));
@@ -852,12 +909,13 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 						       cvmx_nand_state[chip].onfi_timing);
 				status = cvmx_nand_get_status(chip);
 				if ((status & 0xE3) != 0xE0) {
-					cvmx_dprintf("%s: Status 0x%x setting timing feature\n",
+					nand_debug("%s: Status 0x%x setting timing feature\n",
 						     __func__, status);
 				}
 				if (cvmx_nand_state[chip].page_size + cvmx_nand_state[chip].oob_size > CVMX_NAND_MAX_PAGE_AND_OOB_SIZE) {
-					cvmx_dprintf("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
+					nand_debug("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
 						     __func__, cvmx_nand_state[chip].page_size, cvmx_nand_state[chip].oob_size, CVMX_NAND_MAX_PAGE_AND_OOB_SIZE);
+					__cvmx_nand_select(nand_selected);
 					return CVMX_NAND_ERROR;
 				}
 				/* We have completed setup for this ONFI chip, so go on to next chip. */
@@ -865,14 +923,14 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 			} else {
 				/* Parameter page is not valid */
 				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-					cvmx_dprintf("%s: ONFI paramater page missing or invalid.\n", __func__);
+					nand_debug("%s: ONFI paramater page missing or invalid.\n", __func__);
 
 			}
 
 		} else {
 			/* We have a non-ONFI part. */
 			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-				cvmx_dprintf("%s: Chip %d doesn't support ONFI.  ID: 0x%02x 0x%02x\n",
+				nand_debug("%s: Chip %d doesn't support ONFI.  ID: 0x%02x 0x%02x\n",
 					     __func__, chip, nand_id_buffer[0],
 					     nand_id_buffer[1]);
 
@@ -902,7 +960,7 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 					cvmx_nand_state[chip].oob_size *= 2;
 
 				cvmx_nand_state[chip].blocks =
-					nand_size_bits / 
+					nand_size_bits /
 					(8ULL
 					 * cvmx_nand_state[chip].page_size
 					 * cvmx_nand_state[chip].pages_per_block);
@@ -917,16 +975,16 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 				}
 
 				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
-					cvmx_dprintf("%s: Samsung NAND chip detected, using parameters decoded from ID bytes.\n",
+					nand_debug("%s: Samsung NAND chip detected, using parameters decoded from ID bytes.\n",
 						     __func__);
-					cvmx_dprintf("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, part size: %d MBytes, timing mode: %d\n",
+					nand_debug("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, part size: %d MBytes, timing mode: %d\n",
 						     __func__,
 						     cvmx_nand_state[chip].page_size,
 						     cvmx_nand_state[chip].oob_size,
 						     cvmx_nand_state[chip].pages_per_block,
 						     (int)(nand_size_bits / (8 * 1024 * 1024)),
 						     cvmx_nand_state[chip].onfi_timing);
-					cvmx_dprintf("%s: Address cycles: %d, column bits: %d, row bits: %d, block count: %d\n",
+					nand_debug("%s: Address cycles: %d, column bits: %d, row bits: %d, block count: %d\n",
 						     __func__,
 						     __cvmx_nand_get_address_cycles(chip),
 						     __cvmx_nand_get_column_bits(chip),
@@ -938,11 +996,12 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 						       clocks_us,
 						       cvmx_nand_state[chip].onfi_timing);
 				if (cvmx_nand_state[chip].page_size + cvmx_nand_state[chip].oob_size > CVMX_NAND_MAX_PAGE_AND_OOB_SIZE) {
-					cvmx_dprintf("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
+					nand_debug("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
 						     __func__,
 						     cvmx_nand_state[chip].page_size,
 						     cvmx_nand_state[chip].oob_size,
 						     CVMX_NAND_MAX_PAGE_AND_OOB_SIZE);
+					__cvmx_nand_select(nand_selected);
 					return CVMX_NAND_ERROR;
 				}
 
@@ -987,25 +1046,26 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 					cvmx_nand_state[chip].onfi_timing = 8;
 					break;
 				default:
-					cvmx_dprintf("%s: Unknown Micron chip ID 0x%02x\n",
+					nand_debug("%s: Unknown Micron chip ID 0x%02x\n",
 						     __func__, nand_id_buffer[1]);
+					__cvmx_nand_select(nand_selected);
 					return CVMX_NAND_ERROR;
 				}
 				cvmx_nand_state[chip].flags |= CVMX_NAND_NUMONYX;
 				cvmx_nand_state[chip].blocks =
-					nand_size_bits / 
+					nand_size_bits /
 						(8 * cvmx_nand_state[chip].page_size * cvmx_nand_state[chip].pages_per_block);
 				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
-					cvmx_dprintf("%s: Micron/Numonyx NAND chip detected, using parameters decoded from ID bytes.\n",
+					nand_debug("%s: Micron/Numonyx NAND chip detected, using parameters decoded from ID bytes.\n",
 						     __func__);
-					cvmx_dprintf("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, part size: %d MBytes, timing mode: %d\n",
+					nand_debug("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, part size: %d MBytes, timing mode: %d\n",
 						     __func__,
 						     cvmx_nand_state[chip].page_size,
 						     cvmx_nand_state[chip].oob_size,
 						     cvmx_nand_state[chip].pages_per_block,
 						     (int)(nand_size_bits / (8 * 1024 * 1024)),
 						     cvmx_nand_state[chip].onfi_timing);
-					cvmx_dprintf("%s: Address cycles: %d, column bits: %d, row bits: %d, block count: %d\n",
+					nand_debug("%s: Address cycles: %d, column bits: %d, row bits: %d, block count: %d\n",
 						     __func__,
 						     __cvmx_nand_get_address_cycles(chip),
 						     __cvmx_nand_get_column_bits(chip),
@@ -1019,11 +1079,12 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 				if ((cvmx_nand_state[chip].page_size +
 				     cvmx_nand_state[chip].oob_size) >
 				    CVMX_NAND_MAX_PAGE_AND_OOB_SIZE) {
-					cvmx_dprintf("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
+					nand_debug("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
 						     __func__,
 						     cvmx_nand_state[chip].page_size,
 						     cvmx_nand_state[chip].oob_size,
 						     CVMX_NAND_MAX_PAGE_AND_OOB_SIZE);
+					__cvmx_nand_select(nand_selected);
 					return CVMX_NAND_ERROR;
 				}
 
@@ -1045,10 +1106,11 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 		} else {
 
 			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-				cvmx_dprintf("%s: Unable to determine NAND parameters, and no defaults supplied.\n",
+				nand_debug("%s: Unable to determine NAND parameters, and no defaults supplied.\n",
 					     __func__);
 		}
 	}
+	__cvmx_nand_select(nand_selected);
 	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
 }
 EXPORT_SYMBOL(cvmx_nand_initialize);
@@ -1170,32 +1232,34 @@ cvmx_nand_status_t cvmx_nand_submit(cvmx_nand_cmd_t cmd)
 		if (__cvmx_nand_get_free_cmd_bytes() < 8)
 			CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
 		cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
-		CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+		break;
 
 	case 5:		/* ALE commands take either one or two 64bit words */
 		if (cmd.ale.adr_byte_num < 5) {
 			if (__cvmx_nand_get_free_cmd_bytes() < 8)
 				CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
 			cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
-			CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
 		} else {
 			if (__cvmx_nand_get_free_cmd_bytes() < 16)
 				CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
 			cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
 			cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[0]);
-			CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
 		}
+		break;
 
 	case 11:		/* Wait status commands take two 64bit words */
-		if (__cvmx_nand_get_free_cmd_bytes() < 16)
+		if (__cvmx_nand_get_free_cmd_bytes() < 16) {
 			CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+		}
 		cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
 		cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[0]);
-		CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+		break;
 
 	default:
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 	}
+
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
 }
 
 /**
@@ -1404,16 +1468,16 @@ static void __cvmx_nand_hex_dump(uint64_t buffer_address, int buffer_length)
 	int offset = 0;
 	while (offset < buffer_length) {
 		int i;
-		cvmx_dprintf("%*s%04x:", 2 * debug_indent, "", offset);
+		nand_debug("%*s%04x:", 2 * debug_indent, "", offset);
 		for (i = 0; i < 32; i++) {
 			if ((i & 3) == 0)
-				cvmx_dprintf(" ");
+				nand_debug(" ");
 			if (offset + i < buffer_length)
-				cvmx_dprintf("%02x", 0xff & buffer[offset + i]);
+				nand_debug("%02x", 0xff & buffer[offset + i]);
 			else
-				cvmx_dprintf("  ");
+				nand_debug("  ");
 		}
-		cvmx_dprintf("\n");
+		nand_debug("\n");
 		offset += 32;
 	}
 }
@@ -1449,6 +1513,8 @@ static inline int __cvmx_nand_low_level_read(int chip,
 	cvmx_nand_cmd_t cmd;
 	union cvmx_mio_ndf_dma_cfg ndf_dma_cfg;
 	int bytes;
+	int nand_selected;
+	int status = CVMX_NAND_ERROR;
 
 	CVMX_NAND_LOG_CALLED();
 	CVMX_NAND_LOG_PARAM("%d", chip);
@@ -1470,28 +1536,36 @@ static inline int __cvmx_nand_low_level_read(int chip,
 	if (!buffer_length)
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 
+	nand_selected = __cvmx_nand_select(1);
+
 	/* Build the command and address cycles */
-	if (__cvmx_nand_build_pre_cmd(chip, nand_command1, address_cycles,
-				      nand_address, nand_command2))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __cvmx_nand_build_pre_cmd(chip, nand_command1,
+					   address_cycles, nand_address,
+					   nand_command2);
+	if (status)
+		goto error;
 
 	/* Send WAIT.  This waits for some time, then
 	 * waits for busy to be de-asserted.
 	 */
-	if (__wait_for_busy_done(chip))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __wait_for_busy_done(chip);
+	if (status)
+		goto error;
 
 	/* Wait for tRR after busy de-asserts.
 	 * Use 2* tALS as proxy.  This is overkill in
-	 * the slow modes, but not bad in the faster ones. 
+	 * the slow modes, but not bad in the faster ones.
 	 */
 	memset(&cmd, 0, sizeof(cmd));
 	cmd.wait.two = 2;
 	cmd.wait.n = 4;
-	if (cvmx_nand_submit(cmd))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
-	if (cvmx_nand_submit(cmd))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = cvmx_nand_submit(cmd);
+	if (status)
+		goto error;
+
+	status = cvmx_nand_submit(cmd);
+	if (status)
+		goto error;
 
 	/* Send READ */
 	memset(&cmd, 0, sizeof(cmd));
@@ -1506,20 +1580,24 @@ static inline int __cvmx_nand_low_level_read(int chip,
 	cmd.rd.rdn2 = cvmx_nand_state[chip].rdn[1];
 	cmd.rd.rdn3 = cvmx_nand_state[chip].rdn[2];
 	cmd.rd.rdn4 = cvmx_nand_state[chip].rdn[3];
-	if (cvmx_nand_submit(cmd))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = cvmx_nand_submit(cmd);
+	if (status)
+		goto error;
 
 	__cvmx_nand_setup_dma(chip, 0, buffer_address, buffer_length);
 
-	if (__cvmx_nand_build_post_cmd())
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __cvmx_nand_build_post_cmd();
+	if (status)
+		goto error;
+
 	WATCHDOG_RESET();
 	/* Wait for the DMA to complete */
 	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_NDF_DMA_CFG,
 				  union cvmx_mio_ndf_dma_cfg,
 				  en, ==, 0, NAND_TIMEOUT_USECS_READ)) {
 		WATCHDOG_RESET();
-		CVMX_NAND_RETURN(CVMX_NAND_TIMEOUT);
+		status = CVMX_NAND_TIMEOUT;
+		goto error;
 	}
 	/* Return the number of bytes transfered */
 	ndf_dma_cfg.u64 = cvmx_read_csr(CVMX_MIO_NDF_DMA_CFG);
@@ -1528,7 +1606,12 @@ static inline int __cvmx_nand_low_level_read(int chip,
 	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
 		__cvmx_nand_hex_dump(buffer_address, bytes);
 
+	__cvmx_nand_select(nand_selected);
 	CVMX_NAND_RETURN(bytes);
+
+error:
+	__cvmx_nand_select(nand_selected);
+	CVMX_NAND_RETURN(status);
 }
 
 /**
@@ -1608,7 +1691,7 @@ int cvmx_nand_random_data_out(int chip, uint64_t nand_address,
 	int bytes, column_bits, column_mask;
 
 	CVMX_NAND_LOG_CALLED();
-	
+
 	CVMX_NAND_LOG_PARAM("%d", chip);
 	CVMX_NAND_LOG_PARAM("0x%llx", CAST_ULL(nand_address));
 	CVMX_NAND_LOG_PARAM("0x%llx", CAST_ULL(buffer_address));
@@ -1626,7 +1709,7 @@ int cvmx_nand_random_data_out(int chip, uint64_t nand_address,
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 	if (!buffer_length)
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
-	
+
 	nand_address = __cvmx_nand_adjust_address(chip, nand_address);
 	column_bits = __cvmx_nand_get_column_bits(chip);
 	column_mask = (1 << column_bits) - 1;
@@ -1658,6 +1741,8 @@ cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
 {
 	cvmx_nand_cmd_t cmd;
 	int buffer_length;
+	int nand_selected;
+	cvmx_nand_status_t status = CVMX_NAND_SUCCESS;
 
 	CVMX_NAND_LOG_CALLED();
 	CVMX_NAND_LOG_PARAM("%d", chip);
@@ -1673,6 +1758,8 @@ cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
 	if (buffer_address & 7)
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 
+	nand_selected = __cvmx_nand_select(1);
+
 	nand_address = __cvmx_nand_adjust_address(chip, nand_address);
 
 	buffer_length =
@@ -1688,10 +1775,11 @@ cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
 	buffer_length &= ~0x7;
 
 	/* Build the command and address cycles */
-	if (__cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_PROGRAM,
-				      __cvmx_nand_get_address_cycles(chip),
-				      nand_address, 0))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_PROGRAM,
+					   __cvmx_nand_get_address_cycles(chip),
+					   nand_address, 0);
+	if (status)
+		goto done;
 
 	/* Send WRITE */
 	memset(&cmd, 0, sizeof(cmd));
@@ -1699,8 +1787,9 @@ cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
 	cmd.wr.eight = 8;
 	cmd.wr.wrn1 = cvmx_nand_state[chip].wrn[0];
 	cmd.wr.wrn2 = cvmx_nand_state[chip].wrn[1];
-	if (cvmx_nand_submit(cmd))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = cvmx_nand_submit(cmd);
+	if (status)
+		goto done;
 
 	/* Send WRITE command */
 	memset(&cmd, 0, sizeof(cmd));
@@ -1709,17 +1798,20 @@ cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
 	cmd.cle.clen2 = cvmx_nand_state[chip].clen[1];
 	cmd.cle.clen3 = cvmx_nand_state[chip].clen[2];
 	cmd.cle.four = 4;
-	if (cvmx_nand_submit(cmd))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = cvmx_nand_submit(cmd);
+	if (status)
+		goto done;
 
 	__cvmx_nand_setup_dma(chip, 1, buffer_address, buffer_length);
 
 	/* WAIT for R_B to signal program is complete  */
-	if (__wait_for_busy_done(chip))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __wait_for_busy_done(chip);
+	if (status)
+		goto done;
 
-	if (__cvmx_nand_build_post_cmd())
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __cvmx_nand_build_post_cmd();
+	if (status)
+		goto done;
 
 	/* Wait for the DMA to complete */
 	WATCHDOG_RESET();
@@ -1727,9 +1819,12 @@ cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
 				  union cvmx_mio_ndf_dma_cfg, en, ==, 0,
 				  NAND_TIMEOUT_USECS_WRITE)) {
 		WATCHDOG_RESET();
-		CVMX_NAND_RETURN(CVMX_NAND_TIMEOUT);
+		status = CVMX_NAND_TIMEOUT;
+		goto done;
 	}
-	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+done:
+	__cvmx_nand_select(nand_selected);
+	CVMX_NAND_RETURN(status);
 }
 EXPORT_SYMBOL(cvmx_nand_page_write);
 
@@ -1744,6 +1839,8 @@ EXPORT_SYMBOL(cvmx_nand_page_write);
  */
 cvmx_nand_status_t cvmx_nand_block_erase(int chip, uint64_t nand_address)
 {
+	cvmx_nand_status_t status = CVMX_NAND_SUCCESS;
+	int nand_selected;
 	CVMX_NAND_LOG_CALLED();
 	CVMX_NAND_LOG_PARAM("%d", chip);
 	CVMX_NAND_LOG_PARAM("0x%llx", CAST_ULL(nand_address));
@@ -1753,29 +1850,36 @@ cvmx_nand_status_t cvmx_nand_block_erase(int chip, uint64_t nand_address)
 	if (!cvmx_nand_state[chip].page_size)
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 
+	nand_selected = __cvmx_nand_select(1);
 	/* Build the command and address cycles */
-	if (__cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_ERASE,
-				      (__cvmx_nand_get_row_bits(chip) + 7) >> 3,
-				      nand_address >> __cvmx_nand_get_column_bits(chip),
-				      NAND_COMMAND_ERASE_FIN))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_ERASE,
+					   (__cvmx_nand_get_row_bits(chip) + 7) >> 3,
+					   nand_address >> __cvmx_nand_get_column_bits(chip),
+					   NAND_COMMAND_ERASE_FIN);
+	if (status)
+		goto done;
 
 	/* WAIT for R_B to signal erase is complete  */
-	if (__wait_for_busy_done(chip))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __wait_for_busy_done(chip);
+	if (status)
+		goto done;
 
-	if (__cvmx_nand_build_post_cmd())
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __cvmx_nand_build_post_cmd();
+	if (status)
+		goto done;
 
 	/* Wait for the command queue to be idle, which means the wait is done */
 	WATCHDOG_RESET();
 	if (CVMX_WAIT_FOR_FIELD64(CVMX_NDF_ST_REG, union cvmx_ndf_st_reg,
 				  exe_idle, ==, 1, NAND_TIMEOUT_USECS_BLOCK_ERASE)) {
 		WATCHDOG_RESET();
-		CVMX_NAND_RETURN(CVMX_NAND_TIMEOUT);
+		status = CVMX_NAND_TIMEOUT;
+		goto done;
 	}
 
-	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+done:
+	__cvmx_nand_select(nand_selected);
+	CVMX_NAND_RETURN(status);
 }
 EXPORT_SYMBOL(cvmx_nand_block_erase);
 
@@ -1912,23 +2016,23 @@ EXPORT_SYMBOL(cvmx_nand_get_status);
 
 /**
  * Gets the specified feature number
- * 
+ *
  * @param chip     Chip select for NAND flash
  * @param feat_num Feature number to get
  * @param feature  P1 - P4 of the feature data
- * 
+ *
  * @return cvmx_nand_status_t error code
  */
 cvmx_nand_status_t cvmx_nand_get_feature(int chip, uint8_t feat_num,
 					 uint8_t feature[4])
 {
 	int status;
-	
+
 	CVMX_NAND_LOG_CALLED();
 	CVMX_NAND_LOG_PARAM("%d", chip);
 	CVMX_NAND_LOG_PARAM("%d", feat_num);
 	CVMX_NAND_LOG_PARAM("%p", feature);
-	
+
 
 	if ((chip < 0) || (chip > 7))
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
@@ -1949,18 +2053,19 @@ EXPORT_SYMBOL(cvmx_nand_get_feature);
 
 /**
  * Sets the specified feature number
- * 
+ *
  * @param chip     Chip select for NAND flash
  * @param feat_num Feature number to get
  * @param feature  P1 - P4 of the feature data
- * 
+ *
  * @return cvmx_nand_status_t error code
  */
 cvmx_nand_status_t cvmx_nand_set_feature(int chip, uint8_t feat_num,
 					 const uint8_t feature[4])
 {
-	int status;
+	cvmx_nand_status_t status = CVMX_NAND_SUCCESS;
 	cvmx_nand_cmd_t cmd;
+	int nand_selected;
 
 	CVMX_NAND_LOG_CALLED();
 	CVMX_NAND_LOG_PARAM("%d", chip);
@@ -1969,15 +2074,18 @@ cvmx_nand_status_t cvmx_nand_set_feature(int chip, uint8_t feat_num,
 	CVMX_NAND_LOG_PARAM("0x%x", feature[1]);
 	CVMX_NAND_LOG_PARAM("0x%x", feature[2]);
 	CVMX_NAND_LOG_PARAM("0x%x", feature[3]);
-	
+
 	if ((chip < 0) || (chip > 7))
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 	if (feature == NULL)
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 
-	if ((status = __cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_SET_FEATURES,
-						1, feat_num, 0)))
-		CVMX_NAND_RETURN(status);
+	nand_selected = __cvmx_nand_select(1);
+	status = __cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_SET_FEATURES,
+					   1, feat_num, 0);
+	if (status)
+		goto done;
+
 	memcpy(cvmx_nand_buffer, feature, 4);
 	memset(cvmx_nand_buffer + 4, 0, 4);
 
@@ -1986,24 +2094,30 @@ cvmx_nand_status_t cvmx_nand_set_feature(int chip, uint8_t feat_num,
 	cmd.wr.eight = 8;
 	cmd.wr.wrn1 = cvmx_nand_state[chip].wrn[0];
 	cmd.wr.wrn2 = cvmx_nand_state[chip].wrn[1];
-	if (cvmx_nand_submit(cmd))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = cvmx_nand_submit(cmd);
+	if (status)
+		goto done;
 
 	__cvmx_nand_setup_dma(chip, 1, cvmx_ptr_to_phys(cvmx_nand_buffer), 8);
 
-	if (__wait_for_busy_done(chip))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __wait_for_busy_done(chip);
+	if (status)
+		goto done;
 
-	if (__cvmx_nand_build_post_cmd())
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	status = __cvmx_nand_build_post_cmd();
+	if (status)
+		goto done;
 
 	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_NDF_DMA_CFG,
 				  union cvmx_mio_ndf_dma_cfg, en, ==, 0,
 				  NAND_TIMEOUT_USECS_WRITE)) {
 		WATCHDOG_RESET();
-		CVMX_NAND_RETURN(CVMX_NAND_TIMEOUT);
+		status = CVMX_NAND_TIMEOUT;
+		goto done;
 	}
-	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+done:
+	__cvmx_nand_select(nand_selected);
+	CVMX_NAND_RETURN(status);
 }
 EXPORT_SYMBOL(cvmx_nand_set_feature);
 
@@ -2095,6 +2209,8 @@ int cvmx_nand_get_blocks(int chip)
  */
 cvmx_nand_status_t cvmx_nand_reset(int chip)
 {
+	cvmx_nand_status_t status = CVMX_NAND_SUCCESS;
+	int nand_selected;
 	CVMX_NAND_LOG_CALLED();
 	CVMX_NAND_LOG_PARAM("%d", chip);
 
@@ -2103,17 +2219,23 @@ cvmx_nand_status_t cvmx_nand_reset(int chip)
 	if (!cvmx_nand_state[chip].page_size)
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 
-	if (__cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_RESET, 0, 0, 0))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
-
-	/* WAIT for R_B to signal reset is complete  */
-	if (__wait_for_busy_done(chip))
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	nand_selected = __cvmx_nand_select(1);
+	status = __cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_RESET, 0, 0, 0);
+	if (status)
+		goto done;
 
-	if (__cvmx_nand_build_post_cmd())
-		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
 
-	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+	/* WAIT for R_B to signal reset is complete  */
+	status = __wait_for_busy_done(chip);
+	if (status)
+		goto done;
+
+	status = __cvmx_nand_build_post_cmd();
+	if (status)
+		goto done;
+done:
+	__cvmx_nand_select(nand_selected);
+	CVMX_NAND_RETURN(status);
 }
 EXPORT_SYMBOL(cvmx_nand_reset);
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pcie.c b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
index fa2672d..21ae773 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pcie.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2011  Cavium, Inc. <support@cavium.com>.  All rights
+ * Copyright (c) 2003-2013  Cavium, Inc. <support@cavium.com>.  All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 82360 $<hr>
+ * <hr>$Revision: 91009 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -58,6 +58,7 @@
 #include <asm/octeon/cvmx-pemx-defs.h>
 #include <asm/octeon/cvmx-pexp-defs.h>
 #include <asm/octeon/cvmx-pescx-defs.h>
+#include <asm/octeon/cvmx-rst-defs.h>
 #include <asm/octeon/cvmx-sli-defs.h>
 #include <asm/octeon/cvmx-sriox-defs.h>
 #include <asm/octeon/cvmx-helper-jtag.h>
@@ -85,6 +86,7 @@
 #include "cvmx-helper-errata.h"
 #include "cvmx-qlm.h"
 #include "cvmx-bootmem.h"
+#include "cvmx-rst-defs.h"
 #include "octeon_mem_map.h"
 #ifdef __U_BOOT__
 # include <libfdt.h>
@@ -473,6 +475,11 @@ static int __cvmx_pcie_rc_initialize_gen1(int pcie_port)
 	cvmx_pciercx_cfg032_t pciercx_cfg032;
 	cvmx_npei_bar1_indexx_t bar1_index;
 
+	if (pcie_port >= CVMX_PCIE_PORTS) {
+		//cvmx_dprintf("Invalid PCIe%d port\n", pcie_port);
+		return -1;
+	}
+
 retry:
 	/* Make sure we aren't trying to setup a target mode interface in host mode */
 	npei_ctl_status.u64 = cvmx_read_csr(CVMX_PEXP_NPEI_CTL_STATUS);
@@ -794,6 +801,19 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 	cvmx_pciercx_cfg032_t pciercx_cfg032;
 	cvmx_pciercx_cfg448_t pciercx_cfg448;
 
+	/* For CN7XXX we must turn the PEM on */
+	if (OCTEON_IS_OCTEON3()) {
+		cvmx_pemx_on_t pemx_on;
+
+		pemx_on.u64 = cvmx_read_csr(CVMX_PEMX_ON(pcie_port));
+		pemx_on.s.pemon = 1;
+		cvmx_write_csr(CVMX_PEMX_ON(pcie_port), pemx_on.u64);
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_PEMX_ON(pcie_port), cvmx_pemx_on_t, pemoor, ==, 1, 100000)) {
+			cvmx_dprintf("PCIe: Port %d PEM not on, skipping\n", pcie_port);
+			return -1;
+		}
+	}
+
 	/* Bring up the link */
 	pem_ctl_status.u64 = cvmx_read_csr(CVMX_PEMX_CTL_STATUS(pcie_port));
 	pem_ctl_status.s.lnk_enb = 1;
@@ -856,16 +876,27 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	cvmx_sli_mem_access_ctl_t sli_mem_access_ctl;
 	cvmx_sli_mem_access_subidx_t mem_access_subid;
 	cvmx_pemx_bar1_indexx_t bar1_index;
-	uint64_t ciu_soft_prst_reg;
+	uint64_t ciu_soft_prst_reg, rst_ctl_reg;
 	int ep_mode;
 	int qlm = pcie_port;
 	int connected_pcie_reset = -1;
+	enum cvmx_qlm_mode mode = CVMX_QLM_MODE_DISABLED;
+
+	if (pcie_port >= CVMX_PCIE_PORTS) {
+		//cvmx_dprintf("Invalid PCIe%d port\n", pcie_port);
+		return -1;
+	}
 
 	/* Make sure this interface is PCIe */
-	if (octeon_has_feature(OCTEON_FEATURE_PCIE)) {
+	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
+		if (cvmx_qlm_get_dlm_mode(1, pcie_port) == CVMX_QLM_MODE_DISABLED) {
+			cvmx_dprintf("PCIe: Port %d not in PCIe mode, skipping\n",
+						pcie_port);
+			return -1;
+		}
+	} else if (octeon_has_feature(OCTEON_FEATURE_PCIE)) {
 		/* Requires reading the MIO_QLMX_CFG register to figure
 		   out the port type. */
-		enum cvmx_qlm_mode mode;
 		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
 			qlm = 3 - (pcie_port * 2);
 		else if (OCTEON_IS_MODEL(OCTEON_CN61XX)) {
@@ -878,6 +909,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		   2 PCIe ports in x1 */
 		else if (OCTEON_IS_MODEL(OCTEON_CNF71XX))
 			qlm = 1;
+
 		mode = cvmx_qlm_get_mode(qlm);
 		if (mode == CVMX_QLM_MODE_SRIO_1X4 ||
 		    mode == CVMX_QLM_MODE_SRIO_2X2 ||
@@ -896,7 +928,8 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 			return -1;
 		} else if (mode != CVMX_QLM_MODE_PCIE &&
 			   mode != CVMX_QLM_MODE_PCIE_1X2 &&
-			   mode != CVMX_QLM_MODE_PCIE_2X1) {
+			   mode != CVMX_QLM_MODE_PCIE_2X1 &&
+			   mode != CVMX_QLM_MODE_PCIE_1X1) {
 			cvmx_dprintf("PCIe: Port %d is unknown, skipping.\n", pcie_port);
 			return -1;
 		}
@@ -921,10 +954,28 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 #endif
 
 	/* Make sure we aren't trying to setup a target mode interface in host mode */
-	mio_rst_ctl.u64 = cvmx_read_csr(CVMX_MIO_RST_CTLX(pcie_port));
+	if (OCTEON_IS_OCTEON3()) {
+		ciu_soft_prst_reg = CVMX_RST_SOFT_PRSTX(pcie_port);
+		rst_ctl_reg = CVMX_RST_CTLX(pcie_port);
+	} else {
+		ciu_soft_prst_reg = (pcie_port) ?
+				 CVMX_CIU_SOFT_PRST1 : CVMX_CIU_SOFT_PRST;
+		rst_ctl_reg = CVMX_MIO_RST_CTLX(pcie_port);
+	}
+
+	mio_rst_ctl.u64 = cvmx_read_csr(rst_ctl_reg);
 	ep_mode = ((OCTEON_IS_MODEL(OCTEON_CN61XX) ||
-		    OCTEON_IS_MODEL(OCTEON_CNF71XX)) ?
-		(mio_rst_ctl.s.prtmode != 1) : (!mio_rst_ctl.s.host_mode));
+		    OCTEON_IS_MODEL(OCTEON_CNF71XX))
+		? (mio_rst_ctl.s.prtmode != 1) : (!mio_rst_ctl.s.host_mode));
+
+	if (OCTEON_IS_MODEL(OCTEON_CN70XX) && pcie_port) {
+		cvmx_pemx_cfg_t pemx_cfg;
+		pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(0));
+		if ((pemx_cfg.s.md & 3) == 2) {
+			cvmx_dprintf("PCIe: Port %d in 1x4 mode.\n", pcie_port);
+			return -1;
+		}
+	}
 	if (ep_mode) {
 		cvmx_dprintf("PCIe: Port %d in endpoint mode.\n", pcie_port);
 		return -1;
@@ -964,9 +1015,6 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		}
 	}
 
-	ciu_soft_prst_reg = (pcie_port) ?
-				 CVMX_CIU_SOFT_PRST1 : CVMX_CIU_SOFT_PRST;
-
 	/* On some boards, notably the SFF6100 board, the PCIe reset lines
 	 * are miswired in PCIe 2x1 mode.  In 2x1 mode, the PRST line of
 	 * QLM0 should go to PCIe PEM 0 and the PRST line of QLM1 should
@@ -978,10 +1026,10 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 	static void *fdt_addr = 0;
 
-	if (fdt_addr == 0)
+	if (fdt_addr == 0 && mode == CVMX_QLM_MODE_PCIE_2X1)
 		fdt_addr = __cvmx_phys_addr_to_ptr(cvmx_sysinfo_get()->fdt_addr,
 						   OCTEON_FDT_MAX_SIZE);
-	if (fdt_addr) {
+	if (fdt_addr && mode == CVMX_QLM_MODE_PCIE_2X1) {
 		uint32_t *prop;
 		int offset;
 
@@ -995,7 +1043,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		}
 	}
 #else
-	{
+	if (mode == CVMX_QLM_MODE_PCIE_2X1) {
 		struct device_node *node = of_find_node_by_path("/soc@0");
 		if (node) {
 			if (of_property_read_u32(node,
@@ -1083,7 +1131,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	/* Check and make sure PCIe came out of reset. If it doesn't the board
 	   probably hasn't wired the clocks up and the interface should be
 	   skipped */
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_RST_CTLX(pcie_port), cvmx_mio_rst_ctlx_t, rst_done, ==, 1, 10000)) {
+	if (CVMX_WAIT_FOR_FIELD64(rst_ctl_reg, cvmx_mio_rst_ctlx_t, rst_done, ==, 1, 10000)) {
 		cvmx_dprintf("PCIe: Port %d stuck in reset, skipping.\n", pcie_port);
 		return -1;
 	}
@@ -1148,7 +1196,10 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		__cvmx_increment_ba(&mem_access_subid);
 	}
 
-	if (!OCTEON_IS_MODEL(OCTEON_CN61XX)) {
+	if (OCTEON_IS_MODEL(OCTEON_CN63XX) ||
+	    OCTEON_IS_MODEL(OCTEON_CN66XX) ||
+	    OCTEON_IS_MODEL(OCTEON_CN68XX) ||
+	    OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		/* Disable the peer to peer forwarding register. This must be setup
 		   by the OS after it enumerates the bus and assigns addresses to the
 		   PCIe busses */
@@ -1202,7 +1253,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	/* Allow config retries for 250ms. Count is based off the 5Ghz SERDES
 	   clock */
 	pemx_ctl_status.u64 = cvmx_read_csr(CVMX_PEMX_CTL_STATUS(pcie_port));
-	pemx_ctl_status.s.cfg_rtry = 250 * 5000000 / 0x10000;
+	pemx_ctl_status.cn63xx.cfg_rtry = 250 * 5000000 / 0x10000;
 	cvmx_write_csr(CVMX_PEMX_CTL_STATUS(pcie_port), pemx_ctl_status.u64);
 
 	/* Display the link status */
@@ -1469,6 +1520,8 @@ void cvmx_pcie_cfgx_write(int pcie_port, uint32_t cfg_offset, uint32_t val)
 	}
 }
 
+extern int cvmx_pcie_is_host_mode(int pcie_port);
+
 /**
  * Initialize a PCIe port for use in target(EP) mode.
  *
@@ -1478,19 +1531,8 @@ void cvmx_pcie_cfgx_write(int pcie_port, uint32_t cfg_offset, uint32_t val)
  */
 int cvmx_pcie_ep_initialize(int pcie_port)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
-		cvmx_npei_ctl_status_t npei_ctl_status;
-		npei_ctl_status.u64 = cvmx_read_csr(CVMX_PEXP_NPEI_CTL_STATUS);
-		if (npei_ctl_status.s.host_mode)
-			return -1;
-	} else {
-		cvmx_mio_rst_ctlx_t mio_rst_ctl;
-		int ep_mode;
-		mio_rst_ctl.u64 = cvmx_read_csr(CVMX_MIO_RST_CTLX(pcie_port));
-		ep_mode = (OCTEON_IS_MODEL(OCTEON_CN61XX) ? (mio_rst_ctl.s.prtmode != 0) : mio_rst_ctl.s.host_mode);
-		if (ep_mode)
-			return -1;
-	}
+	if (!cvmx_pcie_is_host_mode(pcie_port))
+		return -1;
 
 	/* CN63XX Pass 1.0 errata G-14395 requires the QLM De-emphasis be programmed */
 	if (OCTEON_IS_MODEL(OCTEON_CN63XX_PASS1_0)) {
@@ -1670,3 +1712,32 @@ void cvmx_pcie_wait_for_pending(int pcie_port)
 		}
 	}
 }
+
+/**
+ * Returns if a PCIe port is in host or target mode.
+ *
+ * @param pcie_port PCIe port number (PEM number)
+ *
+ * @return 0 if PCIe port is in target mode, !0 if in host mode.
+ */
+int cvmx_pcie_is_host_mode(int pcie_port)
+{
+	if (OCTEON_IS_OCTEON3()) {
+		cvmx_rst_ctlx_t rst_ctl;
+		rst_ctl.u64 = cvmx_read_csr(CVMX_RST_CTLX(pcie_port));
+		return !!rst_ctl.s.host_mode;
+	} else if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
+		cvmx_npei_ctl_status_t npei_ctl_status;
+		npei_ctl_status.u64 = cvmx_read_csr(CVMX_PEXP_NPEI_CTL_STATUS);
+		return !!npei_ctl_status.s.host_mode;
+	} else {
+		cvmx_mio_rst_ctlx_t mio_rst_ctl;
+
+		mio_rst_ctl.u64 = cvmx_read_csr(CVMX_MIO_RST_CTLX(pcie_port));
+		if (OCTEON_IS_MODEL(OCTEON_CN61XX) ||
+		    OCTEON_IS_MODEL(OCTEON_CNF71XX))
+			return mio_rst_ctl.s.prtmode != 0;
+		else
+			return !!mio_rst_ctl.s.host_mode;
+	}
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
new file mode 100644
index 0000000..6a2b1ef
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
@@ -0,0 +1,278 @@
+/***********************license start***************
+ * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * PKI Support.
+ */
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <linux/module.h>
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-pki-defs.h>
+#include <asm/octeon/cvmx-pki.h>
+#include "asm/octeon/cvmx-global-resources.h"
+#include "asm/octeon/cvmx-range.h"
+#else
+#include "cvmx.h"
+#include "cvmx-version.h"
+#include "cvmx-error.h"
+#include "cvmx-pki.h"
+#include "cvmx-global-resources.h"
+#include "cvmx-range.h"
+#endif
+
+/**
+ * This function allocates/reserves a style from pool of global styles per node.
+ * @param node	 node to allocate style from.
+ * @param style	 style to allocate, if -1 it will be allocated
+                 first available style from style resource. If index is positive
+		 number and in range, it will try to allocate specified style.
+ * @return 	 style number on success, -1 on failure.
+ */
+int cvmx_pki_alloc_style(int node, int style)
+{
+	if(cvmx_create_global_resource_range(CVMX_GR_TAG_STYLE(node),CVMX_PKI_NUM_INTERNAL_STYLES)) {
+		cvmx_dprintf("\nERROR: Failed to create styles global resource\n");
+		return -1;
+	}
+	if(style >= 0) {
+		style = cvmx_reserve_global_resource_range(CVMX_GR_TAG_STYLE(node), style, style,1);
+		if(style == -1){
+			cvmx_dprintf("\nERROR: Failed to reserve style %d\n", (int)style);
+			return -1;
+		}
+	}
+	else {
+		style = cvmx_allocate_global_resource_range(CVMX_GR_TAG_STYLE(node), style, 1,1);
+		if(style == -1){
+			cvmx_dprintf("ERROR: Failed to allocate style %d\n", (int)style);
+			//vinita, define enum later
+			return -1;
+		}
+	}
+	return style;
+}
+
+/**
+ * This function allocates/reserves a cluster group from per node
+   cluster group resources.
+ * @param node	 	node to allocate cluster group from.
+   @param cl_grp	cluster group to allocate/reserve, if -1 ,
+                        allocate any available cluster group.
+ * @param num_clusters	number of clusters that will be attached to
+			the cluster group.
+ * @param parsing_mask  mask of parsing that will be enabled on the cluster group.
+ * @return 	 	cluster group number or -1 on failure
+ */
+int cvmx_pki_alloc_cluster_group(int node, int cl_grp, int num_clusters,
+				 uint64_t parsing_mask, uint64_t *cluster_mask)
+{
+	int cluster = 0;
+
+	if(node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d",node);
+		return -1;
+	}
+
+	if(cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTERS(node),CVMX_PKI_NUM_CLUSTERS)) {
+		cvmx_dprintf("Failed to create Clusters global resource\n");
+		return -1;
+	}
+	if(cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node),CVMX_PKI_NUM_CLUSTER_GROUP)) {
+		cvmx_dprintf("Failed to create Cluster group global resource\n");
+		return -1;
+	}
+
+	if( cl_grp >=0 )
+		cl_grp = cvmx_reserve_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node),0,cl_grp,1);
+
+	else {
+		cl_grp = cvmx_allocate_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node),0,1,1);
+
+		if(cl_grp == -1) {
+			cvmx_dprintf("Warning: Failed to alloc cluster grp %d\n", cl_grp);
+			return -1;
+		}
+	}
+	if(cl_grp >= CVMX_PKI_NUM_CLUSTER_GROUP) {
+		cvmx_dprintf("ERROR: Invalid cluster group %d got allocated\n",cl_grp);
+		return -1;
+	}
+	if(cl_grp == -1) {
+		cvmx_dprintf("Warning: Failed to alloc cluster grp sharing the cluster grp\n");
+		//vinita cl_grp = cvmx_find_global_resource_range_owner(CVMX_GR_TAG_CLUSTER_GRP(node), num_clusters);
+		return -1; //vinita
+	}
+	else {
+		cluster = cvmx_allocate_global_resource_range(CVMX_GR_TAG_CLUSTERS(node),
+				cl_grp, num_clusters, 1);
+		if(cluster >= CVMX_PKI_NUM_CLUSTERS) {
+			cvmx_dprintf("ERROR: Invalid clusters %d got allocated\n", (int)cluster);
+			return -1;
+		}
+		if(cluster == -1) {
+			cvmx_dprintf("Warning: Failed to allocate clusters %d sharing the clusters \n", (int)num_clusters);
+			//vinita cl_grp = cvmx_find_global_resource_range_owner(CVMX_GR_TAG_CLUSTERS(node), num_clusters);
+			//to_do vinita cluster = cvmx_find_global_resource_owner_range(CVMX_GR_TAG_CLUSTERS(node), cl_grp);
+			return -1; //vinita
+		}
+	}
+	if(cl_grp == -1 || cluster == -1){
+			cvmx_dprintf("Failed to allocate Cluster group global resource\n");
+		return -1;
+	}
+	else {
+		*cluster_mask = cvmx_build_mask((uint64_t)((num_clusters-(uint64_t)cluster+1) << cluster));
+		return cl_grp;
+	}
+}
+
+int cvmx_pki_free_cluster_group(int node, int grp_index)
+{
+	if(node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d",node);
+		return -1;
+	}
+
+	//spinlock it
+	if (--pki_config[node].cluster_cfg[grp_index].users) {
+		cvmx_dprintf("ERROR: cluster group %d is in use, can't free it\n", (int)grp_index);
+		return -1;
+	}
+	if (grp_index >= CVMX_PKI_NUM_CLUSTER_GROUP) {
+		cvmx_dprintf("ERROR: Invalid cluster group %d in cvmx_pki_free_cluster_group\n", (int)grp_index);
+		return -1;
+	}
+	if (cvmx_free_global_resource_range_with_owner(CVMX_GR_TAG_CLUSTER_GRP(node), grp_index) == -1) {
+		cvmx_dprintf("ERROR Failed to release cluster group %d\n", (int)grp_index);
+		return -1;
+	}
+	//spinlock it
+	pki_config[node].cluster_cfg[grp_index].users--;
+	return 0;
+}
+
+/**
+ * This function allocates/reserves a pcam entry from node
+ * @param node	 	node to allocate pcam entry from.
+   @param index  	index of pacm entry (0-191), if -1 ,
+                        allocate any available pcam entry.
+ * @param bank		pcam bank where to allocate/reserve pcan entry from
+ * @param cluster_mask  mask of clusters from which pcam entry is needed.
+ * @return 	 	pcam entry of -1 on failure
+ */
+int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_mask)
+{
+	uint64_t cluster=0;
+
+	while( cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if(cluster_mask & (0x01L << cluster)) {
+			if (cvmx_create_global_resource_range(CVMX_GR_TAG_PCAM(node,cluster,bank),
+			    	CVMX_PKI_TOTAL_PCAM_ENTRY)) {
+				cvmx_dprintf("\nFailed to create pki pcam global resource");
+				return -1;
+			}
+			if (index >= 0)
+				index = cvmx_reserve_global_resource_range(CVMX_GR_TAG_PCAM(node,cluster,bank),
+						cluster, index, 1);
+			else
+				index = cvmx_allocate_global_resource_range(CVMX_GR_TAG_PCAM(node,cluster,bank),
+						cluster, 1, 1);
+			if(index == -1) {
+				cvmx_dprintf("Error:index %d not available in cluster %d bank %d",
+						(int)index, (int)cluster, bank);
+				return -1;
+			}
+			cluster++;
+		}
+	}
+	//vinita to_do , implement cluster handle, for now assume
+	//all clusters will have same base index
+	return index;
+}
+
+/**
+ * This function allocates/reserves QPG table entries per node.
+ * @param node	 	node number.
+ * @param base_offset	base_offset in qpg table. If -1, first available
+			qpg base_offset will be allocated. If base_offset is positive
+		 	number and in range, it will try to allocate specified base_offset.
+   @param count		number of consecutive qpg entries to allocate. They will be consecutive
+                        from base offset.
+ * @return 	 	qpg table base offset number on success, -1 on failure.
+ */
+int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count )
+{
+	if(cvmx_create_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node),CVMX_PKI_NUM_QPG_ENTRY)) {
+		cvmx_dprintf("\nERROR: Failed to create qpg_entry global resource\n");
+		return -1;
+	}
+	if(base_offset >= 0) {
+		base_offset = cvmx_reserve_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), base_offset, base_offset,count);
+		if(base_offset == -1){
+			cvmx_dprintf("\nERROR: Failed to reserve qpg entry %d\n", (int)base_offset);
+			return -1;
+		}
+	}
+	else {
+		base_offset = cvmx_allocate_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), base_offset, count,1);
+		if(base_offset == -1){
+			cvmx_dprintf("ERROR: Failed to allocate qpg entry %d\n", (int)base_offset);
+			return -1;
+		}
+	}
+	return base_offset;
+}
+
+/**
+ * This function frees QPG table entries per node.
+ * @param node	 	node number.
+ * @param base_offset	base_offset in qpg table. If -1, first available
+			qpg base_offset will be allocated. If base_offset is positive
+		 	number and in range, it will try to allocate specified base_offset.
+   @param count		number of consecutive qpg entries to allocate. They will be consecutive
+                        from base offset.
+ * @return 	 	qpg table base offset number on success, -1 on failure.
+ */
+int cvmx_pki_free_qpg_entry(int node, int base_offset, int count )
+{
+	return 0;
+	//vinita_to_do
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki.c b/arch/mips/cavium-octeon/executive/cvmx-pki.c
index c286059..bda29bd 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki.c
@@ -47,6 +47,9 @@
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-pki-defs.h>
 #include <asm/octeon/cvmx-pki.h>
+#include <asm/octeon/cvmx-fpa.h>
+#include <asm/octeon/cvmx-pki-cluster.h>
+#include <asm/octeon/cvmx-pki-resources.h>
 #else
 #include "cvmx.h"
 #include "cvmx-version.h"
@@ -54,11 +57,12 @@
 #include "cvmx-pki-defs.h"
 #include "cvmx-pki.h"
 #include "cvmx-fpa.h"
-#endif
-
+#include "cvmx-pki-resources.h"
 #include "cvmx-pki-cluster.h"
+#endif
 
 CVMX_SHARED struct cvmx_pki_config pki_config[CVMX_MAX_NODES];
+CVMX_SHARED struct cvmx_pki_profiles pki_profiles[CVMX_MAX_NODES];
 
 /**
  * This function enables pki
@@ -106,7 +110,6 @@ EXPORT_SYMBOL(cvmx_pki_disable);
  */
 int cvmx_pki_setup_clusters(int node)
 {
-
 	int i;
 	for(i=0; i< cvmx_pki_cluster_code_length; i++)
 		cvmx_write_csr_node(node, CVMX_PKI_IMEMX(i),cvmx_pki_cluster_code_default[i]);
@@ -230,8 +233,6 @@ void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
 	cvmx_pki_clx_stylex_alg_t style_alg_reg;
 	cvmx_pki_stylex_buf_t     style_buf_reg;
 	int cluster = 0;
-	int num_entry;
-	int index;
 
 	//vinita to_do break it differnt functions
 	while( cluster < CVMX_PKI_NUM_CLUSTERS) {
@@ -245,7 +246,7 @@ void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
 			//style_cfg_reg.s.fcs_chk = style_cfg.en_FCS_chk;
 			//style_cfg_reg.s.strip_FCS = style_cfg.strip_l2_FCS;
 			//style_cfg_reg.s.minmax_sel = style_cfg.max_min_frame_sel;
-			style_cfg_reg.s.qpg_base = style_cfg.qpg_cfg.base_offset;
+			style_cfg_reg.s.qpg_base = style_cfg.qpg_base_offset;
 			style_cfg_reg.s.qpg_dis_padd = style_cfg.qpg_calc_port_addr;
 			style_cfg_reg.s.qpg_dis_aura = style_cfg.qpg_calc_aura;
 			style_cfg_reg.s.qpg_dis_grp = style_cfg.qpg_calc_group;
@@ -285,21 +286,12 @@ void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
 		cluster++;
 	}
 	style_buf_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_STYLEX_BUF(style));
-	style_buf_reg.s.first_skip = style_cfg.first_mbuf_skip;
-	style_buf_reg.s.later_skip = style_cfg.later_mbuf_skip;
+	style_buf_reg.s.first_skip = (style_cfg.first_mbuf_skip)/8;
+	style_buf_reg.s.later_skip = style_cfg.later_mbuf_skip/8;
 	style_buf_reg.s.opc_mode = style_cfg.cache_mode;
-	style_buf_reg.s.mb_size = style_cfg.mbuff_size;
+	style_buf_reg.s.mb_size = (style_cfg.mbuff_size)/8;
 	style_buf_reg.s.dis_wq_dat = 0;
 	cvmx_write_csr_node(node,CVMX_PKI_STYLEX_BUF(style), style_buf_reg.u64);
-
-	num_entry = style_cfg.qpg_cfg.num_entries;
-	index = style_cfg.qpg_cfg.base_offset;
-	while(num_entry--) {
-		cvmx_pki_write_qpg_entry(node, index, style_cfg.qpg_cfg.qpg_entry[num_entry].port_add,
-					   style_cfg.qpg_cfg.qpg_entry[num_entry].aura, style_cfg.qpg_cfg.qpg_entry[num_entry].grp_ok,
-					   style_cfg.qpg_cfg.qpg_entry[num_entry].grp_bad);
-		index++;
-	}
 }
 
 
@@ -384,7 +376,7 @@ int cvmx_pki_enable_aura_qos(int node, int aura, bool ena_red,
 	pki_aura_cfg.s.ena_red = ena_red;
 	pki_aura_cfg.s.ena_drop = ena_drop;
 	pki_aura_cfg.s.ena_bp = ena_bp;
-	cvmx_write_csr_node(node, CVMX_PKI_AURAX_CFG(aura),pki_aura_cfg.u64 );
+	cvmx_write_csr_node(node, CVMX_PKI_AURAX_CFG(aura),pki_aura_cfg.u64);
 	return 0;
 }
 
@@ -452,7 +444,7 @@ int cvmx_pki_frame_len_check(int node, int id, int maxframesize, int minframesiz
 	return 0;
 }
 
-int cvmx_pki_config_l2_frame_len(int node, uint64_t maxframesize, uint64_t minframesize)
+int cvmx_pki_set_l2_frame_len(int node, uint64_t maxframesize, uint64_t minframesize)
 {
 	if (cvmx_pki_frame_len_check(node,0,maxframesize, minframesize)) {
 		if (cvmx_pki_frame_len_check(node,1,maxframesize, minframesize)) {
@@ -465,38 +457,468 @@ int cvmx_pki_config_l2_frame_len(int node, uint64_t maxframesize, uint64_t minfr
 		return 0;
 }
 
+/**
+ * This function finds if cluster profile with name already exist
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	profile index in cluster list on SUCCESS
+                -1 if profile not found in cluster list
+ */
+int cvmx_pki_cluster_profile_exist(int node, char *name)
+{
+	int index = pki_profiles[node].cl_profile_list.index;
+
+	while(index--)
+	{
+		if(strcmp(name,pki_profiles[node].cl_profile_list.cl_profile[index].name) == 0)
+			return index;
+	}
+	return -1;
+}
+
+/**
+ * This function finds cluster mask associated with
+ * given cluster profile name.
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	cluster_mask on SUCCESS
+                -1 if profile not found in cluster list
+ */
+int cvmx_pki_find_cluster_mask(int node, char *name)
+{
+	int index;
+	int cl_grp;
+
+	if((index = cvmx_pki_cluster_profile_exist(node,name)) == -1)
+		return -1;
+
+	cl_grp = pki_profiles[node].cl_profile_list.cl_profile[index].cluster_group;
+	return pki_config[node].cluster_cfg[cl_grp].cluster_mask;
+
+}
+
+/**
+ * This function finds cluster group associated with
+ * given cluster profile name
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	cluster group number on SUCCESS
+                -1 if profile not found in cluster list
+ */
+int cvmx_pki_find_cluster_group(int node, char *name)
+{
+	int index;
+
+	if((index = cvmx_pki_cluster_profile_exist(node,name)) == -1)
+		return -1;
+	return pki_profiles[node].cl_profile_list.cl_profile[index].cluster_group;
+}
+
+/**
+ * This function finds if fpa pool profile with
+ * name already exist
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	profile index in pool list on SUCCESS
+                -1 if profile not found in pool list
+ */
+int cvmx_pki_pool_profile_exist(int node, char *name)
+{
+	int index = pki_profiles[node].pool_profile_list.index;
+
+	while(index--)
+	{
+		if(strcmp(name,pki_profiles[node].pool_profile_list.pool_profile[index].pool_name) == 0) {
+			return index;
+		}
+	}
+	return -1;
+}
+
+/**
+ * This function finds if fpa pool number associated with
+ * given profile name
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	pool number on SUCCESS
+                -1 if profile not found in pool list
+ */
+int cvmx_pki_find_pool(int node, char *name)
+{
+	int index;
+
+	if((index = cvmx_pki_pool_profile_exist(node,name)) == -1)
+		return -1;
+	return pki_profiles[node].pool_profile_list.pool_profile[index].pool_cfg.pool_num;
+}
+
+/**
+ * This function finds if fpa aura with given name
+ * exist in aura list
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	aura index in aura list on SUCCESS
+                -1 if profile not found in aura list
+ */
+int cvmx_pki_aura_profile_exist(int node, char *name)
+{
+	int index = pki_profiles[node].aura_profile_list.index;
+
+	while(index--)
+	{
+		if(strcmp(name,pki_profiles[node].aura_profile_list.aura_profile[index].aura_name) == 0)
+			return index;
+	}
+	return -1;
+}
+
+/**
+ * This function finds aura number associated with
+ * given aura name.
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	aura number in aura list on SUCCESS
+                -1 if profile not found in aura list
+ */
+int cvmx_pki_find_aura(int node, char *name)
+{
+	int index;
+
+	if((index = cvmx_pki_aura_profile_exist(node,name)) == -1)
+		return -1;
+	return pki_profiles[node].aura_profile_list.aura_profile[index].aura_num;
+}
+
+/**
+ * This function finds if group with given name
+ * exist in group list
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	index in group list on SUCCESS
+                -1 if profile not found in group list
+ */
+int cvmx_pki_group_profile_exist(int node, char *name)
+{
+	int index = pki_profiles[node].sso_grp_profile_list.index;
+
+	while(index--)
+	{
+		if(strcmp(name,pki_profiles[node].sso_grp_profile_list.grp_profile[index].grp_name) == 0)
+			return index;
+	}
+	return -1;
+}
+
+/**
+ * This function finds group number associated with
+ * given group profile name
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	group number on SUCCESS
+                -1 if profile not found in group list
+ */
+int cvmx_pki_find_group(int node, char *name)
+{
+	int index;
+
+	if((index = cvmx_pki_group_profile_exist(node,name)) == -1)
+		return -1;
+	return pki_profiles[node].sso_grp_profile_list.grp_profile[index].grp_num;
+}
+
+/**
+ * This function finds if qpg profile with given name
+ * exist in qpg list
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	index in qpg list on SUCCESS
+                -1 if profile not found in qpg list
+ */
+int cvmx_pki_qpg_profile_exist(int node, char *name)
+{
+	int index = pki_profiles[node].qpg_profile_list.index;
+
+	while(index--)
+	{
+		if(strcmp(name,pki_profiles[node].qpg_profile_list.qpg_profile[index].qpg_name) == 0)
+			return index;
+	}
+	return -1;
+}
+
+/**
+ * This function finds qpg base offset associated with
+ * given qpg profile name.
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	qpg base offset on SUCCESS
+                -1 if profile not found in qpg list
+ */
+int cvmx_pki_find_qpg_base_offset(int node, char *name)
+{
+	int index;
+
+	if((index = cvmx_pki_qpg_profile_exist(node,name)) == -1)
+		return -1;
+	return pki_profiles[node].qpg_profile_list.qpg_profile[index].base_offset;
+}
+
+/**
+ * This function get the buffer size of the given pool number
+ * @param node  node number
+ * @param pool  fpa pool number
+ * @return 	buffer size SUCCESS
+                -1 if pool number is not found in pool list
+ */
+int cvmx_pki_get_pool_buffer_size(int node,int pool)
+{
+	int index = pki_profiles[node].aura_profile_list.index;
+
+	while(index--)
+	{
+		if(pki_profiles[node].pool_profile_list.pool_profile[index].pool_cfg.pool_num == pool) {
+			return pki_profiles[node].pool_profile_list.pool_profile[index].pool_cfg.buffer_size;
+		}
+	}
+	return -1;
+}
+
+/**
+ * This function get the buffer size of the given aura number
+ * @param node  node number
+ * @param pool  fpa aura number
+ * @return 	buffer size SUCCESS
+                -1 if aura number is not found in aura list
+ */
+int cvmx_pki_get_aura_buffer_size(int node, int aura)
+{
+	int index = pki_profiles[node].aura_profile_list.index;
+	int pool_num;
+
+	while(index--)
+	{
+		if(pki_profiles[node].aura_profile_list.aura_profile[index].aura_num == aura) {
+			pool_num = pki_profiles[node].aura_profile_list.aura_profile[index].pool_num;
+			return cvmx_pki_get_pool_buffer_size(node,pool_num);
+		}
+	}
+	return -1;
+}
+
+int cvmx_pki_get_mbuff_size (int node, int base_offset)
+{
+	int index = pki_profiles[node].qpg_profile_list.index;
+	int aura;
+	int min_size;
+	int aura_size;
+	int i;
+
+	while(index--)
+	{
+		if(pki_profiles[node].qpg_profile_list.qpg_profile[index].base_offset == base_offset) {
+			int num_entry = pki_profiles[node].qpg_profile_list.qpg_profile[index].num_entries;
+			aura = pki_config[node].qpg_cfg[base_offset].aura;
+			min_size = cvmx_pki_get_aura_buffer_size(node,aura);
+			for(i=1; i < num_entry; i++) {
+				aura = pki_config[node].qpg_cfg[base_offset+i].aura;
+				aura_size = cvmx_pki_get_aura_buffer_size(node,aura);
+				if(min_size > aura_size)
+					min_size = aura_size;
+			}
+			return min_size;
+		}
+	}
+	return -1;
+}
+
+/**
+ * This function finds if style profile with given name
+ * exist in style list
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	index into style list on SUCCESS
+                -1 if profile not found in style list
+ */
+int cvmx_pki_style_profile_exist(int node, char *name)
+{
+	int index = pki_profiles[node].style_profile_list.index;
+
+	while(index--)
+	{
+		if(strcmp(name,pki_profiles[node].style_profile_list.style_profile[index].name) == 0)
+			return index;
+	}
+	return -1;
+}
+
+/**
+ * This function finds style number associated with
+ * given style profile name.
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	style number on SUCCESS
+                -1 if profile not found in style list
+ */
+int cvmx_pki_find_style(int node, char *name)
+{
+	int index;
+
+	if((index = cvmx_pki_style_profile_exist(node,name)) == -1)
+		return -1;
+	return pki_profiles[node].style_profile_list.style_profile[index].style_num;
+}
 
-int cvmx_pki_config_cluster_group(int node, char *name, int cluster_group, uint64_t cluster_mask)
+/**
+ * This function stores the cluster configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param name  	name associated with this config
+ * @param cl_profile    structure containing cluster profile parameters below
+ * 			-cluster_group (-1 if needs to be allocated)
+ * 			-num_cluster   (number of cluster in the cluster group)
+ * 			-parsing_mask  (parsing mask for the cluster group)
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_cluster_config(int node, struct cvmx_pki_cluster_profile cl_profile)
 {
 	int index;
+	int cluster_group;
+	uint64_t cluster_mask;
 
 	if(node >= CVMX_MAX_NODES) {
 		cvmx_dprintf("Invalid node number %d",node);
 		return -1;
 	}
+	if(cvmx_pki_cluster_profile_exist(node,cl_profile.name) >= 0) {
+		cvmx_dprintf("ERROR:cluster profile already exist with name %s",cl_profile.name);
+		return -1;
+	}
+	if((cluster_group = cvmx_pki_alloc_cluster_group(node, cl_profile.cluster_group,
+	    cl_profile.num_clusters, cl_profile.parsing_mask, &cluster_mask)) == -1) {
+		cvmx_dprintf("ERROR:allocating cluster_group\n");
+		return -1;
+	}
+	cl_profile.cluster_group = cluster_group;
 	//spinlock it
-	index = pki_config[node].cluster_list.index;
+	index = pki_profiles[node].cl_profile_list.index;
 
 	if(index >= CVMX_PKI_MAX_CLUSTER_PROFILES) {
 		cvmx_dprintf("ERROR: Max cluster profiles %d reached\n", index);
 		return -1;
 	}
+	pki_profiles[node].cl_profile_list.index++;
+	//spinlock free
+
+	pki_profiles[node].cl_profile_list.cl_profile[index] = cl_profile;
+	pki_config[node].cluster_cfg[cluster_group].cluster_mask = cluster_mask;
+	return 0;
+}
+
+/**
+ * This function stores the pool configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pool_name  	name associated with this config
+ * @param pool_numb     pool number (-1 if need to be allocated)
+ * @param buffer_size	size of buffers in specified pool
+ * @param num_buffers	numberof buffers in specified pool
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_pool_config(int node, char* pool_name, int pool_num,
+			     uint64_t buffer_size, uint64_t num_buffers)
+{
+	uint64_t index;
+	struct cvmx_pki_pool_profile* pool_profile;
+
+	if(node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d",node);
+		return -1;
+	}
+	if(cvmx_pki_pool_profile_exist(node, pool_name) >= 0) {
+		cvmx_dprintf("ERROR:pool profile already exist with name %s",pool_name);
+		return -1;
+	}
+	if(cvmx_fpa_allocate_fpa_pools(node,&pool_num,1) == -1) {
+		cvmx_dprintf("ERROR:allocating pool for pool_config\n");
+		return -1;
+	}
+
+	//spinlock it
+	index = pki_profiles[node].pool_profile_list.index;
+	if(index >= CVMX_PKI_MAX_POOL_PROFILES) {
+		cvmx_dprintf("ERROR: Max pool profile %d reached\n", (int)index);
+		return -1;
+
+	}
+	pki_profiles[node].pool_profile_list.index++;
 	//spinlock free
-	pki_config[node].cluster_list.cl_profile[index].cl_group = (uint64_t)cluster_group;
-	pki_config[node].cluster_list.cl_profile[index].cl_mask = cluster_mask;
-	if(strlen(name) > CVMX_PKI_MAX_NAME) {
-		cvmx_dprintf("ERROR: cluster profile name exceeds max length of %d\n",
-			     (int)CVMX_PKI_MAX_NAME);
+
+	pool_profile = &pki_profiles[node].pool_profile_list.pool_profile[index];
+	strcpy(pool_profile->pool_name, pool_name);
+	pool_profile->pool_cfg.pool_num = pool_num;
+	pool_profile->pool_cfg.buffer_size = buffer_size;
+	pool_profile->pool_cfg.buffer_count = num_buffers;
+	return 0;
+}
+
+/**
+ * This function stores the aura configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param aura_name  	name associated with this config
+ * @param aura_num      aura number (-1 if need to be allocated)
+ * @param pool  	pool to which aura is mapped
+ * @param num_buffers	number of buffers to allocate to aura.
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_aura_config(int node, char* aura_name, int aura_num, int pool,
+			      int num_buffers)
+{
+	uint64_t index;
+	struct cvmx_pki_aura_profile* aura_profile;
+
+	if(node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d",node);
 		return -1;
 	}
-	strcpy(pki_config[node].cluster_list.cl_profile[index].name, name);
-	pki_config[node].cluster_list.index++;
+	if(cvmx_pki_aura_profile_exist(node,aura_name) >= 0) {
+		cvmx_dprintf("ERROR:aura profile already exist with name %s",aura_name);
+		return -1;
+	}
+	if((aura_num = cvmx_fpa_allocate_auras(node,&aura_num,1)) == -1) {
+		cvmx_dprintf("ERROR:allocating aura for aura_config\n");
+		return -1;
+	}
+	//spinlock it
+	index = pki_profiles[node].aura_profile_list.index;
+	if(index >= CVMX_PKI_MAX_AURA_PROFILES) {
+		cvmx_dprintf("ERROR: Max aura profile %d reached\n", (int)index);
+		return -1;
+
+	}
+	pki_profiles[node].aura_profile_list.index++;
+	//spinlock free
+
+	aura_profile = &pki_profiles[node].aura_profile_list.aura_profile[index];
+	strcpy(aura_profile->aura_name, aura_name);
+	aura_profile->aura_num = aura_num;
+	aura_profile->pool_num = pool;
+	aura_profile->buffer_count = num_buffers;
 	return 0;
 }
 
-int cvmx_pki_pcam_config_entry(int node,uint64_t cl_mask,
-			       struct cvmx_pki_pcam_input input,
-			       struct cvmx_pki_pcam_action action)
+/**
+ * This function stores the group configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param grp_profile	struct to SSO group profile to configure
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_sso_group_config(int node, struct cvmx_pki_sso_grp_profile grp_profile)
 {
 	uint64_t index;
 
@@ -504,27 +926,249 @@ int cvmx_pki_pcam_config_entry(int node,uint64_t cl_mask,
 		cvmx_dprintf("Invalid node number %d",node);
 		return -1;
 	}
+	if(cvmx_pki_group_profile_exist(node, grp_profile.grp_name) >= 0) {
+		cvmx_dprintf("ERROR:group profile already exist with name %s",grp_profile.grp_name);
+		return -1;
+	}
+#if 0 //vinita_to_do uncomment when group_alloc is ready
+	if((group = cvmx_pki_allocate_group(node,group)) == -1) {
+		cvmx_dprintf("ERROR:allocating group for group_config\n");
+		return -1;
+	}
+#endif
 
 	//spinlock it
-	index = pki_config[node].pcam_list.index;
-	if(index >= CVMX_PKI_TOTAL_PCAM_ENTRY) {
-		cvmx_dprintf("ERROR: Max pcam lists %d reached\n", (int)index);
+	index = pki_profiles[node].sso_grp_profile_list.index;
+	if(index >= CVMX_PKI_MAX_SSO_GROUP_PROFILES) {
+		cvmx_dprintf("ERROR: Max group profile %d reached\n", (int)index);
+		return -1;
+
+	}
+	pki_profiles[node].sso_grp_profile_list.index++;
+	//spinlock free
+
+	pki_profiles[node].sso_grp_profile_list.grp_profile[index] = grp_profile;
+	return 0;
+
+}
+
+/**
+ * This function stores the qpg configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param name  	name associated with this config
+ * @param base_offset	offset in QPG table (-1 if needs to be allocated)
+ * @param num_entries	total number of indexes needs to be allocated from
+ *                      base_offset.
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_qpg_profile(int node, char* name, int base_offset, int num_entries)
+{
+	int64_t index;
+	struct cvmx_pki_qpg_profile* qpg_profile;
+
+	if(node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d",node);
+		return -1;
+	}
+	if(cvmx_pki_qpg_profile_exist(node,name) >= 0) {
+		cvmx_dprintf("ERROR:qpg profile already exist with name %s",name);
+		return -1;
+	}
+	if((base_offset = cvmx_pki_alloc_qpg_entry(node,base_offset,num_entries)) == -1) {
+		cvmx_dprintf("ERROR:allocating entry for qpg_table\n");
+		return -1;
+	}
+
+	//spinlock it
+	index = pki_profiles[node].qpg_profile_list.index;
+	if(index >= CVMX_PKI_MAX_QPG_PROFILES) {
+		cvmx_dprintf("ERROR: Max qpg profile %d reached\n", (int)index);
 		return -1;
 
 	}
+	pki_profiles[node].qpg_profile_list.index++;
 	//spinlock free
 
-	pki_config[node].pcam_list.pcam_cfg[index].cluster_mask = cl_mask;
-	pki_config[node].pcam_list.pcam_cfg[index].pcam_input = input;
-	pki_config[node].pcam_list.pcam_cfg[index].pcam_action = action;
-	pki_config[node].pcam_list.index++;
+	qpg_profile = &pki_profiles[node].qpg_profile_list.qpg_profile[index];
+	strcpy(qpg_profile->qpg_name, name);
+	qpg_profile->base_offset = base_offset;
+	qpg_profile->num_entries = num_entries;
+	return 0;
+}
+
+/**
+ * This function stores the group configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param aura_name  	name associated with this config
+ * @param group		SSO group number (-1 if needs to be allocated)
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_qpg_config(int node, char* name, int entry_start,
+			    int entry_end, struct cvmx_pki_qpg_config qpg_config)
+{
+	int index;
+	int base_offset;
+	int num_entry;
+
+	if(node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d",node);
+		return -1;
+	}
+	if((index = cvmx_pki_qpg_profile_exist(node,name)) < 0) {
+		cvmx_dprintf("ERROR:qpg profile %s not found\n",name);
+		return -1;
+	}
+	if ((base_offset = pki_profiles[node].qpg_profile_list.qpg_profile[index].base_offset) < 0) {
+		cvmx_dprintf("ERROR: invalid base offset %d in qpg profile %s",base_offset,name);
+		return -1;
+	}
+	num_entry = pki_profiles[node].qpg_profile_list.qpg_profile[index].num_entries;
+	if(entry_start > num_entry || entry_end > num_entry) {
+		cvmx_dprintf("ERROR: start_entry %llu or end_entry %llu is > %llu for qpg_profile %s",
+			     (unsigned long long)entry_start,(unsigned long long)entry_end,(unsigned long long)num_entry,name);
+	}
+	while(entry_start <= entry_end) {
+		pki_config[node].qpg_cfg[base_offset + entry_start] = qpg_config;
+		entry_start++;
+	}
 	return 0;
 }
 
-int cvmx_pki_config_QPG_entry(void)
+/**
+ * This function stores the style configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param aura_name  	name associated with this config
+ * @param style_num	style number (-1 if needs to be allocated)
+ * @param style_cfg	pointer to struct which has parameters related
+ *                      to style config
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_style_config(int node, char* style_name, int style_num,
+			       struct cvmx_pki_style_config* style_cfg)
 {
+	uint64_t index;
+	struct cvmx_pki_style_profile* style_profile;
+
+	if(node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d",node);
+		return -1;
+	}
+	if(cvmx_pki_style_profile_exist(node,style_name) > 0) {
+		cvmx_dprintf("ERROR: style profile already exist with name %s",style_name);
+		return -1;
+	}
+	if((style_num = cvmx_pki_alloc_style(node,style_num)) == -1) {
+		cvmx_dprintf("ERROR:allocating style for style_config\n");
+		return -1;
+	}
+
+	//spinlock it
+	index = pki_profiles[node].style_profile_list.index;
+	if(index >= CVMX_PKI_MAX_STYLE_PROFILES) {
+		cvmx_dprintf("ERROR: Max style profile %d reached\n", (int)index);
+		return -1;
+
+	}
+	pki_profiles[node].style_profile_list.index++;
+	//spinlock free
+
+	style_profile = &pki_profiles[node].style_profile_list.style_profile[index];
+	strcpy(style_profile->name, style_name);
+	style_profile->style_num = style_num;
+	memcpy(&pki_config[node].style_cfg[style_num], style_cfg, sizeof(struct cvmx_pki_style_config));
+	return index;
+}
+
+/**
+ * This function stores the pkind style configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pkind  	pkind number
+ * @param style		style number which need to be assigned to pkind
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_pkind_style(int node, int pkind, int style)
+{
+	pki_config[node].pkind_cfg[pkind].initial_style = style;
+	pki_config[node].style_cfg[style].cluster_mask = pki_config[node].pkind_cfg[pkind].cluster_mask;
 	return 0;
+}
+
+/**
+ * This function stores the pkind initial parse mode in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pkind  	pkind number
+ * @param parse_mode    parse mode to assign to specified pkind.
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+void cvmx_pki_set_pkind_initial_parse_mode(int node, int pkind, int parse_mode)
+{
+	pki_config[node].pkind_cfg[pkind].parsing_mode=parse_mode;
+}
+
+/**
+ * This function stores the pkind cluster configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pkind  	pkind number
+ * @param style_name	pointer to style name which need to be assigned to pkind
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+void cvmx_pki_set_pkind_cluster_config(int node, int pkind,
+					   int cl_grp, uint64_t cl_mask)
+{
+	pki_config[node].pkind_cfg[pkind].cluster_grp = cl_grp;
+	pki_config[node].pkind_cfg[pkind].cluster_mask = cl_mask;
+
+}
+
+/**
+ * This function stores the pcam entry in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pcam_index	which pcam entry to configure (-1 to allocate from available entries)
+ * @param cluster_mask	Mask of clusters on which the entry meeds to be appiled.
+ * @param input		structure of pcam input parameter which defines matching creteria.
+ * @param action	structure of pcam action parameters which aill be applied if match is found.
+ * @return              0 on scuccess
+ *			-1 on failure
+ */
+int cvmx_pki_set_pcam_entry(int node, int pcam_index, uint64_t cl_mask,
+			       struct cvmx_pki_pcam_input input,
+			       struct cvmx_pki_pcam_action action)
+{
+	uint64_t index;
+
+	if(node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d",node);
+		return -1;
+	}
+
+	//spinlock it
+	index = pki_profiles[node].pcam_list.index;
+	if(index >= CVMX_PKI_TOTAL_PCAM_ENTRY) {
+		cvmx_dprintf("ERROR: Max pcam lists %d reached\n", (int)index);
+		return -1;
 
+	}
+	pki_profiles[node].pcam_list.index++;
+	//spinlock free
+
+	pki_profiles[node].pcam_list.pcam_cfg[index].cluster_mask = cl_mask;
+	pki_profiles[node].pcam_list.pcam_cfg[index].entry_num = pcam_index;
+	pki_profiles[node].pcam_list.pcam_cfg[index].pcam_input = input;
+	pki_profiles[node].pcam_list.pcam_cfg[index].pcam_action = action;
+	return 0;
 }
 
 /**
@@ -597,3 +1241,51 @@ void cvmx_pki_show_valid_pcam_entries(int node)
 	}
 }
 
+/**
+ * This function shows the pkind attributes in readable format,
+ * read directly from hardware.
+ * @param node    node number
+ */
+void cvmx_pki_show_pkind_attributes(int node, int pkind)
+{
+	int cluster=0;
+	int index;
+	cvmx_pki_pkindx_icgsel_t pkind_clsel;
+	cvmx_pki_clx_pkindx_style_t pkind_cfg_style;
+	cvmx_pki_icgx_cfg_t pki_cl_grp;
+	cvmx_pki_clx_stylex_cfg_t style_cfg;
+	cvmx_pki_clx_stylex_alg_t style_alg;
+
+	if(pkind >= CVMX_PKI_NUM_PKIND) {
+		cvmx_dprintf("ERROR: PKIND %d is beyond range\n", pkind);
+		return;
+	}
+	pkind_clsel.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKINDX_ICGSEL(pkind));
+	cvmx_dprintf("cluster group:	%d\n", pkind_clsel.s.icg);
+	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(pkind_clsel.s.icg));
+	cvmx_dprintf("cluster mask of the group:	0x%x\n",pki_cl_grp.s.clusters);
+
+	while( cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if(pki_cl_grp.s.clusters & (0x01L << cluster)) {
+			//vinita_to_do later modify in human readble format or now just print register value
+			pkind_cfg_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(pkind, cluster));
+			cvmx_dprintf("initial parse Mode: %d\n",pkind_cfg_style.s.pm);
+			cvmx_dprintf("initial_style: %d\n", pkind_cfg_style.s.style);
+			style_alg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(pkind_cfg_style.s.style, cluster));
+			cvmx_dprintf("style_alg: 0x%llx\n", (unsigned long long)style_alg.u64);
+			style_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(pkind_cfg_style.s.style, cluster));
+			cvmx_dprintf("style_cfg: 0x%llx\n", (unsigned long long)style_cfg.u64);
+			cvmx_dprintf("style_cfg2: 0x%llx\n",
+				     (unsigned long long)cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(pkind_cfg_style.s.style, cluster)));
+			cvmx_dprintf("style_buf: 0x%llx\n",
+				     (unsigned long long)cvmx_read_csr_node(node, CVMX_PKI_STYLEX_BUF(pkind_cfg_style.s.style)));
+			break;
+		}
+	}
+	cvmx_dprintf("qpg base: %d\n",style_cfg.s.qpg_base);
+	cvmx_dprintf("qpg qos: %d\n",style_alg.s.qpg_qos);
+	for(index=0; index < 8; index++) {
+		cvmx_dprintf("qpg index %d: 0x%llx\n", (index+style_cfg.s.qpg_base),
+			     (unsigned long long)cvmx_read_csr_node(node, CVMX_PKI_QPG_TBLX(style_cfg.s.qpg_base+index)));
+	}
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-qlm.c b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
index 85e80a1..bf9dfb7 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-qlm.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2011  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2011-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 84617 $<hr>
+ * <hr>$Revision: 90025 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -51,9 +51,17 @@
 #include <asm/octeon/cvmx-qlm.h>
 #include <asm/octeon/cvmx-clock.h>
 #include <asm/octeon/cvmx-gmxx-defs.h>
+#include <asm/octeon/cvmx-gserx-defs.h>
 #include <asm/octeon/cvmx-sriox-defs.h>
 #include <asm/octeon/cvmx-sriomaintx-defs.h>
 #include <asm/octeon/cvmx-pciercx-defs.h>
+#include <asm/octeon/cvmx-pemx-defs.h>
+#elif defined(CVMX_BUILD_FOR_UBOOT)
+#include <common.h>
+#include <asm/arch/cvmx.h>
+#include <asm/arch/cvmx-bootmem.h>
+#include <asm/arch/cvmx-helper-jtag.h>
+#include <asm/arch/cvmx-qlm.h>
 #else
 #include "cvmx.h"
 #include "cvmx-bootmem.h"
@@ -61,6 +69,10 @@
 #include "cvmx-qlm.h"
 #endif
 
+#ifdef CVMX_BUILD_FOR_UBOOT
+DECLARE_GLOBAL_DATA_PTR;
+#endif
+
 /**
  * The JTAG chain for CN52XX and CN56XX is 4 * 268 bits long, or 1072.
  * CN5XXX full chain shift is:
@@ -133,6 +145,20 @@ int cvmx_qlm_interface(int interface)
 			return 0;
 		else
 			cvmx_dprintf("Warning: cvmx_qlm_interface: Invalid interface %d\n", interface);
+	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		switch (interface) {
+		case 0:
+			return MUX_78XX_IFACE0 ? 2 : 0;
+		case 1:
+			return MUX_78XX_IFACE1 ? 3 : 1;
+		case 2:
+		case 3:
+		case 4:
+		case 5:
+			return interface + 2;
+		default:
+			break;
+		}
 	} else {
 		/* Must be cn68XX */
 		switch (interface) {
@@ -220,6 +246,9 @@ void cvmx_qlm_init(void)
 	static uint64_t qlm_base = 0;
 	const cvmx_bootmem_named_block_desc_t *desc;
 
+	if (OCTEON_IS_OCTEON3())
+		return;
+
 #ifndef CVMX_BUILD_FOR_LINUX_HOST
 	/* Skip actual JTAG accesses on simulator */
 	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM)
@@ -678,14 +707,223 @@ int cvmx_qlm_get_gbaud_mhz(int qlm)
 		default:
 			return 0;	/* Disabled */
 		}
+	} else if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
+		cvmx_gserx_dlmx_mpll_multiplier_t mpll_multiplier;
+		uint64_t meas_refclock;
+		uint64_t freq;
+
+		/* Measure the reference clock */
+		meas_refclock = cvmx_qlm_measure_clock(qlm);
+		/* Multiply to get the final frequency */
+		mpll_multiplier.u64 = cvmx_read_csr(CVMX_GSERX_DLMX_MPLL_MULTIPLIER(qlm, 0));
+		freq = meas_refclock * mpll_multiplier.s.mpll_multiplier;
+		freq = (freq + 500000) / 1000000;
+		return freq;
 	}
 	return 0;
 }
 
+static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn70xx(int qlm)
+{
+#ifndef CVMX_BUILD_FOR_LINUX_HOST
+	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+		union cvmx_gserx_dlmx_phy_reset phy_reset;
+
+		phy_reset.u64 = cvmx_read_csr(CVMX_GSERX_DLMX_PHY_RESET(qlm, 0));
+		if (phy_reset.s.phy_reset)
+			return CVMX_QLM_MODE_DISABLED;
+
+	}
+#endif
+
+	switch(qlm) {
+	case 0: /* DLM0/DLM1 - SGMII/QSGMII/RXAUI */
+		{
+			union cvmx_gmxx_inf_mode inf_mode0, inf_mode1;
+
+			inf_mode0.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(0));
+			inf_mode1.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(1));
+
+			/* SGMII0 SGMII1 */
+			switch (inf_mode0.s.mode) {
+			case CVMX_GMX_INF_MODE_SGMII:
+				switch (inf_mode1.s.mode) {
+				case CVMX_GMX_INF_MODE_SGMII:
+					return CVMX_QLM_MODE_SGMII_SGMII;
+				case CVMX_GMX_INF_MODE_QSGMII:
+					return CVMX_QLM_MODE_SGMII_QSGMII;
+				default:
+					return CVMX_QLM_MODE_SGMII_DISABLED;
+				}
+			case CVMX_GMX_INF_MODE_QSGMII:
+				switch (inf_mode1.s.mode) {
+				case CVMX_GMX_INF_MODE_SGMII:
+					return CVMX_QLM_MODE_QSGMII_SGMII;
+				case CVMX_GMX_INF_MODE_QSGMII:
+					return CVMX_QLM_MODE_QSGMII_QSGMII;
+				default:
+					return CVMX_QLM_MODE_QSGMII_DISABLED;
+				}
+			case CVMX_GMX_INF_MODE_RXAUI:
+				return CVMX_QLM_MODE_RXAUI_1X2;
+			default:
+				return CVMX_QLM_MODE_DISABLED;
+			}
+		}
+	case 1:  /* Sata / pem0 */
+		{
+			union cvmx_gserx_sata_cfg sata_cfg;
+			union cvmx_pemx_cfg pem0_cfg;
+
+			sata_cfg.u64 = cvmx_read_csr(CVMX_GSERX_SATA_CFG(0));
+			pem0_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(0));
+
+			switch(pem0_cfg.cn70xx.md) {
+			case CVMX_PEM_MD_GEN2_2LANE:
+			case CVMX_PEM_MD_GEN1_2LANE:
+				return CVMX_QLM_MODE_PCIE_1X2;
+			case CVMX_PEM_MD_GEN2_1LANE:
+			case CVMX_PEM_MD_GEN1_1LANE:
+				if (sata_cfg.s.sata_en)
+					/* Both PEM0 and PEM1 */
+					return CVMX_QLM_MODE_PCIE_2X1;
+				else
+					/* Only PEM0 */
+					return CVMX_QLM_MODE_PCIE_1X1;
+			case CVMX_PEM_MD_GEN2_4LANE:
+			case CVMX_PEM_MD_GEN1_4LANE:
+				return CVMX_QLM_MODE_PCIE;
+			default:
+				return CVMX_QLM_MODE_DISABLED;
+			}
+		}
+	case 2:
+		{
+			union cvmx_gserx_sata_cfg sata_cfg;
+			union cvmx_pemx_cfg pem0_cfg, pem1_cfg, pem2_cfg;
+
+			sata_cfg.u64 = cvmx_read_csr(CVMX_GSERX_SATA_CFG(0));
+			pem0_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(0));
+			pem1_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(1));
+			pem2_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(2));
+
+			if (sata_cfg.s.sata_en)
+				return CVMX_QLM_MODE_SATA_2X1;
+			if (pem0_cfg.cn70xx.md == CVMX_PEM_MD_GEN2_4LANE
+			    || pem0_cfg.cn70xx.md == CVMX_PEM_MD_GEN1_4LANE)
+				return CVMX_QLM_MODE_PCIE;
+			if (pem1_cfg.cn70xx.md == CVMX_PEM_MD_GEN2_2LANE
+			    || pem1_cfg.cn70xx.md == CVMX_PEM_MD_GEN1_2LANE) {
+				return CVMX_QLM_MODE_PCIE_1X2;
+			}
+			if (pem1_cfg.cn70xx.md == CVMX_PEM_MD_GEN2_1LANE
+			    || pem1_cfg.cn70xx.md == CVMX_PEM_MD_GEN1_1LANE) {
+				if (pem2_cfg.cn70xx.md == CVMX_PEM_MD_GEN2_1LANE
+				    || pem2_cfg.cn70xx.md == CVMX_PEM_MD_GEN1_1LANE) {
+					return CVMX_QLM_MODE_PCIE_2X1;
+				} else
+					return CVMX_QLM_MODE_PCIE_1X1;
+			}
+			if (pem2_cfg.cn70xx.md == CVMX_PEM_MD_GEN2_1LANE
+			    || pem2_cfg.cn70xx.md == CVMX_PEM_MD_GEN1_1LANE)
+				return CVMX_QLM_MODE_PCIE_2X1;
+			return CVMX_QLM_MODE_DISABLED;
+		}
+	default:
+		return CVMX_QLM_MODE_DISABLED;
+	}
+
+	return CVMX_QLM_MODE_DISABLED;
+}
+
 /*
- * Read QLM and return mode.
+ * Get the DLM mode for the interface based on the interface type.
+ *
+ * @param interface_type   0 - SGMII/QSGMII/RXAUI interface
+ *                         1 - PCIe
+ *                         2 - SATA
+ * @param interface        interface to use
+ * @return  the qlm mode the interface is
  */
-enum cvmx_qlm_mode cvmx_qlm_get_mode(int qlm)
+enum cvmx_qlm_mode cvmx_qlm_get_dlm_mode(int interface_type, int interface)
+{
+	switch (interface_type) {
+	case 0:  /* SGMII/QSGMII/RXAUI */
+	{
+		enum cvmx_qlm_mode qlm_mode = __cvmx_qlm_get_mode_cn70xx(0);
+		switch (interface) {
+		case 0:
+			switch (qlm_mode) {
+			case CVMX_QLM_MODE_SGMII_SGMII:
+			case CVMX_QLM_MODE_SGMII_DISABLED:
+			case CVMX_QLM_MODE_SGMII_QSGMII:
+				return CVMX_QLM_MODE_SGMII;
+			case CVMX_QLM_MODE_QSGMII_QSGMII:
+			case CVMX_QLM_MODE_QSGMII_DISABLED:
+			case CVMX_QLM_MODE_QSGMII_SGMII:
+				return CVMX_QLM_MODE_QSGMII;
+			case CVMX_QLM_MODE_RXAUI_1X2:
+				return CVMX_QLM_MODE_RXAUI;
+			default:
+				return CVMX_QLM_MODE_DISABLED;
+			}
+		case 1:
+			switch (qlm_mode) {
+			case CVMX_QLM_MODE_SGMII_SGMII:
+			case CVMX_QLM_MODE_DISABLED_SGMII:
+			case CVMX_QLM_MODE_QSGMII_SGMII:
+				return CVMX_QLM_MODE_SGMII;
+			case CVMX_QLM_MODE_QSGMII_QSGMII:
+			case CVMX_QLM_MODE_DISABLED_QSGMII:
+			case CVMX_QLM_MODE_SGMII_QSGMII:
+				return CVMX_QLM_MODE_QSGMII;
+			default:
+				return CVMX_QLM_MODE_DISABLED;
+			}
+		default:
+			return qlm_mode;
+		}
+	}
+	case 1:  /* PCIe */
+	{
+		enum cvmx_qlm_mode qlm_mode1 = __cvmx_qlm_get_mode_cn70xx(1);
+		enum cvmx_qlm_mode qlm_mode2 = __cvmx_qlm_get_mode_cn70xx(2);
+
+		switch (interface) {
+		case 0: /* PCIe0 can be DLM1 with 1, 2 or 4 lanes */
+			return qlm_mode1;
+		case 1: /* PCIe1 can be in DLM1 1 lane(1), DLM2 1 lane(0) or 2 lanes(0-1) */
+			if (qlm_mode1 == CVMX_QLM_MODE_PCIE_2X1)
+				return CVMX_QLM_MODE_PCIE_2X1;
+			else if (qlm_mode2 == CVMX_QLM_MODE_PCIE_1X2 ||
+				 qlm_mode2 == CVMX_QLM_MODE_PCIE_2X1)
+				return qlm_mode2;
+			else
+				return CVMX_QLM_MODE_DISABLED;
+		case 2: /* PCIe2 can be DLM2 1 lanes(1) */
+			if (qlm_mode2 == CVMX_QLM_MODE_PCIE_2X1)
+				return qlm_mode2;
+			else
+				return CVMX_QLM_MODE_DISABLED;
+		default:
+			return CVMX_QLM_MODE_DISABLED;
+		}
+	}
+	case 2:  /* SATA */
+	{
+		enum cvmx_qlm_mode qlm_mode = __cvmx_qlm_get_mode_cn70xx(2);
+
+		if (qlm_mode == CVMX_QLM_MODE_SATA_2X1)
+			return CVMX_QLM_MODE_SATA_2X1;
+		else
+			return CVMX_QLM_MODE_DISABLED;
+	}
+	default:
+		return CVMX_QLM_MODE_DISABLED;
+	}
+}
+
+static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn6xxx(int qlm)
 {
 	cvmx_mio_qlmx_cfg_t qlmx_cfg;
 
@@ -822,6 +1060,44 @@ enum cvmx_qlm_mode cvmx_qlm_get_mode(int qlm)
 	return CVMX_QLM_MODE_DISABLED;
 }
 
+static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn78xx(int qlm)
+{
+	/*
+	 * Until gser configuration is in place, we hard code the
+	 * qlm mode here. This means that for the time being, this
+	 * function and __cvmx_get_mode_cn78xx() have to be in sync
+	 * since they are both hard coded. Note that register
+	 * CVMX_MIO_QLMX_CFG is not yet modeled by the simulator.
+	 */
+	switch(qlm) {
+	case 0:
+	case 1:
+		return CVMX_QLM_MODE_SGMII;
+	case 4:
+		return CVMX_QLM_MODE_ILK;
+	case 5:
+	case 6:
+	case 7:
+		return CVMX_QLM_MODE_XAUI;
+	}
+	return CVMX_QLM_MODE_DISABLED;
+}
+
+/*
+ * Read QLM and return mode.
+ */
+enum cvmx_qlm_mode cvmx_qlm_get_mode(int qlm)
+{
+	if (OCTEON_IS_OCTEON2())
+		return __cvmx_qlm_get_mode_cn6xxx(qlm);
+	else if (OCTEON_IS_MODEL(OCTEON_CN70XX))
+		return __cvmx_qlm_get_mode_cn70xx(qlm);
+	else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		return __cvmx_qlm_get_mode_cn78xx(qlm);
+
+	return CVMX_QLM_MODE_DISABLED;
+}
+
 /**
  * Measure the reference clock of a QLM
  *
@@ -829,7 +1105,7 @@ enum cvmx_qlm_mode cvmx_qlm_get_mode(int qlm)
  *
  * @return Clock rate in Hz
  *       */
-static int __cvmx_qlm_measure_clock(int qlm)
+int cvmx_qlm_measure_clock(int qlm)
 {
 	cvmx_mio_ptp_clock_cfg_t ptp_clock;
 	uint64_t count;
@@ -840,11 +1116,13 @@ static int __cvmx_qlm_measure_clock(int qlm)
 
 	/* Force the reference to 156.25Mhz when running in simulation.
 	   This supports the most speeds */
-#ifndef CVMX_BUILD_FOR_LINUX_HOST
+#ifdef CVMX_BUILD_FOR_UBOOT
+	if (gd->board_type == CVMX_BOARD_TYPE_SIM)
+		return 156250000;
+#elif !defined(CVMX_BUILD_FOR_LINUX_HOST)
 	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM)
 		return 156250000;
 #endif
-
 	/* Disable the PTP event counter while we configure it */
 	ptp_clock.u64 = cvmx_read_csr(CVMX_MIO_PTP_CLOCK_CFG);	/* For CN63XXp1 errata */
 	ptp_clock.s.evcnt_en = 0;
@@ -881,271 +1159,6 @@ static int __cvmx_qlm_measure_clock(int qlm)
 	return count * cvmx_clock_get_rate(CVMX_CLOCK_CORE) / (stop_cycle - start_cycle);
 }
 
-static int __cvmx_qlm_is_ref_clock(int qlm, int reference_mhz)
-{
-	int ref_clock = __cvmx_qlm_measure_clock(qlm);
-	int mhz = ref_clock / 1000000;
-	int range = reference_mhz / 10;
-	return ((mhz >= reference_mhz - range) && (mhz <= reference_mhz + range));
-}
-
-static int __cvmx_qlm_get_qlm_spd(int qlm, int speed)
-{
-	int qlm_spd = 0xf;
-
-	if (OCTEON_IS_MODEL(OCTEON_CN3XXX) || OCTEON_IS_MODEL(OCTEON_CN5XXX))
-		return -1;
-
-	if (__cvmx_qlm_is_ref_clock(qlm, 100)) {
-		if (speed == 1250)
-			qlm_spd = 0x3;
-		else if (speed == 2500)
-			qlm_spd = 0x2;
-		else if (speed == 5000)
-			qlm_spd = 0x0;
-		else {
-			//cvmx_dprintf("Invalide speed(%d) for QLM(%d)\n", speed, qlm);
-			qlm_spd = 0xf;
-		}
-	} else if (__cvmx_qlm_is_ref_clock(qlm, 125)) {
-		if (speed == 1250)
-			qlm_spd = 0xa;
-		else if (speed == 2500)
-			qlm_spd = 0x9;
-		else if (speed == 3125)
-			qlm_spd = 0x8;
-		else if (speed == 5000)
-			qlm_spd = 0x6;
-		else if (speed == 6250)
-			qlm_spd = 0x5;
-		else {
-			//cvmx_dprintf("Invalide speed(%d) for QLM(%d)\n", speed, qlm);
-			qlm_spd = 0xf;
-		}
-	} else if (__cvmx_qlm_is_ref_clock(qlm, 156)) {
-		if (speed == 1250)
-			qlm_spd = 0x4;
-		else if (speed == 2500)
-			qlm_spd = 0x7;
-		else if (speed == 3125)
-			qlm_spd = 0xe;
-		else if (speed == 3750)
-			qlm_spd = 0xd;
-		else if (speed == 5000)
-			qlm_spd = 0xb;
-		else if (speed == 6250)
-			qlm_spd = 0xc;
-		else {
-			//cvmx_dprintf("Invalide speed(%d) for QLM(%d)\n", speed, qlm);
-			qlm_spd = 0xf;
-		}
-	}
-	return qlm_spd;
-}
-
-static void __cvmx_qlm_set_qlm_pcie_mode(int pcie_port, int root_complex)
-{
-	int rc = root_complex ? 1 : 0;
-	int ep = root_complex ? 0 : 1;
-	cvmx_ciu_soft_prst1_t soft_prst1;
-	cvmx_ciu_soft_prst_t soft_prst;
-	cvmx_mio_rst_ctlx_t rst_ctl;
-
-	if (pcie_port) {
-		soft_prst1.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST1);
-		soft_prst1.s.soft_prst = 1;
-		cvmx_write_csr(CVMX_CIU_SOFT_PRST1, soft_prst1.u64);
-	} else {
-		soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST);
-		soft_prst.s.soft_prst = 1;
-		cvmx_write_csr(CVMX_CIU_SOFT_PRST, soft_prst.u64);
-	}
-
-	rst_ctl.u64 = cvmx_read_csr(CVMX_MIO_RST_CTLX(pcie_port));
-
-	rst_ctl.s.prst_link = rc;
-	rst_ctl.s.rst_link = ep;
-	rst_ctl.s.prtmode = rc;
-	rst_ctl.s.rst_drv = rc;
-	rst_ctl.s.rst_rcv = 0;
-	rst_ctl.s.rst_chip = ep;
-	cvmx_write_csr(CVMX_MIO_RST_CTLX(pcie_port), rst_ctl.u64);
-
-	if (root_complex == 0) {
-		if (pcie_port) {
-			soft_prst1.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST1);
-			soft_prst1.s.soft_prst = 0;
-			cvmx_write_csr(CVMX_CIU_SOFT_PRST1, soft_prst1.u64);
-		} else {
-			soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST);
-			soft_prst.s.soft_prst = 0;
-			cvmx_write_csr(CVMX_CIU_SOFT_PRST, soft_prst.u64);
-		}
-	}
-}
-
-/**
- * Configure qlm speed and mode. MIO_QLMX_CFG[speed,mode] are not set
- * for CN61XX.
- *
- * @param qlm     The QLM to configure
- * @param speed   The speed the QLM needs to be configured in Mhz.
- * @param mode    The QLM to be configured as SGMII/XAUI/PCIe.
- *                  QLM 0: 0 = PCIe0 1X4, 1 = Reserved, 2 = SGMII1, 3 = XAUI1
- *                  QLM 1: 0 = PCIe1 1x2, 1 = PCIe(0/1) 2x1, 2 - 3 = Reserved
- *                  QLM 2: 0 - 1 = Reserved, 2 = SGMII0, 3 = XAUI0
- * @param rc      Only used for PCIe, rc = 1 for root complex mode, 0 for EP mode.
- * @param pcie2x1 Only used when QLM1 is in PCIE2x1 mode. The QLM_SPD has different
- *                value on how PEMx needs to be configured:
- *                   0x0 - both PEM0 & PEM1 are in gen1 mode.
- *                   0x1 - PEM0 in gen2 and PEM1 in gen1 mode.
- *                   0x2 - PEM0 in gen1 and PEM1 in gen2 mode.
- *                   0x3 - both PEM0 & PEM1 are in gen2 mode.
- *               SPEED value is ignored in this mode. QLM_SPD is set based on
- *               pcie2x1 value in this mode.
- *
- * @return       Return 0 on success or -1.
- */
-int cvmx_qlm_configure_qlm(int qlm, int speed, int mode, int rc, int pcie2x1)
-{
-	cvmx_mio_qlmx_cfg_t qlm_cfg;
-
-	/* The QLM speed varies for SGMII/XAUI and PCIe mode. And depends on
-	   reference clock. */
-	if (!OCTEON_IS_MODEL(OCTEON_CN61XX))
-		return -1;
-
-	if (qlm < 3)
-		qlm_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(qlm));
-	else {
-		cvmx_dprintf("WARNING: Invalid QLM(%d) passed\n", qlm);
-		return -1;
-	}
-
-	switch (qlm) {
-		/* SGMII/XAUI mode */
-	case 2:
-		{
-			if (mode < 2) {
-				//cvmx_dprintf("Invalide mode(%d) for QLM(%d)\n", mode, qlm);
-				qlm_cfg.s.qlm_spd = 0xf;
-				break;
-			}
-			qlm_cfg.s.qlm_spd = __cvmx_qlm_get_qlm_spd(qlm, speed);
-			qlm_cfg.s.qlm_cfg = mode;
-			break;
-		}
-	case 1:
-		{
-			if (mode == 1) {	/* 2x1 mode */
-				cvmx_mio_qlmx_cfg_t qlm0;
-
-				/* When QLM0 is configured as PCIe(QLM_CFG=0x0) and enabled
-				   (QLM_SPD != 0xf), QLM1 cannot be configured as PCIe 2x1 mode
-				   (QLM_CFG=0x1) and enabled (QLM_SPD != 0xf). */
-				qlm0.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(0));
-				if (qlm0.s.qlm_spd != 0xf && qlm0.s.qlm_cfg == 0) {
-					cvmx_dprintf("Invalid mode(%d) for QLM(%d) as QLM1 is PCIe mode\n", mode, qlm);
-					qlm_cfg.s.qlm_spd = 0xf;
-					break;
-				}
-
-				/* Set QLM_SPD based on reference clock and mode */
-				if (__cvmx_qlm_is_ref_clock(qlm, 100)) {
-					if (pcie2x1 == 0x3)
-						qlm_cfg.s.qlm_spd = 0x0;
-					else if (pcie2x1 == 0x1)
-						qlm_cfg.s.qlm_spd = 0x2;
-					else if (pcie2x1 == 0x2)
-						qlm_cfg.s.qlm_spd = 0x1;
-					else if (pcie2x1 == 0x0)
-						qlm_cfg.s.qlm_spd = 0x3;
-					else
-						qlm_cfg.s.qlm_spd = 0xf;
-				} else if (__cvmx_qlm_is_ref_clock(qlm, 125)) {
-					if (pcie2x1 == 0x3)
-						qlm_cfg.s.qlm_spd = 0x4;
-					else if (pcie2x1 == 0x1)
-						qlm_cfg.s.qlm_spd = 0x6;
-					else if (pcie2x1 == 0x2)
-						qlm_cfg.s.qlm_spd = 0x9;
-					else if (pcie2x1 == 0x0)
-						qlm_cfg.s.qlm_spd = 0x7;
-					else
-						qlm_cfg.s.qlm_spd = 0xf;
-				}
-				qlm_cfg.s.qlm_cfg = mode;
-				cvmx_write_csr(CVMX_MIO_QLMX_CFG(qlm), qlm_cfg.u64);
-
-				/* Set PCIe mode bits */
-				__cvmx_qlm_set_qlm_pcie_mode(0, rc);
-				__cvmx_qlm_set_qlm_pcie_mode(1, rc);
-				return 0;
-			} else if (mode > 1) {
-				cvmx_dprintf("Invalid mode(%d) for QLM(%d).\n", mode, qlm);
-				qlm_cfg.s.qlm_spd = 0xf;
-				break;
-			}
-
-			/* Set speed and mode for PCIe 1x2 mode. */
-			if (__cvmx_qlm_is_ref_clock(qlm, 100)) {
-				if (speed == 5000)
-					qlm_cfg.s.qlm_spd = 0x1;
-				else if (speed == 2500)
-					qlm_cfg.s.qlm_spd = 0x2;
-				else
-					qlm_cfg.s.qlm_spd = 0xf;
-			} else if (__cvmx_qlm_is_ref_clock(qlm, 125)) {
-				if (speed == 5000)
-					qlm_cfg.s.qlm_spd = 0x4;
-				else if (speed == 2500)
-					qlm_cfg.s.qlm_spd = 0x6;
-				else
-					qlm_cfg.s.qlm_spd = 0xf;
-			} else
-				qlm_cfg.s.qlm_spd = 0xf;
-
-			qlm_cfg.s.qlm_cfg = mode;
-			cvmx_write_csr(CVMX_MIO_QLMX_CFG(qlm), qlm_cfg.u64);
-
-			/* Set PCIe mode bits */
-			__cvmx_qlm_set_qlm_pcie_mode(1, rc);
-			return 0;
-		}
-	case 0:
-		{
-			/* QLM_CFG = 0x1 - Reserved */
-			if (mode == 1) {
-				//cvmx_dprintf("Invalid mode(%d) for QLM(%d)\n", mode, qlm);
-				qlm_cfg.s.qlm_spd = 0xf;
-				break;
-			}
-			/* QLM_CFG = 0x0 - PCIe 1x4(PEM0) */
-			if (mode == 0 && speed != 5000 && speed != 2500) {
-				//cvmx_dprintf("Invalid speed(%d) for QLM(%d) for PCIe mode.\n", speed, qlm);
-				qlm_cfg.s.qlm_spd = 0xf;
-				break;
-			}
-
-			/* Set speed and mode */
-			qlm_cfg.s.qlm_spd = __cvmx_qlm_get_qlm_spd(qlm, speed);
-			qlm_cfg.s.qlm_cfg = mode;
-			cvmx_write_csr(CVMX_MIO_QLMX_CFG(qlm), qlm_cfg.u64);
-
-			/* Set PCIe mode bits */
-			if (mode == 0)
-				__cvmx_qlm_set_qlm_pcie_mode(0, rc);
-
-			return 0;
-		}
-	default:
-		cvmx_dprintf("WARNING: Invalid QLM(%d) passed\n", qlm);
-		qlm_cfg.s.qlm_spd = 0xf;
-	}
-	cvmx_write_csr(CVMX_MIO_QLMX_CFG(qlm), qlm_cfg.u64);
-	return 0;
-}
-
 void cvmx_qlm_display_registers(int qlm)
 {
 	int num_lanes = cvmx_qlm_get_lanes(qlm);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-srio.c b/arch/mips/cavium-octeon/executive/cvmx-srio.c
index 48ec438..88a4563 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-srio.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-srio.c
@@ -714,9 +714,7 @@ int cvmx_srio_initialize(int srio_port, cvmx_srio_initialize_flags_t flags)
 	cvmx_write_csr(CVMX_SRIOX_INT_REG(srio_port), cvmx_read_csr(CVMX_SRIOX_INT_REG(srio_port)));
 
 	/* Enable error reporting */
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	octeon_error_tree_enable(CVMX_ERROR_GROUP_SRIO, srio_port);
-#elif !defined(CVMX_BUILD_FOR_LINUX_HOST)
+#if defined(CVMX_BUILD_FOR_STANDALONE)
 	cvmx_error_enable_group(CVMX_ERROR_GROUP_SRIO, srio_port);
 #endif
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-usb.c b/arch/mips/cavium-octeon/executive/cvmx-usb.c
index 45dd000..79558be 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-usb.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-usb.c
@@ -283,7 +283,8 @@ typedef struct {
     } while (0)
 
 /* Returns the IO address to push/pop stuff data from the FIFOs */
-#define USB_FIFO_ADDRESS(channel, usb_index) (CVMX_USBCX_GOTGCTL(usb_index) + ((channel)+1)*0x1000)
+#define USB_FIFO_ADDRESS(channel, usb_index)	\
+	(CVMX_USBCX_GOTGCTL(usb_index) + ((channel)+1)*0x1000)
 
 /**
  * @INTERNAL
@@ -296,7 +297,8 @@ typedef struct {
  *
  * @return Result of the read
  */
-static inline uint32_t __cvmx_usb_read_csr32(cvmx_usb_internal_state_t * usb, uint64_t address)
+static inline uint32_t __cvmx_usb_read_csr32(cvmx_usb_internal_state_t * usb,
+					     uint64_t address)
 {
 	uint32_t result = cvmx_read64_uint32(address ^ 4);
 #if ALLOW_CSR_DECODES
@@ -318,7 +320,8 @@ static inline uint32_t __cvmx_usb_read_csr32(cvmx_usb_internal_state_t * usb, ui
  * @param address 64bit address to write
  * @param value   Value to write
  */
-static inline void __cvmx_usb_write_csr32(cvmx_usb_internal_state_t * usb, uint64_t address, uint32_t value)
+static inline void __cvmx_usb_write_csr32(cvmx_usb_internal_state_t * usb,
+					  uint64_t address, uint32_t value)
 {
 #if ALLOW_CSR_DECODES
 	if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_CSRS)) {
@@ -340,7 +343,8 @@ static inline void __cvmx_usb_write_csr32(cvmx_usb_internal_state_t * usb, uint6
  *
  * @return Result of the read
  */
-static inline uint64_t __cvmx_usb_read_csr64(cvmx_usb_internal_state_t * usb, uint64_t address)
+static inline uint64_t __cvmx_usb_read_csr64(cvmx_usb_internal_state_t * usb,
+					     uint64_t address)
 {
 	uint64_t result = cvmx_read64_uint64(address);
 #if ALLOW_CSR_DECODES
@@ -361,7 +365,8 @@ static inline uint64_t __cvmx_usb_read_csr64(cvmx_usb_internal_state_t * usb, ui
  * @param address 64bit address to write
  * @param value   Value to write
  */
-static inline void __cvmx_usb_write_csr64(cvmx_usb_internal_state_t * usb, uint64_t address, uint64_t value)
+static inline void __cvmx_usb_write_csr64(cvmx_usb_internal_state_t * usb,
+					  uint64_t address, uint64_t value)
 {
 #if ALLOW_CSR_DECODES
 	if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_CSRS)) {
@@ -416,9 +421,11 @@ static const char *__cvmx_usb_complete_to_string(cvmx_usb_complete_t complete_co
  *
  * @return Non zero if we need to do split transactions
  */
-static inline int __cvmx_usb_pipe_needs_split(cvmx_usb_internal_state_t * usb, cvmx_usb_pipe_t * pipe)
+static inline int __cvmx_usb_pipe_needs_split(cvmx_usb_internal_state_t * usb,
+					      cvmx_usb_pipe_t * pipe)
 {
-	return ((pipe->device_speed != CVMX_USB_SPEED_HIGH) && (usb->usbcx_hprt.s.prtspd == CVMX_USB_SPEED_HIGH));
+	return ((pipe->device_speed != CVMX_USB_SPEED_HIGH) &&
+		(usb->usbcx_hprt.s.prtspd == CVMX_USB_SPEED_HIGH));
 }
 
 /**
@@ -481,7 +488,8 @@ EXPORT_SYMBOL(cvmx_usb_get_num_ports);
  *
  * @return Transaction or NULL
  */
-static inline cvmx_usb_transaction_t *__cvmx_usb_alloc_transaction(cvmx_usb_internal_state_t * usb)
+static inline cvmx_usb_transaction_t *
+__cvmx_usb_alloc_transaction(cvmx_usb_internal_state_t * usb)
 {
 	cvmx_usb_transaction_t *t;
 	t = usb->free_transaction_head;
@@ -507,7 +515,9 @@ static inline cvmx_usb_transaction_t *__cvmx_usb_alloc_transaction(cvmx_usb_inte
  * @param transaction
  *               Transaction to free
  */
-static inline void __cvmx_usb_free_transaction(cvmx_usb_internal_state_t * usb, cvmx_usb_transaction_t * transaction)
+static inline void
+__cvmx_usb_free_transaction(cvmx_usb_internal_state_t * usb,
+			    cvmx_usb_transaction_t * transaction)
 {
 	transaction->flags = 0;
 	transaction->prev = NULL;
@@ -525,7 +535,8 @@ static inline void __cvmx_usb_free_transaction(cvmx_usb_internal_state_t * usb,
  * @param list   List to add pipe to
  * @param pipe   Pipe to add
  */
-static inline void __cvmx_usb_append_pipe(cvmx_usb_pipe_list_t * list, cvmx_usb_pipe_t * pipe)
+static inline void __cvmx_usb_append_pipe(cvmx_usb_pipe_list_t * list,
+					  cvmx_usb_pipe_t * pipe)
 {
 	pipe->next = NULL;
 	pipe->prev = list->tail;
@@ -542,7 +553,8 @@ static inline void __cvmx_usb_append_pipe(cvmx_usb_pipe_list_t * list, cvmx_usb_
  * @param list   List to remove pipe from
  * @param pipe   Pipe to remove
  */
-static inline void __cvmx_usb_remove_pipe(cvmx_usb_pipe_list_t * list, cvmx_usb_pipe_t * pipe)
+static inline void __cvmx_usb_remove_pipe(cvmx_usb_pipe_list_t * list,
+					  cvmx_usb_pipe_t * pipe)
 {
 	if (list->head == pipe) {
 		list->head = pipe->next;
@@ -581,7 +593,9 @@ static inline void __cvmx_usb_remove_pipe(cvmx_usb_pipe_list_t * list, cvmx_usb_
  * @return CVMX_USB_SUCCESS or a negative error code defined in
  *         cvmx_usb_status_t.
  */
-cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_number, cvmx_usb_initialize_flags_t flags)
+cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state,
+				      int usb_port_number,
+				      cvmx_usb_initialize_flags_t flags)
 {
 	cvmx_usbnx_clk_ctl_t usbn_clk_ctl;
 	cvmx_usbnx_usbp_ctl_status_t usbn_usbp_ctl_status;
@@ -651,7 +665,8 @@ cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_num
 	/* 1. Wait for DCOK to assert (nothing to do) */
 	/* 2a. Write USBN0/1_CLK_CTL[POR] = 1 and
 	   USBN0/1_CLK_CTL[HRST,PRST,HCLK_RST] = 0 */
-	usbn_clk_ctl.u64 = __cvmx_usb_read_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index));
+	usbn_clk_ctl.u64 = __cvmx_usb_read_csr64(usb,
+						 CVMX_USBNX_CLK_CTL(usb->index));
 	usbn_clk_ctl.s.por = 1;
 	usbn_clk_ctl.s.hrst = 0;
 	usbn_clk_ctl.s.prst = 0;
@@ -666,7 +681,8 @@ cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_num
 		if (OCTEON_IS_MODEL(OCTEON_CN3XXX)) {
 			usbn_clk_ctl.cn31xx.p_rclk = 1;	/* From CN31XX,CN30XX manual */
 			usbn_clk_ctl.cn31xx.p_xenbn = 0;
-		} else if (OCTEON_IS_MODEL(OCTEON_CN56XX) || OCTEON_IS_MODEL(OCTEON_CN50XX))
+		} else if (OCTEON_IS_MODEL(OCTEON_CN56XX) ||
+			   OCTEON_IS_MODEL(OCTEON_CN50XX))
 			usbn_clk_ctl.cn56xx.p_rtype = 2;	/* From CN56XX,CN50XX manual */
 		else
 			usbn_clk_ctl.cn52xx.p_rtype = 1;	/* From CN52XX manual */
@@ -688,7 +704,8 @@ cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_num
 		if (OCTEON_IS_MODEL(OCTEON_CN3XXX)) {
 			usbn_clk_ctl.cn31xx.p_rclk = 1;	/* From CN31XX,CN30XX manual */
 			usbn_clk_ctl.cn31xx.p_xenbn = 1;
-		} else if (OCTEON_IS_MODEL(OCTEON_CN56XX) || OCTEON_IS_MODEL(OCTEON_CN50XX))
+		} else if (OCTEON_IS_MODEL(OCTEON_CN56XX) ||
+			   OCTEON_IS_MODEL(OCTEON_CN50XX))
 			usbn_clk_ctl.cn56xx.p_rtype = 0;	/* From CN56XX,CN50XX manual */
 		else
 			usbn_clk_ctl.cn52xx.p_rtype = 0;	/* From CN52XX manual */
@@ -705,47 +722,65 @@ cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_num
 		usbn_clk_ctl.s.divide = divisor;
 		usbn_clk_ctl.s.divide2 = 0;
 	}
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index), usbn_clk_ctl.u64);
+	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index),
+			       usbn_clk_ctl.u64);
 	/* 2d. Write USBN0/1_CLK_CTL[HCLK_RST] = 1 */
 	usbn_clk_ctl.s.hclk_rst = 1;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index), usbn_clk_ctl.u64);
+	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index),
+			       usbn_clk_ctl.u64);
 	/* 2e.  Wait 64 core-clock cycles for HCLK to stabilize */
 	cvmx_wait(64);
 	/* 3. Program the power-on reset field in the USBN clock-control register:
 	   USBN_CLK_CTL[POR] = 0 */
 	usbn_clk_ctl.s.por = 0;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index), usbn_clk_ctl.u64);
+	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index),
+			       usbn_clk_ctl.u64);
 	/* 4. Wait 1 ms for PHY clock to start */
 	cvmx_wait_usec(1000);
-	/* 5. Program the Reset input from automatic test equipment field in the
-	   USBP control and status register: USBN_USBP_CTL_STATUS[ATE_RESET] = 1 */
-	usbn_usbp_ctl_status.u64 = __cvmx_usb_read_csr64(usb, CVMX_USBNX_USBP_CTL_STATUS(usb->index));
+	/* 5. Program the Reset input from automatic test equipment field in
+	 *    the USBP control and status register:
+	 *	 USBN_USBP_CTL_STATUS[ATE_RESET] = 1
+	 */
+	usbn_usbp_ctl_status.u64 = __cvmx_usb_read_csr64(usb,
+							 CVMX_USBNX_USBP_CTL_STATUS(usb->index));
 	usbn_usbp_ctl_status.s.ate_reset = 1;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_USBP_CTL_STATUS(usb->index), usbn_usbp_ctl_status.u64);
+	__cvmx_usb_write_csr64(usb,
+			       CVMX_USBNX_USBP_CTL_STATUS(usb->index),
+			       usbn_usbp_ctl_status.u64);
 	/* 6. Wait 10 cycles */
 	cvmx_wait(10);
 	/* 7. Clear ATE_RESET field in the USBN clock-control register:
 	   USBN_USBP_CTL_STATUS[ATE_RESET] = 0 */
 	usbn_usbp_ctl_status.s.ate_reset = 0;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_USBP_CTL_STATUS(usb->index), usbn_usbp_ctl_status.u64);
+	__cvmx_usb_write_csr64(usb,
+			       CVMX_USBNX_USBP_CTL_STATUS(usb->index),
+			       usbn_usbp_ctl_status.u64);
 	/* 8. Program the PHY reset field in the USBN clock-control register:
 	   USBN_CLK_CTL[PRST] = 1 */
 	usbn_clk_ctl.s.prst = 1;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index), usbn_clk_ctl.u64);
+	__cvmx_usb_write_csr64(usb,
+			       CVMX_USBNX_CLK_CTL(usb->index),
+			       usbn_clk_ctl.u64);
 	/* 9. Program the USBP control and status register to select host or
 	   device mode. USBN_USBP_CTL_STATUS[HST_MODE] = 0 for host, = 1 for
 	   device */
 	usbn_usbp_ctl_status.s.hst_mode = 0;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_USBP_CTL_STATUS(usb->index), usbn_usbp_ctl_status.u64);
+	__cvmx_usb_write_csr64(usb,
+			       CVMX_USBNX_USBP_CTL_STATUS(usb->index),
+			       usbn_usbp_ctl_status.u64);
 	/* 10. Wait 1 s */
 	cvmx_wait_usec(1);
 	/* 11. Program the hreset_n field in the USBN clock-control register:
 	   USBN_CLK_CTL[HRST] = 1 */
 	usbn_clk_ctl.s.hrst = 1;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index), usbn_clk_ctl.u64);
+	__cvmx_usb_write_csr64(usb,
+			       CVMX_USBNX_CLK_CTL(usb->index),
+			       usbn_clk_ctl.u64);
 	/* 12. Proceed to USB core initialization */
 	usbn_clk_ctl.s.enable = 1;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index), usbn_clk_ctl.u64);
+	__cvmx_usb_write_csr64(usb,
+			       CVMX_USBNX_CLK_CTL(usb->index),
+			       usbn_clk_ctl.u64);
 	cvmx_wait_usec(1);
 
 	/* USB Core Initialization */
@@ -779,7 +814,9 @@ cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_num
 		usbcx_gahbcfg.s.nptxfemplvl = 1;
 		usbcx_gahbcfg.s.ptxfemplvl = 1;
 		usbcx_gahbcfg.s.glblintrmsk = 1;
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_GAHBCFG(usb->index), usbcx_gahbcfg.u32);
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_GAHBCFG(usb->index),
+				       usbcx_gahbcfg.u32);
 	}
 	/* 3. Program the following fields in USBC_GUSBCFG register.
 	   HS/FS timeout calibration, USBC_GUSBCFG[TOUTCAL] = 0
@@ -788,12 +825,15 @@ cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_num
 	   PHY low-power clock select, USBC_GUSBCFG[PHYLPWRCLKSEL] = 0 */
 	{
 		cvmx_usbcx_gusbcfg_t usbcx_gusbcfg;
-		usbcx_gusbcfg.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_GUSBCFG(usb->index));
+		usbcx_gusbcfg.u32 = __cvmx_usb_read_csr32(usb,
+							  CVMX_USBCX_GUSBCFG(usb->index));
 		usbcx_gusbcfg.s.toutcal = 0;
 		usbcx_gusbcfg.s.ddrsel = 0;
 		usbcx_gusbcfg.s.usbtrdtim = 0x5;
 		usbcx_gusbcfg.s.phylpwrclksel = 0;
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_GUSBCFG(usb->index), usbcx_gusbcfg.u32);
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_GUSBCFG(usb->index),
+				       usbcx_gusbcfg.u32);
 	}
 	/* 4. The software must unmask the following bits in the USBC_GINTMSK
 	   register.
@@ -803,7 +843,8 @@ cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_num
 		cvmx_usbcx_gintmsk_t usbcx_gintmsk;
 		int channel;
 
-		usbcx_gintmsk.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_GINTMSK(usb->index));
+		usbcx_gintmsk.u32 = __cvmx_usb_read_csr32(usb,
+							  CVMX_USBCX_GINTMSK(usb->index));
 		usbcx_gintmsk.s.otgintmsk = 1;
 		usbcx_gintmsk.s.modemismsk = 1;
 		usbcx_gintmsk.s.hchintmsk = 1;
@@ -811,34 +852,47 @@ cvmx_usb_status_t cvmx_usb_initialize(cvmx_usb_state_t * state, int usb_port_num
 		/* We need RX FIFO interrupts if we don't have DMA */
 		if (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA)
 			usbcx_gintmsk.s.rxflvlmsk = 1;
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_GINTMSK(usb->index), usbcx_gintmsk.u32);
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_GINTMSK(usb->index),
+				       usbcx_gintmsk.u32);
 
 		/* Disable all channel interrupts. We'll enable them per channel later */
 		for (channel = 0; channel < 8; channel++)
-			__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCINTMSKX(channel, usb->index), 0);
+			__cvmx_usb_write_csr32(usb,
+					       CVMX_USBCX_HCINTMSKX(channel,
+								    usb->index),
+					       0);
 	}
 
 	{
 		/* Host Port Initialization */
 		if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_INFO))
-			cvmx_dprintf("%s: USB%d is in host mode\n", __func__, usb->index);
+			cvmx_dprintf("%s: USB%d is in host mode\n",
+				     __func__, usb->index);
 
 		/* 1. Program the host-port interrupt-mask field to unmask,
 		   USBC_GINTMSK[PRTINT] = 1 */
-		USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index), cvmx_usbcx_gintmsk_t, prtintmsk, 1);
-		USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index), cvmx_usbcx_gintmsk_t, disconnintmsk, 1);
-		/* 2. Program the USBC_HCFG register to select full-speed host or
-		   high-speed host. */
+		USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index),
+				cvmx_usbcx_gintmsk_t, prtintmsk, 1);
+		USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index),
+				cvmx_usbcx_gintmsk_t, disconnintmsk, 1);
+		/* 2. Program the USBC_HCFG register to select full-speed host
+		 *    or high-speed host.
+		 */
 		{
 			cvmx_usbcx_hcfg_t usbcx_hcfg;
-			usbcx_hcfg.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCFG(usb->index));
+			usbcx_hcfg.u32 = __cvmx_usb_read_csr32(usb,
+							       CVMX_USBCX_HCFG(usb->index));
 			usbcx_hcfg.s.fslssupp = 0;
 			usbcx_hcfg.s.fslspclksel = 0;
-			__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCFG(usb->index), usbcx_hcfg.u32);
+			__cvmx_usb_write_csr32(usb,
+					       CVMX_USBCX_HCFG(usb->index),
+					       usbcx_hcfg.u32);
 		}
 		/* 3. Program the port power bit to drive VBUS on the USB,
 		   USBC_HPRT[PRTPWR] = 1 */
-		USB_SET_FIELD32(CVMX_USBCX_HPRT(usb->index), cvmx_usbcx_hprt_t, prtpwr, 1);
+		USB_SET_FIELD32(CVMX_USBCX_HPRT(usb->index),
+				cvmx_usbcx_hprt_t, prtpwr, 1);
 
 		/* Steps 4-15 from the manual are done later in the port enable */
 	}
@@ -873,7 +927,9 @@ cvmx_usb_status_t cvmx_usb_shutdown(cvmx_usb_state_t * state)
 	/* Make sure all pipes are closed */
 	if (usb->idle_pipes.head ||
 	    usb->active_pipes[CVMX_USB_TRANSFER_ISOCHRONOUS].head ||
-	    usb->active_pipes[CVMX_USB_TRANSFER_INTERRUPT].head || usb->active_pipes[CVMX_USB_TRANSFER_CONTROL].head || usb->active_pipes[CVMX_USB_TRANSFER_BULK].head)
+	    usb->active_pipes[CVMX_USB_TRANSFER_INTERRUPT].head ||
+	    usb->active_pipes[CVMX_USB_TRANSFER_CONTROL].head ||
+	    usb->active_pipes[CVMX_USB_TRANSFER_BULK].head)
 		CVMX_USB_RETURN(CVMX_USB_BUSY);
 
 #ifdef __CVMX_ERROR_H__
@@ -881,13 +937,15 @@ cvmx_usb_status_t cvmx_usb_shutdown(cvmx_usb_state_t * state)
 #endif
 
 	/* Disable the clocks and put them in power on reset */
-	usbn_clk_ctl.u64 = __cvmx_usb_read_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index));
+	usbn_clk_ctl.u64 = __cvmx_usb_read_csr64(usb,
+						 CVMX_USBNX_CLK_CTL(usb->index));
 	usbn_clk_ctl.s.enable = 1;
 	usbn_clk_ctl.s.por = 1;
 	usbn_clk_ctl.s.hclk_rst = 1;
 	usbn_clk_ctl.s.prst = 0;
 	usbn_clk_ctl.s.hrst = 0;
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index), usbn_clk_ctl.u64);
+	__cvmx_usb_write_csr64(usb, CVMX_USBNX_CLK_CTL(usb->index),
+			       usbn_clk_ctl.u64);
 	CVMX_USB_RETURN(CVMX_USB_SUCCESS);
 }
 
@@ -911,7 +969,8 @@ cvmx_usb_status_t cvmx_usb_enable(cvmx_usb_state_t * state)
 	CVMX_USB_LOG_CALLED();
 	CVMX_USB_LOG_PARAM("%p", state);
 
-	usb->usbcx_hprt.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HPRT(usb->index));
+	usb->usbcx_hprt.u32 = __cvmx_usb_read_csr32(usb,
+						    CVMX_USBCX_HPRT(usb->index));
 
 	/* If the port is already enabled the just return. We don't need to do
 	   anything */
@@ -926,58 +985,85 @@ cvmx_usb_status_t cvmx_usb_enable(cvmx_usb_state_t * state)
 	}
 
 	/* Program the port reset bit to start the reset process */
-	USB_SET_FIELD32(CVMX_USBCX_HPRT(usb->index), cvmx_usbcx_hprt_t, prtrst, 1);
+	USB_SET_FIELD32(CVMX_USBCX_HPRT(usb->index),
+			cvmx_usbcx_hprt_t, prtrst, 1);
 
 	/* Wait at least 50ms (high speed), or 10ms (full speed) for the reset
 	   process to complete. */
 	cvmx_wait_usec(50000);
 
 	/* Program the port reset bit to 0, USBC_HPRT[PRTRST] = 0 */
-	USB_SET_FIELD32(CVMX_USBCX_HPRT(usb->index), cvmx_usbcx_hprt_t, prtrst, 0);
+	USB_SET_FIELD32(CVMX_USBCX_HPRT(usb->index),
+			cvmx_usbcx_hprt_t,
+			prtrst, 0);
 
 	/* Wait for the USBC_HPRT[PRTENA]. */
-	if (CVMX_WAIT_FOR_FIELD32(CVMX_USBCX_HPRT(usb->index), cvmx_usbcx_hprt_t, prtena, ==, 1, 100000)) {
+	if (CVMX_WAIT_FOR_FIELD32(CVMX_USBCX_HPRT(usb->index),
+				  cvmx_usbcx_hprt_t, prtena, ==, 1, 100000)) {
 		if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_INFO))
-			cvmx_dprintf("%s: Timeout waiting for the port to finish reset\n", __func__);
+			cvmx_dprintf("%s: Timeout waiting for the port to finish reset\n",
+				     __func__);
 		CVMX_USB_RETURN(CVMX_USB_TIMEOUT);
 	}
 
-	/* Read the port speed field to get the enumerated speed, USBC_HPRT[PRTSPD]. */
-	usb->usbcx_hprt.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HPRT(usb->index));
+	/* Read the port speed field to get the enumerated speed,
+	 * USBC_HPRT[PRTSPD].
+	 */
+	usb->usbcx_hprt.u32 = __cvmx_usb_read_csr32(usb,
+						    CVMX_USBCX_HPRT(usb->index));
 	if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_INFO))
-		cvmx_dprintf("%s: USB%d is in %s speed mode\n", __func__, usb->index,
-			     (usb->usbcx_hprt.s.prtspd == CVMX_USB_SPEED_HIGH) ? "high" : (usb->usbcx_hprt.s.prtspd == CVMX_USB_SPEED_FULL) ? "full" : "low");
-
-	usbcx_ghwcfg3.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_GHWCFG3(usb->index));
-
-	/* 13. Program the USBC_GRXFSIZ register to select the size of the receive
-	   FIFO (25%). */
-	USB_SET_FIELD32(CVMX_USBCX_GRXFSIZ(usb->index), cvmx_usbcx_grxfsiz_t, rxfdep, usbcx_ghwcfg3.s.dfifodepth / 4);
+		cvmx_dprintf("%s: USB%d is in %s speed mode\n",
+			     __func__, usb->index,
+			     (usb->usbcx_hprt.s.prtspd == CVMX_USB_SPEED_HIGH)
+			     ? "high"
+			     : (usb->usbcx_hprt.s.prtspd == CVMX_USB_SPEED_FULL)
+			        ? "full" : "low");
+
+	usbcx_ghwcfg3.u32 = __cvmx_usb_read_csr32(usb,
+						  CVMX_USBCX_GHWCFG3(usb->index));
+
+	/* 13. Program the USBC_GRXFSIZ register to select the size of the
+	 *     receive FIFO (25%).
+	 */
+	USB_SET_FIELD32(CVMX_USBCX_GRXFSIZ(usb->index), cvmx_usbcx_grxfsiz_t,
+			rxfdep, usbcx_ghwcfg3.s.dfifodepth / 4);
 	/* 14. Program the USBC_GNPTXFSIZ register to select the size and the
-	   start address of the non- periodic transmit FIFO for nonperiodic
-	   transactions (50%). */
+	 *     start address of the non- periodic transmit FIFO for nonperiodic
+	 *     transactions (50%).
+	 */
 	{
 		cvmx_usbcx_gnptxfsiz_t siz;
-		siz.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_GNPTXFSIZ(usb->index));
+		siz.u32 = __cvmx_usb_read_csr32(usb,
+						CVMX_USBCX_GNPTXFSIZ(usb->index));
 		siz.s.nptxfdep = usbcx_ghwcfg3.s.dfifodepth / 2;
 		siz.s.nptxfstaddr = usbcx_ghwcfg3.s.dfifodepth / 4;
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_GNPTXFSIZ(usb->index), siz.u32);
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_GNPTXFSIZ(usb->index),
+				       siz.u32);
 	}
 	/* 15. Program the USBC_HPTXFSIZ register to select the size and start
-	   address of the periodic transmit FIFO for periodic transactions (25%). */
+	 *     address of the periodic transmit FIFO for periodic transactions
+	 *     (25%).
+	 */
 	{
 		cvmx_usbcx_hptxfsiz_t siz;
-		siz.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HPTXFSIZ(usb->index));
+		siz.u32 = __cvmx_usb_read_csr32(usb,
+						CVMX_USBCX_HPTXFSIZ(usb->index));
 		siz.s.ptxfsize = usbcx_ghwcfg3.s.dfifodepth / 4;
 		siz.s.ptxfstaddr = 3 * usbcx_ghwcfg3.s.dfifodepth / 4;
 		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HPTXFSIZ(usb->index), siz.u32);
 	}
 	/* Flush all FIFOs */
-	USB_SET_FIELD32(CVMX_USBCX_GRSTCTL(usb->index), cvmx_usbcx_grstctl_t, txfnum, 0x10);
-	USB_SET_FIELD32(CVMX_USBCX_GRSTCTL(usb->index), cvmx_usbcx_grstctl_t, txfflsh, 1);
-	CVMX_WAIT_FOR_FIELD32(CVMX_USBCX_GRSTCTL(usb->index), cvmx_usbcx_grstctl_t, txfflsh, ==, 0, 100);
-	USB_SET_FIELD32(CVMX_USBCX_GRSTCTL(usb->index), cvmx_usbcx_grstctl_t, rxfflsh, 1);
-	CVMX_WAIT_FOR_FIELD32(CVMX_USBCX_GRSTCTL(usb->index), cvmx_usbcx_grstctl_t, rxfflsh, ==, 0, 100);
+	USB_SET_FIELD32(CVMX_USBCX_GRSTCTL(usb->index),
+			cvmx_usbcx_grstctl_t, txfnum, 0x10);
+	USB_SET_FIELD32(CVMX_USBCX_GRSTCTL(usb->index),
+			cvmx_usbcx_grstctl_t, txfflsh, 1);
+	CVMX_WAIT_FOR_FIELD32(CVMX_USBCX_GRSTCTL(usb->index),
+			      cvmx_usbcx_grstctl_t, txfflsh, ==, 0, 100);
+	USB_SET_FIELD32(CVMX_USBCX_GRSTCTL(usb->index),
+			cvmx_usbcx_grstctl_t, rxfflsh, 1);
+	CVMX_WAIT_FOR_FIELD32(CVMX_USBCX_GRSTCTL(usb->index),
+			      cvmx_usbcx_grstctl_t, rxfflsh, ==, 0, 100);
 
 	CVMX_USB_RETURN(CVMX_USB_SUCCESS);
 }
@@ -1004,7 +1090,8 @@ cvmx_usb_status_t cvmx_usb_disable(cvmx_usb_state_t * state)
 	CVMX_USB_LOG_PARAM("%p", state);
 
 	/* Disable the port */
-	USB_SET_FIELD32(CVMX_USBCX_HPRT(usb->index), cvmx_usbcx_hprt_t, prtena, 1);
+	USB_SET_FIELD32(CVMX_USBCX_HPRT(usb->index), cvmx_usbcx_hprt_t,
+			prtena, 1);
 	CVMX_USB_RETURN(CVMX_USB_SUCCESS);
 }
 
@@ -1046,7 +1133,9 @@ cvmx_usb_port_status_t cvmx_usb_get_status(cvmx_usb_state_t * state)
 	if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_CALLS))
 		cvmx_dprintf("%*s%s: returned port enabled=%d, over_current=%d, powered=%d, speed=%d, connected=%d, connect_change=%d\n",
 			     2 * (--usb->indent), "", __func__,
-			     result.port_enabled, result.port_over_current, result.port_powered, result.port_speed, result.connected, result.connect_change);
+			     result.port_enabled, result.port_over_current,
+			     result.port_powered, result.port_speed,
+			     result.connected, result.connect_change);
 	return result;
 }
 
@@ -1064,7 +1153,8 @@ EXPORT_SYMBOL(cvmx_usb_get_status);
  * @param port_status
  *               Port status to set, most like returned by cvmx_usb_get_status()
  */
-void cvmx_usb_set_status(cvmx_usb_state_t * state, cvmx_usb_port_status_t port_status)
+void cvmx_usb_set_status(cvmx_usb_state_t * state,
+			 cvmx_usb_port_status_t port_status)
 {
 	cvmx_usb_internal_state_t *usb = (cvmx_usb_internal_state_t *) state;
 	CVMX_USB_LOG_CALLED();
@@ -1086,9 +1176,11 @@ EXPORT_SYMBOL(cvmx_usb_set_status);
  *
  * @return Handle
  */
-static inline int __cvmx_usb_get_submit_handle(cvmx_usb_internal_state_t * usb, cvmx_usb_transaction_t * transaction)
+static inline int __cvmx_usb_get_submit_handle(cvmx_usb_internal_state_t * usb,
+					       cvmx_usb_transaction_t * transaction)
 {
-	return ((unsigned long)transaction - (unsigned long)usb->transaction) / sizeof(*transaction);
+	return ((unsigned long)transaction - (unsigned long)usb->transaction)
+				/ sizeof(*transaction);
 }
 
 /**
@@ -1101,7 +1193,8 @@ static inline int __cvmx_usb_get_submit_handle(cvmx_usb_internal_state_t * usb,
  *
  * @return Handle
  */
-static inline int __cvmx_usb_get_pipe_handle(cvmx_usb_internal_state_t * usb, cvmx_usb_pipe_t * pipe)
+static inline int __cvmx_usb_get_pipe_handle(cvmx_usb_internal_state_t * usb,
+					     cvmx_usb_pipe_t * pipe)
 {
 	return ((unsigned long)pipe - (unsigned long)usb->pipe) / sizeof(*pipe);
 }
@@ -1165,7 +1258,9 @@ static inline int __cvmx_usb_get_pipe_handle(cvmx_usb_internal_state_t * usb, cv
 int cvmx_usb_open_pipe(cvmx_usb_state_t * state, cvmx_usb_pipe_flags_t flags,
 		       int device_addr, int endpoint_num,
 		       cvmx_usb_speed_t device_speed, int max_packet,
-		       cvmx_usb_transfer_t transfer_type, cvmx_usb_direction_t transfer_dir, int interval, int multi_count, int hub_device_addr, int hub_port)
+		       cvmx_usb_transfer_t transfer_type,
+		       cvmx_usb_direction_t transfer_dir, int interval,
+		       int multi_count, int hub_device_addr, int hub_port)
 {
 	cvmx_usb_pipe_t *pipe;
 	cvmx_usb_internal_state_t *usb = (cvmx_usb_internal_state_t *) state;
@@ -1184,9 +1279,11 @@ int cvmx_usb_open_pipe(cvmx_usb_state_t * state, cvmx_usb_pipe_flags_t flags,
 	CVMX_USB_LOG_PARAM("%d", hub_device_addr);
 	CVMX_USB_LOG_PARAM("%d", hub_port);
 
-	if (cvmx_unlikely((device_addr < 0) || (device_addr > MAX_USB_ADDRESS)))
+	if (cvmx_unlikely((device_addr < 0) ||
+			  (device_addr > MAX_USB_ADDRESS)))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
-	if (cvmx_unlikely((endpoint_num < 0) || (endpoint_num > MAX_USB_ENDPOINT)))
+	if (cvmx_unlikely((endpoint_num < 0) ||
+			  (endpoint_num > MAX_USB_ENDPOINT)))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 	if (cvmx_unlikely(device_speed > CVMX_USB_SPEED_LOW))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
@@ -1194,7 +1291,8 @@ int cvmx_usb_open_pipe(cvmx_usb_state_t * state, cvmx_usb_pipe_flags_t flags,
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 	if (cvmx_unlikely(transfer_type > CVMX_USB_TRANSFER_INTERRUPT))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
-	if (cvmx_unlikely((transfer_dir != CVMX_USB_DIRECTION_OUT) && (transfer_dir != CVMX_USB_DIRECTION_IN)))
+	if (cvmx_unlikely((transfer_dir != CVMX_USB_DIRECTION_OUT) &&
+			  (transfer_dir != CVMX_USB_DIRECTION_IN)))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 	if (cvmx_unlikely(interval < 0))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
@@ -1202,9 +1300,11 @@ int cvmx_usb_open_pipe(cvmx_usb_state_t * state, cvmx_usb_pipe_flags_t flags,
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 	if (cvmx_unlikely(multi_count < 0))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
-	if (cvmx_unlikely((device_speed != CVMX_USB_SPEED_HIGH) && (multi_count != 0)))
+	if (cvmx_unlikely((device_speed != CVMX_USB_SPEED_HIGH) &&
+			  (multi_count != 0)))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
-	if (cvmx_unlikely((hub_device_addr < 0) || (hub_device_addr > MAX_USB_ADDRESS)))
+	if (cvmx_unlikely((hub_device_addr < 0) ||
+			  (hub_device_addr > MAX_USB_ADDRESS)))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 	if (cvmx_unlikely((hub_port < 0) || (hub_port > MAX_USB_HUB_PORT)))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
@@ -1215,7 +1315,9 @@ int cvmx_usb_open_pipe(cvmx_usb_state_t * state, cvmx_usb_pipe_flags_t flags,
 		CVMX_USB_RETURN(CVMX_USB_NO_MEMORY);
 	__cvmx_usb_remove_pipe(&usb->free_pipes, pipe);
 	pipe->flags = flags | __CVMX_USB_PIPE_FLAGS_OPEN;
-	if ((device_speed == CVMX_USB_SPEED_HIGH) && (transfer_dir == CVMX_USB_DIRECTION_OUT) && (transfer_type == CVMX_USB_TRANSFER_BULK))
+	if ((device_speed == CVMX_USB_SPEED_HIGH) &&
+	    (transfer_dir == CVMX_USB_DIRECTION_OUT) &&
+	    (transfer_type == CVMX_USB_TRANSFER_BULK))
 		pipe->flags |= __CVMX_USB_PIPE_FLAGS_NEED_PING;
 	pipe->device_addr = device_addr;
 	pipe->endpoint_num = endpoint_num;
@@ -1270,7 +1372,8 @@ static void __cvmx_usb_poll_rx_fifo(cvmx_usb_internal_state_t * usb)
 	CVMX_USB_LOG_CALLED();
 	CVMX_USB_LOG_PARAM("%p", usb);
 
-	rx_status.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_GRXSTSPH(usb->index));
+	rx_status.u32 = __cvmx_usb_read_csr32(usb,
+					      CVMX_USBCX_GRXSTSPH(usb->index));
 	/* Only read data if IN data is there */
 	if (rx_status.s.pktsts != 2)
 		CVMX_USB_RETURN_NOTHING();
@@ -1284,13 +1387,20 @@ static void __cvmx_usb_poll_rx_fifo(cvmx_usb_internal_state_t * usb)
 		CVMX_USB_RETURN_NOTHING();
 
 	/* Get where the DMA engine would have written this data */
-	address = __cvmx_usb_read_csr64(usb, CVMX_USBNX_DMA0_INB_CHN0(usb->index) + channel * 8);
+	address = __cvmx_usb_read_csr64(usb,
+					CVMX_USBNX_DMA0_INB_CHN0(usb->index)
+						+ channel * 8);
 	ptr = cvmx_phys_to_ptr(address);
-	__cvmx_usb_write_csr64(usb, CVMX_USBNX_DMA0_INB_CHN0(usb->index) + channel * 8, address + bytes);
+	__cvmx_usb_write_csr64(usb,
+			       CVMX_USBNX_DMA0_INB_CHN0(usb->index)
+					+ channel * 8,
+			       address + bytes);
 
 	/* Loop writing the FIFO data for this packet into memory */
 	while (bytes > 0) {
-		*ptr++ = __cvmx_usb_read_csr32(usb, USB_FIFO_ADDRESS(channel, usb->index));
+		*ptr++ = __cvmx_usb_read_csr32(usb,
+					       USB_FIFO_ADDRESS(channel,
+								usb->index));
 		bytes -= 4;
 	}
 	CVMX_SYNCW;
@@ -1310,7 +1420,8 @@ static void __cvmx_usb_poll_rx_fifo(cvmx_usb_internal_state_t * usb)
  * @return Non zero if the hardware fifo was too small and needs
  *         to be serviced again.
  */
-static int __cvmx_usb_fill_tx_hw(cvmx_usb_internal_state_t * usb, cvmx_usb_tx_fifo_t * fifo, int available)
+static int __cvmx_usb_fill_tx_hw(cvmx_usb_internal_state_t * usb,
+				 cvmx_usb_tx_fifo_t * fifo, int available)
 {
 	CVMX_USB_LOG_CALLED();
 	CVMX_USB_LOG_PARAM("%p", usb);
@@ -1322,7 +1433,8 @@ static int __cvmx_usb_fill_tx_hw(cvmx_usb_internal_state_t * usb, cvmx_usb_tx_fi
 	while (available && (fifo->head != fifo->tail)) {
 		int i = fifo->tail;
 		const uint32_t *ptr = cvmx_phys_to_ptr(fifo->entry[i].address);
-		uint64_t csr_address = USB_FIFO_ADDRESS(fifo->entry[i].channel, usb->index) ^ 4;
+		uint64_t csr_address = USB_FIFO_ADDRESS(fifo->entry[i].channel,
+							usb->index) ^ 4;
 		int words = available;
 
 		/* Limit the amount of data to waht the SW fifo has */
@@ -1371,20 +1483,28 @@ static void __cvmx_usb_poll_tx_fifo(cvmx_usb_internal_state_t * usb)
 
 	if (usb->periodic.head != usb->periodic.tail) {
 		cvmx_usbcx_hptxsts_t tx_status;
-		tx_status.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HPTXSTS(usb->index));
-		if (__cvmx_usb_fill_tx_hw(usb, &usb->periodic, tx_status.s.ptxfspcavail))
-			USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index), cvmx_usbcx_gintmsk_t, ptxfempmsk, 1);
+		tx_status.u32 = __cvmx_usb_read_csr32(usb,
+						      CVMX_USBCX_HPTXSTS(usb->index));
+		if (__cvmx_usb_fill_tx_hw(usb, &usb->periodic,
+					  tx_status.s.ptxfspcavail))
+			USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index),
+					cvmx_usbcx_gintmsk_t, ptxfempmsk, 1);
 		else
-			USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index), cvmx_usbcx_gintmsk_t, ptxfempmsk, 0);
+			USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index),
+					cvmx_usbcx_gintmsk_t, ptxfempmsk, 0);
 	}
 
 	if (usb->nonperiodic.head != usb->nonperiodic.tail) {
 		cvmx_usbcx_gnptxsts_t tx_status;
-		tx_status.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_GNPTXSTS(usb->index));
-		if (__cvmx_usb_fill_tx_hw(usb, &usb->nonperiodic, tx_status.s.nptxfspcavail))
-			USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index), cvmx_usbcx_gintmsk_t, nptxfempmsk, 1);
+		tx_status.u32 = __cvmx_usb_read_csr32(usb,
+						      CVMX_USBCX_GNPTXSTS(usb->index));
+		if (__cvmx_usb_fill_tx_hw(usb, &usb->nonperiodic,
+					  tx_status.s.nptxfspcavail))
+			USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index),
+					cvmx_usbcx_gintmsk_t, nptxfempmsk, 1);
 		else
-			USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index), cvmx_usbcx_gintmsk_t, nptxfempmsk, 0);
+			USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index),
+					cvmx_usbcx_gintmsk_t, nptxfempmsk, 0);
 	}
 
 	CVMX_USB_RETURN_NOTHING();
@@ -1398,7 +1518,8 @@ static void __cvmx_usb_poll_tx_fifo(cvmx_usb_internal_state_t * usb)
  *                cvmx_usb_initialize().
  * @param channel Channel number to get packet from
  */
-static void __cvmx_usb_fill_tx_fifo(cvmx_usb_internal_state_t * usb, int channel)
+static void __cvmx_usb_fill_tx_fifo(cvmx_usb_internal_state_t * usb,
+				    int channel)
 {
 	cvmx_usbcx_hccharx_t hcchar;
 	cvmx_usbcx_hcspltx_t usbc_hcsplt;
@@ -1410,27 +1531,39 @@ static void __cvmx_usb_fill_tx_fifo(cvmx_usb_internal_state_t * usb, int channel
 	CVMX_USB_LOG_PARAM("%d", channel);
 
 	/* We only need to fill data on outbound channels */
-	hcchar.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCCHARX(channel, usb->index));
+	hcchar.u32 = __cvmx_usb_read_csr32(usb,
+					   CVMX_USBCX_HCCHARX(channel,
+							      usb->index));
 	if (hcchar.s.epdir != CVMX_USB_DIRECTION_OUT)
 		CVMX_USB_RETURN_NOTHING();
 
 	/* OUT Splits only have data on the start and not the complete */
-	usbc_hcsplt.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCSPLTX(channel, usb->index));
+	usbc_hcsplt.u32 = __cvmx_usb_read_csr32(usb,
+						CVMX_USBCX_HCSPLTX(channel,
+								   usb->index));
 	if (usbc_hcsplt.s.spltena && usbc_hcsplt.s.compsplt)
 		CVMX_USB_RETURN_NOTHING();
 
-	/* Find out how many bytes we need to fill and convert it into 32bit words */
-	usbc_hctsiz.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCTSIZX(channel, usb->index));
+	/* Find out how many bytes we need to fill and convert it into 32bit
+	 * words
+	 */
+	usbc_hctsiz.u32 = __cvmx_usb_read_csr32(usb,
+						CVMX_USBCX_HCTSIZX(channel,
+								   usb->index));
 	if (!usbc_hctsiz.s.xfersize)
 		CVMX_USB_RETURN_NOTHING();
 
-	if ((hcchar.s.eptype == CVMX_USB_TRANSFER_INTERRUPT) || (hcchar.s.eptype == CVMX_USB_TRANSFER_ISOCHRONOUS))
+	if ((hcchar.s.eptype == CVMX_USB_TRANSFER_INTERRUPT) ||
+	    (hcchar.s.eptype == CVMX_USB_TRANSFER_ISOCHRONOUS))
 		fifo = &usb->periodic;
 	else
 		fifo = &usb->nonperiodic;
 
 	fifo->entry[fifo->head].channel = channel;
-	fifo->entry[fifo->head].address = __cvmx_usb_read_csr64(usb, CVMX_USBNX_DMA0_OUTB_CHN0(usb->index) + channel * 8);
+	fifo->entry[fifo->head].address =
+		__cvmx_usb_read_csr64(usb,
+				      CVMX_USBNX_DMA0_OUTB_CHN0(usb->index)
+						+ channel * 8);
 	fifo->entry[fifo->head].size = (usbc_hctsiz.s.xfersize + 3) >> 2;
 	fifo->head++;
 	if (fifo->head > MAX_CHANNELS)
@@ -1452,11 +1585,15 @@ static void __cvmx_usb_fill_tx_fifo(cvmx_usb_internal_state_t * usb, int channel
  * @param channel Channel to setup
  * @param pipe    Pipe for control transaction
  */
-static void __cvmx_usb_start_channel_control(cvmx_usb_internal_state_t * usb, int channel, cvmx_usb_pipe_t * pipe)
+static void __cvmx_usb_start_channel_control(cvmx_usb_internal_state_t * usb,
+					     int channel,
+					     cvmx_usb_pipe_t * pipe)
 {
 	cvmx_usb_transaction_t *transaction = pipe->head;
-	cvmx_usb_control_header_t *header = cvmx_phys_to_ptr(transaction->control_header);
-	int bytes_to_transfer = transaction->buffer_length - transaction->actual_bytes;
+	cvmx_usb_control_header_t *header =
+			cvmx_phys_to_ptr(transaction->control_header);
+	int bytes_to_transfer =
+			transaction->buffer_length - transaction->actual_bytes;
 	int packets_to_transfer;
 	cvmx_usbcx_hctsizx_t usbc_hctsiz;
 
@@ -1465,7 +1602,9 @@ static void __cvmx_usb_start_channel_control(cvmx_usb_internal_state_t * usb, in
 	CVMX_USB_LOG_PARAM("%d", channel);
 	CVMX_USB_LOG_PARAM("%p", pipe);
 
-	usbc_hctsiz.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCTSIZX(channel, usb->index));
+	usbc_hctsiz.u32 = __cvmx_usb_read_csr32(usb,
+						CVMX_USBCX_HCTSIZX(channel,
+								   usb->index));
 
 	switch (transaction->stage) {
 	case CVMX_USB_STAGE_NON_CONTROL:
@@ -1476,17 +1615,25 @@ static void __cvmx_usb_start_channel_control(cvmx_usb_internal_state_t * usb, in
 		usbc_hctsiz.s.pid = 3;	/* Setup */
 		bytes_to_transfer = sizeof(*header);
 		/* All Control operations start with a setup going OUT */
-		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index), cvmx_usbcx_hccharx_t, epdir, CVMX_USB_DIRECTION_OUT);
+		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index),
+				cvmx_usbcx_hccharx_t, epdir,
+				CVMX_USB_DIRECTION_OUT);
 		/* Setup send the control header instead of the buffer data. The
 		   buffer data will be used in the next stage */
-		__cvmx_usb_write_csr64(usb, CVMX_USBNX_DMA0_OUTB_CHN0(usb->index) + channel * 8, transaction->control_header);
+		__cvmx_usb_write_csr64(usb,
+				       CVMX_USBNX_DMA0_OUTB_CHN0(usb->index) +
+						channel * 8,
+				       transaction->control_header);
 		break;
 	case CVMX_USB_STAGE_SETUP_SPLIT_COMPLETE:
 		usbc_hctsiz.s.pid = 3;	/* Setup */
 		bytes_to_transfer = 0;
 		/* All Control operations start with a setup going OUT */
-		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index), cvmx_usbcx_hccharx_t, epdir, CVMX_USB_DIRECTION_OUT);
-		USB_SET_FIELD32(CVMX_USBCX_HCSPLTX(channel, usb->index), cvmx_usbcx_hcspltx_t, compsplt, 1);
+		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index),
+				cvmx_usbcx_hccharx_t, epdir,
+				CVMX_USB_DIRECTION_OUT);
+		USB_SET_FIELD32(CVMX_USBCX_HCSPLTX(channel, usb->index),
+				cvmx_usbcx_hcspltx_t, compsplt, 1);
 		break;
 	case CVMX_USB_STAGE_DATA:
 		usbc_hctsiz.s.pid = __cvmx_usb_get_data_pid(pipe);
@@ -1497,33 +1644,48 @@ static void __cvmx_usb_start_channel_control(cvmx_usb_internal_state_t * usb, in
 				bytes_to_transfer = pipe->max_packet;
 		}
 		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index),
-				cvmx_usbcx_hccharx_t, epdir, ((header->s.request_type & 0x80) ? CVMX_USB_DIRECTION_IN : CVMX_USB_DIRECTION_OUT));
+				cvmx_usbcx_hccharx_t, epdir,
+				((header->s.request_type & 0x80)
+					? CVMX_USB_DIRECTION_IN
+					: CVMX_USB_DIRECTION_OUT));
 		break;
 	case CVMX_USB_STAGE_DATA_SPLIT_COMPLETE:
 		usbc_hctsiz.s.pid = __cvmx_usb_get_data_pid(pipe);
 		if (!(header->s.request_type & 0x80))
 			bytes_to_transfer = 0;
 		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index),
-				cvmx_usbcx_hccharx_t, epdir, ((header->s.request_type & 0x80) ? CVMX_USB_DIRECTION_IN : CVMX_USB_DIRECTION_OUT));
-		USB_SET_FIELD32(CVMX_USBCX_HCSPLTX(channel, usb->index), cvmx_usbcx_hcspltx_t, compsplt, 1);
+				cvmx_usbcx_hccharx_t, epdir,
+				((header->s.request_type & 0x80)
+				? CVMX_USB_DIRECTION_IN
+				: CVMX_USB_DIRECTION_OUT));
+		USB_SET_FIELD32(CVMX_USBCX_HCSPLTX(channel, usb->index),
+				cvmx_usbcx_hcspltx_t, compsplt, 1);
 		break;
 	case CVMX_USB_STAGE_STATUS:
 		usbc_hctsiz.s.pid = __cvmx_usb_get_data_pid(pipe);
 		bytes_to_transfer = 0;
-		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index), cvmx_usbcx_hccharx_t, epdir,
-				((header->s.request_type & 0x80) ? CVMX_USB_DIRECTION_OUT : CVMX_USB_DIRECTION_IN));
+		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index),
+				cvmx_usbcx_hccharx_t, epdir,
+				((header->s.request_type & 0x80)
+				? CVMX_USB_DIRECTION_OUT
+				: CVMX_USB_DIRECTION_IN));
 		break;
 	case CVMX_USB_STAGE_STATUS_SPLIT_COMPLETE:
 		usbc_hctsiz.s.pid = __cvmx_usb_get_data_pid(pipe);
 		bytes_to_transfer = 0;
-		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index), cvmx_usbcx_hccharx_t, epdir,
-				((header->s.request_type & 0x80) ? CVMX_USB_DIRECTION_OUT : CVMX_USB_DIRECTION_IN));
-		USB_SET_FIELD32(CVMX_USBCX_HCSPLTX(channel, usb->index), cvmx_usbcx_hcspltx_t, compsplt, 1);
+		USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index),
+				cvmx_usbcx_hccharx_t, epdir,
+				((header->s.request_type & 0x80)
+				? CVMX_USB_DIRECTION_OUT
+				: CVMX_USB_DIRECTION_IN));
+		USB_SET_FIELD32(CVMX_USBCX_HCSPLTX(channel, usb->index),
+				cvmx_usbcx_hcspltx_t, compsplt, 1);
 		break;
 	}
 
 	/* Make sure the transfer never exceeds the byte limit of the hardware.
-	   Further bytes will be sent as continued transactions */
+	 * Further bytes will be sent as continued transactions
+	 */
 	if (bytes_to_transfer > MAX_TRANSFER_BYTES) {
 		/* Round MAX_TRANSFER_BYTES to a multiple of out packet size */
 		bytes_to_transfer = MAX_TRANSFER_BYTES / pipe->max_packet;
@@ -1532,18 +1694,22 @@ static void __cvmx_usb_start_channel_control(cvmx_usb_internal_state_t * usb, in
 
 	/* Calculate the number of packets to transfer. If the length is zero
 	   we still need to transfer one packet */
-	packets_to_transfer = (bytes_to_transfer + pipe->max_packet - 1) / pipe->max_packet;
+	packets_to_transfer =
+		(bytes_to_transfer + pipe->max_packet - 1) / pipe->max_packet;
 	if (packets_to_transfer == 0)
 		packets_to_transfer = 1;
-	else if ((packets_to_transfer > 1) && (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA)) {
-		/* Limit to one packet when not using DMA. Channels must be restarted
-		   between every packet for IN transactions, so there is no reason to
-		   do multiple packets in a row */
+	else if ((packets_to_transfer > 1) &&
+		 (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA)) {
+		/* Limit to one packet when not using DMA. Channels must be
+		 * restarted between every packet for IN transactions, so there
+		 * is no reason to do multiple packets in a row
+		 */
 		packets_to_transfer = 1;
 		bytes_to_transfer = packets_to_transfer * pipe->max_packet;
 	} else if (packets_to_transfer > MAX_TRANSFER_PACKETS) {
 		/* Limit the number of packet and data transferred to what the
-		   hardware can handle */
+		 * hardware can handle
+		 */
 		packets_to_transfer = MAX_TRANSFER_PACKETS;
 		bytes_to_transfer = packets_to_transfer * pipe->max_packet;
 	}
@@ -1551,7 +1717,8 @@ static void __cvmx_usb_start_channel_control(cvmx_usb_internal_state_t * usb, in
 	usbc_hctsiz.s.xfersize = bytes_to_transfer;
 	usbc_hctsiz.s.pktcnt = packets_to_transfer;
 
-	__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCTSIZX(channel, usb->index), usbc_hctsiz.u32);
+	__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCTSIZX(channel, usb->index),
+			       usbc_hctsiz.u32);
 	CVMX_USB_RETURN_NOTHING();
 }
 
@@ -1564,7 +1731,8 @@ static void __cvmx_usb_start_channel_control(cvmx_usb_internal_state_t * usb, in
  * @param channel Channel to setup
  * @param pipe    Pipe to start
  */
-static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channel, cvmx_usb_pipe_t * pipe)
+static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb,
+				     int channel, cvmx_usb_pipe_t * pipe)
 {
 	cvmx_usb_transaction_t *transaction = pipe->head;
 
@@ -1573,9 +1741,13 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 	CVMX_USB_LOG_PARAM("%d", channel);
 	CVMX_USB_LOG_PARAM("%p", pipe);
 
-	if (cvmx_unlikely((usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_TRANSFERS) || (pipe->flags & CVMX_USB_PIPE_FLAGS_DEBUG_TRANSFERS)))
+	if (cvmx_unlikely((usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_TRANSFERS)
+			  || (pipe->flags & CVMX_USB_PIPE_FLAGS_DEBUG_TRANSFERS)))
 		cvmx_dprintf("%s: Channel %d started. Pipe %d transaction %d stage %d\n",
-			     __func__, channel, __cvmx_usb_get_pipe_handle(usb, pipe), __cvmx_usb_get_submit_handle(usb, transaction), transaction->stage);
+			     __func__, channel,
+			     __cvmx_usb_get_pipe_handle(usb, pipe),
+			     __cvmx_usb_get_submit_handle(usb, transaction),
+			     transaction->stage);
 
 	/* Make sure all writes to the DMA region get flushed */
 	CVMX_SYNCW;
@@ -1595,19 +1767,27 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 		cvmx_usbcx_haintmsk_t usbc_haintmsk;
 
 		/* Clear all channel status bits */
-		usbc_hcint.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCINTX(channel, usb->index));
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCINTX(channel, usb->index), usbc_hcint.u32);
+		usbc_hcint.u32 = __cvmx_usb_read_csr32(usb,
+						       CVMX_USBCX_HCINTX(channel,
+									 usb->index));
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_HCINTX(channel, usb->index),
+				       usbc_hcint.u32);
 
 		usbc_hcintmsk.u32 = 0;
 		usbc_hcintmsk.s.chhltdmsk = 1;
 		if (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA) {
-			/* Channels need these extra interrupts when we aren't in DMA mode */
+			/* Channels need these extra interrupts when we aren't
+			 * in DMA mode
+			 */
 			usbc_hcintmsk.s.datatglerrmsk = 1;
 			usbc_hcintmsk.s.frmovrunmsk = 1;
 			usbc_hcintmsk.s.bblerrmsk = 1;
 			usbc_hcintmsk.s.xacterrmsk = 1;
 			if (__cvmx_usb_pipe_needs_split(usb, pipe)) {
-				/* Splits don't generate xfercompl, so we need ACK and NYET */
+				/* Splits don't generate xfercompl, so we need
+				 * ACK and NYET
+				 */
 				usbc_hcintmsk.s.nyetmsk = 1;
 				usbc_hcintmsk.s.ackmsk = 1;
 			}
@@ -1615,12 +1795,16 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 			usbc_hcintmsk.s.stallmsk = 1;
 			usbc_hcintmsk.s.xfercomplmsk = 1;
 		}
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCINTMSKX(channel, usb->index), usbc_hcintmsk.u32);
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_HCINTMSKX(channel, usb->index),
+				       usbc_hcintmsk.u32);
 
 		/* Enable the channel interrupt to propagate */
-		usbc_haintmsk.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HAINTMSK(usb->index));
+		usbc_haintmsk.u32 = __cvmx_usb_read_csr32(usb,
+							  CVMX_USBCX_HAINTMSK(usb->index));
 		usbc_haintmsk.s.haintmsk |= 1 << channel;
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HAINTMSK(usb->index), usbc_haintmsk.u32);
+		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HAINTMSK(usb->index),
+				       usbc_haintmsk.u32);
 	}
 
 	/* Setup the locations the DMA engines use  */
@@ -1628,8 +1812,12 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 		uint64_t dma_address = transaction->buffer + transaction->actual_bytes;
 		if (transaction->type == CVMX_USB_TRANSFER_ISOCHRONOUS)
 			dma_address = transaction->buffer + transaction->iso_packets[0].offset + transaction->actual_bytes;
-		__cvmx_usb_write_csr64(usb, CVMX_USBNX_DMA0_OUTB_CHN0(usb->index) + channel * 8, dma_address);
-		__cvmx_usb_write_csr64(usb, CVMX_USBNX_DMA0_INB_CHN0(usb->index) + channel * 8, dma_address);
+		__cvmx_usb_write_csr64(usb,
+				       CVMX_USBNX_DMA0_OUTB_CHN0(usb->index) + channel * 8,
+				       dma_address);
+		__cvmx_usb_write_csr64(usb,
+				       CVMX_USBNX_DMA0_INB_CHN0(usb->index) + channel * 8,
+				       dma_address);
 	}
 
 	/* Setup both the size of the transfer and the SPLIT characteristics */
@@ -1637,24 +1825,31 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 		cvmx_usbcx_hcspltx_t usbc_hcsplt = {.u32 = 0 };
 		cvmx_usbcx_hctsizx_t usbc_hctsiz = {.u32 = 0 };
 		int packets_to_transfer;
-		int bytes_to_transfer = transaction->buffer_length - transaction->actual_bytes;
+		int bytes_to_transfer = transaction->buffer_length
+						- transaction->actual_bytes;
 
 		/* ISOCHRONOUS transactions store each individual transfer size in the
 		   packet structure, not the global buffer_length */
 		if (transaction->type == CVMX_USB_TRANSFER_ISOCHRONOUS)
-			bytes_to_transfer = transaction->iso_packets[0].length - transaction->actual_bytes;
+			bytes_to_transfer = transaction->iso_packets[0].length
+						- transaction->actual_bytes;
 
-		/* We need to do split transactions when we are talking to non high
-		   speed devices that are behind a high speed hub */
+		/* We need to do split transactions when we are talking to non
+		 * high speed devices that are behind a high speed hub
+		 */
 		if (__cvmx_usb_pipe_needs_split(usb, pipe)) {
-			/* On the start split phase (stage is even) record the frame number we
-			   will need to send the split complete. We only store the lower two bits
-			   since the time ahead can only be two frames */
+			/* On the start split phase (stage is even) record the
+			 * frame number we will need to send the split complete.
+			 * We only store the lower two bits since the time ahead
+			 * can only be two frames
+			 */
 			if ((transaction->stage & 1) == 0) {
 				if (transaction->type == CVMX_USB_TRANSFER_BULK)
-					pipe->split_sc_frame = (usb->frame_number + 1) & 0x7f;
+					pipe->split_sc_frame =
+						(usb->frame_number + 1) & 0x7f;
 				else
-					pipe->split_sc_frame = (usb->frame_number + 2) & 0x7f;
+					pipe->split_sc_frame =
+						(usb->frame_number + 2) & 0x7f;
 			} else
 				pipe->split_sc_frame = -1;
 
@@ -1663,29 +1858,39 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 			usbc_hcsplt.s.prtaddr = pipe->hub_port;
 			usbc_hcsplt.s.compsplt = (transaction->stage == CVMX_USB_STAGE_NON_CONTROL_SPLIT_COMPLETE);
 
-			/* SPLIT transactions can only ever transmit one data packet so
-			   limit the transfer size to the max packet size */
+			/* SPLIT transactions can only ever transmit one data
+			 * packet so limit the transfer size to the max packet
+			 * size
+			 */
 			if (bytes_to_transfer > pipe->max_packet)
 				bytes_to_transfer = pipe->max_packet;
 
 			/* ISOCHRONOUS OUT splits are unique in that they limit
 			   data transfers to 188 byte chunks representing the
 			   begin/middle/end of the data or all */
-			if (!usbc_hcsplt.s.compsplt && (pipe->transfer_dir == CVMX_USB_DIRECTION_OUT) && (pipe->transfer_type == CVMX_USB_TRANSFER_ISOCHRONOUS)) {
-				/* Clear the split complete frame number as there isn't going
-				   to be a split complete */
+			if (!usbc_hcsplt.s.compsplt &&
+			    (pipe->transfer_dir == CVMX_USB_DIRECTION_OUT) &&
+			    (pipe->transfer_type == CVMX_USB_TRANSFER_ISOCHRONOUS)) {
+				/* Clear the split complete frame number as
+				 * there isn't going to be a split complete
+				 */
 				pipe->split_sc_frame = -1;
-				/* See if we've started this transfer and sent data */
+				/* See if we've started this transfer and sent
+				 * data
+				 */
 				if (transaction->actual_bytes == 0) {
-					/* Nothing sent yet, this is either a begin or the
-					   entire payload */
+					/* Nothing sent yet, this is either a
+					 * begin or the entire payload
+					 */
 					if (bytes_to_transfer <= 188)
 						usbc_hcsplt.s.xactpos = 3;	/* Entire payload in one go */
 					else
 						usbc_hcsplt.s.xactpos = 2;	/* First part of payload */
 				} else {
-					/* Continuing the previous data, we must either be
-					   in the middle or at the end */
+					/* Continuing the previous data, we
+					 * must either be in the middle or at
+					 * the end
+					 */
 					if (bytes_to_transfer <= 188)
 						usbc_hcsplt.s.xactpos = 1;	/* End of payload */
 					else
@@ -1697,23 +1902,30 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 			}
 		}
 
-		/* Make sure the transfer never exceeds the byte limit of the hardware.
-		   Further bytes will be sent as continued transactions */
+		/* Make sure the transfer never exceeds the byte limit of the
+		 * hardware.  Further bytes will be sent as continued
+		 * transactions
+		 */
 		if (bytes_to_transfer > MAX_TRANSFER_BYTES) {
 			/* Round MAX_TRANSFER_BYTES to a multiple of out packet size */
 			bytes_to_transfer = MAX_TRANSFER_BYTES / pipe->max_packet;
 			bytes_to_transfer *= pipe->max_packet;
 		}
 
-		/* Calculate the number of packets to transfer. If the length is zero
-		   we still need to transfer one packet */
-		packets_to_transfer = (bytes_to_transfer + pipe->max_packet - 1) / pipe->max_packet;
+		/* Calculate the number of packets to transfer. If the length
+		 * is zero we still need to transfer one packet
+		 */
+		packets_to_transfer =
+			(bytes_to_transfer + pipe->max_packet - 1) / pipe->max_packet;
 		if (packets_to_transfer == 0)
 			packets_to_transfer = 1;
-		else if ((packets_to_transfer > 1) && (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA)) {
-			/* Limit to one packet when not using DMA. Channels must be restarted
-			   between every packet for IN transactions, so there is no reason to
-			   do multiple packets in a row */
+		else if ((packets_to_transfer > 1) &&
+			 (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA)) {
+			/* Limit to one packet when not using DMA. Channels must
+			 * be restarted between every packet for IN
+			 * transactions, so there is no reason to do
+			 * multiple packets in a row
+			 */
 			packets_to_transfer = 1;
 			bytes_to_transfer = packets_to_transfer * pipe->max_packet;
 		} else if (packets_to_transfer > MAX_TRANSFER_PACKETS) {
@@ -1732,21 +1944,28 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 		if (pipe->flags & __CVMX_USB_PIPE_FLAGS_NEED_PING)
 			usbc_hctsiz.s.dopng = 1;
 
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCSPLTX(channel, usb->index), usbc_hcsplt.u32);
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCTSIZX(channel, usb->index), usbc_hctsiz.u32);
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_HCSPLTX(channel, usb->index),
+				       usbc_hcsplt.u32);
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_HCTSIZX(channel, usb->index),
+				       usbc_hctsiz.u32);
 	}
 
 	/* Setup the Host Channel Characteristics Register */
 	{
 		cvmx_usbcx_hccharx_t usbc_hcchar = {.u32 = 0 };
 
-		/* Set the startframe odd/even properly. This is only used for periodic */
+		/* Set the startframe odd/even properly. This is only used for
+		 * periodic
+		 */
 		usbc_hcchar.s.oddfrm = usb->frame_number & 1;
 
-		/* Set the number of back to back packets allowed by this endpoint.
-		   Split transactions interpret "ec" as the number of immediate
-		   retries of failure. These retries happen too quickly, so we
-		   disable these entirely for splits */
+		/* Set the number of back to back packets allowed by this
+		 * endpoint.  Split transactions interpret "ec" as the number
+		 * of immediate retries of failure. These retries happen too
+		 * quickly, so we disable these entirely for splits
+		 */
 		if (__cvmx_usb_pipe_needs_split(usb, pipe))
 			usbc_hcchar.s.ec = 1;
 		else if (pipe->multi_count < 1)
@@ -1763,7 +1982,9 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 		usbc_hcchar.s.epdir = pipe->transfer_dir;
 		usbc_hcchar.s.epnum = pipe->endpoint_num;
 		usbc_hcchar.s.mps = pipe->max_packet;
-		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCCHARX(channel, usb->index), usbc_hcchar.u32);
+		__cvmx_usb_write_csr32(usb,
+				       CVMX_USBCX_HCCHARX(channel, usb->index),
+				       usbc_hcchar.u32);
 	}
 
 	/* Do transaction type specific fixups as needed */
@@ -1776,26 +1997,38 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
 		break;
 	case CVMX_USB_TRANSFER_ISOCHRONOUS:
 		if (!__cvmx_usb_pipe_needs_split(usb, pipe)) {
-			/* ISO transactions require different PIDs depending on direction
-			   and how many packets are needed */
+			/* ISO transactions require different PIDs depending on
+			 * direction and how many packets are needed
+			 */
 			if (pipe->transfer_dir == CVMX_USB_DIRECTION_OUT) {
 				if (pipe->multi_count < 2)	/* Need DATA0 */
-					USB_SET_FIELD32(CVMX_USBCX_HCTSIZX(channel, usb->index), cvmx_usbcx_hctsizx_t, pid, 0);
+					USB_SET_FIELD32(CVMX_USBCX_HCTSIZX(channel,
+									   usb->index),
+							cvmx_usbcx_hctsizx_t,
+							pid, 0);
 				else	/* Need MDATA */
-					USB_SET_FIELD32(CVMX_USBCX_HCTSIZX(channel, usb->index), cvmx_usbcx_hctsizx_t, pid, 3);
+					USB_SET_FIELD32(CVMX_USBCX_HCTSIZX(channel,
+									   usb->index),
+							cvmx_usbcx_hctsizx_t,
+							pid, 3);
 			}
 		}
 		break;
 	}
 	{
-		cvmx_usbcx_hctsizx_t usbc_hctsiz = {.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCTSIZX(channel, usb->index)) };
+		cvmx_usbcx_hctsizx_t usbc_hctsiz = {
+			.u32 = __cvmx_usb_read_csr32(usb,
+						     CVMX_USBCX_HCTSIZX(channel,
+									usb->index))
+		};
 		transaction->xfersize = usbc_hctsiz.s.xfersize;
 		transaction->pktcnt = usbc_hctsiz.s.pktcnt;
 	}
 	/* Remeber when we start a split transaction */
 	if (__cvmx_usb_pipe_needs_split(usb, pipe))
 		usb->active_split = transaction;
-	USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index), cvmx_usbcx_hccharx_t, chena, 1);
+	USB_SET_FIELD32(CVMX_USBCX_HCCHARX(channel, usb->index),
+			cvmx_usbcx_hccharx_t, chena, 1);
 	if (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA)
 		__cvmx_usb_fill_tx_fifo(usb, channel);
 	CVMX_USB_RETURN_NOTHING();
@@ -1812,13 +2045,18 @@ static void __cvmx_usb_start_channel(cvmx_usb_internal_state_t * usb, int channe
  *
  * @return Pipe or NULL if none are ready
  */
-static cvmx_usb_pipe_t *__cvmx_usb_find_ready_pipe(cvmx_usb_internal_state_t * usb, cvmx_usb_pipe_list_t * list, uint64_t current_frame)
+static cvmx_usb_pipe_t *__cvmx_usb_find_ready_pipe(cvmx_usb_internal_state_t *usb,
+						   cvmx_usb_pipe_list_t *list,
+						   uint64_t current_frame)
 {
 	cvmx_usb_pipe_t *pipe = list->head;
 	while (pipe) {
-		if (!(pipe->flags & __CVMX_USB_PIPE_FLAGS_SCHEDULED) && pipe->head &&
+		if (!(pipe->flags & __CVMX_USB_PIPE_FLAGS_SCHEDULED) &&
+		    pipe->head &&
 		    (pipe->next_tx_frame <= current_frame) &&
-		    ((pipe->split_sc_frame == -1) || ((((int)current_frame - (int)pipe->split_sc_frame) & 0x7f) < 0x40)) &&
+		    ((pipe->split_sc_frame == -1) ||
+		     ((((int)current_frame - (int)pipe->split_sc_frame) & 0x7f) < 0x40))
+		    &&
 		    (!usb->active_split || (usb->active_split == pipe->head))) {
 			CVMX_PREFETCH(pipe, 128);
 			CVMX_PREFETCH(pipe->head, 0);
@@ -1847,11 +2085,20 @@ static void __cvmx_usb_schedule(cvmx_usb_internal_state_t * usb, int is_sof)
 
 	CVMX_USB_LOG_CALLED();
 	CVMX_USB_LOG_PARAM("%p", usb);
+	CVMX_USB_LOG_PARAM("%d", is_sof);
 
 	if (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA) {
-		/* Without DMA we need to be careful to not schedule something at the end of a frame and cause an overrun */
-		cvmx_usbcx_hfnum_t hfnum = {.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HFNUM(usb->index)) };
-		cvmx_usbcx_hfir_t hfir = {.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HFIR(usb->index)) };
+		/* Without DMA we need to be careful to not schedule something
+		 * at the end of a frame and cause an overrun
+		 */
+		cvmx_usbcx_hfnum_t hfnum = {
+			.u32 = __cvmx_usb_read_csr32(usb,
+						     CVMX_USBCX_HFNUM(usb->index))
+		};
+		cvmx_usbcx_hfir_t hfir = {
+			.u32 = __cvmx_usb_read_csr32(usb,
+						     CVMX_USBCX_HFIR(usb->index))
+		};
 		if (hfnum.s.frrem < hfir.s.frint / 4)
 			goto done;
 	}
@@ -1862,24 +2109,34 @@ static void __cvmx_usb_schedule(cvmx_usb_internal_state_t * usb, int is_sof)
 		channel = 31 - channel;
 		if (cvmx_unlikely(channel > 7)) {
 			if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_INFO))
-				cvmx_dprintf("%s: Idle hardware channels has a channel higher than 7. This is wrong\n", __func__);
+				cvmx_dprintf("%s: Idle hardware channels has a channel higher than 7. This is wrong\n",
+					     __func__);
 			break;
 		}
 
 		/* Find a pipe needing service */
 		pipe = NULL;
 		if (is_sof) {
-			/* Only process periodic pipes on SOF interrupts. This way we are
-			   sure that the periodic data is sent in the beginning of the
-			   frame */
-			pipe = __cvmx_usb_find_ready_pipe(usb, usb->active_pipes + CVMX_USB_TRANSFER_ISOCHRONOUS, usb->frame_number);
+			/* Only process periodic pipes on SOF interrupts.  This
+			 * way we are sure that the periodic data is sent in the
+			 * beginning of the frame
+			 */
+			pipe = __cvmx_usb_find_ready_pipe(usb,
+							  usb->active_pipes + CVMX_USB_TRANSFER_ISOCHRONOUS,
+							  usb->frame_number);
 			if (cvmx_likely(!pipe))
-				pipe = __cvmx_usb_find_ready_pipe(usb, usb->active_pipes + CVMX_USB_TRANSFER_INTERRUPT, usb->frame_number);
+				pipe = __cvmx_usb_find_ready_pipe(usb,
+								  usb->active_pipes + CVMX_USB_TRANSFER_INTERRUPT,
+								  usb->frame_number);
 		}
 		if (cvmx_likely(!pipe)) {
-			pipe = __cvmx_usb_find_ready_pipe(usb, usb->active_pipes + CVMX_USB_TRANSFER_CONTROL, usb->frame_number);
+			pipe = __cvmx_usb_find_ready_pipe(usb,
+							  usb->active_pipes + CVMX_USB_TRANSFER_CONTROL,
+							  usb->frame_number);
 			if (cvmx_likely(!pipe))
-				pipe = __cvmx_usb_find_ready_pipe(usb, usb->active_pipes + CVMX_USB_TRANSFER_BULK, usb->frame_number);
+				pipe = __cvmx_usb_find_ready_pipe(usb,
+								  usb->active_pipes + CVMX_USB_TRANSFER_BULK,
+								  usb->frame_number);
 		}
 		if (!pipe)
 			break;
@@ -1887,19 +2144,24 @@ static void __cvmx_usb_schedule(cvmx_usb_internal_state_t * usb, int is_sof)
 		CVMX_USB_LOG_PARAM("%d", channel);
 		CVMX_USB_LOG_PARAM("%p", pipe);
 
-		if (cvmx_unlikely((usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_TRANSFERS) || (pipe->flags & CVMX_USB_PIPE_FLAGS_DEBUG_TRANSFERS))) {
+		if (cvmx_unlikely((usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_TRANSFERS)
+				  || (pipe->flags & CVMX_USB_PIPE_FLAGS_DEBUG_TRANSFERS))) {
 			cvmx_usb_transaction_t *transaction = pipe->head;
-			const cvmx_usb_control_header_t *header = (transaction->control_header) ? cvmx_phys_to_ptr(transaction->control_header) : NULL;
-			const char *dir = (pipe->transfer_dir == CVMX_USB_DIRECTION_IN) ? "IN" : "OUT";
+			const cvmx_usb_control_header_t *header = (transaction->control_header)
+				? cvmx_phys_to_ptr(transaction->control_header) : NULL;
+			const char *dir = (pipe->transfer_dir == CVMX_USB_DIRECTION_IN)
+						? "IN" : "OUT";
 			const char *type;
 			switch (pipe->transfer_type) {
 			case CVMX_USB_TRANSFER_CONTROL:
 				type = "SETUP";
 				if (!header) {
-					cvmx_dprintf("%s: fatal error (header == NULL)\n", __func__);
+					cvmx_dprintf("%s: fatal error (header == NULL)\n",
+						     __func__);
 					dir = "INVALID";
 				} else
-					dir = (header->s.request_type & 0x80) ? "IN" : "OUT";
+					dir = (header->s.request_type & 0x80)
+							? "IN" : "OUT";
 				break;
 			case CVMX_USB_TRANSFER_ISOCHRONOUS:
 				type = "ISOCHRONOUS";
@@ -1912,18 +2174,23 @@ static void __cvmx_usb_schedule(cvmx_usb_internal_state_t * usb, int is_sof)
 				break;
 			}
 			cvmx_dprintf("%s: Starting pipe %d, transaction %d on channel %d. %s %s len=%d header=0x%llx\n",
-				     __func__, __cvmx_usb_get_pipe_handle(usb, pipe),
+				     __func__,
+				     __cvmx_usb_get_pipe_handle(usb, pipe),
 				     __cvmx_usb_get_submit_handle(usb, transaction),
-				     channel, type, dir, transaction->buffer_length, (header) ? (unsigned long long)header->u64 : 0ull);
+				     channel, type, dir,
+				     transaction->buffer_length,
+				     (header) ? (unsigned long long)header->u64 : 0ull);
 		}
 		__cvmx_usb_start_channel(usb, channel, pipe);
 	}
 
 done:
 	/* Only enable SOF interrupts when we have transactions pending in the
-	   future that might need to be scheduled */
+	 * future that might need to be scheduled
+	 */
 	need_sof = 0;
-	for (ttype = CVMX_USB_TRANSFER_CONTROL; ttype <= CVMX_USB_TRANSFER_INTERRUPT; ttype++) {
+	for (ttype = CVMX_USB_TRANSFER_CONTROL;
+	     ttype <= CVMX_USB_TRANSFER_INTERRUPT; ttype++) {
 		pipe = usb->active_pipes[ttype].head;
 		while (pipe) {
 			if (pipe->next_tx_frame > usb->frame_number) {
@@ -1933,7 +2200,8 @@ done:
 			pipe = pipe->next;
 		}
 	}
-	USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index), cvmx_usbcx_gintmsk_t, sofmsk, need_sof);
+	USB_SET_FIELD32(CVMX_USBCX_GINTMSK(usb->index), cvmx_usbcx_gintmsk_t,
+			sofmsk, need_sof);
 	CVMX_USB_RETURN_NOTHING();
 }
 
@@ -1951,7 +2219,10 @@ done:
  *               Completion code for the transaction, if any
  */
 static void __cvmx_usb_perform_callback(cvmx_usb_internal_state_t * usb,
-					cvmx_usb_pipe_t * pipe, cvmx_usb_transaction_t * transaction, cvmx_usb_callback_t reason, cvmx_usb_complete_t complete_code)
+					cvmx_usb_pipe_t * pipe,
+					cvmx_usb_transaction_t * transaction,
+					cvmx_usb_callback_t reason,
+					cvmx_usb_complete_t complete_code)
 {
 	cvmx_usb_callback_func_t callback = usb->callback[reason];
 	void *user_data = usb->callback_data[reason];
@@ -1966,7 +2237,8 @@ static void __cvmx_usb_perform_callback(cvmx_usb_internal_state_t * usb,
 		submit_handle = __cvmx_usb_get_submit_handle(usb, transaction);
 		bytes_transferred = transaction->actual_bytes;
 		/* Transactions are allowed to override the default callback */
-		if ((reason == CVMX_USB_CALLBACK_TRANSFER_COMPLETE) && transaction->callback) {
+		if ((reason == CVMX_USB_CALLBACK_TRANSFER_COMPLETE) &&
+		    transaction->callback) {
 			callback = transaction->callback;
 			user_data = transaction->callback_data;
 		}
@@ -1978,12 +2250,17 @@ static void __cvmx_usb_perform_callback(cvmx_usb_internal_state_t * usb,
 	if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_CALLBACKS))
 		cvmx_dprintf("%*s%s: calling callback %p(usb=%p, complete_code=%s, "
 			     "pipe_handle=%d, submit_handle=%d, bytes_transferred=%d, user_data=%p);\n",
-			     2 * usb->indent, "", __func__, callback, usb, __cvmx_usb_complete_to_string(complete_code), pipe_handle, submit_handle, bytes_transferred, user_data);
+			     2 * usb->indent, "", __func__, callback, usb,
+			     __cvmx_usb_complete_to_string(complete_code),
+			     pipe_handle, submit_handle, bytes_transferred,
+			     user_data);
 
-	callback((cvmx_usb_state_t *) usb, reason, complete_code, pipe_handle, submit_handle, bytes_transferred, user_data);
+	callback((cvmx_usb_state_t *) usb, reason, complete_code, pipe_handle,
+		 submit_handle, bytes_transferred, user_data);
 
 	if (cvmx_unlikely(usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_CALLBACKS))
-		cvmx_dprintf("%*s%s: callback %p complete\n", 2 * usb->indent, "", __func__, callback);
+		cvmx_dprintf("%*s%s: callback %p complete\n", 2 * usb->indent,
+			     "", __func__, callback);
 }
 
 /**
@@ -1999,7 +2276,10 @@ static void __cvmx_usb_perform_callback(cvmx_usb_internal_state_t * usb,
  * @param complete_code
  *               Completion code
  */
-static void __cvmx_usb_perform_complete(cvmx_usb_internal_state_t * usb, cvmx_usb_pipe_t * pipe, cvmx_usb_transaction_t * transaction, cvmx_usb_complete_t complete_code)
+static void __cvmx_usb_perform_complete(cvmx_usb_internal_state_t * usb,
+					cvmx_usb_pipe_t * pipe,
+					cvmx_usb_transaction_t * transaction,
+					cvmx_usb_complete_t complete_code)
 {
 	CVMX_USB_LOG_CALLED();
 	CVMX_USB_LOG_PARAM("%p", usb);
@@ -2011,19 +2291,25 @@ static void __cvmx_usb_perform_complete(cvmx_usb_internal_state_t * usb, cvmx_us
 	if (usb->active_split == transaction)
 		usb->active_split = NULL;
 
-	/* Isochronous transactions need extra processing as they might not be done
-	   after a single data transfer */
+	/* Isochronous transactions need extra processing as they might not be
+	 * done after a single data transfer
+	 */
 	if (cvmx_unlikely(transaction->type == CVMX_USB_TRANSFER_ISOCHRONOUS)) {
 		/* Update the number of bytes transferred in this ISO packet */
 		transaction->iso_packets[0].length = transaction->actual_bytes;
 		transaction->iso_packets[0].status = complete_code;
 
-		/* If there are more ISOs pending and we succeeded, schedule the next
-		   one */
-		if ((transaction->iso_number_packets > 1) && (complete_code == CVMX_USB_COMPLETE_SUCCESS)) {
-			transaction->actual_bytes = 0;	/* No bytes transferred for this packet as of yet */
-			transaction->iso_number_packets--;	/* One less ISO waiting to transfer */
-			transaction->iso_packets++;	/* Increment to the next location in our packet array */
+		/* If there are more ISOs pending and we succeeded, schedule
+		 * the next one
+		 */
+		if ((transaction->iso_number_packets > 1) &&
+		    (complete_code == CVMX_USB_COMPLETE_SUCCESS)) {
+			/* No bytes transferred for this packet as of yet */
+			transaction->actual_bytes = 0;
+			/* One less ISO waiting to transfer */
+			transaction->iso_number_packets--;
+			/* Increment to the next location in our packet array */
+			transaction->iso_packets++;
 			transaction->stage = CVMX_USB_STAGE_NON_CONTROL;
 			goto done;
 		}
@@ -2039,11 +2325,14 @@ static void __cvmx_usb_perform_complete(cvmx_usb_internal_state_t * usb, cvmx_us
 	else
 		pipe->head = transaction->next;
 	if (!pipe->head) {
-		__cvmx_usb_remove_pipe(usb->active_pipes + pipe->transfer_type, pipe);
+		__cvmx_usb_remove_pipe(usb->active_pipes + pipe->transfer_type,
+				       pipe);
 		__cvmx_usb_append_pipe(&usb->idle_pipes, pipe);
 
 	}
-	__cvmx_usb_perform_callback(usb, pipe, transaction, CVMX_USB_CALLBACK_TRANSFER_COMPLETE, complete_code);
+	__cvmx_usb_perform_callback(usb, pipe, transaction,
+				    CVMX_USB_CALLBACK_TRANSFER_COMPLETE,
+				    complete_code);
 	__cvmx_usb_free_transaction(usb, transaction);
 done:
 	CVMX_USB_RETURN_NOTHING();
@@ -2083,7 +2372,11 @@ static int __cvmx_usb_submit_transaction(cvmx_usb_internal_state_t * usb,
 					 uint64_t buffer,
 					 int buffer_length,
 					 uint64_t control_header,
-					 int iso_start_frame, int iso_number_packets, cvmx_usb_iso_packet_t * iso_packets, cvmx_usb_callback_func_t callback, void *user_data)
+					 int iso_start_frame,
+					 int iso_number_packets,
+					 cvmx_usb_iso_packet_t * iso_packets,
+					 cvmx_usb_callback_func_t callback,
+					 void *user_data)
 {
 	int submit_handle;
 	cvmx_usb_transaction_t *transaction;
@@ -2123,11 +2416,13 @@ static int __cvmx_usb_submit_transaction(cvmx_usb_internal_state_t * usb,
 		transaction->prev->next = transaction;
 	} else {
 		if (pipe->next_tx_frame < usb->frame_number)
-			pipe->next_tx_frame = usb->frame_number + pipe->interval - (usb->frame_number - pipe->next_tx_frame) % pipe->interval;
+			pipe->next_tx_frame = usb->frame_number + pipe->interval -
+				(usb->frame_number - pipe->next_tx_frame) % pipe->interval;
 		transaction->prev = NULL;
 		pipe->head = transaction;
 		__cvmx_usb_remove_pipe(&usb->idle_pipes, pipe);
-		__cvmx_usb_append_pipe(usb->active_pipes + pipe->transfer_type, pipe);
+		__cvmx_usb_append_pipe(usb->active_pipes + pipe->transfer_type,
+				       pipe);
 	}
 	pipe->tail = transaction;
 
@@ -2171,7 +2466,9 @@ static int __cvmx_usb_submit_transaction(cvmx_usb_internal_state_t * usb,
  *         failure. Negative values are failure codes from
  *         cvmx_usb_status_t.
  */
-int cvmx_usb_submit_bulk(cvmx_usb_state_t * state, int pipe_handle, uint64_t buffer, int buffer_length, cvmx_usb_callback_func_t callback, void *user_data)
+int cvmx_usb_submit_bulk(cvmx_usb_state_t * state, int pipe_handle,
+			 uint64_t buffer, int buffer_length,
+			 cvmx_usb_callback_func_t callback, void *user_data)
 {
 	int submit_handle;
 	cvmx_usb_internal_state_t *usb = (cvmx_usb_internal_state_t *) state;
@@ -2188,8 +2485,11 @@ int cvmx_usb_submit_bulk(cvmx_usb_state_t * state, int pipe_handle, uint64_t buf
 	if (cvmx_unlikely(buffer_length < 0))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 
-	submit_handle = __cvmx_usb_submit_transaction(usb, pipe_handle, CVMX_USB_TRANSFER_BULK, 0,	/* flags */
-						      buffer, buffer_length, 0,	/* control_header */
+	submit_handle = __cvmx_usb_submit_transaction(usb, pipe_handle,
+						      CVMX_USB_TRANSFER_BULK,
+						      0,	/* flags */
+						      buffer, buffer_length,
+						      0,	/* control_header */
 						      0,	/* iso_start_frame */
 						      0,	/* iso_number_packets */
 						      NULL,	/* iso_packets */
@@ -2230,7 +2530,10 @@ EXPORT_SYMBOL(cvmx_usb_submit_bulk);
  *         failure. Negative values are failure codes from
  *         cvmx_usb_status_t.
  */
-int cvmx_usb_submit_interrupt(cvmx_usb_state_t * state, int pipe_handle, uint64_t buffer, int buffer_length, cvmx_usb_callback_func_t callback, void *user_data)
+int cvmx_usb_submit_interrupt(cvmx_usb_state_t * state, int pipe_handle,
+			      uint64_t buffer, int buffer_length,
+			      cvmx_usb_callback_func_t callback,
+			      void *user_data)
 {
 	int submit_handle;
 	cvmx_usb_internal_state_t *usb = (cvmx_usb_internal_state_t *) state;
@@ -2247,8 +2550,11 @@ int cvmx_usb_submit_interrupt(cvmx_usb_state_t * state, int pipe_handle, uint64_
 	if (cvmx_unlikely(buffer_length < 0))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 
-	submit_handle = __cvmx_usb_submit_transaction(usb, pipe_handle, CVMX_USB_TRANSFER_INTERRUPT, 0,	/* flags */
-						      buffer, buffer_length, 0,	/* control_header */
+	submit_handle = __cvmx_usb_submit_transaction(usb, pipe_handle,
+						      CVMX_USB_TRANSFER_INTERRUPT,
+						      0,	/* flags */
+						      buffer, buffer_length,
+						      0,	/* control_header */
 						      0,	/* iso_start_frame */
 						      0,	/* iso_number_packets */
 						      NULL,	/* iso_packets */
@@ -2294,7 +2600,9 @@ EXPORT_SYMBOL(cvmx_usb_submit_interrupt);
  *         cvmx_usb_status_t.
  */
 int cvmx_usb_submit_control(cvmx_usb_state_t * state, int pipe_handle,
-			    uint64_t control_header, uint64_t buffer, int buffer_length, cvmx_usb_callback_func_t callback, void *user_data)
+			    uint64_t control_header, uint64_t buffer,
+			    int buffer_length,
+			    cvmx_usb_callback_func_t callback, void *user_data)
 {
 	int submit_handle;
 	cvmx_usb_internal_state_t *usb = (cvmx_usb_internal_state_t *) state;
@@ -2318,8 +2626,12 @@ int cvmx_usb_submit_control(cvmx_usb_state_t * state, int pipe_handle,
 	if ((header->s.request_type & 0x80) == 0)
 		buffer_length = cvmx_le16_to_cpu(header->s.length);
 
-	submit_handle = __cvmx_usb_submit_transaction(usb, pipe_handle, CVMX_USB_TRANSFER_CONTROL, 0,	/* flags */
-						      buffer, buffer_length, control_header, 0,	/* iso_start_frame */
+	submit_handle = __cvmx_usb_submit_transaction(usb, pipe_handle,
+						      CVMX_USB_TRANSFER_CONTROL,
+						      0,	/* flags */
+						      buffer, buffer_length,
+						      control_header,
+						      0,	/* iso_start_frame */
 						      0,	/* iso_number_packets */
 						      NULL,	/* iso_packets */
 						      callback, user_data);
@@ -2375,7 +2687,11 @@ EXPORT_SYMBOL(cvmx_usb_submit_control);
  */
 int cvmx_usb_submit_isochronous(cvmx_usb_state_t * state, int pipe_handle,
 				int start_frame, int flags,
-				int number_packets, cvmx_usb_iso_packet_t packets[], uint64_t buffer, int buffer_length, cvmx_usb_callback_func_t callback, void *user_data)
+				int number_packets,
+				cvmx_usb_iso_packet_t packets[],
+				uint64_t buffer, int buffer_length,
+				cvmx_usb_callback_func_t callback,
+				void *user_data)
 {
 	int submit_handle;
 	cvmx_usb_internal_state_t *usb = (cvmx_usb_internal_state_t *) state;
@@ -2404,8 +2720,14 @@ int cvmx_usb_submit_isochronous(cvmx_usb_state_t * state, int pipe_handle,
 	if (cvmx_unlikely(buffer_length < 0))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 
-	submit_handle = __cvmx_usb_submit_transaction(usb, pipe_handle, CVMX_USB_TRANSFER_ISOCHRONOUS, flags, buffer, buffer_length, 0,	/* control_header */
-						      start_frame, number_packets, packets, callback, user_data);
+	submit_handle = __cvmx_usb_submit_transaction(usb, pipe_handle,
+						      CVMX_USB_TRANSFER_ISOCHRONOUS,
+						      flags,
+						      buffer, buffer_length,
+						      0,	/* control_header */
+						      start_frame,
+						      number_packets, packets,
+						      callback, user_data);
 	CVMX_USB_RETURN(submit_handle);
 }
 
@@ -2423,12 +2745,14 @@ EXPORT_SYMBOL(cvmx_usb_submit_isochronous);
  * @param pipe_handle
  *               Pipe handle to cancel requests in.
  * @param submit_handle
- *               Handle to transaction to cancel, returned by the submit function.
+ *               Handle to transaction to cancel, returned by the submit
+ *               function.
  *
  * @return CVMX_USB_SUCCESS or a negative error code defined in
  *         cvmx_usb_status_t.
  */
-cvmx_usb_status_t cvmx_usb_cancel(cvmx_usb_state_t * state, int pipe_handle, int submit_handle)
+cvmx_usb_status_t cvmx_usb_cancel(cvmx_usb_state_t * state, int pipe_handle,
+				  int submit_handle)
 {
 	cvmx_usb_transaction_t *transaction;
 	cvmx_usb_internal_state_t *usb = (cvmx_usb_internal_state_t *) state;
@@ -2441,7 +2765,8 @@ cvmx_usb_status_t cvmx_usb_cancel(cvmx_usb_state_t * state, int pipe_handle, int
 
 	if (cvmx_unlikely((pipe_handle < 0) || (pipe_handle >= MAX_PIPES)))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
-	if (cvmx_unlikely((submit_handle < 0) || (submit_handle >= MAX_TRANSACTIONS)))
+	if (cvmx_unlikely((submit_handle < 0) ||
+			  (submit_handle >= MAX_TRANSACTIONS)))
 		CVMX_USB_RETURN(CVMX_USB_INVALID_PARAM);
 
 	/* Fail if the pipe isn't open */
@@ -2456,7 +2781,8 @@ cvmx_usb_status_t cvmx_usb_cancel(cvmx_usb_state_t * state, int pipe_handle, int
 
 	/* If the transaction is the HEAD of the queue and scheduled. We need to
 	   treat it special */
-	if ((pipe->head == transaction) && (pipe->flags & __CVMX_USB_PIPE_FLAGS_SCHEDULED)) {
+	if ((pipe->head == transaction) &&
+	    (pipe->flags & __CVMX_USB_PIPE_FLAGS_SCHEDULED)) {
 		cvmx_usbcx_hccharx_t usbc_hcchar;
 
 		usb->pipe_for_channel[pipe->channel] = NULL;
@@ -2464,14 +2790,22 @@ cvmx_usb_status_t cvmx_usb_cancel(cvmx_usb_state_t * state, int pipe_handle, int
 
 		CVMX_SYNCW;
 
-		usbc_hcchar.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCCHARX(pipe->channel, usb->index));
-		/* If the channel isn't enabled then the transaction already completed */
+		usbc_hcchar.u32 = __cvmx_usb_read_csr32(usb,
+							CVMX_USBCX_HCCHARX(pipe->channel,
+									   usb->index));
+		/* If the channel isn't enabled then the transaction already
+		 * completed
+		 */
 		if (usbc_hcchar.s.chena) {
 			usbc_hcchar.s.chdis = 1;
-			__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCCHARX(pipe->channel, usb->index), usbc_hcchar.u32);
+			__cvmx_usb_write_csr32(usb,
+					       CVMX_USBCX_HCCHARX(pipe->channel,
+								  usb->index),
+					       usbc_hcchar.u32);
 		}
 	}
-	__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_CANCEL);
+	__cvmx_usb_perform_complete(usb, pipe, transaction,
+				    CVMX_USB_COMPLETE_CANCEL);
 	CVMX_USB_RETURN(CVMX_USB_SUCCESS);
 }
 
@@ -2507,7 +2841,8 @@ cvmx_usb_status_t cvmx_usb_cancel_all(cvmx_usb_state_t * state, int pipe_handle)
 	/* Simply loop through and attempt to cancel each transaction */
 	while (pipe->head) {
 		cvmx_usb_status_t result = cvmx_usb_cancel(state, pipe_handle,
-							   __cvmx_usb_get_submit_handle(usb, pipe->head));
+							   __cvmx_usb_get_submit_handle(usb,
+											pipe->head));
 		if (cvmx_unlikely(result != CVMX_USB_SUCCESS))
 			CVMX_USB_RETURN(result);
 	}
@@ -2568,7 +2903,10 @@ EXPORT_SYMBOL(cvmx_usb_close_pipe);
  * @return CVMX_USB_SUCCESS or a negative error code defined in
  *         cvmx_usb_status_t.
  */
-cvmx_usb_status_t cvmx_usb_register_callback(cvmx_usb_state_t * state, cvmx_usb_callback_t reason, cvmx_usb_callback_func_t callback, void *user_data)
+cvmx_usb_status_t cvmx_usb_register_callback(cvmx_usb_state_t * state,
+					     cvmx_usb_callback_t reason,
+					     cvmx_usb_callback_func_t callback,
+					     void *user_data)
 {
 	cvmx_usb_internal_state_t *usb = (cvmx_usb_internal_state_t *) state;
 
@@ -2608,7 +2946,8 @@ int cvmx_usb_get_frame_number(cvmx_usb_state_t * state)
 	CVMX_USB_LOG_CALLED();
 	CVMX_USB_LOG_PARAM("%p", state);
 
-	usbc_hfnum.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HFNUM(usb->index));
+	usbc_hfnum.u32 = __cvmx_usb_read_csr32(usb,
+					       CVMX_USBCX_HFNUM(usb->index));
 	frame_number = usbc_hfnum.s.frnum;
 
 	CVMX_USB_RETURN(frame_number);
@@ -2641,7 +2980,9 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 	CVMX_USB_LOG_PARAM("%d", channel);
 
 	/* Read the interrupt status bits for the channel */
-	usbc_hcint.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCINTX(channel, usb->index));
+	usbc_hcint.u32 = __cvmx_usb_read_csr32(usb,
+					       CVMX_USBCX_HCINTX(channel,
+								 usb->index));
 
 #if 0
 	cvmx_dprintf("Channel %d%s%s%s%s%s%s%s%s%s%s%s\n", channel,
@@ -2657,44 +2998,63 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 #endif
 
 	if (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA) {
-		usbc_hcchar.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCCHARX(channel, usb->index));
+		usbc_hcchar.u32 = __cvmx_usb_read_csr32(usb,
+							CVMX_USBCX_HCCHARX(channel,
+									   usb->index));
 
 		if (usbc_hcchar.s.chena && usbc_hcchar.s.chdis) {
-			/* There seems to be a bug in CN31XX which can cause interrupt
-			   IN transfers to get stuck until we do a write of HCCHARX
-			   without changing things */
-			__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCCHARX(channel, usb->index), usbc_hcchar.u32);
+			/* There seems to be a bug in CN31XX which can cause
+			 * interrupt IN transfers to get stuck until we do a
+			 * write of HCCHARX without changing things
+			 */
+			__cvmx_usb_write_csr32(usb,
+					       CVMX_USBCX_HCCHARX(channel,
+								  usb->index),
+					       usbc_hcchar.u32);
 			CVMX_USB_RETURN(0);
 		}
 
-		/* In non DMA mode the channels don't halt themselves. We need to
-		   manually disable channels that are left running */
+		/* In non DMA mode the channels don't halt themselves. We need
+		 * to manually disable channels that are left running
+		 */
 		if (!usbc_hcint.s.chhltd) {
 			if (usbc_hcchar.s.chena) {
 				cvmx_usbcx_hcintmskx_t hcintmsk;
 				/* Disable all interrupts except CHHLTD */
 				hcintmsk.u32 = 0;
 				hcintmsk.s.chhltdmsk = 1;
-				__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCINTMSKX(channel, usb->index), hcintmsk.u32);
+				__cvmx_usb_write_csr32(usb,
+						       CVMX_USBCX_HCINTMSKX(channel,
+									    usb->index),
+						       hcintmsk.u32);
 				usbc_hcchar.s.chdis = 1;
-				__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCCHARX(channel, usb->index), usbc_hcchar.u32);
+				__cvmx_usb_write_csr32(usb,
+						       CVMX_USBCX_HCCHARX(channel,
+									  usb->index),
+						       usbc_hcchar.u32);
 				CVMX_USB_RETURN(0);
 			} else if (usbc_hcint.s.xfercompl) {
-				/* Successful IN/OUT with transfer complete. Channel halt isn't needed */
+				/* Successful IN/OUT with transfer complete.
+				 * Channel halt isn't needed
+				 */
 			} else {
-				cvmx_dprintf("USB%d: Channel %d interrupt without halt\n", usb->index, channel);
+				cvmx_dprintf("USB%d: Channel %d interrupt without halt\n",
+					     usb->index, channel);
 				CVMX_USB_RETURN(0);
 			}
 		}
 	} else {
-		/* There is are no interrupts that we need to process when the channel is
-		   still running */
+		/* There is are no interrupts that we need to process when the
+		 * channel is still running
+		 */
 		if (!usbc_hcint.s.chhltd)
 			CVMX_USB_RETURN(0);
 	}
 
 	/* Disable the channel interrupts now that it is done */
-	__cvmx_usb_write_csr32(usb, CVMX_USBCX_HCINTMSKX(channel, usb->index), 0);
+	__cvmx_usb_write_csr32(usb,
+			       CVMX_USBCX_HCINTMSKX(channel, usb->index),
+			       0);
 	usb->idle_hardware_channels |= (1 << channel);
 
 	/* Make sure this channel is tied to a valid pipe */
@@ -2706,33 +3066,43 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 	transaction = pipe->head;
 	CVMX_PREFETCH0(transaction);
 
-	/* Disconnect this pipe from the HW channel. Later the schedule function will
-	   figure out which pipe needs to go */
+	/* Disconnect this pipe from the HW channel. Later the schedule
+	 * function will figure out which pipe needs to go
+	 */
 	usb->pipe_for_channel[channel] = NULL;
 	pipe->flags &= ~__CVMX_USB_PIPE_FLAGS_SCHEDULED;
 
 	/* Read the channel config info so we can figure out how much data
 	   transfered */
-	usbc_hcchar.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCCHARX(channel, usb->index));
-	usbc_hctsiz.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HCTSIZX(channel, usb->index));
-
-	/* Calculating the number of bytes successfully transferred is dependent on
-	   the transfer direction */
+	usbc_hcchar.u32 = __cvmx_usb_read_csr32(usb,
+						CVMX_USBCX_HCCHARX(channel,
+								   usb->index));
+	usbc_hctsiz.u32 = __cvmx_usb_read_csr32(usb,
+						CVMX_USBCX_HCTSIZX(channel,
+								   usb->index));
+
+	/* Calculating the number of bytes successfully transferred is
+	 * dependent on the transfer direction
+	 */
 	packets_processed = transaction->pktcnt - usbc_hctsiz.s.pktcnt;
 	if (usbc_hcchar.s.epdir) {
-		/* IN transactions are easy. For every byte received the hardware
-		   decrements xfersize. All we need to do is subtract the current
-		   value of xfersize from its starting value and we know how many
-		   bytes were written to the buffer */
-		bytes_this_transfer = transaction->xfersize - usbc_hctsiz.s.xfersize;
+		/* IN transactions are easy. For every byte received the
+		 * hardware decrements xfersize. All we need to do is subtract
+		 * the current value of xfersize from its starting value and we
+		 * know how many bytes were written to the buffer
+		 */
+		bytes_this_transfer =
+			transaction->xfersize - usbc_hctsiz.s.xfersize;
 	} else {
 		/* OUT transaction don't decrement xfersize. Instead pktcnt is
-		   decremented on every successful packet send. The hardware does
-		   this when it receives an ACK, or NYET. If it doesn't
-		   receive one of these responses pktcnt doesn't change */
+		 * decremented on every successful packet send. The hardware
+		 * does this when it receives an ACK, or NYET. If it doesn't
+		 * receive one of these responses pktcnt doesn't change
+		 */
 		bytes_this_transfer = packets_processed * usbc_hcchar.s.mps;
 		/* The last packet may not be a full transfer if we didn't have
-		   enough data */
+		 * enough data
+		 */
 		if (bytes_this_transfer > transaction->xfersize)
 			bytes_this_transfer = transaction->xfersize;
 	}
@@ -2743,102 +3113,136 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 		bytes_in_last_packet = bytes_this_transfer;
 
 	/* As a special case, setup transactions output the setup header, not
-	   the user's data. For this reason we don't count setup data as bytes
-	   transferred */
-	if ((transaction->stage == CVMX_USB_STAGE_SETUP) || (transaction->stage == CVMX_USB_STAGE_SETUP_SPLIT_COMPLETE))
+	 * the user's data. For this reason we don't count setup data as bytes
+	 * transferred
+	 */
+	if ((transaction->stage == CVMX_USB_STAGE_SETUP) ||
+	    (transaction->stage == CVMX_USB_STAGE_SETUP_SPLIT_COMPLETE))
 		bytes_this_transfer = 0;
 
 	/* Optional debug output */
 	if (cvmx_unlikely((usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_DEBUG_TRANSFERS) || (pipe->flags & CVMX_USB_PIPE_FLAGS_DEBUG_TRANSFERS)))
 		cvmx_dprintf("%s: Channel %d halted. Pipe %d transaction %d stage %d bytes=%d\n",
-			     __func__, channel, __cvmx_usb_get_pipe_handle(usb, pipe), __cvmx_usb_get_submit_handle(usb, transaction), transaction->stage, bytes_this_transfer);
+			     __func__, channel,
+			     __cvmx_usb_get_pipe_handle(usb, pipe),
+			     __cvmx_usb_get_submit_handle(usb, transaction),
+			     transaction->stage, bytes_this_transfer);
 
 	/* Add the bytes transferred to the running total. It is important that
-	   bytes_this_transfer doesn't count any data that needs to be
-	   retransmitted */
+	 * bytes_this_transfer doesn't count any data that needs to be
+	 * retransmitted
+	 */
 	transaction->actual_bytes += bytes_this_transfer;
 	if (transaction->type == CVMX_USB_TRANSFER_ISOCHRONOUS)
 		buffer_space_left = transaction->iso_packets[0].length - transaction->actual_bytes;
 	else
 		buffer_space_left = transaction->buffer_length - transaction->actual_bytes;
 
-	/* We need to remember the PID toggle state for the next transaction. The
-	   hardware already updated it for the next transaction */
+	/* We need to remember the PID toggle state for the next transaction.
+	 * The hardware already updated it for the next transaction
+	 */
 	pipe->pid_toggle = !(usbc_hctsiz.s.pid == 0);
 
-	/* For high speed bulk out, assume the next transaction will need to do a
-	   ping before proceeding. If this isn't true the ACK processing below
-	   will clear this flag */
-	if ((pipe->device_speed == CVMX_USB_SPEED_HIGH) && (pipe->transfer_type == CVMX_USB_TRANSFER_BULK) && (pipe->transfer_dir == CVMX_USB_DIRECTION_OUT))
+	/* For high speed bulk out, assume the next transaction will need to do
+	 * a ping before proceeding. If this isn't true the ACK processing
+	 * below will clear this flag
+	 */
+	if ((pipe->device_speed == CVMX_USB_SPEED_HIGH) &&
+	    (pipe->transfer_type == CVMX_USB_TRANSFER_BULK) &&
+	    (pipe->transfer_dir == CVMX_USB_DIRECTION_OUT))
 		pipe->flags |= __CVMX_USB_PIPE_FLAGS_NEED_PING;
 
 	if (usbc_hcint.s.stall) {
-		/* STALL as a response means this transaction cannot be completed
-		   because the device can't process transactions. Tell the user. Any
-		   data that was transferred will be counted on the actual bytes
-		   transferred */
+		/* STALL as a response means this transaction cannot be
+		 * completed because the device can't process transactions.
+		 * Tell the user.  Any data that was transferred will be
+		 * counted on the actual bytes transferred
+		 */
 		pipe->pid_toggle = 0;
-		__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_STALL);
+		__cvmx_usb_perform_complete(usb, pipe, transaction,
+					    CVMX_USB_COMPLETE_STALL);
 	} else if (usbc_hcint.s.xacterr) {
-		/* We know at least one packet worked if we get a ACK or NAK. Reset the retry counter */
+		/* We know at least one packet worked if we get a ACK or NAK.
+		 * Reset the retry counter
+		 */
 		if (usbc_hcint.s.nak || usbc_hcint.s.ack)
 			transaction->retries = 0;
 		transaction->retries++;
 		if (transaction->retries > MAX_RETRIES) {
-			/* XactErr as a response means the device signaled something wrong with
-			   the transfer. For example, PID toggle errors cause these */
-			__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_XACTERR);
+			/* XactErr as a response means the device signaled
+			 * something wrong with the transfer. For example, PID
+			 * toggle errors cause these
+			 */
+			__cvmx_usb_perform_complete(usb, pipe, transaction,
+						    CVMX_USB_COMPLETE_XACTERR);
 		} else {
-			/* If this was a split then clear our split in progress marker */
+			/* If this was a split then clear our split in progress
+			 * marker
+			 */
 			if (usb->active_split == transaction)
 				usb->active_split = NULL;
-			/* Rewind to the beginning of the transaction by anding off the
-			   split complete bit */
+			/* Rewind to the beginning of the transaction by anding
+			 * off the split complete bit
+			 */
 			transaction->stage &= ~1;
 			pipe->split_sc_frame = -1;
 			pipe->next_tx_frame += pipe->interval;
 			if (pipe->next_tx_frame < usb->frame_number)
-				pipe->next_tx_frame = usb->frame_number + pipe->interval - (usb->frame_number - pipe->next_tx_frame) % pipe->interval;
+				pipe->next_tx_frame =
+					usb->frame_number
+					+ pipe->interval
+					- (usb->frame_number - pipe->next_tx_frame) % pipe->interval;
 		}
 	} else if (usbc_hcint.s.bblerr) {
 		/* Babble Error (BblErr) */
-		__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_BABBLEERR);
+		__cvmx_usb_perform_complete(usb, pipe, transaction,
+					    CVMX_USB_COMPLETE_BABBLEERR);
 	} else if (usbc_hcint.s.datatglerr) {
 		/* We'll retry the exact same transaction again */
 		transaction->retries++;
 	} else if (usbc_hcint.s.nyet) {
-		/* NYET as a response is only allowed in three cases: as a response to
-		   a ping, as a response to a split transaction, and as a response to
-		   a bulk out. The ping case is handled by hardware, so we only have
-		   splits and bulk out */
+		/* NYET as a response is only allowed in three cases: as a
+		 * response to a ping, as a response to a split transaction,
+		 * and as a response to a bulk out. The ping case is handled by
+		 * hardware, so we only have splits and bulk out
+		 */
 		if (!__cvmx_usb_pipe_needs_split(usb, pipe)) {
 			transaction->retries = 0;
-			/* If there is more data to go then we need to try again. Otherwise
-			   this transaction is complete */
-			if ((buffer_space_left == 0) || (bytes_in_last_packet < pipe->max_packet))
-				__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_SUCCESS);
+			/* If there is more data to go then we need to try
+			 * again.  Otherwise this transaction is complete
+			 */
+			if ((buffer_space_left == 0) ||
+			    (bytes_in_last_packet < pipe->max_packet))
+				__cvmx_usb_perform_complete(usb, pipe,
+							    transaction,
+							    CVMX_USB_COMPLETE_SUCCESS);
 		} else {
-			/* Split transactions retry the split complete 4 times then rewind
-			   to the start split and do the entire transactions again */
+			/* Split transactions retry the split complete 4 times
+			 * then rewind to the start split and do the entire
+			 * transactions again
+			 */
 			transaction->retries++;
 			if ((transaction->retries & 0x3) == 0) {
-				/* Rewind to the beginning of the transaction by anding off the
-				   split complete bit */
+				/* Rewind to the beginning of the transaction
+				 * by anding off the split complete bit
+				 */
 				transaction->stage &= ~1;
 				pipe->split_sc_frame = -1;
 			}
 		}
 	} else if (usbc_hcint.s.ack) {
 		transaction->retries = 0;
-		/* The ACK bit can only be checked after the other error bits. This is
-		   because a multi packet transfer may succeed in a number of packets
-		   and then get a different response on the last packet. In this case
-		   both ACK and the last response bit will be set. If none of the
-		   other response bits is set, then the last packet must have been an
-		   ACK */
-
-		/* Since we got an ACK, we know we don't need to do a ping on this
-		   pipe */
+		/* The ACK bit can only be checked after the other error bits.
+		 * This is because a multi packet transfer may succeed in a
+		 * number of packets and then get a different response on the
+		 * last packet.  In this case both ACK and the last response
+		 * bit will be set.  If none of the other response bits is set,
+		 * then the last packet must have been an ACK
+		 */
+
+		/* Since we got an ACK, we know we don't need to do a ping on
+		 * this pipe
+		 */
 		pipe->flags &= ~__CVMX_USB_PIPE_FLAGS_NEED_PING;
 
 		switch (transaction->type) {
@@ -2847,14 +3251,18 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 			case CVMX_USB_STAGE_NON_CONTROL:
 			case CVMX_USB_STAGE_NON_CONTROL_SPLIT_COMPLETE:
 				/* This should be impossible */
-				__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_ERROR);
+				__cvmx_usb_perform_complete(usb, pipe,
+							    transaction,
+							    CVMX_USB_COMPLETE_ERROR);
 				break;
 			case CVMX_USB_STAGE_SETUP:
 				pipe->pid_toggle = 1;
 				if (__cvmx_usb_pipe_needs_split(usb, pipe))
 					transaction->stage = CVMX_USB_STAGE_SETUP_SPLIT_COMPLETE;
 				else {
-					cvmx_usb_control_header_t *header = cvmx_phys_to_ptr(transaction->control_header);
+					cvmx_usb_control_header_t *header =
+						cvmx_phys_to_ptr(transaction->control_header);
+
 					if (header->s.length)
 						transaction->stage = CVMX_USB_STAGE_DATA;
 					else
@@ -2863,7 +3271,9 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 				break;
 			case CVMX_USB_STAGE_SETUP_SPLIT_COMPLETE:
 				{
-					cvmx_usb_control_header_t *header = cvmx_phys_to_ptr(transaction->control_header);
+					cvmx_usb_control_header_t *header =
+						cvmx_phys_to_ptr(transaction->control_header);
+
 					if (header->s.length)
 						transaction->stage = CVMX_USB_STAGE_DATA;
 					else
@@ -2873,22 +3283,26 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 			case CVMX_USB_STAGE_DATA:
 				if (__cvmx_usb_pipe_needs_split(usb, pipe)) {
 					transaction->stage = CVMX_USB_STAGE_DATA_SPLIT_COMPLETE;
-					/* For setup OUT data that are splits, the hardware
-					   doesn't appear to count transferred data. Here
-					   we manually update the data transferred */
+					/* For setup OUT data that are splits,
+					 * the hardware doesn't appear to count
+					 * transferred data.  Here we manually
+					 * update the data transferred
+					 */
 					if (!usbc_hcchar.s.epdir) {
 						if (buffer_space_left < pipe->max_packet)
 							transaction->actual_bytes += buffer_space_left;
 						else
 							transaction->actual_bytes += pipe->max_packet;
 					}
-				} else if ((buffer_space_left == 0) || (bytes_in_last_packet < pipe->max_packet)) {
+				} else if ((buffer_space_left == 0) ||
+					   (bytes_in_last_packet < pipe->max_packet)) {
 					pipe->pid_toggle = 1;
 					transaction->stage = CVMX_USB_STAGE_STATUS;
 				}
 				break;
 			case CVMX_USB_STAGE_DATA_SPLIT_COMPLETE:
-				if ((buffer_space_left == 0) || (bytes_in_last_packet < pipe->max_packet)) {
+				if ((buffer_space_left == 0) ||
+				    (bytes_in_last_packet < pipe->max_packet)) {
 					pipe->pid_toggle = 1;
 					transaction->stage = CVMX_USB_STAGE_STATUS;
 				} else {
@@ -2899,10 +3313,14 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 				if (__cvmx_usb_pipe_needs_split(usb, pipe))
 					transaction->stage = CVMX_USB_STAGE_STATUS_SPLIT_COMPLETE;
 				else
-					__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_SUCCESS);
+					__cvmx_usb_perform_complete(usb, pipe,
+								    transaction,
+								    CVMX_USB_COMPLETE_SUCCESS);
 				break;
 			case CVMX_USB_STAGE_STATUS_SPLIT_COMPLETE:
-				__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_SUCCESS);
+				__cvmx_usb_perform_complete(usb, pipe,
+							    transaction,
+							    CVMX_USB_COMPLETE_SUCCESS);
 				break;
 			}
 			break;
@@ -2916,54 +3334,80 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 				if (transaction->stage == CVMX_USB_STAGE_NON_CONTROL)
 					transaction->stage = CVMX_USB_STAGE_NON_CONTROL_SPLIT_COMPLETE;
 				else {
-					if (buffer_space_left && (bytes_in_last_packet == pipe->max_packet))
+					if (buffer_space_left &&
+					    (bytes_in_last_packet == pipe->max_packet))
 						transaction->stage = CVMX_USB_STAGE_NON_CONTROL;
 					else {
 						if (transaction->type == CVMX_USB_TRANSFER_INTERRUPT)
 							pipe->next_tx_frame += pipe->interval;
-						__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_SUCCESS);
+						__cvmx_usb_perform_complete(usb,
+									    pipe,
+									    transaction,
+									    CVMX_USB_COMPLETE_SUCCESS);
 					}
 				}
 			} else {
 				if ((pipe->device_speed == CVMX_USB_SPEED_HIGH) &&
-				    (pipe->transfer_type == CVMX_USB_TRANSFER_BULK) && (pipe->transfer_dir == CVMX_USB_DIRECTION_OUT) && (usbc_hcint.s.nak))
+				    (pipe->transfer_type == CVMX_USB_TRANSFER_BULK) &&
+				    (pipe->transfer_dir == CVMX_USB_DIRECTION_OUT) &&
+				    (usbc_hcint.s.nak))
 					pipe->flags |= __CVMX_USB_PIPE_FLAGS_NEED_PING;
-				if (!buffer_space_left || (bytes_in_last_packet < pipe->max_packet)) {
+				if (!buffer_space_left ||
+				    (bytes_in_last_packet < pipe->max_packet)) {
 					if (transaction->type == CVMX_USB_TRANSFER_INTERRUPT)
 						pipe->next_tx_frame += pipe->interval;
-					__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_SUCCESS);
+					__cvmx_usb_perform_complete(usb, pipe,
+								    transaction,
+								    CVMX_USB_COMPLETE_SUCCESS);
 				}
 			}
 			break;
 		case CVMX_USB_TRANSFER_ISOCHRONOUS:
 			if (__cvmx_usb_pipe_needs_split(usb, pipe)) {
-				/* ISOCHRONOUS OUT splits don't require a complete split stage.
-				   Instead they use a sequence of begin OUT splits to transfer
-				   the data 188 bytes at a time. Once the transfer is complete,
-				   the pipe sleeps until the next schedule interval */
+				/* ISOCHRONOUS OUT splits don't require a
+				 * complete split stage.  Instead they use a
+				 * sequence of begin OUT splits to transfer
+				 * the data 188 bytes at a time.  Once the
+				 * transfer is complete, the pipe sleeps until
+				 * the next schedule interval
+				 */
 				if (pipe->transfer_dir == CVMX_USB_DIRECTION_OUT) {
-					/* If no space left or this wasn't a max size packet then
-					   this transfer is complete. Otherwise start it again
-					   to send the next 188 bytes */
-					if (!buffer_space_left || (bytes_this_transfer < 188)) {
+					/* If no space left or this wasn't a
+					 * max size packet then this transfer
+					 * is complete. Otherwise start it
+					 * again to send the next 188 bytes
+					 */
+					if (!buffer_space_left ||
+					    (bytes_this_transfer < 188)) {
 						pipe->next_tx_frame += pipe->interval;
-						__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_SUCCESS);
+						__cvmx_usb_perform_complete(usb,
+									    pipe,
+									    transaction,
+									    CVMX_USB_COMPLETE_SUCCESS);
 					}
 				} else {
 					if (transaction->stage == CVMX_USB_STAGE_NON_CONTROL_SPLIT_COMPLETE) {
-						/* We are in the incoming data phase. Keep getting
-						   data until we run out of space or get a small
-						   packet */
-						if ((buffer_space_left == 0) || (bytes_in_last_packet < pipe->max_packet)) {
+						/* We are in the incoming data
+						 * phase.  Keep getting data
+						 * until we run out of space or
+						 * get a small packet
+						 */
+						if ((buffer_space_left == 0) ||
+						    (bytes_in_last_packet < pipe->max_packet)) {
 							pipe->next_tx_frame += pipe->interval;
-							__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_SUCCESS);
+							__cvmx_usb_perform_complete(usb,
+										    pipe,
+										    transaction,
+										    CVMX_USB_COMPLETE_SUCCESS);
 						}
 					} else
 						transaction->stage = CVMX_USB_STAGE_NON_CONTROL_SPLIT_COMPLETE;
 				}
 			} else {
 				pipe->next_tx_frame += pipe->interval;
-				__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_SUCCESS);
+				__cvmx_usb_perform_complete(usb, pipe,
+							    transaction,
+							    CVMX_USB_COMPLETE_SUCCESS);
 			}
 			break;
 		}
@@ -2971,15 +3415,17 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 		/* If this was a split then clear our split in progress marker */
 		if (usb->active_split == transaction)
 			usb->active_split = NULL;
-		/* NAK as a response means the device couldn't accept the transaction,
-		   but it should be retried in the future. Rewind to the beginning of
-		   the transaction by anding off the split complete bit. Retry in the
-		   next interval */
+		/* NAK as a response means the device couldn't accept the
+		 * transaction, but it should be retried in the future.
+		 * Rewind to the beginning of the transaction by anding off
+		 * the split complete bit.  Retry in the next interval
+		 */
 		transaction->retries = 0;
 		transaction->stage &= ~1;
 		pipe->next_tx_frame += pipe->interval;
 		if (pipe->next_tx_frame < usb->frame_number)
-			pipe->next_tx_frame = usb->frame_number + pipe->interval - (usb->frame_number - pipe->next_tx_frame) % pipe->interval;
+			pipe->next_tx_frame = usb->frame_number + pipe->interval
+				- (usb->frame_number - pipe->next_tx_frame) % pipe->interval;
 	} else {
 		cvmx_usb_port_status_t port;
 		port = cvmx_usb_get_status((cvmx_usb_state_t *) usb);
@@ -2987,8 +3433,9 @@ static int __cvmx_usb_poll_channel(cvmx_usb_internal_state_t * usb, int channel)
 			/* We'll retry the exact same transaction again */
 			transaction->retries++;
 		} else {
-			/* We get channel halted interrupts with no result bits sets when the
-			   cable is unplugged */
+			/* We get channel halted interrupts with no result bits
+			 * sets when the cable is unplugged
+			 */
 			__cvmx_usb_perform_complete(usb, pipe, transaction, CVMX_USB_COMPLETE_ERROR);
 		}
 	}
@@ -3023,22 +3470,26 @@ cvmx_usb_status_t cvmx_usb_poll(cvmx_usb_state_t * state)
 	CVMX_USB_LOG_PARAM("%p", state);
 
 	/* Update the frame counter */
-	usbc_hfnum.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HFNUM(usb->index));
+	usbc_hfnum.u32 = __cvmx_usb_read_csr32(usb,
+					       CVMX_USBCX_HFNUM(usb->index));
 	if ((usb->frame_number & 0x3fff) > usbc_hfnum.s.frnum)
 		usb->frame_number += 0x4000;
 	usb->frame_number &= ~0x3fffull;
 	usb->frame_number |= usbc_hfnum.s.frnum;
 
 	/* Read the pending interrupts */
-	usbc_gintsts.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_GINTSTS(usb->index));
+	usbc_gintsts.u32 = __cvmx_usb_read_csr32(usb,
+						 CVMX_USBCX_GINTSTS(usb->index));
 
 	/* Clear the interrupts now that we know about them */
-	__cvmx_usb_write_csr32(usb, CVMX_USBCX_GINTSTS(usb->index), usbc_gintsts.u32);
+	__cvmx_usb_write_csr32(usb, CVMX_USBCX_GINTSTS(usb->index),
+			       usbc_gintsts.u32);
 
 	if (usbc_gintsts.s.rxflvl) {
 		/* RxFIFO Non-Empty (RxFLvl)
-		   Indicates that there is at least one packet pending to be read
-		   from the RxFIFO. */
+		 * Indicates that there is at least one packet pending to be
+		 * read from the RxFIFO.
+		 */
 		/* In DMA mode this is handled by hardware */
 		if (usb->init_flags & CVMX_USB_INITIALIZE_FLAGS_NO_DMA)
 			__cvmx_usb_poll_rx_fifo(usb);
@@ -3051,35 +3502,43 @@ cvmx_usb_status_t cvmx_usb_poll(cvmx_usb_state_t * state)
 	if (usbc_gintsts.s.disconnint || usbc_gintsts.s.prtint) {
 		cvmx_usbcx_hprt_t usbc_hprt;
 		/* Disconnect Detected Interrupt (DisconnInt)
-		   Asserted when a device disconnect is detected. */
+		 * Asserted when a device disconnect is detected.
+		 */
 
 		/* Host Port Interrupt (PrtInt)
-		   The core sets this bit to indicate a change in port status of one
-		   of the O2P USB core ports in Host mode. The application must
-		   read the Host Port Control and Status (HPRT) register to
-		   determine the exact event that caused this interrupt. The
-		   application must clear the appropriate status bit in the Host Port
-		   Control and Status register to clear this bit. */
+		 * The core sets this bit to indicate a change in port status of one
+		 * of the O2P USB core ports in Host mode. The application must
+		 * read the Host Port Control and Status (HPRT) register to
+		 * determine the exact event that caused this interrupt. The
+		 * application must clear the appropriate status bit in the Host Port
+		 * Control and Status register to clear this bit.
+		 */
 
 		/* Call the user's port callback */
-		__cvmx_usb_perform_callback(usb, NULL, NULL, CVMX_USB_CALLBACK_PORT_CHANGED, CVMX_USB_COMPLETE_SUCCESS);
+		__cvmx_usb_perform_callback(usb, NULL, NULL,
+					    CVMX_USB_CALLBACK_PORT_CHANGED,
+					    CVMX_USB_COMPLETE_SUCCESS);
 		/* Clear the port change bits */
-		usbc_hprt.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HPRT(usb->index));
+		usbc_hprt.u32 = __cvmx_usb_read_csr32(usb,
+						      CVMX_USBCX_HPRT(usb->index));
 		usbc_hprt.s.prtena = 0;
 		__cvmx_usb_write_csr32(usb, CVMX_USBCX_HPRT(usb->index), usbc_hprt.u32);
 	}
 	if (usbc_gintsts.s.hchint) {
 		/* Host Channels Interrupt (HChInt)
-		   The core sets this bit to indicate that an interrupt is pending on
-		   one of the channels of the core (in Host mode). The application
-		   must read the Host All Channels Interrupt (HAINT) register to
-		   determine the exact number of the channel on which the
-		   interrupt occurred, and then read the corresponding Host
-		   Channel-n Interrupt (HCINTn) register to determine the exact
-		   cause of the interrupt. The application must clear the
-		   appropriate status bit in the HCINTn register to clear this bit. */
+		 * The core sets this bit to indicate that an interrupt is
+		 * pending on one of the channels of the core (in Host mode).
+		 * The application must read the Host All Channels Interrupt
+		 * (HAINT) register to determine the exact number of the
+		 * channel on which the interrupt occurred, and then read
+		 * the corresponding Host Channel-n Interrupt (HCINTn)
+		 * register to determine the exact cause of the interrupt.
+		 * The application must clear the appropriate status bit in
+		 * the HCINTn register to clear this bit.
+		 */
 		cvmx_usbcx_haint_t usbc_haint;
-		usbc_haint.u32 = __cvmx_usb_read_csr32(usb, CVMX_USBCX_HAINT(usb->index));
+		usbc_haint.u32 = __cvmx_usb_read_csr32(usb,
+						       CVMX_USBCX_HAINT(usb->index));
 		while (usbc_haint.u32) {
 			int channel;
 			CVMX_CLZ(channel, usbc_haint.u32);
diff --git a/arch/mips/cavium-octeon/executive/octeon-feature.c b/arch/mips/cavium-octeon/executive/octeon-feature.c
index 890ad59..858bf56 100644
--- a/arch/mips/cavium-octeon/executive/octeon-feature.c
+++ b/arch/mips/cavium-octeon/executive/octeon-feature.c
@@ -102,6 +102,7 @@ void __init octeon_feature_init(void)
 
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_SAAD);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_ZIP);
+	OCTEON_FEATURE_SET(OCTEON_FEATURE_ZIP3);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_CRYPTO);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_DORM_CRYPTO);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_PCIE);
@@ -131,8 +132,10 @@ void __init octeon_feature_init(void)
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_MULTICAST_TIMER);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_MULTINODE);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_CIU3);
+	OCTEON_FEATURE_SET(OCTEON_FEATURE_FPA3);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_CN78XX_WQE);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_SPI);
+	OCTEON_FEATURE_SET(OCTEON_FEATURE_BCH);
 
 	val = OCTEON_FEATURE_SUCCESS;
 
@@ -226,8 +229,8 @@ int octeon_clear_attr(octeon_attr_t attr)
 void __init octeon_attr_init(void)
 {
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	if (cvmx_coremask_is_first_core(&cvmx_sysinfo_get()->core_mask))
-		octeon_set_attr((int)OCTEON_ATTR_FIRST_CORE);
+	if (cvmx_is_init_core())
+		octeon_set_attr((int)OCTEON_ATTR_INIT_CORE);
 #endif
 }
 
diff --git a/arch/mips/cavium-octeon/octeon-error-tree.c b/arch/mips/cavium-octeon/octeon-error-tree.c
index 80234d0..d1f6ce3 100644
--- a/arch/mips/cavium-octeon/octeon-error-tree.c
+++ b/arch/mips/cavium-octeon/octeon-error-tree.c
@@ -111,6 +111,7 @@ static int octeon_error_tree_map_irq_reg(u64 r)
 		case 0:
 			return 0;
 		case 0x108:
+		case 0x8000:
 			return 1;
 		default:
 			break;
diff --git a/arch/mips/include/asm/octeon/cvmx-agl-defs.h b/arch/mips/include/asm/octeon/cvmx-agl-defs.h
index 134fdf7..800d4ab 100644
--- a/arch/mips/include/asm/octeon/cvmx-agl-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-agl-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-app-hotplug.h b/arch/mips/include/asm/octeon/cvmx-app-hotplug.h
index ac75f78..0429cd9 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-hotplug.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-hotplug.h
@@ -125,7 +125,7 @@ struct cvmx_app_hotplug_global {
 typedef struct cvmx_app_hotplug_global cvmx_app_hotplug_global_t;
 
 int is_core_being_hot_plugged(void);
-int is_app_being_booted_or_shutdown(void);
+int is_app_under_boot_or_shutdown(void);
 void set_app_unber_boot(int val);
 void set_app_under_shutdown(int val);
 int cvmx_app_hotplug_shutdown_request(const struct cvmx_coremask *, int);
diff --git a/arch/mips/include/asm/octeon/cvmx-app-init.h b/arch/mips/include/asm/octeon/cvmx-app-init.h
index fbc518f..1f75ff4 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-init.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-init.h
@@ -41,7 +41,7 @@
  * @file
  * Header file for simple executive application initialization.  This defines
  * part of the ABI between the bootloader and the application.
- * <hr>$Revision: 84656 $<hr>
+ * <hr>$Revision: 88298 $<hr>
  *
  */
 
@@ -271,7 +271,8 @@ enum cvmx_board_types_enum {
 	CVMX_BOARD_TYPE_IW_EVB = 52,
 	CVMX_BOARD_TYPE_CNF71XX_REF = 53,
 	CVMX_BOARD_TYPE_MOONSHOT = 54,
-	CVMX_BOARD_TYPE_EVB7000_SFF = 55,
+	CVMX_BOARD_TYPE_EVB7000_INTERPOSER = 55,
+	CVMX_BOARD_TYPE_EVB7000 = 56,
 	CVMX_BOARD_TYPE_MAX,
 	/* NOTE:  256-257 are being used by a customer. */
 
@@ -310,6 +311,7 @@ enum cvmx_board_types_enum {
 	/* Set aside a range for customer private use.  The SDK won't
 	 ** use any numbers in this range. */
 	CVMX_BOARD_TYPE_CUST_PRIVATE_MIN = 20001,
+	CVMX_BOARD_TYPE_UBNT_E100 = 20002,
 	CVMX_BOARD_TYPE_CUST_PRIVATE_MAX = 30000,
 
 	/* Range for IO modules */
@@ -393,7 +395,8 @@ static inline const char *cvmx_board_type_to_string(enum cvmx_board_types_enum t
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_IW_EVB)
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CNF71XX_REF)
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MOONSHOT)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_SFF)
+		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_INTERPOSER)
+		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000)
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MAX)
 
 		    /* Customer boards listed here */
@@ -424,6 +427,7 @@ static inline const char *cvmx_board_type_to_string(enum cvmx_board_types_enum t
 
 		    /* Customer private range */
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_PRIVATE_MIN)
+		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_UBNT_E100)
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_PRIVATE_MAX)
 
 		    /* Module range */
diff --git a/arch/mips/include/asm/octeon/cvmx-ase-defs.h b/arch/mips/include/asm/octeon/cvmx-ase-defs.h
index 514c394..5111139 100644
--- a/arch/mips/include/asm/octeon/cvmx-ase-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ase-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -375,28 +375,21 @@ static inline uint64_t CVMX_ASE_SPARE_FUNC(void)
 /**
  * cvmx_ase_backdoor_req_ctl
  *
- * Used to configure and trigger backdoor requests.
- * Backdoor requests can be inserted at any time. They will be inserted into
- * the request stream from LAP.
- *
- * The request packet needs to be written to ASE_BACKDOOR_REQ_DATA*
- * need to be written before VALID is triggerd.
- * Both CNT and VALID can be written same cycle.
- *
- * The hardware will clear the VALID bit when the request is sent.
- * If another VALID=1 is written before the bit is cleared,
- * it will not trigger another SOP.
- *
- * Software should take care to wait for the RSP before issuing another REQ.
- * Hardware will deassert ASE_BACKDOOR_RSP_CTL[VALID] when VALID is triggered.
+ * This register is used to configure and trigger backdoor requests. Backdoor requests can be
+ * inserted at any time. They are inserted into the request stream from LAP. The request packet
+ * needs to be written to ASE_BACKDOOR_REQ_DATA(0..15), and must be written before VALID is
+ * triggered. Both CNT and VALID can be written in the same cycle. The hardware clears the VALID
+ * bit when the request is sent. If another VALID=1 is written before the bit is cleared, it will
+ * not trigger another SOP. Software should take care to wait for the response before issuing
+ * another request. Hardware deasserts ASE_BACKDOOR_RSP_CTL[VALID] when VALID is triggered.
  */
 union cvmx_ase_backdoor_req_ctl {
 	uint64_t u64;
 	struct cvmx_ase_backdoor_req_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t valid                        : 1;  /**< Writing 1 triggers CNT beats to be sent as a packet into ASE. */
+	uint64_t valid                        : 1;  /**< Valid. Writing 1 triggers CNT beats to be sent as a packet into ASE. */
 	uint64_t reserved_4_62                : 59;
-	uint64_t cnt                          : 4;  /**< Number of DATA beats to send. Valid values: 2 to 10.
+	uint64_t cnt                          : 4;  /**< Number of DATA beats to send. Valid values are 0x2 - 0xB.
                                                          INTERNAL: Value of 0x0 will send 16 beats. */
 #else
 	uint64_t cnt                          : 4;
@@ -411,9 +404,9 @@ typedef union cvmx_ase_backdoor_req_ctl cvmx_ase_backdoor_req_ctl_t;
 /**
  * cvmx_ase_backdoor_req_data#
  *
- * Lowest address is first beat (aka control word) and will have SOP.
- * Next address is next beat, etc. CNTth address will have EOP.
- * See further documentation in ASE_BACKDOOR_REQ_CTL.
+ * The lowest address is first beat (aka control word) and has the SOP. The next address is next
+ * beat, etc. The register offset indicated by ASE_BACKDOOR_REQ_CTL[CNT] has the EOP. See further
+ * information in ASE_BACKDOOR_REQ_CTL.
  */
 union cvmx_ase_backdoor_req_datax {
 	uint64_t u64;
@@ -431,21 +424,19 @@ typedef union cvmx_ase_backdoor_req_datax cvmx_ase_backdoor_req_datax_t;
 /**
  * cvmx_ase_backdoor_rsp_ctl
  *
- * Used to indicate backdoor response complete.
- * See description in ASE_BACKDOOR_REQ_CTL.
- *
- * Hardware will assert VALID when the full response packet has been received
- * and has been posted to CNT and ASE_BACKDOOR_RSP_DATA*.
- * Hardware will not change CNT and ASE_BACKDOOR_RSP_DATA* while VALID is asserted.
- * Hardware will deassert VALID when ASE_BACKDOOR_REQ_CTL[VALID] is triggered.
+ * This register is used to indicate that the backdoor response is complete. See description in
+ * ASE_BACKDOOR_REQ_CTL. Hardware asserts VALID when the full response packet has been received
+ * and has been posted to CNT and ASE_BACKDOOR_RSP_DATA(0..7). Hardware does not change CNT and
+ * ASE_BACKDOOR_RSP_DATA(0..7) while VALID is asserted. Hardware deasserts VALID when
+ * ASE_BACKDOOR_REQ_CTL[VALID] is triggered.
  */
 union cvmx_ase_backdoor_rsp_ctl {
 	uint64_t u64;
 	struct cvmx_ase_backdoor_rsp_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t valid                        : 1;  /**< Asserted means there is valid response packet data. */
+	uint64_t valid                        : 1;  /**< Valid. Asserted means there is valid response packet data. */
 	uint64_t reserved_3_62                : 60;
-	uint64_t cnt                          : 3;  /**< Number of DATA beats received. Valid values: 2 to 5. */
+	uint64_t cnt                          : 3;  /**< Number of DATA beats received. Valid values are 2 to 5. */
 #else
 	uint64_t cnt                          : 3;
 	uint64_t reserved_3_62                : 60;
@@ -459,8 +450,9 @@ typedef union cvmx_ase_backdoor_rsp_ctl cvmx_ase_backdoor_rsp_ctl_t;
 /**
  * cvmx_ase_backdoor_rsp_data#
  *
- * Lowest address is first beat (aka control word) and will have SOP.
- * Next address is next beat, etc. CNTth address will have EOP.
+ * The lowest address is first beat (aka control word) and has the SOP. The next address is next
+ * beat, etc. The register offset indicated by ASE_BACKDOOR_RSP_CTL[CNT] has the EOP. See further
+ * information in ASE_BACKDOOR_RSP_CTL.
  */
 union cvmx_ase_backdoor_rsp_datax {
 	uint64_t u64;
@@ -478,7 +470,7 @@ typedef union cvmx_ase_backdoor_rsp_datax cvmx_ase_backdoor_rsp_datax_t;
 /**
  * cvmx_ase_bist_status0
  *
- * BIST status register.
+ * This is BIST status register 0.
  *
  */
 union cvmx_ase_bist_status0 {
@@ -486,7 +478,7 @@ union cvmx_ase_bist_status0 {
 	struct cvmx_ase_bist_status0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
-	uint64_t lue_rmc_ndone                : 4;  /**< Combined 'BIST is not complete' for the LUE RMC[3..0] RAMs. */
+	uint64_t lue_rmc_ndone                : 4;  /**< Combined `BIST is not complete' for the LUE RMC[3..0] RAMs. */
 	uint64_t reserved_51_55               : 5;
 	uint64_t lue_rft_ndone                : 1;  /**< BIST is not complete for the LUE HST RFT RAM. */
 	uint64_t lue_tat_ndone                : 1;  /**< BIST is not complete for the LUE HST TAT RAM. */
@@ -543,7 +535,7 @@ typedef union cvmx_ase_bist_status0 cvmx_ase_bist_status0_t;
 /**
  * cvmx_ase_bist_status1
  *
- * BIST status register. Per LUE RMC engine.
+ * This is the per-LUE RMC engine BIST status register 1.
  *
  */
 union cvmx_ase_bist_status1 {
@@ -594,7 +586,7 @@ typedef union cvmx_ase_bist_status1 cvmx_ase_bist_status1_t;
 /**
  * cvmx_ase_config
  *
- * General configuration for the ASE block.
+ * This is the general configuration register for the ASE block.
  *
  */
 union cvmx_ase_config {
@@ -602,14 +594,13 @@ union cvmx_ase_config {
 	struct cvmx_ase_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_7_63                : 57;
-	uint64_t endian_mode                  : 2;  /**< See ASE_ENDIAN_E. Endian swapping only applies to LU_REQ header data and KEY_RSP match result. */
+	uint64_t endian_mode                  : 2;  /**< See ASE_ENDIAN_E. Endian swapping only applies to lookup request header data and KEY_RSP
+                                                         match result. */
 	uint64_t reserved_2_4                 : 3;
-	uint64_t div2_clken                   : 1;  /**< Enable conditional sclk/2 in ASE.
-                                                         This only enables the sclk/2 domain, not the sclk.
-                                                         Turn this on if you want to do lookup requests. */
-	uint64_t div1_clken                   : 1;  /**< Enable conditional sclk in ASE.
-                                                         This only enables the sclk domain, not the sclk/2.
-                                                         Turn this on if you want to do lookup requests OR if you want to access OSM. */
+	uint64_t div2_clken                   : 1;  /**< Enable conditional SCLK/2 in ASE. This only enables the SCLK/2 domain, not the SCLK. Turn
+                                                         this on if you want to do lookup requests. */
+	uint64_t div1_clken                   : 1;  /**< Enable conditional SCLK in ASE. This only enables the SCLK domain, not the SCLK/2. Turn
+                                                         this on if you want to do lookup requests or if you want to access OSM. */
 #else
 	uint64_t div1_clken                   : 1;
 	uint64_t div2_clken                   : 1;
@@ -626,48 +617,46 @@ typedef union cvmx_ase_config cvmx_ase_config_t;
  * cvmx_ase_ecc_ctl
  *
  * This register can be used to disable ECC checks, insert ECC errors.
- *
- * Fields *ECC_DIS: Disables SBE detection/correction and DBE detection.
- * If ECC_DIS is 0x1, then no errors are detected.
- *
- * Fields *ECC_FLIP_SYND:  Flip the syndrom<1:0> bits to generate 1-bit/2-bits error for testing.
- *   0x0: normal operation
- *   0x1: SBE on bit<0>
- *   0x2: SBE on bit<1>
- *   0x3: DBE on bit<1:0>
+ * Fields *ECC_DIS disable SBE detection/correction and DBE detection. If ECC_DIS is 0x1, then no
+ * errors are detected.
+ * Fields *ECC_FLIP_SYND flip the syndrome<1:0> bits to generate 1-bit/2-bits error for testing.
+ * 0x0 = normal operation
+ * 0x1 = SBE on bit<0>
+ * 0x2 = SBE on bit<1>
+ * 0x3 = DBE on bit<1:0>
  */
 union cvmx_ase_ecc_ctl {
 	uint64_t u64;
 	struct cvmx_ase_ecc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_54_63               : 10;
-	uint64_t lue_kdt_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE RMC Key Data Transfer Buffer. */
-	uint64_t lue_rul_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE RMC Buffer Aligner Wrapper Rule FIFO. */
-	uint64_t lue_rft_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE HST and RMC Rule Format Tables.
+	uint64_t lue_kdt_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE RMC key data transfer buffer. */
+	uint64_t lue_rul_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE RMC buffer aligner wrapper rule FIFO. */
+	uint64_t lue_rft_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE HST and RMC rule format tables.
                                                          INTERNAL: RFT replicated 5 times for timing purposes, controls all copies. */
-	uint64_t lue_tat_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE HST Tree Access Table. */
-	uint64_t lue_kdb_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE KRQ Key Data Buffer. */
+	uint64_t lue_tat_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE HST ruleDB access table. */
+	uint64_t lue_kdb_ecc_flip_synd        : 2;  /**< Flip syndrome in LUE KRQ key data buffer. */
 	uint64_t reserved_37_43               : 7;
-	uint64_t lue_kdt_ecc_dis              : 1;  /**< Disable ECC for LUE RMC Key Data Transfer Buffer. */
-	uint64_t lue_rul_ecc_dis              : 1;  /**< Disable ECC for LUE RMC Buffer Aligner Wrapper Rule FIFO. */
-	uint64_t lue_rft_ecc_dis              : 1;  /**< Disable ECC for LUE HST and RMC Rule Format Tables.
+	uint64_t lue_kdt_ecc_dis              : 1;  /**< Disable ECC for LUE RMC key data transfer buffer. */
+	uint64_t lue_rul_ecc_dis              : 1;  /**< Disable ECC for LUE RMC buffer aligner wrapper rule FIFO. */
+	uint64_t lue_rft_ecc_dis              : 1;  /**< Disable ECC for LUE HST and RMC rule format tables.
                                                          INTERNAL: RFT replicated 5 times for timing purposes, controls all copies. */
-	uint64_t lue_tat_ecc_dis              : 1;  /**< Disable ECC for LUE HST Tree Access Table. */
-	uint64_t lue_kdb_ecc_dis              : 1;  /**< Disable ECC for LUE KRQ Key Data Buffer. */
+	uint64_t lue_tat_ecc_dis              : 1;  /**< Disable ECC for LUE HST ruleDB access table. */
+	uint64_t lue_kdb_ecc_dis              : 1;  /**< Disable ECC for LUE KRQ key data buffer. */
 	uint64_t reserved_26_31               : 6;
-	uint64_t lop_txb_ecc_flip_synd        : 2;  /**< Flip syndrome in LOP TXBUFF Data Memory. */
+	uint64_t lop_txb_ecc_flip_synd        : 2;  /**< Flip syndrome in LOP TXBUFF data memory. */
 	uint64_t reserved_17_23               : 7;
-	uint64_t lop_txb_ecc_dis              : 1;  /**< Disable ECC for LOP TXBUFF Data Memory. */
+	uint64_t lop_txb_ecc_dis              : 1;  /**< Disable ECC for LOP TXBUFF data memory. */
 	uint64_t reserved_14_15               : 2;
-	uint64_t lip_newq_ecc_flip_synd       : 2;  /**< Flip syndrome in LIP New Queue. */
-	uint64_t lip_pht_ecc_flip_synd        : 2;  /**< Flip syndrome in LIP Packet Header Table. */
-	uint64_t lip_gdt_ecc_flip_synd        : 2;  /**< Flip syndrome in LIP Global Definition Table. */
-	uint64_t lip_isf_ecc_flip_synd        : 2;  /**< Flip syndrome in LIP Input Skid FIFO. */
+	uint64_t lip_newq_ecc_flip_synd       : 2;  /**< Flip syndrome in LIP new queue. */
+	uint64_t lip_pht_ecc_flip_synd        : 2;  /**< Flip syndrome in LIP packet header table. */
+	uint64_t lip_gdt_ecc_flip_synd        : 2;  /**< Flip syndrome in LIP group definition table. */
+	uint64_t lip_isf_ecc_flip_synd        : 2;  /**< Flip syndrome in LIP input skid FIFO. */
 	uint64_t reserved_4_5                 : 2;
-	uint64_t lip_newq_ecc_dis             : 1;  /**< Disable ECC for LIP New Queue. */
-	uint64_t lip_pht_ecc_dis              : 1;  /**< Disable ECC for LIP Packet Header Table. */
-	uint64_t lip_gdt_ecc_dis              : 1;  /**< Disable ECC for LIP Global Definition Table. */
-	uint64_t lip_isf_ecc_dis              : 1;  /**< Disable ECC for LIP Input Skid FIFO. */
+	uint64_t lip_newq_ecc_dis             : 1;  /**< Disable ECC for LIP new queue. */
+	uint64_t lip_pht_ecc_dis              : 1;  /**< Disable ECC for LIP packet header table. */
+	uint64_t lip_gdt_ecc_dis              : 1;  /**< Disable ECC for LIP group definition table. */
+	uint64_t lip_isf_ecc_dis              : 1;  /**< Disable ECC for LIP input skid FIFO. */
 #else
 	uint64_t lip_isf_ecc_dis              : 1;
 	uint64_t lip_gdt_ecc_dis              : 1;
@@ -704,66 +693,54 @@ typedef union cvmx_ase_ecc_ctl cvmx_ase_ecc_ctl_t;
 /**
  * cvmx_ase_ecc_int
  *
- * Interrupt status for ECC failures.
- *
- * In all cases below EXCEPT LUE_KDT_*, any request that generates an
- * error will have its response marked as errored.
- * The LUE_KDT_DBE error will not be indicated in the response packet;
- * the only indication of this error is the interrupt mechanism.
- * INTERNAL: Therefore, most of these interrupts are for diagnostic use, not for error handling.
- *
- * For all the LUE* errors below, additional information can be obtained
- * by reading the ASE_LUE_ERROR_LOG. For all the LIP* /LOP* errors below, additional
- * information can be obtained by reading the ASE_LUF_ERROR_LOG CSR.
+ * This register contains the interrupt status for ECC failures. In all cases below, except
+ * LUE_KDT_*, any request that generates an error has its response marked as errored. The
+ * LUE_KDT_DBE error is not indicated in the response packet; the only indication of this error
+ * is the interrupt mechanism.
+ * For all the LUE* errors below, additional information can be obtained by reading the
+ * ASE_LUE_ERROR_LOG. For all the LIP* /LOP* errors below, additional information can be obtained
+ * by reading ASE_LUF_ERROR_LOG.
  */
 union cvmx_ase_ecc_int {
 	uint64_t u64;
 	struct cvmx_ase_ecc_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_44_63               : 20;
-	uint64_t lue_kdt_dbe                  : 1;  /**< Detected Double-Bit Error on LUE RMC Key Data Tranfer Buffer. */
-	uint64_t lue_kdt_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LUE RMC Key Data Transfer Buffer. */
-	uint64_t lue_rul_dbe                  : 1;  /**< Detected Double-Bit Error on LUE RMC Buffer Aligner Wrapper Rule FIFO. */
-	uint64_t lue_rul_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LUE RMC Buffer Aligner Wrapper Rule FIFO. */
+	uint64_t lue_kdt_dbe                  : 1;  /**< Detected double-bit error on LUE RMC key data transfer buffer. */
+	uint64_t lue_kdt_sbe                  : 1;  /**< Detected and corrected single-bit error on LUE RMC key data transfer buffer. */
+	uint64_t lue_rul_dbe                  : 1;  /**< Detected double-bit error on LUE RMC buffer aligner wrapper rule FIFO. */
+	uint64_t lue_rul_sbe                  : 1;  /**< Detected and corrected single-bit error on LUE RMC buffer aligner wrapper rule FIFO. */
 	uint64_t reserved_38_39               : 2;
-	uint64_t lue_rft_dbe                  : 1;  /**< Detected Double-Bit Error on LUE HST and RMC Rule Format Tables.
-                                                         This bit will not be set for software accesses to the RFT, it will only get set for lookup
-                                                         accesses.
+	uint64_t lue_rft_dbe                  : 1;  /**< Detected double-bit error on LUE HST and RMC rule format tables. This bit is not set for
+                                                         software accesses to the RFT; it is only set for lookup accesses.
                                                          INTERNAL: RFT replicated 5 times for timing purposes, this indicates error for any of the
                                                          RFT. */
-	uint64_t lue_rft_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LUE HST and RMC Rule Format Tables.
-                                                         This bit will not be set for software accesses to the RFT, it will only get set for lookup
-                                                         accesses.
+	uint64_t lue_rft_sbe                  : 1;  /**< Detected and corrected single-bit error on LUE HST and RMC rule format tables. This bit is
+                                                         not set for software accesses to the RFT; it only gets set for lookup accesses.
                                                          INTERNAL: RFT replicated 5 times for timing purposes, this indicates error for any of the
                                                          RFT. */
-	uint64_t lue_tat_dbe                  : 1;  /**< Detected Double-Bit Error on LUE HST Tree Access Table.
-                                                         This bit will not be set for software accesses to the TAT, it will only get set for lookup
-                                                         accesses. */
-	uint64_t lue_tat_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LUE HST Tree Access Table.
-                                                         This bit will not be set for software accesses to the TAT, it will only get set for lookup
-                                                         accesses. */
-	uint64_t lue_kdb_dbe                  : 1;  /**< Detected Double-Bit Error on LUE KRQ Key Data Buffer. */
-	uint64_t lue_kdb_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LUE KRQ Key Data Buffer. */
+	uint64_t lue_tat_dbe                  : 1;  /**< Detected double-bit error on LUE HST ruleDB access table. This bit is not set for software
+                                                         accesses to the TAT; it only gets set for lookup accesses. */
+	uint64_t lue_tat_sbe                  : 1;  /**< Detected and corrected single-bit error on LUE HST ruleDB access table. This bit is not
+                                                         set for software accesses to the TAT; it only gets set for lookup accesses. */
+	uint64_t lue_kdb_dbe                  : 1;  /**< Detected double-bit error on LUE KRQ key data buffer. */
+	uint64_t lue_kdb_sbe                  : 1;  /**< Detected and corrected single-bit error on LUE KRQ key data buffer. */
 	uint64_t reserved_18_31               : 14;
-	uint64_t lop_txb_dbe                  : 1;  /**< Detected Bouble-Bit Error on LOP's TXBUFF ram read. */
-	uint64_t lop_txb_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LOP's TXBUFF ram read. */
+	uint64_t lop_txb_dbe                  : 1;  /**< Detected double-bit error on LOP's TXBUFF RAM read. */
+	uint64_t lop_txb_sbe                  : 1;  /**< Detected and corrected single-bit error on LOP's TXBUFF RAM read. */
 	uint64_t reserved_8_15                : 8;
-	uint64_t lip_newq_dbe                 : 1;  /**< Detected Double-Bit Error on LIP's New Queue. */
-	uint64_t lip_newq_sbe                 : 1;  /**< Detected and corrected Single-Bit Error on LIP's New Queue. */
-	uint64_t lip_pht_dbe                  : 1;  /**< Detected Double-Bit Error on LIP's Packet Header Table.
-                                                         This bit will not be set for software accesses to the GDT, it will only get set for lookup
-                                                         accesses. */
-	uint64_t lip_pht_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LIP's Packet Header Table.
-                                                         This bit will not be set for software accesses to the GDT, it will only get set for lookup
-                                                         accesses. */
-	uint64_t lip_gdt_dbe                  : 1;  /**< Detected Double-Bit Error on LIP's Global Definition Table.
-                                                         This bit will not be set for software accesses to the GDT, it will only get set for lookup
-                                                         accesses. */
-	uint64_t lip_gdt_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LIP's Global Definition Table.
-                                                         This bit will not be set for software accesses to the GDT, it will only get set for lookup
-                                                         accesses. */
-	uint64_t lip_isf_dbe                  : 1;  /**< Detected Double-Bit Error on LIP's Input Skid FIFO. */
-	uint64_t lip_isf_sbe                  : 1;  /**< Detected and corrected Single-Bit Error on LIP's Input Skid FIFO. */
+	uint64_t lip_newq_dbe                 : 1;  /**< Detected double-bit error on LIP's new queue. */
+	uint64_t lip_newq_sbe                 : 1;  /**< Detected and corrected single-bit error on LIP's new queue. */
+	uint64_t lip_pht_dbe                  : 1;  /**< Detected double-bit error on LIP's packet header table. This bit is not set for software
+                                                         accesses to the GDT; it only gets set for lookup accesses. */
+	uint64_t lip_pht_sbe                  : 1;  /**< Detected and corrected single-bit error on LIP's packet header table. This bit is not set
+                                                         for software accesses to the GDT; it only gets set for lookup accesses. */
+	uint64_t lip_gdt_dbe                  : 1;  /**< Detected double-bit error on LIP's group definition table. This bit is not set for
+                                                         software accesses to the GDT; it only gets set for lookup accesses. */
+	uint64_t lip_gdt_sbe                  : 1;  /**< Detected and corrected single-bit error on LIP's group definition table. This bit is not
+                                                         set for software accesses to the GDT; it only gets set for lookup accesses. */
+	uint64_t lip_isf_dbe                  : 1;  /**< Detected double-bit error on LIP's input skid FIFO. */
+	uint64_t lip_isf_sbe                  : 1;  /**< Detected and corrected single-bit error on LIP's input skid FIFO. */
 #else
 	uint64_t lip_isf_sbe                  : 1;
 	uint64_t lip_isf_dbe                  : 1;
@@ -798,62 +775,53 @@ typedef union cvmx_ase_ecc_int cvmx_ase_ecc_int_t;
 /**
  * cvmx_ase_gen_int
  *
- * Interrupt status for general ASE interrupts.
- *
- * Errors reported in bit positions <38:32>, <7:2>, and <0> are most likely
- * due to software programming errors.
- *
- * In all LUE* cases below, any request that generates an error will have its response marked as
+ * This register contains the interrupt status for general ASE interrupts. Errors reported in bit
+ * positions <39:32>, <7:2>, and <0> are most likely due to software programming errors.
+ * In all LUE* cases below, any request that generates an error has its response marked as
  * errored. These LUE* interrupts are for diagnostic use, not for error handling. For all the
- * LUE* errors below, additional information can be obtained by reading the ASE_LUE_ERROR_LOG
- * CSR.
+ * LUE* errors below, additional information can be obtained by reading ASE_LUE_ERROR_LOG.
  */
 union cvmx_ase_gen_int {
 	uint64_t u64;
 	struct cvmx_ase_gen_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_40_63               : 24;
-	uint64_t lue_rme_fatal                : 1;  /**< One or more of the Rule Match Engines detected a fatal error.
-                                                         INTERNAL: It is expected that error recovery will require resetting
-                                                         the ASE and loading corrected software into OSM. */
-	uint64_t lue_invalid_req              : 1;  /**< An invalid access during a lookup request was observed.
-                                                         The cause is one of:
-                                                         * Remote request
-                                                         * Migration request
-                                                         * Insufficient key data provided for a new lookup request
-                                                         INTERNAL: It is expected that error recovery will require resetting
-                                                         the ASE and loading corrected software into OSM. */
-	uint64_t lue_hr_err_log               : 1;  /**< An error occurred for a Host request and generated a Host Response with error. */
+	uint64_t lue_rme_fatal                : 1;  /**< One or more of the lookup engines detected a fatal error. It is expected that error
+                                                         recovery will require resetting the ASE and loading corrected software into OSM.
+                                                         INTERNAL: 'Lookup engine' refers to 'Rule Match Engine.' */
+	uint64_t lue_invalid_req              : 1;  /**< Insufficient key data was provided for a new lookup request. It is expected that error
+                                                         recovery will require resetting the ASE and loading corrected software into OSM.
+                                                         INTERNAL: The cause could also be a remote request or migration request. */
+	uint64_t lue_hr_err_log               : 1;  /**< An error occurred for a host request and generated a host response with error. */
 	uint64_t reserved_35_36               : 2;
-	uint64_t lue_tic_bad_write            : 1;  /**< Data was loaded in to the TIC that results in a wrap condition.
-                                                         Either the TAT row pointed to by the TIC entry is invalid, or
-                                                         the starting TAT row and the increment value points beyond the
-                                                         end of the TAT. */
-	uint64_t lue_tic_multi_hit            : 1;  /**< A TIC lookup request resulted in multiple entries reporting a hit. */
-	uint64_t lue_tic_miss                 : 1;  /**< A TIC lookup request did not match a valid entry. */
+	uint64_t lue_tic_bad_write            : 1;  /**< Data was loaded in to the TIC that results in a wrap condition. Either the TAT row pointed
+                                                         to by the TIC entry is invalid, or the starting TAT row and the increment value points
+                                                         beyond the send of the TAT. It is expected that error recovery will require loading
+                                                         corrected software into the TIC. */
+	uint64_t lue_tic_multi_hit            : 1;  /**< A TIC lookup request resulted in multiple entries reporting a hit. It is expected that
+                                                         error recovery will require resetting the ASE and loading corrected software into the TIC. */
+	uint64_t lue_tic_miss                 : 1;  /**< A TIC lookup request did not match a valid entry. It is expected that error recovery will
+                                                         require resetting the ASE and loading corrected software into the TIC. */
 	uint64_t reserved_8_31                : 24;
-	uint64_t lip_tbf_missing_eop          : 1;  /**< The incoming TBL command did not indicate EOP on the correct beat,
-                                                         or the incoming LU command did not indicate EOP before the 12th beat.
-                                                         The request will be marked FATAL. */
+	uint64_t lip_tbf_missing_eop          : 1;  /**< The incoming TBL command did not indicate EOP on the correct beat, or the incoming lookup
+                                                         command did not indicate EOP before the 12th beat. The request will be marked FATAL. */
 	uint64_t lip_tbf_early_eop            : 1;  /**< The incoming TBL write command did not have enough write data beats to match the command.
-                                                         The write will be marked FATAL. */
-	uint64_t lip_obf_missing_eop          : 1;  /**< The incoming OSM command did not indicate EOP on the correct beat.
-                                                         The request will be marked FATAL. */
+                                                         The write is marked FATAL. */
+	uint64_t lip_obf_missing_eop          : 1;  /**< The incoming OSM command did not indicate EOP on the correct beat. The request is marked FATAL. */
 	uint64_t lip_obf_early_eop            : 1;  /**< The incoming OSM Write command did not have enough write data beats to match the command.
-                                                         The write will be marked FATAL. */
-	uint64_t lip_obf_drop_unkn_cmd        : 1;  /**< The incoming Control Word at LIP OSM Bypass Splitter does not decode to a valid command.
-                                                         The packet will be dropped since we can't trust the command to figure out what kind of
-                                                         response to send to LAP. We depend on LAP timeouts to inform software. */
-	uint64_t lip_obf_drop_malformed       : 1;  /**< LIP OSM Bypass Splitter dropped a beat because it was expecting a
-                                                         start-of-packet beat and didn't see the SOP indication, or it saw both
-                                                         SOP and EOP indication. */
-	uint64_t lip_obf_drop_cmd_dbe         : 1;  /**< LIP OSM Bypass Splitter sees the incoming Control Word is marked as having a
-                                                         Double Bit Error. The packet will be dropped since we can't trust the LID to
-                                                         send even an error response to LAP. We depend on LAP timeouts to inform software. */
-	uint64_t lip_isf_drop_full            : 1;  /**< LIP Input Skid FIFO dropped a beat because it was full. This only happens if
-                                                         LAP issues request beats but has no ase__lap1_credit<0>'s to do so; this indicates LAP
-                                                         credits are mis-programmed. If this interrupt fires, the software has to reset LAP1
-                                                         and ASE to recover, as the credits are out of sync. */
+                                                         The write is marked FATAL. */
+	uint64_t lip_obf_drop_unkn_cmd        : 1;  /**< The incoming control word at LIP OSM bypass splitter does not decode to a valid command.
+                                                         The packet is dropped since we can't trust the command to figure out what kind of response
+                                                         to send to LAP. We depend on LAP timeouts to inform software. */
+	uint64_t lip_obf_drop_malformed       : 1;  /**< LIP OSM bypass splitter dropped a beat because it was expecting a start-of-packet beat and
+                                                         didn't see the SOP indication, or it saw both SOP and EOP indication. */
+	uint64_t lip_obf_drop_cmd_dbe         : 1;  /**< LIP OSM bypass splitter sees the incoming control word is marked as having a double-bit
+                                                         error. The packet is dropped since we can't trust the LID to send even an error response
+                                                         to LAP. We depend on LAP timeouts to inform software. */
+	uint64_t lip_isf_drop_full            : 1;  /**< LIP Input Skid FIFO dropped a beat because it was full. This only happens if LAP issues
+                                                         request beats but has no ase__lap1_credit<0>s to do so; this indicates LAP credits are
+                                                         misprogrammed. If this interrupt fires, the software has to reset LAP1 and ASE to recover,
+                                                         as the credits are out of sync. */
 #else
 	uint64_t lip_isf_drop_full            : 1;
 	uint64_t lip_obf_drop_cmd_dbe         : 1;
@@ -881,7 +849,7 @@ typedef union cvmx_ase_gen_int cvmx_ase_gen_int_t;
 /**
  * cvmx_ase_lip_config
  *
- * Configuration for LIP.
+ * This register provides configuration for the LIP.
  *
  */
 union cvmx_ase_lip_config {
@@ -889,16 +857,14 @@ union cvmx_ase_lip_config {
 	struct cvmx_ase_lip_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t drop_xoff_en                 : 1;  /**< If enabled, LIP pays attention to the LAP's DROP_XOFF indication and may drop the
-                                                         indicated LU_REQ packets.
-                                                         If disabled, LIP ignores DROP_XOFF and will not drop packets. */
-	uint64_t gen_xon_en                   : 1;  /**< If enabled, LIP generates XON indication to LAP when LU_REQ's are backpressured.
-                                                         If disabled, LIP does not assert XON. */
+	uint64_t drop_xoff_en                 : 1;  /**< This feature should remain disabled.
+                                                         INTERNAL: Keep disabled, bug 18665. */
+	uint64_t gen_xon_en                   : 1;  /**< If enabled, the LIP generates XON indication to the LAP when lookup requests are
+                                                         backpressured. If disabled, the LIP does not assert XON. */
 	uint64_t reserved_1_1                 : 1;
-	uint64_t hst_osm_hw_ecc_bypass        : 1;  /**< If enabled, Host accesses to the OSM memory will bypass hardware ECC
-                                                         generation and calculation/correction/detection.
-                                                         If disabled, Host accesses will use hardware ECC
-                                                         generation and calculation/correction/detection. */
+	uint64_t hst_osm_hw_ecc_bypass        : 1;  /**< If enabled, host accesses to the OSM memory bypass hardware ECC generation and
+                                                         calculation/correction/detection. If disabled, host accesses use hardware ECC generation
+                                                         and calculation/correction/detection. */
 #else
 	uint64_t hst_osm_hw_ecc_bypass        : 1;
 	uint64_t reserved_1_1                 : 1;
@@ -933,7 +899,7 @@ typedef union cvmx_ase_lip_spare cvmx_ase_lip_spare_t;
 /**
  * cvmx_ase_lop_config
  *
- * Configuration for LOP.
+ * This register provides configuration for the LOP.
  *
  */
 union cvmx_ase_lop_config {
@@ -941,19 +907,19 @@ union cvmx_ase_lop_config {
 	struct cvmx_ase_lop_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t rsp_pri                      : 4;  /**< Response output priority.
-                                                         <7>: LUE Key response
-                                                         <6>: LUF table response
-                                                         <5>: LUE table response
-                                                         <4>: OSM write/read response
-                                                         There are 2 priority levels per response type: 1 -  higher priority; 0 - lower priority.
-                                                         RR is used among the responses with higher priority to send back to LAP or CSR. When there
-                                                         is no response with higher priority left,
-                                                         RR is used to choose a response with lower priority to send back to LAP or CSR. */
+	uint64_t rsp_pri                      : 4;  /**< Response output priority as follows:
+                                                         <7> LUE key response
+                                                         <6> LUF table response
+                                                         <5> LUE table response
+                                                         <4> OSM write/read response
+                                                         There are two priority levels per response type: 1 = higher priority;
+                                                         0 = lower priority. Round robin is used among the responses with higher priority to send
+                                                         back to the LAP or CSR. When there is no response with higher priority left, round robin
+                                                         is used to choose a response with lower priority to send back to LAP or CSR. */
 	uint64_t reserved_1_3                 : 3;
-	uint64_t rsp_dis                      : 1;  /**< If set, LOP will not send response(s) to LAP/CSR. It is only used for diagnosis purpose.
-                                                         For example, it can be used to built up back-pressure to LUE/LIP/LAP/OSM.
-                                                         In normal operation, it must not be set. */
+	uint64_t rsp_dis                      : 1;  /**< If set, the LOP does not send response(s) to the LAP/CSR. It is only used for diagnosis
+                                                         purposes. For example, it can be used to build up backpressure to LUE/LIP/LAP/OSM. In
+                                                         normal operation, it must not be set. */
 #else
 	uint64_t rsp_dis                      : 1;
 	uint64_t reserved_1_3                 : 3;
@@ -987,7 +953,7 @@ typedef union cvmx_ase_lop_spare cvmx_ase_lop_spare_t;
 /**
  * cvmx_ase_lue_config
  *
- * Configuration for LUE.
+ * This register provides configuration for the LUE.
  *
  */
 union cvmx_ase_lue_config {
@@ -995,40 +961,29 @@ union cvmx_ase_lue_config {
 	struct cvmx_ase_lue_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
-	uint64_t pfcache_en                   : 1;  /**< Enable Bucket Entry PFLEN Caching
-                                                         When clear, if PFLEN < OCM-Line, PFLEN BE caching is disabled,
-                                                         and a BEREQ is made for each PFLEN group of BEs processed.
-                                                         When set, if PFLEN < OCM-Line, only a single BEREQ is made
-                                                         for the OCM-line which caches all of the BEs. */
-	uint64_t pfab_en                      : 1;  /**< Enable Bucket Entry Pre-fetch Phase A/B Request Scheme
-                                                         When clear, each Bucket Walk Engine is allowed to have a
-                                                         maximum of 8 outstanding Rule read requests in progress
-                                                         at a time.
-                                                         When set, each Bucket Walk Engine is allowed to have a
-                                                         maximum of 16 outstanding Rule read requests in progress at
-                                                         a time, split in to two groups of 8 (Phases A and B).
-                                                         After the initial 8 Bucket Entries, the next set of [up to]
-                                                         8 Bucket Entries are speculatively read and submitted to the
-                                                         Rule Walk Engine.
-                                                         Subsequent speculative reads are performed once all
-                                                         outstanding requests for a Phase have completed. */
+	uint64_t pfcache_en                   : 1;  /**< Enable bucket entry PFLEN caching. When clear, if PFLEN < OSM-line, PFLEN BE caching is
+                                                         disabled, and a BEREQ is made for each PFLEN group of BEs processed. When set, if PFLEN <
+                                                         OSM-line, only a single BEREQ is made for the OSM-line which caches all of the BEs. */
+	uint64_t pfab_en                      : 1;  /**< Enable bucket entry prefetch phase A/B request scheme. When clear, each Bucket Walk Engine
+                                                         is allowed to have a maximum of 8 outstanding rule read requests in progress at a time.
+                                                         When set, each Bucket Walk Engine is allowed to have a maximum of 16 outstanding rule read
+                                                         requests in progress at a time, split in to two groups of 8 (Phases A and B). After the
+                                                         initial 8 bucket entries, the next set of [up to] 8 bucket entries are speculatively read
+                                                         and submitted to the Rule Walk Engine. Subsequent speculative reads are performed once all
+                                                         outstanding requests for a phase have completed. */
 	uint64_t reserved_20_31               : 12;
-	uint64_t twc_strspsta_rr              : 1;  /**< Within the TWC block, configures the arbiter which selects
-                                                         between Pending TWE or BWE STRSPs. When clear, fixed priority
-                                                         arbitration is selected, which gives BWEs higher priority over TWEs.
-                                                         When set, round robin arbitration is selected which ensures fairness
-                                                         across the TWE and BWE STRSPs.
-                                                         If enabled, use round-robin. If disabled, use fixed priority. */
-	uint64_t tta_req_rr                   : 1;  /**< Within the TTA blocks, configures the arbiter which selects
-                                                         between Host access requests and Lookup requests. When configured
-                                                         for fixed priority, Host accesses have higher priority.
-                                                         If enabled, use round-robin. If disabled, use fixed priority. */
-	uint64_t rft_req_rr                   : 1;  /**< Within the RFT access logic, configures the arbiter which selects
-                                                         between Host access requests and Lookup requests. When configured
-                                                         for fixed priority, Host accesses have higher priority.
-                                                         If enabled, use round-robin. If disabled, use fixed priority. */
+	uint64_t twc_strspsta_rr              : 1;  /**< Within the TWC block, configures the arbiter which selects between Pending TWE or BWE
+                                                         STRSPs. When clear, fixed priority arbitration is selected, which gives BWEs higher
+                                                         priority over TWEs. When set, round robin arbitration is selected which ensures fairness
+                                                         across the TWE and BWE STRSPs. */
+	uint64_t tta_req_rr                   : 1;  /**< Within the TTA blocks, configures the arbiter which selects between host access requests
+                                                         and lookup requests. When configured for fixed priority, host accesses have higher
+                                                         priority. If enabled, use round robin. If disabled, use fixed priority. */
+	uint64_t rft_req_rr                   : 1;  /**< Within the RFT access logic, configures the arbiter which selects between host access
+                                                         requests and lookup requests. When configured for fixed priority, host accesses have
+                                                         higher priority. If enabled, use round-robin. If disabled, use fixed priority. */
 	uint64_t reserved_4_16                : 13;
-	uint64_t rme_enable                   : 4;  /**< Each bit, when set, enables Rule processing by a local Rule Match Engine. */
+	uint64_t rme_enable                   : 4;  /**< Each bit, when set, enables rule processing by a local Rule Match Engine. */
 #else
 	uint64_t rme_enable                   : 4;
 	uint64_t reserved_4_16                : 13;
@@ -1048,15 +1003,12 @@ typedef union cvmx_ase_lue_config cvmx_ase_lue_config_t;
 /**
  * cvmx_ase_lue_dbg_ctl0
  *
- * Select engines for debug observations for the LUE's 4 16-bit debug muxes.
- *
- * INTERNAL: We are not rewiring the NSP's 16-bit debug bus. Instead we are duplicating that mux
- * 4 times to give Octeon better observability.
- *
- * And select context for observation.
- *
- * INTERNAL: LUE DBGCTX is a DOR daisy-chained through the TWE and BWE engines, it can't be moved
- * to a straight Octeon-style debug bus without rewriting the whole thing.
+ * We are not rewiring the NSP's 16-bit debug bus. Instead we are duplicating that mux 4 times to
+ * give OCTEON better observability.
+ * LUE DBGCTX is a DOR daisy-chained through the TWE and BWE engines, it can't be moved to a
+ * straight OCTEON-style debug bus without rewriting the whole thing.
+ * This register selects engines for debug observations for the LUE's four 16-bit debug muxes and
+ * selects context for observation.
  */
 union cvmx_ase_lue_dbg_ctl0 {
 	uint64_t u64;
@@ -1071,17 +1023,17 @@ union cvmx_ase_lue_dbg_ctl0 {
 	uint64_t reserved_39_39               : 1;
 	uint64_t sel0                         : 7;  /**< Debug select for LUE's mux 0. */
 	uint64_t reserved_20_31               : 12;
-	uint64_t ctx_col_dbg                  : 4;  /**< 32-bit column of context information to display in the ASE_LUE_CTX debug field.
+	uint64_t ctx_col_dbg                  : 4;  /**< Context column debug. 32-bit column of context information to display in the ASE_LUE_CTX
+                                                         debug field.
                                                          TWE: Valid column values 0-12.
                                                          BWE: Valid column values 0-2.
                                                          RWE: Valid column values 0-8. */
 	uint64_t reserved_13_15               : 3;
-	uint64_t ctx_eng_dbg                  : 5;  /**< Engine ID from which context information will be made
-                                                         available in the ASE_LUE_CTX debug field.
-                                                         Valid values are 0-19. */
+	uint64_t ctx_eng_dbg                  : 5;  /**< Engine ID from which context information will be made available in the ASE_LUE_CTX debug
+                                                         field. Must be 0 to 19. */
 	uint64_t reserved_2_7                 : 6;
-	uint64_t ctx_src_dbg                  : 2;  /**< Engine type from which context information will be made
-                                                         available in the ASE_LUE_CTX debug field.
+	uint64_t ctx_src_dbg                  : 2;  /**< Engine type from which context information will be made available in the ASE_LUE_CTX debug
+                                                         field.
                                                          0 = Tree Walk Engine
                                                          1 = Bucket Walk Engine
                                                          2 = Rule Walk Engine
@@ -1110,60 +1062,43 @@ typedef union cvmx_ase_lue_dbg_ctl0 cvmx_ase_lue_dbg_ctl0_t;
 /**
  * cvmx_ase_lue_dbg_ctl1
  *
- * Select engines for debug observations for the LUE's 4 16-bit debug muxes.
- * INTERNAL: The per-engine filtering from NSP is not really worth moving to DTX-style
- * addressing.
- * INTERNAL: We are not rewiring the NSP's 16-bit debug bus. Instead we are duplicating that mux
- * 4 times to give Octeon better observability.
+ * The per-engine filtering from NSP is not really worth moving to DTX-style addressing.
+ * We are not rewiring the NSP's 16-bit debug bus. Instead we are duplicating that mux 4 times to
+ * give OCTEON better observability.
+ * This register selects engines for debug observations for the LUE's four 16-bit debug muxes.
  */
 union cvmx_ase_lue_dbg_ctl1 {
 	uint64_t u64;
 	struct cvmx_ase_lue_dbg_ctl1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_62_63               : 2;
-	uint64_t rmc_dbg3                     : 2;  /**< Mux 3.
-                                                         Selects which of the 4 RMC modules will present signals
-                                                         on the debug bus when a RMC signal group is selected for
-                                                         observation. */
+	uint64_t rmc_dbg3                     : 2;  /**< Mux 3. Selects which of the four RMC modules will present signals on the debug bus when a
+                                                         RMC signal group is selected for observation. */
 	uint64_t reserved_58_59               : 2;
-	uint64_t rmc_dbg2                     : 2;  /**< Mux 2.
-                                                         Selects which of the 4 RMC modules will present signals
-                                                         on the debug bus when a RMC signal group is selected for
-                                                         observation. */
+	uint64_t rmc_dbg2                     : 2;  /**< Mux 2. Selects which of the four RMC modules will present signals on the debug bus when a
+                                                         RMC signal group is selected for observation. */
 	uint64_t reserved_54_55               : 2;
-	uint64_t rmc_dbg1                     : 2;  /**< Mux 1.
-                                                         Selects which of the 4 RMC modules will present signals
-                                                         on the debug bus when a RMC signal group is selected for
-                                                         observation. */
+	uint64_t rmc_dbg1                     : 2;  /**< Mux 1. Selects which of the four RMC modules will present signals on the debug bus when a
+                                                         RMC signal group is selected for observation. */
 	uint64_t reserved_50_51               : 2;
-	uint64_t rmc_dbg0                     : 2;  /**< Mux 0.
-                                                         Selects which of the 4 RMC modules will present signals
-                                                         on the debug bus when a RMC signal group is selected for
-                                                         observation. */
+	uint64_t rmc_dbg0                     : 2;  /**< Mux 0. Selects which of the four RMC modules will present signals on the debug bus when a
+                                                         RMC signal group is selected for observation. */
 	uint64_t reserved_29_47               : 19;
-	uint64_t eng_id_dbg3                  : 5;  /**< Mux 3.
-                                                         Selects which Tree Walk Engine or Bucket Walk Engine will
-                                                         present signals on the debug bus when a TWC or BWC signal
-                                                         group is selected for observation.
-                                                         Valid values are 0-19. */
+	uint64_t eng_id_dbg3                  : 5;  /**< Mux 3. Selects which Tree Walk Engine or Bucket Walk Engine will present signals on the
+                                                         debug bus when a TWC or BWC signal group is selected for observation. Valid values are
+                                                         0-19. */
 	uint64_t reserved_21_23               : 3;
-	uint64_t eng_id_dbg2                  : 5;  /**< Mux 2.
-                                                         Selects which Tree Walk Engine or Bucket Walk Engine will
-                                                         present signals on the debug bus when a TWC or BWC signal
-                                                         group is selected for observation.
-                                                         Valid values are 0-19. */
+	uint64_t eng_id_dbg2                  : 5;  /**< Mux 2. Selects which Tree Walk Engine or Bucket Walk Engine will present signals on the
+                                                         debug bus when a TWC or BWC signal group is selected for observation. Valid values are
+                                                         0-19. */
 	uint64_t reserved_13_15               : 3;
-	uint64_t eng_id_dbg1                  : 5;  /**< Mux 1.
-                                                         Selects which Tree Walk Engine or Bucket Walk Engine will
-                                                         present signals on the debug bus when a TWC or BWC signal
-                                                         group is selected for observation.
-                                                         Valid values are 0-19. */
+	uint64_t eng_id_dbg1                  : 5;  /**< Mux 1. Selects which Tree Walk Engine or Bucket Walk Engine will present signals on the
+                                                         debug bus when a TWC or BWC signal group is selected for observation. Valid values are
+                                                         0-19. */
 	uint64_t reserved_5_7                 : 3;
-	uint64_t eng_id_dbg0                  : 5;  /**< Mux 0.
-                                                         Selects which Tree Walk Engine or Bucket Walk Engine will
-                                                         present signals on the debug bus when a TWC or BWC signal
-                                                         group is selected for observation.
-                                                         Valid values are 0-19. */
+	uint64_t eng_id_dbg0                  : 5;  /**< Mux 0. Selects which Tree Walk Engine or Bucket Walk Engine will present signals on the
+                                                         debug bus when a TWC or BWC signal group is selected for observation. Valid values are
+                                                         0-19. */
 #else
 	uint64_t eng_id_dbg0                  : 5;
 	uint64_t reserved_5_7                 : 3;
@@ -1190,56 +1125,41 @@ typedef union cvmx_ase_lue_dbg_ctl1 cvmx_ase_lue_dbg_ctl1_t;
 /**
  * cvmx_ase_lue_error_log
  *
- * "
- * Logs information to help diagnose LUE errors indicated in ASE_*_INT[LUE*].
- *
- * Information is only logged to this CSR if the bit corresponding to the ERROR_ID
- * is set in ASE_LUE_ERROR_LOG_ENABLE.
- *
- * The contents of this CSR are invalid if no fields are set in ASE_*_INT[LUE*].
- *
- * The contents of this CSR are retained until all the bits in the ASE_*_INT[LUE*]
- * are cleared, or an error occurs that is of higher-priority than the error for
+ * This register logs information to help diagnose LUE errors indicated in ASE_*_INT[LUE*].
+ * Information is only logged to this register if the bit corresponding to the ERROR_ID is set in
+ * ASE_LUE_ERROR_LOG_ENABLE. The contents of this register are invalid if no fields are set in
+ * ASE_*_INT[LUE*]. The contents of this register are retained until all the bits in the
+ * ASE_*_INT[LUE*] are cleared, or an error occurs that is of higher-priority than the error for
  * which information is currently logged by this CSR.
- *
- * The priority of the error is encoded by the enumerated values in ASE_LUE_ERROR_ID_E.
- * The highest priority error is KDT_DBE, the lowest is RFT_SBE.
- * For RFT errors, if multiple errors of equal weight are reported
- * during a clock cycle, the error on the local RFT is reported with highest
- * priority, followed by RMC0, RMC1, RMC2, RMC3.
- *
- * Only interrupts listed in ASE_LUE_ERROR_ID_E log errors.
- * "
+ * The priority of the error is encoded by the enumerated values in ASE_LUE_ERROR_ID_E. The
+ * highest priority error is KDT_DBE, the lowest is RFT_SBE. For RFT errors, if multiple errors
+ * of equal weight are reported during a clock cycle, the error on the local RFT is reported with
+ * highest priority, followed by RMC0, RMC1, RMC2, RMC3. Only interrupts listed in
+ * ASE_LUE_ERROR_ID_E log errors.
  */
 union cvmx_ase_lue_error_log {
 	uint64_t u64;
 	struct cvmx_ase_lue_error_log_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_62_63               : 2;
-	uint64_t error_id                     : 6;  /**< Type of error logged. See ASE_LUE_ERROR_ID_E.
-                                                         If ERROR_ID == HR_ERR_LOG, see HR_ERR_ID for how to decode the DATA field.
-                                                         Otherwise, ERROR_ID indicates how to decode the DATA field. */
+	uint64_t error_id                     : 6;  /**< Type of error logged. See ASE_LUE_ERROR_ID_E. If ERROR_ID == HR_ERR_LOG, see HR_ERR_ID for
+                                                         how to decode the DATA field. Otherwise, ERROR_ID indicates how to decode the DATA field. */
 	uint64_t reserved_54_55               : 2;
-	uint64_t hr_err_id                    : 6;  /**< Type of Host error logged. See ASE_LUE_ERROR_ID_E.
-                                                         Ignore HR_ERR_ID if ERROR_ID != HR_ERR_LOG.
-                                                         Indicates how to decode the DATA field if ERROR_ID == HR_ERR_LOG. */
-	uint64_t data                         : 48; /**< "
-                                                         Error Logging Information
-                                                         The information in this field takes on different meanings
-                                                         depending on the type of error that is latched in the
-                                                         ASE_*_INT[LUE*] fields.
-                                                         Decode this field based on ERROR_ID and HR_ERR_ID:
-                                                           TIC_MISS or TIC_MULTI_HIT: see ASE_LUE_ERROR_LOG_TIC_S.
-                                                           TIC_BAD_WRITE: see ASE_LUE_ERROR_LOG_TIC_BAD_WRITE_S.
-                                                           INVALID_TBL_ACC: see ASE_LUE_ERROR_LOG_INVTBLACC_S.
-                                                           INVALID_REQ: see ASE_LUE_ERROR_LOG_INVREQ_S.
-                                                           RME_FATAL: see ASE_LUE_ERROR_LOG_RME_FATAL_S.
-                                                           KDB_*BE: see ASE_LUE_ERROR_LOG_KDB_ECC_S.
-                                                           TAT_*BE: see ASE_LUE_ERROR_LOG_TAT_ECC_S.
-                                                           RFT_*BE: see ASE_LUE_ERROR_LOG_RFT_ECC_S.
-                                                           RUL_*BE: see ASE_LUE_ERROR_LOG_RUL_ECC_S.
-                                                           KDT_*BE: see ASE_LUE_ERROR_LOG_KDT_ECC_S.
-                                                         " */
+	uint64_t hr_err_id                    : 6;  /**< Type of host error logged. See ASE_LUE_ERROR_ID_E. Ignore HR_ERR_ID if ERROR_ID !=
+                                                         HR_ERR_LOG. Indicates how to decode the DATA field if ERROR_ID == HR_ERR_LOG. */
+	uint64_t data                         : 48; /**< Error logging information. The information in this field takes on different meanings
+                                                         depending on the type of error that is latched in the ASE_*_INT[LUE*] fields. Decode this
+                                                         field based on ERROR_ID and HR_ERR_ID:
+                                                         TIC_MISS or TIC_MULTI_HIT, see ASE_LUE_ERROR_LOG_TIC_S.
+                                                         TIC_BAD_WRITE, see ASE_LUE_ERROR_LOG_TIC_BAD_WRITE_S.
+                                                         INVALID_TBL_ACC, see ASE_LUE_ERROR_LOG_INVTBLACC_S.
+                                                         INVALID_REQ, see ASE_LUE_ERROR_LOG_INVREQ_S.
+                                                         RME_FATAL, see ASE_LUE_ERROR_LOG_RME_FATAL_S.
+                                                         KDB_*BE, see ASE_LUE_ERROR_LOG_KDB_ECC_S.
+                                                         TAT_*BE, see ASE_LUE_ERROR_LOG_TAT_ECC_S.
+                                                         RFT_*BE: see ASE_LUE_ERROR_LOG_RFT_ECC_S.
+                                                         RUL_*BE, see ASE_LUE_ERROR_LOG_RUL_ECC_S.
+                                                         KDT_*BE, see ASE_LUE_ERROR_LOG_KDT_ECC_S. */
 #else
 	uint64_t data                         : 48;
 	uint64_t hr_err_id                    : 6;
@@ -1255,8 +1175,8 @@ typedef union cvmx_ase_lue_error_log cvmx_ase_lue_error_log_t;
 /**
  * cvmx_ase_lue_error_log_enable
  *
- * Each field in this CSR, when set, allows the corresponding field in the
- * ASE_*_INT[LUE*] to log information in the ASE_LUE_ERROR_LOG CSR upon assertion.
+ * Each field in this register, when set, allows the corresponding field in the ASE_*_INT[LUE*]
+ * to log information in ASE_LUE_ERROR_LOG upon assertion.
  */
 union cvmx_ase_lue_error_log_enable {
 	uint64_t u64;
@@ -1314,7 +1234,7 @@ typedef union cvmx_ase_lue_error_log_enable cvmx_ase_lue_error_log_enable_t;
 /**
  * cvmx_ase_lue_perf_filt
  *
- * Filters for performance counter events.
+ * This register contains filters for performance counter events.
  *
  */
 union cvmx_ase_lue_perf_filt {
@@ -1322,35 +1242,27 @@ union cvmx_ase_lue_perf_filt {
 	struct cvmx_ase_lue_perf_filt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_49_63               : 15;
-	uint64_t hst_tta_tic_id               : 9;  /**< Lookups to the TTA in the HST module will trigger a
-                                                         performance event if the lookup is for the TIC ID value
-                                                         indicated in this field. See ASE_TBLDAT_TIC_S for
-                                                         description of TIC_ID. */
+	uint64_t hst_tta_tic_id               : 9;  /**< Lookups to the TTA in the HST module will trigger a performance event if the lookup is for
+                                                         the TIC ID value indicated in this field. See ASE_TBLDAT_TIC_S for description of TIC_ID. */
 	uint64_t reserved_38_39               : 2;
-	uint64_t hst_rft_kftidx               : 6;  /**< Lookups to the RFT in the HST module will trigger a
-                                                         performance event if the lookup is for the KFTIDX value
-                                                         indicated in this field. */
+	uint64_t hst_rft_kftidx               : 6;  /**< Lookups to the RFT in the HST module will trigger a performance event if the lookup is for
+                                                         the KFTIDX value indicated in this field. */
 	uint64_t reserved_26_31               : 6;
-	uint64_t sel_all_perf                 : 1;  /**< Disable Filtering.
-                                                         When set, overrides the setting of SEL_ID_PERF for some
-                                                         performance counter events.
-                                                         This field is used by the TWC, BWC, and STR modules. */
-	uint64_t sel_id_perf                  : 1;  /**< Selects how the value in the ENG_KID_ID_PERF field is interpreted.
-                                                         This field is used by the TWC, BWC, and STR modules. */
+	uint64_t sel_all_perf                 : 1;  /**< Disable Filtering. When set, overrides the setting of SEL_ID_PERF for some performance
+                                                         counter events. This field is used by the TWC, BWC, and STR modules. */
+	uint64_t sel_id_perf                  : 1;  /**< Selects how the value in the ENG_KID_ID_PERF field is interpreted. This field is used by
+                                                         the TWC, BWC, and STR modules. */
 	uint64_t reserved_22_23               : 2;
-	uint64_t eng_kid_id_perf              : 6;  /**< When SEL_ID_PERF is clear, this field is interpreted as an 8-bit KID.
-                                                         When SEL_ID_PERF is set, the lower five bits of this field are
-                                                         interpreted as the Engine ID and the upper three bits are ignored,
-                                                         and valid values are 0-19.
-                                                         This field is used by the TWC, BWC, and STR modules. */
+	uint64_t eng_kid_id_perf              : 6;  /**< When SEL_ID_PERF is clear, this field is interpreted as an 8-bit KID. When SEL_ID_PERF is
+                                                         set, the lower five bits of this field are interpreted as the Engine ID and the upper
+                                                         three bits are ignored, and valid values are 0-19. This field is used by the TWC, BWC, and
+                                                         STR modules. */
 	uint64_t reserved_14_15               : 2;
 	uint64_t rmc_perf                     : 2;  /**< RMC to monitor for performance events. */
 	uint64_t reserved_11_11               : 1;
-	uint64_t perf_bwc_eng                 : 5;  /**< BWE to monitor for performance events.
-                                                         Valid values are 0-19. */
+	uint64_t perf_bwc_eng                 : 5;  /**< BWE to monitor for performance events. Valid values are 0-19. */
 	uint64_t reserved_5_5                 : 1;
-	uint64_t perf_twc_eng                 : 5;  /**< TWE to monitor for performance events.
-                                                         Valid values are 0-19. */
+	uint64_t perf_twc_eng                 : 5;  /**< TWE to monitor for performance events. Valid values are 0-19. */
 #else
 	uint64_t perf_twc_eng                 : 5;
 	uint64_t reserved_5_5                 : 1;
@@ -1376,35 +1288,34 @@ typedef union cvmx_ase_lue_perf_filt cvmx_ase_lue_perf_filt_t;
 /**
  * cvmx_ase_lue_performance_control#
  *
- * A write to a LUE_PERFORMANCE_CONTROL* CSR which sets the ENABLE or
- * field to 0x1 must not change the values of any other fields in the CSR.
+ * A write to LUE_PERFORMANCE_CONTROL*, which sets the ENABLE field to 0x1 must not change the
+ * values of any other fields in the CSR.
  */
 union cvmx_ase_lue_performance_controlx {
 	uint64_t u64;
 	struct cvmx_ase_lue_performance_controlx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t frozen                       : 1;  /**< Indicates that the counter is frozen (i.e one shot
-                                                         event occurred) Remains frozen until the clear bit
-                                                         written. */
-	uint64_t clear                        : 1;  /**< Writing 1 to this bit will generate a hardware pulse
-                                                         that will clear the LUE_PERFOMANCE_COUNTER and
-                                                         field FROZEN of this register. */
-	uint64_t enable                       : 1;  /**< Enable the counter. This bit is set to 1 to use
-                                                         the corresponding counter. */
+	uint64_t frozen                       : 1;  /**< Indicates that the counter is frozen (i.e one shot event occurred) and remains frozen
+                                                         until the clear bit written. */
+	uint64_t clear                        : 1;  /**< Writing 1 to this bit generates a hardware pulse that clears the LUE_PERFOMANCE_COUNTER
+                                                         and field FROZEN of this register. */
+	uint64_t enable                       : 1;  /**< Enable the counter. This bit is set to 1 to use the corresponding counter. */
 	uint64_t reserved_27_28               : 2;
-	uint64_t mode                         : 3;  /**< Performance Counter Mode.
-                                                         Bit[24] - '1' Event counted SEL0 | SEL1 | SEL2
-                                                                   '0' Event counted SEL0 & SEL1 & SEL2
-                                                         Bits[26:25] - 2'b00 - Pos Edge
-                                                                       2'b01 - Neg Edge
-                                                                       2'b10 - Level
-                                                                       2'b11 - One shot */
-	uint64_t sel2                         : 8;  /**< Performance Counter Event Select, third mux.
+	uint64_t mode                         : 3;  /**< Performance counter mode.
+                                                         Bit<24>:
+                                                         1 = Event counted SEL0 | SEL1 | SEL2.
+                                                         0 = Event counted SEL0 & SEL1 & SEL2.
+                                                         Bits<26:25>:
+                                                         0x0 = Pos Edge.
+                                                         0x1 = Neg Edge.
+                                                         0x2 = Level.
+                                                         0x3 = One shot. */
+	uint64_t sel2                         : 8;  /**< Performance counter event select, third mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
-	uint64_t sel1                         : 8;  /**< Performance Counter Event Select, second mux.
+	uint64_t sel1                         : 8;  /**< Performance counter event select, second mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
-	uint64_t sel0                         : 8;  /**< Performance Counter Event Select, first mux.
+	uint64_t sel0                         : 8;  /**< Performance counter event select, first mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
 #else
 	uint64_t sel0                         : 8;
@@ -1425,39 +1336,36 @@ typedef union cvmx_ase_lue_performance_controlx cvmx_ase_lue_performance_control
 /**
  * cvmx_ase_lue_performance_control0
  *
- * A write to a LUE_PERFORMANCE_CONTROL* CSR which sets the ENABLE
- * field to 0x1 must not change the values of any other fields in the CSR.
+ * A write to LUE_PERFORMANCE_CONTROL*, which sets the ENABLE field to 0x1 must not change the
+ * values of any other fields in the CSR.
  */
 union cvmx_ase_lue_performance_control0 {
 	uint64_t u64;
 	struct cvmx_ase_lue_performance_control0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t frozen                       : 1;  /**< Indicates that the counter is frozen (i.e one shot
-                                                         event occurred) Remains frozen until the clear bit
-                                                         written. */
-	uint64_t clear                        : 1;  /**< Writing 1 to this bit will generate a hardware pulse
-                                                         that will clear the LUE_PERFOMANCE_COUNTER and
-                                                         field FROZEN of this register. */
-	uint64_t enable                       : 1;  /**< Enable the counter. This bit is set to 1 to use
-                                                         the corresponding counter. */
-	uint64_t global_stop                  : 1;  /**< Writing a 1 to this bit stops all the counters in
-                                                         the group of eight counters. This bit is only
-                                                         implemented in the first control register of a
-                                                         counter group. */
+	uint64_t frozen                       : 1;  /**< Indicates that the counter is frozen (i.e one shot event occurred) and remains frozen
+                                                         until the clear bit written. */
+	uint64_t clear                        : 1;  /**< Writing 1 to this bit generates a hardware pulse that clears the LUE_PERFOMANCE_COUNTER
+                                                         and field FROZEN of this register. */
+	uint64_t enable                       : 1;  /**< Enable the counter. This bit is set to 1 to use the corresponding counter. */
+	uint64_t global_stop                  : 1;  /**< Writing a 1 to this bit stops all the counters in the group of eight counters. This bit is
+                                                         only implemented in the first control register of a counter group. */
 	uint64_t reserved_27_27               : 1;
-	uint64_t mode                         : 3;  /**< Performance Counter Mode.
-                                                         Bit[24] - '1' Event counted SEL0 | SEL1 | SEL2
-                                                                   '0' Event counted SEL0 & SEL1 & SEL2
-                                                         Bits[26:25] - 2'b00 - Pos Edge
-                                                                       2'b01 - Neg Edge
-                                                                       2'b10 - Level
-                                                                       2'b11 - One shot */
-	uint64_t sel2                         : 8;  /**< Performance Counter Event Select, third mux.
+	uint64_t mode                         : 3;  /**< Performance counter mode.
+                                                         Bit<24>:
+                                                         1 = Event counted SEL0.
+                                                         0 = Event counted SEL0 & SEL1 & SEL2.
+                                                         Bits<26:25>:
+                                                         0x0 = Pos Edge.
+                                                         0x1 = Neg Edge.
+                                                         0x2 = Level.
+                                                         0x3 = One shot. */
+	uint64_t sel2                         : 8;  /**< Performance counter event select, third mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
-	uint64_t sel1                         : 8;  /**< Performance Counter Event Select, second mux.
+	uint64_t sel1                         : 8;  /**< Performance counter event select, second mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
-	uint64_t sel0                         : 8;  /**< Performance Counter Event Select, first mux.
+	uint64_t sel0                         : 8;  /**< Performance counter event select, first mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
 #else
 	uint64_t sel0                         : 8;
@@ -1479,42 +1387,37 @@ typedef union cvmx_ase_lue_performance_control0 cvmx_ase_lue_performance_control
 /**
  * cvmx_ase_lue_performance_control1
  *
- * A write to a LUE_PERFORMANCE_CONTROL* CSR which sets the ENABLE or
- * GLOBAL_ENABLE fields to 0x1 must not change the values of any other
- * fields in the CSR.
+ * A write to LUE_PERFORMANCE_CONTROL*, which sets the ENABLE or GLOBAL_ENABLE fields to 0x1 must
+ * not change the values of any other fields in the CSR.
  */
 union cvmx_ase_lue_performance_control1 {
 	uint64_t u64;
 	struct cvmx_ase_lue_performance_control1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t frozen                       : 1;  /**< Indicates that the counter is frozen (i.e one shot
-                                                         event occurred) Remains frozen until the clear bit
-                                                         written. */
-	uint64_t clear                        : 1;  /**< Writing 1 to this bit will generate a hardware pulse
-                                                         that will clear the LUE_PERFOMANCE_COUNTER and
-                                                         field FROZEN of this register. */
-	uint64_t enable                       : 1;  /**< Enable the counter. This bit is set to 1 to use
-                                                         the corresponding counter. */
-	uint64_t global_enable                : 1;  /**< Writing a 1 to this bit starts all the counters in
-                                                         the group of eight counters. This bit is only
-                                                         implemented in the second control register of a
-                                                         counter group.
-                                                         Counters are enabled by the OR of the individual ENABLEs
-                                                         and GLOBAL_ENABLE. */
+	uint64_t frozen                       : 1;  /**< Indicates that the counter is frozen (i.e one shot event occurred) and remains frozen
+                                                         until the clear bit written. */
+	uint64_t clear                        : 1;  /**< Writing 1 to this bit generates a hardware pulse that clears the LUE_PERFOMANCE_COUNTER
+                                                         and field FROZEN of this register. */
+	uint64_t enable                       : 1;  /**< Enable the counter. This bit is set to 1 to use the corresponding counter. */
+	uint64_t global_enable                : 1;  /**< Writing a 1 to this bit starts all the counters in the group of eight counters. This bit
+                                                         is only implemented in the second control register of a counter group. Counters are
+                                                         enabled by the OR of the individual ENABLEs and GLOBAL_ENABLE. */
 	uint64_t reserved_27_27               : 1;
-	uint64_t mode                         : 3;  /**< Performance Counter Mode.
-                                                         Bit[24] - '1' Event counted SEL0 | SEL1 | SEL2
-                                                                   '0' Event counted SEL0 & SEL1 & SEL2
-                                                         Bits[26:25] - 2'b00 - Pos Edge
-                                                                       2'b01 - Neg Edge
-                                                                       2'b10 - Level
-                                                                       2'b11 - One shot */
-	uint64_t sel2                         : 8;  /**< Performance Counter Event Select, third mux.
+	uint64_t mode                         : 3;  /**< Performance counter mode.
+                                                         Bit<24>:
+                                                         1 = Event counted SEL0 | SEL1 | SEL2
+                                                         0 = Event counted SEL0 & SEL1 & SEL2
+                                                         Bits<26:25>:
+                                                         0x0 = Pos Edge.
+                                                         0x1 = Neg Edge.
+                                                         0x2 = Level.
+                                                         0x3 = One shot. */
+	uint64_t sel2                         : 8;  /**< Performance counter event select, third mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
-	uint64_t sel1                         : 8;  /**< Performance Counter Event Select, second mux.
+	uint64_t sel1                         : 8;  /**< Performance counter event select, second mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
-	uint64_t sel0                         : 8;  /**< Performance Counter Event Select, first mux.
+	uint64_t sel0                         : 8;  /**< Performance counter event select, first mux.
                                                          INTERNAL: For details of mapping of events to selects, see lue.perf. */
 #else
 	uint64_t sel0                         : 8;
@@ -1535,18 +1438,13 @@ typedef union cvmx_ase_lue_performance_control1 cvmx_ase_lue_performance_control
 
 /**
  * cvmx_ase_lue_performance_counter#
- *
- * A write to a LUE_PERFORMANCE_CONTROL* CSR which sets the ENABLE or
- * GLOBAL_ENABLE fields to 0x1 must not at the same time
- * change the values of any other fields in the CSR.
  */
 union cvmx_ase_lue_performance_counterx {
 	uint64_t u64;
 	struct cvmx_ase_lue_performance_counterx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t perf_cnt                     : 48; /**< Reflect the value of the perfomance counter.
-                                                         Please see LUE_PERFOMANCE_CONTROL register. */
+	uint64_t perf_cnt                     : 48; /**< Reflect the value of the performance counter. See ASE_LUE_PERFORMANCE_CONTROL* registers. */
 #else
 	uint64_t perf_cnt                     : 48;
 	uint64_t reserved_48_63               : 16;
@@ -1578,7 +1476,7 @@ typedef union cvmx_ase_lue_spare cvmx_ase_lue_spare_t;
 /**
  * cvmx_ase_lue_twe_bwe_enable
  *
- * Enable tree/bucket walk engines.
+ * This register enables the tree/bucket walk engines.
  *
  */
 union cvmx_ase_lue_twe_bwe_enable {
@@ -1586,12 +1484,11 @@ union cvmx_ase_lue_twe_bwe_enable {
 	struct cvmx_ase_lue_twe_bwe_enable_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_52_63               : 12;
-	uint64_t bwe_en                       : 20; /**< Each bit enables a Bucket Walk Engine to accept a thread
-                                                         graduation from a TWE.
-                                                         Meaning of enable bits: [BWE19 ... BWE0]. */
+	uint64_t bwe_en                       : 20; /**< Each bit enables a bucket walk engine to accept a thread graduation from a TWE. Meaning of
+                                                         enable bits: [BWE19 ... BWE0]. */
 	uint64_t reserved_20_31               : 12;
-	uint64_t twe_en                       : 20; /**< Each bit enables a Tree Walk Engine to accept new Lookup requests.
-                                                         Meaning of enable bits: [TWE19 ... TWE0]. */
+	uint64_t twe_en                       : 20; /**< Each bit enables a tree walk engine to accept new lookup requests. Meaning of enable bits:
+                                                         [TWE19 ... TWE0]. */
 #else
 	uint64_t twe_en                       : 20;
 	uint64_t reserved_20_31               : 12;
@@ -1606,36 +1503,25 @@ typedef union cvmx_ase_lue_twe_bwe_enable cvmx_ase_lue_twe_bwe_enable_t;
 /**
  * cvmx_ase_luf_error_log
  *
- * "
- * Logs information to help diagnose Look Up Frontend (LookUp Input/Output
- * Pre/Postprocessor) errors as indicated in ASE_*_INT[LIP* /LOP*].
- *
- * The contents of this CSR are invalid if no fields are set in ASE_*_INT[LIP* /LOP*].
- *
- * The contents of this CSR are retained until all the bits in the ASE_*_INT[LIP* /LOP*]
- * are cleared, or an error occurs that is of higher-priority than the error for
- * which information is currently logged by this CSR.
- *
- * The priority of the error is encoded by the enumerated values in ASE_LUF_ERROR_ID_E.
- * Only interrupts listed in ASE_LUF_ERROR_ID_E log errors.
- * "
+ * The information logged in this register helps diagnose lookup front end (LUF) (look up
+ * input/output pre/postprocessor) errors as indicated in ASE_*_INT[LIP* /LOP*]. The contents of
+ * this CSR are invalid if no fields are set in ASE_*_INT[LIP* /LOP*]. The contents of this CSR
+ * are retained until all the bits in the ASE_*_INT[LIP* /LOP*] are cleared, or an error occurs
+ * that is of higher-priority than the error for which information is currently logged by this
+ * CSR. The priority of the error is encoded by the enumerated values in ASE_LUF_ERROR_ID_E. Only
+ * interrupts listed in ASE_LUF_ERROR_ID_E log errors.
  */
 union cvmx_ase_luf_error_log {
 	uint64_t u64;
 	struct cvmx_ase_luf_error_log_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
-	uint64_t error_id                     : 4;  /**< Type of error logged. See ASE_LUF_ERROR_ID_E.
-                                                         Also indicates how to decode the DATA field. */
-	uint64_t data                         : 56; /**< "
-                                                         Error Logging Information
-                                                         The information in this field takes on different meanings
-                                                         depending on the type of error that is latched in the
-                                                         ASE_*_INT[LIP* /LOP*] fields.
+	uint64_t error_id                     : 4;  /**< Type of error logged. See ASE_LUF_ERROR_ID_E. Also indicates how to decode the DATA field. */
+	uint64_t data                         : 56; /**< Error logging information. The information in this field takes on different meanings
+                                                         depending on the type of error that is latched in the ASE_*_INT[LIP* /LOP*] fields.
                                                          Decode this field based on ERROR_ID.
-                                                           LIP_*_*BE: see ASE_LUF_ERROR_LOG_LIP_ECC_S.
-                                                           LOP_TXB_*BE: see ASE_LUF_ERROR_LOG_LOP_ECC_S.
-                                                         " */
+                                                         For LIP_*_*BE, see ASE_LUF_ERROR_LOG_LIP_ECC_S.
+                                                         For LOP_TXB_*BE, see ASE_LUF_ERROR_LOG_LOP_ECC_S. */
 #else
 	uint64_t data                         : 56;
 	uint64_t error_id                     : 4;
@@ -1649,7 +1535,7 @@ typedef union cvmx_ase_luf_error_log cvmx_ase_luf_error_log_t;
 /**
  * cvmx_ase_sft_rst
  *
- * Allows soft reset.
+ * This register allows soft reset.
  *
  */
 union cvmx_ase_sft_rst {
@@ -1659,9 +1545,9 @@ union cvmx_ase_sft_rst {
 	uint64_t busy                         : 1;  /**< When 1, ASE is busy completing reset. No access except the reading of this bit should
                                                          occur to the ASE until this is clear. */
 	uint64_t reserved_1_62                : 62;
-	uint64_t rst                          : 1;  /**< When set to 1 by software, ASE gets a short reset pulse (eight cycles in duration).
-                                                         Everything but the RSL interface is reset (including CSRs).
-                                                         Hardware will clear this bit when the reset is complete. */
+	uint64_t rst                          : 1;  /**< When set to 1 by software, ASE gets a short reset pulse (32 cycles in duration).
+                                                         Everything but the RSL interface is reset (including CSRs). Hardware clears this bit when
+                                                         the reset is complete. */
 #else
 	uint64_t rst                          : 1;
 	uint64_t reserved_1_62                : 62;
diff --git a/arch/mips/include/asm/octeon/cvmx-asm.h b/arch/mips/include/asm/octeon/cvmx-asm.h
index 659632f..2755a0f 100644
--- a/arch/mips/include/asm/octeon/cvmx-asm.h
+++ b/arch/mips/include/asm/octeon/cvmx-asm.h
@@ -42,7 +42,7 @@
  *
  * This is file defines ASM primitives for the executive.
 
- * <hr>$Revision: 84791 $<hr>
+ * <hr>$Revision: 86220 $<hr>
  *
  *
  */
@@ -66,6 +66,7 @@
 #define COP0_ENTRYLO0	$2,0	/* TLB entryLo0 */
 #define COP0_ENTRYLO1	$3,0	/* TLB entryLo1 */
 #define COP0_CONTEXT	$4,0	/* Context */
+#define COP0_USERLOCAL	$4,2	/* User Local (OCTEON II and later) */
 #define COP0_PAGEMASK	$5,0	/* TLB pagemask */
 #define COP0_PAGEGRAIN	$5,1	/* TLB config for max page sizes */
 #define COP0_WIRED	$6,0	/* TLB number of wired entries */
@@ -89,6 +90,8 @@
 #define COP0_CONFIG1	$16,1	/* Misc config options */
 #define COP0_CONFIG2	$16,2	/* Misc config options */
 #define COP0_CONFIG3	$16,3	/* Misc config options */
+#define COP0_CONFIG4	$16,4	/* Misc config options (OCTEON III and later) */
+#define COP0_CONFIG5	$16,5	/* Misc config options (OCTEON III and later) */
 #define COP0_WATCHLO0	$18,0	/* Address watch registers */
 #define COP0_WATCHLO1	$18,1	/* Address watch registers */
 #define COP0_WATCHHI0	$19,0	/* Address watch registers */
@@ -113,7 +116,10 @@
 #define COP0_DATAHID	$29,3	/* ? */
 #define COP0_ERROREPC	$30,0	/* Error PC */
 #define COP0_DESAVE	$31,0	/* Debug scratch area */
-
+#define COP0_KSCRATCH1	$31,2	/* KScratch 1 (OCTEON II and later) */
+#define COP0_KSCRATCH2	$31,3	/* KScratch 2 (OCTEON II and later) */
+#define COP0_KSCRATCH3	$31,4	/* KScratch 3 (OCTEON III and later) */
+#define COP0_KSCRATCH4	$31,5	/* KScratch 3 (OCTEON III and later) */
 #define COP1_FIR	$0	/* Floating point implementation register */
 #define COP1_FCSR	$31	/* Floating point control and status register */
 
diff --git a/arch/mips/include/asm/octeon/cvmx-asxx-defs.h b/arch/mips/include/asm/octeon/cvmx-asxx-defs.h
index 29c0de3..56fb582 100644
--- a/arch/mips/include/asm/octeon/cvmx-asxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-asxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-bch-defs.h b/arch/mips/include/asm/octeon/cvmx-bch-defs.h
index 02ec72a..858a066 100644
--- a/arch/mips/include/asm/octeon/cvmx-bch-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-bch-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-bch.h b/arch/mips/include/asm/octeon/cvmx-bch.h
new file mode 100644
index 0000000..b0cbd6a
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-bch.h
@@ -0,0 +1,368 @@
+/***********************license start***************
+ * Copyright (c) 2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+ *
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+ *
+ * This Software, including technical data, may be subject to U.S. export
+ * control laws, including the U.S. Export Administration Act and its associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+ *
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION
+ * OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Interface to the CN7XXX hardware BCH engine.
+ *
+ * <hr>$Revision: 79788 $<hr>
+ */
+
+#ifndef __CVMX_BCH_H__
+#define __CVMX_BCH_H__
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+# include <asm/octeon/octeon.h>
+# include <asm/octeon/cvmx-bch-defs.h>
+# include <asm/octeon/cvmx-fpa.h>
+#elif defined(CVMX_BUILD_FOR_UBOOT)
+# include <common.h>
+# include <asm/arch/cvmx.h>
+# include <asm/arch/cvmx-bch-defs.h>
+# include <asm/arch/cvmx-fpa.h>
+#else
+# include "cvmx.h"
+# include "cvmx-bch-defs.h"
+# include "cvmx-fpa.h"
+#endif
+#ifdef __cplusplus
+/* *INDENT-OFF* */
+extern "C" {
+/* *INDENT-ON* */
+#endif
+
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_BCH_DRBELL CVMX_BCH_DRBELL_FUNC()
+static inline uint64_t CVMX_BCH_DRBELL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN70XX)))
+		cvmx_warn("CVMX_BCH_DRBELL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001710000000000ull);
+}
+#else
+#define CVMX_BCH_DRBELL (CVMX_ADD_IO_SEG(0x0001710000000000ull))
+#endif
+
+union cvmx_bch_drbell {
+	uint64_t u64;
+	struct cvmx_bch_drbell_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_20_63	: 44;
+		uint64_t cnt		: 20;	/**
+		* Number of 64-bit words to add
+		* to the BCH instruction
+		* doorbell count.  BCH
+		* instructions are from 4 to 36
+		* words.
+		*/
+#else
+		uint64_t cnt		: 20;	/**
+		* Number of 64-bit words to add
+		* to the BCH instruction
+		* doorbell count.  BCH
+		* instructions are from 4 to 36
+		* words.
+		*/
+		uint64_t reserved_20_63	: 44;
+#endif
+	} s;
+	struct cvmx_bch_drbell_s	cn70xx;
+};
+typedef union cvmx_bch_drbell cvmx_bch_drbell_t;
+
+typedef enum {
+	CVMX_BCH_INST_BLOCK_CORRECTION	= 0,	/** Perform block correction */
+	CVMX_BCH_INST_ECC_GENERATION	= 1,	/** Generate ECC data */
+} cvmx_bch_inst_type_t;
+
+typedef union cvmx_bch_command {
+	uint64_t u64[4];
+	struct fields {
+		/** CWORD Format */
+		struct _cword {
+#ifdef __BIG_ENDIAN_BITFIELD
+			uint64_t	ecc_gen:1;	/** See cvmx_bch_inst_type_t */
+			uint64_t	reserved1:24;	/** Must be zero */
+			/**
+			 * Maximum number of errors that can be corrected.  The number
+			 * of parity bytes is equal to ((15 * ecc_level) + 7) / 8.
+			 * ecc_level must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
+			 */
+			uint64_t	ecc_level:7;
+			uint64_t	reserved2:20;	/** Must be zero */
+			/** Size in bytes of data block.  Must be multiple of 2 */
+			uint64_t	size:12;
+#else
+			uint64_t	size:12;
+			uint64_t	reserved1:20;
+			uint64_t	ecc_level:7;
+			uint64_t	reserved2:24;
+			uint64_t	ecc_gen:1;
+#endif
+		} cword;
+		/** OWORD Format */
+		struct _oword {
+#ifdef __BIG_ENDIAN_BITFIELD
+			uint64_t	reserved1:6;	/** Must be zero */
+			/**
+			 * BCH can modify any byte in any 128-byte cache line
+			 * touched by L2/DRAM addresses oword.ptr through
+			 * oword.ptr + cword.size - 1.  Setting this to 1 can
+			 * improve hardware performance as some DRAM load
+			 * operations can be avoided on L2 cache misses.
+			 */
+			uint64_t	fw:1;
+			/**
+			 * When set indicates that BCH should not allocate L2
+			 * cache space for the parity correction data on L2
+			 * misses.
+			 */
+			uint64_t	nc:1;
+			uint64_t	reserved2:16;	/** Must be zero */
+			/**
+			 * Starting address of L2/DRAM buffer.  When ecc_gen is
+			 * CVMX_BCH_INST_BLOCK_CORRECTION this contains the
+			 * address where the corrected data shall be placed,
+			 * otherwise this contains the address of the generated
+			 * ecc data.
+			 *
+			 * ptr must be naturally-aligned on an 8-byte boundary.
+			 */
+			uint64_t	ptr:40;
+#else
+			uint64_t	ptr:40;
+			uint64_t	reserved1:16;
+			uint64_t	nc:1;
+			uint64_t	fw:1;
+			uint64_t	reserved2:6;
+#endif
+		} oword;
+		/** IWORD Format */
+		struct _iword {
+#ifdef __BIG_ENDIAN_BITFIELD
+			uint64_t	reserved1:7;	/** Must be zero */
+			/**
+			 * When set do not allocate L2 cache space for the input
+			 * data on L2 cache misses.
+			 */
+			uint64_t	nc:1;
+			uint64_t	reserved2:16;	/** Must be zero */
+			/**
+			 * Starting address of input data in L2/DRAM.
+			 *
+			 * When ecc_gen is CVMX_BCH_INST_BLOCK_CORRECTION this
+			 * contains the address where the ecc data is located,
+			 * otherwwise this contains the address of the data
+			 * block.
+			 *
+			 * ptr must be naturally-aligned on an 8-byte boundary.
+			 */
+			uint64_t	ptr:40;
+#else
+			uint64_t	ptr:40;
+			uint64_t	reserved1:16;
+			uint64_t	nc:1;
+			uint64_t	reserved2:7;
+#endif
+		} iword;
+		/** RESP Format */
+		struct _resp {
+#ifdef __BIG_ENDIAN_BITFIELD
+			uint64_t	reserved:24;	/** Must be zero */
+			/**
+			 * Pointer where two byte operation status will be
+			 * written
+			 */
+			uint64_t	ptr:40;
+#else
+			uint64_t	ptr:40;
+			uint64_t	reserved:24;
+#endif
+		} resp;
+	} s;
+} cvmx_bch_command_t;
+
+/** Response from BCH instruction */
+union cvmx_bch_response {
+	uint16_t  u16;
+	struct cvmx_bch_response_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint16_t	done:1;		/** Block is done */
+		uint16_t	uncorrectable:1;/** Block could not be corrected */
+		uint16_t	erased:1;	/** Block is erased */
+		uint16_t	zero:6;		/** Always zero, ignore */
+		uint16_t	num_errors:7;	/** Number of errors in block */
+#else
+		uint16_t	num_errors:7;	/** Number of errors in block */
+		uint16_t	zero:6;		/** Always zero, ignore */
+		uint16_t	erased:1;	/** Block is erased */
+		uint16_t	uncorrectable:1;/** Block could not be corrected */
+		uint16_t	done:1;		/** Block is done */
+#endif
+	} s;
+};
+typedef union cvmx_bch_response cvmx_bch_response_t;
+
+/**
+ * Sets up the BCH configuration data
+ * (only FPA pool for now)
+ */
+typedef struct {
+	cvmx_fpa_pool_config_t	command_queue_pool;	/** BCH FPA pool */
+	int			aura;
+} cvmx_bch_app_config_t;
+
+extern CVMX_SHARED cvmx_bch_app_config_t bch_config;
+
+/**
+ * Gets the pool number used by BCH
+ *
+ * @return FPA pool number used
+ */
+static inline int64_t cvmx_fpa_get_bch_pool(void)
+{
+	return bch_config.command_queue_pool.pool_num;
+}
+
+/**
+ * Gets the size of the buffer in BCH FPA pool
+ *
+ * @return FPA pool buffer size
+ */
+static inline uint64_t cvmx_fpa_get_bch_pool_block_size(void)
+{
+	return bch_config.command_queue_pool.buffer_size;
+}
+
+/**
+ * Gets the buffer count of the BCH pool
+ *
+ * @return buffer count of BCH FPA pool
+ */
+static inline uint64_t cvmx_fpa_get_bch_pool_buffer_count(void)
+{
+	return bch_config.command_queue_pool.buffer_count;
+}
+
+/**
+ * Ring the BCH doorbell telling it that new commands are
+ * available.
+ *
+ * @param num_commands	Number of new commands
+ */
+static inline void cvmx_bch_write_doorbell(uint64_t num_commands)
+{
+	uint64_t num_words =
+		num_commands * sizeof(cvmx_bch_command_t) / sizeof(uint64_t);
+	CVMX_SYNCWS;
+	cvmx_write_csr(CVMX_BCH_DRBELL, num_words);
+}
+
+/**
+ * Sets the internal FPA pool data structure for bch pool.
+ * @param pool	fpa pool number to use
+ * @param buffer_size	buffer size of pool
+ * @param buffer_count	number of buffers to allocate to pool
+ */
+void cvmx_bch_set_cmd_que_pool_config(int64_t pool, uint64_t buffer_size,
+				      uint64_t buffer_count);
+
+/**
+ * Gets the FPA pool data from internal data structure
+ * @param bch_pool pointer to the fpa data structure to copy data
+ */
+void cvmx_bch_get_cmd_que_pool_config(cvmx_fpa_pool_config_t *bch_pool);
+
+/**
+ * Initializes the BCH hardware before use.
+ * @return 0 on success, -1 on failure
+ */
+int cvmx_bch_initialize(void);
+
+/**
+ * Shutdown and cleanup resources used by the BCH
+ */
+int cvmx_bch_shutdown(void);
+
+/**
+ * Given a data block calculate the ecc data and fill in the response
+ *
+ * @param[in] block	8-byte aligned pointer to data block to calculate ECC
+ * @param block_size	Size of block in bytes, must be a multiple of two.
+ * @param ecc_level	Number of errors that must be corrected.  The number of
+ * 			parity bytes is equal to ((15 * ecc_level) + 7) / 8.
+ * 			Must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
+ * @param[out] ecc	8-byte aligned pointer to where ecc data should go
+ * @param[in] response	pointer to where responses will be written.
+ *
+ * @return Zero on success, negative on failure.
+ */
+int cvmx_bch_encode(const void *block, uint16_t block_size,
+		    uint8_t ecc_level, void *ecc,
+		    volatile cvmx_bch_response_t *response);
+
+/**
+ * Given a data block and ecc data correct the data block
+ *
+ * @param[in] block_ecc_in	8-byte aligned pointer to data block with ECC
+ *				data concatenated to the end to correct
+ * @param block_size		Size of block in bytes, must be a multiple of
+ *				two.
+ * @param ecc_level		Number of errors that must be corrected.  The
+ *				number of parity bytes is equal to
+ *				((15 * ecc_level) + 7) / 8.
+ * 				Must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
+ * @param[out] block_out	8-byte aligned pointer to corrected data buffer.
+ * 				This should not be the same as block_ecc_in.
+ * @param[in] response		pointer to where responses will be written.
+ *
+ * @return Zero on success, negative on failure.
+ */
+int cvmx_bch_decode(const void *block_ecc_in, uint16_t block_size,
+		    uint8_t ecc_level, volatile void *block_out,
+		    volatile cvmx_bch_response_t *response);
+
+#ifdef __cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
+#endif
+
+#endif /* __CVMX_BCH_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-bgx.h b/arch/mips/include/asm/octeon/cvmx-bgx.h
new file mode 100644
index 0000000..71ab334
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-bgx.h
@@ -0,0 +1,64 @@
+/***********************license start***************
+ * Copyright (c) 2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Functions to configure the BGX MAC.
+ *
+ * <hr>$Revision$<hr>
+ */
+
+#ifndef __CVMX_BGX_H__
+#define __CVMX_BGX_H__
+
+
+/**
+ * @INTERNAL
+ * Configure the bgx mac.
+ *
+ * @param interface Interface to bring up
+ *
+ * @param mode      Mode to configure the bgx mac as
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int bgx_init(int interface, cvmx_helper_interface_mode_t mode);
+
+#endif /* __CVMX_BGX_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
index 5139b4a..af45ce9 100644
--- a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1904,10 +1904,39 @@ static inline uint64_t CVMX_BGXX_SPU_SDSX_STATES(unsigned long offset, unsigned
 /**
  * cvmx_bgx#_cmr#_config
  *
- * "***************************************************************
- * BGX Global per lmac related CSR (may be sent to any of GMP, SMU, SPU)
- * ***************************************************************
- * Logical PCS and MAC Configuration"
+ * Logical MAC/PCS configuration registers; one per LMAC. The maximum number of LMACs (and
+ * maximum LMAC ID) that can be enabled by these registers is limited by
+ * BGX(0..5)_CMR_RX_LMACS[LMACS] and BGX(0..5)_CMR_TX_LMACS[LMACS]. When multiple LMACs are
+ * enabled, they must be configured with the same [LMAC_TYPE] value.
+ * Typical configurations:
+ *   ---------------------------------------------------------------------------
+ *   Configuration           LMACS  Register             [ENABLE]    [LMAC_TYPE]
+ *   ---------------------------------------------------------------------------
+ *   1x40GBASE-R4            1      BGXn_CMR0_CONFIG     1           4
+ *                                  BGXn_CMR1_CONFIG     0           --
+ *                                  BGXn_CMR2_CONFIG     0           --
+ *                                  BGXn_CMR3_CONFIG     0           --
+ *   ---------------------------------------------------------------------------
+ *   4x10GBASE-R             4      BGXn_CMR0_CONFIG     1           3
+ *                                  BGXn_CMR1_CONFIG     1           3
+ *                                  BGXn_CMR2_CONFIG     1           3
+ *                                  BGXn_CMR3_CONFIG     1           3
+ *   ---------------------------------------------------------------------------
+ *   2xRXAUI                 2      BGXn_CMR0_CONFIG     1           2
+ *                                  BGXn_CMR1_CONFIG     1           2
+ *                                  BGXn_CMR2_CONFIG     0           --
+ *                                  BGXn_CMR3_CONFIG     0           --
+ *   ---------------------------------------------------------------------------
+ *   1x10GBASE-X/XAUI/DXAUI  1      BGXn_CMR0_CONFIG     1           1
+ *                                  BGXn_CMR1_CONFIG     0           --
+ *                                  BGXn_CMR2_CONFIG     0           --
+ *                                  BGXn_CMR3_CONFIG     0           --
+ *   ---------------------------------------------------------------------------
+ *   4xSGMII/1000BASE-X      4      BGXn_CMR0_CONFIG     1           0
+ *                                  BGXn_CMR1_CONFIG     1           0
+ *                                  BGXn_CMR2_CONFIG     1           0
+ *                                  BGXn_CMR3_CONFIG     1           0
+ *   ---------------------------------------------------------------------------
  */
 union cvmx_bgxx_cmrx_config {
 	uint64_t u64;
@@ -1933,35 +1962,36 @@ union cvmx_bgxx_cmrx_config {
                                                          during normal operation. When set, the LMAC's PCS layer ignores RXVALID and
                                                          TXREADY/TXCREDIT from the associated serdes lane(s), internally generates fake (idle)
                                                          RXVALID and TXCREDIT pulses, and suppresses transmission to the serdes */
-	uint64_t mix_en                       : 1;  /**< Managmenet enable(for 2 LMACs, namely
-                                                         0 and 1 only). Setting this will pipe the
-                                                         lmac to and from the MIX inteface. For
-                                                         these LMACs LMAC_TYPE should be 0(SGMII) */
+	uint64_t mix_en                       : 1;  /**< Managemenet enable. This bit is used by LMACs 0 and 1 only, and should be kept clear for
+                                                         LMACs 2 and 3. Setting it will pipe the LMAC to and from the MIX inteface (LMAC0 to/from
+                                                         MIX0, LMAC1 to/from MIX1). LMAC_TYPE must be 0 (SGMII) then this bit is set. Note that at
+                                                         most one BGX can be attached to each of MIX0 and MIX1, i.e. at most one
+                                                         BGX(0..5)_CMR0_CONFIG[MIX_EN] bit and one BGX(0..5)_CMR1_CONFIG[MIX_EN] bit can be set. */
 	uint64_t lmac_type                    : 3;  /**< Logical MAC/PCS Type:
-                                                         ----------+----------------------------------------------------------
-                                                         LMAC_TYPE | Name         Description                NUM_PCS_LANES
-                                                         ----------+----------------------------------------------------------
-                                                         0         | SGMII      SGMII/1000BASE-X             1
-                                                         1         | XAUI       10GBASE-X/XAUI or DXAUI      4
-                                                         2         | RXAUI      Reduced XAUI                 2
-                                                         3         | 10G_R      10GBASE-R                    1
-                                                         4         | 40G_R      40GBASE-R                    4
-                                                         Other     | -          Reserved                     -
-                                                         ----------+----------------------------------------------------------
+                                                           ----------+----------------------------------------------------------
+                                                           LMAC_TYPE | Name         Description                NUM_PCS_LANES
+                                                           ----------+----------------------------------------------------------
+                                                           0         | SGMII      SGMII/1000BASE-X             1
+                                                           1         | XAUI       10GBASE-X/XAUI or DXAUI      4
+                                                           2         | RXAUI      Reduced XAUI                 2
+                                                           3         | 10G_R      10GBASE-R                    1
+                                                           4         | 40G_R      40GBASE-R                    4
+                                                           Other     | -          Reserved                     -
+                                                           ----------+----------------------------------------------------------
                                                          NUM_PCS_LANES specifies the number of of PCS lanes that are valid for
                                                          each type. Each valid PCS lane is mapped to a physical serdes lane
-                                                         based on the programming of the LANE_TO_SDS field below. */
-	uint64_t lane_to_sds                  : 8;  /**< "PCS Lane to Serdes Mapping
+                                                         based on the programming of [LANE_TO_SDS]. */
+	uint64_t lane_to_sds                  : 8;  /**< PCS Lane to Serdes Mapping.
                                                          This is an array of 2-bit values that map each logical PCS Lane to a
                                                          physical serdes lane, as follows:
-                                                         ----------+----------------------------------------------------------
-                                                         Bits     | Description                     Reset value
-                                                         ----------+----------------------------------------------------------
-                                                         <7:6>    | PCS Lane 3 Serdes ID            0x3
-                                                         <5:4>    | PCS Lane 2 Serdes ID            0x2
-                                                         <3:2>    | PCS Lane 1 Serdes ID            0x1
-                                                         <1:0>    | PCS Lane 0 Serdes ID            0x0
-                                                         ----------+----------------------------------------------------------
+                                                           ----------+----------------------------------------------------------
+                                                           Bits     | Description                     Reset value
+                                                           ----------+----------------------------------------------------------
+                                                           <7:6>    | PCS Lane 3 Serdes ID            0x3
+                                                           <5:4>    | PCS Lane 2 Serdes ID            0x2
+                                                           <3:2>    | PCS Lane 1 Serdes ID            0x1
+                                                           <1:0>    | PCS Lane 0 Serdes ID            0x0
+                                                           ----------+----------------------------------------------------------
                                                          PCS lanes 0 through NUM_PCS_LANES-1 are valid, where NUM_PCS_LANES is
                                                          a function of the logical MAC/PCS type (see definition of
                                                          LMAC_TYPE field in this register). For example, when LMAC_TYPE =
@@ -1977,9 +2007,7 @@ union cvmx_bgxx_cmrx_config {
                                                          alignment marker lock on the receive side (i.e. the associated
                                                          MARKER_LOCK bit is set in BR_ALGN_STATUS), then the actual detected
                                                          RX PCS lane number is recorded in the corresponding LNx_MAPPING
-                                                         field in BR_LANE_MAP.
-                                                         For SGMII, the lane serdes assignments are hardcoded. LMAC 0 will
-                                                         always use lane 0 and is connected to sds 0. Same for LMAC 1, 2, 3." */
+                                                         field in BR_LANE_MAP. */
 #else
 	uint64_t lane_to_sds                  : 8;
 	uint64_t lmac_type                    : 3;
@@ -2003,9 +2031,10 @@ union cvmx_bgxx_cmrx_int {
 	struct cvmx_bgxx_cmrx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t pko_nxc                      : 1;  /**< TX channel out-of-range from PKO Interface */
-	uint64_t overflw                      : 1;  /**< RX Overflow */
-	uint64_t pause_drp                    : 1;  /**< RX Pause packet was dropped due to full RXB FIFO */
+	uint64_t pko_nxc                      : 1;  /**< TX channel out-of-range from PKO interface. Assigned to the LMAC ID based on the lower 2
+                                                         bits of the offending channel */
+	uint64_t overflw                      : 1;  /**< RX overflow. */
+	uint64_t pause_drp                    : 1;  /**< RX PAUSE packet was dropped due to full RXB FIFO or during partner reset. */
 #else
 	uint64_t pause_drp                    : 1;
 	uint64_t overflw                      : 1;
@@ -2019,17 +2048,18 @@ typedef union cvmx_bgxx_cmrx_int cvmx_bgxx_cmrx_int_t;
 
 /**
  * cvmx_bgx#_cmr#_prt_cbfc_ctl
+ *
+ * See XOFF definition listed under BGX(0..5)_SMU(0..3)_CBFC_CTL.
+ *
  */
 union cvmx_bgxx_cmrx_prt_cbfc_ctl {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_prt_cbfc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t phys_bp                      : 16; /**< When BGX_SMU_CBFC_CTL[RX_EN] is set and the HW is backpressuring any
-                                                         lmacs (from either PFC/CBFC pause packets or the
-                                                         BGX_CMR_TX_OVR_BP[TX_CHAN_BP] register) and all lmacs
-                                                         indiciated by PHYS_BP are backpressured, simulate
-                                                         physical backpressure by defering all packets on
+	uint64_t phys_bp                      : 16; /**< When BGXn_SMUm_CBFC_CTL[RX_EN] is set and the hardware is backpressuring any LMACs (from
+                                                         either PFC/CBFC PAUSE packets or BGXn_CMR_TX_OVR_BP[TX_CHAN_BP]) and all LMACs indicated
+                                                         by PHYS_BP are backpressured, simulate physical backpressure by deferring all packets on
                                                          the transmitter. */
 	uint64_t reserved_0_15                : 16;
 #else
@@ -2050,17 +2080,17 @@ union cvmx_bgxx_cmrx_rx_adr_ctl {
 	struct cvmx_bgxx_cmrx_rx_adr_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t cam_accept                   : 1;  /**< Allow or deny DMAC address filter
-                                                         0 = reject the packet on DMAC CAM address match
-                                                         1 = accept the packet on DMAC CAM address match */
-	uint64_t mcst_mode                    : 2;  /**< Multicast Mode
-                                                         0 = Force reject all multicast packets
-                                                         1 = Force accept all multicast packets
-                                                         2 = Use the Address Filter CAM
-                                                         3 = Reserved. */
-	uint64_t bcst_accept                  : 1;  /**< Allow or deny broadcast Packets
-                                                         0 = reject all broadcast Packets
-                                                         1 = accept all broadcast Packets */
+	uint64_t cam_accept                   : 1;  /**< Allow or deny DMAC address filter.
+                                                         0 = Reject the packet on DMAC CAM address match
+                                                         1 = Accept the packet on DMAC CAM address match */
+	uint64_t mcst_mode                    : 2;  /**< Multicast mode.
+                                                         0x0 = Force reject all multicast packets
+                                                         0x1 = Force accept all multicast packets
+                                                         0x2 = Use the address filter CAM
+                                                         0x3 = Reserved */
+	uint64_t bcst_accept                  : 1;  /**< Allow or deny broadcast packets.
+                                                         0 = Reject all broadcast packets
+                                                         1 = Accept all broadcast Packets */
 #else
 	uint64_t bcst_accept                  : 1;
 	uint64_t mcst_mode                    : 2;
@@ -2080,12 +2110,11 @@ union cvmx_bgxx_cmrx_rx_bp_drop {
 	struct cvmx_bgxx_cmrx_rx_bp_drop_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_7_63                : 57;
-	uint64_t mark                         : 7;  /**< Number of 8B cycles to reserve in the RX FIFO.
-                                                         When the FIFO exceeds this count, packets will
-                                                         be dropped and not buffered.
-                                                         MARK should typically be programmed to BGX_CMR_RX_LMACS[LMACS]+1.
-                                                         Failure to program correctly can lead to system
-                                                         instability. */
+	uint64_t mark                         : 7;  /**< Number of eight-byte cycles to reserve in the RX FIFO. When the number of free
+                                                         entries in the RX FIFO is less than or equal to MARK, incoming packet data is
+                                                         dropped. Mark additionally indicates the number of entries to reserve in the RX FIFO for
+                                                         closing partially received packets. MARK should typically be programmed to its reset
+                                                         value; failure to program correctly can lead to system instability. */
 #else
 	uint64_t mark                         : 7;
 	uint64_t reserved_7_63                : 57;
@@ -2103,7 +2132,8 @@ union cvmx_bgxx_cmrx_rx_bp_off {
 	struct cvmx_bgxx_cmrx_rx_bp_off_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_7_63                : 57;
-	uint64_t mark                         : 7;  /**< Water mark (8B cycles to deassert backpressure) */
+	uint64_t mark                         : 7;  /**< Low watermark (number of eight-byte cycles to deassert backpressure). Level is also used
+                                                         to exit the overflow dropping state. */
 #else
 	uint64_t mark                         : 7;
 	uint64_t reserved_7_63                : 57;
@@ -2121,16 +2151,14 @@ union cvmx_bgxx_cmrx_rx_bp_on {
 	struct cvmx_bgxx_cmrx_rx_bp_on_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t mark                         : 12; /**< Hiwater mark (number of 8B cycles to assert bp)
-                                                         Each register is for an individual lmac.
-                                                         BGX_CMR_RX_BP_ON(MARK) must satisfy
-                                                         BP_OFF <= BP_ON < (FIFO_SIZE - BP_DROP)
-                                                         A value of zero will immediately assert back
-                                                         pressure.
-                                                         Recommended value is 1/4th the size of the per
-                                                         lmac RX FIFO_SIZE as determined by BGX_CMR_RX_LMACS[LMACS].
-                                                         For example, with 4 lmacs of type SGMII where
-                                                         BGX_CMR_RX_LMACS[LMACS]=4, MARK=0x100(reset value) */
+	uint64_t mark                         : 12; /**< High watermark (number of eight-byte cycles to assert backpressure). Each register is for
+                                                         an individual LMAC. MARK must satisfy:
+                                                         BGX(0..5)_CMR(0..3)_RX_BP_OFF[MARK] <= MARK <
+                                                         (FIFO_SIZE - BGX(0..5)_CMR(0..3)_RX_BP_DROP[MARK]).
+                                                         A value of 0x0 immediately asserts backpressure.
+                                                         The recommended value is 1/4th the size of the per-LMAC RX FIFO_SIZE as determined by
+                                                         GX_CMR_RX_LMACS[LMACS]. For example in SGMII mode with four LMACs of type SGMII where
+                                                         BGX*_CMR*_RX_LMACS[LMACS]=0x4, MARK = 0x100 (the reset value. */
 #else
 	uint64_t mark                         : 12;
 	uint64_t reserved_12_63               : 52;
@@ -2148,9 +2176,9 @@ union cvmx_bgxx_cmrx_rx_bp_status {
 	struct cvmx_bgxx_cmrx_rx_bp_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t bp                           : 1;  /**< Per lmac backpressure status
-                                                         0=lmac is not backpressued
-                                                         1=lmac is backpressured */
+	uint64_t bp                           : 1;  /**< Per-LMAC backpressure status.
+                                                         0 = LMAC is not backpressured
+                                                         1 = LMAC is backpressured */
 #else
 	uint64_t bp                           : 1;
 	uint64_t reserved_1_63                : 63;
@@ -2168,7 +2196,7 @@ union cvmx_bgxx_cmrx_rx_fifo_len {
 	struct cvmx_bgxx_cmrx_rx_fifo_len_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t fifo_len                     : 13; /**< Per lmac fifo length. Useful for determining if fifo is empty when bringing an lmac down. */
+	uint64_t fifo_len                     : 13; /**< Per-LMAC FIFO length. Useful for determining if FIFO is empty when bringing an LMAC down. */
 #else
 	uint64_t fifo_len                     : 13;
 	uint64_t reserved_13_63               : 51;
@@ -2181,26 +2209,22 @@ typedef union cvmx_bgxx_cmrx_rx_fifo_len cvmx_bgxx_cmrx_rx_fifo_len_t;
 /**
  * cvmx_bgx#_cmr#_rx_id_map
  *
- * "**************************************************************
- * BGX CMR RXB related CSR per lmac
- * **************************************************************
- * BGX_CMR_RX_ID_MAP = RX LMAC ID mapping for X2P/PKI"
+ * These registers set the RX LMAC ID mapping for X2P/PKI.
+ *
  */
 union cvmx_bgxx_cmrx_rx_id_map {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_rx_id_map_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t rid                          : 7;  /**< "Reassembly ID for this LMAC:
-                                                         A shared pool of 96 reassembly ids (RIDs) exists for all MACs. See
-                                                         description of RIDs in TBD.
-                                                         The RID for this LMAC must be constrained such that it does not
-                                                         overlap with any other MAC in the system. Its reset value has been
-                                                         chosen such that this condition is satisified:
+	uint64_t rid                          : 7;  /**< Reassembly ID map for this LMAC. A shared pool of 96 reassembly IDs (RIDs) exists for all
+                                                         MACs. See description of RIDs in .
+                                                         The RID for this LMAC must be constrained such that it does not overlap with any other MAC
+                                                         in the system. Its reset value has been chosen such that this condition is satisfied:
                                                          RID reset value = 4*(BGX_ID + 1) + LMAC_ID
-                                                         Changes to RID must only occur when the LMAC is quiescent (i.e. the
-                                                         LMAC receive interface is down and the RX fifo is empty)." */
-	uint64_t pknd                         : 8;  /**< Port Kind for this LMAC. */
+                                                         Changes to RID must only occur when the LMAC is quiescent (i.e. the LMAC receive interface
+                                                         is down and the RX FIFO is empty). */
+	uint64_t pknd                         : 8;  /**< Port kind for this LMAC */
 #else
 	uint64_t pknd                         : 8;
 	uint64_t rid                          : 7;
@@ -2219,10 +2243,10 @@ union cvmx_bgxx_cmrx_rx_logl_xoff {
 	struct cvmx_bgxx_cmrx_rx_logl_xoff_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t xoff                         : 16; /**< Together with BGX(0..5)_CMR(0..3)_RX_LOGL_XON defines type of channel backpressure to
-                                                         apply to the SMU.  Do not write when HiGig2 is enabled.
-                                                         Writing 1 sets the same physical register as that which is cleared by XON.
-                                                         An XOFF value of 1 will cause a backpressure on SMU. */
+	uint64_t xoff                         : 16; /**< Together with BGX(0..5)_CMR(0..3)_RX_LOGL_XON, defines type of channel backpressure to
+                                                         apply to the SMU. Do not write when HiGig2 is enabled. Writing 1 sets the same physical
+                                                         register as that which is cleared by XON. An XOFF value of 1 will cause a backpressure on
+                                                         SMU. */
 #else
 	uint64_t xoff                         : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2241,9 +2265,9 @@ union cvmx_bgxx_cmrx_rx_logl_xon {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t xon                          : 16; /**< Together with BGX(0..5)_CMR(0..3)_RX_LOGL_XOFF defines type of channel backpressure to
-                                                         apply.  Do not write when HiGig2 is enabled.
-                                                         Writing 1 clears the same physical register as that which is set by XOFF.
-                                                         An XON value of 1 means only PKI channel BP can cause a backpressure on SMU. */
+                                                         apply. Do not write when HiGig2 is enabled. Writing 1 clears the same physical register as
+                                                         that which is set by XOFF. An XON value of 1 means only PKI channel BP can cause a
+                                                         backpressure on SMU. */
 #else
 	uint64_t xon                          : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2261,7 +2285,7 @@ union cvmx_bgxx_cmrx_rx_pause_drop_time {
 	struct cvmx_bgxx_cmrx_rx_pause_drop_time_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t pause_time                   : 16; /**< Time extracted from the PAUSE packet dropped due to RXB fifo full */
+	uint64_t pause_time                   : 16; /**< Time extracted from the dropped PAUSE packet dropped due to RXB FIFO full or during partner reset */
 #else
 	uint64_t pause_time                   : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2274,20 +2298,19 @@ typedef union cvmx_bgxx_cmrx_rx_pause_drop_time cvmx_bgxx_cmrx_rx_pause_drop_tim
 /**
  * cvmx_bgx#_cmr#_rx_stat0
  *
- * Count of received packets - packets that are:
- * 1. not recognized as PAUSE packets
- * 2. not dropped due the DMAC filtering
- * 3. not dropped due FIFO full status
- * 4. not have have any other OPCODE (FCS, Length, etc).
- * Note: late collision packets (those signaled after eop) will be counted here
- * even though they are dropped by the CMR.
+ * These registers provide a count of received packets that meet the following conditions:
+ * are not recognized as PAUSE packets
+ * are not dropped due DMAC filtering
+ * are not dropped due FIFO full status
+ * do not have any other OPCODE (FCS, Length, etc).
  */
 union cvmx_bgxx_cmrx_rx_stat0 {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_rx_stat0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Count of received packets */
+	uint64_t cnt                          : 48; /**< Count of received packets. CNT will wrap and is cleared if LMAC is disabled with
+                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2300,7 +2323,7 @@ typedef union cvmx_bgxx_cmrx_rx_stat0 cvmx_bgxx_cmrx_rx_stat0_t;
 /**
  * cvmx_bgx#_cmr#_rx_stat1
  *
- * Count of octets of recieved packets, refer to details above in STAT0 definition
+ * These registers provide a count of octets of received packets.
  *
  */
 union cvmx_bgxx_cmrx_rx_stat1 {
@@ -2308,7 +2331,8 @@ union cvmx_bgxx_cmrx_rx_stat1 {
 	struct cvmx_bgxx_cmrx_rx_stat1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Octet count of received packets */
+	uint64_t cnt                          : 48; /**< Octet count of received packets. CNT will wrap and is cleared if LMAC is disabled with
+                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2321,19 +2345,21 @@ typedef union cvmx_bgxx_cmrx_rx_stat1 cvmx_bgxx_cmrx_rx_stat1_t;
 /**
  * cvmx_bgx#_cmr#_rx_stat2
  *
- * Count of all packets received that were recognized as Flow Control or
- * PAUSE packets.  PAUSE packets with any kind of error are counted in
- * BGX_CMR_RX_STAT8(error stats register).  Pause packets
- * will never be counted in BGX_CMR_RX_STAT0. Pause packets dropped due to the dmac
- * filter will be counted in BGX_CMR_RX_STAT4 and not here.  Pause packets dropped due
- * full receive fifo will be counted in BGX_CMR_RX_STAT6 and not here.
+ * These registers provide a count of all packets received that were recognized as flow-control
+ * or PAUSE packets. PAUSE packets with any kind of error are counted in BGX*_CMR*_RX_STAT8
+ * (error stats register) and does not include those reported in BGX(0..5)_CMR(0..3)_RX_STAT6
+ * nor BGX(0..5)_CMR(0..3)_RX_STAT4.
+ * Pause packets can be optionally dropped or forwarded based on
+ * BGX_SMU_RX_FRM_CTL[CTL_DRP]. This count increments regardless of whether the packet is
+ * dropped. PAUSE packets are never counted in BGX*_CMR*_RX_STAT0.
  */
 union cvmx_bgxx_cmrx_rx_stat2 {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_rx_stat2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Count of received pause packets */
+	uint64_t cnt                          : 48; /**< Count of received PAUSE packets. CNT will wrap and is cleared if LMAC is disabled with
+                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2346,7 +2372,7 @@ typedef union cvmx_bgxx_cmrx_rx_stat2 cvmx_bgxx_cmrx_rx_stat2_t;
 /**
  * cvmx_bgx#_cmr#_rx_stat3
  *
- * Count of octets of recieved pause and control packets
+ * These registers provide a count of octets of received PAUSE and control packets.
  *
  */
 union cvmx_bgxx_cmrx_rx_stat3 {
@@ -2354,7 +2380,8 @@ union cvmx_bgxx_cmrx_rx_stat3 {
 	struct cvmx_bgxx_cmrx_rx_stat3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Octet count of received pause packets */
+	uint64_t cnt                          : 48; /**< Octet count of received PAUSE packets. CNT will wrap and is cleared if LMAC is disabled
+                                                         with BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2367,18 +2394,20 @@ typedef union cvmx_bgxx_cmrx_rx_stat3 cvmx_bgxx_cmrx_rx_stat3_t;
 /**
  * cvmx_bgx#_cmr#_rx_stat4
  *
- * Count of all packets received that were dropped by the dmac filter.
- * Packets that match the DMAC will be dropped and counted here regardless
- * of whether they were err packets.  These packets will never be counted in
- * BGX_CMR_RX_STAT0.  DMAC drop packets that are dropped due to full receive fifo
- * will be counted in BGX_CMR_RX_STAT6 and not here.
+ * These registers provide a count of all packets received that were dropped by the DMAC filter.
+ * Packets that match the DMAC are dropped and counted here regardless of whether they were ERR
+ * packets, but does not include those reported in BGX(0..5)_CMR(0..3)_RX_STAT6.
+ * These packets are never counted in BGX*_CMR*_RX_STAT0. Eight-byte packets as the
+ * result of truncation or other means are not be dropped by CN78XX and will never appear in this
+ * count.
  */
 union cvmx_bgxx_cmrx_rx_stat4 {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_rx_stat4_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Count of filtered dmac packets */
+	uint64_t cnt                          : 48; /**< Count of filtered DMAC packets. CNT will wrap and is cleared if LMAC is disabled with
+                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2391,7 +2420,7 @@ typedef union cvmx_bgxx_cmrx_rx_stat4 cvmx_bgxx_cmrx_rx_stat4_t;
 /**
  * cvmx_bgx#_cmr#_rx_stat5
  *
- * Count of octets of filtered dmac packets
+ * These registers provide a count of octets of filtered DMAC packets.
  *
  */
 union cvmx_bgxx_cmrx_rx_stat5 {
@@ -2399,7 +2428,8 @@ union cvmx_bgxx_cmrx_rx_stat5 {
 	struct cvmx_bgxx_cmrx_rx_stat5_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Octet count of filtered dmac packets */
+	uint64_t cnt                          : 48; /**< Octet count of filtered DMAC packets. CNT will wrap and is cleared if LMAC is disabled
+                                                         with BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2412,18 +2442,18 @@ typedef union cvmx_bgxx_cmrx_rx_stat5 cvmx_bgxx_cmrx_rx_stat5_t;
 /**
  * cvmx_bgx#_cmr#_rx_stat6
  *
- * Count of all packets received that were dropped due to a full receive FIFO.
- * It does not count any packet that is truncated at the point at the point of overflow
- * and sent on to the PKI.  This counts all entire packets dropped by the FIFO for a
- * given lmac regardless of whether they are errored, dmac drop packets
- * or control packets
+ * These registers provide a count of all packets received that were dropped due to a full
+ * receive FIFO. They do not count any packet that is truncated at the point at the point of
+ * overflow and sent on to the PKI. These registers count all entire packets dropped by the FIFO
+ * for a given LMAC regardless of DMAC or PAUSE type.
  */
 union cvmx_bgxx_cmrx_rx_stat6 {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_rx_stat6_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Count of dropped packets */
+	uint64_t cnt                          : 48; /**< Count of dropped packets. CNT will wrap and is cleared if LMAC is disabled with
+                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2436,15 +2466,16 @@ typedef union cvmx_bgxx_cmrx_rx_stat6 cvmx_bgxx_cmrx_rx_stat6_t;
 /**
  * cvmx_bgx#_cmr#_rx_stat7
  *
- * Count of octets of packets received that were dropped due to a full receive FIFO.
- *
+ * These registers provide a count of octets of received packets that were dropped due to a full
+ * receive FIFO.
  */
 union cvmx_bgxx_cmrx_rx_stat7 {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_rx_stat7_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Octet count of dropped packets */
+	uint64_t cnt                          : 48; /**< Octet count of dropped packets. CNT will wrap and is cleared if LMAC is disabled with
+                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2457,15 +2488,29 @@ typedef union cvmx_bgxx_cmrx_rx_stat7 cvmx_bgxx_cmrx_rx_stat7_t;
 /**
  * cvmx_bgx#_cmr#_rx_stat8
  *
- * Count of all packets received with some error that were not dropped
- * either due to the dmac filter or lack of room in the receive FIFO.
+ * These registers provide a count of all packets received with some error that were not dropped
+ * either due to the DMAC filter or lack of room in the receive FIFO.
+ * This does not include packets which were counted in
+ * BGX(0..5)_CMR(0..3)_RX_STAT2, BGX(0..5)_CMR(0..3)_RX_STAT4 nor
+ * BGX(0..5)_CMR(0..3)_RX_STAT6 nor BGX(0..5)_CMR(0..3)_RX_STAT8.
+ * Which statistics are updated on errors and drops are shown below:
+ * if dropped [
+ *   if !errored STAT8
+ *   if overflow STAT6
+ *   else if dmac drop STAT4
+ *   else if filter drop STAT2
+ * ] else [
+ *   if errored STAT2
+ *   else STAT8
+ * ]
  */
 union cvmx_bgxx_cmrx_rx_stat8 {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_rx_stat8_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t cnt                          : 48; /**< Count of error packets */
+	uint64_t cnt                          : 48; /**< Count of error packets. CNT will wrap and is cleared if LMAC is disabled with
+                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2483,11 +2528,9 @@ union cvmx_bgxx_cmrx_rx_weight {
 	struct cvmx_bgxx_cmrx_rx_weight_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t weight                       : 4;  /**< For the weighted round robin algorithm in CMR RXB.
-                                                         Weight to assign for this LMAC relative to other
-                                                         LMAC weights. Defaults to round robin(non weighted
-                                                         minimum setting of 1). A setting of 0 effectively
-                                                         takes the lmac out of eligibility. */
+	uint64_t weight                       : 4;  /**< For the weighted round robin algorithm in CMR RXB, weight to assign for this LMAC relative
+                                                         to other LMAC weights. Defaults to round-robin (non-weighted minimum setting of 0x1). A
+                                                         setting of 0x0 effectively takes the LMAC out of eligibility. */
 #else
 	uint64_t weight                       : 4;
 	uint64_t reserved_4_63                : 60;
@@ -2499,27 +2542,18 @@ typedef union cvmx_bgxx_cmrx_rx_weight cvmx_bgxx_cmrx_rx_weight_t;
 
 /**
  * cvmx_bgx#_cmr#_tx_channel
- *
- * "**************************************************************
- * BGX CMR TXB related CSR
- * **************************************************************
- * BGX_CMR_TX_CHANNEL"
  */
 union cvmx_bgxx_cmrx_tx_channel {
 	uint64_t u64;
 	struct cvmx_bgxx_cmrx_tx_channel_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t msk                          : 16; /**< BP channel mask
-                                                         BGX can completely ignore the channel BP for
-                                                         channel specified by the MSK field.  Any channel
-                                                         in which MSK == 1, will never send BP information
-                                                         to PKO. */
-	uint64_t dis                          : 16; /**< Credit Return BP disable
-                                                         BGX stops returning channel credits for any channel
-                                                         that is backpressured.  These bits can be used to
-                                                         override that.  DIS == 1 allows channel credits to
-                                                         flow back regardless of the backpressure for that chan */
+	uint64_t msk                          : 16; /**< Backpressure channel mask. BGX can completely ignore the channel backpressure for channel
+                                                         specified by this field. Any channel in which MSK == 1 never sends backpressure
+                                                         information to PKO. */
+	uint64_t dis                          : 16; /**< Credit return backpressure disable. BGX stops returning channel credits for any channel
+                                                         that is backpressured. These bits can be used to override that. DIS == 1 allows channel
+                                                         credits to flow back regardless of the backpressure for that channel. */
 #else
 	uint64_t dis                          : 16;
 	uint64_t msk                          : 16;
@@ -2539,9 +2573,9 @@ union cvmx_bgxx_cmrx_tx_fifo_len {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
 	uint64_t lmac_idle                    : 1;  /**< Idle signal to identify when all credits and other pipeline buffers are also cleared out
-                                                         and lmac can be considered IDLE in the BGX CMR TX. */
-	uint64_t fifo_len                     : 13; /**< Per lmac TXB main fifo length. Useful for determining if main fifo is empty when bringing
-                                                         an lmac down. */
+                                                         and LMAC can be considered IDLE in the BGX CMR TX. */
+	uint64_t fifo_len                     : 13; /**< Per-LMAC TXB main FIFO length. Useful for determining if main FIFO is empty when bringing
+                                                         an LMAC down. */
 #else
 	uint64_t fifo_len                     : 13;
 	uint64_t lmac_idle                    : 1;
@@ -2560,15 +2594,11 @@ union cvmx_bgxx_cmrx_tx_hg2_status {
 	struct cvmx_bgxx_cmrx_tx_hg2_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t xof                          : 16; /**< 16 bit xof back pressure vector from HiGig2 msg pkt
-                                                         or from PFC/CBFC packets.
-                                                         Non-zero only when logical back pressure is active
-                                                         All bits will be 0 when LGTIM2GO=0 */
-	uint64_t lgtim2go                     : 16; /**< Logical packet flow back pressure time remaining
-                                                         Initial value set from xof time field of HiGig2
-                                                         message packet received or a function of the
-                                                         enabled and current timers for PFC/CBFC packets.
-                                                         Non-zero only when logical back pressure is active */
+	uint64_t xof                          : 16; /**< 16-bit XOF back pressure vector from HiGig2 message packet or from PFC/CBFC packets. Non-
+                                                         zero only when logical back pressure is active. All bits are 0 when LGTIM2GO=0x0. */
+	uint64_t lgtim2go                     : 16; /**< Logical packet flow back pressure time remaining. Initial value set from XOF time field of
+                                                         HiGig2 message packet received or a function of the enabled and current timers for
+                                                         PFC/CBFC packets. Non-zero only when logical back pressure is active. */
 #else
 	uint64_t lgtim2go                     : 16;
 	uint64_t xof                          : 16;
@@ -2587,9 +2617,8 @@ union cvmx_bgxx_cmrx_tx_ovr_bp {
 	struct cvmx_bgxx_cmrx_tx_ovr_bp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t tx_chan_bp                   : 16; /**< Per channel BP sent to PKO
-                                                         0=Channel is available
-                                                         1=Channel should be back pressured */
+	uint64_t tx_chan_bp                   : 16; /**< Per-channel backpressure status sent to PKO.
+                                                         1 = channel should be backpressured, 0 = channel is available */
 #else
 	uint64_t tx_chan_bp                   : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2607,10 +2636,10 @@ union cvmx_bgxx_cmrx_tx_stat0 {
 	struct cvmx_bgxx_cmrx_tx_stat0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t xscol                        : 48; /**< Number of packets dropped (never successfully
-                                                         sent) due to excessive collision.  Defined by
-                                                         BGX_GMP_GMI_TX_COL_ATTEMPT[LIMIT].
-                                                         (SGMII/1000Base-X half-duplex only) */
+	uint64_t xscol                        : 48; /**< Number of packets dropped (never successfully sent) due to excessive collision. Defined by
+                                                         BGX_GMP_GMI_TX_COL_ATTEMPT[LIMIT]. SGMII/1000Base-X half-duplex only.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t xscol                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2628,9 +2657,10 @@ union cvmx_bgxx_cmrx_tx_stat1 {
 	struct cvmx_bgxx_cmrx_tx_stat1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t xsdef                        : 48; /**< Number of packets dropped (never successfully
-                                                         sent) due to excessive deferal
-                                                         (SGMII/1000Base-X half-duplex only) */
+	uint64_t xsdef                        : 48; /**< Number of packets dropped (never successfully sent) due to excessive deferral.
+                                                         SGMII/1000BASE-X half-duplex only.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t xsdef                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2648,8 +2678,12 @@ union cvmx_bgxx_cmrx_tx_stat10 {
 	struct cvmx_bgxx_cmrx_tx_stat10_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t hist4                        : 48; /**< Number of packets sent with an octet count
-                                                         between 256 and 511 inclusive. */
+	uint64_t hist4                        : 48; /**< Number of packets sent with an octet count between 256-511. Packet length is the sum of
+                                                         all data transmitted on the wire for the given packet including packet data, pad bytes,
+                                                         FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or
+                                                         EXTEND cycles.
+                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist4                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2667,8 +2701,12 @@ union cvmx_bgxx_cmrx_tx_stat11 {
 	struct cvmx_bgxx_cmrx_tx_stat11_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t hist5                        : 48; /**< Number of packets sent with an octet count
-                                                         between 512 and 1023 inclusive. */
+	uint64_t hist5                        : 48; /**< Number of packets sent with an octet count between 512-1023. Packet length is the sum of
+                                                         all data transmitted on the wire for the given packet including packet data, pad bytes,
+                                                         FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or
+                                                         EXTEND cycles.
+                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist5                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2686,8 +2724,12 @@ union cvmx_bgxx_cmrx_tx_stat12 {
 	struct cvmx_bgxx_cmrx_tx_stat12_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t hist6                        : 48; /**< Number of packets sent with an octet count
-                                                         between 1024 and 1518 inclusive. */
+	uint64_t hist6                        : 48; /**< Number of packets sent with an octet count between 1024-1518. Packet length is the sum of
+                                                         all data transmitted on the wire for the given packet including packet data, pad bytes,
+                                                         FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or
+                                                         EXTEND cycles.
+                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist6                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2705,8 +2747,12 @@ union cvmx_bgxx_cmrx_tx_stat13 {
 	struct cvmx_bgxx_cmrx_tx_stat13_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t hist7                        : 48; /**< Number of packets sent with an octet count
-                                                         of > 1518. */
+	uint64_t hist7                        : 48; /**< Number of packets sent with an octet count > 1518. Packet length is the sum of all data
+                                                         transmitted on the wire for the given packet including packet data, pad bytes, FCS bytes,
+                                                         PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or EXTEND
+                                                         cycles.
+                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist7                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2724,8 +2770,13 @@ union cvmx_bgxx_cmrx_tx_stat14 {
 	struct cvmx_bgxx_cmrx_tx_stat14_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t bcst                         : 48; /**< Number of packets sent to broadcast DMAC.
-                                                         Does not include MCST packets. */
+	uint64_t bcst                         : 48; /**< Number of packets sent to multicast DMAC. Does not include MCST packets.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap.
+                                                         Note that BGX determines if the packet is MCST or BCST from the DMAC of the packet. BGX
+                                                         assumes that the DMAC lies in the first six bytes of the packet as per the 802.3 frame
+                                                         definition. If the system requires additional data before the L2 header, the MCST and BCST
+                                                         counters may not reflect reality and should be ignored by software. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t bcst                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2743,8 +2794,13 @@ union cvmx_bgxx_cmrx_tx_stat15 {
 	struct cvmx_bgxx_cmrx_tx_stat15_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t mcst                         : 48; /**< Number of packets sent to multicast DMAC.
-                                                         Does not include BCST packets. */
+	uint64_t mcst                         : 48; /**< Number of packets sent to multicast DMAC. Does not include BCST packets.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap.
+                                                         Note that BGX determines if the packet is MCST or BCST from the DMAC of the packet. BGX
+                                                         assumes that the DMAC lies in the first six bytes of the packet as per the 802.3 frame
+                                                         definition. If the system requires additional data before the L2 header, then the MCST and
+                                                         BCST counters may not reflect reality and should be ignored by software. Cleared if LMAC
+                                                         is disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t mcst                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2762,7 +2818,9 @@ union cvmx_bgxx_cmrx_tx_stat16 {
 	struct cvmx_bgxx_cmrx_tx_stat16_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t undflw                       : 48; /**< Number of underflow packets */
+	uint64_t undflw                       : 48; /**< Number of underflow packets.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t undflw                       : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2780,12 +2838,12 @@ union cvmx_bgxx_cmrx_tx_stat17 {
 	struct cvmx_bgxx_cmrx_tx_stat17_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t ctl                          : 48; /**< Number of Control packets (PAUSE flow control)
-                                                         generated by BGX.  It does not include control
-                                                         packets forwarded or generated by the PP's.
-                                                         CTL will count the number of generated PFC frames.
-                                                         CTL will not track the number of generated HG2
-                                                         messages. */
+	uint64_t ctl                          : 48; /**< Number of control packets (PAUSE flow control) generated by BGX. It does not include
+                                                         control packets forwarded or generated by the cores.
+                                                         CTL counts the number of generated PFC frames and does not track the number of generated
+                                                         HG2 messages.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t ctl                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2803,9 +2861,10 @@ union cvmx_bgxx_cmrx_tx_stat2 {
 	struct cvmx_bgxx_cmrx_tx_stat2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t mcol                         : 48; /**< Number of packets sent with multiple collisions
-                                                         but < BGX_GMP_GMI_TX_COL_ATTEMPT[LIMIT].
-                                                         (SGMII/1000Base-X half-duplex only) */
+	uint64_t mcol                         : 48; /**< Number of packets sent with multiple collisions. Must be less than
+                                                         BGX_GMP_GMI_TX_COL_ATTEMPT[LIMIT]. SGMII/1000BASE-X half-duplex only.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t mcol                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2823,8 +2882,9 @@ union cvmx_bgxx_cmrx_tx_stat3 {
 	struct cvmx_bgxx_cmrx_tx_stat3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t scol                         : 48; /**< Number of packets sent with a single collision
-                                                         (SGMII/1000Base-X half-duplex only) */
+	uint64_t scol                         : 48; /**< Number of packets sent with a single collision. SGMII/1000BASE-X half-duplex only.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t scol                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2842,9 +2902,13 @@ union cvmx_bgxx_cmrx_tx_stat4 {
 	struct cvmx_bgxx_cmrx_tx_stat4_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t octs                         : 48; /**< Number of total octets sent on the interface.
-                                                         Does not count octets from frames that were
-                                                         truncated due to collisions in halfdup mode. */
+	uint64_t octs                         : 48; /**< Number of total octets sent on the interface. Does not count octets from frames that were
+                                                         truncated due to collisions in half-duplex mode.
+                                                         Octet counts are the sum of all data transmitted on the wire including packet data, pad
+                                                         bytes, FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE
+                                                         byte or EXTEND cycles.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t octs                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2862,9 +2926,10 @@ union cvmx_bgxx_cmrx_tx_stat5 {
 	struct cvmx_bgxx_cmrx_tx_stat5_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t pkts                         : 48; /**< Number of total frames sent on the interface.
-                                                         Does not count frames that were truncated due to
-                                                         collisions in halfdup mode. */
+	uint64_t pkts                         : 48; /**< Number of total frames sent on the interface. Does not count octets from frames that were
+                                                         truncated due to collisions in half-duplex mode.
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t pkts                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2882,8 +2947,12 @@ union cvmx_bgxx_cmrx_tx_stat6 {
 	struct cvmx_bgxx_cmrx_tx_stat6_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t hist0                        : 48; /**< Number of packets sent with an octet count
-                                                         of < 64. */
+	uint64_t hist0                        : 48; /**< Number of packets sent with an octet count < 64. Packet length is the sum of all data
+                                                         transmitted on the wire for the given packet including packet data, pad bytes, FCS bytes,
+                                                         PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or EXTEND
+                                                         cycles.
+                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist0                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2901,8 +2970,12 @@ union cvmx_bgxx_cmrx_tx_stat7 {
 	struct cvmx_bgxx_cmrx_tx_stat7_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t hist1                        : 48; /**< Number of packets sent with an octet count
-                                                         of 64. */
+	uint64_t hist1                        : 48; /**< Number of packets sent with an octet count of 64. Packet length is the sum of all data
+                                                         transmitted on the wire for the given packet including packet data, pad bytes, FCS bytes,
+                                                         PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or EXTEND
+                                                         cycles.
+                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist1                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2920,8 +2993,12 @@ union cvmx_bgxx_cmrx_tx_stat8 {
 	struct cvmx_bgxx_cmrx_tx_stat8_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t hist2                        : 48; /**< Number of packets sent with an octet count
-                                                         of > 64 and < 128. */
+	uint64_t hist2                        : 48; /**< Number of packets sent with an octet count between 65-127. Packet length is the sum of all
+                                                         data transmitted on the wire for the given packet including packet data, pad bytes, FCS
+                                                         bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or EXTEND
+                                                         cycles.
+                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist2                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2939,8 +3016,12 @@ union cvmx_bgxx_cmrx_tx_stat9 {
 	struct cvmx_bgxx_cmrx_tx_stat9_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t hist3                        : 48; /**< Number of packets sent with an octet count
-                                                         between 128 and 255 inclusive. */
+	uint64_t hist3                        : 48; /**< Number of packets sent with an octet count between 128-255. Packet length is the sum of
+                                                         all data transmitted on the wire for the given packet including packet data, pad bytes,
+                                                         FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or
+                                                         EXTEND cycles.
+                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist3                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2976,33 +3057,24 @@ union cvmx_bgxx_cmr_bist_status {
 	struct cvmx_bgxx_cmr_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
-	uint64_t status                       : 25; /**< "BIST Results.
-                                                          HW sets a bit in BIST for memory that fails. INTERNAL:
-                                                         - 0: bgx#.rxb.infif_gmp
-                                                         - 1: bgx#.rxb.infif_smu
-                                                         - 2: bgx#.rxb.fif_bnk00
-                                                         - 3: bgx#.rxb.fif_bnk01
-                                                         - 4: bgx#.rxb.fif_bnk10
-                                                         - 5: bgx#.rxb.fif_bnk11
-                                                         - 6: bgx#.rxb.skd_fif
-                                                         - 7: bgx#.rxb_mix0_fif
-                                                         - 8: bgx#.rxb_mix1_fif
-                                                         - 9: RAZ
-                                                          - 10: bgx#.txb_fif_bnk0
-                                                          - 11: bgx#.txb_fif_bnk1
-                                                          - 12: bgx#.txb_skd_fif
-                                                          - 13: bgx#.txb_mix0_fif
-                                                          - 14: bgx#.txb_mix1_fif
-                                                          - 15: RAZ
-                                                          - 16: RAZ
-                                                          - 17: RAZ
-                                                          - 18: RAZ
-                                                          - 19: RAZ
-                                                          - 20: RAZ
-                                                          - 21: RAZ
-                                                          - 22: RAZ
-                                                          - 23: RAZ
-                                                          - 24: RAZ" */
+	uint64_t status                       : 25; /**< "BIST results. Hardware sets a bit to 1 for memory that fails; 0 indicates pass or never
+                                                         run. INTERNAL:
+                                                         <0> = bgx#.rxb.infif_gmp
+                                                         <1> = bgx#.rxb.infif_smu
+                                                         <2> = bgx#.rxb.fif_bnk00
+                                                         <3> = bgx#.rxb.fif_bnk01
+                                                         <4> = bgx#.rxb.fif_bnk10
+                                                         <5> = bgx#.rxb.fif_bnk11
+                                                         <6> = bgx#.rxb.skd_fif
+                                                         <7> = bgx#.rxb_mix0_fif
+                                                         <8> = bgx#.rxb_mix1_fif
+                                                         <9> = RAZ
+                                                         <10> = bgx#.txb_fif_bnk0
+                                                         <11> = bgx#.txb_fif_bnk1
+                                                         <12> = bgx#.txb_skd_fif
+                                                         <13> = bgx#.txb_mix0_fif
+                                                         <14> = bgx#.txb_mix1_fif
+                                                         <24:15> = RAZ" */
 #else
 	uint64_t status                       : 25;
 	uint64_t reserved_25_63               : 39;
@@ -3019,17 +3091,16 @@ union cvmx_bgxx_cmr_chan_msk_and {
 	uint64_t u64;
 	struct cvmx_bgxx_cmr_chan_msk_and_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t msk_and                      : 64; /**< Assert physical BP when the BP channel vector
-                                                         combined with MSK_AND indicates BP as follows.
-                                                         phys_bp_msk_and =
-                                                         (CHAN_VECTOR<x:y> & MSK_AND<x:y>) == MSK_AND<x:y>
+	uint64_t msk_and                      : 64; /**< Assert physical backpressure when the backpressure channel vector combined with MSK_AND
+                                                         indicates backpressure as follows:
+                                                         phys_bp_msk_and = (CHAN_VECTOR<x:y> & MSK_AND<x:y>) == MSK_AND<x:y>
                                                          phys_bp = phys_bp_msk_or || phys_bp_msk_and
-                                                         In single LMACS configs, x=63, y=0
-                                                         In multi LMAC configs, x/y are set as follows:
-                                                         LMAC interface0, x=15, y=0
-                                                         LMAC interface1, x=31, y=16
-                                                         LMAC interface2, x=47, y=32
-                                                         LMAC interface3, x=63, y=48 */
+                                                         In single LMAC configurations, x = 63, y = 0
+                                                         In multi-LMAC configurations, x/y are set as follows:
+                                                         LMAC interface 0, x = 15, y = 0
+                                                         LMAC interface 1, x = 31, y = 16
+                                                         LMAC interface 2, x = 47, y = 32
+                                                         LMAC interface 3, x = 63, y = 48 */
 #else
 	uint64_t msk_and                      : 64;
 #endif
@@ -3045,17 +3116,16 @@ union cvmx_bgxx_cmr_chan_msk_or {
 	uint64_t u64;
 	struct cvmx_bgxx_cmr_chan_msk_or_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t msk_or                       : 64; /**< Assert physical BP when the BP channel vector
-                                                         combined with MSK_OR indicates BP as follows.
-                                                         phys_bp_msk_or =
-                                                         (CHAN_VECTOR<x:y> & MSK_OR<x:y>) != 0
+	uint64_t msk_or                       : 64; /**< Assert physical backpressure when the backpressure channel vector combined with MSK_OR
+                                                         indicates backpressure as follows:
+                                                         phys_bp_msk_or = (CHAN_VECTOR<x:y> & MSK_OR<x:y>) & MSK_OR<x:y>
                                                          phys_bp = phys_bp_msk_or || phys_bp_msk_and
-                                                         In single LMAC config, x=63, y=0
-                                                         In multi LMAC config, x/y are set as follows:
-                                                         LMAC interface0, x=15, y=0
-                                                         LMAC interface1, x=31, y=16
-                                                         LMAC interface2, x=47, y=32
-                                                         LMAC interface3, x=63, y=48 */
+                                                         In single LMAC configurations, x = 63, y = 0
+                                                         In multi-LMAC configurations, x/y are set as follows:
+                                                         LMAC interface 0, x = 15, y = 0
+                                                         LMAC interface 1, x = 31, y = 16
+                                                         LMAC interface 2, x = 47, y = 32
+                                                         LMAC interface 3, x = 63, y = 48 */
 #else
 	uint64_t msk_or                       : 64;
 #endif
@@ -3067,38 +3137,45 @@ typedef union cvmx_bgxx_cmr_chan_msk_or cvmx_bgxx_cmr_chan_msk_or_t;
 /**
  * cvmx_bgx#_cmr_global_config
  *
- * "***************************************************************
- * BGX Global related CSR (affects all lmacs and may be sent to any of GMP, SMU, SPU)
- * ***************************************************************
- * Global CMR, PCS and MAC Configuration"
+ * These registers configures the global CMR, PCS, and MAC.
+ *
  */
 union cvmx_bgxx_cmr_global_config {
 	uint64_t u64;
 	struct cvmx_bgxx_cmr_global_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t cmr_mix1_reset               : 1;  /**< If the MIX1 block is reset, software also needs to reset the the MIX interface in the BGX
-                                                         by setting this bit to 1. It resets the MIX interface state in the BGX (mix FIFO and
-                                                         pending requests to MIX) and prevents the RXB FIFOs for all LMACs from pushing data
-                                                         to the interface. Setting this bit to 0 will not reset the MIX interface.
-                                                         After MIX comes out of reset, software should clear CMR_MIX_RESET. */
-	uint64_t cmr_mix0_reset               : 1;  /**< If the MIX0 block is reset, software also needs to reset the the MIX interface in the BGX
-                                                         by setting this bit to 1. It resets the MIX interface state in the BGX (mix FIFO and
-                                                         pending requests to MIX) and prevents the RXB FIFOs for all LMACs from pushing data
-                                                         to the interface. Setting this bit to 0 will not reset the MIX interface.
-                                                         After MIX comes out of reset, software should clear CMR_MIX_RESET. */
-	uint64_t cmr_x2p_reset                : 1;  /**< If the PKI block is reset, software also needs to reset the the X2P interface in the BGX
-                                                         by setting this bit to 1. It resets the X2P interface state in the BGX (skid FIFO and
-                                                         pending requests to PKI) and prevents the RXB FIFOs for all LMACs from pushing data
-                                                         to the interface. Setting this bit to 0 will not reset the X2P interface.
-                                                         After PKI comes out of reset, software should clear CMR_X2P_RESET. */
-	uint64_t bgx_clk_enable               : 1;  /**< The global clock enable for BGX.  Setting this bit will override clock enables set by the
-                                                         BGX_CMR_CONFIG[ENABLE] and BGX_CMR_CONFIG[LMAC_TYPE] register bits, essentially
-                                                         turning on clocks for the entire BGX.  Setting this bit to 0 will result in
-                                                         not overriding clock enables set by BGX_CMR_CONFIG[ENABLE] and
-                                                         BGX_CMR_CONFIG[LMAC_TYPE] register bits. */
-	uint64_t pmux_sds_sel                 : 1;  /**< The global serdes output select for BGX.  Setting this bit to 1 will select serdes output
-                                                         1 Setting this bit to 1 will select serdes output 0. */
+	uint64_t cmr_mix1_reset               : 1;  /**< If the MIX1 block is reset, software also needs to reset the MIX interface in the BGX by
+                                                         setting this bit to 1. It resets the MIX interface state in the BGX (mix FIFO and pending
+                                                         requests to MIX) and prevents the RXB FIFOs for all LMACs from pushing data to the
+                                                         interface. Setting this bit to 0 will not reset the MIX interface. After MIX comes out of
+                                                         reset, software should clear CMR_MIX_RESET. */
+	uint64_t cmr_mix0_reset               : 1;  /**< If the MIX0 block is reset, software also needs to reset the MIX interface in the BGX by
+                                                         setting this bit to 1. It resets the MIX interface state in the BGX (mix FIFO and pending
+                                                         requests to MIX) and prevents the RXB FIFOs for all LMACs from pushing data to the
+                                                         interface. Setting this bit to 0 will not reset the MIX interface. After MIX comes out of
+                                                         reset, software should clear CMR_MIX_RESET. */
+	uint64_t cmr_x2p_reset                : 1;  /**< If the PKI block is reset, software also needs to reset the X2P interface in the BGX by
+                                                         setting this bit to 1. It resets the X2P interface state in the BGX (skid FIFO and pending
+                                                         requests to PKI) and prevents the RXB FIFOs for all LMACs from pushing data to the
+                                                         interface. Setting this bit to 0 does not reset the X2P interface. After PKI comes out of
+                                                         reset, software should clear CMR_X2P_RESET. */
+	uint64_t bgx_clk_enable               : 1;  /**< The global clock enable for BGX. Setting this bit overrides clock enables set by
+                                                         BGX_CMR_CONFIG[ENABLE] and BGX_CMR_CONFIG[LMAC_TYPE], essentially turning on clocks for
+                                                         the entire BGX. Setting this bit to 0 results in not overriding clock enables set by
+                                                         BGX_CMR_CONFIG[ENABLE] and BGX_CMR_CONFIG[LMAC_TYPE]. */
+	uint64_t pmux_sds_sel                 : 1;  /**< Serdes/QLM output select. Specifies which QLM output is selected as the BGX input, as
+                                                         follows:
+                                                           ------+----------------+----------------
+                                                           Block | PMUX_SDS_SEL=0 | PMUX_SDS_SEL=1
+                                                           ------+----------------+----------------
+                                                           BGX0  | QLM0           | QLM2
+                                                           BGX1  | QLM1           | QLM3
+                                                           BGX2  | QLM4           | N/A
+                                                           BGX3  | QLM5           | N/A
+                                                           BGX4  | QLM6           | N/A
+                                                           BGX5  | QLM7           | N/A
+                                                           ------+----------------+---------------- */
 #else
 	uint64_t pmux_sds_sel                 : 1;
 	uint64_t bgx_clk_enable               : 1;
@@ -3120,22 +3197,22 @@ union cvmx_bgxx_cmr_mem_ctrl {
 	struct cvmx_bgxx_cmr_mem_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_24_63               : 40;
-	uint64_t txb_skid_synd                : 2;  /**< Syndrom to flip and generate 1-bit/2-bits error for RXB SKID FIFO */
-	uint64_t txb_skid_cor_dis             : 1;  /**< ECC correction disable for the RXB SKID FIFO */
-	uint64_t txb_fif_bk1_syn              : 2;  /**< Syndrom to flip and generate 1-bit/2-bits error for TXB main Bank1 */
-	uint64_t txb_fif_bk1_cdis             : 1;  /**< ECC corr disable for the TXB main Bank1 */
-	uint64_t txb_fif_bk0_syn              : 2;  /**< Syndrom to flip and generate 1-bit/2-bits error for TXB main Bank0 */
-	uint64_t txb_fif_bk0_cdis             : 1;  /**< ECC corr disable for the TXB main Bank0 */
-	uint64_t rxb_skid_synd                : 2;  /**< Syndrom to flip and generate 1-bit/2-bits error for RXB SKID FIFO */
-	uint64_t rxb_skid_cor_dis             : 1;  /**< ECC correction disable for the RXB SKID FIFO */
-	uint64_t rxb_fif_bk1_syn1             : 2;  /**< Syndrom to flip and generate 1-bit/2-bits error for RXB main Bank1 srf1 */
-	uint64_t rxb_fif_bk1_cdis1            : 1;  /**< ECC corr disable for the RXB main Bank1 srf1 */
-	uint64_t rxb_fif_bk1_syn0             : 2;  /**< Syndrom to flip and generate 1-bit/2-bits error for RXB main Bank1 srf0 */
-	uint64_t rxb_fif_bk1_cdis0            : 1;  /**< ECC corr disable for the RXB main Bank1 srf0 */
-	uint64_t rxb_fif_bk0_syn1             : 2;  /**< Syndrom to flip and generate 1-bit/2-bits error for RXB main Bank0 srf1 */
-	uint64_t rxb_fif_bk0_cdis1            : 1;  /**< ECC corr disable for the RXB main Bank0 srf1 */
-	uint64_t rxb_fif_bk0_syn0             : 2;  /**< Syndrom to flip and generate 1-bit/2-bits error for RXB main Bank0 srf0 */
-	uint64_t rxb_fif_bk0_cdis0            : 1;  /**< ECC corr disable for the RXB main Bank0 srf0 */
+	uint64_t txb_skid_synd                : 2;  /**< Syndrome to flip and generate single-bit/double-bit for TXB SKID FIFO */
+	uint64_t txb_skid_cor_dis             : 1;  /**< ECC-correction disable for the TXB SKID FIFO */
+	uint64_t txb_fif_bk1_syn              : 2;  /**< Syndrome to flip and generate single-bit/double-bit error for TXB main bank1 */
+	uint64_t txb_fif_bk1_cdis             : 1;  /**< ECC-correction disable for the TXB main bank1 */
+	uint64_t txb_fif_bk0_syn              : 2;  /**< Syndrome to flip and generate single-bit/double-bit error for TXB main bank0 */
+	uint64_t txb_fif_bk0_cdis             : 1;  /**< ECC-correction disable for the TXB main bank0 */
+	uint64_t rxb_skid_synd                : 2;  /**< Syndrome to flip and generate single-bit/double-bit error for RXB SKID FIFO */
+	uint64_t rxb_skid_cor_dis             : 1;  /**< ECC-correction disable for the RXB SKID FIFO */
+	uint64_t rxb_fif_bk1_syn1             : 2;  /**< Syndrome to flip and generate single-bit/double-bit error for RXB main bank1 srf1 */
+	uint64_t rxb_fif_bk1_cdis1            : 1;  /**< ECC-correction disable for the RXB main bank1 srf1 */
+	uint64_t rxb_fif_bk1_syn0             : 2;  /**< Syndrome to flip and generate single-bit/double-bit error for RXB main bank1 srf0 */
+	uint64_t rxb_fif_bk1_cdis0            : 1;  /**< ECC-correction disable for the RXB main bank1 srf0. */
+	uint64_t rxb_fif_bk0_syn1             : 2;  /**< Syndrome to flip and generate single-bit/double-bit error for RXB main bank0 srf1 */
+	uint64_t rxb_fif_bk0_cdis1            : 1;  /**< ECC-correction disable for the RXB main bank0 srf1 */
+	uint64_t rxb_fif_bk0_syn0             : 2;  /**< Syndrome to flip and generate single-bit/double-bit error for RXB main bank0 srf0 */
+	uint64_t rxb_fif_bk0_cdis0            : 1;  /**< ECC-correction disable for the RXB main bank0 srf0 */
 #else
 	uint64_t rxb_fif_bk0_cdis0            : 1;
 	uint64_t rxb_fif_bk0_syn0             : 2;
@@ -3162,35 +3239,30 @@ typedef union cvmx_bgxx_cmr_mem_ctrl cvmx_bgxx_cmr_mem_ctrl_t;
 
 /**
  * cvmx_bgx#_cmr_mem_int
- *
- * "***************************************************************************************
- * BGX CMR related CSR starting here with interrupts, then later RX and TX side registers
- * ***************************************************************************************
- * BGX_CMR_MEM_INT = Memory Interrupt Register"
  */
 union cvmx_bgxx_cmr_mem_int {
 	uint64_t u64;
 	struct cvmx_bgxx_cmr_mem_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
-	uint64_t smu_in_overfl                : 1;  /**< RX SMU INFIFO Overflow */
-	uint64_t gmp_in_overfl                : 1;  /**< RX GMP INFIFO Overflow */
-	uint64_t txb_skid_sbe                 : 1;  /**< TXB SKID FIFO single bit error */
-	uint64_t txb_skid_dbe                 : 1;  /**< TXB SKID FIFO double bit error */
-	uint64_t txb_fif_bk1_sbe              : 1;  /**< TXB Main FIFO Bank1 single bit error */
-	uint64_t txb_fif_bk1_dbe              : 1;  /**< TXB Main FIFO Bank1 double bit error */
-	uint64_t txb_fif_bk0_sbe              : 1;  /**< TXB Main FIFO Bank0 single bit error */
-	uint64_t txb_fif_bk0_dbe              : 1;  /**< TXB Main FIFO Bank0 double bit error */
-	uint64_t rxb_skid_sbe                 : 1;  /**< RXB SKID FIFO single bit error */
-	uint64_t rxb_skid_dbe                 : 1;  /**< RXB SKID FIFO double bit error */
-	uint64_t rxb_fif_bk1_sbe1             : 1;  /**< RXB Main FIFO Bank1 srf1 single bit error */
-	uint64_t rxb_fif_bk1_dbe1             : 1;  /**< RXB Main FIFO Bank1 srf1 double bit error */
-	uint64_t rxb_fif_bk1_sbe0             : 1;  /**< RXB Main FIFO Bank1 srf0 single bit error */
-	uint64_t rxb_fif_bk1_dbe0             : 1;  /**< RXB Main FIFO Bank1 srf0 double bit error */
-	uint64_t rxb_fif_bk0_sbe1             : 1;  /**< RXB Main FIFO Bank0 srf1 single bit error */
-	uint64_t rxb_fif_bk0_dbe1             : 1;  /**< RXB Main FIFO Bank0 srf1 double bit error */
-	uint64_t rxb_fif_bk0_sbe0             : 1;  /**< RXB Main FIFO Bank0 srf0 single bit error */
-	uint64_t rxb_fif_bk0_dbe0             : 1;  /**< RXB Main FIFO Bank0 srf0 double bit error */
+	uint64_t smu_in_overfl                : 1;  /**< RX SMU INFIFO overflow */
+	uint64_t gmp_in_overfl                : 1;  /**< RX GMP INFIFO overflow */
+	uint64_t txb_skid_sbe                 : 1;  /**< TXB SKID FIFO single-bit error */
+	uint64_t txb_skid_dbe                 : 1;  /**< TXB SKID FIFO double-bit error */
+	uint64_t txb_fif_bk1_sbe              : 1;  /**< TXB Main FIFO Bank1 single-bit error */
+	uint64_t txb_fif_bk1_dbe              : 1;  /**< TXB Main FIFO Bank1 double-bit error */
+	uint64_t txb_fif_bk0_sbe              : 1;  /**< TXB Main FIFO Bank0 single-bit error */
+	uint64_t txb_fif_bk0_dbe              : 1;  /**< TXB Main FIFO Bank0 double-bit error */
+	uint64_t rxb_skid_sbe                 : 1;  /**< RXB SKID FIFO single-bit error */
+	uint64_t rxb_skid_dbe                 : 1;  /**< RXB SKID FIFO double-bit error */
+	uint64_t rxb_fif_bk1_sbe1             : 1;  /**< RXB main FIFO bank1 srf1 single-bit error */
+	uint64_t rxb_fif_bk1_dbe1             : 1;  /**< RXB main FIFO bank1 srf1 double-bit error */
+	uint64_t rxb_fif_bk1_sbe0             : 1;  /**< RXB main FIFO bank1 srf0 single-bit error */
+	uint64_t rxb_fif_bk1_dbe0             : 1;  /**< RXB main FIFO bank1 srf0 double-bit error */
+	uint64_t rxb_fif_bk0_sbe1             : 1;  /**< RXB main FIFO bank0 srf1 single-bit error */
+	uint64_t rxb_fif_bk0_dbe1             : 1;  /**< RXB main FIFO bank0 srf1 double-bit error */
+	uint64_t rxb_fif_bk0_sbe0             : 1;  /**< RXB main FIFO bank0 srf0 single-bit error */
+	uint64_t rxb_fif_bk0_dbe0             : 1;  /**< RXB main FIFO bank0 srf0 double-bit error */
 #else
 	uint64_t rxb_fif_bk0_dbe0             : 1;
 	uint64_t rxb_fif_bk0_sbe0             : 1;
@@ -3224,13 +3296,13 @@ union cvmx_bgxx_cmr_nxc_adr {
 	uint64_t u64;
 	struct cvmx_bgxx_cmr_nxc_adr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_14_63               : 50;
-	uint64_t lmac_id                      : 2;  /**< Logged LMAC_ID associated with NXC exceptions */
+	uint64_t reserved_16_63               : 48;
+	uint64_t lmac_id                      : 4;  /**< Logged LMAC ID associated with NXC exceptions */
 	uint64_t channel                      : 12; /**< Logged channel for NXC exceptions */
 #else
 	uint64_t channel                      : 12;
-	uint64_t lmac_id                      : 2;
-	uint64_t reserved_14_63               : 50;
+	uint64_t lmac_id                      : 4;
+	uint64_t reserved_16_63               : 48;
 #endif
 	} s;
 	struct cvmx_bgxx_cmr_nxc_adr_s        cn78xx;
@@ -3240,40 +3312,30 @@ typedef union cvmx_bgxx_cmr_nxc_adr cvmx_bgxx_cmr_nxc_adr_t;
 /**
  * cvmx_bgx#_cmr_rx_adr#_cam
  *
- * "**************************************************************
- * Following regs are not per lane but shared in the BGX CMR RXB
- * **************************************************************
- * BGX_CMR_RX_ADR_CAM = Address Filtering CAM"
+ * These registers provide access to the 32 DMAC CAM entries in BGX.
+ *
  */
 union cvmx_bgxx_cmr_rx_adrx_cam {
 	uint64_t u64;
 	struct cvmx_bgxx_cmr_rx_adrx_cam_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_54_63               : 10;
-	uint64_t id                           : 2;  /**< Logical Mac ID this DMAC CAM address will apply to
-                                                         BGX has 32 DMAC CAM entries that can be accessed
-                                                         with the BGX_CMR_RX_ADR_CAM[0..31] CSRs.
-                                                         These 32 DMAC entries can be used by any of the
-                                                         four SGMII MACs or the 10G/40G MACs using the
-                                                         these register bits. A typical configuration is to
-                                                         provide 8 CAM entries per lmac id which is
-                                                         configured using the following settings:
-                                                         lmac0 BGX_CMR_RX_ADR_CAM[0..7] ID= 2'b00
-                                                         lmac1 BGX_CMR_RX_ADR_CAM[8..15] ID= 2'b01
-                                                         lmac2 BGX_CMR_RX_ADR_CAM[16..23] ID= 2'b10
-                                                         lmac3 BGX_CMR_RX_ADR_CAM[24..31] ID= 2'b11 */
+	uint64_t id                           : 2;  /**< Logical MAC ID that this DMAC CAM address applies to. BGX has 32 DMAC CAM entries that can
+                                                         be accessed with the BGX*_CMR_RX_ADR_CAM(0..31) CSRs. These 32 DMAC entries can be used by
+                                                         any of the four SGMII MACs or the 10G/40G MACs using these register bits.
+                                                         A typical configuration is to provide eight CAM entries per LMAC ID, which is configured
+                                                         using the following settings:
+                                                         LMAC interface 0: BGX(0..5)_CMR_RX_ADR(0..7)_CAM[ID] = 0x0
+                                                         LMAC interface 1: BGX(0..5)_CMR_RX_ADR(8..15)_CAM[ID] = 0x1
+                                                         LMAC interface 2: BGX(0..5)_CMR_RX_ADR(16..23)_CAM[ID] = 0x2
+                                                         LMAC interface 3: BGX(0..5)_CMR_RX_ADR(24..31)_CAM[ID] = 0x3 */
 	uint64_t reserved_49_51               : 3;
-	uint64_t en                           : 1;  /**< CAM Entry Enable for this DMAC Address
-                                                         A value of 1 means include this address in the
-                                                         matching algorithm
-                                                         A value of 0 means dont include this address in
-                                                         matching algorigthm */
-	uint64_t adr                          : 48; /**< DMAC address in the CAM used for matching
-                                                         The CAM matches against unicast or multicast DMAC
-                                                         addresses.
-                                                         ALL BGX_CMR_RX_ADR_CAM[0..31] CSRs may be used
-                                                         in any of the LMAC_TYPE combinations such that any BGX
-                                                         MAC can use any of the 32 common DMAC entries. */
+	uint64_t en                           : 1;  /**< CAM entry enable for this DMAC address.
+                                                         1 = Include this address in the matching algorithm.
+                                                         0 = Don't include this address in the matching algorithm. */
+	uint64_t adr                          : 48; /**< DMAC address in the CAM used for matching. The CAM matches against unicast or multicast
+                                                         DMAC addresses. All BGX*_CMR_RX_ADR_CAM(0..31) CSRs can be used in any of the LMAC_TYPE
+                                                         combinations such that any BGX MAC can use any of the 32 common DMAC entries. */
 #else
 	uint64_t adr                          : 48;
 	uint64_t en                           : 1;
@@ -3297,17 +3359,17 @@ union cvmx_bgxx_cmr_rx_lmacs {
 	uint64_t lmacs                        : 3;  /**< "Number of LMACS: Specifies the number of LMACs that can be enabled.
                                                          This determines the logical RX buffer size per LMAC and the maximum
                                                          LMAC ID that can be used:
-                                                         ----------+---------------------------------------------------
-                                                         LMACS     |   RX buffer           Maximum
-                                                                   |   size per LMAC       LMAC ID
-                                                         ----------+---------------------------------------------------
-                                                         0         |   reserved
-                                                         1         |   64KB                0
-                                                         2         |   32KB                1
-                                                         3         |   16KB                2
-                                                         4         |   16KB                3
-                                                         5-7       |   reserved
-                                                         ----------+---------------------------------------------------
+                                                           ----------+---------------------------------------------------
+                                                           LMACS     |   RX buffer           Maximum
+                                                                         size per LMAC       LMAC ID
+                                                           ----------+---------------------------------------------------
+                                                           0         |   reserved
+                                                           1         |   64KB                0
+                                                           2         |   32KB                1
+                                                           3         |   16KB                2
+                                                           4         |   16KB                3
+                                                           5-7       |   reserved
+                                                           ----------+---------------------------------------------------
                                                          Note: The maximum LMAC ID is determined by the smaller of
                                                          BGX_CMR_RX_LMACS[LMACS] and BGX_CMR_TX_LMACS[LMACS]. The two fields
                                                          should be set to the same value for normal operation." */
@@ -3322,18 +3384,27 @@ typedef union cvmx_bgxx_cmr_rx_lmacs cvmx_bgxx_cmr_rx_lmacs_t;
 
 /**
  * cvmx_bgx#_cmr_rx_ovr_bp
+ *
+ * BGX_CMR_RX_OVR_BP[EN<0>] must be set to one and BGX_CMR_RX_OVR_BP[BP<0>] must be cleared to
+ * zero (to forcibly disable hardware-automatic 802.3 PAUSE packet generation) with the HiGig2
+ * Protocol when BGX_SMU_HG2_CONTROL[HG2TX_EN]=0. (The HiGig2 protocol is indicated by
+ * BGX_SMU_TX_CTL[HG_EN]=1 and BGX_SMU_RX_UDD_SKP[LEN]=16). Hardware can only auto-generate
+ * backpressure through HiGig2 messages (optionally, when BGX_SMU_HG2_CONTROL[HG2TX_EN]=1) with
+ * the HiGig2 protocol.
  */
 union cvmx_bgxx_cmr_rx_ovr_bp {
 	uint64_t u64;
 	struct cvmx_bgxx_cmr_rx_ovr_bp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t en                           : 4;  /**< Per lmac Enable back pressure override */
-	uint64_t bp                           : 4;  /**< Per lmac BackPressure status to use
-                                                         0=lmac is available
-                                                         1=lmac should be back pressured */
-	uint64_t ign_fifo_bp                  : 4;  /**< Ignore the RX FIFO BP_ON signal when computing BP.
-                                                         CMR will not backpressure the mac due to the fifo length passing BP_ON mark. */
+	uint64_t en                           : 4;  /**< Per-LMAC enable backpressure override.
+                                                         1 = Enable override, 0 = Don't enable
+                                                         Bit<8> represents LMAC 0, ..., bit<11> represents LMAC 3. */
+	uint64_t bp                           : 4;  /**< Per-LMAC backpressure status to use:
+                                                         1 = LMAC should be backpressured, 0 = LMAC is available
+                                                         Bit<4> represents LMAC 0, ..., bit<7> represents LMAC 3. */
+	uint64_t ign_fifo_bp                  : 4;  /**< Ignore the RX FIFO BP_ON signal when computing backpressure. CMR does not backpressure the
+                                                         MAC due to the FIFO length passing BP_ON mark. */
 #else
 	uint64_t ign_fifo_bp                  : 4;
 	uint64_t bp                           : 4;
@@ -3348,10 +3419,8 @@ typedef union cvmx_bgxx_cmr_rx_ovr_bp cvmx_bgxx_cmr_rx_ovr_bp_t;
 /**
  * cvmx_bgx#_cmr_tx_lmacs
  *
- * "**************************************************************
- * Following regs are not per lane but shared in the BGX CMR TXB
- * **************************************************************
- * BGX_CMR_TX_LMACS = Number of TX lmacs"
+ * Number of transmit LMACs.
+ *
  */
 union cvmx_bgxx_cmr_tx_lmacs {
 	uint64_t u64;
@@ -3361,17 +3430,17 @@ union cvmx_bgxx_cmr_tx_lmacs {
 	uint64_t lmacs                        : 3;  /**< "Number of LMACS: Specifies the number of LMACs that can be enabled.
                                                          This determines the logical TX buffer size per LMAC and the maximum
                                                          LMAC ID that can be used:
-                                                         ----------+---------------------------------------------------
-                                                         LMACS     |   TX buffer           Maximum
-                                                                   |   size per LMAC       LMAC ID
-                                                         ----------+---------------------------------------------------
-                                                         0         |   reserved
-                                                         1         |   32KB                0
-                                                         2         |   16KB                1
-                                                         3         |   8KB                 2
-                                                         4         |   8KB                 3
-                                                         5-7       |   reserved
-                                                         ----------+---------------------------------------------------
+                                                           ----------+---------------------------------------------------
+                                                           LMACS     |   TX buffer           Maximum
+                                                                         size per LMAC       LMAC ID
+                                                           ----------+---------------------------------------------------
+                                                           0         |   reserved
+                                                           1         |   32KB                0
+                                                           2         |   16KB                1
+                                                           3         |   8KB                 2
+                                                           4         |   8KB                 3
+                                                           5-7       |   reserved
+                                                           ----------+---------------------------------------------------
                                                          Note: The maximum LMAC ID is determined by the smaller of
                                                          BGX_CMR_RX_LMACS[LMACS] and BGX_CMR_TX_LMACS[LMACS]. The two fields
                                                          should be set to the same value for normal operation." */
@@ -3386,34 +3455,36 @@ typedef union cvmx_bgxx_cmr_tx_lmacs cvmx_bgxx_cmr_tx_lmacs_t;
 
 /**
  * cvmx_bgx#_gmp_gmi_prt#_cfg
+ *
+ * This register controls the configuration of the LMAC.
+ *
  */
 union cvmx_bgxx_gmp_gmi_prtx_cfg {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_prtx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t tx_idle                      : 1;  /**< TX Machine is idle */
-	uint64_t rx_idle                      : 1;  /**< RX Machine is idle */
+	uint64_t tx_idle                      : 1;  /**< TX machine is idle. */
+	uint64_t rx_idle                      : 1;  /**< RX machine is idle. */
 	uint64_t reserved_9_11                : 3;
-	uint64_t speed_msb                    : 1;  /**< Link Speed MSB [SPEED_MSB:SPEED]
-                                                         10 = 10Mbs operation
-                                                         00 = 100Mbs operation
-                                                         01 = 1000Mbs operation
+	uint64_t speed_msb                    : 1;  /**< Link speed MSB [SPEED_MSB:SPEED]
+                                                         10 = 10 Mb/s operation
+                                                         00 = 100 Mb/s operation
+                                                         01 = 1000 Mb/s operation
                                                          11 = Reserved
                                                          (SGMII/1000Base-X only) */
 	uint64_t reserved_4_7                 : 4;
-	uint64_t slottime                     : 1;  /**< Slot Time for Half-Duplex operation
-                                                         0 = 512 bitimes (10/100Mbs operation)
-                                                         1 = 4096 bitimes (1000Mbs operation)
+	uint64_t slottime                     : 1;  /**< Slot time for half-duplex operation
+                                                         0 = 512 bit times (10/100 Mb/s operation)
+                                                         1 = 4096 bit times (1000 Mb/s operation)
                                                          (SGMII/1000Base-X only) */
-	uint64_t duplex                       : 1;  /**< Duplex
-                                                         0 = Half Duplex (collisions/extentions/bursts)
-                                                         1 = Full Duplex
+	uint64_t duplex                       : 1;  /**< Duplex mode:
+                                                         0 = half-duplex (collisions/extensions/bursts), 1 = full-duplex.
                                                          (SGMII/1000Base-X only) */
 	uint64_t speed                        : 1;  /**< Link Speed LSB [SPEED_MSB:SPEED]
-                                                         10 = 10Mbs operation
-                                                         00 = 100Mbs operation
-                                                         01 = 1000Mbs operation
+                                                         10 = 10 Mb/s operation
+                                                         00 = 100 Mb/s operation
+                                                         01 = 1000 Mb/s operation
                                                          11 = Reserved
                                                          (SGMII/1000Base-X only) */
 	uint64_t reserved_0_0                 : 1;
@@ -3438,7 +3509,7 @@ typedef union cvmx_bgxx_gmp_gmi_prtx_cfg cvmx_bgxx_gmp_gmi_prtx_cfg_t;
  * cvmx_bgx#_gmp_gmi_rx#_decision
  *
  * Notes:
- * As each byte in a packet is received by GMX, the L2 byte count is compared
+ * As each byte in a packet is received by GMI, the L2 byte count is compared
  * against the BGX_GMP_GMI_RX_DECISION[CNT].  The L2 byte count is the number of bytes
  * from the beginning of the L2 header (DMAC).  In normal operation, the L2
  * header begins after the PREAMBLE+SFD (BGX_GMP_GMI_RX_FRM_CTL[PRE_CHK]=1) and any
@@ -3461,8 +3532,7 @@ union cvmx_bgxx_gmp_gmi_rxx_decision {
 	struct cvmx_bgxx_gmp_gmi_rxx_decision_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t cnt                          : 5;  /**< The byte count to decide when to accept or filter
-                                                         a packet. */
+	uint64_t cnt                          : 5;  /**< The byte count used to decide when to accept or filter a packet. Refer to GMI Decisions. */
 #else
 	uint64_t cnt                          : 5;
 	uint64_t reserved_5_63                : 59;
@@ -3474,25 +3544,20 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_decision cvmx_bgxx_gmp_gmi_rxx_decision_t;
 
 /**
  * cvmx_bgx#_gmp_gmi_rx#_frm_chk
- *
- * Notes:
- * If BGX_GMP_GMI_RX_UDD_SKP[LEN] != 0, then LENERR will be forced to zero in HW.
- * BGX_GMP_GMI_RX_FRM_CHK = Which frame errors will set the ERR bit of the frame
  */
 union cvmx_bgxx_gmp_gmi_rxx_frm_chk {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_rxx_frm_chk_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t skperr                       : 1;  /**< Skipper error */
-	uint64_t rcverr                       : 1;  /**< Frame was received with Data reception error */
+	uint64_t skperr                       : 1;  /**< Skipper error. */
+	uint64_t rcverr                       : 1;  /**< Frame was received with data-reception error. */
 	uint64_t reserved_5_6                 : 2;
-	uint64_t fcserr                       : 1;  /**< Frame was received with FCS/CRC error */
-	uint64_t jabber                       : 1;  /**< Frame was received with length > sys_length */
+	uint64_t fcserr                       : 1;  /**< Frame was received with FCS/CRC error. */
+	uint64_t jabber                       : 1;  /**< Frame was received with length > sys_length. */
 	uint64_t reserved_2_2                 : 1;
-	uint64_t carext                       : 1;  /**< Carrier extend error
-                                                         (SGMII/1000Base-X only) */
-	uint64_t minerr                       : 1;  /**< Pause Frame was received with length<minFrameSize */
+	uint64_t carext                       : 1;  /**< Carrier extend error. SGMII/1000Base-X only. */
+	uint64_t minerr                       : 1;  /**< PAUSE frame was received with length < minFrameSize. */
 #else
 	uint64_t minerr                       : 1;
 	uint64_t carext                       : 1;
@@ -3537,61 +3602,51 @@ union cvmx_bgxx_gmp_gmi_rxx_frm_ctl {
 	struct cvmx_bgxx_gmp_gmi_rxx_frm_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t ptp_mode                     : 1;  /**< Timestamp mode
-                                                         When PTP_MODE is set, a 64-bit timestamp will be
-                                                         prepended to every incoming packet. The timestamp
-                                                         bytes are added to the packet in such a way as to
-                                                         not modify the packet's receive byte count.  This
-                                                         implies that the BGX_GMP_GMI_RX_JABBER, MINERR,
-                                                         BGX_GMP_GMI_RX_DECISION, BGX_GMP_GMI_RX_UDD_SKP, and the
-                                                         BGX_GMP_GMI_RX_STATS_* do not require any adjustment
-                                                         as they operate on the received packet size.
-                                                         When the packet reaches PKI, its size will
-                                                         reflect the additional bytes and is subject to
-                                                         the restrictions below.
-                                                         If PTP_MODE=1 and PRE_CHK=1, PRE_STRP must be 1.
-                                                         If PTP_MODE=1,
-                                                         PIP_PRT_CFGx[SKIP] should be increased by 8.
-                                                         PIP_PRT_CFGx[HIGIG_EN] should be 0.
-                                                         PIP_FRM_CHKx[MAXLEN] should be increased by 8.
-                                                         PIP_FRM_CHKx[MINLEN] should be increased by 8.
-                                                         PIP_TAG_INCx[EN] should be adjusted.
-                                                         PIP_PRT_CFGBx[ALT_SKP_EN] should be 0. */
+	uint64_t ptp_mode                     : 1;  /**< Timestamp mode. When PTP_MODE is set, a 64-bit timestamp is prepended to every incoming
+                                                         packet.
+                                                         The timestamp bytes are added to the packet in such a way as to not modify the packet's
+                                                         receive byte count. This implies that the BGX(0..5)_GMP_GMI_RX(0..3)_RX_JABBER,
+                                                         BGX(0..5)_GMP_GMI_RX(0..3)_RX_DECISION, BGX(0..5)_GMP_GMI_RX(0..3)_UDD_SKP, and
+                                                         BGX(0..5)_CMR(0..3)_RX_STAT* do not require any adjustment as they operate on the received
+                                                         packet size. When the packet reaches PKI, its size reflects the additional bytes and is
+                                                         subject to the following restrictions:
+                                                         If PTP_MODE = 1 and PRE_CHK = 1, PRE_STRP must be 1.
+                                                         If PTP_MODE = 1
+                                                         PKI_CL(0..3)_PKIND(0..63)_SKIP[FCS_SKIP,INST_SKIP] should be increased by 8.
+                                                         PKI_CL(0..3)_PKIND(0..63)_CFG[HG_EN] should be 0.
+                                                         PKI_FRM_LEN_CHK(0..1)[MAXLEN] should be increased by 8.
+                                                         PKI_FRM_LEN_CHK(0..1)[MINLEN] should be increased by 8.
+                                                         PKI_TAG_INC(0..63)_MASK should be adjusted.
+                                                         This supported in uCode in O78 >>> PIP_PRT_CFGB(0..63)[ALT_SKP_EN] should be 0. */
 	uint64_t reserved_11_11               : 1;
-	uint64_t null_dis                     : 1;  /**< When set, do not modify the MOD bits on NULL ticks
-                                                         due to PARITAL packets */
-	uint64_t pre_align                    : 1;  /**< When set, PREAMBLE parser aligns the the SFD byte
-                                                         regardless of the number of previous PREAMBLE
-                                                         nibbles.  In this mode, PRE_STRP should be set to
-                                                         account for the variable nature of the PREAMBLE.
-                                                         PRE_CHK must be set to enable this and all
-                                                         PREAMBLE features.
-                                                         (SGMII at 10/100Mbs only) */
+	uint64_t null_dis                     : 1;  /**< When set, do not modify the MOD bits on NULL ticks due to partial packets. */
+	uint64_t pre_align                    : 1;  /**< When set, PREAMBLE parser aligns the SFD byte regardless of the number of previous
+                                                         PREAMBLE nibbles. In this mode, PRE_STRP should be set to account for the variable nature
+                                                         of the PREAMBLE. PRE_CHK must be set to enable this and all PREAMBLE features.
+                                                         SGMII at 10/100Mbs only. */
 	uint64_t reserved_7_8                 : 2;
-	uint64_t pre_free                     : 1;  /**< When set, PREAMBLE checking is  less strict.
-                                                         GMX will begin the frame at the first SFD.
-                                                         PRE_CHK must be set to enable this and all
-                                                         PREAMBLE features.
-                                                         (SGMII/1000Base-X only) */
-	uint64_t ctl_smac                     : 1;  /**< Control Pause Frames can match station SMAC */
-	uint64_t ctl_mcst                     : 1;  /**< Control Pause Frames can match globally assign
-                                                         Multicast address */
-	uint64_t ctl_bck                      : 1;  /**< Forward pause information to TX block */
-	uint64_t ctl_drp                      : 1;  /**< Drop Control Pause Frames */
-	uint64_t pre_strp                     : 1;  /**< Strip off the preamble (when present)
-                                                         0=PREAMBLE+SFD is sent to core as part of frame
-                                                         1=PREAMBLE+SFD is dropped
-                                                         PRE_CHK must be set to enable this and all
-                                                         PREAMBLE features.
-                                                         If PTP_MODE=1 and PRE_CHK=1, PRE_STRP must be 1. */
-	uint64_t pre_chk                      : 1;  /**< This port is configured to send a valid 802.3
-                                                         PREAMBLE to begin every frame. GMX checks that a
-                                                         valid PREAMBLE is received (based on PRE_FREE).
-                                                         When a problem does occur within the PREAMBLE
-                                                         seqeunce, the frame is marked as bad and not sent
-                                                         into the core.  The BGX_GMP_GMI_RX_INT[PCTERR]
-                                                         interrupt is also raised.
-                                                         If PTP_MODE=1 and PRE_CHK=1, PRE_STRP must be 1. */
+	uint64_t pre_free                     : 1;  /**< When set, PREAMBLE checking is less strict. GMI will begin the frame at the first SFD.
+                                                         PRE_CHK must be set to enable this and all PREAMBLE features. SGMII/1000Base-X only. */
+	uint64_t ctl_smac                     : 1;  /**< Control PAUSE frames can match station SMAC. */
+	uint64_t ctl_mcst                     : 1;  /**< Control PAUSE frames can match globally assign multicast address. */
+	uint64_t ctl_bck                      : 1;  /**< Forward PAUSE information to TX block. */
+	uint64_t ctl_drp                      : 1;  /**< Drop control-PAUSE frames. */
+	uint64_t pre_strp                     : 1;  /**< Strip off the preamble (when present).
+                                                         0 = PREAMBLE + SFD is sent to core as part of frame.
+                                                         1 = PREAMBLE + SFD is dropped.
+                                                         [PRE_CHK] must be set to enable this and all PREAMBLE features.
+                                                         If PTP_MODE=1 and PRE_CHK=1, PRE_STRP must be 1.
+                                                         When PRE_CHK is set (indicating that the PREAMBLE will be sent), PRE_STRP determines if
+                                                         the PREAMBLE+SFD bytes are thrown away or sent to the core as part of the packet. In
+                                                         either mode, the PREAMBLE+SFD bytes are not counted toward the packet size when checking
+                                                         against the MIN and MAX bounds. Furthermore, the bytes are skipped when locating the start
+                                                         of the L2 header for DMAC and Control frame recognition. */
+	uint64_t pre_chk                      : 1;  /**< Check the preamble for correctness. This port is configured to send a valid 802.3 PREAMBLE
+                                                         to begin every frame. GMI checks that a valid PREAMBLE is received (based on PRE_FREE).
+                                                         When a problem does occur within the PREAMBLE sequence, the frame is marked as bad and not
+                                                         sent into the core. The BGX(0..5)_SMU(0..3)_RX_INT[PCTERR] interrupt is also raised.
+                                                         When BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] is set, PRE_CHK must be 0. If PTP_MODE = 1 and
+                                                         PRE_CHK = 1, PRE_STRP must be 1. */
 #else
 	uint64_t pre_chk                      : 1;
 	uint64_t pre_strp                     : 1;
@@ -3615,7 +3670,7 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_frm_ctl cvmx_bgxx_gmp_gmi_rxx_frm_ctl_t;
 /**
  * cvmx_bgx#_gmp_gmi_rx#_ifg
  *
- * BGX_GMP_GMI_RX_IFG = RX Min IFG
+ * This register specifies the minimum number of interframe-gap (IFG) cycles between packets.
  *
  */
 union cvmx_bgxx_gmp_gmi_rxx_ifg {
@@ -3623,13 +3678,11 @@ union cvmx_bgxx_gmp_gmi_rxx_ifg {
 	struct cvmx_bgxx_gmp_gmi_rxx_ifg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t ifg                          : 4;  /**< Min IFG (in IFG*8 bits) between packets used to
-                                                         determine IFGERR. Normally IFG is 96 bits.
-                                                         Note in some operating modes, IFG cycles can be
-                                                         inserted or removed in order to achieve clock rate
-                                                         adaptation. For these reasons, the default value
-                                                         is slightly conservative and does not check upto
-                                                         the full 96 bits of IFG.
+	uint64_t ifg                          : 4;  /**< Min IFG (in IFG * 8 bits) between packets used to determine IFGERR. Normally IFG is 96
+                                                         bits.
+                                                         Note that in some operating modes, IFG cycles can be inserted or removed in order to
+                                                         achieve clock rate adaptation. For these reasons, the default value is slightly
+                                                         conservative and does not check up to the full 96 bits of IFG.
                                                          (SGMII/1000Base-X only) */
 #else
 	uint64_t ifg                          : 4;
@@ -3651,7 +3704,7 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_ifg cvmx_bgxx_gmp_gmi_rxx_ifg_t;
  * as either MINERR o r CAREXT errors.
  * (4) JABBER An RX Jabber error indicates that a packet was received which
  * is longer than the maximum allowed packet as defined by the
- * system.  GMX will truncate the packet at the JABBER count.
+ * system.  GMI will truncate the packet at the JABBER count.
  * Failure to do so could lead to system instabilty.
  * (5) NIBERR This error is illegal at 1000Mbs speeds
  * (BGX_GMP_GMI_RX_PRT_CFG[SPEED]==0) and will never assert.
@@ -3678,10 +3731,10 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_ifg cvmx_bgxx_gmp_gmi_rxx_ifg_t;
  * (B) PCTERR checks that the frame begins with a valid PREAMBLE sequence.
  * Does not check the number of PREAMBLE cycles.
  * (C) OVRERR
- * OVRERR is an architectural assertion check internal to GMX to
+ * OVRERR is an architectural assertion check internal to GMI to
  * make sure no assumption was violated.  In a correctly operating
  * system, this interrupt can never fire.
- * GMX has an internal arbiter which selects which of 4 ports to
+ * GMI has an internal arbiter which selects which of 4 ports to
  * buffer in the main RX FIFO.  If we normally buffer 8 bytes,
  * then each port will typically push a tick every 8 cycles if
  * the packet interface is going as fast as possible.  If there
@@ -3695,28 +3748,30 @@ union cvmx_bgxx_gmp_gmi_rxx_int {
 	struct cvmx_bgxx_gmp_gmi_rxx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t ifgerr                       : 1;  /**< Interframe Gap Violation
-                                                         Does not necessarily indicate a failure
-                                                         (SGMII/1000Base-X only) */
-	uint64_t coldet                       : 1;  /**< Collision Detection
-                                                         (SGMII/1000Base-X half-duplex only) */
-	uint64_t falerr                       : 1;  /**< False carrier error or extend error after slottime
-                                                         (SGMII/1000Base-X only) */
-	uint64_t rsverr                       : 1;  /**< Reserved opcodes */
-	uint64_t pcterr                       : 1;  /**< Bad Preamble / Protocol */
-	uint64_t ovrerr                       : 1;  /**< Internal Data Aggregation Overflow ??
-                                                         This interrupt should never assert
-                                                         (SGMII/1000Base-X only) */
-	uint64_t skperr                       : 1;  /**< Skipper error */
-	uint64_t rcverr                       : 1;  /**< Frame was received with Data reception error */
-	uint64_t fcserr                       : 1;  /**< Frame was received with FCS/CRC error */
-	uint64_t jabber                       : 1;  /**< Frame was received with length > sys_length */
+	uint64_t ifgerr                       : 1;  /**< Interframe gap violation. Does not necessarily indicate a failure. SGMII/1000Base-X only. */
+	uint64_t coldet                       : 1;  /**< Collision detection. Collisions can only occur in half-duplex mode. A collision is assumed
+                                                         by the receiver when the slottime (BGX(0..5)_GMP_GMI_PRT(0..3)_CFG[SLOTTIME]) is not
+                                                         satisfied. In 10/100 mode, this will result in a frame < SLOTTIME. In 1000 mode, it could
+                                                         result either in frame < SLOTTIME or a carrier extend error with the SLOTTIME. These
+                                                         conditions are visible by 1) transfer ended before slottime - COLDET or 2) carrier extend
+                                                         error - CAREXT. */
+	uint64_t falerr                       : 1;  /**< False-carrier error, or carrier-extend error after slottime is satisfied. SGMII/1000Base-X only. */
+	uint64_t rsverr                       : 1;  /**< Reserved opcode. */
+	uint64_t pcterr                       : 1;  /**< Bad preamble/protocol error. Checks that the frame begins with a valid PREAMBLE sequence.
+                                                         Does not check the number of PREAMBLE cycles. */
+	uint64_t ovrerr                       : 1;  /**< Internal data aggregation overflow. This interrupt should never assert. SGMII/1000Base-X only. */
+	uint64_t skperr                       : 1;  /**< Skipper error. */
+	uint64_t rcverr                       : 1;  /**< Data-reception error. Frame was received with data-reception error */
+	uint64_t fcserr                       : 1;  /**< FCS/CRC error. Frame was received with FCS/CRC error */
+	uint64_t jabber                       : 1;  /**< System-length error: frame was received with length > sys_length.
+                                                         An RX Jabber error indicates that a packet was received which is longer than the maximum
+                                                         allowed packet as defined by the system. GMI truncates the packet at the JABBER count.
+                                                         Failure to do so could lead to system instability. */
 	uint64_t carext                       : 1;  /**< Carrier extend error
                                                          (SGMII/1000Base-X only) */
-	uint64_t minerr                       : 1;  /**< Pause Frame was received with length<minFrameSize
-                                                         Frame length checks are typically handled in PIP
-                                                         (PIP_INT[MINERR]), but pause frames are
-                                                         normally discarded before being inspected by PIP. */
+	uint64_t minerr                       : 1;  /**< PAUSE frame was received with length < minFrameSize. Frame length checks are typically
+                                                         handled in PKI, but PAUSE frames are normally discarded before being inspected by PKI.
+                                                         Total frame DA+SA+TL+DATA+PAD+FCS < 64. */
 #else
 	uint64_t minerr                       : 1;
 	uint64_t carext                       : 1;
@@ -3748,17 +3803,16 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_int cvmx_bgxx_gmp_gmi_rxx_int_t;
  * defined as...
  * max_sized_packet = BGX_GMP_GMI_RX_JABBER[CNT]+((BGX_GMP_GMI_RX_FRM_CTL[PRE_CHK] &
  * !BGX_GMP_GMI_RX_FRM_CTL[PRE_STRP])*8)
- * BGX_GMP_GMI_RX_JABBER = The max size packet after which GMX will truncate
+ * BGX_GMP_GMI_RX_JABBER = The max size packet after which GMI will truncate
  */
 union cvmx_bgxx_gmp_gmi_rxx_jabber {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_rxx_jabber_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t cnt                          : 16; /**< Byte count for jabber check
-                                                         Failing packets set the JABBER interrupt and are
-                                                         optionally sent with opcode==JABBER
-                                                         GMX will truncate the packet to CNT bytes */
+	uint64_t cnt                          : 16; /**< Byte count for jabber check. Failing packets set the JABBER interrupt and are optionally
+                                                         sent with opcode = JABBER. GMI truncates the packet to CNT bytes.
+                                                         CNT must be 8-byte aligned such that CNT<2:0> = 000. */
 #else
 	uint64_t cnt                          : 16;
 	uint64_t reserved_16_63               : 48;
@@ -3797,13 +3851,20 @@ union cvmx_bgxx_gmp_gmi_rxx_udd_skp {
 	struct cvmx_bgxx_gmp_gmi_rxx_udd_skp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t fcssel                       : 1;  /**< Include the skip bytes in the FCS calculation
+	uint64_t fcssel                       : 1;  /**< Include the skip bytes in the FCS calculation.
                                                          0 = all skip bytes are included in FCS
-                                                         1 = the skip bytes are not included in FCS */
+                                                         1 = the skip bytes are not included in FCS
+                                                         When BGX(0..5)_GMP_GMI_TX(0..3)_CTL[HG_EN] is set, this field must be 0.
+                                                         The skip bytes are part of the packet and are sent through the IOI packet interface and
+                                                         are handled by PKI. The system can determine if the UDD bytes are included in the FCS
+                                                         check by using the FCSSEL field, if the FCS check is enabled. */
 	uint64_t reserved_7_7                 : 1;
-	uint64_t len                          : 7;  /**< Amount of User-defined data before the start of
-                                                         the L2 data.  Zero means L2 comes first.
-                                                         Max value is 64. */
+	uint64_t len                          : 7;  /**< Amount of user-defined data before the start of the L2C data, in bytes.
+                                                         Setting to 0 means L2C comes first; maximum value is 64.
+                                                         LEN must be 0x0 in half-duplex operation.
+                                                         When BGX(0..5)_GMP_GMI_TX(0..3)_CTL[HG_EN] is set, this field must be set to 12 or 16
+                                                         (depending on HiGig header size) to account for the HiGig header.
+                                                         LEN = 12 selects HiGig/HiGig+; LEN = 16 selects HiGig2. */
 #else
 	uint64_t len                          : 7;
 	uint64_t reserved_7_7                 : 1;
@@ -3823,8 +3884,7 @@ union cvmx_bgxx_gmp_gmi_smacx {
 	struct cvmx_bgxx_gmp_gmi_smacx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t smac                         : 48; /**< The SMAC field is used for generating and
-                                                         accepting Control Pause packets */
+	uint64_t smac                         : 48; /**< The SMAC field is used for generating and accepting control PAUSE packets. */
 #else
 	uint64_t smac                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3842,14 +3902,11 @@ union cvmx_bgxx_gmp_gmi_txx_append {
 	struct cvmx_bgxx_gmp_gmi_txx_append_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t force_fcs                    : 1;  /**< Append the Ethernet FCS on each pause packet
-                                                         when FCS is clear. Pause packets are normally
-                                                         padded to 60 bytes.
-                                                         If BGX_GMP_GMI_TX_MIN_PKT[MIN_SIZE]
-                                                         exceeds 59, then FORCE_FCS will not be used. */
-	uint64_t fcs                          : 1;  /**< Append the Ethernet FCS on each packet */
-	uint64_t pad                          : 1;  /**< Append PAD bytes such that min sized */
-	uint64_t preamble                     : 1;  /**< Prepend the Ethernet preamble on each transfer */
+	uint64_t force_fcs                    : 1;  /**< Append the Ethernet FCS on each PAUSE packet. PAUSE packets are normally padded to 60
+                                                         bytes. If BGX(0..5)_GMP_GMI_TX(0..3)_MIN_PKT[MIN_SIZE] exceeds 59, then FCS_C is not used. */
+	uint64_t fcs                          : 1;  /**< Append the Ethernet FCS on each packet. */
+	uint64_t pad                          : 1;  /**< Append PAD bytes such that minimum-sized packet is transmitted. */
+	uint64_t preamble                     : 1;  /**< Prepend the Ethernet preamble on each transfer. */
 #else
 	uint64_t preamble                     : 1;
 	uint64_t pad                          : 1;
@@ -3870,11 +3927,11 @@ union cvmx_bgxx_gmp_gmi_txx_burst {
 	struct cvmx_bgxx_gmp_gmi_txx_burst_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t burst                        : 16; /**< Burst (refer to 802.3 to set correctly)
-                                                         Only valid for 1000Mbs half-duplex operation
-                                                         halfdup / 1000Mbs: 0x2000
-                                                         all other modes:   0x0
-                                                         (SGMII/1000Base-X only) */
+	uint64_t burst                        : 16; /**< Burst (refer to 802.3 to set correctly). Only valid for 1000Mb/s half-duplex operation as
+                                                         follows:
+                                                         half duplex/1000Mb/s: 0x2000
+                                                         all other modes: 0x0
+                                                         SGMII/1000Base-X only. */
 #else
 	uint64_t burst                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -3892,12 +3949,10 @@ union cvmx_bgxx_gmp_gmi_txx_ctl {
 	struct cvmx_bgxx_gmp_gmi_txx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t xsdef_en                     : 1;  /**< Enables the excessive deferral check for stats
-                                                         and interrupts
-                                                         (SGMII/1000Base-X half-duplex only) */
-	uint64_t xscol_en                     : 1;  /**< Enables the excessive collision check for stats
-                                                         and interrupts
-                                                         (SGMII/1000Base-X half-duplex only) */
+	uint64_t xsdef_en                     : 1;  /**< Enables the excessive-deferral check for statistics and interrupts. SGMII/1000Base-X half-
+                                                         duplex only. */
+	uint64_t xscol_en                     : 1;  /**< Enables the excessive-collision check for statistics and interrupts. SGMII/1000Base-X
+                                                         half-duplex only. */
 #else
 	uint64_t xscol_en                     : 1;
 	uint64_t xsdef_en                     : 1;
@@ -3916,15 +3971,11 @@ union cvmx_bgxx_gmp_gmi_txx_int {
 	struct cvmx_bgxx_gmp_gmi_txx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t ptp_lost                     : 1;  /**< A packet with a PTP request was not able to be
-                                                         sent due to XSCOL */
-	uint64_t late_col                     : 1;  /**< TX Late Collision
-                                                         (SGMII/1000Base-X half-duplex only) */
-	uint64_t xsdef                        : 1;  /**< TX Excessive deferral
-                                                         (SGMII/1000Base-X half-duplex only) */
-	uint64_t xscol                        : 1;  /**< TX Excessive collisions
-                                                         (SGMII/1000Base-X half-duplex only) */
-	uint64_t undflw                       : 1;  /**< TX Underflow */
+	uint64_t ptp_lost                     : 1;  /**< A packet with a PTP request was not able to be sent due to XSCOL. */
+	uint64_t late_col                     : 1;  /**< TX late collision. (SGMII/1000BASE-X half-duplex only) */
+	uint64_t xsdef                        : 1;  /**< TX excessive deferral. (SGMII/1000BASE-X half-duplex only) */
+	uint64_t xscol                        : 1;  /**< TX excessive collisions. (SGMII/1000BASE-X half-duplex only) */
+	uint64_t undflw                       : 1;  /**< TX underflow. */
 #else
 	uint64_t undflw                       : 1;
 	uint64_t xscol                        : 1;
@@ -3940,21 +3991,16 @@ typedef union cvmx_bgxx_gmp_gmi_txx_int cvmx_bgxx_gmp_gmi_txx_int_t;
 
 /**
  * cvmx_bgx#_gmp_gmi_tx#_min_pkt
- *
- * BGX_GMP_GMI_TX_MIN_PKT = Packet TX Min Size Packet (PAD upto min size)
- *
  */
 union cvmx_bgxx_gmp_gmi_txx_min_pkt {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_txx_min_pkt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t min_size                     : 8;  /**< Min frame in bytes before the FCS is applied
-                                                         Padding is only appened when
-                                                         BGX_GMP_GMI_TX_APPEND[PAD] for the coresponding port
-                                                         is set.
-                                                         In SGMII mode, packets will be padded to
-                                                         MIN_SIZE+1. The reset value will pad to 60 bytes. */
+	uint64_t min_size                     : 8;  /**< Minimum frame size in bytes before the FCS is applied.
+                                                         Padding is only appended when BGX(0..5)_GMP_GMI_TX(0..3)_APPEND[PAD] for the corresponding
+                                                         LMAC is set.
+                                                         In SGMII mode, packets are padded to MIN_SIZE+1. The reset value pads to 60 bytes. */
 #else
 	uint64_t min_size                     : 8;
 	uint64_t reserved_8_63                : 56;
@@ -3988,12 +4034,9 @@ union cvmx_bgxx_gmp_gmi_txx_pause_pkt_interval {
 	struct cvmx_bgxx_gmp_gmi_txx_pause_pkt_interval_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t interval                     : 16; /**< Arbitrate for a 802.3 pause packet,
-                                                         or CBFC pause packet every (INTERVAL*512)
-                                                         bit-times.
-                                                         Normally, 0 < INTERVAL < BGX_GMP_GMI_TX_PAUSE_PKT_TIME
-                                                         INTERVAL=0, will only send a single PAUSE packet
-                                                         for each backpressure event */
+	uint64_t interval                     : 16; /**< Arbitrate for a 802.3 PAUSE packet or CBFC PAUSE packet every (INTERVAL * 512) bit-times.
+                                                         Normally, 0 < INTERVAL < BGX(0..5)_GMP_GMI_TX(0..3)_PAUSE_PKT_TIME[TIME].
+                                                         INTERVAL = 0 only sends a single PAUSE packet for each backpressure event. */
 #else
 	uint64_t interval                     : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4005,32 +4048,16 @@ typedef union cvmx_bgxx_gmp_gmi_txx_pause_pkt_interval cvmx_bgxx_gmp_gmi_txx_pau
 
 /**
  * cvmx_bgx#_gmp_gmi_tx#_pause_pkt_time
- *
- * Notes:
- * Choosing proper values of BGX_GMP_GMI_TX_PAUSE_PKT_TIME[TIME] and
- * BGX_GMP_GMI_TX_PAUSE_PKT_INTERVAL[INTERVAL] can be challenging to the system
- * designer.  It is suggested that TIME be much greater than INTERVAL and
- * BGX_GMP_GMI_TX_PAUSE_ZERO[SEND] be set.  This allows a periodic refresh of the PAUSE
- * count and then when the backpressure condition is lifted, a PAUSE packet
- * with TIME==0 will be sent indicating that Octane is ready for additional
- * data.
- * If the system chooses to not set BGX_GMP_GMI_TX_PAUSE_ZERO[SEND], then it is
- * suggested that TIME and INTERVAL are programmed such that they satisify the
- * following rule...
- * INTERVAL <= TIME - (largest_pkt_size + IFG + pause_pkt_size)
- * where largest_pkt_size is that largest packet that the system can send
- * (normally 1518B), IFG is the interframe gap and pause_pkt_size is the size
- * of the PAUSE packet (normally 64B).
  */
 union cvmx_bgxx_gmp_gmi_txx_pause_pkt_time {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_txx_pause_pkt_time_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t ptime                        : 16; /**< The pause_time field placed in outbnd 802.3 pause
-                                                         packets, or CBFC pause packets.
-                                                         pause_time is in 512 bit-times
-                                                         Normally, TIME > BGX_GMP_GMI_TX_PAUSE_PKT_INTERVAL */
+	uint64_t ptime                        : 16; /**< Provides the pause_time field placed in outbound 802.3 PAUSE packets or CBFC PAUSE packets
+                                                         in 512 bit-times. Normally, P_TIME >
+                                                         BGX(0..5)_GMP_GMI_TX(0..3)_PAUSE_PKT_INTERVAL[INTERVAL]. For programming information see
+                                                         BGX(0..5)_GMP_GMI_TX(0..3)_PAUSE_PKT_INTERVAL. */
 #else
 	uint64_t ptime                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4048,8 +4075,7 @@ union cvmx_bgxx_gmp_gmi_txx_pause_togo {
 	struct cvmx_bgxx_gmp_gmi_txx_pause_togo_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t ptime                        : 16; /**< Amount of time remaining to backpressure
-                                                         From the standard 802.3 pause timer */
+	uint64_t ptime                        : 16; /**< Amount of time remaining to backpressure, from the standard 802.3 PAUSE timer. */
 #else
 	uint64_t ptime                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4067,9 +4093,8 @@ union cvmx_bgxx_gmp_gmi_txx_pause_zero {
 	struct cvmx_bgxx_gmp_gmi_txx_pause_zero_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t send                         : 1;  /**< When backpressure condition clear, send PAUSE
-                                                         packet with pause_time of zero to enable the
-                                                         channel */
+	uint64_t send                         : 1;  /**< Send PAUSE-zero enable.When this bit is set, and the backpressure condition is clear, it
+                                                         allows sending a PAUSE packet with pause_time of 0 to enable the channel. */
 #else
 	uint64_t send                         : 1;
 	uint64_t reserved_1_63                : 63;
@@ -4087,26 +4112,17 @@ union cvmx_bgxx_gmp_gmi_txx_sgmii_ctl {
 	struct cvmx_bgxx_gmp_gmi_txx_sgmii_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t align                        : 1;  /**< Align the transmission to even cycles
-                                                         Recommended value is:
-                                                         ALIGN = !BGX_GMP_GMI_TX_APPEND[PREAMBLE]
-                                                         (See the Transmit Conversion to Code groups
-                                                         section in the SGMII Interface chapter of the
-                                                         HRM for a complete discussion)
-                                                         0 = Data can be sent on any cycle
-                                                         In this mode, the interface will function at
-                                                         maximum bandwidth. It is possible to for the
-                                                         TX PCS machine to drop first byte of the TX
-                                                         frame.  When BGX_GMP_GMI_TX_APPEND[PREAMBLE] is
-                                                         set, the first byte will be a preamble byte
-                                                         which can be dropped to compensate for an
-                                                         extended IPG.
-                                                         1 = Data will only be sent on even cycles.
-                                                         In this mode, there can be bandwidth
-                                                         implications when sending odd-byte packets as
-                                                         the IPG can extend an extra cycle.
-                                                         There will be no loss of data.
-                                                         (SGMII/1000Base-X only) */
+	uint64_t align                        : 1;  /**< Align the transmission to even cycles: (SGMII/1000BASE-X half-duplex only)
+                                                         Recommended value is: ALIGN = !BGXn_GMP_GMI_TXm_APPEND[PREAMBLE].
+                                                         (See Transmit Conversion to Code groups, Transmit Conversion to Code Groups for a complete
+                                                         discussion.)
+                                                         0 = Data can be sent on any cycle. In this mode, the interface functions at maximum
+                                                         bandwidth. It is possible for the TX PCS machine to drop the first byte of the TX frame.
+                                                         When BGXn_GMP_GMI_TXm_APPEND[PREAMBLE] is set, the first byte is a preamble byte, which
+                                                         can be dropped to compensate for an extended IPG.
+                                                         1 = Data is only sent on even cycles. In this mode, there can be bandwidth implications
+                                                         when sending odd-byte packets as the IPG can extend an extra cycle. There will be no loss
+                                                         of data. */
 #else
 	uint64_t align                        : 1;
 	uint64_t reserved_1_63                : 63;
@@ -4124,10 +4140,10 @@ union cvmx_bgxx_gmp_gmi_txx_slot {
 	struct cvmx_bgxx_gmp_gmi_txx_slot_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
-	uint64_t slot                         : 10; /**< Slottime (refer to 802.3 to set correctly)
-                                                         10/100Mbs: 0x40
-                                                         1000Mbs:   0x200
-                                                         (SGMII/1000Base-X only) */
+	uint64_t slot                         : 10; /**< Slottime (refer to Std 802.3 to set correctly):
+                                                         10/100Mbs: set SLOT to 0x40
+                                                         1000Mbs: set SLOT to 0x200
+                                                         SGMII/1000Base-X only. */
 #else
 	uint64_t slot                         : 10;
 	uint64_t reserved_10_63               : 54;
@@ -4139,16 +4155,13 @@ typedef union cvmx_bgxx_gmp_gmi_txx_slot cvmx_bgxx_gmp_gmi_txx_slot_t;
 
 /**
  * cvmx_bgx#_gmp_gmi_tx#_soft_pause
- *
- * BGX_GMP_GMI_TX_SOFT_PAUSE = Packet TX Software Pause
- *
  */
 union cvmx_bgxx_gmp_gmi_txx_soft_pause {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_txx_soft_pause_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t ptime                        : 16; /**< Back off the TX bus for (TIME*512) bit-times */
+	uint64_t ptime                        : 16; /**< Back off the TX bus for (PTIME * 512) bit-times. */
 #else
 	uint64_t ptime                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4160,29 +4173,23 @@ typedef union cvmx_bgxx_gmp_gmi_txx_soft_pause cvmx_bgxx_gmp_gmi_txx_soft_pause_
 
 /**
  * cvmx_bgx#_gmp_gmi_tx#_thresh
- *
- * Per Port
- * BGX_GMP_GMI_TX_THRESH = Packet TX Threshold
  */
 union cvmx_bgxx_gmp_gmi_txx_thresh {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_txx_thresh_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
-	uint64_t cnt                          : 9;  /**< Number of 128b words to accumulate in the TX FIFO
-                                                         before sending on the packet interface
-                                                         This register should be large enough to prevent
-                                                         underflow on the packet interface and must never
-                                                         be set to zero.
-                                                         10G/40G Mode, CNT == 0x100
-                                                         In all modes, this register cannot exceed the
-                                                         the TX FIFO depth which is...
-                                                         BGX_CMR_TX_LMACS==0,1:  CNT MAX = 0x7FF
-                                                         BGX_CMR_TX_LMACS==2  :  CNT MAX = 0x3FF
-                                                         BGX_CMR_TX_LMACS==3  :  CNT MAX = 0x1FF */
-#else
-	uint64_t cnt                          : 9;
-	uint64_t reserved_9_63                : 55;
+	uint64_t reserved_11_63               : 53;
+	uint64_t cnt                          : 11; /**< Number of 128-bit words to accumulate in the TX FIFO before sending on the packet
+                                                         interface. This field should be large enough to prevent underflow on the packet interface
+                                                         and must never be set to 0x0.
+                                                         10G/40G Mode, CNT = 0x100. In all modes, this register cannot exceed the TX FIFO depth as
+                                                         follows.
+                                                         BGX*_CMR*_TX_LMACS = 0,1:  CNT maximum = 0x7FF
+                                                         BGX*_CMR*_TX_LMACS = 2:     CNT maximum = 0x3FF
+                                                         BGX*_CMR*_TX_LMACS = 3,4:  CNT maximum = 0x1FF */
+#else
+	uint64_t cnt                          : 11;
+	uint64_t reserved_11_63               : 53;
 #endif
 	} s;
 	struct cvmx_bgxx_gmp_gmi_txx_thresh_s cn78xx;
@@ -4197,8 +4204,7 @@ union cvmx_bgxx_gmp_gmi_tx_col_attempt {
 	struct cvmx_bgxx_gmp_gmi_tx_col_attempt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t limit                        : 5;  /**< Collision Attempts
-                                                         (SGMII/1000Base-X half-duplex only) */
+	uint64_t limit                        : 5;  /**< Number of collision attempts allowed. (SGMII/1000BASE-X half-duplex only.) */
 #else
 	uint64_t limit                        : 5;
 	uint64_t reserved_5_63                : 59;
@@ -4211,31 +4217,25 @@ typedef union cvmx_bgxx_gmp_gmi_tx_col_attempt cvmx_bgxx_gmp_gmi_tx_col_attempt_
 /**
  * cvmx_bgx#_gmp_gmi_tx_ifg
  *
- * Notes:
- * * Programming IFG1 and IFG2.
- * For 10/100/1000Mbs half-duplex systems that require IEEE 802.3
- * compatibility, IFG1 must be in the range of 1-8, IFG2 must be in the range
- * of 4-12, and the IFG1+IFG2 sum must be 12.
- * For 10/100/1000Mbs full-duplex systems that require IEEE 802.3
- * compatibility, IFG1 must be in the range of 1-11, IFG2 must be in the range
- * of 1-11, and the IFG1+IFG2 sum must be 12.
- * For all other systems, IFG1 and IFG2 can be any value in the range of
- * 1-15.  Allowing for a total possible IFG sum of 2-30.
- * Common BGX_GMP_GMI_TX_IFG = Packet TX Interframe Gap
+ * Consider the following when programming IFG1 and IFG2:
+ * For 10/100/1000 Mb/s half-duplex systems that require IEEE 802.3 compatibility, IFG1 must be
+ * in the range of 1-8, IFG2 must be in the range of 4-12, and the IFG1 + IFG2 sum must be 12.
+ * For 10/100/1000 Mb/s full-duplex systems that require IEEE 802.3 compatibility, IFG1 must be
+ * in the range of 1-11, IFG2 must be in the range of 1-11, and the IFG1 + IFG2 sum must be 12.
+ * For all other systems, IFG1 and IFG2 can be any value in the range of 1-15, allowing for a
+ * total possible IFG sum of 2-30.
  */
 union cvmx_bgxx_gmp_gmi_tx_ifg {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_tx_ifg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t ifg2                         : 4;  /**< 1/3 of the interframe gap timing (in IFG2*8 bits)
-                                                         If CRS is detected during IFG2, then the
-                                                         interFrameSpacing timer is not reset and a frame
-                                                         is transmited once the timer expires. */
-	uint64_t ifg1                         : 4;  /**< 2/3 of the interframe gap timing (in IFG1*8 bits)
-                                                         If CRS is detected during IFG1, then the
-                                                         interFrameSpacing timer is reset and a frame is
-                                                         not transmited. */
+	uint64_t ifg2                         : 4;  /**< Remainder of interFrameGap timing, equal to interFrameGap - IFG1 (in IFG2 * 8 bits). If
+                                                         CRS is detected during IFG2, the interFrameSpacing timer is not reset and a frame is
+                                                         transmitted once the timer expires. */
+	uint64_t ifg1                         : 4;  /**< First portion of interFrameGap timing, in the range of 0 to 2/3 (in IFG2 * 8 bits). If CRS
+                                                         is detected during IFG1, the interFrameSpacing timer is reset and a frame is not
+                                                         transmitted. */
 #else
 	uint64_t ifg1                         : 4;
 	uint64_t ifg2                         : 4;
@@ -4249,7 +4249,7 @@ typedef union cvmx_bgxx_gmp_gmi_tx_ifg cvmx_bgxx_gmp_gmi_tx_ifg_t;
 /**
  * cvmx_bgx#_gmp_gmi_tx_jam
  *
- * BGX_GMP_GMI_TX_JAM = Packet TX Jam Pattern
+ * This register provides the pattern used in JAM bytes.
  *
  */
 union cvmx_bgxx_gmp_gmi_tx_jam {
@@ -4257,8 +4257,7 @@ union cvmx_bgxx_gmp_gmi_tx_jam {
 	struct cvmx_bgxx_gmp_gmi_tx_jam_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t jam                          : 8;  /**< Jam pattern
-                                                         (SGMII/1000Base-X half-duplex only) */
+	uint64_t jam                          : 8;  /**< JAM pattern. (SGMII/1000BASE-X half-duplex only.) */
 #else
 	uint64_t jam                          : 8;
 	uint64_t reserved_8_63                : 56;
@@ -4270,16 +4269,17 @@ typedef union cvmx_bgxx_gmp_gmi_tx_jam cvmx_bgxx_gmp_gmi_tx_jam_t;
 
 /**
  * cvmx_bgx#_gmp_gmi_tx_lfsr
+ *
+ * This register shows the contents of the linear feedback shift register (LFSR), which is used
+ * to implement truncated binary exponential backoff.
  */
 union cvmx_bgxx_gmp_gmi_tx_lfsr {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_tx_lfsr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t lfsr                         : 16; /**< The current state of the LFSR used to feed random
-                                                         numbers to compute truncated binary exponential
-                                                         backoff.
-                                                         (SGMII/1000Base-X half-duplex only) */
+	uint64_t lfsr                         : 16; /**< Contains the current state of the LFSR, which is used to feed random numbers to compute
+                                                         truncated binary exponential backoff. (SGMII/1000Base-X half-duplex only.) */
 #else
 	uint64_t lfsr                         : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4297,7 +4297,7 @@ union cvmx_bgxx_gmp_gmi_tx_pause_pkt_dmac {
 	struct cvmx_bgxx_gmp_gmi_tx_pause_pkt_dmac_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t dmac                         : 48; /**< The DMAC field placed is outbnd pause pkts */
+	uint64_t dmac                         : 48; /**< The DMAC field, which is placed is outbound PAUSE packets. */
 #else
 	uint64_t dmac                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -4309,13 +4309,16 @@ typedef union cvmx_bgxx_gmp_gmi_tx_pause_pkt_dmac cvmx_bgxx_gmp_gmi_tx_pause_pkt
 
 /**
  * cvmx_bgx#_gmp_gmi_tx_pause_pkt_type
+ *
+ * This register provides the PTYPE field that is placed in outbound PAUSE packets.
+ *
  */
 union cvmx_bgxx_gmp_gmi_tx_pause_pkt_type {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_gmi_tx_pause_pkt_type_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t ptype                        : 16; /**< The TYPE field placed is outbnd pause pkts */
+	uint64_t ptype                        : 16; /**< The PTYPE field placed in outbound PAUSE packets. */
 #else
 	uint64_t ptype                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4327,33 +4330,28 @@ typedef union cvmx_bgxx_gmp_gmi_tx_pause_pkt_type cvmx_bgxx_gmp_gmi_tx_pause_pkt
 
 /**
  * cvmx_bgx#_gmp_pcs_an#_adv
- *
- * BGX_GMP_PCS_AN_ADV = AN Advertisement Register4
- *
  */
 union cvmx_bgxx_gmp_pcs_anx_adv {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_anx_adv_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t np                           : 1;  /**< Always 0, no next page capability supported */
+	uint64_t np                           : 1;  /**< Next page capable. This feature is not supported; this field is always 0. */
 	uint64_t reserved_14_14               : 1;
-	uint64_t rem_flt                      : 2;  /**< [<13>,<12>]
-                                                         0    0  Link OK  XMIT=DATA
-                                                         0    1  Link failure (loss of sync, XMIT!= DATA)
-                                                         1    0  local device Offline
-                                                         1    1  AN Error failure to complete AN
-                                                         AN Error is set if resolution function
-                                                         precludes operation with link partner */
+	uint64_t rem_flt                      : 2;  /**< Remote fault.
+                                                         00 = Link OK, XMIT = DATA
+                                                         01 = Link failure (loss of sync, XMIT !=DATA)
+                                                         10 = Local device offline
+                                                         11 = Auto-Negotiation error; failure to complete Auto-Negotiation. AN error is set if
+                                                         resolution function precludes operation with link partner. */
 	uint64_t reserved_9_11                : 3;
-	uint64_t pause                        : 2;  /**< [<8>, <7>] Pause frame flow capability across link
-                                                         Exchanged during Auto Negotiation
-                                                         0    0  No Pause
-                                                         0    1  Symmetric pause
-                                                         1    0  Asymmetric Pause
-                                                         1    1  Both symm and asymm pause to local device */
-	uint64_t hfd                          : 1;  /**< 1 means local device Half Duplex capable */
-	uint64_t fd                           : 1;  /**< 1 means local device Full Duplex capable */
+	uint64_t pause                        : 2;  /**< PAUSE frame flow capability across link, exchanged during Auto-Negotiation as follows:
+                                                         00 = No PAUSE.
+                                                         01 = Symmetric PAUSE.
+                                                         10 = Asymmetric PAUSE.
+                                                         11 = Both symmetric and asymmetric PAUSE to local device. */
+	uint64_t hfd                          : 1;  /**< Half-duplex. When set, local device is half-duplex capable. */
+	uint64_t fd                           : 1;  /**< Full-duplex. When set, local device is full-duplex capable. */
 	uint64_t reserved_0_4                 : 5;
 #else
 	uint64_t reserved_0_4                 : 5;
@@ -4373,19 +4371,16 @@ typedef union cvmx_bgxx_gmp_pcs_anx_adv cvmx_bgxx_gmp_pcs_anx_adv_t;
 
 /**
  * cvmx_bgx#_gmp_pcs_an#_ext_st
- *
- * BGX_GMP_PCS_AN_EXT_ST = AN Extended Status Register15
- * as per IEEE802.3 Clause 22
  */
 union cvmx_bgxx_gmp_pcs_anx_ext_st {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_anx_ext_st_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t thou_xfd                     : 1;  /**< 1 means PHY is 1000BASE-X Full Dup capable */
-	uint64_t thou_xhd                     : 1;  /**< 1 means PHY is 1000BASE-X Half Dup capable */
-	uint64_t thou_tfd                     : 1;  /**< 1 means PHY is 1000BASE-T Full Dup capable */
-	uint64_t thou_thd                     : 1;  /**< 1 means PHY is 1000BASE-T Half Dup capable */
+	uint64_t thou_xfd                     : 1;  /**< When set, PHY is 1000 BASE-X full duplex capable. */
+	uint64_t thou_xhd                     : 1;  /**< When set, PHY is 1000 BASE-X half duplex capable. */
+	uint64_t thou_tfd                     : 1;  /**< When set, PHY is 1000 BASE-T full duplex capable. */
+	uint64_t thou_thd                     : 1;  /**< When set, PHY is 1000 BASE-T half duplex capable. */
 	uint64_t reserved_0_11                : 12;
 #else
 	uint64_t reserved_0_11                : 12;
@@ -4403,7 +4398,7 @@ typedef union cvmx_bgxx_gmp_pcs_anx_ext_st cvmx_bgxx_gmp_pcs_anx_ext_st_t;
 /**
  * cvmx_bgx#_gmp_pcs_an#_lp_abil
  *
- * as per IEEE802.3 Clause 37
+ * This is the Auto-Negotiation Link partner ability register 5 as per IEEE 802.3, Clause 37.
  *
  */
 union cvmx_bgxx_gmp_pcs_anx_lp_abil {
@@ -4411,21 +4406,22 @@ union cvmx_bgxx_gmp_pcs_anx_lp_abil {
 	struct cvmx_bgxx_gmp_pcs_anx_lp_abil_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t np                           : 1;  /**< 1=lp next page capable, 0=lp not next page capable */
-	uint64_t ack                          : 1;  /**< 1=Acknowledgement received */
-	uint64_t rem_flt                      : 2;  /**< [<13>,<12>] Link Partner's link status
-                                                         0    0  Link OK
-                                                         0    1  Offline
-                                                         1    0  Link failure
-                                                         1    1  AN Error */
+	uint64_t np                           : 1;  /**< 0 = Link partner not next page capable.
+                                                         1 = Link partner next page capable. */
+	uint64_t ack                          : 1;  /**< When set, indicates acknowledgement received. */
+	uint64_t rem_flt                      : 2;  /**< Link partner's link status as follows:
+                                                         00 = Link OK.
+                                                         01 = Offline.
+                                                         10 = Link failure.
+                                                         11 = Auto-Negotiation error. */
 	uint64_t reserved_9_11                : 3;
-	uint64_t pause                        : 2;  /**< [<8>, <7>] Link Partner Pause setting
-                                                         0    0  No Pause
-                                                         0    1  Symmetric pause
-                                                         1    0  Asymmetric Pause
-                                                         1    1  Both symm and asymm pause to local device */
-	uint64_t hfd                          : 1;  /**< 1 means link partner Half Duplex capable */
-	uint64_t fd                           : 1;  /**< 1 means link partner Full Duplex capable */
+	uint64_t pause                        : 2;  /**< Link partner PAUSE setting as follows:
+                                                         00 = No PAUSE.
+                                                         01 = Symmetric PAUSE.
+                                                         10 = Asymmetric PAUSE.
+                                                         11 = Both symmetric and asymmetric PAUSE to local device. */
+	uint64_t hfd                          : 1;  /**< Half-duplex. When set, link partner is half-duplex capable. */
+	uint64_t fd                           : 1;  /**< Full-duplex. When set, link partner is full-duplex capable. */
 	uint64_t reserved_0_4                 : 5;
 #else
 	uint64_t reserved_0_4                 : 5;
@@ -4446,28 +4442,30 @@ typedef union cvmx_bgxx_gmp_pcs_anx_lp_abil cvmx_bgxx_gmp_pcs_anx_lp_abil_t;
 /**
  * cvmx_bgx#_gmp_pcs_an#_results
  *
- * NOTE:
- * an_results_reg is don't care when AN_OVRD is set to 1. If AN_OVRD=0 and AN_CPT=1
- * the an_results_reg is valid.
+ * This register is not valid when BGX(0..5)_GMP_PCS_MR(0..3)_CONTROL[AN_OVRD] is set to 1. If
+ * BGX(0..5)_GMP_PCS_MR(0..3)_CONTROL[AN_OVRD] is set to 0 and
+ * BGX(0..5)_GMP_PCS_AN(0..3)_RESULTS[AN_CPT] is set to 1, this register is valid.
  */
 union cvmx_bgxx_gmp_pcs_anx_results {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_anx_results_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_7_63                : 57;
-	uint64_t pause                        : 2;  /**< [<6>, <5>] PAUSE Selection (Don't care for SGMII)
-                                                         0    0  Disable Pause, TX and RX
-                                                         0    1  Enable pause frames RX only
-                                                         1    0  Enable Pause frames TX only
-                                                         1    1  Enable pause frames TX and RX */
-	uint64_t spd                          : 2;  /**< [<4>, <3>] Link Speed Selection
-                                                         0    0  10Mb/s
-                                                         0    1  100Mb/s
-                                                         1    0  1000Mb/s
-                                                         1    1  NS */
-	uint64_t an_cpt                       : 1;  /**< 1=AN Completed, 0=AN not completed or failed */
-	uint64_t dup                          : 1;  /**< 1=Full Duplex, 0=Half Duplex */
-	uint64_t link_ok                      : 1;  /**< 1=Link up(OK), 0=Link down */
+	uint64_t pause                        : 2;  /**< PAUSE selection ('don't care' for SGMII) as follows:
+                                                         00 = Disable PAUSE, TX and RX.
+                                                         01 = Enable PAUSE frames, RX only.
+                                                         10 = Enable PAUSE frames, TX only.
+                                                         11 = Enable PAUSE frames, TX and RX. */
+	uint64_t spd                          : 2;  /**< Link speed selection as follows:
+                                                         00 = 10 Mb/s.
+                                                         01 = 100 Mb/s.
+                                                         10 = 1000 Mb/s.
+                                                         11 = Reserved. */
+	uint64_t an_cpt                       : 1;  /**< Auto-Negotiation completed.
+                                                         1 = Auto-Negotiation completed.
+                                                         0 = Auto-Negotiation not completed or failed. */
+	uint64_t dup                          : 1;  /**< Duplex mode. 1 = full duplex, 0 = half duplex. */
+	uint64_t link_ok                      : 1;  /**< Link status: 1 = link up (OK), 1 = link down. */
 #else
 	uint64_t link_ok                      : 1;
 	uint64_t dup                          : 1;
@@ -4483,40 +4481,35 @@ typedef union cvmx_bgxx_gmp_pcs_anx_results cvmx_bgxx_gmp_pcs_anx_results_t;
 
 /**
  * cvmx_bgx#_gmp_pcs_int#
- *
- * PCS Interrupt Register
- *
  */
 union cvmx_bgxx_gmp_pcs_intx {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_intx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t dbg_sync                     : 1;  /**< Code Group sync failure debug help */
-	uint64_t dup                          : 1;  /**< Set whenever Duplex mode changes on the link */
-	uint64_t sync_bad                     : 1;  /**< Set by HW whenever rx sync st machine reaches a bad
-                                                         state. Should never be set during normal operation */
-	uint64_t an_bad                       : 1;  /**< Set by HW whenever AN st machine reaches a bad
-                                                         state. Should never be set during normal operation */
-	uint64_t rxlock                       : 1;  /**< Set by HW whenever code group Sync or bit lock
-                                                         failure occurs
-                                                         Cannot fire in loopback1 mode */
-	uint64_t rxbad                        : 1;  /**< Set by HW whenever rx st machine reaches a  bad
-                                                         state. Should never be set during normal operation */
-	uint64_t rxerr                        : 1;  /**< Set whenever RX receives a code group error in
-                                                         10 bit to 8 bit decode logic
-                                                         Cannot fire in loopback1 mode */
-	uint64_t txbad                        : 1;  /**< Set by HW whenever tx st machine reaches a bad
-                                                         state. Should never be set during normal operation */
-	uint64_t txfifo                       : 1;  /**< Set whenever HW detects a TX fifo overflow
-                                                         condition */
-	uint64_t txfifu                       : 1;  /**< Set whenever HW detects a TX fifo underflowflow
-                                                         condition */
-	uint64_t an_err                       : 1;  /**< AN Error, AN resolution function failed */
-	uint64_t xmit                         : 1;  /**< Set whenever HW detects a change in the XMIT
-                                                         variable. XMIT variable states are IDLE, CONFIG and
-                                                         DATA */
-	uint64_t lnkspd                       : 1;  /**< Set by HW whenever Link Speed has changed */
+	uint64_t dbg_sync                     : 1;  /**< Code group sync failure debug help. DBG_SYNC interrupt fires when code group
+                                                         synchronization state machine makes a transition from SYNC_ACQUIRED_1 state to
+                                                         SYNC_ACQUIRED_2 state. (See IEEE 802.3-2005, figure 37-9). It indicates that a bad code
+                                                         group was received after code group synchronization was achieved. This interrupt should be
+                                                         disabled during normal link operation. Use it as a debug help feature only. */
+	uint64_t dup                          : 1;  /**< Set whenever duplex mode changes on the link. */
+	uint64_t sync_bad                     : 1;  /**< Set by hardware whenever RX sync state machine reaches a bad state. Should never be set
+                                                         during normal operation. */
+	uint64_t an_bad                       : 1;  /**< Set by hardware whenever Auto-Negotiation state machine reaches a bad state. Should never
+                                                         be set during normal operation. */
+	uint64_t rxlock                       : 1;  /**< Set by hardware whenever code group sync or bit lock failure occurs. Cannot fire in loopback1 mode. */
+	uint64_t rxbad                        : 1;  /**< Set by hardware whenever RX state machine reaches a bad state. Should never be set during
+                                                         normal operation. */
+	uint64_t rxerr                        : 1;  /**< Set whenever RX receives a code group error in 10-bit to 8-bit decode logic. Cannot fire
+                                                         in loopback1 mode. */
+	uint64_t txbad                        : 1;  /**< Set by hardware whenever TX state machine reaches a bad state. Should never be set during
+                                                         normal operation. */
+	uint64_t txfifo                       : 1;  /**< Set whenever hardware detects a TX FIFO overflow condition. */
+	uint64_t txfifu                       : 1;  /**< Set whenever hardware detects a TX FIFO underflow condition. */
+	uint64_t an_err                       : 1;  /**< Auto-Negotiation error; AN resolution function failed. */
+	uint64_t xmit                         : 1;  /**< Set whenever hardware detects a change in the XMIT variable. XMIT variable states are
+                                                         IDLE, CONFIG and DATA. */
+	uint64_t lnkspd                       : 1;  /**< Set by hardware whenever link speed has changed. */
 #else
 	uint64_t lnkspd                       : 1;
 	uint64_t xmit                         : 1;
@@ -4540,16 +4533,18 @@ typedef union cvmx_bgxx_gmp_pcs_intx cvmx_bgxx_gmp_pcs_intx_t;
 
 /**
  * cvmx_bgx#_gmp_pcs_link#_timer
+ *
+ * This is the 1.6 ms nominal Link timer register.
+ *
  */
 union cvmx_bgxx_gmp_pcs_linkx_timer {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_linkx_timer_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t count                        : 16; /**< (core clock period times 1024) times "COUNT" should
-                                                         be 1.6ms(SGMII)/10ms(otherwise) which is the link
-                                                         timer used in auto negotiation.
-                                                         Reset assums a 700MHz sclk for 1.6ms link timer */
+	uint64_t count                        : 16; /**< (Coprocessor clock period * 1024) * COUNT should be 1.6 ms for SGMII and 10 ms otherwise,
+                                                         which is the link timer used in Auto-Negotiation. Reset assumes a 700 MHz coprocessor
+                                                         clock for 1.6 ms link timer. */
 #else
 	uint64_t count                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4580,34 +4575,34 @@ union cvmx_bgxx_gmp_pcs_miscx_ctl {
 	struct cvmx_bgxx_gmp_pcs_miscx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t sgmii                        : 1;  /**< 1=SGMII or 1000Base-X mode selected.
-                                                         0=XAUI or PCIE mode selected.
-                                                         See GSERx_LANE_MODE[LMODE]. */
-	uint64_t gmxeno                       : 1;  /**< GMX Enable override. When set to 1, forces GMX to
-                                                         appear disabled. The enable/disable status of GMX
-                                                         is checked only at SOP of every packet. */
-	uint64_t loopbck2                     : 1;  /**< Sets external loopback mode to return rx data back
-                                                         out via tx data path. 0=no loopback, 1=loopback */
-	uint64_t mac_phy                      : 1;  /**< 0=MAC, 1=PHY decides the tx_config_reg value to be
-                                                         sent during auto negotiation.
-                                                         See SGMII spec ENG-46158 from CISCO */
-	uint64_t mode                         : 1;  /**< 0=SGMII or 1= 1000 Base X */
-	uint64_t an_ovrd                      : 1;  /**< 0=disable, 1= enable over ride AN results
-                                                         Auto negotiation is allowed to happen but the
-                                                         results are ignored when set. Duplex and Link speed
-                                                         values are set from the pcs_mr_ctrl reg */
-	uint64_t samp_pt                      : 7;  /**< "Byte# in elongated frames for 10/100Mb/s operation
-                                                         for data sampling on RX side in PCS.
-                                                         Recommended values are 0x5 for 100Mb/s operation
-                                                         and 0x32 for 10Mb/s operation.
-                                                         For 10Mb/s operaton this field should be set to a
-                                                         value less than 99 and greater than 0. If set out
-                                                         of this range a value of 50 will be used for actual
-                                                         sampling internally without affecting the CSR field
-                                                         For 100Mb/s operation this field should be set to a
-                                                         value less than 9 and greater than 0. If set out of
-                                                         this range a value of 5 will be used for actual
-                                                         sampling internally without affecting the CSR field" */
+	uint64_t sgmii                        : 1;  /**< SGMII mode. 1 = SGMII or 1000BASE-X mode selected, 0 = other mode selected. See
+                                                         GSERx_LANE_MODE[LMODE]. */
+	uint64_t gmxeno                       : 1;  /**< GMI enable override. When set, forces GMI to appear disabled. The enable/disable status of
+                                                         GMI is checked only at SOP of every packet. */
+	uint64_t loopbck2                     : 1;  /**< Sets external loopback mode to return RX data back out via the TX data path. 0 = No
+                                                         loopback, 1 = Loopback.
+                                                         LOOPBCK1 and LOOPBCK2 modes may not be supported simultaneously. */
+	uint64_t mac_phy                      : 1;  /**< MAC/PHY.
+                                                         0 = MAC, 1 = PHY decides the TX_CONFIG_REG value to be sent during Auto-Negotiation. */
+	uint64_t mode                         : 1;  /**< Mode bit. 0 = SGMII, 1 = 1000Base X.
+                                                         1 = 1000Base-X mode is selected. Auto-Negotiation follows IEEE 802.3 clause 37.
+                                                         0 = SGMII mode is selected and the following note applies.
+                                                         The SGMII AN advertisement register (BGX(0..5)_GMP_PCS_SGM(0..3)_AN_ADV) is sent during
+                                                         Auto-Negotiation if BGX(0..5)_GMP_PCS_MISC(0..3)_CTL[MAC_PHY] = 1 (PHY mode). If [MAC_PHY]
+                                                         = 0 (MAC mode), the TX_CONFIG_REG<14> becomes ACK bit and <0> is always 1. All other bits
+                                                         in TX_CONFIG_REG sent are 0. The PHY dictates the Auto-Negotiation results. */
+	uint64_t an_ovrd                      : 1;  /**< Auto-Negotiation results override: 1 = enable override, 0 = disable.
+                                                         Auto-Negotiation is allowed to happen but the results are ignored when this bit is set.
+                                                         Duplex and Link speed values are set from BGX(0..5)_GMP_PCS_MISC(0..3)_CTL. */
+	uint64_t samp_pt                      : 7;  /**< Byte number in elongated frames for 10/100Mb/s operation for data sampling on RX side in
+                                                         PCS. Recommended values are 0x5 for
+                                                         100Mb/s operation and 0x32 for 10Mb/s operation.
+                                                         For 10Mb/s operation, this field should be set to a value less than 99 and greater than 0.
+                                                         If set out of this range, a value of 50 is used for actual sampling internally without
+                                                         affecting the CSR field.
+                                                         For 100Mb/s operation this field should be set to a value less than 9 and greater than 0.
+                                                         If set out of this range, a value of 5 is used for actual sampling internally without
+                                                         affecting the CSR field. */
 #else
 	uint64_t samp_pt                      : 7;
 	uint64_t an_ovrd                      : 1;
@@ -4625,50 +4620,43 @@ typedef union cvmx_bgxx_gmp_pcs_miscx_ctl cvmx_bgxx_gmp_pcs_miscx_ctl_t;
 
 /**
  * cvmx_bgx#_gmp_pcs_mr#_control
- *
- * NOTE:
- * Whenever AN_EN bit[12] is set, Auto negotiation is allowed to happen. The results
- * of the auto negotiation process set the fields in the AN_RESULTS reg. When AN_EN is not set,
- * AN_RESULTS reg is don't care. The effective SPD, DUP etc.. get their values
- * from the pcs_mr_ctrl reg.
  */
 union cvmx_bgxx_gmp_pcs_mrx_control {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_mrx_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t reset                        : 1;  /**< 1=SW Reset, the bit will return to 0 after pcs has
-                                                         been reset. Takes 32 sclk cycles to reset pcs */
-	uint64_t loopbck1                     : 1;  /**< 0=normal operation, 1=loopback. The loopback mode
-                                                         will return(loopback) tx data from GMII tx back to
-                                                         GMII rx interface. The loopback happens in the pcs
-                                                         module. Auto Negotiation will be disabled even if
-                                                         the AN_EN bit is set, during loopback */
-	uint64_t spdlsb                       : 1;  /**< See bit 6 description */
-	uint64_t an_en                        : 1;  /**< 1=AN Enable, 0=AN Disable */
-	uint64_t pwr_dn                       : 1;  /**< 1=Power Down(HW reset), 0=Normal operation */
+	uint64_t reset                        : 1;  /**< Set to reset. 1 = software PCS reset, 0 = normal operation.
+                                                         The bit returns to 0 after PCS has been reset. Takes 32 coprocessor-clock cycles to reset
+                                                         PCS. */
+	uint64_t loopbck1                     : 1;  /**< Enable loopback: 1 = internal loopback mode, 0 = normal operation
+                                                         The loopback mode returns loopback TX data from GMII TX back to GMII RX interface. The
+                                                         loopback happens in the PCS module. Auto-Negotiation is disabled even if AN_EN is set
+                                                         during loopback. */
+	uint64_t spdlsb                       : 1;  /**< Least-significant bit of the link-speed field, i.e. SPD<0>. Refer to SPDMSB. */
+	uint64_t an_en                        : 1;  /**< Auto-Negotiation enable: 1 = enable, 0 = disable. */
+	uint64_t pwr_dn                       : 1;  /**< Power down: 1 = power down (hardware reset), 0 = normal operation. */
 	uint64_t reserved_10_10               : 1;
-	uint64_t rst_an                       : 1;  /**< If bit 12 is set and bit 3 of status reg is 1
-                                                         Auto Negotiation begins. Else,SW writes are ignored
-                                                         and this bit remians at 0. This bit clears itself
-                                                         to 0, when AN starts. */
-	uint64_t dup                          : 1;  /**< 1=full duplex, 0=half duplex; effective only if AN
-                                                         disabled. If status register bits [15:9] and and
-                                                         extended status reg bits [15:12] allow only one
-                                                         duplex mode|, this bit will correspond to that
-                                                         value and any attempt to write will be ignored. */
-	uint64_t coltst                       : 1;  /**< 1=enable COL signal test, 0=disable test
-                                                         During COL test, the COL signal will reflect the
-                                                         GMII TX_EN signal with less than 16BT delay */
-	uint64_t spdmsb                       : 1;  /**< [<6>, <13>]Link Speed effective only if AN disabled
-                                                         0    0  10Mb/s
-                                                         0    1  100Mb/s
-                                                         1    0  1000Mb/s
-                                                         1    1  NS */
-	uint64_t uni                          : 1;  /**< Unidirectional (Std 802.3-2005, Clause 66.2)
-                                                         This bit will override the AN_EN bit and disable
-                                                         auto-negotiation variable mr_an_enable, when set
-                                                         Used in both 1000Base-X and SGMII modes */
+	uint64_t rst_an                       : 1;  /**< Reset Auto-Negotiation. When set, if AN_EN = 1 and
+                                                         BGX(0..5)_GMP_PCS_MR(0..3)_STATUS[AN_ABIL] = 1, Auto-Negotiation begins. Otherwise,
+                                                         software write requests are ignored and this bit remains at 0. This bit clears itself to
+                                                         0, when Auto-Negotiation starts. */
+	uint64_t dup                          : 1;  /**< Duplex mode: 1 = full duplex, 0 = half duplex; effective only if Auto-Negotiation is
+                                                         disabled. If BGX(0..5)_GMP_PCS_MR(0..3)_STATUS <15:9> and
+                                                         BGX(0..5)_GMP_PCS_AN(0..3)_ADV<15:12> allow only one duplex mode, this bit corresponds to
+                                                         that value and any attempts to write are ignored. */
+	uint64_t coltst                       : 1;  /**< COL test: 1 = enable COL signal test, 0 = disable test.
+                                                         During COL test, the COL signal reflects the GMII TX_EN signal with less than 16BT delay. */
+	uint64_t spdmsb                       : 1;  /**< Link speed most-significant bit, i.e SPD<1>; effective only if Auto-Negotiation is
+                                                         disabled.
+                                                         SPDMSB SPDLSB Link Speed
+                                                         0 0 10 Mb/s
+                                                         0 1 100 Mb/s
+                                                         1 0 1000 Mb/s
+                                                         1 1 reserved */
+	uint64_t uni                          : 1;  /**< Unidirectional (Std 802.3-2005, Clause 66.2). When set to 1, this bit overrides AN_EN and
+                                                         disables the Auto-Negotiation variable mr_an_enable. Used in both 1000BASE-X and SGMII
+                                                         modes. */
 	uint64_t reserved_0_4                 : 5;
 #else
 	uint64_t reserved_0_4                 : 5;
@@ -4693,45 +4681,41 @@ typedef union cvmx_bgxx_gmp_pcs_mrx_control cvmx_bgxx_gmp_pcs_mrx_control_t;
 /**
  * cvmx_bgx#_gmp_pcs_mr#_status
  *
- * Bits [15:9] in the Status Register indicate ability to operate as per those signalling
- * specification,
- * when misc ctl reg MAC_PHY bit is set to MAC mode. Bits [15:9] will all, always read 0,
- * indicating
- * that the chip cannot operate in the corresponding modes.
- * Bit [4] RM_FLT is a don't care when the selected mode is SGMII.
- * BGX_GMP_PCS_MR_STATUS = Status Register1
+ * Bits <15:9> in this register indicate the ability to operate when
+ * BGX(0..5)_GMP_PCS_MISC(0..3)_CTL[MAC_PHY] is set to MAC mode. Bits <15:9> are always read as
+ * 0, indicating that the chip cannot operate in the corresponding modes. The field [RM_FLT] is a
+ * 'don't care' when the selected mode is SGMII.
  */
 union cvmx_bgxx_gmp_pcs_mrx_status {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_mrx_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t hun_t4                       : 1;  /**< 1 means 100Base-T4 capable */
-	uint64_t hun_xfd                      : 1;  /**< 1 means 100Base-X Full Duplex */
-	uint64_t hun_xhd                      : 1;  /**< 1 means 100Base-X Half Duplex */
-	uint64_t ten_fd                       : 1;  /**< 1 means 10Mb/s Full Duplex */
-	uint64_t ten_hd                       : 1;  /**< 1 means 10Mb/s Half Duplex */
-	uint64_t hun_t2fd                     : 1;  /**< 1 means 100Base-T2 Full Duplex */
-	uint64_t hun_t2hd                     : 1;  /**< 1 means 100Base-T2 Half Duplex */
-	uint64_t ext_st                       : 1;  /**< 1 means extended status info in reg15 */
+	uint64_t hun_t4                       : 1;  /**< Indicates 100BASE-T4 capable. */
+	uint64_t hun_xfd                      : 1;  /**< Indicates 100BASE-X full duplex. */
+	uint64_t hun_xhd                      : 1;  /**< Indicates 100BASE-X half duplex. */
+	uint64_t ten_fd                       : 1;  /**< Indicates 10Mb/s full duplex. */
+	uint64_t ten_hd                       : 1;  /**< Indicates 10Mb/s half duplex. */
+	uint64_t hun_t2fd                     : 1;  /**< Indicates 100BASE-T2 full duplex. */
+	uint64_t hun_t2hd                     : 1;  /**< Indicates 100BASE-T2 half duplex. */
+	uint64_t ext_st                       : 1;  /**< Extended status information. When set to 1, indicates that additional status data is
+                                                         available in BGX(0..5)_GMP_PCS_AN(0..3)_EXT_ST. */
 	uint64_t reserved_7_7                 : 1;
-	uint64_t prb_sup                      : 1;  /**< 1 means able to work without preamble bytes at the
-                                                         beginning of frames. 0 means not able to accept
-                                                         frames without preamble bytes preceding them. */
-	uint64_t an_cpt                       : 1;  /**< 1 means Auto Negotiation is complete and the
-                                                         contents of the an_results_reg are valid. */
-	uint64_t rm_flt                       : 1;  /**< Set to 1 when remote flt condition occurs. This bit
-                                                         implements a latching Hi behavior. It is cleared by
-                                                         SW read of this reg or when reset bit [15] in
-                                                         Control Reg is asserted.
-                                                         See an adv reg[13:12] for flt conditions */
-	uint64_t an_abil                      : 1;  /**< 1 means Auto Negotiation capable */
-	uint64_t lnk_st                       : 1;  /**< 1=link up, 0=link down. Set during AN process
-                                                         Set whenever XMIT=DATA. Latching Lo behavior when
-                                                         link goes down. Link down value of the bit stays
-                                                         low until SW reads the reg. */
+	uint64_t prb_sup                      : 1;  /**< Preamble not needed.
+                                                         1 = Can work without preamble bytes at the beginning of frames.
+                                                         0 = Cannot accept frames without preamble bytes. */
+	uint64_t an_cpt                       : 1;  /**< Indicates Auto-Negotiation is complete; the contents of the
+                                                         BGX(0..5)_GMP_PCS_AN(0..3)_RESULTS are valid. */
+	uint64_t rm_flt                       : 1;  /**< Indicates remote fault condition occurred. This bit implements a latching-high behavior.
+                                                         It is cleared when software reads this register or when
+                                                         BGX(0..5)_GMP_PCS_MR(0..3)_CONTROL[RESET] is asserted.
+                                                         See BGX(0..5)_GMP_PCS_AN(0..3)_ADV[REM_FLT] for fault conditions. */
+	uint64_t an_abil                      : 1;  /**< Indicates Auto-Negotiation capable. */
+	uint64_t lnk_st                       : 1;  /**< Link state: 0 = link down, 1 = link up.
+                                                         Set during Auto-Negotiation process. Set whenever XMIT = DATA. Latching-low behavior when
+                                                         link goes down. Link down value of the bit stays low until software reads the register. */
 	uint64_t reserved_1_1                 : 1;
-	uint64_t extnd                        : 1;  /**< Always 0, no extended capability regs present */
+	uint64_t extnd                        : 1;  /**< This field is always 0, extended capability registers not present. */
 #else
 	uint64_t extnd                        : 1;
 	uint64_t reserved_1_1                 : 1;
@@ -4764,12 +4748,12 @@ union cvmx_bgxx_gmp_pcs_rxx_states {
 	struct cvmx_bgxx_gmp_pcs_rxx_states_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t rx_bad                       : 1;  /**< Receive state machine in an illegal state */
-	uint64_t rx_st                        : 5;  /**< Receive state machine state */
-	uint64_t sync_bad                     : 1;  /**< Receive synchronization SM in an illegal state */
-	uint64_t sync                         : 4;  /**< Receive synchronization SM state */
-	uint64_t an_bad                       : 1;  /**< Auto Negotiation state machine in an illegal state */
-	uint64_t an_st                        : 4;  /**< Auto Negotiation state machine state */
+	uint64_t rx_bad                       : 1;  /**< Receive state machine is in an illegal state. */
+	uint64_t rx_st                        : 5;  /**< Receive state-machine state. */
+	uint64_t sync_bad                     : 1;  /**< Receive synchronization state machine is in an illegal state. */
+	uint64_t sync                         : 4;  /**< Receive synchronization state-machine state. */
+	uint64_t an_bad                       : 1;  /**< Auto-Negotiation state machine is in an illegal state. */
+	uint64_t an_st                        : 4;  /**< Auto-Negotiation state-machine state. */
 #else
 	uint64_t an_st                        : 4;
 	uint64_t an_bad                       : 1;
@@ -4786,17 +4770,14 @@ typedef union cvmx_bgxx_gmp_pcs_rxx_states cvmx_bgxx_gmp_pcs_rxx_states_t;
 
 /**
  * cvmx_bgx#_gmp_pcs_rx#_sync
- *
- * BGX_GMP_PCS_RX_SYNC = Code Group synchronization reg
- *
  */
 union cvmx_bgxx_gmp_pcs_rxx_sync {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_rxx_sync_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t sync                         : 1;  /**< 1 means code group synchronization achieved */
-	uint64_t bit_lock                     : 1;  /**< 1 means bit lock achieved */
+	uint64_t sync                         : 1;  /**< When set, code group synchronization achieved. */
+	uint64_t bit_lock                     : 1;  /**< When set, bit lock achieved. */
 #else
 	uint64_t bit_lock                     : 1;
 	uint64_t sync                         : 1;
@@ -4810,29 +4791,28 @@ typedef union cvmx_bgxx_gmp_pcs_rxx_sync cvmx_bgxx_gmp_pcs_rxx_sync_t;
 /**
  * cvmx_bgx#_gmp_pcs_sgm#_an_adv
  *
- * NOTE: The SGMII AN Advertisement Register will be sent during Auto Negotiation if the
- * MAC_PHY mode bit in misc_ctl_reg
- * is set (1=PHY mode). If the bit is not set (0=MAC mode), the tx_config_reg[14] becomes ACK bit
- * and [0] is always 1.
- * All other bits in tx_config_reg sent will be 0. The PHY dictates the Auto Negotiation results.
- * SGMII AN Advertisement Register (sent out as tx_config_reg)
+ * This is the SGMII Auto-Negotiation advertisement register (sent out as TX_CONFIG_REG). This
+ * register is sent during Auto-Negotiation if
+ * BGX(0..5)_GMP_PCS_MISC(0..3)_CTL[MAC_PHY] is set (1 = PHY mode). If the bit is not set (0 =
+ * MAC mode), the TX_CONFIG_REG<14> becomes ACK bit and <0> is always 1. All other bits in
+ * TX_CONFIG_REG sent will be 0. The PHY dictates the Auto-Negotiation results.
  */
 union cvmx_bgxx_gmp_pcs_sgmx_an_adv {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_sgmx_an_adv_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t link                         : 1;  /**< Link status 1 Link Up, 0 Link Down */
-	uint64_t ack                          : 1;  /**< Auto negotiation ack */
+	uint64_t link                         : 1;  /**< Link status: 1 = Link up, 0 = Link down. */
+	uint64_t ack                          : 1;  /**< Auto-Negotiation acknowledgement. */
 	uint64_t reserved_13_13               : 1;
-	uint64_t dup                          : 1;  /**< Duplex mode 1=full duplex, 0=half duplex */
-	uint64_t speed                        : 2;  /**< Link Speed
-                                                         0    0  10Mb/s
-                                                         0    1  100Mb/s
-                                                         1    0  1000Mb/s
-                                                         1    1  NS */
+	uint64_t dup                          : 1;  /**< Duplex mode: 1 = full duplex, 0 = half duplex */
+	uint64_t speed                        : 2;  /**< Link speed:
+                                                         00 = 10 Mb/s.
+                                                         01 = 100 Mb/s.
+                                                         10 = 1000 Mb/s.
+                                                         11 = Reserved. */
 	uint64_t reserved_1_9                 : 9;
-	uint64_t one                          : 1;  /**< Always set to match tx_config_reg<0> */
+	uint64_t one                          : 1;  /**< Always set to match TX_CONFIG_REG<0>. */
 #else
 	uint64_t one                          : 1;
 	uint64_t reserved_1_9                 : 9;
@@ -4851,7 +4831,7 @@ typedef union cvmx_bgxx_gmp_pcs_sgmx_an_adv cvmx_bgxx_gmp_pcs_sgmx_an_adv_t;
 /**
  * cvmx_bgx#_gmp_pcs_sgm#_lp_adv
  *
- * SGMII LP Advertisement Register (received as rx_config_reg)
+ * This is the SGMII Link partner advertisement register (received as RX_CONFIG_REG).
  *
  */
 union cvmx_bgxx_gmp_pcs_sgmx_lp_adv {
@@ -4859,16 +4839,16 @@ union cvmx_bgxx_gmp_pcs_sgmx_lp_adv {
 	struct cvmx_bgxx_gmp_pcs_sgmx_lp_adv_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t link                         : 1;  /**< Link status 1 Link Up, 0 Link Down */
+	uint64_t link                         : 1;  /**< Link status: 1 = Link up, 0 = Link down. */
 	uint64_t reserved_13_14               : 2;
-	uint64_t dup                          : 1;  /**< Duplex mode 1=full duplex, 0=half duplex */
-	uint64_t speed                        : 2;  /**< Link Speed
-                                                         0    0  10Mb/s
-                                                         0    1  100Mb/s
-                                                         1    0  1000Mb/s
-                                                         1    1  NS */
+	uint64_t dup                          : 1;  /**< Duplex mode: 1 = Full duplex, 0 = Half duplex */
+	uint64_t speed                        : 2;  /**< Link speed:
+                                                         00 = 10 Mb/s.
+                                                         01 = 100 Mb/s.
+                                                         10 = 1000 Mb/s.
+                                                         11 = Reserved. */
 	uint64_t reserved_1_9                 : 9;
-	uint64_t one                          : 1;  /**< Always set to match tx_config_reg<0> */
+	uint64_t one                          : 1;  /**< Always set to match TX_CONFIG_REG<0> */
 #else
 	uint64_t one                          : 1;
 	uint64_t reserved_1_9                 : 9;
@@ -4891,9 +4871,12 @@ union cvmx_bgxx_gmp_pcs_txx_states {
 	struct cvmx_bgxx_gmp_pcs_txx_states_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_7_63                : 57;
-	uint64_t xmit                         : 2;  /**< 0=undefined, 1=config, 2=idle, 3=data */
-	uint64_t tx_bad                       : 1;  /**< Xmit state machine in a bad state */
-	uint64_t ord_st                       : 4;  /**< Xmit ordered set state machine state */
+	uint64_t xmit                         : 2;  /**< 0x0 = Undefined.
+                                                         0x1 = Config.
+                                                         0x2 = Idle.
+                                                         0x3 = Data */
+	uint64_t tx_bad                       : 1;  /**< Transmit state machine in an illegal state. */
+	uint64_t ord_st                       : 4;  /**< Transmit ordered set state-machine state. */
 #else
 	uint64_t ord_st                       : 4;
 	uint64_t tx_bad                       : 1;
@@ -4908,24 +4891,24 @@ typedef union cvmx_bgxx_gmp_pcs_txx_states cvmx_bgxx_gmp_pcs_txx_states_t;
 /**
  * cvmx_bgx#_gmp_pcs_tx_rx#_polarity
  *
- * Note:
- * r_tx_rx_polarity_reg bit [2] will show correct polarity needed on the link receive path after
- * code grp synchronization is achieved.
- * BGX_GMP_PCS_POLARITY = TX_RX polarity reg
+ * BGX(0..5)_GMP_PCS_TX_RX(0..3)_POLARITY[AUTORXPL] shows correct polarity needed on the link
+ * receive path after code group synchronization is achieved.
  */
 union cvmx_bgxx_gmp_pcs_tx_rxx_polarity {
 	uint64_t u64;
 	struct cvmx_bgxx_gmp_pcs_tx_rxx_polarity_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t rxovrd                       : 1;  /**< When 0, <2> determines polarity
-                                                         when 1, <1> determines polarity */
-	uint64_t autorxpl                     : 1;  /**< Auto RX polarity detected. 1=inverted, 0=normal
-                                                         This bit always represents the correct rx polarity
-                                                         setting needed for successful rx path operartion,
-                                                         once a successful code group sync is obtained */
-	uint64_t rxplrt                       : 1;  /**< 1 is inverted polarity, 0 is normal polarity */
-	uint64_t txplrt                       : 1;  /**< 1 is inverted polarity, 0 is normal polarity */
+	uint64_t rxovrd                       : 1;  /**< RX polarity override.
+                                                         0 = AUTORXPL determines polarity
+                                                         1 = RXPLRT determines polarity */
+	uint64_t autorxpl                     : 1;  /**< Auto RX polarity detected:
+                                                         0 = Normal polarity
+                                                         1 = Inverted polarity
+                                                         This bit always represents the correct RX polarity setting needed for successful RX path
+                                                         operation, once a successful code group sync is obtained. */
+	uint64_t rxplrt                       : 1;  /**< RX polarity: 0 = Normal polarity, 1 = Inverted polarity. */
+	uint64_t txplrt                       : 1;  /**< TX polarity: 0 = Normal polarity, 1 = Inverted polarity. */
 #else
 	uint64_t txplrt                       : 1;
 	uint64_t rxplrt                       : 1;
@@ -4945,27 +4928,21 @@ union cvmx_bgxx_smux_cbfc_ctl {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_cbfc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t phys_en                      : 16; /**< Determines which ports will have physical
-                                                         backpressure pause packets.
-                                                         The value placed in the Class Enable Vector
-                                                         field of the PFC/CBFC pause packet will be
-                                                         PHYS_EN | LOGL_EN */
-	uint64_t logl_en                      : 16; /**< Determines which ports will have logical
-                                                         backpressure pause packets.
-                                                         The value placed in the Class Enable Vector
-                                                         field of the PFC/CBFC pause packet will be
-                                                         PHYS_EN | LOGL_EN */
+	uint64_t phys_en                      : 16; /**< Physical backpressure enable. Determines which LMACs will have physical backpressure PAUSE
+                                                         packets. The value placed in the Class Enable Vector field of the PFC/CBFC PAUSE packet is
+                                                         PHYS_EN | LOGL_EN. */
+	uint64_t logl_en                      : 16; /**< Logical backpressure enable. Determines which LMACs will have logical backpressure PAUSE
+                                                         packets. The value placed in the Class Enable Vector field of the PFC/CBFC PAUSE packet is
+                                                         PHYS_EN | LOGL_EN. */
 	uint64_t reserved_4_31                : 28;
-	uint64_t bck_en                       : 1;  /**< Forward PFC/CBFC Pause information to BP block */
-	uint64_t drp_en                       : 1;  /**< Drop Control PFC/CBFC Pause Frames */
-	uint64_t tx_en                        : 1;  /**< When set, allow for PFC/CBFC Pause Packets
-                                                         Must be clear in HiGig2 mode i.e. when
-                                                         BGX_TX_CTL[HG_EN]=1 and
-                                                         BGX_RX_UDD_SKP[SKIP]=16. */
-	uint64_t rx_en                        : 1;  /**< When set, allow for PFC/CBFC Pause Packets
-                                                         Must be clear in HiGig2 mode i.e. when
-                                                         BGX_TX_CTL[HG_EN]=1 and
-                                                         BGX_RX_UDD_SKP[SKIP]=16. */
+	uint64_t bck_en                       : 1;  /**< Forward PFC/CBFC PAUSE information to the backpressure block. */
+	uint64_t drp_en                       : 1;  /**< Drop-control enable. When set, drop PFC/CBFC PAUSE frames. */
+	uint64_t tx_en                        : 1;  /**< Transmit enable. When set, allow for PFC/CBFC PAUSE packets. Must be clear in HiGig2 mode
+                                                         i.e. when BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] = 1 and BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] =
+                                                         16. */
+	uint64_t rx_en                        : 1;  /**< Receive enable. When set, allow for PFC/CBFC PAUSE packets. Must be clear in HiGig2 mode
+                                                         i.e. when BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] = 1 and BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] =
+                                                         16. */
 #else
 	uint64_t rx_en                        : 1;
 	uint64_t tx_en                        : 1;
@@ -4982,23 +4959,15 @@ typedef union cvmx_bgxx_smux_cbfc_ctl cvmx_bgxx_smux_cbfc_ctl_t;
 
 /**
  * cvmx_bgx#_smu#_ctrl
- *
- * "**************************************************************
- * BGX TX common (to all LMACs) registers                       *
- * **************************************************************
- * **************************************************************
- * BGX TX/RX registers                                          *
- * **************************************************************
- * BGX_SMU_CTRL = SMU Control Register"
  */
 union cvmx_bgxx_smux_ctrl {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t tx_idle                      : 1;  /**< TX Machine is idle This indication pertains to the framer FSM and ignores the effects on
+	uint64_t tx_idle                      : 1;  /**< TX machine is idle This indication pertains to the framer FSM and ignores the effects on
                                                          the data-path controls or values which occur when BGX_SMU_TX_CTL[LS_BYP] is set */
-	uint64_t rx_idle                      : 1;  /**< RX Machine is idle */
+	uint64_t rx_idle                      : 1;  /**< RX machine is idle. */
 #else
 	uint64_t rx_idle                      : 1;
 	uint64_t tx_idle                      : 1;
@@ -5011,19 +4980,19 @@ typedef union cvmx_bgxx_smux_ctrl cvmx_bgxx_smux_ctrl_t;
 
 /**
  * cvmx_bgx#_smu#_ext_loopback
+ *
+ * In loopback mode, the IFG1+IFG2 of local and remote parties must match exactly; otherwise one
+ * of the two sides' loopback FIFO will overrun: BGX(0..5)_SMU(0..3)_TX_INT[LB_OVRFLW].
  */
 union cvmx_bgxx_smux_ext_loopback {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_ext_loopback_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t en                           : 1;  /**< Loopback enable
-                                                         Puts the packet interface in external loopback
-                                                         mode where the RX lines are reflected on the TX lines. */
-	uint64_t thresh                       : 4;  /**< Threshhold on the TX FIFO
-                                                         SW must only write the typical value.  Any other
-                                                         value will cause loopback mode not to function
-                                                         correctly. */
+	uint64_t en                           : 1;  /**< Loopback enable. Puts the packet interface in external loopback mode where the RX lines
+                                                         are reflected on the TX lines. */
+	uint64_t thresh                       : 4;  /**< Threshold on the TX FIFO. Software must only write the typical value. Any other value
+                                                         causes loopback mode not to function correctly. */
 #else
 	uint64_t thresh                       : 4;
 	uint64_t en                           : 1;
@@ -5036,22 +5005,35 @@ typedef union cvmx_bgxx_smux_ext_loopback cvmx_bgxx_smux_ext_loopback_t;
 
 /**
  * cvmx_bgx#_smu#_hg2_control
+ *
+ * HiGig2 TX- and RX-enable are normally set together for HiGig2 messaging. Setting just the TX
+ * or RX bit results in only the HG2 message transmit or receive capability.
+ * Setting [PHYS_EN] and [LOGL_EN] to 1 allows link PAUSE or backpressure to PKO as per the
+ * received HiGig2 message. Setting these fields to 0 disables link PAUSE and backpressure to PKO
+ * in response to received messages.
+ * BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] must be set (to enable HiGig) whenever either [HG2TX_EN] or
+ * [HG2RX_EN] are set. BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] must be set to 16 (to select HiGig2)
+ * whenever either [HG2TX_EN] or [HG2RX_EN] are set.
+ * BGX(0..5)_CMR_RX_OVR_BP[EN<0>] must be set and BGX(0..5)_CMR_RX_OVR_BP[BP<0>] must be cleared
+ * to 0 (to forcibly disable hardware-automatic 802.3 PAUSE packet generation) with the HiGig2
+ * Protocol when BGX(0..5)_SMU(0..3)_HG2_CONTROL[HG2TX_EN] = 0. (The HiGig2 protocol is indicated
+ * by BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] = 1 and BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN]=16.) Hardware
+ * can only autogenerate backpressure via HiGig2 messages (optionally, when HG2TX_EN = 1) with
+ * the HiGig2 protocol.
  */
 union cvmx_bgxx_smux_hg2_control {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_hg2_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_19_63               : 45;
-	uint64_t hg2tx_en                     : 1;  /**< Enable Transmission of HG2 phys and logl messages
-                                                         When set, also disables HW auto-generated (802.3
-                                                         and PFC/CBFC) pause frames. (OCTEON cannot generate
-                                                         proper 802.3 or PFC/CBFC pause frames in HiGig2
-                                                         mode.) */
-	uint64_t hg2rx_en                     : 1;  /**< Enable extraction and processing of HG2 message
-                                                         packet from RX flow. Physical logical pause info
-                                                         is used to pause physical link, back pressure PKO
-                                                         HG2RX_EN must be set when HiGig2 messages are
-                                                         present in the receive stream. */
+	uint64_t hg2tx_en                     : 1;  /**< Enable transmission of HG2 physical and logical messages. When set, also disables hardware
+                                                         autogenerated (802.3 and PFC/CBFC) PAUSE frames. (CN78XX cannot generate proper 802.3 or
+                                                         PFC/CBFC PAUSE frames in HiGig2 mode.) */
+	uint64_t hg2rx_en                     : 1;  /**< Enable extraction and processing of HG2 message packet from RX flow. Physical and logical
+                                                         PAUSE information is used to PAUSE physical-link, backpressure PKO. This field must be set
+                                                         when HiGig2 messages are present in the receive stream. This bit is also forwarded to CMR
+                                                         so it can generate the required deferring signals to SMU TX and backpressure signals to
+                                                         PKO. */
 	uint64_t phys_en                      : 1;  /**< 1 bit physical link pause enable for recevied
                                                          HiGig2 physical pause message. This bit enables the SMU TX
                                                          to CMR HG2 deferring counter to be set every time SMU RX
@@ -5059,7 +5041,7 @@ union cvmx_bgxx_smux_hg2_control {
 	uint64_t logl_en                      : 16; /**< 16 bit xof enables for recevied HiGig2 messages
                                                          or PFC/CBFC packets. This field is NOT used by SMU at all.
                                                          It is forwarded to CMR without alteration. It appears here
-                                                         for backward compatibility tieh O68. */
+                                                         for backward compatibility with O68. */
 #else
 	uint64_t logl_en                      : 16;
 	uint64_t phys_en                      : 1;
@@ -5080,12 +5062,10 @@ union cvmx_bgxx_smux_rx_bad_col_hi {
 	struct cvmx_bgxx_smux_rx_bad_col_hi_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_17_63               : 47;
-	uint64_t val                          : 1;  /**< Set when BGX_RX_INT[PCTERR] is set. */
-	uint64_t state                        : 8;  /**< When BGX_RX_INT[PCTERR] is set, STATE will
-                                                         contain the receive state and the LMAC ID at the time of the
-                                                         error. */
-	uint64_t lane_rxc                     : 8;  /**< When BGX_RX_INT[PCTERR] is set, LANE_RXC will
-                                                         contain the column at the time of the error. */
+	uint64_t val                          : 1;  /**< Set when BGX(0..5)_SMU(0..3)_RX_INT[PCTERR] is set. */
+	uint64_t state                        : 8;  /**< When BGX(0..5)_SMU(0..3)_RX_INT[PCTERR] is set, contains the receive state at the time of
+                                                         the error. */
+	uint64_t lane_rxc                     : 8;  /**< When BGX(0..5)_SMU(0..3)_RX_INT[PCTERR] is set, contains the column at the time of the error. */
 #else
 	uint64_t lane_rxc                     : 8;
 	uint64_t state                        : 8;
@@ -5104,8 +5084,8 @@ union cvmx_bgxx_smux_rx_bad_col_lo {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_rx_bad_col_lo_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t lane_rxd                     : 64; /**< When BGX_RX_INT[PCTERR] is set, LANE_RXD will
-                                                         contain the column at the time of the error. */
+	uint64_t lane_rxd                     : 64; /**< When BGX(0..5)_SMU(0..3)_RX_INT[PCTERR] is set, LANE_RXD contains the XAUI/RXAUI column at
+                                                         the time of the error. */
 #else
 	uint64_t lane_rxd                     : 64;
 #endif
@@ -5122,11 +5102,11 @@ union cvmx_bgxx_smux_rx_ctl {
 	struct cvmx_bgxx_smux_rx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t status                       : 2;  /**< Link Status
-                                                         0=Link OK
-                                                         1=Local Fault
-                                                         2=Remote Fault
-                                                         3=Reserved */
+	uint64_t status                       : 2;  /**< Link status.
+                                                         0x0 = Link OK
+                                                         0x1 = Local fault
+                                                         0x2 = Remote fault
+                                                         0x3 = Reserved */
 #else
 	uint64_t status                       : 2;
 	uint64_t reserved_2_63                : 62;
@@ -5138,14 +5118,19 @@ typedef union cvmx_bgxx_smux_rx_ctl cvmx_bgxx_smux_rx_ctl_t;
 
 /**
  * cvmx_bgx#_smu#_rx_decision
+ *
+ * This register specifies the byte count used to determine when to accept or to filter a packet.
+ * As each byte in a packet is received by BGX, the L2 byte count (i.e. the number of bytes from
+ * the beginning of the L2 header (DMAC)) is compared against CNT. In normal operation, the L2
+ * header begins after the PREAMBLE + SFD (BGX(0..5)_SMU(0..3)_RX_FRM_CTL[PRE_CHK] = 1) and any
+ * optional UDD skip data (BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN]).
  */
 union cvmx_bgxx_smux_rx_decision {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_rx_decision_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t cnt                          : 5;  /**< The byte count to decide when to accept or filter
-                                                         a packet. */
+	uint64_t cnt                          : 5;  /**< The byte count to decide when to accept or filter a packet. Refer to SMU Decisions. */
 #else
 	uint64_t cnt                          : 5;
 	uint64_t reserved_5_63                : 59;
@@ -5157,18 +5142,21 @@ typedef union cvmx_bgxx_smux_rx_decision cvmx_bgxx_smux_rx_decision_t;
 
 /**
  * cvmx_bgx#_smu#_rx_frm_chk
+ *
+ * The CSRs provide the enable bits for a subset of errors passed to CMR encoded.
+ *
  */
 union cvmx_bgxx_smux_rx_frm_chk {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_rx_frm_chk_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t skperr                       : 1;  /**< Skipper error */
-	uint64_t rcverr                       : 1;  /**< Frame was received with Data reception error */
+	uint64_t skperr                       : 1;  /**< Skipper error. */
+	uint64_t rcverr                       : 1;  /**< Frame was received with data-reception error. */
 	uint64_t reserved_6_6                 : 1;
-	uint64_t fcserr_c                     : 1;  /**< Control Frame was received with FCS/CRC error */
-	uint64_t fcserr_d                     : 1;  /**< Data Frame was received with FCS/CRC error */
-	uint64_t jabber                       : 1;  /**< Frame was received with length > sys_length */
+	uint64_t fcserr_c                     : 1;  /**< Control frame was received with FCS/CRC error. */
+	uint64_t fcserr_d                     : 1;  /**< Data frame was received with FCS/CRC error. */
+	uint64_t jabber                       : 1;  /**< Frame was received with length > sys_length. */
 	uint64_t reserved_0_2                 : 3;
 #else
 	uint64_t reserved_0_2                 : 3;
@@ -5187,54 +5175,59 @@ typedef union cvmx_bgxx_smux_rx_frm_chk cvmx_bgxx_smux_rx_frm_chk_t;
 
 /**
  * cvmx_bgx#_smu#_rx_frm_ctl
+ *
+ * This register controls the handling of the frames.
+ * The CTL_BCK/CTL_DRP bits control how the hardware handles incoming PAUSE packets. The most
+ * common modes of operation:
+ * CTL_BCK = 1, CTL_DRP = 1: hardware handles everything
+ * CTL_BCK = 0, CTL_DRP = 0: software sees all PAUSE frames
+ * CTL_BCK = 0, CTL_DRP = 1: all PAUSE frames are completely ignored
+ * These control bits should be set to CTL_BCK = 0,CTL_DRP = 0 in half-duplex mode. Since PAUSE
+ * packets only apply to full duplex operation, any PAUSE packet would constitute an exception
+ * which should be handled by the processing cores. PAUSE packets should not be forwarded.
  */
 union cvmx_bgxx_smux_rx_frm_ctl {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_rx_frm_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t ptp_mode                     : 1;  /**< Timestamp mode
-                                                         When PTP_MODE is set, a 64-bit timestamp will be
-                                                         prepended to every incoming packet. The timestamp
-                                                         bytes are added to the packet in such a way as to
-                                                         not modify the packet's receive byte count.
-                                                         This implies that the BGX_RX_JABBER,
-                                                         BGX_RX_DECISION, and BGX_RX_UDD_SKP do not require
-                                                         any adjustment as
-                                                         they operate on the received packet size.
-                                                         When the packet reaches PKI, its size will
-                                                         reflect the additional bytes and is subject to
-                                                         the restrictions below.
-                                                         If PTP_MODE=1 and PRE_CHK=1, PRE_STRP must be 1.
-                                                         If PTP_MODE=1,
-                                                         PIP_PRT_CFGx[SKIP] should be increased by 8.
-                                                         PIP_PRT_CFGx[HIGIG_EN] should be 0.
-                                                         PIP_FRM_CHKx[MAXLEN] should be increased by 8.
-                                                         PIP_FRM_CHKx[MINLEN] should be increased by 8.
-                                                         PIP_TAG_INCx[EN] should be adjusted.
-                                                         PIP_PRT_CFGBx[ALT_SKP_EN] should be 0. */
+	uint64_t ptp_mode                     : 1;  /**< Timestamp mode. When PTP_MODE is set, a 64-bit timestamp is prepended to every incoming
+                                                         packet.
+                                                         The timestamp bytes are added to the packet in such a way as to not modify the packet's
+                                                         receive byte count. This implies that the BGX(0..5)_SMU(0..3)_RX_JABBER,
+                                                         BGX(0..5)_SMU(0..3)_RX_DECISION, and BGX(0..5)_SMU(0..3)_RX_UDD_SKP do not require any
+                                                         adjustment as they operate on the received packet size. When the packet reaches PKI, its
+                                                         size reflects the additional bytes and is subject to the following restrictions:
+                                                         If PTP_MODE = 1 and PRE_CHK = 1, PRE_STRP must be 1.
+                                                         If PTP_MODE = 1
+                                                         PKI_CL(0..3)_PKIND(0..63)_SKIP[FCS_SKIP,INST_SKIP] should be increased by 8
+                                                         PKI_CL(0..3)_PKIND(0..63)_CFG[HG_EN] should be 0
+                                                         PKI_FRM_LEN_CHK(0..1)[MAXLEN] should be increased by 8
+                                                         PKI_FRM_LEN_CHK(0..1)[MINLEN] should be increased by 8
+                                                         PKI_TAG_INC(0..63)_MASK should be adjusted
+                                                         This supported in uCode in O78 >>> PIP_PRT_CFGB(0..63)[ALT_SKP_EN] should be 0. */
 	uint64_t reserved_6_11                : 6;
-	uint64_t ctl_smac                     : 1;  /**< Control Pause Frames can match station SMAC */
-	uint64_t ctl_mcst                     : 1;  /**< Control Pause Frames can match globally assign
-                                                         Multicast address */
-	uint64_t ctl_bck                      : 1;  /**< Forward pause information to TX block */
-	uint64_t ctl_drp                      : 1;  /**< Drop Control Pause Frames */
-	uint64_t pre_strp                     : 1;  /**< Strip off the preamble (when present)
-                                                         0=PREAMBLE+SFD is sent to core as part of frame
-                                                         1=PREAMBLE+SFD is dropped
-                                                         PRE_CHK must be set to enable this and all
-                                                         PREAMBLE features.
-                                                         If PTP_MODE=1 and PRE_CHK=1, PRE_STRP must be 1. */
-	uint64_t pre_chk                      : 1;  /**< This port is configured to send a valid 802.3
-                                                         PREAMBLE to begin every frame. BGX checks that a
-                                                         valid PREAMBLE is received (based on PRE_FREE).
-                                                         When a problem does occur within the PREAMBLE
-                                                         seqeunce, the frame is marked as bad and not sent
-                                                         into the core.  The BGX_RX_INT[PCTERR]
-                                                         interrupt is also raised.
-                                                         When BGX_TX_CTL[HG_EN] is set, PRE_CHK
-                                                         must be zero.
-                                                         If PTP_MODE=1 and PRE_CHK=1, PRE_STRP must be 1. */
+	uint64_t ctl_smac                     : 1;  /**< Control PAUSE frames can match station SMAC. */
+	uint64_t ctl_mcst                     : 1;  /**< Control PAUSE frames can match globally assign multicast address. */
+	uint64_t ctl_bck                      : 1;  /**< Forward PAUSE information to TX block. */
+	uint64_t ctl_drp                      : 1;  /**< Drop control PAUSE frames. */
+	uint64_t pre_strp                     : 1;  /**< Strip off the preamble (when present).
+                                                         0 = PREAMBLE + SFD is sent to core as part of frame
+                                                         1 = PREAMBLE + SFD is dropped
+                                                         [PRE_CHK] must be set to enable this and all PREAMBLE features.
+                                                         If PTP_MODE = 1 and PRE_CHK = 1, PRE_STRP must be 1.
+                                                         When PRE_CHK is set (indicating that the PREAMBLE will be sent), PRE_STRP determines if
+                                                         the PREAMBLE+SFD bytes are thrown away or sent to the core as part of the packet. In
+                                                         either mode, the PREAMBLE+SFD bytes are not counted toward the packet size when checking
+                                                         against the MIN and MAX bounds. Furthermore, the bytes are skipped when locating the start
+                                                         of the L2 header for DMAC and control frame recognition. */
+	uint64_t pre_chk                      : 1;  /**< Check the preamble for correctness.
+                                                         This port is configured to send a valid 802.3 PREAMBLE to begin every frame. BGX checks
+                                                         that a valid PREAMBLE is received (based on PRE_FREE). When a problem does occur within
+                                                         the PREAMBLE sequence, the frame is marked as bad and not sent into the core. The
+                                                         BGX(0..5)_SMU(0..3)_RX_INT[PCTERR] interrupt is also raised.
+                                                         When BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] is set, PRE_CHK must be 0.
+                                                         If PTP_MODE = 1 and PRE_CHK = 1, PRE_STRP must be 1. */
 #else
 	uint64_t pre_chk                      : 1;
 	uint64_t pre_strp                     : 1;
@@ -5254,47 +5247,43 @@ typedef union cvmx_bgxx_smux_rx_frm_ctl cvmx_bgxx_smux_rx_frm_ctl_t;
 /**
  * cvmx_bgx#_smu#_rx_int
  *
- * "**************************************************************
- * BGX RX per LMAC registers                                    *
- * **************************************************************
- * BGX_SMU_RX_INT = Interrupt Register"
+ * SMU Interrupt Register.
+ *
  */
 union cvmx_bgxx_smux_rx_int {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_rx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t hg2cc                        : 1;  /**< HiGig2 received message CRC or Control char  error
-                                                         Set when either CRC8 error detected or when
-                                                         a Control Character is found in the message
-                                                         bytes after the K.SOM
-                                                         NOTE: HG2CC has higher priority than HG2FLD
-                                                         i.e. a HiGig2 message that results in HG2CC
-                                                         getting set, will never set HG2FLD. */
-	uint64_t hg2fld                       : 1;  /**< HiGig2 received message field error, as below
-                                                         1) MSG_TYPE field not 6'b00_0000
-                                                         i.e. it is not a FLOW CONTROL message, which
-                                                         is the only defined type for HiGig2
-                                                         2) FWD_TYPE field not 2'b00 i.e. Link Level msg
-                                                         which is the only defined type for HiGig2
-                                                         3) FC_OBJECT field is neither 4'b0000 for
-                                                         Physical Link nor 4'b0010 for Logical Link.
-                                                         Those are the only two defined types in HiGig2 */
-	uint64_t bad_term                     : 1;  /**< Frame is terminated by control character other
-                                                         than /T/.  The error propagation control
-                                                         character /E/ will be included as part of the
-                                                         frame and does not cause a frame termination. */
-	uint64_t bad_seq                      : 1;  /**< Reserved Sequence Deteted */
-	uint64_t rem_fault                    : 1;  /**< Remote Fault Sequence Deteted */
-	uint64_t loc_fault                    : 1;  /**< Local Fault Sequence Deteted */
-	uint64_t rsverr                       : 1;  /**< Reserved opcodes */
-	uint64_t pcterr                       : 1;  /**< Bad Preamble / Protocol
-                                                         The column of data that was
-                                                         bad will be logged in BGX_RX_BAD_COL */
-	uint64_t skperr                       : 1;  /**< Skipper error */
-	uint64_t rcverr                       : 1;  /**< Frame was received with Data reception error */
+	uint64_t hg2cc                        : 1;  /**< HiGig2 received message CRC or control-character error. Set when either a CRC8 error is
+                                                         detected, or when a control character is found in the message bytes after the K.SOM.
+                                                         HG2CC has higher priority than HG2FLD, which means that a HiGig2 message that results in
+                                                         HG2CC getting set never sets HG2FLD. */
+	uint64_t hg2fld                       : 1;  /**< HiGig2 received message field error:
+                                                         MSG_TYPE field not 0x0, i.e. it is not a flow-control message, which is the only defined
+                                                         type for HiGig2
+                                                         FWD_TYPE field not 0x0, i.e. it is not a link-level message, which is the only defined
+                                                         type for HiGig2
+                                                         FC_OBJECT field is neither 0x0 for physical link, nor 0x2 for logical link. Those are the
+                                                         only two defined types in HiGig2 */
+	uint64_t bad_term                     : 1;  /**< Frame is terminated by control character other than /T/. (XAUI/RXAUI mode only) The error
+                                                         propagation control character /E/ will be included as part of the frame and does not cause
+                                                         a frame termination. */
+	uint64_t bad_seq                      : 1;  /**< Reserved sequence detected. (XAUI/RXAUI mode only) */
+	uint64_t rem_fault                    : 1;  /**< Remote-fault sequence detected. (XAUI/RXAUI mode only) */
+	uint64_t loc_fault                    : 1;  /**< Local-fault sequence detected. (XAUI/RXAUI mode only) */
+	uint64_t rsverr                       : 1;  /**< Reserved opcodes. */
+	uint64_t pcterr                       : 1;  /**< Bad preamble/protocol. In XAUI/RXAUI mode, the column of data that was bad is logged in
+                                                         BGX(0..5)_SMU(0..3)_RX_BAD_COL_*. PCTERR checks that the frame begins with a valid
+                                                         PREAMBLE sequence. Does not check the number of PREAMBLE cycles. */
+	uint64_t skperr                       : 1;  /**< Skipper error. */
+	uint64_t rcverr                       : 1;  /**< Frame was received with data-reception error. */
 	uint64_t fcserr                       : 1;  /**< Frame was received with FCS/CRC error */
-	uint64_t jabber                       : 1;  /**< Frame was received with length > sys_length */
+	uint64_t jabber                       : 1;  /**< Frame was received with length > sys_length. An RX Jabber error indicates that a packet
+                                                         was received which is longer than the maximum allowed packet as defined by the system. BGX
+                                                         terminates the packet with an EOP on the beat on which JABBER was exceeded. The beat on
+                                                         which JABBER was exceeded is left unchanged and all subsequent data beats are dropped.
+                                                         Failure to truncate could lead to system instability. */
 #else
 	uint64_t jabber                       : 1;
 	uint64_t fcserr                       : 1;
@@ -5323,10 +5312,9 @@ union cvmx_bgxx_smux_rx_jabber {
 	struct cvmx_bgxx_smux_rx_jabber_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t cnt                          : 16; /**< Byte count for jabber check
-                                                         Failing packets set the JABBER interrupt and are
-                                                         optionally sent with opcode==JABBER
-                                                         BGX will truncate the packet to CNT+1 to CNT+8 bytes */
+	uint64_t cnt                          : 16; /**< Byte count for jabber check. Failing packets set the JABBER interrupt and are optionally
+                                                         sent with opcode = JABBER. BGX truncates the packet to CNT+1 to CNT+8 bytes.
+                                                         CNT must be 8-byte aligned such that CNT[2:0] = 000. */
 #else
 	uint64_t cnt                          : 16;
 	uint64_t reserved_16_63               : 48;
@@ -5344,19 +5332,20 @@ union cvmx_bgxx_smux_rx_udd_skp {
 	struct cvmx_bgxx_smux_rx_udd_skp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t fcssel                       : 1;  /**< Include the skip bytes in the FCS calculation
-                                                         0 = all skip bytes are included in FCS
-                                                         1 = the skip bytes are not included in FCS
-                                                         When BGX_TX_CTL[HG_EN] is set, FCSSEL must
-                                                         be zero. */
+	uint64_t fcssel                       : 1;  /**< Include the skip bytes in the FCS calculation.
+                                                         0 = All skip bytes are included in FCS
+                                                         1 = The skip bytes are not included in FCS
+                                                         When BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] is set, this field must be 0.
+                                                         The skip bytes are part of the packet and are sent through the IOI packet interface and
+                                                         are handled by PKI. The system can determine if the UDD bytes are included in the FCS
+                                                         check by using the FCSSEL field, if the FCS check is enabled. */
 	uint64_t reserved_7_7                 : 1;
-	uint64_t len                          : 7;  /**< Amount of User-defined data before the start of
-                                                         the L2 data.  Zero means L2 comes first.
-                                                         Max value is 64.
-                                                         When BGX_TX_CTL[HG_EN] is set, LEN must be
-                                                         set to 12 or 16 (depending on HiGig header size)
-                                                         to account for the HiGig header. LEN=12 selects
-                                                         HiGig/HiGig+, and LEN=16 selects HiGig2. */
+	uint64_t len                          : 7;  /**< Amount of user-defined data before the start of the L2C data, in bytes.
+                                                         Setting to 0 means L2C comes first; maximum value is 64.
+                                                         LEN must be 0x0 in half-duplex operation.
+                                                         When BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] is set, this field must be set to 12 or 16
+                                                         (depending on HiGig header size) to account for the HiGig header.
+                                                         LEN = 12 selects HiGig/HiGig+; LEN = 16 selects HiGig2. */
 #else
 	uint64_t len                          : 7;
 	uint64_t reserved_7_7                 : 1;
@@ -5376,8 +5365,7 @@ union cvmx_bgxx_smux_smac {
 	struct cvmx_bgxx_smux_smac_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t smac                         : 48; /**< The SMAC field is used for generating and
-                                                         accepting Control Pause packets */
+	uint64_t smac                         : 48; /**< The SMAC field is used for generating and accepting control PAUSE packets. */
 #else
 	uint64_t smac                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -5389,19 +5377,21 @@ typedef union cvmx_bgxx_smux_smac cvmx_bgxx_smux_smac_t;
 
 /**
  * cvmx_bgx#_smu#_tx_append
+ *
+ * For more details on the interactions between FCS and PAD, see also the description of
+ * BGX(0..5)_SMU(0..3)_TX_MIN_PKT[MIN_SIZE].
  */
 union cvmx_bgxx_smux_tx_append {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_tx_append_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t fcs_c                        : 1;  /**< Append the Ethernet FCS on each pause packet
-                                                         Pause packets are normally padded to 60 bytes. */
-	uint64_t fcs_d                        : 1;  /**< Append the Ethernet FCS on each data packet */
-	uint64_t pad                          : 1;  /**< Append PAD bytes such that min sized */
-	uint64_t preamble                     : 1;  /**< Prepend the Ethernet preamble on each transfer
-                                                         When BGX_TX_CTL[HG_EN] is set, PREAMBLE
-                                                         must be zero. */
+	uint64_t fcs_c                        : 1;  /**< Append the Ethernet FCS on each PAUSE packet. PAUSE packets are normally padded to 60
+                                                         bytes. If BGX(0..5)_SMU(0..3)_TX_MIN_PKT[MIN_SIZE] exceeds 59, then FCS_C is not used. */
+	uint64_t fcs_d                        : 1;  /**< Append the Ethernet FCS on each data packet. */
+	uint64_t pad                          : 1;  /**< Append PAD bytes such that minimum-sized packet is transmitted. */
+	uint64_t preamble                     : 1;  /**< Prepend the Ethernet preamble on each transfer. When BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN] is
+                                                         set, PREAMBLE must be 0. */
 #else
 	uint64_t preamble                     : 1;
 	uint64_t pad                          : 1;
@@ -5433,44 +5423,35 @@ union cvmx_bgxx_smux_tx_ctl {
                                                          alignment marker period of 16363 blocks (exclusive) per lane, as
                                                          specified in 802.3ba-2010. The default value should always be used
                                                          for normal operation. */
-	uint64_t hg_pause_hgi                 : 2;  /**< HGI Field for HW generated HiGig pause packets */
-	uint64_t hg_en                        : 1;  /**< Enable HiGig Mode
-                                                         When HG_EN is set and BGX_RX_UDD_SKP[SKIP]=12
-                                                         the interface is in HiGig/HiGig+ mode and the
-                                                         following must be set:
-                                                         BGX_RX_FRM_CTL[PRE_CHK] == 0
-                                                         BGX_RX_UDD_SKP[FCSSEL] == 0
-                                                         BGX_RX_UDD_SKP[SKIP] == 12
-                                                         BGX_TX_APPEND[PREAMBLE] == 0
-                                                         When HG_EN is set and BGX_RX_UDD_SKP[SKIP]=16
-                                                         the interface is in HiGig2 mode and the
-                                                         following must be set:
-                                                         BGX_RX_FRM_CTL[PRE_CHK] == 0
-                                                         BGX_RX_UDD_SKP[FCSSEL] == 0
-                                                         BGX_RX_UDD_SKP[SKIP] == 16
-                                                         BGX_TX_APPEND[PREAMBLE] == 0
-                                                         BGX_SMUX_CBFC_CTL[RX_EN] == 0
-                                                         BGX_SMUX_CBFC_CTL[TX_EN] == 0 */
+	uint64_t hg_pause_hgi                 : 2;  /**< HGI field for hardware-generated HiGig PAUSE packets. */
+	uint64_t hg_en                        : 1;  /**< Enable HiGig mode.
+                                                         When this field is set and BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] = 12, the interface is in
+                                                         HiGig/HiGig+ mode and the following must be set:
+                                                         BGX(0..5)_SMU(0..3)_RX_FRM_CTL[PRE_CHK] = 0
+                                                         BGX(0..5)_SMU(0..3)_RX_UDD_SKP[FCSSEL] = 0
+                                                         BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] = 12
+                                                         BGX(0..5)_SMU(0..3)_TX_APPEND[PREAMBLE] = 0
+                                                         When this field is set and BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] = 16, the interface is in
+                                                         HiGig2 mode and the following must be set:
+                                                         BGX(0..5)_SMU(0..3)_RX_FRM_CTL[PRE_CHK] = 0
+                                                         BGX(0..5)_SMU(0..3)_RX_UDD_SKP[FCSSEL] = 0
+                                                         BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] = 16
+                                                         BGX(0..5)_SMU(0..3)_TX_APPEND[PREAMBLE] = 0
+                                                         BGX(0..5)_SMU(0..3)_SMUX_CBFC_CTL[RX_EN] = 0
+                                                         BGX(0..5)_SMU(0..3)_CBFC_CTL[TX_EN] = 0 */
 	uint64_t l2p_bp_conv                  : 1;  /**< If set will cause TX to generate 802.3 pause packets when CMR applies logical backpressure
-                                                         (XOFF), if and only if BGX_SMUX_CBFC_CTL[TX_EN] == 0 and
-                                                         BGX(0..5)_SMU(0..3)_HG2_CONTROL[HG2TX_EN] == 0. */
-	uint64_t ls_byp                       : 1;  /**< Bypass the link status as determined by the XGMII
-                                                         receiver and set the link status of the
-                                                         transmitter to LS. */
-	uint64_t ls                           : 2;  /**< Link Status
-                                                         0 = Link Ok
-                                                         Link runs normally. RS passes MAC data to PCS
-                                                         1 = Local Fault
-                                                         RS layer sends continuous remote fault
-                                                         sequences.
-                                                         2 = Remote Fault
-                                                         RS layer sends continuous idles sequences
-                                                         3 = Link Drain
-                                                         RS layer drops full packets to allow BGX and
-                                                         PKO to drain their FIFOs */
+                                                         (XOFF), if and only if BGX(0..5)_SMU(0..3)_CBFC_CTL[TX_EN] is clear and
+                                                         BGX(0..5)_SMU(0..3)_HG2_CONTROL[HG2TX_EN] is clear. */
+	uint64_t ls_byp                       : 1;  /**< Bypass the link status, as determined by the XGMII receiver, and set the link status of
+                                                         the transmitter to LS. */
+	uint64_t ls                           : 2;  /**< Link status.
+                                                         0 = Link OK; link runs normally. RS passes MAC data to PCS.
+                                                         1 = Local fault. RS layer sends continuous remote fault sequences.
+                                                         2 = Remote fault. RS layer sends continuous idle sequences.
+                                                         3 = Link drain. RS layer drops full packets to allow BGX and PKO to drain their FIFOs. */
 	uint64_t reserved_2_3                 : 2;
-	uint64_t uni_en                       : 1;  /**< Enable Unidirectional Mode (IEEE Clause 66) */
-	uint64_t dic_en                       : 1;  /**< Enable the deficit idle counter for IFG averaging */
+	uint64_t uni_en                       : 1;  /**< Enable unidirectional mode (IEEE Clause 66). */
+	uint64_t dic_en                       : 1;  /**< Enable the deficit idle counter for IFG averaging. */
 #else
 	uint64_t dic_en                       : 1;
 	uint64_t uni_en                       : 1;
@@ -5490,6 +5471,12 @@ typedef union cvmx_bgxx_smux_tx_ctl cvmx_bgxx_smux_tx_ctl_t;
 
 /**
  * cvmx_bgx#_smu#_tx_ifg
+ *
+ * Programming IFG1 and IFG2:
+ * For XAUI/RXAUI/10Gbs/40Gbs systems that require IEEE 802.3 compatibility, the IFG1+IFG2 sum
+ * must be 12.
+ * In loopback mode, the IFG1+IFG2 of local and remote parties must match exactly; otherwise one
+ * of the two sides' loopback FIFO will overrun: BGX(0..5)_SMU(0..3)_TX_INT[LB_OVRFLW].
  */
 union cvmx_bgxx_smux_tx_ifg {
 	uint64_t u64;
@@ -5516,14 +5503,12 @@ union cvmx_bgxx_smux_tx_int {
 	struct cvmx_bgxx_smux_tx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t lb_ovrflw                    : 1;  /**< TX Loopback Overflow */
-	uint64_t lb_undflw                    : 1;  /**< TX Loopback Underflow */
-	uint64_t fake_commit                  : 1;  /**< TX SMU started a packet with PTP on SOP and has not seen a commit for it
-                                                         from TX SPU after 2^SMU_TX_PTP_TIMEOUT_WIDTH (2^8) cycles so it faked a
-                                                         commit to CMR */
-	uint64_t xchange                      : 1;  /**< link status changed - this denotes a
-                                                         change to BGX_RX_CTL[STATUS] */
-	uint64_t undflw                       : 1;  /**< TX Underflow */
+	uint64_t lb_ovrflw                    : 1;  /**< TX loopback overflow. */
+	uint64_t lb_undflw                    : 1;  /**< TX loopback underflow. */
+	uint64_t fake_commit                  : 1;  /**< TX SMU started a packet with PTP on SOP and has not seen a commit for it from TX SPU after
+                                                         2^SMU_TX_PTP_TIMEOUT_WIDTH (2^8) cycles so it faked a commit to CMR. */
+	uint64_t xchange                      : 1;  /**< Link status changed. This denotes a change to BGX(0..5)_SMU(0..3)_RX_CTL[STATUS]. */
+	uint64_t undflw                       : 1;  /**< TX underflow. */
 #else
 	uint64_t undflw                       : 1;
 	uint64_t xchange                      : 1;
@@ -5545,12 +5530,9 @@ union cvmx_bgxx_smux_tx_min_pkt {
 	struct cvmx_bgxx_smux_tx_min_pkt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t min_size                     : 8;  /**< Min frame in bytes inclusive of FCS, if applied.
-                                                         Padding is only appended when BGX_TX_APPEND[PAD]
-                                                         for the coresponding port is set.
-                                                         When FCS is added to a packet which was padded,
-                                                         the FCS will always appear in the 4 octets
-                                                         preceding /T/ or /E/ */
+	uint64_t min_size                     : 8;  /**< Min frame in bytes inclusive of FCS, if applied. Padding is only appended when
+                                                         BGX_TX_APPEND[PAD] for the corresponding port is set. When FCS is added to a packet which
+                                                         was padded, the FCS always appears in the 4 octets preceding /T/ or /E/. */
 #else
 	uint64_t min_size                     : 8;
 	uint64_t reserved_8_63                : 56;
@@ -5562,13 +5544,16 @@ typedef union cvmx_bgxx_smux_tx_min_pkt cvmx_bgxx_smux_tx_min_pkt_t;
 
 /**
  * cvmx_bgx#_smu#_tx_pause_pkt_dmac
+ *
+ * This register provides the DMAC value that is placed in outbound PAUSE packets.
+ *
  */
 union cvmx_bgxx_smux_tx_pause_pkt_dmac {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_tx_pause_pkt_dmac_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t dmac                         : 48; /**< The DMAC field placed is outbnd pause pkts */
+	uint64_t dmac                         : 48; /**< The DMAC field, which is placed is outbound PAUSE packets. */
 #else
 	uint64_t dmac                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -5580,27 +5565,24 @@ typedef union cvmx_bgxx_smux_tx_pause_pkt_dmac cvmx_bgxx_smux_tx_pause_pkt_dmac_
 
 /**
  * cvmx_bgx#_smu#_tx_pause_pkt_interval
+ *
+ * This register specifies how often PAUSE packets are sent.
+ *
  */
 union cvmx_bgxx_smux_tx_pause_pkt_interval {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_tx_pause_pkt_interval_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_33_63               : 31;
-	uint64_t hg2_intra_en                 : 1;  /**< Allow intrapacket HiGig2 message generation
-                                                         Relevant only if HiGig2 message generation is enabled */
-	uint64_t hg2_intra_interval           : 16; /**< Arbitrate for a HiGig2 message, every (INTERVAL*512)
-                                                         bit-times whilst sending regular packet data
-                                                         Relevant only if HiGig2 message generation and HG2_INTRA_EN
-                                                         are both set.
-                                                         Normally, 0 < INTERVAL < BGX_TX_PAUSE_PKT_TIME
-                                                         INTERVAL=0, will only send a single PAUSE packet
-                                                         for each backpressure event */
-	uint64_t interval                     : 16; /**< Arbitrate for a 802.3 pause packet, HiGig2 message,
-                                                         or PFC/CBFC pause packet every (INTERVAL*512)
-                                                         bit-times.
-                                                         Normally, 0 < INTERVAL < BGX_TX_PAUSE_PKT_TIME
-                                                         INTERVAL=0, will only send a single PAUSE packet
-                                                         for each backpressure event */
+	uint64_t hg2_intra_en                 : 1;  /**< Allow intrapacket HiGig2 message generation. Relevant only if HiGig2 message generation is enabled. */
+	uint64_t hg2_intra_interval           : 16; /**< Arbitrate for a HiGig2 message, every (INTERVAL*512) bit-times whilst sending regular
+                                                         packet data. Relevant only if HiGig2 message generation and HG2_INTRA_EN are both set.
+                                                         Normally, 0 < INTERVAL < BGX_TX_PAUSE_PKT_TIME.
+                                                         INTERVAL = 0 only sends a single PAUSE packet for each backpressure event. */
+	uint64_t interval                     : 16; /**< Arbitrate for a 802.3 PAUSE packet, HiGig2 message, or PFC/CBFC PAUSE packet every
+                                                         (INTERVAL * 512) bit-times.
+                                                         Normally, 0 < INTERVAL < BGX(0..5)_SMU(0..3)_TX_PAUSE_PKT_TIME[TIME].
+                                                         INTERVAL = 0 only sends a single PAUSE packet for each backpressure event. */
 #else
 	uint64_t interval                     : 16;
 	uint64_t hg2_intra_interval           : 16;
@@ -5620,11 +5602,10 @@ union cvmx_bgxx_smux_tx_pause_pkt_time {
 	struct cvmx_bgxx_smux_tx_pause_pkt_time_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t p_time                       : 16; /**< The pause_time field placed in outbnd 802.3 pause
-                                                         packets, HiGig2 messages, or PFC/CBFC pause
-                                                         packets.
-                                                         pause_time is in 512 bit-times
-                                                         Normally, P_TIME > BGX_TX_PAUSE_PKT_INTERVAL */
+	uint64_t p_time                       : 16; /**< Provides the pause_time field placed in outbound 802.3 PAUSE packets, HiGig2 messages, or
+                                                         PFC/CBFC PAUSE packets in 512 bit-times. Normally, P_TIME >
+                                                         BGX(0..5)_SMU(0..3)_TX_PAUSE_PKT_INTERVAL[INTERVAL]. See programming notes in
+                                                         BGX(0..5)_SMU(0..3)_TX_PAUSE_PKT_INTERVAL. */
 #else
 	uint64_t p_time                       : 16;
 	uint64_t reserved_16_63               : 48;
@@ -5636,13 +5617,16 @@ typedef union cvmx_bgxx_smux_tx_pause_pkt_time cvmx_bgxx_smux_tx_pause_pkt_time_
 
 /**
  * cvmx_bgx#_smu#_tx_pause_pkt_type
+ *
+ * This register provides the P_TYPE field that is placed in outbound PAUSE packets.
+ *
  */
 union cvmx_bgxx_smux_tx_pause_pkt_type {
 	uint64_t u64;
 	struct cvmx_bgxx_smux_tx_pause_pkt_type_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t p_type                       : 16; /**< The P_TYPE field placed is outbnd pause pkts */
+	uint64_t p_type                       : 16; /**< The P_TYPE field that is placed in outbound PAUSE packets. */
 #else
 	uint64_t p_type                       : 16;
 	uint64_t reserved_16_63               : 48;
@@ -5660,11 +5644,9 @@ union cvmx_bgxx_smux_tx_pause_togo {
 	struct cvmx_bgxx_smux_tx_pause_togo_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t msg_time                     : 16; /**< Amount of time remaining to backpressure
-                                                         From the higig2 physical message pause timer
-                                                         (only valid on port0) */
-	uint64_t p_time                       : 16; /**< Amount of time remaining to backpressure
-                                                         From the standard 802.3 pause timer */
+	uint64_t msg_time                     : 16; /**< Amount of time remaining to backpressure, from the HiGig2 physical message PAUSE timer
+                                                         (only valid on port0). */
+	uint64_t p_time                       : 16; /**< Amount of time remaining to backpressure, from the standard 802.3 PAUSE timer. */
 #else
 	uint64_t p_time                       : 16;
 	uint64_t msg_time                     : 16;
@@ -5683,9 +5665,8 @@ union cvmx_bgxx_smux_tx_pause_zero {
 	struct cvmx_bgxx_smux_tx_pause_zero_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t send                         : 1;  /**< When backpressure condition clear, send PAUSE
-                                                         packet with pause_time of zero to enable the
-                                                         channel */
+	uint64_t send                         : 1;  /**< Send PAUSE-zero enable. When this bit is set, and the backpressure condition is clear, it
+                                                         allows sending a PAUSE packet with pause_time of 0 to enable the channel. */
 #else
 	uint64_t send                         : 1;
 	uint64_t reserved_1_63                : 63;
@@ -5703,7 +5684,7 @@ union cvmx_bgxx_smux_tx_soft_pause {
 	struct cvmx_bgxx_smux_tx_soft_pause_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t p_time                       : 16; /**< Back off the TX bus for (P_TIME*512) bit-times */
+	uint64_t p_time                       : 16; /**< Back off the TX bus for (P_TIME * 512) bit-times */
 #else
 	uint64_t p_time                       : 16;
 	uint64_t reserved_16_63               : 48;
@@ -5721,17 +5702,14 @@ union cvmx_bgxx_smux_tx_thresh {
 	struct cvmx_bgxx_smux_tx_thresh_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_11_63               : 53;
-	uint64_t cnt                          : 11; /**< Number of 128b words to accumulate in the TX FIFO
-                                                         before sending on the packet interface
-                                                         This register should be large enough to prevent
-                                                         underflow on the packet interface and must never
-                                                         be set to zero.
-                                                         10G/40G Mode, CNT == 0x100
-                                                         In all modes, this register cannot exceed the
-                                                         the TX FIFO depth which is...
-                                                         BGX_CMR_TX_LMACS==0,1:  CNT MAX = 0x7FF
-                                                         BGX_CMR_TX_LMACS==2  :  CNT MAX = 0x3FF
-                                                         BGX_CMR_TX_LMACS==3  :  CNT MAX = 0x1FF */
+	uint64_t cnt                          : 11; /**< Number of 128-bit words to accumulate in the TX FIFO before sending on the packet
+                                                         interface. This field should be large enough to prevent underflow on the packet interface
+                                                         and must never be set to 0x0.
+                                                         In 10G/40G mode, CNT = 0x100.
+                                                         In all modes, this register cannot exceed the TX FIFO depth as follows.
+                                                         BGX(0..5)_CMR_TX_PRTS = 0,1:  CNT maximum = 0x7FF
+                                                         BGX(0..5)_CMR_TX_PRTS = 2:     CNT maximum = 0x3FF
+                                                         BGX(0..5)_CMR_TX_PRTS = 3,4:  CNT maximum = 0x1FF */
 #else
 	uint64_t cnt                          : 11;
 	uint64_t reserved_11_63               : 53;
@@ -5744,47 +5722,40 @@ typedef union cvmx_bgxx_smux_tx_thresh cvmx_bgxx_smux_tx_thresh_t;
 /**
  * cvmx_bgx#_spu#_an_adv
  *
- * "Auto Negotiation Advertisement:
- * Software programs the AN_ADV register with the contents of the AN link
- * codeword base page to be transmitted during Auto-Negotiation. See section 802.3
- * section 73.6 for details.
- * Any writes to this register prior to completion of Auto-Negotiation, as indicated
- * by the AN_COMPLETE bit in AN_STATUS, should be followed by a
- * renegotiation for the new values to take effect. Renegotiation is initiated by
- * setting the AN_RESTART bit in AN_CONTROL.
- * Once Auto-Negotiation has completed, software may examine this register along with
- * the LP base page ability register to determine the highest common denominator
- * technology."
+ * Software programs this register with the contents of the AN-link code word base page to be
+ * transmitted during Auto-Negotiation. (See Std 802.3 section 73.6 for details.) Any write
+ * operations to this register prior to completion of Auto-Negotiation, as indicated by
+ * BGX(0..5)_SPU(0..3)_AN_STATUS[AN_COMPLETE], should be followed by a renegotiation in order for
+ * the new values to take effect. Renegotiation is initiated by setting
+ * BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_RESTART]. Once Auto-Negotiation has completed, software can
+ * examine this register along with BGX(0..5)_SPU(0..3)_AN_LP_BASE to determine the highest
+ * common denominator technology.
  */
 union cvmx_bgxx_spux_an_adv {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_an_adv_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t fec_req                      : 1;  /**< FEC Requested */
-	uint64_t fec_able                     : 1;  /**< FEC Ability */
-	uint64_t arsv                         : 19; /**< Technology Ability reserved bits
-                                                         Should always be 0. */
-	uint64_t a100g_cr10                   : 1;  /**< 100GBASE-CR10 Ability
-                                                         Should always be 0; 100GBASE-R is not supported. */
-	uint64_t a40g_cr4                     : 1;  /**< 40GBASE-CR4 Ability */
-	uint64_t a40g_kr4                     : 1;  /**< 40GBASE-KR4 Ability */
-	uint64_t a10g_kr                      : 1;  /**< 10GBASE-KR Ability */
-	uint64_t a10g_kx4                     : 1;  /**< 10GBASE-KX4 Ability */
-	uint64_t a1g_kx                       : 1;  /**< 1000BASE-KX Ability */
-	uint64_t t                            : 5;  /**< "Transmitted Nonce: This field is automatically updated with a
-                                                         pseudo-random value on entry to the AN Ability Detect state." */
-	uint64_t np                           : 1;  /**< Next Page. */
-	uint64_t ack                          : 1;  /**< Ack: Always 0 in this register. */
-	uint64_t rf                           : 1;  /**< Remote Fault */
-	uint64_t xnp_able                     : 1;  /**< Extended Next Page ability. */
-	uint64_t asm_dir                      : 1;  /**< Asymmetric Pause */
-	uint64_t pause                        : 1;  /**< Pause Ability */
-	uint64_t e                            : 5;  /**< Echoed Nonce
-                                                         Echoed Nonce value to use when ACK=0 in transmitted DME page. Should
-                                                         always be 0. */
-	uint64_t s                            : 5;  /**< Selector
-                                                         Should be 0x1 (encoding for IEEE Std 802.3). */
+	uint64_t fec_req                      : 1;  /**< FEC requested. */
+	uint64_t fec_able                     : 1;  /**< FEC ability. */
+	uint64_t arsv                         : 19; /**< Technology ability. Reserved bits, should always be 0. */
+	uint64_t a100g_cr10                   : 1;  /**< 100GBASE-CR10 ability. Should always be 0; 100GBASE-R is not supported. */
+	uint64_t a40g_cr4                     : 1;  /**< 40GBASE-CR4 ability. */
+	uint64_t a40g_kr4                     : 1;  /**< 40GBASE-KR4 ability. */
+	uint64_t a10g_kr                      : 1;  /**< 10GBASE-KR ability. */
+	uint64_t a10g_kx4                     : 1;  /**< 10GBASE-KX4 ability. */
+	uint64_t a1g_kx                       : 1;  /**< 1000BASE-KX ability. Should always be 0; Auto-Negotiation is not supported for 1000Base-KX. */
+	uint64_t t                            : 5;  /**< Transmitted nonce. This field is automatically updated with a pseudo-random value on entry
+                                                         to the AN ability detect state. */
+	uint64_t np                           : 1;  /**< Next page. Always 0; extended next pages are not used for 10G+ Auto-Negotiation. */
+	uint64_t ack                          : 1;  /**< Acknowledge. Always 0 in this register. */
+	uint64_t rf                           : 1;  /**< Remote fault. */
+	uint64_t xnp_able                     : 1;  /**< Extended next page ability. */
+	uint64_t asm_dir                      : 1;  /**< Asymmetric PAUSE. */
+	uint64_t pause                        : 1;  /**< PAUSE ability. */
+	uint64_t e                            : 5;  /**< Echoed nonce. Provides the echoed-nonce value to use when ACK = 0 in transmitted DME page.
+                                                         Should always be 0x0. */
+	uint64_t s                            : 5;  /**< Selector. Should be 0x1 (encoding for IEEE Std 802.3). */
 #else
 	uint64_t s                            : 5;
 	uint64_t e                            : 5;
@@ -5814,22 +5785,19 @@ typedef union cvmx_bgxx_spux_an_adv cvmx_bgxx_spux_an_adv_t;
 /**
  * cvmx_bgx#_spu#_an_bp_status
  *
- * "Backplane Ethernet & BASE-R Copper Status:
- * The contents of the AN_BP_STATUS register (with the exception of the
- * static BP_AN_ABLE bit) are updated during Auto-Negotiation and are valid
- * when the AN_COMPLETE bit is set in AN_STATUS. At that time, one of the
- * port type bits (A100G_CR10, A40G_CR4, A40G_KR4, A10G_KR, A10G_KX4, A1G_KX)
- * will be set depending on the AN priority resolution. If a BASE-R type is
- * negotiated, then the FEC bit will be set to indicate that FEC operation
- * has been negotiated, and will be clear otherwise."
+ * The contents of this register (with the exception of the static BP_AN_ABLE bit) are updated
+ * during Auto-Negotiation and are valid when BGX(0..5)_SPU(0..3)_AN_STATUS[AN_COMPLETE] is set.
+ * At that time, one of the port type bits (A100G_CR10, A40G_CR4, A40G_KR4, A10G_KR, A10G_KX4,
+ * A1G_KX) will be set depending on the AN priority resolution. If a BASE-R type is negotiated,
+ * then the FEC bit will be set to indicate that FEC operation has been negotiated, and will be
+ * clear otherwise.
  */
 union cvmx_bgxx_spux_an_bp_status {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_an_bp_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t n100g_cr10                   : 1;  /**< "100GBASE-CR10 negotiated:
-                                                         Expected to always be 0; 100GBASE-R is not supported." */
+	uint64_t n100g_cr10                   : 1;  /**< 100GBASE-CR10 negotiated; expected to always be 0; 100GBASE-R is not supported. */
 	uint64_t reserved_7_7                 : 1;
 	uint64_t n40g_cr4                     : 1;  /**< 40GBASE-CR4 negotiated */
 	uint64_t n40g_kr4                     : 1;  /**< 40GBASE-KR4 negotiated */
@@ -5837,8 +5805,7 @@ union cvmx_bgxx_spux_an_bp_status {
 	uint64_t n10g_kr                      : 1;  /**< 10GBASE-KR negotiated */
 	uint64_t n10g_kx4                     : 1;  /**< 10GBASE-KX4 or CX4 negotiated (XAUI) */
 	uint64_t n1g_kx                       : 1;  /**< 1000BASE-KX negotiated */
-	uint64_t bp_an_able                   : 1;  /**< "Backplane or BASE-R Copper AN Ability:
-                                                         Always 1." */
+	uint64_t bp_an_able                   : 1;  /**< Backplane or BASE-R copper AN Ability; always 1. */
 #else
 	uint64_t bp_an_able                   : 1;
 	uint64_t n1g_kx                       : 1;
@@ -5858,30 +5825,26 @@ typedef union cvmx_bgxx_spux_an_bp_status cvmx_bgxx_spux_an_bp_status_t;
 
 /**
  * cvmx_bgx#_spu#_an_control
- *
- * Auto Negotiation Control
- *
  */
 union cvmx_bgxx_spux_an_control {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_an_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t an_reset                     : 1;  /**< "Auto-Negotiation Reset:
-                                                         Writing a 1 to this bit or to the RESET bit in register CONTROL1
-                                                         resets the logical PCS (LPCS), sets the 802.3 PCS, FEC and AN
-                                                         registers for the LPCS to their default states, and resets the
-                                                         associated serdes lanes. It takes up to 32 sclk cycles to reset the
-                                                         LPCS, after which this bit is automatically cleared." */
+	uint64_t an_reset                     : 1;  /**< Auto-Negotiation reset. Setting this bit or BGXn_SPUm_CONTROL1[RESET] to 1 causes the
+                                                         following to happen:
+                                                         Resets the logical PCS (LPCS)
+                                                         Sets the Std 802.3 PCS, FEC and AN registers for the LPCS to their default states
+                                                         Resets the associated SerDes lanes.
+                                                         It takes up to 32 coprocessor-clock cycles to reset the LPCS, after which RESET is
+                                                         automatically cleared. */
 	uint64_t reserved_14_14               : 1;
-	uint64_t xnp_en                       : 1;  /**< Extended Next Page Enable. */
-	uint64_t an_en                        : 1;  /**< Auto-Negotiation Enable. This bit should not be set when
-                                                         BGX_CMR_CONFIG[LMAC_TYPE] is set to RXAUI; auto-negotiation is not
-                                                         supported in RXAUI mode. */
+	uint64_t xnp_en                       : 1;  /**< Extended next-page enable. */
+	uint64_t an_en                        : 1;  /**< Auto-Negotiation enable. This bit should not be set when BGX_CMR_CONFIG[LMAC_TYPE] is set
+                                                         to RXAUI; auto-negotiation is not supported in RXAUI mode. */
 	uint64_t reserved_10_11               : 2;
-	uint64_t an_restart                   : 1;  /**< "Auto-Negotiation Restart:
-                                                         Writing a 1 to this bit restarts the Auto-Negotiation process if the
-                                                         AN_EN bit in the register is also set. This is a self-clearing bit." */
+	uint64_t an_restart                   : 1;  /**< Auto-Negotiation restart. Writing a 1 to this bit restarts the Auto-Negotiation process if
+                                                         AN_EN is also set. This is a self-clearing bit. */
 	uint64_t reserved_0_8                 : 9;
 #else
 	uint64_t reserved_0_8                 : 9;
@@ -5901,35 +5864,33 @@ typedef union cvmx_bgxx_spux_an_control cvmx_bgxx_spux_an_control_t;
 /**
  * cvmx_bgx#_spu#_an_lp_base
  *
- * "Auto Negotiation Link Partner Base Page Ability:
- * The AN_LP_BASE register captures the contents of the latest AN link
- * codeword base page received from the link partner during Auto-Negotiation. See
- * section 802.3 section 73.6 for details. The PAGE_RX bit in AN_STATUS is
- * set when this register is updated by hardware."
+ * This register captures the contents of the latest AN link code word base page received from
+ * the link partner during Auto-Negotiation. (See Std 802.3 section 73.6 for details.)
+ * BGX(0..5)_SPU(0..3)_AN_STATUS[PAGE_RX] is set when this register is updated by hardware.
  */
 union cvmx_bgxx_spux_an_lp_base {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_an_lp_base_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t fec_req                      : 1;  /**< FEC Requested */
-	uint64_t fec_able                     : 1;  /**< FEC Ability */
-	uint64_t arsv                         : 19; /**< Technology Ability reserved bits */
-	uint64_t a100g_cr10                   : 1;  /**< 100GBASE-CR10 Ability */
-	uint64_t a40g_cr4                     : 1;  /**< 40GBASE-CR4 Ability */
-	uint64_t a40g_kr4                     : 1;  /**< 40GBASE-KR4 Ability */
-	uint64_t a10g_kr                      : 1;  /**< 10GBASE-KR Ability */
-	uint64_t a10g_kx4                     : 1;  /**< 10GBASE-KX4 Ability */
-	uint64_t a1g_kx                       : 1;  /**< 1000BASE-KX Ability */
-	uint64_t t                            : 5;  /**< Transmitted Nonce */
-	uint64_t np                           : 1;  /**< Next Page */
-	uint64_t ack                          : 1;  /**< Acknowledge */
-	uint64_t rf                           : 1;  /**< Remote Fault */
-	uint64_t xnp_able                     : 1;  /**< Extended Next Page ability. */
-	uint64_t asm_dir                      : 1;  /**< Asymmetric Pause */
-	uint64_t pause                        : 1;  /**< Pause Ability */
-	uint64_t e                            : 5;  /**< Echoed Nonce */
-	uint64_t s                            : 5;  /**< Selector */
+	uint64_t fec_req                      : 1;  /**< FEC requested. */
+	uint64_t fec_able                     : 1;  /**< FEC ability. */
+	uint64_t arsv                         : 19; /**< Technology ability. Reserved bits, should always be 0. */
+	uint64_t a100g_cr10                   : 1;  /**< 100GBASE-CR10 ability. */
+	uint64_t a40g_cr4                     : 1;  /**< 40GBASE-CR4 ability. */
+	uint64_t a40g_kr4                     : 1;  /**< 40GBASE-KR4 ability. */
+	uint64_t a10g_kr                      : 1;  /**< 10GBASE-KR ability. */
+	uint64_t a10g_kx4                     : 1;  /**< 10GBASE-KX4 ability. */
+	uint64_t a1g_kx                       : 1;  /**< 1000BASE-KX ability. */
+	uint64_t t                            : 5;  /**< Transmitted nonce. */
+	uint64_t np                           : 1;  /**< Next page. */
+	uint64_t ack                          : 1;  /**< Acknowledge. */
+	uint64_t rf                           : 1;  /**< Remote fault. */
+	uint64_t xnp_able                     : 1;  /**< Extended next page ability. */
+	uint64_t asm_dir                      : 1;  /**< Asymmetric PAUSE. */
+	uint64_t pause                        : 1;  /**< PAUSE ability. */
+	uint64_t e                            : 5;  /**< Echoed nonce. */
+	uint64_t s                            : 5;  /**< Selector. */
 #else
 	uint64_t s                            : 5;
 	uint64_t e                            : 5;
@@ -5959,23 +5920,21 @@ typedef union cvmx_bgxx_spux_an_lp_base cvmx_bgxx_spux_an_lp_base_t;
 /**
  * cvmx_bgx#_spu#_an_lp_xnp
  *
- * "Auto Negotiation Link Partner Extended Next Page (XNP) Ability:
- * The AN_LP_XNP register captures the contents of the latest Next Page
- * codeword received from the link partner during Auto-Negotiation, if any.
- * See section 802.3 section 73.7.7 for details."
+ * This register captures the contents of the latest next page code word received from the link
+ * partner during Auto-Negotiation, if any. See section 802.3 section 73.7.7 for details.
  */
 union cvmx_bgxx_spux_an_lp_xnp {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_an_lp_xnp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t u                            : 32; /**< Unformatted Code field. */
-	uint64_t np                           : 1;  /**< Next Page. */
+	uint64_t u                            : 32; /**< Unformatted code field. */
+	uint64_t np                           : 1;  /**< Next page. */
 	uint64_t ack                          : 1;  /**< Acknowledge. */
-	uint64_t mp                           : 1;  /**< Message Page. */
+	uint64_t mp                           : 1;  /**< Message page. */
 	uint64_t ack2                         : 1;  /**< Acknowledge 2. */
 	uint64_t toggle                       : 1;  /**< Toggle. */
-	uint64_t m_u                          : 11; /**< Message/Unformatted Code field. */
+	uint64_t m_u                          : 11; /**< Message/unformatted code field. */
 #else
 	uint64_t m_u                          : 11;
 	uint64_t toggle                       : 1;
@@ -5993,53 +5952,39 @@ typedef union cvmx_bgxx_spux_an_lp_xnp cvmx_bgxx_spux_an_lp_xnp_t;
 
 /**
  * cvmx_bgx#_spu#_an_status
- *
- * Auto Negotiation Status
- *
  */
 union cvmx_bgxx_spux_an_status {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_an_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
-	uint64_t prl_flt                      : 1;  /**< "Parallel Detection Fault:
-                                                         Always 0; SPU does not support parallel detection as part of the
-                                                         Auto-Negotiation protocol." */
+	uint64_t prl_flt                      : 1;  /**< Parallel detection fault. Always 0; SPU does not support parallel detection as part of the
+                                                         auto-negotiation protocol. */
 	uint64_t reserved_8_8                 : 1;
-	uint64_t xnp_stat                     : 1;  /**< Extended Next Page Status. */
-	uint64_t page_rx                      : 1;  /**< "Page Received:
-                                                         This bit is set when a New Page has been received and stored in the
-                                                         AN_LP_BASE or AN_LP_XNP register. Latching High bit; stays set until a
-                                                         1 is written by software, Auto-Negotiation is disabled or restarted,
-                                                         or Next page exchange is initiated.
-                                                         Note that in order to avoid read side effects, this is implemented as
-                                                         a write-1-to-clear bit, rather than latching high read-only as
-                                                         specified in 802.3." */
-	uint64_t an_complete                  : 1;  /**< "Auto-Negotiation Complete:
-                                                         This bit is set when the Auto-Negotiation process has been completed
-                                                         and the link is up and running using the negotiated Highest Common
-                                                         Denominator (HCD) technology.
-                                                           If AN is enabled (AN_EN=1 in register AN_CONTROL) and this bit is
-                                                         read as a zero, it indicates that the AN process has not been
-                                                         completed, and the contents of the AN_LP_BASE, AN_XNP_TX and
-                                                         AN_LP_XNP registers are as defined by the current state of the
-                                                         Auto-Negotiation protocol, or as written for manual configuration.
-                                                         This bit is always zero when AN is disabled (AN_EN=0)." */
-	uint64_t rmt_flt                      : 1;  /**< Remote Fault: Always 0 . */
-	uint64_t an_able                      : 1;  /**< Auto-Negotiation Ability: Always 1. */
-	uint64_t link_status                  : 1;  /**< Link Status:
-                                                         "This bit captures the state of the link_status variable as defined in
-                                                         802.3 section 73.9.1.  When set, indicates that a valid link has been
-                                                         established.  When clear, indicates that the link has been invalid
-                                                         after this bit was last set by software. Latching Low bit; stays clear
-                                                         until a 1 is written by software.
-                                                         Note that in order to avoid read side effects, this is implemented as
-                                                         a write-1-to-set bit, rather than latching low read-only as specified
-                                                         in 802.3." */
+	uint64_t xnp_stat                     : 1;  /**< Extended next-page status. */
+	uint64_t page_rx                      : 1;  /**< Page received. This latching-high bit is set when a new page has been received and stored
+                                                         in BGXn_SPUm_AN_LP_BASE or BGXn_SPUm_AN_LP_XNP; stays set until a 1 is written by
+                                                         software, Auto-Negotiation is disabled or restarted, or next page exchange is initiated.
+                                                         Note that in order to avoid read side effects, this is implemented as a write-1-to-clear
+                                                         bit, rather than latching high read-only as specified in 802.3. */
+	uint64_t an_complete                  : 1;  /**< Auto-Negotiation complete. Set when the Auto-Negotiation process has been completed and
+                                                         the link is up and running using the negotiated highest common denominator (HCD)
+                                                         technology. If AN is enabled (BGXn_SPUm_AN_CONTROL[AN_EN] = 1) and this bit is read as a
+                                                         zero, it indicates that the AN process has not been completed, and the contents of
+                                                         BGXn_SPUm_AN_LP_BASE, BGXn_SPUm_AN_XNP_TX, and BGXn_SPUm_AN_LP_XNP are as defined by the
+                                                         current state of the Auto-Negotiation protocol, or as written for manual configuration.
+                                                         This bit is always zero when AN is disabled (BGXn_SPUm_AN_CONTROL[AN_EN] = 0). */
+	uint64_t rmt_flt                      : 1;  /**< Remote fault: Always 0. */
+	uint64_t an_able                      : 1;  /**< Auto-Negotiation ability: Always 1. */
+	uint64_t link_status                  : 1;  /**< Link status. This bit captures the state of the link_status variable as defined in 802.3
+                                                         section 73.9.1. When set, indicates that a valid link has been established. When clear,
+                                                         indicates that the link has been invalid after this bit was last set by software. Latching
+                                                         low bit; stays clear until a 1 is written by software. Note that in order to avoid read
+                                                         side effects, this is implemented as a write-1-to-set bit, rather than latching low read-
+                                                         only as specified in 802.3. */
 	uint64_t reserved_1_1                 : 1;
-	uint64_t lp_an_able                   : 1;  /**< "Link Partner AN Ability:
-                                                         Set to indicate that the link partner is able to participate in the
-                                                         Auto-Negotiation function, and cleared otherwise." */
+	uint64_t lp_an_able                   : 1;  /**< Link partner Auto-Negotiation ability. Set to indicate that the link partner is able to
+                                                         participate in the Auto-Negotiation function, and cleared otherwise. */
 #else
 	uint64_t lp_an_able                   : 1;
 	uint64_t reserved_1_1                 : 1;
@@ -6061,39 +6006,32 @@ typedef union cvmx_bgxx_spux_an_status cvmx_bgxx_spux_an_status_t;
 /**
  * cvmx_bgx#_spu#_an_xnp_tx
  *
- * "Auto Negotiation Extended Next Page (XNP) Transmit:
- * Software programs the AN_XNP_TX register with the contents of the AN
- * Message next page or Unformatted next page link code word to be
- * transmitted during Auto-Negotiation. Next page exchange occurs after the
- * base link codewords have been exchanged if either end of the link segment
- * sets the NP bit to 1, indicating that it has at least one next page to
- * send. Once initiated, Next page exchange continues until both end of the
- * link segment set their NP bits to 0. See section 802.3 section 73.7.7 for
- * details."
+ * Software programs this register with the contents of the AN message next page or unformatted
+ * next page link code word to be transmitted during auto-negotiation. Next page exchange occurs
+ * after the base link code words have been exchanged if either end of the link segment sets the
+ * NP bit to 1, indicating that it has at least one next page to send. Once initiated, next page
+ * exchange continues until both end of the link segment set their NP bits to 0. See section
+ * 802.3 section 73.7.7 for details.
  */
 union cvmx_bgxx_spux_an_xnp_tx {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_an_xnp_tx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t u                            : 32; /**< "Unformatted Code field: When the MP bit is set, this field contains
-                                                         the 32-bit Unformatted Code field of the Message next page. When MP is
-                                                         clear, this field contains the upper 32 bits of the 43-bit Unformatted
-                                                         Code field of the Unformatted next page." */
-	uint64_t np                           : 1;  /**< Next Page. */
+	uint64_t u                            : 32; /**< Unformatted code field. When the MP bit is set, this field contains the 32-bit unformatted
+                                                         code field of the message next page. When MP is clear, this field contains the upper 32
+                                                         bits of the 43-bit unformatted code field of the unformatted next page. */
+	uint64_t np                           : 1;  /**< Next page. */
 	uint64_t ack                          : 1;  /**< Ack: Always 0 in this register. */
-	uint64_t mp                           : 1;  /**< "Message Page: Set to indicate that this register contains a Message
-                                                         next page. Clear to indicate that the register contains an Unformatted
-                                                         next page." */
-	uint64_t ack2                         : 1;  /**< "Acknowledge 2: Indicates that the receiver is able to act on the
-                                                         information (or perform the task) defined in the message." */
-	uint64_t toggle                       : 1;  /**< "Used to ensure proper synchronization between the local device and
-                                                         the link partner. This bit takes the opposite value of the Toggle bit
-                                                         in the previously exchanged link codeword." */
-	uint64_t m_u                          : 11; /**< "Message/Unformatted Code field: When the MP bit is set, this field
-                                                         contains the Message Code field (M) of the Message next page. When MP
-                                                         is clear, this field contains the lower 11 bits of the 43-bit
-                                                         Unformatted Code field of the Unformatted next page." */
+	uint64_t mp                           : 1;  /**< Message page. Set to indicate that this register contains a message next page. Clear to
+                                                         indicate that the register contains anunformatted next page. */
+	uint64_t ack2                         : 1;  /**< Acknowledge 2. Indicates that the receiver is able to act on the information (or perform
+                                                         the task) defined in the message. */
+	uint64_t toggle                       : 1;  /**< This bit is ignored by hardware. The value of the TOGGLE bit in
+                                                         transmitted next pages is automatically generated by hardware. */
+	uint64_t m_u                          : 11; /**< Message/Unformatted code field: When the MP bit is set, this field contains the message
+                                                         code field (M) of the message next page. When MP is clear, this field contains the lower
+                                                         11 bits of the 43-bit unformatted code field of the unformatted next page. */
 #else
 	uint64_t m_u                          : 11;
 	uint64_t toggle                       : 1;
@@ -6112,29 +6050,26 @@ typedef union cvmx_bgxx_spux_an_xnp_tx cvmx_bgxx_spux_an_xnp_tx_t;
 /**
  * cvmx_bgx#_spu#_br_algn_status
  *
- * "Multi-lane BASE-R PCS alignment status:
- * This register implements the 802.3 Multi-lane BASE-R PCS alignment status 1-4
- * registers (3.50-3.53). The register is only valid when the logical PCS type is
- * 40GBASE-R (LMAC_TYPE = 40G_R in the associated BGX_CMR_CONFIG register in the
- * CMR sub-block), and always returns 0 for all other LPCS types. 802.3 bits that are
- * not applicable to 40GBASE-R (i.e. status bits for PCS lanes 19-4) are not
- * implemented and marked as reserved. PCS lanes 3-0 are valid and are mapped to
- * physical serdes lanes based on the programming of the LANE_TO_SDS field in
- * BGX_CMR_CONFIG."
+ * This register implements the Std 802.3 multilane BASE-R PCS alignment status 1-4 registers
+ * (3.50-3.53). It is valid only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] =
+ * 0x4), and always returns 0x0 for all other LPCS types. Std 802.3 bits that are not applicable
+ * to 40GBASE-R (e.g. status bits for PCS lanes 19-4) are not implemented and marked as reserved.
+ * PCS lanes 3-0 are valid and are mapped to physical SerDes lanes based on the programming of
+ * BGXn_CMRm_CONFIG[[LANE_TO_SDS].
  */
 union cvmx_bgxx_spux_br_algn_status {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_algn_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t marker_lock                  : 4;  /**< Marker locked status for PCS lanes 3-0 */
+	uint64_t marker_lock                  : 4;  /**< Marker-locked status for PCS lanes 3-0.
+                                                         1 = locked, 0 = not locked */
 	uint64_t reserved_13_31               : 19;
-	uint64_t alignd                       : 1;  /**< All lanes locked & aligned:
-                                                         This bit returns 1 when the logical PCS has locked and aligned all
-                                                         associated receive lanes, and returns 0 otherwise. For all other PCS
-                                                         types, this bit always returns 0. */
+	uint64_t alignd                       : 1;  /**< All lanes are locked and aligned. This bit returns 1 when the logical PCS has locked and
+                                                         aligned all associated receive lanes; returns 0 otherwise. For all other PCS types, this
+                                                         bit always returns 0. */
 	uint64_t reserved_4_11                : 8;
-	uint64_t block_lock                   : 4;  /**< Block lock status for PCS lanes 3-0 */
+	uint64_t block_lock                   : 4;  /**< Block-lock status for PCS lanes 3-0: 1 = locked, 0 = not locked */
 #else
 	uint64_t block_lock                   : 4;
 	uint64_t reserved_4_11                : 8;
@@ -6151,34 +6086,26 @@ typedef union cvmx_bgxx_spux_br_algn_status cvmx_bgxx_spux_br_algn_status_t;
 /**
  * cvmx_bgx#_spu#_br_bip_err_cnt
  *
- * "40GBASE-R Bit Interleaved Parity error counters
- * This register implements the 802.3 BIP error counter registers for PCS
- * lanes 0-3 (3.200-3.203). The register is only valid when the logical PCS
- * type is 40GBASE-R (LMAC_TYPE = 40G_R in the associated BGX_CMR_CONFIG
- * register in the CMR sub-block), and always returns 0 for all other LPCS
- * types. The counters are indexed by the RX PCS lane number based on the
- * Alignment Marker detected on each lane and captured in the BR_LANE_MAP
- * register. Each counter counts the BIP errors for its PCS lane, and is
- * held at all ones in case of overflow. The counters are reset to all
- * zeros when this register is read by software. The reset operation takes
- * precedence over the increment operation; if the register is read on the
- * same clock cycle an increment operation, the counter will be reset to
- * all zeros and the increment operation will be lost.  The counters are
- * writable for test purposes, rather than read-only as specified in
- * 802.3."
+ * This register implements the Std 802.3 BIP error-counter registers for PCS lanes 0-3
+ * (3.200-3.203). It is valid only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] =
+ * 0x4), and always returns 0x0 for all other LPCS types. The counters are indexed by the RX PCS
+ * lane number based on the Alignment Marker detected on each lane and captured in
+ * BGX(0..5)_SPU(0..3)_BR_LANE_MAP. Each counter counts the BIP errors for its PCS lane, and is
+ * held at all ones in case of overflow. The counters are reset to all 0s when this register is
+ * read by software.
+ * The reset operation takes precedence over the increment operation; if the register is read on
+ * the same clock cycle as an increment operation, the counter is reset to all 0s and the
+ * increment operation is lost. The counters are writable for test purposes, rather than read-
+ * only as specified in Std 802.3.
  */
 union cvmx_bgxx_spux_br_bip_err_cnt {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_bip_err_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t bip_err_cnt_ln3              : 16; /**< "BIP error counter for lane on which PCS lane 3 markers are
-                                                         received." */
-	uint64_t bip_err_cnt_ln2              : 16; /**< "BIP error counter for lane on which PCS lane 2 markers are
-                                                         received." */
-	uint64_t bip_err_cnt_ln1              : 16; /**< "BIP error counter for lane on which PCS lane 1 markers are
-                                                         received." */
-	uint64_t bip_err_cnt_ln0              : 16; /**< "BIP error counter for lane on which PCS lane 0 markers are
-                                                         received." */
+	uint64_t bip_err_cnt_ln3              : 16; /**< BIP error counter for lane on which PCS lane 3 markers are received. */
+	uint64_t bip_err_cnt_ln2              : 16; /**< BIP error counter for lane on which PCS lane 2 markers are received. */
+	uint64_t bip_err_cnt_ln1              : 16; /**< BIP error counter for lane on which PCS lane 1 markers are received. */
+	uint64_t bip_err_cnt_ln0              : 16; /**< BIP error counter for lane on which PCS lane 0 markers are received. */
 #else
 	uint64_t bip_err_cnt_ln0              : 16;
 	uint64_t bip_err_cnt_ln1              : 16;
@@ -6193,25 +6120,18 @@ typedef union cvmx_bgxx_spux_br_bip_err_cnt cvmx_bgxx_spux_br_bip_err_cnt_t;
 /**
  * cvmx_bgx#_spu#_br_lane_map
  *
- * "40GBASE-R PCS lane mapping registers:
- * This register implements the 802.3 lane 0-3 mapping registers
- * (3.400-3.403).  The register is only valid when the logical PCS type is
- * 40GBASE-R (LMAC_TYPE = 40G_R in the associated BGX_CMR_CONFIG register
- * in the CMR sub-block), and always returns 0 for all other LPCS types.
- * The LNx_MAPPING field for each programmed PCS lane (called 'service
- * interface' in 802.3ba-2010) is valid when that lane has achieved
- * alignment marker lock on the receive side (i.e. the associated
- * MARKER_LOCK bit is set in BR_ALGN_STATUS), and is invalid otherwise.
- * When valid, it returns the actual detected receive PCS lane number based
- * on the received alignment marker contents received on that service
- * interface. The mapping is flexible because 802.3 allows multi-lane
- * BASE-R receive lanes to be re-ordered.
- * Note that for the transmit side, each PCS lane is mapped to a physical
- * serdes lane based on the programming of the LANE_TO_SDS field in
- * BGX_CMR_CONFIG.
- * For the receive side, LANE_TO_SDS specifies the service interface to
- * physical serdes lane mapping, and this register specifies the PCS lane
- * to service interface mapping."
+ * This register implements the Std 802.3 lane 0-3 mapping registers (3.400-3.403). It is valid
+ * only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x4), and always returns
+ * 0x0 for all other LPCS types. The LNx_MAPPING field for each programmed PCS lane (called
+ * service interface in 802.3ba-2010) is valid when that lane has achieved alignment marker lock
+ * on the receive side (i.e. the associated BGXn_SPUm_BR_ALGN_STATUS[MARKER_LOCK] = 1), and is
+ * invalid otherwise. When valid, it returns the actual detected receive PCS lane number based on
+ * the received alignment marker contents received on that service interface.
+ * The mapping is flexible because Std 802.3 allows multilane BASE-R receive lanes to be re-
+ * ordered. Note that for the transmit side, each PCS lane is mapped to a physical SerDes lane
+ * based on the programming of BGXn_CMRm_CONFIG[LANE_TO_SDS]. For the receive side,
+ * BGXn_CMRm_CONFIG[LANE_TO_SDS] specifies the service interface to physical SerDes lane mapping,
+ * and this register specifies the PCS lane to service interface mapping.
  */
 union cvmx_bgxx_spux_br_lane_map {
 	uint64_t u64;
@@ -6242,20 +6162,17 @@ typedef union cvmx_bgxx_spux_br_lane_map cvmx_bgxx_spux_br_lane_map_t;
 
 /**
  * cvmx_bgx#_spu#_br_pmd_control
- *
- * BASE-R PMD control
- *
  */
 union cvmx_bgxx_spux_br_pmd_control {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_pmd_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t train_en                     : 1;  /**< BASE-R Training Enable */
-	uint64_t train_restart                : 1;  /**< "BASE-R Training Restart:
-                                                         Writing a 1 to this bit restarts the training process if the
-                                                         TRAIN_EN bit in this register is also set. This is a self-clearing
-                                                         bit." */
+	uint64_t train_en                     : 1;  /**< BASE-R training enable */
+	uint64_t train_restart                : 1;  /**< BASE-R training restart. Writing a 1 to this bit restarts the training process if the
+                                                         TRAIN_EN bit in this register is also set. This is a self-clearing bit. Software should
+                                                         wait a minimum of 1.7ms after BGX(0..5)_SPU(0..3)_INT[TRAINING_FAILURE] is set before
+                                                         restarting the training process. */
 #else
 	uint64_t train_restart                : 1;
 	uint64_t train_en                     : 1;
@@ -6269,35 +6186,30 @@ typedef union cvmx_bgxx_spux_br_pmd_control cvmx_bgxx_spux_br_pmd_control_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_ld_cup
  *
- * "BASE-R PMD local device coefficient update:
- * This register implements 802.3 MDIO register 1.153 for 10GBASE-R (when
- * LMAC_TYPE = 10G_R in the associated BGX_CMR_CONFIG register) and MDIO
- * registers 1.1300-1.1303 for 40GBASE-R (when LMAC_TYPE = 40G_R). It is
- * automatically cleared at the start of training. When link training is in
- * progress, each field reflects the contents of the coefficient update
- * field in the associated lane's outgoing training frame.
- * The fields in this register are read/write even though they are
- * specified as read-only in 802.3. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is
- * set, then this register must be updated by software during link training
- * and hardware updates are disabled. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN]
- * is clear, this register is automatically updated by hardware, and it
- * should not be written by software.
- * The lane fields in this register are indexed by logical PCS lane ID. The
- * lane 0 field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R . The
- * remaining fields (LN1_*, LN2_*, LN3_*) are only valid for 40GBASE-R."
+ * This register implements 802.3 MDIO register 1.153 for 10GBASE-R (when LMAC_TYPE = 10G_R in
+ * the associated BGX_CMR_CONFIG register) and MDIO registers 1.1300-1.1303 for 40GBASE-R (when
+ * LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. When link training
+ * is in progress, each field reflects the contents of the coefficient update field in the
+ * associated lane's outgoing training frame. The fields in this register are read/write even
+ * though they are specified as read-only in 802.3. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is set,
+ * then this register must be updated by software during link training and hardware updates are
+ * disabled. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is clear, this register is automatically
+ * updated by hardware, and it should not be written by software. The lane fields in this
+ * register are indexed by logical PCS lane ID. The lane 0 field (LN0_*) is valid for both
+ * 10GBASE-R and 40GBASE-R. The remaining fields (LN1_*, LN2_*, LN3_*) are only valid for
+ * 40GBASE-R.
  */
 union cvmx_bgxx_spux_br_pmd_ld_cup {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_pmd_ld_cup_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ln3_cup                      : 16; /**< "PCS lane 3 Coefficient Update: Format defined by
-                                                         BGX_SPU_BR_TRAIN_CUP_S. Not valid for 10GBASE-R" */
-	uint64_t ln2_cup                      : 16; /**< "PCS lane 2 Coefficient Update: Format defined by
-                                                         BGX_SPU_BR_TRAIN_CUP_S. Not valid for 10GBASE-R" */
-	uint64_t ln1_cup                      : 16; /**< "PCS lane 1 Coefficient Update: Format defined by
-                                                         BGX_SPU_BR_TRAIN_CUP_S. Not valid for 10GBASE-R" */
-	uint64_t ln0_cup                      : 16; /**< "PCS lane 0 Coefficient Update: Format defined by
-                                                         BGX_SPU_BR_TRAIN_CUP_S." */
+	uint64_t ln3_cup                      : 16; /**< PCS lane 3 coefficient update: format defined by BGX_SPU_BR_TRAIN_CUP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln2_cup                      : 16; /**< PCS lane 2 coefficient update: format defined by BGX_SPU_BR_TRAIN_CUP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln1_cup                      : 16; /**< PCS lane 1 coefficient update: format defined by BGX_SPU_BR_TRAIN_CUP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln0_cup                      : 16; /**< PCS lane 0 coefficient update: format defined by BGX_SPU_BR_TRAIN_CUP_S. */
 #else
 	uint64_t ln0_cup                      : 16;
 	uint64_t ln1_cup                      : 16;
@@ -6312,34 +6224,29 @@ typedef union cvmx_bgxx_spux_br_pmd_ld_cup cvmx_bgxx_spux_br_pmd_ld_cup_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_ld_rep
  *
- * "BASE-R PMD local device status report:
- * This register implements 802.3 MDIO register 1.154 for 10GBASE-R (when
- * LMAC_TYPE = 10G_R in the associated BGX_CMR_CONFIG register) and MDIO
- * registers 1.1400-1.1403 for 40GBASE-R (when LMAC_TYPE = 40G_R). It is
- * automatically cleared at the start of training. Each field reflects the
- * contents of the status report field in the associated lane's outgoing
- * training frame.
- * The fields in this register are read/write even though they are
- * specified as read-only in 802.3. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is
- * set, then this register must be updated by software during link training
- * and hardware updates are disabled. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN]
- * is clear, this register is automatically updated by hardware, and it
- * should not be written by software.
- * The lane fields in this register are indexed by logical PCS lane ID. The
- * lane 0 field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R . The
- * remaining fields (LN1_*, LN2_*, LN3_*) are only valid for 40GBASE-R."
+ * This register implements 802.3 MDIO register 1.154 for 10GBASE-R (when LMAC_TYPE = 10G_R in
+ * the associated BGX_CMR_CONFIG register) and MDIO registers 1.1400-1.1403 for 40GBASE-R (when
+ * LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. Each field reflects
+ * the contents of the status report field in the associated lane's outgoing training frame. The
+ * fields in this register are read/write even though they are specified as read-only in 802.3.
+ * If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is set, then this register must be updated by software
+ * during link training and hardware updates are disabled. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN]
+ * is clear, this register is automatically updated by hardware, and it should not be written by
+ * software. The lane fields in this register are indexed by logical PCS lane ID. The lane 0
+ * field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R. The remaining fields (LN1_*, LN2_*,
+ * LN3_*) are only valid for 40GBASE-R.
  */
 union cvmx_bgxx_spux_br_pmd_ld_rep {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_pmd_ld_rep_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ln3_rep                      : 16; /**< "PCS lane 3 Status Report: Format defined by BGX_SPU_BR_TRAIN_REP_S. Not
-                                                         valid for 10GBASE-R" */
-	uint64_t ln2_rep                      : 16; /**< "PCS lane 2 Status Report: Format defined by BGX_SPU_BR_TRAIN_REP_S. Not
-                                                         valid for 10GBASE-R" */
-	uint64_t ln1_rep                      : 16; /**< "PCS lane 1 Status Report: Format defined by BGX_SPU_BR_TRAIN_REP_S. Not
-                                                         valid for 10GBASE-R" */
-	uint64_t ln0_rep                      : 16; /**< "PCS lane 0 Status Report: Format defined by BGX_SPU_BR_TRAIN_REP_S." */
+	uint64_t ln3_rep                      : 16; /**< PCS lane 3 status report: format defined by BGX_SPU_BR_TRAIN_REP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln2_rep                      : 16; /**< PCS lane 2 status report: format defined by BGX_SPU_BR_TRAIN_REP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln1_rep                      : 16; /**< PCS lane 1 status report: format defined by BGX_SPU_BR_TRAIN_REP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln0_rep                      : 16; /**< PCS lane 0 status report: format defined by BGX_SPU_BR_TRAIN_REP_S. */
 #else
 	uint64_t ln0_rep                      : 16;
 	uint64_t ln1_rep                      : 16;
@@ -6354,30 +6261,26 @@ typedef union cvmx_bgxx_spux_br_pmd_ld_rep cvmx_bgxx_spux_br_pmd_ld_rep_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_lp_cup
  *
- * "BASE-R PMD link partner coefficient update:
- * This register implements 802.3 MDIO register 1.152 for 10GBASE-R (when
- * LMAC_TYPE = 10G_R in the associated BGX_CMR_CONFIG register) and MDIO
- * registers 1.1100-1.1103 for 40GBASE-R (when LMAC_TYPE = 40G_R). It is
- * automatically cleared at the start of training. Each field reflects the
- * contents of the coefficient update field in the lane's most recently
- * received training frame. This register should not be written when link
- * training is enabled, i.e. when TRAIN_EN is set BR_PMD_CONTROL.
- * The lane fields in this register are indexed by logical PCS lane ID. The
- * lane 0 field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R . The
- * remaining fields (LN1_*, LN2_*, LN3_*) are only valid for 40GBASE-R."
+ * This register implements 802.3 MDIO register 1.152 for 10GBASE-R (when LMAC_TYPE = 10G_R in
+ * the associated BGX_CMR_CONFIG register) and MDIO registers 1.1100-1.1103 for 40GBASE-R (when
+ * LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. Each field reflects
+ * the contents of the coefficient update field in the lane's most recently received training
+ * frame. This register should not be written when link training is enabled, i.e. when TRAIN_EN
+ * is set BR_PMD_CONTROL. The lane fields in this register are indexed by logical PCS lane ID.
+ * The lane 0 field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R. The remaining fields
+ * (LN1_*, LN2_*, LN3_*) are only valid for 40GBASE-R.
  */
 union cvmx_bgxx_spux_br_pmd_lp_cup {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_pmd_lp_cup_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ln3_cup                      : 16; /**< "PCS lane 3 Coefficient Update: Format defined by
-                                                         BGX_SPU_BR_TRAIN_CUP_S. Not valid for 10GBASE-R" */
-	uint64_t ln2_cup                      : 16; /**< "PCS lane 2 Coefficient Update: Format defined by
-                                                         BGX_SPU_BR_TRAIN_CUP_S. Not valid for 10GBASE-R" */
-	uint64_t ln1_cup                      : 16; /**< "PCS lane 1 Coefficient Update: Format defined by
-                                                         BGX_SPU_BR_TRAIN_CUP_S. Not valid for 10GBASE-R" */
-	uint64_t ln0_cup                      : 16; /**< "PCS lane 0 Coefficient Update: Format defined by
-                                                         BGX_SPU_BR_TRAIN_CUP_S." */
+	uint64_t ln3_cup                      : 16; /**< PCS lane 3 coefficient update: format defined by BGX_SPU_BR_TRAIN_CUP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln2_cup                      : 16; /**< PCS lane 2 coefficient update: format defined by BGX_SPU_BR_TRAIN_CUP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln1_cup                      : 16; /**< PCS lane 1 coefficient update: format defined by BGX_SPU_BR_TRAIN_CUP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln0_cup                      : 16; /**< PCS lane 0 coefficient update: format defined by BGX_SPU_BR_TRAIN_CUP_S. */
 #else
 	uint64_t ln0_cup                      : 16;
 	uint64_t ln1_cup                      : 16;
@@ -6392,28 +6295,25 @@ typedef union cvmx_bgxx_spux_br_pmd_lp_cup cvmx_bgxx_spux_br_pmd_lp_cup_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_lp_rep
  *
- * "BASE-R PMD link partner status report:
- * This register implements 802.3 MDIO register 1.153 for 10GBASE-R (when
- * LMAC_TYPE = 10G_R in the associated BGX_CMR_CONFIG register) and MDIO
- * registers 1.1200-1.1203 for 40GBASE-R (when LMAC_TYPE = 40G_R). It is
- * automatically cleared at the start of training. Each field reflects the
- * contents of the status report field in the associated lane's most
- * recently received training frame.
- * The lane fields in this register are indexed by logical PCS lane ID. The
- * lane 0 field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R . The
- * remaining fields (LN1_*, LN2_*, LN3_*) are only valid for 40GBASE-R."
+ * This register implements 802.3 MDIO register 1.153 for 10GBASE-R (when LMAC_TYPE = 10G_R in
+ * the associated BGX_CMR_CONFIG register) and MDIO registers 1.1200-1.1203 for 40GBASE-R (when
+ * LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. Each field reflects
+ * the contents of the status report field in the associated lane's most recently received
+ * training frame. The lane fields in this register are indexed by logical PCS lane ID. The lane
+ * 0 field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R. The remaining fields (LN1_*, LN2_*,
+ * LN3_*) are only valid for 40GBASE-R.
  */
 union cvmx_bgxx_spux_br_pmd_lp_rep {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_pmd_lp_rep_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ln3_rep                      : 16; /**< "PCS lane 3 Status Report: Format defined by BGX_SPU_BR_TRAIN_REP_S. Not
-                                                         valid for 10GBASE-R" */
-	uint64_t ln2_rep                      : 16; /**< "PCS lane 2 Status Report: Format defined by BGX_SPU_BR_TRAIN_REP_S. Not
-                                                         valid for 10GBASE-R" */
-	uint64_t ln1_rep                      : 16; /**< "PCS lane 1 Status Report: Format defined by BGX_SPU_BR_TRAIN_REP_S. Not
-                                                         valid for 10GBASE-R" */
-	uint64_t ln0_rep                      : 16; /**< "PCS lane 0 Status Report: Format defined by BGX_SPU_BR_TRAIN_REP_S." */
+	uint64_t ln3_rep                      : 16; /**< PCS lane 3 status report: format defined by BGX_SPU_BR_TRAIN_REP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln2_rep                      : 16; /**< PCS lane 2 status report: format defined by BGX_SPU_BR_TRAIN_REP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln1_rep                      : 16; /**< PCS lane 1 status report: format defined by BGX_SPU_BR_TRAIN_REP_S. Not valid for
+                                                         10GBASE-R. */
+	uint64_t ln0_rep                      : 16; /**< PCS lane 0 status report: format defined by BGX_SPU_BR_TRAIN_REP_S. */
 #else
 	uint64_t ln0_rep                      : 16;
 	uint64_t ln1_rep                      : 16;
@@ -6428,24 +6328,22 @@ typedef union cvmx_bgxx_spux_br_pmd_lp_rep cvmx_bgxx_spux_br_pmd_lp_rep_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_status
  *
- * "BASE-R PMD status:
- * The lane fields in this register are indexed by logical PCS lane ID. The
- * lane 0 field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R . The
- * remaining fields (LN1_*, LN2_*, LN3_*) are only valid for 40GBASE-R."
+ * The lane fields in this register are indexed by logical PCS lane ID. The lane 0 field (LN0_*)
+ * is valid for both 10GBASE-R and 40GBASE-R. The remaining fields (LN1_*, LN2_*, LN3_*) are only
+ * valid for 40GBASE-R.
  */
 union cvmx_bgxx_spux_br_pmd_status {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_pmd_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t ln3_train_status             : 4;  /**< "PCS lane 3 link training status. Format defined by
-                                                         BGX_SPU_BR_LANE_TRAIN_STATUS_S. Not valid for 10GBASE-R" */
-	uint64_t ln2_train_status             : 4;  /**< "PCS lane 2 link training status. Format defined by
-                                                         BGX_SPU_BR_LANE_TRAIN_STATUS_S. Not valid for 10GBASE-R" */
-	uint64_t ln1_train_status             : 4;  /**< "PCS lane 1 link training status. Format defined by
-                                                         BGX_SPU_BR_LANE_TRAIN_STATUS_S. Not valid for 10GBASE-R" */
-	uint64_t ln0_train_status             : 4;  /**< "PCS lane 0 link training status. Format defined by
-                                                         BGX_SPU_BR_LANE_TRAIN_STATUS_S." */
+	uint64_t ln3_train_status             : 4;  /**< PCS lane 3 link training status. Format defined by BGX_SPU_BR_LANE_TRAIN_STATUS_S. Not
+                                                         valid for 10GBASE-R. */
+	uint64_t ln2_train_status             : 4;  /**< PCS lane 2 link training status. Format defined by BGX_SPU_BR_LANE_TRAIN_STATUS_S. Not
+                                                         valid for 10GBASE-R. */
+	uint64_t ln1_train_status             : 4;  /**< PCS lane 1 link training status. Format defined by BGX_SPU_BR_LANE_TRAIN_STATUS_S. Not
+                                                         valid for 10GBASE-R. */
+	uint64_t ln0_train_status             : 4;  /**< PCS lane 0 link training status. Format defined by BGX_SPU_BR_LANE_TRAIN_STATUS_S. */
 #else
 	uint64_t ln0_train_status             : 4;
 	uint64_t ln1_train_status             : 4;
@@ -6460,37 +6358,33 @@ typedef union cvmx_bgxx_spux_br_pmd_status cvmx_bgxx_spux_br_pmd_status_t;
 
 /**
  * cvmx_bgx#_spu#_br_status1
- *
- * BASE-R PCS status 1
- *
  */
 union cvmx_bgxx_spux_br_status1 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_status1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t rcv_lnk                      : 1;  /**< BASE-R receive link status
-                                                         1 = BASE-R PCS receive link up 0 = BASE-R PCS receive link down.
-                                                         This bit is a reflection of the PCS_status variable defined in 802.3
-                                                         sections 49.2.14.1 and 82.3.1. */
+	uint64_t rcv_lnk                      : 1;  /**< BASE-R receive link status.
+                                                         1 = BASE-R PCS receive-link up
+                                                         0 = BASE-R PCS receive-link down.
+                                                         This bit is a reflection of the PCS_status variable defined in Std 802.3 sections
+                                                         49.2.14.1 and 82.3.1. */
 	uint64_t reserved_4_11                : 8;
-	uint64_t prbs9                        : 1;  /**< 10GBASE-R PRBS9 pattern testing ability. Always 0; PRBS9 pattern
-                                                         testing not supported. */
-	uint64_t prbs31                       : 1;  /**< 10GBASE-R PRBS31 pattern testing ability. Always 0; PRBS31 pattern
-                                                         testing not supported. */
-	uint64_t hi_ber                       : 1;  /**< BASE-R PCS high Bit Error Rate
-                                                         Returns 1 to indicate that the 64B/66B receiver is detecting a BER of
-                                                         >= 10.4, and returns 0 otherwise. This bit is a direct reflection of
-                                                         the state of the hi_ber variable in the 64B/66B state diagram and is
-                                                         defined in 802.3 sections 49.2.13.2.2 and 82.2.18.2.2. */
-	uint64_t blk_lock                     : 1;  /**< "BASE-R PCS block lock
-                                                         Returns 1 to indicate that the 64B/66B receiver for BASE-R has
-                                                         achieved block lock, and returns 0 otherwise. This bit is a direct
-                                                         reflection of the state of the block_lock variable in the 64B/66B
-                                                         state diagram and is defined in 802.3 sections 49.2.13.2.2 and
-                                                         82.2.18.2.2.  For a multi-lane logical PCS (i.e. 40GBASE-R), this bit
-                                                         indicates that the receiver has both block lock and alignment for all
-                                                         lanes and is identical to the ALIGND bit in BR_ALGN_STATUS." */
+	uint64_t prbs9                        : 1;  /**< 10GBASE-R PRBS9 pattern testing ability. Always 0; PRBS9 pattern testing is not supported. */
+	uint64_t prbs31                       : 1;  /**< 10GBASE-R PRBS31 pattern testing ability. Always 0; PRBS31 pattern testing is not supported. */
+	uint64_t hi_ber                       : 1;  /**< BASE-R PCS high bit-error rate.
+                                                         1 = 64B/66B receiver is detecting a bit-error rate of >= 10.4
+                                                         0 = 64B/66B receiver is detecting a bit-error rate of < 10.4
+                                                         This bit is a direct reflection of the state of the HI_BER variable in the 64B/66B state
+                                                         diagram and is defined in Std 802.3 sections 49.2.13.2.2 and 82.2.18.2.2. */
+	uint64_t blk_lock                     : 1;  /**< BASE-R PCS block lock.
+                                                         1 = 64B/66B receiver for BASE-R has block lock
+                                                         0 = No block lock
+                                                         This bit is a direct reflection of the state of the BLOCK_LOCK variable in the 64B/66B
+                                                         state diagram and is defined in Std 802.3 sections 49.2.13.2.2 and 82.2.18.2.2.
+                                                         For a multilane logical PCS (i.e. 40GBASE-R), this bit indicates that the receiver has
+                                                         both block lock and alignment for all lanes and is identical to
+                                                         BGXn_SPUm_BR_ALGN_STATUS[ALIGND]. */
 #else
 	uint64_t blk_lock                     : 1;
 	uint64_t hi_ber                       : 1;
@@ -6508,61 +6402,54 @@ typedef union cvmx_bgxx_spux_br_status1 cvmx_bgxx_spux_br_status1_t;
 /**
  * cvmx_bgx#_spu#_br_status2
  *
- * "BASE-R PCS status 2
- * This register implements a combination of the following 802.3 registers: BASE-R PCS
- * status 2 (MDIO address 3.33), BASE-R BER high order counter (MDIO address 3.44),
- * and Errored blocks high order counter (MDIO address 3.45). The relative locations
- * of some fields have been moved from 802.3 in order to make the register layout more
- * software friendly: the BER counter high order and low order bits from 3.44 and
- * 3.33 have been combined into the contiguous 22-bit BER_CNT field; likewise, the
- * errored blocks counter high order and low order bits from 3.45 have been combined
- * into the contiguous 22-bit ERR_BLKS field."
+ * This register implements a combination of the following Std 802.3 registers:
+ * BASE-R PCS status 2 (MDIO address 3.33)
+ * BASE-R BER high-order counter (MDIO address 3.44)
+ * Errored-blocks high-order counter (MDIO address 3.45).
+ * Note that the relative locations of some fields have been moved from Std 802.3 in order to
+ * make the register layout more software friendly: the BER counter high-order and low-order bits
+ * from sections 3.44 and 3.33 have been combined into the contiguous, 22-bit BER_CNT field;
+ * likewise, the errored-blocks counter high-order and low-order bits from section 3.45 have been
+ * combined into the contiguous, 22-bit ERR_BLKS field.
  */
 union cvmx_bgxx_spux_br_status2 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_status2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_62_63               : 2;
-	uint64_t err_blks                     : 22; /**< Errored blocks counter
-                                                         This is the BASE-R errored blocks counter as defined by the
-                                                         errored_block_count variable specified in 802.3 sections 49.2.14.2
-                                                         and 82.2.18.2.4. It increments by 1 on each block for which the
-                                                         BASE-R receive state machine, specified in 802.3 diagrams 49-15 and
-                                                         82-15, enters the RX_E state. Back-to-back blocks in the RX_E state
-                                                         are counted as transitions from RX_E to RX_E and keep incrementing
-                                                         the counter. The counter is reset to all zeros after this register
-                                                         is read by software, and is held at all ones in case of overflow.
-                                                         The reset operation takes precedence over the increment operation;
-                                                         if the register is read on the same clock cycle an increment
-                                                         operation, the counter will be reset to all zeros and the increment
-                                                         operation will be lost.  This field is writable for test purposes,
-                                                         rather than read-only as specified in 802.3. */
+	uint64_t err_blks                     : 22; /**< Errored-blocks counter. This is the BASE-R errored-blocks counter as defined by the
+                                                         errored_block_count variable specified in Std 802.3 sections 49.2.14.2 and 82.2.18.2.4. It
+                                                         increments by 1 on each block for which the BASE-R receive state machine, specified in Std
+                                                         802.3 diagrams 49-15 and 82-15, enters the RX_E state.
+                                                         Back-to-back blocks in the RX_E state are counted as transitions from RX_E to RX_E and
+                                                         keep incrementing the counter. The counter is reset to all 0s after this register is read
+                                                         by software.
+                                                         The reset operation takes precedence over the increment operation: if the register is read
+                                                         on the same clock cycle as an increment operation, the counter is reset to all 0s and the
+                                                         increment operation is lost.
+                                                         This field is writable for test purposes, rather than read-only as specified in Std 802.3. */
 	uint64_t reserved_38_39               : 2;
-	uint64_t ber_cnt                      : 22; /**< Bit Error Rate counter
-                                                         This is the BASE-R BER counter as defined by the ber_count variable
-                                                         in 802.3 sections 49.2.14.2 and 82.2.18.2.4. The counter is reset to
-                                                         all zeros after this register is read by software, and is held at
-                                                         all ones in case of overflow. The reset operation takes precedence
-                                                         over the increment operation; if the register is read on the same
-                                                         clock cycle an increment operation, the counter will be reset to all
-                                                         zeros and the increment operation will be lost.
-                                                         This field is writable for test purposes, rather than read-only as
-                                                         specified in 802.3. */
-	uint64_t latched_lock                 : 1;  /**< "Latched block lock:
-                                                         Returns 1 to indicate that the 64B/66B receiver for BASE-R has
-                                                         achieved block lock, and returns 0 otherwise. This is a Latching Low
-                                                         version of the BLK_LOCK bit in BR_STATUS1; stays clear until a 1 is
-                                                         written by software.
-                                                         Note that in order to avoid read side effects, this is implemented as
-                                                         a write-1-to-set bit, rather than latching low read-only as specified
-                                                         in 802.3." */
-	uint64_t latched_ber                  : 1;  /**< "Latched high Bit Error Rate:
-                                                         Returns 1 to indicate that the 64B/66B receiver is detecting a high
-                                                         BER and returns 0 otherwise. This is a Latching High version of the
-                                                         HI_BER bit in BR_STATUS1; stays set until a 1 is written by software.
-                                                         Note that in order to avoid read side effects, this is implemented as
-                                                         a write-1-to-clear bit, rather than latching high read-only as
-                                                         specified in 802.3." */
+	uint64_t ber_cnt                      : 22; /**< Bit-error-rate counter. This is the BASE-R BER counter as defined by the ber_count
+                                                         variable in Std 802.3 sections 49.2.14.2 and 82.2.18.2.4. The counter is reset to all 0s
+                                                         after this register is read by software, and is held at all 1s in case of overflow.
+                                                         The reset operation takes precedence over the increment operation: if the register is read
+                                                         on the same clock cycle an increment operation, the counter is reset to all 0s and the
+                                                         increment operation is lost.
+                                                         This field is writable for test purposes, rather than read-only as specified in Std 802.3. */
+	uint64_t latched_lock                 : 1;  /**< Latched-block lock.
+                                                         1 = 64B/66B receiver for BASE-R has block lock
+                                                         0 = No block
+                                                         This is a latching-low version of BGXn_SPUm_BR_STATUS1[BLK_LOCK]; it stays clear until the
+                                                         register is read by software.
+                                                         Note that in order to avoid read side effects, this is implemented as a write-1-to-set
+                                                         bit, rather than latching low read-only as specified in 802.3. */
+	uint64_t latched_ber                  : 1;  /**< Latched-high bit-error rate.
+                                                         1 = 64B/66B receiver is detecting a high BER
+                                                         0 = Not a high BER
+                                                         This is a latching-high version of BGXn_SPUm_BR_STATUS1[HI_BER]; it stays set until the
+                                                         register is read by software.
+                                                         Note that in order to avoid read side effects, this is implemented as a write-1-to-clear
+                                                         bit, rather than latching high read-only as specified in 802.3. */
 	uint64_t reserved_0_13                : 14;
 #else
 	uint64_t reserved_0_13                : 14;
@@ -6581,33 +6468,26 @@ typedef union cvmx_bgxx_spux_br_status2 cvmx_bgxx_spux_br_status2_t;
 /**
  * cvmx_bgx#_spu#_br_tp_control
  *
- * "BASE-R PCS test pattern control:
- * Refer to the test pattern methodology described in 802.3 sections 49.2.8 and 82.2.10."
+ * Refer to the test pattern methodology described in 802.3 sections 49.2.8 and 82.2.10.
+ *
  */
 union cvmx_bgxx_spux_br_tp_control {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_br_tp_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t scramble_tp                  : 1;  /**< Select scrambled idle test pattern
-                                                          This bit selects the transmit test pattern used when TX_TP_EN is set
-                                                          in this register:
-                                                         - 1: Scrambled idle test pattern, 0: Square wave test pattern. */
-	uint64_t prbs9_tx                     : 1;  /**< 10GBASE-R PRBS9 TP transmit enable. Always 0; PRBS9 pattern testing
-                                                         not supported. */
-	uint64_t prbs31_rx                    : 1;  /**< 10GBASE-R PRBS31 TP receive enable. Always 0; PRBS31 pattern testing
-                                                         not supported. */
-	uint64_t prbs31_tx                    : 1;  /**< 10GBASE-R PRBS31 TP transmit enable. Always 0; PRBS31 pattern
-                                                         testing not supported. */
-	uint64_t tx_tp_en                     : 1;  /**< Transmit test pattern enable */
-	uint64_t rx_tp_en                     : 1;  /**< Receive test pattern enable
-                                                         The only supported receive test pattern is the scrambled idle test
-                                                         pattern. Setting this bit enables checking of that receive pattern. */
-	uint64_t tp_sel                       : 1;  /**< Square v/s PRBS test pattern select
-                                                         Always 1 to select square wave test pattern; PRBS test patterns are
-                                                         not supported. */
-	uint64_t dp_sel                       : 1;  /**< Data pattern select
-                                                         Always 0; PRBS test patterns are not supported. */
+	uint64_t scramble_tp                  : 1;  /**< Select scrambled idle test pattern. This bit selects the transmit test pattern used when
+                                                         TX_TP_EN is set:
+                                                         1 = scrambled idle test pattern, 0 = square wave test pattern. */
+	uint64_t prbs9_tx                     : 1;  /**< 10GBASE-R PRBS9 TP transmit enable. Always 0; PRBS9 pattern testing is not supported. */
+	uint64_t prbs31_rx                    : 1;  /**< 10GBASE-R PRBS31 TP receive enable. Always 0; PRBS31 pattern testing is not supported. */
+	uint64_t prbs31_tx                    : 1;  /**< 10GBASE-R PRBS31 TP transmit enable. Always 0; PRBS31 pattern is not supported. */
+	uint64_t tx_tp_en                     : 1;  /**< Transmit-test-pattern enable. */
+	uint64_t rx_tp_en                     : 1;  /**< Receive-test-pattern enable. The only supported receive test pattern is the scrambled idle
+                                                         test pattern. Setting this bit enables checking of that receive pattern. */
+	uint64_t tp_sel                       : 1;  /**< Square/PRBS test pattern select. Always 1 to select square wave test pattern; PRBS test
+                                                         patterns are not supported. */
+	uint64_t dp_sel                       : 1;  /**< Data pattern select. Always 0; PRBS test patterns are not supported. */
 #else
 	uint64_t dp_sel                       : 1;
 	uint64_t tp_sel                       : 1;
@@ -6627,7 +6507,7 @@ typedef union cvmx_bgxx_spux_br_tp_control cvmx_bgxx_spux_br_tp_control_t;
 /**
  * cvmx_bgx#_spu#_br_tp_err_cnt
  *
- * BASE-R PCS test pattern error counter
+ * This register provides the BASE-R PCS test-pattern error counter.
  *
  */
 union cvmx_bgxx_spux_br_tp_err_cnt {
@@ -6635,19 +6515,15 @@ union cvmx_bgxx_spux_br_tp_err_cnt {
 	struct cvmx_bgxx_spux_br_tp_err_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t err_cnt                      : 16; /**< Error Counter
-                                                         The test pattern error counter is a sixteen bit counter that contains
-                                                         the number of errors received during a pattern test. These bits are
-                                                         reset to all zeros when this register is read by software, and they
-                                                         are  held at all ones in the case of overflow. The test pattern
-                                                         methodology is described in 802.3 sections 49.2.12 and 82.2.10. This
-                                                         counter will count either block errors or bit errors dependent on
-                                                         the test mode (see 49.2.12). The reset operation takes precedence
-                                                         over the increment operation; if the register is read on the same
-                                                         clock cycle an increment operation, the counter will be reset to all
-                                                         zeros and the increment operation will be lost.
-                                                         This field is writable for test purposes, rather than read-only as
-                                                         specified in 802.3. */
+	uint64_t err_cnt                      : 16; /**< Error counter. This 16-bit counter contains the number of errors received during a pattern
+                                                         test. These bits are reset to all 0s when this register is read by software, and they are
+                                                         held at all 1s in the case of overflow.
+                                                         The test pattern methodology is described in Std 802.3, Sections 49.2.12 and 82.2.10. This
+                                                         counter counts either block errors or bit errors dependent on the test mode (see Section
+                                                         49.2.12). The reset operation takes precedence over the increment operation; if the
+                                                         register is read on the same clock cycle as an increment operation, the counter is reset
+                                                         to all 0s and the increment operation is lost. This field is writable for test purposes,
+                                                         rather than read-only as specified in Std 802.3. */
 #else
 	uint64_t err_cnt                      : 16;
 	uint64_t reserved_16_63               : 48;
@@ -6659,26 +6535,20 @@ typedef union cvmx_bgxx_spux_br_tp_err_cnt cvmx_bgxx_spux_br_tp_err_cnt_t;
 
 /**
  * cvmx_bgx#_spu#_bx_status
- *
- * 10GBASE-X PCS status
- *
  */
 union cvmx_bgxx_spux_bx_status {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_bx_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t alignd                       : 1;  /**< 10GBASE-X lane alignment status:
-                                                         1=Receive lanes aligned, 0=Receive lanes not aligned. */
-	uint64_t pattst                       : 1;  /**< Pattern testing ability:
-                                                         Always 0; 10GBASE-X pattern testing not supported. */
+	uint64_t alignd                       : 1;  /**< 10GBASE-X lane-alignment status.
+                                                         1 = receive lanes aligned, 0 = receive lanes not aligned */
+	uint64_t pattst                       : 1;  /**< Pattern-testing ability. Always 0; 10GBASE-X pattern is testing not supported. */
 	uint64_t reserved_4_10                : 7;
-	uint64_t lsync                        : 4;  /**< Lane sync:
-                                                         BASE-X lane synchronization status for PCS lanes 3-0. Each bit is
-                                                         set when the associated lane is code-group synchonized, and clear
-                                                         otherwise. If the PCS type is RXAUI (LMAC_TYPE = RXAUI in the
-                                                         associated BGX_CMR_CONFIG register in the CMR sub-block), then
-                                                         only lanes 1-0 are valid. */
+	uint64_t lsync                        : 4;  /**< Lane synchronization. BASE-X lane synchronization status for PCS lanes 3-0. Each bit is
+                                                         set when the associated lane is code-group synchronized, and clear otherwise. If the PCS
+                                                         type is RXAUI (i.e. the associated BGXn_CMRm_CONFIG[LMAC_TYPE] = RXAUI), then only lanes
+                                                         1-0 are valid. */
 #else
 	uint64_t lsync                        : 4;
 	uint64_t reserved_4_10                : 7;
@@ -6693,47 +6563,42 @@ typedef union cvmx_bgxx_spux_bx_status cvmx_bgxx_spux_bx_status_t;
 
 /**
  * cvmx_bgx#_spu#_control1
- *
- * PCS control 1
- *
  */
 union cvmx_bgxx_spux_control1 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_control1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t reset                        : 1;  /**< "Reset:
-                                                         Writing a 1 to this bit or to the AN_RESET bit in register
-                                                         AN_CONTROL resets the logical PCS (LPCS), sets the 802.3 PCS, FEC
-                                                         and AN registers for the LPCS to their default states, and resets
-                                                         the associated serdes lanes. It takes up to 32 sclk cycles to reset
-                                                         the LPCS, after which this bit is automatically cleared." */
-	uint64_t loopbck                      : 1;  /**< Loopback:
-                                                         TX to RX Loopback Enable: When set, transmit data for each serdes
-                                                         lane is looped back as receive data. */
-	uint64_t spdsel1                      : 1;  /**< Speed Select 1: Always 1. */
+	uint64_t reset                        : 1;  /**< Reset. Setting this bit or BGXn_SPUm_AN_CONTROL[AN_RESET] to 1 causes the following to
+                                                         happen:
+                                                         Resets the logical PCS (LPCS)
+                                                         Sets the Std 802.3 PCS, FEC and AN registers for the LPCS to their default states
+                                                         Resets the associated SerDes lanes.
+                                                         It takes up to 32 coprocessor-clock cycles to reset the LPCS, after which RESET is
+                                                         automatically cleared. */
+	uint64_t loopbck                      : 1;  /**< TX-to-RX loopback enable. When set, transmit data for each SerDes lane is looped back as
+                                                         receive data. */
+	uint64_t spdsel1                      : 1;  /**< Speed select 1: always 1. */
 	uint64_t reserved_12_12               : 1;
-	uint64_t lo_pwr                       : 1;  /**< "Low Power:
-                                                         When set, the Logical PCS is disabled (overriding the ENABLE bit in
-                                                         the associated BGX_CMR_CONFIG register in the CMR sub-block), and
-                                                         the serdes lanes associated with the LPCS are reset." */
+	uint64_t lo_pwr                       : 1;  /**< Low power enable. When set, the LPCS is disabled (overriding the associated
+                                                         BGXn_CMRm_CONFIG[ENABLE]), and the SerDes lanes associated with the LPCS are reset. */
 	uint64_t reserved_7_10                : 4;
-	uint64_t spdsel0                      : 1;  /**< Speed Select 0: Always 1. */
+	uint64_t spdsel0                      : 1;  /**< Speed select 0: always 1. */
 	uint64_t spd                          : 4;  /**< "Speed selection:
                                                          Note that this is a read-only field rather than read/write as
                                                          specified in 802.3. The Logical PCS speed is actually configured by
                                                          the LMAC_TYPE field in the associated BGX_CMR_CONFIG register in
                                                          the CMR sub-block. The Read values returned by this field are as
                                                          follows:
-                                                         ----------+---------------------------------------------------
-                                                         LMAC_TYPE |   Speed       SPD Read Value      Comment
-                                                         ----------+---------------------------------------------------
-                                                         XAUI      |   10G/20G     0x0                 20G if DXAUI
-                                                         RXAUI     |   10G         0x0
-                                                         10G_R     |   10G         0x0
-                                                         40G_R     |   40G         0x3
-                                                         Other     |   -           X
-                                                         ----------+---------------------------------------------------" */
+                                                           ----------+---------------------------------------------------
+                                                           LMAC_TYPE |   Speed       SPD Read Value      Comment
+                                                           ----------+---------------------------------------------------
+                                                           XAUI      |   10G/20G     0x0                 20G if DXAUI
+                                                           RXAUI     |   10G         0x0
+                                                           10G_R     |   10G         0x0
+                                                           40G_R     |   40G         0x3
+                                                           Other     |   -           X
+                                                           ----------+---------------------------------------------------" */
 	uint64_t reserved_0_1                 : 2;
 #else
 	uint64_t reserved_0_1                 : 2;
@@ -6754,9 +6619,6 @@ typedef union cvmx_bgxx_spux_control1 cvmx_bgxx_spux_control1_t;
 
 /**
  * cvmx_bgx#_spu#_control2
- *
- * PCS control 2
- *
  */
 union cvmx_bgxx_spux_control2 {
 	uint64_t u64;
@@ -6769,16 +6631,16 @@ union cvmx_bgxx_spux_control2 {
                                                          the LMAC_TYPE field in the associated BGX_CMR_CONFIG register in
                                                          the CMR sub-block. The Read values returned by this field are as
                                                          follows:
-                                                         ----------+------------------------------------------
-                                                         LMAC_TYPE |   PCS_TYPE          Comment
-                                                         |   Read Value
-                                                         ----------+------------------------------------------
-                                                         XAUI      |   0x1               10GBASE-X PCS type
-                                                         RXAUI     |   0x1               10GBASE-X PCS type
-                                                         10G_R     |   0x0               10GBASE-R PCS type
-                                                         40G_R     |   0x4               40GBASE-R PCS type
-                                                         Other     |   Undefined         Reserved
-                                                         ----------+------------------------------------------" */
+                                                           ----------+------------------------------------------
+                                                           LMAC_TYPE |   PCS_TYPE          Comment
+                                                                         Read Value
+                                                           ----------+------------------------------------------
+                                                           XAUI      |   0x1               10GBASE-X PCS type
+                                                           RXAUI     |   0x1               10GBASE-X PCS type
+                                                           10G_R     |   0x0               10GBASE-R PCS type
+                                                           40G_R     |   0x4               40GBASE-R PCS type
+                                                           Other     |   Undefined         Reserved
+                                                           ----------+------------------------------------------" */
 #else
 	uint64_t pcs_type                     : 3;
 	uint64_t reserved_3_63                : 61;
@@ -6790,23 +6652,16 @@ typedef union cvmx_bgxx_spux_control2 cvmx_bgxx_spux_control2_t;
 
 /**
  * cvmx_bgx#_spu#_fec_abil
- *
- * BASE-R FEC ability
- *
  */
 union cvmx_bgxx_spux_fec_abil {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_fec_abil_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t err_abil                     : 1;  /**< "BASE-R FEC error indication ability:
-                                                         Always 1 when the logical PCS type is BASE-R, i.e. LMAC_TYPE = 40G_R
-                                                         or 10G_R in the associated BGX_CMR_CONFIG register in the CMR
-                                                         sub-block. Always 0 otherwise." */
-	uint64_t fec_abil                     : 1;  /**< "BASE-R FEC ability:
-                                                         Always 1 when the logical PCS type is BASE-R, i.e. LMAC_TYPE = 40G_R
-                                                         or 10G_R in the associated BGX_CMR_CONFIG register in the CMR
-                                                         sub-block. Always 0 otherwise." */
+	uint64_t err_abil                     : 1;  /**< BASE-R FEC error-indication ability. Always 1 when the LPCS type is BASE-R, i.e.
+                                                         BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x3 or 0x4. Always 0 otherwise. */
+	uint64_t fec_abil                     : 1;  /**< BASE-R FEC ability. Always 1 when the LPCS type is BASE-R, i.e.
+                                                         BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x3 or 0x4. Always 0 otherwise. */
 #else
 	uint64_t fec_abil                     : 1;
 	uint64_t err_abil                     : 1;
@@ -6819,29 +6674,22 @@ typedef union cvmx_bgxx_spux_fec_abil cvmx_bgxx_spux_fec_abil_t;
 
 /**
  * cvmx_bgx#_spu#_fec_control
- *
- * BASE-R FEC control
- *
  */
 union cvmx_bgxx_spux_fec_control {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_fec_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t err_en                       : 1;  /**< "BASE-R FEC error indication enable:
-                                                         This bit corresponds to FEC_Enable_Error_to_PCS variable for BASE-R
-                                                         as defined in 802.3 Clause 74. When FEC is enabled (per FEC_EN bit
-                                                         in this register) and this bit is set to 1, the FEC decoder on the
-                                                         receive side will signal an uncorrectable FEC error to the BASE-R
-                                                         decoder by driving a value of 2'b11 on the sync bits for some of the
-                                                         32 64B/66B blocks belonging to the uncorrectable FEC block. See
-                                                         802.3-2008/802.3ba-2010 section 74.7.4.5.1 for more details." */
-	uint64_t fec_en                       : 1;  /**< "BASE-R FEC enable:
-                                                         When this bit is set and the logical PCS type is BASE-R (LMAC_TYPE =
-                                                         40G_R or 10G_R in the associated BGX_CMR_CONFIG register in the
-                                                         CMR sub-block), Forward Error Correction is enabled. FEC is disabled
-                                                         otherwise. Forward Error Correction is defined in IEEE Std
-                                                         802.3-2008/802.3ba-2010 Clause 74." */
+	uint64_t err_en                       : 1;  /**< BASE-R FEC error-indication enable. This bit corresponds to FEC_Enable_Error_to_PCS
+                                                         variable for BASE-R as defined in 802.3 Clause 74. When FEC is enabled (per FEC_EN bit in
+                                                         this register) and this bit is set, the FEC decoder on the receive side signals an
+                                                         uncorrectable FEC error to the BASE-R decoder by driving a value of 2'b11 on the sync bits
+                                                         for some of the 32 64B/66B blocks belonging to the uncorrectable FEC block. See
+                                                         802.3-2008/802.3ba-2010 section 74.7.4.5.1 for more details. */
+	uint64_t fec_en                       : 1;  /**< BASE-R FEC enable. When this bit is set and the LPCS type is BASE-R
+                                                         (BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x4), forward error correction is enabled. FEC is disabled
+                                                         otherwise. Forward error correction is defined in IEEE Std 802.3-2008/802.3ba-2010 Clause
+                                                         74. */
 #else
 	uint64_t fec_en                       : 1;
 	uint64_t err_en                       : 1;
@@ -6855,33 +6703,30 @@ typedef union cvmx_bgxx_spux_fec_control cvmx_bgxx_spux_fec_control_t;
 /**
  * cvmx_bgx#_spu#_fec_corr_blks01
  *
- * "BASE-R FEC corrected blocks counters, lanes 0-1:
- * This register is only valid when the logical PCS type is BASE-R, i.e. LMAC_TYPE =
- * 40G_R or 10G_R in the associated BGX_CMR_CONFIG register in the CMR sub-block.
- * The FEC corrected block counters are defined in 802.3 section 74.8.4.1.
- * For 10GBASE-R, LN0_CORR_BLKS corresponds to the 802.3 FEC_corrected_blocks_counter
- * variable (registers 1.172-1.173), and LN1_CORR_BLKS is reserved. For 40GBASE-R,
- * LN0_CORR_BLKS and LN1_CORR_BLKS correspond to the 802.3
- * FEC_corrected_blocks_counter_0 variable (registers 1.300-1.301) and
- * FEC_corrected_blocks_counter_1 variable (registers 1.302-1.303), respectively.
- * Each corrected blocks counter increments by 1 for a corrected FEC block, i.e. an
- * FEC block that has been received with invalid parity on the associated PCS lane,
- * and has been corrected by the FEC decoder.  The counter is reset to all
- * zeros when the register is read, and held at all ones in case of
- * overflow. The reset operation takes precedence over the increment
- * operation; if the register is read on the same clock cycle an increment
- * operation, the counter will be reset to all zeros and the increment
- * operation will be lost.
- * The counters are writable for test purposes, rather than read-only as
- * specified in 802.3.
- * "
+ * This register is valid only when the LPCS type is BASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x3 or
+ * 0x4). The FEC corrected-block counters are defined in Std 802.3 section 74.8.4.1. Each
+ * corrected-blocks counter increments by 1 for a corrected FEC block, i.e. an FEC block that has
+ * been received with invalid parity on the associated PCS lane and has been corrected by the FEC
+ * decoder. The counter is reset to all 0s when the register is read, and held at all 1s in case
+ * of overflow.
+ * The reset operation takes precedence over the increment operation; if the register is read on
+ * the same clock cycle as an increment operation, the counter is reset to all 0s and the
+ * increment operation is lost. The counters are writable for test purposes, rather than read-
+ * only as specified in Std 802.3.
  */
 union cvmx_bgxx_spux_fec_corr_blks01 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_fec_corr_blks01_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ln1_corr_blks                : 32; /**< PCS Lane 1 FEC corrected blocks */
-	uint64_t ln0_corr_blks                : 32; /**< PCS Lane 0 FEC corrected blocks */
+	uint64_t ln1_corr_blks                : 32; /**< PCS Lane 1 FEC corrected blocks.
+                                                         For 10GBASE-R, reserved.
+                                                         For 40GBASE-R, correspond to the Std 802.3 FEC_corrected_blocks_counter_1 variable
+                                                         (registers 1.302-1.303). */
+	uint64_t ln0_corr_blks                : 32; /**< PCS Lane 0 FEC corrected blocks.
+                                                         For 10GBASE-R, corresponds to the Std 802.3 FEC_corrected_blocks_counter variable
+                                                         (registers 1.172-1.173).
+                                                         For 40GBASE-R, correspond to the Std 802.3 FEC_corrected_blocks_counter_0 variable
+                                                         (registers 1.300-1.301). */
 #else
 	uint64_t ln0_corr_blks                : 32;
 	uint64_t ln1_corr_blks                : 32;
@@ -6894,31 +6739,25 @@ typedef union cvmx_bgxx_spux_fec_corr_blks01 cvmx_bgxx_spux_fec_corr_blks01_t;
 /**
  * cvmx_bgx#_spu#_fec_corr_blks23
  *
- * "BASE-R FEC corrected blocks counters, lanes 2-3:
- * This register is only valid when the logical PCS type is 40GBASE-R, i.e. LMAC_TYPE
- * = 40G_R in the associated BGX_CMR_CONFIG register in the CMR sub-block. The FEC
- * corrected block counters are defined in 802.3 section 74.8.4.1.
- * LN2_CORR_BLKS and LN3_CORR_BLKS correspond to the 802.3
- * FEC_corrected_blocks_counter_2 variable (registers 1.304-1.305) and
- * FEC_corrected_blocks_counter_3 variable (registers 1.306-1.307), respectively.
- * Each corrected blocks counter increments by 1 for a corrected FEC block, i.e. an
- * FEC block that has been received with invalid parity on the associated PCS lane,
- * and has been corrected by the FEC decoder.  The counter is reset to all
- * zeros when the register is read, and held at all ones in case of
- * overflow. The reset operation takes precedence over the increment
- * operation; if the register is read on the same clock cycle an increment
- * operation, the counter will be reset to all zeros and the increment
- * operation will be lost.
- * The counters are writable for test purposes, rather than read-only as
- * specified in 802.3.
- * "
+ * This register is valid only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] =
+ * 0x4). The FEC corrected-block counters are defined in Std 802.3 section 74.8.4.1. Each
+ * corrected-blocks counter increments by 1 for a corrected FEC block, i.e. an FEC block that has
+ * been received with invalid parity on the associated PCS lane and has been corrected by the FEC
+ * decoder. The counter is reset to all 0s when the register is read, and held at all 1s in case
+ * of overflow.
+ * The reset operation takes precedence over the increment operation; if the register is read on
+ * the same clock cycle as an increment operation, the counter is reset to all 0s and the
+ * increment operation is lost. The counters are writable for test purposes, rather than read-
+ * only as specified in Std 802.3.
  */
 union cvmx_bgxx_spux_fec_corr_blks23 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_fec_corr_blks23_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ln3_corr_blks                : 32; /**< PCS Lane 3 FEC corrected blocks */
-	uint64_t ln2_corr_blks                : 32; /**< PCS Lane 2 FEC corrected blocks */
+	uint64_t ln3_corr_blks                : 32; /**< PCS Lane 3 FEC corrected blocks. Correspond to the Std 802.3
+                                                         FEC_corrected_blocks_counter_3 variable (registers 1.306-1.307). */
+	uint64_t ln2_corr_blks                : 32; /**< PCS Lane 2 FEC corrected blocks. Correspond to the Std 802.3
+                                                         FEC_corrected_blocks_counter_3 variable (registers 1.304-1.305). */
 #else
 	uint64_t ln2_corr_blks                : 32;
 	uint64_t ln3_corr_blks                : 32;
@@ -6931,33 +6770,30 @@ typedef union cvmx_bgxx_spux_fec_corr_blks23 cvmx_bgxx_spux_fec_corr_blks23_t;
 /**
  * cvmx_bgx#_spu#_fec_uncorr_blks01
  *
- * "BASE-R FEC uncorrected blocks counters, lanes 0-1:
- * This register is only valid when the logical PCS type is BASE-R, i.e. LMAC_TYPE =
- * 40G_R or 10G_R in the associated BGX_CMR_CONFIG register in the CMR sub-block.
- * The FEC uncorrected block counters are defined in 802.3 section 74.8.4.2.
- * For 10GBASE-R, LN0_UNCORR_BLKS corresponds to the 802.3 FEC_uncorrected_blocks_counter
- * variable (registers 1.174-1.175), and LN1_UNCORR_BLKS is reserved. For 40GBASE-R,
- * LN0_UNCORR_BLKS and LN1_UNCORR_BLKS correspond to the 802.3
- * FEC_uncorrected_blocks_counter_0 variable (registers 1.700-1.701) and
- * FEC_uncorrected_blocks_counter_1 variable (registers 1.702-1.703), respectively.
- * Each uncorrected blocks counter increments by 1 for an uncorrected FEC block, i.e.
- * an FEC block that has been received with invalid parity on the associated PCS lane,
- * and has not been corrected by the FEC decoder.  The counter is reset to
- * all zeros when the register is read, and held at all ones in case of
- * overflow. The reset operation takes precedence over the increment
- * operation; if the register is read on the same clock cycle an increment
- * operation, the counter will be reset to all zeros and the increment
- * operation will be lost.
- * The counters are writable for test purposes, rather than read-only as
- * specified in 802.3.
- * "
+ * This register is valid only when the LPCS type is BASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x3 or
+ * 0x4). The FEC corrected-block counters are defined in Std 802.3 section 74.8.4.2. Each
+ * uncorrected-blocks counter increments by 1 for an uncorrected FEC block, i.e. an FEC block
+ * that has been received with invalid parity on the associated PCS lane and has not been
+ * corrected by the FEC decoder. The counter is reset to all 0s when the register is read, and
+ * held at all 1s in case of overflow.
+ * The reset operation takes precedence over the increment operation; if the register is read on
+ * the same clock cycle as an increment operation, the counter is reset to all 0s and the
+ * increment operation is lost. The counters are writable for test purposes, rather than read-
+ * only as specified in Std 802.3.
  */
 union cvmx_bgxx_spux_fec_uncorr_blks01 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_fec_uncorr_blks01_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ln1_uncorr_blks              : 32; /**< PCS Lane 1 FEC uncorrected blocks */
-	uint64_t ln0_uncorr_blks              : 32; /**< PCS Lane 0 FEC uncorrected blocks */
+	uint64_t ln1_uncorr_blks              : 32; /**< PCS Lane 1 FEC corrected blocks.
+                                                         For 10GBASE-R, reserved.
+                                                         For 40GBASE-R, corresponds to the Std 802.3 FEC_uncorrected_blocks_counter_1 variable
+                                                         (registers 1.702-1.703). */
+	uint64_t ln0_uncorr_blks              : 32; /**< PCS Lane 0 FEC uncorrected blocks.
+                                                         For 10GBASE-R, corresponds to the Std 802.3 FEC_uncorrected_blocks_counter variable
+                                                         (registers 1.174-1.175).
+                                                         For 40GBASE-R, correspond to the Std 802.3 FEC_uncorrected_blocks_counter_0 variable
+                                                         (registers 1.700-1.701). */
 #else
 	uint64_t ln0_uncorr_blks              : 32;
 	uint64_t ln1_uncorr_blks              : 32;
@@ -6970,31 +6806,25 @@ typedef union cvmx_bgxx_spux_fec_uncorr_blks01 cvmx_bgxx_spux_fec_uncorr_blks01_
 /**
  * cvmx_bgx#_spu#_fec_uncorr_blks23
  *
- * "BASE-R FEC uncorrected blocks counters, lanes 2-3:
- * This register is only valid when the logical PCS type is 40GBASE-R, i.e. LMAC_TYPE
- * = 40G_R in the associated BGX_CMR_CONFIG register in the CMR sub-block. The FEC
- * uncorrected block counters are defined in 802.3 section 74.8.4.2.
- * LN2_UNCORR_BLKS and LN3_UNCORR_BLKS correspond to the 802.3
- * FEC_uncorrected_blocks_counter_2 variable (registers 1.704-1.705) and
- * FEC_uncorrected_blocks_counter_3 variable (registers 1.706-1.707), respectively.
- * Each uncorrected blocks counter increments by 1 for an uncorrected FEC block, i.e.
- * an FEC block that has been received with invalid parity on the associated PCS lane,
- * and has not been corrected by the FEC decoder.  The counter is reset to
- * all zeros when the register is read, and held at all ones in case of
- * overflow. The reset operation takes precedence over the increment
- * operation; if the register is read on the same clock cycle an increment
- * operation, the counter will be reset to all zeros and the increment
- * operation will be lost.
- * The counters are writable for test purposes, rather than read-only as
- * specified in 802.3.
- * "
+ * This register is valid only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] =
+ * 0x4). The FEC uncorrected-block counters are defined in Std 802.3 section 74.8.4.2. Each
+ * corrected-blocks counter increments by 1 for an uncorrected FEC block, i.e. an FEC block that
+ * has been received with invalid parity on the associated PCS lane and has not been corrected by
+ * the FEC decoder. The counter is reset to all 0s when the register is read, and held at all 1s
+ * in case of overflow.
+ * The reset operation takes precedence over the increment operation; if the register is read on
+ * the same clock cycle as an increment operation, the counter is reset to all 0s and the
+ * increment operation is lost. The counters are writable for test purposes, rather than read-
+ * only as specified in Std 802.3.
  */
 union cvmx_bgxx_spux_fec_uncorr_blks23 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_fec_uncorr_blks23_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ln3_uncorr_blks              : 32; /**< PCS Lane 3 FEC uncorrected blocks */
-	uint64_t ln2_uncorr_blks              : 32; /**< PCS Lane 2 FEC uncorrected blocks */
+	uint64_t ln3_uncorr_blks              : 32; /**< PCS Lane 3 FEC uncorrected blocks. Corresponds to the Std 802.3
+                                                         FEC_uncorrected_blocks_counter_3 variable (registers 1.706-1.707). */
+	uint64_t ln2_uncorr_blks              : 32; /**< PCS Lane 2 FEC uncorrected blocks. Corresponds to the Std 802.3
+                                                         FEC_uncorrected_blocks_counter_3 variable (registers 1.704-1.705). */
 #else
 	uint64_t ln2_uncorr_blks              : 32;
 	uint64_t ln3_uncorr_blks              : 32;
@@ -7006,91 +6836,67 @@ typedef union cvmx_bgxx_spux_fec_uncorr_blks23 cvmx_bgxx_spux_fec_uncorr_blks23_
 
 /**
  * cvmx_bgx#_spu#_int
- *
- * SPU interrupt
- *
  */
 union cvmx_bgxx_spux_int {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t training_failure             : 1;  /**< "BASE-R PMD training failure:
-                                                         Set when BASE-R PMD link training has failed on the 10GBASE-R lane
-                                                         or any 40GBASE-R lane. Valid if the LPCS type selected by
-                                                         BGX_CMR_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R and
-                                                         BGX_SPU_BR_PMD_CONTROL[TRAIN_EN] is 1, and never set otherwise." */
-	uint64_t training_done                : 1;  /**< "BASE-R PMD training done:
-                                                         Set when the 10GBASE-R lane or all 40GBASE-R lanes have
-                                                         successfully completed BASE-R PMD link training. Valid if the LPCS
-                                                         type selected by BGX_CMR_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R
-                                                         and BGX_SPU_BR_PMD_CONTROL[TRAIN_EN] is 1, and never set otherwise." */
-	uint64_t an_complete                  : 1;  /**< "Auto-Negotiation Link Good:
-                                                         Set when BGX_SPU_AN_STATUS[AN_COMPLETE] is set, indicating that the
-                                                         Auto-Negotiation process has been completed and the link is up and
-                                                         running using the negotiated Highest Common Denominator (HCD)
-                                                         technology." */
-	uint64_t an_link_good                 : 1;  /**< "Auto-Negotiation Link Good:
-                                                         Set when the an_link_good variable is set as defined in 802.3-2008
-                                                         Figure 73-11, indicating that Auto-Negotiation has completed." */
-	uint64_t an_page_rx                   : 1;  /**< "Auto-Negotiation Page Received:
-                                                         This bit is set along with the PAGE_RX bit in AN_STATUS when a New
-                                                         Page has been received and stored in the AN_LP_BASE or AN_LP_XNP
-                                                         register." */
-	uint64_t fec_uncorr                   : 1;  /**< "Uncorrectable FEC error:
-                                                         Set when an FEC block with an uncorrectable error is received on the
-                                                         10GBASE-R lane or any 40GBASE-R lane.  Valid if the LPCS type
-                                                         selected by BGX_CMR_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R, and
-                                                         never set otherwise." */
-	uint64_t fec_corr                     : 1;  /**< "Correctable FEC error:
-                                                         Set when an FEC block with a correctable error is received on the
-                                                         10GBASE-R lane or any 40GBASE-R lane.  Valid if the LPCS type
-                                                         selected by BGX_CMR_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R, and
-                                                         never set otherwise." */
-	uint64_t bip_err                      : 1;  /**< "40GBASE-R Bit Interleaved Parity Error: Set when a BIP error is
-                                                         detected on any lane.  Valid if the LPCS type selected by
-                                                         BGX_CMR_CONFIG[LMAC_TYPE] is 40GBASE-R, and never set otherwise." */
-	uint64_t dbg_sync                     : 1;  /**< "Sync failure debug:
-                                                         This interrupt is provided for link problem debugging help. It is
-                                                         set as follows based on the LPCS type selected by
-                                                         BGX_CMR_CONFIG[LMAC_TYPE], and whether FEC is enabled or disabled by
+	uint64_t training_failure             : 1;  /**< BASE-R PMD training failure. Set when BASE-R PMD link training has failed on the 10GBASE-R
+                                                         lane or any 40GBASE-R lane. Valid if the LPCS type selected by
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R and
+                                                         BGX(0..5)_SPU(0..3)_BR_PMD_CONTROL[TRAIN_EN] is 1, and never set otherwise. */
+	uint64_t training_done                : 1;  /**< BASE-R PMD training done. Set when the 10GBASE-R lane or all 40GBASE-R lanes have
+                                                         successfully completed BASE-R PMD link training. Valid if the LPCS type selected by
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R and
+                                                         BGX(0..5)_SPU(0..3)_BR_PMD_CONTROL[TRAIN_EN] is 1, and never set otherwise. */
+	uint64_t an_complete                  : 1;  /**< Auto-Negotiation complete. Set when BGX(0..5)_SPU(0..3)_AN_STATUS[AN_COMPLETE] is set,
+                                                         indicating that the Auto-Negotiation process has been completed and the link is up and
+                                                         running using the negotiated highest common denominator (HCD) technology. */
+	uint64_t an_link_good                 : 1;  /**< Auto-Negotiation link good. Set when the an_link_good variable is set as defined in
+                                                         802.3-2008 Figure 73-11, indicating that Auto-Negotiation has completed. */
+	uint64_t an_page_rx                   : 1;  /**< Auto-Negotiation page received. This bit is set along with
+                                                         BGX(0..5)_SPU(0..3)_AN_STATUS[PAGE_RX] when a new page has been received and stored in
+                                                         BGX(0..5)_SPU(0..3)_AN_LP_BASE or BGX(0..5)_SPU(0..3)_AN_LP_XNP. */
+	uint64_t fec_uncorr                   : 1;  /**< Uncorrectable FEC error. Set when an FEC block with an uncorrectable error is received on
+                                                         the 10GBASE-R lane or any 40GBASE-R lane. Valid if the LPCS type selected by
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R, and never set otherwise. */
+	uint64_t fec_corr                     : 1;  /**< Correctable FEC error. Set when an FEC block with a correctable error is received on the
+                                                         10GBASE-R lane or any 40GBASE-R lane. Valid if the LPCS type selected by
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R, and never set otherwise. */
+	uint64_t bip_err                      : 1;  /**< 40GBASE-R bit interleaved parity error. Set when a BIP error is detected on any lane.
+                                                         Valid if the LPCS type selected by BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] is 40GBASE-R, and
+                                                         never set otherwise. */
+	uint64_t dbg_sync                     : 1;  /**< Sync failure debug. This interrupt is provided for link problem debugging help. It is set
+                                                         as follows based on the LPCS type selected by BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE], and
+                                                         whether FEC is enabled or disabled by BGX(0..5)_SPU(0..3)_FEC_CONTROL[FEC_EN]:
+                                                         XAUI or RXAUI: Set when any lane's PCS synchronization state transitions from
+                                                         SYNC_ACQUIRED_1 to SYNC_ACQUIRED_2 (see 802.3-2008 Figure 48-7).
+                                                         10GBASE-R or 40GBASE-R with FEC disabled: Set when sh_invalid_cnt increments to 1 while
+                                                         block_lock is 1 (see 802.3-2008 Figure 49-12 and 802.3ba-2010 Figure 82-20).
+                                                         10GBASE-R or 40GBASE-R with FEC enabled: Set when parity_invalid_cnt increments to 1 while
+                                                         fec_block_lock is 1 (see 802.3-2008 Figure 74-8). */
+	uint64_t algnlos                      : 1;  /**< Loss of lane alignment. Set when lane-to-lane alignment is lost. This is only valid if the
+                                                         logical PCS is a multilane type (i.e. XAUI, RXAUI or 40GBASE-R is selected by
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE]), and is never set otherwise. */
+	uint64_t synlos                       : 1;  /**< Loss of lane sync. Lane code-group or block synchronization is lost on one or more lanes
+                                                         associated with the LMAC/LPCS. Set as follows based on the LPCS type selected by
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE], and whether FEC is enabled or disabled by
                                                          BGX_SPU_FEC_CONTROL[FEC_EN]:
-                                                         * XAUI or RXAUI: Set when any lane's PCS synchronization state
-                                                           transitions from SYNC_ACQUIRED_1 to SYNC_ACQUIRED_2 (see
-                                                           802.3-2008 Figure 48-7).
-                                                         * 10GBASE-R or 40GBASE-R with FEC disabled: Set when sh_invalid_cnt
-                                                           increments to 1 while block_lock is 1 (see 802.3-2008 Figure 49-12
-                                                           and 802.3ba-2010 Figure 82-20).
-                                                         * 10GBASE-R or 40GBASE-R with FEC enabled: Set when
-                                                           parity_invalid_cnt increments to 1 while fec_block_lock is 1 (see
-                                                           802.3-2008 Figure 74-8)." */
-	uint64_t algnlos                      : 1;  /**< "Loss of lane alignment:
-                                                         Set when lane-to-lane alignment is lost. This is only valid if the
-                                                         logical PCS is a multi-lane type (i.e. XAUI, RXAUI or 40GBASE-R is
-                                                         selected by BGX_CMR_CONFIG[LMAC_TYPE]), and is never set otherwise." */
-	uint64_t synlos                       : 1;  /**< "Loss of Lane Sync:
-                                                         Lane code-group or block synchronization is lost on one or more
-                                                         lanes associated with the LMAC/LPCS. Set as follows based on the
-                                                         LPCS type selected by BGX_CMR_CONFIG[LMAC_TYPE], and whether FEC is
-                                                         enabled or disabled by BGX_SPU_FEC_CONTROL[FEC_EN]:
-                                                         * XAUI or RXAUI: Set when any any lane's PCS synchronization state
-                                                           transitions to LOSS_OF_SYNC (see 802.3-2008 Figure 48-7)
-                                                         * 10GBASE-R or 40GBASE-R with FEC disabled: set when the block_lock
-                                                           variable is cleared on the 10G lane or any 40G lane (see
-                                                           802.3-2008 Figure 49-12 and 802.3ba-2010 Figure 82-20).
-                                                         * 10GBASE-R or 40GBASE-R with FEC enabled: set when the
-                                                           fec_block_lock variable is cleared on the 10G lane or any 40G
-                                                           lane (see 802.3-2008 Figure 74-8)." */
+                                                         XAUI or RXAUI: Set when any lane's PCS synchronization state transitions to LOSS_OF_SYNC
+                                                         (see 802.3-2008 Figure 48-7)
+                                                         10GBASE-R or 40GBASE-R with FEC disabled: set when the block_lock variable is cleared on
+                                                         the 10G lane or any 40G lane (see 802.3-2008 Figure 49-12 and 802.3ba-2010 Figure 82-20).
+                                                         10GBASE-R or 40GBASE-R with FEC enabled: set when the fec_block_lock variable is cleared
+                                                         on the 10G lane or any 40G lane (see 802.3-2008 Figure 74-8). */
 	uint64_t bitlckls                     : 1;  /**< Bit lock lost on one or more lanes associated with the LMAC/LPCS. */
-	uint64_t err_blk                      : 1;  /**< "Errored Block Received:
-                                                         Set when an errored BASE-R block is received as described for
-                                                         BGX_SPU_BR_STATUS2[ERR_BLKS].  Valid if the LPCS type selected by
-                                                         BGX_CMR_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R, and never set
-                                                         otherwise." */
-	uint64_t rx_link_down                 : 1;  /**< Set when the receive link goes down, which is the same condition that
-                                                         sets BGX_SPU_STATUS2[RCVFLT]. */
-	uint64_t rx_link_up                   : 1;  /**< Set when the receive link comes up, which is the same condition that
-                                                         allows the setting of BGX_SPU_STATUS1[RCV_LNK]. */
+	uint64_t err_blk                      : 1;  /**< Errored block received. Set when an errored BASE-R block is received as described for
+                                                         BGX(0..5)_SPU(0..3)_BR_STATUS2[ERR_BLKS]. Valid if the LPCS type selected by
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] is 10GBASE-R or 40GBASE-R, and never set otherwise. */
+	uint64_t rx_link_down                 : 1;  /**< Set when the receive link goes down, which is the same condition that sets
+                                                         BGX(0..5)_SPU(0..3)_STATUS2[RCVFLT]. */
+	uint64_t rx_link_up                   : 1;  /**< Set when the receive link comes up, which is the same condition that allows the setting of
+                                                         BGX(0..5)_SPU(0..3)_STATUS1[RCV_LNK]. */
 #else
 	uint64_t rx_link_up                   : 1;
 	uint64_t rx_link_down                 : 1;
@@ -7116,20 +6922,16 @@ typedef union cvmx_bgxx_spux_int cvmx_bgxx_spux_int_t;
 
 /**
  * cvmx_bgx#_spu#_lpcs_states
- *
- * BASE-X Transmit/Receive states
- *
  */
 union cvmx_bgxx_spux_lpcs_states {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_lpcs_states_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t br_rx_sm                     : 3;  /**< BASE-R Receive State Machine state */
+	uint64_t br_rx_sm                     : 3;  /**< BASE-R receive state machine state */
 	uint64_t reserved_10_11               : 2;
-	uint64_t bx_rx_sm                     : 2;  /**< BASE-X Receive State Machine state */
-	uint64_t deskew_am_found              : 4;  /**< 40GBASE-R deskew state machine alignment marker found flag per
-                                                         logical PCS lane ID. */
+	uint64_t bx_rx_sm                     : 2;  /**< BASE-X receive state machine state */
+	uint64_t deskew_am_found              : 4;  /**< 40GBASE-R deskew state machine alignment marker found flag per logical PCS lane ID. */
 	uint64_t reserved_3_3                 : 1;
 	uint64_t deskew_sm                    : 3;  /**< BASE-X and 40GBASE-R deskew state machine state */
 #else
@@ -7149,60 +6951,58 @@ typedef union cvmx_bgxx_spux_lpcs_states cvmx_bgxx_spux_lpcs_states_t;
 /**
  * cvmx_bgx#_spu#_misc_control
  *
- * "TX_RX polarity:
  * RX logical PCS lane polarity vector [3:0] = XOR_RXPLRT[3:0] ^ [4[RXPLRT]].
- * TX logical PCS lane polarity vector [3:0] = XOR_TXPLRT[3:0] ^ [4[TXPLRT]].
- * In short keep RXPLRT and TXPLRT cleared, and use XOR_RXPLRT and
- * XOR_TXPLRT fields to define the polarity per logical PCS lane. Only bit
- * 0 of vector is used for 10GBASE-R, and only bits 1:0 of vector are used
- * for RXAUI."
+ *  TX logical PCS lane polarity vector [3:0] = XOR_TXPLRT[3:0] ^ [4[TXPLRT]].
+ *  In short, keep RXPLRT and TXPLRT cleared, and use XOR_RXPLRT and XOR_TXPLRT fields to define
+ *  the polarity per logical PCS lane. Only bit 0 of vector is used for 10GBASE-R, and only bits
+ * - 1:0 of vector are used for RXAUI.
  */
 union cvmx_bgxx_spux_misc_control {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_misc_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t rx_packet_dis                : 1;  /**< "Receive packet disable:
-                                                         This bit can be set or cleared by software at any time to gracefully
-                                                         disable or re-enable packet reception by the LPCS. If this bit is
-                                                         set while a packet is being received, the packet is completed and
-                                                         all subsequent received packets are discarded by the LPCS.
-                                                         Similarly, if this bit is cleared while a received packet is being
-                                                         discarded, packet reception resumes after the current packet is
-                                                         fully discarded.
-                                                           When set for a 40GBASE-R or 10GBASE-R LMAC/LPCS type (selected by
-                                                         BGX_CMR_CONFIG[LMAC_TYPE]), received errors and faults will be
-                                                         ignored while receive packets are disarded; idles will be sent to
-                                                         the MAC layer (SMU) and the errored blocks counter
-                                                         (BGX_SPU_BR_STATUS2[ERR_BLKS]) will not increment." */
-	uint64_t skip_after_term              : 1;  /**< "Enable sending of Idle Skip after Terminate:
-                                                         This bit is meaningful when the logical PCS type is XAUI or RXAUI
-                                                         (selected by BGX_CMR_CONFIG[LMAC_TYPE]), and has no effect
-                                                         otherwise. When set, the LMAC/LPCS transmits more Idle Skip columns
-                                                         for clock compensation. Typically set in HiGig/HiGig2 modes.  Clear
-                                                         otherwise." */
-	uint64_t intlv_rdisp                  : 1;  /**< "RXAUI Interleaved Running Disparity:
-                                                         This bit is meaningful when the logical PCS type is RXAUI (LMAC_TYPE
-                                                         = RXAUI in the associated BGX_CMR_CONFIG register in the CMR
-                                                         sub-block), and has no effect otherwise. It selects which disparity
-                                                         calculation to use when combining or splitting the RXAUI lanes, as
+	uint64_t rx_packet_dis                : 1;  /**< Receive packet disable. Software can set or clear this bit at any time to gracefully
+                                                         disable or re-enable packet reception by the LPCS. If this bit is set while a packet is
+                                                         being received, the packet is completed and all subsequent received packets are discarded
+                                                         by the LPCS. Similarly, if this bit is cleared while a received packet is being discarded,
+                                                         packet reception resumes after the current packet is fully discarded. When set for a
+                                                         40GBASE-R or 10GBASE-R LMAC/LPCS type (selected by BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE]),
+                                                         received errors and faults will be ignored while receive packets are discarded; idles will
+                                                         be sent to the MAC layer (SMU) and the errored blocks counter
+                                                         (BGX(0..5)_SPU(0..3)_BR_STATUS2[ERR_BLKS]) will not increment. */
+	uint64_t skip_after_term              : 1;  /**< Enable sending of Idle Skip after Terminate. This bit is meaningful when the logical PCS
+                                                         type is XAUI or RXAUI (selected by BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE]), and has no
+                                                         effect otherwise. When set, the LMAC/LPCS transmits more Idle Skip columns for clock
+                                                         compensation. Typically set in HiGig/HiGig2 modes; clear otherwise. This field can be set
+                                                         to ensure sufficient density of XAUI Idle Skip (||R||) columns with a small transmit
+                                                         inter-frame gap (IFG) in order to allow the link partner's receiver to delete ||R
+                                                         columns as needed for clock rate compensation. It is usually set when the LMAC's transmit
+                                                         IFG is set to 8 bytes in HiGig/HiGig2 modes (i.e. BGX(0..5)_SMU(0..3)_TX_IFG[IFG1] +
+                                                         BGX(0..5)_SMU(0..3)_TX_IFG[IFG2] = 8), and should be cleared when the transmit IFG is
+                                                         greater than 8 bytes. When this bit is set, the SPU will send an ||R|| column after a
+                                                         ||T0|| column (terminate in lane 0) if no ||R|| was sent in the previous IFG. This is a
+                                                         minor deviation from the functionality specified in 802.3-2008 Figure 48-6 (PCS transmit
+                                                         source state diagram), whereby the state will transition directly from SEND_DATA to
+                                                         SEND_RANDOM_R after ||T0|| if no ||R|| was transmitted in the previous IFG. Sending ||R
+                                                         after ||T0|| only (and not ||T1||, |T2|| or ||T3||) ensures that the check_end function at
+                                                         the receiving end, as defined in 802.3-2008 sub-clause 48.2.6.1.4, does not detect an
+                                                         error due to this functional change. When this bit is clear, the LMAC will fully conform
+                                                         to the functionality specified in Figure 48-6. */
+	uint64_t intlv_rdisp                  : 1;  /**< RXAUI interleaved running disparity. This bit is meaningful when the logical PCS type is
+                                                         RXAUI (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = RXAUI), and has no effect otherwise. It
+                                                         selects which disparity calculation to use when combining or splitting the RXAUI lanes, as
                                                          follows:
-                                                         0 = Common Running Disparity: Common running disparity is
-                                                         computed for even and odd code-groups of an RXAUI lane, i.e.
-                                                         interleave lanes before PCS layer As described in the Dune
-                                                         Networks/Broadcom RXAUI v2.1 specification. This obeys
-                                                         6.25GHz serdes disparity.
-                                                         1 = Interleaved Running Disparity: Running disparity is computed
-                                                         separately for even and odd code-groups of an RXAUI lane,
-                                                         i.e. interleave lanes after PCS layer As described in the
-                                                         Marvell RXAUI Interface specification. This does NOT obey
-                                                         6.25GHz serdes disparity." */
+                                                         0 = Common running disparity. Common running disparity is computed for even and odd code-
+                                                         groups of an RXAUI lane, i.e. interleave lanes before PCS layer as described in the Dune
+                                                         Networks/Broadcom RXAUI v2.1 specification. This obeys 6.25GHz serdes disparity.
+                                                         1 = Interleaved running disparity: Running disparity is computed separately for even and
+                                                         odd code-groups of an RXAUI lane, i.e. interleave lanes after PCS layer as described in
+                                                         the Marvell RXAUI Interface specification. This does not obey 6.25GHz SerDes disparity. */
 	uint64_t xor_rxplrt                   : 4;  /**< RX polarity control per logical PCS lane */
 	uint64_t xor_txplrt                   : 4;  /**< TX polarity control per logical PCS lane */
-	uint64_t rxplrt                       : 1;  /**< Receive Polarity
-                                                         1=inverted polarity, 0=normal polarity. */
-	uint64_t txplrt                       : 1;  /**< Transmit Polarity
-                                                         1=inverted polarity, 0=normal polarity. */
+	uint64_t rxplrt                       : 1;  /**< Receive polarity. 1 = inverted polarity, 0 = normal polarity. */
+	uint64_t txplrt                       : 1;  /**< Transmit polarity. 1 = inverted polarity, 0 = normal polarity. */
 #else
 	uint64_t txplrt                       : 1;
 	uint64_t rxplrt                       : 1;
@@ -7220,19 +7020,16 @@ typedef union cvmx_bgxx_spux_misc_control cvmx_bgxx_spux_misc_control_t;
 
 /**
  * cvmx_bgx#_spu#_spd_abil
- *
- * PCS speed ability
- *
  */
 union cvmx_bgxx_spux_spd_abil {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_spd_abil_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t hundredgb                    : 1;  /**< 100G capable: Always 0. */
-	uint64_t fortygb                      : 1;  /**< 40G capable: Always 1. */
-	uint64_t tenpasst                     : 1;  /**< 10PASS-TS/2BASE-TL capable: Always 0. */
-	uint64_t tengb                        : 1;  /**< 10G capable: Always 1. */
+	uint64_t hundredgb                    : 1;  /**< 100G capable. Always 0. */
+	uint64_t fortygb                      : 1;  /**< 40G capable. Always 1. */
+	uint64_t tenpasst                     : 1;  /**< 10PASS-TS/2BASE-TL capable. Always 0. */
+	uint64_t tengb                        : 1;  /**< 10G capable. Always 1. */
 #else
 	uint64_t tengb                        : 1;
 	uint64_t tenpasst                     : 1;
@@ -7247,32 +7044,25 @@ typedef union cvmx_bgxx_spux_spd_abil cvmx_bgxx_spux_spd_abil_t;
 
 /**
  * cvmx_bgx#_spu#_status1
- *
- * PCS status 1
- *
  */
 union cvmx_bgxx_spux_status1 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_status1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t flt                          : 1;  /**< Fault:
-                                                         1 = Fault condition detected, 0 = No fault condition detected. This
-                                                         bit is a logical OR of the XMTFLT and RCVFLT bits in STATUS2. */
+	uint64_t flt                          : 1;  /**< Fault: 1 = fault condition detected, 0 = no fault condition detected.
+                                                         This bit is a logical OR of
+                                                         BGX(0..5)_SPU(0..3)_STATUS2[XMTFLT, RCVFLT]. */
 	uint64_t reserved_3_6                 : 4;
-	uint64_t rcv_lnk                      : 1;  /**< "PCS Receive Link Status:
-                                                         1 = Receive Link up, 0 = Receive Link down. Latching Low bit; stays
-                                                         clear until a 1 is written by software. For a BASE-X logical PCS type
-                                                         (LMAC_TYPE = XAUI or RXAUI in the associated BGX_CMR_CONFIG register
-                                                         in the CMR sub-block), this is a latching low version of the ALIGND
-                                                         bit in register BX_STATUS. For a BASE-R logical PCS type (LMAC_TYPE =
-                                                         10G_R or 40G_R), this is a latching low version of the RCV_LNK bit in
-                                                         register BR_STATUS1.
-                                                         Note that in order to avoid read side effects, this is implemented as
-                                                         a write-1-to-set bit, rather than latching low read-only as specified
-                                                         in 802.3." */
-	uint64_t lpable                       : 1;  /**< Low-power ability:
-                                                         Always returns 1 to indicate that the LPCS supports low power mode. */
+	uint64_t rcv_lnk                      : 1;  /**< PCS receive link status: 1 = receive link up, 0 = receive link down.
+                                                         This is a latching-low bit; it stays clear until the register is read by software.
+                                                         For a BASE-X logical PCS type (in the associated BGXn_CMRm_CONFIG[LMAC_TYPE] = XAUI or
+                                                         RXAUI), this is a latching-low version of BGXn_SPUm_BX_STATUS[ALIGND].
+                                                         For a BASE-R logical PCS type (in the associated BGXn_CMRm_CONFIG[LMAC_TYPE] = 10G_R or
+                                                         40G_R), this is a latching-low version of BGXn_SPUm_BR_STATUS1[RCV_LNK].
+                                                         Note that in order to avoid read side effects, this is implemented as a write-1-to-set
+                                                         bit, rather than latching low read-only as specified in 802.3. */
+	uint64_t lpable                       : 1;  /**< Low-power ability. Always returns 1 to indicate that the LPCS supports low-power mode. */
 	uint64_t reserved_0_0                 : 1;
 #else
 	uint64_t reserved_0_0                 : 1;
@@ -7289,31 +7079,26 @@ typedef union cvmx_bgxx_spux_status1 cvmx_bgxx_spux_status1_t;
 
 /**
  * cvmx_bgx#_spu#_status2
- *
- * PCS status 2
- *
  */
 union cvmx_bgxx_spux_status2 {
 	uint64_t u64;
 	struct cvmx_bgxx_spux_status2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t dev                          : 2;  /**< Device Present:
-                                                         Always returns 0x2 to indicate device present at this address. */
+	uint64_t dev                          : 2;  /**< Device present. Always returns 0x2 to indicate a device is present at this address. */
 	uint64_t reserved_12_13               : 2;
-	uint64_t xmtflt                       : 1;  /**< Transmit Fault: The SPU never sets this bit. Always returns 0. */
-	uint64_t rcvflt                       : 1;  /**< "Receive Fault.
-                                                         Latching High bit; stays set until a 1 is written by software.
-                                                         Note that in order to avoid read side effects, this is implemented as
-                                                         a write-1-to-clear bit, rather than latching high read-only as
-                                                         specified in 802.3." */
+	uint64_t xmtflt                       : 1;  /**< Transmit fault. Always returns 0. */
+	uint64_t rcvflt                       : 1;  /**< Receive fault: 1 = receive fault, 0 = no receive fault. Latching high bit; stays set until
+                                                         software writes a 1.
+                                                         Note that in order to avoid read side effects, this is implemented as a write-1-to-clear
+                                                         bit, rather than latching high read-only as specified in 802.3. */
 	uint64_t reserved_6_9                 : 4;
-	uint64_t hundredgb_r                  : 1;  /**< 100GBASE-R capable: Always 0. */
-	uint64_t fortygb_r                    : 1;  /**< 40GBASE-R capable: Always 1. */
-	uint64_t tengb_t                      : 1;  /**< 10GBASE-T capable: Always 0. */
-	uint64_t tengb_w                      : 1;  /**< 10GBASE-W capable: Always 0. */
-	uint64_t tengb_x                      : 1;  /**< 10GBASE-X capable: Always 1. */
-	uint64_t tengb_r                      : 1;  /**< 10GBASE-R capable: Always 1. */
+	uint64_t hundredgb_r                  : 1;  /**< 100GBASE-R capable. Always 0. */
+	uint64_t fortygb_r                    : 1;  /**< 40GBASE-R capable. Always 1. */
+	uint64_t tengb_t                      : 1;  /**< 10GBASE-T capable. Always 0. */
+	uint64_t tengb_w                      : 1;  /**< 10GBASE-W capable. Always 0. */
+	uint64_t tengb_x                      : 1;  /**< 10GBASE-X capable. Always 1. */
+	uint64_t tengb_r                      : 1;  /**< 10GBASE-R capable. Always 1. */
 #else
 	uint64_t tengb_r                      : 1;
 	uint64_t tengb_x                      : 1;
@@ -7336,16 +7121,16 @@ typedef union cvmx_bgxx_spux_status2 cvmx_bgxx_spux_status2_t;
 /**
  * cvmx_bgx#_spu_bist_status
  *
- * "SPU Memory Status: This register provides memory BIST and ECC status
- * from the SPU RX_BUF lane FIFOs"
+ * This register provides memory BIST status from the SPU RX_BUF lane FIFOs.
+ *
  */
 union cvmx_bgxx_spu_bist_status {
 	uint64_t u64;
 	struct cvmx_bgxx_spu_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t rx_buf_bist_status           : 4;  /**< "SPU RX_BUF BIST status for lanes 3-0: One bit per serdes lane, set
-                                                         to indicate BIST failure for the associated RX_BUF lane FIFO." */
+	uint64_t rx_buf_bist_status           : 4;  /**< SPU RX_BUF BIST status for lanes 3-0. One bit per SerDes lane, set to indicate BIST
+                                                         failure for the associated RX_BUF lane FIFO. */
 #else
 	uint64_t rx_buf_bist_status           : 4;
 	uint64_t reserved_4_63                : 60;
@@ -7357,121 +7142,98 @@ typedef union cvmx_bgxx_spu_bist_status cvmx_bgxx_spu_bist_status_t;
 
 /**
  * cvmx_bgx#_spu_dbg_control
- *
- * SPU Debug Control
- *
  */
 union cvmx_bgxx_spu_dbg_control {
 	uint64_t u64;
 	struct cvmx_bgxx_spu_dbg_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_56_63               : 8;
-	uint64_t ms_clk_period                : 12; /**< "Millisecond Clock Period: Specifies the number of microsecond clock
-                                                         ticks per millisecond, minus 1. The default value of 999 (0x3e7)
-                                                         should be used during normal operation; other values may be used for
-                                                         test/debug purposes." */
-	uint64_t us_clk_period                : 12; /**< "Microsecond Clock Period: Specifies the number of SCLK cycles per
-                                                         microseconds, minus 1. For example, if SCLK runs at 1.3 GHz, the
-                                                         number of SCLK cycles per microsecond is 1,300 so the value of this
-                                                         field should be 1,299 (0x513). This is used by the BASE-R BER
-                                                         monitor timers." */
+	uint64_t ms_clk_period                : 12; /**< Millisecond clock period. Specifies the number of microsecond clock ticks per millisecond,
+                                                         minus 1. The default value of 999 (0x3E7) should be used during normal operation; other
+                                                         values may be used for test/debug purposes. */
+	uint64_t us_clk_period                : 12; /**< Microsecond clock period. Specifies the number of SCLK cycles per microseconds, minus 1.
+                                                         For example, if SCLK runs at 1.3 GHz, the number of SCLK cycles per microsecond is 1,300
+                                                         so the value of this field should be 1,299 (0x513). This is used by the BASE-R BER monitor
+                                                         timers. */
 	uint64_t reserved_31_31               : 1;
-	uint64_t br_ber_mon_dis               : 1;  /**< "BASE-R Bit Error Rate Monitor Disable:
-                                                         This bit should be clear for normal oepration. Setting it disables
-                                                         the BASE-R BER monitor state machine defined in 802.3-2008 Figure
-                                                         49-13 for 10GBASE-R and 802.3ba-2010 Figure 82-13 for 40GBASE-R." */
-	uint64_t an_nonce_match_dis           : 1;  /**< "Auto-Negotiation Nonce Match Disable:
-                                                         This bit should be clear for normal oepration. Setting it disables
-                                                         Nonce Match check by forcing nonce_match variable to 0 in the AN
-                                                         arbitration state diagram, as defined in 802.3-2008 Figure 73-11.
-                                                         This bit can be set by software for test purposes, e.g. for running
-                                                         auto-negotiation in loopback mode." */
-	uint64_t timestamp_norm_dis           : 1;  /**< "40GBASE-R RX Timestamp Normalization Disable:
-                                                         This bit controls the generation of the receive SOP timestamp passed
-                                                         to the SMU sub-block for a 40GBASE-R LMAC/LPCS. When this bit is
-                                                         clear, SPU normalizes the receive SOP timestamp in order to
-                                                         compensate for lane-to-lane skew on a 40GBASE-R link, as described
-                                                         below. When this bit is set, timestamp normalization is disabled and
-                                                         SPU directly passes the captured SOP timestamp values to SMU.
-                                                         In 40GBASE-R mode, a packet's SOP block can be transferred on any of
-                                                         the LMAC's lanes. In the presence of lane-to-lane skew, the SOP
-                                                         delay from transmit (by the link partner) to receive by SPU varies
-                                                         depending on which lane is used by the SOP block. This variation
-                                                         reduces the accuracy of the received SOP timestamp relative to when
-                                                         it was transmitted by the link partner.
-                                                         SPU captures the timestamp of the alignment marker received on each
-                                                         serdes lane during align/skew detection; the captured value can be
-                                                         read from the serdes lane's BGX_SPU_SDS_SKEW_STATUS[SKEW_STATUS]
-                                                         field (AM_TIMESTAMP sub-field). If alignment markers are transmitted
-                                                         at about the same time on all lanes by the link partner, then the
-                                                         difference between the AM_TIMESTAMP values for a pair of lanes
-                                                         represents the approximate skew between those lanes.
-                                                         SPU uses the 40GBASE-R LMAC's programmed PCS lane 0 as a reference
-                                                         and computes the AM_TIMESTAMP delta of every other lane relative to
-                                                         PCS lane 0. When normalization is enabled, SPU adjusts the timestamp
-                                                         of a received SOP by subtracting the receiving lane's AM_TIMESTAMP
-                                                         delta from the captured timestamp value. The adjusted/normalized
-                                                         timestamp value is then passed to SMU along with the SOP.
-                                                         Software can determine the actual maximum skew of a 40GBASE-R link
-                                                         by examining the AM_TIMESTAMP values in the BGX_SPU_SDS_SKEW_STATUS
-                                                         registers, and decide if timestamp normalization should be enabled or
-                                                         disabled to improve PTP accuracy. Normalization improves accurary
-                                                         for larger skew values but reduces the accuracy (due to timestamp
-                                                         measurement errors) for small skew values." */
-	uint64_t rx_buf_flip_synd             : 8;  /**< "Flip SPU RX_BUF FIFO ECC bits:
-                                                         Two bits per serdes lane; used to inject single-bit and double-bit
-                                                         errors into the ECC field on writes to the associated SPU RX_BUF
-                                                         lane FIFO, as follows:
-                                                             0x0: normal operation
-                                                             0x1: SBE on ECC bit 0
-                                                             0x2: SBE on ECC bit 1
-                                                             0x3: DBE on ECC bits 1:0
-                                                         " */
-	uint64_t br_pmd_train_soft_en         : 1;  /**< "Enable BASE-R PMD Software Controlled Link Training:
-                                                         This bit configures the operation mode for BASE-R link training for
-                                                         all LMACs and lanes. When this bit is set along with
-                                                         BR_PMD_CONTROL[TRAIN_EN] for a given LMAC, the BASE-R link training
-                                                         protocol for that LMAC is executed under software control, whereby
-                                                         the contents the BR_PMD_LD_CUP and BR_PMD_LD_REP registers are
-                                                         updated by software. When this bit is clear and
-                                                         BR_PMD_CONTROL[TRAIN_EN] is set, the link training protocol is fully
-                                                         automated in hardware, whereby the contents BR_PMD_LD_CUP and
-                                                         BR_PMD_LD_REP registers are automatically updated by hardware." */
-	uint64_t an_arb_link_chk_en           : 1;  /**< "Enable link status checking by AN Arbitration State Machine:
-                                                         When Auto-Negotiation is enabled (AN_EN is set in AN_CONTROL), this
-                                                         bit controls the behavior of the AN arbitration state machine when it
-                                                         reaches the AN GOOD CHECK state after DME pages are successfully
-                                                         exchanged, as defined in Figure 73-11 in 802.3-2008.
-                                                         When this bit is set and the negotiated Highest Common Denominator
-                                                         (HCD) technology matches LMAC_TYPE in BGX_CMR_CONFIG, the AN
-                                                         arbitration SM performs the actions defined for the AN GOOD CHECK
-                                                         state in Figure 73-11, i.e. run the link_fail_inhibit timer and
-                                                         eventually transition to the AN GOOD or TRANSMIT DISABLE state.
-                                                         When this bit is clear or the HCD technology does not match LMAC_TYPE,
-                                                         the AN arbitration SM stay in the AN GOOD CHECK state, with the
-                                                         expectation that software will perform the appropriate actions to
-                                                         complete the Auto-Negotiation protocol, as follows:
-                                                         * If this bit is clear and the HCD technology matches LMAC_TYPE, clear
-                                                           AN_EN in AN_CONTROL.
-                                                         * Otherwise, disable the LPCS by clearing the ENABLE bit in
-                                                           BGX_CMR_CONFIG, clear AN_EN in AN_CONTROL, reconfigure the LPCS with
-                                                           the correct LMAC_TYPE, and re-enable the LPCS by setting ENABLE in
-                                                           BGX_CMR_CONFIG.
-                                                         In both cases, software should implement the link_fail_inhibit timer
-                                                         and verify the link status as specified for the AN GOOD CHECK state.
-                                                         " */
+	uint64_t br_ber_mon_dis               : 1;  /**< BASE-R bit error rate monitor disable. This bit should be clear for normal operation.
+                                                         Setting it disables the BASE-R BER monitor state machine defined in 802.3-2008 Figure
+                                                         49-13 for 10GBASE-R and 802.3ba-2010 Figure 82-13 for 40GBASE-R. */
+	uint64_t an_nonce_match_dis           : 1;  /**< Auto-Negotiation nonce match disable. This bit should be clear for normal operation.
+                                                         Setting it disables Nonce Match check by forcing nonce_match variable to 0 in the Auto-
+                                                         Negotiation arbitration state diagram, as defined in 802.3-2008 Figure 73-11. This bit can
+                                                         be set by software for test purposes, e.g. for running auto-negotiation in loopback mode. */
+	uint64_t timestamp_norm_dis           : 1;  /**< 40GBASE-R RX timestamp normalization disable. This bit controls the generation of the
+                                                         receive SOP timestamp passed to the SMU sub-block for a 40GBASE-R LMAC/LPCS. When this bit
+                                                         is clear, SPU normalizes the receive SOP timestamp in order to compensate for lane-to-lane
+                                                         skew on a 40GBASE-R link, as described below. When this bit is set, timestamp
+                                                         normalization is disabled and SPU directly passes the captured SOP timestamp values to
+                                                         SMU.
+                                                         In 40GBASE-R mode, a packet's SOP block can be transferred on any of the LMAC's lanes. In
+                                                         the presence of lane-to-lane skew, the SOP delay from transmit (by the link partner) to
+                                                         receive by SPU varies depending on which lane is used by the SOP block. This variation
+                                                         reduces the accuracy of the received SOP timestamp relative to when it was transmitted by
+                                                         the link partner.
+                                                         SPU captures the timestamp of the alignment marker received on each SerDes lane during
+                                                         align/skew detection; the captured value can be read from the SerDes lane's
+                                                         BGX(0..5)_SPU_SDS(0..3)_SKEW_STATUS[SKEW_STATUS] field (AM_TIMESTAMP sub-field). If
+                                                         alignment markers are transmitted at about the same time on all lanes by the link partner,
+                                                         then the difference between the AM_TIMESTAMP values for a pair of lanes represents the
+                                                         approximate skew between those lanes.
+                                                         SPU uses the 40GBASE-R LMAC's programmed PCS lane 0 as a reference and computes the
+                                                         AM_TIMESTAMP delta of every other lane relative to PCS lane 0. When normalization is
+                                                         enabled, SPU adjusts the timestamp of a received SOP by subtracting the receiving lane's
+                                                         AM_TIMESTAMP delta from the captured timestamp value. The adjusted/normalized timestamp
+                                                         value is then passed to SMU along with the SOP.
+                                                         Software can determine the actual maximum skew of a 40GBASE-R link by examining the
+                                                         AM_TIMESTAMP values in the BGX(0..5)_SPU_SDS(0..3)_SKEW_STATUS registers, and decide if
+                                                         timestamp normalization should be enabled or disabled to improve PTP accuracy.
+                                                         Normalization improves accuracy for larger skew values but reduces the accuracy (due to
+                                                         timestamp measurement errors) for small skew values. */
+	uint64_t rx_buf_flip_synd             : 8;  /**< Flip SPU RX_BUF FIFO ECC bits. Two bits per SerDes lane; used to inject single-bit and
+                                                         double-bit errors into the ECC field on writes to the associated SPU RX_BUF lane FIFO, as
+                                                         follows:
+                                                         0x0 = Normal operation
+                                                         0x1 = SBE on ECC bit 0
+                                                         0x2 = SBE on ECC bit 1
+                                                         0x3 = DBE on ECC bits 1:0 */
+	uint64_t br_pmd_train_soft_en         : 1;  /**< Enable BASE-R PMD software controlled link training. This bit configures the operation
+                                                         mode for BASE-R link training for all LMACs and lanes. When this bit is set along with
+                                                         BR_PMD_CONTROL[TRAIN_EN] for a given LMAC, the BASE-R link training protocol for that LMAC
+                                                         is executed under software control, whereby the contents the BR_PMD_LD_CUP and
+                                                         BR_PMD_LD_REP registers are updated by software. When this bit is clear and
+                                                         BR_PMD_CONTROL[TRAIN_EN] is set, the link training protocol is fully automated in
+                                                         hardware, whereby the contents BR_PMD_LD_CUP and BR_PMD_LD_REP registers are automatically
+                                                         updated by hardware. */
+	uint64_t an_arb_link_chk_en           : 1;  /**< Enable link status checking by Auto-Negotiation arbitration state machine. When Auto-
+                                                         Negotiation is enabled (BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_EN] is set), this bit controls
+                                                         the behavior of the Auto-Negotiation arbitration state machine when it reaches the AN GOOD
+                                                         CHECK state after DME pages are successfully exchanged, as defined in Figure 73-11 in
+                                                         802.3-2008.
+                                                         When this bit is set and the negotiated highest common denominator (HCD) technology
+                                                         matches BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE], the Auto-Negotiation arbitration SM
+                                                         performs the actions defined for the AN GOOD CHECK state in Figure 73-11, i.e. run the
+                                                         link_fail_inhibit timer and eventually transition to the AN GOOD or TRANSMIT DISABLE
+                                                         state.
+                                                         When this bit is clear or the HCD technology does not match LMAC_TYPE, the AN arbitration
+                                                         SM stay in the AN GOOD CHECK state, with the expectation that software will perform the
+                                                         appropriate actions to complete the Auto-Negotiation protocol, as follows:
+                                                         If this bit is clear and the HCD technology matches LMAC_TYPE, clear AN_EN in AN_CONTROL.
+                                                         Otherwise, disable the LPCS by clearing the BGX(0..5)_CMR(0..3)_CONFIG[ENABLE], clear
+                                                         BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_EN], reconfigure the LPCS with the correct LMAC_TYPE,
+                                                         and re-enable the LPCS by setting BGX(0..5)_CMR(0..3)_CONFIG[ENABLE].
+                                                         In both cases, software should implement the link_fail_inhibit timer and verify the link
+                                                         status as specified for the AN GOOD CHECK state. */
 	uint64_t rx_buf_cor_dis               : 1;  /**< When set, disables ECC correction on all SPU RX_BUF FIFOs. */
-	uint64_t scramble_dis                 : 1;  /**< BASE-R Scrambler/descrambler Disable:
-                                                         Setting this bit to 1 disables the BASE-R scrambler & descrambler
-                                                         functions and FEC PN-2112 scrambler & descrambler functions for
-                                                         debug purposes. */
+	uint64_t scramble_dis                 : 1;  /**< BASE-R Scrambler/descrambler disable. Setting this bit to 1 disables the BASE-R scrambler
+                                                         & descrambler functions and FEC PN-2112 scrambler & descrambler functions for debug
+                                                         purposes. */
 	uint64_t reserved_15_15               : 1;
-	uint64_t marker_rxp                   : 15; /**< BASE-R Alignment Marker Receive Period:
-                                                         For a multi-lane BASE-R logical PCS (i.e. 40GBASE-R), this field
-                                                         specifies the expected alignment marker receive period per lane, i.e.
-                                                         the expected number of received 66b non-marker blocks between
-                                                         consecutive markers on the same lane. The default value corresponds
-                                                         to a period of 16363 blocks (exclusive) as specified in 802.3ba-2010. */
+	uint64_t marker_rxp                   : 15; /**< BASE-R alignment marker receive period. For a multilane BASE-R logical PCS (i.e.
+                                                         40GBASE-R), this field specifies the expected alignment marker receive period per lane,
+                                                         i.e. the expected number of received 66b non-marker blocks between consecutive markers on
+                                                         the same lane. The default value corresponds to a period of 16363 blocks (exclusive) as
+                                                         specified in 802.3ba-2010. Must be greater than 64. */
 #else
 	uint64_t marker_rxp                   : 15;
 	uint64_t reserved_15_15               : 1;
@@ -7495,21 +7257,16 @@ typedef union cvmx_bgxx_spu_dbg_control cvmx_bgxx_spu_dbg_control_t;
 
 /**
  * cvmx_bgx#_spu_mem_int
- *
- * SPU Memory Interrupt
- *
  */
 union cvmx_bgxx_spu_mem_int {
 	uint64_t u64;
 	struct cvmx_bgxx_spu_mem_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t rx_buf_sbe                   : 4;  /**< "SPU RX_BUF Single-Bit Error for lanes 3-0: One bit per physical
-                                                         serdes lane.  Each bit is set when the associated RX_BUF lane FIFO
-                                                         detects a single-bit ECC error" */
-	uint64_t rx_buf_dbe                   : 4;  /**< "SPU RX_BUF Double-Bit Error for lanes 3-0: One bit per physical
-                                                         serdes lane.  Each bit is set when the associated RX_BUF lane FIFO
-                                                         detects a double-bit ECC error." */
+	uint64_t rx_buf_sbe                   : 4;  /**< SPU RX_BUF single-bit error for lanes 3-0. One bit per physical SerDes lane. Each bit is
+                                                         set when the associated RX_BUF lane FIFO detects a single-bit ECC error. */
+	uint64_t rx_buf_dbe                   : 4;  /**< SPU RX_BUF double-bit error for lanes 3-0. One bit per physical SerDes lane. Each bit is
+                                                         set when the associated RX_BUF lane FIFO detects a double-bit ECC error. */
 #else
 	uint64_t rx_buf_dbe                   : 4;
 	uint64_t rx_buf_sbe                   : 4;
@@ -7523,19 +7280,18 @@ typedef union cvmx_bgxx_spu_mem_int cvmx_bgxx_spu_mem_int_t;
 /**
  * cvmx_bgx#_spu_mem_status
  *
- * "SPU Memory Status: This register provides memory BIST and ECC status
- * from the SPU RX_BUF lane FIFOs"
+ * This register provides memory ECC status from the SPU RX_BUF lane FIFOs.
+ *
  */
 union cvmx_bgxx_spu_mem_status {
 	uint64_t u64;
 	struct cvmx_bgxx_spu_mem_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t rx_buf_ecc_synd              : 32; /**< "SPU RX_BUF ECC Syndromes for lanes 3-0: 8-bit syndrome sub-field
-                                                         per serdes lane. Each 8-bit sub-field contains the syndrome of the
-                                                         latest single-bit or double-bit ECC error detected by the associated
-                                                         RX_BUF lane FIFO, i.e. it is loaded when the corresponding
-                                                         RX_BUF_SBE or RX_BUF_DBE bit is set in the SPU MEM_INT register." */
+	uint64_t rx_buf_ecc_synd              : 32; /**< SPU RX_BUF ECC syndromes for lanes 3-0. 8-bit syndrome sub-field per SerDes lane. Each
+                                                         8-bit sub-field contains the syndrome of the latest single-bit or double-bit ECC error
+                                                         detected by the associated RX_BUF lane FIFO, i.e. it is loaded when the corresponding
+                                                         RX_BUF_SBE or RX_BUF_DBE bit is set in the SPU MEM_INT register. */
 #else
 	uint64_t rx_buf_ecc_synd              : 32;
 	uint64_t reserved_32_63               : 32;
@@ -7548,7 +7304,7 @@ typedef union cvmx_bgxx_spu_mem_status cvmx_bgxx_spu_mem_status_t;
 /**
  * cvmx_bgx#_spu_sds#_skew_status
  *
- * Serdes lane skew status. One register per physical serdes lane.
+ * This register provides SerDes lane skew status. One register per physical SerDes lane.
  *
  */
 union cvmx_bgxx_spu_sdsx_skew_status {
@@ -7569,7 +7325,7 @@ typedef union cvmx_bgxx_spu_sdsx_skew_status cvmx_bgxx_spu_sdsx_skew_status_t;
 /**
  * cvmx_bgx#_spu_sds#_states
  *
- * Serdes lane states. One register per physical serdes lane.
+ * This register provides SerDes lane states. One register per physical SerDes lane.
  *
  */
 union cvmx_bgxx_spu_sdsx_states {
@@ -7577,25 +7333,25 @@ union cvmx_bgxx_spu_sdsx_states {
 	struct cvmx_bgxx_spu_sdsx_states_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_52_63               : 12;
-	uint64_t am_lock_invld_cnt            : 2;  /**< 40GBASE-R Alignment Marker Lock state machine invalid AM counter */
-	uint64_t am_lock_sm                   : 2;  /**< 40GBASE-R Alignment Marker Lock state machine state */
+	uint64_t am_lock_invld_cnt            : 2;  /**< 40GBASE-R alignment marker lock state machine invalid AM counter */
+	uint64_t am_lock_sm                   : 2;  /**< 40GBASE-R alignment marker lock state machine state */
 	uint64_t reserved_45_47               : 3;
-	uint64_t train_sm                     : 3;  /**< Link Training state machine state */
-	uint64_t train_code_viol              : 1;  /**< Link Training code violation in received Control Channel */
-	uint64_t train_frame_lock             : 1;  /**< Link Training frame lock status */
-	uint64_t train_lock_found_1st_marker  : 1;  /**< Link Training Lock State Machine found first marker flag */
-	uint64_t train_lock_bad_markers       : 3;  /**< Link Training Lock State Machine bad markers counter */
+	uint64_t train_sm                     : 3;  /**< Link training state machine state */
+	uint64_t train_code_viol              : 1;  /**< Link training code violation in received control channel */
+	uint64_t train_frame_lock             : 1;  /**< Link training frame lock status */
+	uint64_t train_lock_found_1st_marker  : 1;  /**< Link training lock state machine found first marker flag */
+	uint64_t train_lock_bad_markers       : 3;  /**< Link training lock state machine bad markers counter */
 	uint64_t reserved_35_35               : 1;
-	uint64_t an_arb_sm                    : 3;  /**< Auto-Negotiation Arbitration State Machine state */
-	uint64_t an_rx_sm                     : 2;  /**< Auto-Negotiation Receive State Machine state */
+	uint64_t an_arb_sm                    : 3;  /**< Auto-Negotiation arbitration state machine state */
+	uint64_t an_rx_sm                     : 2;  /**< Auto-Negotiation receive state machine state */
 	uint64_t reserved_29_29               : 1;
-	uint64_t fec_block_sync               : 1;  /**< FEC Block Sync status */
+	uint64_t fec_block_sync               : 1;  /**< FEC block sync status */
 	uint64_t fec_sync_cnt                 : 4;  /**< FEC block sync state machine good/bad parity block counter */
 	uint64_t reserved_23_23               : 1;
-	uint64_t br_sh_invld_cnt              : 7;  /**< BASE-R Lock State Machine Invalid Sync Header Counter */
-	uint64_t br_block_lock                : 1;  /**< BASE-R Block Lock status */
-	uint64_t br_sh_cnt                    : 11; /**< BASE-R Lock State Machine Sync Header Counter */
-	uint64_t bx_sync_sm                   : 4;  /**< BASE-X PCS Syncronization state machine state */
+	uint64_t br_sh_invld_cnt              : 7;  /**< BASE-R lock state machine invalid sync header counter */
+	uint64_t br_block_lock                : 1;  /**< BASE-R block lock status */
+	uint64_t br_sh_cnt                    : 11; /**< BASE-R lock state machine sync header counter */
+	uint64_t bx_sync_sm                   : 4;  /**< BASE-X PCS synchronization state machine state */
 #else
 	uint64_t bx_sync_sm                   : 4;
 	uint64_t br_sh_cnt                    : 11;
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
index 14021f9..7a99cc6 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -916,6 +916,17 @@ static inline uint64_t CVMX_CIU_PP_POKEX(unsigned long offset)
 #endif
 #define CVMX_CIU_PP_RST (CVMX_ADD_IO_SEG(0x0001070000000700ull))
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU_PP_RST_PENDING CVMX_CIU_PP_RST_PENDING_FUNC()
+static inline uint64_t CVMX_CIU_PP_RST_PENDING_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN70XX)))
+		cvmx_warn("CVMX_CIU_PP_RST_PENDING not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001070000000740ull);
+}
+#else
+#define CVMX_CIU_PP_RST_PENDING (CVMX_ADD_IO_SEG(0x0001070000000740ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_CIU_QLM0 CVMX_CIU_QLM0_FUNC()
 static inline uint64_t CVMX_CIU_QLM0_FUNC(void)
 {
@@ -1364,7 +1375,7 @@ union cvmx_ciu_bist {
 	struct cvmx_ciu_bist_cn61xx           cn66xx;
 	struct cvmx_ciu_bist_s                cn68xx;
 	struct cvmx_ciu_bist_s                cn68xxp1;
-	struct cvmx_ciu_bist_cn61xx           cn70xx;
+	struct cvmx_ciu_bist_cn52xx           cn70xx;
 	struct cvmx_ciu_bist_cn61xx           cnf71xx;
 };
 typedef union cvmx_ciu_bist cvmx_ciu_bist_t;
@@ -12550,7 +12561,12 @@ typedef union cvmx_ciu_pp_pokex cvmx_ciu_pp_pokex_t;
  *
  * Contains the reset control for each PP.  Value of '1' will hold a PP in reset, '0' will
  * release.
- * Resets to all 1's when PCI boot is enabled, 0xe otherwise.
+ * Resets to all 1's when REMOTE_BOOT is enabled, 0xe otherwise.  Writes to this register should
+ * occur
+ * only if the CIU_PP_RST_PENDING register is cleared.
+ * On pass 2, RST_PP_POWER register can be statically set and writes to this register will
+ * automatically enable/disable power
+ * saving when RST_PP_POWER[GATE] is enabled.
  */
 union cvmx_ciu_pp_rst {
 	uint64_t u64;
@@ -12664,6 +12680,30 @@ union cvmx_ciu_pp_rst {
 typedef union cvmx_ciu_pp_rst cvmx_ciu_pp_rst_t;
 
 /**
+ * cvmx_ciu_pp_rst_pending
+ *
+ * This register contains the reset status for each core. A 1 indicated the core is waiting to
+ * change it's reset state.
+ * (Pass 2) Normally a reset change occurs immediately but if RST_PP_POWER[GATE] bit is set and
+ * the core is released from reset
+ * a delay of 64K core clocks per PP will occur to satisify power management.
+ */
+union cvmx_ciu_pp_rst_pending {
+	uint64_t u64;
+	struct cvmx_ciu_pp_rst_pending_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t pend                         : 48; /**< Core waiting on reset to deassert complete.  This register always returns zero on 70xx Pass 1. */
+#else
+	uint64_t pend                         : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_ciu_pp_rst_pending_s      cn70xx;
+};
+typedef union cvmx_ciu_pp_rst_pending cvmx_ciu_pp_rst_pending_t;
+
+/**
  * cvmx_ciu_qlm0
  *
  * Notes:
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu2-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu2-defs.h
index d9eb776..eca97c0 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu2-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu2-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
index 776ddfb..e5a3b59 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -218,17 +218,6 @@ static inline uint64_t CVMX_CIU3_INTR_SLOWDOWN_FUNC(void)
 #define CVMX_CIU3_INTR_SLOWDOWN (CVMX_ADD_IO_SEG(0x0001010000000240ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_CIU3_INT_DBG_SEL CVMX_CIU3_INT_DBG_SEL_FUNC()
-static inline uint64_t CVMX_CIU3_INT_DBG_SEL_FUNC(void)
-{
-	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_CIU3_INT_DBG_SEL not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001010000000200ull);
-}
-#else
-#define CVMX_CIU3_INT_DBG_SEL (CVMX_ADD_IO_SEG(0x0001010000000200ull))
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_CIU3_ISCMEM_BASE CVMX_CIU3_ISCMEM_BASE_FUNC()
 static inline uint64_t CVMX_CIU3_ISCMEM_BASE_FUNC(void)
 {
@@ -317,6 +306,17 @@ static inline uint64_t CVMX_CIU3_PP_RST_FUNC(void)
 #define CVMX_CIU3_PP_RST (CVMX_ADD_IO_SEG(0x0001010000000100ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU3_PP_RST_PENDING CVMX_CIU3_PP_RST_PENDING_FUNC()
+static inline uint64_t CVMX_CIU3_PP_RST_PENDING_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_CIU3_PP_RST_PENDING not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001010000000108ull);
+}
+#else
+#define CVMX_CIU3_PP_RST_PENDING (CVMX_ADD_IO_SEG(0x0001010000000108ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_CIU3_SISCX(unsigned long offset)
 {
 	if (!(
@@ -357,11 +357,22 @@ union cvmx_ciu3_bist {
 	uint64_t u64;
 	struct cvmx_ciu3_bist_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_7_63                : 57;
-	uint64_t bist                         : 7;  /**< BIST results. Hardware sets a bit for each memory that fails BIST. */
-#else
-	uint64_t bist                         : 7;
-	uint64_t reserved_7_63                : 57;
+	uint64_t reserved_11_63               : 53;
+	uint64_t bist                         : 11; /**< BIST results. Hardware sets a bit for each memory that fails BIST. INTERNAL:
+                                                         <10>= ncbo_crd_fif_mem0.
+                                                         <9> = ciu_nbt_sso_req_ram.
+                                                         <8> = ciu_nbt_rsp_ram.
+                                                         <7> = ciu_sso_output_fifo_mem.
+                                                         <6> = ciu_isc_ram2.
+                                                         <5> = ciu_isc_ram1.
+                                                         <4> = ciu_isc_ram0.
+                                                         <3> = ciu_sist_ram.
+                                                         <2> = ciu_idt_ram.
+                                                         <1> = csr req_mem.
+                                                         <0> = ciu3_wdg_ctl_mem. */
+#else
+	uint64_t bist                         : 11;
+	uint64_t reserved_11_63               : 53;
 #endif
 	} s;
 	struct cvmx_ciu3_bist_s               cn78xx;
@@ -616,37 +627,6 @@ union cvmx_ciu3_idtx_ppx {
 typedef union cvmx_ciu3_idtx_ppx cvmx_ciu3_idtx_ppx_t;
 
 /**
- * cvmx_ciu3_int_dbg_sel
- */
-union cvmx_ciu3_int_dbg_sel {
-	uint64_t u64;
-	struct cvmx_ciu3_int_dbg_sel_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_19_63               : 45;
-	uint64_t sel                          : 3;  /**< Selects if all or the specific interrupt is presented on the debug port.
-                                                         0x0 = erst_n
-                                                         0x1 = start_bist
-                                                         0x2 = toggle at coprocessor clock/2 frequency
-                                                         0x3 = All core interrupt bits are ORed together
-                                                         0x4 = Only the selected virtual core/IRQ is selected */
-	uint64_t reserved_10_15               : 6;
-	uint64_t irq                          : 2;  /**< Which IRQ to select: 0x0=IRQ2, 0x1=IRQ3, 0x2=IRQ4. */
-	uint64_t reserved_6_7                 : 2;
-	uint64_t pp                           : 6;  /**< Which core to select. */
-#else
-	uint64_t pp                           : 6;
-	uint64_t reserved_6_7                 : 2;
-	uint64_t irq                          : 2;
-	uint64_t reserved_10_15               : 6;
-	uint64_t sel                          : 3;
-	uint64_t reserved_19_63               : 45;
-#endif
-	} s;
-	struct cvmx_ciu3_int_dbg_sel_s        cn78xx;
-};
-typedef union cvmx_ciu3_int_dbg_sel cvmx_ciu3_int_dbg_sel_t;
-
-/**
  * cvmx_ciu3_intr_ram_ecc_ctl
  */
 union cvmx_ciu3_intr_ram_ecc_ctl {
@@ -676,9 +656,9 @@ union cvmx_ciu3_intr_ram_ecc_st {
 	uint64_t u64;
 	struct cvmx_ciu3_intr_ram_ecc_st_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_59_63               : 5;
-	uint64_t addr                         : 11; /**< Latch the address for latest SBE/DBE that occurred. */
-	uint64_t reserved_6_47                : 42;
+	uint64_t reserved_52_63               : 12;
+	uint64_t addr                         : 20; /**< Latch the address for latest SBE/DBE that occurred. */
+	uint64_t reserved_6_31                : 26;
 	uint64_t sisc_dbe                     : 1;  /**< SISC Double-bit error observed. Throws CIU_INTSN_E::CIU3_ECC_SISC_DBE. */
 	uint64_t sisc_sbe                     : 1;  /**< SISC Single-bit error observed. Throws CIU_INTSN_E::CIU3_ECC_SISC_SBE. */
 	uint64_t idt_dbe                      : 1;  /**< IDT Double-bit error observed. Throws CIU_INTSN_E::CIU3_ECC_IDT_DBE. */
@@ -692,9 +672,9 @@ union cvmx_ciu3_intr_ram_ecc_st {
 	uint64_t idt_dbe                      : 1;
 	uint64_t sisc_sbe                     : 1;
 	uint64_t sisc_dbe                     : 1;
-	uint64_t reserved_6_47                : 42;
-	uint64_t addr                         : 11;
-	uint64_t reserved_59_63               : 5;
+	uint64_t reserved_6_31                : 26;
+	uint64_t addr                         : 20;
+	uint64_t reserved_52_63               : 12;
 #endif
 	} s;
 	struct cvmx_ciu3_intr_ram_ecc_st_s    cn78xx;
@@ -738,12 +718,12 @@ union cvmx_ciu3_intr_slowdown {
 	uint64_t ctl                          : 3;  /**< Slow down CIU interrupt walker processing time. IRQ2/3/4 for all cores are sent to the
                                                          core (MRC) in a serial bus to reduce global routing. There is no backpressure mechanism
                                                          designed for this scheme. It will only be a problem when SCLK is faster; this Control will
-                                                         process 1 interrupt in 2^CTL SCLK cycles. With different a setting, clock rate ratio can
+                                                         process 1 interrupt in 4*2^CTL SCLK cycles. With different a setting, clock rate ratio can
                                                          handle:
                                                          SLOWDOWN sclk_freq/aclk_freq ratio
-                                                         0 3
-                                                         1 6
-                                                         n 3*2n */
+                                                         0 4
+                                                         1 8
+                                                         n 4*2^n */
 #else
 	uint64_t ctl                          : 3;
 	uint64_t reserved_3_63                : 61;
@@ -923,8 +903,9 @@ typedef union cvmx_ciu3_pp_pokex cvmx_ciu3_pp_pokex_t;
  * cvmx_ciu3_pp_rst
  *
  * This register contains the reset control for each core. A 1 holds a core in reset, 0 release
- * from reset. It resets to all ones when REMOTE_BOOT is enabled, all ones excluding bit 0 clear
- * otherwise.
+ * from reset. It resets to all ones when REMOTE_BOOT is enabled or all ones excluding bit 0 when
+ * REMOTE_BOOT is disabled. Writes to this register should occur only if the CIU3_PP_RST_PENDING
+ * register is cleared.
  */
 union cvmx_ciu3_pp_rst {
 	uint64_t u64;
@@ -945,6 +926,30 @@ union cvmx_ciu3_pp_rst {
 typedef union cvmx_ciu3_pp_rst cvmx_ciu3_pp_rst_t;
 
 /**
+ * cvmx_ciu3_pp_rst_pending
+ *
+ * This register contains the reset status for each core.
+ *
+ */
+union cvmx_ciu3_pp_rst_pending {
+	uint64_t u64;
+	struct cvmx_ciu3_pp_rst_pending_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t pend                         : 48; /**< Set if corresponding core is waiting to change its reset state. Normally a reset change
+                                                         occurs immediately but if RST_PP_POWER[GATE] bit is set and the core is released from
+                                                         reset a delay of 64K core clocks between each core reset will apply to satisfy power
+                                                         management. */
+#else
+	uint64_t pend                         : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_ciu3_pp_rst_pending_s     cn78xx;
+};
+typedef union cvmx_ciu3_pp_rst_pending cvmx_ciu3_pp_rst_pending_t;
+
+/**
  * cvmx_ciu3_sisc#
  */
 union cvmx_ciu3_siscx {
diff --git a/arch/mips/include/asm/octeon/cvmx-clock.h b/arch/mips/include/asm/octeon/cvmx-clock.h
index fede873..240c7e5 100644
--- a/arch/mips/include/asm/octeon/cvmx-clock.h
+++ b/arch/mips/include/asm/octeon/cvmx-clock.h
@@ -133,9 +133,9 @@ static inline uint64_t cvmx_clock_get_rate(cvmx_clock_t clock)
 {
 	switch (clock) {
 	case CVMX_CLOCK_RCLK:
+	case CVMX_CLOCK_CORE:
 		return octeon_get_clock_rate();
 	case CVMX_CLOCK_SCLK:
-	case CVMX_CLOCK_CORE:
 	case CVMX_CLOCK_TIM:
 	case CVMX_CLOCK_IPD:
 		return octeon_get_io_clock_rate();
@@ -146,6 +146,7 @@ static inline uint64_t cvmx_clock_get_rate(cvmx_clock_t clock)
 }
 #else
 extern uint64_t cvmx_clock_get_rate(cvmx_clock_t clock);
+extern uint64_t cvmx_clock_get_rate_node(int node, cvmx_clock_t clock);
 #endif
 
 #ifdef	__cplusplus
diff --git a/arch/mips/include/asm/octeon/cvmx-cmd-queue.h b/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
index c53b241..f7f780b 100644
--- a/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
+++ b/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
@@ -82,7 +82,7 @@
  * internal cycle counter to completely eliminate any causes of
  * bus traffic.
  *
- * <hr> $Revision: 85265 $ <hr>
+ * <hr> $Revision: 90195 $ <hr>
  */
 
 #ifndef __CVMX_CMD_QUEUE_H__
@@ -120,7 +120,9 @@ typedef enum {
 	CVMX_CMD_QUEUE_RAID = 0x30000,
 	CVMX_CMD_QUEUE_DMA_BASE = 0x40000,
 #define CVMX_CMD_QUEUE_DMA(queue) ((cvmx_cmd_queue_id_t)(CVMX_CMD_QUEUE_DMA_BASE + (0xffff&(queue))))
-	CVMX_CMD_QUEUE_END = 0x50000,
+	CVMX_CMD_QUEUE_BCH = 0x50000,
+#define CVMX_CMD_QUEUE_BCH(queue) ((cvmx_cmd_queue_id_t)(CVMX_CMD_QUEUE_BCH + (0xffff&(queue))))
+	CVMX_CMD_QUEUE_END = 0x60000,
 } cvmx_cmd_queue_id_t;
 
 /**
@@ -186,7 +188,9 @@ typedef struct {
  *
  * @return CVMX_CMD_QUEUE_SUCCESS or a failure code
  */
-cvmx_cmd_queue_result_t cvmx_cmd_queue_initialize(cvmx_cmd_queue_id_t queue_id, int max_depth, int fpa_pool, int pool_size);
+cvmx_cmd_queue_result_t cvmx_cmd_queue_initialize(cvmx_cmd_queue_id_t queue_id,
+						  int max_depth, int fpa_pool,
+						  int pool_size);
 
 /**
  * Shutdown a queue a free it's command buffers to the FPA. The
@@ -231,10 +235,12 @@ void *cvmx_cmd_queue_buffer(cvmx_cmd_queue_id_t queue_id);
  */
 static inline int __cvmx_cmd_queue_get_index(cvmx_cmd_queue_id_t queue_id)
 {
-	/* Warning: This code currently only works with devices that have 256 queues
-	   or less. Devices with more than 16 queues are laid out in memory to allow
-	   cores quick access to every 16th queue. This reduces cache thrashing
-	   when you are running 16 queues per port to support lockless operation */
+	/* Warning: This code currently only works with devices that have 256
+	 * queues or less.  Devices with more than 16 queues are laid out in
+	 * memory to allow cores quick access to every 16th queue. This reduces
+	 * cache thrashing when you are running 16 queues per port to support
+	 * lockless operation
+	 */
 	int unit = queue_id >> 16;
 	int q = (queue_id >> 4) & 0xf;
 	int core = queue_id & 0xf;
@@ -248,7 +254,9 @@ static inline int __cvmx_cmd_queue_get_index(cvmx_cmd_queue_id_t queue_id)
  *
  * @param queue_id Queue ID to lock
  * @param qptr     Pointer to the queue's global state
- */ static inline void __cvmx_cmd_queue_lock(cvmx_cmd_queue_id_t queue_id, __cvmx_cmd_queue_state_t * qptr)
+ */
+static inline void __cvmx_cmd_queue_lock(cvmx_cmd_queue_id_t queue_id,
+					 __cvmx_cmd_queue_state_t * qptr)
 {
 	extern CVMX_SHARED __cvmx_cmd_queue_all_state_t *__cvmx_cmd_queue_state_ptr;
 	int tmp;
@@ -258,7 +266,9 @@ static inline int __cvmx_cmd_queue_get_index(cvmx_cmd_queue_id_t queue_id)
 		      ".set noreorder\n"
 		      "1:\n"
 		      "lld     %[my_ticket], %[ticket_ptr]\n"
-		      /* Atomic add one to ticket_ptr 64-bit operation for endian nutral access. */
+		      /* Atomic add one to ticket_ptr 64-bit operation for
+		       * endian nutral access.
+		       */
 		      "daddiu  %[ticket], %[my_ticket], 1\n"
 		      /*    and store the original value  in my_ticket */
 		      "scd     %[ticket], %[ticket_ptr]\n"
@@ -306,7 +316,8 @@ static inline void __cvmx_cmd_queue_unlock(__cvmx_cmd_queue_state_t * qptr)
  *
  * @return Queue structure or NULL on failure
  */
-static inline __cvmx_cmd_queue_state_t *__cvmx_cmd_queue_get_state(cvmx_cmd_queue_id_t queue_id)
+static inline __cvmx_cmd_queue_state_t *
+__cvmx_cmd_queue_get_state(cvmx_cmd_queue_id_t queue_id)
 {
 	extern CVMX_SHARED __cvmx_cmd_queue_all_state_t *__cvmx_cmd_queue_state_ptr;
 	if (CVMX_ENABLE_PARAMETER_CHECKING) {
@@ -333,7 +344,9 @@ static inline __cvmx_cmd_queue_state_t *__cvmx_cmd_queue_get_state(cvmx_cmd_queu
  *
  * @return CVMX_CMD_QUEUE_SUCCESS or a failure code
  */
-static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write(cvmx_cmd_queue_id_t queue_id, int use_locking, int cmd_count, uint64_t * cmds)
+static inline cvmx_cmd_queue_result_t
+cvmx_cmd_queue_write(cvmx_cmd_queue_id_t queue_id, int use_locking,
+		     int cmd_count, uint64_t * cmds)
 {
 	__cvmx_cmd_queue_state_t *qptr = __cvmx_cmd_queue_get_state(queue_id);
 
@@ -379,16 +392,18 @@ static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write(cvmx_cmd_queue_id_t q
 			return CVMX_CMD_QUEUE_NO_MEMORY;
 		}
 		ptr = (uint64_t *) cvmx_phys_to_ptr((uint64_t) qptr->base_ptr_div128 << 7);
-		/* Figure out how many command words will fit in this buffer. One
-		   location will be needed for the next buffer pointer */
+		/* Figure out how many command words will fit in this buffer.
+		 * One location will be needed for the next buffer pointer
+		 */
 		count = qptr->pool_size_m1 - qptr->index;
 		ptr += qptr->index;
 		cmd_count -= count;
 		while (count--)
 			*ptr++ = *cmds++;
 		*ptr = cvmx_ptr_to_phys(new_buffer);
-		/* The current buffer is full and has a link to the next buffer. Time
-		   to write the rest of the commands into the new buffer */
+		/* The current buffer is full and has a link to the next buffer.
+		 * Time to write the rest of the commands into the new buffer
+		 */
 		qptr->base_ptr_div128 = *ptr >> 7;
 		qptr->index = cmd_count;
 		ptr = new_buffer;
@@ -416,7 +431,9 @@ static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write(cvmx_cmd_queue_id_t q
  *
  * @return CVMX_CMD_QUEUE_SUCCESS or a failure code
  */
-static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write2(cvmx_cmd_queue_id_t queue_id, int use_locking, uint64_t cmd1, uint64_t cmd2)
+static inline cvmx_cmd_queue_result_t
+cvmx_cmd_queue_write2(cvmx_cmd_queue_id_t queue_id, int use_locking,
+		      uint64_t cmd1, uint64_t cmd2)
 {
 	__cvmx_cmd_queue_state_t *qptr = __cvmx_cmd_queue_get_state(queue_id);
 
@@ -497,7 +514,9 @@ static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write2(cvmx_cmd_queue_id_t
  *
  * @return CVMX_CMD_QUEUE_SUCCESS or a failure code
  */
-static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write3(cvmx_cmd_queue_id_t queue_id, int use_locking, uint64_t cmd1, uint64_t cmd2, uint64_t cmd3)
+static inline cvmx_cmd_queue_result_t
+cvmx_cmd_queue_write3(cvmx_cmd_queue_id_t queue_id, int use_locking,
+		      uint64_t cmd1, uint64_t cmd2, uint64_t cmd3)
 {
 	__cvmx_cmd_queue_state_t *qptr = __cvmx_cmd_queue_get_state(queue_id);
 
@@ -531,8 +550,9 @@ static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write3(cvmx_cmd_queue_id_t
 		ptr[2] = cmd3;
 	} else {
 		uint64_t *ptr;
-		/* Figure out how many command words will fit in this buffer. One
-		   location will be needed for the next buffer pointer */
+		/* Figure out how many command words will fit in this buffer.
+		 * One location will be needed for the next buffer pointer
+		 */
 		int count = qptr->pool_size_m1 - qptr->index;
 		/* We need a new command buffer. Fail if there isn't one available */
 		uint64_t *new_buffer = (uint64_t *) cvmx_fpa_alloc(qptr->fpa_pool);
@@ -551,8 +571,9 @@ static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write3(cvmx_cmd_queue_id_t
 				*ptr++ = cmd3;
 		}
 		*ptr = cvmx_ptr_to_phys(new_buffer);
-		/* The current buffer is full and has a link to the next buffer. Time
-		   to write the rest of the commands into the new buffer */
+		/* The current buffer is full and has a link to the next buffer.
+		 * Time to write the rest of the commands into the new buffer
+		 */
 		qptr->base_ptr_div128 = *ptr >> 7;
 		qptr->index = 0;
 		ptr = new_buffer;
diff --git a/arch/mips/include/asm/octeon/cvmx-core.h b/arch/mips/include/asm/octeon/cvmx-core.h
index 8bee2e6..848498f 100644
--- a/arch/mips/include/asm/octeon/cvmx-core.h
+++ b/arch/mips/include/asm/octeon/cvmx-core.h
@@ -42,7 +42,7 @@
  *
  * Module to support operations on core such as TLB config, etc.
  *
- * <hr>$Revision: 84158 $<hr>
+ * <hr>$Revision: 90021 $<hr>
  *
  */
 
@@ -208,20 +208,20 @@ typedef enum cvmx_core_perf {
 	CVMX_CORE_PERF_FPADDSUB = 87,
 				     /**< Number of retired FP ADD.fmt and SUB.fmt instructions */
 	CVMX_CORE_PERF_FPCVT = 88,
-				     /**< Number of retired FP ormat conversion instructions (e.g., CVT.S.D) */
+				     /**< Number of retired FP format conversion instructions (e.g., CVT.S.D) */
 	CVMX_CORE_PERF_FPMUL = 89,
 				     /**< Number of retired FP MUL.fmt instructions */
-	CVMX_CORE_PERF_FPMADD = 96,
+	CVMX_CORE_PERF_FPMADD = 90,
 				     /**< Number of retired FP MADD.fmt variant instructions */
-	CVMX_CORE_PERF_FPDIVRECIP = 97,
+	CVMX_CORE_PERF_FPDIVRECIP = 91,
 				     /**< Number of retired FP DIV.fmt and RECIP.fmt instructions */
-	CVMX_CORE_PERF_FPSQRTRSQRT = 98,
+	CVMX_CORE_PERF_FPSQRTRSQRT = 92,
 				     /**< Number of retired FP SQRT.fmt and RSQRT.fmt instructions */
-	CVMX_CORE_PERF_FPLOAD = 99,
+	CVMX_CORE_PERF_FPLOAD = 93,
 				     /**< Number of retired FP load instructions */
-	CVMX_CORE_PERF_FPSTORE = 100,
+	CVMX_CORE_PERF_FPSTORE = 94,
 				     /**< Number of retired FP store instructions */
-	CVMX_CORE_PERF_FPALL = 101,
+	CVMX_CORE_PERF_FPALL = 95,
 				     /**< Number of retired FP instructions(all) */
 	CVMX_CORE_PERF_MAX	     /**< This not a counter, just a marker for the highest number */
 } cvmx_core_perf_t;
@@ -234,7 +234,14 @@ typedef union cvmx_core_perf_control {
 #ifdef __BIG_ENDIAN_BITFIELD
 		uint32_t m:1;	     /**< Set to 1 for sel 0 and 0 for sel 2, indicating there are two performance counters */
 		uint32_t w:1;	     /**< Set to 1 indicating counters are 64 bit */
-		uint32_t reserved_11_29:15;
+		uint32_t reserved_25_29:5;
+		uint32_t ec:2;       /**< Event Class
+					  0x0 = root events counted; active in root context
+					  0x1 = root intervention events counted; active in root context
+					  0x2 = guest events counted; active in guest context
+					  0x3 = guest events plus root intervention events counted; active in guest
+context */
+		uint32_t reserved_15_22:8;
 		cvmx_core_perf_t event:10;
 				     /**< Selects the event to be counted by the corresponding Counter Register */
 		uint32_t ie:1;
@@ -251,7 +258,9 @@ typedef union cvmx_core_perf_control {
 		uint32_t u:1;
 		uint32_t ie:1;
 		uint32_t event:10;
-		uint32_t reserved_11_29:15;
+		uint32_t reserved_15_22:8;
+		uint32_t ec:2;
+		uint32_t reserved_25_29:5;
 		uint32_t w:1;
 		uint32_t m:1;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-coremask.h b/arch/mips/include/asm/octeon/cvmx-coremask.h
index 00b590e..64cc999 100644
--- a/arch/mips/include/asm/octeon/cvmx-coremask.h
+++ b/arch/mips/include/asm/octeon/cvmx-coremask.h
@@ -60,7 +60,7 @@
  * provide future compatibility if more cores are added to future processors
  * or more nodes are supported.
  *
- * <hr>$Revision: 83933 $<hr>
+ * <hr>$Revision: 87873 $<hr>
  *
  */
 
@@ -371,8 +371,16 @@ static inline uint32_t cvmx_coremask_get32(const cvmx_coremask_t *pcm)
 static inline int cvmx_coremask_cmp(const cvmx_coremask_t *pcm1,
 				    const cvmx_coremask_t *pcm2)
 {
-	return memcmp((void *)pcm1->coremask_bitmap,
-	    (void *)pcm2->coremask_bitmap, CVMX_MAX_USED_CORES_BMP / 8);
+	int i;
+	/* Start from highest node for arithemtically correct result */
+	for ( i = CVMX_COREMASK_USED_BMPSZ-1; i >= 0 ; i-- )
+		if( pcm1->coremask_bitmap[i] != pcm2->coremask_bitmap[i] )
+			return (
+				pcm1->coremask_bitmap[i] -
+				pcm2->coremask_bitmap[i] 
+				);
+
+	return 0;
 }
 
 /*
@@ -607,20 +615,15 @@ cvmx_coremask_is_core_first_core(const cvmx_coremask_t *pcm,
 	return (__builtin_ffs(pcm->coremask_bitmap[n]) == core + 1);
 }
 
-/**
- * Test to see if current core is first core in coremask.
- *
- * @param[in]  pcm  pointer to the coremask to test against
- *
- * @return  1 if current core is first core in the coremask, 0 otherwise
- *
+/*
+ * NOTE:
+ * cvmx_coremask_is_first_core() was retired due to improper usage.
+ * For inquiring about the current core being the initializing
+ * core for an application, use cvmx_is_init_core().
+ * For simply inquring if the current core is numerically
+ * lowest in a given mask, use :
+ * 	cvmx_coremask_is_core_first_core( pcm, dvmx_get_core_num())
  */
-static inline int
-cvmx_coremask_is_first_core(const cvmx_coremask_t *pcm)
-{
-	return cvmx_coremask_is_core_first_core(pcm,
-						cvmx_get_core_num());
-}
 
 /**
  * Returns the number of 1 bits set in a coremask
diff --git a/arch/mips/include/asm/octeon/cvmx-dbg-defs.h b/arch/mips/include/asm/octeon/cvmx-dbg-defs.h
index 022c714..2edabc2 100644
--- a/arch/mips/include/asm/octeon/cvmx-dbg-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-dbg-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-debug.h b/arch/mips/include/asm/octeon/cvmx-debug.h
index 3c3dbf0..0902f8e 100644
--- a/arch/mips/include/asm/octeon/cvmx-debug.h
+++ b/arch/mips/include/asm/octeon/cvmx-debug.h
@@ -42,7 +42,6 @@
  *
  * Interface to debug exception handler
  *
- * <hr>$Revision:  $<hr>
  */
 
 #ifndef __CVMX_DEBUG_H__
@@ -55,7 +54,7 @@
 #define CVMX_DEBUG_MAX_RESPONSE_SIZE 1024 + 5
 
 #define CVMX_DEBUG_GLOBALS_BLOCK_NAME "cvmx-debug-globals"
-#define CVMX_DEBUG_GLOBALS_VERSION 5
+#define CVMX_DEBUG_GLOBALS_VERSION 6
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
@@ -252,26 +251,26 @@ typedef enum {
 			/**< The focus core changed */
 } cvmx_debug_command_t;
 
-/* Every field in this struct has to be uint32_t. */
+/* Every field in this struct has to be uint64_t. */
 typedef struct {
-	uint32_t known_cores;
-	uint32_t step_isr;
+	uint64_t known_cores;
+	uint64_t step_isr;
 				/**< True if we are going to step into ISR's. */
-	uint32_t focus_switch;
+	uint64_t focus_switch;
 				/**< Focus can be switched. */
-	uint32_t core_finished;
+	uint64_t core_finished;
 				/**< True if a core has finished and not been processed yet.  */
-	uint32_t command;
+	uint64_t command;
 				/**< Command for all cores (cvmx_debug_command_t) */
-	uint32_t step_all;
+	uint64_t step_all;
 				/**< True if step and continue should affect all cores. False, only the focus core is affected */
-	uint32_t focus_core;
+	uint64_t focus_core;
 				/**< Core currently under control of the debugger */
-	uint32_t active_cores;
+	uint64_t active_cores;
 				/**< Bitmask of cores that should stop on a breakpoint */
-	uint32_t handler_cores;
+	uint64_t handler_cores;
 				/**< Bitmask of cores currently running the exception handler */
-	uint32_t ever_been_in_debug;
+	uint64_t ever_been_in_debug;
 				    /**< True if we have been ever been in the debugger stub at all.  */
 } __attribute__ ((aligned(sizeof(uint64_t)))) cvmx_debug_state_t;
 
@@ -282,9 +281,10 @@ typedef struct cvmx_debug_globals_s {
 	uint64_t comm_type;	/* cvmx_debug_comm_type_t */
 	volatile uint64_t comm_changed;	/* cvmx_debug_comm_type_t+1 when someone wants to change it. */
 	volatile uint64_t init_complete;
-	uint32_t tlb_entries;
-	uint32_t state[sizeof(cvmx_debug_state_t) / sizeof(uint32_t)];
+	uint64_t tlb_entries;
+	uint64_t state[sizeof(cvmx_debug_state_t) / sizeof(uint64_t)];
 	cvmx_spinlock_t lock;
+	uint32_t pad;
 
 	volatile cvmx_debug_core_context_t contextes[CVMX_MAX_CORES];
 } cvmx_debug_globals_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
index bf9acfe..f6ee9f7 100644
--- a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -286,6 +286,17 @@ static inline uint64_t CVMX_DPI_DMA_PPX_CNT(unsigned long offset)
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_DPI_DMA_PP_INT CVMX_DPI_DMA_PP_INT_FUNC()
+static inline uint64_t CVMX_DPI_DMA_PP_INT_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_DPI_DMA_PP_INT not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001DF0000000038ull);
+}
+#else
+#define CVMX_DPI_DMA_PP_INT (CVMX_ADD_IO_SEG(0x0001DF0000000038ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_DPI_ECC_CTL CVMX_DPI_ECC_CTL_FUNC()
 static inline uint64_t CVMX_DPI_ECC_CTL_FUNC(void)
 {
@@ -339,7 +350,7 @@ static inline uint64_t CVMX_DPI_INFO_REG_FUNC(void)
 #define CVMX_DPI_INT_EN CVMX_DPI_INT_EN_FUNC()
 static inline uint64_t CVMX_DPI_INT_EN_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
 		cvmx_warn("CVMX_DPI_INT_EN not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001DF0000000010ull);
 }
@@ -566,6 +577,17 @@ static inline uint64_t CVMX_DPI_SLI_PRTX_ERR_INFO(unsigned long offset)
 #else
 #define CVMX_DPI_SLI_PRTX_ERR_INFO(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000940ull) + ((offset) & 3) * 8)
 #endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_DPI_SWA_Q_VMID CVMX_DPI_SWA_Q_VMID_FUNC()
+static inline uint64_t CVMX_DPI_SWA_Q_VMID_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_DPI_SWA_Q_VMID not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001DF0000000030ull);
+}
+#else
+#define CVMX_DPI_SWA_Q_VMID (CVMX_ADD_IO_SEG(0x0001DF0000000030ull))
+#endif
 
 /**
  * cvmx_dpi_bist_status
@@ -577,6 +599,17 @@ union cvmx_dpi_bist_status {
 	uint64_t u64;
 	struct cvmx_dpi_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_51_63               : 13;
+	uint64_t bist                         : 51; /**< BIST Results.
+                                                         HW sets a bit in BIST for for memory that fails
+                                                         BIST. */
+#else
+	uint64_t bist                         : 51;
+	uint64_t reserved_51_63               : 13;
+#endif
+	} s;
+	struct cvmx_dpi_bist_status_cn61xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_47_63               : 17;
 	uint64_t bist                         : 47; /**< BIST Results.
                                                          HW sets a bit in BIST for for memory that fails
@@ -585,8 +618,7 @@ union cvmx_dpi_bist_status {
 	uint64_t bist                         : 47;
 	uint64_t reserved_47_63               : 17;
 #endif
-	} s;
-	struct cvmx_dpi_bist_status_s         cn61xx;
+	} cn61xx;
 	struct cvmx_dpi_bist_status_cn63xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_45_63               : 19;
@@ -609,12 +641,12 @@ union cvmx_dpi_bist_status {
 	uint64_t reserved_37_63               : 27;
 #endif
 	} cn63xxp1;
-	struct cvmx_dpi_bist_status_s         cn66xx;
+	struct cvmx_dpi_bist_status_cn61xx    cn66xx;
 	struct cvmx_dpi_bist_status_cn63xx    cn68xx;
 	struct cvmx_dpi_bist_status_cn63xx    cn68xxp1;
-	struct cvmx_dpi_bist_status_s         cn70xx;
-	struct cvmx_dpi_bist_status_cn63xx    cn78xx;
-	struct cvmx_dpi_bist_status_s         cnf71xx;
+	struct cvmx_dpi_bist_status_cn61xx    cn70xx;
+	struct cvmx_dpi_bist_status_s         cn78xx;
+	struct cvmx_dpi_bist_status_cn61xx    cnf71xx;
 };
 typedef union cvmx_dpi_bist_status cvmx_dpi_bist_status_t;
 
@@ -1547,6 +1579,24 @@ union cvmx_dpi_dma_ppx_cnt {
 typedef union cvmx_dpi_dma_ppx_cnt cvmx_dpi_dma_ppx_cnt_t;
 
 /**
+ * cvmx_dpi_dma_pp_int
+ */
+union cvmx_dpi_dma_pp_int {
+	uint64_t u64;
+	struct cvmx_dpi_dma_pp_int_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t complete                     : 48; /**< DPI DMA per-core instruction completion interrupt.  See DPI_DMA_PP(0..47)_CNT. */
+#else
+	uint64_t complete                     : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_dpi_dma_pp_int_s          cn78xx;
+};
+typedef union cvmx_dpi_dma_pp_int cvmx_dpi_dma_pp_int_t;
+
+/**
  * cvmx_dpi_ecc_ctl
  *
  * This register allows inserting ECC errors for testing.
@@ -1556,17 +1606,21 @@ union cvmx_dpi_ecc_ctl {
 	uint64_t u64;
 	struct cvmx_dpi_ecc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t ram_cdis                     : 16; /**< RDB RAM ECC correction disable. Each bit corresponds to a different RAM. */
-	uint64_t ram_flip1                    : 16; /**< Flip syndrome bits on write. Flip syndrome bits <1> on writes to the corresponding RDB ram
+	uint64_t reserved_33_63               : 31;
+	uint64_t ram_cdis                     : 1;  /**< RDB RAM ECC correction disable. Each bit corresponds to a different RAM. */
+	uint64_t reserved_17_31               : 15;
+	uint64_t ram_flip1                    : 1;  /**< Flip syndrome bits on write. Flip syndrome bits <1> on writes to the corresponding RDB ram
                                                          to test single-bit or double-bit error handling. */
-	uint64_t ram_flip0                    : 16; /**< Flip syndrome bits on write. Flip syndrome bits <0> on writes to the corresponding RDB ram
+	uint64_t reserved_1_15                : 15;
+	uint64_t ram_flip0                    : 1;  /**< Flip syndrome bits on write. Flip syndrome bits <0> on writes to the corresponding RDB ram
                                                          to test single-bit or double-bit error handling. */
 #else
-	uint64_t ram_flip0                    : 16;
-	uint64_t ram_flip1                    : 16;
-	uint64_t ram_cdis                     : 16;
-	uint64_t reserved_48_63               : 16;
+	uint64_t ram_flip0                    : 1;
+	uint64_t reserved_1_15                : 15;
+	uint64_t ram_flip1                    : 1;
+	uint64_t reserved_17_31               : 15;
+	uint64_t ram_cdis                     : 1;
+	uint64_t reserved_33_63               : 31;
 #endif
 	} s;
 	struct cvmx_dpi_ecc_ctl_s             cn78xx;
@@ -1583,17 +1637,17 @@ union cvmx_dpi_ecc_int {
 	uint64_t u64;
 	struct cvmx_dpi_ecc_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_55_63               : 9;
-	uint64_t ram_dbe                      : 23; /**< Set when a double-bit error is detected in the corresponding ram. Throws
-                                                         DPI_INTSN_E::DPI_ERR_RAM_DBE. */
-	uint64_t reserved_23_31               : 9;
-	uint64_t ram_sbe                      : 23; /**< Set when a single-bit error is detected in the corresponding ram. Throws
+	uint64_t reserved_47_63               : 17;
+	uint64_t ram_sbe                      : 15; /**< Set when a single-bit error is detected in the corresponding ram. Throws
                                                          DPI_INTSN_E::DPI_ERR_RAM_SBE. */
+	uint64_t reserved_15_31               : 17;
+	uint64_t ram_dbe                      : 15; /**< Set when a double-bit error is detected in the corresponding ram. Throws
+                                                         DPI_INTSN_E::DPI_ERR_RAM_DBE. */
 #else
-	uint64_t ram_sbe                      : 23;
-	uint64_t reserved_23_31               : 9;
-	uint64_t ram_dbe                      : 23;
-	uint64_t reserved_55_63               : 9;
+	uint64_t ram_dbe                      : 15;
+	uint64_t reserved_15_31               : 17;
+	uint64_t ram_sbe                      : 15;
+	uint64_t reserved_47_63               : 17;
 #endif
 	} s;
 	struct cvmx_dpi_ecc_int_s             cn78xx;
@@ -1819,7 +1873,6 @@ union cvmx_dpi_int_en {
 	struct cvmx_dpi_int_en_cn63xx         cn68xx;
 	struct cvmx_dpi_int_en_cn63xx         cn68xxp1;
 	struct cvmx_dpi_int_en_s              cn70xx;
-	struct cvmx_dpi_int_en_s              cn78xx;
 	struct cvmx_dpi_int_en_s              cnf71xx;
 };
 typedef union cvmx_dpi_int_en cvmx_dpi_int_en_t;
@@ -2689,4 +2742,37 @@ union cvmx_dpi_sli_prtx_err_info {
 };
 typedef union cvmx_dpi_sli_prtx_err_info cvmx_dpi_sli_prtx_err_info_t;
 
+/**
+ * cvmx_dpi_swa_q_vmid
+ *
+ * This register defines.
+ *
+ */
+union cvmx_dpi_swa_q_vmid {
+	uint64_t u64;
+	struct cvmx_dpi_swa_q_vmid_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t vmid7                        : 8;  /**< The SWA VMID for Queue 7. */
+	uint64_t vmid6                        : 8;  /**< The SWA VMID for Queue 6. */
+	uint64_t vmid5                        : 8;  /**< The SWA VMID for Queue 5. */
+	uint64_t vmid4                        : 8;  /**< The SWA VMID for Queue 4. */
+	uint64_t vmid3                        : 8;  /**< The SWA VMID for Queue 3. */
+	uint64_t vmid2                        : 8;  /**< The SWA VMID for Queue 2. */
+	uint64_t vmid1                        : 8;  /**< The SWA VMID for Queue 1. */
+	uint64_t vmid0                        : 8;  /**< The SWA VMID for Queue 0. */
+#else
+	uint64_t vmid0                        : 8;
+	uint64_t vmid1                        : 8;
+	uint64_t vmid2                        : 8;
+	uint64_t vmid3                        : 8;
+	uint64_t vmid4                        : 8;
+	uint64_t vmid5                        : 8;
+	uint64_t vmid6                        : 8;
+	uint64_t vmid7                        : 8;
+#endif
+	} s;
+	struct cvmx_dpi_swa_q_vmid_s          cn78xx;
+};
+typedef union cvmx_dpi_swa_q_vmid cvmx_dpi_swa_q_vmid_t;
+
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa-defs.h b/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
index 3d7725e..3441908 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1573,8 +1573,8 @@ union cvmx_fpa_gen_cfg {
                                                          0x1 = 32 pools, 640 FPF entries per pool.
                                                          0x2 = 16 pools, 1280 FPF entries per pool.
                                                          0x3 = Reserved */
-	uint64_t avg_en                       : 1;  /**< QoS Averaging enable. When set, compute average buffer levels. When clear, do not compute
-                                                         averages and save a few mW of power. */
+	uint64_t avg_en                       : 1;  /**< QoS averaging enable. When set, compute average buffer levels, and [LVL_DLY] must be non-
+                                                         zero. When clear, do not compute averages and save a few mW of power. */
 	uint64_t reserved_0_0                 : 1;
 #else
 	uint64_t reserved_0_0                 : 1;
@@ -3289,7 +3289,7 @@ union cvmx_fpa_poolx_op_pc {
 	uint64_t u64;
 	struct cvmx_fpa_poolx_op_pc_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t count                        : 64; /**< Number of allocations or returns performed to this poolFPA_POOL(0..63)_STACK_BASE. */
+	uint64_t count                        : 64; /**< Number of allocations or returns performed to this pool, including those that fail due to RED. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -3718,7 +3718,9 @@ union cvmx_fpa_sft_rst {
 	uint64_t busy                         : 1;  /**< When 1, FPA is busy completing reset. No access except the reading of this bit should
                                                          occur to the FPA until this is clear. */
 	uint64_t reserved_1_62                : 62;
-	uint64_t rst                          : 1;  /**< Reset. When set to 1 by software, FPA gets a short reset pulse (three cycles in duration). */
+	uint64_t rst                          : 1;  /**< Reset. When set to 1 by software, FPA gets a short reset pulse (three cycles in duration).
+                                                         Following a write to this register and prior to performing another FPA operation, software
+                                                         must write SSO_BIST_STATUS0 (or any register on the same IOI bus as FPA) and read it back. */
 #else
 	uint64_t rst                          : 1;
 	uint64_t reserved_1_62                : 62;
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa.h b/arch/mips/include/asm/octeon/cvmx-fpa.h
index 1331635..311cebd 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa.h
@@ -42,7 +42,7 @@
  *
  * Interface to the hardware Free Pool Allocator.
  *
- * <hr>$Revision: 85179 $<hr>
+ * <hr>$Revision: 86473 $<hr>
  *
  */
 
@@ -69,6 +69,8 @@ extern "C" {
 #define CVMX_FPA_AURA_NUM       1024
 #define CVMX_FPA_MIN_BLOCK_SIZE 128
 #define CVMX_FPA_ALIGNMENT      128
+#define CVMX_FPA_POOL_NAME_LEN  16
+#define CVMX_FPA_AURA_NAME_LEN  16
 
 /**
  * Structure describing the data format used for stores to the FPA.
@@ -192,7 +194,7 @@ enum fpa_pool_alignment {
  * Structure describing the current state of a FPA pool.
  */
 typedef struct {
-	const char *name;		/**< Name it was created under */
+	char name[CVMX_FPA_POOL_NAME_LEN];	/**< FPA Pool Name */
 	uint64_t size;			/**< Size of each block */
 	void *base;			/**< The base memory address of whole block */
 	uint64_t stack_base;               /**< Base address of stack of FPA pool */
@@ -206,6 +208,7 @@ typedef struct {
  * Structure which contains information on auras.
  */
 typedef struct {
+	char name[CVMX_FPA_AURA_NAME_LEN];
 	int pool_num;
 } cvmx_fpa_aura_info_t;
 
@@ -608,6 +611,7 @@ int cvmx_fpa_release_pool(int pool);
  * the FPA pool with kernel memory as opposed to using bootmem.
  * @param node     - specifies the node of FPA pool.
  * @parma pool     - Specifies the FPA pool number.
+ * @param name     - Specifies the FPA pool name.
  * @param mem_node - specifies the node from which the memory for the stack
  *                   is allocated.
  * @param max_buffer_cnt - specifies the maximum buffers that FPA pool can hold.
@@ -616,8 +620,9 @@ int cvmx_fpa_release_pool(int pool);
  *                         to specify the size of each buffer in the FPA .
  *
  */
-int cvmx_fpa_pool_stack_init(int node, int pool, int mem_node, int max_buffer_cnt,
-			     enum fpa_pool_alignment align, int buffer_sz);
+int cvmx_fpa_pool_stack_init(int node, int pool, char *name, int mem_node,
+		int max_buffer_cnt, enum fpa_pool_alignment align,
+		int buffer_sz);
 
 /**
  * This call will allocated buffers_cnt number of buffers from  the bootmemory
@@ -630,13 +635,14 @@ int cvmx_fpa_pool_stack_init(int node, int pool, int mem_node, int max_buffer_cn
  * in the pool using it's own allocation mechanism.
  * @param node     - specifies the node of aura to be initialized
  * @parma aura     - specifies the aura to be initalized.
+ * @param name     - specifies the name of aura to be initalized.
  * @param mem_node - specifies the node from which the memory for the buffers
  *                   is allocated.
  * @param ptr_dis - Need to look into this more but is on the lines of of whether
  * the hardware checks double frees.
  */
-int cvmx_fpa_aura_init(int node, int aura, int mem_node, int buffers_cnt,
-		       int ptr_dis);
+int cvmx_fpa_aura_init(int node, int aura, char *name, int mem_node,
+		int buffers_cnt, int ptr_dis);
 int cvmx_fpa_config_red_params(int node, int qos_avg_en, int red_lvl_dly, int avg_dly);
 
 /**
@@ -660,6 +666,16 @@ static inline int cvmx_fpa_assign_aura(int node, int aura, int pool_index)
 
 int cvmx_fpa_allocate_auras(int node, int auras_allocated[], int count);
 int cvmx_fpa_free_auras(int node, int *pools_allocated, int count);
+/**
+ * This will allocate count number of FPA pools on the specified node to the
+ * calling application. These pools will be for exclusive use of the application
+ * until they are freed.
+ * @param pools_allocated is an array of length count allocated by the application
+ * before invoking the cvmx_allocate_fpa_pool call. On return it will contain the
+ * index numbers of the pools allocated.
+ * @return 0 on success and -1 on failure.
+ */
+int cvmx_fpa_allocate_fpa_pools(int node, int pools_allocated[], int count);
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-global-resources.h b/arch/mips/include/asm/octeon/cvmx-global-resources.h
index 2c329c2..e12d06d 100644
--- a/arch/mips/include/asm/octeon/cvmx-global-resources.h
+++ b/arch/mips/include/asm/octeon/cvmx-global-resources.h
@@ -14,9 +14,18 @@
 #define CVMX_GR_TAG_CLUSTERS(x)	    cvmx_get_gr_tag('c','v','m','_','c','l','u','s','t','e','r','_',(x+'0'),'.','.','.')
 #define CVMX_GR_TAG_CLUSTER_GRP(x)  cvmx_get_gr_tag('c','v','m','_','c','l','g','r','p','_',(x+'0'),'.','.','.','.','.')
 #define CVMX_GR_TAG_STYLE(x)        cvmx_get_gr_tag('c','v','m','_','s','t','y','l','e','_',(x+'0'),'.','.','.','.','.')
+#define CVMX_GR_TAG_QPG_ENTRY(x)    cvmx_get_gr_tag('c','v','m','_','q','p','g','e','t','_',(x+'0'),'.','.','.','.','.')
 #define CVMX_GR_TAG_PCAM(x,y,z) \
 	cvmx_get_gr_tag('c','v','m','_','p','c','a','m','_',(x+'0'),(y+'0'),(z+'0'),'.','.','.','.')
 
+#define CVMX_GR_TAG_CIU3_IDT(_n) \
+	cvmx_get_gr_tag('c','v','m','_','c','i','u','3','_', ((_n) + '0'),'_','i','d','t','.','.')
+
+
+/* Allocation of the 512 SW INTSTs (in the  12 bit SW INTSN space) */
+#define CVMX_GR_TAG_CIU3_SWINTSN(_n) \
+	cvmx_get_gr_tag('c','v','m','_','c','i','u','3','_', ((_n) + '0'),'_','s','w','i','s','n')
+
 
 #define TAG_INIT_PART(A,B,C,D,E,F,G,H) ( \
 	(((uint64_t)(A) & 0xff) << 56) | (((uint64_t)(B) & 0xff) << 48) | (((uint64_t)(C) & 0xff) << 40)  | (((uint64_t)(D) & 0xff) << 32) | \
@@ -82,10 +91,10 @@ int cvmx_allocate_global_resource_range(struct global_resource_tag tag,
  * @param allocated_elements returns indexs of the allocated entries.
  * @return returns 0 on success and -1 on failure.
  */
-int cvmx_allocate_global_resource_range_non_contiguos(struct global_resource_tag tag,
-						      uint64_t owner,
-						      int nelements,
-						      int allocated_elements[]);
+int cvmx_resource_alloc_many(struct global_resource_tag tag,
+			     uint64_t owner,
+			     int nelements,
+			     int allocated_elements[]);
 /*
  * @INTERNAL
  * Reserve nelements starting from base in the global resource range with the
@@ -156,10 +165,6 @@ void  cvmx_show_global_resource_range(struct global_resource_tag tag);
  */
 void cvmx_global_resources_show(void);
 
-int cvmx_allocate_global_resource_range_non_contiguous(struct global_resource_tag tag,
-						      uint64_t owner,
-						      int nelements,
-						      int allocated_elements[]);
 
 #endif
 
diff --git a/arch/mips/include/asm/octeon/cvmx-gmxx-defs.h b/arch/mips/include/asm/octeon/cvmx-gmxx-defs.h
index 13b410d..db98f90 100644
--- a/arch/mips/include/asm/octeon/cvmx-gmxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gmxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-gpio-defs.h b/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
index 8ec298f..29639a0 100644
--- a/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1161,21 +1161,28 @@ union cvmx_gpio_usbh_ctl {
 	uint64_t u64;
 	struct cvmx_gpio_usbh_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_0_63                : 64;
+#else
+	uint64_t reserved_0_63                : 64;
+#endif
+	} s;
+	struct cvmx_gpio_usbh_ctl_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t sel1                         : 5;  /**< Selects the GPIO(0..19) received data (GPIO_RX_DAT[DAT]) for USB1
-                                                         over-current control. With SEL1 values 20-31,
-                                                         signal is always zero. */
+	uint64_t sel                          : 5;  /**< Selects the GPIO(0..19) received data (GPIO_RX_DAT[DAT]) for USB0
+                                                         over-current control. With SEL0 values 20-31, signal is always zero.
+                                                         CSR read out for bit 12..8 will have SEL1(4..0) value. */
 	uint64_t reserved_5_7                 : 3;
-	uint64_t sel                          : 5;  /**< Selects the GPIO(0..19) input pin for USBH over-current control. With SEL values 20-31,
-                                                         signal is always zero. */
+	uint64_t sel1                         : 5;  /**< Selects the GPIO(0..19) received data (GPIO_RX_DAT[DAT]) USB1
+                                                         over-current control. With SEL1 values 20-31, signal is always zero.
+                                                         CSR read out for bit 4..0 will have SEL(12..8) value. */
 #else
-	uint64_t sel                          : 5;
-	uint64_t reserved_5_7                 : 3;
 	uint64_t sel1                         : 5;
+	uint64_t reserved_5_7                 : 3;
+	uint64_t sel                          : 5;
 	uint64_t reserved_13_63               : 51;
 #endif
-	} s;
-	struct cvmx_gpio_usbh_ctl_s           cn70xx;
+	} cn70xx;
 	struct cvmx_gpio_usbh_ctl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
diff --git a/arch/mips/include/asm/octeon/cvmx-gser.h b/arch/mips/include/asm/octeon/cvmx-gser.h
new file mode 100644
index 0000000..7fa0682
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-gser.h
@@ -0,0 +1,63 @@
+/***********************license start***************
+ * Copyright (c) 2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Helper utilities for gser.
+ *
+ * <hr>$Revision$<hr>
+ */
+
+#ifndef __CVMX_GSER_H__
+#define __CVMX_GSER_H__
+
+/**
+ * @INTERNAL
+ * Configure the gser.
+ *
+ * @param interface Interface to bring up
+ *
+ * @param mode      Mode to configure the gser as
+ *
+ * @return Zero on success, negative on failure
+ */
+int gser_init(int interface, cvmx_helper_interface_mode_t mode);
+
+#endif /* __CVMX_GSER_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
index 5186903..c2e533b 100644
--- a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -537,6 +537,17 @@ static inline uint64_t CVMX_GSERX_DLMX_TX_TERM_OFFSET(unsigned long offset, unsi
 #define CVMX_GSERX_DLMX_TX_TERM_OFFSET(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090003040ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_IDDQ_MODE(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 13)))))
+		cvmx_warn("CVMX_GSERX_IDDQ_MODE(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090000018ull) + ((block_id) & 15) * 0x1000000ull;
+}
+#else
+#define CVMX_GSERX_IDDQ_MODE(block_id) (CVMX_ADD_IO_SEG(0x0001180090000018ull) + ((block_id) & 15) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_LANEX_PX_MODE_0(unsigned long a, unsigned long b, unsigned long c)
 {
 	if (!(
@@ -559,6 +570,72 @@ static inline uint64_t CVMX_GSERX_LANEX_PX_MODE_1(unsigned long a, unsigned long
 #define CVMX_GSERX_LANEX_PX_MODE_1(a, b, c) (CVMX_ADD_IO_SEG(0x00011800904E0048ull) + ((a) << 24) + ((b) << 20) + ((c) << 5))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_RX_CTLE_CTRL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_RX_CTLE_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090440058ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_RX_CTLE_CTRL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090440058ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_RX_PRECORR_CTRL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_RX_PRECORR_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090440060ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_RX_PRECORR_CTRL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090440060ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_RX_VALBBD_CTRL_0(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_RX_VALBBD_CTRL_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090440240ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_RX_VALBBD_CTRL_0(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090440240ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_RX_VALBBD_CTRL_1(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_RX_VALBBD_CTRL_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090440248ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_RX_VALBBD_CTRL_1(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090440248ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_RX_VALBBD_CTRL_2(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_RX_VALBBD_CTRL_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090440250ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_RX_VALBBD_CTRL_2(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090440250ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_RX_VMA_CTRL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_RX_VMA_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090440200ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_RX_VMA_CTRL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090440200ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_LANEX_VMA_COARSE_CTRL_0(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -592,6 +669,39 @@ static inline uint64_t CVMX_GSERX_LANEX_VMA_COARSE_CTRL_2(unsigned long offset,
 #define CVMX_GSERX_LANEX_VMA_COARSE_CTRL_2(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904E01C0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_VMA_FINE_CTRL_0(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_VMA_FINE_CTRL_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904E01C8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_VMA_FINE_CTRL_0(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904E01C8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_VMA_FINE_CTRL_1(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_VMA_FINE_CTRL_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904E01D0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_VMA_FINE_CTRL_1(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904E01D0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_VMA_FINE_CTRL_2(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_VMA_FINE_CTRL_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904E01D8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_VMA_FINE_CTRL_2(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904E01D8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_LANE_LPBKEN(unsigned long block_id)
 {
 	if (!(
@@ -801,15 +911,114 @@ static inline uint64_t CVMX_GSERX_PCIE_TX_VBOOST_LVL(unsigned long block_id)
 #define CVMX_GSERX_PCIE_TX_VBOOST_LVL(block_id) (CVMX_ADD_IO_SEG(0x0001180090080440ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_PHYX_SCOPE_MASKX(unsigned long a, unsigned long b, unsigned long c)
+static inline uint64_t CVMX_GSERX_PHYX_IDCODE_HI(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_IDCODE_HI(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090400008ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_IDCODE_HI(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090400008ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_IDCODE_LO(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_IDCODE_LO(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090400000ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_IDCODE_LO(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090400000ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE0_RX_LBERT_CTL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE0_RX_LBERT_CTL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904080B0ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE0_RX_LBERT_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904080B0ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE0_RX_LBERT_ERR(unsigned long offset, unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((a == 0)) && ((b <= 2)) && ((c <= 7))))))
-		cvmx_warn("CVMX_GSERX_PHYX_SCOPE_MASKX(%lu,%lu,%lu) is invalid on this chip\n", a, b, c);
-	return CVMX_ADD_IO_SEG(0x0001180090000120ull) + ((a) << 0) + ((b) << 19) + ((c) << 3);
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE0_RX_LBERT_ERR(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904080B8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
 }
 #else
-#define CVMX_GSERX_PHYX_SCOPE_MASKX(a, b, c) (CVMX_ADD_IO_SEG(0x0001180090000120ull) + ((a) << 0) + ((b) << 19) + ((c) << 3))
+#define CVMX_GSERX_PHYX_LANE0_RX_LBERT_ERR(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904080B8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE0_TXDEBUG(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE0_TXDEBUG(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408080ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE0_TXDEBUG(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408080ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE0_TX_LBERT_CTL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE0_TX_LBERT_CTL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904080A8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE0_TX_LBERT_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904080A8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE1_RX_LBERT_CTL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE1_RX_LBERT_CTL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904088B0ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE1_RX_LBERT_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904088B0ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE1_RX_LBERT_ERR(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE1_RX_LBERT_ERR(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904088B8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE1_RX_LBERT_ERR(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904088B8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE1_TXDEBUG(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE1_TXDEBUG(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408880ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE1_TXDEBUG(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408880ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE1_TX_LBERT_CTL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE1_TX_LBERT_CTL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904088A8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE1_TX_LBERT_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904088A8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_PHY_CTL(unsigned long block_id)
@@ -933,15 +1142,26 @@ static inline uint64_t CVMX_GSERX_RX_EIE_DETSTS(unsigned long block_id)
 #define CVMX_GSERX_RX_EIE_DETSTS(block_id) (CVMX_ADD_IO_SEG(0x0001180090000150ull) + ((block_id) & 15) * 0x1000000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_RX_EIE_FILTER(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 13)))))
+		cvmx_warn("CVMX_GSERX_RX_EIE_FILTER(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090000158ull) + ((block_id) & 15) * 0x1000000ull;
+}
+#else
+#define CVMX_GSERX_RX_EIE_FILTER(block_id) (CVMX_ADD_IO_SEG(0x0001180090000158ull) + ((block_id) & 15) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_RX_POLARITY(unsigned long block_id)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 13)))))
 		cvmx_warn("CVMX_GSERX_RX_POLARITY(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x0001180090000158ull) + ((block_id) & 15) * 0x1000000ull;
+	return CVMX_ADD_IO_SEG(0x0001180090000160ull) + ((block_id) & 15) * 0x1000000ull;
 }
 #else
-#define CVMX_GSERX_RX_POLARITY(block_id) (CVMX_ADD_IO_SEG(0x0001180090000158ull) + ((block_id) & 15) * 0x1000000ull)
+#define CVMX_GSERX_RX_POLARITY(block_id) (CVMX_ADD_IO_SEG(0x0001180090000160ull) + ((block_id) & 15) * 0x1000000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_RX_PSTATE(unsigned long block_id)
@@ -1098,17 +1318,6 @@ static inline uint64_t CVMX_GSERX_SATA_TX_INVERT(unsigned long block_id)
 #define CVMX_GSERX_SATA_TX_INVERT(block_id) (CVMX_ADD_IO_SEG(0x0001180090100220ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_SLICEX_PX_MODE(unsigned long a, unsigned long b, unsigned long c)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((a <= 13)) && ((b <= 1)) && ((c <= 11))))))
-		cvmx_warn("CVMX_GSERX_SLICEX_PX_MODE(%lu,%lu,%lu) is invalid on this chip\n", a, b, c);
-	return CVMX_ADD_IO_SEG(0x0001180090560228ull) + ((a) << 24) + ((b) << 20) + ((c) << 3);
-}
-#else
-#define CVMX_GSERX_SLICEX_PX_MODE(a, b, c) (CVMX_ADD_IO_SEG(0x0001180090560228ull) + ((a) << 24) + ((b) << 20) + ((c) << 3))
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_SPD(unsigned long block_id)
 {
 	if (!(
@@ -1161,18 +1370,14 @@ union cvmx_gserx_ana_atest {
 	struct cvmx_gserx_ana_atest_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t ana_dac_b                    : 7;  /**< Used to control the B-side DAC input to the analog test block.
-                                                         Note that the QLM0 register is tied to the analog
-                                                         test block, for non-OCI links.
-                                                         Note that the OCI0 register is tied to the analog
-                                                         test block, for OCI links.
-                                                         The other QLM GSER_ANA_DAC_B registers are unused. */
-	uint64_t ana_dac_a                    : 5;  /**< Used to control A-side DAC input to the analog test block.
-                                                         Note that the QLM0 register is tied to the analog
-                                                         test block, for non-OCI links.
-                                                         Note that the OCI0 register is tied to the analog
-                                                         test block, for OCI links.
-                                                         The other QLM GSER_ANA_DAC_A registers are unused. */
+	uint64_t ana_dac_b                    : 7;  /**< Used to control the B-side DAC input to the analog test block. Note that the QLM4 register
+                                                         is tied to the analog test block, for non-OCI links. Note that the OCI4 register is tied
+                                                         to the analog test block, for OCI links. The other QLM GSER_ANA_DAC_B registers are
+                                                         unused. For diagnostic use only. */
+	uint64_t ana_dac_a                    : 5;  /**< Used to control A-side DAC input to the analog test block. Note that the QLM4 register is
+                                                         tied to the analog test block, for non-OCI links. Note that the OCI4 register is tied to
+                                                         the analog test block, for OCI links. The other QLM GSER_ANA_DAC_A registers are unused.
+                                                         For diagnostic use only. */
 #else
 	uint64_t ana_dac_a                    : 5;
 	uint64_t ana_dac_b                    : 7;
@@ -1191,12 +1396,10 @@ union cvmx_gserx_ana_sel {
 	struct cvmx_gserx_ana_sel_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t ana_sel                      : 9;  /**< Used to control the adr_global input to the analog test block.
-                                                         Note that the QLM0 register is tied to the analog
-                                                         test block, for non-OCI links.
-                                                         Note that the QLM8 register is tied to the analog
-                                                         test block, for OCI links.
-                                                         The other QLM GSER_ANA_SEL registers are unused. */
+	uint64_t ana_sel                      : 9;  /**< Used to control the adr_global input to the analog test block. Note that the QLM0 register
+                                                         is tied to the analog test block, for non-OCI links. Note that the QLM8 register is tied
+                                                         to the analog test block, for OCI links. The other QLM GSER_ANA_SEL registers are unused.
+                                                         For diagnostic use only. */
 #else
 	uint64_t ana_sel                      : 9;
 	uint64_t reserved_9_63                : 55;
@@ -1214,20 +1417,22 @@ union cvmx_gserx_br_rxx_ctl {
 	struct cvmx_gserx_br_rxx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t rxt_swm                      : 1;  /**< Set when RX Base-R Link Training is to be performed under software control. */
-	uint64_t rxt_preset                   : 1;  /**< When in SW Base-R Training Mode, this bit is used to determine how to
-                                                         set the preset bit. When preset is set, RX training is disabled.
-                                                         To perform a preset, set this bit prior to setting training enable.
-                                                         Note that it is illegal to set both the preset and initialize bits at the same time.
-                                                         - 1: preset is set.  A single CU message is sent to the link partner
-                                                         - 0: preset is clear */
-	uint64_t rxt_initialize               : 1;  /**< When in SW Base-R Training Mode, this bit is used to determine how to
-                                                         set the initialize bit the the Coefficient Update Message at the start
-                                                         of RX training.
-                                                         To perform a initialize, set this bit prior to setting training enable.
-                                                         Note that it is illegal to set both the preset and initialize bits at the same time.
-                                                         - 1: training starts with initialize set
-                                                         - 0: training starts with initialize clear */
+	uint64_t rxt_swm                      : 1;  /**< Set when RX Base-R Link Training is to be performed under software control. For diagnostic
+                                                         use only. */
+	uint64_t rxt_preset                   : 1;  /**< For all link training, this bit determines how to configure the preset bit in the
+                                                         coefficient update message that is sent to the far end transmitter. When set, a one time
+                                                         request is made that the coefficients be set to a state where equalization is turned off.
+                                                         To perform a preset, set this bit prior to link training. link training needs to be
+                                                         disabled to complete the request and get the rxtrain state machine back to IDLE. Note that
+                                                         it is illegal to set both the preset and initialize bits at the same time. For diagnostic
+                                                         use only. */
+	uint64_t rxt_initialize               : 1;  /**< For all link training, this bit determines how to configure the initialize bit in the
+                                                         coefficient update message that is sent to the far end transmitter of RX training. When
+                                                         set, a request is made that the coefficients be set to its INITIALIZE state. To perform a
+                                                         initialize prior to link training, set this bit prior to performing link training. Note
+                                                         that it is illegal to set both the preset and initialize bits at the same time. Since the
+                                                         far end transmitter is required to be initialized prior to starting link training, it is
+                                                         not expected that software will need to set this bit. For diagnostic use only. */
 #else
 	uint64_t rxt_initialize               : 1;
 	uint64_t rxt_preset                   : 1;
@@ -1248,7 +1453,8 @@ union cvmx_gserx_br_rxx_cu {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
 	uint64_t rxt_cu                       : 9;  /**< When RX Base-R Link Training is being performed under software control,
-                                                         This is the Coefficient Update Message to send to the MAC (BGX/OCI). */
+                                                         (GSER(0..13)_BR_RX(0..3)_CTL[RXT_SWM] is set), this is the coefficient update message to
+                                                         send to the MAC (BGX/OCI). For diagnostic use only. */
 #else
 	uint64_t rxt_cu                       : 9;
 	uint64_t reserved_9_63                : 55;
@@ -1261,29 +1467,41 @@ typedef union cvmx_gserx_br_rxx_cu cvmx_gserx_br_rxx_cu_t;
 /**
  * cvmx_gser#_br_rx#_eer
  *
- * GSER SW Base-R RX Link Training Equalization Evaluation Request (EER)
- * A write to this register will perform a Equalization Request to the RAW PCS.
- * A read of this register will return the Equalization Status Message and a valid
- * bit indicating it was updated.
+ * GSER software Base-R RX Link Training equalization evaluation request (EER). A write to
+ * RXT_EER initiates a equalization request to the RAW PCS. A read of this register returns the
+ * equalization status message and a valid bit indicating it was updated. These registers are for
+ * diagnostic use only.
  */
 union cvmx_gserx_br_rxx_eer {
 	uint64_t u64;
 	struct cvmx_gserx_br_rxx_eer_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_15_63               : 49;
-	uint64_t rxt_esv                      : 1;  /**< When RX Base-R Link Training is being performed under software control,
-                                                         This is the bit indicating that the Equalization Status is valid.  Reading
-                                                         this register will clear this bit. */
-	uint64_t rxt_esm                      : 14; /**< When RX Base-R Link Training is being performed under software control,
-                                                         This is the Equalization Status Message from the RAW PCS.
-                                                         bits[13:6]: figure of merit
-                                                         bits[5:4]:  RX recommended TXPOST direction change
-                                                         bits[3:2]:  RX recommended TXMAIN direction change
-                                                         bits[5:4]:  RX recommended TXPRE direction change */
+	uint64_t reserved_16_63               : 48;
+	uint64_t rxt_eer                      : 1;  /**< When RX Base-R Link Training is being performed under software control,
+                                                         (GSER(0..13)_BR_RX(0..3)_CTL[RXT_SWM] is set), writing this bit initiates an equalization
+                                                         request to the RAW PCS. Reading this bit always returns a zero. */
+	uint64_t rxt_esv                      : 1;  /**< When performing an equalization request (RXT_EER), this bit, when set, indicates that the
+                                                         Equalization Status (RXT_ESM) is valid. When issuing a RXT_EER request, it is expected
+                                                         that RXT_ESV will get written to zero so that a valid RXT_ESM can be determined. */
+	uint64_t rxt_esm                      : 14; /**< When performing a equalization request (RXT_EER), this is the equalization status message
+                                                         from the RAW PCS. It is valid with RXT_ESV is set.
+                                                         <13:6>: Figure of merit. An 8-bit output from the PHY indicating the quality of the
+                                                         received data eye. A higher value indicates better link equalization, with 8'd0 indicating
+                                                         worst equalization setting and 8'd255 indicating the best equalization setting.
+                                                         <5:4>: RX recommended TXPOST direction change.
+                                                         <3:2>: RX recommended TXMAIN direction change.
+                                                         <1:0>: RX recommended TXPRE direction change.
+                                                         Recommended direction change outputs from the PHY for the link partner transmitter
+                                                         coefficients.
+                                                         0x0 = Hold.
+                                                         0x1 = Increment.
+                                                         0x2 = Decrement.
+                                                         0x3 = Hold. */
 #else
 	uint64_t rxt_esm                      : 14;
 	uint64_t rxt_esv                      : 1;
-	uint64_t reserved_15_63               : 49;
+	uint64_t rxt_eer                      : 1;
+	uint64_t reserved_16_63               : 48;
 #endif
 	} s;
 	struct cvmx_gserx_br_rxx_eer_s        cn78xx;
@@ -1299,7 +1517,8 @@ union cvmx_gserx_br_rxx_sr {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
 	uint64_t rxt_sr                       : 6;  /**< When RX Base-R Link Training is being performed under software control,
-                                                         This is the Status Response Message from the Link Partner. */
+                                                         (GSER(0..13)_BR_RX(0..3)_CTL[RXT_SWM] is set), this is the status report message from the
+                                                         link partner. For diagnostic use only. */
 #else
 	uint64_t rxt_sr                       : 6;
 	uint64_t reserved_6_63                : 58;
@@ -1317,7 +1536,8 @@ union cvmx_gserx_br_txx_ctl {
 	struct cvmx_gserx_br_txx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t txt_swm                      : 1;  /**< Set when TX Base-R Link Training is to be performed under software control. */
+	uint64_t txt_swm                      : 1;  /**< Set when TX Base-R Link Training is to be performed under software control. For diagnostic
+                                                         use only. */
 #else
 	uint64_t txt_swm                      : 1;
 	uint64_t reserved_1_63                : 63;
@@ -1335,8 +1555,9 @@ union cvmx_gserx_br_txx_cu {
 	struct cvmx_gserx_br_txx_cu_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t txt_cu                       : 9;  /**< When in SW TX Base-R Link Training, this is the Coefficient Update
-                                                         message from the link partner. */
+	uint64_t txt_cu                       : 9;  /**< When TX Base-R Link Training is being performed under software control,
+                                                         (GSER(0..13)_BR_TX(0..3)_CTL[TXT_SWM] is set), this is the coefficient update message from
+                                                         the link partner. For diagnostic use only. */
 #else
 	uint64_t txt_cu                       : 9;
 	uint64_t reserved_9_63                : 55;
@@ -1348,20 +1569,19 @@ typedef union cvmx_gserx_br_txx_cu cvmx_gserx_br_txx_cu_t;
 
 /**
  * cvmx_gser#_br_tx#_cur
- *
- * GSER SW Base-R TX Coeffiecient Update Request
- *
  */
 union cvmx_gserx_br_txx_cur {
 	uint64_t u64;
 	struct cvmx_gserx_br_txx_cur_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t txt_cur                      : 14; /**< When in SW TX Base-R Link Training, this is the Coefficient Update
-                                                         to be written to the RAW PCS.
-                                                         bits 13:9: TX_POST[4:0]
-                                                         bits 8:4:  TX_SWING[4:0]
-                                                         bits 3:0:  TX_PRE[4:0] */
+	uint64_t txt_cur                      : 14; /**< When TX Base-R Link Training is being performed under software control,
+                                                         (GSER_BR_TX(0..3)_CTL.TXT_SWM is set), this is the Coefficient Update to be written to the
+                                                         PHY.
+                                                         Bits 13:9: TX_POST<4:0>
+                                                         Bits 8:4: TX_SWING<4:0>
+                                                         Bits 3:0: TX_PRE<4:0>
+                                                         For diagnostic use only. */
 #else
 	uint64_t txt_cur                      : 14;
 	uint64_t reserved_14_63               : 50;
@@ -1379,10 +1599,10 @@ union cvmx_gserx_br_txx_sr {
 	struct cvmx_gserx_br_txx_sr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
-	uint64_t txt_sr                       : 6;  /**< When in SW TX Base-R Link Training, this is the Status Response
-                                                         to be sent to the link partner.  Writing this message will cause
-                                                         a new SR message to be sent to the Mac (BGX/OCI) to be forwarded
-                                                         to the link partner. */
+	uint64_t txt_sr                       : 6;  /**< When TX Base-R Link Training is being performed under software control,
+                                                         (GSER(0..13)_BR_TX(0..3)_CTL[TXT_SWM] is set), this is the status report (SR) message to
+                                                         be sent to the link partner. Writing this register causes a new SR message to be sent to
+                                                         the MAC (BGX/OCI) to be forwarded to the link partner. For diagnostic use only. */
 #else
 	uint64_t txt_sr                       : 6;
 	uint64_t reserved_6_63                : 58;
@@ -1400,25 +1620,18 @@ union cvmx_gserx_cfg {
 	struct cvmx_gserx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t bgx_quad                     : 1;  /**< For non-OCI links, this indicates the BGX is
-                                                         in quad aggregation mode when BGX is also set.
-                                                         A single controller is used for all 4 lanes.
-                                                         For OCI links this bit has no meaning. */
-	uint64_t bgx_dual                     : 1;  /**< For non-OCI links, this indicates the BGX is
-                                                         in dual aggregation mode when BGX is also set.
-                                                         A single controller is used for lanes 0 & 1 and
-                                                         another controller is used for lanes 2 & 3.
-                                                         For OCI links this bit has no meaning. */
-	uint64_t bgx                          : 1;  /**< For non-OCI links, this indicates the GSER is configured
-                                                         for BGX mode.
-                                                         For OCI links this bit has no meaning. */
-	uint64_t ila                          : 1;  /**< For non-OCI links, this indicates the GSER is configured
-                                                         for ILK/ILA mode.
-                                                         For OCI links, this indicates the GSER is configured
-                                                         for OCI mode. */
-	uint64_t pcie                         : 1;  /**< For non-OCI links, this indicates the GSER is configured
-                                                         for PCIE mode.
-                                                         For OCI links this bit has no meaning. */
+	uint64_t bgx_quad                     : 1;  /**< For non-OCI links, indicates the BGX is in quad aggregation mode when GSER(0..13)_CFG[BGX]
+                                                         is also set. A single controller is used for all four lanes. For OCI links, this bit has
+                                                         no meaning. */
+	uint64_t bgx_dual                     : 1;  /**< For non-OCI links, indicates the BGX is in dual aggregation mode when GSER(0..13)_CFG[BGX]
+                                                         is also set. A single controller is used for lanes 0 and 1 and another controller is used
+                                                         for lanes 2 and 3. For OCI links, this bit has no meaning. */
+	uint64_t bgx                          : 1;  /**< For non-OCI links, indicates the GSER is configured for BGX mode. Only one of the BGX,
+                                                         ILA, or PCIE modes can be set at any one time. For OCI links, this bit has no meaning. */
+	uint64_t ila                          : 1;  /**< For non-OCI links, indicates the GSER is configured for ILK/ILA mode. Only one of the BGX,
+                                                         ILA, or PCIE modes can be set at any one time. For OCI links, this bit has no meaning. */
+	uint64_t pcie                         : 1;  /**< For non-OCI links, indicates the GSER is configured for PCIE mode. Only one of the BGX,
+                                                         ILA, or PCIE modes can be set at any one time. For OCI links, this bit has no meaning. */
 #else
 	uint64_t pcie                         : 1;
 	uint64_t ila                          : 1;
@@ -1440,7 +1653,8 @@ union cvmx_gserx_dbg {
 	struct cvmx_gserx_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t rxqtm_on                     : 1;  /**< When asserted, the RX FIFOs are turned on. */
+	uint64_t rxqtm_on                     : 1;  /**< For non BGX/ILK configurations, setting this bit enables the RX FIFOs. This allows
+                                                         received data to become visible to the RSL debug port. For diagnostic use only. */
 #else
 	uint64_t rxqtm_on                     : 1;
 	uint64_t reserved_1_63                : 63;
@@ -1710,7 +1924,7 @@ union cvmx_gserx_dlmx_ref_ssp_en {
 	struct cvmx_gserx_dlmx_ref_ssp_en_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t ref_ssp_en                   : 1;  /**< This signal should always be set. */
+	uint64_t ref_ssp_en                   : 1;  /**< Enables the PHY's internal reference clock. */
 #else
 	uint64_t ref_ssp_en                   : 1;
 	uint64_t reserved_1_63                : 63;
@@ -2275,52 +2489,128 @@ union cvmx_gserx_dlmx_tx_term_offset {
 typedef union cvmx_gserx_dlmx_tx_term_offset cvmx_gserx_dlmx_tx_term_offset_t;
 
 /**
+ * cvmx_gser#_iddq_mode
+ */
+union cvmx_gserx_iddq_mode {
+	uint64_t u64;
+	struct cvmx_gserx_iddq_mode_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t phy_iddq_mode                : 1;  /**< When set, power downs all circuitry in PHY for IDDQ testing */
+#else
+	uint64_t phy_iddq_mode                : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_gserx_iddq_mode_s         cn78xx;
+};
+typedef union cvmx_gserx_iddq_mode cvmx_gserx_iddq_mode_t;
+
+/**
  * cvmx_gser#_lane#_p#_mode_0
  *
- * RAW PCS Per Lane Global Settings Mode 0 Register
- * Per Lane registers are specific to a paticular lane.
- * The Protocol selects the specific protocol register as follows.
- * P0:  PCIE1
- * P1:  PCIE2
- * P2:  PCIE3
- * P3:  KX
- * P4:  XAUI
- * P5:  KR
- * P6:  SGMII
- * P7:  QSGMII
- * P8:  RXAUI
- * P9:  PCIE1_125
- * P10: PCIE2_125
- * P11: PCIE3_125
+ * These are the RAW PCS per-lane global settings mode 0 registers. The Protocol selects the
+ * specific protocol register as enumerated by GSER_LMODE_E.
  */
 union cvmx_gserx_lanex_px_mode_0 {
 	uint64_t u64;
 	struct cvmx_gserx_lanex_px_mode_0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t ctle                         : 2;  /**< CTLE pole value. */
+	uint64_t ctle                         : 2;  /**< Continuous time linear equalizer pole configuration.
+                                                         0x0 = ~5dB of peaking at 4 GHz (Minimum bandwidth).
+                                                         0x1 =~10dB of peaking at 5 GHz
+                                                         0x2 = ~15dB of peaking at 5.5 GHz
+                                                         0x3 = ~20dB of peaking at 6 GHz (Maximum bandwidth).
+                                                         Recommended settings:
+                                                         R_25G_REFCLK100: 0x0
+                                                         R_5G_REFCLK100: 0x0
+                                                         R_8G_REFCLK100: 0x3
+                                                         R_125G_REFCLK15625_KX: 0x0
+                                                         R_3125G_REFCLK15625_XAUI: 0x0
+                                                         R_103215G_REFCLK15625_KR: 0x3
+                                                         R_125G_REFCLK15625_SGMII: 0x0
+                                                         R_5G_REFCLK15625_QSGMII: 0x0
+                                                         R_625G_REFCLK15625_RXAUI: 0x0
+                                                         R_25G_REFCLK125: 0x0
+                                                         R_5G_REFCLK125: 0x0
+                                                         R_8G_REFCLK125: 0x3 */
 	uint64_t pcie                         : 1;  /**< Selects between RX terminations.
-                                                         - 0: pcs_sds_rx_terminate_to_vdda
-                                                         - 1: VSS */
-	uint64_t tx_ldiv                      : 2;  /**< Configues clock divider used to determine the transmit rate. */
-	uint64_t rx_ldiv                      : 2;  /**< Configues clock divider used to determine the receive rate. */
-	uint64_t srate                        : 3;  /**< Used to generate strobe to effectively divide the clock down
-                                                         to a slower rate. */
-	uint64_t op_range                     : 1;  /**< When set DFE is enabled.  Otherwise DFE is disabled. */
-	uint64_t tx_mode                      : 2;  /**< TX Data Width.
-                                                         - 00: 8-bit  raw data (not supported)
-                                                         - 01: 10-bit raw data (not supported)
-                                                         - 10: 16-bit raw data (not supported)
-                                                         - 11: 20-bit raw data */
-	uint64_t rx_mode                      : 2;  /**< RX Data Width.
-                                                         - 00: 8-bit  raw data (not supported)
-                                                         - 01: 10-bit raw data (not supported)
-                                                         - 10: 16-bit raw data (not supported)
-                                                         - 11: 20-bit raw data */
+                                                         - 0: Differential termination
+                                                         - 1: Termination between pad and SDS_VDDS.
+                                                          Recommended settings:
+                                                          R_25G_REFCLK100: 0x1
+                                                          R_5G_REFCLK100: 0x1
+                                                          R_8G_REFCLK100: 0x0
+                                                          R_125G_REFCLK15625_KX: 0x0
+                                                          R_3125G_REFCLK15625_XAUI: 0x0
+                                                          R_103215G_REFCLK15625_KR: 0x0
+                                                          R_125G_REFCLK15625_SGMII: 0x0
+                                                          R_5G_REFCLK15625_QSGMII: 0x0
+                                                          R_625G_REFCLK15625_RXAUI: 0x0
+                                                          R_25G_REFCLK125: 0x1
+                                                          R_5G_REFCLK125: 0x1
+                                                          R_8G_REFCLK125: 0x0 */
+	uint64_t tx_ldiv                      : 2;  /**< Configures clock divider used to determine the receive rate. Encoding is:
+                                                         0x0 = full data rate.
+                                                         0x1 = 1/2 data rate.
+                                                         0x2 = 1/4 data rate.
+                                                         0x3 = 1/8 data rate.
+                                                         Recommended settings:
+                                                         R_25G_REFCLK100: 0x1
+                                                         R_5G_REFCLK100: 0x0
+                                                         R_8G_REFCLK100: 0x0
+                                                         R_125G_REFCLK15625_KX: 0x2
+                                                         R_3125G_REFCLK15625_XAUI: 0x1
+                                                         R_103215G_REFCLK15625_KR: 0x0
+                                                         R_125G_REFCLK15625_SGMII: 0x2
+                                                         R_5G_REFCLK15625_QSGMII: 0x0
+                                                         R_625G_REFCLK15625_RXAUI: 0x0
+                                                         R_25G_REFCLK125: 0x1
+                                                         R_5G_REFCLK125: 0x0
+                                                         R_8G_REFCLK125: 0x0 */
+	uint64_t rx_ldiv                      : 2;  /**< Configures clock divider used to determine the receive rate. Encoding is:
+                                                         0x0 = full data rate
+                                                         0x1 = 1/2 data rate
+                                                         0x2 = 1/4 data rate
+                                                         0x3 = 1/8 data rate
+                                                         Recommended settings:
+                                                         R_25G_REFCLK100: 0x1
+                                                         R_5G_REFCLK100: 0x0
+                                                         R_8G_REFCLK100: 0x0
+                                                         R_125G_REFCLK15625_KX: 0x2
+                                                         R_3125G_REFCLK15625_XAUI: 0x1
+                                                         R_103215G_REFCLK15625_KR: 0x0
+                                                         R_125G_REFCLK15625_SGMII: 0x2
+                                                         R_5G_REFCLK15625_QSGMII: 0x0
+                                                         R_625G_REFCLK15625_RXAUI: 0x0
+                                                         R_25G_REFCLK125: 0x1
+                                                         R_5G_REFCLK125: 0x0
+                                                         R_8G_REFCLK125: 0x0 */
+	uint64_t srate                        : 3;  /**< Sample rate, used to generate strobe to effectively divide the clock down to a slower
+                                                         rate. Encoding is:
+                                                         0x0 = Full rate
+                                                         0x1 = 1/2 data rate
+                                                         0x2 = 1/4 data rate
+                                                         0x3 = 1/8 data rate
+                                                         0x4 = 1/16 data rate
+                                                         else = Reserved.
+                                                         This field should always be set to zero (full rate). */
+	uint64_t reserved_4_4                 : 1;
+	uint64_t tx_mode                      : 2;  /**< TX data width:
+                                                         0x0 = 8-bit raw data (not supported).
+                                                         0x1 = 10-bit raw data (not supported).
+                                                         0x2 = 16-bit raw data (not supported).
+                                                         0x3 = 20-bit raw data. */
+	uint64_t rx_mode                      : 2;  /**< RX data width:
+                                                         0x0 = 8-bit raw data (not supported).
+                                                         0x1 = 10-bit raw data (not supported).
+                                                         0x2 = 16-bit raw data (not supported).
+                                                         0x3 = 20-bit raw data. */
 #else
 	uint64_t rx_mode                      : 2;
 	uint64_t tx_mode                      : 2;
-	uint64_t op_range                     : 1;
+	uint64_t reserved_4_4                 : 1;
 	uint64_t srate                        : 3;
 	uint64_t rx_ldiv                      : 2;
 	uint64_t tx_ldiv                      : 2;
@@ -2336,38 +2626,51 @@ typedef union cvmx_gserx_lanex_px_mode_0 cvmx_gserx_lanex_px_mode_0_t;
 /**
  * cvmx_gser#_lane#_p#_mode_1
  *
- * RAW PCS Per Lane Global Settings Mode 1 Register
- * Per Lane registers are specific to a paticular lane.
- * The Protocol selects the specific protocol register as follows.
- * P0:  PCIE1
- * P1:  PCIE2
- * P2:  PCIE3
- * P3:  KX
- * P4:  XAUI
- * P5:  KR
- * P6:  SGMII
- * P7:  QSGMII
- * P8:  RXAUI
- * P9:  PCIE1_125
- * P10: PCIE2_125
- * P11: PCIE3_125
+ * The Protocol selects the specific protocol register as enumerated by GSER_LMODE_E.
+ *
  */
 union cvmx_gserx_lanex_px_mode_1 {
 	uint64_t u64;
 	struct cvmx_gserx_lanex_px_mode_1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t vma_kr_sel                   : 1;  /**< 0: Disabled.  Coarse step adaptation selected
-                                                         - 1: Enabled.  Fine step adaptation selected */
-	uint64_t vma_mm                       : 1;  /**< 0: Adaptive DFE
-                                                         - 1: Manual DFE */
-	uint64_t cdr_fgain                    : 4;  /**< CDR Frequency Gain. */
-	uint64_t ph_acc_adj                   : 10; /**< Phase accumulator adjust. */
+	uint64_t vma_fine_cfg_sel             : 1;  /**< Values at reset:
+                                                         1 = Enabled. Fine step adaptation selected (10.3125 Gbps rate).
+                                                         0 = Disabled. Coarse step adaptation selected (rates lower than 10.3125 Gbps). */
+	uint64_t vma_mm                       : 1;  /**< Manual DFE verses adaptive DFE mode. Recommended settings:
+                                                         0 = Adaptive DFE (5 Gbps and higher)
+                                                         1 = Manual DFE, fixed tap (3.125 Gbps and lower). */
+	uint64_t cdr_fgain                    : 4;  /**< CDR frequency gain. Values at reset:
+                                                         R_25G_REFCLK100: 0xA
+                                                         R_5G_REFCLK100: 0xA
+                                                         R_8G_REFCLK100: 0xB
+                                                         R_125G_REFCLK15625_KX: 0xC
+                                                         R_3125G_REFCLK15625_XAUI: 0xC
+                                                         R_103215G_REFCLK15625_KR: 0xA
+                                                         R_125G_REFCLK15625_SGMII: 0xC
+                                                         R_5G_REFCLK15625_QSGMII: 0xC
+                                                         R_625G_REFCLK15625_RXAUI: 0xA
+                                                         R_25G_REFCLK125: 0xA
+                                                         R_5G_REFCLK125: 0xA
+                                                         R_8G_REFCLK125: 0xB */
+	uint64_t ph_acc_adj                   : 10; /**< Phase accumulator adjust. Values at reset:
+                                                         R_25G_REFCLK100: 0x14
+                                                         R_5G_REFCLK100: 0x14
+                                                         R_8G_REFCLK100: 0x23
+                                                         R_125G_REFCLK15625_KX: 0x1E
+                                                         R_3125G_REFCLK15625_XAUI: 0x1E
+                                                         R_103215G_REFCLK15625_KR: 0xF
+                                                         R_125G_REFCLK15625_SGMII: 0x1E
+                                                         R_5G_REFCLK15625_QSGMII: 0x1E
+                                                         R_625G_REFCLK15625_RXAUI: 0x14
+                                                         R_25G_REFCLK125: 0x14
+                                                         R_5G_REFCLK125: 0x14
+                                                         R_8G_REFCLK125: 0x23 */
 #else
 	uint64_t ph_acc_adj                   : 10;
 	uint64_t cdr_fgain                    : 4;
 	uint64_t vma_mm                       : 1;
-	uint64_t vma_kr_sel                   : 1;
+	uint64_t vma_fine_cfg_sel             : 1;
 	uint64_t reserved_16_63               : 48;
 #endif
 	} s;
@@ -2376,23 +2679,264 @@ union cvmx_gserx_lanex_px_mode_1 {
 typedef union cvmx_gserx_lanex_px_mode_1 cvmx_gserx_lanex_px_mode_1_t;
 
 /**
+ * cvmx_gser#_lane#_rx_ctle_ctrl
+ *
+ * These are the RAW PCS per-lane RX CTLE control registers.
+ *
+ */
+union cvmx_gserx_lanex_rx_ctle_ctrl {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_rx_ctle_ctrl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t pcs_sds_rx_ctle_bias_ctrl    : 2;  /**< CTLE bias trim bits.
+                                                         - 00: -10%
+                                                         - 01:   0%
+                                                         - 10: +5%
+                                                         - 11: +10%. */
+	uint64_t pcs_sds_rx_ctle_zero         : 4;  /**< Equalizer peaking control. */
+	uint64_t rx_ctle_pole_ovrrd_en        : 1;  /**< Equalizer pole adjustment override enable. */
+	uint64_t rx_ctle_pole_ovrrd_val       : 4;  /**< Equalizer pole adjustment override value.
+                                                         RX pre-correlation sample counter control
+                                                         bit 3: Optimize CTLE during training.
+                                                         bit 2: Turn off DFE1 for edge samplers.
+                                                         bits 1:0:
+                                                         - 00: ~ 5dB of peaking at 4.0 GHz.
+                                                         - 01: ~10dB of peaking at 5.0 GHz.
+                                                         - 10: ~15dB of peaking at 5.5 GHz.
+                                                         - 11: ~20dB of peaking at 6.0 GHz. */
+	uint64_t pcs_sds_rx_ctle_pole_max     : 2;  /**< Maximum pole value (for VMA adaption, not applicable in manual mode). */
+	uint64_t pcs_sds_rx_ctle_pole_min     : 2;  /**< Minimum pole value (for VMA adaption, not applicable in manual mode). */
+	uint64_t pcs_sds_rx_ctle_pole_step    : 1;  /**< Step pole value (for VMA adaption, not applicable in manual mode). */
+#else
+	uint64_t pcs_sds_rx_ctle_pole_step    : 1;
+	uint64_t pcs_sds_rx_ctle_pole_min     : 2;
+	uint64_t pcs_sds_rx_ctle_pole_max     : 2;
+	uint64_t rx_ctle_pole_ovrrd_val       : 4;
+	uint64_t rx_ctle_pole_ovrrd_en        : 1;
+	uint64_t pcs_sds_rx_ctle_zero         : 4;
+	uint64_t pcs_sds_rx_ctle_bias_ctrl    : 2;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_rx_ctle_ctrl_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_rx_ctle_ctrl cvmx_gserx_lanex_rx_ctle_ctrl_t;
+
+/**
+ * cvmx_gser#_lane#_rx_precorr_ctrl
+ *
+ * These are the RAW PCS per-lane RX precorrelation control registers. These registers are for
+ * diagnostic use only.
+ */
+union cvmx_gserx_lanex_rx_precorr_ctrl {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_rx_precorr_ctrl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t rx_precorr_disable           : 1;  /**< Disable RX precorrelation calculation. */
+	uint64_t rx_precorr_en_ovrrd_en       : 1;  /**< Override enable for RX precorrelation calculation enable. */
+	uint64_t rx_precorr_en_ovrrd_val      : 1;  /**< Override value for RX precorrelation calculation enable. */
+	uint64_t pcs_sds_rx_precorr_scnt_ctrl : 2;  /**< RX pre-correlation sample counter control.
+                                                         - 00: load max sample counter with 12'1FF.
+                                                         - 01: load max sample counter with 12'3FF.
+                                                         - 10: load max sample counter with 12'7FF.
+                                                         - 11: load max sample counter with 12'FFF. */
+#else
+	uint64_t pcs_sds_rx_precorr_scnt_ctrl : 2;
+	uint64_t rx_precorr_en_ovrrd_val      : 1;
+	uint64_t rx_precorr_en_ovrrd_en       : 1;
+	uint64_t rx_precorr_disable           : 1;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_rx_precorr_ctrl_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_rx_precorr_ctrl cvmx_gserx_lanex_rx_precorr_ctrl_t;
+
+/**
+ * cvmx_gser#_lane#_rx_valbbd_ctrl_0
+ */
+union cvmx_gserx_lanex_rx_valbbd_ctrl_0 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_rx_valbbd_ctrl_0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_14_63               : 50;
+	uint64_t agc_gain                     : 2;  /**< AGC gain. */
+	uint64_t dfe_gain                     : 2;  /**< DFE gain. */
+	uint64_t dfe_c5_mval                  : 4;  /**< DFE Tap5 manual value when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+	uint64_t dfe_c5_msgn                  : 1;  /**< DFE Tap5 manual sign when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+	uint64_t dfe_c4_mval                  : 4;  /**< DFE Tap4 manual value when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+	uint64_t dfe_c4_msgn                  : 1;  /**< DFE Tap4 manual sign when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+#else
+	uint64_t dfe_c4_msgn                  : 1;
+	uint64_t dfe_c4_mval                  : 4;
+	uint64_t dfe_c5_msgn                  : 1;
+	uint64_t dfe_c5_mval                  : 4;
+	uint64_t dfe_gain                     : 2;
+	uint64_t agc_gain                     : 2;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_rx_valbbd_ctrl_0_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_0 cvmx_gserx_lanex_rx_valbbd_ctrl_0_t;
+
+/**
+ * cvmx_gser#_lane#_rx_valbbd_ctrl_1
+ */
+union cvmx_gserx_lanex_rx_valbbd_ctrl_1 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_rx_valbbd_ctrl_1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_15_63               : 49;
+	uint64_t dfe_c3_mval                  : 4;  /**< DFE Tap3 manual value when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+	uint64_t dfe_c3_msgn                  : 1;  /**< DFE Tap3 manual sign when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+	uint64_t dfe_c2_mval                  : 4;  /**< DFE Tap2 manual value when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+	uint64_t dfe_c2_msgn                  : 1;  /**< DFE Tap2 manual sign when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+	uint64_t dfe_c1_mval                  : 4;  /**< DFE Tap1 manual value when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. Recommended settings: For the following modes:
+                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that DFE_C1_MVAL
+                                                         be set to zero after setting GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM] and also after
+                                                         updating the GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2 register. In all other modes this
+                                                         register can be ignored. */
+	uint64_t dfe_c1_msgn                  : 1;  /**< DFE Tap1 manual sign when GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         [DFE_C5_OVRD_VAL] are both set. */
+#else
+	uint64_t dfe_c1_msgn                  : 1;
+	uint64_t dfe_c1_mval                  : 4;
+	uint64_t dfe_c2_msgn                  : 1;
+	uint64_t dfe_c2_mval                  : 4;
+	uint64_t dfe_c3_msgn                  : 1;
+	uint64_t dfe_c3_mval                  : 4;
+	uint64_t reserved_15_63               : 49;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_rx_valbbd_ctrl_1_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_1 cvmx_gserx_lanex_rx_valbbd_ctrl_1_t;
+
+/**
+ * cvmx_gser#_lane#_rx_valbbd_ctrl_2
+ */
+union cvmx_gserx_lanex_rx_valbbd_ctrl_2 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_rx_valbbd_ctrl_2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_6_63                : 58;
+	uint64_t dfe_ovrd_en                  : 1;  /**< Override enable for DFE tap controls. When asserted, the register bits in
+                                                         GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_0 and GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_1 are
+                                                         used for controlling the DFE tap manual mode, instead the manual mode signal indexed by
+                                                         GSER(0..13)_LANE_MODE[LMODE]. Recommended settings: For the following modes: 5G_REFCLK100,
+                                                         5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that DFE tap controls be put in
+                                                         manual mode by setting this bit. In all other modes this register can be ignored. */
+	uint64_t dfe_c5_ovrd_val              : 1;  /**< Override value for DFE Tap5 manual enable. Recommended settings: For the following modes;
+                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap5
+                                                         manual enable be set after setting GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]. In all
+                                                         other modes this register can be ignored. */
+	uint64_t dfe_c4_ovrd_val              : 1;  /**< Override value for DFE Tap4 manual enable. Recommended settings: For the following modes:
+                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap4
+                                                         manual enable be set after setting GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]. In all
+                                                         other modes this register can be ignored. */
+	uint64_t dfe_c3_ovrd_val              : 1;  /**< Override value for DFE Tap3 manual enable. Recommended settings: For the following modes;
+                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap3
+                                                         manual enable be set after setting GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]. In all
+                                                         other modes this register can be ignored. */
+	uint64_t dfe_c2_ovrd_val              : 1;  /**< Override value for DFE Tap2 manual enable. Recommended settings: For the following modes;
+                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap2
+                                                         manual enable be set after setting GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]. In all
+                                                         other modes this register can be ignored. */
+	uint64_t dfe_c1_ovrd_val              : 1;  /**< Override value for DFE Tap1 manual enable. Recommended settings: For the following modes;
+                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap1
+                                                         manual enable be set after setting GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]. In all
+                                                         other modes this register can be ignored. */
+#else
+	uint64_t dfe_c1_ovrd_val              : 1;
+	uint64_t dfe_c2_ovrd_val              : 1;
+	uint64_t dfe_c3_ovrd_val              : 1;
+	uint64_t dfe_c4_ovrd_val              : 1;
+	uint64_t dfe_c5_ovrd_val              : 1;
+	uint64_t dfe_ovrd_en                  : 1;
+	uint64_t reserved_6_63                : 58;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_rx_valbbd_ctrl_2_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_2 cvmx_gserx_lanex_rx_valbbd_ctrl_2_t;
+
+/**
+ * cvmx_gser#_lane#_rx_vma_ctrl
+ *
+ * These are the RAW PCS per-lane RX VMA control registers. These registers are for diagnostic
+ * use only.
+ */
+union cvmx_gserx_lanex_rx_vma_ctrl {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_rx_vma_ctrl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t vma_fine_cfg_sel_ovrrd_en    : 1;  /**< Enable override of VMA fine configuration selection. */
+	uint64_t vma_fine_cfg_sel_ovrrd_val   : 1;  /**< Override value of VMA fine configuration selection.
+                                                         - 0: Coarse mode.
+                                                         - 1: Fine mode. */
+	uint64_t rx_fom_div_delta             : 1;  /**< TX figure of merit delta division-mode enable. */
+	uint64_t rx_vna_ctrl_18_16            : 3;  /**< RX VMA loop control. */
+	uint64_t rx_vna_ctrl_9_0              : 10; /**< RX VMA loop control.
+                                                         bits 9:8: Parameter settling wait time.
+                                                         bit 7: Limit CTLE peak to max value.
+                                                         bit 6: Long reach enabled.
+                                                         bit 5: Short reach enabled.
+                                                         bit 4: Training done override enable.
+                                                         bit 3: Training done override value.
+                                                         bits 2:0: VMA clock modulation. */
+#else
+	uint64_t rx_vna_ctrl_9_0              : 10;
+	uint64_t rx_vna_ctrl_18_16            : 3;
+	uint64_t rx_fom_div_delta             : 1;
+	uint64_t vma_fine_cfg_sel_ovrrd_val   : 1;
+	uint64_t vma_fine_cfg_sel_ovrrd_en    : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_rx_vma_ctrl_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_rx_vma_ctrl cvmx_gserx_lanex_rx_vma_ctrl_t;
+
+/**
  * cvmx_gser#_lane#_vma_coarse_ctrl_0
  *
- * RAW PCS Per Lane Coarse VMA Control Configuration 0 Register
- * Per Lane registers are specific to a paticular lane.
+ * These registers are for diagnostic use only.
+ *
  */
 union cvmx_gserx_lanex_vma_coarse_ctrl_0 {
 	uint64_t u64;
 	struct cvmx_gserx_lanex_vma_coarse_ctrl_0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t iq_max                       : 4;  /**< Slice DLL IQ Maximum Value. */
-	uint64_t iq_min                       : 4;  /**< Slice DLL IQ Minimum Value. */
-	uint64_t iq_step                      : 2;  /**< Slice DLL IQ step size. */
-	uint64_t window_wait                  : 3;  /**< Adaptation window wait setting. */
-	uint64_t lms_wait                     : 3;  /**< LMS wait time setting used to control the number
-                                                         of samples taken during the collection of
-                                                         statistics. */
+	uint64_t iq_max                       : 4;  /**< Slice DLL IQ maximum value in VMA coarse mode. */
+	uint64_t iq_min                       : 4;  /**< Slice DLL IQ minimum value in VMA coarse mode. */
+	uint64_t iq_step                      : 2;  /**< Slice DLL IQ step size in VMA coarse mode. */
+	uint64_t window_wait                  : 3;  /**< Adaptation window wait setting in VMA coarse mode. */
+	uint64_t lms_wait                     : 3;  /**< LMS wait time setting used to control the number of samples taken during the collection of
+                                                         statistics in VMA coarse mode. */
 #else
 	uint64_t lms_wait                     : 3;
 	uint64_t window_wait                  : 3;
@@ -2409,17 +2953,17 @@ typedef union cvmx_gserx_lanex_vma_coarse_ctrl_0 cvmx_gserx_lanex_vma_coarse_ctr
 /**
  * cvmx_gser#_lane#_vma_coarse_ctrl_1
  *
- * RAW PCS Per Lane Coarse VMA Control Configuration 1 Register
- * Per Lane registers are specific to a paticular lane.
+ * These registers are for diagnostic use only.
+ *
  */
 union cvmx_gserx_lanex_vma_coarse_ctrl_1 {
 	uint64_t u64;
 	struct cvmx_gserx_lanex_vma_coarse_ctrl_1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
-	uint64_t ctle_pmax                    : 4;  /**< RX CTLE Peak maximum value. */
-	uint64_t ctle_pmin                    : 4;  /**< RX CTLE Peak minimum value. */
-	uint64_t ctle_pstep                   : 2;  /**< CTLE Peak Peak step size. */
+	uint64_t ctle_pmax                    : 4;  /**< RX CTLE peak maximum value in VMA coarse mode. */
+	uint64_t ctle_pmin                    : 4;  /**< RX CTLE peak minimum value in VMA coarse mode. */
+	uint64_t ctle_pstep                   : 2;  /**< CTLE peak step size in VMA coarse mode. */
 #else
 	uint64_t ctle_pstep                   : 2;
 	uint64_t ctle_pmin                    : 4;
@@ -2434,17 +2978,17 @@ typedef union cvmx_gserx_lanex_vma_coarse_ctrl_1 cvmx_gserx_lanex_vma_coarse_ctr
 /**
  * cvmx_gser#_lane#_vma_coarse_ctrl_2
  *
- * RAW PCS Per Lane Coarse VMA Control Configuration 2 Register
- * Per Lane registers are specific to a paticular lane.
+ * These registers are for diagnostic use only.
+ *
  */
 union cvmx_gserx_lanex_vma_coarse_ctrl_2 {
 	uint64_t u64;
 	struct cvmx_gserx_lanex_vma_coarse_ctrl_2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
-	uint64_t pctle_gmax                   : 4;  /**< RX PRE-CTLE Gain maximum value. */
-	uint64_t pctle_gmin                   : 4;  /**< RX PRE-CTLE Gain minimum value. */
-	uint64_t pctle_gstep                  : 2;  /**< CTLE PRE-Peak Gain step size. */
+	uint64_t pctle_gmax                   : 4;  /**< RX PRE-CTLE gain maximum value in VMA coarse mode. */
+	uint64_t pctle_gmin                   : 4;  /**< RX PRE-CTLE gain minimum value in VMA coarse mode. */
+	uint64_t pctle_gstep                  : 2;  /**< CTLE PRE-peak gain step size in VMA coarse mode. */
 #else
 	uint64_t pctle_gstep                  : 2;
 	uint64_t pctle_gmin                   : 4;
@@ -2457,6 +3001,107 @@ union cvmx_gserx_lanex_vma_coarse_ctrl_2 {
 typedef union cvmx_gserx_lanex_vma_coarse_ctrl_2 cvmx_gserx_lanex_vma_coarse_ctrl_2_t;
 
 /**
+ * cvmx_gser#_lane#_vma_fine_ctrl_0
+ *
+ * These registers are for diagnostic use only.
+ *
+ */
+union cvmx_gserx_lanex_vma_fine_ctrl_0 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_vma_fine_ctrl_0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t rx_sdll_iq_max_fine          : 4;  /**< RX Slice DLL IQ maximum value in VMA Fine mode (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_FINE_CFG_SEL]=1 and
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+	uint64_t rx_sdll_iq_min_fine          : 4;  /**< RX slice DLL IQ minimum value in VMA fine mode (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_FINE_CFG_SEL]=1 and
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+	uint64_t rx_sdll_iq_step_fine         : 2;  /**< RX Slice DLL IQ step size in VMA Fine mode (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_FINE_CFG_SEL]=1 and
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+	uint64_t vma_window_wait_fine         : 3;  /**< Adaptation window wait setting (in VMA fine mode); used to control the number of samples
+                                                         taken during the collection of statistics (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1
+                                                         [VMA_FINE_CFG_SEL]=1 and GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+	uint64_t lms_wait_time_fine           : 3;  /**< LMS wait time setting (in VMA fine mode); used to control the number of samples taken
+                                                         during the collection of statistics (valid when GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1
+                                                         [VMA_FINE_CFG_SEL=1] and GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+#else
+	uint64_t lms_wait_time_fine           : 3;
+	uint64_t vma_window_wait_fine         : 3;
+	uint64_t rx_sdll_iq_step_fine         : 2;
+	uint64_t rx_sdll_iq_min_fine          : 4;
+	uint64_t rx_sdll_iq_max_fine          : 4;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_vma_fine_ctrl_0_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_vma_fine_ctrl_0 cvmx_gserx_lanex_vma_fine_ctrl_0_t;
+
+/**
+ * cvmx_gser#_lane#_vma_fine_ctrl_1
+ *
+ * These registers are for diagnostic use only.
+ *
+ */
+union cvmx_gserx_lanex_vma_fine_ctrl_1 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_vma_fine_ctrl_1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_10_63               : 54;
+	uint64_t rx_ctle_peak_max_fine        : 4;  /**< RX CTLE peak maximum value in VMA fine mode (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1
+                                                         [VMA_FINE_CFG_SEL=1] and GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+	uint64_t rx_ctle_peak_min_fine        : 4;  /**< RX CTLE peak minimum value in VMA fine mode (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1
+                                                         [VMA_FINE_CFG_SEL=1] and GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+	uint64_t rx_ctle_peak_step_fine       : 2;  /**< RX CTLE Peak step size in VMA Fine mode (valid when GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1
+                                                         [VMA_FINE_CFG_SEL=1] and GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+#else
+	uint64_t rx_ctle_peak_step_fine       : 2;
+	uint64_t rx_ctle_peak_min_fine        : 4;
+	uint64_t rx_ctle_peak_max_fine        : 4;
+	uint64_t reserved_10_63               : 54;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_vma_fine_ctrl_1_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_vma_fine_ctrl_1 cvmx_gserx_lanex_vma_fine_ctrl_1_t;
+
+/**
+ * cvmx_gser#_lane#_vma_fine_ctrl_2
+ *
+ * These registers are for diagnostic use only.
+ *
+ */
+union cvmx_gserx_lanex_vma_fine_ctrl_2 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_vma_fine_ctrl_2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_10_63               : 54;
+	uint64_t rx_prectle_peak_max_fine     : 4;  /**< RX PRE-CTLE peak maximum value in VMA fine mode (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1
+                                                         [VMA_FINE_CFG_SEL=1] and GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+	uint64_t rx_prectle_peak_min_fine     : 4;  /**< RX PRE-CTLE peak minimum value in VMA fine mode (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1
+                                                         [VMA_FINE_CFG_SEL=1] and GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+	uint64_t rx_prectle_peak_step_fine    : 2;  /**< RX PRE-CTLE peak step size in VMA fine mode (valid when
+                                                         GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1
+                                                         [VMA_FINE_CFG_SEL=1] and GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1[VMA_MM]=0). */
+#else
+	uint64_t rx_prectle_peak_step_fine    : 2;
+	uint64_t rx_prectle_peak_min_fine     : 4;
+	uint64_t rx_prectle_peak_max_fine     : 4;
+	uint64_t reserved_10_63               : 54;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_vma_fine_ctrl_2_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_vma_fine_ctrl_2 cvmx_gserx_lanex_vma_fine_ctrl_2_t;
+
+/**
  * cvmx_gser#_lane_lpbken
  */
 union cvmx_gserx_lane_lpbken {
@@ -2464,10 +3109,12 @@ union cvmx_gserx_lane_lpbken {
 	struct cvmx_gserx_lane_lpbken_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t lpbken                       : 4;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         ties to the mac_pcs_lane_loopnk_en[3:0] pins of the RAW PCS.
-                                                         When asserted in P0 state, Tx-to-Rx serial
-                                                         loopback is activated on lane X. */
+	uint64_t lpbken                       : 4;  /**< For links that are not in PCIE mode (including all OCI links). When asserted in P0 state,
+                                                         allows per lane TX-to-RX serial loopback activation.
+                                                         <3>: Lane 3
+                                                         <2>: Lane 2
+                                                         <1>: Lane 1
+                                                         <0>: Lane 0 */
 #else
 	uint64_t lpbken                       : 4;
 	uint64_t reserved_4_63                : 60;
@@ -2479,30 +3126,44 @@ typedef union cvmx_gserx_lane_lpbken cvmx_gserx_lane_lpbken_t;
 
 /**
  * cvmx_gser#_lane_mode
- *
- * GSER Lane Mode
- *
  */
 union cvmx_gserx_lane_mode {
 	uint64_t u64;
 	struct cvmx_gserx_lane_mode_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t lmode                        : 4;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         ties to the mac_pcs_lane_mode[3:0] pins of the RAW PCS.
-                                                          0x0: PCIE1
-                                                          0x1: PCIE2
-                                                          0x2: PCIE3
-                                                          0x3: KX
-                                                          0x4: XAUI
-                                                          0x5: KR
-                                                          0x6: SGMII
-                                                          0x7: QSGMII
-                                                          0x8: RXAUI
-                                                          0x9: PCIE1_125
-                                                          0xa: PCIE2_125
-                                                          0xb: PCIE3_125
-                                                          0xc - 0xf: Reserved. */
+	uint64_t lmode                        : 4;  /**< For links that are not in PCIE mode (including all OCI links), used to index into the PHY
+                                                         table to select electrical specs and link rate. Note that the PHY table can be modified
+                                                         such that any supported link rate can be derived regardless of the configured LMODE.
+                                                         0x0: R_25G_REFCLK100
+                                                         0x1: R_5G_REFCLK100
+                                                         0x2: R_8G_REFCLK100
+                                                         0x3: R_125G_REFCLK15625_KX
+                                                         0x4: R_3125G_REFCLK15625_XAUI
+                                                         0x5: R_103215G_REFCLK15625_KR
+                                                         0x6: R_125G_REFCLK15625_SGMII
+                                                         0x7: R_5G_REFCLK15625_QSGMII
+                                                         0x8: R_625G_REFCLK15625_RXAUI
+                                                         0x9: R_25G_REFCLK125
+                                                         0xA: R_5G_REFCLK125
+                                                         0xB: R_8G_REFCLK125
+                                                         0xC - 0xF: reserved
+                                                         This register is not used for PCIE configurations. For non-OCI links, this registers
+                                                         defaults to R_625G_REFCLK15625_RXAUI. For OCI links, the value is mapped at reset from the
+                                                         GSER_SPD and the appropriate table updates are performed so the rate is obtained for the
+                                                         particular reference clock.
+                                                         It is recommended that the PHY be in reset when reconfiguring the LMODE
+                                                         (GSER(0..13)_PHY_CTL[PHY_RESET] is set). If the LMODE is modified when the PHY is out of
+                                                         reset, the GSER(0..13)_RXTX_STAT[LMC] can be used to determine when the PHY has
+                                                         transitioned to the new setting.
+                                                         Once the LMODE has been configured, and the PHY is out of reset, the table entries for the
+                                                         selected LMODE must be updated to reflect the reference clock speed. Refer to the register
+                                                         description and index into the table using the rate and reference speed to obtain the
+                                                         recommended values.
+                                                         Write GSER(0..13)_PLL_P(0..11)_MODE_0.
+                                                         Write GSER(0..13)_PLL_P(0..11)_MODE_1.
+                                                         Write GSER(0..13)_LANE(0..3)_P(0..11)_MODE_0.
+                                                         Write GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1. */
 #else
 	uint64_t lmode                        : 4;
 	uint64_t reserved_4_63                : 60;
@@ -2520,9 +3181,12 @@ union cvmx_gserx_lane_poff {
 	struct cvmx_gserx_lane_poff_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t lpoff                        : 4;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         ties to the mac_pcs_lane_pwr_off[3:0] pins of the RAW PCS.
-                                                         Control signal to power down lane X. */
+	uint64_t lpoff                        : 4;  /**< For links that are not in PCIE mode (including all OCI links), allows for per lane power
+                                                         down.
+                                                         <3>: Lane 3
+                                                         <2>: Lane 2
+                                                         <1>: Lane 1
+                                                         <0>: Lane 0 */
 #else
 	uint64_t lpoff                        : 4;
 	uint64_t reserved_4_63                : 60;
@@ -2534,21 +3198,20 @@ typedef union cvmx_gserx_lane_poff cvmx_gserx_lane_poff_t;
 
 /**
  * cvmx_gser#_lane_srst
- *
- * GSER Lane Soft Reset
- *
  */
 union cvmx_gserx_lane_srst {
 	uint64_t u64;
 	struct cvmx_gserx_lane_srst_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_4_63                : 60;
-	uint64_t lsrst                        : 4;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         ties to the mac_pcs_lane_soft_reset[3:0] pins of the RAW PCS.
-                                                         Allows reset to Lane X. */
+	uint64_t reserved_1_63                : 63;
+	uint64_t lsrst                        : 1;  /**< For links that are not in PCIE mode (including all OCI links), resets all 4 lanes
+                                                         (equivalent to the P2 power state) after any pending requests (power state change, rate
+                                                         change) are complete. The lanes remain in reset state while this signal is asserted. When
+                                                         the signal deasserts, the lanes exit the reset state and the PHY returns to the power
+                                                         state the PHY was in prior. For diagnostic use only. */
 #else
-	uint64_t lsrst                        : 4;
-	uint64_t reserved_4_63                : 60;
+	uint64_t lsrst                        : 1;
+	uint64_t reserved_1_63                : 63;
 #endif
 	} s;
 	struct cvmx_gserx_lane_srst_s         cn78xx;
@@ -2696,17 +3359,22 @@ union cvmx_gserx_pcie_pipe_port_sel {
 	struct cvmx_gserx_pcie_pipe_port_sel_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t cfg_pem1_lane                : 1;  /**< Configures the PIPE/PHY configuration for PEM1 when all 4 PIPEs are enabled.
-                                                         Only set this bit for the 3x1 PCIe mode.  In all other modes this bit needs
-                                                         to be clear. */
+	uint64_t cfg_pem1_dlm2                : 1;  /**< The PIPE (Pipe1 or Pipe2) and PHY (DLM1 or DLM2) configuration for PEM1
+                                                          when in 4-Pipe Mode.
+                                                          This bit should not be set in Single Pipe or 2-Pipe Mode.
+                                                         - 0: PEM1 is tied to Pipe1/DLM1.  This is 3x1 PCIe mode when all 4 PIPES are enabled.
+                                                         - 1: PEM1 is tied to Pipe2/DLM2.  This is 2x1 PCIe mode with SATA */
 	uint64_t pipe_port_sel                : 2;  /**< PIPE enable request.  Change only when phy_reset is asserted.
                                                          - 00: Disables all PIPEs
-                                                         - 01: Enables PIPE0 only.  This is 1x4 PCIe mode.
-                                                         - 10: Enables PIPEs 0 and 1. This is 2x2 PCIe mode or 1x2 PCIe mode with SATA.
-                                                         - 11: Enables PIPEs 0, 1, 2, and 3. This is 2x1 PCIe mode with SATA or 3x1 PCIe mode. */
+                                                         - 01: Single Pipe Mode. Enables PIPE0 (PEM0) only.
+                                                             This is 1x4 PCIe mode.
+                                                         - 10: 2-Pipe Mode.  Enables PIPEs 0 (PEM0) and 1 (PEM1).
+                                                             This is 2x2 PCIe mode or 1x2 PCIe mode with SATA.
+                                                         - 11: 4-Pipe Mode. Enables PIPEs 0 (PEM0), 1, 2 (PEM1), and 3 (PEM2).
+                                                             This is 2x1 PCIe mode with SATA or 3x1 PCIe mode. */
 #else
 	uint64_t pipe_port_sel                : 2;
-	uint64_t cfg_pem1_lane                : 1;
+	uint64_t cfg_pem1_dlm2                : 1;
 	uint64_t reserved_3_63                : 61;
 #endif
 	} s;
@@ -2725,10 +3393,15 @@ union cvmx_gserx_pcie_pipe_rst {
 	struct cvmx_gserx_pcie_pipe_rst_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t pipe3_rst                    : 1;  /**< Pipe 3 Reset.  Setting this bit will put Pipe 3 into reset. */
-	uint64_t pipe2_rst                    : 1;  /**< Pipe 2 Reset.  Setting this bit will put Pipe 2 into reset. */
-	uint64_t pipe1_rst                    : 1;  /**< Pipe 1 Reset.  Setting this bit will put Pipe 1 into reset. */
-	uint64_t pipe0_rst                    : 1;  /**< Pipe 0 Reset.  Setting this bit will put Pipe 0 into reset. */
+	uint64_t pipe3_rst                    : 1;  /**< Pipe 3 Reset.  Setting this bit will put Pipe 3 into reset.
+                                                         PEM2 is always tied to Pipe 3. */
+	uint64_t pipe2_rst                    : 1;  /**< Pipe 2 Reset.  Setting this bit will put Pipe 2 into reset.
+                                                         PEM1 is tied to Pipe 2 in 3x1 PCIe mode (GSER_PCIE_PIPE_PORT_SEL.PIPE_PORT_SEL
+                                                         is set to 4-pipe mode, and GSER_PCIE_PIPE_PORT_SEL.CFG_PEM1_DLM2 is also set). */
+	uint64_t pipe1_rst                    : 1;  /**< Pipe 1 Reset.  Setting this bit will put Pipe 1 into reset.
+                                                         PEM1 is tied to Pipe 1 in 2x2 PCIe or 2x1 PCIe with SATA modes. */
+	uint64_t pipe0_rst                    : 1;  /**< Pipe 0 Reset.  Setting this bit will put Pipe 0 into reset.
+                                                         PEM0 is always tied to Pipe 0. */
 #else
 	uint64_t pipe0_rst                    : 1;
 	uint64_t pipe1_rst                    : 1;
@@ -2754,20 +3427,23 @@ union cvmx_gserx_pcie_pipe_rst_sts {
 	uint64_t reserved_4_63                : 60;
 	uint64_t pipe3_rst                    : 1;  /**< Reflects the current state of the pipe3_rst_n which includes
                                                          the rst__pem2_pcs_rst_n term from the reset controller.  Note that
-                                                         when PIPE3_RST is asserted, no Pipe clocks are generated to PEM3 and
-                                                         any RSL reads to the application side registers will time out. */
+                                                         when PIPE3_RST is asserted (active low), no Pipe clocks are generated
+                                                         to PEM3 and any RSL reads to the application side registers will time out. */
 	uint64_t pipe2_rst                    : 1;  /**< Reflects the current state of the pipe2_rst_n which includes
                                                          the rst__pem2_pcs_rst_n term from the reset controller.  Note that
-                                                         when PIPE2_RST is asserted, no Pipe clocks are generated to PEM1 and
-                                                         any RSL reads to the application side registers will time out. */
+                                                         when PIPE2_RST is asserted (active low) and PEM1 is being used in
+                                                         3x1 PCIe mode (4-Pipe Mode with CFG_PEM1_DLM2 set), no Pipe clocks
+                                                         are generated to PEM1 and any RSL reads to the application side
+                                                         registers will time out. */
 	uint64_t pipe1_rst                    : 1;  /**< Reflects the current state of the pipe1_rst_n which includes
                                                          the rst__pem1_pcs_rst_n term from the reset controller.  Note that
-                                                         when PIPE1_RST is asserted, no Pipe clocks are generated to PEM1 and
-                                                         any RSL reads to the application side registers will time out. */
+                                                         when PIPE1_RST is asserted (active low) and PEM1 is being used in
+                                                         2x2 PCIe or 2x1 PCIe with SATA, no Pipe clocks are generated to PEM1
+                                                         and any RSL reads to the application side registers will time out. */
 	uint64_t pipe0_rst                    : 1;  /**< Reflects the current state of the pipe0_rst_n which includes
                                                          the rst__pem0_pcs_rst_n term from the reset controller.  Note that
-                                                         when PIPE0_RST is asserted, no Pipe clocks are generated to PEM0 and
-                                                         any RSL reads to the application side registers will time out. */
+                                                         when PIPE0_RST is asserted (active low), no Pipe clocks are generated
+                                                         to PEM0 and any RSL reads to the application side registers will time out. */
 #else
 	uint64_t pipe0_rst                    : 1;
 	uint64_t pipe1_rst                    : 1;
@@ -2960,30 +3636,300 @@ union cvmx_gserx_pcie_tx_vboost_lvl {
 typedef union cvmx_gserx_pcie_tx_vboost_lvl cvmx_gserx_pcie_tx_vboost_lvl_t;
 
 /**
- * cvmx_gser#_phy#_scope_mask#
+ * cvmx_gser#_phy#_idcode_hi
+ *
+ * PHY Version Hi.
+ *
+ */
+union cvmx_gserx_phyx_idcode_hi {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_idcode_hi_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t idcode_hi                    : 16; /**< The PHY version high. */
+#else
+	uint64_t idcode_hi                    : 16;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_idcode_hi_s    cn70xx;
+};
+typedef union cvmx_gserx_phyx_idcode_hi cvmx_gserx_phyx_idcode_hi_t;
+
+/**
+ * cvmx_gser#_phy#_idcode_lo
  *
- * Starting count value of PHY Mask register
+ * PHY Version Low.
  *
  */
-union cvmx_gserx_phyx_scope_maskx {
+union cvmx_gserx_phyx_idcode_lo {
 	uint64_t u64;
-	struct cvmx_gserx_phyx_scope_maskx_s {
+	struct cvmx_gserx_phyx_idcode_lo_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t mask_val                     : 16; /**< The internal PHY MASK_VAL_N registers. */
+	uint64_t idcode_lo                    : 16; /**< The PHY version low. */
 #else
-	uint64_t mask_val                     : 16;
+	uint64_t idcode_lo                    : 16;
 	uint64_t reserved_16_63               : 48;
 #endif
 	} s;
-	struct cvmx_gserx_phyx_scope_maskx_s  cn70xx;
+	struct cvmx_gserx_phyx_idcode_lo_s    cn70xx;
+};
+typedef union cvmx_gserx_phyx_idcode_lo cvmx_gserx_phyx_idcode_lo_t;
+
+/**
+ * cvmx_gser#_phy#_lane0_rx_lbert_ctl
+ *
+ * PHY LANE0 RX LBERT Control.
+ *
+ */
+union cvmx_gserx_phyx_lane0_rx_lbert_ctl {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane0_rx_lbert_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t sync                         : 1;  /**< Synchronizes pattern matcher with incoming data.  A write of a 1
+                                                         to this bit resets the error counter and starts a synchronization of
+                                                         the PM.  Once this bit is set, there is no need to write the field back
+                                                         to a zero. */
+	uint64_t mode                         : 4;  /**< Pattern to match.  When changing modes, the field must be set to zero
+                                                          first.  This field should match what was configured for the TX LBERT
+                                                          Control register.
+                                                         - 0: disabled
+                                                         - 1: lfsr31     X^31 + X^28 + 1
+                                                         - 2: lfsr23     X^23 + X^18 + 1
+                                                         - 3: lfsr15     X^15 + X^14 + 1
+                                                         - 4: lfsr7      X^7 + X^6 + 1
+                                                         - 5: d[n] = d[n-10]
+                                                         - 6: d[n] = !d[n-10]
+                                                         - 7: d[n] = !d[n-20]
+                                                          - 15-8: Reserved. */
+#else
+	uint64_t mode                         : 4;
+	uint64_t sync                         : 1;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane0_rx_lbert_ctl_s cn70xx;
 };
-typedef union cvmx_gserx_phyx_scope_maskx cvmx_gserx_phyx_scope_maskx_t;
+typedef union cvmx_gserx_phyx_lane0_rx_lbert_ctl cvmx_gserx_phyx_lane0_rx_lbert_ctl_t;
+
+/**
+ * cvmx_gser#_phy#_lane0_rx_lbert_err
+ *
+ * PHY LANE0 RX LBERT Error.
+ * A read of this register, or a SYNC from the RX LBERT Control register
+ * resets the error count.  If all bits in this regisert are set, the
+ * error counter has saturated.
+ */
+union cvmx_gserx_phyx_lane0_rx_lbert_err {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane0_rx_lbert_err_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t ov14                         : 1;  /**< If this bit is set, and COUNT[15] is also set, signals a overflow of counter. */
+	uint64_t count                        : 15; /**< Current error count if OV14 field is active, then multiply count
+                                                         by 128 to get the actual count. */
+#else
+	uint64_t count                        : 15;
+	uint64_t ov14                         : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane0_rx_lbert_err_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane0_rx_lbert_err cvmx_gserx_phyx_lane0_rx_lbert_err_t;
+
+/**
+ * cvmx_gser#_phy#_lane0_tx_lbert_ctl
+ *
+ * PHY LANE0 TX LBERT Control.
+ *
+ */
+union cvmx_gserx_phyx_lane0_tx_lbert_ctl {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane0_tx_lbert_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_15_63               : 49;
+	uint64_t pat0                         : 10; /**< 10-bit pattern for modes that use this field.  Ignored for
+                                                         other modes. */
+	uint64_t trig_err                     : 1;  /**< Single shot inversion of the LSB of the current symbol.
+                                                         Any write of 1 to this bit will insert an error. */
+	uint64_t mode                         : 4;  /**< Pattern to generate.  When changing modes, the field must be set to zero
+                                                          first.
+                                                         - 0: disabled
+                                                         - 1: lfsr31     X^31 + X^28 + 1
+                                                         - 2: lfsr23     X^23 + X^18 + 1
+                                                         - 3: lfsr15     X^15 + X^14 + 1
+                                                         - 4: lfsr7      X^7 + X^6 + 1
+                                                         - 5: Fixed word (PAT0)
+                                                         - 6: DC-balanced word (PAT0, ~PAT0)
+                                                         - 7: Word pattern (20-bit)
+                                                          - 15-8: Reserved. */
+#else
+	uint64_t mode                         : 4;
+	uint64_t trig_err                     : 1;
+	uint64_t pat0                         : 10;
+	uint64_t reserved_15_63               : 49;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane0_tx_lbert_ctl_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane0_tx_lbert_ctl cvmx_gserx_phyx_lane0_tx_lbert_ctl_t;
+
+/**
+ * cvmx_gser#_phy#_lane0_txdebug
+ *
+ * PHY LANE0 TX DEBUG.
+ *
+ */
+union cvmx_gserx_phyx_lane0_txdebug {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane0_txdebug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t rxdet_meas_time              : 8;  /**< Time to wait for rxdet measurement. */
+	uint64_t detrx_always                 : 1;  /**< Always signals 1 for rx_detect ignoring analog. */
+	uint64_t dtb_sel                      : 3;  /**< Selects data to drive on the DTB. */
+#else
+	uint64_t dtb_sel                      : 3;
+	uint64_t detrx_always                 : 1;
+	uint64_t rxdet_meas_time              : 8;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane0_txdebug_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane0_txdebug cvmx_gserx_phyx_lane0_txdebug_t;
+
+/**
+ * cvmx_gser#_phy#_lane1_rx_lbert_ctl
+ *
+ * PHY LANE1 TX LBERT Control.
+ *
+ */
+union cvmx_gserx_phyx_lane1_rx_lbert_ctl {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane1_rx_lbert_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_4_63                : 60;
+	uint64_t sync                         : 1;  /**< Synchronizes pattern matcher with incoming data.  A write of a 1
+                                                         to this bit resets the error counter and starts a synchronization of
+                                                         the PM.  Once this bit is set, there is no need to write the field back
+                                                         to a zero. */
+	uint64_t mode                         : 3;  /**< Pattern to match.  When changing modes, the field must be set to zero
+                                                          first.  This field should match what was configured for the TX LBERT
+                                                          Control register.
+                                                         - 0: disabled
+                                                         - 1: lfsr31     X^31 + X^28 + 1
+                                                         - 2: lfsr23     X^23 + X^18 + 1
+                                                         - 3: lfsr15     X^15 + X^14 + 1
+                                                         - 4: lfsr7      X^7 + X^6 + 1
+                                                         - 5: d[n] = d[n-10]
+                                                         - 6: d[n] = !d[n-10]
+                                                         - 7: d[n] = !d[n-20] */
+#else
+	uint64_t mode                         : 3;
+	uint64_t sync                         : 1;
+	uint64_t reserved_4_63                : 60;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane1_rx_lbert_ctl_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane1_rx_lbert_ctl cvmx_gserx_phyx_lane1_rx_lbert_ctl_t;
+
+/**
+ * cvmx_gser#_phy#_lane1_rx_lbert_err
+ *
+ * PHY LANE1 RX LBERT Error.
+ * A read of this register, or a SYNC from the RX LBERT Control register
+ * resets the error count.  If all bits in this regisert are set, the
+ * error counter has saturated.
+ */
+union cvmx_gserx_phyx_lane1_rx_lbert_err {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane1_rx_lbert_err_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t ov14                         : 1;  /**< If this bit is set, and COUNT[15] is also set, signals a overflow of counter. */
+	uint64_t count                        : 15; /**< Current error count if OV14 field is active, then multiply count
+                                                         by 128 to get the actual count. */
+#else
+	uint64_t count                        : 15;
+	uint64_t ov14                         : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane1_rx_lbert_err_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane1_rx_lbert_err cvmx_gserx_phyx_lane1_rx_lbert_err_t;
+
+/**
+ * cvmx_gser#_phy#_lane1_tx_lbert_ctl
+ *
+ * PHY LANE1 RX LBERT Control.
+ *
+ */
+union cvmx_gserx_phyx_lane1_tx_lbert_ctl {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane1_tx_lbert_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_15_63               : 49;
+	uint64_t pat0                         : 10; /**< 10-bit pattern for modes that use this field.  Ignored for
+                                                         other modes. */
+	uint64_t trig_err                     : 1;  /**< Single shot inversion of the LSB of the current symbol.
+                                                         Any write of 1 to this bit will insert an error. */
+	uint64_t mode                         : 4;  /**< Pattern to generate.  When changing modes, the field must be set to zero
+                                                          first.
+                                                         - 0: disabled
+                                                         - 1: lfsr31     X^31 + X^28 + 1
+                                                         - 2: lfsr23     X^23 + X^18 + 1
+                                                         - 3: lfsr15     X^15 + X^14 + 1
+                                                         - 4: lfsr7      X^7 + X^6 + 1
+                                                         - 5: Fixed word (PAT0)
+                                                         - 6: DC-balanced word (PAT0, ~PAT0)
+                                                         - 7: Word pattern (20-bit)
+                                                          - 15-8: Reserved. */
+#else
+	uint64_t mode                         : 4;
+	uint64_t trig_err                     : 1;
+	uint64_t pat0                         : 10;
+	uint64_t reserved_15_63               : 49;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane1_tx_lbert_ctl_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane1_tx_lbert_ctl cvmx_gserx_phyx_lane1_tx_lbert_ctl_t;
+
+/**
+ * cvmx_gser#_phy#_lane1_txdebug
+ *
+ * PHY LANE1 TX DEBUG.
+ *
+ */
+union cvmx_gserx_phyx_lane1_txdebug {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane1_txdebug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t rxdet_meas_time              : 8;  /**< Time to wait for rxdet measurement. */
+	uint64_t detrx_always                 : 1;  /**< Always signals 1 for rx_detect ignoring analog. */
+	uint64_t dtb_sel                      : 3;  /**< Selects data to drive on the DTB. */
+#else
+	uint64_t dtb_sel                      : 3;
+	uint64_t detrx_always                 : 1;
+	uint64_t rxdet_meas_time              : 8;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane1_txdebug_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane1_txdebug cvmx_gserx_phyx_lane1_txdebug_t;
 
 /**
  * cvmx_gser#_phy_ctl
  *
- * General PHY/PLL control of the RAW PCS.
+ * This register contains general PHY/PLL control of the RAW PCS.
  *
  */
 union cvmx_gserx_phy_ctl {
@@ -2991,13 +3937,15 @@ union cvmx_gserx_phy_ctl {
 	struct cvmx_gserx_phy_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t phy_pd                       : 1;  /**< Tied to the mac_pcs_refclk_pd pin of the RAW PCS
-                                                         When asserted, the PHY is powered down. */
-	uint64_t phy_reset                    : 1;  /**< Tied to the phy_reset pin of the RAW PCS
-                                                         When asserted, the PHY is held in reset. */
+	uint64_t phy_reset                    : 1;  /**< When asserted, the PHY is held in reset. This bit is initialized as follows:
+                                                         0 (not reset): Bootable PCIe, or OCI when GSER(0..13)_SPD[SPD] comes up in a bootable
+                                                         mode.
+                                                         1 (reset): Non-bootable PCIe, BGX/ILK, or OCI when GSER(0..13)_SPD[SPD] comes up in
+                                                         SW_MODE. */
+	uint64_t phy_pd                       : 1;  /**< When asserted, the PHY is powered down. */
 #else
-	uint64_t phy_reset                    : 1;
 	uint64_t phy_pd                       : 1;
+	uint64_t phy_reset                    : 1;
 	uint64_t reserved_2_63                : 62;
 #endif
 	} s;
@@ -3013,8 +3961,8 @@ union cvmx_gserx_pipe_lpbk {
 	struct cvmx_gserx_pipe_lpbk_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t pcie_lpbk                    : 1;  /**< For non-OCI links, Ties to pipeX_tx2rx_loopbk, analag Serial Loop Back Control
-                                                         input of the PCIE PCS. */
+	uint64_t pcie_lpbk                    : 1;  /**< For links that are in PCIE mode, places the PHY in serial loopback mode, where the
+                                                         QLMn_TXN/QLMn_TXP data are looped back to the QLMn_RXN/QLMn_RXP. */
 #else
 	uint64_t pcie_lpbk                    : 1;
 	uint64_t reserved_1_63                : 63;
@@ -3027,30 +3975,48 @@ typedef union cvmx_gserx_pipe_lpbk cvmx_gserx_pipe_lpbk_t;
 /**
  * cvmx_gser#_pll_p#_mode_0
  *
- * RAW PCS PLL Global Settings Mode 0 Register
- * Global registers are shared across the entire PCS
- * The Protocol selects the specific protocol register as follows.
- * P0:  PCIE1
- * P1:  PCIE2
- * P2:  PCIE3
- * P3:  KX
- * P4:  XAUI
- * P5:  KR
- * P6:  SGMII
- * P7:  RXAUI
- * P9:  CEI
- * P9:  PCIE1_125
- * P10: PCIE2_125
- * P11: PCIE3_125
+ * These are the RAW PCS PLL global settings mode 0 registers. Global registers are shared across
+ * the entire PCS. The Protocol selects the specific protocol register as enumerated by
+ * GSER_LMODE_E.
  */
 union cvmx_gserx_pll_px_mode_0 {
 	uint64_t u64;
 	struct cvmx_gserx_pll_px_mode_0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t pll_icp                      : 4;  /**< PLL Charge pump enable. */
-	uint64_t pll_rloop                    : 3;  /**< Loop resistor tuning. */
-	uint64_t pll_pcs_div                  : 9;  /**< The divider that generates pcs_mac_tx_clk. */
+	uint64_t pll_icp                      : 4;  /**< PLL charge pump enable. This field must be set appropriately if running a
+                                                         GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock. A 'NS' indicates that the
+                                                         rate is not supported at the specified reference clock. Recommended settings:
+                                                                         100Mhz          125Mhz          156.25Mhz
+                                                         1.25G:          0x1             0x1             0x1
+                                                         2.5G:           0x4             0x3             0x3
+                                                         3.125G:         NS              0x1             0x1
+                                                         5.0G:           0x4             0x3             0x3
+                                                         6.25G:          NS              0x1             0x1
+                                                         8.0G:           0x3             0x2             NS
+                                                         10.3215G:       NS              NS              0x1 */
+	uint64_t pll_rloop                    : 3;  /**< Loop resistor tuning. This field must be set appropriately if running a
+                                                         GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock. A 'NS' indicates that the
+                                                         rate is not supported at the specified reference clock. Recommended settings:
+                                                         1.25G: 0x3
+                                                         2.5G: 0x3
+                                                         3.125G: 0x3
+                                                         5.0G: 0x3
+                                                         6.25G: 0x3
+                                                         8.0G: 0x5
+                                                         10.3215G: 0x5 */
+	uint64_t pll_pcs_div                  : 9;  /**< The divider that generates PCS_MAC_TX_CLK. The frequency of the clock is (pll_frequency /
+                                                         PLL_PCS_DIV). This field must be set appropriately if running a
+                                                         GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock or doesn't default to a
+                                                         20-bit RX/TX data path. A 'NS' indicates that the rate is not supported at the specified
+                                                         reference clock. Recommended settings:
+                                                         1.25G: 0x28
+                                                         2.5G: 0x5
+                                                         3.125G: 0x24
+                                                         5.0G: 0xA
+                                                         6.25G: 0xA
+                                                         8.0G: 0xA
+                                                         10.3215G: 0x24 */
 #else
 	uint64_t pll_pcs_div                  : 9;
 	uint64_t pll_rloop                    : 3;
@@ -3065,33 +4031,55 @@ typedef union cvmx_gserx_pll_px_mode_0 cvmx_gserx_pll_px_mode_0_t;
 /**
  * cvmx_gser#_pll_p#_mode_1
  *
- * RAW PCS PLL Global Settings Mode 0 Register
- * Global registers are shared across the entire PCS
- * The Protocol selects the specific protocol register as follows.
- * P0:  PCIE1
- * P1:  PCIE2
- * P2:  PCIE3
- * P3:  KX
- * P4:  XAUI
- * P5:  KR
- * P6:  SGMII
- * P7:  RXAUI
- * P8:  CEI
- * P9:  PCIE1_125
- * P10: PCIE2_125
- * P11: PCIE3_125
+ * Global registers are shared across the entire PCS. The Protocol selects the specific protocol
+ * register as enumerated by GSER_LMODE_E.
  */
 union cvmx_gserx_pll_px_mode_1 {
 	uint64_t u64;
 	struct cvmx_gserx_pll_px_mode_1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t pll_16p5en                   : 1;  /**< Enable for the div 16.5 clock. */
-	uint64_t pll_cpadj                    : 2;  /**< PLL Charge adjust. */
-	uint64_t pll_pcie3en                  : 1;  /**< Enable PCIE3 Mode. */
-	uint64_t pll_opr                      : 1;  /**< 0: Use Ring Oscillator VCO
-                                                         - 1: Use LC-tank VCO */
-	uint64_t pll_div                      : 9;  /**< PLL divider in feedback path which sets the PLL frequency. */
+	uint64_t pll_16p5en                   : 1;  /**< Enable for the DIV 16.5 divided down clock. This field must be set appropriately if
+                                                         running a GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock. A 'NS'
+                                                         indicates that the rate is not supported at the specified reference clock. Recommended
+                                                         settings:
+                                                                         100Mhz          125Mhz          156.25Mhz
+                                                         1.25G:          0x1             0x1             0x1
+                                                         2.5G:           0x0             0x0             0x0
+                                                         3.125G:         NS              0x1             0x1
+                                                         5.0G:           0x0             0x0             0x0
+                                                         6.25G:          NS              0x0             0x0
+                                                         8.0G:           0x0             0x0             NS
+                                                         10.3215G:       NS              NS              0x1 */
+	uint64_t pll_cpadj                    : 2;  /**< PLL charge adjust. This field must be set appropriately if running a
+                                                         GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock. A 'NS' indicates that the
+                                                         rate is not supported at the specified reference clock. Recommended settings:
+                                                                         100Mhz          125Mhz          156.25Mhz
+                                                         1.25G:          0x2             0x2             0x3
+                                                         2.5G:           0x2             0x1             0x2
+                                                         3.125G:         NS              0x2             0x2
+                                                         5.0G:           0x2             0x1             0x2
+                                                         6.25G:          NS              0x2             0x2
+                                                         8.0G:           0x2             0x1             NS
+                                                         10.3215G:       NS              NS              0x2 */
+	uint64_t pll_pcie3en                  : 1;  /**< Enable PCIE3 mode. Recommended settings:
+                                                         0 = Any rate other than 8 Gbps.
+                                                         1 = Rate is equal to 8 Gbps. */
+	uint64_t pll_opr                      : 1;  /**< PLL op range:
+                                                         0 = Use Ring Oscillator VCO. Recommended for rates 6.25 Gbps and lower.
+                                                         1 = Use LC-tank VCO. Recommended for rates 8 Gbps and higher. */
+	uint64_t pll_div                      : 9;  /**< PLL divider in feedback path which sets the PLL frequency. This field must be set
+                                                         appropriately if running a GSER(0..13)_LANE_MODE[LMODE] with a non-default reference
+                                                         clock. A 'NS' indicates that the rate is not supported at the specified reference clock.
+                                                         Recommended settings:
+                                                                         100Mhz          125Mhz          156.25Mhz
+                                                         1.25G:          0x19            0x14            0x10
+                                                         2.5G:           0x19            0x14            0x10
+                                                         3.125G:         NS              0x19            0xa
+                                                         5.0G:           0x19            0x14            0x10
+                                                         6.25G:          NS              0x19            0x14
+                                                         8.0G:           0x28            0x20            NS
+                                                         10.3215G:       NS              NS              0x21 */
 #else
 	uint64_t pll_div                      : 9;
 	uint64_t pll_opr                      : 1;
@@ -3107,16 +4095,13 @@ typedef union cvmx_gserx_pll_px_mode_1 cvmx_gserx_pll_px_mode_1_t;
 
 /**
  * cvmx_gser#_pll_stat
- *
- * GSER PLL Status
- *
  */
 union cvmx_gserx_pll_stat {
 	uint64_t u64;
 	struct cvmx_gserx_pll_stat_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t pll_lock                     : 1;  /**< This is the RAW PCS PLL Lock indication. */
+	uint64_t pll_lock                     : 1;  /**< When set, indicates that the PHY PLL is locked. */
 #else
 	uint64_t pll_lock                     : 1;
 	uint64_t reserved_1_63                : 63;
@@ -3134,11 +4119,9 @@ union cvmx_gserx_qlm_stat {
 	struct cvmx_gserx_qlm_stat_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t rst_rdy                      : 1;  /**< When asserted, the QLM is configured (CSR_GSER_CAV_CFG)
-                                                         and the PLLs are stable. The GSER is ready to accept
-                                                         traffic from the MAC. */
-	uint64_t dcok                         : 1;  /**< When asserted, there is a PLL reference clock indicating there
-                                                         is power to the QLM. */
+	uint64_t rst_rdy                      : 1;  /**< When asserted, the QLM is configured (CSR_GSER_CAV_CFG) and the PLLs are stable. The GSER
+                                                         is ready to accept TX traffic from the MAC. */
+	uint64_t dcok                         : 1;  /**< When asserted, there is a PLL reference clock indicating there is power to the QLM. */
 #else
 	uint64_t dcok                         : 1;
 	uint64_t rst_rdy                      : 1;
@@ -3152,7 +4135,7 @@ typedef union cvmx_gserx_qlm_stat cvmx_gserx_qlm_stat_t;
 /**
  * cvmx_gser#_refclk_sel
  *
- * GSER Reference Clock Control.
+ * This register selects the reference clock.
  *
  */
 union cvmx_gserx_refclk_sel {
@@ -3160,12 +4143,15 @@ union cvmx_gserx_refclk_sel {
 	struct cvmx_gserx_refclk_sel_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t pcie_refclk125               : 1;  /**< For non-OCI links, indicates a 125Mhz Reference clock. */
-	uint64_t com_clk_sel                  : 1;  /**< For non-OCI links, this allows the reference clock to
-                                                         be sourced from the external clock mux (when set). */
-	uint64_t use_com1                     : 1;  /**< For non-OCI links, this is the external mux select.
-                                                         When set, qlmc_refclkn/p_1 are selected as the reference clock
-                                                         When clear, qlmc_refclkn/p_0 are selected as the reference clock. */
+	uint64_t pcie_refclk125               : 1;  /**< For bootable PCIe links, this is loaded with
+                                                         PCIE0/2_REFCLK_125 at cold reset and indicates a 125 MHz reference clock when set. For
+                                                         non-bootable PCIe links, this bit is set to zero at cold reset and indicates a 100 MHz
+                                                         reference clock. It is not used for non-PCIe links. */
+	uint64_t com_clk_sel                  : 1;  /**< When set, the reference clock is sourced from the external clock mux. For bootable PCIe
+                                                         links, this bit is loaded with the PCIEn_COM0_CLK_EN pin at cold reset. */
+	uint64_t use_com1                     : 1;  /**< For non-OCI links, this bit controls the external mux select. When set, QLMC_REF_CLK1_N/P
+                                                         are selected as the reference clock. When clear, QLMC_REF_CLK0_N/P are selected as the
+                                                         reference clock. */
 #else
 	uint64_t use_com1                     : 1;
 	uint64_t com_clk_sel                  : 1;
@@ -3185,10 +4171,16 @@ union cvmx_gserx_rx_coast {
 	struct cvmx_gserx_rx_coast_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t coast                        : 4;  /**< For links that are not in PCIE or BGX mode (including all OCI links),
-                                                         ties to the mac_pcs_rx_cdr_coast[3:0] pins of the RAW PCS.  This
-                                                         is a control signal to freeze the frequency of the CDR in the PHY.
-                                                         This signal is only valid in P0 state. */
+	uint64_t coast                        : 4;  /**< For links that are not in PCIE mode (including all OCI links), control signals to freeze
+                                                         the frequency of the per lane CDR in the PHY. The COAST signals are only valid in P0
+                                                         state, come up asserted and are deasserted in hardware after detecting the electrical idle
+                                                         exit (GSER(0..13)_RX_EIE_DETSTS[EIESTS]). Once the COAST signal deasserts, the CDR is
+                                                         allowed to lock. In BGX mode, the BGX MAC can also control the COAST inputs to the PHY to
+                                                         allow Auto-Negotiation for backplane Ethernet. For diagnostic use only.
+                                                         <3>: Lane 3
+                                                         <2>: Lane 2
+                                                         <1>: Lane 1
+                                                         <0>: Lane 0 */
 #else
 	uint64_t coast                        : 4;
 	uint64_t reserved_4_63                : 60;
@@ -3206,10 +4198,15 @@ union cvmx_gserx_rx_eie_deten {
 	struct cvmx_gserx_rx_eie_deten_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t eiede                        : 4;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         this bit ties to the mac_pcs_rx_eie_det_en[3:0] pins of the RAW PCS.
-                                                         When set, the RAW PCS looks for an Electrical Idle
-                                                         Exit Condition. */
+	uint64_t eiede                        : 4;  /**< For links that are not in PCIE mode (including all OCI links), these bits enable per lane
+                                                         electrical idle exit (EIE) detection. When EIE is detected,
+                                                         GSER(0..13)_RX_EIE_DETSTS[EIELTCH] is asserted. EIEDE defaults to the enabled state. Once
+                                                         EIE has been detected, EIEDE must be disabled, and then enabled again to perform another
+                                                         EIE detection.
+                                                         <3>: Lane 3
+                                                         <2>: Lane 2
+                                                         <1>: Lane 1
+                                                         <0>: Lane 0 */
 #else
 	uint64_t eiede                        : 4;
 	uint64_t reserved_4_63                : 60;
@@ -3227,15 +4224,33 @@ union cvmx_gserx_rx_eie_detsts {
 	struct cvmx_gserx_rx_eie_detsts_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t cdrlock                      : 4;  /**< Lane X CDR lock time has been met after the detection of the Electrical
-                                                         Idle Exit condition. */
-	uint64_t eiests                       : 4;  /**< Status from lane X's RX indicating the detection of a electical IDLE exit
-                                                         condition.  Note that this is a dynamic indication and valid when the
-                                                         associated mac_pcs_rx_eie_det_en[3:0] bit is set. */
-	uint64_t eieltch                      : 4;  /**< Status from lane X's RX indicating the detection of a electical IDLE exit
-                                                         condition.  Note that this is a latched indication that electrical IDLE
-                                                         exit condition was met at least once during the period of time that the
-                                                         associate mac_pcs_rx_eie_det_en[3:0] bit was set. */
+	uint64_t cdrlock                      : 4;  /**< After an electrical idle exit condition (EIE) has been detected, the CDR needs 10000 UI to
+                                                         lock. During this time, there may be RX bit errors. These bits will set when the CDR is
+                                                         guaranteed to be locked. Note that link training can't start until the lane CDRLOCK is
+                                                         set. Software can use CDRLOCK to determine when to expect error free RX data.
+                                                         <11>: Lane 3
+                                                         <10>: Lane 2
+                                                         <9>: Lane 1
+                                                         <8>: Lane 0 */
+	uint64_t eiests                       : 4;  /**< When electrical idle exit detection is enabled (GSER(0..13)_RX_EIE_DETEN[EIEDE] is
+                                                         asserted), indicates that an electrical idle exit condition (EIE) was detected. For higher
+                                                         data rates, the received data needs to have sufficient low frequency content (for example,
+                                                         IDLE symbols) for data transitions to be detected and for EIESTS to stay set accordingly.
+                                                         Under most conditions, EIESTS
+                                                         will stay asserted until GSER(0..13)_RX_EIE_DETEN[EIEDE] is deasserted.
+                                                         <7>: Lane 3
+                                                         <6>: Lane 2
+                                                         <5>: Lane 1
+                                                         <4>: Lane 0 */
+	uint64_t eieltch                      : 4;  /**< When electrical idle exit detection is enabled (GSER(0..13)_RX_EIE_DETEN[EIEDE] is
+                                                         asserted), indicates that an electrical idle exit condition (EIE) was detected. Once a EIE
+                                                         condition has been detected, the per-lane EIELTCH will stay set until
+                                                         GSER_RX_EIE_DETEN.EIEDE is deasserted. Note that there may be RX bit errors until CDRLOCK
+                                                         is set.
+                                                         <3>: Lane 3
+                                                         <2>: Lane 2
+                                                         <1>: Lane 1
+                                                         <0>: Lane 0 */
 #else
 	uint64_t eieltch                      : 4;
 	uint64_t eiests                       : 4;
@@ -3248,6 +4263,39 @@ union cvmx_gserx_rx_eie_detsts {
 typedef union cvmx_gserx_rx_eie_detsts cvmx_gserx_rx_eie_detsts_t;
 
 /**
+ * cvmx_gser#_rx_eie_filter
+ */
+union cvmx_gserx_rx_eie_filter {
+	uint64_t u64;
+	struct cvmx_gserx_rx_eie_filter_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t eii_filt                     : 16; /**< The GSER uses electrical idle inference to determine when a RX lane has reentered
+                                                         electrical IDLE (EI). The PHY electrical IDLE exit detection supports a minimum pulse
+                                                         width of 400ps, therefore configurations that run faster than 2.5G can indicate EI when
+                                                         the serial lines are still driven. For rates faster than 2.5G, it takes 16000 UI of
+                                                         consecutive deasserted GSER(0..13)_RX_EIE_DETSTS[EIESTS] for the GSER to infer EI and
+                                                         begin invalidating RX data. In the event of electrical IDLE inference, the following
+                                                         happens:
+                                                         GSER(0..13)_RX_EIE_DETSTS[CDRLOCK]<lane> is zeroed
+                                                         GSER(0..13)_RX_EIE_DETSTS[EIELTCH]<lane> is zeroed
+                                                         GSER(0..13)_RX_EIE_DETSTS[EIESTS]<lane> is zeroed
+                                                         GSER(0..13)_RX_COAST[COAST]<lane> is asserted to prevent the CDR from trying to lock on
+                                                         the incoming data stream.
+                                                         The lane incoming RX data is invalidated.
+                                                         Writing this register to a non-zero value causes the electrical idle inference to use the
+                                                         EII_FILT count instead of the default settings. Each EII_FILT count represents 20 ns of
+                                                         incremental EI inference time. */
+#else
+	uint64_t eii_filt                     : 16;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_rx_eie_filter_s     cn78xx;
+};
+typedef union cvmx_gserx_rx_eie_filter cvmx_gserx_rx_eie_filter_t;
+
+/**
  * cvmx_gser#_rx_polarity
  */
 union cvmx_gserx_rx_polarity {
@@ -3255,8 +4303,13 @@ union cvmx_gserx_rx_polarity {
 	struct cvmx_gserx_rx_polarity_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t rx_inv                       : 4;  /**< Control signal to invert the polarity of received data.  When
-                                                         asserted, the polarity of the received data is inverted. */
+	uint64_t rx_inv                       : 4;  /**< For links that are not in PCIE mode (including all OCI links), control signal to invert
+                                                         the polarity of received data. When asserted, the polarity of the received data is
+                                                         inverted.
+                                                         <3>: Lane 3
+                                                         <2>: Lane 2
+                                                         <1>: Lane 1
+                                                         <0>: Lane 0 */
 #else
 	uint64_t rx_inv                       : 4;
 	uint64_t reserved_4_63                : 60;
@@ -3274,13 +4327,14 @@ union cvmx_gserx_rx_pstate {
 	struct cvmx_gserx_rx_pstate_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t rxpstate                     : 3;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         ties to the mac_pcs_rx_pstate[3:0] pins of the RAW PCS.
-                                                          - 000:  P0
-                                                          - 001:  P0s
-                                                          - 010:  P1
-                                                          - 011:  P2
-                                                          1xx:  Reserved */
+	uint64_t rxpstate                     : 3;  /**< For links that are not in PCIE mode (including all OCI links), allows RX lane power state
+                                                         control. For diagnostic use only.
+                                                         0x0 = P0. Active state. All internal clocks in the PHY are operational, the only state
+                                                         where the PHY transmits and receives link data.
+                                                         0x1 = P0s. Standby state. The RX link is disabled.
+                                                         0x2 = P1. low power state. Selected internal clocks in the PHY are turned off.
+                                                         0x3 = P2. Power down state. All clocks in the PHY are turned off.
+                                                         else = Reserved. */
 #else
 	uint64_t rxpstate                     : 3;
 	uint64_t reserved_3_63                : 61;
@@ -3298,18 +4352,16 @@ union cvmx_gserx_rxtx_stat {
 	struct cvmx_gserx_rxtx_stat_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t lmc                          : 1;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         this bit is set for a lane mode change (a write
-                                                         to GSER_LANE_MODE that changes the value of the Lane Mode.
-                                                         This bit is clear when each lane acknowledges the change. */
-	uint64_t tpsc                         : 1;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         this bit is set for a TX Power state change (a write
-                                                         to GSER_TX_PSTATE that changes the value of the Power State.
-                                                         This bit is clear when each lane acknowledges the change. */
-	uint64_t rpsc                         : 1;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         this bit is set for a RX Power state change (a write
-                                                         to GSER_RX_PSTATE that changes the value of the Power State.
-                                                         This bit is clear when each lane acknowledges the change. */
+	uint64_t lmc                          : 1;  /**< For links that are not in PCIE mode (including all OCI links), this bit is set when a
+                                                         write is performed to that changes the value of GSER(0..13)_LANE_MODE when the PHY is out
+                                                         of reset. This bit is clear when the PHY acknowledges the change for all 4 lanes. */
+	uint64_t tpsc                         : 1;  /**< For links that are not in PCIE mode (including all OCI links), this bit is set when a
+                                                         write is performed to that changes the value of GSER(0..13)_TX_PSTATE when the PHY is out
+                                                         of reset. This bit is clear when the PHY acknowledges the change for all 4 lanes. For
+                                                         diagnostic use only. */
+	uint64_t rpsc                         : 1;  /**< For links that are not in PCIE mode (including all OCI links), this bit is set when a
+                                                         write is performed to that changes the value to GSER(0..13)_RX_PSTATE. This bit is clear
+                                                         when the PHY acknowledges the change for all 4 lanes. For diagnostic use only. */
 #else
 	uint64_t rpsc                         : 1;
 	uint64_t tpsc                         : 1;
@@ -3638,52 +4690,6 @@ union cvmx_gserx_sata_tx_invert {
 typedef union cvmx_gserx_sata_tx_invert cvmx_gserx_sata_tx_invert_t;
 
 /**
- * cvmx_gser#_slice#_p#_mode
- *
- * RAW PCS Slice Mode Register
- * Slice Registers are shared across two adjacent lanes. SLICE0 access
- * lane pairs 0 & 1. SLICE1 acceses lane pairs 2 & 3.
- * The Protocol selects the specific protocol register as follows.
- * P0:  PCIE1
- * P1:  PCIE2
- * P2:  PCIE3
- * P3:  KX
- * P4:  XAUI
- * P5:  KR
- * P6:  SGMII
- * P7:  QSGMII
- * P8:  RXAUI
- * P9:  PCIE1_125
- * P10: PCIE2_125
- * P11: PCIE3_125
- */
-union cvmx_gserx_slicex_px_mode {
-	uint64_t u64;
-	struct cvmx_gserx_slicex_px_mode_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_15_63               : 49;
-	uint64_t s_spare                      : 2;  /**< bit 14: enable rx1_div33 clock in the SerDes
-                                                         bit 13: enable rx0_div33 clock in the SerDes */
-	uint64_t ldll_isel                    : 2;  /**< Lane DLL current select. */
-	uint64_t sdll_isel                    : 2;  /**< Slice DLL current select. */
-	uint64_t pi_bwsel                     : 3;  /**< PI bandwidth select. */
-	uint64_t ldll_bwsel                   : 3;  /**< Lane DLL bandwidth select. */
-	uint64_t sdll_bwsel                   : 3;  /**< Slice DLL bandwidth select. */
-#else
-	uint64_t sdll_bwsel                   : 3;
-	uint64_t ldll_bwsel                   : 3;
-	uint64_t pi_bwsel                     : 3;
-	uint64_t sdll_isel                    : 2;
-	uint64_t ldll_isel                    : 2;
-	uint64_t s_spare                      : 2;
-	uint64_t reserved_15_63               : 49;
-#endif
-	} s;
-	struct cvmx_gserx_slicex_px_mode_s    cn78xx;
-};
-typedef union cvmx_gserx_slicex_px_mode cvmx_gserx_slicex_px_mode_t;
-
-/**
  * cvmx_gser#_spd
  */
 union cvmx_gserx_spd {
@@ -3691,19 +4697,31 @@ union cvmx_gserx_spd {
 	struct cvmx_gserx_spd_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t spd                          : 4;  /**< For OCI links,
-                                                         spd[3]: When set, indicates 125Mhz reference clock,
-                                                                 When clear, indicates 100Mhz reference clock.
-                                                         spd[2:0]:
-                                                         0x0: 1.25G
-                                                         0x1: 2.5G
-                                                         0x2: 3.125G
-                                                         0x3: 5G
-                                                         0x4: 6.25G
-                                                         0x5: 8G
-                                                         0x6: 10G
-                                                         0x7: SW Mode (Phy comes up in powerdown state)
-                                                         For non-OCI links these bits are not used. */
+	uint64_t spd                          : 4;  /**< For OCI links, these bits are loaded at cold reset from the OCI_SPD<3:0> pins and
+                                                         configure the GSER to a rate/reference clock. This field can be reconfigured and the new
+                                                         GSER(0..13)_LANE_MODE[LMODE] clock takes affect on the next warm reset.
+                                                         For SPD settings that configure a non-default reference clock, hardware updates the PLL
+                                                         settings of the specific lane mode (LMODE) table entry to derive the correct link rate.
+                                                         For non-OCI links, this field is not used.
+                                                         config  refclk      link rate       LMODE
+                                                         0x0:    100Mhz      1.25Gbps        R_125G_REFCLK15625_KX
+                                                         0x1:    100Mhz      2.5Gbps         R_25G_REFCLK100
+                                                         0x2:    100Mhz      5Gbps           R_5G_REFCLK100
+                                                         0x3:    100Mhz      8Gbps           R_8G_REFCLK100
+                                                         0x4:    125Mhz      1.25Gbps        R_125G_REFCLK15625_KX
+                                                         0x5:    125Mhz      2.5Gbps         R_25G_REFCLK125
+                                                         0x6:    125Mhz      3.125Gbps       R_3125G_REFCLK15625_XAUI
+                                                         0x7:    125Mhz      5Gbps           R_5G_REFCLK125
+                                                         0x8:    125Mhz      6.25Gbps        R_625G_REFCLK15625_RXAUI
+                                                         0x9:    125Mhz      8Gbps           R_8G_REFCLK125
+                                                         0xA:    156.25Mhz   2.5Gbps         R_25G_REFCLK100
+                                                         0xB:    156.25Mhz   3.125Gbps       R_3125G_REFCLK15625_XAUI
+                                                         0xC:    156.25Mhz   5Gbps           R_5G_REFCLK125
+                                                         0xD:    156.25Mhz   6.25Gbps        R_625G_REFCLK15625_RXAUI
+                                                         0xE:    126.25Mhz   10.3125Gbps     R_103215G_REFCLK15625_KR
+                                                         0xF:    SW_MODE
+                                                         Note that a value of 0xF is called SW_MODE. The OCI link does not come up configured.
+                                                         Software can come up and configure the interface at a later time. */
 #else
 	uint64_t spd                          : 4;
 	uint64_t reserved_4_63                : 60;
@@ -3721,8 +4739,8 @@ union cvmx_gserx_srst {
 	struct cvmx_gserx_srst_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t srst                         : 1;  /**< When asserted, resets all per lane state in the GSER
-                                                         with the exception of the PHY. */
+	uint64_t srst                         : 1;  /**< When asserted, resets all per-lane state in the GSER with the exception of the PHY and the
+                                                         GSER_CFG. For diagnostic use only. */
 #else
 	uint64_t srst                         : 1;
 	uint64_t reserved_1_63                : 63;
@@ -3740,13 +4758,14 @@ union cvmx_gserx_tx_pstate {
 	struct cvmx_gserx_tx_pstate_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t txpstate                     : 3;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         ties to the mac_pcs_tx_pstate[3:0] pins of the RAW PCS.
-                                                          - 000:  P0
-                                                          - 001:  P0s
-                                                          - 010:  P1
-                                                          - 011:  P2
-                                                          1xx:  Reserved. */
+	uint64_t txpstate                     : 3;  /**< For links that are not in PCIE mode (including all OCI links), allows TX lane power state
+                                                         control. For diagnostic use only.
+                                                         0x0 = P0. Active state. All internal clocks in the PHY are operational, the only state
+                                                         where the PHY transmits and receives link data.
+                                                         0x1 = P0s. Standby state. The TX link is disabled.
+                                                         0x2 = P1. Low power state: Selected internal clocks in the PHY are turned off.
+                                                         0x3 = P2. Power down. All clocks in the PHY are turned off.
+                                                         else = Reserved. */
 #else
 	uint64_t txpstate                     : 3;
 	uint64_t reserved_3_63                : 61;
@@ -3764,8 +4783,12 @@ union cvmx_gserx_tx_vboost {
 	struct cvmx_gserx_tx_vboost_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t vboost                       : 4;  /**< For links that are not in PCIE mode (including all OCI links),
-                                                         ties to the mac_pcs_tx_vboost_en[3:0] pins of the RAW PCS. */
+	uint64_t vboost                       : 4;  /**< For links that are not in PCIE mode (including all OCI links), boosts the TX Vswing from
+                                                         VDD to 1.0 VPPD.
+                                                         <3>: Lane 3
+                                                         <2>: Lane 2
+                                                         <1>: Lane 1
+                                                         <0>: Lane 0 */
 #else
 	uint64_t vboost                       : 4;
 	uint64_t reserved_4_63                : 60;
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-board.h b/arch/mips/include/asm/octeon/cvmx-helper-board.h
index 97aeeb6..c36798e 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-board.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-board.h
@@ -43,7 +43,7 @@
  * Helper functions to abstract board specific data about
  * network ports from the rest of the cvmx-helper files.
  *
- * <hr>$Revision: 77852 $<hr>
+ * <hr>$Revision: 86922 $<hr>
  */
 #ifndef __CVMX_HELPER_BOARD_H__
 #define __CVMX_HELPER_BOARD_H__
@@ -66,12 +66,14 @@ typedef enum {
 	MARVELL_GENERIC_PHY,
  	VITESSE_GENERIC_PHY,
 	CORTINA_PHY,
+ 	INBAND_PHY,
 } cvmx_phy_type_t;
 
 /** Used to record the host mode used by the Cortina CS4321 PHY */
 typedef enum {
 	CVMX_PHY_HOST_MODE_UNKNOWN,
 	CVMX_PHY_HOST_MODE_SGMII,
+	CVMX_PHY_HOST_MODE_QSGMII,
 	CVMX_PHY_HOST_MODE_XAUI,
 	CVMX_PHY_HOST_MODE_RXAUI,
 } cvmx_phy_host_mode_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
index 2e88414..8b8b4b4 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -121,6 +121,11 @@ struct cvmx_cfg_port_param {
 	int8_t ccpp_bpid;
 	int8_t ccpp_pko_port_base;
 	int8_t ccpp_pko_num_ports;
+	bool valid;			/** 1 = port valid, 0 = invalid */
+	bool sgmii_phy_mode;		/** 1 = port in PHY mode, 0 = MAC mode */
+	bool sgmii_1000x_mode;		/** 1 = 1000Base-X mode, 0 = SGMII mode */
+	bool agl_rx_clk_delay_bypass;	/** 1 = use rx clock delay bypass for AGL mode */
+	uint8_t agl_rx_clk_skew;	/** AGL rx clock skew setting (default 0) */
 };
 
 /*
@@ -194,7 +199,7 @@ extern int __cvmx_helper_cfg_pknd(int interface, int index);
  */
 extern int __cvmx_helper_cfg_bpid(int interface, int index);
 
-/*
+/**
  * @INTERNAL
  * Return the configured pko_port base for the port
  *
@@ -412,6 +417,71 @@ int init_cvmx_pko_que_range(void);
  */
 void cvmx_pko_queue_free_all(void);
 
+/**
+ * Returns if port is valid for a given interface
+ *
+ * @param interface  interface to check
+ * @param index      port index in the interface
+ *
+ * @return status of the port present or not.
+ */
+int cvmx_helper_is_port_valid(int interface, int index);
+
+/**
+ * Set whether or not a port is valid
+ *
+ * @param interface interface to set
+ * @param index     port index to set
+ * @param valid     set 0 to make port invalid, 1 for valid
+ */
+void cvmx_helper_set_port_valid(int interface, int index, bool valid);
+
+/**
+ * @INTERNAL
+ * Return if port is in PHY mode
+ *
+ * @param interface the interface number
+ * @param index the port's index number
+ *
+ * @return 1 if port is in PHY mode, 0 if port is in MAC mode
+ */
+extern bool cvmx_helper_get_mac_phy_mode(int interface, int index);
+extern void cvmx_helper_set_mac_phy_mode(int interface, int index, bool valid);
+
+/**
+ * @INTERNAL
+ * Return if port is in 1000Base X mode
+ *
+ * @param interface the interface number
+ * @param index the port's index number
+ *
+ * @return 1 if port is in 1000Base X mode, 0 if port is in SGMII mode
+ */
+extern bool cvmx_helper_get_1000x_mode(int interface, int index);
+extern void cvmx_helper_set_1000x_mode(int interface, int index, bool valid);
+
+/**
+ * @INTERNAL
+ * Return if an AGL port should bypass the RX clock delay
+ *
+ * @param interface the interface number
+ * @param index the port's index number
+ */
+extern bool cvmx_helper_get_agl_rx_clock_delay_bypass(int interface, int index);
+extern void cvmx_helper_set_agl_rx_clock_delay_bypass(int interface, int index,
+						      bool valid);
+
+/**
+ * @INTERNAL
+ * Return the AGL port rx clock skew, only used
+ * if agl_rx_clock_delay_bypass is set.
+ *
+ * @param interface the interface number
+ * @param index the port's index number
+ */
+extern uint8_t cvmx_helper_get_agl_rx_clock_skew(int interface, int index);
+extern void cvmx_helper_set_agl_rx_clock_skew(int interface, int index,
+					      uint8_t value);
 /*
  * Initializes cvmx with user specified config info.
  */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-ilk.h b/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
index 9b5a063..83feed0 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
@@ -52,6 +52,37 @@ extern int __cvmx_helper_ilk_enumerate(int interface);
 
 /**
  * @INTERNAL
+ * Initialize all calendar entries to the xoff state. This
+ * means no data is sent or received.
+ *
+ * @param interface Interface whose calendar are to be initialized.
+ */
+extern void __cvmx_ilk_init_cal(int interface);
+
+/**
+ * @INTERNAL
+ * Setup the channel's tx calendar entry.
+ *
+ * @param interface Interface channel belongs to
+ * @param channel Channel whose calendar entry is to be updated
+ * @param bpid Bpid assigned to the channel
+ */
+extern void __cvmx_ilk_write_tx_cal_entry(int interface, int channel,
+					  unsigned char bpid);
+
+/**
+ * @INTERNAL
+ * Setup the channel's rx calendar entry.
+ *
+ * @param interface Interface channel belongs to
+ * @param channel Channel whose calendar entry is to be updated
+ * @param pipe PKO assigned to the channel
+ */
+void __cvmx_ilk_write_rx_cal_entry(int interface, int channel,
+				   unsigned char pipe);
+
+/**
+ * @INTERNAL
  * Probe a ILK interface and determine the number of ports
  * connected to it. The ILK interface should still be down after
  * this call.
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h b/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
index 93cf850..81c9e08 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
@@ -43,7 +43,7 @@
  * Functions for RGMII/GMII/MII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 73842 $<hr>
+ * <hr>$Revision: 86586 $<hr>
  */
 #ifndef __CVMX_HELPER_RGMII_H__
 #define __CVMX_HELPER_RGMII_H__
@@ -93,6 +93,19 @@ extern int __cvmx_helper_rgmii_enable(int interface);
  *
  * @return Link state
  */
+extern cvmx_helper_link_info_t __cvmx_helper_gmii_link_get(int ipd_port);
+
+/**
+ * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set().
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
 extern cvmx_helper_link_info_t __cvmx_helper_rgmii_link_get(int ipd_port);
 
 /**
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h b/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
index 3c9316a..9317f8a 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 73842 $<hr>
+ * <hr>$Revision: 86626 $<hr>
  */
 #ifndef __CVMX_HELPER_SGMII_H__
 #define __CVMX_HELPER_SGMII_H__
@@ -117,4 +117,79 @@ extern int __cvmx_helper_sgmii_link_set(int ipd_port, cvmx_helper_link_info_t li
  */
 extern int __cvmx_helper_sgmii_configure_loopback(int ipd_port, int enable_internal, int enable_external);
 
+/**
+ * @INTERNAL
+ * Probe a SGMII interface and determine the number of ports
+ * connected to it. The SGMII interface should still be down after
+ * this call. This is used by interfaces using the bgx mac.
+ *
+ * @param interface Interface to probe
+ *
+ * @return Number of ports on the interface. Zero to disable.
+ */
+extern int __cvmx_helper_bgx_sgmii_probe(int interface);
+
+/**
+ * @INTERNAL
+ * Bringup and enable a SGMII interface. After this call packet
+ * I/O should be fully functional. This is called with IPD
+ * enabled but PKO disabled. This is used by interfaces using the
+ * bgx mac.
+ *
+ * @param interface Interface to bring up
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int __cvmx_helper_bgx_sgmii_enable(int interface);
+
+/**
+ * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set(). This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
+extern cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port);
+
+/**
+ * @INTERNAL
+ * Configure an IPD/PKO port for the specified link state. This
+ * function does not influence auto negotiation at the PHY level.
+ * The passed link state must always match the link state returned
+ * by cvmx_helper_link_get(). It is normally best to use
+ * cvmx_helper_link_autoconf() instead. This is used by interfaces
+ * using the bgx mac.
+ *
+ * @param ipd_port  IPD/PKO port to configure
+ * @param link_info The new link state
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port, 
+					    cvmx_helper_link_info_t link_info);
+
+/**
+ * @INTERNAL
+ * Configure a port for internal and/or external loopback. Internal loopback
+ * causes packets sent by the port to be received by Octeon. External loopback
+ * causes packets received from the wire to sent out again. This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to loopback.
+ * @param enable_internal
+ *                 Non zero if you want internal loopback
+ * @param enable_external
+ *                 Non zero if you want external loopback
+ *
+ * @return Zero on success, negative on failure.
+ */
+extern int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port, 
+						      int enable_internal, 
+						      int enable_external);
+
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-util.h b/arch/mips/include/asm/octeon/cvmx-helper-util.h
index 4b3f606..7c67709 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-util.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-util.h
@@ -42,7 +42,7 @@
  *
  * Small helper utilities.
  *
- * <hr>$Revision: 84558 $<hr>
+ * <hr>$Revision: 86308 $<hr>
  */
 
 #ifndef __CVMX_HELPER_UTIL_H__
@@ -60,11 +60,9 @@ typedef char cvmx_bpid_t;
 #define CVMX_MAX_PKND		((cvmx_pknd_t) 64)
 #define CVMX_MAX_BPID		((cvmx_bpid_t) 64)
 
-#define CVMX_HELPER_MAX_IFACE		9
+#define CVMX_HELPER_MAX_IFACE		10
 #define CVMX_HELPER_MAX_PORTS		16
 
-extern CVMX_SHARED bool __cvmx_helper_port_invalid[CVMX_HELPER_MAX_IFACE][CVMX_HELPER_MAX_PORTS];
-
 /**
  * Convert a interface mode into a human readable string
  *
@@ -327,26 +325,6 @@ extern int cvmx_helper_get_interface_num(int ipd_port);
 extern int cvmx_helper_get_interface_index_num(int ipd_port);
 
 /**
- * Returns if port is valid for a given interface
- *
- * @param interface  interface to check
- * @param index      port index in the interface
- *
- * @return status of the port present or not.
- */
-extern int cvmx_helper_is_port_valid(int interface, int index);
-
-/**
- * Set the value returned by cvmx_helper_is_port_valid()
- *
- * @param interface  interface to check
- * @param index      port index in the interface
- * @param valid      true or false.
- *
- */
-void cvmx_helper_set_port_valid(int interface, int index, bool valid);
-
-/**
  * Get port kind for a given port in an interface.
  *
  * @param interface  Interface
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-xaui.h b/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
index 45b344f..99af3db 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 73842 $<hr>
+ * <hr>$Revision: 86925 $<hr>
  */
 #ifndef __CVMX_HELPER_XAUI_H__
 #define __CVMX_HELPER_XAUI_H__
@@ -63,6 +63,18 @@ extern int __cvmx_helper_xaui_enumerate(int interface);
 
 /**
  * @INTERNAL
+ * Probe a XAUI interface and determine the number of ports
+ * connected to it. The XAUI interface should still be down
+ * after this call.
+ *
+ * @param interface Interface to probe
+ *
+ * @return Number of ports on the interface. Zero to disable.
+ */
+extern int __cvmx_helper_bgx_xaui_probe(int interface);
+
+/**
+ * @INTERNAL
  * Bringup and enable a XAUI interface. After this call packet
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
@@ -75,6 +87,18 @@ extern int __cvmx_helper_xaui_enable(int interface);
 
 /**
  * @INTERNAL
+ * Bringup and enable a XAUI interface. After this call packet
+ * I/O should be fully functional. This is called with IPD
+ * enabled but PKO disabled.
+ *
+ * @param interface Interface to bring up
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int __cvmx_helper_bgx_xaui_enable(int interface);
+
+/**
+ * @INTERNAL
  * Return the link state of an IPD/PKO port as returned by
  * auto negotiation. The result of this function may not match
  * Octeon's link config if auto negotiation has changed since
@@ -88,6 +112,19 @@ extern cvmx_helper_link_info_t __cvmx_helper_xaui_link_get(int ipd_port);
 
 /**
  * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set().
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
+extern cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port);
+
+/**
+ * @INTERNAL
  * Configure an IPD/PKO port for the specified link state. This
  * function does not influence auto negotiation at the PHY level.
  * The passed link state must always match the link state returned
@@ -103,6 +140,22 @@ extern int __cvmx_helper_xaui_link_set(int ipd_port, cvmx_helper_link_info_t lin
 
 /**
  * @INTERNAL
+ * Configure an IPD/PKO port for the specified link state. This
+ * function does not influence auto negotiation at the PHY level.
+ * The passed link state must always match the link state returned
+ * by cvmx_helper_link_get(). It is normally best to use
+ * cvmx_helper_link_autoconf() instead.
+ *
+ * @param ipd_port  IPD/PKO port to configure
+ * @param link_info The new link state
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port,
+					   cvmx_helper_link_info_t link_info);
+
+/**
+ * @INTERNAL
  * Configure a port for internal and/or external loopback. Internal loopback
  * causes packets sent by the port to be received by Octeon. External loopback
  * causes packets received from the wire to sent out again.
@@ -117,4 +170,22 @@ extern int __cvmx_helper_xaui_link_set(int ipd_port, cvmx_helper_link_info_t lin
  */
 extern int __cvmx_helper_xaui_configure_loopback(int ipd_port, int enable_internal, int enable_external);
 
+/**
+ * @INTERNAL
+ * Configure a port for internal and/or external loopback. Internal loopback
+ * causes packets sent by the port to be received by Octeon. External loopback
+ * causes packets received from the wire to sent out again.
+ *
+ * @param ipd_port IPD/PKO port to loopback.
+ * @param enable_internal
+ *                 Non zero if you want internal loopback
+ * @param enable_external
+ *                 Non zero if you want external loopback
+ *
+ * @return Zero on success, negative on failure.
+ */
+extern int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port,
+						     int enable_internal,
+						     int enable_external);
+
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-helper.h b/arch/mips/include/asm/octeon/cvmx-helper.h
index 4333946..5ea02cd 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper.h
@@ -42,7 +42,7 @@
  *
  * Helper functions for common, but complicated tasks.
  *
- * <hr>$Revision: 84302 $<hr>
+ * <hr>$Revision: 86434 $<hr>
  */
 
 #ifndef __CVMX_HELPER_H__
@@ -110,6 +110,8 @@ extern "C" {
         CVMX_HELPER_WRITE_CSR(CVMX_HELPER_CSR_INIT_READ, chcsr_csr,     \
             chcsr_type, chcsr_chip, chcsr_fld, chcsr_val)
 
+/* These flags are passed to __cvmx_helper_packet_hardware_enable */
+
 typedef enum {
 	CVMX_HELPER_INTERFACE_MODE_DISABLED,
 	CVMX_HELPER_INTERFACE_MODE_RGMII,
@@ -170,6 +172,17 @@ void cvmx_rgmii_set_back_pressure(uint64_t backpressure_dis);
 extern CVMX_SHARED void (*cvmx_override_pko_queue_priority) (int ipd_port, uint64_t * priorities);
 
 /**
+ * cvmx_override_iface_phy_mode(int interface, int index) is a function pointer.
+ * It is meant to allow customization of interfaces which do not have a PHY.
+ *
+ * @returns 0 if MAC decides TX_CONFIG_REG or 1 if PHY decides  TX_CONFIG_REG.
+ *
+ * If this function pointer is NULL then it defaults to the MAC.
+ */
+extern CVMX_SHARED int (*cvmx_override_iface_phy_mode) (int interface,
+							int index);
+
+/**
  * cvmx_override_ipd_port_setup(int ipd_port) is a function
  * pointer. It is meant to allow customization of the IPD port/port kind
  * setup before packet input/output comes online. It is called
diff --git a/arch/mips/include/asm/octeon/cvmx-hna-defs.h b/arch/mips/include/asm/octeon/cvmx-hna-defs.h
index c13a98b..b802478 100644
--- a/arch/mips/include/asm/octeon/cvmx-hna-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-hna-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -108,163 +108,250 @@ static inline uint64_t CVMX_HNA_DBELL_FUNC(void)
 #define CVMX_HNA_DBELL (CVMX_ADD_IO_SEG(0x0001470000000000ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_DEBUG0 CVMX_HNA_DEBUG0_FUNC()
-static inline uint64_t CVMX_HNA_DEBUG0_FUNC(void)
+#define CVMX_HNA_DIFCTL CVMX_HNA_DIFCTL_FUNC()
+static inline uint64_t CVMX_HNA_DIFCTL_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_DEBUG0 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001180047000040ull);
+		cvmx_warn("CVMX_HNA_DIFCTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001470600000000ull);
 }
 #else
-#define CVMX_HNA_DEBUG0 (CVMX_ADD_IO_SEG(0x0001180047000040ull))
+#define CVMX_HNA_DIFCTL (CVMX_ADD_IO_SEG(0x0001470600000000ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_DEBUG1 CVMX_HNA_DEBUG1_FUNC()
-static inline uint64_t CVMX_HNA_DEBUG1_FUNC(void)
+#define CVMX_HNA_DIFRDPTR CVMX_HNA_DIFRDPTR_FUNC()
+static inline uint64_t CVMX_HNA_DIFRDPTR_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_DEBUG1 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001180047000048ull);
+		cvmx_warn("CVMX_HNA_DIFRDPTR not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001470200000000ull);
 }
 #else
-#define CVMX_HNA_DEBUG1 (CVMX_ADD_IO_SEG(0x0001180047000048ull))
+#define CVMX_HNA_DIFRDPTR (CVMX_ADD_IO_SEG(0x0001470200000000ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_DEBUG2 CVMX_HNA_DEBUG2_FUNC()
-static inline uint64_t CVMX_HNA_DEBUG2_FUNC(void)
+#define CVMX_HNA_ERROR CVMX_HNA_ERROR_FUNC()
+static inline uint64_t CVMX_HNA_ERROR_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_DEBUG2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001180047000050ull);
+		cvmx_warn("CVMX_HNA_ERROR not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000028ull);
 }
 #else
-#define CVMX_HNA_DEBUG2 (CVMX_ADD_IO_SEG(0x0001180047000050ull))
+#define CVMX_HNA_ERROR (CVMX_ADD_IO_SEG(0x0001180047000028ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_DEBUG3 CVMX_HNA_DEBUG3_FUNC()
-static inline uint64_t CVMX_HNA_DEBUG3_FUNC(void)
+#define CVMX_HNA_HPU_CSR CVMX_HNA_HPU_CSR_FUNC()
+static inline uint64_t CVMX_HNA_HPU_CSR_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_DEBUG3 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001180047000058ull);
+		cvmx_warn("CVMX_HNA_HPU_CSR not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000010ull);
 }
 #else
-#define CVMX_HNA_DEBUG3 (CVMX_ADD_IO_SEG(0x0001180047000058ull))
+#define CVMX_HNA_HPU_CSR (CVMX_ADD_IO_SEG(0x0001180047000010ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_DIFCTL CVMX_HNA_DIFCTL_FUNC()
-static inline uint64_t CVMX_HNA_DIFCTL_FUNC(void)
+#define CVMX_HNA_HPU_DBG CVMX_HNA_HPU_DBG_FUNC()
+static inline uint64_t CVMX_HNA_HPU_DBG_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_DIFCTL not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001470600000000ull);
+		cvmx_warn("CVMX_HNA_HPU_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000008ull);
 }
 #else
-#define CVMX_HNA_DIFCTL (CVMX_ADD_IO_SEG(0x0001470600000000ull))
+#define CVMX_HNA_HPU_DBG (CVMX_ADD_IO_SEG(0x0001180047000008ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_DIFRDPTR CVMX_HNA_DIFRDPTR_FUNC()
-static inline uint64_t CVMX_HNA_DIFRDPTR_FUNC(void)
+#define CVMX_HNA_HPU_EIR CVMX_HNA_HPU_EIR_FUNC()
+static inline uint64_t CVMX_HNA_HPU_EIR_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_DIFRDPTR not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001470200000000ull);
+		cvmx_warn("CVMX_HNA_HPU_EIR not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000018ull);
 }
 #else
-#define CVMX_HNA_DIFRDPTR (CVMX_ADD_IO_SEG(0x0001470200000000ull))
+#define CVMX_HNA_HPU_EIR (CVMX_ADD_IO_SEG(0x0001180047000018ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_DTCFADR CVMX_HNA_DTCFADR_FUNC()
-static inline uint64_t CVMX_HNA_DTCFADR_FUNC(void)
+#define CVMX_HNA_PFC0_CNT CVMX_HNA_PFC0_CNT_FUNC()
+static inline uint64_t CVMX_HNA_PFC0_CNT_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_DTCFADR not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001180047000060ull);
+		cvmx_warn("CVMX_HNA_PFC0_CNT not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000090ull);
 }
 #else
-#define CVMX_HNA_DTCFADR (CVMX_ADD_IO_SEG(0x0001180047000060ull))
+#define CVMX_HNA_PFC0_CNT (CVMX_ADD_IO_SEG(0x0001180047000090ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_ERROR CVMX_HNA_ERROR_FUNC()
-static inline uint64_t CVMX_HNA_ERROR_FUNC(void)
+#define CVMX_HNA_PFC0_CTL CVMX_HNA_PFC0_CTL_FUNC()
+static inline uint64_t CVMX_HNA_PFC0_CTL_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_ERROR not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001180047000028ull);
+		cvmx_warn("CVMX_HNA_PFC0_CTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000088ull);
 }
 #else
-#define CVMX_HNA_ERROR (CVMX_ADD_IO_SEG(0x0001180047000028ull))
+#define CVMX_HNA_PFC0_CTL (CVMX_ADD_IO_SEG(0x0001180047000088ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_PFC1_CNT CVMX_HNA_PFC1_CNT_FUNC()
+static inline uint64_t CVMX_HNA_PFC1_CNT_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_PFC1_CNT not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800470000A0ull);
+}
+#else
+#define CVMX_HNA_PFC1_CNT (CVMX_ADD_IO_SEG(0x00011800470000A0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_PFC1_CTL CVMX_HNA_PFC1_CTL_FUNC()
+static inline uint64_t CVMX_HNA_PFC1_CTL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_PFC1_CTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000098ull);
+}
+#else
+#define CVMX_HNA_PFC1_CTL (CVMX_ADD_IO_SEG(0x0001180047000098ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_PFC2_CNT CVMX_HNA_PFC2_CNT_FUNC()
+static inline uint64_t CVMX_HNA_PFC2_CNT_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_PFC2_CNT not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800470000B0ull);
+}
+#else
+#define CVMX_HNA_PFC2_CNT (CVMX_ADD_IO_SEG(0x00011800470000B0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_PFC2_CTL CVMX_HNA_PFC2_CTL_FUNC()
+static inline uint64_t CVMX_HNA_PFC2_CTL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_PFC2_CTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800470000A8ull);
+}
+#else
+#define CVMX_HNA_PFC2_CTL (CVMX_ADD_IO_SEG(0x00011800470000A8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_PFC3_CNT CVMX_HNA_PFC3_CNT_FUNC()
+static inline uint64_t CVMX_HNA_PFC3_CNT_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_PFC3_CNT not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800470000C0ull);
+}
+#else
+#define CVMX_HNA_PFC3_CNT (CVMX_ADD_IO_SEG(0x00011800470000C0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_PFC3_CTL CVMX_HNA_PFC3_CTL_FUNC()
+static inline uint64_t CVMX_HNA_PFC3_CTL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_PFC3_CTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800470000B8ull);
+}
+#else
+#define CVMX_HNA_PFC3_CTL (CVMX_ADD_IO_SEG(0x00011800470000B8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_PFC_GCTL CVMX_HNA_PFC_GCTL_FUNC()
+static inline uint64_t CVMX_HNA_PFC_GCTL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_PFC_GCTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000080ull);
+}
+#else
+#define CVMX_HNA_PFC_GCTL (CVMX_ADD_IO_SEG(0x0001180047000080ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_SBD_DBG0 CVMX_HNA_SBD_DBG0_FUNC()
+static inline uint64_t CVMX_HNA_SBD_DBG0_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_SBD_DBG0 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000040ull);
+}
+#else
+#define CVMX_HNA_SBD_DBG0 (CVMX_ADD_IO_SEG(0x0001180047000040ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_SBD_DBG1 CVMX_HNA_SBD_DBG1_FUNC()
+static inline uint64_t CVMX_HNA_SBD_DBG1_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_SBD_DBG1 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000048ull);
+}
+#else
+#define CVMX_HNA_SBD_DBG1 (CVMX_ADD_IO_SEG(0x0001180047000048ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_HNA_MEMHIDAT CVMX_HNA_MEMHIDAT_FUNC()
-static inline uint64_t CVMX_HNA_MEMHIDAT_FUNC(void)
+#define CVMX_HNA_SBD_DBG2 CVMX_HNA_SBD_DBG2_FUNC()
+static inline uint64_t CVMX_HNA_SBD_DBG2_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_HNA_MEMHIDAT not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001470700000000ull);
+		cvmx_warn("CVMX_HNA_SBD_DBG2 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000050ull);
 }
 #else
-#define CVMX_HNA_MEMHIDAT (CVMX_ADD_IO_SEG(0x0001470700000000ull))
+#define CVMX_HNA_SBD_DBG2 (CVMX_ADD_IO_SEG(0x0001180047000050ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_SBD_DBG3 CVMX_HNA_SBD_DBG3_FUNC()
+static inline uint64_t CVMX_HNA_SBD_DBG3_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_SBD_DBG3 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000058ull);
+}
+#else
+#define CVMX_HNA_SBD_DBG3 (CVMX_ADD_IO_SEG(0x0001180047000058ull))
 #endif
 
 /**
  * cvmx_hna_bist0
+ *
+ * Description:
+ *
  */
 union cvmx_hna_bist0 {
 	uint64_t u64;
 	struct cvmx_hna_bist0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_30_63               : 34;
-	uint64_t mrp                          : 2;  /**< Bist Results for MRP RAM(s) (per-DLC)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t gfb                          : 4;  /**< Bist Results for GFB RAM(s) (per-cluster)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t stx3                         : 2;  /**< Bist Results for STX3 RAM(s)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t stx2                         : 2;  /**< Bist Results for STX2 RAM(s)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t stx1                         : 2;  /**< Bist Results for STX1 RAM(s)
+	uint64_t reserved_60_63               : 4;
+	uint64_t hpc3                         : 12; /**< Bist Results for HPC3 RAM(s) (per-HPU)
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD */
-	uint64_t stx                          : 2;  /**< Bist Results for STX0 RAM(s)
+	uint64_t reserved_44_47               : 4;
+	uint64_t hpc2                         : 12; /**< Bist Results for HPC2 RAM(s) (per-HPU)
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD */
-	uint64_t dtx3                         : 2;  /**< Bist Results for DTX3 RAM(s)
+	uint64_t reserved_28_31               : 4;
+	uint64_t hpc1                         : 12; /**< Bist Results for HPC1 RAM(s) (per-HPU)
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD */
-	uint64_t dtx2                         : 2;  /**< Bist Results for DTX2 RAM(s)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t dtx1                         : 2;  /**< Bist Results for DTX1 RAM(s)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t dtx                          : 2;  /**< Bist Results for DTX0 RAM(s)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t rdf                          : 4;  /**< Bist Results for RWB RAM(s) (per-cluster)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t pdb                          : 4;  /**< Bist Results for PDB RAM(s) (per-cluster)
+	uint64_t reserved_12_15               : 4;
+	uint64_t hpc0                         : 12; /**< Bist Results for HPC0 RAM(s) (per-HPU)
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD */
 #else
-	uint64_t pdb                          : 4;
-	uint64_t rdf                          : 4;
-	uint64_t dtx                          : 2;
-	uint64_t dtx1                         : 2;
-	uint64_t dtx2                         : 2;
-	uint64_t dtx3                         : 2;
-	uint64_t stx                          : 2;
-	uint64_t stx1                         : 2;
-	uint64_t stx2                         : 2;
-	uint64_t stx3                         : 2;
-	uint64_t gfb                          : 4;
-	uint64_t mrp                          : 2;
-	uint64_t reserved_30_63               : 34;
+	uint64_t hpc0                         : 12;
+	uint64_t reserved_12_15               : 4;
+	uint64_t hpc1                         : 12;
+	uint64_t reserved_28_31               : 4;
+	uint64_t hpc2                         : 12;
+	uint64_t reserved_44_47               : 4;
+	uint64_t hpc3                         : 12;
+	uint64_t reserved_60_63               : 4;
 #endif
 	} s;
 	struct cvmx_hna_bist0_s               cn78xx;
@@ -273,98 +360,39 @@ typedef union cvmx_hna_bist0 cvmx_hna_bist0_t;
 
 /**
  * cvmx_hna_bist1
+ *
+ * Description:
+ *
  */
 union cvmx_hna_bist1 {
 	uint64_t u64;
 	struct cvmx_hna_bist1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_24_63               : 40;
-	uint64_t dc3ram3                      : 1;  /**< "Cluster#3 Bist Results for RAM3 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t dc3ram2                      : 1;  /**< "Cluster#3 Bist Results for RAM2 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t dc3ram1                      : 1;  /**< "Cluster#3 Bist Results for RAM1 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t dlc1ram                      : 1;  /**< DLC1 Bist Results
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t dlc0ram                      : 1;  /**< DLC0 Bist Results
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t dc2ram3                      : 1;  /**< "Cluster#2 Bist Results for RAM3 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t dc2ram2                      : 1;  /**< "Cluster#2 Bist Results for RAM2 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t dc2ram1                      : 1;  /**< "Cluster#2 Bist Results for RAM1 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t dc1ram3                      : 1;  /**< "Cluster#1 Bist Results for RAM3 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t dc1ram2                      : 1;  /**< "Cluster#1 Bist Results for RAM2 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t dc1ram1                      : 1;  /**< "Cluster#1 Bist Results for RAM1 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t ram3                         : 1;  /**< "Cluster#0 Bist Results for RAM3 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t ram2                         : 1;  /**< "Cluster#0 Bist Results for RAM2 RAM
+	uint64_t reserved_7_63                : 57;
+	uint64_t hnc1                         : 1;  /**< "SC1 Bist Results for cumulative HNC1 RAMs
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD" */
-	uint64_t ram1                         : 1;  /**< "Cluster#0 Bist Results for RAM1 RAM
+	uint64_t hnc0                         : 1;  /**< "SC0 Bist Results for cumulative HNC0 RAMs
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD" */
-	uint64_t crq                          : 1;  /**< Bist Results for CRQ RAM
+	uint64_t mrp1                         : 1;  /**< Bist Results for DSM-DLC:MRP1 RAM
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD */
-	uint64_t gutv                         : 1;  /**< Bist Results for GUTV RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t gutp                         : 4;  /**< Bist Results for GUTP RAMs (per-cluster)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t ncd                          : 1;  /**< Bist Results for NCD RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t gif                          : 1;  /**< Bist Results for GIF RAM
+	uint64_t mrp0                         : 1;  /**< Bist Results for DSM-DLC:MRP0 RAM
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD */
+	uint64_t reserved_1_2                 : 2;
 	uint64_t gib                          : 1;  /**< Bist Results for GIB RAM
                                                          - 0: GOOD (or bist in progress/never run)
                                                          - 1: BAD */
-	uint64_t gfu                          : 1;  /**< Bist Results for GFU RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
 #else
-	uint64_t gfu                          : 1;
 	uint64_t gib                          : 1;
-	uint64_t gif                          : 1;
-	uint64_t ncd                          : 1;
-	uint64_t gutp                         : 4;
-	uint64_t gutv                         : 1;
-	uint64_t crq                          : 1;
-	uint64_t ram1                         : 1;
-	uint64_t ram2                         : 1;
-	uint64_t ram3                         : 1;
-	uint64_t dc1ram1                      : 1;
-	uint64_t dc1ram2                      : 1;
-	uint64_t dc1ram3                      : 1;
-	uint64_t dc2ram1                      : 1;
-	uint64_t dc2ram2                      : 1;
-	uint64_t dc2ram3                      : 1;
-	uint64_t dlc0ram                      : 1;
-	uint64_t dlc1ram                      : 1;
-	uint64_t dc3ram1                      : 1;
-	uint64_t dc3ram2                      : 1;
-	uint64_t dc3ram3                      : 1;
-	uint64_t reserved_24_63               : 40;
+	uint64_t reserved_1_2                 : 2;
+	uint64_t mrp0                         : 1;
+	uint64_t mrp1                         : 1;
+	uint64_t hnc0                         : 1;
+	uint64_t hnc1                         : 1;
+	uint64_t reserved_7_63                : 57;
 #endif
 	} s;
 	struct cvmx_hna_bist1_s               cn78xx;
@@ -374,76 +402,98 @@ typedef union cvmx_hna_bist1 cvmx_hna_bist1_t;
 /**
  * cvmx_hna_config
  *
- * Specify the RSL base addresses for the block
- * HNA_CONFIG = HNA Configuration Register
+ * This register specifies the HNA HPU programmable controls.
+ *
  */
 union cvmx_hna_config {
 	uint64_t u64;
 	struct cvmx_hna_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
-	uint64_t repl_ena                     : 1;  /**< Replication Mode Enable
-                                                         *** o63-P2 NEW ***
-                                                         When set, enables replication mode performance enhancement
-                                                         feature. This enables the HNA to communicate address
-                                                         replication information during memory references to the
-                                                         memory controller.
-                                                         For o63-P2:        This is used by the memory controller
-                                                         to support graph data in multiple banks (or bank sets), so that
-                                                         the least full bank can be selected to minimize the effects of
-                                                         DDR3 bank conflicts (ie: tRC=row cycle time).
-                                                         For o68: This is used by the memory controller to support graph
-                                                         data in multiple ports (or port sets), so that the least full
-                                                         port can be selected to minimize latency effects.
-                                                         SWNOTE: Using this mode requires the HNA SW compiler and HNA
-                                                         driver to be aware of the address replication changes.
-                                                         This involves changes to the MLOAD/GWALK HNA instruction format
-                                                         (see: IWORD2.SREPL), as well as changes to node arc and metadata
-                                                         definitions which now support an additional REPL field.
-                                                         When clear, replication mode is disabled, and HNA will interpret
-                                                         HNA instructions and node-arc formats which DO NOT have
-                                                         address replication information. */
+	uint64_t reserved_25_63               : 39;
+	uint64_t stk_ll_dis                   : 1;  /**< Stack Linked-List Disable.
+                                                         When set, the linked-list mechanism for run stack
+                                                         and save stack structures will be disabled.  In this mode,
+                                                         the linked-list chunk boundary checking is not done, and
+                                                         therefore the previous/next pointers are non-existent.  The
+                                                         stacks are effectively in an infinite linear buffer, bounded
+                                                         only by the maximum sizes provided in the instruction
+                                                         (IWORD3[RUNSTACKSZ] and IWORD6[SVSTACKSZ]).  There is no
+                                                         space reserved for the previous and next pointers, and
+                                                         [STK_CHKSZ] will be ignored.
+                                                         When the STK_LL_DIS is cleared, the stack linked-list mechanism
+                                                         will operate as per spec. */
+	uint64_t reserved_23_23               : 1;
+	uint64_t stk_chksz                    : 3;  /**< Stack Chunk Size
+                                                          This encoded value specifies the chunk size for both the RNSTK/SVSTK data structures.
+                                                          The RNSTK/SVSTK use a doubly linked list where EACH Chunk's first two 64bit
+                                                          entries contain the PREVIOUS and NEXT chunk pointers.
+                                                         - 0: 32 entries or 256 bytes
+                                                         - 1: 64 entries or 512 Bytes
+                                                         - 2: 128 entries or 1K bytes
+                                                         - 3: 256 entries or 2K bytes    <= DEFAULT power on
+                                                         - 4: 512 entries or 4K bytes
+                                                         - 5: 1024 entries or 8K bytes
+                                                         - 6: 2048 entries or 16K bytes
+                                                         - 7: 4096 entries or 32K bytes
+                                                          NOTE: This field can only be changed at initialization/power on time before
+                                                          the HNA is fed instructions. */
+	uint64_t rnstk_lwm                    : 4;  /**< "RNSTK Low Water Mark
+                                                         This field specifies the low watermark for the run stack. Valid Range: [0..15]
+                                                         Once the run stack goes below the low water mark, HNA will fill entries from the
+                                                         global run stack head to the local run stack tail.
+                                                         The granularity of this field is represented as number of 128B cachelines.
+                                                         NOTE: This field can only be changed at initialization/power on time before
+                                                         the HNA is fed instructions." */
+	uint64_t rnstk_hwm                    : 4;  /**< "RNSTK High Water Mark
+                                                         This field specifies the hi watermark for the run stack. Valid Range: [0..15]
+                                                         Once the local run stack level goes above the hi water mark, the HNA will spill
+                                                         entries from the local run stack tail to the global run stack head (in DDR memory).
+                                                         The granularity of this field is represented as number of 128B cachelines.
+                                                         NOTE: This field can only be changed at initialization/power on time before
+                                                         the HNA is fed instructions." */
+	uint64_t reserved_9_11                : 3;
+	uint64_t ecccordis                    : 1;  /**< ECC Correction Disable
+                                                         When set, all HNA ECC protected data structures will disable their ECC correction
+                                                         logic. When clear (default) ECC correction is always enabled. */
 	uint64_t clmskcrip                    : 4;  /**< Cluster Cripple Mask
-                                                         A one in each bit of the mask represents which DTE cluster to
-                                                         cripple.
-                                                         NOTE: o63 has only a single Cluster (therefore CLMSKCRIP[0]
-                                                         is the only bit used.
-                                                         o2 has 4 clusters, where all CLMSKCRIP mask bits are used.
+                                                         A one in each bit of the mask represents which HPC cluster to
+                                                         cripple. o78 HNA has 4 clusters, where all CLMSKCRIP mask bits are used.
                                                          SWNOTE: The MIO_FUS___HNA_CLMASK_CRIPPLE[3:0] fuse bits will
                                                          be forced into this register at reset. Any fuse bits that
                                                          contain '1' will be disallowed during a write and will always
                                                          be read as '1'. */
-	uint64_t cldtecrip                    : 3;  /**< "Encoding which represents \#of DTEs to cripple for each
-                                                         cluster. Typically DTE_CLCRIP=0 which enables all DTEs
+	uint64_t hpu_clcrip                   : 3;  /**< "HPU Cluster Cripple
+                                                         Encoding which represents number of HPUs to cripple for each
+                                                         cluster. Typically HPU_CLCRIP=0 which enables all HPUs
                                                          within each cluster. However, when the HNA performance
-                                                         counters are used, SW may want to limit the \#of DTEs
+                                                         counters are used, SW may want to limit the number of HPUs
                                                          per cluster available, as there are only 4 parallel
                                                          performance counters.
-                                                         DTE_CLCRIP | \#DTEs crippled(per cluster)
-                                                         ------------+-----------------------------
-                                                         0    |  0      DTE[15:0]:ON
-                                                         1    |  1/2    DTE[15:8]:OFF  /DTE[7:0]:ON
-                                                         2    |  1/4    DTE[15:12]:OFF /DTE[11:0]:ON
-                                                         3    |  3/4    DTE[15:4]:OFF  /DTE[3:0]:ON
-                                                         4    |  1/8    DTE[15:14]:OFF /DTE[13:0]:ON
-                                                         5    |  5/8    DTE[15:6]:OFF  /DTE[5:0]:ON
-                                                         6    |  3/8    DTE[15:10]:OFF /DTE[9:0]:ON
-                                                         7    |  7/8    DTE[15:2]:OFF  /DTE[1:0]:ON
-                                                         NOTE: Higher numbered DTEs are crippled first. For instance,
-                                                         on o63 (with 16 DTEs/cluster), if DTE_CLCRIP=1(1/2), then
-                                                         DTE#s [15:8] within the cluster are crippled and only
-                                                         DTE#s [7:0] are available.
+                                                         HPU_CLCRIP | \#HPUs crippled(per cluster)
+                                                         -----------+-----------------------------
+                                                            0       |  0      HPU[9:0]:ON                   All engines enabled
+                                                            1       |  1      HPU[9]:OFF    /HPU[8:0]:ON    (n-1) engines enabled
+                                                            2       |  3      HPU[9:7]:OFF  /HPU[6:0]:ON    (n-3) engines enabled
+                                                            3       |  4      HPU[9:6]:OFF  /HPU[5:0]:ON    (n-4) engines enabled
+                                                            4       |  5      HPU[9:5]:OFF  /HPU[4:0]:ON    (n-5) engines enabled
+                                                            5       |  6      HPU[9:4]:OFF  /HPU[3:0]:ON    (n-6) engines enabled
+                                                            6       |  8      HPU[9:2]:OFF  /HPU[1:0]:ON    (n-8) engines enabled
+                                                            7       |  9      HPU[9:1]:OFF  /HPU[0]:ON      (n-9) single engine enabled
+                                                         NOTE: Higher numbered HPUs are crippled first. For instance,
+                                                         on o78 (with 10 HPUs/cluster), if HPU_CLCRIP=0x1, then
+                                                         HPU#s [9] within the cluster are crippled and only
+                                                         HPU#s [8:0] are available.
                                                          IMPNOTE: The encodings are done in such a way as to later
-                                                         be used with fuses (for future o2 revisions which will disable
-                                                         some \#of DTEs). Blowing a fuse has the effect that there will
-                                                         always be fewer DTEs available. [ie: we never want a customer
-                                                         to blow additional fuses to get more DTEs].
-                                                         SWNOTE: The MIO_FUS___HNA_NUMDTE_CRIPPLE[2:0] fuse bits will
+                                                         be used with fuses (for future revisions which will disable
+                                                         some number of HPUs). Blowing a fuse has the effect that there will
+                                                         always be fewer HPUs available. [ie: we never want a customer
+                                                         to blow additional fuses to get more HPUs].
+                                                         SWNOTE: The MIO_FUS___HNA_NUMHPU_CRIPPLE[2:0] fuse bits will
                                                          be forced into this register at reset. Any fuse bits that
                                                          contain '1' will be disallowed during a write and will always
                                                          be read as '1'." */
-	uint64_t dteclkdis                    : 1;  /**< HNA Clock Disable Source
-                                                         When SET, the HNA clocks for DTE(thread engine)
+	uint64_t hpuclkdis                    : 1;  /**< HNA Clock Disable Source
+                                                         When SET, the HNA clocks for HPU(thread engine)
                                                          operation are disabled (to conserve overall chip clocking
                                                          power when the HNA function is not used).
                                                          NOTE: When SET, SW MUST NEVER issue NCB-Direct CSR
@@ -451,16 +501,22 @@ union cvmx_hna_config {
                                                          errors).
                                                          NOTE: This should only be written to a different value
                                                          during power-on SW initialization.
-                                                         SWNOTE: The MIO_FUS___HNA_DTE_DISABLE fuse bit will
+                                                         SWNOTE: The MIO_FUS___HNA_HPU_DISABLE fuse bit will
                                                          be forced into this register at reset. If the fuse bit
-                                                         contains '1', writes to DTECLKDIS are disallowed and
+                                                         contains '1', writes to HPUCLKDIS are disallowed and
                                                          will always be read as '1'. */
 #else
-	uint64_t dteclkdis                    : 1;
-	uint64_t cldtecrip                    : 3;
+	uint64_t hpuclkdis                    : 1;
+	uint64_t hpu_clcrip                   : 3;
 	uint64_t clmskcrip                    : 4;
-	uint64_t repl_ena                     : 1;
-	uint64_t reserved_9_63                : 55;
+	uint64_t ecccordis                    : 1;
+	uint64_t reserved_9_11                : 3;
+	uint64_t rnstk_hwm                    : 4;
+	uint64_t rnstk_lwm                    : 4;
+	uint64_t stk_chksz                    : 3;
+	uint64_t reserved_23_23               : 1;
+	uint64_t stk_ll_dis                   : 1;
+	uint64_t reserved_25_63               : 39;
 #endif
 	} s;
 	struct cvmx_hna_config_s              cn78xx;
@@ -469,12 +525,20 @@ typedef union cvmx_hna_config cvmx_hna_config_t;
 
 /**
  * cvmx_hna_control
+ *
+ * This register specifies the HNA CTL/HNC programmable controls.
+ *
  */
 union cvmx_hna_control {
 	uint64_t u64;
 	struct cvmx_hna_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_12_63               : 52;
+	uint64_t reserved_13_63               : 51;
+	uint64_t frcperr                      : 1;  /**< Force Parity Error during CLOAD (HNC-write)
+                                                         When SET, a parity error is forced during the HNC CLOAD
+                                                         instruction. SW can force a single line in the HNC to contain
+                                                         a parity error by setting this bit and performance a CLOAD
+                                                         for a single line (DLEN=32), then clearing the bit. */
 	uint64_t sbdnum                       : 6;  /**< "SBD Debug Entry#
                                                          INTERNAL:
                                                          HNA Scoreboard debug control
@@ -491,11 +555,11 @@ union cvmx_hna_control {
                                                          from that instant in time. */
 	uint64_t reserved_3_4                 : 2;
 	uint64_t pmode                        : 1;  /**< NCB-NRP Arbiter Mode
-                                                         (0=Fixed Priority [LP=WQF,DFF,HP=RGF]/1=RR
+                                                         (0=Fixed Priority [LP=DFF,HP=RGF]/1=RR
                                                          NOTE: This should only be written to a different value
                                                          during power-on SW initialization. */
 	uint64_t qmode                        : 1;  /**< NCB-NRQ Arbiter Mode
-                                                         (0=Fixed Priority [LP=IRF,RWF,PRF,HP=GRF]/1=RR
+                                                         (0=Fixed Priority [LP=NPF,IRF,WRF,PRF,RSRF,HP=SLL]/1=RR
                                                          NOTE: This should only be written to a different value
                                                          during power-on SW initialization. */
 	uint64_t imode                        : 1;  /**< NCB-Inbound Arbiter
@@ -509,7 +573,8 @@ union cvmx_hna_control {
 	uint64_t reserved_3_4                 : 2;
 	uint64_t sbdlck                       : 1;
 	uint64_t sbdnum                       : 6;
-	uint64_t reserved_12_63               : 52;
+	uint64_t frcperr                      : 1;
+	uint64_t reserved_13_63               : 51;
 #endif
 	} s;
 	struct cvmx_hna_control_s             cn78xx;
@@ -519,13 +584,14 @@ typedef union cvmx_hna_control cvmx_hna_control_t;
 /**
  * cvmx_hna_dbell
  *
+ * Description:
  * NOTE: To write to the HNA_DBELL register, a device would issue an IOBST directed at the HNA
- * with addr[34:33]=2'b00.
+ * with addr[34:32] = 0x0 or 0x1.
  * To read the HNA_DBELL register, a device would issue an IOBLD64 directed at the HNA with
- * addr[34:33]=2'b00.
- * NOTE: If HNA_CONFIG[DTECLKDIS]=1 (HNA-DTE clocks disabled), reads/writes to the HNA_DBELL
+ * addr[34:32] = 0x0 or 0x1.
+ * NOTE: If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to the HNA_DBELL
  * register do not take effect.
- * NOTE: If FUSE[TBD]="HNA DTE disable" is blown, reads/writes to the HNA_DBELL register do not
+ * NOTE: If FUSE[TBD]="HNA HPU disable" is blown, reads/writes to the HNA_DBELL register do not
  * take effect.
  */
 union cvmx_hna_dbell {
@@ -538,7 +604,7 @@ union cvmx_hna_dbell {
                                                          into the HNA Instruction FIFO (DIF) in main memory.
                                                          Each HNA instruction contains a fixed size 64B
                                                          instruction word which is executed by the HNA HW.
-                                                         The DBL register can hold up to 1M-1 (2^20-1)
+                                                         The DBELL field can hold up to 1M-1 (2^20-1)
                                                          pending HNA instruction requests.
                                                          During a read (by SW), the 'most recent' contents
                                                          of the HNA_DBELL register are returned at the time
@@ -555,159 +621,18 @@ union cvmx_hna_dbell {
 typedef union cvmx_hna_dbell cvmx_hna_dbell_t;
 
 /**
- * cvmx_hna_debug0
- *
- * "INTERNAL: When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
- * are locked down.
- * Otherwise, the contents of this register are the 'active' contents of the HNA Scoreboard at
- * the time of the
- * CSR read.
- * VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the behavioral
- * model)
- * on the reads unless the DTE Engine specified by HNA_CONTROL[SBDNUM] has previously been
- * assigned an
- * instruction."
- */
-union cvmx_hna_debug0 {
-	uint64_t u64;
-	struct cvmx_hna_debug0_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sbd0                         : 64; /**< "HNA ScoreBoard \#0 Data
-                                                         (HNA Scoreboard Debug)
-                                                         [63:38]   (26) rptr[28:3]: Result Base Pointer (QW-aligned)
-                                                         [37:22]   (16) Cumulative Result Write Counter (for HDR write)
-                                                         [21]       (1) Waiting for GRdRsp EOT
-                                                         [20]       (1) Waiting for GRdReq Issue (to NRQ)
-                                                         [19]       (1) GLPTR/GLCNT Valid
-                                                         [18]       (1) Completion Mark Detected
-                                                         [17:15]    (3) Completion Code [0=PDGONE/1=PERR/2=RFULL/3=TERM]
-                                                         [14]       (1) Completion Detected
-                                                         [13]       (1) Waiting for HDR RWrCmtRsp
-                                                         [12]       (1) Waiting for LAST RESULT RWrCmtRsp
-                                                         [11]       (1) Waiting for HDR RWrReq
-                                                         [10]        (1) Waiting for RWrReq
-                                                         [9]        (1) Waiting for WQWrReq issue
-                                                         [8]        (1) Waiting for PRdRsp EOT
-                                                         [7]        (1) Waiting for PRdReq Issue (to NRQ)
-                                                         [6]        (1) Packet Data Valid
-                                                         [5]        (1) WQVLD
-                                                         [4]        (1) WQ Done Point (either WQWrReq issued (for WQPTR<>0) OR HDR RWrCmtRsp)
-                                                         [3]        (1) Resultant write STF/P Mode
-                                                         [2]        (1) Packet Data LDT mode
-                                                         [1]        (1) Gather Mode
-                                                         [0]        (1) Valid" */
-#else
-	uint64_t sbd0                         : 64;
-#endif
-	} s;
-	struct cvmx_hna_debug0_s              cn78xx;
-};
-typedef union cvmx_hna_debug0 cvmx_hna_debug0_t;
-
-/**
- * cvmx_hna_debug1
- *
- * "INTERNAL: When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
- * are locked down.
- * Otherwise, the contents of this register are the 'active' contents of the HNA Scoreboard at
- * the time of the
- * CSR read.
- * VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the behavioral
- * model)
- * on the reads unless the DTE Engine specified by HNA_CONTROL[SBDNUM] has previously been
- * assigned an
- * instruction."
- */
-union cvmx_hna_debug1 {
-	uint64_t u64;
-	struct cvmx_hna_debug1_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sbd1                         : 64; /**< "HNA ScoreBoard \#1 Data
-                                                         HNA Scoreboard Debug Data
-                                                         [63:56]   (8) UNUSED
-                                                         [55:16]  (40) Packet Data Pointer
-                                                         [15:0]   (16) Packet Data Counter" */
-#else
-	uint64_t sbd1                         : 64;
-#endif
-	} s;
-	struct cvmx_hna_debug1_s              cn78xx;
-};
-typedef union cvmx_hna_debug1 cvmx_hna_debug1_t;
-
-/**
- * cvmx_hna_debug2
- *
- * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
- * are locked down.
- * Otherwise, the contents of this register are the 'active' contents of the HNA Scoreboard at
- * the time of the
- * CSR read.
- * VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the behavioral
- * model)
- * on the reads unless the DTE Engine specified by HNA_CONTROL[SBDNUM] has previously been
- * assigned an
- * instruction.
- */
-union cvmx_hna_debug2 {
-	uint64_t u64;
-	struct cvmx_hna_debug2_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sbd2                         : 64; /**< "HNA ScoreBoard \#2 Data
-                                                         [63:45] (19) UNUSED
-                                                         [44:42]  (3) Instruction Type
-                                                         [41:5]  (37) rwptr[39:3]: Result Write Pointer
-                                                         [4:0]    (5) prwcnt[4:0]: Pending Result Write Counter" */
-#else
-	uint64_t sbd2                         : 64;
-#endif
-	} s;
-	struct cvmx_hna_debug2_s              cn78xx;
-};
-typedef union cvmx_hna_debug2 cvmx_hna_debug2_t;
-
-/**
- * cvmx_hna_debug3
- *
- * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
- * are locked down.
- * Otherwise, the contents of this register are the 'active' contents of the HNA Scoreboard at
- * the time of the
- * CSR read.
- * VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the behavioral
- * model)
- * on the reads unless the DTE Engine specified by HNA_CONTROL[SBDNUM] has previously been
- * assigned an
- * instruction.
- */
-union cvmx_hna_debug3 {
-	uint64_t u64;
-	struct cvmx_hna_debug3_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sbd3                         : 64; /**< "HNA ScoreBoard \#3 Data
-                                                         [63:52] (11) rptr[39:29]: Result Base Pointer (QW-aligned)
-                                                         [52:16] (37) glptr[39:3]: Gather List Pointer
-                                                         [15:0]  (16) glcnt Gather List Counter" */
-#else
-	uint64_t sbd3                         : 64;
-#endif
-	} s;
-	struct cvmx_hna_debug3_s              cn78xx;
-};
-typedef union cvmx_hna_debug3 cvmx_hna_debug3_t;
-
-/**
  * cvmx_hna_difctl
  *
+ * Description:
  * NOTE: To write to the HNA_DIFCTL register, a device would issue an IOBST directed at the HNA
- * with addr[34:32]=3'b110.
+ * with addr[34:32]=0x6.
  * To read the HNA_DIFCTL register, a device would issue an IOBLD64 directed at the HNA with
- * addr[34:32]=3'b110.
+ * addr[34:32]=0x6.
  * NOTE: This register is intended to ONLY be written once (at power-up). Any future writes could
  * cause the HNA and FPA HW to become unpredictable.
- * NOTE: If HNA_CONFIG[DTECLKDIS]=1 (HNA-DTE clocks disabled), reads/writes to the HNA_DIFCTL
+ * NOTE: If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to the HNA_DIFCTL
  * register do not take effect.
- * NOTE: If FUSE[TBD]="HNA DTE disable" is blown, reads/writes to the HNA_DIFCTL register do not
+ * NOTE: If FUSE[TBD]="HNA HPU disable" is blown, reads/writes to the HNA_DIFCTL register do not
  * take effect.
  */
 union cvmx_hna_difctl {
@@ -719,31 +644,7 @@ union cvmx_hna_difctl {
                                                          when the HNA instruction chunk is recycled back
                                                          to the Free Page List maintained by the FPA HW
                                                          (once the HNA instruction has been issued). */
-	uint64_t msegbase                     : 6;  /**< Memory Segmentation Base Address
-                                                         For debug purposes, backdoor accesses to the HNA
-                                                         memory are supported via NCB-Direct CSR accesses to
-                                                         the HNA Memory REGION(if addr[34:32]=5. However due
-                                                         to the existing NCB address decoding scheme, the
-                                                         address only offers a 4GB extent into the HNA memory
-                                                         REGION. Therefore, the MSEGBASE CSR field provides
-                                                         the additional upper memory address bits to allow access
-                                                         to the full extent of memory (128GB MAX).
-                                                         For HNA Memory REGION read NCB-Direct CSR accesses, the
-                                                         38bit L2/DRAM memory byte address is generated as follows:
-                                                         memaddr[37:0] = [HNA_DIFCTL[MSEGBASE],ncb_addr[31:3],3'b0]
-                                                         NOTE: See the upper 6bits of the memory address are sourced
-                                                         from HNA_DIFCTL[MSEGBASE] CSR field. The lower 4GB address
-                                                         offset is directly referenced using the NCB address bits during
-                                                         the reference itself.
-                                                         NOTE: The HNA_DIFCTL[MSEGBASE] is shared amongst all references.
-                                                         As such, if multiple PPs are accessing different segments in memory,
-                                                         their must be a SW mutual exclusive lock during each HNA Memory
-                                                         REGION access to avoid collisions between PPs using the same MSEGBASE
-                                                         CSR field.
-                                                         NOTE: See also HNA_ERROR[HNANXM] programmable interrupt which is
-                                                         flagged if SW tries to access non-existent memory space (address hole
-                                                         or upper unused region of 38bit address space). */
-	uint64_t reserved_13_19               : 7;
+	uint64_t reserved_13_25               : 13;
 	uint64_t ldwb                         : 1;  /**< Load Don't Write Back.
                                                          When set, the HW will issue LDWB command towards the cache when
                                                          fetching last word of instructions, as a result the line will not be written back when
@@ -751,7 +652,7 @@ union cvmx_hna_difctl {
                                                          When clear, the HW will issue regular load towards cache which will cause
                                                          the line to be written back before being replaced. */
 	uint64_t reserved_9_11                : 3;
-	uint64_t size                         : 9;  /**< "Represents the \# of 64B instructions contained
+	uint64_t size                         : 9;  /**< "Represents the number of 64B instructions contained
                                                          within each HNA instruction chunk. At Power-on,
                                                          SW will seed the SIZE register with a fixed
                                                          chunk-size. (Must be at least 3)
@@ -769,8 +670,7 @@ union cvmx_hna_difctl {
 	uint64_t size                         : 9;
 	uint64_t reserved_9_11                : 3;
 	uint64_t ldwb                         : 1;
-	uint64_t reserved_13_19               : 7;
-	uint64_t msegbase                     : 6;
+	uint64_t reserved_13_25               : 13;
 	uint64_t aura                         : 16;
 	uint64_t reserved_42_63               : 22;
 #endif
@@ -782,26 +682,27 @@ typedef union cvmx_hna_difctl cvmx_hna_difctl_t;
 /**
  * cvmx_hna_difrdptr
  *
+ * Description:
  * NOTE: To write to the HNA_DIFRDPTR register, a device would issue an IOBST directed at the HNA
- * with addr[34:33]=2'b01.
+ * with addr[34:32] = 0x2 or 0x3.
  * To read the HNA_DIFRDPTR register, a device would issue an IOBLD64 directed at the HNA with
- * addr[34:33]=2'b01.
- * NOTE: If HNA_CONFIG[DTECLKDIS]=1 (HNA-DTE clocks disabled), reads/writes to the HNA_DIFRDPTR
+ * addr[34:32] = 0x2 or 0x3.
+ * NOTE: If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to the HNA_DIFRDPTR
  * register do not take effect.
- * NOTE: If FUSE[TBD]="HNA DTE disable" is blown, reads/writes to the HNA_DIFRDPTR register do
+ * NOTE: If FUSE[TBD]="HNA HPU disable" is blown, reads/writes to the HNA_DIFRDPTR register do
  * not take effect.
  */
 union cvmx_hna_difrdptr {
 	uint64_t u64;
 	struct cvmx_hna_difrdptr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_40_63               : 24;
-	uint64_t rdptr                        : 35; /**< Represents the 64B-aligned address of the current
+	uint64_t reserved_42_63               : 22;
+	uint64_t rdptr                        : 36; /**< Represents the 64B-aligned address of the current
                                                          instruction in the HNA Instruction FIFO in main
                                                          memory. The RDPTR must be seeded by software at
                                                          boot time, and is then maintained thereafter
                                                          by HNA HW.
-                                                         During the seed write (by SW), RDPTR[6:5]=0,
+                                                         During the seed write (by SW), RDPTR[6]=0,
                                                          since HNA instruction chunks must be 128B aligned.
                                                          During a read (by SW), the 'most recent' contents
                                                          of the RDPTR register are returned at the time
@@ -811,11 +712,11 @@ union cvmx_hna_difrdptr {
                                                          its guaranteed that no new DoorBell register
                                                          writes have occurred and the DoorBell register is
                                                          read as zero). */
-	uint64_t reserved_0_4                 : 5;
+	uint64_t reserved_0_5                 : 6;
 #else
-	uint64_t reserved_0_4                 : 5;
-	uint64_t rdptr                        : 35;
-	uint64_t reserved_40_63               : 24;
+	uint64_t reserved_0_5                 : 6;
+	uint64_t rdptr                        : 36;
+	uint64_t reserved_42_63               : 22;
 #endif
 	} s;
 	struct cvmx_hna_difrdptr_s            cn78xx;
@@ -823,56 +724,10 @@ union cvmx_hna_difrdptr {
 typedef union cvmx_hna_difrdptr cvmx_hna_difrdptr_t;
 
 /**
- * cvmx_hna_dtcfadr
- *
- * "HNA Node Cache Failing Address/Control Error Capture information.
- * This register contains useful information to help in isolating a Node Cache RAM failure.
- * NOTE: The first detected PERR failure is captured in HNA_DTCFADR (locked down), until the
- * corresponding PERR Interrupt is cleared by writing one (W1C). (see: HNA_ERR[DC0PERR[2:0]]).
- * NOTE: In the rare event that multiple parity errors are detected in the same cycle from
- * multiple
- * clusters, the FADR register will be locked down for the least signicant cluster \# (0->3)."
- */
-union cvmx_hna_dtcfadr {
-	uint64_t u64;
-	struct cvmx_hna_dtcfadr_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_44_63               : 20;
-	uint64_t ram3fadr                     : 12; /**< HNA RAM3 Failing Address
-                                                         If HNA_ERR[DC0PERR<2>]=1, this field indicates the
-                                                         failing RAM3 Address. The failing address is locked
-                                                         down until the DC0PERR<2> W1C occurs.
-                                                         NOTE: If multiple DC0PERR<0>=1 errors are detected,
-                                                         then the lsb cluster error information is captured. */
-	uint64_t reserved_25_31               : 7;
-	uint64_t ram2fadr                     : 9;  /**< HNA RAM2 Failing Address
-                                                         If HNA_ERR[DC0PERR<1>]=1, this field indicates the
-                                                         failing RAM2 Address. The failing address is locked
-                                                         down until the DC0PERR<1> W1C occurs.
-                                                         NOTE: If multiple DC0PERR<0>=1 errors are detected,
-                                                         then the lsb cluster error information is captured. */
-	uint64_t reserved_14_15               : 2;
-	uint64_t ram1fadr                     : 14; /**< HNA RAM1 Failing Address
-                                                         If HNA_ERR[DC0PERR<0>]=1, this field indicates the
-                                                         failing RAM1 Address. The failing address is locked
-                                                         down until the DC0PERR<0> W1C occurs.
-                                                         NOTE: If multiple DC0PERR<0>=1 errors are detected,
-                                                         then the lsb cluster error information is captured. */
-#else
-	uint64_t ram1fadr                     : 14;
-	uint64_t reserved_14_15               : 2;
-	uint64_t ram2fadr                     : 9;
-	uint64_t reserved_25_31               : 7;
-	uint64_t ram3fadr                     : 12;
-	uint64_t reserved_44_63               : 20;
-#endif
-	} s;
-	struct cvmx_hna_dtcfadr_s             cn78xx;
-};
-typedef union cvmx_hna_dtcfadr cvmx_hna_dtcfadr_t;
-
-/**
  * cvmx_hna_error
+ *
+ * This register contains error status information.
+ *
  */
 union cvmx_hna_error {
 	uint64_t u64;
@@ -881,7 +736,7 @@ union cvmx_hna_error {
 	uint64_t reserved_20_63               : 44;
 	uint64_t osmerr                       : 1;  /**< OSM reported an Error with the response data. */
 	uint64_t replerr                      : 1;  /**< HNA Illegal Replication Factor Error
-                                                         For o68: HNA only supports 1x, 2x, and 4x port replication.
+                                                         HNA only supports 1x, 2x, and 4x port replication.
                                                          Legal configurations for memory are to support 2 port or
                                                          4 port configurations.
                                                          The REPLERR interrupt will be set in the following illegal
@@ -894,69 +749,46 @@ union cvmx_hna_error {
                                                          If REPLERR is set during a NCB-Direct CSR read access to HNA
                                                          Memory REGION, then the CSR read response data is UNPREDICTABLE. */
 	uint64_t hnanxm                       : 1;  /**< HNA Non-existent Memory Access
-                                                         For o68: DTEs (and backdoor CSR HNA Memory REGION reads)
-                                                         have access to the following 38bit L2/DRAM address space
-                                                         which maps to a 37bit physical DDR3 SDRAM address space.
+                                                         HPUs (and backdoor CSR HNA Memory REGION reads)
+                                                         have access to the following 40bit L2/DRAM address space
+                                                         which maps to a 38bit physical DDR3 SDRAM address space [256GB(max)].
                                                          see:
                                                          DR0: 0x0 0000 0000 0000 to 0x0 0000 0FFF FFFF
                                                          maps to lower 256MB of physical DDR3 SDRAM
                                                          DR1: 0x0 0000 2000 0000 to 0x0 0020 0FFF FFFF
                                                          maps to upper 127.75GB of DDR3 SDRAM
+                                                         NOTE: the 2nd 256MB HOLE maps to IO and is unused(nonexistent) for memory.
                                                          L2/DRAM address space                     Physical DDR3 SDRAM Address space
-                                                         (38bit address)                           (37bit address)
-                                                         +-----------+ 0x0020.0FFF.FFFF
-                                                         ===   DR1   ===                          +-----------+ 0x001F.FFFF.FFFF
-                                                         (128GB-256MB)
-                                                         |           |                     =>    |           |  (128GB-256MB)
-                                                         +-----------+ 0x0000.1FFF.FFFF          |   DR1
-                                                         256MB   |   HOLE    |   (DO NOT USE)
-                                                         +-----------+ 0x0000.0FFF.FFFF          +-----------+ 0x0000.0FFF.FFFF
-                                                         256MB   |    DR0    |                           |   DR0     |   (256MB)
-                                                         +-----------+ 0x0000.0000.0000          +-----------+ 0x0000.0000.0000
+                                                         (40bit address)                           (38bit address)
+                                                         +-----------+ 0x0040.0FFF.FFFF
+                                                         |   DR1     |                            +-----------+ 0x003F.FFFF.FFFF
+                                                         |           | (256GB-256MB)
+                                                         |           |                     =>     |   DR1
+                                                         +-----------+ 0x0000.1FFF.FFFF           |           | (256GB-256MB)
+                                                         |   HOLE    | 256MB (DO NOT USE)
+                                                         +-----------+ 0x0000.0FFF.FFFF           +-----------+ 0x0000.0FFF.FFFF
+                                                         |    DR0    | 256MB                      |   DR0     | (256MB)
+                                                         +-----------+ 0x0000.0000.0000           +-----------+ 0x0000.0000.0000
                                                          In the event the HNA generates a reference to the L2/DRAM
-                                                         address hole (0x0000.0FFF.FFFF - 0x0000.1FFF.FFFF) or to
-                                                         an address above 0x0020.0FFF.FFFF, the HNANXM programmable
-                                                         interrupt bit will be set.
+                                                         address hole (0x0000.0FFF.FFFF - 0x0000.1FFF.FFFF) the HNANXM
+                                                         programmable interrupt bit will be set.
                                                          SWNOTE: Both the 1) SW HNA Graph compiler and the 2) SW NCB-Direct CSR
                                                          accesses to HNA Memory REGION MUST avoid making references
-                                                         to these non-existent memory regions.
+                                                         to this 2nd 256MB HOLE which is non-existent memory region.
                                                          NOTE: If HNANXM is set during a HNA Graph Walk operation,
                                                          then the walk will prematurely terminate with RWORD0[REA]=ERR.
                                                          If HNANXM is set during a NCB-Direct CSR read access to HNA
                                                          Memory REGION, then the CSR read response data is forced to
                                                          128'hBADE_FEED_DEAD_BEEF_FACE_CAFE_BEAD_C0DE. (NOTE: the QW
                                                          being accessed, either the upper or lower QW will be returned). */
-	uint64_t cndrd                        : 1;  /**< If Any of the cluster's detected a Parity error on RAM1
-                                                         this additional bit further specifies that the
-                                                         RAM1 parity error was detected during a CND-RD
-                                                         (Cache Node Metadata Read).
-                                                         INTERNAL: For CNDRD Parity Error, the previous CNA arc fetch
-                                                         information is written to RWORD1+ as follows:
-                                                         RWORD1+[NTYPE]=MNODE
-                                                         RWORD1+[NDNID]=cna.ndnid
-                                                         RWORD1+[NHMSK]=cna.hmsk
-                                                         RWORD1+[NNPTR]=cna.nnptr[13:0]
-                                                         NOTE: This bit is set if ANY node cluster's RAM1 accesses
-                                                         detect a CNDRD error. */
-	uint64_t reserved_15_15               : 1;
+	uint64_t reserved_15_16               : 2;
 	uint64_t dlc1_ovferr                  : 1;  /**< DLC1 Fifo Overflow Error Detected
                                                          This condition should NEVER architecturally occur, and
                                                          is here in case HW credit/debit scheme is not working. */
 	uint64_t dlc0_ovferr                  : 1;  /**< DLC0 Fifo Overflow Error Detected
                                                          This condition should NEVER architecturally occur, and
                                                          is here in case HW credit/debit scheme is not working. */
-	uint64_t dc3perr                      : 3;  /**< "Cluster#3 RAM[3:1] Parity Error Detected
-                                                         See also HNA_DTCFADR register which contains the
-                                                         failing addresses for the internal node cache RAMs." */
-	uint64_t dc2perr                      : 3;  /**< "Cluster#2 RAM[3:1] Parity Error Detected
-                                                         See also HNA_DTCFADR register which contains the
-                                                         failing addresses for the internal node cache RAMs." */
-	uint64_t dc1perr                      : 3;  /**< "Cluster#1 RAM[3:1] Parity Error Detected
-                                                         See also HNA_DTCFADR register which contains the
-                                                         failing addresses for the internal node cache RAMs." */
-	uint64_t dc0perr                      : 3;  /**< "Cluster#0 RAM[3:1] Parity Error Detected
-                                                         See also HNA_DTCFADR register which contains the
-                                                         failing addresses for the internal node cache RAMs." */
+	uint64_t reserved_1_12                : 12;
 	uint64_t dblovf                       : 1;  /**< Doorbell Overflow detected - Status bit
                                                          When set, the 20b accumulated doorbell register
                                                          had overflowed (SW wrote too many doorbell requests).
@@ -969,14 +801,10 @@ union cvmx_hna_error {
                                                          Throws HNA_INTSN_E::HNA_ERROR_DBLOVF. */
 #else
 	uint64_t dblovf                       : 1;
-	uint64_t dc0perr                      : 3;
-	uint64_t dc1perr                      : 3;
-	uint64_t dc2perr                      : 3;
-	uint64_t dc3perr                      : 3;
+	uint64_t reserved_1_12                : 12;
 	uint64_t dlc0_ovferr                  : 1;
 	uint64_t dlc1_ovferr                  : 1;
-	uint64_t reserved_15_15               : 1;
-	uint64_t cndrd                        : 1;
+	uint64_t reserved_15_16               : 2;
 	uint64_t hnanxm                       : 1;
 	uint64_t replerr                      : 1;
 	uint64_t osmerr                       : 1;
@@ -988,53 +816,508 @@ union cvmx_hna_error {
 typedef union cvmx_hna_error cvmx_hna_error_t;
 
 /**
- * cvmx_hna_memhidat
+ * cvmx_hna_hpu_csr
  *
- * HNA supports NCB-Direct CSR acccesses to DFM Memory space for debug purposes. Unfortunately,
- * NCB-Direct accesses
- * are limited to QW-size(64bits), whereas the minimum access granularity for DFM Memory space is
- * OW(128bits). To
- * support writes to DFM Memory space, the Hi-QW of data is sourced from the HNA_MEMHIDAT
- * register. Recall, the
- * OW(128b) in DDR3 memory space is fixed format:
- * OWDATA[127:118]: OWECC[9:0] 10bits of in-band OWECC SEC/DED codeword
- * This can be precomputed/written by SW OR
- * if DFM_FNTCTL[ECC_WENA]=1, DFM hardware will auto-compute the 10b OWECC and place in the
- * OWDATA[127:118] before being written to memory.
- * OWDATA[117:0]:   Memory Data (contains fixed MNODE/MONODE arc formats for use by DTEs(thread
- * engines).
- * Or, a user may choose to treat DFM Memory Space as 'scratch pad' in which case the
- * OWDATA[117:0] may contain user-specified information accessible via NCB-Direct CSR mode
- * accesses to HNA Memory Space.
- * NOTE: To write to the HNA_MEMHIDAT register, a device would issue an IOBST directed at the HNA
- * with addr[34:32]=3'b111.
- * To read the HNA_MEMHIDAT register, a device would issue an IOBLD64 directed at the HNA with
- * addr[34:32]=3'b111.
- * NOTE: If HNA_CONFIG[DTECLKDIS]=1 (HNA-DTE clocks disabled), reads/writes to the HNA_MEMHIDAT
- * register do not take effect.
- * NOTE: If FUSE[TBD]="HNA DTE disable" is blown, reads/writes to the HNA_MEMHIDAT register do
- * not take effect.
- * NOTE: PLEASE REMOVE DEFINITION FROM o68 HRM
+ * "To read one of the HPU internal CSRs for debug (ie: HPU_STATUS, DBG_CURSTK,
+ * DBG_GENERAL),
+ * first a CSR WRITE of the HNA_HPU_DBG is done to specify the HPU CSR#, cluster#=CLID and
+ * HPU#=HPUID,
+ * which is followed by a CSR READ of the HPA_HPU_CSR which returns the contents of the specified
+ * HPU CSR."
+ */
+union cvmx_hna_hpu_csr {
+	uint64_t u64;
+	struct cvmx_hna_hpu_csr_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t csrdat                       : 64; /**< HPU CSR contents specified by the HNA_HPU_DBG CSR. */
+#else
+	uint64_t csrdat                       : 64;
+#endif
+	} s;
+	struct cvmx_hna_hpu_csr_s             cn78xx;
+};
+typedef union cvmx_hna_hpu_csr cvmx_hna_hpu_csr_t;
+
+/**
+ * cvmx_hna_hpu_dbg
+ *
+ * "This register specifies the HPU CSR#, cluster#=CLID and HPU#=HPUID used during a
+ * a CSR READ of the HNA_HPU_CSR register."
+ */
+union cvmx_hna_hpu_dbg {
+	uint64_t u64;
+	struct cvmx_hna_hpu_dbg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_8_63                : 56;
+	uint64_t csrnum                       : 2;  /**< "HPU CSR#
+                                                         - 0: HPU_STATUS
+                                                         - 1: DBG_CURSTK
+                                                         - 2: DBG_GENERAL" */
+	uint64_t clid                         : 2;  /**< HPC Cluster# Valid Range=[0..3] */
+	uint64_t hpuid                        : 4;  /**< HPU Engine ID# Valid Range=[0..11] */
+#else
+	uint64_t hpuid                        : 4;
+	uint64_t clid                         : 2;
+	uint64_t csrnum                       : 2;
+	uint64_t reserved_8_63                : 56;
+#endif
+	} s;
+	struct cvmx_hna_hpu_dbg_s             cn78xx;
+};
+typedef union cvmx_hna_hpu_dbg cvmx_hna_hpu_dbg_t;
+
+/**
+ * cvmx_hna_hpu_eir
+ *
+ * "Used by SW to force Parity or ECC errors on some internal HPU data structures.
+ * A CSR WRITE of this register will force either a Parity or ECC error on the next access
+ * at cluster#=CLID, HPU#=HPUID."
+ */
+union cvmx_hna_hpu_eir {
+	uint64_t u64;
+	struct cvmx_hna_hpu_eir_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t wrdone                       : 1;  /**< When the HNA_HPU_EIR register is written, this bit will
+                                                         be cleared by HW. When the targeted HPU has received
+                                                         the error injection command (ie: error injection armed),
+                                                         the WRDONE bit will be SET.
+                                                         SW will first write the HNA_HPU_EIR register, then do a
+                                                         polling read of the WRDONE bit (until it becomes 1),
+                                                         before issueing an HNA instruction to the targeted HPU
+                                                         which will inject the intended error type for a single
+                                                         occurrence (one-shot). */
+	uint64_t pdperr                       : 1;  /**< Packet Data buffer Parity error
+                                                         Forces parity error on next Packet data buffer read. */
+	uint64_t svflipsyn                    : 2;  /**< Save stack flip syndrome control.
+                                                         Forces 1-bit/2-bit errors on next save stack read. */
+	uint64_t rsflipsyn                    : 2;  /**< Run stack flip syndrome control.
+                                                         Forces 1-bit/2-bit errors on next run stack read. */
+	uint64_t clid                         : 2;  /**< HPC Cluster# Valid Range=[0..3] */
+	uint64_t hpuid                        : 4;  /**< HPU Engine ID# Valid Range=[0..11] */
+#else
+	uint64_t hpuid                        : 4;
+	uint64_t clid                         : 2;
+	uint64_t rsflipsyn                    : 2;
+	uint64_t svflipsyn                    : 2;
+	uint64_t pdperr                       : 1;
+	uint64_t wrdone                       : 1;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} s;
+	struct cvmx_hna_hpu_eir_s             cn78xx;
+};
+typedef union cvmx_hna_hpu_eir cvmx_hna_hpu_eir_t;
+
+/**
+ * cvmx_hna_pfc0_cnt
+ */
+union cvmx_hna_pfc0_cnt {
+	uint64_t u64;
+	struct cvmx_hna_pfc0_cnt_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t pfcnt                        : 64; /**< "HNA Performance Counter 0.
+                                                         When HNA_PFC_GCTL[CNT0ENA]=1, the event selected
+                                                         by HNA_PFC0_CTL[EVSEL] is counted.
+                                                         See also HNA_PFC_GCTL[CNT0WCLR] and HNA_PFC_GCTL
+                                                         [CNT0RCLR] for special clear count cases available
+                                                         for SW data collection." */
+#else
+	uint64_t pfcnt                        : 64;
+#endif
+	} s;
+	struct cvmx_hna_pfc0_cnt_s            cn78xx;
+};
+typedef union cvmx_hna_pfc0_cnt cvmx_hna_pfc0_cnt_t;
+
+/**
+ * cvmx_hna_pfc0_ctl
+ */
+union cvmx_hna_pfc0_ctl {
+	uint64_t u64;
+	struct cvmx_hna_pfc0_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_14_63               : 50;
+	uint64_t evsel                        : 6;  /**< Performance Counter#0 Event Selector (64 total) */
+	uint64_t reserved_6_7                 : 2;
+	uint64_t clhpu                        : 4;  /**< "Performance Counter 0 Cluster HPU Selector.
+                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+                                                         is used to select/monitor the cluster's HPU# for all events
+                                                         associated with Performance Counter#0." */
+	uint64_t clnum                        : 2;  /**< "Performance Counter 0 Cluster Selector.
+                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+                                                         is used to select/monitor the cluster# for all events
+                                                         associated with Performance Counter#0." */
+#else
+	uint64_t clnum                        : 2;
+	uint64_t clhpu                        : 4;
+	uint64_t reserved_6_7                 : 2;
+	uint64_t evsel                        : 6;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_hna_pfc0_ctl_s            cn78xx;
+};
+typedef union cvmx_hna_pfc0_ctl cvmx_hna_pfc0_ctl_t;
+
+/**
+ * cvmx_hna_pfc1_cnt
+ */
+union cvmx_hna_pfc1_cnt {
+	uint64_t u64;
+	struct cvmx_hna_pfc1_cnt_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t pfcnt                        : 64; /**< "HNA Performance Counter 1.
+                                                         When HNA_PFC_GCTL[CNT1ENA]=1, the event selected
+                                                         by HNA_PFC1_CTL[EVSEL] is counted.
+                                                         See also HNA_PFC_GCTL[CNT1WCLR] and HNA_PFC_GCTL
+                                                         [CNT1RCLR] for special clear count cases available
+                                                         for SW data collection." */
+#else
+	uint64_t pfcnt                        : 64;
+#endif
+	} s;
+	struct cvmx_hna_pfc1_cnt_s            cn78xx;
+};
+typedef union cvmx_hna_pfc1_cnt cvmx_hna_pfc1_cnt_t;
+
+/**
+ * cvmx_hna_pfc1_ctl
+ */
+union cvmx_hna_pfc1_ctl {
+	uint64_t u64;
+	struct cvmx_hna_pfc1_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_14_63               : 50;
+	uint64_t evsel                        : 6;  /**< Performance Counter#1 Event Selector (64 total) */
+	uint64_t reserved_6_7                 : 2;
+	uint64_t clhpu                        : 4;  /**< "Performance Counter 1 Cluster HPU Selector.
+                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+                                                         is used to select/monitor the cluster's HPU# for all events
+                                                         associated with Performance Counter#1." */
+	uint64_t clnum                        : 2;  /**< "Performance Counter 1 Cluster Selector.
+                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+                                                         is used to select/monitor the cluster# for all events
+                                                         associated with Performance Counter#1." */
+#else
+	uint64_t clnum                        : 2;
+	uint64_t clhpu                        : 4;
+	uint64_t reserved_6_7                 : 2;
+	uint64_t evsel                        : 6;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_hna_pfc1_ctl_s            cn78xx;
+};
+typedef union cvmx_hna_pfc1_ctl cvmx_hna_pfc1_ctl_t;
+
+/**
+ * cvmx_hna_pfc2_cnt
+ */
+union cvmx_hna_pfc2_cnt {
+	uint64_t u64;
+	struct cvmx_hna_pfc2_cnt_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t pfcnt                        : 64; /**< "HNA Performance Counter 2.
+                                                         When HNA_PFC_GCTL[CNT2ENA]=1, the event selected
+                                                         by HNA_PFC2_CTL[EVSEL] is counted.
+                                                         See also HNA_PFC_GCTL[CNT2WCLR] and HNA_PFC_GCTL
+                                                         [CNT2RCLR] for special clear count cases available
+                                                         for SW data collection." */
+#else
+	uint64_t pfcnt                        : 64;
+#endif
+	} s;
+	struct cvmx_hna_pfc2_cnt_s            cn78xx;
+};
+typedef union cvmx_hna_pfc2_cnt cvmx_hna_pfc2_cnt_t;
+
+/**
+ * cvmx_hna_pfc2_ctl
  */
-union cvmx_hna_memhidat {
+union cvmx_hna_pfc2_ctl {
 	uint64_t u64;
-	struct cvmx_hna_memhidat_s {
+	struct cvmx_hna_pfc2_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t hidat                        : 64; /**< HNA Hi-QW of Write data during NCB-Direct DFM DDR3
-                                                         Memory accesses.
-                                                         All DFM DDR3 memory accesses are OW(128b) references,
-                                                         and since NCB-Direct Mode writes only support QW(64b),
-                                                         the Hi QW of data must be sourced from a CSR register.
-                                                         NOTE: This single register is 'shared' for ALL DFM
-                                                         DDR3 Memory writes.
-                                                         For o68: This register is UNUSED. Treat as spare bits.
-                                                         NOTE: PLEASE REMOVE DEFINITION FROM o68 HRM */
+	uint64_t reserved_14_63               : 50;
+	uint64_t evsel                        : 6;  /**< Performance Counter#2 Event Selector (64 total) */
+	uint64_t reserved_6_7                 : 2;
+	uint64_t clhpu                        : 4;  /**< "Performance Counter#2 Cluster HPU Selector.
+                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+                                                         is used to select/monitor the cluster's HPU# for all events
+                                                         associated with Performance Counter#2." */
+	uint64_t clnum                        : 2;  /**< "Performance Counter#2 Cluster Selector.
+                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+                                                         is used to select/monitor the cluster# for all events
+                                                         associated with Performance Counter#2." */
+#else
+	uint64_t clnum                        : 2;
+	uint64_t clhpu                        : 4;
+	uint64_t reserved_6_7                 : 2;
+	uint64_t evsel                        : 6;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_hna_pfc2_ctl_s            cn78xx;
+};
+typedef union cvmx_hna_pfc2_ctl cvmx_hna_pfc2_ctl_t;
+
+/**
+ * cvmx_hna_pfc3_cnt
+ */
+union cvmx_hna_pfc3_cnt {
+	uint64_t u64;
+	struct cvmx_hna_pfc3_cnt_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t pfcnt                        : 64; /**< "HNA Performance Counter 3.
+                                                         When HNA_PFC_GCTL[CNT3ENA]=1, the event selected
+                                                         by HNA_PFC3_CTL[EVSEL] is counted.
+                                                         See also HNA_PFC_GCTL[CNT3WCLR] and HNA_PFC_GCTL
+                                                         [CNT3RCLR] for special clear count cases available
+                                                         for SW data collection." */
+#else
+	uint64_t pfcnt                        : 64;
+#endif
+	} s;
+	struct cvmx_hna_pfc3_cnt_s            cn78xx;
+};
+typedef union cvmx_hna_pfc3_cnt cvmx_hna_pfc3_cnt_t;
+
+/**
+ * cvmx_hna_pfc3_ctl
+ */
+union cvmx_hna_pfc3_ctl {
+	uint64_t u64;
+	struct cvmx_hna_pfc3_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_14_63               : 50;
+	uint64_t evsel                        : 6;  /**< Performance Counter 3 Event Selector (64 total) */
+	uint64_t reserved_6_7                 : 2;
+	uint64_t clhpu                        : 4;  /**< "Performance Counter 3 Cluster HPU Selector.
+                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+                                                         is used to select/monitor the cluster's HPU# for all events
+                                                         associated with Performance Counter#3." */
+	uint64_t clnum                        : 2;  /**< "Performance Counter 3 Cluster Selector.
+                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+                                                         is used to select/monitor the cluster# for all events
+                                                         associated with Performance Counter 3." */
+#else
+	uint64_t clnum                        : 2;
+	uint64_t clhpu                        : 4;
+	uint64_t reserved_6_7                 : 2;
+	uint64_t evsel                        : 6;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_hna_pfc3_ctl_s            cn78xx;
+};
+typedef union cvmx_hna_pfc3_ctl cvmx_hna_pfc3_ctl_t;
+
+/**
+ * cvmx_hna_pfc_gctl
+ *
+ * Global control across all performance counters.
+ *
+ */
+union cvmx_hna_pfc_gctl {
+	uint64_t u64;
+	struct cvmx_hna_pfc_gctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t cnt3rclr                     : 1;  /**< "Performance Counter 3 Read Clear.
+                                                         If this bit is set, CSR reads to the HNA_PFC3_CNT
+                                                         will clear the count value. This allows SW to maintain
+                                                         'cumulative' counters to avoid HW wraparound." */
+	uint64_t cnt2rclr                     : 1;  /**< "Performance Counter 2 Read Clear.
+                                                         If this bit is set, CSR reads to the HNA_PFC2_CNT
+                                                         will clear the count value. This allows SW to maintain
+                                                         'cumulative' counters to avoid HW wraparound." */
+	uint64_t cnt1rclr                     : 1;  /**< "Performance Counter 1 Read Clear.
+                                                         If this bit is set, CSR reads to the HNA_PFC1_CNT
+                                                         will clear the count value. This allows SW to maintain
+                                                         'cumulative' counters to avoid HW wraparound." */
+	uint64_t cnt0rclr                     : 1;  /**< "Performance Counter 0 Read Clear.
+                                                         If this bit is set, CSR reads to the HNA_PFC0_CNT
+                                                         will clear the count value. This allows SW to maintain
+                                                         'cumulative' counters to avoid HW wraparound." */
+	uint64_t cnt3wclr                     : 1;  /**< "Performance Counter 3 Write Clear.
+                                                         If this bit is set, CSR writes to the HNA_PFC3_CNT
+                                                         will clear the count value.
+                                                         If this bit is clear, CSR writes to the HNA_PFC3_CNT
+                                                         will continue the count from the written value." */
+	uint64_t cnt2wclr                     : 1;  /**< "Performance Counter 2 Write Clear.
+                                                         If this bit is set, CSR writes to the HNA_PFC2_CNT
+                                                         will clear the count value.
+                                                         If this bit is clear, CSR writes to the HNA_PFC2_CNT
+                                                         will continue the count from the written value." */
+	uint64_t cnt1wclr                     : 1;  /**< "Performance Counter 1 Write Clear.
+                                                         If this bit is set, CSR writes to the HNA_PFC1_CNT
+                                                         will clear the count value.
+                                                         If this bit is clear, CSR writes to the HNA_PFC1_CNT
+                                                         will continue the count from the written value." */
+	uint64_t cnt0wclr                     : 1;  /**< "Performance Counter 0 Write Clear.
+                                                         If this bit is set, CSR writes to the HNA_PFC0_CNT
+                                                         will clear the count value.
+                                                         If this bit is clear, CSR writes to the HNA_PFC0_CNT
+                                                         will continue the count from the written value." */
+	uint64_t cnt3ena                      : 1;  /**< "Performance Counter 3 Enable.
+                                                         When this bit is set, the performance counter \#3
+                                                         is enabled." */
+	uint64_t cnt2ena                      : 1;  /**< "Performance Counter 2 Enable.
+                                                         When this bit is set, the performance counter \#2
+                                                         is enabled." */
+	uint64_t cnt1ena                      : 1;  /**< "Performance Counter 1 Enable.
+                                                         When this bit is set, the performance counter \#1
+                                                         is enabled." */
+	uint64_t cnt0ena                      : 1;  /**< "Performance Counter 0 Enable.
+                                                         When this bit is set, the performance counter \#0
+                                                         is enabled." */
+#else
+	uint64_t cnt0ena                      : 1;
+	uint64_t cnt1ena                      : 1;
+	uint64_t cnt2ena                      : 1;
+	uint64_t cnt3ena                      : 1;
+	uint64_t cnt0wclr                     : 1;
+	uint64_t cnt1wclr                     : 1;
+	uint64_t cnt2wclr                     : 1;
+	uint64_t cnt3wclr                     : 1;
+	uint64_t cnt0rclr                     : 1;
+	uint64_t cnt1rclr                     : 1;
+	uint64_t cnt2rclr                     : 1;
+	uint64_t cnt3rclr                     : 1;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} s;
+	struct cvmx_hna_pfc_gctl_s            cn78xx;
+};
+typedef union cvmx_hna_pfc_gctl cvmx_hna_pfc_gctl_t;
+
+/**
+ * cvmx_hna_sbd_dbg0
+ *
+ * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
+ * are locked down. Otherwise, the contents of this register are the 'active' contents of the
+ * HNA Scoreboard at the time of the CSR read.
+ * INTERNAL: VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the
+ * behavioral
+ * model) on the reads unless the HPU Engine specified by HNA_CONTROL[SBDNUM] has previously been
+ * assigned an instruction.
+ */
+union cvmx_hna_sbd_dbg0 {
+	uint64_t u64;
+	struct cvmx_hna_sbd_dbg0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t sbd                          : 64; /**< "HNA ScoreBoard 0 Data.
+                                                         [63:38]   (26) rptr[28:3]: Result Base Pointer (QW-aligned)
+                                                         [37:22]   (16) Cumulative Result Write Counter (for HDR write)
+                                                         [21]       (1) Waiting for GRdRsp EOT
+                                                         [20]       (1) Waiting for GRdReq Issue (to NRQ)
+                                                         [19]       (1) GLPTR/GLCNT Valid
+                                                         [18]       (1) Completion Mark Detected
+                                                         [17:15]    (3) Completion Code [0=PDGONE/1=PERR/2=RFULL/3=TERM]
+                                                         [14]       (1) Completion Detected
+                                                         [13]       (1) Waiting for HDR RWrCmtRsp
+                                                         [12]       (1) Waiting for LAST RESULT RWrCmtRsp
+                                                         [11]       (1) Waiting for HDR RWrReq
+                                                         [10]        (1) Waiting for RWrReq
+                                                         [9]        (1) Waiting for WQWrReq issue
+                                                         [8]        (1) Waiting for PRdRsp EOT
+                                                         [7]        (1) Waiting for PRdReq Issue (to NRQ)
+                                                         [6]        (1) Packet Data Valid
+                                                         [5]        (1) WQVLD
+                                                         [4]        (1) WQ Done Point (either WQWrReq issued (for WQPTR<>0) OR HDR RWrCmtRsp)
+                                                         [3]        (1) Resultant write STF/P Mode
+                                                         [2]        (1) Packet Data LDT mode
+                                                         [1]        (1) Gather Mode
+                                                         [0]        (1) Valid" */
+#else
+	uint64_t sbd                          : 64;
+#endif
+	} s;
+	struct cvmx_hna_sbd_dbg0_s            cn78xx;
+};
+typedef union cvmx_hna_sbd_dbg0 cvmx_hna_sbd_dbg0_t;
+
+/**
+ * cvmx_hna_sbd_dbg1
+ *
+ * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
+ * are locked down. Otherwise, the contents of this register are the 'active' contents of the
+ * HNA Scoreboard at the time of the CSR read.
+ * INTERNAL: VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the
+ * behavioral
+ * model) on the reads unless the HPU Engine specified by HNA_CONTROL[SBDNUM] has previously been
+ * assigned an instruction.
+ */
+union cvmx_hna_sbd_dbg1 {
+	uint64_t u64;
+	struct cvmx_hna_sbd_dbg1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t sbd                          : 64; /**< "HNA ScoreBoard 1 Data.
+                                                         [63:56]   (8) UNUSED
+                                                         [55:16]  (40) Packet Data Pointer
+                                                         [15:0]   (16) Packet Data Counter" */
+#else
+	uint64_t sbd                          : 64;
+#endif
+	} s;
+	struct cvmx_hna_sbd_dbg1_s            cn78xx;
+};
+typedef union cvmx_hna_sbd_dbg1 cvmx_hna_sbd_dbg1_t;
+
+/**
+ * cvmx_hna_sbd_dbg2
+ *
+ * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
+ * are locked down. Otherwise, the contents of this register are the 'active' contents of the
+ * HNA Scoreboard at the time of the CSR read.
+ * INTERNAL: VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the
+ * behavioral
+ * model) on the reads unless the HPU Engine specified by HNA_CONTROL[SBDNUM] has previously been
+ * assigned an instruction.
+ */
+union cvmx_hna_sbd_dbg2 {
+	uint64_t u64;
+	struct cvmx_hna_sbd_dbg2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t sbd                          : 64; /**< "HNA ScoreBoard 2 Data.
+                                                         [63:45] (19) UNUSED
+                                                         [44:42]  (3) Instruction Type
+                                                         [41:5]  (37) rwptr[39:3]: Result Write Pointer
+                                                         [4:0]    (5) prwcnt[4:0]: Pending Result Write Counter" */
+#else
+	uint64_t sbd                          : 64;
+#endif
+	} s;
+	struct cvmx_hna_sbd_dbg2_s            cn78xx;
+};
+typedef union cvmx_hna_sbd_dbg2 cvmx_hna_sbd_dbg2_t;
+
+/**
+ * cvmx_hna_sbd_dbg3
+ *
+ * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
+ * are locked down. Otherwise, the contents of this register are the 'active' contents of the
+ * HNA Scoreboard at the time of the CSR read.
+ * INTERNAL: VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the
+ * behavioral
+ * model) on the reads unless the HPU Engine specified by HNA_CONTROL[SBDNUM] has previously been
+ * assigned an instruction.
+ */
+union cvmx_hna_sbd_dbg3 {
+	uint64_t u64;
+	struct cvmx_hna_sbd_dbg3_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t sbd                          : 64; /**< "HNA ScoreBoard 3 Data.
+                                                         [63:52] (11) rptr[39:29]: Result Base Pointer (QW-aligned)
+                                                         [52:16] (37) glptr[39:3]: Gather List Pointer
+                                                         [15:0]  (16) glcnt Gather List Counter" */
 #else
-	uint64_t hidat                        : 64;
+	uint64_t sbd                          : 64;
 #endif
 	} s;
-	struct cvmx_hna_memhidat_s            cn78xx;
+	struct cvmx_hna_sbd_dbg3_s            cn78xx;
 };
-typedef union cvmx_hna_memhidat cvmx_hna_memhidat_t;
+typedef union cvmx_hna_sbd_dbg3 cvmx_hna_sbd_dbg3_t;
 
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-ila-defs.h b/arch/mips/include/asm/octeon/cvmx-ila-defs.h
index cae55b7..efed1f5 100644
--- a/arch/mips/include/asm/octeon/cvmx-ila-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ila-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -78,34 +78,34 @@ static inline uint64_t CVMX_ILA_GBL_CFG_FUNC(void)
 static inline uint64_t CVMX_ILA_LNEX_TRN_CTL(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 15)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 7)))))
 		cvmx_warn("CVMX_ILA_LNEX_TRN_CTL(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011800170380F0ull) + ((offset) & 15) * 1024;
+	return CVMX_ADD_IO_SEG(0x00011800170380F0ull) + ((offset) & 7) * 1024;
 }
 #else
-#define CVMX_ILA_LNEX_TRN_CTL(offset) (CVMX_ADD_IO_SEG(0x00011800170380F0ull) + ((offset) & 15) * 1024)
+#define CVMX_ILA_LNEX_TRN_CTL(offset) (CVMX_ADD_IO_SEG(0x00011800170380F0ull) + ((offset) & 7) * 1024)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_ILA_LNEX_TRN_LD(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 15)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 7)))))
 		cvmx_warn("CVMX_ILA_LNEX_TRN_LD(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011800170380E0ull) + ((offset) & 15) * 1024;
+	return CVMX_ADD_IO_SEG(0x00011800170380E0ull) + ((offset) & 7) * 1024;
 }
 #else
-#define CVMX_ILA_LNEX_TRN_LD(offset) (CVMX_ADD_IO_SEG(0x00011800170380E0ull) + ((offset) & 15) * 1024)
+#define CVMX_ILA_LNEX_TRN_LD(offset) (CVMX_ADD_IO_SEG(0x00011800170380E0ull) + ((offset) & 7) * 1024)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_ILA_LNEX_TRN_LP(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 15)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 7)))))
 		cvmx_warn("CVMX_ILA_LNEX_TRN_LP(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011800170380E8ull) + ((offset) & 15) * 1024;
+	return CVMX_ADD_IO_SEG(0x00011800170380E8ull) + ((offset) & 7) * 1024;
 }
 #else
-#define CVMX_ILA_LNEX_TRN_LP(offset) (CVMX_ADD_IO_SEG(0x00011800170380E8ull) + ((offset) & 15) * 1024)
+#define CVMX_ILA_LNEX_TRN_LP(offset) (CVMX_ADD_IO_SEG(0x00011800170380E8ull) + ((offset) & 7) * 1024)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_ILA_LNE_DBG CVMX_ILA_LNE_DBG_FUNC()
@@ -350,6 +350,17 @@ static inline uint64_t CVMX_ILA_RX_LNEX_STAT1(unsigned long offset)
 #define CVMX_ILA_RX_LNEX_STAT1(offset) (CVMX_ADD_IO_SEG(0x0001180017038020ull) + ((offset) & 7) * 1024)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_ILA_RX_LNEX_STAT10(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 7)))))
+		cvmx_warn("CVMX_ILA_RX_LNEX_STAT10(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001180017038068ull) + ((offset) & 7) * 1024;
+}
+#else
+#define CVMX_ILA_RX_LNEX_STAT10(offset) (CVMX_ADD_IO_SEG(0x0001180017038068ull) + ((offset) & 7) * 1024)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_ILA_RX_LNEX_STAT2(unsigned long offset)
 {
 	if (!(
@@ -743,7 +754,7 @@ union cvmx_ila_rxx_byte_cntx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_40_63               : 24;
 	uint64_t rx_bytes                     : 40; /**< Indicates the number of bytes received per channel. Wraps on overflow. On overflow, sets
-                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t rx_bytes                     : 40;
 	uint64_t reserved_40_63               : 24;
@@ -919,7 +930,7 @@ union cvmx_ila_rxx_pkt_cntx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
 	uint64_t rx_pkt                       : 34; /**< Indicates the number of packets received per channel. Wraps on overflow. On overflow, sets
-                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t rx_pkt                       : 34;
 	uint64_t reserved_34_63               : 30;
@@ -939,7 +950,7 @@ union cvmx_ila_rxx_stat0 {
 	uint64_t reserved_33_63               : 31;
 	uint64_t crc24_match_cnt              : 33; /**< Indicates the number of CRC24 matches received. Wraps on overflow if
                                                          ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On overflow/saturate, sets
-                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t crc24_match_cnt              : 33;
 	uint64_t reserved_33_63               : 31;
@@ -959,7 +970,7 @@ union cvmx_ila_rxx_stat1 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t crc24_err_cnt                : 18; /**< Indicates the number of bursts with a detected CRC error. Wraps on overflow if
                                                          ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On overflow/saturate, sets
-                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t crc24_err_cnt                : 18;
 	uint64_t reserved_18_63               : 46;
@@ -979,11 +990,11 @@ union cvmx_ila_rxx_stat2 {
 	uint64_t reserved_48_63               : 16;
 	uint64_t brst_not_full_cnt            : 16; /**< Indicates the number of bursts received that terminated without an EOP and contained fewer
                                                          than BurstMax words. Wraps on overflow if ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise,
-                                                         saturates. On overflow/saturate, sets ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates. On overflow/saturate, sets ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 	uint64_t reserved_28_31               : 4;
 	uint64_t brst_cnt                     : 28; /**< Indicates the number of bursts correctly received (i.e. good CRC24, not in violation of
                                                          BurstMax or BurstShort). Wraps on overflow if ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise,
-                                                         saturates. On overflow/saturate, sets ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates. On overflow/saturate, sets ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t brst_cnt                     : 28;
 	uint64_t reserved_28_31               : 4;
@@ -1005,7 +1016,7 @@ union cvmx_ila_rxx_stat3 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t brst_max_err_cnt             : 16; /**< Indicates the number of bursts received longer than the BurstMax parameter. Wraps on
                                                          overflow if ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On overflow/saturate,
-                                                         sets ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         sets ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t brst_max_err_cnt             : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1025,7 +1036,7 @@ union cvmx_ila_rxx_stat4 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t brst_shrt_err_cnt            : 16; /**< Indicates the number of bursts received that violate the BurstShort parameter. Wraps on
                                                          overflow if ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On overflow/saturate,
-                                                         sets ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         sets ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t brst_shrt_err_cnt            : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1045,7 +1056,7 @@ union cvmx_ila_rxx_stat5 {
 	uint64_t reserved_23_63               : 41;
 	uint64_t align_cnt                    : 23; /**< Indicates the number of alignment sequences received (i.e. those that do not violate the
                                                          current alignment). Wraps on overflow if ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise,
-                                                         saturates. On overflow/saturate, sets ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates. On overflow/saturate, sets ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t align_cnt                    : 23;
 	uint64_t reserved_23_63               : 41;
@@ -1065,7 +1076,7 @@ union cvmx_ila_rxx_stat6 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t align_err_cnt                : 16; /**< Indicates the number of alignment sequences received in error (i.e. those that violate the
                                                          current alignment). Wraps on overflow if ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise,
-                                                         saturates. On overflow/saturate, sets ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates. On overflow/saturate, sets ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t align_err_cnt                : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1085,7 +1096,7 @@ union cvmx_ila_rxx_stat7 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t bad_64b67b_cnt               : 16; /**< Indicates the number of bad 64B/67B code words. Wraps on overflow if
                                                          ILA_RX(0)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On overflow/saturate, sets
-                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t bad_64b67b_cnt               : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1145,7 +1156,8 @@ union cvmx_ila_rx_lnex_cfg {
                                                          destripped.
                                                          If the lane is in internal loopback mode, this field is ignored and skip words are always
                                                          discarded in the lane logic. */
-	uint64_t reserved_6_7                 : 2;
+	uint64_t reserved_7_7                 : 1;
+	uint64_t rx_dis_disp_chk              : 1;  /**< Disable the RX disparity check, see ILA_RX_LNE(0..7)_INT[DISP_ERR]. */
 	uint64_t rx_scrm_sync                 : 1;  /**< RX scrambler-synchronization status. A 1 means synchronization has been achieved. */
 	uint64_t rx_bdry_sync                 : 1;  /**< RX word-boundary-synchronization status. A 1 means synchronization has been achieved */
 	uint64_t rx_dis_ukwn                  : 1;  /**< Disable normal response to unknown words. Unknown words are still logged but do not cause
@@ -1161,7 +1173,8 @@ union cvmx_ila_rx_lnex_cfg {
 	uint64_t rx_dis_ukwn                  : 1;
 	uint64_t rx_bdry_sync                 : 1;
 	uint64_t rx_scrm_sync                 : 1;
-	uint64_t reserved_6_7                 : 2;
+	uint64_t rx_dis_disp_chk              : 1;
+	uint64_t reserved_7_7                 : 1;
 	uint64_t rx_dis_psh_skip              : 1;
 	uint64_t reserved_9_63                : 55;
 #endif
@@ -1177,7 +1190,8 @@ union cvmx_ila_rx_lnex_int {
 	uint64_t u64;
 	struct cvmx_ila_rx_lnex_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
+	uint64_t reserved_10_63               : 54;
+	uint64_t disp_err                     : 1;  /**< RX disparity error encountered. Throws ILA_INTSN_E::ILA_RXLNE(0..7)_DISP_ERR. */
 	uint64_t bad_64b67b                   : 1;  /**< Bad 64B/67B code word encountered. Once the bad word reaches the burst-control unit (as
                                                          indicated by ILA_RX(0)_INT[LANE_BAD_WORD]) it is discarded and all open packets receive an
                                                          error. Throws ILA_INTSN_E::ILA_RXLNE(0..7)_BAD_64B67B. */
@@ -1203,7 +1217,8 @@ union cvmx_ila_rx_lnex_int {
 	uint64_t stat_msg                     : 1;
 	uint64_t stat_cnt_ovfl                : 1;
 	uint64_t bad_64b67b                   : 1;
-	uint64_t reserved_9_63                : 55;
+	uint64_t disp_err                     : 1;
+	uint64_t reserved_10_63               : 54;
 #endif
 	} s;
 	struct cvmx_ila_rx_lnex_int_s         cn78xx;
@@ -1219,7 +1234,7 @@ union cvmx_ila_rx_lnex_stat0 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t ser_lock_loss_cnt            : 18; /**< Indicates the number of times the lane lost clock-data-recovery. On overflow, saturates
-                                                         and sets ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         and sets ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t ser_lock_loss_cnt            : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1238,7 +1253,7 @@ union cvmx_ila_rx_lnex_stat1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t bdry_sync_loss_cnt           : 18; /**< Indicates the number of times a lane lost word-boundary synchronization. On overflow,
-                                                         saturates and sets ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates and sets ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t bdry_sync_loss_cnt           : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1249,6 +1264,30 @@ union cvmx_ila_rx_lnex_stat1 {
 typedef union cvmx_ila_rx_lnex_stat1 cvmx_ila_rx_lnex_stat1_t;
 
 /**
+ * cvmx_ila_rx_lne#_stat10
+ */
+union cvmx_ila_rx_lnex_stat10 {
+	uint64_t u64;
+	struct cvmx_ila_rx_lnex_stat10_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_43_63               : 21;
+	uint64_t prbs_bad                     : 11; /**< Indicates the number of training frames with bad PRBS. On overflow, saturates and sets
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
+	uint64_t reserved_11_31               : 21;
+	uint64_t prbs_good                    : 11; /**< Indicates the number of training frames with correct PRBS. On overflow, saturates and sets
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
+#else
+	uint64_t prbs_good                    : 11;
+	uint64_t reserved_11_31               : 21;
+	uint64_t prbs_bad                     : 11;
+	uint64_t reserved_43_63               : 21;
+#endif
+	} s;
+	struct cvmx_ila_rx_lnex_stat10_s      cn78xx;
+};
+typedef union cvmx_ila_rx_lnex_stat10 cvmx_ila_rx_lnex_stat10_t;
+
+/**
  * cvmx_ila_rx_lne#_stat2
  */
 union cvmx_ila_rx_lnex_stat2 {
@@ -1257,10 +1296,10 @@ union cvmx_ila_rx_lnex_stat2 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_50_63               : 14;
 	uint64_t syncw_good_cnt               : 18; /**< Indicates the number of good synchronization words. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 	uint64_t reserved_18_31               : 14;
 	uint64_t syncw_bad_cnt                : 18; /**< Indicates the number of bad synchronization words. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t syncw_bad_cnt                : 18;
 	uint64_t reserved_18_31               : 14;
@@ -1281,7 +1320,7 @@ union cvmx_ila_rx_lnex_stat3 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t bad_64b67b_cnt               : 18; /**< Indicates the number of bad 64B/67B words, meaning bit <65> or bit <64> has been
-                                                         corrupted. On overflow, saturates and sets ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         corrupted. On overflow, saturates and sets ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t bad_64b67b_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1300,10 +1339,10 @@ union cvmx_ila_rx_lnex_stat4 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_59_63               : 5;
 	uint64_t cntl_word_cnt                : 27; /**< Indicates the number of control words received. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 	uint64_t reserved_27_31               : 5;
 	uint64_t data_word_cnt                : 27; /**< Indicates the number of data words received. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t data_word_cnt                : 27;
 	uint64_t reserved_27_31               : 5;
@@ -1324,7 +1363,7 @@ union cvmx_ila_rx_lnex_stat5 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t unkwn_word_cnt               : 18; /**< Indicates the number of unknown control words. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t unkwn_word_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1344,7 +1383,7 @@ union cvmx_ila_rx_lnex_stat6 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t scrm_sync_loss_cnt           : 18; /**< Indicates the number of times scrambler synchronization was lost (due to either four
                                                          consecutive bad sync words or three consecutive scrambler-state mismatches). On overflow,
-                                                         saturates and sets ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates and sets ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t scrm_sync_loss_cnt           : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1363,7 +1402,7 @@ union cvmx_ila_rx_lnex_stat7 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t scrm_match_cnt               : 18; /**< Indicates the number of scrambler-state matches received. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t scrm_match_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1382,7 +1421,7 @@ union cvmx_ila_rx_lnex_stat8 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t skipw_good_cnt               : 18; /**< Indicates the number of good skip words. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t skipw_good_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1401,10 +1440,10 @@ union cvmx_ila_rx_lnex_stat9 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_50_63               : 14;
 	uint64_t crc32_err_cnt                : 18; /**< Indicates the number of errors in the lane CRC. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 	uint64_t reserved_27_31               : 5;
 	uint64_t crc32_match_cnt              : 27; /**< Indicates the number of CRC32 matches received. On overflow, saturates and sets
-                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_RX_LNE(0..7)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t crc32_match_cnt              : 27;
 	uint64_t reserved_27_31               : 5;
@@ -1461,7 +1500,7 @@ union cvmx_ila_txx_byte_cntx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_40_63               : 24;
 	uint64_t tx_bytes                     : 40; /**< Number of bytes transmitted per channel. Wraps on overflow. On overflow, sets
-                                                         ILA_TX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_TX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t tx_bytes                     : 40;
 	uint64_t reserved_40_63               : 24;
@@ -1540,12 +1579,12 @@ union cvmx_ila_txx_cfg1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_44_63               : 20;
 	uint64_t txf_byp_dis                  : 1;  /**< TX-FIFO bypass disable. */
-	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes. SER_LIMIT must be
-                                                         set as follows:
-                                                         SER_LIMIT >= (((17 + NUM_LANES) * (BAUD/SCLK/20) + 4) * 20
+	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes. If 0x0, hardware
+                                                         will compute it. Otherwise, SER_LIMIT must be set as follows:
+                                                         SER_LIMIT >= 148 + (BAUD / SCLK) * (12 + NUM_LANES)
                                                          For instance, for SCLK=1.1GHz,BAUD=10.3125,NUM_LANES=8:
-                                                         SER_LIMIT >= (((17 + 8) * (10.3125/1.1/20) + 4) * 20
-                                                         SER_LIMIT >= 314 */
+                                                         SER_LIMIT >= 148 + (10.3125 / 1.1 * (12+ 8))
+                                                         SER_LIMIT >= 336 */
 	uint64_t pkt_busy                     : 1;  /**< TX-link is transmitting data. */
 	uint64_t reserved_26_31               : 6;
 	uint64_t skip_cnt                     : 4;  /**< Number of skip words to insert after the scrambler state. */
@@ -1678,7 +1717,7 @@ union cvmx_ila_txx_pkt_cntx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
 	uint64_t tx_pkt                       : 28; /**< Number of packets transmitted per channel. Wraps on overflow. On overflow, sets
-                                                         ILA_TX(0)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILA_TX(0)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t tx_pkt                       : 28;
 	uint64_t reserved_28_63               : 36;
@@ -1696,7 +1735,7 @@ union cvmx_ila_txx_rmatch {
 	struct cvmx_ila_txx_rmatch_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_50_63               : 14;
-	uint64_t grnlrty                      : 2;  /**< Granularity of a token, where 1 token equal (1<<GRNLRTY) bytes. */
+	uint64_t grnlrty                      : 2;  /**< Reserved. */
 	uint64_t brst_limit                   : 16; /**< Size of token bucket, also the maximum quantity of data that can be burst across the
                                                          interface before invoking rate-limiting logic. */
 	uint64_t time_limit                   : 16; /**< Number of cycles per time interval. Must be >= 4. */
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
index 0420bfa..57a7089 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -622,6 +622,17 @@ static inline uint64_t CVMX_ILK_RX_LNEX_STAT1(unsigned long offset)
 #define CVMX_ILK_RX_LNEX_STAT1(offset) (CVMX_ADD_IO_SEG(0x0001180014038020ull) + ((offset) & 15) * 1024)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_ILK_RX_LNEX_STAT10(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 15)))))
+		cvmx_warn("CVMX_ILK_RX_LNEX_STAT10(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001180014038068ull) + ((offset) & 15) * 1024;
+}
+#else
+#define CVMX_ILK_RX_LNEX_STAT10(offset) (CVMX_ADD_IO_SEG(0x0001180014038068ull) + ((offset) & 15) * 1024)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_ILK_RX_LNEX_STAT2(unsigned long offset)
 {
 	if (!(
@@ -1830,7 +1841,7 @@ union cvmx_ilk_rxx_byte_cntx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_40_63               : 24;
 	uint64_t rx_bytes                     : 40; /**< Number of bytes received per channel. Wraps on overflow. On overflow, sets
-                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t rx_bytes                     : 40;
 	uint64_t reserved_40_63               : 24;
@@ -1894,7 +1905,7 @@ union cvmx_ilk_rxx_cfg0 {
                                                          Supported range:
                                                          ILK_RX(0..1)_CFG1[SKIP_CNT] + 32 < MFRM_LEN <= 4096 */
 	uint64_t brst_shrt                    : 7;  /**< Minimum interval between burst control words, as a multiple of eight bytes. Supported
-                                                         range from 8 to 512 bytes (i.e. 0 < BRST_SHRT <= 64).
+                                                         range from 8 to 512 bytes (i.e. 4 <= BRST_SHRT <= 64).
                                                          This field affects the ILK_RX(0..1)_STAT4[BRST_SHRT_ERR_CNT] counter. It does not affect
                                                          correct operation of the link. */
 	uint64_t lane_rev                     : 1;  /**< Lane reversal. When enabled, lane destriping is performed from most-significant lane
@@ -2934,7 +2945,7 @@ union cvmx_ilk_rxx_pkt_cntx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
 	uint64_t rx_pkt                       : 34; /**< Number of packets received per channel. Wraps on overflow. On overflow, sets
-                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t rx_pkt                       : 34;
 	uint64_t reserved_34_63               : 30;
@@ -2990,7 +3001,7 @@ union cvmx_ilk_rxx_stat0 {
 	uint64_t reserved_35_63               : 29;
 	uint64_t crc24_match_cnt              : 35; /**< Indicates the number of CRC24 matches received. Wraps on overflow if
                                                          ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On overflow/saturate, sets
-                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t crc24_match_cnt              : 35;
 	uint64_t reserved_35_63               : 29;
@@ -3030,7 +3041,7 @@ union cvmx_ilk_rxx_stat1 {
 	uint64_t reserved_20_63               : 44;
 	uint64_t crc24_err_cnt                : 20; /**< Indicates the number of bursts with a detected CRC error. Wraps on overflow if
                                                          ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On overflow/saturate, sets
-                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t crc24_err_cnt                : 20;
 	uint64_t reserved_20_63               : 44;
@@ -3061,11 +3072,11 @@ union cvmx_ilk_rxx_stat2 {
 	uint64_t reserved_50_63               : 14;
 	uint64_t brst_not_full_cnt            : 18; /**< Indicates the number of bursts received that terminated without an EOP and contained fewer
                                                          than BurstMax words. Wraps on overflow if ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1. Otherwise,
-                                                         saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 	uint64_t reserved_30_31               : 2;
 	uint64_t brst_cnt                     : 30; /**< Indicates the number of bursts correctly received. (i.e. good CRC24, not in violation of
                                                          BurstMax or BurstShort). Wraps on overflow if ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1.
-                                                         Otherwise, saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         Otherwise, saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t brst_cnt                     : 30;
 	uint64_t reserved_30_31               : 2;
@@ -3119,7 +3130,7 @@ union cvmx_ilk_rxx_stat3 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t brst_max_err_cnt             : 18; /**< Indicates the number of bursts received longer than the BurstMax parameter. Wraps on
                                                          overflow if ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On
-                                                         overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t brst_max_err_cnt             : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3149,7 +3160,7 @@ union cvmx_ilk_rxx_stat4 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t brst_shrt_err_cnt            : 18; /**< Indicates the number of bursts received that violate the BurstShort parameter. Wraps on
                                                          overflow if ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On
-                                                         overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t brst_shrt_err_cnt            : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3181,7 +3192,7 @@ union cvmx_ilk_rxx_stat5 {
 	uint64_t reserved_25_63               : 39;
 	uint64_t align_cnt                    : 25; /**< Indicates the number of alignment sequences received (i.e. those that do not violate the
                                                          current alignment). Wraps on overflow if ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1. Otherwise,
-                                                         saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t align_cnt                    : 25;
 	uint64_t reserved_25_63               : 39;
@@ -3223,7 +3234,7 @@ union cvmx_ilk_rxx_stat6 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t align_err_cnt                : 18; /**< Indicates the number of alignment sequences received in error (i.e. those that violate the
                                                          current alignment). Wraps on overflow if ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1. Otherwise,
-                                                         saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t align_err_cnt                : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3255,7 +3266,7 @@ union cvmx_ilk_rxx_stat7 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t bad_64b67b_cnt               : 18; /**< Indicates the number of bad 64B/67B code words.Wraps on overflow if
                                                          ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1. Otherwise, saturates. On overflow/saturate, sets
-                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t bad_64b67b_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3286,10 +3297,10 @@ union cvmx_ilk_rxx_stat8 {
 	uint64_t reserved_32_63               : 32;
 	uint64_t pkt_drop_rid_cnt             : 16; /**< Indicates the number of packets dropped due to the lack of reassembly IDs or because
                                                          ILK_RX(0..1)_CFG1[PKT_ENA] = 0. Wraps on overflow if ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1.
-                                                         Otherwise, saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         Otherwise, saturates. On overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 	uint64_t pkt_drop_rxf_cnt             : 16; /**< Indicates the number of packets dropped due to RX_FIFO_CNT >= RX_FIFO_MAX. Wraps on
                                                          overflow if ILK_RX(0..1)_CFG0[LNK_STATS_WRAP]=1.Otherwise, saturates. On
-                                                         overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         overflow/saturate, sets ILK_RX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t pkt_drop_rxf_cnt             : 16;
 	uint64_t pkt_drop_rid_cnt             : 16;
@@ -3335,7 +3346,8 @@ union cvmx_ilk_rx_lnex_cfg {
                                                          destripped.
                                                          If the lane is in internal loopback mode, this field is ignored and skip words are always
                                                          discarded in the lane logic. */
-	uint64_t reserved_6_7                 : 2;
+	uint64_t reserved_7_7                 : 1;
+	uint64_t rx_dis_disp_chk              : 1;  /**< Disable the RX disparity check, see ILK_RX_LNE(0..15)_INT[DISP_ERR]. */
 	uint64_t rx_scrm_sync                 : 1;  /**< RX scrambler-synchronization status. A 1 means synchronization has been achieved. */
 	uint64_t rx_bdry_sync                 : 1;  /**< RX word-boundary-synchronization status. A 1 means synchronization has been achieved */
 	uint64_t rx_dis_ukwn                  : 1;  /**< Disable normal response to unknown words. Unknown words are still logged but do not cause
@@ -3351,12 +3363,49 @@ union cvmx_ilk_rx_lnex_cfg {
 	uint64_t rx_dis_ukwn                  : 1;
 	uint64_t rx_bdry_sync                 : 1;
 	uint64_t rx_scrm_sync                 : 1;
-	uint64_t reserved_6_7                 : 2;
+	uint64_t rx_dis_disp_chk              : 1;
+	uint64_t reserved_7_7                 : 1;
 	uint64_t rx_dis_psh_skip              : 1;
 	uint64_t reserved_9_63                : 55;
 #endif
 	} s;
-	struct cvmx_ilk_rx_lnex_cfg_s         cn68xx;
+	struct cvmx_ilk_rx_lnex_cfg_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_9_63                : 55;
+	uint64_t rx_dis_psh_skip              : 1;  /**< When RX_DIS_PSH_SKIP=0, skip words are de-stripped.
+                                                         When RX_DIS_PSH_SKIP=1, skip words are discarded in the lane
+                                                         logic.
+
+                                                         If the lane is in internal loopback mode, RX_DIS_PSH_SKIP
+                                                         is ignored and skip words are always discarded in the lane
+                                                         logic.
+
+                                                         ***NOTE: Added in pass 2.0 */
+	uint64_t reserved_6_7                 : 2;
+	uint64_t rx_scrm_sync                 : 1;  /**< Rx scrambler synchronization status
+                                                         '1' means synchronization achieved
+
+                                                         ***NOTE: Added in pass 2.0 */
+	uint64_t rx_bdry_sync                 : 1;  /**< Rx word boundary sync status
+                                                         '1' means synchronization achieved */
+	uint64_t rx_dis_ukwn                  : 1;  /**< Disable normal response to unknown words.  They are still
+                                                         logged but do not cause an error to all open channels. */
+	uint64_t rx_dis_scram                 : 1;  /**< Disable lane scrambler (debug) */
+	uint64_t stat_rdclr                   : 1;  /**< CSR read to ILK_RX_LNEx_STAT* clears the selected counter after
+                                                         returning its current value. */
+	uint64_t stat_ena                     : 1;  /**< Enable RX lane statistics counters */
+#else
+	uint64_t stat_ena                     : 1;
+	uint64_t stat_rdclr                   : 1;
+	uint64_t rx_dis_scram                 : 1;
+	uint64_t rx_dis_ukwn                  : 1;
+	uint64_t rx_bdry_sync                 : 1;
+	uint64_t rx_scrm_sync                 : 1;
+	uint64_t reserved_6_7                 : 2;
+	uint64_t rx_dis_psh_skip              : 1;
+	uint64_t reserved_9_63                : 55;
+#endif
+	} cn68xx;
 	struct cvmx_ilk_rx_lnex_cfg_cn68xxp1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
@@ -3388,7 +3437,8 @@ union cvmx_ilk_rx_lnex_int {
 	uint64_t u64;
 	struct cvmx_ilk_rx_lnex_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
+	uint64_t reserved_10_63               : 54;
+	uint64_t disp_err                     : 1;  /**< RX disparity error encountered. Throws ILK_INTSN_E::ILK_RXLNE(0..15)_DISP_ERR. */
 	uint64_t bad_64b67b                   : 1;  /**< Bad 64B/67B code word encountered. Once the bad word reaches the burst control unit (as
                                                          denoted by ILK_RX(0..1)_INT[LANE_BAD_WORD]) it is discarded and all open packets receive
                                                          an error. Throws ILK_INTSN_E::ILK_RXLNE(0..15)_BAD_64B67B. */
@@ -3414,11 +3464,43 @@ union cvmx_ilk_rx_lnex_int {
 	uint64_t stat_msg                     : 1;
 	uint64_t stat_cnt_ovfl                : 1;
 	uint64_t bad_64b67b                   : 1;
-	uint64_t reserved_9_63                : 55;
+	uint64_t disp_err                     : 1;
+	uint64_t reserved_10_63               : 54;
 #endif
 	} s;
-	struct cvmx_ilk_rx_lnex_int_s         cn68xx;
-	struct cvmx_ilk_rx_lnex_int_s         cn68xxp1;
+	struct cvmx_ilk_rx_lnex_int_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_9_63                : 55;
+	uint64_t bad_64b67b                   : 1;  /**< Bad 64B/67B codeword encountered.  Once the bad word reaches
+                                                         the burst control unit (as deonted by
+                                                         ILK_RXx_INT[LANE_BAD_WORD]) it will be tossed and all open
+                                                         packets will receive an error. */
+	uint64_t stat_cnt_ovfl                : 1;  /**< Rx lane statistic counter overflow */
+	uint64_t stat_msg                     : 1;  /**< Status bits for the link or a lane transitioned from a '1'
+                                                         (healthy) to a '0' (problem) */
+	uint64_t dskew_fifo_ovfl              : 1;  /**< Rx deskew fifo overflow occurred. */
+	uint64_t scrm_sync_loss               : 1;  /**< 4 consecutive bad sync words or 3 consecutive scramble state
+                                                         mismatches */
+	uint64_t ukwn_cntl_word               : 1;  /**< Unknown framing control word. Block type does not match any of
+                                                         (SYNC,SCRAM,SKIP,DIAG) */
+	uint64_t crc32_err                    : 1;  /**< Diagnostic CRC32 errors */
+	uint64_t bdry_sync_loss               : 1;  /**< Rx logic loses word boundary sync (16 tries).  Hardware will
+                                                         automatically attempt to regain word boundary sync */
+	uint64_t serdes_lock_loss             : 1;  /**< Rx SERDES loses lock */
+#else
+	uint64_t serdes_lock_loss             : 1;
+	uint64_t bdry_sync_loss               : 1;
+	uint64_t crc32_err                    : 1;
+	uint64_t ukwn_cntl_word               : 1;
+	uint64_t scrm_sync_loss               : 1;
+	uint64_t dskew_fifo_ovfl              : 1;
+	uint64_t stat_msg                     : 1;
+	uint64_t stat_cnt_ovfl                : 1;
+	uint64_t bad_64b67b                   : 1;
+	uint64_t reserved_9_63                : 55;
+#endif
+	} cn68xx;
+	struct cvmx_ilk_rx_lnex_int_cn68xx    cn68xxp1;
 	struct cvmx_ilk_rx_lnex_int_s         cn78xx;
 };
 typedef union cvmx_ilk_rx_lnex_int cvmx_ilk_rx_lnex_int_t;
@@ -3474,7 +3556,7 @@ union cvmx_ilk_rx_lnex_stat0 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t ser_lock_loss_cnt            : 18; /**< Indicates the number of times the lane lost clock-data-recovery. On overflow, saturates
-                                                         and sets ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         and sets ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t ser_lock_loss_cnt            : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3495,7 +3577,7 @@ union cvmx_ilk_rx_lnex_stat1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t bdry_sync_loss_cnt           : 18; /**< Indicates the number of times a lane lost word-boundary synchronization. On overflow,
-                                                         saturates and sets ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates and sets ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t bdry_sync_loss_cnt           : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3508,6 +3590,30 @@ union cvmx_ilk_rx_lnex_stat1 {
 typedef union cvmx_ilk_rx_lnex_stat1 cvmx_ilk_rx_lnex_stat1_t;
 
 /**
+ * cvmx_ilk_rx_lne#_stat10
+ */
+union cvmx_ilk_rx_lnex_stat10 {
+	uint64_t u64;
+	struct cvmx_ilk_rx_lnex_stat10_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_43_63               : 21;
+	uint64_t prbs_bad                     : 11; /**< Indicates the number of training frames with bad PRBS. On overflow, saturates and sets
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
+	uint64_t reserved_11_31               : 21;
+	uint64_t prbs_good                    : 11; /**< Indicates the number of training frames with correct PRBS. On overflow, saturates and sets
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
+#else
+	uint64_t prbs_good                    : 11;
+	uint64_t reserved_11_31               : 21;
+	uint64_t prbs_bad                     : 11;
+	uint64_t reserved_43_63               : 21;
+#endif
+	} s;
+	struct cvmx_ilk_rx_lnex_stat10_s      cn78xx;
+};
+typedef union cvmx_ilk_rx_lnex_stat10 cvmx_ilk_rx_lnex_stat10_t;
+
+/**
  * cvmx_ilk_rx_lne#_stat2
  */
 union cvmx_ilk_rx_lnex_stat2 {
@@ -3516,10 +3622,10 @@ union cvmx_ilk_rx_lnex_stat2 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_50_63               : 14;
 	uint64_t syncw_good_cnt               : 18; /**< Indicates the number of good synchronization words. On overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 	uint64_t reserved_18_31               : 14;
 	uint64_t syncw_bad_cnt                : 18; /**< Indicates the number of bad synchronization words. On overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t syncw_bad_cnt                : 18;
 	uint64_t reserved_18_31               : 14;
@@ -3542,7 +3648,7 @@ union cvmx_ilk_rx_lnex_stat3 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t bad_64b67b_cnt               : 18; /**< Indicates the number of bad 64B/67B words, meaning bit <65> or bit <64> has been
-                                                         corrupted. On overflow, saturates and sets ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         corrupted. On overflow, saturates and sets ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t bad_64b67b_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3563,10 +3669,10 @@ union cvmx_ilk_rx_lnex_stat4 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_59_63               : 5;
 	uint64_t cntl_word_cnt                : 27; /**< Indicates the number of control words received. SOn overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 	uint64_t reserved_27_31               : 5;
 	uint64_t data_word_cnt                : 27; /**< Indicates the number of data words received. On overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t data_word_cnt                : 27;
 	uint64_t reserved_27_31               : 5;
@@ -3589,7 +3695,7 @@ union cvmx_ilk_rx_lnex_stat5 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t unkwn_word_cnt               : 18; /**< Indicates the number of unknown control words.On overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t unkwn_word_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3611,7 +3717,7 @@ union cvmx_ilk_rx_lnex_stat6 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t scrm_sync_loss_cnt           : 18; /**< Indicates the number of times scrambler synchronization was lost (due to either four
                                                          consecutive bad sync words or three consecutive scrambler-state mismatches). On overflow,
-                                                         saturates and sets ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         saturates and sets ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t scrm_sync_loss_cnt           : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3632,7 +3738,7 @@ union cvmx_ilk_rx_lnex_stat7 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t scrm_match_cnt               : 18; /**< Indicates the number of scrambler-state matches received. On overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t scrm_match_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3653,7 +3759,7 @@ union cvmx_ilk_rx_lnex_stat8 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t skipw_good_cnt               : 18; /**< Indicates the number of good skip words. On overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t skipw_good_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -3674,10 +3780,10 @@ union cvmx_ilk_rx_lnex_stat9 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_50_63               : 14;
 	uint64_t crc32_err_cnt                : 18; /**< Indicates the number of errors in the lane CRC. On overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 	uint64_t reserved_27_31               : 5;
 	uint64_t crc32_match_cnt              : 27; /**< Indicates the number of CRC32 matches received. On overflow, saturates and sets
-                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_RX_LNE(0..15)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t crc32_match_cnt              : 27;
 	uint64_t reserved_27_31               : 5;
@@ -3842,7 +3948,7 @@ union cvmx_ilk_txx_byte_cntx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_40_63               : 24;
 	uint64_t tx_bytes                     : 40; /**< Number of bytes transmitted per channel. Wraps on overflow. On overflow, sets
-                                                         ILK_TX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_TX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t tx_bytes                     : 40;
 	uint64_t reserved_40_63               : 24;
@@ -4071,12 +4177,17 @@ union cvmx_ilk_txx_cfg1 {
 	uint64_t u64;
 	struct cvmx_ilk_txx_cfg1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_43_63               : 21;
-	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes.
-                                                         SER_LIMIT >= (((17 + NUM_LANES) * (BAUD/SCLK/20)) + 4) * 20.
+	uint64_t reserved_53_63               : 11;
+	uint64_t brst_min                     : 5;  /**< Minimum size of a data burst, as a multiple of 32-byte blocks. 0 disables the scheduling
+                                                         enhancement. When non-zero, must satisfy:
+                                                         (BRST_SHRT*8) <= (BRST_MIN*32) <= (BRST_MAX*64)/2. */
+	uint64_t reserved_43_47               : 5;
+	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes. If 0x0, hardware
+                                                         will compute it. Otherwise, SER_LIMIT must be set as follows:
+                                                         SER_LIMIT >= 148 + (BAUD / SCLK) * (12 + (NUM_LANES/2))
                                                          For instance, for sclk=1.1GHz,BAUD=10.3125,NUM_LANES=16 :
-                                                         SER_LIMIT >= (((17+16)*(10.3125/1.1/20))+4)*20
-                                                         SER_LIMIT >= 390 */
+                                                         SER_LIMIT >= 148 + (10.3125 / 1.1 * (12 + (12/2))
+                                                         SER_LIMIT >= 317 */
 	uint64_t pkt_busy                     : 1;  /**< Packet busy. When set to 1, indicates the TX-link is transmitting data. */
 	uint64_t pipe_crd_dis                 : 1;  /**< Disable channel credits. Should be set to 1 when PKO is configured to ignore channel credits. */
 	uint64_t ptp_delay                    : 5;  /**< Reserved. */
@@ -4116,7 +4227,9 @@ union cvmx_ilk_txx_cfg1 {
 	uint64_t pipe_crd_dis                 : 1;
 	uint64_t pkt_busy                     : 1;
 	uint64_t ser_limit                    : 10;
-	uint64_t reserved_43_63               : 21;
+	uint64_t reserved_43_47               : 5;
+	uint64_t brst_min                     : 5;
+	uint64_t reserved_53_63               : 11;
 #endif
 	} s;
 	struct cvmx_ilk_txx_cfg1_cn68xx {
@@ -4807,7 +4920,7 @@ union cvmx_ilk_txx_pkt_cntx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
 	uint64_t tx_pkt                       : 34; /**< Number of packets transmitted per channel. Wraps on overflow. On overflow, sets
-                                                         ILK_TX(0..1)_INT[STAT_CNT_OVFL]=1. */
+                                                         ILK_TX(0..1)_INT[STAT_CNT_OVFL]. */
 #else
 	uint64_t tx_pkt                       : 34;
 	uint64_t reserved_34_63               : 30;
@@ -4825,11 +4938,10 @@ union cvmx_ilk_txx_rmatch {
 	struct cvmx_ilk_txx_rmatch_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_50_63               : 14;
-	uint64_t grnlrty                      : 2;  /**< Granularity of a token, where 1 token equal (1<<GRNLRTY) bytes. */
-	uint64_t brst_limit                   : 16; /**< Size of token bucket, also the maximum quantity of data that can be burst across the
-                                                         interface before invoking rate-limiting logic. */
-	uint64_t time_limit                   : 16; /**< Number of cycles per time interval. Must be >= 4. */
-	uint64_t rate_limit                   : 16; /**< Number of tokens added to the bucket when the interval timer expires. */
+	uint64_t grnlrty                      : 2;  /**< Reserved. */
+	uint64_t brst_limit                   : 16; /**< Reserved. */
+	uint64_t time_limit                   : 16; /**< Reserved. */
+	uint64_t rate_limit                   : 16; /**< Reserved. */
 #else
 	uint64_t rate_limit                   : 16;
 	uint64_t time_limit                   : 16;
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk.h b/arch/mips/include/asm/octeon/cvmx-ilk.h
index a2c59a9..815fed1 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk.h
@@ -61,11 +61,15 @@ extern "C" {
 
 /* CSR typedefs have been moved to cvmx-ilk-defs.h */
 
+/*
+ * Note: this macro must match the first ilk port in the ipd_port_map_68xx[]
+ * and ipd_port_map_78xx[] arrays.
+ */
 static inline int CVMX_ILK_GBL_BASE(void) {
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
 		return 5;
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-		return 5;
+		return 6;
 	return -1;
 }
 static inline int CVMX_ILK_QLM_BASE(void) {
@@ -126,6 +130,7 @@ typedef struct {
 } cvmx_ilk_stats_ctrl_t;
 
 #define CVMX_ILK_MAX_CAL      288
+#define CVMX_ILK_MAX_CAL_IDX  (CVMX_ILK_MAX_CAL / 8)
 #define CVMX_ILK_TX_MIN_CAL   1
 #define CVMX_ILK_RX_MIN_CAL   1
 #define CVMX_ILK_CAL_GRP_SZ   8
diff --git a/arch/mips/include/asm/octeon/cvmx-iob-defs.h b/arch/mips/include/asm/octeon/cvmx-iob-defs.h
index 19c8ef0..40fc1ba 100644
--- a/arch/mips/include/asm/octeon/cvmx-iob-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-iob-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -526,7 +526,20 @@ union cvmx_iob_chip_cur_pwr {
 	struct cvmx_iob_chip_cur_pwr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t current_power_setting        : 8;  /**< Current Power Setting. */
+	uint64_t current_power_setting        : 8;  /**< Global throttling value currently being used.
+                                                         Throttling can force units (CPU cores, in particular) idle for a
+                                                         portion of time, which will reduce power consumption.  When
+                                                         CURRENT_POWER_SETTING is equal to zero, the unit is idle most
+                                                         of the time and consumes minimum power. When CURRENT_POWER_SETTING
+                                                         is equal to 0xFF, units are never idled to reduce power.
+                                                         The hardware generally uses a CURRENT_POWER_SETTING value that
+                                                         is as large as possible (in order to maximize performance) subject
+                                                         to the following constraints (in priority order):
+                                                           - PWR_MIN <= CURRENT_POWER_SETTING <= PWR_MAX
+                                                           - Power limits from the PWR_SETTING feedback control system
+                                                         In the case of the CPU cores, CURRENT_POWER_SETTING effectively
+                                                         limits the CP0 PowThrottle[POWLIM] value:
+                                                           effective POWLIM = MINIMUM(CURRENT_POWER_SETTING,PowThrottle[POWLIM]) */
 #else
 	uint64_t current_power_setting        : 8;
 	uint64_t reserved_8_63                : 56;
@@ -547,10 +560,37 @@ union cvmx_iob_chip_glb_pwr_throttle {
 	struct cvmx_iob_chip_glb_pwr_throttle_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
-	uint64_t pwr_bw                       : 2;  /**< Power BW. */
-	uint64_t pwr_max                      : 8;  /**< Max power setting in ma/Ghz. */
-	uint64_t pwr_min                      : 8;  /**< Min power setting in ma/Ghz. */
-	uint64_t pwr_setting                  : 16; /**< in ma/Ghz. */
+	uint64_t pwr_bw                       : 2;  /**< Configures the reaction time of the closed-loop feedback
+                                                         control system for the AVG_CHIP_POWER power approximation.
+                                                         Higher numbers decrease bandwidth, reducing response time,
+                                                         which could lead to greater tracking error, but reduce
+                                                         ringing. */
+	uint64_t pwr_max                      : 8;  /**< Maximum allowed CURRENT_POWER_SETTING value. PWR_MAX must
+                                                         be >= PWR_MIN. */
+	uint64_t pwr_min                      : 8;  /**< Minimum allowed CURRENT_POWER_SETTING value. PWR_MIN must
+                                                         be <= PWR_MAX.
+                                                         We recommend a PWR_MIN value larger than zero to set a
+                                                         minimum performance level in case PWR_SETTING is set to
+                                                         an unreachable goal. See the CPU CP0 PowThrottle description.
+                                                         PWR_MIN = 50% of PowThrottle[MAXPOW] could be a good
+                                                         choice, for example. */
+	uint64_t pwr_setting                  : 16; /**< A power limiter for the chip.
+                                                         A limiter of the power consumption of the chip. This power
+                                                         limiting is implemented by a closed-loop feedback control
+                                                         system for the AVG_CHIP_POWER power approximation. The
+                                                         direct output of the PWR_SETTING feedback control system
+                                                         is the CURRENT_POWER_SETTING value. The power consumed
+                                                         by the chip (estimated currently by the AVG_CHIP_POWER
+                                                         value) is an indirect output of the PWR_SETTING feedback
+                                                         control system.
+                                                         PWR_SETTING is not used by the hardware when PWR_MIN equals
+                                                         PWR_MAX. PWR_MIN and PWR_MAX threshold requirements always
+                                                         supercede PWR_SETTING limits. (For maximum PWR_SETTING
+                                                         feedback control freedom, set PWR_MIN=0 and PWR_MAX=0xff.)
+                                                         PWR_SETTING equal to 0 forces the chip to consume near
+                                                         minimum power. Increasing PWR_SETTING value from 0 to
+                                                         0xffff increases the power that the chip is alloed to
+                                                         consume linearly (roughly) from minimum to maximum. */
 #else
 	uint64_t pwr_setting                  : 16;
 	uint64_t pwr_min                      : 8;
@@ -573,15 +613,26 @@ union cvmx_iob_chip_pwr_out {
 	uint64_t u64;
 	struct cvmx_iob_chip_pwr_out_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t cmb_pwr                      : 16; /**< CMB Power number. */
-	uint64_t chip_power                   : 16; /**< Total Chip Power number. */
-	uint64_t roc_power                    : 16; /**< Total ROC Power. */
-	uint64_t avg_chip_power               : 16; /**< Avg chip power. */
+	uint64_t cpu_pwr                      : 16; /**< An estimate of the current CPU core complex power consumption.
+                                                         The CPU core complex includes the caches and DRAM controller(s),
+                                                         as well as all CPU cores. Linearly larger values indicate linearly
+                                                         higher power consumption. This power consumption estimate is
+                                                         energy per core clock. */
+	uint64_t chip_power                   : 16; /**< An estimate of the current total power consumption by the chip.
+                                                         Linearly larger values indicate linearly higher power consumption.
+                                                         CHIP_POWER is the sum of CPU_POWER and COPROC_POWER. */
+	uint64_t coproc_power                 : 16; /**< An estimate of the current coprocessor power consumption.
+                                                         Linearly larger values indicate linearly higher power consumption.
+                                                         This estimate is energy per core clock, and will
+                                                         generally decrease as the ratio of core to coprocessor clock
+                                                         speed increases. */
+	uint64_t avg_chip_power               : 16; /**< An average of CHIP_POWER, calculated using an IIR filter with
+                                                         an average weight of 16K core clocks. */
 #else
 	uint64_t avg_chip_power               : 16;
-	uint64_t roc_power                    : 16;
+	uint64_t coproc_power                 : 16;
 	uint64_t chip_power                   : 16;
-	uint64_t cmb_pwr                      : 16;
+	uint64_t cpu_pwr                      : 16;
 #endif
 	} s;
 	struct cvmx_iob_chip_pwr_out_s        cn70xx;
diff --git a/arch/mips/include/asm/octeon/cvmx-iobn-defs.h b/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
index e25c8ff..30b0e39 100644
--- a/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -247,7 +247,20 @@ union cvmx_iobn_chip_cur_pwr {
 	struct cvmx_iobn_chip_cur_pwr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t current_power_setting        : 8;  /**< Current power setting. */
+	uint64_t current_power_setting        : 8;  /**< Global throttling value currently being used.
+                                                         Throttling can force units (CPU cores, in particular) idle for a
+                                                         portion of time, which will reduce power consumption.  When
+                                                         CURRENT_POWER_SETTING is equal to zero, the unit is idle most
+                                                         of the time and consumes minimum power. When CURRENT_POWER_SETTING
+                                                         is equal to 0xFF, units are never idled to reduce power.
+                                                         The hardware generally uses a CURRENT_POWER_SETTING value that
+                                                         is as large as possible (in order to maximize performance) subject
+                                                         to the following constraints (in priority order):
+                                                           - PWR_MIN <= CURRENT_POWER_SETTING <= PWR_MAX
+                                                           - Power limits from the PWR_SETTING feedback control system
+                                                         In the case of the CPU cores, CURRENT_POWER_SETTING effectively
+                                                         limits the CP0 PowThrottle[POWLIM] value:
+                                                           effective POWLIM = MINIMUM(CURRENT_POWER_SETTING,PowThrottle[POWLIM]) */
 #else
 	uint64_t current_power_setting        : 8;
 	uint64_t reserved_8_63                : 56;
@@ -268,10 +281,37 @@ union cvmx_iobn_chip_glb_pwr_throttle {
 	struct cvmx_iobn_chip_glb_pwr_throttle_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
-	uint64_t pwr_bw                       : 2;  /**< Power BW. */
-	uint64_t pwr_max                      : 8;  /**< Max power setting in ma/Ghz. */
-	uint64_t pwr_min                      : 8;  /**< Min power setting in ma/Ghz. */
-	uint64_t pwr_setting                  : 16; /**< in ma/Ghz. */
+	uint64_t pwr_bw                       : 2;  /**< Configures the reaction time of the closed-loop feedback
+                                                         control system for the AVG_CHIP_POWER power approximation.
+                                                         Higher numbers decrease bandwidth, reducing response time,
+                                                         which could lead to greater tracking error, but reduce
+                                                         ringing. */
+	uint64_t pwr_max                      : 8;  /**< Maximum allowed CURRENT_POWER_SETTING value. PWR_MAX must
+                                                         be >= PWR_MIN. */
+	uint64_t pwr_min                      : 8;  /**< Minimum allowed CURRENT_POWER_SETTING value. PWR_MIN must
+                                                         be <= PWR_MAX.
+                                                         We recommend a PWR_MIN value larger than zero to set a
+                                                         minimum performance level in case PWR_SETTING is set to
+                                                         an unreachable goal. See the CPU CP0 PowThrottle description.
+                                                         PWR_MIN = 50% of PowThrottle[MAXPOW] could be a good
+                                                         choice, for example. */
+	uint64_t pwr_setting                  : 16; /**< A power limiter for the chip.
+                                                         A limiter of the power consumption of the chip. This power
+                                                         limiting is implemented by a closed-loop feedback control
+                                                         system for the AVG_CHIP_POWER power approximation. The
+                                                         direct output of the PWR_SETTING feedback control system
+                                                         is the CURRENT_POWER_SETTING value. The power consumed
+                                                         by the chip (estimated currently by the AVG_CHIP_POWER
+                                                         value) is an indirect output of the PWR_SETTING feedback
+                                                         control system.
+                                                         PWR_SETTING is not used by the hardware when PWR_MIN equals
+                                                         PWR_MAX. PWR_MIN and PWR_MAX threshold requirements always
+                                                         supercede PWR_SETTING limits. (For maximum PWR_SETTING
+                                                         feedback control freedom, set PWR_MIN=0 and PWR_MAX=0xff.)
+                                                         PWR_SETTING equal to 0 forces the chip to consume near
+                                                         minimum power. Increasing PWR_SETTING value from 0 to
+                                                         0xffff increases the power that the chip is alloed to
+                                                         consume linearly (roughly) from minimum to maximum. */
 #else
 	uint64_t pwr_setting                  : 16;
 	uint64_t pwr_min                      : 8;
@@ -294,15 +334,26 @@ union cvmx_iobn_chip_pwr_out {
 	uint64_t u64;
 	struct cvmx_iobn_chip_pwr_out_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t cmb_pwr                      : 16; /**< CMB power number. */
-	uint64_t chip_power                   : 16; /**< Total chip power number. */
-	uint64_t roc_power                    : 16; /**< Total ROC power. */
-	uint64_t avg_chip_power               : 16; /**< Average chip power. */
+	uint64_t cpu_pwr                      : 16; /**< An estimate of the current CPU core complex power consumption.
+                                                         The CPU core complex includes the caches and DRAM controller(s),
+                                                         as well as all CPU cores. Linearly larger values indicate linearly
+                                                         higher power consumption. This power consumption estimate is
+                                                         energy per core clock. */
+	uint64_t chip_power                   : 16; /**< An estimate of the current total power consumption by the chip.
+                                                         Linearly larger values indicate linearly higher power consumption.
+                                                         CHIP_POWER is the sum of CPU_POWER and COPROC_POWER. */
+	uint64_t coproc_power                 : 16; /**< An estimate of the current coprocessor power consumption.
+                                                         Linearly larger values indicate linearly higher power consumption.
+                                                         This estimate is energy per core clock, and will
+                                                         generally decrease as the ratio of core to coprocessor clock
+                                                         speed increases. */
+	uint64_t avg_chip_power               : 16; /**< An average of CHIP_POWER, calculated using an IIR filter with
+                                                         an average weight of 16K core clocks. */
 #else
 	uint64_t avg_chip_power               : 16;
-	uint64_t roc_power                    : 16;
+	uint64_t coproc_power                 : 16;
 	uint64_t chip_power                   : 16;
-	uint64_t cmb_pwr                      : 16;
+	uint64_t cpu_pwr                      : 16;
 #endif
 	} s;
 	struct cvmx_iobn_chip_pwr_out_s       cn78xx;
diff --git a/arch/mips/include/asm/octeon/cvmx-iobp-defs.h b/arch/mips/include/asm/octeon/cvmx-iobp-defs.h
index b9bc325..bddc995 100644
--- a/arch/mips/include/asm/octeon/cvmx-iobp-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-iobp-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-ipd-defs.h b/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
index 9a19b75..26fce64 100644
--- a/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-l2c-defs.h b/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
index d95e06a..cc005b1 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -165,6 +165,17 @@ static inline uint64_t CVMX_L2C_CBCX_BIST_STATUS(unsigned long block_id)
 #define CVMX_L2C_CBCX_BIST_STATUS(block_id) (CVMX_ADD_IO_SEG(0x0001180080E007F8ull) + ((block_id) & 3) * 0x40000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_L2C_CBCX_DLL(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
+		cvmx_warn("CVMX_L2C_CBCX_DLL(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180080E00018ull) + ((block_id) & 3) * 0x40000ull;
+}
+#else
+#define CVMX_L2C_CBCX_DLL(block_id) (CVMX_ADD_IO_SEG(0x0001180080E00018ull) + ((block_id) & 3) * 0x40000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_L2C_CBCX_INT(unsigned long block_id)
 {
 	if (!(
@@ -189,6 +200,17 @@ static inline uint64_t CVMX_L2C_CBCX_IOCERR(unsigned long block_id)
 #define CVMX_L2C_CBCX_IOCERR(block_id) (CVMX_ADD_IO_SEG(0x0001180080E007E8ull) + ((block_id) & 3) * 0x40000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_L2C_CBCX_MIBERR(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((block_id >= 2) && (block_id <= 3))))))
+		cvmx_warn("CVMX_L2C_CBCX_MIBERR(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + ((block_id) & 3) * 0x40000ull - 262144*2;
+}
+#else
+#define CVMX_L2C_CBCX_MIBERR(block_id) (CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + ((block_id) & 3) * 0x40000ull - 262144*2)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_L2C_CBCX_RSDERR(unsigned long block_id)
 {
 	if (!(
@@ -913,12 +935,13 @@ static inline uint64_t CVMX_L2C_SPAR4_FUNC(void)
 static inline uint64_t CVMX_L2C_TADX_DLL(unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id == 0)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id == 0))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 7)))))
 		cvmx_warn("CVMX_L2C_TADX_DLL(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x0001180080A00018ull);
+	return CVMX_ADD_IO_SEG(0x0001180080A00018ull) + ((block_id) & 7) * 0x40000ull;
 }
 #else
-#define CVMX_L2C_TADX_DLL(block_id) (CVMX_ADD_IO_SEG(0x0001180080A00018ull))
+#define CVMX_L2C_TADX_DLL(block_id) (CVMX_ADD_IO_SEG(0x0001180080A00018ull) + ((block_id) & 7) * 0x40000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_L2C_TADX_ECC0(unsigned long block_id)
@@ -1412,11 +1435,15 @@ static inline uint64_t CVMX_L2C_XMDX_PFC(unsigned long offset)
 /**
  * cvmx_l2c_big_ctl
  *
+ * L2C_BIG_CTL = L2C Big memory control register
+ *
+ *
+ * Notes:
  * (1) BIGRD interrupts can occur during normal operation as the PP's are allowed to prefetch to
- * non-existent memory locations.  Therefore, BIGRD is for informational purposes only.
+ *     non-existent memory locations.  Therefore, BIGRD is for informational purposes only.
  *
- * (2) When a HOLERD/BIGRD occurs or HOLEWR/BIGWR blocks a store L2C_TAD(0..7)_ERR will be
- * loaded.  L2C_TAD(0..7)_ERR will be not be locked for a BIGRD, however.
+ * (2) When HOLEWR/BIGWR blocks a store L2C_VER_ID, L2C_VER_PP, L2C_VER_IOB, and L2C_VER_MSC will be
+ *     loaded just like a store which is blocked by VRTWR.  Additionally, L2C_ERR_XMC will be loaded.
  */
 union cvmx_l2c_big_ctl {
 	uint64_t u64;
@@ -1480,24 +1507,30 @@ union cvmx_l2c_big_ctl {
 	struct cvmx_l2c_big_ctl_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t maxdram                      : 4;  /**< Amount of configured DRAM
-                                                         0 = reserved
-                                                         1 = 512MB
-                                                         2 = 1GB
-                                                         3 = 2GB
-                                                         4 = 4GB
-                                                         5 = 8GB
-                                                         6 = 16GB
-                                                         7 = 32GB
-                                                         8 = 64GB
-                                                         9 = 128GB
-                                                         10 = 256GB
-                                                         11 = 512GB
-                                                         12-15 reserved
-                                                         Violations of this limit causes L2C to set L2C_TAD(0..0)_INT[BIGRD/BIGWR]. */
+	uint64_t maxdram                      : 4;  /**< Amount of configured DRAM.
+                                                         0x0 = reserved.
+                                                         0x1 = 512 MB.
+                                                         0x2 = 1 GB.
+                                                         0x3 = 2 GB.
+                                                         0x4 = 4 GB.
+                                                         0x5 = 8 GB.
+                                                         0x6 = 16 GB.
+                                                         0x7 = 32 GB.
+                                                         0x8 = 64 GB.
+                                                         0x9 = 128 GB.
+                                                         0xA = 256 GB.
+                                                         0xB = 512 GB.
+                                                         0xC-0xF= reserved.
+                                                         Violations of this limit causes L2C to set L2C_INT_REG[BIGRD/BIGWR].
+                                                         BIGRD interrupts can occur during normal operation as the cores are allowed to prefetch to
+                                                         nonexistent memory locations. Therefore, BIGRD is for informational purposes only.
+                                                         When a HOLERD/BIGRD occurs or HOLEWR/BIGWR blocks a store operation, L2C_TAD(0..0)_ERR is
+                                                         loaded. L2C_TAD(0..0)_ERR is not locked for a BIGRD, however.
+                                                         The BIG logic only applies to local addresses. A command for a remote address does not
+                                                         cause a BIGRD/BIGWR on the requesting node. */
 	uint64_t reserved_1_3                 : 3;
-	uint64_t disbig                       : 1;  /**< When set, disables the BIG/HOLE logic completely. When clear, BIGWR and HOLEWR block
-                                                         stores and BIGRD/HOLERD is reported. */
+	uint64_t disbig                       : 1;  /**< Disable the BIG/HOLE logic. When set, the BIG/HOLE is logic disabled completely. When
+                                                         clear, BIGWR and HOLEWR block stores and BIGRD/HOLERD is reported. */
 #else
 	uint64_t disbig                       : 1;
 	uint64_t reserved_1_3                 : 3;
@@ -2226,6 +2259,19 @@ union cvmx_l2c_cbcx_bist_status {
 	uint64_t u64;
 	struct cvmx_l2c_cbcx_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_39_63               : 25;
+	uint64_t mibfl                        : 5;  /**< BIST failure status for various MIB memories. ([XMD, IPM, IRM, MXD, MXN]) */
+	uint64_t ioccmdfl                     : 2;  /**< BIST failure status for IOCCMD0-1. */
+	uint64_t rsdfl                        : 32; /**< BIST failure status for RSDQW0-31. */
+#else
+	uint64_t rsdfl                        : 32;
+	uint64_t ioccmdfl                     : 2;
+	uint64_t mibfl                        : 5;
+	uint64_t reserved_39_63               : 25;
+#endif
+	} s;
+	struct cvmx_l2c_cbcx_bist_status_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
 	uint64_t ioccmdfl                     : 2;  /**< BIST failure status for IOCCMD0-1. */
 	uint64_t rsdfl                        : 32; /**< BIST failure status for RSDQW0-31. */
@@ -2234,13 +2280,47 @@ union cvmx_l2c_cbcx_bist_status {
 	uint64_t ioccmdfl                     : 2;
 	uint64_t reserved_34_63               : 30;
 #endif
-	} s;
-	struct cvmx_l2c_cbcx_bist_status_s    cn70xx;
+	} cn70xx;
 	struct cvmx_l2c_cbcx_bist_status_s    cn78xx;
 };
 typedef union cvmx_l2c_cbcx_bist_status cvmx_l2c_cbcx_bist_status_t;
 
 /**
+ * cvmx_l2c_cbc#_dll
+ *
+ * Register for DLL observability
+ *
+ */
+union cvmx_l2c_cbcx_dll {
+	uint64_t u64;
+	struct cvmx_l2c_cbcx_dll_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t pd_pos_rclk_refclk           : 1;  /**< Phase detector output. */
+	uint64_t pdl_rclk_refclk              : 1;  /**< Phase detector output. */
+	uint64_t pdr_rclk_refclk              : 1;  /**< Phase detector output. */
+	uint64_t clk_invert                   : 1;  /**< Clock invert. */
+	uint64_t dly_elem_enable              : 16; /**< Delay element enable. */
+	uint64_t dll_setting                  : 12; /**< DLL setting. */
+	uint64_t dll_state                    : 3;  /**< DLL state. */
+	uint64_t dll_lock                     : 1;  /**< DLL locked. */
+#else
+	uint64_t dll_lock                     : 1;
+	uint64_t dll_state                    : 3;
+	uint64_t dll_setting                  : 12;
+	uint64_t dly_elem_enable              : 16;
+	uint64_t clk_invert                   : 1;
+	uint64_t pdr_rclk_refclk              : 1;
+	uint64_t pdl_rclk_refclk              : 1;
+	uint64_t pd_pos_rclk_refclk           : 1;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_l2c_cbcx_dll_s            cn78xx;
+};
+typedef union cvmx_l2c_cbcx_dll cvmx_l2c_cbcx_dll_t;
+
+/**
  * cvmx_l2c_cbc#_int
  *
  * This register is for CBC-based interrupts.
@@ -2250,11 +2330,30 @@ union cvmx_l2c_cbcx_int {
 	uint64_t u64;
 	struct cvmx_l2c_cbcx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_6_63                : 58;
+	uint64_t mibdbe                       : 1;  /**< MIB double-bit error occurred. See L2C_CBC(2..3)_MIBERR for logged information. */
+	uint64_t mibsbe                       : 1;  /**< MIB double-bit error occurred. See L2C_CBC(2..3)_MIBERR for logged information. */
+	uint64_t ioccmddbe                    : 1;  /**< IOCCMD double-bit error occurred. See L2C_CBC(0..3)_IOCERR for logged information. */
+	uint64_t ioccmdsbe                    : 1;  /**< IOCCMD single-bit error occurred. See L2C_CBC(0..3)_IOCERR for logged information. */
+	uint64_t rsddbe                       : 1;  /**< RSD double-bit error occurred. See L2C_CBC(0..3)_RSDERR for logged information. */
+	uint64_t rsdsbe                       : 1;  /**< RSD single-bit error occurred. See L2C_CBC(0..3)_RSDERR for logged information. */
+#else
+	uint64_t rsdsbe                       : 1;
+	uint64_t rsddbe                       : 1;
+	uint64_t ioccmdsbe                    : 1;
+	uint64_t ioccmddbe                    : 1;
+	uint64_t mibsbe                       : 1;
+	uint64_t mibdbe                       : 1;
+	uint64_t reserved_6_63                : 58;
+#endif
+	} s;
+	struct cvmx_l2c_cbcx_int_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t ioccmddbe                    : 1;  /**< IOCCMD double-bit error occurred. See L2C_CBC_IOCERR for logged information. */
-	uint64_t ioccmdsbe                    : 1;  /**< IOCCMD single-bit error occurred. See L2C_CBC_IOCERR for logged information. */
-	uint64_t rsddbe                       : 1;  /**< RSD double-bit error occurred. See L2C_CBC_RSDERR for logged information. */
-	uint64_t rsdsbe                       : 1;  /**< RSD single-bit error occurred. See L2C_CBC_RSDERR for logged information. */
+	uint64_t ioccmddbe                    : 1;  /**< IOCCMD double-bit error occurred. See L2C_CBC(0..3)_IOCERR for logged information. */
+	uint64_t ioccmdsbe                    : 1;  /**< IOCCMD single-bit error occurred. See L2C_CBC(0..3)_IOCERR for logged information. */
+	uint64_t rsddbe                       : 1;  /**< RSD double-bit error occurred. See L2C_CBC(0..3)_RSDERR for logged information. */
+	uint64_t rsdsbe                       : 1;  /**< RSD single-bit error occurred. See L2C_CBC(0..3)_RSDERR for logged information. */
 #else
 	uint64_t rsdsbe                       : 1;
 	uint64_t rsddbe                       : 1;
@@ -2262,8 +2361,7 @@ union cvmx_l2c_cbcx_int {
 	uint64_t ioccmddbe                    : 1;
 	uint64_t reserved_4_63                : 60;
 #endif
-	} s;
-	struct cvmx_l2c_cbcx_int_s            cn70xx;
+	} cn70xx;
 	struct cvmx_l2c_cbcx_int_s            cn78xx;
 };
 typedef union cvmx_l2c_cbcx_int cvmx_l2c_cbcx_int_t;
@@ -2287,7 +2385,7 @@ union cvmx_l2c_cbcx_iocerr {
 	uint64_t reserved_40_61               : 22;
 	uint64_t syn                          : 8;  /**< Error syndrome. */
 	uint64_t reserved_3_31                : 29;
-	uint64_t xmcnum                       : 3;  /**< XMC which had the error. */
+	uint64_t xmcnum                       : 3;  /**< Indicates the XMC that had the error. */
 #else
 	uint64_t xmcnum                       : 3;
 	uint64_t reserved_3_31                : 29;
@@ -2303,6 +2401,45 @@ union cvmx_l2c_cbcx_iocerr {
 typedef union cvmx_l2c_cbcx_iocerr cvmx_l2c_cbcx_iocerr_t;
 
 /**
+ * cvmx_l2c_cbc#_miberr
+ *
+ * This register records error information for all CBC MIB errors.
+ * An error locks the INDEX, and SYN fields and set the bit corresponding to the error received.
+ * MIBDBE errors take priority and overwrite an earlier logged MIBSBE error. Only one of
+ * MIBSBE/MIBDBE is set at any given time and serves to document which error the INDEX/SYN is
+ * associated with.
+ * The syndrome is recorded for DBE errors, though the utility of the value is not clear.
+ */
+union cvmx_l2c_cbcx_miberr {
+	uint64_t u64;
+	struct cvmx_l2c_cbcx_miberr_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t mibdbe                       : 1;  /**< INDEX/SYN corresponds to a double-bit MIB ECC error. */
+	uint64_t mibsbe                       : 1;  /**< INDEX/SYN corresponds to a single-bit MIB ECC error. */
+	uint64_t reserved_40_61               : 22;
+	uint64_t syn                          : 8;  /**< Error syndrome. */
+	uint64_t reserved_3_31                : 29;
+	uint64_t memid                        : 2;  /**< Indicates the memory that had the error.
+                                                         0x0 = Error from MXB_VC_MRN, MXB_VC_MFN, MXB_VC_MPN VCs.
+                                                         0x1 = Error from MXB_VC_MRD, MXB_VC_MPD VCs.
+                                                         0x2 = Error from MXB_VC_IRM VC.
+                                                         0x3 = Error from MXB_VC_IPM VC. */
+	uint64_t mibnum                       : 1;  /**< Indicates the CBC that had the error. */
+#else
+	uint64_t mibnum                       : 1;
+	uint64_t memid                        : 2;
+	uint64_t reserved_3_31                : 29;
+	uint64_t syn                          : 8;
+	uint64_t reserved_40_61               : 22;
+	uint64_t mibsbe                       : 1;
+	uint64_t mibdbe                       : 1;
+#endif
+	} s;
+	struct cvmx_l2c_cbcx_miberr_s         cn78xx;
+};
+typedef union cvmx_l2c_cbcx_miberr cvmx_l2c_cbcx_miberr_t;
+
+/**
  * cvmx_l2c_cbc#_rsderr
  *
  * This register records error information for all CBC RSD errors.
@@ -2321,9 +2458,9 @@ union cvmx_l2c_cbcx_rsderr {
 	uint64_t reserved_40_61               : 22;
 	uint64_t syn                          : 8;  /**< Error syndrome. */
 	uint64_t reserved_9_31                : 23;
-	uint64_t tadnum                       : 3;  /**< TAD fifo containing the error. */
-	uint64_t qwnum                        : 2;  /**< QW containing the error. */
-	uint64_t rsdnum                       : 4;  /**< RSD which had the error. */
+	uint64_t tadnum                       : 3;  /**< Indicates the TAD FIFO containing the error. */
+	uint64_t qwnum                        : 2;  /**< Indicates the QW containing the error. */
+	uint64_t rsdnum                       : 4;  /**< Indicates the RSD that had the error. */
 #else
 	uint64_t rsdnum                       : 4;
 	uint64_t qwnum                        : 2;
@@ -2903,77 +3040,126 @@ typedef union cvmx_l2c_cfg cvmx_l2c_cfg_t;
  * (3) if the PPID is outside the range of 0-47,255 or if the PP in question is in reset
  * a write will be ignored and reads will timeout the RSL bus.
  *
- * (4) Referring to note (1) above, the following rd/sel values are supported:
+ * (4) Referring to note (1) above, the following root/rd/sel values are supported:
  * NOTE: Put only the "Customer type" in HRM. do not put the "Real type" in HRM.
- * Customer                                                    Real
- * rd     sel     type         Description                                 type
- * ======+=======+==========+==============================================+=========
- * 4      2       RO          COP0 UserLocal                                RW
- * 7      0       RO          COP0 HWREna                                   RW
- * 9      0       RO          COP0 Count                                    RW
- * 9      6       RO          COP0 CvmCount                                 RW
- * 9      7       RO          COP0 CvmCtl                                   RW
- * 11      0       RO          COP0 Compare                                  RW
- * 11      6       RW          COP0 PowThrottle                              RW
- * 12      0       RO          COP0 Status                                   RW
- * 12      1       RO          COP0 IntCtl                                   RO
- * 12      2       RO          COP0 SRSCtl                                   RO
- * 13      0       RO          COP0 Cause                                    RW
- * 14      0       RO          COP0 EPC                                      RW
- * 15      0       RO          COP0 PrID                                     RO
- * 15      1       RO          COP0 EBase                                    RW
- * 16      0       RO          PC Issue Debug Info (see details below)       RO
- * 16      1       RO          PC Fetch Debug Info (see details below)       RO
- * 16      2       RO          PC Fill Debug Info (see details below)        RO
- * 16      3       RO          PC Misc Debug Info (see details below)        RO
- * 18      0       RO          COP0 WatchLo0                                 RW
- * 19      0       RO          COP0 WatchHi0                                 RW
- * 22      0       RO          COP0 MultiCoreDebug                           RW
- * 22      1                   COP0 VoltageMonitor                           RW
- * 23      0       RO          COP0 Debug                                    RW
- * 23      6       RO          COP0 Debug2                                   RO
- * 24      0       RO          COP0 DEPC                                     RW
- * 25      0       RO          COP0 PerfCnt Control0                         RW
- * 25      1       RO          COP0 PerfCnt Counter0                         RW
- * 25      2       RO          COP0 PerfCnt Control1                         RW
- * 25      3       RO          COP0 PerfCnt Counter1                         RW
- * 25      4       RO          COP0 PerfCnt Control2                         RW
- * 25      5       RO          COP0 PerfCnt Counter2                         RW
- * 25      6       RO          COP0 PerfCnt Control3                         RW
- * 25      7       RO          COP0 PerfCnt Counter3                         RW
- * 27      0       RO          COP0 CacheErr (icache)                        RW
- * 27      2              RO          COP0 IcacheDebug                                RW
- * 28      0       RO          COP0 TagLo (icache)                           RW
- * 28      1       RO          COP0 DataLo (icache)                          RW
- * 29      1       RO          COP0 DataHi (icache)                          RW
- * 30      0       RO          COP0 ErrorEPC                                 RW
- * 31      0       RO          COP0 DESAVE                                   RW
- * 31      2       RO          COP0 Scratch                                  RW
- * 31      3       RO          COP0 Scratch1                                 RW
- * 31      4       RO          COP0 Scratch2                                 RW
+ *
+ *              Customer                                           Real
+ * root rd  sel   type         Description                         type
+ * ====+===+===+========+=========================================+====
+ *  1    4   2     RO     CP0 Root.UserLocal                        RW
+ *  0    4   2     RO     CP0 Guest.UserLocal                       RW
+ *  1    7   0     RO     CP0 Root.HWREna                           RW
+ *  0    7   0     RO     CP0 Guest.HWREna                          RW
+ *  1    8   1     RO     CP0 Root.BadInstr                         RW
+ *  0    8   1     RO     CP0 Guest.BadInstr                        RW
+ *  1    8   2     RO     CP0 Root.BadInstrP                        RW
+ *  0    8   2     RO     CP0 Guest.BadInstrP                       RW
+ *  1    9   0     RO     CP0 Root.Count                            RW
+ *  1    9   6     RO     CP0 Root.CvmCount                         RW
+ *  1    9   7     RO     CP0 Root.CvmCtl                           RW
+ *  0    9   7     RO     CP0 Guest.CvmCtl                          RW
+ *  1   10   5     RO     CP0 Root.GuestCtl0                        RW
+ *  1   11   0     RO     CP0 Root.Compare                          RW
+ *  0   11   0     RO     CP0 Guest.Compare                         RW
+ *  1   11   4     RO     CP0 Root.GuestCtl0Ext                     RW
+ *  1   11   6     RW     CP0 Root.PowThrottle                      RW
+ *  1   12   0     RO     CP0 Root.Status                           RW
+ *  0   12   0     RO     CP0 Guest.Status                          RW
+ *  1   12   1     RO     CP0 Root.IntCtl                           RO
+ *  0   12   1     RO     CP0 Guest.IntCtl                          RO
+ *  1   12   2     RO     CP0 Root.SRSCtl                           RO
+ *  0   12   2     RO     CP0 Guest.SRSCtl                          RO
+ *  1   12   6     RO     CP0 Root.GuestCtl0                        RW
+ *  1   12   7     RO     CP0 Root.GTOffset                         RW
+ *  1   13   0     RO     CP0 Root.Cause                            RW
+ *  0   13   0     RO     CP0 Guest.Cause                           RW
+ *  1   14   0     RO     CP0 Root.EPC                              RW
+ *  0   14   0     RO     CP0 Guest.EPC                             RW
+ *  1   15   0     RO     CP0 Root.PrID                             RO
+ *  0   15   0     RO     CP0 Guest.PrID                            RO
+ *  1   15   1     RO     CP0 Root.EBase                            RW
+ *  0   15   1     RO     CP0 Guest.EBase                           RW
+ *  1   16   0     RO     PC Issue Debug Info (see details below)   RO
+ *  1   16   1     RO     PC Fetch Debug Info (see details below)   RO
+ *  1   16   2     RO     PC Fill Debug Info (see details below)    RO
+ *  1   16   3     RO     PC Misc Debug Info (see details below)    RO
+ *  1   16   5     RO     PC Committed Info (see details below)     RO
+ *  1   18   0     RO     CP0 Root.WatchLo0                         RW
+ *  1   19   0     RO     CP0 Root.WatchHi0                         RW
+ *  1   22   0     RO     CP0 Root.MultiCoreDebug                   RW
+ *  1   22   1            CP0 Root.ImplDebug                        R0
+ *  1   22   2     RO     CP0 Root.CvmCountOffset                   RW
+ *  1   23   0     RO     CP0 Root.Debug                            RW
+ *  1   23   6     RO     CP0 Root.Debug2                           RO
+ *  1   24   0     RO     CP0 Root.DEPC                             RW
+ *  1   25   0     RO     CP0 Root.PerfCnt Control0                 RW
+ *  1   25   1     RO     CP0 Root.PerfCnt Counter0                 RW
+ *  1   25   2     RO     CP0 Root.PerfCnt Control1                 RW
+ *  1   25   3     RO     CP0 Root.PerfCnt Counter1                 RW
+ *  1   25   4     RO     CP0 Root.PerfCnt Control2                 RW
+ *  1   25   5     RO     CP0 Root.PerfCnt Counter2                 RW
+ *  1   25   6     RO     CP0 Root.PerfCnt Control3                 RW
+ *  1   25   7     RO     CP0 Root.PerfCnt Counter3                 RW
+ *  1   27   0     RO     CP0 Root.CacheErr (icache)                RW
+ *  1   27   2     RO     CP0 Root.IcacheDebug                      RO
+ *  1   28   0     RO     CP0 Root.TagLo (icache)                   RW
+ *  1   28   1     RO     CP0 Root.DataLo (icache)                  RW
+ *  1   29   1     RO     CP0 Root.DataHi (icache)                  RW
+ *  1   30   0     RO     CP0 Root.ErrorEPC                         RW
+ *  0   30   0     RO     CP0 Guest.ErrorEPC                        RW
+ *  1   31   0     RO     CP0 Root.DESAVE                           RW
+ *  1   31   2     RO     CP0 Root.Scratch                          RW
+ *  0   31   2     RO     CP0 Guest.Scratch                         RW
+ *  1   31   3     RO     CP0 Root.Scratch1                         RW
+ *  0   31   3     RO     CP0 Guest.Scratch1                        RW
+ *  1   31   4     RO     CP0 Root.Scratch2                         RW
+ *  0   31   4     RO     CP0 Guest.Scratch2                        RW
+ *  1   31   5     RO     CP0 Root.Scratch3                         RW
+ *
  * PC Issue Debug Info
- * - 63:2 pc0_5a<63:2> // often VA<63:2> of the next instruction to issue
- * //    but can also be the VA of an instruction executing/replaying on pipe 0
- * //    or can also be a VA being filled into the instruction cache
- * //    or can also be unpredictable
- * // <61:49> RAZ
- * 1    illegal      // set when illegal VA
- * 0    delayslot    // set when VA is delayslot (prior branch may be either taken or not taken)
+ *  - 63:2  issue_address<63:2>   // often VA<63:2> (PC) of the next instruction to issue (5a in
+ * pipeline)
+ *                              //    but can also be the PC of an instruction
+ * executing/replaying
+ *                              //    or can also be a PC being filled into the instruction cache
+ *                              //    or can also be unpredictable
+ *                              // <58:50> is a copy of <49>
+ *  1     issue_illegal         // set when issue_address is an illegal PC
+ *  0     issue_delayslot       // set when issue_address is in a delayslot (prior instruction
+ * may be either taken or not taken)
+ *
  * PC Fetch Debug Info
- * - 63:0 fetch_address_3a // VA being fetched from the instruction cache
- * // <61:49>, <1:0> RAZ
+ *  - 63:1  fetch_address<63:1>   // VA <63:0> (PC) being fetched from the instruction cache (3a in
+ * pipeline)
+ *                              // <58:50> is a copy of <49>
+ *                              // <1> RAZ
+ *  0     fetch_guest           // set when fetch_address is for the guest
+ *
  * PC Fill Debug Info
- * - 63:0 fill_address_4a<63:2> // VA<63:2> being filled into instruction cache
- * // valid when waiting_for_ifill_4a is set (see PC Misc Debug Info below)
- * // <61:49> RAZ
- * 1 illegal               // set when illegal VA
- * 0 RAZ
+ *  - 63:2  fill_address<63:2>    // VA<63:2> being filled into instruction cache (4a in pipeline)
+ *                              // valid when waiting_for_ifill is set (see PC Misc Debug Info
+ * below)
+ *                              // <58:50> is a copy of <49>
+ *  1     fill_illegal          // set when fill_address is an illegal PC
+ *  0     fill_guest            // set when fill_address is for the guest
+ *
  * PC Misc Debug Info
- * - 63:3 RAZ
- * 2 mem_stall_3a         // stall term from L1 memory system
- * 1 waiting_for_pfill_4a // when waiting_for_ifill_4a is set, indicates whether instruction
- * cache fill is due to a prefetch
- * 0 waiting_for_ifill_4a // set when there is an outstanding instruction cache fill
+ *  - 63:5  RAZ
+ *  4     kernel_mode           // set if the CPU is in kernel mode (6a in pipeline)
+ *  3     guest_mode            // set if the CPU is in guest mode (6a in pipeline)
+ *  2     mem_stall             // stall term from L1 memory system (3a in pipeline)
+ *  1     waiting_for_pfill     // when waiting_for_ifill is set, indicates whether instruction
+ *                              // cache fill is due to a prefetch (4a in pipeline)
+ *  0     waiting_for_ifill     // set when there is an outstanding instruction cache fill (4a in
+ * pipeline)
+ *
+ * PC Committed Debug Info
+ *  63    commit_guest          // Set if commit_address was for the guest
+ *  - 62:55 commit_ASID           // ASID of commit_address
+ *  - 54:49 commit_address<63:59> // VA<63:59> (PC) of the last committed instruction (11a in
+ * pipeline)
+ *  - 48:0  commit_address<48:0>  // VA<48:0> (PC) of last committed instruction (11a in pipeline)
+ *                              // <1:0> RAZ
  */
 union cvmx_l2c_cop0_adr {
 	uint64_t u64;
@@ -3004,7 +3190,7 @@ typedef union cvmx_l2c_cop0_adr cvmx_l2c_cop0_adr_t;
 /**
  * cvmx_l2c_cop0_dat
  *
- * Provides data access for the COP0 register specified by the L2C_COP_ADR register.
+ * Provides data access for the COP0 register specified by the L2C_COP0_ADR register.
  *
  */
 union cvmx_l2c_cop0_dat {
@@ -3193,17 +3379,13 @@ union cvmx_l2c_ctl {
 	uint64_t xmc_arb_mode                 : 1;  /**< Arbitration mode for XMC QOS queues
                                                          == 0, fully determined through QOS
                                                          == 1, QOS0 highest priority, QOS1-3 use normal mode */
-	uint64_t reserved_6_13                : 8;
-	uint64_t vab_thresh                   : 4;  /**< VAB Threshold
-                                                         When the number of valid VABs exceeds this number the
-                                                         L2C increases the priority of all writes in the LMC. */
+	uint64_t reserved_2_13                : 12;
 	uint64_t disecc                       : 1;  /**< Tag and Data ECC Disable */
 	uint64_t disidxalias                  : 1;  /**< Index Alias Disable */
 #else
 	uint64_t disidxalias                  : 1;
 	uint64_t disecc                       : 1;
-	uint64_t vab_thresh                   : 4;
-	uint64_t reserved_6_13                : 8;
+	uint64_t reserved_2_13                : 12;
 	uint64_t xmc_arb_mode                 : 1;
 	uint64_t rsp_arb_mode                 : 1;
 	uint64_t maxlfb                       : 4;
@@ -3492,9 +3674,10 @@ union cvmx_l2c_ctl {
                                                          3. STDN/SCDN/SCFL */
 	uint64_t xmc_arb_mode                 : 1;  /**< Arbitration mode for ADD bus QOS queues. 0 = fully determined through QOS, 1 = QOS0
                                                          highest priority; QOS 1-7 use normal mode. */
-	uint64_t rdf_cnt                      : 8;  /**< Defines the sample point of the LMC response data in the DCLK/RCLK crossing. For optimal
-                                                         performance set to 10 * (DCLK period/RCLK period) - 1. To disable set to 0. All other
-                                                         values are reserved. */
+	uint64_t rdf_cnt                      : 8;  /**< Defines the sample point of the LMC response data in the DDR-clock/core-clock crossing.
+                                                         For optimal performance set to
+                                                         10 * (DDR-clock period/core-clock period) - 1.
+                                                         To disable set to 0. All other values are reserved. */
 	uint64_t reserved_2_5                 : 4;
 	uint64_t disecc                       : 1;  /**< Tag and data ECC disable. */
 	uint64_t disidxalias                  : 1;  /**< Index alias disable. */
@@ -3514,7 +3697,50 @@ union cvmx_l2c_ctl {
 	uint64_t reserved_32_63               : 32;
 #endif
 	} cn70xx;
-	struct cvmx_l2c_ctl_cn70xx            cn78xx;
+	struct cvmx_l2c_ctl_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t ocla_qos                     : 3;  /**< QOS level for the transactions from OCLA to L2C. */
+	uint64_t reserved_28_28               : 1;
+	uint64_t disstgl2i                    : 1;  /**< Disable STGL2Is from changing the tags. */
+	uint64_t reserved_25_26               : 2;
+	uint64_t discclk                      : 1;  /**< Disable conditional clocking in L2C PNR blocks. */
+	uint64_t reserved_16_23               : 8;
+	uint64_t rsp_arb_mode                 : 1;  /**< Arbitration mode for RSC/RSD bus. 0 = round-robin; 1 = static priority.
+                                                         1. IOR data
+                                                         2. STIN/FILLs
+                                                         3. STDN/SCDN/SCFL */
+	uint64_t xmc_arb_mode                 : 1;  /**< Arbitration mode for ADD bus QOS queues. 0 = fully determined through QOS, 1 = QOS0
+                                                         highest priority; QOS 1-7 use normal mode. */
+	uint64_t rdf_cnt                      : 8;  /**< Defines the sample point of the LMC response data in the DDR-clock/core-clock crossing.
+                                                         For optimal performance set to
+                                                         10 * (DDR-clock period/core-clock period) - 1.
+                                                         To disable set to 0. All other values are reserved. */
+	uint64_t reserved_4_5                 : 2;
+	uint64_t disldwb                      : 1;  /**< Suppresses the DWB functionality of any received LDWB, effectively turning them into LDTs. */
+	uint64_t dissblkdty                   : 1;  /**< Disable bandwidth optimization between L2 and LMC and MOB which only transfers modified
+                                                         sub-blocks when possible. NOTE: in an OCI system all nodes must use the same setting of
+                                                         DISSBLKDTY or operation is undefined. FIXME: should reset to 0, once verif supports it. */
+	uint64_t disecc                       : 1;  /**< Tag and data ECC disable. */
+	uint64_t disidxalias                  : 1;  /**< Index alias disable. */
+#else
+	uint64_t disidxalias                  : 1;
+	uint64_t disecc                       : 1;
+	uint64_t dissblkdty                   : 1;
+	uint64_t disldwb                      : 1;
+	uint64_t reserved_4_5                 : 2;
+	uint64_t rdf_cnt                      : 8;
+	uint64_t xmc_arb_mode                 : 1;
+	uint64_t rsp_arb_mode                 : 1;
+	uint64_t reserved_16_23               : 8;
+	uint64_t discclk                      : 1;
+	uint64_t reserved_25_26               : 2;
+	uint64_t disstgl2i                    : 1;
+	uint64_t reserved_28_28               : 1;
+	uint64_t ocla_qos                     : 3;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} cn78xx;
 	struct cvmx_l2c_ctl_cn61xx            cnf71xx;
 };
 typedef union cvmx_l2c_ctl cvmx_l2c_ctl_t;
@@ -4170,8 +4396,27 @@ union cvmx_l2c_ecc_ctl {
 	uint64_t u64;
 	struct cvmx_l2c_ecc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t mibflip                      : 2;  /**< Generate an ECC error in the MIB. See note above. */
+	uint64_t l2dflip                      : 2;  /**< Generate an ECC error in the L2D. See note above. */
+	uint64_t l2tflip                      : 2;  /**< Generate an ECC error in the L2T. */
+	uint64_t rdfflip                      : 2;  /**< Generate an ECC error in RDF memory. */
+	uint64_t xmdflip                      : 2;  /**< Generate an ECC error in all corresponding CBC XMD memories. */
+	uint64_t ioccmdflip                   : 2;  /**< Generate an ECC error in all corresponding IOCCMD memories. */
+#else
+	uint64_t ioccmdflip                   : 2;
+	uint64_t xmdflip                      : 2;
+	uint64_t rdfflip                      : 2;
+	uint64_t l2tflip                      : 2;
+	uint64_t l2dflip                      : 2;
+	uint64_t mibflip                      : 2;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} s;
+	struct cvmx_l2c_ecc_ctl_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
-	uint64_t l2dflip                      : 2;  /**< Generate an ECC error in the L2D (see Note 1). */
+	uint64_t l2dflip                      : 2;  /**< Generate an ECC error in the L2D. See note above. */
 	uint64_t l2tflip                      : 2;  /**< Generate an ECC error in the L2T. */
 	uint64_t rdfflip                      : 2;  /**< Generate an ECC error in RDF memory. */
 	uint64_t xmdflip                      : 2;  /**< Generate an ECC error in all corresponding CBC XMD memories. */
@@ -4184,8 +4429,7 @@ union cvmx_l2c_ecc_ctl {
 	uint64_t l2dflip                      : 2;
 	uint64_t reserved_10_63               : 54;
 #endif
-	} s;
-	struct cvmx_l2c_ecc_ctl_s             cn70xx;
+	} cn70xx;
 	struct cvmx_l2c_ecc_ctl_s             cn78xx;
 };
 typedef union cvmx_l2c_ecc_ctl cvmx_l2c_ecc_ctl_t;
@@ -5617,7 +5861,7 @@ typedef union cvmx_l2c_lfb3 cvmx_l2c_lfb3_t;
  * cvmx_l2c_mci#_bist_status
  *
  * If clear BIST is desired, CLEAR_BIST must be written to 1 before START_BIST is written to 1
- * using a separate CSR write.
+ * using a separate CSR write operation.
  * CLEAR_BIST must not be changed after writing START_BIST to 1 until the BIST operation
  * completes (indicated by START_BIST returning to 0) or operation is undefined.
  */
@@ -5625,7 +5869,7 @@ union cvmx_l2c_mcix_bist_status {
 	uint64_t u64;
 	struct cvmx_l2c_mcix_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t start_bist                   : 1;  /**< When written to 1, starts BIST. Will read 1 until BIST is complete. */
+	uint64_t start_bist                   : 1;  /**< When written to 1, starts BIST. Remains 1 until BIST is complete. */
 	uint64_t clear_bist                   : 1;  /**< When BIST is triggered, run clear BIST. */
 	uint64_t reserved_2_61                : 60;
 	uint64_t vbffl                        : 2;  /**< BIST failure status for VBF0-1. */
@@ -5696,8 +5940,8 @@ union cvmx_l2c_mcix_int {
 	struct cvmx_l2c_mcix_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t vbfdbe                       : 1;  /**< VBF double-bit error occurred. See L2C_MCI_ERR for logged information. */
-	uint64_t vbfsbe                       : 1;  /**< VBF single-bit error occurred. See L2C_MCI_ERR for logged information. */
+	uint64_t vbfdbe                       : 1;  /**< VBF double-bit error occurred. See L2C_MCI(0..3)_ERR for logged information. */
+	uint64_t vbfsbe                       : 1;  /**< VBF single-bit error occurred. See L2C_MCI(0..3)_ERR for logged information. */
 #else
 	uint64_t vbfsbe                       : 1;
 	uint64_t vbfdbe                       : 1;
@@ -5716,15 +5960,52 @@ union cvmx_l2c_oci_ctl {
 	uint64_t u64;
 	struct cvmx_l2c_oci_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_3_63                : 61;
-	uint64_t iofrcl                       : 1;  /**< When set, L2C services all I/O reads and writes on the local node, regardless of the value
-                                                         of the node ID bits in the physical address. During normal operation this bit is expected
-                                                         to be 0. */
-	uint64_t gksegnode                    : 2;  /**< Initialized to OCI node on reset; writable by software. */
-#else
+	uint64_t reserved_17_63               : 47;
+	uint64_t shtoioen                     : 1;  /**< When set, any PP issues any of an IO load, acking store, IOBDMA, LMTDMA, acking IOBADDR,
+                                                         or acking LMTST to a node that doesn't exist (existence defined by the ENAOCI bits),
+                                                         then the hardware sets the SHTO CSR field. */
+	uint64_t shtoen                       : 3;  /**< When set, if the corresponding OCI link is down, the hardware sets the SHTO CSR field. */
+	uint64_t shto                         : 1;  /**< Use short timeout intervals. When set, PP will use SDIDTTO for both DID and commit counter
+                                                         timeouts, rather than DIDTTO/DIDTTO2. Similarly, L2C will use short instead of long
+                                                         timeout (FIXME -  more info needed) */
+	uint64_t inv_mode                     : 2;  /**< Describes how aggressive to be when waiting for local invalidates before sending OCI
+                                                         responses which act like commits at the remote. 0 - conservative mode, waits until all
+                                                         local invalidates have been sent by their respective CBCs to the PPs. 1 - moderate mode,
+                                                         waits until all local invalidates have been sent to their respective CBCs, but not
+                                                         necessarily actually sent to the PPs themselves. 2 - aggressive mode, does not wait for
+                                                         local invalidates to begin their processing. */
+	uint64_t cas_fdx                      : 1;  /**< When set, L2 STC/CAS operations performed at the home will immediately bring the block
+                                                         exclusive into the home. Default operation is to first request the block shared and only
+                                                         invalidate the remote if the compare succeeds. */
+	uint64_t rldd_psha                    : 1;  /**< When set, RLDD will be assumed to return a shared response (PSHA). Default operation will
+                                                         assume an exclusive response (PEMD). Note that an incorrect assumption only causes an
+                                                         extra tag write to be done upon receiving the response. */
+	uint64_t lock_local                   : 1;  /**< When set, L2 atomic operations (excluding CAS/STC) to remote addresses which miss at the
+                                                         requester will be performed locally on the requesting node. Default operation will instead
+                                                         send the atomic request to be performed on the home node. Note that CAS/STC operations
+                                                         which miss at the requester will always be performed at the home node regardless of this
+                                                         setting. */
+	uint64_t iofrcl                       : 1;  /**< When set, L2C services all I/O read and write operations on the local node, regardless of
+                                                         the value of the node ID bits in the physical address. During normal operation this bit is
+                                                         expected to be 0. */
+	uint64_t gksegnode                    : 2;  /**< Initialized to the OCX_COM_NODE[ID] value on reset, which will equal the OCI_NODE_ID pins
+                                                         on a cold reset, but could be something else on a chip warm or soft reset; writable by
+                                                         software. */
+	uint64_t enaoci                       : 4;  /**< Enable OCI processing (one per node_id). When set, perform OCI processing. When clear, OCI
+                                                         references cause
+                                                         RDDISOCI/WRDISOCI interrupts (NYI). */
+#else
+	uint64_t enaoci                       : 4;
 	uint64_t gksegnode                    : 2;
 	uint64_t iofrcl                       : 1;
-	uint64_t reserved_3_63                : 61;
+	uint64_t lock_local                   : 1;
+	uint64_t rldd_psha                    : 1;
+	uint64_t cas_fdx                      : 1;
+	uint64_t inv_mode                     : 2;
+	uint64_t shto                         : 1;
+	uint64_t shtoen                       : 3;
+	uint64_t shtoioen                     : 1;
+	uint64_t reserved_17_63               : 47;
 #endif
 	} s;
 	struct cvmx_l2c_oci_ctl_s             cn78xx;
@@ -6632,18 +6913,41 @@ union cvmx_l2c_tadx_dll {
 	uint64_t u64;
 	struct cvmx_l2c_tadx_dll_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t pd_pos_rclk_refclk           : 1;  /**< Phase detector output. */
+	uint64_t pdl_rclk_refclk              : 1;  /**< Phase detector output. */
+	uint64_t pdr_rclk_refclk              : 1;  /**< Phase detector output. */
+	uint64_t clk_invert                   : 1;  /**< Clock invert. */
+	uint64_t dly_elem_enable              : 16; /**< Delay element enable. */
+	uint64_t dll_setting                  : 12; /**< DLL setting. */
+	uint64_t dll_state                    : 3;  /**< DLL state. */
+	uint64_t dll_lock                     : 1;  /**< DLL locked. */
+#else
+	uint64_t dll_lock                     : 1;
+	uint64_t dll_state                    : 3;
+	uint64_t dll_setting                  : 12;
+	uint64_t dly_elem_enable              : 16;
+	uint64_t clk_invert                   : 1;
+	uint64_t pdr_rclk_refclk              : 1;
+	uint64_t pdl_rclk_refclk              : 1;
+	uint64_t pd_pos_rclk_refclk           : 1;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_l2c_tadx_dll_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t dll_setting                  : 12; /**< DLL setting. */
 	uint64_t dll_state                    : 3;  /**< DLL state. */
-	uint64_t dll_lock                     : 1;  /**< ==1, DLL is locked. */
+	uint64_t dll_lock                     : 1;  /**< DLL locked. */
 #else
 	uint64_t dll_lock                     : 1;
 	uint64_t dll_state                    : 3;
 	uint64_t dll_setting                  : 12;
 	uint64_t reserved_16_63               : 48;
 #endif
-	} s;
-	struct cvmx_l2c_tadx_dll_s            cn70xx;
+	} cn70xx;
+	struct cvmx_l2c_tadx_dll_s            cn78xx;
 };
 typedef union cvmx_l2c_tadx_dll cvmx_l2c_tadx_dll_t;
 
@@ -6742,10 +7046,38 @@ union cvmx_l2c_tadx_err {
 	uint64_t bigwr                        : 1;  /**< Logged information is for a BIGWR error. */
 	uint64_t holerd                       : 1;  /**< Logged information is for a HOLERD error. */
 	uint64_t holewr                       : 1;  /**< Logged information is for a HOLEWR error. */
+	uint64_t reserved_59_59               : 1;
+	uint64_t cmd                          : 8;  /**< XMC command of request causing error. FIXME, needs better description for OCI */
+	uint64_t source                       : 7;  /**< XMC 'source' of request causing error. If SOURCE<6>==0, SOURCE<5:0> = PPID else
+                                                         SOURCE<3:0> is BUSID of IOB which made the request. */
+	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error. For BIG* errors NODE will always be the node
+                                                         logging the error (BIG* errors are logged at the home node). For HOLE* errors, NODE could
+                                                         be any OCI node in the system (HOLE* errors are logged at the requester node). */
+	uint64_t addr                         : 40; /**< XMC address causing the error. This field is the physical address after hole removal and
+                                                         index aliasing (if enabled). (The hole is between DR0 and DR1. Remove the hole by
+                                                         subtracting 256MB from all L2/DRAM physical addresses >= 512 MB.) */
+#else
+	uint64_t addr                         : 40;
+	uint64_t node                         : 4;
+	uint64_t source                       : 7;
+	uint64_t cmd                          : 8;
+	uint64_t reserved_59_59               : 1;
+	uint64_t holewr                       : 1;
+	uint64_t holerd                       : 1;
+	uint64_t bigwr                        : 1;
+	uint64_t bigrd                        : 1;
+#endif
+	} s;
+	struct cvmx_l2c_tadx_err_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t bigrd                        : 1;  /**< Logged information is for a BIGRD error. */
+	uint64_t bigwr                        : 1;  /**< Logged information is for a BIGWR error. */
+	uint64_t holerd                       : 1;  /**< Logged information is for a HOLERD error. */
+	uint64_t holewr                       : 1;  /**< Logged information is for a HOLEWR error. */
 	uint64_t reserved_58_59               : 2;
 	uint64_t cmd                          : 7;  /**< XMC command of request causing error. */
-	uint64_t source                       : 7;  /**< XMC 'source' of request causing error. If SOURCE<6>==0, SOURCE<5:0>=PPID else SOURCE<3:0>
-                                                         is BUSID of IOB which made the request. */
+	uint64_t source                       : 7;  /**< XMC 'source' of request causing error. If SOURCE<6>==0, SOURCE<5:0> = PPID else
+                                                         SOURCE<3:0> is BUSID of IOB which made the request. */
 	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error. For BIG* errors NODE will always be the node
                                                          logging the error (BIG* errors are logged at the home node). For HOLE* errors, NODE could
                                                          be any OCI node in the system (HOLE* errors are logged at the requester node). */
@@ -6763,8 +7095,7 @@ union cvmx_l2c_tadx_err {
 	uint64_t bigwr                        : 1;
 	uint64_t bigrd                        : 1;
 #endif
-	} s;
-	struct cvmx_l2c_tadx_err_s            cn70xx;
+	} cn70xx;
 	struct cvmx_l2c_tadx_err_s            cn78xx;
 };
 typedef union cvmx_l2c_tadx_err cvmx_l2c_tadx_err_t;
@@ -6874,7 +7205,9 @@ union cvmx_l2c_tadx_int {
 	uint64_t u64;
 	struct cvmx_l2c_tadx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_34_63               : 30;
+	uint64_t reserved_36_63               : 28;
+	uint64_t wrdisoci                     : 1;  /**< (NYI) Illegal write operation to a remote node with L2C_TAD_CTL[ENAOCI] clear. */
+	uint64_t rddisoci                     : 1;  /**< (NYI) Illegal read operation to a remote node with L2C_TAD_CTL[ENAOCI] clear. */
 	uint64_t rtgdbe                       : 1;  /**< RTG double-bit error */
 	uint64_t rtgsbe                       : 1;  /**< RTG single-bit error */
 	uint64_t reserved_15_31               : 17;
@@ -6900,7 +7233,9 @@ union cvmx_l2c_tadx_int {
 	uint64_t reserved_15_31               : 17;
 	uint64_t rtgsbe                       : 1;
 	uint64_t rtgdbe                       : 1;
-	uint64_t reserved_34_63               : 30;
+	uint64_t rddisoci                     : 1;
+	uint64_t wrdisoci                     : 1;
+	uint64_t reserved_36_63               : 28;
 #endif
 	} s;
 	struct cvmx_l2c_tadx_int_cn61xx {
@@ -6961,22 +7296,22 @@ union cvmx_l2c_tadx_int {
 	uint64_t holerd                       : 1;  /**< Read reference to 256MB hole occurred. */
 	uint64_t holewr                       : 1;  /**< Write reference to 256MB hole occurred. */
 	uint64_t noway                        : 1;  /**< No way was available for allocation. L2C sets NOWAY during its processing of a transaction
-                                                         whenever it needed/wanted to allocate a WAY in the L2 cache, but was unable to. NOWAY==1
-                                                         is (generally) not an indication that L2C failed to complete transactions. Rather, it is a
-                                                         hint of possible performance degradation. (For example, L2C must read-modify-write DRAM
-                                                         for every transaction that updates some, but not all, of the bytes in a cache block,
-                                                         misses in the L2 cache, and cannot allocate a WAY.) There is one 'failure' case where L2C
-                                                         will set NOWAY: when it cannot leave a block locked in the L2 cache as part of a LCKL2
-                                                         transaction. See L2C_TTG_ERR for logged information. */
-	uint64_t tagdbe                       : 1;  /**< TAG double-bit error occurred. See L2C_TTG_ERR for logged information. */
-	uint64_t tagsbe                       : 1;  /**< TAG single-bit error occurred. See L2C_TTG_ERR for logged information. */
+                                                         whenever it needed/wanted to allocate a WAY in the L2 cache, but was unable to. When this
+                                                         bit = 1, it is (generally) not an indication that L2C failed to complete transactions.
+                                                         Rather, it is a hint of possible performance degradation. (For example, L2C must read-
+                                                         modify-write DRAM for every transaction that updates some, but not all, of the bytes in a
+                                                         cache block, misses in the L2 cache, and cannot allocate a WAY.) There is one 'failure'
+                                                         case where L2C sets NOWAY: when it cannot leave a block locked in the L2 cache as part of
+                                                         a LCKL2 transaction. See L2C_TTG(0..7)_ERR for logged information. */
+	uint64_t tagdbe                       : 1;  /**< TAG double-bit error occurred. See L2C_TTG(0..7)_ERR for logged information. */
+	uint64_t tagsbe                       : 1;  /**< TAG single-bit error occurred. See L2C_TTG(0..7)_ERR for logged information. */
 	uint64_t reserved_6_7                 : 2;
-	uint64_t fbfdbe                       : 1;  /**< FBF double-bit error occurred. See L2C_TQD_ERR for logged information. */
-	uint64_t fbfsbe                       : 1;  /**< FBF single-bit error occurred. See L2C_TQD_ERR for logged information. */
-	uint64_t sbfdbe                       : 1;  /**< SBF double-bit error occurred. See L2C_TQD_ERR for logged information. */
-	uint64_t sbfsbe                       : 1;  /**< SBF single-bit error occurred. See L2C_TQD_ERR for logged information. */
-	uint64_t l2ddbe                       : 1;  /**< L2D double-bit error occurred. See L2C_TQD_ERR for logged information. */
-	uint64_t l2dsbe                       : 1;  /**< L2D single-bit error occurred. See L2C_TQD_ERR for logged information. */
+	uint64_t fbfdbe                       : 1;  /**< FBF double-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t fbfsbe                       : 1;  /**< FBF single-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t sbfdbe                       : 1;  /**< SBF double-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t sbfsbe                       : 1;  /**< SBF single-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t l2ddbe                       : 1;  /**< L2D double-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t l2dsbe                       : 1;  /**< L2D single-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
 #else
 	uint64_t l2dsbe                       : 1;
 	uint64_t l2ddbe                       : 1;
@@ -7000,7 +7335,62 @@ union cvmx_l2c_tadx_int {
 	uint64_t reserved_34_63               : 30;
 #endif
 	} cn70xx;
-	struct cvmx_l2c_tadx_int_cn70xx       cn78xx;
+	struct cvmx_l2c_tadx_int_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t wrdisoci                     : 1;  /**< (NYI) Illegal write operation to a remote node with L2C_TAD_CTL[ENAOCI] clear. */
+	uint64_t rddisoci                     : 1;  /**< (NYI) Illegal read operation to a remote node with L2C_TAD_CTL[ENAOCI] clear. */
+	uint64_t rtgdbe                       : 1;  /**< RTG double-bit error */
+	uint64_t rtgsbe                       : 1;  /**< RTG single-bit error */
+	uint64_t reserved_17_31               : 15;
+	uint64_t wrdislmc                     : 1;  /**< Illegal write to disabled LMC error. A DRAM write arrived before the LMC(s) were enabled. */
+	uint64_t rddislmc                     : 1;  /**< Illegal read to disabled LMC error. A DRAM read arrived before the LMC(s) were enabled. */
+	uint64_t bigrd                        : 1;  /**< Read reference past L2C_BIG_CTL[MAXDRAM] occurred. */
+	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. */
+	uint64_t holerd                       : 1;  /**< Read reference to 256MB hole occurred. */
+	uint64_t holewr                       : 1;  /**< Write reference to 256MB hole occurred. */
+	uint64_t noway                        : 1;  /**< No way was available for allocation. L2C sets NOWAY during its processing of a transaction
+                                                         whenever it needed/wanted to allocate a WAY in the L2 cache, but was unable to. When this
+                                                         bit = 1, it is (generally) not an indication that L2C failed to complete transactions.
+                                                         Rather, it is a hint of possible performance degradation. (For example, L2C must read-
+                                                         modify-write DRAM for every transaction that updates some, but not all, of the bytes in a
+                                                         cache block, misses in the L2 cache, and cannot allocate a WAY.) There is one 'failure'
+                                                         case where L2C sets NOWAY: when it cannot leave a block locked in the L2 cache as part of
+                                                         a LCKL2 transaction. See L2C_TTG(0..7)_ERR for logged information. */
+	uint64_t tagdbe                       : 1;  /**< TAG double-bit error occurred. See L2C_TTG(0..7)_ERR for logged information. */
+	uint64_t tagsbe                       : 1;  /**< TAG single-bit error occurred. See L2C_TTG(0..7)_ERR for logged information. */
+	uint64_t reserved_6_7                 : 2;
+	uint64_t fbfdbe                       : 1;  /**< FBF double-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t fbfsbe                       : 1;  /**< FBF single-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t sbfdbe                       : 1;  /**< SBF double-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t sbfsbe                       : 1;  /**< SBF single-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t l2ddbe                       : 1;  /**< L2D double-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+	uint64_t l2dsbe                       : 1;  /**< L2D single-bit error occurred. See L2C_TQD(0..7)_ERR for logged information. */
+#else
+	uint64_t l2dsbe                       : 1;
+	uint64_t l2ddbe                       : 1;
+	uint64_t sbfsbe                       : 1;
+	uint64_t sbfdbe                       : 1;
+	uint64_t fbfsbe                       : 1;
+	uint64_t fbfdbe                       : 1;
+	uint64_t reserved_6_7                 : 2;
+	uint64_t tagsbe                       : 1;
+	uint64_t tagdbe                       : 1;
+	uint64_t noway                        : 1;
+	uint64_t holewr                       : 1;
+	uint64_t holerd                       : 1;
+	uint64_t bigwr                        : 1;
+	uint64_t bigrd                        : 1;
+	uint64_t rddislmc                     : 1;
+	uint64_t wrdislmc                     : 1;
+	uint64_t reserved_17_31               : 15;
+	uint64_t rtgsbe                       : 1;
+	uint64_t rtgdbe                       : 1;
+	uint64_t rddisoci                     : 1;
+	uint64_t wrdisoci                     : 1;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} cn78xx;
 	struct cvmx_l2c_tadx_int_cn61xx       cnf71xx;
 };
 typedef union cvmx_l2c_tadx_int cvmx_l2c_tadx_int_t;
@@ -7209,26 +7599,12 @@ union cvmx_l2c_tadx_tag {
 	uint64_t u64;
 	struct cvmx_l2c_tadx_tag_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits. 70xx does not implement true sub-block dirty bits, therefore when
-                                                         L2C_TAD_TAG is written, it is set to all ones if DIRTY is 1, or all zeroes if DIRTY is
-                                                         zero. LTGL2I will always result in similar legal values being loaded. */
-	uint64_t reserved_57_59               : 3;
-	uint64_t businfo                      : 9;  /**< The bus info bits */
-	uint64_t reserved_47_47               : 1;
-	uint64_t ecc                          : 7;  /**< The tag ECC */
-	uint64_t reserved_3_39                : 37;
-	uint64_t valid                        : 1;  /**< The valid bit */
-	uint64_t dirty                        : 1;  /**< The dirty bit */
+	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits.  Ignored/loaded with 0 for RTG accesses. */
+	uint64_t reserved_1_59                : 59;
 	uint64_t lock                         : 1;  /**< The lock bit */
 #else
 	uint64_t lock                         : 1;
-	uint64_t dirty                        : 1;
-	uint64_t valid                        : 1;
-	uint64_t reserved_3_39                : 37;
-	uint64_t ecc                          : 7;
-	uint64_t reserved_47_47               : 1;
-	uint64_t businfo                      : 9;
-	uint64_t reserved_57_59               : 3;
+	uint64_t reserved_1_59                : 59;
 	uint64_t sblkdty                      : 4;
 #endif
 	} s;
@@ -7262,9 +7638,9 @@ union cvmx_l2c_tadx_tag {
 	struct cvmx_l2c_tadx_tag_cn61xx       cn68xxp1;
 	struct cvmx_l2c_tadx_tag_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits. 70xx does not implement true sub-block dirty bits, therefore when
-                                                         L2C_TAD_TAG is written, it is set to all ones if DIRTY is 1, or all zeroes if DIRTY is
-                                                         zero. LTGL2I will always result in similar legal values being loaded. */
+	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits. INTERNAL: 70xx does not implement true sub-block dirty bits,
+                                                         therefore when L2C_TAD_TAG is written, it is set to all ones if DIRTY is 1, or all zeroes
+                                                         if DIRTY is zero. LTGL2I will always result in similar legal values being loaded. */
 	uint64_t reserved_56_59               : 4;
 	uint64_t businfo                      : 8;  /**< The businfo bits. Legal values: when [55]==1, we are in idmode and [54:50] must be 0,
                                                          [49:48] are the PPVID of the PP which could be holding the block; when [55]==0, we are in
@@ -7297,32 +7673,32 @@ union cvmx_l2c_tadx_tag {
 	} cn70xx;
 	struct cvmx_l2c_tadx_tag_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits. 70xx does not implement true sub-block dirty bits, therefore when
-                                                         L2C_TAD_TAG is written, it is set to all ones if DIRTY is 1, or all zeroes if DIRTY is
-                                                         zero. LTGL2I will always result in similar legal values being loaded. */
-	uint64_t reserved_57_59               : 3;
-	uint64_t businfo                      : 9;  /**< The bus info bits */
-	uint64_t reserved_47_47               : 1;
-	uint64_t ecc                          : 7;  /**< The tag ECC. This field is undefined if L2C_CTL[DISECC] is not 1 when the LTGL2I reads the tags. */
-	uint64_t tag                          : 20; /**< The tag. The tag is the corresponding bits from the L2C+LMC internal L2/DRAM byte address. */
+	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits.  Ignored/loaded with 0 for RTG accesses. */
+	uint64_t reserved_58_59               : 2;
+	uint64_t businfo                      : 9;  /**< The bus information bits.  Ignored/loaded with 0 for RTG accesses. */
+	uint64_t ecc                          : 7;  /**< The tag ECC. This field is undefined if L2C_CTL[DISECC] is not 1 when the LTGL2I reads the
+                                                         tags. */
+	uint64_t tag                          : 22; /**< The tag. TAG[39:20] is the corresponding bits from the L2C+LMC internal L2/DRAM byte
+                                                         address. TAG[41:40] is the OCI node of the address. The RTG must always have the
+                                                         TAG[41:40] == to
+                                                         the current node or operation is undefined. */
 	uint64_t reserved_4_19                : 16;
 	uint64_t used                         : 1;  /**< The LRU use bit. If setting the LOCK bit, the USE bit should also be set or the operation
-                                                         is undefined. */
-	uint64_t valid                        : 1;  /**< The valid bit */
-	uint64_t dirty                        : 1;  /**< The dirty bit */
+                                                         is undefined.  Ignored/loaded with 0 for RTG accesses. */
+	uint64_t ts                           : 2;  /**< The TAG state. 0 - Invalid; 1 - Shared; 2 - Exclusive. Note that a local address will
+                                                         never have the value of 2 (Exclusive) as that state is encoded as Shared in the TAG and
+                                                         Invalid in the RTG. */
 	uint64_t lock                         : 1;  /**< The lock bit. If setting the LOCK bit, the USE bit should also be set or the operation is
-                                                         undefined. */
+                                                         undefined.  Ignored/loaded with 0 for RTG accesses. */
 #else
 	uint64_t lock                         : 1;
-	uint64_t dirty                        : 1;
-	uint64_t valid                        : 1;
+	uint64_t ts                           : 2;
 	uint64_t used                         : 1;
 	uint64_t reserved_4_19                : 16;
-	uint64_t tag                          : 20;
+	uint64_t tag                          : 22;
 	uint64_t ecc                          : 7;
-	uint64_t reserved_47_47               : 1;
 	uint64_t businfo                      : 9;
-	uint64_t reserved_57_59               : 3;
+	uint64_t reserved_58_59               : 2;
 	uint64_t sblkdty                      : 4;
 #endif
 	} cn78xx;
@@ -7337,8 +7713,8 @@ typedef union cvmx_l2c_tadx_tag cvmx_l2c_tadx_tag_t;
  * though there are 32 LFBs/VABs in a full TAD, the number applies to both halves.
  * If MAXLFB is != 0, VBF_THRESH should be less than MAXLFB.
  * If MAXVBF is != 0, VBF_THRESH should be less than MAXVBF.
- * If MAXLFB == 0, EXLRQ + EXRRQ + EXFWD + EXVIC must be less than or equal to 13.
- * If MAXLFB != 0, EXLRQ + EXRRQ + EXFWD + EXVIC must be less than or equal to MAXLFB-3.
+ * If MAXLFB = 0, EXLRQ + EXRRQ + EXFWD + EXVIC must be less than or equal to 13.
+ * If MAXLFB != 0, EXLRQ + EXRRQ + EXFWD + EXVIC must be less than or equal to MAXLFB - 3.
  */
 union cvmx_l2c_tad_ctl {
 	uint64_t u64;
@@ -7346,15 +7722,15 @@ union cvmx_l2c_tad_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
 	uint64_t exlrq                        : 4;  /**< Extra LFBs to reserve for locally generated XMC commands. None are reserved for functional
-                                                         correctness. */
+                                                         correctness. Ignored if L2C_OCI_CTL[ENAOCI] is 0. */
 	uint64_t exrrq                        : 4;  /**< Extra LFBs to reserve for Rxxx OCI commands beyond the 1 required for OCI protocol
-                                                         functional correctness. */
+                                                         functional correctness. Ignored if L2C_OCI_CTL[ENAOCI] is 0. */
 	uint64_t exfwd                        : 4;  /**< Extra LFBs to reserve for Fxxx/SINV OCI commands beyond the 1 required for OCI protocol
-                                                         functional correctness. */
+                                                         functional correctness. Ignored if L2C_OCI_CTL[ENAOCI] is 0. */
 	uint64_t exvic                        : 4;  /**< Extra LFBs to reserve for VICx OCI commands beyond the 1 required for OCI protocol
-                                                         functional correctness. */
+                                                         functional correctness. Ignored if L2C_OCI_CTL[ENAOCI] is 0. */
 	uint64_t vbf_thresh                   : 4;  /**< VBF threshold. When the number of in-use VBFs exceeds this number the L2C TAD increases
-                                                         the priority of all its writes in the LMC. */
+                                                         the priority of all its write operations in the LMC. */
 	uint64_t maxvbf                       : 4;  /**< Maximum VBFs in use at once (0 means 16, 1-15 as expected). */
 	uint64_t maxlfb                       : 4;  /**< Maximum VABs/LFBs in use at once (0 means 16, 1-15 as expected). */
 #else
@@ -7372,7 +7748,7 @@ union cvmx_l2c_tad_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_11_63               : 53;
 	uint64_t vbf_thresh                   : 3;  /**< VBF threshold. When the number of in-use VBFs exceeds this number the L2C TAD increases
-                                                         the priority of all its writes in the LMC. */
+                                                         the priority of all its write operations in the LMC. */
 	uint64_t reserved_7_7                 : 1;
 	uint64_t maxvbf                       : 3;  /**< Maximum VABs/LFBs in use at once (0 means 16, 1-15 as expected). */
 	uint64_t reserved_3_3                 : 1;
@@ -7486,11 +7862,11 @@ union cvmx_l2c_ttgx_bist_status {
 	struct cvmx_l2c_ttgx_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t rtgfl                        : 16; /**< BIST failure status for RTG ways 0-15 */
+	uint64_t rtgfl                        : 16; /**< BIST failure status for RTG ways. */
 	uint64_t reserved_18_31               : 14;
-	uint64_t lrulfbfl                     : 1;  /**< BIST failure status for LRULFB memory */
+	uint64_t lrulfbfl                     : 1;  /**< Reserved, always zero. */
 	uint64_t lrufl                        : 1;  /**< BIST failure status for tag LRU */
-	uint64_t tagfl                        : 16; /**< BIST failure status for TAG ways 0-15 */
+	uint64_t tagfl                        : 16; /**< BIST failure status for TAG ways. */
 #else
 	uint64_t tagfl                        : 16;
 	uint64_t lrufl                        : 1;
@@ -7950,7 +8326,7 @@ union cvmx_l2c_wpar_iobx {
 	struct cvmx_l2c_wpar_iobx_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t mask                         : 4;  /**< Way partitioning mask (1 means do not use). The read value of MASK will include bits set
+	uint64_t mask                         : 4;  /**< Way partitioning mask (1 means do not use). The read value of MASK includes bits set
                                                          because of the L2C cripple fuses. */
 #else
 	uint64_t mask                         : 4;
@@ -7992,7 +8368,7 @@ union cvmx_l2c_wpar_ppx {
 	struct cvmx_l2c_wpar_ppx_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t mask                         : 4;  /**< Way partitioning mask (1 means do not use). The read value of MASK will include bits set
+	uint64_t mask                         : 4;  /**< Way partitioning mask (1 means do not use). The read value of MASK includes bits set
                                                          because of the L2C cripple fuses. */
 #else
 	uint64_t mask                         : 4;
@@ -8037,18 +8413,18 @@ typedef union cvmx_l2c_xmcx_pfc cvmx_l2c_xmcx_pfc_t;
  * Note the following:
  * The ADD bus command chosen must not be a IOB-destined command or operation is UNDEFINED.
  * The ADD bus command will have SID forced to IOB, DID forced to L2C, no virtualization checks
- * performed (always pass), and xmdmsk forced to 0. Note that this implies that commands which
+ * performed (always pass), and xmdmsk forced to 0. Note that this implies that commands that
  * REQUIRE a STORE cycle (STP, STC, SAA, FAA, FAS) should not be used or the results are
- * unpredictable. The sid=IOB means that the way partitioning used for the command is
- * L2C_WPAR_IOB0/1. None of L2C_QOS_IOB0/1, L2C_QOS_PP(0..31), L2C_VIRTID_IOB0/1,
- * L2C_VIRTID_PP(0..31) are used for these commands.
+ * unpredictable. The sid = IOB means that the way partitioning used for the command is
+ * L2C_WPAR_IOB(0..1). Neither L2C_QOS_IOB(0..1) or L2C_QOS_PP(0..47) are used for these
+ * commands.
  * Any FILL responses generated by the ADD bus command are ignored. Generated STINs, however,
  * will correctly invalidate the required cores.
  * Any L2D read generated by the ADD bus command records the syndrome information in
  * L2C_TAD(0..3)_ECC0/1. If ECC is disabled prior to the CSR write, this provides the ability to
  * read the ECC bits directly. If ECC is not disabled, this should log zeros (assuming no ECC
  * errors were found in the block).
- * A write which arrives while the INUSE bit is set will block until the INUSE bit clears. This
+ * A write that arrives while the INUSE bit is set will block until the INUSE bit clears. This
  * gives software two options when needing to issue a stream of write operations to L2C_XMC_CMD:
  * polling on the INUSE bit, or allowing hardware to handle the interlock -- at the expense of
  * locking up the RSL bus for potentially tens of cycles at a time while waiting for an available
@@ -8068,7 +8444,7 @@ union cvmx_l2c_xmc_cmd {
                                                          ordered relative to other traffic) and HW can accept
                                                          another command. */
 	uint64_t reserved_47_62               : 16;
-	uint64_t qos                          : 3;  /**< QOS level to use for simulated XMC request. */
+	uint64_t qos                          : 3;  /**< QOS level to use for simulated ADD bus request. */
 	uint64_t node                         : 4;  /**< OCI node to use for simulated ADD bus request. */
 	uint64_t addr                         : 40; /**< Address to use for simulated XMC request (see Note 6) */
 #else
@@ -8108,12 +8484,12 @@ union cvmx_l2c_xmc_cmd {
                                                          another command. */
 	uint64_t cmd                          : 7;  /**< Command to use for simulated ADD bus request. A new request can be accepted. */
 	uint64_t reserved_47_55               : 9;
-	uint64_t qos                          : 3;  /**< QOS level to use for simulated XMC request. */
+	uint64_t qos                          : 3;  /**< QOS level to use for simulated ADD bus request. */
 	uint64_t node                         : 4;  /**< OCI node to use for simulated ADD bus request. */
-	uint64_t addr                         : 40; /**< Address to use for simulated ADD bus request. (See note The address written to L2C_XMC_CMD
-                                                         is a physical address. L2C performs hole removal and index aliasing (if enabled) on the
-                                                         written address and uses that for the command. This hole removed/index aliased address is
-                                                         what is returned on a read of the L2C_XMC_CMD register..) */
+	uint64_t addr                         : 40; /**< Address to use for simulated ADD bus request. (The address written to L2C_XMC_CMD is a
+                                                         physical address. L2C performs hole removal and index aliasing (if enabled) on the written
+                                                         address and uses that for the command. This hole-removed/index-aliased address is what is
+                                                         returned on a read of L2C_XMC_CMD.) */
 #else
 	uint64_t addr                         : 40;
 	uint64_t node                         : 4;
diff --git a/arch/mips/include/asm/octeon/cvmx-l2c.h b/arch/mips/include/asm/octeon/cvmx-l2c.h
index 6a1a9c3..9b9b538 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2c.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2c.h
@@ -43,7 +43,7 @@
  * Interface to the Level 2 Cache (L2C) control, measurement, and debugging
  * facilities.
  *
- * <hr>$Revision: 84158 $<hr>
+ * <hr>$Revision: 89914 $<hr>
  *
  */
 
@@ -59,13 +59,13 @@
 #define CVMX_L2C_MEMBANK_SELECT_SIZE  4096
 
 /* Maximium number of TADs */
-#define CVMX_L2C_MAX_TADS     4
+#define CVMX_L2C_MAX_TADS     8
 /* Maximium number of L2C performance counters */
 #define CVMX_L2C_MAX_PCNT     4
 
 /* Number of L2C Tag-and-data sections (TADs) that are connected to LMC. */
-#define CVMX_L2C_TADS  ((OCTEON_IS_MODEL(OCTEON_CN68XX) \
-			 || OCTEON_IS_MODEL(OCTEON_CN78XX)) ? 4 : 1)
+#define CVMX_L2C_TADS  ((OCTEON_IS_MODEL(OCTEON_CN68XX)) ? 4 : \
+			(OCTEON_IS_MODEL(OCTEON_CN78XX)) ? 8 : 1)
 /* Number of L2C IOBs connected to LMC. */
 #define CVMX_L2C_IOBS  ((OCTEON_IS_MODEL(OCTEON_CN68XX) \
 			 || OCTEON_IS_MODEL(OCTEON_CN78XX)) ? 2 : 1)
@@ -192,6 +192,22 @@ enum cvmx_l2c_tad_event {
 	CVMX_L2C_TAD_EVENT_QUAD3_READ = 177,	/* Quad 3 read data bus inuse */
 	CVMX_L2C_TAD_EVENT_QUAD3_BANK = 178,	/* Quad 3 \# banks inuse (0-4/cycle) */
 	CVMX_L2C_TAD_EVENT_QUAD3_WDAT = 179,	/* Quad 3 wdat flops inuse (0-4/cycle) */
+	CVMX_L2C_TAD_EVENT_QUAD4_INDEX = 192,	/* Quad 4 index bus inuse */
+	CVMX_L2C_TAD_EVENT_QUAD4_READ = 193,	/* Quad 4 read data bus inuse */
+	CVMX_L2C_TAD_EVENT_QUAD4_BANK = 194,	/* Quad 4 \# banks inuse (0-4/cycle) */
+	CVMX_L2C_TAD_EVENT_QUAD4_WDAT = 195,	/* Quad 4 wdat flops inuse (0-4/cycle) */
+	CVMX_L2C_TAD_EVENT_QUAD5_INDEX = 208,	/* Quad 5 index bus inuse */
+	CVMX_L2C_TAD_EVENT_QUAD5_READ = 209,	/* Quad 5 read data bus inuse */
+	CVMX_L2C_TAD_EVENT_QUAD5_BANK = 210,	/* Quad 5 \# banks inuse (0-4/cycle) */
+	CVMX_L2C_TAD_EVENT_QUAD5_WDAT = 211,	/* Quad 5 wdat flops inuse (0-4/cycle) */
+	CVMX_L2C_TAD_EVENT_QUAD6_INDEX = 224,	/* Quad 6 index bus inuse */
+	CVMX_L2C_TAD_EVENT_QUAD6_READ = 225,	/* Quad 6 read data bus inuse */
+	CVMX_L2C_TAD_EVENT_QUAD6_BANK = 226,	/* Quad 6 \# banks inuse (0-4/cycle) */
+	CVMX_L2C_TAD_EVENT_QUAD6_WDAT = 227,	/* Quad 6 wdat flops inuse (0-4/cycle) */
+	CVMX_L2C_TAD_EVENT_QUAD7_INDEX = 240,	/* Quad 7 index bus inuse */
+	CVMX_L2C_TAD_EVENT_QUAD7_READ = 241,	/* Quad 7 read data bus inuse */
+	CVMX_L2C_TAD_EVENT_QUAD7_BANK = 242,	/* Quad 7 \# banks inuse (0-4/cycle) */
+	CVMX_L2C_TAD_EVENT_QUAD7_WDAT = 243,	/* Quad 7 wdat flops inuse (0-4/cycle) */
 	CVMX_L2C_TAD_EVENT_MAX
 };
 typedef enum cvmx_l2c_tad_event cvmx_l2c_tad_event_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-l2d-defs.h b/arch/mips/include/asm/octeon/cvmx-l2d-defs.h
index 37a377e..73d4f1c 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2d-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2d-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-l2t-defs.h b/arch/mips/include/asm/octeon/cvmx-l2t-defs.h
index b16becf..21dea30 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2t-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2t-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-lapx-defs.h b/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
index 84487a1..d3e35ff 100644
--- a/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -337,11 +337,10 @@ union cvmx_lapx_cfg {
                                                          When ENA transitions from 0 to 1, LAP will build the free list and empty all queue lists.
                                                          Results are unpredictable if ENA is toggled with traffic outstanding. */
 	uint64_t lab_size                     : 3;  /**< Number of LABs versus size of each LAB. This register may only be changed when [ENA]=0.
-                                                         0x0 = 96 LABs, 16 words/LAB (1024 bits)
-                                                         0x1 = 128 LABs, 12 words/LAB (768 bits)
-                                                         0x2 = 192 LABs, 8 words/LAB (512 bits)
-                                                         0x3 = 256 LABs, 6 words/LAB (384 bits)
-                                                         0x4-0x7 Reserved */
+                                                         0x0 = 128 LABs, 16 words/LAB (1024 bits)
+                                                         0x1 = 170 LABs, 12 words/LAB (768 bits)
+                                                         0x2 = 256 LABs, 8 words/LAB (512 bits)
+                                                         0x3-0x7 Reserved */
 #else
 	uint64_t lab_size                     : 3;
 	uint64_t ena                          : 1;
@@ -364,11 +363,11 @@ union cvmx_lapx_edat_err_st {
 	struct cvmx_lapx_edat_err_st_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_24_63               : 40;
-	uint64_t fsyn                         : 8;  /**< Syndrome of last Expected Mask Ram ECC error. Latched when LAP0/1_GEN_INT[EDAT_SBE] or
+	uint64_t fsyn                         : 8;  /**< Syndrome of last Expected Mask Ram ECC error. Latched when LAP(0..1)_GEN_INT[EDAT_SBE] or
                                                          [EDAT_DBE] set */
 	uint64_t reserved_4_15                : 12;
 	uint64_t fadr                         : 4;  /**< Address of last Expected Mask Ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[EDAT_SBE] or [EDAT_DBE] set. */
+                                                         LAP(0..1)_GEN_INT[EDAT_SBE] or [EDAT_DBE] set. */
 #else
 	uint64_t fadr                         : 4;
 	uint64_t reserved_4_15                : 12;
@@ -389,10 +388,10 @@ union cvmx_lapx_emsk_err_st {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_24_63               : 40;
 	uint64_t fsyn                         : 8;  /**< Syndrome of last Expected Data Ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[EMSK_SBE] or [EMSK_DBE] set */
+                                                         LAP(0..1)_GEN_INT[EMSK_SBE] or [EMSK_DBE] set */
 	uint64_t reserved_4_15                : 12;
 	uint64_t fadr                         : 4;  /**< Address of last Expected Data Ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[EMSK_SBE] or [EMSK_DBE] set. */
+                                                         LAP(0..1)_GEN_INT[EMSK_SBE] or [EMSK_DBE] set. */
 #else
 	uint64_t fadr                         : 4;
 	uint64_t reserved_4_15                : 12;
@@ -463,7 +462,7 @@ union cvmx_lapx_expx_data {
 	struct cvmx_lapx_expx_data_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t data                         : 64; /**< Data value expected. The packet must have bits matching this value if the corresponding
-                                                         bits in LAP0/1_EXP(0..15)_VALID are set. */
+                                                         bits in LAP(0..1)_EXP(0..15)_VALID are set. */
 #else
 	uint64_t data                         : 64;
 #endif
@@ -483,12 +482,12 @@ union cvmx_lapx_expx_valid {
 	struct cvmx_lapx_expx_valid_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t valid                        : 64; /**< Valid mask. Each bit corresponds to a bit in
-                                                         LAP0/1_EXP(0..15)_VALID:
+                                                         LAP(0..1)_EXP(0..15)_VALID:
                                                          0 = Corresponding bit is a don't care.
                                                          1 = Corresponding bit compared against
-                                                         LAP0/1_EXP(0..15)_VALID.
+                                                         LAP(0..1)_EXP(0..15)_VALID.
                                                          Note that some response bits indicated by LAP_CTL_RTN_S are for Interlaken control, and
-                                                         thus should always be zero (don't care) in LAP0/1_EXP_VALID(0). */
+                                                         thus should always be zero (don't care) in LAP(0..1)_EXP_VALID(0). */
 #else
 	uint64_t valid                        : 64;
 #endif
@@ -536,31 +535,34 @@ union cvmx_lapx_gen_int {
 	uint64_t u64;
 	struct cvmx_lapx_gen_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_18_63               : 46;
+	uint64_t reserved_19_63               : 45;
+	uint64_t xid_bad                      : 1;  /**< A response packet's transaction ID was targeted to an LAB not in PROCESSING state. Not
+                                                         reported if packet also has CRC or MISMATCH errors. Typically indicates TCAM or
+                                                         configuration error. Throws LAP_INTSN_E::LAP(0..1)_GEN_XID_BAD. */
 	uint64_t nbr_dbe                      : 1;  /**< An ECC uncorrectable error has occurred in the NBR RAM. Throws
                                                          LAP_INTSN_E::LAP(0..1)_GEN_NBR_DBE. */
 	uint64_t nbr_sbe                      : 1;  /**< An ECC correctable error has occurred in the NBR RAM. Throws
                                                          LAP_INTSN_E::LAP(0..1)_GEN_NBR_SBE. */
 	uint64_t edat_dbe                     : 1;  /**< An ECC uncorrectable error has occurred in the EDAT RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_EDAT_DBE. See also LAP0/1_EDAT_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_EDAT_DBE. See also LAP(0..1)_EDAT_ERR_ST. */
 	uint64_t edat_sbe                     : 1;  /**< An ECC correctable error has occurred in the EDAT RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_EDAT_SBE. See also LAP0/1_EDAT_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_EDAT_SBE. See also LAP(0..1)_EDAT_ERR_ST. */
 	uint64_t emsk_dbe                     : 1;  /**< An ECC uncorrectable error has occurred in the EMSK RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_EMSK_DBE. See also LAP0/1_EMSK_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_EMSK_DBE. See also LAP(0..1)_EMSK_ERR_ST. */
 	uint64_t emsk_sbe                     : 1;  /**< An ECC correctable error has occurred in the EMSK RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_EMSK_SBE. See also LAP0/1_EMSK_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_EMSK_SBE. See also LAP(0..1)_EMSK_ERR_ST. */
 	uint64_t nxt_dbe                      : 1;  /**< An ECC uncorrectable error has occurred in the NXT RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_NXT_DBE. See also LAP0/1_NXT_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_NXT_DBE. See also LAP(0..1)_NXT_ERR_ST. */
 	uint64_t nxt_sbe                      : 1;  /**< An ECC correctable error has occurred in the NXT RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_NXT_SBE. See also LAP0/1_NXT_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_NXT_SBE. See also LAP(0..1)_NXT_ERR_ST. */
 	uint64_t sta_dbe                      : 1;  /**< An ECC uncorrectable error has occurred in the STA RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_STA_DBE. See also LAP0/1_STA_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_STA_DBE. See also LAP(0..1)_STA_ERR_ST. */
 	uint64_t sta_sbe                      : 1;  /**< An ECC correctable error has occurred in the STA RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_STA_SBE. See also LAP0/1_STA_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_STA_SBE. See also LAP(0..1)_STA_ERR_ST. */
 	uint64_t lab_dbe                      : 1;  /**< An ECC uncorrectable error has occurred in the LAB RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_LAB_DBE. See also LAP0/1_LAB_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_LAB_DBE. See also LAP(0..1)_LAB_ERR_ST. */
 	uint64_t lab_sbe                      : 1;  /**< An ECC correctable error has occurred in the LAB RAM. Throws
-                                                         LAP_INTSN_E::LAP(0..1)_GEN_LAB_SBE. See also LAP0/1_LAB_ERR_ST. */
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_LAB_SBE. See also LAP(0..1)_LAB_ERR_ST. */
 	uint64_t reserved_4_5                 : 2;
 	uint64_t timeout                      : 1;  /**< Indication timer transitioned an LAB to error state. This interrupt will typically be
                                                          masked off, as error delivery can be in-band. Throws LAP_INTSN_E::LAP(0..1)_GEN_TIMEOUT. */
@@ -568,8 +570,9 @@ union cvmx_lapx_gen_int {
                                                          exception queue for new packets. Throws LAP_INTSN_E::LAP(0..1)_GEN_NEW_EXC. */
 	uint64_t lost_exc                     : 1;  /**< Error indicating exception packet received with no LABs available on the exception queue;
                                                          the exception packet was dropped. Throws LAP_INTSN_E::LAP(0..1)_GEN_LOST_EXC. */
-	uint64_t labs_out                     : 1;  /**< Error indicating did push with no free LABs available, or LAP0/1_QUE(0..2)_CFG[MAX_LABS]
-                                                         was exceeded. Throws LAP_INTSN_E::LAP(0..1)_GEN_LABS_OUT. */
+	uint64_t labs_out                     : 1;  /**< Error indicating did push with no free LABs available, or
+                                                         LAP(0..1)_QUE(0..2)_CFG[MAX_LABS] was exceeded. Throws
+                                                         LAP_INTSN_E::LAP(0..1)_GEN_LABS_OUT. */
 #else
 	uint64_t labs_out                     : 1;
 	uint64_t lost_exc                     : 1;
@@ -588,7 +591,8 @@ union cvmx_lapx_gen_int {
 	uint64_t edat_dbe                     : 1;
 	uint64_t nbr_sbe                      : 1;
 	uint64_t nbr_dbe                      : 1;
-	uint64_t reserved_18_63               : 46;
+	uint64_t xid_bad                      : 1;
+	uint64_t reserved_19_63               : 45;
 #endif
 	} s;
 	struct cvmx_lapx_gen_int_s            cn78xx;
@@ -633,7 +637,7 @@ typedef union cvmx_lapx_labx_state cvmx_lapx_labx_state_t;
  * cvmx_lap#_lab_data#
  *
  * "This register reads raw data from the LABs. The address is calculated from (LAB#  *
- * words_per_lab_from_table_in_LAP0/1_CFG[LAB_SIZE] + offset_in_LAB) * 8."
+ * words_per_lab_from_table_in_LAP(0..1)_CFG[LAB_SIZE] + offset_in_LAB) * 8."
  */
 union cvmx_lapx_lab_datax {
 	uint64_t u64;
@@ -657,10 +661,10 @@ union cvmx_lapx_lab_err_st {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_26_63               : 38;
 	uint64_t fsyn                         : 10; /**< Syndrome of last LAB data ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[LAB_SBE] or [LAB_DBE] set */
+                                                         LAP(0..1)_GEN_INT[LAB_SBE] or [LAB_DBE] set */
 	uint64_t reserved_10_15               : 6;
 	uint64_t fadr                         : 10; /**< Address of last LAB data ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[LAB_SBE] or [LAB_DBE] set. */
+                                                         LAP(0..1)_GEN_INT[LAB_SBE] or [LAB_DBE] set. */
 #else
 	uint64_t fadr                         : 10;
 	uint64_t reserved_10_15               : 6;
@@ -681,10 +685,10 @@ union cvmx_lapx_nxt_err_st {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_21_63               : 43;
 	uint64_t fsyn                         : 5;  /**< Syndrome of last Next Pointer Ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[NXT_SBE] or [NXT_DBE] set */
+                                                         LAP(0..1)_GEN_INT[NXT_SBE] or [NXT_DBE] set */
 	uint64_t reserved_8_15                : 8;
 	uint64_t fadr                         : 8;  /**< Address of last Next Pointer Ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[NXT_SBE] or [NXT_DBE] set. */
+                                                         LAP(0..1)_GEN_INT[NXT_SBE] or [NXT_DBE] set. */
 #else
 	uint64_t fadr                         : 8;
 	uint64_t reserved_8_15                : 8;
@@ -705,9 +709,10 @@ union cvmx_lapx_quex_cfg {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
 	uint64_t max_labs                     : 9;  /**< Maximum number of LABS allowed to be assigned to this queue; compared against
-                                                         LAP0/1_QUE(0..2)_STATE[LABS_RX] + LAP0/1_QUE(0..2)_STATE[LABS_PROC] to generate errors.
-                                                         The total across all queues' [MAX_LABS] may be over-provisioned, in which case the global
-                                                         LAP0/1_SFT_RSTLAP0/1_CFG[LAB_SIZE] number of LABs will throttle the transaction count. */
+                                                         LAP(0..1)_QUE(0..2)_STATE[LABS_RX] + LAP(0..1)_QUE(0..2)_STATE[LABS_PROC] to generate
+                                                         errors. The total across all queues' [MAX_LABS] may be over-provisioned, in which case the
+                                                         global LAP(0..1)_SFT_RSTLAP(0..1)_CFG[LAB_SIZE] number of LABs will throttle the
+                                                         transaction count. */
 #else
 	uint64_t max_labs                     : 9;
 	uint64_t reserved_9_63                : 55;
@@ -815,10 +820,10 @@ union cvmx_lapx_sta_err_st {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_23_63               : 41;
 	uint64_t fsyn                         : 7;  /**< Syndrome of last LAB state ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[STA_SBE] or [STA_DBE] set */
+                                                         LAP(0..1)_GEN_INT[STA_SBE] or [STA_DBE] set */
 	uint64_t reserved_8_15                : 8;
 	uint64_t fadr                         : 8;  /**< Address of last LAB state ram ECC error. Latched when
-                                                         LAP0/1_GEN_INT[STA_SBE] or [STA_DBE] set. */
+                                                         LAP(0..1)_GEN_INT[STA_SBE] or [STA_DBE] set. */
 #else
 	uint64_t fadr                         : 8;
 	uint64_t reserved_8_15                : 8;
@@ -848,7 +853,7 @@ union cvmx_lapx_timeout {
 	uint64_t reserved_12_15               : 4;
 	uint64_t resp                         : 12; /**< Timeout waiting for a response in number of sclks minus one divided by 256. After between
                                                          one and two times this interval an in-flight LAB will be considered lost and marked as
-                                                         RECEIVED with error. RESP must be set to >= (2 * LAP0/1_TIMEOUT[IOBDMA] + 1).
+                                                         RECEIVED with error. RESP must be set to >= (2 * LAP(0..1)_TIMEOUT[IOBDMA] + 1).
                                                          0x0 = Timeout between 256 and 511 cycles
                                                          0x1 = Timeout between 512 and 1023 cycles
                                                          0x2 = Timeout between 768 and 1535 cycles
diff --git a/arch/mips/include/asm/octeon/cvmx-lbk-defs.h b/arch/mips/include/asm/octeon/cvmx-lbk-defs.h
index 13adc60..7f82745 100644
--- a/arch/mips/include/asm/octeon/cvmx-lbk-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lbk-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-led-defs.h b/arch/mips/include/asm/octeon/cvmx-led-defs.h
index 63b3b7c..f9b8a17 100644
--- a/arch/mips/include/asm/octeon/cvmx-led-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-led-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
index 447c0d7..3ce2632 100644
--- a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -600,6 +600,17 @@ static inline uint64_t CVMX_LMCX_DUAL_MEMCFG(unsigned long block_id)
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_LMCX_ECC_PARITY_TEST(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
+		cvmx_warn("CVMX_LMCX_ECC_PARITY_TEST(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180088000108ull) + ((block_id) & 3) * 0x1000000ull;
+}
+#else
+#define CVMX_LMCX_ECC_PARITY_TEST(block_id) (CVMX_ADD_IO_SEG(0x0001180088000108ull) + ((block_id) & 3) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_LMCX_ECC_SYND(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
@@ -1608,8 +1619,8 @@ union cvmx_lmcx_bist_ctl {
 	struct cvmx_lmcx_bist_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t dlcram_bist_status           : 1;  /**< DLC RAM BIST status, 1 means fail. */
-	uint64_t dlcram_bist_done             : 1;  /**< DLC RAM BIST complete indication, 1 means complete. */
+	uint64_t dlcram_bist_status           : 1;  /**< DLC RAM BIST status; 1 means fail. */
+	uint64_t dlcram_bist_done             : 1;  /**< DLC RAM BIST complete indication; 1 means complete. */
 	uint64_t start_bist                   : 1;  /**< Start BIST on DLC memory. */
 	uint64_t reserved_0_0                 : 1;
 #else
@@ -1636,10 +1647,10 @@ union cvmx_lmcx_bist_ctl {
 	struct cvmx_lmcx_bist_ctl_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t dlcram_bist_status           : 1;  /**< DLC RAM BIST status, 1 means fail. */
-	uint64_t dlcram_bist_done             : 1;  /**< DLC RAM BIST complete indication, 1 means complete. */
-	uint64_t start_bist                   : 1;  /**< Start BIST on DLC memory. */
-	uint64_t clear_bist                   : 1;  /**< Start clear BIST on DLC memory. */
+	uint64_t dlcram_bist_status           : 1;  /**< Reserved. */
+	uint64_t dlcram_bist_done             : 1;  /**< Reserved. */
+	uint64_t start_bist                   : 1;  /**< Reserved. */
+	uint64_t clear_bist                   : 1;  /**< Reserved. */
 #else
 	uint64_t clear_bist                   : 1;
 	uint64_t start_bist                   : 1;
@@ -1709,22 +1720,21 @@ typedef union cvmx_lmcx_bist_result cvmx_lmcx_bist_result_t;
 /**
  * cvmx_lmc#_char_ctl
  *
- * INTERNAL: This register is an assortment of various control fields needed to charecterize the
- * DDR3 interface.
+ * This register provides an assortment of various control fields needed to characterize the DDR3
+ * interface.
  */
 union cvmx_lmcx_char_ctl {
 	uint64_t u64;
 	struct cvmx_lmcx_char_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_53_63               : 11;
-	uint64_t dq_char_check_lock           : 1;  /**< INTERNAL: Indicates if a lock has been achieved, will only go to 1 if a lock is
-                                                         achieved during the LFSR priming period after LMC(0..3)_CHAR_CTL[DQ_CHAR_CHECK_ENABLE]
-                                                         is set to 1, and will be forced back to 0 when LMC(0..3)_CHAR_CTL[DQ_CHAR_CHECK_ENABLE]
-                                                         is set to 0. */
-	uint64_t dq_char_check_enable         : 1;  /**< INTERNAL: Enable DQ pattern check, on transition from disabled to enable will
-                                                         clear the LMC*CHAR_DQ_ERR_COUNT CSR. */
-	uint64_t dq_char_bit_sel              : 3;  /**< INTERNAL: Select a bit within the byte for DQ characterization pattern check. */
-	uint64_t dq_char_byte_sel             : 4;  /**< INTERNAL: Select a byte of data for DQ characterization pattern check. */
+	uint64_t dq_char_check_lock           : 1;  /**< Indicates if a lock has been achieved. Is set to 1 only if a lock is achieved during the
+                                                         LFSR priming period after DQ_CHAR_CHECK_ENABLE is set to 1, and is forced back to 0 when
+                                                         DQ_CHAR_CHECK_ENABLE is set to 0. */
+	uint64_t dq_char_check_enable         : 1;  /**< Enable DQ pattern check. The transition from disabled to enabled clears
+                                                         LMC(0..3)_CHAR_DQ_ERR_COUNT. */
+	uint64_t dq_char_bit_sel              : 3;  /**< Select a bit within the byte for DQ characterization pattern check. */
+	uint64_t dq_char_byte_sel             : 4;  /**< Select a byte of data for DQ characterization pattern check. */
 	uint64_t dr                           : 1;  /**< Pattern at Data Rate (not Clock Rate) */
 	uint64_t skew_on                      : 1;  /**< Skew adjacent bits */
 	uint64_t en                           : 1;  /**< Enable characterization */
@@ -1798,7 +1808,7 @@ typedef union cvmx_lmcx_char_ctl cvmx_lmcx_char_ctl_t;
 /**
  * cvmx_lmc#_char_dq_err_count
  *
- * INTERNAL: This register counts error in the DQ characterization mode.
+ * This register is used to initiate the various control sequences in the LMC.
  *
  */
 union cvmx_lmcx_char_dq_err_count {
@@ -1806,7 +1816,7 @@ union cvmx_lmcx_char_dq_err_count {
 	struct cvmx_lmcx_char_dq_err_count_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_40_63               : 24;
-	uint64_t dq_err_count                 : 40; /**< INTERNAL: DQ error count. */
+	uint64_t dq_err_count                 : 40; /**< DQ error count. */
 #else
 	uint64_t dq_err_count                 : 40;
 	uint64_t reserved_40_63               : 24;
@@ -1820,8 +1830,8 @@ typedef union cvmx_lmcx_char_dq_err_count cvmx_lmcx_char_dq_err_count_t;
 /**
  * cvmx_lmc#_char_mask0
  *
- * INTERNAL: This register is an assortment of various control fields needed to charecterize the
- * DDR3 interface.
+ * This register provides an assortment of various control fields needed to characterize the DDR3
+ * interface.
  */
 union cvmx_lmcx_char_mask0 {
 	uint64_t u64;
@@ -1847,8 +1857,8 @@ typedef union cvmx_lmcx_char_mask0 cvmx_lmcx_char_mask0_t;
 /**
  * cvmx_lmc#_char_mask1
  *
- * INTERNAL: This register is an assortment of various control fields needed to charecterize the
- * DDR3 interface.
+ * This register provides an assortment of various control fields needed to characterize the DDR3
+ * interface.
  */
 union cvmx_lmcx_char_mask1 {
 	uint64_t u64;
@@ -1876,8 +1886,8 @@ typedef union cvmx_lmcx_char_mask1 cvmx_lmcx_char_mask1_t;
 /**
  * cvmx_lmc#_char_mask2
  *
- * INTERNAL: This register is an assortment of various control fields needed to charecterize the
- * DDR3 interface.
+ * This register provides an assortment of various control fields needed to characterize the DDR3
+ * interface.
  */
 union cvmx_lmcx_char_mask2 {
 	uint64_t u64;
@@ -1903,8 +1913,8 @@ typedef union cvmx_lmcx_char_mask2 cvmx_lmcx_char_mask2_t;
 /**
  * cvmx_lmc#_char_mask3
  *
- * INTERNAL: This register is an assortment of various control fields needed to charecterize the
- * DDR3 interface.
+ * This register provides an assortment of various control fields needed to characterize the DDR3
+ * interface.
  */
 union cvmx_lmcx_char_mask3 {
 	uint64_t u64;
@@ -1932,14 +1942,26 @@ typedef union cvmx_lmcx_char_mask3 cvmx_lmcx_char_mask3_t;
 /**
  * cvmx_lmc#_char_mask4
  *
- * INTERNAL: This register is an assortment of various control fields needed to charecterize the
- * DDR3 interface.
+ * This register is an assortment of various control fields needed to characterize the DDR3 interface.
+ *
  */
 union cvmx_lmcx_char_mask4 {
 	uint64_t u64;
 	struct cvmx_lmcx_char_mask4_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_45_63               : 19;
+	uint64_t ref_pin_on_mask              : 9;  /**< INTERNAL: This mask is applied to the REF_PIN_ON signals that go to
+                                                         the PHY, so that each byte lane can selectively turn off or on the signals
+                                                         once the master signals is enabled.  Using the symbol R, the mask looks
+                                                         like this:
+                                                         RRRRRRRRR
+                                                         876543210 */
+	uint64_t dac_on_mask                  : 9;  /**< INTERNAL: This mask is applied to the DAC_ON signals that go to
+                                                         the PHY, so that each byte lane can selectively turn off or on the signals
+                                                         once the master signals are enabled.  Using the symbols D  for DAC_ON,
+                                                         the mask looks like this:
+                                                         DDDDDDDDD
+                                                         876543210 */
+	uint64_t reserved_45_45               : 1;
 	uint64_t dbi_mask                     : 9;  /**< Mask for DBI/DQS<1>. */
 	uint64_t par_mask                     : 1;  /**< Mask for PAR. */
 	uint64_t act_n_mask                   : 1;  /**< Mask for ACT_N. */
@@ -1971,7 +1993,9 @@ union cvmx_lmcx_char_mask4 {
 	uint64_t act_n_mask                   : 1;
 	uint64_t par_mask                     : 1;
 	uint64_t dbi_mask                     : 9;
-	uint64_t reserved_45_63               : 19;
+	uint64_t reserved_45_45               : 1;
+	uint64_t dac_on_mask                  : 9;
+	uint64_t ref_pin_on_mask              : 9;
 #endif
 	} s;
 	struct cvmx_lmcx_char_mask4_cn61xx {
@@ -2008,7 +2032,43 @@ union cvmx_lmcx_char_mask4 {
 	struct cvmx_lmcx_char_mask4_cn61xx    cn66xx;
 	struct cvmx_lmcx_char_mask4_cn61xx    cn68xx;
 	struct cvmx_lmcx_char_mask4_cn61xx    cn68xxp1;
-	struct cvmx_lmcx_char_mask4_s         cn70xx;
+	struct cvmx_lmcx_char_mask4_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_45_63               : 19;
+	uint64_t dbi_mask                     : 9;  /**< Mask for DBI/DQS<1>. */
+	uint64_t par_mask                     : 1;  /**< Mask for PAR. */
+	uint64_t act_n_mask                   : 1;  /**< Mask for ACT_N. */
+	uint64_t a17_mask                     : 1;  /**< Mask for A17. */
+	uint64_t reset_n_mask                 : 1;  /**< Mask for RESET_L. */
+	uint64_t a_mask                       : 16; /**< Mask for A<15:0>. */
+	uint64_t ba_mask                      : 3;  /**< Mask for BA<2:0>. */
+	uint64_t we_n_mask                    : 1;  /**< Mask for WE_N. */
+	uint64_t cas_n_mask                   : 1;  /**< Mask for CAS_N. */
+	uint64_t ras_n_mask                   : 1;  /**< Mask for RAS_N. */
+	uint64_t odt1_mask                    : 2;  /**< Mask for ODT1. */
+	uint64_t odt0_mask                    : 2;  /**< Mask for ODT0. */
+	uint64_t cs1_n_mask                   : 2;  /**< Mask for CS1_N. */
+	uint64_t cs0_n_mask                   : 2;  /**< Mask for CS0_N. */
+	uint64_t cke_mask                     : 2;  /**< Mask for CKE*. */
+#else
+	uint64_t cke_mask                     : 2;
+	uint64_t cs0_n_mask                   : 2;
+	uint64_t cs1_n_mask                   : 2;
+	uint64_t odt0_mask                    : 2;
+	uint64_t odt1_mask                    : 2;
+	uint64_t ras_n_mask                   : 1;
+	uint64_t cas_n_mask                   : 1;
+	uint64_t we_n_mask                    : 1;
+	uint64_t ba_mask                      : 3;
+	uint64_t a_mask                       : 16;
+	uint64_t reset_n_mask                 : 1;
+	uint64_t a17_mask                     : 1;
+	uint64_t act_n_mask                   : 1;
+	uint64_t par_mask                     : 1;
+	uint64_t dbi_mask                     : 9;
+	uint64_t reserved_45_63               : 19;
+#endif
+	} cn70xx;
 	struct cvmx_lmcx_char_mask4_s         cn78xx;
 	struct cvmx_lmcx_char_mask4_cn61xx    cnf71xx;
 };
@@ -2126,9 +2186,9 @@ union cvmx_lmcx_comp_ctl2 {
 	struct cvmx_lmcx_comp_ctl2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
-	uint64_t rclk_char_mode               : 1;  /**< INTERNAL: Select RCLK characterization mode. */
+	uint64_t rclk_char_mode               : 1;  /**< Reserved. INTERNAL: Select RCLK characterization mode. */
 	uint64_t reserved_40_49               : 10;
-	uint64_t ptune_offset                 : 4;  /**< Ptune Offset value. */
+	uint64_t ptune_offset                 : 4;  /**< Ptune offset value. */
 	uint64_t reserved_12_35               : 24;
 	uint64_t cmd_ctl                      : 4;  /**< Drive strength control for CMD/A/RESET_L drivers
                                                          0001 = 24 ohm
@@ -2242,12 +2302,12 @@ union cvmx_lmcx_comp_ctl2 {
 	struct cvmx_lmcx_comp_ctl2_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
-	uint64_t rclk_char_mode               : 1;  /**< INTERNAL: Select RCLK characterization mode. */
+	uint64_t rclk_char_mode               : 1;  /**< Reserved. INTERNAL: Select RCLK characterization mode. */
 	uint64_t ddr__ptune                   : 5;  /**< DDR PCTL from compensation circuit. The encoded value provides debug information for the
                                                          compensation impedance on P-pullup. */
 	uint64_t ddr__ntune                   : 5;  /**< DDR NCTL from compensation circuit. The encoded value provides debug information for the
                                                          compensation impedance on N-pulldown. */
-	uint64_t ptune_offset                 : 4;  /**< Ptune Offset value. */
+	uint64_t ptune_offset                 : 4;  /**< Ptune offset value. */
 	uint64_t ntune_offset                 : 4;  /**< Ntune offset value. */
 	uint64_t m180                         : 1;  /**< Reserved; must be zero. INTERNAL: Cap impedance at 180 ohm, instead of 240 ohm. */
 	uint64_t byp                          : 1;  /**< Bypass mode. When set, PTUNE,NTUNE are the compensation setting. When clear,
@@ -2255,58 +2315,58 @@ union cvmx_lmcx_comp_ctl2 {
 	uint64_t ptune                        : 5;  /**< PCTL impedance control in bypass mode. */
 	uint64_t ntune                        : 5;  /**< NCTL impedance control in bypass mode. */
 	uint64_t rodt_ctl                     : 4;  /**< RODT NCTL impedance control bits. This field controls ODT values during a memory read.
-                                                         In DDR3 mode:
-                                                         0000 = No ODT. 0011 = 40 ohm.
-                                                         0001 = 20 ohm. 0100 = 60 ohm.
-                                                         0010 = 30 ohm. 0101 = 120 ohm.
-                                                         0110-1111 = Reserved.
+                                                         0x0 = No ODT. 0x3 = 40 ohm.
+                                                         0x1 = 20 ohm. 0x4 = 60 ohm.
+                                                         0x2 = 30 ohm. 0x5 = 120 ohm.
+                                                         0x6-0xF = Reserved
                                                          In DDR4 mode:
-                                                         0000 = No ODT. 0100 = 120 ohm.
-                                                         0001 = 40 ohm. 0101 = 240 ohm.
-                                                         0010 = 60 ohm. 0110 =  34 ohm.
-                                                         0011 = 80 ohm. 0111 =  48 ohm. */
+                                                         0x0 = No ODT. 0x4 = 120 ohm.
+                                                         0x1 = 40 ohm. 0x5 = 240 ohm.
+                                                         0x2 = 60 ohm. 0x6 = 34 ohm.
+                                                         0x3 = 80 ohm. 0x7 = 48 ohm.
+                                                         0x8-0xF = Reserved */
 	uint64_t control_ctl                  : 4;  /**< Drive strength control for ODT, etc. drivers.
                                                          In DDR3 mode:
-                                                         0001 = 24 ohm.    0101 = 40 ohm.
-                                                         0010 = 26.67 ohm. 0110 = 48 ohm.
-                                                         0011 = 30 ohm.    0111 = 60 ohm.
-                                                         0100 = 34.3 ohm.  0000,1000-1111 = Reserved.
+                                                         0x1 = 24 ohm. 0x5 = 40 ohm.
+                                                         0x2 = 26.67 ohm. 0x6 = 48 ohm.
+                                                         0x3 = 30 ohm. 0x7 = 60 ohm.
+                                                         0x4 = 34.3 ohm. 0x0, 0x8-0xF = Reserved.
                                                          In DDR4 mode:
-                                                         0000 = Reserved.  0001 = Reserved.
-                                                         0010 = 26 ohm.    0011 = 30 ohm.
-                                                         0100 = 34 ohm.    0101 = 40 ohm.
-                                                         0110 = 48 ohm.    0111 = 68 ohm.
-                                                         1000-1111 = Reserved. */
+                                                         0x0 = Reserved. 0x4 = 34 ohm.
+                                                         0x1 = Reserved. 0x5 = 40 ohm.
+                                                         0x2 = 26 ohm. 0x6 = 48 ohm.
+                                                         0x3 = 30 ohm. 0x7 = 68 ohm.
+                                                         0x8-0xF = Reserved. */
 	uint64_t cmd_ctl                      : 4;  /**< Drive strength control for CMD/A/RESET_L drivers.
                                                          In DDR3 mode:
-                                                         0001 = 24 ohm. 0101 = 40 ohm.
-                                                         0010 = 26.67 ohm. 0110 = 48 ohm.
-                                                         0011 = 30 ohm. 0111 = 60 ohm.
-                                                         0100 = 34.3 ohm. 0000,1000-1111 = Reserved.
+                                                         0x1 = 24 ohm. 0x5 = 40 ohm.
+                                                         0x2 = 26.67 ohm. 0x6 = 48 ohm.
+                                                         0x3 = 30 ohm. 0x7 = 60 ohm.
+                                                         0x4 = 34.3 ohm. 0x0,0x8-0xF = Reserved.
                                                          In DDR4 mode:
-                                                         0000 = Reserved.  0001 = Reserved.
-                                                         0010 = 26 ohm.    0011 = 30 ohm.
-                                                         0100 = 34 ohm.    0101 = 40 ohm.
-                                                         0110 = 48 ohm.    0111 = 68 ohm.
-                                                         1000-1111 = Reserved. */
-	uint64_t ck_ctl                       : 4;  /**< ""Drive strength control for DDR#_CK_*_P/DDR#_DIMM*_CS*_L/DDR#_DIMM*_ODT_* /DDR#_DIMM*_CKE*
+                                                         0x0 = Reserved. 0x4 = 34 ohm.
+                                                         0x1 = Reserved. 0x5 = 40 ohm.
+                                                         0x2 = 26 ohm. 0x6 = 48 ohm.
+                                                         0x3 = 30 ohm. 0x7 = 68 ohm.
+                                                         0x8-0xF = Reserved. */
+	uint64_t ck_ctl                       : 4;  /**< "Drive strength control for DDR_CK_*_P/DDR_DIMM*_CS*_L/DDR_DIMM*_ODT_* /DDR#_DIMM*_CKE*
                                                          drivers.
                                                          In DDR3 mode:
-                                                         0001 = 24 ohm. 0101 = 40 ohm.
-                                                         0010 = 26.67 ohm. 0110 = 48 ohm.
-                                                         0011 = 30 ohm. 0111 = 60 ohm.
-                                                         0100 = 34.3 ohm. 0000,1000-1111 = Reserved."
+                                                         0x1 = 24 ohm. 0x5 = 40 ohm.
+                                                         0x2 = 26.67 ohm. 0x6 = 48 ohm.
+                                                         0x3 = 30 ohm. 0x7 = 60 ohm.
+                                                         0x4 = 34.3 ohm. 0x0,0x8-0xF = Reserved.
                                                          In DDR4 mode:
-                                                         0000 = Reserved.  0001 = Reserved.
-                                                         0010 = 26 ohm.    0011 = 30 ohm.
-                                                         0100 = 34 ohm.    0101 = 40 ohm.
-                                                         0110 = 48 ohm.    0111 = 68 ohm.
-                                                         1000-1111 = Reserved." */
-	uint64_t dqx_ctl                      : 4;  /**< "Drive strength control for DDR#_DQ* /DDR#_DQS_*_P/N drivers.
-                                                         0001 = 24 ohm. 0101 = 40 ohm.
-                                                         0010 = 26.67 ohm. 0110 = 48 ohm.
-                                                         0011 = 30 ohm. 0111 = 60 ohm.
-                                                         0100 = 34.3 ohm. 0000,1000-1111 = Reserved." */
+                                                         0x0 = Reserved. 0x4 = 34 ohm.
+                                                         0x1 = Reserved. 0x5 = 40 ohm.
+                                                         0x2 = 26 ohm. 0x6 = 48 ohm.
+                                                         0x3 = 30 ohm. 0x7 = 68 ohm.
+                                                         0x8-0xF = Reserved." */
+	uint64_t dqx_ctl                      : 4;  /**< Drive strength control for DDR_DQ* /DDR_DQS_*_P/N drivers.
+                                                         0x1 = 24 ohm. 0x5 = 40 ohm.
+                                                         0x2 = 26.67 ohm. 0x6 = 48 ohm.
+                                                         0x3 = 30 ohm. 0x7 = 60 ohm.
+                                                         0x4 = 34.3 ohm. 0x0,0x8-0xF = Reserved. */
 #else
 	uint64_t dqx_ctl                      : 4;
 	uint64_t ck_ctl                       : 4;
@@ -2348,10 +2408,9 @@ union cvmx_lmcx_config {
 	struct cvmx_lmcx_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_63_63               : 1;
-	uint64_t bg2_enable                   : 1;  /**< BG2 pin is active for DDR4 mode.  Only has an effect when LMC*_CONFIG[MODEDDR4] = 1.
-                                                         Typically only cleared for DDR4 x16 devices, where there is no BG2 pin on the device. */
-	uint64_t mode_x4dev                   : 1;  /**< DDR x4 device mode.  Set when using DIMMs with x4 devices or if using
-                                                         embedded x4 devices. */
+	uint64_t bg2_enable                   : 1;  /**< BG2 pin is active for DDR4 mode. Only has an effect when LMC(0..3)_CONFIG[MODEDDR4] = 1.
+                                                         Typically only cleared for DDR4 *16 devices, where there is no BG2 pin on the device. */
+	uint64_t mode_x4dev                   : 1;  /**< DDR *4 device mode. */
 	uint64_t mode32b                      : 1;  /**< 32b Datapath Mode                                          NS
                                                          Set to 1 if we use only 32 DQ pins
                                                          0 for 64b DQ mode. */
@@ -3510,93 +3569,82 @@ union cvmx_lmcx_config {
 	struct cvmx_lmcx_config_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_63_63               : 1;
-	uint64_t bg2_enable                   : 1;  /**< BG2 pin is active for DDR4 mode.  Only has an effect when LMC*_CONFIG[MODEDDR4] = 1.
-                                                         Typically only cleared for DDR4 x16 devices, where there is no BG2 pin on the device. */
-	uint64_t mode_x4dev                   : 1;  /**< DDR x4 device mode.  Set when using DIMMs with x4 devices or if using
-                                                         embedded x4 devices, must be 0. */
-	uint64_t mode32b                      : 1;  /**< 32-bit datapath mode. When set, only 32 DQ pins are used, must be 1. */
+	uint64_t bg2_enable                   : 1;  /**< BG2 pin is active for DDR4 mode. Only has an effect when LMC(0..0)_CONFIG[MODEDDR4] = 1.
+                                                         Typically only cleared for DDR4 *16 devices, where there is no BG2 pin on the device. */
+	uint64_t mode_x4dev                   : 1;  /**< Always reads as 0 for 70xx devices, there is no x4 device support. */
+	uint64_t mode32b                      : 1;  /**< Always reads as 1 for 70xx devices, only 32b mode is supported. */
 	uint64_t scrz                         : 1;  /**< Hide LMC(0..0)_SCRAMBLE_CFG0 and LMC(0..0)_SCRAMBLE_CFG1 when set. */
 	uint64_t early_unload_d1_r1           : 1;  /**< When set, unload the PHY silo one cycle early for Rank 3 reads.
-                                                         The recommended EARLY_UNLOAD_D1_R1 value can be calculated after the final
-                                                         LMC*_RLEVEL_RANK3[BYTE*] values are selected (as part of read-leveling initialization).
-                                                         Then, determine the largest read-leveling setting for rank 3 (i.e. calculate
-                                                         maxset=MAX(LMC*_RLEVEL_RANK3[BYTEi]) across all i), then set EARLY_UNLOAD_D1_R1 when the
-                                                         low two bits of this largest setting is not 3 (i.e. EARLY_UNLOAD_D1_R1 = (maxset<1:0>
-                                                         !=3)). */
+                                                         The recommended EARLY_UNLOAD_D1_R1 value is 0. */
 	uint64_t early_unload_d1_r0           : 1;  /**< When set, unload the PHY silo one cycle early for Rank 2 reads.
-                                                         The recommended EARLY_UNLOAD_D1_RO value can be calculated after the final
-                                                         LMC*_RLEVEL_RANK2[BYTE*] values are selected (as part of read-leveling initialization).
-                                                         Then, determine the largest read-leveling setting for rank 2 (i.e. calculate
-                                                         maxset=MAX(LMC*_RLEVEL_RANK2[BYTEi]) across all i), then set EARLY_UNLOAD_D1_RO when the
-                                                         low two bits of this largest setting is not 3 (i.e. EARLY_UNLOAD_D1_RO = (maxset<1:0>
-                                                         !=3)). */
+                                                         The recommended EARLY_UNLOAD_D1_RO value is 0. */
 	uint64_t early_unload_d0_r1           : 1;  /**< When set, unload the PHY silo one cycle early for Rank 1 reads.
-                                                         The recommended EARLY_UNLOAD_D0_R1 value can be calculated after the final
-                                                         LMC*_RLEVEL_RANK1[BYTE*] values are selected (as part of read-leveling initialization).
-                                                         Then, determine the largest read-leveling setting for rank 1 (i.e. calculate
-                                                         maxset=MAX(LMC*_RLEVEL_RANK1[BYTEi]) across all i), then set EARLY_UNLOAD_D0_R1 when the
-                                                         low two bits of this largest setting is not 3 (i.e. EARLY_UNLOAD_D0_R1 = (maxset<1:0>
-                                                         !=3)). */
+                                                         The recommended EARLY_UNLOAD_D0_R1 value is 0. */
 	uint64_t early_unload_d0_r0           : 1;  /**< When set, unload the PHY silo one cycle early for Rank 0 reads.
-                                                         The recommended EARLY_UNLOAD_D0_R0 value can be calculated after the final
-                                                         LMC*_RLEVEL_RANK0[BYTE*] values are selected (as part of read-leveling initialization).
-                                                         Then, determine the largest read-leveling setting for rank 0 (i.e. calculate
-                                                         maxset=MAX(LMC*_RLEVEL_RANK0[BYTEi]) across all i), then set EARLY_UNLOAD_D0_R0 when the
-                                                         low two bits of this largest setting is not 3 (i.e. EARLY_UNLOAD_D0_R0 = (maxset<1:0>
-                                                         !=3)). */
+                                                         The recommended EARLY_UNLOAD_D0_R0 value is 0. */
 	uint64_t init_status                  : 4;  /**< Indicates status of initialization. INIT_STATUS[n] = 1 implies rank n has been
-                                                         initialized.  Software must set necessary RANKMASK bits before executing the
-                                                         initialization sequence using the LMC*_SEQ_CTL register.  If the rank has been
-                                                         selected for init with the RANKMASK bits, the INIT_STATUS bits will be set after
-                                                         successful
-                                                         initialization and after self-refresh exit.  INIT_STATUS determines the chip-selects
-                                                         that assert during refresh, ZQCS, precharge power-down entry/exit, and self-refresh entry
-                                                         SEQ_SEL's. */
+                                                         initialized.
+                                                         Software must set necessary RANKMASK bits before executing the initialization sequence
+                                                         using LMC(0..0)_SEQ_CTL. If the rank has been selected for init with the RANKMASK bits,
+                                                         the INIT_STATUS bits will be set after successful initialization and after self-refresh
+                                                         exit. INIT_STATUS determines the chip-selects that assert during refresh, ZQCS, precharge
+                                                         power-down entry/exit, and self-refresh entry SEQ_SEL's. */
 	uint64_t mirrmask                     : 4;  /**< "Mask determining which ranks are address-mirrored.
                                                          MIRRMASK<n> = 1 means Rank n addresses are mirrored for
                                                          0 <= n <= 3.
-                                                         A mirrored read/write operation has the following differences:
+                                                         In DDR3, a mirrored read/write operation has the following differences:
                                                          DDR#_BA<1> is swapped with DDR#_BA<0>;
                                                          DDR#_A<8> is swapped with DDR#_A<7>;
                                                          DDR#_A<6> is swapped with DDR#_A<5>;
                                                          DDR#_A<4> is swapped with DDR#_A<3>.
-                                                         When RANK_ENA = 0, MIRRMASK<1> and MIRRMASK<3> MBZ." */
+                                                         For 70xx, MIRRMASK<3:2> MBZ.
+                                                         When RANK_ENA = 0, MIRRMASK<1> MBZ."
+                                                         INTERNAL:
+                                                         In DDR4, a mirrored read/write operation has the following differences:
+                                                         DDR#_BG<1> is swapped with DDR#_BG<0>;
+                                                         DDR#_BA<1> is swapped with DDR#_BA<0>;
+                                                         DDR#_A<13> is swapped with DDR#_A<11>;
+                                                         DDR#_A<8> is swapped with DDR#_A<7>;
+                                                         DDR#_A<6> is swapped with DDR#_A<5>;
+                                                         DDR#_A<4> is swapped with DDR#_A<3>.
+                                                         For 70xx, MIRRMASK<3:2> MBZ.
+                                                         When RANK_ENA = 0, MIRRMASK<1> MBZ." */
 	uint64_t rankmask                     : 4;  /**< Mask to select rank to be leveled/initialized. To write-level/read-level/initialize rank
                                                          i, set RANKMASK< i>
-                                                         RANK_ENA = 1 RANK_ENA = 0
-                                                         RANKMASK<0> = DIMM0_CS0 DIMM0_CS0
-                                                         RANKMASK<1> = DIMM0_CS1 MBZ
-                                                         RANKMASK<2> = DIMM1_CS0 DIMM1_CS0
-                                                         RANKMASK<3> = DIMM1_CS1 MBZ
+                                                                       RANK_ENA = 1 RANK_ENA = 0
+                                                         RANKMASK<0> = DIMM0_CS0    DIMM0_CS0
+                                                         RANKMASK<1> = DIMM0_CS1    MBZ
+                                                         RANKMASK<2> = MBZ          MBZ
+                                                         RANKMASK<3> = MBZ          MBZ
                                                          For read/write leveling, each rank has to be leveled separately, so RANKMASK should only
                                                          have one bit set. RANKMASK is not used during self-refresh entry/exit and precharge power-
-                                                         down entry/exit instruction sequences. When RANK_ENA = 0, RANKMASK<1> and RANKMASK<3> MBZ. */
+                                                         down entry/exit instruction sequences. For 70xx, RANKMASK<3:2> MBZ.  When RANK_ENA = 0,
+                                                         RANKMASK<1> MBZ. */
 	uint64_t rank_ena                     : 1;  /**< "RANK enable (for use with dual-rank DIMMs).
                                                          For dual-rank DIMMs, the RANK_ENA bit will enable the drive of the DDR#_DIMM*_CS*_L and
                                                          ODT_<1:0> pins differently based on the (PBANK_LSB - 1) address bit.
                                                          Write 0 for SINGLE ranked DIMMs." */
 	uint64_t sref_with_dll                : 1;  /**< Self-refresh entry/exit write mode registers. When set, self-refresh entry sequence writes
                                                          MR2 and MR1 (in this order, in all ranks), and self-refresh exit sequence writes MR1, MR0,
-                                                         MR2, and MR3 (in this order, for all ranks).  The write operations occur before
-                                                         self-refresh entry, and after self-refresh exit.  When clear, self-refresh entry and exit
+                                                         MR2, and MR3 (in this order, for all ranks). The write operations occur before self-
+                                                         refresh entry, and after self-refresh exit. When clear, self-refresh entry and exit
                                                          instruction sequences do not write any mode registers in the DDR3/4 parts. */
 	uint64_t early_dqx                    : 1;  /**< Set this bit to send DQx signals one CK cycle earlier for the case when the shortest DQx
                                                          lines have a larger delay than the CK line. */
-	uint64_t ref_zqcs_int                 : 22; /**< Refresh interval is represented in number of 512 CK cycle increments. ZQCS interval
-                                                         is represented in a number of refresh intervals.  A refresh sequence is triggered when
-                                                         bits <24:18> are equal to 0x0, and a ZQCS sequence is triggered when <39:18> are equal
-                                                         to 0x0.  The ZQCS timer only decrements when the refresh timer is 0.
+	uint64_t ref_zqcs_int                 : 22; /**< Refresh interval is represented in number of 512 CK cycle increments. ZQCS interval is
+                                                         represented in a number of refresh intervals. A refresh sequence is triggered when bits
+                                                         <24:18> are equal to 0x0, and a ZQCS sequence is triggered when <39:18> are equal to 0x0.
+                                                         The ZQCS timer only decrements when the refresh timer is 0.
                                                          Program <24:18> to RND-DN(TREFI/clkPeriod/512).
                                                          A value of 0 in bits <24:18> will effectively turn off refresh.
                                                          Program <36:25> to (RND-DN(ZQCS_Period / Refresh_Period) - 1), where Refresh_Period is the
-                                                         effective period programmed in bis <24:18>. Note that this value should always be greater
+                                                         effective period programmed in bits <24:18>. Note that this value should always be greater
                                                          than 32, to account for resistor calibration delays.
-                                                         000_00000000_00000000: Reserved
-                                                         Max Refresh interval = 127*512= 65024 CK cycles
+                                                         000_00000000_0000000: Reserved
+                                                         Max Refresh interval = 127 * 512= 65024 CK cycles
                                                          Max ZQCS interval = 32768 * 127 * 512 = 2130706432 CK cycles
                                                          If refresh interval is programmed to ~8us, max ZQCS interval is ~262ms, or ~4 ZQCS
-                                                         operations
-                                                         per second.
+                                                         operations per second.
                                                          LMC(0..0)_CONFIG[INIT_STATUS] determines which ranks receive the REF / ZQCS. LMC does not
                                                          send any refreshes / ZQCS's when LMC(0..0)_CONFIG[INIT_STATUS]=0. */
 	uint64_t reset                        : 1;  /**< Reset one-shot pulse for LMC(0..0)_OPS_CNT, LMC(0..0)_IFB_CNT, and LMC(0..0)_DCLK_CNT
@@ -3614,17 +3662,17 @@ union cvmx_lmcx_config {
 	uint64_t pbank_lsb                    : 4;  /**< "DIMM address bit select. Reverting to the explanation for ROW_LSB, PBANK_LSB would be:
                                                          ROW_LSB bit + \#rowbits + \#rankbits
                                                          Decoding for PBANK_LSB:
-                                                         - 0000:DIMM = mem_adr<28> / rank = mem_adr[27] (if RANK_ENA)
-                                                         - 0001:DIMM = mem_adr<29> / rank = mem_adr<28>      &quot;
-                                                         - 0010:DIMM = mem_adr<30> / rank = mem_adr<29>      &quot;
-                                                         - 0011:DIMM = mem_adr<31> / rank = mem_adr<30>      &quot;
-                                                         - 0100:DIMM = mem_adr<32> / rank = mem_adr<31>      &quot;
-                                                         - 0101:DIMM = mem_adr<33> / rank = mem_adr<32>      &quot;
-                                                         - 0110:DIMM = mem_adr<34> / rank = mem_adr<33>      &quot;
-                                                         - 0111:DIMM = mem_adr<35> / rank = mem_adr<34>      &quot;
-                                                         - 1000:DIMM = mem_adr<36> / rank = mem_adr<35>      &quot;
-                                                         - 1001:DIMM = 0 / rank = mem_adr<36>      &quot;
-                                                         - 1010-1111: Reserved
+                                                         0x0: DIMM = mem_adr<28>; if RANK_ENA=1, rank = mem_adr<27>
+                                                         0x1: DIMM = mem_adr<29>; if RANK_ENA=1, rank = mem_adr<28>
+                                                         0x2: DIMM = mem_adr<30>; if RANK_ENA=1, rank = mem_adr<29>
+                                                         0x3: DIMM = mem_adr<31>; if RANK_ENA=1, rank = mem_adr<30>
+                                                         0x4: DIMM = mem_adr<32>; if RANK_ENA=1, rank = mem_adr<31>
+                                                         0x5: DIMM = mem_adr<33>; if RANK_ENA=1, rank = mem_adr<32>
+                                                         0x6: DIMM = mem_adr<34>; if RANK_ENA=1, rank = mem_adr<33>
+                                                         0x7: DIMM = mem_adr<35>; if RANK_ENA=1, rank = mem_adr<34>
+                                                         0x8: DIMM = mem_adr<36>; if RANK_ENA=1, rank = mem_adr<35>
+                                                         0x9: DIMM = 0; if RANK_ENA=1, rank = mem_adr<36>
+                                                         0xA-0xF: reserved
                                                          For example, for a DIMM made of Samsung's K4B1G0846C-F7 1Gb (16M * 8 bit * 8 bank) DDR3
                                                          parts, the column address width = 10, so with 10b of col, 3b of bus, 3b of bank, ROW_LSB =
                                                          16. So, row = mem_adr<29:16>.
@@ -3634,25 +3682,25 @@ union cvmx_lmcx_config {
                                                          Encoding used to determine which memory address bit position represents the low order DDR
                                                          ROW address. The processor's memory address<34:7> needs to be translated to DRAM addresses
                                                          (bnk,row,col,rank and DIMM) and that is a function of the following:
-                                                         Datapath width (64)
+                                                         Datapath width (32)
                                                          \# banks (8)
                                                          \# column bits of the memory part--specified indirectly by this register.
                                                          \# row bits of the memory part--specified indirectly by PBANK_LSB
                                                          \# ranks in a DIMM--specified by RANK_ENA
                                                          \# DIMMs in the system by the register below (PBANK_LSB).
-                                                         Col Address starts from mem_addr[3] for 64b (8Bytes) DQ width. ROW_LSB is mem_adr[15] for
-                                                         64b mode. Therefore, the ROW_LSB parameter should be set to 001 (64b).
+                                                         Col Address starts from mem_addr[2] for 32b (4Bytes) DQ width. ROW_LSB is mem_adr[14] for
+                                                         32b mode. Therefore, the ROW_LSB parameter should be set to 000 (32b).
                                                          Decoding for row_lsb:
                                                          Mem address  Mem address
-                                                         Value bit that is LSB Value bit that is LSB
+                                                         Value and corresponding bit that is LSB:
                                                          000 <14>. 100 <18>.
                                                          001 <15>. 101 <19>.
                                                          010 <16>. 110 <20>.
                                                          011 <17>. 111 Reserved.
                                                          For example, for a DIMM made of Samsung's K4B1G0846C-F7 1GB (16M * 8 bit * 8 bank) DDR3
-                                                         parts, the column address width = 10, so with 10b of col, 3b of bus, 3b of bank, ROW_LSB =
-                                                         16. So, row = mem_adr<29:16>.
-                                                         Refer to ." */
+                                                         parts, the column address width = 10, so with 10b of col, 2b of bus, 3b of bank, ROW_LSB =
+                                                         15. So, row = mem_adr<28:15>, and ROW_LSB parameter should be set to 001.
+                                                         Refer to Cache-block Read Transaction Example." */
 	uint64_t ecc_ena                      : 1;  /**< ECC enable. When set, enables the 8b ECC check/correct logic. Should be 1 when used with
                                                          DIMMs with ECC; 0, otherwise.
                                                          When this mode is turned on, DQ<71:64> on write operations contains the ECC code generated
@@ -5331,9 +5379,9 @@ typedef union cvmx_lmcx_ddr2_ctl cvmx_lmcx_ddr2_ctl_t;
 /**
  * cvmx_lmc#_ddr4_dimm_ctl
  *
- * Note that this CSR is only used when LMC(0..3)_CONTROL[RDIMM_ENA] = 1. During an RCW init
- * sequence, this CSR controls LMC's write operations to the extended DDR4 control words in the
- * JEDEC standard registering clock driver on an RDIMM.
+ * This register is used only when LMC(0..3)_CONTROL[RDIMM_ENA] = 1. During an RCW initialization
+ * sequence, this register controls LMC's write operations to the extended DDR4 control words in
+ * the JEDEC standard registering clock driver on an RDIMM.
  */
 union cvmx_lmcx_ddr4_dimm_ctl {
 	uint64_t u64;
@@ -5359,32 +5407,32 @@ typedef union cvmx_lmcx_ddr4_dimm_ctl cvmx_lmcx_ddr4_dimm_ctl_t;
  * This register controls the DDR_CK frequency. For details, refer to CK Speed Programming. See
  * LMC Initialization Sequence for the initialization sequence.
  * DDR PLL Bringup sequence:
- * 1.  Write CLKF, DDR_PS_EN, DFM_PS_EN, DIFFAMP, CPS, CPB.
- * If test mode is going to be activated, then also write jtg__ddr_pll_tm_en1,
- * jtg__ddr_pll_tm_en2, jtg__ddr_pll_tm_en3,
+ * 1. Write CLKF, DDR_PS_EN, DFM_PS_EN, DIFFAMP, CPS, CPB. If test mode is going to be activated,
+ * then also write jtg__ddr_pll_tm_en1, jtg__ddr_pll_tm_en2, jtg__ddr_pll_tm_en3,
  * jtg__ddr_pll_tm_en4, jtg__dfa_pll_tm_en1, jtg__dfa_pll_tm_en2, jtg__dfa_pll_tm_en3,
  * jtg__dfa_pll_tm_en4, JTAG_TEST_MODE
- * 2.  Wait 128 ref clock cycles (7680 rclk cycles)
- * 3.  Write 1 to RESET_N
- * 4.  Wait 1152 ref clocks (1152*16 rclk cycles)
- * 5.  Write 0 to  DDR_DIV_RESET and DFM_DIV_RESET
- * 6.  Wait 10 ref clock cycles (160 rclk cycles) before bringing up the DDR interface
- * If test mode is going to be activated, wait an additional 8191 ref clocks (8191*16 rclk
+ * 2. Wait 128 ref clock cycles (7680 rclk cycles)
+ * 3. Write 1 to RESET_N
+ * 4. Wait 1152 ref clocks (1152*16 rclk cycles)
+ * 5. Write 0 to DDR_DIV_RESET and DFM_DIV_RESET
+ * 6. Wait 10 ref clock cycles (160 rclk cycles) before bringing up the DDR interface
+ * If test mode is going to be activated, wait an additional 8191 ref clocks (8191*16 rclk+
  * cycles) to allow PLL clock alignment.
  */
 union cvmx_lmcx_ddr_pll_ctl {
 	uint64_t u64;
 	struct cvmx_lmcx_ddr_pll_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_31_63               : 33;
-	uint64_t phy_dcok                     : 1;  /**< Set to power up PHY logic after setting LMC#_DDR_PLL_CTL[DDR4_MODE]. */
-	uint64_t ddr4_mode                    : 1;  /**< DDR4 mode select (0 for DDR3). */
+	uint64_t reserved_32_63               : 32;
+	uint64_t dclk_invert                  : 1;  /**< Invert dclk that feeds LMC/DDR at the south side of the chip. */
+	uint64_t phy_dcok                     : 1;  /**< Set to power up PHY logic after setting LMC(0..3)_DDR_PLL_CTL[DDR4_MODE]. */
+	uint64_t ddr4_mode                    : 1;  /**< DDR4 mode select: 1 = DDR4, 0 = DDR3. */
 	uint64_t pll_fbslip                   : 1;  /**< PLL FBSLIP indication. */
 	uint64_t pll_lock                     : 1;  /**< PLL LOCK indication. */
 	uint64_t reserved_18_26               : 9;
 	uint64_t diffamp                      : 4;  /**< PLL diffamp input transconductance */
 	uint64_t cps                          : 3;  /**< PLL charge-pump current */
-	uint64_t cpb                          : 3;  /**< PLL charge-pump current */
+	uint64_t reserved_8_10                : 3;
 	uint64_t reset_n                      : 1;  /**< PLL reset */
 	uint64_t clkf                         : 7;  /**< Multiply reference by CLKF
                                                          32 <= CLKF <= 64
@@ -5393,7 +5441,7 @@ union cvmx_lmcx_ddr_pll_ctl {
 #else
 	uint64_t clkf                         : 7;
 	uint64_t reset_n                      : 1;
-	uint64_t cpb                          : 3;
+	uint64_t reserved_8_10                : 3;
 	uint64_t cps                          : 3;
 	uint64_t diffamp                      : 4;
 	uint64_t reserved_18_26               : 9;
@@ -5401,7 +5449,8 @@ union cvmx_lmcx_ddr_pll_ctl {
 	uint64_t pll_fbslip                   : 1;
 	uint64_t ddr4_mode                    : 1;
 	uint64_t phy_dcok                     : 1;
-	uint64_t reserved_31_63               : 33;
+	uint64_t dclk_invert                  : 1;
+	uint64_t reserved_32_63               : 32;
 #endif
 	} s;
 	struct cvmx_lmcx_ddr_pll_ctl_cn61xx {
@@ -5477,15 +5526,14 @@ union cvmx_lmcx_ddr_pll_ctl {
 	uint64_t pll_fbslip                   : 1;  /**< PLL FBSLIP indication. */
 	uint64_t pll_lock                     : 1;  /**< PLL LOCK indication. */
 	uint64_t pll_rfslip                   : 1;  /**< PLL RFSLIP indication. */
-	uint64_t clkr                         : 2;  /**< PLL post divider control. */
-	uint64_t jtg_test_mode                : 1;  /**< "Reserved; must be zero. INTERNAL: JTAG Test Mode. Clock alignment between DCLK & REFCLK
-                                                         as well as FCLK & REFCLK can only be performed after the ddr_pll_divider_reset is
-                                                         deasserted. SW need to wait atleast 10 reference clock cycles after deasserting
-                                                         pll_divider_reset before asserting LMC#_DDR_PLL_CTL[JTG_TEST_MODE]. During alignment
-                                                         (which can take upto 160 microseconds) DCLK and FCLK can exhibit some high frequency
-                                                         pulses. Therefore, all bring up activities in that clock domain need to be delayed (when
-                                                         the chip operates in jtg_test_mode) by about 160 microseconds to ensure that lock is
-                                                         achieved." */
+	uint64_t clkr                         : 2;  /**< PLL post-divider control. */
+	uint64_t jtg_test_mode                : 1;  /**< Reserved; must be zero. INTERNAL: JTAG test mode. Clock alignment between DCLK & REFCLK as
+                                                         well as FCLK & REFCLK can only be performed after the ddr_pll_divider_reset is deasserted.
+                                                         SW need to wait at least 10 reference clock cycles after deasserting pll_divider_reset
+                                                         before asserting LMC(0..0)_DDR_PLL_CTL[JTG_TEST_MODE]. During alignment (which can take up
+                                                         to 160 microseconds) DCLK and FCLK can exhibit some high-frequency pulses. Therefore, all
+                                                         bring up activities in that clock domain need to be delayed (when the chip operates in
+                                                         jtg_test_mode) by about 160 microseconds to ensure that lock is achieved. */
 	uint64_t ddr_div_reset                : 1;  /**< DDR postscalar divider reset. */
 	uint64_t ddr_ps_en                    : 4;  /**< DDR postscalar divide ratio. Determines the LMC CK speed.
                                                          0x0 = divide LMC PLL by 1.
@@ -5525,7 +5573,65 @@ union cvmx_lmcx_ddr_pll_ctl {
 	uint64_t reserved_31_63               : 33;
 #endif
 	} cn70xx;
-	struct cvmx_lmcx_ddr_pll_ctl_cn70xx   cn78xx;
+	struct cvmx_lmcx_ddr_pll_ctl_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t dclk_invert                  : 1;  /**< Invert dclk that feeds LMC/DDR at the south side of the chip. */
+	uint64_t phy_dcok                     : 1;  /**< Set to power up PHY logic after setting LMC(0..3)_DDR_PLL_CTL[DDR4_MODE]. */
+	uint64_t ddr4_mode                    : 1;  /**< DDR4 mode select: 1 = DDR4, 0 = DDR3. */
+	uint64_t pll_fbslip                   : 1;  /**< PLL FBSLIP indication. */
+	uint64_t pll_lock                     : 1;  /**< PLL LOCK indication. */
+	uint64_t pll_rfslip                   : 1;  /**< PLL RFSLIP indication. */
+	uint64_t clkr                         : 2;  /**< PLL post-divider control. */
+	uint64_t jtg_test_mode                : 1;  /**< Reserved; must be zero. INTERNAL: JTAG test mode. Clock alignment between DCLK & REFCLK as
+                                                         well as FCLK & REFCLK can only be performed after the ddr_pll_divider_reset is deasserted.
+                                                         SW need to wait at least 10 reference clock cycles after deasserting pll_divider_reset
+                                                         before asserting LMC(0..3)_DDR_PLL_CTL[JTG_TEST_MODE]. During alignment (which can take up
+                                                         to 160 microseconds) DCLK and FCLK can exhibit some high-frequency pulses. Therefore, all
+                                                         bring up activities in that clock domain need to be delayed (when the chip operates in
+                                                         jtg_test_mode) by about 160 microseconds to ensure that lock is achieved. */
+	uint64_t ddr_div_reset                : 1;  /**< DDR postscalar divider reset. */
+	uint64_t ddr_ps_en                    : 4;  /**< DDR postscalar divide ratio. Determines the LMC CK speed.
+                                                         0x0 = divide LMC PLL by TBD.
+                                                         0x1 = divide LMC PLL by TBD.
+                                                         0x2 = divide LMC PLL by TBD.
+                                                         0x3 = divide LMC PLL by TBD.
+                                                         0x4 = divide LMC PLL by TBD.
+                                                         0x5 = divide LMC PLL by TBD.
+                                                         0x6 = divide LMC PLL by TBD.
+                                                         0x7 = divide LMC PLL by TBD.
+                                                         0x8 = divide LMC PLL by TBD.
+                                                         0x9 = divide LMC PLL by TBD.
+                                                         0xA = divide LMC PLL by TBD.
+                                                         0xB = divide LMC PLL by TBD.
+                                                         0xC = divide LMC PLL by TBD.
+                                                         0xD = divide LMC PLL by TBD.
+                                                         0xE = divide LMC PLL by TBD.
+                                                         0xF = divide LMC PLL by TBD.
+                                                         DDR_PS_EN is not used when DDR_DIV_RESET = 1 */
+	uint64_t reserved_9_17                : 9;
+	uint64_t clkf_ext                     : 1;  /**< A 1-bit extension to the CLKF register to support for DDR4-2666. */
+	uint64_t reset_n                      : 1;  /**< PLL reset */
+	uint64_t clkf                         : 7;  /**< Multiply reference by CLKF. 32 <= CLKF <= 64. LMC PLL frequency = 50 * CLKF. min = 1.6
+                                                         GHz, max = 3.2 GHz. */
+#else
+	uint64_t clkf                         : 7;
+	uint64_t reset_n                      : 1;
+	uint64_t clkf_ext                     : 1;
+	uint64_t reserved_9_17                : 9;
+	uint64_t ddr_ps_en                    : 4;
+	uint64_t ddr_div_reset                : 1;
+	uint64_t jtg_test_mode                : 1;
+	uint64_t clkr                         : 2;
+	uint64_t pll_rfslip                   : 1;
+	uint64_t pll_lock                     : 1;
+	uint64_t pll_fbslip                   : 1;
+	uint64_t ddr4_mode                    : 1;
+	uint64_t phy_dcok                     : 1;
+	uint64_t dclk_invert                  : 1;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} cn78xx;
 	struct cvmx_lmcx_ddr_pll_ctl_cn61xx   cnf71xx;
 };
 typedef union cvmx_lmcx_ddr_pll_ctl cvmx_lmcx_ddr_pll_ctl_t;
@@ -5604,7 +5710,7 @@ typedef union cvmx_lmcx_delay_cfg cvmx_lmcx_delay_cfg_t;
  * cvmx_lmc#_dimm#_ddr4_params0
  *
  * This register contains values to be programmed into the extra DDR4 control words in the
- * corresponding (registered) DIMM.  These are control words RC1x through RC8x.
+ * corresponding (registered) DIMM. These are control words RC1x through RC8x.
  */
 union cvmx_lmcx_dimmx_ddr4_params0 {
 	uint64_t u64;
@@ -5638,7 +5744,7 @@ typedef union cvmx_lmcx_dimmx_ddr4_params0 cvmx_lmcx_dimmx_ddr4_params0_t;
  * cvmx_lmc#_dimm#_ddr4_params1
  *
  * This register contains values to be programmed into the extra DDR4 control words in the
- * corresponding (registered) DIMM.  These are control words RCBx through RC9x.
+ * corresponding (registered) DIMM. These are control words RC9x through RCBx.
  */
 union cvmx_lmcx_dimmx_ddr4_params1 {
 	uint64_t u64;
@@ -5903,7 +6009,8 @@ union cvmx_lmcx_dll_ctl2 {
 	uint64_t intf_en                      : 1;  /**< Interface enable. */
 	uint64_t dll_bringup                  : 1;  /**< DLL bring up. */
 	uint64_t dreset                       : 1;  /**< System-memory-clock domain reset. The reset signal that is used by the system-memory-clock
-                                                         domain is (DRESET -OR- core-clock reset). */
+                                                         domain is
+                                                         (DRESET -OR- core-clock reset). */
 	uint64_t quad_dll_ena                 : 1;  /**< DLL enable. */
 	uint64_t byp_sel                      : 4;  /**< Reserved; must be zero. INTERNAL: Bypass select.
                                                          0000 = no byte.
@@ -5913,9 +6020,9 @@ union cvmx_lmcx_dll_ctl2 {
                                                          1010 = all bytes.
                                                          1011-1111 = Reserved. */
 	uint64_t byp_setting                  : 9;  /**< Reserved; must be zero. INTERNAL: Bypass setting.
-                                                         DDR3-1600 : 00100010.
-                                                         DDR3-1333 : 00110010.
-                                                         DDR3-1066 : 01001011.
+                                                         DDR3-1600: 00100010.
+                                                         DDR3-1333: 00110010.
+                                                         DDR3-1066: 01001011.
                                                          DDR3-800  : 01110101.
                                                          DDR3-667  : 10010110.
                                                          DDR3-600  : 10101100. */
@@ -6136,7 +6243,7 @@ typedef union cvmx_lmcx_dll_ctl3 cvmx_lmcx_dll_ctl3_t;
  * cvmx_lmc#_dual_memcfg
  *
  * This register controls certain parameters of dual-memory configuration.
- * This register enables the design to have two, separate memory configurations, selected
+ * This register enables the design to have two separate memory configurations, selected
  * dynamically by the reference address. Note however, that both configurations share
  * LMC(0..3)_CONTROL[XOR_BANK], LMC(0..3)_CONFIG [PBANK_LSB], LMC(0..3)_CONFIG[RANK_ENA], and all
  * timing parameters.
@@ -6208,7 +6315,7 @@ union cvmx_lmcx_dual_memcfg {
 	uint64_t row_lsb                      : 3;  /**< Encoding used to determine which memory address bit position represents the low order DDR
                                                          ROW address. Refer to
                                                          LMC(0..0)_CONFIG[ROW_LSB].
-                                                         Refer to . */
+                                                         Refer to Cache-block Read Transaction Example. */
 	uint64_t reserved_4_15                : 12;
 	uint64_t cs_mask                      : 4;  /**< Chip-select mask. This mask corresponds to the four chip-select signals for a memory
                                                          configuration. Each reference address asserts one of the chip-select signals. If that
@@ -6227,6 +6334,42 @@ union cvmx_lmcx_dual_memcfg {
 typedef union cvmx_lmcx_dual_memcfg cvmx_lmcx_dual_memcfg_t;
 
 /**
+ * cvmx_lmc#_ecc_parity_test
+ *
+ * This register has bits to control the ECC and CA Parity errors creation during test modes.
+ * ECC error is generated by enabling the CA_PARITY_CORRUPT_ENA bit of this register and
+ * selecting any ECC_CORRUPT_IDX index of the dataword from the cacheline to be
+ * corrupted. User can select which bit of the 128-bits dataword to corrupt by asserting
+ * any of the CHAR_MASK0 and CHAR_MASK2 bits. (CHAR_MASK0 and CHAR_MASK2 corresponds to the
+ * lower and upper 64-bit signal that can corrupt any individual bit of the data).
+ *
+ * CA Parity error is generated by enabling CA_PARITY_CORRUPT_ENA bit of this register and
+ * selecting the DDR command that the parity is to be corrupted with through CA_PARITY_SEL.
+ */
+union cvmx_lmcx_ecc_parity_test {
+	uint64_t u64;
+	struct cvmx_lmcx_ecc_parity_test_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t ecc_corrupt_ena              : 1;  /**< enables the ECC data corruption. */
+	uint64_t ecc_corrupt_idx              : 3;  /**< selects the cacheline index that the dataword is to be corrupted with */
+	uint64_t reserved_6_7                 : 2;
+	uint64_t ca_parity_corrupt_ena        : 1;  /**< enables the CA Parity bit corruption. */
+	uint64_t ca_parity_sel                : 5;  /**< selects the type of DDR command to corrupt the parity bit. */
+#else
+	uint64_t ca_parity_sel                : 5;
+	uint64_t ca_parity_corrupt_ena        : 1;
+	uint64_t reserved_6_7                 : 2;
+	uint64_t ecc_corrupt_idx              : 3;
+	uint64_t ecc_corrupt_ena              : 1;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} s;
+	struct cvmx_lmcx_ecc_parity_test_s    cn78xx;
+};
+typedef union cvmx_lmcx_ecc_parity_test cvmx_lmcx_ecc_parity_test_t;
+
+/**
  * cvmx_lmc#_ecc_synd
  *
  * LMC_ECC_SYND = MRD ECC Syndromes
@@ -6291,33 +6434,66 @@ typedef union cvmx_lmcx_ecc_synd cvmx_lmcx_ecc_synd_t;
 /**
  * cvmx_lmc#_ext_config
  *
- * This register has additional configuration and control bits for the LMC
+ * This register has additional configuration and control bits for the LMC.
  *
  */
 union cvmx_lmcx_ext_config {
 	uint64_t u64;
 	struct cvmx_lmcx_ext_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_21_63               : 43;
+	uint64_t reserved_46_63               : 18;
+	uint64_t error_alert_n_sample         : 1;  /**< Read to get a sample of the DRAM error_alert_n pin. */
+	uint64_t ea_int_polarity              : 1;  /**< Set to invert error_alert_n interrupt polarity.  When clear, interrupt will be signaled
+                                                         on the rising edge of error_alert_n.  When set, interrupt will be signeld on the falling
+                                                         edge of error_alert_n. */
+	uint64_t reserved_43_43               : 1;
+	uint64_t par_addr_mask                : 3;  /**< Mask applied to parity for address bits 14, 13, and 12.  Clear to exclude these
+                                                         address bits from the parity calculation, necessary if the DRAM device does not
+                                                         have these pins. */
+	uint64_t reserved_38_39               : 2;
+	uint64_t mrs_cmd_override             : 1;  /**< Set to override behavior of MRS and RCS DRAM operations. */
+	uint64_t mrs_cmd_select               : 1;  /**< When LMC(0..3)_EXT_CONFIG[MRS_CMD_OVERRIDE] is set, use this bit to select which
+                                                         style of operation for MRS and RCW commands.  If clear, select operation where
+                                                         signals other than CS are active before and after the CS_N active cycle.  When set,
+                                                         select operation where the other command signals (RAS_N,CAS_N,WE_n,ADDR,etc) all are
+                                                         active only during the cycle where the CS_N is also active. */
+	uint64_t reserved_33_35               : 3;
+	uint64_t invert_data                  : 1;  /**< Set this bit to cause all data to be inverted before writing or reading to/from
+                                                         DRAM - this effectively uses the scramble logic to instead invert all the data,
+                                                         so this bit must not be set if data scrambling is enabled.  May be useful if
+                                                         data inversion will result in lower power. */
+	uint64_t reserved_30_31               : 2;
+	uint64_t cmd_rti                      : 1;  /**< Set this bit to change the behavior of the LMC to return to a completely
+                                                         idle command (no CS active, no command pins active, and address/ba/bg all low)
+                                                         on the interface after an active command, rather than only forcing the CS
+                                                         inactive between commands. */
+	uint64_t cal_ena                      : 1;  /**< Set to cause LMC to operate in CAL mode.  DRAM mode registers must first be
+                                                         programmed into CAL mode, then set CAL_ENABLE. */
+	uint64_t reserved_27_27               : 1;
+	uint64_t par_include_a17              : 1;  /**< If set, include A17 in parity calculations in DDR4 mode. */
+	uint64_t par_include_bg1              : 1;  /**< If set, include BG1 in parity calculations in DDR4 mode. */
+	uint64_t gen_par                      : 1;  /**< Enable parity generation in the DRAM commands, must be set prior to enabling
+                                                         parity in register or DRAM devices */
+	uint64_t reserved_21_23               : 3;
 	uint64_t vrefint_seq_deskew           : 1;  /**< Personality bit to change the operation of what is normally the internal
                                                          vref training sequence into the deskew training sequence. */
-	uint64_t read_ena_bprch               : 1;  /**< Drive DQx for one cycle longer than normal during write operations. */
-	uint64_t read_ena_fprch               : 1;  /**< Drive DQX starting one cycle earlier than normal during write operations. */
-	uint64_t slot_ctl_reset_force         : 1;  /**< Write 1 to reset the slot control override for all slot control registers.
-                                                         After writing a 1 to this bit, slot control registers will update with changes made to
-                                                         other timing control registers.  One shot operation, will automatically return to 0
-                                                         after a write to 1. */
-	uint64_t ref_int_lsbs                 : 9;  /**< These are the 9 LSBs for the refresh interval value, default to 0, but can be set to
-                                                         a non-zero value to get a more precise refresh interval. */
+	uint64_t read_ena_bprch               : 1;  /**< Enable pad receiver one cycle longer than normal during read operations. */
+	uint64_t read_ena_fprch               : 1;  /**< Enable pad receiver starting one cycle earlier than normal during read operations. */
+	uint64_t slot_ctl_reset_force         : 1;  /**< Write 1 to reset the slot-control override for all slot-control registers. After writing a
+                                                         1 to this bit, slot-control registers will update with changes made to other timing-
+                                                         control registers. This is a one-shot operation; it automatically returns to 0 after a
+                                                         write to 1. */
+	uint64_t ref_int_lsbs                 : 9;  /**< Refresh-interval value least-significant bits. The default is 0x0; but it can be set to a
+                                                         non-zero value to get a more precise refresh interval. */
 	uint64_t drive_ena_bprch              : 1;  /**< Drive DQx for one cycle longer than normal during write operations. */
 	uint64_t drive_ena_fprch              : 1;  /**< Drive DQX starting one cycle earlier than normal during write operations. */
-	uint64_t dlcram_flip_synd             : 2;  /**< INTERNAL: DLC RAM flip syndrome control bits. */
-	uint64_t dlcram_cor_dis               : 1;  /**< INTERNAL: DLC RAM correction disable control. */
-	uint64_t dlc_nxm_rd                   : 1;  /**< When set, enable NXM events for DLC reads.  Default is disabled, but
+	uint64_t dlcram_flip_synd             : 2;  /**< Reserved. INTERNAL: DLC RAM flip syndrome control bits. */
+	uint64_t dlcram_cor_dis               : 1;  /**< Reserved. INTERNAL: DLC RAM correction disable control. */
+	uint64_t dlc_nxm_rd                   : 1;  /**< When set, enable NXM events for HFA read operations. INTERNAL: Default is disabled, but
                                                          could be useful for debug of DLC/DFA accesses. */
-	uint64_t l2c_nxm_rd                   : 1;  /**< When set, enable NXM events for L2C reads.  Default is disabled
-                                                         as L2C NXM reads are possible and expected during normal operation. */
-	uint64_t l2c_nxm_wr                   : 1;  /**< When set, enable NXM events for L2C writes. */
+	uint64_t l2c_nxm_rd                   : 1;  /**< When set, enable NXM events for L2C read operations. INTERNAL: Default is disabled as L2C
+                                                         NXM read operations are possible and expected during normal operation. */
+	uint64_t l2c_nxm_wr                   : 1;  /**< When set, enable NXM events for L2C write operations. */
 #else
 	uint64_t l2c_nxm_wr                   : 1;
 	uint64_t l2c_nxm_rd                   : 1;
@@ -6331,30 +6507,48 @@ union cvmx_lmcx_ext_config {
 	uint64_t read_ena_fprch               : 1;
 	uint64_t read_ena_bprch               : 1;
 	uint64_t vrefint_seq_deskew           : 1;
-	uint64_t reserved_21_63               : 43;
+	uint64_t reserved_21_23               : 3;
+	uint64_t gen_par                      : 1;
+	uint64_t par_include_bg1              : 1;
+	uint64_t par_include_a17              : 1;
+	uint64_t reserved_27_27               : 1;
+	uint64_t cal_ena                      : 1;
+	uint64_t cmd_rti                      : 1;
+	uint64_t reserved_30_31               : 2;
+	uint64_t invert_data                  : 1;
+	uint64_t reserved_33_35               : 3;
+	uint64_t mrs_cmd_select               : 1;
+	uint64_t mrs_cmd_override             : 1;
+	uint64_t reserved_38_39               : 2;
+	uint64_t par_addr_mask                : 3;
+	uint64_t reserved_43_43               : 1;
+	uint64_t ea_int_polarity              : 1;
+	uint64_t error_alert_n_sample         : 1;
+	uint64_t reserved_46_63               : 18;
 #endif
 	} s;
-	struct cvmx_lmcx_ext_config_s         cn70xx;
-	struct cvmx_lmcx_ext_config_cn78xx {
+	struct cvmx_lmcx_ext_config_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_20_63               : 44;
-	uint64_t read_ena_bprch               : 1;  /**< Drive DQx for one cycle longer than normal during write operations. */
-	uint64_t read_ena_fprch               : 1;  /**< Drive DQX starting one cycle earlier than normal during write operations. */
-	uint64_t slot_ctl_reset_force         : 1;  /**< Write 1 to reset the slot control override for all slot control registers.
-                                                         After writing a 1 to this bit, slot control registers will update with changes made to
-                                                         other timing control registers.  One shot operation, will automatically return to 0
-                                                         after a write to 1. */
+	uint64_t reserved_21_63               : 43;
+	uint64_t vrefint_seq_deskew           : 1;  /**< Personality bit to change the operation of what is normally the internal
+                                                         vref training sequence into the deskew training sequence. */
+	uint64_t read_ena_bprch               : 1;  /**< Enable pad receiver one cycle longer than normal during read operations. */
+	uint64_t read_ena_fprch               : 1;  /**< Enable pad receiver starting one cycle earlier than normal during read operations. */
+	uint64_t slot_ctl_reset_force         : 1;  /**< Write 1 to reset the slot-control override for all slot-control registers. After writing a
+                                                         1 to this bit, slot-control registers will update with changes made to other timing-
+                                                         control registers. This is a one-shot operation; it automatically returns to 0 after a
+                                                         write to 1. */
 	uint64_t ref_int_lsbs                 : 9;  /**< These are the 9 LSBs for the refresh interval value, default to 0, but can be set to
                                                          a non-zero value to get a more precise refresh interval. */
 	uint64_t drive_ena_bprch              : 1;  /**< Drive DQx for one cycle longer than normal during write operations. */
 	uint64_t drive_ena_fprch              : 1;  /**< Drive DQX starting one cycle earlier than normal during write operations. */
-	uint64_t dlcram_flip_synd             : 2;  /**< INTERNAL: DLC RAM flip syndrome control bits. */
-	uint64_t dlcram_cor_dis               : 1;  /**< INTERNAL: DLC RAM correction disable control. */
+	uint64_t dlcram_flip_synd             : 2;  /**< Reserved. INTERNAL: DLC RAM flip syndrome control bits. */
+	uint64_t dlcram_cor_dis               : 1;  /**< Reserved. INTERNAL: DLC RAM correction disable control. */
 	uint64_t dlc_nxm_rd                   : 1;  /**< When set, enable NXM events for DLC reads.  Default is disabled, but
                                                          could be useful for debug of DLC/DFA accesses. */
-	uint64_t l2c_nxm_rd                   : 1;  /**< When set, enable NXM events for L2C reads.  Default is disabled
-                                                         as L2C NXM reads are possible and expected during normal operation. */
-	uint64_t l2c_nxm_wr                   : 1;  /**< When set, enable NXM events for L2C writes. */
+	uint64_t l2c_nxm_rd                   : 1;  /**< When set, enable NXM events for L2C read operations. INTERNAL: Default is disabled as L2C
+                                                         NXM read operations are possible and expected during normal operation. */
+	uint64_t l2c_nxm_wr                   : 1;  /**< When set, enable NXM events for L2C write operations. */
 #else
 	uint64_t l2c_nxm_wr                   : 1;
 	uint64_t l2c_nxm_rd                   : 1;
@@ -6367,19 +6561,29 @@ union cvmx_lmcx_ext_config {
 	uint64_t slot_ctl_reset_force         : 1;
 	uint64_t read_ena_fprch               : 1;
 	uint64_t read_ena_bprch               : 1;
-	uint64_t reserved_20_63               : 44;
+	uint64_t vrefint_seq_deskew           : 1;
+	uint64_t reserved_21_63               : 43;
 #endif
-	} cn78xx;
+	} cn70xx;
+	struct cvmx_lmcx_ext_config_s         cn78xx;
 };
 typedef union cvmx_lmcx_ext_config cvmx_lmcx_ext_config_t;
 
 /**
  * cvmx_lmc#_fadr
  *
- * This register only captures the first transaction with ECC errors. A DED error can
- * over-write this register with its failing addresses if the first error was a SEC. If you write
- * LMC*_INT -> SEC_ERR/DED_ERR, it clears the error bits and captures the next failing
+ * This register only captures the first transaction with ECC errors. A DED error can over-write
+ * this register with its failing addresses if the first error was a SEC. If you write
+ * LMC(0..3)_INT -> SEC_ERR/DED_ERR, it clears the error bits and captures the next failing
  * address. If FDIMM is 1, that means the error is in the high DIMM.
+ * LMC(0..3)_FADR captures the failing pre-scrambled address location (split into DIMM, bunk,
+ * bank, etc). If scrambling is off, then LMC(0..3)_FADR will also capture the failing physical
+ * location in the DRAM parts. LMC(0..3)_SCRAMBLED_FADR captures the actual failing address
+ * location in the physical DRAM parts, i.e.,
+ * If scrambling is on, LMC(0..3)_SCRAMBLED_FADR contains the failing physical location in the
+ * DRAM parts (split into DIMM, bunk, bank, etc.)
+ * If scrambling is off, the pre-scramble and post-scramble addresses are the same; and so the
+ * contents of LMC(0..3)_SCRAMBLED_FADR match the contents of LMC(0..3)_FADR.
  */
 union cvmx_lmcx_fadr {
 	uint64_t u64;
@@ -6582,7 +6786,7 @@ union cvmx_lmcx_int {
 	struct cvmx_lmcx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t ddr_err                      : 1;  /**< DDR RAM Error alert interrupt. */
+	uint64_t ddr_err                      : 1;  /**< DDR RAM error alert interrupt. */
 	uint64_t dlcram_ded_err               : 1;  /**< DLC RAM ECC double error detect (DED). */
 	uint64_t dlcram_sec_err               : 1;  /**< DLC RAM ECC single error correct (SEC). */
 	uint64_t ded_err                      : 4;  /**< Double Error detected (DED) of Rd Data
@@ -6738,7 +6942,7 @@ typedef union cvmx_lmcx_int_en cvmx_lmcx_int_en_t;
 /**
  * cvmx_lmc#_lane#_crc_swiz
  *
- * CRC bit swizzle for even and odd ranks.
+ * This register contains the CRC bit swizzle for even and odd ranks.
  *
  */
 union cvmx_lmcx_lanex_crc_swiz {
@@ -7650,27 +7854,27 @@ union cvmx_lmcx_modereg_params3 {
 	uint64_t wr_cmd_lat                   : 2;  /**< Write command latency when CRC and DM are both enabled. */
 	uint64_t fgrm                         : 3;  /**< Fine granularity refresh mode. */
 	uint64_t temp_sense                   : 1;  /**< Temperature sensor readout enable. */
-	uint64_t pda                          : 1;  /**< Per DRAM Addressability. */
+	uint64_t pda                          : 1;  /**< Per DRAM addressability. */
 	uint64_t gd                           : 1;  /**< Gear-down mode. */
 	uint64_t crc                          : 1;  /**< CRC mode. */
-	uint64_t lpasr                        : 2;  /**< LP Auto Self Refresh. */
-	uint64_t tccd_l                       : 3;  /**< TCCD_L timing parameter
-                                                         - 000: 4. 011: 7.
-                                                         - 001: 5. 100: 8.
-                                                         - 010: 6. 101-111: Reserved. */
+	uint64_t lpasr                        : 2;  /**< LP auto self refresh. */
+	uint64_t tccd_l                       : 3;  /**< TCCD_L timing parameter:
+                                                         0x0 = 4. 0x3 = 7.
+                                                         0x1 = 5. 0x4 = 8.
+                                                         0x2 = 6. 0x5-0x7 = reserved. */
 	uint64_t rd_dbi                       : 1;  /**< Read DBI. */
 	uint64_t wr_dbi                       : 1;  /**< Write DBI. */
 	uint64_t dm                           : 1;  /**< Data mask enable. */
 	uint64_t ca_par_pers                  : 1;  /**< Command/address persistent parity error mode. */
 	uint64_t odt_pd                       : 1;  /**< ODT in PD mode. */
 	uint64_t par_lat_mode                 : 3;  /**< Parity latency mode. */
-	uint64_t wr_preamble                  : 1;  /**< Write preamble, 0 = 1 nCK, 1 = 2 nCK. */
-	uint64_t rd_preamble                  : 1;  /**< Write preamble, 0 = 1 nCK, 1 = 2 nCK. */
+	uint64_t wr_preamble                  : 1;  /**< Write preamble, 0 = one nCK, 1 = two nCK. */
+	uint64_t rd_preamble                  : 1;  /**< Write preamble, 0 = one nCK, 1 = two nCK. */
 	uint64_t sre_abort                    : 1;  /**< Self refresh abort. */
-	uint64_t cal                          : 3;  /**< CS to CMD/ADDR latency mode (cycles). */
-	uint64_t vref_mon                     : 1;  /**< Internal VREF monitor, 0 = Disable, 1 = Enable. */
-	uint64_t tc_ref                       : 1;  /**< Temperature Controlled Refresh Range, 0 = Normal, 1 = Extended. */
-	uint64_t max_pd                       : 1;  /**< Maximum power down mode, 0 = Disable, 1 = Enable. */
+	uint64_t cal                          : 3;  /**< CS-to-CMD/ADDR latency mode (cycles). */
+	uint64_t vref_mon                     : 1;  /**< Internal VREF monitor: 0 = disable, 1 = enable. */
+	uint64_t tc_ref                       : 1;  /**< Temperature controlled refresh range: 0 = normal, 1 = extended. */
+	uint64_t max_pd                       : 1;  /**< Maximum power-down mode: 0 = disable, 1 = enable. */
 #else
 	uint64_t max_pd                       : 1;
 	uint64_t tc_ref                       : 1;
@@ -7705,16 +7909,15 @@ typedef union cvmx_lmcx_modereg_params3 cvmx_lmcx_modereg_params3_t;
 /**
  * cvmx_lmc#_mpr_data0
  *
- * Bits <63:0> of MPR data register.
+ * This register provides bits <63:0> of MPR data register.
  *
  */
 union cvmx_lmcx_mpr_data0 {
 	uint64_t u64;
 	struct cvmx_lmcx_mpr_data0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t mpr_data                     : 64; /**< MPR data bits <63:0>.  Bits <7:0> represent the MPR data for the lowest order
-                                                         x4 device (x4 device number 0), bits <15:8> represent x4 device number 1, ...,
-                                                         bits <63:56> are for x4 device number 7. */
+	uint64_t mpr_data                     : 64; /**< MPR data bits<63:0>. Bits<7:0> represent the MPR data for the lowest-order *4 device (*4
+                                                         device 0); bits<15:8> represent *4 device 1; ..., bits<63:56> are for *4 device 7. */
 #else
 	uint64_t mpr_data                     : 64;
 #endif
@@ -7727,16 +7930,15 @@ typedef union cvmx_lmcx_mpr_data0 cvmx_lmcx_mpr_data0_t;
 /**
  * cvmx_lmc#_mpr_data1
  *
- * Bits <127:64> of MPR data register.
+ * This register provides bits <127:64> of MPR data register.
  *
  */
 union cvmx_lmcx_mpr_data1 {
 	uint64_t u64;
 	struct cvmx_lmcx_mpr_data1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t mpr_data                     : 64; /**< MPR data bits <127:64>.  Bits <7:0> of the field represent the MPR data for
-                                                         x4 device number 8, bits <15:8> represent x4 device numnber 9, ..., and bits
-                                                         <63:56> represent x4 device number 15. */
+	uint64_t mpr_data                     : 64; /**< MPR data bits<127:64>. Bits<7:0> represent the MPR data for *4 device 8; bits<15:8>
+                                                         represent *4 device 9; ...; bits<63:56> are for *4 device 15. */
 #else
 	uint64_t mpr_data                     : 64;
 #endif
@@ -7749,7 +7951,7 @@ typedef union cvmx_lmcx_mpr_data1 cvmx_lmcx_mpr_data1_t;
 /**
  * cvmx_lmc#_mpr_data2
  *
- * Bits <143:128> of MPR data register.
+ * This register provides bits <143:128> of MPR data register.
  *
  */
 union cvmx_lmcx_mpr_data2 {
@@ -7757,8 +7959,8 @@ union cvmx_lmcx_mpr_data2 {
 	struct cvmx_lmcx_mpr_data2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t mpr_data                     : 16; /**< MPR data bits <143:128>.  Bits <7:0> of the field represent the MPR data for
-                                                         x4 device number 16, and bits <15:8> represent x4 device number 17. */
+	uint64_t mpr_data                     : 16; /**< MPR data bits<143:128>. Bits<7:0> represent the MPR data for *4 device 16; bits<15:8>
+                                                         represent *4 device 17. */
 #else
 	uint64_t mpr_data                     : 16;
 	uint64_t reserved_16_63               : 48;
@@ -7779,30 +7981,77 @@ union cvmx_lmcx_mr_mpr_ctl {
 	uint64_t u64;
 	struct cvmx_lmcx_mr_mpr_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_57_63               : 7;
+	uint64_t mr_wr_bg1                    : 1;  /**< BG1 part of address select for MRS in DDR4 mode. */
+	uint64_t reserved_53_55               : 3;
+	uint64_t mr_wr_use_default_value      : 1;  /**< When set, write the value to the MR that is computed from the value set in various CSR
+                                                         fields that would be used during initialization, rather that using the value in the
+                                                         LMC(0..3)_MR_MPR_CTL[MR_WR_ADDR] CSR field.  Useful to re-write the same value or
+                                                         to change single bits without having to compute a whole new value for the MR. */
+	uint64_t mpr_whole_byte_enable        : 1;  /**< Reserved. INTERNAL: Select a whole byte of DRAM data to read when whole-byte mode enabled. */
+	uint64_t mpr_byte_select              : 4;  /**< Reserved. INTERNAL: Select a whole byte of DRAM data to read when whole-byte mode enabled. */
+	uint64_t mpr_bit_select               : 2;  /**< Select which of four bits to read for each nibble of DRAM data. Typically all four bits
+                                                         from a *4 device, or all eight bits from a *8 device, or all 16 bits from a *16 device
+                                                         carry the same data, but this field allows selection of which device bit will be used to
+                                                         read the MPR data. */
+	uint64_t mpr_wr                       : 1;  /**< MPR sequence will perform a write operation when set. */
+	uint64_t mpr_loc                      : 2;  /**< MPR location select for MPR sequence. Only makes a difference for DDR4. */
+	uint64_t mr_wr_pda_enable             : 1;  /**< PDA write enable. When set, MRW operations use PDA, enabled by MR_WR_PDA_MASK per device.
+                                                         Only available for DDR4 devices. */
+	uint64_t mr_wr_pda_mask               : 18; /**< PDA mask. If MR_WR_PDA_ENABLE = 1 and there is a 1 in the bit for this mask value, then
+                                                         the corresponding DRAM device is enabled for the PDA MR write operation.
+                                                         Bit<23> corresponds to the lowest order, *4 device, and bit<40> corresponds to the highest
+                                                         order *4 device, for a total of up to 18 devices. */
+	uint64_t mr_wr_rank                   : 2;  /**< Selects the DRAM rank for either MRW or MPR sequences. */
+	uint64_t mr_wr_sel                    : 3;  /**< Selects which MR to write with the MR write sequence.
+                                                         Which pins to drive and how to drive them is automatically controlled through the DDR3/4
+                                                         mode setting. Bits<19:18> are also used to select the MPR page for an MPR sequence.
+                                                         A value of 0x7 selects an RCW write for both DDR4 and DDR3 MRW operations. */
+	uint64_t mr_wr_addr                   : 18; /**< Sets a value for A<17:0> for MR write operations. Note that many of these bits must be 0
+                                                         for various MRs. Bits<7:0> are also used for write data on an MPR sequence write
+                                                         operation. */
+#else
+	uint64_t mr_wr_addr                   : 18;
+	uint64_t mr_wr_sel                    : 3;
+	uint64_t mr_wr_rank                   : 2;
+	uint64_t mr_wr_pda_mask               : 18;
+	uint64_t mr_wr_pda_enable             : 1;
+	uint64_t mpr_loc                      : 2;
+	uint64_t mpr_wr                       : 1;
+	uint64_t mpr_bit_select               : 2;
+	uint64_t mpr_byte_select              : 4;
+	uint64_t mpr_whole_byte_enable        : 1;
+	uint64_t mr_wr_use_default_value      : 1;
+	uint64_t reserved_53_55               : 3;
+	uint64_t mr_wr_bg1                    : 1;
+	uint64_t reserved_57_63               : 7;
+#endif
+	} s;
+	struct cvmx_lmcx_mr_mpr_ctl_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_52_63               : 12;
-	uint64_t mpr_whole_byte_enable        : 1;  /**< Select a whole byte of DRAM data to read when whole byte mode enabled. */
-	uint64_t mpr_byte_select              : 4;  /**< Select a whole byte of DRAM data to read when whole byte mode enabled. */
-	uint64_t mpr_bit_select               : 2;  /**< Select which of 4 bits to read for each nibble of DRAM data.  Typically all 4 bits
-                                                         from a x4 device, or all 8 bits from a x8 device, or all 16 bits from a x16 device
-                                                         will carry the same data, but this fields allows selection of which device bit will
-                                                         be used to read the MPR data. */
+	uint64_t mpr_whole_byte_enable        : 1;  /**< Reserved. INTERNAL: Select a whole byte of DRAM data to read when whole-byte mode enabled. */
+	uint64_t mpr_byte_select              : 4;  /**< Reserved. INTERNAL: Select a whole byte of DRAM data to read when whole-byte mode enabled. */
+	uint64_t mpr_bit_select               : 2;  /**< Select which of four bits to read for each nibble of DRAM data. Typically all four bits
+                                                         from a *4 device, or all eight bits from a *8 device, or all 16 bits from a *16 device
+                                                         carry the same data, but this field allows selection of which device bit will be used to
+                                                         read the MPR data. */
 	uint64_t mpr_wr                       : 1;  /**< MPR sequence will perform a write operation when set. */
-	uint64_t mpr_loc                      : 2;  /**< MPR location select for MPR sequence, only makes a difference for DDR4. */
-	uint64_t mr_wr_pda_enable             : 1;  /**< PDA write enable, if set MRW operations will use PDA, enabled by the
-                                                         LMC(0..3)_MR_MPR_CTL[MR_WR_PDA_MASK] per device. */
-	uint64_t mr_wr_pda_mask               : 18; /**< PDA mask, if LMC(0..3)_MR_MPR_CTL[MR_WR_PDA_ENABLE] is set and there is a 1 in
-                                                         the bit for this make value, then the correpsonding DRAM device will be enabled
-                                                         for the PDA MR write.  Bit <23> corresponds to the lowest order, x4 device, and
-                                                         bit <40> corresponds to the highest order x4 device, for a total of up to 18
-                                                         devices. */
-	uint64_t mr_wr_rank                   : 2;  /**< This field selects the DRAM rank for either MRW or MPR sequences. */
-	uint64_t mr_wr_sel                    : 3;  /**< Use this field to select which MR to write with the MR write seqeunce.  Which pins
-                                                         to drive and how to drive them is automatically controlled through the DDR3/4 mode
-                                                         setting.  Bits <19:18> are also used to select the MPR page for an MPR sequence.
-                                                         MR_WR_SEL==7 selects an RCW write for both DDR4 and DDR3 MRW operations. */
-	uint64_t mr_wr_addr                   : 18; /**< Use this field to set a value for A<17:0> for MR writes.  Note that many
-                                                         of these bits must be 0 for various MRs.  The lower 8 bits, <7:0> of this
-                                                         field are also used for write data on an MPR sequence write operation. */
+	uint64_t mpr_loc                      : 2;  /**< MPR location select for MPR sequence. Only makes a difference for DDR4. */
+	uint64_t mr_wr_pda_enable             : 1;  /**< PDA write enable. When set, MRW operations use PDA, enabled by MR_WR_PDA_MASK per device.
+                                                         Only available for DDR4 devices. */
+	uint64_t mr_wr_pda_mask               : 18; /**< PDA mask. If MR_WR_PDA_ENABLE = 1 and there is a 1 in the bit for this mask value, then
+                                                         the corresponding DRAM device is enabled for the PDA MR write operation.
+                                                         Bit<23> corresponds to the lowest order, *4 device, and bit<40> corresponds to the highest
+                                                         order *4 device, for a total of up to 18 devices. */
+	uint64_t mr_wr_rank                   : 2;  /**< Selects the DRAM rank for either MRW or MPR sequences. */
+	uint64_t mr_wr_sel                    : 3;  /**< Selects which MR to write with the MR write sequence.
+                                                         Which pins to drive and how to drive them is automatically controlled through the DDR3/4
+                                                         mode setting. Bits<19:18> are also used to select the MPR page for an MPR sequence.
+                                                         A value of 0x7 selects an RCW write for both DDR4 and DDR3 MRW operations. */
+	uint64_t mr_wr_addr                   : 18; /**< Sets a value for A<17:0> for MR write operations. Note that many of these bits must be 0
+                                                         for various MRs. Bits<7:0> are also used for write data on an MPR sequence write
+                                                         operation. */
 #else
 	uint64_t mr_wr_addr                   : 18;
 	uint64_t mr_wr_sel                    : 3;
@@ -7816,8 +8065,7 @@ union cvmx_lmcx_mr_mpr_ctl {
 	uint64_t mpr_whole_byte_enable        : 1;
 	uint64_t reserved_52_63               : 12;
 #endif
-	} s;
-	struct cvmx_lmcx_mr_mpr_ctl_s         cn70xx;
+	} cn70xx;
 	struct cvmx_lmcx_mr_mpr_ctl_s         cn78xx;
 };
 typedef union cvmx_lmcx_mr_mpr_ctl cvmx_lmcx_mr_mpr_ctl_t;
@@ -7826,24 +8074,7 @@ typedef union cvmx_lmcx_mr_mpr_ctl cvmx_lmcx_mr_mpr_ctl_t;
  * cvmx_lmc#_nxm
  *
  * Following is the decoding for mem_msb/rank:
- * - 0000: mem_msb = mem_adr[25]
- * - 0001: mem_msb = mem_adr[26]
- * - 0010: mem_msb = mem_adr[27]
- * - 0011: mem_msb = mem_adr[28]
- * - 0100: mem_msb = mem_adr[29]
- * - 0101: mem_msb = mem_adr[30]
- * - 0110: mem_msb = mem_adr[31]
- * - 0111: mem_msb = mem_adr[32]
- * - 1000: mem_msb = mem_adr[33]
- * - 1001: mem_msb = mem_adr[34]
- * - 1010: mem_msb = mem_adr[35]
- * - 1011: mem_msb = mem_adr[36]
- * 1010-1111 = Reserved
- * For example, for a DIMM made of Samsung's K4B1G0846C-ZCF7 1Gb (16M * 8 bit * 8 bank) DDR3
- * parts, the column address width = 10; so with 10b of col, 3b of bus, 3b of bank, row_lsb = 16.
- * Therefore, row = mem_adr[29:16] and mem_msb = 4.
- * Note also that addresses greater than the max defined space (pbank_msb) are also treated as
- * NXM accesses.
+ *
  */
 union cvmx_lmcx_nxm {
 	uint64_t u64;
@@ -7863,16 +8094,14 @@ union cvmx_lmcx_nxm {
 	uint64_t mem_msb_d0_r1                : 4;  /**< Max Row MSB for DIMM0, RANK1/DIMM0 in Single Ranked */
 	uint64_t mem_msb_d0_r0                : 4;  /**< Max Row MSB for DIMM0, RANK0 */
 	uint64_t cs_mask                      : 8;  /**< Chip select mask.
-                                                         This mask corresponds to the chip selects for a memory
-                                                         configuration.  If LMC*_CONFIG[RANK_ENA]==0 then this
-                                                         mask must be set in pairs because each reference address
-                                                         will assert a pair of chip selects.  If the chip
-                                                         select(s) have a corresponding CS_MASK bit set, then the
-                                                         reference is to non-existent memory (NXM).  LMC will alias a
-                                                         NXM read reference to use the lowest, legal chip select(s)
-                                                         and return 0's. LMC normally discards NXM writes, but will
-                                                         also alias them when LMC*_CONTROL[NXM_WRITE_EN]=1.
-                                                         CS_MASK<7:4> must all be set in 6xxx */
+                                                         CS_MASK[3:0] corresponds to the 4 chip selects for a memory
+                                                         configuration.  If the memory configuration does not populate
+                                                         a rank of memory for a chip select, the corresponding bit in
+                                                         the CS_MASK field must be set, and for 6xxx devices bits
+                                                         CS_MASK[7:4] must always all be set.  LMC will alias a NXM
+                                                         read reference to use the lowest, legal chip select and
+                                                         return 0s for data.  LMC normally discards NXM writes, but
+                                                         will also alias them when LMC*_CONTROL[NXM_WRITE_EN]=1. */
 #else
 	uint64_t cs_mask                      : 8;
 	uint64_t mem_msb_d0_r0                : 4;
@@ -7919,13 +8148,13 @@ union cvmx_lmcx_nxm {
 	uint64_t mem_msb_d0_r1                : 4;  /**< Max row MSB for DIMM0, RANK1/DIMM0 in single ranked. */
 	uint64_t mem_msb_d0_r0                : 4;  /**< Max row MSB for DIMM0, RANK0. */
 	uint64_t reserved_4_7                 : 4;
-	uint64_t cs_mask                      : 4;  /**< Chip select mask. This mask corresponds to the 4 chip selects for a memory configuration.
-                                                         If LMC(0..0)_CONFIG[RANK_ENA]=0 then this mask must be set in pairs because each reference
-                                                         address will assert a pair of chip selects. If the chip select(s) have a corresponding
-                                                         CS_MASK bit set, then the reference is to nonexistent memory (NXM). LMC will alias a NXM
-                                                         read reference to use the lowest, legal chip select(s) and return zeros. LMC normally
-                                                         discards NXM write operations, but will also alias them when
-                                                         LMC(0..0)_CONTROL[NXM_WRITE_EN]=1. */
+	uint64_t cs_mask                      : 4;  /**< Chip select mask. This mask corresponds to the four chip selects for a memory
+                                                         configuration. If LMC(0..0)_CONFIG[RANK_ENA]=0 then this mask must be set in pairs because
+                                                         each reference address will assert a pair of chip selects. If the chip select(s) have a
+                                                         corresponding CS_MASK bit set, then the reference is to nonexistent memory (NXM). LMC will
+                                                         alias a NXM read reference to use the lowest, legal chip select(s) and return zeros. LMC
+                                                         normally discards NXM write operations, but will also alias them when LMC(0..0)_CONTROL
+                                                         [NXM_WRITE_EN]=1. */
 #else
 	uint64_t cs_mask                      : 4;
 	uint64_t reserved_4_7                 : 4;
@@ -7944,26 +8173,24 @@ typedef union cvmx_lmcx_nxm cvmx_lmcx_nxm_t;
 /**
  * cvmx_lmc#_nxm_fadr
  *
- * This register only captures the first transaction with a NXM error while an interrupt
- * is pending, and will only capture a subsequent event once the interrupt is cleared by
- * writing a 1 to LMC*_INT[NXM_ERR].  It captures the actual L2C-LMC address provided to
- * the LMC that caused the NXM error.  A read or write NXM error will only be captured if
- * enabled using the NXM event enables.
+ * This register captures only the first transaction with a NXM error while an interrupt is
+ * pending, and only captures a subsequent event once the interrupt is cleared by writing a 1 to
+ * LMC(0..3)_INT[NXM_ERR]. It captures the actual L2C-LMC address provided to the LMC that caused
+ * the NXM error. A read or write NXM error is captured only if enabled using the NXM event
+ * enables.
  */
 union cvmx_lmcx_nxm_fadr {
 	uint64_t u64;
 	struct cvmx_lmcx_nxm_fadr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_39_63               : 25;
-	uint64_t nxm_src                      : 1;  /**< Indicates the source of the operation that caused a NXM error.
-                                                         - 0: source = L2C
-                                                         - 1: source = DLC */
-	uint64_t nxm_type                     : 1;  /**< Indicates the type of operation that caused NXM error.
-                                                         - 0: type = read
-                                                         - 1: type = write */
-	uint64_t nxm_faddr                    : 37; /**< Failing L2C-LMC address.  Bits [3:0] will always be zero for a DLC access, and
-                                                         bits [4:0] will be zero for an L2C access.  Bits [5:4] represent the fill order
-                                                         for an L2C read, and the start point within a cache line for a write. */
+	uint64_t nxm_src                      : 1;  /**< Indicates the source of the operation that caused a NXM error:
+                                                         0 = L2C, 1 = HFA */
+	uint64_t nxm_type                     : 1;  /**< Indicates the type of operation that caused NXM error:
+                                                         0 = Read, 1 = Write */
+	uint64_t nxm_faddr                    : 37; /**< Failing L2C-LMC address. Bits<3:0> are always 0s for an HFA access, and bits<4:0> are
+                                                         always 0s for an L2C access. Bits<5:4> represent the fill order for an L2C read operation,
+                                                         and the start point within a cache line for a write operation. */
 #else
 	uint64_t nxm_faddr                    : 37;
 	uint64_t nxm_type                     : 1;
@@ -8083,35 +8310,36 @@ union cvmx_lmcx_phy_ctl {
 	struct cvmx_lmcx_phy_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
-	uint64_t phy_reset                    : 1;  /**< INTERNAL: Write to 1 to reset the PHY, one shot operation, will automatically
+	uint64_t phy_reset                    : 1;  /**< Reserved. INTERNAL: Write to 1 to reset the PHY, one-shot operation, will automatically
                                                          clear to value of 0. */
-	uint64_t dsk_dbg_rd_complete          : 1;  /**< INTERNAL: Indicates completion of a read operation, will clear to 0 when
-                                                         a read operation is started, then set to 1 when operation is complete. */
-	uint64_t dsk_dbg_rd_data              : 10; /**< INTERNAL: Data from a deskew read operation.  Only valid when the
+	uint64_t dsk_dbg_rd_complete          : 1;  /**< Reserved. INTERNAL: Indicates completion of a read operation, will clear to 0 when a read
+                                                         operation is started, then set to 1 when operation is complete. */
+	uint64_t dsk_dbg_rd_data              : 10; /**< Reserved. INTERNAL: Data from a deskew read operation. Only valid when the
                                                          LMCX_PHY_CTL[DSK_DBG_RD_COMPLETE] bit is set. */
-	uint64_t dsk_dbg_rd_start             : 1;  /**< INTERNAL: Write 1 to start deskew data read operation, will automatically
-                                                         clear to 0.  Write to 1 will also clear the complete bit. */
-	uint64_t dsk_dbg_clk_scaler           : 2;  /**< INTERNAL: Adjust clock toggle rate for reading deskew debug information:
-                                                         - 0: Deskew read clock toggles every 1 DCLK
-                                                         - 1: Deskew read clock toggles every 2 DCLKs
-                                                         - 2: Deskew read clock toggles every 3 DCLKs
-                                                         - 3: Deskew read clock toggles every 4 DCLKs */
-	uint64_t dsk_dbg_offset               : 2;  /**< INTERNAL: Offset to change delay of deskew debug data return time
-                                                         to LMC from DDR PHY. */
-	uint64_t dsk_dbg_num_bits_sel         : 1;  /**< INTERNAL: Deskew debug, select number of bits per byte lane.
-                                                         - 0: 8 bits per byte lane, no DBI
-                                                         - 1: 9 bits ber byte lane, including DBI */
-	uint64_t dsk_dbg_byte_sel             : 4;  /**< INTERNAL: Deskew debug byte select for read operation.  Values 0-3 correspond
-                                                         to byte lanes 0-3, 4 is for ECC, 5-8 are byte lanes 4-7. */
-	uint64_t dsk_dbg_bit_sel              : 4;  /**< INTERNAL: Deskew debug bit select for dsk read operation. */
+	uint64_t dsk_dbg_rd_start             : 1;  /**< Reserved. INTERNAL: Write 1 to start deskew data read operation, will automatically clear
+                                                         to 0. Write to 1 will also clear the complete bit. */
+	uint64_t dsk_dbg_clk_scaler           : 2;  /**< Reserved. INTERNAL: Adjust clock toggle rate for reading deskew debug information:
+                                                         0 = Deskew read clock toggles every 4 DCLK
+                                                         1 = Deskew read clock toggles every 8 DCLKs
+                                                         2 = Deskew read clock toggles every 12 DCLKs
+                                                         3 = Deskew read clock toggles every 16 DCLKs */
+	uint64_t dsk_dbg_offset               : 2;  /**< Reserved. INTERNAL: Offset to change delay of deskew debug data return time to LMC from
+                                                         DDR PHY. */
+	uint64_t dsk_dbg_num_bits_sel         : 1;  /**< Reserved. INTERNAL: Deskew debug, select number of bits per byte lane.
+                                                         0 = 8 bits per byte lane, no DBI
+                                                         1 = 9 bits ber byte lane, including DBI */
+	uint64_t dsk_dbg_byte_sel             : 4;  /**< Reserved. INTERNAL: Deskew debug byte select for read operation.  Values 0-3 correspond to
+                                                         byte lanes 0-3, 4 is for ECC, 5-8 are byte lanes 4-7. */
+	uint64_t dsk_dbg_bit_sel              : 4;  /**< Reserved. INTERNAL: Deskew debug bit select for dsk read operation. */
 	uint64_t dbi_mode_ena                 : 1;  /**< Enable DBI mode for PHY. */
 	uint64_t ddr_error_n_ena              : 1;  /**< Enable error_alert_n signal for PHY. */
-	uint64_t ref_pin_on                   : 1;  /**< INTERNAL: Voltage reference pin enabled. */
-	uint64_t dac_on                       : 1;  /**< INTERNAL: PHY DAC on. */
+	uint64_t ref_pin_on                   : 1;  /**< Reserved. INTERNAL: Voltage reference pin enabled. */
+	uint64_t dac_on                       : 1;  /**< Reserved. INTERNAL: PHY DAC on. */
 	uint64_t int_pad_loopback_ena         : 1;  /**< DDR pad loopback enable. */
 	uint64_t int_phy_loopback_ena         : 1;  /**< Internal PHY loopback enable. */
-	uint64_t phy_dsk_reset                : 1;  /**< Deskew bypass. */
-	uint64_t phy_dsk_byp                  : 1;  /**< Deskew bypass. */
+	uint64_t phy_dsk_reset                : 1;  /**< PHY deskew reset. When set, the deskew reset signal goes active if the vrefint/deskew
+                                                         training sequence is in the idle state. */
+	uint64_t phy_dsk_byp                  : 1;  /**< PHY deskew bypass. */
 	uint64_t phy_pwr_save_disable         : 1;  /**< DDR PHY power save disable. */
 	uint64_t ten                          : 1;  /**< DDR PHY test enable pin. */
 	uint64_t rx_always_on                 : 1;  /**< Disable dynamic DDR3 IO Rx power gating */
@@ -8580,8 +8808,31 @@ typedef union cvmx_lmcx_read_level_rankx cvmx_lmcx_read_level_rankx_t;
 /**
  * cvmx_lmc#_reset_ctl
  *
- * Specify the RSL base addresses for the block
- *
+ * "Specify the RSL base addresses for the block.
+ * INTERNAL: DDR3RST DDR3 DRAM parts have a RESET# pin that wasn't present in DDR2 parts. The
+ * DDR3RST CSR field controls the assertion of the 7xxx pin that attaches to RESET#. When DDR3RST
+ * is set, 6xxx asserts RESET#. When DDR3RST is clear, 6xxx de-asserts RESET#. DDR3RST is set on
+ * a cold reset. Warm and soft chip resets do not affect the DDR3RST value. Outside of cold
+ * reset, only software CSR writes change the DDR3RST value. DDR3PWARM Enables preserve mode
+ * during a warm reset. When set, the DDR3 controller hardware automatically puts the attached
+ * DDR3 DRAM parts into self refresh (see LMC*CONFIG[SEQ_SEL] below) at the beginning of a warm
+ * reset sequence, provided that the DDR3 controller is up. When clear, the DDR3 controller
+ * hardware does not put the attached DDR3 DRAM parts into self-refresh during a warm reset
+ * sequence. DDR3PWARM is cleared on a cold reset. Warm and soft chip resets do not affect the
+ * DDR3PWARM value. Outside of cold reset, only software CSR writes change the DDR3PWARM value.
+ * Note that if a warm reset follows a soft reset, DDR3PWARM has no effect, as the DDR3
+ * controller is no longer up after any cold/warm/soft reset sequence. DDR3PSOFT Enables preserve
+ * mode during a soft reset. When set, the DDR3 controller hardware automatically puts the
+ * attached DDR3 DRAM parts into self refresh (see LMC*CONFIG[SEQ_SEL] below) at the beginning of
+ * a soft reset sequence, provided that the DDR3 controller is up. When clear, the DDR3
+ * controller hardware does not put the attached DDR3 DRAM parts into self-refresh during a soft
+ * reset sequence. DDR3PSOFT is cleared on a cold reset. Warm and soft chip resets do not affect
+ * the DDR3PSOFT value. Outside of cold reset, only software CSR writes change the DDR3PSOFT
+ * value. DDR3PSV May be useful for system software to determine when the DDR3 contents have been
+ * preserved. Cleared by hardware during a cold reset. Never cleared by hardware during a
+ * warm/soft reset. Set by hardware during a warm/soft reset if the hardware automatically put
+ * the DDR3 DRAM into self-refresh during the reset sequence. Can also be written by software (to
+ * any value)."
  */
 union cvmx_lmcx_reset_ctl {
 	uint64_t u64;
@@ -8625,20 +8876,20 @@ union cvmx_lmcx_rlevel_ctl {
 	struct cvmx_lmcx_rlevel_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t pattern                      : 8;  /**< Sets the data pattern used to match in read leveling operations. */
+	uint64_t pattern                      : 8;  /**< Sets the data pattern used to match in read-leveling operations. */
 	uint64_t reserved_22_23               : 2;
 	uint64_t delay_unload_3               : 1;  /**< When set, unload the PHY silo one cycle later
                                                          during read-leveling if LMC*_RLEVEL_RANKi[BYTE*<1:0>] = 3
-                                                         DELAY_UNLOAD_3 should normally be set, particularly at higher speeds. */
+                                                         DELAY_UNLOAD_3 should normally be set. */
 	uint64_t delay_unload_2               : 1;  /**< When set, unload the PHY silo one cycle later
                                                          during read-leveling if LMC*_RLEVEL_RANKi[BYTE*<1:0>] = 2
-                                                         DELAY_UNLOAD_2 should normally not be set. */
+                                                         DELAY_UNLOAD_2 should normally be set. */
 	uint64_t delay_unload_1               : 1;  /**< When set, unload the PHY silo one cycle later
                                                          during read-leveling if LMC*_RLEVEL_RANKi[BYTE*<1:0>] = 1
-                                                         DELAY_UNLOAD_1 should normally not be set. */
+                                                         DELAY_UNLOAD_1 should normally be set. */
 	uint64_t delay_unload_0               : 1;  /**< When set, unload the PHY silo one cycle later
                                                          during read-leveling if LMC*_RLEVEL_RANKi[BYTE*<1:0>] = 0
-                                                         DELAY_UNLOAD_0 should normally not be set. */
+                                                         DELAY_UNLOAD_0 should normally be set. */
 	uint64_t bitmask                      : 8;  /**< Mask to select bit lanes on which read-leveling
                                                          feedback is returned when OR_DIS is set to 1 */
 	uint64_t or_dis                       : 1;  /**< Disable or'ing of bits in a byte lane when computing
@@ -8676,16 +8927,16 @@ union cvmx_lmcx_rlevel_ctl {
 	uint64_t reserved_22_63               : 42;
 	uint64_t delay_unload_3               : 1;  /**< When set, unload the PHY silo one cycle later
                                                          during read-leveling if LMC*_RLEVEL_RANKi[BYTE*<1:0>] = 3
-                                                         DELAY_UNLOAD_3 should normally be set, particularly at higher speeds. */
+                                                         DELAY_UNLOAD_3 should normally be set. */
 	uint64_t delay_unload_2               : 1;  /**< When set, unload the PHY silo one cycle later
                                                          during read-leveling if LMC*_RLEVEL_RANKi[BYTE*<1:0>] = 2
-                                                         DELAY_UNLOAD_2 should normally not be set. */
+                                                         DELAY_UNLOAD_2 should normally be set. */
 	uint64_t delay_unload_1               : 1;  /**< When set, unload the PHY silo one cycle later
                                                          during read-leveling if LMC*_RLEVEL_RANKi[BYTE*<1:0>] = 1
-                                                         DELAY_UNLOAD_1 should normally not be set. */
+                                                         DELAY_UNLOAD_1 should normally be set. */
 	uint64_t delay_unload_0               : 1;  /**< When set, unload the PHY silo one cycle later
                                                          during read-leveling if LMC*_RLEVEL_RANKi[BYTE*<1:0>] = 0
-                                                         DELAY_UNLOAD_0 should normally not be set. */
+                                                         DELAY_UNLOAD_0 should normally be set. */
 	uint64_t bitmask                      : 8;  /**< Mask to select bit lanes on which read-leveling
                                                          feedback is returned when OR_DIS is set to 1 */
 	uint64_t or_dis                       : 1;  /**< Disable or'ing of bits in a byte lane when computing
@@ -8968,30 +9219,6 @@ typedef union cvmx_lmcx_rodt_ctl cvmx_lmcx_rodt_ctl_t;
  * pin for the rank that is being read should always be 0x0.
  * When a given RANK is selected, the RODT mask for that rank is used. The resulting RODT mask is
  * driven to the DIMMs in the following manner:
- * RANK_ENA=1                    RANK_ENA=0
- * Mask[3] -> DIMM1_ODT_1                    MBZ
- * Mask[2] -> DIMM1_ODT_0                          DIMM1_ODT_0
- * Mask[1] -> DIMM0_ODT_1                    MBZ
- * Mask[0] -> DIMM0_ODT_0                    DIMM0_ODT_0
- * LMC always reads entire cache blocks and always reads them via two consecutive
- * read CAS operations to the same rank+bank+row spaced exactly 4 CK's apart.
- * When a RODT mask bit is set, LMC asserts the OCTEON ODT output
- * pin(s) starting (CL CWL) CK's after the first read CAS operation. Then, OCTEON
- * normally continues to assert the ODT output pin(s) for 9+LMC*_CONTROL[RODT_BPRCH] more CK's
- * for a total of 10+LMC*_CONTROL[RODT_BPRCH] CK's for the entire cache block read -
- * through the second read CAS operation of the cache block,
- * satisfying the 6 CK DDR3 ODTH8 requirements.
- * But it is possible for OCTEON to issue two cache block reads separated by as few as
- * RtR = 8 or 9 (10 if LMC*_CONTROL[RODT_BPRCH]=1) CK's. In that case, OCTEON asserts the ODT
- * output pin(s)
- * for the RODT mask of the first cache block read for RtR CK's, then asserts
- * the ODT output pin(s) for the RODT mask of the second cache block read for
- * 10+LMC*_CONTROL[RODT_BPRCH] CK's
- * (or less if a third cache block read follows within 8 or 9 (or 10) CK's of this second cache
- * block read).
- * Note that it may be necessary to force LMC to space back-to-back cache block reads
- * to different ranks apart by at least 10+LMC*_CONTROL[RODT_BPRCH] CK's to prevent DDR3 ODTH8
- * violations.
  */
 union cvmx_lmcx_rodt_mask {
 	uint64_t u64;
@@ -9049,11 +9276,9 @@ union cvmx_lmcx_rodt_mask {
 	struct cvmx_lmcx_rodt_mask_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t rodt_d1_r1                   : 4;  /**< Read ODT mask DIMM1, RANK1/DIMM1 in SingleRanked. If RANK_ENA=1, RODT_D1_R1<3> must be
-                                                         zero. Otherwise RODT_D1_R1<3:0> is not used and must be zero. */
+	uint64_t rodt_d1_r1                   : 4;  /**< Reserved. */
 	uint64_t reserved_20_23               : 4;
-	uint64_t rodt_d1_r0                   : 4;  /**< Read ODT mask DIMM1, RANK0. If RANK_ENA=1, RODT_D1_RO<2> must be zero. Otherwise,
-                                                         RODT_D1_RO<3:2,1> must be zero. */
+	uint64_t rodt_d1_r0                   : 4;  /**< Reserved. */
 	uint64_t reserved_12_15               : 4;
 	uint64_t rodt_d0_r1                   : 4;  /**< Read ODT mask DIMM0, RANK1/DIMM0 in SingleRanked. If RANK_ENA=1, RODT_D0_R1<1> must be
                                                          zero. Otherwise, RODT_D0_R1<3:0> is not used and must be zero. */
@@ -9133,10 +9358,10 @@ typedef union cvmx_lmcx_scramble_cfg1 cvmx_lmcx_scramble_cfg1_t;
  * DRAM parts (split into DIMM, bunk, bank, etc);
  * If scrambling is off, the pre-scramble and post-scramble addresses are the same, and so the
  * contents of LMC(0..3)_SCRAMBLED_FADR match the contents of LMC(0..3)_FADR.
- * This register only captures the first transaction with ECC errors. A DED error can
- * over-write this register with its failing addresses if the first error was a SEC. If you write
- * LMC(0..3)_CONFIG -> SEC_ERR/DED_ERR, it clears the error bits and captures the next
- * failing address. If FDIMM is 1, that means the error is in the higher DIMM.
+ * This register only captures the first transaction with ECC errors. A DED error can over-write
+ * this register with its failing addresses if the first error was a SEC. If you write
+ * LMC(0..3)_CONFIG -> SEC_ERR/DED_ERR, it clears the error bits and captures the next failing
+ * address. If FDIMM is 1, that means the error is in the higher DIMM.
  */
 union cvmx_lmcx_scrambled_fadr {
 	uint64_t u64;
@@ -9216,63 +9441,42 @@ union cvmx_lmcx_seq_ctl {
 	struct cvmx_lmcx_seq_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
-	uint64_t seq_complete                 : 1;  /**< This bit will clear when the LMC(0..3)_SEQ_CTL[INIT_START] bit is set to a 1, and will
-                                                         then be set to 1 when the sequence is completed. */
-	uint64_t seq_sel                      : 4;  /**< Selects the sequence that LMC runs after a 0->1 transition on
-                                                         LMC(0..3)_SEQ_CTL[INIT_START].
-                                                         0x0 = Power-up/init:
-                                                         RANKMASK selects participating ranks (should be all ranks with attached DRAM).
-                                                         DDR*_DIMM*_CKE* signals activated (if they weren't already active).
-                                                         RDIMM register control words 0-15 will be written to RANKMASK-selected RDIMMs when
-                                                         LMC(0..3)_CONTROL[RDIMM_ENA]=1 and corresponding LMC(0..3)_DIMM_CTL[DIMM*_WMASK] bits are
-                                                         set. (Refer to LMC(0..3)_DIMM0/1_PARAMS and LMC(0..3)_DIMM_CTL descriptions below for more
+	uint64_t seq_complete                 : 1;  /**< Sequence complete. This bit is cleared when INIT_START is set to a 1 and then is set to 1
+                                                         when the sequence is completed. */
+	uint64_t seq_sel                      : 4;  /**< Selects the sequence that LMC runs after a 0->1 transition on INIT_START.
+                                                         0x0 = Power-up/initialization:
+                                                         LMC(0..3)_CONFIG[RANKMASK] selects participating ranks (should be all ranks with attached
+                                                         DRAM). DDR*_DIMM*_CKE* signals are activated (if not already active). RDIMM register
+                                                         control words 0-15 are written to LMC(0..3)_CONFIG[RANKMASK]-selected RDIMMs when
+                                                         LMC(0..3)_CONTROL[RDIMM_ENA] = 1 and corresponding LMC(0..3)_DIMM_CTL[DIMM*_WMASK] bits
+                                                         are set. (Refer to LMC(0..3)_DIMM(0..1)_PARAMS and LMC(0..3)_DIMM_CTL descriptions for
+                                                         more
                                                          details.)
-                                                         MR0, MR1, MR2, and MR3 will be written to selected ranks.
+                                                         The DRAM registers MR0, MR1, MR2, and MR3 are written in the selected ranks.
                                                          0x1 = Read-leveling:
-                                                         RANKMASK selects the rank to be read-leveled.
-                                                         MR3 written to selected rank.
+                                                         LMC(0..3)_CONFIG[RANKMASK] selects the rank to be read-leveled. MR3 written in the
+                                                         selected rank.
                                                          0x2 = Self-refresh entry:
-                                                         INIT_STATUS selects participating ranks (should be all ranks with attached DRAM).
-                                                         MR1 and MR2 will be written to selected ranks if SREF_WITH_DLL=1.
-                                                         DDR*_DIMM*_CKE* signals de-activated.
+                                                         LMC(0..3)_CONFIG[INIT_STATUS] selects the participating ranks (should be all ranks with
+                                                         attached DRAM). MR1 and MR2 are written in the selected ranks if
+                                                         LMC(0..3)_CONFIG[SREF_WITH_DLL] = 1. DDR*_DIMM*_CKE* signals de-activated.
                                                          0x3 = Self-refresh exit:
-                                                         RANKMASK must be set to indicate participating ranks (should be all ranks with attached
-                                                         DRAM).
-                                                         DDR*_DIMM*_CKE* signals activated.
-                                                         MR0, MR1, MR2, and MR3 will be written to participating ranks if SREF_WITH_DLL=1.
-                                                         INIT_STATUS will be updated for ranks that are selected.
+                                                         LMC(0..3)_CONFIG[RANKMASK] must be set to indicate participating ranks (should be all
+                                                         ranks with attached DRAM). DDR*_DIMM*_CKE* signals activated. MR0, MR1, MR2, and MR3 are
+                                                         written in the participating ranks if LMC(0..3)_CONFIG[SREF_WITH_DLL] = 1.
+                                                         LMC(0..3)_CONFIG[INIT_STATUS] is updated for ranks that are selected.
                                                          0x6 = Write-leveling:
-                                                         RANKMASK selects the rank to be write-leveled.
-                                                         INIT_STATUS must indicate all ranks with attached DRAM.
-                                                         MR1 and MR2 written to INIT_STATUS-selected ranks.
-                                                         0x7 = Init RCW
-                                                         RANKMASK selects participating ranks (should be all ranks with attached DRAM).
-                                                         In DDR3 mode, RDIMM register control words 0-15 will be written to RANKMASK-selected
-                                                         RDIMMs when LMC(0..3)_CONTROL[RDIMM_ENA]=1 and corresponding
-                                                         LMC(0..3)_DIMM_CTL[DIMM*_WMASK]
-                                                         bits are set. (Refer to LMC(0..3)_DIMM0/1_PARAMS and LMC(0..3)_DIMM_CTL descriptions below
-                                                         for more details.)
-                                                         0x8 = MRW
-                                                         Mode Register Write sequence.
-                                                         0x9 = MPR
-                                                         MPR register read or write sequence.
-                                                         Self-refresh entry SEQ_SEL's may also be automatically
-                                                         generated by hardware upon a chip warm or soft reset
-                                                         sequence when LMC*_RESET_CTL[DDR3PWARM,DDR3PSOFT] are set.
-                                                         LMC writes the LMC*_MODEREG_PARAMS0 and LMC*_MODEREG_PARAMS1 CSR field values
-                                                         to the Mode registers in the DRAM parts (i.e. MR0, MR1, MR2, and MR3) as part of some of
-                                                         these sequences.
-                                                         Refer to the LMC*_MODEREG_PARAMS0 and LMC*_MODEREG_PARAMS1 descriptions for more details.
-                                                         If there are two consecutive power-up/init's without
-                                                         a DRESET assertion between them, LMC asserts DDR_DIMM*_CKE as part of
-                                                         the first power-up/init, and continues to assert DDR_DIMM*_CKE
-                                                         through the remainder of the first and the second power-up/init.
-                                                         If DDR_DIMM*_CKE deactivation and reactivation is needed for
-                                                         a second power-up/init, a DRESET assertion is required
-                                                         between the first and the second." */
-	uint64_t init_start                   : 1;  /**< A 0->1 transition starts the DDR memory sequence that is selected by
-                                                         LMC(0..3)_SEQ_CTL[SEQ_SEL]. This register is a oneshot and clears itself each time it is
-                                                         set. */
+                                                         LMC(0..3)_CONFIG[RANKMASK] selects the rank to be write-leveled.
+                                                         LMC(0..3)_CONFIG[INIT_STATUS] must indicate all ranks with attached DRAM. MR1 and MR2
+                                                         written in the LMC(0..3)_CONFIG[INIT_STATUS]-selected ranks.
+                                                         0x7 = Initialize RCW:
+                                                         LMC(0..3)_CONFIG[RANKMASK] selects participating ranks (should be all ranks with attached
+                                                         DRAM). In DDR3 mode, RDIMM register control words 0-15 are written to
+                                                         LMC(0..3)_CONFIG[RANKMASK]-selected RDIMMs when LMC(0..3)_CONTROL[RDIMM_ENA] = 1 and
+                                                         corresponding LMC(0..3)_DIMM_CTL[DIMM*_WMASK] bits are set. (Refer to
+                                                         LMC(0..3)_DIMM(0..1)_PARAMS and LMC(0..3)_DIMM_CTL descriptions for more details.) */
+	uint64_t init_start                   : 1;  /**< A 0->1 transition starts the DDR memory sequence that is selected by SEQ_SEL. This
+                                                         register is a one-shot and clears itself each time it is set. */
 #else
 	uint64_t init_start                   : 1;
 	uint64_t seq_sel                      : 4;
@@ -9291,34 +9495,20 @@ typedef union cvmx_lmcx_seq_ctl cvmx_lmcx_seq_ctl_t;
  * This register is an assortment of control fields needed by the memory controller. If software
  * has not previously written to this register (since the last DRESET), hardware updates the
  * fields in this register to the minimum allowed value when any of LMC(0..3)_RLEVEL_RANK(0..3),
- * LMC(0..3)_WLEVEL_RANK(0..3), LMC(0..3)_CONTROL and LMC(0..3)_MODEREG_PARAMS0 CSRs change.
- * Ideally, only read this register after LMC has been initialized and
+ * LMC(0..3)_WLEVEL_RANK(0..3), LMC(0..3)_CONTROL, and LMC(0..3)_MODEREG_PARAMS0 registers
+ * change. Ideally, only read this register after LMC has been initialized and
  * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
- * The field value is the minimum CK cycles between when the DRAM
- * part registers CAS commands of the first and second types from different cache blocks.
- *
- * "*_S_INIT" fields are DDR3 timing or DDR4 short timing parameters
- * "*_L_INIT" fields are DDR4 long timing parameters
- *
- * The hardware-calculated minimums are:
- * min R2R_S_INIT = 4
- * min R2W_S_INIT = 8 + (RL + MaxRdSkew) (WL + MinWrSkew) + LMC*_CONTROL[BPRCH]
- * min W2R_S_INIT = 5 + LMC*_TIMING_PARAMS1[TWTR] + WL
- * min W2W_S_INIT = 4
- * min R2R_L_INIT = LMC*_MODEREG_PARAMS3[TCCD_L] (decoded)
- * min R2W_L_INIT = 8 + (RL + MaxRdSkew) (WL + MinWrSkew) + LMC*_CONTROL[BPRCH]
- * min W2R_L_INIT = 5 + LMC*_TIMING_PARAMS2[TWTR_L] + WL
- * min W2W_L_INIT = LMC*_MODEREG_PARAMS3[TCCD_L] (decoded)
- * where
- * RL        = CL  + AL (LMC*_MODEREG_PARAMS0[CL] selects CL, LMC*_MODEREG_PARAMS0[AL] selects
- * AL)
- * WL        = CWL + AL (LMC*_MODEREG_PARAMS0[CWL] selects CWL)
- * MaxRdSkew = max(LMC*_RLEVEL_RANKi[BYTEj]/4) + 1
- * (max is across all ranks i (0..3) and bytes j (0..8))
- * MinWrSkew = min(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX]
- * (min is across all ranks i (0..3) and bytes j (0..8))
- *
- * R2W_INIT has 1 CK cycle built in for OCTEON-internal ODT settling/channel turnaround time.
+ * The interpretation of the fields in this register depends on LMC(0)_CONFIG[DDR2T]:
+ * If LMC(0..3)_CONFIG[DDR2T]=1, (FieldValue + 4) is the minimum CK cycles between when the DRAM
+ * part registers CAS commands of the 1
+ * st and 2
+ * nd types from different cache blocks.
+ * If LMC(0..3)_CONFIG[DDR2T]=0, (FieldValue + 3) is the minimum CK cycles between when the DRAM
+ * part registers CAS commands of the 1
+ * st and 2
+ * nd types from different cache blocks. FieldValue = 0 is always illegal in this case.
+ * The hardware-calculated minimums for these fields are shown in LMC(0)_SLOT_CTL0 Hardware-
+ * Calculated Minimums.
  */
 union cvmx_lmcx_slot_ctl0 {
 	uint64_t u64;
@@ -9400,29 +9590,17 @@ typedef union cvmx_lmcx_slot_ctl0 cvmx_lmcx_slot_ctl0_t;
  * LMC(0..3)_WLEVEL_RANK(0..3), LMC(0..3)_CONTROL and LMC(0..3)_MODEREG_PARAMS0 CSRs change.
  * Ideally, only read this register after LMC has been initialized and
  * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
- * The field value is the minimum CK cycles between when the DRAM
- * part registers CAS commands of the first and second types from different cache blocks.
- *
- * The hardware-calculated minimums are:
- * min R2R_XRANK_INIT = 5 + MaxRdSkew MinRdSkew + LMC*_CONTROL[RODT_BPRCH]
- * min R2W_XRANK_INIT = 8 + (RL + MaxRdSkew) - (WL + MinWrSkew) + LMC*_CONTROL[BPRCH]
- * min W2R_XRANK_INIT = 6 + MaxWrSkew + LMC*_CONTROL[FPRCH2]
- * min W2W_XRANK_INIT = 7 + MaxWrSkew - MinWrSkew
- * where
- * RL        = CL  + AL (LMC*_MODEREG_PARAMS0[CL] selects CL, LMC*_MODEREG_PARAMS0[AL] selects
- * AL)
- * WL        = CWL + AL (LMC*_MODEREG_PARAMS0[CWL] selects CWL)
- * MinRdSkew = min(LMC*_RLEVEL_RANKi[BYTEj]/4)                              (min is across all
- * ranks i (0..3) and bytes j (0..8))
- * MaxRdSkew = max(LMC*_RLEVEL_RANKi[BYTEj]/4) + 1                          (max is across all
- * ranks i (0..3) and bytes j (0..8))
- * MinWrSkew = min(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX]     (min is across all
- * ranks i (0..3) and bytes j (0..8))
- * MaxWrSkew = max(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX] + 1 (max is across all
- * ranks i (0..3) and bytes j (0..8))
- * R2W_XRANK_INIT has 1 extra CK cycle built in for OCTEON-internal ODT settling/channel
- * turnaround time.
- * W2R_XRANK_INIT has 1 extra CK cycle built in for channel turnaround time.
+ * The interpretation of the fields in this CSR depends on LMC(0)_CONFIG[DDR2T]:
+ * If LMC(0..3)_CONFIG[DDR2T]=1, (FieldValue + 4) is the minimum CK cycles between when the DRAM
+ * part registers CAS commands of the 1
+ * st and 2
+ * nd types from different cache blocks.
+ * If LMC(0..3)_CONFIG[DDR2T]=0, (FieldValue + 3) is the minimum CK cycles between when the DRAM
+ * part registers CAS commands of the 1
+ * st and 2
+ * nd types from different cache blocks. FieldValue = 0 is always illegal in this case.
+ * The hardware-calculated minimums for these fields are shown in LMC(0)_SLOT_CTL1 Hardware-
+ * Calculated Minimums.
  */
 union cvmx_lmcx_slot_ctl1 {
 	uint64_t u64;
@@ -9467,34 +9645,19 @@ typedef union cvmx_lmcx_slot_ctl1 cvmx_lmcx_slot_ctl1_t;
  * This register is an assortment of control fields needed by the memory controller. If software
  * has not previously written to this register (since the last DRESET), hardware updates the
  * fields in this register to the minimum allowed value when any of LMC(0..3)_RLEVEL_RANK(0..3),
- * LMC(0..3)_WLEVEL_RANK(0..3)LMC*_WLEVEL_RANKn, LMC*_CONTROL and LMC*_MODEREG_PARAMS0 CSRs
- * change. Ideally, only read this register after LMC has been initialized and LMC*_RLEVEL_RANKn,
- * LMC*_WLEVEL_RANKn have valid data.
- *
- * The field value is the minimum CK cycles between when the DRAM
- * part registers CAS commands of the first and second types from different cache blocks.
- *
- * The hardware-calculated minimums are:
- * min R2R_XDIMM_INIT = 6 + MaxRdSkew MinRdSkew + LMC*_CONTROL[RODT_BPRCH]
- * min R2W_XDIMM_INIT = 9 + (RL + MaxRdSkew) - (WL + MinWrSkew) + LMC*_CONTROL[BPRCH]
- * min W2R_XDIMM_INIT = 6 + MaxWrSkew + LMC*_CONTROL[FPRCH2]
- * min W2W_XDIMM_INIT = 8 + MaxWrSkew - MinWrSkew
- * where
- * RL        = CL  + AL (LMC*_MODEREG_PARAMS0[CL] selects CL, LMC*_MODEREG_PARAMS0[AL] selects
- * AL)
- * WL        = CWL + AL (LMC*_MODEREG_PARAMS0[CWL] selects CWL)
- * MinRdSkew = min(LMC*_RLEVEL_RANKi[BYTEj]/4)                              (min is across all
- * ranks i (0..3) and bytes j (0..8))
- * MaxRdSkew = max(LMC*_RLEVEL_RANKi[BYTEj]/4) + 1                          (max is across all
- * ranks i (0..3) and bytes j (0..8))
- * MinWrSkew = min(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX]     (min is across all
- * ranks i (0..3) and bytes j (0..8))
- * MaxWrSkew = max(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX] + 1 (max is across all
- * ranks i (0..3) and bytes j (0..8))
- * R2W_XDIMM_INIT has 2 extra CK cycles built in for OCTEON-internal ODT settling/channel
- * turnaround time.
- * R2R_XDIMM_INIT, W2R_XRANK_INIT, W2W_XDIMM_INIT have 1 extra CK cycle built in for channel
- * turnaround time.
+ * LMC(0..3)_WLEVEL_RANK(0..3), LMC(0..3)_CONTROL and LMC(0..3)_MODEREG_PARAMS0 CSRs change.
+ * Ideally, only read this register after LMC has been initialized and
+ * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
+ * The interpretation of the fields in this CSR depends on LMC(0)_CONFIG[DDR2T]:
+ * If LMC(0..3)_CONFIG[DDR2T] = 1, (FieldValue + 4) is the minimum CK cycles between when the
+ * DRAM part registers CAS commands of the 1
+ * st and 2
+ * nd types from different cache blocks.
+ * If LMC(0..3)_CONFIG[DDR2T] = 0, (FieldValue + 3) is the minimum CK cycles between when the
+ * DRAM part registers CAS commands of the 1
+ * st and 2
+ * nd types from different cache blocks. FieldValue = 0 is always illegal in this case.
+ * The hardware-calculated minimums for these fields are shown in LMC Registers.
  */
 union cvmx_lmcx_slot_ctl2 {
 	uint64_t u64;
@@ -10132,30 +10295,29 @@ union cvmx_lmcx_timing_params2 {
 	struct cvmx_lmcx_timing_params2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t trtp                         : 4;  /**< Set this field as follows:
+	uint64_t trtp                         : 4;  /**< Specifies the TRTP parameter, in cycles. Set this field as follows:
                                                          RNDUP[TRTP(ns) / TCYC(ns)] - 1,
-                                                         Indicates the tRTP parameter, in cycles.  For DDR3, TYP = max(4 nCK, 7.5ns),
-                                                         for DDR4 the rRTP parameter is dictated by the tWR MR bits. */
-	uint64_t t_rw_op_max                  : 4;  /**< Indicates the maximum delay for a read or write operation to complete, used to set the
+                                                         For DDR3, typical = max(4 nCK, 7.5ns).
+                                                         For DDR4 the TRTP parameter is dictated by the TWR MR bits. */
+	uint64_t t_rw_op_max                  : 4;  /**< Specifies the maximum delay for a read or write operation to complete, used to set the
                                                          timing of MRW and MPR operations. Set this field as follows:
-                                                         RNDUP[Max operation delay (cycles) / 8]
-                                                         TYP = 7 */
-	uint64_t twtr_l                       : 4;  /**< Set this field as follows:
-                                                         RNDUP[TWTR_L(ns) / TCYC(ns)] - 1,
-                                                         where TWTR_L is from the JEDEC DDR4 spec, and TCYC(ns) is the DDR clock frequency (not
+                                                         RNDUP[Maximum operation delay (cycles) / 8]
+                                                         Typical = 0x7. */
+	uint64_t twtr_l                       : 4;  /**< Specifies TWTR_L constraints. Set this field as follows:
+                                                         RNDUP[TWTR_L(ns) / TCYC(ns)] - 1
+                                                         where TWTR_L is from the JEDEC DDR4 spec, and TCYC(ns) is the DDR clock frequency (not the
                                                          data rate).
-                                                         TYP = max(4 nCK, 7.5 ns)
-                                                         INTERNAL: Seem the "- 1" is because we add 1 back into slot timing equation */
-	uint64_t trrd_l                       : 3;  /**< Indicates TRRD_L constraints. Set this field as follows:
+                                                         Typical = MAX(4 nCK, 7.5 ns)
+                                                         INTERNAL: Seems the '- 1' is because we add 1 back into slot timing equation */
+	uint64_t trrd_l                       : 3;  /**< Specifies TRRD_L constraints. Set this field as follows:
                                                          RNDUP[TRRD_L(ns) / TCYC(ns)] - 1,
-                                                         where TRRD_L is from the JEDEC DDR4 spec, and TCYC(ns) is the DDR clock frequency (not
+                                                         where TRRD_L is from the JEDEC DDR4 spec, and TCYC(ns) is the DDR clock frequency (not the
                                                          data rate).
-                                                         TYP = max(4 nCK, 7.5 ns)
-                                                         - 000: Reserved.
-                                                         - 001: 2 TCYC
-                                                         - ...
-                                                         - 110: 7 TCYC
-                                                         - 111: 8 TCYC */
+                                                         Typical = MAX(4 nCK, 7.5 ns)
+                                                         0x0 = reserved. 0x4 = five TCYC.
+                                                         0x1 = two TCYC. 0x5 = six TCYC.
+                                                         0x2 = three TCYC. 0x6 = seven TCYC.
+                                                         0x3 = four TCYC. 0x7 = eight TCYC. */
 #else
 	uint64_t trrd_l                       : 3;
 	uint64_t twtr_l                       : 4;
@@ -10563,10 +10725,10 @@ typedef union cvmx_lmcx_wodt_ctl1 cvmx_lmcx_wodt_ctl1_t;
  * Each rank has its own ODT pin that fans out to all of the memory parts in that DIMM. System
  * designers may prefer different combinations of ODT ONs for write operations into different
  * ranks. CN78XX supports full programmability by way of the mask register below. Each rank
- * position has its own 4-bit programmable field. When the controller does a write to that rank,
+ * position has its own 8-bit programmable field. When the controller does a write to that rank,
  * it sets the 4 ODT pins to the mask pins below. For example, when doing a write into Rank0, a
  * system designer may desire to terminate the lines with the resistor on DIMM0/Rank1. The mask
- * WODT_D0_R0 would then be [0010].
+ * WODT_D0_R0 would then be [00000010].
  * CN78XX drives the appropriate mask values on the ODT pins by default. If this feature is not
  * required, write 0x0 in this register. When a given RANK is selected, the WODT mask for that
  * RANK is used. The resulting WODT mask is driven to the DIMMs in the following manner:
@@ -10615,10 +10777,9 @@ union cvmx_lmcx_wodt_mask {
 	struct cvmx_lmcx_wodt_mask_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t wodt_d1_r1                   : 4;  /**< Write ODT mask DIMM1, RANK1/DIMM1 in SingleRanked.
-                                                         If RANK_ENA=0, WODT_D1_R1<3:0> must be zero. */
+	uint64_t wodt_d1_r1                   : 4;  /**< Reserved. */
 	uint64_t reserved_20_23               : 4;
-	uint64_t wodt_d1_r0                   : 4;  /**< Write ODT mask DIMM1, RANK0. If RANK_ENA=0, WODT_D1_R0<3,1> must be zero. */
+	uint64_t wodt_d1_r0                   : 4;  /**< Reserved. */
 	uint64_t reserved_12_15               : 4;
 	uint64_t wodt_d0_r1                   : 4;  /**< Write ODT mask DIMM0, RANK1/DIMM0 in SingleRanked. If RANK_ENA=0, WODT_D0_R1<3:0> must be
                                                          zero. */
diff --git a/arch/mips/include/asm/octeon/cvmx-mio-defs.h b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
index 6af9aab..10e915b 100644
--- a/arch/mips/include/asm/octeon/cvmx-mio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -497,7 +497,7 @@ static inline uint64_t CVMX_MIO_FUS_DAT4_FUNC(void)
 #define CVMX_MIO_FUS_EMA CVMX_MIO_FUS_EMA_FUNC()
 static inline uint64_t CVMX_MIO_FUS_EMA_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN5XXX) || OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN5XXX) || OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
 		cvmx_warn("CVMX_MIO_FUS_EMA not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001180000001550ull);
 }
@@ -2212,10 +2212,7 @@ typedef union cvmx_mio_boot_bist_stat cvmx_mio_boot_bist_stat_t;
  * cvmx_mio_boot_comp
  *
  * This register sets the termination of boot-bus output pins.
- * Reset value is as follows:
- * no pullups,                               PCTL=6, NCTL=6 (50 ohm termination)
- * pullup on boot_ad[9]                      PCTL=7, NCTL=7 (40 ohm termination)
- * pullup on boot_ad[10].                    PCTL=4, NCTL=4 (75 ohm termination)
+ *
  */
 union cvmx_mio_boot_comp {
 	uint64_t u64;
@@ -2390,7 +2387,7 @@ union cvmx_mio_boot_dma_cfgx {
 	uint64_t size                         : 20; /**< DMA engine 0-1 size. SIZE is specified in number of bus transfers, where one transfer is
                                                          equal to the following number of bytes, dependent on MIO_BOOT_DMA_TIMn[WIDTH] and
                                                          MIO_BOOT_DMA_TIMn[DDR]:
-                                                         WIDTH DDR Transfer Size (bytes)
+                                                         WIDTH DDR  Transfer Size (bytes)
                                                          0 0 2
                                                          0 1 4
                                                          1 0 4
@@ -2761,21 +2758,7 @@ union cvmx_mio_boot_pin_defs {
 	uint64_t u64;
 	struct cvmx_mio_boot_pin_defs_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_57_63               : 7;
-	uint64_t dlm_supply                   : 1;  /**< DLM Power Supply Setting based on DLMC_VPH_SELECT_18 pin 1 = 1.8V 0 = 2.5V All others = Reserved */
-	uint64_t rgm_supply                   : 2;  /**< RGMii Power Supply Setting based on VDD_RGM_SUPPLY_SELECT pin 01 = 1.8V 10 = 2.5V All
-                                                         others = Reserved */
-	uint64_t smi_supply                   : 3;  /**< SMI power supply setting based on VDD_SMI_SUPPLY_SELECT pin:
-                                                         0x1 = 1.8V.
-                                                         0x2 = 2.5V.
-                                                         0x8 = 3.3V.
-                                                         else Reserved. */
-	uint64_t io_supply                    : 3;  /**< I/O power supply setting based on VDD_IO_SUPPLY_SELECT pin:
-                                                         0x1 = 1.8V.
-                                                         0x2 = 2.5V.
-                                                         0x8 = 3.3V.
-                                                         else Reserved. */
-	uint64_t reserved_16_47               : 32;
+	uint64_t reserved_16_63               : 48;
 	uint64_t ale                          : 1;  /**< Region 0 default ALE mode */
 	uint64_t width                        : 1;  /**< Region 0 default bus width */
 	uint64_t reserved_0_13                : 14;
@@ -2783,12 +2766,7 @@ union cvmx_mio_boot_pin_defs {
 	uint64_t reserved_0_13                : 14;
 	uint64_t width                        : 1;
 	uint64_t ale                          : 1;
-	uint64_t reserved_16_47               : 32;
-	uint64_t io_supply                    : 3;
-	uint64_t smi_supply                   : 3;
-	uint64_t rgm_supply                   : 2;
-	uint64_t dlm_supply                   : 1;
-	uint64_t reserved_57_63               : 7;
+	uint64_t reserved_16_63               : 48;
 #endif
 	} s;
 	struct cvmx_mio_boot_pin_defs_cn52xx {
@@ -2867,7 +2845,7 @@ union cvmx_mio_boot_pin_defs {
 	struct cvmx_mio_boot_pin_defs_cn52xx  cn68xxp1;
 	struct cvmx_mio_boot_pin_defs_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_57_63               : 7;
+	uint64_t reserved_33_63               : 31;
 	uint64_t dlm_supply                   : 1;  /**< DLM Power Supply Setting based on DLMC_VPH_SELECT_18 pin 1 = 1.8V 0 = 2.5V All others = Reserved */
 	uint64_t rgm_supply                   : 2;  /**< RGMii Power Supply Setting based on VDD_RGM_SUPPLY_SELECT pin 01 = 1.8V 10 = 2.5V All
                                                          others = Reserved */
@@ -2875,7 +2853,7 @@ union cvmx_mio_boot_pin_defs {
                                                          3.3V All others = Reserved */
 	uint64_t io_supply                    : 3;  /**< I/O Power Supply Setting based on VDD_IO_SUPPLY_SELECT pin 001 = 1.8V 010 = 2.5V 100 =
                                                          3.3V All others = Reserved */
-	uint64_t reserved_17_47               : 31;
+	uint64_t reserved_17_23               : 7;
 	uint64_t ref_sel                      : 1;  /**< Reference Clock Selection based on UART0_RTS_N pin at powerup 0 = DLM_REF_CLK[1] pins div
                                                          2, must be set to 100Mhz 1 = PLL_REF_CLK pin (default), must be set to 50Mhz */
 	uint64_t ale                          : 1;  /**< Set to 1 for backward compatability */
@@ -2895,12 +2873,12 @@ union cvmx_mio_boot_pin_defs {
 	uint64_t width                        : 1;
 	uint64_t ale                          : 1;
 	uint64_t ref_sel                      : 1;
-	uint64_t reserved_17_47               : 31;
+	uint64_t reserved_17_23               : 7;
 	uint64_t io_supply                    : 3;
 	uint64_t smi_supply                   : 3;
 	uint64_t rgm_supply                   : 2;
 	uint64_t dlm_supply                   : 1;
-	uint64_t reserved_57_63               : 7;
+	uint64_t reserved_33_63               : 31;
 #endif
 	} cn70xx;
 	struct cvmx_mio_boot_pin_defs_cn78xx {
@@ -4619,11 +4597,12 @@ union cvmx_mio_fus_dat3 {
 	uint64_t u64;
 	struct cvmx_mio_fus_dat3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_58_63               : 6;
+	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. */
 	uint64_t pll_ctl                      : 10; /**< Fuse information - PLL control */
 	uint64_t dfa_info_dte                 : 3;  /**< Fuse information - DFA information (DTE) */
 	uint64_t dfa_info_clm                 : 4;  /**< Fuse information - DFA information (Cluster mask) */
-	uint64_t reserved_38_40               : 3;
+	uint64_t reserved_40_40               : 1;
+	uint64_t ema                          : 2;  /**< Fuse information - EMA */
 	uint64_t efus_lck_rsv                 : 1;  /**< Fuse information - efuse lockdown */
 	uint64_t efus_lck_man                 : 1;  /**< Fuse information - efuse lockdown */
 	uint64_t pll_half_dis                 : 1;  /**< Fuse information - RCLK PLL control */
@@ -4636,9 +4615,9 @@ union cvmx_mio_fus_dat3 {
 	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore */
 	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable */
 	uint64_t nodfa_dte                    : 1;  /**< Fuse information - DFA Disable (DTE) */
-	uint64_t icache                       : 24; /**< Fuse information - ICACHE Hard Repair Data */
+	uint64_t reserved_0_23                : 24;
 #else
-	uint64_t icache                       : 24;
+	uint64_t reserved_0_23                : 24;
 	uint64_t nodfa_dte                    : 1;
 	uint64_t nozip                        : 1;
 	uint64_t efus_ign                     : 1;
@@ -4650,11 +4629,12 @@ union cvmx_mio_fus_dat3 {
 	uint64_t pll_half_dis                 : 1;
 	uint64_t efus_lck_man                 : 1;
 	uint64_t efus_lck_rsv                 : 1;
-	uint64_t reserved_38_40               : 3;
+	uint64_t ema                          : 2;
+	uint64_t reserved_40_40               : 1;
 	uint64_t dfa_info_clm                 : 4;
 	uint64_t dfa_info_dte                 : 3;
 	uint64_t pll_ctl                      : 10;
-	uint64_t reserved_58_63               : 6;
+	uint64_t ema0                         : 6;
 #endif
 	} s;
 	struct cvmx_mio_fus_dat3_cn30xx {
@@ -4824,7 +4804,7 @@ union cvmx_mio_fus_dat3 {
 	struct cvmx_mio_fus_dat3_cn61xx       cn68xxp1;
 	struct cvmx_mio_fus_dat3_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ema                          : 6;  /**< Fuse information - EMA. */
+	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. */
 	uint64_t pll_ctl                      : 10; /**< Fuse information - PLL control. */
 	uint64_t dfa_info_dte                 : 3;  /**< Fuse information - HFA information (HTE). */
 	uint64_t dfa_info_clm                 : 4;  /**< Fuse information - HFA information (cluster mask). */
@@ -4833,11 +4813,11 @@ union cvmx_mio_fus_dat3 {
 	uint64_t efus_lck_man                 : 1;  /**< Fuse information - efuse lockdown. */
 	uint64_t pll_half_dis                 : 1;  /**< Fuse information - Coprocessor-clock PLL control. */
 	uint64_t l2c_crip                     : 3;  /**< Fuse information - L2C cripple:
-                                                         0x0 = 16-way, 2MB cache
-                                                         0x1 = 12-way, 1.5MB cache
-                                                         0x2 = 8-way, 1MB cache
-                                                         0x3 = 4-way, 512KB cache
-                                                         0x4-0x7 = reserved */
+                                                         0 -- full cache (4-way 512KB)
+                                                         1 -- 3/4 ways   (3-way 384KB)
+                                                         2 -- 1/2 ways   (2-way 256KB)
+                                                         3 -- 1/4 ways   (1-way 128KB)
+                                                         4-7 -- illegal */
 	uint64_t reserved_31_31               : 1;
 	uint64_t zip_info                     : 2;  /**< Fuse information - Zip information */
 	uint64_t bar2_en                      : 1;  /**< Fuse information - BAR2 present (when blown `1') */
@@ -4845,9 +4825,11 @@ union cvmx_mio_fus_dat3 {
 	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore */
 	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable */
 	uint64_t nodfa_dte                    : 1;  /**< Fuse information - HFA disable (HTE) */
-	uint64_t reserved_0_23                : 24;
+	uint64_t ema1                         : 6;  /**< Fuse information - EMA1. */
+	uint64_t reserved_0_17                : 18;
 #else
-	uint64_t reserved_0_23                : 24;
+	uint64_t reserved_0_17                : 18;
+	uint64_t ema1                         : 6;
 	uint64_t nodfa_dte                    : 1;
 	uint64_t nozip                        : 1;
 	uint64_t efus_ign                     : 1;
@@ -4863,10 +4845,61 @@ union cvmx_mio_fus_dat3 {
 	uint64_t dfa_info_clm                 : 4;
 	uint64_t dfa_info_dte                 : 3;
 	uint64_t pll_ctl                      : 10;
-	uint64_t ema                          : 6;
+	uint64_t ema0                         : 6;
 #endif
 	} cn70xx;
-	struct cvmx_mio_fus_dat3_cn70xx       cn78xx;
+	struct cvmx_mio_fus_dat3_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. */
+	uint64_t pll_ctl                      : 10; /**< Fuse information - PLL control. */
+	uint64_t dfa_info_dte                 : 3;  /**< Fuse information - HFA information (HTE). */
+	uint64_t dfa_info_clm                 : 4;  /**< Fuse information - HFA information (cluster mask). */
+	uint64_t reserved_38_40               : 3;
+	uint64_t efus_lck_rsv                 : 1;  /**< Fuse information - efuse lockdown. */
+	uint64_t efus_lck_man                 : 1;  /**< Fuse information - efuse lockdown. */
+	uint64_t pll_half_dis                 : 1;  /**< Fuse information - Coprocessor-clock PLL control. */
+	uint64_t l2c_crip                     : 3;  /**< Fuse information - L2C cripple:
+                                                         0x0 = Full cache (16-way, 16 MB)
+                                                         0x1 = 3/4 ways (12-way, 12 MB)
+                                                         0x2 = 1/2 ways (8-way, 8 MB)
+                                                         0x3 = 1/4 ways (4-way, 4MB)
+                                                         0x4-0x7 = Reserved */
+	uint64_t reserved_31_31               : 1;
+	uint64_t zip_info                     : 2;  /**< Fuse information - Zip information */
+	uint64_t bar2_en                      : 1;  /**< Fuse information - BAR2 present (when blown `1') */
+	uint64_t efus_lck                     : 1;  /**< Fuse information - efuse lockdown */
+	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore */
+	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable */
+	uint64_t nodfa_dte                    : 1;  /**< Fuse information - HFA disable (HTE) */
+	uint64_t ema1                         : 6;  /**< Fuse information - EMA1. */
+	uint64_t nohna_dte                    : 1;  /**< Fuse information - HNA disable (DTE). */
+	uint64_t hna_info_dte                 : 3;  /**< Fuse information - HNA information (DTE). */
+	uint64_t hna_info_clm                 : 4;  /**< Fuse information - HNA information (cluster mask). */
+	uint64_t reserved_0_9                 : 10;
+#else
+	uint64_t reserved_0_9                 : 10;
+	uint64_t hna_info_clm                 : 4;
+	uint64_t hna_info_dte                 : 3;
+	uint64_t nohna_dte                    : 1;
+	uint64_t ema1                         : 6;
+	uint64_t nodfa_dte                    : 1;
+	uint64_t nozip                        : 1;
+	uint64_t efus_ign                     : 1;
+	uint64_t efus_lck                     : 1;
+	uint64_t bar2_en                      : 1;
+	uint64_t zip_info                     : 2;
+	uint64_t reserved_31_31               : 1;
+	uint64_t l2c_crip                     : 3;
+	uint64_t pll_half_dis                 : 1;
+	uint64_t efus_lck_man                 : 1;
+	uint64_t efus_lck_rsv                 : 1;
+	uint64_t reserved_38_40               : 3;
+	uint64_t dfa_info_clm                 : 4;
+	uint64_t dfa_info_dte                 : 3;
+	uint64_t pll_ctl                      : 10;
+	uint64_t ema0                         : 6;
+#endif
+	} cn78xx;
 	struct cvmx_mio_fus_dat3_cn61xx       cnf71xx;
 };
 typedef union cvmx_mio_fus_dat3 cvmx_mio_fus_dat3_t;
@@ -4879,14 +4912,14 @@ union cvmx_mio_fus_dat4 {
 	struct cvmx_mio_fus_dat4_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_52_63               : 12;
-	uint64_t east_rclk_byp_select         : 1;  /**< N/A */
+	uint64_t east_rclk_byp_select         : 1;  /**< Reserved. */
 	uint64_t east_rclk_byp_setting        : 12; /**< Reserved. */
 	uint64_t cmb_rclk_byp_select          : 1;  /**< Reserved. */
 	uint64_t cmb_rclk_byp_setting         : 12; /**< Reserved. */
 	uint64_t pp_rclk_byp_select           : 1;  /**< Reserved. */
 	uint64_t pp_rclk_byp_setting          : 12; /**< Reserved. */
-	uint64_t tad_rclk_byp_select          : 1;  /**< N/A */
-	uint64_t tad_rclk_byp_setting         : 12; /**< N/A */
+	uint64_t tad_rclk_byp_select          : 1;  /**< Reserved. */
+	uint64_t tad_rclk_byp_setting         : 12; /**< Reserved. */
 #else
 	uint64_t tad_rclk_byp_setting         : 12;
 	uint64_t tad_rclk_byp_select          : 1;
@@ -4946,16 +4979,6 @@ union cvmx_mio_fus_ema {
 	struct cvmx_mio_fus_ema_s             cn66xx;
 	struct cvmx_mio_fus_ema_s             cn68xx;
 	struct cvmx_mio_fus_ema_s             cn68xxp1;
-	struct cvmx_mio_fus_ema_cn70xx {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_3_63                : 61;
-	uint64_t ema                          : 3;  /**< Reserved. */
-#else
-	uint64_t ema                          : 3;
-	uint64_t reserved_3_63                : 61;
-#endif
-	} cn70xx;
-	struct cvmx_mio_fus_ema_cn70xx        cn78xx;
 	struct cvmx_mio_fus_ema_s             cnf71xx;
 };
 typedef union cvmx_mio_fus_ema cvmx_mio_fus_ema_t;
@@ -5484,7 +5507,7 @@ union cvmx_mio_fus_read_times {
 	uint64_t reserved_32_63               : 32;
 	uint64_t done                         : 4;  /**< Hold time of CSB, PGENB, and LOAD with respect to falling edge of STROBE for read and
                                                          write mode in PLL_REF_CLK + 1 cycles. Timing specs are th_CS = 6ns, th_PG = 10ns, th_LD_p
-                                                         = 7ns. Default of 0x0 yields 20ns for a PLL_REF_CLK of 50 MHz. */
+                                                         = 7ns. Default of 0x0 yields 20ns for a PLL_REF_CLK of 50 MHz, 10ns at 100MHz. */
 	uint64_t reserved_0_27                : 28;
 #else
 	uint64_t reserved_0_27                : 28;
@@ -5548,20 +5571,20 @@ union cvmx_mio_fus_read_times {
 	uint64_t reserved_32_63               : 32;
 	uint64_t done                         : 4;  /**< Hold time of CSB, PGENB, and LOAD with respect to falling edge of STROBE for read and
                                                          write mode in PLL_REF_CLK + 1 cycles. Timing specs are th_CS = 6ns, th_PG = 10ns, th_LD_p
-                                                         = 7ns. Default of 0x0 yields 20ns for a PLL_REF_CLK of 50 MHz. */
+                                                         = 7ns. Default of 0x0 yields 20ns for a PLL_REF_CLK of 50 MHz, 10ns at 100MHz. */
 	uint64_t ahd                          : 4;  /**< Hold time of A with respect to falling edge of STROBE for read and write modes in
                                                          PLL_REF_CLK + 2 cycles. Timing spec of tsu_A_r and tsu_A_p is 3ns min. Default of 0x0
-                                                         yields 40ns for a PLL_REF_CLK of 50 MHz. */
+                                                         yields 40ns for a PLL_REF_CLK of 50 MHz, 20ns at 100MHz. */
 	uint64_t wrstb_wh                     : 12; /**< Pulse width high of STROBE in write mode in PLL_REF_CLK + 1 cycles. Timing spec of
                                                          twh_SB_p is 9.8us max. Default of 0x1F3 yields 10 us at PLL_REF_CLK of 50 MHz. */
 	uint64_t rdstb_wh                     : 4;  /**< Pulse width high of STROBE in read mode in PLL_REF_CLK + 1 cycles. Timing spec of twh_SB_p
-                                                         is 20ns min. Default of 0x0 yields 20 ns at PLL_REF_CLK of 50 MHz. */
+                                                         is 20ns min. Default of 0x1 yields 40 ns at PLL_REF_CLK of 50 MHz, 20ns at 100MHz. */
 	uint64_t asu                          : 4;  /**< Setup time of A to rising edge of STROBE for read and write modes in PLL_REF_CLK cycles.
-                                                         Timing spec of tsu_A_r and rsu_A-P is 12 ns min. Default of 0x1 yields 20 ns at
-                                                         PLL_REF_CLK of 50 MHz. */
+                                                         Timing spec of tsu_A_r and tsu_A_p is 12 ns min. Default of 0x1 yields 40 ns at
+                                                         PLL_REF_CLK of 50 MHz, 20ns at 100MHz. */
 	uint64_t setup                        : 4;  /**< Setup of CSB, PGENB, LOAD to rising edge of STROBE in read and write modes in PLL_REF_CLK
-                                                         + 1 cycles. TSUCS= 16ns, TSUPG= 14ns, TSULD_R= 10ns. Default of 0x0 yields 20 ns at
-                                                         PLL_REF_CLK of 50 MHz. */
+                                                         + 1 cycles. tsu_CS = 16ns, tsu_PG = 14ns, tsu_LD_r = 10ns. Default of 0x0 yields 20 ns
+                                                         plush ASU cycles at PLL_REF_CLK of 50 MHz, 10ns + ASU at 100MHz. */
 #else
 	uint64_t setup                        : 4;
 	uint64_t asu                          : 4;
@@ -6120,8 +6143,8 @@ typedef union cvmx_mio_pll_setting cvmx_mio_pll_setting_t;
 /**
  * cvmx_mio_ptp_ckout_hi_incr
  *
- * This register contains the high bytes of the PTP clock out increment. MIO_PTP Registers for
- * address.
+ * This register contains the high bytes of the PTP clock out increment.
+ *
  */
 union cvmx_mio_ptp_ckout_hi_incr {
 	uint64_t u64;
@@ -6146,7 +6169,7 @@ typedef union cvmx_mio_ptp_ckout_hi_incr cvmx_mio_ptp_ckout_hi_incr_t;
 /**
  * cvmx_mio_ptp_ckout_lo_incr
  *
- * This register contains the low bytes of the PTP clock out increment. MIO_PTP Registers for address.
+ * This register contains the low bytes of the PTP clock out increment.
  *
  */
 union cvmx_mio_ptp_ckout_lo_incr {
@@ -6174,7 +6197,7 @@ typedef union cvmx_mio_ptp_ckout_lo_incr cvmx_mio_ptp_ckout_lo_incr_t;
  *
  * This register contains the high bytes of the PTP clock out. Writes to MIO_PTP_CKOUT_THRESH_HI
  * also clear MIO_PTP_CKOUT_THRESH_LO; to update all 96 bits, write MIO_PTP_CKOUT_THRESH_HI
- * followed by MIO_PTP_CKOUT_THRESH_LO. MIO_PTP Registers for address.
+ * followed by MIO_PTP_CKOUT_THRESH_LO.
  */
 union cvmx_mio_ptp_ckout_thresh_hi {
 	uint64_t u64;
@@ -6197,7 +6220,7 @@ typedef union cvmx_mio_ptp_ckout_thresh_hi cvmx_mio_ptp_ckout_thresh_hi_t;
 /**
  * cvmx_mio_ptp_ckout_thresh_lo
  *
- * This register contains the low bytes of the PTP clock out. MIO_PTP Registers for address.
+ * This register contains the low bytes of the PTP clock out.
  *
  */
 union cvmx_mio_ptp_ckout_thresh_lo {
@@ -6223,7 +6246,7 @@ typedef union cvmx_mio_ptp_ckout_thresh_lo cvmx_mio_ptp_ckout_thresh_lo_t;
 /**
  * cvmx_mio_ptp_clock_cfg
  *
- * This register configures the timestamp architecture. MIO_PTP Registers for address
+ * This register configures the timestamp architecture. See MIO_PTP Registers for address
  *
  */
 union cvmx_mio_ptp_clock_cfg {
@@ -6561,7 +6584,7 @@ typedef union cvmx_mio_ptp_clock_cfg cvmx_mio_ptp_clock_cfg_t;
 /**
  * cvmx_mio_ptp_clock_comp
  *
- * This register provides the compensation value the PTP clock. MIO_PTP Registers for address.
+ * This register provides the compensation value the PTP clock.
  *
  */
 union cvmx_mio_ptp_clock_comp {
@@ -6591,8 +6614,7 @@ typedef union cvmx_mio_ptp_clock_comp cvmx_mio_ptp_clock_comp_t;
  * cvmx_mio_ptp_clock_hi
  *
  * This register provides bits<95:32> of the PTP clock. Writes to MIO_PTP_CLOCK_HI also clear
- * MIO_PTP_CLOCK_LO. To update all 96 bits, write MIO_PTP_CLOCK_HI followed by
- * MIO_PTP_CLOCK_LOMIO_PTP Registers for address.
+ * MIO_PTP_CLOCK_LO. To update all 96 bits, write MIO_PTP_CLOCK_HI followed by MIO_PTP_CLOCK_LO.
  */
 union cvmx_mio_ptp_clock_hi {
 	uint64_t u64;
@@ -6618,7 +6640,7 @@ typedef union cvmx_mio_ptp_clock_hi cvmx_mio_ptp_clock_hi_t;
 /**
  * cvmx_mio_ptp_clock_lo
  *
- * This register provides bits<31:0> of the PTP clock. MIO_PTP Registers for address.
+ * This register provides bits<31:0> of the PTP clock.
  *
  */
 union cvmx_mio_ptp_clock_lo {
@@ -6647,7 +6669,7 @@ typedef union cvmx_mio_ptp_clock_lo cvmx_mio_ptp_clock_lo_t;
 /**
  * cvmx_mio_ptp_dpll_err_int
  *
- * This register contains the Digital PLL error event interrupt. MIO_PTP Registers for address.
+ * This register contains the Digital PLL error event interrupt.
  *
  */
 union cvmx_mio_ptp_dpll_err_int {
@@ -6670,7 +6692,7 @@ typedef union cvmx_mio_ptp_dpll_err_int cvmx_mio_ptp_dpll_err_int_t;
 /**
  * cvmx_mio_ptp_dpll_err_thresh
  *
- * This register configures the Digital PLL error interrupt. MIO_PTP Registers for address.
+ * This register configures the Digital PLL error interrupt.
  *
  */
 union cvmx_mio_ptp_dpll_err_thresh {
@@ -6691,8 +6713,8 @@ typedef union cvmx_mio_ptp_dpll_err_thresh cvmx_mio_ptp_dpll_err_thresh_t;
 /**
  * cvmx_mio_ptp_dpll_incr
  *
- * This register contains the Digital PLL increment. Zero disables the digital PLL. MIO_PTP
- * Registers for address.
+ * This register contains the Digital PLL increment. Zero disables the digital PLL.
+ *
  */
 union cvmx_mio_ptp_dpll_incr {
 	uint64_t u64;
@@ -6712,7 +6734,7 @@ typedef union cvmx_mio_ptp_dpll_incr cvmx_mio_ptp_dpll_incr_t;
 /**
  * cvmx_mio_ptp_evt_cnt
  *
- * This register contains the PTP event counter. MIO_PTP Registers for address.
+ * This register contains the PTP event counter.
  *
  */
 union cvmx_mio_ptp_evt_cnt {
@@ -6739,7 +6761,7 @@ typedef union cvmx_mio_ptp_evt_cnt cvmx_mio_ptp_evt_cnt_t;
 /**
  * cvmx_mio_ptp_evt_int
  *
- * This register contains the PTP event interrupt. MIO_PTP Registers for address.
+ * This register contains the PTP event interrupt.
  *
  */
 union cvmx_mio_ptp_evt_int {
@@ -6787,7 +6809,7 @@ typedef union cvmx_mio_ptp_phy_1pps_in cvmx_mio_ptp_phy_1pps_in_t;
 /**
  * cvmx_mio_ptp_pps_hi_incr
  *
- * This register contains the high bytes of the PTP PPS increment. MIO_PTP Registers for address.
+ * This register contains the high bytes of the PTP PPS increment.
  *
  */
 union cvmx_mio_ptp_pps_hi_incr {
@@ -6813,7 +6835,7 @@ typedef union cvmx_mio_ptp_pps_hi_incr cvmx_mio_ptp_pps_hi_incr_t;
 /**
  * cvmx_mio_ptp_pps_lo_incr
  *
- * This register contains the low bytes of the PTP PPS increment. MIO_PTP Registers for address.
+ * This register contains the low bytes of the PTP PPS increment.
  *
  */
 union cvmx_mio_ptp_pps_lo_incr {
@@ -6841,7 +6863,7 @@ typedef union cvmx_mio_ptp_pps_lo_incr cvmx_mio_ptp_pps_lo_incr_t;
  *
  * This register contains the high bytes of the PTP PPS. Writes to MIO_PTP_PPS_THRESH_HI also
  * clear MIO_PTP_PPS_THRESH_LO; to update all 96 bits write MIO_PTP_PPS_THRESH_HI followed by
- * MIO_PTP_PPS_THRESH_LO. MIO_PTP Registers for address.
+ * MIO_PTP_PPS_THRESH_LO.
  */
 union cvmx_mio_ptp_pps_thresh_hi {
 	uint64_t u64;
@@ -6864,7 +6886,7 @@ typedef union cvmx_mio_ptp_pps_thresh_hi cvmx_mio_ptp_pps_thresh_hi_t;
 /**
  * cvmx_mio_ptp_pps_thresh_lo
  *
- * This register contains the low bytes of the PTP PPS. MIO_PTP Registers for address.
+ * This register contains the low bytes of the PTP PPS.
  *
  */
 union cvmx_mio_ptp_pps_thresh_lo {
@@ -6891,7 +6913,7 @@ typedef union cvmx_mio_ptp_pps_thresh_lo cvmx_mio_ptp_pps_thresh_lo_t;
  * cvmx_mio_ptp_timestamp
  *
  * This register contains the timestamp latched on MIO_PTP_CLOCK_CFG[TSTMP_EDGE] edge of
- * MIO_PTP_CLOCK_CFG[TSTMP_IN]. MIO_PTP Registers for address.
+ * MIO_PTP_CLOCK_CFG[TSTMP_IN].
  */
 union cvmx_mio_ptp_timestamp {
 	uint64_t u64;
@@ -8755,10 +8777,11 @@ typedef union cvmx_mio_twsx_twsi_sw cvmx_mio_twsx_twsi_sw_t;
  * cvmx_mio_uart#_dlh
  *
  * The 8-bit divisor latch high register in conjunction with the 8-bit divisor latch low
- * (MIO_UART0/1_DLL) register form a 16-bit, read/write, Divisor Latch register that contains the
- * baud-rate divisor for the UART. It is accessed by first setting MIO_UART0/1_LCR[DLAB] (bit 7)
- * (refer to MIO UART Line Control Register). The output baud rate is equal to the coprocessor-
- * clock frequency divided by sixteen times the value of the baud-rate divisor, as follows:
+ * (MIO_UART(0..1)_DLL) register form a 16-bit, read/write, Divisor Latch register that contains
+ * the baud-rate divisor for the UART. It is accessed by first setting MIO_UART(0..1)_LCR[DLAB]
+ * (bit 7) (refer to MIO UART Line Control Register). The output baud rate is equal to the
+ * coprocessor-clock frequency divided by sixteen times the value of the baud-rate divisor, as
+ * follows:
  * baud rate = coprocessor-clock frequency / (16 * divisor).
  * Note that once both divisor latch registers are set, at least eight coprocessor-clock cycles
  * should be allowed to pass before transmitting or receiving data.
@@ -8802,10 +8825,11 @@ typedef cvmx_mio_uartx_dlh_t cvmx_uart_dlh_t;
  * cvmx_mio_uart#_dll
  *
  * The 8-bit divisor latch high register in conjunction with the 8-bit divisor latch low
- * (MIO_UART0/1_DLL) register form a 16-bit, read/write, Divisor Latch register that contains the
- * baud-rate divisor for the UART. It is accessed by first setting MIO_UART0/1_LCR[DLAB] (bit 7)
- * (refer to MIO UART Line Control Register). The output baud rate is equal to the coprocessor-
- * clock frequency divided by sixteen times the value of the baud-rate divisor, as follows:
+ * (MIO_UART(0..1)_DLL) register form a 16-bit, read/write, Divisor Latch register that contains
+ * the baud-rate divisor for the UART. It is accessed by first setting MIO_UART(0..1)_LCR[DLAB]
+ * (bit 7) (refer to MIO UART Line Control Register). The output baud rate is equal to the
+ * coprocessor-clock frequency divided by sixteen times the value of the baud-rate divisor, as
+ * follows:
  * baud rate = coprocessor-clock frequency / (16 * divisor).
  * Note that once both divisor latch registers are set, at least eight coprocessor-clock cycles
  * should be allowed to pass before transmitting or receiving data.
@@ -8850,10 +8874,10 @@ typedef cvmx_mio_uartx_dll_t cvmx_uart_dll_t;
  *
  * The FIFO access register is used to enable a FIFO-access mode for testing, so that the receive
  * FIFO can be written by software and the transmit FIFO can be read by software when the FIFOs
- * are enabled. When FIFOs are not enabled it allows the MIO_UART0/1_RBR to be written by
- * software and the MIO_UART0/1_THR to be read by software. Note, that when the FIFO-access mode
- * is enabled/disabled, the control portion of the receive FIFO and transmit FIFO is reset and
- * the FIFOs are treated as empty.
+ * are enabled. When FIFOs are not enabled it allows the MIO_UART(0..1)_RBR to be written by
+ * software and the MIO_UART(0..1)_THR to be read by software. Note, that when the FIFO-access
+ * mode is enabled/disabled, the control portion of the receive FIFO and transmit FIFO is reset
+ * and the FIFOs are treated as empty.
  */
 union cvmx_mio_uartx_far {
 	uint64_t u64;
@@ -9306,7 +9330,7 @@ typedef cvmx_mio_uartx_msr_t cvmx_uart_msr_t;
  *
  * The receive buffer register is a read-only register that contains the data byte received on
  * the serial input port (SIN). The data in this register is valid only if the
- * MIO_UART0/1_LSR[DR] bit is set (
+ * MIO_UART(0..1)_LSR[DR] bit is set (
  */
 union cvmx_mio_uartx_rbr {
 	uint64_t u64;
@@ -9388,7 +9412,7 @@ typedef cvmx_mio_uartx_rfl_t cvmx_uart_rfl_t;
  * cvmx_mio_uart#_rfw
  *
  * The receive FIFO write register is only valid when FIFO-access mode is enabled (i.e.
- * MIO_UART0/1_FAR[FAR] = 1).
+ * MIO_UART(0..1)_FAR[FAR] = 1).
  */
 union cvmx_mio_uartx_rfw {
 	uint64_t u64;
@@ -9433,8 +9457,8 @@ typedef cvmx_mio_uartx_rfw_t cvmx_uart_rfw_t;
  * cvmx_mio_uart#_sbcr
  *
  * The shadow break control register is a shadow register for the
- * MIO_UART0/1_LCR[BRK] bit that can be used to remove the burden of having to perform a read-
- * modify-write on MIO_UART0/1_LCR.
+ * MIO_UART(0..1)_LCR[BRK] bit that can be used to remove the burden of having to perform a read-
+ * modify-write on MIO_UART(0..1)_LCR.
  */
 union cvmx_mio_uartx_sbcr {
 	uint64_t u64;
@@ -9515,9 +9539,10 @@ typedef cvmx_mio_uartx_scr_t cvmx_uart_scr_t;
 /**
  * cvmx_mio_uart#_sfe
  *
- * The shadow FIFO enable register is a shadow register for MIO_UART0/1_FCR[EN] that can be used
- * to remove the burden of having to store the previously written value to MIO_UART0/1_FCR in
- * memory and having to mask this value so that only the FIFO enable bit gets updated.
+ * The shadow FIFO enable register is a shadow register for MIO_UART(0..1)_FCR[EN] that can be
+ * used to remove the burden of having to store the previously written value to
+ * MIO_UART(0..1)_FCR in memory and having to mask this value so that only the FIFO enable bit
+ * gets updated.
  */
 union cvmx_mio_uartx_sfe {
 	uint64_t u64;
@@ -9603,8 +9628,8 @@ typedef cvmx_mio_uartx_srr_t cvmx_uart_srr_t;
  * cvmx_mio_uart#_srt
  *
  * The shadow RX trigger register is a shadow register for the RX trigger bits
- * (MIO_UART0/1_FCR[RXTRIG]) that can be used to remove the burden of having to store the
- * previously written value to MIO_UART0/1_FCR in memory and having to mask this value so that
+ * (MIO_UART(0..1)_FCR[RXTRIG]) that can be used to remove the burden of having to store the
+ * previously written value to MIO_UART(0..1)_FCR in memory and having to mask this value so that
  * only the RX trigger bits get updated.
  */
 union cvmx_mio_uartx_srt {
@@ -9646,8 +9671,8 @@ typedef cvmx_mio_uartx_srt_t cvmx_uart_srt_t;
  * cvmx_mio_uart#_srts
  *
  * The shadow request to send register is a shadow register for the
- * MIO_UART0/1_MCR[RTS] bit that can be used to remove the burden of having to perform a read-
- * modify-write on MIO_UART0/1_MCR.
+ * MIO_UART(0..1)_MCR[RTS] bit that can be used to remove the burden of having to perform a read-
+ * modify-write on MIO_UART(0..1)_MCR.
  */
 union cvmx_mio_uartx_srts {
 	uint64_t u64;
@@ -9688,8 +9713,8 @@ typedef cvmx_mio_uartx_srts_t cvmx_uart_srts_t;
  * cvmx_mio_uart#_stt
  *
  * The shadow TX trigger register is a shadow register for the TX trigger bits
- * (MIO_UART0/1_FCR[TXTRIG]) that can be used to remove the burden of having to store the
- * previously written value to MIO_UART0/1_FCR in memory and having to mask this value so that
+ * (MIO_UART(0..1)_FCR[TXTRIG]) that can be used to remove the burden of having to store the
+ * previously written value to MIO_UART(0..1)_FCR in memory and having to mask this value so that
  * only the TX trigger bits get updated.
  */
 union cvmx_mio_uartx_stt {
@@ -9772,7 +9797,7 @@ typedef cvmx_mio_uartx_tfl_t cvmx_uart_tfl_t;
  * cvmx_mio_uart#_tfr
  *
  * The transmit FIFO read register is only valid when FIFO-access mode is enabled (i.e.
- * MIO_UART0/1_FAR[FAR] = 1).
+ * MIO_UART(0..1)_FAR[FAR] = 1).
  */
 union cvmx_mio_uartx_tfr {
 	uint64_t u64;
@@ -9813,8 +9838,8 @@ typedef cvmx_mio_uartx_tfr_t cvmx_uart_tfr_t;
  * cvmx_mio_uart#_thr
  *
  * The transmit holding register is a write-only register that contains data to be transmitted on
- * the serial output port (UART0/1_SOUT). Data can be written to MIO_UART0/1_THR any time that
- * MIO_UART0/1_LSR[THRE] = 1.
+ * the serial output port (UART0/1_SOUT). Data can be written to MIO_UART(0..1)_THR any time that
+ * MIO_UART(0..1)_LSR[THRE] = 1.
  */
 union cvmx_mio_uartx_thr {
 	uint64_t u64;
@@ -9855,7 +9880,7 @@ typedef cvmx_mio_uartx_thr_t cvmx_uart_thr_t;
  * cvmx_mio_uart#_usr
  *
  * The receive FIFO write register is only valid when FIFO-access mode is enabled (i.e.
- * MIO_UART0/1_FAR[FAR] = 1).
+ * MIO_UART(0..1)_FAR[FAR] = 1).
  */
 union cvmx_mio_uartx_usr {
 	uint64_t u64;
diff --git a/arch/mips/include/asm/octeon/cvmx-mixx-defs.h b/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
index 57edfeb..07a6fee 100644
--- a/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -378,9 +378,9 @@ union cvmx_mixx_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
 	uint64_t ts_thresh                    : 4;  /**< TimeStamp interrupt threshold. When the number of pending Timestamp interrupts
-                                                         (MIX0/1_TSCTL[TSCNT] is greater than
-                                                         MIX0/1_CTL[TS_THRESH], then a programmable TimeStamp interrupt is issued (see
-                                                         MIX0/1_INTR[TS], MIX0/1_INTENA[TSENA]).
+                                                         (MIX(0..1)_TSCTL[TSCNT] is greater than
+                                                         MIX(0..1)_CTL[TS_THRESH], then a programmable TimeStamp interrupt is issued (see
+                                                         MIX(0..1)_INTR[TS].
                                                          For CN78XX, since the implementation only supports four outstanding timestamp interrupts,
                                                          this field should only be programmed from [0..3]. */
 	uint64_t crc_strip                    : 1;  /**< Hardware CRC strip enable. When enabled, the last 4 bytes (CRC) of the ingress packet are
@@ -398,15 +398,15 @@ union cvmx_mixx_ctl {
                                                          reset.
                                                          During a soft reset, CSR accesses are not effected. However, the values of the fields are
                                                          affected by soft reset (except
-                                                         MIX0/1_CTL[RESET] itself).
+                                                         MIX(0..1)_CTL[RESET] itself).
                                                          After power-on, the MIX-BGX are held in reset until RESET is written to 0. Software must
-                                                         also perform a MIX0/1_CTL CSR read after this write to ensure the soft reset de-assertion
-                                                         has had sufficient time to propagate to all MIO-MIX internal logic before any subsequent
-                                                         MIX CSR accesses are issued.
+                                                         also perform a MIX(0..1)_CTL CSR read after this write to ensure the soft reset de-
+                                                         assertion has had sufficient time to propagate to all MIO-MIX internal logic before any
+                                                         subsequent MIX CSR accesses are issued.
                                                          The intended 'soft reset' sequence is:
                                                          Write EN = 0 (to prevent any NEW transactions from being started)
                                                          Wait for BUSY = 0 (to indicate that all in-flight transactions have completed)
-                                                         Write RESET = 1, followed by a MIX0/1_CTL register read and wait for the result.
+                                                         Write RESET = 1, followed by a MIX(0..1)_CTL register read and wait for the result.
                                                          Re-initialize the MIX just as would be done for a hard reset.
                                                          Once the MIX has been soft-reset, please refer to MIX Bring-up Sequence, MIX Bring-up
                                                          Sequence to complete the MIX re-initialization sequence.
@@ -730,9 +730,7 @@ union cvmx_mixx_irhwm {
                                                          enough so that packets are not dropped by CN78XX. */
 	uint64_t irhwm                        : 20; /**< I-Ring entry high-watermark threshold. Used to determine when the number of inbound
                                                          packets in system memory
-                                                         (MIX0/1_IRCNT[IRCNT]) exceeds this IRHWM threshold.
-                                                         The power-on value of the CIU_INTx_EN*[RGMII] interrupt enable bits is 0 and must be
-                                                         enabled to allow interrupts to be reported. */
+                                                         (MIX(0..1)_IRCNT[IRCNT]) exceeds this IRHWM threshold. */
 #else
 	uint64_t irhwm                        : 20;
 	uint64_t ibplwm                       : 20;
@@ -850,7 +848,7 @@ union cvmx_mixx_iring2 {
 	uint64_t itlptr                       : 20; /**< The inbound ring (I-Ring) tail pointer selects the I-Ring entry that the hardware will
                                                          process next. After the hardware completes receiving an inbound packet, it increments the
                                                          I-Ring tail pointer.
-                                                         The I-Ring tail pointer hardware increment is always modulo MIX0/1_IRING2[ISIZE].
+                                                         The I-Ring tail pointer hardware increment is always modulo MIX(0..1)_IRING2[ISIZE].
                                                          This field is read-only to software. */
 	uint64_t reserved_20_31               : 12;
 	uint64_t idbell                       : 20; /**< Represents the cumulative total of pending inbound ring (I-Ring) buffer entries. Each
@@ -861,7 +859,7 @@ union cvmx_mixx_iring2 {
                                                          inbound ring.' When the MIX hardware receives the doorbell ring, it advances the doorbell
                                                          count for the I-Ring.
                                                          Software must never cause the doorbell count for the I-Ring to exceed the size of
-                                                         MIX0/1_IRING1[ISIZE]. A read of the CSR indicates the current doorbell count. */
+                                                         MIX(0..1)_IRING1[ISIZE]. A read of the CSR indicates the current doorbell count. */
 #else
 	uint64_t idbell                       : 20;
 	uint64_t reserved_20_31               : 12;
@@ -895,71 +893,58 @@ union cvmx_mixx_isr {
 	struct cvmx_mixx_isr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t ts                           : 1;  /**< Timestamp interrupt. Throws MIX_INTSN_E::MIX(0..1)_INT_TS. When the number of pending
-                                                         timestamp interrupts (MIX0/1_TSCTL[TSCNT]) is greater than the timestamp interrupt
-                                                         threshold (MIX0/1_CTL[TS_THRESH]) value, this interrupt bit is set.
-                                                         If both the global interrupt mask bits (CIU_INTx[RGMII]) and this local interrupt mask bit
-                                                         is set, than an interrupt is reported for an Outbound Ring with Timestamp event. (See
-                                                         MIX0/1_INTENA[TSENA]). */
+	uint64_t ts                           : 1;  /**< Timestamp interrupt. Throws MIX_INTSN_E:MIX(0..1)_INT_TS. This bit is set and the
+                                                         interrupt generated when the number of pending timestamp interrupts
+                                                         (MIX(0..1)_TSCTL[TSCNT]) is greater than the timestamp interrupt threshold
+                                                         (MIX(0..1)_CTL[TS_THRESH]) value. */
 	uint64_t orun                         : 1;  /**< O-ring packet count underflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_ORUN. If
-                                                         software writes a larger value than what is currently in the MIX0/1_ORCNT[ORCNT], then
+                                                         software writes a larger value than what is currently in the MIX(0..1)_ORCNT[ORCNT], then
                                                          hardware reports the underflow condition.
-                                                         The MIX0/1_ORCNT[IOCNT] will clamp to zero.
+                                                         The MIX(0..1)_ORCNT[IOCNT] will clamp to zero.
                                                          If an ORUN underflow condition is detected, the integrity of the MIX hardware state has
                                                          been compromised. To recover, Software must issue a software reset sequence. (See
-                                                         MIX0/1_CTL[RESET.] */
+                                                         MIX(0..1)_CTL[RESET.] */
 	uint64_t irun                         : 1;  /**< I-ring packet count underflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_IRUN. If
-                                                         software writes a larger value than what is currently in the MIX0/1_IRCNT[IRCNT], then
+                                                         software writes a larger value than what is currently in the MIX(0..1)_IRCNT[IRCNT], then
                                                          hardware reports the underflow condition.
-                                                         The MIX0/1_IRCNT[IRCNT] will clamp to zero.
+                                                         The MIX(0..1)_IRCNT[IRCNT] will clamp to zero.
                                                          If an IRUN underflow condition is detected, the integrity of the MIX hardware state has
                                                          been compromised. To recover, software must issue a software reset sequence. (See
-                                                         MIX0/1_CTL[RESET]). */
+                                                         MIX(0..1)_CTL[RESET]). */
 	uint64_t data_drp                     : 1;  /**< Data was dropped due to RX FIFO full. Throws MIX_INTSN_E::MIX(0..1)_INT_DATA_DRP. If this
-                                                         does occur, the DATA_DRP is set and the CIU_INTx_SUM0/4[RGMII] bit is set.
-                                                         If both the global interrupt mask bits (CIU_INTx[RGMII]) and the local interrupt mask
-                                                         bit(DATA_DRPENA) is set, than an interrupt is reported for this event. */
+                                                         event does occur, DATA_DRP is set and the interrupt is generated. */
 	uint64_t irthresh                     : 1;  /**< Inbound ring packet threshold exceeded. Throws MIX_INTSN_E::MIX(0..1)_INT_IRTHRESH. When
                                                          the pending number of inbound packets in system memory (IRCNT) has exceeded a programmable
-                                                         threshold (IRHWM), this bit is set. If this does occur, the IRTHRESH is set and the
-                                                         CIU_INTx_SUM0/4[RGMII] bit is set if ((MIX_ISR & MIX_INTENA) != 0)).
-                                                         If both the global interrupt mask bits (CIU_INTx[RGMII]) and the local interrupt mask bit
-                                                         (ITHENA) is set, than an interrupt is reported for this event. */
+                                                         threshold (IRHWM), this bit is set and the interrupt is generated. */
 	uint64_t orthresh                     : 1;  /**< Outbound ring packet threshold exceeded. Throws MIX_INTSN_E::MIX(0..1)_INT_ORTHRESH. When
                                                          the pending number of outbound packets in system memory (ORCNT) has exceeded a
-                                                         programmable threshold (ORHWM), this bit is set. If this does occur, the ORTHRESH is set
-                                                         and the CIU_INTx_SUM0/4[RGMII] bit is set if ((MIX_ISR & MIX_INTENA) != 0)).
-                                                         If both the global interrupt mask bits (CIU_INTx[RGMII]) and the local interrupt mask bit
-                                                         (OTHENA) is set, than an interrupt is reported for this event. */
+                                                         programmable threshold (ORHWM), this bit is set and the interrupt is generated. */
 	uint64_t idblovf                      : 1;  /**< "Inbound doorbell (IDBELL) overflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_IDBLOVF.
-                                                         If software attempts to write to the MIX0/1_IRING2[IDBELL] with a value greater than the
-                                                         remaining number of I-Ring buffer entries
-                                                         (MIX0/1_REMCNT[IREMCNT]), then the following occurs:
-                                                         The MIX0/1_IRING2[IDBELL] write is IGNORED
-                                                         The ODBLOVF is set and the CIU_INTx_SUM0/4[RGMII] bits are set if ((MIX0/1_ISR &
-                                                         MIX0/1_INTENA) != 0)).
-                                                         If both the global interrupt mask bits (CIU_INTx[RGMII]) and the local interrupt mask bit
-                                                         (IVFENA) is set, an interrupt is reported for this event.
+                                                         If software attempts to write to the MIX(0..1)_IRING2[IDBELL] with a value greater than
+                                                         the remaining number of I-Ring buffer entries
+                                                         (MIX(0..1)_REMCNT[IREMCNT]), then the following occurs:
+                                                         The MIX(0..1)_IRING2[IDBELL] write is IGNORED
+                                                         The ODBLOVF is set and an interrupt is generated.
                                                          Software should keep track of the \# of I-Ring entries in use (i.e. the cumulative number
                                                          of IDBELL write operations), and ensure that future IDBELL write operations don't exceed
-                                                         the size of the I-Ring Buffer (MIX0/1_IRING2[ISIZE]). Software must reclaim I-Ring entries
-                                                         by keeping track of the number of IRing entries, and writing to the MIX0/1_IRCNT[IRCNT].
-                                                         The MIX0/1_IRCNT[IRCNT] register represents the total number of packets (not IRing
+                                                         the size of the I-Ring Buffer (MIX(0..1)_IRING2[ISIZE]). Software must reclaim I-Ring
+                                                         entries by keeping track of the number of IRing entries, and writing to the
+                                                         MIX(0..1)_IRCNT[IRCNT].
+                                                         The MIX(0..1)_IRCNT[IRCNT] register represents the total number of packets (not IRing
                                                          entries) and software must further keep track of the number of I-Ring entries associated
                                                          with each packet as they are processed.
                                                          There is no recovery from an IDBLOVF Interrupt. If it occurs, it is an indication that
                                                          software has overwritten the I-Ring buffer, and the only recourse is a hardware reset." */
 	uint64_t odblovf                      : 1;  /**< Outbound doorbell (ODBELL) overflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_ODBLOVF.
-                                                         If software attempts to write to MIX0/1_ORING2[ODBELL] with a value greater than the
+                                                         If software attempts to write to MIX(0..1)_ORING2[ODBELL] with a value greater than the
                                                          remaining number of O-Ring buffer entries
-                                                         (MIX0/1_REMCNT[OREMCNT]), then the following occurs:
-                                                         The MIX0/1_ORING2[ODBELL] write operation is IGNORED
-                                                         ODBLOVF is set and the CIU_INTx_SUM0/4[RGMII] bits are set if ((MIX0/1_ISR &
-                                                         MIX0/1_INTENA) != 0)).
+                                                         (MIX(0..1)_REMCNT[OREMCNT]), then the following occurs:
+                                                         The MIX(0..1)_IRING2[ODBELL] write operation is IGNORED
+                                                         ODBLOVF is set and the interrupt is generated.
                                                          Software should keep track of the number of I-Ring entries in use (i.e. the cumulative
                                                          number of ODBELL write operations), and ensure that future ODBELL write operations don't
-                                                         exceed the size of the O-Ring buffer (MIX0/1_ORING2[OSIZE]). Software must reclaim O-Ring
-                                                         entries by writing to MIX0/1_ORCNT[ORCNT].
+                                                         exceed the size of the O-Ring buffer (MIX(0..1)_ORING2[OSIZE]). Software must reclaim
+                                                         O-Ring entries by writing to MIX(0..1)_ORCNT[ORCNT].
                                                          There is no recovery from an ODBLOVF Interrupt. If it occurs, it is an indication that
                                                          software has overwritten the O-Ring buffer, and the only recourse is a hardware reset. */
 #else
@@ -1106,8 +1091,8 @@ union cvmx_mixx_orcnt {
                                                          Reading ORCNT returns the current count.
                                                          Writing ORCNT decrements the count by the value written.
                                                          This register is used to generate interrupts to alert software of pending outbound MIX
-                                                         packets that have been removed from system memory. (See MIX0/1_ISR[ORTHRESH] description
-                                                         for more details.)
+                                                         packets that have been removed from system memory. (See MIX(0..1)_ISR[ORTHRESH]
+                                                         description for more details.)
                                                          For outbound packets, the number of O-Ring Packets is equal to the number of O-Ring
                                                          Entries. */
 #else
@@ -1141,10 +1126,8 @@ union cvmx_mixx_orhwm {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
 	uint64_t orhwm                        : 20; /**< O-Ring entry high-watermark threshold. Used to determine when the number of outbound
-                                                         packets in system memory that can be reclaimed (MIX0/1_ORCNT[ORCNT]) exceeds this ORHWM
-                                                         threshold.
-                                                         The power-on value of the CIU_INTx_EN*[RGMII] interrupt enable bits is 0 and must be
-                                                         enabled to allow interrupts to be reported. */
+                                                         packets in system memory that can be reclaimed (MIX(0..1)_ORCNT[ORCNT]) exceeds this ORHWM
+                                                         threshold. */
 #else
 	uint64_t orhwm                        : 20;
 	uint64_t reserved_20_63               : 44;
@@ -1261,7 +1244,7 @@ union cvmx_mixx_oring2 {
 	uint64_t otlptr                       : 20; /**< The outbound ring tail pointer selects the O-Ring entry that the hardware will process
                                                          next. After the hardware completes sending an outbound packet, it increments the O-Ring
                                                          tail pointer.
-                                                         The O-Ring tail pointer hardware increment is always modulo MIX0/1_ORING2[OSIZE].
+                                                         The O-Ring tail pointer hardware increment is always modulo MIX(0..1)_ORING2[OSIZE].
                                                          This field is read-only to software. */
 	uint64_t reserved_20_31               : 12;
 	uint64_t odbell                       : 20; /**< Represents the cumulative total of pending outbound ring (O-Ring) buffer entries. Each
@@ -1272,7 +1255,7 @@ union cvmx_mixx_oring2 {
                                                          count of the newly inserted entries.' When the MIX hardware receives the doorbell ring, it
                                                          increments the current doorbell count by the CSR write value.
                                                          Software must never cause the doorbell count for the O-Ring to exceed the size of
-                                                         MIX0/1_ORING1[OSIZE]. A read of the CSR indicates the current doorbell count. */
+                                                         MIX(0..1)_ORING1[OSIZE]. A read of the CSR indicates the current doorbell count. */
 #else
 	uint64_t odbell                       : 20;
 	uint64_t reserved_20_31               : 12;
@@ -1307,19 +1290,19 @@ union cvmx_mixx_remcnt {
 	uint64_t reserved_52_63               : 12;
 	uint64_t iremcnt                      : 20; /**< Remaining I-Ring buffer count. Reflects the number of unused/remaining I-Ring entries that
                                                          hardware currently detects in the I-Ring buffer. Hardware uses this value to detect I-Ring
-                                                         doorbell overflows. (See MIX0/1_ISR[IDBLOVF].)
-                                                         When software writes the MIX0/1_IRING1[ISIZE], IREMCNT is loaded with the
-                                                         MIX0/1_IRING2[ISIZE] value. (Note: ISIZE should only be written at power-on, when it is
+                                                         doorbell overflows. (See MIX(0..1)_ISR[IDBLOVF].)
+                                                         When software writes the MIX(0..1)_IRING1[ISIZE], IREMCNT is loaded with the
+                                                         MIX(0..1)_IRING2[ISIZE] value. (Note: ISIZE should only be written at power-on, when it is
                                                          known that there are no I-Ring entries currently in use by hardware.) When software writes
                                                          to the IDBELL register, the IREMCNT is decremented by the CSR write value. When hardware
                                                          issues an I-Ring write request (onto the IOI), REMCNT is incremented by 1. */
 	uint64_t reserved_20_31               : 12;
 	uint64_t oremcnt                      : 20; /**< Remaining O-Ring buffer count. Reflects the number of unused/remaining O-Ring entries that
                                                          hardware currently detects in the O-Ring buffer. Hardware uses this value to detect O-Ring
-                                                         doorbell overflows. (See MIX0/1_ISR[ODBLOVF].)
-                                                         When software writes the MIX0/1_IRING1[OSIZE], OREMCNT is loaded with the
-                                                         MIX0/1_ORING2[OSIZE] value. (Note: [OSIZE] should only be written at power-on, when it is
-                                                         known that no O-Ring entries are currently in use by hardware.) When software writes to
+                                                         doorbell overflows. (See MIX(0..1)_ISR[ODBLOVF].)
+                                                         When software writes the MIX(0..1)_ORING1[OSIZE], OREMCNT is loaded with the
+                                                         MIX(0..1)_ORING2[OSIZE] value. (Note: [OSIZE] should only be written at power-on, when it
+                                                         is known that no O-Ring entries are currently in use by hardware.) When software writes to
                                                          the ODBELL register, OREMCNT is decremented by the CSR write value. When software writes
                                                          to OREMCNT, it is decremented by the CSR write value. */
 #else
@@ -1350,14 +1333,14 @@ typedef union cvmx_mixx_remcnt cvmx_mixx_remcnt_t;
  * to determine the number pending timestamp interrupts ([TSCNT]), the number outstanding
  * timestamp requests in flight ([TSTOT]), and the number of available timestamp entries (TSAVL)
  * in the timestamp FIFO.
- * Writing to this register advances the MIX0/1_TSTAMP FIFO head pointer by 1 and decrements the
- * [TSCNT, TSTOT] pending counts by 1. For example, if software reads [TSCNT] = 2 (two pending
- * timestamp interrupts), it would immediately issue this sequence:
- * a MIX0/1_TSTAMP[TSTAMP] read operation followed by MIX0/1_TSCTL write operation (i.e. it gets
- * the timestamp value, pops the timestamp FIFO, and decrements pending counts by 1).
- * a MIX0/1_TSTAMP[TSTAMP] read operation followed by MIX0/1_TSCTL write operation.
- * Note for Software: A MIX0/1_TSCTL write operation is ignored when
- * MIX0/1_TSCTL[TSCNT] = 0 (i.e., TimeStamp FIFO empty).
+ * Writing to this register advances the MIX(0..1)_TSTAMP FIFO head pointer by 1 and decrements
+ * the [TSCNT, TSTOT] pending counts by 1. For example, if software reads [TSCNT] = 2 (two
+ * pending timestamp interrupts), it would immediately issue this sequence:
+ * a MIX(0..1)_TSTAMP[TSTAMP] read operation followed by MIX(0..1)_TSCTL write operation (i.e. it
+ * gets the timestamp value, pops the timestamp FIFO, and decrements pending counts by 1).
+ * a MIX(0..1)_TSTAMP[TSTAMP] read operation followed by MIX(0..1)_TSCTL write operation.
+ * Note for Software: A MIX(0..1)_TSCTL write operation is ignored when
+ * MIX(0..1)_TSCTL[TSCNT] = 0 (i.e., TimeStamp FIFO empty).
  */
 union cvmx_mixx_tsctl {
 	uint64_t u64;
@@ -1407,26 +1390,25 @@ union cvmx_mixx_tstamp {
                                                          sent to the BGX. Later the BGX sends sample strobe(s) to capture a global 64-bit timestamp
                                                          value, followed by a 'commit' strobe which writes the last sampled value into the outbound
                                                          timestamp FIFO (max depth = 4) and increments
-                                                         MIX0/1_TSCTL[TSCNT] to indicate the total number of pending timestamp interrupts.
-                                                         If the number of pending timestamp interrupts (MIX0/1_TSCTL[TSCNT]) is greater than the
-                                                         MIX0/1_CTL[TS_THRESH] value, then a programmable interrupt is also triggered (see
-                                                         MIX0/1_ISR[TS] and
-                                                         MIX0/1_INTENA[TSENA]).
-                                                         Software then reads MIX0/1_TSTAMP[TSTAMP], and must then write MIX0/1_TSCTL, which will
-                                                         decrement MIX0/1_TSCTL[TSCNT] to indicate that a single timestamp interrupt has been
-                                                         serviced.
+                                                         MIX(0..1)_TSCTL[TSCNT] to indicate the total number of pending timestamp interrupts.
+                                                         If the number of pending timestamp interrupts (MIX(0..1)_TSCTL[TSCNT]) is greater than the
+                                                         MIX(0..1)_CTL[TS_THRESH] value, then a programmable interrupt is also triggered (see
+                                                         MIX(0..1)_ISR[TS].
+                                                         Software then reads MIX(0..1)_TSTAMP[TSTAMP], and must then write MIX(0..1)_TSCTL, which
+                                                         will decrement MIX(0..1)_TSCTL[TSCNT] to indicate that a single timestamp interrupt has
+                                                         been serviced.
                                                          The MIO-MIX hardware tracks up to MAX = 4 outstanding timestamped outbound packets at a
                                                          time. All subsequent O-RING entries with SOP-TSTAMP will be stalled until software can
                                                          service the 4 outstanding interrupts. Software can read
-                                                         MIX0/1_TSCTL to determine the number of pending timestamp interrupts (TSCNT), plus the
+                                                         MIX(0..1)_TSCTL to determine the number of pending timestamp interrupts (TSCNT), plus the
                                                          number of outstanding timestamp requests in flight (TSTOT), as well as the number of
                                                          available timestamp entries (TSAVL).
                                                          A MIX_TSTAMP read when
-                                                         MIX_TSCTL[TSCNT] = 0 will result in a return value of all zeroes. Software should only
-                                                         read this register when
-                                                         MIX0/1_ISR[TS] = 1 (or when MIX0/1_TSCTL[TSCNT] != 0) to retrieve the timestamp value
-                                                         recorded by hardware. If software reads the TSTAMP when hardware has not recorded a valid
-                                                         timestamp, then an all zeroes value is returned. */
+                                                         MIX(0..1)_TSCTL[TSCNT] = 0 will result in a return value of all zeroes. Software should
+                                                         only read this register when
+                                                         MIX(0..1)_ISR[TS] = 1 (or when MIX(0..1)_TSCTL[TSCNT] != 0) to retrieve the timestamp
+                                                         value recorded by hardware. If software reads the TSTAMP when hardware has not recorded a
+                                                         valid timestamp, then an all zeroes value is returned. */
 #else
 	uint64_t tstamp                       : 64;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-mpi-defs.h b/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
index 20db602..996f9fd 100644
--- a/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -482,8 +482,10 @@ union cvmx_mpi_cfg {
                                                          completion of MPI transaction
                                                          1, clock never idles, requires CS deassertion
                                                          assertion between commands */
-	uint64_t idlelo                       : 1;  /**< If 0, SPI_CLK idles high, 1st transition is hi->lo
-                                                         1, SPI_CLK idles low, 1st transition is lo->hi */
+	uint64_t idlelo                       : 1;  /**< 0 = SPI_CK idles high, first transition is high-to-low. This mode corresponds to SPI Block
+                                                         Guide options CPOL = 1, CPHA = 1.
+                                                         1 = SPI_CK idles low, first transition is low-to-high. This mode corresponds to SPI Block
+                                                         Guide options CPOL = 0, CPHA = 0. */
 	uint64_t enable                       : 1;  /**< MPI/SPI master enable.
                                                          0 = UART0_DTR_L/SPI_DO, UART0_DCD_L/SPI_DI,  pins are UART pins.
                                                          1 = UART0_DTR_L/SPI_DO and UART0_DCD_L/SPI_DI pins are MPI/SPI pins.
@@ -548,8 +550,10 @@ union cvmx_mpi_cfg {
                                                          0 = clock idles to value given by IDLELO after completion of MPI/SPI transaction.
                                                          1 = clock never idles, requires SPI_CSn_L deassertion/assertion between commands. */
 	uint64_t idlelo                       : 1;  /**< Clock idle low/clock invert.
-                                                         0 = SPI_CK idles high, first transition is high-to-low.
-                                                         1 = SPI_CK idles low, first transition is low-to-high. */
+                                                         0 = SPI_CK idles high, first transition is high-to-low. This mode corresponds to SPI Block
+                                                         Guide options CPOL = 1, CPHA = 1.
+                                                         1 = SPI_CK idles low, first transition is low-to-high. This mode corresponds to SPI Block
+                                                         Guide options CPOL = 0, CPHA = 0. */
 	uint64_t enable                       : 1;  /**< MPI/SPI enable.
                                                          0 = UART0_DTR_L/SPI_DO, UART0_DCD_L/SPI_DI, UART1_CTS_L/SPI_CS2_L, UART1_RTS_L/SPI_CS3_L
                                                          pins are UART pins.
diff --git a/arch/mips/include/asm/octeon/cvmx-ndf-defs.h b/arch/mips/include/asm/octeon/cvmx-ndf-defs.h
index 4453139..b160bfc 100644
--- a/arch/mips/include/asm/octeon/cvmx-ndf-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ndf-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-npei-defs.h b/arch/mips/include/asm/octeon/cvmx-npei-defs.h
index 0714258..f8fed4b 100644
--- a/arch/mips/include/asm/octeon/cvmx-npei-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-npei-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-npi-defs.h b/arch/mips/include/asm/octeon/cvmx-npi-defs.h
index 4049973..eda66ff 100644
--- a/arch/mips/include/asm/octeon/cvmx-npi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-npi-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
index fafc4f0..ff2d96c 100644
--- a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -447,16 +447,18 @@ union cvmx_oclax_cdhx_ctl {
 	uint64_t dis_stamp                    : 1;  /**< Remove time stamps from data stream. */
 	uint64_t cap_ctl                      : 4;  /**< Minterms that will cause data to be captured. These minterms are the four inputs to a 4-1
                                                          mux selected by PLA1 and 0. The output is thus calulated from the equation:
-                                                         out = (    (<3> & PLA1 & PLA0)
-                                                         || (<2> & PLA1 & !PLA0)
-                                                         || (<1> & !PLA1 & PLA0)
-                                                         || (<0> & !PLA1 & !PLA0))
+                                                         fsmcap0 = OCLA(0..4)_FSM(0)_STATE[state0][CAP]
+                                                         fsmcap1 = OCLA(0..4)_FSM(1)_STATE[state1][CAP]
+                                                         out = (    (<3> & fsmcap0 & fsmcap0)
+                                                         || (<2> & fsmcap1 & !fsmcap0)
+                                                         || (<1> & !fsmcap1 & fsmcap0)
+                                                         || (<0> & !fsmcap1 & !fsmcap0))
                                                          Common examples:
                                                          0x0 = No capture
-                                                         0x2 = Capture when PLA0 requests capture
-                                                         0x4 = Capture when PLA1 requests capture
-                                                         0x6 = Capture on PLA0 | PLA1
-                                                         0x8 = Capture on PLA0 & PLA1
+                                                         0x2 = Capture when fsmcap0 requests capture
+                                                         0x4 = Capture when fsmcap1 requests capture
+                                                         0x6 = Capture on fsmcap0 | fsmcap1
+                                                         0x8 = Capture on fsmcap0 & fsmcap1
                                                          0xF = Always capture. */
 #else
 	uint64_t cap_ctl                      : 4;
@@ -480,7 +482,7 @@ union cvmx_oclax_const {
 	uint64_t reserved_16_63               : 48;
 	uint64_t dat_size                     : 16; /**< Size of data RAM in units of 36-bit entries. This value is subject to change between chip
                                                          passes, and software should thus use this value rather than a hard coded constant.
-                                                         OCLA(0..3) size is 8192, OCLA(4) size is 4096. */
+                                                         OCLA(0..3) size is 4096, OCLA(4) size is 8192. */
 #else
 	uint64_t dat_size                     : 16;
 	uint64_t reserved_16_63               : 48;
@@ -566,8 +568,9 @@ union cvmx_oclax_fifo_limit {
 	struct cvmx_oclax_fifo_limit_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t overfull                     : 16; /**< Stop level. When OCLA(0..4)_FIFO_DEPTH > OVERFULL, stop capturing and set
-                                                         OCLA(0..4)_STATE_INT[OVERFULL]. This should be set to just less than the FIFO size when
-                                                         using DDR capture to insure that overflow can be detected. */
+                                                         OCLA(0..4)_STATE_INT[OVERFULL]. This should be set to no more than
+                                                         OCLA(0..4)_CONST[DAT_SIZE] minus 26 when using DDR capture to insure that overflow can be
+                                                         detected. */
 	uint64_t ddr                          : 16; /**< DDR level. When OCLA(0..4)_FIFO_DEPTH > DDR, FIFO entries will be removed, packed into a
                                                          cache line, and overflowed to DDR/L2. All-ones disables overflow to DDR/L2. If non-zero
                                                          must be at least 28. */
@@ -615,7 +618,8 @@ union cvmx_oclax_fifo_trig {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
 	uint64_t limit                        : 16; /**< Post-trigger number of entries to collect before stopping collection. If zero, collection
-                                                         will never stop, which may be desirable when overflowing to DDR/L2. */
+                                                         will never stop, which may be desirable when overflowing to DDR/L2. Must be <
+                                                         OCLA(0..4)_CONST[DAT_SIZE] - 5. */
 	uint64_t cnt                          : 16; /**< Number of entries collected since trigger. Cleared when OCLA(0..4)_STATE_INT[TRIG] clear. */
 #else
 	uint64_t cnt                          : 16;
@@ -650,7 +654,7 @@ typedef union cvmx_oclax_fifo_wrap cvmx_oclax_fifo_wrap_t;
 /**
  * cvmx_ocla#_fsm#_and#_i#
  *
- * Values for PLA-AND plane. AND(0..31) represents the 32 allowed AND terms. I(0..1) for I=0
+ * Values for PLA-AND plane. AND(0..15) represents the 15 allowed AND terms. I(0..1) for I=0
  * indicates the term non-inverted, for I=1 indicates the term inverted. Any AND tree may be
  * disabled by setting the same bit in both _I(0) and _I(1), as '((1) & !(1))' is always false.
  */
@@ -751,9 +755,7 @@ union cvmx_oclax_gen_ctl {
                                                          signal to release the trigger (it is not edge sensitive.) */
 	uint64_t den                          : 1;  /**< Enable data bus and counter clocking. When set, the OCLA inbound data bus may be used and
                                                          counters may increment. When clear, the bus is always zero and internal flops may be clock
-                                                         gated off to save power. Must be set for normal operation. INTERNAL: When clear, RTL must
-                                                         assert that the data bus is zero, to make sure at full chip that no block is 'spamming'
-                                                         non-zero OCLA data after reset. */
+                                                         gated off to save power. Must be set for normal operation. */
 	uint64_t stt                          : 1;  /**< Store to DDR directly, bypassing L2 cache. */
 	uint64_t reserved_0_0                 : 1;
 #else
@@ -1049,8 +1051,8 @@ union cvmx_oclax_state_int {
                                                          holds FSM1 in state zero, writing one to OCLA(0..4)_STATE_INT[FSM1_RST] removes the hold. */
 	uint64_t fsm0_rst                     : 1;  /**< FSM0 hold in state zero. Writing one to OCLA(0..4)_STATE_SET[FSM0_RST] sets this bit and
                                                          holds FSM0 in state zero, writing one to OCLA(0..4)_STATE_INT[FSM0_RST] removes the hold. */
-	uint64_t fsm1_ena                     : 1;  /**< FSM1 sequencing and capturing enabled. */
-	uint64_t fsm0_ena                     : 1;  /**< FSM0 sequencing and capturing enabled. */
+	uint64_t fsm1_ena                     : 1;  /**< FSM1 sequencing enabled. */
+	uint64_t fsm0_ena                     : 1;  /**< FSM0 sequencing enabled. */
 	uint64_t reserved_19_31               : 13;
 	uint64_t ddrfull                      : 1;  /**< DDR buffer wrapped. Asserted when OCLA(0..4)_STACK_CUR has wrapped and been re-initialized
                                                          to OCLA(0..4)_STACK_BASE. */
diff --git a/arch/mips/include/asm/octeon/cvmx-ocx-defs.h b/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
index dcbff43..f3b26d3 100644
--- a/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -53,6 +53,17 @@
 #define __CVMX_OCX_DEFS_H__
 
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_OCX_COM_BIST_STATUS CVMX_OCX_COM_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_OCX_COM_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_OCX_COM_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800110000F0ull);
+}
+#else
+#define CVMX_OCX_COM_BIST_STATUS (CVMX_ADD_IO_SEG(0x00011800110000F0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_OCX_COM_DUAL_SORT CVMX_OCX_COM_DUAL_SORT_FUNC()
 static inline uint64_t CVMX_OCX_COM_DUAL_SORT_FUNC(void)
 {
@@ -130,6 +141,50 @@ static inline uint64_t CVMX_OCX_DLLX_STATUS(unsigned long offset)
 #define CVMX_OCX_DLLX_STATUS(offset) (CVMX_ADD_IO_SEG(0x0001180011000080ull) + ((offset) & 1) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_OCX_FRCX_STAT0(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 5)))))
+		cvmx_warn("CVMX_OCX_FRCX_STAT0(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x000118001100FA00ull) + ((offset) & 7) * 8;
+}
+#else
+#define CVMX_OCX_FRCX_STAT0(offset) (CVMX_ADD_IO_SEG(0x000118001100FA00ull) + ((offset) & 7) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_OCX_FRCX_STAT1(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 5)))))
+		cvmx_warn("CVMX_OCX_FRCX_STAT1(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x000118001100FA80ull) + ((offset) & 7) * 8;
+}
+#else
+#define CVMX_OCX_FRCX_STAT1(offset) (CVMX_ADD_IO_SEG(0x000118001100FA80ull) + ((offset) & 7) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_OCX_FRCX_STAT2(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 5)))))
+		cvmx_warn("CVMX_OCX_FRCX_STAT2(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x000118001100FB00ull) + ((offset) & 7) * 8;
+}
+#else
+#define CVMX_OCX_FRCX_STAT2(offset) (CVMX_ADD_IO_SEG(0x000118001100FB00ull) + ((offset) & 7) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_OCX_FRCX_STAT3(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 5)))))
+		cvmx_warn("CVMX_OCX_FRCX_STAT3(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x000118001100FB80ull) + ((offset) & 7) * 8;
+}
+#else
+#define CVMX_OCX_FRCX_STAT3(offset) (CVMX_ADD_IO_SEG(0x000118001100FB80ull) + ((offset) & 7) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_OCX_LNEX_BAD_CNT(unsigned long offset)
 {
 	if (!(
@@ -317,6 +372,28 @@ static inline uint64_t CVMX_OCX_LNEX_STAT12(unsigned long offset)
 #define CVMX_OCX_LNEX_STAT12(offset) (CVMX_ADD_IO_SEG(0x00011800110080A0ull) + ((offset) & 31) * 256)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_OCX_LNEX_STAT13(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 23)))))
+		cvmx_warn("CVMX_OCX_LNEX_STAT13(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800110080A8ull) + ((offset) & 31) * 256;
+}
+#else
+#define CVMX_OCX_LNEX_STAT13(offset) (CVMX_ADD_IO_SEG(0x00011800110080A8ull) + ((offset) & 31) * 256)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_OCX_LNEX_STAT14(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 23)))))
+		cvmx_warn("CVMX_OCX_LNEX_STAT14(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800110080B0ull) + ((offset) & 31) * 256;
+}
+#else
+#define CVMX_OCX_LNEX_STAT14(offset) (CVMX_ADD_IO_SEG(0x00011800110080B0ull) + ((offset) & 31) * 256)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_OCX_LNEX_STATUS(unsigned long offset)
 {
 	if (!(
@@ -474,7 +551,7 @@ static inline uint64_t CVMX_OCX_RLKX_ENABLES(unsigned long offset)
 static inline uint64_t CVMX_OCX_RLKX_FIFOX_CNT(unsigned long offset, unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 12)) && ((block_id <= 2))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 13)) && ((block_id <= 2))))))
 		cvmx_warn("CVMX_OCX_RLKX_FIFOX_CNT(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180011018100ull) + (((offset) & 15) + ((block_id) & 3) * 0x400ull) * 8;
 }
@@ -504,6 +581,17 @@ static inline uint64_t CVMX_OCX_RLKX_MCD_CTL(unsigned long offset)
 #define CVMX_OCX_RLKX_MCD_CTL(offset) (CVMX_ADD_IO_SEG(0x0001180011018020ull) + ((offset) & 3) * 8192)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_OCX_TLKX_BIST_STATUS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 2)))))
+		cvmx_warn("CVMX_OCX_TLKX_BIST_STATUS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001180011010008ull) + ((offset) & 3) * 8192;
+}
+#else
+#define CVMX_OCX_TLKX_BIST_STATUS(offset) (CVMX_ADD_IO_SEG(0x0001180011010008ull) + ((offset) & 3) * 8192)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_OCX_TLKX_ECC_CTL(unsigned long offset)
 {
 	if (!(
@@ -518,7 +606,7 @@ static inline uint64_t CVMX_OCX_TLKX_ECC_CTL(unsigned long offset)
 static inline uint64_t CVMX_OCX_TLKX_FIFOX_CNT(unsigned long offset, unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 12)) && ((block_id <= 2))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 13)) && ((block_id <= 2))))))
 		cvmx_warn("CVMX_OCX_TLKX_FIFOX_CNT(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180011010100ull) + (((offset) & 15) + ((block_id) & 3) * 0x400ull) * 8;
 }
@@ -540,7 +628,7 @@ static inline uint64_t CVMX_OCX_TLKX_LNK_DATA(unsigned long offset)
 static inline uint64_t CVMX_OCX_TLKX_LNK_VCX_CNT(unsigned long offset, unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 12)) && ((block_id <= 2))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 13)) && ((block_id <= 2))))))
 		cvmx_warn("CVMX_OCX_TLKX_LNK_VCX_CNT(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180011010200ull) + (((offset) & 15) + ((block_id) & 3) * 0x400ull) * 8;
 }
@@ -562,7 +650,7 @@ static inline uint64_t CVMX_OCX_TLKX_MCD_CTL(unsigned long offset)
 static inline uint64_t CVMX_OCX_TLKX_RTN_VCX_CNT(unsigned long offset, unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 12)) && ((block_id <= 2))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 13)) && ((block_id <= 2))))))
 		cvmx_warn("CVMX_OCX_TLKX_RTN_VCX_CNT(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180011010300ull) + (((offset) & 15) + ((block_id) & 3) * 0x400ull) * 8;
 }
@@ -683,7 +771,7 @@ static inline uint64_t CVMX_OCX_TLKX_STAT_VCX_CMD(unsigned long offset, unsigned
 static inline uint64_t CVMX_OCX_TLKX_STAT_VCX_CON(unsigned long offset, unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 12)) && ((block_id <= 2))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 13)) && ((block_id <= 2))))))
 		cvmx_warn("CVMX_OCX_TLKX_STAT_VCX_CON(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180011010580ull) + (((offset) & 15) + ((block_id) & 3) * 0x400ull) * 8;
 }
@@ -694,7 +782,7 @@ static inline uint64_t CVMX_OCX_TLKX_STAT_VCX_CON(unsigned long offset, unsigned
 static inline uint64_t CVMX_OCX_TLKX_STAT_VCX_PKT(unsigned long offset, unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 12)) && ((block_id <= 2))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 13)) && ((block_id <= 2))))))
 		cvmx_warn("CVMX_OCX_TLKX_STAT_VCX_PKT(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180011010500ull) + (((offset) & 15) + ((block_id) & 3) * 0x400ull) * 8;
 }
@@ -747,6 +835,45 @@ static inline uint64_t CVMX_OCX_WIN_WR_DATA_FUNC(void)
 #endif
 
 /**
+ * cvmx_ocx_com_bist_status
+ *
+ * Contains Status from last Memory BIST for all RX FIFO Memories.  BIST status for TX FIFO
+ * Memories
+ * and REPLAY Memories are organized by link and are located in OCX_TLK(0..2)_BIST_STATUS.
+ */
+union cvmx_ocx_com_bist_status {
+	uint64_t u64;
+	struct cvmx_ocx_com_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t status                       : 36; /**< 35:34 - Link 2 VC4/VC2      RX FIFOs
+                                                         - 33:32 - Link 2 VC10/VC8/VC6 RX FIFOs
+                                                         - 31:30 - Link 1 VC4/VC2      RX FIFOs
+                                                         - 29:28 - Link 1 VC10/VC8/VC6 RX FIFOs
+                                                         - 27:26 - Link 0 VC4/VC2      RX FIFOs
+                                                         - 25:24 - Link 0 VC10/VC8/VC6 RX FIFOs
+                                                         - 23:22 - Link 2 VC12         RX FIFOs
+                                                         - 21:20 - Link 2 VC1/VC0      RX FIFOs
+                                                         - 19:18 - Link 2 VC5/VC3      RX FIFOs
+                                                         - 17:16 - Link 2 VC11/VC9/VC7 RX FIFOs
+                                                         - 15:14 - Link 1 VC12         RX FIFOs
+                                                         - 13:12 - Link 1 VC1/VC0      RX FIFOs
+                                                         - 11:10 - Link 1 VC5/VC3      RX FIFOs
+                                                         - 9: 8 - Link 1 VC11/VC9/VC7 RX FIFOs
+                                                         - 7: 6 - Link 0 VC12         RX FIFOs
+                                                         - 5: 4 - Link 0 VC1/VC0      RX FIFOs
+                                                         - 3: 2 - Link 0 VC5/VC3      RX FIFOs
+                                                         - 1: 0 - Link 0 VC11/VC9/VC7 RX FIFOs */
+#else
+	uint64_t status                       : 36;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_ocx_com_bist_status_s     cn78xx;
+};
+typedef union cvmx_ocx_com_bist_status cvmx_ocx_com_bist_status_t;
+
+/**
  * cvmx_ocx_com_dual_sort
  */
 union cvmx_ocx_com_dual_sort {
@@ -775,19 +902,27 @@ union cvmx_ocx_com_int {
 	struct cvmx_ocx_com_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_55_63               : 9;
-	uint64_t io_badid                     : 1;  /**< I/O request or response cannot be send because Node ID is invalid. Transaction has been dropped. */
-	uint64_t mem_badid                    : 1;  /**< Memory request or response cannot be send because Node ID is invalid. Transaction has been dropped. */
-	uint64_t copr_badid                   : 1;  /**< Scheduler add work or buffer pool return cannot be sent because Node ID is invalid.
-                                                         Transaction has been dropped. */
-	uint64_t win_req_badid                : 1;  /**< Window request specified in SLI_WIN_RD_ADDR, SLI_WIN_WR_ADDR or OCX_PP_CMD cannot be sent
-                                                         because Node ID is invalid. Transaction has been dropped. */
-	uint64_t win_req_tout                 : 1;  /**< Window request was dropped because it could not be send during the period specified by
-                                                         OCX_WIN_TIMER. */
-	uint64_t win_req_xmit                 : 1;  /**< Window request specified in SLI_WIN_RD_ADDR, SLI_WIN_WR_ADDR or OCX_WIN_CMD has been
-                                                         scheduled for transmission. If the command was not expecting a response, then a new
-                                                         command may be issued. */
-	uint64_t win_rsp                      : 1;  /**< A response to a previous SLI window request or core request has been received. A new
-                                                         command may be issued. */
+	uint64_t io_badid                     : 1;  /**< I/O request or response cannot be sent because a link was not found with a packet Node ID
+                                                         matching the OCX_COM_LINK(0..2)_CTL[ID]
+                                                         with OCX_COM_LINK(0..2)_CTL[VALID] bit set. Transaction has been dropped. */
+	uint64_t mem_badid                    : 1;  /**< Memory request or response cannot be send because a link was not found with a packet Node
+                                                         ID matching the OCX_COM_LINK(0..2)_CTL[ID]
+                                                         with OCX_COM_LINK(0..2)_CTL[VALID] bit set. Transaction has been dropped. */
+	uint64_t copr_badid                   : 1;  /**< Scheduler add work or buffer pool return cannot be sent because a link was not found with
+                                                         a Node ID matching the
+                                                         OCX_COM_LINK(0..2)_CTL[ID] with OCX_COM_LINK(0..2)_CTL[VALID] bit set.  Transaction has
+                                                         been dropped. */
+	uint64_t win_req_badid                : 1;  /**< Window request specified in SLI_WIN_RD_ADDR, SLI_WIN_WR_ADDR, OCX_WIN_CMD or OCX_PP_CMD
+                                                         cannot be sent because a link was not found with a request Node ID matching the
+                                                         OCX_COM_LINK(0..2)_CTL[ID]
+                                                         with OCX_COM_LINK(0..2)_CTL[VALID] bit set.  Transaction has been dropped. */
+	uint64_t win_req_tout                 : 1;  /**< Window or core request was dropped because it could not be send during the period
+                                                         specified by OCX_WIN_TIMER. */
+	uint64_t win_req_xmit                 : 1;  /**< Window request specified in SLI_WIN_RD_ADDR, SLI_WIN_WR_ADDR, OCX_WIN_CMD or OCX_PP_CMD
+                                                         has been scheduled for transmission. If the command was not expecting a response, then a
+                                                         new command may be issued. */
+	uint64_t win_rsp                      : 1;  /**< A response to a previous window request or core request has been received. A new command
+                                                         may be issued. */
 	uint64_t reserved_24_47               : 24;
 	uint64_t rx_lane                      : 24; /**< SerDes RX lane interrupt. See OCX_LNE_STATUS[23..0] for more information. */
 #else
@@ -814,7 +949,10 @@ union cvmx_ocx_com_linkx_ctl {
 	uint64_t u64;
 	struct cvmx_ocx_com_linkx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_8_63                : 56;
+	uint64_t reserved_9_63                : 55;
+	uint64_t loopback                     : 1;  /**< Reserved. INTERNAL: Diagnostic data loopback.Set to force outgoing link to inbound port.
+                                                         All data and link credits are returned and appear to come from link partner. Typically
+                                                         SERDES should be disabled during this operation. */
 	uint64_t reinit                       : 1;  /**< Reinitialize Link. Setting bit forces link back into init state and also sets DROP bit.
                                                          Bit must be cleared for link to operate normally. */
 	uint64_t gate                         : 1;  /**< Enable clock gating on this link to save power. */
@@ -822,9 +960,10 @@ union cvmx_ocx_com_linkx_ctl {
                                                          software wishes to manage deassertion of DROP. */
 	uint64_t drop                         : 1;  /**< Drop all requests on given link. Typically set by hardware when link has failed or been
                                                          reinitialized. Cleared by software once pending link traffic is removed. (See
-                                                         OCX_TLK[0..2]_FIFO[0..12]_CNT.) */
+                                                         OCX_TLK[0..2]_FIFO[0..13]_CNT.) */
 	uint64_t up                           : 1;  /**< Link is operating normally. */
-	uint64_t valid                        : 1;  /**< Link has valid lanes and is exchanging information. */
+	uint64_t valid                        : 1;  /**< Link has valid lanes and is exchanging information.  This bit will never be set if
+                                                         OCX_LNK(0..2)_CFG[QLM_SELECT] is zero. */
 	uint64_t id                           : 2;  /**< This ID is used to sort traffic by link. If more than one link has the same value, the
                                                          OCX_COM_DUAL_SORT[SORT] field and traffic VC are used to choose a link. This field is only
                                                          reset during a cold reset to an arbitrary value to avoid conflicts with the
@@ -838,7 +977,8 @@ union cvmx_ocx_com_linkx_ctl {
 	uint64_t auto_clr                     : 1;
 	uint64_t gate                         : 1;
 	uint64_t reinit                       : 1;
-	uint64_t reserved_8_63                : 56;
+	uint64_t loopback                     : 1;
+	uint64_t reserved_9_63                : 55;
 #endif
 	} s;
 	struct cvmx_ocx_com_linkx_ctl_s       cn78xx;
@@ -922,14 +1062,19 @@ union cvmx_ocx_com_node {
 	uint64_t fixed_pin                    : 1;  /**< The current value of the OCI_FIXED_ID pin. */
 	uint64_t fixed                        : 1;  /**< ID Valid associated with the chip. This register is used by the link initialization
                                                          software to help assign IDs and is transmitted over OCI. The FIXED field set during a cold
-                                                         reset to the value of the OCI_FIXED_ID pin. The value should also be readable in the
-                                                         OCX_LNE(0..23)_CFG[RX_META_DAT] on the corresponding link of the partner. */
+                                                         reset to the value of the OCI_FIXED_ID pin. The value is also be readable in the
+                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT[2]] for each lane.
+                                                         The FIXED field of the link partner can be examined by locally reading the
+                                                         OCX_LNE(0..23)_STS_MSG[RX_META_DAT[2]] on each valid lane or remotely reading the
+                                                         OCX_COM_NODE[FIXED] on the link partner. */
 	uint64_t id                           : 2;  /**< Node ID associated with the chip. This register is used by the rest of the chip to
                                                          determine what traffic is transmitted over OCI. The value should not match the
                                                          OCX_COM_LINK(0..2)_CTL[ID] of any active link. The ID field is set during a cold reset to
-                                                         the value of the OCI_NODE_ID pins. The value should be readable in the
-                                                         OCX_LNE(0..23)_CFG[RX_META_DAT] on the corresponding link of the partner. It can be
-                                                         changed as long as no traffic is being transferred. */
+                                                         the value of the OCI_NODE_ID pins. The value is also be readable in the
+                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT[1:0]] for each lane.
+                                                         The ID field of the link partner can be examined by locally reading the
+                                                         OCX_LNE(0..23)_STS_MSG[RX_META_DAT[1:0]] on each valid lane or remotely reading the
+                                                         OCX_COM_NODE[ID] on the link partner. */
 #else
 	uint64_t id                           : 2;
 	uint64_t fixed                        : 1;
@@ -978,6 +1123,80 @@ union cvmx_ocx_dllx_status {
 typedef union cvmx_ocx_dllx_status cvmx_ocx_dllx_status_t;
 
 /**
+ * cvmx_ocx_frc#_stat0
+ */
+union cvmx_ocx_frcx_stat0 {
+	uint64_t u64;
+	struct cvmx_ocx_frcx_stat0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_21_63               : 43;
+	uint64_t align_cnt                    : 21; /**< Indicates the number of alignment sequences received (i.e. those that do not violate the
+                                                         current alignment). */
+#else
+	uint64_t align_cnt                    : 21;
+	uint64_t reserved_21_63               : 43;
+#endif
+	} s;
+	struct cvmx_ocx_frcx_stat0_s          cn78xx;
+};
+typedef union cvmx_ocx_frcx_stat0 cvmx_ocx_frcx_stat0_t;
+
+/**
+ * cvmx_ocx_frc#_stat1
+ */
+union cvmx_ocx_frcx_stat1 {
+	uint64_t u64;
+	struct cvmx_ocx_frcx_stat1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_21_63               : 43;
+	uint64_t align_err_cnt                : 21; /**< Indicates the number of alignment sequences received in error (i.e. those that violate the
+                                                         current alignment). */
+#else
+	uint64_t align_err_cnt                : 21;
+	uint64_t reserved_21_63               : 43;
+#endif
+	} s;
+	struct cvmx_ocx_frcx_stat1_s          cn78xx;
+};
+typedef union cvmx_ocx_frcx_stat1 cvmx_ocx_frcx_stat1_t;
+
+/**
+ * cvmx_ocx_frc#_stat2
+ */
+union cvmx_ocx_frcx_stat2 {
+	uint64_t u64;
+	struct cvmx_ocx_frcx_stat2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_21_63               : 43;
+	uint64_t align_done                   : 21; /**< Indicates the number of attempt at alignment that succeeded. */
+#else
+	uint64_t align_done                   : 21;
+	uint64_t reserved_21_63               : 43;
+#endif
+	} s;
+	struct cvmx_ocx_frcx_stat2_s          cn78xx;
+};
+typedef union cvmx_ocx_frcx_stat2 cvmx_ocx_frcx_stat2_t;
+
+/**
+ * cvmx_ocx_frc#_stat3
+ */
+union cvmx_ocx_frcx_stat3 {
+	uint64_t u64;
+	struct cvmx_ocx_frcx_stat3_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_21_63               : 43;
+	uint64_t align_fail                   : 21; /**< Indicates the number of attempt at alignment that failed. */
+#else
+	uint64_t align_fail                   : 21;
+	uint64_t reserved_21_63               : 43;
+#endif
+	} s;
+	struct cvmx_ocx_frcx_stat3_s          cn78xx;
+};
+typedef union cvmx_ocx_frcx_stat3 cvmx_ocx_frcx_stat3_t;
+
+/**
  * cvmx_ocx_lne#_bad_cnt
  */
 union cvmx_ocx_lnex_bad_cnt {
@@ -1036,7 +1255,8 @@ union cvmx_ocx_lnex_int {
 	uint64_t u64;
 	struct cvmx_ocx_lnex_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
+	uint64_t reserved_10_63               : 54;
+	uint64_t disp_err                     : 1;  /**< RX disparity error encountered. */
 	uint64_t bad_64b67b                   : 1;  /**< Bad 64B/67B codeword encountered. Once the bad word reaches the burst control unit, as
                                                          denoted by OCX_RXx_INT[LANE_BAD_WORD], it is tossed and all open packets will receive an
                                                          error. */
@@ -1059,7 +1279,8 @@ union cvmx_ocx_lnex_int {
 	uint64_t stat_msg                     : 1;
 	uint64_t stat_cnt_ovfl                : 1;
 	uint64_t bad_64b67b                   : 1;
-	uint64_t reserved_9_63                : 55;
+	uint64_t disp_err                     : 1;
+	uint64_t reserved_10_63               : 54;
 #endif
 	} s;
 	struct cvmx_ocx_lnex_int_s            cn78xx;
@@ -1350,19 +1571,57 @@ union cvmx_ocx_lnex_stat12 {
 typedef union cvmx_ocx_lnex_stat12 cvmx_ocx_lnex_stat12_t;
 
 /**
+ * cvmx_ocx_lne#_stat13
+ */
+union cvmx_ocx_lnex_stat13 {
+	uint64_t u64;
+	struct cvmx_ocx_lnex_stat13_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t trn_bad_cnt                  : 16; /**< N/A */
+#else
+	uint64_t trn_bad_cnt                  : 16;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_ocx_lnex_stat13_s         cn78xx;
+};
+typedef union cvmx_ocx_lnex_stat13 cvmx_ocx_lnex_stat13_t;
+
+/**
+ * cvmx_ocx_lne#_stat14
+ */
+union cvmx_ocx_lnex_stat14 {
+	uint64_t u64;
+	struct cvmx_ocx_lnex_stat14_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t trn_prbs_bad_cnt             : 16; /**< N/A */
+#else
+	uint64_t trn_prbs_bad_cnt             : 16;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_ocx_lnex_stat14_s         cn78xx;
+};
+typedef union cvmx_ocx_lnex_stat14 cvmx_ocx_lnex_stat14_t;
+
+/**
  * cvmx_ocx_lne#_status
  */
 union cvmx_ocx_lnex_status {
 	uint64_t u64;
 	struct cvmx_ocx_lnex_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_2_63                : 62;
+	uint64_t reserved_3_63                : 61;
+	uint64_t rx_trn_val                   : 1;  /**< The control channel of a link training was recieved without any errors. */
 	uint64_t rx_scrm_sync                 : 1;  /**< RX scrambler synchronization status. One when synchronization achieved. */
 	uint64_t rx_bdry_sync                 : 1;  /**< RX word boundary sync status. One when synchronization achieved. */
 #else
 	uint64_t rx_bdry_sync                 : 1;
 	uint64_t rx_scrm_sync                 : 1;
-	uint64_t reserved_2_63                : 62;
+	uint64_t rx_trn_val                   : 1;
+	uint64_t reserved_3_63                : 61;
 #endif
 	} s;
 	struct cvmx_ocx_lnex_status_s         cn78xx;
@@ -1466,7 +1725,8 @@ union cvmx_ocx_lne_dbg {
 	uint64_t u64;
 	struct cvmx_ocx_lne_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_37_63               : 27;
+	uint64_t reserved_38_63               : 26;
+	uint64_t frc_stats_ena                : 1;  /**< Enable FRC statistic counters. */
 	uint64_t rx_dis_psh_skip              : 1;  /**< When RX_DIS_PSH_SKIP=0, skip words are de-stripped. When RX_DIS_PSH_SKIP=1, skip words are
                                                          discarded in the lane logic. If the lane is in internal loopback mode, RX_DIS_PSH_SKIP is
                                                          ignored and skip words are always discarded in the lane logic. */
@@ -1501,7 +1761,8 @@ union cvmx_ocx_lne_dbg {
 	uint64_t rx_dis_ukwn                  : 1;
 	uint64_t rx_mfrm_len                  : 2;
 	uint64_t rx_dis_psh_skip              : 1;
-	uint64_t reserved_37_63               : 27;
+	uint64_t frc_stats_ena                : 1;
+	uint64_t reserved_38_63               : 26;
 #endif
 	} s;
 	struct cvmx_ocx_lne_dbg_s             cn78xx;
@@ -1529,7 +1790,9 @@ union cvmx_ocx_lnkx_cfg {
                                                          LINK 0 may not select QLM4, QLM5.
                                                          LINK 1 may not select QLM0, QLM1, QLM4, QLM5.
                                                          LINK 2 may not select QLM0, QLM1.
-                                                         This field is initialized using the OCI_SPD pins during a cold reset.
+                                                         During a cold reset, this field is initialized to 0x3f when pi_oci_spd == 0xf.
+                                                         During a cold reset, this field is initialized to 0x0  when pi_oci_spd != 0xf.
+                                                         This field is not modified by hardware at any other time.
                                                          This field is not affected by soft or warm reset. */
 	uint64_t reserved_38_47               : 10;
 	uint64_t qlm_select                   : 6;  /**< QLM select mask, where each bit corresponds to a QLM. A link will transmit/receive data
@@ -1544,7 +1807,17 @@ union cvmx_ocx_lnkx_cfg {
                                                          QLM_SELECT<5> = LNE(23..23) = QLM5.
                                                          LINK 0 may not select QLM4, QLM5.
                                                          LINK 1 may not select QLM0, QLM1, QLM4, QLM5.
-                                                         LINK 2 may not select QLM0, QLM1. */
+                                                         LINK 2 may not select QLM0, QLM1.
+                                                         LINK 0 automatically selects QLM0 when QLM_MANUAL[0]=0
+                                                         LINK 0 automatically selects QLM1 when QLM_MANUAL[1]=0
+                                                         LINK 0 automatically selects QLM2 when QLM_MANUAL[2]=0 and OCX_QLM2_CFG.SER_LOCAL=0
+                                                         LINK 1 automatically selects QLM2 when QLM_MANUAL[2]=0 and OCX_QLM2_CFG.SER_LOCAL=1
+                                                         LINK 1 automatically selects QLM3 when QLM_MANUAL[3]=0 and OCX_QLM3_CFG.SER_LOCAL=1
+                                                         LINK 2 automatically selects QLM3 when QLM_MANUAL[3]=0 and OCX_QLM3_CFG.SER_LOCAL=0
+                                                         LINK 3 automatically selects QLM4 when QLM_MANUAL[4]=0
+                                                         LINK 3 automatically selects QLM5 when QLM_MANUAL[5]=0
+                                                         NOTE:  A link with QLM_SELECT = 000000 is invalid and will never exchange traffic with the
+                                                         link partner */
 	uint64_t reserved_10_31               : 22;
 	uint64_t lane_align_dis               : 1;  /**< Disable the RX lane alignment. */
 	uint64_t lane_rev                     : 1;  /**< RX lane reversal.   When enabled, lane de-striping is performed from the most significant
@@ -1661,7 +1934,9 @@ union cvmx_ocx_qlmx_cfg {
 	uint64_t u64;
 	struct cvmx_ocx_qlmx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_26_63               : 38;
+	uint64_t reserved_42_63               : 22;
+	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes. */
+	uint64_t reserved_26_31               : 6;
 	uint64_t timer_dis                    : 1;  /**< Disable bad lane timer. A timer counts core clocks (RCLKs) when any enabled lane is not
                                                          ready, i.e. not in the scrambler sync state. If this timer expires before all enabled
                                                          lanes can be made ready, then any lane which is not ready is disabled via
@@ -1669,7 +1944,7 @@ union cvmx_ocx_qlmx_cfg {
 	uint64_t trn_ena                      : 1;  /**< Link training enable. Link training is performed during auto link bring up. Initialized to
                                                          1 during cold reset when OCI_SPD<3:0> pins indicate speed > 6.25 GBAUD. Otherwise,
                                                          initialized to 0 during a cold reset. This field is not affected by soft or warm reset. */
-	uint64_t reserved_20_23               : 4;
+	uint64_t ser_lane_ready               : 4;  /**< SerDes lanes that are ready for bundling into the link. */
 	uint64_t ser_lane_bad                 : 4;  /**< SerDes lanes excluded from use. */
 	uint64_t reserved_7_15                : 9;
 	uint64_t ser_lane_rev                 : 1;  /**< SerDes lane reversal has been detected. */
@@ -1694,8 +1969,8 @@ union cvmx_ocx_qlmx_cfg {
                                                          QLM4/5 can only participate in LNK2; therefore
                                                          OCX_QLM4/5_CFG[SER_LOCAL] has no effect.
                                                          During a cold reset, initialized as follows:
-                                                         OCX_QLM2_CFG.SER_LOCAL = pi_qlm_local[0]
-                                                         OCX_QLM3_CFG.SER_LOCAL = pi_qlm_local[1] */
+                                                         OCX_QLM2_CFG.SER_LOCAL = pi_oci2_link1
+                                                         OCX_QLM3_CFG.SER_LOCAL = pi_oci3_link1 */
 #else
 	uint64_t ser_local                    : 1;
 	uint64_t reserved_1_2                 : 2;
@@ -1705,10 +1980,12 @@ union cvmx_ocx_qlmx_cfg {
 	uint64_t ser_lane_rev                 : 1;
 	uint64_t reserved_7_15                : 9;
 	uint64_t ser_lane_bad                 : 4;
-	uint64_t reserved_20_23               : 4;
+	uint64_t ser_lane_ready               : 4;
 	uint64_t trn_ena                      : 1;
 	uint64_t timer_dis                    : 1;
-	uint64_t reserved_26_63               : 38;
+	uint64_t reserved_26_31               : 6;
+	uint64_t ser_limit                    : 10;
+	uint64_t reserved_42_63               : 22;
 #endif
 	} s;
 	struct cvmx_ocx_qlmx_cfg_s            cn78xx;
@@ -1791,7 +2068,10 @@ union cvmx_ocx_rlkx_enables {
 	struct cvmx_ocx_rlkx_enables_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t mcd                          : 1;  /**< Master enable for all inbound MCD bits. This bit must be enabled by software. */
+	uint64_t mcd                          : 1;  /**< Master enable for all inbound MCD bits. This bit should always be enabled by software once
+                                                         any
+                                                         Authentik validation has occured and before any MCD traffic is generated.  MCD traffic is
+                                                         typically controlled by the OCX_TLK(0..2)_MCD_CTL register. */
 	uint64_t m_req                        : 1;  /**< Master enable for all inbound memory requests. This bit is typically set at reset but is
                                                          cleared when operating in Authentik mode and must be enabled by software. */
 	uint64_t io_req                       : 1;  /**< Master enable for all inbound I/O Requests. This bit is typically set at reset but is
@@ -1821,7 +2101,8 @@ union cvmx_ocx_rlkx_fifox_cnt {
 	struct cvmx_ocx_rlkx_fifox_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t count                        : 16; /**< RX FIFO count of 64-bit words to send to core. */
+	uint64_t count                        : 16; /**< RX FIFO count of 64-bit words to send to core.  VC13 traffic is used immediately so
+                                                         the FIFO count is always 0. (see OCX_RLK(0..2)_LNK_DATA) */
 #else
 	uint64_t count                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1855,6 +2136,11 @@ typedef union cvmx_ocx_rlkx_lnk_data cvmx_ocx_rlkx_lnk_data_t;
 
 /**
  * cvmx_ocx_rlk#_mcd_ctl
+ *
+ * This debug register captures which new MCD bits have been received from the link partner.  The
+ * MCD bits are
+ * received when the both the OCX_RLK(0..2)_ENABLES[MCD] bit is set and the MCD was not
+ * previously transmitted.
  */
 union cvmx_ocx_rlkx_mcd_ctl {
 	uint64_t u64;
@@ -1873,6 +2159,29 @@ union cvmx_ocx_rlkx_mcd_ctl {
 typedef union cvmx_ocx_rlkx_mcd_ctl cvmx_ocx_rlkx_mcd_ctl_t;
 
 /**
+ * cvmx_ocx_tlk#_bist_status
+ *
+ * Contains Status from last Memory BIST for all TX FIFO Memories and REPLAY Memories in this
+ * link.
+ * RX FIFO Status can be found in OCX_COM_BIST_STATUS
+ */
+union cvmx_ocx_tlkx_bist_status {
+	uint64_t u64;
+	struct cvmx_ocx_tlkx_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_15_63               : 49;
+	uint64_t status                       : 15; /**< "14:13 - REPLAY Memories BIST Status [1:0]
+                                                         - 12:0  - TX_FIFO[12:0] by Link VC#" */
+#else
+	uint64_t status                       : 15;
+	uint64_t reserved_15_63               : 49;
+#endif
+	} s;
+	struct cvmx_ocx_tlkx_bist_status_s    cn78xx;
+};
+typedef union cvmx_ocx_tlkx_bist_status cvmx_ocx_tlkx_bist_status_t;
+
+/**
  * cvmx_ocx_tlk#_ecc_ctl
  */
 union cvmx_ocx_tlkx_ecc_ctl {
@@ -1947,7 +2256,7 @@ union cvmx_ocx_tlkx_lnk_vcx_cnt {
 	struct cvmx_ocx_tlkx_lnk_vcx_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t count                        : 16; /**< Link VC credits available for use. */
+	uint64_t count                        : 16; /**< Link VC credits available for use.  VC13 always reads 1 since credits are not required. */
 #else
 	uint64_t count                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1959,6 +2268,13 @@ typedef union cvmx_ocx_tlkx_lnk_vcx_cnt cvmx_ocx_tlkx_lnk_vcx_cnt_t;
 
 /**
  * cvmx_ocx_tlk#_mcd_ctl
+ *
+ * This register controls which MCD bits are transported via the link. For proper operation
+ * only one link must be enabled in both directions between each pair of link partners.
+ * Internal:  If N chips are connected over OCX, N-1 links should have MCD enabled.
+ * A single "central" chip should connect all MCD buses and have a single MCD enabled link
+ * to each of the other chips.  No MCD enabled links should connect between chips that don't
+ * include the "central" chip.
  */
 union cvmx_ocx_tlkx_mcd_ctl {
 	uint64_t u64;
@@ -1983,7 +2299,7 @@ union cvmx_ocx_tlkx_rtn_vcx_cnt {
 	struct cvmx_ocx_tlkx_rtn_vcx_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t count                        : 16; /**< Link VC credits to return. */
+	uint64_t count                        : 16; /**< Link VC credits to return.  VC13 always reads 0 since credits are never returned. */
 #else
 	uint64_t count                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2146,8 +2462,9 @@ union cvmx_ocx_tlkx_stat_vcx_cmd {
 	uint64_t u64;
 	struct cvmx_ocx_tlkx_stat_vcx_cmd_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t count                        : 64; /**< Number of blocks received with an error over the OCI link while
-                                                         OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+	uint64_t count                        : 64; /**< Number of commands on this VC that have been transfered over the OCI link while
+                                                         OCX_TLK(a)_STAT_CTL[ENABLE] has been set.  For VCs 6 thru 13 the number of commands is
+                                                         equal to the number of packets. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2164,7 +2481,8 @@ union cvmx_ocx_tlkx_stat_vcx_con {
 	struct cvmx_ocx_tlkx_stat_vcx_con_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t count                        : 64; /**< Number of conflicts on this VC while OCX_TLK(a)_STAT_CTL[ENABLE] has been set. A conflict
-                                                         is indicated when a VC has one or more packets to send and no link credits are available. */
+                                                         is indicated when a VC has one or more packets to send and no link credits are available.
+                                                         VC13 does not require credits so no conflicts are ever indicated (ie. reads 0). */
 #else
 	uint64_t count                        : 64;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-osm-defs.h b/arch/mips/include/asm/octeon/cvmx-osm-defs.h
index d17e28d..bb4c364 100644
--- a/arch/mips/include/asm/octeon/cvmx-osm-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-osm-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -138,21 +138,21 @@ union cvmx_osm_ase_rate_limit_ctrl {
 	struct cvmx_osm_ase_rate_limit_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t rwc_rate_limit               : 1;  /**< To support ASE running at SCLK/2, OSM can rate-limit
-                                                         responses sent back to ASE. Each request is assigned to either phase 0 or phase 1.
-                                                         When set, OSM will not send back-to-back responses for requests
-                                                         with the same phase. Instead a idle cycle will be inserted between the responses.
-                                                         This enable applies to RWC ports. */
-	uint64_t bwc_rate_limit               : 1;  /**< To support ASE running at SCLK/2, OSM can rate-limit
-                                                         responses sent back to ASE. Each request is assigned to either phase 0 or phase 1.
-                                                         When set, OSM will not send back-to-back responses for requests
-                                                         with the same phase. Instead a idle cycle will be inserted between the responses.
-                                                         This enable applies to BWC port. */
-	uint64_t twc_rate_limit               : 1;  /**< To support ASE running at SCLK/2, OSM can rate-limit
-                                                         responses sent back to ASE. Each request is assigned to either phase 0 or phase 1.
-                                                         When set, OSM will not send back-to-back responses for requests
-                                                         with the same phase. Instead a idle cycle will be inserted between the responses.
-                                                         This enable applies to TWC port. */
+	uint64_t rwc_rate_limit               : 1;  /**< Reserved. INTERNAL: Must be enabled when ASE is running at SCLK/2. If ASE is running at
+                                                         SCLK/1, this should be disabled for best performance. Mechanism: Each request is assigned
+                                                         to either phase 0 or phase 1. When feature is enabled, OSM does not send back-to-back
+                                                         responses for requests on the RWC ports with the same phase. Instead, a idle cycle is
+                                                         inserted between the responses. This enable applies to RWC ports. */
+	uint64_t bwc_rate_limit               : 1;  /**< Reserved. INTERNAL: Must be enabled when ASE is running at SCLK/2. If ASE is running at
+                                                         SCLK/1, this should be disabled for best performance. Mechanism: Each request is assigned
+                                                         to either phase 0 or phase 1. When feature is enabled, OSM does not send back-to-back
+                                                         responses for requests on the RWC ports with the same phase. Instead, a idle cycle is
+                                                         inserted between the responses. This enable applies to BWC ports. */
+	uint64_t twc_rate_limit               : 1;  /**< Reserved. INTERNAL: Must be enabled when ASE is running at SCLK/2. If ASE is running at
+                                                         SCLK/1, this should be disabled for best performance. Mechanism: Each request is assigned
+                                                         to either phase 0 or phase 1. When feature is enabled, OSM does not send back-to-back
+                                                         responses for requests on the RWC ports with the same phase. Instead, a idle cycle is
+                                                         inserted between the responses. This enable applies to TWC ports. */
 #else
 	uint64_t twc_rate_limit               : 1;
 	uint64_t bwc_rate_limit               : 1;
@@ -172,24 +172,20 @@ union cvmx_osm_bankx_ctrl {
 	struct cvmx_osm_bankx_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t bank_assign                  : 3;  /**< See BANK_ASSIGN_E enumeration for encoding.
-                                                         Port assignment for each memory bank. Memory structure is
-                                                         64k words x 246 data bits (plus ECC). This is further
-                                                         divided into 64 banks each containing 1k words x 246 data bits.
-                                                         A bank can only support one access per cycle, this is implemented
-                                                         by assigning each bank to a specific requester. Most requesters can
-                                                         only make one request per cycle so that mostly solves the problem.
-                                                         RWC is the only requester that can make multiple requests per cycle
-                                                         and will need to implement its own bank-aware scheduler to prevent
-                                                         bank conflicts. Bank assignment can be reconfigured dynamically, but
-                                                         memory accesses to a bank must be quiesced before that bank can be
-                                                         reassigned to another requester. A host request can access any bank,
-                                                         arbitration logic will prevent bank conflicts for host requests.
+	uint64_t bank_assign                  : 3;  /**< Port assignment for each memory bank. Memory structure is 64k words * 246 data bits (plus
+                                                         ECC). This is further divided into 64 banks each containing 1k words * 246 data bits. A
+                                                         bank can only support one access per cycle, this is implemented by assigning each bank to
+                                                         a specific requester. Most requesters can only make one request per cycle so that mostly
+                                                         solves the problem. RWC is the only requester that can make multiple requests per cycle
+                                                         and will need to implement its own bank-aware scheduler to prevent bank conflicts. Bank
+                                                         assignment can be reconfigured dynamically, but memory accesses to a bank must be quiesced
+                                                         before that bank can be reassigned to another requester. A host request can access any
+                                                         bank; arbitration logic will prevent bank conflicts for host requests.
                                                          Addresses: bit<15:10> = bank, bit<9:0> = offset.
-                                                         bank0 corresponds to memory address 0x0000-0x03ff.
-                                                         bank1 corresponds to memory address 0x0400-0x07ff.
-                                                         bank63 corresponds to memory address 0xfc00-0xffff.
-                                                         See BANK_ASSIGN_E enumeration for encoding. */
+                                                         Bank 0 corresponds to memory address 0x0000-0x03FF.
+                                                         Bank 1 corresponds to memory address 0x0400-0x07FF.
+                                                         Bank 63 corresponds to memory address 0xFC00-0xFFFF.
+                                                         See OSM_BANK_ASSIGN_E for encoding. */
 #else
 	uint64_t bank_assign                  : 3;
 	uint64_t reserved_3_63                : 61;
@@ -202,7 +198,7 @@ typedef union cvmx_osm_bankx_ctrl cvmx_osm_bankx_ctrl_t;
 /**
  * cvmx_osm_ecc_ctrl
  *
- * ECC Control register.
+ * ECC control register.
  *
  */
 union cvmx_osm_ecc_ctrl {
@@ -210,11 +206,11 @@ union cvmx_osm_ecc_ctrl {
 	struct cvmx_osm_ecc_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t flip_synd                    : 2;  /**< Flip the syndrom<1:0> bits to generate 1-bit/2-bits error for testing.
-                                                         0x0: normal operation.
-                                                         0x1: SBE on bit<0>.
-                                                         0x2: SBE on bit<1>.
-                                                         0x3: DBE on bit<1:0>. */
+	uint64_t flip_synd                    : 2;  /**< Flip syndrom<1:0> bits to generate 1-bit/2-bits error for testing.
+                                                         0x0 = Normal operation.
+                                                         0x1 = SBE on bit<0>.
+                                                         0x2 = SBE on bit<1>.
+                                                         0x3 = DBE on bits<1:0>. */
 	uint64_t cor_dis                      : 1;  /**< Disables SBE correction. SBE/DBE are still detected. */
 #else
 	uint64_t cor_dis                      : 1;
@@ -229,20 +225,19 @@ typedef union cvmx_osm_ecc_ctrl cvmx_osm_ecc_ctrl_t;
 /**
  * cvmx_osm_int_info_addr
  *
- * Address error interrupt info.
  * This register can be used to debug address errors (illegal bank). Fields are captured when
- * there are no outstanding address errors indicated in OSM_INT_STAT register and a new address
- * error arrives. Prioritization for multiple events occurring at the same time is indicated by
- * the ADDR_ERR_SOURCE_E enumeration: highest encoded value has highest priority.
+ * there are no outstanding address errors indicated in OSM_INT_STAT and a new address error
+ * arrives. Prioritization for multiple events occurring at the same time is indicated by the
+ * OSM_ADDR_ERR_SOURCE_E enumeration; highest encoded value has highest priority.
  */
 union cvmx_osm_int_info_addr {
 	uint64_t u64;
 	struct cvmx_osm_int_info_addr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_35_63               : 29;
-	uint64_t addr_err_source              : 3;  /**< Source of address error, see OSM_ADDR_ERR_SOURCE_E enumeration. */
+	uint64_t addr_err_source              : 3;  /**< Source of address error; see OSM_ADDR_ERR_SOURCE_E */
 	uint64_t reserved_16_31               : 16;
-	uint64_t addr_err_address             : 16; /**< RAM Address of the address error. */
+	uint64_t addr_err_address             : 16; /**< RAM address of the address error. */
 #else
 	uint64_t addr_err_address             : 16;
 	uint64_t reserved_16_31               : 16;
@@ -257,21 +252,20 @@ typedef union cvmx_osm_int_info_addr cvmx_osm_int_info_addr_t;
 /**
  * cvmx_osm_int_info_ecc
  *
- * ECC error interrupt info.
  * This register can be used to debug ECC failures. Fields are captured when there are no
- * outstanding ECC errors indicated in OSM_INT_STAT register and a new ECC error arrives.
- * Prioritization for multiple events occurring at the same time is indicated by the
- * ECC_ERR_SOURCE_E enumeration: highest encoded value has highest priority. For current bank
- * assignment, see OSM_BANK(0..63)_CTRL register.
+ * outstanding ECC errors indicated in OSM_INT_STAT and a new ECC error arrives. Prioritization
+ * for multiple events occurring at the same time is indicated by the OSM_ECC_ERR_SOURCE_E
+ * enumeration; highest encoded value has highest priority. For current bank assignment, see
+ * OSM_BANK(0..63)_CTRL.
  */
 union cvmx_osm_int_info_ecc {
 	uint64_t u64;
 	struct cvmx_osm_int_info_ecc_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_37_63               : 27;
-	uint64_t ecc_err_source               : 5;  /**< Source of ECC error, see OSM_ECC_ERR_SOURCE_E enumeration. */
+	uint64_t ecc_err_source               : 5;  /**< Source of ECC error; see OSM_ECC_ERR_SOURCE_E. */
 	uint64_t reserved_16_31               : 16;
-	uint64_t ecc_err_address              : 16; /**< RAM Address of the ECC error. */
+	uint64_t ecc_err_address              : 16; /**< RAM address of the ECC error. */
 #else
 	uint64_t ecc_err_address              : 16;
 	uint64_t reserved_16_31               : 16;
@@ -286,42 +280,39 @@ typedef union cvmx_osm_int_info_ecc cvmx_osm_int_info_ecc_t;
 /**
  * cvmx_osm_int_stat
  *
- * Interrupt Status.
- * DBEs are detected. SBE's are corrected. For debugging output for ECC DBE/SBE's, see
- * OSM_INT_INFO_ECC register.
- * Address Errors happen when a requester attempts to access a bank that was not assigned to it.
- * For example, Bank 0 is assigned to DFA and HNA attempts to access it. For debugging output for
- * Address Errors, see OSM_INT_INFO_ADDR register. For current bank assignment, see
- * OSM_BANK(0..63)_CTRL register.
+ * For debugging output for ECC DBE/SBEs, see OSM_INT_INFO_ECC. Address errors happen when a
+ * requester attempts to access a bank that was not assigned to it. For example, Bank 0 is
+ * assigned to HFA, and HNA attempts to access it. For debugging output for address errors, see
+ * OSM_INT_INFO_ADDR. For current bank assignment, see OSM_BANK(0..63)_CTRL.
  */
 union cvmx_osm_int_stat {
 	uint64_t u64;
 	struct cvmx_osm_int_stat_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_23_63               : 41;
-	uint64_t rwc3_addr_err                : 1;  /**< RWC3 port address error (illegal bank). */
-	uint64_t rwc2_addr_err                : 1;  /**< RWC2 port address error (illegal bank). */
-	uint64_t rwc1_addr_err                : 1;  /**< RWC1 port address error (illegal bank). */
-	uint64_t bwc_addr_err                 : 1;  /**< BWC port address error (illegal bank). */
-	uint64_t twc_addr_err                 : 1;  /**< TWC port address error (illegal bank). */
-	uint64_t hna_addr_err                 : 1;  /**< HNA port address error (illegal bank). */
-	uint64_t dfa_addr_err                 : 1;  /**< DFA port address error (illegal bank). */
-	uint64_t host_sbe                     : 1;  /**< Host port single bit error. */
-	uint64_t host_dbe                     : 1;  /**< Host port double bit error. */
-	uint64_t rwc3_sbe                     : 1;  /**< ASE RWC3 port single bit error. */
-	uint64_t rwc3_dbe                     : 1;  /**< ASE RWC3 port double bit error. */
-	uint64_t rwc2_sbe                     : 1;  /**< ASE RWC2 port single bit error. */
-	uint64_t rwc2_dbe                     : 1;  /**< ASE RWC2 port double bit error. */
-	uint64_t rwc1_sbe                     : 1;  /**< ASE RWC1 port single bit error. */
-	uint64_t rwc1_dbe                     : 1;  /**< ASE RWC1 port double bit error. */
-	uint64_t bwc_sbe                      : 1;  /**< ASE BWC port single bit error. */
-	uint64_t bwc_dbe                      : 1;  /**< ASE BWC port double bit error. */
-	uint64_t twc_sbe                      : 1;  /**< ASE TWC port single bit error. */
-	uint64_t twc_dbe                      : 1;  /**< ASE TWC port double bit error. */
-	uint64_t hna_sbe                      : 1;  /**< HNA port single bit error. */
-	uint64_t hna_dbe                      : 1;  /**< HNA port double bit error. */
-	uint64_t dfa_sbe                      : 1;  /**< DFA port single bit error. */
-	uint64_t dfa_dbe                      : 1;  /**< DFA port double bit error. */
+	uint64_t rwc3_addr_err                : 1;  /**< RWC3 port illegal bank address error. */
+	uint64_t rwc2_addr_err                : 1;  /**< RWC2 port illegal bank address error. */
+	uint64_t rwc1_addr_err                : 1;  /**< RWC1 port illegal bank address error. */
+	uint64_t bwc_addr_err                 : 1;  /**< BWC port illegal bank address error. */
+	uint64_t twc_addr_err                 : 1;  /**< TWC port illegal bank address error. */
+	uint64_t hna_addr_err                 : 1;  /**< HNA port illegal bank address error. */
+	uint64_t dfa_addr_err                 : 1;  /**< HFA port illegal bank address error. */
+	uint64_t host_sbe                     : 1;  /**< Host port single-bit error. */
+	uint64_t host_dbe                     : 1;  /**< Host port double-bit error. */
+	uint64_t rwc3_sbe                     : 1;  /**< ASE RWC3 port single-bit error. */
+	uint64_t rwc3_dbe                     : 1;  /**< ASE RWC3 port double-bit error. */
+	uint64_t rwc2_sbe                     : 1;  /**< ASE RWC2 port single-bit error. */
+	uint64_t rwc2_dbe                     : 1;  /**< ASE RWC2 port double-bit error. */
+	uint64_t rwc1_sbe                     : 1;  /**< ASE RWC1 port single-bit error. */
+	uint64_t rwc1_dbe                     : 1;  /**< ASE RWC1 port double-bit error. */
+	uint64_t bwc_sbe                      : 1;  /**< ASE BWC port single-bit error. */
+	uint64_t bwc_dbe                      : 1;  /**< ASE BWC port double-bit error. */
+	uint64_t twc_sbe                      : 1;  /**< ASE TWC port single-bit error. */
+	uint64_t twc_dbe                      : 1;  /**< ASE TWC port double-bit error. */
+	uint64_t hna_sbe                      : 1;  /**< HNA port single-bit error. */
+	uint64_t hna_dbe                      : 1;  /**< HNA port double-bit error. */
+	uint64_t dfa_sbe                      : 1;  /**< HFA port single-bit error. */
+	uint64_t dfa_dbe                      : 1;  /**< HFA port double-bit error. */
 #else
 	uint64_t dfa_dbe                      : 1;
 	uint64_t dfa_sbe                      : 1;
@@ -356,20 +347,18 @@ typedef union cvmx_osm_int_stat cvmx_osm_int_stat_t;
 /**
  * cvmx_osm_mem#_bist_status
  *
- * Built In Self Test Status Register.
- * Results from BIST runs of OSM's memories.
- * OSM_MEM is instantiated 8 times, each instance of OSM_MEM has its own BIST_STATUS
- * register. Each OSM_MEM contains 32 BIST memory instances, so there are 32 status bits
- * per register.
- * Each BIST Memory Instance (1 BIST engine + multiple physical memories) contains
- * 2 physical memories, srf1024x32m8 and srf1024x33m3.
+ * Results from BIST runs of OSM's memories. OSM_MEM is instantiated 8 times, each instance of
+ * OSM_MEM has its own BIST_STATUS. Each OSM_MEM contains 32 BIST memory instances, so there are
+ * 32 status bits per register.
  */
 union cvmx_osm_memx_bist_status {
 	uint64_t u64;
 	struct cvmx_osm_memx_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t bist_status                  : 32; /**< BIST Status of BIST Memory Instance 31..0 in bits 31..0 respectively. */
+	uint64_t bist_status                  : 32; /**< BIST status of BIST memory instance 31..0 in bits 31..0 respectively.
+                                                         INTERNAL: Each BIST Memory Instance (1 BIST engine + multiple physical memories) contains
+                                                         2 physical memories. */
 #else
 	uint64_t bist_status                  : 32;
 	uint64_t reserved_32_63               : 32;
diff --git a/arch/mips/include/asm/octeon/cvmx-pci-defs.h b/arch/mips/include/asm/octeon/cvmx-pci-defs.h
index 28be954..d75607e 100644
--- a/arch/mips/include/asm/octeon/cvmx-pci-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pci-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-pcie.h b/arch/mips/include/asm/octeon/cvmx-pcie.h
index 4c891dd..daa4222 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcie.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcie.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 73845 $<hr>
+ * <hr>$Revision: 88161 $<hr>
  */
 
 #ifndef __CVMX_PCIE_H__
@@ -54,6 +54,15 @@ extern "C" {
 /* *INDENT-ON* */
 #endif
 
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/cvmx.h>
+#else
+#include <cvmx.h>
+#endif
+
+#define CVMX_PCIE_MAX_PORTS	3
+#define CVMX_PCIE_PORTS		(OCTEON_IS_OCTEON3() ? CVMX_PCIE_MAX_PORTS : 2)
+
 /*
  * The physical memory base mapped by BAR1.  256MB at the end of the
  * first 4GB.
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
index 3e44b0d..fbdbbaf 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1269,12 +1269,13 @@ union cvmx_pcieepvfx_cfg031 {
                                                          The default value is the value you specify during hardware
                                                          configuration (x1, x4, x8, or x16) */
 	uint32_t mls                          : 4;  /**< "Maximum Link Speed
-                                                         The reset value of this field is controled by a value sent from
-                                                         the input pin qlm#_cfg[1].
-                                                         qlm#_cfg[1]   RST_VALUE   NOTE
-                                                         ?             0001b       2.5 GHz supported
-                                                         ?             0010b       5.0 GHz and 2.5 GHz supported
-                                                         ?             0100b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported
+                                                         The reset value of this field is controlled by the value read from
+                                                         the PEM csr PEM(0..3)_CFG.MD.
+                                                         PEM(0..2)_CFG.MD  RST_VALUE   NOTE
+                                                         00                0001b       2.5 GHz supported
+                                                         01                0010b       5.0 GHz and 2.5 GHz supported
+                                                         10                0011b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported
+                                                         11                0011b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported (RC Mode)
                                                          This field is writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 #else
@@ -1499,14 +1500,15 @@ union cvmx_pcieepvfx_cfg039 {
                                                          Bit definitions are:
                                                          Bit 1 2.5 GT/s
                                                          Bit 2 5.0 GT/s
-                                                         Bit 3 8.0 GT/s (Not Supported)
+                                                         Bit 3 8.0 GT/s
                                                          Bits 7:4 reserved
-                                                         The reset value of this field is controled by a value sent from
-                                                         the lsb of the MIO_QLM#_SPD register
-                                                         qlm#_spd[0]   RST_VALUE   NOTE
-                                                         ?             0001b       2.5 GHz supported
-                                                         ?             0011b       5.0 GHz and 2.5 GHz supported
-                                                         ?             0111b       8.0 GHz, 5.0 GHz and 2.5 GHz supported" */
+                                                         The reset value of this field is controlled by a value read from
+                                                         the PEM csr PEM(0..3)_CFG.MD.
+                                                         PEM(0..3)_CFG.MD   RST_VALUE   NOTE
+                                                         00                 0001b       2.5 GHz supported
+                                                         01                 0011b       5.0 GHz and 2.5 GHz supported
+                                                         10                 0111b       8.0 GHz, 5.0 GHz and 2.5 GHz supported
+                                                         11                 0111b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported (RC Mode)" */
 	uint32_t reserved_0_0                 : 1;
 #else
 	uint32_t reserved_0_0                 : 1;
@@ -1590,15 +1592,22 @@ union cvmx_pcieepvfx_cfg040 {
                                                          the upstream component in its training sequences:
                                                          - 0001: 2.5Gb/s Target Link Speed
                                                          - 0010: 5Gb/s Target Link Speed
-                                                         - 0100: 8Gb/s Target Link Speed
+                                                         - 0100: 8Gb/s Target Link Speed (Not Supported)
                                                          All other encodings are reserved.
+                                                         If a value is written to this field that does not correspond to
+                                                         a speed included in the Supported Link Speeds field, the
+                                                         result is undefined.
+                                                         For both Upstream and Downstream ports, this field is
+                                                         used to set the target compliance mode speed when
+                                                         software is using the Enter Compliance bit to force a link
                                                          into compliance mode.
-                                                         The reset value of this field is controled by a value sent from
-                                                         the lsb of the MIO_QLM#_SPD register
-                                                         qlm#_spd[0]   RST_VALUE   NOTE
-                                                         ?             0001b       2.5 GHz supported
-                                                         ?             0010b       5.0 GHz and 2.5 GHz supported
-                                                         ?             0100b       8.0 GHz, 5.0 GHz and 2.5 GHz supported" */
+                                                         The reset value of this field is controlled by the value read from
+                                                         the PEM csr PEM(0..3)_CFG.MD.
+                                                         PEM(0..2)_CFG.MD  RST_VALUE   NOTE
+                                                         00                0001b       2.5 GHz supported
+                                                         01                0010b       5.0 GHz and 2.5 GHz supported
+                                                         10                0011b       8.0 GHz, 5.0 GHz and 2.5 GHz supported
+                                                         11                0011b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported (RC Mode)" */
 #else
 	uint32_t tls                          : 4;
 	uint32_t ec                           : 1;
@@ -2127,7 +2136,8 @@ union cvmx_pcieepvfx_cfg452 {
                                                          the PCIe core can negotiate a smaller link width, so all
                                                          of x8, x4, x2, and x1 are supported when LME=0xF,
                                                          for example.) */
-	uint32_t reserved_8_15                : 8;
+	uint32_t reserved_12_15               : 4;
+	uint32_t link_rate                    : 4;  /**< Reserved. */
 	uint32_t flm                          : 1;  /**< Fast Link Mode
                                                          Sets all internal timers to fast mode for simulation purposes.
                                                          If during an eeprom load, the first word loaded is 0xffffffff,
@@ -2161,7 +2171,8 @@ union cvmx_pcieepvfx_cfg452 {
 	uint32_t dllle                        : 1;
 	uint32_t reserved_6_6                 : 1;
 	uint32_t flm                          : 1;
-	uint32_t reserved_8_15                : 8;
+	uint32_t link_rate                    : 4;
+	uint32_t reserved_12_15               : 4;
 	uint32_t lme                          : 6;
 	uint32_t reserved_22_31               : 10;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
index 960c474..624cb7d 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1456,6 +1456,7 @@ static inline uint64_t CVMX_PCIEEPX_CFG023(unsigned long block_id)
 static inline uint64_t CVMX_PCIEEPX_CFG024(unsigned long block_id)
 {
 	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id <= 2))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
 		cvmx_warn("CVMX_PCIEEPX_CFG024(%lu) is invalid on this chip\n", block_id);
 	return 0x0000030000000060ull + ((block_id) & 3) * 0x100000000ull;
@@ -1467,6 +1468,7 @@ static inline uint64_t CVMX_PCIEEPX_CFG024(unsigned long block_id)
 static inline uint64_t CVMX_PCIEEPX_CFG025(unsigned long block_id)
 {
 	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id <= 2))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
 		cvmx_warn("CVMX_PCIEEPX_CFG025(%lu) is invalid on this chip\n", block_id);
 	return 0x0000030000000064ull + ((block_id) & 3) * 0x100000000ull;
@@ -5468,6 +5470,7 @@ union cvmx_pcieepx_cfg024 {
 	uint32_t msimm                        : 32;
 #endif
 	} s;
+	struct cvmx_pcieepx_cfg024_s          cn70xx;
 	struct cvmx_pcieepx_cfg024_s          cn78xx;
 };
 typedef union cvmx_pcieepx_cfg024 cvmx_pcieepx_cfg024_t;
@@ -5489,6 +5492,7 @@ union cvmx_pcieepx_cfg025 {
 	uint32_t msimp                        : 32;
 #endif
 	} s;
+	struct cvmx_pcieepx_cfg025_s          cn70xx;
 	struct cvmx_pcieepx_cfg025_s          cn78xx;
 };
 typedef union cvmx_pcieepx_cfg025 cvmx_pcieepx_cfg025_t;
@@ -7295,7 +7299,47 @@ union cvmx_pcieepx_cfg065 {
 	struct cvmx_pcieepx_cfg065_cn61xx     cn66xx;
 	struct cvmx_pcieepx_cfg065_cn61xx     cn68xx;
 	struct cvmx_pcieepx_cfg065_cn52xx     cn68xxp1;
-	struct cvmx_pcieepx_cfg065_cn61xx     cn70xx;
+	struct cvmx_pcieepx_cfg065_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t reserved_25_31               : 7;
+	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Status */
+	uint32_t reserved_23_23               : 1;
+	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Status */
+	uint32_t reserved_21_21               : 1;
+	uint32_t ures                         : 1;  /**< Unsupported Request Error Status */
+	uint32_t ecrces                       : 1;  /**< ECRC Error Status */
+	uint32_t mtlps                        : 1;  /**< Malformed TLP Status */
+	uint32_t ros                          : 1;  /**< Receiver Overflow Status */
+	uint32_t ucs                          : 1;  /**< Unexpected Completion Status */
+	uint32_t cas                          : 1;  /**< Completer Abort Status */
+	uint32_t cts                          : 1;  /**< Completion Timeout Status */
+	uint32_t fcpes                        : 1;  /**< Flow Control Protocol Error Status */
+	uint32_t ptlps                        : 1;  /**< Poisoned TLP Status */
+	uint32_t reserved_6_11                : 6;
+	uint32_t sdes                         : 1;  /**< Surprise Down Error Status (not supported) */
+	uint32_t dlpes                        : 1;  /**< Data Link Protocol Error Status */
+	uint32_t reserved_0_3                 : 4;
+#else
+	uint32_t reserved_0_3                 : 4;
+	uint32_t dlpes                        : 1;
+	uint32_t sdes                         : 1;
+	uint32_t reserved_6_11                : 6;
+	uint32_t ptlps                        : 1;
+	uint32_t fcpes                        : 1;
+	uint32_t cts                          : 1;
+	uint32_t cas                          : 1;
+	uint32_t ucs                          : 1;
+	uint32_t ros                          : 1;
+	uint32_t mtlps                        : 1;
+	uint32_t ecrces                       : 1;
+	uint32_t ures                         : 1;
+	uint32_t reserved_21_21               : 1;
+	uint32_t ucies                        : 1;
+	uint32_t reserved_23_23               : 1;
+	uint32_t uatombs                      : 1;
+	uint32_t reserved_25_31               : 7;
+#endif
+	} cn70xx;
 	struct cvmx_pcieepx_cfg065_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
@@ -7761,7 +7805,47 @@ union cvmx_pcieepx_cfg067 {
 	struct cvmx_pcieepx_cfg067_cn61xx     cn66xx;
 	struct cvmx_pcieepx_cfg067_cn61xx     cn68xx;
 	struct cvmx_pcieepx_cfg067_cn52xx     cn68xxp1;
-	struct cvmx_pcieepx_cfg067_cn61xx     cn70xx;
+	struct cvmx_pcieepx_cfg067_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t reserved_25_31               : 7;
+	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Severity */
+	uint32_t reserved_23_23               : 1;
+	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Severity */
+	uint32_t reserved_21_21               : 1;
+	uint32_t ures                         : 1;  /**< Unsupported Request Error Severity */
+	uint32_t ecrces                       : 1;  /**< ECRC Error Severity */
+	uint32_t mtlps                        : 1;  /**< Malformed TLP Severity */
+	uint32_t ros                          : 1;  /**< Receiver Overflow Severity */
+	uint32_t ucs                          : 1;  /**< Unexpected Completion Severity */
+	uint32_t cas                          : 1;  /**< Completer Abort Severity */
+	uint32_t cts                          : 1;  /**< Completion Timeout Severity */
+	uint32_t fcpes                        : 1;  /**< Flow Control Protocol Error Severity */
+	uint32_t ptlps                        : 1;  /**< Poisoned TLP Severity */
+	uint32_t reserved_6_11                : 6;
+	uint32_t sdes                         : 1;  /**< Surprise Down Error Severity (not supported) */
+	uint32_t dlpes                        : 1;  /**< Data Link Protocol Error Severity */
+	uint32_t reserved_0_3                 : 4;
+#else
+	uint32_t reserved_0_3                 : 4;
+	uint32_t dlpes                        : 1;
+	uint32_t sdes                         : 1;
+	uint32_t reserved_6_11                : 6;
+	uint32_t ptlps                        : 1;
+	uint32_t fcpes                        : 1;
+	uint32_t cts                          : 1;
+	uint32_t cas                          : 1;
+	uint32_t ucs                          : 1;
+	uint32_t ros                          : 1;
+	uint32_t mtlps                        : 1;
+	uint32_t ecrces                       : 1;
+	uint32_t ures                         : 1;
+	uint32_t reserved_21_21               : 1;
+	uint32_t ucies                        : 1;
+	uint32_t reserved_23_23               : 1;
+	uint32_t uatombs                      : 1;
+	uint32_t reserved_25_31               : 7;
+#endif
+	} cn70xx;
 	struct cvmx_pcieepx_cfg067_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
@@ -7910,7 +7994,7 @@ union cvmx_pcieepx_cfg068 {
 	struct cvmx_pcieepx_cfg068_cn52xx     cn66xx;
 	struct cvmx_pcieepx_cfg068_cn52xx     cn68xx;
 	struct cvmx_pcieepx_cfg068_cn52xx     cn68xxp1;
-	struct cvmx_pcieepx_cfg068_cn52xx     cn70xx;
+	struct cvmx_pcieepx_cfg068_s          cn70xx;
 	struct cvmx_pcieepx_cfg068_s          cn78xx;
 	struct cvmx_pcieepx_cfg068_s          cnf71xx;
 };
@@ -8302,7 +8386,7 @@ typedef union cvmx_pcieepx_cfg083 cvmx_pcieepx_cfg083_t;
 /**
  * cvmx_pcieep#_cfg084
  *
- * PCIE_CFG112 = One hundred thirteenth 32-bits of PCIE type 0 config space
+ * PCIE_CFG084 = Eighty-fifth 32-bits of PCIE type 0 config space
  * (PCI Express Resizable BAR (RBAR) Control Register)
  */
 union cvmx_pcieepx_cfg084 {
@@ -9151,6 +9235,90 @@ union cvmx_pcieepx_cfg450 {
                                                          * As the The Force Link is a pulse, writing a 1 to it does
                                                            trigger the forced link state event, even thought reading it
                                                            always returns a 0. */
+	uint32_t reserved_12_14               : 3;
+	uint32_t link_cmd                     : 4;  /**< Link Command
+                                                         The Link command that the PCI Express Core will be forced to
+                                                         transmit when bit 15 (Force Link) is set.
+                                                         Command encoding:
+                                                         o PEM_SEND_IDLE              1h
+                                                         o PEM_SEND_EIDLE             2h
+                                                         o PEM_XMT_IN_EIDLE           3h
+                                                         o PEM_MOD_COMPL_PATTERN      4h
+                                                         o PEM_SEND_RCVR_DETECT_SEQ   5h
+                                                         o PEM_SEND_TS1               6h
+                                                         o PEM_SEND_TS2               7h
+                                                         o PEM_COMPLIANCE_PATTERN     8h
+                                                         o PEM_SEND_SDS               9h
+                                                         o PEM_SEND_BEACON            ah
+                                                         o PEM_SEND_N_FTS             bh
+                                                         o PEM_NORM                   ch
+                                                         o PEM_SEND_SKP               dh
+                                                         o PEM_SEND_EIES              eh
+                                                         o PEM_SEND_EIES_SYM          fh */
+	uint32_t link_num                     : 8;  /**< Link Number
+                                                         Not used for Endpoint */
+#else
+	uint32_t link_num                     : 8;
+	uint32_t link_cmd                     : 4;
+	uint32_t reserved_12_14               : 3;
+	uint32_t force_link                   : 1;
+	uint32_t link_state                   : 6;
+	uint32_t reserved_22_23               : 2;
+	uint32_t lpec                         : 8;
+#endif
+	} s;
+	struct cvmx_pcieepx_cfg450_cn52xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t lpec                         : 8;  /**< Low Power Entrance Count
+                                                         The Power Management state will wait for this many clock cycles
+                                                         for the associated completion of a CfgWr to PCIE_CFG017 register
+                                                         Power State (PS) field register to go low-power. This register
+                                                         is intended for applications that do not let the PCI Express
+                                                         bus handle a completion for configuration request to the
+                                                         Power Management Control and Status (PCIE_CFG017) register. */
+	uint32_t reserved_22_23               : 2;
+	uint32_t link_state                   : 6;  /**< Link State
+                                                         The Link state that the PCI Express Bus will be forced to
+                                                         when bit 15 (Force Link) is set.
+                                                         State encoding:
+                                                         o DETECT_QUIET              00h
+                                                         o DETECT_ACT                01h
+                                                         o POLL_ACTIVE               02h
+                                                         o POLL_COMPLIANCE           03h
+                                                         o POLL_CONFIG               04h
+                                                         o PRE_DETECT_QUIET          05h
+                                                         o DETECT_WAIT               06h
+                                                         o CFG_LINKWD_START          07h
+                                                         o CFG_LINKWD_ACEPT          08h
+                                                         o CFG_LANENUM_WAIT          09h
+                                                         o CFG_LANENUM_ACEPT         0Ah
+                                                         o CFG_COMPLETE              0Bh
+                                                         o CFG_IDLE                  0Ch
+                                                         o RCVRY_LOCK                0Dh
+                                                         o RCVRY_SPEED               0Eh
+                                                         o RCVRY_RCVRCFG             0Fh
+                                                         o RCVRY_IDLE                10h
+                                                         o L0                        11h
+                                                         o L0S                       12h
+                                                         o L123_SEND_EIDLE           13h
+                                                         o L1_IDLE                   14h
+                                                         o L2_IDLE                   15h
+                                                         o L2_WAKE                   16h
+                                                         o DISABLED_ENTRY            17h
+                                                         o DISABLED_IDLE             18h
+                                                         o DISABLED                  19h
+                                                         o LPBK_ENTRY                1Ah
+                                                         o LPBK_ACTIVE               1Bh
+                                                         o LPBK_EXIT                 1Ch
+                                                         o LPBK_EXIT_TIMEOUT         1Dh
+                                                         o HOT_RESET_ENTRY           1Eh
+                                                         o HOT_RESET                 1Fh */
+	uint32_t force_link                   : 1;  /**< Force Link
+                                                         Forces the Link to the state specified by the Link State field.
+                                                         The Force Link pulse will trigger Link re-negotiation.
+                                                         * As the The Force Link is a pulse, writing a 1 to it does
+                                                           trigger the forced link state event, even thought reading it
+                                                           always returns a 0. */
 	uint32_t reserved_8_14                : 7;
 	uint32_t link_num                     : 8;  /**< Link Number
                                                          Not used for Endpoint */
@@ -9162,20 +9330,19 @@ union cvmx_pcieepx_cfg450 {
 	uint32_t reserved_22_23               : 2;
 	uint32_t lpec                         : 8;
 #endif
-	} s;
-	struct cvmx_pcieepx_cfg450_s          cn52xx;
-	struct cvmx_pcieepx_cfg450_s          cn52xxp1;
-	struct cvmx_pcieepx_cfg450_s          cn56xx;
-	struct cvmx_pcieepx_cfg450_s          cn56xxp1;
-	struct cvmx_pcieepx_cfg450_s          cn61xx;
-	struct cvmx_pcieepx_cfg450_s          cn63xx;
-	struct cvmx_pcieepx_cfg450_s          cn63xxp1;
-	struct cvmx_pcieepx_cfg450_s          cn66xx;
-	struct cvmx_pcieepx_cfg450_s          cn68xx;
-	struct cvmx_pcieepx_cfg450_s          cn68xxp1;
+	} cn52xx;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn52xxp1;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn56xx;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn56xxp1;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn61xx;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn63xx;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn63xxp1;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn66xx;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn68xx;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg450_s          cn70xx;
-	struct cvmx_pcieepx_cfg450_s          cn78xx;
-	struct cvmx_pcieepx_cfg450_s          cnf71xx;
+	struct cvmx_pcieepx_cfg450_cn52xx     cn78xx;
+	struct cvmx_pcieepx_cfg450_cn52xx     cnf71xx;
 };
 typedef union cvmx_pcieepx_cfg450 cvmx_pcieepx_cfg450_t;
 
@@ -9332,6 +9499,78 @@ union cvmx_pcieepx_cfg452 {
                                                           of lanes in use by the PCIe. LME sets the max number of lanes
                                                           in the PCIe core that COULD be used. As per the PCIe specs,
                                                           the PCIe core can negotiate a smaller link width) */
+	uint32_t reserved_12_15               : 4;
+	uint32_t link_rate                    : 4;  /**< Reserved. */
+	uint32_t flm                          : 1;  /**< Fast Link Mode
+                                                         Sets all internal timers to fast mode for simulation purposes.
+                                                         If during an eeprom load, the first word loaded is 0xffffffff,
+                                                         then the EEPROM load will be terminated and this bit will be set. */
+	uint32_t reserved_6_6                 : 1;
+	uint32_t dllle                        : 1;  /**< DLL Link Enable
+                                                         Enables Link initialization. If DLL Link Enable = 0, the PCI
+                                                         Express bus does not transmit InitFC DLLPs and does not
+                                                         establish a Link. */
+	uint32_t reserved_4_4                 : 1;
+	uint32_t ra                           : 1;  /**< Reset Assert
+                                                         Triggers a recovery and forces the LTSSM to the Hot Reset
+                                                         state (downstream port only). */
+	uint32_t le                           : 1;  /**< Loopback Enable
+                                                         Initiate loopback mode as a master. On a 0->1 transition,
+                                                         the PCIe core sends TS ordered sets with the loopback bit set
+                                                         to cause the link partner to enter into loopback mode as a
+                                                         slave. Normal transmission is not possible when LE=1. To exit
+                                                         loopback mode, take the link through a reset sequence. */
+	uint32_t sd                           : 1;  /**< Scramble Disable
+                                                         Turns off data scrambling. */
+	uint32_t omr                          : 1;  /**< Other Message Request
+                                                         When software writes a `1' to this bit, the PCI Express bus
+                                                         transmits the Message contained in the Other Message register. */
+#else
+	uint32_t omr                          : 1;
+	uint32_t sd                           : 1;
+	uint32_t le                           : 1;
+	uint32_t ra                           : 1;
+	uint32_t reserved_4_4                 : 1;
+	uint32_t dllle                        : 1;
+	uint32_t reserved_6_6                 : 1;
+	uint32_t flm                          : 1;
+	uint32_t link_rate                    : 4;
+	uint32_t reserved_12_15               : 4;
+	uint32_t lme                          : 6;
+	uint32_t reserved_22_24               : 3;
+	uint32_t eccrc                        : 1;
+	uint32_t reserved_26_31               : 6;
+#endif
+	} s;
+	struct cvmx_pcieepx_cfg452_cn52xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t reserved_26_31               : 6;
+	uint32_t eccrc                        : 1;  /**< Enable Corrupted CRC
+                                                         Causes corrupt LCRC for TLPs when set,
+                                                         using the pattern contained in the Other Message register.
+                                                         This is a test feature, not to be used in normal operation. */
+	uint32_t reserved_22_24               : 3;
+	uint32_t lme                          : 6;  /**< Link Mode Enable
+                                                         o 000001: x1
+                                                         o 000011: x2
+                                                         o 000111: x4
+                                                         o 001111: x8  (not supported)
+                                                         o 011111: x16 (not supported)
+                                                         o 111111: x32 (not supported)
+                                                         This field indicates the MAXIMUM number of lanes supported
+                                                         by the PCIe port. It is set to 0x7 or 0x3 depending
+                                                         on the value of the QLM_CFG bits (0x7 when QLM_CFG == 0x3
+                                                         otherwise 0x3). The value can be set less than 0x7 or 0x3
+                                                         to limit the number of lanes the PCIe will attempt to use.
+                                                         If the value of 0x7 or 0x3 set by the HW is not desired,
+                                                         this field can be programmed to a smaller value (i.e. EEPROM)
+                                                         See also MLW.
+                                                         (Note: The value of this field does NOT indicate the number
+                                                          of lanes in use by the PCIe. LME sets the max number of lanes
+                                                          in the PCIe core that COULD be used. As per the PCIe specs,
+                                                          the PCIe core can negotiate a smaller link width, so all
+                                                          of x4, x2, and x1 are supported when LME=0x7,
+                                                          for example.) */
 	uint32_t reserved_8_15                : 8;
 	uint32_t flm                          : 1;  /**< Fast Link Mode
                                                          Sets all internal timers to fast mode for simulation purposes.
@@ -9372,11 +9611,10 @@ union cvmx_pcieepx_cfg452 {
 	uint32_t eccrc                        : 1;
 	uint32_t reserved_26_31               : 6;
 #endif
-	} s;
-	struct cvmx_pcieepx_cfg452_s          cn52xx;
-	struct cvmx_pcieepx_cfg452_s          cn52xxp1;
-	struct cvmx_pcieepx_cfg452_s          cn56xx;
-	struct cvmx_pcieepx_cfg452_s          cn56xxp1;
+	} cn52xx;
+	struct cvmx_pcieepx_cfg452_cn52xx     cn52xxp1;
+	struct cvmx_pcieepx_cfg452_cn52xx     cn56xx;
+	struct cvmx_pcieepx_cfg452_cn52xx     cn56xxp1;
 	struct cvmx_pcieepx_cfg452_cn61xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_22_31               : 10;
@@ -9438,13 +9676,75 @@ union cvmx_pcieepx_cfg452 {
 	uint32_t reserved_22_31               : 10;
 #endif
 	} cn61xx;
-	struct cvmx_pcieepx_cfg452_s          cn63xx;
-	struct cvmx_pcieepx_cfg452_s          cn63xxp1;
+	struct cvmx_pcieepx_cfg452_cn52xx     cn63xx;
+	struct cvmx_pcieepx_cfg452_cn52xx     cn63xxp1;
 	struct cvmx_pcieepx_cfg452_cn61xx     cn66xx;
 	struct cvmx_pcieepx_cfg452_cn61xx     cn68xx;
 	struct cvmx_pcieepx_cfg452_cn61xx     cn68xxp1;
-	struct cvmx_pcieepx_cfg452_cn61xx     cn70xx;
-	struct cvmx_pcieepx_cfg452_cn61xx     cn78xx;
+	struct cvmx_pcieepx_cfg452_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t reserved_22_31               : 10;
+	uint32_t lme                          : 6;  /**< Link Mode Enable
+                                                         o 000001: x1
+                                                         o 000011: x2
+                                                         o 000111: x4
+                                                         o 001111: x8  (not supported)
+                                                         o 011111: x16 (not supported)
+                                                         o 111111: x32 (not supported)
+                                                         This field indicates the MAXIMUM number of lanes supported
+                                                         by the PCIe port. The value can be set less than 0x7
+                                                         to limit the number of lanes the PCIe will attempt to use.
+                                                         If the value of 0x7 set by the HW is not desired,
+                                                         this field can be programmed to a smaller value (i.e. EEPROM)
+                                                         See also MLW.
+                                                         (Note: The value of this field does NOT indicate the number
+                                                         of lanes in use by the PCIe. LME sets the max number of lanes
+                                                         in the PCIe core that COULD be used. As per the PCIe specs,
+                                                         the PCIe core can negotiate a smaller link width, so all
+                                                         of x4, x2, and x1 are supported when LME=0x7,
+                                                         for example.) */
+	uint32_t reserved_12_15               : 4;
+	uint32_t link_rate                    : 4;  /**< Reserved. */
+	uint32_t flm                          : 1;  /**< Fast Link Mode
+                                                         Sets all internal timers to fast mode for simulation purposes.
+                                                         If during an eeprom load, the first word loaded is 0xffffffff,
+                                                         then the EEPROM load will be terminated and this bit will be set. */
+	uint32_t reserved_6_6                 : 1;
+	uint32_t dllle                        : 1;  /**< DLL Link Enable
+                                                         Enables Link initialization. If DLL Link Enable = 0, the PCI
+                                                         Express bus does not transmit InitFC DLLPs and does not
+                                                         establish a Link. */
+	uint32_t reserved_4_4                 : 1;
+	uint32_t ra                           : 1;  /**< Reset Assert
+                                                         Triggers a recovery and forces the LTSSM to the Hot Reset
+                                                         state (downstream port only). */
+	uint32_t le                           : 1;  /**< Loopback Enable
+                                                         Initiate loopback mode as a master. On a 0->1 transition,
+                                                         the PCIe core sends TS ordered sets with the loopback bit set
+                                                         to cause the link partner to enter into loopback mode as a
+                                                         slave. Normal transmission is not possible when LE=1. To exit
+                                                         loopback mode, take the link through a reset sequence. */
+	uint32_t sd                           : 1;  /**< Scramble Disable
+                                                         Turns off data scrambling. */
+	uint32_t omr                          : 1;  /**< Other Message Request
+                                                         When software writes a `1' to this bit, the PCI Express bus
+                                                         transmits the Message contained in the Other Message register. */
+#else
+	uint32_t omr                          : 1;
+	uint32_t sd                           : 1;
+	uint32_t le                           : 1;
+	uint32_t ra                           : 1;
+	uint32_t reserved_4_4                 : 1;
+	uint32_t dllle                        : 1;
+	uint32_t reserved_6_6                 : 1;
+	uint32_t flm                          : 1;
+	uint32_t link_rate                    : 4;
+	uint32_t reserved_12_15               : 4;
+	uint32_t lme                          : 6;
+	uint32_t reserved_22_31               : 10;
+#endif
+	} cn70xx;
+	struct cvmx_pcieepx_cfg452_cn70xx     cn78xx;
 	struct cvmx_pcieepx_cfg452_cn61xx     cnf71xx;
 };
 typedef union cvmx_pcieepx_cfg452 cvmx_pcieepx_cfg452_t;
@@ -9593,7 +9893,25 @@ union cvmx_pcieepx_cfg454 {
 	struct cvmx_pcieepx_cfg454_cn61xx     cn66xx;
 	struct cvmx_pcieepx_cfg454_cn61xx     cn68xx;
 	struct cvmx_pcieepx_cfg454_cn52xx     cn68xxp1;
-	struct cvmx_pcieepx_cfg454_cn61xx     cn70xx;
+	struct cvmx_pcieepx_cfg454_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t reserved_24_31               : 8;
+	uint32_t tmanlt                       : 5;  /**< Timer Modifier for Ack/Nak Latency Timer
+                                                         Increases the timer value for the Ack/Nak latency timer, in
+                                                         increments of 64 clock cycles. */
+	uint32_t tmrt                         : 5;  /**< Timer Modifier for Replay Timer
+                                                         Increases the timer value for the replay timer, in increments
+                                                         of 64 clock cycles. */
+	uint32_t reserved_8_13                : 6;
+	uint32_t mfuncn                       : 8;  /**< Max Number of Functions Supported */
+#else
+	uint32_t mfuncn                       : 8;
+	uint32_t reserved_8_13                : 6;
+	uint32_t tmrt                         : 5;
+	uint32_t tmanlt                       : 5;
+	uint32_t reserved_24_31               : 8;
+#endif
+	} cn70xx;
 	struct cvmx_pcieepx_cfg454_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_29_31               : 3;
@@ -10632,9 +10950,9 @@ union cvmx_pcieepx_cfg558 {
 	struct cvmx_pcieepx_cfg558_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t ple                          : 1;  /**< Pipe Loopback Enable */
-	uint32_t reserved_0_30                : 31;
+	uint32_t rxstatus                     : 31; /**< Reserved. */
 #else
-	uint32_t reserved_0_30                : 31;
+	uint32_t rxstatus                     : 31;
 	uint32_t ple                          : 1;
 #endif
 	} s;
diff --git a/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h b/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
index 369a5b6..89a7667 100644
--- a/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -6480,9 +6480,7 @@ union cvmx_pciercx_cfg065 {
 	struct cvmx_pciercx_cfg065_cn61xx     cn66xx;
 	struct cvmx_pciercx_cfg065_cn61xx     cn68xx;
 	struct cvmx_pciercx_cfg065_cn52xx     cn68xxp1;
-	struct cvmx_pciercx_cfg065_cn61xx     cn70xx;
-	struct cvmx_pciercx_cfg065_s          cn78xx;
-	struct cvmx_pciercx_cfg065_cnf71xx {
+	struct cvmx_pciercx_cfg065_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_25_31               : 7;
 	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Status */
@@ -6522,7 +6520,9 @@ union cvmx_pciercx_cfg065 {
 	uint32_t uatombs                      : 1;
 	uint32_t reserved_25_31               : 7;
 #endif
-	} cnf71xx;
+	} cn70xx;
+	struct cvmx_pciercx_cfg065_s          cn78xx;
+	struct cvmx_pciercx_cfg065_cn70xx     cnf71xx;
 };
 typedef union cvmx_pciercx_cfg065 cvmx_pciercx_cfg065_t;
 
@@ -6714,9 +6714,7 @@ union cvmx_pciercx_cfg067 {
 	uint32_t reserved_26_31               : 6;
 	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Severity */
 	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Severity */
-	uint32_t reserved_23_23               : 1;
-	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Severity */
-	uint32_t reserved_21_21               : 1;
+	uint32_t reserved_21_23               : 3;
 	uint32_t ures                         : 1;  /**< Unsupported Request Error Severity */
 	uint32_t ecrces                       : 1;  /**< ECRC Error Severity */
 	uint32_t mtlps                        : 1;  /**< Malformed TLP Severity */
@@ -6744,9 +6742,7 @@ union cvmx_pciercx_cfg067 {
 	uint32_t mtlps                        : 1;
 	uint32_t ecrces                       : 1;
 	uint32_t ures                         : 1;
-	uint32_t reserved_21_21               : 1;
-	uint32_t ucies                        : 1;
-	uint32_t reserved_23_23               : 1;
+	uint32_t reserved_21_23               : 3;
 	uint32_t uatombs                      : 1;
 	uint32_t tpbes                        : 1;
 	uint32_t reserved_26_31               : 6;
@@ -6830,13 +6826,13 @@ union cvmx_pciercx_cfg067 {
 	struct cvmx_pciercx_cfg067_cn61xx     cn66xx;
 	struct cvmx_pciercx_cfg067_cn61xx     cn68xx;
 	struct cvmx_pciercx_cfg067_cn52xx     cn68xxp1;
-	struct cvmx_pciercx_cfg067_cn61xx     cn70xx;
-	struct cvmx_pciercx_cfg067_cn78xx {
+	struct cvmx_pciercx_cfg067_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t reserved_26_31               : 6;
-	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Severity */
+	uint32_t reserved_25_31               : 7;
 	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Severity */
-	uint32_t reserved_21_23               : 3;
+	uint32_t reserved_23_23               : 1;
+	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Severity */
+	uint32_t reserved_21_21               : 1;
 	uint32_t ures                         : 1;  /**< Unsupported Request Error Severity */
 	uint32_t ecrces                       : 1;  /**< ECRC Error Severity */
 	uint32_t mtlps                        : 1;  /**< Malformed TLP Severity */
@@ -6864,19 +6860,19 @@ union cvmx_pciercx_cfg067 {
 	uint32_t mtlps                        : 1;
 	uint32_t ecrces                       : 1;
 	uint32_t ures                         : 1;
-	uint32_t reserved_21_23               : 3;
+	uint32_t reserved_21_21               : 1;
+	uint32_t ucies                        : 1;
+	uint32_t reserved_23_23               : 1;
 	uint32_t uatombs                      : 1;
-	uint32_t tpbes                        : 1;
-	uint32_t reserved_26_31               : 6;
+	uint32_t reserved_25_31               : 7;
 #endif
-	} cn78xx;
-	struct cvmx_pciercx_cfg067_cnf71xx {
+	} cn70xx;
+	struct cvmx_pciercx_cfg067_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t reserved_25_31               : 7;
+	uint32_t reserved_26_31               : 6;
+	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Severity */
 	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Severity */
-	uint32_t reserved_23_23               : 1;
-	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Severity */
-	uint32_t reserved_21_21               : 1;
+	uint32_t unsuperr                     : 3;  /**< Reserved. */
 	uint32_t ures                         : 1;  /**< Unsupported Request Error Severity */
 	uint32_t ecrces                       : 1;  /**< ECRC Error Severity */
 	uint32_t mtlps                        : 1;  /**< Malformed TLP Severity */
@@ -6904,13 +6900,13 @@ union cvmx_pciercx_cfg067 {
 	uint32_t mtlps                        : 1;
 	uint32_t ecrces                       : 1;
 	uint32_t ures                         : 1;
-	uint32_t reserved_21_21               : 1;
-	uint32_t ucies                        : 1;
-	uint32_t reserved_23_23               : 1;
+	uint32_t unsuperr                     : 3;
 	uint32_t uatombs                      : 1;
-	uint32_t reserved_25_31               : 7;
+	uint32_t tpbes                        : 1;
+	uint32_t reserved_26_31               : 6;
 #endif
-	} cnf71xx;
+	} cn78xx;
+	struct cvmx_pciercx_cfg067_cn70xx     cnf71xx;
 };
 typedef union cvmx_pciercx_cfg067 cvmx_pciercx_cfg067_t;
 
@@ -6979,7 +6975,7 @@ union cvmx_pciercx_cfg068 {
 	struct cvmx_pciercx_cfg068_cn52xx     cn66xx;
 	struct cvmx_pciercx_cfg068_cn52xx     cn68xx;
 	struct cvmx_pciercx_cfg068_cn52xx     cn68xxp1;
-	struct cvmx_pciercx_cfg068_cn52xx     cn70xx;
+	struct cvmx_pciercx_cfg068_s          cn70xx;
 	struct cvmx_pciercx_cfg068_s          cn78xx;
 	struct cvmx_pciercx_cfg068_s          cnf71xx;
 };
@@ -7442,41 +7438,45 @@ union cvmx_pciercx_cfg089 {
 	struct cvmx_pciercx_cfg089_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l1drph                       : 3;  /**< "Lane 1 Upstream Component Receiver Preset Hint
+	uint32_t l1urph                       : 3;  /**< "Lane 1 Upstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l1dtp                        : 4;  /**< "Lane 1 Upstream Component Transmitter Preset
+	uint32_t l1utp                        : 4;  /**< "Lane 1 Upstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_23_23               : 1;
-	uint32_t l1urph                       : 3;  /**< "Lane 1 Downstream Component Receiver Preset Hint
+	uint32_t l1drph                       : 3;  /**< "Lane 1 Downstream Component Receiver Preset Hint
+                                                         Writable through PEM#_CFG_WR.
+                                                         However, the application must not change this field." */
+	uint32_t l1ddtp                       : 4;  /**< "Lane 1 Downstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t reserved_15_19               : 5;
-	uint32_t l0drph                       : 3;  /**< "Lane 0 Upstream Component Receiver Preset Hint
+	uint32_t reserved_15_15               : 1;
+	uint32_t l0urph                       : 3;  /**< "Lane 0 Upstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l0dtp                        : 4;  /**< "Lane 0 Upstream Component Transmitter Preset
+	uint32_t l0utp                        : 4;  /**< "Lane 0 Upstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_7_7                 : 1;
-	uint32_t l0urph                       : 3;  /**< "Lane 0 Downstream Component Receiver Preset Hint
+	uint32_t l0drph                       : 3;  /**< "Lane 0 Downstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l0utp                        : 4;  /**< "Lane 0 Downstream Component Transmitter Preset
+	uint32_t l0dtp                        : 4;  /**< "Lane 0 Downstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 #else
-	uint32_t l0utp                        : 4;
-	uint32_t l0urph                       : 3;
-	uint32_t reserved_7_7                 : 1;
 	uint32_t l0dtp                        : 4;
 	uint32_t l0drph                       : 3;
-	uint32_t reserved_15_19               : 5;
-	uint32_t l1urph                       : 3;
-	uint32_t reserved_23_23               : 1;
-	uint32_t l1dtp                        : 4;
+	uint32_t reserved_7_7                 : 1;
+	uint32_t l0utp                        : 4;
+	uint32_t l0urph                       : 3;
+	uint32_t reserved_15_15               : 1;
+	uint32_t l1ddtp                       : 4;
 	uint32_t l1drph                       : 3;
+	uint32_t reserved_23_23               : 1;
+	uint32_t l1utp                        : 4;
+	uint32_t l1urph                       : 3;
 	uint32_t reserved_31_31               : 1;
 #endif
 	} s;
@@ -7496,45 +7496,45 @@ union cvmx_pciercx_cfg090 {
 	struct cvmx_pciercx_cfg090_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l3drph                       : 3;  /**< "Lane 3 Upstream Component Receiver Preset Hint
+	uint32_t l3urph                       : 3;  /**< "Lane 3 Upstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l3dtp                        : 4;  /**< "Lane 3 Upstream Component Transmitter Preset
+	uint32_t l3utp                        : 4;  /**< "Lane 3 Upstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_23_23               : 1;
-	uint32_t l3urph                       : 3;  /**< "Lane 3 Downstream Component Receiver Preset Hint
+	uint32_t l3drph                       : 3;  /**< "Lane 3 Downstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l3utp                        : 4;  /**< "Lane 3 Downstream Component Transmitter Preset
+	uint32_t l3dtp                        : 4;  /**< "Lane 3 Downstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_15_15               : 1;
-	uint32_t l2drph                       : 3;  /**< "Lane 2 Upstream Component Receiver Preset Hint
+	uint32_t l2urph                       : 3;  /**< "Lane 2 Upstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l2dtp                        : 4;  /**< "Lane 2 Upstream Component Transmitter Preset
+	uint32_t l2utp                        : 4;  /**< "Lane 2 Upstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_7_7                 : 1;
-	uint32_t l2urph                       : 3;  /**< "Lane 2 Downstream Component Receiver Preset Hint
+	uint32_t l2drph                       : 3;  /**< "Lane 2 Downstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l2utp                        : 4;  /**< "Lane 2 Downstream Component Transmitter Preset
+	uint32_t l2dtp                        : 4;  /**< "Lane 2 Downstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 #else
-	uint32_t l2utp                        : 4;
-	uint32_t l2urph                       : 3;
-	uint32_t reserved_7_7                 : 1;
 	uint32_t l2dtp                        : 4;
 	uint32_t l2drph                       : 3;
+	uint32_t reserved_7_7                 : 1;
+	uint32_t l2utp                        : 4;
+	uint32_t l2urph                       : 3;
 	uint32_t reserved_15_15               : 1;
-	uint32_t l3utp                        : 4;
-	uint32_t l3urph                       : 3;
-	uint32_t reserved_23_23               : 1;
 	uint32_t l3dtp                        : 4;
 	uint32_t l3drph                       : 3;
+	uint32_t reserved_23_23               : 1;
+	uint32_t l3utp                        : 4;
+	uint32_t l3urph                       : 3;
 	uint32_t reserved_31_31               : 1;
 #endif
 	} s;
@@ -7554,45 +7554,45 @@ union cvmx_pciercx_cfg091 {
 	struct cvmx_pciercx_cfg091_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l5drph                       : 3;  /**< "Lane 5 Upstream Component Receiver Preset Hint
+	uint32_t l5urph                       : 3;  /**< "Lane 5 Upstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l5dtp                        : 4;  /**< "Lane 5 Upstream Component Transmitter Preset
+	uint32_t l5utp                        : 4;  /**< "Lane 5 Upstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_23_23               : 1;
-	uint32_t l5urph                       : 3;  /**< "Lane 5 Downstream Component Receiver Preset Hint
+	uint32_t l5drph                       : 3;  /**< "Lane 5 Downstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l5utp                        : 4;  /**< "Lane 5 Downstream Component Transmitter Preset
+	uint32_t l5dtp                        : 4;  /**< "Lane 5 Downstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_15_15               : 1;
-	uint32_t l4drph                       : 3;  /**< "Lane 4 Upstream Component Receiver Preset Hint
+	uint32_t l4urph                       : 3;  /**< "Lane 4 Upstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l4dtp                        : 4;  /**< "Lane 4 Upstream Component Transmitter Preset
+	uint32_t l4utp                        : 4;  /**< "Lane 4 Upstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_7_7                 : 1;
-	uint32_t l4urph                       : 3;  /**< "Lane 4 Downstream Component Receiver Preset Hint
+	uint32_t l4drph                       : 3;  /**< "Lane 4 Downstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l4utp                        : 4;  /**< "Lane 4 Downstream Component Transmitter Preset
+	uint32_t l4dtp                        : 4;  /**< "Lane 4 Downstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 #else
-	uint32_t l4utp                        : 4;
-	uint32_t l4urph                       : 3;
-	uint32_t reserved_7_7                 : 1;
 	uint32_t l4dtp                        : 4;
 	uint32_t l4drph                       : 3;
+	uint32_t reserved_7_7                 : 1;
+	uint32_t l4utp                        : 4;
+	uint32_t l4urph                       : 3;
 	uint32_t reserved_15_15               : 1;
-	uint32_t l5utp                        : 4;
-	uint32_t l5urph                       : 3;
-	uint32_t reserved_23_23               : 1;
 	uint32_t l5dtp                        : 4;
 	uint32_t l5drph                       : 3;
+	uint32_t reserved_23_23               : 1;
+	uint32_t l5utp                        : 4;
+	uint32_t l5urph                       : 3;
 	uint32_t reserved_31_31               : 1;
 #endif
 	} s;
@@ -7612,45 +7612,45 @@ union cvmx_pciercx_cfg092 {
 	struct cvmx_pciercx_cfg092_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l7drph                       : 3;  /**< "Lane 7 Upstream Component Receiver Preset Hint
+	uint32_t l7urph                       : 3;  /**< "Lane 7 Upstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l7dtp                        : 4;  /**< "Lane 7 Upstream Component Transmitter Preset
+	uint32_t l7utp                        : 4;  /**< "Lane 7 Upstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_23_23               : 1;
-	uint32_t l7urph                       : 3;  /**< "Lane 7 Downstream Component Receiver Preset Hint
+	uint32_t l7drph                       : 3;  /**< "Lane 7 Downstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l7utp                        : 4;  /**< "Lane 7 Downstream Component Transmitter Preset
+	uint32_t l7dtp                        : 4;  /**< "Lane 7 Downstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_15_15               : 1;
-	uint32_t l6drph                       : 3;  /**< "Lane 6 Upstream Component Receiver Preset Hint
+	uint32_t l6urph                       : 3;  /**< "Lane 6 Upstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l6dtp                        : 4;  /**< "Lane 6 Upstream Component Transmitter Preset
+	uint32_t l6utp                        : 4;  /**< "Lane 6 Upstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 	uint32_t reserved_7_7                 : 1;
-	uint32_t l6urph                       : 3;  /**< "Lane 6 Downstream Component Receiver Preset Hint
+	uint32_t l6drph                       : 3;  /**< "Lane 6 Downstream Component Receiver Preset Hint
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
-	uint32_t l6utp                        : 4;  /**< "Lane 6 Downstream Component Transmitter Preset
+	uint32_t l6dtp                        : 4;  /**< "Lane 6 Downstream Component Transmitter Preset
                                                          Writable through PEM#_CFG_WR.
                                                          However, the application must not change this field." */
 #else
-	uint32_t l6utp                        : 4;
-	uint32_t l6urph                       : 3;
-	uint32_t reserved_7_7                 : 1;
 	uint32_t l6dtp                        : 4;
 	uint32_t l6drph                       : 3;
+	uint32_t reserved_7_7                 : 1;
+	uint32_t l6utp                        : 4;
+	uint32_t l6urph                       : 3;
 	uint32_t reserved_15_15               : 1;
-	uint32_t l7utp                        : 4;
-	uint32_t l7urph                       : 3;
-	uint32_t reserved_23_23               : 1;
 	uint32_t l7dtp                        : 4;
 	uint32_t l7drph                       : 3;
+	uint32_t reserved_23_23               : 1;
+	uint32_t l7utp                        : 4;
+	uint32_t l7urph                       : 3;
 	uint32_t reserved_31_31               : 1;
 #endif
 	} s;
@@ -7807,6 +7807,89 @@ union cvmx_pciercx_cfg450 {
                                                          * As the The Force Link is a pulse, writing a 1 to it does
                                                            trigger the forced link state event, even thought reading it
                                                            always returns a 0. */
+	uint32_t reserved_12_14               : 3;
+	uint32_t link_cmd                     : 4;  /**< Link Command
+                                                         The Link command that the PCI Express Core will be forced to
+                                                         transmit when bit 15 (Force Link) is set.
+                                                         Command encoding:
+                                                         o PEM_SEND_IDLE              1h
+                                                         o PEM_SEND_EIDLE             2h
+                                                         o PEM_XMT_IN_EIDLE           3h
+                                                         o PEM_MOD_COMPL_PATTERN      4h
+                                                         o PEM_SEND_RCVR_DETECT_SEQ   5h
+                                                         o PEM_SEND_TS1               6h
+                                                         o PEM_SEND_TS2               7h
+                                                         o PEM_COMPLIANCE_PATTERN     8h
+                                                         o PEM_SEND_SDS               9h
+                                                         o PEM_SEND_BEACON            ah
+                                                         o PEM_SEND_N_FTS             bh
+                                                         o PEM_NORM                   ch
+                                                         o PEM_SEND_SKP               dh
+                                                         o PEM_SEND_EIES              eh
+                                                         o PEM_SEND_EIES_SYM          fh */
+	uint32_t link_num                     : 8;  /**< Link Number */
+#else
+	uint32_t link_num                     : 8;
+	uint32_t link_cmd                     : 4;
+	uint32_t reserved_12_14               : 3;
+	uint32_t force_link                   : 1;
+	uint32_t link_state                   : 6;
+	uint32_t reserved_22_23               : 2;
+	uint32_t lpec                         : 8;
+#endif
+	} s;
+	struct cvmx_pciercx_cfg450_cn52xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t lpec                         : 8;  /**< Low Power Entrance Count
+                                                         The Power Management state will wait for this many clock cycles
+                                                         for the associated completion of a CfgWr to PCIE_CFG017 register
+                                                         Power State (PS) field register to go low-power. This register
+                                                         is intended for applications that do not let the PCI Express
+                                                         bus handle a completion for configuration request to the
+                                                         Power Management Control and Status (PCIE_CFG017) register. */
+	uint32_t reserved_22_23               : 2;
+	uint32_t link_state                   : 6;  /**< Link State
+                                                         The Link state that the PCI Express Bus will be forced to
+                                                         when bit 15 (Force Link) is set.
+                                                         State encoding:
+                                                         o DETECT_QUIET              00h
+                                                         o DETECT_ACT                01h
+                                                         o POLL_ACTIVE               02h
+                                                         o POLL_COMPLIANCE           03h
+                                                         o POLL_CONFIG               04h
+                                                         o PRE_DETECT_QUIET          05h
+                                                         o DETECT_WAIT               06h
+                                                         o CFG_LINKWD_START          07h
+                                                         o CFG_LINKWD_ACEPT          08h
+                                                         o CFG_LANENUM_WAIT          09h
+                                                         o CFG_LANENUM_ACEPT         0Ah
+                                                         o CFG_COMPLETE              0Bh
+                                                         o CFG_IDLE                  0Ch
+                                                         o RCVRY_LOCK                0Dh
+                                                         o RCVRY_SPEED               0Eh
+                                                         o RCVRY_RCVRCFG             0Fh
+                                                         o RCVRY_IDLE                10h
+                                                         o L0                        11h
+                                                         o L0S                       12h
+                                                         o L123_SEND_EIDLE           13h
+                                                         o L1_IDLE                   14h
+                                                         o L2_IDLE                   15h
+                                                         o L2_WAKE                   16h
+                                                         o DISABLED_ENTRY            17h
+                                                         o DISABLED_IDLE             18h
+                                                         o DISABLED                  19h
+                                                         o LPBK_ENTRY                1Ah
+                                                         o LPBK_ACTIVE               1Bh
+                                                         o LPBK_EXIT                 1Ch
+                                                         o LPBK_EXIT_TIMEOUT         1Dh
+                                                         o HOT_RESET_ENTRY           1Eh
+                                                         o HOT_RESET                 1Fh */
+	uint32_t force_link                   : 1;  /**< Force Link
+                                                         Forces the Link to the state specified by the Link State field.
+                                                         The Force Link pulse will trigger Link re-negotiation.
+                                                         * As the The Force Link is a pulse, writing a 1 to it does
+                                                           trigger the forced link state event, even thought reading it
+                                                           always returns a 0. */
 	uint32_t reserved_8_14                : 7;
 	uint32_t link_num                     : 8;  /**< Link Number */
 #else
@@ -7817,20 +7900,19 @@ union cvmx_pciercx_cfg450 {
 	uint32_t reserved_22_23               : 2;
 	uint32_t lpec                         : 8;
 #endif
-	} s;
-	struct cvmx_pciercx_cfg450_s          cn52xx;
-	struct cvmx_pciercx_cfg450_s          cn52xxp1;
-	struct cvmx_pciercx_cfg450_s          cn56xx;
-	struct cvmx_pciercx_cfg450_s          cn56xxp1;
-	struct cvmx_pciercx_cfg450_s          cn61xx;
-	struct cvmx_pciercx_cfg450_s          cn63xx;
-	struct cvmx_pciercx_cfg450_s          cn63xxp1;
-	struct cvmx_pciercx_cfg450_s          cn66xx;
-	struct cvmx_pciercx_cfg450_s          cn68xx;
-	struct cvmx_pciercx_cfg450_s          cn68xxp1;
+	} cn52xx;
+	struct cvmx_pciercx_cfg450_cn52xx     cn52xxp1;
+	struct cvmx_pciercx_cfg450_cn52xx     cn56xx;
+	struct cvmx_pciercx_cfg450_cn52xx     cn56xxp1;
+	struct cvmx_pciercx_cfg450_cn52xx     cn61xx;
+	struct cvmx_pciercx_cfg450_cn52xx     cn63xx;
+	struct cvmx_pciercx_cfg450_cn52xx     cn63xxp1;
+	struct cvmx_pciercx_cfg450_cn52xx     cn66xx;
+	struct cvmx_pciercx_cfg450_cn52xx     cn68xx;
+	struct cvmx_pciercx_cfg450_cn52xx     cn68xxp1;
 	struct cvmx_pciercx_cfg450_s          cn70xx;
-	struct cvmx_pciercx_cfg450_s          cn78xx;
-	struct cvmx_pciercx_cfg450_s          cnf71xx;
+	struct cvmx_pciercx_cfg450_cn52xx     cn78xx;
+	struct cvmx_pciercx_cfg450_cn52xx     cnf71xx;
 };
 typedef union cvmx_pciercx_cfg450 cvmx_pciercx_cfg450_t;
 
@@ -7990,6 +8072,75 @@ union cvmx_pciercx_cfg452 {
                                                           in the PCIe core that COULD be used. As per the PCIe specs,
                                                           the PCIe core can negotiate a smaller link width, so
                                                           x1 is also supported when LME=0x3, for example.) */
+	uint32_t reserved_12_15               : 4;
+	uint32_t link_rate                    : 4;  /**< Reserved. */
+	uint32_t flm                          : 1;  /**< Fast Link Mode
+                                                         Sets all internal timers to fast mode for simulation purposes. */
+	uint32_t reserved_6_6                 : 1;
+	uint32_t dllle                        : 1;  /**< DLL Link Enable
+                                                         Enables Link initialization. If DLL Link Enable = 0, the PCI
+                                                         Express bus does not transmit InitFC DLLPs and does not
+                                                         establish a Link. */
+	uint32_t reserved_4_4                 : 1;
+	uint32_t ra                           : 1;  /**< Reset Assert
+                                                         Triggers a recovery and forces the LTSSM to the Hot Reset
+                                                         state (downstream port only). */
+	uint32_t le                           : 1;  /**< Loopback Enable
+                                                         Initiate loopback mode as a master. On a 0->1 transition,
+                                                         the PCIe core sends TS ordered sets with the loopback bit set
+                                                         to cause the link partner to enter into loopback mode as a
+                                                         slave. Normal transmission is not possible when LE=1. To exit
+                                                         loopback mode, take the link through a reset sequence. */
+	uint32_t sd                           : 1;  /**< Scramble Disable
+                                                         Turns off data scrambling. */
+	uint32_t omr                          : 1;  /**< Other Message Request
+                                                         When software writes a `1' to this bit, the PCI Express bus
+                                                         transmits the Message contained in the Other Message register. */
+#else
+	uint32_t omr                          : 1;
+	uint32_t sd                           : 1;
+	uint32_t le                           : 1;
+	uint32_t ra                           : 1;
+	uint32_t reserved_4_4                 : 1;
+	uint32_t dllle                        : 1;
+	uint32_t reserved_6_6                 : 1;
+	uint32_t flm                          : 1;
+	uint32_t link_rate                    : 4;
+	uint32_t reserved_12_15               : 4;
+	uint32_t lme                          : 6;
+	uint32_t reserved_22_24               : 3;
+	uint32_t eccrc                        : 1;
+	uint32_t reserved_26_31               : 6;
+#endif
+	} s;
+	struct cvmx_pciercx_cfg452_cn52xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t reserved_26_31               : 6;
+	uint32_t eccrc                        : 1;  /**< Enable Corrupted CRC
+                                                         Causes corrupt LCRC for TLPs when set,
+                                                         using the pattern contained in the Other Message register.
+                                                         This is a test feature, not to be used in normal operation. */
+	uint32_t reserved_22_24               : 3;
+	uint32_t lme                          : 6;  /**< Link Mode Enable
+                                                         o 000001: x1
+                                                         o 000011: x2
+                                                         o 000111: x4
+                                                         o 001111: x8 (not supported)
+                                                         o 011111: x16 (not supported)
+                                                         o 111111: x32 (not supported)
+                                                         This field indicates the MAXIMUM number of lanes supported
+                                                         by the PCIe port. It is normally set to 0x7 or 0x3 depending
+                                                         on the value of the QLM_CFG bits (0x7 when QLM_CFG == 0x3
+                                                         otherwise 0x3). The value can be set less than 0x7 or 0x3
+                                                         to limit the number of lanes the PCIe will attempt to use.
+                                                         The programming of this field needs to be done by SW BEFORE
+                                                         enabling the link. See also MLW.
+                                                         (Note: The value of this field does NOT indicate the number
+                                                          of lanes in use by the PCIe. LME sets the max number of lanes
+                                                          in the PCIe core that COULD be used. As per the PCIe specs,
+                                                          the PCIe core can negotiate a smaller link width, so all
+                                                          of x4, x2, and x1 are supported when LME=0x7,
+                                                          for example.) */
 	uint32_t reserved_8_15                : 8;
 	uint32_t flm                          : 1;  /**< Fast Link Mode
                                                          Sets all internal timers to fast mode for simulation purposes. */
@@ -8028,11 +8179,10 @@ union cvmx_pciercx_cfg452 {
 	uint32_t eccrc                        : 1;
 	uint32_t reserved_26_31               : 6;
 #endif
-	} s;
-	struct cvmx_pciercx_cfg452_s          cn52xx;
-	struct cvmx_pciercx_cfg452_s          cn52xxp1;
-	struct cvmx_pciercx_cfg452_s          cn56xx;
-	struct cvmx_pciercx_cfg452_s          cn56xxp1;
+	} cn52xx;
+	struct cvmx_pciercx_cfg452_cn52xx     cn52xxp1;
+	struct cvmx_pciercx_cfg452_cn52xx     cn56xx;
+	struct cvmx_pciercx_cfg452_cn52xx     cn56xxp1;
 	struct cvmx_pciercx_cfg452_cn61xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_22_31               : 10;
@@ -8091,13 +8241,72 @@ union cvmx_pciercx_cfg452 {
 	uint32_t reserved_22_31               : 10;
 #endif
 	} cn61xx;
-	struct cvmx_pciercx_cfg452_s          cn63xx;
-	struct cvmx_pciercx_cfg452_s          cn63xxp1;
+	struct cvmx_pciercx_cfg452_cn52xx     cn63xx;
+	struct cvmx_pciercx_cfg452_cn52xx     cn63xxp1;
 	struct cvmx_pciercx_cfg452_cn61xx     cn66xx;
 	struct cvmx_pciercx_cfg452_cn61xx     cn68xx;
 	struct cvmx_pciercx_cfg452_cn61xx     cn68xxp1;
-	struct cvmx_pciercx_cfg452_cn61xx     cn70xx;
-	struct cvmx_pciercx_cfg452_cn61xx     cn78xx;
+	struct cvmx_pciercx_cfg452_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t reserved_22_31               : 10;
+	uint32_t lme                          : 6;  /**< Link Mode Enable
+                                                         o 000001: x1
+                                                         o 000011: x2
+                                                         o 000111: x4
+                                                         o 001111: x8  (not supported)
+                                                         o 011111: x16 (not supported)
+                                                         o 111111: x32 (not supported)
+                                                         This field indicates the MAXIMUM number of lanes supported
+                                                         by the PCIe port. The value can be set less than 0x7
+                                                         to limit the number of lanes the PCIe will attempt to use.
+                                                         The programming of this field needs to be done by SW BEFORE
+                                                         enabling the link. See also MLW.
+                                                         (Note: The value of this field does NOT indicate the number
+                                                         of lanes in use by the PCIe. LME sets the max number of lanes
+                                                         in the PCIe core that COULD be used. As per the PCIe specs,
+                                                         the PCIe core can negotiate a smaller link width, so all
+                                                         of x4, x2, and x1 are supported when LME=0x7,
+                                                         for example.) */
+	uint32_t reserved_12_15               : 4;
+	uint32_t link_rate                    : 4;  /**< Reserved. */
+	uint32_t flm                          : 1;  /**< Fast Link Mode
+                                                         Sets all internal timers to fast mode for simulation purposes. */
+	uint32_t reserved_6_6                 : 1;
+	uint32_t dllle                        : 1;  /**< DLL Link Enable
+                                                         Enables Link initialization. If DLL Link Enable = 0, the PCI
+                                                         Express bus does not transmit InitFC DLLPs and does not
+                                                         establish a Link. */
+	uint32_t reserved_4_4                 : 1;
+	uint32_t ra                           : 1;  /**< Reset Assert
+                                                         Triggers a recovery and forces the LTSSM to the Hot Reset
+                                                         state (downstream port only). */
+	uint32_t le                           : 1;  /**< Loopback Enable
+                                                         Initiate loopback mode as a master. On a 0->1 transition,
+                                                         the PCIe core sends TS ordered sets with the loopback bit set
+                                                         to cause the link partner to enter into loopback mode as a
+                                                         slave. Normal transmission is not possible when LE=1. To exit
+                                                         loopback mode, take the link through a reset sequence. */
+	uint32_t sd                           : 1;  /**< Scramble Disable
+                                                         Turns off data scrambling. */
+	uint32_t omr                          : 1;  /**< Other Message Request
+                                                         When software writes a `1' to this bit, the PCI Express bus
+                                                         transmits the Message contained in the Other Message register. */
+#else
+	uint32_t omr                          : 1;
+	uint32_t sd                           : 1;
+	uint32_t le                           : 1;
+	uint32_t ra                           : 1;
+	uint32_t reserved_4_4                 : 1;
+	uint32_t dllle                        : 1;
+	uint32_t reserved_6_6                 : 1;
+	uint32_t flm                          : 1;
+	uint32_t link_rate                    : 4;
+	uint32_t reserved_12_15               : 4;
+	uint32_t lme                          : 6;
+	uint32_t reserved_22_31               : 10;
+#endif
+	} cn70xx;
+	struct cvmx_pciercx_cfg452_cn70xx     cn78xx;
 	struct cvmx_pciercx_cfg452_cn61xx     cnf71xx;
 };
 typedef union cvmx_pciercx_cfg452 cvmx_pciercx_cfg452_t;
@@ -8246,7 +8455,25 @@ union cvmx_pciercx_cfg454 {
 	struct cvmx_pciercx_cfg454_cn61xx     cn66xx;
 	struct cvmx_pciercx_cfg454_cn61xx     cn68xx;
 	struct cvmx_pciercx_cfg454_cn52xx     cn68xxp1;
-	struct cvmx_pciercx_cfg454_cn61xx     cn70xx;
+	struct cvmx_pciercx_cfg454_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t reserved_24_31               : 8;
+	uint32_t tmanlt                       : 5;  /**< Timer Modifier for Ack/Nak Latency Timer
+                                                         Increases the timer value for the Ack/Nak latency timer, in
+                                                         increments of 64 clock cycles. */
+	uint32_t tmrt                         : 5;  /**< Timer Modifier for Replay Timer
+                                                         Increases the timer value for the replay timer, in increments
+                                                         of 64 clock cycles. */
+	uint32_t reserved_8_13                : 6;
+	uint32_t mfuncn                       : 8;  /**< Max Number of Functions Supported */
+#else
+	uint32_t mfuncn                       : 8;
+	uint32_t reserved_8_13                : 6;
+	uint32_t tmrt                         : 5;
+	uint32_t tmanlt                       : 5;
+	uint32_t reserved_24_31               : 8;
+#endif
+	} cn70xx;
 	struct cvmx_pciercx_cfg454_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_29_31               : 3;
@@ -9284,9 +9511,9 @@ union cvmx_pciercx_cfg558 {
 	struct cvmx_pciercx_cfg558_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t ple                          : 1;  /**< Pipe Loopback Enable */
-	uint32_t reserved_0_30                : 31;
+	uint32_t rxstatus                     : 31; /**< Reserved. */
 #else
-	uint32_t reserved_0_30                : 31;
+	uint32_t rxstatus                     : 31;
 	uint32_t ple                          : 1;
 #endif
 	} s;
diff --git a/arch/mips/include/asm/octeon/cvmx-pcsx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcsx-defs.h
index 856b077..d504dbe 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcsx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcsx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h
index a4ca741..d880b3d 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -57,12 +57,12 @@ static inline uint64_t CVMX_PCSXX_10GBX_STATUS_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000828ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -74,17 +74,17 @@ static inline uint64_t CVMX_PCSXX_10GBX_STATUS_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_10GBX_STATUS_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000828ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000828ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_10GBX_STATUS_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000828ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000828ull) + (block_id) * 0x8000000ull;
@@ -99,12 +99,12 @@ static inline uint64_t CVMX_PCSXX_BIST_STATUS_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000870ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -116,17 +116,17 @@ static inline uint64_t CVMX_PCSXX_BIST_STATUS_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_BIST_STATUS_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000870ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000870ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_BIST_STATUS_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000870ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000870ull) + (block_id) * 0x8000000ull;
@@ -141,12 +141,12 @@ static inline uint64_t CVMX_PCSXX_BIT_LOCK_STATUS_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000850ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -158,17 +158,17 @@ static inline uint64_t CVMX_PCSXX_BIT_LOCK_STATUS_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_BIT_LOCK_STATUS_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000850ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000850ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_BIT_LOCK_STATUS_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000850ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000850ull) + (block_id) * 0x8000000ull;
@@ -183,12 +183,12 @@ static inline uint64_t CVMX_PCSXX_CONTROL1_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000800ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -200,17 +200,17 @@ static inline uint64_t CVMX_PCSXX_CONTROL1_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_CONTROL1_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000800ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000800ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_CONTROL1_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000800ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000800ull) + (block_id) * 0x8000000ull;
@@ -225,12 +225,12 @@ static inline uint64_t CVMX_PCSXX_CONTROL2_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000818ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -242,17 +242,17 @@ static inline uint64_t CVMX_PCSXX_CONTROL2_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_CONTROL2_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000818ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000818ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_CONTROL2_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000818ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000818ull) + (block_id) * 0x8000000ull;
@@ -267,12 +267,12 @@ static inline uint64_t CVMX_PCSXX_INT_EN_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000860ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -284,17 +284,17 @@ static inline uint64_t CVMX_PCSXX_INT_EN_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_INT_EN_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000860ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000860ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_INT_EN_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000860ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000860ull) + (block_id) * 0x8000000ull;
@@ -309,12 +309,12 @@ static inline uint64_t CVMX_PCSXX_INT_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000858ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -326,17 +326,17 @@ static inline uint64_t CVMX_PCSXX_INT_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_INT_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000858ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000858ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_INT_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000858ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000858ull) + (block_id) * 0x8000000ull;
@@ -351,12 +351,12 @@ static inline uint64_t CVMX_PCSXX_LOG_ANL_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000868ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -368,17 +368,17 @@ static inline uint64_t CVMX_PCSXX_LOG_ANL_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_LOG_ANL_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000868ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000868ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_LOG_ANL_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000868ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000868ull) + (block_id) * 0x8000000ull;
@@ -393,12 +393,12 @@ static inline uint64_t CVMX_PCSXX_MISC_CTL_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000848ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -410,17 +410,17 @@ static inline uint64_t CVMX_PCSXX_MISC_CTL_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_MISC_CTL_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000848ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000848ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_MISC_CTL_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000848ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000848ull) + (block_id) * 0x8000000ull;
@@ -435,12 +435,12 @@ static inline uint64_t CVMX_PCSXX_RX_SYNC_STATES_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000838ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -452,17 +452,17 @@ static inline uint64_t CVMX_PCSXX_RX_SYNC_STATES_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_RX_SYNC_STATES_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000838ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000838ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_RX_SYNC_STATES_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000838ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000838ull) + (block_id) * 0x8000000ull;
@@ -476,24 +476,24 @@ static inline uint64_t CVMX_PCSXX_RX_SYNC_STATES_REG(unsigned long block_id)
 static inline uint64_t CVMX_PCSXX_SERDES_CRDT_CNT_REG(unsigned long block_id)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id <= 1)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id == 0)))))
 		cvmx_warn("CVMX_PCSXX_SERDES_CRDT_CNT_REG(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000880ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000880ull);
 }
 #else
-#define CVMX_PCSXX_SERDES_CRDT_CNT_REG(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000880ull) + ((block_id) & 1) * 0x8000000ull)
+#define CVMX_PCSXX_SERDES_CRDT_CNT_REG(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000880ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PCSXX_SPD_ABIL_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000810ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -505,17 +505,17 @@ static inline uint64_t CVMX_PCSXX_SPD_ABIL_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_SPD_ABIL_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000810ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000810ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_SPD_ABIL_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000810ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000810ull) + (block_id) * 0x8000000ull;
@@ -530,12 +530,12 @@ static inline uint64_t CVMX_PCSXX_STATUS1_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000808ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -547,17 +547,17 @@ static inline uint64_t CVMX_PCSXX_STATUS1_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_STATUS1_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000808ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000808ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_STATUS1_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000808ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000808ull) + (block_id) * 0x8000000ull;
@@ -572,12 +572,12 @@ static inline uint64_t CVMX_PCSXX_STATUS2_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000820ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -589,17 +589,17 @@ static inline uint64_t CVMX_PCSXX_STATUS2_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_STATUS2_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000820ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000820ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_STATUS2_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000820ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000820ull) + (block_id) * 0x8000000ull;
@@ -614,12 +614,12 @@ static inline uint64_t CVMX_PCSXX_TX_RX_POLARITY_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000840ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -631,17 +631,17 @@ static inline uint64_t CVMX_PCSXX_TX_RX_POLARITY_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_TX_RX_POLARITY_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000840ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000840ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_TX_RX_POLARITY_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000840ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000840ull) + (block_id) * 0x8000000ull;
@@ -656,12 +656,12 @@ static inline uint64_t CVMX_PCSXX_TX_RX_STATES_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			if ((block_id <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800B0000830ull) + ((block_id) & 1) * 0x8000000ull;
 			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -673,17 +673,17 @@ static inline uint64_t CVMX_PCSXX_TX_RX_STATES_REG(unsigned long block_id)
 			break;
 	}
 	cvmx_warn("CVMX_PCSXX_TX_RX_STATES_REG (block_id = %lu) not supported on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800B0000830ull) + ((block_id) & 1) * 0x8000000ull;
+	return CVMX_ADD_IO_SEG(0x00011800B0000830ull) + ((block_id) & 0) * 0x8000000ull;
 }
 #else
 static inline uint64_t CVMX_PCSXX_TX_RX_STATES_REG(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000830ull) + (block_id) * 0x8000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800B0000830ull) + (block_id) * 0x8000000ull;
diff --git a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
index a128425..d013afd 100644
--- a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -179,19 +179,44 @@ static inline uint64_t CVMX_PEMX_BAR_CTL(unsigned long block_id)
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEMX_BIST_STATUS(unsigned long block_id)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN61XX) && ((block_id <= 1))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN63XX) && ((block_id <= 1))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN66XX) && ((block_id <= 1))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN68XX) && ((block_id <= 1))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id <= 2))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((block_id <= 1)))))
-		cvmx_warn("CVMX_PEMX_BIST_STATUS(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + ((block_id) & 3) * 0x1000000ull;
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			if ((block_id <= 1))
+				return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + ((block_id) & 1) * 0x1000000ull;
+			break;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+			if ((block_id <= 2))
+				return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + ((block_id) & 3) * 0x1000000ull;
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((block_id <= 3))
+				return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + ((block_id) & 3) * 0x1000000ull;
+			break;
+	}
+	cvmx_warn("CVMX_PEMX_BIST_STATUS (block_id = %lu) not supported on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + ((block_id) & 1) * 0x1000000ull;
 }
 #else
-#define CVMX_PEMX_BIST_STATUS(block_id) (CVMX_ADD_IO_SEG(0x00011800C0000018ull) + ((block_id) & 3) * 0x1000000ull)
+static inline uint64_t CVMX_PEMX_BIST_STATUS(unsigned long block_id)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + (block_id) * 0x1000000ull;
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + (block_id) * 0x1000000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + (block_id) * 0x1000000ull;
+	}
+	return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + (block_id) * 0x1000000ull;
+}
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEMX_BIST_STATUS2(unsigned long block_id)
@@ -209,10 +234,6 @@ static inline uint64_t CVMX_PEMX_BIST_STATUS2(unsigned long block_id)
 			if ((block_id <= 2))
 				return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + ((block_id) & 3) * 0x1000000ull;
 			break;
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((block_id <= 3))
-				return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + ((block_id) & 3) * 0x1000000ull;
-			break;
 	}
 	cvmx_warn("CVMX_PEMX_BIST_STATUS2 (block_id = %lu) not supported on this chip\n", block_id);
 	return CVMX_ADD_IO_SEG(0x00011800C0000420ull) + ((block_id) & 1) * 0x1000000ull;
@@ -229,8 +250,6 @@ static inline uint64_t CVMX_PEMX_BIST_STATUS2(unsigned long block_id)
 			return CVMX_ADD_IO_SEG(0x00011800C0000420ull) + (block_id) * 0x1000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + (block_id) * 0x1000000ull;
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + (block_id) * 0x1000000ull;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800C0000420ull) + (block_id) * 0x1000000ull;
 }
@@ -328,6 +347,17 @@ static inline uint64_t CVMX_PEMX_CTL_STATUS(unsigned long block_id)
 #define CVMX_PEMX_CTL_STATUS(block_id) (CVMX_ADD_IO_SEG(0x00011800C0000000ull) + ((block_id) & 3) * 0x1000000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEMX_CTL_STATUS2(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
+		cvmx_warn("CVMX_PEMX_CTL_STATUS2(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x00011800C0000008ull) + ((block_id) & 3) * 0x1000000ull;
+}
+#else
+#define CVMX_PEMX_CTL_STATUS2(block_id) (CVMX_ADD_IO_SEG(0x00011800C0000008ull) + ((block_id) & 3) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEMX_DBG_INFO(unsigned long block_id)
 {
 	switch(cvmx_get_octeon_family()) {
@@ -378,7 +408,6 @@ static inline uint64_t CVMX_PEMX_DBG_INFO_EN(unsigned long block_id)
 	      (OCTEON_IS_MODEL(OCTEON_CN66XX) && ((block_id <= 1))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN68XX) && ((block_id <= 1))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id <= 2))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((block_id <= 1)))))
 		cvmx_warn("CVMX_PEMX_DBG_INFO_EN(%lu) is invalid on this chip\n", block_id);
 	return CVMX_ADD_IO_SEG(0x00011800C00000A0ull) + ((block_id) & 3) * 0x1000000ull;
@@ -406,26 +435,58 @@ static inline uint64_t CVMX_PEMX_DIAG_STATUS(unsigned long block_id)
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEMX_ECC_ENA(unsigned long block_id)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id <= 2))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
-		cvmx_warn("CVMX_PEMX_ECC_ENA(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800C00000C0ull) + ((block_id) & 3) * 0x1000000ull;
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+			if ((block_id <= 2))
+				return CVMX_ADD_IO_SEG(0x00011800C00000C0ull) + ((block_id) & 3) * 0x1000000ull;
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((block_id <= 3))
+				return CVMX_ADD_IO_SEG(0x00011800C0000448ull) + ((block_id) & 3) * 0x1000000ull;
+			break;
+	}
+	cvmx_warn("CVMX_PEMX_ECC_ENA (block_id = %lu) not supported on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x00011800C0000448ull) + ((block_id) & 3) * 0x1000000ull;
 }
 #else
-#define CVMX_PEMX_ECC_ENA(block_id) (CVMX_ADD_IO_SEG(0x00011800C00000C0ull) + ((block_id) & 3) * 0x1000000ull)
+static inline uint64_t CVMX_PEMX_ECC_ENA(unsigned long block_id)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800C00000C0ull) + (block_id) * 0x1000000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800C0000448ull) + (block_id) * 0x1000000ull;
+	}
+	return CVMX_ADD_IO_SEG(0x00011800C0000448ull) + (block_id) * 0x1000000ull;
+}
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEMX_ECC_SYND_CTRL(unsigned long block_id)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((block_id <= 2))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
-		cvmx_warn("CVMX_PEMX_ECC_SYND_CTRL(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x00011800C00000C8ull) + ((block_id) & 3) * 0x1000000ull;
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+			if ((block_id <= 2))
+				return CVMX_ADD_IO_SEG(0x00011800C00000C8ull) + ((block_id) & 3) * 0x1000000ull;
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((block_id <= 3))
+				return CVMX_ADD_IO_SEG(0x00011800C0000450ull) + ((block_id) & 3) * 0x1000000ull;
+			break;
+	}
+	cvmx_warn("CVMX_PEMX_ECC_SYND_CTRL (block_id = %lu) not supported on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x00011800C0000450ull) + ((block_id) & 3) * 0x1000000ull;
 }
 #else
-#define CVMX_PEMX_ECC_SYND_CTRL(block_id) (CVMX_ADD_IO_SEG(0x00011800C00000C8ull) + ((block_id) & 3) * 0x1000000ull)
+static inline uint64_t CVMX_PEMX_ECC_SYND_CTRL(unsigned long block_id)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800C00000C8ull) + (block_id) * 0x1000000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800C0000450ull) + (block_id) * 0x1000000ull;
+	}
+	return CVMX_ADD_IO_SEG(0x00011800C0000450ull) + (block_id) * 0x1000000ull;
+}
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEMX_INB_READ_CREDITS(unsigned long block_id)
@@ -483,10 +544,6 @@ static inline uint64_t CVMX_PEMX_INT_ENB(unsigned long block_id)
 			if ((block_id <= 2))
 				return CVMX_ADD_IO_SEG(0x00011800C0000430ull) + ((block_id) & 3) * 0x1000000ull;
 			break;
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((block_id <= 3))
-				return CVMX_ADD_IO_SEG(0x00011800C0000430ull) + ((block_id) & 3) * 0x1000000ull;
-			break;
 	}
 	cvmx_warn("CVMX_PEMX_INT_ENB (block_id = %lu) not supported on this chip\n", block_id);
 	return CVMX_ADD_IO_SEG(0x00011800C0000410ull) + ((block_id) & 1) * 0x1000000ull;
@@ -503,8 +560,6 @@ static inline uint64_t CVMX_PEMX_INT_ENB(unsigned long block_id)
 			return CVMX_ADD_IO_SEG(0x00011800C0000410ull) + (block_id) * 0x1000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000430ull) + (block_id) * 0x1000000ull;
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800C0000430ull) + (block_id) * 0x1000000ull;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800C0000410ull) + (block_id) * 0x1000000ull;
 }
@@ -525,10 +580,6 @@ static inline uint64_t CVMX_PEMX_INT_ENB_INT(unsigned long block_id)
 			if ((block_id <= 2))
 				return CVMX_ADD_IO_SEG(0x00011800C0000438ull) + ((block_id) & 3) * 0x1000000ull;
 			break;
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((block_id <= 3))
-				return CVMX_ADD_IO_SEG(0x00011800C0000438ull) + ((block_id) & 3) * 0x1000000ull;
-			break;
 	}
 	cvmx_warn("CVMX_PEMX_INT_ENB_INT (block_id = %lu) not supported on this chip\n", block_id);
 	return CVMX_ADD_IO_SEG(0x00011800C0000418ull) + ((block_id) & 1) * 0x1000000ull;
@@ -545,8 +596,6 @@ static inline uint64_t CVMX_PEMX_INT_ENB_INT(unsigned long block_id)
 			return CVMX_ADD_IO_SEG(0x00011800C0000418ull) + (block_id) * 0x1000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000438ull) + (block_id) * 0x1000000ull;
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800C0000438ull) + (block_id) * 0x1000000ull;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800C0000418ull) + (block_id) * 0x1000000ull;
 }
@@ -883,52 +932,54 @@ typedef union cvmx_pemx_bar_ctl cvmx_pemx_bar_ctl_t;
 /**
  * cvmx_pem#_bist_status
  *
- * Contains the diffrent interrupt summary bits of the PEM.
- *
+ * "PEM#_BIST_STATUS2 = PEM BIST Status Register
+ * Results from BIST runs of PEM's memories."
  */
 union cvmx_pemx_bist_status {
 	uint64_t u64;
 	struct cvmx_pemx_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_25_63               : 39;
-	uint64_t retrya                       : 1;  /**< Retry Buffer Memory A */
-	uint64_t retryb                       : 1;  /**< Retry Buffer Memory B */
+	uint64_t reserved_26_63               : 38;
 	uint64_t retryc                       : 1;  /**< Retry Buffer Memory C */
-	uint64_t reserved_21_21               : 1;
-	uint64_t rqhdra0                      : 1;  /**< Rx Queue Header Memory A0 */
-	uint64_t rqhdra1                      : 1;  /**< Rx Queue Header Memory A1 */
-	uint64_t rqhdra2                      : 1;  /**< Rx Queue Header Memory A2 */
-	uint64_t rqhdrb0                      : 1;  /**< Rx Queue Header Memory B0 */
-	uint64_t rqhdrb1                      : 1;  /**< Rx Queue Header Memory B1 */
-	uint64_t rqhdrb2                      : 1;  /**< Rx Queue Header Memory B2 */
-	uint64_t rqdataa0                     : 1;  /**< Rx Queue Data Memory A0 */
-	uint64_t rqdataa1                     : 1;  /**< Rx Queue Data Memory A1 */
-	uint64_t rqdataa2                     : 1;  /**< Rx Queue Data Memory A2 */
-	uint64_t rqdataa3                     : 1;  /**< Rx Queue Data Memory A3 */
-	uint64_t rqdataa4                     : 1;  /**< Rx Queue Data Memory A4 */
-	uint64_t rqdatab0                     : 1;  /**< Rx Queue Data Memory B0 */
-	uint64_t rqdatab1                     : 1;  /**< Rx Queue Data Memory B1 */
+	uint64_t reserved_24_24               : 1;
+	uint64_t rqhdrb0                      : 1;  /**< Rx Queue Header Memory Buffer 0 */
+	uint64_t rqhdrb1                      : 1;  /**< Rx Queue Header Memory Buffer 1 */
+	uint64_t rqdatab0                     : 1;  /**< Rx Queue Data Buffer 0 */
+	uint64_t rqdatab1                     : 1;  /**< Rx Queue Data Buffer 1 */
+	uint64_t tlpan_d0                     : 1;  /**< BIST Status for the tlp_n_afifo_data0 */
+	uint64_t tlpan_d1                     : 1;  /**< BIST Status for the tlp_n_afifo_data1 */
+	uint64_t tlpan_ctl                    : 1;  /**< BIST Status for the tlp_n_afifo_ctl */
+	uint64_t tlpap_d0                     : 1;  /**< BIST Status for the tlp_p_afifo_data0 */
+	uint64_t tlpap_d1                     : 1;  /**< BIST Status for the tlp_p_afifo_data1 */
+	uint64_t tlpap_ctl                    : 1;  /**< BIST Status for the tlp_p_afifo_ctl */
+	uint64_t tlpac_d0                     : 1;  /**< BIST Status for the tlp_c_afifo_data0 */
+	uint64_t tlpac_d1                     : 1;  /**< BIST Status for the tlp_c_afifo_data1 */
+	uint64_t tlpac_ctl                    : 1;  /**< BIST Status for the tlp_c_afifo_ctl */
+	uint64_t peai_p2e                     : 1;  /**< BIST Status for the peai__pesc_fifo */
+	uint64_t tlpn_d0                      : 1;  /**< BIST Status for the tlp_n_fifo_data0 */
+	uint64_t tlpn_d1                      : 1;  /**< BIST Status for the tlp_n_fifo_data1 */
 	uint64_t reserved_0_7                 : 8;
 #else
 	uint64_t reserved_0_7                 : 8;
+	uint64_t tlpn_d1                      : 1;
+	uint64_t tlpn_d0                      : 1;
+	uint64_t peai_p2e                     : 1;
+	uint64_t tlpac_ctl                    : 1;
+	uint64_t tlpac_d1                     : 1;
+	uint64_t tlpac_d0                     : 1;
+	uint64_t tlpap_ctl                    : 1;
+	uint64_t tlpap_d1                     : 1;
+	uint64_t tlpap_d0                     : 1;
+	uint64_t tlpan_ctl                    : 1;
+	uint64_t tlpan_d1                     : 1;
+	uint64_t tlpan_d0                     : 1;
 	uint64_t rqdatab1                     : 1;
 	uint64_t rqdatab0                     : 1;
-	uint64_t rqdataa4                     : 1;
-	uint64_t rqdataa3                     : 1;
-	uint64_t rqdataa2                     : 1;
-	uint64_t rqdataa1                     : 1;
-	uint64_t rqdataa0                     : 1;
-	uint64_t rqhdrb2                      : 1;
 	uint64_t rqhdrb1                      : 1;
 	uint64_t rqhdrb0                      : 1;
-	uint64_t rqhdra2                      : 1;
-	uint64_t rqhdra1                      : 1;
-	uint64_t rqhdra0                      : 1;
-	uint64_t reserved_21_21               : 1;
+	uint64_t reserved_24_24               : 1;
 	uint64_t retryc                       : 1;
-	uint64_t retryb                       : 1;
-	uint64_t retrya                       : 1;
-	uint64_t reserved_25_63               : 39;
+	uint64_t reserved_26_63               : 38;
 #endif
 	} s;
 	struct cvmx_pemx_bist_status_cn61xx {
@@ -980,59 +1031,61 @@ union cvmx_pemx_bist_status {
 	} cn70xx;
 	struct cvmx_pemx_bist_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_25_63               : 39;
-	uint64_t retrya                       : 1;  /**< Retry Buffer Memory A */
-	uint64_t retryb                       : 1;  /**< Retry Buffer Memory B */
+	uint64_t reserved_26_63               : 38;
 	uint64_t retryc                       : 1;  /**< Retry Buffer Memory C */
 	uint64_t sot                          : 1;  /**< Start of Transfer Memory */
-	uint64_t rqhdra0                      : 1;  /**< Rx Queue Header Memory A0 */
-	uint64_t rqhdra1                      : 1;  /**< Rx Queue Header Memory A1 */
-	uint64_t rqhdra2                      : 1;  /**< Rx Queue Header Memory A2 */
-	uint64_t rqhdrb0                      : 1;  /**< Rx Queue Header Memory B0 */
-	uint64_t rqhdrb1                      : 1;  /**< Rx Queue Header Memory B1 */
-	uint64_t rqhdrb2                      : 1;  /**< Rx Queue Header Memory B2 */
-	uint64_t rqdataa0                     : 1;  /**< Rx Queue Data Memory A0 */
-	uint64_t rqdataa1                     : 1;  /**< Rx Queue Data Memory A1 */
-	uint64_t rqdataa2                     : 1;  /**< Rx Queue Data Memory A2 */
-	uint64_t rqdataa3                     : 1;  /**< Rx Queue Data Memory A3 */
-	uint64_t rqdataa4                     : 1;  /**< Rx Queue Data Memory A4 */
-	uint64_t rqdatab0                     : 1;  /**< Rx Queue Data Memory B0 */
-	uint64_t rqdatab1                     : 1;  /**< Rx Queue Data Memory B1 */
-	uint64_t rqdatab2                     : 1;  /**< Rx Queue Data Memory B2 */
-	uint64_t rqdatab3                     : 1;  /**< Rx Queue Data Memory B3 */
-	uint64_t rqdatab4                     : 1;  /**< Rx Queue Data Memory B4 */
-	uint64_t rqdatac0                     : 1;  /**< Rx Queue Data Memory C0 */
-	uint64_t rqdatac1                     : 1;  /**< Rx Queue Data Memory C1 */
-	uint64_t rqdatac2                     : 1;  /**< Rx Queue Data Memory C2 */
-	uint64_t rqdatac3                     : 1;  /**< Rx Queue Data Memory C3 */
-	uint64_t rqdatac4                     : 1;  /**< Rx Queue Data Memory C4 */
-#else
-	uint64_t rqdatac4                     : 1;
-	uint64_t rqdatac3                     : 1;
-	uint64_t rqdatac2                     : 1;
-	uint64_t rqdatac1                     : 1;
-	uint64_t rqdatac0                     : 1;
-	uint64_t rqdatab4                     : 1;
-	uint64_t rqdatab3                     : 1;
-	uint64_t rqdatab2                     : 1;
+	uint64_t rqhdrb0                      : 1;  /**< Rx Queue Header Memory Buffer 0 */
+	uint64_t rqhdrb1                      : 1;  /**< Rx Queue Header Memory Buffer 1 */
+	uint64_t rqdatab0                     : 1;  /**< Rx Queue Data Buffer 0 */
+	uint64_t rqdatab1                     : 1;  /**< Rx Queue Data Buffer 1 */
+	uint64_t tlpan_d0                     : 1;  /**< BIST Status for the tlp_n_afifo_data0 */
+	uint64_t tlpan_d1                     : 1;  /**< BIST Status for the tlp_n_afifo_data1 */
+	uint64_t tlpan_ctl                    : 1;  /**< BIST Status for the tlp_n_afifo_ctl */
+	uint64_t tlpap_d0                     : 1;  /**< BIST Status for the tlp_p_afifo_data0 */
+	uint64_t tlpap_d1                     : 1;  /**< BIST Status for the tlp_p_afifo_data1 */
+	uint64_t tlpap_ctl                    : 1;  /**< BIST Status for the tlp_p_afifo_ctl */
+	uint64_t tlpac_d0                     : 1;  /**< BIST Status for the tlp_c_afifo_data0 */
+	uint64_t tlpac_d1                     : 1;  /**< BIST Status for the tlp_c_afifo_data1 */
+	uint64_t tlpac_ctl                    : 1;  /**< BIST Status for the tlp_c_afifo_ctl */
+	uint64_t peai_p2e                     : 1;  /**< BIST Status for the peai__pesc_fifo */
+	uint64_t tlpn_d0                      : 1;  /**< BIST Status for the tlp_n_fifo_data0 */
+	uint64_t tlpn_d1                      : 1;  /**< BIST Status for the tlp_n_fifo_data1 */
+	uint64_t tlpn_ctl                     : 1;  /**< BIST Status for the tlp_n_fifo_ctl */
+	uint64_t tlpp_d0                      : 1;  /**< BIST Status for the tlp_p_fifo_data0 */
+	uint64_t tlpp_d1                      : 1;  /**< BIST Status for the tlp_p_fifo_data1 */
+	uint64_t tlpp_ctl                     : 1;  /**< BIST Status for the tlp_p_fifo_ctl */
+	uint64_t tlpc_d0                      : 1;  /**< BIST Status for the tlp_c_fifo_data0 */
+	uint64_t tlpc_d1                      : 1;  /**< BIST Status for the tlp_c_fifo_data1 */
+	uint64_t tlpc_ctl                     : 1;  /**< BIST Status for the tlp_c_fifo_ctl */
+	uint64_t m2s                          : 1;  /**< BIST Status for the m2s_fifo */
+#else
+	uint64_t m2s                          : 1;
+	uint64_t tlpc_ctl                     : 1;
+	uint64_t tlpc_d1                      : 1;
+	uint64_t tlpc_d0                      : 1;
+	uint64_t tlpp_ctl                     : 1;
+	uint64_t tlpp_d1                      : 1;
+	uint64_t tlpp_d0                      : 1;
+	uint64_t tlpn_ctl                     : 1;
+	uint64_t tlpn_d1                      : 1;
+	uint64_t tlpn_d0                      : 1;
+	uint64_t peai_p2e                     : 1;
+	uint64_t tlpac_ctl                    : 1;
+	uint64_t tlpac_d1                     : 1;
+	uint64_t tlpac_d0                     : 1;
+	uint64_t tlpap_ctl                    : 1;
+	uint64_t tlpap_d1                     : 1;
+	uint64_t tlpap_d0                     : 1;
+	uint64_t tlpan_ctl                    : 1;
+	uint64_t tlpan_d1                     : 1;
+	uint64_t tlpan_d0                     : 1;
 	uint64_t rqdatab1                     : 1;
 	uint64_t rqdatab0                     : 1;
-	uint64_t rqdataa4                     : 1;
-	uint64_t rqdataa3                     : 1;
-	uint64_t rqdataa2                     : 1;
-	uint64_t rqdataa1                     : 1;
-	uint64_t rqdataa0                     : 1;
-	uint64_t rqhdrb2                      : 1;
 	uint64_t rqhdrb1                      : 1;
 	uint64_t rqhdrb0                      : 1;
-	uint64_t rqhdra2                      : 1;
-	uint64_t rqhdra1                      : 1;
-	uint64_t rqhdra0                      : 1;
 	uint64_t sot                          : 1;
 	uint64_t retryc                       : 1;
-	uint64_t retryb                       : 1;
-	uint64_t retrya                       : 1;
-	uint64_t reserved_25_63               : 39;
+	uint64_t reserved_26_63               : 38;
 #endif
 	} cn78xx;
 	struct cvmx_pemx_bist_status_cn61xx   cnf71xx;
@@ -1049,21 +1102,17 @@ union cvmx_pemx_bist_status2 {
 	uint64_t u64;
 	struct cvmx_pemx_bist_status2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_19_63               : 45;
-	uint64_t tlpn_d0                      : 1;  /**< BIST Status for the tlp_n_fifo_data0 */
-	uint64_t tlpn_d1                      : 1;  /**< BIST Status for the tlp_n_fifo_data1 */
-	uint64_t reserved_16_16               : 1;
-	uint64_t tlpp_d0                      : 1;  /**< BIST Status for the tlp_p_fifo_data0 */
-	uint64_t tlpp_d1                      : 1;  /**< BIST Status for the tlp_p_fifo_data1 */
-	uint64_t reserved_0_13                : 14;
+	uint64_t reserved_13_63               : 51;
+	uint64_t tlpn_d                       : 1;  /**< BIST Status for the tlp_n_fifo_data */
+	uint64_t tlpn_ctl                     : 1;  /**< BIST Status for the tlp_n_fifo_ctl */
+	uint64_t tlpp_d                       : 1;  /**< BIST Status for the tlp_p_fifo_data */
+	uint64_t reserved_0_9                 : 10;
 #else
-	uint64_t reserved_0_13                : 14;
-	uint64_t tlpp_d1                      : 1;
-	uint64_t tlpp_d0                      : 1;
-	uint64_t reserved_16_16               : 1;
-	uint64_t tlpn_d1                      : 1;
-	uint64_t tlpn_d0                      : 1;
-	uint64_t reserved_19_63               : 45;
+	uint64_t reserved_0_9                 : 10;
+	uint64_t tlpp_d                       : 1;
+	uint64_t tlpn_ctl                     : 1;
+	uint64_t tlpn_d                       : 1;
+	uint64_t reserved_13_63               : 51;
 #endif
 	} s;
 	struct cvmx_pemx_bist_status2_cn61xx {
@@ -1133,53 +1182,6 @@ union cvmx_pemx_bist_status2 {
 	uint64_t reserved_14_63               : 50;
 #endif
 	} cn70xx;
-	struct cvmx_pemx_bist_status2_cn78xx {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_20_63               : 44;
-	uint64_t peai_p2e                     : 1;  /**< BIST Status for the peai__pesc_fifo */
-	uint64_t tlpn_d0                      : 1;  /**< BIST Status for the tlp_n_fifo_data0 */
-	uint64_t tlpn_d1                      : 1;  /**< BIST Status for the tlp_n_fifo_data1 */
-	uint64_t tlpn_ctl                     : 1;  /**< BIST Status for the tlp_n_fifo_ctl */
-	uint64_t tlpp_d0                      : 1;  /**< BIST Status for the tlp_p_fifo_data0 */
-	uint64_t tlpp_d1                      : 1;  /**< BIST Status for the tlp_p_fifo_data1 */
-	uint64_t tlpp_ctl                     : 1;  /**< BIST Status for the tlp_p_fifo_ctl */
-	uint64_t tlpc_d0                      : 1;  /**< BIST Status for the tlp_c_fifo_data0 */
-	uint64_t tlpc_d1                      : 1;  /**< BIST Status for the tlp_c_fifo_data1 */
-	uint64_t tlpc_ctl                     : 1;  /**< BIST Status for the tlp_c_fifo_ctl */
-	uint64_t tlpan_d0                     : 1;  /**< BIST Status for the tlp_n_afifo_data0 */
-	uint64_t tlpan_d1                     : 1;  /**< BIST Status for the tlp_n_afifo_data1 */
-	uint64_t tlpan_ctl                    : 1;  /**< BIST Status for the tlp_n_afifo_ctl */
-	uint64_t tlpap_d0                     : 1;  /**< BIST Status for the tlp_p_afifo_data0 */
-	uint64_t tlpap_d1                     : 1;  /**< BIST Status for the tlp_p_afifo_data1 */
-	uint64_t tlpap_ctl                    : 1;  /**< BIST Status for the tlp_p_afifo_ctl */
-	uint64_t tlpac_d0                     : 1;  /**< BIST Status for the tlp_c_afifo_data0 */
-	uint64_t tlpac_d1                     : 1;  /**< BIST Status for the tlp_c_afifo_data1 */
-	uint64_t tlpac_ctl                    : 1;  /**< BIST Status for the tlp_c_afifo_ctl */
-	uint64_t m2s                          : 1;  /**< BIST Status for the m2s_fifo */
-#else
-	uint64_t m2s                          : 1;
-	uint64_t tlpac_ctl                    : 1;
-	uint64_t tlpac_d1                     : 1;
-	uint64_t tlpac_d0                     : 1;
-	uint64_t tlpap_ctl                    : 1;
-	uint64_t tlpap_d1                     : 1;
-	uint64_t tlpap_d0                     : 1;
-	uint64_t tlpan_ctl                    : 1;
-	uint64_t tlpan_d1                     : 1;
-	uint64_t tlpan_d0                     : 1;
-	uint64_t tlpc_ctl                     : 1;
-	uint64_t tlpc_d1                      : 1;
-	uint64_t tlpc_d0                      : 1;
-	uint64_t tlpp_ctl                     : 1;
-	uint64_t tlpp_d1                      : 1;
-	uint64_t tlpp_d0                      : 1;
-	uint64_t tlpn_ctl                     : 1;
-	uint64_t tlpn_d1                      : 1;
-	uint64_t tlpn_d0                      : 1;
-	uint64_t peai_p2e                     : 1;
-	uint64_t reserved_20_63               : 44;
-#endif
-	} cn78xx;
 	struct cvmx_pemx_bist_status2_cn61xx  cnf71xx;
 };
 typedef union cvmx_pemx_bist_status2 cvmx_pemx_bist_status2_t;
@@ -1194,20 +1196,41 @@ union cvmx_pemx_cfg {
 	uint64_t u64;
 	struct cvmx_pemx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_0_63                : 64;
+	uint64_t reserved_5_63                : 59;
+	uint64_t laneswap                     : 1;  /**< This field will overwrite the pin setting for lane swapping.
+                                                         When set, lane swapping is performed to/from the SerDes.
+                                                         When clear, no lane swapping is performed. */
+	uint64_t reserved_2_3                 : 2;
+	uint64_t md                           : 2;  /**< This field will overwrite the pin settings for speed.
+                                                         00 - EP Mode, Gen1 Speed
+                                                         01 - EP Mode, Gen2 Speed
+                                                         10 - EP Mode, Gen3 Speed
+                                                         11 - Rsvd */
 #else
-	uint64_t reserved_0_63                : 64;
+	uint64_t md                           : 2;
+	uint64_t reserved_2_3                 : 2;
+	uint64_t laneswap                     : 1;
+	uint64_t reserved_5_63                : 59;
 #endif
 	} s;
 	struct cvmx_pemx_cfg_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t laneswap                     : 1;  /**< When set, lane swapping is performed to/from the SerDes.
+	uint64_t laneswap                     : 1;  /**< This field will overwrite the pin setting for lane swapping.
+                                                         When set, lane swapping is performed to/from the SerDes.
                                                          When clear, no lane swapping is performed. */
-	uint64_t hostmd                       : 1;  /**< When set, the PEM is configured to be a Root Complex.
+	uint64_t hostmd                       : 1;  /**< This field will overwrite the pin settings for host mode.
+                                                         When set, the PEM is configured to be a Root Complex.
                                                          When clear, the PEM is configured to be an End Point. */
 	uint64_t md                           : 3;  /**< This field will overwrite the pin settings for speed and lane
-                                                         configuration:
+                                                         configuration. This value is used to set the Maximum Link Width
+                                                         field in the core's Link Capabilities Register (CFG031) to
+                                                         indicate the maximum number of lanes supported. Note that less
+                                                         lanes than the specified maximum can be configured for use via
+                                                         the core's Link Control Register (CFG032) Negotiated Link Width
+                                                         field.
+                                                         NOTE - The lower two bits of the MD field must
+                                                         be the same across all configured PEMs!
                                                            000 - Gen2 Speed, 2-lanes
                                                            001 - Gen2 Speed, 1-lane
                                                            010 - Gen2 Speed, 4-lanes
@@ -1225,22 +1248,32 @@ union cvmx_pemx_cfg {
 	} cn70xx;
 	struct cvmx_pemx_cfg_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_4_63                : 60;
-	uint64_t laneswap                     : 1;  /**< When set, lane swapping is performed to/from the SerDes.
+	uint64_t reserved_5_63                : 59;
+	uint64_t laneswap                     : 1;  /**< This field will overwrite the pin setting for lane swapping.
+                                                         When set, lane swapping is performed to/from the SerDes.
                                                          When clear, no lane swapping is performed. */
-	uint64_t lanes8                       : 1;  /**< When set, the PEM is configured for 8-lanes,
-                                                         When clear, the PEM is configured for 4-lanes */
-	uint64_t md                           : 2;  /**< When both bits are set, the PEM is configured to be a Root Complex.
-                                                         When both bits are not set, the PEM is configured to be a End Point:
-                                                           00 - EP Mode, Gen1 Speed
-                                                           01 - EP Mode, Gen2 Speed
-                                                           10 - EP Mode, Gen3 Speed
-                                                           11 - RC Mode */
+	uint64_t lanes8                       : 1;  /**< This field will overwrite the pin setting for number of lanes.
+                                                         When set, the PEM is configured for a maximum of 8-lanes,
+                                                         When clear, the PEM is configured for a maximum of 4-lanes.
+                                                         This value is used to set the Maximum Link Width field in the
+                                                         core's Link Capabilities Register (CFG031) to indicate the
+                                                         maximum number of lanes supported. Note that less lanes than
+                                                         the specified maximum can be configured for use via the core's
+                                                         Link Control Register (CFG032) Negotiated Link Width field. */
+	uint64_t hostmd                       : 1;  /**< This field will overwrite the pin settings for host mode.
+                                                         When set, the PEM is configured to be a Root Complex.
+                                                         When clear, the PEM is configured to be an End Point. */
+	uint64_t md                           : 2;  /**< This field will overwrite the pin settings for speed.
+                                                         00 - EP Mode, Gen1 Speed
+                                                         01 - EP Mode, Gen2 Speed
+                                                         10 - EP Mode, Gen3 Speed
+                                                         11 - Rsvd */
 #else
 	uint64_t md                           : 2;
+	uint64_t hostmd                       : 1;
 	uint64_t lanes8                       : 1;
 	uint64_t laneswap                     : 1;
-	uint64_t reserved_4_63                : 60;
+	uint64_t reserved_5_63                : 59;
 #endif
 	} cn78xx;
 };
@@ -1508,12 +1541,103 @@ union cvmx_pemx_ctl_status {
 	struct cvmx_pemx_ctl_status_cn61xx    cn68xx;
 	struct cvmx_pemx_ctl_status_cn61xx    cn68xxp1;
 	struct cvmx_pemx_ctl_status_s         cn70xx;
-	struct cvmx_pemx_ctl_status_s         cn78xx;
+	struct cvmx_pemx_ctl_status_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_51_63               : 13;
+	uint64_t inv_dpar                     : 1;  /**< Invert the generated parity to be written into the
+                                                         the most significant Data Queue Buffer ram block
+                                                         to force a parity error when it is later read. */
+	uint64_t reserved_48_49               : 2;
+	uint64_t auto_sd                      : 1;  /**< Link Hardware Autonomous Speed Disable. */
+	uint64_t dnum                         : 5;  /**< Primary bus device number. */
+	uint64_t pbus                         : 8;  /**< Primary bus number. */
+	uint64_t reserved_32_33               : 2;
+	uint64_t cfg_rtry                     : 16; /**< The time x 0x10000 in core clocks to wait for a
+                                                         CPL to a CFG RD that does not carry a Retry Status.
+                                                         Until such time that the timeout occurs and Retry
+                                                         Status is received for a CFG RD, the Read CFG Read
+                                                         will be resent. A value of 0 disables retries and
+                                                         treats a CPL Retry as a CPL UR.
+                                                         When enabled only one CFG RD may be issued until
+                                                         either successful completion or CPL UR. */
+	uint64_t reserved_12_15               : 4;
+	uint64_t pm_xtoff                     : 1;  /**< When WRITTEN with a '1' a single cycle pulse is
+                                                         to the PCIe core pm_xmt_turnoff port. RC mode. */
+	uint64_t pm_xpme                      : 1;  /**< When WRITTEN with a '1' a single cycle pulse is
+                                                         to the PCIe core pm_xmt_pme port. EP mode. */
+	uint64_t ob_p_cmd                     : 1;  /**< When WRITTEN with a '1' a single cycle pulse is
+                                                         to the PCIe core outband_pwrup_cmd port. EP mode. */
+	uint64_t reserved_7_8                 : 2;
+	uint64_t nf_ecrc                      : 1;  /**< Do not forward peer-to-peer ECRC TLPs. */
+	uint64_t dly_one                      : 1;  /**< When set the output client state machines will
+                                                         wait one cycle before starting a new TLP out. */
+	uint64_t lnk_enb                      : 1;  /**< When set '1' the link is enabled when '0' the
+                                                         link is disabled. This bit only is active when in
+                                                         RC mode. */
+	uint64_t ro_ctlp                      : 1;  /**< When set '1' C-TLPs that have the RO bit set will
+                                                         not wait for P-TLPs that normaly would be sent
+                                                         first. */
+	uint64_t fast_lm                      : 1;  /**< When '1' forces fast link mode. */
+	uint64_t inv_ecrc                     : 1;  /**< When '1' causes the LSB of the ECRC to be inverted. */
+	uint64_t inv_lcrc                     : 1;  /**< When '1' causes the LSB of the LCRC to be inverted. */
+#else
+	uint64_t inv_lcrc                     : 1;
+	uint64_t inv_ecrc                     : 1;
+	uint64_t fast_lm                      : 1;
+	uint64_t ro_ctlp                      : 1;
+	uint64_t lnk_enb                      : 1;
+	uint64_t dly_one                      : 1;
+	uint64_t nf_ecrc                      : 1;
+	uint64_t reserved_7_8                 : 2;
+	uint64_t ob_p_cmd                     : 1;
+	uint64_t pm_xpme                      : 1;
+	uint64_t pm_xtoff                     : 1;
+	uint64_t reserved_12_15               : 4;
+	uint64_t cfg_rtry                     : 16;
+	uint64_t reserved_32_33               : 2;
+	uint64_t pbus                         : 8;
+	uint64_t dnum                         : 5;
+	uint64_t auto_sd                      : 1;
+	uint64_t reserved_48_49               : 2;
+	uint64_t inv_dpar                     : 1;
+	uint64_t reserved_51_63               : 13;
+#endif
+	} cn78xx;
 	struct cvmx_pemx_ctl_status_cn61xx    cnf71xx;
 };
 typedef union cvmx_pemx_ctl_status cvmx_pemx_ctl_status_t;
 
 /**
+ * cvmx_pem#_ctl_status2
+ *
+ * Additional general control and status of the PEM.
+ *
+ */
+union cvmx_pemx_ctl_status2 {
+	uint64_t u64;
+	struct cvmx_pemx_ctl_status2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t no_fwd_prg                   : 16; /**< The time x 0x10000 in core clocks to wait for the
+                                                         TLP FIFOs to be able to unload an entry. If there is
+                                                         no forward progress, such that the timeout occurs,
+                                                         credits will be returned to the SLI and an interrupt
+                                                         (if enabled) will be asserted. Any more TLPs received
+                                                         will be dropped on the floor and the credits
+                                                         associated with those TLPs will be returned, as well.
+                                                         Note that 0xFFFF is a reserved value that will put
+                                                         the PEM in the 'forward progress stopped' state immediately.
+                                                         This state will hold until a mac reset is received. */
+#else
+	uint64_t no_fwd_prg                   : 16;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_pemx_ctl_status2_s        cn78xx;
+};
+typedef union cvmx_pemx_ctl_status2 cvmx_pemx_ctl_status2_t;
+
+/**
  * cvmx_pem#_dbg_info
  *
  * "PEM#_DBG_INFO = PEM Debug Information
@@ -1523,7 +1647,14 @@ union cvmx_pemx_dbg_info {
 	uint64_t u64;
 	struct cvmx_pemx_dbg_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_50_63               : 14;
+	uint64_t reserved_58_63               : 6;
+	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a Core Header Queue Bank1 double bit error */
+	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a Core Header Queue Bank1 single bit error */
+	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a Core Header Queue Bank0 double bit error */
+	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a Core Header Queue Bank0 single bit error */
+	uint64_t rtry_dbe                     : 1;  /**< Detected a Core Retry RAM double bit error */
+	uint64_t rtry_sbe                     : 1;  /**< Detected a Core Retry RAM single bit error */
+	uint64_t reserved_50_51               : 2;
 	uint64_t c_d1_dbe                     : 1;  /**< Detected a TLP CPL Fifo data1 double bit error */
 	uint64_t c_d1_sbe                     : 1;  /**< Detected a TLP CPL Fifo data1 single bit error */
 	uint64_t c_d0_dbe                     : 1;  /**< Detected a TLP CPL Fifo data0 double bit error */
@@ -1531,7 +1662,7 @@ union cvmx_pemx_dbg_info {
 	uint64_t reserved_34_45               : 12;
 	uint64_t datq_pe                      : 1;  /**< Detected a Data Queue RAM parity error */
 	uint64_t hdrq_pe                      : 1;  /**< Detected a Header Queue RAM parity error */
-	uint64_t rtry_pe                      : 1;  /**< Detected a Retry RAM parity error */
+	uint64_t reserved_31_31               : 1;
 	uint64_t ecrc_e                       : 1;  /**< Received a ECRC error.
                                                          radm_ecrc_err */
 	uint64_t rawwpp                       : 1;  /**< Received a write with poisoned payload
@@ -1639,7 +1770,7 @@ union cvmx_pemx_dbg_info {
 	uint64_t racpp                        : 1;
 	uint64_t rawwpp                       : 1;
 	uint64_t ecrc_e                       : 1;
-	uint64_t rtry_pe                      : 1;
+	uint64_t reserved_31_31               : 1;
 	uint64_t hdrq_pe                      : 1;
 	uint64_t datq_pe                      : 1;
 	uint64_t reserved_34_45               : 12;
@@ -1647,7 +1778,14 @@ union cvmx_pemx_dbg_info {
 	uint64_t c_d0_dbe                     : 1;
 	uint64_t c_d1_sbe                     : 1;
 	uint64_t c_d1_dbe                     : 1;
-	uint64_t reserved_50_63               : 14;
+	uint64_t reserved_50_51               : 2;
+	uint64_t rtry_sbe                     : 1;
+	uint64_t rtry_dbe                     : 1;
+	uint64_t qhdr_b0_sbe                  : 1;
+	uint64_t qhdr_b0_dbe                  : 1;
+	uint64_t qhdr_b1_sbe                  : 1;
+	uint64_t qhdr_b1_dbe                  : 1;
+	uint64_t reserved_58_63               : 6;
 #endif
 	} s;
 	struct cvmx_pemx_dbg_info_cn61xx {
@@ -1916,7 +2054,13 @@ union cvmx_pemx_dbg_info {
 	} cn70xx;
 	struct cvmx_pemx_dbg_info_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_52_63               : 12;
+	uint64_t reserved_58_63               : 6;
+	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a Core Header Queue Bank1 double bit error */
+	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a Core Header Queue Bank1 single bit error */
+	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a Core Header Queue Bank0 double bit error */
+	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a Core Header Queue Bank0 single bit error */
+	uint64_t rtry_dbe                     : 1;  /**< Detected a Core Retry RAM double bit error */
+	uint64_t rtry_sbe                     : 1;  /**< Detected a Core Retry RAM single bit error */
 	uint64_t c_c_dbe                      : 1;  /**< Detected a TLP CPL Fifo ctrl double bit error */
 	uint64_t c_c_sbe                      : 1;  /**< Detected a TLP CPL Fifo ctrl single bit error */
 	uint64_t c_d1_dbe                     : 1;  /**< Detected a TLP CPL Fifo data1 double bit error */
@@ -1936,8 +2080,8 @@ union cvmx_pemx_dbg_info {
 	uint64_t p_d0_dbe                     : 1;  /**< Detected a TLP Posted Fifo data0 double bit error */
 	uint64_t p_d0_sbe                     : 1;  /**< Detected a TLP Posted Fifo data0 single bit error */
 	uint64_t datq_pe                      : 1;  /**< Detected a Data Queue RAM parity error */
-	uint64_t hdrq_pe                      : 1;  /**< Detected a Header Queue RAM parity error */
-	uint64_t rtry_pe                      : 1;  /**< Detected a Retry RAM parity error */
+	uint64_t reserved_32_32               : 1;
+	uint64_t lofp                         : 1;  /**< Lack of Forward Progress at TLP FIFOs timeout occured. */
 	uint64_t ecrc_e                       : 1;  /**< Received a ECRC error.
                                                          radm_ecrc_err */
 	uint64_t rawwpp                       : 1;  /**< Received a write with poisoned payload
@@ -2048,8 +2192,8 @@ union cvmx_pemx_dbg_info {
 	uint64_t racpp                        : 1;
 	uint64_t rawwpp                       : 1;
 	uint64_t ecrc_e                       : 1;
-	uint64_t rtry_pe                      : 1;
-	uint64_t hdrq_pe                      : 1;
+	uint64_t lofp                         : 1;
+	uint64_t reserved_32_32               : 1;
 	uint64_t datq_pe                      : 1;
 	uint64_t p_d0_sbe                     : 1;
 	uint64_t p_d0_dbe                     : 1;
@@ -2069,7 +2213,13 @@ union cvmx_pemx_dbg_info {
 	uint64_t c_d1_dbe                     : 1;
 	uint64_t c_c_sbe                      : 1;
 	uint64_t c_c_dbe                      : 1;
-	uint64_t reserved_52_63               : 12;
+	uint64_t rtry_sbe                     : 1;
+	uint64_t rtry_dbe                     : 1;
+	uint64_t qhdr_b0_sbe                  : 1;
+	uint64_t qhdr_b0_dbe                  : 1;
+	uint64_t qhdr_b1_sbe                  : 1;
+	uint64_t qhdr_b1_dbe                  : 1;
+	uint64_t reserved_58_63               : 6;
 #endif
 	} cn78xx;
 	struct cvmx_pemx_dbg_info_cn61xx      cnf71xx;
@@ -2086,179 +2236,18 @@ union cvmx_pemx_dbg_info_en {
 	uint64_t u64;
 	struct cvmx_pemx_dbg_info_en_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_52_63               : 12;
-	uint64_t tpcdbe2                      : 1;  /**< Allows PEM_DBG_INFO[51] to generate an interrupt. */
-	uint64_t reserved_49_50               : 2;
-	uint64_t tpcsbe2                      : 1;  /**< Allows PEM_DBG_INFO[48] to generate an interrupt. */
-	uint64_t reserved_36_47               : 12;
-	uint64_t tpfsbe1                      : 1;  /**< Allows PEM_DBG_INFO[35] to generate an interrupt. */
-	uint64_t tpfsbe0                      : 1;  /**< Allows PEM_DBG_INFO[34] to generate an interrupt. */
-	uint64_t datq_pe                      : 1;  /**< Allows PEM_DBG_INFO[33] to generate an interrupt. */
-	uint64_t hdrq_pe                      : 1;  /**< Allows PEM_DBG_INFO[32] to generate an interrupt. */
-	uint64_t rtry_pe                      : 1;  /**< Allows PEM_DBG_INFO[31] to generate an interrupt. */
-	uint64_t ecrc_e                       : 1;  /**< Allows PEM_DBG_INFO[30] to generate an interrupt. */
-	uint64_t rawwpp                       : 1;  /**< Allows PEM_DBG_INFO[29] to generate an interrupt. */
-	uint64_t racpp                        : 1;  /**< Allows PEM_DBG_INFO[28] to generate an interrupt. */
-	uint64_t ramtlp                       : 1;  /**< Allows PEM_DBG_INFO[27] to generate an interrupt. */
-	uint64_t rarwdns                      : 1;  /**< Allows PEM_DBG_INFO[26] to generate an interrupt. */
-	uint64_t caar                         : 1;  /**< Allows PEM_DBG_INFO[25] to generate an interrupt. */
-	uint64_t racca                        : 1;  /**< Allows PEM_DBG_INFO[24] to generate an interrupt. */
-	uint64_t racur                        : 1;  /**< Allows PEM_DBG_INFO[23] to generate an interrupt. */
-	uint64_t rauc                         : 1;  /**< Allows PEM_DBG_INFO[22] to generate an interrupt. */
-	uint64_t rqo                          : 1;  /**< Allows PEM_DBG_INFO[21] to generate an interrupt. */
-	uint64_t fcuv                         : 1;  /**< Allows PEM_DBG_INFO[20] to generate an interrupt. */
-	uint64_t rpe                          : 1;  /**< Allows PEM_DBG_INFO[19] to generate an interrupt. */
-	uint64_t fcpvwt                       : 1;  /**< Allows PEM_DBG_INFO[18] to generate an interrupt. */
-	uint64_t dpeoosd                      : 1;  /**< Allows PEM_DBG_INFO[17] to generate an interrupt. */
-	uint64_t rtwdle                       : 1;  /**< Allows PEM_DBG_INFO[16] to generate an interrupt. */
-	uint64_t rdwdle                       : 1;  /**< Allows PEM_DBG_INFO[15] to generate an interrupt. */
-	uint64_t mre                          : 1;  /**< Allows PEM_DBG_INFO[14] to generate an interrupt. */
-	uint64_t rte                          : 1;  /**< Allows PEM_DBG_INFO[13] to generate an interrupt. */
-	uint64_t acto                         : 1;  /**< Allows PEM_DBG_INFO[12] to generate an interrupt. */
-	uint64_t rvdm                         : 1;  /**< Allows PEM_DBG_INFO[11] to generate an interrupt. */
-	uint64_t rumep                        : 1;  /**< Allows PEM_DBG_INFO[10] to generate an interrupt. */
-	uint64_t rptamrc                      : 1;  /**< Allows PEM_DBG_INFO[9] to generate an interrupt. */
-	uint64_t rpmerc                       : 1;  /**< Allows PEM_DBG_INFO[8] to generate an interrupt. */
-	uint64_t rfemrc                       : 1;  /**< Allows PEM_DBG_INFO[7] to generate an interrupt. */
-	uint64_t rnfemrc                      : 1;  /**< Allows PEM_DBG_INFO[6] to generate an interrupt. */
-	uint64_t rcemrc                       : 1;  /**< Allows PEM_DBG_INFO[5] to generate an interrupt. */
-	uint64_t rpoison                      : 1;  /**< Allows PEM_DBG_INFO[4] to generate an interrupt. */
-	uint64_t recrce                       : 1;  /**< Allows PEM_DBG_INFO[3] to generate an interrupt. */
-	uint64_t rtlplle                      : 1;  /**< Allows PEM_DBG_INFO[2] to generate an interrupt. */
-	uint64_t rtlpmal                      : 1;  /**< Allows PEM_DBG_INFO[1] to generate an interrupt. */
-	uint64_t spoison                      : 1;  /**< Allows PEM_DBG_INFO[0] to generate an interrupt. */
-#else
-	uint64_t spoison                      : 1;
-	uint64_t rtlpmal                      : 1;
-	uint64_t rtlplle                      : 1;
-	uint64_t recrce                       : 1;
-	uint64_t rpoison                      : 1;
-	uint64_t rcemrc                       : 1;
-	uint64_t rnfemrc                      : 1;
-	uint64_t rfemrc                       : 1;
-	uint64_t rpmerc                       : 1;
-	uint64_t rptamrc                      : 1;
-	uint64_t rumep                        : 1;
-	uint64_t rvdm                         : 1;
-	uint64_t acto                         : 1;
-	uint64_t rte                          : 1;
-	uint64_t mre                          : 1;
-	uint64_t rdwdle                       : 1;
-	uint64_t rtwdle                       : 1;
-	uint64_t dpeoosd                      : 1;
-	uint64_t fcpvwt                       : 1;
-	uint64_t rpe                          : 1;
-	uint64_t fcuv                         : 1;
-	uint64_t rqo                          : 1;
-	uint64_t rauc                         : 1;
-	uint64_t racur                        : 1;
-	uint64_t racca                        : 1;
-	uint64_t caar                         : 1;
-	uint64_t rarwdns                      : 1;
-	uint64_t ramtlp                       : 1;
-	uint64_t racpp                        : 1;
-	uint64_t rawwpp                       : 1;
-	uint64_t ecrc_e                       : 1;
-	uint64_t rtry_pe                      : 1;
-	uint64_t hdrq_pe                      : 1;
-	uint64_t datq_pe                      : 1;
-	uint64_t tpfsbe0                      : 1;
-	uint64_t tpfsbe1                      : 1;
-	uint64_t reserved_36_47               : 12;
-	uint64_t tpcsbe2                      : 1;
-	uint64_t reserved_49_50               : 2;
-	uint64_t tpcdbe2                      : 1;
-	uint64_t reserved_52_63               : 12;
-#endif
-	} s;
-	struct cvmx_pemx_dbg_info_en_cn61xx {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_31_63               : 33;
-	uint64_t ecrc_e                       : 1;  /**< Allows PEM_DBG_INFO[30] to generate an interrupt. */
-	uint64_t rawwpp                       : 1;  /**< Allows PEM_DBG_INFO[29] to generate an interrupt. */
-	uint64_t racpp                        : 1;  /**< Allows PEM_DBG_INFO[28] to generate an interrupt. */
-	uint64_t ramtlp                       : 1;  /**< Allows PEM_DBG_INFO[27] to generate an interrupt. */
-	uint64_t rarwdns                      : 1;  /**< Allows PEM_DBG_INFO[26] to generate an interrupt. */
-	uint64_t caar                         : 1;  /**< Allows PEM_DBG_INFO[25] to generate an interrupt. */
-	uint64_t racca                        : 1;  /**< Allows PEM_DBG_INFO[24] to generate an interrupt. */
-	uint64_t racur                        : 1;  /**< Allows PEM_DBG_INFO[23] to generate an interrupt. */
-	uint64_t rauc                         : 1;  /**< Allows PEM_DBG_INFO[22] to generate an interrupt. */
-	uint64_t rqo                          : 1;  /**< Allows PEM_DBG_INFO[21] to generate an interrupt. */
-	uint64_t fcuv                         : 1;  /**< Allows PEM_DBG_INFO[20] to generate an interrupt. */
-	uint64_t rpe                          : 1;  /**< Allows PEM_DBG_INFO[19] to generate an interrupt. */
-	uint64_t fcpvwt                       : 1;  /**< Allows PEM_DBG_INFO[18] to generate an interrupt. */
-	uint64_t dpeoosd                      : 1;  /**< Allows PEM_DBG_INFO[17] to generate an interrupt. */
-	uint64_t rtwdle                       : 1;  /**< Allows PEM_DBG_INFO[16] to generate an interrupt. */
-	uint64_t rdwdle                       : 1;  /**< Allows PEM_DBG_INFO[15] to generate an interrupt. */
-	uint64_t mre                          : 1;  /**< Allows PEM_DBG_INFO[14] to generate an interrupt. */
-	uint64_t rte                          : 1;  /**< Allows PEM_DBG_INFO[13] to generate an interrupt. */
-	uint64_t acto                         : 1;  /**< Allows PEM_DBG_INFO[12] to generate an interrupt. */
-	uint64_t rvdm                         : 1;  /**< Allows PEM_DBG_INFO[11] to generate an interrupt. */
-	uint64_t rumep                        : 1;  /**< Allows PEM_DBG_INFO[10] to generate an interrupt. */
-	uint64_t rptamrc                      : 1;  /**< Allows PEM_DBG_INFO[9] to generate an interrupt. */
-	uint64_t rpmerc                       : 1;  /**< Allows PEM_DBG_INFO[8] to generate an interrupt. */
-	uint64_t rfemrc                       : 1;  /**< Allows PEM_DBG_INFO[7] to generate an interrupt. */
-	uint64_t rnfemrc                      : 1;  /**< Allows PEM_DBG_INFO[6] to generate an interrupt. */
-	uint64_t rcemrc                       : 1;  /**< Allows PEM_DBG_INFO[5] to generate an interrupt. */
-	uint64_t rpoison                      : 1;  /**< Allows PEM_DBG_INFO[4] to generate an interrupt. */
-	uint64_t recrce                       : 1;  /**< Allows PEM_DBG_INFO[3] to generate an interrupt. */
-	uint64_t rtlplle                      : 1;  /**< Allows PEM_DBG_INFO[2] to generate an interrupt. */
-	uint64_t rtlpmal                      : 1;  /**< Allows PEM_DBG_INFO[1] to generate an interrupt. */
-	uint64_t spoison                      : 1;  /**< Allows PEM_DBG_INFO[0] to generate an interrupt. */
-#else
-	uint64_t spoison                      : 1;
-	uint64_t rtlpmal                      : 1;
-	uint64_t rtlplle                      : 1;
-	uint64_t recrce                       : 1;
-	uint64_t rpoison                      : 1;
-	uint64_t rcemrc                       : 1;
-	uint64_t rnfemrc                      : 1;
-	uint64_t rfemrc                       : 1;
-	uint64_t rpmerc                       : 1;
-	uint64_t rptamrc                      : 1;
-	uint64_t rumep                        : 1;
-	uint64_t rvdm                         : 1;
-	uint64_t acto                         : 1;
-	uint64_t rte                          : 1;
-	uint64_t mre                          : 1;
-	uint64_t rdwdle                       : 1;
-	uint64_t rtwdle                       : 1;
-	uint64_t dpeoosd                      : 1;
-	uint64_t fcpvwt                       : 1;
-	uint64_t rpe                          : 1;
-	uint64_t fcuv                         : 1;
-	uint64_t rqo                          : 1;
-	uint64_t rauc                         : 1;
-	uint64_t racur                        : 1;
-	uint64_t racca                        : 1;
-	uint64_t caar                         : 1;
-	uint64_t rarwdns                      : 1;
-	uint64_t ramtlp                       : 1;
-	uint64_t racpp                        : 1;
-	uint64_t rawwpp                       : 1;
-	uint64_t ecrc_e                       : 1;
-	uint64_t reserved_31_63               : 33;
-#endif
-	} cn61xx;
-	struct cvmx_pemx_dbg_info_en_cn61xx   cn63xx;
-	struct cvmx_pemx_dbg_info_en_cn61xx   cn63xxp1;
-	struct cvmx_pemx_dbg_info_en_cn61xx   cn66xx;
-	struct cvmx_pemx_dbg_info_en_cn61xx   cn68xx;
-	struct cvmx_pemx_dbg_info_en_cn61xx   cn68xxp1;
-	struct cvmx_pemx_dbg_info_en_cn70xx {
-#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_46_63               : 18;
 	uint64_t tpcdbe1                      : 1;  /**< Allows PEM_DBG_INFO[45] to generate an interrupt. */
-	uint64_t tpcdbe0                      : 1;  /**< Allows PEM_DBG_INFO[44] to generate an interrupt. */
-	uint64_t tpcsbe1                      : 1;  /**< Allows PEM_DBG_INFO[43] to generate an interrupt. */
+	uint64_t tpcsbe1                      : 1;  /**< Allows PEM_DBG_INFO[44] to generate an interrupt. */
+	uint64_t tpcdbe0                      : 1;  /**< Allows PEM_DBG_INFO[43] to generate an interrupt. */
 	uint64_t tpcsbe0                      : 1;  /**< Allows PEM_DBG_INFO[42] to generate an interrupt. */
 	uint64_t tnfdbe1                      : 1;  /**< Allows PEM_DBG_INFO[41] to generate an interrupt. */
-	uint64_t tnfdbe0                      : 1;  /**< Allows PEM_DBG_INFO[40] to generate an interrupt. */
-	uint64_t tnfsbe1                      : 1;  /**< Allows PEM_DBG_INFO[39] to generate an interrupt. */
+	uint64_t tnfsbe1                      : 1;  /**< Allows PEM_DBG_INFO[40] to generate an interrupt. */
+	uint64_t tnfdbe0                      : 1;  /**< Allows PEM_DBG_INFO[39] to generate an interrupt. */
 	uint64_t tnfsbe0                      : 1;  /**< Allows PEM_DBG_INFO[38] to generate an interrupt. */
 	uint64_t tpfdbe1                      : 1;  /**< Allows PEM_DBG_INFO[37] to generate an interrupt. */
-	uint64_t tpfdbe0                      : 1;  /**< Allows PEM_DBG_INFO[36] to generate an interrupt. */
-	uint64_t tpfsbe1                      : 1;  /**< Allows PEM_DBG_INFO[35] to generate an interrupt. */
+	uint64_t tpfsbe1                      : 1;  /**< Allows PEM_DBG_INFO[36] to generate an interrupt. */
+	uint64_t tpfdbe0                      : 1;  /**< Allows PEM_DBG_INFO[35] to generate an interrupt. */
 	uint64_t tpfsbe0                      : 1;  /**< Allows PEM_DBG_INFO[34] to generate an interrupt. */
 	uint64_t datq_pe                      : 1;  /**< Allows PEM_DBG_INFO[33] to generate an interrupt. */
 	uint64_t hdrq_pe                      : 1;  /**< Allows PEM_DBG_INFO[32] to generate an interrupt. */
@@ -2330,44 +2319,23 @@ union cvmx_pemx_dbg_info_en {
 	uint64_t hdrq_pe                      : 1;
 	uint64_t datq_pe                      : 1;
 	uint64_t tpfsbe0                      : 1;
-	uint64_t tpfsbe1                      : 1;
 	uint64_t tpfdbe0                      : 1;
+	uint64_t tpfsbe1                      : 1;
 	uint64_t tpfdbe1                      : 1;
 	uint64_t tnfsbe0                      : 1;
-	uint64_t tnfsbe1                      : 1;
 	uint64_t tnfdbe0                      : 1;
+	uint64_t tnfsbe1                      : 1;
 	uint64_t tnfdbe1                      : 1;
 	uint64_t tpcsbe0                      : 1;
-	uint64_t tpcsbe1                      : 1;
 	uint64_t tpcdbe0                      : 1;
+	uint64_t tpcsbe1                      : 1;
 	uint64_t tpcdbe1                      : 1;
 	uint64_t reserved_46_63               : 18;
 #endif
-	} cn70xx;
-	struct cvmx_pemx_dbg_info_en_cn78xx {
+	} s;
+	struct cvmx_pemx_dbg_info_en_cn61xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_52_63               : 12;
-	uint64_t tpcdbe2                      : 1;  /**< Allows PEM_DBG_INFO[51] to generate an interrupt. */
-	uint64_t tpcdbe1                      : 1;  /**< Allows PEM_DBG_INFO[50] to generate an interrupt. */
-	uint64_t tpcdbe0                      : 1;  /**< Allows PEM_DBG_INFO[49] to generate an interrupt. */
-	uint64_t tpcsbe2                      : 1;  /**< Allows PEM_DBG_INFO[48] to generate an interrupt. */
-	uint64_t tpcsbe1                      : 1;  /**< Allows PEM_DBG_INFO[47] to generate an interrupt. */
-	uint64_t tpcsbe0                      : 1;  /**< Allows PEM_DBG_INFO[46] to generate an interrupt. */
-	uint64_t tnfdbe2                      : 1;  /**< Allows PEM_DBG_INFO[45] to generate an interrupt. */
-	uint64_t tnfdbe1                      : 1;  /**< Allows PEM_DBG_INFO[44] to generate an interrupt. */
-	uint64_t tnfdbe0                      : 1;  /**< Allows PEM_DBG_INFO[43] to generate an interrupt. */
-	uint64_t tnfsbe2                      : 1;  /**< Allows PEM_DBG_INFO[42] to generate an interrupt. */
-	uint64_t tnfsbe1                      : 1;  /**< Allows PEM_DBG_INFO[41] to generate an interrupt. */
-	uint64_t tnfsbe0                      : 1;  /**< Allows PEM_DBG_INFO[40] to generate an interrupt. */
-	uint64_t tpfdbe2                      : 1;  /**< Allows PEM_DBG_INFO[39] to generate an interrupt. */
-	uint64_t tpfdbe1                      : 1;  /**< Allows PEM_DBG_INFO[38] to generate an interrupt. */
-	uint64_t tpfdbe0                      : 1;  /**< Allows PEM_DBG_INFO[37] to generate an interrupt. */
-	uint64_t tpfsbe2                      : 1;  /**< Allows PEM_DBG_INFO[36] to generate an interrupt. */
-	uint64_t tpfsbe1                      : 1;  /**< Allows PEM_DBG_INFO[35] to generate an interrupt. */
-	uint64_t tpfsbe0                      : 1;  /**< Allows PEM_DBG_INFO[34] to generate an interrupt. */
-	uint64_t datq_pe                      : 1;  /**< Allows PEM_DBG_INFO[33] to generate an interrupt. */
-	uint64_t hdrq_pe                      : 1;  /**< Allows PEM_DBG_INFO[32] to generate an interrupt. */
-	uint64_t rtry_pe                      : 1;  /**< Allows PEM_DBG_INFO[31] to generate an interrupt. */
+	uint64_t reserved_31_63               : 33;
 	uint64_t ecrc_e                       : 1;  /**< Allows PEM_DBG_INFO[30] to generate an interrupt. */
 	uint64_t rawwpp                       : 1;  /**< Allows PEM_DBG_INFO[29] to generate an interrupt. */
 	uint64_t racpp                        : 1;  /**< Allows PEM_DBG_INFO[28] to generate an interrupt. */
@@ -2431,30 +2399,15 @@ union cvmx_pemx_dbg_info_en {
 	uint64_t racpp                        : 1;
 	uint64_t rawwpp                       : 1;
 	uint64_t ecrc_e                       : 1;
-	uint64_t rtry_pe                      : 1;
-	uint64_t hdrq_pe                      : 1;
-	uint64_t datq_pe                      : 1;
-	uint64_t tpfsbe0                      : 1;
-	uint64_t tpfsbe1                      : 1;
-	uint64_t tpfsbe2                      : 1;
-	uint64_t tpfdbe0                      : 1;
-	uint64_t tpfdbe1                      : 1;
-	uint64_t tpfdbe2                      : 1;
-	uint64_t tnfsbe0                      : 1;
-	uint64_t tnfsbe1                      : 1;
-	uint64_t tnfsbe2                      : 1;
-	uint64_t tnfdbe0                      : 1;
-	uint64_t tnfdbe1                      : 1;
-	uint64_t tnfdbe2                      : 1;
-	uint64_t tpcsbe0                      : 1;
-	uint64_t tpcsbe1                      : 1;
-	uint64_t tpcsbe2                      : 1;
-	uint64_t tpcdbe0                      : 1;
-	uint64_t tpcdbe1                      : 1;
-	uint64_t tpcdbe2                      : 1;
-	uint64_t reserved_52_63               : 12;
+	uint64_t reserved_31_63               : 33;
 #endif
-	} cn78xx;
+	} cn61xx;
+	struct cvmx_pemx_dbg_info_en_cn61xx   cn63xx;
+	struct cvmx_pemx_dbg_info_en_cn61xx   cn63xxp1;
+	struct cvmx_pemx_dbg_info_en_cn61xx   cn66xx;
+	struct cvmx_pemx_dbg_info_en_cn61xx   cn68xx;
+	struct cvmx_pemx_dbg_info_en_cn61xx   cn68xxp1;
+	struct cvmx_pemx_dbg_info_en_s        cn70xx;
 	struct cvmx_pemx_dbg_info_en_cn61xx   cnf71xx;
 };
 typedef union cvmx_pemx_dbg_info_en cvmx_pemx_dbg_info_en_t;
@@ -2511,14 +2464,18 @@ typedef union cvmx_pemx_diag_status cvmx_pemx_diag_status_t;
 /**
  * cvmx_pem#_ecc_ena
  *
- * Contains enables for ECC RAMs
+ * Contains enables for TLP FIFO ECC RAMs
  *
  */
 union cvmx_pemx_ecc_ena {
 	uint64_t u64;
 	struct cvmx_pemx_ecc_ena_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
+	uint64_t reserved_35_63               : 29;
+	uint64_t qhdr_b1_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank1 RAM */
+	uint64_t qhdr_b0_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank0 RAM */
+	uint64_t rtry_ena                     : 1;  /**< ECC enable for Core's RETRY RAM */
+	uint64_t reserved_9_31                : 23;
 	uint64_t c_c_ena                      : 1;  /**< ECC enable for TLP CPL ctl Fifo */
 	uint64_t c_d1_ena                     : 1;  /**< ECC enable for TLP CPL data1 Fifo */
 	uint64_t c_d0_ena                     : 1;  /**< ECC enable for TLP CPL data0 Fifo */
@@ -2528,7 +2485,11 @@ union cvmx_pemx_ecc_ena {
 	uint64_t c_d0_ena                     : 1;
 	uint64_t c_d1_ena                     : 1;
 	uint64_t c_c_ena                      : 1;
-	uint64_t reserved_9_63                : 55;
+	uint64_t reserved_9_31                : 23;
+	uint64_t rtry_ena                     : 1;
+	uint64_t qhdr_b0_ena                  : 1;
+	uint64_t qhdr_b1_ena                  : 1;
+	uint64_t reserved_35_63               : 29;
 #endif
 	} s;
 	struct cvmx_pemx_ecc_ena_cn70xx {
@@ -2552,7 +2513,11 @@ union cvmx_pemx_ecc_ena {
 	} cn70xx;
 	struct cvmx_pemx_ecc_ena_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
+	uint64_t reserved_35_63               : 29;
+	uint64_t qhdr_b1_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank1 RAM */
+	uint64_t qhdr_b0_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank0 RAM */
+	uint64_t rtry_ena                     : 1;  /**< ECC enable for Core's RETRY RAM */
+	uint64_t reserved_9_31                : 23;
 	uint64_t c_c_ena                      : 1;  /**< ECC enable for TLP CPL ctl Fifo */
 	uint64_t c_d1_ena                     : 1;  /**< ECC enable for TLP CPL data1 Fifo */
 	uint64_t c_d0_ena                     : 1;  /**< ECC enable for TLP CPL data0 Fifo */
@@ -2572,7 +2537,11 @@ union cvmx_pemx_ecc_ena {
 	uint64_t c_d0_ena                     : 1;
 	uint64_t c_d1_ena                     : 1;
 	uint64_t c_c_ena                      : 1;
-	uint64_t reserved_9_63                : 55;
+	uint64_t reserved_9_31                : 23;
+	uint64_t rtry_ena                     : 1;
+	uint64_t qhdr_b0_ena                  : 1;
+	uint64_t qhdr_b1_ena                  : 1;
+	uint64_t reserved_35_63               : 29;
 #endif
 	} cn78xx;
 };
@@ -2582,13 +2551,17 @@ typedef union cvmx_pemx_ecc_ena cvmx_pemx_ecc_ena_t;
  * cvmx_pem#_ecc_synd_ctrl
  *
  * PEM_ECC_SYND_CTL
- * Contains Syndrome Control for ECC RAMs
+ * Contains Syndrome Control for TLP FIFO ECC RAMs
  */
 union cvmx_pemx_ecc_synd_ctrl {
 	uint64_t u64;
 	struct cvmx_pemx_ecc_synd_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_18_63               : 46;
+	uint64_t reserved_38_63               : 26;
+	uint64_t qhdr_b1_syn                  : 2;  /**< Syndrome Flip bits for Core's Q HDR Bank1 RAM */
+	uint64_t qhdr_b0_syn                  : 2;  /**< Syndrome Flip bits for Core's Q HDR Bank0 RAM */
+	uint64_t rtry_syn                     : 2;  /**< Syndrome Flip bits for Core's RETRY RAM */
+	uint64_t reserved_18_31               : 14;
 	uint64_t c_c_syn                      : 2;  /**< Syndrome Flip bits for TLP CPL ctl Fifo */
 	uint64_t c_d1_syn                     : 2;  /**< Syndrome Flip bits for TLP CPL data1 Fifo */
 	uint64_t c_d0_syn                     : 2;  /**< Syndrome Flip bits for TLP CPL data0 Fifo */
@@ -2598,7 +2571,11 @@ union cvmx_pemx_ecc_synd_ctrl {
 	uint64_t c_d0_syn                     : 2;
 	uint64_t c_d1_syn                     : 2;
 	uint64_t c_c_syn                      : 2;
-	uint64_t reserved_18_63               : 46;
+	uint64_t reserved_18_31               : 14;
+	uint64_t rtry_syn                     : 2;
+	uint64_t qhdr_b0_syn                  : 2;
+	uint64_t qhdr_b1_syn                  : 2;
+	uint64_t reserved_38_63               : 26;
 #endif
 	} s;
 	struct cvmx_pemx_ecc_synd_ctrl_cn70xx {
@@ -2622,7 +2599,11 @@ union cvmx_pemx_ecc_synd_ctrl {
 	} cn70xx;
 	struct cvmx_pemx_ecc_synd_ctrl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_18_63               : 46;
+	uint64_t reserved_38_63               : 26;
+	uint64_t qhdr_b1_syn                  : 2;  /**< Syndrome Flip bits for Core's Q HDR Bank1 RAM */
+	uint64_t qhdr_b0_syn                  : 2;  /**< Syndrome Flip bits for Core's Q HDR Bank0 RAM */
+	uint64_t rtry_syn                     : 2;  /**< Syndrome Flip bits for Core's RETRY RAM */
+	uint64_t reserved_18_31               : 14;
 	uint64_t c_c_syn                      : 2;  /**< Syndrome Flip bits for TLP CPL ctl Fifo */
 	uint64_t c_d1_syn                     : 2;  /**< Syndrome Flip bits for TLP CPL data1 Fifo */
 	uint64_t c_d0_syn                     : 2;  /**< Syndrome Flip bits for TLP CPL data0 Fifo */
@@ -2642,7 +2623,11 @@ union cvmx_pemx_ecc_synd_ctrl {
 	uint64_t c_d0_syn                     : 2;
 	uint64_t c_d1_syn                     : 2;
 	uint64_t c_c_syn                      : 2;
-	uint64_t reserved_18_63               : 46;
+	uint64_t reserved_18_31               : 14;
+	uint64_t rtry_syn                     : 2;
+	uint64_t qhdr_b0_syn                  : 2;
+	uint64_t qhdr_b1_syn                  : 2;
+	uint64_t reserved_38_63               : 26;
 #endif
 	} cn78xx;
 };
@@ -2750,7 +2735,6 @@ union cvmx_pemx_int_enb {
 	struct cvmx_pemx_int_enb_s            cn68xx;
 	struct cvmx_pemx_int_enb_s            cn68xxp1;
 	struct cvmx_pemx_int_enb_s            cn70xx;
-	struct cvmx_pemx_int_enb_s            cn78xx;
 	struct cvmx_pemx_int_enb_s            cnf71xx;
 };
 typedef union cvmx_pemx_int_enb cvmx_pemx_int_enb_t;
@@ -2819,7 +2803,6 @@ union cvmx_pemx_int_enb_int {
 	struct cvmx_pemx_int_enb_int_s        cn68xx;
 	struct cvmx_pemx_int_enb_int_s        cn68xxp1;
 	struct cvmx_pemx_int_enb_int_s        cn70xx;
-	struct cvmx_pemx_int_enb_int_s        cn78xx;
 	struct cvmx_pemx_int_enb_int_s        cnf71xx;
 };
 typedef union cvmx_pemx_int_enb_int cvmx_pemx_int_enb_int_t;
@@ -2834,6 +2817,57 @@ union cvmx_pemx_int_sum {
 	uint64_t u64;
 	struct cvmx_pemx_int_sum_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. */
+	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. */
+	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. */
+	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. */
+	uint64_t reserved_14_59               : 46;
+	uint64_t crs_dr                       : 1;  /**< Had a CRS Timeout when Retries were disabled. */
+	uint64_t crs_er                       : 1;  /**< Had a CRS Timeout when Retries were enabled. */
+	uint64_t rdlk                         : 1;  /**< Received Read Lock TLP. */
+	uint64_t exc                          : 1;  /**< Set when the PEM_DBG_INFO register has a bit
+                                                         set and its cooresponding PEM_DBG_INFO_EN bit
+                                                         is set. */
+	uint64_t un_bx                        : 1;  /**< Received N-TLP for an unknown Bar. */
+	uint64_t un_b2                        : 1;  /**< Received N-TLP for Bar2 when bar2 is disabled. */
+	uint64_t un_b1                        : 1;  /**< Received N-TLP for Bar1 when bar1 index valid
+                                                         is not set. */
+	uint64_t up_bx                        : 1;  /**< Received P-TLP for an unknown Bar. */
+	uint64_t up_b2                        : 1;  /**< Received P-TLP for Bar2 when bar2 is disabeld. */
+	uint64_t up_b1                        : 1;  /**< Received P-TLP for Bar1 when bar1 index valid
+                                                         is not set. */
+	uint64_t pmem                         : 1;  /**< Recived PME MSG.
+                                                         (radm_pm_pme) */
+	uint64_t pmei                         : 1;  /**< PME Interrupt.
+                                                         (cfg_pme_int) */
+	uint64_t se                           : 1;  /**< System Error, RC Mode Only.
+                                                         (cfg_sys_err_rc) */
+	uint64_t aeri                         : 1;  /**< Advanced Error Reporting Interrupt, RC Mode Only.
+                                                         (cfg_aer_rc_err_int). */
+#else
+	uint64_t aeri                         : 1;
+	uint64_t se                           : 1;
+	uint64_t pmei                         : 1;
+	uint64_t pmem                         : 1;
+	uint64_t up_b1                        : 1;
+	uint64_t up_b2                        : 1;
+	uint64_t up_bx                        : 1;
+	uint64_t un_b1                        : 1;
+	uint64_t un_b2                        : 1;
+	uint64_t un_bx                        : 1;
+	uint64_t exc                          : 1;
+	uint64_t rdlk                         : 1;
+	uint64_t crs_er                       : 1;
+	uint64_t crs_dr                       : 1;
+	uint64_t reserved_14_59               : 46;
+	uint64_t inta                         : 1;
+	uint64_t intb                         : 1;
+	uint64_t intc                         : 1;
+	uint64_t intd                         : 1;
+#endif
+	} s;
+	struct cvmx_pemx_int_sum_cn61xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
 	uint64_t crs_dr                       : 1;  /**< Had a CRS Timeout when Retries were disabled. */
 	uint64_t crs_er                       : 1;  /**< Had a CRS Timeout when Retries were enabled. */
@@ -2874,16 +2908,62 @@ union cvmx_pemx_int_sum {
 	uint64_t crs_dr                       : 1;
 	uint64_t reserved_14_63               : 50;
 #endif
-	} s;
-	struct cvmx_pemx_int_sum_s            cn61xx;
-	struct cvmx_pemx_int_sum_s            cn63xx;
-	struct cvmx_pemx_int_sum_s            cn63xxp1;
-	struct cvmx_pemx_int_sum_s            cn66xx;
-	struct cvmx_pemx_int_sum_s            cn68xx;
-	struct cvmx_pemx_int_sum_s            cn68xxp1;
-	struct cvmx_pemx_int_sum_s            cn70xx;
-	struct cvmx_pemx_int_sum_s            cn78xx;
-	struct cvmx_pemx_int_sum_s            cnf71xx;
+	} cn61xx;
+	struct cvmx_pemx_int_sum_cn61xx       cn63xx;
+	struct cvmx_pemx_int_sum_cn61xx       cn63xxp1;
+	struct cvmx_pemx_int_sum_cn61xx       cn66xx;
+	struct cvmx_pemx_int_sum_cn61xx       cn68xx;
+	struct cvmx_pemx_int_sum_cn61xx       cn68xxp1;
+	struct cvmx_pemx_int_sum_cn61xx       cn70xx;
+	struct cvmx_pemx_int_sum_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. */
+	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. */
+	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. */
+	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. */
+	uint64_t reserved_14_59               : 46;
+	uint64_t crs_dr                       : 1;  /**< Had a CRS Timeout when Retries were disabled. */
+	uint64_t crs_er                       : 1;  /**< Had a CRS Timeout when Retries were enabled. */
+	uint64_t rdlk                         : 1;  /**< Received Read Lock TLP. */
+	uint64_t reserved_10_10               : 1;
+	uint64_t un_bx                        : 1;  /**< Received N-TLP for an unknown Bar. */
+	uint64_t un_b2                        : 1;  /**< Received N-TLP for Bar2 when bar2 is disabled. */
+	uint64_t un_b1                        : 1;  /**< Received N-TLP for Bar1 when bar1 index valid
+                                                         is not set. */
+	uint64_t up_bx                        : 1;  /**< Received P-TLP for an unknown Bar. */
+	uint64_t up_b2                        : 1;  /**< Received P-TLP for Bar2 when bar2 is disabeld. */
+	uint64_t up_b1                        : 1;  /**< Received P-TLP for Bar1 when bar1 index valid
+                                                         is not set. */
+	uint64_t reserved_3_3                 : 1;
+	uint64_t pmei                         : 1;  /**< PME Interrupt.
+                                                         (cfg_pme_int) */
+	uint64_t se                           : 1;  /**< System Error, RC DEode Only.
+                                                         (cfg_sys_err_rc) */
+	uint64_t aeri                         : 1;  /**< Advanced Error Reporting Interrupt, RC Mode Only.
+                                                         (cfg_aer_rc_err_int). */
+#else
+	uint64_t aeri                         : 1;
+	uint64_t se                           : 1;
+	uint64_t pmei                         : 1;
+	uint64_t reserved_3_3                 : 1;
+	uint64_t up_b1                        : 1;
+	uint64_t up_b2                        : 1;
+	uint64_t up_bx                        : 1;
+	uint64_t un_b1                        : 1;
+	uint64_t un_b2                        : 1;
+	uint64_t un_bx                        : 1;
+	uint64_t reserved_10_10               : 1;
+	uint64_t rdlk                         : 1;
+	uint64_t crs_er                       : 1;
+	uint64_t crs_dr                       : 1;
+	uint64_t reserved_14_59               : 46;
+	uint64_t inta                         : 1;
+	uint64_t intb                         : 1;
+	uint64_t intc                         : 1;
+	uint64_t intd                         : 1;
+#endif
+	} cn78xx;
+	struct cvmx_pemx_int_sum_cn61xx       cnf71xx;
 };
 typedef union cvmx_pemx_int_sum cvmx_pemx_int_sum_t;
 
diff --git a/arch/mips/include/asm/octeon/cvmx-pescx-defs.h b/arch/mips/include/asm/octeon/cvmx-pescx-defs.h
index 354e0d4..58f27d4 100644
--- a/arch/mips/include/asm/octeon/cvmx-pescx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pescx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-pexp-defs.h b/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
index 19979ad..f9eede7 100644
--- a/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1723,13 +1723,12 @@ static inline uint64_t CVMX_PEXP_SLI_PKTX_INSTR_HEADER(unsigned long offset)
 	      (OCTEON_IS_MODEL(OCTEON_CN66XX) && ((offset <= 31))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN68XX) && ((offset <= 31))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((offset <= 31))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 63))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PEXP_SLI_PKTX_INSTR_HEADER(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000013400ull) + ((offset) & 63) * 16;
+	return CVMX_ADD_IO_SEG(0x00011F0000013400ull) + ((offset) & 31) * 16;
 }
 #else
-#define CVMX_PEXP_SLI_PKTX_INSTR_HEADER(offset) (CVMX_ADD_IO_SEG(0x00011F0000013400ull) + ((offset) & 63) * 16)
+#define CVMX_PEXP_SLI_PKTX_INSTR_HEADER(offset) (CVMX_ADD_IO_SEG(0x00011F0000013400ull) + ((offset) & 31) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEXP_SLI_PKTX_IN_BP(unsigned long offset)
diff --git a/arch/mips/include/asm/octeon/cvmx-pip-defs.h b/arch/mips/include/asm/octeon/cvmx-pip-defs.h
index 614ed1d..e50242c 100644
--- a/arch/mips/include/asm/octeon/cvmx-pip-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pip-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-cluster.h b/arch/mips/include/asm/octeon/cvmx-pki-cluster.h
new file mode 100644
index 0000000..66cd876
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-pki-cluster.h
@@ -0,0 +1,636 @@
+/* This file is autgenerated from obj/ipemainc.elf */
+const int cvmx_pki_cluster_code_length = 632;
+const uint64_t cvmx_pki_cluster_code_default[] = {
+    0x000000000a000000ull,
+    0x0000413a68024070ull,
+    0x0000813800200020ull,
+    0x900081b800200020ull,
+    0x0004dd80ffff0001ull,
+    0x000455ab68010b0eull,
+    0x00045fba46010000ull,
+    0x9046898120002000ull,
+    0x0004418068010028ull,
+    0x90665326680100f0ull,
+    0x0004413f68004070ull,
+    0x000653a7680100f0ull,
+    0x00045dbb6803a0f0ull,
+    0x000401bb48000001ull,
+    0x00045cb968030870ull,
+    0x0007debd00100010ull,
+    0x0000813b80008000ull,
+    0x0004413b68004070ull,
+    0x9001c00000000000ull,
+    0x9021c00000000000ull,
+    0x00044180680100f0ull,
+    0x0004c639ff000200ull,
+    0x0004400172030000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000041ba68034078ull,
+    0x0000512268030870ull,
+    0x000041bc68034070ull,
+    0x00005d3a68030870ull,
+    0x000483891f000000ull,
+    0x000f542868090a48ull,
+    0x000f583068020070ull,
+    0x00045cb942080000ull,
+    0x0004552a4e09312dull,
+    0x00045cb968082868ull,
+    0x0004410246090000ull,
+    0x0000813901000000ull,
+    0x000481b800010001ull,
+    0x000685b800020002ull,
+    0xa006823800010001ull,
+    0x0006c639ff000500ull,
+    0xa0685f3e68010405ull,
+    0x0008418368010800ull,
+    0xa0485f3e68010305ull,
+    0xa4085f3e68010028ull,
+    0xa441c00000000000ull,
+    0x0009418368010030ull,
+    0xa466400172030001ull,
+    0x00095f3e68030030ull,
+    0x00095f3e68010416ull,
+    0x0006debd00010001ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x9000813901000000ull,
+    0x0004c639ff000a00ull,
+    0x0004400072010000ull,
+    0x00048181ffffffffull,
+    0x0007820101000100ull,
+    0x00048301ffff0180ull,
+    0x0008d5ab10001000ull,
+    0x0004d4a900010001ull,
+    0x0001c00000000000ull,
+    0x00045cb942080000ull,
+    0x9024552a4e09312dull,
+    0x0004c639ff000b00ull,
+    0x90445f80680100f0ull,
+    0x000459b368020070ull,
+    0x000401024000000cull,
+    0x0006823fffffffffull,
+    0x00088281ffffffffull,
+    0x000ad5ab20002000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0004403f72010001ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000c8b3fffffc200ull,
+    0x000c8b01ffff0001ull,
+    0x000ddebd00020002ull,
+    0x00045cb942080000ull,
+    0x0004552a4e09312dull,
+    0x00045cb968082868ull,
+    0x0004410246090000ull,
+    0x0000813901000000ull,
+    0x000481b800080008ull,
+    0x9846c639ff001200ull,
+    0x9861c00000000000ull,
+    0x00064180680100f0ull,
+    0x0006400372010000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000683891f000200ull,
+    0x000ed52a00800080ull,
+    0x000e5e3c68020070ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x0000813d00020002ull,
+    0x0004893901000000ull,
+    0x9004893800040004ull,
+    0x9024c639ff001300ull,
+    0x00044180680100f0ull,
+    0x9044400372010001ull,
+    0x0001c00000000000ull,
+    0x00045f3e68010044ull,
+    0x0004debd00040004ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000483891f000200ull,
+    0x000ed52a00800080ull,
+    0x000e5e3c68020070ull,
+    0x00045cb942080000ull,
+    0x0004552a4e09312dull,
+    0x00045cb968082868ull,
+    0x0004410246090000ull,
+    0x000581b902000000ull,
+    0x9826c639ff001800ull,
+    0x9801c00000000000ull,
+    0x00064180680100f0ull,
+    0x0006400172030000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000682091f000200ull,
+    0x000883aa00800080ull,
+    0x000ed52a00400040ull,
+    0x000e5e3c68020870ull,
+    0x000fd52a00800080ull,
+    0x000f5e3c68020070ull,
+    0x000983891f000000ull,
+    0x000f54a968090148ull,
+    0x000f59b368020870ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x000081b902000000ull,
+    0x9826c639ff001900ull,
+    0x9801c00000000000ull,
+    0x00064180680100f0ull,
+    0x0006400172030001ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000682091f000200ull,
+    0x000883aa00800080ull,
+    0x000ed52a00400040ull,
+    0x000e5e3c68020870ull,
+    0x000fd52a00800080ull,
+    0x000f5e3c68020070ull,
+    0x000983891f000000ull,
+    0x000f54a968090148ull,
+    0x000f59b368020870ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x000081b902000000ull,
+    0x9826c639ff001a00ull,
+    0x9801c00000000000ull,
+    0x00064180680100f0ull,
+    0x0006400172030000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000682091f000200ull,
+    0x000883aa00800080ull,
+    0x000ed52a00400040ull,
+    0x000e5e3c68020870ull,
+    0x000fd52a00800080ull,
+    0x000f5e3c68020070ull,
+    0x000983891f000000ull,
+    0x000f54a968090148ull,
+    0x000f59b368020870ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x000081b902000000ull,
+    0x9826c639ff001b00ull,
+    0x9801c00000000000ull,
+    0x00064180680100f0ull,
+    0x0006400172030001ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000682091f000200ull,
+    0x000883aa00800080ull,
+    0x000ed52a00400040ull,
+    0x000e5e3c68020870ull,
+    0x000fd52a00800080ull,
+    0x000f5e3c68020070ull,
+    0x000983891f000000ull,
+    0x000f54a968090148ull,
+    0x000f59b368020870ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x9000813902000000ull,
+    0x000481b800400040ull,
+    0x00004180680100f0ull,
+    0x00068981ffff8847ull,
+    0x00068581ffff8848ull,
+    0x0006debd00080008ull,
+    0x9806c639ff001e00ull,
+    0x9821c00000000000ull,
+    0x00065f80680100f0ull,
+    0x0006403f72010000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006823902000000ull,
+    0x0008010240000002ull,
+    0xac28828101000100ull,
+    0x000b010240000002ull,
+    0xa42b820101000100ull,
+    0x0009010240000002ull,
+    0xac29828101000100ull,
+    0x000b010240000002ull,
+    0xa42b820101000100ull,
+    0x0009010240000002ull,
+    0xac29828101000100ull,
+    0x000b010240000002ull,
+    0x00065f3e68010629ull,
+    0x00040183840005ffull,
+    0x0006010240000008ull,
+    0x9801c00000000000ull,
+    0x0006debd00200020ull,
+    0x00048181ffff0806ull,
+    0x0006d4a907c00180ull,
+    0x00048201ffff8035ull,
+    0x00068581ffff8035ull,
+    0x0008d4a907c001c0ull,
+    0x0006dcb97c007c00ull,
+    0x00048201ffff0800ull,
+    0x00088601ffff86ddull,
+    0x00068581ffff0800ull,
+    0x00068581ffff86ddull,
+    0x0008d4a907c00200ull,
+    0x0007823d00200020ull,
+    0x000685bd00200020ull,
+    0x0008d4a907c00140ull,
+    0x0006010240000002ull,
+    0x8001c00000000000ull,
+    0x0006593268020070ull,
+    0x000315ab74000227ull,
+    0x9000813904000000ull,
+    0x0001c00000000000ull,
+    0x00048181f0004000ull,
+    0x9886593268020070ull,
+    0x0006d4a907c00200ull,
+    0x00068201ff000000ull,
+    0xa40815ab74000345ull,
+    0x0009debd01000100ull,
+    0x0009418068010038ull,
+    0x0009028386000005ull,
+    0xac8a15ab74000343ull,
+    0x000b5a3468010870ull,
+    0x000b5a3468010070ull,
+    0xac6b8203000f0005ull,
+    0x0009d4a907c00240ull,
+    0x000b820120000000ull,
+    0x000886011fff0000ull,
+    0x0009552a6801000dull,
+    0x0009d4a9f8006800ull,
+    0x0009593268020870ull,
+    0x0006418068030230ull,
+    0x0006410242030000ull,
+    0x9c01c00000000000ull,
+    0x0001c00000000000ull,
+    0x00078201f0006000ull,
+    0x0008593268020070ull,
+    0xa068d4a907c00280ull,
+    0x00085a3468010874ull,
+    0x0008818100ff0000ull,
+    0x000615ab74000345ull,
+    0x00075a3468010078ull,
+    0x0007010240000028ull,
+    0xa80782b400ff0000ull,
+    0x000ad4a907c002c0ull,
+    0x000a5a3468010078ull,
+    0x000a410244010000ull,
+    0xa80782b400ff003cull,
+    0x000ad4a907c002c0ull,
+    0x000a5a3468010078ull,
+    0x000a410244010000ull,
+    0xa80782b400ff002bull,
+    0x000ad4a907c002c0ull,
+    0x000a5a3468010078ull,
+    0x000a410244010000ull,
+    0xa80782b400ff002cull,
+    0x000ad4a9ffc06ac0ull,
+    0x000a593268020870ull,
+    0x000ad52a00010001ull,
+    0x000a5a3468010078ull,
+    0x0007debd01000100ull,
+    0x000481bd01000100ull,
+    0x0006c639ff002300ull,
+    0x000641aa68034000ull,
+    0x000641a968034846ull,
+    0x0006403472030001ull,
+    0x0004822902000200ull,
+    0x000915ab74000341ull,
+    0x000082aa00010001ull,
+    0x000a86ab00ff0045ull,
+    0x000adcb978007800ull,
+    0x00008229fa006a00ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x8001c00000000000ull,
+    0x00088a3908000000ull,
+    0xa02315ab74000343ull,
+    0x000881b400ff0011ull,
+    0x00068981ffff2118ull,
+    0x0006593268020870ull,
+    0x0006d4a9f8009800ull,
+    0x9c26debd02000200ull,
+    0x0007813400ff002full,
+    0x00048901ffff6558ull,
+    0x0004593268020870ull,
+    0x0004d4a9f800a800ull,
+    0x0004debd02000200ull,
+    0x000882bd02000200ull,
+    0xa86ac639ff002800ull,
+    0xa841c00000000000ull,
+    0x000a418368010878ull,
+    0x000a400172030000ull,
+    0x000a5bb768030078ull,
+    0x000a5b36680100f0ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000a5cb942080000ull,
+    0x000a552a4e09312dull,
+    0x000a5cb968082868ull,
+    0x000a410246090000ull,
+    0x0000812907c004c0ull,
+    0x0004852907c00540ull,
+    0x9004893910000000ull,
+    0x0001c00000000000ull,
+    0x00048181f0004000ull,
+    0x988658b168020070ull,
+    0x0006d428001f0008ull,
+    0x00068201ff000000ull,
+    0xa40815ab74000545ull,
+    0x0009debd04000400ull,
+    0x0009418068010038ull,
+    0x0009028384000004ull,
+    0xac8a15ab74000543ull,
+    0x000b5a3468010870ull,
+    0x000b5a3468010070ull,
+    0xac6b8303000f0005ull,
+    0x000dd428001f0009ull,
+    0x000b830120000000ull,
+    0x000c87011fff0000ull,
+    0x000dd42803e001a0ull,
+    0x000d58b168020870ull,
+    0x000ddcb960006000ull,
+    0x0006418068030230ull,
+    0x0006410242030000ull,
+    0x9c01c00000000000ull,
+    0x0001c00000000000ull,
+    0x00078201f0006000ull,
+    0x000858b168020070ull,
+    0xa068d428001f000aull,
+    0x00085a3468010874ull,
+    0x0008818100ff0000ull,
+    0x000615ab74000545ull,
+    0x00075a3468010078ull,
+    0x0007010240000028ull,
+    0xa80782b400ff0000ull,
+    0x000ad428001f000bull,
+    0x000a5a3468010078ull,
+    0x000a410244010000ull,
+    0xa80782b400ff003cull,
+    0x000ad428001f000bull,
+    0x000a5a3468010078ull,
+    0x000a410244010000ull,
+    0xa80782b400ff002bull,
+    0x000ad428001f000bull,
+    0x000a5a3468010078ull,
+    0x000a410244010000ull,
+    0xa80782b400ff002cull,
+    0x000ad42803ff01abull,
+    0x000adcb960006000ull,
+    0x000a58b168020870ull,
+    0x000a5a3468010078ull,
+    0x0007debd04000400ull,
+    0x000481bd04000400ull,
+    0x0006c639ff002b00ull,
+    0x000641aa68034000ull,
+    0x000641a868034840ull,
+    0x0006403472030001ull,
+    0x0004822902000200ull,
+    0x000815ab74000541ull,
+    0x000082ab00ff0045ull,
+    0x000adcb960006000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x8001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000315ab74000561ull,
+    0x0000813920000000ull,
+    0x000481b400ff006cull,
+    0x0006d42803e001c0ull,
+    0x000658b168020870ull,
+    0x0007823400ff0032ull,
+    0xa048863400ff0033ull,
+    0x0008d42803e00180ull,
+    0xa0685ab5680100f0ull,
+    0x000858b168020870ull,
+    0x00085dbb680100f0ull,
+    0x986981b400ff002full,
+    0x0006d42803e00280ull,
+    0x00065ab5680100f0ull,
+    0x000658b168020870ull,
+    0x0004823400ff0011ull,
+    0x0008d42803e00220ull,
+    0x000481b400ff0084ull,
+    0x0008863400ff0084ull,
+    0x0006d42803e00240ull,
+    0x000481b400ff0006ull,
+    0x98c8863400ff0006ull,
+    0x0006d42803e00200ull,
+    0x90265ebd68010b31ull,
+    0x0004c639ff003000ull,
+    0x0004403472010000ull,
+    0x000858b168020870ull,
+    0x00088181ffff0000ull,
+    0x000615ab74000664ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000081b800100010ull,
+    0x00045cb942080000ull,
+    0x0004552a4e09312dull,
+    0x00045cb968082868ull,
+    0x0004410246090000ull,
+    0x000483891f000000ull,
+    0x000f542868090a48ull,
+    0x000f583068020070ull,
+    0x000689b940004000ull,
+    0x000689a803e00000ull,
+    0x000641b168004078ull,
+    0x0006413842030000ull,
+    0x9801c00000000000ull,
+    0x9821c00000000000ull,
+    0x00064180680100f0ull,
+    0x0006c639ff003900ull,
+    0x0006400172030001ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000683891f000000ull,
+    0x000f542868090a48ull,
+    0x000f583068020070ull,
+    0x00065cb942080000ull,
+    0x0006552a4e09312dull,
+    0x00065cb968082868ull,
+    0x0006410246090000ull,
+    0x00005fb968004250ull,
+    0x0000003f70000000ull,
+    0x000041b968034070ull,
+    0x0000512268030070ull,
+    0x0000813800200020ull,
+    0x0004413a68024070ull,
+    0x9001c00000000000ull,
+    0x000081b800200020ull,
+    0x9026898180008000ull,
+    0x0004890110001000ull,
+    0x000456ad680100a0ull,
+    0x0006898180008000ull,
+    0x000652a56801001dull,
+    0x000456ad68090b5bull,
+    0x000556ad680900f0ull,
+    0x0000562c680800f0ull,
+    0x0000833d00200020ull,
+    0x000c872907c00000ull,
+    0x000dd62c20000000ull,
+    0x0000822902800280ull,
+    0x000841b268034070ull,
+    0x000982a802800280ull,
+    0x000a41b168034070ull,
+    0x000b822907c00000ull,
+    0x0000003f70000800ull,
+    0x000941b268034070ull,
+    0x0000418048030000ull,
+    0x0000018340000008ull,
+    0x0009018348000004ull,
+    0x000050a168030c20ull,
+    0x000082aa00800080ull,
+    0x000850a168080c2bull,
+    0x000752a56808001eull,
+    0x000a822a00400040ull,
+    0x00088a0900010001ull,
+    0x000841bc68034078ull,
+    0x000941bc68034070ull,
+    0x000a583068030870ull,
+    0x0005c180ffff0000ull,
+    0x00058288001e0000ull,
+    0x000b8208001e0008ull,
+    0x00085d2168004030ull,
+    0x00098308001e0010ull,
+    0x00088608001e0010ull,
+    0x000c5d2168004070ull,
+    0x0008418068080025ull,
+    0x000841ba6803a0f0ull,
+    0x000856ad40030000ull,
+    0x0008c180ffff0000ull,
+    0x0005820807000500ull,
+    0x00088a3d00010001ull,
+    0x000841be68004050ull,
+    0x0005828807000300ull,
+    0x000a8abd00040004ull,
+    0x000a41be68004040ull,
+    0x0005820807000100ull,
+    0x00088a2a00800080ull,
+    0x0008413068004078ull,
+    0xa021c00000000000ull,
+    0x0005828807000200ull,
+    0x000841806801002dull,
+    0x000a8abd00080008ull,
+    0x000a41be68004026ull,
+    0x0005820807000400ull,
+    0x00088a2902000200ull,
+    0x000841b46800405aull,
+    0x000556ad40030000ull,
+    0x000081bd00100010ull,
+    0x0006c180ffff0000ull,
+    0x0006822a00800080ull,
+    0x00088a0900100010ull,
+    0x0008413c68024070ull,
+    0xa021c00000000000ull,
+    0x0006832902000200ull,
+    0x0008c181f0008000ull,
+    0x000841834c00ffffull,
+    0x0006822a00400040ull,
+    0x00088a0900200020ull,
+    0x0008413c68024078ull,
+    0xa021c00000000000ull,
+    0x000c828901000100ull,
+    0x0008dc01f0008000ull,
+    0x000841b84c03ffffull,
+    0x000a823400ff0033ull,
+    0x000841bb4c03ffffull,
+    0x0008863400ff0014ull,
+    0x000841b54c03ffffull,
+    0x000c828900400040ull,
+    0x000a41b44c0300ffull,
+    0x000682a9f800a800ull,
+    0x000a86a9f8009800ull,
+    0x000a8a8904000400ull,
+    0x000a41b74c0300ffull,
+    0x000a41b64c03ffffull,
+    0x000682287c005800ull,
+    0x00088a0902000200ull,
+    0x0008413068024070ull,
+    0xa001c00000000000ull,
+    0x0006830900020002ull,
+    0x00088281e0002000ull,
+    0xa84a868108000800ull,
+    0xa861c00000000000ull,
+    0x000a41814c03ffffull,
+    0x000a41814c03ffffull,
+    0x000653a7680300f0ull,
+    0x000c5321680040b0ull,
+    0x000dd3260fff0fffull,
+    0x0000003f70000400ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x000082a902000200ull,
+    0x000a413268024070ull,
+    0xa50a822902800280ull,
+    0x0006828900800080ull,
+    0x00098301ffffffffull,
+    0xb12d8381f000e000ull,
+    0x000ed5ab40004000ull,
+    0xa18c8381ffffffffull,
+    0x000a8abd08000800ull,
+    0x000e8781ff00ff00ull,
+    0x000ed5ab80008000ull,
+    0x000a8abd40000000ull,
+    0x0000572e680800f0ull,
+    0x000057af680900f0ull,
+    0x0007d72ef0ff0000ull,
+    0x0007d7aff0000000ull,
+    0x000ad72e00fc0000ull,
+    0x0000000008000000ull
+};
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-defs.h b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
index e9ffbad..dcdef0e 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -53,6 +53,39 @@
 #define __CVMX_PKI_DEFS_H__
 
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKI_ACTIVE0 CVMX_PKI_ACTIVE0_FUNC()
+static inline uint64_t CVMX_PKI_ACTIVE0_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKI_ACTIVE0 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180044000220ull);
+}
+#else
+#define CVMX_PKI_ACTIVE0 (CVMX_ADD_IO_SEG(0x0001180044000220ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKI_ACTIVE1 CVMX_PKI_ACTIVE1_FUNC()
+static inline uint64_t CVMX_PKI_ACTIVE1_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKI_ACTIVE1 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180044000230ull);
+}
+#else
+#define CVMX_PKI_ACTIVE1 (CVMX_ADD_IO_SEG(0x0001180044000230ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKI_ACTIVE2 CVMX_PKI_ACTIVE2_FUNC()
+static inline uint64_t CVMX_PKI_ACTIVE2_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKI_ACTIVE2 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180044000240ull);
+}
+#else
+#define CVMX_PKI_ACTIVE2 (CVMX_ADD_IO_SEG(0x0001180044000240ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKI_AURAX_CFG(unsigned long offset)
 {
 	if (!(
@@ -482,6 +515,28 @@ static inline uint64_t CVMX_PKI_PCAM_RESULT_FUNC(void)
 #define CVMX_PKI_PCAM_RESULT (CVMX_ADD_IO_SEG(0x0001180044000510ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKI_PFE_DIAG CVMX_PKI_PFE_DIAG_FUNC()
+static inline uint64_t CVMX_PKI_PFE_DIAG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKI_PFE_DIAG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180044000560ull);
+}
+#else
+#define CVMX_PKI_PFE_DIAG (CVMX_ADD_IO_SEG(0x0001180044000560ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKI_PIX_DIAG CVMX_PKI_PIX_DIAG_FUNC()
+static inline uint64_t CVMX_PKI_PIX_DIAG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKI_PIX_DIAG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180044000580ull);
+}
+#else
+#define CVMX_PKI_PIX_DIAG (CVMX_ADD_IO_SEG(0x0001180044000580ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKI_PKINDX_ICGSEL(unsigned long offset)
 {
 	if (!(
@@ -965,6 +1020,77 @@ static inline uint64_t CVMX_PKI_TAG_SECRET_FUNC(void)
 #else
 #define CVMX_PKI_TAG_SECRET (CVMX_ADD_IO_SEG(0x0001180044000430ull))
 #endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKI_X2P_REQ_OFL CVMX_PKI_X2P_REQ_OFL_FUNC()
+static inline uint64_t CVMX_PKI_X2P_REQ_OFL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKI_X2P_REQ_OFL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180044000038ull);
+}
+#else
+#define CVMX_PKI_X2P_REQ_OFL (CVMX_ADD_IO_SEG(0x0001180044000038ull))
+#endif
+
+/**
+ * cvmx_pki_active0
+ */
+union cvmx_pki_active0 {
+	uint64_t u64;
+	struct cvmx_pki_active0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t pfe_active                   : 1;  /**< PFE active. For internal use; software should use PKI_SFT_RST[ACTIVE]. */
+#else
+	uint64_t pfe_active                   : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_pki_active0_s             cn78xx;
+};
+typedef union cvmx_pki_active0 cvmx_pki_active0_t;
+
+/**
+ * cvmx_pki_active1
+ */
+union cvmx_pki_active1 {
+	uint64_t u64;
+	struct cvmx_pki_active1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_4_63                : 60;
+	uint64_t fpc_active                   : 1;  /**< PBE FPC and FPA bus active. For internal use; software should use PKI_SFT_RST[ACTIVE]. */
+	uint64_t iobp_active                  : 1;  /**< PBE PMW and IOBP bus active. For internal use; software should use PKI_SFT_RST[ACTIVE]. */
+	uint64_t sws_active                   : 1;  /**< PBE SWS active. For internal use; software should use PKI_SFT_RST[ACTIVE]. */
+	uint64_t pbtag_active                 : 1;  /**< PBE pbtags active. For internal use; software should use PKI_SFT_RST[ACTIVE]. */
+#else
+	uint64_t pbtag_active                 : 1;
+	uint64_t sws_active                   : 1;
+	uint64_t iobp_active                  : 1;
+	uint64_t fpc_active                   : 1;
+	uint64_t reserved_4_63                : 60;
+#endif
+	} s;
+	struct cvmx_pki_active1_s             cn78xx;
+};
+typedef union cvmx_pki_active1 cvmx_pki_active1_t;
+
+/**
+ * cvmx_pki_active2
+ */
+union cvmx_pki_active2 {
+	uint64_t u64;
+	struct cvmx_pki_active2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t pix_active                   : 5;  /**< PIX control and ICG active. For internal use; software should use PKI_SFT_RST[ACTIVE]. */
+#else
+	uint64_t pix_active                   : 5;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_pki_active2_s             cn78xx;
+};
+typedef union cvmx_pki_active2 cvmx_pki_active2_t;
 
 /**
  * cvmx_pki_aura#_cfg
@@ -1074,9 +1200,16 @@ union cvmx_pki_bist_status2 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
 	uint64_t bist                         : 25; /**< BIST results. Hardware sets a bit in BIST for memory that fails BIST. INTERNAL: This
-                                                         register collects status for PKI_PIX.
+                                                         register collects status for PKI_PIX (verif/vkits/pki/pki_mem_info_table.sv).
                                                          - 24: IMEM
-                                                         23..16: IPEC IPEs
+                                                         - 23: IPEC3 / IPEs 10 .. 19 (RegFile + DMEM)
+                                                         - 22: IPEC3 / IPEs  0 ..  9 (RegFile + DMEM)
+                                                         - 21: IPEC2 / IPEs 10 .. 19 (RegFile + DMEM)
+                                                         - 20: IPEC2 / IPEs  0 ..  9 (RegFile + DMEM)
+                                                         - 19: IPEC1 / IPEs 10 .. 19 (RegFile + DMEM)
+                                                         - 18: IPEC1 / IPEs  0 ..  9 (RegFile + DMEM)
+                                                         - 17: IPEC0 / IPEs 10 .. 19 (RegFile + DMEM)
+                                                         - 16: IPEC0 / IPEs  0 ..  9 (RegFile + DMEM)
                                                          15..12: IPEC SMEM
                                                          11..8: IPEC PCAM ECC
                                                          7..4: IPEC PCAM RES
@@ -1125,14 +1258,11 @@ union cvmx_pki_buf_ctl {
                                                          1 = Wait until buffers become available, only dropping packets if buffering ahead of PKI
                                                          fills. This may lead to head-of-line blocking of packets on other Auras. */
 	uint64_t fpa_cac_dis                  : 1;  /**< When set, disable caching any FPA buffers, and immediately return any cached buffers to the FPA. */
-	uint64_t reserved_7_8                 : 2;
-	uint64_t pki_full                     : 1;  /**< PKI full. When this bit is set to 1, the PKI drives the PKI_BUFF_FULL line to the IOB
-                                                         arbiter, telling it to not give grants to IOI devices sending packet data; when it is
-                                                         clear to 0, the PKI acts normally. */
+	uint64_t reserved_6_8                 : 3;
 	uint64_t pkt_off                      : 1;  /**< Packet buffer off. When this bit is set to 1, the PKI does not buffer the received packet
                                                          data; when it is clear to 0, the PKI works normally, buffering the received packet data. */
 	uint64_t reserved_3_4                 : 2;
-	uint64_t pbp_en                       : 1;  /**< Bpid enable. When set, enables the sending of bpid level backpressure to the CN78XX input
+	uint64_t pbp_en                       : 1;  /**< Bpid enable. When set, enables the sending of bpid level backpressure to the input
                                                          interface.
                                                          The application should not de-assert this bit after asserting it. The receivers of this
                                                          bit may have been put into backpressure mode and can only be released by PKI informing
@@ -1148,8 +1278,7 @@ union cvmx_pki_buf_ctl {
 	uint64_t pbp_en                       : 1;
 	uint64_t reserved_3_4                 : 2;
 	uint64_t pkt_off                      : 1;
-	uint64_t pki_full                     : 1;
-	uint64_t reserved_7_8                 : 2;
+	uint64_t reserved_6_8                 : 3;
 	uint64_t fpa_cac_dis                  : 1;
 	uint64_t fpa_wait                     : 1;
 	uint64_t reserved_11_63               : 53;
@@ -1196,36 +1325,32 @@ union cvmx_pki_clx_ecc_ctl {
 	uint64_t u64;
 	struct cvmx_pki_clx_ecc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_26_63               : 38;
+	uint64_t reserved_24_63               : 40;
 	uint64_t pcam1_flip                   : 2;  /**< PCAM1 flip syndrome bits on write. */
 	uint64_t pcam0_flip                   : 2;  /**< PCAM  flip syndrome bits on write. */
-	uint64_t smem_flip                    : 2;  /**< SMEM flip syndrome bits on write. */
-	uint64_t kmem_flip                    : 2;  /**< KMEM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram to
+	uint64_t smem_flip                    : 2;  /**< SMEM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram to
                                                          test single-bit or double-bit error handling. */
 	uint64_t dmem_flip                    : 1;  /**< DMEM flip parity. */
 	uint64_t rf_flip                      : 1;  /**< RF flip parity. */
-	uint64_t reserved_6_15                : 10;
+	uint64_t reserved_5_15                : 11;
 	uint64_t pcam1_cdis                   : 1;  /**< PCAM1 ECC correction disable. */
 	uint64_t pcam0_cdis                   : 1;  /**< PCAM0 ECC correction disable. */
 	uint64_t smem_cdis                    : 1;  /**< SMEM ECC correction disable. */
-	uint64_t kmem_cdis                    : 1;  /**< KMEM ECC correction disable. */
 	uint64_t dmem_cdis                    : 1;  /**< DMEM parity poising disable. */
 	uint64_t rf_cdis                      : 1;  /**< RF RAM parity poising disable. */
 #else
 	uint64_t rf_cdis                      : 1;
 	uint64_t dmem_cdis                    : 1;
-	uint64_t kmem_cdis                    : 1;
 	uint64_t smem_cdis                    : 1;
 	uint64_t pcam0_cdis                   : 1;
 	uint64_t pcam1_cdis                   : 1;
-	uint64_t reserved_6_15                : 10;
+	uint64_t reserved_5_15                : 11;
 	uint64_t rf_flip                      : 1;
 	uint64_t dmem_flip                    : 1;
-	uint64_t kmem_flip                    : 2;
 	uint64_t smem_flip                    : 2;
 	uint64_t pcam0_flip                   : 2;
 	uint64_t pcam1_flip                   : 2;
-	uint64_t reserved_26_63               : 38;
+	uint64_t reserved_24_63               : 40;
 #endif
 	} s;
 	struct cvmx_pki_clx_ecc_ctl_s         cn78xx;
@@ -1239,29 +1364,25 @@ union cvmx_pki_clx_ecc_int {
 	uint64_t u64;
 	struct cvmx_pki_clx_ecc_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_10_63               : 54;
+	uint64_t reserved_8_63                : 56;
 	uint64_t pcam1_dbe                    : 1;  /**< PCAM1 ECC double bit error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_PCAM1_DBE. */
 	uint64_t pcam1_sbe                    : 1;  /**< PCAM1 ECC single bit error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_PCAM1_SBE. */
 	uint64_t pcam0_dbe                    : 1;  /**< PCAM0 ECC double bit error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_PCAM0_DBE. */
 	uint64_t pcam0_sbe                    : 1;  /**< PCAM0 ECC single bit error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_PCAM0_SBE. */
 	uint64_t smem_dbe                     : 1;  /**< SMEM ECC double bit error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_SMEM_DBE. */
 	uint64_t smem_sbe                     : 1;  /**< SMEM ECC single bit error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_SMEM_SBE. */
-	uint64_t kmem_dbe                     : 1;  /**< KMEM ECC double bit error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_KMEM_DBE. */
-	uint64_t kmem_sbe                     : 1;  /**< KMEM ECC single bit error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_KMEM_SBE. */
 	uint64_t dmem_perr                    : 1;  /**< DMEM parity error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_DMEM_PERR. */
 	uint64_t rf_perr                      : 1;  /**< RF RAM parity error. Throws PKI_INTSN_E::PKI_CL(0..3)_ECC_RF_PERR. */
 #else
 	uint64_t rf_perr                      : 1;
 	uint64_t dmem_perr                    : 1;
-	uint64_t kmem_sbe                     : 1;
-	uint64_t kmem_dbe                     : 1;
 	uint64_t smem_sbe                     : 1;
 	uint64_t smem_dbe                     : 1;
 	uint64_t pcam0_sbe                    : 1;
 	uint64_t pcam0_dbe                    : 1;
 	uint64_t pcam1_sbe                    : 1;
 	uint64_t pcam1_dbe                    : 1;
-	uint64_t reserved_10_63               : 54;
+	uint64_t reserved_8_63                : 56;
 #endif
 	} s;
 	struct cvmx_pki_clx_ecc_int_s         cn78xx;
@@ -1275,7 +1396,10 @@ union cvmx_pki_clx_int {
 	uint64_t u64;
 	struct cvmx_pki_clx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_4_63                : 60;
+	uint64_t reserved_5_63                : 59;
+	uint64_t trapz                        : 1;  /**< PCAM sequencer trapz interrupt. Throws PKI_INTSN_E::PKI_CL(0..3)_INT_TRAPZ. INTERNAL:
+                                                         Caused by TRAP sequence state, may indicate PKI enabled without proper sequencer code
+                                                         loaded in PKI_IMEM(0..2047). */
 	uint64_t iptint                       : 1;  /**< PCAM sequencer debug interrupt. Throws PKI_INTSN_E::PKI_CL(0..3)_INT_IPTINT. INTERNAL:
                                                          Caused by TRAP or INTR sequence state. */
 	uint64_t sched_conf                   : 1;  /**< PCAM/SMEM internal port conflict. Internal error, should not occur. Throws
@@ -1288,7 +1412,8 @@ union cvmx_pki_clx_int {
 	uint64_t pcam_conf                    : 2;
 	uint64_t sched_conf                   : 1;
 	uint64_t iptint                       : 1;
-	uint64_t reserved_4_63                : 60;
+	uint64_t trapz                        : 1;
+	uint64_t reserved_5_63                : 59;
 #endif
 	} s;
 	struct cvmx_pki_clx_int_s             cn78xx;
@@ -1349,8 +1474,8 @@ union cvmx_pki_clx_pcamx_actionx {
 	uint64_t setty                        : 5;  /**< Set pointer type. If non-zero, indicates the layer type to be set as described under
                                                          PKI_PCAM_TERM_E. Values are enumerated in PKI_LTYPE_E. Must be zero for invalid entries. */
 	uint64_t advance                      : 8;  /**< Relative number of bytes to advance scan pointer when entry matches. See Parser Skip and
-                                                         Advancing. Must be zero for invalid entries and for TERMs that do not allow an advance as
-                                                         specified in the PKI_PCAM_TERM_E table. */
+                                                         Advancing. Must be even. Must be zero for invalid entries and for TERMs that do not allow
+                                                         an advance as specified in the PKI_PCAM_TERM_E table. */
 #else
 	uint64_t advance                      : 8;
 	uint64_t setty                        : 5;
@@ -1440,7 +1565,12 @@ union cvmx_pki_clx_pkindx_cfg {
 	uint64_t u64;
 	struct cvmx_pki_clx_pkindx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_7_63                : 57;
+	uint64_t reserved_8_63                : 56;
+	uint64_t fcs_pres                     : 1;  /**< FCS present.
+                                                         0 = FCS not present. FCS may not be checked nor stripped.
+                                                         1 = FCS present; the last four bytes of the packet are part of the FCS and may not be
+                                                         considered part of a IP, TCP or other header for length error checks.
+                                                         PKI_CL(0..3)_STYLE(0..63)_CFG[FCS_CHK or FCS_STRIP] may optionally be set. */
 	uint64_t mpls_en                      : 1;  /**< Enable MPLS parsing.
                                                          0 = Any MPLS labels are ignored, but may be handled by custom Ethertype PCAM matchers.
                                                          1 = MPLS label stacks are parsed and skipped over. PKI_GBL_PEN[MPLS_PEN] must be set. */
@@ -1473,7 +1603,8 @@ union cvmx_pki_clx_pkindx_cfg {
 	uint64_t lg_custom                    : 1;
 	uint64_t inst_hdr                     : 1;
 	uint64_t mpls_en                      : 1;
-	uint64_t reserved_7_63                : 57;
+	uint64_t fcs_pres                     : 1;
+	uint64_t reserved_8_63                : 56;
 #endif
 	} s;
 	struct cvmx_pki_clx_pkindx_cfg_s      cn78xx;
@@ -1558,13 +1689,14 @@ union cvmx_pki_clx_pkindx_skip {
 	struct cvmx_pki_clx_pkindx_skip_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t fcs_skip                     : 8;  /**< Skip amount from front of packet to first byte covered by FCS start. If PTP_MODE, the
-                                                         8-byte timestamp is prepended to the packet, and FCS_SKIP must be at least 8. */
+	uint64_t fcs_skip                     : 8;  /**< Skip amount from front of packet to first byte covered by FCS start. The skip must be
+                                                         even. If PTP_MODE, the 8-byte timestamp is prepended to the packet, and FCS_SKIP must be
+                                                         at least 8. */
 	uint64_t inst_skip                    : 8;  /**< Skip amount from front of packet to begin parsing at. If
                                                          PKI_CL(0..3)_PKIND(0..63)_CFG[INST_HDR] is set, points at the first byte of the
-                                                         instruction header. If INST_HDR is clear, points at the first byte to begin parsing at. If
-                                                         PTP_MODE, the 8-byte timestamp is prepended to the packet, and INST_SKIP must be at least
-                                                         8. */
+                                                         instruction header. If INST_HDR is clear, points at the first byte to begin parsing at.
+                                                         The skip must be even. If PTP_MODE, the 8-byte timestamp is prepended to the packet, and
+                                                         INST_SKIP must be at least 8. */
 #else
 	uint64_t inst_skip                    : 8;
 	uint64_t fcs_skip                     : 8;
@@ -1724,8 +1856,9 @@ union cvmx_pki_clx_stylex_cfg {
                                                          patterns. IPv6 outlaws this and the spec says to always check UDP checksum.
                                                          0 = Spec compliant, do not allow optional code.
                                                          1 = Treat IPv6 as IPv4; the all-0s pattern will cause a UDP checksum pass. */
-	uint64_t lenerr_en                    : 1;  /**< L2 length error check enable. Check if frame was received with L2 length error, see LENERR
-                                                         in Table 10-2. This check is typically not enabled for incoming packets on the DPI ports. */
+	uint64_t lenerr_en                    : 1;  /**< L2 length error check enable. Check if frame was received with L2 length error. This check
+                                                         is typically not enabled for incoming packets on the DPI ports. INTERNAL: Sequencer clears
+                                                         this bit for PKI_BE when SNAP length checks are not appropriate. */
 	uint64_t lenerr_eqpad                 : 1;  /**< L2 length checks exact pad size.
                                                          0 = Length check uses greater then or equal comparison. Packets must have at least minimum
                                                          padding, but may have more. This mode must be used when there may be extra Etherypes
@@ -1736,21 +1869,22 @@ union cvmx_pki_clx_stylex_cfg {
                                                          checks.
                                                          0 = use PKI_FRM_LEN_CHK0
                                                          1 = use PKI_FRM_LEN_CHK1 */
-	uint64_t maxerr_en                    : 1;  /**< Max frame error check enable. See MAXLEN in Table 10-2. */
-	uint64_t minerr_en                    : 1;  /**< Min frame error check enable. See MINLEN in Table 10-2. This check is typically not
-                                                         enabled for incoming packets on the DPI ports. */
-	uint64_t reserved_24_24               : 1;
-	uint64_t fcs_strip                    : 1;  /**< Strip L2 FCS bytes from packet, decrease WQE[LEN] by 4 bytes. */
-	uint64_t fcs_chk                      : 1;  /**< FCS Checking enabled. */
+	uint64_t maxerr_en                    : 1;  /**< Max frame error check enable. */
+	uint64_t minerr_en                    : 1;  /**< Min frame error check enable. This check is typically not enabled for incoming packets on
+                                                         the DPI ports. */
+	uint64_t qpg_dis_grptag               : 1;  /**< Disable computing group using WQE[TAG]. */
+	uint64_t fcs_strip                    : 1;  /**< Strip L2 FCS bytes from packet, decrease WQE[LEN] by 4 bytes.
+                                                         PKI_CL(0..3)_PKIND(0..63)_CFG[FCS_PRES] must be set. */
+	uint64_t fcs_chk                      : 1;  /**< FCS checking enabled. PKI_CL(0..3)_PKIND(0..63)_CFG[FCS_PRES] must be set. */
 	uint64_t rawdrp                       : 1;  /**< Allow RAW packet drop.
                                                          0 = Never drop packets with WQE[RAW] set.
-                                                         1 = Allow the PKI to drop RAW packets based on QoS. */
+                                                         1 = Allow the PKI to drop RAW packets based on PKI_AURA(0..1023)_CFG[ENA_RED/ENA_DROP]. */
 	uint64_t drop                         : 1;  /**< Force packet dropping.
-                                                         0 = Drop packet based on QoS.
+                                                         0 = Drop packet based on PKI_AURA(0..1023)_CFG[ENA_RED/ENA_DROP].
                                                          1 = Always drop the packet. Overrides NODROP, RAWDRP. */
 	uint64_t nodrop                       : 1;  /**< Disable QoS packet drop.
-                                                         0 = Allowed to drop packet based on QoS.
-                                                         1 = Never drop the packet based on QoS. Overrides RAWDRP. */
+                                                         0 = Allowed to drop packet based on PKI_AURA(0..1023)_CFG[ENA_RED/ENA_DROP].
+                                                         1 = Never drop the packet. Overrides RAWDRP. */
 	uint64_t qpg_dis_padd                 : 1;  /**< Disable computing port adder by QPG algorithm. */
 	uint64_t qpg_dis_grp                  : 1;  /**< Disable computing group by QPG algorithm. */
 	uint64_t qpg_dis_aura                 : 1;  /**< Disable computing aura by QPG algorithm. */
@@ -1768,7 +1902,7 @@ union cvmx_pki_clx_stylex_cfg {
 	uint64_t rawdrp                       : 1;
 	uint64_t fcs_chk                      : 1;
 	uint64_t fcs_strip                    : 1;
-	uint64_t reserved_24_24               : 1;
+	uint64_t qpg_dis_grptag               : 1;
 	uint64_t minerr_en                    : 1;
 	uint64_t maxerr_en                    : 1;
 	uint64_t minmax_sel                   : 1;
@@ -1791,22 +1925,25 @@ union cvmx_pki_clx_stylex_cfg2 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
 	uint64_t tag_inc                      : 4;  /**< Include masked tags using PKI_TAG_INC(0..31)_MASK. Each bit indicates to include the
-                                                         corresponding PKI_TAG_INC_MASK range, see WQE[TAG]. Multiple TAG_INCs may be selected to
-                                                         allow a tag calculation to include data from floating Layer B through Layer G positions. */
+                                                         corresponding PKI_TAG_INC_MASK range, see PKI_INST_HDR_S. */
 	uint64_t reserved_25_27               : 3;
-	uint64_t tag_masken                   : 1;  /**< Apply PKI_STYLE(0..63)_TAG_MASK to computed tag. */
+	uint64_t tag_masken                   : 1;  /**< Apply PKI_STYLE(0..63)_TAG_MASK to computed tag. INTERNAL: Sequencer must clear for PKI BE
+                                                         when the tag comes from the PKI_INST_HDR_S. */
 	uint64_t tag_src_lg                   : 1;  /**< Include Layer G source address in tuple tag generation. */
 	uint64_t tag_src_lf                   : 1;  /**< Include Layer F source address in tuple tag generation. */
 	uint64_t tag_src_le                   : 1;  /**< Include Layer E source address in tuple tag generation. */
 	uint64_t tag_src_ld                   : 1;  /**< Include Layer D source address in tuple tag generation. */
 	uint64_t tag_src_lc                   : 1;  /**< Include Layer C source address in tuple tag generation. */
-	uint64_t tag_src_lb                   : 1;  /**< Include Layer B source address in tuple tag generation. */
+	uint64_t tag_src_lb                   : 1;  /**< Include Layer B source address in tuple tag generation. INTERNAL: Sequencer must clear
+                                                         TAG_SRC_L* for PKI BE when TCP SYNs are not tagged, or when the tag comes from the
+                                                         PKI_INST_HDR_S. */
 	uint64_t tag_dst_lg                   : 1;  /**< Include Layer G destination address in tuple tag generation. */
 	uint64_t tag_dst_lf                   : 1;  /**< Include Layer F destination address in tuple tag generation. */
 	uint64_t tag_dst_le                   : 1;  /**< Include Layer E destination address in tuple tag generation. */
 	uint64_t tag_dst_ld                   : 1;  /**< Include Layer D destination address in tuple tag generation. */
 	uint64_t tag_dst_lc                   : 1;  /**< Include Layer C destination address in tuple tag generation. */
-	uint64_t tag_dst_lb                   : 1;  /**< Include Layer B destination address in tuple tag generation. */
+	uint64_t tag_dst_lb                   : 1;  /**< Include Layer B destination address in tuple tag generation. INTERNAL: Sequencer must
+                                                         clear TAG_SRC_L* for PKI BE when the tag comes from the PKI_INST_HDR_S. */
 	uint64_t len_lg                       : 1;  /**< Check length of Layer G. */
 	uint64_t len_lf                       : 1;  /**< Check length of Layer F. */
 	uint64_t len_le                       : 1;  /**< Check length of Layer E. */
@@ -2128,8 +2265,8 @@ union cvmx_pki_frm_len_chkx {
 	struct cvmx_pki_frm_len_chkx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t maxlen                       : 16; /**< Byte count for max-sized frame check. See MAXLEN in Table 10-2 for adjustments to this value. */
-	uint64_t minlen                       : 16; /**< Byte count for min-sized frame check.See MINLEN in Table 10-2. */
+	uint64_t maxlen                       : 16; /**< Byte count for max-sized frame check. */
+	uint64_t minlen                       : 16; /**< Byte count for min-sized frame check. */
 #else
 	uint64_t minlen                       : 16;
 	uint64_t maxlen                       : 16;
@@ -2214,7 +2351,9 @@ union cvmx_pki_gen_int {
 	uint64_t u64;
 	struct cvmx_pki_gen_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_7_63                : 57;
+	uint64_t reserved_8_63                : 56;
+	uint64_t x2p_req_ofl                  : 1;  /**< Set when a device attempts to have more than the allocated requests outstanding to PKI.
+                                                         Throws PKI_INTSN_E::PKI_GEN_X2P_REQ_OFL. */
 	uint64_t drp_noavail                  : 1;  /**< Set when packet dropped due to no FPA pointers available for the aura the packet
                                                          requested. Throws PKI_INTSN_E::PKI_GEN_DRP_NOAVAIL. */
 	uint64_t dat                          : 1;  /**< Set when data arrives before a SOP for the same reasm-id for a packet. The first detected
@@ -2228,12 +2367,15 @@ union cvmx_pki_gen_int {
                                                          detected error associated with bits [DAT,EOP,SOP] of this register is only set here. A new
                                                          bit can be set when the previous reported bit is cleared. Also see PKI_PKT_ERR. Throws
                                                          PKI_INTSN_E::PKI_GEN_SOP. */
-	uint64_t bckprs                       : 1;  /**< PKI asserted backpressure. PKI can assert backpressure to the receive logic when the to-do
-                                                         list exceeds a high-water mark. When this occurs, PKI can raise an interrupt to software.
-                                                         Throws PKI_INTSN_E::PKI_GEN_BCKPRS. */
-	uint64_t crcerr                       : 1;  /**< PKI calculated bad CRC. PKI can compute CRC in two places. Each RGMII port computes its
-                                                         own CRC, but PKI can provide an additional check. If PKI computes a bad CRC, PKI raises an
-                                                         interrupt. Throws PKI_INTSN_E::PKI_GEN_CRCERR. */
+	uint64_t bckprs                       : 1;  /**< PKI asserted backpressure. Set when PKI was unable to accept the next valid data from
+                                                         BGX/DPI/ILK etc. over X2P due to all internal resources being used up, and PKI will
+                                                         backpressure X2P. Throws PKI_INTSN_E::PKI_GEN_BCKPRS. */
+	uint64_t crcerr                       : 1;  /**< PKI calculated bad CRC. If the packet arrived via a BGX interface, the packet had an FCS
+                                                         error. If the packet arrived via PKO internal loopback, the packet had one or more parity
+                                                         errors. Not applicable when the packet arrived via the DPI interface. For ILK interfaces,
+                                                         the following ILK errors can cause packets to terminate with this error code:
+                                                         SERDES_LOCK_LOSS, BDRY_SYNC_LOSS, SCRM_SYNC_LOSS, LANE_ALIGN_FAIL, DESKEW_FIFO_OVFL,
+                                                         CRC24_ERR, UKWN_CNTL_WORD, and BAD_64B67B. Throws PKI_INTSN_E::PKI_GEN_CRCERR. */
 	uint64_t pktdrp                       : 1;  /**< Packet dropped due to QOS. If the QOS algorithm decides to drop a packet, PKI asserts this
                                                          interrupt. Throws PKI_INTSN_E::PKI_GEN_PKTDRP. */
 #else
@@ -2244,7 +2386,8 @@ union cvmx_pki_gen_int {
 	uint64_t eop                          : 1;
 	uint64_t dat                          : 1;
 	uint64_t drp_noavail                  : 1;
-	uint64_t reserved_7_63                : 57;
+	uint64_t x2p_req_ofl                  : 1;
+	uint64_t reserved_8_63                : 56;
 #endif
 	} s;
 	struct cvmx_pki_gen_int_s             cn78xx;
@@ -2268,9 +2411,12 @@ union cvmx_pki_icgx_cfg {
                                                          packet processing, other values will decrease performance. */
 	uint64_t reserved_36_47               : 12;
 	uint64_t clusters                     : 4;  /**< Bit-mask of clusters in this cluster group. A given cluster can only be enabled in a
-                                                         single cluster group. A value of 0 disables the cluster group, all packets to this group
-                                                         will be dropped. IGC(0)'s entry resets to 0xF, all other entries to 0x0. */
-	uint64_t reserved_26_31               : 6;
+                                                         single cluster group. Behavior is undefined for an ICG which receives traffic with a
+                                                         [CLUSTERS] of 0x0. IGC(0)'s entry resets to 0xF, all other entries to 0x0. */
+	uint64_t reserved_27_31               : 5;
+	uint64_t release_rqd                  : 1;  /**< Release required. For diagnostic use only. INTERNAL:
+                                                         0 = Release of r64 to r95 will occur immediately, no release microop is needed.
+                                                         1 = Release will wait until release microop executes. */
 	uint64_t mlo                          : 1;  /**< Memory low bypass enable. For diagnostic use only. INTERNAL:
                                                          0 = KMEM specifies contents of r48 to r63. The sequencer code expects this setting.
                                                          1 = KMEM specifies contents of r32 to r47. This may be desirable when PKIENA=0 to allow
@@ -2294,7 +2440,8 @@ union cvmx_pki_icgx_cfg {
 	uint64_t timer                        : 12;
 	uint64_t pena                         : 1;
 	uint64_t mlo                          : 1;
-	uint64_t reserved_26_31               : 6;
+	uint64_t release_rqd                  : 1;
+	uint64_t reserved_27_31               : 5;
 	uint64_t clusters                     : 4;
 	uint64_t reserved_36_47               : 12;
 	uint64_t maxipe_use                   : 5;
@@ -2344,8 +2491,8 @@ typedef union cvmx_pki_ltypex_map cvmx_pki_ltypex_map_t;
 /**
  * cvmx_pki_pcam_lookup
  *
- * For diagnostic use only, perform a PCAM lookup against the provided cluster and PCAM and load
- * results into PKI_PCAM_RESULT.
+ * For diagnostic use only, perform a PCAM lookup against the provided cluster and PCAM instance
+ * and loads results into PKI_PCAM_RESULT.
  */
 union cvmx_pki_pcam_lookup {
 	uint64_t u64;
@@ -2379,22 +2526,30 @@ union cvmx_pki_pcam_result {
 	uint64_t u64;
 	struct cvmx_pki_pcam_result_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_32_63               : 32;
+	uint64_t reserved_41_63               : 23;
+	uint64_t match                        : 1;  /**< Resulting match. */
+	uint64_t entry                        : 8;  /**< Resulting matching entry number, unpredictable unless [MATCH] set. */
 	uint64_t result                       : 32; /**< Resulting data from matching line's PKI_CL(0..3)_PCAM(0..1)_ACTION(0..191), or zero if no match. */
 #else
 	uint64_t result                       : 32;
-	uint64_t reserved_32_63               : 32;
+	uint64_t entry                        : 8;
+	uint64_t match                        : 1;
+	uint64_t reserved_41_63               : 23;
 #endif
 	} s;
 	struct cvmx_pki_pcam_result_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t conflict                     : 1;  /**< Conflict. The lookup resulted in multiple entries matching PKI_PCAM_LOOKUP[DATA] and
-                                                         [TERM], or zero if no match. */
-	uint64_t reserved_32_62               : 31;
+	uint64_t conflict                     : 1;  /**< Conflict. The lookup resulted in multiple entries matching PKI_PCAM_LOOKUP[DATA], [TERM]
+                                                         and [STYLE], or zero if no match. */
+	uint64_t reserved_41_62               : 22;
+	uint64_t match                        : 1;  /**< Resulting match. */
+	uint64_t entry                        : 8;  /**< Resulting matching entry number, unpredictable unless [MATCH] set. */
 	uint64_t result                       : 32; /**< Resulting data from matching line's PKI_CL(0..3)_PCAM(0..1)_ACTION(0..191), or zero if no match. */
 #else
 	uint64_t result                       : 32;
-	uint64_t reserved_32_62               : 31;
+	uint64_t entry                        : 8;
+	uint64_t match                        : 1;
+	uint64_t reserved_41_62               : 22;
 	uint64_t conflict                     : 1;
 #endif
 	} cn78xx;
@@ -2402,6 +2557,42 @@ union cvmx_pki_pcam_result {
 typedef union cvmx_pki_pcam_result cvmx_pki_pcam_result_t;
 
 /**
+ * cvmx_pki_pfe_diag
+ */
+union cvmx_pki_pfe_diag {
+	uint64_t u64;
+	struct cvmx_pki_pfe_diag_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t bad_rid                      : 1;  /**< Asserted when PFE sees and drops an X2P transaction with a RID > 95. */
+#else
+	uint64_t bad_rid                      : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_pki_pfe_diag_s            cn78xx;
+};
+typedef union cvmx_pki_pfe_diag cvmx_pki_pfe_diag_t;
+
+/**
+ * cvmx_pki_pix_diag
+ */
+union cvmx_pki_pix_diag {
+	uint64_t u64;
+	struct cvmx_pki_pix_diag_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_4_63                : 60;
+	uint64_t nosched                      : 4;  /**< Asserted when PFE requests an ICG with no enabled CLUSTERS. */
+#else
+	uint64_t nosched                      : 4;
+	uint64_t reserved_4_63                : 60;
+#endif
+	} s;
+	struct cvmx_pki_pix_diag_s            cn78xx;
+};
+typedef union cvmx_pki_pix_diag cvmx_pki_pix_diag_t;
+
+/**
  * cvmx_pki_pkind#_icgsel
  */
 union cvmx_pki_pkindx_icgsel {
@@ -2514,10 +2705,12 @@ union cvmx_pki_qpg_tblx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
 	uint64_t padd                         : 12; /**< Port to channel adder for calculating WQE[CHAN]. */
-	uint64_t reserved_42_47               : 6;
-	uint64_t grp_ok                       : 10; /**< SSO Group to schedule packet to and to load WQE[GRP] with if no error is detected. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t grp_bad                      : 10; /**< SSO Group to schedule packet to and to load WQE[GRP] with if an error is detected. */
+	uint64_t grptag_ok                    : 3;  /**< Number of WQE[TAG] bits to add into WQE[GRP] if no error is detected. */
+	uint64_t reserved_42_44               : 3;
+	uint64_t grp_ok                       : 10; /**< SSO group to schedule packet to and to load WQE[GRP] with if no error is detected. */
+	uint64_t grptag_bad                   : 3;  /**< Number of WQE[TAG] bits to add into WQE[GRP] if an error is detected. */
+	uint64_t reserved_26_28               : 3;
+	uint64_t grp_bad                      : 10; /**< SSO group to schedule packet to and to load WQE[GRP] with if an error is detected. */
 	uint64_t reserved_12_15               : 4;
 	uint64_t aura_node                    : 2;  /**< Aura node number. The node number is part of the upper aura bits, however PKI can only
                                                          allocate from auras on the local node, therefore these bits are hardcoded to the node
@@ -2528,9 +2721,11 @@ union cvmx_pki_qpg_tblx {
 	uint64_t aura_node                    : 2;
 	uint64_t reserved_12_15               : 4;
 	uint64_t grp_bad                      : 10;
-	uint64_t reserved_26_31               : 6;
+	uint64_t reserved_26_28               : 3;
+	uint64_t grptag_bad                   : 3;
 	uint64_t grp_ok                       : 10;
-	uint64_t reserved_42_47               : 6;
+	uint64_t reserved_42_44               : 3;
+	uint64_t grptag_ok                    : 3;
 	uint64_t padd                         : 12;
 	uint64_t reserved_60_63               : 4;
 #endif
@@ -2598,21 +2793,28 @@ typedef union cvmx_pki_req_wgt cvmx_pki_req_wgt_t;
 
 /**
  * cvmx_pki_sft_rst
- *
- * Allows soft reset.
- *
  */
 union cvmx_pki_sft_rst {
 	uint64_t u64;
 	struct cvmx_pki_sft_rst_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t busy                         : 1;  /**< When 1, PKI is busy completing reset. No access except the reading of this bit should
-                                                         occur to the PKI until this is clear. */
-	uint64_t reserved_1_62                : 62;
-	uint64_t rst                          : 1;  /**< Reset. When set to 1 by software, PKI gets a short reset pulse (three cycles in duration). */
+	uint64_t busy                         : 1;  /**< When set, PKI is busy completing reset. No access except the reading of this bit should
+                                                         occur to the PKI until this is clear. INTERNAL: The BUSY bit for this implementation is a
+                                                         placeholder and is not required to be implemented in HW. The soft reset pulse is short
+                                                         enough that we can guarantee that reset will complete below a subsequent RSL reference can
+                                                         be made. It is still useful for this bit to exist in case that property every changes and
+                                                         the reset requires a longer duration. For this implementation, SW will check the bit which
+                                                         will always report not BUSY allowing SW to proceed with its flow. */
+	uint64_t reserved_33_62               : 30;
+	uint64_t active                       : 1;  /**< When set, PKI is actively processing packet traffic. It is recommenced that software wait
+                                                         until ACTIVE is clear before setting RST. INTERNAL: ACTIVE is an OR of PKI_ACTIVE0..2. */
+	uint64_t reserved_1_31                : 31;
+	uint64_t rst                          : 1;  /**< Reset. When set to 1 by software, PKI will produce an internal reset pulse. */
 #else
 	uint64_t rst                          : 1;
-	uint64_t reserved_1_62                : 62;
+	uint64_t reserved_1_31                : 31;
+	uint64_t active                       : 1;
+	uint64_t reserved_33_62               : 30;
 	uint64_t busy                         : 1;
 #endif
 	} s;
@@ -2827,8 +3029,8 @@ union cvmx_pki_statx_stat12 {
 	struct cvmx_pki_statx_stat12_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t l2err                        : 48; /**< Number of packets with receive errors (WQE[ERRLEV]==RE or L2) not covered by more specific
-                                                         length or FCS statistic error registers. */
+	uint64_t l2err                        : 48; /**< Number of non-dropped packets with receive errors (WQE[ERRLEV]==RE or L2) not covered by
+                                                         more specific length or FCS statistic error registers. */
 #else
 	uint64_t l2err                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2846,7 +3048,8 @@ union cvmx_pki_statx_stat13 {
 	struct cvmx_pki_statx_stat13_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t spec                         : 48; /**< Number of packets with special handling. For profiling and diagnostic use only.
+	uint64_t spec                         : 48; /**< Number of packets, dropped or non-dropped, with special handling. For profiling and
+                                                         diagnostic use only.
                                                          INTERNAL: Counts packets completing IPE processing with WQE[SH] set. */
 #else
 	uint64_t spec                         : 48;
@@ -2922,9 +3125,8 @@ union cvmx_pki_statx_stat17 {
 	struct cvmx_pki_statx_stat17_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t drp_mcast                    : 48; /**< Number of packets with IPv4 or IPv6 L3 multicast destination address, or IPv6 L3 multicast
-                                                         destination address that were dropped due to RED or buffer exhaustion. See WQE[L3M] for
-                                                         the definition of L2 multicast. */
+	uint64_t drp_mcast                    : 48; /**< Number of packets with IPv4 or IPv6 L3 multicast destination address that were dropped due
+                                                         to RED or buffer exhaustion. See WQE[L3M] for the definition of L3 multicast. */
 #else
 	uint64_t drp_mcast                    : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3148,13 +3350,13 @@ union cvmx_pki_stylex_buf {
 	uint64_t first_skip                   : 6;  /**< The number of eight-byte words from the top of the first MBUF that the PKI stores the next
                                                          pointer. If [DIS_WQ_DAT]=1, any value is legal. If [DIS_WQ_DAT]=0, legal values must
                                                          satisfy:
-                                                         FIRST_SKIP + 18 <= PKI_STYLE(0..63)_BUF[MB_SIZE]
+                                                         FIRST_SKIP <= PKI_STYLE(0..63)_BUF[MB_SIZE] - 18.
                                                          FIRST_SKIP must be at least 0x4, but 0x5 is recommended minimum. 0x4 will drop WQE WORD4,
                                                          for use in backward compatible applications.
                                                          WQE_SKIP * (128/8) + 4 <= FIRST_SKIP, to insure the minimum of four work-queue entry words
                                                          will fit within FIRST_SKIP. */
 	uint64_t later_skip                   : 6;  /**< The number of eight-byte words from the top of any MBUF that is not the first MBUF that
-                                                         PKI writes the next-pointer to. Legal values are 0 to PKI_STYLE(0..63)_BUF[MB_SIZE] - 16. */
+                                                         PKI writes the next-pointer to. Legal values are 0 to PKI_STYLE(0..63)_BUF[MB_SIZE] - 18. */
 	uint64_t opc_mode                     : 2;  /**< Select the style of write to the L2C.
                                                          0 = all packet data and next-buffer pointers are written through to memory.
                                                          1 = all packet data and next-buffer pointers are written into the cache.
@@ -3336,8 +3538,8 @@ typedef union cvmx_pki_tag_incx_mask cvmx_pki_tag_incx_mask_t;
 /**
  * cvmx_pki_tag_secret
  *
- * The source and destination initial values (IVs) in tag generation provide a mechanism for each
- * CN78XX to be unique.
+ * The source and destination initial values (IVs) in tag generation provide a mechanism for
+ * seeding with a random initialization value to reduce cache collision attacks.
  */
 union cvmx_pki_tag_secret {
 	uint64_t u64;
@@ -3362,4 +3564,23 @@ union cvmx_pki_tag_secret {
 };
 typedef union cvmx_pki_tag_secret cvmx_pki_tag_secret_t;
 
+/**
+ * cvmx_pki_x2p_req_ofl
+ */
+union cvmx_pki_x2p_req_ofl {
+	uint64_t u64;
+	struct cvmx_pki_x2p_req_ofl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_4_63                : 60;
+	uint64_t x2p_did                      : 4;  /**< When PKI_GEN_INT[X2P_REQ_OFL] is set, this field latches the X2P device id number which
+                                                         attempted to overflow the allowed outstanding requests to PKI. */
+#else
+	uint64_t x2p_did                      : 4;
+	uint64_t reserved_4_63                : 60;
+#endif
+	} s;
+	struct cvmx_pki_x2p_req_ofl_s         cn78xx;
+};
+typedef union cvmx_pki_x2p_req_ofl cvmx_pki_x2p_req_ofl_t;
+
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-resources.h b/arch/mips/include/asm/octeon/cvmx-pki-resources.h
new file mode 100644
index 0000000..f68f527
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-pki-resources.h
@@ -0,0 +1,112 @@
+/***********************license start***************
+ * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Resource management for PKI resources.
+ */
+
+#ifndef __CVMX_PKI_RESOURCES_H__
+#define __CVMX_PKI_RESOURCES_H__
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/cvmx.h>
+#endif
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+extern "C" {
+/* *INDENT-ON* */
+#endif
+
+/**
+ * This function allocates/reserves a style from pool of global styles per node.
+ * @param node	 node to allocate style from.
+ * @param style	 style to allocate, if -1 it will be allocated
+                 first available style from style resource. If index is positive
+		 number and in range, it will try to allocate specified style.
+ * @return 	 style number on success, -1 on failure.
+ */
+int cvmx_pki_alloc_style(int node, int style);
+
+/**
+ * This function allocates/reserves a cluster group from per node
+   cluster group resources.
+ * @param node	 	node to allocate cluster group from.
+   @param cl_grp	cluster group to allocate/reserve, if -1 ,
+                        allocate any available cluster group.
+ * @param num_clusters	number of clusters that will be attached to
+			the cluster group.
+ * @param parsing_mask  mask of parsing that will be enabled on the cluster gro.
+ * @return 	 	cluster group number or -1 on failure
+ */
+int cvmx_pki_alloc_cluster_group(int node, int cl_grp, int num_clusters,
+				 uint64_t parsing_mask, uint64_t *cluster_mask);
+
+/**
+ * This function allocates/reserves a pcam entry from node
+ * @param node	 	node to allocate pcam entry from.
+   @param index  	index of pacm entry (0-191), if -1 ,
+                        allocate any available pcam entry.
+ * @param bank		pcam bank where to allocate/reserve pcan entry from
+ * @param cluster_mask  mask of clusters from which pcam entry is needed.
+ * @return 	 	pcam entry of -1 on failure
+ */
+int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_mask);
+
+/**
+ * This function allocates/reserves QPG table entries per node.
+ * @param node	 	node number.
+ * @param base_offset	base_offset in qpg table. If -1, first available
+			qpg base_offset will be allocated. If base_offset is positive
+		 	number and in range, it will try to allocate specified base_offset.
+   @param count		number of consecutive qpg entries to allocate. They will be consecutive
+                        from base offset.
+ * @return 	 	qpg table base offset number on success, -1 on failure.
+ */
+int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count );
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
+#endif
+
+#endif /*  __CVM_PKI_RESOURCES_H__ */
\ No newline at end of file
diff --git a/arch/mips/include/asm/octeon/cvmx-pki.h b/arch/mips/include/asm/octeon/cvmx-pki.h
index 7739fe0..3ca9528 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki.h
@@ -49,6 +49,9 @@
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-pki-defs.h>
+#include <asm/octeon/cvmx-fpa.h>
+#else
+#include "cvmx-fpa.h"
 #endif
 
 #ifdef	__cplusplus
@@ -66,46 +69,124 @@ extern "C" {
 #define CVMX_PKI_NUM_QPG_ENTRY		(2048)
 #define CVMX_PKI_NUM_FRAME_CHECK_VALUES	(2)
 #define CVMX_PKI_NUM_LTYPES		(32)
-#define CVMX_PKI_MAX_CLUSTER_PROFILES   (4)
-#define CVMX_PKI_NUM_STYLE_PROFILES	(1024)
-#define CVMX_PKI_MAX_NAME		(64)
 #define CVMX_PKI_NUM_CLUSTERS		(4)
 #define CVMX_PKI_NUM_CLUSTER_GROUP      (4)
 #define CVMX_PKI_NUM_PCAM_BANK		(2)
 #define CVMX_PKI_NUM_PCAM_ENTRY		(192)
-#define CVMX_PKI_TOTAL_PCAM_ENTRY	((CVMX_PKI_NUM_CLUSTERS) * (CVMX_PKI_NUM_PCAM_BANK) *\
-						(CVMX_PKI_NUM_PCAM_ENTRY))
-#define CVMX_PKI_MAX_QPG_STYLE_INDEX	(8)
-#define CVMX_PKI_MAX_FRAME_SIZE		(65535)
+#define CVMX_PKI_NUM_QPG_STYLE_INDEX	(8)
 #define CVMX_PKI_NUM_FRAME_SIZE_ID	(2)
 #define CVMX_PKI_NUM_CHANNELS		(4096)
 #define CVMX_PKI_NUM_BPID		(1024)
+#define CVMX_PKI_MAX_FRAME_SIZE		(65535)
 #define CVMX_PKI_FIND_AVAL_ENTRY        (-1)
+#define CVMX_PKI_MAX_CLUSTER_PROFILES   (4)
+#define CVMX_PKI_MAX_STYLE_PROFILES	(256)
+#define CVMX_PKI_MAX_NAME		(16)
+#define CVMX_PKI_MAX_POOL_PROFILES	(64) //modify it later
+#define CVMX_PKI_MAX_AURA_PROFILES	(256) //modify it later
+#define CVMX_PKI_MAX_SSO_GROUP_PROFILES	(256)
+
+#ifdef CVMX_SUPPORT_SEPARATE_CLUSTER_CONFIG
+#define CVMX_PKI_TOTAL_PCAM_ENTRY	((CVMX_PKI_NUM_CLUSTERS) * (CVMX_PKI_NUM_PCAM_BANK) *\
+						(CVMX_PKI_NUM_PCAM_ENTRY))
+#else
+#define CVMX_PKI_TOTAL_PCAM_ENTRY	(CVMX_PKI_NUM_PCAM_BANK * CVMX_PKI_NUM_PCAM_ENTRY)
+#endif
+
+#define CVMX_PKI_MAX_QPG_PROFILES	(2048)
+#define CVMX_PKI_NOT_ASSIGNED		(-88)
 
 
 struct cvmx_pki_cluster_profile
 {
 	char		name[CVMX_PKI_MAX_NAME];
-	uint64_t	cl_group;
-#define CVMX_PKI_CLUSTER_0	0x1
-#define CVMX_PKI_CLUSTER_1	0x2
-#define	CVMX_PKI_CLUSTER_2	0x4
-#define CVMX_PKI_CLUSTER_3	0x8
-#define CVMX_PKI_CLUSTER_ALL 0xf
-	uint64_t	cl_mask;
+	int 		num_clusters;
+	int 		cluster_group;
+#define CVMX_PKI_PARSE_DSP		0x01
+#define CVMX_PKI_PARSE_FULCRUM		0x02
+#define CVMX_PKI_PARSE_MPLS		0x04
+#define CVMX_PKI_PARSE_L3		0x08
+#define CVMX_PKI_PARSE_IL3		0x10
+#define CVMX_PKI_PARSE_L4 		0x20
+#define CVMX_PKI_PARSE_CUSTOM_L2	0x40
+#define CVMX_PKI_PARSE_CUSTOM_LG	0x80
+#define CVMX_PKI_PARSE_VIRTUALIZATION	0x100
+#define CVMX_PKI_CLUSTER_ALL            0xf
+	uint64_t        parsing_mask;
+
 };
 
 struct cvmx_pki_cluster_list
 {
-	uint64_t index;
+	int index;
 	struct cvmx_pki_cluster_profile cl_profile[CVMX_PKI_MAX_CLUSTER_PROFILES];
 };
 
+struct cvmx_pki_pool_profile
+{
+	char pool_name[CVMX_PKI_MAX_NAME];
+	cvmx_fpa_pool_config_t	pool_cfg;
+};
+
+struct cvmx_pki_pool_list
+{
+	int index;
+	struct cvmx_pki_pool_profile pool_profile[CVMX_PKI_MAX_POOL_PROFILES];
+};
+
+struct cvmx_pki_aura_profile
+{
+	char aura_name[CVMX_PKI_MAX_NAME];
+	int aura_num;
+	int pool_num;
+	int buffer_count;
+};
+
+struct cvmx_pki_aura_list
+{
+	int index;
+	struct cvmx_pki_aura_profile aura_profile[CVMX_PKI_MAX_AURA_PROFILES];
+};
+
+struct cvmx_pki_sso_grp_profile
+{
+	char grp_name[CVMX_PKI_MAX_NAME];
+	int grp_num;
+	int priority;
+	int weight;
+	int affinity;
+	uint64_t core_affinity_mask;
+	uint64_t core_affinity_mask_set;
+};
+struct cvmx_pki_sso_grp_list
+{
+	int index;
+	struct cvmx_pki_sso_grp_profile grp_profile[CVMX_PKI_MAX_SSO_GROUP_PROFILES];
+};
+
+struct cvmx_pki_qpg_profile
+{
+	char qpg_name[CVMX_PKI_MAX_NAME];
+	int base_offset;
+	int num_entries;
+};
+
+struct cvmx_pki_qpg_list
+{
+	int index;
+	struct cvmx_pki_qpg_profile qpg_profile[CVMX_PKI_MAX_QPG_PROFILES];
+};
+
 struct cvmx_pki_style_profile
 {
-	char		name[CVMX_PKI_MAX_NAME];
-	uint64_t	style_num;
-	uint64_t	cluster;
+	char				name[CVMX_PKI_MAX_NAME];
+	int				style_num;
+};
+
+struct cvmx_pki_style_list
+{
+	int    index;
+	struct cvmx_pki_style_profile style_profile[CVMX_PKI_MAX_STYLE_PROFILES];
 };
 
 struct cvmx_pki_framelen_chk {
@@ -115,16 +196,23 @@ struct cvmx_pki_framelen_chk {
 
 struct cvmx_pki_global_config
 {
-	uint64_t			pki_;
 	uint64_t			parsing_mask;
 	uint64_t			clusters_in_use_mask;
 	struct cvmx_pki_framelen_chk    frame_len_chk[CVMX_PKI_NUM_FRAME_SIZE_ID];
 	//enum cvmx_pki_bel		bel_type_map[CVMX_PKI_MAX_LTYPE];
 };
 
+struct cvmx_pki_qpg_config
+{
+	int  port_add;
+	int  aura;
+	int  group_ok;
+	int  group_bad;
+};
+
 struct cvmx_pki_clustergrp_config
 {
-	uint64_t 	users;
+	int		users;
 	uint64_t	cluster_mask;
 };
 
@@ -138,20 +226,21 @@ enum cvmx_pki_pkind_parse_mode{
 
 enum cvmx_pki_parse_mode_chg {
 	CVMX_PKI_PARSE_NO_CHG = 0x0,
-	CVMX_PKI_PARSE_SKIP_LA = 0x1,
-	CVMX_PKI_PARSE_SKIP_LA_TO_LB = 0x3,
-	CVMX_PKI_PARSE_SKIP_LA_TO_LC = 0x7,
-	CVMX_PKI_PARSE_SKIP_LA_TO_LF = 0x3f,
+	CVMX_PKI_PARSE_SKIP_TO_LB = 0x1,
+	CVMX_PKI_PARSE_SKIP_TO_LC = 0x3,
+	CVMX_PKI_PARSE_SKIP_TO_LD = 0x7,
+	CVMX_PKI_PARSE_SKIP_TO_LG = 0x3f,
 	CVMX_PKI_PARSE_SKIP_ALL = 0x7f,
 };
 
 struct cvmx_pki_pkind_config
 {
-        bool				in_use;
-	uint64_t			cluster_grp;
+	int				users;
 	enum cvmx_pki_pkind_parse_mode	parsing_mode;
+	uint64_t 			cluster_mask;
 	uint64_t 			l2_parsing_mask;
-	uint64_t 			initial_style;
+	int	 			initial_style;
+	int				cluster_grp;
 };
 
 struct cvmx_pki_tag_fields
@@ -179,43 +268,6 @@ struct cvmx_pki_tag_fields
 	uint64_t tag_vni:1;
 };
 
-/**
- * Structure to store FPA pool configuration parameters.
-   vinita modify it after FPA block has defined it for 78xx
- */
-struct cvmx_pki_pool_config
-{
-	int64_t aura_num;
-	uint64_t buffer_size;
-	uint64_t buffer_count;
-};
-
-struct cvmx_pki_qpg_entry
-{
-	int port_add;
-	int aura;
-	int grp_ok;
-	int grp_bad;
-};
-
-struct cvmx_pki_qpg_config
-{
-	int base_offset;
-	int num_entries;
-	//vinita, later modify it to use malloc, if it can be use
-	struct cvmx_pki_qpg_entry qpg_entry[CVMX_PKI_MAX_QPG_STYLE_INDEX];
-};
-
-struct cvmx_pki_aura_config
-{
-	bool in_use;
-	char pool_name[CVMX_PKI_MAX_NAME];
-	char aura_name[CVMX_PKI_MAX_NAME];
-	int pool_number;
-	int aura_number;
-	uint64_t buffer_size;
-};
-
 enum cvmx_pki_l2_len_mode {
 	PKI_L2_LENCHK_EQUAL_GREATER = 0,
 	PKI_L2_LENCHK_EQUAL_ONLY
@@ -243,35 +295,43 @@ enum cvmx_sso_tag_type{
 			- NULL_NULL can be exited by a new work request. A NULL_SWITCH load can also switch the state to NULL */
 };
 
+enum cvmx_pki_qpg_qos {
+	CVMX_PKI_QPG_QOS_NONE = 0,
+	CVMX_PKI_QPG_QOS_VLAN,
+	CVMX_PKI_QPG_QOS_MPLS,
+	CVMX_PKI_QPG_QOS_DSA_SRC,
+	CVMX_PKI_QPG_QOS_DIFFSERV,
+	CVMX_PKI_QPG_QOS_HIGIG
+};
 
 struct cvmx_pki_style_config
 {
-	uint64_t			users;
+	int				users;
 	bool				en_l2_lenchk;
+	uint64_t			cluster_mask;
 	enum cvmx_pki_l2_len_mode	l2_lenchk_mode;
 	bool 				en_maxframe_errchk;
 	bool 				en_minframe_errchk;
-	uint64_t 			max_min_frame_sel;
-	bool 				strip_l2_FCS;
-	bool 				en_FCS_check;
+	int	 			max_min_frame_sel;
+	bool 				strip_l2_fcs;
+	bool 				en_fcs_check;
+	int	 			wqe_header_size;
+	int 				wqe_start_offset;
+	int 				first_mbuf_skip;
+	int	 			later_mbuf_skip;
+	int				mbuff_size;
+	enum cvmx_pki_cache_mode 	cache_mode;
+	bool 				data_wqe_buf_diff;
+	int				wqe_vlan;
+	int				qpg_base_offset;
 	bool 				qpg_calc_port_addr;
 	bool 				qpg_calc_aura;
 	bool 				qpg_calc_group;
-	//uint64_t 			qpg_table_base;
-	uint64_t			qpg_qos;
-	uint64_t 			wqe_header_size;
-	uint64_t 			wqe_start_offset;
-	uint64_t 			first_mbuf_skip;
-	uint64_t 			later_mbuf_skip;
-	uint64_t			mbuff_size;
-	enum cvmx_pki_cache_mode 	cache_mode;
-	bool 				data_wqe_buf_same;
-	uint64_t			wqe_vlan;
+	enum cvmx_pki_qpg_qos		qpg_qos;
+	int				qpg_port_msb;
+	int				qpg_port_shift;
 	enum cvmx_sso_tag_type	 	tag_type;
-	//enum cvmx_pki_tag_mode	 	tag_order;
 	struct cvmx_pki_tag_fields 	tag_fields;
-	struct cvmx_pki_qpg_config      qpg_cfg;
-	struct cvmx_pki_aura_config     aura_cfg[CVMX_PKI_MAX_QPG_STYLE_INDEX];
 };
 
 #define CVMX_PKI_PCAM_TERM_E_NONE_M                            (0x0)
@@ -317,7 +377,7 @@ struct cvmx_pki_pcam_input
 	uint64_t 		style;
 	uint64_t		style_mask;
 	enum cvmx_pki_term	field;
-	uint64_t 		field_mask;
+	uint32_t 		field_mask;
 	uint64_t 		data;
 	uint64_t 		data_mask;
 };
@@ -379,14 +439,15 @@ struct cvmx_pki_pcam_action
 {
 	enum cvmx_pki_parse_mode_chg	parse_mode_chg;
 	enum cvmx_pki_layer_type	layer_type_set;
-	uint64_t			style_add;
-	uint64_t			parse_flag_set;
-	uint64_t			pointer_advance;
+	int				style_add;
+	int				parse_flag_set;
+	int				pointer_advance;
 };
 
 struct cvmx_pki_pcam_config
 {
-	uint64_t			in_use;
+	int				in_use;
+	int 				entry_num;
 	uint64_t			cluster_mask;
 	struct cvmx_pki_pcam_input	pcam_input;
 	struct cvmx_pki_pcam_action	pcam_action;
@@ -394,25 +455,36 @@ struct cvmx_pki_pcam_config
 
 struct cvmx_pki_pcam_list
 {
-	uint64_t 			index;
+	int	 			index;
 	struct cvmx_pki_pcam_config	pcam_cfg[CVMX_PKI_TOTAL_PCAM_ENTRY];
 };
 
-
+/** PKI block configuration*/
 struct cvmx_pki_config
 {
 	struct cvmx_pki_global_config		global_cfg;
 	struct cvmx_pki_clustergrp_config	cluster_cfg[CVMX_PKI_NUM_CLUSTER_GROUP];
-	struct cvmx_pki_pkind_config		pkind_config[CVMX_PKI_NUM_PKIND];
+	struct cvmx_pki_pkind_config		pkind_cfg[CVMX_PKI_NUM_PKIND];
 	struct cvmx_pki_style_config		style_cfg[CVMX_PKI_NUM_FINAL_STYLES];
+	struct cvmx_pki_qpg_config		qpg_cfg[CVMX_PKI_NUM_QPG_ENTRY];
+	//struct cvmx_fpa_pool_config_t		pool_cfg[CVMX_FPA_NUM_POOLS_78XX];
+	//struct cvmx_pki_aura_config		aura_cfg[CVMX_FPA_AURA_NUM];//fpa should have aura config defined but it does not
+};
+
+/** Mapping of profile names to their respective config number*/
+struct cvmx_pki_profiles
+{
 	struct cvmx_pki_pcam_list		pcam_list;
-	struct cvmx_pki_cluster_list    	cluster_list;
-	struct cvmx_pki_style_profile		style_profile[CVMX_PKI_NUM_FINAL_STYLES];
-	//struct cvmx_pki_bp_config_t		bp_cfg;
-	//struct cvmx_pki_red_config_t		red_cfg;
+	struct cvmx_pki_cluster_list    	cl_profile_list;
+	struct cvmx_pki_style_list		style_profile_list;
+	struct cvmx_pki_pool_list		pool_profile_list;
+	struct cvmx_pki_aura_list		aura_profile_list;
+	struct cvmx_pki_sso_grp_list	        sso_grp_profile_list;
+	struct cvmx_pki_qpg_list	        qpg_profile_list;
 };
 
 extern CVMX_SHARED struct cvmx_pki_config pki_config[CVMX_MAX_NODES];
+extern CVMX_SHARED struct cvmx_pki_profiles pki_profiles[CVMX_MAX_NODES];
 
 /**
  * This function writes qpg entry at specified offset in hardware
@@ -607,9 +679,298 @@ int cvmx_pki_write_aura_bpid(int node, int aura, int bpid);
  *                  max DROP level exceeds.
  *                  1-enable 0-disable
  */
- int cvmx_pki_enable_aura_qos(int node, int aura, bool ena_red,
+int cvmx_pki_enable_aura_qos(int node, int aura, bool ena_red,
 			      bool ena_drop, bool ena_bp);
 
+/**
+ * This function finds if cluster profile with name already exist
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	profile index in cluster list on SUCCESS
+                -1 if profile not found in cluster list
+ */
+int cvmx_pki_cluster_profile_exist(int node, char *name);
+
+/**
+ * This function finds cluster mask associated with
+ * given cluster profile name.
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	cluster_mask on SUCCESS
+                -1 if profile not found in cluster list
+ */
+int cvmx_pki_find_cluster_mask(int node, char *name);
+
+/**
+ * This function finds cluster group associated with
+ * given cluster profile name
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	cluster group number on SUCCESS
+                -1 if profile not found in cluster list
+ */
+int cvmx_pki_find_cluster_group(int node, char *name);
+
+/**
+ * This function finds if fpa pool profile with
+ * name already exist
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	profile index in pool list on SUCCESS
+                -1 if profile not found in pool list
+ */
+int cvmx_pki_pool_profile_exist(int node, char *name);
+
+/**
+ * This function finds if fpa pool number associated with
+ * given profile name
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	pool number on SUCCESS
+                -1 if profile not found in pool list
+ */
+int cvmx_pki_find_pool(int node, char *name);
+
+/**
+ * This function finds if fpa aura with given name
+ * exist in aura list
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	aura index in aura list on SUCCESS
+                -1 if profile not found in aura list
+ */
+int cvmx_pki_aura_profile_exist(int node, char *name);
+
+/**
+ * This function finds aura number associated with
+ * given aura name.
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	aura number in aura list on SUCCESS
+                -1 if profile not found in aura list
+ */
+int cvmx_pki_find_aura(int node, char *name);
+
+/**
+ * This function finds if group with given name
+ * exist in group list
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	index in group list on SUCCESS
+                -1 if profile not found in group list
+ */
+int cvmx_pki_group_profile_exist(int node, char *name);
+
+/**
+ * This function finds group number associated with
+ * given group profile name
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	group number on SUCCESS
+                -1 if profile not found in group list
+ */
+int cvmx_pki_find_group(int node, char *name);
+
+/**
+ * This function finds if qpg profile with given name
+ * exist in qpg list
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	index in qpg list on SUCCESS
+                -1 if profile not found in qpg list
+ */
+int cvmx_pki_qpg_profile_exist(int node, char *name);
+
+/**
+ * This function finds qpg base offset associated with
+ * given qpg profile name.
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	qpg base offset on SUCCESS
+                -1 if profile not found in qpg list
+ */
+int cvmx_pki_find_qpg_base_offset(int node, char *name);
+
+/**
+ * This function get the buffer size of the given pool number
+ * @param node  node number
+ * @param pool  fpa pool number
+ * @return 	buffer size SUCCESS
+                -1 if pool number is not found in pool list
+ */
+int cvmx_pki_get_pool_buffer_size(int node,int pool);
+
+/**
+ * This function get the buffer size of the given aura number
+ * @param node  node number
+ * @param pool  fpa aura number
+ * @return 	buffer size SUCCESS
+                -1 if aura number is not found in aura list
+ */
+int cvmx_pki_get_aura_buffer_size(int node, int aura);
+
+int cvmx_pki_get_mbuff_size (int node, int base_offset);
+
+/**
+ * This function finds if style profile with given name
+ * exist in style list
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	index into style list on SUCCESS
+                -1 if profile not found in style list
+ */
+int cvmx_pki_style_profile_exist(int node, char *name);
+
+/**
+ * This function finds style number associated with
+ * given style profile name.
+ * @param node  node number
+ * @param name  profile name to look for
+ * @return 	style number on SUCCESS
+                -1 if profile not found in style list
+ */
+int cvmx_pki_find_style(int node, char *name);
+
+
+/**
+ * This function stores the cluster configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param name  	name associated with this config
+ * @param cl_profile    structure containing cluster profile parameters below
+ * 			-cluster_group (-1 if needs to be allocated)
+ * 			-num_cluster   (number of cluster in the cluster group)
+ * 			-parsing_mask  (parsing mask for the cluster group)
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_cluster_config(int node, struct cvmx_pki_cluster_profile cl_profile);
+
+/**
+ * This function stores the pool configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pool_name  	name associated with this config
+ * @param pool_numb     pool number (-1 if need to be allocated)
+ * @param buffer_size	size of buffers in specified pool
+ * @param num_buffers	numberof buffers in specified pool
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_pool_config(int node, char* pool_name, int pool_num,
+			     uint64_t buffer_size, uint64_t num_buffers);
+
+/**
+ * This function stores the aura configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param aura_name  	name associated with this config
+ * @param aura_num      aura number (-1 if need to be allocated)
+ * @param pool  	pool to which aura is mapped
+ * @param num_buffers	number of buffers to allocate to aura.
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_aura_config(int node, char* aura_name, int aura_num, int pool,
+			     int num_buffers);
+
+/**
+ * This function stores the group configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param grp_profile	struct to SSO group profile to configure
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_sso_group_config(int node, struct cvmx_pki_sso_grp_profile grp_profile);
+
+/**
+ * This function stores the qpg configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param name  	name associated with this config
+ * @param base_offset	offset in QPG table (-1 if needs to be allocated)
+ * @param num_entries	total number of indexes needs to be allocated from
+ *                      base_offset.
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_qpg_profile(int node, char* name, int base_offset, int num_entries);
+
+/**
+ * This function stores the group configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param aura_name  	name associated with this config
+ * @param group		SSO group number (-1 if needs to be allocated)
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_qpg_config(int node, char* name, int entry_start,
+			    int entry_end, struct cvmx_pki_qpg_config qpg_config);
+
+/**
+ * This function stores the style configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param aura_name  	name associated with this config
+ * @param style_num	style number (-1 if needs to be allocated)
+ * @param style_cfg	pointer to struct which has parameters related
+ *                      to style config
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_style_config(int node, char* style_name, int style_num,
+			      struct cvmx_pki_style_config* style_cfg);
+
+/**
+ * This function stores the pkind style configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pkind  	pkind number
+ * @param style_name	pointer to style name which need to be assigned to pkind
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+int cvmx_pki_set_pkind_style(int node, int pkind, int style_name);
+
+/**
+ * This function stores the pkind initial parse mode in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pkind  	pkind number
+ * @param parse_mode    parse mode to assign to specified pkind.
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+void cvmx_pki_set_pkind_initial_parse_mode(int node, int pkind, int parse_mode);
+
+/**
+ * This function stores the pkind cluster configuration in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param pkind  	pkind number
+ * @param style_name	pointer to style name which need to be assigned to pkind
+ * @return 		0 on SUCCESS
+                        -1 on failure
+ */
+void cvmx_pki_set_pkind_cluster_config(int node, int pkind,
+				       int cl_grp, uint64_t cl_mask);
+
+/**
+ * This function stores the pcam entry in data structure
+ * which is then used to program the hardware.
+ * @param node  	node number
+ * @param cluster_mask	Mask of clusters on which the entry meeds to be appiled.
+ * @param input		structure of pcam input parameter which defines matching creteria.
+ * @param action	structure of pcam action parameters which aill be applied if match is found.
+ * @return              0 on scuccess
+ *			-1 on failure
+ */
+int cvmx_pki_set_pcam_entry(int node, int pcam_index, uint64_t cl_mask,
+			    struct cvmx_pki_pcam_input input,
+			    struct cvmx_pki_pcam_action action);
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-pko-defs.h b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
index 1396d44..22c7fa1 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -108,6 +108,17 @@ static inline uint64_t CVMX_PKO_DPFI_STATUS_FUNC(void)
 #define CVMX_PKO_DPFI_STATUS (CVMX_ADD_IO_SEG(0x0001540000C00000ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_DQX_BYTES(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
+		cvmx_warn("CVMX_PKO_DQX_BYTES(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00015400000000C8ull) + ((offset) & 1023) * 512;
+}
+#else
+#define CVMX_PKO_DQX_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000C8ull) + ((offset) & 1023) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_DQX_CIR(unsigned long offset)
 {
 	if (!(
@@ -141,6 +152,28 @@ static inline uint64_t CVMX_PKO_DQX_DROPPED_PACKETS(unsigned long offset)
 #define CVMX_PKO_DQX_DROPPED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000D0ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_DQX_FIFO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
+		cvmx_warn("CVMX_PKO_DQX_FIFO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001540000300078ull) + ((offset) & 1023) * 512;
+}
+#else
+#define CVMX_PKO_DQX_FIFO(offset) (CVMX_ADD_IO_SEG(0x0001540000300078ull) + ((offset) & 1023) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_DQX_PACKETS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
+		cvmx_warn("CVMX_PKO_DQX_PACKETS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00015400000000C0ull) + ((offset) & 1023) * 512;
+}
+#else
+#define CVMX_PKO_DQX_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000C0ull) + ((offset) & 1023) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_DQX_PICK(unsigned long offset)
 {
 	if (!(
@@ -196,28 +229,6 @@ static inline uint64_t CVMX_PKO_DQX_SCHED_STATE(unsigned long offset)
 #define CVMX_PKO_DQX_SCHED_STATE(offset) (CVMX_ADD_IO_SEG(0x0001540000280028ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_DQX_SENT_BYTES(unsigned long offset)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
-		cvmx_warn("CVMX_PKO_DQX_SENT_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000C8ull) + ((offset) & 1023) * 512;
-}
-#else
-#define CVMX_PKO_DQX_SENT_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000C8ull) + ((offset) & 1023) * 512)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_DQX_SENT_PACKETS(unsigned long offset)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
-		cvmx_warn("CVMX_PKO_DQX_SENT_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000C0ull) + ((offset) & 1023) * 512;
-}
-#else
-#define CVMX_PKO_DQX_SENT_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000C0ull) + ((offset) & 1023) * 512)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_DQX_SHAPE(unsigned long offset)
 {
 	if (!(
@@ -295,6 +306,28 @@ static inline uint64_t CVMX_PKO_DQX_WM_CTL_W1C(unsigned long offset)
 #define CVMX_PKO_DQX_WM_CTL_W1C(offset) (CVMX_ADD_IO_SEG(0x0001540000000048ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_DQ_DEBUG CVMX_PKO_DQ_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_DQ_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_DQ_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000300128ull);
+}
+#else
+#define CVMX_PKO_DQ_DEBUG (CVMX_ADD_IO_SEG(0x0001540000300128ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_DRAIN_IRQ CVMX_PKO_DRAIN_IRQ_FUNC()
+static inline uint64_t CVMX_PKO_DRAIN_IRQ_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_DRAIN_IRQ not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000000140ull);
+}
+#else
+#define CVMX_PKO_DRAIN_IRQ (CVMX_ADD_IO_SEG(0x0001540000000140ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_ENABLE CVMX_PKO_ENABLE_FUNC()
 static inline uint64_t CVMX_PKO_ENABLE_FUNC(void)
 {
@@ -317,6 +350,28 @@ static inline uint64_t CVMX_PKO_FORMATX_CTL(unsigned long offset)
 #define CVMX_PKO_FORMATX_CTL(offset) (CVMX_ADD_IO_SEG(0x0001540000900800ull) + ((offset) & 127) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L1_SQA_DEBUG CVMX_PKO_L1_SQA_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L1_SQA_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L1_SQA_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000080128ull);
+}
+#else
+#define CVMX_PKO_L1_SQA_DEBUG (CVMX_ADD_IO_SEG(0x0001540000080128ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L1_SQB_DEBUG CVMX_PKO_L1_SQB_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L1_SQB_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L1_SQB_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000080130ull);
+}
+#else
+#define CVMX_PKO_L1_SQB_DEBUG (CVMX_ADD_IO_SEG(0x0001540000080130ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_CIR(unsigned long offset)
 {
 	if (!(
@@ -328,6 +383,28 @@ static inline uint64_t CVMX_PKO_L1_SQX_CIR(unsigned long offset)
 #define CVMX_PKO_L1_SQX_CIR(offset) (CVMX_ADD_IO_SEG(0x0001540000000018ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_DROPPED_BYTES(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_DROPPED_BYTES(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00015400000000B8ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_DROPPED_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000B8ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_DROPPED_PACKETS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_DROPPED_PACKETS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00015400000000B0ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_DROPPED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000B0ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_GREEN(unsigned long offset)
 {
 	if (!(
@@ -339,6 +416,28 @@ static inline uint64_t CVMX_PKO_L1_SQX_GREEN(unsigned long offset)
 #define CVMX_PKO_L1_SQX_GREEN(offset) (CVMX_ADD_IO_SEG(0x0001540000080058ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_GREEN_BYTES(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_GREEN_BYTES(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001540000000088ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_GREEN_BYTES(offset) (CVMX_ADD_IO_SEG(0x0001540000000088ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_GREEN_PACKETS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_GREEN_PACKETS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001540000000080ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_GREEN_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000080ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_LINK(unsigned long offset)
 {
 	if (!(
@@ -383,6 +482,28 @@ static inline uint64_t CVMX_PKO_L1_SQX_RED(unsigned long offset)
 #define CVMX_PKO_L1_SQX_RED(offset) (CVMX_ADD_IO_SEG(0x0001540000080068ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_RED_BYTES(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_RED_BYTES(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00015400000000A8ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_RED_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000A8ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_RED_PACKETS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_RED_PACKETS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00015400000000A0ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_RED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000A0ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_SHAPE(unsigned long offset)
 {
 	if (!(
@@ -438,6 +559,50 @@ static inline uint64_t CVMX_PKO_L1_SQX_YELLOW(unsigned long offset)
 #define CVMX_PKO_L1_SQX_YELLOW(offset) (CVMX_ADD_IO_SEG(0x0001540000080060ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_YELLOW_BYTES(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_YELLOW_BYTES(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001540000000098ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_YELLOW_BYTES(offset) (CVMX_ADD_IO_SEG(0x0001540000000098ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_YELLOW_PACKETS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_YELLOW_PACKETS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_YELLOW_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L2_SQA_DEBUG CVMX_PKO_L2_SQA_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L2_SQA_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L2_SQA_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000100128ull);
+}
+#else
+#define CVMX_PKO_L2_SQA_DEBUG (CVMX_ADD_IO_SEG(0x0001540000100128ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L2_SQB_DEBUG CVMX_PKO_L2_SQB_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L2_SQB_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L2_SQB_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000100130ull);
+}
+#else
+#define CVMX_PKO_L2_SQB_DEBUG (CVMX_ADD_IO_SEG(0x0001540000100130ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L2_SQX_CIR(unsigned long offset)
 {
 	if (!(
@@ -592,6 +757,28 @@ static inline uint64_t CVMX_PKO_L3_L2_SQX_CHANNEL(unsigned long offset)
 #define CVMX_PKO_L3_L2_SQX_CHANNEL(offset) (CVMX_ADD_IO_SEG(0x0001540000080038ull) + ((offset) & 511) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L3_SQA_DEBUG CVMX_PKO_L3_SQA_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L3_SQA_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L3_SQA_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000180128ull);
+}
+#else
+#define CVMX_PKO_L3_SQA_DEBUG (CVMX_ADD_IO_SEG(0x0001540000180128ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L3_SQB_DEBUG CVMX_PKO_L3_SQB_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L3_SQB_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L3_SQB_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000180130ull);
+}
+#else
+#define CVMX_PKO_L3_SQB_DEBUG (CVMX_ADD_IO_SEG(0x0001540000180130ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L3_SQX_CIR(unsigned long offset)
 {
 	if (!(
@@ -735,6 +922,28 @@ static inline uint64_t CVMX_PKO_L3_SQX_YELLOW(unsigned long offset)
 #define CVMX_PKO_L3_SQX_YELLOW(offset) (CVMX_ADD_IO_SEG(0x0001540000180060ull) + ((offset) & 511) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L4_SQA_DEBUG CVMX_PKO_L4_SQA_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L4_SQA_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L4_SQA_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000200128ull);
+}
+#else
+#define CVMX_PKO_L4_SQA_DEBUG (CVMX_ADD_IO_SEG(0x0001540000200128ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L4_SQB_DEBUG CVMX_PKO_L4_SQB_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L4_SQB_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L4_SQB_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000200130ull);
+}
+#else
+#define CVMX_PKO_L4_SQB_DEBUG (CVMX_ADD_IO_SEG(0x0001540000200130ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L4_SQX_CIR(unsigned long offset)
 {
 	if (!(
@@ -878,6 +1087,28 @@ static inline uint64_t CVMX_PKO_L4_SQX_YELLOW(unsigned long offset)
 #define CVMX_PKO_L4_SQX_YELLOW(offset) (CVMX_ADD_IO_SEG(0x0001540000200060ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L5_SQA_DEBUG CVMX_PKO_L5_SQA_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L5_SQA_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L5_SQA_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000280128ull);
+}
+#else
+#define CVMX_PKO_L5_SQA_DEBUG (CVMX_ADD_IO_SEG(0x0001540000280128ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L5_SQB_DEBUG CVMX_PKO_L5_SQB_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L5_SQB_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L5_SQB_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000280130ull);
+}
+#else
+#define CVMX_PKO_L5_SQB_DEBUG (CVMX_ADD_IO_SEG(0x0001540000280130ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L5_SQX_CIR(unsigned long offset)
 {
 	if (!(
@@ -1312,6 +1543,17 @@ static inline uint64_t CVMX_PKO_MEM_THROTTLE_PIPE_FUNC(void)
 #define CVMX_PKO_MEM_THROTTLE_PIPE (CVMX_ADD_IO_SEG(0x0001180050001050ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_NCB_BIST_STATUS CVMX_PKO_NCB_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_NCB_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_NCB_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000EFFF00ull);
+}
+#else
+#define CVMX_PKO_NCB_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000EFFF00ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_NCB_ECC_CTL0 CVMX_PKO_NCB_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_NCB_ECC_CTL0_FUNC(void)
 {
@@ -1400,6 +1642,17 @@ static inline uint64_t CVMX_PKO_NCB_TX_ERR_WORD_FUNC(void)
 #define CVMX_PKO_NCB_TX_ERR_WORD (CVMX_ADD_IO_SEG(0x0001540000E00000ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_BIST_STATUS CVMX_PKO_PDM_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PDM_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008FFF00ull);
+}
+#else
+#define CVMX_PKO_PDM_BIST_STATUS (CVMX_ADD_IO_SEG(0x00015400008FFF00ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PDM_CFG CVMX_PKO_PDM_CFG_FUNC()
 static inline uint64_t CVMX_PKO_PDM_CFG_FUNC(void)
 {
@@ -1411,6 +1664,28 @@ static inline uint64_t CVMX_PKO_PDM_CFG_FUNC(void)
 #define CVMX_PKO_PDM_CFG (CVMX_ADD_IO_SEG(0x0001540000800000ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_CFG_DBG CVMX_PKO_PDM_CFG_DBG_FUNC()
+static inline uint64_t CVMX_PKO_PDM_CFG_DBG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_CFG_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000800FF8ull);
+}
+#else
+#define CVMX_PKO_PDM_CFG_DBG (CVMX_ADD_IO_SEG(0x0001540000800FF8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_CP_DBG CVMX_PKO_PDM_CP_DBG_FUNC()
+static inline uint64_t CVMX_PKO_PDM_CP_DBG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_CP_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000800190ull);
+}
+#else
+#define CVMX_PKO_PDM_CP_DBG (CVMX_ADD_IO_SEG(0x0001540000800190ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_PDM_DQX_MINPAD(unsigned long offset)
 {
 	if (!(
@@ -1422,6 +1697,28 @@ static inline uint64_t CVMX_PKO_PDM_DQX_MINPAD(unsigned long offset)
 #define CVMX_PKO_PDM_DQX_MINPAD(offset) (CVMX_ADD_IO_SEG(0x00015400008F0000ull) + ((offset) & 1023) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_DRPBUF_DBG CVMX_PKO_PDM_DRPBUF_DBG_FUNC()
+static inline uint64_t CVMX_PKO_PDM_DRPBUF_DBG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_DRPBUF_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008000B0ull);
+}
+#else
+#define CVMX_PKO_PDM_DRPBUF_DBG (CVMX_ADD_IO_SEG(0x00015400008000B0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_DWPBUF_DBG CVMX_PKO_PDM_DWPBUF_DBG_FUNC()
+static inline uint64_t CVMX_PKO_PDM_DWPBUF_DBG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_DWPBUF_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008000A8ull);
+}
+#else
+#define CVMX_PKO_PDM_DWPBUF_DBG (CVMX_ADD_IO_SEG(0x00015400008000A8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PDM_ECC_CTL0 CVMX_PKO_PDM_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_PDM_ECC_CTL0_FUNC(void)
 {
@@ -1433,6 +1730,17 @@ static inline uint64_t CVMX_PKO_PDM_ECC_CTL0_FUNC(void)
 #define CVMX_PKO_PDM_ECC_CTL0 (CVMX_ADD_IO_SEG(0x00015400008FFFD0ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_ECC_CTL1 CVMX_PKO_PDM_ECC_CTL1_FUNC()
+static inline uint64_t CVMX_PKO_PDM_ECC_CTL1_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_ECC_CTL1 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008FFFD8ull);
+}
+#else
+#define CVMX_PKO_PDM_ECC_CTL1 (CVMX_ADD_IO_SEG(0x00015400008FFFD8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PDM_ECC_DBE_STS0 CVMX_PKO_PDM_ECC_DBE_STS0_FUNC()
 static inline uint64_t CVMX_PKO_PDM_ECC_DBE_STS0_FUNC(void)
 {
@@ -1449,10 +1757,10 @@ static inline uint64_t CVMX_PKO_PDM_ECC_DBE_STS_CMB0_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
 		cvmx_warn("CVMX_PKO_PDM_ECC_DBE_STS_CMB0 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00015400008FFFD8ull);
+	return CVMX_ADD_IO_SEG(0x00015400008FFFE0ull);
 }
 #else
-#define CVMX_PKO_PDM_ECC_DBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x00015400008FFFD8ull))
+#define CVMX_PKO_PDM_ECC_DBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x00015400008FFFE0ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PDM_ECC_SBE_STS0 CVMX_PKO_PDM_ECC_SBE_STS0_FUNC()
@@ -1477,6 +1785,50 @@ static inline uint64_t CVMX_PKO_PDM_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PDM_ECC_SBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x00015400008FFFE8ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_ISRD_DBG CVMX_PKO_PDM_ISRD_DBG_FUNC()
+static inline uint64_t CVMX_PKO_PDM_ISRD_DBG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_ISRD_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000800090ull);
+}
+#else
+#define CVMX_PKO_PDM_ISRD_DBG (CVMX_ADD_IO_SEG(0x0001540000800090ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_ISRD_DBG_DQ CVMX_PKO_PDM_ISRD_DBG_DQ_FUNC()
+static inline uint64_t CVMX_PKO_PDM_ISRD_DBG_DQ_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_ISRD_DBG_DQ not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000800290ull);
+}
+#else
+#define CVMX_PKO_PDM_ISRD_DBG_DQ (CVMX_ADD_IO_SEG(0x0001540000800290ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_ISRM_DBG CVMX_PKO_PDM_ISRM_DBG_FUNC()
+static inline uint64_t CVMX_PKO_PDM_ISRM_DBG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_ISRM_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000800098ull);
+}
+#else
+#define CVMX_PKO_PDM_ISRM_DBG (CVMX_ADD_IO_SEG(0x0001540000800098ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_ISRM_DBG_DQ CVMX_PKO_PDM_ISRM_DBG_DQ_FUNC()
+static inline uint64_t CVMX_PKO_PDM_ISRM_DBG_DQ_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_ISRM_DBG_DQ not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000800298ull);
+}
+#else
+#define CVMX_PKO_PDM_ISRM_DBG_DQ (CVMX_ADD_IO_SEG(0x0001540000800298ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PDM_MEM_ADDR CVMX_PKO_PDM_MEM_ADDR_FUNC()
 static inline uint64_t CVMX_PKO_PDM_MEM_ADDR_FUNC(void)
 {
@@ -1521,15 +1873,15 @@ static inline uint64_t CVMX_PKO_PDM_MEM_RW_STS_FUNC(void)
 #define CVMX_PKO_PDM_MEM_RW_STS (CVMX_ADD_IO_SEG(0x0001540000800028ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_PKO_PDM_SENDPKT_LMTXX_ERR CVMX_PKO_PDM_SENDPKT_LMTXX_ERR_FUNC()
-static inline uint64_t CVMX_PKO_PDM_SENDPKT_LMTXX_ERR_FUNC(void)
+#define CVMX_PKO_PDM_MWPBUF_DBG CVMX_PKO_PDM_MWPBUF_DBG_FUNC()
+static inline uint64_t CVMX_PKO_PDM_MWPBUF_DBG_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_PKO_PDM_SENDPKT_LMTXX_ERR not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00015400008000F8ull);
+		cvmx_warn("CVMX_PKO_PDM_MWPBUF_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008000A0ull);
 }
 #else
-#define CVMX_PKO_PDM_SENDPKT_LMTXX_ERR (CVMX_ADD_IO_SEG(0x00015400008000F8ull))
+#define CVMX_PKO_PDM_MWPBUF_DBG (CVMX_ADD_IO_SEG(0x00015400008000A0ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PDM_STS CVMX_PKO_PDM_STS_FUNC()
@@ -1543,6 +1895,17 @@ static inline uint64_t CVMX_PKO_PDM_STS_FUNC(void)
 #define CVMX_PKO_PDM_STS (CVMX_ADD_IO_SEG(0x0001540000800008ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PEB_BIST_STATUS CVMX_PKO_PEB_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PEB_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900D00ull);
+}
+#else
+#define CVMX_PKO_PEB_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000900D00ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PEB_ECC_CTL0 CVMX_PKO_PEB_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_PEB_ECC_CTL0_FUNC(void)
 {
@@ -1620,103 +1983,180 @@ static inline uint64_t CVMX_PKO_PEB_ERR_INT_FUNC(void)
 #define CVMX_PKO_PEB_ERR_INT (CVMX_ADD_IO_SEG(0x0001540000900C00ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_DROPPED_BYTES(unsigned long offset)
+#define CVMX_PKO_PEB_EXT_HDR_DEF_ERR_INFO CVMX_PKO_PEB_EXT_HDR_DEF_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_EXT_HDR_DEF_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_DROPPED_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000B8ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_EXT_HDR_DEF_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C08ull);
 }
 #else
-#define CVMX_PKO_PQX_DROPPED_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000B8ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_EXT_HDR_DEF_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C08ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_DROPPED_PACKETS(unsigned long offset)
+#define CVMX_PKO_PEB_FCS_SOP_ERR_INFO CVMX_PKO_PEB_FCS_SOP_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_FCS_SOP_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_DROPPED_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000B0ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_FCS_SOP_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C18ull);
 }
 #else
-#define CVMX_PKO_PQX_DROPPED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000B0ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_FCS_SOP_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C18ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_GREEN_SENT_BYTES(unsigned long offset)
+#define CVMX_PKO_PEB_JUMP_DEF_ERR_INFO CVMX_PKO_PEB_JUMP_DEF_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_JUMP_DEF_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_GREEN_SENT_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000088ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_JUMP_DEF_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C10ull);
 }
 #else
-#define CVMX_PKO_PQX_GREEN_SENT_BYTES(offset) (CVMX_ADD_IO_SEG(0x0001540000000088ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_JUMP_DEF_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C10ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_GREEN_SENT_PACKETS(unsigned long offset)
+#define CVMX_PKO_PEB_MACX_CFG_WR_ERR_INFO CVMX_PKO_PEB_MACX_CFG_WR_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_MACX_CFG_WR_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_GREEN_SENT_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000080ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_MACX_CFG_WR_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C50ull);
 }
 #else
-#define CVMX_PKO_PQX_GREEN_SENT_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000080ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_MACX_CFG_WR_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C50ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_RED_SENT_BYTES(unsigned long offset)
+#define CVMX_PKO_PEB_MAX_LINK_ERR_INFO CVMX_PKO_PEB_MAX_LINK_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_MAX_LINK_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_RED_SENT_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000A8ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_MAX_LINK_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C48ull);
 }
 #else
-#define CVMX_PKO_PQX_RED_SENT_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000A8ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_MAX_LINK_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C48ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_RED_SENT_PACKETS(unsigned long offset)
+#define CVMX_PKO_PEB_PAD_ERR_INFO CVMX_PKO_PEB_PAD_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_PAD_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_RED_SENT_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000A0ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_PAD_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C28ull);
 }
 #else
-#define CVMX_PKO_PQX_RED_SENT_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000A0ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_PAD_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C28ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_TOPOLOGY(unsigned long offset)
+#define CVMX_PKO_PEB_PSE_FIFO_ERR_INFO CVMX_PKO_PEB_PSE_FIFO_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_PSE_FIFO_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_TOPOLOGY(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000000ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_PSE_FIFO_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C20ull);
 }
 #else
-#define CVMX_PKO_PQX_TOPOLOGY(offset) (CVMX_ADD_IO_SEG(0x0001540000000000ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_PSE_FIFO_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C20ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_YELLOW_SENT_BYTES(unsigned long offset)
+#define CVMX_PKO_PEB_SUBD_ADDR_ERR_INFO CVMX_PKO_PEB_SUBD_ADDR_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_SUBD_ADDR_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_YELLOW_SENT_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000098ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_SUBD_ADDR_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C38ull);
 }
 #else
-#define CVMX_PKO_PQX_YELLOW_SENT_BYTES(offset) (CVMX_ADD_IO_SEG(0x0001540000000098ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_SUBD_ADDR_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C38ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_PQX_YELLOW_SENT_PACKETS(unsigned long offset)
+#define CVMX_PKO_PEB_SUBD_SIZE_ERR_INFO CVMX_PKO_PEB_SUBD_SIZE_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_SUBD_SIZE_ERR_INFO_FUNC(void)
 {
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_PQX_YELLOW_SENT_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_SUBD_SIZE_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C40ull);
+}
+#else
+#define CVMX_PKO_PEB_SUBD_SIZE_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C40ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PEB_TRUNC_ERR_INFO CVMX_PKO_PEB_TRUNC_ERR_INFO_FUNC()
+static inline uint64_t CVMX_PKO_PEB_TRUNC_ERR_INFO_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_TRUNC_ERR_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900C30ull);
 }
 #else
-#define CVMX_PKO_PQX_YELLOW_SENT_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_PEB_TRUNC_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C30ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PQA_DEBUG CVMX_PKO_PQA_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_PQA_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PQA_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000000128ull);
+}
+#else
+#define CVMX_PKO_PQA_DEBUG (CVMX_ADD_IO_SEG(0x0001540000000128ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PQB_DEBUG CVMX_PKO_PQB_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_PQB_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PQB_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000000130ull);
+}
+#else
+#define CVMX_PKO_PQB_DEBUG (CVMX_ADD_IO_SEG(0x0001540000000130ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PQ_DEBUG_GREEN CVMX_PKO_PQ_DEBUG_GREEN_FUNC()
+static inline uint64_t CVMX_PKO_PQ_DEBUG_GREEN_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PQ_DEBUG_GREEN not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000000058ull);
+}
+#else
+#define CVMX_PKO_PQ_DEBUG_GREEN (CVMX_ADD_IO_SEG(0x0001540000000058ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PQ_DEBUG_LINKS CVMX_PKO_PQ_DEBUG_LINKS_FUNC()
+static inline uint64_t CVMX_PKO_PQ_DEBUG_LINKS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PQ_DEBUG_LINKS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000000068ull);
+}
+#else
+#define CVMX_PKO_PQ_DEBUG_LINKS (CVMX_ADD_IO_SEG(0x0001540000000068ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PQ_DEBUG_YELLOW CVMX_PKO_PQ_DEBUG_YELLOW_FUNC()
+static inline uint64_t CVMX_PKO_PQ_DEBUG_YELLOW_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PQ_DEBUG_YELLOW not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000000060ull);
+}
+#else
+#define CVMX_PKO_PQ_DEBUG_YELLOW (CVMX_ADD_IO_SEG(0x0001540000000060ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PSE_DQ_BIST_STATUS CVMX_PKO_PSE_DQ_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PSE_DQ_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PSE_DQ_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000300138ull);
+}
+#else
+#define CVMX_PKO_PSE_DQ_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000300138ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PSE_DQ_ECC_CTL0 CVMX_PKO_PSE_DQ_ECC_CTL0_FUNC()
@@ -1774,6 +2214,17 @@ static inline uint64_t CVMX_PKO_PSE_DQ_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PSE_DQ_ECC_SBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x0001540000300110ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PSE_PQ_BIST_STATUS CVMX_PKO_PSE_PQ_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PSE_PQ_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PSE_PQ_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000000138ull);
+}
+#else
+#define CVMX_PKO_PSE_PQ_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000000138ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PSE_PQ_ECC_CTL0 CVMX_PKO_PSE_PQ_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_PSE_PQ_ECC_CTL0_FUNC(void)
 {
@@ -1829,6 +2280,17 @@ static inline uint64_t CVMX_PKO_PSE_PQ_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PSE_PQ_ECC_SBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x0001540000000110ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PSE_SQ1_BIST_STATUS CVMX_PKO_PSE_SQ1_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PSE_SQ1_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PSE_SQ1_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000080138ull);
+}
+#else
+#define CVMX_PKO_PSE_SQ1_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000080138ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PSE_SQ1_ECC_CTL0 CVMX_PKO_PSE_SQ1_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_PSE_SQ1_ECC_CTL0_FUNC(void)
 {
@@ -1884,6 +2346,17 @@ static inline uint64_t CVMX_PKO_PSE_SQ1_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PSE_SQ1_ECC_SBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x0001540000080110ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PSE_SQ2_BIST_STATUS CVMX_PKO_PSE_SQ2_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PSE_SQ2_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PSE_SQ2_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000100138ull);
+}
+#else
+#define CVMX_PKO_PSE_SQ2_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000100138ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PSE_SQ2_ECC_CTL0 CVMX_PKO_PSE_SQ2_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_PSE_SQ2_ECC_CTL0_FUNC(void)
 {
@@ -1939,6 +2412,17 @@ static inline uint64_t CVMX_PKO_PSE_SQ2_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PSE_SQ2_ECC_SBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x0001540000100110ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PSE_SQ3_BIST_STATUS CVMX_PKO_PSE_SQ3_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PSE_SQ3_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PSE_SQ3_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000180138ull);
+}
+#else
+#define CVMX_PKO_PSE_SQ3_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000180138ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PSE_SQ3_ECC_CTL0 CVMX_PKO_PSE_SQ3_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_PSE_SQ3_ECC_CTL0_FUNC(void)
 {
@@ -1994,6 +2478,17 @@ static inline uint64_t CVMX_PKO_PSE_SQ3_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PSE_SQ3_ECC_SBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x0001540000180110ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PSE_SQ4_BIST_STATUS CVMX_PKO_PSE_SQ4_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PSE_SQ4_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PSE_SQ4_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000200138ull);
+}
+#else
+#define CVMX_PKO_PSE_SQ4_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000200138ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PSE_SQ4_ECC_CTL0 CVMX_PKO_PSE_SQ4_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_PSE_SQ4_ECC_CTL0_FUNC(void)
 {
@@ -2049,6 +2544,17 @@ static inline uint64_t CVMX_PKO_PSE_SQ4_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PSE_SQ4_ECC_SBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x0001540000200110ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PSE_SQ5_BIST_STATUS CVMX_PKO_PSE_SQ5_BIST_STATUS_FUNC()
+static inline uint64_t CVMX_PKO_PSE_SQ5_BIST_STATUS_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PSE_SQ5_BIST_STATUS not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000280138ull);
+}
+#else
+#define CVMX_PKO_PSE_SQ5_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001540000280138ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PSE_SQ5_ECC_CTL0 CVMX_PKO_PSE_SQ5_ECC_CTL0_FUNC()
 static inline uint64_t CVMX_PKO_PSE_SQ5_ECC_CTL0_FUNC(void)
 {
@@ -2426,11 +2932,11 @@ union cvmx_pko_dpfi_flush {
 	struct cvmx_pko_dpfi_flush_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t flush_en                     : 1;  /**< Pointer cache flush enable. When set to 1 this flag commands the DPFI logic to flush all
+	uint64_t flush_en                     : 1;  /**< Pointer cache flush enable. When set, this flag commands the DPFI logic to flush all
                                                          valid pointers from the pointer cache and return them to the FPA. The flush operation is
-                                                         complete when the CACHE_FLUSHED flag in the PKO_DFPI_STATUS register is set. Clearing the
-                                                         FLUSH_EN flag results in the DPFI reloading its pointer cache. This flush mechanism should
-                                                         only be enabled when the PKO is quiescent and is intended as test/debug feature. */
+                                                         complete when the CACHE_FLUSHED flag in PKO_DPFI_STATUS is set. Clearing the FLUSH_EN flag
+                                                         results in the DPFI reloading its pointer cache. This flush mechanism should only be
+                                                         enabled when the PKO is quiescent and all DQs have been closed. */
 #else
 	uint64_t flush_en                     : 1;
 	uint64_t reserved_1_63                : 63;
@@ -2467,32 +2973,24 @@ union cvmx_pko_dpfi_status {
 	uint64_t u64;
 	struct cvmx_pko_dpfi_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_13_63               : 51;
-	uint64_t isrd_ptr1_rtn_full           : 1;  /**< 1 = ISRD pointer return register 1 contains a valid pointer
-                                                         0 = ISRD pointer return register 1 is empty */
-	uint64_t isrd_ptr0_rtn_full           : 1;  /**< 1 = ISRD pointer return register 0 contains a valid pointer
-                                                         0 = ISRD pointer return register 0 is empty */
-	uint64_t isrm_ptr1_rtn_full           : 1;  /**< 1 = ISRM pointer return register 1 contains a valid pointer
-                                                         0 = ISRM pointer return register 1 is empty */
-	uint64_t isrm_ptr0_rtn_full           : 1;  /**< 1 = ISRM pointer return register 0 contains a valid pointer
-                                                         0 = ISRM pointer return register 0 is empty */
-	uint64_t isrd_ptr1_val                : 1;  /**< 1 = ISRD pointer register 1 contains a valid pointer
-                                                         0 = ISRD pointer register 1 is empty */
-	uint64_t isrd_ptr0_val                : 1;  /**< 1 = ISRD pointer register 0 contains a valid pointer
-                                                         0 = ISRD pointer register 0 is empty */
-	uint64_t isrm_ptr1_val                : 1;  /**< 1 = ISRM pointer register 1 contains a valid pointer
-                                                         0 = ISRM pointer register 1 is empty */
-	uint64_t isrm_ptr0_val                : 1;  /**< 1 = ISRM pointer register 0 contains a valid pointer
-                                                         0 = ISRM pointer register 0 is empty */
-	uint64_t ptr_req_pend                 : 1;  /**< 1 = DPFI has pointer requests to FPA pending
-                                                         0 = DPFI has no pointer requests to FPA pending */
-	uint64_t ptr_rtn_pend                 : 1;  /**< 1 = DPFI has pointer returns to FPA pending
-                                                         0 = DPFI has no pointer returns to FPA pending */
-	uint64_t fpa_empty                    : 1;  /**< 1 = FPA responded to pointer request with 'no pointers available'.
+	uint64_t ptr_cnt                      : 32; /**< The number of pointers currently in use for storing descriptors
+                                                         and meta-packets plus those available in the DPFI pointer cache. */
+	uint64_t reserved_13_31               : 19;
+	uint64_t isrd_ptr1_rtn_full           : 1;  /**< ISRD pointer return register 1 contains a valid pointer. */
+	uint64_t isrd_ptr0_rtn_full           : 1;  /**< ISRD pointer return register 0 contains a valid pointer. */
+	uint64_t isrm_ptr1_rtn_full           : 1;  /**< ISRM pointer return register 1 contains a valid pointer. */
+	uint64_t isrm_ptr0_rtn_full           : 1;  /**< ISRM pointer return register 0 contains a valid pointer. */
+	uint64_t isrd_ptr1_val                : 1;  /**< ISRD pointer register 1 contains a valid pointer. */
+	uint64_t isrd_ptr0_val                : 1;  /**< ISRD pointer register 0 contains a valid pointer. */
+	uint64_t isrm_ptr1_val                : 1;  /**< ISRM pointer register 1 contains a valid pointer. */
+	uint64_t isrm_ptr0_val                : 1;  /**< ISRM pointer register 0 contains a valid pointer. */
+	uint64_t ptr_req_pend                 : 1;  /**< DPFI has pointer requests to FPA pending. */
+	uint64_t ptr_rtn_pend                 : 1;  /**< DPFI has pointer returns to FPA pending. */
+	uint64_t fpa_empty                    : 1;  /**< 1 = FPA responded to pointer request with 'no pointers available.'
                                                          0 = FPA is providing pointers when requested. */
-	uint64_t dpfi_empty                   : 1;  /**< 1 = DPFI pointer cache is empty.
-                                                         0 = DPFI pointer cache is not empty. */
-	uint64_t cache_flushed                : 1;  /**< 1 = Cache flush has completed.
+	uint64_t dpfi_empty                   : 1;  /**< DPFI pointer cache is empty. */
+	uint64_t cache_flushed                : 1;  /**< 1 = Cache flush has completed. PKO_DPFI_STATUS[PTR_CNT] will read zero if all
+                                                             outstanding pointers have been returned to the FPA.
                                                          0 = Cache flush not enabled or in-progress. */
 #else
 	uint64_t cache_flushed                : 1;
@@ -2508,7 +3006,8 @@ union cvmx_pko_dpfi_status {
 	uint64_t isrm_ptr1_rtn_full           : 1;
 	uint64_t isrd_ptr0_rtn_full           : 1;
 	uint64_t isrd_ptr1_rtn_full           : 1;
-	uint64_t reserved_13_63               : 51;
+	uint64_t reserved_13_31               : 19;
+	uint64_t ptr_cnt                      : 32;
 #endif
 	} s;
 	struct cvmx_pko_dpfi_status_s         cn78xx;
@@ -2516,6 +3015,24 @@ union cvmx_pko_dpfi_status {
 typedef union cvmx_pko_dpfi_status cvmx_pko_dpfi_status_t;
 
 /**
+ * cvmx_pko_dq#_bytes
+ */
+union cvmx_pko_dqx_bytes {
+	uint64_t u64;
+	struct cvmx_pko_dqx_bytes_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+#else
+	uint64_t count                        : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_pko_dqx_bytes_s           cn78xx;
+};
+typedef union cvmx_pko_dqx_bytes cvmx_pko_dqx_bytes_t;
+
+/**
  * cvmx_pko_dq#_cir
  */
 union cvmx_pko_dqx_cir {
@@ -2585,29 +3102,69 @@ union cvmx_pko_dqx_dropped_packets {
 typedef union cvmx_pko_dqx_dropped_packets cvmx_pko_dqx_dropped_packets_t;
 
 /**
+ * cvmx_pko_dq#_fifo
+ */
+union cvmx_pko_dqx_fifo {
+	uint64_t u64;
+	struct cvmx_pko_dqx_fifo_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_15_63               : 49;
+	uint64_t p_con                        : 1;  /**< Reserved. */
+	uint64_t head                         : 7;  /**< See PKO_L2_SQ(0..511)_POINTERS[PREV]. */
+	uint64_t tail                         : 7;  /**< See PKO_L2_SQ(0..511)_POINTERS[NEXT]. */
+#else
+	uint64_t tail                         : 7;
+	uint64_t head                         : 7;
+	uint64_t p_con                        : 1;
+	uint64_t reserved_15_63               : 49;
+#endif
+	} s;
+	struct cvmx_pko_dqx_fifo_s            cn78xx;
+};
+typedef union cvmx_pko_dqx_fifo cvmx_pko_dqx_fifo_t;
+
+/**
+ * cvmx_pko_dq#_packets
+ */
+union cvmx_pko_dqx_packets {
+	uint64_t u64;
+	struct cvmx_pko_dqx_packets_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_40_63               : 24;
+	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+#else
+	uint64_t count                        : 40;
+	uint64_t reserved_40_63               : 24;
+#endif
+	} s;
+	struct cvmx_pko_dqx_packets_s         cn78xx;
+};
+typedef union cvmx_pko_dqx_packets cvmx_pko_dqx_packets_t;
+
+/**
  * cvmx_pko_dq#_pick
  */
 union cvmx_pko_dqx_pick {
 	uint64_t u64;
 	struct cvmx_pko_dqx_pick_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq                           : 10; /**< Descriptor Queue. Index of originating descriptor queue. */
+	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
 	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
                                                          result is connected in a flow that extends through the child result, this is the
                                                          index of that child result. */
-	uint64_t bubble                       : 1;  /**< This meta-packet is a fake passed forward after a prune. */
-	uint64_t p_con                        : 1;  /**< Parent Connected Flag. This pick has more picks in front of it. */
-	uint64_t c_con                        : 1;  /**< Child Connected Flag. This pick has more picks behind it. */
+	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
+	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
+	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
 	uint64_t uid                          : 7;  /**< Unique ID. 7-bit unique value assigned at the DQ level, increments for each packet. */
 	uint64_t jump                         : 1;  /**< Jump. Set when metapacket originated from a jump descriptor. */
-	uint64_t fpd                          : 1;  /**< First Packet Descriptor. Set when metapacket was the first in a cacheline. */
-	uint64_t ds                           : 1;  /**< Don't Send. Set when metapacket is not to be sent. */
+	uint64_t fpd                          : 1;  /**< First packet descriptor. Set when metapacket was the first in a cacheline. */
+	uint64_t ds                           : 1;  /**< Don't send. Set when metapacket is not to be sent. */
 	uint64_t adjust                       : 9;  /**< See PKO_L2_SQ(0..511)_SHAPE[ADJUST]. */
-	uint64_t pir_dis                      : 1;  /**< PIR Disable. Peak shaper disabled. */
-	uint64_t cir_dis                      : 1;  /**< CIR Disable. Committed shaper disabled. */
+	uint64_t pir_dis                      : 1;  /**< PIR disable. Peak shaper disabled. */
+	uint64_t cir_dis                      : 1;  /**< CIR disable. Committed shaper disabled. */
 	uint64_t red_algo_override            : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[RED_ALGO]. */
-	uint64_t length                       : 16; /**< Packet Length. The packet length in bytes. */
+	uint64_t length                       : 16; /**< Packet length. The packet length in bytes. */
 #else
 	uint64_t length                       : 16;
 	uint64_t red_algo_override            : 2;
@@ -2711,13 +3268,12 @@ union cvmx_pko_dqx_schedule {
 	struct cvmx_pko_dqx_schedule_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's
-                                                         scheduling algorithm. When this SQ is not used, we recommend
-                                                         PRIO be zero. The legal PRIO values are 0-9 when the SQ is used.
-                                                         In addition to priority, PRIO determines whether the SQ is a static
-                                                         queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
-                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this
-                                                         is a round-robin child queue into the shaper at the next level. */
+	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's scheduling
+                                                         algorithm. When this SQ is not used, we recommend setting PRIO to zero. The legal PRIO
+                                                         values are 0-9 when the SQ is used. In addition to priority, PRIO determines whether the
+                                                         SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
+                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
+                                                         the shaper at the next level. */
 	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
 #else
 	uint64_t rr_quantum                   : 24;
@@ -2730,42 +3286,6 @@ union cvmx_pko_dqx_schedule {
 typedef union cvmx_pko_dqx_schedule cvmx_pko_dqx_schedule_t;
 
 /**
- * cvmx_pko_dq#_sent_bytes
- */
-union cvmx_pko_dqx_sent_bytes {
-	uint64_t u64;
-	struct cvmx_pko_dqx_sent_bytes_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
-#else
-	uint64_t count                        : 48;
-	uint64_t reserved_48_63               : 16;
-#endif
-	} s;
-	struct cvmx_pko_dqx_sent_bytes_s      cn78xx;
-};
-typedef union cvmx_pko_dqx_sent_bytes cvmx_pko_dqx_sent_bytes_t;
-
-/**
- * cvmx_pko_dq#_sent_packets
- */
-union cvmx_pko_dqx_sent_packets {
-	uint64_t u64;
-	struct cvmx_pko_dqx_sent_packets_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_40_63               : 24;
-	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
-#else
-	uint64_t count                        : 40;
-	uint64_t reserved_40_63               : 24;
-#endif
-	} s;
-	struct cvmx_pko_dqx_sent_packets_s    cn78xx;
-};
-typedef union cvmx_pko_dqx_sent_packets cvmx_pko_dqx_sent_packets_t;
-
-/**
  * cvmx_pko_dq#_shape
  */
 union cvmx_pko_dqx_shape {
@@ -2773,8 +3293,8 @@ union cvmx_pko_dqx_shape {
 	struct cvmx_pko_dqx_shape_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
-	uint64_t length_disable               : 1;  /**< Length Disable. Disables the use of packet lengths in shaping calculations such that
-                                                         only the value of the ADJUST field described below is used. */
+	uint64_t length_disable               : 1;  /**< Length disable. Disables the use of packet lengths in shaping calculations such that only
+                                                         the value of PKO_L5_SQ(0..1023)_SHAPE[ADJUST]. */
 	uint64_t reserved_13_23               : 11;
 	uint64_t yellow_disable               : 1;  /**< Disable yellow transitions. Disables green-to-yellow packet color marking transitions when set. */
 	uint64_t red_disable                  : 1;  /**< Disable red transitions. Disables green-to-red and yellow-to-red packet color marking
@@ -2830,7 +3350,14 @@ union cvmx_pko_dqx_sw_xoff {
 	uint64_t u64;
 	struct cvmx_pko_dqx_sw_xoff_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
+	uint64_t reserved_4_63                : 60;
+	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
+	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
+                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         until the path has drained." */
+	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
+                                                         ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
+                                                         be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
 	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
@@ -2838,7 +3365,10 @@ union cvmx_pko_dqx_sw_xoff {
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
-	uint64_t reserved_1_63                : 63;
+	uint64_t drain                        : 1;
+	uint64_t drain_null_link              : 1;
+	uint64_t drain_irq                    : 1;
+	uint64_t reserved_4_63                : 60;
 #endif
 	} s;
 	struct cvmx_pko_dqx_sw_xoff_s         cn78xx;
@@ -2892,9 +3422,7 @@ union cvmx_pko_dqx_wm_ctl {
 	struct cvmx_pko_dqx_wm_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
-	uint64_t enable                       : 1;  /**< Watermark enable.
-                                                         0 = Disabled
-                                                         1 = Enable */
+	uint64_t enable                       : 1;  /**< Watermark enable. */
 	uint64_t kind                         : 1;  /**< Watermark kind. The watermark logic can use a byte count or packet count.
                                                          0 = Byte count
                                                          1 = Packet count */
@@ -2939,6 +3467,43 @@ union cvmx_pko_dqx_wm_ctl_w1c {
 typedef union cvmx_pko_dqx_wm_ctl_w1c cvmx_pko_dqx_wm_ctl_w1c_t;
 
 /**
+ * cvmx_pko_dq_debug
+ */
+union cvmx_pko_dq_debug {
+	uint64_t u64;
+	struct cvmx_pko_dq_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_dq_debug_s            cn78xx;
+};
+typedef union cvmx_pko_dq_debug cvmx_pko_dq_debug_t;
+
+/**
+ * cvmx_pko_drain_irq
+ */
+union cvmx_pko_drain_irq {
+	uint64_t u64;
+	struct cvmx_pko_drain_irq_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t intr                         : 1;  /**< Interrupt. The interrupt bit is asserted and an interrupt message to the CIU is generated
+                                                         when the DRAIN command reaches the PQ level. Subsequent interrupt messages are only
+                                                         generated
+                                                         after this bit has been cleared by writing 1. Throws PKO_INTSN_E::PKO_PSE_PQ_DRAIN. */
+#else
+	uint64_t intr                         : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_pko_drain_irq_s           cn78xx;
+};
+typedef union cvmx_pko_drain_irq cvmx_pko_drain_irq_t;
+
+/**
  * cvmx_pko_enable
  */
 union cvmx_pko_enable {
@@ -2966,10 +3531,10 @@ union cvmx_pko_formatx_ctl {
 	uint64_t reserved_28_63               : 36;
 	uint64_t ip4_ck                       : 1;  /**< IPv4 header checksum recalculate */
 	uint64_t offset                       : 11; /**< Bits to add to PKO_SEND_EXT[MARKPTR]*8 to determine where to start marking. */
-	uint64_t y_mask                       : 4;  /**< Yellow mark mask. Corresponding bits in packet's data will be cleared when marking packet yellow */
-	uint64_t y_val                        : 4;  /**< Yellow mark value. Corresponding bits in packet's data will be set when marking packet yellow */
-	uint64_t r_mask                       : 4;  /**< Red mark mask. Corresponding bits in packet's data will be cleared when marking packet red */
-	uint64_t r_val                        : 4;  /**< Red mark value. Corresponding bits in packet's data will be set when marking packet red */
+	uint64_t y_mask                       : 4;  /**< Yellow mark mask. Corresponding bits in packet's data are cleared when marking packet yellow. */
+	uint64_t y_val                        : 4;  /**< Yellow mark value. Corresponding bits in packet's data are set when marking packet yellow. */
+	uint64_t r_mask                       : 4;  /**< Red mark mask. Corresponding bits in packet's data are cleared when marking packet red. */
+	uint64_t r_val                        : 4;  /**< Red mark value. Corresponding bits in packet's data are set when marking packet red. */
 #else
 	uint64_t r_val                        : 4;
 	uint64_t r_mask                       : 4;
@@ -3018,6 +3583,42 @@ union cvmx_pko_l1_sqx_cir {
 typedef union cvmx_pko_l1_sqx_cir cvmx_pko_l1_sqx_cir_t;
 
 /**
+ * cvmx_pko_l1_sq#_dropped_bytes
+ */
+union cvmx_pko_l1_sqx_dropped_bytes {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_dropped_bytes_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+#else
+	uint64_t count                        : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_dropped_bytes_s cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_dropped_bytes cvmx_pko_l1_sqx_dropped_bytes_t;
+
+/**
+ * cvmx_pko_l1_sq#_dropped_packets
+ */
+union cvmx_pko_l1_sqx_dropped_packets {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_dropped_packets_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_40_63               : 24;
+	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+#else
+	uint64_t count                        : 40;
+	uint64_t reserved_40_63               : 24;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_dropped_packets_s cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_dropped_packets cvmx_pko_l1_sqx_dropped_packets_t;
+
+/**
  * cvmx_pko_l1_sq#_green
  */
 union cvmx_pko_l1_sqx_green {
@@ -3025,18 +3626,20 @@ union cvmx_pko_l1_sqx_green {
 	struct cvmx_pko_l1_sqx_green_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_41_63               : 23;
-	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. */
-	uint64_t reserved_25_31               : 7;
-	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to *this*
-                                                         scheduling queue are active. */
+	uint64_t rr_active                    : 1;  /**< Round-robin red active. Indicates that the round-robin input is mapped to RED. */
+	uint64_t active_vec                   : 20; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to this
+                                                         scheduling queue are active. For internal use only. */
+	uint64_t reserved_19_19               : 1;
+	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t reserved_9_9                 : 1;
+	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 9;
-	uint64_t reserved_25_31               : 7;
+	uint64_t reserved_9_9                 : 1;
 	uint64_t head                         : 9;
+	uint64_t reserved_19_19               : 1;
+	uint64_t active_vec                   : 20;
+	uint64_t rr_active                    : 1;
 	uint64_t reserved_41_63               : 23;
 #endif
 	} s;
@@ -3045,6 +3648,42 @@ union cvmx_pko_l1_sqx_green {
 typedef union cvmx_pko_l1_sqx_green cvmx_pko_l1_sqx_green_t;
 
 /**
+ * cvmx_pko_l1_sq#_green_bytes
+ */
+union cvmx_pko_l1_sqx_green_bytes {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_green_bytes_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+#else
+	uint64_t count                        : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_green_bytes_s  cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_green_bytes cvmx_pko_l1_sqx_green_bytes_t;
+
+/**
+ * cvmx_pko_l1_sq#_green_packets
+ */
+union cvmx_pko_l1_sqx_green_packets {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_green_packets_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_40_63               : 24;
+	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+#else
+	uint64_t count                        : 40;
+	uint64_t reserved_40_63               : 24;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_green_packets_s cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_green_packets cvmx_pko_l1_sqx_green_packets_t;
+
+/**
  * cvmx_pko_l1_sq#_link
  */
 union cvmx_pko_l1_sqx_link {
@@ -3090,23 +3729,23 @@ union cvmx_pko_l1_sqx_pick {
 	uint64_t u64;
 	struct cvmx_pko_l1_sqx_pick_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq                           : 10; /**< Descriptor Queue. Index of originating descriptor queue. */
+	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
 	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
                                                          result is connected in a flow that extends through the child result, this is the
                                                          index of that child result. */
-	uint64_t bubble                       : 1;  /**< This meta-packet is a fake passed forward after a prune. */
-	uint64_t p_con                        : 1;  /**< Parent Connected Flag. This pick has more picks in front of it. */
-	uint64_t c_con                        : 1;  /**< Child Connected Flag. This pick has more picks behind it. */
+	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
+	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
+	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
 	uint64_t uid                          : 7;  /**< Unique ID. 7-bit unique value assigned at the DQ level, increments for each packet. */
 	uint64_t jump                         : 1;  /**< Jump. Set when metapacket originated from a jump descriptor. */
-	uint64_t fpd                          : 1;  /**< First Packet Descriptor. Set when metapacket was the first in a cacheline. */
-	uint64_t ds                           : 1;  /**< Don't Send. Set when metapacket is not to be sent. */
+	uint64_t fpd                          : 1;  /**< First packet descriptor. Set when metapacket was the first in a cacheline. */
+	uint64_t ds                           : 1;  /**< Don't send. Set when metapacket is not to be sent. */
 	uint64_t adjust                       : 9;  /**< See PKO_L2_SQ(0..511)_SHAPE[ADJUST]. */
-	uint64_t pir_dis                      : 1;  /**< PIR Disable. Peak shaper disabled. */
-	uint64_t cir_dis                      : 1;  /**< CIR Disable. Committed shaper disabled. */
+	uint64_t pir_dis                      : 1;  /**< PIR disable. Peak shaper disabled. */
+	uint64_t cir_dis                      : 1;  /**< CIR disable. Committed shaper disabled. */
 	uint64_t red_algo_override            : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[RED_ALGO]. */
-	uint64_t length                       : 16; /**< Packet Length. The packet length in bytes. */
+	uint64_t length                       : 16; /**< Packet length. The packet length in bytes. */
 #else
 	uint64_t length                       : 16;
 	uint64_t red_algo_override            : 2;
@@ -3169,20 +3808,15 @@ union cvmx_pko_l1_sqx_red {
 	uint64_t u64;
 	struct cvmx_pko_l1_sqx_red_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_41_63               : 23;
-	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. */
-	uint64_t reserved_25_31               : 7;
-	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to *this*
-                                                         scheduling queue are active. */
+	uint64_t reserved_19_63               : 45;
+	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t reserved_9_9                 : 1;
+	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 9;
-	uint64_t reserved_25_31               : 7;
+	uint64_t reserved_9_9                 : 1;
 	uint64_t head                         : 9;
-	uint64_t reserved_41_63               : 23;
+	uint64_t reserved_19_63               : 45;
 #endif
 	} s;
 	struct cvmx_pko_l1_sqx_red_s          cn78xx;
@@ -3190,6 +3824,42 @@ union cvmx_pko_l1_sqx_red {
 typedef union cvmx_pko_l1_sqx_red cvmx_pko_l1_sqx_red_t;
 
 /**
+ * cvmx_pko_l1_sq#_red_bytes
+ */
+union cvmx_pko_l1_sqx_red_bytes {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_red_bytes_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+#else
+	uint64_t count                        : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_red_bytes_s    cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_red_bytes cvmx_pko_l1_sqx_red_bytes_t;
+
+/**
+ * cvmx_pko_l1_sq#_red_packets
+ */
+union cvmx_pko_l1_sqx_red_packets {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_red_packets_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_40_63               : 24;
+	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+#else
+	uint64_t count                        : 40;
+	uint64_t reserved_40_63               : 24;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_red_packets_s  cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_red_packets cvmx_pko_l1_sqx_red_packets_t;
+
+/**
  * cvmx_pko_l1_sq#_shape
  */
 union cvmx_pko_l1_sqx_shape {
@@ -3244,7 +3914,14 @@ union cvmx_pko_l1_sqx_sw_xoff {
 	uint64_t u64;
 	struct cvmx_pko_l1_sqx_sw_xoff_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
+	uint64_t reserved_4_63                : 60;
+	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
+	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
+                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         until the path has drained." */
+	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
+                                                         ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
+                                                         be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
 	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
@@ -3252,7 +3929,10 @@ union cvmx_pko_l1_sqx_sw_xoff {
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
-	uint64_t reserved_1_63                : 63;
+	uint64_t drain                        : 1;
+	uint64_t drain_null_link              : 1;
+	uint64_t drain_irq                    : 1;
+	uint64_t reserved_4_63                : 60;
 #endif
 	} s;
 	struct cvmx_pko_l1_sqx_sw_xoff_s      cn78xx;
@@ -3316,20 +3996,15 @@ union cvmx_pko_l1_sqx_yellow {
 	uint64_t u64;
 	struct cvmx_pko_l1_sqx_yellow_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_41_63               : 23;
-	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. */
-	uint64_t reserved_25_31               : 7;
-	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to *this*
-                                                         scheduling queue are active. */
+	uint64_t reserved_19_63               : 45;
+	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t reserved_9_9                 : 1;
+	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 9;
-	uint64_t reserved_25_31               : 7;
+	uint64_t reserved_9_9                 : 1;
 	uint64_t head                         : 9;
-	uint64_t reserved_41_63               : 23;
+	uint64_t reserved_19_63               : 45;
 #endif
 	} s;
 	struct cvmx_pko_l1_sqx_yellow_s       cn78xx;
@@ -3337,6 +4012,74 @@ union cvmx_pko_l1_sqx_yellow {
 typedef union cvmx_pko_l1_sqx_yellow cvmx_pko_l1_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l1_sq#_yellow_bytes
+ */
+union cvmx_pko_l1_sqx_yellow_bytes {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_yellow_bytes_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+#else
+	uint64_t count                        : 48;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_yellow_bytes_s cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_yellow_bytes cvmx_pko_l1_sqx_yellow_bytes_t;
+
+/**
+ * cvmx_pko_l1_sq#_yellow_packets
+ */
+union cvmx_pko_l1_sqx_yellow_packets {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_yellow_packets_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_40_63               : 24;
+	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+#else
+	uint64_t count                        : 40;
+	uint64_t reserved_40_63               : 24;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_yellow_packets_s cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_yellow_packets cvmx_pko_l1_sqx_yellow_packets_t;
+
+/**
+ * cvmx_pko_l1_sqa_debug
+ */
+union cvmx_pko_l1_sqa_debug {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqa_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqa_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l1_sqa_debug cvmx_pko_l1_sqa_debug_t;
+
+/**
+ * cvmx_pko_l1_sqb_debug
+ */
+union cvmx_pko_l1_sqb_debug {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqb_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqb_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l1_sqb_debug cvmx_pko_l1_sqb_debug_t;
+
+/**
  * cvmx_pko_l2_sq#_cir
  */
 union cvmx_pko_l2_sqx_cir {
@@ -3377,18 +4120,20 @@ union cvmx_pko_l2_sqx_green {
 	struct cvmx_pko_l2_sqx_green_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_41_63               : 23;
-	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. */
-	uint64_t reserved_25_31               : 7;
-	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to *this*
-                                                         scheduling queue are active. */
+	uint64_t rr_active                    : 1;  /**< Round-robin red active. Indicates that the round-robin input is mapped to RED. */
+	uint64_t active_vec                   : 20; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to this
+                                                         scheduling queue are active. For internal use only. */
+	uint64_t reserved_19_19               : 1;
+	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t reserved_9_9                 : 1;
+	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 9;
-	uint64_t reserved_25_31               : 7;
+	uint64_t reserved_9_9                 : 1;
 	uint64_t head                         : 9;
+	uint64_t reserved_19_19               : 1;
+	uint64_t active_vec                   : 20;
+	uint64_t rr_active                    : 1;
 	uint64_t reserved_41_63               : 23;
 #endif
 	} s;
@@ -3403,23 +4148,23 @@ union cvmx_pko_l2_sqx_pick {
 	uint64_t u64;
 	struct cvmx_pko_l2_sqx_pick_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq                           : 10; /**< Descriptor Queue. Index of originating descriptor queue. */
+	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
 	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
                                                          result is connected in a flow that extends through the child result, this is the
                                                          index of that child result. */
-	uint64_t bubble                       : 1;  /**< This meta-packet is a fake passed forward after a prune. */
-	uint64_t p_con                        : 1;  /**< Parent Connected Flag. This pick has more picks in front of it. */
-	uint64_t c_con                        : 1;  /**< Child Connected Flag. This pick has more picks behind it. */
+	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
+	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
+	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
 	uint64_t uid                          : 7;  /**< Unique ID. 7-bit unique value assigned at the DQ level, increments for each packet. */
 	uint64_t jump                         : 1;  /**< Jump. Set when metapacket originated from a jump descriptor. */
-	uint64_t fpd                          : 1;  /**< First Packet Descriptor. Set when metapacket was the first in a cacheline. */
-	uint64_t ds                           : 1;  /**< Don't Send. Set when metapacket is not to be sent. */
+	uint64_t fpd                          : 1;  /**< First packet descriptor. Set when metapacket was the first in a cacheline. */
+	uint64_t ds                           : 1;  /**< Don't send. Set when metapacket is not to be sent. */
 	uint64_t adjust                       : 9;  /**< See PKO_L2_SQ(0..511)_SHAPE[ADJUST]. */
-	uint64_t pir_dis                      : 1;  /**< PIR Disable. Peak shaper disabled. */
-	uint64_t cir_dis                      : 1;  /**< CIR Disable. Committed shaper disabled. */
+	uint64_t pir_dis                      : 1;  /**< PIR disable. Peak shaper disabled. */
+	uint64_t cir_dis                      : 1;  /**< CIR disable. Committed shaper disabled. */
 	uint64_t red_algo_override            : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[RED_ALGO]. */
-	uint64_t length                       : 16; /**< Packet Length. The packet length in bytes. */
+	uint64_t length                       : 16; /**< Packet length. The packet length in bytes. */
 #else
 	uint64_t length                       : 16;
 	uint64_t red_algo_override            : 2;
@@ -3504,20 +4249,15 @@ union cvmx_pko_l2_sqx_red {
 	uint64_t u64;
 	struct cvmx_pko_l2_sqx_red_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_41_63               : 23;
-	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. */
-	uint64_t reserved_25_31               : 7;
-	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to *this*
-                                                         scheduling queue are active. */
+	uint64_t reserved_19_63               : 45;
+	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t reserved_9_9                 : 1;
+	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 9;
-	uint64_t reserved_25_31               : 7;
+	uint64_t reserved_9_9                 : 1;
 	uint64_t head                         : 9;
-	uint64_t reserved_41_63               : 23;
+	uint64_t reserved_19_63               : 45;
 #endif
 	} s;
 	struct cvmx_pko_l2_sqx_red_s          cn78xx;
@@ -3550,13 +4290,12 @@ union cvmx_pko_l2_sqx_schedule {
 	struct cvmx_pko_l2_sqx_schedule_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's
-                                                         scheduling algorithm. When this SQ is not used, we recommend
-                                                         PRIO be zero. The legal PRIO values are 0-9 when the SQ is used.
-                                                         In addition to priority, PRIO determines whether the SQ is a static
-                                                         queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
-                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this
-                                                         is a round-robin child queue into the shaper at the next level. */
+	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's scheduling
+                                                         algorithm. When this SQ is not used, we recommend setting PRIO to zero. The legal PRIO
+                                                         values are 0-9 when the SQ is used. In addition to priority, PRIO determines whether the
+                                                         SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
+                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
+                                                         the shaper at the next level. */
 	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
 #else
 	uint64_t rr_quantum                   : 24;
@@ -3577,17 +4316,17 @@ union cvmx_pko_l2_sqx_shape {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
 	uint64_t length_disable               : 1;  /**< Length disable. Disables the use of packet lengths in shaping calculations such that only
-                                                         the value of the ADJUST field described below is used. */
+                                                         the value of PKO_L2_SQ(0..511)_SHAPE[ADJUST]. */
 	uint64_t reserved_13_23               : 11;
 	uint64_t yellow_disable               : 1;  /**< Disable yellow transitions. Disables green-to-yellow packet color marking transitions when set. */
 	uint64_t red_disable                  : 1;  /**< Disable red transitions. Disables green-to-red and yellow-to-red packet color marking
                                                          transitions when set. */
 	uint64_t red_algo                     : 2;  /**< Shaper red state algorithm.
                                                          0 = Stall packets while in RED state until YELLOW or GREEN state is reached (aka never
-                                                         send RED packets)
-                                                         1 = Send packets while in RED state
-                                                         2 = Same as 0 above (stall)
-                                                         3 = Discard packets while in RED state (red packets are converted to drop packets) */
+                                                         send RED packets).
+                                                         1 = Send packets while in RED state.
+                                                         2 = Same as 0 above (stall).
+                                                         3 = Discard packets while in RED state (red packets are converted to drop packets). */
 	uint64_t adjust                       : 9;  /**< Shaping calculation adjustment. This 9-bit signed values allows +/- 256 bytes to be added
                                                          to the packet length for the shaping calculations. */
 #else
@@ -3639,7 +4378,14 @@ union cvmx_pko_l2_sqx_sw_xoff {
 	uint64_t u64;
 	struct cvmx_pko_l2_sqx_sw_xoff_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
+	uint64_t reserved_4_63                : 60;
+	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
+	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
+                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         until the path has drained." */
+	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
+                                                         ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
+                                                         be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
 	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
@@ -3647,7 +4393,10 @@ union cvmx_pko_l2_sqx_sw_xoff {
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
-	uint64_t reserved_1_63                : 63;
+	uint64_t drain                        : 1;
+	uint64_t drain_null_link              : 1;
+	uint64_t drain_irq                    : 1;
+	uint64_t reserved_4_63                : 60;
 #endif
 	} s;
 	struct cvmx_pko_l2_sqx_sw_xoff_s      cn78xx;
@@ -3664,12 +4413,11 @@ union cvmx_pko_l2_sqx_topology {
 	uint64_t reserved_41_63               : 23;
 	uint64_t prio_anchor                  : 9;  /**< See PKO_L1_SQ(0..31)_TOPOLOGY[PRIO_ANCHOR]. */
 	uint64_t reserved_21_31               : 11;
-	uint64_t parent                       : 5;  /**< Parent queue index. The index of the shaping element at the next lower
-                                                         hierachical level that accepts *this* shaping element's outputs.
-                                                         Refer to the PKO_*_SQn_TOPOLOGY[PRIO_ANCHOR,RR_PRIO] descriptions
-                                                         for constraints on which child queues can attach to which shapers
-                                                         at the next lower level. When this shaper is unused, we recommend
-                                                         PARENT be zero. */
+	uint64_t parent                       : 5;  /**< Parent queue index. The index of the shaping element at the next lower hierarchical level
+                                                         that accepts this shaping element's outputs. Refer to the
+                                                         PKO_*_SQn_TOPOLOGY[PRIO_ANCHOR,RR_PRIO] descriptions for constraints on which child queues
+                                                         can attach to which shapers at the next lower level. When this shaper is unused, we
+                                                         recommend that PARENT be zero. */
 	uint64_t reserved_5_15                : 11;
 	uint64_t rr_prio                      : 4;  /**< See PKO_L1_SQ(0..31)_TOPOLOGY[RR_PRIO]. */
 	uint64_t reserved_0_0                 : 1;
@@ -3694,20 +4442,15 @@ union cvmx_pko_l2_sqx_yellow {
 	uint64_t u64;
 	struct cvmx_pko_l2_sqx_yellow_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_41_63               : 23;
-	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. */
-	uint64_t reserved_25_31               : 7;
-	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to *this*
-                                                         scheduling queue are active. */
+	uint64_t reserved_19_63               : 45;
+	uint64_t head                         : 9;  /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t reserved_9_9                 : 1;
+	uint64_t tail                         : 9;  /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 9;
-	uint64_t reserved_25_31               : 7;
+	uint64_t reserved_9_9                 : 1;
 	uint64_t head                         : 9;
-	uint64_t reserved_41_63               : 23;
+	uint64_t reserved_19_63               : 45;
 #endif
 	} s;
 	struct cvmx_pko_l2_sqx_yellow_s       cn78xx;
@@ -3715,6 +4458,38 @@ union cvmx_pko_l2_sqx_yellow {
 typedef union cvmx_pko_l2_sqx_yellow cvmx_pko_l2_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l2_sqa_debug
+ */
+union cvmx_pko_l2_sqa_debug {
+	uint64_t u64;
+	struct cvmx_pko_l2_sqa_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l2_sqa_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l2_sqa_debug cvmx_pko_l2_sqa_debug_t;
+
+/**
+ * cvmx_pko_l2_sqb_debug
+ */
+union cvmx_pko_l2_sqb_debug {
+	uint64_t u64;
+	struct cvmx_pko_l2_sqb_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l2_sqb_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l2_sqb_debug cvmx_pko_l2_sqb_debug_t;
+
+/**
  * cvmx_pko_l3_l2_sq#_channel
  */
 union cvmx_pko_l3_l2_sqx_channel {
@@ -3723,13 +4498,12 @@ union cvmx_pko_l3_l2_sqx_channel {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_44_63               : 20;
 	uint64_t cc_channel                   : 12; /**< Channel ID. */
-	uint64_t cc_word_cnt                  : 20; /**< Channel credit word count.
-                                                         This value, plus 1 MTU, represents the maximum outstanding word count (words are 16 bytes)
-                                                         for this channel.
-                                                         Note that this 20-bit field represents a signed value that decrements towards zero as
-                                                         credits are used. Packets are not allowed to flow when the count is less than zero. As
-                                                         such, the most significant bit should normally be programmed as zero (positive count).
-                                                         This gives a maximum value for this field of 2^18 - 1. */
+	uint64_t cc_word_cnt                  : 20; /**< Channel credit word count. This value, plus 1 MTU, represents the maximum outstanding word
+                                                         count for this channel. (Words are 16 bytes.) Note that this 20-bit field represents a
+                                                         signed value that decrements towards zero as credits are used. Packets are not allowed to
+                                                         flow when the count is less than zero. As such, the most significant bit should normally
+                                                         be programmed as zero (positive count). This gives a maximum value for this field of 2^18
+                                                         - 1. */
 	uint64_t cc_packet_cnt                : 10; /**< Channel credit packet count. This value, plus 1, represents the maximum outstanding packet
                                                          count for this channel.
                                                          Note that this 10-bit field represents a signed value that decrements towards zero as
@@ -3737,8 +4511,8 @@ union cvmx_pko_l3_l2_sqx_channel {
                                                          such the most significant bit should normally be programmed as zero (positive count). This
                                                          gives a maximum value for this field of 2^9 - 1. */
 	uint64_t cc_enable                    : 1;  /**< Channel credit enable. Enables CC_WORD_CNT and CC_PACKET_CNT credit processing. */
-	uint64_t hw_xoff                      : 1;  /**< Hardware XOFF status. The status of hardware XON/XOFF. This is write-able to get around
-                                                         LUT issues and for reconfiguration. */
+	uint64_t hw_xoff                      : 1;  /**< Hardware XOFF status. The status of hardware XON/XOFF. This is writable to get around LUT
+                                                         issues and for reconfiguration. */
 #else
 	uint64_t hw_xoff                      : 1;
 	uint64_t cc_enable                    : 1;
@@ -3792,19 +4566,18 @@ union cvmx_pko_l3_sqx_green {
 	uint64_t u64;
 	struct cvmx_pko_l3_sqx_green_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_41_63               : 23;
+	uint64_t rr_active                    : 1;  /**< Round-robin red active. Indicates that the round-robin input is mapped to RED. */
+	uint64_t active_vec                   : 20; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to this
+                                                         scheduling queue are active. For internal use only. */
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t active_vec                   : 20;
+	uint64_t rr_active                    : 1;
+	uint64_t reserved_41_63               : 23;
 #endif
 	} s;
 	struct cvmx_pko_l3_sqx_green_s        cn78xx;
@@ -3818,23 +4591,23 @@ union cvmx_pko_l3_sqx_pick {
 	uint64_t u64;
 	struct cvmx_pko_l3_sqx_pick_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq                           : 10; /**< Descriptor Queue. Index of originating descriptor queue. */
+	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
 	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
                                                          result is connected in a flow that extends through the child result, this is the
                                                          index of that child result. */
-	uint64_t bubble                       : 1;  /**< This meta-packet is a fake passed forward after a prune. */
-	uint64_t p_con                        : 1;  /**< Parent Connected Flag. This pick has more picks in front of it. */
-	uint64_t c_con                        : 1;  /**< Child Connected Flag. This pick has more picks behind it. */
+	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
+	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
+	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
 	uint64_t uid                          : 7;  /**< Unique ID. 7-bit unique value assigned at the DQ level, increments for each packet. */
 	uint64_t jump                         : 1;  /**< Jump. Set when metapacket originated from a jump descriptor. */
-	uint64_t fpd                          : 1;  /**< First Packet Descriptor. Set when metapacket was the first in a cacheline. */
-	uint64_t ds                           : 1;  /**< Don't Send. Set when metapacket is not to be sent. */
+	uint64_t fpd                          : 1;  /**< First packet descriptor. Set when metapacket was the first in a cacheline. */
+	uint64_t ds                           : 1;  /**< Don't send. Set when metapacket is not to be sent. */
 	uint64_t adjust                       : 9;  /**< See PKO_L2_SQ(0..511)_SHAPE[ADJUST]. */
-	uint64_t pir_dis                      : 1;  /**< PIR Disable. Peak shaper disabled. */
-	uint64_t cir_dis                      : 1;  /**< CIR Disable. Committed shaper disabled. */
+	uint64_t pir_dis                      : 1;  /**< PIR disable. Peak shaper disabled. */
+	uint64_t cir_dis                      : 1;  /**< CIR disable. Committed shaper disabled. */
 	uint64_t red_algo_override            : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[RED_ALGO]. */
-	uint64_t length                       : 16; /**< Packet Length. The packet length in bytes. */
+	uint64_t length                       : 16; /**< Packet length. The packet length in bytes. */
 #else
 	uint64_t length                       : 16;
 	uint64_t red_algo_override            : 2;
@@ -3919,19 +4692,13 @@ union cvmx_pko_l3_sqx_red {
 	uint64_t u64;
 	struct cvmx_pko_l3_sqx_red_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
 	struct cvmx_pko_l3_sqx_red_s          cn78xx;
@@ -3964,13 +4731,12 @@ union cvmx_pko_l3_sqx_schedule {
 	struct cvmx_pko_l3_sqx_schedule_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's
-                                                         scheduling algorithm. When this SQ is not used, we recommend
-                                                         PRIO be zero. The legal PRIO values are 0-9 when the SQ is used.
-                                                         In addition to priority, PRIO determines whether the SQ is a static
-                                                         queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
-                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this
-                                                         is a round-robin child queue into the shaper at the next level. */
+	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's scheduling
+                                                         algorithm. When this SQ is not used, we recommend setting PRIO to zero. The legal PRIO
+                                                         values are 0-9 when the SQ is used. In addition to priority, PRIO determines whether the
+                                                         SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
+                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
+                                                         the shaper at the next level. */
 	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
 #else
 	uint64_t rr_quantum                   : 24;
@@ -3991,7 +4757,7 @@ union cvmx_pko_l3_sqx_shape {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
 	uint64_t length_disable               : 1;  /**< Length disable. Disables the use of packet lengths in shaping calculations such that only
-                                                         the value of the ADJUST field described below is used. */
+                                                         the value of the ADJUST field is used. */
 	uint64_t reserved_13_23               : 11;
 	uint64_t yellow_disable               : 1;  /**< Disable yellow transitions. Disables green-to-yellow packet color marking transitions when set. */
 	uint64_t red_disable                  : 1;  /**< Disable red transitions. Disables green-to-red and yellow-to-red packet color marking
@@ -4047,7 +4813,14 @@ union cvmx_pko_l3_sqx_sw_xoff {
 	uint64_t u64;
 	struct cvmx_pko_l3_sqx_sw_xoff_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
+	uint64_t reserved_4_63                : 60;
+	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
+	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
+                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         until the path has drained." */
+	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
+                                                         ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
+                                                         be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
 	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
@@ -4055,7 +4828,10 @@ union cvmx_pko_l3_sqx_sw_xoff {
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
-	uint64_t reserved_1_63                : 63;
+	uint64_t drain                        : 1;
+	uint64_t drain_null_link              : 1;
+	uint64_t drain_irq                    : 1;
+	uint64_t reserved_4_63                : 60;
 #endif
 	} s;
 	struct cvmx_pko_l3_sqx_sw_xoff_s      cn78xx;
@@ -4097,19 +4873,13 @@ union cvmx_pko_l3_sqx_yellow {
 	uint64_t u64;
 	struct cvmx_pko_l3_sqx_yellow_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
 	struct cvmx_pko_l3_sqx_yellow_s       cn78xx;
@@ -4117,6 +4887,38 @@ union cvmx_pko_l3_sqx_yellow {
 typedef union cvmx_pko_l3_sqx_yellow cvmx_pko_l3_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l3_sqa_debug
+ */
+union cvmx_pko_l3_sqa_debug {
+	uint64_t u64;
+	struct cvmx_pko_l3_sqa_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l3_sqa_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l3_sqa_debug cvmx_pko_l3_sqa_debug_t;
+
+/**
+ * cvmx_pko_l3_sqb_debug
+ */
+union cvmx_pko_l3_sqb_debug {
+	uint64_t u64;
+	struct cvmx_pko_l3_sqb_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l3_sqb_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l3_sqb_debug cvmx_pko_l3_sqb_debug_t;
+
+/**
  * cvmx_pko_l4_sq#_cir
  */
 union cvmx_pko_l4_sqx_cir {
@@ -4156,19 +4958,18 @@ union cvmx_pko_l4_sqx_green {
 	uint64_t u64;
 	struct cvmx_pko_l4_sqx_green_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_41_63               : 23;
+	uint64_t rr_active                    : 1;  /**< Round-robin red active. Indicates that the round-robin input is mapped to RED. */
+	uint64_t active_vec                   : 20; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to this
+                                                         scheduling queue are active. For internal use only. */
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t active_vec                   : 20;
+	uint64_t rr_active                    : 1;
+	uint64_t reserved_41_63               : 23;
 #endif
 	} s;
 	struct cvmx_pko_l4_sqx_green_s        cn78xx;
@@ -4182,23 +4983,23 @@ union cvmx_pko_l4_sqx_pick {
 	uint64_t u64;
 	struct cvmx_pko_l4_sqx_pick_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq                           : 10; /**< Descriptor Queue. Index of originating descriptor queue. */
+	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
 	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
                                                          result is connected in a flow that extends through the child result, this is the
                                                          index of that child result. */
-	uint64_t bubble                       : 1;  /**< This meta-packet is a fake passed forward after a prune. */
-	uint64_t p_con                        : 1;  /**< Parent Connected Flag. This pick has more picks in front of it. */
-	uint64_t c_con                        : 1;  /**< Child Connected Flag. This pick has more picks behind it. */
+	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
+	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
+	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
 	uint64_t uid                          : 7;  /**< Unique ID. 7-bit unique value assigned at the DQ level, increments for each packet. */
 	uint64_t jump                         : 1;  /**< Jump. Set when metapacket originated from a jump descriptor. */
-	uint64_t fpd                          : 1;  /**< First Packet Descriptor. Set when metapacket was the first in a cacheline. */
-	uint64_t ds                           : 1;  /**< Don't Send. Set when metapacket is not to be sent. */
+	uint64_t fpd                          : 1;  /**< First packet descriptor. Set when metapacket was the first in a cacheline. */
+	uint64_t ds                           : 1;  /**< Don't send. Set when metapacket is not to be sent. */
 	uint64_t adjust                       : 9;  /**< See PKO_L2_SQ(0..511)_SHAPE[ADJUST]. */
-	uint64_t pir_dis                      : 1;  /**< PIR Disable. Peak shaper disabled. */
-	uint64_t cir_dis                      : 1;  /**< CIR Disable. Committed shaper disabled. */
+	uint64_t pir_dis                      : 1;  /**< PIR disable. Peak shaper disabled. */
+	uint64_t cir_dis                      : 1;  /**< CIR disable. Committed shaper disabled. */
 	uint64_t red_algo_override            : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[RED_ALGO]. */
-	uint64_t length                       : 16; /**< Packet Length. The packet length in bytes. */
+	uint64_t length                       : 16; /**< Packet length. The packet length in bytes. */
 #else
 	uint64_t length                       : 16;
 	uint64_t red_algo_override            : 2;
@@ -4283,19 +5084,13 @@ union cvmx_pko_l4_sqx_red {
 	uint64_t u64;
 	struct cvmx_pko_l4_sqx_red_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
 	struct cvmx_pko_l4_sqx_red_s          cn78xx;
@@ -4328,13 +5123,12 @@ union cvmx_pko_l4_sqx_schedule {
 	struct cvmx_pko_l4_sqx_schedule_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's
-                                                         scheduling algorithm. When this SQ is not used, we recommend
-                                                         PRIO be zero. The legal PRIO values are 0-9 when the SQ is used.
-                                                         In addition to priority, PRIO determines whether the SQ is a static
-                                                         queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
-                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this
-                                                         is a round-robin child queue into the shaper at the next level. */
+	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's scheduling
+                                                         algorithm. When this SQ is not used, we recommend setting PRIO to zero. The legal PRIO
+                                                         values are 0-9 when the SQ is used. In addition to priority, PRIO determines whether the
+                                                         SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
+                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
+                                                         the shaper at the next level. */
 	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
 #else
 	uint64_t rr_quantum                   : 24;
@@ -4355,7 +5149,7 @@ union cvmx_pko_l4_sqx_shape {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
 	uint64_t length_disable               : 1;  /**< Length disable. Disables the use of packet lengths in shaping calculations such that only
-                                                         the value of the ADJUST field described below is used. */
+                                                         the value of the ADJUST field is used. */
 	uint64_t reserved_13_23               : 11;
 	uint64_t yellow_disable               : 1;  /**< Disable yellow transitions. Disables green-to-yellow packet color marking transitions when set. */
 	uint64_t red_disable                  : 1;  /**< Disable red transitions. Disables green-to-red and yellow-to-red packet color marking
@@ -4411,7 +5205,14 @@ union cvmx_pko_l4_sqx_sw_xoff {
 	uint64_t u64;
 	struct cvmx_pko_l4_sqx_sw_xoff_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
+	uint64_t reserved_4_63                : 60;
+	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
+	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
+                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         until the path has drained." */
+	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
+                                                         ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
+                                                         be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
 	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
@@ -4419,7 +5220,10 @@ union cvmx_pko_l4_sqx_sw_xoff {
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
-	uint64_t reserved_1_63                : 63;
+	uint64_t drain                        : 1;
+	uint64_t drain_null_link              : 1;
+	uint64_t drain_irq                    : 1;
+	uint64_t reserved_4_63                : 60;
 #endif
 	} s;
 	struct cvmx_pko_l4_sqx_sw_xoff_s      cn78xx;
@@ -4461,19 +5265,13 @@ union cvmx_pko_l4_sqx_yellow {
 	uint64_t u64;
 	struct cvmx_pko_l4_sqx_yellow_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
 	struct cvmx_pko_l4_sqx_yellow_s       cn78xx;
@@ -4481,6 +5279,38 @@ union cvmx_pko_l4_sqx_yellow {
 typedef union cvmx_pko_l4_sqx_yellow cvmx_pko_l4_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l4_sqa_debug
+ */
+union cvmx_pko_l4_sqa_debug {
+	uint64_t u64;
+	struct cvmx_pko_l4_sqa_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l4_sqa_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l4_sqa_debug cvmx_pko_l4_sqa_debug_t;
+
+/**
+ * cvmx_pko_l4_sqb_debug
+ */
+union cvmx_pko_l4_sqb_debug {
+	uint64_t u64;
+	struct cvmx_pko_l4_sqb_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l4_sqb_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l4_sqb_debug cvmx_pko_l4_sqb_debug_t;
+
+/**
  * cvmx_pko_l5_sq#_cir
  */
 union cvmx_pko_l5_sqx_cir {
@@ -4520,19 +5350,18 @@ union cvmx_pko_l5_sqx_green {
 	uint64_t u64;
 	struct cvmx_pko_l5_sqx_green_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_41_63               : 23;
+	uint64_t rr_active                    : 1;  /**< Round-robin red active. Indicates that the round-robin input is mapped to RED. */
+	uint64_t active_vec                   : 20; /**< Active vector. A 10-bit vector, ordered by priority, that indicate which inputs to this
+                                                         scheduling queue are active. For internal use only. */
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t active_vec                   : 20;
+	uint64_t rr_active                    : 1;
+	uint64_t reserved_41_63               : 23;
 #endif
 	} s;
 	struct cvmx_pko_l5_sqx_green_s        cn78xx;
@@ -4546,23 +5375,23 @@ union cvmx_pko_l5_sqx_pick {
 	uint64_t u64;
 	struct cvmx_pko_l5_sqx_pick_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq                           : 10; /**< Descriptor Queue. Index of originating descriptor queue. */
+	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
 	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
                                                          result is connected in a flow that extends through the child result, this is the
                                                          index of that child result. */
-	uint64_t bubble                       : 1;  /**< This meta-packet is a fake passed forward after a prune. */
-	uint64_t p_con                        : 1;  /**< Parent Connected Flag. This pick has more picks in front of it. */
-	uint64_t c_con                        : 1;  /**< Child Connected Flag. This pick has more picks behind it. */
+	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
+	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
+	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
 	uint64_t uid                          : 7;  /**< Unique ID. 7-bit unique value assigned at the DQ level, increments for each packet. */
 	uint64_t jump                         : 1;  /**< Jump. Set when metapacket originated from a jump descriptor. */
-	uint64_t fpd                          : 1;  /**< First Packet Descriptor. Set when metapacket was the first in a cacheline. */
-	uint64_t ds                           : 1;  /**< Don't Send. Set when metapacket is not to be sent. */
+	uint64_t fpd                          : 1;  /**< First packet descriptor. Set when metapacket was the first in a cacheline. */
+	uint64_t ds                           : 1;  /**< Don't send. Set when metapacket is not to be sent. */
 	uint64_t adjust                       : 9;  /**< See PKO_L2_SQ(0..511)_SHAPE[ADJUST]. */
-	uint64_t pir_dis                      : 1;  /**< PIR Disable. Peak shaper disabled. */
-	uint64_t cir_dis                      : 1;  /**< CIR Disable. Committed shaper disabled. */
+	uint64_t pir_dis                      : 1;  /**< PIR disable. Peak shaper disabled. */
+	uint64_t cir_dis                      : 1;  /**< CIR disable. Committed shaper disabled. */
 	uint64_t red_algo_override            : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[RED_ALGO]. */
-	uint64_t length                       : 16; /**< Packet Length. The packet length in bytes. */
+	uint64_t length                       : 16; /**< Packet length. The packet length in bytes. */
 #else
 	uint64_t length                       : 16;
 	uint64_t red_algo_override            : 2;
@@ -4647,19 +5476,13 @@ union cvmx_pko_l5_sqx_red {
 	uint64_t u64;
 	struct cvmx_pko_l5_sqx_red_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
 	struct cvmx_pko_l5_sqx_red_s          cn78xx;
@@ -4692,13 +5515,12 @@ union cvmx_pko_l5_sqx_schedule {
 	struct cvmx_pko_l5_sqx_schedule_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's
-                                                         scheduling algorithm. When this SQ is not used, we recommend
-                                                         PRIO be zero. The legal PRIO values are 0-9 when the SQ is used.
-                                                         In addition to priority, PRIO determines whether the SQ is a static
-                                                         queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
-                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this
-                                                         is a round-robin child queue into the shaper at the next level. */
+	uint64_t prio                         : 4;  /**< Priority. The priority used for this SQ in the (lower-level) parent's scheduling
+                                                         algorithm. When this SQ is not used, we recommend setting PRIO to zero. The legal PRIO
+                                                         values are 0-9 when the SQ is used. In addition to priority, PRIO determines whether the
+                                                         SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
+                                                         PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
+                                                         the shaper at the next level. */
 	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
 #else
 	uint64_t rr_quantum                   : 24;
@@ -4718,8 +5540,8 @@ union cvmx_pko_l5_sqx_shape {
 	struct cvmx_pko_l5_sqx_shape_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
-	uint64_t length_disable               : 1;  /**< Length Disable. Disables the use of packet lengths in shaping calculations such that
-                                                         only the value of the ADJUST field described below is used. */
+	uint64_t length_disable               : 1;  /**< Length disable. Disables the use of packet lengths in shaping calculations such that only
+                                                         the value of PKO_L5_SQ(0..1023)_SHAPE[ADJUST]. */
 	uint64_t reserved_13_23               : 11;
 	uint64_t yellow_disable               : 1;  /**< Disable yellow transitions. Disables green-to-yellow packet color marking transitions when set. */
 	uint64_t red_disable                  : 1;  /**< Disable red transitions. Disables green-to-red and yellow-to-red packet color marking
@@ -4775,7 +5597,14 @@ union cvmx_pko_l5_sqx_sw_xoff {
 	uint64_t u64;
 	struct cvmx_pko_l5_sqx_sw_xoff_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
+	uint64_t reserved_4_63                : 60;
+	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
+	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
+                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         until the path has drained." */
+	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
+                                                         ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
+                                                         be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
 	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
@@ -4783,7 +5612,10 @@ union cvmx_pko_l5_sqx_sw_xoff {
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
-	uint64_t reserved_1_63                : 63;
+	uint64_t drain                        : 1;
+	uint64_t drain_null_link              : 1;
+	uint64_t drain_irq                    : 1;
+	uint64_t reserved_4_63                : 60;
 #endif
 	} s;
 	struct cvmx_pko_l5_sqx_sw_xoff_s      cn78xx;
@@ -4825,19 +5657,13 @@ union cvmx_pko_l5_sqx_yellow {
 	uint64_t u64;
 	struct cvmx_pko_l5_sqx_yellow_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t head                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[HEAD]. */
-	uint64_t reserved_26_31               : 6;
-	uint64_t tail                         : 10; /**< See PKO_L1_SQ(0..31)_GREEN[TAIL]. */
-	uint64_t reserved_10_15               : 6;
-	uint64_t active_vec                   : 10; /**< See PKO_L1_SQ(0..31)_GREEN[ACTIVE]. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t head                         : 10; /**< Head pointer. The index of round-robin linked-list head. For internal use only. */
+	uint64_t tail                         : 10; /**< Tail pointer. The index of round-robin linked-list tail. For internal use only. */
 #else
-	uint64_t active_vec                   : 10;
-	uint64_t reserved_10_15               : 6;
 	uint64_t tail                         : 10;
-	uint64_t reserved_26_31               : 6;
 	uint64_t head                         : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
 	struct cvmx_pko_l5_sqx_yellow_s       cn78xx;
@@ -4845,6 +5671,38 @@ union cvmx_pko_l5_sqx_yellow {
 typedef union cvmx_pko_l5_sqx_yellow cvmx_pko_l5_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l5_sqa_debug
+ */
+union cvmx_pko_l5_sqa_debug {
+	uint64_t u64;
+	struct cvmx_pko_l5_sqa_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l5_sqa_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l5_sqa_debug cvmx_pko_l5_sqa_debug_t;
+
+/**
+ * cvmx_pko_l5_sqb_debug
+ */
+union cvmx_pko_l5_sqb_debug {
+	uint64_t u64;
+	struct cvmx_pko_l5_sqb_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_l5_sqb_debug_s        cn78xx;
+};
+typedef union cvmx_pko_l5_sqb_debug cvmx_pko_l5_sqb_debug_t;
+
+/**
  * cvmx_pko_lut#
  */
 union cvmx_pko_lutx {
@@ -4875,13 +5733,11 @@ union cvmx_pko_lut_bist_status {
 	uint64_t u64;
 	struct cvmx_pko_lut_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_2_63                : 62;
-	uint64_t bist_done                    : 1;  /**< FIXME needs work - must indicate done status of each RAM. */
-	uint64_t bist_status                  : 1;  /**< FIXME needs work - must indicate status of each RAM. */
+	uint64_t reserved_1_63                : 63;
+	uint64_t bist_status                  : 1;  /**< C2Q LUT BIST status. */
 #else
 	uint64_t bist_status                  : 1;
-	uint64_t bist_done                    : 1;
-	uint64_t reserved_2_63                : 62;
+	uint64_t reserved_1_63                : 63;
 #endif
 	} s;
 	struct cvmx_pko_lut_bist_status_s     cn78xx;
@@ -4915,7 +5771,9 @@ union cvmx_pko_lut_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_lut_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t c2q_lut_ram_dbe              : 1;  /**< Double-bit error for C2Q_LUT_RAM. */
+	uint64_t c2q_lut_ram_dbe              : 1;  /**< Double-bit error for C2Q_LUT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.pko_c2q_lut.pko_c2q_lut_ram_i */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -4933,7 +5791,12 @@ union cvmx_pko_lut_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_lut_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t lut_dbe_cmb0                 : 1;  /**< Double-bit error for C2Q_LUT_RAM. Throws PKO_INTSN_E::PKO_LUT_DBE_CMB0. */
+	uint64_t lut_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_LUT_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_LUT_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_LUT_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.pko_c2q_lut.pko_c2q_lut_ram_i */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -4951,7 +5814,9 @@ union cvmx_pko_lut_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_lut_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t c2q_lut_ram_sbe              : 1;  /**< Single-bit error for C2Q_LUT_RAM. */
+	uint64_t c2q_lut_ram_sbe              : 1;  /**< Single-bit error for C2Q_LUT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.pko_c2q_lut.pko_c2q_lut_ram_i */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -4969,7 +5834,12 @@ union cvmx_pko_lut_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_lut_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t lut_sbe_cmb0                 : 1;  /**< Single-bit error for C2Q_LUT_RAM. Throws PKO_INTSN_E::PKO_LUT_SBE_CMB0. */
+	uint64_t lut_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_LUT_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_LUT_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_LUT_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.pko_c2q_lut.pko_c2q_lut_ram_i */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -4990,12 +5860,14 @@ union cvmx_pko_macx_cfg {
 	uint64_t reserved_17_63               : 47;
 	uint64_t min_pad_ena                  : 1;  /**< Minimum padding is enabled for this MAC/FIFO */
 	uint64_t fcs_ena                      : 1;  /**< Enable outside FCS for this MAC/FIFO */
-	uint64_t fcs_sop_off                  : 8;  /**< Offset from SOP for beginning of outside FCS calculation */
-	uint64_t skid_max_cnt                 : 2;  /**< Maximum number of SKID credits. 0x0 = 16, 0x1 = 32, 0x2 = 64. */
+	uint64_t fcs_sop_off                  : 8;  /**< FCS start of packet offset.  For this MAC, the number of bytes in the front
+                                                         of each packet to exclude from FCS. */
+	uint64_t skid_max_cnt                 : 2;  /**< Maximum number of SKID credits. 0x0 = 16; 0x1 = 32; 0x2 = 64. */
 	uint64_t fifo_num                     : 5;  /**< The PEB TX FIFO number assigned to the given MAC. A value of 0x1F means unassigned. Unused
                                                          MACs must be assigned a FIFO_NUM = 0x1F. For each active MAC, a unique FIFO_NUM must be
                                                          assigned. Legal values depend on the values in PKO_PTGF(0..7)_CFG[SIZE]. Assigning the
-                                                         same FIFO_NUM to more than a single active MAC will have unpredictable results. */
+                                                         same FIFO_NUM to more than a single active MAC will have unpredictable results.  FIFOs
+                                                         0x1E and 0x1D are invalid and will cause unpredictable results if used. */
 #else
 	uint64_t fifo_num                     : 5;
 	uint64_t skid_max_cnt                 : 2;
@@ -7085,6 +7957,35 @@ union cvmx_pko_mem_throttle_pipe {
 typedef union cvmx_pko_mem_throttle_pipe cvmx_pko_mem_throttle_pipe_t;
 
 /**
+ * cvmx_pko_ncb_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_ncb_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_ncb_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t ncbi_l2_out_ram_bist_status  : 1;  /**< BIST status for NCBI_L2_OUT_RAM. */
+	uint64_t ncbi_pp_out_ram_bist_status  : 1;  /**< BIST status for NCBI_PP_OUT_RAM. */
+	uint64_t ncbo_pdm_cmd_dat_ram_bist_status : 1;/**< BIST status for NCBO_PDM_CMD_DAT_RAM. */
+	uint64_t ncbi_l2_pdm_pref_ram_bist_status : 1;/**< BIST status for NCBI_L2_PDM_PREF_RAM. */
+	uint64_t ncbo_pp_fif_ram_bist_status  : 1;  /**< BIST status for NCBO_PP_FIF_RAM. */
+	uint64_t reserved_0_58                : 59;
+#else
+	uint64_t reserved_0_58                : 59;
+	uint64_t ncbo_pp_fif_ram_bist_status  : 1;
+	uint64_t ncbi_l2_pdm_pref_ram_bist_status : 1;
+	uint64_t ncbo_pdm_cmd_dat_ram_bist_status : 1;
+	uint64_t ncbi_pp_out_ram_bist_status  : 1;
+	uint64_t ncbi_l2_out_ram_bist_status  : 1;
+#endif
+	} s;
+	struct cvmx_pko_ncb_bist_status_s     cn78xx;
+};
+typedef union cvmx_pko_ncb_bist_status cvmx_pko_ncb_bist_status_t;
+
+/**
  * cvmx_pko_ncb_ecc_ctl0
  */
 union cvmx_pko_ncb_ecc_ctl0 {
@@ -7127,11 +8028,21 @@ union cvmx_pko_ncb_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_ncb_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ncbi_l2_out_ram_dbe          : 1;  /**< Double-bit error for NCBI_L2_OUT_RAM. */
-	uint64_t ncbi_pp_out_ram_dbe          : 1;  /**< Double-bit error for NCBI_PP_OUT_RAM. */
-	uint64_t ncbo_pdm_cmd_dat_ram_dbe     : 1;  /**< Double-bit error for NCBO_PDM_CMD_DAT_RAM. */
-	uint64_t ncbi_l2_pdm_pref_ram_dbe     : 1;  /**< Double-bit error for NCBI_L2_PDM_PREF_RAM. */
-	uint64_t ncbo_pp_fif_ram_dbe          : 1;  /**< Double-bit error for NCBO_PP_FIF_RAM. */
+	uint64_t ncbi_l2_out_ram_dbe          : 1;  /**< Double-bit error for NCBI_L2_OUT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.l2_out_fifo */
+	uint64_t ncbi_pp_out_ram_dbe          : 1;  /**< Double-bit error for NCBI_PP_OUT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.pp_out_fifo */
+	uint64_t ncbo_pdm_cmd_dat_ram_dbe     : 1;  /**< Double-bit error for NCBO_PDM_CMD_DAT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.ncb__pdm_cmnd_data_fifo */
+	uint64_t ncbi_l2_pdm_pref_ram_dbe     : 1;  /**< Double-bit error for NCBI_L2_PDM_PREF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_l2_pipe.pdm_prefbuf_fifo */
+	uint64_t ncbo_pp_fif_ram_dbe          : 1;  /**< Double-bit error for NCBO_PP_FIF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.pp_fifo */
 	uint64_t reserved_0_58                : 59;
 #else
 	uint64_t reserved_0_58                : 59;
@@ -7153,7 +8064,16 @@ union cvmx_pko_ncb_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_ncb_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ncb_dbe_cmb0                 : 1;  /**< Double-bit error for NCBI_L2_OUT_RAM. Throws PKO_INTSN_E::PKO_NCB_DBE_CMB0. */
+	uint64_t ncb_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_NCB_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_NCB_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_NCB_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.l2_out_fifo
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.pp_out_fifo
+                                                         pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.ncb__pdm_cmnd_data_fifo
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_l2_pipe.pdm_prefbuf_fifo
+                                                         pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.pp_fifo */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -7171,11 +8091,21 @@ union cvmx_pko_ncb_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_ncb_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ncbi_l2_out_ram_sbe          : 1;  /**< Single-bit error for NCBI_L2_OUT_RAM. */
-	uint64_t ncbi_pp_out_ram_sbe          : 1;  /**< Single-bit error for NCBI_PP_OUT_RAM. */
-	uint64_t ncbo_pdm_cmd_dat_ram_sbe     : 1;  /**< Single-bit error for NCBO_PDM_CMD_DAT_RAM. */
-	uint64_t ncbi_l2_pdm_pref_ram_sbe     : 1;  /**< Single-bit error for NCBI_L2_PDM_PREF_RAM. */
-	uint64_t ncbo_pp_fif_ram_sbe          : 1;  /**< Single-bit error for NCBO_PP_FIF_RAM. */
+	uint64_t ncbi_l2_out_ram_sbe          : 1;  /**< Single-bit error for NCBI_L2_OUT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.l2_out_fifo */
+	uint64_t ncbi_pp_out_ram_sbe          : 1;  /**< Single-bit error for NCBI_PP_OUT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.pp_out_fifo */
+	uint64_t ncbo_pdm_cmd_dat_ram_sbe     : 1;  /**< Single-bit error for NCBO_PDM_CMD_DAT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.ncb__pdm_cmnd_data_fifo */
+	uint64_t ncbi_l2_pdm_pref_ram_sbe     : 1;  /**< Single-bit error for NCBI_L2_PDM_PREF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_l2_pipe.pdm_prefbuf_fifo */
+	uint64_t ncbo_pp_fif_ram_sbe          : 1;  /**< Single-bit error for NCBO_PP_FIF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.pp_fifo */
 	uint64_t reserved_0_58                : 59;
 #else
 	uint64_t reserved_0_58                : 59;
@@ -7197,7 +8127,16 @@ union cvmx_pko_ncb_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_ncb_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ncb_sbe_cmb0                 : 1;  /**< Single-bit error for NCBI_L2_OUT_RAM. Throws PKO_INTSN_E::PKO_NCB_SBE_CMB0. */
+	uint64_t ncb_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_NCB_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_NCB_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_NCB_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.l2_out_fifo
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.pp_out_fifo
+                                                         pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.ncb__pdm_cmnd_data_fifo
+                                                         pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_l2_pipe.pdm_prefbuf_fifo
+                                                         pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.pp_fifo */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -7265,7 +8204,7 @@ union cvmx_pko_ncb_tx_err_word {
 	struct cvmx_pko_ncb_tx_err_word_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t err_word                     : 64; /**< PKO NCB error word (first word of erroneous transaction).
-                                                         Note: this is only the 64-bit data word; the NCB info that goes with it is in
+                                                         Note: This is only the 64-bit data word; the NCB info that goes with it is in
                                                          PKO_NCB_TX_ERR_INFO. */
 #else
 	uint64_t err_word                     : 64;
@@ -7276,29 +8215,107 @@ union cvmx_pko_ncb_tx_err_word {
 typedef union cvmx_pko_ncb_tx_err_word cvmx_pko_ncb_tx_err_word_t;
 
 /**
+ * cvmx_pko_pdm_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_pdm_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_pdm_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t flshb_cache_lo_ram_bist_status : 1;/**< BIST status for FLSHB_CACHE_LO_RAM. */
+	uint64_t flshb_cache_hi_ram_bist_status : 1;/**< BIST status for FLSHB_CACHE_HI_RAM. */
+	uint64_t isrm_ca_iinst_ram_bist_status : 1; /**< BIST status for ISRM_CA_IINST_RAM. */
+	uint64_t isrm_ca_cm_ram_bist_status   : 1;  /**< BIST status for ISRM_CA_CM_RAM. */
+	uint64_t isrm_st_ram2_bist_status     : 1;  /**< BIST status for ISRM_ST_RAM2. */
+	uint64_t isrm_st_ram1_bist_status     : 1;  /**< BIST status for ISRM_ST_RAM1. */
+	uint64_t isrm_st_ram0_bist_status     : 1;  /**< BIST status for ISRM_ST_RAM0. */
+	uint64_t isrd_st_ram3_bist_status     : 1;  /**< BIST status for ISRD_ST_RAM3. */
+	uint64_t isrd_st_ram2_bist_status     : 1;  /**< BIST status for ISRD_ST_RAM2. */
+	uint64_t isrd_st_ram1_bist_status     : 1;  /**< BIST status for ISRD_ST_RAM1. */
+	uint64_t isrd_st_ram0_bist_status     : 1;  /**< BIST status for ISRD_ST_RAM0. */
+	uint64_t drp_hi_ram_bist_status       : 1;  /**< BIST status for DRP_HI_RAM. */
+	uint64_t drp_lo_ram_bist_status       : 1;  /**< BIST status for DRP_LO_RAM. */
+	uint64_t dwp_hi_ram_bist_status       : 1;  /**< BIST status for DWP_HI_RAM. */
+	uint64_t dwp_lo_ram_bist_status       : 1;  /**< BIST status for DWP_LO_RAM. */
+	uint64_t mwp_hi_ram_bist_status       : 1;  /**< BIST status for MWP_HI_RAM. */
+	uint64_t mwp_lo_ram_bist_status       : 1;  /**< BIST status for MWP_LO_RAM. */
+	uint64_t fillb_m_rsp_ram_hi_bist_status : 1;/**< BIST status for FILLB_M_RSP_RAM_HI. */
+	uint64_t fillb_m_rsp_ram_lo_bist_status : 1;/**< BIST status for FILLB_M_RSP_RAM_LO. */
+	uint64_t fillb_d_rsp_ram_hi_bist_status : 1;/**< BIST status for FILLB_D_RSP_RAM_HI. */
+	uint64_t fillb_d_rsp_ram_lo_bist_status : 1;/**< BIST status for FILLB_D_RSP_RAM_LO. */
+	uint64_t fillb_d_rsp_dat_fifo_bist_status : 1;/**< BIST status for FILLB_FLSHB_M_DAT_RAM. */
+	uint64_t fillb_m_rsp_dat_fifo_bist_status : 1;/**< BIST status for FILLB_M_DAT_FIFO. */
+	uint64_t flshb_m_dat_ram_bist_status  : 1;  /**< BIST status for FLSHB_M_DAT_RAM. */
+	uint64_t flshb_d_dat_ram_bist_status  : 1;  /**< BIST status for FLSHB_M_DAT_RAM. */
+	uint64_t minpad_ram_bist_status       : 1;  /**< BIST status for MINPAD_RAM. */
+	uint64_t reserved_0_37                : 38;
+#else
+	uint64_t reserved_0_37                : 38;
+	uint64_t minpad_ram_bist_status       : 1;
+	uint64_t flshb_d_dat_ram_bist_status  : 1;
+	uint64_t flshb_m_dat_ram_bist_status  : 1;
+	uint64_t fillb_m_rsp_dat_fifo_bist_status : 1;
+	uint64_t fillb_d_rsp_dat_fifo_bist_status : 1;
+	uint64_t fillb_d_rsp_ram_lo_bist_status : 1;
+	uint64_t fillb_d_rsp_ram_hi_bist_status : 1;
+	uint64_t fillb_m_rsp_ram_lo_bist_status : 1;
+	uint64_t fillb_m_rsp_ram_hi_bist_status : 1;
+	uint64_t mwp_lo_ram_bist_status       : 1;
+	uint64_t mwp_hi_ram_bist_status       : 1;
+	uint64_t dwp_lo_ram_bist_status       : 1;
+	uint64_t dwp_hi_ram_bist_status       : 1;
+	uint64_t drp_lo_ram_bist_status       : 1;
+	uint64_t drp_hi_ram_bist_status       : 1;
+	uint64_t isrd_st_ram0_bist_status     : 1;
+	uint64_t isrd_st_ram1_bist_status     : 1;
+	uint64_t isrd_st_ram2_bist_status     : 1;
+	uint64_t isrd_st_ram3_bist_status     : 1;
+	uint64_t isrm_st_ram0_bist_status     : 1;
+	uint64_t isrm_st_ram1_bist_status     : 1;
+	uint64_t isrm_st_ram2_bist_status     : 1;
+	uint64_t isrm_ca_cm_ram_bist_status   : 1;
+	uint64_t isrm_ca_iinst_ram_bist_status : 1;
+	uint64_t flshb_cache_hi_ram_bist_status : 1;
+	uint64_t flshb_cache_lo_ram_bist_status : 1;
+#endif
+	} s;
+	struct cvmx_pko_pdm_bist_status_s     cn78xx;
+};
+typedef union cvmx_pko_pdm_bist_status cvmx_pko_pdm_bist_status_t;
+
+/**
  * cvmx_pko_pdm_cfg
  */
 union cvmx_pko_pdm_cfg {
 	uint64_t u64;
 	struct cvmx_pko_pdm_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_10_63               : 54;
-	uint64_t pko_pad_minlen               : 7;  /**< Minimum frame padding min length. When */
-	uint64_t diag_mode                    : 1;  /**< Diagnostic mode. Enable to read/write to memories in PDM through CSR interface. */
+	uint64_t reserved_13_63               : 51;
+	uint64_t dis_lpd_w2r_fill             : 1;  /**< Set to disable the write to read fill caused by LPD in the PDM. If disabled, must wait for
+                                                         FPD bit from PEB, which is a performance penalty when the time is large for the PEB
+                                                         request to make it back to PDM. For diagnostic use only. */
+	uint64_t en_fr_w2r_ptr_swp            : 1;  /**< Set to enable pointer swap on a fill response when we go in-sync (only one cacheline in
+                                                         DQ).
+                                                         For diagnostic use only. */
+	uint64_t dis_flsh_cache               : 1;  /**< Set to disable the flush buffer's cache. This makes all fills require full memory latency.
+                                                         For diagnostic use only. */
+	uint64_t pko_pad_minlen               : 7;  /**< Minimum frame padding min length. */
+	uint64_t diag_mode                    : 1;  /**< Set to enable read/write to memories in PDM through CSR interface.  For diagnostic use only. */
 	uint64_t alloc_lds                    : 1;  /**< Allocate LDS. This signal prevents the loads to IOBP from being allocated in on-chip cache
-                                                         (LDWB vs. LDD). Two modes as follows:
-                                                         0 = No allocate (LDWB)
-                                                         1 = Allocate (LDD) */
+                                                         (LDWB vs. LDD). Two modes as follows: 0 = No allocate (LDWB); 1 = Allocate (LDD). */
 	uint64_t alloc_sts                    : 1;  /**< Allocate STS. This signal prevents the stores to NCB from being allocated in on-chip cache
-                                                         (STF vs. STT). Two modes as follows:
-                                                         0 = No allocate (STT)
-                                                         1 = Allocate (STF) */
+                                                         (STF vs. STT). Two modes as follows: 0 = No allocate (STT); 1 = Allocate (STF). */
 #else
 	uint64_t alloc_sts                    : 1;
 	uint64_t alloc_lds                    : 1;
 	uint64_t diag_mode                    : 1;
 	uint64_t pko_pad_minlen               : 7;
-	uint64_t reserved_10_63               : 54;
+	uint64_t dis_flsh_cache               : 1;
+	uint64_t en_fr_w2r_ptr_swp            : 1;
+	uint64_t dis_lpd_w2r_fill             : 1;
+	uint64_t reserved_13_63               : 51;
 #endif
 	} s;
 	struct cvmx_pko_pdm_cfg_s             cn78xx;
@@ -7306,6 +8323,54 @@ union cvmx_pko_pdm_cfg {
 typedef union cvmx_pko_pdm_cfg cvmx_pko_pdm_cfg_t;
 
 /**
+ * cvmx_pko_pdm_cfg_dbg
+ */
+union cvmx_pko_pdm_cfg_dbg {
+	uint64_t u64;
+	struct cvmx_pko_pdm_cfg_dbg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t cp_stall_thrshld             : 32; /**< Program this register to the 32-bit number of cycles to test for the PDM(CP) stalled on
+                                                         inputs going into the ISRs. PKO_PDM_STS[CP_STALL_THRSHLD_HIT] indicates the threshold has
+                                                         been hit. INTERNAL: Do not list field in HRM. For lab debug only; will likely disappear in
+                                                         pass 2. */
+#else
+	uint64_t cp_stall_thrshld             : 32;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} s;
+	struct cvmx_pko_pdm_cfg_dbg_s         cn78xx;
+};
+typedef union cvmx_pko_pdm_cfg_dbg cvmx_pko_pdm_cfg_dbg_t;
+
+/**
+ * cvmx_pko_pdm_cp_dbg
+ */
+union cvmx_pko_pdm_cp_dbg {
+	uint64_t u64;
+	struct cvmx_pko_pdm_cp_dbg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t stateless_fif_cnt            : 6;  /**< Stateless fifo count. */
+	uint64_t reserved_5_9                 : 5;
+	uint64_t op_fif_not_full              : 5;  /**< Output fifo not full signals. The order of the bits is:
+                                                         - 4: ISR CMD FIFO not full
+                                                         - 3: DESC DAT FIFO HIGH not full
+                                                         - 2: DESC DAT FIFO LOW not full
+                                                         - 1: MP DAT FIFO not full
+                                                         - 0: PSE CMD RESP FIFO has credit */
+#else
+	uint64_t op_fif_not_full              : 5;
+	uint64_t reserved_5_9                 : 5;
+	uint64_t stateless_fif_cnt            : 6;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_pko_pdm_cp_dbg_s          cn78xx;
+};
+typedef union cvmx_pko_pdm_cp_dbg cvmx_pko_pdm_cp_dbg_t;
+
+/**
  * cvmx_pko_pdm_dq#_minpad
  */
 union cvmx_pko_pdm_dqx_minpad {
@@ -7313,12 +8378,11 @@ union cvmx_pko_pdm_dqx_minpad {
 	struct cvmx_pko_pdm_dqx_minpad_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t minpad                       : 1;  /**< MINPAD setting per DQ. Each DQ has a seperate CSR address, and bit 0 of the
-                                                         data read/write value will be the MINPAD bit.
-                                                         When MINPAD is set, the send-packet header will have the total field adjusted by MINLEN
-                                                         (PKO_PDM_CFG.PKO_PAD_MINLEN) as follows:
-                                                           if( MINPAD )
-                                                               if( send_hdr.total < MINLEN ) send_hdr.total = MINLEN */
+	uint64_t minpad                       : 1;  /**< MINPAD setting per DQ. Each DQ has a separate CSR address; and bit 0 of the data
+                                                         read/write value is the MINPAD bit. When MINPAD is set, the send-packet header has the
+                                                         total field adjusted by MINLEN (PKO_PDM_CFG.PKO_PAD_MINLEN) as follows:
+                                                         if (MINPAD)
+                                                         if (send_hdr.total < MINLEN) send_hdr.total = MINLEN */
 #else
 	uint64_t minpad                       : 1;
 	uint64_t reserved_1_63                : 63;
@@ -7329,6 +8393,80 @@ union cvmx_pko_pdm_dqx_minpad {
 typedef union cvmx_pko_pdm_dqx_minpad cvmx_pko_pdm_dqx_minpad_t;
 
 /**
+ * cvmx_pko_pdm_drpbuf_dbg
+ */
+union cvmx_pko_pdm_drpbuf_dbg {
+	uint64_t u64;
+	struct cvmx_pko_pdm_drpbuf_dbg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_43_63               : 21;
+	uint64_t sel_nxt_ptr                  : 1;  /**< Sel_nxt_ptr signal. */
+	uint64_t load_val                     : 1;  /**< Load valid signal. */
+	uint64_t rdy                          : 1;  /**< Ready signal. */
+	uint64_t cur_state                    : 3;  /**< Current state from the pbuf controller. */
+	uint64_t reserved_33_36               : 4;
+	uint64_t track_rd_cnt                 : 6;  /**< Track read count value. */
+	uint64_t track_wr_cnt                 : 6;  /**< Track write count value. */
+	uint64_t reserved_17_20               : 4;
+	uint64_t mem_addr                     : 13; /**< Memory address for pbuf ram. */
+	uint64_t mem_en                       : 4;  /**< Memory write/chip enable signals. The order of the bits is:
+                                                         - 3: low wen; 2: low cen; 1: high wen; 0: high cen. */
+#else
+	uint64_t mem_en                       : 4;
+	uint64_t mem_addr                     : 13;
+	uint64_t reserved_17_20               : 4;
+	uint64_t track_wr_cnt                 : 6;
+	uint64_t track_rd_cnt                 : 6;
+	uint64_t reserved_33_36               : 4;
+	uint64_t cur_state                    : 3;
+	uint64_t rdy                          : 1;
+	uint64_t load_val                     : 1;
+	uint64_t sel_nxt_ptr                  : 1;
+	uint64_t reserved_43_63               : 21;
+#endif
+	} s;
+	struct cvmx_pko_pdm_drpbuf_dbg_s      cn78xx;
+};
+typedef union cvmx_pko_pdm_drpbuf_dbg cvmx_pko_pdm_drpbuf_dbg_t;
+
+/**
+ * cvmx_pko_pdm_dwpbuf_dbg
+ */
+union cvmx_pko_pdm_dwpbuf_dbg {
+	uint64_t u64;
+	struct cvmx_pko_pdm_dwpbuf_dbg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_43_63               : 21;
+	uint64_t sel_nxt_ptr                  : 1;  /**< Sel_nxt_ptr signal. */
+	uint64_t load_val                     : 1;  /**< Load valid signal. */
+	uint64_t rdy                          : 1;  /**< Ready signal. */
+	uint64_t cur_state                    : 3;  /**< Current state from the pbuf controller. */
+	uint64_t reserved_33_36               : 4;
+	uint64_t track_rd_cnt                 : 6;  /**< Track read count value. */
+	uint64_t track_wr_cnt                 : 6;  /**< Track write count value. */
+	uint64_t reserved_17_20               : 4;
+	uint64_t mem_addr                     : 13; /**< Memory address for pbuf ram. */
+	uint64_t mem_en                       : 4;  /**< Memory write/chip enable signals. The order of the bits is:
+                                                         - 3: low wen; 2: low cen; 1: high wen; 0: high cen. */
+#else
+	uint64_t mem_en                       : 4;
+	uint64_t mem_addr                     : 13;
+	uint64_t reserved_17_20               : 4;
+	uint64_t track_wr_cnt                 : 6;
+	uint64_t track_rd_cnt                 : 6;
+	uint64_t reserved_33_36               : 4;
+	uint64_t cur_state                    : 3;
+	uint64_t rdy                          : 1;
+	uint64_t load_val                     : 1;
+	uint64_t sel_nxt_ptr                  : 1;
+	uint64_t reserved_43_63               : 21;
+#endif
+	} s;
+	struct cvmx_pko_pdm_dwpbuf_dbg_s      cn78xx;
+};
+typedef union cvmx_pko_pdm_dwpbuf_dbg cvmx_pko_pdm_dwpbuf_dbg_t;
+
+/**
  * cvmx_pko_pdm_ecc_ctl0
  */
 union cvmx_pko_pdm_ecc_ctl0 {
@@ -7369,21 +8507,25 @@ union cvmx_pko_pdm_ecc_ctl0 {
 	uint64_t mwp_hi_ram_cdis              : 1;  /**< MWP_HI_RAM ECC correction disable. */
 	uint64_t mwp_lo_ram_flip              : 2;  /**< MWP_LO_RAM flip syndrome bits on write. */
 	uint64_t mwp_lo_ram_cdis              : 1;  /**< MWP_LO_RAM ECC correction disable. */
-	uint64_t fillb_m_dat_ram_flip         : 2;  /**< FILLB_M_DAT_RAM flip syndrome bits on write. */
-	uint64_t fillb_m_dat_ram_cdis         : 1;  /**< FILLB_M_DAT_RAM ECC correction disable. */
-	uint64_t fillb_d_dat_ram_flip         : 2;  /**< FILLB_D_DAT_RAM flip syndrome bits on write. */
-	uint64_t fillb_d_dat_ram_cdis         : 1;  /**< FILLB_D_DAT_RAM ECC correction disable. */
-	uint64_t minpad_ram_flip              : 2;  /**< MINPAD_RAM flip syndrome bits on write. */
-	uint64_t minpad_ram_cdis              : 1;  /**< MINPAD_RAM ECC correction disable. */
-	uint64_t reserved_0_3                 : 4;
+	uint64_t fillb_m_rsp_ram_hi_flip      : 2;  /**< FILLB_M_RSP_RAM_HI flip syndrome bits on write. */
+	uint64_t fillb_m_rsp_ram_hi_cdis      : 1;  /**< FILLB_M_RSP_RAM_HI ECC correction disable. */
+	uint64_t fillb_m_rsp_ram_lo_flip      : 2;  /**< FILLB_M_RSP_RAM_LO flip syndrome bits on write. */
+	uint64_t fillb_m_rsp_ram_lo_cdis      : 1;  /**< FILLB_M_RSP_RAM_LO ECC correction disable. */
+	uint64_t fillb_d_rsp_ram_hi_flip      : 2;  /**< FILLB_D_RSP_RAM_LO flip syndrome bits on write. */
+	uint64_t fillb_d_rsp_ram_hi_cdis      : 1;  /**< FILLB_D_RSP_RAM_HI ECC correction disable. */
+	uint64_t fillb_d_rsp_ram_lo_flip      : 2;  /**< FILLB_D_DAT_RAM_LO flip syndrome bits on write. */
+	uint64_t fillb_d_rsp_ram_lo_cdis      : 1;  /**< FILLB_D_RSP_RAM_LO ECC correction disable. */
+	uint64_t reserved_0_0                 : 1;
 #else
-	uint64_t reserved_0_3                 : 4;
-	uint64_t minpad_ram_cdis              : 1;
-	uint64_t minpad_ram_flip              : 2;
-	uint64_t fillb_d_dat_ram_cdis         : 1;
-	uint64_t fillb_d_dat_ram_flip         : 2;
-	uint64_t fillb_m_dat_ram_cdis         : 1;
-	uint64_t fillb_m_dat_ram_flip         : 2;
+	uint64_t reserved_0_0                 : 1;
+	uint64_t fillb_d_rsp_ram_lo_cdis      : 1;
+	uint64_t fillb_d_rsp_ram_lo_flip      : 2;
+	uint64_t fillb_d_rsp_ram_hi_cdis      : 1;
+	uint64_t fillb_d_rsp_ram_hi_flip      : 2;
+	uint64_t fillb_m_rsp_ram_lo_cdis      : 1;
+	uint64_t fillb_m_rsp_ram_lo_flip      : 2;
+	uint64_t fillb_m_rsp_ram_hi_cdis      : 1;
+	uint64_t fillb_m_rsp_ram_hi_flip      : 2;
 	uint64_t mwp_lo_ram_cdis              : 1;
 	uint64_t mwp_lo_ram_flip              : 2;
 	uint64_t mwp_hi_ram_cdis              : 1;
@@ -7425,38 +8567,106 @@ union cvmx_pko_pdm_ecc_ctl0 {
 typedef union cvmx_pko_pdm_ecc_ctl0 cvmx_pko_pdm_ecc_ctl0_t;
 
 /**
+ * cvmx_pko_pdm_ecc_ctl1
+ */
+union cvmx_pko_pdm_ecc_ctl1 {
+	uint64_t u64;
+	struct cvmx_pko_pdm_ecc_ctl1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_3_63                : 61;
+	uint64_t minpad_ram_flip              : 2;  /**< MINPAD_RAM flip syndrome bits on write. */
+	uint64_t minpad_ram_cdis              : 1;  /**< MINPAD_RAM ECC correction disable. */
+#else
+	uint64_t minpad_ram_cdis              : 1;
+	uint64_t minpad_ram_flip              : 2;
+	uint64_t reserved_3_63                : 61;
+#endif
+	} s;
+	struct cvmx_pko_pdm_ecc_ctl1_s        cn78xx;
+};
+typedef union cvmx_pko_pdm_ecc_ctl1 cvmx_pko_pdm_ecc_ctl1_t;
+
+/**
  * cvmx_pko_pdm_ecc_dbe_sts0
  */
 union cvmx_pko_pdm_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pdm_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t flshb_cache_lo_ram_dbe       : 1;  /**< Double-bit error for FLSHB_CACHE_LO_RAM. */
-	uint64_t flshb_cache_hi_ram_dbe       : 1;  /**< Double-bit error for FLSHB_CACHE_HI_RAM. */
-	uint64_t isrm_ca_iinst_ram_dbe        : 1;  /**< Double-bit error for ISRM_CA_IINST_RAM. */
-	uint64_t isrm_ca_cm_ram_dbe           : 1;  /**< Double-bit error for ISRM_CA_CM_RAM. */
-	uint64_t isrm_st_ram2_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM2. */
-	uint64_t isrm_st_ram1_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM1. */
-	uint64_t isrm_st_ram0_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM0. */
-	uint64_t isrd_st_ram3_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM3. */
-	uint64_t isrd_st_ram2_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM2. */
-	uint64_t isrd_st_ram1_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM1. */
-	uint64_t isrd_st_ram0_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM0. */
-	uint64_t drp_hi_ram_dbe               : 1;  /**< Double-bit error for DRP_HI_RAM. */
-	uint64_t drp_lo_ram_dbe               : 1;  /**< Double-bit error for DRP_LO_RAM. */
-	uint64_t dwp_hi_ram_dbe               : 1;  /**< Double-bit error for DWP_HI_RAM. */
-	uint64_t dwp_lo_ram_dbe               : 1;  /**< Double-bit error for DWP_LO_RAM. */
-	uint64_t mwp_hi_ram_dbe               : 1;  /**< Double-bit error for MWP_HI_RAM. */
-	uint64_t mwp_lo_ram_dbe               : 1;  /**< Double-bit error for MWP_LO_RAM. */
-	uint64_t fillb_m_dat_ram_dbe          : 1;  /**< Double-bit error for FILLB_M_DAT_RAM. */
-	uint64_t fillb_d_dat_ram_dbe          : 1;  /**< Double-bit error for FILLB_D_DAT_RAM. */
-	uint64_t minpad_ram_dbe               : 1;  /**< Double-bit error for MINPAD_RAM. */
-	uint64_t reserved_0_43                : 44;
-#else
-	uint64_t reserved_0_43                : 44;
+	uint64_t flshb_cache_lo_ram_dbe       : 1;  /**< Double-bit error for FLSHB_CACHE_LO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_lo */
+	uint64_t flshb_cache_hi_ram_dbe       : 1;  /**< Double-bit error for FLSHB_CACHE_HI_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_hi */
+	uint64_t isrm_ca_iinst_ram_dbe        : 1;  /**< Double-bit error for ISRM_CA_IINST_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.iinst_in_fif */
+	uint64_t isrm_ca_cm_ram_dbe           : 1;  /**< Double-bit error for ISRM_CA_CM_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.cred_accum_ctrlr_and_mem.cred_accum_spr */
+	uint64_t isrm_st_ram2_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM2.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem2 */
+	uint64_t isrm_st_ram1_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM1.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem1 */
+	uint64_t isrm_st_ram0_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0 */
+	uint64_t isrd_st_ram3_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM3.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem3 */
+	uint64_t isrd_st_ram2_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM2.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem2 */
+	uint64_t isrd_st_ram1_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM1.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem1 */
+	uint64_t isrd_st_ram0_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem0 */
+	uint64_t drp_hi_ram_dbe               : 1;  /**< Double-bit error for DRP_HI_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_1 */
+	uint64_t drp_lo_ram_dbe               : 1;  /**< Double-bit error for DRP_LO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_2 */
+	uint64_t dwp_hi_ram_dbe               : 1;  /**< Double-bit error for DWP_HI_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_high */
+	uint64_t dwp_lo_ram_dbe               : 1;  /**< Double-bit error for DWP_LO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_low */
+	uint64_t mwp_hi_ram_dbe               : 1;  /**< Double-bit error for MWP_HI_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_high */
+	uint64_t mwp_lo_ram_dbe               : 1;  /**< Double-bit error for MWP_LO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_low */
+	uint64_t fillb_m_rsp_ram_hi_dbe       : 1;  /**< Double-bit error for FILLB_M_DAT_RAM_HI.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_ram_hi */
+	uint64_t fillb_m_rsp_ram_lo_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_LO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_ram_lo */
+	uint64_t fillb_d_rsp_ram_hi_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_HI.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_hi */
+	uint64_t fillb_d_rsp_ram_lo_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_LO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_lo */
+	uint64_t minpad_ram_dbe               : 1;  /**< Double-bit error for MINPAD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.cp.minpad_ram */
+	uint64_t reserved_0_41                : 42;
+#else
+	uint64_t reserved_0_41                : 42;
 	uint64_t minpad_ram_dbe               : 1;
-	uint64_t fillb_d_dat_ram_dbe          : 1;
-	uint64_t fillb_m_dat_ram_dbe          : 1;
+	uint64_t fillb_d_rsp_ram_lo_dbe       : 1;
+	uint64_t fillb_d_rsp_ram_hi_dbe       : 1;
+	uint64_t fillb_m_rsp_ram_lo_dbe       : 1;
+	uint64_t fillb_m_rsp_ram_hi_dbe       : 1;
 	uint64_t mwp_lo_ram_dbe               : 1;
 	uint64_t mwp_hi_ram_dbe               : 1;
 	uint64_t dwp_lo_ram_dbe               : 1;
@@ -7487,7 +8697,33 @@ union cvmx_pko_pdm_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pdm_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pdm_dbe_cmb0                 : 1;  /**< Double-bit error for FLSHB_CACHE_LO_RAM. Throws PKO_INTSN_E::PKO_PDM_DBE_CMB0. */
+	uint64_t pdm_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PDM_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PDM_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PDM_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_hi
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_lo
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.iinst_in_fif
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.cred_accum_ctrlr_and_mem.cred_
+                                                         accum_spr
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem1
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem2
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem0
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem1
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem2
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem3
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_1
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_2
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_low
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_high
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_low
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_high
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_hi
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_lo
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_dat_fifo
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.cp.minpad_ram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -7505,32 +8741,80 @@ union cvmx_pko_pdm_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pdm_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t flshb_cache_lo_ram_sbe       : 1;  /**< Single-bit error for FLSHB_CACHE_LO_RAM. */
-	uint64_t flshb_cache_hi_ram_sbe       : 1;  /**< Single-bit error for FLSHB_CACHE_HI_RAM. */
-	uint64_t isrm_ca_iinst_ram_sbe        : 1;  /**< Single-bit error for ISRM_CA_IINST_RAM. */
-	uint64_t isrm_ca_cm_ram_sbe           : 1;  /**< Single-bit error for ISRM_CA_CM_RAM. */
-	uint64_t isrm_st_ram2_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM2. */
-	uint64_t isrm_st_ram1_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM1. */
-	uint64_t isrm_st_ram0_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM0. */
-	uint64_t isrd_st_ram3_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM3. */
-	uint64_t isrd_st_ram2_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM2. */
-	uint64_t isrd_st_ram1_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM1. */
-	uint64_t isrd_st_ram0_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM0. */
-	uint64_t drp_hi_ram_sbe               : 1;  /**< Single-bit error for DRP_HI_RAM. */
-	uint64_t drp_lo_ram_sbe               : 1;  /**< Single-bit error for DRP_LO_RAM. */
-	uint64_t dwp_hi_ram_sbe               : 1;  /**< Single-bit error for DWP_HI_RAM. */
-	uint64_t dwp_lo_ram_sbe               : 1;  /**< Single-bit error for DWP_LO_RAM. */
-	uint64_t mwp_hi_ram_sbe               : 1;  /**< Single-bit error for MWP_HI_RAM. */
-	uint64_t mwp_lo_ram_sbe               : 1;  /**< Single-bit error for MWP_LO_RAM. */
-	uint64_t fillb_m_dat_ram_sbe          : 1;  /**< Single-bit error for FILLB_M_DAT_RAM. */
-	uint64_t fillb_d_dat_ram_sbe          : 1;  /**< Single-bit error for FILLB_D_DAT_RAM. */
-	uint64_t minpad_ram_sbe               : 1;  /**< Single-bit error for MINPAD_RAM. */
-	uint64_t reserved_0_43                : 44;
-#else
-	uint64_t reserved_0_43                : 44;
+	uint64_t flshb_cache_lo_ram_sbe       : 1;  /**< Single-bit error for FLSHB_CACHE_LO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_lo */
+	uint64_t flshb_cache_hi_ram_sbe       : 1;  /**< Single-bit error for FLSHB_CACHE_HI_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_hi */
+	uint64_t isrm_ca_iinst_ram_sbe        : 1;  /**< Single-bit error for ISRM_CA_IINST_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.iinst_in_fif */
+	uint64_t isrm_ca_cm_ram_sbe           : 1;  /**< Single-bit error for ISRM_CA_CM_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.cred_accum_ctrlr_and_mem.cred_accum_spr */
+	uint64_t isrm_st_ram2_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM2.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem2 */
+	uint64_t isrm_st_ram1_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM1.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem1 */
+	uint64_t isrm_st_ram0_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0 */
+	uint64_t isrd_st_ram3_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM3.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem3 */
+	uint64_t isrd_st_ram2_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM2.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem2 */
+	uint64_t isrd_st_ram1_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM1.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem1 */
+	uint64_t isrd_st_ram0_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem0 */
+	uint64_t drp_hi_ram_sbe               : 1;  /**< Single-bit error for DRP_HI_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_1 */
+	uint64_t drp_lo_ram_sbe               : 1;  /**< Single-bit error for DRP_LO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_2 */
+	uint64_t dwp_hi_ram_sbe               : 1;  /**< Single-bit error for DWP_HI_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_high */
+	uint64_t dwp_lo_ram_sbe               : 1;  /**< Single-bit error for DWP_LO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_low */
+	uint64_t mwp_hi_ram_sbe               : 1;  /**< Single-bit error for MWP_HI_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_high */
+	uint64_t mwp_lo_ram_sbe               : 1;  /**< Single-bit error for MWP_LO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_low */
+	uint64_t fillb_m_rsp_ram_hi_sbe       : 1;  /**< Single-bit error for FILLB_M_RSP_RAM_HI.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_ram_hi */
+	uint64_t fillb_m_rsp_ram_lo_sbe       : 1;  /**< Single-bit error for FILLB_M_RSP_RAM_LO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_ram_lo */
+	uint64_t fillb_d_rsp_ram_hi_sbe       : 1;  /**< Single-bit error for FILLB_D_RSP_RAM_HI.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_hi */
+	uint64_t fillb_d_rsp_ram_lo_sbe       : 1;  /**< Single-bit error for FILLB_D_RSP_RAM_LO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_lo */
+	uint64_t minpad_ram_sbe               : 1;  /**< Single-bit error for MINPAD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr1.pko_pnr1_pdm.cp.minpad_ram */
+	uint64_t reserved_0_41                : 42;
+#else
+	uint64_t reserved_0_41                : 42;
 	uint64_t minpad_ram_sbe               : 1;
-	uint64_t fillb_d_dat_ram_sbe          : 1;
-	uint64_t fillb_m_dat_ram_sbe          : 1;
+	uint64_t fillb_d_rsp_ram_lo_sbe       : 1;
+	uint64_t fillb_d_rsp_ram_hi_sbe       : 1;
+	uint64_t fillb_m_rsp_ram_lo_sbe       : 1;
+	uint64_t fillb_m_rsp_ram_hi_sbe       : 1;
 	uint64_t mwp_lo_ram_sbe               : 1;
 	uint64_t mwp_hi_ram_sbe               : 1;
 	uint64_t dwp_lo_ram_sbe               : 1;
@@ -7561,7 +8845,33 @@ union cvmx_pko_pdm_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pdm_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pdm_sbe_cmb0                 : 1;  /**< Single-bit error for FLSHB_CACHE_LO_RAM. Throws PKO_INTSN_E::PKO_PDM_SBE_CMB0. */
+	uint64_t pdm_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PDM_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PDM_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PDM_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_hi
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_lo
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.iinst_in_fif
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.cred_accum_ctrlr_and_mem.cred_
+                                                         accum_spr
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem1
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem2
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem0
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem1
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem2
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem3
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_1
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_2
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_low
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_high
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_low
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_high
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_hi
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_lo
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_dat_fifo
+                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.cp.minpad_ram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -7573,6 +8883,204 @@ union cvmx_pko_pdm_ecc_sbe_sts_cmb0 {
 typedef union cvmx_pko_pdm_ecc_sbe_sts_cmb0 cvmx_pko_pdm_ecc_sbe_sts_cmb0_t;
 
 /**
+ * cvmx_pko_pdm_isrd_dbg
+ */
+union cvmx_pko_pdm_isrd_dbg {
+	uint64_t u64;
+	struct cvmx_pko_pdm_isrd_dbg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_44_63               : 20;
+	uint64_t in_arb_reqs                  : 8;  /**< Input arbitration request signals. The order of the bits is:
+                                                         - 43: Fill response - normal path request
+                                                         - 42: Fill response - flushb path request
+                                                         - 41: CP queue-open request
+                                                         - 40: CP queue-closed request
+                                                         - 39: CP queue-query request
+                                                         - 38: CP send-packet request
+                                                         - 37: PEB fill request
+                                                         - 36: PEB read request */
+	uint64_t in_arb_gnts                  : 7;  /**< Input arbitration grant signals. The order of the bits is:
+                                                         - 35: Fill response grant
+                                                         - 34: CP - queue-open grant
+                                                         - 33: CP - queue-close grant
+                                                         - 32: CP - queue-query grant
+                                                         - 31: CP - send-packet grant
+                                                         - 30: PEB fill grant
+                                                         - 29: PEB read grant */
+	uint64_t cmt_arb_reqs                 : 7;  /**< Commit arbitration request signals. The order of the bits is:
+                                                         - 28: Fill response grant
+                                                         - 27: CP - queue-open grant
+                                                         - 26: CP - queue-close grant
+                                                         - 25: CP - queue-query grant
+                                                         - 24: CP - send-packet grant
+                                                         - 23: PEB fill grant
+                                                         - 22: PEB read grant */
+	uint64_t cmt_arb_gnts                 : 7;  /**< Commit arbitration grant signals. The order of the bits is:
+                                                         - 21: Fill response grant
+                                                         - 20: CP - queue-open grant
+                                                         - 19: CP - queue-close grant
+                                                         - 18: CP - queue-query grant
+                                                         - 17: CP - send-packet grant
+                                                         - 16: PEB fill grant
+                                                         - 15: PEB read grant */
+	uint64_t in_use                       : 4;  /**< In use signals indicate the execution units are in use. The order of the bits is:
+                                                         - 14: PEB fill unit
+                                                         - 13: PEB read unit
+                                                         - 12: CP unit
+                                                         - 11: Fill response unit */
+	uint64_t has_cred                     : 4;  /**< Has credit signals indicate there is sufficient credit to commit. The order of the bits
+                                                          is:
+                                                          - 10: Flush buffer has credit
+                                                         - 9: Fill buffer has credit
+                                                         - 8: DW command output FIFO has credit
+                                                         - 7: DR command output FIFO has credit */
+	uint64_t val_exec                     : 7;  /**< Valid bits for the execution units; means the unit can commit if it gets the grant of the
+                                                          commit arb and other conditions are met. The order of the bits is:
+                                                         - 6: Fill response unit
+                                                         - 5: CP unit - queue-open
+                                                         - 4: CP unit - queue-close
+                                                         - 3: CP unit - queue-probe
+                                                         - 2: CP unit - send-packet
+                                                         - 1: PEB fill unit
+                                                         - 0: PEB read unit */
+#else
+	uint64_t val_exec                     : 7;
+	uint64_t has_cred                     : 4;
+	uint64_t in_use                       : 4;
+	uint64_t cmt_arb_gnts                 : 7;
+	uint64_t cmt_arb_reqs                 : 7;
+	uint64_t in_arb_gnts                  : 7;
+	uint64_t in_arb_reqs                  : 8;
+	uint64_t reserved_44_63               : 20;
+#endif
+	} s;
+	struct cvmx_pko_pdm_isrd_dbg_s        cn78xx;
+};
+typedef union cvmx_pko_pdm_isrd_dbg cvmx_pko_pdm_isrd_dbg_t;
+
+/**
+ * cvmx_pko_pdm_isrd_dbg_dq
+ */
+union cvmx_pko_pdm_isrd_dbg_dq {
+	uint64_t u64;
+	struct cvmx_pko_pdm_isrd_dbg_dq_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_46_63               : 18;
+	uint64_t pebrd_sic_dq                 : 10; /**< CP SIC's DQ number. */
+	uint64_t reserved_34_35               : 2;
+	uint64_t pebfill_sic_dq               : 10; /**< CP SIC's DQ number. */
+	uint64_t reserved_22_23               : 2;
+	uint64_t fr_sic_dq                    : 10; /**< CP SIC's DQ number. */
+	uint64_t reserved_10_11               : 2;
+	uint64_t cp_sic_dq                    : 10; /**< CP SIC's DQ number. */
+#else
+	uint64_t cp_sic_dq                    : 10;
+	uint64_t reserved_10_11               : 2;
+	uint64_t fr_sic_dq                    : 10;
+	uint64_t reserved_22_23               : 2;
+	uint64_t pebfill_sic_dq               : 10;
+	uint64_t reserved_34_35               : 2;
+	uint64_t pebrd_sic_dq                 : 10;
+	uint64_t reserved_46_63               : 18;
+#endif
+	} s;
+	struct cvmx_pko_pdm_isrd_dbg_dq_s     cn78xx;
+};
+typedef union cvmx_pko_pdm_isrd_dbg_dq cvmx_pko_pdm_isrd_dbg_dq_t;
+
+/**
+ * cvmx_pko_pdm_isrm_dbg
+ */
+union cvmx_pko_pdm_isrm_dbg {
+	uint64_t u64;
+	struct cvmx_pko_pdm_isrm_dbg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_34_63               : 30;
+	uint64_t in_arb_reqs                  : 7;  /**< Input arbitration request signals. The order of the bits is:
+                                                         - 33: PSE ACK
+                                                         - 32: Fill Response - normal path request
+                                                         - 31: Fill Response - flushb path request
+                                                         - 30: CP queue-open
+                                                         - 29: CP queue-closed
+                                                         - 28: CP queue-query
+                                                         - 27: CP send-packet */
+	uint64_t in_arb_gnts                  : 6;  /**< Input arbitration grant signals. The order of the bits is:
+                                                         - 26: PSE ACK
+                                                         - 25: Fill Response
+                                                         - 24: CP - queue-open
+                                                         - 23: CP - queue-close
+                                                         - 22: CP - queue-query
+                                                         - 21: CP - send-packet */
+	uint64_t cmt_arb_reqs                 : 6;  /**< Commit arbitration request signals. The order of the bits is:
+                                                         - 20: PSE ACK
+                                                         - 19: Fill Response
+                                                         - 18: CP - queue-open
+                                                         - 17: CP - queue-close
+                                                         - 16: CP - queue-query
+                                                         - 15: CP - send-packet */
+	uint64_t cmt_arb_gnts                 : 6;  /**< Commit arbitration grant signals. The order of the bits is:
+                                                          - 14: PSE ACK
+                                                          - 13: Fill Response
+                                                          - 12: CP - queue-open
+                                                          - 11: CP - queue-close
+                                                          - 10: CP - queue-query
+                                                         - 9: CP - send-packet */
+	uint64_t in_use                       : 3;  /**< In use signals indicate the execution units are in use. The order of the bits is:
+                                                         - 8: (PSE) ACK unit
+                                                         - 7: Fill response unit
+                                                         - 6: CP unit */
+	uint64_t has_cred                     : 3;  /**< Has credit signals indicate there is sufficient credit to commit. The order of the bits
+                                                          is:
+                                                         - 5: Flush buffer has credit
+                                                         - 4: Fill buffer has credit
+                                                         - 3: MWP command output FIFO has credit */
+	uint64_t val_exec                     : 3;  /**< Valid bits for the execution units; means the unit can commit if it gets the grant of the
+                                                          commit arb and other conditions are met. The order of the bits is:
+                                                         - 2: (PSE) ACK unit
+                                                         - 1: Fill response unit
+                                                         - 0: CP unit - ALL */
+#else
+	uint64_t val_exec                     : 3;
+	uint64_t has_cred                     : 3;
+	uint64_t in_use                       : 3;
+	uint64_t cmt_arb_gnts                 : 6;
+	uint64_t cmt_arb_reqs                 : 6;
+	uint64_t in_arb_gnts                  : 6;
+	uint64_t in_arb_reqs                  : 7;
+	uint64_t reserved_34_63               : 30;
+#endif
+	} s;
+	struct cvmx_pko_pdm_isrm_dbg_s        cn78xx;
+};
+typedef union cvmx_pko_pdm_isrm_dbg cvmx_pko_pdm_isrm_dbg_t;
+
+/**
+ * cvmx_pko_pdm_isrm_dbg_dq
+ */
+union cvmx_pko_pdm_isrm_dbg_dq {
+	uint64_t u64;
+	struct cvmx_pko_pdm_isrm_dbg_dq_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_34_63               : 30;
+	uint64_t ack_sic_dq                   : 10; /**< CP SIC's DQ number. */
+	uint64_t reserved_22_23               : 2;
+	uint64_t fr_sic_dq                    : 10; /**< CP SIC's DQ number. */
+	uint64_t reserved_10_11               : 2;
+	uint64_t cp_sic_dq                    : 10; /**< CP SIC's DQ number. */
+#else
+	uint64_t cp_sic_dq                    : 10;
+	uint64_t reserved_10_11               : 2;
+	uint64_t fr_sic_dq                    : 10;
+	uint64_t reserved_22_23               : 2;
+	uint64_t ack_sic_dq                   : 10;
+	uint64_t reserved_34_63               : 30;
+#endif
+	} s;
+	struct cvmx_pko_pdm_isrm_dbg_dq_s     cn78xx;
+};
+typedef union cvmx_pko_pdm_isrm_dbg_dq cvmx_pko_pdm_isrm_dbg_dq_t;
+
+/**
  * cvmx_pko_pdm_mem_addr
  */
 union cvmx_pko_pdm_mem_addr {
@@ -7580,12 +9088,13 @@ union cvmx_pko_pdm_mem_addr {
 	struct cvmx_pko_pdm_mem_addr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t memsel                       : 3;  /**< Memory select. Selects the RAM to read or write to.
-                                                         0 = Invalid, 1 = ISRM states, 2 = ISRDstates, 3 = DWPBUF,
-                                                         4 = DRPBUF, 5 = MWPBUF */
+                                                         0 = Invalid, 1 = ISRM states, 2 = ISRD states, 3 = DWPBUF, 4 = DRPBUF, 5 = MWPBUF */
 	uint64_t reserved_17_60               : 44;
 	uint64_t memaddr                      : 14; /**< Memory address for the RAM. */
 	uint64_t reserved_2_2                 : 1;
-	uint64_t membanksel                   : 2;  /**< Memory bank select. Selects the bank to write to. */
+	uint64_t membanksel                   : 2;  /**< Memory bank select. Selects the bank to write to. Note that bit 0 is the only bit used in
+                                                         the PBUF's because there are only 2 banks per each PBUF. In the ISRM bank sel 3 is
+                                                         illegal. */
 #else
 	uint64_t membanksel                   : 2;
 	uint64_t reserved_2_2                 : 1;
@@ -7605,7 +9114,9 @@ union cvmx_pko_pdm_mem_data {
 	uint64_t u64;
 	struct cvmx_pko_pdm_mem_data_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t data                         : 64; /**< Raw data to write into the memory, or the raw data read out from the memory. */
+	uint64_t data                         : 64; /**< Raw data to write into the memory, or the raw data read out from the memory.
+                                                         Note that the ISR RAMs are only 57 bits wide, so [56:0] are the only bits that can be read
+                                                         or written to them. The PBUFs are 64 bits wide. */
 #else
 	uint64_t data                         : 64;
 #endif
@@ -7642,7 +9153,7 @@ union cvmx_pko_pdm_mem_rw_sts {
 	struct cvmx_pko_pdm_mem_rw_sts_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t readdone                     : 1;  /**< This will be set to 1 when the read is complete and the data is valid in the data register. */
+	uint64_t readdone                     : 1;  /**< This bit is set to 1 when the read is complete and the data is valid in the data register. */
 #else
 	uint64_t readdone                     : 1;
 	uint64_t reserved_1_63                : 63;
@@ -7653,28 +9164,41 @@ union cvmx_pko_pdm_mem_rw_sts {
 typedef union cvmx_pko_pdm_mem_rw_sts cvmx_pko_pdm_mem_rw_sts_t;
 
 /**
- * cvmx_pko_pdm_sendpkt_lmtxx_err
+ * cvmx_pko_pdm_mwpbuf_dbg
  */
-union cvmx_pko_pdm_sendpkt_lmtxx_err {
+union cvmx_pko_pdm_mwpbuf_dbg {
 	uint64_t u64;
-	struct cvmx_pko_pdm_sendpkt_lmtxx_err_s {
+	struct cvmx_pko_pdm_mwpbuf_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_4_63                : 60;
-	uint64_t lmtst_err_cond               : 2;  /**< Error condition for PKO_PDM_STS[SENDPKT_LMTST_ERR].
-                                                         if( ERR_COND == 2'b10 ) PKO_DQSTATUS_E::DQNOFPABUF
-                                                         else if( ERR_COND == 2'b01 ) PKO_DQSTATUS_E::DQNOTCREATED */
-	uint64_t lmtdma_err_cond              : 2;  /**< Error condition for PKO_PDM_STS[SENDPKT_LMTDMA_ERR].
-                                                         if( ERR_COND == 2'b10 ) PKO_DQSTATUS_E::DQNOFPABUF
-                                                         else if( ERR_COND == 2'b01 ) PKO_DQSTATUS_E::DQNOTCREATED */
-#else
-	uint64_t lmtdma_err_cond              : 2;
-	uint64_t lmtst_err_cond               : 2;
-	uint64_t reserved_4_63                : 60;
+	uint64_t reserved_43_63               : 21;
+	uint64_t sel_nxt_ptr                  : 1;  /**< Sel_nxt_ptr signal. */
+	uint64_t load_val                     : 1;  /**< Load valid signal. */
+	uint64_t rdy                          : 1;  /**< Ready signal. */
+	uint64_t cur_state                    : 3;  /**< Current state from the pbuf controller. */
+	uint64_t reserved_33_36               : 4;
+	uint64_t track_rd_cnt                 : 6;  /**< Track read count value. */
+	uint64_t track_wr_cnt                 : 6;  /**< Track write count value. */
+	uint64_t reserved_17_20               : 4;
+	uint64_t mem_addr                     : 13; /**< Memory address for pbuf ram. */
+	uint64_t mem_en                       : 4;  /**< Memory write/chip enable signals. The order of the bits is:
+                                                         - 3: low wen; 2: low cen; 1: high wen; 0: high cen. */
+#else
+	uint64_t mem_en                       : 4;
+	uint64_t mem_addr                     : 13;
+	uint64_t reserved_17_20               : 4;
+	uint64_t track_wr_cnt                 : 6;
+	uint64_t track_rd_cnt                 : 6;
+	uint64_t reserved_33_36               : 4;
+	uint64_t cur_state                    : 3;
+	uint64_t rdy                          : 1;
+	uint64_t load_val                     : 1;
+	uint64_t sel_nxt_ptr                  : 1;
+	uint64_t reserved_43_63               : 21;
 #endif
 	} s;
-	struct cvmx_pko_pdm_sendpkt_lmtxx_err_s cn78xx;
+	struct cvmx_pko_pdm_mwpbuf_dbg_s      cn78xx;
 };
-typedef union cvmx_pko_pdm_sendpkt_lmtxx_err cvmx_pko_pdm_sendpkt_lmtxx_err_t;
+typedef union cvmx_pko_pdm_mwpbuf_dbg cvmx_pko_pdm_mwpbuf_dbg_t;
 
 /**
  * cvmx_pko_pdm_sts
@@ -7683,25 +9207,87 @@ union cvmx_pko_pdm_sts {
 	uint64_t u64;
 	struct cvmx_pko_pdm_sts_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_6_63                : 58;
-	uint64_t sendpkt_lmtdma_err           : 1;  /**< recieved signal that FPA cannot allocate pointer. Throws
+	uint64_t reserved_38_63               : 26;
+	uint64_t cp_stalled_thrshld_hit       : 1;  /**< This register is set to 1 if the PDM stalls the inputs for more than
+                                                         PKO_PDM_CFG_DBG[CP_STALL_THRSHLD]. INTERNAL: Do not list field in HRM. For lab debug only;
+                                                         will likely disapear in pass 2. */
+	uint64_t reserved_35_36               : 2;
+	uint64_t mwpbuf_data_val_err          : 1;  /**< Received signal that MWPBUF had data valid error. Throws
+                                                         PKO_INTSN_E::PKO_MWPBUF_DATA_VAL_ERR. */
+	uint64_t drpbuf_data_val_err          : 1;  /**< Received signal that DRPBUF had data valid error. Throws
+                                                         PKO_INTSN_E::PKO_DRPBUF_DATA_VAL_ERR. */
+	uint64_t dwpbuf_data_val_err          : 1;  /**< Received signal that DWPBUF had data valid error. Throws
+                                                         PKO_INTSN_E::PKO_DWPBUF_DATA_VAL_ERR. */
+	uint64_t reserved_30_31               : 2;
+	uint64_t qcmd_iobx_err_sts            : 4;  /**< When PKO_PDM_STS[QCMD_IOBX_ERR] is set, this contains the queue command response's status
+                                                         field for the response causing the error. Note that if multiple errors occur, only the
+                                                         first error status is captured here until PKO_PDM_STS[QCMD_IOBX_ERR] is cleared.
+                                                         Enumerated by PKO_DQSTATUS_E. */
+	uint64_t qcmd_iobx_err                : 1;  /**< Queue command IOBDMA/IOBLD error status occurred in PKO/PDM.
+                                                         PKO_PDM_STS[QCMD_IOBX_ERR_STS] contains the status code. Note that FPA being out of
+                                                         pointers does not set this bit. (See PKO_FPA_NO_PTRS). Throws
+                                                         PKO_INTSN_E::PKO_QCMD_IOBX_ERR. */
+	uint64_t sendpkt_lmtdma_err_sts       : 4;  /**< Status field of the command response on the LMTDMA failure indicated by
+                                                         PKO_PDM_STS[SENDPKT_LMTDMA_ERR] bits being asserted. Note that if multiple errors occur,
+                                                         only the first error status is captured here until PKO_PDM_STS[SENDPKT_LMTDMA_ERR] is
+                                                         cleared. Enumerated by PKO_DQSTATUS_E. */
+	uint64_t sendpkt_lmtdma_err           : 1;  /**< Send-packet of type LMTDMA error status occurred in PKO/PDM.
+                                                         PKO_PDM_STS[SENDPKT_LMTDMA_ERR_STS] contains the status code. Note that FPA being out of
+                                                         pointers does not set this bit. (See PKO_FPA_NO_PTRS). Throws
                                                          PKO_INTSN_E::PKO_SENDPKT_LMTDMA_ERR. */
-	uint64_t sendpkt_lmtst_err            : 1;  /**< recieved signal that FPA cannot allocate pointer. Throws
+	uint64_t sendpkt_lmtst_err_sts        : 4;  /**< Status field of the command response on the LMTST failure indicated by
+                                                         PKO_PDM_STS[SENDPKT_LMTST_ERR] bits being asserted.
+                                                         Note that if multiple errors occur only the first error status will be captured here until
+                                                         PKO_PDM_STS[SENDPKT_LMTST_ERR] is cleared.
+                                                         Enumerated by PKO_DQSTATUS_E. */
+	uint64_t sendpkt_lmtst_err            : 1;  /**< Send-packet of type LMTST error status occurred in PKO/PDM.
+                                                         PKO_PDM_STS[SENDPKT_LMTST_ERR_STS] contains the status code. Note that FPA being out of
+                                                         pointers does not set this bit. (See PKO_FPA_NO_PTRS). Throws
                                                          PKO_INTSN_E::PKO_SENDPKT_LMTST_ERR. */
-	uint64_t fpa_no_ptrs                  : 1;  /**< recieved signal that FPA cannot allocate pointer. Throws PKO_INTSN_E::PKO_FPA_NO_PTRS. */
-	uint64_t cp_sendpkt_err_no_drp        : 1;  /**< We did not drop a send-packet, but it appears to violate rules. (1. send jump not at end
-                                                         of descriptor). Throws PKO_INTSN_E::PKO_CP_SENDPKT_ERR_NO_DRP. */
-	uint64_t cp_pkt_drp                   : 1;  /**< Dropped a packet in PDM/CP due to rule violation. Throws PKO_INTSN_E::PKO_CP_ERR_PKT_DROP. */
-	uint64_t desc_crc_err                 : 1;  /**< CRC error occurred in a descriptor. (State may have been corrupted). Throws
-                                                         PKO_INTSN_E::PKO_DESC_CRC_ERR. */
+	uint64_t fpa_no_ptrs                  : 1;  /**< FPA signalled PKO that FPA can not allocate pointers. This is a fatal error.
+                                                         Throws PKO_INTSN_E::PKO_FPA_NO_PTRS. */
+	uint64_t reserved_12_13               : 2;
+	uint64_t cp_sendpkt_err_no_drp_code   : 2;  /**< This field stores the error code for illegally constructed send-packets that did not drop.
+                                                         Note that if multiple errors occur, only the first error code is captured here until
+                                                         PKO_PDM_STS[CP_SENDPKT_ERR_NO_DRP] is cleared. Codes:
+                                                         2'b00: NO ERROR CODE
+                                                         2'b01: SEND_JUMP not at end of descriptor. */
+	uint64_t cp_sendpkt_err_no_drp        : 1;  /**< PKO/PDM/CP did not drop a send-packet; however, the SEND_JUMP command is not at end of the
+                                                         descriptor. The error code is captured in PKO_PDM_STS[CP_SENDPKT_ERR_NO_DRP_CODE]. Throws
+                                                         PKO_INTSN_E::PKO_CP_SENDPKT_ERR_NO_DRP. */
+	uint64_t reserved_7_8                 : 2;
+	uint64_t cp_sendpkt_err_drop_code     : 3;  /**< This field stores the error code for illegally constructed send-packet drops. Note that if
+                                                         multiple errors occur, only the first error code is captured here until
+                                                         PKO_PDM_STS[CP_SENDPKT_ERR_DROP] is cleared. PKO_CPSENDDROP_E enumerates the codes and
+                                                         conditions. */
+	uint64_t cp_sendpkt_err_drop          : 1;  /**< Dropped a send-packet in PDM/CP due to a rule violation. The error code is captured in
+                                                         PKO_PDM_STS[CP_SENDPKT_ERR_DROP_CODE]. Throws PKO_INTSN_E::PKO_CP_SENDPKT_ERR_DROP. */
+	uint64_t reserved_1_2                 : 2;
+	uint64_t desc_crc_err                 : 1;  /**< CRC error occurred in a descriptor. (State may have been corrupted.) INTERNAL: Note that
+                                                         this is a pass 2 feature. Throws PKO_INTSN_E::PKO_DESC_CRC_ERR. */
 #else
 	uint64_t desc_crc_err                 : 1;
-	uint64_t cp_pkt_drp                   : 1;
+	uint64_t reserved_1_2                 : 2;
+	uint64_t cp_sendpkt_err_drop          : 1;
+	uint64_t cp_sendpkt_err_drop_code     : 3;
+	uint64_t reserved_7_8                 : 2;
 	uint64_t cp_sendpkt_err_no_drp        : 1;
+	uint64_t cp_sendpkt_err_no_drp_code   : 2;
+	uint64_t reserved_12_13               : 2;
 	uint64_t fpa_no_ptrs                  : 1;
 	uint64_t sendpkt_lmtst_err            : 1;
+	uint64_t sendpkt_lmtst_err_sts        : 4;
 	uint64_t sendpkt_lmtdma_err           : 1;
-	uint64_t reserved_6_63                : 58;
+	uint64_t sendpkt_lmtdma_err_sts       : 4;
+	uint64_t qcmd_iobx_err                : 1;
+	uint64_t qcmd_iobx_err_sts            : 4;
+	uint64_t reserved_30_31               : 2;
+	uint64_t dwpbuf_data_val_err          : 1;
+	uint64_t drpbuf_data_val_err          : 1;
+	uint64_t mwpbuf_data_val_err          : 1;
+	uint64_t reserved_35_36               : 2;
+	uint64_t cp_stalled_thrshld_hit       : 1;
+	uint64_t reserved_38_63               : 26;
 #endif
 	} s;
 	struct cvmx_pko_pdm_sts_s             cn78xx;
@@ -7709,6 +9295,77 @@ union cvmx_pko_pdm_sts {
 typedef union cvmx_pko_pdm_sts cvmx_pko_pdm_sts_t;
 
 /**
+ * cvmx_pko_peb_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_peb_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_peb_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_26_63               : 38;
+	uint64_t add_work_fifo                : 1;  /**< ADD_WORK_FIFO RAM BIST status. */
+	uint64_t pdm_pse_buf_ram              : 1;  /**< PDM_PSE_BUF RAM BIST status. */
+	uint64_t iobp0_fifo_ram               : 1;  /**< IOBP0_FIFO RAM BIST status. */
+	uint64_t iobp1_fifo_ram               : 1;  /**< IOBP1_FIFO RAM BIST status. */
+	uint64_t state_mem0                   : 1;  /**< STATE_MEM0 RAM BIST status. */
+	uint64_t state_mem1                   : 1;  /**< STATE_MEM1 RAM BIST status. */
+	uint64_t state_mem2                   : 1;  /**< STATE_MEM2 RAM BIST status. */
+	uint64_t state_mem3                   : 1;  /**< STATE_MEM3 RAM BIST status. */
+	uint64_t iobp1_uid_fifo_ram           : 1;  /**< IOBP1_UID_FIFO RAM BIST status. */
+	uint64_t nxt_link_ptr_ram             : 1;  /**< NXT_LINK_PTR RAM BIST status. */
+	uint64_t pd_bank0_ram                 : 1;  /**< PD_BANK0 RAM BIST status. */
+	uint64_t pd_bank1_ram                 : 1;  /**< PD_BANK1 RAM BIST status. */
+	uint64_t pd_bank2_ram                 : 1;  /**< PD_BANK2 RAM BIST status. */
+	uint64_t pd_bank3_ram                 : 1;  /**< PD_BANK3 RAM BIST status. */
+	uint64_t pd_var_bank_ram              : 1;  /**< PD_VAR_BANK RAM BIST status. */
+	uint64_t pdm_resp_buf_ram             : 1;  /**< PDM_RESP_BUF RAM BIST status. */
+	uint64_t tx_fifo_pkt_ram              : 1;  /**< TX_FIFO_PKT RAM BIST status. */
+	uint64_t tx_fifo_hdr_ram              : 1;  /**< TX_FIFO_HDR RAM BIST status. */
+	uint64_t tx_fifo_crc_ram              : 1;  /**< TX_FIFO_CRC RAM BIST status. */
+	uint64_t ts_addwork_ram               : 1;  /**< TS_ADDWORK RAM BIST status. */
+	uint64_t send_mem_ts_fifo             : 1;  /**< SEND_MEM_TS_FIFO RAM BIST status. */
+	uint64_t send_mem_stdn_fifo           : 1;  /**< SEND_MEM_STDN_FIFO RAM BIST status. */
+	uint64_t send_mem_fifo                : 1;  /**< SEND_MEM_FIFO RAM BIST status. */
+	uint64_t pkt_mrk_ram                  : 1;  /**< PKT_MRK RAM BIST status. */
+	uint64_t peb_st_inf_ram               : 1;  /**< PEB_ST_INF RAM BIST status. */
+	uint64_t peb_sm_jmp_ram               : 1;  /**< PEB_SM_JMP RAM BIST status. */
+#else
+	uint64_t peb_sm_jmp_ram               : 1;
+	uint64_t peb_st_inf_ram               : 1;
+	uint64_t pkt_mrk_ram                  : 1;
+	uint64_t send_mem_fifo                : 1;
+	uint64_t send_mem_stdn_fifo           : 1;
+	uint64_t send_mem_ts_fifo             : 1;
+	uint64_t ts_addwork_ram               : 1;
+	uint64_t tx_fifo_crc_ram              : 1;
+	uint64_t tx_fifo_hdr_ram              : 1;
+	uint64_t tx_fifo_pkt_ram              : 1;
+	uint64_t pdm_resp_buf_ram             : 1;
+	uint64_t pd_var_bank_ram              : 1;
+	uint64_t pd_bank3_ram                 : 1;
+	uint64_t pd_bank2_ram                 : 1;
+	uint64_t pd_bank1_ram                 : 1;
+	uint64_t pd_bank0_ram                 : 1;
+	uint64_t nxt_link_ptr_ram             : 1;
+	uint64_t iobp1_uid_fifo_ram           : 1;
+	uint64_t state_mem3                   : 1;
+	uint64_t state_mem2                   : 1;
+	uint64_t state_mem1                   : 1;
+	uint64_t state_mem0                   : 1;
+	uint64_t iobp1_fifo_ram               : 1;
+	uint64_t iobp0_fifo_ram               : 1;
+	uint64_t pdm_pse_buf_ram              : 1;
+	uint64_t add_work_fifo                : 1;
+	uint64_t reserved_26_63               : 38;
+#endif
+	} s;
+	struct cvmx_pko_peb_bist_status_s     cn78xx;
+};
+typedef union cvmx_pko_peb_bist_status cvmx_pko_peb_bist_status_t;
+
+/**
  * cvmx_pko_peb_ecc_ctl0
  */
 union cvmx_pko_peb_ecc_ctl0 {
@@ -7835,28 +9492,72 @@ union cvmx_pko_peb_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_peb_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t iobp1_uid_fifo_ram_dbe       : 1;  /**< Double-bit error for IOBP1_UID_FIFO_RAM. */
-	uint64_t iobp0_fifo_ram_dbe           : 1;  /**< Double-bit error for IOBP0_FIFO_RAM. */
-	uint64_t iobp1_fifo_ram_dbe           : 1;  /**< Double-bit error for IOBP1_FIFO_RAM. */
-	uint64_t pdm_resp_buf_ram_dbe         : 1;  /**< Double-bit error for PDM_RESP_BUF_RAM. */
-	uint64_t pdm_pse_buf_ram_dbe          : 1;  /**< Double-bit error for PDM_PSE_BUF_RAM. */
-	uint64_t peb_sm_jmp_ram_dbe           : 1;  /**< Double-bit error for PEB_SM_JMP_RAM. */
-	uint64_t peb_st_inf_ram_dbe           : 1;  /**< Double-bit error for PEB_ST_INF_RAM. */
-	uint64_t pd_bank3_ram_dbe             : 1;  /**< Double-bit error for PD_BANK3_RAM. */
-	uint64_t pd_bank2_ram_dbe             : 1;  /**< Double-bit error for PD_BANK2_RAM. */
-	uint64_t pd_bank1_ram_dbe             : 1;  /**< Double-bit error for PD_BANK1_RAM. */
-	uint64_t pd_bank0_ram_dbe             : 1;  /**< Double-bit error for PD_BANK0_RAM. */
-	uint64_t pd_var_bank_ram_dbe          : 1;  /**< Double-bit error for PD_VAR_BANK_RAM. */
-	uint64_t tx_fifo_crc_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_CRC_RAM. */
-	uint64_t tx_fifo_hdr_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_HDR_RAM. */
-	uint64_t tx_fifo_pkt_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_PKT_RAM. */
-	uint64_t add_work_fifo_dbe            : 1;  /**< Double-bit error for ADD_WORK_FIFO. */
-	uint64_t send_mem_fifo_dbe            : 1;  /**< Double-bit error for SEND_MEM_FIFO. */
-	uint64_t send_mem_stdn_fifo_dbe       : 1;  /**< Double-bit error for SEND_MEM_STDN_FIFO. */
-	uint64_t send_mem_ts_fifo_dbe         : 1;  /**< Double-bit error for SEND_MEM_TS_FIFO. */
-	uint64_t nxt_link_ptr_ram_dbe         : 1;  /**< Double-bit error for NXT_LINK_PTR_RAM. */
-	uint64_t pkt_mrk_ram_dbe              : 1;  /**< Double-bit error for PKT_MRK_RAM. */
-	uint64_t ts_addwork_ram_dbe           : 1;  /**< Double-bit error for TS_ADDWORK_RAM. */
+	uint64_t iobp1_uid_fifo_ram_dbe       : 1;  /**< Double-bit error for IOBP1_UID_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_uid_fifo_i */
+	uint64_t iobp0_fifo_ram_dbe           : 1;  /**< Double-bit error for IOBP0_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_iobp0_fifo_i */
+	uint64_t iobp1_fifo_ram_dbe           : 1;  /**< Double-bit error for IOBP1_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i */
+	uint64_t pdm_resp_buf_ram_dbe         : 1;  /**< Double-bit error for PDM_RESP_BUF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i */
+	uint64_t pdm_pse_buf_ram_dbe          : 1;  /**< Double-bit error for PDM_PSE_BUF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i */
+	uint64_t peb_sm_jmp_ram_dbe           : 1;  /**< Double-bit error for PEB_SM_JMP_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i */
+	uint64_t peb_st_inf_ram_dbe           : 1;  /**< Double-bit error for PEB_ST_INF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i */
+	uint64_t pd_bank3_ram_dbe             : 1;  /**< Double-bit error for PD_BANK3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank3_i */
+	uint64_t pd_bank2_ram_dbe             : 1;  /**< Double-bit error for PD_BANK2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank2_i */
+	uint64_t pd_bank1_ram_dbe             : 1;  /**< Double-bit error for PD_BANK1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank1_i */
+	uint64_t pd_bank0_ram_dbe             : 1;  /**< Double-bit error for PD_BANK0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank0_i */
+	uint64_t pd_var_bank_ram_dbe          : 1;  /**< Double-bit error for PD_VAR_BANK_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_var_mem_bank_i */
+	uint64_t tx_fifo_crc_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_CRC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_crc_i */
+	uint64_t tx_fifo_hdr_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_HDR_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_hdr_i */
+	uint64_t tx_fifo_pkt_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_PKT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_pkt_i */
+	uint64_t add_work_fifo_dbe            : 1;  /**< Double-bit error for ADD_WORK_FIFO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_add_work_fifo_i */
+	uint64_t send_mem_fifo_dbe            : 1;  /**< Double-bit error for SEND_MEM_FIFO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_fifo_i */
+	uint64_t send_mem_stdn_fifo_dbe       : 1;  /**< Double-bit error for SEND_MEM_STDN_FIFO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_stdn_fifo_i */
+	uint64_t send_mem_ts_fifo_dbe         : 1;  /**< Double-bit error for SEND_MEM_TS_FIFO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_ts_fifo_i */
+	uint64_t nxt_link_ptr_ram_dbe         : 1;  /**< Double-bit error for NXT_LINK_PTR_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_nxt_link_ptr_mem_i */
+	uint64_t pkt_mrk_ram_dbe              : 1;  /**< Double-bit error for PKT_MRK_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pkt_mrk_mem_i */
+	uint64_t ts_addwork_ram_dbe           : 1;  /**< Double-bit error for TS_ADDWORK_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_ts_addwork_mem_i */
 	uint64_t reserved_0_41                : 42;
 #else
 	uint64_t reserved_0_41                : 42;
@@ -7895,7 +9596,33 @@ union cvmx_pko_peb_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_peb_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t peb_dbe_cmb0                 : 1;  /**< Double-bit error for IOBP1_UID_FIFO_RAM. Throws PKO_INTSN_E::PKO_PEB_DBE_CMB0. */
+	uint64_t peb_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PEB_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PEB_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PEB_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_uid_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_iobp0_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank3_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank0_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank1_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank2_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_var_mem_bank_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_crc_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_hdr_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_pkt_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_add_work_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_stdn_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_ts_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_nxt_link_ptr_mem_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pkt_mrk_mem_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_ts_addwork_mem_i */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -7913,28 +9640,72 @@ union cvmx_pko_peb_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_peb_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t iobp1_uid_fifo_ram_sbe       : 1;  /**< Single-bit error for IOBP1_UID_FIFO_RAM. */
-	uint64_t iobp0_fifo_ram_sbe           : 1;  /**< Single-bit error for IOBP0_FIFO_RAM. */
-	uint64_t iobp1_fifo_ram_sbe           : 1;  /**< Single-bit error for IOBP1_FIFO_RAM. */
-	uint64_t pdm_resp_buf_ram_sbe         : 1;  /**< Single-bit error for PDM_RESP_BUF_RAM. */
-	uint64_t pdm_pse_buf_ram_sbe          : 1;  /**< Single-bit error for PDM_PSE_BUF_RAM. */
-	uint64_t peb_sm_jmp_ram_sbe           : 1;  /**< Single-bit error for PEB_SM_JMP_RAM. */
-	uint64_t peb_st_inf_ram_sbe           : 1;  /**< Single-bit error for PEB_ST_INF_RAM. */
-	uint64_t pd_bank3_ram_sbe             : 1;  /**< Single-bit error for PD_BANK3_RAM. */
-	uint64_t pd_bank2_ram_sbe             : 1;  /**< Single-bit error for PD_BANK2_RAM. */
-	uint64_t pd_bank1_ram_sbe             : 1;  /**< Single-bit error for PD_BANK1_RAM. */
-	uint64_t pd_bank0_ram_sbe             : 1;  /**< Single-bit error for PD_BANK0_RAM. */
-	uint64_t pd_var_bank_ram_sbe          : 1;  /**< Single-bit error for PD_VAR_BANK_RAM. */
-	uint64_t tx_fifo_crc_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_CRC_RAM. */
-	uint64_t tx_fifo_hdr_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_HDR_RAM. */
-	uint64_t tx_fifo_pkt_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_PKT_RAM. */
-	uint64_t add_work_fifo_sbe            : 1;  /**< Single-bit error for ADD_WORK_FIFO. */
-	uint64_t send_mem_fifo_sbe            : 1;  /**< Single-bit error for SEND_MEM_FIFO. */
-	uint64_t send_mem_stdn_fifo_sbe       : 1;  /**< Single-bit error for SEND_MEM_STDN_FIFO. */
-	uint64_t send_mem_ts_fifo_sbe         : 1;  /**< Single-bit error for SEND_MEM_TS_FIFO. */
-	uint64_t nxt_link_ptr_ram_sbe         : 1;  /**< Single-bit error for NXT_LINK_PTR_RAM. */
-	uint64_t pkt_mrk_ram_sbe              : 1;  /**< Single-bit error for PKT_MRK_RAM. */
-	uint64_t ts_addwork_ram_sbe           : 1;  /**< Single-bit error for TS_ADDWORK_RAM. */
+	uint64_t iobp1_uid_fifo_ram_sbe       : 1;  /**< Single-bit error for IOBP1_UID_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_uid_fifo_i */
+	uint64_t iobp0_fifo_ram_sbe           : 1;  /**< Single-bit error for IOBP0_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_iobp0_fifo_i */
+	uint64_t iobp1_fifo_ram_sbe           : 1;  /**< Single-bit error for IOBP1_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i */
+	uint64_t pdm_resp_buf_ram_sbe         : 1;  /**< Single-bit error for PDM_RESP_BUF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i */
+	uint64_t pdm_pse_buf_ram_sbe          : 1;  /**< Single-bit error for PDM_PSE_BUF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i */
+	uint64_t peb_sm_jmp_ram_sbe           : 1;  /**< Single-bit error for PEB_SM_JMP_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i */
+	uint64_t peb_st_inf_ram_sbe           : 1;  /**< Single-bit error for PEB_ST_INF_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i */
+	uint64_t pd_bank3_ram_sbe             : 1;  /**< Single-bit error for PD_BANK3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank3_i */
+	uint64_t pd_bank2_ram_sbe             : 1;  /**< Single-bit error for PD_BANK2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank2_i */
+	uint64_t pd_bank1_ram_sbe             : 1;  /**< Single-bit error for PD_BANK1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank1_i */
+	uint64_t pd_bank0_ram_sbe             : 1;  /**< Single-bit error for PD_BANK1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank0_i */
+	uint64_t pd_var_bank_ram_sbe          : 1;  /**< Single-bit error for PD_VAR_BANK_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_var_mem_bank_i */
+	uint64_t tx_fifo_crc_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_CRC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_crc_i */
+	uint64_t tx_fifo_hdr_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_HDR_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_hdr_i */
+	uint64_t tx_fifo_pkt_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_PKT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_pkt_i */
+	uint64_t add_work_fifo_sbe            : 1;  /**< Single-bit error for ADD_WORK_FIFO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_add_work_fifo_i */
+	uint64_t send_mem_fifo_sbe            : 1;  /**< Single-bit error for SEND_MEM_FIFO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_fifo_i */
+	uint64_t send_mem_stdn_fifo_sbe       : 1;  /**< Single-bit error for SEND_MEM_STDN_FIFO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_stdn_fifo_i */
+	uint64_t send_mem_ts_fifo_sbe         : 1;  /**< Single-bit error for SEND_MEM_TS_FIFO.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_ts_fifo_i */
+	uint64_t nxt_link_ptr_ram_sbe         : 1;  /**< Single-bit error for NXT_LINK_PTR_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_nxt_link_ptr_mem_i */
+	uint64_t pkt_mrk_ram_sbe              : 1;  /**< Single-bit error for PKT_MRK_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pkt_mrk_mem_i */
+	uint64_t ts_addwork_ram_sbe           : 1;  /**< Single-bit error for TS_ADDWORK_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_ts_addwork_mem_i */
 	uint64_t reserved_0_41                : 42;
 #else
 	uint64_t reserved_0_41                : 42;
@@ -7973,7 +9744,33 @@ union cvmx_pko_peb_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_peb_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t peb_sbe_cmb0                 : 1;  /**< Single-bit error for IOBP1_UID_FIFO_RAM. Throws PKO_INTSN_E::PKO_PEB_SBE_CMB0. */
+	uint64_t peb_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PEB_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PEB_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PEB_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_uid_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_iobp0_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank3_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank0_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank1_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank2_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_var_mem_bank_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_crc_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_hdr_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_pkt_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_add_work_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_stdn_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_ts_fifo_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_nxt_link_ptr_mem_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pkt_mrk_mem_i
+                                                         pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_ts_addwork_mem_i */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -7992,8 +9789,8 @@ union cvmx_pko_peb_err_int {
 	struct cvmx_pko_peb_err_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
-	uint64_t peb_macx_cfg_wr_err          : 1;  /**< Asserted when SW writes a FIFO number to PKO_MACx_CFG when that FIFO is already assigned.
-                                                         Throws PKO_INTSN_E::PEB_MACX_CFG_WR_ERR. */
+	uint64_t peb_macx_cfg_wr_err          : 1;  /**< Asserted when software writes a FIFO number to PKO_MACx_CFG when that FIFO is already
+                                                         assigned. Throws PKO_INTSN_E::PEB_MACX_CFG_WR_ERR. */
 	uint64_t peb_max_link_err             : 1;  /**< Asserted when 200 LINK segments have been followed.  Indicates likelihood of infinite
                                                          loop.  Throws PKO_INTSN_E::PEB_MAX_LINK_ERR. */
 	uint64_t peb_subd_size_err            : 1;  /**< Asserted when a SEND_LINK/GATHER/IMM/JUMP subD has size=0.  Throws
@@ -8003,11 +9800,11 @@ union cvmx_pko_peb_err_int {
 	uint64_t peb_trunc_err                : 1;  /**< Asserted when a PD has truncated data.  Throws PKO_INTSN_E::PEB_TRUNC_ERR. */
 	uint64_t peb_pad_err                  : 1;  /**< Asserted when a PD has data padded to it (SEND_HDR[TOTAL] < sum(SEND_DATA[size])).  Throws
                                                          PKO_INTSN_E::PEB_PAD_ERR. */
-	uint64_t peb_pse_fifo_cfg_err         : 1;  /**< Asserted when PSE sends PD information for a non-configured FIFO.  Throws
-                                                         PKO_INTSN_E::PEB_PSE_FIFO_CFG_ERR. */
+	uint64_t peb_pse_fifo_err             : 1;  /**< Asserted when PSE sends PD information for a nonconfigured FIFO. Throws
+                                                         PKO_INTSN_E::PEB_PSE_FIFO_ERR. */
 	uint64_t peb_fcs_sop_err              : 1;  /**< Asserted when FCS SOP value greater than packet size detected.  Throws
                                                          PKO_INTSN_E::PEB_FCS_SOP_ERR. */
-	uint64_t peb_jump_def_err             : 1;  /**< Asserted when JUMP sub-descriptor is not last in a PD.  Throws
+	uint64_t peb_jump_def_err             : 1;  /**< Asserted when JUMP subdescriptor is not last in a PD. Throws
                                                          PKO_INTSN_E::PEB_JUMP_DEF_ERR. */
 	uint64_t peb_ext_hdr_def_err          : 1;  /**< Asserted when EXT_HDR is not the second sub-descriptor in a PD.  Throws
                                                          PKO_INTSN_E::PEB_EXT_HDR_DEF_ERR. */
@@ -8015,7 +9812,7 @@ union cvmx_pko_peb_err_int {
 	uint64_t peb_ext_hdr_def_err          : 1;
 	uint64_t peb_jump_def_err             : 1;
 	uint64_t peb_fcs_sop_err              : 1;
-	uint64_t peb_pse_fifo_cfg_err         : 1;
+	uint64_t peb_pse_fifo_err             : 1;
 	uint64_t peb_pad_err                  : 1;
 	uint64_t peb_trunc_err                : 1;
 	uint64_t peb_subd_addr_err            : 1;
@@ -8030,174 +9827,345 @@ union cvmx_pko_peb_err_int {
 typedef union cvmx_pko_peb_err_int cvmx_pko_peb_err_int_t;
 
 /**
- * cvmx_pko_pq#_dropped_bytes
+ * cvmx_pko_peb_ext_hdr_def_err_info
  */
-union cvmx_pko_pqx_dropped_bytes {
+union cvmx_pko_peb_ext_hdr_def_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_dropped_bytes_s {
+	struct cvmx_pko_peb_ext_hdr_def_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_EXT_HDR_DEF_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_EXT_HDR_DEF_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_EXT_HDR_DEF_ERR. */
 #else
-	uint64_t count                        : 48;
-	uint64_t reserved_48_63               : 16;
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
-	struct cvmx_pko_pqx_dropped_bytes_s   cn78xx;
+	struct cvmx_pko_peb_ext_hdr_def_err_info_s cn78xx;
 };
-typedef union cvmx_pko_pqx_dropped_bytes cvmx_pko_pqx_dropped_bytes_t;
+typedef union cvmx_pko_peb_ext_hdr_def_err_info cvmx_pko_peb_ext_hdr_def_err_info_t;
 
 /**
- * cvmx_pko_pq#_dropped_packets
+ * cvmx_pko_peb_fcs_sop_err_info
  */
-union cvmx_pko_pqx_dropped_packets {
+union cvmx_pko_peb_fcs_sop_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_dropped_packets_s {
+	struct cvmx_pko_peb_fcs_sop_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_40_63               : 24;
-	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_FCS_SOP_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_FCS_SOP_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_FCS_SOP_ERR. */
 #else
-	uint64_t count                        : 40;
-	uint64_t reserved_40_63               : 24;
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
-	struct cvmx_pko_pqx_dropped_packets_s cn78xx;
+	struct cvmx_pko_peb_fcs_sop_err_info_s cn78xx;
 };
-typedef union cvmx_pko_pqx_dropped_packets cvmx_pko_pqx_dropped_packets_t;
+typedef union cvmx_pko_peb_fcs_sop_err_info cvmx_pko_peb_fcs_sop_err_info_t;
 
 /**
- * cvmx_pko_pq#_green_sent_bytes
+ * cvmx_pko_peb_jump_def_err_info
  */
-union cvmx_pko_pqx_green_sent_bytes {
+union cvmx_pko_peb_jump_def_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_green_sent_bytes_s {
+	struct cvmx_pko_peb_jump_def_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_JUMP_DEF_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_JUMP_DEF_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_JUMP_DEF_ERR. */
 #else
-	uint64_t count                        : 48;
-	uint64_t reserved_48_63               : 16;
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
-	struct cvmx_pko_pqx_green_sent_bytes_s cn78xx;
+	struct cvmx_pko_peb_jump_def_err_info_s cn78xx;
 };
-typedef union cvmx_pko_pqx_green_sent_bytes cvmx_pko_pqx_green_sent_bytes_t;
+typedef union cvmx_pko_peb_jump_def_err_info cvmx_pko_peb_jump_def_err_info_t;
 
 /**
- * cvmx_pko_pq#_green_sent_packets
+ * cvmx_pko_peb_macx_cfg_wr_err_info
  */
-union cvmx_pko_pqx_green_sent_packets {
+union cvmx_pko_peb_macx_cfg_wr_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_green_sent_packets_s {
+	struct cvmx_pko_peb_macx_cfg_wr_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_40_63               : 24;
-	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+	uint64_t reserved_8_63                : 56;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_MACX_CFG_WR_ERR] is set. */
+	uint64_t mac                          : 7;  /**< MAC number associated with the captured PEB_MACX_CFG_WR_ERR. */
 #else
-	uint64_t count                        : 40;
-	uint64_t reserved_40_63               : 24;
+	uint64_t mac                          : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_8_63                : 56;
 #endif
 	} s;
-	struct cvmx_pko_pqx_green_sent_packets_s cn78xx;
+	struct cvmx_pko_peb_macx_cfg_wr_err_info_s cn78xx;
 };
-typedef union cvmx_pko_pqx_green_sent_packets cvmx_pko_pqx_green_sent_packets_t;
+typedef union cvmx_pko_peb_macx_cfg_wr_err_info cvmx_pko_peb_macx_cfg_wr_err_info_t;
 
 /**
- * cvmx_pko_pq#_red_sent_bytes
+ * cvmx_pko_peb_max_link_err_info
  */
-union cvmx_pko_pqx_red_sent_bytes {
+union cvmx_pko_peb_max_link_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_red_sent_bytes_s {
+	struct cvmx_pko_peb_max_link_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_MAX_LINK_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_MAX_LINK_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_MAX_LINK_ERR. */
 #else
-	uint64_t count                        : 48;
-	uint64_t reserved_48_63               : 16;
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
-	struct cvmx_pko_pqx_red_sent_bytes_s  cn78xx;
+	struct cvmx_pko_peb_max_link_err_info_s cn78xx;
 };
-typedef union cvmx_pko_pqx_red_sent_bytes cvmx_pko_pqx_red_sent_bytes_t;
+typedef union cvmx_pko_peb_max_link_err_info cvmx_pko_peb_max_link_err_info_t;
 
 /**
- * cvmx_pko_pq#_red_sent_packets
+ * cvmx_pko_peb_pad_err_info
  */
-union cvmx_pko_pqx_red_sent_packets {
+union cvmx_pko_peb_pad_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_red_sent_packets_s {
+	struct cvmx_pko_peb_pad_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_40_63               : 24;
-	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_PAD_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_PAD_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_PAD_ERR. */
 #else
-	uint64_t count                        : 40;
-	uint64_t reserved_40_63               : 24;
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
-	struct cvmx_pko_pqx_red_sent_packets_s cn78xx;
+	struct cvmx_pko_peb_pad_err_info_s    cn78xx;
 };
-typedef union cvmx_pko_pqx_red_sent_packets cvmx_pko_pqx_red_sent_packets_t;
+typedef union cvmx_pko_peb_pad_err_info cvmx_pko_peb_pad_err_info_t;
 
 /**
- * cvmx_pko_pq#_topology
+ * cvmx_pko_peb_pse_fifo_err_info
  */
-union cvmx_pko_pqx_topology {
+union cvmx_pko_peb_pse_fifo_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_topology_s {
+	struct cvmx_pko_peb_pse_fifo_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_21_63               : 43;
-	uint64_t link                         : 5;  /**< Link index. Index of the link (a.k.a. the MAC) associated with this port queue. Note that
-                                                         while the hardware reset state has LINK = 0, the hardware is not properly configured for
-                                                         LINK = 0 until an explicit register write occurs. */
-	uint64_t reserved_14_15               : 2;
-	uint64_t peb_fifo                     : 5;  /**< PEB FIFO. The PEB transmit FIFO number. (fixme: A value of 0x1F means unassigned). */
-	uint64_t reserved_0_8                 : 9;
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_PSE_FIFO_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_PSE_FIFO_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_PSE_FIFO_ERR. */
 #else
-	uint64_t reserved_0_8                 : 9;
-	uint64_t peb_fifo                     : 5;
-	uint64_t reserved_14_15               : 2;
-	uint64_t link                         : 5;
-	uint64_t reserved_21_63               : 43;
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
-	struct cvmx_pko_pqx_topology_s        cn78xx;
+	struct cvmx_pko_peb_pse_fifo_err_info_s cn78xx;
 };
-typedef union cvmx_pko_pqx_topology cvmx_pko_pqx_topology_t;
+typedef union cvmx_pko_peb_pse_fifo_err_info cvmx_pko_peb_pse_fifo_err_info_t;
 
 /**
- * cvmx_pko_pq#_yellow_sent_bytes
+ * cvmx_pko_peb_subd_addr_err_info
  */
-union cvmx_pko_pqx_yellow_sent_bytes {
+union cvmx_pko_peb_subd_addr_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_yellow_sent_bytes_s {
+	struct cvmx_pko_peb_subd_addr_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t count                        : 48; /**< Count. The running count of bytes. Note that this count wraps. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_SUBD_ADDR_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_SUBD_ADDR_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_SUBD_ADDR_ERR. */
 #else
-	uint64_t count                        : 48;
-	uint64_t reserved_48_63               : 16;
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
-	struct cvmx_pko_pqx_yellow_sent_bytes_s cn78xx;
+	struct cvmx_pko_peb_subd_addr_err_info_s cn78xx;
 };
-typedef union cvmx_pko_pqx_yellow_sent_bytes cvmx_pko_pqx_yellow_sent_bytes_t;
+typedef union cvmx_pko_peb_subd_addr_err_info cvmx_pko_peb_subd_addr_err_info_t;
 
 /**
- * cvmx_pko_pq#_yellow_sent_packets
+ * cvmx_pko_peb_subd_size_err_info
  */
-union cvmx_pko_pqx_yellow_sent_packets {
+union cvmx_pko_peb_subd_size_err_info {
 	uint64_t u64;
-	struct cvmx_pko_pqx_yellow_sent_packets_s {
+	struct cvmx_pko_peb_subd_size_err_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_40_63               : 24;
-	uint64_t count                        : 40; /**< Count. The running count of packets. Note that this count wraps. */
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_SUBD_SIZE_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_SUBD_SIZE_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_SUBD_SIZE_ERR. */
 #else
-	uint64_t count                        : 40;
-	uint64_t reserved_40_63               : 24;
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
-	struct cvmx_pko_pqx_yellow_sent_packets_s cn78xx;
+	struct cvmx_pko_peb_subd_size_err_info_s cn78xx;
 };
-typedef union cvmx_pko_pqx_yellow_sent_packets cvmx_pko_pqx_yellow_sent_packets_t;
+typedef union cvmx_pko_peb_subd_size_err_info cvmx_pko_peb_subd_size_err_info_t;
+
+/**
+ * cvmx_pko_peb_trunc_err_info
+ */
+union cvmx_pko_peb_trunc_err_info {
+	uint64_t u64;
+	struct cvmx_pko_peb_trunc_err_info_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_20_63               : 44;
+	uint64_t val                          : 1;  /**< Asserted when PKO_PEB_ERR_INT[PEB_TRUNC_ERR] is set. */
+	uint64_t fifo                         : 7;  /**< FIFO number associated with the captured PEB_TRUNC_ERR. */
+	uint64_t chan                         : 12; /**< Channel number associated with the captured PEB_TRUNC_ERR. */
+#else
+	uint64_t chan                         : 12;
+	uint64_t fifo                         : 7;
+	uint64_t val                          : 1;
+	uint64_t reserved_20_63               : 44;
+#endif
+	} s;
+	struct cvmx_pko_peb_trunc_err_info_s  cn78xx;
+};
+typedef union cvmx_pko_peb_trunc_err_info cvmx_pko_peb_trunc_err_info_t;
+
+/**
+ * cvmx_pko_pq_debug_green
+ */
+union cvmx_pko_pq_debug_green {
+	uint64_t u64;
+	struct cvmx_pko_pq_debug_green_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t g_valid                      : 32; /**< g_valid vector. */
+	uint64_t cred_ok_n                    : 32; /**< cred_ok_n vector. */
+#else
+	uint64_t cred_ok_n                    : 32;
+	uint64_t g_valid                      : 32;
+#endif
+	} s;
+	struct cvmx_pko_pq_debug_green_s      cn78xx;
+};
+typedef union cvmx_pko_pq_debug_green cvmx_pko_pq_debug_green_t;
+
+/**
+ * cvmx_pko_pq_debug_links
+ */
+union cvmx_pko_pq_debug_links {
+	uint64_t u64;
+	struct cvmx_pko_pq_debug_links_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t links_ready                  : 32; /**< links_ready vector. */
+	uint64_t peb_lnk_rdy_ir               : 32; /**< peb_lnk_rdy_ir vector. */
+#else
+	uint64_t peb_lnk_rdy_ir               : 32;
+	uint64_t links_ready                  : 32;
+#endif
+	} s;
+	struct cvmx_pko_pq_debug_links_s      cn78xx;
+};
+typedef union cvmx_pko_pq_debug_links cvmx_pko_pq_debug_links_t;
+
+/**
+ * cvmx_pko_pq_debug_yellow
+ */
+union cvmx_pko_pq_debug_yellow {
+	uint64_t u64;
+	struct cvmx_pko_pq_debug_yellow_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t y_valid                      : 32; /**< y_valid vector. */
+	uint64_t link_vv                      : 32; /**< link_vv vector. */
+#else
+	uint64_t link_vv                      : 32;
+	uint64_t y_valid                      : 32;
+#endif
+	} s;
+	struct cvmx_pko_pq_debug_yellow_s     cn78xx;
+};
+typedef union cvmx_pko_pq_debug_yellow cvmx_pko_pq_debug_yellow_t;
+
+/**
+ * cvmx_pko_pqa_debug
+ */
+union cvmx_pko_pqa_debug {
+	uint64_t u64;
+	struct cvmx_pko_pqa_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_pqa_debug_s           cn78xx;
+};
+typedef union cvmx_pko_pqa_debug cvmx_pko_pqa_debug_t;
+
+/**
+ * cvmx_pko_pqb_debug
+ */
+union cvmx_pko_pqb_debug {
+	uint64_t u64;
+	struct cvmx_pko_pqb_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dbg_vec                      : 64; /**< Debug Vector. */
+#else
+	uint64_t dbg_vec                      : 64;
+#endif
+	} s;
+	struct cvmx_pko_pqb_debug_s           cn78xx;
+};
+typedef union cvmx_pko_pqb_debug cvmx_pko_pqb_debug_t;
+
+/**
+ * cvmx_pko_pse_dq_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_pse_dq_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_pse_dq_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_9_63                : 55;
+	uint64_t wt_sram                      : 1;  /**< Work table. */
+	uint64_t rt7_sram                     : 1;  /**< Result table 7 - DQ FIFO[1023:896]. */
+	uint64_t rt6_sram                     : 1;  /**< Result table 6 - DQ FIFO[895:768]. */
+	uint64_t rt5_sram                     : 1;  /**< Result table 5 - DQ FIFO[767:640]. */
+	uint64_t rt4_sram                     : 1;  /**< Result table 4 - DQ FIFO[639:512]. */
+	uint64_t rt3_sram                     : 1;  /**< Result table 3 - DQ FIFO[511:384]. */
+	uint64_t rt2_sram                     : 1;  /**< Result table 2 - DQ FIFO[383:256]. */
+	uint64_t rt1_sram                     : 1;  /**< Result table 1 - DQ FIFO[255:128]. */
+	uint64_t rt0_sram                     : 1;  /**< Result table 0 - DQ FIFO[127:0]. */
+#else
+	uint64_t rt0_sram                     : 1;
+	uint64_t rt1_sram                     : 1;
+	uint64_t rt2_sram                     : 1;
+	uint64_t rt3_sram                     : 1;
+	uint64_t rt4_sram                     : 1;
+	uint64_t rt5_sram                     : 1;
+	uint64_t rt6_sram                     : 1;
+	uint64_t rt7_sram                     : 1;
+	uint64_t wt_sram                      : 1;
+	uint64_t reserved_9_63                : 55;
+#endif
+	} s;
+	struct cvmx_pko_pse_dq_bist_status_s  cn78xx;
+};
+typedef union cvmx_pko_pse_dq_bist_status cvmx_pko_pse_dq_bist_status_t;
 
 /**
  * cvmx_pko_pse_dq_ecc_ctl0
@@ -8258,15 +10226,33 @@ union cvmx_pko_pse_dq_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_dq_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq_wt_ram_dbe                : 1;  /**< Double-bit error for DQ_WT_RAM. */
-	uint64_t dq_rt7_dbe                   : 1;  /**< Double-bit error for DQ_RT7. */
-	uint64_t dq_rt6_dbe                   : 1;  /**< Double-bit error for DQ_RT6. */
-	uint64_t dq_rt5_dbe                   : 1;  /**< Double-bit error for DQ_RT5. */
-	uint64_t dq_rt4_dbe                   : 1;  /**< Double-bit error for DQ_RT4. */
-	uint64_t dq_rt3_dbe                   : 1;  /**< Double-bit error for DQ_RT3. */
-	uint64_t dq_rt2_dbe                   : 1;  /**< Double-bit error for DQ_RT2. */
-	uint64_t dq_rt1_dbe                   : 1;  /**< Double-bit error for DQ_RT1. */
-	uint64_t dq_rt0_dbe                   : 1;  /**< Double-bit error for DQ_RT0. */
+	uint64_t dq_wt_ram_dbe                : 1;  /**< Double-bit error for DQ_WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.wt_sram */
+	uint64_t dq_rt7_dbe                   : 1;  /**< Double-bit error for DQ_RT7_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt7 */
+	uint64_t dq_rt6_dbe                   : 1;  /**< Double-bit error for DQ_RT6_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt6 */
+	uint64_t dq_rt5_dbe                   : 1;  /**< Double-bit error for DQ_RT5_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt5 */
+	uint64_t dq_rt4_dbe                   : 1;  /**< Double-bit error for DQ_RT4_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt4 */
+	uint64_t dq_rt3_dbe                   : 1;  /**< Double-bit error for DQ_RT3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt3 */
+	uint64_t dq_rt2_dbe                   : 1;  /**< Double-bit error for DQ_RT2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt2 */
+	uint64_t dq_rt1_dbe                   : 1;  /**< Double-bit error for DQ_RT1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt1 */
+	uint64_t dq_rt0_dbe                   : 1;  /**< Double-bit error for DQ_RT0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt0 */
 	uint64_t reserved_0_54                : 55;
 #else
 	uint64_t reserved_0_54                : 55;
@@ -8292,7 +10278,20 @@ union cvmx_pko_pse_dq_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_dq_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_dq_dbe_cmb0              : 1;  /**< Double-bit error for DQ_WT_RAM. Throws PKO_INTSN_E::PKO_PSE_DQ_DBE_CMB0. */
+	uint64_t pse_dq_dbe_cmb0              : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_DQ_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_DQ_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_DQ_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.wt_sram
+                                                         pko_pnr2.pko_pse.pse_dq.rt0
+                                                         pko_pnr2.pko_pse.pse_dq.rt1
+                                                         pko_pnr2.pko_pse.pse_dq.rt2
+                                                         pko_pnr2.pko_pse.pse_dq.rt3
+                                                         pko_pnr2.pko_pse.pse_dq.rt4
+                                                         pko_pnr2.pko_pse.pse_dq.rt5
+                                                         pko_pnr2.pko_pse.pse_dq.rt6
+                                                         pko_pnr2.pko_pse.pse_dq.rt7 */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -8310,15 +10309,33 @@ union cvmx_pko_pse_dq_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_dq_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq_wt_ram_sbe                : 1;  /**< Single-bit error for DQ_WT_RAM. */
-	uint64_t dq_rt7_sbe                   : 1;  /**< Single-bit error for DQ_RT7. */
-	uint64_t dq_rt6_sbe                   : 1;  /**< Single-bit error for DQ_RT6. */
-	uint64_t dq_rt5_sbe                   : 1;  /**< Single-bit error for DQ_RT5. */
-	uint64_t dq_rt4_sbe                   : 1;  /**< Single-bit error for DQ_RT4. */
-	uint64_t dq_rt3_sbe                   : 1;  /**< Single-bit error for DQ_RT3. */
-	uint64_t dq_rt2_sbe                   : 1;  /**< Single-bit error for DQ_RT2. */
-	uint64_t dq_rt1_sbe                   : 1;  /**< Single-bit error for DQ_RT1. */
-	uint64_t dq_rt0_sbe                   : 1;  /**< Single-bit error for DQ_RT0. */
+	uint64_t dq_wt_ram_sbe                : 1;  /**< Single-bit error for DQ_WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.wt_sram */
+	uint64_t dq_rt7_sbe                   : 1;  /**< Single-bit error for DQ_RT7_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt7 */
+	uint64_t dq_rt6_sbe                   : 1;  /**< Single-bit error for DQ_RT6_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt6 */
+	uint64_t dq_rt5_sbe                   : 1;  /**< Single-bit error for DQ_RT5_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt5 */
+	uint64_t dq_rt4_sbe                   : 1;  /**< Single-bit error for DQ_RT4_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt4 */
+	uint64_t dq_rt3_sbe                   : 1;  /**< Single-bit error for DQ_RT3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt3 */
+	uint64_t dq_rt2_sbe                   : 1;  /**< Single-bit error for DQ_RT2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt2 */
+	uint64_t dq_rt1_sbe                   : 1;  /**< Single-bit error for DQ_RT1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt1 */
+	uint64_t dq_rt0_sbe                   : 1;  /**< Single-bit error for DQ_RT0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.rt0 */
 	uint64_t reserved_0_54                : 55;
 #else
 	uint64_t reserved_0_54                : 55;
@@ -8344,7 +10361,20 @@ union cvmx_pko_pse_dq_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_dq_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_dq_sbe_cmb0              : 1;  /**< Single-bit error for DQ_WT_RAM. Throws PKO_INTSN_E::PKO_PSE_DQ_SBE_CMB0. */
+	uint64_t pse_dq_sbe_cmb0              : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_DQ_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_DQ_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_DQ_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_dq.wt_sram
+                                                         pko_pnr2.pko_pse.pse_dq.rt0
+                                                         pko_pnr2.pko_pse.pse_dq.rt1
+                                                         pko_pnr2.pko_pse.pse_dq.rt2
+                                                         pko_pnr2.pko_pse.pse_dq.rt3
+                                                         pko_pnr2.pko_pse.pse_dq.rt4
+                                                         pko_pnr2.pko_pse.pse_dq.rt5
+                                                         pko_pnr2.pko_pse.pse_dq.rt6
+                                                         pko_pnr2.pko_pse.pse_dq.rt7 */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -8356,6 +10386,55 @@ union cvmx_pko_pse_dq_ecc_sbe_sts_cmb0 {
 typedef union cvmx_pko_pse_dq_ecc_sbe_sts_cmb0 cvmx_pko_pse_dq_ecc_sbe_sts_cmb0_t;
 
 /**
+ * cvmx_pko_pse_pq_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_pse_pq_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_pse_pq_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_15_63               : 49;
+	uint64_t tp_sram                      : 1;  /**< Topology parent - pko_pse_pq_srf32x5e */
+	uint64_t irq_fifo_sram                : 1;  /**< Interrupt message FIFO - pko_pse_pq_srf1024x10e */
+	uint64_t wmd_sram                     : 1;  /**< Dynamic watermark state - pko_pse_wmd_srf1024x49e */
+	uint64_t wms_sram                     : 1;  /**< Static watermark configuration - pko_pse_wms_srf1024x50e */
+	uint64_t cxd_sram                     : 1;  /**< Dynamic channel state - pko_pse_cxd_srf32x31e */
+	uint64_t dqd_sram                     : 1;  /**< DQ dropped stats - pko_pse_stats_srf1024x88 */
+	uint64_t dqs_sram                     : 1;  /**< DQ sent stats - pko_pse_stats_srf1024x88 */
+	uint64_t pqd_sram                     : 1;  /**< PQ dropped stats - pko_pse_stats_srf32x88 */
+	uint64_t pqr_sram                     : 1;  /**< PQ read stats - pko_pse_stats_srf32x88 */
+	uint64_t pqy_sram                     : 1;  /**< PQ yellow stats - pko_pse_stats_srf32x88 */
+	uint64_t pqg_sram                     : 1;  /**< PQ green stats - pko_pse_stats_srf32x88 */
+	uint64_t std_sram                     : 1;  /**< Dynamic shaping state - pko_pse_std_srf32x105e */
+	uint64_t st_sram                      : 1;  /**< Static shaping configuration - pko_pse_sts_srf32x74e */
+	uint64_t reserved_1_1                 : 1;
+	uint64_t cxs_sram                     : 1;  /**< Static channel credit configuration - pko_pse_cx0_srf32x6e */
+#else
+	uint64_t cxs_sram                     : 1;
+	uint64_t reserved_1_1                 : 1;
+	uint64_t st_sram                      : 1;
+	uint64_t std_sram                     : 1;
+	uint64_t pqg_sram                     : 1;
+	uint64_t pqy_sram                     : 1;
+	uint64_t pqr_sram                     : 1;
+	uint64_t pqd_sram                     : 1;
+	uint64_t dqs_sram                     : 1;
+	uint64_t dqd_sram                     : 1;
+	uint64_t cxd_sram                     : 1;
+	uint64_t wms_sram                     : 1;
+	uint64_t wmd_sram                     : 1;
+	uint64_t irq_fifo_sram                : 1;
+	uint64_t tp_sram                      : 1;
+	uint64_t reserved_15_63               : 49;
+#endif
+	} s;
+	struct cvmx_pko_pse_pq_bist_status_s  cn78xx;
+};
+typedef union cvmx_pko_pse_pq_bist_status cvmx_pko_pse_pq_bist_status_t;
+
+/**
  * cvmx_pko_pse_pq_ecc_ctl0
  */
 union cvmx_pko_pse_pq_ecc_ctl0 {
@@ -8410,14 +10489,30 @@ union cvmx_pko_pse_pq_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_pq_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pq_cxs_ram_dbe               : 1;  /**< Double-bit error for PQ_CXS_RAM. */
-	uint64_t pq_cxd_ram_dbe               : 1;  /**< Double-bit error for PQ_CXD_RAM. */
-	uint64_t irq_fifo_sram_dbe            : 1;  /**< Double-bit error for IRQ_FIFO_SRAM. */
-	uint64_t tp_sram_dbe                  : 1;  /**< Double-bit error for TP_SRAM. */
-	uint64_t pq_std_ram_dbe               : 1;  /**< Double-bit error for PQ_STD_RAM. */
-	uint64_t pq_st_ram_dbe                : 1;  /**< Double-bit error for PQ_ST_RAM. */
-	uint64_t pq_wmd_ram_dbe               : 1;  /**< Double-bit error for PQ_WMD_RAM. */
-	uint64_t pq_wms_ram_dbe               : 1;  /**< Double-bit error for PQ_WMS_RAM. */
+	uint64_t pq_cxs_ram_dbe               : 1;  /**< Double-bit error for PQ_CXS_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.cxs_sram */
+	uint64_t pq_cxd_ram_dbe               : 1;  /**< Double-bit error for PQ_CXD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.cxd_sram */
+	uint64_t irq_fifo_sram_dbe            : 1;  /**< Double-bit error for IRQ_FIFO_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.irq_fifo_sram */
+	uint64_t tp_sram_dbe                  : 1;  /**< Double-bit error for TP_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.tp_sram */
+	uint64_t pq_std_ram_dbe               : 1;  /**< Double-bit error for PQ_STD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.std_sram */
+	uint64_t pq_st_ram_dbe                : 1;  /**< Double-bit error for PQ_ST_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.st_sram */
+	uint64_t pq_wmd_ram_dbe               : 1;  /**< Double-bit error for PQ_WMD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.wmd_sram */
+	uint64_t pq_wms_ram_dbe               : 1;  /**< Double-bit error for PQ_WMS_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.wms_sram */
 	uint64_t reserved_0_55                : 56;
 #else
 	uint64_t reserved_0_55                : 56;
@@ -8442,7 +10537,19 @@ union cvmx_pko_pse_pq_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_pq_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_pq_dbe_cmb0              : 1;  /**< Double-bit error for PQ_CXS_RAM. Throws PKO_INTSN_E::PKO_PSE_PQ_DBE_CMB0. */
+	uint64_t pse_pq_dbe_cmb0              : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_PQ_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_PQ_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_PQ_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.cxs_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.cxd_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.irq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.tp_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.std_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.st_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.wmd_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.wms_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -8460,14 +10567,30 @@ union cvmx_pko_pse_pq_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_pq_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pq_cxs_ram_sbe               : 1;  /**< Single-bit error for PQ_CXS_RAM. */
-	uint64_t pq_cxd_ram_sbe               : 1;  /**< Single-bit error for PQ_CXD_RAM. */
-	uint64_t irq_fifo_sram_sbe            : 1;  /**< Single-bit error for IRQ_FIFO_SRAM. */
-	uint64_t tp_sram_sbe                  : 1;  /**< Single-bit error for TP_SRAM. */
-	uint64_t pq_std_ram_sbe               : 1;  /**< Single-bit error for PQ_STD_RAM. */
-	uint64_t pq_st_ram_sbe                : 1;  /**< Single-bit error for PQ_ST_RAM. */
-	uint64_t pq_wmd_ram_sbe               : 1;  /**< Single-bit error for PQ_WMD_RAM. */
-	uint64_t pq_wms_ram_sbe               : 1;  /**< Single-bit error for PQ_WMS_RAM. */
+	uint64_t pq_cxs_ram_sbe               : 1;  /**< Single-bit error for PQ_CXS_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.cxs_sram */
+	uint64_t pq_cxd_ram_sbe               : 1;  /**< Single-bit error for PQ_CXD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.cxd_sram */
+	uint64_t irq_fifo_sram_sbe            : 1;  /**< Single-bit error for IRQ_FIFO_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.irq_fifo_sram */
+	uint64_t tp_sram_sbe                  : 1;  /**< Single-bit error for TP_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.tp_sram */
+	uint64_t pq_std_ram_sbe               : 1;  /**< Single-bit error for PQ_STD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.std_sram */
+	uint64_t pq_st_ram_sbe                : 1;  /**< Single-bit error for PQ_ST_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.st_sram */
+	uint64_t pq_wmd_ram_sbe               : 1;  /**< Single-bit error for PQ_WMD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.wmd_sram */
+	uint64_t pq_wms_ram_sbe               : 1;  /**< Single-bit error for PQ_WMS_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.wms_sram */
 	uint64_t reserved_0_55                : 56;
 #else
 	uint64_t reserved_0_55                : 56;
@@ -8492,7 +10615,19 @@ union cvmx_pko_pse_pq_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_pq_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_pq_sbe_cmb0              : 1;  /**< Single-bit error for PQ_CXS_RAM. Throws PKO_INTSN_E::PKO_PSE_PQ_SBE_CMB0. */
+	uint64_t pse_pq_sbe_cmb0              : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_PQ_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_PQ_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_PQ_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.cxs_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.cxd_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.irq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.tp_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.std_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.st_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.wmd_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.wms_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -8504,6 +10639,67 @@ union cvmx_pko_pse_pq_ecc_sbe_sts_cmb0 {
 typedef union cvmx_pko_pse_pq_ecc_sbe_sts_cmb0 cvmx_pko_pse_pq_ecc_sbe_sts_cmb0_t;
 
 /**
+ * cvmx_pko_pse_sq1_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_pse_sq1_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_pse_sq1_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_29_63               : 35;
+	uint64_t sc_sram                      : 1;  /**< SQ[5:1] scheduling configuration */
+	uint64_t pc_sram                      : 1;  /**< SQ[1] physical channel - pko_pse_pc_srf32x12e */
+	uint64_t xon_sram                     : 1;  /**< XON SRAM */
+	uint64_t cc_sram                      : 1;  /**< SQ[1] channel credit OK state array */
+	uint64_t vc1_sram                     : 1;  /**< SQ[1] virtual channel - pko_pse_sq1_vc_srf256x9e */
+	uint64_t vc0_sram                     : 1;  /**< SQ[1] virtual channel - pko_pse_sq1_vc_srf256x9e */
+	uint64_t reserved_21_22               : 2;
+	uint64_t tp1_sram                     : 1;  /**< SQ[5:1] topology parent configuration */
+	uint64_t tp0_sram                     : 1;  /**< SQ[5:1] topology parent configuration */
+	uint64_t xo_sram                      : 1;  /**< XOFF SRAM */
+	uint64_t rt_sram                      : 1;  /**< Result table */
+	uint64_t reserved_9_16                : 8;
+	uint64_t tw1_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 1 command FIFO SRAM */
+	uint64_t std_sram                     : 1;  /**< Dynamic shaping state */
+	uint64_t sts_sram                     : 1;  /**< Static shaping configuration */
+	uint64_t tw0_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 0 command FIFO SRAM */
+	uint64_t cxd_sram                     : 1;  /**< SQ[1] dynamic channel credit state */
+	uint64_t cxs_sram                     : 1;  /**< SQ[1] static channel credit configuration */
+	uint64_t nt_sram                      : 1;  /**< SQ[5:1] next pointer table */
+	uint64_t pt_sram                      : 1;  /**< SQ[5:1] previous pointer table */
+	uint64_t wt_sram                      : 1;  /**< SQ[5:1] work table */
+#else
+	uint64_t wt_sram                      : 1;
+	uint64_t pt_sram                      : 1;
+	uint64_t nt_sram                      : 1;
+	uint64_t cxs_sram                     : 1;
+	uint64_t cxd_sram                     : 1;
+	uint64_t tw0_cmd_fifo                 : 1;
+	uint64_t sts_sram                     : 1;
+	uint64_t std_sram                     : 1;
+	uint64_t tw1_cmd_fifo                 : 1;
+	uint64_t reserved_9_16                : 8;
+	uint64_t rt_sram                      : 1;
+	uint64_t xo_sram                      : 1;
+	uint64_t tp0_sram                     : 1;
+	uint64_t tp1_sram                     : 1;
+	uint64_t reserved_21_22               : 2;
+	uint64_t vc0_sram                     : 1;
+	uint64_t vc1_sram                     : 1;
+	uint64_t cc_sram                      : 1;
+	uint64_t xon_sram                     : 1;
+	uint64_t pc_sram                      : 1;
+	uint64_t sc_sram                      : 1;
+	uint64_t reserved_29_63               : 35;
+#endif
+	} s;
+	struct cvmx_pko_pse_sq1_bist_status_s cn78xx;
+};
+typedef union cvmx_pko_pse_sq1_bist_status cvmx_pko_pse_sq1_bist_status_t;
+
+/**
  * cvmx_pko_pse_sq1_ecc_ctl0
  */
 union cvmx_pko_pse_sq1_ecc_ctl0 {
@@ -8598,24 +10794,60 @@ union cvmx_pko_pse_sq1_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq1_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t cxs_ram_dbe                  : 1;  /**< Double-bit error for CXS_RAM. */
-	uint64_t cxd_ram_dbe                  : 1;  /**< Double-bit error for CXD_RAM. */
-	uint64_t vc1_sram_dbe                 : 1;  /**< Double-bit error for VC1_SRAM. */
-	uint64_t vc0_sram_dbe                 : 1;  /**< Double-bit error for VC0_SRAM. */
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. */
-	uint64_t pc_ram_dbe                   : 1;  /**< Double-bit error for PC_RAM. */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. */
+	uint64_t cxs_ram_dbe                  : 1;  /**< Double-bit error for CXS_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxs_sram */
+	uint64_t cxd_ram_dbe                  : 1;  /**< Double-bit error for CXD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxd_sram */
+	uint64_t vc1_sram_dbe                 : 1;  /**< Double-bit error for VC1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc1_sram */
+	uint64_t vc0_sram_dbe                 : 1;  /**< Double-bit error for VC0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc0_sram */
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.nt_sram */
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.pt_sram */
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.rt_sram */
+	uint64_t pc_ram_dbe                   : 1;  /**< Double-bit error for PC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pc_sram */
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_0.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_1.sq_fifo_sram */
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp0_sram */
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp1_sram */
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts1_sram */
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts0_sram */
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.std1_sram */
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.std0_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sc_sram */
 	uint64_t reserved_0_45                : 46;
 #else
 	uint64_t reserved_0_45                : 46;
@@ -8650,7 +10882,29 @@ union cvmx_pko_pse_sq1_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq1_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq1_dbe_cmb0             : 1;  /**< Double-bit error for CXS_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ1_DBE_CMB0. */
+	uint64_t pse_sq1_dbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ1_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ1_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ1_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxs_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxd_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pc_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -8668,24 +10922,60 @@ union cvmx_pko_pse_sq1_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq1_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t cxs_ram_sbe                  : 1;  /**< Single-bit error for CXS_RAM. */
-	uint64_t cxd_ram_sbe                  : 1;  /**< Single-bit error for CXD_RAM. */
-	uint64_t vc1_sram_sbe                 : 1;  /**< Single-bit error for VC1_SRAM. */
-	uint64_t vc0_sram_sbe                 : 1;  /**< Single-bit error for VC0_SRAM. */
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. */
-	uint64_t pc_ram_sbe                   : 1;  /**< Single-bit error for PC_RAM. */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. */
+	uint64_t cxs_ram_sbe                  : 1;  /**< Single-bit error for CXS_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxs_sram */
+	uint64_t cxd_ram_sbe                  : 1;  /**< Single-bit error for CXD_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxd_sram */
+	uint64_t vc1_sram_sbe                 : 1;  /**< Single-bit error for VC1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc0_sram */
+	uint64_t vc0_sram_sbe                 : 1;  /**< Single-bit error for VC0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc1_sram */
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.nt_sram */
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.pt_sram */
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.rt_sram */
+	uint64_t pc_ram_sbe                   : 1;  /**< Single-bit error for PC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pc_sram */
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_0.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_1.sq_fifo_sram */
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp0_sram */
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp1_sram */
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts0_sram */
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts1_sram */
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.std0_sram */
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.std1_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sc_sram */
 	uint64_t reserved_0_45                : 46;
 #else
 	uint64_t reserved_0_45                : 46;
@@ -8720,7 +11010,29 @@ union cvmx_pko_pse_sq1_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq1_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq1_sbe_cmb0             : 1;  /**< Single-bit error for CXS_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ1_SBE_CMB0. */
+	uint64_t pse_sq1_sbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ1_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ1_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ1_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxs_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxd_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pc_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -8732,6 +11044,55 @@ union cvmx_pko_pse_sq1_ecc_sbe_sts_cmb0 {
 typedef union cvmx_pko_pse_sq1_ecc_sbe_sts_cmb0 cvmx_pko_pse_sq1_ecc_sbe_sts_cmb0_t;
 
 /**
+ * cvmx_pko_pse_sq2_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_pse_sq2_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_pse_sq2_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_29_63               : 35;
+	uint64_t sc_sram                      : 1;  /**< Scheduling configuration. */
+	uint64_t reserved_21_27               : 7;
+	uint64_t tp1_sram                     : 1;  /**< SQ[5:1] topology parent configuration. */
+	uint64_t tp0_sram                     : 1;  /**< SQ[5:1] topology parent configuration. */
+	uint64_t reserved_18_18               : 1;
+	uint64_t rt_sram                      : 1;  /**< Result table. */
+	uint64_t reserved_9_16                : 8;
+	uint64_t tw1_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 1 command FIFO SRAM. */
+	uint64_t std_sram                     : 1;  /**< Dynamic shaping state */
+	uint64_t sts_sram                     : 1;  /**< Static shaping configuration. */
+	uint64_t tw0_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 0 command FIFO SRAM. */
+	uint64_t reserved_3_4                 : 2;
+	uint64_t nt_sram                      : 1;  /**< Next pointer table. */
+	uint64_t pt_sram                      : 1;  /**< Previous pointer table. */
+	uint64_t wt_sram                      : 1;  /**< Work table. */
+#else
+	uint64_t wt_sram                      : 1;
+	uint64_t pt_sram                      : 1;
+	uint64_t nt_sram                      : 1;
+	uint64_t reserved_3_4                 : 2;
+	uint64_t tw0_cmd_fifo                 : 1;
+	uint64_t sts_sram                     : 1;
+	uint64_t std_sram                     : 1;
+	uint64_t tw1_cmd_fifo                 : 1;
+	uint64_t reserved_9_16                : 8;
+	uint64_t rt_sram                      : 1;
+	uint64_t reserved_18_18               : 1;
+	uint64_t tp0_sram                     : 1;
+	uint64_t tp1_sram                     : 1;
+	uint64_t reserved_21_27               : 7;
+	uint64_t sc_sram                      : 1;
+	uint64_t reserved_29_63               : 35;
+#endif
+	} s;
+	struct cvmx_pko_pse_sq2_bist_status_s cn78xx;
+};
+typedef union cvmx_pko_pse_sq2_bist_status cvmx_pko_pse_sq2_bist_status_t;
+
+/**
  * cvmx_pko_pse_sq2_ecc_ctl0
  */
 union cvmx_pko_pse_sq2_ecc_ctl0 {
@@ -8806,19 +11167,45 @@ union cvmx_pko_pse_sq2_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq2_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. */
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.nt_sram */
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pt_sram */
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.rt_sram */
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_1.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_0.sq_fifo_sram */
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp1_sram */
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp0_sram */
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts1_sram */
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts0_sram */
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.std1_sram */
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.std0_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sc_sram */
 	uint64_t reserved_0_50                : 51;
 #else
 	uint64_t reserved_0_50                : 51;
@@ -8848,7 +11235,24 @@ union cvmx_pko_pse_sq2_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq2_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq2_dbe_cmb0             : 1;  /**< Double-bit error for SQ_PT_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ2_DBE_CMB0. */
+	uint64_t pse_sq2_dbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ2_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ2_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ2_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -8866,19 +11270,45 @@ union cvmx_pko_pse_sq2_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq2_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. */
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.nt_sram */
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pt_sram */
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.rt_sram */
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_1.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_0.sq_fifo_sram */
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp1_sram */
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp0_sram */
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts1_sram */
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts0_sram */
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.std1_sram */
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.std0_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sc_sram */
 	uint64_t reserved_0_50                : 51;
 #else
 	uint64_t reserved_0_50                : 51;
@@ -8908,7 +11338,24 @@ union cvmx_pko_pse_sq2_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq2_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq2_sbe_cmb0             : 1;  /**< Single-bit error for SQ_PT_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ2_SBE_CMB0. */
+	uint64_t pse_sq2_sbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ2_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ2_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ2_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -8920,6 +11367,67 @@ union cvmx_pko_pse_sq2_ecc_sbe_sts_cmb0 {
 typedef union cvmx_pko_pse_sq2_ecc_sbe_sts_cmb0 cvmx_pko_pse_sq2_ecc_sbe_sts_cmb0_t;
 
 /**
+ * cvmx_pko_pse_sq3_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_pse_sq3_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_pse_sq3_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_29_63               : 35;
+	uint64_t sc_sram                      : 1;  /**< Scheduling configuration */
+	uint64_t reserved_23_27               : 5;
+	uint64_t tp3_sram                     : 1;  /**< SQ[5:3] topology parent configuration */
+	uint64_t tp2_sram                     : 1;  /**< SQ[5:3] topology parent configuration */
+	uint64_t tp1_sram                     : 1;  /**< SQ[5:1] topology parent configuration */
+	uint64_t tp0_sram                     : 1;  /**< SQ[5:1] topology parent configuration */
+	uint64_t reserved_18_18               : 1;
+	uint64_t rt_sram                      : 1;  /**< Result table */
+	uint64_t reserved_15_16               : 2;
+	uint64_t tw3_cmd_fifo                 : 1;  /**< SQ[5:3] time wheel 3 command FIFO SRAM */
+	uint64_t reserved_12_13               : 2;
+	uint64_t tw2_cmd_fifo                 : 1;  /**< SQ[5:3] time wheel 2 command FIFO SRAM */
+	uint64_t reserved_9_10                : 2;
+	uint64_t tw1_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 1 command FIFO SRAM */
+	uint64_t std_sram                     : 1;  /**< Dynamic shaping state */
+	uint64_t sts_sram                     : 1;  /**< Static shaping configuration */
+	uint64_t tw0_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 0 command FIFO SRAM */
+	uint64_t reserved_3_4                 : 2;
+	uint64_t nt_sram                      : 1;  /**< Next pointer table */
+	uint64_t pt_sram                      : 1;  /**< Previous pointer table */
+	uint64_t wt_sram                      : 1;  /**< Work table */
+#else
+	uint64_t wt_sram                      : 1;
+	uint64_t pt_sram                      : 1;
+	uint64_t nt_sram                      : 1;
+	uint64_t reserved_3_4                 : 2;
+	uint64_t tw0_cmd_fifo                 : 1;
+	uint64_t sts_sram                     : 1;
+	uint64_t std_sram                     : 1;
+	uint64_t tw1_cmd_fifo                 : 1;
+	uint64_t reserved_9_10                : 2;
+	uint64_t tw2_cmd_fifo                 : 1;
+	uint64_t reserved_12_13               : 2;
+	uint64_t tw3_cmd_fifo                 : 1;
+	uint64_t reserved_15_16               : 2;
+	uint64_t rt_sram                      : 1;
+	uint64_t reserved_18_18               : 1;
+	uint64_t tp0_sram                     : 1;
+	uint64_t tp1_sram                     : 1;
+	uint64_t tp2_sram                     : 1;
+	uint64_t tp3_sram                     : 1;
+	uint64_t reserved_23_27               : 5;
+	uint64_t sc_sram                      : 1;
+	uint64_t reserved_29_63               : 35;
+#endif
+	} s;
+	struct cvmx_pko_pse_sq3_bist_status_s cn78xx;
+};
+typedef union cvmx_pko_pse_sq3_bist_status cvmx_pko_pse_sq3_bist_status_t;
+
+/**
  * cvmx_pko_pse_sq3_ecc_ctl0
  */
 union cvmx_pko_pse_sq3_ecc_ctl0 {
@@ -9026,27 +11534,69 @@ union cvmx_pko_pse_sq3_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq3_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. */
-	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM. */
-	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM. */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM. */
-	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM. */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. */
-	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM. */
-	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM. */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. */
-	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM. */
-	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM. */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. */
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.nt_sram */
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.pt_sram */
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_3.sq_fifo_sram */
+	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_2.sq_fifo_sram */
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_1.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_0.sq_fifo_sram */
+	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp3_sram */
+	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp2_sram */
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp1_sram */
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp0_sram */
+	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts3_sram */
+	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts2_sram */
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts1_sram */
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts0_sram */
+	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std3_sram */
+	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std2_sram */
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std1_sram */
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std0_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -9084,7 +11634,32 @@ union cvmx_pko_pse_sq3_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq3_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq3_dbe_cmb0             : 1;  /**< Double-bit error for SQ_PT_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ3_DBE_CMB0. */
+	uint64_t pse_sq3_dbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ3_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ3_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ3_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_2.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_3.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -9102,27 +11677,69 @@ union cvmx_pko_pse_sq3_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq3_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. */
-	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM. */
-	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM. */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM. */
-	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM. */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. */
-	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM. */
-	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM. */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. */
-	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM. */
-	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM. */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. */
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.nt_sram */
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.pt_sram */
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_3.sq_fifo_sram */
+	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_2.sq_fifo_sram */
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_1.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_0.sq_fifo_sram */
+	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp3_sram */
+	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp2_sram */
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp1_sram */
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp0_sram */
+	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts3_sram */
+	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts2_sram */
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts1_sram */
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts0_sram */
+	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std3_sram */
+	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std2_sram */
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std1_sram */
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std0_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -9160,7 +11777,32 @@ union cvmx_pko_pse_sq3_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq3_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq3_sbe_cmb0             : 1;  /**< Single-bit error for SQ_PT_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ3_SBE_CMB0. */
+	uint64_t pse_sq3_sbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ3_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ3_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ3_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_2.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_3.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -9172,6 +11814,67 @@ union cvmx_pko_pse_sq3_ecc_sbe_sts_cmb0 {
 typedef union cvmx_pko_pse_sq3_ecc_sbe_sts_cmb0 cvmx_pko_pse_sq3_ecc_sbe_sts_cmb0_t;
 
 /**
+ * cvmx_pko_pse_sq4_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_pse_sq4_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_pse_sq4_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_29_63               : 35;
+	uint64_t sc_sram                      : 1;  /**< Scheduling configuration */
+	uint64_t reserved_23_27               : 5;
+	uint64_t tp3_sram                     : 1;  /**< SQ[5:3] topology parent configuration */
+	uint64_t tp2_sram                     : 1;  /**< SQ[5:3] topology parent configuration */
+	uint64_t tp1_sram                     : 1;  /**< SQ[5:1] topology parent configuration */
+	uint64_t tp0_sram                     : 1;  /**< SQ[5:1] topology parent configuration */
+	uint64_t reserved_18_18               : 1;
+	uint64_t rt_sram                      : 1;  /**< Result Table */
+	uint64_t reserved_15_16               : 2;
+	uint64_t tw3_cmd_fifo                 : 1;  /**< SQ[5:3] time wheel 3 command FIFO SRAM */
+	uint64_t reserved_12_13               : 2;
+	uint64_t tw2_cmd_fifo                 : 1;  /**< SQ[5:3] time wheel 2 command FIFO SRAM. */
+	uint64_t reserved_9_10                : 2;
+	uint64_t tw1_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 1 command FIFO SRAM. */
+	uint64_t std_sram                     : 1;  /**< Dynamic shaping state. */
+	uint64_t sts_sram                     : 1;  /**< Static shaping configuration. */
+	uint64_t tw0_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 0 command FIFO SRAM. */
+	uint64_t reserved_3_4                 : 2;
+	uint64_t nt_sram                      : 1;  /**< Next pointer table. */
+	uint64_t pt_sram                      : 1;  /**< Previous pointer table. */
+	uint64_t wt_sram                      : 1;  /**< Work table. */
+#else
+	uint64_t wt_sram                      : 1;
+	uint64_t pt_sram                      : 1;
+	uint64_t nt_sram                      : 1;
+	uint64_t reserved_3_4                 : 2;
+	uint64_t tw0_cmd_fifo                 : 1;
+	uint64_t sts_sram                     : 1;
+	uint64_t std_sram                     : 1;
+	uint64_t tw1_cmd_fifo                 : 1;
+	uint64_t reserved_9_10                : 2;
+	uint64_t tw2_cmd_fifo                 : 1;
+	uint64_t reserved_12_13               : 2;
+	uint64_t tw3_cmd_fifo                 : 1;
+	uint64_t reserved_15_16               : 2;
+	uint64_t rt_sram                      : 1;
+	uint64_t reserved_18_18               : 1;
+	uint64_t tp0_sram                     : 1;
+	uint64_t tp1_sram                     : 1;
+	uint64_t tp2_sram                     : 1;
+	uint64_t tp3_sram                     : 1;
+	uint64_t reserved_23_27               : 5;
+	uint64_t sc_sram                      : 1;
+	uint64_t reserved_29_63               : 35;
+#endif
+	} s;
+	struct cvmx_pko_pse_sq4_bist_status_s cn78xx;
+};
+typedef union cvmx_pko_pse_sq4_bist_status cvmx_pko_pse_sq4_bist_status_t;
+
+/**
  * cvmx_pko_pse_sq4_ecc_ctl0
  */
 union cvmx_pko_pse_sq4_ecc_ctl0 {
@@ -9278,27 +11981,69 @@ union cvmx_pko_pse_sq4_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq4_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. */
-	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM. */
-	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM. */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM. */
-	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM. */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. */
-	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM. */
-	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM. */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. */
-	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM. */
-	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM. */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. */
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.pt_sram */
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.nt_sram */
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_3.sq_fifo_sram */
+	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_2.sq_fifo_sram */
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_1.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_0.sq_fifo_sram */
+	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp3_sram */
+	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp2_sram */
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp1_sram */
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp0_sram */
+	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts3_sram */
+	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts2_sram */
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts1_sram */
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts0_sram */
+	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std3_sram */
+	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std2_sram */
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std1_sram */
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std0_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -9336,7 +12081,32 @@ union cvmx_pko_pse_sq4_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq4_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq4_dbe_cmb0             : 1;  /**< Double-bit error for SQ_PT_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ4_DBE_CMB0. */
+	uint64_t pse_sq4_dbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ4_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ4_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ4_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_2.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_3.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -9354,27 +12124,69 @@ union cvmx_pko_pse_sq4_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq4_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. */
-	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM. */
-	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM. */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM. */
-	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM. */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. */
-	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM. */
-	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM. */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. */
-	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM. */
-	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM. */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. */
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.nt_sram */
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.pt_sram */
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_3.sq_fifo_sram */
+	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_2.sq_fifo_sram */
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_1.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_0.sq_fifo_sram */
+	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp3_sram */
+	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp2_sram */
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp1_sram */
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp0_sram */
+	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts3_sram */
+	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts2_sram */
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts1_sram */
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts0_sram */
+	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std3_sram */
+	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std2_sram */
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std1_sram */
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std0_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -9412,7 +12224,32 @@ union cvmx_pko_pse_sq4_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq4_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq4_sbe_cmb0             : 1;  /**< Single-bit error for SQ_PT_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ4_SBE_CMB0. */
+	uint64_t pse_sq4_sbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ4_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ4_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ4_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_2.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_3.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -9424,6 +12261,67 @@ union cvmx_pko_pse_sq4_ecc_sbe_sts_cmb0 {
 typedef union cvmx_pko_pse_sq4_ecc_sbe_sts_cmb0 cvmx_pko_pse_sq4_ecc_sbe_sts_cmb0_t;
 
 /**
+ * cvmx_pko_pse_sq5_bist_status
+ *
+ * Each bit is the BIST result of an individual memory (per bit, 0 = pass and 1 = fail).
+ *
+ */
+union cvmx_pko_pse_sq5_bist_status {
+	uint64_t u64;
+	struct cvmx_pko_pse_sq5_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_29_63               : 35;
+	uint64_t sc_sram                      : 1;  /**< Scheduling configuration. */
+	uint64_t reserved_23_27               : 5;
+	uint64_t tp3_sram                     : 1;  /**< SQ[5:3] topology parent configuration. */
+	uint64_t tp2_sram                     : 1;  /**< SQ[5:3] topology parent configuration. */
+	uint64_t tp1_sram                     : 1;  /**< SQ[5:1] topology parent configuration. */
+	uint64_t tp0_sram                     : 1;  /**< SQ[5:1] topology parent configuration. */
+	uint64_t reserved_18_18               : 1;
+	uint64_t rt_sram                      : 1;  /**< Result table. */
+	uint64_t reserved_15_16               : 2;
+	uint64_t tw3_cmd_fifo                 : 1;  /**< SQ[5:3] time wheel 3 command FIFO SRAM. */
+	uint64_t reserved_12_13               : 2;
+	uint64_t tw2_cmd_fifo                 : 1;  /**< SQ[5:3] time wheel 2 command FIFO SRAM. */
+	uint64_t reserved_9_10                : 2;
+	uint64_t tw1_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 1 command FIFO SRAM. */
+	uint64_t std_sram                     : 1;  /**< Dynamic shaping state. */
+	uint64_t sts_sram                     : 1;  /**< Static shaping configuration. */
+	uint64_t tw0_cmd_fifo                 : 1;  /**< SQ[5:1] time wheel 0 command FIFO SRAM. */
+	uint64_t reserved_3_4                 : 2;
+	uint64_t nt_sram                      : 1;  /**< Next pointer table. */
+	uint64_t pt_sram                      : 1;  /**< Previous pointer table. */
+	uint64_t wt_sram                      : 1;  /**< Work table. */
+#else
+	uint64_t wt_sram                      : 1;
+	uint64_t pt_sram                      : 1;
+	uint64_t nt_sram                      : 1;
+	uint64_t reserved_3_4                 : 2;
+	uint64_t tw0_cmd_fifo                 : 1;
+	uint64_t sts_sram                     : 1;
+	uint64_t std_sram                     : 1;
+	uint64_t tw1_cmd_fifo                 : 1;
+	uint64_t reserved_9_10                : 2;
+	uint64_t tw2_cmd_fifo                 : 1;
+	uint64_t reserved_12_13               : 2;
+	uint64_t tw3_cmd_fifo                 : 1;
+	uint64_t reserved_15_16               : 2;
+	uint64_t rt_sram                      : 1;
+	uint64_t reserved_18_18               : 1;
+	uint64_t tp0_sram                     : 1;
+	uint64_t tp1_sram                     : 1;
+	uint64_t tp2_sram                     : 1;
+	uint64_t tp3_sram                     : 1;
+	uint64_t reserved_23_27               : 5;
+	uint64_t sc_sram                      : 1;
+	uint64_t reserved_29_63               : 35;
+#endif
+	} s;
+	struct cvmx_pko_pse_sq5_bist_status_s cn78xx;
+};
+typedef union cvmx_pko_pse_sq5_bist_status cvmx_pko_pse_sq5_bist_status_t;
+
+/**
  * cvmx_pko_pse_sq5_ecc_ctl0
  */
 union cvmx_pko_pse_sq5_ecc_ctl0 {
@@ -9530,27 +12428,69 @@ union cvmx_pko_pse_sq5_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq5_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. */
-	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM. */
-	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM. */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM. */
-	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM. */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. */
-	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM. */
-	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM. */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. */
-	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM. */
-	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM. */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. */
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.pt_sram */
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.nt_sram */
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_3.sq_fifo_sram */
+	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_2.sq_fifo_sram */
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_1.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_0.sq_fifo_sram */
+	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp3_sram */
+	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp2_sram */
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp1_sram */
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp0_sram */
+	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts3_sram */
+	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts2_sram */
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts1_sram */
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts0_sram */
+	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std3_sram */
+	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std2_sram */
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std1_sram */
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std0_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -9588,7 +12528,32 @@ union cvmx_pko_pse_sq5_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq5_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq5_dbe_cmb0             : 1;  /**< Double-bit error for SQ_PT_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ5_DBE_CMB0. */
+	uint64_t pse_sq5_dbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ5_ECC_DBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ5_ECC_DBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ5_DBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_2.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_3.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -9606,27 +12571,69 @@ union cvmx_pko_pse_sq5_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq5_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. */
-	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM. */
-	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM. */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. */
-	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM. */
-	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM. */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. */
-	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM. */
-	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM. */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. */
-	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM. */
-	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM. */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. */
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.pt_sram */
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.nt_sram */
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_3.sq_fifo_sram */
+	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_2.sq_fifo_sram */
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_1.sq_fifo_sram */
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_0.sq_fifo_sram */
+	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp3_sram */
+	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp2_sram */
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp1_sram */
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp0_sram */
+	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts3_sram */
+	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts2_sram */
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts1_sram */
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts0_sram */
+	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std3_sram */
+	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std2_sram */
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std1_sram */
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std0_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -9664,7 +12671,32 @@ union cvmx_pko_pse_sq5_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq5_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pse_sq5_sbe_cmb0             : 1;  /**< Single-bit error for SQ_PT_RAM. Throws PKO_INTSN_E::PKO_PSE_SQ5_SBE_CMB0. */
+	uint64_t pse_sq5_sbe_cmb0             : 1;  /**< This bit is the logical OR of all bits in PKO_PSE_SQ5_ECC_SBE_STS.
+                                                         To clear this bit, software must clear bits in PKO_PSE_SQ5_ECC_SBE_STS.
+                                                         When this bit is set, the corresponding interrupt is set.
+                                                         Throws PKO_INTSN_E::PKO_PSE_SQ5_SBE_CMB0.
+                                                         INTERNAL: Instances:
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.nt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.pt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.rt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_0.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_1.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_2.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_3.sq_fifo_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts0_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts1_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts2_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts3_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.wt_sram
+                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sc_sram */
 	uint64_t reserved_0_62                : 63;
 #else
 	uint64_t reserved_0_62                : 63;
@@ -9682,13 +12714,19 @@ union cvmx_pko_ptfx_status {
 	uint64_t u64;
 	struct cvmx_pko_ptfx_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_5_63                : 59;
-	uint64_t mac_num                      : 5;  /**< The MAC assigned to the given PKO TX FIFO. A value of 0x1F means unassigned. These
-                                                         registers values are derived automatically by the hardware from the
+	uint64_t reserved_20_63               : 44;
+	uint64_t total_in_flight_cnt          : 8;  /**< Total number of packets currently in-flight within PEB.  Useful
+                                                         both for reconfiguration (able to disable a FIFO when it is empty) and debugging. */
+	uint64_t in_flight_cnt                : 7;  /**< Number of packets currently in-flight within PEB for this link.
+                                                         Useful both for reconfiguration (able to disable a FIFO when it is empty) and debugging. */
+	uint64_t mac_num                      : 5;  /**< MAC assigned to the given PKO TX FIFO. A value of 0x1F means unassigned. These
+                                                         register values are derived automatically by the hardware from the
                                                          PKO_MAC(0..27)_CFG[FIFO_NUM] settings. */
 #else
 	uint64_t mac_num                      : 5;
-	uint64_t reserved_5_63                : 59;
+	uint64_t in_flight_cnt                : 7;
+	uint64_t total_in_flight_cnt          : 8;
+	uint64_t reserved_20_63               : 44;
 #endif
 	} s;
 	struct cvmx_pko_ptfx_status_s         cn78xx;
@@ -9727,10 +12765,25 @@ union cvmx_pko_ptgfx_cfg {
 	uint64_t u64;
 	struct cvmx_pko_ptgfx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_3_63                : 61;
-	uint64_t size                         : 3;  /**< "The PKO supports up to 29 independent TX FIFOs where 0-27 are physical and 28 is
-                                                         virtual. The FIFOs are grouped into 8 sets of four contiguously numbered queues
-                                                         where each FIFO has a base storage amount of 2.5K bytes of buffering.
+	uint64_t reserved_7_63                : 57;
+	uint64_t reset                        : 1;  /**< This bit resets the address pointers for the FIFOs in this group. This should only be
+                                                         performed when a PTGF is empty and the SIZE field is to be being changed. */
+	uint64_t rate                         : 3;  /**< Each PTGF can support up to 100Gbs. The total aggregate rate across all FIFOs (including
+                                                         the NULL) should never exceed 250Gbs.
+                                                         This field represents the rate for each active FIFO in PEB; thus the calculation for
+                                                         throughput is a function of the SIZE field and whether or not the FIFO is assigned to a
+                                                         MAC in PKO_MACx_CFG.
+                                                         RATE: Throughput
+                                                         ----------------
+                                                         - 000:    6.25Gbs
+                                                         - 001:   12.5 Gbs
+                                                         - 010:   25   Gbs
+                                                         - 011:   50   Gbs
+                                                         - 100:  100   Gbs
+                                                         Note: 101-111 are illegal RATE values and should not be used. */
+	uint64_t size                         : 3;  /**< "PKO supports up to 29 independent TX FIFOs where 0-27 are physical and 28 is virtual. The
+                                                         FIFOs are grouped into 8 sets of four contiguously numbered queues where each FIFO has a
+                                                         base storage amount of 2.5K bytes of buffering.
                                                          PKO_PTGF(0)_CFG -> FIFO#  0-3
                                                          PKO_PTGF(1)_CFG -> FIFO#  4-7
                                                          PKO_PTGF(2)_CFG -> FIFO#  8-11
@@ -9749,17 +12802,24 @@ union cvmx_pko_ptgfx_cfg {
                                                          001 :     5.0k    0.0k    2.5k    2.5k
                                                          010 :     2.5k    2.5k    5.0k    0.0k
                                                          011 :     5.0k    0.0k    5.0k    0.0k
-                                                         1xx :    10.0k    0.0k    0.0k    0.0k
-                                                         Note that when a FIFO is set to a size of 0K bytes that FIFO_NUM is no longer legal and
-                                                         cannot be assigned to an active MAC. For example, for the set of FIFOs 8-11, if the
-                                                         PKO_PTGF(2)_CFG.SIZE = 3'b100 then FIFO_NUMs 9, 10 and 11 are no longer valid. Only
-                                                         FIFO_NUM = 8 is available from this set for assignment to a MAC because all of the
-                                                         10 Kbytes of buffering was configured to FIFO#8.
+                                                         100 :    10.0k    0.0k    0.0k    0.0k
+                                                         Note: 101-111 are illegal SIZE values and should not be used.
+                                                         Note that when a FIFO is set to a size of 0K bytes, FIFO_NUM is no longer legal and cannot
+                                                         be assigned to an active MAC. For example, for the set of FIFOs 8-11, if the
+                                                         PKO_PTGF(2)_CFG[SIZE] = 3'b100, then FIFO_NUMs 9, 10 and 11 are no longer valid. Only
+                                                         FIFO_NUM = 8 is available from this set for assignment to a MAC because all of the 10
+                                                         Kbytes of buffering was configured to FIFO#8.
                                                          FIFO_NUM = 28 is a virtual FIFO and is used exclusively to indicate the NULL FIFO. Packets
-                                                         targeting the NULL FIFO are dropped by the PKO and their buffers returned to the FPA." */
+                                                         targeting the NULL FIFO are dropped by PKO and their buffers returned to the FPA. The SIZE
+                                                         field for PKO_PTGF(7) should always be set to zero.
+                                                         Modifications to this field require two writes. The first write must assert
+                                                         PKO_PTGFx_CFG[RESET] to reset the address pointers for the FIFOS in this group. The second
+                                                         write clears the RESET bit as well as configures the new SIZE values." */
 #else
 	uint64_t size                         : 3;
-	uint64_t reserved_3_63                : 61;
+	uint64_t rate                         : 3;
+	uint64_t reset                        : 1;
+	uint64_t reserved_7_63                : 57;
 #endif
 	} s;
 	struct cvmx_pko_ptgfx_cfg_s           cn78xx;
@@ -11411,9 +14471,9 @@ union cvmx_pko_status {
 	uint64_t pdm_rdy                      : 1;  /**< PKO PDM block ready for configuration. */
 	uint64_t peb_rdy                      : 1;  /**< PKO PEB block ready for configuration. */
 	uint64_t csi_rdy                      : 1;  /**< PKO CSI block ready for configuration. */
-	uint64_t reserved_4_15                : 12;
-	uint64_t c2qlut_bist_status           : 1;  /**< PKO C2QLUT block BIST status. 0 = BIST passed;
-                                                         1 = BIST failed. */
+	uint64_t reserved_5_15                : 11;
+	uint64_t ncb_bist_status              : 1;  /**< PKO NCB block BIST status. 0 = BIST passed; 1 = BIST failed. */
+	uint64_t c2qlut_bist_status           : 1;  /**< PKO C2QLUT block BIST status. 0 = BIST passed; 1 = BIST failed. */
 	uint64_t pdm_bist_status              : 1;  /**< PKO PDM block BIST status. 0 = BIST passed; 1 = BIST failed. */
 	uint64_t peb_bist_status              : 1;  /**< PKO PEB block BIST status. 0 = BIST passed; 1 = BIST failed. */
 	uint64_t pse_bist_status              : 1;  /**< PKO PSE block BIST status. 0 = BIST passed; 1 = BIST failed. */
@@ -11422,7 +14482,8 @@ union cvmx_pko_status {
 	uint64_t peb_bist_status              : 1;
 	uint64_t pdm_bist_status              : 1;
 	uint64_t c2qlut_bist_status           : 1;
-	uint64_t reserved_4_15                : 12;
+	uint64_t ncb_bist_status              : 1;
+	uint64_t reserved_5_15                : 11;
 	uint64_t csi_rdy                      : 1;
 	uint64_t peb_rdy                      : 1;
 	uint64_t pdm_rdy                      : 1;
diff --git a/arch/mips/include/asm/octeon/cvmx-pow-defs.h b/arch/mips/include/asm/octeon/cvmx-pow-defs.h
index 8e4dd02..7617fea 100644
--- a/arch/mips/include/asm/octeon/cvmx-pow-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pow-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -643,8 +643,10 @@ union cvmx_pow_bist_stat {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
 	uint64_t cam                          : 1;  /**< POW CAM BIST status */
-	uint64_t nbr                          : 3;  /**< NCB receiver memory BIST status */
-	uint64_t nbt                          : 4;  /**< NCB transmitter memory BIST status */
+	uint64_t reserved_10_10               : 1;
+	uint64_t nbr                          : 2;  /**< NCB receiver memory BIST status */
+	uint64_t reserved_6_7                 : 2;
+	uint64_t nbt                          : 2;  /**< NCB transmitter memory BIST status */
 	uint64_t index                        : 1;  /**< Index memory BIST status */
 	uint64_t fidx                         : 1;  /**< Forward index memory BIST status */
 	uint64_t pend                         : 1;  /**< Pending switch memory BIST status */
@@ -654,8 +656,10 @@ union cvmx_pow_bist_stat {
 	uint64_t pend                         : 1;
 	uint64_t fidx                         : 1;
 	uint64_t index                        : 1;
-	uint64_t nbt                          : 4;
-	uint64_t nbr                          : 3;
+	uint64_t nbt                          : 2;
+	uint64_t reserved_6_7                 : 2;
+	uint64_t nbr                          : 2;
+	uint64_t reserved_10_10               : 1;
 	uint64_t cam                          : 1;
 	uint64_t reserved_12_63               : 52;
 #endif
@@ -716,20 +720,20 @@ typedef union cvmx_pow_ds_pc cvmx_pow_ds_pc_t;
  * queue entries.
  * This register also contains the illegal operation error bits and the corresponding interrupt
  * enables as follows:
- * <0> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP from PP in NULL_NULL state
- * <1> Received SWTAG/SWTAG_DESCH/DESCH/UPD_WQP from PP in NULL state
- * <2> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/GET_WORK from PP with pending tag switch to ORDERED
+ *  <0> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP from PP in NULL_NULL state
+ *  <1> Received SWTAG/SWTAG_DESCH/DESCH/UPD_WQP from PP in NULL state
+ *  <2> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/GET_WORK from PP with pending tag switch to ORDERED
  * or ATOMIC
- * <3> Received SWTAG/SWTAG_FULL/SWTAG_DESCH from PP with tag specified as NULL_NULL
- * <4> Received SWTAG_FULL/SWTAG_DESCH from PP with tag specified as NULL
- * <5> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP/GET_WORK/NULL_RD from PP with GET_WORK
- * pending
- * <6> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP/GET_WORK/NULL_RD from PP with NULL_RD
+ *  <3> Received SWTAG/SWTAG_FULL/SWTAG_DESCH from PP with tag specified as NULL_NULL
+ *  <4> Received SWTAG_FULL/SWTAG_DESCH from PP with tag specified as NULL
+ *  <5> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP/GET_WORK/NULL_RD from PP with
+ * GET_WORK pending
+ *  <6> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP/GET_WORK/NULL_RD from PP with NULL_RD
  * pending
- * <7> Received CLR_NSCHED from PP with SWTAG_DESCH/DESCH/CLR_NSCHED pending
- * <8> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP/GET_WORK/NULL_RD from PP with
+ *  <7> Received CLR_NSCHED from PP with SWTAG_DESCH/DESCH/CLR_NSCHED pending
+ *  <8> Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP/GET_WORK/NULL_RD from PP with
  * CLR_NSCHED pending
- * <9> Received illegal opcode
+ *  <9> Received illegal opcode
  * <10> Received ADD_WORK with tag specified as NULL_NULL
  * <11> Received DBG load from PP with DBG load pending
  * <12> Received CSR load from PP with CSR load pending
@@ -1056,21 +1060,25 @@ typedef union cvmx_pow_nos_cnt cvmx_pow_nos_cnt_t;
  * request timeout counter is reset when this register is written.
  * There are two new work request timeout cases:
  * - WAIT bit clear.  The new work request can timeout if the timer expires before the pre-fetch
- * engine has reached the end of all work queues.  This can occur if the executable work queue
- * entry is deep in the queue and the pre-fetch engine is subject to many resets (i.e. high
+ *   engine has reached the end of all work queues.  This can occur if the executable work queue
+ *   entry is deep in the queue and the pre-fetch engine is subject to many resets (i.e. high
  * switch,
- * de-schedule, or new work load from other PP's).  Thus, it is possible for a PP to receive a
+ *   de-schedule, or new work load from other PP's).  Thus, it is possible for a PP to receive a
  * work
- * response with the NO_WORK bit set even though there was at least one executable entry in the
- * work queues.  The other (and typical) scenario for receiving a NO_WORK response with the WAIT
- * bit clear is that the pre-fetch engine has reached the end of all work queues without finding
- * executable work.
+ *   response with the NO_WORK bit set even though there was at least one executable entry in the
+ *   work queues.  The other (and typical) scenario for receiving a NO_WORK response with the
+ * WAIT
+ *   bit clear is that the pre-fetch engine has reached the end of all work queues without
+ * finding
+ *   executable work.
  * - WAIT bit set.  The new work request can timeout if the timer expires before the pre-fetch
- * engine has found executable work.  In this case, the only scenario where the PP will receive a
- * work response with the NO_WORK bit set is if the timer expires.  Note: it is still possible
+ *   engine has found executable work.  In this case, the only scenario where the PP will receive
+ * a
+ *   work response with the NO_WORK bit set is if the timer expires.  Note: it is still possible
  * for
- * a PP to receive a NO_WORK response even though there was at least one executable entry in the
- * work queues.
+ *   a PP to receive a NO_WORK response even though there was at least one executable entry in
+ * the
+ *   work queues.
  * In either case, it's important to note that switches and de-schedules are higher priority
  * operations that can cause the pre-fetch engine to reset.  Thus in a system with many switches
  * or
@@ -1533,8 +1541,7 @@ typedef union cvmx_pow_wa_pcx cvmx_pow_wa_pcx_t;
  * cvmx_pow_wq_int
  *
  * Contains the bits (1 per group) that set work queue interrupts and are used to clear these
- * interrupts.  Also contains the input queue interrupt temporary disable bits (1 per group).
- * For
+ * interrupts.  Also contains the input queue interrupt temporary disable bits (1 per group). For
  * more information regarding this register, see the interrupt section.
  */
 union cvmx_pow_wq_int {
diff --git a/arch/mips/include/asm/octeon/cvmx-pow.h b/arch/mips/include/asm/octeon/cvmx-pow.h
index c4191ce..4fcd6da 100644
--- a/arch/mips/include/asm/octeon/cvmx-pow.h
+++ b/arch/mips/include/asm/octeon/cvmx-pow.h
@@ -87,6 +87,9 @@ extern "C" {
 #define CVMX_ENABLE_POW_CHECKS 1
 #endif
 
+#define CVMX_SSO_NUM_GROUPS_78XX	(256)
+#define CVMX_SSO_NUM_GROUPS_SET		(CVMX_SSO_NUM_GROUPS_78XX/64)
+
 /**
  * Wait flag values for pow functions.
  */
@@ -709,7 +712,7 @@ typedef union {
 		uint64_t pend_get_work:1;
 					    /**< Set when there is a pending GET_WORK */
 		uint64_t pend_get_work_wait:1;
-					    /**< when pend_get_work is set, this biit indicates that the 
+					    /**< when pend_get_work is set, this biit indicates that the
                                                  wait bit was set. */
 		uint64_t pend_nosched:1;
 					    /**< Set when nosched is desired and pend_desched is set. */
@@ -806,7 +809,7 @@ typedef union {
 		uint64_t pend_get_work:1;
 					    /**< Set when there is a pending GET_WORK */
 		uint64_t pend_get_work_wait:1;
-					    /**< when pend_get_work is set, this biit indicates that the 
+					    /**< when pend_get_work is set, this biit indicates that the
                                                  wait bit was set. */
 		uint64_t pend_nosched:1;
 					    /**< Set when nosched is desired and pend_desched is set. */
@@ -1536,6 +1539,13 @@ typedef union {
 
 /* CSR typedefs have been moved to cvmx-pow-defs.h */
 
+/*enum for group priority parameters which needs modification*/
+enum cvmx_sso_group_modify_mask{
+	CVMX_SSO_MODIFY_GROUP_PRIORITY = 0x01,
+	CVMX_SSO_MODIFY_GROUP_WEIGHT = 0x02,
+	CVMX_SSO_MODIFY_GROUP_AFFINITY = 0x04
+};
+
 /**
  * Get the POW tag for this core. This returns the current
  * tag type, tag, group, and POW entry index associated with
@@ -1774,12 +1784,59 @@ static inline void cvmx_pow_work_request_async_nocheck(int scr_addr, cvmx_pow_wa
 
 	/* scr_addr must be 8 byte aligned */
 	data.u64 = 0;
-	data.s.scraddr = scr_addr >> 3;
-	data.s.len = 1;
-	data.s.did = CVMX_OCT_DID_TAG_SWTAG;
-	data.s.wait = wait;
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		data.s_cn78xx.node = cvmx_get_node_num();
+		data.s_cn78xx.scraddr = scr_addr >> 3;
+		data.s_cn78xx.len = 1;
+		data.s_cn78xx.did = CVMX_OCT_DID_TAG_SWTAG;
+		data.s_cn78xx.wait = wait;
+	} else {
+		data.s.scraddr = scr_addr >> 3;
+		data.s.len = 1;
+		data.s.did = CVMX_OCT_DID_TAG_SWTAG;
+		data.s.wait = wait;
+	}
+	cvmx_send_single(data.u64);
+}
+
+/**
+ * Asynchronous work request.  Work is requested from the POW unit, and should later
+ * be checked with function cvmx_pow_work_response_async.
+ * This function does NOT wait for previous tag switches to complete,
+ * so the caller must ensure that there is not a pending tag switch.
+ *
+ * @param scr_addr Scratch memory address that response will be returned to,
+ *                  which is either a valid WQE, or a response with the invalid bit set.
+ *                  Byte address, must be 8 byte aligned.
+ * @param group     group to receive work for.
+ * @param wait      1 to cause response to wait for work to become available (or timeout)
+ *                  0 to cause response to return immediately
+ */
+static inline void cvmx_sso_work_request_grp_async_nocheck(int scr_addr, unsigned group, cvmx_pow_wait_t wait)
+{
+	cvmx_pow_iobdma_store_t data;
+	if (CVMX_ENABLE_POW_CHECKS)
+		__cvmx_pow_warn_if_pending_switch(__func__);
+
+	/* scr_addr must be 8 byte aligned */
+	data.u64 = 0;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		unsigned int node = cvmx_get_node_num();
+		data.s_cn78xx.scraddr = scr_addr >> 3;
+		data.s_cn78xx.len = 1;
+		data.s_cn78xx.did = CVMX_OCT_DID_TAG_SWTAG;
+		data.s_cn78xx.grouped = 1;
+		data.s_cn78xx.index_grp_mask = (node << 8) | (group & 0xff);
+		data.s_cn78xx.wait = wait;
+		data.s_cn78xx.node = node;
+	} else {
+		/* GRP not supported on older chips, ignore it */
+		data.s.scraddr = scr_addr >> 3;
+		data.s.len = 1;
+		data.s.did = CVMX_OCT_DID_TAG_SWTAG;
+		data.s.wait = wait;
+	}
+
 	cvmx_send_single(data.u64);
 }
 
@@ -1838,7 +1895,7 @@ static inline cvmx_wqe_t *cvmx_pow_work_response_async(int scr_addr)
  */
 static inline uint64_t cvmx_pow_work_invalid(cvmx_wqe_t * wqe_ptr)
 {
-	return (wqe_ptr == NULL);
+	return (wqe_ptr == NULL);	/* FIXME: improve */
 }
 
 /**
@@ -1885,6 +1942,7 @@ static inline void cvmx_pow_tag_sw_nocheck(uint32_t tag, cvmx_pow_tag_type_t tag
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		tag_req.s_cn78xx_other.op   = CVMX_POW_TAG_OP_SWTAG;
 		tag_req.s_cn78xx_other.type = tag_type;
+		/* FIXME: tag */
 	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		tag_req.s_cn68xx_other.op = CVMX_POW_TAG_OP_SWTAG;
 		tag_req.s_cn68xx_other.tag = tag;
@@ -1996,7 +2054,7 @@ static inline void cvmx_pow_tag_sw_full_nocheck(cvmx_wqe_t * wqp, uint32_t tag,
 		tag_req.s_cn78xx_other.op = CVMX_POW_TAG_OP_SWTAG_FULL;
 		tag_req.s_cn78xx_other.type = tag_type;
 		tag_req.s_cn78xx_other.grp = group;
-		tag_req.s_cn78xx_other.wqp = CAST64(wqp);
+		tag_req.s_cn78xx_other.wqp = CAST64(wqp); /* FIXME: phys ? */
 	}
 	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		tag_req.s_cn68xx_other.op = CVMX_POW_TAG_OP_SWTAG_FULL;
@@ -2219,6 +2277,116 @@ static inline void cvmx_pow_set_group_mask(uint64_t core_num, uint64_t mask)
 }
 
 /**
+ * This function sets the group mask for a core.  The group mask
+ * indicates which groups each core will accept work from. There are
+ * 256 groups in 78xx.
+ *
+ * @param node 		node number
+ * @param core_num   	core to apply mask to
+ * @param mask_set	78XX has 2 set of masks per core each with 256 groups.
+ *                      Cores can choose which mask set to get work from when
+                        getting the work.
+ * @param mask   	Group mask. There are 256 groups, divided in 4 of 64 bit mask sets.
+ * 	        	Each 1 bit in the mask enables the core to accept work from
+ *      	        the corresponding group.
+ */
+static inline void cvmx_pow_set_group_mask_78xx(int node, uint64_t core_num,
+		uint64_t mask_set, const uint64_t mask[])
+{
+	int grp;
+
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_sso_ppx_sx_grpmskx_t grp_msk;
+		for (grp = 0; grp < CVMX_SSO_NUM_GROUPS_SET; grp++) {
+			if(mask_set & 1) {
+				grp_msk.u64 = cvmx_read_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core_num, 0, grp));
+				grp_msk.s.grp_msk |= mask[grp];
+				cvmx_write_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core_num, 0, grp), grp_msk.u64);
+			}
+			if(mask_set & 2) {
+				grp_msk.u64 = cvmx_read_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core_num, 1, grp));
+				grp_msk.s.grp_msk |= mask[grp];
+				cvmx_write_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core_num, 1, grp), grp_msk.u64);
+			}
+		}
+	}
+}
+
+/**
+ * This function sets the the affinity of group to the cores in 78xx.
+ * It sets up all the cores in core_mask to accept work from the specified group.
+ *
+ * @param node 		node number
+ * @param group  	group to accept work from.
+ * @param core_mask	mask of all the cores which will accept work from this group
+ * @param mask_set	every core has set of 2 masks which can be set to accept work
+ *                      from 256 groups. At the time of get_work, cores can choose which
+ *			mask_set to get work from.
+ */
+static inline void cvmx_sso_set_group_core_affinity(int node, int group,
+		uint64_t core_mask, int mask_set)
+{
+	cvmx_sso_ppx_sx_grpmskx_t grp_msk;
+	int core;
+	int grp_index  = group >> 6;
+	int bit_pos = group % 64;
+
+	//cvmx_dprintf("Vinita group=%d grp_index=%d bit_pos=%d core_mask=0x%lx\n",group,grp_index,bit_pos,core_mask);
+	while((core = __builtin_ffsll(core_mask))) {
+		core--;
+		if(mask_set & 1) {
+			grp_msk.u64 = cvmx_read_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core, 0, grp_index));
+			grp_msk.s.grp_msk |= (uint64_t)(1ull << bit_pos);
+			cvmx_write_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core, 0, grp_index), grp_msk.u64);
+		}
+		if(mask_set & 2) {
+			grp_msk.u64 = cvmx_read_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core, 1, grp_index));
+			grp_msk.s.grp_msk |= (uint64_t)(1ull << bit_pos);
+			cvmx_write_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core, 1, grp_index), grp_msk.u64);
+		}
+		core_mask &= core_mask - 1;
+	}
+
+}
+
+/**
+ * This function sets the priority and group affinity arbitration for each group.
+ *
+ * @param node 		node number
+ * @param group  	group to apply mask parameters to
+ * @param priority	priority of the group relative to other groups
+ *			0x0 - highest priority
+ *			0x7 - lowest priority
+ * @param weight	Cross-group arbitration weight to apply to this group.
+ *			valid values are 1-63
+ *			h/w default is 0x3f
+ * @param affinity	Processor affinity arbitration weight to apply to this group.
+ *			If zero, affinity is disabled.
+ *			valid values are 0-15
+ *			h/w default which is 0xf.
+ * @param modify_mask   mask of the parameters which needs to be modified.
+ *			enum cvmx_sso_group_modify_mask
+ *                      to modify only priority -- set bit0
+ *                      to modify only weight   -- set bit1
+ *			to modify only affinity -- set bit2
+ */
+static inline void cvmx_sso_set_group_priority(int node , int group, int priority,
+					       int weight, int affinity,
+					       enum cvmx_sso_group_modify_mask modify_mask)
+{
+	cvmx_sso_grpx_pri_t grp_pri;
+
+	grp_pri.u64 = cvmx_read_csr_node(node, CVMX_SSO_GRPX_PRI(group));
+	if(modify_mask & CVMX_SSO_MODIFY_GROUP_PRIORITY)
+		grp_pri.s.pri = priority;
+	if(modify_mask & CVMX_SSO_MODIFY_GROUP_WEIGHT)
+		grp_pri.s.weight = weight;
+	if(modify_mask & CVMX_SSO_MODIFY_GROUP_AFFINITY)
+		grp_pri.s.affinity = affinity;
+	cvmx_write_csr_node(node,CVMX_SSO_GRPX_PRI(group),grp_pri.u64);
+}
+
+/**
  * This function sets POW static priorities for a core. Each input queue has
  * an associated priority value.
  *
@@ -2451,7 +2619,7 @@ static inline void cvmx_pow_desched(uint64_t no_sched)
 	CVMX_SYNCWS;
 
 	tag_req.u64 = 0;
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		tag_req.s_cn78xx_other.op = CVMX_POW_TAG_OP_DESCH;
 		tag_req.s_cn78xx_other.no_sched = no_sched;
 	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
@@ -2547,6 +2715,37 @@ static inline uint32_t cvmx_pow_tag_get_hw_bits(uint64_t tag)
 	return (tag & cvmx_build_mask(32 - CVMX_TAG_SW_BITS));
 }
 
+static inline uint64_t cvmx_sso_get_total_wqe_count(void)
+{
+	if(OCTEON_IS_MODEL(OCTEON_CN78XX))
+	{
+		cvmx_sso_grpx_aq_cnt_t sso_iq_com_cnt;
+		int grp = 0;
+		uint64_t cnt = 0;
+
+		for( grp = 0; grp < CVMX_SSO_NUM_GROUPS_78XX; grp++) {
+			sso_iq_com_cnt.u64 = cvmx_read_csr_node(0,CVMX_SSO_GRPX_AQ_CNT(grp));
+			cnt += sso_iq_com_cnt.u64;
+		}
+		return cnt;
+	}
+	else if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+	{
+		cvmx_sso_iq_com_cnt_t sso_iq_com_cnt;
+
+		sso_iq_com_cnt.u64 = cvmx_read_csr(CVMX_SSO_IQ_COM_CNT);
+
+		return (sso_iq_com_cnt.s.iq_cnt);
+	}
+	else
+	{
+		cvmx_pow_iq_com_cnt_t pow_iq_com_cnt;
+
+		pow_iq_com_cnt.u64 = cvmx_read_csr(CVMX_POW_IQ_COM_CNT);
+		return(pow_iq_com_cnt.s.iq_cnt);
+	}
+}
+
 /**
  * Store the current POW internal state into the supplied
  * buffer. It is recommended that you pass a buffer of at least
diff --git a/arch/mips/include/asm/octeon/cvmx-qlm.h b/arch/mips/include/asm/octeon/cvmx-qlm.h
index 928ff2c..7c8dc18 100644
--- a/arch/mips/include/asm/octeon/cvmx-qlm.h
+++ b/arch/mips/include/asm/octeon/cvmx-qlm.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2011  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2011-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 74158 $<hr>
+ * <hr>$Revision: 90025 $<hr>
  */
 
 #ifndef __CVMX_QLM_H__
@@ -50,6 +50,20 @@
 
 #include "cvmx.h"
 
+/*
+ * Interface 0 on the 78xx can be connected to qlm 0 or qlm 2. When interface
+ * 0 is connected to qlm 0, this macro must be set to 0. When interface 0 is
+ * connected to qlm 2, this macro must be set to 1.
+ */
+#define MUX_78XX_IFACE0		0
+
+/*
+ * Interface 1 on the 78xx can be connected to qlm 1 or qlm 3. When interface
+ * 1 is connected to qlm 1, this macro must be set to 0. When interface 1 is
+ * connected to qlm 3, this macro must be set to 1.
+ */
+#define MUX_78XX_IFACE1		0
+
 /* Uncomment this line to print QLM JTAG state */
 /* #define CVMX_QLM_DUMP_STATE 1 */
 
@@ -155,20 +169,60 @@ enum cvmx_qlm_mode {
 	CVMX_QLM_MODE_PCIE,	/* gen2 / gen1 */
 	CVMX_QLM_MODE_PCIE_1X2,	/* 1x2 gen2 / gen1 */
 	CVMX_QLM_MODE_PCIE_2X1,	/* 2x1 gen2 / gen1 */
+	CVMX_QLM_MODE_PCIE_1X1,	/* 1x1 gen2 / gen1 */
 	CVMX_QLM_MODE_SRIO_1X4,	/* 1x4 short / long */
 	CVMX_QLM_MODE_SRIO_2X2,	/* 2x2 short / long */
 	CVMX_QLM_MODE_SRIO_4X1,	/* 4x1 short / long */
 	CVMX_QLM_MODE_ILK,
+	CVMX_QLM_MODE_QSGMII,
+	CVMX_QLM_MODE_SGMII_SGMII,
+	CVMX_QLM_MODE_SGMII_DISABLED,
+	CVMX_QLM_MODE_DISABLED_SGMII,
+	CVMX_QLM_MODE_SGMII_QSGMII,
+	CVMX_QLM_MODE_QSGMII_QSGMII,
+	CVMX_QLM_MODE_QSGMII_DISABLED,
+	CVMX_QLM_MODE_DISABLED_QSGMII,
+	CVMX_QLM_MODE_QSGMII_SGMII,
+	CVMX_QLM_MODE_RXAUI_1X2,
+	CVMX_QLM_MODE_SATA_2X1,
+};
+
+enum cvmx_gmx_inf_mode {
+	CVMX_GMX_INF_MODE_DISABLED = 0,
+	CVMX_GMX_INF_MODE_SGMII = 1,     /* Other interface can be SGMII or QSGMII */
+	CVMX_GMX_INF_MODE_QSGMII = 2,    /* Other interface can be SGMII or QSGMII */
+	CVMX_GMX_INF_MODE_RXAUI = 3,     /* Only interface 0, interface 1 must be DISABLED */
+};
+
+/**
+ * These apply to DLM1 and DLM2 if its not in SATA mode
+ * Manual refers to lanes as follows:
+ *  DML 0 lane 0 == GSER0 lane 0
+ *  DML 0 lane 1 == GSER0 lane 1
+ *  DML 1 lane 2 == GSER1 lane 0
+ *  DML 1 lane 3 == GSER1 lane 1
+ *  DML 2 lane 4 == GSER2 lane 0
+ *  DML 2 lane 5 == GSER2 lane 1
+ */
+enum cvmx_pemx_cfg_mode {
+	CVMX_PEM_MD_GEN2_2LANE = 0,	/* Valid for PEM0(DLM1), PEM1(DLM2) */
+	CVMX_PEM_MD_GEN2_1LANE = 1,	/* Valid for PEM0(DLM1.0), PEM1(DLM1.1,DLM2.0), PEM2(DLM2.1) */
+	CVMX_PEM_MD_GEN2_4LANE = 2,	/* Valid for PEM0(DLM1-2) */
+	/* Reserved */
+	CVMX_PEM_MD_GEN1_2LANE = 4,	/* Valid for PEM0(DLM1), PEM1(DLM2) */
+	CVMX_PEM_MD_GEN1_1LANE = 5,	/* Valid for PEM0(DLM1.0), PEM1(DLM1.1,DLM2.0), PEM2(DLM2.1) */
+	CVMX_PEM_MD_GEN1_4LANE = 6,	/* Valid for PEM0(DLM1-2) */
+	/* Reserved */
 };
 
 /*
  * Read QLM and return mode.
  */
 extern enum cvmx_qlm_mode cvmx_qlm_get_mode(int qlm);
+extern enum cvmx_qlm_mode cvmx_qlm_get_dlm_mode(int dlm_mode, int interface);
 
 extern void cvmx_qlm_display_registers(int qlm);
 
-extern int cvmx_qlm_configure_qlm(int qlm, int speed, int mode,
-				  int rc, int pcie2x1);
+extern int cvmx_qlm_measure_clock(int qlm);
 
 #endif /* __CVMX_QLM_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-rnm-defs.h b/arch/mips/include/asm/octeon/cvmx-rnm-defs.h
index b8df0c5..855c175 100644
--- a/arch/mips/include/asm/octeon/cvmx-rnm-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-rnm-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-rst-defs.h b/arch/mips/include/asm/octeon/cvmx-rst-defs.h
index d2a200d..03f830d 100644
--- a/arch/mips/include/asm/octeon/cvmx-rst-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-rst-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -190,7 +190,7 @@ union cvmx_rst_boot {
 	uint64_t jtcsrdis                     : 1;  /**< When set, internal CSR access via JTAG TAP controller is disabled This field resets to 1
                                                          in Authentik mode, else 0. */
 	uint64_t ejtagdis                     : 1;  /**< When set, external EJTAG access is disabled This field resets to 1 in Authentik mode, else 0. */
-	uint64_t romen                        : 1;  /**< When set, Authentik/eMMC boot ROM is visible in the boot bus address space.  This field
+	uint64_t romen                        : 1;  /**< When set, Authentik/eMMC boot ROM is visible in the boot bus address space. This field
                                                          resets to 1 in an Authentik part or when booting from eMMC. Else, resets to 0. */
 	uint64_t ckill_ppdis                  : 1;  /**< When set, cores other than 0 are disabled during a CHIPKILL.  Writes have no effect when
                                                          RST_BOOT[CHIPKILL]=1. */
@@ -198,12 +198,13 @@ union cvmx_rst_boot {
 	uint64_t vrm_err                      : 1;  /**< VRM did not complete operations within 5.25mS of DCOK being asserted. PLLs were released
                                                          automatically. */
 	uint64_t reserved_37_56               : 20;
-	uint64_t c_mul                        : 7;  /**< Core clock multiplier.
-                                                         C_MUL = (core CLK speed) / (ref clock speed)
-                                                         'ref clock speed' should always be 50MHz. */
-	uint64_t pnr_mul                      : 6;  /**< Coprocessor clock multiplier.
-                                                         PNR_MUL = (coprocessor CLK speed) /(ref clock speed)
-                                                         'ref clock speed' should always be 50MHz. */
+	uint64_t c_mul                        : 7;  /**< Core-clock multiplier. C_MUL = (core-clock speed) / (ref-clock speed). 'ref-clock speed'
+                                                         should always be 50MHz. */
+	uint64_t pnr_mul                      : 6;  /**< Coprocessor-clock multiplier. PNR_MUL = (coprocessor-clock speed) /(ref-clock speed).
+                                                         'ref-clock speed' should always be 50MHz.
+                                                         For PCIe Gen1, the coprocessor-clock speed must be greater than 250MHz; for PCIe Gen2, the
+                                                         coprocessor-clock speed must be greater than 500MHz; for PCIe Gen3, the coprocessor-clock
+                                                         speed must be greater than 800MHz. */
 	uint64_t reserved_21_23               : 3;
 	uint64_t lboot_oci                    : 3;  /**< Last boot cause mask; resets only with DCOK.
                                                          <20> Warm reset due to OCI Link 2 going down.
@@ -464,7 +465,7 @@ union cvmx_rst_power_dbg {
 	struct cvmx_rst_power_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t str                          : 3;  /**< Reserved. INTERNAL: Internal power driver strength. Resets only on Cold Reset. */
+	uint64_t str                          : 3;  /**< Reserved. INTERNAL: Internal power driver strength. Resets only on cold reset. */
 #else
 	uint64_t str                          : 3;
 	uint64_t reserved_3_63                : 61;
@@ -485,7 +486,10 @@ union cvmx_rst_pp_power {
 	struct cvmx_rst_pp_power_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t gate                         : 48; /**< When set, corresponding PP has voltage removed to save power. */
+	uint64_t gate                         : 48; /**< Powerdown enable. When both a bit and the corresponding CIU3_PP_RST bit are set, the core
+                                                         has voltage removed to save power. In typical operation these bits are setup during
+                                                         initialization and PP resets are controlled through CIU3_PP_RST. These bits may only be
+                                                         changed when the corresponding core is in reset using CIU3_PP_RST. */
 #else
 	uint64_t gate                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -517,7 +521,7 @@ union cvmx_rst_soft_prstx {
                                                          If the RST_CTL*[HOST_MODE] = 0, SOFT_PRST resets to 0.
                                                          If the RST_CTL*[HOST_MODE] = 1, SOFT_PRST resets to 1.
                                                          When CN78XX is configured to drive PERST*_L (i.e.
-                                                         RST_CTL0/1[RST_DRV] = 1), this controls the output value on PERST*_L. */
+                                                         RST_CTL(0..3)[RST_DRV] = 1), this controls the output value on PERST*_L. */
 #else
 	uint64_t soft_prst                    : 1;
 	uint64_t reserved_1_63                : 63;
diff --git a/arch/mips/include/asm/octeon/cvmx-sli-defs.h b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
index cb55cf6..4f9cb37 100644
--- a/arch/mips/include/asm/octeon/cvmx-sli-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -284,39 +284,12 @@ static inline uint64_t CVMX_SLI_MAC_CREDIT_CNT2_FUNC(void)
 #define CVMX_SLI_MAC_NUMBER CVMX_SLI_MAC_NUMBER_FUNC()
 static inline uint64_t CVMX_SLI_MAC_NUMBER_FUNC(void)
 {
-	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return 0x0000000000003E00ull;
-			break;
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return 0x0000000000013E00ull;
-			break;
-	}
-	cvmx_warn("CVMX_SLI_MAC_NUMBER not supported on this chip\n");
+	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
+		cvmx_warn("CVMX_SLI_MAC_NUMBER not supported on this chip\n");
 	return 0x0000000000003E00ull;
 }
 #else
-#define CVMX_SLI_MAC_NUMBER CVMX_SLI_MAC_NUMBER_FUNC()
-static inline uint64_t CVMX_SLI_MAC_NUMBER_FUNC(void)
-{
-	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return 0x0000000000003E00ull;
-		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return 0x0000000000013E00ull;
-	}
-	return 0x0000000000003E00ull;
-}
+#define CVMX_SLI_MAC_NUMBER (0x0000000000003E00ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_MEM_ACCESS_CTL CVMX_SLI_MEM_ACCESS_CTL_FUNC()
@@ -742,13 +715,12 @@ static inline uint64_t CVMX_SLI_PKTX_INSTR_HEADER(unsigned long offset)
 	      (OCTEON_IS_MODEL(OCTEON_CN66XX) && ((offset <= 31))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN68XX) && ((offset <= 31))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((offset <= 31))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 63))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_SLI_PKTX_INSTR_HEADER(%lu) is invalid on this chip\n", offset);
-	return 0x0000000000003400ull + ((offset) & 63) * 16;
+	return 0x0000000000003400ull + ((offset) & 31) * 16;
 }
 #else
-#define CVMX_SLI_PKTX_INSTR_HEADER(offset) (0x0000000000003400ull + ((offset) & 63) * 16)
+#define CVMX_SLI_PKTX_INSTR_HEADER(offset) (0x0000000000003400ull + ((offset) & 31) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_PKTX_INT_LEVELS(unsigned long offset)
@@ -1870,7 +1842,7 @@ union cvmx_sli_ctl_status {
 	struct cvmx_sli_ctl_status_cn61xx     cn66xx;
 	struct cvmx_sli_ctl_status_cn63xx     cn68xx;
 	struct cvmx_sli_ctl_status_cn63xx     cn68xxp1;
-	struct cvmx_sli_ctl_status_cn61xx     cn70xx;
+	struct cvmx_sli_ctl_status_cn63xx     cn70xx;
 	struct cvmx_sli_ctl_status_s          cn78xx;
 	struct cvmx_sli_ctl_status_cn61xx     cnf71xx;
 };
@@ -4157,8 +4129,11 @@ union cvmx_sli_int_sum {
 	uint64_t pcnt                         : 1;  /**< Packet counter has an interrupt. The specific rings can be found in SLI_PKT_CNT_INT.
                                                          Throws SLI_INTSN_E::SLI_INT_PCNT. */
 	uint64_t reserved_1_3                 : 3;
-	uint64_t rml_to                       : 1;  /**< A read or write transfer did not complete within 0xFFFF coprocessor-clock cycles. Throws
-                                                         SLI_INTSN_E::SLI_INT_RML_TO. */
+	uint64_t rml_to                       : 1;  /**< A read or write transfer to a RSL that did not complete within SLI_WINDOW_CTL[TIME] sclk
+                                                         cycles, or
+                                                         a notification from the OCI that is has sent a previously written command and can take
+                                                         another within
+                                                         SLI_WINDOW_CTL[OCX_TIME]. Throws a SLI_INTSN_E::SLI_INT_RML_TO. */
 #else
 	uint64_t rml_to                       : 1;
 	uint64_t reserved_1_3                 : 3;
@@ -5773,8 +5748,8 @@ typedef union cvmx_sli_pktx_input_control cvmx_sli_pktx_input_control_t;
 /**
  * cvmx_sli_pkt#_instr_baddr
  *
- * This register contains the start-of-instruction for input packets.
- *
+ * This register contains the start-of-instruction for input packets. The address must be
+ * addressed-aligned to the size of the instruction.
  */
 union cvmx_sli_pktx_instr_baddr {
 	uint64_t u64;
@@ -5870,7 +5845,7 @@ typedef union cvmx_sli_pktx_instr_fifo_rsize cvmx_sli_pktx_instr_fifo_rsize_t;
 /**
  * cvmx_sli_pkt#_instr_header
  *
- * "SLI_PKT[0..63]_INSTR_HEADER = SLI Packet ring# Instruction Header.
+ * "SLI_PKT[0..31]_INSTR_HEADER = SLI Packet ring# Instruction Header.
  * VAlues used to build input packet header."
  */
 union cvmx_sli_pktx_instr_header {
@@ -6015,7 +5990,6 @@ union cvmx_sli_pktx_instr_header {
 	struct cvmx_sli_pktx_instr_header_s   cn68xx;
 	struct cvmx_sli_pktx_instr_header_cn61xx cn68xxp1;
 	struct cvmx_sli_pktx_instr_header_cn61xx cn70xx;
-	struct cvmx_sli_pktx_instr_header_s   cn78xx;
 	struct cvmx_sli_pktx_instr_header_cn61xx cnf71xx;
 };
 typedef union cvmx_sli_pktx_instr_header cvmx_sli_pktx_instr_header_t;
@@ -6891,8 +6865,8 @@ typedef union cvmx_sli_pkt_input_control cvmx_sli_pkt_input_control_t;
 /**
  * cvmx_sli_pkt_instr_enb
  *
- * This register enables the instruction fetch for a packet ring.
- *
+ * "This register enables the instruction fetch for a packet ring. This is the PF version also
+ * see SLI_PKT#_INPUT_CONTROL[ENB]."
  */
 union cvmx_sli_pkt_instr_enb {
 	uint64_t u64;
@@ -7012,7 +6986,6 @@ typedef union cvmx_sli_pkt_int cvmx_sli_pkt_int_t;
 /**
  * cvmx_sli_pkt_int_levels
  *
- * 0x90F0 reserved SLI_PKT_PCIE_PORT2
  * SLI_PKT_INT_LEVELS = SLI's Packet Interrupt Levels
  * Output packet interrupt levels.
  */
@@ -7323,8 +7296,8 @@ typedef union cvmx_sli_pkt_out_bp_en cvmx_sli_pkt_out_bp_en_t;
 /**
  * cvmx_sli_pkt_out_enb
  *
- * This register enables the output packet engines.
- *
+ * "This register enables the output packet engines. This is the PF version. Also see
+ * SLI_PKT#_OUTPUT_CONTROL[ENB]."
  */
 union cvmx_sli_pkt_out_enb {
 	uint64_t u64;
@@ -7425,9 +7398,6 @@ typedef union cvmx_sli_pkt_pcie_port cvmx_sli_pkt_pcie_port_t;
 /**
  * cvmx_sli_pkt_port_in_rst
  *
- * 91c0 reserved
- * 91d0 reserved
- * 91e0 reserved
  * SLI_PKT_PORT_IN_RST = SLI Packet Port In Reset
  * Vector bits related to ring-port for ones that are reset.
  */
@@ -8273,6 +8243,22 @@ union cvmx_sli_window_ctl {
 	uint64_t u64;
 	struct cvmx_sli_window_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t ocx_time                     : 32; /**< When a command acknowledge or a request to fetch read-data is expected from the OCI, The
+                                                         SLI will
+                                                         wait this many sclks before determining the OCI is not going to respond and timeout the
+                                                         request. */
+	uint64_t time                         : 32; /**< Time to wait in core clocks for a
+                                                         BAR0 access to completeon the NCB
+                                                         before timing out. A value of 0 will cause no
+                                                         timeouts. A minimum value of 0x200000 should be
+                                                         used when this register is not set to 0x0. */
+#else
+	uint64_t time                         : 32;
+	uint64_t ocx_time                     : 32;
+#endif
+	} s;
+	struct cvmx_sli_window_ctl_cn61xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
 	uint64_t time                         : 32; /**< Time to wait in core clocks for a
                                                          BAR0 access to completeon the NCB
@@ -8283,16 +8269,15 @@ union cvmx_sli_window_ctl {
 	uint64_t time                         : 32;
 	uint64_t reserved_32_63               : 32;
 #endif
-	} s;
-	struct cvmx_sli_window_ctl_s          cn61xx;
-	struct cvmx_sli_window_ctl_s          cn63xx;
-	struct cvmx_sli_window_ctl_s          cn63xxp1;
-	struct cvmx_sli_window_ctl_s          cn66xx;
-	struct cvmx_sli_window_ctl_s          cn68xx;
-	struct cvmx_sli_window_ctl_s          cn68xxp1;
-	struct cvmx_sli_window_ctl_s          cn70xx;
+	} cn61xx;
+	struct cvmx_sli_window_ctl_cn61xx     cn63xx;
+	struct cvmx_sli_window_ctl_cn61xx     cn63xxp1;
+	struct cvmx_sli_window_ctl_cn61xx     cn66xx;
+	struct cvmx_sli_window_ctl_cn61xx     cn68xx;
+	struct cvmx_sli_window_ctl_cn61xx     cn68xxp1;
+	struct cvmx_sli_window_ctl_cn61xx     cn70xx;
 	struct cvmx_sli_window_ctl_s          cn78xx;
-	struct cvmx_sli_window_ctl_s          cnf71xx;
+	struct cvmx_sli_window_ctl_cn61xx     cnf71xx;
 };
 typedef union cvmx_sli_window_ctl cvmx_sli_window_ctl_t;
 
diff --git a/arch/mips/include/asm/octeon/cvmx-smix-defs.h b/arch/mips/include/asm/octeon/cvmx-smix-defs.h
index eae1bb2..9405d86 100644
--- a/arch/mips/include/asm/octeon/cvmx-smix-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-smix-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-spxx-defs.h b/arch/mips/include/asm/octeon/cvmx-spxx-defs.h
index d9e326d..0f246a7 100644
--- a/arch/mips/include/asm/octeon/cvmx-spxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-spxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h b/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
index 0d11df1..4355cfb 100644
--- a/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-sriox-defs.h b/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
index 4f46c7b..6fff67c 100644
--- a/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-srxx-defs.h b/arch/mips/include/asm/octeon/cvmx-srxx-defs.h
index 48adf21..af7a998 100644
--- a/arch/mips/include/asm/octeon/cvmx-srxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-srxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-sso-defs.h b/arch/mips/include/asm/octeon/cvmx-sso-defs.h
index 1e2c275..7778474 100644
--- a/arch/mips/include/asm/octeon/cvmx-sso-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sso-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -2024,10 +2024,12 @@ union cvmx_sso_err0 {
 	uint64_t fff_sbe                      : 1;  /**< Single-bit error for  RAM. Throws SSO_INTSN_E::SSO_ERR0_FFF_SBE. */
 	uint64_t wes_dbe                      : 1;  /**< Double-bit error for WES RAM. Throws SSO_INTSN_E::SSO_ERR0_WES_DBE. */
 	uint64_t wes_sbe                      : 1;  /**< Single-bit error for WES RAM. Throws SSO_INTSN_E::SSO_ERR0_WES_SBE. */
-	uint64_t reserved_5_31                : 27;
+	uint64_t reserved_6_31                : 26;
+	uint64_t addwq_dropped                : 1;  /**< Add work dropped due to wrong command/DID requested. Throws
+                                                         SSO_INTSN_E::SSO_ERR0_ADD_WQDROPPED. */
 	uint64_t awempty                      : 1;  /**< Received add work with tag specified as EMPTY. Throws SSO_INTSN_E::SSO_ERR0_AWEMPTY. */
 	uint64_t grpdis                       : 1;  /**< Add work to disabled group. An ADDWQ was received and dropped to a group with
-                                                         SSO_GRP(0..255)_TAQ_THR[RSVD_THR] = 0. Throws SSO_INTSN_E::SSO_ERR0_GRPDIS. */
+                                                         SSO_GRP(0..255)_IAQ_THR[RSVD_THR] = 0. Throws SSO_INTSN_E::SSO_ERR0_GRPDIS. */
 	uint64_t bfp                          : 1;  /**< Bad-fill-packet error. The WAE VLD_CRC field was incorrect, or the XAQ next address was
                                                          zero. Throws SSO_INTSN_E::SSO_ERR0_BFP. */
 	uint64_t awe                          : 1;  /**< Out-of-memory error. (ADDWQ request is dropped.) Throws SSO_INTSN_E::SSO_ERR0_AWE. */
@@ -2039,7 +2041,8 @@ union cvmx_sso_err0 {
 	uint64_t bfp                          : 1;
 	uint64_t grpdis                       : 1;
 	uint64_t awempty                      : 1;
-	uint64_t reserved_5_31                : 27;
+	uint64_t addwq_dropped                : 1;
+	uint64_t reserved_6_31                : 26;
 	uint64_t wes_sbe                      : 1;
 	uint64_t wes_dbe                      : 1;
 	uint64_t fff_sbe                      : 1;
@@ -2633,8 +2636,9 @@ union cvmx_sso_grpx_taq_thr {
 	uint64_t reserved_43_47               : 5;
 	uint64_t max_thr                      : 11; /**< Max threshold for this transitory admission queue, in buffers of 13 entries. Must be >= 3,
                                                          must be >= [RSVD_THR], and to insure full streaming performance on this group, should be
-                                                         at least 16 buffers. SSO may exceed this count by one buffer if and only if persistently
-                                                         backpressured by IOBI. Must not be changed after traffic is sent to this group. */
+                                                         at least 16 buffers. SSO may exceed this count using unreserved free buffers if and only
+                                                         if persistently backpressured by IOBI. Must not be changed after traffic is sent to this
+                                                         group. */
 	uint64_t reserved_11_31               : 21;
 	uint64_t rsvd_thr                     : 11; /**< Reserved threshold for this transitory admission queue, in buffers of 13 entries. Must be
                                                          at least 3 buffers for any groups that are to be used. Changes to this field must also
@@ -2728,14 +2732,9 @@ union cvmx_sso_gwe_cfg {
 	uint64_t gwe_rfpgw_dis                : 1;  /**< Disable periodic restart of GWE for pending get_work */
 	uint64_t odu_prf_dis                  : 1;  /**< Disable ODU-initiated prefetches of WQEs into L2C
                                                          For diagnostic use only. */
-	uint64_t odu_bmp_dis                  : 1;  /**< Disable ODU bumps.
-                                                         If SSO_PP_STRICT is true, could
-                                                         prevent forward progress under some circumstances.
-                                                         For diagnostic use only. */
-	uint64_t reserved_0_7                 : 8;
+	uint64_t reserved_0_8                 : 9;
 #else
-	uint64_t reserved_0_7                 : 8;
-	uint64_t odu_bmp_dis                  : 1;
+	uint64_t reserved_0_8                 : 9;
 	uint64_t odu_prf_dis                  : 1;
 	uint64_t gwe_rfpgw_dis                : 1;
 	uint64_t odu_ffpgw_dis                : 1;
@@ -2798,13 +2797,15 @@ union cvmx_sso_gwe_cfg {
 	} cn68xxp1;
 	struct cvmx_sso_gwe_cfg_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_8_63                : 56;
+	uint64_t reserved_9_63                : 55;
+	uint64_t dis_wgt_credit               : 1;  /**< Disable group weight credits. When set, groups have infinite weight credit. */
 	uint64_t ws_retries                   : 8;  /**< Work slot retries. When a given work-slot performs this number of retries without
                                                          successfully finding work then NO_WORK will be returned. Zero disables the retry counter.
                                                          Values 1, 2, 3 are reserved. */
 #else
 	uint64_t ws_retries                   : 8;
-	uint64_t reserved_8_63                : 56;
+	uint64_t dis_wgt_credit               : 1;
+	uint64_t reserved_9_63                : 55;
 #endif
 	} cn78xx;
 };
@@ -2911,13 +2912,16 @@ union cvmx_sso_ientx_links {
 	struct cvmx_sso_ientx_links_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t prev_index                   : 12; /**< The previous entry in the tag chain. Unpredictable if the entry is at the head of the list. */
-	uint64_t reserved_12_15               : 4;
+	uint64_t prev_index                   : 12; /**< The previous entry in the tag chain. Unpredictable if the entry is at the head of the list
+                                                         or the head of a conflicted tag chain. */
+	uint64_t reserved_13_15               : 3;
+	uint64_t next_index_vld               : 1;  /**< The NEXT_INDEX is valid. Unpredictable unless the entry is the tail entry of an atomic tag chain. */
 	uint64_t next_index                   : 12; /**< The next entry in the tag chain or conflicted tag chain. Unpredictable if the entry is at
                                                          the tail of the list. */
 #else
 	uint64_t next_index                   : 12;
-	uint64_t reserved_12_15               : 4;
+	uint64_t next_index_vld               : 1;
+	uint64_t reserved_13_15               : 3;
 	uint64_t prev_index                   : 12;
 	uint64_t reserved_28_63               : 36;
 #endif
@@ -2965,7 +2969,7 @@ union cvmx_sso_ientx_qlinks {
 	struct cvmx_sso_ientx_qlinks_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t next_index                   : 12; /**< The next entry in the IQ/AQ/DQ. */
+	uint64_t next_index                   : 12; /**< The next entry in the AQ/CQ/DQ. */
 #else
 	uint64_t next_index                   : 12;
 	uint64_t reserved_12_63               : 52;
@@ -3649,8 +3653,8 @@ union cvmx_sso_ppx_sx_grpmskx {
                                                          GRPMSK(3) for groups <255:192>
                                                          A value of 0x0 in each GRPMSK(0..3) for a given core prevents the core from receiving new
                                                          work. Cores that will never receive work should use GRPMSK(0..3)=0x0; while this setting
-                                                         is not special in CN78XX, for backward and forward compatibility this may enable
-                                                         reallocation of internal resources to the remaining (non-zero-mask) cores. */
+                                                         is not special in SSO, for backward and forward compatibility this may enable reallocation
+                                                         of internal resources to the remaining (non-zero-mask) cores. */
 #else
 	uint64_t grp_msk                      : 64;
 #endif
@@ -3990,8 +3994,8 @@ union cvmx_sso_sl_ppx_links {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t tailc                        : 1;  /**< Set when this SSO entry is the tail of the conflicted tail chain, and so there are no
                                                          additional conflicts on this tag chain. */
-	uint64_t reserved_61_62               : 2;
-	uint64_t index                        : 13; /**< The SSO entry attached to the core. */
+	uint64_t reserved_60_62               : 3;
+	uint64_t index                        : 12; /**< The SSO entry attached to the core. */
 	uint64_t reserved_38_47               : 10;
 	uint64_t grp                          : 10; /**< The group attached to the core (updated when new tag list entered on SWTAG_FULL). The
                                                          upper two bits are hardcoded to the node number. */
@@ -4000,20 +4004,19 @@ union cvmx_sso_sl_ppx_links {
 	uint64_t reserved_25_25               : 1;
 	uint64_t revlink_index                : 12; /**< Prior SSO entry in the tag list when HEAD==0 and TT is not UNTAGGED nor EMPTY, otherwise
                                                          unpredictable. */
-	uint64_t reserved_11_12               : 2;
-	uint64_t link_index                   : 11; /**< Next SSO entry in the tag list when TAIL==0 and TT is not UNTAGGED nor EMPTY, otherwise
-                                                         unpredictable. */
+	uint64_t link_index_vld               : 1;  /**< LINK_INDEX is valid when TAIL==1 and TT is ATOMIC, otherwise unpredictable. */
+	uint64_t link_index                   : 12; /**< Next SSO entry in the tag list when TAILC==0 and TT is ATOMIC, otherwise unpredictable. */
 #else
-	uint64_t link_index                   : 11;
-	uint64_t reserved_11_12               : 2;
+	uint64_t link_index                   : 12;
+	uint64_t link_index_vld               : 1;
 	uint64_t revlink_index                : 12;
 	uint64_t reserved_25_25               : 1;
 	uint64_t tail                         : 1;
 	uint64_t head                         : 1;
 	uint64_t grp                          : 10;
 	uint64_t reserved_38_47               : 10;
-	uint64_t index                        : 13;
-	uint64_t reserved_61_62               : 2;
+	uint64_t index                        : 12;
+	uint64_t reserved_60_62               : 3;
 	uint64_t tailc                        : 1;
 #endif
 	} s;
@@ -4031,7 +4034,7 @@ union cvmx_sso_sl_ppx_pendtag {
 	uint64_t u64;
 	struct cvmx_sso_sl_ppx_pendtag_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pend_switch                  : 1;  /**< Send when there is a pending SWTAG, SWTAG_DESCHED, or SWTAG_FULL to ORDERED or ATOMIC. If
+	uint64_t pend_switch                  : 1;  /**< Set when there is a pending SWTAG, SWTAG_DESCHED, or SWTAG_FULL to ORDERED or ATOMIC. If
                                                          the register read was issued after an indexed GET_WORK, the DESCHED portion of a
                                                          SWTAG_DESCHED cannot still be pending. */
 	uint64_t pend_get_work                : 1;  /**< Set when there is a pending GET_WORK. */
@@ -4078,7 +4081,7 @@ union cvmx_sso_sl_ppx_pendwqp {
 	uint64_t u64;
 	struct cvmx_sso_sl_ppx_pendwqp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pend_switch                  : 1;  /**< Send when there is a pending SWTAG, SWTAG_DESCHED, or SWTAG_FULL to ORDERED or ATOMIC. If
+	uint64_t pend_switch                  : 1;  /**< Set when there is a pending SWTAG, SWTAG_DESCHED, or SWTAG_FULL to ORDERED or ATOMIC. If
                                                          the status load was issued after an indexed GET_WORK, the DESCHED portion of a
                                                          SWTAG_DESCHED cannot still be pending. */
 	uint64_t pend_get_work                : 1;  /**< Set when there is a pending GET_WORK. */
@@ -4641,7 +4644,8 @@ union cvmx_sso_ws_cfg {
 	struct cvmx_sso_ws_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_56_63               : 8;
-	uint64_t ocla_bp                      : 8;  /**< Enable OCLA backpressure stalls. For diagnostic use only. INTERNAL:
+	uint64_t ocla_bp                      : 8;  /**< Enable OCLA backpressure stalls. For diagnostic use only.
+                                                         INTERNAL:
                                                          <55> NCBB input fifo stall (ncbo.)
                                                          <54> Work-slot response. (arbrsp.)
                                                          <53> Work-slot switching of descheduled work entries. (arbx.)
@@ -4650,13 +4654,17 @@ union cvmx_sso_ws_cfg {
                                                          <50> Work-slot CAM access. (arbc.)
                                                          <49> Work-slot RAM access. (arbr.)
                                                          <48> Work-slot pushes to AQ, CQ, DQ. (arbq.) */
-	uint64_t reserved_2_47                : 46;
+	uint64_t reserved_4_47                : 44;
+	uint64_t arbc_step_en                 : 1;  /**< Enable single-stepping WS CAM arbiter, twice per 16 clocks. For diagnostic use only. */
+	uint64_t ncbo_step_en                 : 1;  /**< Enable single-stepping commands from NCBO, once per 32 clocks. For diagnostic use only. */
 	uint64_t soc_ccam_dis                 : 1;  /**< Disable power saving SOC conditional CAM. */
 	uint64_t sso_cclk_dis                 : 1;  /**< Disable power saving SSO conditional clocking, */
 #else
 	uint64_t sso_cclk_dis                 : 1;
 	uint64_t soc_ccam_dis                 : 1;
-	uint64_t reserved_2_47                : 46;
+	uint64_t ncbo_step_en                 : 1;
+	uint64_t arbc_step_en                 : 1;
+	uint64_t reserved_4_47                : 44;
 	uint64_t ocla_bp                      : 8;
 	uint64_t reserved_56_63               : 8;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-stxx-defs.h b/arch/mips/include/asm/octeon/cvmx-stxx-defs.h
index 4e1f5ce..9499bdb 100644
--- a/arch/mips/include/asm/octeon/cvmx-stxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-stxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-sysinfo.h b/arch/mips/include/asm/octeon/cvmx-sysinfo.h
index 13c4c15..53eae3e 100644
--- a/arch/mips/include/asm/octeon/cvmx-sysinfo.h
+++ b/arch/mips/include/asm/octeon/cvmx-sysinfo.h
@@ -42,7 +42,7 @@
  *
  * This module provides system/board information obtained by the bootloader.
  *
- * <hr>$Revision: 83018 $<hr>
+ * <hr>$Revision: 87487 $<hr>
  *
  */
 
@@ -51,6 +51,7 @@
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 #include "cvmx-app-init.h"
+#include "cvmx-access.h"
 #endif
 #include "cvmx-coremask.h"
 
@@ -92,7 +93,7 @@ struct cvmx_sysinfo {
 	cvmx_coremask_t core_mask;
 			     /**< coremask defining cores running application */
 	uint32_t init_core;
-			     /**< Deprecated, use cvmx_coremask_first_core() to select init core */
+			     /**< The initial boot core for this application */
 	uint64_t exception_base_addr;
 				       /**< exception base address, as set by bootloader */
 	uint32_t cpu_clock_hz;
@@ -147,6 +148,34 @@ typedef struct cvmx_sysinfo cvmx_sysinfo_t;
 
 extern struct cvmx_sysinfo *cvmx_sysinfo_get(void);
 
+/*
+ * This function determines if the current core is the initial boot core
+ * for the application, which may not necesarily be the numerically lowest
+ * core number in the core mask.
+ * RETURNS 1 if the current core is the initial core for the application,
+ * -1 on error, and 0 otherwise.
+ *
+ * NOTE: Use this function instead of OCTEON_IS_FIRST_CORE() or 
+ * cvmx_coremask_is_first_core() to protect code sections that
+ * need to be executted only on one core.
+ * Also, note that when hotplugging is enabled, the initial core
+ * will not be allowed to be unplugged, unless the entire application is
+ * being shut down.
+ */
+static inline int cvmx_is_init_core(void)
+{
+#ifdef CVMX_BUILD_FOR_TOOLCHAIN
+  extern int __octeon_init_core_p;
+  return __octeon_init_core_p;
+#else
+	struct cvmx_sysinfo * si = cvmx_sysinfo_get();
+	if( si != NULL )
+		return si->init_core == cvmx_get_core_num();
+	else
+		return -1;
+#endif
+}
+
 /**
  * This function adds the current cpu to sysinfo coremask
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h b/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
index d5b937b..82342a7 100644
--- a/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -637,13 +637,14 @@ union cvmx_uctlx_ctl {
 	uint64_t u64;
 	struct cvmx_uctlx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t clear_bist                   : 1;  /**< BIST fast-clear mode select.
+	uint64_t clear_bist                   : 1;  /**< BIST fast-clear mode select. A BIST run with this bit set clears all entries in USBH RAMs
+                                                         to 0x0.
                                                          There are 2 major modes of BIST: full and clear. Full BIST is run by the BIST state
-                                                         machine when clear_bist is deasserted during BIST. Clear BIST is run if clear_bist is
-                                                         asserted during BIST. A Clear BIST run will simply clear all entries in USBH RAMs to 0x0.
+                                                         machine when CLEAR_BIST is deasserted during BIST. Clear BIST is run if CLEAR_BIST is
+                                                         asserted during BIST.
                                                          To avoid race conditions, software must first perform a CSR write operation that puts the
-                                                         clear_bist setting into the correct state and then perform another CSR write operation to
-                                                         set the BIST trigger (keeping the clear_bist state constant).
+                                                         CLEAR_BIST setting into the correct state and then perform another CSR write operation to
+                                                         set the BIST trigger (keeping the CLEAR_BIST state constant).
                                                          CLEAR BIST completion is indicated by UCTL(0)_BIST_STATUS[NDONE]. A BIST clear operation
                                                          takes almost 2,000 host-controller-clock cycles for the largest RAM. */
 	uint64_t start_bist                   : 1;  /**< Rising edge starts BIST on the memories in USBH.
@@ -655,129 +656,68 @@ union cvmx_uctlx_ctl {
                                                          BIST defect status can be checked after FULL BIST completion, both of which are indicated
                                                          in UCTL(0)_BIST_STATUS. The full BIST run takes almost 80,000 host-controller-clock cycles
                                                          for the largest RAM. */
-	uint64_t ref_clk_sel                  : 2;  /**< Choose reference clock source for the SuperSpeed and HighSpeed PLL blocks.
-                                                           0x0 = Reference clock source for both PLLs come from the USB pads.
-                                                           0x1 = Reference clock source for SuperSpeed PLL is from the USB pads,
-                                                                 reference clock source for HighSpeed PLL is PLL_REF_CLK.
-                                                           0x2 = Reserved.
-                                                           0x3 = Reference clock source for both PLLs come from PLL_REF_CLK.
-                                                         The PLL_REF_CLK is a 50MHz reference clock from an on-chip PLL.
+	uint64_t ref_clk_sel                  : 2;  /**< Reference clock select. Choose reference clock source for the SuperSpeed and HighSpeed PLL
+                                                         blocks.
+                                                         0x0 = Reference clock source for both PLLs come from the USB pads.
+                                                         0x1 = Reserved
+                                                         0x2 = Reserved.
+                                                         0x3 = Reserved.
                                                          This value can be changed only during UPHY_RST.
-                                                         Note: If REF_CLK_SEL = 0x0, then the reference clock input cannot be
-                                                         spread-spectrum. */
+                                                         Note: If REF_CLK_SEL = 0x0, then the reference clock input cannot be spread-spectrum.
+                                                         INTERNAL: For the 0x1 selection, reference clock source for SuperSpeed PLL is from the USB
+                                                         pads, reference clock source for HighSpeed PLL is PLL_REF_CLK. But in 78xx, PLL_REF_CLK
+                                                         cannot be routed to USB without violating jitter requirements */
 	uint64_t ssc_en                       : 1;  /**< Enables spread-spectrum clock production in the SuperSpeed function.
                                                          If the input reference clock for the SuperSpeed PLL is already spread-spectrum,
                                                          then do not enable this function. The clocks sourced to the SuperSpeed function
                                                          must have spread-spectrum to be compliant with the USB specification.
                                                          The HighSpeed PLL cannot support a spread-spectrum input, so REF_CLK_SEL = 0x0
-                                                         must enable this feature. The PLL_REF_CLK is not spread-spectrum, so REF_CLK_SEL
-                                                         = 0x3 must enable this feature.
+                                                         must enable this feature.
                                                          This value may only be changed during UPHY_RST. */
-	uint64_t ssc_range                    : 3;  /**< Selects the range of spread spectrum modulation when ssc_en is asserted and the PHY is
-                                                         spreading the SuperSpeed transmit clocks.
+	uint64_t ssc_range                    : 3;  /**< Spread-spectrum clock range. Selects the range of spread-spectrum modulation when SSC_EN
+                                                         is asserted and the PHY is spreading the SuperSpeed transmit clocks.
                                                          Applies a fixed offset to the phase accumulator.
-                                                           0x0 : -4980 ppm downspread of clock
-                                                           0x1 : -4492 ppm
-                                                           0x2 : -4003 ppm
-                                                           others: reserved
-                                                         All of these settings are within the USB 3.0 specification.
-                                                         The amount of EMI emission reduction might decrease as the
-                                                         SSC_RANGE increases; therefore, the SSC_RANGE settings can
-                                                         be registered to enable the amount of spreading to be adjusted
-                                                         on a per-application basis.
-                                                         This value may only be changed during UPHY_RST. */
+                                                         0x0 = -4980 ppm downspread of clock
+                                                         0x1 = -4492 ppm
+                                                         0x2 = -4003 ppm
+                                                         0x3-0x7 = reserved
+                                                         All of these settings are within the USB 3.0 specification. The amount of EMI emission
+                                                         reduction might decrease as the SSC_RANGE increases; therefore, the SSC_RANGE settings can
+                                                         be registered to enable the amount of spreading to be adjusted on a per-application basis.
+                                                         This value can be changed only during UPHY_RST. */
 	uint64_t ssc_ref_clk_sel              : 9;  /**< Enables non-standard oscillator frequencies to generate targeted MPLL output rates. Input
                                                          corresponds to the frequency-synthesis coefficient.
                                                          [55:53]: modulus - 1,
                                                          [52:47]: 2's complement push amount
-                                                         A value of 0x0 means this feature is disabled.
-                                                         The legal values are:
-                                                           If REF_CLK_SEL = 0x0 then:
-                                                             0x0 is the only legal value.
-                                                           If REF_CLK_SEL = 0x1 then:
-                                                             0x108: if the external reference clock is 19.2MHz, 24MHz, 26MHz, 38.4MHz, 48MHz,
-                                                                    52MHz, 76.8MHz, 96MHz, 104MHz.
-                                                             0x0: if the external reference clock is another supported frequency (see list
-                                                                  in MPLL_MULTIPLIER description).
-                                                           If REF_CLK_SEL = 0x3 then:
-                                                             0x0 is the only legal value.
-                                                         All other values are reserved.
-                                                         This value may only be changed during UPHY_RST.
-                                                         Note: If REF_CLK_SEL = 0x1 or 0x3, then MPLL_MULTPLIER, REF_CLK_DIV2, and SSC_REF_CLK_SEL
-                                                         must all be programmed to the same frequency setting. */
-	uint64_t mpll_multiplier              : 7;  /**< Multiplies the reference clock to a frequency suitable for intended operating speed. The
-                                                         legal values are:
-                                                           If REF_CLK_SEL = 0x0 then:
-                                                             0x0 is the only legal value.
-                                                           If REF_CLK_SEL = 0x1 then:
-                                                             0x02 =  19.2MHz on the external reference clock
-                                                             0x7D =  20  MHz on the external reference clock
-                                                             0x68 =  24  MHz on the external reference clock
-                                                             0x64 =  25  MHz on the external reference clock
-                                                             0x60 =  26  MHz on the external reference clock
-                                                             0x41 =  38.4MHz on the external reference clock
-                                                             0x7D =  40  MHz on the external reference clock
-                                                             0x34 =  48  MHz on the external reference clock
-                                                             0x32 =  50  MHz on the external reference clock
-                                                             0x30 =  52  MHz on the external reference clock
-                                                             0x41 =  76.8MHz on the external reference clock
-                                                             0x1A =  96  MHz on the external reference clock
-                                                             0x19 = 100  MHz on the external reference clock
-                                                             0x18 = 104  MHz on the external reference clock if REF_CLK_DIV2 is 0x0
-                                                             0x30 = 104  MHz on the external reference clock if REF_CLK_DIV2 is 0x1
-                                                             0x28 = 125  MHz on the external reference clock
-                                                             0x19 = 200  MHz on the external reference clock
-                                                           If REF_CLK_SEL = 0x3 then:
-                                                             0x32 is the only legal value.
-                                                         All other values are reserved.
+                                                         Must leave at reset value of 0x0.
+                                                         This value may only be changed during UPHY_RST. */
+	uint64_t mpll_multiplier              : 7;  /**< Multiplies the reference clock to a frequency suitable for intended operating speed.
+                                                         Must leave at reset value of 0x0.
                                                          This value may only be changed during UPHY_RST.
-                                                         Note: If REF_CLK_SEL = 0x1 or 0x3, then MPLL_MULTPLIER, REF_CLK_DIV2, and SSC_REF_CLK_SEL
-                                                         must all be programmed to the same frequency setting. When REF_CLK_SEL = 0x0, this value
-                                                         is
-                                                         superceded by the REF_CLK_FSEL<5:3> selection. */
+                                                         This value is superceded by the REF_CLK_FSEL<5:3> selection. */
 	uint64_t ref_ssp_en                   : 1;  /**< Enables reference clock to the prescaler for SuperSpeed function. This should always be
-                                                         enabled since this output clock is used to drive the UAHC suspend-mode clock during
-                                                         low-power states.
+                                                         enabled since this output clock is used to drive the UAHC suspend-mode clock during low-
+                                                         power states.
                                                          This value can be changed only during UPHY_RST or during low-power states.
-                                                         The reference clock must be running and stable before UPHY_RST is deasserted and
-                                                         before REF_SSP_EN is asserted. */
+                                                         The reference clock must be running and stable before UPHY_RST is deasserted and before
+                                                         REF_SSP_EN is asserted. */
 	uint64_t ref_clk_div2                 : 1;  /**< Divides the reference clock by 2 before feeding it into the REF_CLK_FSEL divider.
-                                                         The legal values are:
-                                                           If REF_CLK_SEL = 0x0, then:
-                                                             all reference clock frequencies: 0x0 is the only legal value.
-                                                           If REF_CLK_SEL = 0x1, then:
-                                                             0x1: if external reference clock is 125MHz, 40MHz, 76.8MHz, or 200MHz.
-                                                             0x0 or 0x: if external reference clock is 104MHz (depending on MPLL_MULTIPLIER
-                                                         setting)
-                                                             0x0: if external reference clock is another supported frequency,
-                                                                  (see list in MPLL_MULTIPLIER description).
-                                                           If REF_CLK_SEL = 0x3 then:
-                                                             0x0 is the only legal value.
-                                                         This value can be changed only during UPHY_RST.
-                                                         Note: If REF_CLK_SEL = 0x1 or 0x3, then MPLL_MULTPLIER, REF_CLK_DIV2, and SSC_REF_CLK_SEL
-                                                         must all be programmed to the same frequency setting. */
-	uint64_t ref_clk_fsel                 : 6;  /**< Selects the reference clock frequency for the SuperSpeed and HighSpeed PLL blocks.
-                                                         The legal values are:
-                                                           If REF_CLK_SEL = 0x0 then:
-                                                             0x27: external reference clock 100  MHz
-                                                             0x2A: external reference clock  24  MHz
-                                                             0x31: external reference clock  20  MHz
-                                                             0x38: external reference clock  19.2MHz
-                                                           If REF_CLK_SEL = 0x1 then:
-                                                             0x7 is the only legal value.
-                                                           If REF_CLK_SEL = 0x3 then:
-                                                             0x7 is the only legal value.
+                                                         Must leave at reset value of 0x0.
+                                                         This value can be changed only during UPHY_RST. */
+	uint64_t ref_clk_fsel                 : 6;  /**< Selects the reference clock frequency for the SuperSpeed and HighSpeed PLL blocks. The
+                                                         legal values are as follows:
+                                                         0x27 = External reference clock 100 MHz
+                                                         0x2A = External reference clock 24 MHz
+                                                         0x31 = External reference clock 20 MHz
+                                                         0x38 = External reference clock 19.2 MHz
                                                          All other values are reserved.
-                                                         This value may only be changed during UPHY_RST.
-                                                         Note: When REF_CLK_SEL = 0x1 or 0x3, then MPLL_MULTPLIER, REF_CLK_DIV2, and
-                                                         SSC_REF_CLK_SEL
-                                                         must all be programmed to the same frequency setting. */
+                                                         This value may only be changed during UPHY_RST. */
 	uint64_t reserved_31_31               : 1;
 	uint64_t h_clk_en                     : 1;  /**< Host-controller-clock enable. When set to 1, the host-controller clock is generated. This
                                                          also enables access to UCTL registers 0x30-0xF8. */
 	uint64_t h_clk_byp_sel                : 1;  /**< Select the bypass input to the host-controller-clock divider.
-                                                         0 = use the divided coprocessor clock from the H_CLKDIV divider
-                                                         1 = use the bypass clock from the GPIO pins
+                                                         0 = Use the divided coprocessor clock from the H_CLKDIV divider
+                                                         1 = Use the bypass clock from the GPIO pins
                                                          This signal is just a multiplexer-select signal; it does not enable the host-controller
                                                          clock. You must still set H_CLKDIV_EN separately. H_CLK_BYP_SEL select should not be
                                                          changed unless H_CLKDIV_EN is disabled.
@@ -820,14 +760,14 @@ union cvmx_uctlx_ctl {
 	uint64_t usb3_port_disable            : 1;  /**< Disables the USB3 (SuperSpeed) portion of this PHY. When set to 1, this signal stops
                                                          reporting connect/disconnect events on the port and keeps the port in disabled state. This
                                                          could be used for security reasons where hardware can disable a port regardless of whether
-                                                         XHCI driver enables a port or not.
+                                                         xHCI driver enables a port or not.
                                                          UAHC(0)_HCSPARAMS1[MAXPORTS] is not affected by this signal.
                                                          This is a strap signal; it should be modified only when UPHY_RST is asserted. */
 	uint64_t reserved_17_17               : 1;
 	uint64_t usb2_port_disable            : 1;  /**< Disables USB2 (HighSpeed/FullSpeed/LowSpeed) portion of this PHY. When set to 1, this
                                                          signal stops reporting connect/disconnect events on the port and keeps the port in
                                                          disabled state. This could be used for security reasons where hardware can disable a port
-                                                         regardless of whether XHCI driver enables a port or not.
+                                                         regardless of whether xHCI driver enables a port or not.
                                                          UAHC(0)_HCSPARAMS1[MAXPORTS] is not affected by this signal.
                                                          This is a strap signal; it should only be modified when UPHY_RST is asserted.
                                                          If Port0 is required to be disabled, ensure that the utmi_clk[0] is running at the normal
@@ -900,16 +840,17 @@ typedef union cvmx_uctlx_ctl cvmx_uctlx_ctl_t;
  * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
  * This register can be used to disable ECC correction, insert ECC errors, and debug ECC
  * failures.
- * Fields ECC_ERR* are captured when there are no outstanding ECC errors indicated in INTSTAT
+ * The ECC_ERR* fields are captured when there are no outstanding ECC errors indicated in INTSTAT
  * and a new ECC error arrives. Prioritization for multiple events occurring on the same cycle is
  * indicated by the ECC_ERR_SOURCE enumeration: highest encoded value has highest priority.
- * Fields *ECC_DIS: Disables ECC correction, SBE and DBE errors are still reported.
- * If ECC_DIS is 0x1, then no data-correction occurs.
- * Fields *ECC_FLIP_SYND:  Flip the syndrom[1:0] bits to generate 1-bit/2-bits error for testing.
- *   0x0: normal operation
- *   0x1: SBE on bit[0]
- *   0x2: SBE on bit[1]
- *   0x3: DBE on bit[1:0]
+ * The *ECC_*_DIS fields disable ECC correction; SBE and DBE errors are still reported. If
+ * *ECC_*_DIS = 0x1, then no data-correction occurs.
+ * The *ECC_FLIP_SYND fields flip the syndrome<1:0> bits to generate single-bit/double-bit error
+ * for testing.
+ * 0x0 = normal operation
+ * 0x1 = SBE on bit[0]
+ * 0x2 = SBE on bit[1]
+ * 0x3 = DBE on bit[1:0]
  */
 union cvmx_uctlx_ecc {
 	uint64_t u64;
@@ -1125,11 +1066,11 @@ union cvmx_uctlx_host_cfg {
                                                          set by the Set LTV command. */
 	uint64_t reserved_38_47               : 10;
 	uint64_t fla                          : 6;  /**< HighSpeed jitter adjustment. Indicates the correction required to accommodate mac3 clock
-                                                         and utmi clock jitter to measure 125us duration. With FLA tied to zero, the HighSpeed
+                                                         and utmi clock jitter to measure 125us duration. With FLA tied to 0x0, the HighSpeed
                                                          125us micro-frame is counted for 123933ns. The value needs to be programmed in terms of
                                                          HighSpeed bit times in a 30 MHz cycle. Default value that needs to be driven is 0x20
                                                          (assuming 30 MHz perfect clock).
-                                                         FLA connects to the FLADJ register defined in the XHCI spec in the PCI configuration
+                                                         FLA connects to the FLADJ register defined in the xHCI spec in the PCI configuration
                                                          space. Each count is equal to 16 HighSpeed bit times. By default when this register is
                                                          set to 0x20, it gives 125us interval. Now, based on the clock accuracy, you can decrement
                                                          the count or increment the count to get the 125 us uSOF window.
@@ -1138,30 +1079,30 @@ union cvmx_uctlx_host_cfg {
 	uint64_t reserved_29_31               : 3;
 	uint64_t bme                          : 1;  /**< Bus-master enable. This signal is used to disable the bus-mastering capability of the
                                                          host. Disabling this capability stalls DMA accesses. */
-	uint64_t oci_en                       : 1;  /**< Overcurrent-indication enable.
-                                                         When enabled, OCI input to UAHC is taken from the MIO's GPIO signals and sense-converted
-                                                         based on OCI_ACTIVE_HIGH_EN. The MIO GPIO multiplexer must be programmed accordingly.
+	uint64_t oci_en                       : 1;  /**< Overcurrent-indication enable. When enabled, OCI input to UAHC is taken from the GPIO
+                                                         signals and sense-converted based on OCI_ACTIVE_HIGH_EN. The MIO GPIO multiplexer must be
+                                                         programmed accordingly.
                                                          When disabled, OCI input to UAHC is forced to the correct inactive state based on
                                                          OCI_ACTIVE_HIGH_EN.
                                                          This is a strap signal; it should only be modified when UAHC is in reset (soft-reset
                                                          okay). */
 	uint64_t oci_active_high_en           : 1;  /**< Overcurrent sense selection. The off-chip sense (high/low) is converted to match the host-
                                                          controller's active-high sense.
-                                                         1 = overcurrent indication from off-chip source is active-high.
-                                                         0 = overcurrent indication from off-chip source is active-low.
+                                                         1 = Overcurrent indication from off-chip source is active-high.
+                                                         0 = Overcurrent indication from off-chip source is active-low.
                                                          This is a strap signal; it should only be modified when UAHC is in reset (soft-reset
                                                          okay). */
 	uint64_t ppc_en                       : 1;  /**< Port-power-control enable.
                                                          0 = UAHC(0)_HCCPARAMS[PPC] report port-power-control feature is unavailable.
                                                          1 = UAHC(0)_HCCPARAMS[PPC] reports port-power-control feature is available. PPC output
-                                                         from UAHC is taken to the MIO's GPIO signals and sense-converted based on
-                                                         PPC_ACTIVE_HIGH_EN. The MIO GPIO multiplexer must be programmed accordingly.
+                                                         from UAHC is taken to the GPIO signals and sense-converted based on PPC_ACTIVE_HIGH_EN.
+                                                         The MIO GPIO multiplexer must be programmed accordingly.
                                                          This is a strap signal; it should only be modified when UAHC is in reset (soft-reset
                                                          okay). */
 	uint64_t ppc_active_high_en           : 1;  /**< Port power control sense selection. The active-high port-power-control output to off-chip
                                                          source is converted to match the off-chip sense.
-                                                         1 = port-power control to off-chip source is active-high.
-                                                         0 = port-power control to off-chip source is active-low.
+                                                         1 = Port-power control to off-chip source is active-high.
+                                                         0 = Port-power control to off-chip source is active-low.
                                                          This is a strap signal; it should only be modified when UAHC is in reset (soft reset
                                                          okay). */
 	uint64_t reserved_0_23                : 24;
@@ -1304,9 +1245,8 @@ typedef union cvmx_uctlx_int_reg cvmx_uctlx_int_reg_t;
  *
  * Accessible by: always
  * Reset by: IOI reset (srst_n)
- * Summary of different bits of RSL interrupts.
- * DBE's are detected. SBE's are corrected. For debugging output for ECC DBE/SBE's,
- * see UCTL_ECC register.
+ * This register provides a summary of different bits of RSL interrupts. DBEs are detected and
+ * SBE are corrected. For debugging output for ECC DBEs/SBEs, see UCTL(0)_ECC.
  */
 union cvmx_uctlx_intstat {
 	uint64_t u64;
@@ -1337,13 +1277,11 @@ union cvmx_uctlx_intstat {
 	uint64_t reserved_3_15                : 13;
 	uint64_t xm_bad_dma                   : 1;  /**< Detected bad DMA access from UAHC to IOI. Error information is logged in
                                                          UCTL(0)_SHIM_CFG[XM_BAD_DMA_*]. Received a DMA request from UAHC that violates the
-                                                         assumptions
-                                                         made by the AXI-to-IOI shim. Such scenarios include: illegal length/size combinations and
-                                                         address out-of-bounds.
-                                                         For more information on exact failures, see description in
-                                                         UCTL(0)_SHIM_CFG[XM_BAD_DMA_TYPE].
-                                                         The hardware does not translate the request correctly and results may violate IOI
-                                                         protocols.
+                                                         assumptions made by the AXI-to-IOI shim. Such scenarios include: illegal length/size
+                                                         combinations and address out-of-bounds.
+                                                         For more information on exact failures, see the description in
+                                                         UCTL(0)_SHIM_CFG[XM_BAD_DMA_TYPE]. The hardware does not translate the request correctly
+                                                         and results may violate IOI protocols.
                                                          Throws UCTL_INTSN_E::UCTL(0)_INTSTAT_XM_BAD_DMA. */
 	uint64_t xs_ncb_oob                   : 1;  /**< Detected out-of-bound register access to UAHC over IOI. The UAHC defines 1MB of register
                                                          space, starting at offset 0x0. Any accesses outside of this register space cause this bit
@@ -1527,11 +1465,11 @@ union cvmx_uctlx_portx_cfg_hs {
 	uint64_t tx_res_tune                  : 2;  /**< USB source-impedance adjustment. Some applications require additional devices to be added
                                                          on the USB, such as a series switch, which can add significant series resistance. This bus
                                                          adjusts the driver source impedance to compensate for added series resistance on the USB.
-                                                           0x3: source impedence is decreased by approximately 4 ohms.
-                                                           0x2: source impedence is decreased by approximately 2 ohms.
-                                                           0x1: design default
-                                                           0x0: source impedence is increased by approximately 1.5 ohms.
-                                                         Note: Any setting other than the default can result in source-impedance variation across
+                                                         0x3 = source impedance is decreased by approximately 4 ohm.
+                                                         0x2 = source impedance is decreased by approximately 2 ohm.
+                                                         0x1 = design default.
+                                                         0x0 = source impedance is decreased by approximately 1.5 ohm.
+                                                         Any setting other than the default can result in source-impedance variation across
                                                          process, voltage, and temperature conditions that does not meet USB 2.0 specification
                                                          limits. If this bus is not used, leave it at the default setting. */
 	uint64_t tx_rise_tune                 : 2;  /**< HighSpeed transmitter rise-/fall-time adjustment. Adjusts the rise/fall times of the
@@ -1587,8 +1525,7 @@ typedef union cvmx_uctlx_portx_cfg_hs cvmx_uctlx_portx_cfg_hs_t;
  * Accessible by: only when H_CLKDIV_EN
  * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
  * This register controls configuration and test controls for the portX PHY.
- * INTERNAL: All these settings are for SS or centralized functionality, connect on vp power
- * domain.
+ * INTERNAL: All these settings are for HS functionality, connect on DVDD power domain.
  */
 union cvmx_uctlx_portx_cfg_ss {
 	uint64_t u64;
@@ -1609,29 +1546,28 @@ union cvmx_uctlx_portx_cfg_ss {
                                                          A negative binary bit setting change results in a -15 mVp incremental change in the LOS
                                                          threshold. The 0x0 setting is reserved and must not be used. The default 0x5 setting
                                                          corresponds to approximately 105 mVp.
-                                                             0x0: invalid
-                                                             0x1:  45 mV
-                                                             0x2:  60 mV
-                                                             0x3:  75 mV
-                                                             0x4:  90 mV
-                                                             0x5: 105 mV
-                                                             0x6: 120 mV
-                                                             0x7: 135 mV */
-	uint64_t lane0_ext_pclk_req           : 1;  /**< When asserted, this signal enables the pipe0_pclk output regardless of power state
-                                                         (along with the associated increase in power consumption). You can use this input
-                                                         to enable pipe0_pclk in the P3 state without going through a complete boot sequence. */
+                                                         0x0 = invalid
+                                                         0x1 = 45 mV
+                                                         0x2 = 60 mV
+                                                         0x3 = 75 mV
+                                                         0x4 = 90 mV
+                                                         0x5 = 105 mV (default)
+                                                         0x6 = 120 mV
+                                                         0x7 = 135 mV */
+	uint64_t lane0_ext_pclk_req           : 1;  /**< When asserted, this signal enables the pipe0_pclk output regardless of power state (along
+                                                         with the associated increase in power consumption). You can use this input to enable
+                                                         pipe0_pclk in the P3 state without going through a complete boot sequence. */
 	uint64_t lane0_tx2rx_loopbk           : 1;  /**< When asserted, data from TX predriver is looped back to RX slicers. LOS is bypassed and
                                                          based on the tx0_en input so that rx0_los = !tx_data_en. */
 	uint64_t reserved_42_55               : 14;
-	uint64_t pcs_rx_los_mask_val          : 10; /**< Configurable Loss-of-Signal Mask Width.
-                                                         Sets the number of reference clock cycles to mask the incoming LFPS in U3 and U2 states.
-                                                         Masks the incoming LFPS for the number of reference clock cycles equal to the value of
-                                                         pcs_rx_los_mask_val<9:0>. This control filters out short, non-compliant LFPS glitches
-                                                         sent by a non-compliant host.
+	uint64_t pcs_rx_los_mask_val          : 10; /**< Configurable loss-of-signal mask width. Sets the number of reference clock cycles to mask
+                                                         the incoming LFPS in U3 and U2 states. Masks the incoming LFPS for the number of reference
+                                                         clock cycles equal to the value of pcs_rx_los_mask_val<9:0>. This control filters out
+                                                         short, non-compliant LFPS glitches sent by a noncompliant host.
                                                          For normal operation, set to a targeted mask interval of 10us (value = 10us / Tref_clk).
                                                          If the UCTL(0)_CTL[REF_CLK_DIV2] is used, then (value = 10us / (2 * Tref_clk)).
                                                          These equations are based on the SuperSpeed reference clock frequency.
-                                                         The value of PCS_RX_LOS_MASK_VAL should be:
+                                                         The value of PCS_RX_LOS_MASK_VAL should be as follows:
                                                              Frequency DIV2 LOS_MASK
                                                               200  MHz    1    0x3E8
                                                               125  MHz    0    0x4E2
@@ -1658,11 +1594,11 @@ union cvmx_uctlx_portx_cfg_ss {
                                                          derived from the following equation:
                                                          TX de-emphasis (db) =
                                                          20 * log_base_10((128 - 2 * pcs_tx_deemph)/128)
-                                                         INTERNAL: Default Value is Package-Dependant.
                                                          In general, the parameter controls are static signals to be set prior to taking the PHY
                                                          out of reset. However, you can dynamically change these values on-the-fly for test
                                                          purposes. In this case, changes to the transmitter to reflect the current value occur only
-                                                         after the pipeP_tx_deemph[1:0] input changes. */
+                                                         after the pipeP_tx_deemph[1:0] input changes.
+                                                         INTERNAL: Default value is package dependant. */
 	uint64_t pcs_tx_deemph_6db            : 6;  /**< Fine-tune transmitter driver de-emphasis when set to 6db.
                                                          This static value sets the Tx driver de-emphasis value when pipeP_tx_deemph[1:0] is set to
                                                          0x2 (according to the PIPE3 specification). This bus is provided for completeness and as a
@@ -1670,25 +1606,25 @@ union cvmx_uctlx_portx_cfg_ss {
                                                          the following equation:
                                                          TX de-emphasis (db) =
                                                          20 * log_base_10((128 - 2 * pcs_tx_deemph)/128)
-                                                         INTERNAL: Default Value is Package-Dependant.
                                                          In general, the parameter controls are static signals to be set prior to taking the PHY
                                                          out of reset. However, you can dynamically change these values on-the-fly for test
                                                          purposes. In this case, changes to the transmitter to reflect the current value occur only
-                                                         after the pipeP_tx_deemph[1:0] input changes. */
+                                                         after the pipeP_tx_deemph[1:0] input changes.
+                                                         INTERNAL: Default value is package dependant. */
 	uint64_t pcs_tx_swing_full            : 7;  /**< Launch amplitude of the transmitter. Sets the launch amplitude of the transmitter. The
                                                          values for transmit amplitude are derived from the following equation:
                                                          TX amplitude (V) = vptx * ((pcs_tx_swing_full + 1)/128)
-                                                         INTERNAL: Default Value is Package-Dependant.
                                                          In general, the parameter controls are static signals to be set prior to taking the PHY
                                                          out of reset. However, you can dynamically change these values on-the-fly for test
                                                          purposes. In this case, changes to the transmitter to reflect the current value occur only
-                                                         after the pipeP_tx_deemph[1:0] input changes. */
+                                                         after the pipeP_tx_deemph[1:0] input changes.
+                                                         INTERNAL: Default value is package dependant. */
 	uint64_t lane0_tx_term_offset         : 5;  /**< Transmitter termination offset. Reserved, set to 0x0. */
 	uint64_t reserved_6_7                 : 2;
-	uint64_t res_tune_ack                 : 1;  /**< While asserted, indicates a resistor tune is in progress. */
-	uint64_t res_tune_req                 : 1;  /**< Rising edge triggers a resistor tune request (if one is not already in progress). When
-                                                         asserted, RES_TUNE_ACK goes high until calibration of the termination impedance is
-                                                         complete.
+	uint64_t res_tune_ack                 : 1;  /**< Resistor tune acknowledge. While asserted, indicates a resistor tune is in progress. */
+	uint64_t res_tune_req                 : 1;  /**< Resistor tune request. The rising edge triggers a resistor tune request (if one is not
+                                                         already in progress). When asserted, RES_TUNE_ACK is asserted high until calibration of
+                                                         the termination impedance is complete.
                                                          Tuning disrupts the normal flow of data; therefore, assert RES_TUNE_REQ only when the PHY
                                                          is inactive. The PHY automatically performs a tune when coming out of PRST. */
 	uint64_t reserved_0_3                 : 4;
@@ -1858,11 +1794,10 @@ typedef union cvmx_uctlx_ppaf_wm cvmx_uctlx_ppaf_wm_t;
  *
  * Accessible by: only when H_CLKDIV_EN
  * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
- * This register allows configuration of various shim (UCTL) features.
- * Fields XS_NCB_OOB_* are captured when there are no outstanding OOB errors indicated in INTSTAT
- * and a new OOB error arrives.
- * Fields XS_BAD_DMA_* are captured when there are no outstanding DMA errors indicated in INTSTAT
- * and a new DMA error arrives.
+ * This register allows configuration of various shim (UCTL) features. The fields XS_NCB_OOB_*
+ * are captured when there are no outstanding OOB errors indicated in INTSTAT and a new OOB error
+ * arrives. The fields XS_BAD_DMA_* are captured when there are no outstanding DMA errors
+ * indicated in INTSTAT and a new DMA error arrives.
  */
 union cvmx_uctlx_shim_cfg {
 	uint64_t u64;
@@ -1887,7 +1822,7 @@ union cvmx_uctlx_shim_cfg {
 	uint64_t reserved_14_39               : 26;
 	uint64_t dma_read_cmd                 : 2;  /**< Selects the IOI read command used by DMA accesses. See UCTL_DMA_READ_CMD_E. */
 	uint64_t reserved_11_11               : 1;
-	uint64_t dma_write_cmd                : 1;  /**< Selects the NCB write command used by DMA accesses. See enum UCTL_DMA_WRITE_CMD_E. */
+	uint64_t dma_write_cmd                : 1;  /**< Selects the NCB write command used by DMA accesses. See UCTL_DMA_WRITE_CMD_E. */
 	uint64_t dma_endian_mode              : 2;  /**< Selects the endian format for DMA accesses to the L2C. See UCTL_ENDIAN_MODE_E. */
 	uint64_t reserved_2_7                 : 6;
 	uint64_t csr_endian_mode              : 2;  /**< Selects the endian format for IOI CSR accesses to the UAHC. Note that when UAHC CSRs are
diff --git a/arch/mips/include/asm/octeon/cvmx-usbcx-defs.h b/arch/mips/include/asm/octeon/cvmx-usbcx-defs.h
index db7f03e..c7e8a4a 100644
--- a/arch/mips/include/asm/octeon/cvmx-usbcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-usbcx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-usbnx-defs.h b/arch/mips/include/asm/octeon/cvmx-usbnx-defs.h
index 6a952f8..bd5b4f2 100644
--- a/arch/mips/include/asm/octeon/cvmx-usbnx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-usbnx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/octeon-boot-info.h b/arch/mips/include/asm/octeon/octeon-boot-info.h
index db7bc29..9676b81 100644
--- a/arch/mips/include/asm/octeon/octeon-boot-info.h
+++ b/arch/mips/include/asm/octeon/octeon-boot-info.h
@@ -51,8 +51,10 @@
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/types.h>
 #include <asm/octeon/cvmx-asm.h>
+#elif defined(__U_BOOT__)
+# include <asm/arch/cvmx-asm.h>
 #else
-#include "cvmx-asm.h"
+# include "cvmx-asm.h"
 #endif
 
 #define OCTEON_BOOT_MOVEABLE_MAGIC	0xDB00110ad358eace
diff --git a/arch/mips/include/asm/octeon/octeon-feature.h b/arch/mips/include/asm/octeon/octeon-feature.h
index 7044384..b9e45cb 100644
--- a/arch/mips/include/asm/octeon/octeon-feature.h
+++ b/arch/mips/include/asm/octeon/octeon-feature.h
@@ -42,7 +42,6 @@
  *
  * File defining checks for different Octeon features.
  *
- * <hr>$Revision: 30468 $<hr>
  */
 
 #ifndef __OCTEON_FEATURE_H__
@@ -67,12 +66,12 @@ typedef enum {
  * runtime. It provides a unified way to answer yes-or-no quetions.
  */
 typedef enum {
-	OCTEON_ATTR_FIRST_CORE,	/* first core in the boot coremask */
+	OCTEON_ATTR_INIT_CORE,	/* initial core to run the app when booted */
 	OCTEON_ATTR_TRACED,	/* the core is traced */
 	OCTEON_ATTR_NO_IOCFG,	/* skip IO config in cvmx_user_app_init() */
 	OCTEON_ATTR_MAX
 } octeon_attr_t;
-#define OCTEON_IS_FIRST_CORE()	octeon_has_attr(OCTEON_ATTR_FIRST_CORE)
+#define OCTEON_IS_INIT_CORE()	octeon_has_attr(OCTEON_ATTR_INIT_CORE)
 #define OCTEON_IS_TRACED()	octeon_has_attr(OCTEON_ATTR_TRACED)
 #define OCTEON_IS_NO_IOCFG()	octeon_has_attr(OCTEON_ATTR_NO_IOCFG)
 
@@ -153,10 +152,16 @@ typedef enum {
 				/**<  Octeon has node support */
 	OCTEON_FEATURE_CIU3,
 				/**<  Octeon has CIU3 */
+	OCTEON_FEATURE_FPA3,
+				/**<  Octeon has FPA first seen on 78XX */
 	OCTEON_FEATURE_CN78XX_WQE,
 				/**<  CN78XX has different fields in word0 - word2 */
 	OCTEON_FEATURE_SPI,
 				/**< Octeon supports SPI interfaces */
+	OCTEON_FEATURE_ZIP3,
+				/**<  Octeon has zip first seen on 78XX */
+ 	OCTEON_FEATURE_BCH,
+  				/**< Octeon supports BCH ECC */
 	OCTEON_MAX_FEATURE
 } octeon_feature_t;
 
@@ -175,6 +180,16 @@ static inline int octeon_has_feature_OCTEON_FEATURE_ZIP(void)
 		return !cvmx_fuse_read(121);
 }
 
+static inline int octeon_has_feature_OCTEON_FEATURE_ZIP3(void)
+{
+	return (OCTEON_IS_MODEL(OCTEON_CN78XX));
+}
+
+static inline int octeon_has_feature_OCTEON_FEATURE_BCH(void)
+{
+	return OCTEON_IS_OCTEON3();
+}
+
 static inline int octeon_has_feature_OCTEON_FEATURE_CRYPTO(void)
 {
 	if (!OCTEON_IS_OCTEON1PLUS()) {	/* OCTEON II and later */
@@ -329,6 +344,10 @@ static inline int octeon_has_feature_OCTEON_FEATURE_CIU3(void)
 	return (OCTEON_IS_MODEL(OCTEON_CN78XX));
 }
 
+static inline int octeon_has_feature_OCTEON_FEATURE_FPA3(void)
+{
+	return (OCTEON_IS_MODEL(OCTEON_CN78XX));
+}
 
 static inline int octeon_has_feature_OCTEON_FEATURE_NAND(void)
 {
diff --git a/arch/mips/include/asm/octeon/octeon-model.h b/arch/mips/include/asm/octeon/octeon-model.h
index e12eaa6..8a51e8e 100644
--- a/arch/mips/include/asm/octeon/octeon-model.h
+++ b/arch/mips/include/asm/octeon/octeon-model.h
@@ -43,7 +43,7 @@
  * File defining different Octeon model IDs and macros to
  * compare them.
  *
- * <hr>$Revision: 84894 $<hr>
+ * <hr>$Revision: 88111 $<hr>
  */
 
 #ifndef __OCTEON_MODEL_H__
@@ -126,7 +126,6 @@ extern "C" {
  */
 #define OCTEON_CN68XX_PASS1_0   0x000d9100
 #define OCTEON_CN68XX_PASS1_1   0x000d9101
-#define OCTEON_CN68XX_PASS1_2   0x000d9102
 #define OCTEON_CN68XX_PASS2_0   0x000d9108
 #define OCTEON_CN68XX_PASS2_1   0x000d9109
 #define OCTEON_CN68XX_PASS2_2   0x000d910a
-- 
1.7.0.4

