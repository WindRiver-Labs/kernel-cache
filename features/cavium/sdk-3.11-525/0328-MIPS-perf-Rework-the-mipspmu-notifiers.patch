From b96cb3c0295a92ffd7657f0a2db0da2ebebd6527 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Thu, 7 Nov 2013 17:43:36 -0800
Subject: [PATCH 328/518] MIPS perf: Rework the mipspmu notifiers.

Source: Cavium Networks, Inc.
MR: 00000
Type: Integration
Disposition: Merged from Octeon Tree
ChangeID: e39ed68a5d61c91764c889c7f11375a7d6dbfc93
Description:

We need to know if the PMU is active or not, so we change the actions
to MIPSPMU_ACTIVE and MIPSPMU_INACTIVE fix up the callers so they get
sent at the proper times.

Signed-off-by: David Daney <david.daney@cavium.com>
Signed-off-by: Corey Minyard <cminyard@mvista.com>
[Original patch taken from Cavium SDK 3.1.1 525]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/cavium-octeon/setup.c      | 22 ++++++++++------------
 arch/mips/include/asm/perf_event.h   |  4 ++--
 arch/mips/kernel/perf_event_mipsxx.c | 15 ++++++++++-----
 3 files changed, 22 insertions(+), 19 deletions(-)

diff --git a/arch/mips/cavium-octeon/setup.c b/arch/mips/cavium-octeon/setup.c
index ef74dae..914e68f 100644
--- a/arch/mips/cavium-octeon/setup.c
+++ b/arch/mips/cavium-octeon/setup.c
@@ -879,28 +879,26 @@ late_initcall(octeon_l2_cache_lock);
 static int octeon_mipspmu_notifier(struct notifier_block *nb,
 				   unsigned long action, void *data)
 {
-	u64 cvmctl;
+	u64 cvmctl_orig = read_c0_cvmctl();
+	u64 cvmctl_new = cvmctl_orig;
+	u64 mask = (1ull << 15) | (1ull << 17);
+
 	switch (action) {
-	case MIPSPMU_ENABLE:
-		cvmctl = read_c0_cvmctl();
+	case MIPSPMU_ACTIVE:
+		cvmctl_new = cvmctl_orig | mask;
 		/*
 		 * Set CvmCtl[DCICLK,DISCE] for more accurate profiling at
 		 * the expense of power consumption.
 		 */
-		cvmctl |= ((1ull << 15) | (1ull << 17));
-		write_c0_cvmctl(cvmctl);
 		break;
-	case MIPSPMU_DISABLE:
-		cvmctl = read_c0_cvmctl();
-		/*
-		 * Clear CvmCtl[DCICLK,DISCE] for lower power consumption.
-		 */
-		cvmctl &= ~((1ull << 15) | (1ull << 17));
-		write_c0_cvmctl(cvmctl);
+	case MIPSPMU_INACTIVE:
+		cvmctl_new = cvmctl_orig & ~mask;
 		break;
 	default:
 		break;
 	}
+	if (cvmctl_new != cvmctl_orig)
+		write_c0_cvmctl(cvmctl_new);
 	return NOTIFY_OK;
 }
 static struct notifier_block octeon_mipspmu_nb = {
diff --git a/arch/mips/include/asm/perf_event.h b/arch/mips/include/asm/perf_event.h
index 0cf24f7..bfd8f0a 100644
--- a/arch/mips/include/asm/perf_event.h
+++ b/arch/mips/include/asm/perf_event.h
@@ -17,7 +17,7 @@
 /* Allow CPU specific actions on PMU state changes. */
 int mipspmu_notifier_register(struct notifier_block *nb);
 int mipspmu_notifier_unregister(struct notifier_block *nb);
-#define MIPSPMU_ENABLE 0
-#define MIPSPMU_DISABLE 1
+#define MIPSPMU_ACTIVE 0
+#define MIPSPMU_INACTIVE 1
 
 #endif /* __MIPS_PERF_EVENT_H__ */
diff --git a/arch/mips/kernel/perf_event_mipsxx.c b/arch/mips/kernel/perf_event_mipsxx.c
index be30034..f0aeb48 100644
--- a/arch/mips/kernel/perf_event_mipsxx.c
+++ b/arch/mips/kernel/perf_event_mipsxx.c
@@ -186,7 +186,7 @@ static unsigned int counters_total_to_per_cpu(unsigned int counters)
 
 #endif /* CONFIG_MIPS_PERF_SHARED_TC_COUNTERS */
 
-static void resume_local_counters(void);
+static int resume_local_counters(void);
 static void pause_local_counters(void);
 static irqreturn_t mipsxx_pmu_handle_irq(int, void *);
 static int mipsxx_pmu_handle_shared_irq(void);
@@ -533,11 +533,12 @@ static void mipspmu_read(struct perf_event *event)
 
 static void mipspmu_enable(struct pmu *pmu)
 {
+	int i;
 #ifdef CONFIG_MIPS_PERF_SHARED_TC_COUNTERS
 	write_unlock(&pmuint_rwlock);
 #endif
-	resume_local_counters();
-	atomic_notifier_call_chain(&mipsxx_pmu_chain, MIPSPMU_ENABLE, NULL);
+	i = resume_local_counters();
+	atomic_notifier_call_chain(&mipsxx_pmu_chain, i ? MIPSPMU_ACTIVE : MIPSPMU_INACTIVE, NULL);
 }
 
 /*
@@ -557,7 +558,6 @@ static void mipspmu_disable(struct pmu *pmu)
 #ifdef CONFIG_MIPS_PERF_SHARED_TC_COUNTERS
 	write_lock(&pmuint_rwlock);
 #endif
-	atomic_notifier_call_chain(&mipsxx_pmu_chain, MIPSPMU_DISABLE, NULL);
 }
 
 static atomic_t active_events = ATOMIC_INIT(0);
@@ -816,6 +816,7 @@ static void reset_counters(void *arg)
 		mipsxx_pmu_write_control(0, 0);
 		mipspmu.write_counter(0, 0);
 	}
+	atomic_notifier_call_chain(&mipsxx_pmu_chain, MIPSPMU_INACTIVE, NULL);
 }
 
 /* 24K/34K/1004K cores can share the same event map. */
@@ -1297,15 +1298,19 @@ static void pause_local_counters(void)
 	local_irq_restore(flags);
 }
 
-static void resume_local_counters(void)
+static int resume_local_counters(void)
 {
+	int r = 0;
 	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);
 	int ctr = mipspmu.num_counters;
 
 	do {
 		ctr--;
 		mipsxx_pmu_write_control(ctr, cpuc->saved_ctrl[ctr]);
+		r += (cpuc->saved_ctrl[ctr] & M_PERFCTL_INTERRUPT_ENABLE) != 0;
 	} while (ctr > 0);
+
+	return r;
 }
 
 static int mipsxx_pmu_handle_shared_irq(void)
-- 
1.9.1

