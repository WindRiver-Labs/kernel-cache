From 422f3db3a1ae31ee4cbbe3410fa2ec73d05f0531 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Wed, 5 Sep 2012 16:44:21 +0800
Subject: [PATCH 21/27] MIPS: octeon2: add cn68xx irq support

Based on SDK 2.3.0-427

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/cavium-octeon/octeon-irq.c           |  499 +++++++++++++++++++++++-
 arch/mips/cavium-octeon/setup.c                |  127 +++++-
 arch/mips/include/asm/mach-cavium-octeon/irq.h |   12 +-
 drivers/of/irq.c                               |    8 +-
 4 files changed, 628 insertions(+), 18 deletions(-)

diff --git a/arch/mips/cavium-octeon/octeon-irq.c b/arch/mips/cavium-octeon/octeon-irq.c
index ffd4ae6..8a54d33 100644
--- a/arch/mips/cavium-octeon/octeon-irq.c
+++ b/arch/mips/cavium-octeon/octeon-irq.c
@@ -13,6 +13,7 @@
 #include <linux/smp.h>
 
 #include <asm/octeon/octeon.h>
+#include <asm/octeon/cvmx-ciu2-defs.h>
 
 static DEFINE_RAW_SPINLOCK(octeon_irq_ciu0_lock);
 static DEFINE_RAW_SPINLOCK(octeon_irq_ciu1_lock);
@@ -38,6 +39,27 @@ struct octeon_core_chip_data {
 	u8 bit;
 };
 
+/*
+ * irq_create_of_mapping - Hook to resolve OF irq specifier into a Linux irq#
+ *
+ * Octeon irq maps are a pair of indexes.  The first selects either
+ * ciu0 or ciu1, the second is the bit within the ciu register.
+ */
+unsigned int octeon_irq_create_of_mapping(struct device_node *controller,
+                                   const u32 *intspec, unsigned int intsize)
+{
+        unsigned int irq = 0;
+        unsigned int ciu, bit;
+
+        ciu = intspec[0];
+        bit = intspec[1];
+
+        if (ciu < 8 && bit < 64)
+                irq = octeon_irq_ciu_to_irq[ciu][bit];
+
+        return irq;
+}
+
 #define MIPS_CORE_IRQ_LINES 8
 
 static struct octeon_core_chip_data octeon_irq_core_chip_data[MIPS_CORE_IRQ_LINES];
@@ -58,7 +80,7 @@ static void __init octeon_irq_set_ciu_mapping(int irq, int line, int bit,
 	octeon_irq_ciu_to_irq[line][bit] = irq;
 }
 
-static int octeon_coreid_for_cpu(int cpu)
+int octeon_coreid_for_cpu(int cpu)
 {
 #ifdef CONFIG_SMP
 	return cpu_logical_map(cpu);
@@ -542,7 +564,7 @@ static int octeon_irq_ciu_set_affinity(struct irq_data *data,
 
 	/*
 	 * For non-v2 CIU, we will allow only single CPU affinity.
-	 * This removes the need to do locking in the .ack/.eoi
+	 * This removes the need to do locking in the .irq_ack/.eoi
 	 * functions.
 	 */
 	if (cpumask_weight(dest) != 1)
@@ -837,6 +859,17 @@ static void octeon_irq_ip3_v2(void)
 	}
 }
 
+static void __cpuinit octeon_irq_local_enable_ip4(void *arg)
+{
+	int coreid = cvmx_get_core_num();
+
+	set_c0_status(STATUSF_IP4);
+
+	/* Enable MSIRED interrupt */
+	cvmx_write_csr(CVMX_CIU2_EN_PPX_IP4_IO_W1S(coreid), 1 << 12);
+	cvmx_read_csr(CVMX_CIU2_SUM_PPX_IP2(coreid));
+}
+
 static void octeon_irq_ip4_mask(void)
 {
 	clear_c0_status(STATUSF_IP4);
@@ -847,8 +880,17 @@ static void (*octeon_irq_ip2)(void);
 static void (*octeon_irq_ip3)(void);
 static void (*octeon_irq_ip4)(void);
 
+static bool octeon_irq_use_ip4;
+
 void __cpuinitdata (*octeon_irq_setup_secondary)(void);
 
+void __cpuinit octeon_irq_set_ip4_handler(octeon_irq_ip4_handler_t h)
+{
+	octeon_irq_ip4 = h;
+	octeon_irq_use_ip4 = true;
+	on_each_cpu(octeon_irq_local_enable_ip4, NULL, 1);
+}
+
 static void __cpuinit octeon_irq_percpu_enable(void)
 {
 	irq_cpu_online();
@@ -880,7 +922,10 @@ static void __cpuinit octeon_irq_setup_secondary_ciu(void)
 
 	/* Enable the CIU lines */
 	set_c0_status(STATUSF_IP3 | STATUSF_IP2);
-	clear_c0_status(STATUSF_IP4);
+	if (octeon_irq_use_ip4)
+		set_c0_status(STATUSF_IP4);
+	else
+		clear_c0_status(STATUSF_IP4);
 }
 
 static void __init octeon_irq_init_ciu(void)
@@ -1000,6 +1045,449 @@ static void __init octeon_irq_init_ciu(void)
 	clear_c0_status(STATUSF_IP4);
 }
 
+static void octeon_irq_init_ciu2_percpu(void)
+{
+	u64 regx, ipx;
+	int coreid = cvmx_get_core_num();
+	u64 base = CVMX_CIU2_EN_PPX_IP2_WRKQ(coreid);
+
+	/*
+	 * Disable All CIU2 Interrupts. The ones we need will be
+	 * enabled later.  Read the SUM register so we know the write
+	 * completed.
+	 *
+	 * There are 9 registers and 3 IPX levels with strides 0x1000
+	 * and 0x200 respectivly.  Use loops to clear them.
+	 */
+	for (regx = 0; regx <= 0x8000; regx += 0x1000) {
+		for (ipx = 0; ipx <= 0x400; ipx += 0x200)
+			cvmx_write_csr(base + regx + ipx, 0);
+	}
+
+	cvmx_read_csr(CVMX_CIU2_SUM_PPX_IP2(coreid));
+}
+
+static void octeon_irq_setup_secondary_ciu2(void)
+{
+	octeon_irq_init_ciu2_percpu();
+	octeon_irq_percpu_enable();
+
+	/* Enable the CIU lines */
+	set_c0_status(STATUSF_IP3 | STATUSF_IP2);
+	if (octeon_irq_use_ip4)
+		set_c0_status(STATUSF_IP4);
+	else
+		clear_c0_status(STATUSF_IP4);
+}
+
+/*
+ * Watchdog interrupts are special.  They are associated with a single
+ * core, so we hardwire the affinity to that core.
+ */
+static void octeon_irq_ciu2_wd_enable(struct irq_data *data)
+{
+	u64 mask;
+	u64 en_addr;
+
+	int coreid = data->irq - OCTEON_IRQ_WDOG0;
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+	mask = 1ull << (cd.s.bit);
+
+	en_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) + (0x1000ull * cd.s.line);
+	cvmx_write_csr(en_addr, mask);
+
+}
+
+static void octeon_irq_ciu2_enable(struct irq_data *data)
+{
+	u64 mask;
+	u64 en_addr;
+	int cpu = next_cpu_for_irq(data);
+	int coreid = octeon_coreid_for_cpu(cpu);
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+	mask = 1ull << (cd.s.bit);
+
+	en_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) + (0x1000ull * cd.s.line);
+	cvmx_write_csr(en_addr, mask);
+
+}
+
+static void octeon_irq_ciu2_enable_local(struct irq_data *data)
+{
+	u64 mask;
+	u64 en_addr;
+	int coreid = cvmx_get_core_num();
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+	mask = 1ull << (cd.s.bit);
+
+	en_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) + (0x1000ull * cd.s.line);
+	cvmx_write_csr(en_addr, mask);
+
+}
+
+static void octeon_irq_ciu2_disable_local(struct irq_data *data)
+{
+	u64 mask;
+	u64 en_addr;
+	int coreid = cvmx_get_core_num();
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+	mask = 1ull << (cd.s.bit);
+
+	en_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(coreid) + (0x1000ull * cd.s.line);
+	cvmx_write_csr(en_addr, mask);
+
+}
+
+static void octeon_irq_ciu2_ack(struct irq_data *data)
+{
+	u64 mask;
+	u64 en_addr;
+	int coreid = cvmx_get_core_num();
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+	mask = 1ull << (cd.s.bit);
+
+	en_addr = CVMX_CIU2_RAW_PPX_IP2_WRKQ(coreid) + (0x1000ull * cd.s.line);
+	cvmx_write_csr(en_addr, mask);
+
+}
+
+static void octeon_irq_ciu2_disable_all(struct irq_data *data)
+{
+	int cpu;
+	u64 mask;
+	union octeon_ciu_chip_data cd;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+	mask = 1ull << (cd.s.bit);
+
+	for_each_online_cpu(cpu) {
+		u64 en_addr =
+			CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(octeon_coreid_for_cpu(cpu)) +
+			(0x1000ull * cd.s.line);
+		cvmx_write_csr(en_addr, mask);
+	}
+}
+
+static void octeon_irq_ciu2_mbox_disable_all(struct irq_data *data)
+{
+	int cpu;
+	u64 mask;
+
+	mask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);
+
+	for_each_online_cpu(cpu) {
+		u64 en_addr =
+			CVMX_CIU2_EN_PPX_IP3_MBOX_W1C(octeon_coreid_for_cpu(cpu));
+		cvmx_write_csr(en_addr, mask);
+	}
+}
+
+static void octeon_irq_ciu2_mbox_enable_local(struct irq_data *data)
+{
+	u64 mask;
+	u64 en_addr;
+	int coreid = cvmx_get_core_num();
+
+	mask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);
+	en_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1S(coreid);
+	cvmx_write_csr(en_addr, mask);
+}
+
+static void octeon_irq_ciu2_mbox_disable_local(struct irq_data *data)
+{
+	u64 mask;
+	u64 en_addr;
+	int coreid = cvmx_get_core_num();
+
+	mask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);
+	en_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1C(coreid);
+	cvmx_write_csr(en_addr, mask);
+}
+
+#ifdef CONFIG_SMP
+static int octeon_irq_ciu2_set_affinity(struct irq_data *data,
+					const struct cpumask *dest, bool force)
+{
+	int cpu;
+	int enable_one = !irqd_irq_disabled(data) && !irqd_irq_masked(data);
+	u64 mask;
+	union octeon_ciu_chip_data cd;
+
+	if (!enable_one)
+		return 0;
+
+	cd.p = irq_data_get_irq_chip_data(data);
+	mask = 1ull << cd.s.bit;
+
+	for_each_online_cpu(cpu) {
+		u64 en_addr;
+		if (cpumask_test_cpu(cpu, dest) && enable_one) {
+			enable_one = 0;
+			en_addr =
+				CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(octeon_coreid_for_cpu(cpu)) +
+				(0x1000ull * cd.s.line);
+		}
+		else {
+			en_addr =
+				CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(octeon_coreid_for_cpu(cpu)) +
+				(0x1000ull * cd.s.line);
+		}
+		cvmx_write_csr(en_addr, mask);
+	}
+
+	return 0;
+}
+#endif
+
+static struct irq_chip octeon_irq_chip_ciu2 = {
+	.name = "CIU2",
+	.irq_enable = octeon_irq_ciu2_enable,
+	.irq_disable = octeon_irq_ciu2_disable_all,
+	.irq_mask = octeon_irq_ciu2_disable_local,
+	.irq_unmask = octeon_irq_ciu2_enable,
+#ifdef CONFIG_SMP
+	.irq_set_affinity = octeon_irq_ciu2_set_affinity,
+#endif
+};
+
+static struct irq_chip octeon_irq_chip_ciu2_edge = {
+	.name = "CIU2-E",
+	.irq_enable = octeon_irq_ciu2_enable,
+	.irq_disable = octeon_irq_ciu2_disable_all,
+	.irq_ack = octeon_irq_ciu2_ack,
+	.irq_mask = octeon_irq_ciu2_disable_local,
+	.irq_unmask = octeon_irq_ciu2_enable,
+#ifdef CONFIG_SMP
+	.irq_set_affinity = octeon_irq_ciu2_set_affinity,
+#endif
+};
+
+static struct irq_chip octeon_irq_chip_ciu2_mbox = {
+	.name = "CIU2-M",
+	.irq_enable = octeon_irq_ciu2_mbox_enable_local,
+	.irq_disable = octeon_irq_ciu2_mbox_disable_all,
+	.irq_ack = octeon_irq_ciu2_mbox_disable_local,
+	.irq_eoi = octeon_irq_ciu2_mbox_enable_local,
+};
+
+static struct irq_chip octeon_irq_chip_ciu2_wd = {
+	.name = "CIU2-W",
+	.irq_enable = octeon_irq_ciu2_wd_enable,
+	.irq_disable = octeon_irq_ciu2_disable_all,
+	.irq_mask = octeon_irq_ciu2_disable_local,
+	.irq_unmask = octeon_irq_ciu2_enable_local,
+};
+
+static void octeon_irq_ciu2(void)
+{
+	int line;
+	int bit;
+	int irq;
+	u64 src_reg, src, sum;
+	const unsigned long core_id = cvmx_get_core_num();
+
+	sum = cvmx_read_csr(CVMX_CIU2_SUM_PPX_IP2(core_id)) & 0xfful;
+
+	if (unlikely(!sum))
+		goto spurious;
+
+	line = fls64(sum) - 1;
+	src_reg = CVMX_CIU2_SRC_PPX_IP2_WRKQ(core_id) + (0x1000 * line);
+	src = cvmx_read_csr(src_reg);
+
+	if (unlikely(!src))
+		goto spurious;
+
+	bit = fls64(src) - 1;
+	irq = octeon_irq_ciu_to_irq[line][bit];
+	if (unlikely(!irq))
+		goto spurious;
+
+	do_IRQ(irq);
+	goto out;
+
+  spurious:
+	spurious_interrupt();
+  out:
+	/* CN68XX pass 1.x has an errata that accessing the ACK registers
+	   can stop interrupts from propagating */
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		cvmx_read_csr(CVMX_CIU2_INTR_CIU_READY);
+	else
+		cvmx_read_csr(CVMX_CIU2_ACK_PPX_IP2(core_id));
+	return;
+}
+
+static void octeon_irq_ciu2_mbox(void)
+{
+	int line;
+
+	const unsigned long core_id = cvmx_get_core_num();
+	u64 sum = cvmx_read_csr(CVMX_CIU2_SUM_PPX_IP3(core_id)) >> 60;
+
+	if (unlikely(!sum))
+		goto spurious;
+
+	line = fls64(sum) - 1;
+
+	do_IRQ(OCTEON_IRQ_MBOX0 + line);
+	goto out;
+
+  spurious:
+	spurious_interrupt();
+  out:
+	/* CN68XX pass 1.x has an errata that accessing the ACK registers
+	   can stop interrupts from propagating */
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		cvmx_read_csr(CVMX_CIU2_INTR_CIU_READY);
+	else
+		cvmx_read_csr(CVMX_CIU2_ACK_PPX_IP3(core_id));
+	return;
+}
+
+static void __init octeon_irq_init_ciu2(void)
+{
+	unsigned int i;
+
+	octeon_irq_init_ciu2_percpu();
+	octeon_irq_setup_secondary = octeon_irq_setup_secondary_ciu2;
+
+	octeon_irq_ip2 = octeon_irq_ciu2;
+	octeon_irq_ip3 = octeon_irq_ciu2_mbox;
+	octeon_irq_ip4 = octeon_irq_ip4_mask;
+
+	/* Mips internal */
+	octeon_irq_init_core();
+
+	/* CUI2 */
+	for (i = 0; i < 64; i++)
+		octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_WORKQ0, 0, i,
+					   &octeon_irq_chip_ciu2, handle_level_irq);
+
+	for (i = 0; i < 32; i++)
+		octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_WDOG0, 1, i,
+					   &octeon_irq_chip_ciu2_wd,
+					   handle_level_irq);
+
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_IOB, 2, 0, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_FPA, 2, 4, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_IPD, 2, 5, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_PIP, 2, 6, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_PKO, 2, 7, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_POW, 2, 16, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_ZIP, 2, 24, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_TIM, 2, 28, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_RAD, 2, 29, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_KEY, 2, 30, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_SLI, 2, 32, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_DPI, 2, 33, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_DFA, 2, 40, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_L2C, 2, 48, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	for (i = 0; i < 4; i++)
+		octeon_irq_set_ciu_mapping(OCTEON_IRQ_TRACE0 + i, 2, i + 52,
+					   &octeon_irq_chip_ciu2, handle_level_irq);
+
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_IPDPPTHR, 3, 0,
+					   &octeon_irq_chip_ciu2, handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_IPD_DRP, 3, 2,
+					   &octeon_irq_chip_ciu2_edge, handle_edge_irq);
+	for (i = 0; i < 4; i++)
+		octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_TIMER0, 3, i + 8,
+						   &octeon_irq_chip_ciu2_edge,
+						   handle_edge_irq);
+
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_NAND, 3, 16, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_MIO, 3, 17, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_BOOTDMA, 3, 18,
+						   &octeon_irq_chip_ciu2, handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_TWSI, 3, 32, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_TWSI2, 3, 33, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_UART0, 3, 36, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_UART1, 3, 37, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_USBCTL, 3, 40,
+							   &octeon_irq_chip_ciu2, handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_USB0, 3, 44, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_PTP, 3, 48,
+						   &octeon_irq_chip_ciu2_edge, handle_edge_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_RST, 3, 63, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+
+	for (i = 0; i < 4; i++)
+		octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_PCI_INT0, 4, i,
+							   &octeon_irq_chip_ciu2, handle_level_irq);
+
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX_PASS1_X))
+		for (i = 0; i < 4; i++)
+			octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_PCI_MSI0, 4, i + 8,
+								   &octeon_irq_chip_ciu2,
+								   handle_level_irq);
+
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_PEM0, 4, 32, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_PEM1, 4, 33, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+
+	for (i = 0; i < 4; i++)
+		octeon_irq_set_ciu_mapping(OCTEON_IRQ_LMC0 + i, 5, i,
+						   &octeon_irq_chip_ciu2, handle_level_irq);
+
+	for (i = 0; i < 5; i++)
+		octeon_irq_set_ciu_mapping(OCTEON_IRQ_AGX0 + i, 6, i,
+						   &octeon_irq_chip_ciu2, handle_level_irq);
+	for (i = 0; i < 5; i++)
+		octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_GMX_DRP0 + i, 6, i + 8,
+								   &octeon_irq_chip_ciu2_edge,
+								   handle_edge_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_AGL, 6, 32, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+	octeon_irq_set_ciu_mapping(OCTEON_IRQ_MII0, 6, 40, &octeon_irq_chip_ciu2,
+							   handle_level_irq);
+
+	irq_set_chip_and_handler(OCTEON_IRQ_MBOX0, &octeon_irq_chip_ciu2_mbox,
+							 handle_percpu_irq);
+	irq_set_chip_and_handler(OCTEON_IRQ_MBOX1, &octeon_irq_chip_ciu2_mbox,
+							 handle_percpu_irq);
+	irq_set_chip_and_handler(OCTEON_IRQ_MBOX2, &octeon_irq_chip_ciu2_mbox,
+							 handle_percpu_irq);
+	irq_set_chip_and_handler(OCTEON_IRQ_MBOX3, &octeon_irq_chip_ciu2_mbox,
+							 handle_percpu_irq);
+
+	/* Enable the CIU lines */
+	set_c0_status(STATUSF_IP3 | STATUSF_IP2);
+	clear_c0_status(STATUSF_IP4);
+}
+
 void __init arch_init_irq(void)
 {
 #ifdef CONFIG_SMP
@@ -1007,7 +1495,10 @@ void __init arch_init_irq(void)
 	cpumask_clear(irq_default_affinity);
 	cpumask_set_cpu(smp_processor_id(), irq_default_affinity);
 #endif
-	octeon_irq_init_ciu();
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		octeon_irq_init_ciu2();
+	else
+		octeon_irq_init_ciu();
 }
 
 asmlinkage void plat_irq_dispatch(void)
diff --git a/arch/mips/cavium-octeon/setup.c b/arch/mips/cavium-octeon/setup.c
index 36643cf..8209a61 100644
--- a/arch/mips/cavium-octeon/setup.c
+++ b/arch/mips/cavium-octeon/setup.c
@@ -35,6 +35,7 @@
 #include <asm/octeon/octeon.h>
 #include <asm/octeon/pci-octeon.h>
 #include <asm/octeon/cvmx-mio-defs.h>
+#include <asm/octeon/cvmx-sso-defs.h>
 
 #ifdef CONFIG_CAVIUM_DECODE_RSL
 extern void cvmx_interrupt_rsl_decode(void);
@@ -399,10 +400,17 @@ void octeon_user_io_init(void)
 	fau_timeout.s.tout_enb = 0;
 	cvmx_write_csr(CVMX_IOB_FAU_TIMEOUT, fau_timeout.u64);
 
-	nm_tim.u64 = 0;
-	/* 4096 cycles */
-	nm_tim.s.nw_tim = 3;
-	cvmx_write_csr(CVMX_POW_NW_TIM, nm_tim.u64);
+        if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+                nm_tim.u64 = 0;
+                /* 4096 cycles */
+                nm_tim.s.nw_tim = 3;
+                cvmx_write_csr(CVMX_SSO_NW_TIM, nm_tim.u64);
+        } else {
+		nm_tim.u64 = 0;
+		/* 4096 cycles */
+		nm_tim.s.nw_tim = 3;
+		cvmx_write_csr(CVMX_POW_NW_TIM, nm_tim.u64);
+	}
 
 	write_octeon_c0_icacheerr(0);
 	write_c0_derraddr1(0);
@@ -769,10 +777,113 @@ void prom_free_prom_memory(void)
 #ifdef CONFIG_CAVIUM_DECODE_RSL
 	cvmx_interrupt_rsl_enable();
 
-	/* Add an interrupt handler for general failures. */
-	if (request_irq(OCTEON_IRQ_RML, octeon_rlm_interrupt, IRQF_SHARED,
-			"RML/RSL", octeon_rlm_interrupt)) {
-		panic("Unable to request_irq(OCTEON_IRQ_RML)");
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+		int i;
+		if (request_irq(OCTEON_IRQ_NAND, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "NAND RML_RSL",
+					cvmx_error_get_index(CVMX_NDF_INT))) {
+			panic("Unable to request_irq(OCTEON_IRQ_NAND)");
+		}
+		if (request_irq(OCTEON_IRQ_MIO, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "MIO RML_RSL",
+					cvmx_error_get_index(CVMX_MIO_RST_INT))) {
+			panic("Unable to request_irq(OCTEON_IRQ_MIO)");
+		}
+		if (request_irq(OCTEON_IRQ_FPA, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "FPA RML_RSL",
+					cvmx_error_get_index(CVMX_FPA_INT_SUM))) {
+			panic("Unable to request_irq(OCTEON_IRQ_FPA)");
+		}
+		if (request_irq(OCTEON_IRQ_L2C, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "L2C RML_RSL",
+					cvmx_error_get_index(CVMX_L2C_INT_REG))) {
+			panic("Unable to request_irq(OCTEON_IRQ_L2C)");
+		}
+		if (request_irq(OCTEON_IRQ_IPD, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "IPD RML_RSL",
+					cvmx_error_get_index(CVMX_IPD_INT_SUM))) {
+			panic("Unable to request_irq(OCTEON_IRQ_IPD)");
+		}
+		if (request_irq(OCTEON_IRQ_PIP, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "PIP RML_RSL",
+					cvmx_error_get_index(CVMX_PIP_INT_REG))) {
+			panic("Unable to request_irq(OCTEON_IRQ_PIP)");
+		}
+		if (request_irq(OCTEON_IRQ_PKO, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "PKO RML_RSL",
+					cvmx_error_get_index(CVMX_PKO_REG_ERROR))) {
+			panic("Unable to request_irq(OCTEON_IRQ_PKO)");
+		}
+		if (request_irq(OCTEON_IRQ_ZIP, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "ZIP RML_RSL",
+					cvmx_error_get_index(CVMX_ZIP_ERROR))) {
+			panic("Unable to request_irq(OCTEON_IRQ_ZIP)");
+		}
+		if (request_irq(OCTEON_IRQ_RAD, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "RAD RML_RSL",
+					cvmx_error_get_index(CVMX_RAD_REG_ERROR))) {
+			panic("Unable to request_irq(OCTEON_IRQ_RAD)");
+		}
+		if (request_irq(OCTEON_IRQ_KEY, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "KEY RML_RSL",
+					cvmx_error_get_index(CVMX_KEY_INT_SUM))) {
+			panic("Unable to request_irq(OCTEON_IRQ_KEY)");
+		}
+		/* Disable any pending SLI interrupt */
+		if (cvmx_read_csr(CVMX_PEXP_SLI_INT_SUM) & 0x1)	{
+			pr_info("clearing pending SLI_INT_SUM[RML_TO] (ignore)");
+			cvmx_write_csr(CVMX_PEXP_SLI_INT_SUM, 1);
+		}
+		if (request_irq(OCTEON_IRQ_SLI, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "SLI RML_RSL",
+					cvmx_error_get_index(
+						CVMX_PEXP_SLI_INT_SUM))) {
+			panic("Unable to request_irq(OCTEON_IRQ_SLI)");
+		}
+		if (request_irq(OCTEON_IRQ_DFA, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "DFA RML_RSL",
+					cvmx_error_get_index(CVMX_DFA_ERROR))) {
+			panic("Unable to request_irq(OCTEON_IRQ_DFA)");
+		}
+		if (request_irq(OCTEON_IRQ_DPI, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "DPI RML_RSL",
+					cvmx_error_get_index(CVMX_DPI_INT_REG))) {
+			panic("Unable to request_irq(OCTEON_IRQ_DPI)");
+		}
+		if (request_irq(OCTEON_IRQ_AGL, octeon_rml_interrupt_v2,
+					IRQF_SHARED, "AGL RML_RSL",
+					cvmx_error_get_index(
+						CVMX_AGL_GMX_BAD_REG))) {
+			panic("Unable to request_irq(OCTEON_IRQ_AGL)");
+		}
+		for (i = 0; i < 4; i++) {
+			cvmx_lmcx_dll_ctl2_t ctl2;
+			cvmx_error_info_t *index;
+
+			/*
+			 * Check if LMC is initialized before enabling
+			 * the interrupts.
+			 */
+			ctl2.u64 = cvmx_read_csr(CVMX_LMCX_DLL_CTL2(i));
+			if (ctl2.s.intf_en == 0)
+				continue;
+
+			/* Clear pending interrupts before enabling it. */
+			cvmx_write_csr(CVMX_LMCX_INT(i),
+				       cvmx_read_csr(CVMX_LMCX_INT(i)));
+
+			index = cvmx_error_get_index(CVMX_LMCX_INT(i));
+			if (request_irq(OCTEON_IRQ_LMC0 + i,
+					octeon_rml_interrupt_v2, IRQF_SHARED,
+					"LMC RML_RSL", index))
+				panic("Unable to request_irq(OCTEON_IRQ_LMC%d)", i);
+		}
+	} else {
+		/* Add an interrupt handler for general failures. */
+		if (request_irq(OCTEON_IRQ_RML, octeon_rlm_interrupt, IRQF_SHARED,
+				"RML/RSL", octeon_rlm_interrupt)) {
+			panic("Unable to request_irq(OCTEON_IRQ_RML)");
+		}
 	}
 #endif
 }
diff --git a/arch/mips/include/asm/mach-cavium-octeon/irq.h b/arch/mips/include/asm/mach-cavium-octeon/irq.h
index 5b05f18..31b9838 100644
--- a/arch/mips/include/asm/mach-cavium-octeon/irq.h
+++ b/arch/mips/include/asm/mach-cavium-octeon/irq.h
@@ -21,11 +21,13 @@ enum octeon_irq {
 	OCTEON_IRQ_TIMER,
 /* sources in CIU_INTX_EN0 */
 	OCTEON_IRQ_WORKQ0,
-	OCTEON_IRQ_GPIO0 = OCTEON_IRQ_WORKQ0 + 16,
-	OCTEON_IRQ_WDOG0 = OCTEON_IRQ_GPIO0 + 16,
-	OCTEON_IRQ_WDOG15 = OCTEON_IRQ_WDOG0 + 15,
-	OCTEON_IRQ_MBOX0 = OCTEON_IRQ_WDOG0 + 16,
-	OCTEON_IRQ_MBOX1,
+        OCTEON_IRQ_GPIO0 = OCTEON_IRQ_WORKQ0 + 64,
+        OCTEON_IRQ_WDOG0 = OCTEON_IRQ_GPIO0 + 16,
+        OCTEON_IRQ_WDOG31 = OCTEON_IRQ_WDOG0 + 31,
+        OCTEON_IRQ_MBOX0 = OCTEON_IRQ_WDOG0 + 32,
+        OCTEON_IRQ_MBOX1,
+        OCTEON_IRQ_MBOX2,
+        OCTEON_IRQ_MBOX3,
 	OCTEON_IRQ_UART0,
 	OCTEON_IRQ_UART1,
 	OCTEON_IRQ_UART2,
diff --git a/drivers/of/irq.c b/drivers/of/irq.c
index 9cf0060..3fe3472 100644
--- a/drivers/of/irq.c
+++ b/drivers/of/irq.c
@@ -34,15 +34,21 @@
  * This function is a wrapper that chains of_irq_map_one() and
  * irq_create_of_mapping() to make things easier to callers
  */
+unsigned int octeon_irq_create_of_mapping(struct device_node *controller,
+                                   const u32 *intspec, unsigned int intsize);
 unsigned int irq_of_parse_and_map(struct device_node *dev, int index)
 {
 	struct of_irq oirq;
 
 	if (of_irq_map_one(dev, index, &oirq))
 		return 0;
-
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	return octeon_irq_create_of_mapping(oirq.controller, oirq.specifier,
+				     oirq.size);
+#else
 	return irq_create_of_mapping(oirq.controller, oirq.specifier,
 				     oirq.size);
+#endif
 }
 EXPORT_SYMBOL_GPL(irq_of_parse_and_map);
 
-- 
1.7.9.7

