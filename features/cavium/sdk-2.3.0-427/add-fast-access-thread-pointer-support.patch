From ff97a4536fe7d7a30e76c6ffd3f5b5c08c2e6abd Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Thu, 30 Aug 2012 17:47:57 +0800
Subject: [PATCH 25/27] add fast access thread pointer support

For MIPS, normally the TLS thread pointer is accessed by the
userspace program executing a "rdhwr" from register $29. This
register doesn't exist, so the kernel emulates the instruction
assigning the thread pointer to the value register. This option
supplies an alternate, faster access to the thread pointer. A
side effect of this option is that the highest 8 bytes of CVMSEG
is used by the kernel to save and restore the thread pointer during
the TLB fault handlers. This CVMSEG address isn't available to user
applications.

Based on SDK 2.3.0-427

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/cavium-octeon/Kconfig    |   15 +++++++++++++++
 arch/mips/include/asm/mipsregs.h   |   11 ++++++++++-
 arch/mips/include/asm/stackframe.h |    3 +++
 arch/mips/kernel/genex.S           |    6 ++++++
 arch/mips/kernel/octeon_switch.S   |    9 +++++++++
 arch/mips/kernel/syscall.c         |   16 ++++++++++++++++
 arch/mips/mm/tlbex.c               |   15 +++++++++++++++
 7 files changed, 74 insertions(+), 1 deletion(-)

diff --git a/arch/mips/cavium-octeon/Kconfig b/arch/mips/cavium-octeon/Kconfig
index 929018e..fda637e 100644
--- a/arch/mips/cavium-octeon/Kconfig
+++ b/arch/mips/cavium-octeon/Kconfig
@@ -41,6 +41,21 @@ config CAVIUM_OCTEON_CVMSEG_SIZE
 	  legally range is from zero to 54 cache blocks (i.e. CVMSEG LM is
 	  between zero and 6192 bytes).
 
+config FAST_ACCESS_TO_THREAD_POINTER
+        bool "Enable fast access to the thread pointer"
+        depends on CPU_CAVIUM_OCTEON
+        default "y"
+        help
+          For MIPS, normally the TLS thread pointer is accessed by the
+          userspace program executing a "rdhwr" from register $29. This
+          register doesn't exist, so the kernel emulates the instruction
+          assigning the thread pointer to the value register. This option
+          supplies an alternate, faster access to the thread pointer. A
+          side effect of this option is that the highest 8 bytes of CVMSEG
+          is used by the kernel to save and restore the thread pointer during
+          the TLB fault handlers. This CVMSEG address isn't available to user
+          applications.
+
 config REPLACE_EMULATED_ACCESS_TO_THREAD_POINTER
         bool "Support dynamically replacing emulated thread pointer accesses"
         depends on FAST_ACCESS_TO_THREAD_POINTER
diff --git a/arch/mips/include/asm/mipsregs.h b/arch/mips/include/asm/mipsregs.h
index d3ea319..e64be7c6 100644
--- a/arch/mips/include/asm/mipsregs.h
+++ b/arch/mips/include/asm/mipsregs.h
@@ -601,7 +601,6 @@
 
 #define MIPS_CONF7_RPS		(_ULCAST_(1) << 2)
 
-
 /*
  * Bits in the MIPS32/64 coprocessor 1 (FPU) revision register.
  */
@@ -613,6 +612,16 @@
 #define MIPS_FPIR_L		(_ULCAST_(1) << 21)
 #define MIPS_FPIR_F64		(_ULCAST_(1) << 22)
 
+/*
+ * These defines are used on Octeon to implement fast access to the
+ * thread pointer from userspace. Octeon uses a 64bit location in
+ * CVMSEG to store the thread pointer for quick access.
+ */
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+#define FAST_ACCESS_THREAD_OFFSET       (CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE * 128 - 8 - 32768)
+#define FAST_ACCESS_THREAD_REGISTER     (*(unsigned long *)(FAST_ACCESS_THREAD_OFFSET))
+#endif
+
 #ifndef __ASSEMBLY__
 
 /*
diff --git a/arch/mips/include/asm/stackframe.h b/arch/mips/include/asm/stackframe.h
index cb41af5..5417ee1 100644
--- a/arch/mips/include/asm/stackframe.h
+++ b/arch/mips/include/asm/stackframe.h
@@ -449,6 +449,9 @@
 		.macro	RESTORE_SP_AND_RET
 		LONG_L	sp, PT_R29(sp)
 		.set	mips3
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+                LONG_L  k0, FAST_ACCESS_THREAD_OFFSET($0) /* K0 = thread pointer */
+#endif
 		eret
 		.set	mips0
 		.endm
diff --git a/arch/mips/kernel/genex.S b/arch/mips/kernel/genex.S
index 8882e57..691d81e 100644
--- a/arch/mips/kernel/genex.S
+++ b/arch/mips/kernel/genex.S
@@ -190,6 +190,9 @@ NESTED(handle_int, PT_SIZE, sp)
 	and	k0, ST0_IE
 	bnez	k0, 1f
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+        LONG_L  k0, FAST_ACCESS_THREAD_OFFSET($0)
+#endif
 	eret
 #endif
 1:
@@ -532,6 +535,9 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	ori	k1, _THREAD_MASK
 	xori	k1, _THREAD_MASK
 	LONG_L	v1, TI_TP_VALUE(k1)
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+        move    k0, v1
+#endif
 	.set	mips3
 	eret
 	.set	mips0
diff --git a/arch/mips/kernel/octeon_switch.S b/arch/mips/kernel/octeon_switch.S
index ce89c80..d232abc 100644
--- a/arch/mips/kernel/octeon_switch.S
+++ b/arch/mips/kernel/octeon_switch.S
@@ -114,6 +114,15 @@
 #endif
 	set_saved_sp	t0, t1, t2
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+        /* We need to put the thread pointer in CVMMEM immediately. The
+         * kernel will use this value during TLB exceptions even
+         * though userspace hasn't accessed CVMMEM
+         */
+        LONG_L  t1, TI_TP_VALUE($28)
+        LONG_S  t1, FAST_ACCESS_THREAD_OFFSET($0)
+#endif
+
 	mfc0	t1, CP0_STATUS		/* Do we really need this? */
 	li	a3, 0xff01
 	and	t1, a3
diff --git a/arch/mips/kernel/syscall.c b/arch/mips/kernel/syscall.c
index 6736233..5435250 100644
--- a/arch/mips/kernel/syscall.c
+++ b/arch/mips/kernel/syscall.c
@@ -44,6 +44,11 @@
 #include <asm/uaccess.h>
 #include <asm/switch_to.h>
 
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS) || \
+       defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+#include <asm/processor.h>
+#endif
+
 /*
  * For historic reasons the pipe(2) syscall on MIPS has an unusual calling
  * convention.  It returns results in registers $v0 / $v1 which means there
@@ -162,6 +167,9 @@ SYSCALL_DEFINE1(set_thread_area, unsigned long, addr)
 	if (cpu_has_userlocal)
 		write_c0_userlocal(addr);
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+        FAST_ACCESS_THREAD_REGISTER = addr;
+#endif
 	return 0;
 }
 
@@ -297,6 +305,14 @@ _sys_sysmips(nabi_no_regargs struct pt_regs regs)
 	case FLUSH_CACHE:
 		__flush_cache_all();
 		return 0;
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS) || \
+        defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+        case MIPS_CAVIUM_XKPHYS_READ:
+                return xkphys_usermem_read(arg1);
+
+        case MIPS_CAVIUM_XKPHYS_WRITE:
+                return xkphys_usermem_write(arg1, arg2);
+#endif
 	}
 
 	return -EINVAL;
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index b69f80f..bcbeb26 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -1201,15 +1201,24 @@ build_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,
 		UASM_i_MFC0(p, scratch, 31, c0_scratch);
 		build_tlb_write_entry(p, l, r, tlb_random);
 		uasm_l_leave(l, *p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+                UASM_i_MFC0(p, K0, 4, 2);
+#endif
 		rv.restore_scratch = 1;
 	} else if (PAGE_SHIFT == 14 || PAGE_SHIFT == 13)  {
 		build_tlb_write_entry(p, l, r, tlb_random);
 		uasm_l_leave(l, *p);
 		UASM_i_LW(p, scratch, scratchpad_offset(0), 0);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+                UASM_i_LW(p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread pointer */
+#endif
 	} else {
 		UASM_i_LW(p, scratch, scratchpad_offset(0), 0);
 		build_tlb_write_entry(p, l, r, tlb_random);
 		uasm_l_leave(l, *p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+                UASM_i_LW(p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread pointer */
+#endif
 		rv.restore_scratch = 1;
 	}
 
@@ -1280,6 +1289,9 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 		build_update_entries(&p, K0, K1);
 		build_tlb_write_entry(&p, &l, &r, tlb_random);
 		uasm_l_leave(&l, p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+                UASM_i_LW(&p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread ptr */
+#endif
 		uasm_i_eret(&p); /* return from trap */
 	}
 #ifdef CONFIG_HUGETLB_PAGE
@@ -1837,6 +1849,9 @@ build_r4000_tlbchange_handler_tail(u32 **p, struct uasm_label **l,
 	build_tlb_write_entry(p, l, r, tlb_indexed);
 	uasm_l_leave(l, *p);
 	build_restore_work_registers(p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+        UASM_i_LW(p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread ptr */
+#endif
 	uasm_i_eret(p); /* return from trap */
 
 #ifdef CONFIG_64BIT
-- 
1.7.9.7

