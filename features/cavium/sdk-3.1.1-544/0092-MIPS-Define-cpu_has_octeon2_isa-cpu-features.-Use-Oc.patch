From 59f4d7dc83ae4551689eb507e2fd7f7c6248fd47 Mon Sep 17 00:00:00 2001
From: David Daney <ddaney@caviumnetworks.com>
Date: Fri, 13 Feb 2015 14:47:00 +0530
Subject: [PATCH 092/148] MIPS: Define cpu_has_octeon2_isa cpu features. Use
 Octeon2 atomic instructions when cpu_has_octeon2_isa.

Commit 8d7ba43f6cfc876773652f99f7ec2c9089c0cb1a from
git://git.yoctoproject.org/linux-yocto-3.14

Only use SAA instructions for CONFIG_CAVIUM_OCTEON2.

Add octeon2 build and configuration option.

Fix arch in assembly for saa instruction.

Add cpu_has_saa to cpu-features.h

Signed-off-by: David Daney <ddaney@caviumnetworks.com>
Signed-off-by: Leonid Rosenboim <lrosenboim@caviumnetworks.com>
Signed-off-by: Andrew Pinski <apinski@cavium.com>
Signed-off-by: Abhishek Paliwal <abhishek.paliwal@aricent.com>
---
 arch/mips/Makefile                                 |  16 ++-
 arch/mips/cavium-octeon/Kconfig                    | 127 ++++++++++++++++++++-
 arch/mips/cavium-octeon/setup.c                    |   7 +-
 arch/mips/include/asm/atomic.h                     | 120 +++++++++++++++++--
 arch/mips/include/asm/barrier.h                    |  14 ++-
 arch/mips/include/asm/cmpxchg.h                    |  36 +++++-
 arch/mips/include/asm/cpu-features.h               |   3 +
 .../asm/mach-cavium-octeon/cpu-feature-overrides.h |  14 +--
 arch/mips/kernel/unaligned.c                       |   5 -
 9 files changed, 308 insertions(+), 34 deletions(-)

diff --git a/arch/mips/Makefile b/arch/mips/Makefile
index 90acd4b..69bd6f7 100644
--- a/arch/mips/Makefile
+++ b/arch/mips/Makefile
@@ -154,9 +154,19 @@ cflags-$(CONFIG_CPU_SB1)	+= $(call cc-option,-march=sb1,-march=r5000) \
 cflags-$(CONFIG_CPU_R8000)	+= -march=r8000 -Wa,--trap
 cflags-$(CONFIG_CPU_R10000)	+= $(call cc-option,-march=r10000,-march=r8000) \
 			-Wa,--trap
-cflags-$(CONFIG_CPU_CAVIUM_OCTEON) += $(call cc-option,-march=octeon) -Wa,--trap
-ifeq (,$(findstring march=octeon, $(cflags-$(CONFIG_CPU_CAVIUM_OCTEON))))
-cflags-$(CONFIG_CPU_CAVIUM_OCTEON) += -Wa,-march=octeon
+
+ifdef CONFIG_CPU_CAVIUM_OCTEON
+ifdef CONFIG_CAVIUM_OCTEON2
+cflags-y += $(call cc-option,-march=octeon2) -Wa,--trap
+ifeq (,$(findstring march=octeon2, $(cflags-y)))
+cflags-y += -Wa,-march=octeon2
+endif
+else
+cflags-y += $(call cc-option,-march=octeon) -Wa,--trap
+ifeq (,$(findstring march=octeon, $(cflags-y)))
+cflags-y += -Wa,-march=octeon
+endif
+endif
 endif
 
 cflags-$(CONFIG_CPU_CAVIUM_OCTEON) += -DCVMX_BUILD_FOR_LINUX_KERNEL=1 -DUSE_RUNTIME_MODEL_CHECKS=1
diff --git a/arch/mips/cavium-octeon/Kconfig b/arch/mips/cavium-octeon/Kconfig
index b74c13c..c88eca4 100644
--- a/arch/mips/cavium-octeon/Kconfig
+++ b/arch/mips/cavium-octeon/Kconfig
@@ -63,6 +63,68 @@ config FAST_ACCESS_TO_THREAD_POINTER
 	  the TLB fault handlers. This CVMSEG address is not available to user
 	  applications.
 
+choice
+	prompt "Allow User space to access hardware IO directly"
+	default CAVIUM_OCTEON_USER_IO_PER_PROCESS
+	depends on CPU_CAVIUM_OCTEON
+
+config CAVIUM_OCTEON_USER_IO
+	bool "Allowed"
+	depends on CPU_CAVIUM_OCTEON
+	help
+	  Allows user applications to directly access the Octeon hardware
+	  IO addresses (0x1000000000000 - 0x1ffffffffffff). This allows high
+	  performance networking applications to run in user space with minimal
+	  performance penalties. This also means a user application can bring
+	  down the entire system. Only use this option on embedded devices
+	  where all user applications are strictly controlled.
+
+config CAVIUM_OCTEON_USER_IO_PER_PROCESS
+	bool "Per process"
+	help
+	  Allows user applications to use XKPHYS addresses directly to IO.
+	  This option dynamically enable/disable with sysmips syscall,
+	  by a process with root privilege. Without root privilege you can
+	  only remove access.
+
+config CAVIUM_OCTEON_USER_IO_DISABLED
+	bool "Disabled"
+
+endchoice
+
+choice
+	prompt "Allow User space to access memory directly"
+	default CAVIUM_OCTEON_USER_MEM_PER_PROCESS
+	depends on CPU_CAVIUM_OCTEON
+
+config CAVIUM_OCTEON_USER_MEM
+	bool "Allowed"
+	help
+	  Allows user applications to use XKPHYS addresses directly to memory.
+	  This allows user space direct access to shared memory not in use by
+	  Linux. This memory is suitable for use with the Octeon hardware.
+	  Cavium simple executive applications also share this memory. Since
+	  this bypass all of the Linux memory protection, only use this option
+	  on embedded devices where all user applications are strictly
+	  controlled.
+
+config CAVIUM_OCTEON_USER_MEM_PER_PROCESS
+	bool "Per process"
+	help
+	  Allows user applications to use XKPHYS addresses directly to memory.
+	  This option dynamically enable/disable with sysmips syscall,
+	  by a process with root privilege. Without root privilege you can only
+	  remove access.
+
+config CAVIUM_OCTEON_USER_MEM_DISABLED
+	bool "Disabled"
+
+endchoice
+
+endif # CPU_CAVIUM_OCTEON
+
+if CAVIUM_OCTEON_SOC
+
 config CAVIUM_OCTEON_LOCK_L2
 	bool "Lock often used kernel code in the L2"
 	default "y"
@@ -104,6 +166,53 @@ config CAVIUM_OCTEON_LOCK_L2_MEMCPY
 	help
 	  Lock the kernel's implementation of memcpy() into L2.
 
+config CAVIUM_RESERVE32
+	int "Memory to reserve for user processes shared region (MB)"
+	range 0 1536
+	depends on CPU_CAVIUM_OCTEON
+	default "0"
+	help
+	  Reserve a shared memory region for user processes to use for hardware
+	  memory buffers. This is required for 32bit applications to be able to
+	  send and receive packets directly. Applications access this memory by
+	  memory mapping /dev/mem for the addresses in /proc/octeon_info. For
+	  optimal performance with HugeTLBs, keep this size an even number of
+	  megabytes.
+
+config CAVIUM_OCTEON_NAND
+	tristate "Octeon NAND driver"
+	depends on MTD_NAND && !CPU_LITTLE_ENDIAN
+	help
+	  This option enables a MTD driver for the NAND controller introduced
+	  in the Octeon CN52XX pass 2 processor. It supports up to 8 NAND
+	  devices connected directly to Octeon's boot bus.
+
+config CAVIUM_OCTEON_RAPIDIO
+	bool "Enable support for Octeon Serial Rapid IO"
+	select RAPIDIO
+	select OCTEON_ETHERNET_MEM
+	help
+	  Connect the SRIO interfaces available in the Octeon II series of
+	  processors to the kernel's RapidIO subsystem. The existence of the
+	  SRIO ports is automatically detected and configured as either a
+	  host or device. Bus enumeration will be performed on host interfaces
+	  as appropriate. After configuring this option, you will likely want
+	  to enable the RapidIO network adapter under the devices menu.
+
+config CAVIUM_OCTEON_ERROR_TREE
+	bool "OCTEON hardware error reporting"
+	default y
+	help
+	  Install handlers for error signals from many on-SoC devices.
+
+config CAVIUM_OCTEON_KERNEL_CRYPTO
+	bool "Enable support for use of OCTEON crypto instructions from kernel code"
+	help
+	  Use of OCTEON crypto instructions from kernel code requires
+	  great care, and if done improperly, can corrupt userspace
+	  crypto state.  If OCTEON crypto instruction support is
+	  needed, select this option.
+
 config CAVIUM_OCTEON_PERF
 	bool "OCTEON-specific hardware performance counters"
 	default y
@@ -122,6 +231,12 @@ config SWIOTLB
 	select IOMMU_HELPER
 	select NEED_SG_DMA_LENGTH
 
+config DISABLE_ELF_NOTE_HEADER
+	bool "Disable the creation of the ELF PT_NOTE program header in vmlinux"
+	help
+	  Some early Octeon bootloaders cannot process PT_NOTE program
+	  headers.  Select y to omit these headers so that the kernel
+	  can be loaded with older bootloaders.
 
 config OCTEON_ILM
 	tristate "Module to measure interrupt latency using Octeon CIU Timer"
@@ -132,4 +247,14 @@ config OCTEON_ILM
 	  To compile this driver as a module, choose M here.  The module
 	  will be called octeon-ilm
 
-endif # CAVIUM_OCTEON_SOC
+config OCTEON_ERROR_INJECTOR
+	tristate "Module to inject hardware errors into the system"
+	help
+	  Used to test hardware error reporting.  Should never be used
+	  in a normal running system.
+
+# To be enabled later
+# source "arch/mips/cavium-octeon/executive/Kconfig"
+
+endif # CPU_CAVIUM_OCTEON
+
diff --git a/arch/mips/cavium-octeon/setup.c b/arch/mips/cavium-octeon/setup.c
index 9757112..c870cb2 100644
--- a/arch/mips/cavium-octeon/setup.c
+++ b/arch/mips/cavium-octeon/setup.c
@@ -265,7 +265,7 @@ static void octeon_crash_shutdown(struct pt_regs *regs)
 
 #endif /* CONFIG_KEXEC */
 
-#ifdef CONFIG_CAVIUM_RESERVE32
+#ifndef CONFIG_CAVIUM_RESERVE32
 #define  CONFIG_CAVIUM_RESERVE32        0ULL
 #endif
 
@@ -680,9 +680,6 @@ void __init prom_init(void)
 	int argc;
 
 	octeon_scache_init = octeon_soc_scache_init;
-#ifdef CONFIG_CAVIUM_RESERVE32
-	int64_t addr = -1;
-#endif
 	/*
 	 * The bootloader passes a pointer to the boot descriptor in
 	 * $a3, this is available as fw_arg3.
@@ -811,7 +808,6 @@ void __init prom_init(void)
 	 * Allocate memory for RESERVED32 aligned on 2MB boundary. This
 	 * is in case we later use hugetlb entries with it.
 	 */
-#ifdef CONFIG_CAVIUM_RESERVE32
 	if (CONFIG_CAVIUM_RESERVE32 > 0) {
 		int64_t addr = -1;
 		addr = cvmx_bootmem_phy_named_block_alloc(
@@ -823,7 +819,6 @@ void __init prom_init(void)
 		else
 			octeon_reserve32_memory = addr;
 	}
-#endif
 	octeon_check_cpu_bist();
 
 	octeon_uart = octeon_get_boot_uart();
diff --git a/arch/mips/include/asm/atomic.h b/arch/mips/include/asm/atomic.h
index 7eed2f2..c7f1d34 100644
--- a/arch/mips/include/asm/atomic.h
+++ b/arch/mips/include/asm/atomic.h
@@ -49,7 +49,15 @@
  */
 static __inline__ void atomic_add(int i, atomic_t * v)
 {
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_saa) {
+		__asm__ __volatile__(
+		".set	push\n\t"
+		".set	arch=octeon+\n\t"
+		"saa    %1, (%2)\t# atomic_add (%0)\n\t"
+		".set	pop"
+		: "+m" (v->counter)
+		: "r" (i), "r" (&v->counter));
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
 		__asm__ __volatile__(
@@ -92,7 +100,15 @@ static __inline__ void atomic_add(int i, atomic_t * v)
  */
 static __inline__ void atomic_sub(int i, atomic_t * v)
 {
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_saa) {
+		__asm__ __volatile__(
+		".set	push\n\t"
+		".set	arch=octeon+\n\t"
+		"saa    %1, (%2)\t# atomic_sub(%0)\n\t"
+		".set	pop"
+		: "+m" (v->counter)
+		: "r" (-i), "r" (&v->counter));
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
 		__asm__ __volatile__(
@@ -135,7 +151,25 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 
 	smp_mb__before_llsc();
 
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_octeon2_isa && kernel_uses_llsc) {
+		/*
+		 * For proper barrier semantics, the preceding
+		 * smp_mb__before_llsc() must expand to syncw.
+		 */
+		if (__builtin_constant_p(i) && i == 1)
+			__asm__ __volatile__("lai\t%0,(%2)\t# atomic_add_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter));
+		else if (__builtin_constant_p(i) && i == -1)
+			__asm__ __volatile__("lad\t%0,(%2)\t# atomic_add_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter));
+		else
+			__asm__ __volatile__("laa\t%0,(%2),%3\t# atomic_add_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter), "r" (i));
+		result += i;
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
 		__asm__ __volatile__(
@@ -184,7 +218,25 @@ static __inline__ int atomic_sub_return(int i, atomic_t * v)
 
 	smp_mb__before_llsc();
 
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_octeon2_isa && kernel_uses_llsc) {
+		/*
+		 * For proper barrier semantics, the preceding
+		 * smp_mb__before_llsc() must expand to syncw.
+		 */
+		if (__builtin_constant_p(i) && i == -1)
+			__asm__ __volatile__("lai\t%0,(%2)\t# atomic_sub_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter));
+		else if (__builtin_constant_p(i) && i == 1)
+			__asm__ __volatile__("lad\t%0,(%2)\t# atomic_sub_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter));
+		else
+			__asm__ __volatile__("laa\t%0,(%2),%3\t# atomic_sub_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter), "r" (-i));
+		result -= i;
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
 		__asm__ __volatile__(
@@ -416,7 +468,15 @@ static __inline__ int __atomic_add_unless(atomic_t *v, int a, int u)
  */
 static __inline__ void atomic64_add(long i, atomic64_t * v)
 {
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_saa) {
+		__asm__ __volatile__(
+		".set	push\n\t"
+		".set	arch=octeon+\n\t"
+		"saad   %1, (%2)\t# atomic64_add (%0)\n\t"
+		".set	pop"
+		: "+m" (v->counter)
+		: "r" (i), "r" (v));
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		long temp;
 
 		__asm__ __volatile__(
@@ -459,7 +519,15 @@ static __inline__ void atomic64_add(long i, atomic64_t * v)
  */
 static __inline__ void atomic64_sub(long i, atomic64_t * v)
 {
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_saa) {
+		__asm__ __volatile__(
+		".set	push\n\t"
+		".set	arch=octeon+\n\t"
+		"saad    %1, (%2)\t# atomic64_sub (%0)\n\t"
+		".set	pop"
+		: "+m" (v->counter)
+		: "r" (-i), "r" (v));
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		long temp;
 
 		__asm__ __volatile__(
@@ -502,7 +570,25 @@ static __inline__ long atomic64_add_return(long i, atomic64_t * v)
 
 	smp_mb__before_llsc();
 
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_octeon2_isa && kernel_uses_llsc) {
+		/*
+		 * For proper barrier semantics, the preceding
+		 * smp_mb__before_llsc() must expand to syncw.
+		 */
+		if (__builtin_constant_p(i) && i == 1)
+			__asm__ __volatile__("laid\t%0,(%2)\t# atomic64_add_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter));
+		else if (__builtin_constant_p(i) && i == -1)
+			__asm__ __volatile__("ladd\t%0,(%2)\t# atomic64_add_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter));
+		else
+			__asm__ __volatile__("laad\t%0,(%2),%3\t# atomic64_add_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter), "r" (i));
+		result += i;
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		long temp;
 
 		__asm__ __volatile__(
@@ -552,7 +638,25 @@ static __inline__ long atomic64_sub_return(long i, atomic64_t * v)
 
 	smp_mb__before_llsc();
 
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_octeon2_isa && kernel_uses_llsc) {
+		/*
+		 * For proper barrier semantics, the preceding
+		 * smp_mb__before_llsc() must expand to syncw.
+		 */
+		if (__builtin_constant_p(i) && i == -1)
+			__asm__ __volatile__("laid\t%0,(%2)\t# atomic64_sub_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter));
+		else if (__builtin_constant_p(i) && i == 1)
+			__asm__ __volatile__("ladd\t%0,(%2)\t# atomic64_sub_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter));
+		else
+			__asm__ __volatile__("laad\t%0,(%2),%3\t# atomic64_sub_return (%1)"
+					: "=r" (result), "+m" (v->counter)
+					: "r" (&v->counter), "r" (-i));
+		result -= i;
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		long temp;
 
 		__asm__ __volatile__(
diff --git a/arch/mips/include/asm/barrier.h b/arch/mips/include/asm/barrier.h
index e1aa4e4..07c6f0e 100644
--- a/arch/mips/include/asm/barrier.h
+++ b/arch/mips/include/asm/barrier.h
@@ -91,7 +91,19 @@
 		: "m" (*(int *)CKSEG1)		\
 		: "memory")
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
-# define OCTEON_SYNCW_STR	".set push\n.set arch=octeon\nsyncw\nsyncw\n.set pop\n"
+# ifdef CONFIG_CAVIUM_OCTEON2
+#  define OCTEON_SYNCW_STR	".set push\n\t.set arch=octeon\n\tsyncw\n\t.set pop"
+# else
+/*
+ * We actually use two syncw instructions in a row when we need a
+ * write memory barrier. This is because the CN3XXX series of Octeons
+ * have errata Core-401.  This can cause a single syncw to not enforce
+ * ordering under very rare conditions. Even if it is rare, better
+ * safe than sorry.
+ */
+#  define OCTEON_SYNCW_STR	".set push\n.set arch=octeon\nsyncw\nsyncw\n.set pop\n"
+# endif /* CONFIG_CAVIUM_OCTEON2 */
+
 # define __syncw()	__asm__ __volatile__(OCTEON_SYNCW_STR : : : "memory")
 
 # define fast_wmb()	__syncw()
diff --git a/arch/mips/include/asm/cmpxchg.h b/arch/mips/include/asm/cmpxchg.h
index 466069b..7a61366 100644
--- a/arch/mips/include/asm/cmpxchg.h
+++ b/arch/mips/include/asm/cmpxchg.h
@@ -18,7 +18,23 @@ static inline unsigned long __xchg_u32(volatile int * m, unsigned int val)
 
 	smp_mb__before_llsc();
 
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_octeon2_isa && kernel_uses_llsc) {
+		if (__builtin_constant_p(val) && val == 0)
+			__asm__ __volatile__("lac\t%0,(%1)\t# xchg_u32"
+					: "=r" (retval)
+					: "r" (m)
+					: "memory");
+		else if (__builtin_constant_p(val) && val == 0xffffffffu)
+			__asm__ __volatile__("las\t%0,(%1)\t# xchg_u32"
+					: "=r" (retval)
+					: "r" (m)
+					: "memory");
+		else
+			__asm__ __volatile__("law\t%0,(%1),%2\t# xchg_u32"
+					: "=r" (retval)
+					: "r" (m), "r" (val)
+					: "memory");
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		unsigned long dummy;
 
 		__asm__ __volatile__(
@@ -70,7 +86,23 @@ static inline __u64 __xchg_u64(volatile __u64 * m, __u64 val)
 
 	smp_mb__before_llsc();
 
-	if (kernel_uses_llsc && R10000_LLSC_WAR) {
+	if (cpu_has_octeon2_isa && kernel_uses_llsc) {
+		if (__builtin_constant_p(val) && val == 0)
+			__asm__ __volatile__("lacd\t%0,(%1)\t# xchg_u64"
+					: "=r" (retval)
+					: "r" (m)
+					: "memory");
+		else if (__builtin_constant_p(val) && val == 0xffffffffffffffffull)
+			__asm__ __volatile__("lasd\t%0,(%1)\t# xchg_u64"
+					: "=r" (retval)
+					: "r" (m)
+					: "memory");
+		else
+			__asm__ __volatile__("lawd\t%0,(%1),%2\t# xchg_u64"
+					: "=r" (retval)
+					: "r" (m), "r" (val)
+					: "memory");
+	} else if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		unsigned long dummy;
 
 		__asm__ __volatile__(
diff --git a/arch/mips/include/asm/cpu-features.h b/arch/mips/include/asm/cpu-features.h
index 6e70b03..f95e6f3 100644
--- a/arch/mips/include/asm/cpu-features.h
+++ b/arch/mips/include/asm/cpu-features.h
@@ -133,6 +133,9 @@
 #ifndef cpu_has_local_ebase
 #define cpu_has_local_ebase	1
 #endif
+#ifndef cpu_has_octeon2_isa
+#define cpu_has_octeon2_isa 0
+#endif
 
 /*
  * I-Cache snoops remote store.	 This only matters on SMP.  Some multiprocessors
diff --git a/arch/mips/include/asm/mach-cavium-octeon/cpu-feature-overrides.h b/arch/mips/include/asm/mach-cavium-octeon/cpu-feature-overrides.h
index cf80228..0349d3b 100644
--- a/arch/mips/include/asm/mach-cavium-octeon/cpu-feature-overrides.h
+++ b/arch/mips/include/asm/mach-cavium-octeon/cpu-feature-overrides.h
@@ -45,7 +45,12 @@
 #define cpu_has_ic_fills_f_dc	0
 #define cpu_has_64bits		1
 #define cpu_has_octeon_cache	1
-#define cpu_has_saa		octeon_has_saa()
+#ifdef CONFIG_CAVIUM_OCTEON2
+#define cpu_has_octeon2_isa     1
+#define cpu_has_saa		1
+#else
+#define cpu_has_saa		0
+#endif
 #define cpu_has_mips32r1	0
 #define cpu_has_mips32r2	0
 #define cpu_has_mips64r1	0
@@ -73,13 +78,6 @@
 #define ARCH_HAS_USABLE_BUILTIN_POPCOUNT 1
 #endif
 
-static inline int octeon_has_saa(void)
-{
-	int id;
-	asm volatile ("mfc0 %0, $15,0" : "=r" (id));
-	return id >= 0x000d0300;
-}
-
 /*
  * The last 256MB are reserved for device to device mappings and the
  * BAR1 hole.
diff --git a/arch/mips/kernel/unaligned.c b/arch/mips/kernel/unaligned.c
index 3abf05c..9c64b90 100644
--- a/arch/mips/kernel/unaligned.c
+++ b/arch/mips/kernel/unaligned.c
@@ -1668,11 +1668,6 @@ asmlinkage void do_ade(struct pt_regs *regs)
 			memcpy((void *)(CVMSEG_BASE + 256), current->thread.cvmseg.cvmseg[2],
 				cvmseg_size - 256);
 
-#if defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
-		struct task_struct *group_leader = current->group_leader;
-		if (!test_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN))
-			goto sigbus;
-#endif
 		preempt_enable();
 		return;
 	}
-- 
1.8.2.1

