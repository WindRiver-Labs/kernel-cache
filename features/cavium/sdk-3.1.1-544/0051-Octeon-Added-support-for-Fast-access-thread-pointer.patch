From e4b107bac6cbcd1c4abbb2296bf9747253fe0814 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Fri, 13 Feb 2015 13:59:38 +0530
Subject: [PATCH 051/148] Octeon: Added support for Fast access thread pointer

Commit 24fc95ff39b6dbecd2fbac0654faf200342c59cc from
git://git.yoctoproject.org/linux-yocto-3.14

Added support for Fast access thread pointer on stackframe TLB support,
syscall hook support,Kconfig for FAST_ACCESS_TO_THREAD_POINTER,
Fast TLS support in octeon_switch.S, genex.S

Signed-off-by: David Daney <david.daney@cavium.com>
Signed-off-by: Abhishek Paliwal <abhishek.paliwal@aricent.com>
---
 arch/mips/cavium-octeon/Kconfig    | 14 ++++++++++++++
 arch/mips/include/asm/mipsregs.h   | 15 +++++++++++++++
 arch/mips/include/asm/stackframe.h |  3 +++
 arch/mips/kernel/genex.S           |  7 +++++++
 arch/mips/kernel/octeon_switch.S   |  8 +++++++-
 arch/mips/kernel/syscall.c         |  4 +++-
 arch/mips/mm/tlbex.c               | 12 ++++++++++++
 7 files changed, 61 insertions(+), 2 deletions(-)

diff --git a/arch/mips/cavium-octeon/Kconfig b/arch/mips/cavium-octeon/Kconfig
index 606cc8e..4c4359b 100644
--- a/arch/mips/cavium-octeon/Kconfig
+++ b/arch/mips/cavium-octeon/Kconfig
@@ -50,6 +50,20 @@ config CAVIUM_OCTEON_CVMSEG_SIZE
 	  legally range is from zero to 54 cache blocks (i.e. CVMSEG LM is
 	  between zero and 6192 bytes).
 
+config FAST_ACCESS_TO_THREAD_POINTER
+	bool "Enable fast access to the thread pointer"
+	default "y"
+	help
+	  For Mips, normally the TLS thread pointer is accessed by the
+	  userspace program executing a "rdhwr" from register $29. This
+	  register does not exist, so the kernel emulates the instruction
+	  assigning the thread pointer to the value register. This option
+	  supplies an alternate, faster access to the thread pointer. A
+	  side effect of this option is that the highest 8 bytes of CVMSEG
+	  is used by the kernel to save and restore the thread pointer during
+	  the TLB fault handlers. This CVMSEG address is not available to user
+	  applications.
+
 config CAVIUM_OCTEON_LOCK_L2
 	bool "Lock often used kernel code in the L2"
 	default "y"
diff --git a/arch/mips/include/asm/mipsregs.h b/arch/mips/include/asm/mipsregs.h
index b7feb87..9605d5e 100644
--- a/arch/mips/include/asm/mipsregs.h
+++ b/arch/mips/include/asm/mipsregs.h
@@ -669,6 +669,21 @@
 #define MIPS_FPIR_F64		(_ULCAST_(1) << 22)
 
 /*
+ * These defines are used on Octeon to implement fast access to the
+ * thread pointer from userspace. Octeon uses a 64bit location in
+ * CVMSEG to store the thread pointer for quick access.
+ *
+ * We use the second CVMSEG line.  TLB refill uses location -16 (and
+ * below), fast access is -8 (both from the top of the area).
+ */
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+#define FAST_ACCESS_THREAD_OFFSET (2 * 128 - 8 - 32768)
+#define FAST_ACCESS_THREAD_REGISTER                     \
+	(*(unsigned long *)(FAST_ACCESS_THREAD_OFFSET))
+#endif
+#define CAVIUM_OCTEON_SCRATCH_OFFSET (2 * 128 - 16 - 32768)
+
+/*
  * Bits in the MIPS32 Memory Segmentation registers.
  */
 #define MIPS_SEGCFG_PA_SHIFT	9
diff --git a/arch/mips/include/asm/stackframe.h b/arch/mips/include/asm/stackframe.h
index 4857e2c..a0408c2 100644
--- a/arch/mips/include/asm/stackframe.h
+++ b/arch/mips/include/asm/stackframe.h
@@ -436,6 +436,9 @@
 		.macro	RESTORE_SP_AND_RET
 		LONG_L	sp, PT_R29(sp)
 		.set	mips3
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		LONG_L  k0, FAST_ACCESS_THREAD_OFFSET($0) /* K0 = thread pointer */
+#endif
 		eret
 		.set	mips0
 		.endm
diff --git a/arch/mips/kernel/genex.S b/arch/mips/kernel/genex.S
index 03a878c..eb59fed 100644
--- a/arch/mips/kernel/genex.S
+++ b/arch/mips/kernel/genex.S
@@ -191,6 +191,9 @@ NESTED(handle_int, PT_SIZE, sp)
 	and	k0, ST0_IE
 	bnez	k0, 1f
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	LONG_L  k0, FAST_ACCESS_THREAD_OFFSET($0)
+#endif
 	eret
 #endif
 1:
@@ -389,6 +392,7 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	jal	nmi_exception_handler
 	/* nmi_exception_handler never returns */
 	.set	pop
+	RESTORE_ALL_AND_RET
 	END(nmi_handler)
 
 	.macro	__build_clear_none
@@ -595,6 +599,9 @@ isrdhwr:
 	ori	k1, _THREAD_MASK
 	xori	k1, _THREAD_MASK
 	LONG_L	v1, TI_TP_VALUE(k1)
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	move    k0, v1
+#endif
 	.set	mips3
 	eret
 	.set	mips0
diff --git a/arch/mips/kernel/octeon_switch.S b/arch/mips/kernel/octeon_switch.S
index f0b8173..db8f9b1 100644
--- a/arch/mips/kernel/octeon_switch.S
+++ b/arch/mips/kernel/octeon_switch.S
@@ -129,7 +129,13 @@
 
 	PTR_ADDU t0, $28, _THREAD_SIZE - 32
 	set_saved_sp	t0, t1, t2
-
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	/* We need to put the thread pointer in CVMMEM immediately. The
+		kernel will use this value during TLB exceptions even
+		though userspace hasn't accessed CVMMEM */
+	LONG_L  t1, TI_TP_VALUE($28)
+	LONG_S  t1, FAST_ACCESS_THREAD_OFFSET($0)
+#endif
 	mfc0	t1, CP0_STATUS		/* Do we really need this? */
 	li	a3, 0xff01
 	and	t1, a3
diff --git a/arch/mips/kernel/syscall.c b/arch/mips/kernel/syscall.c
index b79d13f..42b3e5c 100644
--- a/arch/mips/kernel/syscall.c
+++ b/arch/mips/kernel/syscall.c
@@ -92,7 +92,9 @@ SYSCALL_DEFINE1(set_thread_area, unsigned long, addr)
 	ti->tp_value = addr;
 	if (cpu_has_userlocal)
 		write_c0_userlocal(addr);
-
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	FAST_ACCESS_THREAD_REGISTER = addr;
+#endif
 	return 0;
 }
 
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index 4b14d7c..c918860 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -1215,15 +1215,24 @@ build_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,
 		UASM_i_MFC0(p, scratch, c0_kscratch(), c0_scratch_reg);
 		build_tlb_write_entry(p, l, r, tlb_random);
 		uasm_l_leave(l, *p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		UASM_i_MFC0(p, K0, 4, 2);
+#endif
 		rv.restore_scratch = 1;
 	} else if (PAGE_SHIFT == 14 || PAGE_SHIFT == 13)  {
 		build_tlb_write_entry(p, l, r, tlb_random);
 		uasm_l_leave(l, *p);
 		UASM_i_LW(p, scratch, scratchpad_offset(0), 0);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		UASM_i_LW(p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread pointer */
+#endif
 	} else {
 		UASM_i_LW(p, scratch, scratchpad_offset(0), 0);
 		build_tlb_write_entry(p, l, r, tlb_random);
 		uasm_l_leave(l, *p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		UASM_i_LW(p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread pointer */
+#endif
 		rv.restore_scratch = 1;
 	}
 
@@ -1886,6 +1895,9 @@ build_r4000_tlbchange_handler_tail(u32 **p, struct uasm_label **l,
 	build_tlb_write_entry(p, l, r, tlb_indexed);
 	uasm_l_leave(l, *p);
 	build_restore_work_registers(p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	UASM_i_LW(p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread ptr */
+#endif
 	uasm_i_eret(p); /* return from trap */
 
 #ifdef CONFIG_64BIT
-- 
1.8.2.1

