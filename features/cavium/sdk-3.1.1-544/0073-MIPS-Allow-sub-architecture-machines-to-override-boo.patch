From 6484ceaafd010745cce603798b1ac4d5426a4590 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Fri, 13 Feb 2015 14:24:18 +0530
Subject: [PATCH 073/148] MIPS: Allow sub-architecture 'machines' to override
 bootmem initialization.

Commit 9d6eb4d676da222889a878f09599c3d3600047aa from
git://git.yoctoproject.org/linux-yocto-3.14

This is done be adding a asm/mach_??/mach_bootmem.h file.

MIPS:KDUMP: Fix build issues with previous commit.

Move function call in ifdef

MIPS: Sort and merge /proc/iomem RAM regions.

Sorting makes things easier to understand, and easier to merge.
Merging makes kexec work better.

MIPS: Add the concept of BOOT_MEM_KERNEL to boot_mem_map.

No change to memory initialization, but this gets us ready for the
next patches for OCTEON NUMA support.

Signed-off-by: David Daney <david.daney@cavium.com>
Signed-off-by: Tsvetan Erenditsov <terenditsov@caviumnetworks.com>
Signed-off-by: Chandrakala Chavva <cchavva@caviumnetworks.com>
Signed-off-by: Abhishek Paliwal <abhishek.paliwal@aricent.com>
---
 arch/mips/include/asm/bootinfo.h                  |   1 +
 arch/mips/include/asm/mach-generic/mach_bootmem.h |   1 +
 arch/mips/include/asm/octeon/cvmx-fau.h           | 630 ++++++++++++----------
 arch/mips/kernel/setup.c                          |  68 ++-
 4 files changed, 395 insertions(+), 305 deletions(-)
 create mode 100644 arch/mips/include/asm/mach-generic/mach_bootmem.h

diff --git a/arch/mips/include/asm/bootinfo.h b/arch/mips/include/asm/bootinfo.h
index 4d2cdea..7808a50 100644
--- a/arch/mips/include/asm/bootinfo.h
+++ b/arch/mips/include/asm/bootinfo.h
@@ -87,6 +87,7 @@ extern unsigned long mips_machtype;
 #define BOOT_MEM_ROM_DATA	2
 #define BOOT_MEM_RESERVED	3
 #define BOOT_MEM_INIT_RAM	4
+#define BOOT_MEM_KERNEL		5
 
 /*
  * A memory map that's built upon what was determined
diff --git a/arch/mips/include/asm/mach-generic/mach_bootmem.h b/arch/mips/include/asm/mach-generic/mach_bootmem.h
new file mode 100644
index 0000000..710cecc
--- /dev/null
+++ b/arch/mips/include/asm/mach-generic/mach_bootmem.h
@@ -0,0 +1 @@
+/* Empty */
diff --git a/arch/mips/include/asm/octeon/cvmx-fau.h b/arch/mips/include/asm/octeon/cvmx-fau.h
index ef98f7f..ccaae1d 100644
--- a/arch/mips/include/asm/octeon/cvmx-fau.h
+++ b/arch/mips/include/asm/octeon/cvmx-fau.h
@@ -1,49 +1,79 @@
 /***********************license start***************
- * Author: Cavium Networks
- *
- * Contact: support@caviumnetworks.com
- * This file is part of the OCTEON SDK
- *
- * Copyright (c) 2003-2008 Cavium Networks
- *
- * This file is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License, Version 2, as
- * published by the Free Software Foundation.
- *
- * This file is distributed in the hope that it will be useful, but
- * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
- * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
- * NONINFRINGEMENT.  See the GNU General Public License for more
- * details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this file; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
- * or visit http://www.gnu.org/licenses/.
- *
- * This file may also be available under a different license from Cavium.
- * Contact Cavium Networks for more information
+ * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
  ***********************license end**************************************/
 
-/*
+/**
+ * @file
+ *
  * Interface to the hardware Fetch and Add Unit.
+ *
+ * <hr>$Revision: 78319 $<hr>
  */
 
 #ifndef __CVMX_FAU_H__
 #define __CVMX_FAU_H__
 
+typedef int cvmx_fau_reg64_t;
+typedef int cvmx_fau_reg32_t;
+typedef int cvmx_fau_reg16_t;
+typedef int cvmx_fau_reg8_t;
+
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+extern "C" {
+/* *INDENT-ON* */
+#endif
+
 /*
  * Octeon Fetch and Add Unit (FAU)
  */
 
 #define CVMX_FAU_LOAD_IO_ADDRESS    cvmx_build_io_address(0x1e, 0)
-#define CVMX_FAU_BITS_SCRADDR	    63, 56
-#define CVMX_FAU_BITS_LEN	    55, 48
-#define CVMX_FAU_BITS_INEVAL	    35, 14
-#define CVMX_FAU_BITS_TAGWAIT	    13, 13
-#define CVMX_FAU_BITS_NOADD	    13, 13
-#define CVMX_FAU_BITS_SIZE	    12, 11
-#define CVMX_FAU_BITS_REGISTER	    10, 0
+#define CVMX_FAU_BITS_SCRADDR       63,56
+#define CVMX_FAU_BITS_LEN           55,48
+#define CVMX_FAU_BITS_INEVAL        35,14
+#define CVMX_FAU_BITS_TAGWAIT       13,13
+#define CVMX_FAU_BITS_NOADD         13,13
+#define CVMX_FAU_BITS_SIZE          12,11
+#define CVMX_FAU_BITS_REGISTER      10,0
+
+#define CVMX_FAU_MAX_REGISTERS_8  (2048)
 
 typedef enum {
 	CVMX_FAU_OP_SIZE_8 = 0,
@@ -105,60 +135,65 @@ typedef union {
 	} s;
 } cvmx_fau_async_tagwait_result_t;
 
+#ifdef __LITTLE_ENDIAN_BITFIELD
+#define SWIZZLE_8  0x7
+#define SWIZZLE_16 0x6
+#define SWIZZLE_32 0x4
+#else
+#define SWIZZLE_8  0
+#define SWIZZLE_16 0
+#define SWIZZLE_32 0
+#endif
+
 /**
+ * @INTERNAL
  * Builds a store I/O address for writing to the FAU
  *
- * @noadd:  0 = Store value is atomically added to the current value
- *		 1 = Store value is atomically written over the current value
- * @reg:    FAU atomic register to access. 0 <= reg < 2048.
- *		 - Step by 2 for 16 bit access.
- *		 - Step by 4 for 32 bit access.
- *		 - Step by 8 for 64 bit access.
- * Returns Address to store for atomic update
+ * @param noadd  0 = Store value is atomically added to the current value
+ *               1 = Store value is atomically written over the current value
+ * @param reg    FAU atomic register to access. 0 <= reg < 2048.
+ *               - Step by 2 for 16 bit access.
+ *               - Step by 4 for 32 bit access.
+ *               - Step by 8 for 64 bit access.
+ * @return Address to store for atomic update
  */
 static inline uint64_t __cvmx_fau_store_address(uint64_t noadd, uint64_t reg)
 {
-	return CVMX_ADD_IO_SEG(CVMX_FAU_LOAD_IO_ADDRESS) |
-	       cvmx_build_bits(CVMX_FAU_BITS_NOADD, noadd) |
-	       cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg);
+	return (CVMX_ADD_IO_SEG(CVMX_FAU_LOAD_IO_ADDRESS) | cvmx_build_bits(CVMX_FAU_BITS_NOADD, noadd) | cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
 }
 
 /**
+ * @INTERNAL
  * Builds a I/O address for accessing the FAU
  *
- * @tagwait: Should the atomic add wait for the current tag switch
- *		  operation to complete.
- *		  - 0 = Don't wait
- *		  - 1 = Wait for tag switch to complete
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 2 for 16 bit access.
- *		  - Step by 4 for 32 bit access.
- *		  - Step by 8 for 64 bit access.
- * @value:   Signed value to add.
- *		  Note: When performing 32 and 64 bit access, only the low
- *		  22 bits are available.
- * Returns Address to read from for atomic update
- */
-static inline uint64_t __cvmx_fau_atomic_address(uint64_t tagwait, uint64_t reg,
-						 int64_t value)
+ * @param tagwait Should the atomic add wait for the current tag switch
+ *                operation to complete.
+ *                - 0 = Don't wait
+ *                - 1 = Wait for tag switch to complete
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 2 for 16 bit access.
+ *                - Step by 4 for 32 bit access.
+ *                - Step by 8 for 64 bit access.
+ * @param value   Signed value to add.
+ *                Note: When performing 32 and 64 bit access, only the low
+ *                22 bits are available.
+ * @return Address to read from for atomic update
+ */ static inline uint64_t __cvmx_fau_atomic_address(uint64_t tagwait, uint64_t reg, int64_t value)
 {
-	return CVMX_ADD_IO_SEG(CVMX_FAU_LOAD_IO_ADDRESS) |
-	       cvmx_build_bits(CVMX_FAU_BITS_INEVAL, value) |
-	       cvmx_build_bits(CVMX_FAU_BITS_TAGWAIT, tagwait) |
-	       cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg);
+	return (CVMX_ADD_IO_SEG(CVMX_FAU_LOAD_IO_ADDRESS) |
+		cvmx_build_bits(CVMX_FAU_BITS_INEVAL, value) | cvmx_build_bits(CVMX_FAU_BITS_TAGWAIT, tagwait) | cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
 }
 
 /**
  * Perform an atomic 64 bit add
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 8 for 64 bit access.
- * @value:   Signed value to add.
- *		  Note: Only the low 22 bits are available.
- * Returns Value of the register before the update
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 8 for 64 bit access.
+ * @param value   Signed value to add.
+ *                Note: Only the low 22 bits are available.
+ * @return Value of the register before the update
  */
-static inline int64_t cvmx_fau_fetch_and_add64(cvmx_fau_reg_64_t reg,
-					       int64_t value)
+static inline int64_t cvmx_fau_fetch_and_add64(cvmx_fau_reg64_t reg, int64_t value)
 {
 	return cvmx_read64_int64(__cvmx_fau_atomic_address(0, reg, value));
 }
@@ -166,41 +201,42 @@ static inline int64_t cvmx_fau_fetch_and_add64(cvmx_fau_reg_64_t reg,
 /**
  * Perform an atomic 32 bit add
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 4 for 32 bit access.
- * @value:   Signed value to add.
- *		  Note: Only the low 22 bits are available.
- * Returns Value of the register before the update
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 4 for 32 bit access.
+ * @param value   Signed value to add.
+ *                Note: Only the low 22 bits are available.
+ * @return Value of the register before the update
  */
-static inline int32_t cvmx_fau_fetch_and_add32(cvmx_fau_reg_32_t reg,
-					       int32_t value)
+static inline int32_t cvmx_fau_fetch_and_add32(cvmx_fau_reg32_t reg, int32_t value)
 {
+	reg ^= SWIZZLE_32;
 	return cvmx_read64_int32(__cvmx_fau_atomic_address(0, reg, value));
 }
 
 /**
  * Perform an atomic 16 bit add
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 2 for 16 bit access.
- * @value:   Signed value to add.
- * Returns Value of the register before the update
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 2 for 16 bit access.
+ * @param value   Signed value to add.
+ * @return Value of the register before the update
  */
-static inline int16_t cvmx_fau_fetch_and_add16(cvmx_fau_reg_16_t reg,
-					       int16_t value)
+static inline int16_t cvmx_fau_fetch_and_add16(cvmx_fau_reg16_t reg, int16_t value)
 {
+	reg ^= SWIZZLE_16;
 	return cvmx_read64_int16(__cvmx_fau_atomic_address(0, reg, value));
 }
 
 /**
  * Perform an atomic 8 bit add
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- * @value:   Signed value to add.
- * Returns Value of the register before the update
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ * @param value   Signed value to add.
+ * @return Value of the register before the update
  */
-static inline int8_t cvmx_fau_fetch_and_add8(cvmx_fau_reg_8_t reg, int8_t value)
+static inline int8_t cvmx_fau_fetch_and_add8(cvmx_fau_reg8_t reg, int8_t value)
 {
+	reg ^= SWIZZLE_8;
 	return cvmx_read64_int8(__cvmx_fau_atomic_address(0, reg, value));
 }
 
@@ -208,23 +244,21 @@ static inline int8_t cvmx_fau_fetch_and_add8(cvmx_fau_reg_8_t reg, int8_t value)
  * Perform an atomic 64 bit add after the current tag switch
  * completes
  *
- * @reg:    FAU atomic register to access. 0 <= reg < 2048.
- *		 - Step by 8 for 64 bit access.
- * @value:  Signed value to add.
- *		 Note: Only the low 22 bits are available.
- * Returns If a timeout occurs, the error bit will be set. Otherwise
- *	   the value of the register before the update will be
- *	   returned
+ * @param reg    FAU atomic register to access. 0 <= reg < 2048.
+ *               - Step by 8 for 64 bit access.
+ * @param value  Signed value to add.
+ *               Note: Only the low 22 bits are available.
+ * @return If a timeout occurs, the error bit will be set. Otherwise
+ *         the value of the register before the update will be
+ *         returned
  */
-static inline cvmx_fau_tagwait64_t
-cvmx_fau_tagwait_fetch_and_add64(cvmx_fau_reg_64_t reg, int64_t value)
+static inline cvmx_fau_tagwait64_t cvmx_fau_tagwait_fetch_and_add64(cvmx_fau_reg64_t reg, int64_t value)
 {
 	union {
 		uint64_t i64;
 		cvmx_fau_tagwait64_t t;
 	} result;
-	result.i64 =
-	    cvmx_read64_int64(__cvmx_fau_atomic_address(1, reg, value));
+	result.i64 = cvmx_read64_int64(__cvmx_fau_atomic_address(1, reg, value));
 	return result.t;
 }
 
@@ -232,23 +266,22 @@ cvmx_fau_tagwait_fetch_and_add64(cvmx_fau_reg_64_t reg, int64_t value)
  * Perform an atomic 32 bit add after the current tag switch
  * completes
  *
- * @reg:    FAU atomic register to access. 0 <= reg < 2048.
- *		 - Step by 4 for 32 bit access.
- * @value:  Signed value to add.
- *		 Note: Only the low 22 bits are available.
- * Returns If a timeout occurs, the error bit will be set. Otherwise
- *	   the value of the register before the update will be
- *	   returned
+ * @param reg    FAU atomic register to access. 0 <= reg < 2048.
+ *               - Step by 4 for 32 bit access.
+ * @param value  Signed value to add.
+ *               Note: Only the low 22 bits are available.
+ * @return If a timeout occurs, the error bit will be set. Otherwise
+ *         the value of the register before the update will be
+ *         returned
  */
-static inline cvmx_fau_tagwait32_t
-cvmx_fau_tagwait_fetch_and_add32(cvmx_fau_reg_32_t reg, int32_t value)
+static inline cvmx_fau_tagwait32_t cvmx_fau_tagwait_fetch_and_add32(cvmx_fau_reg32_t reg, int32_t value)
 {
 	union {
 		uint64_t i32;
 		cvmx_fau_tagwait32_t t;
 	} result;
-	result.i32 =
-	    cvmx_read64_int32(__cvmx_fau_atomic_address(1, reg, value));
+	reg ^= SWIZZLE_32;
+	result.i32 = cvmx_read64_int32(__cvmx_fau_atomic_address(1, reg, value));
 	return result.t;
 }
 
@@ -256,22 +289,21 @@ cvmx_fau_tagwait_fetch_and_add32(cvmx_fau_reg_32_t reg, int32_t value)
  * Perform an atomic 16 bit add after the current tag switch
  * completes
  *
- * @reg:    FAU atomic register to access. 0 <= reg < 2048.
- *		 - Step by 2 for 16 bit access.
- * @value:  Signed value to add.
- * Returns If a timeout occurs, the error bit will be set. Otherwise
- *	   the value of the register before the update will be
- *	   returned
+ * @param reg    FAU atomic register to access. 0 <= reg < 2048.
+ *               - Step by 2 for 16 bit access.
+ * @param value  Signed value to add.
+ * @return If a timeout occurs, the error bit will be set. Otherwise
+ *         the value of the register before the update will be
+ *         returned
  */
-static inline cvmx_fau_tagwait16_t
-cvmx_fau_tagwait_fetch_and_add16(cvmx_fau_reg_16_t reg, int16_t value)
+static inline cvmx_fau_tagwait16_t cvmx_fau_tagwait_fetch_and_add16(cvmx_fau_reg16_t reg, int16_t value)
 {
 	union {
 		uint64_t i16;
 		cvmx_fau_tagwait16_t t;
 	} result;
-	result.i16 =
-	    cvmx_read64_int16(__cvmx_fau_atomic_address(1, reg, value));
+	reg ^= SWIZZLE_16;
+	result.i16 = cvmx_read64_int16(__cvmx_fau_atomic_address(1, reg, value));
 	return result.t;
 }
 
@@ -279,235 +311,205 @@ cvmx_fau_tagwait_fetch_and_add16(cvmx_fau_reg_16_t reg, int16_t value)
  * Perform an atomic 8 bit add after the current tag switch
  * completes
  *
- * @reg:    FAU atomic register to access. 0 <= reg < 2048.
- * @value:  Signed value to add.
- * Returns If a timeout occurs, the error bit will be set. Otherwise
- *	   the value of the register before the update will be
- *	   returned
+ * @param reg    FAU atomic register to access. 0 <= reg < 2048.
+ * @param value  Signed value to add.
+ * @return If a timeout occurs, the error bit will be set. Otherwise
+ *         the value of the register before the update will be
+ *         returned
  */
-static inline cvmx_fau_tagwait8_t
-cvmx_fau_tagwait_fetch_and_add8(cvmx_fau_reg_8_t reg, int8_t value)
+static inline cvmx_fau_tagwait8_t cvmx_fau_tagwait_fetch_and_add8(cvmx_fau_reg8_t reg, int8_t value)
 {
 	union {
 		uint64_t i8;
 		cvmx_fau_tagwait8_t t;
 	} result;
+	reg ^= SWIZZLE_8;
 	result.i8 = cvmx_read64_int8(__cvmx_fau_atomic_address(1, reg, value));
 	return result.t;
 }
 
 /**
+ * @INTERNAL
  * Builds I/O data for async operations
  *
- * @scraddr: Scratch pad byte address to write to.  Must be 8 byte aligned
- * @value:   Signed value to add.
- *		  Note: When performing 32 and 64 bit access, only the low
- *		  22 bits are available.
- * @tagwait: Should the atomic add wait for the current tag switch
- *		  operation to complete.
- *		  - 0 = Don't wait
- *		  - 1 = Wait for tag switch to complete
- * @size:    The size of the operation:
- *		  - CVMX_FAU_OP_SIZE_8	(0) = 8 bits
- *		  - CVMX_FAU_OP_SIZE_16 (1) = 16 bits
- *		  - CVMX_FAU_OP_SIZE_32 (2) = 32 bits
- *		  - CVMX_FAU_OP_SIZE_64 (3) = 64 bits
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 2 for 16 bit access.
- *		  - Step by 4 for 32 bit access.
- *		  - Step by 8 for 64 bit access.
- * Returns Data to write using cvmx_send_single
- */
-static inline uint64_t __cvmx_fau_iobdma_data(uint64_t scraddr, int64_t value,
-					      uint64_t tagwait,
-					      cvmx_fau_op_size_t size,
-					      uint64_t reg)
+ * @param scraddr Scratch pad byte addres to write to.  Must be 8 byte aligned
+ * @param value   Signed value to add.
+ *                Note: When performing 32 and 64 bit access, only the low
+ *                22 bits are available.
+ * @param tagwait Should the atomic add wait for the current tag switch
+ *                operation to complete.
+ *                - 0 = Don't wait
+ *                - 1 = Wait for tag switch to complete
+ * @param size    The size of the operation:
+ *                - CVMX_FAU_OP_SIZE_8  (0) = 8 bits
+ *                - CVMX_FAU_OP_SIZE_16 (1) = 16 bits
+ *                - CVMX_FAU_OP_SIZE_32 (2) = 32 bits
+ *                - CVMX_FAU_OP_SIZE_64 (3) = 64 bits
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 2 for 16 bit access.
+ *                - Step by 4 for 32 bit access.
+ *                - Step by 8 for 64 bit access.
+ * @return Data to write using cvmx_send_single
+ */
+static inline uint64_t __cvmx_fau_iobdma_data(uint64_t scraddr, int64_t value, uint64_t tagwait, cvmx_fau_op_size_t size, uint64_t reg)
 {
-	return CVMX_FAU_LOAD_IO_ADDRESS |
-	       cvmx_build_bits(CVMX_FAU_BITS_SCRADDR, scraddr >> 3) |
-	       cvmx_build_bits(CVMX_FAU_BITS_LEN, 1) |
-	       cvmx_build_bits(CVMX_FAU_BITS_INEVAL, value) |
-	       cvmx_build_bits(CVMX_FAU_BITS_TAGWAIT, tagwait) |
-	       cvmx_build_bits(CVMX_FAU_BITS_SIZE, size) |
-	       cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg);
+	return (CVMX_FAU_LOAD_IO_ADDRESS |
+		cvmx_build_bits(CVMX_FAU_BITS_SCRADDR, scraddr >> 3) |
+		cvmx_build_bits(CVMX_FAU_BITS_LEN, 1) |
+		cvmx_build_bits(CVMX_FAU_BITS_INEVAL, value) |
+		cvmx_build_bits(CVMX_FAU_BITS_TAGWAIT, tagwait) | cvmx_build_bits(CVMX_FAU_BITS_SIZE, size) | cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
 }
 
 /**
  * Perform an async atomic 64 bit add. The old value is
  * placed in the scratch memory at byte address scraddr.
  *
- * @scraddr: Scratch memory byte address to put response in.
- *		  Must be 8 byte aligned.
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 8 for 64 bit access.
- * @value:   Signed value to add.
- *		  Note: Only the low 22 bits are available.
- * Returns Placed in the scratch pad register
- */
-static inline void cvmx_fau_async_fetch_and_add64(uint64_t scraddr,
-						  cvmx_fau_reg_64_t reg,
-						  int64_t value)
+ * @param scraddr Scratch memory byte address to put response in.
+ *                Must be 8 byte aligned.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 8 for 64 bit access.
+ * @param value   Signed value to add.
+ *                Note: Only the low 22 bits are available.
+ * @return Placed in the scratch pad register
+ */
+static inline void cvmx_fau_async_fetch_and_add64(uint64_t scraddr, cvmx_fau_reg64_t reg, int64_t value)
 {
-	cvmx_send_single(__cvmx_fau_iobdma_data
-			 (scraddr, value, 0, CVMX_FAU_OP_SIZE_64, reg));
+	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 0, CVMX_FAU_OP_SIZE_64, reg));
 }
 
 /**
  * Perform an async atomic 32 bit add. The old value is
  * placed in the scratch memory at byte address scraddr.
  *
- * @scraddr: Scratch memory byte address to put response in.
- *		  Must be 8 byte aligned.
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 4 for 32 bit access.
- * @value:   Signed value to add.
- *		  Note: Only the low 22 bits are available.
- * Returns Placed in the scratch pad register
- */
-static inline void cvmx_fau_async_fetch_and_add32(uint64_t scraddr,
-						  cvmx_fau_reg_32_t reg,
-						  int32_t value)
+ * @param scraddr Scratch memory byte address to put response in.
+ *                Must be 8 byte aligned.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 4 for 32 bit access.
+ * @param value   Signed value to add.
+ *                Note: Only the low 22 bits are available.
+ * @return Placed in the scratch pad register
+ */
+static inline void cvmx_fau_async_fetch_and_add32(uint64_t scraddr, cvmx_fau_reg32_t reg, int32_t value)
 {
-	cvmx_send_single(__cvmx_fau_iobdma_data
-			 (scraddr, value, 0, CVMX_FAU_OP_SIZE_32, reg));
+	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 0, CVMX_FAU_OP_SIZE_32, reg));
 }
 
 /**
  * Perform an async atomic 16 bit add. The old value is
  * placed in the scratch memory at byte address scraddr.
  *
- * @scraddr: Scratch memory byte address to put response in.
- *		  Must be 8 byte aligned.
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 2 for 16 bit access.
- * @value:   Signed value to add.
- * Returns Placed in the scratch pad register
+ * @param scraddr Scratch memory byte address to put response in.
+ *                Must be 8 byte aligned.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 2 for 16 bit access.
+ * @param value   Signed value to add.
+ * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_fetch_and_add16(uint64_t scraddr,
-						  cvmx_fau_reg_16_t reg,
-						  int16_t value)
+static inline void cvmx_fau_async_fetch_and_add16(uint64_t scraddr, cvmx_fau_reg16_t reg, int16_t value)
 {
-	cvmx_send_single(__cvmx_fau_iobdma_data
-			 (scraddr, value, 0, CVMX_FAU_OP_SIZE_16, reg));
+	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 0, CVMX_FAU_OP_SIZE_16, reg));
 }
 
 /**
  * Perform an async atomic 8 bit add. The old value is
  * placed in the scratch memory at byte address scraddr.
  *
- * @scraddr: Scratch memory byte address to put response in.
- *		  Must be 8 byte aligned.
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- * @value:   Signed value to add.
- * Returns Placed in the scratch pad register
+ * @param scraddr Scratch memory byte address to put response in.
+ *                Must be 8 byte aligned.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ * @param value   Signed value to add.
+ * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_fetch_and_add8(uint64_t scraddr,
-						 cvmx_fau_reg_8_t reg,
-						 int8_t value)
+static inline void cvmx_fau_async_fetch_and_add8(uint64_t scraddr, cvmx_fau_reg8_t reg, int8_t value)
 {
-	cvmx_send_single(__cvmx_fau_iobdma_data
-			 (scraddr, value, 0, CVMX_FAU_OP_SIZE_8, reg));
+	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 0, CVMX_FAU_OP_SIZE_8, reg));
 }
 
 /**
  * Perform an async atomic 64 bit add after the current tag
  * switch completes.
  *
- * @scraddr: Scratch memory byte address to put response in.  Must be
- *	     8 byte aligned.  If a timeout occurs, the error bit (63)
- *	     will be set. Otherwise the value of the register before
- *	     the update will be returned
- *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 8 for 64 bit access.
- * @value:   Signed value to add.
- *		  Note: Only the low 22 bits are available.
- * Returns Placed in the scratch pad register
- */
-static inline void cvmx_fau_async_tagwait_fetch_and_add64(uint64_t scraddr,
-							  cvmx_fau_reg_64_t reg,
-							  int64_t value)
+ * @param scraddr Scratch memory byte address to put response in.
+ *                Must be 8 byte aligned.
+ *                If a timeout occurs, the error bit (63) will be set. Otherwise
+ *                the value of the register before the update will be
+ *                returned
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 8 for 64 bit access.
+ * @param value   Signed value to add.
+ *                Note: Only the low 22 bits are available.
+ * @return Placed in the scratch pad register
+ */
+static inline void cvmx_fau_async_tagwait_fetch_and_add64(uint64_t scraddr, cvmx_fau_reg64_t reg, int64_t value)
 {
-	cvmx_send_single(__cvmx_fau_iobdma_data
-			 (scraddr, value, 1, CVMX_FAU_OP_SIZE_64, reg));
+	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 1, CVMX_FAU_OP_SIZE_64, reg));
 }
 
 /**
  * Perform an async atomic 32 bit add after the current tag
  * switch completes.
  *
- * @scraddr: Scratch memory byte address to put response in.  Must be
- *	     8 byte aligned.  If a timeout occurs, the error bit (63)
- *	     will be set. Otherwise the value of the register before
- *	     the update will be returned
- *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 4 for 32 bit access.
- * @value:   Signed value to add.
- *		  Note: Only the low 22 bits are available.
- * Returns Placed in the scratch pad register
- */
-static inline void cvmx_fau_async_tagwait_fetch_and_add32(uint64_t scraddr,
-							  cvmx_fau_reg_32_t reg,
-							  int32_t value)
+ * @param scraddr Scratch memory byte address to put response in.
+ *                Must be 8 byte aligned.
+ *                If a timeout occurs, the error bit (63) will be set. Otherwise
+ *                the value of the register before the update will be
+ *                returned
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 4 for 32 bit access.
+ * @param value   Signed value to add.
+ *                Note: Only the low 22 bits are available.
+ * @return Placed in the scratch pad register
+ */
+static inline void cvmx_fau_async_tagwait_fetch_and_add32(uint64_t scraddr, cvmx_fau_reg32_t reg, int32_t value)
 {
-	cvmx_send_single(__cvmx_fau_iobdma_data
-			 (scraddr, value, 1, CVMX_FAU_OP_SIZE_32, reg));
+	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 1, CVMX_FAU_OP_SIZE_32, reg));
 }
 
 /**
  * Perform an async atomic 16 bit add after the current tag
  * switch completes.
  *
- * @scraddr: Scratch memory byte address to put response in.  Must be
- *	     8 byte aligned.  If a timeout occurs, the error bit (63)
- *	     will be set. Otherwise the value of the register before
- *	     the update will be returned
- *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 2 for 16 bit access.
- * @value:   Signed value to add.
- *
- * Returns Placed in the scratch pad register
- */
-static inline void cvmx_fau_async_tagwait_fetch_and_add16(uint64_t scraddr,
-							  cvmx_fau_reg_16_t reg,
-							  int16_t value)
+ * @param scraddr Scratch memory byte address to put response in.
+ *                Must be 8 byte aligned.
+ *                If a timeout occurs, the error bit (63) will be set. Otherwise
+ *                the value of the register before the update will be
+ *                returned
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 2 for 16 bit access.
+ * @param value   Signed value to add.
+ * @return Placed in the scratch pad register
+ */
+static inline void cvmx_fau_async_tagwait_fetch_and_add16(uint64_t scraddr, cvmx_fau_reg16_t reg, int16_t value)
 {
-	cvmx_send_single(__cvmx_fau_iobdma_data
-			 (scraddr, value, 1, CVMX_FAU_OP_SIZE_16, reg));
+	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 1, CVMX_FAU_OP_SIZE_16, reg));
 }
 
 /**
  * Perform an async atomic 8 bit add after the current tag
  * switch completes.
  *
- * @scraddr: Scratch memory byte address to put response in.  Must be
- *	     8 byte aligned.  If a timeout occurs, the error bit (63)
- *	     will be set. Otherwise the value of the register before
- *	     the update will be returned
- *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- * @value:   Signed value to add.
- *
- * Returns Placed in the scratch pad register
+ * @param scraddr Scratch memory byte address to put response in.
+ *                Must be 8 byte aligned.
+ *                If a timeout occurs, the error bit (63) will be set. Otherwise
+ *                the value of the register before the update will be
+ *                returned
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ * @param value   Signed value to add.
+ * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_tagwait_fetch_and_add8(uint64_t scraddr,
-							 cvmx_fau_reg_8_t reg,
-							 int8_t value)
+static inline void cvmx_fau_async_tagwait_fetch_and_add8(uint64_t scraddr, cvmx_fau_reg8_t reg, int8_t value)
 {
-	cvmx_send_single(__cvmx_fau_iobdma_data
-			 (scraddr, value, 1, CVMX_FAU_OP_SIZE_8, reg));
+	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 1, CVMX_FAU_OP_SIZE_8, reg));
 }
 
 /**
  * Perform an atomic 64 bit add
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 8 for 64 bit access.
- * @value:   Signed value to add.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 8 for 64 bit access.
+ * @param value   Signed value to add.
  */
-static inline void cvmx_fau_atomic_add64(cvmx_fau_reg_64_t reg, int64_t value)
+static inline void cvmx_fau_atomic_add64(cvmx_fau_reg64_t reg, int64_t value)
 {
 	cvmx_write64_int64(__cvmx_fau_store_address(0, reg), value);
 }
@@ -515,46 +517,49 @@ static inline void cvmx_fau_atomic_add64(cvmx_fau_reg_64_t reg, int64_t value)
 /**
  * Perform an atomic 32 bit add
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 4 for 32 bit access.
- * @value:   Signed value to add.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 4 for 32 bit access.
+ * @param value   Signed value to add.
  */
-static inline void cvmx_fau_atomic_add32(cvmx_fau_reg_32_t reg, int32_t value)
+static inline void cvmx_fau_atomic_add32(cvmx_fau_reg32_t reg, int32_t value)
 {
+	reg ^= SWIZZLE_32;
 	cvmx_write64_int32(__cvmx_fau_store_address(0, reg), value);
 }
 
 /**
  * Perform an atomic 16 bit add
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 2 for 16 bit access.
- * @value:   Signed value to add.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 2 for 16 bit access.
+ * @param value   Signed value to add.
  */
-static inline void cvmx_fau_atomic_add16(cvmx_fau_reg_16_t reg, int16_t value)
+static inline void cvmx_fau_atomic_add16(cvmx_fau_reg16_t reg, int16_t value)
 {
+	reg ^= SWIZZLE_16;
 	cvmx_write64_int16(__cvmx_fau_store_address(0, reg), value);
 }
 
 /**
  * Perform an atomic 8 bit add
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- * @value:   Signed value to add.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ * @param value   Signed value to add.
  */
-static inline void cvmx_fau_atomic_add8(cvmx_fau_reg_8_t reg, int8_t value)
+static inline void cvmx_fau_atomic_add8(cvmx_fau_reg8_t reg, int8_t value)
 {
+	reg ^= SWIZZLE_8;
 	cvmx_write64_int8(__cvmx_fau_store_address(0, reg), value);
 }
 
 /**
  * Perform an atomic 64 bit write
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 8 for 64 bit access.
- * @value:   Signed value to write.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 8 for 64 bit access.
+ * @param value   Signed value to write.
  */
-static inline void cvmx_fau_atomic_write64(cvmx_fau_reg_64_t reg, int64_t value)
+static inline void cvmx_fau_atomic_write64(cvmx_fau_reg64_t reg, int64_t value)
 {
 	cvmx_write64_int64(__cvmx_fau_store_address(1, reg), value);
 }
@@ -562,36 +567,75 @@ static inline void cvmx_fau_atomic_write64(cvmx_fau_reg_64_t reg, int64_t value)
 /**
  * Perform an atomic 32 bit write
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 4 for 32 bit access.
- * @value:   Signed value to write.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 4 for 32 bit access.
+ * @param value   Signed value to write.
  */
-static inline void cvmx_fau_atomic_write32(cvmx_fau_reg_32_t reg, int32_t value)
+static inline void cvmx_fau_atomic_write32(cvmx_fau_reg32_t reg, int32_t value)
 {
+	reg ^= SWIZZLE_32;
 	cvmx_write64_int32(__cvmx_fau_store_address(1, reg), value);
 }
 
 /**
  * Perform an atomic 16 bit write
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- *		  - Step by 2 for 16 bit access.
- * @value:   Signed value to write.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ *                - Step by 2 for 16 bit access.
+ * @param value   Signed value to write.
  */
-static inline void cvmx_fau_atomic_write16(cvmx_fau_reg_16_t reg, int16_t value)
+static inline void cvmx_fau_atomic_write16(cvmx_fau_reg16_t reg, int16_t value)
 {
+	reg ^= SWIZZLE_16;
 	cvmx_write64_int16(__cvmx_fau_store_address(1, reg), value);
 }
 
 /**
  * Perform an atomic 8 bit write
  *
- * @reg:     FAU atomic register to access. 0 <= reg < 2048.
- * @value:   Signed value to write.
+ * @param reg     FAU atomic register to access. 0 <= reg < 2048.
+ * @param value   Signed value to write.
  */
-static inline void cvmx_fau_atomic_write8(cvmx_fau_reg_8_t reg, int8_t value)
+static inline void cvmx_fau_atomic_write8(cvmx_fau_reg8_t reg, int8_t value)
 {
+	reg ^= SWIZZLE_8;
 	cvmx_write64_int8(__cvmx_fau_store_address(1, reg), value);
 }
 
+/** Allocates 64bit FAU register.
+ *  @return value is the base address of allocated FAU register
+ */
+extern int cvmx_fau64_alloc(void);
+
+/** Allocates 32bit FAU register.
+ *  @return value is the base address of allocated FAU register
+ */
+extern int cvmx_fau32_alloc(void);
+
+/** Allocates 16bit FAU register.
+ *  @return value is the base address of allocated FAU register
+ */
+extern int cvmx_fau16_alloc(void);
+
+/** Allocates 8bit FAU register.
+ *  @return value is the base address of allocated FAU register
+ */
+extern int cvmx_fau8_alloc(void);
+
+/** Frees the specified FAU register.
+ *  @param Base address of register to release.
+ *  @return 0 on success; -1 on failure
+ */
+extern int cvmx_fau_free(int address);
+
+/** Display the fau registers array
+ */
+extern void cvmx_fau_show(void);
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
+#endif
+
 #endif /* __CVMX_FAU_H__ */
diff --git a/arch/mips/kernel/setup.c b/arch/mips/kernel/setup.c
index a842154..fee7d88 100644
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@ -24,6 +24,7 @@
 #include <linux/debugfs.h>
 #include <linux/kexec.h>
 #include <linux/sizes.h>
+#include <linux/sort.h>
 
 #include <asm/addrspace.h>
 #include <asm/bootinfo.h>
@@ -35,6 +36,8 @@
 #include <asm/smp-ops.h>
 #include <asm/prom.h>
 
+#include <mach_bootmem.h>
+
 struct cpuinfo_mips cpu_data[NR_CPUS] __read_mostly;
 
 EXPORT_SYMBOL(cpu_data);
@@ -161,6 +164,9 @@ static void __init print_memory_map(void)
 		case BOOT_MEM_INIT_RAM:
 			printk(KERN_CONT "(usable after init)\n");
 			break;
+		case BOOT_MEM_KERNEL:
+			printk(KERN_CONT "(kernel data and code)\n");
+			break;
 		case BOOT_MEM_ROM_DATA:
 			printk(KERN_CONT "(ROM data)\n");
 			break;
@@ -282,11 +288,16 @@ static unsigned long __init init_initrd(void)
  * Initialize the bootmem allocator. It also setup initrd related data
  * if needed.
  */
-#ifdef CONFIG_SGI_IP27
+#if defined(CONFIG_SGI_IP27) || defined(mach_bootmem_init)
+
+#ifndef mach_bootmem_init
+static void mach_bootmem_init(void) {}
+#endif
 
 static void __init bootmem_init(void)
 {
 	init_initrd();
+	mach_bootmem_init();
 	finalize_initrd();
 }
 
@@ -598,18 +609,29 @@ static void __init request_crashkernel(struct resource *res)
 			(unsigned long)(crashk_res.start  >> 20));
 }
 #else /* !defined(CONFIG_KEXEC)		*/
-static void __init mips_parse_crashkernel(void)
-{
-}
 
 static void __init request_crashkernel(struct resource *res)
 {
 }
 #endif /* !defined(CONFIG_KEXEC)  */
 
+static int __init mem_map_entry_cmp(const void *a, const void *b)
+{
+	const struct boot_mem_map_entry *ea = a;
+	const struct boot_mem_map_entry *eb = b;
+
+	if (ea->addr < eb->addr)
+		return -1;
+	else if (ea->addr > eb->addr)
+		return 1;
+	else
+		return 0;
+}
+
 static void __init arch_mem_init(char **cmdline_p)
 {
 	extern void plat_mem_setup(void);
+	phys_t kernel_begin, init_begin, init_end, kernel_end;
 
 	/* call board setup routine */
 	plat_mem_setup();
@@ -620,12 +642,16 @@ static void __init arch_mem_init(char **cmdline_p)
 	 * into another memory section you don't want that to be
 	 * freed when the initdata is freed.
 	 */
-	arch_mem_addpart(PFN_DOWN(__pa_symbol(&_text)) << PAGE_SHIFT,
-			 PFN_UP(__pa_symbol(&_edata)) << PAGE_SHIFT,
-			 BOOT_MEM_RAM);
-	arch_mem_addpart(PFN_UP(__pa_symbol(&__init_begin)) << PAGE_SHIFT,
-			 PFN_DOWN(__pa_symbol(&__init_end)) << PAGE_SHIFT,
-			 BOOT_MEM_INIT_RAM);
+	kernel_begin = PFN_DOWN(__pa_symbol(&_text)) << PAGE_SHIFT;
+	kernel_end = PFN_UP(__pa_symbol(&_end)) << PAGE_SHIFT;
+	init_begin = PFN_UP(__pa_symbol(&__init_begin)) << PAGE_SHIFT;
+	init_end = PFN_DOWN(__pa_symbol(&__init_end)) << PAGE_SHIFT;
+	arch_mem_addpart(kernel_begin, init_begin, BOOT_MEM_KERNEL);
+	arch_mem_addpart(init_end, kernel_end, BOOT_MEM_KERNEL);
+	arch_mem_addpart(init_begin, init_end, BOOT_MEM_INIT_RAM);
+
+	sort(boot_mem_map.map, boot_mem_map.nr_map,
+	     sizeof(struct boot_mem_map_entry), mem_map_entry_cmp, NULL);
 
 	pr_info("Determined physical RAM map:\n");
 	print_memory_map();
@@ -663,9 +689,9 @@ static void __init arch_mem_init(char **cmdline_p)
 				BOOTMEM_DEFAULT);
 	}
 #endif
-
-	mips_parse_crashkernel();
 #ifdef CONFIG_KEXEC
+	mips_parse_crashkernel();
+
 	if (crashk_res.start != crashk_res.end)
 		reserve_bootmem(crashk_res.start,
 				crashk_res.end - crashk_res.start + 1,
@@ -705,6 +731,24 @@ static void __init resource_init(void)
 		case BOOT_MEM_RAM:
 		case BOOT_MEM_INIT_RAM:
 		case BOOT_MEM_ROM_DATA:
+			/* Try to merge on next piece, they are sorted. */
+			while (i + 1 < boot_mem_map.nr_map &&
+			    boot_mem_map.map[i + 1].addr == end + 1) {
+				switch (boot_mem_map.map[i + 1].type) {
+				case BOOT_MEM_RAM:
+				case BOOT_MEM_INIT_RAM:
+				case BOOT_MEM_ROM_DATA:
+				case BOOT_MEM_KERNEL:
+					i++;
+					end = boot_mem_map.map[i].addr + boot_mem_map.map[i].size - 1;
+					if (end >= HIGHMEM_START)
+						end = HIGHMEM_START - 1;
+					break;
+				default:
+					goto no_merge;
+				}
+		}
+no_merge:
 			res->name = "System RAM";
 			break;
 		case BOOT_MEM_RESERVED:
-- 
1.8.2.1

