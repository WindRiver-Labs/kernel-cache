From 1efba3d58021fb6e125de0b07267b55bbd7c8c43 Mon Sep 17 00:00:00 2001
From: Chandrakala Chavva <cchavva@caviumnetworks.com>
Date: Fri, 13 Feb 2015 15:06:28 +0530
Subject: [PATCH 101/148] netdev: octeon-ethernet: Add common module for
 setting mac address

Commit 2a1c7dc32897cd0fbf07f016a0bf26d81e879f93 from
git://git.yoctoproject.org/linux-yocto-3.14

Moved setting of mac address and RX filter to a common place.
Modified mgmt and ethernet driver to use this code.

Redo common code for changing MTU. Moved setting
of MTU to common module.

Signed-off-by: Chandrakala Chavva <cchavva@caviumnetworks.com>
Signed-off-by: Abhishek Paliwal <abhishek.paliwal@aricent.com>
---
 drivers/net/ethernet/octeon/Kconfig         |  60 +++++-
 drivers/net/ethernet/octeon/octeon_common.c | 193 +++++++++++++++++++
 drivers/net/ethernet/octeon/octeon_mgmt.c   | 279 ++++++++++------------------
 3 files changed, 347 insertions(+), 185 deletions(-)
 create mode 100644 drivers/net/ethernet/octeon/octeon_common.c

diff --git a/drivers/net/ethernet/octeon/Kconfig b/drivers/net/ethernet/octeon/Kconfig
index a7aa280..1dd804e 100644
--- a/drivers/net/ethernet/octeon/Kconfig
+++ b/drivers/net/ethernet/octeon/Kconfig
@@ -2,13 +2,71 @@
 # Cavium network device configuration
 #
 
+config OCTEON_BGX_NEXUS
+	tristate
+	depends on CAVIUM_OCTEON_SOC
+
+config OCTEON_BGX_PORT
+	tristate
+	depends on CAVIUM_OCTEON_SOC
+	select OCTEON_BGX_NEXUS
+
+config OCTEON3_ETHERNET
+	tristate "Cavium Inc. OCTEON III PKI/PKO Ethernet support (not cn70xx)"
+	depends on CAVIUM_OCTEON_SOC
+	select OCTEON_BGX_PORT
+	help
+	  Support for 'BGX' Ethernet via PKI/PKO units.  No support
+	  for cn70xx chips (use OCTEON_ETHERNET for cn70xx)
+
+config OCTEON_ETHERNET
+	tristate "Cavium Inc. OCTEON Ethernet support"
+	depends on CPU_CAVIUM_OCTEON
+	select PHYLIB
+	select MDIO_OCTEON
+	select NET_VENDOR_OCTEON
+	select OCTEON_ETHERNET_MEM
+	select OCTEON_ETHERNET_COMMON
+	help
+	  This driver supports the builtin ethernet ports on Cavium
+	  Inc.' products in the Octeon family. This driver supports the
+	  CN3XXX, CN5XXX, CN6XXX and CNF7XXX OCTEON processors.
+
+	  To compile this driver as a module, choose M here.  The module
+	  will be called octeon-ethernet.
+
+config OCTEON_ETHERNET_MEM
+	tristate
+	depends on CPU_CAVIUM_OCTEON
+
+config OCTEON_POW_ONLY_ETHERNET
+	tristate "POW based internal only ethernet driver"
+	depends on  CPU_CAVIUM_OCTEON
+	depends on  OCTEON_ETHERNET
+	help
+	  This option enables a very simple ethernet driver for internal core
+	  to core traffic. It relies on another driver, octeon-ethernet,
+	  to perform all hardware setup. This driver's purpose is to supply
+	  basic networking between different Linux images running on the same
+	  chip. A single core loads the octeon-ethernet module, all other cores
+	  load this driver. On load, the driver waits for some other core to
+	  perform hardware setup.
+
 config OCTEON_MGMT_ETHERNET
 	tristate "Octeon Management port ethernet driver (CN5XXX, CN6XXX)"
-	depends on CAVIUM_OCTEON_SOC
+	depends on  CAVIUM_OCTEON_SOC
 	select PHYLIB
 	select MDIO_OCTEON
+	select NET_VENDOR_OCTEON
+	select OCTEON_ETHERNET_COMMON
 	default y
 	---help---
 	  This option enables the ethernet driver for the management
 	  port on Cavium Networks' Octeon CN57XX, CN56XX, CN55XX,
 	  CN54XX, CN52XX, and CN6XXX chips.
+
+config NET_VENDOR_OCTEON
+	bool
+
+config OCTEON_ETHERNET_COMMON
+	tristate
diff --git a/drivers/net/ethernet/octeon/octeon_common.c b/drivers/net/ethernet/octeon/octeon_common.c
new file mode 100644
index 0000000..5344a06
--- /dev/null
+++ b/drivers/net/ethernet/octeon/octeon_common.c
@@ -0,0 +1,193 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2013 Cavium, Inc.
+ */
+
+#include <linux/module.h>
+
+#include <asm/octeon/octeon.h>
+#include "octeon_common.h"
+
+#include <asm/octeon/cvmx-gmxx-defs.h>
+#include <asm/octeon/cvmx-agl-defs.h>
+#include <asm/octeon/cvmx-pip-defs.h>
+
+struct cvm_oct_cam_state {
+	u64 cam[6];
+	u64 cam_mask;
+	int cam_index;
+};
+
+static void cvm_oct_cam_state_add(struct cvm_oct_cam_state *cs, unsigned char *addr)
+{
+	int i;
+
+	for (i = 0; i < 6; i++)
+		cs->cam[i] |= (u64)addr[i] << (8 * (cs->cam_index));
+	cs->cam_mask |= (1ULL << cs->cam_index);
+	cs->cam_index++;
+}
+
+/**
+ * Set the multicast list
+ * @dev      : Device to work on
+ * @base_reg : Base address of register bank
+ * @rx_lock  : For locking
+ *
+ */
+void cvm_oct_common_set_rx_filtering(struct net_device *dev, u64 base_reg, spinlock_t *lock)
+{
+	u64 reg, saved_reg;
+	unsigned long flags;
+	unsigned int cam_mode = 1; /* 1 - Accept on CAM match */
+	unsigned int multicast_mode = 1; /* 1 - Reject all multicast.  */
+	struct cvm_oct_cam_state cam_state;
+	struct netdev_hw_addr *ha;
+	int available_cam_entries;
+
+	if (base_reg == 0)
+		return;
+
+	memset(&cam_state, 0, sizeof(cam_state));
+
+	if ((dev->flags & IFF_PROMISC) || dev->uc.count > 7) {
+		cam_mode = 0;
+		available_cam_entries = 8;
+	} else {
+		/* One CAM entry for the primary address, leaves seven
+		 * for the secondary addresses.
+		 */
+		available_cam_entries = 7 - dev->uc.count;
+	}
+
+	if (dev->flags & IFF_MULTICAST) {
+		if (cam_mode == 0 || (dev->flags & IFF_ALLMULTI) ||
+		    netdev_mc_count(dev) > available_cam_entries)
+			multicast_mode = 2; /* 2 - Accept all multicast.  */
+		else
+			multicast_mode = 0; /* 0 - Use CAM.  */
+	}
+
+	if (cam_mode == 1) {
+		/* Add primary address. */
+		cvm_oct_cam_state_add(&cam_state, dev->dev_addr);
+		netdev_for_each_uc_addr(ha, dev)
+			cvm_oct_cam_state_add(&cam_state, ha->addr);
+	}
+	if (multicast_mode == 0) {
+		netdev_for_each_mc_addr(ha, dev)
+			cvm_oct_cam_state_add(&cam_state, ha->addr);
+	}
+
+	/* Disable packet I/O. */
+	spin_lock_irqsave(lock, flags);
+
+	reg = cvmx_read_csr(base_reg + GMX_PRT_CFG);
+	saved_reg = reg;
+	cvmx_write_csr(base_reg + GMX_PRT_CFG, reg & ~1ull);
+
+	reg = 0;
+	reg |= (cam_mode << 3) & 0x8;
+	reg |= (multicast_mode << 1) & 0x6;
+	reg |= 1;     /* Allow broadcast */
+
+	cvmx_write_csr(base_reg + GMX_RX_ADR_CTL, reg);
+
+	cvmx_write_csr(base_reg + GMX_RX_ADR_CAM0, cam_state.cam[0]);
+	cvmx_write_csr(base_reg + GMX_RX_ADR_CAM1, cam_state.cam[1]);
+	cvmx_write_csr(base_reg + GMX_RX_ADR_CAM2, cam_state.cam[2]);
+	cvmx_write_csr(base_reg + GMX_RX_ADR_CAM3, cam_state.cam[3]);
+	cvmx_write_csr(base_reg + GMX_RX_ADR_CAM4, cam_state.cam[4]);
+	cvmx_write_csr(base_reg + GMX_RX_ADR_CAM5, cam_state.cam[5]);
+	cvmx_write_csr(base_reg + GMX_RX_ADR_CAM_EN, cam_state.cam_mask);
+
+	/* Restore packet I/O. */
+	cvmx_write_csr(base_reg + GMX_PRT_CFG, saved_reg);
+
+	spin_unlock_irqrestore(lock, flags);
+}
+EXPORT_SYMBOL(cvm_oct_common_set_rx_filtering);
+
+/**
+ * Set the hardware MAC address for a device.
+ * @dev      : Device to work on
+ * @addr     : Address to change it to
+ * @base_reg : Base address of register bank
+ * @rx_lock  : For locking
+ *
+ * Returns zero on success
+ */
+int cvm_oct_common_set_mac_address(struct net_device *dev, void *addr,
+	 u64 base_reg, spinlock_t *lock)
+{
+	int r = eth_mac_addr(dev, addr);
+
+	if (r)
+		return r;
+
+	cvm_oct_common_set_rx_filtering(dev, base_reg, lock);
+
+	return 0;
+}
+EXPORT_SYMBOL(cvm_oct_common_set_mac_address);
+
+/**
+ * cvm_oct_common_change_mtu - change the link MTU
+ * @dev      : Device to change
+ * @mtu      : The new MTU
+ * @base_reg : Base address of register bank
+ * @pip_reg  : Used for frame checking
+ * @mtu_limit: Max allowed MTU size
+ *
+ * Returns Zero on success
+ */
+int cvm_oct_common_change_mtu(struct net_device *dev, int mtu, u64 base_reg,
+		u64 pip_reg, int mtu_limit)
+{
+	int max_packet = mtu + OCTEON_FRAME_HEADER_LEN;
+
+	if (max_packet < 64 || max_packet > mtu_limit) {
+		netdev_err(dev, "MTU must be between %d and %d.\n",
+			64 - OCTEON_FRAME_HEADER_LEN, mtu_limit - OCTEON_FRAME_HEADER_LEN);
+		return -EINVAL;
+	}
+
+	dev->mtu = mtu;
+
+	/* Set the hardware to truncate packets larger than
+	 * the MTU. The jabber register must be set to a
+	 * multiple of 8 bytes, so round up.
+	 */
+	if (base_reg) {
+		if (pip_reg == 0)
+			cvmx_write_csr(base_reg + GMX_RX_FRM_MAX, max_packet);
+		else {
+			union cvmx_pip_prt_cfgx port_cfg;
+
+			port_cfg.u64 = cvmx_read_csr(pip_reg);
+			if (port_cfg.s.maxerr_en) {
+				/* Disable the PIP check as it can
+				 * only be controlled over a group of
+				 * ports, let the check be done in the
+				 * GMX instead.
+				 */
+				port_cfg.s.maxerr_en = 0;
+				cvmx_write_csr(pip_reg, port_cfg.u64);
+			}
+		}
+		/* Set the hardware to truncate packets larger than
+		 * the MTU. The jabber register must be set to a
+		 * multiple of 8 bytes, so round up.
+		 */
+		cvmx_write_csr(base_reg + GMX_RX_JABBER, (max_packet + 7) & ~7u);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(cvm_oct_common_change_mtu);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Cavium, Inc. Common Network Driver");
diff --git a/drivers/net/ethernet/octeon/octeon_mgmt.c b/drivers/net/ethernet/octeon/octeon_mgmt.c
index 3cf913e..db2df10 100644
--- a/drivers/net/ethernet/octeon/octeon_mgmt.c
+++ b/drivers/net/ethernet/octeon/octeon_mgmt.c
@@ -8,13 +8,11 @@
 
 #include <linux/platform_device.h>
 #include <linux/dma-mapping.h>
-#include <linux/etherdevice.h>
 #include <linux/capability.h>
 #include <linux/net_tstamp.h>
 #include <linux/interrupt.h>
 #include <linux/netdevice.h>
 #include <linux/spinlock.h>
-#include <linux/if_vlan.h>
 #include <linux/of_mdio.h>
 #include <linux/module.h>
 #include <linux/of_net.h>
@@ -26,6 +24,7 @@
 #include <asm/octeon/octeon.h>
 #include <asm/octeon/cvmx-mixx-defs.h>
 #include <asm/octeon/cvmx-agl-defs.h>
+#include "octeon_common.h"
 
 #define DRV_NAME "octeon_mgmt"
 #define DRV_VERSION "2.0"
@@ -40,9 +39,6 @@
 #define OCTEON_MGMT_RX_RING_SIZE 512
 #define OCTEON_MGMT_TX_RING_SIZE 128
 
-/* Allow 8 bytes for vlan and FCS. */
-#define OCTEON_MGMT_RX_HEADROOM (ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN)
-
 union mgmt_port_ring_entry {
 	u64 d64;
 	struct {
@@ -84,23 +80,12 @@ union mgmt_port_ring_entry {
 
 #define AGL_GMX_PRT_CFG			0x10
 #define AGL_GMX_RX_FRM_CTL		0x18
-#define AGL_GMX_RX_FRM_MAX		0x30
-#define AGL_GMX_RX_JABBER		0x38
 #define AGL_GMX_RX_STATS_CTL		0x50
 
 #define AGL_GMX_RX_STATS_PKTS_DRP	0xb0
 #define AGL_GMX_RX_STATS_OCTS_DRP	0xb8
 #define AGL_GMX_RX_STATS_PKTS_BAD	0xc0
 
-#define AGL_GMX_RX_ADR_CTL		0x100
-#define AGL_GMX_RX_ADR_CAM_EN		0x108
-#define AGL_GMX_RX_ADR_CAM0		0x180
-#define AGL_GMX_RX_ADR_CAM1		0x188
-#define AGL_GMX_RX_ADR_CAM2		0x190
-#define AGL_GMX_RX_ADR_CAM3		0x198
-#define AGL_GMX_RX_ADR_CAM4		0x1a0
-#define AGL_GMX_RX_ADR_CAM5		0x1a8
-
 #define AGL_GMX_TX_CLK			0x208
 #define AGL_GMX_TX_STATS_CTL		0x268
 #define AGL_GMX_TX_CTL			0x270
@@ -220,7 +205,7 @@ static void octeon_mgmt_rx_fill_ring(struct net_device *netdev)
 		struct sk_buff *skb;
 
 		/* CN56XX pass 1 needs 8 bytes of padding.  */
-		size = netdev->mtu + OCTEON_MGMT_RX_HEADROOM + 8 + NET_IP_ALIGN;
+		size = netdev->mtu + OCTEON_FRAME_HEADER_LEN + 8 + NET_IP_ALIGN;
 
 		skb = netdev_alloc_skb(netdev, size);
 		if (!skb)
@@ -398,7 +383,7 @@ static u64 octeon_mgmt_dequeue_rx_buffer(struct octeon_mgmt *p,
 	*pskb = __skb_dequeue(&p->rx_list);
 
 	dma_unmap_single(p->dev, re.s.addr,
-			 ETH_FRAME_LEN + OCTEON_MGMT_RX_HEADROOM,
+			 ETH_FRAME_LEN + OCTEON_FRAME_HEADER_LEN,
 			 DMA_FROM_DEVICE);
 
 	return re.d64;
@@ -559,105 +544,18 @@ static void octeon_mgmt_reset_hw(struct octeon_mgmt *p)
 			 (unsigned long long)agl_gmx_bist.u64);
 }
 
-struct octeon_mgmt_cam_state {
-	u64 cam[6];
-	u64 cam_mask;
-	int cam_index;
-};
-
-static void octeon_mgmt_cam_state_add(struct octeon_mgmt_cam_state *cs,
-				      unsigned char *addr)
-{
-	int i;
-
-	for (i = 0; i < 6; i++)
-		cs->cam[i] |= (u64)addr[i] << (8 * (cs->cam_index));
-	cs->cam_mask |= (1ULL << cs->cam_index);
-	cs->cam_index++;
-}
-
 static void octeon_mgmt_set_rx_filtering(struct net_device *netdev)
 {
 	struct octeon_mgmt *p = netdev_priv(netdev);
-	union cvmx_agl_gmx_rxx_adr_ctl adr_ctl;
-	union cvmx_agl_gmx_prtx_cfg agl_gmx_prtx;
-	unsigned long flags;
-	unsigned int prev_packet_enable;
-	unsigned int cam_mode = 1; /* 1 - Accept on CAM match */
-	unsigned int multicast_mode = 1; /* 1 - Reject all multicast.  */
-	struct octeon_mgmt_cam_state cam_state;
-	struct netdev_hw_addr *ha;
-	int available_cam_entries;
-
-	memset(&cam_state, 0, sizeof(cam_state));
-
-	if ((netdev->flags & IFF_PROMISC) || netdev->uc.count > 7) {
-		cam_mode = 0;
-		available_cam_entries = 8;
-	} else {
-		/* One CAM entry for the primary address, leaves seven
-		 * for the secondary addresses.
-		 */
-		available_cam_entries = 7 - netdev->uc.count;
-	}
 
-	if (netdev->flags & IFF_MULTICAST) {
-		if (cam_mode == 0 || (netdev->flags & IFF_ALLMULTI) ||
-		    netdev_mc_count(netdev) > available_cam_entries)
-			multicast_mode = 2; /* 2 - Accept all multicast.  */
-		else
-			multicast_mode = 0; /* 0 - Use CAM.  */
-	}
-
-	if (cam_mode == 1) {
-		/* Add primary address. */
-		octeon_mgmt_cam_state_add(&cam_state, netdev->dev_addr);
-		netdev_for_each_uc_addr(ha, netdev)
-			octeon_mgmt_cam_state_add(&cam_state, ha->addr);
-	}
-	if (multicast_mode == 0) {
-		netdev_for_each_mc_addr(ha, netdev)
-			octeon_mgmt_cam_state_add(&cam_state, ha->addr);
-	}
-
-	spin_lock_irqsave(&p->lock, flags);
-
-	/* Disable packet I/O. */
-	agl_gmx_prtx.u64 = cvmx_read_csr(p->agl + AGL_GMX_PRT_CFG);
-	prev_packet_enable = agl_gmx_prtx.s.en;
-	agl_gmx_prtx.s.en = 0;
-	cvmx_write_csr(p->agl + AGL_GMX_PRT_CFG, agl_gmx_prtx.u64);
-
-	adr_ctl.u64 = 0;
-	adr_ctl.s.cam_mode = cam_mode;
-	adr_ctl.s.mcst = multicast_mode;
-	adr_ctl.s.bcst = 1;     /* Allow broadcast */
-
-	cvmx_write_csr(p->agl + AGL_GMX_RX_ADR_CTL, adr_ctl.u64);
-
-	cvmx_write_csr(p->agl + AGL_GMX_RX_ADR_CAM0, cam_state.cam[0]);
-	cvmx_write_csr(p->agl + AGL_GMX_RX_ADR_CAM1, cam_state.cam[1]);
-	cvmx_write_csr(p->agl + AGL_GMX_RX_ADR_CAM2, cam_state.cam[2]);
-	cvmx_write_csr(p->agl + AGL_GMX_RX_ADR_CAM3, cam_state.cam[3]);
-	cvmx_write_csr(p->agl + AGL_GMX_RX_ADR_CAM4, cam_state.cam[4]);
-	cvmx_write_csr(p->agl + AGL_GMX_RX_ADR_CAM5, cam_state.cam[5]);
-	cvmx_write_csr(p->agl + AGL_GMX_RX_ADR_CAM_EN, cam_state.cam_mask);
-
-	/* Restore packet I/O. */
-	agl_gmx_prtx.s.en = prev_packet_enable;
-	cvmx_write_csr(p->agl + AGL_GMX_PRT_CFG, agl_gmx_prtx.u64);
-
-	spin_unlock_irqrestore(&p->lock, flags);
+	cvm_oct_common_set_rx_filtering(netdev, p->agl, &p->lock);
 }
 
 static int octeon_mgmt_set_mac_address(struct net_device *netdev, void *addr)
 {
-	int r = eth_mac_addr(netdev, addr);
-
-	if (r)
-		return r;
+	struct octeon_mgmt *p = netdev_priv(netdev);
 
-	octeon_mgmt_set_rx_filtering(netdev);
+	cvm_oct_common_set_mac_address(netdev, addr, p->agl, &p->lock);
 
 	return 0;
 }
@@ -665,23 +563,14 @@ static int octeon_mgmt_set_mac_address(struct net_device *netdev, void *addr)
 static int octeon_mgmt_change_mtu(struct net_device *netdev, int new_mtu)
 {
 	struct octeon_mgmt *p = netdev_priv(netdev);
-	int size_without_fcs = new_mtu + OCTEON_MGMT_RX_HEADROOM;
 
 	/* Limit the MTU to make sure the ethernet packets are between
 	 * 64 bytes and 16383 bytes.
 	 */
-	if (size_without_fcs < 64 || size_without_fcs > 16383) {
-		dev_warn(p->dev, "MTU must be between %d and %d.\n",
-			 64 - OCTEON_MGMT_RX_HEADROOM,
-			 16383 - OCTEON_MGMT_RX_HEADROOM);
-		return -EINVAL;
-	}
-
-	netdev->mtu = new_mtu;
+	int ret = cvm_oct_common_change_mtu(netdev, new_mtu, p->agl, 0, 16383);
 
-	cvmx_write_csr(p->agl + AGL_GMX_RX_FRM_MAX, size_without_fcs);
-	cvmx_write_csr(p->agl + AGL_GMX_RX_JABBER,
-		       (size_without_fcs + 7) & 0xfff8);
+	if (ret)
+		return ret;
 
 	return 0;
 }
@@ -861,6 +750,9 @@ static void octeon_mgmt_update_link(struct octeon_mgmt *p)
 
 	prtx_cfg.u64 = cvmx_read_csr(p->agl + AGL_GMX_PRT_CFG);
 
+	if (!p->phydev)
+		return;
+
 	if (!p->phydev->link)
 		prtx_cfg.s.duplex = 1;
 	else
@@ -987,6 +879,45 @@ static int octeon_mgmt_init_phy(struct net_device *netdev)
 	return 0;
 }
 
+static int octeon_mgmt_stop(struct net_device *netdev)
+{
+	struct octeon_mgmt *p = netdev_priv(netdev);
+
+	napi_disable(&p->napi);
+	netif_stop_queue(netdev);
+
+	if (p->phydev)
+		phy_disconnect(p->phydev);
+	p->phydev = NULL;
+
+	netif_carrier_off(netdev);
+
+	octeon_mgmt_reset_hw(p);
+
+	if (p->irq)
+		free_irq(p->irq, netdev);
+
+	/* dma_unmap is a nop on Octeon, so just free everything.  */
+	skb_queue_purge(&p->tx_list);
+	skb_queue_purge(&p->rx_list);
+
+	if (p->rx_ring_handle)
+		dma_unmap_single(p->dev, p->rx_ring_handle,
+				 ring_size_to_bytes(OCTEON_MGMT_RX_RING_SIZE),
+				 DMA_BIDIRECTIONAL);
+	if (p->rx_ring)
+		kfree(p->rx_ring);
+
+	if (p->tx_ring_handle)
+		dma_unmap_single(p->dev, p->tx_ring_handle,
+				 ring_size_to_bytes(OCTEON_MGMT_TX_RING_SIZE),
+				 DMA_BIDIRECTIONAL);
+	if (p->tx_ring)
+		kfree(p->tx_ring);
+
+	return 0;
+}
+
 static int octeon_mgmt_open(struct net_device *netdev)
 {
 	struct octeon_mgmt *p = netdev_priv(netdev);
@@ -1244,54 +1175,13 @@ static int octeon_mgmt_open(struct net_device *netdev)
 	napi_enable(&p->napi);
 
 	return 0;
+
 err_noirq:
-	octeon_mgmt_reset_hw(p);
-	dma_unmap_single(p->dev, p->rx_ring_handle,
-			 ring_size_to_bytes(OCTEON_MGMT_RX_RING_SIZE),
-			 DMA_BIDIRECTIONAL);
-	kfree(p->rx_ring);
 err_nomem:
-	dma_unmap_single(p->dev, p->tx_ring_handle,
-			 ring_size_to_bytes(OCTEON_MGMT_TX_RING_SIZE),
-			 DMA_BIDIRECTIONAL);
-	kfree(p->tx_ring);
+	octeon_mgmt_stop(netdev);
 	return -ENOMEM;
 }
 
-static int octeon_mgmt_stop(struct net_device *netdev)
-{
-	struct octeon_mgmt *p = netdev_priv(netdev);
-
-	napi_disable(&p->napi);
-	netif_stop_queue(netdev);
-
-	if (p->phydev)
-		phy_disconnect(p->phydev);
-	p->phydev = NULL;
-
-	netif_carrier_off(netdev);
-
-	octeon_mgmt_reset_hw(p);
-
-	free_irq(p->irq, netdev);
-
-	/* dma_unmap is a nop on Octeon, so just free everything.  */
-	skb_queue_purge(&p->tx_list);
-	skb_queue_purge(&p->rx_list);
-
-	dma_unmap_single(p->dev, p->rx_ring_handle,
-			 ring_size_to_bytes(OCTEON_MGMT_RX_RING_SIZE),
-			 DMA_BIDIRECTIONAL);
-	kfree(p->rx_ring);
-
-	dma_unmap_single(p->dev, p->tx_ring_handle,
-			 ring_size_to_bytes(OCTEON_MGMT_TX_RING_SIZE),
-			 DMA_BIDIRECTIONAL);
-	kfree(p->tx_ring);
-
-	return 0;
-}
-
 static int octeon_mgmt_xmit(struct sk_buff *skb, struct net_device *netdev)
 {
 	struct octeon_mgmt *p = netdev_priv(netdev);
@@ -1430,6 +1320,37 @@ static const struct net_device_ops octeon_mgmt_ops = {
 #endif
 };
 
+static int octeon_mgmt_remove(struct platform_device *pdev)
+{
+	struct net_device *netdev = dev_get_drvdata(&pdev->dev);
+	struct octeon_mgmt *p = netdev_priv(netdev);
+
+	if (p->napi.dev)
+		netif_napi_del(&p->napi);
+	tasklet_kill(&p->tx_clean_tasklet);
+	unregister_netdev(netdev);
+	dev_set_drvdata(&pdev->dev, NULL);
+	free_netdev(netdev);
+
+	if (p->agl_prt_ctl)
+		devm_iounmap(&pdev->dev,
+			(void __iomem *)p->agl_prt_ctl);
+	if (p->agl_prt_ctl_phys)
+		devm_release_region(&pdev->dev,
+			p->agl_prt_ctl_phys, p->agl_prt_ctl_size);
+	if (p->agl)
+		devm_iounmap(&pdev->dev,
+			(void __iomem *)p->agl);
+	if (p->agl_phys)
+		devm_release_region(&pdev->dev, p->agl_phys, p->agl_size);
+	if (p->mix)
+		devm_iounmap(&pdev->dev,
+			(void __iomem *)p->mix);
+	if (p->mix_phys)
+		devm_release_region(&pdev->dev, p->mix_phys, p->mix_size);
+	return 0;
+}
+
 static int octeon_mgmt_probe(struct platform_device *pdev)
 {
 	struct net_device *netdev;
@@ -1473,55 +1394,54 @@ static int octeon_mgmt_probe(struct platform_device *pdev)
 		goto err;
 
 	p->irq = result;
+	result = -ENXIO; /* default err from here down */
 
 	res_mix = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	if (res_mix == NULL) {
 		dev_err(&pdev->dev, "no 'reg' resource\n");
-		result = -ENXIO;
 		goto err;
 	}
 
 	res_agl = platform_get_resource(pdev, IORESOURCE_MEM, 1);
 	if (res_agl == NULL) {
 		dev_err(&pdev->dev, "no 'reg' resource\n");
-		result = -ENXIO;
 		goto err;
 	}
 
 	res_agl_prt_ctl = platform_get_resource(pdev, IORESOURCE_MEM, 3);
 	if (res_agl_prt_ctl == NULL) {
 		dev_err(&pdev->dev, "no 'reg' resource\n");
-		result = -ENXIO;
 		goto err;
 	}
 
 	p->mix_phys = res_mix->start;
 	p->mix_size = resource_size(res_mix);
-	p->agl_phys = res_agl->start;
-	p->agl_size = resource_size(res_agl);
-	p->agl_prt_ctl_phys = res_agl_prt_ctl->start;
-	p->agl_prt_ctl_size = resource_size(res_agl_prt_ctl);
-
 
 	if (!devm_request_mem_region(&pdev->dev, p->mix_phys, p->mix_size,
 				     res_mix->name)) {
+		p->mix_phys = 0;
 		dev_err(&pdev->dev, "request_mem_region (%s) failed\n",
 			res_mix->name);
-		result = -ENXIO;
 		goto err;
 	}
 
+	p->agl_phys = res_agl->start;
+	p->agl_size = resource_size(res_agl);
+
 	if (!devm_request_mem_region(&pdev->dev, p->agl_phys, p->agl_size,
 				     res_agl->name)) {
-		result = -ENXIO;
+		p->agl_phys = 0;
 		dev_err(&pdev->dev, "request_mem_region (%s) failed\n",
 			res_agl->name);
 		goto err;
 	}
 
+	p->agl_prt_ctl_phys = res_agl_prt_ctl->start;
+	p->agl_prt_ctl_size = resource_size(res_agl_prt_ctl);
+
 	if (!devm_request_mem_region(&pdev->dev, p->agl_prt_ctl_phys,
 				     p->agl_prt_ctl_size, res_agl_prt_ctl->name)) {
-		result = -ENXIO;
+		p->agl_prt_ctl_phys = 0;
 		dev_err(&pdev->dev, "request_mem_region (%s) failed\n",
 			res_agl_prt_ctl->name);
 		goto err;
@@ -1565,19 +1485,10 @@ static int octeon_mgmt_probe(struct platform_device *pdev)
 	return 0;
 
 err:
-	free_netdev(netdev);
+	octeon_mgmt_remove(pdev);
 	return result;
 }
 
-static int octeon_mgmt_remove(struct platform_device *pdev)
-{
-	struct net_device *netdev = platform_get_drvdata(pdev);
-
-	unregister_netdev(netdev);
-	free_netdev(netdev);
-	return 0;
-}
-
 static struct of_device_id octeon_mgmt_match[] = {
 	{
 		.compatible = "cavium,octeon-5750-mix",
-- 
1.8.2.1

