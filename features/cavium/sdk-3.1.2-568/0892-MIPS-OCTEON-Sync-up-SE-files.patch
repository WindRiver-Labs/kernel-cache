From 63d228b169ae706bf7768fb653fd452cfc2d4ba0 Mon Sep 17 00:00:00 2001
From: Carlos Munoz <cmunoz@caviumnetworks.com>
Date: Fri, 4 Jul 2014 18:05:50 -0700
Subject: [PATCH 892/974] MIPS: OCTEON: Sync-up SE files.

Signed-off-by: Carlos Munoz <cmunoz@caviumnetworks.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c |  728 ++++++------
 .../cavium-octeon/executive/cvmx-helper-board.c    |   54 +-
 .../mips/cavium-octeon/executive/cvmx-helper-pki.c |   21 +
 .../cavium-octeon/executive/cvmx-helper-pko3.c     |  364 ++++--
 .../cavium-octeon/executive/cvmx-helper-srio.c     |   16 +-
 .../cavium-octeon/executive/cvmx-helper-util.c     |   24 +-
 arch/mips/cavium-octeon/executive/cvmx-helper.c    |   80 +-
 arch/mips/cavium-octeon/executive/cvmx-ilk.c       |   15 +
 arch/mips/cavium-octeon/executive/cvmx-ipd.c       |   10 +-
 arch/mips/cavium-octeon/executive/cvmx-pcie.c      |    4 +-
 arch/mips/cavium-octeon/executive/cvmx-pki.c       |  146 ++-
 .../mips/cavium-octeon/executive/cvmx-pko3-queue.c |    6 +-
 .../cavium-octeon/executive/cvmx-pko3-resources.c  |    8 +-
 arch/mips/cavium-octeon/executive/cvmx-qlm.c       |  507 +++++++--
 arch/mips/cavium-octeon/executive/cvmx-srio.c      |  171 +--
 arch/mips/include/asm/octeon/cvmx-bgxx-defs.h      |   13 +-
 arch/mips/include/asm/octeon/cvmx-ciu-defs.h       |   20 +-
 arch/mips/include/asm/octeon/cvmx-ciu3-defs.h      |    5 +-
 arch/mips/include/asm/octeon/cvmx-dpi-defs.h       |  337 ++++--
 arch/mips/include/asm/octeon/cvmx-dtx-defs.h       |  561 ++++++++-
 arch/mips/include/asm/octeon/cvmx-fpa-defs.h       |    8 +-
 arch/mips/include/asm/octeon/cvmx-gpio-defs.h      |    5 +-
 arch/mips/include/asm/octeon/cvmx-gserx-defs.h     |  489 +++++---
 arch/mips/include/asm/octeon/cvmx-helper-bgx.h     |   11 +
 arch/mips/include/asm/octeon/cvmx-helper-board.h   |    5 +-
 arch/mips/include/asm/octeon/cvmx-helper-pko3.h    |    7 +
 arch/mips/include/asm/octeon/cvmx-helper-srio.h    |   11 +
 arch/mips/include/asm/octeon/cvmx-helper.h         |   10 +-
 arch/mips/include/asm/octeon/cvmx-hna-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-ilk-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-ipd.h            |   78 +-
 arch/mips/include/asm/octeon/cvmx-l2c-defs.h       |   16 +-
 arch/mips/include/asm/octeon/cvmx-lmcx-defs.h      |  158 ++-
 arch/mips/include/asm/octeon/cvmx-mio-defs.h       |   14 +-
 arch/mips/include/asm/octeon/cvmx-mixx-defs.h      |    1 +
 arch/mips/include/asm/octeon/cvmx-mpi-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-oclax-defs.h     |   12 +-
 arch/mips/include/asm/octeon/cvmx-ocx-defs.h       |   65 +-
 arch/mips/include/asm/octeon/cvmx-osm-defs.h       |   74 +-
 arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h |  124 +-
 arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h   |   60 +-
 arch/mips/include/asm/octeon/cvmx-pciercx-defs.h   |  312 ++---
 arch/mips/include/asm/octeon/cvmx-pemx-defs.h      |  335 ++++--
 arch/mips/include/asm/octeon/cvmx-pexp-defs.h      |    6 +-
 arch/mips/include/asm/octeon/cvmx-pki-defs.h       |   43 +-
 arch/mips/include/asm/octeon/cvmx-pko-defs.h       |   75 +-
 arch/mips/include/asm/octeon/cvmx-pko3-queue.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-pko3-resources.h |    2 +
 arch/mips/include/asm/octeon/cvmx-pko3.h           |   25 +-
 arch/mips/include/asm/octeon/cvmx-qlm.h            |   22 +-
 arch/mips/include/asm/octeon/cvmx-rst-defs.h       |    7 +-
 arch/mips/include/asm/octeon/cvmx-sli-defs.h       | 1189 +++++++++++++-------
 arch/mips/include/asm/octeon/cvmx-srio.h           |   23 +
 .../mips/include/asm/octeon/cvmx-sriomaintx-defs.h |   10 +-
 arch/mips/include/asm/octeon/cvmx-sriox-defs.h     |   50 +-
 arch/mips/include/asm/octeon/cvmx-sso-defs.h       |    4 +-
 arch/mips/include/asm/octeon/cvmx-wqe.h            |  107 +-
 arch/mips/include/asm/octeon/cvmx-xcv-defs.h       |    3 +-
 58 files changed, 4424 insertions(+), 2035 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
index 9bf65ae..e8a8910 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -92,6 +92,7 @@ __cvmx_helper_bgx_interface_enable_delay(cvmx_helper_interface_mode_t mode)
 		cvmx_wait_usec(50000);
 		break;
 	default:
+		cvmx_wait_usec(50000);
 		break;
 	}
 }
@@ -110,17 +111,6 @@ int __cvmx_helper_bgx_enumerate(int xiface)
 	int qlm;
 	enum cvmx_qlm_mode mode;
 
-	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
-		/* CNF75XX only supports single-lane modes
-		 * hence each interface, which is half-bgx
-		 * has two ports exactly
-		 */
-		if (xi.interface < 2)
-			return 2;
-
-		return -1;
-	}
-
 	/*
 	 * Check the QLM is configured correctly for SGMII, verify the
 	 * speed as well as the mode.
@@ -138,28 +128,26 @@ int __cvmx_helper_bgx_enumerate(int xiface)
 	case CVMX_QLM_MODE_SGMII:
 	case CVMX_QLM_MODE_10G_KR:
 	case CVMX_QLM_MODE_XFI:
-		if (OCTEON_IS_MODEL(OCTEON_CN73XX)
-		    && (qlm == 5 || qlm == 6))
-			return 2;
+	case CVMX_QLM_MODE_RGMII_SGMII:
+	case CVMX_QLM_MODE_RGMII_10G_KR:
+	case CVMX_QLM_MODE_RGMII_XFI:
+	case CVMX_QLM_MODE_MIXED:
 		return 4;
 	case CVMX_QLM_MODE_XAUI:
 	case CVMX_QLM_MODE_40G_KR4:
 	case CVMX_QLM_MODE_XLAUI:
+	case CVMX_QLM_MODE_RXAUI_1X2:
 		return 1;
 	case CVMX_QLM_MODE_RGMII_XAUI:
 	case CVMX_QLM_MODE_RGMII_40G_KR4:
 	case CVMX_QLM_MODE_RGMII_XLAUI:
-		return 2;
 	case CVMX_QLM_MODE_RXAUI:
 	case CVMX_QLM_MODE_RGMII_RXAUI:
+	case CVMX_QLM_MODE_SGMII_1X2:
+	case CVMX_QLM_MODE_RGMII_SGMII_1X1:
+	case CVMX_QLM_MODE_10G_KR_1X2:
+	case CVMX_QLM_MODE_XFI_1X2:
 		return 2;
-	case CVMX_QLM_MODE_RGMII_SGMII:
-	case CVMX_QLM_MODE_RGMII_10G_KR:
-	case CVMX_QLM_MODE_RGMII_XFI:
-		if (OCTEON_IS_MODEL(OCTEON_CN73XX)
-		    && (qlm == 5 || qlm == 6))
-			return 2;
-		return 4;
 	default:
 		return 0;
 	}
@@ -167,38 +155,6 @@ int __cvmx_helper_bgx_enumerate(int xiface)
 
 /**
  * @INTERNAL
- *
- * Convert global interface and port index into
- * a BGX block number and LMAC within that block.
- * Returns -1 if the interface is not mapped to BGX.
- */
-static int cvmx_helper_bgx_index(int xiface, int index,
-	unsigned *block, unsigned *lmac)
-{
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	int max = __cvmx_helper_bgx_enumerate(xiface);
-
-	if (max < 0 || index >= max)
-		return -1;
-
-	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
-		*lmac = ((xi.interface & 1 ) << 1) + (index & 1);
-		*block = xi.interface >> 1;
-	} else if (OCTEON_IS_MODEL(OCTEON_CN73XX)) {
-		*block = (xi.interface < 2) ? xi.interface : 2;
-		if (xi.interface == 3)
-			*lmac = index+2;
-		else
-			*lmac = index;
-	} else {
-		*block = xi.interface;
-		*lmac = index;
-	}
-	return 0;
-}
-
-/**
- * @INTERNAL
  * Disable the BGX port
  *
  * @param xipd_port IPD port of the BGX interface to disable
@@ -211,17 +167,13 @@ void cvmx_helper_bgx_disable(int xipd_port)
 	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_bgxx_cmrx_config_t cmr_config;
-	unsigned unit, lmac;
-
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return;
 
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
-	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_0) || lmac)
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_0) || index)
 		cmr_config.s.enable = 0;
 	cmr_config.s.data_pkt_tx_en = 0;
 	cmr_config.s.data_pkt_rx_en = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 }
 
 
@@ -242,20 +194,21 @@ static void __cvmx_bgx_common_init(int xiface, int index)
 	int lmac_type = 0;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int node = xi.node;
-	unsigned lane_to_sds = 0;
-	unsigned unit, lmac, num_lmacs;
+	int lane_to_sds = 0;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
 	/* Nothing to do here, already configured by u-boot */
+	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		return;
+	}
+
+	/* Nothing to do here, already configured by u-boot */
 	if (OCTEON_IS_MODEL(OCTEON_CN73XX)) {
 		cvmx_bgxx_cmrx_config_t cmr_config;
-		unit = xi.interface;
-		if (xi.interface == 3)
-			return;
-		cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, unit));
+		cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 		if (cmr_config.s.lmac_type == 5) {
 			cvmx_xcv_reset_t xcv_reset;
 			cvmx_xcv_ctl_t xcv_ctl;
@@ -308,19 +261,9 @@ static void __cvmx_bgx_common_init(int xiface, int index)
 		return;
 	}
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return;
-
 	num_ports = cvmx_helper_ports_on_interface(xiface);
 	mode = cvmx_helper_interface_get_mode(xiface);
 
-	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
-		num_lmacs = 4;	/* Only SGMII/XFI supported on o75 */
-	} else {
-		num_lmacs = num_ports;
-	}
-
-
 	switch (mode) {
 	case CVMX_HELPER_INTERFACE_MODE_SGMII:
 		lmac_type = 0;
@@ -349,39 +292,38 @@ static void __cvmx_bgx_common_init(int xiface, int index)
 
 	/* Set mode and lanes for all interface ports */
 	cmr_config.u64 =
-		cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+		cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 	cmr_config.s.enable = 0;
 	cmr_config.s.data_pkt_tx_en = 0;
 	cmr_config.s.data_pkt_rx_en = 0;
 	cmr_config.s.lmac_type = lmac_type;
-	cmr_config.s.lane_to_sds = ((lane_to_sds == 1) ? lmac
+	cmr_config.s.lane_to_sds = ((lane_to_sds == 1) ? index
 				: ((lane_to_sds == 0)
-				? (lmac ? 0xe : 4) : lane_to_sds));
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+				? (index ? 0xe : 4) : lane_to_sds));
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 
 	if (debug)
 		cvmx_dprintf("%s: lane_to_sds=%#x\n",
 		__func__, cmr_config.s.lane_to_sds);
 
-	if (lmac == 0) {
+	if (index == 0) {
 		bgx_cmr_rx_lmacs.u64 = 0;
-		bgx_cmr_rx_lmacs.s.lmacs = num_lmacs;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_LMACS(unit), bgx_cmr_rx_lmacs.u64);
+		bgx_cmr_rx_lmacs.s.lmacs = num_ports;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_LMACS(xi.interface), bgx_cmr_rx_lmacs.u64);
 
 		bgx_cmr_tx_lmacs.u64 = 0;
-		bgx_cmr_tx_lmacs.s.lmacs = num_lmacs;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMR_TX_LMACS(unit), bgx_cmr_tx_lmacs.u64);
+		bgx_cmr_tx_lmacs.s.lmacs = num_ports;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMR_TX_LMACS(xi.interface), bgx_cmr_tx_lmacs.u64);
 	}
 }
 
 static void __cvmx_bgx_common_init_pknd(int xiface, int index)
 {
 	int num_ports;
-	int num_chl = 16; /* FIXME: modify it to 64 for xlaui and xaui*/
+	int num_chl = 16;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int node = xi.node;
 	int pknd;
-	unsigned lmac, unit;
 	cvmx_bgxx_cmrx_rx_bp_on_t bgx_rx_bp_on;
 	cvmx_bgxx_cmrx_rx_id_map_t cmr_rx_id_map;
 	cvmx_bgxx_cmr_chan_msk_and_t chan_msk_and;
@@ -391,9 +333,6 @@ static void __cvmx_bgx_common_init_pknd(int xiface, int index)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return;
-
 	num_ports = cvmx_helper_ports_on_interface(xiface);
 	/* Modify bp_on mark, depending on number of LMACS on that interface
 	and write it for every port */
@@ -402,19 +341,22 @@ static void __cvmx_bgx_common_init_pknd(int xiface, int index)
 
 	/* Setup pkind */
 	pknd = cvmx_helper_get_pknd(xiface, index);
-	cmr_rx_id_map.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_RX_ID_MAP(lmac, unit));
+	cmr_rx_id_map.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_RX_ID_MAP(index, xi.interface));
 	cmr_rx_id_map.s.pknd = pknd;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ID_MAP(lmac, unit),
+	/* Change the default reassembly id (RID), as max 14 RIDs allowed */
+	if (OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX))
+		cmr_rx_id_map.s.rid = ((4 * xi.interface) + 2 + index);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ID_MAP(index, xi.interface),
 			    cmr_rx_id_map.u64);
 	/* Set backpressure channel mask AND/OR registers */
-	chan_msk_and.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(unit));
-	chan_msk_or.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(unit));
-	chan_msk_and.s.msk_and |= ((1 << num_chl) - 1) << (16 * lmac);
-	chan_msk_or.s.msk_or |= ((1 << num_chl) - 1) << (16 * lmac);
-	cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(unit), chan_msk_and.u64);
-	cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(unit), chan_msk_or.u64);
+	chan_msk_and.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(xi.interface));
+	chan_msk_or.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(xi.interface));
+	chan_msk_and.s.msk_and |= ((1 << num_chl) - 1) << (16 * index);
+	chan_msk_or.s.msk_or |= ((1 << num_chl) - 1) << (16 * index);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(xi.interface), chan_msk_and.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(xi.interface), chan_msk_or.u64);
 	/* set rx back pressure (bp_on) on value */
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_BP_ON(lmac, unit), bgx_rx_bp_on.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_BP_ON(index, xi.interface), bgx_rx_bp_on.u64);
 }
 
 /**
@@ -454,7 +396,6 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int xiface, int index)
 	const uint64_t clock_mhz = cvmx_clock_get_rate_node(node, CVMX_CLOCK_SCLK) / 1000000;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
 	cvmx_bgxx_gmp_pcs_linkx_timer_t gmp_timer;
-	unsigned unit, lmac;
 
 	if (!cvmx_helper_is_port_valid(xi.interface, index))
 		return 0;
@@ -463,23 +404,20 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int xiface, int index)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
 	/*
 	 * Write PCS*_LINK*_TIMER_COUNT_REG[COUNT] with the
 	 * appropriate value. 1000BASE-X specifies a 10ms
 	 * interval. SGMII specifies a 1.6ms interval.
 	 */
-	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
 	/* Adjust the MAC mode if requested by device tree */
 	gmp_misc_ctl.s.mac_phy =
 		cvmx_helper_get_mac_phy_mode(xiface, index);
 	gmp_misc_ctl.s.mode =
 		cvmx_helper_get_1000x_mode(xiface, index);
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit), gmp_misc_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface), gmp_misc_ctl.u64);
 
-	gmp_timer.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_LINKX_TIMER(lmac, unit));
+	gmp_timer.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, xi.interface));
 	if (gmp_misc_ctl.s.mode)
 		/* 1000BASE-X */
 		gmp_timer.s.count = (10000ull * clock_mhz) >> 10;
@@ -487,7 +425,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int xiface, int index)
 		/* SGMII */
 		gmp_timer.s.count = (1600ull * clock_mhz) >> 10;
 
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_LINKX_TIMER(lmac, unit), gmp_timer.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, xi.interface), gmp_timer.u64);
 
 	/*
 	 * Write the advertisement register to be used as the
@@ -501,20 +439,20 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int xiface, int index)
 	if (gmp_misc_ctl.s.mode) {
 		/* 1000BASE-X */
 		cvmx_bgxx_gmp_pcs_anx_adv_t gmp_an_adv;
-		gmp_an_adv.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_ANX_ADV(lmac, unit));
+		gmp_an_adv.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_ANX_ADV(index, xi.interface));
 		gmp_an_adv.s.rem_flt = 0;
 		gmp_an_adv.s.pause = 3;
 		gmp_an_adv.s.hfd = 1;
 		gmp_an_adv.s.fd = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_ANX_ADV(lmac, unit), gmp_an_adv.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_ANX_ADV(index, xi.interface), gmp_an_adv.u64);
 	} else {
 		if (gmp_misc_ctl.s.mac_phy) {
 			/* PHY Mode */
 			cvmx_bgxx_gmp_pcs_sgmx_an_adv_t gmp_sgmx_an_adv;
-			gmp_sgmx_an_adv.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(lmac, unit));
+			gmp_sgmx_an_adv.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(index, xi.interface));
 			gmp_sgmx_an_adv.s.dup = 1;
 			gmp_sgmx_an_adv.s.speed = 2;
-			cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(lmac, unit),
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(index, xi.interface),
 				       gmp_sgmx_an_adv.u64);
 		} else {
 			/* MAC Mode - Nothing to do */
@@ -604,7 +542,6 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
 	int node = xi.node;
-	unsigned lmac, unit;
 
 	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
@@ -613,41 +550,38 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
-	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit));
+	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
 	/* Take PCS through a reset sequence */
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		gmp_control.s.reset = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit),
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface),
 		       					     gmp_control.u64);
 
 		/* Wait until GMP_PCS_MRX_CONTROL[reset] comes out of reset */
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface),
 				cvmx_bgxx_gmp_pcs_mrx_control_t, reset, ==, 0, 10000)) {
-			cvmx_dprintf("SGMII%d: Timeout waiting for port %d to finish reset\n", interface, lmac);
+			cvmx_dprintf("SGMII%d: Timeout waiting for port %d to finish reset\n", interface, index);
 			return -1;
 		}
 	}
 
 	/* Write GMP_PCS_MR*_CONTROL[RST_AN]=1 to ensure a fresh SGMII
 	   negotiation starts. */
-	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit));
+	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
 	gmp_control.s.rst_an = 1;
 	gmp_control.s.an_en = 1;
 	gmp_control.s.pwr_dn = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit),
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface),
 		       gmp_control.u64);
 
 
 	phy_mode = cvmx_helper_get_mac_phy_mode(xiface, index);
 	mode_1000x = cvmx_helper_get_1000x_mode(xiface, index);
 
-	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
 	gmp_misc_ctl.s.mac_phy = phy_mode;
 	gmp_misc_ctl.s.mode = mode_1000x;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit), gmp_misc_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface), gmp_misc_ctl.u64);
 
 	if (phy_mode)
 		/* In PHY mode we can't query the link status so we just
@@ -659,7 +593,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
 	   ethernet link, but a link between OCTEON and PHY. */
 
 	if ((cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) &&
-	     CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_STATUS(lmac, unit),
+	     CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_STATUS(index, xi.interface),
 				   cvmx_bgxx_gmp_pcs_mrx_status_t, an_cpt,
 				   ==, 1, 10000)) {
 		cvmx_dprintf("SGMII%d: Port %d link timeout\n", interface, index);
@@ -690,7 +624,6 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int xiface,
 	cvmx_bgxx_gmp_gmi_prtx_cfg_t gmp_prtx_cfg;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int node = xi.node;
-	unsigned unit, lmac;
 
 	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
@@ -699,36 +632,33 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int xiface,
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
 	/* Errata bgx-22429*/
 	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X) || index) {
 		/* Disable GMX before we make any changes. Remember the enable state */
-		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 		is_enabled = cmr_config.s.enable;
 		cmr_config.s.enable = 0;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 	}
 
 	/* Wait for GMX to be idle */
-	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(lmac, unit),
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface),
 				  cvmx_bgxx_gmp_gmi_prtx_cfg_t, rx_idle, ==, 1, 10000) ||
-	    CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(lmac, unit),
+	    CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface),
 				  cvmx_bgxx_gmp_gmi_prtx_cfg_t, tx_idle, ==, 1, 10000)) {
 		cvmx_dprintf("SGMII%d:%d: Timeout waiting for port %d to be idle\n",
-			     node, unit, lmac);
+			     node, xi.interface, index);
 		return -1;
 	}
 
 	/* Read GMX CFG again to make sure the disable completed */
-	gmp_prtx_cfg.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(lmac, unit));
+	gmp_prtx_cfg.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface));
 
 	/*
 	 * Get the misc control for PCS. We will need to set the
 	 * duplication amount.
 	 */
-	gmp_miscx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit));
+	gmp_miscx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
 
 	/*
 	 * Use GMXENO to force the link down if the status we get says
@@ -748,54 +678,54 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int xiface,
 		gmp_prtx_cfg.s.slottime = 0;
 		/* Setting from GMX-603 */
 		gmp_miscx_ctl.s.samp_pt = 25;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(lmac, unit), 64);
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(lmac, unit), 0);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(index, xi.interface), 64);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(index, xi.interface), 0);
 		break;
 	case 100:
 		gmp_prtx_cfg.s.speed = 0;
 		gmp_prtx_cfg.s.speed_msb = 0;
 		gmp_prtx_cfg.s.slottime = 0;
 		gmp_miscx_ctl.s.samp_pt = 0x5;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(lmac, unit), 64);
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(lmac, unit), 0);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(index, xi.interface), 64);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(index, xi.interface), 0);
 		break;
 	case 1000:
 		gmp_prtx_cfg.s.speed = 1;
 		gmp_prtx_cfg.s.speed_msb = 0;
 		gmp_prtx_cfg.s.slottime = 1;
 		gmp_miscx_ctl.s.samp_pt = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(lmac, unit), 512);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(index, xi.interface), 512);
 		if (gmp_prtx_cfg.s.duplex)
 			/* full duplex */
-			cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(lmac, unit), 0);
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(index, xi.interface), 0);
 		else
 			/* half duplex */
-			cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(lmac, unit), 8192);
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(index, xi.interface), 8192);
 		break;
 	default:
 		break;
 	}
 
 	/* Write the new misc control for PCS */
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit),
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface),
 		       gmp_miscx_ctl.u64);
 
 	/* Write the new GMX settings with the port still disabled */
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(lmac, unit), gmp_prtx_cfg.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface), gmp_prtx_cfg.u64);
 
 	/* Read GMX CFG again to make sure the config completed */
-	cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(lmac, unit));
+	cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface));
 
 	/* Restore the enabled/disabled state */
 	/* bgx-22429 */
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
-	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X) || lmac)
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X) || index)
 		cmr_config.s.enable = is_enabled;
 #ifndef CVMX_BUILD_FOR_UBOOT
 	cmr_config.s.data_pkt_tx_en = 1;
 	cmr_config.s.data_pkt_rx_en = 1;
 #endif
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 
 	return 0;
 }
@@ -823,7 +753,6 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
 	int speed = 1000;
-	unsigned unit, lmac;
 
 	result.u64 = 0;
 
@@ -834,9 +763,6 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return result;
-
 	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM) {
 		/* The simulator gives you a simulated 1Gbps full duplex link */
 		result.s.link_up = 1;
@@ -847,7 +773,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 
 	speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
 
-	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit));
+	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
 	if (gmp_control.s.loopbck1) {
 		/* Force 1Gbps full duplex link for internal loopback */
 		result.s.link_up = 1;
@@ -856,7 +782,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 		return result;
 	}
 
-	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
 	if (gmp_misc_ctl.s.mac_phy) {
 		/* PHY Mode */
 		/* Note that this also works for 1000base-X mode */
@@ -931,7 +857,6 @@ int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
 	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
-	unsigned unit, lmac;
 
 	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
@@ -940,42 +865,39 @@ int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
 		cvmx_helper_bgx_errata_22429(xipd_port, link_info.s.link_up);
 	}
 
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 	if (link_info.s.link_up) {
 		cmr_config.s.enable = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 		__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
 	} else {
 		cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
 		cmr_config.s.data_pkt_tx_en = 0;
 		cmr_config.s.data_pkt_rx_en = 0;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
-		gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit));
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
+		gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
 
 		/* Disable autonegotiation only when MAC mode. */
 		if (gmp_misc_ctl.s.mac_phy == 0) {
 			cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
 
-			gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit));
+			gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
 			gmp_control.s.an_en = 0;
-			cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit), gmp_control.u64);
-			cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit));
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface), gmp_control.u64);
+			cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
 		}
 		/*
 		 * Use GMXENO to force the link down it will get
 		 * reenabled later...
 		 */
 		gmp_misc_ctl.s.gmxeno = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit),
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface),
 			       gmp_misc_ctl.u64);
-		cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit));
+		cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
 		return 0;
 	}
 	return __cvmx_helper_bgx_sgmii_hardware_init_link_speed(xiface, index, link_info);
@@ -1009,15 +931,11 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	int node = xi.node;
 	int use_auto_neg = 0;
 	int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
-	unsigned unit, lmac;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
 	mode = cvmx_helper_interface_get_mode(xiface);
 
 	if (mode == CVMX_HELPER_INTERFACE_MODE_10G_KR
@@ -1034,12 +952,12 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	   BGX(0..5)_SPU(0..3)_MISC_CONTROL[RX_PACKET_DIS] = 1 to disable
 	   reception. */
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
-		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit));
+		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface));
 		spu_control1.s.reset = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit), spu_control1.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface), spu_control1.u64);
 
 		/* 1. Wait for PCS to come out of reset */
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface),
 				cvmx_bgxx_spux_control1_t, reset, ==, 0, 10000)) {
 			cvmx_dprintf("BGX%d:%d: SPU stuck in reset\n", node, interface);
 			return -1;
@@ -1049,29 +967,29 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		      BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 1 and
 		      BGX(0..5)_SPU(0..3)_MISC_CONTROL[RX_PACKET_DIS] = 1. */
 		if (!cvmx_helper_bgx_errata_22429(xipd_port, 0)) {
-			cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+			cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 			cmr_config.s.enable = 0;
-			cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+			cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 		}
-		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit));
+		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface));
 		spu_control1.s.lo_pwr = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit), spu_control1.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface), spu_control1.u64);
 
-		spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit));
+		spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface));
 		spu_misc_control.s.rx_packet_dis = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit), spu_misc_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface), spu_misc_control.u64);
 
 		/* 3. At this point, it may be appropriate to disable all BGX and SMU/SPU
 		    interrupts, as a number of them will occur during bring-up of the Link.
 		    - zero BGX(0..5)_SMU(0..3)_RX_INT
 		    - zero BGX(0..5)_SMU(0..3)_TX_INT
 		    - zero BGX(0..5)_SPU(0..3)_INT */
-		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_INT(lmac, unit),
-			cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_INT(lmac, unit)));
-		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_INT(lmac, unit),
-			cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_INT(lmac, unit)));
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(lmac, unit),
-			cvmx_read_csr_node(node, CVMX_BGXX_SPUX_INT(lmac, unit)));
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_INT(index, xi.interface),
+			cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_INT(index, xi.interface)));
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_INT(index, xi.interface),
+			cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_INT(index, xi.interface)));
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, xi.interface),
+			cvmx_read_csr_node(node, CVMX_BGXX_SPUX_INT(index, xi.interface)));
 
 		/* 4. Configure the BGX LMAC. */
 		/* 4a. Configure the LMAC type (40GBASE-R/10GBASE-R/RXAUI/XAUI) and
@@ -1081,13 +999,13 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 
 		/* 4b. Write BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 1 and
 		     BGX(0..5)_SPU(0..3)_MISC_CONTROL[RX_PACKET_DIS] = 1. */
-		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit));
+		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface));
 		spu_control1.s.lo_pwr = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit), spu_control1.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface), spu_control1.u64);
 
-		spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit));
+		spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface));
 		spu_misc_control.s.rx_packet_dis = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit), spu_misc_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface), spu_misc_control.u64);
 
 		/* 4b. Initialize the selected SerDes lane(s) in the QLM. See Section
 		      28.1.2.2 in the GSER chapter. */
@@ -1097,36 +1015,36 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		     BGX(0..5)_SPU(0..3)_BR_PMD_CONTROL[TRAIN_EN] = 1. */
 		/* Moved to xaui_link */
 	} else { /* enable for simulator */
-		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 		cmr_config.s.enable = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 	}
 
 	/* 4d. Program all other relevant BGX configuration while
 	       BGX(0..5)_CMR(0..3)_CONFIG[ENABLE] = 0. This includes all things
 	       described in this chapter. */
 	/* Always add FCS to PAUSE frames */
-	smu_tx_append.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_APPEND(lmac, unit));
+	smu_tx_append.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_APPEND(index, xi.interface));
 	smu_tx_append.s.fcs_d = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_APPEND(lmac, unit), smu_tx_append.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_APPEND(index, xi.interface), smu_tx_append.u64);
 
 	/* 4e. If Forward Error Correction is desired for 10GBASE-R or 40GBASE-R,
 	       enable it by writing BGX(0..5)_SPU(0..3)_FEC_CONTROL[FEC_EN] = 1. */
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		/* FEC is optional for 10GBASE-KR, 40GBASE-KR4, and XLAUI. We're going
 		to disable it by default */
-		spu_fec_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(lmac, unit));
+		spu_fec_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, xi.interface));
 		spu_fec_control.s.fec_en = 0;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(lmac, unit), spu_fec_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, xi.interface), spu_fec_control.u64);
 
 		/* 4f. If Auto-Negotiation is desired, configure and enable
 		      Auto-Negotiation as described in Section 33.6.2. */
-		spu_an_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(lmac, unit));
+		spu_an_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, xi.interface));
 		spu_an_control.s.an_en = use_auto_neg;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(lmac, unit), spu_an_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, xi.interface), spu_an_control.u64);
 
-		spu_fec_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_FEC_CONTROL(lmac, unit));
-		spu_an_adv.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_ADV(lmac, unit));
+		spu_fec_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_FEC_CONTROL(index, xi.interface));
+		spu_an_adv.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_ADV(index, xi.interface));
 		spu_an_adv.s.fec_req = spu_fec_control.s.fec_en;
 		spu_an_adv.s.fec_able = 1;
 		spu_an_adv.s.a100g_cr10 = 0;
@@ -1136,12 +1054,12 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		spu_an_adv.s.a10g_kx4 = 0;
 		spu_an_adv.s.a1g_kx = 0;
 		spu_an_adv.s.rf = 0;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_ADV(lmac, unit), spu_an_adv.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_ADV(index, xi.interface), spu_an_adv.u64);
 
 		/* 3. Set BGX(0..5)_SPU_DBG_CONTROL[AN_ARB_LINK_CHK_EN] = 1. */
-		spu_dbg_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPU_DBG_CONTROL(unit));
+		spu_dbg_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPU_DBG_CONTROL(xi.interface));
 		spu_dbg_control.s.an_arb_link_chk_en = use_auto_neg;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPU_DBG_CONTROL(unit), spu_dbg_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPU_DBG_CONTROL(xi.interface), spu_dbg_control.u64);
 
 		/* 4. Execute the link bring-up sequence in Section 33.6.3. */
 
@@ -1152,13 +1070,13 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		/* 3h. Set BGX(0..5)_CMR(0..3)_CONFIG[ENABLE] = 1 and
 		    BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 0 to enable the LMAC. */
 		cvmx_helper_bgx_errata_22429(xipd_port, 1);
-		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 		cmr_config.s.enable = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 
-		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit));
+		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface));
 		spu_control1.s.lo_pwr = 0;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit), spu_control1.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface), spu_control1.u64);
 	}
 
 	/* 4g. Set the polarity and lane swapping of the QLM SerDes. Refer to
@@ -1166,31 +1084,31 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	   and BGX(0..5)_SPU(0..3)_MISC_CONTROL[TXPLRT,RXPLRT]. */
 
 	/* 4c. Write BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 0. */
-	spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit));
+	spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface));
 	spu_control1.s.lo_pwr = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit), spu_control1.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface), spu_control1.u64);
 
 	/* 4d. Select Deficit Idle Count mode and unidirectional enable/disable
 	   via BGX(0..5)_SMU(0..3)_TX_CTL[DIC_EN,UNI_EN]. */
-	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(lmac, unit));
+	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, xi.interface));
 	smu_tx_ctl.s.dic_en = 1;
 	smu_tx_ctl.s.uni_en = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(lmac, unit), smu_tx_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, xi.interface), smu_tx_ctl.u64);
 
 	{
 		/* Calculate the number of s-clk cycles per usec. */
 		const uint64_t clock_mhz = cvmx_clock_get_rate_node(node, CVMX_CLOCK_SCLK) / 1000000;
 		cvmx_bgxx_spu_dbg_control_t dbg_control;
-		dbg_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPU_DBG_CONTROL(unit));
+		dbg_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPU_DBG_CONTROL(xi.interface));
 		dbg_control.s.us_clk_period = clock_mhz - 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPU_DBG_CONTROL(unit), dbg_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPU_DBG_CONTROL(xi.interface), dbg_control.u64);
 	}
 	/* The PHY often takes at least 100ms to stabilize */
 	__cvmx_helper_bgx_interface_enable_delay(mode);
 	return 0;
 }
 
-static void __cvmx_bgx_start_training(int node, int unit, int lmac)
+static void __cvmx_bgx_start_training(int node, int unit, int index)
 {
 	cvmx_bgxx_spux_int_t spu_int;
 	cvmx_bgxx_spux_br_pmd_control_t pmd_control;
@@ -1200,32 +1118,32 @@ static void __cvmx_bgx_start_training(int node, int unit, int lmac)
 	spu_int.u64 = 0;
 	spu_int.s.training_failure = 1;
 	spu_int.s.training_done = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(lmac, unit), spu_int.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, unit), spu_int.u64);
 
 	/* These registers aren't cleared when training is restarted. Manually
 	   clear them as per Errata BGX-20968. */
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LP_CUP(lmac, unit), 0);
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_CUP(lmac, unit), 0);
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_REP(lmac, unit), 0);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LP_CUP(index, unit), 0);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_CUP(index, unit), 0);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_REP(index, unit), 0);
 
 	/* Disable autonegotiation */
-	an_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(lmac, unit));
+	an_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, unit));
 	an_control.s.an_en = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(lmac, unit), an_control.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, unit), an_control.u64);
 	cvmx_wait_usec(1);
 
 	/* Restart training */
-	pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(lmac, unit));
+	pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, unit));
 	pmd_control.s.train_en = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(lmac, unit), pmd_control.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, unit), pmd_control.u64);
 
 	cvmx_wait_usec(1);
-	pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(lmac, unit));
+	pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, unit));
 	pmd_control.s.train_restart = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(lmac, unit), pmd_control.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, unit), pmd_control.u64);
 }
 
-static void __cvmx_bgx_restart_training(int node, int unit, int lmac)
+static void __cvmx_bgx_restart_training(int node, int unit, int index)
 {
 	cvmx_bgxx_spux_int_t spu_int;
 	cvmx_bgxx_spux_br_pmd_control_t pmd_control;
@@ -1234,20 +1152,20 @@ static void __cvmx_bgx_restart_training(int node, int unit, int lmac)
 	spu_int.u64 = 0;
 	spu_int.s.training_failure = 1;
 	spu_int.s.training_done = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(lmac, unit), spu_int.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, unit), spu_int.u64);
 
 	cvmx_wait_usec(1700);  /* Wait 1.7 msec */
 
 	/* These registers aren't cleared when training is restarted. Manually
 	   clear them as per Errata BGX-20968. */
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LP_CUP(lmac, unit), 0);
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_CUP(lmac, unit), 0);
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_REP(lmac, unit), 0);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LP_CUP(index, unit), 0);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_CUP(index, unit), 0);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_REP(index, unit), 0);
 
 	/* Restart training */
-	pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(lmac, unit));
+	pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, unit));
 	pmd_control.s.train_restart = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(lmac, unit), pmd_control.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, unit), pmd_control.u64);
 }
 
 /*
@@ -1268,15 +1186,11 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_helper_interface_mode_t mode;
-	unsigned unit, lmac;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
 	mode = cvmx_helper_interface_get_mode(xiface);
 
 	__cvmx_bgx_common_init(xiface, index);
@@ -1291,14 +1205,14 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 		/* Set TX Threshold */
 		gmi_tx_thresh.u64 = 0;
 		gmi_tx_thresh.s.cnt = 0x20;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_THRESH(lmac, unit),
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_THRESH(index, xi.interface),
 				    gmi_tx_thresh.u64);
 		__cvmx_helper_bgx_sgmii_hardware_init_one_time(xiface, index);
 		gmp_txx_append.u64 = cvmx_read_csr_node(node,
-					CVMX_BGXX_GMP_GMI_TXX_APPEND(lmac, unit));
-		gmp_sgmii_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(lmac, unit));
+					CVMX_BGXX_GMP_GMI_TXX_APPEND(index, xi.interface));
+		gmp_sgmii_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, xi.interface));
 		gmp_sgmii_ctl.s.align = gmp_txx_append.s.preamble ? 0 : 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(lmac, unit),
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, xi.interface),
 			    gmp_sgmii_ctl.u64);
 
 	} else {
@@ -1316,16 +1230,16 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 		* big to adversly effect shaping.
 		*/
 		smu_tx_thresh.s.cnt = 0x100;
-		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_THRESH(lmac, unit),
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_THRESH(index, xi.interface),
 				    smu_tx_thresh.u64);
 		/* Set disparity for RXAUI interface as described in the
 		Marvell RXAUI Interface specification. */
 		if (mode == CVMX_HELPER_INTERFACE_MODE_RXAUI && phy_pres) {
 			cvmx_bgxx_spux_misc_control_t misc_control;
 			misc_control.u64 = cvmx_read_csr_node(node,
-					CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit));
+					CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface));
 			misc_control.s.intlv_rdisp = 1;
-			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit),
+			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface),
 					    misc_control.u64);
 		}
 	}
@@ -1359,7 +1273,6 @@ int __cvmx_helper_bgx_sgmii_configure_loopback(int xipd_port, int enable_interna
 	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_mrx_control;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
-	unsigned unit, lmac;
 
 	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
@@ -1368,16 +1281,13 @@ int __cvmx_helper_bgx_sgmii_configure_loopback(int xipd_port, int enable_interna
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
-	gmp_mrx_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit));
+	gmp_mrx_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
 	gmp_mrx_control.s.loopbck1 = enable_internal;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(lmac, unit), gmp_mrx_control.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface), gmp_mrx_control.u64);
 
-	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
 	gmp_misc_ctl.s.loopbck2 = enable_external;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(lmac, unit), gmp_misc_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface), gmp_misc_ctl.u64);
 
 	__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
 
@@ -1395,25 +1305,21 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 	cvmx_bgxx_spux_misc_control_t spu_misc_control;
 	cvmx_bgxx_cmrx_config_t cmr_config;
 	cvmx_helper_interface_mode_t mode;
-	unsigned unit, lmac;
 	int use_training = 0;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
 	mode = cvmx_helper_interface_get_mode(xiface);
 
 	if (mode == CVMX_HELPER_INTERFACE_MODE_10G_KR || mode == CVMX_HELPER_INTERFACE_MODE_40G_KR4)
 		use_training = 1;
 
 	/* Disable packet reception */
-	spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit));
+	spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface));
 	spu_misc_control.s.rx_packet_dis = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit), spu_misc_control.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface), spu_misc_control.u64);
 
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		cvmx_bgxx_spux_an_control_t spu_an_control;
@@ -1462,17 +1368,26 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 			}
 		}
 
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface),
 					  cvmx_bgxx_spux_control1_t, reset, ==, 0, 10000)) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: PCS in reset", node, interface, index);
 			return -1;
 		}
 
+		/* With XFI and XLAUI, we need to perform RX equalization when the
+		   link is receiving data the first time */
+		if (mode == CVMX_HELPER_INTERFACE_MODE_XFI
+		    || mode == CVMX_HELPER_INTERFACE_MODE_XLAUI) {
+			int qlm = cvmx_qlm_interface(xiface);
+			__cvmx_qlm_rx_equalization(node, qlm,
+				(mode == CVMX_HELPER_INTERFACE_MODE_XLAUI ? -1 : index));
+		}
+
 		if (mode == CVMX_HELPER_INTERFACE_MODE_XFI
 		    || mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
 		    || mode == CVMX_HELPER_INTERFACE_MODE_10G_KR
 		    || mode == CVMX_HELPER_INTERFACE_MODE_40G_KR4) {
-			if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_BR_STATUS1(lmac, unit),
+			if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_BR_STATUS1(index, xi.interface),
 					  cvmx_bgxx_spux_br_status1_t, blk_lock, ==, 1, 10000)) {
 				//cvmx_dprintf("ERROR: %d:BGX%d:%d: BASE-R PCS block not locked\n", node, interface, index);
                 		return -1;
@@ -1480,7 +1395,7 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 		} else {
 			/* (5) Check to make sure that the link appears up and stable. */
 			/* Wait for PCS to be aligned */
-			if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_BX_STATUS(lmac, unit),
+			if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_BX_STATUS(index, xi.interface),
 				  cvmx_bgxx_spux_bx_status_t, alignd, ==, 1, 10000)) {
 				cvmx_dprintf("ERROR: %d:BGX%d:%d: PCS not aligned\n", node, interface, index);
 				return -1;
@@ -1488,11 +1403,11 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 		}
 
 		/* Clear rcvflt bit (latching high) and read it back */
-		spu_status2.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS2(lmac, unit));
+		spu_status2.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS2(index, xi.interface));
 		spu_status2.s.rcvflt = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_STATUS2(lmac, unit), spu_status2.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_STATUS2(index, xi.interface), spu_status2.u64);
 
-		spu_status2.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS2(lmac, unit));
+		spu_status2.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS2(index, xi.interface));
 		if (spu_status2.s.rcvflt) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: Receive fault, need to retry\n",
 					node, interface, index);
@@ -1504,39 +1419,39 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 		}
 
 		/* Wait for MAC RX to be ready */
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_RX_CTL(lmac, unit),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_RX_CTL(index, xi.interface),
 					  cvmx_bgxx_smux_rx_ctl_t, status, ==, 0, 10000)) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: RX not ready\n", node, interface, index);
 			return -1;
 		}
 
 		/* Wait for BGX RX to be idle */
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_CTRL(lmac, unit),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_CTRL(index, xi.interface),
 				  cvmx_bgxx_smux_ctrl_t, rx_idle, ==, 1, 10000)) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: RX not idle\n", node, interface, index);
 			return -1;
 		}
 
 		/* Wait for GMX TX to be idle */
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_CTRL(lmac, unit),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_CTRL(index, xi.interface),
 				  cvmx_bgxx_smux_ctrl_t, tx_idle, ==, 1, 10000)) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: TX not idle\n", node, interface, index);
 			return -1;
 		}
 
 		/* rcvflt should still be 0 */
-		spu_status2.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS2(lmac, unit));
+		spu_status2.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS2(index, xi.interface));
 		if (spu_status2.s.rcvflt) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: Receive fault, need to retry\n", node, interface, index);
 			return -1;
 		}
 
 		/* Receive link is latching low. Force it high and verify it */
-		spu_status1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS1(lmac, unit));
+		spu_status1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS1(index, xi.interface));
 		spu_status1.s.rcv_lnk = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_STATUS1(lmac, unit), spu_status1.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_STATUS1(index, xi.interface), spu_status1.u64);
 
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_STATUS1(lmac, unit),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_STATUS1(index, xi.interface),
 				cvmx_bgxx_spux_status1_t, rcv_lnk, ==, 1, 10000)) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: Receive link down\n", node, interface, index);
 			return -1;
@@ -1544,14 +1459,14 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 	}
 
 	/* (7) Enable packet transmit and receive */
-	spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit));
+	spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface));
 	spu_misc_control.s.rx_packet_dis = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(lmac, unit), spu_misc_control.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface), spu_misc_control.u64);
 
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 	cmr_config.s.data_pkt_tx_en = 1;
 	cmr_config.s.data_pkt_rx_en = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 
 	return 0;
 }
@@ -1603,7 +1518,6 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
 	cvmx_bgxx_smux_rx_ctl_t smu_rx_ctl;
 	cvmx_helper_link_info_t result;
-	unsigned unit, lmac;
 
 	result.u64 = 0;
 
@@ -1611,18 +1525,9 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return result;
-
-	spu_status1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS1(lmac, unit));
-	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(lmac, unit));
-	smu_rx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(lmac, unit));
-
-	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
-		cvmx_printf("ERROR: %s: unimplemented for this model\n",__func__);
-		/* FIXME: o75 needs below logic revised */
-		return result;
-	}
+	spu_status1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS1(index, xi.interface));
+	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, xi.interface));
+	smu_rx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(index, xi.interface));
 
 	if ((smu_tx_ctl.s.ls == 0)
 	    && (smu_rx_ctl.s.status == 0)
@@ -1674,18 +1579,14 @@ int __cvmx_helper_bgx_xaui_link_set(int xipd_port, cvmx_helper_link_info_t link_
 	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
 	cvmx_bgxx_smux_rx_ctl_t smu_rx_ctl;
 	cvmx_bgxx_spux_status1_t spu_status1;
-	unsigned lmac, unit;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
-	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(lmac, unit));
-	smu_rx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(lmac, unit));
-	spu_status1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS1(lmac, unit));
+	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, xi.interface));
+	smu_rx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(index, xi.interface));
+	spu_status1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS1(index, xi.interface));
 
 	/* If the link shouldn't be up, then just return */
 	if (!link_info.s.link_up)
@@ -1710,27 +1611,117 @@ int __cvmx_helper_bgx_xaui_configure_loopback(int xipd_port,
 	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_bgxx_spux_control1_t spu_control1;
 	cvmx_bgxx_smux_ext_loopback_t smu_ext_loopback;
-	unsigned unit, lmac;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
 	/* Set the internal loop */
-	spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit));
+	spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface));
 	spu_control1.s.loopbck = enable_internal;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(lmac, unit), spu_control1.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface), spu_control1.u64);
 	/* Set the external loop */
-	smu_ext_loopback.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_EXT_LOOPBACK(lmac, unit));
+	smu_ext_loopback.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_EXT_LOOPBACK(index, xi.interface));
 	smu_ext_loopback.s.en = enable_external;
-	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_EXT_LOOPBACK(lmac, unit), smu_ext_loopback.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_EXT_LOOPBACK(index, xi.interface), smu_ext_loopback.u64);
 
 	return __cvmx_helper_bgx_xaui_link_init(index, xiface);
 }
 
+
+int __cvmx_helper_bgx_mixed_enable(int xiface)
+{
+	int index;
+	int num_ports = cvmx_helper_ports_on_interface(xiface);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
+
+	for (index = 0; index < num_ports; index++) {
+		cvmx_bgxx_cmrx_config_t cmr_config;
+		int xipd_port, phy_pres = 0;
+
+		if (!cvmx_helper_is_port_valid(xiface, index))
+			continue;
+	
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+		xipd_port = cvmx_helper_get_ipd_port(xiface, index);
+
+		if (cmr_config.s.lmac_type == 2 &&
+			(cvmx_helper_get_port_phy_present(xiface, index)))
+			phy_pres = 1;
+
+		if (__cvmx_helper_bgx_port_init(xipd_port, phy_pres))
+			continue;
+
+		/* Call SGMII init code for lmac_type = 0 */
+		if (cmr_config.s.lmac_type == 0) {
+			int do_link_set = 1;
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+			if (!(cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM))
+				do_link_set = 0;
+#endif
+
+			if (do_link_set)
+				__cvmx_helper_bgx_sgmii_link_set(xipd_port,
+					__cvmx_helper_bgx_sgmii_link_get(xipd_port));
+		/* All other lmac type call XAUI init code */
+		} else {
+			if (__cvmx_helper_bgx_xaui_link_init(index, xiface)) {
+				cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", node, interface, index);
+				continue;
+			}
+		}
+	}
+	return 0;
+}
+
+cvmx_helper_link_info_t __cvmx_helper_bgx_mixed_link_get(int xipd_port)
+{
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int index = cvmx_helper_get_interface_index_num(xipd_port);
+
+	cmr_config.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	if (cmr_config.s.lmac_type == 0)
+		return __cvmx_helper_bgx_sgmii_link_get(xipd_port);
+	else
+		return __cvmx_helper_bgx_xaui_link_get(xipd_port);
+}
+
+int __cvmx_helper_bgx_mixed_link_set(int xipd_port, cvmx_helper_link_info_t link_info)
+{
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int index = cvmx_helper_get_interface_index_num(xipd_port);
+
+	cmr_config.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	if (cmr_config.s.lmac_type == 0)
+		return __cvmx_helper_bgx_sgmii_link_set(xipd_port, link_info);
+	else
+		return __cvmx_helper_bgx_xaui_link_set(xipd_port, link_info);
+}
+
+int __cvmx_helper_bgx_mixed_configure_loopback(int xipd_port,
+						     int enable_internal,
+						     int enable_external)
+{
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int index = cvmx_helper_get_interface_index_num(xipd_port);
+
+	cmr_config.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	if (cmr_config.s.lmac_type == 0)
+		return __cvmx_helper_bgx_sgmii_configure_loopback(xipd_port,
+						enable_internal, enable_external);
+	else
+		return __cvmx_helper_bgx_xaui_configure_loopback(xipd_port,
+						enable_internal, enable_external);
+}
+
 /**
  * @INTERNAL
  * Configure Priority-Based Flow Control (a.k.a. PFC/CBFC)
@@ -1741,18 +1732,14 @@ void __cvmx_helper_bgx_xaui_config_pfc(unsigned node,
 {
 	int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	unsigned lmac, unit;
 	cvmx_bgxx_smux_cbfc_ctl_t cbfc_ctl;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return;
-
 	cbfc_ctl.u64 = cvmx_read_csr_node(node,
-		CVMX_BGXX_SMUX_CBFC_CTL(lmac, unit)
+		CVMX_BGXX_SMUX_CBFC_CTL(index, xi.interface)
 		);
 
 	/* Enable all PFC controls if requiested */
@@ -1766,9 +1753,9 @@ void __cvmx_helper_bgx_xaui_config_pfc(unsigned node,
 #endif
 	if (debug)
 		cvmx_dprintf("%s: CVMX_BGXX_SMUX_CBFC_CTL(%d,%d)=%#llx\n",
-			__func__, lmac, unit, (unsigned long long)cbfc_ctl.u64);
+			__func__, index, xi.interface, (unsigned long long)cbfc_ctl.u64);
 	cvmx_write_csr_node(node,
-		CVMX_BGXX_SMUX_CBFC_CTL(lmac, unit),
+		CVMX_BGXX_SMUX_CBFC_CTL(index, xi.interface),
 		cbfc_ctl.u64);
 }
 
@@ -1781,30 +1768,25 @@ void __cvmx_helper_bgx_xaui_config_pfc(unsigned node,
  * ctl_bck = 0, ctl_drp = 1: all PAUSE frames are completely ignored
  * @param node		node number.
  * @param interface	interface number
- * @param port		port number
+ * @param index		port number
  * @param ctl_bck	1: Forward PAUSE information to TX block
  * @param ctl_drp	1: Drop control PAUSE frames.
  */
 void cvmx_helper_bgx_rx_pause_ctl(unsigned node, unsigned interface,
-			unsigned port, unsigned ctl_bck, unsigned ctl_drp)
+			unsigned index, unsigned ctl_bck, unsigned ctl_drp)
 {
 	int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	unsigned lmac, unit;
 	cvmx_bgxx_smux_rx_frm_ctl_t frm_ctl;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
-		__func__, xi.node, xi.interface, port);
-
-	if (cvmx_helper_bgx_index(xiface, port, &unit, &lmac) < 0)
-		return;
-
+		__func__, xi.node, xi.interface, index);
 
-	frm_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(lmac, unit));
+	frm_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(index, xi.interface));
 	frm_ctl.s.ctl_bck = ctl_bck;
 	frm_ctl.s.ctl_drp = ctl_drp;
-	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(lmac, unit), frm_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(index, xi.interface), frm_ctl.u64);
 }
 
 /**
@@ -1812,7 +1794,7 @@ void cvmx_helper_bgx_rx_pause_ctl(unsigned node, unsigned interface,
  * and dmac filter match packets.
  * @param node		node number.
  * @param interface	interface number
- * @param port		port number
+ * @param index		port number
  * @param cam_accept	0: reject packets on dmac filter match
  *                      1: accept packet on dmac filter match
  * @param mcast_mode	0x0 = Force reject all multicast packets
@@ -1821,27 +1803,23 @@ void cvmx_helper_bgx_rx_pause_ctl(unsigned node, unsigned interface,
  * @param bcast_accept  0 = Reject all broadcast packets
  *                      1 = Accept all broadcast packets
  */
-void cvmx_helper_bgx_rx_adr_ctl(unsigned node, unsigned interface, unsigned port,
+void cvmx_helper_bgx_rx_adr_ctl(unsigned node, unsigned interface, unsigned index,
                                  unsigned cam_accept, unsigned mcast_mode, unsigned bcast_accept)
 {
 	int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	unsigned lmac, unit;
         cvmx_bgxx_cmrx_rx_adr_ctl_t adr_ctl;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
-		__func__, xi.node, xi.interface, port);
-
-	if (cvmx_helper_bgx_index(xiface, port, &unit, &lmac) < 0)
-		return;
+		__func__, xi.node, xi.interface, index);
 
-        adr_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(lmac, unit));
+        adr_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(index, xi.interface));
         adr_ctl.s.cam_accept = cam_accept;
         adr_ctl.s.mcst_mode = mcast_mode;
         adr_ctl.s.bcst_accept = bcast_accept;
 
-        cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(lmac, unit), adr_ctl.u64);
+        cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(index, xi.interface), adr_ctl.u64);
 }
 
 /**
@@ -1859,7 +1837,6 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 	cvmx_bgxx_smux_tx_append_t  smu_tx_append;
 	int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	unsigned unit, lmac;
 
 	if (__cvmx_helper_bgx_enumerate(xiface) < 0)
 		return;
@@ -1868,11 +1845,8 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return;
-
 	cmr_config.u64 = cvmx_read_csr_node(node,
-		CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+		CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 
 	(void) cmr_config;	/* In case we need LMAC_TYPE later */
 
@@ -1883,14 +1857,14 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 	/* per HRM Sec 34.3.4.4 */
 	gmp_min_pkt.s.min_size = 59;
 	cvmx_write_csr_node(node,
-		CVMX_BGXX_GMP_GMI_TXX_MIN_PKT(lmac, unit),
+		CVMX_BGXX_GMP_GMI_TXX_MIN_PKT(index, xi.interface),
 		gmp_min_pkt.u64);
 	gmp_txx_append.u64 = cvmx_read_csr_node(node,
-		CVMX_BGXX_GMP_GMI_TXX_APPEND(lmac, unit));
+		CVMX_BGXX_GMP_GMI_TXX_APPEND(index, xi.interface));
 	gmp_txx_append.s.fcs = fcs_enable;
 	gmp_txx_append.s.pad = pad_enable;
 	cvmx_write_csr_node(node,
-		CVMX_BGXX_GMP_GMI_TXX_APPEND(lmac, unit),
+		CVMX_BGXX_GMP_GMI_TXX_APPEND(index, xi.interface),
 		gmp_txx_append.u64);
 
 	/* Set SMUX (XAUI/XFI) Tx options */
@@ -1898,14 +1872,14 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 	/* HRM Sec 33.3.4.3 should read 64 */
 	 smu_min_pkt.s.min_size = 0x40;
 	cvmx_write_csr_node(node,
-		CVMX_BGXX_SMUX_TX_MIN_PKT(lmac, unit),
+		CVMX_BGXX_SMUX_TX_MIN_PKT(index, xi.interface),
 		smu_min_pkt.u64);
 	smu_tx_append.u64 = cvmx_read_csr_node(node,
-		CVMX_BGXX_SMUX_TX_APPEND(lmac, unit));
+		CVMX_BGXX_SMUX_TX_APPEND(index, xi.interface));
 	smu_tx_append.s.fcs_c = fcs_enable;
 	smu_tx_append.s.pad = pad_enable;
 	cvmx_write_csr_node(node,
-		CVMX_BGXX_SMUX_TX_APPEND(lmac, unit),
+		CVMX_BGXX_SMUX_TX_APPEND(index, xi.interface),
 		smu_tx_append.u64);
 }
 
@@ -1930,7 +1904,6 @@ void cvmx_helper_bgx_set_mac(int xipd_port, int bcst, int mcst, uint64_t mac)
 	cvmx_bgxx_cmrx_rx_adr_ctl_t adr_ctl;
 	cvmx_bgxx_cmrx_config_t cmr_config;
 	int saved_state;
-	unsigned unit, lmac;
 	cvmx_helper_interface_mode_t mode;
 
 	if (__cvmx_helper_bgx_enumerate(xiface) < 0)
@@ -1942,25 +1915,22 @@ void cvmx_helper_bgx_set_mac(int xipd_port, int bcst, int mcst, uint64_t mac)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return;
-
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 	saved_state = cmr_config.s.enable;
 	cmr_config.s.enable = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 
 	/* Set the mac */
 	adr_cam.u64 = 0;
-	adr_cam.s.id = lmac;
+	adr_cam.s.id = index;
 
 	if (mac != 0ull)
 		adr_cam.s.en = 1;
 	adr_cam.s.adr = mac;
 
-	cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_ADRX_CAM(lmac * 8, unit), adr_cam.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_ADRX_CAM(index * 8, xi.interface), adr_cam.u64);
 
-	adr_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(lmac, unit));
+	adr_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(index, xi.interface));
 	if (mac != 0ull)
 		adr_ctl.s.cam_accept = 1;  /* Accept the packet on DMAC CAM address */
 	else
@@ -1968,13 +1938,13 @@ void cvmx_helper_bgx_set_mac(int xipd_port, int bcst, int mcst, uint64_t mac)
 
 	adr_ctl.s.mcst_mode = mcst;   /* Use the address filter CAM */
 	adr_ctl.s.bcst_accept = bcst; /* Accept all broadcast packets */
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(lmac, unit), adr_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(index, xi.interface), adr_ctl.u64);
 	/* Set SMAC for PAUSE frames */
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_SMACX(lmac, unit), mac);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_SMACX(index, xi.interface), mac);
 
 	/* Restore back the interface state */
 	cmr_config.s.enable = saved_state;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
 	/* Wait 100ms after bringing up the link to give the PHY some time */
 	if (cmr_config.s.enable) {
 		mode = cvmx_helper_interface_get_mode(xiface);
@@ -2003,8 +1973,6 @@ int cvmx_bgx_set_backpressure_override(int xiface, unsigned port_mask)
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	cvmx_bgxx_cmr_rx_ovr_bp_t rx_ovr_bp;
 	int node = xi.node;
-	unsigned unit, lmac;
-	const unsigned index = 0;
 
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d port_mask=%#x\n",
@@ -2013,20 +1981,12 @@ int cvmx_bgx_set_backpressure_override(int xiface, unsigned port_mask)
 	if (__cvmx_helper_bgx_enumerate(xiface) <= 0)
 		return -1;
 
-	/* check number of BGX unit against per-model max */
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return -1;
-
-	/* Full-BGX interfaces, lmac==0, half-BGX interfaces lmax = 0 or 2 */
-	/* Adjust port_mask for half-BGX interfaces */
-	port_mask <<= lmac;
-
 	/* Check for valid arguments */
 	rx_ovr_bp.u64 = 0;
 	rx_ovr_bp.s.en = port_mask;	/* Per port Enable back pressure override */
 	rx_ovr_bp.s.ign_fifo_bp = port_mask;	/* Ignore the RX FIFO full when computing BP */
 
-	cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_OVR_BP(unit), rx_ovr_bp.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_OVR_BP(xi.interface), rx_ovr_bp.u64);
 	return 0;
 }
 
@@ -2039,28 +1999,24 @@ void cvmx_helper_bgx_set_jabber(int xiface, unsigned index,
 {
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	cvmx_bgxx_cmrx_config_t cmr_config;
-	unsigned unit, lmac, node;
+	int node;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_BGX))
 		return;
 
 	node = xi.node;
 
-	/* check number of BGX unit against per-model max */
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
-		return;
-
 	/* Get LMAC type from common config */
 	cmr_config.u64 = cvmx_read_csr_node(node,
-		CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+		CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 
 	/* Set GMI or SMUX register based on lmac_type */
 	if (cmr_config.s.lmac_type == 0) {
 		cvmx_write_csr_node(node,
-				CVMX_BGXX_GMP_GMI_RXX_JABBER(lmac, unit), size);
+				CVMX_BGXX_GMP_GMI_RXX_JABBER(index, xi.interface), size);
 	} else {
 		cvmx_write_csr_node(node,
-			CVMX_BGXX_SMUX_RX_JABBER(lmac, unit), size);
+			CVMX_BGXX_SMUX_RX_JABBER(index, xi.interface), size);
 	}
 }
 
@@ -2071,7 +2027,7 @@ void cvmx_helper_bgx_set_jabber(int xiface, unsigned index,
 int cvmx_helper_bgx_shutdown_port(int xiface, int index)
 {
 	cvmx_bgxx_cmrx_config_t cmr_config;
-	unsigned unit, lmac, node;
+	int node;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
 	node = xi.node;
@@ -2080,32 +2036,32 @@ int cvmx_helper_bgx_shutdown_port(int xiface, int index)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, node, xi.interface, index);
 
-	if (cvmx_helper_bgx_index(xiface, index, &unit, &lmac) < 0)
+	if (__cvmx_helper_bgx_enumerate(xiface) <= 0)
 		return -1;
 
 	/* Disable BGX CMR before we make any changes. */
 	cmr_config.u64 = cvmx_read_csr_node(node,
-		CVMX_BGXX_CMRX_CONFIG(lmac, unit));
+		CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 
 	cmr_config.s.enable = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(lmac, unit),
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface),
 		cmr_config.u64);
 
 	/* Clear pending common interrupts */
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_INT(lmac, unit), 0x7);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_INT(index, xi.interface), 0x7);
 
 	if (cmr_config.s.lmac_type == 0) {	/* SGMII */
 		/* Clear GMP interrupts */
 		cvmx_write_csr_node(node,
-			CVMX_BGXX_GMP_GMI_RXX_INT(lmac, unit), 0xfff);
+			CVMX_BGXX_GMP_GMI_RXX_INT(index, xi.interface), 0xfff);
 		cvmx_write_csr_node(node,
-			CVMX_BGXX_GMP_GMI_TXX_INT(lmac, unit), 0x1f);
+			CVMX_BGXX_GMP_GMI_TXX_INT(index, xi.interface), 0x1f);
 		/* Wait for GMX to be idle */
 		if (CVMX_WAIT_FOR_FIELD64_NODE(node,
-			CVMX_BGXX_GMP_GMI_PRTX_CFG(lmac, unit),
+			CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface),
 			cvmx_bgxx_gmp_gmi_prtx_cfg_t, rx_idle, ==, 1, 10000) ||
 		    CVMX_WAIT_FOR_FIELD64_NODE(node,
-			CVMX_BGXX_GMP_GMI_PRTX_CFG(lmac, unit),
+			CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface),
 			cvmx_bgxx_gmp_gmi_prtx_cfg_t, tx_idle, ==, 1, 10000)) {
 				cvmx_printf("ERROR: %s: SGMII: "
 				"Timeout waiting for port %u:%d/%d to stop\n",
@@ -2114,22 +2070,22 @@ int cvmx_helper_bgx_shutdown_port(int xiface, int index)
 			}
 		/* Read GMX CFG again to make sure the disable completed */
 		cvmx_read_csr_node(node,
-			CVMX_BGXX_GMP_GMI_PRTX_CFG(lmac, unit));
+			CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface));
 	} else {		/* XAUI/XFI/10-KR */
 		/* Clear all pending SMUX interrupts */
-		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_INT(lmac, unit),
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_INT(index, xi.interface),
 			0xfff);
-		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_INT(lmac, unit),
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_INT(index, xi.interface),
 			0x1f);
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(lmac, unit),
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, xi.interface),
 			0x7fff);
 
 		/* Wait for GMX RX to be idle */
 		if (CVMX_WAIT_FOR_FIELD64_NODE(node,
-			CVMX_BGXX_SMUX_CTRL(lmac, unit),
+			CVMX_BGXX_SMUX_CTRL(index, xi.interface),
 			cvmx_bgxx_smux_ctrl_t, rx_idle, ==, 1, 10000) ||
 		    CVMX_WAIT_FOR_FIELD64_NODE(node,
-			CVMX_BGXX_SMUX_CTRL(lmac, unit),
+			CVMX_BGXX_SMUX_CTRL(index, xi.interface),
 			cvmx_bgxx_smux_ctrl_t, tx_idle, ==, 1, 10000)) {
 				cvmx_printf("ERROR: %s: XAUI: "
 				"Timeout waiting for port %u:%d/%d to stop\n",
@@ -3051,7 +3007,7 @@ int cvmx_helper_bgx_gmp_frm_ctl(int node, int bgx, unsigned N)
 	PRMns("GMP:FRM_CTL: Strip off the preamble (pre_strp)",
 		mask_sgmii, "   %8s    ",
 		lmac[ind].gmp_gmi_rx_frm_ctl.s.pre_strp ? " Enabled" : "Disabled");
-	PRMns("GMP:FRM_CTL: Check preamble is correc(pre_chk)",
+	PRMns("GMP:FRM_CTL: Check preamble is correct(pre_chk)",
 		mask_sgmii, "   %8s    ",
 		lmac[ind].gmp_gmi_rx_frm_ctl.s.pre_chk ? " Enabled" : "Disabled");
 	return 0;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
index df7fe85..9c6a6a2 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
@@ -126,6 +126,13 @@ __get_marvell_phy_link_state(cvmx_phy_info_t *phy_info);
  */
 static cvmx_helper_link_info_t
 __get_aquantia_phy_link_state(cvmx_phy_info_t *phy_info);
+
+/**
+ * @INTERNAL
+ * Get link state of the Vitesse VSC8490 PHY
+ */
+static cvmx_helper_link_info_t
+__get_vitesse_vsc8490_phy_link_state(cvmx_phy_info_t *phy_info);
 #endif
 
 /**
@@ -644,6 +651,9 @@ int __cvmx_helper_78xx_parse_phy(struct cvmx_phy_info *phy_info, int ipd_port)
 	} else if (!memcmp("cortina", compat, strlen("cortina"))) {
 		phy_info->phy_type = CORTINA_PHY;
 		phy_info->link_function = __cvmx_get_cortina_phy_link_state;
+	} else if (!strcmp("vitesse,vsc8490", compat)) {
+		phy_info->phy_type = VITESSE_VSC8490_PHY;
+		phy_info->link_function = __get_vitesse_vsc8490_phy_link_state;
 	}
 
 	phy_info->ipd_port = ipd_port;
@@ -1072,8 +1082,13 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 		if (dbg)
 			cvmx_dprintf("Vitesse PHY detected for ipd_port %d\n",
 				     ipd_port);
-		if (!fdt_node_check_compatible(fdt_addr, phy,
-					       "ethernet-phy-ieee802.3-c22")) {
+		if (!fdt_node_check_compatible(fdt_addr, phy, "vitesse,vsc8490")) {
+			phy_info->phy_type = VITESSE_VSC8490_PHY;
+			if (dbg)
+				cvmx_dprintf("Vitesse VSC8490 detected\n");
+			phy_info->link_function = __get_vitesse_vsc8490_phy_link_state;
+		} else if (!fdt_node_check_compatible(fdt_addr, phy,
+						      "ethernet-phy-ieee802.3-c22")) {
 			phy_info->phy_type = GENERIC_8023_C22_PHY;
 			phy_info->link_function =
 					__cvmx_get_generic_8023_c22_phy_link_state;
@@ -1719,6 +1734,41 @@ __get_generic_8023_c45_phy_link_state(cvmx_phy_info_t *phy_info)
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 /**
  * @INTERNAL
+ * Get link state of generic C45 compliant PHYs
+ */
+static cvmx_helper_link_info_t
+__get_vitesse_vsc8490_phy_link_state(cvmx_phy_info_t *phy_info)
+{
+	cvmx_helper_link_info_t result;
+	int phy_status;
+	uint32_t phy_addr = phy_info->phy_addr;
+	int xiface;
+	cvmx_helper_interface_mode_t mode;
+
+	xiface = cvmx_helper_get_interface_num(phy_info->ipd_port);
+	mode = cvmx_helper_interface_get_mode(xiface);
+
+	/* For 10G just use the generic 10G support */
+	if (mode == CVMX_HELPER_INTERFACE_MODE_XAUI ||
+	    mode == CVMX_HELPER_INTERFACE_MODE_RXAUI)
+		return __get_generic_8023_c45_phy_link_state(phy_info);
+
+	phy_status = cvmx_mdio_45_read(phy_addr >> 8, phy_addr & 0xff,
+				       3, 0xe10d);
+
+	result.u64 = 0;
+	if ((phy_status & 0x111) != 0x111)
+		return result;
+
+	result.s.speed = 1000;
+	result.s.full_duplex = 1;
+	result.s.link_up = 1;
+
+	return result;
+}
+
+/**
+ * @INTERNAL
  * Get link state of Aquantia PHY
  */
 static cvmx_helper_link_info_t
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
index 88e87b1..90d4b07 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
@@ -51,6 +51,7 @@
 #include <asm/octeon/cvmx-pki-resources.h>
 #include <asm/octeon/cvmx-helper-util.h>
 #include <asm/octeon/cvmx-ipd.h>
+#include <asm/octeon/cvmx-helper-pki.h>
 #include <asm/octeon/cvmx-global-resources.h>
 #else
 #include "cvmx.h"
@@ -551,6 +552,7 @@ EXPORT_SYMBOL(cvmx_helper_pki_port_shutdown);
  */
 void cvmx_helper_pki_shutdown(int node)
 {
+	int i, k;
 	/* remove pcam entries */
 	/* Disable PKI */
 	cvmx_pki_disable(node);
@@ -561,6 +563,25 @@ void cvmx_helper_pki_shutdown(int node)
 	/* Free all the allocated PKI resources
 	except fpa pools & aura which will be done in fpa block */
 	__cvmx_pki_global_rsrc_free(node);
+	/* Setup some configuration registers to the reset state.*/
+	for (i = 0; i < CVMX_PKI_NUM_PKIND; i++) {
+		for (k = 0; k < (int)CVMX_PKI_NUM_CLUSTER; k++) {
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(i, k), 0);			
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(i, k), 0);			
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_SKIP(i, k), 0);			
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_L2_CUSTOM(i, k), 0);			
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_LG_CUSTOM(i, k), 0);			
+		}
+		cvmx_write_csr_node(node, CVMX_PKI_PKINDX_ICGSEL(k), 0);			
+	}
+	for (i = 0; i < CVMX_PKI_NUM_FINAL_STYLE; i++) {
+		for (k = 0; k < (int)CVMX_PKI_NUM_CLUSTER; k++) {
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(i, k), 0);			
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(i, k), 0);			
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(i, k), 0);			
+		}
+		cvmx_write_csr_node(node, CVMX_PKI_STYLEX_BUF(k), (0x5 << 22) | 0x20);			
+	}
 }
 EXPORT_SYMBOL(cvmx_helper_pki_shutdown);
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
index a8410e8..18f6f0d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
@@ -923,11 +923,6 @@ int cvmx_helper_pko3_init_interface(int xiface)
 		cvmx_dprintf("ERROR: %s: invalid iface %u:%u\n",
 			     __FUNCTION__, xi.node, xi.interface);
 		return -1;
-	} else if (num_ports == 1 && (
-		mode == CVMX_HELPER_INTERFACE_MODE_XAUI ||
-		mode == CVMX_HELPER_INTERFACE_MODE_XLAUI)) {
-		/* Force PFC for 4-lane interfaces */
-		pfc = true;
 	}
 
 	if (mode == CVMX_HELPER_INTERFACE_MODE_LOOP) {
@@ -947,7 +942,6 @@ int cvmx_helper_pko3_init_interface(int xiface)
 			goto __cfg_error;
 		}
 	}
-
 	else if (mode == CVMX_HELPER_INTERFACE_MODE_NPI) {
 		num_queues =
 			__cvmx_pko_queue_static_config.
@@ -965,7 +959,6 @@ int cvmx_helper_pko3_init_interface(int xiface)
 			goto __cfg_error;
 		}
 	}
-
 	/* ILK-specific queue configuration */
 	else if (mode == CVMX_HELPER_INTERFACE_MODE_ILK) {
 		unsigned num_chans = __cvmx_helper_ilk_enumerate(xiface);
@@ -973,7 +966,6 @@ int cvmx_helper_pko3_init_interface(int xiface)
 		res = __cvmx_pko3_config_chan_interface(xiface, num_chans,
 				num_queues, qos);
 	}
-
 	/* Setup all ethernet configured for PFC */
 	else if (pfc) {
 		/* PFC interfaces have 8 prioritized queues */
@@ -988,7 +980,6 @@ int cvmx_helper_pko3_init_interface(int xiface)
 				xi.interface, subif, true);
 		}
 	}
-
 	/* All other interfaces follow static configuration */
 	else {
 
@@ -1019,18 +1010,6 @@ int cvmx_helper_pko3_init_interface(int xiface)
 
 	/* Setup interface options */
 	for (subif = 0; subif < num_ports; subif++) {
-		int num_bgx_interfaces = 0;
-
-		if(OCTEON_IS_MODEL(OCTEON_CN78XX))
-			num_bgx_interfaces = 6;
-		/* o73 BGX 0,1 map to interface 0,1
-		 * while each half of BGX2 is mapped to interface 2,3
-		 */
-		if(OCTEON_IS_MODEL(OCTEON_CN73XX))
-			num_bgx_interfaces = 4;
-		/* o75 has every half-BGX as a separate interface */
-		if(OCTEON_IS_MODEL(OCTEON_CNF75XX))
-			num_bgx_interfaces = 2;
 
 		/* Open interface/port DQs to allow transmission to begin */
 		res = __cvmx_pko3_helper_dqs_activate(xiface,
@@ -1055,7 +1034,7 @@ int cvmx_helper_pko3_init_interface(int xiface)
 		if (mode == CVMX_HELPER_INTERFACE_MODE_SRIO)
 			fcs_sof_off = 16;
 
-		if (xi.interface >= num_bgx_interfaces) {
+		if (xi.interface >= CVMX_HELPER_MAX_GMX) {
 			/* Non-BGX interface, use PKO for FCS/PAD */
 			res = cvmx_pko3_interface_options(xiface, subif,
 				fcs_enable, pad_enable_pko, fcs_sof_off);
@@ -1415,44 +1394,45 @@ do {\
 } while (0)
 
 #define PKO_MAC_NUM	32
-char *pko_macmap[PKO_MAC_NUM] = {
-	[0]  = "LBK",
-	[1]  = "DPI",
-	[2]  = "ILK0",
-	[3]  = "ILK1",
-	[4]  = "BGX0:MAC0",
-	[5]  = "BGX0:MAC1",
-	[6]  = "BGX0:MAC2",
-	[7]  = "BGX0:MAC3",
-	[8]  = "BGX1:MAC0",
-	[9]  = "BGX1:MAC1",
-	[10] = "BGX1:MAC2",
-	[11] = "BGX1:MAC3",
-	[12] = "BGX2:MAC0",
-	[13] = "BGX2:MAC1",
-	[14] = "BGX2:MAC2",
-	[15] = "BGX2:MAC3",
-	[16] = "BGX3:MAC0",
-	[17] = "BGX3:MAC1",
-	[18] = "BGX3:MAC2",
-	[19] = "BGX3:MAC3",
-	[20] = "BGX4:MAC0",
-	[21] = "BGX4:MAC1",
-	[22] = "BGX4:MAC2",
-	[23] = "BGX4:MAC3",
-	[24] = "BGX5:MAC0",
-	[25] = "BGX5:MAC1",
-	[26] = "BGX5:MAC2",
-	[27] = "BGX5:MAC3",
-	[28] = "NULL",
-	[29] = "Undef",
-	[30] = "Undef",
-	[31] = "Undef"
+char *pko_macmap[PKO_MAC_NUM][3] = {
+			/*CN78XX		CN73XX			CNF75XX*/
+	[0]  = {"LBK",			"LBK",			"LBK"},
+	[1]  = {"DPI",			"DPI",			"DPI"},
+	[2]  = {"ILK0",			"BGX0:MAC0",	"BGX0:MAC0"},
+	[3]  = {"ILK1",			"BGX0:MAC1",	"BGX0:MAC1"},
+	[4]  = {"BGX0:MAC0",	"BGX0:MAC2",	"BGX0:MAC2"},
+	[5]  = {"BGX0:MAC1",	"BGX0:MAC3",	"BGX0:MAC3"},
+	[6]  = {"BGX0:MAC2",	"BGX1:MAC0",	"SRIO0-0"},
+	[7]  = {"BGX0:MAC3",	"BGX1:MAC1",	"SRIO0-1"},
+	[8]  = {"BGX1:MAC0",	"BGX1:MAC2",	"SRIO1-0"},
+	[9]  = {"BGX1:MAC1",	"BGX1:MAC3",	"SRIO1-1"},
+	[10] = {"BGX1:MAC2",	"BGX2:MAC0",	"NULL"},
+	[11] = {"BGX1:MAC3",	"BGX2:MAC1",	NULL},
+	[12] = {"BGX2:MAC0",	"BGX2:MAC2",	NULL},
+	[13] = {"BGX2:MAC1",	"BGX2:MAC3",	NULL},
+	[14] = {"BGX2:MAC2",	"NULL",			NULL},
+	[15] = {"BGX2:MAC3",	NULL,			NULL},
+	[16] = {"BGX3:MAC0",	NULL,			NULL},
+	[17] = {"BGX3:MAC1",	NULL,			NULL},
+	[18] = {"BGX3:MAC2",	NULL,			NULL},
+	[19] = {"BGX3:MAC3",	NULL,			NULL},
+	[20] = {"BGX4:MAC0",	NULL,			NULL},
+	[21] = {"BGX4:MAC1",	NULL,			NULL},
+	[22] = {"BGX4:MAC2",	NULL,			NULL},
+	[23] = {"BGX4:MAC3",	NULL,			NULL},
+	[24] = {"BGX5:MAC0",	NULL,			NULL},
+	[25] = {"BGX5:MAC1",	NULL,			NULL},
+	[26] = {"BGX5:MAC2",	NULL,			NULL},
+	[27] = {"BGX5:MAC3",	NULL,			NULL},
+	[28] = {"NULL",			NULL,			NULL},
+	[29] = {NULL,			NULL,			NULL},
+	[30] = {NULL,			NULL,			NULL},
+	[31] = {NULL,			NULL,			NULL}
 };
 
 int cvmx_helper_pko3_config_dump(unsigned int node)
 {
-	int queue, group, base;
+	int queue, nqueues, group, base, nmacs, ngroups;
 	cvmx_pko_dqx_sw_xoff_t dqxoff;
 	cvmx_pko_dqx_topology_t dqtop;
 	cvmx_pko_l5_sqx_topology_t l5top;
@@ -1465,103 +1445,192 @@ int cvmx_helper_pko3_config_dump(unsigned int node)
 	cvmx_pko_l4_sqx_schedule_t l4sch;
 	cvmx_pko_l3_sqx_schedule_t l3sch;
 	cvmx_pko_l2_sqx_schedule_t l2sch;
+	cvmx_pko_l1_sqx_schedule_t l1sch;
 	cvmx_pko_macx_cfg_t maccfg;
 	cvmx_pko_l3_l2_sqx_channel_t chcfg;
 	cvmx_pko_channel_level_t chlvl;
 	uint32_t crc32, pcrc32;
-	char lines[4][256];
+	char lines[4][128];
 
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX) ||
+		OCTEON_IS_MODEL(OCTEON_CN73XX) ||
+		OCTEON_IS_MODEL(OCTEON_CNF75XX))) {
+		cvmx_printf("PKO3 Config Dump is not supported on this OCTEON model\n");
+		return 0;
+	}
 	chlvl.u64 = cvmx_read_csr_node(node, CVMX_PKO_CHANNEL_LEVEL);
 	memset(lines[3], '*', PKO_PRN_LINELEN);  lines[3][PKO_PRN_LINELEN] = '\0';
 	cvmx_printf("\n%s\n", lines[3]);
-	cvmx_printf("   PKO Configuration (Node %d)\n", cvmx_get_node_num());
+	cvmx_printf("   PKO Configuration (Node %d)\n", node);
 	cvmx_printf("%s\n", lines[3]);
 	cvmx_printf("%-*s%*s%*s%*s%*s%*s%*s%*s%*s\n", PKO_PRN_HEADLEN, "",
 		PKO_PRN_DPLEN(8), "DQ", PKO_PRN_DPLEN(8), "L5", PKO_PRN_DPLEN(8), "L4",
 		PKO_PRN_DPLEN(8), "L3", PKO_PRN_DPLEN(8),"L2", PKO_PRN_DPLEN(8), "L1",
 		PKO_PRN_DPLEN(8), "MAC", PKO_PRN_DPLEN(8), "FIFO");
 
-	for (queue = 0, pcrc32 = 0, base = 0; queue < 1024; queue++) {
+	nqueues = cvmx_pko3_num_level_queues(CVMX_PKO_DESCR_QUEUES);
+	nmacs = __cvmx_pko3_num_macs();
+	for (queue = 0, pcrc32 = 0, base = 0; queue < nqueues; queue++) {
 		CVMX_MT_CRC_POLYNOMIAL(0x1edc6f41);
 		CVMX_MT_CRC_IV(0xffffffff);
+		/* Descriptor Queue Level: */
 		dqxoff.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_SW_XOFF(queue));
 		CVMX_MT_CRC_DWORD(dqxoff.u64);
 		dqtop.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_TOPOLOGY(queue));
 		CVMX_MT_CRC_DWORD(dqtop.u64);
-		l5top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L5_SQX_TOPOLOGY(dqtop.s.parent));
-		CVMX_MT_CRC_DWORD(l5top.u64);
-		l4top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L4_SQX_TOPOLOGY(l5top.s.parent));
-		CVMX_MT_CRC_DWORD(l4top.u64);
-		l3top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_SQX_TOPOLOGY(l4top.s.parent));
-		CVMX_MT_CRC_DWORD(l3top.u64);
+		dqsch.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_SCHEDULE(queue));
+		CVMX_MT_CRC_DWORD(dqsch.u64);
+
+		/* L5-L3 Queue Levels: */
+		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) { 
+			l5top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L5_SQX_TOPOLOGY(dqtop.s.parent));
+			CVMX_MT_CRC_DWORD(l5top.u64);
+			l4top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L4_SQX_TOPOLOGY(l5top.s.parent));
+			CVMX_MT_CRC_DWORD(l4top.u64);
+			l3top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_SQX_TOPOLOGY(l4top.s.parent));
+			CVMX_MT_CRC_DWORD(l3top.u64);
+
+			l5sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L5_SQX_SCHEDULE(dqtop.s.parent));
+			CVMX_MT_CRC_DWORD(l5sch.u64);
+			l4sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L4_SQX_SCHEDULE(l5top.s.parent));
+			CVMX_MT_CRC_DWORD(l4sch.u64);
+			l3sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_SQX_SCHEDULE(l4top.s.parent));
+			CVMX_MT_CRC_DWORD(l3sch.u64);
+		}
+		else {
+			l5top.u64 = l4top.u64 = 0;
+			l3top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_SQX_TOPOLOGY(dqtop.s.parent));
+			CVMX_MT_CRC_DWORD(l3top.u64);
+
+			l5sch.u64 = l4sch.u64 = 0;
+			l3sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_SQX_SCHEDULE(dqtop.s.parent));
+			CVMX_MT_CRC_DWORD(l3sch.u64);
+		}
+		/* L2-L1 Queue Levels: */
 		l2top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L2_SQX_TOPOLOGY(l3top.s.parent));
 		CVMX_MT_CRC_DWORD(l2top.u64);
 		l1top.u64 = cvmx_read_csr_node(node, CVMX_PKO_L1_SQX_TOPOLOGY(l2top.s.parent));
 		CVMX_MT_CRC_DWORD(l1top.u64);
-		maccfg.u64 = cvmx_read_csr_node(node, CVMX_PKO_MACX_CFG(l1top.s.link));
+
+		l2sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L2_SQX_SCHEDULE(l3top.s.parent));
+		CVMX_MT_CRC_DWORD(l2sch.u64);
+		l1sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L1_SQX_SCHEDULE(l2top.s.parent));
+		CVMX_MT_CRC_DWORD(l1sch.u64);
+
+		/* MAC/FIFO Level: */
+		if (l1top.s.link > nmacs) {
+			maccfg.u64 = 0;
+			sprintf(lines[0], "Undef");
+		}
+		else if (l1top.s.link == nmacs) {
+			maccfg.u64 = 0;
+			sprintf(lines[0], "NULL");
+		}
+		else {
+			maccfg.u64 = cvmx_read_csr_node(node, CVMX_PKO_MACX_CFG(l1top.s.link));
+			if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+				sprintf(lines[0], "%s", pko_macmap[l1top.s.link][0]);
+			else if (OCTEON_IS_MODEL(OCTEON_CN73XX))
+				sprintf(lines[0], "%s", pko_macmap[l1top.s.link][1]);
+			else if (OCTEON_IS_MODEL(OCTEON_CNF75XX))
+				sprintf(lines[0], "%s", pko_macmap[l1top.s.link][2]);
+		}
+		sprintf(lines[1], "%d", maccfg.s.fifo_num);
 		CVMX_MT_CRC_DWORD(maccfg.u64);
-		if (chlvl.s.cc_level == 0) { /* Level 2 as the Channel Level*/
-			chcfg.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_L2_SQX_CHANNEL(l3top.s.parent));
-			sprintf(lines[0], "%s", "--");
-			sprintf(lines[1], "%d", chcfg.s.cc_channel);
+
+		if (chlvl.s.cc_level == 0) { /* Level 2 as the Channel Level?*/
+			chcfg.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_L2_SQX_CHANNEL(l2top.s.parent));
+			sprintf(lines[2], "%s", "--");
+			sprintf(lines[3], "%d", chcfg.s.cc_channel);
 		}
 		else {
-			chcfg.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_L2_SQX_CHANNEL(l4top.s.parent));
-			sprintf(lines[0], "%d", chcfg.s.cc_channel);
-			sprintf(lines[1], "%s", "--");
+			chcfg.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_L2_SQX_CHANNEL(l3top.s.parent));
+			sprintf(lines[2], "%d", chcfg.s.cc_channel);
+			sprintf(lines[3], "%s", "--");
 		}
 		CVMX_MT_CRC_DWORD(chcfg.u64);
-		dqsch.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_SCHEDULE(queue));
-		CVMX_MT_CRC_DWORD(dqsch.u64);
-		l5sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L5_SQX_SCHEDULE(dqtop.s.parent));
-		CVMX_MT_CRC_DWORD(l5sch.u64);
-		l4sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L4_SQX_SCHEDULE(l5top.s.parent));
-		CVMX_MT_CRC_DWORD(l4sch.u64);
-		l3sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L3_SQX_SCHEDULE(l4top.s.parent));
-		CVMX_MT_CRC_DWORD(l3sch.u64);
-		l2sch.u64 = cvmx_read_csr_node(node, CVMX_PKO_L2_SQX_SCHEDULE(l3top.s.parent));
-		CVMX_MT_CRC_DWORD(l2sch.u64);
 		CVMX_MF_CRC_IV(crc32);
 		if (crc32 == pcrc32)
 			continue;
+
+		/* Display DQ...FIFO Queue-Chain configuration: */
 		if (queue > 0 && (queue - 1) != base)
-			cvmx_printf("\nDQUEUE(s) %02d-%02d -- same as DQUEUE %02d\n",
+			cvmx_printf("\nDQ(s) %02d-%02d -- same as DQ %02d\n",
 				queue - 1, base + 1, base);
 		pcrc32 = crc32;
 		base = queue;
 		cvmx_printf("DQ%d:\n", queue);
-		PARPRINT("Path", "%*s%*d%*d%*d%*d%*d%*d%*d\n",
-			PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), dqtop.s.parent,
-			PKO_PRN_DPLEN(8), l5top.s.parent, PKO_PRN_DPLEN(8), l4top.s.parent,
-			PKO_PRN_DPLEN(8), l3top.s.parent, PKO_PRN_DPLEN(8), l2top.s.parent,
-			PKO_PRN_DPLEN(8), l1top.s.link, PKO_PRN_DPLEN(8), maccfg.s.fifo_num);
-		PARPRINT("Prio", "%*d%*d%*d%*d%*d%*s%*s%*s\n",
-			PKO_PRN_DPLEN(8), dqsch.s.prio, PKO_PRN_DPLEN(8), l5sch.s.prio,
-			PKO_PRN_DPLEN(8), l4sch.s.prio, PKO_PRN_DPLEN(8), l3sch.s.prio,
-			PKO_PRN_DPLEN(8), l2sch.s.prio, PKO_PRN_DPLEN(8), "--",
-			PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
-		PARPRINT("RR-Prio", "%*s%*d%*d%*d%*d%*d%*s%*s\n",
-			PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), l5top.s.rr_prio,
-			PKO_PRN_DPLEN(8), l4top.s.rr_prio, PKO_PRN_DPLEN(8), l3top.s.rr_prio,
-			PKO_PRN_DPLEN(8), l2top.s.rr_prio, PKO_PRN_DPLEN(8), l1top.s.rr_prio,
-			PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
-		PARPRINT("Prio-Anchor", "%*s%*d%*d%*d%*d%*d%*s%*s\n",
-			PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), l5top.s.prio_anchor,
-			PKO_PRN_DPLEN(8), l4top.s.prio_anchor, PKO_PRN_DPLEN(8), l3top.s.prio_anchor,
-			PKO_PRN_DPLEN(8), l2top.s.prio_anchor, PKO_PRN_DPLEN(8), l1top.s.prio_anchor,
-			PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
+		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+			PARPRINT("Path", "%*s%*d%*d%*d%*d%*d%*d%*s\n",
+				PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), dqtop.s.parent,
+				PKO_PRN_DPLEN(8), l5top.s.parent, PKO_PRN_DPLEN(8), l4top.s.parent,
+				PKO_PRN_DPLEN(8), l3top.s.parent, PKO_PRN_DPLEN(8), l2top.s.parent,
+				PKO_PRN_DPLEN(8), l1top.s.link, PKO_PRN_DPLEN(8), lines[1]);
+			PARPRINT("Prio-Anchor", "%*s%*d%*d%*d%*d%*d%*s%*s\n",
+				PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), l5top.s.prio_anchor,
+				PKO_PRN_DPLEN(8), l4top.s.prio_anchor, PKO_PRN_DPLEN(8), l3top.s.prio_anchor,
+				PKO_PRN_DPLEN(8), l2top.s.prio_anchor, PKO_PRN_DPLEN(8), l1top.s.prio_anchor,
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
+			PARPRINT("Prio", "%*d%*d%*d%*d%*d%*s%*s%*s\n",
+				PKO_PRN_DPLEN(8), dqsch.s.prio, PKO_PRN_DPLEN(8), l5sch.s.prio,
+				PKO_PRN_DPLEN(8), l4sch.s.prio, PKO_PRN_DPLEN(8), l3sch.s.prio,
+				PKO_PRN_DPLEN(8), l2sch.s.prio, PKO_PRN_DPLEN(8), "--",
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
+			PARPRINT("RR-Prio", "%*s%*d%*d%*d%*d%*d%*s%*s\n",
+				PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), l5top.s.rr_prio,
+				PKO_PRN_DPLEN(8), l4top.s.rr_prio, PKO_PRN_DPLEN(8), l3top.s.rr_prio,
+				PKO_PRN_DPLEN(8), l2top.s.rr_prio, PKO_PRN_DPLEN(8), l1top.s.rr_prio,
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
+			PARPRINT("RR-Quantum", "%*x%*x%*x%*x%*x%*x%*s%*s\n",
+				PKO_PRN_DPLEN(8), dqsch.s.rr_quantum, PKO_PRN_DPLEN(8), l5sch.s.rr_quantum,
+				PKO_PRN_DPLEN(8), l4sch.s.rr_quantum, PKO_PRN_DPLEN(8), l3sch.s.rr_quantum,
+				PKO_PRN_DPLEN(8), l2sch.s.rr_quantum, PKO_PRN_DPLEN(8), l1sch.s.rr_quantum,
+				PKO_PRN_DPLEN(8), "(hex)", PKO_PRN_DPLEN(8), "");
+		}
+		else {
+			PARPRINT("Path", "%*s%*s%*s%*d%*d%*d%*d%*s\n",
+				PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), "",
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), dqtop.s.parent,
+				PKO_PRN_DPLEN(8), l3top.s.parent, PKO_PRN_DPLEN(8), l2top.s.parent,
+				PKO_PRN_DPLEN(8), l1top.s.link, PKO_PRN_DPLEN(8), lines[1]);
+			PARPRINT("Prio-Anchor", "%*s%*s%*s%*d%*d%*d%*s%*s\n",
+				PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), "",
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), l3top.s.prio_anchor,
+				PKO_PRN_DPLEN(8), l2top.s.prio_anchor, PKO_PRN_DPLEN(8), l1top.s.prio_anchor,
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
+			PARPRINT("Prio", "%*d%*s%*s%*d%*d%*s%*s%*s\n",
+				PKO_PRN_DPLEN(8), dqsch.s.prio, PKO_PRN_DPLEN(8), "",
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), l3sch.s.prio,
+				PKO_PRN_DPLEN(8), l2sch.s.prio, PKO_PRN_DPLEN(8), "--",
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
+			PARPRINT("RR-Prio", "%*s%*s%*s%*d%*d%*d%*s%*s\n",
+				PKO_PRN_DPLEN(8), "--", PKO_PRN_DPLEN(8), "",
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), l3top.s.rr_prio,
+				PKO_PRN_DPLEN(8), l2top.s.rr_prio, PKO_PRN_DPLEN(8), l1top.s.rr_prio,
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "");
+			PARPRINT("RR-Quantum", "%*x%*s%*s%*x%*x%*x%*s%*s\n",
+				PKO_PRN_DPLEN(8), dqsch.s.rr_quantum, PKO_PRN_DPLEN(8), "",
+				PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), l3sch.s.rr_quantum,
+				PKO_PRN_DPLEN(8), l2sch.s.rr_quantum, PKO_PRN_DPLEN(8), l1sch.s.rr_quantum,
+				PKO_PRN_DPLEN(8), "(hex)", PKO_PRN_DPLEN(8), "");
+		}
 		PARPRINT("Channel", "%*s%*s%*s%*s%*s%*s(%s)\n",
 			PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "", PKO_PRN_DPLEN(8), "",
-			PKO_PRN_DPLEN(8), lines[0], PKO_PRN_DPLEN(8), lines[1],
-			PKO_PRN_DPLEN(21), "", pko_macmap[l1top.s.link]);
+			PKO_PRN_DPLEN(8), lines[2], PKO_PRN_DPLEN(8), lines[3],
+			PKO_PRN_DPLEN(21), "", lines[0]);
 	}
 	if ((queue - 1) != base)
-		cvmx_printf("\nDQUEUE(s) %02d-%02d -- same as DQUEUE %02d\n",
+		cvmx_printf("\nDQ(s) %02d-%02d -- same as DQ %02d\n",
 			queue - 1, base + 1, base);
 
+	/* Display FIFO Groups: */
 	DLMPRINT("FIFO Groups:");
 	cvmx_printf("Group: (FIFOs)\n");
-	for (group = 0, pcrc32 = 0, base = 0; group < 7; group++) {
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		ngroups = 7;
+	else
+		ngroups = 4;
+	for (group = 0, pcrc32 = 0, base = 0; group < ngroups; group++) {
 		cvmx_pko_ptgfx_cfg_t fgcfg;
 		CVMX_MT_CRC_POLYNOMIAL(0x1edc6f41);
 		CVMX_MT_CRC_IV(0xffffffff);
@@ -1585,5 +1654,84 @@ int cvmx_helper_pko3_config_dump(unsigned int node)
 			group - 1, base + 1, base);
 	return 0;
 }
+
+#undef PKO_PRN_HEADLEN
+#define PKO_PRN_HEADLEN  36 
+#undef PKO_PRN_DATALEN
+#define PKO_PRN_DATALEN  44
+int cvmx_helper_pko3_stats_dump(unsigned int node)
+{
+	int queue, nqueues, n;
+	cvmx_pko_dqx_packets_t dq_pkts;
+	cvmx_pko_dqx_bytes_t dq_bytes;
+	cvmx_pko_dqx_dropped_packets_t dq_drppkts;
+	cvmx_pko_dqx_dropped_bytes_t dq_drpbytes;
+	cvmx_pko_l1_sqx_dropped_packets_t l1_drppkts;
+	cvmx_pko_l1_sqx_dropped_bytes_t l1_drpbytes;
+	cvmx_pko_l1_sqx_red_packets_t l1_redpkts;
+	cvmx_pko_l1_sqx_red_bytes_t l1_redbytes;
+	cvmx_pko_l1_sqx_yellow_packets_t l1_yelpkts;
+	cvmx_pko_l1_sqx_yellow_bytes_t l1_yelbytes;
+	cvmx_pko_l1_sqx_green_packets_t l1_grnpkts;
+	cvmx_pko_l1_sqx_green_bytes_t l1_grnbytes;
+	char lines[4][256];
+
+	memset(lines[3], '*', PKO_PRN_LINELEN);  lines[3][PKO_PRN_LINELEN] = '\0';
+	cvmx_printf("\n%s\n", lines[3]);
+	cvmx_printf("   PKO Statistics (Node %d)\n", node);
+	cvmx_printf("%s\n", lines[3]);
+	DLMPRINT("Descriptor Queues:");
+	nqueues = cvmx_pko3_num_level_queues(CVMX_PKO_DESCR_QUEUES);
+	for (queue = 0; queue < nqueues; queue++) {
+		dq_pkts.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_PACKETS(queue));
+		dq_bytes.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_BYTES(queue));
+		dq_drppkts.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_DROPPED_PACKETS(queue));
+		dq_drpbytes.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_DROPPED_BYTES(queue));
+		n = dq_pkts.s.count + dq_bytes.s.count + dq_drppkts.s.count + dq_drpbytes.s.count;
+		if (n == 0)
+			continue;
+		cvmx_printf("DQ%d:\n", queue);
+		if (dq_pkts.s.count)
+			PARPRINT("Packets", "%*lld\n", PKO_PRN_DPLEN(1), (long long)dq_pkts.s.count);
+		if (dq_bytes.s.count)
+			PARPRINT("Bytes", "%*lld\n", PKO_PRN_DPLEN(1), (long long)dq_bytes.s.count);
+		if (dq_drppkts.s.count)
+			PARPRINT("Dropped Packets", "%*lld\n", PKO_PRN_DPLEN(1), (long long)dq_drppkts.s.count);
+		if (dq_drpbytes.s.count)
+			PARPRINT("Dropped Bytes", "%*lld\n", PKO_PRN_DPLEN(1), (long long)dq_drpbytes.s.count);
+	}
+	DLMPRINT("Port(L1) Queues:");
+	nqueues = cvmx_pko3_num_level_queues(CVMX_PKO_PORT_QUEUES);
+	for (queue = 0; queue < nqueues; queue++) {
+		l1_grnpkts.u64 = cvmx_read_csr_node(node, CVMX_PKO_L1_SQX_GREEN_PACKETS(queue));
+		l1_grnbytes.u64 = cvmx_read_csr_node(node, CVMX_PKO_L1_SQX_GREEN_BYTES(queue));
+		l1_yelpkts.u64 = cvmx_read_csr_node(node, CVMX_PKO_L1_SQX_YELLOW_PACKETS(queue));
+		l1_yelbytes.u64 = cvmx_read_csr_node(node, CVMX_PKO_L1_SQX_YELLOW_BYTES(queue));
+		l1_redpkts.u64 = cvmx_read_csr_node(node, CVMX_PKO_L1_SQX_RED_PACKETS(queue));
+		l1_redbytes.u64 = cvmx_read_csr_node(node, CVMX_PKO_L1_SQX_RED_BYTES(queue));
+		n = l1_grnpkts.s.count + l1_grnbytes.s.count + l1_yelpkts.s.count + l1_yelbytes.s.count +
+			l1_redpkts.s.count + l1_redbytes.s.count + l1_drppkts.s.count + l1_drpbytes.s.count;
+		if (n == 0)
+			continue;
+		cvmx_printf("L1-SQ%d:\n", queue);
+		if (l1_grnpkts.s.count)
+			PARPRINT("Green Packets", "%*lld\n", PKO_PRN_DPLEN(1), (long long)l1_grnpkts.s.count);
+		if (l1_grnbytes.s.count)
+			PARPRINT("Green Bytes", "%*lld\n", PKO_PRN_DPLEN(1), (long long)l1_grnbytes.s.count);
+		if (l1_yelpkts.s.count)
+			PARPRINT("Yellow Packets", "%*lld\n", PKO_PRN_DPLEN(1), (long long)l1_yelpkts.s.count);
+		if (l1_yelbytes.s.count)
+			PARPRINT("Yellow Bytes", "%*lld\n", PKO_PRN_DPLEN(1), (long long)l1_yelbytes.s.count);
+		if (l1_redpkts.s.count)
+			PARPRINT("Red Packets", "%*lld\n", PKO_PRN_DPLEN(1), (long long)l1_redpkts.s.count);
+		if (l1_redbytes.s.count)
+			PARPRINT("Red Bytes", "%*lld\n", PKO_PRN_DPLEN(1), (long long)l1_redbytes.s.count);
+		if (l1_drppkts.s.count)
+			PARPRINT("Dropped Packets", "%*lld\n", PKO_PRN_DPLEN(1), (long long)l1_drppkts.s.count);
+		if (l1_drpbytes.s.count)
+			PARPRINT("Dropped Bytes", "%*lld\n", PKO_PRN_DPLEN(1), (long long)l1_drpbytes.s.count);
+	}
+	return 0;
+}
 #endif /* CVMX_DUMP_PKO */
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c b/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
index 2399713..9983850 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
@@ -71,8 +71,12 @@ static const int debug = 0;
  * @INTERNAL
  * Convert interface number to sRIO link number
  * per SoC model.
+ *
+ * @param xiface Interface to convert
+ *
+ * @return Srio link number
  */
-static int __cvmx_helper_srio_port(int xiface)
+int __cvmx_helper_srio_port(int xiface)
 {
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int  srio_port = -1;
@@ -84,15 +88,17 @@ static int __cvmx_helper_srio_port(int xiface)
 		return -1;
 
 	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
-		srio_port = xi.interface - 2;
-		if (srio_port > 1) srio_port = -1;
+		srio_port = xi.interface - 1;
+		if (srio_port > 1)
+			srio_port = -1;
 	} else if (OCTEON_IS_MODEL(OCTEON_CN66XX)) {
 		srio_port = xi.interface - 4;
 		if (srio_port > 3 || srio_port == 1)
 			srio_port = -1;
 	} else {
 		srio_port = xi.interface - 4;
-		if (srio_port > 1) srio_port = -1;
+		if (srio_port > 1)
+			srio_port = -1;
 	}
 
 	return srio_port;
@@ -235,7 +241,7 @@ int __cvmx_helper_srio_enable(int xiface)
 			fcs = __cvmx_helper_get_has_fcs(xiface);
 
 			/* Initialize sRIO INST_HDR_S registers */
-			// FIXMEL Move this code to cvmx-srio.c !!
+			// FIXME Move this code to cvmx-srio.c !!
 			if (use_inst_hdr)
 			    for(i = 0; i < 256 && index == 0; i++) {
 				cvmx_sriox_imsg_inst_hdrx_t inst_hdr;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
index ecd3041..68d9bc0 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
@@ -170,10 +170,9 @@ static const struct ipd_port_map ipd_port_map_78xx[CVMX_HELPER_MAX_IFACE] = {
 static const struct ipd_port_map ipd_port_map_73xx[CVMX_HELPER_MAX_IFACE] = {
 	{GMII,	0x800,	0x83f,	0x00},		/* Interface 0 - BGX(0,0-3) */
 	{GMII,	0x900,	0x93f,	0x00},		/* Interface 1  -BGX(1,0-3) */
-	{GMII,	0xa00,	0xa1f,	0x00},		/* Interface 2  -BGX(2,0-1) */
-	{GMII,	0xa20,	0xa3f,	0x00},		/* Interface 3  -BGX(2,2-3) */
-	{NPI,	0x100,	0x13f,	0x00},		/* Interface 6 - DPI */
-	{LB,	0x000,	0x03f,	0x00},		/* Interface 7 - LOOPBACK */
+	{GMII,	0xa00,	0xa3f,	0x00},		/* Interface 2  -BGX(2,0-3) */
+	{NPI,	0x100,	0x13f,	0x00},		/* Interface 3 - DPI */
+	{LB,	0x000,	0x03f,	0x00},		/* Interface 4 - LOOPBACK */
 };
 
 /**
@@ -181,12 +180,11 @@ static const struct ipd_port_map ipd_port_map_73xx[CVMX_HELPER_MAX_IFACE] = {
  * Interface number to ipd port map for the octeon 75xx.
  */
 static const struct ipd_port_map ipd_port_map_75xx[CVMX_HELPER_MAX_IFACE] = {
-	{GMII,	0x800,	0x81f,	0x00},		/* Interface 0 - BGX0,0-1 */
-	{GMII,	0x820,	0x83f,	0x00},		/* Interface 1 - BGX0,2-3 */
-	{SRIO,	0x240,	0x241,	0x00},		/* Interface 2 - SRIO 0 */
-	{SRIO,	0x242,	0x243,	0x00},		/* Interface 3 - SRIO 1 */
-	{NPI,	0x100,	0x13f,	0x00},		/* Interface 4 - DPI */
-	{LB,	0x000,	0x03f,	0x00},		/* Interface 5 - LOOPBACK */
+	{GMII,	0x800,	0x83f,	0x00},		/* Interface 0 - BGX0 */
+	{SRIO,	0x240,	0x241,	0x00},		/* Interface 1 - SRIO 0 */
+	{SRIO,	0x242,	0x243,	0x00},		/* Interface 2 - SRIO 1 */
+	{NPI,	0x100,	0x13f,	0x00},		/* Interface 3 - DPI */
+	{LB,	0x000,	0x03f,	0x00},		/* Interface 4 - LOOPBACK */
 };
 
 
@@ -251,6 +249,8 @@ const char *cvmx_helper_interface_mode_to_string(cvmx_helper_interface_mode_t mo
 		return "40G_KR4";
 	case CVMX_HELPER_INTERFACE_MODE_10G_KR:
 		return "10G_KR";
+	case CVMX_HELPER_INTERFACE_MODE_MIXED:
+		return "MIXED";
 	}
 	return "UNKNOWN";
 }
@@ -1223,7 +1223,7 @@ int cvmx_helper_get_interface_index_num(int ipd_port)
 				port -= port_map[i].ipd_port_adj;
 
 			port >>= 4;
-/*	cvmx_dprintf("%s: ipd_port=%#x port=%d\n", __func__, ipd_port, port); */
+			/* cvmx_dprintf("%s: ipd_port=%#x port=%d,%d\n", __func__, ipd_port, port,i); */
 			return port;
 
 		/*
@@ -1236,7 +1236,7 @@ int cvmx_helper_get_interface_index_num(int ipd_port)
 		case NPI:
 		case LB:
 			port = ipd_port - port_map[i].first_ipd_port;
-/*	cvmx_dprintf("%s: ipd_port=%#x port=%d\n", __func__, ipd_port, port); */
+		        /* cvmx_dprintf("%s: ipd_port=%#x port=%d, i = %d\n", __func__, ipd_port, port,i); */
 			return port;
 
 		default:
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper.c b/arch/mips/cavium-octeon/executive/cvmx-helper.c
index 1a785e9..9213adf 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper.c
@@ -423,6 +423,21 @@ static const struct iface_ops iface_ops_spi = {
 /**
  * @INTERNAL
  * This structure specifies the interface methods used by interfaces
+ * configured as mixed mode, some ports are sgmii and some are xfi.
+ */
+static const struct iface_ops iface_ops_bgx_mixed = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_MIXED,
+	.enumerate	= __cvmx_helper_bgx_enumerate,
+	.probe		= __cvmx_helper_bgx_probe,
+	.enable		= __cvmx_helper_bgx_mixed_enable,
+	.link_get	= __cvmx_helper_bgx_mixed_link_get,
+	.link_set	= __cvmx_helper_bgx_mixed_link_set,
+	.loopback	= __cvmx_helper_bgx_mixed_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
  * configured as loop.
  */
 static const struct iface_ops iface_ops_loop = {
@@ -686,9 +701,9 @@ int cvmx_helper_get_number_of_interfaces(void)
 	else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 		return 10;
 	else if (OCTEON_IS_MODEL(OCTEON_CNF75XX))
-		return 6;
+		return 5;
 	else if (OCTEON_IS_MODEL(OCTEON_CN73XX))
-		return 6;
+		return 5;
 	else
 		return 3;
 }
@@ -919,7 +934,7 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn73xx(int xiface)
 	int interface = xi.interface;
 
 	/* SGMII/XAUI/XLAUI/XFI */
-	if (interface < 4) {
+	if (interface < 3) {
 		int qlm = cvmx_qlm_interface(xiface);
 		enum cvmx_qlm_mode qlm_mode;
 
@@ -931,7 +946,9 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn73xx(int xiface)
 
 		switch (qlm_mode) {
 		case CVMX_QLM_MODE_SGMII:
+		case CVMX_QLM_MODE_SGMII_1X2:
 		case CVMX_QLM_MODE_RGMII_SGMII:
+		case CVMX_QLM_MODE_RGMII_SGMII_1X1:
 			iface_ops[interface] = &iface_ops_bgx_sgmii;
 			break;
 		case CVMX_QLM_MODE_XAUI:
@@ -939,6 +956,7 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn73xx(int xiface)
 			iface_ops[interface] = &iface_ops_bgx_xaui;
 			break;
 		case CVMX_QLM_MODE_RXAUI:
+		case CVMX_QLM_MODE_RXAUI_1X2:
 		case CVMX_QLM_MODE_RGMII_RXAUI:
 			iface_ops[interface] = &iface_ops_bgx_rxaui;
 			break;
@@ -947,10 +965,12 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn73xx(int xiface)
 			iface_ops[interface] = &iface_ops_bgx_xlaui;
 			break;
 		case CVMX_QLM_MODE_XFI:
+		case CVMX_QLM_MODE_XFI_1X2:
 		case CVMX_QLM_MODE_RGMII_XFI:
 			iface_ops[interface] = &iface_ops_bgx_xfi;
 			break;
 		case CVMX_QLM_MODE_10G_KR:
+		case CVMX_QLM_MODE_10G_KR_1X2:
 		case CVMX_QLM_MODE_RGMII_10G_KR:
 			iface_ops[interface] = &iface_ops_bgx_10G_KR;
 			break;
@@ -958,13 +978,16 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn73xx(int xiface)
 		case CVMX_QLM_MODE_RGMII_40G_KR4:
 			iface_ops[interface] = &iface_ops_bgx_40G_KR4;
 			break;
+		case CVMX_QLM_MODE_MIXED:
+			iface_ops[interface] = &iface_ops_bgx_mixed;
+			break;
 		default:
 			iface_ops[interface] = &iface_ops_dis;
 			break;
 		}
-	} else if (interface == 4) /* DPI */
+	} else if (interface == 3) /* DPI */
 		iface_ops[interface] = &iface_ops_npi;
-	else if (interface == 5) /* LOOP */
+	else if (interface == 4) /* LOOP */
 		iface_ops[interface] = &iface_ops_loop;
 	else
 		iface_ops[interface] = &iface_ops_dis;
@@ -982,42 +1005,43 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn73xx(int xiface)
  * GSER5 supports 1G/10G single late modes, i.e. SGMII, XFI, 10G-KR.
  * Each half-BGX is thus designated as a separate interface with two ports each.
  */
-static cvmx_helper_interface_mode_t __cvmx_get_mode_cn75xx(int xiface)
+static cvmx_helper_interface_mode_t __cvmx_get_mode_cnf75xx(int xiface)
 {
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
 
-	/* BGX0: SGMII/XFI */
-	if (interface < 2) {
-		// int qlm = cvmx_qlm_interface(interface);
+	/* BGX0: SGMII (DLM4/DLM5)/XFI(DLM5)  */
+	if (interface < 1) {
 		enum cvmx_qlm_mode qlm_mode;
+		int qlm = cvmx_qlm_interface(interface);
 
-		if (interface == 0) {
-			qlm_mode =  CVMX_QLM_MODE_SGMII;
-		} else {
-			qlm_mode = CVMX_QLM_MODE_XFI;
+		if (qlm == -1) {
+			iface_ops[interface] = &iface_ops_dis;
+			return iface_ops[interface]->mode;
 		}
-
-		// FIXME: DLM3 could be either SGMII or XFI mode
-		// should detect dynamically from GSER5 configuration
+		qlm_mode = cvmx_qlm_get_mode(qlm);
 
 		switch (qlm_mode) {
 		case CVMX_QLM_MODE_SGMII:
+		case CVMX_QLM_MODE_SGMII_1X2:
 			iface_ops[interface] = &iface_ops_bgx_sgmii;
 			break;
-		case CVMX_QLM_MODE_XFI:
+		case CVMX_QLM_MODE_XFI_1X2:
 			iface_ops[interface] = &iface_ops_bgx_xfi;
 			break;
-		case CVMX_QLM_MODE_10G_KR:
+		case CVMX_QLM_MODE_10G_KR_1X2:
 			iface_ops[interface] = &iface_ops_bgx_10G_KR;
 			break;
+		case CVMX_QLM_MODE_MIXED:
+			iface_ops[interface] = &iface_ops_bgx_mixed;
+			break;
 		default:
 			iface_ops[interface] = &iface_ops_dis;
 			break;
 		}
-	} else if (interface < 4) {
-		union cvmx_sriox_status_reg sriox_status_reg;
-		int srio_port = interface - 2;
+	} else if (interface < 3) {
+		cvmx_sriox_status_reg_t sriox_status_reg;
+		int srio_port = interface - 1;
 		sriox_status_reg.u64 =
 			cvmx_read_csr(CVMX_SRIOX_STATUS_REG(srio_port));
 
@@ -1025,9 +1049,9 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn75xx(int xiface)
 			iface_ops[interface] = &iface_ops_srio;
 		else
 			iface_ops[interface] = &iface_ops_dis;
-	} else if (interface == 4) /* DPI */
+	} else if (interface == 3) /* DPI */
 		iface_ops[interface] = &iface_ops_npi;
-	else if (interface == 5) /* LOOP */
+	else if (interface == 4) /* LOOP */
 		iface_ops[interface] = &iface_ops_loop;
 	else
 		iface_ops[interface] = &iface_ops_dis;
@@ -1290,7 +1314,7 @@ cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int xiface)
 
 	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
 		cvmx_helper_interface_mode_t mode;
-		mode = __cvmx_get_mode_cn75xx(xiface);
+		mode = __cvmx_get_mode_cnf75xx(xiface);
 		return mode;
 	}
 
@@ -1450,6 +1474,7 @@ int cvmx_helper_interface_probe(int xiface)
 	case CVMX_HELPER_INTERFACE_MODE_XFI:
 	case CVMX_HELPER_INTERFACE_MODE_10G_KR:
 	case CVMX_HELPER_INTERFACE_MODE_40G_KR4:
+	case CVMX_HELPER_INTERFACE_MODE_MIXED:
 		has_fcs = 1;
 		padding = CVMX_PKO_PADDING_60;
 		break;
@@ -1549,6 +1574,7 @@ static int __cvmx_helper_global_setup_backpressure(int node)
 			case CVMX_HELPER_INTERFACE_MODE_SGMII:
 			case CVMX_HELPER_INTERFACE_MODE_QSGMII:
 			case CVMX_HELPER_INTERFACE_MODE_PICMG:
+			case CVMX_HELPER_INTERFACE_MODE_MIXED:
 				if (octeon_has_feature(OCTEON_FEATURE_BGX))
 					cvmx_bgx_set_backpressure_override(xiface, 0xf);
 				else
@@ -1998,11 +2024,14 @@ int cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
 		int index;
 		int num_ports = cvmx_helper_ports_on_interface(xiface);
 
+		if (num_ports > 4)
+			num_ports = 4;
+
+		cvmx_bgx_set_backpressure_override(xiface, (1<<num_ports)-1);
 		for (index = 0; index < num_ports; index++) {
 			if (!cvmx_helper_is_port_valid(xiface, index))
 				continue;
 
-			cvmx_bgx_set_backpressure_override(xiface, 1 << index);
 			cvmx_helper_bgx_shutdown_port(xiface, index);
 		}
 	}
@@ -2044,6 +2073,7 @@ int cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
 		case CVMX_HELPER_INTERFACE_MODE_10G_KR:
 		case CVMX_HELPER_INTERFACE_MODE_40G_KR4:
 		case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		case CVMX_HELPER_INTERFACE_MODE_MIXED:
 		{
 			int index;
 			int num_ports = cvmx_helper_ports_on_interface(xiface);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
index 0e3819e..7e2952c 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
@@ -321,6 +321,21 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 	cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 
+	/* For 10.3125Gbs data rate, set SER_LIMIT to 0x3ff for x8 & x12 mode */
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		cvmx_gserx_lane_mode_t lmode0, lmode1;
+		lmode0.u64 = cvmx_read_csr_node(node, CVMX_GSERX_LANE_MODE(5));
+		lmode1.u64 = cvmx_read_csr_node(node, CVMX_GSERX_LANE_MODE(7));
+		if ((lmode0.s.lmode == 5 || lmode1.s.lmode == 5)
+		     && (lane_mask == 0xfff || lane_mask == 0xfff0
+			 || lane_mask == 0xff || lane_mask == 0xff00)) {
+			cvmx_ilk_txx_cfg1_t ilk_txx_cfg1;
+			ilk_txx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG1(interface));
+			ilk_txx_cfg1.s.ser_limit = 0x3ff;
+			cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG1(interface), ilk_txx_cfg1.u64);
+		}
+	}
+
 	/* write to local cache. for lane speed, if interface 0 has 8 lanes,
 	 * assume both qlms have the same speed */
 	cvmx_ilk_intf_cfg[node][interface].intf_en = 1;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ipd.c b/arch/mips/cavium-octeon/executive/cvmx-ipd.c
index aa44130..a9f0cfb 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ipd.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ipd.c
@@ -50,7 +50,6 @@
 #include <asm/octeon/cvmx-pip-defs.h>
 #include <asm/octeon/cvmx-dbg-defs.h>
 #include <asm/octeon/cvmx-sso-defs.h>
-
 #include <asm/octeon/cvmx-fpa1.h>
 #include <asm/octeon/cvmx-wqe.h>
 #include <asm/octeon/cvmx-ipd.h>
@@ -129,8 +128,6 @@ void cvmx_ipd_convert_to_newcfg(cvmx_ipd_config_t ipd_config)
 					 ipd_config.packet_pool.pool_num, ipd_config.packet_pool.buffer_count);
 }
 
-
-
 int cvmx_ipd_set_config(cvmx_ipd_config_t ipd_config)
 {
 	cvmx_ipd_cfg = ipd_config;
@@ -152,15 +149,14 @@ void cvmx_ipd_set_packet_pool_buffer_count(uint64_t buffer_count)
 void cvmx_ipd_set_packet_pool_config(int64_t pool, uint64_t buffer_size,
 				     uint64_t buffer_count)
 {
+	cvmx_ipd_cfg.packet_pool.pool_num = pool;
+	cvmx_ipd_cfg.packet_pool.buffer_size = buffer_size;
+	cvmx_ipd_cfg.packet_pool.buffer_count = buffer_count;
 	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
 		int node = cvmx_get_node_num();
 		int64_t aura = pool;
 		cvmx_helper_pki_set_dflt_pool(node, pool, buffer_size, buffer_count);
 		cvmx_helper_pki_set_dflt_aura(node, aura, pool, buffer_count);
-	} else {
-		cvmx_ipd_cfg.packet_pool.pool_num = pool;
-		cvmx_ipd_cfg.packet_pool.buffer_size = buffer_size;
-		cvmx_ipd_cfg.packet_pool.buffer_count = buffer_count;
 	}
 }
 EXPORT_SYMBOL(cvmx_ipd_set_packet_pool_config);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pcie.c b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
index 30dc8fe..ee3fee3 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pcie.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 115911 $<hr>
+ * <hr>$Revision: 118139 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -2316,7 +2316,7 @@ int cvmx_pcie_is_host_mode(int pcie_port)
 	    || OCTEON_IS_MODEL(OCTEON_CN73XX)) {
 		cvmx_pemx_strap_t strap;
 		strap.u64 = CVMX_READ_CSR(CVMX_PEMX_STRAP(pcie_port));
-		return (strap.cn78xx.pimode != 3);
+		return (strap.cn78xx.pimode == 3);
 	} else if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
 		cvmx_rst_ctlx_t rst_ctl;
 		rst_ctl.u64 = cvmx_read_csr(CVMX_RST_CTLX(pcie_port));
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki.c b/arch/mips/cavium-octeon/executive/cvmx-pki.c
index f077970..2e0a20a 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki.c
@@ -1180,11 +1180,28 @@ int cvmx_pki_config_dump(unsigned node)
 		cvmx_printf("%*s%-*s%*s\n", offs, "", PKI_PRN_HEADLEN - offs, name, PKI_PRN_DATALEN, dbuf);
 		va_end(args);
 	}
-	void int2bitstr(char *buf, int data, int nbits) {
+	void int2cstr(char *buf, int data, int nbits) {
+		char *lbits[8] = {"G","F", "E", "D", "C", "B", "?", "?"};
 		buf[0] = '\0';
 		for (nbits--; nbits >= 0; nbits--, data >>= 1)
-			strcat(buf, (data & 1) ? "1" : "0");
+			strcat(buf, (data & 1) ? lbits[nbits & 0x7] : "-");
 	}
+	char *qpgqos_map[8] = {
+		[0x0] = "NONE",
+		[0x1] = "VLAN",
+		[0x2] = "MPLS",
+		[0x3] = "DSA_SRC",
+		[0x4] = "DIFF",
+		[0x5] = "HIGIG",
+		[0x6] = "Undef",
+		[0x7] = "Undef"
+	};
+	char *tagtype_map[4] = {
+		[0x0] = "Ordered",
+		[0x1] = "Atomic",
+		[0x2] = "Untagged",
+		[0x3] = "Empty"
+	};
 	int nclusters = CVMX_PKI_NUM_CLUSTER;
 	cvmx_pki_tag_secret_t secret;
 	cvmx_pki_buf_ctl_t ctl;
@@ -1205,20 +1222,18 @@ int cvmx_pki_config_dump(unsigned node)
 	cvmx_printf("\n%s\n", lines[0]);
 	cvmx_printf("   PKI Configuration (Node %d)\n", node);
 	cvmx_printf("%s\n", lines[0]);
-	DLMPRINT("Global Parameters:");
 	printfl(0, "PKI Enabled/Active", "%d/%d", ctl.s.pki_en, rst.s.active);
 	printfl(0, "Packet buffering", "%*s", PKI_PRN_DATALEN, ctl.s.pkt_off ? "Disabled" : "Enabled");
-	printfl(0, "FPA buffer policy", "%*s", PKI_PRN_DATALEN, ctl.s.fpa_wait ? "Wait" : "Drop packet");
+	printfl(0, "FPA buffer policy", "%*s", PKI_PRN_DATALEN, ctl.s.fpa_wait ? "Wait" : "Drop");
 	printfl(0, "BPID backpressure", "%*s", PKI_PRN_DATALEN, ctl.s.pbp_en ? "Enabled" : "Disabled");
-	printfl(0, "Tag secret words (hex)", "%*s%*s%*s%*s",
-		PKI_PRN_DPLEN(4), "DST6", PKI_PRN_DPLEN(4), "SRC6",
+	printfl(0, "", "%*s%*s%*s%*s", PKI_PRN_DPLEN(4), "DST6", PKI_PRN_DPLEN(4), "SRC6",
 		PKI_PRN_DPLEN(4), "DST", PKI_PRN_DPLEN(4), "SRC");
-	printfl(0, "", "%*x%*x%*x%*x", PKI_PRN_DPLEN(4), secret.s.dst6,
+	printfl(0, "Tag secret words (hex)", "%*x%*x%*x%*x", PKI_PRN_DPLEN(4), secret.s.dst6,
 		PKI_PRN_DPLEN(4), secret.s.src6, PKI_PRN_DPLEN(4), secret.s.dst,
 		PKI_PRN_DPLEN(4), secret.s.src);
-	cvmx_printf("%-30s %4s %4s %4s %4s %4s %4s %4s %4s %4s %4s\n", "Parser:",
+	cvmx_printf("%-30s %4s %4s %4s %4s %4s %4s %4s %4s %4s %4s\n", "",
 		"VIRT", "CLG", "CL2", "L4", "IL3", "L3", "MPLS", "FULC", "DSA", "HG");
-	cvmx_printf("%30s %4d %4d %4d %4d %4d %4d %4d %4d %4d %4d\n", "",
+	cvmx_printf("%-30s %4d %4d %4d %4d %4d %4d %4d %4d %4d %4d\n", "Parsing enabled",
 		pen.s.virt_pen, pen.s.clg_pen, pen.s.cl2_pen, pen.s.l4_pen, pen.s.il3_pen,
 		pen.s.l3_pen, pen.s.mpls_pen, pen.s.fulc_pen, pen.s.dsa_pen, pen.s.hg_pen);
 	/* Show PKINDs.*/
@@ -1227,8 +1242,8 @@ int cvmx_pki_config_dump(unsigned node)
 		cvmx_pki_clx_pkindx_style_t pkstyle[CVMX_PKI_NUM_CLUSTER];
 		cvmx_pki_clx_pkindx_cfg_t pkcfg[CVMX_PKI_NUM_CLUSTER];
 		cvmx_pki_clx_pkindx_skip_t pkskip[CVMX_PKI_NUM_CLUSTER];
-		uint64_t pkl2cust[CVMX_PKI_NUM_CLUSTER];
-		uint64_t pklgcust[CVMX_PKI_NUM_CLUSTER];
+		cvmx_pki_clx_pkindx_l2_custom_t pkl2cust[CVMX_PKI_NUM_CLUSTER];
+		cvmx_pki_clx_pkindx_lg_custom_t pklgcust[CVMX_PKI_NUM_CLUSTER];
 
 		cgsel.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKINDX_ICGSEL(pkind));
 		cgcfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(cgsel.s.icg));
@@ -1238,20 +1253,20 @@ int cvmx_pki_config_dump(unsigned node)
 
 		CVMX_MT_CRC_POLYNOMIAL(0x1edc6f41);
 		CVMX_MT_CRC_IV(0xffffffff);
-		CVMX_MT_CRC_DWORD(cgsel.u64);
+		CVMX_MT_CRC_DWORD(cgsel.u64 & 0x3ull);
 		for (cluster = 0; cluster < nclusters; cluster++) {
 			if (((1 << cluster) & mask) == 0)
 				continue;
 			pkstyle[cluster].u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(pkind, cluster));
 			pkcfg[cluster].u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pkind, cluster));
 			pkskip[cluster].u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_SKIP(pkind, cluster));
-			pkl2cust[cluster] = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_L2_CUSTOM(pkind, cluster));
-			pklgcust[cluster] = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_LG_CUSTOM(pkind, cluster));
-			CVMX_MT_CRC_DWORD(pkstyle[cluster].u64);
-			CVMX_MT_CRC_DWORD(pkcfg[cluster].u64);
-			CVMX_MT_CRC_DWORD(pkskip[cluster].u64);
-			CVMX_MT_CRC_DWORD(pkl2cust[cluster]);
-			CVMX_MT_CRC_DWORD(pklgcust[cluster]);
+			pkl2cust[cluster].u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_L2_CUSTOM(pkind, cluster));
+			pklgcust[cluster].u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_LG_CUSTOM(pkind, cluster));
+			CVMX_MT_CRC_DWORD(pkstyle[cluster].u64 & ((1ull << 16) - 1));
+			CVMX_MT_CRC_DWORD(pkcfg[cluster].u64 & ((1ull << 16) - 1));
+			CVMX_MT_CRC_DWORD(pkskip[cluster].u64 & ((1ull << 16) - 1));
+			CVMX_MT_CRC_DWORD(pkl2cust[cluster].u64 & ((1ull << 16) - 1));
+			CVMX_MT_CRC_DWORD(pklgcust[cluster].u64 & ((1ull << 8) - 1));
 		}
 		CVMX_MF_CRC_IV(crc32);
 		if (crc32 == pcrc32)
@@ -1265,20 +1280,27 @@ int cvmx_pki_config_dump(unsigned node)
 		cvmx_printf("Mapping:\n");
 		printfl(1, "Cluster Group", "%*d", PKI_PRN_DATALEN, cgsel.s.icg);
 		NSPRINT(nclusters, __i, sprintf(lines[__i], "Cluster%d", __i));
-		NMPRINT(nclusters, mask, __i, 0, "Parsing", "%*s", lines[__i]);
-		NMPRINT(nclusters, mask, __i, 1, "INST Header present", "%*s", pkcfg[__i].s.inst_hdr ? "Yes" : "No");
-		NMPRINT(nclusters, mask, __i, 1, "INST skip", "%*d", pkskip[__i].s.inst_skip);
-		NMPRINT(nclusters, mask, __i, 1, "FCS skip", "%*d", pkskip[__i].s.fcs_skip);
-		if (NMCMPEQ(0, (pkl2cust[__i] & (1ull << 15)), nclusters, mask, __i) != 0)
-			NMPRINT(nclusters, mask, __i, 1, "L2 Custom offset", "%*lld", (pkl2cust[__i] & 0xFFull));
-		NMPRINT(nclusters, mask, __i, 1, "LG Custom offset", "%*lld", (pklgcust[__i] & 0xFFull));
+		NMPRINT(nclusters, mask, __i, 0, "Parsing:", "%*s", lines[__i]);
+		NMPRINT(nclusters, mask, __i, 1, "Initial Style", "%*d", pkstyle[__i].s.style);
 		NSPRINT(nclusters, __i, sprintf(lines[__i], "%c%c%c%c%c%c%c",
 			(pkstyle[__i].s.pm & (1 << 0)) ? '-' : 'A', (pkstyle[__i].s.pm & (1 << 1)) ? '-' : 'B',
 			(pkstyle[__i].s.pm & (1 << 2)) ? '-' : 'C', (pkstyle[__i].s.pm & (1 << 3)) ? '-' : 'D',
 			(pkstyle[__i].s.pm & (1 << 4)) ? '-' : 'E', (pkstyle[__i].s.pm & (1 << 5)) ? '-' : 'F',
 			(pkstyle[__i].s.pm & (1 << 6)) ? '-' : 'G'));
 		NMPRINT(nclusters, mask, __i, 1, "Initial Parse Mode", "%*s", lines[__i]);
-		NMPRINT(nclusters, mask, __i, 1, "Initial Style", "%*d", pkstyle[__i].s.style);
+		NMPRINT(nclusters, mask, __i, 1, "INST skip", "%*d", pkskip[__i].s.inst_skip);
+		if (NMCMPEQ(0, pkcfg[__i].s.inst_hdr, nclusters, mask, __i) != 0)
+			NMPRINT(nclusters, mask, __i, 1, "INST Header present", "%*s", pkcfg[__i].s.inst_hdr ? "Yes" : "No");
+		NMPRINT(nclusters, mask, __i, 1, "FCS skip", "%*d", pkskip[__i].s.fcs_skip);
+		NMPRINT(nclusters, mask, __i, 1, "FCS present", "%*s", pkcfg[__i].s.fcs_pres ? "On":"Off");
+		if (NMCMPEQ(0, pkl2cust[__i].s.valid, nclusters, mask, __i) != 0) {
+			NMPRINT(nclusters, mask, __i, 1, "L2 custom match", "%*s", pkl2cust[__i].s.valid ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "L2 Custom offset", "%*d", pkl2cust[__i].s.offset);
+		}
+		if (NMCMPEQ(0, pkcfg[__i].s.lg_custom, nclusters, mask, __i) != 0) {
+			NMPRINT(nclusters, mask, __i, 1, "LG custom match", "%*s", pkcfg[__i].s.lg_custom ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "LG Custom offset", "%*d", pklgcust[__i].s.offset);
+		}
 		if (NMCMPEQ(0, pkcfg[__i].s.mpls_en, nclusters, mask, __i) != 0)
 			NMPRINT(nclusters, mask, __i, 1, "MPLS parsing", "%*s", pkcfg[__i].s.mpls_en ? "On":"Off");
 		if (NMCMPEQ(0, pkcfg[__i].s.dsa_en, nclusters, mask, __i) != 0)
@@ -1287,8 +1309,6 @@ int cvmx_pki_config_dump(unsigned node)
 			NMPRINT(nclusters, mask, __i, 1, "HG parsing", "%*s", pkcfg[__i].s.hg_en ? "On":"Off");
 		if (NMCMPEQ(0, pkcfg[__i].s.hg2_en, nclusters, mask, __i) != 0)
 			NMPRINT(nclusters, mask, __i, 1, "HG2 parsing", "%*s", pkcfg[__i].s.hg2_en ? "On":"Off");
-		if (NMCMPEQ(0, pkcfg[__i].s.lg_custom, nclusters, mask, __i) != 0)
-			NMPRINT(nclusters, mask, __i, 1, "LG custom match", "%*s", pkcfg[__i].s.lg_custom ? "On":"Off");
 		if (NMCMPEQ(0, pkcfg[__i].s.fulc_en, nclusters, mask, __i) != 0)
 			NMPRINT(nclusters, mask, __i, 1, "Fulcrum Header parsing", "%*s", pkcfg[__i].s.fulc_en ? "On":"Off");
 	}
@@ -1305,15 +1325,15 @@ int cvmx_pki_config_dump(unsigned node)
 		CVMX_MT_CRC_POLYNOMIAL(0x1edc6f41);
 		CVMX_MT_CRC_IV(0xffffffff);
 		stbuf.u64 = cvmx_read_csr_node(node, CVMX_PKI_STYLEX_BUF(style));
-		CVMX_MT_CRC_DWORD(stbuf.u64);
+		CVMX_MT_CRC_DWORD(stbuf.u64 & ((1ull << 33) - 1));
 		mask = 0;
 		for (cluster = 0; cluster < nclusters; cluster++) {
 			stcfg[cluster].u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster));
 			stcfg2[cluster].u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster));
 			stalg[cluster].u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(style, cluster));
-			CVMX_MT_CRC_DWORD(stcfg[cluster].u64);
-			CVMX_MT_CRC_DWORD(stcfg2[cluster].u64);
-			CVMX_MT_CRC_DWORD(stalg[cluster].u64);
+			CVMX_MT_CRC_DWORD(stcfg[cluster].u64 & 0x7FFF07FF);
+			CVMX_MT_CRC_DWORD(stcfg2[cluster].u64 & ((1ull << 32) - 1));
+			CVMX_MT_CRC_DWORD(stalg[cluster].u64 & ((1ull << 32) - 1));
 			mask |= 1 << cluster;
 		}
 		CVMX_MF_CRC_IV(crc32);
@@ -1325,12 +1345,14 @@ int cvmx_pki_config_dump(unsigned node)
 		ibase = style;
 
 		DLMPRINT("STYLE %02d:", style);
+		cvmx_printf("Buffering:\n");
 		stbuf.u64 = cvmx_read_csr_node(node, CVMX_PKI_STYLEX_BUF(style));
-		printfl(0, "WQE header", "%s", stbuf.s.wqe_hsz ? "WORD0..5" : "WORD0..4");
-		printfl(0, "WQE Skip", "%d", stbuf.s.wqe_skip);
-		printfl(0, "First Skip", "%d", stbuf.s.first_skip);
-		printfl(0, "Later Skip", "%d", stbuf.s.later_skip);
-		printfl(0, "OPC Mode", "%d", stbuf.s.opc_mode);
+		printfl(1, "WQE header", "%s", stbuf.s.wqe_hsz ? "WORD0..5" : "WORD0..4");
+		printfl(1, "WQE and Data buffers", "%s", stbuf.s.dis_wq_dat ? "Separate" : "Same");
+		printfl(1, "WQE Skip", "%d", stbuf.s.wqe_skip);
+		printfl(1, "First Skip", "%d", stbuf.s.first_skip);
+		printfl(1, "Later Skip", "%d", stbuf.s.later_skip);
+		printfl(1, "OPC Mode", "%d", stbuf.s.opc_mode);
 		if (NMCMPEQ(0, stcfg2[__i].s.tag_masken, 4, mask, __i) != 0) {
 			cvmx_pki_stylex_tag_mask_t sttmask;
 			sttmask.u64 = cvmx_read_csr_node(node, CVMX_PKI_STYLEX_TAG_MASK(style));
@@ -1357,26 +1379,38 @@ int cvmx_pki_config_dump(unsigned node)
 		}
 		NSPRINT(nclusters, __i, sprintf(lines[__i], "Cluster%d", __i));
 		NMPRINT(nclusters, mask, __i, 0, "", "%*s", lines[__i]);
-		NMPRINT(nclusters, mask, __i, 0, "Strip FCS", "%*d", stcfg[__i].s.fcs_strip);
+		NMPRINT(nclusters, mask, __i, 0, "Strip FCS", "%*s", stcfg[__i].s.fcs_strip ? "Yes":"No");
 		cvmx_printf("Tag:\n");
-		NMPRINT(nclusters, mask, __i, 1, "SSO Tag Type", "%*d", stalg[__i].s.tt);
-		for (cluster = 0; cluster < nclusters; cluster++)
-			sprintf(lines[cluster], "%s", "BCDEFG");
-		NMPRINT(nclusters, mask, __i, 1, "Parse Layers", "%*s", lines[__i]);
-		NSPRINT(nclusters, __i, int2bitstr(lines[__i], (stcfg2[__i].u64 >> 18) & 0x3F, 6));
-		NMPRINT(nclusters, mask, __i, 1, "T-Tag <= Source", "%*s", lines[__i]);
-		NSPRINT(nclusters, __i, int2bitstr(lines[__i], (stcfg2[__i].u64 >> 12) & 0x3F, 6));
-		NMPRINT(nclusters, mask, __i, 1, "T-Tag <= Dest", "%*s", lines[__i]);
-		NMPRINT(nclusters, mask, __i, 1, "T-Tag <= Port", "%*s", stalg[__i].s.tag_prt ? "On":"Off");
+		NMPRINT(nclusters, mask, __i, 1, "Tag Type", "%*s", tagtype_map[stalg[__i].s.tt]);
+		if (NMCMPEQ(0, ((stcfg2[__i].u64 >> 18) & 0x3F), 4, mask, __i) != 0) {
+			NSPRINT(nclusters, __i, int2cstr(lines[__i], (stcfg2[__i].u64 >> 18) & 0x3F, 6));
+			NMPRINT(nclusters, mask, __i, 1, "T-Tag <= Source", "%*s", lines[__i]);
+		}
+		if (NMCMPEQ(0, ((stcfg2[__i].u64 >> 12) & 0x3F), 4, mask, __i) != 0) {
+			NSPRINT(nclusters, __i, int2cstr(lines[__i], (stcfg2[__i].u64 >> 12) & 0x3F, 6));
+			NMPRINT(nclusters, mask, __i, 1, "T-Tag <= Dest", "%*s", lines[__i]);
+		}
+		if (NMCMPEQ(0, stalg[__i].s.tag_pctl, 4, mask, __i) != 0)
+			NMPRINT(nclusters, mask, __i, 1, "T-Tag <= Proto", "%*s", stalg[__i].s.tag_pctl ? "On":"Off");
+		if (NMCMPEQ(0, stalg[__i].s.tag_vs0, 4, mask, __i) != 0)
+			NMPRINT(nclusters, mask, __i, 1, "T-Tag <= VLAN0", "%*s", stalg[__i].s.tag_vs0 ? "On":"Off");
+		if (NMCMPEQ(0, stalg[__i].s.tag_vs1, 4, mask, __i) != 0)
+			NMPRINT(nclusters, mask, __i, 1, "T-Tag <= VLAN1", "%*s", stalg[__i].s.tag_vs1 ? "On":"Off");
+		if (NMCMPEQ(0, stalg[__i].s.tag_prt, 4, mask, __i) != 0)
+			NMPRINT(nclusters, mask, __i, 1, "T-Tag <= Port", "%*s", stalg[__i].s.tag_prt ? "On":"Off");
 		if (NMCMPEQ(0, stcfg2[__i].s.tag_inc, 4, mask, __i) != 0)
 			NMPRINT(nclusters, mask, __i, 1, "C-Tag Mask (hex)", "%*x", stcfg2[__i].s.tag_inc);
 		cvmx_printf("QPG:\n");
-		NMPRINT(nclusters, mask, __i, 1, "QPG <= QOS Algo", "%*d", stalg[__i].s.qpg_qos);
-		NMPRINT(nclusters, mask, __i, 1, "Port Adder <= QPG", "%*s", stcfg[__i].s.qpg_dis_padd ? "Off":"On");
-		NMPRINT(nclusters, mask, __i, 1, "Aura <= QPG", "%*s", stcfg[__i].s.qpg_dis_aura ? "Off":"On");
-		NMPRINT(nclusters, mask, __i, 1, "Group <= QPG", "%*s", stcfg[__i].s.qpg_dis_grp ? "Off":"On");
-		NMPRINT(nclusters, mask, __i, 1, "Group <= WQE[TAG]", "%*s", stcfg[__i].s.qpg_dis_grp ? "Off":"On");
-		NMPRINT(nclusters, mask, __i, 1, "QPG base", "%*d", stcfg[__i].s.qpg_base);
+		NMPRINT(nclusters, mask, __i, 1, "QOS Algo", "%*s", qpgqos_map[stalg[__i].s.qpg_qos]);
+		NMPRINT(nclusters, mask, __i, 1, "QPG Base (dec)", "%*d", stcfg[__i].s.qpg_base);
+		if (NMCMPEQ(0, stalg[__i].s.qpg_port_msb, 4, mask, __i) != 0) {
+			NMPRINT(nclusters, mask, __i, 1, "Port MSB (hex)", "%*x", stalg[__i].s.qpg_port_msb);
+			NMPRINT(nclusters, mask, __i, 1, "Port Shift (dec)", "%*d", stalg[__i].s.qpg_port_sh);
+		}
+		NMPRINT(nclusters, mask, __i, 1, "QPG => PortAdder", "%*s", stcfg[__i].s.qpg_dis_padd ? "Off":"On");
+		NMPRINT(nclusters, mask, __i, 1, "QPG => Aura", "%*s", stcfg[__i].s.qpg_dis_aura ? "Off":"On");
+		NMPRINT(nclusters, mask, __i, 1, "QPG => Group", "%*s", stcfg[__i].s.qpg_dis_grp ? "Off":"On");
+		NMPRINT(nclusters, mask, __i, 1, "WQE[TAG] => Group", "%*s", stcfg[__i].s.qpg_dis_grptag ? "Off":"On");
 	}
 	if (style > 0 && (style - 1) != ibase)
 		cvmx_printf("\nSTYLE(s) %02d-%02d -- same as STYLE %02d\n", style - 1, ibase + 1, ibase);
@@ -1389,7 +1423,7 @@ int cvmx_pki_config_dump(unsigned node)
 			continue;
 
 		DLMPRINT("CLUSTER GROUP %d:", group);
-		cvmx_printf("Action = {PMC(hex) : Style_Add(dec) : PF(hex) : SetTy(dec) : Advance(dec)}\n");
+		cvmx_printf("Action = {PMC(hex) : +STYLE(dec) : PF(hex) : SETTY(dec) : ADVANCE(dec)}\n");
 		printfl(0, "Parsing", "%s", cgcfg.s.pena ? "Enabled" : "Disabled");
 		printfl(0, "Entry", "%*s%*s", PKI_PRN_DPLEN(2), "PCAM0", PKI_PRN_DPLEN(2), "PCAM1");
 		for (cluster = 0; cluster < nclusters; cluster++) {
@@ -1465,7 +1499,7 @@ int cvmx_pki_config_dump(unsigned node)
 	for (i = 0; i < CVMX_PKI_NUM_CHANNEL; i++) {
 		cvmx_pki_chanx_cfg_t chan;
 		chan.u64 = cvmx_read_csr_node(node, CVMX_PKI_CHANX_CFG(i));
-		if (chan.s.bpid != 0) {
+		if (chan.s.imp == 1 && chan.s.bpid != 0) {
 
 			if (i >= 0 && i < 64) /* LBK*/
 				sprintf(lines[1], "LBK:%d", i);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
index 2fca1bd..112eebc 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
@@ -188,9 +188,9 @@ int __cvmx_pko3_dq_table_setup(void)
 
 /*
  * @INTERNAL
- * Register a range of Descriptor Queues wth an interface port
+ * Register a range of Descriptor Queues with an interface port
  *
- * This function poulates the DQ-to-IPD translation table
+ * This function populates the DQ-to-IPD translation table
  * used by the application to retreive the DQ range (typically ordered
  * by priority) for a given IPD-port, which is either a physical port,
  * or a channel on a channelized interface (i.e. ILK).
@@ -202,7 +202,7 @@ int __cvmx_pko3_dq_table_setup(void)
  * @param dq_count is the number of consecutive Descriptor Queues leading
  *        the same channel or port.
  *
- * Only a consecurive range of Descriptor Queues can be associated with any
+ * Only a consecutive range of Descriptor Queues can be associated with any
  * given channel/port, and usually they are ordered from most to least
  * in terms of scheduling priority.
  *
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3-resources.c b/arch/mips/cavium-octeon/executive/cvmx-pko3-resources.c
index 1da8991..ec4a47e 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3-resources.c
@@ -94,7 +94,7 @@ static const short cvmx_pko_num_queues_73XX[256] =
 	[CVMX_PKO_DESCR_QUEUES] = 256
 };
 
-static inline int __cvmx_pko3_get_num_queues(enum cvmx_pko3_level_e level)
+int cvmx_pko3_num_level_queues(enum cvmx_pko3_level_e level)
 {
 	unsigned nq = 0, ne = 0;
 
@@ -119,7 +119,7 @@ static inline int __cvmx_pko3_get_num_queues(enum cvmx_pko3_level_e level)
 static inline struct global_resource_tag
 __cvmx_pko_get_queues_resource_tag(int node, enum cvmx_pko3_level_e queue_level)
 {
-	if (__cvmx_pko3_get_num_queues(queue_level) == 0) {
+	if (cvmx_pko3_num_level_queues(queue_level) == 0) {
 		cvmx_printf("ERROR: %s: queue level %#x invalid\n",
 				__func__, queue_level);
 		return CVMX_GR_TAG_INVALID;
@@ -190,7 +190,7 @@ int cvmx_pko_alloc_global_resource(struct global_resource_tag tag, int base_queu
 int cvmx_pko_alloc_queues(int node, int level, int owner, int base_queue, int num_queues)
 {
 	struct global_resource_tag tag = __cvmx_pko_get_queues_resource_tag(node, level);
-	int max_num_queues = __cvmx_pko3_get_num_queues(level);
+	int max_num_queues = cvmx_pko3_num_level_queues(level);
 
 	return cvmx_pko_alloc_global_resource(tag, base_queue, owner, num_queues, max_num_queues);
 }
@@ -234,7 +234,7 @@ int __cvmx_pko3_dq_param_setup(unsigned node)
 	block_name[i-1] += node;
 
 	/* Get number of descriptor queues for sizing the table */
-	i = __cvmx_pko3_get_num_queues(CVMX_PKO_DESCR_QUEUES);
+	i = cvmx_pko3_num_level_queues(CVMX_PKO_DESCR_QUEUES);
 
 	pParam = cvmx_bootmem_alloc_named_range_once(
 		/* size */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-qlm.c b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
index 3e35d66..3e1a572 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-qlm.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 116798 $<hr>
+ * <hr>$Revision: 118803 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -219,12 +219,9 @@ int cvmx_qlm_interface(int xiface)
 		cvmx_gserx_cfg_t gserx_cfg;
 		int qlm;
 
-		/* QLM2, QLM3, QLM5/QLM6 */
-		if (xi.interface < 4) {
-			if (xi.interface < 2)
-				qlm = xi.interface + 2;
-			else
-				qlm = xi.interface + 3;
+		/* (interface)0->QLM2, 1->QLM3, 2->DLM5/3->DLM6 */
+		if (xi.interface < 2) {
+			qlm = xi.interface + 2; /* (0,1)->ret(2,3) */
 
 			phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
 			if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset) {
@@ -235,7 +232,77 @@ int cvmx_qlm_interface(int xiface)
 				return qlm;
 			else
 				return -1;
+		} else if (xi.interface == 2) {
+			cvmx_gserx_cfg_t g1, g2;
+			g1.u64 = cvmx_read_csr(CVMX_GSERX_CFG(5));
+			g2.u64 = cvmx_read_csr(CVMX_GSERX_CFG(6));
+			/* Check if both QLM5 & QLM6 are BGX2 */
+			if (g2.s.bgx) {
+				if (g1.s.bgx) {
+					cvmx_gserx_phy_ctl_t phy_ctl1;
+					phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(5));
+					phy_ctl1.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(6));
+					if ((phy_ctl.s.phy_pd
+					     || phy_ctl.s.phy_reset)
+					    && (phy_ctl1.s.phy_pd
+					        || phy_ctl1.s.phy_reset))
+						return -1;
+					return 5;
+				} else { /* QLM6 is BGX2 */
+					phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(6));
+					if (phy_ctl.s.phy_pd
+					    || phy_ctl.s.phy_reset)
+						return -1;
+					return 6;
+				}
+			} else if (g1.s.bgx) {
+				phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(5));
+				if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
+					return -1;
+				return 5;
+			}
+		}
+		return -1;
+	} else if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		cvmx_gserx_phy_ctl_t phy_ctl;
+		cvmx_gserx_cfg_t gserx_cfg;
+		int qlm;
+		if (xi.interface == 0) {
+			cvmx_gserx_cfg_t g1, g2;
+			g1.u64 = cvmx_read_csr(CVMX_GSERX_CFG(4));
+			g2.u64 = cvmx_read_csr(CVMX_GSERX_CFG(5));
+			/* Check if both QLM4 & QLM5 are BGX0 */
+			if (g2.s.bgx) {
+				if (g1.s.bgx) {
+					cvmx_gserx_phy_ctl_t phy_ctl1;
+					phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(5));
+					phy_ctl1.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(6));
+					if ((phy_ctl.s.phy_pd
+					     || phy_ctl.s.phy_reset)
+					    && (phy_ctl1.s.phy_pd
+					        || phy_ctl1.s.phy_reset))
+						return -1;
+					return 4;
+				} else { /* QLM5 is BGX0 */
+					phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(6));
+					if (phy_ctl.s.phy_pd
+					    || phy_ctl.s.phy_reset)
+						return -1;
+					return 5;
+				}
+			} else if (g1.s.bgx) {
+				phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(5));
+				if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
+					return -1;
+				return 4;
+			}
+		} else if (xi.interface < 2) {
+			qlm = (xi.interface == 1) ? 2 : 3;
+			gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
+			if (gserx_cfg.s.srio)
+				return qlm;
 		}
+		return -1;
 	} else {
 		/* Must be cn68XX */
 		switch (xi.interface) {
@@ -264,7 +331,7 @@ int cvmx_qlm_get_lanes(int qlm)
 	else if (OCTEON_IS_MODEL(OCTEON_CN73XX))
 		return (qlm < 4) ? 4/*QLM0,1,2,3*/ : 2/*DLM4,5,6*/;
 	else if (OCTEON_IS_MODEL(OCTEON_CNF75XX))
-		return (qlm < 2) ? 4/*QLM0,1*/ : 2/*DLM0,1,2,3*/;
+		return (qlm == 2 || qlm == 3) ? 4/*QLM2,3*/ : 2/*DLM0,1,4,5*/;
 	return 4;
 }
 
@@ -1439,7 +1506,7 @@ enum cvmx_qlm_mode cvmx_qlm_get_mode_cn78xx(int node, int qlm)
 				CVMX_BGXX_SPUX_BR_PMD_CONTROL(0, bgx), pmd_control.u64);
 			break;
 		case 4:
-			/* Use training to determine if we're in 10GBASE-KR or XFI */
+			/* Use training to determine if we're in 40GBASE-KR or XLAUI */
 			if (pmd_control.s.train_en)
 				qlm_mode[node][qlm] = CVMX_QLM_MODE_40G_KR4;
 			else
@@ -1461,9 +1528,19 @@ enum cvmx_qlm_mode cvmx_qlm_get_mode_cn78xx(int node, int qlm)
 enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn73xx(int qlm)
 {
 	cvmx_gserx_cfg_t gserx_cfg;
+#ifdef CVMX_BUILD_FOR_UBOOT
+	int qlm_mode[7] = {-1, -1, -1, -1, -1, -1, -1};
+#else
+	static int qlm_mode[7] = {-1, -1, -1, -1, -1, -1, -1};
+#endif
 
-	if (qlm > 6)
-		return CVMX_QLM_MODE_DISABLED;
+	if (qlm_mode[qlm] != -1)
+		return qlm_mode[qlm];
+
+	if (qlm > 6) {
+		cvmx_dprintf("Invalid QLM(%d) passed\n", qlm);
+		return -1;
+	}
 
 	gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
 	if (gserx_cfg.s.pcie) {
@@ -1474,46 +1551,69 @@ enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn73xx(int qlm)
 		{
 			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(0));
 			if (pemx_cfg.cn78xx.lanes8)
-				return CVMX_QLM_MODE_PCIE_1X8; /* PEM0 x8 */
+				qlm_mode[qlm] = CVMX_QLM_MODE_PCIE_1X8; /* PEM0 x8 */
 			else
-				return CVMX_QLM_MODE_PCIE;     /* PEM0/PEM1 x4 */
+				qlm_mode[qlm] = CVMX_QLM_MODE_PCIE;     /* PEM0/PEM1 x4 */
+			break;
 		}
 		case 2: /* Either PEM2 x4 or PEM2 x8 */
 		{
 			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(2));
 			if (pemx_cfg.cn78xx.lanes8)
-				return CVMX_QLM_MODE_PCIE_1X8;  /* PEM2 x8 */
+				qlm_mode[qlm] = CVMX_QLM_MODE_PCIE_1X8;  /* PEM2 x8 */
 			else
-				return CVMX_QLM_MODE_PCIE;      /* PEM2 x4 */
+				qlm_mode[qlm] = CVMX_QLM_MODE_PCIE;      /* PEM2 x4 */
+			break;
 		}
 		case 5:
 		case 6:	/* PEM3 x2 */
-			return CVMX_QLM_MODE_PCIE_1X2; /* PEM3 x2 */
+			qlm_mode[qlm] = CVMX_QLM_MODE_PCIE_1X2; /* PEM3 x2 */
+			break;
 		case 3: /* Either PEM2 x8 or PEM3 x4 */
 		{
 			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(2));
 			if (pemx_cfg.cn78xx.lanes8)
-				return CVMX_QLM_MODE_PCIE_1X8;  /* PEM2 x8 */
+				qlm_mode[qlm] = CVMX_QLM_MODE_PCIE_1X8;  /* PEM2 x8 */
 			else
-				return CVMX_QLM_MODE_PCIE; /* PEM3 x4 */
+				qlm_mode[qlm] = CVMX_QLM_MODE_PCIE; /* PEM3 x4 */
+			break;
 		}
 		default:
-			return CVMX_QLM_MODE_DISABLED;
+			qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
 		}
 	} else if (gserx_cfg.s.bgx) {
 		cvmx_bgxx_cmrx_config_t cmr_config;
 		cvmx_bgxx_spux_br_pmd_control_t pmd_control;
 		int bgx = 0;
-		int index;
+		int start = 0, end = 4, index;
 		int lane_mask = 0, train_mask = 0;
+		int mux = 0; // 0:BGX2 (DLM5/DLM6), 1:BGX2(DLM5), 2:BGX2(DLM6)
 		if (qlm < 4)
 			bgx = qlm - 2;
 		else if (qlm == 5 || qlm == 6) {
+			cvmx_gserx_cfg_t gser1, gser2;
+			gser1.u64 = cvmx_read_csr(CVMX_GSERX_CFG(5));
+			gser2.u64 = cvmx_read_csr(CVMX_GSERX_CFG(6));
+			if (gser1.s.bgx && gser2.s.bgx) {
+				start = 0;
+				end = 4;
+			} else if (gser1.s.bgx) {
+				start = 0;
+				end = 2;
+				mux = 1;
+			} else if (gser2.s.bgx) {
+				start = 2;
+				end = 4;
+				mux = 2;
+			} else {
+				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+				return qlm_mode[qlm];
+			}
 			bgx = 2;
-			return CVMX_QLM_MODE_DISABLED;
 		}
 
-		for (index = 0; index < 4; index++) {
+		for (index = start; index < end; index++) {
 			cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, bgx));
 			pmd_control.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, bgx));
 			lane_mask |= (cmr_config.s.lmac_type << (index * 4));
@@ -1521,73 +1621,201 @@ enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn73xx(int qlm)
 		}
 
 		switch(lane_mask) {
-		case 0:		return CVMX_QLM_MODE_SGMII;
-		case 0x1:	return CVMX_QLM_MODE_XAUI;
-		case 0x22:	return CVMX_QLM_MODE_RXAUI;
+		case 0:
+			if (mux == 1 || mux == 2)
+				qlm_mode[qlm] = CVMX_QLM_MODE_SGMII_1X2;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_SGMII;
+			break;
+		case 0x1:
+			qlm_mode[qlm] = CVMX_QLM_MODE_XAUI;
+			break;
+		case 0x2:
+			if (mux == 2)
+				qlm_mode[qlm] = CVMX_QLM_MODE_RXAUI_1X2;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
+		case 0x22:
+			qlm_mode[qlm] = CVMX_QLM_MODE_RXAUI;
+			break;
 		case 0x3333:
 			/* Use training to determine if we're in 10GBASE-KR or XFI */
 			if (train_mask)
-				return CVMX_QLM_MODE_10G_KR;
+				qlm_mode[qlm] = CVMX_QLM_MODE_10G_KR;
 			else
-				return CVMX_QLM_MODE_XFI;
+				qlm_mode[qlm] = CVMX_QLM_MODE_XFI;
+			break;
 		case 0x4:
 			/* Use training to determine if we're in 40GBASE-KR or XLAUI */
 			if (train_mask)
-				return CVMX_QLM_MODE_40G_KR4;
+				qlm_mode[qlm] = CVMX_QLM_MODE_40G_KR4;
 			else
-				return CVMX_QLM_MODE_XLAUI;
-		case 0x0005:	return CVMX_QLM_MODE_RGMII_SGMII;
-		case 0x3335:	if (train_mask)
-					return CVMX_QLM_MODE_RGMII_10G_KR;
-				else
-					return CVMX_QLM_MODE_RGMII_XFI;
-		case 0x45:	if (train_mask)
-					return CVMX_QLM_MODE_RGMII_40G_KR4;
-				else
-					return CVMX_QLM_MODE_RGMII_XLAUI;
-		case 0x225:	return CVMX_QLM_MODE_RGMII_RXAUI;
-		case 0x15:	return CVMX_QLM_MODE_RGMII_XAUI;
-		case 0x3300:	if (qlm == 5)
-					return CVMX_QLM_MODE_SGMII;
-				if (train_mask)
-					return CVMX_QLM_MODE_10G_KR;
-				else
-					return CVMX_QLM_MODE_XFI;
-		case 0x200:	if (qlm == 5)
-					return CVMX_QLM_MODE_SGMII;
-				return CVMX_QLM_MODE_RXAUI;
-		case 0x233:	if (qlm == 6)
-					return CVMX_QLM_MODE_RXAUI;
-				if (train_mask)
-					return CVMX_QLM_MODE_10G_KR;
-				else
-					return CVMX_QLM_MODE_XFI;
-		case 0x3305:	if (qlm == 5)
-					return CVMX_QLM_MODE_RGMII_SGMII;
-				if (train_mask)
-					return CVMX_QLM_MODE_10G_KR;
-				else
-					return CVMX_QLM_MODE_XFI;
-		case 0x205:	if (qlm == 5)
-					return CVMX_QLM_MODE_RGMII_SGMII;
-				else
-					return CVMX_QLM_MODE_RXAUI;
-		case 0x0035:	if (qlm == 6)
-					return CVMX_QLM_MODE_SGMII;
-				if (train_mask)
-					return CVMX_QLM_MODE_RGMII_10G_KR;
-				else
-					return CVMX_QLM_MODE_RGMII_XFI;
-		case 0x235:	if (qlm == 6)
-					return CVMX_QLM_MODE_RXAUI;
-				if (train_mask)
-					return CVMX_QLM_MODE_RGMII_10G_KR;
-				else
-					return CVMX_QLM_MODE_RGMII_XFI;
-		default: return CVMX_QLM_MODE_DISABLED;
+				qlm_mode[qlm] = CVMX_QLM_MODE_XLAUI;
+			break;
+		case 0x0005:
+			qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_SGMII;
+			break;
+		case 0x3335:
+			if (train_mask)
+				qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_10G_KR;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_XFI;
+			break;
+		case 0x45:
+			if (train_mask)
+				qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_40G_KR4;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_XLAUI;
+			break;
+		case 0x225:
+			qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_RXAUI;
+			break;
+		case 0x15:
+			qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_XAUI;
+			break;
+
+		case 0x200:
+		case 0x205:
+		case 0x233:
+		case 0x3305:
+			if (mux == 0)
+				qlm_mode[qlm] = CVMX_QLM_MODE_MIXED;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
+		case 0x3300:
+			if (mux == 0)
+				qlm_mode[qlm] = CVMX_QLM_MODE_MIXED;
+			else if (mux == 2)
+				qlm_mode[qlm] = CVMX_QLM_MODE_XFI_1X2;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
+		case 0x0035:
+			if (mux == 0)
+				qlm_mode[qlm] = CVMX_QLM_MODE_MIXED;
+			else if (train_mask)
+				qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_10G_KR_1X1;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_RGMII_XFI_1X1;
+			break;
+		case 0x235:
+			if (mux == 0)
+				qlm_mode[qlm] = CVMX_QLM_MODE_MIXED;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
+		default:
+			qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
 		}
+	} else if (gserx_cfg.s.sata)
+		qlm_mode[qlm] = CVMX_QLM_MODE_SATA_2X1;
+	else
+		qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+	return qlm_mode[qlm];
+}
+
+enum cvmx_qlm_mode __cvmx_qlm_get_mode_cnf75xx(int qlm)
+{
+	cvmx_gserx_cfg_t gserx_cfg;
+#ifdef CVMX_BUILD_FOR_UBOOT
+	int qlm_mode[9] = {-1, -1, -1, -1, -1, -1, -1};
+#else
+	static int qlm_mode[9] = {-1, -1, -1, -1, -1, -1, -1};
+#endif
+
+	if (qlm_mode[qlm] != -1)
+		return qlm_mode[qlm];
+
+	if (qlm > 9) {
+		cvmx_dprintf("Invalid QLM(%d) passed\n", qlm);
+		return -1;
 	}
-	return CVMX_QLM_MODE_DISABLED;
+
+	if (qlm == 2 || qlm == 3) {
+		cvmx_sriox_status_reg_t status_reg;
+		int port = (qlm == 2) ? 0 : 1;
+		status_reg.u64 = cvmx_read_csr(CVMX_SRIOX_STATUS_REG(port));
+		/* FIXME add different width */
+		if (status_reg.s.srio)
+			qlm_mode[qlm] = CVMX_QLM_MODE_SRIO_1X4;
+		else
+			qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+		return qlm_mode[qlm];
+	}
+
+	gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
+	if (gserx_cfg.s.pcie) {
+		switch (qlm) {
+		case 0: /* Either PEM0 x2 or PEM0 x4 */
+		case 1: /* Either PEM1 x2 or PEM0 x4 */
+		{
+			/* FIXME later */
+			qlm_mode[qlm] = CVMX_QLM_MODE_PCIE;
+			break;
+		}
+		default:
+			qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
+		}
+	} else if (gserx_cfg.s.bgx) {
+		cvmx_bgxx_cmrx_config_t cmr_config;
+		cvmx_bgxx_spux_br_pmd_control_t pmd_control;
+		int bgx = 0;
+		int start = 0, end = 4, index;
+		int lane_mask = 0, train_mask = 0;
+		int mux = 0; // 0:BGX0 (DLM4/DLM5), 1:BGX0(DLM4), 2:BGX0(DLM5)
+		cvmx_gserx_cfg_t gser1, gser2;
+		gser1.u64 = cvmx_read_csr(CVMX_GSERX_CFG(4));
+		gser2.u64 = cvmx_read_csr(CVMX_GSERX_CFG(5));
+		if (gser1.s.bgx && gser2.s.bgx) {
+			start = 0;
+			end = 4;
+		} else if (gser1.s.bgx) {
+			start = 0;
+			end = 2;
+			mux = 1;
+		} else if (gser2.s.bgx) {
+			start = 2;
+			end = 4;
+			mux = 2;
+		} else {
+			qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			return qlm_mode[qlm];
+		}
+
+		for (index = start; index < end; index++) {
+			cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, bgx));
+			pmd_control.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, bgx));
+			lane_mask |= (cmr_config.s.lmac_type << (index * 4));
+			train_mask |= (pmd_control.s.train_en << (index * 4));
+		}
+
+		switch(lane_mask) {
+		case 0:
+			if (mux == 1 || mux == 2)
+				qlm_mode[qlm] = CVMX_QLM_MODE_SGMII_1X2;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_SGMII;
+			break;
+		case 0x3300:
+			if (mux == 0)
+				qlm_mode[qlm] = CVMX_QLM_MODE_MIXED;
+			else if (mux == 2)
+				qlm_mode[qlm] = CVMX_QLM_MODE_XFI_1X2;
+			else
+				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
+		default:
+			qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+			break;
+		}
+	} else
+		qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
+
+	return qlm_mode[qlm];
 }
 
 /*
@@ -1603,6 +1831,8 @@ enum cvmx_qlm_mode cvmx_qlm_get_mode(int qlm)
 		return cvmx_qlm_get_mode_cn78xx(cvmx_get_node_num(), qlm);
 	else if (OCTEON_IS_MODEL(OCTEON_CN73XX))
 		return __cvmx_qlm_get_mode_cn73xx(qlm);
+	else if (OCTEON_IS_MODEL(OCTEON_CNF75XX))
+		return __cvmx_qlm_get_mode_cnf75xx(qlm);
 
 	return CVMX_QLM_MODE_DISABLED;
 }
@@ -1670,6 +1900,7 @@ int cvmx_qlm_measure_clock(int qlm)
 	uint64_t count;
 	uint64_t start_cycle, stop_cycle;
 	int evcnt_offset = 0x10;
+	int incr_count = 1;
 #ifdef CVMX_BUILD_FOR_UBOOT
 	int ref_clock[16] = {0};
 #else
@@ -1694,6 +1925,14 @@ int cvmx_qlm_measure_clock(int qlm)
 	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM)
 		return 156250000;
 #endif
+	if (OCTEON_IS_MODEL(OCTEON_CN70XX) && qlm == 0) {
+		cvmx_gserx_dlmx_ref_clkdiv2_t ref_clkdiv2;
+
+		ref_clkdiv2.u64 = cvmx_read_csr(CVMX_GSERX_DLMX_REF_CLKDIV2(qlm, 0));
+		if (ref_clkdiv2.s.ref_clkdiv2)
+			incr_count = 2;
+	}
+
 	/* Fix reference clock for OCI QLMs */
 
 	/* Disable the PTP event counter while we configure it */
@@ -1728,18 +1967,114 @@ int cvmx_qlm_measure_clock(int qlm)
 	cvmx_write_csr(CVMX_MIO_PTP_CLOCK_CFG, ptp_clock.u64);
 	/* Clock counted down, so reverse it */
 	count = 1000000000 - count;
-	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
-		cvmx_gserx_dlmx_ref_clkdiv2_t ref_clkdiv2;
-
-		ref_clkdiv2.u64 = cvmx_read_csr(CVMX_GSERX_DLMX_REF_CLKDIV2(qlm, 0));
-		if (ref_clkdiv2.s.ref_clkdiv2)
-			count *= 2;
-	}
+	count *= incr_count;
 	/* Return the rate */
 	ref_clock[qlm] = count * cvmx_clock_get_rate(CVMX_CLOCK_CORE) / (stop_cycle - start_cycle);
 	return ref_clock[qlm];
 }
 
+/*
+ * Perform RX equalization on a QLM
+ *
+ * @param node	Node the QLM is on
+ * @param qlm	QLM to perform RX equalization on
+ * @param lane	Lane to use, or -1 for all lanes
+ *
+ * @return Zero on sucess, negative if any lane failed RX equalization
+ */
+int __cvmx_qlm_rx_equalization(int node, int qlm, int lane)
+{
+	cvmx_gserx_phy_ctl_t phy_ctl;
+	cvmx_gserx_spd_t gserx_spd;
+	int fail, gbaud, l;
+	enum cvmx_qlm_mode mode;
+
+	/* Don't touch QLMs if it is reset or powered down */
+	phy_ctl.u64 = cvmx_read_csr_node(node, CVMX_GSERX_PHY_CTL(qlm));
+	if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
+		return -1;
+
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		gbaud = cvmx_qlm_get_gbaud_mhz_node(node, qlm);
+	else
+		gbaud = cvmx_qlm_get_gbaud_mhz(qlm);
+
+	/* Apply RX Equalization for speed >= 8G */
+	if (qlm < 8) {
+		if (gbaud < 8000)
+			return 0;
+	} else { // OCI
+		gserx_spd.u64 = cvmx_read_csr_node(node, CVMX_GSERX_SPD(qlm));
+		/* Supported with SW init at 6.25G */
+		if (gserx_spd.s.spd == 0xf) {
+			if (gbaud < 6250)
+				return 0;
+		} else { /* Only supported at 8G or higher */
+			if (gbaud < 8000)
+				return 0;
+		}
+	}
+
+	/* Don't run on PCIe Links */
+	mode = cvmx_qlm_get_mode(qlm);
+	if (mode == CVMX_QLM_MODE_PCIE
+	    || mode == CVMX_QLM_MODE_PCIE_1X8
+	    || mode == CVMX_QLM_MODE_PCIE_1X2
+	    || mode == CVMX_QLM_MODE_PCIE_2X1)
+		return -1;
+
+	fail = 0;
+
+	for (l = 0; l < 4; l++) {
+		cvmx_gserx_br_rxx_ctl_t rxx_ctl;
+		cvmx_gserx_br_rxx_eer_t rxx_eer;
+
+		if ((lane != -1) && (lane != l))
+			continue;
+
+		/* Enable software control */
+		rxx_ctl.u64 = cvmx_read_csr_node(node, CVMX_GSERX_BR_RXX_CTL(l, qlm));
+		rxx_ctl.s.rxt_swm = 1;
+		cvmx_write_csr_node(node, CVMX_GSERX_BR_RXX_CTL(l, qlm), rxx_ctl.u64);
+
+		/* Clear the completion flag and initiate a new request */
+		rxx_eer.u64 = cvmx_read_csr_node(node, CVMX_GSERX_BR_RXX_EER(l, qlm));
+		rxx_eer.s.rxt_esv = 0;
+		rxx_eer.s.rxt_eer = 1;
+		cvmx_write_csr_node(node, CVMX_GSERX_BR_RXX_EER(l, qlm), rxx_eer.u64);
+	}
+
+	/* Wait for RX equalization to complete */
+	for (l = 0; l < 4; l++) {
+		cvmx_gserx_br_rxx_eer_t rxx_eer;
+
+		if ((lane != -1) && (lane != l))
+			continue;
+
+		CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_GSERX_BR_RXX_EER(l, qlm),
+				cvmx_gserx_br_rxx_eer_t, rxt_esv, ==, 1, 100000);
+		rxx_eer.u64 = cvmx_read_csr_node(node, CVMX_GSERX_BR_RXX_EER(l, qlm));
+		if (!rxx_eer.s.rxt_esv) {
+			//cvmx_dprintf("%d:QLM%d: Lane %d RX equalization timeout\n", node, qlm, lane);
+			fail = 1;
+		}
+	}
+
+	/* Switch back to hardware control */
+	for (l = 0; l < 4; l++) {
+		cvmx_gserx_br_rxx_ctl_t rxx_ctl;
+
+		if ((lane != -1) && (lane != l))
+			continue;
+
+		rxx_ctl.u64 = cvmx_read_csr_node(node, CVMX_GSERX_BR_RXX_CTL(l, qlm));
+		rxx_ctl.s.rxt_swm = 0;
+		cvmx_write_csr_node(node, CVMX_GSERX_BR_RXX_CTL(l, qlm), rxx_ctl.u64);
+	}
+
+	return (fail) ? -1 : 0;
+} 
+
 void cvmx_qlm_display_registers(int qlm)
 {
 	int num_lanes = cvmx_qlm_get_lanes(qlm);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-srio.c b/arch/mips/cavium-octeon/executive/cvmx-srio.c
index cd593cf..5760e9d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-srio.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-srio.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2015  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -380,6 +380,62 @@ static int __cvmx_srio_local_write32(int srio_port, uint32_t offset, uint32_t da
 	return 0;
 }
 
+
+#ifdef CVMX_BUILD_FOR_STANDALONE
+/**
+ * Convert an ipd port number to its sRIO link number per SoC model.
+ *
+ * @param ipd_port Ipd port number to convert
+ *
+ * @return Srio link number
+ */
+int cvmx_srio_ipd2srio(int ipd_port)
+{
+	int xiface;
+
+	xiface = cvmx_helper_get_interface_num(ipd_port);
+	return __cvmx_helper_srio_port(xiface);
+}
+
+/**
+ * Get our device ID
+ *
+ * @return Device ID, or negative number on error
+ */
+int cvmx_srio_get_did(int srio_port)
+{
+	cvmx_sriomaintx_pri_dev_id_t	dev_id;
+
+	if (__cvmx_srio_local_read32(srio_port,
+				     CVMX_SRIOMAINTX_PRI_DEV_ID(srio_port),
+				     &dev_id.u32))
+		return -1;
+
+	return dev_id.s.id8;
+}
+
+/**
+ * Set our device ID
+ *
+ * @return Device ID, or negative number on error
+ */
+int cvmx_srio_set_did(int srio_port, int did)
+{
+	cvmx_sriomaintx_pri_dev_id_t	dev_id;
+
+	dev_id.u32 = 0;
+	dev_id.s.id8 = did;
+	dev_id.s.id16 = did;
+
+	if (__cvmx_srio_local_write32(srio_port,
+				      CVMX_SRIOMAINTX_PRI_DEV_ID(srio_port),
+				      dev_id.u32))
+		return -1;
+
+	return 0;
+}
+#endif
+
 /**
  * Reset SRIO to link partner
  *
@@ -443,7 +499,7 @@ cvmx_srio_init_cn75xx(int srio_port, cvmx_srio_initialize_flags_t flags)
 	cvmx_sriomaintx_port_0_ctl_t port_0_ctl;
 	cvmx_sriomaintx_core_enables_t core_enables;
 	cvmx_sriomaintx_port_gen_ctl_t port_gen_ctl;
-	cvmx_sriox_status_reg_t sriox_status_reg;
+	cvmx_sriox_status_reg_t status_reg;
 	cvmx_sriox_imsg_vport_thr_t sriox_imsg_vport_thr;
 	cvmx_rst_ctlx_t rst_ctl;
 	cvmx_rst_soft_prstx_t prst;
@@ -451,7 +507,6 @@ cvmx_srio_init_cn75xx(int srio_port, cvmx_srio_initialize_flags_t flags)
 	cvmx_dpi_sli_prtx_cfg_t prt_cfg;
 	cvmx_sriomaintx_port_0_ctl2_t port_0_ctl2;
 	unsigned rst_port, sli_port;
-	enum cvmx_qlm_mode mode;
 
 	/* Check 'srio_port" range */
 	if (srio_port > 1 || srio_port < 0) {
@@ -459,62 +514,62 @@ cvmx_srio_init_cn75xx(int srio_port, cvmx_srio_initialize_flags_t flags)
 		return -1;
 	}
 
-	sriox_status_reg.u64 = cvmx_read_csr(CVMX_SRIOX_STATUS_REG(srio_port));
-
-	if (debug)
-		cvmx_dprintf("%s: srio_port %d stat_reg=%#llx\n",
-			__func__, srio_port, CAST_ULL(sriox_status_reg.u64));
-
-	sriox_status_reg.s.srio = 1;
-	cvmx_write_csr(CVMX_SRIOX_STATUS_REG(srio_port),sriox_status_reg.u64);
-
-	if (!sriox_status_reg.s.srio) {
-		cvmx_dprintf("SRIO%d: Initialization called on a port not in SRIO mode\n", srio_port);
-		return -1;
-	}
-	/* SRIO0 -> QLM0, SRIO1 -> QLM1 */
-	mode = cvmx_qlm_get_mode(srio_port);
-
-	/* Don't receive or drive reset signals for the SRIO QLM */
-	/* SerDes reset handling is in QLM module now */
-	(void) mode;	/* FIXME: inspect if QLM is alive */
-
-	__cvmx_srio_state[srio_port].flags = flags;
-
-	// FIXME: copied these settings from old models, review.
-
 	rst_port = __cvmx_srio_to_rst(srio_port);
 	rst_ctl.u64 = cvmx_read_csr(CVMX_RST_CTLX(rst_port));
-	rst_ctl.s.rst_drv = 0;
-	rst_ctl.s.rst_rcv = 0;
-	rst_ctl.s.rst_chip = 0;
-	cvmx_write_csr(CVMX_RST_CTLX(rst_port), rst_ctl.u64);
-
-	rst_ctl.u64 = cvmx_read_csr(CVMX_RST_CTLX(srio_port));
 
 	cvmx_dprintf("INFO: SRIO%d: Port in %s mode\n",
 		srio_port, (rst_ctl.s.host_mode) ? "host" : "endpoint");
 
-	/* Bring the port out of reset if necessary */
-	prst.u64 = cvmx_read_csr(CVMX_RST_SOFT_PRSTX(rst_port));
-
-	if (debug)
-		cvmx_dprintf("%s: SOFT_PRST%u=%#llx\n",
-			__func__, rst_port, CAST_ULL(prst.u64));
-
-	if (prst.s.soft_prst) {
+	/* Reset sequence is different if SRIO is in host mode or EP mode */
+	if (rst_ctl.s.host_mode) { /* host mode */
+		prst.u64 = cvmx_read_csr(CVMX_RST_SOFT_PRSTX(rst_port));
+		if (prst.s.soft_prst == 0) {
+			/* Reset the port */
+			prst.s.soft_prst = 1;
+			cvmx_write_csr(CVMX_RST_SOFT_PRSTX(rst_port), prst.u64);
+			/* Wait until SRIO resets the port */
+			cvmx_wait_usec(2000);
+		}
+		prst.u64 = cvmx_read_csr(CVMX_RST_SOFT_PRSTX(rst_port));
 		prst.s.soft_prst = 0;
 		cvmx_write_csr(CVMX_RST_SOFT_PRSTX(rst_port), prst.u64);
-		if (CVMX_WAIT_FOR_FIELD64(
-		    CVMX_SRIOX_STATUS_REG(srio_port),
-			cvmx_sriox_status_reg_t, access, ==, 1, 250000)) {
-			cvmx_printf("ERROR: %s: SRIO%u stuck in reset\n",
-				__func__, srio_port);
+
+		/* Wait for SRIO to reset completely */
+		cvmx_wait_usec(1000);
+
+		/* Check and make sure PCIe came out of reset. If it doesn't the board
+	   	probably hasn't wired the clocks up and the interface should be
+	   	skipped */
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_RST_CTLX(rst_port), cvmx_mio_rst_ctlx_t,
+					rst_done, ==, 1, 10000)) {
+			cvmx_dprintf("SRIO%d stuck in reset, skipping.\n", srio_port);
 			return -1;
 		}
+	}
+
+	/* Enable SRIO mode */
+	status_reg.u64 = cvmx_read_csr(CVMX_SRIOX_STATUS_REG(srio_port));
+	status_reg.s.srio = 1;
+	cvmx_write_csr(CVMX_SRIOX_STATUS_REG(srio_port), status_reg.u64);
+
+	/* Make sure SRIOx_STATUS_REG.access is set, needed to program
+	   additional SRIO and SRIOx Maintaince registers */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_SRIOX_STATUS_REG(srio_port),
+			cvmx_sriox_status_reg_t, access, ==, 1, 250000)) {
+		cvmx_dprintf("SRIO%d access not set, skipping.\n", srio_port);
+		return -1;
+	}
 
+	if (debug) {
+		status_reg.u64 = cvmx_read_csr(CVMX_SRIOX_STATUS_REG(srio_port));
+		cvmx_dprintf("%s: srio_port %d stat_reg=%#llx\n",
+			__func__, srio_port, CAST_ULL(status_reg.u64));
 	}
 
+	__cvmx_srio_state[srio_port].flags = flags;
+
+	// FIXME: copied these settings from old models, review.
+
 	/* Disable the link while we make changes */
 	if (__cvmx_srio_local_read32(srio_port,
 	    CVMX_SRIOMAINTX_PORT_0_CTL(srio_port), &port_0_ctl.u32)) {
@@ -592,7 +647,7 @@ cvmx_srio_init_cn75xx(int srio_port, cvmx_srio_initialize_flags_t flags)
 
 	/* Setup RX messaging thresholds */
 	sriox_imsg_vport_thr.u64 = cvmx_read_csr(CVMX_SRIOX_IMSG_VPORT_THR(srio_port));
-	sriox_imsg_vport_thr.cnf75xx.base = 8 + 44 * srio_port;
+	sriox_imsg_vport_thr.cnf75xx.base = 8 + (44 * srio_port);
 	sriox_imsg_vport_thr.cnf75xx.max_tot = 44;
 	sriox_imsg_vport_thr.cnf75xx.sp_vport = 1;
 	sriox_imsg_vport_thr.cnf75xx.buf_thr = 8;
@@ -638,11 +693,7 @@ cvmx_srio_init_cn75xx(int srio_port, cvmx_srio_initialize_flags_t flags)
 	sli_mem_access_ctl.u64 = cvmx_read_csr(CVMX_PEXP_SLI_MEM_ACCESS_CTL);
 	sli_mem_access_ctl.s.max_word = 0;	/* Allow 16 words to combine */
 	sli_mem_access_ctl.s.timer = 127;	/* Wait up to 127 cycles for more data */
-	/* This register is also set in cvmx_pcie.c */
 	cvmx_write_csr(CVMX_PEXP_SLI_MEM_ACCESS_CTL, sli_mem_access_ctl.u64);
-
-	// FIXME: Conflict with PCIe settings for SLI ?
-
 	return 0;
 }
 
@@ -741,9 +792,6 @@ cvmx_srio_init_cn6xxx(int srio_port, cvmx_srio_initialize_flags_t flags)
 			if (prst.s.soft_prst) {
 				prst.s.soft_prst = 0;
 				cvmx_write_csr(CVMX_CIU_SOFT_PRST, prst.u64);
-				/* Wait up to 250ms for the port to come out of reset */
-				if (CVMX_WAIT_FOR_FIELD64(CVMX_SRIOX_STATUS_REG(srio_port), cvmx_sriox_status_reg_t, access, ==, 1, 250000))
-					return -1;
 			}
 			break;
 		}
@@ -754,9 +802,6 @@ cvmx_srio_init_cn6xxx(int srio_port, cvmx_srio_initialize_flags_t flags)
 			if (prst.s.soft_prst) {
 				prst.s.soft_prst = 0;
 				cvmx_write_csr(CVMX_CIU_SOFT_PRST1, prst.u64);
-				/* Wait up to 250ms for the port to come out of reset */
-				if (CVMX_WAIT_FOR_FIELD64(CVMX_SRIOX_STATUS_REG(srio_port), cvmx_sriox_status_reg_t, access, ==, 1, 250000))
-					return -1;
 			}
 			break;
 		}
@@ -767,9 +812,6 @@ cvmx_srio_init_cn6xxx(int srio_port, cvmx_srio_initialize_flags_t flags)
 			if (prst.s.soft_prst) {
 				prst.s.soft_prst = 0;
 				cvmx_write_csr(CVMX_CIU_SOFT_PRST2, prst.u64);
-				/* Wait up to 250ms for the port to come out of reset */
-				if (CVMX_WAIT_FOR_FIELD64(CVMX_SRIOX_STATUS_REG(srio_port), cvmx_sriox_status_reg_t, access, ==, 1, 250000))
-					return -1;
 			}
 			break;
 		}
@@ -780,14 +822,17 @@ cvmx_srio_init_cn6xxx(int srio_port, cvmx_srio_initialize_flags_t flags)
 			if (prst.s.soft_prst) {
 				prst.s.soft_prst = 0;
 				cvmx_write_csr(CVMX_CIU_SOFT_PRST3, prst.u64);
-				/* Wait up to 250ms for the port to come out of reset */
-				if (CVMX_WAIT_FOR_FIELD64(CVMX_SRIOX_STATUS_REG(srio_port), cvmx_sriox_status_reg_t, access, ==, 1, 250000))
-					return -1;
 			}
 			break;
 		}
 	}
 
+	/* Wait up to 250ms for the registers to become accessible */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_SRIOX_STATUS_REG(srio_port),
+				  cvmx_sriox_status_reg_t, access, ==, 1,
+				  250000))
+		return -1;
+
 	/* Disable the link while we make changes */
 	if (__cvmx_srio_local_read32(srio_port, CVMX_SRIOMAINTX_PORT_0_CTL(srio_port), &port_0_ctl.u32))
 		return -1;
diff --git a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
index 789990f..71e7cfe 100644
--- a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
@@ -694,6 +694,7 @@ static inline uint64_t CVMX_BGXX_CMR_ECO(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 5))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2)))))
 		cvmx_warn("CVMX_BGXX_CMR_ECO(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800E0001028ull) + ((offset) & 7) * 0x1000000ull;
@@ -2611,10 +2612,10 @@ union cvmx_bgxx_cmrx_rx_id_map {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
 	uint64_t rid                          : 7;  /**< Reassembly ID map for this LMAC. A shared pool of 96 reassembly IDs (RIDs) exists for all
-                                                         MACs.
+                                                         MACs. See PKI_REASM_E.
                                                          The RID for this LMAC must be constrained such that it does not overlap with any other MAC
                                                          in the system. Its reset value has been chosen such that this condition is satisfied:
-                                                         _ RID reset value = 4*(BGX_ID + 1) + LMAC_ID
+                                                         _ RID reset value = 4 + (4*BGX_ID) + LMAC_ID
                                                          Changes to RID must only occur when the LMAC is quiescent (i.e. the LMAC receive interface
                                                          is down and the RX FIFO is empty). */
 	uint64_t pknd                         : 8;  /**< Port kind for this LMAC. */
@@ -2627,11 +2628,11 @@ union cvmx_bgxx_cmrx_rx_id_map {
 	struct cvmx_bgxx_cmrx_rx_id_map_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t rid                          : 7;  /**< Reassembly ID map for this LMAC. A shared pool of 96 reassembly IDs (RIDs) exists for all
-                                                         MACs.
+	uint64_t rid                          : 7;  /**< Reassembly ID map for this LMAC. A shared pool of 14 reassembly IDs (RIDs) exists for all
+                                                         MACs. See PKI_REASM_E.
                                                          The RID for this LMAC must be constrained such that it does not overlap with any other MAC
-                                                         in the system. Its reset value has been chosen such that this condition is satisfied:
-                                                         _ RID reset value = 4*(BGX_ID + 1) + LMAC_ID
+                                                         in the system. Suggested programming values for each LMAC are:
+                                                         _ RID reset value = 2 + (4*BGX_ID) + LMAC_ID
                                                          Changes to RID must only occur when the LMAC is quiescent (i.e. the LMAC receive interface
                                                          is down and the RX FIFO is empty). */
 	uint64_t reserved_6_7                 : 2;
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
index f73a075..5e7b63c 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
@@ -217,8 +217,8 @@ static inline uint64_t CVMX_CIU_DINT_FUNC(void)
 			return CVMX_ADD_IO_SEG(0x0001070000000720ull);
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000000180ull);
 			break;
 	}
@@ -245,8 +245,8 @@ static inline uint64_t CVMX_CIU_DINT_FUNC(void)
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001070000000720ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000000180ull);
 	}
 	return CVMX_ADD_IO_SEG(0x0001010000000180ull);
@@ -441,8 +441,8 @@ static inline uint64_t CVMX_CIU_FUSE_FUNC(void)
 			return CVMX_ADD_IO_SEG(0x0001070000000728ull);
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00010100000001A0ull);
 			break;
 	}
@@ -469,8 +469,8 @@ static inline uint64_t CVMX_CIU_FUSE_FUNC(void)
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001070000000728ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00010100000001A0ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00010100000001A0ull);
@@ -970,8 +970,8 @@ static inline uint64_t CVMX_CIU_PP_DBG_FUNC(void)
 			return CVMX_ADD_IO_SEG(0x0001070000000708ull);
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000000120ull);
 			break;
 	}
@@ -998,8 +998,8 @@ static inline uint64_t CVMX_CIU_PP_DBG_FUNC(void)
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001070000000708ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000000120ull);
 	}
 	return CVMX_ADD_IO_SEG(0x0001010000000120ull);
@@ -1114,8 +1114,8 @@ static inline uint64_t CVMX_CIU_PP_RST_FUNC(void)
 			return CVMX_ADD_IO_SEG(0x0001070000000700ull);
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000000100ull);
 			break;
 	}
@@ -1142,8 +1142,8 @@ static inline uint64_t CVMX_CIU_PP_RST_FUNC(void)
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001070000000700ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000000100ull);
 	}
 	return CVMX_ADD_IO_SEG(0x0001010000000100ull);
@@ -1155,8 +1155,8 @@ static inline uint64_t CVMX_CIU_PP_RST_PENDING_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000000110ull);
 			break;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
@@ -1172,8 +1172,8 @@ static inline uint64_t CVMX_CIU_PP_RST_PENDING_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000000110ull);
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001070000000740ull);
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
index 7318cef..d05da67 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
@@ -628,8 +628,9 @@ union cvmx_ciu3_intr_ready {
 	uint64_t index                        : 14; /**< Scanner index. If [READY] set, the current index, else the index the scanner stopped at.
                                                          For diagnostic use only. */
 	uint64_t reserved_1_31                : 31;
-	uint64_t ready                        : 1;  /**< CIU is idle. If clear, CIU is performing a background scan searching for secondary
-                                                         interrupts. Write one to force a new scan. For diagnostic use only. */
+	uint64_t ready                        : 1;  /**< CIU background scanner is running. If set, CIU is performing a background scan searching
+                                                         for
+                                                         secondary interrupts. Write one to force a new scan. For diagnostic use only. */
 #else
 	uint64_t ready                        : 1;
 	uint64_t reserved_1_31                : 31;
diff --git a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
index 79d3d32..bc9d2c6 100644
--- a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
@@ -864,7 +864,7 @@ union cvmx_dpi_dmax_err_rsp_status {
 	struct cvmx_dpi_dmax_err_rsp_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
-	uint64_t status                       : 6;  /**< QUE captures the ErrorResponse status of the last 6 instructions for each instruction
+	uint64_t status                       : 6;  /**< STATUS captures the ErrorResponse status of the last 6 instructions for each instruction
                                                          queue. STATUS<5> represents the status for first instruction in instruction order while
                                                          STATUS<0> represents the last or most recent instruction. If STATUS<n> is set, then the
                                                          Nth instruction in the given queue experienced an ErrorResponse. Otherwise, it completed
@@ -1219,23 +1219,41 @@ union cvmx_dpi_dma_control {
 	uint64_t dma_enb                      : 6;  /**< DMA engine enable. Enables the operation of the DMA engine. After being enabled an engine
                                                          should not be disabled while processing instructions.
                                                          When PKT_EN=1, then DMA_ENB<5>=0 and DMA_ENB<4>=0. */
-	uint64_t wqecsdis                     : 1;  /**< Work queue completion status disable. */
-	uint64_t wqecsoff                     : 7;  /**< Work queue completion status offset. */
-	uint64_t zbwcsen                      : 1;  /**< Zero-byte-write completion status enable. */
-	uint64_t wqecsmode                    : 2;  /**< WQE completion status mode.
-                                                         0x0 = Default behavior. Only instructions with exceptions will issue completion
-                                                         status write and must wait for commit.
-                                                         0x1 = All DPI_DMA_INSTR_HDR_S[PT]=0x2 instructions will have a completion status
-                                                         write.
+	uint64_t wqecsdis                     : 1;  /**< Work queue completion status disable. See DPI_HDR_PT_WQP_E.
+                                                         When [WQECSDIS] is set, DPI never writes completion status into a work queue entry. */
+	uint64_t wqecsoff                     : 7;  /**< Work queue completion status byte offset. For a DPI_HDR_PT_WQP_E::STATUSCA
+                                                         or DPI_HDR_PT_WQP_E::STATUSNC DPI DMA instruction, DPI writes a
+                                                         non-DPI_CS_E::NOERR (i.e. non-zero) completion status byte to (big-endian
+                                                         byte address) L2/DRAM address
+                                                            (DPI_DMA_INSTR_HDR_S[PTR] & 0xFFFFFFFFFFFFFFF8) + [WQECSOFF]
+                                                         With the reset value 0x7, DPI will write WORD0<7:0> of the WQE. */
+	uint64_t zbwcsen                      : 1;  /**< Zero-byte-write completion status enable.
+                                                         See DPI_HDR_PT_E::ZBC_CA and DPI_HDR_PT_E::ZBC_NC. */
+	uint64_t wqecsmode                    : 2;  /**< WQE completion status mode. Relevant for DPI DMA instructions with
+                                                         DPI_DMA_INSTR_HDR_S[PT]=DPI_HDR_PT_E::WQP when [WQECSDIS]=0.
+                                                         0x0 = Normal behavior. DPI will not write the completion status byte for
+                                                               DPI_HDR_PT_E::WQP DPI DMA instructions with DPI_CS_E::NOERR (i.e. zero)
+                                                               completion status, regardless of the DPI_HDR_PT_WQP_E selection of
+                                                               DPI_DMA_INSTR_HDR_S[PTR<2:0>]. DPI will write the completion
+                                                               status byte for all other DPI_CS_E (i.e. non-zero) values
+                                                               when DPI_DMA_INSTR_HDR_S[PTR<2:0>] is DPI_HDR_PT_WQP_E::STATUSCA
+                                                               or DPI_HDR_PT_WQP_E::STATUSNC and [WQECSDIS] is clear.
+                                                         0x1 = DPI will perform the completion status byte write for all
+                                                               DPI_HDR_PT_E::WQP DPI DMA instructions when DPI_DMA_INSTR_HDR_S[PTR<2:0>]
+                                                               is DPI_HDR_PT_WQP_E::STATUSCA or DPI_HDR_PT_WQP_E::STATUSNC
+                                                               and [WQECSDIS] is clear, regardless of the DPI_CS_E completion
+                                                               status value for the instruction.
                                                          0x2 = DPI will not wait for the completion status write commit before issuing
-                                                         SSO work queue add.
+                                                               SSO work queue add.
                                                          0x3 = Both debug modes specified above (under 0x1 and 0x2) are enabled. */
 	uint64_t reserved_35_36               : 2;
 	uint64_t ncb_tag                      : 1;  /**< NCB tag enable. It allows DMA Read/Write transactions over NCB to be mapped to
                                                          individual request queues by using tags. This enables more parallelism, giving a
                                                          performance boost. */
-	uint64_t b0_lend                      : 1;  /**< Little-endian. When set to 1 and the DPI is in the mode to write 0 to L2C when a DMA
-                                                         transaction is done, the address to be written is treated as a little-endian address. */
+	uint64_t b0_lend                      : 1;  /**< Endian-ness for DPI_HDR_PT_E::ZBC_CA and DPI_HDR_PT_E::ZBC_NC DPI DMA
+                                                         instructions. When clear, DPI_DMA_INSTR_HDR_S[PTR] is big-endian for
+                                                         these instructions. When set, DPI_DMA_INSTR_HDR_S[PTR] is little-endian
+                                                         for these instructions. */
 	uint64_t reserved_20_32               : 13;
 	uint64_t o_add1                       : 1;  /**< Add one.
                                                          0 = The number of bytes in the DMA transfer is added to SLI_DMA()_CNT.
@@ -1243,10 +1261,7 @@ union cvmx_dpi_dma_control {
 	uint64_t o_ro                         : 1;  /**< Relaxed ordering mode for DMA transactions */
 	uint64_t o_ns                         : 1;  /**< No snoop. */
 	uint64_t o_es                         : 2;  /**< Endian swap mode for DMA.
-                                                         0 = pass-through mode (no swap).
-                                                         1 = 64-bit byte-swap mode [ABCD_EFGH] -> [HGFE_DCBA].
-                                                         2 = 32-bit byte-swap mode [ABCD_EFGH] -> [DCBA_HGFE].
-                                                         3 = 32-bit exchange mode [ABCD_EFGH] -> [EFGH_ABCD]. */
+                                                         See SLI_ENDIANSWAP_E. */
 	uint64_t o_mode                       : 1;  /**< Select PCI_POINTER mode.
                                                          0 = DPTR format 1 is used. Use register values for address; use pointer values for ES, NS,
                                                          RO.
@@ -1586,27 +1601,45 @@ union cvmx_dpi_dma_control {
 	uint64_t dma_enb                      : 6;  /**< DMA engine enable. Enables the operation of the DMA engine. After being enabled an engine
                                                          should not be disabled while processing instructions.
                                                          When PKT_EN=1, then DMA_ENB<5>=0 and DMA_ENB<4>=0. */
-	uint64_t wqecsdis                     : 1;  /**< Work queue completion status disable. */
-	uint64_t wqecsoff                     : 7;  /**< Work queue completion status offset. */
-	uint64_t zbwcsen                      : 1;  /**< Zero-byte-write completion status enable. */
-	uint64_t wqecsmode                    : 2;  /**< WQE completion status mode.
-                                                         0x0 = Default behavior. Only instructions with exceptions will issue completion
-                                                         status write and must wait for commit.
-                                                         0x1 = All DPI_DMA_INSTR_HDR_S[PT]=0x2 instructions will have a completion status
-                                                         write.
+	uint64_t wqecsdis                     : 1;  /**< Work queue completion status disable. See DPI_HDR_PT_WQP_E.
+                                                         When [WQECSDIS] is set, DPI never writes completion status into a work queue entry. */
+	uint64_t wqecsoff                     : 7;  /**< Work queue completion status byte offset. For a DPI_HDR_PT_WQP_E::STATUSCA
+                                                         or DPI_HDR_PT_WQP_E::STATUSNC DPI DMA instruction, DPI writes a
+                                                         non-DPI_CS_E::NOERR (i.e. non-zero) completion status byte to (big-endian
+                                                         byte address) L2/DRAM address
+                                                            (DPI_DMA_INSTR_HDR_S[PTR] & 0xFFFFFFFFFFFFFFF8) + [WQECSOFF]
+                                                         With the reset value 0x7, DPI will write WORD0<7:0> of the WQE. */
+	uint64_t zbwcsen                      : 1;  /**< Zero-byte-write completion status enable.
+                                                         See DPI_HDR_PT_E::ZBC_CA and DPI_HDR_PT_E::ZBC_NC. */
+	uint64_t wqecsmode                    : 2;  /**< WQE completion status mode. Relevant for DPI DMA instructions with
+                                                         DPI_DMA_INSTR_HDR_S[PT]=DPI_HDR_PT_E::WQP when [WQECSDIS]=0.
+                                                         0x0 = Normal behavior. DPI will not write the completion status byte for
+                                                               DPI_HDR_PT_E::WQP DPI DMA instructions with DPI_CS_E::NOERR (i.e. zero)
+                                                               completion status, regardless of the DPI_HDR_PT_WQP_E selection of
+                                                               DPI_DMA_INSTR_HDR_S[PTR<2:0>]. DPI will write the completion
+                                                               status byte for all other DPI_CS_E (i.e. non-zero) values
+                                                               when DPI_DMA_INSTR_HDR_S[PTR<2:0>] is DPI_HDR_PT_WQP_E::STATUSCA
+                                                               or DPI_HDR_PT_WQP_E::STATUSNC and [WQECSDIS] is clear.
+                                                         0x1 = DPI will perform the completion status byte write for all
+                                                               DPI_HDR_PT_E::WQP DPI DMA instructions when DPI_DMA_INSTR_HDR_S[PTR<2:0>]
+                                                               is DPI_HDR_PT_WQP_E::STATUSCA or DPI_HDR_PT_WQP_E::STATUSNC
+                                                               and [WQECSDIS] is clear, regardless of the DPI_CS_E completion
+                                                               status value for the instruction.
                                                          0x2 = DPI will not wait for the completion status write commit before issuing
-                                                         SSO work queue add.
+                                                               SSO work queue add.
                                                          0x3 = Both debug modes specified above (under 0x1 and 0x2) are enabled. */
 	uint64_t reserved_35_36               : 2;
 	uint64_t ncb_tag                      : 1;  /**< NCB tag enable. It allows DMA Read/Write transactions over NCB to be mapped to
                                                          individual request queues by using tags. This enables more parallelism, giving a
                                                          performance boost. */
-	uint64_t b0_lend                      : 1;  /**< Little-endian. When set to 1 and the DPI is in the mode to write 0 to L2C when a DMA
-                                                         transaction is done, the address to be written is treated as a little-endian address. */
-	uint64_t ldwb                         : 1;  /**< Load don't write back. When set, the hardware is able to issue LDWB commands to the cache.
-                                                         As a result, the line will not be written back when replaced. When clear, the hardware
-                                                         issues regular load commands to the cache which cause the line to be written back before
-                                                         being replaced. */
+	uint64_t b0_lend                      : 1;  /**< Endian-ness for DPI_HDR_PT_E::ZBC_CA and DPI_HDR_PT_E::ZBC_NC DPI DMA
+                                                         instructions. When clear, DPI_DMA_INSTR_HDR_S[PTR] is big-endian for
+                                                         these instructions. When set, DPI_DMA_INSTR_HDR_S[PTR] is little-endian
+                                                         for these instructions. */
+	uint64_t ldwb                         : 1;  /**< Load don't write back. When set, the hardware is able to issue LDWB commands for pointers
+                                                         that are being freed. As a result, the line will not be written back when replaced.
+                                                         When clear, the hardware issues regular load commands to the cache which cause the
+                                                         line to be written back before being replaced. */
 	uint64_t aura_ichk                    : 12; /**< AURA instruction chunk. The AURA that the instruction chunk for DMA operations page will
                                                          be returned to when freed. */
 	uint64_t o_add1                       : 1;  /**< Add one.
@@ -1615,10 +1648,7 @@ union cvmx_dpi_dma_control {
 	uint64_t o_ro                         : 1;  /**< Relaxed ordering mode for DMA transactions */
 	uint64_t o_ns                         : 1;  /**< No snoop. */
 	uint64_t o_es                         : 2;  /**< Endian swap mode for DMA.
-                                                         0 = pass-through mode (no swap).
-                                                         1 = 64-bit byte-swap mode [ABCD_EFGH] -> [HGFE_DCBA].
-                                                         2 = 32-bit byte-swap mode [ABCD_EFGH] -> [DCBA_HGFE].
-                                                         3 = 32-bit exchange mode [ABCD_EFGH] -> [EFGH_ABCD]. */
+                                                         See SLI_ENDIANSWAP_E. */
 	uint64_t o_mode                       : 1;  /**< Select PCI_POINTER mode.
                                                          0 = DPTR format 1 is used. Use register values for address; use pointer values for ES, NS,
                                                          RO.
@@ -1730,12 +1760,13 @@ union cvmx_dpi_dma_ppx_cnt {
 	struct cvmx_dpi_dma_ppx_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t cnt                          : 16; /**< DPI DMA per-core instruction completion counter. The counter is incremented according to
-                                                         conditions described below and is decremented by values written to this field. A CNT of
-                                                         nonzero causes an interrupt in DPI_DMA_PP_INT.
-                                                         Each DMA instruction that has the DPI_DMA_INSTR_HDR_S[PT]=CNT and a PTR value of 1 to
-                                                         0x30 will increment DPI_DMA_PP()_CNT value -1 counter. Hardware reserves the values
-                                                         0x31 to 0x3F for future use, treats them as a PTR of 0, and does nothing. */
+	uint64_t cnt                          : 16; /**< DPI DMA per-core instruction completion counter. DPI can increment a counter upon
+                                                         completion of a DPI DMA instruction. DPI subtracts the value written
+                                                         from [CNT] on a software write. A nonzero [CNT] asserts the corresponding
+                                                         DPI_DMA_PP_INT bit and a 0->1 [CNT] transition throws the corresponding
+                                                         DPI_INTSN_E::DPI_DMA_PP()_INT.
+                                                         DPI increments the [CNT] selected by DPI_DMA_INSTR_HDR_S[PTR] by one after completing
+                                                         a DPI_DMA_INSTR_HDR_S[PT]=DPI_HDR_PT_E::CNT DPI DMA instruction. */
 #else
 	uint64_t cnt                          : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1761,7 +1792,8 @@ union cvmx_dpi_dma_pp_int {
 	struct cvmx_dpi_dma_pp_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t complete                     : 48; /**< DPI DMA per-core instruction completion interrupt. See DPI_DMA_PP()_CNT. */
+	uint64_t complete                     : 48; /**< DPI DMA per-core instruction completion interrupt. See DPI_DMA_PP()_CNT
+                                                         and DPI_INTSN_E::DPI_DMA_PP()_INT. */
 #else
 	uint64_t complete                     : 48;
 	uint64_t reserved_48_63               : 16;
@@ -1770,7 +1802,8 @@ union cvmx_dpi_dma_pp_int {
 	struct cvmx_dpi_dma_pp_int_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t complete                     : 16; /**< DPI DMA per-core instruction completion interrupt. See DPI_DMA_PP()_CNT. */
+	uint64_t complete                     : 16; /**< DPI DMA per-core instruction completion interrupt. See DPI_DMA_PP()_CNT
+                                                         and DPI_INTSN_E::DPI_DMA_PP()_INT. */
 #else
 	uint64_t complete                     : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1987,9 +2020,9 @@ union cvmx_dpi_info_reg {
 	uint64_t reserved_8_63                : 56;
 	uint64_t ffp                          : 4;  /**< Force forward progress indicator. */
 	uint64_t reserved_2_3                 : 2;
-	uint64_t ncb                          : 1;  /**< NCB register access. This interrupt fires in normal operation when software reads a DPI
+	uint64_t ncb                          : 1;  /**< NCB register access. This bit gets set in normal operation when software reads a DPI
                                                          register through the IOI interface. */
-	uint64_t rsl                          : 1;  /**< RSL register access. This interrupt fires in normal operation when software reads a DPI
+	uint64_t rsl                          : 1;  /**< RSL register access. This bit is set in normal operation when software reads a DPI
                                                          register through the RSL interface. */
 #else
 	uint64_t rsl                          : 1;
@@ -2190,10 +2223,18 @@ union cvmx_dpi_int_reg {
 	struct cvmx_dpi_int_reg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t sprt3_rst                    : 1;  /**< Reserved. */
-	uint64_t sprt2_rst                    : 1;  /**< Reserved. */
-	uint64_t sprt1_rst                    : 1;  /**< Reserved. */
-	uint64_t sprt0_rst                    : 1;  /**< Reserved. */
+	uint64_t sprt3_rst                    : 1;  /**< DMA instruction was dropped because the source or
+                                                          destination port was in reset.
+                                                         this bit is set. */
+	uint64_t sprt2_rst                    : 1;  /**< DMA instruction was dropped because the source or
+                                                          destination port was in reset.
+                                                         this bit is set. */
+	uint64_t sprt1_rst                    : 1;  /**< DMA instruction was dropped because the source or
+                                                          destination port was in reset.
+                                                         this bit is set. */
+	uint64_t sprt0_rst                    : 1;  /**< DMA instruction was dropped because the source or
+                                                          destination port was in reset.
+                                                         this bit is set. */
 	uint64_t reserved_23_23               : 1;
 	uint64_t req_badfil                   : 1;  /**< Unexpected fill error. This bit is set when an instruction fill is received when there is
                                                          no outstanding request. Throws DPI_INTSN_E::DPI_INT_REQ_BADFIL. */
@@ -2307,11 +2348,55 @@ union cvmx_dpi_int_reg {
 	struct cvmx_dpi_int_reg_cn63xx        cn68xxp1;
 	struct cvmx_dpi_int_reg_s             cn70xx;
 	struct cvmx_dpi_int_reg_s             cn70xxp1;
-	struct cvmx_dpi_int_reg_s             cn73xx;
+	struct cvmx_dpi_int_reg_cn73xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_23_63               : 41;
+	uint64_t req_badfil                   : 1;  /**< Unexpected fill error. This bit is set when an instruction fill is received when there is
+                                                         no outstanding request. Throws DPI_INTSN_E::DPI_INT_REQ_BADFIL. */
+	uint64_t req_inull                    : 1;  /**< Interrupt should be ignored. INTERNAL: The interrupt means that the DPI unit
+                                                         received fill data in which one or more or the 64-bit instruction words was all
+                                                         0's. In previous DPI implementations, there was never a case in which a valid
+                                                         instruction stream would have all 0's. In the new dual-instruction word scheme,
+                                                         the 2nd word could be zero. For example, if no completion operation is requested
+                                                         on the instruction and both PTR and DEALLOCV are zero. */
+	uint64_t req_anull                    : 1;  /**< Instruction bad error. This bit is set when a fetched instruction word was 0x0. Throws
+                                                         DPI_INTSN_E::DPI_INT_REQ_ANULL. */
+	uint64_t req_undflw                   : 1;  /**< Instruction FIFO underflow error. This bit is set when the instruction FIFO underflows.
+                                                         Throws DPI_INTSN_E::DPI_INT_REQ_UNDFLW. */
+	uint64_t req_ovrflw                   : 1;  /**< Instruction FIFO overflow error. This bit is set when the instruction FIFO overflows.
+                                                         Throws DPI_INTSN_E::DPI_INT_REQ_OVRFLW. */
+	uint64_t req_badlen                   : 1;  /**< Fetch with length zero error. This bit is set when DPI forms an instruction fetch with
+                                                         length of zero. Throws DPI_INTSN_E::DPI_INT_REQ_BADLEN. */
+	uint64_t req_badadr                   : 1;  /**< Fetch with bad pointer error. This bit is set when DPI forms an instruction fetch to the
+                                                         NULL pointer. Throws DPI_INTSN_E::DPI_INT_REQ_BADADR. */
+	uint64_t dmadbo                       : 8;  /**< Doorbell overflow error. DPI has a 32-bit counter for each request queue's outstanding
+                                                         doorbell counts. A bit is set when the corresponding doorbell count overflows. Throws
+                                                         DPI_INTSN_E::DPI_INT_DMADBO(). */
+	uint64_t reserved_2_7                 : 6;
+	uint64_t nfovr                        : 1;  /**< CSR FIFO overflow error. DPI can store up to 16 CSR requests, and the FIFO overflows if
+                                                         that number is exceeded. Throws DPI_INTSN_E::DPI_INT_NFOVR. */
+	uint64_t nderr                        : 1;  /**< IOI decode error. This bit is set when the DPI received an IOI transaction on the outbound
+                                                         bus to the DPI device ID, but the command was not recognized. Throws
+                                                         DPI_INTSN_E::DPI_INT_NDERR. */
+#else
+	uint64_t nderr                        : 1;
+	uint64_t nfovr                        : 1;
+	uint64_t reserved_2_7                 : 6;
+	uint64_t dmadbo                       : 8;
+	uint64_t req_badadr                   : 1;
+	uint64_t req_badlen                   : 1;
+	uint64_t req_ovrflw                   : 1;
+	uint64_t req_undflw                   : 1;
+	uint64_t req_anull                    : 1;
+	uint64_t req_inull                    : 1;
+	uint64_t req_badfil                   : 1;
+	uint64_t reserved_23_63               : 41;
+#endif
+	} cn73xx;
 	struct cvmx_dpi_int_reg_s             cn78xx;
-	struct cvmx_dpi_int_reg_s             cn78xxp2;
+	struct cvmx_dpi_int_reg_cn73xx        cn78xxp2;
 	struct cvmx_dpi_int_reg_s             cnf71xx;
-	struct cvmx_dpi_int_reg_s             cnf75xx;
+	struct cvmx_dpi_int_reg_cn73xx        cnf75xx;
 };
 typedef union cvmx_dpi_int_reg cvmx_dpi_int_reg_t;
 
@@ -2348,7 +2433,7 @@ typedef union cvmx_dpi_ncbx_cfg cvmx_dpi_ncbx_cfg_t;
 /**
  * cvmx_dpi_ncb_ctl
  *
- * This register chooses which NCB interface to direct traffic for internal only transactions.
+ * This register chooses which NCB interface DPI uses for L2/DRAM reads/writes.
  *
  */
 union cvmx_dpi_ncb_ctl {
@@ -2356,23 +2441,51 @@ union cvmx_dpi_ncb_ctl {
 	struct cvmx_dpi_ncb_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
-	uint64_t ncbsel_prt_xor_dis           : 1;  /**< Disable the inclusion of the instruction header LPORT field when computing the NCB bus. */
+	uint64_t ncbsel_prt_xor_dis           : 1;  /**< When set, prevents DPI_DMA_INSTR_HDR_S[FPORT,LPORT] from determining the IOI/NCB
+                                                         DPI uses to process instructions. See [NCBSEL_SRC], [NCBSEL_DST], and
+                                                         DPI_SLI_PRT()_CFG[NCBSEL]. */
 	uint64_t reserved_21_23               : 3;
-	uint64_t ncbsel_zbw                   : 1;  /**< ZBW select.
-                                                         0 = Zero-byte-write transaction will make requests and receive responses using NCB2.
-                                                         1 = Zero-byte-write transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel_zbw                   : 1;  /**< Selects the IOBI/NCBI bus DPI uses for byte status writes by any DPI_HDR_PT_E::ZBW_CA,
+                                                         DPI_HDR_PT_E::ZBW_NC, or DPI_HDR_PT_E::WQP DPI DMA instructions.
+                                                         0 = DPI uses IOBI2/NCBI2 for all byte status writes
+                                                         1 = DPI uses IOBI3/NCBI3 for all byte status writes */
 	uint64_t reserved_17_19               : 3;
-	uint64_t ncbsel_req                   : 1;  /**< Request select.
-                                                         0 = Instruction request transaction will make requests and receive responses using NCB2.
-                                                         1 = Instruction request transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel_req                   : 1;  /**< Selects the IOB/NCB bus DPI uses for fetching the DPI_DMA_INSTR_HDR_S's,
+                                                         the first pointers, and the last pointers. DPI does not read the source data of
+                                                         the DPI DMA instruction via [NCBSEL_REQ] - see DPI_SLI_PRT()_CFG[NCBSEL] and
+                                                         [NCBSEL_SRC].
+                                                         0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for all DPI_DMA_INSTR_HDR_S and pointer reads
+                                                         1 = DPI uses IOBI3/IOBO3 (aka NCBI3/NCBO3) for all DPI_DMA_INSTR_HDR_S and pointer reads */
 	uint64_t reserved_13_15               : 3;
-	uint64_t ncbsel_dst                   : 1;  /**< Destination select.
-                                                         0 = Transaction will make requests and receive responses using NCB2.
-                                                         1 = Transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel_dst                   : 1;  /**< The default IOI/NCB that DPI uses for DPI_HDR_XTYPE_E::INTERNAL_ONLY L2/DRAM data
+                                                         writes.
+                                                         In the normal case (DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] clear),
+                                                            [NCBSEL_DST] XOR DPI_DMA_INSTR_HDR_S[LPORT<0>]
+                                                         determines the IOI/NCB that DPI uses for writes.
+                                                         0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for DPI_HDR_XTYPE_E::INTERNAL_ONLY
+                                                             DPI DMA instruction L2/DRAM writes.
+                                                         1 = DPI uses IOBI3/IOBO3 (aka NCBI3/NCBO3) for DPI_HDR_XTYPE_E::INTERNAL_ONLY
+                                                             DPI DMA instruction L2/DRAM writes.
+                                                         If DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] is set, [NCBSEL_DST] solely determines the IOI/NCB.
+                                                         The DPI_SLI_PRT()_CFG[NCBSEL] selected by DPI_DMA_INSTR_HDR_S[LPORT]
+                                                         is the equivalent of [NCBSEL_DST] for DPI_HDR_XTYPE_E::INBOUND DPI DMA instructions.
+                                                         (DPI_DMA_INSTR_HDR_S[FPORT<0>] is used with DPI_SLI_PRT()_CFG[NCBSEL]
+                                                         for DPI_HDR_XTYPE_E::INBOUND, not DPI_DMA_INSTR_HDR_S[LPORT<0>].) */
 	uint64_t reserved_9_11                : 3;
-	uint64_t ncbsel_src                   : 1;  /**< Source select.
-                                                         0 = Transaction will make requests and receive responses using NCB2.
-                                                         1 = Transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel_src                   : 1;  /**< The default IOI/NCB that DPI uses for DPI_HDR_XTYPE_E::INTERNAL_ONLY L2/DRAM data
+                                                         reads.
+                                                         In the normal case (DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] clear),
+                                                            [NCBSEL_SRC] XOR DPI_DMA_INSTR_HDR_S[FPORT<0>]
+                                                         determines the IOI/NCB that DPI uses.
+                                                         0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for DPI_HDR_XTYPE_E::INTERNAL_ONLY
+                                                             DPI DMA instruction L2/DRAM data reads.
+                                                         1 = DPI uses IOBI3/IOBO3 (aka NCBI3/NCBO3) for DPI_HDR_XTYPE_E::INTERNAL_ONLY
+                                                             DPI DMA instruction L2/DRAM data reads.
+                                                         If DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] is set, [NCBSEL_SRC] solely determines the IOI/NCB.
+                                                         Note that DPI uses [NCBSEL_REQ] for DPI_DMA_INSTR_HDR_S and pointer IOI/NCB
+                                                         reads, not [NCBSEL_SRC] nor DPI_DMA_INSTR_HDR_S[FPORT<0>].
+                                                         The DPI_SLI_PRT()_CFG[NCBSEL] selected by DPI_DMA_INSTR_HDR_S[LPORT] is
+                                                         the equivalent of [NCBSEL_SRC] for DPI_HDR_XTYPE_E::OUTBOUND DPI DMA instructions. */
 	uint64_t reserved_1_7                 : 7;
 	uint64_t prt                          : 1;  /**< Reserved. */
 #else
@@ -2393,23 +2506,51 @@ union cvmx_dpi_ncb_ctl {
 	struct cvmx_dpi_ncb_ctl_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
-	uint64_t ncbsel_prt_xor_dis           : 1;  /**< Disable the inclusion of the instruction header LPORT field when computing the NCB bus. */
+	uint64_t ncbsel_prt_xor_dis           : 1;  /**< When set, prevents DPI_DMA_INSTR_HDR_S[FPORT,LPORT] from determining the IOI/NCB
+                                                         DPI uses to process instructions. See [NCBSEL_SRC], [NCBSEL_DST], and
+                                                         DPI_SLI_PRT()_CFG[NCBSEL]. */
 	uint64_t reserved_21_23               : 3;
-	uint64_t ncbsel_zbw                   : 1;  /**< ZBW select.
-                                                         0 = Zero-byte-write transaction will make requests and receive responses using NCB2.
-                                                         1 = Zero-byte-write transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel_zbw                   : 1;  /**< Selects the IOBI/NCBI bus DPI uses for byte status writes by any DPI_HDR_PT_E::ZBW_CA,
+                                                         DPI_HDR_PT_E::ZBW_NC, or DPI_HDR_PT_E::WQP DPI DMA instructions.
+                                                         0 = DPI uses IOBI2/NCBI2 for all byte status writes
+                                                         1 = DPI uses IOBI3/NCBI3 for all byte status writes */
 	uint64_t reserved_17_19               : 3;
-	uint64_t ncbsel_req                   : 1;  /**< Request select.
-                                                         0 = Instruction request transaction will make requests and receive responses using NCB2.
-                                                         1 = Instruction request transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel_req                   : 1;  /**< Selects the IOB/NCB bus DPI uses for fetching the DPI_DMA_INSTR_HDR_S's,
+                                                         the first pointers, and the last pointers. DPI does not read the source data of
+                                                         the DPI DMA instruction via [NCBSEL_REQ] - see DPI_SLI_PRT()_CFG[NCBSEL] and
+                                                         [NCBSEL_SRC].
+                                                         0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for all DPI_DMA_INSTR_HDR_S and pointer reads
+                                                         1 = DPI uses IOBI3/IOBO3 (aka NCBI3/NCBO3) for all DPI_DMA_INSTR_HDR_S and pointer reads */
 	uint64_t reserved_13_15               : 3;
-	uint64_t ncbsel_dst                   : 1;  /**< Destination select.
-                                                         0 = Transaction will make requests and receive responses using NCB2.
-                                                         1 = Transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel_dst                   : 1;  /**< The default IOI/NCB that DPI uses for DPI_HDR_XTYPE_E::INTERNAL_ONLY L2/DRAM data
+                                                         writes.
+                                                         In the normal case (DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] clear),
+                                                            [NCBSEL_DST] XOR DPI_DMA_INSTR_HDR_S[LPORT<0>]
+                                                         determines the IOI/NCB that DPI uses for writes.
+                                                         0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for DPI_HDR_XTYPE_E::INTERNAL_ONLY
+                                                             DPI DMA instruction L2/DRAM writes.
+                                                         1 = DPI uses IOBI3/IOBO3 (aka NCBI3/NCBO3) for DPI_HDR_XTYPE_E::INTERNAL_ONLY
+                                                             DPI DMA instruction L2/DRAM writes.
+                                                         If DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] is set, [NCBSEL_DST] solely determines the IOI/NCB.
+                                                         The DPI_SLI_PRT()_CFG[NCBSEL] selected by DPI_DMA_INSTR_HDR_S[LPORT]
+                                                         is the equivalent of [NCBSEL_DST] for DPI_HDR_XTYPE_E::INBOUND DPI DMA instructions.
+                                                         (DPI_DMA_INSTR_HDR_S[FPORT<0>] is used with DPI_SLI_PRT()_CFG[NCBSEL]
+                                                         for DPI_HDR_XTYPE_E::INBOUND, not DPI_DMA_INSTR_HDR_S[LPORT<0>].) */
 	uint64_t reserved_9_11                : 3;
-	uint64_t ncbsel_src                   : 1;  /**< Source select.
-                                                         0 = Transaction will make requests and receive responses using NCB2.
-                                                         1 = Transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel_src                   : 1;  /**< The default IOI/NCB that DPI uses for DPI_HDR_XTYPE_E::INTERNAL_ONLY L2/DRAM data
+                                                         reads.
+                                                         In the normal case (DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] clear),
+                                                            [NCBSEL_SRC] XOR DPI_DMA_INSTR_HDR_S[FPORT<0>]
+                                                         determines the IOI/NCB that DPI uses.
+                                                         0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for DPI_HDR_XTYPE_E::INTERNAL_ONLY
+                                                             DPI DMA instruction L2/DRAM data reads.
+                                                         1 = DPI uses IOBI3/IOBO3 (aka NCBI3/NCBO3) for DPI_HDR_XTYPE_E::INTERNAL_ONLY
+                                                             DPI DMA instruction L2/DRAM data reads.
+                                                         If DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] is set, [NCBSEL_SRC] solely determines the IOI/NCB.
+                                                         Note that DPI uses [NCBSEL_REQ] for DPI_DMA_INSTR_HDR_S and pointer IOI/NCB
+                                                         reads, not [NCBSEL_SRC] nor DPI_DMA_INSTR_HDR_S[FPORT<0>].
+                                                         The DPI_SLI_PRT()_CFG[NCBSEL] selected by DPI_DMA_INSTR_HDR_S[LPORT] is
+                                                         the equivalent of [NCBSEL_SRC] for DPI_HDR_XTYPE_E::OUTBOUND DPI DMA instructions. */
 	uint64_t reserved_0_7                 : 8;
 #else
 	uint64_t reserved_0_7                 : 8;
@@ -2695,9 +2836,21 @@ union cvmx_dpi_sli_prtx_cfg {
 	struct cvmx_dpi_sli_prtx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_29_63               : 35;
-	uint64_t ncbsel                       : 1;  /**< NCB select.
-                                                         0 = Inbound/outbound transaction will make requests and receive responses using NCB2.
-                                                         1 = Inbound/outbound transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel                       : 1;  /**< The default IOI/NCB that DPI uses for DPI_HDR_XTYPE_E::OUTBOUND L2/DRAM data
+                                                         reads and DPI_HDR_XTYPE_E::INBOUND L2/DRAM writes. DPI_DMA_INSTR_HDR_S[LPORT]
+                                                         selects which DPI_SLI_PRT()_CFG[NCBSEL] is used for a DPI DMA instruction.
+                                                         In the normal case (DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] clear),
+                                                            [NCBSEL] XOR DPI_DMA_INSTR_HDR_S[FPORT<0>]
+                                                         determines the IOI/NCB that DPI uses.
+                                                         0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for DPI_HDR_XTYPE_E::OUTBOUND and
+                                                             DPI_HDR_XTYPE_E::INBOUND DPI DMA instructions.
+                                                         1 = DPI uses IOBI3/IOBO3 (aka NCBI3/NCBO3) for DPI_HDR_XTYPE_E::OUTBOUND and
+                                                             DPI_HDR_XTYPE_E::INBOUND DPI DMA instructions.
+                                                         If DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] is set, [NCBSEL] solely determines the IOI/NCB.
+                                                         Note that DPI uses DPI_NCB_CTL[NCBSEL_REQ] for reading DPI_DMA_INSTR_HDR_S's
+                                                         and first/last pointers, not [NCBSEL]. DPI_NCB_CTL[NCBSEL_SRC,NCBSEL_DST]
+                                                         are the equivalent of [NCBSEL] for DPI_HDR_XTYPE_E::INTERNAL_ONLY DPI DMA
+                                                         instructions. */
 	uint64_t reserved_25_27               : 3;
 	uint64_t halt                         : 1;  /**< When set, HALT indicates that the MAC has detected a reset condition. No further
                                                          instructions that reference the MAC from any instruction queue will be issued until the
@@ -3056,9 +3209,21 @@ union cvmx_dpi_sli_prtx_cfg {
 	struct cvmx_dpi_sli_prtx_cfg_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_29_63               : 35;
-	uint64_t ncbsel                       : 1;  /**< NCB select.
-                                                         0 = Inbound/outbound transaction will make requests and receive responses using NCB2.
-                                                         1 = Inbound/outbound transaction will make requests and receive responses using NCB3. */
+	uint64_t ncbsel                       : 1;  /**< The default IOI/NCB that DPI uses for DPI_HDR_XTYPE_E::OUTBOUND L2/DRAM data
+                                                         reads and DPI_HDR_XTYPE_E::INBOUND L2/DRAM writes. DPI_DMA_INSTR_HDR_S[LPORT]
+                                                         selects which DPI_SLI_PRT()_CFG[NCBSEL] is used for a DPI DMA instruction.
+                                                         In the normal case (DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] clear),
+                                                            [NCBSEL] XOR DPI_DMA_INSTR_HDR_S[FPORT<0>]
+                                                         determines the IOI/NCB that DPI uses.
+                                                         0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for DPI_HDR_XTYPE_E::OUTBOUND and
+                                                             DPI_HDR_XTYPE_E::INBOUND DPI DMA instructions.
+                                                         1 = DPI uses IOBI3/IOBO3 (aka NCBI3/NCBO3) for DPI_HDR_XTYPE_E::OUTBOUND and
+                                                             DPI_HDR_XTYPE_E::INBOUND DPI DMA instructions.
+                                                         If DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] is set, [NCBSEL] solely determines the IOI/NCB.
+                                                         Note that DPI uses DPI_NCB_CTL[NCBSEL_REQ] for reading DPI_DMA_INSTR_HDR_S's
+                                                         and first/last pointers, not [NCBSEL]. DPI_NCB_CTL[NCBSEL_SRC,NCBSEL_DST]
+                                                         are the equivalent of [NCBSEL] for DPI_HDR_XTYPE_E::INTERNAL_ONLY DPI DMA
+                                                         instructions. */
 	uint64_t reserved_25_27               : 3;
 	uint64_t halt                         : 1;  /**< When set, HALT indicates that the MAC has detected a reset condition. No further
                                                          instructions that reference the MAC from any instruction queue will be issued until the
@@ -3215,7 +3380,7 @@ union cvmx_dpi_sli_prtx_err_info {
 	struct cvmx_dpi_sli_prtx_err_info_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t pvf                          : 16; /**< Physical/Virtual function that caused the ErrorResponse. */
+	uint64_t pvf                          : 16; /**< Physical/Virtual function that caused the ErrorResponse. DPI_DMA_FUNC_SEL_S format. */
 	uint64_t reserved_9_15                : 7;
 	uint64_t lock                         : 1;  /**< DPI_SLI_PRT()_ERR and DPI_SLI_PRT()_ERR_INFO have captured and locked contents.
                                                          When CNXXXX first detects an ErrorResponse, the TYPE, REQQ, and ADDR of the error is saved
diff --git a/arch/mips/include/asm/octeon/cvmx-dtx-defs.h b/arch/mips/include/asm/octeon/cvmx-dtx-defs.h
index 42f257f..1c56e0b 100644
--- a/arch/mips/include/asm/octeon/cvmx-dtx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-dtx-defs.h
@@ -490,6 +490,61 @@ static inline uint64_t CVMX_DTX_BROADCAST_SELX(unsigned long offset)
 #define CVMX_DTX_BROADCAST_SELX(offset) (CVMX_ADD_IO_SEG(0x00011800FE7F0000ull) + ((offset) & 1) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_DTX_BTS_BCST_RSP CVMX_DTX_BTS_BCST_RSP_FUNC()
+static inline uint64_t CVMX_DTX_BTS_BCST_RSP_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+		cvmx_warn("CVMX_DTX_BTS_BCST_RSP not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800FE5B0080ull);
+}
+#else
+#define CVMX_DTX_BTS_BCST_RSP (CVMX_ADD_IO_SEG(0x00011800FE5B0080ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_DTX_BTS_CTL CVMX_DTX_BTS_CTL_FUNC()
+static inline uint64_t CVMX_DTX_BTS_CTL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+		cvmx_warn("CVMX_DTX_BTS_CTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800FE5B0060ull);
+}
+#else
+#define CVMX_DTX_BTS_CTL (CVMX_ADD_IO_SEG(0x00011800FE5B0060ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_BTS_DATX(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
+		cvmx_warn("CVMX_DTX_BTS_DATX(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800FE5B0040ull) + ((offset) & 1) * 8;
+}
+#else
+#define CVMX_DTX_BTS_DATX(offset) (CVMX_ADD_IO_SEG(0x00011800FE5B0040ull) + ((offset) & 1) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_BTS_ENAX(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
+		cvmx_warn("CVMX_DTX_BTS_ENAX(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800FE5B0020ull) + ((offset) & 1) * 8;
+}
+#else
+#define CVMX_DTX_BTS_ENAX(offset) (CVMX_ADD_IO_SEG(0x00011800FE5B0020ull) + ((offset) & 1) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_BTS_SELX(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
+		cvmx_warn("CVMX_DTX_BTS_SELX(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800FE5B0000ull) + ((offset) & 1) * 8;
+}
+#else
+#define CVMX_DTX_BTS_SELX(offset) (CVMX_ADD_IO_SEG(0x00011800FE5B0000ull) + ((offset) & 1) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_DTX_CIU_BCST_RSP CVMX_DTX_CIU_BCST_RSP_FUNC()
 static inline uint64_t CVMX_DTX_CIU_BCST_RSP_FUNC(void)
 {
@@ -846,8 +901,8 @@ static inline uint64_t CVMX_DTX_FPA_BCST_RSP_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE940080ull);
 			break;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
@@ -863,8 +918,8 @@ static inline uint64_t CVMX_DTX_FPA_BCST_RSP_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE940080ull);
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE140080ull);
@@ -878,8 +933,8 @@ static inline uint64_t CVMX_DTX_FPA_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE940060ull);
 			break;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
@@ -895,8 +950,8 @@ static inline uint64_t CVMX_DTX_FPA_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE940060ull);
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE140060ull);
@@ -909,8 +964,8 @@ static inline uint64_t CVMX_DTX_FPA_DATX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FE940040ull) + ((offset) & 1) * 8;
 			break;
@@ -927,8 +982,8 @@ static inline uint64_t CVMX_DTX_FPA_DATX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE940040ull) + (offset) * 8;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE140040ull) + (offset) * 8;
@@ -941,8 +996,8 @@ static inline uint64_t CVMX_DTX_FPA_ENAX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FE940020ull) + ((offset) & 1) * 8;
 			break;
@@ -959,8 +1014,8 @@ static inline uint64_t CVMX_DTX_FPA_ENAX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE940020ull) + (offset) * 8;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE140020ull) + (offset) * 8;
@@ -973,8 +1028,8 @@ static inline uint64_t CVMX_DTX_FPA_SELX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FE940000ull) + ((offset) & 1) * 8;
 			break;
@@ -991,8 +1046,8 @@ static inline uint64_t CVMX_DTX_FPA_SELX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE940000ull) + (offset) * 8;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE140000ull) + (offset) * 8;
@@ -2324,12 +2379,12 @@ static inline uint64_t CVMX_DTX_OCX_TOP_SELX(unsigned long offset)
 static inline uint64_t CVMX_DTX_OSM_BCST_RSP_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800FE6E0080ull);
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEEE0080ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800FE6E0080ull);
+			break;
 	}
 	cvmx_warn("CVMX_DTX_OSM_BCST_RSP not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0080ull);
@@ -2339,10 +2394,10 @@ static inline uint64_t CVMX_DTX_OSM_BCST_RSP_FUNC(void)
 static inline uint64_t CVMX_DTX_OSM_BCST_RSP_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800FE6E0080ull);
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEEE0080ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800FE6E0080ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0080ull);
 }
@@ -2352,12 +2407,12 @@ static inline uint64_t CVMX_DTX_OSM_BCST_RSP_FUNC(void)
 static inline uint64_t CVMX_DTX_OSM_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800FE6E0060ull);
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEEE0060ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800FE6E0060ull);
+			break;
 	}
 	cvmx_warn("CVMX_DTX_OSM_CTL not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0060ull);
@@ -2367,10 +2422,10 @@ static inline uint64_t CVMX_DTX_OSM_CTL_FUNC(void)
 static inline uint64_t CVMX_DTX_OSM_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800FE6E0060ull);
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEEE0060ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800FE6E0060ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0060ull);
 }
@@ -2379,14 +2434,14 @@ static inline uint64_t CVMX_DTX_OSM_CTL_FUNC(void)
 static inline uint64_t CVMX_DTX_OSM_DATX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011800FE6E0040ull) + ((offset) & 1) * 8;
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FEEE0040ull) + ((offset) & 1) * 8;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 1))
+				return CVMX_ADD_IO_SEG(0x00011800FE6E0040ull) + ((offset) & 1) * 8;
+			break;
 	}
 	cvmx_warn("CVMX_DTX_OSM_DATX (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0040ull) + ((offset) & 1) * 8;
@@ -2395,10 +2450,10 @@ static inline uint64_t CVMX_DTX_OSM_DATX(unsigned long offset)
 static inline uint64_t CVMX_DTX_OSM_DATX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800FE6E0040ull) + (offset) * 8;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEEE0040ull) + (offset) * 8;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800FE6E0040ull) + (offset) * 8;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0040ull) + (offset) * 8;
 }
@@ -2407,14 +2462,14 @@ static inline uint64_t CVMX_DTX_OSM_DATX(unsigned long offset)
 static inline uint64_t CVMX_DTX_OSM_ENAX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011800FE6E0020ull) + ((offset) & 1) * 8;
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FEEE0020ull) + ((offset) & 1) * 8;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 1))
+				return CVMX_ADD_IO_SEG(0x00011800FE6E0020ull) + ((offset) & 1) * 8;
+			break;
 	}
 	cvmx_warn("CVMX_DTX_OSM_ENAX (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0020ull) + ((offset) & 1) * 8;
@@ -2423,10 +2478,10 @@ static inline uint64_t CVMX_DTX_OSM_ENAX(unsigned long offset)
 static inline uint64_t CVMX_DTX_OSM_ENAX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800FE6E0020ull) + (offset) * 8;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEEE0020ull) + (offset) * 8;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800FE6E0020ull) + (offset) * 8;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0020ull) + (offset) * 8;
 }
@@ -2435,14 +2490,14 @@ static inline uint64_t CVMX_DTX_OSM_ENAX(unsigned long offset)
 static inline uint64_t CVMX_DTX_OSM_SELX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011800FE6E0000ull) + ((offset) & 1) * 8;
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FEEE0000ull) + ((offset) & 1) * 8;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 1))
+				return CVMX_ADD_IO_SEG(0x00011800FE6E0000ull) + ((offset) & 1) * 8;
+			break;
 	}
 	cvmx_warn("CVMX_DTX_OSM_SELX (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0000ull) + ((offset) & 1) * 8;
@@ -2451,10 +2506,10 @@ static inline uint64_t CVMX_DTX_OSM_SELX(unsigned long offset)
 static inline uint64_t CVMX_DTX_OSM_SELX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800FE6E0000ull) + (offset) * 8;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEEE0000ull) + (offset) * 8;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800FE6E0000ull) + (offset) * 8;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800FE6E0000ull) + (offset) * 8;
 }
@@ -2828,8 +2883,8 @@ static inline uint64_t CVMX_DTX_PKO_BCST_RSP_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEAA0080ull);
 			break;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
@@ -2845,8 +2900,8 @@ static inline uint64_t CVMX_DTX_PKO_BCST_RSP_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEAA0080ull);
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE280080ull);
@@ -2860,8 +2915,8 @@ static inline uint64_t CVMX_DTX_PKO_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEAA0060ull);
 			break;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
@@ -2877,8 +2932,8 @@ static inline uint64_t CVMX_DTX_PKO_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEAA0060ull);
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE280060ull);
@@ -2891,8 +2946,8 @@ static inline uint64_t CVMX_DTX_PKO_DATX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FEAA0040ull) + ((offset) & 1) * 8;
 			break;
@@ -2909,8 +2964,8 @@ static inline uint64_t CVMX_DTX_PKO_DATX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEAA0040ull) + (offset) * 8;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE280040ull) + (offset) * 8;
@@ -2923,8 +2978,8 @@ static inline uint64_t CVMX_DTX_PKO_ENAX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FEAA0020ull) + ((offset) & 1) * 8;
 			break;
@@ -2941,8 +2996,8 @@ static inline uint64_t CVMX_DTX_PKO_ENAX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEAA0020ull) + (offset) * 8;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE280020ull) + (offset) * 8;
@@ -2955,8 +3010,8 @@ static inline uint64_t CVMX_DTX_PKO_SELX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x00011800FEAA0000ull) + ((offset) & 1) * 8;
 			break;
@@ -2973,8 +3028,8 @@ static inline uint64_t CVMX_DTX_PKO_SELX(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FEAA0000ull) + (offset) * 8;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800FE280000ull) + (offset) * 8;
@@ -3371,6 +3426,61 @@ static inline uint64_t CVMX_DTX_RDEC_SELX(unsigned long offset)
 #define CVMX_DTX_RDEC_SELX(offset) (CVMX_ADD_IO_SEG(0x00011800FED68000ull) + ((offset) & 1) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_DTX_RFIF_BCST_RSP CVMX_DTX_RFIF_BCST_RSP_FUNC()
+static inline uint64_t CVMX_DTX_RFIF_BCST_RSP_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+		cvmx_warn("CVMX_DTX_RFIF_BCST_RSP not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800FE6A8080ull);
+}
+#else
+#define CVMX_DTX_RFIF_BCST_RSP (CVMX_ADD_IO_SEG(0x00011800FE6A8080ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_DTX_RFIF_CTL CVMX_DTX_RFIF_CTL_FUNC()
+static inline uint64_t CVMX_DTX_RFIF_CTL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+		cvmx_warn("CVMX_DTX_RFIF_CTL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800FE6A8060ull);
+}
+#else
+#define CVMX_DTX_RFIF_CTL (CVMX_ADD_IO_SEG(0x00011800FE6A8060ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_RFIF_DATX(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
+		cvmx_warn("CVMX_DTX_RFIF_DATX(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800FE6A8040ull) + ((offset) & 1) * 8;
+}
+#else
+#define CVMX_DTX_RFIF_DATX(offset) (CVMX_ADD_IO_SEG(0x00011800FE6A8040ull) + ((offset) & 1) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_RFIF_ENAX(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
+		cvmx_warn("CVMX_DTX_RFIF_ENAX(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800FE6A8020ull) + ((offset) & 1) * 8;
+}
+#else
+#define CVMX_DTX_RFIF_ENAX(offset) (CVMX_ADD_IO_SEG(0x00011800FE6A8020ull) + ((offset) & 1) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_RFIF_SELX(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
+		cvmx_warn("CVMX_DTX_RFIF_SELX(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800FE6A8000ull) + ((offset) & 1) * 8;
+}
+#else
+#define CVMX_DTX_RFIF_SELX(offset) (CVMX_ADD_IO_SEG(0x00011800FE6A8000ull) + ((offset) & 1) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_DTX_RMAP_BCST_RSP CVMX_DTX_RMAP_BCST_RSP_FUNC()
 static inline uint64_t CVMX_DTX_RMAP_BCST_RSP_FUNC(void)
 {
@@ -3728,6 +3838,61 @@ static inline uint64_t CVMX_DTX_SPEM_SELX(unsigned long offset)
 #define CVMX_DTX_SPEM_SELX(offset) (CVMX_ADD_IO_SEG(0x00011800FE600000ull) + ((offset) & 1) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_SRIOX_BCST_RSP(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
+		cvmx_warn("CVMX_DTX_SRIOX_BCST_RSP(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800FE640080ull) + ((offset) & 1) * 32768;
+}
+#else
+#define CVMX_DTX_SRIOX_BCST_RSP(offset) (CVMX_ADD_IO_SEG(0x00011800FE640080ull) + ((offset) & 1) * 32768)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_SRIOX_CTL(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
+		cvmx_warn("CVMX_DTX_SRIOX_CTL(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800FE640060ull) + ((offset) & 1) * 32768;
+}
+#else
+#define CVMX_DTX_SRIOX_CTL(offset) (CVMX_ADD_IO_SEG(0x00011800FE640060ull) + ((offset) & 1) * 32768)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_SRIOX_DATX(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 1))))))
+		cvmx_warn("CVMX_DTX_SRIOX_DATX(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800FE640040ull) + (((offset) & 1) + ((block_id) & 1) * 0x1000ull) * 8;
+}
+#else
+#define CVMX_DTX_SRIOX_DATX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800FE640040ull) + (((offset) & 1) + ((block_id) & 1) * 0x1000ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_SRIOX_ENAX(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 1))))))
+		cvmx_warn("CVMX_DTX_SRIOX_ENAX(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800FE640020ull) + (((offset) & 1) + ((block_id) & 1) * 0x1000ull) * 8;
+}
+#else
+#define CVMX_DTX_SRIOX_ENAX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800FE640020ull) + (((offset) & 1) + ((block_id) & 1) * 0x1000ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_DTX_SRIOX_SELX(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 1))))))
+		cvmx_warn("CVMX_DTX_SRIOX_SELX(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800FE640000ull) + (((offset) & 1) + ((block_id) & 1) * 0x1000ull) * 8;
+}
+#else
+#define CVMX_DTX_SRIOX_SELX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800FE640000ull) + (((offset) & 1) + ((block_id) & 1) * 0x1000ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_DTX_SSO_BCST_RSP CVMX_DTX_SSO_BCST_RSP_FUNC()
 static inline uint64_t CVMX_DTX_SSO_BCST_RSP_FUNC(void)
 {
@@ -5393,6 +5558,106 @@ union cvmx_dtx_broadcast_selx {
 typedef union cvmx_dtx_broadcast_selx cvmx_dtx_broadcast_selx_t;
 
 /**
+ * cvmx_dtx_bts_bcst_rsp
+ */
+union cvmx_dtx_bts_bcst_rsp {
+	uint64_t u64;
+	struct cvmx_dtx_bts_bcst_rsp_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t ena                          : 1;  /**< Enable this DTX instance as the responder to DTX broadcast read/write operations. */
+#else
+	uint64_t ena                          : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_dtx_bts_bcst_rsp_s        cnf75xx;
+};
+typedef union cvmx_dtx_bts_bcst_rsp cvmx_dtx_bts_bcst_rsp_t;
+
+/**
+ * cvmx_dtx_bts_ctl
+ */
+union cvmx_dtx_bts_ctl {
+	uint64_t u64;
+	struct cvmx_dtx_bts_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t active                       : 1;  /**< Force block's gated clocks on, so that the state of idle signals may be captured. */
+	uint64_t reserved_2_3                 : 2;
+	uint64_t echoen                       : 1;  /**< Drive debug bus with the value in DTX_MIO_ENA(0..1) instead of normal block debug data.
+                                                         Not applicable when software directly reads the DAT(0..1) registers.  For diagnostic use
+                                                         only. */
+	uint64_t swap                         : 1;  /**< Swap the high and low 36-bit debug bus outputs. */
+#else
+	uint64_t swap                         : 1;
+	uint64_t echoen                       : 1;
+	uint64_t reserved_2_3                 : 2;
+	uint64_t active                       : 1;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_dtx_bts_ctl_s             cnf75xx;
+};
+typedef union cvmx_dtx_bts_ctl cvmx_dtx_bts_ctl_t;
+
+/**
+ * cvmx_dtx_bts_dat#
+ */
+union cvmx_dtx_bts_datx {
+	uint64_t u64;
+	struct cvmx_dtx_bts_datx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t raw                          : 36; /**< Raw debug data captured by the DTX before the ENA is applied. This gives the ability to
+                                                         peek into blocks during an OCLA capture without OCLA reconfiguration. */
+#else
+	uint64_t raw                          : 36;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_dtx_bts_datx_s            cnf75xx;
+};
+typedef union cvmx_dtx_bts_datx cvmx_dtx_bts_datx_t;
+
+/**
+ * cvmx_dtx_bts_ena#
+ */
+union cvmx_dtx_bts_enax {
+	uint64_t u64;
+	struct cvmx_dtx_bts_enax_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t ena                          : 36; /**< Output enable vector of which bits to drive onto the low/high 36-bit debug buses. Normally
+                                                         only one block will drive each bit. */
+#else
+	uint64_t ena                          : 36;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_dtx_bts_enax_s            cnf75xx;
+};
+typedef union cvmx_dtx_bts_enax cvmx_dtx_bts_enax_t;
+
+/**
+ * cvmx_dtx_bts_sel#
+ */
+union cvmx_dtx_bts_selx {
+	uint64_t u64;
+	struct cvmx_dtx_bts_selx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_24_63               : 40;
+	uint64_t value                        : 24; /**< Debug select. Selects which signals to drive onto low/high 36-bit debug buses. */
+#else
+	uint64_t value                        : 24;
+	uint64_t reserved_24_63               : 40;
+#endif
+	} s;
+	struct cvmx_dtx_bts_selx_s            cnf75xx;
+};
+typedef union cvmx_dtx_bts_selx cvmx_dtx_bts_selx_t;
+
+/**
  * cvmx_dtx_ciu_bcst_rsp
  */
 union cvmx_dtx_ciu_bcst_rsp {
@@ -10273,6 +10538,106 @@ union cvmx_dtx_rdec_selx {
 typedef union cvmx_dtx_rdec_selx cvmx_dtx_rdec_selx_t;
 
 /**
+ * cvmx_dtx_rfif_bcst_rsp
+ */
+union cvmx_dtx_rfif_bcst_rsp {
+	uint64_t u64;
+	struct cvmx_dtx_rfif_bcst_rsp_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t ena                          : 1;  /**< Enable this DTX instance as the responder to DTX broadcast read/write operations. */
+#else
+	uint64_t ena                          : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_dtx_rfif_bcst_rsp_s       cnf75xx;
+};
+typedef union cvmx_dtx_rfif_bcst_rsp cvmx_dtx_rfif_bcst_rsp_t;
+
+/**
+ * cvmx_dtx_rfif_ctl
+ */
+union cvmx_dtx_rfif_ctl {
+	uint64_t u64;
+	struct cvmx_dtx_rfif_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t active                       : 1;  /**< Force block's gated clocks on, so that the state of idle signals may be captured. */
+	uint64_t reserved_2_3                 : 2;
+	uint64_t echoen                       : 1;  /**< Drive debug bus with the value in DTX_MIO_ENA(0..1) instead of normal block debug data.
+                                                         Not applicable when software directly reads the DAT(0..1) registers.  For diagnostic use
+                                                         only. */
+	uint64_t swap                         : 1;  /**< Swap the high and low 36-bit debug bus outputs. */
+#else
+	uint64_t swap                         : 1;
+	uint64_t echoen                       : 1;
+	uint64_t reserved_2_3                 : 2;
+	uint64_t active                       : 1;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_dtx_rfif_ctl_s            cnf75xx;
+};
+typedef union cvmx_dtx_rfif_ctl cvmx_dtx_rfif_ctl_t;
+
+/**
+ * cvmx_dtx_rfif_dat#
+ */
+union cvmx_dtx_rfif_datx {
+	uint64_t u64;
+	struct cvmx_dtx_rfif_datx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t raw                          : 36; /**< Raw debug data captured by the DTX before the ENA is applied. This gives the ability to
+                                                         peek into blocks during an OCLA capture without OCLA reconfiguration. */
+#else
+	uint64_t raw                          : 36;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_dtx_rfif_datx_s           cnf75xx;
+};
+typedef union cvmx_dtx_rfif_datx cvmx_dtx_rfif_datx_t;
+
+/**
+ * cvmx_dtx_rfif_ena#
+ */
+union cvmx_dtx_rfif_enax {
+	uint64_t u64;
+	struct cvmx_dtx_rfif_enax_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t ena                          : 36; /**< Output enable vector of which bits to drive onto the low/high 36-bit debug buses. Normally
+                                                         only one block will drive each bit. */
+#else
+	uint64_t ena                          : 36;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_dtx_rfif_enax_s           cnf75xx;
+};
+typedef union cvmx_dtx_rfif_enax cvmx_dtx_rfif_enax_t;
+
+/**
+ * cvmx_dtx_rfif_sel#
+ */
+union cvmx_dtx_rfif_selx {
+	uint64_t u64;
+	struct cvmx_dtx_rfif_selx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_24_63               : 40;
+	uint64_t value                        : 24; /**< Debug select. Selects which signals to drive onto low/high 36-bit debug buses. */
+#else
+	uint64_t value                        : 24;
+	uint64_t reserved_24_63               : 40;
+#endif
+	} s;
+	struct cvmx_dtx_rfif_selx_s           cnf75xx;
+};
+typedef union cvmx_dtx_rfif_selx cvmx_dtx_rfif_selx_t;
+
+/**
  * cvmx_dtx_rmap_bcst_rsp
  */
 union cvmx_dtx_rmap_bcst_rsp {
@@ -10948,6 +11313,106 @@ union cvmx_dtx_spem_selx {
 typedef union cvmx_dtx_spem_selx cvmx_dtx_spem_selx_t;
 
 /**
+ * cvmx_dtx_srio#_bcst_rsp
+ */
+union cvmx_dtx_sriox_bcst_rsp {
+	uint64_t u64;
+	struct cvmx_dtx_sriox_bcst_rsp_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t ena                          : 1;  /**< Enable this DTX instance as the responder to DTX broadcast read/write operations. */
+#else
+	uint64_t ena                          : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_dtx_sriox_bcst_rsp_s      cnf75xx;
+};
+typedef union cvmx_dtx_sriox_bcst_rsp cvmx_dtx_sriox_bcst_rsp_t;
+
+/**
+ * cvmx_dtx_srio#_ctl
+ */
+union cvmx_dtx_sriox_ctl {
+	uint64_t u64;
+	struct cvmx_dtx_sriox_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t active                       : 1;  /**< Force block's gated clocks on, so that the state of idle signals may be captured. */
+	uint64_t reserved_2_3                 : 2;
+	uint64_t echoen                       : 1;  /**< Drive debug bus with the value in DTX_MIO_ENA(0..1) instead of normal block debug data.
+                                                         Not applicable when software directly reads the DAT(0..1) registers.  For diagnostic use
+                                                         only. */
+	uint64_t swap                         : 1;  /**< Swap the high and low 36-bit debug bus outputs. */
+#else
+	uint64_t swap                         : 1;
+	uint64_t echoen                       : 1;
+	uint64_t reserved_2_3                 : 2;
+	uint64_t active                       : 1;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_dtx_sriox_ctl_s           cnf75xx;
+};
+typedef union cvmx_dtx_sriox_ctl cvmx_dtx_sriox_ctl_t;
+
+/**
+ * cvmx_dtx_srio#_dat#
+ */
+union cvmx_dtx_sriox_datx {
+	uint64_t u64;
+	struct cvmx_dtx_sriox_datx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t raw                          : 36; /**< Raw debug data captured by the DTX before the ENA is applied. This gives the ability to
+                                                         peek into blocks during an OCLA capture without OCLA reconfiguration. */
+#else
+	uint64_t raw                          : 36;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_dtx_sriox_datx_s          cnf75xx;
+};
+typedef union cvmx_dtx_sriox_datx cvmx_dtx_sriox_datx_t;
+
+/**
+ * cvmx_dtx_srio#_ena#
+ */
+union cvmx_dtx_sriox_enax {
+	uint64_t u64;
+	struct cvmx_dtx_sriox_enax_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_36_63               : 28;
+	uint64_t ena                          : 36; /**< Output enable vector of which bits to drive onto the low/high 36-bit debug buses. Normally
+                                                         only one block will drive each bit. */
+#else
+	uint64_t ena                          : 36;
+	uint64_t reserved_36_63               : 28;
+#endif
+	} s;
+	struct cvmx_dtx_sriox_enax_s          cnf75xx;
+};
+typedef union cvmx_dtx_sriox_enax cvmx_dtx_sriox_enax_t;
+
+/**
+ * cvmx_dtx_srio#_sel#
+ */
+union cvmx_dtx_sriox_selx {
+	uint64_t u64;
+	struct cvmx_dtx_sriox_selx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_24_63               : 40;
+	uint64_t value                        : 24; /**< Debug select. Selects which signals to drive onto low/high 36-bit debug buses. */
+#else
+	uint64_t value                        : 24;
+	uint64_t reserved_24_63               : 40;
+#endif
+	} s;
+	struct cvmx_dtx_sriox_selx_s          cnf75xx;
+};
+typedef union cvmx_dtx_sriox_selx cvmx_dtx_sriox_selx_t;
+
+/**
  * cvmx_dtx_sso_bcst_rsp
  */
 union cvmx_dtx_sso_bcst_rsp {
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa-defs.h b/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
index e1a2ace..e3eca6f 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
@@ -65,8 +65,8 @@ static inline uint64_t CVMX_FPA_ADDR_RANGE_ERROR_FUNC(void)
 			return CVMX_ADD_IO_SEG(0x0001180028000458ull);
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001280000000458ull);
 			break;
 	}
@@ -85,8 +85,8 @@ static inline uint64_t CVMX_FPA_ADDR_RANGE_ERROR_FUNC(void)
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180028000458ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001280000000458ull);
 	}
 	return CVMX_ADD_IO_SEG(0x0001280000000458ull);
@@ -230,8 +230,8 @@ static inline uint64_t CVMX_FPA_BIST_STATUS_FUNC(void)
 			return CVMX_ADD_IO_SEG(0x00011800280000E8ull);
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00012800000000E8ull);
 			break;
 	}
@@ -258,8 +258,8 @@ static inline uint64_t CVMX_FPA_BIST_STATUS_FUNC(void)
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800280000E8ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00012800000000E8ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00012800000000E8ull);
diff --git a/arch/mips/include/asm/octeon/cvmx-gpio-defs.h b/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
index b549c86..b0c12cf 100644
--- a/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
@@ -227,6 +227,7 @@ static inline uint64_t CVMX_GPIO_MC_INTRX_W1S(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset >= 4) && (offset <= 7)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset >= 4) && (offset <= 7)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset >= 4) && (offset <= 7))))))
 		cvmx_warn("CVMX_GPIO_MC_INTRX_W1S(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001070000000E20ull) + ((offset) & 7) * 8 - 8*4;
@@ -745,7 +746,7 @@ union cvmx_gpio_clk_syncex {
 	struct cvmx_gpio_clk_syncex_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t qlm_sel                      : 4;  /**< Selects which QLM(0..3) or DLM(4..6) to select from, value 7-15 are invalid. */
+	uint64_t qlm_sel                      : 4;  /**< Selects which QLM(0..3) or DLM(4..6) to select from, values 7-15 are invalid. */
 	uint64_t reserved_4_7                 : 4;
 	uint64_t div                          : 2;  /**< GPIO internal clock divider setting relative to QLM/DLM SERDES CLOCK_SYNCE. The maximum
                                                          supported GPIO output frequency is 125 MHz.
@@ -1200,7 +1201,7 @@ union cvmx_gpio_sata_lab_lb {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
 	uint64_t sel                          : 5;  /**< Selects the GPIO(0..31) input pin for SATA BIST lab-loopback pin.
-                                                         see TBD. */
+                                                         see SATA()_UAHC_GBL_BISTCR[LLB]. */
 #else
 	uint64_t sel                          : 5;
 	uint64_t reserved_5_63                : 59;
diff --git a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
index 5b072db..2f6f6b0 100644
--- a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
@@ -58,7 +58,7 @@ static inline uint64_t CVMX_GSERX_ANA_ATEST(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_ANA_ATEST(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000800ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -71,7 +71,7 @@ static inline uint64_t CVMX_GSERX_ANA_SEL(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_ANA_SEL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000808ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -84,7 +84,7 @@ static inline uint64_t CVMX_GSERX_BR_RXX_CTL(unsigned long offset, unsigned long
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_BR_RXX_CTL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090000400ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
 }
@@ -97,7 +97,7 @@ static inline uint64_t CVMX_GSERX_BR_RXX_EER(unsigned long offset, unsigned long
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_BR_RXX_EER(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090000418ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
 }
@@ -110,7 +110,7 @@ static inline uint64_t CVMX_GSERX_BR_TXX_CTL(unsigned long offset, unsigned long
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_BR_TXX_CTL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090000420ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
 }
@@ -123,7 +123,7 @@ static inline uint64_t CVMX_GSERX_BR_TXX_CUR(unsigned long offset, unsigned long
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_BR_TXX_CUR(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090000438ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
 }
@@ -135,7 +135,8 @@ static inline uint64_t CVMX_GSERX_BR_TXX_TAP(unsigned long offset, unsigned long
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_BR_TXX_TAP(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090000440ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
 }
@@ -148,7 +149,7 @@ static inline uint64_t CVMX_GSERX_CFG(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_CFG(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000080ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -161,7 +162,7 @@ static inline uint64_t CVMX_GSERX_DBG(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_DBG(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000098ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -526,7 +527,7 @@ static inline uint64_t CVMX_GSERX_EQ_WAIT_TIME(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_EQ_WAIT_TIME(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904E0000ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -539,7 +540,7 @@ static inline uint64_t CVMX_GSERX_GLBL_PLL_MONITOR(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_GLBL_PLL_MONITOR(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090460100ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -552,7 +553,7 @@ static inline uint64_t CVMX_GSERX_GLBL_TAD(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_GLBL_TAD(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090460400ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -565,7 +566,7 @@ static inline uint64_t CVMX_GSERX_GLBL_TM_ADMON(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_GLBL_TM_ADMON(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090460408ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -578,7 +579,7 @@ static inline uint64_t CVMX_GSERX_IDDQ_MODE(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_IDDQ_MODE(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000018ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -591,7 +592,7 @@ static inline uint64_t CVMX_GSERX_LANEX_LBERT_CFG(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_LBERT_CFG(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904C0020ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -604,7 +605,7 @@ static inline uint64_t CVMX_GSERX_LANEX_LBERT_ECNT(unsigned long offset, unsigne
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_LBERT_ECNT(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904C0028ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -617,7 +618,7 @@ static inline uint64_t CVMX_GSERX_LANEX_LBERT_PAT_CFG(unsigned long offset, unsi
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_LBERT_PAT_CFG(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904C0018ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -630,7 +631,7 @@ static inline uint64_t CVMX_GSERX_LANEX_MISC_CFG_0(unsigned long offset, unsigne
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_MISC_CFG_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904C0000ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -643,7 +644,7 @@ static inline uint64_t CVMX_GSERX_LANEX_MISC_CFG_1(unsigned long offset, unsigne
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_MISC_CFG_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904C0008ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -656,7 +657,7 @@ static inline uint64_t CVMX_GSERX_LANEX_PCS_CTLIFC_0(unsigned long offset, unsig
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_PCS_CTLIFC_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904C0060ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -669,7 +670,7 @@ static inline uint64_t CVMX_GSERX_LANEX_PCS_CTLIFC_1(unsigned long offset, unsig
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_PCS_CTLIFC_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904C0068ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -682,7 +683,7 @@ static inline uint64_t CVMX_GSERX_LANEX_PCS_CTLIFC_2(unsigned long offset, unsig
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_PCS_CTLIFC_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904C0070ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -690,12 +691,23 @@ static inline uint64_t CVMX_GSERX_LANEX_PCS_CTLIFC_2(unsigned long offset, unsig
 #define CVMX_GSERX_LANEX_PCS_CTLIFC_2(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904C0070ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_PCS_MACIFC_MON_2(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_PCS_MACIFC_MON_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904C0118ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_PCS_MACIFC_MON_2(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904C0118ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_LANEX_PMA_LOOPBACK_CTRL(unsigned long offset, unsigned long block_id)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_PMA_LOOPBACK_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904400D0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -708,7 +720,7 @@ static inline uint64_t CVMX_GSERX_LANEX_PWR_CTRL(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_PWR_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904400D8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -721,7 +733,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_AEQ_OUT_0(unsigned long offset, unsig
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_AEQ_OUT_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440280ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -734,7 +746,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_AEQ_OUT_1(unsigned long offset, unsig
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_AEQ_OUT_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440288ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -747,7 +759,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_AEQ_OUT_2(unsigned long offset, unsig
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_AEQ_OUT_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440290ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -760,7 +772,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CDR_CTRL_1(unsigned long offset, unsi
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CDR_CTRL_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440038ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -773,7 +785,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CDR_CTRL_2(unsigned long offset, unsi
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CDR_CTRL_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440040ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -786,7 +798,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CDR_MISC_CTRL_0(unsigned long offset,
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CDR_MISC_CTRL_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440208ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -799,7 +811,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CDR_STATUS_1(unsigned long offset, un
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CDR_STATUS_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904402D0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -812,7 +824,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CDR_STATUS_2(unsigned long offset, un
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CDR_STATUS_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904402D8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -825,7 +837,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CFG_0(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CFG_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440000ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -838,7 +850,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CFG_1(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CFG_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440008ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -851,7 +863,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CFG_2(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CFG_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440010ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -864,7 +876,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CFG_3(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CFG_3(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440018ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -877,7 +889,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CFG_4(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CFG_4(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440020ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -890,7 +902,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CFG_5(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CFG_5(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440028ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -903,7 +915,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_CTLE_CTRL(unsigned long offset, unsig
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_CTLE_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440058ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -916,7 +928,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_LOOP_CTRL(unsigned long offset, unsig
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_LOOP_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440048ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -929,7 +941,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_MISC_OVRRD(unsigned long offset, unsi
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_MISC_OVRRD(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440258ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -942,7 +954,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_PRECORR_CTRL(unsigned long offset, un
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_PRECORR_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440060ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -955,7 +967,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_PRECORR_VAL(unsigned long offset, uns
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_PRECORR_VAL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440078ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -968,7 +980,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_VALBBD_CTRL_0(unsigned long offset, u
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_VALBBD_CTRL_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440240ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -981,7 +993,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_VALBBD_CTRL_1(unsigned long offset, u
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_VALBBD_CTRL_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440248ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -994,7 +1006,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_VALBBD_CTRL_2(unsigned long offset, u
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_VALBBD_CTRL_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440250ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1007,7 +1019,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_VMA_CTRL(unsigned long offset, unsign
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_VMA_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440200ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1020,7 +1032,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_VMA_STATUS_0(unsigned long offset, un
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_VMA_STATUS_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904402B8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1033,7 +1045,7 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_VMA_STATUS_1(unsigned long offset, un
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_RX_VMA_STATUS_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904402C0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1045,7 +1057,8 @@ static inline uint64_t CVMX_GSERX_LANEX_SDS_PIN_MON_0(unsigned long offset, unsi
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_SDS_PIN_MON_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440130ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1057,7 +1070,8 @@ static inline uint64_t CVMX_GSERX_LANEX_SDS_PIN_MON_1(unsigned long offset, unsi
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_SDS_PIN_MON_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440138ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1069,7 +1083,8 @@ static inline uint64_t CVMX_GSERX_LANEX_SDS_PIN_MON_2(unsigned long offset, unsi
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_SDS_PIN_MON_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090440140ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1082,7 +1097,7 @@ static inline uint64_t CVMX_GSERX_LANEX_TX_CFG_0(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_TX_CFG_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904400A8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1095,7 +1110,7 @@ static inline uint64_t CVMX_GSERX_LANEX_TX_CFG_1(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_TX_CFG_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904400B0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1108,7 +1123,7 @@ static inline uint64_t CVMX_GSERX_LANEX_TX_CFG_2(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_TX_CFG_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904400B8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1121,7 +1136,7 @@ static inline uint64_t CVMX_GSERX_LANEX_TX_CFG_3(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_TX_CFG_3(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904400C0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1134,7 +1149,7 @@ static inline uint64_t CVMX_GSERX_LANEX_TX_PRE_EMPHASIS(unsigned long offset, un
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 3)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANEX_TX_PRE_EMPHASIS(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904400C8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
 }
@@ -1147,7 +1162,7 @@ static inline uint64_t CVMX_GSERX_LANE_LPBKEN(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_LPBKEN(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000110ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1160,7 +1175,7 @@ static inline uint64_t CVMX_GSERX_LANE_MODE(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_MODE(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000118ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1173,7 +1188,7 @@ static inline uint64_t CVMX_GSERX_LANE_POFF(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_POFF(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000108ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1186,7 +1201,7 @@ static inline uint64_t CVMX_GSERX_LANE_PX_MODE_0(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 11)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 11)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 11)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 11)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANE_PX_MODE_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904E0040ull) + (((offset) & 15) + ((block_id) & 15) * 0x80000ull) * 32;
 }
@@ -1199,7 +1214,7 @@ static inline uint64_t CVMX_GSERX_LANE_PX_MODE_1(unsigned long offset, unsigned
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 11)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 11)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 11)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 11)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_LANE_PX_MODE_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904E0048ull) + (((offset) & 15) + ((block_id) & 15) * 0x80000ull) * 32;
 }
@@ -1212,7 +1227,7 @@ static inline uint64_t CVMX_GSERX_LANE_SRST(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_SRST(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000100ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1225,7 +1240,7 @@ static inline uint64_t CVMX_GSERX_LANE_VMA_COARSE_CTRL_0(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_VMA_COARSE_CTRL_0(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904E01B0ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1238,7 +1253,7 @@ static inline uint64_t CVMX_GSERX_LANE_VMA_COARSE_CTRL_1(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_VMA_COARSE_CTRL_1(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904E01B8ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1251,7 +1266,7 @@ static inline uint64_t CVMX_GSERX_LANE_VMA_COARSE_CTRL_2(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_VMA_COARSE_CTRL_2(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904E01C0ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1264,7 +1279,7 @@ static inline uint64_t CVMX_GSERX_LANE_VMA_FINE_CTRL_0(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_VMA_FINE_CTRL_0(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904E01C8ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1277,7 +1292,7 @@ static inline uint64_t CVMX_GSERX_LANE_VMA_FINE_CTRL_1(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_VMA_FINE_CTRL_1(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904E01D0ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1290,7 +1305,7 @@ static inline uint64_t CVMX_GSERX_LANE_VMA_FINE_CTRL_2(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_LANE_VMA_FINE_CTRL_2(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904E01D8ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1677,7 +1692,7 @@ static inline uint64_t CVMX_GSERX_PHY_CTL(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_PHY_CTL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000000ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1690,7 +1705,7 @@ static inline uint64_t CVMX_GSERX_PIPE_LPBK(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_PIPE_LPBK(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000200ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1703,7 +1718,7 @@ static inline uint64_t CVMX_GSERX_PLL_PX_MODE_0(unsigned long offset, unsigned l
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 11)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 11)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 11)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 11)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_PLL_PX_MODE_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904E0030ull) + (((offset) & 15) + ((block_id) & 15) * 0x80000ull) * 32;
 }
@@ -1716,7 +1731,7 @@ static inline uint64_t CVMX_GSERX_PLL_PX_MODE_1(unsigned long offset, unsigned l
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 11)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 11)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 11)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 11)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_PLL_PX_MODE_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x00011800904E0038ull) + (((offset) & 15) + ((block_id) & 15) * 0x80000ull) * 32;
 }
@@ -1729,7 +1744,7 @@ static inline uint64_t CVMX_GSERX_PLL_STAT(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_PLL_STAT(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000010ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1742,7 +1757,7 @@ static inline uint64_t CVMX_GSERX_QLM_STAT(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_QLM_STAT(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800900000A0ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1755,7 +1770,7 @@ static inline uint64_t CVMX_GSERX_RDET_TIME(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_RDET_TIME(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904E0008ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1767,7 +1782,8 @@ static inline uint64_t CVMX_GSERX_REFCLK_EVT_CNTR(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_REFCLK_EVT_CNTR(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000178ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1779,7 +1795,8 @@ static inline uint64_t CVMX_GSERX_REFCLK_EVT_CTRL(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_REFCLK_EVT_CTRL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000170ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1792,7 +1809,7 @@ static inline uint64_t CVMX_GSERX_REFCLK_SEL(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_REFCLK_SEL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000008ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1805,7 +1822,7 @@ static inline uint64_t CVMX_GSERX_RX_COAST(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_RX_COAST(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000138ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1818,7 +1835,7 @@ static inline uint64_t CVMX_GSERX_RX_EIE_DETEN(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_RX_EIE_DETEN(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000148ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1831,7 +1848,7 @@ static inline uint64_t CVMX_GSERX_RX_EIE_DETSTS(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_RX_EIE_DETSTS(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000150ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1844,7 +1861,7 @@ static inline uint64_t CVMX_GSERX_RX_EIE_FILTER(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_RX_EIE_FILTER(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000158ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1857,7 +1874,7 @@ static inline uint64_t CVMX_GSERX_RX_POLARITY(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_RX_POLARITY(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000160ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1870,7 +1887,7 @@ static inline uint64_t CVMX_GSERX_RX_PWR_CTRL_P1(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_RX_PWR_CTRL_P1(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904600B0ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1883,7 +1900,7 @@ static inline uint64_t CVMX_GSERX_RX_PWR_CTRL_P2(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_RX_PWR_CTRL_P2(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800904600B8ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -1906,7 +1923,7 @@ static inline uint64_t CVMX_GSERX_SATA_LANEX_TX_AMPX(unsigned long a, unsigned l
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((a <= 6)) && ((b <= 1)) && ((c <= 2)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((a <= 6)) && ((b <= 1)) && ((c <= 2))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((a <= 8)) && ((b <= 1)) && ((c <= 2))))))
 		cvmx_warn("CVMX_GSERX_SATA_LANEX_TX_AMPX(%lu,%lu,%lu) is invalid on this chip\n", a, b, c);
 	return CVMX_ADD_IO_SEG(0x0001180090000B00ull) + ((a) << 24) + ((b) << 5) + ((c) << 3);
 }
@@ -1918,7 +1935,7 @@ static inline uint64_t CVMX_GSERX_SATA_LANEX_TX_PREEMPHX(unsigned long a, unsign
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((a <= 6)) && ((b <= 1)) && ((c <= 2)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((a <= 6)) && ((b <= 1)) && ((c <= 2))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((a <= 8)) && ((b <= 1)) && ((c <= 2))))))
 		cvmx_warn("CVMX_GSERX_SATA_LANEX_TX_PREEMPHX(%lu,%lu,%lu) is invalid on this chip\n", a, b, c);
 	return CVMX_ADD_IO_SEG(0x0001180090000A00ull) + ((a) << 24) + ((b) << 5) + ((c) << 3);
 }
@@ -1934,13 +1951,16 @@ static inline uint64_t CVMX_GSERX_SATA_LANE_RST(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x0001180090100210ull) + ((offset) & 0) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 8))
+				return CVMX_ADD_IO_SEG(0x0001180090000908ull) + ((offset) & 15) * 0x1000000ull;
+			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 6))
 				return CVMX_ADD_IO_SEG(0x0001180090000908ull) + ((offset) & 7) * 0x1000000ull;
 			break;
 	}
 	cvmx_warn("CVMX_GSERX_SATA_LANE_RST (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001180090000908ull) + ((offset) & 7) * 0x1000000ull;
+	return CVMX_ADD_IO_SEG(0x0001180090000908ull) + ((offset) & 15) * 0x1000000ull;
 }
 #else
 static inline uint64_t CVMX_GSERX_SATA_LANE_RST(unsigned long offset)
@@ -1949,6 +1969,7 @@ static inline uint64_t CVMX_GSERX_SATA_LANE_RST(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180090100210ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001180090000908ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180090000908ull) + (offset) * 0x1000000ull;
 	}
@@ -2063,13 +2084,16 @@ static inline uint64_t CVMX_GSERX_SATA_STATUS(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x0001180090100200ull) + ((offset) & 0) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 8))
+				return CVMX_ADD_IO_SEG(0x0001180090100900ull) + ((offset) & 15) * 0x1000000ull;
+			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 6))
 				return CVMX_ADD_IO_SEG(0x0001180090100900ull) + ((offset) & 7) * 0x1000000ull;
 			break;
 	}
 	cvmx_warn("CVMX_GSERX_SATA_STATUS (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001180090100900ull) + ((offset) & 7) * 0x1000000ull;
+	return CVMX_ADD_IO_SEG(0x0001180090100900ull) + ((offset) & 15) * 0x1000000ull;
 }
 #else
 static inline uint64_t CVMX_GSERX_SATA_STATUS(unsigned long offset)
@@ -2078,6 +2102,7 @@ static inline uint64_t CVMX_GSERX_SATA_STATUS(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180090100200ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001180090100900ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180090100900ull) + (offset) * 0x1000000ull;
 	}
@@ -2093,13 +2118,16 @@ static inline uint64_t CVMX_GSERX_SATA_TX_INVERT(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x0001180090100220ull) + ((offset) & 0) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 8))
+				return CVMX_ADD_IO_SEG(0x0001180090000910ull) + ((offset) & 15) * 0x1000000ull;
+			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 6))
 				return CVMX_ADD_IO_SEG(0x0001180090000910ull) + ((offset) & 7) * 0x1000000ull;
 			break;
 	}
 	cvmx_warn("CVMX_GSERX_SATA_TX_INVERT (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001180090000910ull) + ((offset) & 7) * 0x1000000ull;
+	return CVMX_ADD_IO_SEG(0x0001180090000910ull) + ((offset) & 15) * 0x1000000ull;
 }
 #else
 static inline uint64_t CVMX_GSERX_SATA_TX_INVERT(unsigned long offset)
@@ -2108,6 +2136,7 @@ static inline uint64_t CVMX_GSERX_SATA_TX_INVERT(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180090100220ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001180090000910ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180090000910ull) + (offset) * 0x1000000ull;
 	}
@@ -2120,7 +2149,7 @@ static inline uint64_t CVMX_GSERX_SCRATCH(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_SCRATCH(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000020ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -2133,7 +2162,7 @@ static inline uint64_t CVMX_GSERX_SLICEX_RX_SDLL_CTRL(unsigned long offset, unsi
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 6)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 1)) && ((block_id <= 13)))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 6))))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 8))))))
 		cvmx_warn("CVMX_GSERX_SLICEX_RX_SDLL_CTRL(%lu,%lu) is invalid on this chip\n", offset, block_id);
 	return CVMX_ADD_IO_SEG(0x0001180090460220ull) + (((offset) & 1) + ((block_id) & 15) * 0x8ull) * 2097152;
 }
@@ -2146,7 +2175,7 @@ static inline uint64_t CVMX_GSERX_SLICE_CFG(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_SLICE_CFG(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090460060ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -2159,7 +2188,7 @@ static inline uint64_t CVMX_GSERX_SPD(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_SPD(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000088ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -2167,12 +2196,34 @@ static inline uint64_t CVMX_GSERX_SPD(unsigned long offset)
 #define CVMX_GSERX_SPD(offset) (CVMX_ADD_IO_SEG(0x0001180090000088ull) + ((offset) & 15) * 0x1000000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_SRIO_PCS_CFG_0(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
+		cvmx_warn("CVMX_GSERX_SRIO_PCS_CFG_0(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001180090000240ull) + ((offset) & 15) * 0x1000000ull;
+}
+#else
+#define CVMX_GSERX_SRIO_PCS_CFG_0(offset) (CVMX_ADD_IO_SEG(0x0001180090000240ull) + ((offset) & 15) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_SRIO_PCS_CFG_1(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
+		cvmx_warn("CVMX_GSERX_SRIO_PCS_CFG_1(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001180090000248ull) + ((offset) & 15) * 0x1000000ull;
+}
+#else
+#define CVMX_GSERX_SRIO_PCS_CFG_1(offset) (CVMX_ADD_IO_SEG(0x0001180090000248ull) + ((offset) & 15) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_SRST(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_SRST(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000090ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -2184,7 +2235,8 @@ static inline uint64_t CVMX_GSERX_TXCLK_EVT_CNTR(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_TXCLK_EVT_CNTR(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000188ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -2196,7 +2248,8 @@ static inline uint64_t CVMX_GSERX_TXCLK_EVT_CTRL(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_TXCLK_EVT_CTRL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000180ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -2209,7 +2262,7 @@ static inline uint64_t CVMX_GSERX_TX_VBOOST(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 6)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_TX_VBOOST(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090000130ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -2225,13 +2278,13 @@ union cvmx_gserx_ana_atest {
 	struct cvmx_gserx_ana_atest_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t ana_dac_b                    : 7;  /**< Used to control the B-side DAC input to the analog test block. Note that the QLM[FIXME]
-                                                         register
-                                                         is tied to the analog test block. The other GSER()_ANA_ATEST registers are
-                                                         unused. For diagnostic use only. */
-	uint64_t ana_dac_a                    : 5;  /**< Used to control A-side DAC input to the analog test block. Note that the QLM[FIXME]
-                                                         register is
-                                                         tied to the analog test block. The other GSER()_ANA_ATEST registers are unused.
+	uint64_t ana_dac_b                    : 7;  /**< Used to control the B-side DAC input to the analog test block. Note that only
+                                                         the GSER(4)_ANA_ATEST.ANA_DAC_B register is tied to the analog test block.
+                                                         The GSER(0..3,5..6)_ANA_ATEST.ANA_DAC_B registers are unused.
+                                                         For diagnostic use only. */
+	uint64_t ana_dac_a                    : 5;  /**< Used to control the A-side DAC input to the analog test block. Note that only
+                                                         the GSER(4)_ANA_TEST.ANA_DAC_A register is tied to the analog test block.
+                                                         The GSER(0..3,5..6)_ANA_ATEST.ANA_DAC_A registers are unused.
                                                          For diagnostic use only. */
 #else
 	uint64_t ana_dac_a                    : 5;
@@ -2254,8 +2307,17 @@ union cvmx_gserx_ana_sel {
 	struct cvmx_gserx_ana_sel_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t ana_sel                      : 9;  /**< Used to control the adr_global input to the analog test block. Note that the QLM0 register
-                                                         is tied to the analog test block. The other GSER()_ANA_SEL registers are unused.
+	uint64_t ana_sel                      : 9;  /**< Used to control the adr_global input to the analog test block. Note that only
+                                                         the GSER(4)_ANA_SEL.ANA_SEL register is tied to the analog test block.
+                                                         The GSER(0..3,5..6)_ANA_SEL.ANA_SEL registers are unused.
+                                                         Used to power down the common clock input receiver to reduce power consumption
+                                                         if the common clock input is not used.
+                                                         If the common clock QLMC_REFCLK1_P/N input is unused program the
+                                                         GSER(4)_ANA_SEL.ANA_SEL field to 0x1fd.
+                                                         If the common clock QLMC_REFCLK0_P/N input is unused program the
+                                                         GSER(4)_ANA_SEL.ANA_SEL field to 0x1fe.
+                                                         If both common clock QLMC_REFCLK0_P/N and QLMC_REFCLK1_P/N inputs are unused program the
+                                                         GSER(4)_ANA_SEL.ANA_SEL field to 0x1fc.
                                                          For diagnostic use only. */
 #else
 	uint64_t ana_sel                      : 9;
@@ -2480,6 +2542,40 @@ union cvmx_gserx_cfg {
 	uint64_t u64;
 	struct cvmx_gserx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_9_63                : 55;
+	uint64_t rmac_pipe                    : 1;  /**< Indicates the RMAC is configured for PIPE mode when GSER(6..8)_CFG[RMAC]
+                                                         is also set.  Lanes 0 and 1 of the 2-lane SerDes are used in PIPE mode. */
+	uint64_t rmac                         : 1;  /**< Indicates GSER(6..8) is configured for RMAC mode. Only one of the BGX, PCIE, SRIO, or
+                                                         RMAC modes can be set at any one time. */
+	uint64_t srio                         : 1;  /**< Indicates GSER(2..3) is configured for SRIO mode. GSER(2..3) will power-up with
+                                                         GSER(2..3)_CFG[SRIO] bit set by the hardware.  Only one of the BGX, PCIE, SRIO, or RMAC
+                                                         modes can be set at any one time. */
+	uint64_t sata                         : 1;  /**< Reserved. */
+	uint64_t bgx_quad                     : 1;  /**< Indicates the BGX is in quad aggregation mode when GSER(4..5)_CFG[BGX]
+                                                         is also set. A single controller is used for all four lanes. */
+	uint64_t bgx_dual                     : 1;  /**< Indicates the BGX is in dual aggregation mode when GSER(4..5)_CFG[BGX]
+                                                         is also set. A single controller is used for lanes 0 and 1 and another controller is used
+                                                         for lanes 2 and 3. */
+	uint64_t bgx                          : 1;  /**< Indicates GSER(4..5) is configured for BGX mode. Only one of the BGX,
+                                                         PCIE, SRIO, or RMAC modes can be set at any one time. */
+	uint64_t ila                          : 1;  /**< Reserved. */
+	uint64_t pcie                         : 1;  /**< Indicates GSER(0..1) is configured for PCIE mode. Only one of the BGX,
+                                                         PCIE, SRIO, or RMAC modes can be set at any one time. */
+#else
+	uint64_t pcie                         : 1;
+	uint64_t ila                          : 1;
+	uint64_t bgx                          : 1;
+	uint64_t bgx_dual                     : 1;
+	uint64_t bgx_quad                     : 1;
+	uint64_t sata                         : 1;
+	uint64_t srio                         : 1;
+	uint64_t rmac                         : 1;
+	uint64_t rmac_pipe                    : 1;
+	uint64_t reserved_9_63                : 55;
+#endif
+	} s;
+	struct cvmx_gserx_cfg_cn73xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
 	uint64_t sata                         : 1;  /**< Indicates the GSER is configured for SATA mode. Only one of the BGX, SATA, or PCIE
                                                          modes can be set at any one time. */
@@ -2502,8 +2598,7 @@ union cvmx_gserx_cfg {
 	uint64_t sata                         : 1;
 	uint64_t reserved_6_63                : 58;
 #endif
-	} s;
-	struct cvmx_gserx_cfg_s               cn73xx;
+	} cn73xx;
 	struct cvmx_gserx_cfg_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
@@ -3520,7 +3615,8 @@ union cvmx_gserx_glbl_tad {
                                                          0x01 = DFE Edge I.
                                                          0x02 = DFE CK Q.
                                                          0x03 = DFE CK I.
-                                                         0x04 = TBD.
+                                                         0x04 = DLL use GSER()_SLICE()_RX_SDLL_CTRL.PCS_SDS_RX_SDLL_SWSEL to select signal
+                                                         in the slice dll.
                                                          0x05-0x7 = Reserved.
                                                          0x08 = RX ld_rx[0].
                                                          0x09 = RX rx_clk.
@@ -4098,6 +4194,42 @@ union cvmx_gserx_lanex_pcs_ctlifc_2 {
 typedef union cvmx_gserx_lanex_pcs_ctlifc_2 cvmx_gserx_lanex_pcs_ctlifc_2_t;
 
 /**
+ * cvmx_gser#_lane#_pcs_macifc_mon_2
+ *
+ * These registers are for diagnostic use only.
+ * These registers are reset by hardware only during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ */
+union cvmx_gserx_lanex_pcs_macifc_mon_2 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_pcs_macifc_mon_2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t tx_coeff_req                 : 1;  /**< Indicates current state of the MAC to PCS Tx Coefficient Request input.
+                                                         INTERNAL: mac_pcs_txX_coeff_req. */
+	uint64_t tx_vboost_en                 : 1;  /**< Indicates current state of the MAC to PCS Tx Vboost Enable input.
+                                                         INTERNAL: mac_pcs_txX_vboost_en. */
+	uint64_t tx_swing                     : 5;  /**< Indicates current state of the MAC to PCS Tx Equalizer Swing<4:0> input.
+                                                         INTERNAL: mac_pcs_txX_swing[4:0]. */
+	uint64_t tx_pre                       : 4;  /**< Indicates current state of the MAC to PCS Tx Equalizer Pre Emphasis<3:0> input.
+                                                         INTERNAL: mac_pcs_txX_pre[3:0]. */
+	uint64_t tx_post                      : 5;  /**< Indicates current state of the MAC to PCS Tx Equalizer Post Emphasis<4:0> input.
+                                                         INTERNAL: mac_pcs_txX_post[4:0]. */
+#else
+	uint64_t tx_post                      : 5;
+	uint64_t tx_pre                       : 4;
+	uint64_t tx_swing                     : 5;
+	uint64_t tx_vboost_en                 : 1;
+	uint64_t tx_coeff_req                 : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_pcs_macifc_mon_2_s cn78xx;
+	struct cvmx_gserx_lanex_pcs_macifc_mon_2_s cn78xxp2;
+};
+typedef union cvmx_gserx_lanex_pcs_macifc_mon_2 cvmx_gserx_lanex_pcs_macifc_mon_2_t;
+
+/**
  * cvmx_gser#_lane#_pma_loopback_ctrl
  *
  * These registers are for diagnostic use only.
@@ -5778,8 +5910,8 @@ union cvmx_gserx_lane_lpbken {
 	uint64_t reserved_4_63                : 60;
 	uint64_t lpbken                       : 4;  /**< For links that are not in PCIE nor SATA mode. When asserted in P0 state,
                                                          allows per lane TX-to-RX serial loopback activation.
-                                                         <3>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <2>: Lane 2.  Not supported in GSER4, GSER5, or GSER6.
+                                                         <3>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <2>: Lane 2.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <1>: Lane 1.
                                                          <0>: Lane 0. */
 #else
@@ -6058,8 +6190,8 @@ union cvmx_gserx_lane_poff {
 	uint64_t reserved_4_63                : 60;
 	uint64_t lpoff                        : 4;  /**< For links that are not in PCIE mode, allows for per lane power
                                                          down.
-                                                         <3>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <2>: Lane 2   Not supported in GSER4, GSER5, or GSER6.
+                                                         <3>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <2>: Lane 2   Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <1>: Lane 1.
                                                          <0>: Lane 0. */
 #else
@@ -7800,8 +7932,8 @@ union cvmx_gserx_rx_coast {
                                                          exit (GSER()_RX_EIE_DETSTS[EIESTS]). Once the COAST signal deasserts, the CDR is
                                                          allowed to lock. In BGX mode, the BGX MAC can also control the COAST inputs to the PHY to
                                                          allow Auto-Negotiation for backplane Ethernet. For diagnostic use only.
-                                                         <3>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <2>: Lane 2.  Not supported in GSER4, GSER5, or GSER6.
+                                                         <3>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <2>: Lane 2.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <1>: Lane 1.
                                                          <0>: Lane 0. */
 #else
@@ -7832,8 +7964,8 @@ union cvmx_gserx_rx_eie_deten {
                                                          GSER()_RX_EIE_DETSTS[EIELTCH] is asserted. EIEDE defaults to the enabled state. Once
                                                          EIE has been detected, EIEDE must be disabled, and then enabled again to perform another
                                                          EIE detection.
-                                                         <3>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <2>: Lane 2.  Not supported in GSER4, GSER5, or GSER6.
+                                                         <3>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <2>: Lane 2.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <1>: Lane 1.
                                                          <0>: Lane 0. */
 #else
@@ -7860,8 +7992,8 @@ union cvmx_gserx_rx_eie_detsts {
                                                          lock. During this time, there may be RX bit errors. These bits will set when the CDR is
                                                          guaranteed to be locked. Note that link training can't start until the lane CDRLOCK is
                                                          set. Software can use CDRLOCK to determine when to expect error free RX data.
-                                                         <11>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <10>: Lane 2.  Not supported in GSER4, GSER5, or GSER6.
+                                                         <11>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <10>: Lane 2.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <9>: Lane 1.
                                                          <8>: Lane 0. */
 	uint64_t eiests                       : 4;  /**< When electrical idle exit detection is enabled (GSER()_RX_EIE_DETEN[EIEDE] is
@@ -7870,8 +8002,8 @@ union cvmx_gserx_rx_eie_detsts {
                                                          idle symbols) for data transitions to be detected and for EIESTS to stay set accordingly.
                                                          Under most conditions, EIESTS
                                                          will stay asserted until GSER()_RX_EIE_DETEN[EIEDE] is deasserted.
-                                                         <7>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <6>: Lane 2.  Not supported in GSER4, GSER5, or GSER6.
+                                                         <7>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <6>: Lane 2.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <5>: Lane 1.
                                                          <4>: Lane 0. */
 	uint64_t eieltch                      : 4;  /**< When electrical idle exit detection is enabled (GSER()_RX_EIE_DETEN[EIEDE] is
@@ -7880,8 +8012,8 @@ union cvmx_gserx_rx_eie_detsts {
                                                          GSER()_RX_EIE_DETEN[EIEDE] is deasserted. Note that there may be RX bit errors until
                                                          CDRLOCK
                                                          is set.
-                                                         <3>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <2>: Lane 2.  Not supported in GSER4, GSER5, or GSER6.
+                                                         <3>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <2>: Lane 2.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <1>: Lane 1.
                                                          <0>: Lane 0. */
 #else
@@ -7949,8 +8081,8 @@ union cvmx_gserx_rx_polarity {
 	uint64_t rx_inv                       : 4;  /**< For links that are not in PCIE mode, control signal to invert
                                                          the polarity of received data. When asserted, the polarity of the received data is
                                                          inverted.
-                                                         <3>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <2>: Lane 2.  Not supported in GSER4, GSER5, or GSER6.
+                                                         <3>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <2>: Lane 2.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <1>: Lane 1.
                                                          <0>: Lane 0. */
 #else
@@ -8641,8 +8773,9 @@ union cvmx_gserx_spd {
 	struct cvmx_gserx_spd_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t spd                          : 4;  /**< For CCPI links (i.e. GSER8..13), the hardware loads this CSR field from the OCI_SPD<3:0>
-                                                         pins during chip cold reset. For non-CCPI links, this field is not used.
+	uint64_t spd                          : 4;  /**< For SRIO links (i.e. GSER(2..3), the hardware loads this CSR field from the SRIO_SPD<3:0>
+                                                         signals from the SRIO MAC during chip cold reset. For non-SRIO links, this field is not
+                                                         used.
                                                          For SPD settings that configure a non-default reference clock, hardware updates the PLL
                                                          settings of the specific lane mode (LMODE) table entry to derive the correct link rate.
                                                          <pre>
@@ -8664,11 +8797,11 @@ union cvmx_gserx_spd {
                                                          0xE:  156.25 MHz  10.3125 Gb  R_103125G_REFCLK15625_KR
                                                          0xF:                          SW_MODE
                                                          </pre>
-                                                         Note that a value of 0xF is called SW_MODE. The CCPI link does not come up configured in
+                                                         Note that a value of 0xF is called SW_MODE. The SRIO link does not come up configured in
                                                          SW_MODE.
-                                                         (Software must do all the CCPI GSER configuration to use CCPI in the case of SW_MODE.)
+                                                         (Software must do all the SRIO GSER configuration to use SRIO in the case of SW_MODE.)
                                                          When SPD!=SW_MODE after a chip cold reset, the hardware has initialized the following
-                                                         registers (based on the OCI_SPD selection):
+                                                         registers (based on the SRIO_SPD selection):
                                                           * GSER()_LANE_MODE[LMODE]=Z.
                                                           * GSER()_PLL_P()_MODE_0.
                                                           * GSER()_PLL_P()_MODE_1.
@@ -8677,7 +8810,7 @@ union cvmx_gserx_spd {
                                                           * GSER()_LANE()_RX_VALBBD_CTRL_0.
                                                           * GSER()_LANE()_RX_VALBBD_CTRL_1.
                                                           * GSER()_LANE()_RX_VALBBD_CTRL_2.
-                                                          where in "GSER(x)", x is 8..13, and in "P(z)", z equals LMODE. */
+                                                          where in "GSER(x)", x is 0..8, and in "P(z)", z equals LMODE. */
 #else
 	uint64_t spd                          : 4;
 	uint64_t reserved_4_63                : 60;
@@ -8692,11 +8825,95 @@ union cvmx_gserx_spd {
 	} cn73xx;
 	struct cvmx_gserx_spd_s               cn78xx;
 	struct cvmx_gserx_spd_s               cn78xxp2;
-	struct cvmx_gserx_spd_cn73xx          cnf75xx;
+	struct cvmx_gserx_spd_s               cnf75xx;
 };
 typedef union cvmx_gserx_spd cvmx_gserx_spd_t;
 
 /**
+ * cvmx_gser#_srio_pcs_cfg_0
+ *
+ * These registers are for diagnostic use only. These registers are reset by hardware only during
+ * chip cold reset. The values of the CSR fields in these registers do not change during chip
+ * warm or soft resets.
+ */
+union cvmx_gserx_srio_pcs_cfg_0 {
+	uint64_t u64;
+	struct cvmx_gserx_srio_pcs_cfg_0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t rx_ofst                      : 4;  /**< For links that are in SRIO mode, configures the receiver offset. */
+	uint64_t com_thr                      : 4;  /**< For links that are in SRIO mode, configures the comma character threshold. */
+	uint64_t skp_max                      : 4;  /**< For links that are in SRIO mode, configures the maximum number of skip characters inserted
+                                                         by the
+                                                         SRIO PCS on the Rx data stream to the SRIO MAC */
+	uint64_t skp_min                      : 4;  /**< For links that are in SRIO mode, configures the minumum number of skip characters inserted
+                                                         by the
+                                                         SRIO PCS on the Rx data stream to the SRIO MAC. */
+#else
+	uint64_t skp_min                      : 4;
+	uint64_t skp_max                      : 4;
+	uint64_t com_thr                      : 4;
+	uint64_t rx_ofst                      : 4;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_srio_pcs_cfg_0_s    cnf75xx;
+};
+typedef union cvmx_gserx_srio_pcs_cfg_0 cvmx_gserx_srio_pcs_cfg_0_t;
+
+/**
+ * cvmx_gser#_srio_pcs_cfg_1
+ *
+ * These registers are for diagnostic use only. These registers are reset by hardware only during
+ * chip cold reset. The values of the CSR fields in these registers do not change during chip
+ * warm or soft resets.
+ */
+union cvmx_gserx_srio_pcs_cfg_1 {
+	uint64_t u64;
+	struct cvmx_gserx_srio_pcs_cfg_1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t err_thrshld                  : 2;  /**< For links that are in SRIO mode, sets the error thereshold in the SRIO PCS block. */
+	uint64_t tx_byp                       : 1;  /**< For links that are in SRIO mode, when set configures the Tx bypass diagnostic test mode. */
+	uint64_t tx_byp_inv                   : 1;  /**< For links that are in SRIO mode, when the Tx bypass diagnostic test mode is selected
+                                                         GSER()_SRIO_PCS_CFG_1.TX_BYP[ENB] inverts the Tx data. */
+	uint64_t reserved_10_11               : 2;
+	uint64_t tx_byp_val                   : 10; /**< For links that are in SRIO mode, configures the 10-bit transmit bypass value used when the
+                                                         SRIO PCS is configured for the Tx bypass diagnostic test mode
+                                                         GSER()_SRIO_PCS_CFG_1.TX_BYP[ENB]. */
+#else
+	uint64_t tx_byp_val                   : 10;
+	uint64_t reserved_10_11               : 2;
+	uint64_t tx_byp_inv                   : 1;
+	uint64_t tx_byp                       : 1;
+	uint64_t err_thrshld                  : 2;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_srio_pcs_cfg_1_cnf75xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t err_thrshld                  : 2;  /**< For links that are in SRIO mode, sets the error thereshold in the SRIO PCS block. */
+	uint64_t tx_byp                       : 1;  /**< For links that are in SRIO mode, when set configures the Tx bypass diagnostic test mode. */
+	uint64_t tx_byp_inv                   : 1;  /**< For links that are in SRIO mode, when the Tx bypass diagnostic test mode is selected
+                                                         GSER()_SRIO_PCS_CFG_1.TX_BYP[ENB] inverts the Tx data. */
+	uint64_t reserved_11_10               : 2;
+	uint64_t tx_byp_val                   : 10; /**< For links that are in SRIO mode, configures the 10-bit transmit bypass value used when the
+                                                         SRIO PCS is configured for the Tx bypass diagnostic test mode
+                                                         GSER()_SRIO_PCS_CFG_1.TX_BYP[ENB]. */
+#else
+	uint64_t tx_byp_val                   : 10;
+	uint64_t reserved_11_10               : 2;
+	uint64_t tx_byp_inv                   : 1;
+	uint64_t tx_byp                       : 1;
+	uint64_t err_thrshld                  : 2;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} cnf75xx;
+};
+typedef union cvmx_gserx_srio_pcs_cfg_1 cvmx_gserx_srio_pcs_cfg_1_t;
+
+/**
  * cvmx_gser#_srst
  *
  * These registers are reset by hardware only during chip cold reset. The values of the CSR
@@ -8734,8 +8951,8 @@ union cvmx_gserx_tx_vboost {
 	uint64_t reserved_4_63                : 60;
 	uint64_t vboost                       : 4;  /**< For links that are not in PCIE mode, boosts the TX Vswing from
                                                          VDD to 1.0 VPPD.
-                                                         <3>: Lane 3.  Not supported in GSER4, GSER5, or GSER6.
-                                                         <2>: Lane 2.  Not supported in GSER4, GSER5, or GSER6.
+                                                         <3>: Lane 3.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
+                                                         <2>: Lane 2.  Not supported in GSER2, GSER3, GSER4, GSER5, GSER6, GSER7, or GSER8.
                                                          <1>: Lane 1.
                                                          <0>: Lane 0. */
 #else
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
index c36236d..3d9cf53 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
@@ -197,6 +197,17 @@ extern int __cvmx_helper_bgx_xaui_link_set(int xipd_port,
 extern int __cvmx_helper_bgx_xaui_configure_loopback(int xipd_port,
 						     int enable_internal,
 						     int enable_external);
+
+extern int __cvmx_helper_bgx_mixed_enable(int xiface);
+
+extern cvmx_helper_link_info_t __cvmx_helper_bgx_mixed_link_get(int xipd_port);
+
+extern int __cvmx_helper_bgx_mixed_link_set(int xipd_port, cvmx_helper_link_info_t link_info);
+
+extern int __cvmx_helper_bgx_mixed_configure_loopback(int xipd_port,
+						     int enable_internal,
+						     int enable_external);
+
 /**
  * @INTERNAL
  * Configure Priority-Based Flow Control (a.k.a. PFC/CBFC)
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-board.h b/arch/mips/include/asm/octeon/cvmx-helper-board.h
index bfac979..64aa47a 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-board.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-board.h
@@ -43,7 +43,7 @@
  * Helper functions to abstract board specific data about
  * network ports from the rest of the cvmx-helper files.
  *
- * <hr>$Revision: 109826 $<hr>
+ * <hr>$Revision: 118784 $<hr>
  */
 #ifndef __CVMX_HELPER_BOARD_H__
 #define __CVMX_HELPER_BOARD_H__
@@ -69,7 +69,8 @@ typedef enum cvmx_phy_type {
 	GENERIC_8023_C22_PHY,
 	GENERIC_8023_C45_PHY,
  	INBAND_PHY,
-	QUALCOMM_S17,	/** Qualcomm QCA833X switch */
+	QUALCOMM_S17,		/** Qualcomm QCA833X switch */
+	VITESSE_VSC8490_PHY,	/** Vitesse VSC8490 is non-standard for SGMII */
 } cvmx_phy_type_t;
 
 /** Used to record the host mode used by the Cortina CS4321 PHY */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-pko3.h b/arch/mips/include/asm/octeon/cvmx-helper-pko3.h
index 2c97a2f1..7a4dc3e 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-pko3.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-pko3.h
@@ -106,6 +106,13 @@ extern int cvmx_helper_pko3_shutdown(unsigned int node);
  */
 int cvmx_helper_pko3_config_dump(unsigned int node);
 
+/**
+ * Show integrated PKO statistics.
+ *
+ * @param node	   node number
+ */
+int cvmx_helper_pko3_stats_dump(unsigned int node);
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-srio.h b/arch/mips/include/asm/octeon/cvmx-helper-srio.h
index 7bcf2be..fe4d664 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-srio.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-srio.h
@@ -50,6 +50,17 @@
 
 /**
  * @INTERNAL
+ * Convert interface number to sRIO link number
+ * per SoC model.
+ *
+ * @param xiface Interface to convert
+ *
+ * @return Srio link number
+ */
+extern int __cvmx_helper_srio_port(int xiface);
+
+/**
+ * @INTERNAL
  * Probe a SRIO interface and determine the number of ports
  * connected to it. The SRIO interface should still be down after
  * this call.
diff --git a/arch/mips/include/asm/octeon/cvmx-helper.h b/arch/mips/include/asm/octeon/cvmx-helper.h
index f1561b0..2b2cfd5 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper.h
@@ -42,7 +42,7 @@
  *
  * Helper functions for common, but complicated tasks.
  *
- * <hr>$Revision: 109369 $<hr>
+ * <hr>$Revision: 117608 $<hr>
  */
 
 #ifndef __CVMX_HELPER_H__
@@ -61,8 +61,11 @@ extern "C" {
 #endif
 
 /* Max number of GMXX */
-#define CVMX_HELPER_MAX_GMX             (OCTEON_IS_MODEL(OCTEON_CN78XX) ? 6 \
-					 : (OCTEON_IS_MODEL(OCTEON_CN68XX) ? 5 : 2))
+#define CVMX_HELPER_MAX_GMX	(OCTEON_IS_MODEL(OCTEON_CN78XX) ? 6 \
+				 : (OCTEON_IS_MODEL(OCTEON_CN68XX) ? 5 \
+				    : (OCTEON_IS_MODEL(OCTEON_CN73XX) ? 3 \
+				       : (OCTEON_IS_MODEL(OCTEON_CNF75XX) ? 1 \
+					  : 2))))
 
 #define CVMX_HELPER_CSR_INIT0           0	/* Do not change as
 						   CVMX_HELPER_WRITE_CSR()
@@ -132,6 +135,7 @@ typedef enum {
 	CVMX_HELPER_INTERFACE_MODE_XFI,
 	CVMX_HELPER_INTERFACE_MODE_10G_KR,
 	CVMX_HELPER_INTERFACE_MODE_40G_KR4,
+	CVMX_HELPER_INTERFACE_MODE_MIXED,
 } cvmx_helper_interface_mode_t;
 
 typedef union {
diff --git a/arch/mips/include/asm/octeon/cvmx-hna-defs.h b/arch/mips/include/asm/octeon/cvmx-hna-defs.h
index 19a1c79..3641bfe 100644
--- a/arch/mips/include/asm/octeon/cvmx-hna-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-hna-defs.h
@@ -133,7 +133,7 @@ static inline uint64_t CVMX_HNA_DIFRDPTR_FUNC(void)
 #define CVMX_HNA_ECO CVMX_HNA_ECO_FUNC()
 static inline uint64_t CVMX_HNA_ECO_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX)))
 		cvmx_warn("CVMX_HNA_ECO not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800470000D0ull);
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
index d6f4f2c..ed2104c 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
@@ -1819,7 +1819,7 @@ union cvmx_ilk_rid_cfg {
                                                          restrict each link individually. */
 	uint64_t reserved_7_31                : 25;
 	uint64_t base                         : 7;  /**< The base RID for ILK. There is a shared pool of 96 RIDs for all MACs.
-                                                         ILK can allocate any RID in the range of
+                                                         See PKI_REASM_E. ILK can allocate any RID in the range of
                                                          _ BASE -> (BASE+(MAX_CNT-1)).
                                                          BASE and MAX_CNT must be constrained such that:
                                                          _ 1) BASE >= 2.
diff --git a/arch/mips/include/asm/octeon/cvmx-ipd.h b/arch/mips/include/asm/octeon/cvmx-ipd.h
index a97b045..a07f8cb 100644
--- a/arch/mips/include/asm/octeon/cvmx-ipd.h
+++ b/arch/mips/include/asm/octeon/cvmx-ipd.h
@@ -42,7 +42,7 @@
  *
  * Interface to the hardware Input Packet Data unit.
  *
- * <hr>$Revision: 98855 $<hr>
+ * <hr>$Revision: 116854 $<hr>
  */
 
 #ifndef __CVMX_IPD_H__
@@ -50,13 +50,13 @@
 
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-fpa.h>
 #include <asm/octeon/cvmx-ipd-defs.h>
-#include <asm/octeon/cvmx-helper-pki.h>
+#include <asm/octeon/cvmx-pki.h>
 #else
-#include "cvmx-helper-pki.h"
+#include "cvmx-pki.h"
 #endif
 
-
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 extern "C" {
@@ -109,10 +109,6 @@ extern CVMX_SHARED cvmx_ipd_config_t cvmx_ipd_cfg;
  */
 static inline int64_t cvmx_fpa_get_packet_pool(void)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		int node = cvmx_get_node_num();
-		return pki_dflt_aura[node].aura_num;
-	}
 	return (cvmx_ipd_cfg.packet_pool.pool_num);
 }
 
@@ -121,10 +117,6 @@ static inline int64_t cvmx_fpa_get_packet_pool(void)
  */
 static inline uint64_t cvmx_fpa_get_packet_pool_block_size(void)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		int node = cvmx_get_node_num();
-		return pki_dflt_pool[node].buffer_size;
-	}
 	return (cvmx_ipd_cfg.packet_pool.buffer_size);
 }
 
@@ -133,10 +125,6 @@ static inline uint64_t cvmx_fpa_get_packet_pool_block_size(void)
  */
 static inline uint64_t cvmx_fpa_get_packet_pool_buffer_count(void)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		int node = cvmx_get_node_num();
-		return pki_dflt_pool[node].buffer_count;
-	}
 	return (cvmx_ipd_cfg.packet_pool.buffer_count);
 }
 
@@ -145,10 +133,6 @@ static inline uint64_t cvmx_fpa_get_packet_pool_buffer_count(void)
  */
 static inline int64_t cvmx_fpa_get_wqe_pool(void)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		int node = cvmx_get_node_num();
-		return pki_dflt_aura[node].aura_num;
-	}
 	return (cvmx_ipd_cfg.wqe_pool.pool_num);
 }
 
@@ -157,10 +141,6 @@ static inline int64_t cvmx_fpa_get_wqe_pool(void)
  */
 static inline uint64_t cvmx_fpa_get_wqe_pool_block_size(void)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		int node = cvmx_get_node_num();
-		return pki_dflt_pool[node].buffer_size;
-	}
 	return (cvmx_ipd_cfg.wqe_pool.buffer_size);
 }
 
@@ -169,10 +149,6 @@ static inline uint64_t cvmx_fpa_get_wqe_pool_block_size(void)
  */
 static inline uint64_t cvmx_fpa_get_wqe_pool_buffer_count(void)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		int node = cvmx_get_node_num();
-		return pki_dflt_pool[node].buffer_count;
-	}
 	return (cvmx_ipd_cfg.wqe_pool.buffer_count);
 }
 
@@ -206,6 +182,52 @@ void cvmx_ipd_set_wqe_pool_config(int64_t pool, uint64_t buffer_size,
 				       uint64_t buffer_count);
 
 /**
+ * Gets the FPA packet buffer pool parameters.
+ */
+static inline void cvmx_fpa_get_packet_pool_config(int64_t *pool,
+						uint64_t *buffer_size, uint64_t *buffer_count)
+{
+	if (pool != NULL)
+		*pool = cvmx_ipd_cfg.packet_pool.pool_num;
+	if (buffer_size != NULL)
+		*buffer_size = cvmx_ipd_cfg.packet_pool.buffer_size;
+	if (buffer_count != NULL)
+		*buffer_count = cvmx_ipd_cfg.packet_pool.buffer_count;
+}
+
+/**
+ * Sets the FPA packet buffer pool parameters.
+ */
+static inline void cvmx_fpa_set_packet_pool_config(int64_t pool,
+						uint64_t buffer_size, uint64_t buffer_count)
+{
+	cvmx_ipd_set_packet_pool_config(pool, buffer_size, buffer_count);
+}
+
+/**
+ * Gets the FPA WQE pool parameters.
+ */
+static inline void cvmx_fpa_get_wqe_pool_config(int64_t *pool,
+						uint64_t *buffer_size, uint64_t *buffer_count)
+{
+	if (pool != NULL)
+		*pool = cvmx_ipd_cfg.wqe_pool.pool_num;
+	if (buffer_size != NULL)
+		*buffer_size = cvmx_ipd_cfg.wqe_pool.buffer_size;
+	if (buffer_count != NULL)
+		*buffer_count = cvmx_ipd_cfg.wqe_pool.buffer_count;
+}
+
+/**
+ * Sets the FPA WQE pool parameters.
+ */
+static inline void cvmx_fpa_set_wqe_pool_config(int64_t pool,
+						uint64_t buffer_size, uint64_t buffer_count)
+{
+	cvmx_ipd_set_wqe_pool_config(pool, buffer_size, buffer_count);
+}
+
+/**
  * Configure IPD
  *
  * @param mbuff_size Packets buffer size in 8 byte words
diff --git a/arch/mips/include/asm/octeon/cvmx-l2c-defs.h b/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
index 11f9f2d..5b57f15 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
@@ -237,15 +237,15 @@ static inline uint64_t CVMX_L2C_CBCX_IODISOCIERR(unsigned long offset)
 static inline uint64_t CVMX_L2C_CBCX_MIBERR(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if (((offset >= 2) && (offset <= 3)))
-				return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + ((offset) & 3) * 0x40000ull - 262144*2;
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset == 1))
 				return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + ((offset) & 1) * 0x40000ull - 262144*1;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if (((offset >= 2) && (offset <= 3)))
+				return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + ((offset) & 3) * 0x40000ull - 262144*2;
+			break;
 	}
 	cvmx_warn("CVMX_L2C_CBCX_MIBERR (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + ((offset) & 1) * 0x40000ull - 262144*1;
@@ -254,11 +254,11 @@ static inline uint64_t CVMX_L2C_CBCX_MIBERR(unsigned long offset)
 static inline uint64_t CVMX_L2C_CBCX_MIBERR(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + (offset) * 0x40000ull - 262144*2;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + (offset) * 0x40000ull - 262144*1;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + (offset) * 0x40000ull - 262144*2;
 	}
 	return CVMX_ADD_IO_SEG(0x0001180080E807E0ull) + (offset) * 0x40000ull - 262144*1;
 }
@@ -970,7 +970,8 @@ static inline uint64_t CVMX_L2C_RSDX_PFC(unsigned long offset)
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_L2C_RTGX_ERR(unsigned long offset)
 {
-	if ((0))
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 7)))))
 		cvmx_warn("CVMX_L2C_RTGX_ERR(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180080A00800ull) + ((offset) & 7) * 0x40000ull;
 }
@@ -1222,6 +1223,7 @@ static inline uint64_t CVMX_L2C_TADX_STAT(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 3))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 7))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 3)))))
 		cvmx_warn("CVMX_L2C_TADX_STAT(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180080A00020ull) + ((offset) & 7) * 0x40000ull;
diff --git a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
index 845d7b2..9d00c03 100644
--- a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
@@ -53,6 +53,28 @@
 #define __CVMX_LMCX_DEFS_H__
 
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_LMCX_BANK_CONFLICT1(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3)))))
+		cvmx_warn("CVMX_LMCX_BANK_CONFLICT1(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001180088000360ull) + ((offset) & 3) * 0x1000000ull;
+}
+#else
+#define CVMX_LMCX_BANK_CONFLICT1(offset) (CVMX_ADD_IO_SEG(0x0001180088000360ull) + ((offset) & 3) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_LMCX_BANK_CONFLICT2(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3)))))
+		cvmx_warn("CVMX_LMCX_BANK_CONFLICT2(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001180088000368ull) + ((offset) & 3) * 0x1000000ull;
+}
+#else
+#define CVMX_LMCX_BANK_CONFLICT2(offset) (CVMX_ADD_IO_SEG(0x0001180088000368ull) + ((offset) & 3) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_LMCX_BIST_CTL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
@@ -354,6 +376,7 @@ static inline uint64_t CVMX_LMCX_DBTRAIN_CTL(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_DBTRAIN_CTL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800880003F8ull) + ((offset) & 3) * 0x1000000ull;
@@ -613,11 +636,11 @@ static inline uint64_t CVMX_LMCX_DUAL_MEMCFG(unsigned long offset)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((offset == 0))
 				return CVMX_ADD_IO_SEG(0x0001180088000098ull) + ((offset) & 0) * 0x60000000ull;
@@ -646,11 +669,11 @@ static inline uint64_t CVMX_LMCX_DUAL_MEMCFG(unsigned long offset)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180088000098ull) + (offset) * 0x60000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
@@ -761,6 +784,7 @@ static inline uint64_t CVMX_LMCX_EXT_CONFIG2(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_EXT_CONFIG2(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000090ull) + ((offset) & 3) * 0x1000000ull;
@@ -837,6 +861,7 @@ static inline uint64_t CVMX_LMCX_GENERAL_PURPOSE0(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_GENERAL_PURPOSE0(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000340ull) + ((offset) & 3) * 0x1000000ull;
@@ -849,6 +874,7 @@ static inline uint64_t CVMX_LMCX_GENERAL_PURPOSE1(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_GENERAL_PURPOSE1(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000348ull) + ((offset) & 3) * 0x1000000ull;
@@ -861,6 +887,7 @@ static inline uint64_t CVMX_LMCX_GENERAL_PURPOSE2(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_GENERAL_PURPOSE2(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000350ull) + ((offset) & 3) * 0x1000000ull;
@@ -1133,6 +1160,7 @@ static inline uint64_t CVMX_LMCX_NS_CTL(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_NS_CTL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000178ull) + ((offset) & 3) * 0x1000000ull;
@@ -1328,6 +1356,7 @@ static inline uint64_t CVMX_LMCX_PPR_CTL(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_PPR_CTL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800880003E0ull) + ((offset) & 3) * 0x1000000ull;
@@ -1376,6 +1405,7 @@ static inline uint64_t CVMX_LMCX_REF_STATUS(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_REF_STATUS(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800880000A0ull) + ((offset) & 3) * 0x1000000ull;
@@ -1407,6 +1437,7 @@ static inline uint64_t CVMX_LMCX_RETRY_CONFIG(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_RETRY_CONFIG(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000110ull) + ((offset) & 3) * 0x1000000ull;
@@ -1419,6 +1450,7 @@ static inline uint64_t CVMX_LMCX_RETRY_STATUS(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_RETRY_STATUS(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000118ull) + ((offset) & 3) * 0x1000000ull;
@@ -1589,6 +1621,7 @@ static inline uint64_t CVMX_LMCX_SCRAMBLE_CFG2(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_SCRAMBLE_CFG2(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000338ull) + ((offset) & 3) * 0x1000000ull;
@@ -1672,6 +1705,7 @@ static inline uint64_t CVMX_LMCX_SLOT_CTL3(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_LMCX_SLOT_CTL3(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180088000248ull) + ((offset) & 3) * 0x1000000ull;
@@ -1909,6 +1943,50 @@ static inline uint64_t CVMX_LMCX_WODT_MASK(unsigned long offset)
 #endif
 
 /**
+ * cvmx_lmc#_bank_conflict1
+ *
+ * Added in pass 2.0.
+ *
+ */
+union cvmx_lmcx_bank_conflict1 {
+	uint64_t u64;
+	struct cvmx_lmcx_bank_conflict1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t cnt                          : 64; /**< Bank conflict counter. A 64-bit counter that increments at every dclk
+                                                         cycles when LMC could not issue R/W operations to the DRAM due to
+                                                         bank conflict. This increments when all 8 in-flight buffers are not
+                                                         utilized. */
+#else
+	uint64_t cnt                          : 64;
+#endif
+	} s;
+	struct cvmx_lmcx_bank_conflict1_s     cn78xxp2;
+};
+typedef union cvmx_lmcx_bank_conflict1 cvmx_lmcx_bank_conflict1_t;
+
+/**
+ * cvmx_lmc#_bank_conflict2
+ *
+ * Added in pass 2.0.
+ *
+ */
+union cvmx_lmcx_bank_conflict2 {
+	uint64_t u64;
+	struct cvmx_lmcx_bank_conflict2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t cnt                          : 64; /**< Bank conflict counter. A 64-bit counter that increments at every dclk
+                                                         cycles when LMC could not issue R/W operations to the DRAM due to
+                                                         bank conflict. This increments only when there are less than 4 in-flight
+                                                         buffers that are not utilized. */
+#else
+	uint64_t cnt                          : 64;
+#endif
+	} s;
+	struct cvmx_lmcx_bank_conflict2_s     cn78xxp2;
+};
+typedef union cvmx_lmcx_bank_conflict2 cvmx_lmcx_bank_conflict2_t;
+
+/**
  * cvmx_lmc#_bist_ctl
  *
  * This register has fields to control BIST operation.
@@ -2966,7 +3044,7 @@ union cvmx_lmcx_config {
                                                          16. So, row = mem_adr<29:16>.
                                                          With RANK_ENA = 0, PBANK_LSB = 2.
                                                          With RANK_ENA = 1, PBANK_LSB = 3.
-                                                         TBD for interfacing with 8H 3DS, regardless of RANK_ENA value, set this 0xA. */
+                                                         When interfacing with 8H 3DS, set this 0xA regardless of RANK_ENA value. */
 	uint64_t row_lsb                      : 3;  /**< "Row address bit select.
                                                          0x0 = Address bit 14 is LSB.
                                                          0x1 = Address bit 15 is LSB.
@@ -4300,7 +4378,7 @@ union cvmx_lmcx_config {
                                                          16. So, row = mem_adr<29:16>.
                                                          With RANK_ENA = 0, PBANK_LSB = 2.
                                                          With RANK_ENA = 1, PBANK_LSB = 3.
-                                                         TBD for interfacing with 8H 3DS, regardless of RANK_ENA value, set this 0xA. */
+                                                         When interfacing with 8H 3DS, set this 0xA regardless of RANK_ENA value. */
 	uint64_t row_lsb                      : 3;  /**< "Row address bit select.
                                                          0x0 = Address bit 14 is LSB.
                                                          0x1 = Address bit 15 is LSB.
@@ -7323,8 +7401,7 @@ union cvmx_lmcx_ext_config {
                                                          Intended to be use for the case of DIMM1 having bigger rank/s
                                                          than DIMM0. This bit has priority over DIMM_SEL_INVERT_OFF. */
 	uint64_t coalesce_address_mode        : 1;  /**< When set to 1, this bit enables LMC to coalesce the cache-line
-                                                         address space into the DRAMs' address.
-                                                         INTERNAL: FIXME - more explanation */
+                                                         address space into the DRAMs' address. */
 	uint64_t dimm1_cid                    : 2;  /**< DIMM1 configuration bits that represent the number of Chip
                                                          ID of the DRAM. This value is use for decoding address
                                                          as well as routing Chip IDs to the appropriate output
@@ -7500,6 +7577,66 @@ union cvmx_lmcx_ext_config2 {
 	uint64_t u64;
 	struct cvmx_lmcx_ext_config2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t xor_bank_sel                 : 4;  /**< When LMC()_CONTROL[XOR_BANK] is set to 1, this field selects which
+                                                         L2C-LMC address bits are used to XOR the bank bits with.
+                                                         0x0: bank<3:0> = address<10:7> ^ address<15:12>.
+                                                         0x1: bank<3:0> = address<10:7> ^ address<13:10>.
+                                                         0x2: bank<3:0> = address<10:7> ^ address<14:11>.
+                                                         0x3: bank<3:0> = address<10:7> ^ address<15:12>.
+                                                         0x4: bank<3:0> = address<10:7> ^ address<16:13>.
+                                                         0x5: bank<3:0> = address<10:7> ^ address<17:14>.
+                                                         0x6: bank<3:0> = address<10:7> ^ address<18:15>.
+                                                         0x7: bank<3:0> = address<10:7> ^ address<22:19>.
+                                                         0x8: bank<3:0> = address<10:7> ^ address<23:20>.
+                                                         0x9: bank<3:0> = address<10:7> ^ address<26:23>.
+                                                         0xA: bank<3:0> = address<10:7> ^ address<27:24>.
+                                                         0xB: bank<3:0> = address<10:7> ^ address<30:27>.
+                                                         0xC: bank<3:0> = address<10:7> ^ address<31:28>.
+                                                         0xD: bank<3:0> = address<10:7> ^ address<32:29>.
+                                                         0xE: bank<3:0> = address<10:7> ^ address<35:32>.
+                                                         0xF: bank<3:0> = address<10:7> ^ address<36:33>. */
+	uint64_t reserved_10_11               : 2;
+	uint64_t row_col_switch               : 1;  /**< When set, the memory address bit position that represents bit 4 of the COLUMN
+                                                         address (bit 5 in 32-bit mode) becomes the low order DDR ROW address bit.
+                                                         The upper DDR COLUMN address portion is selected using LMC()_CONFIG[ROW_LSB]
+                                                         (and LMC()_DUAL_MEMCFG[ROW_LSB] for dual-memory configuration).
+                                                         It is recommended to set this bit to 1 when TRR_ON is set. */
+	uint64_t trr_on                       : 1;  /**< When set, this enables row activates counts of the
+                                                         DRAM used in Target Row Refresh mode. This bit can
+                                                         be safely set after the LMC()_EXT_CONFIG2[MACRAM_SCRUB_DONE]
+                                                         has a value of 1. */
+	uint64_t mac                          : 3;  /**< Sets the maximum number of activates allowed within a tMAW interval.
+                                                         0x0 = 100K.
+                                                         0x1 = 400K/2.
+                                                         0x2 = 500K/2.
+                                                         0x3 = 600K/2.
+                                                         0x4 = 700K/2.
+                                                         0x5 = 800K/2.
+                                                         0x6 = 900K/2.
+                                                         0x7 = 1000K/2. */
+	uint64_t macram_scrub_done            : 1;  /**< Maximum Activate Count memory scrub complete indication;
+                                                         1 means the memory has been scrubbed to all zero. */
+	uint64_t macram_scrub                 : 1;  /**< When set, the Maximum Activate Count memory will be scrubbed to all zero values. This
+                                                         should be done before enabling TRR mode by setting LMC()_EXT_CONFIG2[TRR_ON].
+                                                         This is a one-shot operation; it automatically returns to 0 after a write to 1. */
+	uint64_t macram_flip_synd             : 2;  /**< Reserved. INTERNAL: MAC RAM flip syndrome control bits. */
+	uint64_t macram_cor_dis               : 1;  /**< Reserved. INTERNAL: MAC RAM correction disable control. */
+#else
+	uint64_t macram_cor_dis               : 1;
+	uint64_t macram_flip_synd             : 2;
+	uint64_t macram_scrub                 : 1;
+	uint64_t macram_scrub_done            : 1;
+	uint64_t mac                          : 3;
+	uint64_t trr_on                       : 1;
+	uint64_t row_col_switch               : 1;
+	uint64_t reserved_10_11               : 2;
+	uint64_t xor_bank_sel                 : 4;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_lmcx_ext_config2_cn73xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
 	uint64_t row_col_switch               : 1;  /**< When set, the memory address bit position that represents bit 4 of the COLUMN
                                                          address (bit 5 in 32-bit mode) becomes the low order DDR ROW address bit.
@@ -7536,10 +7673,9 @@ union cvmx_lmcx_ext_config2 {
 	uint64_t row_col_switch               : 1;
 	uint64_t reserved_10_63               : 54;
 #endif
-	} s;
-	struct cvmx_lmcx_ext_config2_s        cn73xx;
+	} cn73xx;
 	struct cvmx_lmcx_ext_config2_s        cn78xxp2;
-	struct cvmx_lmcx_ext_config2_s        cnf75xx;
+	struct cvmx_lmcx_ext_config2_cn73xx   cnf75xx;
 };
 typedef union cvmx_lmcx_ext_config2 cvmx_lmcx_ext_config2_t;
 
diff --git a/arch/mips/include/asm/octeon/cvmx-mio-defs.h b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
index 0fa1422..dcd8bd2 100644
--- a/arch/mips/include/asm/octeon/cvmx-mio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
@@ -150,6 +150,7 @@ static inline uint64_t CVMX_MIO_BOOT_DMA_INT_W1SX(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_MIO_BOOT_DMA_INT_W1SX(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180000000150ull) + ((offset) & 1) * 8;
@@ -181,7 +182,7 @@ static inline uint64_t CVMX_MIO_BOOT_DMA_TIMX(unsigned long offset)
 #define CVMX_MIO_BOOT_ECO CVMX_MIO_BOOT_ECO_FUNC()
 static inline uint64_t CVMX_MIO_BOOT_ECO_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_MIO_BOOT_ECO not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800000001F8ull);
 }
@@ -635,11 +636,11 @@ static inline uint64_t CVMX_MIO_FUS_PDF_FUNC(void)
 			break;
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180000001420ull);
@@ -660,11 +661,11 @@ static inline uint64_t CVMX_MIO_FUS_PDF_FUNC(void)
 			return CVMX_ADD_IO_SEG(0x0001180000001428ull);
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180000001420ull);
@@ -1232,6 +1233,7 @@ static inline uint64_t CVMX_MIO_TWSX_INT_W1S(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_MIO_TWSX_INT_W1S(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180000001020ull) + ((offset) & 1) * 512;
@@ -7553,7 +7555,7 @@ typedef union cvmx_mio_ptp_ckout_thresh_lo cvmx_mio_ptp_ckout_thresh_lo_t;
 /**
  * cvmx_mio_ptp_clock_cfg
  *
- * This register configures the timestamp architecture. See MIO_PTP Registers for address
+ * This register configures the timestamp architecture.
  *
  */
 union cvmx_mio_ptp_clock_cfg {
diff --git a/arch/mips/include/asm/octeon/cvmx-mixx-defs.h b/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
index 03b0fcf..8fad590 100644
--- a/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
@@ -206,6 +206,7 @@ static inline uint64_t CVMX_MIXX_ISR_W1S(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_MIXX_ISR_W1S(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001070000100050ull) + ((offset) & 1) * 2048;
diff --git a/arch/mips/include/asm/octeon/cvmx-mpi-defs.h b/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
index 1029d92..69e2eee 100644
--- a/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
@@ -98,7 +98,7 @@ static inline uint64_t CVMX_MPI_STS_FUNC(void)
 #define CVMX_MPI_STS_W1S CVMX_MPI_STS_W1S_FUNC()
 static inline uint64_t CVMX_MPI_STS_W1S_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_MPI_STS_W1S not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001070000001018ull);
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
index cc6ccfd..a46d3d1 100644
--- a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
@@ -128,6 +128,7 @@ static inline uint64_t CVMX_OCLAX_ECO(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((offset == 0))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2)))))
 		cvmx_warn("CVMX_OCLAX_ECO(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800A80000D0ull) + ((offset) & 7) * 0x1000000ull;
@@ -526,16 +527,17 @@ union cvmx_oclax_cdhx_ctl {
                                                          mux selected by PLA1 and 0. The output is thus calculated from the equation:
                                                            fsmcap0 = OCLA(0..2)_FSM(0)_STATE[state0][CAP].
                                                            fsmcap1 = OCLA(0..2)_FSM(1)_STATE[state1][CAP].
-                                                           out = (   (<3> & fsmcap0 & fsmcap0)
+                                                           out = (   (<3> & fsmcap1 & fsmcap0)
                                                          _        || (<2> & fsmcap1 & !fsmcap0)
                                                          _        || (<1> & !fsmcap1 & fsmcap0)
                                                          _        || (<0> & !fsmcap1 & !fsmcap0)).
                                                          Common examples:
                                                          0x0 = No capture.
-                                                         0x2 = Capture when fsmcap0 requests capture.
-                                                         0x4 = Capture when fsmcap1 requests capture.
-                                                         0x6 = Capture on fsmcap0 | fsmcap1.
+                                                         0xA = Capture when fsmcap0 requests capture.
+                                                         0xC = Capture when fsmcap1 requests capture.
+                                                         0x6 = Capture on fsmcap0 EXOR fsmcap1.
                                                          0x8 = Capture on fsmcap0 & fsmcap1.
+                                                         0xE = Capture on fsmcap0 | fsmcap1.
                                                          0xF = Always capture. */
 #else
 	uint64_t cap_ctl                      : 4;
@@ -843,7 +845,7 @@ union cvmx_oclax_fsmx_orx {
 	struct cvmx_oclax_fsmx_orx_cn70xxp1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t or_state                     : 4;  /**< Column to drive on PLA OR-plane. Widened to 16-bits in pass 2. */
+	uint64_t or_state                     : 4;  /**< Column to drive on PLA OR-plane. */
 #else
 	uint64_t or_state                     : 4;
 	uint64_t reserved_4_63                : 60;
diff --git a/arch/mips/include/asm/octeon/cvmx-ocx-defs.h b/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
index 329cd2e..31be22d 100644
--- a/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
@@ -592,6 +592,17 @@ static inline uint64_t CVMX_OCX_RLKX_MCD_CTL(unsigned long offset)
 #define CVMX_OCX_RLKX_MCD_CTL(offset) (CVMX_ADD_IO_SEG(0x0001180011018020ull) + ((offset) & 3) * 8192)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_OCX_STRAP CVMX_OCX_STRAP_FUNC()
+static inline uint64_t CVMX_OCX_STRAP_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_OCX_STRAP not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x000118001100FF08ull);
+}
+#else
+#define CVMX_OCX_STRAP (CVMX_ADD_IO_SEG(0x000118001100FF08ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_OCX_TLKX_BIST_STATUS(unsigned long offset)
 {
 	if (!(
@@ -605,7 +616,8 @@ static inline uint64_t CVMX_OCX_TLKX_BIST_STATUS(unsigned long offset)
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_OCX_TLKX_BYP_CTL(unsigned long offset)
 {
-	if(0)
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 2)))))
 		cvmx_warn("CVMX_OCX_TLKX_BYP_CTL(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180011010030ull) + ((offset) & 3) * 8192;
 }
@@ -1953,9 +1965,12 @@ union cvmx_ocx_lnkx_cfg {
 	uint64_t lane_rev                     : 1;  /**< RX lane reversal.   When enabled, lane destriping is performed from the most significant
                                                          lane enabled to least significant lane enabled QLM_SELECT must be zero before changing
                                                          LANE_REV. */
-	uint64_t reserved_0_7                 : 8;
+	uint64_t lane_rev_auto                : 1;  /**< Automatically detect RX lane reversal.   When enable, LANE_REV will be updated by HW.
+                                                         Added in pass 2. */
+	uint64_t reserved_0_6                 : 7;
 #else
-	uint64_t reserved_0_7                 : 8;
+	uint64_t reserved_0_6                 : 7;
+	uint64_t lane_rev_auto                : 1;
 	uint64_t lane_rev                     : 1;
 	uint64_t lane_align_dis               : 1;
 	uint64_t low_delay                    : 6;
@@ -2314,6 +2329,41 @@ union cvmx_ocx_rlkx_mcd_ctl {
 typedef union cvmx_ocx_rlkx_mcd_ctl cvmx_ocx_rlkx_mcd_ctl_t;
 
 /**
+ * cvmx_ocx_strap
+ *
+ * This register provide read-only access to OCI straps.  Added in pass 2.
+ *
+ */
+union cvmx_ocx_strap {
+	uint64_t u64;
+	struct cvmx_ocx_strap_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_26_63               : 38;
+	uint64_t oci3_lnk1                    : 1;  /**< OCI3_LNK1 strap. */
+	uint64_t oci2_lnk1                    : 1;  /**< OCI2_LNK1 strap. */
+	uint64_t reserved_17_23               : 7;
+	uint64_t oci_fixed_node               : 1;  /**< OCI_FIXED_NODE strap. */
+	uint64_t reserved_10_15               : 6;
+	uint64_t oci_node_id                  : 2;  /**< OCI_NODE_ID<1:0> straps. */
+	uint64_t reserved_4_7                 : 4;
+	uint64_t oci_spd                      : 4;  /**< OCI_SPD<3:0> straps. */
+#else
+	uint64_t oci_spd                      : 4;
+	uint64_t reserved_4_7                 : 4;
+	uint64_t oci_node_id                  : 2;
+	uint64_t reserved_10_15               : 6;
+	uint64_t oci_fixed_node               : 1;
+	uint64_t reserved_17_23               : 7;
+	uint64_t oci2_lnk1                    : 1;
+	uint64_t oci3_lnk1                    : 1;
+	uint64_t reserved_26_63               : 38;
+#endif
+	} s;
+	struct cvmx_ocx_strap_s               cn78xxp2;
+};
+typedef union cvmx_ocx_strap cvmx_ocx_strap_t;
+
+/**
  * cvmx_ocx_tlk#_bist_status
  *
  * Contains status from last memory BIST for all TX FIFO memories and REPLAY memories in this
@@ -2603,10 +2653,11 @@ union cvmx_ocx_tlkx_stat_matchx {
 	uint64_t mask                         : 9;  /**< Setting these bits mask (really matches) the corresponding bit comparison for each packet. */
 	uint64_t reserved_9_15                : 7;
 	uint64_t cmd                          : 5;  /**< These bits are compared against the command for each packet sent over the link. If both
-                                                         the unmasked VC and CMD bits match then OCX_TLK(0..2)_STAT_MAT(0..3)_CNT is incremented. */
-	uint64_t vc                           : 4;  /**< These bits are compared against the link VC number for each packet sent over the link. If
-                                                         both the unmasked VC and CMD bits match, then OCX_TLK(0..2)_STAT_MAT(0..3)_CNT is
-                                                         incremented. */
+                                                         the unmasked VC and CMD bits match then OCX_TLK()_STAT_MAT()_CNT is incremented. */
+	uint64_t vc                           : 4;  /**< These bits are compared against the link VC number for each packet sent over the link.
+                                                         If both the unmasked VC and CMD bits match, then OCX_TLK()_STAT_MAT()_CNT is
+                                                         incremented.  Only memory and I/O traffic are monitored.  Matches are limited to
+                                                         VC0 thru VC11. */
 #else
 	uint64_t vc                           : 4;
 	uint64_t cmd                          : 5;
diff --git a/arch/mips/include/asm/octeon/cvmx-osm-defs.h b/arch/mips/include/asm/octeon/cvmx-osm-defs.h
index 416b6fd..729e645 100644
--- a/arch/mips/include/asm/octeon/cvmx-osm-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-osm-defs.h
@@ -67,14 +67,14 @@ static inline uint64_t CVMX_OSM_ASE_RATE_LIMIT_CTRL_FUNC(void)
 static inline uint64_t CVMX_OSM_BANKX_CTRL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011800DC001000ull) + ((offset) & 63) * 8;
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
 				return CVMX_ADD_IO_SEG(0x0001DC0000001000ull) + ((offset) & 31) * 8;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 63))
+				return CVMX_ADD_IO_SEG(0x00011800DC001000ull) + ((offset) & 63) * 8;
+			break;
 	}
 	cvmx_warn("CVMX_OSM_BANKX_CTRL (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800DC001000ull) + ((offset) & 63) * 8;
@@ -83,10 +83,10 @@ static inline uint64_t CVMX_OSM_BANKX_CTRL(unsigned long offset)
 static inline uint64_t CVMX_OSM_BANKX_CTRL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC001000ull) + (offset) * 8;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000001000ull) + (offset) * 8;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC001000ull) + (offset) * 8;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800DC001000ull) + (offset) * 8;
 }
@@ -107,12 +107,12 @@ static inline uint64_t CVMX_OSM_CLK_CFG_FUNC(void)
 static inline uint64_t CVMX_OSM_ECC_CTRL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC000020ull);
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000000020ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC000020ull);
+			break;
 	}
 	cvmx_warn("CVMX_OSM_ECC_CTRL not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800DC000020ull);
@@ -122,10 +122,10 @@ static inline uint64_t CVMX_OSM_ECC_CTRL_FUNC(void)
 static inline uint64_t CVMX_OSM_ECC_CTRL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC000020ull);
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000000020ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC000020ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011800DC000020ull);
 }
@@ -135,12 +135,12 @@ static inline uint64_t CVMX_OSM_ECC_CTRL_FUNC(void)
 static inline uint64_t CVMX_OSM_ECO_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC003000ull);
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000003000ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC003000ull);
+			break;
 	}
 	cvmx_warn("CVMX_OSM_ECO not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800DC003000ull);
@@ -150,10 +150,10 @@ static inline uint64_t CVMX_OSM_ECO_FUNC(void)
 static inline uint64_t CVMX_OSM_ECO_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC003000ull);
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000003000ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC003000ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011800DC003000ull);
 }
@@ -163,12 +163,12 @@ static inline uint64_t CVMX_OSM_ECO_FUNC(void)
 static inline uint64_t CVMX_OSM_INT_INFO_ADDR_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC000018ull);
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000000018ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC000018ull);
+			break;
 	}
 	cvmx_warn("CVMX_OSM_INT_INFO_ADDR not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800DC000018ull);
@@ -178,10 +178,10 @@ static inline uint64_t CVMX_OSM_INT_INFO_ADDR_FUNC(void)
 static inline uint64_t CVMX_OSM_INT_INFO_ADDR_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC000018ull);
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000000018ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC000018ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011800DC000018ull);
 }
@@ -191,12 +191,12 @@ static inline uint64_t CVMX_OSM_INT_INFO_ADDR_FUNC(void)
 static inline uint64_t CVMX_OSM_INT_INFO_ECC_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC000010ull);
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000000010ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC000010ull);
+			break;
 	}
 	cvmx_warn("CVMX_OSM_INT_INFO_ECC not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800DC000010ull);
@@ -206,10 +206,10 @@ static inline uint64_t CVMX_OSM_INT_INFO_ECC_FUNC(void)
 static inline uint64_t CVMX_OSM_INT_INFO_ECC_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC000010ull);
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000000010ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC000010ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011800DC000010ull);
 }
@@ -219,12 +219,12 @@ static inline uint64_t CVMX_OSM_INT_INFO_ECC_FUNC(void)
 static inline uint64_t CVMX_OSM_INT_STAT_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC000008ull);
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000000008ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC000008ull);
+			break;
 	}
 	cvmx_warn("CVMX_OSM_INT_STAT not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011800DC000008ull);
@@ -234,10 +234,10 @@ static inline uint64_t CVMX_OSM_INT_STAT_FUNC(void)
 static inline uint64_t CVMX_OSM_INT_STAT_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC000008ull);
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000000008ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC000008ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011800DC000008ull);
 }
@@ -246,14 +246,14 @@ static inline uint64_t CVMX_OSM_INT_STAT_FUNC(void)
 static inline uint64_t CVMX_OSM_MEMX_BIST_STATUS(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 7))
-				return CVMX_ADD_IO_SEG(0x00011800DC002000ull) + ((offset) & 7) * 8;
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
 				return CVMX_ADD_IO_SEG(0x0001DC0000002000ull) + ((offset) & 1) * 8;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 7))
+				return CVMX_ADD_IO_SEG(0x00011800DC002000ull) + ((offset) & 7) * 8;
+			break;
 	}
 	cvmx_warn("CVMX_OSM_MEMX_BIST_STATUS (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800DC002000ull) + ((offset) & 7) * 8;
@@ -262,10 +262,10 @@ static inline uint64_t CVMX_OSM_MEMX_BIST_STATUS(unsigned long offset)
 static inline uint64_t CVMX_OSM_MEMX_BIST_STATUS(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011800DC002000ull) + (offset) * 8;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001DC0000002000ull) + (offset) * 8;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011800DC002000ull) + (offset) * 8;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800DC002000ull) + (offset) * 8;
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
index 8864370..ceeed51 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
@@ -56,9 +56,9 @@
 static inline uint64_t CVMX_PCIEEPVFX_CFG000(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG000(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000000ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -69,9 +69,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG000(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG001(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG001(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000004ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -82,9 +82,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG001(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG002(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG002(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000008ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -95,9 +95,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG002(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG003(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG003(%lu) is invalid on this chip\n", offset);
 	return 0x000005000000000Cull + ((offset) & 7) * 0x100000000ull;
 }
@@ -108,9 +108,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG003(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG004(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG004(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000010ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -121,9 +121,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG004(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG005(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG005(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000014ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -134,9 +134,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG005(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG006(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG006(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000018ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -147,9 +147,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG006(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG007(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG007(%lu) is invalid on this chip\n", offset);
 	return 0x000005000000001Cull + ((offset) & 7) * 0x100000000ull;
 }
@@ -160,9 +160,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG007(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG008(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG008(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000020ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -173,9 +173,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG008(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG009(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG009(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000024ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -186,9 +186,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG009(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG010(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG010(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000028ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -199,9 +199,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG010(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG011(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG011(%lu) is invalid on this chip\n", offset);
 	return 0x000005000000002Cull + ((offset) & 7) * 0x100000000ull;
 }
@@ -212,9 +212,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG011(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG012(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG012(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000030ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -225,9 +225,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG012(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG013(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG013(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000034ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -238,9 +238,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG013(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG015(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG015(%lu) is invalid on this chip\n", offset);
 	return 0x000005000000003Cull + ((offset) & 7) * 0x100000000ull;
 }
@@ -251,9 +251,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG015(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG028(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG028(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000070ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -264,9 +264,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG028(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG029(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG029(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000074ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -277,9 +277,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG029(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG030(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG030(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000078ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -290,9 +290,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG030(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG031(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG031(%lu) is invalid on this chip\n", offset);
 	return 0x000005000000007Cull + ((offset) & 7) * 0x100000000ull;
 }
@@ -303,9 +303,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG031(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG032(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG032(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000080ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -316,9 +316,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG032(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG037(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG037(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000094ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -329,9 +329,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG037(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG038(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG038(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000098ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -353,9 +353,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG039(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG040(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG040(%lu) is invalid on this chip\n", offset);
 	return 0x00000500000000A0ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -366,9 +366,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG040(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG044(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG044(%lu) is invalid on this chip\n", offset);
 	return 0x00000500000000B0ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -379,9 +379,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG044(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG045(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG045(%lu) is invalid on this chip\n", offset);
 	return 0x00000500000000B4ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -392,9 +392,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG045(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG046(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG046(%lu) is invalid on this chip\n", offset);
 	return 0x00000500000000B8ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -427,9 +427,9 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG049(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG064(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG064(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000100ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -440,8 +440,8 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG064(unsigned long offset)
 static inline uint64_t CVMX_PCIEEPVFX_CFG065(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 5))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 5)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2) || (offset == 4))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2) || (offset == 4)))))
 		cvmx_warn("CVMX_PCIEEPVFX_CFG065(%lu) is invalid on this chip\n", offset);
 	return 0x0000050000000104ull + ((offset) & 7) * 0x100000000ull;
 }
@@ -1508,8 +1508,16 @@ union cvmx_pcieepvfx_cfg037 {
 	uint32_t ltrs                         : 1;  /**< Latency tolerance reporting (LTR) mechanism supported (not supported). */
 	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR passing. (This bit applies to RCs.) */
 	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp supported (not supported). */
-	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported. */
-	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported. */
+	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported.
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request.
+                                                         Since VF's are tied to BAR0, all AtomicOp's will be dropped as unsupported requests.
+                                                         ATOM64S is set as an inherited attribute from the PF. */
+	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported.
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request.
+                                                         Since VF's are tied to BAR0, all AtomicOp's will be dropped as unsupported requests.
+                                                         ATOM64S is set as an inherited attribute from the PF. */
 	uint32_t atom_ops                     : 1;  /**< AtomicOp routing supported (not applicable for EP). */
 	uint32_t ari                          : 1;  /**< Alternate routing ID forwarding supported (not applicable for EP). */
 	uint32_t ctds                         : 1;  /**< Completion timeout disable supported. */
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
index 3439e5c..ad867bf 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
@@ -4984,12 +4984,21 @@ union cvmx_pcieepx_cfg002 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg002_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t bcc                          : 8;  /**< Base class code, writable through PEM()_CFG_WR. However, the application must not
-                                                         change this field. */
-	uint32_t sc                           : 8;  /**< Subclass code, writable through PEM()_CFG_WR. However, the application must not change
-                                                         this field. */
-	uint32_t pi                           : 8;  /**< Programming interface, writable through PEM()_CFG_WR. However, the application must
-                                                         not change this field. */
+	uint32_t bcc                          : 8;  /**< Base class code,
+                                                         _ PF0:          0x0b  (Processers)
+                                                         _ PF1:          0x0b  (Processors)
+                                                         _ PF2:          0x01  (Mass Storage controller)
+                                                         Writable through PEM()_CFG_WR. However, the application must not change this field. */
+	uint32_t sc                           : 8;  /**< Subclass code,
+                                                         _ PF0:          0x30 (MIPS)
+                                                         _ PF1:          0x30 (MIPS)
+                                                         _ PF2:          0x08 (Non-volatile)
+                                                         Writable through PEM()_CFG_WR. However, the application must not change this field. */
+	uint32_t pi                           : 8;  /**< Programming interface.
+                                                         _ PF0:          0x0 (386)
+                                                         _ PF1:          0x0 (386)
+                                                         _ PF2:          0x2 (NVMe)
+                                                         Writable through PEM()_CFG_WR. However, the application must not change this field. */
 	uint32_t rid                          : 8;  /**< Revision ID, writable through PEM()_CFG_WR. However, the application must not change
                                                          this field. Possible values:
                                                          0x0 = Pass 1.0. */
@@ -5138,8 +5147,8 @@ union cvmx_pcieepx_cfg004 {
 	struct cvmx_pcieepx_cfg004_cn52xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg004_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t lbab                         : 8;  /**< Lower bits of the BAR 0 base address. */
-	uint32_t reserved_4_23                : 20;
+	uint32_t lbab                         : 9;  /**< Lower bits of the BAR 0 base address. */
+	uint32_t reserved_4_22                : 19;
 	uint32_t pf                           : 1;  /**< Prefetchable. This field is writable through PEM()_CFG_WR. However, the application
                                                          must not change this field. */
 	uint32_t typ                          : 2;  /**< BAR type.
@@ -5156,8 +5165,8 @@ union cvmx_pcieepx_cfg004 {
 	uint32_t mspc                         : 1;
 	uint32_t typ                          : 2;
 	uint32_t pf                           : 1;
-	uint32_t reserved_4_23                : 20;
-	uint32_t lbab                         : 8;
+	uint32_t reserved_4_22                : 19;
+	uint32_t lbab                         : 9;
 #endif
 	} cn73xx;
 	struct cvmx_pcieepx_cfg004_cn78xx {
@@ -5933,7 +5942,8 @@ union cvmx_pcieepx_cfg016 {
 	uint32_t pme_clock                    : 1;  /**< PME clock, hardwired to 0. */
 	uint32_t pmsv                         : 3;  /**< Power management specification version, writable through
                                                          PEM()_CFG_WR. However, the application must not change this field. */
-	uint32_t ncp                          : 8;  /**< Next capability pointer. Points to the MSI capabilities by default, writable through
+	uint32_t ncp                          : 8;  /**< Next capability pointer. Points to the MSI capabilities (PF0, PF1) or
+                                                         PCIe capabilities list (PF2) by default, writable through
                                                          PEM()_CFG_WR. However, the application must not change this field. */
 	uint32_t pmcid                        : 8;  /**< Power management capability ID. */
 #else
@@ -7137,8 +7147,18 @@ union cvmx_pcieepx_cfg037 {
 	uint32_t ltrs                         : 1;  /**< Latency tolerance reporting (LTR) mechanism supported (not supported). */
 	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR passing. (This bit applies to RCs.) */
 	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp supported (not supported). */
-	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported. */
-	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported. */
+	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported.
+                                                         _ PF0:          0x1
+                                                         _ PF1:          0x1
+                                                         _ PF2:          0x0
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request. */
+	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported.
+                                                         _ PF0:          0x1
+                                                         _ PF1:          0x1
+                                                         _ PF2:          0x0
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request. */
 	uint32_t atom_ops                     : 1;  /**< AtomicOp routing supported (not applicable for EP). */
 	uint32_t ari                          : 1;  /**< Alternate routing ID forwarding supported (not applicable for EP). */
 	uint32_t ctds                         : 1;  /**< Completion timeout disable supported. */
@@ -7235,8 +7255,18 @@ union cvmx_pcieepx_cfg037 {
 	uint32_t ltrs                         : 1;  /**< Latency tolerance reporting (LTR) mechanism supported (not supported). */
 	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR passing. (This bit applies to RCs.) */
 	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp supported (not supported). */
-	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported. */
-	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported. */
+	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported.
+                                                         _ PF0:          0x1
+                                                         _ PF1:          0x1
+                                                         _ PF2:          0x0
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request. */
+	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported.
+                                                         _ PF0:          0x1
+                                                         _ PF1:          0x1
+                                                         _ PF2:          0x0
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request. */
 	uint32_t atom_ops                     : 1;  /**< AtomicOp routing supported (not applicable for EP). */
 	uint32_t ari                          : 1;  /**< Alternate routing ID forwarding supported (not applicable for EP). */
 	uint32_t ctds                         : 1;  /**< Completion timeout disable supported. */
diff --git a/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h b/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
index cfb95e8..da81ac9 100644
--- a/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
@@ -57,8 +57,8 @@ static inline uint64_t CVMX_PCIERCX_CFG000(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000000ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -85,8 +85,8 @@ static inline uint64_t CVMX_PCIERCX_CFG000(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000000ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000000ull + (offset) * 0x100000000ull;
@@ -107,8 +107,8 @@ static inline uint64_t CVMX_PCIERCX_CFG001(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000004ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -135,8 +135,8 @@ static inline uint64_t CVMX_PCIERCX_CFG001(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000004ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000004ull + (offset) * 0x100000000ull;
@@ -157,8 +157,8 @@ static inline uint64_t CVMX_PCIERCX_CFG002(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000008ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -185,8 +185,8 @@ static inline uint64_t CVMX_PCIERCX_CFG002(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000008ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000008ull + (offset) * 0x100000000ull;
@@ -207,8 +207,8 @@ static inline uint64_t CVMX_PCIERCX_CFG003(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000000Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -235,8 +235,8 @@ static inline uint64_t CVMX_PCIERCX_CFG003(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000000Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000000Cull + (offset) * 0x100000000ull;
@@ -257,8 +257,8 @@ static inline uint64_t CVMX_PCIERCX_CFG004(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000010ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -285,8 +285,8 @@ static inline uint64_t CVMX_PCIERCX_CFG004(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000010ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000010ull + (offset) * 0x100000000ull;
@@ -307,8 +307,8 @@ static inline uint64_t CVMX_PCIERCX_CFG005(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000014ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -335,8 +335,8 @@ static inline uint64_t CVMX_PCIERCX_CFG005(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000014ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000014ull + (offset) * 0x100000000ull;
@@ -357,8 +357,8 @@ static inline uint64_t CVMX_PCIERCX_CFG006(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000018ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -385,8 +385,8 @@ static inline uint64_t CVMX_PCIERCX_CFG006(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000018ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000018ull + (offset) * 0x100000000ull;
@@ -407,8 +407,8 @@ static inline uint64_t CVMX_PCIERCX_CFG007(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000001Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -435,8 +435,8 @@ static inline uint64_t CVMX_PCIERCX_CFG007(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000001Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000001Cull + (offset) * 0x100000000ull;
@@ -457,8 +457,8 @@ static inline uint64_t CVMX_PCIERCX_CFG008(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000020ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -485,8 +485,8 @@ static inline uint64_t CVMX_PCIERCX_CFG008(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000020ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000020ull + (offset) * 0x100000000ull;
@@ -507,8 +507,8 @@ static inline uint64_t CVMX_PCIERCX_CFG009(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000024ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -535,8 +535,8 @@ static inline uint64_t CVMX_PCIERCX_CFG009(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000024ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000024ull + (offset) * 0x100000000ull;
@@ -557,8 +557,8 @@ static inline uint64_t CVMX_PCIERCX_CFG010(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000028ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -585,8 +585,8 @@ static inline uint64_t CVMX_PCIERCX_CFG010(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000028ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000028ull + (offset) * 0x100000000ull;
@@ -607,8 +607,8 @@ static inline uint64_t CVMX_PCIERCX_CFG011(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000002Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -635,8 +635,8 @@ static inline uint64_t CVMX_PCIERCX_CFG011(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000002Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000002Cull + (offset) * 0x100000000ull;
@@ -657,8 +657,8 @@ static inline uint64_t CVMX_PCIERCX_CFG012(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000030ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -685,8 +685,8 @@ static inline uint64_t CVMX_PCIERCX_CFG012(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000030ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000030ull + (offset) * 0x100000000ull;
@@ -707,8 +707,8 @@ static inline uint64_t CVMX_PCIERCX_CFG013(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000034ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -735,8 +735,8 @@ static inline uint64_t CVMX_PCIERCX_CFG013(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000034ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000034ull + (offset) * 0x100000000ull;
@@ -757,8 +757,8 @@ static inline uint64_t CVMX_PCIERCX_CFG014(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000038ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -785,8 +785,8 @@ static inline uint64_t CVMX_PCIERCX_CFG014(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000038ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000038ull + (offset) * 0x100000000ull;
@@ -807,8 +807,8 @@ static inline uint64_t CVMX_PCIERCX_CFG015(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000003Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -835,8 +835,8 @@ static inline uint64_t CVMX_PCIERCX_CFG015(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000003Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000003Cull + (offset) * 0x100000000ull;
@@ -857,8 +857,8 @@ static inline uint64_t CVMX_PCIERCX_CFG016(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000040ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -885,8 +885,8 @@ static inline uint64_t CVMX_PCIERCX_CFG016(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000040ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000040ull + (offset) * 0x100000000ull;
@@ -907,8 +907,8 @@ static inline uint64_t CVMX_PCIERCX_CFG017(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000044ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -935,8 +935,8 @@ static inline uint64_t CVMX_PCIERCX_CFG017(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000044ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000044ull + (offset) * 0x100000000ull;
@@ -957,8 +957,8 @@ static inline uint64_t CVMX_PCIERCX_CFG020(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000050ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -985,8 +985,8 @@ static inline uint64_t CVMX_PCIERCX_CFG020(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000050ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000050ull + (offset) * 0x100000000ull;
@@ -1007,8 +1007,8 @@ static inline uint64_t CVMX_PCIERCX_CFG021(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000054ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1035,8 +1035,8 @@ static inline uint64_t CVMX_PCIERCX_CFG021(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000054ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000054ull + (offset) * 0x100000000ull;
@@ -1057,8 +1057,8 @@ static inline uint64_t CVMX_PCIERCX_CFG022(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000058ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1085,8 +1085,8 @@ static inline uint64_t CVMX_PCIERCX_CFG022(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000058ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000058ull + (offset) * 0x100000000ull;
@@ -1107,8 +1107,8 @@ static inline uint64_t CVMX_PCIERCX_CFG023(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000005Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1135,8 +1135,8 @@ static inline uint64_t CVMX_PCIERCX_CFG023(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000005Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000005Cull + (offset) * 0x100000000ull;
@@ -1157,8 +1157,8 @@ static inline uint64_t CVMX_PCIERCX_CFG028(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000070ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1185,8 +1185,8 @@ static inline uint64_t CVMX_PCIERCX_CFG028(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000070ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000070ull + (offset) * 0x100000000ull;
@@ -1207,8 +1207,8 @@ static inline uint64_t CVMX_PCIERCX_CFG029(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000074ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1235,8 +1235,8 @@ static inline uint64_t CVMX_PCIERCX_CFG029(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000074ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000074ull + (offset) * 0x100000000ull;
@@ -1257,8 +1257,8 @@ static inline uint64_t CVMX_PCIERCX_CFG030(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000078ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1285,8 +1285,8 @@ static inline uint64_t CVMX_PCIERCX_CFG030(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000078ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000078ull + (offset) * 0x100000000ull;
@@ -1307,8 +1307,8 @@ static inline uint64_t CVMX_PCIERCX_CFG031(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000007Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1335,8 +1335,8 @@ static inline uint64_t CVMX_PCIERCX_CFG031(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000007Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000007Cull + (offset) * 0x100000000ull;
@@ -1357,8 +1357,8 @@ static inline uint64_t CVMX_PCIERCX_CFG032(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000080ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1385,8 +1385,8 @@ static inline uint64_t CVMX_PCIERCX_CFG032(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000080ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000080ull + (offset) * 0x100000000ull;
@@ -1407,8 +1407,8 @@ static inline uint64_t CVMX_PCIERCX_CFG033(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000084ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1435,8 +1435,8 @@ static inline uint64_t CVMX_PCIERCX_CFG033(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000084ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000084ull + (offset) * 0x100000000ull;
@@ -1457,8 +1457,8 @@ static inline uint64_t CVMX_PCIERCX_CFG034(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000088ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1485,8 +1485,8 @@ static inline uint64_t CVMX_PCIERCX_CFG034(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000088ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000088ull + (offset) * 0x100000000ull;
@@ -1507,8 +1507,8 @@ static inline uint64_t CVMX_PCIERCX_CFG035(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000008Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1535,8 +1535,8 @@ static inline uint64_t CVMX_PCIERCX_CFG035(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000008Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000008Cull + (offset) * 0x100000000ull;
@@ -1557,8 +1557,8 @@ static inline uint64_t CVMX_PCIERCX_CFG036(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000090ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1585,8 +1585,8 @@ static inline uint64_t CVMX_PCIERCX_CFG036(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000090ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000090ull + (offset) * 0x100000000ull;
@@ -1607,8 +1607,8 @@ static inline uint64_t CVMX_PCIERCX_CFG037(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000094ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1635,8 +1635,8 @@ static inline uint64_t CVMX_PCIERCX_CFG037(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000094ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000094ull + (offset) * 0x100000000ull;
@@ -1657,8 +1657,8 @@ static inline uint64_t CVMX_PCIERCX_CFG038(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000098ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1685,8 +1685,8 @@ static inline uint64_t CVMX_PCIERCX_CFG038(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000098ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000098ull + (offset) * 0x100000000ull;
@@ -1707,8 +1707,8 @@ static inline uint64_t CVMX_PCIERCX_CFG039(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000009Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1735,8 +1735,8 @@ static inline uint64_t CVMX_PCIERCX_CFG039(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000009Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000009Cull + (offset) * 0x100000000ull;
@@ -1757,8 +1757,8 @@ static inline uint64_t CVMX_PCIERCX_CFG040(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x00000200000000A0ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1785,8 +1785,8 @@ static inline uint64_t CVMX_PCIERCX_CFG040(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x00000200000000A0ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x00000200000000A0ull + (offset) * 0x100000000ull;
@@ -1807,8 +1807,8 @@ static inline uint64_t CVMX_PCIERCX_CFG041(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x00000200000000A4ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1835,8 +1835,8 @@ static inline uint64_t CVMX_PCIERCX_CFG041(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x00000200000000A4ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x00000200000000A4ull + (offset) * 0x100000000ull;
@@ -1857,8 +1857,8 @@ static inline uint64_t CVMX_PCIERCX_CFG042(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x00000200000000A8ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1885,8 +1885,8 @@ static inline uint64_t CVMX_PCIERCX_CFG042(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x00000200000000A8ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x00000200000000A8ull + (offset) * 0x100000000ull;
@@ -1946,8 +1946,8 @@ static inline uint64_t CVMX_PCIERCX_CFG064(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000100ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -1974,8 +1974,8 @@ static inline uint64_t CVMX_PCIERCX_CFG064(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000100ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000100ull + (offset) * 0x100000000ull;
@@ -1996,8 +1996,8 @@ static inline uint64_t CVMX_PCIERCX_CFG065(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000104ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2024,8 +2024,8 @@ static inline uint64_t CVMX_PCIERCX_CFG065(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000104ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000104ull + (offset) * 0x100000000ull;
@@ -2046,8 +2046,8 @@ static inline uint64_t CVMX_PCIERCX_CFG066(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000108ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2074,8 +2074,8 @@ static inline uint64_t CVMX_PCIERCX_CFG066(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000108ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000108ull + (offset) * 0x100000000ull;
@@ -2096,8 +2096,8 @@ static inline uint64_t CVMX_PCIERCX_CFG067(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000010Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2124,8 +2124,8 @@ static inline uint64_t CVMX_PCIERCX_CFG067(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000010Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000010Cull + (offset) * 0x100000000ull;
@@ -2146,8 +2146,8 @@ static inline uint64_t CVMX_PCIERCX_CFG068(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000110ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2174,8 +2174,8 @@ static inline uint64_t CVMX_PCIERCX_CFG068(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000110ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000110ull + (offset) * 0x100000000ull;
@@ -2196,8 +2196,8 @@ static inline uint64_t CVMX_PCIERCX_CFG069(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000114ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2224,8 +2224,8 @@ static inline uint64_t CVMX_PCIERCX_CFG069(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000114ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000114ull + (offset) * 0x100000000ull;
@@ -2246,8 +2246,8 @@ static inline uint64_t CVMX_PCIERCX_CFG070(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000118ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2274,8 +2274,8 @@ static inline uint64_t CVMX_PCIERCX_CFG070(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000118ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000118ull + (offset) * 0x100000000ull;
@@ -2296,8 +2296,8 @@ static inline uint64_t CVMX_PCIERCX_CFG071(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000011Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2324,8 +2324,8 @@ static inline uint64_t CVMX_PCIERCX_CFG071(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000011Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000011Cull + (offset) * 0x100000000ull;
@@ -2346,8 +2346,8 @@ static inline uint64_t CVMX_PCIERCX_CFG072(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000120ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2374,8 +2374,8 @@ static inline uint64_t CVMX_PCIERCX_CFG072(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000120ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000120ull + (offset) * 0x100000000ull;
@@ -2396,8 +2396,8 @@ static inline uint64_t CVMX_PCIERCX_CFG073(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000124ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2424,8 +2424,8 @@ static inline uint64_t CVMX_PCIERCX_CFG073(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000124ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000124ull + (offset) * 0x100000000ull;
@@ -2446,8 +2446,8 @@ static inline uint64_t CVMX_PCIERCX_CFG074(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000128ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2474,8 +2474,8 @@ static inline uint64_t CVMX_PCIERCX_CFG074(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000128ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000128ull + (offset) * 0x100000000ull;
@@ -2496,8 +2496,8 @@ static inline uint64_t CVMX_PCIERCX_CFG075(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000012Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2524,8 +2524,8 @@ static inline uint64_t CVMX_PCIERCX_CFG075(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000012Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000012Cull + (offset) * 0x100000000ull;
@@ -2546,8 +2546,8 @@ static inline uint64_t CVMX_PCIERCX_CFG076(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000130ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2574,8 +2574,8 @@ static inline uint64_t CVMX_PCIERCX_CFG076(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000130ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000130ull + (offset) * 0x100000000ull;
@@ -2596,8 +2596,8 @@ static inline uint64_t CVMX_PCIERCX_CFG077(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000134ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2624,8 +2624,8 @@ static inline uint64_t CVMX_PCIERCX_CFG077(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000134ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000134ull + (offset) * 0x100000000ull;
@@ -2737,8 +2737,8 @@ static inline uint64_t CVMX_PCIERCX_CFG448(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000700ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2765,8 +2765,8 @@ static inline uint64_t CVMX_PCIERCX_CFG448(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000700ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000700ull + (offset) * 0x100000000ull;
@@ -2787,8 +2787,8 @@ static inline uint64_t CVMX_PCIERCX_CFG449(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000704ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2815,8 +2815,8 @@ static inline uint64_t CVMX_PCIERCX_CFG449(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000704ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000704ull + (offset) * 0x100000000ull;
@@ -2837,8 +2837,8 @@ static inline uint64_t CVMX_PCIERCX_CFG450(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000708ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2865,8 +2865,8 @@ static inline uint64_t CVMX_PCIERCX_CFG450(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000708ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000708ull + (offset) * 0x100000000ull;
@@ -2887,8 +2887,8 @@ static inline uint64_t CVMX_PCIERCX_CFG451(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000070Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2915,8 +2915,8 @@ static inline uint64_t CVMX_PCIERCX_CFG451(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000070Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000070Cull + (offset) * 0x100000000ull;
@@ -2937,8 +2937,8 @@ static inline uint64_t CVMX_PCIERCX_CFG452(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000710ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -2965,8 +2965,8 @@ static inline uint64_t CVMX_PCIERCX_CFG452(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000710ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000710ull + (offset) * 0x100000000ull;
@@ -2987,8 +2987,8 @@ static inline uint64_t CVMX_PCIERCX_CFG453(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000714ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3015,8 +3015,8 @@ static inline uint64_t CVMX_PCIERCX_CFG453(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000714ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000714ull + (offset) * 0x100000000ull;
@@ -3037,8 +3037,8 @@ static inline uint64_t CVMX_PCIERCX_CFG454(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000718ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3065,8 +3065,8 @@ static inline uint64_t CVMX_PCIERCX_CFG454(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000718ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000718ull + (offset) * 0x100000000ull;
@@ -3087,8 +3087,8 @@ static inline uint64_t CVMX_PCIERCX_CFG455(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000071Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3115,8 +3115,8 @@ static inline uint64_t CVMX_PCIERCX_CFG455(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000071Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000071Cull + (offset) * 0x100000000ull;
@@ -3137,8 +3137,8 @@ static inline uint64_t CVMX_PCIERCX_CFG456(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000720ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3165,8 +3165,8 @@ static inline uint64_t CVMX_PCIERCX_CFG456(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000720ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000720ull + (offset) * 0x100000000ull;
@@ -3187,8 +3187,8 @@ static inline uint64_t CVMX_PCIERCX_CFG458(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000728ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3215,8 +3215,8 @@ static inline uint64_t CVMX_PCIERCX_CFG458(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000728ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000728ull + (offset) * 0x100000000ull;
@@ -3237,8 +3237,8 @@ static inline uint64_t CVMX_PCIERCX_CFG459(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000072Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3265,8 +3265,8 @@ static inline uint64_t CVMX_PCIERCX_CFG459(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000072Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000072Cull + (offset) * 0x100000000ull;
@@ -3287,8 +3287,8 @@ static inline uint64_t CVMX_PCIERCX_CFG460(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000730ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3315,8 +3315,8 @@ static inline uint64_t CVMX_PCIERCX_CFG460(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000730ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000730ull + (offset) * 0x100000000ull;
@@ -3337,8 +3337,8 @@ static inline uint64_t CVMX_PCIERCX_CFG461(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000734ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3365,8 +3365,8 @@ static inline uint64_t CVMX_PCIERCX_CFG461(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000734ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000734ull + (offset) * 0x100000000ull;
@@ -3387,8 +3387,8 @@ static inline uint64_t CVMX_PCIERCX_CFG462(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000738ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3415,8 +3415,8 @@ static inline uint64_t CVMX_PCIERCX_CFG462(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000738ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000738ull + (offset) * 0x100000000ull;
@@ -3437,8 +3437,8 @@ static inline uint64_t CVMX_PCIERCX_CFG463(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000073Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3465,8 +3465,8 @@ static inline uint64_t CVMX_PCIERCX_CFG463(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000073Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000073Cull + (offset) * 0x100000000ull;
@@ -3487,8 +3487,8 @@ static inline uint64_t CVMX_PCIERCX_CFG464(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000740ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3515,8 +3515,8 @@ static inline uint64_t CVMX_PCIERCX_CFG464(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000740ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000740ull + (offset) * 0x100000000ull;
@@ -3537,8 +3537,8 @@ static inline uint64_t CVMX_PCIERCX_CFG465(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000744ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3565,8 +3565,8 @@ static inline uint64_t CVMX_PCIERCX_CFG465(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000744ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000744ull + (offset) * 0x100000000ull;
@@ -3587,8 +3587,8 @@ static inline uint64_t CVMX_PCIERCX_CFG466(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000748ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3615,8 +3615,8 @@ static inline uint64_t CVMX_PCIERCX_CFG466(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000748ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000748ull + (offset) * 0x100000000ull;
@@ -3637,8 +3637,8 @@ static inline uint64_t CVMX_PCIERCX_CFG467(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000074Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3665,8 +3665,8 @@ static inline uint64_t CVMX_PCIERCX_CFG467(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000074Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000074Cull + (offset) * 0x100000000ull;
@@ -3687,8 +3687,8 @@ static inline uint64_t CVMX_PCIERCX_CFG468(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000750ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3715,8 +3715,8 @@ static inline uint64_t CVMX_PCIERCX_CFG468(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000750ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000750ull + (offset) * 0x100000000ull;
@@ -3861,8 +3861,8 @@ static inline uint64_t CVMX_PCIERCX_CFG515(unsigned long offset)
 				return 0x000002000000080Cull + ((offset) & 3) * 0x100000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x000002000000080Cull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3885,8 +3885,8 @@ static inline uint64_t CVMX_PCIERCX_CFG515(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000080Cull + (offset) * 0x100000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x000002000000080Cull + (offset) * 0x100000000ull;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
@@ -3903,8 +3903,8 @@ static inline uint64_t CVMX_PCIERCX_CFG516(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000810ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3931,8 +3931,8 @@ static inline uint64_t CVMX_PCIERCX_CFG516(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000810ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000810ull + (offset) * 0x100000000ull;
@@ -3953,8 +3953,8 @@ static inline uint64_t CVMX_PCIERCX_CFG517(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return 0x0000020000000814ull + ((offset) & 3) * 0x100000000ull;
 			break;
@@ -3981,8 +3981,8 @@ static inline uint64_t CVMX_PCIERCX_CFG517(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000814ull + (offset) * 0x100000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return 0x0000020000000814ull + (offset) * 0x100000000ull;
@@ -5914,8 +5914,12 @@ union cvmx_pciercx_cfg037 {
 	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR passing. When set, the routing element never carries out the passing
                                                          permitted in the relaxed ordering model. */
 	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp supported (not supported). */
-	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported. */
-	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported. */
+	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported.
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request. */
+	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported.
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request. */
 	uint32_t atom_ops                     : 1;  /**< AtomicOp routing supported. */
 	uint32_t reserved_5_5                 : 1;
 	uint32_t ctds                         : 1;  /**< Completion timeout disable supported. */
@@ -6048,8 +6052,12 @@ union cvmx_pciercx_cfg037 {
 	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR passing. When set, the routing element never carries out the passing
                                                          permitted in the relaxed ordering model. */
 	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp supported (not supported). */
-	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported. */
-	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported. */
+	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported.
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request. */
+	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported.
+                                                         Note that inbound AtomicOps targeting BAR0 are not supported and are dropped as an
+                                                         unsupported request. */
 	uint32_t atom_ops                     : 1;  /**< AtomicOp routing supported. */
 	uint32_t ari_fw                       : 1;  /**< Alternate routing ID forwarding supported. */
 	uint32_t ctds                         : 1;  /**< Completion timeout disable supported. */
diff --git a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
index 25dadaa..e4da864 100644
--- a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
@@ -61,8 +61,8 @@ static inline uint64_t CVMX_PEMX_BAR1_INDEXX(unsigned long offset, unsigned long
 				return CVMX_ADD_IO_SEG(0x00011800C0000100ull) + (((offset) & 15) + ((block_id) & 3) * 0x200000ull) * 8;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if (((offset <= 15)) && ((block_id <= 3)))
 				return CVMX_ADD_IO_SEG(0x00011800C0000100ull) + (((offset) & 15) + ((block_id) & 3) * 0x200000ull) * 8;
 			break;
@@ -85,8 +85,8 @@ static inline uint64_t CVMX_PEMX_BAR1_INDEXX(unsigned long offset, unsigned long
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000100ull) + ((offset) + (block_id) * 0x200000ull) * 8;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000100ull) + ((offset) + (block_id) * 0x200000ull) * 8;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
@@ -107,8 +107,8 @@ static inline uint64_t CVMX_PEMX_BAR2_MASK(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x00011800C00000B0ull) + ((offset) & 3) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return CVMX_ADD_IO_SEG(0x00011800C00000B0ull) + ((offset) & 3) * 0x1000000ull;
 			break;
@@ -130,8 +130,8 @@ static inline uint64_t CVMX_PEMX_BAR2_MASK(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000B0ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000B0ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
@@ -151,8 +151,8 @@ static inline uint64_t CVMX_PEMX_BAR_CTL(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x00011800C00000A8ull) + ((offset) & 3) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return CVMX_ADD_IO_SEG(0x00011800C00000A8ull) + ((offset) & 3) * 0x1000000ull;
 			break;
@@ -175,8 +175,8 @@ static inline uint64_t CVMX_PEMX_BAR_CTL(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000A8ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000A8ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
@@ -205,8 +205,8 @@ static inline uint64_t CVMX_PEMX_BIST_STATUS(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + ((offset) & 3) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + ((offset) & 3) * 0x1000000ull;
 			break;
@@ -227,8 +227,8 @@ static inline uint64_t CVMX_PEMX_BIST_STATUS(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000018ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + (offset) * 0x1000000ull;
 	}
 	return CVMX_ADD_IO_SEG(0x00011800C0000440ull) + (offset) * 0x1000000ull;
@@ -396,8 +396,8 @@ static inline uint64_t CVMX_PEMX_DBG_INFO(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + ((offset) & 3) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + ((offset) & 3) * 0x1000000ull;
 			break;
@@ -420,8 +420,8 @@ static inline uint64_t CVMX_PEMX_DBG_INFO(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
@@ -473,8 +473,8 @@ static inline uint64_t CVMX_PEMX_ECC_ENA(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return CVMX_ADD_IO_SEG(0x00011800C0000448ull) + ((offset) & 3) * 0x1000000ull;
 			break;
@@ -491,8 +491,8 @@ static inline uint64_t CVMX_PEMX_ECC_ENA(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000448ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000C0ull) + (offset) * 0x1000000ull;
@@ -505,8 +505,8 @@ static inline uint64_t CVMX_PEMX_ECC_SYND_CTRL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return CVMX_ADD_IO_SEG(0x00011800C0000450ull) + ((offset) & 3) * 0x1000000ull;
 			break;
@@ -523,8 +523,8 @@ static inline uint64_t CVMX_PEMX_ECC_SYND_CTRL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000450ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000C8ull) + (offset) * 0x1000000ull;
@@ -601,8 +601,8 @@ static inline uint64_t CVMX_PEMX_INB_READ_CREDITS(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x00011800C00000B8ull) + ((offset) & 3) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return CVMX_ADD_IO_SEG(0x00011800C00000B8ull) + ((offset) & 3) * 0x1000000ull;
 			break;
@@ -624,8 +624,8 @@ static inline uint64_t CVMX_PEMX_INB_READ_CREDITS(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000B8ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C00000B8ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
@@ -717,8 +717,8 @@ static inline uint64_t CVMX_PEMX_INT_SUM(unsigned long offset)
 				return CVMX_ADD_IO_SEG(0x00011800C0000428ull) + ((offset) & 3) * 0x1000000ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
 				return CVMX_ADD_IO_SEG(0x00011800C0000428ull) + ((offset) & 3) * 0x1000000ull;
 			break;
@@ -741,8 +741,8 @@ static inline uint64_t CVMX_PEMX_INT_SUM(unsigned long offset)
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000428ull) + (offset) * 0x1000000ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011800C0000428ull) + (offset) * 0x1000000ull;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
@@ -945,7 +945,8 @@ union cvmx_pemx_bar1_indexx {
 	uint64_t reserved_24_63               : 40;
 	uint64_t addr_idx                     : 20; /**< Address index. Address bits [41:22] sent to L2C. */
 	uint64_t ca                           : 1;  /**< Cached. Set to 1 when access is not to be cached in L2. */
-	uint64_t end_swp                      : 2;  /**< Endian-swap mode. */
+	uint64_t end_swp                      : 2;  /**< Endian-swap mode.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t addr_v                       : 1;  /**< Address valid. Set to 1 when the selected address range is valid. */
 #else
 	uint64_t addr_v                       : 1;
@@ -1050,7 +1051,8 @@ union cvmx_pemx_bar_ctl {
                                                          0x6 = 2048 MB.
                                                          0x7 = Reserved. */
 	uint64_t bar2_enb                     : 1;  /**< When set to 1, BAR2 is enabled and will respond; when clear, BAR2 access will cause UR responses. */
-	uint64_t bar2_esx                     : 2;  /**< Value is XORed with PCIe address [43:42] to determine the endian swap mode. */
+	uint64_t bar2_esx                     : 2;  /**< Value is XORed with PCIe address [43:42] to determine the endian swap mode.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t bar2_cax                     : 1;  /**< Value is XORed with PCIe address [44] to determine the L2 cache attribute. Not cached in
                                                          L2 if XOR result is 1. */
 #else
@@ -1383,7 +1385,9 @@ union cvmx_pemx_cfg {
                                                          cold reset by the pin straps. (See PEM()_STRAP[PIMODE]. The HOSTMD reset value is the
                                                          bit-wise AND of the PIMODE straps.  As such, PEMs 0 and 2 are configurable and PEMs 1
                                                          and 3 default to 0x1.)  When set, the PEM is configured to be a root complex. When clear,
-                                                         the PEM is configured to be an end point. */
+                                                         the PEM is configured to be an end point.
+                                                         Because SPEM0 and PEM2 share an EEPROM, the PEM2_CFG[HOSTMD] should only be changed by
+                                                         software when SPEM0 is in reset. */
 	uint64_t md                           : 2;  /**< This field enables overwriting the value for speed. The reset value is captured on cold
                                                          reset by the pin straps (see PEM()_STRAP[PIMODE]). For a root complex configuration
                                                          that is not running at Gen3 speed, the HOSTMD bit of this register must be set when this
@@ -1689,8 +1693,11 @@ union cvmx_pemx_ctl_status {
                                                          block to force a parity error when it is later read. */
 	uint64_t reserved_48_49               : 2;
 	uint64_t auto_sd                      : 1;  /**< Link hardware autonomous speed disable. */
-	uint64_t dnum                         : 5;  /**< Primary bus device number. */
-	uint64_t pbus                         : 8;  /**< Primary bus number. */
+	uint64_t dnum                         : 5;  /**< Primary bus device number. In EP mode, the device number latched
+                                                         on a type 0 configuration write to PF0. */
+	uint64_t pbus                         : 8;  /**< Primary bus number. In RC mode, a RO copy of the corresponding
+                                                         PCIERC(0..3)_CFG006[PBNUM]. In EP mode, the bus number latched
+                                                         on a type 0 configuration write to PF0. */
 	uint64_t reserved_32_33               : 2;
 	uint64_t cfg_rtry                     : 16; /**< The time * 0x10000 in coprocessor clocks to wait for a CPL to a configuration read that
                                                          does not carry a retry status. Until such time that the timeout occurs and retry status is
@@ -2159,79 +2166,168 @@ union cvmx_pemx_dbg_info {
 	struct cvmx_pemx_dbg_info_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_62_63               : 2;
-	uint64_t m2s_c_dbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO control0/1 double bit error. */
-	uint64_t m2s_c_sbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO control0/1 single bit error. */
-	uint64_t m2s_d_dbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO data0/1 double bit error. */
-	uint64_t m2s_d_sbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO data0/1 single bit error. */
-	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a core header queue bank1 double bit error. */
-	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a core header queue bank1 single bit error. */
-	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a core header queue bank0 double bit error. */
-	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a core header queue bank0 single bit error. */
-	uint64_t rtry_dbe                     : 1;  /**< Detected a core retry RAM double bit error. */
-	uint64_t rtry_sbe                     : 1;  /**< Detected a core retry RAM single bit error. */
-	uint64_t c_c_dbe                      : 1;  /**< Detected a SLI TLP CPL FIFO control double bit error. */
-	uint64_t c_c_sbe                      : 1;  /**< Detected a SLI TLP CPL FIFO control single bit error. */
-	uint64_t c_d1_dbe                     : 1;  /**< Detected a SLI TLP CPL FIFO data1 double bit error. */
-	uint64_t c_d1_sbe                     : 1;  /**< Detected a SLI TLP CPL FIFO data1 single bit error. */
-	uint64_t c_d0_dbe                     : 1;  /**< Detected a SLI TLP CPL FIFO data0 double bit error. */
-	uint64_t c_d0_sbe                     : 1;  /**< Detected a SLI TLP CPL FIFO data0 single bit error. */
-	uint64_t n_c_dbe                      : 1;  /**< Detected a SLI TLP NP FIFO control double bit error. */
-	uint64_t n_c_sbe                      : 1;  /**< Detected a SLI TLP NP FIFO control single bit error. */
-	uint64_t n_d1_dbe                     : 1;  /**< Detected a SLI TLP NP FIFO data1 double bit error. */
-	uint64_t n_d1_sbe                     : 1;  /**< Detected a SLI TLP NP FIFO data1 single bit error. */
-	uint64_t n_d0_dbe                     : 1;  /**< Detected a SLI TLP NP FIFO data0 double bit error. */
-	uint64_t n_d0_sbe                     : 1;  /**< Detected a SLI TLP NP FIFO data0 single bit error. */
-	uint64_t p_c_dbe                      : 1;  /**< Detected a SLI TLP posted FIFO control double bit error. */
-	uint64_t p_c_sbe                      : 1;  /**< Detected a SLI TLP posted FIFO control single bit error. */
-	uint64_t p_d1_dbe                     : 1;  /**< Detected a SLI TLP posted FIFO data1 double bit error. */
-	uint64_t p_d1_sbe                     : 1;  /**< Detected a SLI TLP posted FIFO data1 single bit error. */
-	uint64_t p_d0_dbe                     : 1;  /**< Detected a SLI TLP posted FIFO data0 double bit error. */
-	uint64_t p_d0_sbe                     : 1;  /**< Detected a SLI TLP posted FIFO data0 single bit error. */
-	uint64_t datq_pe                      : 1;  /**< Detected a data queue RAM parity error. */
+	uint64_t m2s_c_dbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO control0/1 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_M2S_C_DBE. */
+	uint64_t m2s_c_sbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO control0/1 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_M2S_C_SBE. */
+	uint64_t m2s_d_dbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO data0/1 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_M2S_D_DBE. */
+	uint64_t m2s_d_sbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO data0/1 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_M2S_D_SBE. */
+	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a core header queue bank1 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_QHDR_B1_DBE. */
+	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a core header queue bank1 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_QHDR_B1_SBE. */
+	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a core header queue bank0 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_QHDR_B0_DBE. */
+	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a core header queue bank0 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_QHDR_B0_SBE. */
+	uint64_t rtry_dbe                     : 1;  /**< Detected a core retry RAM double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RTRY_DBE. */
+	uint64_t rtry_sbe                     : 1;  /**< Detected a core retry RAM single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RTRY_SBE. */
+	uint64_t c_c_dbe                      : 1;  /**< Detected a SLI TLP CPL FIFO control double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_C_C_DBE. */
+	uint64_t c_c_sbe                      : 1;  /**< Detected a SLI TLP CPL FIFO control single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_C_C_SBE. */
+	uint64_t c_d1_dbe                     : 1;  /**< Detected a SLI TLP CPL FIFO data1 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_C_D1_DBE. */
+	uint64_t c_d1_sbe                     : 1;  /**< Detected a SLI TLP CPL FIFO data1 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_C_D1_SBE. */
+	uint64_t c_d0_dbe                     : 1;  /**< Detected a SLI TLP CPL FIFO data0 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_C_D0_DBE. */
+	uint64_t c_d0_sbe                     : 1;  /**< Detected a SLI TLP CPL FIFO data0 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_C_D0_SBE. */
+	uint64_t n_c_dbe                      : 1;  /**< Detected a SLI TLP NP FIFO control double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_N_C_DBE. */
+	uint64_t n_c_sbe                      : 1;  /**< Detected a SLI TLP NP FIFO control single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_N_C_SBE. */
+	uint64_t n_d1_dbe                     : 1;  /**< Detected a SLI TLP NP FIFO data1 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_N_D1_DBE. */
+	uint64_t n_d1_sbe                     : 1;  /**< Detected a SLI TLP NP FIFO data1 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_N_D1_SBE. */
+	uint64_t n_d0_dbe                     : 1;  /**< Detected a SLI TLP NP FIFO data0 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_N_D0_DBE. */
+	uint64_t n_d0_sbe                     : 1;  /**< Detected a SLI TLP NP FIFO data0 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_N_D0_SBE. */
+	uint64_t p_c_dbe                      : 1;  /**< Detected a SLI TLP posted FIFO control double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_P_C_DBE. */
+	uint64_t p_c_sbe                      : 1;  /**< Detected a SLI TLP posted FIFO control single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_P_C_SBE. */
+	uint64_t p_d1_dbe                     : 1;  /**< Detected a SLI TLP posted FIFO data1 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_P_D1_DBE. */
+	uint64_t p_d1_sbe                     : 1;  /**< Detected a SLI TLP posted FIFO data1 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_P_D1_SBE. */
+	uint64_t p_d0_dbe                     : 1;  /**< Detected a SLI TLP posted FIFO data0 double bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_P_D0_DBE. */
+	uint64_t p_d0_sbe                     : 1;  /**< Detected a SLI TLP posted FIFO data0 single bit error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_P_D0_SBE. */
+	uint64_t datq_pe                      : 1;  /**< Detected a data queue RAM parity error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_DATQ_PE. */
 	uint64_t bmd_e                        : 1;  /**< A NP or P TLP was seen in the outbound path, but it was not allowed to master the bus.
                                                          If a PF TLP and the PCIEEP()_CFG001[ME] is not set.
-                                                         For VF TLP, either the the PCIEEP()_CFG001[ME]/PCIEEPVF()_CFG001[ME] are not set. */
-	uint64_t lofp                         : 1;  /**< Lack of forward progress at TLP FIFOs timeout occurred. */
-	uint64_t ecrc_e                       : 1;  /**< Received an ECRC error. */
-	uint64_t rawwpp                       : 1;  /**< Received a write with poisoned payload. INTERNAL: radm_rcvd_wreq_poisoned. */
-	uint64_t racpp                        : 1;  /**< Received a completion with poisoned payload. INTERNAL: radm_rcvd_cpl_poisoned. */
-	uint64_t ramtlp                       : 1;  /**< Received a malformed TLP. INTERNAL: radm_mlf_tlp_err. */
-	uint64_t rarwdns                      : 1;  /**< Received a request which device does not support. INTERNAL: radm_rcvd_ur_req. */
-	uint64_t caar                         : 1;  /**< Completer aborted a request. radm_rcvd_cpl_ca. */
-	uint64_t racca                        : 1;  /**< Received a completion with CA status. INTERNAL: radm_rcvd_cpl_ca. */
-	uint64_t racur                        : 1;  /**< Received a completion with UR status. INTERNAL: radm_rcvd_cpl_ur. */
-	uint64_t rauc                         : 1;  /**< Received an unexpected completion. INTERNAL: radm_unexp_cpl_err. */
+                                                         For VF TLP, either the the PCIEEP()_CFG001[ME]/PCIEEPVF()_CFG001[ME] are not set.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_BMD_E. */
+	uint64_t lofp                         : 1;  /**< Lack of forward progress at TLP FIFOs timeout occurred.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_LOFP. */
+	uint64_t ecrc_e                       : 1;  /**< Received an ECRC error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_ECRC_E. */
+	uint64_t rawwpp                       : 1;  /**< Received a write with poisoned payload.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RAWWPP.
+                                                         INTERNAL: radm_rcvd_wreq_poisoned. */
+	uint64_t racpp                        : 1;  /**< Received a completion with poisoned payload.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RACPP.
+                                                         INTERNAL: radm_rcvd_cpl_poisoned. */
+	uint64_t ramtlp                       : 1;  /**< Received a malformed TLP.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RAMTLP.
+                                                         INTERNAL: radm_mlf_tlp_err. */
+	uint64_t rarwdns                      : 1;  /**< Received a request which device does not support.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RARWDNS.
+                                                         INTERNAL: radm_rcvd_ur_req. */
+	uint64_t caar                         : 1;  /**< Completer aborted a request.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_CAAR.
+                                                         INTERNAL: radm_rcvd_cpl_ca */
+	uint64_t racca                        : 1;  /**< Received a completion with CA status.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RACCA.
+                                                         INTERNAL: radm_rcvd_cpl_ca. */
+	uint64_t racur                        : 1;  /**< Received a completion with UR status.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RACUR.
+                                                         INTERNAL: radm_rcvd_cpl_ur. */
+	uint64_t rauc                         : 1;  /**< Received an unexpected completion.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RAUC.
+                                                         INTERNAL: radm_unexp_cpl_err. */
 	uint64_t rqo                          : 1;  /**< Receive queue overflow. Normally happens only when flow control advertisements are
-                                                         ignored. INTERNAL: radm_qoverflow. */
-	uint64_t fcuv                         : 1;  /**< Flow control update violation. INTERNAL: (opt. checks) int_xadm_fc_prot_err. */
+                                                         ignored.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RQO.
+                                                         INTERNAL: radm_qoverflow. */
+	uint64_t fcuv                         : 1;  /**< Flow control update violation.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_FCUV.
+                                                         INTERNAL: (opt. checks) int_xadm_fc_prot_err. */
 	uint64_t rpe                          : 1;  /**< PHY reported an 8B/10B decode error (RxStatus = 0x4) or disparity error (RxStatus =
-                                                         0x7). INTERNAL: rmlh_rcvd_err. */
-	uint64_t fcpvwt                       : 1;  /**< Flow control protocol violation (watchdog timer). INTERNAL: rtlh_fc_prot_err. */
-	uint64_t dpeoosd                      : 1;  /**< DLLP protocol error (out of sequence DLLP). INTERNAL: rdlh_prot_err. */
-	uint64_t rtwdle                       : 1;  /**< Received TLP with datalink layer error. INTERNAL: rdlh_bad_tlp_err. */
-	uint64_t rdwdle                       : 1;  /**< Received DLLP with datalink layer error. INTERNAL: rdlh_bad_dllp_err. */
-	uint64_t mre                          : 1;  /**< Maximum number of retries exceeded. INTERNAL: xdlh_replay_num_rlover_err. */
+                                                         0x7).
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RPE.
+                                                         INTERNAL: rmlh_rcvd_err. */
+	uint64_t fcpvwt                       : 1;  /**< Flow control protocol violation (watchdog timer).
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_FCPVWT.
+                                                         INTERNAL: rtlh_fc_prot_err. */
+	uint64_t dpeoosd                      : 1;  /**< DLLP protocol error (out of sequence DLLP).
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_DPEOOSD.
+                                                         INTERNAL: rdlh_prot_err. */
+	uint64_t rtwdle                       : 1;  /**< Received TLP with datalink layer error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RTWDLE.
+                                                         INTERNAL: rdlh_bad_tlp_err. */
+	uint64_t rdwdle                       : 1;  /**< Received DLLP with datalink layer error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RDWDLE.
+                                                         INTERNAL: rdlh_bad_dllp_err. */
+	uint64_t mre                          : 1;  /**< Maximum number of retries exceeded.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_MRE.
+                                                         INTERNAL: xdlh_replay_num_rlover_err. */
 	uint64_t rte                          : 1;  /**< Replay timer expired. This bit is set when the REPLAY_TIMER expires in the PCIe core. The
                                                          probability of this bit being set increases with the traffic load.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RTE.
                                                          INTERNAL: xdlh_replay_timeout_err. */
-	uint64_t acto                         : 1;  /**< A completion timeout occurred. INTERNAL: pedc_radm_cpl_timeout. */
-	uint64_t rvdm                         : 1;  /**< Received vendor-defined message. INTERNAL: pedc_radm_vendor_msg. */
-	uint64_t rumep                        : 1;  /**< Received unlock message (EP mode only). INTERNAL: pedc_radm_msg_unlock. */
-	uint64_t rptamrc                      : 1;  /**< Received PME turnoff acknowledge message (RC mode only). INTERNAL: pedc_radm_pm_to_ack. */
-	uint64_t rpmerc                       : 1;  /**< Received PME message (RC mode only). INTERNAL: pedc_radm_pm_pme. */
+	uint64_t acto                         : 1;  /**< A completion timeout occurred.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_ACTO.
+                                                         INTERNAL: pedc_radm_cpl_timeout. */
+	uint64_t rvdm                         : 1;  /**< Received vendor-defined message.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RVDM.
+                                                         INTERNAL: pedc_radm_vendor_msg. */
+	uint64_t rumep                        : 1;  /**< Received unlock message (EP mode only).
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RUMEP.
+                                                         INTERNAL: pedc_radm_msg_unlock. */
+	uint64_t rptamrc                      : 1;  /**< Received PME turnoff acknowledge message (RC mode only).
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RPTAMRC.
+                                                         INTERNAL: pedc_radm_pm_to_ack. */
+	uint64_t rpmerc                       : 1;  /**< Received PME message (RC mode only).
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RPMERC.
+                                                         INTERNAL: pedc_radm_pm_pme. */
 	uint64_t rfemrc                       : 1;  /**< Received fatal-error message (RC mode only). This bit is set when a message with ERR_FATAL
-                                                         is set. INTERNAL: pedc_radm_fatal_err. */
-	uint64_t rnfemrc                      : 1;  /**< Received nonfatal error message (RC mode only). INTERNAL: pedc_radm_nonfatal_err. */
-	uint64_t rcemrc                       : 1;  /**< Received correctable error message (RC mode only). INTERNAL: pedc_radm_correctable_err. */
-	uint64_t rpoison                      : 1;  /**< Received poisoned TLP. INTERNAL: pedc__radm_trgt1_poisoned & pedc__radm_trgt1_hv. */
-	uint64_t recrce                       : 1;  /**< Received ECRC error. INTERNAL: pedc_radm_trgt1_ecrc_err & pedc__radm_trgt1_eot. */
-	uint64_t rtlplle                      : 1;  /**< Received TLP has link layer error. INTERNAL: pedc_radm_trgt1_dllp_abort &
-                                                         pedc__radm_trgt1_eot. */
+                                                         is set.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RFEMRC.
+                                                         INTERNAL: pedc_radm_fatal_err. */
+	uint64_t rnfemrc                      : 1;  /**< Received nonfatal error message (RC mode only).
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RNFEMRC.
+                                                         INTERNAL: pedc_radm_nonfatal_err. */
+	uint64_t rcemrc                       : 1;  /**< Received correctable error message (RC mode only).
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RCEMRC.
+                                                         INTERNAL: pedc_radm_correctable_err. */
+	uint64_t rpoison                      : 1;  /**< Received poisoned TLP.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RPOISON.
+                                                         INTERNAL: pedc__radm_trgt1_poisoned & pedc__radm_trgt1_hv. */
+	uint64_t recrce                       : 1;  /**< Received ECRC error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RECRCE.
+                                                         INTERNAL: pedc_radm_trgt1_ecrc_err & pedc__radm_trgt1_eot. */
+	uint64_t rtlplle                      : 1;  /**< Received TLP has link layer error.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RTLPLLE.
+                                                         INTERNAL: pedc_radm_trgt1_dllp_abort & pedc__radm_trgt1_eot. */
 	uint64_t rtlpmal                      : 1;  /**< Received TLP is malformed or a message. If the core receives a MSG (or Vendor Message) or
                                                          if a received AtomicOp viloates address/length rules, this bit is set as well.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_RTLPMAL.
                                                          INTERNAL: pedc_radm_trgt1_tlp_abort & pedc__radm_trgt1_eot. */
-	uint64_t spoison                      : 1;  /**< Poisoned TLP sent. Throws PEM_INTSN_E::PEM()_ERROR_SPOISON. peai__client0_tlp_ep &
-                                                         peai__client0_tlp_hv or peai__client1_tlp_ep & peai__client1_tlp_hv (atomic_op). */
+	uint64_t spoison                      : 1;  /**< Poisoned TLP sent.
+                                                         Throws PEM_INTSN_E::PEM()_ERROR_SPOISON.
+                                                         INTERNAL: peai__client0_tlp_ep & peai__client0_tlp_hv or peai__client1_tlp_ep
+                                                                   & peai__client1_tlp_hv (atomic_op). */
 #else
 	uint64_t spoison                      : 1;
 	uint64_t rtlpmal                      : 1;
@@ -3035,8 +3131,6 @@ typedef union cvmx_pemx_flr_glblcnt_ctl cvmx_pemx_flr_glblcnt_ctl_t;
  * when STOPREQ is set for the function, PEM will discard the outgoing request
  * before sending it to the PCIe core.  If a NP, PEM will schedule an immediate
  * SWI_RSP_ERROR completion for the request - no timeout is required.
- * In both cases, SPEM()_DBG_INFO[P0_BMD_E] will be set and a error
- * interrupt is generated.
  *
  * STOPREQ mimics the behavior of PCIEEPVF()_CFG001[ME] for outbound requests that will
  * master the PCIe bus (P and NP).
@@ -3071,8 +3165,6 @@ typedef union cvmx_pemx_flr_pf0_vf_stopreq cvmx_pemx_flr_pf0_vf_stopreq_t;
  * when STOPREQ is set for the function, PEM will discard the outgoing request
  * before sending it to the PCIe core.  If a NP, PEM will schedule an immediate
  * SWI_RSP_ERROR completion for the request - no timeout is required.
- * In both cases, SPEM()_DBG_PF()_INFO[P()_BMD_E] will be set and a error
- * interrupt is generated.
  *
  * STOPREQ mimics the behavior of PCIEEP()_CFG001[ME] for outbound requests that will
  * master the PCIe bus (P and NP).
@@ -3412,26 +3504,49 @@ union cvmx_pemx_int_sum {
 	struct cvmx_pemx_int_sum_cn61xx       cn70xxp1;
 	struct cvmx_pemx_int_sum_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. This is a level-sensitive interrupt. */
-	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. This is a level-sensitive interrupt. */
-	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. This is a level-sensitive interrupt. */
-	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. This is a level-sensitive interrupt. */
+	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. This is a level-sensitive interrupt. This
+                                                         should be ignored in EP mode.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_INTD. */
+	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. This is a level-sensitive interrupt. This
+                                                         should be ignored in EP mode.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_INTC. */
+	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. This is a level-sensitive interrupt. This
+                                                         should be ignored in EP mode.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_INTB. */
+	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. This is a level-sensitive interrupt. This
+                                                         should be ignored in EP mode.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_INTA. */
 	uint64_t reserved_14_59               : 46;
-	uint64_t crs_dr                       : 1;  /**< Had a CRS timeout when retries were disabled. */
-	uint64_t crs_er                       : 1;  /**< Had a CRS timeout when retries were enabled. */
-	uint64_t rdlk                         : 1;  /**< Received read lock TLP. */
+	uint64_t crs_dr                       : 1;  /**< Had a CRS timeout when retries were disabled. This should be ignored in EP mode.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_CRS_DR. */
+	uint64_t crs_er                       : 1;  /**< Had a CRS timeout when retries were enabled. This should be ignored in EP mode.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_CRS_ER. */
+	uint64_t rdlk                         : 1;  /**< Received read lock TLP.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_RDLK. */
 	uint64_t reserved_10_10               : 1;
-	uint64_t un_bx                        : 1;  /**< Received N-TLP for unknown BAR. */
-	uint64_t un_b2                        : 1;  /**< Received N-TLP for BAR2 when BAR2 is disabled. */
-	uint64_t un_b1                        : 1;  /**< Received N-TLP for BAR1 when BAR1 index valid is not set. */
-	uint64_t up_bx                        : 1;  /**< Received P-TLP for an unknown BAR. */
-	uint64_t up_b2                        : 1;  /**< Received P-TLP for BAR2 when BAR2 is disabled. */
-	uint64_t up_b1                        : 1;  /**< Received P-TLP for BAR1 when BAR1 index valid is not set. */
+	uint64_t un_bx                        : 1;  /**< Received N-TLP for unknown BAR.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_UN_BX. */
+	uint64_t un_b2                        : 1;  /**< Received N-TLP for BAR2 when BAR2 is disabled.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_UN_B2. */
+	uint64_t un_b1                        : 1;  /**< Received N-TLP for BAR1 when BAR1 index valid is not set.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_UN_B1. */
+	uint64_t up_bx                        : 1;  /**< Received P-TLP for an unknown BAR.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_UP_BX. */
+	uint64_t up_b2                        : 1;  /**< Received P-TLP for BAR2 when BAR2 is disabled.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_UP_B2. */
+	uint64_t up_b1                        : 1;  /**< Received P-TLP for BAR1 when BAR1 index valid is not set.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_UP_B1. */
 	uint64_t reserved_3_3                 : 1;
-	uint64_t pmei                         : 1;  /**< PME interrupt (cfg_pme_int). This is a level-sensitive interrupt. */
-	uint64_t se                           : 1;  /**< System error, RC mode only.  (cfg_sys_err_rc) */
-	uint64_t aeri                         : 1;  /**< Advanced error reporting interrupt, RC mode only (cfg_aer_rc_err_int).
-                                                         This is a level-sensitive interrupt. */
+	uint64_t pmei                         : 1;  /**< PME interrupt. This is a level-sensitive interrupt.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_PMEI.
+                                                         INTERNAL: cfg_pme_int */
+	uint64_t se                           : 1;  /**< System error, RC mode only.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_SE.
+                                                         INTERNAL: cfg_sys_err_rc */
+	uint64_t aeri                         : 1;  /**< Advanced error reporting interrupt, RC mode only.
+                                                         This is a level-sensitive interrupt.
+                                                         Throws corresponding PEM_INTSN_E::PEM()_ERROR_AERI.
+                                                         INTERNAL: cfg_aer_rc_err_int */
 #else
 	uint64_t aeri                         : 1;
 	uint64_t se                           : 1;
@@ -3525,11 +3640,11 @@ union cvmx_pemx_p2n_bar0_start {
 	struct cvmx_pemx_p2n_bar0_start_cn61xx cn70xxp1;
 	struct cvmx_pemx_p2n_bar0_start_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t addr                         : 40; /**< The starting address of the 64MB BAR0 address space. */
-	uint64_t reserved_0_23                : 24;
+	uint64_t addr                         : 41; /**< The starting address of the 8MB BAR0 address space. */
+	uint64_t reserved_0_22                : 23;
 #else
-	uint64_t reserved_0_23                : 24;
-	uint64_t addr                         : 40;
+	uint64_t reserved_0_22                : 23;
+	uint64_t addr                         : 41;
 #endif
 	} cn73xx;
 	struct cvmx_pemx_p2n_bar0_start_cn78xx {
diff --git a/arch/mips/include/asm/octeon/cvmx-pexp-defs.h b/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
index 10a475f..6e673e9 100644
--- a/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
@@ -1931,7 +1931,7 @@ static inline uint64_t CVMX_PEXP_SLI_PKT_INPUT_CONTROL_FUNC(void)
 #define CVMX_PEXP_SLI_PKT_INSTR_ENB CVMX_PEXP_SLI_PKT_INSTR_ENB_FUNC()
 static inline uint64_t CVMX_PEXP_SLI_PKT_INSTR_ENB_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
 		cvmx_warn("CVMX_PEXP_SLI_PKT_INSTR_ENB not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F0000011000ull);
 }
@@ -2060,7 +2060,7 @@ static inline uint64_t CVMX_PEXP_SLI_PKT_OUT_BMODE_FUNC(void)
 #define CVMX_PEXP_SLI_PKT_OUT_BP_EN CVMX_PEXP_SLI_PKT_OUT_BP_EN_FUNC()
 static inline uint64_t CVMX_PEXP_SLI_PKT_OUT_BP_EN_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN78XX)))
 		cvmx_warn("CVMX_PEXP_SLI_PKT_OUT_BP_EN not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F0000011240ull);
 }
@@ -2071,7 +2071,7 @@ static inline uint64_t CVMX_PEXP_SLI_PKT_OUT_BP_EN_FUNC(void)
 #define CVMX_PEXP_SLI_PKT_OUT_ENB CVMX_PEXP_SLI_PKT_OUT_ENB_FUNC()
 static inline uint64_t CVMX_PEXP_SLI_PKT_OUT_ENB_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
 		cvmx_warn("CVMX_PEXP_SLI_PKT_OUT_ENB not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F0000011010ull);
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-defs.h b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
index 0d1ec13..aa468ec 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
@@ -405,6 +405,7 @@ static inline uint64_t CVMX_PKI_DSTATX_STAT0(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1023))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKI_DSTATX_STAT0(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180044C00000ull) + ((offset) & 1023) * 64;
@@ -417,6 +418,7 @@ static inline uint64_t CVMX_PKI_DSTATX_STAT1(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1023))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKI_DSTATX_STAT1(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180044C00008ull) + ((offset) & 1023) * 64;
@@ -429,6 +431,7 @@ static inline uint64_t CVMX_PKI_DSTATX_STAT2(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1023))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKI_DSTATX_STAT2(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180044C00010ull) + ((offset) & 1023) * 64;
@@ -441,6 +444,7 @@ static inline uint64_t CVMX_PKI_DSTATX_STAT3(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1023))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKI_DSTATX_STAT3(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180044C00018ull) + ((offset) & 1023) * 64;
@@ -453,6 +457,7 @@ static inline uint64_t CVMX_PKI_DSTATX_STAT4(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1023))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKI_DSTATX_STAT4(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180044C00020ull) + ((offset) & 1023) * 64;
@@ -604,7 +609,7 @@ static inline uint64_t CVMX_PKI_LTYPEX_MAP(unsigned long offset)
 #define CVMX_PKI_PBE_ECO CVMX_PKI_PBE_ECO_FUNC()
 static inline uint64_t CVMX_PKI_PBE_ECO_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_PKI_PBE_ECO not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001180044000710ull);
 }
@@ -648,7 +653,7 @@ static inline uint64_t CVMX_PKI_PFE_DIAG_FUNC(void)
 #define CVMX_PKI_PFE_ECO CVMX_PKI_PFE_ECO_FUNC()
 static inline uint64_t CVMX_PKI_PFE_ECO_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_PKI_PFE_ECO not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001180044000720ull);
 }
@@ -681,7 +686,7 @@ static inline uint64_t CVMX_PKI_PIX_DIAG_FUNC(void)
 #define CVMX_PKI_PIX_ECO CVMX_PKI_PIX_ECO_FUNC()
 static inline uint64_t CVMX_PKI_PIX_ECO_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_PKI_PIX_ECO not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001180044000700ull);
 }
@@ -755,7 +760,7 @@ static inline uint64_t CVMX_PKI_PKT_ERR_FUNC(void)
 #define CVMX_PKI_PTAG_AVAIL CVMX_PKI_PTAG_AVAIL_FUNC()
 static inline uint64_t CVMX_PKI_PTAG_AVAIL_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_PKI_PTAG_AVAIL not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001180044000130ull);
 }
@@ -767,6 +772,7 @@ static inline uint64_t CVMX_PKI_QPG_TBLBX(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 2047))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 2047))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 2047)))))
 		cvmx_warn("CVMX_PKI_QPG_TBLBX(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180044820000ull) + ((offset) & 2047) * 8;
@@ -1662,7 +1668,6 @@ union cvmx_pki_clx_ecc_ctl {
 	struct cvmx_pki_clx_ecc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t pcam_en                      : 1;  /**< PCAM ECC checking enable. PCAM_EN must be clear when reading or writing the
-                                                         PKI_CL(0..1)_PCAM(0..1)_TERM(0..191), PKI_CL(0..1)_PCAM(0..1)_MATCH(0..191), or
                                                          PKI_PCAM_RESULT registers. INTERNAL: This enables the PCAM scrubber. */
 	uint64_t reserved_24_62               : 39;
 	uint64_t pcam1_flip                   : 2;  /**< PCAM1 flip syndrome bits on write. */
@@ -1846,9 +1851,6 @@ typedef union cvmx_pki_clx_pcamx_actionx cvmx_pki_clx_pcamx_actionx_t;
 
 /**
  * cvmx_pki_cl#_pcam#_match#
- *
- * PKI_CL(0..1)_ECC_CTL[PCAM_EN] must be clear before accessing this register.
- *
  */
 union cvmx_pki_clx_pcamx_matchx {
 	uint64_t u64;
@@ -1877,9 +1879,6 @@ typedef union cvmx_pki_clx_pcamx_matchx cvmx_pki_clx_pcamx_matchx_t;
 
 /**
  * cvmx_pki_cl#_pcam#_term#
- *
- * PKI_CL(0..1)_ECC_CTL[PCAM_EN] must be clear before accessing this register.
- *
  */
 union cvmx_pki_clx_pcamx_termx {
 	uint64_t u64;
@@ -3157,11 +3156,16 @@ union cvmx_pki_icgx_cfg {
                                                          TIMER is non-zero, a cluster in this group will not start parsing. When a cluster in this
                                                          group starts parsing, TIMER is set to DELAY, and decrements every coprocessor-clock. TIMER
                                                          is zeroed if all clusters in this group are idle. */
-	uint64_t delay                        : 12; /**< Delay between cluster starts, as described under TIMER. If zero, a cluster can start at
-                                                         any time relative to other clusters. DELAY should be typically selected to minimize the
-                                                         average observed parser latency by loading with the parsing delay divided by the number of
-                                                         clusters in this cluster group. The smallest useful non-zero value is 0xA0, corresponding
-                                                         to the minimum number of cycles needed to fill one cluster with packets. */
+	uint64_t delay                        : 12; /**< Delay between cluster starts, as described under TIMER. If 0x0, a cluster can
+                                                         start at any time relative to other clusters. DELAY should be typically selected
+                                                         to minimize the average observed parser latency by loading with the parsing
+                                                         delay divided by the number of clusters in this cluster group which will
+                                                         typically be 800 divided by the population count of CLUSTERS
+                                                         (800/pop_cnt(CLUSTERS)). The smallest useful non-zero value is 0xA0,
+                                                         corresponding to the minimum number of cycles needed to fill one cluster with
+                                                         packets.
+                                                         INTERNAL: The number 800 above was chosen as a typical production ucode
+                                                         length with some additional instruction growth. */
 #else
 	uint64_t delay                        : 12;
 	uint64_t timer                        : 12;
@@ -3655,8 +3659,11 @@ union cvmx_pki_reasm_sopx {
 	uint64_t u64;
 	struct cvmx_pki_reasm_sopx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sop                          : 64; /**< When set, a SOP was detected on a reasm-Id. When clear, a SOP has not yet been received,
-                                                         or an EOP was received on the Reasm-Id. */
+	uint64_t sop                          : 64; /**< When set, a SOP was detected on a reasm-Id. When clear, a SOP has not yet been
+                                                         received, or an EOP was received on the Reasm-Id. The total number of available
+                                                         reassembly IDs is described with the PKI_REASM_E[NUM_REASM] enumeration. Not all
+                                                         bits are implemented. Only PKI_REASM_SOP(0)[SOP<63:0>],
+                                                         PKI_REASM_SOP(1)[SOP<31:0>] are present in this implementation. */
 #else
 	uint64_t sop                          : 64;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-pko-defs.h b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
index 262efbb..62e0a40 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
@@ -1492,7 +1492,7 @@ static inline uint64_t CVMX_PKO_LUTX(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 383))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 383)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 255)))))
 		cvmx_warn("CVMX_PKO_LUTX(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001540000B00000ull) + ((offset) & 1023) * 8;
 }
@@ -1571,7 +1571,7 @@ static inline uint64_t CVMX_PKO_MACX_CFG(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 13))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 27))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 13)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 9)))))
 		cvmx_warn("CVMX_PKO_MACX_CFG(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001540000900000ull) + ((offset) & 31) * 8;
 }
@@ -1606,7 +1606,7 @@ static inline uint64_t CVMX_PKO_MCI1_CRED_CNTX(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 13))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 27))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 13)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 9)))))
 		cvmx_warn("CVMX_PKO_MCI1_CRED_CNTX(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001540000A80100ull) + ((offset) & 31) * 8;
 }
@@ -1619,7 +1619,7 @@ static inline uint64_t CVMX_PKO_MCI1_MAX_CREDX(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 13))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 27))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 13)))))
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 9)))))
 		cvmx_warn("CVMX_PKO_MCI1_MAX_CREDX(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001540000A80000ull) + ((offset) & 31) * 8;
 }
@@ -2088,7 +2088,7 @@ static inline uint64_t CVMX_PKO_PDM_FLSHB_DBG1_FUNC(void)
 #define CVMX_PKO_PDM_INTF_DBG_RD CVMX_PKO_PDM_INTF_DBG_RD_FUNC()
 static inline uint64_t CVMX_PKO_PDM_INTF_DBG_RD_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_PKO_PDM_INTF_DBG_RD not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001540000900F20ull);
 }
@@ -2286,7 +2286,7 @@ static inline uint64_t CVMX_PKO_PEB_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PEB_ECO CVMX_PKO_PEB_ECO_FUNC()
 static inline uint64_t CVMX_PKO_PEB_ECO_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_PKO_PEB_ECO not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001540000901000ull);
 }
@@ -3247,6 +3247,7 @@ static inline uint64_t CVMX_PKO_STATE_UID_IN_USEX_RD(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 2))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 1)))))
 		cvmx_warn("CVMX_PKO_STATE_UID_IN_USEX_RD(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001540000900F00ull) + ((offset) & 3) * 8;
@@ -3270,6 +3271,7 @@ static inline uint64_t CVMX_PKO_TXFX_PKT_CNT_RD(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 15))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 27))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 15)))))
 		cvmx_warn("CVMX_PKO_TXFX_PKT_CNT_RD(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001540000900E00ull) + ((offset) & 31) * 8;
@@ -4995,19 +4997,15 @@ union cvmx_pko_l1_sqx_topology {
                                                           -------------------------------------------------
                                                              0         PKO_MAC0_CFG      LBK loopback
                                                              1         PKO_MAC1_CFG      DPI packet output
-                                                             2         PKO_MAC2_CFG      BGX0 logical MAC 0
-                                                             3         PKO_MAC3_CFG      BGX0 logical MAC 1
-                                                             4         PKO_MAC4_CFG      BGX0 logical MAC 2
-                                                             5         PKO_MAC5_CFG      BGX0 logical MAC 3
-                                                             6         PKO_MAC6_CFG      BGX1 logical MAC 0
-                                                             7         PKO_MAC7_CFG      BGX1 logical MAC 1
-                                                             8         PKO_MAC8_CFG      BGX1 logical MAC 2
-                                                             9         PKO_MAC9_CFG      BGX1 logical MAC 3
-                                                            10         PKO_MAC10_CFG     BGX2 logical MAC 0
-                                                            11         PKO_MAC11_CFG     BGX2 logical MAC 1
-                                                            12         PKO_MAC12_CFG     BGX2 logical MAC 2
-                                                            13         PKO_MAC13_CFG     BGX2 logical MAC 3
-                                                            14            None           NULL FIFO
+                                                             2         PKO_MAC2_CFG      BGX0  logical MAC 0
+                                                             3         PKO_MAC3_CFG      BGX0  logical MAC 1
+                                                             4         PKO_MAC4_CFG      BGX0  logical MAC 2
+                                                             5         PKO_MAC5_CFG      BGX0  logical MAC 3
+                                                             6         PKO_MAC6_CFG      SRIO0 logical MAC 0
+                                                             7         PKO_MAC7_CFG      SRIO0 logical MAC 1
+                                                             8         PKO_MAC8_CFG      SRIO1 logical MAC 0
+                                                             9         PKO_MAC9_CFG      SRIO1 logical MAC 1
+                                                            10            None           NULL FIFO
                                                          </pre>
                                                          When a MAC is used by the L1 SQ, [LINK] must be unique relative to
                                                          other [LINK]'s. [LINK] should be 14 when the L1 SQ is not used. */
@@ -7696,20 +7694,12 @@ typedef union cvmx_pko_l5_sqb_debug cvmx_pko_l5_sqb_debug_t;
  *   LINK/   PKI_CHAN_E    Corresponding
  * MAC_NUM   Range         PKO_LUT index   Description
  * -------   -----------   -------------   -----------------
- *     0     0x000-0x03F   0x0C0-0x0FF     LBK Loopback
- *     1     0x100-0x17F   0x100-0x17F     DPI packet output
+ *     0     0x000-0x03F   0x040-0x07F     LBK Loopback
+ *     1     0x100-0x17F   0x080-0xoFF     DPI packet output
  *     2     0x800-0x80F   0x000-0x00F     BGX0 Logical MAC 0
  *     3     0x810-0x81F   0x010-0x01F     BGX0 Logical MAC 1
  *     4     0x820-0x82F   0x020-0x02F     BGX0 Logical MAC 2
  *     5     0x830-0x83F   0x030-0x03F     BGX0 Logical MAC 3
- *     6     0x900-0x90F   0x040-0x04F     BGX1 Logical MAC 0
- *     7     0x910-0x91F   0x050-0x05F     BGX1 Logical MAC 1
- *     8     0x920-0x92F   0x060-0x06F     BGX1 Logical MAC 2
- *     9     0x930-0x93F   0x070-0x07F     BGX1 Logical MAC 3
- *    10     0xA00-0xA0F   0x080-0x08F     BGX2 Logical MAC 0
- *    11     0xA10-0xA1F   0x090-0x09F     BGX2 Logical MAC 1
- *    12     0xA20-0xA2F   0x0A0-0x0AF     BGX2 Logical MAC 2
- *    13     0xA30-0xA3F   0x0B0-0x0BF     BGX2 Logical MAC 3
  * </pre>
  */
 union cvmx_pko_lutx {
@@ -7902,18 +7892,14 @@ typedef union cvmx_pko_lut_ecc_sbe_sts_cmb0 cvmx_pko_lut_ecc_sbe_sts_cmb0_t;
  *   ---------------------------------
  *   PKO_MAC0_CFG   LBK loopback
  *   PKO_MAC1_CFG   DPI packet output
- *   PKO_MAC2_CFG   BGX0 logical MAC 0
- *   PKO_MAC3_CFG   BGX0 logical MAC 1
- *   PKO_MAC4_CFG   BGX0 logical MAC 2
- *   PKO_MAC5_CFG   BGX0 logical MAC 3
- *   PKO_MAC6_CFG   BGX1 logical MAC 0
- *   PKO_MAC7_CFG   BGX1 logical MAC 1
- *   PKO_MAC8_CFG   BGX1 logical MAC 2
- *   PKO_MAC9_CFG   BGX1 logical MAC 3
- *   PKO_MAC10_CFG  BGX2 logical MAC 0
- *   PKO_MAC11_CFG  BGX2 logical MAC 1
- *   PKO_MAC12_CFG  BGX2 logical MAC 2
- *   PKO_MAC13_CFG  BGX2 logical MAC 3
+ *   PKO_MAC2_CFG   BGX0  logical MAC 0
+ *   PKO_MAC3_CFG   BGX0  logical MAC 1
+ *   PKO_MAC4_CFG   BGX0  logical MAC 2
+ *   PKO_MAC5_CFG   BGX0  logical MAC 3
+ *   PKO_MAC6_CFG   SRIO0 logical MAC 0
+ *   PKO_MAC7_CFG   SRIO0 logical MAC 1
+ *   PKO_MAC8_CFG   SRIO1 logical MAC 0
+ *   PKO_MAC9_CFG   SRIO1 logical MAC 1
  * </pre>
  */
 union cvmx_pko_macx_cfg {
@@ -11427,6 +11413,7 @@ union cvmx_pko_pdm_intf_dbg_rd {
 #endif
 	} s;
 	struct cvmx_pko_pdm_intf_dbg_rd_s     cn73xx;
+	struct cvmx_pko_pdm_intf_dbg_rd_s     cn78xx;
 	struct cvmx_pko_pdm_intf_dbg_rd_s     cn78xxp2;
 	struct cvmx_pko_pdm_intf_dbg_rd_s     cnf75xx;
 };
@@ -16847,7 +16834,9 @@ union cvmx_pko_ptgfx_cfg {
                                                          [RESET].
                                                          PKO_PTGF(4)_CFG[SIZE] should not change from its reset value
                                                          of zero. (The NULL FIFO has no real storage, and the SIZE table
-                                                         above does not apply to the NULL FIFO.) */
+                                                         above does not apply to the NULL FIFO.)
+                                                         A FIFO of size 2.5kB cannot be configured to have a RATE>25GBs
+                                                         A FIFO of size 5.0kB cannot be configured to have a RATE>50GBs */
 #else
 	uint64_t size                         : 3;
 	uint64_t rate                         : 3;
@@ -18627,6 +18616,7 @@ union cvmx_pko_state_uid_in_usex_rd {
 #endif
 	} s;
 	struct cvmx_pko_state_uid_in_usex_rd_s cn73xx;
+	struct cvmx_pko_state_uid_in_usex_rd_s cn78xx;
 	struct cvmx_pko_state_uid_in_usex_rd_s cn78xxp2;
 	struct cvmx_pko_state_uid_in_usex_rd_s cnf75xx;
 };
@@ -18735,6 +18725,7 @@ union cvmx_pko_txfx_pkt_cnt_rd {
 #endif
 	} s;
 	struct cvmx_pko_txfx_pkt_cnt_rd_s     cn73xx;
+	struct cvmx_pko_txfx_pkt_cnt_rd_s     cn78xx;
 	struct cvmx_pko_txfx_pkt_cnt_rd_s     cn78xxp2;
 	struct cvmx_pko_txfx_pkt_cnt_rd_s     cnf75xx;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3-queue.h b/arch/mips/include/asm/octeon/cvmx-pko3-queue.h
index 503e432..1a59714 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko3-queue.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko3-queue.h
@@ -80,7 +80,7 @@ int cvmx_pko3_get_queue_num(int ipd_port);
  * The Scheduler Queues in Levels 3 to 5 and Descriptor Queues are
  * configured one-to-one or many-to-one to a single parent Scheduler
  * Queues. The level of the parent SQ is specified in an argument,
- * as well as the number of childer to attach to the specific parent.
+ * as well as the number of children to attach to the specific parent.
  * The children can have fair round-robin or priority-based scheduling
  * when multiple children are assigned a single parent.
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3-resources.h b/arch/mips/include/asm/octeon/cvmx-pko3-resources.h
index 664a59b..aab4a9d 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko3-resources.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko3-resources.h
@@ -76,6 +76,8 @@ extern int cvmx_pko_free_queues(int node, int level, int owner);
 
 extern int __cvmx_pko3_dq_param_setup(unsigned node);
 
+int cvmx_pko3_num_level_queues(enum cvmx_pko3_level_e level);
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3.h b/arch/mips/include/asm/octeon/cvmx-pko3.h
index a4eef81..77ec29b 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko3.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko3.h
@@ -106,7 +106,7 @@ enum cvmx_pko_dqop {
 static inline unsigned __cvmx_pko3_num_macs(void)
 {
         if(OCTEON_IS_MODEL(OCTEON_CNF75XX))
-		return 10;	//CSR=14 simulator=10 ?? XXX
+		return 10;
         if(OCTEON_IS_MODEL(OCTEON_CN73XX))
 		return 14;
         if(OCTEON_IS_MODEL(OCTEON_CN78XX))
@@ -513,22 +513,11 @@ static inline int __cvmx_pko3_get_mac_num(int xiface, int index)
 	int ilk_mac_base = -1, bgx_mac_base = -1, bgx_ports = 4;
 
 	if (OCTEON_IS_MODEL(OCTEON_CN73XX)) {
-		/* Interface 2,3 each represent half of BGX2 */
-		if ((xi.interface >> 1) == 1) {
-			bgx_ports = 2;
-			bgx_mac_base = 2 + 2 * 4;
-			xi.interface &= 1;
-			return (bgx_mac_base +
-				xi.interface * bgx_ports +
-				index);
-		}
-		/* Interfaces 0,1 each represent full BGX 0,1 respectively */
 		bgx_mac_base = 2;
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
 		bgx_mac_base = 2;
-		bgx_ports = 2;
 	}
 
         if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
@@ -550,12 +539,7 @@ static inline int __cvmx_pko3_get_mac_num(int xiface, int index)
 				return -1;
 			return (ilk_mac_base + interface_index);
 		case CVMX_HELPER_INTERFACE_MODE_SRIO:
-			/* CNF75XX: sRIO MAC# */
-			interface_index = (xi.interface - 2);
-			if (interface_index < 0)
-				return -1;
-			// XXX MAC base guessed from simulator
-			return 6 + interface_index * 2 + index;
+			return (4 + 2 * xi.interface + index);
 		default:
 			if (xi.interface >= CVMX_ILK_GBL_BASE() &&
 			    ilk_mac_base >= 0)
@@ -597,8 +581,9 @@ cvmx_pko3_cvmseg_addr(void)
  * The command should be already stored in the CVMSEG address.
  *
  * @param node is the destination node
- * @param dq is the destonation descriptor queue.
- * @param numworkds is the number of outgoing words
+ * @param dq is the destination descriptor queue.
+ * @param numwords is the number of outgoing words
+ * @param tag_wait Wait to finish tag switch just before issueing LMTDMA
  * @return the PKO3 native query result structure.
  *
  * <numwords> must be between 1 and 15 for CVMX_PKO_DQ_SEND command
diff --git a/arch/mips/include/asm/octeon/cvmx-qlm.h b/arch/mips/include/asm/octeon/cvmx-qlm.h
index 12e75a6..d338230 100644
--- a/arch/mips/include/asm/octeon/cvmx-qlm.h
+++ b/arch/mips/include/asm/octeon/cvmx-qlm.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2011-2014  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2011-2015  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 116105 $<hr>
+ * <hr>$Revision: 118803 $<hr>
  */
 
 #ifndef __CVMX_QLM_H__
@@ -208,6 +208,13 @@ enum cvmx_qlm_mode {
 	CVMX_QLM_MODE_RGMII_XAUI,
 	CVMX_QLM_MODE_RGMII_XLAUI,
 	CVMX_QLM_MODE_RGMII_40G_KR4,
+	CVMX_QLM_MODE_MIXED,      /* BGX2 is mixed mode, DLM5(SGMII) & DLM6(XFI) */
+	CVMX_QLM_MODE_SGMII_1X2,  /* Configure BGX2 separate for DLM5 & DLM6 */ 
+	CVMX_QLM_MODE_10G_KR_1X2, /* Configure BGX2 separate for DLM5 & DLM6 */
+	CVMX_QLM_MODE_XFI_1X2,    /* Configure BGX2 separate for DLM5 & DLM6 */
+	CVMX_QLM_MODE_RGMII_SGMII_1X1, /* Configure BGX2, applies to DLM5 */
+	CVMX_QLM_MODE_RGMII_10G_KR_1X1, /* Configure BGX2, applies to DLM6 */
+	CVMX_QLM_MODE_RGMII_XFI_1X1, /* Configure BGX2, applies to DLM6 */
 	CVMX_QLM_MODE_OCI
 };
 
@@ -251,6 +258,17 @@ extern void cvmx_qlm_display_registers(int qlm);
 
 extern int cvmx_qlm_measure_clock(int qlm);
 
+/*
+ * Perform RX equalization on a QLM
+ *
+ * @param node	Node the QLM is on
+ * @param qlm	QLM to perform RX equalization on
+ * @param lane	Lane to use, or -1 for all lanes
+ *
+ * @return Zero on sucess, negative if any lane failed RX equalization
+ */
+extern int __cvmx_qlm_rx_equalization(int node, int qlm, int lane);
+
 #ifdef CVMX_DUMP_GSER
 /**
  * Dump GSER configuration for node 0
diff --git a/arch/mips/include/asm/octeon/cvmx-rst-defs.h b/arch/mips/include/asm/octeon/cvmx-rst-defs.h
index c5f7668..da6c480 100644
--- a/arch/mips/include/asm/octeon/cvmx-rst-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-rst-defs.h
@@ -56,7 +56,7 @@
 #define CVMX_RST_BIST_TIMER CVMX_RST_BIST_TIMER_FUNC()
 static inline uint64_t CVMX_RST_BIST_TIMER_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_RST_BIST_TIMER not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001180006001760ull);
 }
@@ -112,6 +112,7 @@ static inline uint64_t CVMX_RST_COLD_DATAX(unsigned long offset)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 3))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 3)))))
 		cvmx_warn("CVMX_RST_COLD_DATAX(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011800060017C0ull) + ((offset) & 3) * 8;
@@ -170,7 +171,7 @@ static inline uint64_t CVMX_RST_INT_FUNC(void)
 #define CVMX_RST_INT_W1S CVMX_RST_INT_W1S_FUNC()
 static inline uint64_t CVMX_RST_INT_W1S_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_RST_INT_W1S not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001180006001630ull);
 }
@@ -225,7 +226,7 @@ static inline uint64_t CVMX_RST_PP_POWER_FUNC(void)
 #define CVMX_RST_REF_CNTR CVMX_RST_REF_CNTR_FUNC()
 static inline uint64_t CVMX_RST_REF_CNTR_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
 		cvmx_warn("CVMX_RST_REF_CNTR not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x0001180006001758ull);
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-sli-defs.h b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
index cd7fae8..6183bba 100644
--- a/arch/mips/include/asm/octeon/cvmx-sli-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
@@ -301,16 +301,16 @@ static inline uint64_t CVMX_SLI_MACX_PFX_DMA_VF_INT(unsigned long offset, unsign
 #define CVMX_SLI_MACX_PFX_DMA_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027280ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_SLI_MACX_PFX_ERROR_INFO(unsigned long offset, unsigned long block_id)
+static inline uint64_t CVMX_SLI_MACX_PFX_DMA_VF_INT_ENB(unsigned long offset, unsigned long block_id)
 {
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
-		cvmx_warn("CVMX_SLI_MACX_PFX_ERROR_INFO(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027480ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+		cvmx_warn("CVMX_SLI_MACX_PFX_DMA_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027500ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_ERROR_INFO(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027480ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_DMA_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027500ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_FLR_VF_INT(unsigned long offset, unsigned long block_id)
@@ -373,6 +373,18 @@ static inline uint64_t CVMX_SLI_MACX_PFX_PKT_VF_INT(unsigned long offset, unsign
 #define CVMX_SLI_MACX_PFX_PKT_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027300ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SLI_MACX_PFX_PKT_VF_INT_ENB(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_SLI_MACX_PFX_PKT_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027580ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_SLI_MACX_PFX_PKT_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027580ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_PP_VF_INT(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -385,6 +397,18 @@ static inline uint64_t CVMX_SLI_MACX_PFX_PP_VF_INT(unsigned long offset, unsigne
 #define CVMX_SLI_MACX_PFX_PP_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027200ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SLI_MACX_PFX_PP_VF_INT_ENB(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_SLI_MACX_PFX_PP_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027480ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_SLI_MACX_PFX_PP_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027480ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_MAC_CREDIT_CNT CVMX_SLI_MAC_CREDIT_CNT_FUNC()
 static inline uint64_t CVMX_SLI_MAC_CREDIT_CNT_FUNC(void)
 {
@@ -483,13 +507,13 @@ static inline uint64_t CVMX_SLI_MEM_ACCESS_SUBIDX(unsigned long offset)
 static inline uint64_t CVMX_SLI_MEM_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105E0ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F00000285E0ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F00000105E0ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_MEM_CTL not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F00000285E0ull);
@@ -499,11 +523,11 @@ static inline uint64_t CVMX_SLI_MEM_CTL_FUNC(void)
 static inline uint64_t CVMX_SLI_MEM_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105E0ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F00000285E0ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F00000105E0ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011F00000285E0ull);
 }
@@ -513,13 +537,13 @@ static inline uint64_t CVMX_SLI_MEM_CTL_FUNC(void)
 static inline uint64_t CVMX_SLI_MEM_INT_SUM_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105D0ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F00000285D0ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F00000105D0ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_MEM_INT_SUM not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F00000285D0ull);
@@ -529,11 +553,11 @@ static inline uint64_t CVMX_SLI_MEM_INT_SUM_FUNC(void)
 static inline uint64_t CVMX_SLI_MEM_INT_SUM_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105D0ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F00000285D0ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F00000105D0ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011F00000285D0ull);
 }
@@ -542,15 +566,15 @@ static inline uint64_t CVMX_SLI_MEM_INT_SUM_FUNC(void)
 static inline uint64_t CVMX_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 64))
-				return CVMX_ADD_IO_SEG(0x00011F0000016000ull) + ((offset) & 127) * 16;
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 64))
 				return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + ((offset) & 127) * 16;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 64))
+				return CVMX_ADD_IO_SEG(0x00011F0000016000ull) + ((offset) & 127) * 16;
+			break;
 	}
 	cvmx_warn("CVMX_SLI_MSIXX_TABLE_ADDR (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + ((offset) & 127) * 16;
@@ -559,11 +583,11 @@ static inline uint64_t CVMX_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
 static inline uint64_t CVMX_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000016000ull) + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + (offset) * 16;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000016000ull) + (offset) * 16;
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + (offset) * 16;
 }
@@ -572,15 +596,15 @@ static inline uint64_t CVMX_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
 static inline uint64_t CVMX_SLI_MSIXX_TABLE_DATA(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 64))
-				return CVMX_ADD_IO_SEG(0x00011F0000016008ull) + ((offset) & 127) * 16;
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 64))
 				return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + ((offset) & 127) * 16;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 64))
+				return CVMX_ADD_IO_SEG(0x00011F0000016008ull) + ((offset) & 127) * 16;
+			break;
 	}
 	cvmx_warn("CVMX_SLI_MSIXX_TABLE_DATA (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + ((offset) & 127) * 16;
@@ -589,11 +613,11 @@ static inline uint64_t CVMX_SLI_MSIXX_TABLE_DATA(unsigned long offset)
 static inline uint64_t CVMX_SLI_MSIXX_TABLE_DATA(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000016008ull) + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + (offset) * 16;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000016008ull) + (offset) * 16;
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + (offset) * 16;
 }
@@ -625,13 +649,13 @@ static inline uint64_t CVMX_SLI_MSIX_MACX_PF_TABLE_DATA(unsigned long offset)
 static inline uint64_t CVMX_SLI_MSIX_PBA0_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000017000ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000001000ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000017000ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_MSIX_PBA0 not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F0000001000ull);
@@ -641,11 +665,11 @@ static inline uint64_t CVMX_SLI_MSIX_PBA0_FUNC(void)
 static inline uint64_t CVMX_SLI_MSIX_PBA0_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000017000ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000001000ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000017000ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000001000ull);
 }
@@ -655,32 +679,29 @@ static inline uint64_t CVMX_SLI_MSIX_PBA0_FUNC(void)
 static inline uint64_t CVMX_SLI_MSIX_PBA1_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000017010ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000001010ull);
-			break;
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000001008ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000017010ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_MSIX_PBA1 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000001010ull);
+	return CVMX_ADD_IO_SEG(0x00011F0000001008ull);
 }
 #else
 #define CVMX_SLI_MSIX_PBA1 CVMX_SLI_MSIX_PBA1_FUNC()
 static inline uint64_t CVMX_SLI_MSIX_PBA1_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000017010ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000001010ull);
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000001008ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000017010ull);
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000001010ull);
+	return CVMX_ADD_IO_SEG(0x00011F0000001008ull);
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -956,18 +977,30 @@ static inline uint64_t CVMX_SLI_PKTX_CNTS(unsigned long offset)
 #define CVMX_SLI_PKTX_CNTS(offset) (0x0000000000002400ull + ((offset) & 127) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SLI_PKTX_ERROR_INFO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
+		cvmx_warn("CVMX_SLI_PKTX_ERROR_INFO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F00000100C0ull) + ((offset) & 127) * 0x20000ull;
+}
+#else
+#define CVMX_SLI_PKTX_ERROR_INFO(offset) (CVMX_ADD_IO_SEG(0x00011F00000100C0ull) + ((offset) & 127) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000014000ull) + ((offset) & 63) * 16;
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
 				return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + ((offset) & 127) * 0x20000ull;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 63))
+				return CVMX_ADD_IO_SEG(0x00011F0000014000ull) + ((offset) & 63) * 16;
+			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_INPUT_CONTROL (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + ((offset) & 127) * 0x20000ull;
@@ -976,11 +1009,11 @@ static inline uint64_t CVMX_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
 static inline uint64_t CVMX_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000014000ull) + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + (offset) * 0x20000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000014000ull) + (offset) * 16;
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + (offset) * 0x20000ull;
 }
@@ -1062,15 +1095,15 @@ static inline uint64_t CVMX_SLI_PKTX_INSTR_HEADER(unsigned long offset)
 static inline uint64_t CVMX_SLI_PKTX_INT_LEVELS(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000014400ull) + ((offset) & 63) * 16;
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
 				return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + ((offset) & 127) * 0x20000ull;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 63))
+				return CVMX_ADD_IO_SEG(0x00011F0000014400ull) + ((offset) & 63) * 16;
+			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_INT_LEVELS (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + ((offset) & 127) * 0x20000ull;
@@ -1079,11 +1112,11 @@ static inline uint64_t CVMX_SLI_PKTX_INT_LEVELS(unsigned long offset)
 static inline uint64_t CVMX_SLI_PKTX_INT_LEVELS(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000014400ull) + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + (offset) * 0x20000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000014400ull) + (offset) * 16;
 	}
 	return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + (offset) * 0x20000ull;
 }
@@ -1119,15 +1152,15 @@ static inline uint64_t CVMX_SLI_PKTX_MBOX_INT(unsigned long offset)
 static inline uint64_t CVMX_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000014800ull) + ((offset) & 63) * 16;
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
 				return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 127) * 0x20000ull;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 63))
+				return CVMX_ADD_IO_SEG(0x00011F0000014800ull) + ((offset) & 63) * 16;
+			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_OUTPUT_CONTROL (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 127) * 0x20000ull;
@@ -1136,11 +1169,11 @@ static inline uint64_t CVMX_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
 static inline uint64_t CVMX_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000014800ull) + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 0x20000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000014800ull) + (offset) * 16;
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 0x20000ull;
 }
@@ -1234,6 +1267,18 @@ static inline uint64_t CVMX_SLI_PKTX_SLIST_FIFO_RSIZE(unsigned long offset)
 #define CVMX_SLI_PKTX_SLIST_FIFO_RSIZE(offset) (0x0000000000001C00ull + ((offset) & 127) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SLI_PKTX_VF_INT_SUM(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
+		cvmx_warn("CVMX_SLI_PKTX_VF_INT_SUM(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F00000100D0ull) + ((offset) & 127) * 0x20000ull;
+}
+#else
+#define CVMX_SLI_PKTX_VF_INT_SUM(offset) (CVMX_ADD_IO_SEG(0x00011F00000100D0ull) + ((offset) & 127) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_PKTX_VF_SIG(unsigned long offset)
 {
 	if (!(
@@ -1358,7 +1403,7 @@ static inline uint64_t CVMX_SLI_PKT_INPUT_CONTROL_FUNC(void)
 #define CVMX_SLI_PKT_INSTR_ENB CVMX_SLI_PKT_INSTR_ENB_FUNC()
 static inline uint64_t CVMX_SLI_PKT_INSTR_ENB_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
 		cvmx_warn("CVMX_SLI_PKT_INSTR_ENB not supported on this chip\n");
 	return 0x0000000000001000ull;
 }
@@ -1366,17 +1411,6 @@ static inline uint64_t CVMX_SLI_PKT_INSTR_ENB_FUNC(void)
 #define CVMX_SLI_PKT_INSTR_ENB (0x0000000000001000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_SLI_PKT_INSTR_ENB2 CVMX_SLI_PKT_INSTR_ENB2_FUNC()
-static inline uint64_t CVMX_SLI_PKT_INSTR_ENB2_FUNC(void)
-{
-	if (!(OCTEON_IS_MODEL(OCTEON_CNF75XX)))
-		cvmx_warn("CVMX_SLI_PKT_INSTR_ENB2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029008ull);
-}
-#else
-#define CVMX_SLI_PKT_INSTR_ENB2 (CVMX_ADD_IO_SEG(0x00011F0000029008ull))
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_PKT_INSTR_RD_SIZE CVMX_SLI_PKT_INSTR_RD_SIZE_FUNC()
 static inline uint64_t CVMX_SLI_PKT_INSTR_RD_SIZE_FUNC(void)
 {
@@ -1403,13 +1437,13 @@ static inline uint64_t CVMX_SLI_PKT_INSTR_SIZE_FUNC(void)
 static inline uint64_t CVMX_SLI_PKT_INT_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011160ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000029160ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000011160ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_INT not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F0000029160ull);
@@ -1419,11 +1453,11 @@ static inline uint64_t CVMX_SLI_PKT_INT_FUNC(void)
 static inline uint64_t CVMX_SLI_PKT_INT_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011160ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000029160ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000011160ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000029160ull);
 }
@@ -1485,13 +1519,13 @@ static inline uint64_t CVMX_SLI_PKT_IN_INSTR_COUNTS_FUNC(void)
 static inline uint64_t CVMX_SLI_PKT_IN_INT_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011150ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000029150ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000011150ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_IN_INT not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F0000029150ull);
@@ -1501,16 +1535,27 @@ static inline uint64_t CVMX_SLI_PKT_IN_INT_FUNC(void)
 static inline uint64_t CVMX_SLI_PKT_IN_INT_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011150ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000029150ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000011150ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000029150ull);
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_SLI_PKT_IN_JABBER CVMX_SLI_PKT_IN_JABBER_FUNC()
+static inline uint64_t CVMX_SLI_PKT_IN_JABBER_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX)))
+		cvmx_warn("CVMX_SLI_PKT_IN_JABBER not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011F0000029170ull);
+}
+#else
+#define CVMX_SLI_PKT_IN_JABBER (CVMX_ADD_IO_SEG(0x00011F0000029170ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_PKT_IN_PCIE_PORT CVMX_SLI_PKT_IN_PCIE_PORT_FUNC()
 static inline uint64_t CVMX_SLI_PKT_IN_PCIE_PORT_FUNC(void)
 {
@@ -1604,13 +1649,13 @@ static inline uint64_t CVMX_SLI_PKT_MACX_RINFO(unsigned long offset)
 static inline uint64_t CVMX_SLI_PKT_MEM_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011120ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000029120ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000011120ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_MEM_CTL not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F0000029120ull);
@@ -1620,11 +1665,11 @@ static inline uint64_t CVMX_SLI_PKT_MEM_CTL_FUNC(void)
 static inline uint64_t CVMX_SLI_PKT_MEM_CTL_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011120ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000029120ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000011120ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000029120ull);
 }
@@ -1655,7 +1700,7 @@ static inline uint64_t CVMX_SLI_PKT_OUT_BMODE_FUNC(void)
 #define CVMX_SLI_PKT_OUT_BP_EN CVMX_SLI_PKT_OUT_BP_EN_FUNC()
 static inline uint64_t CVMX_SLI_PKT_OUT_BP_EN_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN78XX)))
 		cvmx_warn("CVMX_SLI_PKT_OUT_BP_EN not supported on this chip\n");
 	return 0x0000000000001240ull;
 }
@@ -1663,37 +1708,59 @@ static inline uint64_t CVMX_SLI_PKT_OUT_BP_EN_FUNC(void)
 #define CVMX_SLI_PKT_OUT_BP_EN (0x0000000000001240ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_SLI_PKT_OUT_BP_EN2 CVMX_SLI_PKT_OUT_BP_EN2_FUNC()
-static inline uint64_t CVMX_SLI_PKT_OUT_BP_EN2_FUNC(void)
+#define CVMX_SLI_PKT_OUT_BP_EN2_W1C CVMX_SLI_PKT_OUT_BP_EN2_W1C_FUNC()
+static inline uint64_t CVMX_SLI_PKT_OUT_BP_EN2_W1C_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
-		cvmx_warn("CVMX_SLI_PKT_OUT_BP_EN2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029250ull);
+		cvmx_warn("CVMX_SLI_PKT_OUT_BP_EN2_W1C not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011F0000029290ull);
 }
 #else
-#define CVMX_SLI_PKT_OUT_BP_EN2 (CVMX_ADD_IO_SEG(0x00011F0000029250ull))
+#define CVMX_SLI_PKT_OUT_BP_EN2_W1C (CVMX_ADD_IO_SEG(0x00011F0000029290ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_SLI_PKT_OUT_ENB CVMX_SLI_PKT_OUT_ENB_FUNC()
-static inline uint64_t CVMX_SLI_PKT_OUT_ENB_FUNC(void)
+#define CVMX_SLI_PKT_OUT_BP_EN2_W1S CVMX_SLI_PKT_OUT_BP_EN2_W1S_FUNC()
+static inline uint64_t CVMX_SLI_PKT_OUT_BP_EN2_W1S_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
-		cvmx_warn("CVMX_SLI_PKT_OUT_ENB not supported on this chip\n");
-	return 0x0000000000001010ull;
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+		cvmx_warn("CVMX_SLI_PKT_OUT_BP_EN2_W1S not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011F0000029270ull);
 }
 #else
-#define CVMX_SLI_PKT_OUT_ENB (0x0000000000001010ull)
+#define CVMX_SLI_PKT_OUT_BP_EN2_W1S (CVMX_ADD_IO_SEG(0x00011F0000029270ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_SLI_PKT_OUT_BP_EN_W1C CVMX_SLI_PKT_OUT_BP_EN_W1C_FUNC()
+static inline uint64_t CVMX_SLI_PKT_OUT_BP_EN_W1C_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+		cvmx_warn("CVMX_SLI_PKT_OUT_BP_EN_W1C not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011F0000029280ull);
+}
+#else
+#define CVMX_SLI_PKT_OUT_BP_EN_W1C (CVMX_ADD_IO_SEG(0x00011F0000029280ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_SLI_PKT_OUT_BP_EN_W1S CVMX_SLI_PKT_OUT_BP_EN_W1S_FUNC()
+static inline uint64_t CVMX_SLI_PKT_OUT_BP_EN_W1S_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+		cvmx_warn("CVMX_SLI_PKT_OUT_BP_EN_W1S not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011F0000029260ull);
+}
+#else
+#define CVMX_SLI_PKT_OUT_BP_EN_W1S (CVMX_ADD_IO_SEG(0x00011F0000029260ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_SLI_PKT_OUT_ENB2 CVMX_SLI_PKT_OUT_ENB2_FUNC()
-static inline uint64_t CVMX_SLI_PKT_OUT_ENB2_FUNC(void)
+#define CVMX_SLI_PKT_OUT_ENB CVMX_SLI_PKT_OUT_ENB_FUNC()
+static inline uint64_t CVMX_SLI_PKT_OUT_ENB_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CNF75XX)))
-		cvmx_warn("CVMX_SLI_PKT_OUT_ENB2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029018ull);
+	if (!(OCTEON_IS_MODEL(OCTEON_CN61XX) || OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX) || OCTEON_IS_MODEL(OCTEON_CN68XX) || OCTEON_IS_MODEL(OCTEON_CN70XX) || OCTEON_IS_MODEL(OCTEON_CN78XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)))
+		cvmx_warn("CVMX_SLI_PKT_OUT_ENB not supported on this chip\n");
+	return 0x0000000000001010ull;
 }
 #else
-#define CVMX_SLI_PKT_OUT_ENB2 (CVMX_ADD_IO_SEG(0x00011F0000029018ull))
+#define CVMX_SLI_PKT_OUT_ENB (0x0000000000001010ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_PKT_PCIE_PORT CVMX_SLI_PKT_PCIE_PORT_FUNC()
@@ -1707,6 +1774,17 @@ static inline uint64_t CVMX_SLI_PKT_PCIE_PORT_FUNC(void)
 #define CVMX_SLI_PKT_PCIE_PORT (0x00000000000010E0ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_SLI_PKT_PKIND_VALID CVMX_SLI_PKT_PKIND_VALID_FUNC()
+static inline uint64_t CVMX_SLI_PKT_PKIND_VALID_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX)))
+		cvmx_warn("CVMX_SLI_PKT_PKIND_VALID not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011F0000029190ull);
+}
+#else
+#define CVMX_SLI_PKT_PKIND_VALID (CVMX_ADD_IO_SEG(0x00011F0000029190ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_PKT_PORT_IN_RST CVMX_SLI_PKT_PORT_IN_RST_FUNC()
 static inline uint64_t CVMX_SLI_PKT_PORT_IN_RST_FUNC(void)
 {
@@ -1722,13 +1800,13 @@ static inline uint64_t CVMX_SLI_PKT_PORT_IN_RST_FUNC(void)
 static inline uint64_t CVMX_SLI_PKT_RING_RST_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000111E0ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F00000291E0ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F00000111E0ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_RING_RST not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F00000291E0ull);
@@ -1738,11 +1816,11 @@ static inline uint64_t CVMX_SLI_PKT_RING_RST_FUNC(void)
 static inline uint64_t CVMX_SLI_PKT_RING_RST_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000111E0ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F00000291E0ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F00000111E0ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011F00000291E0ull);
 }
@@ -1829,13 +1907,13 @@ static inline uint64_t CVMX_SLI_PP_PKT_CSR_CONTROL_FUNC(void)
 static inline uint64_t CVMX_SLI_S2C_END_MERGE_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000015000ull);
-			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000025000ull);
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000015000ull);
+			break;
 	}
 	cvmx_warn("CVMX_SLI_S2C_END_MERGE not supported on this chip\n");
 	return CVMX_ADD_IO_SEG(0x00011F0000025000ull);
@@ -1845,11 +1923,11 @@ static inline uint64_t CVMX_SLI_S2C_END_MERGE_FUNC(void)
 static inline uint64_t CVMX_SLI_S2C_END_MERGE_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000015000ull);
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00011F0000025000ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000015000ull);
 	}
 	return CVMX_ADD_IO_SEG(0x00011F0000025000ull);
 }
@@ -2769,7 +2847,7 @@ typedef union cvmx_sli_ciu_int_sum cvmx_sli_ciu_int_sum_t;
  * cvmx_sli_ctl_port#
  *
  * These registers contains control information for access to ports.
- *
+ * Note: SLI_CTL_PORT0 controls PF0 and PF1
  */
 union cvmx_sli_ctl_portx {
 	uint64_t u64;
@@ -3021,8 +3099,12 @@ union cvmx_sli_ctl_status {
 	struct cvmx_sli_ctl_status_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t m2s1_ncbi                    : 4;  /**< Contains the IOBI that traffic from M2S1 is placed on. Values 2-15 are reserved. */
-	uint64_t m2s0_ncbi                    : 4;  /**< Contains the IOBI that traffic from M2S0 is placed on. Values 2-15 are reserved. */
+	uint64_t m2s1_ncbi                    : 4;  /**< Contains the IOBI that traffic (inbound BAR1/BAR2 posted writes, inbound BAR1/BAR2
+                                                         non-posted reads, outbound BAR1/BAR2 completions, and inbound CPU completions)
+                                                         from MAC2 and MAC3 is placed on. Values 2-15 are reserved. */
+	uint64_t m2s0_ncbi                    : 4;  /**< Contains the IOBI that traffic  (inbound BAR1/BAR2 posted writes, inbound BAR1/BAR2
+                                                         non-posted reads, outbound BAR1/BAR2 completions, and inbound CPU completions)
+                                                         from MAC0 and MAC1 is placed on.  Values 2-15 are reserved. */
 	uint64_t reserved_20_23               : 4;
 	uint64_t p1_ntags                     : 6;  /**< Number of tags available for MAC port 1.
                                                          In RC mode, one tag is needed for each outbound TLP that requires a CPL TLP.
@@ -3050,7 +3132,7 @@ union cvmx_sli_ctl_status {
 	struct cvmx_sli_ctl_status_s          cn78xx;
 	struct cvmx_sli_ctl_status_s          cn78xxp2;
 	struct cvmx_sli_ctl_status_cn61xx     cnf71xx;
-	struct cvmx_sli_ctl_status_s          cnf75xx;
+	struct cvmx_sli_ctl_status_cn73xx     cnf75xx;
 };
 typedef union cvmx_sli_ctl_status cvmx_sli_ctl_status_t;
 
@@ -5566,48 +5648,24 @@ union cvmx_sli_macx_pfx_dma_vf_int {
 typedef union cvmx_sli_macx_pfx_dma_vf_int cvmx_sli_macx_pfx_dma_vf_int_t;
 
 /**
- * cvmx_sli_mac#_pf#_error_info
+ * cvmx_sli_mac#_pf#_dma_vf_int_enb
+ *
+ * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
  *
- * The fields in this register are set when an error conditions occur and can be cleared.
- * These fields are for information purpose only and do not generate interrupts.
- * A PF or VF can set bits in this information register but only a PF can read this.
- * These register are valid for these physical functions
- * PEM0 PF0, PEM0 PF1, PEM1 PF0, PEM2 PF0, PEM3 PF0,
  */
-union cvmx_sli_macx_pfx_error_info {
+union cvmx_sli_macx_pfx_dma_vf_int_enb {
 	uint64_t u64;
-	struct cvmx_sli_macx_pfx_error_info_s {
+	struct cvmx_sli_macx_pfx_dma_vf_int_enb_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_7_63                : 57;
-	uint64_t vf_error                     : 1;  /**< A VF tried to access an illegal memory location */
-	uint64_t pins_err                     : 1;  /**< Packet instruction read error. When a read error occurs on a packet instruction, this bit
-                                                         is set. */
-	uint64_t pop_err                      : 1;  /**< Packet scatter pointer pair error. When a read error occurs on a packet scatter pointer
-                                                         pair, this bit is set. */
-	uint64_t pdi_err                      : 1;  /**< Packet data read error. When a read error occurs on a packet data read, this bit is set. */
-	uint64_t pgl_err                      : 1;  /**< Packet gather list read error. When a read error occurs on a packet gather list read, this
-                                                         bit is set. */
-	uint64_t psldbof                      : 1;  /**< Packet scatter list doorbell count overflowed. Which doorbell can be found in
-                                                         DPI_PINT_INFO[PSLDBOF]. */
-	uint64_t pidbof                       : 1;  /**< When an error response is received on a PF DMA transaction read for this MAC, this bit is
-                                                         set.
-                                                         Packet instruction doorbell count overflowed. Which doorbell can be found in
-                                                         DPI_PINT_INFO[PIDBOF]. */
+	uint64_t vf_int_enb                   : 64; /**< Enables DMA interrupts for the corresponding VF. */
 #else
-	uint64_t pidbof                       : 1;
-	uint64_t psldbof                      : 1;
-	uint64_t pgl_err                      : 1;
-	uint64_t pdi_err                      : 1;
-	uint64_t pop_err                      : 1;
-	uint64_t pins_err                     : 1;
-	uint64_t vf_error                     : 1;
-	uint64_t reserved_7_63                : 57;
+	uint64_t vf_int_enb                   : 64;
 #endif
 	} s;
-	struct cvmx_sli_macx_pfx_error_info_s cn73xx;
-	struct cvmx_sli_macx_pfx_error_info_s cnf75xx;
+	struct cvmx_sli_macx_pfx_dma_vf_int_enb_s cn73xx;
+	struct cvmx_sli_macx_pfx_dma_vf_int_enb_s cnf75xx;
 };
-typedef union cvmx_sli_macx_pfx_error_info cvmx_sli_macx_pfx_error_info_t;
+typedef union cvmx_sli_macx_pfx_dma_vf_int_enb cvmx_sli_macx_pfx_dma_vf_int_enb_t;
 
 /**
  * cvmx_sli_mac#_pf#_flr_vf_int
@@ -5633,7 +5691,7 @@ typedef union cvmx_sli_macx_pfx_flr_vf_int cvmx_sli_macx_pfx_flr_vf_int_t;
  * cvmx_sli_mac#_pf#_int_enb
  *
  * Interrupt enable register for a given PF SLI_MAC()_PF()_INT_SUM register.
- * o73 valid copies are MAC0 PF0, MAC0 PF1, MAC1 PF0, MAC2 PF0, MAC3 PF3
+ * CN73XX valid copies are MAC0 PF0, MAC0 PF1, MAC1 PF0, MAC2 PF0, MAC3 PF3
  * PEM0 PF0, PEM0 PF1, PEM1 PF0, PEM2 PF0, PEM3 PF0,
  */
 union cvmx_sli_macx_pfx_int_enb {
@@ -5716,7 +5774,7 @@ typedef union cvmx_sli_macx_pfx_int_enb cvmx_sli_macx_pfx_int_enb_t;
  * cvmx_sli_mac#_pf#_int_sum
  *
  * Interrupt summary register for a given PF.
- * o73 valid copies are MAC0 PF0, MAC0 PF1, MAC1 PF0, MAC2 PF0, MAC3 PF3
+ * CN73XX valid copies are MAC0 PF0, MAC0 PF1, MAC1 PF0, MAC2 PF0, MAC3 PF0
  * The fields in this register are set when an interrupt condition occurs; write 1 to clear.
  * These register are valid for these physical functions
  * PEM0 PF0, PEM0 PF1, PEM1 PF0, PEM2 PF0, PEM3 PF0,
@@ -5730,14 +5788,18 @@ union cvmx_sli_macx_pfx_int_sum {
                                                          A subsequent read to SLI_MAC()_PF()_PP_VF_INT is required to discover which VF.
                                                          Note: this will only be set for SRIOV PF's PEM0 PF0 PF1 PEM2 PF0 */
 	uint64_t pktpf_err                    : 1;  /**< This bit is set when any of the following events occur
-                                                         1) An error response is received for PF packet transaction read
+                                                         1) An error response is received for PF packet transaction read.
                                                          2) A doorbell overflow for a ring associated with this PF occurs in
-                                                            SLI_PKT()_INSTR_BAOFF_DBELL or SLI_PKT()_SLIST_BAOFF_DBELL. */
+                                                            SLI_PKT()_INSTR_BAOFF_DBELL or SLI_PKT()_SLIST_BAOFF_DBELL.
+                                                         3) A packet was receveived from PKO for ring X, SLI_PKT_GBL_CONTROL[NOPTR_D] = 0
+                                                            and SLI_PKTX_SLIST_BAOFF_DBELL[DBELL] = 0. */
 	uint64_t pktvf_err                    : 1;  /**< This bit is set when any of the following events occur
-                                                         1) An error response is received for VF packet transaction read
+                                                         1) An error response is received for VF packet transaction read.
                                                          2) A doorbell overflow for a ring associated with a VF occurs in
                                                             SLI_PKT()_INSTR_BAOFF_DBELL or SLI_PKT()_SLIST_BAOFF_DBELL.
-                                                         3) An illegal memory access from a VF occurs
+                                                         3) A packet was receveived from PKO for ring X, SLI_PKT_GBL_CONTROL[NOPTR_D] = 0
+                                                            and SLI_PKTX_SLIST_BAOFF_DBELL[DBELL] = 0.
+                                                         4) An illegal bar0 bar1 bar2 memory access from a VF occurs.
                                                          A subsequent read to SLI_MAC()_PF()_PKT_VF_INT is required to discover which VF.
                                                          Note: this will only be set for SRIOV PF's PEM0 PF0 PF1 PEM2 PF0 */
 	uint64_t dmapf_err                    : 1;  /**< When an error response is received for a PF DMA transcation read, this bit is set. */
@@ -5780,11 +5842,11 @@ union cvmx_sli_macx_pfx_int_sum {
                                                          for legacy code.
                                                          Packet counter has an interrupt. The specific rings can be found in SLI_PKT_CNT_INT. */
 	uint64_t reserved_2_3                 : 2;
-	uint64_t mio_int                      : 1;  /**< Interrupt from MIO for this PF. */
+	uint64_t mio_int                      : 1;  /**< Interrupt from CIU for this PF. Each PF has a seperate interrupt from CIU, except MAC 0
+                                                         PF0 and PF1
+                                                         which share a common interrupts from CIU, */
 	uint64_t rml_to                       : 1;  /**< A read or write transfer to a RSL that did not complete within
-                                                         SLI_WINDOW_CTL[TIME] coprocessor-clock cycles, or a notification from the CCPI
-                                                         that is has sent a previously written command and can take another within
-                                                         SLI_WINDOW_CTL[OCX_TIME]. */
+                                                         SLI_WINDOW_CTL[TIME] coprocessor-clock cycles. */
 #else
 	uint64_t rml_to                       : 1;
 	uint64_t mio_int                      : 1;
@@ -5818,17 +5880,18 @@ typedef union cvmx_sli_macx_pfx_int_sum cvmx_sli_macx_pfx_int_sum_t;
 /**
  * cvmx_sli_mac#_pf#_mbox_int
  *
- * When an VF wants to communicate to a PF it writes its SLI_PKT_PF_MBOX_SIG2 register
- * the appropriate VF indexed bit is set.  The appropriate PF should read the appropriate
- * register.
+ * When an VF wants to communicate to a PF it writes its SLI_PKT(0..63)_PF_VF_MBOX_SIG(0..1)
+ * register the appropriate Ring indexed bit is set.  The PF should then read the appropriate
+ * SLI_PKT()_PF_VF_MBOX_SIG() indexed register.
  * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
  */
 union cvmx_sli_macx_pfx_mbox_int {
 	uint64_t u64;
 	struct cvmx_sli_macx_pfx_mbox_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t vf_int                       : 64; /**< When an VF wants to communicate to a PF it writes its SLI_PKT_PF_MBOX_SIG2 register
-                                                         the appropriate VF indexed bit is set. */
+	uint64_t vf_int                       : 64; /**< When an VF wants to communicate to a PF it writes its SLI_PKT(0..63)_PF_VF_MBOX_SIG(0..1)
+                                                         register the appropriate ring indexed bit is set.  The PF should then read  the
+                                                         appropriate SLI_PKT()_PF_VF_MBOX_SIG() indexed register. */
 #else
 	uint64_t vf_int                       : 64;
 #endif
@@ -5864,6 +5927,26 @@ union cvmx_sli_macx_pfx_pkt_vf_int {
 typedef union cvmx_sli_macx_pfx_pkt_vf_int cvmx_sli_macx_pfx_pkt_vf_int_t;
 
 /**
+ * cvmx_sli_mac#_pf#_pkt_vf_int_enb
+ *
+ * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ *
+ */
+union cvmx_sli_macx_pfx_pkt_vf_int_enb {
+	uint64_t u64;
+	struct cvmx_sli_macx_pfx_pkt_vf_int_enb_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t vf_int_enb                   : 64; /**< Enables PKT interrupts for the corresponding VF. */
+#else
+	uint64_t vf_int_enb                   : 64;
+#endif
+	} s;
+	struct cvmx_sli_macx_pfx_pkt_vf_int_enb_s cn73xx;
+	struct cvmx_sli_macx_pfx_pkt_vf_int_enb_s cnf75xx;
+};
+typedef union cvmx_sli_macx_pfx_pkt_vf_int_enb cvmx_sli_macx_pfx_pkt_vf_int_enb_t;
+
+/**
  * cvmx_sli_mac#_pf#_pp_vf_int
  *
  * When an error response is received for a VF PP transaction read, the appropriate VF indexed
@@ -5887,6 +5970,26 @@ union cvmx_sli_macx_pfx_pp_vf_int {
 typedef union cvmx_sli_macx_pfx_pp_vf_int cvmx_sli_macx_pfx_pp_vf_int_t;
 
 /**
+ * cvmx_sli_mac#_pf#_pp_vf_int_enb
+ *
+ * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ *
+ */
+union cvmx_sli_macx_pfx_pp_vf_int_enb {
+	uint64_t u64;
+	struct cvmx_sli_macx_pfx_pp_vf_int_enb_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t vf_int_enb                   : 64; /**< Enables PP interrupts for the corresponding VF. */
+#else
+	uint64_t vf_int_enb                   : 64;
+#endif
+	} s;
+	struct cvmx_sli_macx_pfx_pp_vf_int_enb_s cn73xx;
+	struct cvmx_sli_macx_pfx_pp_vf_int_enb_s cnf75xx;
+};
+typedef union cvmx_sli_macx_pfx_pp_vf_int_enb cvmx_sli_macx_pfx_pp_vf_int_enb_t;
+
+/**
  * cvmx_sli_mac_credit_cnt
  *
  * This register contains the number of credits for the MAC port FIFOs used by the SLI. This
@@ -6111,22 +6214,31 @@ union cvmx_sli_mem_access_subidx {
 	struct cvmx_sli_mem_access_subidx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
-	uint64_t pvf                          : 16; /**< Virtual function. */
+	uint64_t pvf                          : 16; /**< Selects the function number accessed by the reads/writes/atomics. DPI_DMA_FUNC_SEL_S
+                                                         describes the format of this field. If [PVF]!=0, [PORT] must select a PCIe MAC that
+                                                         supports more than one physical function and/or must select a PCIe MAC
+                                                         with SR-IOV enabled. */
 	uint64_t reserved_43_43               : 1;
 	uint64_t zero                         : 1;  /**< Causes all byte read operations to be zero-length read operations. Returns 0s to the EXEC
                                                          for all read data. */
-	uint64_t port                         : 3;  /**< The MAC that reads/writes to this subid are sent. */
-	uint64_t nmerge                       : 1;  /**< When set, no merging is allowed in this window. */
+	uint64_t port                         : 3;  /**< The MAC that the reads/writes/atomics are sent to. */
+	uint64_t nmerge                       : 1;  /**< When set, no merging is allowed in this window. Applicable to writes only. */
 	uint64_t esr                          : 2;  /**< Endian swap for read operations. ES<1:0> for read operations to this subID. ES<1:0> is the
-                                                         endian-swap attribute for these MAC memory space read operations. */
+                                                         endian-swap attribute for these MAC memory space read operations. Not used for write or
+                                                         atomic operations.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t esw                          : 2;  /**< Endian swap for write operations. ES<1:0> for write operations to this subID. ES<1:0> is
-                                                         the endian-swap attribute for these MAC memory space write operations. */
+                                                         the endian-swap attribute for these MAC memory space write operations. Not used for reads
+                                                         and IOBDMAs.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t wtype                        : 2;  /**< Write type. ADDRTYPE<1:0> for write operations to this subID.
                                                          * ADDRTYPE<0> is the relaxed-order attribute.
-                                                         * ADDRTYPE<1> is the no-snoop attribute. */
+                                                         * ADDRTYPE<1> is the no-snoop attribute.
+                                                         Not used for reads and IOBDMAs. */
 	uint64_t rtype                        : 2;  /**< Read type. ADDRTYPE<1:0> for read operations to this subID.
                                                          * ADDRTYPE<0> is the relaxed-order attribute.
-                                                         * ADDRTYPE<1> is the no-snoop attribute. */
+                                                         * ADDRTYPE<1> is the no-snoop attribute.
+                                                         Not used for writes and atomics. */
 	uint64_t reserved_0_29                : 30;
 #else
 	uint64_t reserved_0_29                : 30;
@@ -6235,25 +6347,32 @@ union cvmx_sli_mem_access_subidx {
 	struct cvmx_sli_mem_access_subidx_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
-	uint64_t pvf                          : 16; /**< The function number that the ring belongs to, where <15:13> selects the PF the
-                                                         VF belongs to, and <12:0> selects the VF within that PF (or 0x0 for the PF
-                                                         itself). */
+	uint64_t pvf                          : 16; /**< Selects the function number accessed by the reads/writes/atomics. DPI_DMA_FUNC_SEL_S
+                                                         describes the format of this field. If [PVF]!=0, [PORT] must select a PCIe MAC that
+                                                         supports more than one physical function and/or must select a PCIe MAC
+                                                         with SR-IOV enabled. */
 	uint64_t reserved_43_43               : 1;
 	uint64_t zero                         : 1;  /**< Causes all byte read operations to be zero-length read operations. Returns 0s to the EXEC
                                                          for all read data. */
-	uint64_t port                         : 3;  /**< The MAC that reads/writes to this subid are sent. */
-	uint64_t nmerge                       : 1;  /**< When set, no merging is allowed in this window. */
+	uint64_t port                         : 3;  /**< The MAC that the reads/writes/atomics are sent to. */
+	uint64_t nmerge                       : 1;  /**< When set, no merging is allowed in this window. Applicable to writes only. */
 	uint64_t esr                          : 2;  /**< Endian swap for read operations. ES<1:0> for read operations to this subID. ES<1:0> is the
-                                                         endian-swap attribute for these MAC memory space read operations. */
+                                                         endian-swap attribute for these MAC memory space read operations. Not used for write or
+                                                         atomic operations.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t esw                          : 2;  /**< Endian swap for write operations. ES<1:0> for write operations to this subID. ES<1:0> is
-                                                         the endian-swap attribute for these MAC memory space write operations. */
+                                                         the endian-swap attribute for these MAC memory space write operations. Not used for reads
+                                                         and IOBDMAs.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t wtype                        : 2;  /**< Write type. ADDRTYPE<1:0> for write operations to this subID.
                                                          * ADDRTYPE<0> is the relaxed-order attribute.
-                                                         * ADDRTYPE<1> is the no-snoop attribute. */
+                                                         * ADDRTYPE<1> is the no-snoop attribute.
+                                                         Not used for reads and IOBDMAs. */
 	uint64_t rtype                        : 2;  /**< Read type. ADDRTYPE<1:0> for read operations to this subID.
                                                          * ADDRTYPE<0> is the relaxed-order attribute.
-                                                         * ADDRTYPE<1> is the no-snoop attribute. */
-	uint64_t ba                           : 30; /**< Bus address. Address bits<63:34> for read/write operations that use this subID. */
+                                                         * ADDRTYPE<1> is the no-snoop attribute.
+                                                         Not used for writes and atomics. */
+	uint64_t ba                           : 30; /**< Bus address. Address bits<63:34> for read/write/atomic operations. */
 #else
 	uint64_t ba                           : 30;
 	uint64_t rtype                        : 2;
@@ -6934,34 +7053,39 @@ typedef union cvmx_sli_msi_wr_map cvmx_sli_msi_wr_map_t;
  * The MSI-X table must be addressed on a 8-byte aligned boundary and cannot be burst read or
  * written.
  *
- * The MSI-X Table is 65 entries deep. Each MAC can see up to 64 VF ring entries and its own PF
- * entry. The first 64 entries contain MSI-X vectors for each of the 64 DPI packet rings.
- * Entries, or rings, are assigned to PEM0 and/or PEM2 based on the SRN, RPVF, and TRS fields of
- * SLI_PKT_MAC()_RINFO. Each VF has access to only its own entries and therefore sees the MSI-X
- * table as smaller than 64 entries, unless all 64 rings are assigned to it. A VF must not try to
- * configure more entries than it owns. A VF always sees its first entry as entry 0. The actual
- * MSI-X table offset is calculated as follows:   (SRN + ((VF-1) * RPVF)).
+ * The MSI-X Table is (128 + 5) entries deep. Each PF of a MAC can see up to 64 VF ring entries
+ * and its own PF entry. The (MAC0,PF0), (MAC0,PF1), (MAC1,PF0), (MAC2,PF0), and (MAC3,PF0),
+ * each can see up to 64 entries and its own PF entry.
+ * The first 128 entries contain MSI-X vectors for each of the 128 DPI packet rings.
+ * Entries, or rings, are assigned to (MAC0,PF0), (MAC0,PF1), and (MAC2,PF0) based on the SRN,
+ * RPVF,TRS. and NVFS fields of SLI_PKT_MAC()_RINFO.
+ * Each VF has access to only its own entries and therefore sees the MSI-X table as large as 8
+ * entries,
+ * A VF must not try to configure more entries than it owns. A VF always sees its first entry as
+ * entry 0.
+ * The actual MSI-X table offset is calculated as follows:   (SRN + ((VF-1) * RPVF)).
  *
  * <pre>
- *    RPVF   Rings VF believes it owns   Max VFs
+ *    RPVF   Rings VF owns               Max VFs
  *    ---    -------------------------   -------
+ *      0    0                           0
  *      1    0                           64
  *      2    0,1                         32
  *      4    0,1,2,3                     16
  *      8    0,1,2,3,4,5,6,7              8
- *     16    0,1,2,...13,14,15            4
- *     32    0,1,2,...29,30,31            2
- *     64    0,1,2,...61,62,63            1
  * </pre>
  *
  * A MAC's PF can access the entries for its VF (a total of TNR, regardless of VF Mode).
  *
- * The last (i.e. 65th) entry is for PCIe related errors and is only accessible by the
- * PF. There are actually two entries at the 65th location; one for each MAC's PF. The hardware
- * will enable writing to and reading from the appropriate entry based on the pcsr_src vector.
+ * When (TNR > 0), then the last, i.e. (TNR+1), entry is for PCIe related errors and is only
+ * accessible by the PF. When (TNR = 0), then entry 0 is of PCIe related errors and is only
+ * accessible by PF.
+ *
+ * Each MAC can access one PF. The hardware will enable writing to and reading from the
+ * appropriate entry based on the pcsr_src vector.
  *
- * In PF mode, there is no virtual function support, but a PF can configure up to 65 entries
- * (up to 64 VF rings + 1 PF ring) for itself.
+ * In non SRIO-V mode, there is no virtual function support, but a PF can configure up to 65
+ * entries (up to 64 VF rings + 1 PF ring) for itself.
  */
 union cvmx_sli_msixx_table_addr {
 	uint64_t u64;
@@ -7052,14 +7176,10 @@ typedef union cvmx_sli_msix_macx_pf_table_data cvmx_sli_msix_macx_pf_table_data_
 /**
  * cvmx_sli_msix_pba0
  *
- * "The MSI-X Pending Bit Array must be addressed on a 8-byte aligned boundary and
+ * The MSI-X Pending Bit Array must be addressed on a 8-byte aligned boundary and
  * cannot be burst read.
- * In VF Mode, a PF will find its error interrupt in bit position 0. Bits [63:1]
- * are returned as zero.
- *
- * A VF will find its pending completion interrupts (one for each of the configured
- * (up to 64) DPI Packet Rings) in bit positions [(RPVF-1):0]. If RPVF<64, bits [63:RPVF]
- * are returned as zero.
+ * In SRIO-V Mode, a VF will find its pending completion interrupts in bit
+ * positions [(RPVF-1):0]. If RPVF<64, bits [63:RPVF] are returned as zero.
  *
  * Each VF can read their own pending completion interrupts based on the ring/VF
  * configuration. Therefore, a VF sees the PBA as smaller than what is shown below
@@ -7068,26 +7188,24 @@ typedef union cvmx_sli_msix_macx_pf_table_data cvmx_sli_msix_macx_pf_table_data_
  * <pre>
  *    RPVF  Interrupts per VF   Pending bits returned
  *    ----  -----------------   ---------------------
+ *      0            0          0
  *      1            1          MSG_PND0
  *      2            2          MSG_PND1  - MSG_PND0
  *      4            4          MSG_PND3  - MSG_PND0
  *      8            8          MSG_PND7  - MSG_PND0
- *     16           16          MSG_PND15 - MSG_PND0
- *     32           32          MSG_PND31 - MSG_PND0
- *     64           64          MSG_PND63 - MSG_PND0
  * </pre>
  *
- * In PF Mode there is no virtual function support, but the PF can configure up to 65
- * entries (up to 64 DPI Packet Rings plus 1 PF ring) for itself.
- *
- * In PF Mode, if SLI_PEM()_TNR=63 (i.e. 64 total DPI Packet Rings configured), a PF will
+ * If SLI_PEM()_TNR=63 (i.e. 64 total DPI Packet Rings configured), a PF will
  * find its pending completion interrupts in bit positions [63:0]. When SLI_PEM()_TNR=63,
  * the PF will find its PCIe error interrupt in SLI_MSIX_PBA1, bit position 0.
  *
- * If SLI_PEM()_TNR<63 (i.e. 1, 2, 4, 8, 16, or 32 rings configured), a PF will find its
+ * If SLI_PEM()_TNR<63 (i.e. 0, 1, 2, 4, or 8 rings configured), a PF will find its
  * ring pending completion interrupts in bit positions [TNR:0]. It will find its PCIe
  * error interrupt in bit position [(TNR+1)]. Bits [63:(TNR+2)] are returned as zero.
- * When SLI_PEM()_TNR<63 in PF Mode, SLI_MSIX_PBA1 is not used and returns zeros."
+ * When SLI_PEM()_TNR<63, SLI_MSIX_PBA1 is not used and returns zeros."
+ *
+ * If SRIO-V Mode is off there is no virtual function support, but the PF can configure up to 65
+ * entries (up to 64 DPI Packet Rings plus 1 PF ring) for itself.
  */
 union cvmx_sli_msix_pba0 {
 	uint64_t u64;
@@ -7111,12 +7229,12 @@ typedef union cvmx_sli_msix_pba0 cvmx_sli_msix_pba0_t;
  * The MSI-X pending bit array must be addressed on a 8-byte aligned boundary and cannot be
  * burst read.
  *
- * PF_PND is assigned to PCIe related errors. The error bit is only be found in PBA1 when the MAC
- * is in PF Mode (i.e. no virtualization) and SLI_PEM()_TNR=63 (i.e. 64 total DPI Packet Rings
- * configured).
+ * PF_PND is assigned to PCIe related errors. The error bit can only be found in PBA1 when
+ * SLI_PEM()_TNR=63 (i.e. 64 total DPI Packet Rings configured).
  *
- * This register is accessible by the PF; a VF read returns zeros. A read by a particular PF only
- * returns its own pending status. That is, both PFs read this register, but the hardware ensures
+ * This register is accessible by the PF. A read by a particular PF only
+ * returns its own pending status. That is, any PF can read this register, but the hardware
+ * ensures
  * that the PF only sees its own status.
  */
 union cvmx_sli_msix_pba1 {
@@ -7140,7 +7258,7 @@ typedef union cvmx_sli_msix_pba1 cvmx_sli_msix_pba1_t;
 /**
  * cvmx_sli_nqm_rsp_err_snd_dbg
  *
- * INTERNAL: This register is only for Cavium Debug and need not be listed in the HRM.
+ * This register is for diagnostic use only.
  *
  */
 union cvmx_sli_nqm_rsp_err_snd_dbg {
@@ -7148,7 +7266,7 @@ union cvmx_sli_nqm_rsp_err_snd_dbg {
 	struct cvmx_sli_nqm_rsp_err_snd_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t vf_index                     : 12; /**< On The SLI NQM_RSP_ERR interface, force send this vf_index. For diagnostic use only. */
+	uint64_t vf_index                     : 12; /**< On the SLI NQM_RSP_ERR interface, force-send this vf_index. For diagnostic use only. */
 #else
 	uint64_t vf_index                     : 12;
 	uint64_t reserved_12_63               : 52;
@@ -7328,9 +7446,13 @@ union cvmx_sli_pktx_cnts {
                                                          SLI_PKT_CNT_INT (SLI_PKT_TIME_INT) shows the [CNT] ([TIMER]) component
                                                          for this and all other rings. See also SLI_PKT_IN_DONE()_CNTS[PO_INT]. */
 	uint64_t pi_int                       : 1;  /**< Packet input interrupt bit for the ring. A copy of SLI_PKT_IN_DONE()_CNTS[PI_INT]. */
-	uint64_t mbox_int                     : 1;  /**< Returns a 1 when corresponding bit in SLI_PKT()_MBOX_INT is set */
+	uint64_t mbox_int                     : 1;  /**< Reads corresponding bit in SLI_PKT()_MBOX_INT. */
 	uint64_t resend                       : 1;  /**< A write of 1 will resend an MSI-X interrupt message if there is a pending interrupt in
-                                                         P0_INT, PI_INT or MBOX_INT for this ring. */
+                                                         P0_INT, PI_INT or MBOX_INT for this ring after the write of [CNT] occurs.
+                                                         [RESEND] and [CNT] must be written together with the assumption that the write of
+                                                         [CNT] will clear the [PO_INT] interrupt bit. If the write of [CNT] does not cause
+                                                         the [CNT] to drop below the thresholds another MSI-X message will be sent.
+                                                         The [RESEND] bit will never effect INTA/B/C/D or MSI interrupt. */
 	uint64_t reserved_54_59               : 6;
 	uint64_t timer                        : 22; /**< Timer, incremented every 1024 coprocessor-clock cycles when [CNT] is
                                                          not zero. The hardware clears both [TIMER] and [PO_INT] when [CNT]
@@ -7448,6 +7570,75 @@ union cvmx_sli_pktx_cnts {
 typedef union cvmx_sli_pktx_cnts cvmx_sli_pktx_cnts_t;
 
 /**
+ * cvmx_sli_pkt#_error_info
+ *
+ * The fields in this register are set when an error conditions occur and can be cleared.
+ * These fields are for information purpose only and do NOT generate interrupts.
+ */
+union cvmx_sli_pktx_error_info {
+	uint64_t u64;
+	struct cvmx_sli_pktx_error_info_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_8_63                : 56;
+	uint64_t osize_err                    : 1;  /**< A VF created a bad instruction that caused a gather inbound packet to exceed
+                                                         64K bytes. */
+	uint64_t nobdell_err                  : 1;  /**< A VF has no slists doorbell pointers for an outbound packet that is ready
+                                                         to be sent. */
+	uint64_t pins_err                     : 1;  /**< Packet instruction read error. When a read error occurs on a packet instruction, this bit
+                                                         is set. */
+	uint64_t pop_err                      : 1;  /**< Packet scatter pointer pair error. When a read error occurs on a packet scatter pointer
+                                                         pair, this bit is set. */
+	uint64_t pdi_err                      : 1;  /**< Packet data read error. When a read error occurs on a packet data read, this bit is set. */
+	uint64_t pgl_err                      : 1;  /**< Packet gather list read error. When a read error occurs on a packet gather list read, this
+                                                         bit is set. */
+	uint64_t psldbof                      : 1;  /**< Packet scatter list doorbell count overflowed. Which doorbell can be found in
+                                                         DPI_PINT_INFO[PSLDBOF]. */
+	uint64_t pidbof                       : 1;  /**< Packet instruction doorbell count overflowed. Which doorbell can be found in
+                                                         DPI_PINT_INFO[PIDBOF]. */
+#else
+	uint64_t pidbof                       : 1;
+	uint64_t psldbof                      : 1;
+	uint64_t pgl_err                      : 1;
+	uint64_t pdi_err                      : 1;
+	uint64_t pop_err                      : 1;
+	uint64_t pins_err                     : 1;
+	uint64_t nobdell_err                  : 1;
+	uint64_t osize_err                    : 1;
+	uint64_t reserved_8_63                : 56;
+#endif
+	} s;
+	struct cvmx_sli_pktx_error_info_s     cn73xx;
+	struct cvmx_sli_pktx_error_info_cnf75xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_7_63                : 57;
+	uint64_t nobdell_err                  : 1;  /**< A VF has no slists doorbell pointers for an outbound packet that is ready
+                                                         to be sent. */
+	uint64_t pins_err                     : 1;  /**< Packet instruction read error. When a read error occurs on a packet instruction, this bit
+                                                         is set. */
+	uint64_t pop_err                      : 1;  /**< Packet scatter pointer pair error. When a read error occurs on a packet scatter pointer
+                                                         pair, this bit is set. */
+	uint64_t pdi_err                      : 1;  /**< Packet data read error. When a read error occurs on a packet data read, this bit is set. */
+	uint64_t pgl_err                      : 1;  /**< Packet gather list read error. When a read error occurs on a packet gather list read, this
+                                                         bit is set. */
+	uint64_t psldbof                      : 1;  /**< Packet scatter list doorbell count overflowed. Which doorbell can be found in
+                                                         DPI_PINT_INFO[PSLDBOF]. */
+	uint64_t pidbof                       : 1;  /**< Packet instruction doorbell count overflowed. Which doorbell can be found in
+                                                         DPI_PINT_INFO[PIDBOF]. */
+#else
+	uint64_t pidbof                       : 1;
+	uint64_t psldbof                      : 1;
+	uint64_t pgl_err                      : 1;
+	uint64_t pdi_err                      : 1;
+	uint64_t pop_err                      : 1;
+	uint64_t pins_err                     : 1;
+	uint64_t nobdell_err                  : 1;
+	uint64_t reserved_7_63                : 57;
+#endif
+	} cnf75xx;
+};
+typedef union cvmx_sli_pktx_error_info cvmx_sli_pktx_error_info_t;
+
+/**
  * cvmx_sli_pkt#_in_bp
  *
  * "SLI_PKT[0..31]_IN_BP = SLI Packet ring# Input Backpressure
@@ -7496,33 +7687,38 @@ union cvmx_sli_pktx_input_control {
 	uint64_t u64;
 	struct cvmx_sli_pktx_input_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_31_63               : 33;
+	uint64_t reserved_55_63               : 9;
+	uint64_t rpvf                         : 7;  /**< The number of rings assigned to this VF.
+                                                         Read only copy of SLI_PKT_MAC(0..3)_PF(0..1)_RINFO[RPVF] */
+	uint64_t reserved_31_47               : 17;
 	uint64_t mac_num                      : 2;  /**< The MAC (PEM) that the physical function belongs to. Legal value are 0-3.
                                                          [MAC_NUM] is RO when accessed via BAR0 of a virtual function, and R/W otherwise.
-                                                         [MAC_NUM] applies to both this input ring and to the output ring of the same
-                                                         index. */
-	uint64_t quiet                        : 1;  /**< Asserted when ring is not processing any packet data, instuctions, or gather lists. */
+                                                         [MAC_NUM] applies to the ring pair, which includes both this input
+                                                         ring and to the output ring of the same index. */
+	uint64_t quiet                        : 1;  /**< Asserted after a rings has gone into reset and the the ring has met the conditions
+                                                         of SLI_PKT_GBL_CONTROL[QTIME]. */
 	uint64_t reserved_27_27               : 1;
-	uint64_t rdsize                       : 2;  /**< Number of instructions to be read in one MAC read request for the 4 ports, 16 rings. Two
-                                                         bit value are:
+	uint64_t rdsize                       : 2;  /**< Number of instructions to be read in one MAC read request. Two bit value are:
                                                          0x0 = 1 Instruction.
                                                          0x1 = 2 Instructions.
                                                          0x2 = 3 Instructions.
                                                          0x3 = 4 Instructions. */
-	uint64_t is_64b                       : 1;  /**< When IS_64B=1, instruction input ring i uses 64B. */
+	uint64_t is_64b                       : 1;  /**< When IS_64B=1, instruction input ring i uses 64B versus 32B. */
 	uint64_t rst                          : 1;  /**< Packet reset. When [RST]=1, the rings are in reset. [RST] can be set
                                                          by software writing a 1 to the field, by hardware upon receipt of an
                                                          FLR to an associated function, or by hardware when it receives an error
                                                          response for a read associated with the rings.
-                                                         [MAC_NUM] applies to both this input ring and to the output ring of the same
+                                                         [RST] applies to both this input ring and to the output ring of the same
                                                          index.
-                                                         Software should not clear [RST] from 1->0 until [RST] has been asserted
-                                                         for at least 2ms. A ring reset may clear all state associated with the
-                                                         input and output rings, so software must completely re-initialize both
+                                                         Software canot clear [RST] from 1->0 until the [QUIET] bit is a 1.
+                                                         A ring reset may clear all state associated with the input and
+                                                         output rings, so software must completely re-initialize both
                                                          before reusing them.
                                                          See also SLI_PKT_RING_RST[RST]. */
 	uint64_t enb                          : 1;  /**< Enable for the input ring i. Whenever [RST] is set, hardware forces
-                                                         [ENB] clear.
+                                                         [ENB] clear.  Software can only write [ENB] to 1.  [ENB] can only be cleared
+                                                         only by writing SLI_PKT()_INPUT_CONTROL[RST].  Once [ENB] is cleared software can
+                                                         only write [ENB] to a 1 once [QUIET] is a 1.
                                                          In the PF, [ENB] is also SLI_PKT_INSTR_ENB<i>. */
 	uint64_t pbp_dhi                      : 13; /**< Not used by hardware, but may be cleared by hardware when [RST] is set. */
 	uint64_t d_nsr                        : 1;  /**< If [USE_CSR]=1, [D_NSR] is ADDRTYPE<1> for First Direct and Gather DPTR
@@ -7532,6 +7728,7 @@ union cvmx_sli_pktx_input_control {
                                                          (DPTR Format 1) */
 	uint64_t d_esr                        : 2;  /**< If [USE_CSR]=1, [D_ESR] is ES<1:0> for First Direct and Gather DPTR reads.
                                                          ES<1:0> is the endian-swap attribute for these MAC memory space reads.
+                                                         Enumerated by SLI_ENDIANSWAP_E.
                                                          (DPTR Format 0)
                                                          If [USE_CSR]=0, [D_NSR] is MACADD<63:62> for First Direct and Gather DPTR
                                                          reads. (ES<1:0> comes from DPTR<63:62> in these cases when [USE_CSR]=0.)
@@ -7550,7 +7747,8 @@ union cvmx_sli_pktx_input_control {
                                                          is the no-snoop attribute for PCIe. */
 	uint64_t esr                          : 2;  /**< [ESR] is ES<1:0> for input instruction reads (from
                                                          SLI_PKT()_INSTR_BADDR+) and First Indirect DPTR reads. ES<1:0> is
-                                                         the endian-swap attribute for these MAC memory space reads. */
+                                                         the endian-swap attribute for these MAC memory space reads.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t ror                          : 1;  /**< [ROR] is ADDRTYPE<0> for input instruction reads (from
                                                          SLI_PKT()_INSTR_BADDR+) and First Indirect DPTR reads.
                                                          ADDRTYPE<0> is the relaxed-order attribute for PCIe. */
@@ -7570,28 +7768,31 @@ union cvmx_sli_pktx_input_control {
 	uint64_t reserved_27_27               : 1;
 	uint64_t quiet                        : 1;
 	uint64_t mac_num                      : 2;
-	uint64_t reserved_31_63               : 33;
+	uint64_t reserved_31_47               : 17;
+	uint64_t rpvf                         : 7;
+	uint64_t reserved_55_63               : 9;
 #endif
 	} s;
 	struct cvmx_sli_pktx_input_control_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t pvf_num                      : 16; /**< The function number that the ring belongs to, where <15:13> selects the PF the
-                                                         VF belongs to, and <12:0> selects the VF within that PF (or 0x0 for the PF
-                                                         itself).
-                                                         When [VF_NUM]=0, the physical
-                                                         function controls the ring. When [PVF_NUM]!=0, it must correctly indicate the
-                                                         virtual function number that controls the ring. ([VF_NUM]=1 selects the first
-                                                         virtual function within the selected physical function, [VF_NUM]=2 selects
-                                                         the second virtual function within the selected physical function ...)
-                                                         [PVF_NUM] is RO when accessed via BAR0 of a virtual function, and R/W otherwise.
-                                                         [PVF_NUM] applies to both this input ring and to the output ring of the same
-                                                         index. */
+	uint64_t reserved_55_63               : 9;
+	uint64_t rpvf                         : 7;  /**< The number of rings assigned to this VF.
+                                                         Read only copy of SLI_PKT_MAC(0..3)_PF(0..1)_RINFO[RPVF] */
+	uint64_t pvf_num                      : 16; /**< The function that the ring belongs to. DPI_DMA_FUNC_SEL_S describes
+                                                         the format of this field. If [PVF_NUM]!=0, [MAC_NUM] must select a
+                                                         PCIe MAC that supports more than one physical function and/or must
+                                                         select a PCIe MAC with SR-IOV enabled.
+                                                         [PVF_NUM] configuration must match SLI_PKT_MAC()_PF()_RINFO
+                                                         configuration.
+                                                         [PVF_NUM] is RO when accessed via BAR0 of a virtual function, and R/W
+                                                         otherwise.
+                                                         [PVF_NUM] applies to the ring pair, which includes both this input
+                                                         ring and to the output ring of the same index. */
 	uint64_t reserved_31_31               : 1;
 	uint64_t mac_num                      : 2;  /**< The MAC (PEM) that the physical function belongs to. Legal value are 0-3.
                                                          [MAC_NUM] is RO when accessed via BAR0 of a virtual function, and R/W otherwise.
-                                                         [MAC_NUM] applies to both this input ring and to the output ring of the same
-                                                         index. */
+                                                         [MAC_NUM] applies to the ring pair, which includes both this input
+                                                         ring and to the output ring of the same index. */
 	uint64_t quiet                        : 1;  /**< Asserted after a rings has gone into reset and the the ring has met the conditions
                                                          of SLI_PKT_GBL_CONTROL[QTIME]. */
 	uint64_t reserved_27_27               : 1;
@@ -7600,16 +7801,16 @@ union cvmx_sli_pktx_input_control {
                                                          0x1 = 2 Instructions.
                                                          0x2 = 3 Instructions.
                                                          0x3 = 4 Instructions. */
-	uint64_t is_64b                       : 1;  /**< When IS_64B=1, instruction input ring i uses 64B. */
+	uint64_t is_64b                       : 1;  /**< When IS_64B=1, instruction input ring i uses 64B versus 32B. */
 	uint64_t rst                          : 1;  /**< Packet reset. When [RST]=1, the rings are in reset. [RST] can be set
                                                          by software writing a 1 to the field, by hardware upon receipt of an
                                                          FLR to an associated function, or by hardware when it receives an error
                                                          response for a read associated with the rings.
                                                          [RST] applies to both this input ring and to the output ring of the same
                                                          index.
-                                                         Software should not clear [RST] from 1->0 until [RST] has been asserted
-                                                         for at least 2ms. A ring reset may clear all state associated with the
-                                                         input and output rings, so software must completely re-initialize both
+                                                         Software canot clear [RST] from 1->0 until the [QUIET] bit is a 1.
+                                                         A ring reset may clear all state associated with the input and
+                                                         output rings, so software must completely re-initialize both
                                                          before reusing them.
                                                          See also SLI_PKT_RING_RST[RST]. */
 	uint64_t enb                          : 1;  /**< Enable for the input ring i. Whenever [RST] is set, hardware forces
@@ -7625,6 +7826,7 @@ union cvmx_sli_pktx_input_control {
                                                          (DPTR Format 1) */
 	uint64_t d_esr                        : 2;  /**< If [USE_CSR]=1, [D_ESR] is ES<1:0> for First Direct and Gather DPTR reads.
                                                          ES<1:0> is the endian-swap attribute for these MAC memory space reads.
+                                                         Enumerated by SLI_ENDIANSWAP_E.
                                                          (DPTR Format 0)
                                                          If [USE_CSR]=0, [D_NSR] is MACADD<63:62> for First Direct and Gather DPTR
                                                          reads. (ES<1:0> comes from DPTR<63:62> in these cases when [USE_CSR]=0.)
@@ -7643,7 +7845,8 @@ union cvmx_sli_pktx_input_control {
                                                          is the no-snoop attribute for PCIe. */
 	uint64_t esr                          : 2;  /**< [ESR] is ES<1:0> for input instruction reads (from
                                                          SLI_PKT()_INSTR_BADDR+) and First Indirect DPTR reads. ES<1:0> is
-                                                         the endian-swap attribute for these MAC memory space reads. */
+                                                         the endian-swap attribute for these MAC memory space reads.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t ror                          : 1;  /**< [ROR] is ADDRTYPE<0> for input instruction reads (from
                                                          SLI_PKT()_INSTR_BADDR+) and First Indirect DPTR reads.
                                                          ADDRTYPE<0> is the relaxed-order attribute for PCIe. */
@@ -7665,7 +7868,8 @@ union cvmx_sli_pktx_input_control {
 	uint64_t mac_num                      : 2;
 	uint64_t reserved_31_31               : 1;
 	uint64_t pvf_num                      : 16;
-	uint64_t reserved_48_63               : 16;
+	uint64_t rpvf                         : 7;
+	uint64_t reserved_55_63               : 9;
 #endif
 	} cn73xx;
 	struct cvmx_sli_pktx_input_control_cn78xx {
@@ -7773,7 +7977,8 @@ union cvmx_sli_pktx_instr_baddr {
 	struct cvmx_sli_pktx_instr_baddr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t addr                         : 61; /**< Base address for instruction ring. [ADDR] Must be naturally-aligned to the
-                                                         instruction size selected by SLI_PKT()_INPUT_CONTROL[IS_64B]. */
+                                                         instruction size selected by SLI_PKT()_INPUT_CONTROL[IS_64B].  The hardware
+                                                         will ignore the bottom bits if not naturally aligned. */
 	uint64_t reserved_0_2                 : 3;
 #else
 	uint64_t reserved_0_2                 : 3;
@@ -7849,7 +8054,8 @@ union cvmx_sli_pktx_instr_fifo_rsize {
 	uint64_t rrp                          : 9;  /**< FIFO read pointer. */
 	uint64_t wrp                          : 9;  /**< FIFO write pointer. */
 	uint64_t fcnt                         : 5;  /**< FIFO count. */
-	uint64_t rsize                        : 32; /**< Instruction ring size. */
+	uint64_t rsize                        : 32; /**< Instruction ring size.  Legal values have to be greater then 128.
+                                                         Writes to [RSIZE] of less than 128 will set [RSIZE] to 128. */
 #else
 	uint64_t rsize                        : 32;
 	uint64_t fcnt                         : 5;
@@ -8141,7 +8347,7 @@ union cvmx_sli_pktx_mbox_int {
 	uint64_t po_int                       : 1;  /**< "Returns a 1 when either the corresponding bit in SLI_PKT_TIME_INT[RING<\#>] or
                                                          SLI_PKT_CNT_INT[RING<\#>] is set. This interrupt can be cleared by writing
                                                          SLI_PKT()_CNTS[CNT]." */
-	uint64_t pi_int                       : 1;  /**< "Returns a 1 when the corresponding bit of SLI_PKT_IN_INT[RING<\#>] is set. This interrupt
+	uint64_t pi_int                       : 1;  /**< "Reads corresponding bit of SLI_PKT_IN_INT[RING<\#>]. This interrupt
                                                          can be cleared by writing SLI_PKT_IN_DONE()_CNTS." */
 	uint64_t mbox_int                     : 1;  /**< Set to one when a PF writes the corresponding ring SLI_PKT(0..63)_PF_VF_MBOX_SIG(0)
                                                          register. Writes will clear this interrupt.  This bit can only be written by the VF side.
@@ -8149,7 +8355,10 @@ union cvmx_sli_pktx_mbox_int {
                                                          but will never cause an INTA/B/C/D nor MSI interrupt nor set any
                                                          SLI_MAC()_PF()_INT_SUM bit. */
 	uint64_t resend                       : 1;  /**< A write of 1 will resend an MSI-X interrupt message if there is a pending interrupt in
-                                                         P0_INT, PI_INT or MBOX_INT for this ring. */
+                                                         P0_INT, PI_INT or MBOX_INT for this ring after the clear of [MBOX_INT] occurs.
+                                                         [RESEND] and [MBOX_INT] must be written together with the assumption that the write of
+                                                         [CNT] will clear the [MBOX_INT] interrupt bit.
+                                                         The [RESEND] bit will never effect INTA/B/C/D or MSI interrupt */
 	uint64_t reserved_1_59                : 59;
 	uint64_t mbox_en                      : 1;  /**< Enables interrupt to the MSIX vector associated with this VF when the PF writes the
                                                          corresponding ring in SLI_PKT(0..63)_VF_MBOX_SIG(0). */
@@ -8178,9 +8387,10 @@ union cvmx_sli_pktx_out_size {
 	struct cvmx_sli_pktx_out_size_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_23_63               : 41;
-	uint64_t isize                        : 7;  /**< Info bytes size (bytes) for rings 0-63. Legal sizes are 0 to 120. Not used in buffer-
-                                                         pointer-only mode. */
-	uint64_t bsize                        : 16; /**< Buffer size (bytes) for rings 0-63. */
+	uint64_t isize                        : 7;  /**< Info bytes size (bytes) for this ring. Legal sizes are 0 to 120. Not used in buffer-
+                                                         pointer-only mode. Writes of [ISIZE] greater than 120 will set [ISIZE] to 120. */
+	uint64_t bsize                        : 16; /**< Buffer size (bytes) for this ring. Legal values have to be greater then 128.
+                                                         Writes of [BSIZE] less than 128 will set [BSIZE] to 128. */
 #else
 	uint64_t bsize                        : 16;
 	uint64_t isize                        : 7;
@@ -8270,8 +8480,9 @@ union cvmx_sli_pktx_output_control {
                                                          pairs (from SLI_PKT()_SLIST_BADDR[ADDR]+). ADDRTYPE<0> is the relaxed-order attribute
                                                          for PCIe. */
 	uint64_t enb                          : 1;  /**< Enable for the output ring. Whenever SLI_PKT()_INPUT_CONTROL[RST] is set, hardware
-                                                         forces [ENB] clear.
-                                                         In the PF, [ENB] is also SLI_PKT_OUT_ENB<i>. */
+                                                         forces [ENB] clear.  Software can only write [ENB] to 1.  [ENB] can only be cleared
+                                                         only by writing SLI_PKT()_INPUT_CONTROL[RST].  Once [ENB] is cleared software can
+                                                         only write [ENB] to a 1 once SLI_PKT()_INPUT_CONTROL[QUIET] is 1. */
 #else
 	uint64_t enb                          : 1;
 	uint64_t ror_p                        : 1;
@@ -8298,16 +8509,27 @@ typedef union cvmx_sli_pktx_output_control cvmx_sli_pktx_output_control_t;
 /**
  * cvmx_sli_pkt#_pf_vf_mbox_sig#
  *
- * This register is used for communication of data from the VF to the PF
- * A PF will write to the SLI_PKT()_PF_VF_MBOX_SIG() registers.
- * Each VF may access the same storage using the SLIVF_PKT()_VF_PF_MBOX_SIG() registers.
- * Writes from the PF to the SLI_PKT(0..63)_PF_VF_MBOX_SIG(0) register will cause an
- * interrupt to be set in the corresponding SLI_PKT()_MBOX_INT[MBOX_INT],
- * SLI_PKT_IN_DONE()_CNTS[MBOX_INT], SLI_PKT()_CNTS[MBOX_INT] fields and
- * corresponding bit in SLI_PKT_MBOX_INT register.
- * Writes from the VF to the SLI_PKT(0..63)_PF_VF_MBOX_SIG(1) register will cause an
- * interrupt bit to be set in the corresponding SLI_MAC(0..3)_PF(0..1)_MBOX_INT register.
- * Each PF can only access the rings that its owns as programmed by SLI_PKT_MAC()_RINFO.
+ * These registers are used for communication of data from the PF to the VF and vice versa.
+ *
+ * There are two registers per ring, SIG(0) and SIG(1). The PF and VF, both, have read and
+ * write access to these registers.
+ *
+ * For PF to VF ring interrupt, MBOX_EN bit of the SLI_PKT(0..127)_MBOX_INT must be set.
+ * When MBOX_EN bit is set, write from the PF to byte-0 of the SIG(0) register will cause
+ * an interrupt by setting MBOX_INT field in corresponding ring address of
+ * SLI_PKT()_MBOX_INT[MBOX_INT],
+ * SLI_PKT_IN_DONE()_CNTS[MBOX_INT], SLI_PKT()_CNTS[MBOX_INT].
+ *
+ * For VF to PF ring interrupt, VF_MBOX bit of the SLI_MAC(0..3)_PF(0..1)_INT_ENB must be set.
+ * When VF_MBOX bit is set, write from the VF to byte-0 of the SIG(1) register will cause an
+ * interrupt by setting ring address VF_INT field in corresponding SLI_MAC()_PF()_MBOX_INT
+ * register,
+ * which may cause an interrupt to occure through PF.
+ *
+ * Each PF and VF can only access the rings that its owns as programmed by SLI_PKT_MAC()_RINFO.
+ * The signaling is ring based. If a VF owns more than one ring it can ignore the other
+ * rings registers if not needed.
+ *
  * INTERNAL:
  *   VERIF - PF Write SIG0 interrupts VF owning the same ring. VF Write SIG0 no interrupt.
  *   VERIF - VF Write SIG1 interrupts PF owning the same ring. PF Write SIG1 no interrupt.
@@ -8411,7 +8633,9 @@ union cvmx_sli_pktx_slist_fifo_rsize {
 	struct cvmx_sli_pktx_slist_fifo_rsize_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t rsize                        : 32; /**< The number of buffer/info pointer pairs in the ring. */
+	uint64_t rsize                        : 32; /**< The number of buffer/info pointer pairs in the ring.
+                                                         Legal values have to be greater then 128.
+                                                         Writes to [RSIZE] of less than 128 will set [RSIZE] to 128. */
 #else
 	uint64_t rsize                        : 32;
 	uint64_t reserved_32_63               : 32;
@@ -8443,6 +8667,37 @@ union cvmx_sli_pktx_slist_fifo_rsize {
 typedef union cvmx_sli_pktx_slist_fifo_rsize cvmx_sli_pktx_slist_fifo_rsize_t;
 
 /**
+ * cvmx_sli_pkt#_vf_int_sum
+ *
+ * This register contains summary interrupts bits for a VF. A VF read of this register
+ * for any of its 8 rings will return the same 8 bit summary for packet input, packet
+ * output and mailbox interrupts. If a PF reads this register it will return 0x0.
+ */
+union cvmx_sli_pktx_vf_int_sum {
+	uint64_t u64;
+	struct cvmx_sli_pktx_vf_int_sum_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_40_63               : 24;
+	uint64_t mbox                         : 8;  /**< Summary read-only bits of SLI_PKT()_PF_VF_MBOX_SIG()[MBOX_INT] for rings owned by this VF. */
+	uint64_t reserved_24_31               : 8;
+	uint64_t pkt_out                      : 8;  /**< Summary read-only bits of SLI_PKT_IN_DONE()_CNTS[PI_INT] for rings owned by this VF. */
+	uint64_t reserved_8_15                : 8;
+	uint64_t pkt_in                       : 8;  /**< Summary read-only bits of SLI_PKT()_CNTS[PO_INT] for rings owned by this VF. */
+#else
+	uint64_t pkt_in                       : 8;
+	uint64_t reserved_8_15                : 8;
+	uint64_t pkt_out                      : 8;
+	uint64_t reserved_24_31               : 8;
+	uint64_t mbox                         : 8;
+	uint64_t reserved_40_63               : 24;
+#endif
+	} s;
+	struct cvmx_sli_pktx_vf_int_sum_s     cn73xx;
+	struct cvmx_sli_pktx_vf_int_sum_s     cnf75xx;
+};
+typedef union cvmx_sli_pktx_vf_int_sum cvmx_sli_pktx_vf_int_sum_t;
+
+/**
  * cvmx_sli_pkt#_vf_sig
  *
  * This register is used to signal between PF/VF. These 64 registers are index by VF number.
@@ -8799,7 +9054,14 @@ union cvmx_sli_pkt_gbl_control {
 	uint64_t qtime                        : 16; /**< After a packet ring is disabled on the assertion of SLI_PKT()_INPUT_CONTROL[RST],
                                                          the hardware will set the SLI_PKT()_INPUT_CONTROL[QUIET] bit
                                                          after at least [QTIME] * 1024 cycles. */
-	uint64_t reserved_2_15                : 14;
+	uint64_t reserved_14_15               : 2;
+	uint64_t bpkind                       : 6;  /**< PKIND sent to PKI when DPI_PKT_INST_HDR_S[PKIND] corresponding bit in
+                                                         SLI_PKT_PKIND_VALID[ENB] is set to a 0. */
+	uint64_t reserved_4_7                 : 4;
+	uint64_t pkpfval                      : 1;  /**< when zero, only VF's are subject to SLI_PKT_PKIND_VALID constraints, and PF instructions
+                                                         can select any PKI PKIND.
+                                                         When one, both PF's and VF's are subject to SLI_PKT_PKIND_VALID constraints. */
+	uint64_t bpflr_d                      : 1;  /**< Disables clearing SLI_PKT_OUT_BP_EN bit on an FLR. */
 	uint64_t noptr_d                      : 1;  /**< Disables putting a ring into reset when a packet is received from PKO and
                                                          the associated ring has no doorbells to send the packet out.
                                                          SLI_PKT_IN_DONE()_CNTS[CNT] when written. */
@@ -8808,7 +9070,11 @@ union cvmx_sli_pkt_gbl_control {
 #else
 	uint64_t picnt_d                      : 1;
 	uint64_t noptr_d                      : 1;
-	uint64_t reserved_2_15                : 14;
+	uint64_t bpflr_d                      : 1;
+	uint64_t pkpfval                      : 1;
+	uint64_t reserved_4_7                 : 4;
+	uint64_t bpkind                       : 6;
+	uint64_t reserved_14_15               : 2;
 	uint64_t qtime                        : 16;
 	uint64_t reserved_32_63               : 32;
 #endif
@@ -8816,7 +9082,15 @@ union cvmx_sli_pkt_gbl_control {
 	struct cvmx_sli_pkt_gbl_control_s     cn73xx;
 	struct cvmx_sli_pkt_gbl_control_cnf75xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_2_63                : 62;
+	uint64_t reserved_32_63               : 32;
+	uint64_t qtime                        : 16; /**< After a packet ring is disabled on the assertion of SLI_PKT()_INPUT_CONTROL[RST],
+                                                         the hardware will set the SLI_PKT()_INPUT_CONTROL[QUIET] bit
+                                                         after at least [QTIME] * 1024 cycles. */
+	uint64_t reserved_14_15               : 2;
+	uint64_t bpkind                       : 6;  /**< PKIND sent to PKI when DPI_PKT_INST_HDR_S[PKIND] corresponding bit in
+                                                         SLI_PKT_PKIND_VALID[ENB] is set to a 0. */
+	uint64_t reserved_3_7                 : 5;
+	uint64_t bpflr_d                      : 1;  /**< Disables clearing SLI_PKT_OUT_BP_EN bit on an FLR. */
 	uint64_t noptr_d                      : 1;  /**< Disables putting a ring into reset when a packet is received from PKO and
                                                          the associated ring has no doorbells to send the packet out.
                                                          SLI_PKT_IN_DONE()_CNTS[CNT] when written. */
@@ -8825,7 +9099,12 @@ union cvmx_sli_pkt_gbl_control {
 #else
 	uint64_t picnt_d                      : 1;
 	uint64_t noptr_d                      : 1;
-	uint64_t reserved_2_63                : 62;
+	uint64_t bpflr_d                      : 1;
+	uint64_t reserved_3_7                 : 5;
+	uint64_t bpkind                       : 6;
+	uint64_t reserved_14_15               : 2;
+	uint64_t qtime                        : 16;
+	uint64_t reserved_32_63               : 32;
 #endif
 	} cnf75xx;
 };
@@ -8876,16 +9155,19 @@ union cvmx_sli_pkt_in_donex_cnts {
 	uint64_t po_int                       : 1;  /**< "Returns a 1 when either the corresponding bit in SLI_PKT_TIME_INT[RING[\#]] or
                                                          SLI_PKT_CNT_INT[RING[\#]] is set." */
 	uint64_t pi_int                       : 1;  /**< Packet input interrupt bit for the ring. The hardware sets [PI_INT] whenever it updates
-                                                         [CNT<31:0>] and is greater then [WMARK][15:0] when CINT_ENB is set. Writing a 1 clears
-                                                         [PI_INT].
+                                                         [CNT<31:0>] and is greater then [WMARK][15:0] and CINT_ENB is set.
+                                                         The hardware will clear [PI_INT] when [CNT<31:0>] is less then or equal to [WMARK][15:0]
                                                          [PI_INT] can cause an MSI-X interrupt for the ring, but will never cause an INTA/B/C/D
                                                          nor MSI interrupt nor set any SLI_MAC()_PF()_INT_SUM bit. SLI_PKT_IN_INT is a
-                                                         multi-ring version of
-                                                         [PI_INT], and [PI_INT] is one component of SLI_PKT_INT. See also
+                                                         multi-ring version of [PI_INT], and [PI_INT] is one component of SLI_PKT_INT. See also
                                                          SLI_PKT()_CNTS[PI_INT]. */
-	uint64_t mbox_int                     : 1;  /**< Returns a 1 when corresponding bit in SLI_PKT()_MBOX_INT is set */
+	uint64_t mbox_int                     : 1;  /**< Reads corresponding bit in SLI_PKT()_MBOX_INT. */
 	uint64_t resend                       : 1;  /**< A write of 1 will resend an MSI-X interrupt message if there is a pending interrupt in
-                                                         P0_INT, PI_INT or MBOX_INT for this ring. */
+                                                         P0_INT, PI_INT or MBOX_INT for this ring after the write of [CNT] occurs.
+                                                         [RESEND] and [CNT] must be written together with the assumption that the write of
+                                                         [CNT] will clear the [PI_INT] interrupt bit. If the write of [CNT] does not cause
+                                                         the [CNT] to drop below the thresholds another MSI-X message will be sent.
+                                                         The [RESEND] bit will never effect INTA/B/C/D or MSI interrupt */
 	uint64_t reserved_49_59               : 11;
 	uint64_t cint_enb                     : 1;  /**< Packet input interrupt enable bit for the ring. When [CINT_ENB] is set,
                                                          the hardware will set [PI_INT] whenever it updates [CNT] and it is greater
@@ -9035,6 +9317,28 @@ union cvmx_sli_pkt_in_int {
 typedef union cvmx_sli_pkt_in_int cvmx_sli_pkt_in_int_t;
 
 /**
+ * cvmx_sli_pkt_in_jabber
+ *
+ * Register to set limit on sli packet input packet sizes
+ *
+ */
+union cvmx_sli_pkt_in_jabber {
+	uint64_t u64;
+	struct cvmx_sli_pkt_in_jabber_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t size                         : 32; /**< Byte count for limiting sizes of packet sizes that are allowed for sli packet inbound
+                                                         packets. */
+#else
+	uint64_t size                         : 32;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} s;
+	struct cvmx_sli_pkt_in_jabber_s       cn73xx;
+};
+typedef union cvmx_sli_pkt_in_jabber cvmx_sli_pkt_in_jabber_t;
+
+/**
  * cvmx_sli_pkt_in_pcie_port
  *
  * Assigns Packet Input rings to MAC ports.
@@ -9268,7 +9572,7 @@ union cvmx_sli_pkt_instr_enb {
 	uint64_t u64;
 	struct cvmx_sli_pkt_instr_enb_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t enb                          : 64; /**< Packet input enables for multiple rings. ENB<i> is also SLI_PKT(i)_INPUT_CONTROL[ENB]. */
+	uint64_t enb                          : 64; /**< When ENB<i>=1, instruction input ring i is enabled. */
 #else
 	uint64_t enb                          : 64;
 #endif
@@ -9292,30 +9596,10 @@ union cvmx_sli_pkt_instr_enb {
 	struct cvmx_sli_pkt_instr_enb_s       cn78xx;
 	struct cvmx_sli_pkt_instr_enb_s       cn78xxp2;
 	struct cvmx_sli_pkt_instr_enb_cn61xx  cnf71xx;
-	struct cvmx_sli_pkt_instr_enb_s       cnf75xx;
 };
 typedef union cvmx_sli_pkt_instr_enb cvmx_sli_pkt_instr_enb_t;
 
 /**
- * cvmx_sli_pkt_instr_enb2
- *
- * Multi-ring instruction input enable register. This register is PF-only.
- *
- */
-union cvmx_sli_pkt_instr_enb2 {
-	uint64_t u64;
-	struct cvmx_sli_pkt_instr_enb2_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t enb                          : 64; /**< Packet input enables for multiple rings. ENB<i> is also SLI_PKT(i)_INPUT_CONTROL[ENB]. */
-#else
-	uint64_t enb                          : 64;
-#endif
-	} s;
-	struct cvmx_sli_pkt_instr_enb2_s      cnf75xx;
-};
-typedef union cvmx_sli_pkt_instr_enb2 cvmx_sli_pkt_instr_enb2_t;
-
-/**
  * cvmx_sli_pkt_instr_rd_size
  *
  * The number of instruction allowed to be read at one time.
@@ -9516,11 +9800,11 @@ union cvmx_sli_pkt_macx_pfx_rinfo {
 	uint64_t u64;
 	struct cvmx_sli_pkt_macx_pfx_rinfo_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_56_63               : 8;
-	uint64_t nvfs                         : 8;  /**< The number of VF's for this PF. This field must not be zero whenever RPVF != 0.
+	uint64_t reserved_55_63               : 9;
+	uint64_t nvfs                         : 7;  /**< The number of VF's for this PF. This field must not be zero whenever RPVF != 0.
                                                          Legal values are 0 to 64, with the requirement of (NVFS * RPVF) <= TRS. */
 	uint64_t reserved_40_47               : 8;
-	uint64_t rpvf                         : 8;  /**< The number of rings assigned to a VF for this PF. Legal values are 0 to 64,
+	uint64_t rpvf                         : 8;  /**< The number of rings assigned to a VF for this PF. Legal values are 0,1,2,4,8
                                                          with the requirement of (NVFS * RPVF) <= TRS. */
 	uint64_t reserved_24_31               : 8;
 	uint64_t trs                          : 8;  /**< The number of rings assigned to the PF. Legal value are 0 to 64. */
@@ -9533,8 +9817,8 @@ union cvmx_sli_pkt_macx_pfx_rinfo {
 	uint64_t reserved_24_31               : 8;
 	uint64_t rpvf                         : 8;
 	uint64_t reserved_40_47               : 8;
-	uint64_t nvfs                         : 8;
-	uint64_t reserved_56_63               : 8;
+	uint64_t nvfs                         : 7;
+	uint64_t reserved_55_63               : 9;
 #endif
 	} s;
 	struct cvmx_sli_pkt_macx_pfx_rinfo_s  cn73xx;
@@ -9662,11 +9946,10 @@ union cvmx_sli_pkt_mem_ctl {
 	uint64_t u64;
 	struct cvmx_sli_pkt_mem_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_44_63               : 20;
-	uint64_t msid_fs                      : 2;  /**< Used to flip the synd. for pcsr_ncsr_msix_data_flip_synd. */
-	uint64_t msia_fs                      : 2;  /**< Used to flip the synd. for pcsr_ncsr_msix_addr_flip_synd. */
-	uint64_t msi_ecc                      : 1;  /**< When set pcsr_ncsr_msix_ecc_enawill have an ECC not generated and checked. */
-	uint64_t reserved_36_38               : 3;
+	uint64_t reserved_48_63               : 16;
+	uint64_t msix_mbox_fs                 : 2;  /**< Used to flip the synd. for pcsr_ncsr_msix_mailbox_flip_synd. */
+	uint64_t msix_mbox_ecc                : 1;  /**< When set pcsr_ncsr_msix_mailbox_ecc_ena will have an ECC not generated and checked. */
+	uint64_t reserved_36_44               : 9;
 	uint64_t pos_fs                       : 2;  /**< Used to flip the synd. for pcsr_pout_size_csr_flip_synd. */
 	uint64_t pos_ecc                      : 1;  /**< When set will have an ECC not generated and checked. */
 	uint64_t pinm_fs                      : 2;  /**< Used to flip the synd. for pcsr_instr_mem_csr_flip_synd. */
@@ -9716,19 +9999,21 @@ union cvmx_sli_pkt_mem_ctl {
 	uint64_t pinm_fs                      : 2;
 	uint64_t pos_ecc                      : 1;
 	uint64_t pos_fs                       : 2;
-	uint64_t reserved_36_38               : 3;
-	uint64_t msi_ecc                      : 1;
-	uint64_t msia_fs                      : 2;
-	uint64_t msid_fs                      : 2;
-	uint64_t reserved_44_63               : 20;
+	uint64_t reserved_36_44               : 9;
+	uint64_t msix_mbox_ecc                : 1;
+	uint64_t msix_mbox_fs                 : 2;
+	uint64_t reserved_48_63               : 16;
 #endif
 	} s;
 	struct cvmx_sli_pkt_mem_ctl_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_44_63               : 20;
-	uint64_t msid_fs                      : 2;  /**< Used to flip the synd. for pcsr_ncsr_msix_data_flip_synd. */
-	uint64_t msia_fs                      : 2;  /**< Used to flip the synd. for pcsr_ncsr_msix_addr_flip_synd. */
-	uint64_t msi_ecc                      : 1;  /**< When set pcsr_ncsr_msix_ecc_enawill have an ECC not generated and checked. */
+	uint64_t reserved_48_63               : 16;
+	uint64_t msix_mbox_fs                 : 2;  /**< Used to flip the synd. for pcsr_ncsr_msix_mailbox_flip_synd. */
+	uint64_t msix_mbox_ecc                : 1;  /**< When set pcsr_ncsr_msix_mailbox_ecc_ena will have an ECC not generated and checked. */
+	uint64_t msix_data_fs                 : 2;  /**< Used to flip the synd. for pcsr_ncsr_msix_data_flip_synd. */
+	uint64_t msix_data_ecc                : 1;  /**< When set pcsr_ncsr_msix_data_ecc_ena will have an ECC not generated and checked. */
+	uint64_t msix_addr_fs                 : 2;  /**< Used to flip the synd. for pcsr_ncsr_msix_addr_flip_synd. */
+	uint64_t msix_addr_ecc                : 1;  /**< When set pcsr_ncsr_msix_addr_ecc_ena will have an ECC not generated and checked. */
 	uint64_t pof_fs                       : 2;  /**< Used to flip the synd for packet-out-fifo memory. */
 	uint64_t pof_ecc                      : 1;  /**< When set packet-out-fifo memory will have an ECC not generated and checked. */
 	uint64_t pos_fs                       : 2;  /**< Used to flip the synd. for pcsr_pout_size_csr_flip_synd. */
@@ -9782,10 +10067,13 @@ union cvmx_sli_pkt_mem_ctl {
 	uint64_t pos_fs                       : 2;
 	uint64_t pof_ecc                      : 1;
 	uint64_t pof_fs                       : 2;
-	uint64_t msi_ecc                      : 1;
-	uint64_t msia_fs                      : 2;
-	uint64_t msid_fs                      : 2;
-	uint64_t reserved_44_63               : 20;
+	uint64_t msix_addr_ecc                : 1;
+	uint64_t msix_addr_fs                 : 2;
+	uint64_t msix_data_ecc                : 1;
+	uint64_t msix_data_fs                 : 2;
+	uint64_t msix_mbox_ecc                : 1;
+	uint64_t msix_mbox_fs                 : 2;
+	uint64_t reserved_48_63               : 16;
 #endif
 	} cn73xx;
 	struct cvmx_sli_pkt_mem_ctl_cn78xx {
@@ -9920,45 +10208,117 @@ union cvmx_sli_pkt_out_bp_en {
 #endif
 	} cn68xx;
 	struct cvmx_sli_pkt_out_bp_en_cn68xx  cn68xxp1;
-	struct cvmx_sli_pkt_out_bp_en_s       cn73xx;
 	struct cvmx_sli_pkt_out_bp_en_s       cn78xx;
 	struct cvmx_sli_pkt_out_bp_en_s       cn78xxp2;
-	struct cvmx_sli_pkt_out_bp_en_s       cnf75xx;
 };
 typedef union cvmx_sli_pkt_out_bp_en cvmx_sli_pkt_out_bp_en_t;
 
 /**
- * cvmx_sli_pkt_out_bp_en2
+ * cvmx_sli_pkt_out_bp_en2_w1c
+ *
+ * This register disables sending backpressure to PKO.
+ *
+ */
+union cvmx_sli_pkt_out_bp_en2_w1c {
+	uint64_t u64;
+	struct cvmx_sli_pkt_out_bp_en2_w1c_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t w1c                          : 64; /**< When set, disables the channel-level backpressure to be sent to PKO. Backpressure is sent
+                                                         to
+                                                         the PKO on the channels 0x140-0x17F. See SLI_PKT_OUTPUT_WMARK[WMARK].
+                                                         A read of this register will return the current value of the enables for those channels. */
+#else
+	uint64_t w1c                          : 64;
+#endif
+	} s;
+	struct cvmx_sli_pkt_out_bp_en2_w1c_s  cn73xx;
+	struct cvmx_sli_pkt_out_bp_en2_w1c_s  cnf75xx;
+};
+typedef union cvmx_sli_pkt_out_bp_en2_w1c cvmx_sli_pkt_out_bp_en2_w1c_t;
+
+/**
+ * cvmx_sli_pkt_out_bp_en2_w1s
  *
  * This register enables sending backpressure to PKO.
  *
  */
-union cvmx_sli_pkt_out_bp_en2 {
+union cvmx_sli_pkt_out_bp_en2_w1s {
 	uint64_t u64;
-	struct cvmx_sli_pkt_out_bp_en2_s {
+	struct cvmx_sli_pkt_out_bp_en2_w1s_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t bp_en                        : 64; /**< When set, enable the channel-level backpressure to be sent to PKO. Backpressure is sent to
-                                                         the PKO on the channels 0x140-0x17F. See SLI_PKT_OUTPUT_WMARK[WMARK]. */
+	uint64_t w1s                          : 64; /**< When set, enables the channel-level backpressure to be sent to PKO. Backpressure is sent
+                                                         to
+                                                         the PKO on the channels 0x140-0x17F. See SLI_PKT_OUTPUT_WMARK[WMARK].
+                                                         A read of this register will return the current value of the enables for those channels. */
 #else
-	uint64_t bp_en                        : 64;
+	uint64_t w1s                          : 64;
+#endif
+	} s;
+	struct cvmx_sli_pkt_out_bp_en2_w1s_s  cn73xx;
+	struct cvmx_sli_pkt_out_bp_en2_w1s_s  cnf75xx;
+};
+typedef union cvmx_sli_pkt_out_bp_en2_w1s cvmx_sli_pkt_out_bp_en2_w1s_t;
+
+/**
+ * cvmx_sli_pkt_out_bp_en_w1c
+ *
+ * This register disables sending backpressure to PKO.
+ *
+ */
+union cvmx_sli_pkt_out_bp_en_w1c {
+	uint64_t u64;
+	struct cvmx_sli_pkt_out_bp_en_w1c_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t w1c                          : 64; /**< When set, disables the channel-level backpressure to be sent to PKO. Backpressure is sent
+                                                         to
+                                                         the PKO on the channels 0x100-0x13F. See SLI_PKT_OUTPUT_WMARK[WMARK].
+                                                         A read of this register will return the current value of the enables for those channels. */
+#else
+	uint64_t w1c                          : 64;
+#endif
+	} s;
+	struct cvmx_sli_pkt_out_bp_en_w1c_s   cn73xx;
+	struct cvmx_sli_pkt_out_bp_en_w1c_s   cnf75xx;
+};
+typedef union cvmx_sli_pkt_out_bp_en_w1c cvmx_sli_pkt_out_bp_en_w1c_t;
+
+/**
+ * cvmx_sli_pkt_out_bp_en_w1s
+ *
+ * This register enables sending backpressure to PKO.
+ *
+ */
+union cvmx_sli_pkt_out_bp_en_w1s {
+	uint64_t u64;
+	struct cvmx_sli_pkt_out_bp_en_w1s_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t w1s                          : 64; /**< When set, enables the channel-level backpressure to be sent to PKO. Backpressure is sent
+                                                         to
+                                                         the PKO on the channels 0x100-0x13F. See SLI_PKT_OUTPUT_WMARK[WMARK].
+                                                         A read of this register will return the current value of the enables for those channels. */
+#else
+	uint64_t w1s                          : 64;
 #endif
 	} s;
-	struct cvmx_sli_pkt_out_bp_en2_s      cn73xx;
-	struct cvmx_sli_pkt_out_bp_en2_s      cnf75xx;
+	struct cvmx_sli_pkt_out_bp_en_w1s_s   cn73xx;
+	struct cvmx_sli_pkt_out_bp_en_w1s_s   cnf75xx;
 };
-typedef union cvmx_sli_pkt_out_bp_en2 cvmx_sli_pkt_out_bp_en2_t;
+typedef union cvmx_sli_pkt_out_bp_en_w1s cvmx_sli_pkt_out_bp_en_w1s_t;
 
 /**
  * cvmx_sli_pkt_out_enb
  *
- * This register enables the output packet engines. This is the PF version; also see
- * SLI_PKT()_OUTPUT_CONTROL[ENB].
+ * Multi-ring packet output enable register. This register is PF-only.
+ *
  */
 union cvmx_sli_pkt_out_enb {
 	uint64_t u64;
 	struct cvmx_sli_pkt_out_enb_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t enb                          : 64; /**< Packet output enables for multiple rings. ENB<i> is also SLI_PKT(i)_OUTPUT_CONTROL[ENB]. */
+	uint64_t enb                          : 64; /**< When ENB<i>=1, packet output ring i is enabled.
+                                                         If an error occurs on reading pointers for an
+                                                         output ring, the ring will be disabled by clearing
+                                                         the bit associated with the ring to '0'. */
 #else
 	uint64_t enb                          : 64;
 #endif
@@ -9985,30 +10345,10 @@ union cvmx_sli_pkt_out_enb {
 	struct cvmx_sli_pkt_out_enb_s         cn78xx;
 	struct cvmx_sli_pkt_out_enb_s         cn78xxp2;
 	struct cvmx_sli_pkt_out_enb_cn61xx    cnf71xx;
-	struct cvmx_sli_pkt_out_enb_s         cnf75xx;
 };
 typedef union cvmx_sli_pkt_out_enb cvmx_sli_pkt_out_enb_t;
 
 /**
- * cvmx_sli_pkt_out_enb2
- *
- * This register enables the output packet engines. This is the PF version; also see
- * SLI_PKT()_OUTPUT_CONTROL[ENB].
- */
-union cvmx_sli_pkt_out_enb2 {
-	uint64_t u64;
-	struct cvmx_sli_pkt_out_enb2_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t enb                          : 64; /**< Packet output enables for multiple rings. ENB<i> is also SLI_PKT(i)_OUTPUT_CONTROL[ENB]. */
-#else
-	uint64_t enb                          : 64;
-#endif
-	} s;
-	struct cvmx_sli_pkt_out_enb2_s        cnf75xx;
-};
-typedef union cvmx_sli_pkt_out_enb2 cvmx_sli_pkt_out_enb2_t;
-
-/**
  * cvmx_sli_pkt_output_wmark
  *
  * This register sets the value that determines when backpressure is applied to the PKO. When
@@ -10076,6 +10416,30 @@ union cvmx_sli_pkt_pcie_port {
 typedef union cvmx_sli_pkt_pcie_port cvmx_sli_pkt_pcie_port_t;
 
 /**
+ * cvmx_sli_pkt_pkind_valid
+ *
+ * Enables bits per PKIND that are allowed to be sent to PKI specified in the
+ * DPI_PKT_INST_HDR_S[PKIND]
+ * DPI packet instruction field.
+ */
+union cvmx_sli_pkt_pkind_valid {
+	uint64_t u64;
+	struct cvmx_sli_pkt_pkind_valid_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t enb                          : 64; /**< Enables bits for 64 possible pkinds.  If set to a 1, the corresponding
+                                                         DPI_PKT_INST_HDR_S[PKIND] is allowed to be passed to PKI.  If set to a 0,
+                                                         the DPI_PKT_INST_HDR_S[PKIND] will be changed to the pkind set in
+                                                         SLI_PKT_GBL_CONTROL[BPKIND] when sent to PKI. */
+#else
+	uint64_t enb                          : 64;
+#endif
+	} s;
+	struct cvmx_sli_pkt_pkind_valid_s     cn73xx;
+	struct cvmx_sli_pkt_pkind_valid_s     cnf75xx;
+};
+typedef union cvmx_sli_pkt_pkind_valid cvmx_sli_pkt_pkind_valid_t;
+
+/**
  * cvmx_sli_pkt_port_in_rst
  *
  * SLI_PKT_PORT_IN_RST = SLI Packet Port In Reset
@@ -10109,8 +10473,8 @@ typedef union cvmx_sli_pkt_port_in_rst cvmx_sli_pkt_port_in_rst_t;
 /**
  * cvmx_sli_pkt_ring_rst
  *
- * This register shows which rings are in reset. See also SLI_PKT()_INPUT_CONTROL[RST].
- *
+ * When read by a PF, this register informs which rings owned by the function (0 to N, N as large
+ * as 63) are in reset. See also SLI_PKT()_INPUT_CONTROL[RST].
  */
 union cvmx_sli_pkt_ring_rst {
 	uint64_t u64;
@@ -10392,7 +10756,7 @@ typedef union cvmx_sli_portx_pkind cvmx_sli_portx_pkind_t;
 /**
  * cvmx_sli_pp_pkt_csr_control
  *
- * Access to SLI packet register space from the core processors control register
+ * This register provides access to SLI packet register space from the cores.
  *
  */
 union cvmx_sli_pp_pkt_csr_control {
@@ -10400,7 +10764,10 @@ union cvmx_sli_pp_pkt_csr_control {
 	struct cvmx_sli_pp_pkt_csr_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t pvf                          : 16; /**< Function number to use on a PP register accesses to SLI Packet CSR's */
+	uint64_t pvf                          : 16; /**< Function number to use on a PP register accesses to SLI Packet CSRs,
+                                                         where <15:13> selects the PF the
+                                                         VF belongs to, and <12:0> selects the VF within that PF (or 0x0 for the PF
+                                                         itself). */
 #else
 	uint64_t pvf                          : 16;
 	uint64_t reserved_16_63               : 48;
@@ -10455,10 +10822,29 @@ union cvmx_sli_s2m_portx_ctl {
 	uint64_t wind_d                       : 1;  /**< Window disable. When set to 1, disables access to the window registers from the MAC port. */
 	uint64_t bar0_d                       : 1;  /**< BAR0 disable. When set to 1, disables access from the MAC to BAR0 for the following
                                                          address offsets:
-                                                         * 20000-20040
-                                                         * 28020-282F0
-                                                         * 286E0
-                                                         * 25000 */
+                                                           SLI_WIN_WR_ADDR
+                                                           SLI_WIN_RD_ADDR
+                                                           SLI_WIN_WR_DATA
+                                                           SLI_WIN_WR_MASK
+                                                           SLI_WIN_RD_DATA
+                                                           SLI_MAC_CREDIT_CNT
+                                                           SLI_S2M_PORT(0..3)_CTL
+                                                           SLI_MAC_CREDIT_CNT2
+                                                           SLI_S2C_END_MERGE
+                                                           SLI_CIU_INT_SUM
+                                                           SLI_CIU_INT_ENB
+                                                           SLI_MAC(0..3)_PF(0..1)_FLR_VF_INT
+                                                           SLI_MEM_ACCESS_SUBID(12..27)
+                                                           SLI_PP_PKT_CSR_CONTROL
+                                                           SLI_WINDOW_CTL
+                                                           SLI_MEM_ACCESS_CTL
+                                                           SLI_CTL_STATUS
+                                                           SLI_BIST_STATUS
+                                                           SLI_MEM_INT_SUM
+                                                           SLI_MEM_CTL
+                                                           SLI_CTL_PORT(0..3)
+                                                           SLI_NQM_RSP_ERR_SND_DBG
+                                                           SLI_PKT_MEM_CTL */
 	uint64_t reserved_0_2                 : 3;
 #else
 	uint64_t reserved_0_2                 : 3;
@@ -10522,10 +10908,29 @@ union cvmx_sli_s2m_portx_ctl {
 	uint64_t wind_d                       : 1;  /**< Window disable. When set to 1, disables access to the window registers from the MAC port. */
 	uint64_t bar0_d                       : 1;  /**< BAR0 disable. When set to 1, disables access from the MAC to BAR0 for the following
                                                          address offsets:
-                                                         * 20000-20040
-                                                         * 28020-282F0
-                                                         * 286E0
-                                                         * 25000 */
+                                                           SLI_WIN_WR_ADDR
+                                                           SLI_WIN_RD_ADDR
+                                                           SLI_WIN_WR_DATA
+                                                           SLI_WIN_WR_MASK
+                                                           SLI_WIN_RD_DATA
+                                                           SLI_MAC_CREDIT_CNT
+                                                           SLI_S2M_PORT(0..3)_CTL
+                                                           SLI_MAC_CREDIT_CNT2
+                                                           SLI_S2C_END_MERGE
+                                                           SLI_CIU_INT_SUM
+                                                           SLI_CIU_INT_ENB
+                                                           SLI_MAC(0..3)_PF(0..1)_FLR_VF_INT
+                                                           SLI_MEM_ACCESS_SUBID(12..27)
+                                                           SLI_PP_PKT_CSR_CONTROL
+                                                           SLI_WINDOW_CTL
+                                                           SLI_MEM_ACCESS_CTL
+                                                           SLI_CTL_STATUS
+                                                           SLI_BIST_STATUS
+                                                           SLI_MEM_INT_SUM
+                                                           SLI_MEM_CTL
+                                                           SLI_CTL_PORT(0..3)
+                                                           SLI_NQM_RSP_ERR_SND_DBG
+                                                           SLI_PKT_MEM_CTL */
 	uint64_t ld_cmd                       : 2;  /**< When SLI issues a load command to the L2C that is to be cached, this field selects the
                                                          type of load command to use:
                                                          0x0 = LDD.
@@ -10858,13 +11263,8 @@ typedef union cvmx_sli_tx_pipe cvmx_sli_tx_pipe_t;
  * cvmx_sli_win_rd_addr
  *
  * When the LSB of this register is written, the address in this register will be read. The data
- * returned
- * from this read will be placed in the WIN_RD_DATA register. This register should NOT be used to
- * read
- * SLI_* registers.
- *
- * If SLI_S2M_PORT()_CTL[LCL_NODE] the MAC that it is set for will not be able to write
- * SLI_WIN_RD_ADDR[37:36] which will always be written with the chips CCPI-ID.
+ * returned from this read will be placed in the WIN_RD_DATA register. This register should NOT
+ * be used to read SLI_* registers.
  */
 union cvmx_sli_win_rd_addr {
 	uint64_t u64;
@@ -10945,21 +11345,10 @@ typedef union cvmx_sli_win_rd_data cvmx_sli_win_rd_data_t;
 /**
  * cvmx_sli_win_wr_addr
  *
- * Add Lock Register (set on read, clear on write), software uses to control access to BAR0
- * space.
- *
- * * Total Address is 16Kb; 0x0000 - 0x3fff, 0x000 - 0x7fe(Reg, every other 8B).
- * * General  5kb; 0x0000 - 0x13ff, 0x000 - 0x27e(Reg-General).
- * * PktMem  10Kb; 0x1400 - 0x3bff, 0x280 - 0x77e(Reg-General-Packet).
- * * Rsvd     1Kb; 0x3c00 - 0x3fff, 0x780 - 0x7fe(Reg-NCB Only Mode).
- *
  * This register contains the address to be written to when a write operation is started by
- * writing the SLI_WIN_WR_DATA register. This register should not be used to write SLI_*
+ * writing the SLI_WIN_WR_DATA register.
  *
  * This register should NOT be used to write SLI_* registers.
- *
- * If SLI_S2M_PORT()_CTL[LCL_NODE] the MAC that it is set for will not be able to write
- * SLI_WIN_WR_ADDR[37:36] which will always be written with the chips CCPI-ID.
  */
 union cvmx_sli_win_wr_addr {
 	uint64_t u64;
@@ -11081,9 +11470,7 @@ union cvmx_sli_window_ctl {
 	uint64_t u64;
 	struct cvmx_sli_window_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ocx_time                     : 32; /**< OCX time. When a command acknowledge or a request to fetch read data is expected
-                                                         from CCPI, SLI waits this many SCLKs before determining that the CCPI is not
-                                                         going to respond and timeout the request. */
+	uint64_t ocx_time                     : 32; /**< This fields is unused. */
 	uint64_t time                         : 32; /**< Time to wait. The number of coprocessor-clock cycles to wait for a window access before timing out. */
 #else
 	uint64_t time                         : 32;
diff --git a/arch/mips/include/asm/octeon/cvmx-srio.h b/arch/mips/include/asm/octeon/cvmx-srio.h
index bffa9d6..e665490 100644
--- a/arch/mips/include/asm/octeon/cvmx-srio.h
+++ b/arch/mips/include/asm/octeon/cvmx-srio.h
@@ -575,6 +575,29 @@ int cvmx_srio_omsg_desc(uint64_t port, cvmx_buf_ptr_t * buf_ptr, cvmx_srio_tx_me
 
 extern void cvmx_srio_set_pkind(int srio_link, int index,int pkind);
 
+/**
+ * Convert an ipd port number to its sRIO link number per SoC model.
+ *
+ * @param ipd_port Ipd port number to convert
+ *
+ * @return Srio link number
+ */
+extern int cvmx_srio_ipd2srio(int ipd_port);
+
+/**
+ * Get our device ID
+ *
+ * @return Device ID, or negative number on error
+ */
+extern int cvmx_srio_get_did(int srio_port);
+
+/**
+ * Set our device ID
+ *
+ * @return Device ID, or negative number on error
+ */
+extern int cvmx_srio_set_did(int srio_port, int did);
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h b/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
index 46d2dd6..0403ae9d 100644
--- a/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
@@ -2762,12 +2762,10 @@ typedef union cvmx_sriomaintx_dst_ops cvmx_sriomaintx_dst_ops_t;
  * The HW sets SRIO_INT_REG[PHY_ERB] every time it sets VALID in this CSR.
  * To handle the interrupt, the following procedure may be best:
  *
- * (1) clear SRIO_INT_REG[PHY_ERB],
- *
- * (2) read this CSR, corresponding SRIOMAINT()_ERB_ERR_DET, SRIOMAINT()_ERB_PACK_SYM_CAPT,
+ * (1) read this CSR, corresponding SRIOMAINT()_ERB_ERR_DET, SRIOMAINT()_ERB_PACK_SYM_CAPT,
  * SRIOMAINT()_ERB_PACK_CAPT_1, SRIOMAINT()_ERB_PACK_CAPT_2, and SRIOMAINT()_ERB_PACK_CAPT_3
- *
- * (3) Write VALID in this CSR to 0.
+ * (2) Write VALID in this CSR to 0.
+ * (3) clear SRIO_INT_REG[PHY_ERB],
  */
 union cvmx_sriomaintx_erb_attr_capt {
 	uint32_t u32;
@@ -3416,9 +3414,7 @@ typedef union cvmx_sriomaintx_erb_lt_dev_id_capt cvmx_sriomaintx_erb_lt_dev_id_c
  * (1) read this CSR, corresponding SRIOMAINT()_ERB_LT_ADDR_CAPT_H,
  * SRIOMAINT()_ERB_LT_ADDR_CAPT_L,
  * SRIOMAINT()_ERB_LT_DEV_ID_CAPT, and SRIOMAINT()_ERB_LT_CTRL_CAPT
- *
  * (2) Write this CSR to 0.
- *
  * (3) clear SRIO_INT_REG[LOG_ERB],
  */
 union cvmx_sriomaintx_erb_lt_err_det {
diff --git a/arch/mips/include/asm/octeon/cvmx-sriox-defs.h b/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
index 3bb9704..f9ffcf1 100644
--- a/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
@@ -1800,7 +1800,7 @@ union cvmx_sriox_imsg_vport_thr {
 	uint64_t reserved_63_63               : 1;
 	uint64_t base                         : 7;  /**< Vport starting offset.  The Vports used between SRIO0 and SRIO1 must not overlap
                                                          with each other or other devices.  The first 8 vports are initially for BGX, Loopback,
-                                                         etc.
+                                                         etc. See PKI_REASM_E.
                                                          Default is 8 (to 51) for SRIO0 and 52 (to 95) for SRIO1. */
 	uint64_t reserved_54_55               : 2;
 	uint64_t max_tot                      : 6;  /**< Sets max number of vports available to this SRIO MAC.  Maximum value supported by
@@ -2462,9 +2462,9 @@ typedef union cvmx_sriox_int_info3 cvmx_sriox_int_info3_t;
 /**
  * cvmx_srio#_int_reg
  *
- * This register provides interrupt status.  Like most SRIO CSRs, this register can only
- * be read/written when the corresponding SRIO is both present and not in reset. (SRIO()_INT2_REG
- * can be accessed when SRIO is in reset.) Any set bits written to this register clear the
+ * This register provides interrupt status.  Unlike most of other SRIO registers,
+ * this register can be accessed even when SRIO is in reset.
+ * Any set bits written to this register clear the
  * corresponding interrupt.  The RXBELL interrupt is cleared by reading all the entries in the
  * incoming Doorbell FIFO.  OMSG_ERR is set when
  * an invalid SRIO_OMSG_HDR_S is received.  The SRIO_OMSG_HDR_S is deemed to be invalid if
@@ -2472,7 +2472,7 @@ typedef union cvmx_sriox_int_info3 cvmx_sriox_int_info3_t;
  * would result in more than 16 message segments, or the packet only contains a SRIO_OMSG_HDR_S
  * (no data).
  *
- * This register is reset by the h-clock reset.
+ * This register is reset by the coprocessor clock reset.
  */
 union cvmx_sriox_int_reg {
 	uint64_t u64;
@@ -2502,17 +2502,7 @@ union cvmx_sriox_int_reg {
                                                          When one or more of the segments in an outgoing
                                                          message have a RTRY_ERR, SRIO will not set
                                                          OMSG* after the message "transfer". */
-	uint64_t pko_err                      : 1;  /**< Outbound message received PKO Error  FIXME, going to change to   PKO Reset Error - Message
-                                                         Received from PKO while
-                                                         MAC in reset. This
-                                                         This register provides interrupt status. Unlike SRIO()_INT_REG,
-                                                         SRIO()_INT2_REG can be accessed whenever the SRIO is present,
-                                                         regardless of whether the corresponding SRIO is in reset or not.
-                                                         INT_SUM shows the status of the interrupts in SRIO()_INT_REG.
-                                                         Any set bits written to this register clear the corresponding interrupt.
-                                                         The register can be accessed/modified regardless of the value of
-                                                         SRIO()_STATUS_REG[ACCESS] and probably should be the first register read
-                                                         when an SRIO interrupt occurs.  FIXME */
+	uint64_t reserved_19_19               : 1;
 	uint64_t omsg_err                     : 1;  /**< Outbound message invalid SRIO_OMSG_HDR_S error.
                                                          See SRIO()_INT_INFO2. */
 	uint64_t omsg1                        : 1;  /**< Controller 1 outbound message complete.
@@ -2523,11 +2513,9 @@ union cvmx_sriox_int_reg {
 	uint64_t link_dwn                     : 1;  /**< Serial link going from active to inactive. */
 	uint64_t phy_erb                      : 1;  /**< Physical layer error detected in erb.
                                                          This is a summary interrupt of all SRIOMAINT physical layer interrupts,
-                                                         and this is level interrupt that only can be cleared from SRIOMAINT csrs.
                                                          See SRIOMAINT()_ERB_ATTR_CAPT. */
 	uint64_t log_erb                      : 1;  /**< Logical/transport layer error detected in ERB.
                                                          This is a summary interrupt of all SRIOMAINT logical layer interrupts,
-                                                         and this is level interrupt that only can be cleared from SRIOMAINT csrs.
                                                          See SRIOMAINT()_ERB_LT_ERR_DET. */
 	uint64_t soft_rx                      : 1;  /**< Incoming packet received by soft packet FIFO. */
 	uint64_t soft_tx                      : 1;  /**< Outgoing packet sent by soft packet FIFO. */
@@ -2570,7 +2558,7 @@ union cvmx_sriox_int_reg {
 	uint64_t omsg0                        : 1;
 	uint64_t omsg1                        : 1;
 	uint64_t omsg_err                     : 1;
-	uint64_t pko_err                      : 1;
+	uint64_t reserved_19_19               : 1;
 	uint64_t rtry_err                     : 1;
 	uint64_t f_error                      : 1;
 	uint64_t mac_buf                      : 1;
@@ -2763,17 +2751,7 @@ union cvmx_sriox_int_reg {
                                                          When one or more of the segments in an outgoing
                                                          message have a RTRY_ERR, SRIO will not set
                                                          OMSG* after the message "transfer". */
-	uint64_t pko_err                      : 1;  /**< Outbound message received PKO Error  FIXME, going to change to   PKO Reset Error - Message
-                                                         Received from PKO while
-                                                         MAC in reset. This
-                                                         This register provides interrupt status. Unlike SRIO()_INT_REG,
-                                                         SRIO()_INT2_REG can be accessed whenever the SRIO is present,
-                                                         regardless of whether the corresponding SRIO is in reset or not.
-                                                         INT_SUM shows the status of the interrupts in SRIO()_INT_REG.
-                                                         Any set bits written to this register clear the corresponding interrupt.
-                                                         The register can be accessed/modified regardless of the value of
-                                                         SRIO()_STATUS_REG[ACCESS] and probably should be the first register read
-                                                         when an SRIO interrupt occurs.  FIXME */
+	uint64_t pko_rst_err                  : 1;  /**< PKO Reset Error - Message Received from PKO while MAC in reset. */
 	uint64_t omsg_err                     : 1;  /**< Outbound message invalid SRIO_OMSG_HDR_S error.
                                                          See SRIO()_INT_INFO2. */
 	uint64_t omsg1                        : 1;  /**< Controller 1 outbound message complete.
@@ -2784,11 +2762,9 @@ union cvmx_sriox_int_reg {
 	uint64_t link_dwn                     : 1;  /**< Serial link going from active to inactive. */
 	uint64_t phy_erb                      : 1;  /**< Physical layer error detected in erb.
                                                          This is a summary interrupt of all SRIOMAINT physical layer interrupts,
-                                                         and this is level interrupt that only can be cleared from SRIOMAINT csrs.
                                                          See SRIOMAINT()_ERB_ATTR_CAPT. */
 	uint64_t log_erb                      : 1;  /**< Logical/transport layer error detected in ERB.
                                                          This is a summary interrupt of all SRIOMAINT logical layer interrupts,
-                                                         and this is level interrupt that only can be cleared from SRIOMAINT csrs.
                                                          See SRIOMAINT()_ERB_LT_ERR_DET. */
 	uint64_t soft_rx                      : 1;  /**< Incoming packet received by soft packet FIFO. */
 	uint64_t soft_tx                      : 1;  /**< Outgoing packet sent by soft packet FIFO. */
@@ -2831,7 +2807,7 @@ union cvmx_sriox_int_reg {
 	uint64_t omsg0                        : 1;
 	uint64_t omsg1                        : 1;
 	uint64_t omsg_err                     : 1;
-	uint64_t pko_err                      : 1;
+	uint64_t pko_rst_err                  : 1;
 	uint64_t rtry_err                     : 1;
 	uint64_t f_error                      : 1;
 	uint64_t mac_buf                      : 1;
@@ -2868,14 +2844,14 @@ union cvmx_sriox_int_w1s {
 	uint64_t mac_buf                      : 1;  /**< Reads or sets  SRIO()_INT_REG[MAC_BUF]. */
 	uint64_t f_error                      : 1;  /**< Reads or sets  SRIO()_INT_REG[F_ERROR]. */
 	uint64_t rtry_err                     : 1;  /**< Reads or sets  SRIO()_INT_REG[RTRY_ERR]. */
-	uint64_t pko_err                      : 1;  /**< Reads or sets  SRIO()_INT_REG[PKO_ERR]. */
+	uint64_t pko_rst_err                  : 1;  /**< Reads or sets  SRIO()_INT_REG[PKO_RST_ERR]. */
 	uint64_t omsg_err                     : 1;  /**< Reads or sets  SRIO()_INT_REG[OMSG_ERR]. */
 	uint64_t omsg1                        : 1;  /**< Reads or sets  SRIO()_INT_REG[OMSG1]. */
 	uint64_t omsg0                        : 1;  /**< Reads or sets  SRIO()_INT_REG[OMSG0]. */
 	uint64_t link_up                      : 1;  /**< Reads or sets  SRIO()_INT_REG[LINK_UP]. */
 	uint64_t link_dwn                     : 1;  /**< Reads or sets  SRIO()_INT_REG[LINK_DWN]. */
-	uint64_t phy_erb                      : 1;  /**< Reads SRIO()_INT_REG[PHY_ERB]. */
-	uint64_t log_erb                      : 1;  /**< Reads SRIO()_INT_REG[LOG_ERB]. */
+	uint64_t phy_erb                      : 1;  /**< Reads or sets SRIO()_INT_REG[PHY_ERB]. */
+	uint64_t log_erb                      : 1;  /**< Reads or sets  SRIO()_INT_REG[LOG_ERB]. */
 	uint64_t soft_rx                      : 1;  /**< Reads or sets  SRIO()_INT_REG[SOFT_RX]. */
 	uint64_t soft_tx                      : 1;  /**< Reads or sets  SRIO()_INT_REG[SOFT_TX]. */
 	uint64_t mce_rx                       : 1;  /**< Reads or sets  SRIO()_INT_REG[MCE_RX]. */
@@ -2908,7 +2884,7 @@ union cvmx_sriox_int_w1s {
 	uint64_t omsg0                        : 1;
 	uint64_t omsg1                        : 1;
 	uint64_t omsg_err                     : 1;
-	uint64_t pko_err                      : 1;
+	uint64_t pko_rst_err                  : 1;
 	uint64_t rtry_err                     : 1;
 	uint64_t f_error                      : 1;
 	uint64_t mac_buf                      : 1;
diff --git a/arch/mips/include/asm/octeon/cvmx-sso-defs.h b/arch/mips/include/asm/octeon/cvmx-sso-defs.h
index 1d96fd1..4a55525 100644
--- a/arch/mips/include/asm/octeon/cvmx-sso-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sso-defs.h
@@ -922,8 +922,8 @@ static inline uint64_t CVMX_SSO_RESET_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00016700000010F8ull);
 			break;
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
@@ -939,8 +939,8 @@ static inline uint64_t CVMX_SSO_RESET_FUNC(void)
 {
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00016700000010F8ull);
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x00016700000010F0ull);
diff --git a/arch/mips/include/asm/octeon/cvmx-wqe.h b/arch/mips/include/asm/octeon/cvmx-wqe.h
index 52eb9e3..b2a9d6f 100644
--- a/arch/mips/include/asm/octeon/cvmx-wqe.h
+++ b/arch/mips/include/asm/octeon/cvmx-wqe.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2015  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -915,6 +915,52 @@ typedef union {
 	} cn38xx;
 } cvmx_wqe_word1_t;
 
+typedef union {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_0:8,
+		/**
+		 * NVMe queue manager hardware error info.
+		 */
+		CVMX_BITFIELD_FIELD(uint64_t hwerr:8,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_1:24,
+		/**
+		 * Submission queue ID number
+		 */
+		CVMX_BITFIELD_FIELD(uint64_t sqid:8,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_2:4,
+		/**
+		 * Virtual function number
+		 */
+		CVMX_BITFIELD_FIELD(uint64_t vfnum:12,
+		))))));
+	};
+} cvmx_wqe_word3_t;
+
+typedef union {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_0:21,
+		/**
+		 * SQ flow control counter. For diagnostic use only.
+		 */
+		CVMX_BITFIELD_FIELD(uint64_t sqfc:11,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_1:5,
+		/**
+		 * SQ tail. For diagnostic use only
+		 */
+		CVMX_BITFIELD_FIELD(uint64_t sqtail:11,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_2:3,
+		/**
+		 *  SQ head pointer. The SQ entry number that this
+		 *  command was read from. Useful for pairing up
+		 *  fused operations
+		 */
+		CVMX_BITFIELD_FIELD(uint64_t sqhead:13,
+		))))));
+	};
+} cvmx_wqe_word4_t;
+
 /**
  * Work queue entry format
  *
@@ -969,6 +1015,65 @@ typedef struct cvmx_wqe_s {
 } CVMX_CACHE_LINE_ALIGNED cvmx_wqe_t;
 
 /**
+ * Work queue entry format for NQM
+ *
+ * must be 8-byte aligned
+ */
+typedef struct cvmx_wqe_nqm_s {
+
+    /*****************************************************************
+     * WORD 0
+     *  HW WRITE: the following 64 bits are filled by HW when a packet arrives
+     */
+
+	cvmx_wqe_word0_t word0;
+
+    /*****************************************************************
+     * WORD 1
+     *  HW WRITE: the following 64 bits are filled by HW when a packet arrives
+     */
+
+	cvmx_wqe_word1_t word1;
+    /**
+     * WORD 2
+     * Reserved
+     */
+	uint64_t word2;
+
+    /**
+     * WORD 3
+     * NVMe specific information
+     */
+	cvmx_wqe_word3_t word3;
+
+    /**
+     * WORD 4
+     * NVMe specific information
+     */
+	cvmx_wqe_word4_t word4;
+
+    /**
+     *   HW WRITE: octeon will fill in a programmable amount from the
+     *             packet, up to (at most, but perhaps less) the amount
+     *             needed to fill the work queue entry to 128 bytes
+     *   If the packet is recognized to be IP, the hardware starts (except that
+     *   the IPv4 header is padded for appropriate alignment) writing here where
+     *   the IP header starts.
+     *   If the packet is not recognized to be IP, the hardware starts writing
+     *   the beginning of the packet here.
+     */
+	uint8_t packet_data[88];
+
+    /**
+     * If desired, SW can make the work Q entry any length. For the
+     * purposes of discussion here, Assume 128B always, as this is all that
+     * the hardware deals with.
+     *
+     */
+
+} CVMX_CACHE_LINE_ALIGNED cvmx_wqe_nqm_t;
+
+/**
  * Work queue entry format for 78XX
  * In 78XX packet data always resides in WQE buffer unless
  * option DIS_WQ_DAT=1 in PKI_STYLE_BUF, which causes packet data to use
diff --git a/arch/mips/include/asm/octeon/cvmx-xcv-defs.h b/arch/mips/include/asm/octeon/cvmx-xcv-defs.h
index abc7f90..1bf9b5a 100644
--- a/arch/mips/include/asm/octeon/cvmx-xcv-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-xcv-defs.h
@@ -432,7 +432,8 @@ union cvmx_xcv_reset {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t enable                       : 1;  /**< Port enable. */
 	uint64_t reserved_16_62               : 47;
-	uint64_t clkrst                       : 1;  /**< DLL CLK reset. */
+	uint64_t clkrst                       : 1;  /**< DLL CLK reset.  CLKRST must be set if DLL bypass mode
+                                                         XCV_DLL_CTL[CLKRX_BYP,CLKTX_BYP] is used. */
 	uint64_t reserved_12_14               : 3;
 	uint64_t dllrst                       : 1;  /**< DLL reset. */
 	uint64_t reserved_8_10                : 3;
-- 
2.6.2

