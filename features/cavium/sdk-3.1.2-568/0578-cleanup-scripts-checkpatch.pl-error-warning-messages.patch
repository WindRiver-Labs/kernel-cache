From fb694066acd143943d4d92727a99105b66bc1b32 Mon Sep 17 00:00:00 2001
From: Emil <egoranov@caviumnetworks.com>
Date: Tue, 11 Feb 2014 13:46:59 -0800
Subject: [PATCH 578/974] cleanup scripts/checkpatch.pl error/warning messages

[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/cavium-octeon/executive/cvmx-bch.c  |  81 +++++++--
 arch/mips/cavium-octeon/executive/cvmx-nand.c | 129 +++++++------
 arch/mips/cavium-octeon/octeon-nand.c         | 253 +++++++++++++++-----------
 3 files changed, 290 insertions(+), 173 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-bch.c b/arch/mips/cavium-octeon/executive/cvmx-bch.c
index c90a78d..89c83a7 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-bch.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-bch.c
@@ -20,7 +20,7 @@
  *     derived from this software without specific prior written
  *     permission.
  *
- * This Software, including technical data, may be subject to U.S. export  control
+ * This Software, including technical data, may be subject to U.S. export control
  * laws, including the U.S. Export Administration Act and its  associated
  * regulations, and may be subject to export or import  regulations in other
  * countries.
@@ -28,8 +28,8 @@
  * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
  * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
  * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
- * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
- * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION
+ * OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
  * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
  * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
  * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
@@ -45,6 +45,7 @@
  * <hr>$Revision: 79788 $<hr>
  */
 
+
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 # include <asm/octeon/cvmx.h>
 # include <asm/octeon/cvmx-config.h>
@@ -53,7 +54,12 @@
 # include <asm/octeon/cvmx-fpa1.h>
 # include <asm/octeon/cvmx-helper-fpa.h>
 # include <asm/octeon/cvmx-cmd-queue.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#define USE_BOUNCE_BUFF 1	/* used ONLY for Linux */
+
 #elif defined(CVMX_BUILD_FOR_UBOOT)
+
 # include <common.h>
 # include <asm/arch/cvmx.h>
 # include <asm/arch/cvmx-bch-defs.h>
@@ -84,7 +90,6 @@ CVMX_SHARED cvmx_bch_app_config_t bch_config = {
 };
 
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-extern int cvm_oct_mem_fill_fpa(int pool, int elements);
 extern int cvm_oct_alloc_fpa_pool(int pool, int size);
 #endif
 
@@ -103,6 +108,7 @@ int cvmx_bch_initialize(void)
 
 	/* Initialize FPA pool for BCH pool buffers */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+	int i;
 	bch_pool = CVMX_FPA_OUTPUT_BUFFER_POOL;
 	bch_pool_size = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE;
 
@@ -112,10 +118,13 @@ int cvmx_bch_initialize(void)
 
 	bch_pool = cvm_oct_alloc_fpa_pool(bch_pool, bch_pool_size);
 	if (bch_pool < 0) {
-		pr_err("cvm_oct_alloc_fpa_pool(%d, %lld)\n", bch_pool, bch_pool_size);
+		pr_err("cvm_oct_alloc_fpa_pool(%d, %lld)\n",
+		       bch_pool, bch_pool_size);
 		return -ENOMEM;
 	}
-	cvm_oct_mem_fill_fpa(bch_pool, 128);
+
+	for (i = 0; i < 16; i++)
+		cvmx_fpa1_free(kmalloc(bch_pool_size, GFP_KERNEL), bch_pool, 0);
 #else
 	bch_pool = (int)cvmx_fpa_get_bch_pool();
 	bch_pool_size = cvmx_fpa_get_bch_pool_block_size();
@@ -147,8 +156,8 @@ int cvmx_bch_initialize(void)
 	bch_cmd_buf.s.dwb = bch_pool_size / 128;
 	bch_cmd_buf.s.pool = bch_pool;
 	bch_cmd_buf.s.size = bch_pool_size / 8;
-	bch_cmd_buf.s.ptr =
-		cvmx_ptr_to_phys(cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_BCH)) >> 7;
+	bch_cmd_buf.s.ptr = cvmx_ptr_to_phys(
+		cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_BCH)) >> 7;
 	cvmx_write_csr(CVMX_BCH_CMD_BUF, bch_cmd_buf.u64);
 	cvmx_write_csr(CVMX_BCH_GEN_INT, 7);
 	cvmx_write_csr(CVMX_BCH_GEN_INT_EN, 0);
@@ -170,6 +179,7 @@ EXPORT_SYMBOL(cvmx_bch_initialize);
 int cvmx_bch_shutdown(void)
 {
 	cvmx_bch_ctl_t bch_ctl;
+	int bch_pool;
 
 	debug("%s: ENTER\n", __func__);
 	bch_ctl.u64 = cvmx_read_csr(CVMX_BCH_CTL);
@@ -177,8 +187,24 @@ int cvmx_bch_shutdown(void)
 	cvmx_write_csr(CVMX_BCH_CTL, bch_ctl.u64);
 	cvmx_wait(4);
 
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+	bch_pool = CVMX_FPA_OUTPUT_BUFFER_POOL;
+#else
+	bch_pool = (int)cvmx_fpa_get_bch_pool();
+#endif
 	cvmx_cmd_queue_shutdown(CVMX_CMD_QUEUE_BCH);
 
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+	/* FIXME: BCH cleanup in SE : AJ */
+	{
+		int i;
+		for (i = 0; i < 16; i++)
+			kfree(cvmx_fpa1_alloc(bch_pool));
+	}
+#else
+	cvmx_fpa_shutdown_pool(bch_pool);
+#endif
+	/* AJ: Fix for FPA3 */
 	return 0;
 }
 EXPORT_SYMBOL(cvmx_bch_shutdown);
@@ -189,7 +215,7 @@ EXPORT_SYMBOL(cvmx_bch_shutdown);
  * @param buffer_size	buffer size of pool
  * @param buffer_count	number of buffers to allocate to pool
  */
-void cvmx_bch_set_cmd_que_pool_config (int64_t pool, uint64_t buffer_size,
+void cvmx_bch_set_cmd_que_pool_config(int64_t pool, uint64_t buffer_size,
 				       uint64_t buffer_count)
 {
 	bch_config.command_queue_pool.pool_num = pool;
@@ -212,8 +238,8 @@ void cvmx_bch_get_cmd_que_pool_config(cvmx_fpa_pool_config_t *bch_pool)
  * @param[in] block	8-byte aligned pointer to data block to calculate ECC
  * @param block_size	Size of block in bytes, must be a multiple of two.
  * @param ecc_level	Number of errors that must be corrected.  The number of
- * 			parity bytes is equal to ((15 * ecc_level) + 7) / 8.
- * 			Must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
+ *			parity bytes is equal to ((15 * ecc_level) + 7) / 8.
+ *			Must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
  * @param[out] ecc	8-byte aligned pointer to where ecc data should go
  * @param[in] response	pointer to where responses will be written.
  *
@@ -225,9 +251,26 @@ int cvmx_bch_encode(const void *block, uint16_t block_size,
 {
 	cvmx_bch_command_t command;
 	cvmx_cmd_queue_result_t result;
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#if USE_BOUNCE_BUFF
+	static uint8_t *bounce_buff;
 
+	if (!bounce_buff)
+		bounce_buff = kmalloc(1024, GFP_KERNEL);
+#endif
+#endif
 	debug("%s(%p, %u, %u, %p, %p) ENTRY\n", __func__, block, block_size,
 	      ecc_level, ecc, response);
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#if USE_BOUNCE_BUFF
+	/* there was a problem when the first argument is used directly
+	 * despite of the fact it was 8-byte aligned, so we copy data
+	 * to dedicated 'bounce_buff' and set
+	 * command.s.iword.prt to cvmx_ptr_to_phys((void *)bounce_buff)
+	 */
+	memcpy(bounce_buff, block, block_size);
+#endif
+#endif
 	memset(&result, 0, sizeof(result));
 	memset(&command, 0, sizeof(command));
 	command.s.cword.ecc_gen = CVMX_BCH_INST_ECC_GENERATION;
@@ -235,9 +278,15 @@ int cvmx_bch_encode(const void *block, uint16_t block_size,
 	command.s.cword.size = block_size;
 
 	command.s.oword.ptr = cvmx_ptr_to_phys(ecc);
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#if USE_BOUNCE_BUFF
+	command.s.iword.ptr = cvmx_ptr_to_phys((void *)bounce_buff);
+#else
 	command.s.iword.ptr = cvmx_ptr_to_phys((void *)block);
+#endif
+#endif
 	command.s.resp.ptr = cvmx_ptr_to_phys((void *)response);
-	debug("Command: cword: 0x%llx, oword: 0x%llx, iword: 0x%llx, resp: 0x%llx\n",
+	debug("Cmd: cword:0x%llx, oword:0x%llx, iword:0x%llx, resp:0x%llx\n",
 	      command.u64[0], command.u64[1], command.u64[2], command.u64[3]);
 	result = cvmx_cmd_queue_write(CVMX_CMD_QUEUE_BCH, 1,
 				      sizeof(command) / sizeof(uint64_t),
@@ -263,9 +312,9 @@ EXPORT_SYMBOL(cvmx_bch_encode);
  * @param ecc_level		Number of errors that must be corrected.  The
  *				number of parity bytes is equal to
  *				((15 * ecc_level) + 7) / 8.
- * 				Must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
+ *				Must be 4, 8, 16, 24, 32, 40, 48, 56, 60 or 64.
  * @param[out] block_out	8-byte aligned pointer to corrected data buffer.
- * 				This should not be the same as block_ecc_in.
+ *				This should not be the same as block_ecc_in.
  * @param[in] response		pointer to where responses will be written.
  *
  * @return Zero on success, negative on failure.
@@ -286,9 +335,9 @@ int cvmx_bch_decode(const void *block_ecc_in, uint16_t block_size,
 	command.s.cword.size = block_size;
 
 	command.s.oword.ptr = cvmx_ptr_to_phys((void *)block_out);
- 	command.s.iword.ptr = cvmx_ptr_to_phys((void *)block_ecc_in);
+	command.s.iword.ptr = cvmx_ptr_to_phys((void *)block_ecc_in);
 	command.s.resp.ptr = cvmx_ptr_to_phys((void *)response);
-	debug("Command: cword: 0x%llx, oword: 0x%llx, iword: 0x%llx, resp: 0x%llx\n",
+	debug("Cmd: cword:0x%llx, oword:0x%llx, iword:0x%llx, resp:0x%llx\n",
 	      command.u64[0], command.u64[1], command.u64[2], command.u64[3]);
 	result = cvmx_cmd_queue_write(CVMX_CMD_QUEUE_BCH, 1,
 				      sizeof(command) / sizeof(uint64_t),
diff --git a/arch/mips/cavium-octeon/executive/cvmx-nand.c b/arch/mips/cavium-octeon/executive/cvmx-nand.c
index 80c230c..62dd1ad 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-nand.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-nand.c
@@ -46,7 +46,10 @@
  * <hr>$Revision: 35726 $<hr>
  */
 
+
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+# include <asm/octeon/cvmx.h>
+# include <asm/octeon/cvmx-config.h>
 #include <linux/export.h>
 #include <linux/module.h>
 #include <asm/octeon/octeon.h>
@@ -104,16 +107,16 @@
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 #undef min
-#define min(X, Y)                               \
-        ({ typeof (X) __x = (X);                \
-           typeof (Y) __y = (Y);                \
-                (__x < __y) ? __x : __y; })
+#define min(X, Y)				\
+	({ typeof(X) __x = (X);		\
+	typeof(Y) __y = (Y);			\
+	(__x < __y) ? __x : __y; })
 
 #undef max
 #define max(X, Y)                               \
-        ({ typeof (X) __x = (X);                \
-           typeof (Y) __y = (Y);                \
-                (__x > __y) ? __x : __y; })
+	({ typeof(X) __x = (X);                \
+	typeof(Y) __y = (Y);			\
+	(__x > __y) ? __x : __y; })
 #endif
 /* Structure to store the parameters that we care about that
 ** describe the ONFI speed modes.  This is used to configure
@@ -204,15 +207,17 @@ static CVMX_SHARED const char *cvmx_nand_opcode_labels[] = {
 #ifdef CVMX_NAND_RUNTIME_DEBUG
 /* This macro logs out whenever a function is called if debugging is on */
 #define CVMX_NAND_LOG_CALLED() \
+	do {								\
 	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
-		cvmx_dprintf("%*s%s: called\n", 2*debug_indent++, "", __func__);
+		cvmx_dprintf("%*s%s: called\n", 2*debug_indent++, "", __func__);\
+	} while (0)
 
 /* This macro logs out each function parameter if debugging is on */
 #define CVMX_NAND_LOG_PARAM(format, param) \
 	do {								\
 		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
 			cvmx_dprintf("%*s%s: param %s = " format "\n", 2*debug_indent, "", __func__, #param, param); \
-	} while(0)
+	} while (0)
 
 /* This macro logs out when a function returns a value */
 #define CVMX_NAND_RETURN(v)						\
@@ -353,7 +358,7 @@ static inline int __cvmx_nand_get_column_bits(int chip)
  */
 static inline int __cvmx_fls(int x)
 {
-	return (sizeof(x) * 8 - __builtin_clz(x));
+	return sizeof(x) * 8 - __builtin_clz(x);
 }
 
 /**
@@ -959,34 +964,41 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 					break;
 				}
 
-				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
+				if (cvmx_unlikely(cvmx_nand_flags &
+					CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
 					nand_debug("%s: Samsung NAND chip detected, using parameters decoded from ID bytes.\n",
 						     __func__);
-					nand_debug("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, part size: %d MBytes, timing mode: %d\n",
-						     __func__,
-						     cvmx_nand_state[chip].page_size,
-						     cvmx_nand_state[chip].oob_size,
-						     cvmx_nand_state[chip].pages_per_block,
-						     (int)(nand_size_bits / (8 * 1024 * 1024)),
-						     cvmx_nand_state[chip].onfi_timing);
+					nand_debug(
+						"%s: Defaults: page size: %d, OOB size: %d, pages per block %d, part size: %d MBytes, timing mode: %d\n",
+						__func__,
+						cvmx_nand_state[chip].page_size,
+						cvmx_nand_state[chip].oob_size,
+						cvmx_nand_state[chip].pages_per_block,
+						(int)(nand_size_bits / (8 * 1024 * 1024)),
+						cvmx_nand_state[chip].onfi_timing);
 					nand_debug("%s: Address cycles: %d, column bits: %d, row bits: %d, block count: %d\n",
-						     __func__,
-						     __cvmx_nand_get_address_cycles(chip),
-						     __cvmx_nand_get_column_bits(chip),
-						     __cvmx_nand_get_row_bits(chip),
-						     cvmx_nand_state[chip].blocks);
+						__func__,
+						__cvmx_nand_get_address_cycles(chip),
+						__cvmx_nand_get_column_bits(chip),
+						__cvmx_nand_get_row_bits(chip),
+						cvmx_nand_state[chip].blocks);
 				}
 
 				__set_onfi_timing_mode(cvmx_nand_state[chip].tim_par,
-						       clocks_us,
-						       cvmx_nand_state[chip].onfi_timing);
-				if (cvmx_nand_state[chip].page_size + cvmx_nand_state[chip].oob_size > CVMX_NAND_MAX_PAGE_AND_OOB_SIZE) {
-					nand_debug("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
-						     __func__,
-						     cvmx_nand_state[chip].page_size,
-						     cvmx_nand_state[chip].oob_size,
-						     CVMX_NAND_MAX_PAGE_AND_OOB_SIZE);
-					__cvmx_nand_select(nand_selected);
+					clocks_us,
+					cvmx_nand_state[chip].onfi_timing);
+				if (cvmx_nand_state[chip].page_size
+					+ cvmx_nand_state[chip].oob_size
+					> CVMX_NAND_MAX_PAGE_AND_OOB_SIZE) {
+					nand_debug(
+						"%s: ERROR: Page size (%d) + "
+						"OOB size (%d) is greater than"
+						" max size (%d)\n",
+						__func__,
+						cvmx_nand_state[chip].page_size,
+						cvmx_nand_state[chip].oob_size,
+						CVMX_NAND_MAX_PAGE_AND_OOB_SIZE);
+						__cvmx_nand_select(nand_selected);
 					return CVMX_NAND_ERROR;
 				}
 
@@ -1007,8 +1019,11 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 			__set_chip_defaults(chip, clocks_us);
 		} else {
 
-			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
-				nand_debug("%s: Unable to determine NAND parameters, and no defaults supplied.\n",
+			if (cvmx_unlikely(cvmx_nand_flags &
+					CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+				nand_debug(
+					"%s:Unable to determine NAND parameters"
+					", and no defaults supplied.\n",
 					     __func__);
 		}
 	}
@@ -1150,9 +1165,8 @@ cvmx_nand_status_t cvmx_nand_submit(cvmx_nand_cmd_t cmd)
 		break;
 
 	case 11:		/* Wait status commands take two 64bit words */
-		if (__cvmx_nand_get_free_cmd_bytes() < 16) {
+		if (__cvmx_nand_get_free_cmd_bytes() < 16)
 			CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
-		}
 		cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
 		cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[0]);
 		break;
@@ -1175,16 +1189,17 @@ cvmx_nand_status_t cvmx_nand_submit(cvmx_nand_cmd_t cmd)
  *                  Data to be put on the bus. It is translated according to
  *                  the rules in the file information section.
  *
- * @param cmd_data2 If non zero, adds a second CLE cycle used by a number of NAND
- *                  transactions.
+ * @param cmd_data2 If non zero, adds a second CLE cycle used by a number of
+ *                  NAND transactions.
  *
  * @return Zero on success, a negative cvmx_nand_status_t error code on failure
  */
-static inline cvmx_nand_status_t __cvmx_nand_build_pre_cmd(int chip,
-							   int cmd_data,
-							   int num_address_cycles,
-							   uint64_t nand_address,
-							   int cmd_data2)
+static inline cvmx_nand_status_t __cvmx_nand_build_pre_cmd(
+		int chip,
+		int cmd_data,
+		int num_address_cycles,
+		uint64_t nand_address,
+		int cmd_data2)
 {
 	cvmx_nand_status_t result;
 	cvmx_nand_cmd_t cmd;
@@ -1220,7 +1235,8 @@ static inline cvmx_nand_status_t __cvmx_nand_build_pre_cmd(int chip,
 	cmd.chip_en.chip = chip;
 	cmd.chip_en.one = 1;
 	cmd.chip_en.three = 3;
-	cmd.chip_en.width = (cvmx_nand_state[chip].flags & CVMX_NAND_STATE_16BIT) ? 2 : 1;
+	cmd.chip_en.width =
+		(cvmx_nand_state[chip].flags & CVMX_NAND_STATE_16BIT) ? 2 : 1;
 	result = cvmx_nand_submit(cmd);
 	if (result)
 		CVMX_NAND_RETURN(result);
@@ -1258,7 +1274,8 @@ static inline cvmx_nand_status_t __cvmx_nand_build_pre_cmd(int chip,
 		} else {
 			int column_bits = __cvmx_nand_get_column_bits(chip);
 			int column_shift = ((column_bits + 7) >> 3) << 3;
-			int column = nand_address & (cvmx_nand_state[chip].page_size - 1);
+			int column = nand_address &
+					(cvmx_nand_state[chip].page_size - 1);
 			int row = nand_address >> column_bits;
 			cmd.ale.adr_bytes_l = column + (row << column_shift);
 			cmd.ale.adr_bytes_h = row >> (32 - column_shift);
@@ -1341,14 +1358,17 @@ static inline void __cvmx_nand_setup_dma(int chip, int is_write,
 	CVMX_NAND_LOG_PARAM("%d", is_write);
 	CVMX_NAND_LOG_PARAM("0x%llx", CAST_ULL(buffer_address));
 	CVMX_NAND_LOG_PARAM("%d", buffer_length);
+
 	ndf_dma_cfg.u64 = 0;
 	ndf_dma_cfg.s.en = 1;
-	ndf_dma_cfg.s.rw = is_write;	/* One means DMA reads from memory and writes to flash */
+	/* is_write - one means DMA reads from memory and writes to flash */
+	ndf_dma_cfg.s.rw = is_write;
 	ndf_dma_cfg.s.clr = 0;
 	ndf_dma_cfg.s.size = ((buffer_length + 7) >> 3) - 1;
 	ndf_dma_cfg.s.adr = buffer_address;
 	CVMX_SYNCWS;
 	cvmx_write_csr(CVMX_MIO_NDF_DMA_CFG, ndf_dma_cfg.u64);
+
 	CVMX_NAND_RETURN_NOTHING();
 }
 
@@ -1489,6 +1509,7 @@ static inline int __cvmx_nand_low_level_read(int chip,
 		goto error;
 
 	WATCHDOG_RESET();
+
 	/* Wait for the DMA to complete */
 	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_NDF_DMA_CFG,
 				  union cvmx_mio_ndf_dma_cfg,
@@ -1562,7 +1583,6 @@ int cvmx_nand_page_read(int chip, uint64_t nand_address,
 					   buffer_address, buffer_length);
 	CVMX_NAND_RETURN(bytes);
 }
-
 EXPORT_SYMBOL(cvmx_nand_page_read);
 
 /**
@@ -1748,9 +1768,9 @@ cvmx_nand_status_t cvmx_nand_block_erase(int chip, uint64_t nand_address)
 	nand_selected = __cvmx_nand_select(1);
 	/* Build the command and address cycles */
 	status = __cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_ERASE,
-					   (__cvmx_nand_get_row_bits(chip) + 7) >> 3,
-					   nand_address >> __cvmx_nand_get_column_bits(chip),
-					   NAND_COMMAND_ERASE_FIN);
+			(__cvmx_nand_get_row_bits(chip) + 7) >> 3,
+			nand_address >> __cvmx_nand_get_column_bits(chip),
+			NAND_COMMAND_ERASE_FIN);
 	if (status)
 		goto done;
 
@@ -1766,7 +1786,7 @@ cvmx_nand_status_t cvmx_nand_block_erase(int chip, uint64_t nand_address)
 	/* Wait for the command queue to be idle, which means the wait is done */
 	WATCHDOG_RESET();
 	if (CVMX_WAIT_FOR_FIELD64(CVMX_NDF_ST_REG, union cvmx_ndf_st_reg,
-				  exe_idle, ==, 1, NAND_TIMEOUT_USECS_BLOCK_ERASE)) {
+			exe_idle, ==, 1, NAND_TIMEOUT_USECS_BLOCK_ERASE)) {
 		WATCHDOG_RESET();
 		status = CVMX_NAND_TIMEOUT;
 		goto done;
@@ -1795,12 +1815,12 @@ static void __cvmx_nand_fixup_16bit_id_reads(uint8_t *buf, int buffer_length)
  *
  * @param chip   Chip select for NAND flash
  * @param nand_address
- *               NAND address to read ID from. Usually this is either 0x0 or 0x20.
+ *               NAND address to read ID from. Usually this is either 0 or 0x20.
  * @param buffer_address
  *               Physical address to store data in
  * @param buffer_length
- *               Length of the buffer. Usually this is 4-8 bytes.  For 16 bit mode, this must be twice
- *               as large as the actual expected data.
+ *               Length of the buffer. Usually this is 4-8 bytes.  For 16 bit
+ *               mode, this must be twice as large as the actual expected data.
  *
  * @return Bytes read on success, a negative cvmx_nand_status_t error code on failure
  */
@@ -1833,7 +1853,6 @@ int cvmx_nand_read_id(int chip, uint64_t nand_address, uint64_t buffer_address,
 
 	CVMX_NAND_RETURN(bytes);
 }
-
 EXPORT_SYMBOL(cvmx_nand_read_id);
 
 /**
diff --git a/arch/mips/cavium-octeon/octeon-nand.c b/arch/mips/cavium-octeon/octeon-nand.c
index 8eba9e2..63dd681 100644
--- a/arch/mips/cavium-octeon/octeon-nand.c
+++ b/arch/mips/cavium-octeon/octeon-nand.c
@@ -9,6 +9,13 @@
  * Copyright (C) 2008 - 2012 Cavium, Inc.
  */
 
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-nand.h>
+#include <asm/octeon/octeon.h>
+#include <asm/octeon/cvmx-bch.h>
+#include <asm/octeon/cvmx-bch-defs.h>
+#include <linux/ctype.h>
+
 #include <linux/module.h>
 #include <linux/device.h>
 #include <linux/semaphore.h>
@@ -22,12 +29,6 @@
 #include <linux/slab.h>
 #include <net/irda/parameters.h>
 
-#include <asm/octeon/cvmx.h>
-#include <asm/octeon/cvmx-nand.h>
-#include <asm/octeon/octeon.h>
-#include <asm/octeon/cvmx-bch.h>
-#include <asm/octeon/cvmx-bch-defs.h>
-#include <linux/ctype.h>
 
 #define DRIVER_NAME "octeon-nand"
 
@@ -42,7 +43,7 @@
 
 #define MAX_NAND_NAME_LEN       20
 
-static const char *part_probes[] = { "cmdlinepart", NULL };
+static const char * const part_probes[] = { "cmdlinepart", NULL };
 
 #define DEV_DBG(_level, _dev, _format, _arg...)	do {			\
 	if (unlikely(debug & (_level)))					\
@@ -58,7 +59,7 @@ struct octeon_nand {
 	struct mtd_info mtd;
 	struct nand_chip nand;
 	/* Temporary location to store read data, must be 64 bit aligned */
-	uint8_t data[NAND_MAX_PAGESIZE + NAND_MAX_OOBSIZE] __attribute__((__aligned__(8)));
+	uint8_t data[NAND_MAX_PAGESIZE + NAND_MAX_OOBSIZE] __aligned(8);
 	uint8_t status;
 	int use_status;
 	int data_len;		/* Number of byte in the data buffer */
@@ -103,6 +104,7 @@ static struct octeon_nand *octeon_nand_open_mtd[8];
 static int octeon_nand_bch_correct(struct mtd_info *mtd, u_char *dat,
 				   u_char *read_ecc, u_char *isnull);
 
+
 /*
  * Read a single byte from the temporary buffer. Used after READID
  * to get the NAND information.
@@ -112,7 +114,7 @@ static uint8_t octeon_nand_read_byte(struct mtd_info *mtd)
 	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
 
 	if (priv->use_status) {
-		DEV_DBG(DEBUG_READ, priv->dev, 
+		DEV_DBG(DEBUG_READ, priv->dev,
 			"returning status: 0x%x\n", priv->status);
 		return priv->status;
 	}
@@ -168,7 +170,7 @@ static void octeon_nand_write_buf(struct mtd_info *mtd, const uint8_t *buf,
 		memset(priv->data + priv->data_len, 0xff,
 			sizeof(priv->data) - priv->data_len);
 	} else {
-		printk("Not enough data to write %d bytes\n", len);
+		dev_err(priv->dev, "Not enough data to write %d bytes\n", len);
 	}
 }
 
@@ -233,7 +235,8 @@ static int octeon_nand_hw_bch_read_page(struct mtd_info *mtd,
 	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
 		int stat;
 
-		DEV_DBG(DEBUG_READ, priv->dev, "Correcting block offset %ld, ecc offset %d\n",
+		DEV_DBG(DEBUG_READ, priv->dev,
+			"Correcting block offset %ld, ecc offset %d\n",
 			p - buf, i);
 		stat = chip->ecc.correct(mtd, p, &ecc_code[i], NULL);
 		if (stat < 0) {
@@ -261,16 +264,22 @@ static int octeon_nand_hw_bch_write_page(struct mtd_info *mtd,
 
 	DEV_DBG(DEBUG_WRITE, priv->dev, "%s(%p, %p, %p, %d)\n", __func__, mtd,
 		chip, buf, oob_required);
+	for (i = 0; i < chip->ecc.total; i++)
+		ecc_calc[i] = 0xFF;
 
 	/* Hardware ECC calculation */
 	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
 		int ret;
+
 		ret = chip->ecc.calculate(mtd, p, &ecc_calc[i]);
+
 		if (ret < 0)
-			DEV_DBG(DEBUG_WRITE, priv->dev, "=== chip->ecc.calculate(mtd, p=%p, &ecc_calc[i]) returned %d\n", p, ret);
-		
-		DEV_DBG(DEBUG_WRITE, priv->dev, "block offset %ld, ecc offset %d\n",
-			p - buf, i);
+			DEV_DBG(DEBUG_WRITE, priv->dev,
+				"calculate(mtd, p, &ecc_calc[i]) returned %d\n",
+				ret);
+
+		DEV_DBG(DEBUG_WRITE, priv->dev,
+			"block offset %ld, ecc offset %d\n", p - buf, i);
 	}
 
 	for (i = 0; i < chip->ecc.total; i++)
@@ -384,6 +393,7 @@ static void octeon_nand_cmdfunc(struct mtd_info *mtd, unsigned command,
 
 	down(&octeon_bootbus_sem);
 	priv->use_status = 0;
+
 	switch (command) {
 	case NAND_CMD_READID:
 		DEV_DBG(DEBUG_CONTROL, priv->dev, "READID\n");
@@ -411,7 +421,8 @@ static void octeon_nand_cmdfunc(struct mtd_info *mtd, unsigned command,
 		 */
 		priv->data_len = cvmx_nand_page_read(priv->selected_chip,
 					(page_addr << nand->page_shift) +
-					(1 << nand->page_shift) - priv->data_index,
+					(1 << nand->page_shift) -
+					priv->data_index,
 					virt_to_phys(priv->data),
 					mtd->oobsize + priv->data_index);
 		if (priv->data_len < mtd->oobsize + priv->data_index) {
@@ -457,6 +468,7 @@ static void octeon_nand_cmdfunc(struct mtd_info *mtd, unsigned command,
 		DEV_DBG(DEBUG_CONTROL, priv->dev, "STATUS\n");
 		priv->status = cvmx_nand_get_status(priv->selected_chip);
 		priv->use_status = 1;
+
 		break;
 
 	case NAND_CMD_SEQIN:
@@ -519,25 +531,28 @@ static void octeon_nand_cmdfunc(struct mtd_info *mtd, unsigned command,
  * Return 0 on success or -1 on failure
  */
 static int octeon_nand_bch_calculate_ecc_internal(struct octeon_nand *priv,
-						  const unsigned char *buf,
-						  unsigned char *code)
+						  const uint8_t *buf,
+						  uint8_t *code)
 {
 	struct nand_chip *nand_chip = &priv->nand;
-	volatile static cvmx_bch_response_t response;
+	static volatile cvmx_bch_response_t response;
 	int rc;
 	int i;
-	void *ecc_ptr;
-	uint8_t ecc_buffer[nand_chip->ecc.bytes] __attribute__((__aligned__(8)));
+	static uint8_t *ecc_buffer;
 
-	if ((ulong)code % 8) {
-		ecc_ptr = ecc_buffer;
-	} else
-		ecc_ptr = code;
+	if (!ecc_buffer)
+		ecc_buffer = kmalloc(1024, GFP_KERNEL);
+	if ((ulong)buf % 8)
+		dev_err(priv->dev, "ECC buffer not aligned!");
+
+	memset(ecc_buffer, 0, nand_chip->ecc.bytes);
 
 	response.u16 = 0;
 
-	rc = cvmx_bch_encode(buf, nand_chip->ecc.size, nand_chip->ecc.strength,
-			     ecc_ptr, &response);
+
+	rc = cvmx_bch_encode((void *)buf, nand_chip->ecc.size,
+			     nand_chip->ecc.strength,
+			     (void *)ecc_buffer, &response);
 
 	if (rc) {
 		dev_err(priv->dev, "octeon_bch_encode failed\n");
@@ -547,8 +562,9 @@ static int octeon_nand_bch_calculate_ecc_internal(struct octeon_nand *priv,
 	udelay(10);
 
 	if (!response.s.done) {
-		DEV_DBG(DEBUG_ALL, priv->dev, "octeon_bch_encode timed out, response done: %d, \
-			 uncorrectable: %d, num_errors: %d, erased: %d\n",
+		DEV_DBG(DEBUG_ALL, priv->dev,
+			"octeon_bch_encode timed out, response done: %d, "
+			 "uncorrectable: %d, num_errors: %d, erased: %d\n",
 			response.s.done, response.s.uncorrectable,
 			response.s.num_errors, response.s.erased);
 		cvmx_bch_shutdown();
@@ -556,9 +572,7 @@ static int octeon_nand_bch_calculate_ecc_internal(struct octeon_nand *priv,
 		return -1;
 	}
 
-	if ((ulong)code % 8) {
-		memcpy(code, ecc_buffer, nand_chip->ecc.bytes);
-	}
+	memcpy(code, ecc_buffer, nand_chip->ecc.bytes);
 
 	for (i = 0; i < nand_chip->ecc.bytes; i++)
 		code[i] ^= priv->eccmask[i];
@@ -574,11 +588,15 @@ static int octeon_nand_bch_calculate_ecc_internal(struct octeon_nand *priv,
  * ecc_code:   buffer for ECC
  */
 static int octeon_nand_bch_calculate(struct mtd_info *mtd,
-		const u_char *dat, unsigned char *ecc_code)
+		const uint8_t *dat, uint8_t *ecc_code)
 {
+	int ret;
 	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
 
-	return octeon_nand_bch_calculate_ecc_internal(priv, dat, ecc_code);
+	ret = octeon_nand_bch_calculate_ecc_internal(
+					priv, (void *)dat, (void *)ecc_code);
+
+	return ret;
 }
 
 
@@ -597,26 +615,27 @@ static int octeon_nand_bch_correct(struct mtd_info *mtd, u_char *dat,
 {
 	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
 	struct nand_chip *nand_chip = &priv->nand;
-	volatile static cvmx_bch_response_t response;
+	static volatile cvmx_bch_response_t response;
 	int rc;
 	int i = nand_chip->ecc.size + nand_chip->ecc.bytes;
-	static uint8_t *data_buffer = NULL;
-	static int buffer_size = 0;
+	static uint8_t *data_buffer;
+	static int buffer_size;
 	int max_time = 100;
 
 	if (i > buffer_size) {
-		if (data_buffer)
-			kfree(data_buffer);
+		kfree(data_buffer);
 		data_buffer = kmalloc(i, GFP_KERNEL);
 		if (!data_buffer) {
-			dev_err(priv->dev, "%s: Could not allocate %d bytes for buffer\n",
+			dev_err(priv->dev,
+				"%s: Could not allocate %d bytes for buffer\n",
 				__func__, i);
 			goto error;
 		}
 	}
 
 	memcpy(data_buffer, dat, nand_chip->ecc.size);
-	memcpy(data_buffer + nand_chip->ecc.size, read_ecc, nand_chip->ecc.bytes);
+	memcpy(data_buffer + nand_chip->ecc.size, read_ecc,
+							nand_chip->ecc.bytes);
 
 	for (i = 0; i < nand_chip->ecc.bytes; i++)
 		data_buffer[nand_chip->ecc.size + i] ^= priv->eccmask[i];
@@ -773,9 +792,10 @@ static int octeon_read_extended_parameters(struct octeon_nand *priv)
 
 	down(&octeon_bootbus_sem);
 	if (cvmx_nand_read_param_page(priv->selected_chip,
-				      cvmx_ptr_to_phys(priv->data), 1024) != 1024) {
-		dev_err(priv->dev, "Could not read extended parameters from NAND chip %d\n",
-		       priv->selected_chip);
+			      cvmx_ptr_to_phys(priv->data), 1024) != 1024) {
+		dev_err(priv->dev,
+			"Could not read extended parameters from NAND chip %d\n",
+			priv->selected_chip);
 		up(&octeon_bootbus_sem);
 		return -1;
 	}
@@ -791,13 +811,13 @@ static int octeon_read_extended_parameters(struct octeon_nand *priv)
 			continue;
 
 		if (octeon_onfi_crc16(ONFI_CRC_BASE,
-				      (uint8_t *)hdr->sig, size - 2) == le16_to_cpu(hdr->crc))
+			(uint8_t *)hdr->sig, size - 2) == le16_to_cpu(hdr->crc))
 			break;
 		hdr = calc_next_ext_page(hdr, &offset);
 	} while (hdr);
 
-	DEV_DBG(DEBUG_ALL, priv->dev, "Found valid extended parameter page at offset %d\n",
-		offset);
+	DEV_DBG(DEBUG_ALL, priv->dev,
+		"Found valid extended parameter page at offset %d\n", offset);
 
 	/* Since the types are always in order then section type 2 for
 	 * extended ECC information must be within the first two entries.
@@ -807,7 +827,8 @@ static int octeon_read_extended_parameters(struct octeon_nand *priv)
 		if (hdr->section_types[i].type == NAND_EXTENDED_ECC)
 			break;
 		if (hdr->section_types[i].type == NAND_EXTENDED_UNUSED) {
-			dev_err(priv->dev, "%s: No ECC section found\n", __func__);
+			dev_err(priv->dev,
+				"%s: No ECC section found\n", __func__);
 			return 0;
 		}
 
@@ -817,16 +838,18 @@ static int octeon_read_extended_parameters(struct octeon_nand *priv)
 	ecc_info = (struct nand_extended_ecc_info *)
 					(((uint8_t *)(hdr + 1)) + offset);
 
-	DEV_DBG(DEBUG_ALL, priv->dev, "Found extended ecc header at offset %d in header\n", offset);
+	DEV_DBG(DEBUG_ALL, priv->dev,
+		"Found extended ecc header at offset %d in header\n", offset);
 	priv->nand.ecc.strength = ecc_info->ecc_bits;
 	priv->nand.ecc.size = 1 << ecc_info->ecc_size;
 	if (priv->nand.ecc.strength < 0 || priv->nand.ecc.size > 2048) {
-		DEV_DBG(DEBUG_ALL, priv->dev, "NAND ecc size of %d or strength %d not supported\n",
-		       ecc_info->ecc_bits, priv->nand.ecc.size);
+		DEV_DBG(DEBUG_ALL, priv->dev,
+			"NAND ecc size of %d or strength %d not supported\n",
+			ecc_info->ecc_bits, priv->nand.ecc.size);
 		return -1;
 	}
-	DEV_DBG(DEBUG_ALL, priv->dev, "%s: ecc strength: %d, ecc size: %d\n", __func__,
-	      priv->nand.ecc.strength, priv->nand.ecc.size);
+	DEV_DBG(DEBUG_ALL, priv->dev, "%s: ecc strength: %d, ecc size: %d\n",
+		__func__, priv->nand.ecc.strength, priv->nand.ecc.size);
 
 	return 0;
 }
@@ -860,15 +883,18 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 	if (cvmx_nand_read_param_page(priv->selected_chip,
 				      cvmx_ptr_to_phys(priv->data),
 				      256 * 3) < 256 * 3) {
-		DEV_DBG(DEBUG_ALL, priv->dev, "%s: Error reading ONFI parameter data for chip %d\n",
+		DEV_DBG(DEBUG_ALL, priv->dev,
+			"%s: Error reading ONFI parameter data for chip %d\n",
 		       __func__, priv->selected_chip);
 		goto out;
 	}
 
 	onfi_params =
-		cvmx_nand_onfi_process((cvmx_nand_onfi_param_page_t *)priv->data);
+		cvmx_nand_onfi_process(
+			(cvmx_nand_onfi_param_page_t *)priv->data);
 	if (!onfi_params) {
-		DEV_DBG(DEBUG_ALL, priv->dev, "%s: Invalid ONFI parameter data for chip %d\n",
+		DEV_DBG(DEBUG_ALL, priv->dev,
+			"%s: Invalid ONFI parameter data for chip %d\n",
 			__func__, priv->selected_chip);
 		goto out;
 	}
@@ -879,8 +905,10 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 	       sizeof(struct nand_onfi_params));
 
 	priv->nand.onfi_version =
-		revision_decode[fls(le16_to_cpu(priv->nand.onfi_params.revision))];
-	DEV_DBG(DEBUG_ALL, priv->dev, "ONFI revision %d\n", priv->nand.onfi_version);
+		revision_decode[
+			fls(le16_to_cpu(priv->nand.onfi_params.revision))];
+	DEV_DBG(DEBUG_ALL, priv->dev,
+		"ONFI revision %d\n", priv->nand.onfi_version);
 
 	priv->nand.page_shift =
 		fls(le32_to_cpu(priv->nand.onfi_params.byte_per_page)) - 1;
@@ -898,10 +926,12 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 		priv->nand.ecc.bytes = 3;
 		priv->nand.ecc.size = 256;
 		priv->nand.ecc.strength = 1;
-		DEV_DBG(DEBUG_ALL, priv->dev, "NAND chip %d using single bit ECC\n",
+		DEV_DBG(DEBUG_ALL, priv->dev,
+			"NAND chip %d using single bit ECC\n",
 		      priv->selected_chip);
 	} else if (octeon_has_feature(OCTEON_FEATURE_BCH)) {
-		DEV_DBG(DEBUG_ALL, priv->dev, "Using hardware ECC syndrome support\n");
+		DEV_DBG(DEBUG_ALL, priv->dev,
+			"Using hardware ECC syndrome support\n");
 		priv->nand.ecc.mode = NAND_ECC_HW_SYNDROME;
 		priv->nand.ecc.strength = priv->nand.onfi_params.ecc_bits;
 		priv->nand.ecc.read_page = octeon_nand_hw_bch_read_page;
@@ -914,16 +944,15 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 			/* If 0xff then we need to access the extended parameter
 			 * page.
 			 */
-			if (octeon_read_extended_parameters(priv)) {
+			if (octeon_read_extended_parameters(priv))
 				return -1;
-			}
 		} else {
 			priv->nand.ecc.size = 512;
 		}
 
 		{
 		/*
-		 * nand.ecc.strength will be used as ecc_level so 
+		 * nand.ecc.strength will be used as ecc_level so
 		 * it should be in {4, 8, 16, 24, 32, 40, 48, 56, 60, 64}
 		 * needed ecc_bytes for m=15 (hardcoded in NAND controller)
 		 */
@@ -933,34 +962,47 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 		 * per above ecc_lvls {4,8, 16...64} are
 		 */
 		int ecc_bytes[] = {8, 15, 30, 45, 60, 75, 90, 105, 113, 120};
-		int ecc_totalbytes[] = {32, 60, 120, 180, 240, 300, 360, 420, 452, 480};
-		/* first set the desired ecc_level to match ecc_lvls[] */ 
+		int ecc_totalbytes[] = {
+			32, 60, 120, 180, 240, 300, 360, 420, 452, 480};
+		/* first set the desired ecc_level to match ecc_lvls[] */
 		int index = /* 0..9 */
 			(priv->nand.ecc.strength >= 64) ? 9/*64*/ :
-			(priv->nand.ecc.strength > 56 && priv->nand.ecc.strength <= 60) ? 8/*60*/ :
-			(priv->nand.ecc.strength > 48 && priv->nand.ecc.strength <= 56) ? 7/*56*/ :
-			(priv->nand.ecc.strength > 40 && priv->nand.ecc.strength <= 48) ? 6/*48*/ :
-			(priv->nand.ecc.strength > 32 && priv->nand.ecc.strength <= 40) ? 5/*40*/ :
-			(priv->nand.ecc.strength > 48 && priv->nand.ecc.strength <= 32) ? 4/*32*/ :
-			(priv->nand.ecc.strength > 16 && priv->nand.ecc.strength <= 24) ? 3/*24*/ :
-			(priv->nand.ecc.strength >  8 && priv->nand.ecc.strength <= 16) ? 2/*16*/ :
-			(priv->nand.ecc.strength >  4 && priv->nand.ecc.strength <=  8) ? 1/*8*/ :
-			(priv->nand.ecc.strength >  1 && priv->nand.ecc.strength <=  4) ? 0/*4*/: 0;
+			(priv->nand.ecc.strength > 56 &&
+				priv->nand.ecc.strength <= 60) ? 8/*60*/ :
+			(priv->nand.ecc.strength > 48 &&
+				priv->nand.ecc.strength <= 56) ? 7/*56*/ :
+			(priv->nand.ecc.strength > 40 &&
+				priv->nand.ecc.strength <= 48) ? 6/*48*/ :
+			(priv->nand.ecc.strength > 32 &&
+				priv->nand.ecc.strength <= 40) ? 5/*40*/ :
+			(priv->nand.ecc.strength > 48 &&
+				priv->nand.ecc.strength <= 32) ? 4/*32*/ :
+			(priv->nand.ecc.strength > 16 &&
+				priv->nand.ecc.strength <= 24) ? 3/*24*/ :
+			(priv->nand.ecc.strength >  8 &&
+				priv->nand.ecc.strength <= 16) ? 2/*16*/ :
+			(priv->nand.ecc.strength >  4 &&
+				priv->nand.ecc.strength <=  8) ? 1/*8*/ :
+			(priv->nand.ecc.strength >  1 &&
+				priv->nand.ecc.strength <=  4) ? 0/*4*/: 0;
 		/*
-		 * ..then check if there is enough space in OOB to store ECC bytes 
-		 * and eventualy (if not) change ecc.strenght the the best possible value
+		 * ..then check if there is enough space in OOB to store
+		 * ECC bytes and eventualy (if not) change ecc.strenght
+		 * the the best possible value
 		 */
-		if (ecc_totalbytes[index] <= cvmx_nand_get_oob_size(priv->selected_chip) - 2) {
+		if (ecc_totalbytes[index] <=
+			cvmx_nand_get_oob_size(priv->selected_chip) - 2) {
 			priv->nand.ecc.strength = ecc_lvls[index];
 			priv->nand.ecc.bytes = ecc_bytes[index];
 		} else {
 			int i = 9;
-			while (ecc_totalbytes[i] > cvmx_nand_get_oob_size(priv->selected_chip))
+			while (ecc_totalbytes[i] >
+				cvmx_nand_get_oob_size(priv->selected_chip))
 				i--;
 			priv->nand.ecc.strength = ecc_lvls[i];
 			priv->nand.ecc.bytes = ecc_bytes[i];
 		}
-		
+
 		/*
 		 * strength=24 needs total of ecc.bytes=180 for 4k page
 		 * strength=32 needs total of ecc.bytes=240 for 4k page
@@ -968,7 +1010,7 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 		 * ecc.strength=24 ,ecc.bytes=45 and ecc_totalbytes=180
 		 */
 		}
-		
+
 		/* The number of ECC bits required is m * t
 		 * where (2^m) - 1 > bits per ecc block and
 		 * t is the number of correctible bits.  So if
@@ -982,12 +1024,15 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 		 * OCTEON requires ((15 * t) + 7) / 8
 		 */
 		priv->nand.ecc.bytes = ((15 * priv->nand.ecc.strength) + 7) / 8;
-		
-		priv->nand.ecc.steps = (1 << priv->nand.page_shift) / priv->nand.ecc.size;
+
+		priv->nand.ecc.steps = (1 << priv->nand.page_shift) /
+							priv->nand.ecc.size;
 		priv->nand.ecc.calculate = octeon_nand_bch_calculate;
 		priv->nand.ecc.correct = octeon_nand_bch_correct;
 		priv->nand.ecc.hwctl = octeon_nand_bch_hwctl;
-		DEV_DBG(DEBUG_INIT, priv->dev, "NAND chip %d using hw_bch ECC for %d bits of correction per %d byte block.  ECC size is %d bytes\n",
+		DEV_DBG(DEBUG_INIT, priv->dev,
+			"NAND chip %d using hw_bch ECC for %d bits of "
+			"correction per %d byte block.  ECC size is %d bytes\n",
 		      priv->selected_chip,
 		      priv->nand.ecc.strength,
 		      priv->nand.ecc.size,
@@ -1000,7 +1045,9 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 			 * page.
 			 */
 			if (octeon_read_extended_parameters(priv)) {
-				DEV_DBG(DEBUG_INIT, priv->dev, "%s: Error reading ONFI extended parameter data for chip %d\n",
+				DEV_DBG(DEBUG_INIT, priv->dev,
+					"%s: Error reading ONFI extended "
+					"parameter data for chip %d\n",
 				       __func__, priv->selected_chip);
 				return -1;
 			}
@@ -1017,10 +1064,13 @@ static int octeon_nand_scan_onfi(struct octeon_nand *priv)
 		 * total of 52 bits.  Rounding up this is 7
 		 * bytes.
 		 */
-		priv->nand.ecc.bytes = (((fls(priv->nand.ecc.size) - 1 + 3 + 1) *
-				    priv->nand.ecc.strength) + 7) / 8;
-		priv->nand.ecc.steps = (1 << priv->nand.page_shift) / priv->nand.ecc.size;
-		DEV_DBG(DEBUG_INIT, priv->dev, "NAND chip %d using soft_bch ECC for %d bits of correction per %d byte block.  ECC size is %d bytes\n",
+		priv->nand.ecc.bytes = (((fls(priv->nand.ecc.size) - 1 + 3 + 1)
+					* priv->nand.ecc.strength) + 7) / 8;
+		priv->nand.ecc.steps = (1 << priv->nand.page_shift) /
+							priv->nand.ecc.size;
+		DEV_DBG(DEBUG_INIT, priv->dev,
+			"NAND chip %d using soft_bch ECC for %d bits of "
+			"correction per %d byte block.  ECC size is %d bytes\n",
 		      priv->selected_chip,
 		      priv->nand.ecc.strength,
 		      priv->nand.ecc.size,
@@ -1064,9 +1114,9 @@ static int octeon_nand_calc_ecc_layout(struct octeon_nand *priv)
 	layout->eccbytes = chip->ecc.steps * chip->ecc.bytes;
 	/* Reserve 2 bytes for bad block marker */
 	if (layout->eccbytes + 2 > oobsize) {
-		DEV_DBG(DEBUG_INIT, priv->dev, "no suitable oob scheme available "
-		       "for oobsize %d eccbytes %u\n", oobsize,
-		       layout->eccbytes);
+		DEV_DBG(DEBUG_INIT, priv->dev,
+		"no suitable oob scheme available for oobsize %d eccbytes %u\n",
+		oobsize, layout->eccbytes);
 		goto fail;
 	}
 	/* put ecc bytes at oob tail */
@@ -1078,10 +1128,10 @@ static int octeon_nand_calc_ecc_layout(struct octeon_nand *priv)
 	chip->ecc.layout = layout;
 	priv->ecclayout = layout;
 
-	DEV_DBG(DEBUG_INIT, priv->dev, "  layout eccbytes: %d, free offset: %d, free length: %d\n",
-	      layout->eccbytes, layout->oobfree[0].offset,
-	      layout->oobfree[0].length);
-
+	DEV_DBG(DEBUG_INIT, priv->dev,
+		"  layout eccbytes: %d, free offset: %d, free length: %d\n",
+		layout->eccbytes, layout->oobfree[0].offset,
+		layout->oobfree[0].length);
 
 	return 0;
 
@@ -1133,9 +1183,10 @@ static int octeon_nand_hw_bch_init(struct octeon_nand *priv)
 	memset(priv->eccmask, 0, eccbytes);
 	memset(erased_ecc, 0, eccbytes);
 
-	if (octeon_nand_bch_calculate_ecc_internal(priv, erased_page, erased_ecc)) {
+	if (octeon_nand_bch_calculate_ecc_internal(
+		priv, erased_page, erased_ecc))
 		goto fail;
-	}
+
 	kfree(erased_page);
 
 	for (i = 0; i < eccbytes; i++)
@@ -1144,13 +1195,11 @@ static int octeon_nand_hw_bch_init(struct octeon_nand *priv)
 	return 0;
 
 fail:
-	if (priv->eccmask) {
-		kfree(priv->eccmask);
+	if (priv->eccmask)
 		priv->eccmask = NULL;
-	}
+	kfree(priv->eccmask);
 
-	if (erased_page)
-		kfree(erased_page);
+	kfree(erased_page);
 
 	if (rc)
 		cvmx_bch_shutdown();
-- 
2.6.2

