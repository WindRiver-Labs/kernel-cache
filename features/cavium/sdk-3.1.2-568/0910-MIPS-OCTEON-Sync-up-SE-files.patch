From 2c9078e0e593c0f2b80a0f06446ec168abd1812f Mon Sep 17 00:00:00 2001
From: Chandrakala Chavva <cchavva@caviumnetworks.com>
Date: Mon, 21 Jul 2014 18:05:50 -0700
Subject: [PATCH 910/974] MIPS:OCTEON: Sync-up SE files.

Signed-off-by: Chandrakala Chavva <cchavva@caviumnetworks.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/Makefile                                 |    9 +-
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c |  251 ++-
 .../mips/cavium-octeon/executive/cvmx-helper-cfg.c |    2 +-
 arch/mips/cavium-octeon/executive/cvmx-helper.c    |    6 +-
 arch/mips/cavium-octeon/executive/cvmx-pcie.c      |   41 +-
 arch/mips/cavium-octeon/executive/cvmx-qlm.c       |  122 +-
 arch/mips/include/asm/octeon/cvmx-gserx-defs.h     |  377 +++-
 arch/mips/include/asm/octeon/cvmx-ilk-defs.h       |   13 +-
 arch/mips/include/asm/octeon/cvmx-lmcx-defs.h      |  189 +-
 arch/mips/include/asm/octeon/cvmx-oclax-defs.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h   |    4 +-
 arch/mips/include/asm/octeon/cvmx-pexp-defs.h      |  659 ++++++
 arch/mips/include/asm/octeon/cvmx-qlm.h            |   25 +-
 arch/mips/include/asm/octeon/cvmx-sli-defs.h       |  780 +++----
 arch/mips/include/asm/octeon/cvmx-spemx-defs.h     | 2136 ++++++++++++++++++++
 15 files changed, 3943 insertions(+), 673 deletions(-)
 create mode 100644 arch/mips/include/asm/octeon/cvmx-spemx-defs.h

diff --git a/arch/mips/Makefile b/arch/mips/Makefile
index 51556db..c2f4059 100644
--- a/arch/mips/Makefile
+++ b/arch/mips/Makefile
@@ -178,11 +178,12 @@ cflags-y += -DCVMX_ENABLE_PARAMETER_CHECKING=1
 else
 cflags-y += -DCVMX_ENABLE_PARAMETER_CHECKING=0
 endif
-ifdef  CONFIG_CAVIUM_OCTEON_CHK_CVMX_ADDRESS
 cflags-y += -DCVMX_ENABLE_CSR_ADDRESS_CHECKING=1
-else
-cflags-y += -DCVMX_ENABLE_CSR_ADDRESS_CHECKING=0
-endif
+#ifdef  CONFIG_CAVIUM_OCTEON_CHK_CVMX_ADDRESS
+#cflags-y += -DCVMX_ENABLE_CSR_ADDRESS_CHECKING=1
+#else
+#cflags-y += -DCVMX_ENABLE_CSR_ADDRESS_CHECKING=0
+#endif
 ifdef  CONFIG_CAVIUM_OCTEON_CHK_CVMX_POW
 cflags-y += -DCVMX_ENABLE_POW_CHECKS=1
 else
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
index fd8b467..0e63ee7 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -115,7 +115,7 @@ int __cvmx_helper_bgx_enumerate(int xiface)
 	 * Check the QLM is configured correctly for SGMII, verify the
 	 * speed as well as the mode.
 	 */
-	qlm = cvmx_qlm_interface(xiface);
+	qlm = cvmx_qlm_lmac(xiface, 0);
 	if (qlm == -1)
 		return 0;
 
@@ -147,7 +147,7 @@ int __cvmx_helper_bgx_enumerate(int xiface)
 	case CVMX_QLM_MODE_RGMII_SGMII_1X1:
 	case CVMX_QLM_MODE_10G_KR_1X2:
 	case CVMX_QLM_MODE_XFI_1X2:
-		return 2;
+		return 4;
 	default:
 		return 0;
 	}
@@ -413,6 +413,36 @@ static void __cvmx_bgx_common_init_pknd(int xiface, int index)
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_BP_ON(index, xi.interface), bgx_rx_bp_on.u64);
 }
 
+static void __cvmx_helper_bgx_adjust_index(int xiface, int *start, int *end)
+{
+	int qlm = cvmx_qlm_lmac(xiface, 0);
+	int num_ports = cvmx_helper_ports_on_interface(xiface);
+
+	if (OCTEON_IS_MODEL(OCTEON_CN73XX)) {
+		if (qlm <= 3) {
+			*start = 0;
+			*end = num_ports;
+		} else if (qlm == 5 || qlm == 6) {
+			cvmx_gserx_cfg_t gser1, gser2;
+			gser1.u64 = cvmx_read_csr(CVMX_GSERX_CFG(5));
+			gser2.u64 = cvmx_read_csr(CVMX_GSERX_CFG(6));
+			if (gser1.s.bgx && gser2.s.bgx) {
+				*start = 0;
+				*end = num_ports;
+			} else if (gser1.s.bgx) {
+				*start = 0;
+				*end = 2;
+			} else if (gser2.s.bgx) {
+				*start = 2;
+				*end = num_ports;
+			}
+		}
+	} else {
+		*start = 0;
+		*end = num_ports;
+	}
+}
+
 /**
  * @INTERNAL
  * Probe a SGMII interface and determine the number of ports
@@ -425,10 +455,11 @@ static void __cvmx_bgx_common_init_pknd(int xiface, int index)
  */
 int __cvmx_helper_bgx_probe(int xiface)
 {
-	int num_ports = cvmx_helper_ports_on_interface(xiface);
-	int index;
+	int index, start, end;
 
-	for (index = 0; index < num_ports; index++)
+	__cvmx_helper_bgx_adjust_index(xiface, &start, &end);
+
+	for (index = start; index < end; index++)
 		__cvmx_bgx_common_init(xiface, index);
 	return __cvmx_helper_bgx_enumerate(xiface);
 }
@@ -530,8 +561,11 @@ static int __cvmx_helper_bgx_sgmii_hardware_init(int xiface, int num_ports)
 {
 	int index;
 	int do_link_set = 1;
+	int start, end;
 
-	for (index = 0; index < num_ports; index++) {
+	__cvmx_helper_bgx_adjust_index(xiface, &start, &end);
+
+	for (index = start; index < end; index++) {
 		int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
 
 		if (!cvmx_helper_is_port_valid(xiface, index))
@@ -826,7 +860,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 
 	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
 	if (gmp_control.s.loopbck1) {
-		int qlm = cvmx_qlm_interface(xiface);
+		int qlm = cvmx_qlm_lmac(xiface, index);
 		int speed;
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 			speed = cvmx_qlm_get_gbaud_mhz_node(node, qlm);
@@ -841,7 +875,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 
 	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
 	if (gmp_misc_ctl.s.mac_phy) {
-		int qlm = cvmx_qlm_interface(xiface);
+		int qlm = cvmx_qlm_lmac(xiface, index);
 		int speed;
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 			speed = cvmx_qlm_get_gbaud_mhz_node(node, qlm);
@@ -987,6 +1021,7 @@ int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 {
 	cvmx_bgxx_cmrx_config_t cmr_config;
+	cvmx_bgxx_spux_br_pmd_control_t pmd_control;
 	cvmx_bgxx_spux_misc_control_t spu_misc_control;
 	cvmx_bgxx_spux_control1_t spu_control1;
 	cvmx_bgxx_spux_an_control_t spu_an_control;
@@ -1008,8 +1043,11 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 
 	mode = cvmx_helper_interface_get_mode(xiface);
 
-	if (mode == CVMX_HELPER_INTERFACE_MODE_10G_KR
-	    || mode == CVMX_HELPER_INTERFACE_MODE_40G_KR4) {
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface));
+	if ((cmr_config.s.lmac_type == 3 || cmr_config.s.lmac_type == 4)
+	    && pmd_control.s.train_en
+	    && !OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
 		use_auto_neg = 1;
 	}
 
@@ -1069,21 +1107,20 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 
 		/* 4b. Write BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 1 and
 		     BGX(0..5)_SPU(0..3)_MISC_CONTROL[RX_PACKET_DIS] = 1. */
-		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface));
-		spu_control1.s.lo_pwr = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface), spu_control1.u64);
-
-		spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface));
-		spu_misc_control.s.rx_packet_dis = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface), spu_misc_control.u64);
-
 		/* 4b. Initialize the selected SerDes lane(s) in the QLM. See Section
 		      28.1.2.2 in the GSER chapter. */
 		/* Already done in QLM setup */
 
 		/* 4c. For 10GBASE-KR or 40GBASE-KR, enable link training by writing
 		     BGX(0..5)_SPU(0..3)_BR_PMD_CONTROL[TRAIN_EN] = 1. */
-		/* Moved to xaui_link */
+		if (use_auto_neg) {
+			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LP_CUP(index, interface), 0);
+			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_CUP(index, interface), 0);
+			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_REP(index, interface), 0);
+			pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface));
+			pmd_control.s.train_en = 1;
+			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface), pmd_control.u64);
+		}
 	} else { /* enable for simulator */
 		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 		cmr_config.s.enable = 1;
@@ -1103,9 +1140,9 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		/* FEC is optional for 10GBASE-KR, 40GBASE-KR4, and XLAUI. We're going
 		to disable it by default */
-		spu_fec_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, xi.interface));
+		spu_fec_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_FEC_CONTROL(index, xi.interface));
 		spu_fec_control.s.fec_en = 0;
-		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, xi.interface), spu_fec_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_FEC_CONTROL(index, xi.interface), spu_fec_control.u64);
 
 		/* 4f. If Auto-Negotiation is desired, configure and enable
 		      Auto-Negotiation as described in Section 33.6.2. */
@@ -1119,8 +1156,8 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		spu_an_adv.s.fec_able = 1;
 		spu_an_adv.s.a100g_cr10 = 0;
 		spu_an_adv.s.a40g_cr4 = 0;
-		spu_an_adv.s.a40g_kr4 = (mode == CVMX_HELPER_INTERFACE_MODE_40G_KR4) ;
-		spu_an_adv.s.a10g_kr = (mode == CVMX_HELPER_INTERFACE_MODE_10G_KR) ;
+		spu_an_adv.s.a40g_kr4 = (cmr_config.s.lmac_type == 4 && use_auto_neg);
+		spu_an_adv.s.a10g_kr = (cmr_config.s.lmac_type == 3 && use_auto_neg);
 		spu_an_adv.s.a10g_kx4 = 0;
 		spu_an_adv.s.a1g_kx = 0;
 		spu_an_adv.s.rf = 0;
@@ -1153,11 +1190,6 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	   Section 33.4.1, BGX(0..5)_SPU(0..3)_MISC_CONTROL[XOR_TXPLRT,XOR_RXPLRT]
 	   and BGX(0..5)_SPU(0..3)_MISC_CONTROL[TXPLRT,RXPLRT]. */
 
-	/* 4c. Write BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 0. */
-	spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface));
-	spu_control1.s.lo_pwr = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface), spu_control1.u64);
-
 	/* 4d. Select Deficit Idle Count mode and unidirectional enable/disable
 	   via BGX(0..5)_SMU(0..3)_TX_CTL[DIC_EN,UNI_EN]. */
 	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, xi.interface));
@@ -1178,6 +1210,7 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	return 0;
 }
 
+#if 0
 static void __cvmx_bgx_start_training(int node, int unit, int index)
 {
 	cvmx_bgxx_spux_int_t spu_int;
@@ -1212,6 +1245,7 @@ static void __cvmx_bgx_start_training(int node, int unit, int index)
 	pmd_control.s.train_restart = 1;
 	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, unit), pmd_control.u64);
 }
+#endif
 
 static void __cvmx_bgx_restart_training(int node, int unit, int index)
 {
@@ -1373,8 +1407,8 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 	cvmx_bgxx_spux_status2_t spu_status2;
 	cvmx_bgxx_spux_int_t spu_int;
 	cvmx_bgxx_spux_misc_control_t spu_misc_control;
+	cvmx_bgxx_spux_br_pmd_control_t pmd_control;
 	cvmx_bgxx_cmrx_config_t cmr_config;
-	cvmx_helper_interface_mode_t mode;
 	int use_training = 0;
 	int rgmii_first = 0;
 
@@ -1383,12 +1417,14 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 		__func__, xi.node, xi.interface, index);
 
 	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(0, xi.interface));
+	pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface));
 	rgmii_first = (cmr_config.s.lmac_type == 5);
 
-	mode = cvmx_helper_interface_get_mode(xiface);
-
-	if (mode == CVMX_HELPER_INTERFACE_MODE_10G_KR || mode == CVMX_HELPER_INTERFACE_MODE_40G_KR4)
+	if ((cmr_config.s.lmac_type == 3 || cmr_config.s.lmac_type == 4)
+	    && pmd_control.s.train_en
+	    && !OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
 		use_training = 1;
+	}
 
 	/* Disable packet reception */
 	spu_misc_control.u64 = cvmx_read_csr_node(node,
@@ -1399,7 +1435,6 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		cvmx_bgxx_spux_an_control_t spu_an_control;
-		cvmx_bgxx_spux_br_pmd_control_t pmd_control;
 
 		spu_an_control.u64 = cvmx_read_csr_node(node,
 					CVMX_BGXX_SPUX_AN_CONTROL(index, interface));
@@ -1423,62 +1458,75 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 		}
 
 		if (use_training) {
-			pmd_control.u64 = cvmx_read_csr_node(node,
-						CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface));
-
-			if (pmd_control.s.train_en == 0) {
-				__cvmx_bgx_start_training(node, interface, index);
+			spu_int.u64 = cvmx_read_csr_node(node,
+						  CVMX_BGXX_SPUX_INT(index, interface));
+			if (spu_int.s.training_failure) {
+				__cvmx_bgx_restart_training(node, interface, index);
 				return -1;
 			}
-			else {
-				spu_int.u64 = cvmx_read_csr_node(node,
-						  CVMX_BGXX_SPUX_INT(index, interface));
-				if (spu_int.s.training_failure) {
-					__cvmx_bgx_restart_training(node, interface, index);
-					return -1;
-				}
-				if (!spu_int.s.training_done) {
-					cvmx_dprintf("Waiting for link training\n");
-					return -1;
-				}
+			if (!spu_int.s.training_done) {
+				cvmx_dprintf("Waiting for link training\n");
+				return -1;
 			}
 		}
 
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface),
-					  cvmx_bgxx_spux_control1_t, reset, ==, 0, 10000)) {
-			cvmx_dprintf("ERROR: %d:BGX%d:%d: PCS in reset", node, interface, index);
-			return -1;
-		}
-
 		/* (GSER-21957) GSER RX Equalization may make >= 5gbaud non-KR
 		   channel with DXAUI, RXAUI, XFI and XLAUI, we need to perform
 		   RX equalization when the link is receiving data the first time */
 		if (use_training == 0) {
-			int qlm = cvmx_qlm_interface(xiface);
+			int qlm = cvmx_qlm_lmac(xiface, index);
 			int lane = index;
+			int mux = 0;
 			cmr_config.u64 = cvmx_read_csr_node(node,
 					CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+			/* Check if BGX2 uses both dlms (mux = 0), or
+			   qlm5 only (mux = 1) or qlm6 only (mux = 2) */
+			if (qlm == 5 || qlm == 6)
+				mux = cvmx_qlm_mux_interface(xi.interface);
 			if (cmr_config.s.lmac_type == 4
 			    || cmr_config.s.lmac_type == 1) { // XLAUI/DXAUI
 				lane = -1;
 				__cvmx_qlm_rx_equalization(node, qlm, lane);
+				/* If BGX2 uses both dlms, then configure other dlm also. */
+				if (mux == 0 && qlm == 6)
+					__cvmx_qlm_rx_equalization(node, 6, lane);
 			} else if (cmr_config.s.lmac_type == 2) { // RXAUI
 				lane = index * 2;
+				if (mux == 0 && index != 0 && qlm == 5) {
+					lane = 0;
+					qlm = 6;
+				} else if (mux == 2) {
+					lane = 0;
+					qlm = 6;
+				}
 				if (rgmii_first)
 					lane--;
 				__cvmx_qlm_rx_equalization(node, qlm, lane);
 				__cvmx_qlm_rx_equalization(node, qlm, lane + 1);
 			} else if (cmr_config.s.lmac_type != 5) { // !RGMII
+				if (mux == 2)
+					lane = index - 2;
 				if (rgmii_first)
 					lane--;
-				__cvmx_qlm_rx_equalization(node, qlm, lane);
+				if (mux == 0 && qlm == 5 && index >= 2) {
+					lane = index - 2;
+					__cvmx_qlm_rx_equalization(node, qlm+1, lane);
+				} else if (mux == 0 && qlm == 6 && index >= 2) {
+					lane = index - 2;
+					__cvmx_qlm_rx_equalization(node, qlm, lane);
+				} else
+					__cvmx_qlm_rx_equalization(node, qlm, lane);
 			}
 		}
 
-		if (mode == CVMX_HELPER_INTERFACE_MODE_XFI    ||
-		    mode == CVMX_HELPER_INTERFACE_MODE_XLAUI  ||
-		    mode == CVMX_HELPER_INTERFACE_MODE_10G_KR ||
-		    mode == CVMX_HELPER_INTERFACE_MODE_40G_KR4) {
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_CONTROL1(index, xi.interface),
+					  cvmx_bgxx_spux_control1_t, reset, ==, 0, 10000)) {
+			cvmx_dprintf("ERROR: %d:BGX%d:%d: PCS in reset", node, interface, index);
+			return -1;
+		}
+
+
+		if (cmr_config.s.lmac_type == 3 || cmr_config.s.lmac_type == 4) {
 			if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_BR_STATUS1(index, xi.interface),
 					  cvmx_bgxx_spux_br_status1_t, blk_lock, ==, 1, 10000)) {
 				//cvmx_dprintf("ERROR: %d:BGX%d:%d: BASE-R PCS block not locked\n", node, interface, index);
@@ -1503,11 +1551,6 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 		if (spu_status2.s.rcvflt) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: Receive fault, need to retry\n",
 					node, interface, index);
-
-			if (use_training)
-				__cvmx_bgx_restart_training(node, interface, index);
-			/*cvmx_dprintf("training restarting\n"); */
-			return -1;
 		}
 
 		/* Wait for MAC RX to be ready */
@@ -1566,15 +1609,17 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 int __cvmx_helper_bgx_xaui_enable(int xiface)
 {
 	int index;
-	int num_ports = cvmx_helper_ports_on_interface(xiface);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
 	int node = xi.node;
 	cvmx_helper_interface_mode_t mode;
+	int start = 0, end = 0;
 
 	mode = cvmx_helper_interface_get_mode(xiface);
 
-	for (index = 0; index < num_ports; index++) {
+	__cvmx_helper_bgx_adjust_index(xiface, &start, &end);
+
+	for (index = start; index < end; index++) {
 		int res;
 		int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
 		int phy_pres;
@@ -1586,8 +1631,7 @@ int __cvmx_helper_bgx_xaui_enable(int xiface)
 			phy_pres = 1;
 		else
 			phy_pres = 0;
-		if (__cvmx_helper_bgx_port_init(xipd_port, phy_pres))
-			return -1;
+		__cvmx_helper_bgx_port_init(xipd_port, phy_pres);
 
 		res = __cvmx_helper_bgx_xaui_link_init(index, xiface);
 		if (res == -1) {
@@ -1609,8 +1653,8 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 	cvmx_bgxx_spux_status1_t spu_status1;
 	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
 	cvmx_bgxx_smux_rx_ctl_t smu_rx_ctl;
+	cvmx_bgxx_cmrx_config_t cmr_config;
 	cvmx_helper_link_info_t result;
-	int total_lanes = 4;
 
 	result.u64 = 0;
 
@@ -1626,41 +1670,39 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 	    (smu_rx_ctl.s.status == 0) &&
 	    (spu_status1.s.rcv_lnk)) {
 		int lanes;
-		int qlm = cvmx_qlm_interface(xiface);
+		int qlm = cvmx_qlm_lmac(xiface, index);
 		uint64_t speed;
-		cvmx_helper_interface_mode_t mode;
 		result.s.link_up = 1;
 		result.s.full_duplex = 1;
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 			speed = cvmx_qlm_get_gbaud_mhz_node(node, qlm);
 		else
 			speed = cvmx_qlm_get_gbaud_mhz(qlm);
-		mode = cvmx_helper_interface_get_mode(xiface);
-		if (OCTEON_IS_MODEL(OCTEON_CN73XX) && (qlm == 5 || qlm == 6)) {
-			/* In this case we might have only 2 lanes */
-			if (mode != CVMX_HELPER_INTERFACE_MODE_40G_KR4 &&
-			    mode != CVMX_HELPER_INTERFACE_MODE_XLAUI &&
-			    mode != CVMX_HELPER_INTERFACE_MODE_XAUI)
-				total_lanes = 2;
-		}
 
-		lanes = total_lanes / cvmx_helper_ports_on_interface(xiface);
-		if (debug)
-			cvmx_dprintf("%s: baud: %llu, lanes: %d\n", __func__,
-				     (unsigned long long)speed, lanes);
-		switch(mode) {
-		case CVMX_HELPER_INTERFACE_MODE_XFI:
-		case CVMX_HELPER_INTERFACE_MODE_XLAUI:
-		case CVMX_HELPER_INTERFACE_MODE_10G_KR:
-		case CVMX_HELPER_INTERFACE_MODE_40G_KR4:
-			/* Using 64b66b symbol encoding */
-			speed = (speed * 64 + 33) / 66;
-			break;
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+		switch(cmr_config.s.lmac_type) {
 		default:
-			/* Using 8b10b symbol encoding */
+		case 1:  // XAUI
 			speed = (speed * 8 + 5) / 10;
+			lanes = 4;
+			break;
+		case 2:  // RXAUI
+			speed = (speed * 8 + 5) / 10;
+			lanes = 2;
+			break;
+		case 3:  // XFI
+			speed = (speed * 64 + 33) / 66;
+			lanes = 1;
+			break;
+		case 4:  // XLAUI
+			speed = (speed * 64 + 33) / 66;
+			lanes = 4;
 			break;
 		}
+
+		if (debug)
+			cvmx_dprintf("%s: baud: %llu, lanes: %d\n", __func__,
+				     (unsigned long long)speed, lanes);
 		speed *= lanes;
 		result.s.speed = speed;
 	} else {
@@ -1944,7 +1986,7 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 	int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
-	if (__cvmx_helper_bgx_enumerate(xiface) < 0)
+	if (!cvmx_helper_is_port_valid(xiface, index))
 		return;
 
 	if (debug)
@@ -2012,11 +2054,11 @@ void cvmx_helper_bgx_set_mac(int xipd_port, int bcst, int mcst, uint64_t mac)
 	int saved_state;
 	cvmx_helper_interface_mode_t mode;
 
-	if (__cvmx_helper_bgx_enumerate(xiface) < 0)
-		return;
-
 	index = cvmx_helper_get_interface_index_num(xipd_port);
 
+	if (!cvmx_helper_is_port_valid(xiface, index))
+		return;
+
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
@@ -2080,13 +2122,13 @@ int cvmx_bgx_set_backpressure_override(int xiface, unsigned port_mask)
 	cvmx_bgxx_cmr_rx_ovr_bp_t rx_ovr_bp;
 	int node = xi.node;
 
+	if (xi.interface >= CVMX_HELPER_MAX_GMX)
+		return 0;
+
 	if (debug)
 		cvmx_dprintf("%s: interface %u:%d port_mask=%#x\n",
 			__func__, xi.node, xi.interface, port_mask);
 
-	if (__cvmx_helper_bgx_enumerate(xiface) <= 0)
-		return -1;
-
 	/* Check for valid arguments */
 	rx_ovr_bp.u64 = 0;
 	rx_ovr_bp.s.en = port_mask;	/* Per port Enable back pressure override */
@@ -2110,6 +2152,9 @@ void cvmx_helper_bgx_set_jabber(int xiface, unsigned index,
 	if (!octeon_has_feature(OCTEON_FEATURE_BGX))
 		return;
 
+	if (!cvmx_helper_is_port_valid(xiface, index))
+		return;
+
 	node = xi.node;
 
 	/* Get LMAC type from common config */
@@ -2142,8 +2187,8 @@ int cvmx_helper_bgx_shutdown_port(int xiface, int index)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, node, xi.interface, index);
 
-	if (__cvmx_helper_bgx_enumerate(xiface) <= 0)
-		return -1;
+	if (!cvmx_helper_is_port_valid(xiface, index))
+		return 0;
 
 	/* Disable BGX CMR before we make any changes. */
 	cmr_config.u64 = cvmx_read_csr_node(node,
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
index bb634ba..bdbed62 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
@@ -94,7 +94,7 @@ CVMX_SHARED struct cvmx_cfg_port_param cvmx_cfg_port[CVMX_MAX_NODES][CVMX_HELPER
 				.ccpp_pko_port_base = CVMX_HELPER_CFG_INVALID_VALUE,
 				.ccpp_pko_num_ports = CVMX_HELPER_CFG_INVALID_VALUE,
 				.agl_rx_clk_skew = 0,
-				.valid = true,
+				.valid = false,
 				.sgmii_phy_mode = false,
 				.sgmii_1000x_mode = false,
 				.agl_rx_clk_delay_bypass = false,
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper.c b/arch/mips/cavium-octeon/executive/cvmx-helper.c
index ba11d5d..8d762f5e 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper.c
@@ -786,7 +786,7 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn78xx(int xiface)
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	/* SGMII/RXAUI/XAUI */
 	if (xi.interface < 6) {
-		int qlm = cvmx_qlm_interface(xiface);
+		int qlm = cvmx_qlm_lmac(xiface, 0);
 		enum cvmx_qlm_mode qlm_mode;
 
 		if (qlm == -1) {
@@ -935,7 +935,7 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn73xx(int xiface)
 
 	/* SGMII/XAUI/XLAUI/XFI */
 	if (interface < 3) {
-		int qlm = cvmx_qlm_interface(xiface);
+		int qlm = cvmx_qlm_lmac(xiface, 0);
 		enum cvmx_qlm_mode qlm_mode;
 
 		if (qlm == -1) {
@@ -1013,7 +1013,7 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cnf75xx(int xiface)
 	/* BGX0: SGMII (DLM4/DLM5)/XFI(DLM5)  */
 	if (interface < 1) {
 		enum cvmx_qlm_mode qlm_mode;
-		int qlm = cvmx_qlm_interface(interface);
+		int qlm = cvmx_qlm_lmac(xiface, 0);
 
 		if (qlm == -1) {
 			iface_ops[interface] = &iface_ops_dis;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pcie.c b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
index f35e689..d8848f9 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pcie.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
@@ -65,6 +65,7 @@
 #include <asm/octeon/cvmx-sriox-defs.h>
 #include <asm/octeon/cvmx-helper-jtag.h>
 #include <linux/of.h>
+#include <linux/moduleparam.h>
 
 #ifdef CONFIG_CAVIUM_DECODE_RSL
 #include <asm/octeon/cvmx-error.h>
@@ -758,6 +759,40 @@ static void __cvmx_increment_ba(cvmx_sli_mem_access_subidx_t * pmas)
 		pmas->cn63xx.ba++;
 }
 
+/*
+ * milliseconds to retry PCIe cfg-space access:
+ * Value 32(unscaled) was recommended in HRM, but may be too small for
+ * some PCIe devices. This 48mS default should cover most devices,
+ * but can be extended by bootparam cvmx-pcie.cfg_timeout, or reduced
+ * to speed boot if it is known that no devices need so much time.
+ */
+static int cfg_timeout = 48;
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+module_param(cfg_timeout, int, 0644);
+MODULE_PARM_DESC(cfg_timeout, "PCIe config-space i/o timeout in mS,"
+	" to accomodate slow-to-start devices");
+#endif
+
+static int cfg_retries(void)
+{
+	static int cfg_ticks = -1;
+
+	if (cfg_ticks < 0) {
+		uint64_t nS = cfg_timeout * 1000000;
+		const int ceiling = 0xffff;
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+		cfg_ticks = nS / (octeon_get_io_clock_rate() >> 16);
+#else
+		cfg_ticks = nS / (cvmx_clock_get_rate(CVMX_CLOCK_SCLK) >> 16);
+#endif
+
+		if (cfg_ticks > ceiling)
+			cfg_ticks = ceiling;
+	}
+	return cfg_ticks;
+}
+
 /**
  * Initialize a PCIe gen 1 port for use in host(RC) mode. It doesn't enumerate
  * the bus.
@@ -812,8 +847,7 @@ retry:
 	 * then PCIe1. '1' == round robin.
 	 */
 	npei_ctl_status.s.arb = 1;
-	/* Allow up to 0x20 config retries */
-	npei_ctl_status.s.cfg_rtry = 0x20;
+	npei_ctl_status.s.cfg_rtry = cfg_retries();
 	/* CN52XX pass1.x has an errata where P0_NTAGS and P1_NTAGS don't
 	 * reset
 	 */
@@ -1770,9 +1804,8 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		bar1_index.s.addr_idx += (((1ull << 28) / 16ull) >> 22);
 	}
 
-	/* Value is recommended in CSR files */
 	pemx_ctl_status.u64 = CVMX_READ_CSR(CVMX_PEMX_CTL_STATUS(pcie_port));
-	pemx_ctl_status.cn63xx.cfg_rtry = 32;
+	pemx_ctl_status.cn63xx.cfg_rtry = cfg_retries();
 	CVMX_WRITE_CSR(CVMX_PEMX_CTL_STATUS(pcie_port), pemx_ctl_status.u64);
 
 	/* Display the link status */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-qlm.c b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
index b23c31d..86ef992 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-qlm.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 121623 $<hr>
+ * <hr>$Revision: 121917 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -159,23 +159,48 @@ int cvmx_qlm_get_num(void)
 /**
  * Return the qlm number based on the interface
  *
- * @param xiface  interface to look up
+ * @param interface  interface to look up
  *
  * @return the qlm number based on the xiface
  */
-int cvmx_qlm_interface(int xiface)
+int cvmx_qlm_interface(int interface)
 {
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	if (OCTEON_IS_MODEL(OCTEON_CN61XX)) {
-		return (xi.interface == 0) ? 2 : 0;
+		return (interface == 0) ? 2 : 0;
 	} else if (OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX)) {
-		return 2 - xi.interface;
+		return 2 - interface;
 	} else if (OCTEON_IS_MODEL(OCTEON_CNF71XX)) {
-		if (xi.interface == 0)
+		if (interface == 0)
 			return 0;
 		else
-			cvmx_dprintf("Warning: cvmx_qlm_interface: Invalid interface %d\n", xi.interface);
-	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+			cvmx_dprintf("Warning: cvmx_qlm_interface: Invalid interface %d\n", interface);
+	} else if (octeon_has_feature(OCTEON_FEATURE_BGX)) {
+		cvmx_dprintf("Warning: not supported\n");
+		return -1;
+	} else {
+		/* Must be cn68XX */
+		switch (interface) {
+		case 1:
+			return 0;
+		default:
+			return interface;
+		}
+	}
+	return -1;
+}
+
+/**
+ * Return the qlm number based for a port in the interface
+ *
+ * @param xiface  interface to look up
+ * @param index  index in an interface
+ *
+ * @return the qlm number based on the xiface
+ */
+int cvmx_qlm_lmac(int xiface, int index)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		cvmx_bgxx_cmr_global_config_t gconfig;
 		cvmx_gserx_phy_ctl_t phy_ctl;
 		cvmx_gserx_cfg_t gserx_cfg;
@@ -183,7 +208,8 @@ int cvmx_qlm_interface(int xiface)
 
 		if (xi.interface < 6) {
 			if (xi.interface < 2) {
-				gconfig.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMR_GLOBAL_CONFIG(xi.interface));
+				gconfig.u64 = cvmx_read_csr_node(xi.node,
+						CVMX_BGXX_CMR_GLOBAL_CONFIG(xi.interface));
 				if (gconfig.s.pmux_sds_sel)
 					qlm = xi.interface + 2; /* QLM 2 or 3 */
 				else
@@ -247,6 +273,8 @@ int cvmx_qlm_interface(int xiface)
 					    && (phy_ctl1.s.phy_pd
 					        || phy_ctl1.s.phy_reset))
 						return -1;
+					if (index >= 2)
+						return 6;
 					return 5;
 				} else { /* QLM6 is BGX2 */
 					phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(6));
@@ -303,19 +331,39 @@ int cvmx_qlm_interface(int xiface)
 				return qlm;
 		}
 		return -1;
-	} else {
-		/* Must be cn68XX */
-		switch (xi.interface) {
-		case 1:
-			return 0;
-		default:
-			return xi.interface;
-		}
 	}
 	return -1;
 }
 
 /**
+ * Return if only DLM5/DLM6/DLM5+DLM6 is used by BGX
+ *
+ * @param BGX  BGX to search for.
+ *
+ * @return muxes used 0 = DLM5+DLM6, 1 = DLM5, 2 = DLM6.
+ */
+int cvmx_qlm_mux_interface(int bgx)
+{
+	int mux = 0;
+	cvmx_gserx_cfg_t gser1, gser2;
+
+	if (OCTEON_IS_MODEL(OCTEON_CN73XX) && bgx != 2)
+		return -1;
+
+	gser1.u64 = cvmx_read_csr(CVMX_GSERX_CFG(5));
+	gser2.u64 = cvmx_read_csr(CVMX_GSERX_CFG(6));
+
+	if (gser1.s.bgx && gser2.s.bgx) {
+		mux = 0;
+	} else if (gser1.s.bgx) {
+		mux = 1;  // BGX2 is using DLM5 only
+	} else if (gser2.s.bgx) {
+		mux = 2;  // BGX2 is using DLM6 only
+	}
+	return mux;
+}
+
+/**
  * Return number of lanes for a given qlm
  *
  * @param qlm    QLM to examine
@@ -1606,25 +1654,21 @@ enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn73xx(int qlm)
 		if (qlm < 4)
 			bgx = qlm - 2;
 		else if (qlm == 5 || qlm == 6) {
-			cvmx_gserx_cfg_t gser1, gser2;
-			gser1.u64 = cvmx_read_csr(CVMX_GSERX_CFG(5));
-			gser2.u64 = cvmx_read_csr(CVMX_GSERX_CFG(6));
-			if (gser1.s.bgx && gser2.s.bgx) {
+			bgx = 2;
+			mux = cvmx_qlm_mux_interface(bgx);
+			if (mux == 0) {
 				start = 0;
 				end = 4;
-			} else if (gser1.s.bgx) {
+			} else if (mux == 1) {
 				start = 0;
 				end = 2;
-				mux = 1;  // BGX2 is using DLM5 only
-			} else if (gser2.s.bgx) {
+			} else if (mux == 2) {
 				start = 2;
 				end = 4;
-				mux = 2;  // BGX2 is using DLM6 only
 			} else {
 				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
 				return qlm_mode[qlm];
 			}
-			bgx = 2;
 		}
 
 		for (index = start; index < end; index++) {
@@ -1645,7 +1689,7 @@ enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn73xx(int qlm)
 			qlm_mode[qlm] = CVMX_QLM_MODE_XAUI;
 			break;
 		case 0x2:
-			if (mux == 2)
+			if (mux == 1)
 				qlm_mode[qlm] = CVMX_QLM_MODE_RXAUI_1X2; // NONE+RXAUI
 			else if (mux == 0)
 				qlm_mode[qlm] = CVMX_QLM_MODE_MIXED; // RXAUI+SGMII
@@ -1702,8 +1746,10 @@ enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn73xx(int qlm)
 		case 0x200:
 			if (mux == 2)
 				qlm_mode[qlm] = CVMX_QLM_MODE_RXAUI_1X2;
+			else
 		case 0x205:
-		case 0x233:
+		case 0x2033:
+		case 0x3302:
 		case 0x3305:
 			if (mux == 0)
 				qlm_mode[qlm] = CVMX_QLM_MODE_MIXED;
@@ -1713,15 +1759,21 @@ enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn73xx(int qlm)
 		case 0x3300:
 			if (mux == 0)
 				qlm_mode[qlm] = CVMX_QLM_MODE_MIXED;
-			else if (mux == 2)
-				qlm_mode[qlm] = CVMX_QLM_MODE_XFI_1X2;
-			else
+			else if (mux == 2) {
+				if (train_mask)
+					qlm_mode[qlm] = CVMX_QLM_MODE_10G_KR_1X2;
+				else
+					qlm_mode[qlm] = CVMX_QLM_MODE_XFI_1X2;
+			} else
 				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
 			break;
 		case 0x33:
-			if (mux == 1)
-				qlm_mode[qlm] = CVMX_QLM_MODE_XFI_1X2;
-			else
+			if (mux == 1 || mux == 2) {
+				if (train_mask)
+					qlm_mode[qlm] = CVMX_QLM_MODE_10G_KR_1X2;
+				else
+					qlm_mode[qlm] = CVMX_QLM_MODE_XFI_1X2;
+			} else
 				qlm_mode[qlm] = CVMX_QLM_MODE_DISABLED;
 			break;
 		case 0x0035:
diff --git a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
index 2147f6c..a06fad0 100644
--- a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
@@ -2419,8 +2419,8 @@ union cvmx_gserx_br_rxx_ctl {
                                                          and not used.
                                                          Set this bit to a one to disable the link training receiver adaptation time-out
                                                          timer during Base-R link training under hardware control.  For diagnostic use only. */
-	uint64_t rxt_swm                      : 1;  /**< Set when RX Base-R Link Training is to be performed under software control. For diagnostic
-                                                         use only. */
+	uint64_t rxt_swm                      : 1;  /**< Set when RX Base-R Link Training is to be performed under software control.
+                                                         See GSER()_BR_RX()_EER[EXT_EER]. */
 	uint64_t rxt_preset                   : 1;  /**< For all link training, this bit determines how to configure the preset bit in the
                                                          coefficient update message that is sent to the far end transmitter. When set, a one time
                                                          request is made that the coefficients be set to a state where equalization is turned off.
@@ -2447,8 +2447,8 @@ union cvmx_gserx_br_rxx_ctl {
 	struct cvmx_gserx_br_rxx_ctl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t rxt_swm                      : 1;  /**< Set when RX Base-R Link Training is to be performed under software control. For diagnostic
-                                                         use only. */
+	uint64_t rxt_swm                      : 1;  /**< Set when RX Base-R Link Training is to be performed under software control.
+                                                         See GSER()_BR_RX()_EER[EXT_EER]. */
 	uint64_t rxt_preset                   : 1;  /**< For all link training, this bit determines how to configure the preset bit in the
                                                          coefficient update message that is sent to the far end transmitter. When set, a one time
                                                          request is made that the coefficients be set to a state where equalization is turned off.
@@ -2490,7 +2490,18 @@ union cvmx_gserx_br_rxx_eer {
 	uint64_t reserved_16_63               : 48;
 	uint64_t rxt_eer                      : 1;  /**< When RX Base-R Link Training is being performed under software control,
                                                          (GSER()_BR_RX()_CTL[RXT_SWM] is set), writing this bit initiates an equalization
-                                                         request to the RAW PCS. Reading this bit always returns a zero. */
+                                                         request to the RAW PCS. Reading this bit always returns a zero.
+                                                         When auto-negotiated link training is not present and link speed >= 5Gbaud,
+                                                         including XFI, receiver (only) equalization should be manually performed. After
+                                                         GSER()_BR_RX()_CTL[RXT_SWM] is set, writing this CSR with
+                                                         [RXT_EER]=1 initiates this manual equalization. The operation may take up to
+                                                         2 milliseconds, and then hardware sets [RXT_ESV]. [RXT_ESM] can be
+                                                         ignored after these receiver-only equalizations. The serdes input should
+                                                         be a pattern (something similar to the Base-R training sequence, ideally)
+                                                         during this receiver-only training. If DFE is to be disabled
+                                                         (recommended for 5Gbaud and below), do it prior to this receiver-only
+                                                         initialization. (GSER()_LANE()_RX_VALBBD_CTRL_0, GSER()_LANE()_RX_VALBBD_CTRL_1,
+                                                         and GSER()_LANE()_RX_VALBBD_CTRL_2 configure the DFE.) */
 	uint64_t rxt_esv                      : 1;  /**< When performing an equalization request (RXT_EER), this bit, when set, indicates that the
                                                          Equalization Status (RXT_ESM) is valid. When issuing a RXT_EER request, it is expected
                                                          that RXT_ESV will get written to zero so that a valid RXT_ESM can be determined. */
@@ -5107,15 +5118,27 @@ union cvmx_gserx_lanex_rx_cfg_2 {
 	uint64_t pcs_sds_rx_sampler_boost_en  : 1;  /**< Faster sampler c2q.
                                                          For diagnostic use only. */
 	uint64_t reserved_10_10               : 1;
-	uint64_t rx_sds_rx_agc_mval           : 10; /**< AGC manual value only used when GSERX_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_VAL] is set.
+	uint64_t rx_sds_rx_agc_mval           : 10; /**< AGC manual value used when GSERX_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL]
+                                                         are set.
                                                          <9:8>: Reserved.
-                                                         <7:4>: Pre-CTLE (continuous time linear equalizer) gain:
-                                                         - 0 = -6dB
-                                                         - 1 = -5dB
-                                                         - 3 = +5dB.
+                                                         <7:4>: Pre-CTLE (continuous time linear equalizer) gain (steps of approximately 0.75dB):
+                                                         - 0x0 = -6dB
+                                                         - 0x1 = -5dB
+                                                         - 0xF = +5dB.
                                                          <3:0>: Post-CTLE gain (steps of 0.0875):
                                                          - 0x0 = lowest
-                                                         - 0xf = lowest * 2.3125. */
+                                                         - 0xf = lowest * 2.3125.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <
+                                                         5Gbaud, pre-CTLE, post-CTLE, and peaking control settings should be manually
+                                                         configured. GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL]
+                                                         should both be set, [RX_SDS_RX_AGC_MVAL] has the pre and post settings,
+                                                         and GSER()_LANE()_RX_CTLE_CTRL[PCS_SDS_RX_CTLE_ZERO] controls equalizer
+                                                         peaking.
+                                                         The [RX_SDS_RX_AGC_MVAL] settings should be derived from signal integrity
+                                                         simulations with the IBIS-AMI model supplied by Cavium when
+                                                         GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL] are set.
+                                                         INTERNAL: reset value may be reasonable default settings. */
 #else
 	uint64_t rx_sds_rx_agc_mval           : 10;
 	uint64_t reserved_10_10               : 1;
@@ -5189,10 +5212,10 @@ union cvmx_gserx_lanex_rx_cfg_4 {
                                                          <13:8>: Q/QB error sampler 0 threshold, 6.7mV/step, used for training/LMS.
                                                          <7>: Enable Window mode, after training has finished.
                                                          <6:5>: Control sds_pcs_rx_vma_status[15:8].
-                                                         0x0 = window counter[19:12] (FOM).
-                                                         0x1 = window ouunter[11:4].
-                                                         0x2 = CTLE pole, SDLL_IQ.
-                                                         0x3 = pre-CTLE gain, CTLE peak.
+                                                              0x0 = window counter[19:12] (FOM).
+                                                              0x1 = window ouunter[11:4].
+                                                              0x2 = CTLE pole, SDLL_IQ.
+                                                              0x3 = pre-CTLE gain, CTLE peak.
                                                          <4>: Offset cancellation enable.
                                                          <3:0>: Max CTLE peak setting during training when pcs_sds_rx_vma_ctl[7] is set in
                                                          GSER()_LANE()_RX_VMA_CTRL. */
@@ -5220,8 +5243,22 @@ union cvmx_gserx_lanex_rx_cfg_5 {
 	struct cvmx_gserx_lanex_rx_cfg_5_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t rx_agc_men_ovvrd_en          : 1;  /**< Override enable for AGC manual mode. */
-	uint64_t rx_agc_men_ovvrd_val         : 1;  /**< Override value for AGC manual mode. */
+	uint64_t rx_agc_men_ovvrd_en          : 1;  /**< Override enable for AGC manual mode.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <
+                                                         5Gbaud, pre-CTLE, post-CTLE, and peaking control settings should be manually
+                                                         configured. [RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL] should both be set,
+                                                         GSER()_LANE()_RX_CFG_2[RX_SDS_RX_AGC_MVAL] has the pre and post settings,
+                                                         and GSER()_LANE()_RX_CTLE_CTRL[PCS_SDS_RX_CTLE_ZERO] controls equalizer
+                                                         peaking. */
+	uint64_t rx_agc_men_ovvrd_val         : 1;  /**< Override value for AGC manual mode.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <
+                                                         5Gbaud, pre-CTLE, post-CTLE, and peaking control settings should be manually
+                                                         configured. [RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL] should both be set,
+                                                         GSER()_LANE()_RX_CFG_2[RX_SDS_RX_AGC_MVAL] has the pre and post settings,
+                                                         and GSER()_LANE()_RX_CTLE_CTRL[PCS_SDS_RX_CTLE_ZERO] controls equalizer
+                                                         peaking. */
 	uint64_t rx_widthsel_ovvrd_en         : 1;  /**< Override enable for RX width select to the SerDes pcs_sds_rx_widthsel. */
 	uint64_t rx_widthsel_ovvrd_val        : 2;  /**< Override value for RX width select to the SerDes pcs_sds_rx_widthsel.
                                                          0x0 = 8-bit raw data.
@@ -5260,7 +5297,17 @@ union cvmx_gserx_lanex_rx_ctle_ctrl {
                                                          0x1 =  0%.
                                                          0x2 = +5%.
                                                          0x3 = +10%. */
-	uint64_t pcs_sds_rx_ctle_zero         : 4;  /**< Equalizer peaking control. */
+	uint64_t pcs_sds_rx_ctle_zero         : 4;  /**< Equalizer peaking control.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <
+                                                         5Gbaud, pre-CTLE, post-CTLE, and peaking control settings should be manually
+                                                         configured. GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL]
+                                                         should both be set, GSER()_LANE()_RX_CFG_2[RX_SDS_RX_AGC_MVAL] has the
+                                                         pre and post settings, and [PCS_SDS_RX_CTLE_ZERO] controls equalizer
+                                                         peaking.
+                                                         The [PCS_SDS_RX_CTLE_ZERO] setting should be derived from signal integrity
+                                                         simulations with the IBIS-AMI model supplied by Cavium when auto-negotiated
+                                                         link training is not present and link speed < 5Gbaud. */
 	uint64_t rx_ctle_pole_ovrrd_en        : 1;  /**< Equalizer pole adjustment override enable. */
 	uint64_t rx_ctle_pole_ovrrd_val       : 4;  /**< Equalizer pole adjustment override value.
                                                          RX pre-correlation sample counter control
@@ -5306,17 +5353,18 @@ union cvmx_gserx_lanex_rx_loop_ctrl {
 	uint64_t reserved_12_63               : 52;
 	uint64_t fast_dll_lock                : 1;  /**< Assert to enable fast DLL lock (for simulation purposes only). */
 	uint64_t fast_ofst_cncl               : 1;  /**< Assert to enable fast Offset cancellation (for simulation purposes only). */
-	uint64_t cfg_rx_lctrl                 : 10; /**< When GSER()_LANE()_PWR_CTRL[RX_LCTRL_OVRRD_EN] is set, loop control settings.
-                                                         0x0 = cdr_en_byp.
-                                                         0x1 = dfe_en_byp.
-                                                         0x2 = agc_en_byp.
-                                                         0x3 = ofst_cncl_en_byp.
-                                                         0x4 = CDR resetn.
-                                                         0x5 = CTLE resetn.
-                                                         0x6 = VMA resetn.
-                                                         0x7 = ofst_cncl_rstn_byp.
-                                                         0x8 = lctrl_men.
-                                                         0x9 - 0x3ff = Reserved. */
+	uint64_t cfg_rx_lctrl                 : 10; /**< Loop control settings.
+                                                         <0> = cdr_en_byp.
+                                                         <1> = dfe_en_byp.
+                                                         <2> = agc_en_byp.
+                                                         <3> = ofst_cncl_en_byp.
+                                                         <4> = CDR resetn.
+                                                         <5> = CTLE resetn.
+                                                         <6> = VMA resetn.
+                                                         <7> = ofst_cncl_rstn_byp.
+                                                         <8> = lctrl_men.
+                                                         <9> = Reserved.
+                                                         GSER()_LANE()_PWR_CTRL[RX_LCTRL_OVRRD_EN] controls <9:7> and <3:0>. */
 #else
 	uint64_t cfg_rx_lctrl                 : 10;
 	uint64_t fast_ofst_cncl               : 1;
@@ -5543,13 +5591,45 @@ union cvmx_gserx_lanex_rx_valbbd_ctrl_0 {
 	uint64_t agc_gain                     : 2;  /**< AGC gain. */
 	uint64_t dfe_gain                     : 2;  /**< DFE gain. */
 	uint64_t dfe_c5_mval                  : 4;  /**< DFE Tap5 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c5_msgn                  : 1;  /**< DFE Tap5 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c4_mval                  : 4;  /**< DFE Tap4 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c4_msgn                  : 1;  /**< DFE Tap4 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 #else
 	uint64_t dfe_c4_msgn                  : 1;
 	uint64_t dfe_c4_mval                  : 4;
@@ -5579,22 +5659,65 @@ union cvmx_gserx_lanex_rx_valbbd_ctrl_1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
 	uint64_t dfe_c3_mval                  : 4;  /**< DFE Tap3 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c3_msgn                  : 1;  /**< DFE Tap3 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c2_mval                  : 4;  /**< DFE Tap2 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c2_msgn                  : 1;  /**< DFE Tap2 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c1_mval                  : 4;  /**< DFE Tap1 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
-                                                         Recommended settings: For the following modes:
-                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that DFE_C1_MVAL
-                                                         be set to zero after setting GSER()_LANE_P()_MODE_1[VMA_MM] and also after
-                                                         updating the GSER()_LANE()_RX_VALBBD_CTRL_2 register. In all other modes this
-                                                         register can be ignored. */
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c1_msgn                  : 1;  /**< DFE Tap1 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set. */
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 #else
 	uint64_t dfe_c1_msgn                  : 1;
 	uint64_t dfe_c1_mval                  : 4;
@@ -5626,29 +5749,66 @@ union cvmx_gserx_lanex_rx_valbbd_ctrl_2 {
 	uint64_t dfe_ovrd_en                  : 1;  /**< Override enable for DFE tap controls. When asserted, the register bits in
                                                          GSER()_LANE()_RX_VALBBD_CTRL_0 and GSER()_LANE()_RX_VALBBD_CTRL_1 are
                                                          used for controlling the DFE tap manual mode, instead the manual mode signal indexed by
-                                                         GSER()_LANE_MODE[LMODE]. Recommended settings: For the following modes: 5G_REFCLK100,
-                                                         5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that DFE tap controls be put in
-                                                         manual mode by setting this bit. In all other modes this register can be ignored. */
-	uint64_t dfe_c5_ovrd_val              : 1;  /**< Override value for DFE Tap5 manual enable. Recommended settings: For the following modes;
-                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap5
-                                                         manual enable be set after setting GSER()_LANE_P()_MODE_1[VMA_MM]. In all
-                                                         other modes this register can be ignored. */
-	uint64_t dfe_c4_ovrd_val              : 1;  /**< Override value for DFE Tap4 manual enable. Recommended settings: For the following modes:
-                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap4
-                                                         manual enable be set after setting GSER()_LANE_P()_MODE_1[VMA_MM]. In all
-                                                         other modes this register can be ignored. */
-	uint64_t dfe_c3_ovrd_val              : 1;  /**< Override value for DFE Tap3 manual enable. Recommended settings: For the following modes;
-                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap3
-                                                         manual enable be set after setting GSER()_LANE_P()_MODE_1[VMA_MM]. In all
-                                                         other modes this register can be ignored. */
-	uint64_t dfe_c2_ovrd_val              : 1;  /**< Override value for DFE Tap2 manual enable. Recommended settings: For the following modes;
-                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap2
-                                                         manual enable be set after setting GSER()_LANE_P()_MODE_1[VMA_MM]. In all
-                                                         other modes this register can be ignored. */
-	uint64_t dfe_c1_ovrd_val              : 1;  /**< Override value for DFE Tap1 manual enable. Recommended settings: For the following modes;
-                                                         5G_REFCLK100, 5G_REFCLK15625_QSGMII, and 5G_REFCLK125, it is recommended that the DFE Tap1
-                                                         manual enable be set after setting GSER()_LANE_P()_MODE_1[VMA_MM]. In all
-                                                         other modes this register can be ignored. */
+                                                         GSER()_LANE_MODE[LMODE].
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
+                                                         DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
+	uint64_t dfe_c5_ovrd_val              : 1;  /**< Override value for DFE Tap5 manual enable. Used when [DFE_OVRD_EN] is set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
+                                                         DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
+	uint64_t dfe_c4_ovrd_val              : 1;  /**< Override value for DFE Tap4 manual enable. Used when [DFE_OVRD_EN] is set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
+                                                         DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
+	uint64_t dfe_c3_ovrd_val              : 1;  /**< Override value for DFE Tap3 manual enable. Used when [DFE_OVRD_EN] is set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
+                                                         DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
+	uint64_t dfe_c2_ovrd_val              : 1;  /**< Override value for DFE Tap2 manual enable. Used when [DFE_OVRD_EN] is set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
+                                                         DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
+	uint64_t dfe_c1_ovrd_val              : 1;  /**< Override value for DFE Tap1 manual enable. Used when [DFE_OVRD_EN] is set.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
+                                                         DFE_C1_OVRD_VAL] and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 #else
 	uint64_t dfe_c1_ovrd_val              : 1;
 	uint64_t dfe_c2_ovrd_val              : 1;
@@ -5947,7 +6107,22 @@ union cvmx_gserx_lanex_tx_cfg_0 {
 	uint64_t tx_cm_mode                   : 1;  /**< Assert to enable fast Common-Mode charge up. For simulation purposes only. */
 	uint64_t cfg_tx_swing                 : 5;  /**< TX output swing control.
                                                          Default swing encoding when GSER()_LANE()_TX_CFG_1[TX_SWING_OVRRD_EN] is
-                                                         asserted. */
+                                                         asserted.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present, including XFI and all
+                                                         protocols <= 6.25Gbaud except PCIe, the transmit swing should be manually
+                                                         over-ridden. GSER()_LANE()_TX_CFG_1[TX_SWING_OVRD_EN] should be set
+                                                         and [CFG_TX_SWING] configures the swing.
+                                                         [CFG_TX_SWING] should be derived from signal integrity simulations
+                                                         with the IBIS-AMI model supplied by Cavium when auto-negotiated link
+                                                         training is not present and link speed <= 6.25Gbaud.
+                                                         <pre>
+                                                             Frequency          Possibly useful [CFG_TX_SWING] value
+                                                             --------------------------------------------------------
+                                                              6.25 Gbaud             0xa
+                                                              10.3125 Gbaud          0xd
+                                                              other                  0x7
+                                                         </pre> */
 	uint64_t fast_rdet_mode               : 1;  /**< Assert to enable fast RX Detection. For simulation purposes only. */
 	uint64_t fast_tristate_mode           : 1;  /**< Assert to enable fast Tristate power up. For simulation purposes only. */
 	uint64_t reserved_0_0                 : 1;
@@ -5974,7 +6149,22 @@ union cvmx_gserx_lanex_tx_cfg_0 {
 	uint64_t tx_cm_mode                   : 1;  /**< Assert to enable fast Common-Mode charge up. For simulation purposes only. */
 	uint64_t cfg_tx_swing                 : 5;  /**< TX output swing control.
                                                          Default swing encoding when GSER()_LANE()_TX_CFG_1[TX_SWING_OVRRD_EN] is
-                                                         asserted. */
+                                                         asserted.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present, including XFI and all
+                                                         protocols <= 6.25Gbaud except PCIe, the transmit swing should be manually
+                                                         over-ridden. GSER()_LANE()_TX_CFG_1[TX_SWING_OVRD_EN] should be set
+                                                         and [CFG_TX_SWING] configures the swing.
+                                                         [CFG_TX_SWING] should be derived from signal integrity simulations
+                                                         with the IBIS-AMI model supplied by Cavium when auto-negotiated link
+                                                         training is not present and link speed <= 6.25Gbaud.
+                                                         <pre>
+                                                             Frequency          Possibly useful [CFG_TX_SWING] value
+                                                             --------------------------------------------------------
+                                                              6.25 Gbaud             0xa
+                                                              10.3125 Gbaud          0xd
+                                                              other                  0x7
+                                                         </pre> */
 	uint64_t fast_rdet_mode               : 1;  /**< Assert to enable fast RX Detection. For simulation purposes only. */
 	uint64_t fast_tristate_mode           : 1;  /**< Assert to enable fast Tristate power up. For simulation purposes only. */
 	uint64_t reserved_0_0                 : 1;
@@ -6017,8 +6207,19 @@ union cvmx_gserx_lanex_tx_cfg_1 {
                                                          0x3 = 20-bit. */
 	uint64_t tx_vboost_en_ovrrd_en        : 1;  /**< Override enable for pcs_sds_txX_vboost_en, TX  vboost mode enable. */
 	uint64_t tx_turbo_en_ovrrd_en         : 1;  /**< Override enable for pcs_sds_txX_turbo_en, Turbo mode enable. */
-	uint64_t tx_swing_ovrd_en             : 1;  /**< Override enable for pcs_sds_txX_swing, TX swing. */
-	uint64_t tx_premptap_ovrd_val         : 1;  /**< Override enable for pcs_sds_txX_preemptap, preemphasis control. */
+	uint64_t tx_swing_ovrd_en             : 1;  /**< Override enable for pcs_sds_txX_swing, TX swing.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present, including XFI and all
+                                                         protocols <= 6.25Gbaud except PCIe, the transmit swing should be manually
+                                                         over-ridden. [TX_SWING_OVRD_EN] should be set and
+                                                         GSER()_LANE()_TX_CFG_0[CFG_TX_SWING] configures the swing. */
+	uint64_t tx_premptap_ovrd_val         : 1;  /**< Override enable for pcs_sds_txX_preemptap, preemphasis control.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present, including XFI and all
+                                                         protocols <= 6.25Gbaud except PCIe, the transmit preemphasis pre and post
+                                                         cursor values should be manually over-ridden.  [TX_PREMPTAP_OVRD_VAL] should
+                                                         be set and GSER()_LANE()_TX_PRE_EMPHASIS[CFG_TX_PREMPTAP] has the pre and post
+                                                         cursor values. */
 	uint64_t tx_elec_idle_ovrrd_en        : 1;  /**< Override enable for pcs_sds_txX_elec_idle, TX electrical idle. */
 	uint64_t smpl_rate_ovrd_en            : 1;  /**< Override enable for TX Power state machine sample rate. When asserted, the TX sample is
                                                          specified from SMPL_RATE_OVRD_VAL and the TX Power state machine control signal is
@@ -6178,7 +6379,23 @@ union cvmx_gserx_lanex_tx_pre_emphasis {
 	uint64_t cfg_tx_premptap              : 9;  /**< Override preemphasis control. Applies when
                                                          GSER()_LANE()_TX_CFG_3[TX_PREMPTAP_OVRD_EN] is asserted.
                                                          <8:4> = Post-cursor.
-                                                         <3:0> = Pre-cursor. */
+                                                         <3:0> = Pre-cursor.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present, including XFI and all
+                                                         protocols <= 6.25Gbaud except PCIe, the transmit preemphasis pre and post
+                                                         cursor values should be manually over-ridden.
+                                                         GSER()_LANE()_TX_CFG_1[TX_PREMPTAP_OVRD_VAL] should be set
+                                                         and [CFG_TX_PREMPTAP] has the pre and post cursor values.
+                                                         [CFG_TX_PREMPTAP] should be derived from signal integrity simulations
+                                                         with the IBIS-AMI model supplied by Cavium when auto-negotiated link
+                                                         training is not present and link speed <= 6.25Gbaud.
+                                                         <pre>
+                                                            Frequency        Possibly useful [CFG_TX_PREMPTAP] value
+                                                            --------------------------------------------------------
+                                                             6,25 Gbaud            0xa0
+                                                             10.3125 Gbaud         0xd0
+                                                             other                 0xf0
+                                                         </pre> */
 #else
 	uint64_t cfg_tx_premptap              : 9;
 	uint64_t reserved_9_63                : 55;
@@ -6292,6 +6509,7 @@ union cvmx_gserx_lane_px_mode_0 {
                                                          0x2 = ~15dB of peaking at 5.5 GHz
                                                          0x3 = ~20dB of peaking at 6 GHz (Maximum bandwidth).
                                                          Recommended settings:
+                                                         <pre>
                                                          _ R_25G_REFCLK100:          0x0
                                                          _ R_5G_REFCLK100:           0x0
                                                          _ R_8G_REFCLK100:           0x3
@@ -6303,11 +6521,13 @@ union cvmx_gserx_lane_px_mode_0 {
                                                          _ R_625G_REFCLK15625_RXAUI: 0x0
                                                          _ R_25G_REFCLK125:          0x0
                                                          _ R_5G_REFCLK125:           0x0
-                                                         _ R_8G_REFCLK125:           0x3 */
+                                                         _ R_8G_REFCLK125:           0x3
+                                                         </pre> */
 	uint64_t pcie                         : 1;  /**< Selects between RX terminations.
                                                          - 0: Differential termination
                                                          - 1: Termination between pad and SDS_VDDS.
                                                           Recommended settings:
+                                                          <pre>
                                                           _ R_25G_REFCLK100:          0x1
                                                           _ R_5G_REFCLK100:           0x1
                                                           _ R_8G_REFCLK100:           0x0
@@ -6319,7 +6539,8 @@ union cvmx_gserx_lane_px_mode_0 {
                                                           _ R_625G_REFCLK15625_RXAUI: 0x0
                                                           _ R_25G_REFCLK125:          0x1
                                                           _ R_5G_REFCLK125:           0x1
-                                                          _ R_8G_REFCLK125:           0x0 */
+                                                          _ R_8G_REFCLK125:           0x0
+                                                          </pre> */
 	uint64_t tx_ldiv                      : 2;  /**< Configures clock divider used to determine the receive rate.
                                                          0x0 = full data rate.
                                                          0x1 = 1/2 data rate.
@@ -6421,11 +6642,13 @@ union cvmx_gserx_lane_px_mode_1 {
 	uint64_t vma_fine_cfg_sel             : 1;  /**< Recommended settings:
                                                          1 = Enabled. Fine step adaptation selected (10.3125 Gbaud rate).
                                                          0 = Disabled. Coarse step adaptation selected (rates lower than 10.3125 Gbaud). */
-	uint64_t vma_mm                       : 1;  /**< Manual DFE verses adaptive DFE mode. Recommended settings:
+	uint64_t vma_mm                       : 1;  /**< Manual DFE verses adaptive DFE mode.
+                                                         Recommended settings:
                                                          0 = Adaptive DFE (5 Gbaud and higher)
                                                          1 = Manual DFE, fixed tap (3.125 Gbaud and lower). */
 	uint64_t cdr_fgain                    : 4;  /**< CDR frequency gain.
                                                          Recommended settings:
+                                                         <pre>
                                                          _ R_25G_REFCLK100:          0xA
                                                          _ R_5G_REFCLK100:           0xA
                                                          _ R_8G_REFCLK100:           0xB
@@ -6437,7 +6660,8 @@ union cvmx_gserx_lane_px_mode_1 {
                                                          _ R_625G_REFCLK15625_RXAUI: 0xA
                                                          _ R_25G_REFCLK125:          0xA
                                                          _ R_5G_REFCLK125:           0xA
-                                                         _ R_8G_REFCLK125:           0xB */
+                                                         _ R_8G_REFCLK125:           0xB
+                                                         </pre> */
 	uint64_t ph_acc_adj                   : 10; /**< Phase accumulator adjust.
                                                          Recommended settings:
                                                          <pre>
@@ -8005,7 +8229,8 @@ union cvmx_gserx_pll_px_mode_1 {
                                                          10.3125G:  NS      NS     0x2
                                                          </pre>
                                                          A 'NS' indicates that the rate is not supported at the specified reference clock. */
-	uint64_t pll_pcie3en                  : 1;  /**< Enable PCIE3 mode. Recommended settings:
+	uint64_t pll_pcie3en                  : 1;  /**< Enable PCIE3 mode.
+                                                         Recommended settings:
                                                          0 = Any rate other than 8 Gbaud.
                                                          1 = Rate is equal to 8 Gbaud. */
 	uint64_t pll_opr                      : 1;  /**< PLL op range:
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
index ed2104c..90f34a7 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
@@ -1426,8 +1426,7 @@ union cvmx_ilk_gbl_cfg {
 	uint64_t rid_rstdis                   : 1;  /**< Disable automatic reassembly-ID error recovery. For diagnostic use only. */
 	uint64_t reset                        : 1;  /**< Reset ILK. For diagnostic use only. */
 	uint64_t cclk_dis                     : 1;  /**< Disable ILK conditional clocking. For diagnostic use only. */
-	uint64_t rxf_xlink                    : 1;  /**< Causes external loopback traffic to switch links. Enabling this allow simultaneous use of
-                                                         external and internal loopback. */
+	uint64_t rxf_xlink                    : 1;  /**< Reserved. */
 #else
 	uint64_t rxf_xlink                    : 1;
 	uint64_t cclk_dis                     : 1;
@@ -1704,8 +1703,8 @@ union cvmx_ilk_lne_dbg {
 	uint64_t tx_bad_sync_cnt              : 3;  /**< Specifies the number of bad sync words on the selected lane. */
 	uint64_t tx_bad_scram_cnt             : 3;  /**< Specifies the number of bad scrambler state on the selected lane. */
 	uint64_t tx_bad_lane_sel              : 16; /**< Select the lane to apply the error-injection counts. */
-	uint64_t tx_dis_dispr                 : 16; /**< Per-lane disparity disable. */
-	uint64_t tx_dis_scram                 : 16; /**< Per-lane scrambler disable. */
+	uint64_t tx_dis_dispr                 : 16; /**< Per-lane disparity disable. For diagnostic use only. */
+	uint64_t tx_dis_scram                 : 16; /**< Per-lane scrambler disable. For diagnostic use only. */
 #else
 	uint64_t tx_dis_scram                 : 16;
 	uint64_t tx_dis_dispr                 : 16;
@@ -4050,7 +4049,9 @@ union cvmx_ilk_txx_cfg0 {
                                                          current value. */
 	uint64_t lnk_stats_ena                : 1;  /**< Enable link statistics counters. */
 	uint64_t mltuse_fc_ena                : 1;  /**< When set, the multiuse field of control words contains flow-control status. Otherwise, the
-                                                         multiuse field contains ILK_TX()_CFG1[TX_MLTUSE] */
+                                                         multiuse field contains ILK_TX()_CFG1[TX_MLTUSE].   This field must not be changed unless
+                                                         ILK_TX()_CFG0.LANE_ENA=0.  Setting ILK_TX()_CFG0.MLTUSE_FC_ENA=1 requires
+                                                         ILK_TX()_CFG0.CAL_ENA=1. */
 	uint64_t cal_ena                      : 1;  /**< Enable TX calendar. When not asserted, the default calendar is used:
                                                          First control word:
                                                          _ entry 0 = link
@@ -4253,7 +4254,7 @@ union cvmx_ilk_txx_cfg1 {
                                                          at the end of a packet instead of
                                                          the end of a burst. */
 	uint64_t rx_link_fc_ign               : 1;  /**< Ignore the link flow-control status received in burst/idle control words */
-	uint64_t rmatch                       : 1;  /**< Enable rate matching circuitry. */
+	uint64_t rmatch                       : 1;  /**< Reserved. */
 	uint64_t tx_mltuse                    : 8;  /**< Multiuse bits are used when ILK_TX()_CFG0[MLTUSE_FC_ENA] = 0. */
 #else
 	uint64_t tx_mltuse                    : 8;
diff --git a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
index 74a1f25..e10ff6a 100644
--- a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
@@ -4346,9 +4346,13 @@ union cvmx_lmcx_config {
                                                          instruction sequences do not write any mode registers in the DDR3/4 parts. */
 	uint64_t early_dqx                    : 1;  /**< Set this bit to send DQx signals one CK cycle earlier for the case when the shortest DQx
                                                          lines have a larger delay than the CK line. */
-	uint64_t ref_zqcs_int                 : 22; /**< Refresh interval is represented in number of 512 CK cycle increments. ZQCS interval is
-                                                         represented in a number of refresh intervals. A refresh sequence is triggered when bits
-                                                         <24:18> are equal to 0x0, and a ZQCS sequence is triggered when <39:18> are equal to 0x0.
+	uint64_t ref_zqcs_int                 : 22; /**< Refresh interval is represented in number of 512 CK cycle increments. To get more precise
+                                                         control of the refresh interval, the CSR LMC()_EXT_CONFIG[REF_INT_LSBS] can be set to a
+                                                         non-zero value.
+                                                         ZQCS interval is represented in a number of refresh intervals. A refresh sequence is
+                                                         triggered when bits <24:18> are equal to 0x0, and a ZQCS sequence is triggered when
+                                                         <39:18>
+                                                         are equal to 0x0.
                                                          The ZQCS timer only decrements when the refresh timer is 0.
                                                          Program <24:18> to RND-DN(TREFI/clkPeriod/512).
                                                          A value of 0 in bits <24:18> will effectively turn off refresh.
@@ -6691,7 +6695,8 @@ typedef union cvmx_lmcx_dimmx_ddr4_params1 cvmx_lmcx_dimmx_ddr4_params1_t;
  * (registered) DIMM. The control words allow optimization of the device properties for different
  * raw card designs. Note that LMC only uses this CSR when LMC()_CONTROL[RDIMM_ENA]=1. During
  * a power-up/init sequence, LMC writes these fields into the control words in the JEDEC standard
- * SSTE32882 registering clock driver on an RDIMM when corresponding
+ * DDR3 SSTE32882 registering clock driver or DDR4 Register DDR4RCD01 on an RDIMM when
+ * corresponding
  * LMC()_DIMM_CTL[DIMM*_WMASK] bits are set.
  */
 union cvmx_lmcx_dimmx_params {
@@ -6754,7 +6759,7 @@ typedef union cvmx_lmcx_dimmx_params cvmx_lmcx_dimmx_params_t;
  *
  * Note that this CSR is only used when LMC()_CONTROL[RDIMM_ENA] = 1. During a power-up/init
  * sequence, this CSR controls LMC's write operations to the control words in the JEDEC standard
- * SSTE32882 registering clock driver on an RDIMM.
+ * DDR3 SSTE32882 registering clock driver or DDR4 Register DDR4RCD01 on an RDIMM.
  */
 union cvmx_lmcx_dimm_ctl {
 	uint64_t u64;
@@ -6763,8 +6768,8 @@ union cvmx_lmcx_dimm_ctl {
 	uint64_t reserved_46_63               : 18;
 	uint64_t parity                       : 1;  /**< "Parity. The Par_In input of a registered DIMM should be tied off. LMC adjusts the value
                                                          of the DDR_WE_L (DWE#) pin during DDR3 register part control word writes to ensure the
-                                                         parity is observed correctly by the receiving SSTE32882 register part.
-                                                         When Par_In is grounded, PARITY should be cleared to 0." */
+                                                         parity is observed correctly by the receiving DDR3 SSTE32882 or DDR4 DDR4RCD01 register
+                                                         part. When Par_In is grounded, PARITY should be cleared to 0." */
 	uint64_t tcws                         : 13; /**< LMC waits for this time period before and after a RDIMM control word access during a
                                                          power-up/init SEQUENCE. TCWS is in multiples of 8 CK cycles.
                                                          Set TCWS (CSR field) = RNDUP[TCWS(ns)/(8 * TCYC(ns))], where TCWS is the desired time
@@ -7195,8 +7200,10 @@ union cvmx_lmcx_dll_ctl3 {
                                                          0xE = Vref bypass off.
                                                          0xF = Bit select reset. Clear write deskew settings to default value 0x40 in each DQ bit.
                                                          Also sets Vref bypass to off and deskew reuse setting to off. */
-	uint64_t dclk90_fwd                   : 1;  /**< Reserved; must be zero. INTERNAL: Generate a one cycle pulse to forward setting. This is a
-                                                         oneshot and clears itself each time it is set. */
+	uint64_t dclk90_fwd                   : 1;  /**< When set to one, clock-delay information is forwarded to the neighboring LMC. See LMC CK
+                                                         Locak Initialization step for the LMC bring-up sequence.
+                                                         INTERNAL: Generate a one cycle pulse to forward setting. This is a oneshot and clears
+                                                         itself each time it is set. */
 	uint64_t ddr_90_dly_byp               : 1;  /**< Reserved; must be zero. INTERNAL: Bypass DDR90_DLY in clock tree. */
 	uint64_t dclk90_recal_dis             : 1;  /**< Disable periodic recalibration of DDR90 delay line in. */
 	uint64_t dclk90_byp_sel               : 1;  /**< Bypass setting select for DDR90 delay line. */
@@ -7483,8 +7490,10 @@ union cvmx_lmcx_ext_config {
                                                          DIMM1 instead of DIMM0.
                                                          Intended to be use for the case of DIMM1 having bigger rank/s
                                                          than DIMM0. This bit has priority over DIMM_SEL_INVERT_OFF. */
-	uint64_t coalesce_address_mode        : 1;  /**< When set to 1, this bit enables LMC to coalesce the cache-line
-                                                         address space into the DRAMs' address. */
+	uint64_t coalesce_address_mode        : 1;  /**< When set to 1, LMC coalesces the L2C+LMC internal address mapping
+                                                         to create a uniform memory space that are free from holes in
+                                                         between ranks. When different size DIMMs are used, the DIMM with
+                                                         the smaller size is mapped to the lower address space. */
 	uint64_t dimm1_cid                    : 2;  /**< DIMM1 configuration bits that represent the number of Chip
                                                          ID of the DRAM. This value is use for decoding address
                                                          as well as routing Chip IDs to the appropriate output
@@ -7514,7 +7523,11 @@ union cvmx_lmcx_ext_config {
 	uint64_t par_addr_mask                : 3;  /**< Mask applied to parity for address bits 14, 13, and 12. Clear to exclude these address
                                                          bits from the parity calculation, necessary if the DRAM device does not have these pins. */
 	uint64_t reserved_38_39               : 2;
-	uint64_t mrs_cmd_override             : 1;  /**< Set to override behavior of MRS and RCS DRAM operations. */
+	uint64_t mrs_cmd_override             : 1;  /**< Set to override the behavior of MRS and RCW operations.
+                                                         If this bit is set, the override behavior is governed by the control field
+                                                         MRS_CMD_SELECT. See LMC()_EXT_CONFIG[MRS_CMD_SELECT] for detail.
+                                                         If this bit is cleared, select operation where signals other than CS are active before
+                                                         and after the CS_N active cycle (except for the case when interfacing with DDR3 RDIMM). */
 	uint64_t mrs_cmd_select               : 1;  /**< When MRS_CMD_OVERRIDE is set, use this bit to select which style of operation for MRS and
                                                          RCW commands.
                                                          If this bit is clear, select operation where signals other than CS are active before and
@@ -7548,8 +7561,10 @@ union cvmx_lmcx_ext_config {
                                                          1 to this bit, slot-control registers will update with changes made to other timing-
                                                          control registers. This is a one-shot operation; it automatically returns to 0 after a
                                                          write to 1. */
-	uint64_t ref_int_lsbs                 : 9;  /**< Refresh-interval value least-significant bits. The default is 0x0; but it can be set to a
-                                                         non-zero value to get a more precise refresh interval. */
+	uint64_t ref_int_lsbs                 : 9;  /**< Refresh-interval value least-significant bits. The default is 0x0.
+                                                         Refresh interval is represented in number of 512 CK cycle increments and is controlled by
+                                                         the CSR LMC()_CONFIG[REF_ZQCS_INT]. More precise refresh interval however (in number of
+                                                         1 CK cycle) can be achieved by setting this field to a non-zero value. */
 	uint64_t drive_ena_bprch              : 1;  /**< Drive DQx for one cycle longer than normal during write operations. */
 	uint64_t drive_ena_fprch              : 1;  /**< Drive DQX starting one cycle earlier than normal during write operations. */
 	uint64_t dlcram_flip_synd             : 2;  /**< Reserved. INTERNAL: DLC RAM flip syndrome control bits. */
@@ -7799,7 +7814,11 @@ union cvmx_lmcx_fadr {
 	struct cvmx_lmcx_fadr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t fcid                         : 3;  /**< Failing CID number. */
+	uint64_t fcid                         : 3;  /**< Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
+                                                         either
+                                                         LMC()_EXT_CONFIG[DIMM0_CID] or LMC()_EXT_CONFIG[DIMM1_CID] is non-zero). Returns a value
+                                                         of zero
+                                                         otherwise. */
 	uint64_t fill_order                   : 2;  /**< Fill order for failing transaction. */
 	uint64_t reserved_0_37                : 38;
 #else
@@ -7891,7 +7910,11 @@ union cvmx_lmcx_fadr {
 	struct cvmx_lmcx_fadr_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t fcid                         : 3;  /**< Failing CID number. */
+	uint64_t fcid                         : 3;  /**< Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
+                                                         either
+                                                         LMC()_EXT_CONFIG[DIMM0_CID] or LMC()_EXT_CONFIG[DIMM1_CID] is non-zero). Returns a value
+                                                         of zero
+                                                         otherwise. */
 	uint64_t fill_order                   : 2;  /**< Fill order for failing transaction. */
 	uint64_t fdimm                        : 1;  /**< Failing DIMM number. */
 	uint64_t fbunk                        : 1;  /**< Failing rank number. */
@@ -8215,7 +8238,7 @@ typedef union cvmx_lmcx_int cvmx_lmcx_int_t;
 /**
  * cvmx_lmc#_int_en
  *
- * LMC_INT_EN = LMC Interrupt Enable Register
+ * Unused CSR in O75.
  *
  */
 union cvmx_lmcx_int_en {
@@ -8762,7 +8785,8 @@ union cvmx_lmcx_modereg_params0 {
                                                          operation. */
 	uint64_t wrp                          : 3;  /**< Write recovery for auto precharge. Should be programmed to be equal to or greater than
                                                          RNDUP[TWR(ns) / Tcyc(ns)].
-                                                         0x0 = 5.
+                                                         DDR3:
+                                                         0x0 = 16.
                                                          0x1 = 5.
                                                          0x2 = 6.
                                                          0x3 = 7.
@@ -8770,6 +8794,16 @@ union cvmx_lmcx_modereg_params0 {
                                                          0x5 = 10.
                                                          0x6 = 12.
                                                          0x7 = 14.
+                                                         DDR4:
+                                                         0x0 = 10.
+                                                         0x1 = 12.
+                                                         0x2 = 14.
+                                                         0x3 = 16.
+                                                         0x4 = 18.
+                                                         0x5 = 20.
+                                                         0x6 = 24.
+                                                         0x7 = 22.
+                                                         0x8-0xf = Reserved. (Note that LMC()_MODEREG_PARAMS0[WRP_EXT] = 1).
                                                          LMC writes this value to MR0[WR] in the selected DDR3/DDR4 parts during power-up/init and,
                                                          if
                                                          LMC()_CONFIG[SREF_WITH_DLL] is set, self-refresh exit instruction sequences. See
@@ -9737,7 +9771,15 @@ union cvmx_lmcx_mpr_data0 {
 	struct cvmx_lmcx_mpr_data0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t mpr_data                     : 64; /**< MPR data bits<63:0>. Bits<7:0> represent the MPR data for the lowest-order *4 device (*4
-                                                         device 0); bits<15:8> represent *4 device 1; ..., bits<63:56> are for *4 device 7. */
+                                                         device 0); bits<15:8> represent *4 device 1; ..., bits<63:56> are for *4 device 7.
+                                                         This field is also used to store the results after running the Data Buffer Training
+                                                         sequence
+                                                         (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
+                                                         The format of the stored results is controlled by the CSR LMC()_DBTRAIN_CTL[RW_TRAIN].
+                                                         When LMC()_DBTRAIN_CTL[RW_TRAIN] = 1, this field stores the R/W comparison output
+                                                         from all DQ63 - DQ0.
+                                                         When LMC()_DBTRAIN_CTL[RW_TRAIN] = 0, this field stores the positive edge read data
+                                                         on a particular cycle coming from DQ63 - DQ0. */
 #else
 	uint64_t mpr_data                     : 64;
 #endif
@@ -9762,7 +9804,16 @@ union cvmx_lmcx_mpr_data1 {
 	struct cvmx_lmcx_mpr_data1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t mpr_data                     : 64; /**< MPR data bits<127:64>. Bits<7:0> represent the MPR data for *4 device 8; bits<15:8>
-                                                         represent *4 device 9; ...; bits<63:56> are for *4 device 15. */
+                                                         represent *4 device 9; ...; bits<63:56> are for *4 device 15.
+                                                         This field is also used to store the results after running the Data Buffer Training
+                                                         sequence
+                                                         (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
+                                                         The format of the stored results is controlled by the CSR LMC()_DBTRAIN_CTL[RW_TRAIN].
+                                                         When LMC()_DBTRAIN_CTL[RW_TRAIN] = 1, this field stores the R/W comparison output
+                                                         from the ECC byte (DQ71 - DQ64).
+                                                         When LMC()_DBTRAIN_CTL[RW_TRAIN] = 0, MPR_DATA<7:0> stores the positive edge read data
+                                                         on a particular cycle coming from the ECC byte (DQ71 - DQ64), while
+                                                         MPR_DATA<64:8> stores the negative edge read data coming from DQ55 - DQ0. */
 #else
 	uint64_t mpr_data                     : 64;
 #endif
@@ -9788,7 +9839,14 @@ union cvmx_lmcx_mpr_data2 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t mpr_data                     : 16; /**< MPR data bits<143:128>. Bits<7:0> represent the MPR data for *4 device 16; bits<15:8>
-                                                         represent *4 device 17. */
+                                                         represent *4 device 17.
+                                                         This field is also used to store the results after running the Data Buffer Training
+                                                         sequence
+                                                         (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
+                                                         The format of the stored results is controlled by the CSR LMC()_DBTRAIN_CTL[RW_TRAIN].
+                                                         When LMC()_DBTRAIN_CTL[RW_TRAIN] = 1, this field is not used.
+                                                         When LMC()_DBTRAIN_CTL[RW_TRAIN] = 0, MPR_DATA<15:0> stores the negative edge read data
+                                                         on a particular cycle coming from DQ71 - DQ56. */
 #else
 	uint64_t mpr_data                     : 16;
 	uint64_t reserved_16_63               : 48;
@@ -9806,7 +9864,7 @@ typedef union cvmx_lmcx_mpr_data2 cvmx_lmcx_mpr_data2_t;
 /**
  * cvmx_lmc#_mr_mpr_ctl
  *
- * This register sets timing parameters for DDR4.
+ * This register provides the control functions when programming the MPR of DDR4 DRAMs.
  *
  */
 union cvmx_lmcx_mr_mpr_ctl {
@@ -9822,10 +9880,8 @@ union cvmx_lmcx_mr_mpr_ctl {
 	uint64_t pba_func_space               : 3;  /**< Set the Function Space Selector during PBA mode of the MRW
                                                          sequence. */
 	uint64_t mr_wr_bg1                    : 1;  /**< BG1 part of the address select for MRS in DDR4 mode. */
-	uint64_t mpr_sample_dq_enable         : 1;  /**< Reserved. INTERNAL: Sample the whole r128dat1_2a and r128dat0_2a
-                                                         in one cycle. This has priority over the whole-byte mode. i.e., when
-                                                         this bit is set to 1, the MPR register ignores the value of the
-                                                         MPR_WHOLE_BYTE_ENABLE bit. */
+	uint64_t mpr_sample_dq_enable         : 1;  /**< Reserved. INTERNAL: No longer used due to logic change from
+                                                         initial design. */
 	uint64_t pda_early_dqx                : 1;  /**< When set, it enables lmc_dqx early for PDA/PBA operation. */
 	uint64_t mr_wr_pba_enable             : 1;  /**< Per Buffer Addressability write enable. When set, MRW operations use PBA, enabled by
                                                          MR_WR_PDA_MASK per buffer.
@@ -10284,11 +10340,13 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t c1_sel                       : 2;  /**< 0x0 = C1 is not routed to any output pin.
                                                          0x1 = C1 is routed to CS3.
                                                          0x2 = C1 is routed to A17 address pin.
-                                                         0x3 = C1 is not routed to any output pin. */
+                                                         0x3 = C1 is not routed to any output pin.
+                                                         Set to 0x0 if not interfacing with 3DS DRAM. */
 	uint64_t c0_sel                       : 2;  /**< 0x0 = C0 is not routed to any output pin.
                                                          0x1 = C0 is routed to CS2.
                                                          0x2 = C0 is routed to TEN output pin.
-                                                         0x3 = C0 is not routed to any output pin. */
+                                                         0x3 = C0 is not routed to any output pin.
+                                                         Set to 0x0 if not interfacing with 3DS DRAM. */
 	uint64_t phy_reset                    : 1;  /**< Reserved. INTERNAL: Write to 1 to reset the PHY, one-shot operation, will automatically
                                                          clear to value of 0. */
 	uint64_t dsk_dbg_rd_complete          : 1;  /**< Reserved. INTERNAL: Indicates completion of a read operation, will clear to 0 when a read
@@ -10305,9 +10363,8 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t dsk_dbg_offset               : 2;  /**< Reserved. INTERNAL: Offset to change delay of deskew debug data return time to LMC from
                                                          DDR PHY. */
 	uint64_t dsk_dbg_num_bits_sel         : 1;  /**< Reserved. INTERNAL: Deskew debug, select number of bits per byte lane.
-                                                         0 = 8 bits per byte lane, no DBI, no DAC debug. (mainly for o70)
-                                                         1 = 10 bits per byte lane, including DBI and DAC. (must be set to 1, sinc o73 has DBI
-                                                         and DAC bypass). */
+                                                         0 = 8 bits per byte lane, no DBI, no DAC debug. CN70XX has to be set to this value.
+                                                         1 = 10 bits per byte lane, including DBI and DAC. CNXXXX has to be set to this value. */
 	uint64_t dsk_dbg_byte_sel             : 4;  /**< Reserved. INTERNAL: Deskew debug byte select for read operation. Values 0-3 correspond to
                                                          byte lanes 0-3, 4 is for ECC, 5-8 are byte lanes 4-7. */
 	uint64_t dsk_dbg_bit_sel              : 4;  /**< Reserved. INTERNAL: Deskew debug bit select for dsk read operation.
@@ -10333,7 +10390,9 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t phy_dsk_byp                  : 1;  /**< PHY deskew bypass. */
 	uint64_t phy_pwr_save_disable         : 1;  /**< DDR PHY power save disable. */
 	uint64_t ten                          : 1;  /**< DDR PHY test enable pin. */
-	uint64_t rx_always_on                 : 1;  /**< Reserved; must be zero. INTERNAL: Set to force read_enable to PHY active all the time. */
+	uint64_t rx_always_on                 : 1;  /**< Reserved; must be zero. INTERNAL: Set to force read_enable to PHY active all the time.
+                                                         This bit MUST not be set when LMC initialization is in progress. Internal VREF and
+                                                         Deskew training requires normal operation on the dqx/s read_enable signals. */
 	uint64_t lv_mode                      : 1;  /**< Reserved; must be zero. INTERNAL: Low Voltage Mode (1.35V.) */
 	uint64_t ck_tune1                     : 1;  /**< Reserved; must be zero. INTERNAL: Clock tune. */
 	uint64_t ck_dlyout1                   : 4;  /**< Reserved; must be zero. INTERNAL: Clock delay out. */
@@ -10558,11 +10617,13 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t c1_sel                       : 2;  /**< 0x0 = C1 is not routed to any output pin.
                                                          0x1 = C1 is routed to CS3.
                                                          0x2 = C1 is routed to A17 address pin.
-                                                         0x3 = C1 is not routed to any output pin. */
+                                                         0x3 = C1 is not routed to any output pin.
+                                                         Set to 0x0 if not interfacing with 3DS DRAM. */
 	uint64_t c0_sel                       : 2;  /**< 0x0 = C0 is not routed to any output pin.
                                                          0x1 = C0 is routed to CS2.
                                                          0x2 = C0 is routed to TEN output pin.
-                                                         0x3 = C0 is not routed to any output pin. */
+                                                         0x3 = C0 is not routed to any output pin.
+                                                         Set to 0x0 if not interfacing with 3DS DRAM. */
 	uint64_t phy_reset                    : 1;  /**< Reserved. INTERNAL: Write to 1 to reset the PHY, one-shot operation, will automatically
                                                          clear to value of 0. */
 	uint64_t dsk_dbg_rd_complete          : 1;  /**< Reserved. INTERNAL: Indicates completion of a read operation, will clear to 0 when a read
@@ -10579,9 +10640,8 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t dsk_dbg_offset               : 2;  /**< Reserved. INTERNAL: Offset to change delay of deskew debug data return time to LMC from
                                                          DDR PHY. */
 	uint64_t dsk_dbg_num_bits_sel         : 1;  /**< Reserved. INTERNAL: Deskew debug, select number of bits per byte lane.
-                                                         0 = 8 bits per byte lane, no DBI, no DAC debug. (mainly for o70)
-                                                         1 = 10 bits per byte lane, including DBI and DAC. (must be set to 1, sinc o73 has DBI
-                                                         and DAC bypass). */
+                                                         0 = 8 bits per byte lane, no DBI, no DAC debug. CN70XX has to be set to this value.
+                                                         1 = 10 bits per byte lane, including DBI and DAC. CNXXXX has to be set to this value. */
 	uint64_t dsk_dbg_byte_sel             : 4;  /**< Reserved. INTERNAL: Deskew debug byte select for read operation. Values 0-3 correspond to
                                                          byte lanes 0-3, 4 is for ECC, 5-8 are byte lanes 4-7. */
 	uint64_t dsk_dbg_bit_sel              : 4;  /**< Reserved. INTERNAL: Deskew debug bit select for dsk read operation.
@@ -10607,7 +10667,9 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t phy_dsk_byp                  : 1;  /**< PHY deskew bypass. */
 	uint64_t phy_pwr_save_disable         : 1;  /**< DDR PHY power save disable. */
 	uint64_t ten                          : 1;  /**< DDR PHY test enable pin. */
-	uint64_t rx_always_on                 : 1;  /**< Reserved; must be zero. INTERNAL: Set to force read_enable to PHY active all the time. */
+	uint64_t rx_always_on                 : 1;  /**< Reserved; must be zero. INTERNAL: Set to force read_enable to PHY active all the time.
+                                                         This bit MUST not be set when LMC initialization is in progress. Internal VREF and
+                                                         Deskew training requires normal operation on the dqx/s read_enable signals. */
 	uint64_t lv_mode                      : 1;  /**< Reserved; must be zero. INTERNAL: Low Voltage Mode (1.35V.) */
 	uint64_t ck_tune1                     : 1;  /**< Reserved; must be zero. INTERNAL: Clock tune. */
 	uint64_t ck_dlyout1                   : 4;  /**< Reserved; must be zero. INTERNAL: Clock delay out. */
@@ -11181,9 +11243,10 @@ union cvmx_lmcx_reset_ctl {
                                                          Note that if a warm reset follows a soft reset, DDR3PWARM has no effect, as the DDR3/DDR4
                                                          controller is no longer up after any cold/warm/soft reset sequence. */
 	uint64_t ddr3rst                      : 1;  /**< "Memory reset. 0 = Reset asserted; 1 = Reset deasserted.
-                                                         DDR3/DDR4 DRAM parts have a RESET# pin that was not present in DDR2 parts. The DDR3RST CSR
-                                                         field controls the assertion of the new CNXXXX pin that attaches to RESET#. When DDR3RST
-                                                         is set, CNXXXX deasserts RESET#. When DDR3RST is clear, CNXXXX asserts RESET#.
+                                                         DDR3/DDR4 DRAM parts have a RESET# pin. The DDR3RST CSR field controls the assertion of
+                                                         the new CNXXXX pin that attaches to RESET#.
+                                                         When DDR3RST is set, CNXXXX deasserts RESET#.
+                                                         When DDR3RST is clear, CNXXXX asserts RESET#.
                                                          DDR3RST is cleared on a cold reset. Warm and soft chip resets do not affect the DDR3RST
                                                          value.
                                                          Outside of cold reset, only software CSR write operations change the DDR3RST value." */
@@ -11880,7 +11943,11 @@ union cvmx_lmcx_scrambled_fadr {
 	struct cvmx_lmcx_scrambled_fadr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t fcid                         : 3;  /**< Failing CID number. */
+	uint64_t fcid                         : 3;  /**< Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
+                                                         either
+                                                         LMC()_EXT_CONFIG[DIMM0_CID] or LMC()_EXT_CONFIG[DIMM1_CID] is non-zero). Returns a value
+                                                         of zero
+                                                         otherwise. */
 	uint64_t fill_order                   : 2;  /**< Fill order for failing transaction. */
 	uint64_t reserved_14_37               : 24;
 	uint64_t fcol                         : 14; /**< Failing column address <13:0>. Technically, represents the address of the 128b data that
@@ -11941,7 +12008,11 @@ union cvmx_lmcx_scrambled_fadr {
 	struct cvmx_lmcx_scrambled_fadr_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t fcid                         : 3;  /**< Failing CID number. */
+	uint64_t fcid                         : 3;  /**< Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
+                                                         either
+                                                         LMC()_EXT_CONFIG[DIMM0_CID] or LMC()_EXT_CONFIG[DIMM1_CID] is non-zero). Returns a value
+                                                         of zero
+                                                         otherwise. */
 	uint64_t fill_order                   : 2;  /**< Fill order for failing transaction. */
 	uint64_t fdimm                        : 1;  /**< Failing DIMM number. */
 	uint64_t fbunk                        : 1;  /**< Failing rank number. */
@@ -11989,7 +12060,7 @@ union cvmx_lmcx_seq_ctl {
                                                          LMC()_CONTROL[RDIMM_ENA] = 1 and corresponding LMC()_DIMM_CTL[DIMM*_WMASK] bits
                                                          are set. (Refer to LMC()_DIMM(0..1)_PARAMS and LMC()_DIMM_CTL descriptions for
                                                          more details.)
-                                                         The DRAM registers MR0, MR1, MR2, and MR3 are written in the selected ranks.
+                                                         The DRAM registers MR0-MR6 are written in the selected ranks.
                                                          0x1 = Read-leveling:
                                                          LMC()_CONFIG[RANKMASK] selects the rank to be read-leveled. MR3 written in the
                                                          selected rank.
@@ -12011,7 +12082,33 @@ union cvmx_lmcx_seq_ctl {
                                                          DRAM). In DDR3 mode, RDIMM register control words 0-15 are written to
                                                          LMC()_CONFIG[RANKMASK]-selected RDIMMs when LMC()_CONTROL[RDIMM_ENA] = 1 and
                                                          corresponding LMC()_DIMM_CTL[DIMM*_WMASK] bits are set. (Refer to
-                                                         LMC()_DIMM(0..1)_PARAMS and LMC()_DIMM_CTL descriptions for more details.) */
+                                                         LMC()_DIMM(0..1)_PARAMS and LMC()_DIMM_CTL descriptions for more details.)
+                                                         0x8 = MRW
+                                                         Mode Register Write sequence.
+                                                         0x9 = MPR
+                                                         MPR register read or write sequence.
+                                                         0xa = VREFINT
+                                                         Vref internal training sequence, also used as deskew training sequence when
+                                                         LMC(0..0)_EXT_CONFIG[VREFINT_SEQ_DESKEW] is set.
+                                                         0xb = Offset Training
+                                                         Offset training sequence.
+                                                         0xe = Data Buffer Training. Configurable to run different modes of Data Buffer
+                                                         training on DDR4 LRDIMM. See LMC()_DBTRAIN_CTL for more detail.
+                                                         0xf = DDR4 Post Package Repair sequence. See LMC()_PPR_CTL for more detail.
+                                                         Self-refresh entry SEQ_SEL's may also be automatically
+                                                         generated by hardware upon a chip warm or soft reset
+                                                         sequence when LMC*_RESET_CTL[DDR3PWARM,DDR3PSOFT] are set.
+                                                         LMC writes the LMC*_MODEREG_PARAMS0 and LMC*_MODEREG_PARAMS1 CSR field values
+                                                         to the Mode registers in the DRAM parts (i.e. MR0, MR1, MR2, and MR3) as part of some of
+                                                         these sequences.
+                                                         Refer to the LMC*_MODEREG_PARAMS0 and LMC*_MODEREG_PARAMS1 descriptions for more details.
+                                                         If there are two consecutive power-up/init's without
+                                                         a DRESET assertion between them, LMC asserts DDR_CKE* as part of
+                                                         the first power-up/init, and continues to assert DDR_CKE*
+                                                         through the remainder of the first and the second power-up/init.
+                                                         If DDR_CKE* deactivation and reactivation is needed for
+                                                         a second power-up/init, a DRESET assertion is required
+                                                         between the first and the second." */
 	uint64_t init_start                   : 1;  /**< A 0->1 transition starts the DDR memory sequence that is selected by
                                                          LMC()_SEQ_CTL[SEQ_SEL].
                                                          This register is a one-shot and clears itself each time it is set. */
@@ -13362,7 +13459,7 @@ union cvmx_lmcx_wlevel_ctl {
 	uint64_t sset                         : 1;  /**< Run write-leveling on the current setting only. */
 	uint64_t lanemask                     : 9;  /**< One-shot mask to select byte lane to be leveled by the write-leveling sequence. Used with
                                                          *16 parts where the upper and lower byte lanes need to be leveled independently.
-                                                         This field is also used for byte lane masking in read-leveling sequence. */
+                                                         This field is also used for byte lane masking during read-leveling sequence. */
 #else
 	uint64_t lanemask                     : 9;
 	uint64_t sset                         : 1;
diff --git a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
index 27927d1..5905036 100644
--- a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
@@ -565,7 +565,7 @@ union cvmx_oclax_const {
 	uint64_t reserved_16_63               : 48;
 	uint64_t dat_size                     : 16; /**< Size of data RAM in units of 36-bit entries. This value is subject to change between chip
                                                          passes, and software should thus use this value rather than a hard coded constant.
-                                                         OCLA(0..3) size is 4096, OCLA(4) size is 8192. */
+                                                         OCLA(0..1) size is 4096, OCLA(2) size is 8192. */
 #else
 	uint64_t dat_size                     : 16;
 	uint64_t reserved_16_63               : 48;
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
index 8752c4f..a216b76 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
@@ -8054,7 +8054,9 @@ union cvmx_pcieepx_cfg044 {
                                                          1 = All vectors associated with the function are masked, regardless of their respective
                                                          per-vector mask bits. */
 	uint32_t reserved_27_29               : 3;
-	uint32_t msixts                       : 11; /**< MSI-X table size encoded as (table size - 1). Writable through PEM()_CFG_WR. */
+	uint32_t msixts                       : 11; /**< MSI-X table size encoded as (table size - 1). Writable through PEM()_CFG_WR.
+                                                         This field is writable by issueing a PEM()_CFG_WR to PCIEEP(0)_CFG044
+                                                         when PEM()_CFG_WR[ADDR[31]] is set. */
 	uint32_t ncp                          : 8;  /**< Next capability pointer */
 	uint32_t msixcid                      : 8;  /**< MSI-X Capability ID */
 #else
diff --git a/arch/mips/include/asm/octeon/cvmx-pexp-defs.h b/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
index 2b9c364..3e09d5a 100644
--- a/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
@@ -1149,6 +1149,291 @@ static inline uint64_t CVMX_PEXP_NPEI_WINDOW_CTL_FUNC(void)
 #define CVMX_PEXP_NPEI_WINDOW_CTL (CVMX_ADD_IO_SEG(0x00011F0000008380ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_ACQ(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_ACQ(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000000030ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_ACQ(offset) (CVMX_ADD_IO_SEG(0x0001450000000030ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_AQA(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_AQA(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000000024ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_AQA(offset) (CVMX_ADD_IO_SEG(0x0001450000000024ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_ASQ(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_ASQ(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000000028ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_ASQ(offset) (CVMX_ADD_IO_SEG(0x0001450000000028ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_CAP(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_CAP(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000000000ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_CAP(offset) (CVMX_ADD_IO_SEG(0x0001450000000000ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_CC(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_CC(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000000014ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_CC(offset) (CVMX_ADD_IO_SEG(0x0001450000000014ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_CQX_HDBL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 16)) && ((block_id <= 1027))))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_CQX_HDBL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001450000001004ull) + (((offset) & 31) + ((block_id) & 2047) * 0x4000ull) * 8;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_CQX_HDBL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001450000001004ull) + (((offset) & 31) + ((block_id) & 2047) * 0x4000ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_CSTS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_CSTS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x000145000000001Cull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_CSTS(offset) (CVMX_ADD_IO_SEG(0x000145000000001Cull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_INTMC(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_INTMC(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000000010ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_INTMC(offset) (CVMX_ADD_IO_SEG(0x0001450000000010ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_INTMS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_INTMS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x000145000000000Cull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_INTMS(offset) (CVMX_ADD_IO_SEG(0x000145000000000Cull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_MSIX_PBA(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_MSIX_PBA(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000010200ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_MSIX_PBA(offset) (CVMX_ADD_IO_SEG(0x0001450000010200ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_NSSR(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_NSSR(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000000020ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_NSSR(offset) (CVMX_ADD_IO_SEG(0x0001450000000020ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_SQX_TDBL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 16)) && ((block_id <= 1027))))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_SQX_TDBL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001450000001000ull) + (((offset) & 31) + ((block_id) & 2047) * 0x4000ull) * 8;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_SQX_TDBL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001450000001000ull) + (((offset) & 31) + ((block_id) & 2047) * 0x4000ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_VECX_MSIX_ADDR(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 16)) && ((block_id <= 1027))))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_VECX_MSIX_ADDR(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001450000010000ull) + (((offset) & 31) + ((block_id) & 2047) * 0x2000ull) * 16;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_VECX_MSIX_ADDR(offset, block_id) (CVMX_ADD_IO_SEG(0x0001450000010000ull) + (((offset) & 31) + ((block_id) & 2047) * 0x2000ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_VECX_MSIX_CTL(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 16)) && ((block_id <= 1027))))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_VECX_MSIX_CTL(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001450000010008ull) + (((offset) & 31) + ((block_id) & 2047) * 0x2000ull) * 16;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_VECX_MSIX_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001450000010008ull) + (((offset) & 31) + ((block_id) & 2047) * 0x2000ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_NQM_VFX_VS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 1027)))))
+		cvmx_warn("CVMX_PEXP_NQM_VFX_VS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001450000000008ull) + ((offset) & 2047) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_NQM_VFX_VS(offset) (CVMX_ADD_IO_SEG(0x0001450000000008ull) + ((offset) & 2047) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_MSIXX_TABLE_ADDR(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
+		cvmx_warn("CVMX_PEXP_SLITB_MSIXX_TABLE_ADDR(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000004000ull) + ((offset) & 127) * 16;
+}
+#else
+#define CVMX_PEXP_SLITB_MSIXX_TABLE_ADDR(offset) (CVMX_ADD_IO_SEG(0x00011F0000004000ull) + ((offset) & 127) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_MSIXX_TABLE_DATA(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
+		cvmx_warn("CVMX_PEXP_SLITB_MSIXX_TABLE_DATA(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000004008ull) + ((offset) & 127) * 16;
+}
+#else
+#define CVMX_PEXP_SLITB_MSIXX_TABLE_DATA(offset) (CVMX_ADD_IO_SEG(0x00011F0000004008ull) + ((offset) & 127) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_MSIX_MACX_PFX_TABLE_ADDR(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLITB_MSIX_MACX_PFX_TABLE_ADDR(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000002000ull) + ((offset) & 1) * 4096 + ((block_id) & 3) * 0x10ull;
+}
+#else
+#define CVMX_PEXP_SLITB_MSIX_MACX_PFX_TABLE_ADDR(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000002000ull) + ((offset) & 1) * 4096 + ((block_id) & 3) * 0x10ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_MSIX_MACX_PFX_TABLE_DATA(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLITB_MSIX_MACX_PFX_TABLE_DATA(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000002008ull) + ((offset) & 1) * 4096 + ((block_id) & 3) * 0x10ull;
+}
+#else
+#define CVMX_PEXP_SLITB_MSIX_MACX_PFX_TABLE_DATA(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000002008ull) + ((offset) & 1) * 4096 + ((block_id) & 3) * 0x10ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_PFX_PKT_CNT_INT(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 4))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 4)))))
+		cvmx_warn("CVMX_PEXP_SLITB_PFX_PKT_CNT_INT(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000008000ull) + ((offset) & 7) * 16;
+}
+#else
+#define CVMX_PEXP_SLITB_PFX_PKT_CNT_INT(offset) (CVMX_ADD_IO_SEG(0x00011F0000008000ull) + ((offset) & 7) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_PFX_PKT_INT(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 4))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 4)))))
+		cvmx_warn("CVMX_PEXP_SLITB_PFX_PKT_INT(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000008300ull) + ((offset) & 7) * 16;
+}
+#else
+#define CVMX_PEXP_SLITB_PFX_PKT_INT(offset) (CVMX_ADD_IO_SEG(0x00011F0000008300ull) + ((offset) & 7) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_PFX_PKT_IN_INT(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 4))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 4)))))
+		cvmx_warn("CVMX_PEXP_SLITB_PFX_PKT_IN_INT(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000008200ull) + ((offset) & 7) * 16;
+}
+#else
+#define CVMX_PEXP_SLITB_PFX_PKT_IN_INT(offset) (CVMX_ADD_IO_SEG(0x00011F0000008200ull) + ((offset) & 7) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_PFX_PKT_RING_RST(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 4))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 4)))))
+		cvmx_warn("CVMX_PEXP_SLITB_PFX_PKT_RING_RST(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000008400ull) + ((offset) & 7) * 16;
+}
+#else
+#define CVMX_PEXP_SLITB_PFX_PKT_RING_RST(offset) (CVMX_ADD_IO_SEG(0x00011F0000008400ull) + ((offset) & 7) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_PFX_PKT_TIME_INT(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 4))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 4)))))
+		cvmx_warn("CVMX_PEXP_SLITB_PFX_PKT_TIME_INT(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000008100ull) + ((offset) & 7) * 16;
+}
+#else
+#define CVMX_PEXP_SLITB_PFX_PKT_TIME_INT(offset) (CVMX_ADD_IO_SEG(0x00011F0000008100ull) + ((offset) & 7) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLITB_PKTX_PF_VF_MBOX_SIGX(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 127)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 127))))))
+		cvmx_warn("CVMX_PEXP_SLITB_PKTX_PF_VF_MBOX_SIGX(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000011000ull) + (((offset) & 1) + ((block_id) & 127) * 0x4000ull) * 8;
+}
+#else
+#define CVMX_PEXP_SLITB_PKTX_PF_VF_MBOX_SIGX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000011000ull) + (((offset) & 1) + ((block_id) & 127) * 0x4000ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PEXP_SLI_BIST_STATUS CVMX_PEXP_SLI_BIST_STATUS_FUNC()
 static inline uint64_t CVMX_PEXP_SLI_BIST_STATUS_FUNC(void)
 {
@@ -1560,6 +1845,126 @@ static inline uint64_t CVMX_PEXP_SLI_LAST_WIN_RDATA3_FUNC(void)
 #define CVMX_PEXP_SLI_LAST_WIN_RDATA3 (CVMX_ADD_IO_SEG(0x00011F00000106D0ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_DMA_VF_INT(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_DMA_VF_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027280ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_DMA_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027280ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_DMA_VF_INT_ENB(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_DMA_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027500ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_DMA_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027500ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_FLR_VF_INT(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_FLR_VF_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027400ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_FLR_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027400ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_INT_ENB(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027080ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027080ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_INT_SUM(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_INT_SUM(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027000ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_INT_SUM(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027000ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_MBOX_INT(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_MBOX_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027380ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_MBOX_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027380ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_PKT_VF_INT(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_PKT_VF_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027300ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_PKT_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027300ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_PKT_VF_INT_ENB(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_PKT_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027580ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_PKT_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027580ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_PP_VF_INT(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_PP_VF_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027200ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_PP_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027200ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MACX_PFX_PP_VF_INT_ENB(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_MACX_PFX_PP_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000027480ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MACX_PFX_PP_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027480ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PEXP_SLI_MAC_CREDIT_CNT CVMX_PEXP_SLI_MAC_CREDIT_CNT_FUNC()
 static inline uint64_t CVMX_PEXP_SLI_MAC_CREDIT_CNT_FUNC(void)
 {
@@ -1784,6 +2189,88 @@ static inline uint64_t CVMX_PEXP_SLI_MEM_INT_SUM_FUNC(void)
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 64))
+				return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + ((offset) & 127) * 16;
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 64))
+				return CVMX_ADD_IO_SEG(0x00011F0000016000ull) + ((offset) & 127) * 16;
+			break;
+	}
+	cvmx_warn("CVMX_PEXP_SLI_MSIXX_TABLE_ADDR (offset = %lu) not supported on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + ((offset) & 127) * 16;
+}
+#else
+static inline uint64_t CVMX_PEXP_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + (offset) * 16;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000016000ull) + (offset) * 16;
+	}
+	return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + (offset) * 16;
+}
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MSIXX_TABLE_DATA(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 64))
+				return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + ((offset) & 127) * 16;
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 64))
+				return CVMX_ADD_IO_SEG(0x00011F0000016008ull) + ((offset) & 127) * 16;
+			break;
+	}
+	cvmx_warn("CVMX_PEXP_SLI_MSIXX_TABLE_DATA (offset = %lu) not supported on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + ((offset) & 127) * 16;
+}
+#else
+static inline uint64_t CVMX_PEXP_SLI_MSIXX_TABLE_DATA(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + (offset) * 16;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000016008ull) + (offset) * 16;
+	}
+	return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + (offset) * 16;
+}
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MSIX_MACX_PF_TABLE_ADDR(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3)))))
+		cvmx_warn("CVMX_PEXP_SLI_MSIX_MACX_PF_TABLE_ADDR(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000017C00ull) + ((offset) & 3) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MSIX_MACX_PF_TABLE_ADDR(offset) (CVMX_ADD_IO_SEG(0x00011F0000017C00ull) + ((offset) & 3) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_MSIX_MACX_PF_TABLE_DATA(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3)))))
+		cvmx_warn("CVMX_PEXP_SLI_MSIX_MACX_PF_TABLE_DATA(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000017C08ull) + ((offset) & 3) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_MSIX_MACX_PF_TABLE_DATA(offset) (CVMX_ADD_IO_SEG(0x00011F0000017C08ull) + ((offset) & 3) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PEXP_SLI_MSIX_PBA0 CVMX_PEXP_SLI_MSIX_PBA0_FUNC()
 static inline uint64_t CVMX_PEXP_SLI_MSIX_PBA0_FUNC(void)
 {
@@ -2442,6 +2929,48 @@ static inline uint64_t CVMX_PEXP_SLI_PKTX_CNTS(unsigned long offset)
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKTX_ERROR_INFO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
+		cvmx_warn("CVMX_PEXP_SLI_PKTX_ERROR_INFO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F00000100C0ull) + ((offset) & 127) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_SLI_PKTX_ERROR_INFO(offset) (CVMX_ADD_IO_SEG(0x00011F00000100C0ull) + ((offset) & 127) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 127))
+				return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + ((offset) & 127) * 0x20000ull;
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 63))
+				return CVMX_ADD_IO_SEG(0x00011F0000014000ull) + ((offset) & 63) * 16;
+			break;
+	}
+	cvmx_warn("CVMX_PEXP_SLI_PKTX_INPUT_CONTROL (offset = %lu) not supported on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + ((offset) & 127) * 0x20000ull;
+}
+#else
+static inline uint64_t CVMX_PEXP_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + (offset) * 0x20000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000014000ull) + (offset) * 16;
+	}
+	return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + (offset) * 0x20000ull;
+}
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEXP_SLI_PKTX_INSTR_BADDR(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
@@ -2596,6 +3125,36 @@ static inline uint64_t CVMX_PEXP_SLI_PKTX_INSTR_HEADER(unsigned long offset)
 #define CVMX_PEXP_SLI_PKTX_INSTR_HEADER(offset) (CVMX_ADD_IO_SEG(0x00011F0000013400ull) + ((offset) & 31) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKTX_INT_LEVELS(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 127))
+				return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + ((offset) & 127) * 0x20000ull;
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 63))
+				return CVMX_ADD_IO_SEG(0x00011F0000014400ull) + ((offset) & 63) * 16;
+			break;
+	}
+	cvmx_warn("CVMX_PEXP_SLI_PKTX_INT_LEVELS (offset = %lu) not supported on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + ((offset) & 127) * 0x20000ull;
+}
+#else
+static inline uint64_t CVMX_PEXP_SLI_PKTX_INT_LEVELS(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + (offset) * 0x20000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000014400ull) + (offset) * 16;
+	}
+	return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + (offset) * 0x20000ull;
+}
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEXP_SLI_PKTX_IN_BP(unsigned long offset)
 {
 	if (!(
@@ -2611,6 +3170,48 @@ static inline uint64_t CVMX_PEXP_SLI_PKTX_IN_BP(unsigned long offset)
 #define CVMX_PEXP_SLI_PKTX_IN_BP(offset) (CVMX_ADD_IO_SEG(0x00011F0000013800ull) + ((offset) & 31) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKTX_MBOX_INT(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
+		cvmx_warn("CVMX_PEXP_SLI_PKTX_MBOX_INT(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000010210ull) + ((offset) & 127) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_SLI_PKTX_MBOX_INT(offset) (CVMX_ADD_IO_SEG(0x00011F0000010210ull) + ((offset) & 127) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 127))
+				return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 127) * 0x20000ull;
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 63))
+				return CVMX_ADD_IO_SEG(0x00011F0000014800ull) + ((offset) & 63) * 16;
+			break;
+	}
+	cvmx_warn("CVMX_PEXP_SLI_PKTX_OUTPUT_CONTROL (offset = %lu) not supported on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 127) * 0x20000ull;
+}
+#else
+static inline uint64_t CVMX_PEXP_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 0x20000ull;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00011F0000014800ull) + (offset) * 16;
+	}
+	return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 0x20000ull;
+}
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEXP_SLI_PKTX_OUT_SIZE(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
@@ -2657,6 +3258,18 @@ static inline uint64_t CVMX_PEXP_SLI_PKTX_OUT_SIZE(unsigned long offset)
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKTX_PF_VF_MBOX_SIGX(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 63)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 63))))))
+		cvmx_warn("CVMX_PEXP_SLI_PKTX_PF_VF_MBOX_SIGX(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000010200ull) + (((offset) & 1) + ((block_id) & 63) * 0x4000ull) * 8;
+}
+#else
+#define CVMX_PEXP_SLI_PKTX_PF_VF_MBOX_SIGX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000010200ull) + (((offset) & 1) + ((block_id) & 63) * 0x4000ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PEXP_SLI_PKTX_SLIST_BADDR(unsigned long offset)
 {
 	switch(cvmx_get_octeon_family()) {
@@ -2795,6 +3408,29 @@ static inline uint64_t CVMX_PEXP_SLI_PKTX_SLIST_FIFO_RSIZE(unsigned long offset)
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKTX_VF_INT_SUM(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
+		cvmx_warn("CVMX_PEXP_SLI_PKTX_VF_INT_SUM(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F00000100D0ull) + ((offset) & 127) * 0x20000ull;
+}
+#else
+#define CVMX_PEXP_SLI_PKTX_VF_INT_SUM(offset) (CVMX_ADD_IO_SEG(0x00011F00000100D0ull) + ((offset) & 127) * 0x20000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKTX_VF_SIG(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 63)))))
+		cvmx_warn("CVMX_PEXP_SLI_PKTX_VF_SIG(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000014C00ull) + ((offset) & 63) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_PKTX_VF_SIG(offset) (CVMX_ADD_IO_SEG(0x00011F0000014C00ull) + ((offset) & 63) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PEXP_SLI_PKT_BIST_STATUS CVMX_PEXP_SLI_PKT_BIST_STATUS_FUNC()
 static inline uint64_t CVMX_PEXP_SLI_PKT_BIST_STATUS_FUNC(void)
 {
@@ -3216,6 +3852,29 @@ static inline uint64_t CVMX_PEXP_SLI_PKT_MAC1_SIG1_FUNC(void)
 #define CVMX_PEXP_SLI_PKT_MAC1_SIG1 (CVMX_ADD_IO_SEG(0x00011F0000011330ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKT_MACX_PFX_RINFO(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
+		cvmx_warn("CVMX_PEXP_SLI_PKT_MACX_PFX_RINFO(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011F0000029030ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_PKT_MACX_PFX_RINFO(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000029030ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PEXP_SLI_PKT_MACX_RINFO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3)))))
+		cvmx_warn("CVMX_PEXP_SLI_PKT_MACX_RINFO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011F0000011030ull) + ((offset) & 3) * 16;
+}
+#else
+#define CVMX_PEXP_SLI_PKT_MACX_RINFO(offset) (CVMX_ADD_IO_SEG(0x00011F0000011030ull) + ((offset) & 3) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PEXP_SLI_PKT_MEM_CTL CVMX_PEXP_SLI_PKT_MEM_CTL_FUNC()
 static inline uint64_t CVMX_PEXP_SLI_PKT_MEM_CTL_FUNC(void)
 {
diff --git a/arch/mips/include/asm/octeon/cvmx-qlm.h b/arch/mips/include/asm/octeon/cvmx-qlm.h
index 86429c9..acd48cd 100644
--- a/arch/mips/include/asm/octeon/cvmx-qlm.h
+++ b/arch/mips/include/asm/octeon/cvmx-qlm.h
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 121394 $<hr>
+ * <hr>$Revision: 121917 $<hr>
  */
 
 #ifndef __CVMX_QLM_H__
@@ -83,9 +83,28 @@ extern int cvmx_qlm_get_num(void);
 /**
  * Return the qlm number based on the interface
  *
- * @param xiface  Interface to look up
+ * @param interface  Interface to look
  */
-extern int cvmx_qlm_interface(int xiface);
+extern int cvmx_qlm_interface(int interface);
+
+/**
+ * Return the qlm number based for a port in the interface
+ *
+ * @param xiface  interface to look up
+ * @param index  index in an interface
+ *
+ * @return the qlm number based on the xiface
+ */
+extern int cvmx_qlm_lmac(int xiface, int index);
+
+/**
+ * Return if only DLM5/DLM6/DLM5+DLM6 is used by BGX
+ *
+ * @param BGX  BGX to search for.
+ *
+ * @return muxes used 0 = DLM5+DLM6, 1 = DLM5, 2 = DLM6.
+ */
+extern int cvmx_qlm_mux_interface(int bgx);
 
 /**
  * Return number of lanes for a given qlm
diff --git a/arch/mips/include/asm/octeon/cvmx-sli-defs.h b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
index 9c86091..0b14bb8 100644
--- a/arch/mips/include/asm/octeon/cvmx-sli-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
@@ -64,15 +64,15 @@ static inline uint64_t CVMX_SLI_BIST_STATUS_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0000000000010580ull);
+			return 0x0000000000000580ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0000000000028580ull);
+			return 0x0000000000028580ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_BIST_STATUS not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0000000000028580ull);
+	return 0x0000000000028580ull;
 }
 #else
 #define CVMX_SLI_BIST_STATUS CVMX_SLI_BIST_STATUS_FUNC()
@@ -86,12 +86,12 @@ static inline uint64_t CVMX_SLI_BIST_STATUS_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0000000000010580ull);
+			return 0x0000000000000580ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0000000000028580ull);
+			return 0x0000000000028580ull;
 	}
-	return CVMX_ADD_IO_SEG(0x0000000000028580ull);
+	return 0x0000000000028580ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -125,28 +125,28 @@ static inline uint64_t CVMX_SLI_CTL_PORTX(unsigned long offset)
 		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 1) * 16;
+				return 0x0000000000000050ull + ((offset) & 1) * 16;
 			break;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 2))
-				return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 3) * 16;
+				return 0x0000000000010050ull + ((offset) & 3) * 16;
 			break;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
-				return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 3) * 16;
+				return 0x0000000000000050ull + ((offset) & 3) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
-				return CVMX_ADD_IO_SEG(0x00011F00000106E0ull) + ((offset) & 3) * 16;
+				return 0x00000000000106E0ull + ((offset) & 3) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
-				return CVMX_ADD_IO_SEG(0x00011F00000286E0ull) + ((offset) & 3) * 16;
+				return 0x00000000000286E0ull + ((offset) & 3) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_CTL_PORTX (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F00000286E0ull) + ((offset) & 3) * 16;
+	return 0x00000000000286E0ull + ((offset) & 3) * 16;
 }
 #else
 static inline uint64_t CVMX_SLI_CTL_PORTX(unsigned long offset)
@@ -156,18 +156,18 @@ static inline uint64_t CVMX_SLI_CTL_PORTX(unsigned long offset)
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 16;
+			return 0x0000000000000050ull + (offset) * 16;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 16;
+			return 0x0000000000010050ull + (offset) * 16;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 16;
+			return 0x0000000000000050ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000106E0ull) + (offset) * 16;
+			return 0x00000000000106E0ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000286E0ull) + (offset) * 16;
+			return 0x00000000000286E0ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000286E0ull) + (offset) * 16;
+	return 0x00000000000286E0ull + (offset) * 16;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -182,15 +182,15 @@ static inline uint64_t CVMX_SLI_CTL_STATUS_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0000000000010570ull);
+			return 0x0000000000000570ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0000000000028570ull);
+			return 0x0000000000028570ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_CTL_STATUS not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0000000000028570ull);
+	return 0x0000000000028570ull;
 }
 #else
 #define CVMX_SLI_CTL_STATUS CVMX_SLI_CTL_STATUS_FUNC()
@@ -204,12 +204,12 @@ static inline uint64_t CVMX_SLI_CTL_STATUS_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0000000000010570ull);
+			return 0x0000000000000570ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0000000000028570ull);
+			return 0x0000000000028570ull;
 	}
-	return CVMX_ADD_IO_SEG(0x0000000000028570ull);
+	return 0x0000000000028570ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -224,15 +224,15 @@ static inline uint64_t CVMX_SLI_DATA_OUT_CNT_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105F0ull);
+			return 0x00000000000005F0ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000285F0ull);
+			return 0x00000000000285F0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_DATA_OUT_CNT not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F00000285F0ull);
+	return 0x00000000000285F0ull;
 }
 #else
 #define CVMX_SLI_DATA_OUT_CNT CVMX_SLI_DATA_OUT_CNT_FUNC()
@@ -246,12 +246,12 @@ static inline uint64_t CVMX_SLI_DATA_OUT_CNT_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105F0ull);
+			return 0x00000000000005F0ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000285F0ull);
+			return 0x00000000000285F0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000285F0ull);
+	return 0x00000000000285F0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -288,16 +288,16 @@ static inline uint64_t CVMX_SLI_DMAX_CNT(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011F0000010400ull) + ((offset) & 1) * 16;
+				return 0x0000000000000400ull + ((offset) & 1) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011F0000028400ull) + ((offset) & 1) * 16;
+				return 0x0000000000028400ull + ((offset) & 1) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_DMAX_CNT (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000028400ull) + ((offset) & 1) * 16;
+	return 0x0000000000028400ull + ((offset) & 1) * 16;
 }
 #else
 static inline uint64_t CVMX_SLI_DMAX_CNT(unsigned long offset)
@@ -310,12 +310,12 @@ static inline uint64_t CVMX_SLI_DMAX_CNT(unsigned long offset)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010400ull) + (offset) * 16;
+			return 0x0000000000000400ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028400ull) + (offset) * 16;
+			return 0x0000000000028400ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000028400ull) + (offset) * 16;
+	return 0x0000000000028400ull + (offset) * 16;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -330,16 +330,16 @@ static inline uint64_t CVMX_SLI_DMAX_INT_LEVEL(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011F00000103E0ull) + ((offset) & 1) * 16;
+				return 0x00000000000003E0ull + ((offset) & 1) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011F00000283E0ull) + ((offset) & 1) * 16;
+				return 0x00000000000283E0ull + ((offset) & 1) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_DMAX_INT_LEVEL (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F00000283E0ull) + ((offset) & 1) * 16;
+	return 0x00000000000283E0ull + ((offset) & 1) * 16;
 }
 #else
 static inline uint64_t CVMX_SLI_DMAX_INT_LEVEL(unsigned long offset)
@@ -352,12 +352,12 @@ static inline uint64_t CVMX_SLI_DMAX_INT_LEVEL(unsigned long offset)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000103E0ull) + (offset) * 16;
+			return 0x00000000000003E0ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000283E0ull) + (offset) * 16;
+			return 0x00000000000283E0ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000283E0ull) + (offset) * 16;
+	return 0x00000000000283E0ull + (offset) * 16;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -372,16 +372,16 @@ static inline uint64_t CVMX_SLI_DMAX_TIM(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011F0000010420ull) + ((offset) & 1) * 16;
+				return 0x0000000000000420ull + ((offset) & 1) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011F0000028420ull) + ((offset) & 1) * 16;
+				return 0x0000000000028420ull + ((offset) & 1) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_DMAX_TIM (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000028420ull) + ((offset) & 1) * 16;
+	return 0x0000000000028420ull + ((offset) & 1) * 16;
 }
 #else
 static inline uint64_t CVMX_SLI_DMAX_TIM(unsigned long offset)
@@ -394,12 +394,12 @@ static inline uint64_t CVMX_SLI_DMAX_TIM(unsigned long offset)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010420ull) + (offset) * 16;
+			return 0x0000000000000420ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028420ull) + (offset) * 16;
+			return 0x0000000000028420ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000028420ull) + (offset) * 16;
+	return 0x0000000000028420ull + (offset) * 16;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -492,10 +492,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_DMA_VF_INT(unsigned long offset, unsign
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_DMA_VF_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027280ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027280ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_DMA_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027280ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_DMA_VF_INT(offset, block_id) (0x0000000000027280ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_DMA_VF_INT_ENB(unsigned long offset, unsigned long block_id)
@@ -504,10 +504,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_DMA_VF_INT_ENB(unsigned long offset, un
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_DMA_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027500ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027500ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_DMA_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027500ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_DMA_VF_INT_ENB(offset, block_id) (0x0000000000027500ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_FLR_VF_INT(unsigned long offset, unsigned long block_id)
@@ -516,10 +516,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_FLR_VF_INT(unsigned long offset, unsign
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_FLR_VF_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027400ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027400ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_FLR_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027400ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_FLR_VF_INT(offset, block_id) (0x0000000000027400ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_INT_ENB(unsigned long offset, unsigned long block_id)
@@ -528,10 +528,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_INT_ENB(unsigned long offset, unsigned
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027080ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027080ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027080ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_INT_ENB(offset, block_id) (0x0000000000027080ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_INT_SUM(unsigned long offset, unsigned long block_id)
@@ -540,10 +540,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_INT_SUM(unsigned long offset, unsigned
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_INT_SUM(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027000ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027000ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_INT_SUM(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027000ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_INT_SUM(offset, block_id) (0x0000000000027000ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_MBOX_INT(unsigned long offset, unsigned long block_id)
@@ -552,10 +552,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_MBOX_INT(unsigned long offset, unsigned
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_MBOX_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027380ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027380ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_MBOX_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027380ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_MBOX_INT(offset, block_id) (0x0000000000027380ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_PKT_VF_INT(unsigned long offset, unsigned long block_id)
@@ -564,10 +564,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_PKT_VF_INT(unsigned long offset, unsign
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_PKT_VF_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027300ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027300ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_PKT_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027300ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_PKT_VF_INT(offset, block_id) (0x0000000000027300ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_PKT_VF_INT_ENB(unsigned long offset, unsigned long block_id)
@@ -576,10 +576,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_PKT_VF_INT_ENB(unsigned long offset, un
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_PKT_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027580ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027580ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_PKT_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027580ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_PKT_VF_INT_ENB(offset, block_id) (0x0000000000027580ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_PP_VF_INT(unsigned long offset, unsigned long block_id)
@@ -588,10 +588,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_PP_VF_INT(unsigned long offset, unsigne
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_PP_VF_INT(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027200ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027200ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_PP_VF_INT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027200ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_PP_VF_INT(offset, block_id) (0x0000000000027200ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MACX_PFX_PP_VF_INT_ENB(unsigned long offset, unsigned long block_id)
@@ -600,10 +600,10 @@ static inline uint64_t CVMX_SLI_MACX_PFX_PP_VF_INT_ENB(unsigned long offset, uns
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_MACX_PFX_PP_VF_INT_ENB(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000027480ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000027480ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_MACX_PFX_PP_VF_INT_ENB(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000027480ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_MACX_PFX_PP_VF_INT_ENB(offset, block_id) (0x0000000000027480ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_MAC_CREDIT_CNT CVMX_SLI_MAC_CREDIT_CNT_FUNC()
@@ -617,15 +617,15 @@ static inline uint64_t CVMX_SLI_MAC_CREDIT_CNT_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013D70ull);
+			return 0x0000000000003D70ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023D70ull);
+			return 0x0000000000023D70ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MAC_CREDIT_CNT not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023D70ull);
+	return 0x0000000000023D70ull;
 }
 #else
 #define CVMX_SLI_MAC_CREDIT_CNT CVMX_SLI_MAC_CREDIT_CNT_FUNC()
@@ -639,12 +639,12 @@ static inline uint64_t CVMX_SLI_MAC_CREDIT_CNT_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013D70ull);
+			return 0x0000000000003D70ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023D70ull);
+			return 0x0000000000023D70ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023D70ull);
+	return 0x0000000000023D70ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -657,15 +657,15 @@ static inline uint64_t CVMX_SLI_MAC_CREDIT_CNT2_FUNC(void)
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013E10ull);
+			return 0x0000000000013E10ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023E10ull);
+			return 0x0000000000023E10ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MAC_CREDIT_CNT2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023E10ull);
+	return 0x0000000000023E10ull;
 }
 #else
 #define CVMX_SLI_MAC_CREDIT_CNT2 CVMX_SLI_MAC_CREDIT_CNT2_FUNC()
@@ -677,12 +677,12 @@ static inline uint64_t CVMX_SLI_MAC_CREDIT_CNT2_FUNC(void)
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013E10ull);
+			return 0x0000000000013E10ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023E10ull);
+			return 0x0000000000023E10ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023E10ull);
+	return 0x0000000000023E10ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -739,15 +739,15 @@ static inline uint64_t CVMX_SLI_MEM_ACCESS_CTL_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000102F0ull);
+			return 0x00000000000002F0ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000282F0ull);
+			return 0x00000000000282F0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MEM_ACCESS_CTL not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F00000282F0ull);
+	return 0x00000000000282F0ull;
 }
 #else
 #define CVMX_SLI_MEM_ACCESS_CTL CVMX_SLI_MEM_ACCESS_CTL_FUNC()
@@ -761,12 +761,12 @@ static inline uint64_t CVMX_SLI_MEM_ACCESS_CTL_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000102F0ull);
+			return 0x00000000000002F0ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000282F0ull);
+			return 0x00000000000282F0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000282F0ull);
+	return 0x00000000000282F0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -781,16 +781,16 @@ static inline uint64_t CVMX_SLI_MEM_ACCESS_SUBIDX(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if (((offset >= 12) && (offset <= 27)))
-				return CVMX_ADD_IO_SEG(0x00011F00000100E0ull) + ((offset) & 31) * 16 - 16*12;
+				return 0x00000000000000E0ull + ((offset) & 31) * 16 - 16*12;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if (((offset >= 12) && (offset <= 27)))
-				return CVMX_ADD_IO_SEG(0x00011F00000280E0ull) + ((offset) & 31) * 16 - 16*12;
+				return 0x00000000000280E0ull + ((offset) & 31) * 16 - 16*12;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MEM_ACCESS_SUBIDX (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F00000280E0ull) + ((offset) & 31) * 16 - 16*12;
+	return 0x00000000000280E0ull + ((offset) & 31) * 16 - 16*12;
 }
 #else
 static inline uint64_t CVMX_SLI_MEM_ACCESS_SUBIDX(unsigned long offset)
@@ -803,12 +803,12 @@ static inline uint64_t CVMX_SLI_MEM_ACCESS_SUBIDX(unsigned long offset)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000100E0ull) + (offset) * 16 - 16*12;
+			return 0x00000000000000E0ull + (offset) * 16 - 16*12;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000280E0ull) + (offset) * 16 - 16*12;
+			return 0x00000000000280E0ull + (offset) * 16 - 16*12;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000280E0ull) + (offset) * 16 - 16*12;
+	return 0x00000000000280E0ull + (offset) * 16 - 16*12;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -818,14 +818,14 @@ static inline uint64_t CVMX_SLI_MEM_CTL_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000285E0ull);
+			return 0x00000000000285E0ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105E0ull);
+			return 0x00000000000105E0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MEM_CTL not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F00000285E0ull);
+	return 0x00000000000285E0ull;
 }
 #else
 #define CVMX_SLI_MEM_CTL CVMX_SLI_MEM_CTL_FUNC()
@@ -834,11 +834,11 @@ static inline uint64_t CVMX_SLI_MEM_CTL_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000285E0ull);
+			return 0x00000000000285E0ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105E0ull);
+			return 0x00000000000105E0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000285E0ull);
+	return 0x00000000000285E0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -848,14 +848,14 @@ static inline uint64_t CVMX_SLI_MEM_INT_SUM_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000285D0ull);
+			return 0x00000000000285D0ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105D0ull);
+			return 0x00000000000105D0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MEM_INT_SUM not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F00000285D0ull);
+	return 0x00000000000285D0ull;
 }
 #else
 #define CVMX_SLI_MEM_INT_SUM CVMX_SLI_MEM_INT_SUM_FUNC()
@@ -864,11 +864,11 @@ static inline uint64_t CVMX_SLI_MEM_INT_SUM_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000285D0ull);
+			return 0x00000000000285D0ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000105D0ull);
+			return 0x00000000000105D0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000285D0ull);
+	return 0x00000000000285D0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -878,15 +878,15 @@ static inline uint64_t CVMX_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 64))
-				return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + ((offset) & 127) * 16;
+				return 0x0000000000000000ull + ((offset) & 127) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 64))
-				return CVMX_ADD_IO_SEG(0x00011F0000016000ull) + ((offset) & 127) * 16;
+				return 0x0000000000016000ull + ((offset) & 127) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSIXX_TABLE_ADDR (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + ((offset) & 127) * 16;
+	return 0x0000000000000000ull + ((offset) & 127) * 16;
 }
 #else
 static inline uint64_t CVMX_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
@@ -894,11 +894,11 @@ static inline uint64_t CVMX_SLI_MSIXX_TABLE_ADDR(unsigned long offset)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + (offset) * 16;
+			return 0x0000000000000000ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000016000ull) + (offset) * 16;
+			return 0x0000000000016000ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000000000ull) + (offset) * 16;
+	return 0x0000000000000000ull + (offset) * 16;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -908,15 +908,15 @@ static inline uint64_t CVMX_SLI_MSIXX_TABLE_DATA(unsigned long offset)
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 64))
-				return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + ((offset) & 127) * 16;
+				return 0x0000000000000008ull + ((offset) & 127) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 64))
-				return CVMX_ADD_IO_SEG(0x00011F0000016008ull) + ((offset) & 127) * 16;
+				return 0x0000000000016008ull + ((offset) & 127) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSIXX_TABLE_DATA (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + ((offset) & 127) * 16;
+	return 0x0000000000000008ull + ((offset) & 127) * 16;
 }
 #else
 static inline uint64_t CVMX_SLI_MSIXX_TABLE_DATA(unsigned long offset)
@@ -924,11 +924,11 @@ static inline uint64_t CVMX_SLI_MSIXX_TABLE_DATA(unsigned long offset)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + (offset) * 16;
+			return 0x0000000000000008ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000016008ull) + (offset) * 16;
+			return 0x0000000000016008ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000000008ull) + (offset) * 16;
+	return 0x0000000000000008ull + (offset) * 16;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -937,10 +937,10 @@ static inline uint64_t CVMX_SLI_MSIX_MACX_PF_TABLE_ADDR(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3)))))
 		cvmx_warn("CVMX_SLI_MSIX_MACX_PF_TABLE_ADDR(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000017C00ull) + ((offset) & 3) * 16;
+	return 0x0000000000017C00ull + ((offset) & 3) * 16;
 }
 #else
-#define CVMX_SLI_MSIX_MACX_PF_TABLE_ADDR(offset) (CVMX_ADD_IO_SEG(0x00011F0000017C00ull) + ((offset) & 3) * 16)
+#define CVMX_SLI_MSIX_MACX_PF_TABLE_ADDR(offset) (0x0000000000017C00ull + ((offset) & 3) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_MSIX_MACX_PF_TABLE_DATA(unsigned long offset)
@@ -948,10 +948,10 @@ static inline uint64_t CVMX_SLI_MSIX_MACX_PF_TABLE_DATA(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3)))))
 		cvmx_warn("CVMX_SLI_MSIX_MACX_PF_TABLE_DATA(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000017C08ull) + ((offset) & 3) * 16;
+	return 0x0000000000017C08ull + ((offset) & 3) * 16;
 }
 #else
-#define CVMX_SLI_MSIX_MACX_PF_TABLE_DATA(offset) (CVMX_ADD_IO_SEG(0x00011F0000017C08ull) + ((offset) & 3) * 16)
+#define CVMX_SLI_MSIX_MACX_PF_TABLE_DATA(offset) (0x0000000000017C08ull + ((offset) & 3) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_MSIX_PBA0 CVMX_SLI_MSIX_PBA0_FUNC()
@@ -960,14 +960,14 @@ static inline uint64_t CVMX_SLI_MSIX_PBA0_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000001000ull);
+			return 0x0000000000001000ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000017000ull);
+			return 0x0000000000017000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSIX_PBA0 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000001000ull);
+	return 0x0000000000001000ull;
 }
 #else
 #define CVMX_SLI_MSIX_PBA0 CVMX_SLI_MSIX_PBA0_FUNC()
@@ -976,11 +976,11 @@ static inline uint64_t CVMX_SLI_MSIX_PBA0_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000001000ull);
+			return 0x0000000000001000ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000017000ull);
+			return 0x0000000000017000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000001000ull);
+	return 0x0000000000001000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -990,14 +990,14 @@ static inline uint64_t CVMX_SLI_MSIX_PBA1_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000001008ull);
+			return 0x0000000000001008ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000017010ull);
+			return 0x0000000000017010ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSIX_PBA1 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000001008ull);
+	return 0x0000000000001008ull;
 }
 #else
 #define CVMX_SLI_MSIX_PBA1 CVMX_SLI_MSIX_PBA1_FUNC()
@@ -1006,11 +1006,11 @@ static inline uint64_t CVMX_SLI_MSIX_PBA1_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000001008ull);
+			return 0x0000000000001008ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000017010ull);
+			return 0x0000000000017010ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000001008ull);
+	return 0x0000000000001008ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1069,15 +1069,15 @@ static inline uint64_t CVMX_SLI_MSI_RCV0_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C10ull);
+			return 0x0000000000003C10ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C10ull);
+			return 0x0000000000023C10ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSI_RCV0 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023C10ull);
+	return 0x0000000000023C10ull;
 }
 #else
 #define CVMX_SLI_MSI_RCV0 CVMX_SLI_MSI_RCV0_FUNC()
@@ -1091,12 +1091,12 @@ static inline uint64_t CVMX_SLI_MSI_RCV0_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C10ull);
+			return 0x0000000000003C10ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C10ull);
+			return 0x0000000000023C10ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023C10ull);
+	return 0x0000000000023C10ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1111,15 +1111,15 @@ static inline uint64_t CVMX_SLI_MSI_RCV1_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C20ull);
+			return 0x0000000000003C20ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C20ull);
+			return 0x0000000000023C20ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSI_RCV1 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023C20ull);
+	return 0x0000000000023C20ull;
 }
 #else
 #define CVMX_SLI_MSI_RCV1 CVMX_SLI_MSI_RCV1_FUNC()
@@ -1133,12 +1133,12 @@ static inline uint64_t CVMX_SLI_MSI_RCV1_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C20ull);
+			return 0x0000000000003C20ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C20ull);
+			return 0x0000000000023C20ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023C20ull);
+	return 0x0000000000023C20ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1153,15 +1153,15 @@ static inline uint64_t CVMX_SLI_MSI_RCV2_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C30ull);
+			return 0x0000000000003C30ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C30ull);
+			return 0x0000000000023C30ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSI_RCV2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023C30ull);
+	return 0x0000000000023C30ull;
 }
 #else
 #define CVMX_SLI_MSI_RCV2 CVMX_SLI_MSI_RCV2_FUNC()
@@ -1175,12 +1175,12 @@ static inline uint64_t CVMX_SLI_MSI_RCV2_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C30ull);
+			return 0x0000000000003C30ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C30ull);
+			return 0x0000000000023C30ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023C30ull);
+	return 0x0000000000023C30ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1195,15 +1195,15 @@ static inline uint64_t CVMX_SLI_MSI_RCV3_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C40ull);
+			return 0x0000000000003C40ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C40ull);
+			return 0x0000000000023C40ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSI_RCV3 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023C40ull);
+	return 0x0000000000023C40ull;
 }
 #else
 #define CVMX_SLI_MSI_RCV3 CVMX_SLI_MSI_RCV3_FUNC()
@@ -1217,12 +1217,12 @@ static inline uint64_t CVMX_SLI_MSI_RCV3_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C40ull);
+			return 0x0000000000003C40ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C40ull);
+			return 0x0000000000023C40ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023C40ull);
+	return 0x0000000000023C40ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1237,15 +1237,15 @@ static inline uint64_t CVMX_SLI_MSI_RD_MAP_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013CA0ull);
+			return 0x0000000000003CA0ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023CA0ull);
+			return 0x0000000000023CA0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSI_RD_MAP not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023CA0ull);
+	return 0x0000000000023CA0ull;
 }
 #else
 #define CVMX_SLI_MSI_RD_MAP CVMX_SLI_MSI_RD_MAP_FUNC()
@@ -1259,12 +1259,12 @@ static inline uint64_t CVMX_SLI_MSI_RD_MAP_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013CA0ull);
+			return 0x0000000000003CA0ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023CA0ull);
+			return 0x0000000000023CA0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023CA0ull);
+	return 0x0000000000023CA0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1367,15 +1367,15 @@ static inline uint64_t CVMX_SLI_MSI_WR_MAP_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C90ull);
+			return 0x0000000000003C90ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C90ull);
+			return 0x0000000000023C90ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_MSI_WR_MAP not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023C90ull);
+	return 0x0000000000023C90ull;
 }
 #else
 #define CVMX_SLI_MSI_WR_MAP CVMX_SLI_MSI_WR_MAP_FUNC()
@@ -1389,12 +1389,12 @@ static inline uint64_t CVMX_SLI_MSI_WR_MAP_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013C90ull);
+			return 0x0000000000003C90ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023C90ull);
+			return 0x0000000000023C90ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023C90ull);
+	return 0x0000000000023C90ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1420,15 +1420,15 @@ static inline uint64_t CVMX_SLI_PCIE_MSI_RCV_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013CB0ull);
+			return 0x0000000000003CB0ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023CB0ull);
+			return 0x0000000000023CB0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PCIE_MSI_RCV not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000023CB0ull);
+	return 0x0000000000023CB0ull;
 }
 #else
 #define CVMX_SLI_PCIE_MSI_RCV CVMX_SLI_PCIE_MSI_RCV_FUNC()
@@ -1442,12 +1442,12 @@ static inline uint64_t CVMX_SLI_PCIE_MSI_RCV_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013CB0ull);
+			return 0x0000000000003CB0ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023CB0ull);
+			return 0x0000000000023CB0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023CB0ull);
+	return 0x0000000000023CB0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1462,15 +1462,15 @@ static inline uint64_t CVMX_SLI_PCIE_MSI_RCV_B1_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010650ull);
+			return 0x0000000000000650ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028650ull);
+			return 0x0000000000028650ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PCIE_MSI_RCV_B1 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000028650ull);
+	return 0x0000000000028650ull;
 }
 #else
 #define CVMX_SLI_PCIE_MSI_RCV_B1 CVMX_SLI_PCIE_MSI_RCV_B1_FUNC()
@@ -1484,12 +1484,12 @@ static inline uint64_t CVMX_SLI_PCIE_MSI_RCV_B1_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010650ull);
+			return 0x0000000000000650ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028650ull);
+			return 0x0000000000028650ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000028650ull);
+	return 0x0000000000028650ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1504,15 +1504,15 @@ static inline uint64_t CVMX_SLI_PCIE_MSI_RCV_B2_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010660ull);
+			return 0x0000000000000660ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028660ull);
+			return 0x0000000000028660ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PCIE_MSI_RCV_B2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000028660ull);
+	return 0x0000000000028660ull;
 }
 #else
 #define CVMX_SLI_PCIE_MSI_RCV_B2 CVMX_SLI_PCIE_MSI_RCV_B2_FUNC()
@@ -1526,12 +1526,12 @@ static inline uint64_t CVMX_SLI_PCIE_MSI_RCV_B2_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010660ull);
+			return 0x0000000000000660ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028660ull);
+			return 0x0000000000028660ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000028660ull);
+	return 0x0000000000028660ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1546,15 +1546,15 @@ static inline uint64_t CVMX_SLI_PCIE_MSI_RCV_B3_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010670ull);
+			return 0x0000000000000670ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028670ull);
+			return 0x0000000000028670ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PCIE_MSI_RCV_B3 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000028670ull);
+	return 0x0000000000028670ull;
 }
 #else
 #define CVMX_SLI_PCIE_MSI_RCV_B3 CVMX_SLI_PCIE_MSI_RCV_B3_FUNC()
@@ -1568,12 +1568,12 @@ static inline uint64_t CVMX_SLI_PCIE_MSI_RCV_B3_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010670ull);
+			return 0x0000000000000670ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028670ull);
+			return 0x0000000000028670ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000028670ull);
+	return 0x0000000000028670ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1587,20 +1587,20 @@ static inline uint64_t CVMX_SLI_PKTX_CNTS(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000012400ull) + ((offset) & 31) * 16;
+				return 0x0000000000002400ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000012400ull) + ((offset) & 63) * 16;
+				return 0x0000000000012400ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F00000100B0ull) + ((offset) & 127) * 0x20000ull;
+				return 0x00000000000100B0ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_CNTS (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F00000100B0ull) + ((offset) & 127) * 0x20000ull;
+	return 0x00000000000100B0ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_CNTS(unsigned long offset)
@@ -1612,14 +1612,14 @@ static inline uint64_t CVMX_SLI_PKTX_CNTS(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000012400ull) + (offset) * 16;
+			return 0x0000000000002400ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000012400ull) + (offset) * 16;
+			return 0x0000000000012400ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000100B0ull) + (offset) * 0x20000ull;
+			return 0x00000000000100B0ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000100B0ull) + (offset) * 0x20000ull;
+	return 0x00000000000100B0ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1629,10 +1629,10 @@ static inline uint64_t CVMX_SLI_PKTX_ERROR_INFO(unsigned long offset)
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
 		cvmx_warn("CVMX_SLI_PKTX_ERROR_INFO(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F00000100C0ull) + ((offset) & 127) * 0x20000ull;
+	return 0x00000000000100C0ull + ((offset) & 127) * 0x20000ull;
 }
 #else
-#define CVMX_SLI_PKTX_ERROR_INFO(offset) (CVMX_ADD_IO_SEG(0x00011F00000100C0ull) + ((offset) & 127) * 0x20000ull)
+#define CVMX_SLI_PKTX_ERROR_INFO(offset) (0x00000000000100C0ull + ((offset) & 127) * 0x20000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
@@ -1641,15 +1641,15 @@ static inline uint64_t CVMX_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010000ull + ((offset) & 127) * 0x20000ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000014000ull) + ((offset) & 63) * 16;
+				return 0x0000000000014000ull + ((offset) & 63) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_INPUT_CONTROL (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010000ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
@@ -1657,11 +1657,11 @@ static inline uint64_t CVMX_SLI_PKTX_INPUT_CONTROL(unsigned long offset)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + (offset) * 0x20000ull;
+			return 0x0000000000010000ull + (offset) * 0x20000ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000014000ull) + (offset) * 16;
+			return 0x0000000000014000ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010000ull) + (offset) * 0x20000ull;
+	return 0x0000000000010000ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1675,20 +1675,20 @@ static inline uint64_t CVMX_SLI_PKTX_INSTR_BADDR(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000012800ull) + ((offset) & 31) * 16;
+				return 0x0000000000002800ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000012800ull) + ((offset) & 63) * 16;
+				return 0x0000000000012800ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010010ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010010ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_INSTR_BADDR (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010010ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010010ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_INSTR_BADDR(unsigned long offset)
@@ -1700,14 +1700,14 @@ static inline uint64_t CVMX_SLI_PKTX_INSTR_BADDR(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000012800ull) + (offset) * 16;
+			return 0x0000000000002800ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000012800ull) + (offset) * 16;
+			return 0x0000000000012800ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010010ull) + (offset) * 0x20000ull;
+			return 0x0000000000010010ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010010ull) + (offset) * 0x20000ull;
+	return 0x0000000000010010ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1721,20 +1721,20 @@ static inline uint64_t CVMX_SLI_PKTX_INSTR_BAOFF_DBELL(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000012C00ull) + ((offset) & 31) * 16;
+				return 0x0000000000002C00ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000012C00ull) + ((offset) & 63) * 16;
+				return 0x0000000000012C00ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010020ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010020ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_INSTR_BAOFF_DBELL (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010020ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010020ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_INSTR_BAOFF_DBELL(unsigned long offset)
@@ -1746,14 +1746,14 @@ static inline uint64_t CVMX_SLI_PKTX_INSTR_BAOFF_DBELL(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000012C00ull) + (offset) * 16;
+			return 0x0000000000002C00ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000012C00ull) + (offset) * 16;
+			return 0x0000000000012C00ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010020ull) + (offset) * 0x20000ull;
+			return 0x0000000000010020ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010020ull) + (offset) * 0x20000ull;
+	return 0x0000000000010020ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1767,20 +1767,20 @@ static inline uint64_t CVMX_SLI_PKTX_INSTR_FIFO_RSIZE(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000013000ull) + ((offset) & 31) * 16;
+				return 0x0000000000003000ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000013000ull) + ((offset) & 63) * 16;
+				return 0x0000000000013000ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010030ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010030ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_INSTR_FIFO_RSIZE (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010030ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010030ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_INSTR_FIFO_RSIZE(unsigned long offset)
@@ -1792,14 +1792,14 @@ static inline uint64_t CVMX_SLI_PKTX_INSTR_FIFO_RSIZE(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013000ull) + (offset) * 16;
+			return 0x0000000000003000ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013000ull) + (offset) * 16;
+			return 0x0000000000013000ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010030ull) + (offset) * 0x20000ull;
+			return 0x0000000000010030ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010030ull) + (offset) * 0x20000ull;
+	return 0x0000000000010030ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1825,15 +1825,15 @@ static inline uint64_t CVMX_SLI_PKTX_INT_LEVELS(unsigned long offset)
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + ((offset) & 127) * 0x20000ull;
+				return 0x00000000000100A0ull + ((offset) & 127) * 0x20000ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000014400ull) + ((offset) & 63) * 16;
+				return 0x0000000000014400ull + ((offset) & 63) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_INT_LEVELS (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + ((offset) & 127) * 0x20000ull;
+	return 0x00000000000100A0ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_INT_LEVELS(unsigned long offset)
@@ -1841,11 +1841,11 @@ static inline uint64_t CVMX_SLI_PKTX_INT_LEVELS(unsigned long offset)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + (offset) * 0x20000ull;
+			return 0x00000000000100A0ull + (offset) * 0x20000ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000014400ull) + (offset) * 16;
+			return 0x0000000000014400ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000100A0ull) + (offset) * 0x20000ull;
+	return 0x00000000000100A0ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1870,10 +1870,10 @@ static inline uint64_t CVMX_SLI_PKTX_MBOX_INT(unsigned long offset)
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
 		cvmx_warn("CVMX_SLI_PKTX_MBOX_INT(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010210ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010210ull + ((offset) & 127) * 0x20000ull;
 }
 #else
-#define CVMX_SLI_PKTX_MBOX_INT(offset) (CVMX_ADD_IO_SEG(0x00011F0000010210ull) + ((offset) & 127) * 0x20000ull)
+#define CVMX_SLI_PKTX_MBOX_INT(offset) (0x0000000000010210ull + ((offset) & 127) * 0x20000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
@@ -1882,15 +1882,15 @@ static inline uint64_t CVMX_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010050ull + ((offset) & 127) * 0x20000ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000014800ull) + ((offset) & 63) * 16;
+				return 0x0000000000014800ull + ((offset) & 63) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_OUTPUT_CONTROL (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010050ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
@@ -1898,11 +1898,11 @@ static inline uint64_t CVMX_SLI_PKTX_OUTPUT_CONTROL(unsigned long offset)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 0x20000ull;
+			return 0x0000000000010050ull + (offset) * 0x20000ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000014800ull) + (offset) * 16;
+			return 0x0000000000014800ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010050ull) + (offset) * 0x20000ull;
+	return 0x0000000000010050ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1916,20 +1916,20 @@ static inline uint64_t CVMX_SLI_PKTX_OUT_SIZE(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000010C00ull) + ((offset) & 31) * 16;
+				return 0x0000000000000C00ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000010C00ull) + ((offset) & 63) * 16;
+				return 0x0000000000010C00ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010060ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010060ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_OUT_SIZE (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010060ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010060ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_OUT_SIZE(unsigned long offset)
@@ -1941,14 +1941,14 @@ static inline uint64_t CVMX_SLI_PKTX_OUT_SIZE(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010C00ull) + (offset) * 16;
+			return 0x0000000000000C00ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010C00ull) + (offset) * 16;
+			return 0x0000000000010C00ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010060ull) + (offset) * 0x20000ull;
+			return 0x0000000000010060ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010060ull) + (offset) * 0x20000ull;
+	return 0x0000000000010060ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -1958,10 +1958,10 @@ static inline uint64_t CVMX_SLI_PKTX_PF_VF_MBOX_SIGX(unsigned long offset, unsig
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 63)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 63))))))
 		cvmx_warn("CVMX_SLI_PKTX_PF_VF_MBOX_SIGX(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000010200ull) + (((offset) & 1) + ((block_id) & 63) * 0x4000ull) * 8;
+	return 0x0000000000010200ull + (((offset) & 1) + ((block_id) & 63) * 0x4000ull) * 8;
 }
 #else
-#define CVMX_SLI_PKTX_PF_VF_MBOX_SIGX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000010200ull) + (((offset) & 1) + ((block_id) & 63) * 0x4000ull) * 8)
+#define CVMX_SLI_PKTX_PF_VF_MBOX_SIGX(offset, block_id) (0x0000000000010200ull + (((offset) & 1) + ((block_id) & 63) * 0x4000ull) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_PKTX_SLIST_BADDR(unsigned long offset)
@@ -1974,20 +1974,20 @@ static inline uint64_t CVMX_SLI_PKTX_SLIST_BADDR(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000011400ull) + ((offset) & 31) * 16;
+				return 0x0000000000001400ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000011400ull) + ((offset) & 63) * 16;
+				return 0x0000000000011400ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010070ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010070ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_SLIST_BADDR (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010070ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010070ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_SLIST_BADDR(unsigned long offset)
@@ -1999,14 +1999,14 @@ static inline uint64_t CVMX_SLI_PKTX_SLIST_BADDR(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011400ull) + (offset) * 16;
+			return 0x0000000000001400ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011400ull) + (offset) * 16;
+			return 0x0000000000011400ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010070ull) + (offset) * 0x20000ull;
+			return 0x0000000000010070ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010070ull) + (offset) * 0x20000ull;
+	return 0x0000000000010070ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2020,20 +2020,20 @@ static inline uint64_t CVMX_SLI_PKTX_SLIST_BAOFF_DBELL(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000011800ull) + ((offset) & 31) * 16;
+				return 0x0000000000001800ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000011800ull) + ((offset) & 63) * 16;
+				return 0x0000000000011800ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010080ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010080ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_SLIST_BAOFF_DBELL (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010080ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010080ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_SLIST_BAOFF_DBELL(unsigned long offset)
@@ -2045,14 +2045,14 @@ static inline uint64_t CVMX_SLI_PKTX_SLIST_BAOFF_DBELL(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011800ull) + (offset) * 16;
+			return 0x0000000000001800ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011800ull) + (offset) * 16;
+			return 0x0000000000011800ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010080ull) + (offset) * 0x20000ull;
+			return 0x0000000000010080ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010080ull) + (offset) * 0x20000ull;
+	return 0x0000000000010080ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2066,20 +2066,20 @@ static inline uint64_t CVMX_SLI_PKTX_SLIST_FIFO_RSIZE(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000011C00ull) + ((offset) & 31) * 16;
+				return 0x0000000000001C00ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000011C00ull) + ((offset) & 63) * 16;
+				return 0x0000000000011C00ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010090ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010090ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKTX_SLIST_FIFO_RSIZE (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010090ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010090ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKTX_SLIST_FIFO_RSIZE(unsigned long offset)
@@ -2091,14 +2091,14 @@ static inline uint64_t CVMX_SLI_PKTX_SLIST_FIFO_RSIZE(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011C00ull) + (offset) * 16;
+			return 0x0000000000001C00ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011C00ull) + (offset) * 16;
+			return 0x0000000000011C00ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010090ull) + (offset) * 0x20000ull;
+			return 0x0000000000010090ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010090ull) + (offset) * 0x20000ull;
+	return 0x0000000000010090ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2108,10 +2108,10 @@ static inline uint64_t CVMX_SLI_PKTX_VF_INT_SUM(unsigned long offset)
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 127))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 127)))))
 		cvmx_warn("CVMX_SLI_PKTX_VF_INT_SUM(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F00000100D0ull) + ((offset) & 127) * 0x20000ull;
+	return 0x00000000000100D0ull + ((offset) & 127) * 0x20000ull;
 }
 #else
-#define CVMX_SLI_PKTX_VF_INT_SUM(offset) (CVMX_ADD_IO_SEG(0x00011F00000100D0ull) + ((offset) & 127) * 0x20000ull)
+#define CVMX_SLI_PKTX_VF_INT_SUM(offset) (0x00000000000100D0ull + ((offset) & 127) * 0x20000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_PKTX_VF_SIG(unsigned long offset)
@@ -2119,10 +2119,10 @@ static inline uint64_t CVMX_SLI_PKTX_VF_SIG(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 63)))))
 		cvmx_warn("CVMX_SLI_PKTX_VF_SIG(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000014C00ull) + ((offset) & 63) * 16;
+	return 0x0000000000014C00ull + ((offset) & 63) * 16;
 }
 #else
-#define CVMX_SLI_PKTX_VF_SIG(offset) (CVMX_ADD_IO_SEG(0x00011F0000014C00ull) + ((offset) & 63) * 16)
+#define CVMX_SLI_PKTX_VF_SIG(offset) (0x0000000000014C00ull + ((offset) & 63) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_PKT_BIST_STATUS CVMX_SLI_PKT_BIST_STATUS_FUNC()
@@ -2147,15 +2147,15 @@ static inline uint64_t CVMX_SLI_PKT_CNT_INT_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011130ull);
+			return 0x0000000000001130ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029130ull);
+			return 0x0000000000029130ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_CNT_INT not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029130ull);
+	return 0x0000000000029130ull;
 }
 #else
 #define CVMX_SLI_PKT_CNT_INT CVMX_SLI_PKT_CNT_INT_FUNC()
@@ -2169,12 +2169,12 @@ static inline uint64_t CVMX_SLI_PKT_CNT_INT_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011130ull);
+			return 0x0000000000001130ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029130ull);
+			return 0x0000000000029130ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000029130ull);
+	return 0x0000000000029130ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2305,14 +2305,14 @@ static inline uint64_t CVMX_SLI_PKT_INT_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029160ull);
+			return 0x0000000000029160ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011160ull);
+			return 0x0000000000011160ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_INT not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029160ull);
+	return 0x0000000000029160ull;
 }
 #else
 #define CVMX_SLI_PKT_INT CVMX_SLI_PKT_INT_FUNC()
@@ -2321,11 +2321,11 @@ static inline uint64_t CVMX_SLI_PKT_INT_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029160ull);
+			return 0x0000000000029160ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011160ull);
+			return 0x0000000000011160ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000029160ull);
+	return 0x0000000000029160ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2361,20 +2361,20 @@ static inline uint64_t CVMX_SLI_PKT_IN_DONEX_CNTS(unsigned long offset)
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
-				return CVMX_ADD_IO_SEG(0x00011F0000012000ull) + ((offset) & 31) * 16;
+				return 0x0000000000002000ull + ((offset) & 31) * 16;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 63))
-				return CVMX_ADD_IO_SEG(0x00011F0000012000ull) + ((offset) & 63) * 16;
+				return 0x0000000000012000ull + ((offset) & 63) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 127))
-				return CVMX_ADD_IO_SEG(0x00011F0000010040ull) + ((offset) & 127) * 0x20000ull;
+				return 0x0000000000010040ull + ((offset) & 127) * 0x20000ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_IN_DONEX_CNTS (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000010040ull) + ((offset) & 127) * 0x20000ull;
+	return 0x0000000000010040ull + ((offset) & 127) * 0x20000ull;
 }
 #else
 static inline uint64_t CVMX_SLI_PKT_IN_DONEX_CNTS(unsigned long offset)
@@ -2386,14 +2386,14 @@ static inline uint64_t CVMX_SLI_PKT_IN_DONEX_CNTS(unsigned long offset)
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000012000ull) + (offset) * 16;
+			return 0x0000000000002000ull + (offset) * 16;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000012000ull) + (offset) * 16;
+			return 0x0000000000012000ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010040ull) + (offset) * 0x20000ull;
+			return 0x0000000000010040ull + (offset) * 0x20000ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000010040ull) + (offset) * 0x20000ull;
+	return 0x0000000000010040ull + (offset) * 0x20000ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2408,15 +2408,15 @@ static inline uint64_t CVMX_SLI_PKT_IN_INSTR_COUNTS_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011200ull);
+			return 0x0000000000001200ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029200ull);
+			return 0x0000000000029200ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_IN_INSTR_COUNTS not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029200ull);
+	return 0x0000000000029200ull;
 }
 #else
 #define CVMX_SLI_PKT_IN_INSTR_COUNTS CVMX_SLI_PKT_IN_INSTR_COUNTS_FUNC()
@@ -2430,12 +2430,12 @@ static inline uint64_t CVMX_SLI_PKT_IN_INSTR_COUNTS_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011200ull);
+			return 0x0000000000001200ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029200ull);
+			return 0x0000000000029200ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000029200ull);
+	return 0x0000000000029200ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2445,14 +2445,14 @@ static inline uint64_t CVMX_SLI_PKT_IN_INT_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029150ull);
+			return 0x0000000000029150ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011150ull);
+			return 0x0000000000011150ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_IN_INT not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029150ull);
+	return 0x0000000000029150ull;
 }
 #else
 #define CVMX_SLI_PKT_IN_INT CVMX_SLI_PKT_IN_INT_FUNC()
@@ -2461,11 +2461,11 @@ static inline uint64_t CVMX_SLI_PKT_IN_INT_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029150ull);
+			return 0x0000000000029150ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011150ull);
+			return 0x0000000000011150ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000029150ull);
+	return 0x0000000000029150ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2552,10 +2552,10 @@ static inline uint64_t CVMX_SLI_PKT_MACX_PFX_RINFO(unsigned long offset, unsigne
 	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 1)) && ((block_id <= 3)))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && (((offset <= 1)) && ((block_id <= 3))))))
 		cvmx_warn("CVMX_SLI_PKT_MACX_PFX_RINFO(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x00011F0000029030ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
+	return 0x0000000000029030ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16;
 }
 #else
-#define CVMX_SLI_PKT_MACX_PFX_RINFO(offset, block_id) (CVMX_ADD_IO_SEG(0x00011F0000029030ull) + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
+#define CVMX_SLI_PKT_MACX_PFX_RINFO(offset, block_id) (0x0000000000029030ull + (((offset) & 1) + ((block_id) & 3) * 0x2ull) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SLI_PKT_MACX_RINFO(unsigned long offset)
@@ -2563,10 +2563,10 @@ static inline uint64_t CVMX_SLI_PKT_MACX_RINFO(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 3)))))
 		cvmx_warn("CVMX_SLI_PKT_MACX_RINFO(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000011030ull) + ((offset) & 3) * 16;
+	return 0x0000000000011030ull + ((offset) & 3) * 16;
 }
 #else
-#define CVMX_SLI_PKT_MACX_RINFO(offset) (CVMX_ADD_IO_SEG(0x00011F0000011030ull) + ((offset) & 3) * 16)
+#define CVMX_SLI_PKT_MACX_RINFO(offset) (0x0000000000011030ull + ((offset) & 3) * 16)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_SLI_PKT_MEM_CTL CVMX_SLI_PKT_MEM_CTL_FUNC()
@@ -2575,14 +2575,14 @@ static inline uint64_t CVMX_SLI_PKT_MEM_CTL_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029120ull);
+			return 0x0000000000029120ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011120ull);
+			return 0x0000000000011120ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_MEM_CTL not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029120ull);
+	return 0x0000000000029120ull;
 }
 #else
 #define CVMX_SLI_PKT_MEM_CTL CVMX_SLI_PKT_MEM_CTL_FUNC()
@@ -2591,11 +2591,11 @@ static inline uint64_t CVMX_SLI_PKT_MEM_CTL_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029120ull);
+			return 0x0000000000029120ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011120ull);
+			return 0x0000000000011120ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000029120ull);
+	return 0x0000000000029120ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2610,15 +2610,15 @@ static inline uint64_t CVMX_SLI_PKT_OUTPUT_WMARK_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011180ull);
+			return 0x0000000000001180ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029180ull);
+			return 0x0000000000029180ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_OUTPUT_WMARK not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029180ull);
+	return 0x0000000000029180ull;
 }
 #else
 #define CVMX_SLI_PKT_OUTPUT_WMARK CVMX_SLI_PKT_OUTPUT_WMARK_FUNC()
@@ -2632,12 +2632,12 @@ static inline uint64_t CVMX_SLI_PKT_OUTPUT_WMARK_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011180ull);
+			return 0x0000000000001180ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029180ull);
+			return 0x0000000000029180ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000029180ull);
+	return 0x0000000000029180ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2757,14 +2757,14 @@ static inline uint64_t CVMX_SLI_PKT_RING_RST_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000291E0ull);
+			return 0x00000000000291E0ull;
 			break;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000111E0ull);
+			return 0x00000000000111E0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_RING_RST not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F00000291E0ull);
+	return 0x00000000000291E0ull;
 }
 #else
 #define CVMX_SLI_PKT_RING_RST CVMX_SLI_PKT_RING_RST_FUNC()
@@ -2773,11 +2773,11 @@ static inline uint64_t CVMX_SLI_PKT_RING_RST_FUNC(void)
 	switch(cvmx_get_octeon_family()) {
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000291E0ull);
+			return 0x00000000000291E0ull;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000111E0ull);
+			return 0x00000000000111E0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000291E0ull);
+	return 0x00000000000291E0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2825,15 +2825,15 @@ static inline uint64_t CVMX_SLI_PKT_TIME_INT_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011140ull);
+			return 0x0000000000001140ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029140ull);
+			return 0x0000000000029140ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_PKT_TIME_INT not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000029140ull);
+	return 0x0000000000029140ull;
 }
 #else
 #define CVMX_SLI_PKT_TIME_INT CVMX_SLI_PKT_TIME_INT_FUNC()
@@ -2847,12 +2847,12 @@ static inline uint64_t CVMX_SLI_PKT_TIME_INT_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000011140ull);
+			return 0x0000000000001140ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000029140ull);
+			return 0x0000000000029140ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000029140ull);
+	return 0x0000000000029140ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2927,25 +2927,25 @@ static inline uint64_t CVMX_SLI_S2M_PORTX_CTL(unsigned long offset)
 		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 1))
-				return CVMX_ADD_IO_SEG(0x00011F0000013D80ull) + ((offset) & 1) * 16;
+				return 0x0000000000003D80ull + ((offset) & 1) * 16;
 			break;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 2))
-				return CVMX_ADD_IO_SEG(0x00011F0000013D80ull) + ((offset) & 3) * 16;
+				return 0x0000000000013D80ull + ((offset) & 3) * 16;
 			break;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
-				return CVMX_ADD_IO_SEG(0x00011F0000013D80ull) + ((offset) & 3) * 16;
+				return 0x0000000000003D80ull + ((offset) & 3) * 16;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 3))
-				return CVMX_ADD_IO_SEG(0x00011F0000023D80ull) + ((offset) & 3) * 16;
+				return 0x0000000000023D80ull + ((offset) & 3) * 16;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_S2M_PORTX_CTL (offset = %lu) not supported on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00011F0000023D80ull) + ((offset) & 3) * 16;
+	return 0x0000000000023D80ull + ((offset) & 3) * 16;
 }
 #else
 static inline uint64_t CVMX_SLI_S2M_PORTX_CTL(unsigned long offset)
@@ -2955,17 +2955,17 @@ static inline uint64_t CVMX_SLI_S2M_PORTX_CTL(unsigned long offset)
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013D80ull) + (offset) * 16;
+			return 0x0000000000003D80ull + (offset) * 16;
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013D80ull) + (offset) * 16;
+			return 0x0000000000013D80ull + (offset) * 16;
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000013D80ull) + (offset) * 16;
+			return 0x0000000000003D80ull + (offset) * 16;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000023D80ull) + (offset) * 16;
+			return 0x0000000000023D80ull + (offset) * 16;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000023D80ull) + (offset) * 16;
+	return 0x0000000000023D80ull + (offset) * 16;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -2980,15 +2980,15 @@ static inline uint64_t CVMX_SLI_SCRATCH_1_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000103C0ull);
+			return 0x00000000000003C0ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000283C0ull);
+			return 0x00000000000283C0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_SCRATCH_1 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F00000283C0ull);
+	return 0x00000000000283C0ull;
 }
 #else
 #define CVMX_SLI_SCRATCH_1 CVMX_SLI_SCRATCH_1_FUNC()
@@ -3002,12 +3002,12 @@ static inline uint64_t CVMX_SLI_SCRATCH_1_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000103C0ull);
+			return 0x00000000000003C0ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000283C0ull);
+			return 0x00000000000283C0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000283C0ull);
+	return 0x00000000000283C0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -3022,15 +3022,15 @@ static inline uint64_t CVMX_SLI_SCRATCH_2_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000103D0ull);
+			return 0x00000000000003D0ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000283D0ull);
+			return 0x00000000000283D0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_SCRATCH_2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F00000283D0ull);
+	return 0x00000000000283D0ull;
 }
 #else
 #define CVMX_SLI_SCRATCH_2 CVMX_SLI_SCRATCH_2_FUNC()
@@ -3044,12 +3044,12 @@ static inline uint64_t CVMX_SLI_SCRATCH_2_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000103D0ull);
+			return 0x00000000000003D0ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F00000283D0ull);
+			return 0x00000000000283D0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F00000283D0ull);
+	return 0x00000000000283D0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -3064,15 +3064,15 @@ static inline uint64_t CVMX_SLI_STATE1_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010620ull);
+			return 0x0000000000000620ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028620ull);
+			return 0x0000000000028620ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_STATE1 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000028620ull);
+	return 0x0000000000028620ull;
 }
 #else
 #define CVMX_SLI_STATE1 CVMX_SLI_STATE1_FUNC()
@@ -3086,12 +3086,12 @@ static inline uint64_t CVMX_SLI_STATE1_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010620ull);
+			return 0x0000000000000620ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028620ull);
+			return 0x0000000000028620ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000028620ull);
+	return 0x0000000000028620ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -3106,15 +3106,15 @@ static inline uint64_t CVMX_SLI_STATE2_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010630ull);
+			return 0x0000000000000630ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028630ull);
+			return 0x0000000000028630ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_STATE2 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000028630ull);
+	return 0x0000000000028630ull;
 }
 #else
 #define CVMX_SLI_STATE2 CVMX_SLI_STATE2_FUNC()
@@ -3128,12 +3128,12 @@ static inline uint64_t CVMX_SLI_STATE2_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010630ull);
+			return 0x0000000000000630ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028630ull);
+			return 0x0000000000028630ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000028630ull);
+	return 0x0000000000028630ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -3148,15 +3148,15 @@ static inline uint64_t CVMX_SLI_STATE3_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010640ull);
+			return 0x0000000000000640ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028640ull);
+			return 0x0000000000028640ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_STATE3 not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00011F0000028640ull);
+	return 0x0000000000028640ull;
 }
 #else
 #define CVMX_SLI_STATE3 CVMX_SLI_STATE3_FUNC()
@@ -3170,12 +3170,12 @@ static inline uint64_t CVMX_SLI_STATE3_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000010640ull);
+			return 0x0000000000000640ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00011F0000028640ull);
+			return 0x0000000000028640ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00011F0000028640ull);
+	return 0x0000000000028640ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
@@ -3201,15 +3201,15 @@ static inline uint64_t CVMX_SLI_WINDOW_CTL_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00000000000102E0ull);
+			return 0x00000000000002E0ull;
 			break;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00000000000282E0ull);
+			return 0x00000000000282E0ull;
 			break;
 	}
 	cvmx_warn("CVMX_SLI_WINDOW_CTL not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00000000000282E0ull);
+	return 0x00000000000282E0ull;
 }
 #else
 #define CVMX_SLI_WINDOW_CTL CVMX_SLI_WINDOW_CTL_FUNC()
@@ -3223,12 +3223,12 @@ static inline uint64_t CVMX_SLI_WINDOW_CTL_FUNC(void)
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00000000000102E0ull);
+			return 0x00000000000002E0ull;
 		case OCTEON_CNF75XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN73XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x00000000000282E0ull);
+			return 0x00000000000282E0ull;
 	}
-	return CVMX_ADD_IO_SEG(0x00000000000282E0ull);
+	return 0x00000000000282E0ull;
 }
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
diff --git a/arch/mips/include/asm/octeon/cvmx-spemx-defs.h b/arch/mips/include/asm/octeon/cvmx-spemx-defs.h
new file mode 100644
index 0000000..7320dcf
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-spemx-defs.h
@@ -0,0 +1,2136 @@
+/***********************license start***************
+ * Copyright (c) 2003-2015  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+
+/**
+ * cvmx-spemx-defs.h
+ *
+ * Configuration and status register (CSR) type definitions for
+ * Octeon spemx.
+ *
+ * This file is auto generated. Do not edit.
+ *
+ * <hr>$Revision$<hr>
+ *
+ */
+#ifndef __CVMX_SPEMX_DEFS_H__
+#define __CVMX_SPEMX_DEFS_H__
+
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_BAR1_INDEXX(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 15)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_SPEMX_BAR1_INDEXX(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800C0000100ull) + (((offset) & 15) + ((block_id) & 0) * 0x0ull) * 8;
+}
+#else
+#define CVMX_SPEMX_BAR1_INDEXX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800C0000100ull) + (((offset) & 15) + ((block_id) & 0) * 0x0ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_BAR2_MASK(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_BAR2_MASK(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C00000B0ull);
+}
+#else
+#define CVMX_SPEMX_BAR2_MASK(offset) (CVMX_ADD_IO_SEG(0x00011800C00000B0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_BAR_CTL(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_BAR_CTL(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C00000A8ull);
+}
+#else
+#define CVMX_SPEMX_BAR_CTL(offset) (CVMX_ADD_IO_SEG(0x00011800C00000A8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_BIST_STATUS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_BIST_STATUS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000440ull);
+}
+#else
+#define CVMX_SPEMX_BIST_STATUS(offset) (CVMX_ADD_IO_SEG(0x00011800C0000440ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_CFG(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_CFG(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000410ull);
+}
+#else
+#define CVMX_SPEMX_CFG(offset) (CVMX_ADD_IO_SEG(0x00011800C0000410ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_CFG_RD(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_CFG_RD(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000030ull);
+}
+#else
+#define CVMX_SPEMX_CFG_RD(offset) (CVMX_ADD_IO_SEG(0x00011800C0000030ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_CFG_WR(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_CFG_WR(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000028ull);
+}
+#else
+#define CVMX_SPEMX_CFG_WR(offset) (CVMX_ADD_IO_SEG(0x00011800C0000028ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_CLK_EN(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_CLK_EN(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000400ull);
+}
+#else
+#define CVMX_SPEMX_CLK_EN(offset) (CVMX_ADD_IO_SEG(0x00011800C0000400ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_CPL_LUT_VALID(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_CPL_LUT_VALID(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000098ull);
+}
+#else
+#define CVMX_SPEMX_CPL_LUT_VALID(offset) (CVMX_ADD_IO_SEG(0x00011800C0000098ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_CTL_STATUS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_CTL_STATUS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000000ull);
+}
+#else
+#define CVMX_SPEMX_CTL_STATUS(offset) (CVMX_ADD_IO_SEG(0x00011800C0000000ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_CTL_STATUS2(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_CTL_STATUS2(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000008ull);
+}
+#else
+#define CVMX_SPEMX_CTL_STATUS2(offset) (CVMX_ADD_IO_SEG(0x00011800C0000008ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_DBG_INFO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_DBG_INFO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C00000D0ull);
+}
+#else
+#define CVMX_SPEMX_DBG_INFO(offset) (CVMX_ADD_IO_SEG(0x00011800C00000D0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_DIAG_STATUS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_DIAG_STATUS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000020ull);
+}
+#else
+#define CVMX_SPEMX_DIAG_STATUS(offset) (CVMX_ADD_IO_SEG(0x00011800C0000020ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_ECC_ENA(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_ECC_ENA(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000448ull);
+}
+#else
+#define CVMX_SPEMX_ECC_ENA(offset) (CVMX_ADD_IO_SEG(0x00011800C0000448ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_ECC_SYND_CTRL(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_ECC_SYND_CTRL(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000450ull);
+}
+#else
+#define CVMX_SPEMX_ECC_SYND_CTRL(offset) (CVMX_ADD_IO_SEG(0x00011800C0000450ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_ECO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_ECO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000010ull);
+}
+#else
+#define CVMX_SPEMX_ECO(offset) (CVMX_ADD_IO_SEG(0x00011800C0000010ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_FLR_GLBLCNT_CTL(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_FLR_GLBLCNT_CTL(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000210ull);
+}
+#else
+#define CVMX_SPEMX_FLR_GLBLCNT_CTL(offset) (CVMX_ADD_IO_SEG(0x00011800C0000210ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_FLR_PF0_VF_STOPREQ(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_FLR_PF0_VF_STOPREQ(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000220ull);
+}
+#else
+#define CVMX_SPEMX_FLR_PF0_VF_STOPREQ(offset) (CVMX_ADD_IO_SEG(0x00011800C0000220ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_FLR_PF1_VF_STOPREQ(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_FLR_PF1_VF_STOPREQ(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000228ull);
+}
+#else
+#define CVMX_SPEMX_FLR_PF1_VF_STOPREQ(offset) (CVMX_ADD_IO_SEG(0x00011800C0000228ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_FLR_PF2_VFX_STOPREQ(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 16)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_SPEMX_FLR_PF2_VFX_STOPREQ(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800C0000300ull) + (((offset) & 31) + ((block_id) & 0) * 0x0ull) * 8;
+}
+#else
+#define CVMX_SPEMX_FLR_PF2_VFX_STOPREQ(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800C0000300ull) + (((offset) & 31) + ((block_id) & 0) * 0x0ull) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_FLR_PF_STOPREQ(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_FLR_PF_STOPREQ(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000218ull);
+}
+#else
+#define CVMX_SPEMX_FLR_PF_STOPREQ(offset) (CVMX_ADD_IO_SEG(0x00011800C0000218ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_FLR_ZOMBIE_CTL(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_FLR_ZOMBIE_CTL(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000230ull);
+}
+#else
+#define CVMX_SPEMX_FLR_ZOMBIE_CTL(offset) (CVMX_ADD_IO_SEG(0x00011800C0000230ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_INB_READ_CREDITS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_INB_READ_CREDITS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C00000B8ull);
+}
+#else
+#define CVMX_SPEMX_INB_READ_CREDITS(offset) (CVMX_ADD_IO_SEG(0x00011800C00000B8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_INT_SUM(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_INT_SUM(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000428ull);
+}
+#else
+#define CVMX_SPEMX_INT_SUM(offset) (CVMX_ADD_IO_SEG(0x00011800C0000428ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_NQM_BAR0_START(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_NQM_BAR0_START(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000208ull);
+}
+#else
+#define CVMX_SPEMX_NQM_BAR0_START(offset) (CVMX_ADD_IO_SEG(0x00011800C0000208ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_NQM_TLP_CREDITS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_NQM_TLP_CREDITS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000200ull);
+}
+#else
+#define CVMX_SPEMX_NQM_TLP_CREDITS(offset) (CVMX_ADD_IO_SEG(0x00011800C0000200ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_ON(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_ON(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000420ull);
+}
+#else
+#define CVMX_SPEMX_ON(offset) (CVMX_ADD_IO_SEG(0x00011800C0000420ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_P2N_BAR0_START(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_P2N_BAR0_START(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000080ull);
+}
+#else
+#define CVMX_SPEMX_P2N_BAR0_START(offset) (CVMX_ADD_IO_SEG(0x00011800C0000080ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_P2N_BAR1_START(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_P2N_BAR1_START(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000088ull);
+}
+#else
+#define CVMX_SPEMX_P2N_BAR1_START(offset) (CVMX_ADD_IO_SEG(0x00011800C0000088ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_P2N_BAR2_START(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_P2N_BAR2_START(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000090ull);
+}
+#else
+#define CVMX_SPEMX_P2N_BAR2_START(offset) (CVMX_ADD_IO_SEG(0x00011800C0000090ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_P2P_BARX_END(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_SPEMX_P2P_BARX_END(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800C0000048ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 16;
+}
+#else
+#define CVMX_SPEMX_P2P_BARX_END(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800C0000048ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_P2P_BARX_START(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && (((offset <= 3)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_SPEMX_P2P_BARX_START(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800C0000040ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 16;
+}
+#else
+#define CVMX_SPEMX_P2P_BARX_START(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800C0000040ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 16)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_PF1_DBG_INFO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_PF1_DBG_INFO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000240ull);
+}
+#else
+#define CVMX_SPEMX_PF1_DBG_INFO(offset) (CVMX_ADD_IO_SEG(0x00011800C0000240ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_PF2_DBG_INFO(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_PF2_DBG_INFO(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000248ull);
+}
+#else
+#define CVMX_SPEMX_PF2_DBG_INFO(offset) (CVMX_ADD_IO_SEG(0x00011800C0000248ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_SPI_CTL(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_SPI_CTL(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000180ull);
+}
+#else
+#define CVMX_SPEMX_SPI_CTL(offset) (CVMX_ADD_IO_SEG(0x00011800C0000180ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_SPI_DATA(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_SPI_DATA(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000188ull);
+}
+#else
+#define CVMX_SPEMX_SPI_DATA(offset) (CVMX_ADD_IO_SEG(0x00011800C0000188ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_STRAP(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_STRAP(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000408ull);
+}
+#else
+#define CVMX_SPEMX_STRAP(offset) (CVMX_ADD_IO_SEG(0x00011800C0000408ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_SPEMX_TLP_CREDITS(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset == 0)))))
+		cvmx_warn("CVMX_SPEMX_TLP_CREDITS(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x00011800C0000038ull);
+}
+#else
+#define CVMX_SPEMX_TLP_CREDITS(offset) (CVMX_ADD_IO_SEG(0x00011800C0000038ull))
+#endif
+
+/**
+ * cvmx_spem#_bar1_index#
+ *
+ * This register contains the address index and control bits for access to memory ranges of BAR1.
+ * The index is built from supplied address [25:22].
+ */
+union cvmx_spemx_bar1_indexx {
+	uint64_t u64;
+	struct cvmx_spemx_bar1_indexx_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_24_63               : 40;
+	uint64_t addr_idx                     : 20; /**< Address index. Address bits [41:22] sent to L2C. */
+	uint64_t ca                           : 1;  /**< Cached. Set to 1 when access is not to be cached in L2. */
+	uint64_t end_swp                      : 2;  /**< Endian-swap mode.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
+	uint64_t addr_v                       : 1;  /**< Address valid. Set to 1 when the selected address range is valid. */
+#else
+	uint64_t addr_v                       : 1;
+	uint64_t end_swp                      : 2;
+	uint64_t ca                           : 1;
+	uint64_t addr_idx                     : 20;
+	uint64_t reserved_24_63               : 40;
+#endif
+	} s;
+	struct cvmx_spemx_bar1_indexx_s       cn73xx;
+};
+typedef union cvmx_spemx_bar1_indexx cvmx_spemx_bar1_indexx_t;
+
+/**
+ * cvmx_spem#_bar2_mask
+ *
+ * This register contains the mask pattern that is ANDed with the address from the PCIe core for
+ * BAR2 hits. This allows the effective size of RC BAR2 to be shrunk. Must not be changed
+ * from its reset value in EP mode.
+ */
+union cvmx_spemx_bar2_mask {
+	uint64_t u64;
+	struct cvmx_spemx_bar2_mask_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_42_63               : 22;
+	uint64_t mask                         : 39; /**< The value to be ANDed with the address sent to the CNXXXX memory. */
+	uint64_t reserved_0_2                 : 3;
+#else
+	uint64_t reserved_0_2                 : 3;
+	uint64_t mask                         : 39;
+	uint64_t reserved_42_63               : 22;
+#endif
+	} s;
+	struct cvmx_spemx_bar2_mask_s         cn73xx;
+};
+typedef union cvmx_spemx_bar2_mask cvmx_spemx_bar2_mask_t;
+
+/**
+ * cvmx_spem#_bar_ctl
+ *
+ * This register contains control for BAR accesses.
+ *
+ */
+union cvmx_spemx_bar_ctl {
+	uint64_t u64;
+	struct cvmx_spemx_bar_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_7_63                : 57;
+	uint64_t bar1_siz                     : 3;  /**< PCIe Port 0 Bar1 Size. Must be 0x1 in EP mode.
+                                                         0x0 = Reserved.
+                                                         0x1 = 64 MB.
+                                                         0x2 = 128 MB.
+                                                         0x3 = 256 MB.
+                                                         0x4 = 512 MB.
+                                                         0x5 = 1024 MB.
+                                                         0x6 = 2048 MB.
+                                                         0x7 = Reserved. */
+	uint64_t bar2_enb                     : 1;  /**< When set to 1, BAR2 is enabled and will respond; when clear, BAR2 access will cause UR responses. */
+	uint64_t bar2_esx                     : 2;  /**< Value is XORed with PCIe address [43:42] to determine the endian swap mode.
+                                                         Enumerated by SLI_ENDIANSWAP_E. */
+	uint64_t bar2_cax                     : 1;  /**< Value is XORed with PCIe address [44] to determine the L2 cache attribute. Not cached in
+                                                         L2 if XOR result is 1. */
+#else
+	uint64_t bar2_cax                     : 1;
+	uint64_t bar2_esx                     : 2;
+	uint64_t bar2_enb                     : 1;
+	uint64_t bar1_siz                     : 3;
+	uint64_t reserved_7_63                : 57;
+#endif
+	} s;
+	struct cvmx_spemx_bar_ctl_s           cn73xx;
+};
+typedef union cvmx_spemx_bar_ctl cvmx_spemx_bar_ctl_t;
+
+/**
+ * cvmx_spem#_bist_status
+ *
+ * This register contains results from BIST runs of SPEM's memories.
+ *
+ */
+union cvmx_spemx_bist_status {
+	uint64_t u64;
+	struct cvmx_spemx_bist_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_17_63               : 47;
+	uint64_t m2nqm                        : 1;  /**< BIST status for m2nqm_fifo. */
+	uint64_t retryc                       : 1;  /**< Retry buffer memory C. */
+	uint64_t sot                          : 1;  /**< Start of transfer memory. */
+	uint64_t rqhdrb0                      : 1;  /**< Rx queue header memory buffer 0. */
+	uint64_t rqhdrb1                      : 1;  /**< Rx queue header memory buffer 1. */
+	uint64_t rqdatab0                     : 1;  /**< Rx queue data buffer 0. */
+	uint64_t rqdatab1                     : 1;  /**< Rx queue data buffer 1. */
+	uint64_t tlpn_d0                      : 1;  /**< BIST status for SLI & NQM tlp_n_fifo_data0. */
+	uint64_t tlpn_d1                      : 1;  /**< BIST status for SLI & NQM tlp_n_fifo_data1. */
+	uint64_t tlpn_ctl                     : 1;  /**< BIST status for SLI & NQM tlp_n_fifo_ctl. */
+	uint64_t tlpp_d0                      : 1;  /**< BIST status for SLI & NQM tlp_p_fifo_data0. */
+	uint64_t tlpp_d1                      : 1;  /**< BIST status for SLI & NQM tlp_p_fifo_data1. */
+	uint64_t tlpp_ctl                     : 1;  /**< BIST status for SLI & NQM tlp_p_fifo_ctl. */
+	uint64_t tlpc_d0                      : 1;  /**< BIST status for SLI & NQM tlp_c_fifo_data0. */
+	uint64_t tlpc_d1                      : 1;  /**< BIST status for SLI & NQM tlp_c_fifo_data1. */
+	uint64_t tlpc_ctl                     : 1;  /**< BIST status for SLI & NQM tlp_c_fifo_ctl. */
+	uint64_t m2sli                        : 1;  /**< BIST status for m2sli_fifo. */
+#else
+	uint64_t m2sli                        : 1;
+	uint64_t tlpc_ctl                     : 1;
+	uint64_t tlpc_d1                      : 1;
+	uint64_t tlpc_d0                      : 1;
+	uint64_t tlpp_ctl                     : 1;
+	uint64_t tlpp_d1                      : 1;
+	uint64_t tlpp_d0                      : 1;
+	uint64_t tlpn_ctl                     : 1;
+	uint64_t tlpn_d1                      : 1;
+	uint64_t tlpn_d0                      : 1;
+	uint64_t rqdatab1                     : 1;
+	uint64_t rqdatab0                     : 1;
+	uint64_t rqhdrb1                      : 1;
+	uint64_t rqhdrb0                      : 1;
+	uint64_t sot                          : 1;
+	uint64_t retryc                       : 1;
+	uint64_t m2nqm                        : 1;
+	uint64_t reserved_17_63               : 47;
+#endif
+	} s;
+	struct cvmx_spemx_bist_status_s       cn73xx;
+};
+typedef union cvmx_spemx_bist_status cvmx_spemx_bist_status_t;
+
+/**
+ * cvmx_spem#_cfg
+ *
+ * Configuration of the PCIe Application.
+ *
+ */
+union cvmx_spemx_cfg {
+	uint64_t u64;
+	struct cvmx_spemx_cfg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t laneswap                     : 1;  /**< This field enables overwriting the value for lane swapping. The reset value is captured on
+                                                         cold reset by the pin straps (see PEM()_STRAP[PILANESWAP]). When set, lane swapping is
+                                                         performed to/from the SerDes. When clear, no lane swapping is performed. */
+	uint64_t lanes8                       : 1;  /**< This field enables overwriting the value for the maximum number of lanes. The reset value
+                                                         is captured on cold reset by the pin straps (see PEM()_STRAP[PILANES8]). When set, the
+                                                         PEM is configured for a maximum of 8 lanes when connected to a QLM. When clear, the PEM
+                                                         is configured for a maximum of 4 lanes when connected to a QLM. When the PEM is connected
+                                                         to a DLM, this field is unused, the number of lanes is 2.
+                                                         This value, along with PEM()_QLM[PEMDLMMUX], is used to set the maximum link width field
+                                                         in the core's
+                                                         link capabilities register (CFG031) to indicate the maximum number of lanes
+                                                         supported. Note that less lanes than the specified maximum can be configured for use via
+                                                         the core's link control register (CFG032) negotiated link width field. */
+	uint64_t hostmd                       : 1;  /**< This field enables overwriting the value for host mode. The reset value is captured on
+                                                         cold reset by the pin straps. (See PEM()_STRAP[PIMODE]. The HOSTMD reset value is the
+                                                         bit-wise AND of the PIMODE straps.  As such, PEMs 0 and 2 are configurable and PEMs 1
+                                                         and 3 default to 0x1.)  When set, the PEM is configured to be a root complex. When clear,
+                                                         the PEM is configured to be an end point.
+                                                         Because SPEM0 and PEM2 share an EEPROM, the PEM2_CFG[HOSTMD] should only be changed by
+                                                         software when SPEM0 is in reset. */
+	uint64_t md                           : 2;  /**< This field enables overwriting the value for speed. The reset value is captured on cold
+                                                         reset by the pin straps (see PEM()_STRAP[PIMODE]). For a root complex configuration
+                                                         that is not running at Gen3 speed, the HOSTMD bit of this register must be set when this
+                                                         field is changed.
+                                                         0x0 = Gen1 speed.
+                                                         0x1 = Gen2 speed.
+                                                         0x2 = Gen3 speed.
+                                                         0x3 = Reserved. */
+#else
+	uint64_t md                           : 2;
+	uint64_t hostmd                       : 1;
+	uint64_t lanes8                       : 1;
+	uint64_t laneswap                     : 1;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_spemx_cfg_s               cn73xx;
+};
+typedef union cvmx_spemx_cfg cvmx_spemx_cfg_t;
+
+/**
+ * cvmx_spem#_cfg_rd
+ *
+ * This register allows read access to the configuration in the PCIe core.
+ *
+ */
+union cvmx_spemx_cfg_rd {
+	uint64_t u64;
+	struct cvmx_spemx_cfg_rd_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t data                         : 32; /**< Data. */
+	uint64_t addr                         : 32; /**< Address to read. A write to this register starts a read operation.
+                                                         Following are the subfields of the ADDR field.
+                                                         <31:26> Reserved. Must be zero.
+                                                         <25:24> The physical function number accessed by the read. 0..2 are legal
+                                                                 values in EP mode. Must be zero in RC mode.
+                                                         <23>    When clear, the read accesses a physical function. When set,
+                                                                 the read accesses the virtual function selected by <22:12>.
+                                                                 Must be zero when SR-IOV is not used in the physical function.
+                                                                 Must be zero in RC mode.
+                                                         <22:12> The selected virtual function. Must be zero when <23> is
+                                                                 clear. Must be zero in RC mode. 0..63 are legal values for
+                                                                 PF0 and PF1. 0..1026 are legal values for PF2.
+                                                         <11:0>  Selects the PCIe config space register being read in the
+                                                                 function.
+                                                         INTERNAL:
+                                                           <25:24> is dbi_func_num to the core.
+                                                           <23>    is dbi_vfunc_active to the core.
+                                                           <22:12> is dbi_vfunc_num to the core. */
+#else
+	uint64_t addr                         : 32;
+	uint64_t data                         : 32;
+#endif
+	} s;
+	struct cvmx_spemx_cfg_rd_s            cn73xx;
+};
+typedef union cvmx_spemx_cfg_rd cvmx_spemx_cfg_rd_t;
+
+/**
+ * cvmx_spem#_cfg_wr
+ *
+ * This register allows write access to the configuration in the PCIe core.
+ *
+ */
+union cvmx_spemx_cfg_wr {
+	uint64_t u64;
+	struct cvmx_spemx_cfg_wr_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t data                         : 32; /**< Data to write. A write to this register starts a write operation. */
+	uint64_t addr                         : 32; /**< Address to write. A write to this register starts a write operation.
+                                                         Following are the subfields of the ADDR field.
+                                                         <31>    When clear, the write is the same as a config space write received
+                                                                 from external. When set, the write can modify more fields than
+                                                                 an external write could (i.e. configuration mask register).
+                                                                 Corresponds to the CS2 field in Byte2 of the EEPROM.
+                                                         <30:26> Reserved. Must be zero.
+                                                         <25:24> The physical function number accessed by the write. 0..2 are legal
+                                                                 values in EP mode. Must be zero in RC mode.
+                                                         <23>    When clear, the write accesses a physical function. When set,
+                                                                 the write accesses the virtual function selected by <22:12>.
+                                                                 Must be zero when SR-IOV is not used in the physical function.
+                                                                 Must be zero in RC mode.
+                                                         <22:12> The selected virtual function. Must be zero when <23> is
+                                                                 clear. Must be zero in RC mode. 0..63 are legal values for
+                                                                 PF0 and PF1. 0..1026 are legal values for PF2.
+                                                         <11:0>  Selects the PCIe config space register being written in the
+                                                                 function.
+                                                         INTERNAL:
+                                                           <31>    asserts dbi_cs2 at PCIe core.
+                                                           <25:24> is dbi_func_num to the core.
+                                                           <23>    is dbi_vfunc_active to the core.
+                                                           <22:12> is dbi_vfunc_num to the core. */
+#else
+	uint64_t addr                         : 32;
+	uint64_t data                         : 32;
+#endif
+	} s;
+	struct cvmx_spemx_cfg_wr_s            cn73xx;
+};
+typedef union cvmx_spemx_cfg_wr cvmx_spemx_cfg_wr_t;
+
+/**
+ * cvmx_spem#_clk_en
+ *
+ * This register contains the clock enable for ECLK and PCE_CLK.
+ *
+ */
+union cvmx_spemx_clk_en {
+	uint64_t u64;
+	struct cvmx_spemx_clk_en_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_2_63                : 62;
+	uint64_t pceclk_gate                  : 1;  /**< When set, PCE_CLK is gated off. When clear, PCE_CLK is enabled.
+                                                         Software should set this bit when the PEM is in reset or otherwise not
+                                                         being used in order to reduce power. */
+	uint64_t csclk_gate                   : 1;  /**< When set, CSCLK is gated off. When clear, CSCLK is enabled.
+                                                         Software should set this bit when the PEM is in reset or otherwise not
+                                                         being used in order to reduce power. */
+#else
+	uint64_t csclk_gate                   : 1;
+	uint64_t pceclk_gate                  : 1;
+	uint64_t reserved_2_63                : 62;
+#endif
+	} s;
+	struct cvmx_spemx_clk_en_s            cn73xx;
+};
+typedef union cvmx_spemx_clk_en cvmx_spemx_clk_en_t;
+
+/**
+ * cvmx_spem#_cpl_lut_valid
+ *
+ * This register specifies the bit set for an outstanding tag read.
+ *
+ */
+union cvmx_spemx_cpl_lut_valid {
+	uint64_t u64;
+	struct cvmx_spemx_cpl_lut_valid_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t tag                          : 64; /**< Bit vector set corresponds to an outstanding tag. */
+#else
+	uint64_t tag                          : 64;
+#endif
+	} s;
+	struct cvmx_spemx_cpl_lut_valid_s     cn73xx;
+};
+typedef union cvmx_spemx_cpl_lut_valid cvmx_spemx_cpl_lut_valid_t;
+
+/**
+ * cvmx_spem#_ctl_status
+ *
+ * This is a general control and status register of the SPEM.
+ *
+ */
+union cvmx_spemx_ctl_status {
+	uint64_t u64;
+	struct cvmx_spemx_ctl_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_51_63               : 13;
+	uint64_t inv_dpar                     : 1;  /**< Invert the generated parity to be written into the most significant data queue buffer RAM
+                                                         block to force a parity error when it is later read. */
+	uint64_t reserved_48_49               : 2;
+	uint64_t auto_sd                      : 1;  /**< Link hardware autonomous speed disable. */
+	uint64_t dnum                         : 5;  /**< Not used. */
+	uint64_t pbus                         : 8;  /**< Primary bus number. In RC mode, a RO copy of the corresponding
+                                                         PCIERC(0..3)_CFG006[PBNUM]. In EP mode, the bus number latched
+                                                         on any type 0 configuration write. */
+	uint64_t reserved_32_33               : 2;
+	uint64_t cfg_rtry                     : 16; /**< The time * 0x10000 in coprocessor clocks to wait for a CPL to a configuration read that
+                                                         does not carry a retry status. Until such time that the timeout occurs and retry status is
+                                                         received for a configuration read, the read will be resent. A value of 0 disables retries
+                                                         and treats a CPL Retry as a CPL UR. When enabled, only one CFG RD may be issued until
+                                                         either successful completion or CPL UR. */
+	uint64_t reserved_14_15               : 2;
+	uint64_t pm_pf_xpme                   : 2;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_pme port.
+                                                         EP mode.
+                                                         <13> = PF2.
+                                                         <12> = PF1. */
+	uint64_t pm_xtoff                     : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_turnoff port. RC mode. */
+	uint64_t pm_xpme                      : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_pme port.
+                                                         EP mode PF0. */
+	uint64_t ob_p_cmd                     : 3;  /**< When written with one, a single cycle pulse is sent to the PCIe core outband_pwrup_cmd
+                                                         port. EP mode.
+                                                         <9> = PF0.
+                                                         <8> = PF1.
+                                                         <7> = PF2. */
+	uint64_t nf_ecrc                      : 1;  /**< Do not forward peer-to-peer ECRC TLPs. */
+	uint64_t dly_one                      : 1;  /**< When set the output client state machines will wait one cycle before starting a new TLP out. */
+	uint64_t lnk_enb                      : 1;  /**< When set, the link is enabled; when clear (0) the link is disabled. This bit only is
+                                                         active when in RC mode. */
+	uint64_t ro_ctlp                      : 1;  /**< When set, C-TLPs that have the RO bit set will not wait for P-TLPs that are normally sent first. */
+	uint64_t fast_lm                      : 1;  /**< When set, forces fast link mode. */
+	uint64_t inv_ecrc                     : 1;  /**< When set, causes the LSB of the ECRC to be inverted. */
+	uint64_t inv_lcrc                     : 1;  /**< When set, causes the LSB of the LCRC to be inverted. */
+#else
+	uint64_t inv_lcrc                     : 1;
+	uint64_t inv_ecrc                     : 1;
+	uint64_t fast_lm                      : 1;
+	uint64_t ro_ctlp                      : 1;
+	uint64_t lnk_enb                      : 1;
+	uint64_t dly_one                      : 1;
+	uint64_t nf_ecrc                      : 1;
+	uint64_t ob_p_cmd                     : 3;
+	uint64_t pm_xpme                      : 1;
+	uint64_t pm_xtoff                     : 1;
+	uint64_t pm_pf_xpme                   : 2;
+	uint64_t reserved_14_15               : 2;
+	uint64_t cfg_rtry                     : 16;
+	uint64_t reserved_32_33               : 2;
+	uint64_t pbus                         : 8;
+	uint64_t dnum                         : 5;
+	uint64_t auto_sd                      : 1;
+	uint64_t reserved_48_49               : 2;
+	uint64_t inv_dpar                     : 1;
+	uint64_t reserved_51_63               : 13;
+#endif
+	} s;
+	struct cvmx_spemx_ctl_status_s        cn73xx;
+};
+typedef union cvmx_spemx_ctl_status cvmx_spemx_ctl_status_t;
+
+/**
+ * cvmx_spem#_ctl_status2
+ *
+ * This register contains additional general control and status of the SPEM.
+ *
+ */
+union cvmx_spemx_ctl_status2 {
+	uint64_t u64;
+	struct cvmx_spemx_ctl_status2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t no_fwd_prg                   : 16; /**< The time * 0x10000 in core clocks to wait for the TLP FIFOs to be able to unload an entry.
+                                                         If there is no forward progress, such that the timeout occurs, credits are returned to the
+                                                         SLI and an interrupt (if enabled) is asserted. Any more TLPs received are dropped on the
+                                                         floor and the credits associated with those TLPs are returned as well. Note that 0xFFFF is
+                                                         a reserved value that will put the PEM in the 'forward progress stopped' state
+                                                         immediately. This state holds until a MAC reset is received. */
+#else
+	uint64_t no_fwd_prg                   : 16;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_spemx_ctl_status2_s       cn73xx;
+};
+typedef union cvmx_spemx_ctl_status2 cvmx_spemx_ctl_status2_t;
+
+/**
+ * cvmx_spem#_dbg_info
+ *
+ * This is a debug information register of the SPEM.
+ *
+ */
+union cvmx_spemx_dbg_info {
+	uint64_t u64;
+	struct cvmx_spemx_dbg_info_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_62_63               : 2;
+	uint64_t m2s_c_dbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO control0/1 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_M2S_C_DBE. */
+	uint64_t m2s_c_sbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO control0/1 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_M2S_C_SBE. */
+	uint64_t m2s_d_dbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO data0/1 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_M2S_D_DBE. */
+	uint64_t m2s_d_sbe                    : 1;  /**< Detected a SLI/NQM M2S FIFO data0/1 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_M2S_D_SBE. */
+	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a core header queue bank1 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_QHDR_B1_DBE. */
+	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a core header queue bank1 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_QHDR_B1_SBE. */
+	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a core header queue bank0 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_QHDR_B0_DBE. */
+	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a core header queue bank0 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_QHDR_B0_SBE. */
+	uint64_t rtry_dbe                     : 1;  /**< Detected a core retry RAM double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RTRY_DBE. */
+	uint64_t rtry_sbe                     : 1;  /**< Detected a core retry RAM single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RTRY_SBE. */
+	uint64_t c_c_dbe                      : 1;  /**< Detected a SLI/NQM TLP CPL FIFO control double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_C_C_DBE. */
+	uint64_t c_c_sbe                      : 1;  /**< Detected a SLI/NQM TLP CPL FIFO control single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_C_C_SBE. */
+	uint64_t c_d1_dbe                     : 1;  /**< Detected a SLI/NQM TLP CPL FIFO data1 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_C_D1_DBE. */
+	uint64_t c_d1_sbe                     : 1;  /**< Detected a SLI/NQM TLP CPL FIFO data1 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_C_D1_SBE. */
+	uint64_t c_d0_dbe                     : 1;  /**< Detected a SLI/NQM TLP CPL FIFO data0 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_C_D0_DBE. */
+	uint64_t c_d0_sbe                     : 1;  /**< Detected a SLI/NQM TLP CPL FIFO data0 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_C_D0_SBE. */
+	uint64_t n_c_dbe                      : 1;  /**< Detected a SLI/NQM TLP NP FIFO control double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_N_C_DBE. */
+	uint64_t n_c_sbe                      : 1;  /**< Detected a SLI/NQM TLP NP FIFO control single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_N_C_SBE. */
+	uint64_t n_d1_dbe                     : 1;  /**< Detected a SLI/NQM TLP NP FIFO data1 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_N_D1_DBE. */
+	uint64_t n_d1_sbe                     : 1;  /**< Detected a SLI/NQM TLP NP FIFO data1 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_N_D1_SBE. */
+	uint64_t n_d0_dbe                     : 1;  /**< Detected a SLI/NQM TLP NP FIFO data0 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_N_D0_DBE. */
+	uint64_t n_d0_sbe                     : 1;  /**< Detected a SLI/NQM TLP NP FIFO data0 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_N_D0_SBE. */
+	uint64_t p_c_dbe                      : 1;  /**< Detected a SLI/NQM TLP posted FIFO control double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P_C_DBE. */
+	uint64_t p_c_sbe                      : 1;  /**< Detected a SLI/NQM TLP posted FIFO control single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P_C_SBE. */
+	uint64_t p_d1_dbe                     : 1;  /**< Detected a SLI/NQM TLP posted FIFO data1 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P_D1_DBE. */
+	uint64_t p_d1_sbe                     : 1;  /**< Detected a SLI/NQM TLP posted FIFO data1 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P_D1_SBE. */
+	uint64_t p_d0_dbe                     : 1;  /**< Detected a SLI/NQM TLP posted FIFO data0 double bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P_D0_DBE. */
+	uint64_t p_d0_sbe                     : 1;  /**< Detected a SLI/NQM TLP posted FIFO data0 single bit error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P_D0_SBE. */
+	uint64_t datq_pe                      : 1;  /**< Detected a data queue RAM parity error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_DATQ_PE. */
+	uint64_t p0_bmd_e                     : 1;  /**< A PF0 NP or P TLP was seen in the outbound path, but it was not allowed to master the bus.
+                                                         If a PF TLP and the PCIEEP()_CFG001[ME] is not set.
+                                                         For VF TLP, either the the PCIEEP()_CFG001[ME]/PCIEEPVF()_CFG001[ME] are not set.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_BMD_E. */
+	uint64_t lofp                         : 1;  /**< Lack of forward progress at TLP FIFOs timeout occurred.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_LOFP. */
+	uint64_t p0_ecrc_e                    : 1;  /**< Received an PF0 ECRC error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_ECRC_E. */
+	uint64_t p0_rawwpp                    : 1;  /**< Received a PF0 write with poisoned payload.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_RAWWPP.
+                                                         INTERNAL: radm_rcvd_wreq_poisoned */
+	uint64_t p0_racpp                     : 1;  /**< Received a PF0 completion with poisoned payload.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_RACPP.
+                                                         INTERNAL: radm_rcvd_cpl_poisoned */
+	uint64_t p0_ramtlp                    : 1;  /**< Received a PF0 malformed TLP.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_RAMTLP.
+                                                         INTERNAL: radm_mlf_tlp_err */
+	uint64_t p0_rarwdns                   : 1;  /**< Received a request which device does not support.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_RARWDNS.
+                                                         INTERNAL: radm_rcvd_req_ur. */
+	uint64_t p0_caar                      : 1;  /**< Completer PF0 aborted a request. This bit is never set because CNXXXX does not generate
+                                                         completer aborts.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_CAAR. */
+	uint64_t p0_racca                     : 1;  /**< Received a PF0 completion with CA status.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_RACCA.
+                                                         INTERNAL: radm_rcvd_cpl_ca */
+	uint64_t p0_racur                     : 1;  /**< Received a PF0 completion with UR status.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_RACUR.
+                                                         INTERNAL: radm_rcvd_cpl_ur */
+	uint64_t p0_rauc                      : 1;  /**< Received an PF0 unexpected completion.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_P0_RAUC.
+                                                         INTERNAL: radm_unexp_cpl_err */
+	uint64_t rqo                          : 1;  /**< Receive queue overflow. Normally happens only when flow control advertisements are
+                                                         ignored.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RQO.
+                                                         INTERNAL: radm_qoverflow. */
+	uint64_t fcuv                         : 1;  /**< Flow control update violation.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_FCUV.
+                                                         INTERNAL: (opt. checks) int_xadm_fc_prot_err. */
+	uint64_t rpe                          : 1;  /**< PHY reported an 8B/10B decode error (RxStatus = 0x4) or disparity error (RxStatus =
+                                                         0x7).
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RPE.
+                                                         INTERNAL: rmlh_rcvd_err. */
+	uint64_t fcpvwt                       : 1;  /**< Flow control protocol violation (watchdog timer).
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_FCPVWT.
+                                                         INTERNAL: rtlh_fc_prot_err. */
+	uint64_t dpeoosd                      : 1;  /**< DLLP protocol error (out of sequence DLLP).
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_DPEOOSD.
+                                                         INTERNAL: rdlh_prot_err. */
+	uint64_t rtwdle                       : 1;  /**< Received TLP with datalink layer error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RTWDLE.
+                                                         INTERNAL: rdlh_bad_tlp_err. */
+	uint64_t rdwdle                       : 1;  /**< Received DLLP with datalink layer error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RDWDLE.
+                                                         INTERNAL: rdlh_bad_dllp_err. */
+	uint64_t mre                          : 1;  /**< Maximum number of retries exceeded.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_MRE.
+                                                         INTERNAL: xdlh_replay_num_rlover_err. */
+	uint64_t rte                          : 1;  /**< Replay timer expired. This bit is set when the REPLAY_TIMER expires in the PCIe core. The
+                                                         probability of this bit being set increases with the traffic load.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RTE.
+                                                         INTERNAL: xdlh_replay_timeout_err. */
+	uint64_t acto                         : 1;  /**< A completion timeout occurred.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_ACTO.
+                                                         INTERNAL: pedc_radm_cpl_timeout. */
+	uint64_t rvdm                         : 1;  /**< Received vendor-defined message.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RVDM.
+                                                         INTERNAL: pedc_radm_vendor_msg. */
+	uint64_t rumep                        : 1;  /**< Received unlock message (EP mode only).
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RUMEP.
+                                                         INTERNAL: pedc_radm_msg_unlock. */
+	uint64_t rptamrc                      : 1;  /**< Received PME turnoff acknowledge message (RC mode only).
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RPTAMRC.
+                                                         INTERNAL: pedc_radm_pm_to_ack. */
+	uint64_t rpmerc                       : 1;  /**< Received PME message (RC mode only).
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RPMERC.
+                                                         INTERNAL: pedc_radm_pm_pme. */
+	uint64_t rfemrc                       : 1;  /**< Received fatal-error message (RC mode only). This bit is set when a message with ERR_FATAL
+                                                         is set.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RFEMRC.
+                                                         INTERNAL: pedc_radm_fatal_err. */
+	uint64_t rnfemrc                      : 1;  /**< Received nonfatal error message (RC mode only).
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RNFEMRC.
+                                                         INTERNAL: pedc_radm_nonfatal_err. */
+	uint64_t rcemrc                       : 1;  /**< Received correctable error message (RC mode only).
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RCEMRC.
+                                                         INTERNAL: pedc_radm_correctable_err. */
+	uint64_t rpoison                      : 1;  /**< Received poisoned TLP.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RPOISON.
+                                                         INTERNAL: pedc__radm_trgt1_poisoned & pedc__radm_trgt1_hv. */
+	uint64_t recrce                       : 1;  /**< Received ECRC error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RECRCE.
+                                                         INTERNAL: pedc_radm_trgt1_ecrc_err & pedc__radm_trgt1_eot. */
+	uint64_t rtlplle                      : 1;  /**< Received TLP has link layer error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RTLPLLE.
+                                                         INTERNAL: pedc_radm_trgt1_dllp_abort & pedc__radm_trgt1_eot. */
+	uint64_t rtlpmal                      : 1;  /**< Received TLP is malformed or a message. If the core receives a MSG (or Vendor Message) or
+                                                         if a received AtomicOp viloates address/length rules, this bit is set as well.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RTLPMAL.
+                                                         INTERNAL: pedc_radm_trgt1_tlp_abort & pedc__radm_trgt1_eot. */
+	uint64_t spoison                      : 1;  /**< Poisoned TLP sent.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_SPOISON.
+                                                         INTERNAL: peai__client0_tlp_ep & peai__client0_tlp_hv or peai__client1_tlp_ep
+                                                                   & peai__client1_tlp_hv (atomic_op). */
+#else
+	uint64_t spoison                      : 1;
+	uint64_t rtlpmal                      : 1;
+	uint64_t rtlplle                      : 1;
+	uint64_t recrce                       : 1;
+	uint64_t rpoison                      : 1;
+	uint64_t rcemrc                       : 1;
+	uint64_t rnfemrc                      : 1;
+	uint64_t rfemrc                       : 1;
+	uint64_t rpmerc                       : 1;
+	uint64_t rptamrc                      : 1;
+	uint64_t rumep                        : 1;
+	uint64_t rvdm                         : 1;
+	uint64_t acto                         : 1;
+	uint64_t rte                          : 1;
+	uint64_t mre                          : 1;
+	uint64_t rdwdle                       : 1;
+	uint64_t rtwdle                       : 1;
+	uint64_t dpeoosd                      : 1;
+	uint64_t fcpvwt                       : 1;
+	uint64_t rpe                          : 1;
+	uint64_t fcuv                         : 1;
+	uint64_t rqo                          : 1;
+	uint64_t p0_rauc                      : 1;
+	uint64_t p0_racur                     : 1;
+	uint64_t p0_racca                     : 1;
+	uint64_t p0_caar                      : 1;
+	uint64_t p0_rarwdns                   : 1;
+	uint64_t p0_ramtlp                    : 1;
+	uint64_t p0_racpp                     : 1;
+	uint64_t p0_rawwpp                    : 1;
+	uint64_t p0_ecrc_e                    : 1;
+	uint64_t lofp                         : 1;
+	uint64_t p0_bmd_e                     : 1;
+	uint64_t datq_pe                      : 1;
+	uint64_t p_d0_sbe                     : 1;
+	uint64_t p_d0_dbe                     : 1;
+	uint64_t p_d1_sbe                     : 1;
+	uint64_t p_d1_dbe                     : 1;
+	uint64_t p_c_sbe                      : 1;
+	uint64_t p_c_dbe                      : 1;
+	uint64_t n_d0_sbe                     : 1;
+	uint64_t n_d0_dbe                     : 1;
+	uint64_t n_d1_sbe                     : 1;
+	uint64_t n_d1_dbe                     : 1;
+	uint64_t n_c_sbe                      : 1;
+	uint64_t n_c_dbe                      : 1;
+	uint64_t c_d0_sbe                     : 1;
+	uint64_t c_d0_dbe                     : 1;
+	uint64_t c_d1_sbe                     : 1;
+	uint64_t c_d1_dbe                     : 1;
+	uint64_t c_c_sbe                      : 1;
+	uint64_t c_c_dbe                      : 1;
+	uint64_t rtry_sbe                     : 1;
+	uint64_t rtry_dbe                     : 1;
+	uint64_t qhdr_b0_sbe                  : 1;
+	uint64_t qhdr_b0_dbe                  : 1;
+	uint64_t qhdr_b1_sbe                  : 1;
+	uint64_t qhdr_b1_dbe                  : 1;
+	uint64_t m2s_d_sbe                    : 1;
+	uint64_t m2s_d_dbe                    : 1;
+	uint64_t m2s_c_sbe                    : 1;
+	uint64_t m2s_c_dbe                    : 1;
+	uint64_t reserved_62_63               : 2;
+#endif
+	} s;
+	struct cvmx_spemx_dbg_info_s          cn73xx;
+};
+typedef union cvmx_spemx_dbg_info cvmx_spemx_dbg_info_t;
+
+/**
+ * cvmx_spem#_diag_status
+ *
+ * This register contains selection control for the core diagnostic bus.
+ *
+ */
+union cvmx_spemx_diag_status {
+	uint64_t u64;
+	struct cvmx_spemx_diag_status_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_30_63               : 34;
+	uint64_t pf2_pm_dst                   : 3;  /**< PF2 Current power management DSTATE. */
+	uint64_t pf2_pm_stat                  : 1;  /**< PF2 Power management status. */
+	uint64_t pf2_pm_en                    : 1;  /**< PF2 Power management event enable. */
+	uint64_t pf2_aux_en                   : 1;  /**< PF2 Auxiliary power enable. */
+	uint64_t reserved_22_23               : 2;
+	uint64_t pf1_pm_dst                   : 3;  /**< PF1 Current power management DSTATE. */
+	uint64_t pf1_pm_stat                  : 1;  /**< PF1 Power management status. */
+	uint64_t pf1_pm_en                    : 1;  /**< PF1 Power management event enable. */
+	uint64_t pf1_aux_en                   : 1;  /**< PF1 Auxiliary power enable. */
+	uint64_t reserved_9_15                : 7;
+	uint64_t pwrdwn                       : 3;  /**< PF0 Current mac_phy_powerdown state. */
+	uint64_t pm_dst                       : 3;  /**< PF0 Current power management DSTATE. */
+	uint64_t pm_stat                      : 1;  /**< PF0 Power management status. */
+	uint64_t pm_en                        : 1;  /**< PF0 Power management event enable. */
+	uint64_t aux_en                       : 1;  /**< PF0 Auxiliary power enable. */
+#else
+	uint64_t aux_en                       : 1;
+	uint64_t pm_en                        : 1;
+	uint64_t pm_stat                      : 1;
+	uint64_t pm_dst                       : 3;
+	uint64_t pwrdwn                       : 3;
+	uint64_t reserved_9_15                : 7;
+	uint64_t pf1_aux_en                   : 1;
+	uint64_t pf1_pm_en                    : 1;
+	uint64_t pf1_pm_stat                  : 1;
+	uint64_t pf1_pm_dst                   : 3;
+	uint64_t reserved_22_23               : 2;
+	uint64_t pf2_aux_en                   : 1;
+	uint64_t pf2_pm_en                    : 1;
+	uint64_t pf2_pm_stat                  : 1;
+	uint64_t pf2_pm_dst                   : 3;
+	uint64_t reserved_30_63               : 34;
+#endif
+	} s;
+	struct cvmx_spemx_diag_status_s       cn73xx;
+};
+typedef union cvmx_spemx_diag_status cvmx_spemx_diag_status_t;
+
+/**
+ * cvmx_spem#_ecc_ena
+ *
+ * This register contains enables for NQM & SLI TLP FIFO ECC RAMs.
+ *
+ */
+union cvmx_spemx_ecc_ena {
+	uint64_t u64;
+	struct cvmx_spemx_ecc_ena_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_35_63               : 29;
+	uint64_t qhdr_b1_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank1 RAM. */
+	uint64_t qhdr_b0_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank0 RAM. */
+	uint64_t rtry_ena                     : 1;  /**< ECC enable for Core's RETRY RA. */
+	uint64_t reserved_11_31               : 21;
+	uint64_t m2s_c_ena                    : 1;  /**< ECC enable for M2S Control FIFO. */
+	uint64_t m2s_d_ena                    : 1;  /**< ECC enable for M2S Data FIFO. */
+	uint64_t c_c_ena                      : 1;  /**< ECC enable for TLP CPL control FIFO. */
+	uint64_t c_d1_ena                     : 1;  /**< ECC enable for TLP CPL data1 FIFO. */
+	uint64_t c_d0_ena                     : 1;  /**< ECC enable for TLP CPL data0 FIFO. */
+	uint64_t n_c_ena                      : 1;  /**< ECC enable for TLP NP control FIFO. */
+	uint64_t n_d1_ena                     : 1;  /**< ECC enable for TLP NP data1 FIFO. */
+	uint64_t n_d0_ena                     : 1;  /**< ECC enable for TLP NP data0 FIFO. */
+	uint64_t p_c_ena                      : 1;  /**< ECC enable for TLP posted control FIFO. */
+	uint64_t p_d1_ena                     : 1;  /**< ECC enable for TLP posted data1 FIFO. */
+	uint64_t p_d0_ena                     : 1;  /**< ECC enable for TLP posted data0 FIFO. */
+#else
+	uint64_t p_d0_ena                     : 1;
+	uint64_t p_d1_ena                     : 1;
+	uint64_t p_c_ena                      : 1;
+	uint64_t n_d0_ena                     : 1;
+	uint64_t n_d1_ena                     : 1;
+	uint64_t n_c_ena                      : 1;
+	uint64_t c_d0_ena                     : 1;
+	uint64_t c_d1_ena                     : 1;
+	uint64_t c_c_ena                      : 1;
+	uint64_t m2s_d_ena                    : 1;
+	uint64_t m2s_c_ena                    : 1;
+	uint64_t reserved_11_31               : 21;
+	uint64_t rtry_ena                     : 1;
+	uint64_t qhdr_b0_ena                  : 1;
+	uint64_t qhdr_b1_ena                  : 1;
+	uint64_t reserved_35_63               : 29;
+#endif
+	} s;
+	struct cvmx_spemx_ecc_ena_s           cn73xx;
+};
+typedef union cvmx_spemx_ecc_ena cvmx_spemx_ecc_ena_t;
+
+/**
+ * cvmx_spem#_ecc_synd_ctrl
+ *
+ * This register contains syndrome control for NQM & SLI TLP FIFO ECC RAMs.
+ *
+ */
+union cvmx_spemx_ecc_synd_ctrl {
+	uint64_t u64;
+	struct cvmx_spemx_ecc_synd_ctrl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_38_63               : 26;
+	uint64_t qhdr_b1_syn                  : 2;  /**< Syndrome flip bits for Core's Q HDR Bank1 RAM. */
+	uint64_t qhdr_b0_syn                  : 2;  /**< Syndrome flip bits for Core's Q HDR Bank0 RAM. */
+	uint64_t rtry_syn                     : 2;  /**< Syndrome flip bits for Core's RETRY RAM. */
+	uint64_t reserved_22_31               : 10;
+	uint64_t m2s_c_syn                    : 2;  /**< Syndrome flip bits for M2S Control FIFO. */
+	uint64_t m2s_d_syn                    : 2;  /**< Syndrome flip bits for M2S Data FIFO. */
+	uint64_t c_c_syn                      : 2;  /**< Syndrome flip bits for TLP CPL control FIFO. */
+	uint64_t c_d1_syn                     : 2;  /**< Syndrome flip bits for TLP CPL data1 FIFO. */
+	uint64_t c_d0_syn                     : 2;  /**< Syndrome flip bits for TLP CPL data0 FIFO. */
+	uint64_t n_c_syn                      : 2;  /**< Syndrome flip bits for TLP NP control FIFO. */
+	uint64_t n_d1_syn                     : 2;  /**< Syndrome flip bits for TLP NP data1 FIFO. */
+	uint64_t n_d0_syn                     : 2;  /**< Syndrome flip bits for TLP NP data0 FIFO. */
+	uint64_t p_c_syn                      : 2;  /**< Syndrome flip bits for TLP posted control FIFO. */
+	uint64_t p_d1_syn                     : 2;  /**< Syndrome flip bits for TLP posted data1 FIFO. */
+	uint64_t p_d0_syn                     : 2;  /**< Syndrome flip bits for TLP posted data0 FIFO. */
+#else
+	uint64_t p_d0_syn                     : 2;
+	uint64_t p_d1_syn                     : 2;
+	uint64_t p_c_syn                      : 2;
+	uint64_t n_d0_syn                     : 2;
+	uint64_t n_d1_syn                     : 2;
+	uint64_t n_c_syn                      : 2;
+	uint64_t c_d0_syn                     : 2;
+	uint64_t c_d1_syn                     : 2;
+	uint64_t c_c_syn                      : 2;
+	uint64_t m2s_d_syn                    : 2;
+	uint64_t m2s_c_syn                    : 2;
+	uint64_t reserved_22_31               : 10;
+	uint64_t rtry_syn                     : 2;
+	uint64_t qhdr_b0_syn                  : 2;
+	uint64_t qhdr_b1_syn                  : 2;
+	uint64_t reserved_38_63               : 26;
+#endif
+	} s;
+	struct cvmx_spemx_ecc_synd_ctrl_s     cn73xx;
+};
+typedef union cvmx_spemx_ecc_synd_ctrl cvmx_spemx_ecc_synd_ctrl_t;
+
+/**
+ * cvmx_spem#_eco
+ */
+union cvmx_spemx_eco {
+	uint64_t u64;
+	struct cvmx_spemx_eco_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_8_63                : 56;
+	uint64_t eco_rw                       : 8;  /**< INTERNAL: Reserved for ECO usage. */
+#else
+	uint64_t eco_rw                       : 8;
+	uint64_t reserved_8_63                : 56;
+#endif
+	} s;
+	struct cvmx_spemx_eco_s               cn73xx;
+};
+typedef union cvmx_spemx_eco cvmx_spemx_eco_t;
+
+/**
+ * cvmx_spem#_flr_glblcnt_ctl
+ *
+ * Function Level Reset Global Counter Control.
+ *
+ */
+union cvmx_spemx_flr_glblcnt_ctl {
+	uint64_t u64;
+	struct cvmx_spemx_flr_glblcnt_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_4_63                : 60;
+	uint64_t chge                         : 1;  /**< When set, the default 25ms expiration of the Function Level Reset
+                                                         Global Counter can be changed. */
+	uint64_t inc                          : 1;  /**< When CHGE is set, this bit determines if the 25ms expiration of the Function
+                                                         Level Reset Global Counter will be increased (set) or decreased (not set). */
+	uint64_t delta                        : 2;  /**< When CHGE is set, this field determines the delta time to increase/decrease
+                                                         the 25ms expiration of the Function Level Reset Global Counter.
+                                                         0x0 = 1ms.
+                                                         0x1 = 2ms.
+                                                         0x2 = 4ms.
+                                                         0x3 = 8ms. */
+#else
+	uint64_t delta                        : 2;
+	uint64_t inc                          : 1;
+	uint64_t chge                         : 1;
+	uint64_t reserved_4_63                : 60;
+#endif
+	} s;
+	struct cvmx_spemx_flr_glblcnt_ctl_s   cn73xx;
+};
+typedef union cvmx_spemx_flr_glblcnt_ctl cvmx_spemx_flr_glblcnt_ctl_t;
+
+/**
+ * cvmx_spem#_flr_pf0_vf_stopreq
+ *
+ * PF0 Virtual Function Level Reset Stop Outbound Requests Register.
+ * Hardware automatically sets the STOPREQ bit for the VF when it enters a
+ * Function Level Reset (FLR).  Software is responsible for clearing the STOPREQ
+ * bit but must not do so prior to hardware taking down the FLR, which could be
+ * as long as 100ms.  It may be appropriate for software to wait longer before clearing
+ * STOPREQ, software may need to drain deep DPI queues for example.
+ * Whenever SPEM receives a request mastered by CNXXXX over S2M (i.e. P or NP),
+ * when STOPREQ is set for the function, SPEM will discard the outgoing request
+ * before sending it to the PCIe core.  If a NP, SPEM will schedule an immediate
+ * SWI_RSP_ERROR completion for the request - no timeout is required.
+ *
+ * STOPREQ mimics the behavior of PCIEEPVF()_CFG001[ME] for outbound requests that will
+ * master the PCIe bus (P and NP).
+ *
+ * Note that STOPREQ will have no effect on completions returned by CNXXXX over the S2M,
+ * nor on M2S traffic.
+ */
+union cvmx_spemx_flr_pf0_vf_stopreq {
+	uint64_t u64;
+	struct cvmx_spemx_flr_pf0_vf_stopreq_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t vf_stopreq                   : 64; /**< STOPREQ for the 64 VFs in PF0. */
+#else
+	uint64_t vf_stopreq                   : 64;
+#endif
+	} s;
+	struct cvmx_spemx_flr_pf0_vf_stopreq_s cn73xx;
+};
+typedef union cvmx_spemx_flr_pf0_vf_stopreq cvmx_spemx_flr_pf0_vf_stopreq_t;
+
+/**
+ * cvmx_spem#_flr_pf1_vf_stopreq
+ *
+ * PF1 Virtual Function Level Reset Stop Outbound Requests Register.
+ * Hardware automatically sets the STOPREQ bit for the VF when it enters a
+ * Function Level Reset (FLR).  Software is responsible for clearing the STOPREQ
+ * bit but must not do so prior to hardware taking down the FLR, which could be
+ * as long as 100ms.  It may be appropriate for software to wait longer before clearing
+ * STOPREQ, software may need to drain deep DPI queues for example.
+ * Whenever SPEM receives a request mastered by CNXXXX over S2M (i.e. P or NP),
+ * when STOPREQ is set for the function, SPEM will discard the outgoing request
+ * before sending it to the PCIe core.  If a NP, SPEM will schedule an immediate
+ * SWI_RSP_ERROR completion for the request - no timeout is required.
+ *
+ * STOPREQ mimics the behavior of PCIEEPVF()_CFG001[ME] for outbound requests that will
+ * master the PCIe bus (P and NP).
+ *
+ * Note that STOPREQ will have no effect on completions returned by CNXXXX over the S2M,
+ * nor on M2S traffic.
+ */
+union cvmx_spemx_flr_pf1_vf_stopreq {
+	uint64_t u64;
+	struct cvmx_spemx_flr_pf1_vf_stopreq_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t vf_stopreq                   : 64; /**< STOPREQ for the 64 VFs in PF1. */
+#else
+	uint64_t vf_stopreq                   : 64;
+#endif
+	} s;
+	struct cvmx_spemx_flr_pf1_vf_stopreq_s cn73xx;
+};
+typedef union cvmx_spemx_flr_pf1_vf_stopreq cvmx_spemx_flr_pf1_vf_stopreq_t;
+
+/**
+ * cvmx_spem#_flr_pf2_vf#_stopreq
+ *
+ * PF2 Virtual Function Level Reset Stop Outbound Requests Register.
+ * Hardware automatically sets the STOPREQ bit for the VF when it enters a
+ * Function Level Reset (FLR).  Software is responsible for clearing the STOPREQ
+ * bit but must not do so prior to hardware taking down the FLR, which could be
+ * as long as 100ms.  It may be appropriate for software to wait longer before clearing
+ * STOPREQ, software may need to drain deep DPI queues for example.
+ * Whenever SPEM receives a request mastered by CNXXXX over S2M (i.e. P or NP),
+ * when STOPREQ is set for the function, SPEM will discard the outgoing request
+ * before sending it to the PCIe core.  If a NP, SPEM will schedule an immediate
+ * SWI_RSP_ERROR completion for the request - no timeout is required.
+ *
+ * STOPREQ mimics the behavior of PCIEEPVF()_CFG001[ME] for outbound requests that will
+ * master the PCIe bus (P and NP).
+ *
+ * Note that STOPREQ will have no effect on completions returned by CNXXXX over the S2M,
+ * nor on M2S traffic.
+ */
+union cvmx_spemx_flr_pf2_vfx_stopreq {
+	uint64_t u64;
+	struct cvmx_spemx_flr_pf2_vfx_stopreq_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t vf_stopreq                   : 64; /**< STOPREQ for the 1027 VFs in PF2. */
+#else
+	uint64_t vf_stopreq                   : 64;
+#endif
+	} s;
+	struct cvmx_spemx_flr_pf2_vfx_stopreq_s cn73xx;
+};
+typedef union cvmx_spemx_flr_pf2_vfx_stopreq cvmx_spemx_flr_pf2_vfx_stopreq_t;
+
+/**
+ * cvmx_spem#_flr_pf_stopreq
+ *
+ * PF Function Level Reset Stop Outbound Requests Register.
+ * Hardware automatically sets the STOPREQ bit for the PF when it enters a
+ * Function Level Reset (FLR).  Software is responsible for clearing the STOPREQ
+ * bit but must not do so prior to hardware taking down the FLR, which could be
+ * as long as 100ms.  It may be appropriate for software to wait longer before clearing
+ * STOPREQ, software may need to drain deep DPI queues for example.
+ * Whenever SPEM receives a PF or child VF request mastered by CNXXXX over S2M (i.e. P or NP),
+ * when STOPREQ is set for the function, SPEM will discard the outgoing request
+ * before sending it to the PCIe core.  If a NP, SPEM will schedule an immediate
+ * SWI_RSP_ERROR completion for the request - no timeout is required.
+ * In both cases, SPEM()_DBG_PF()_INFO[P()_BMD_E] will be set and a error
+ * interrupt is generated.
+ *
+ * STOPREQ mimics the behavior of PCIEEP()_CFG001[ME] for outbound requests that will
+ * master the PCIe bus (P and NP).
+ *
+ * Note that STOPREQ will have no effect on completions returned by CNXXXX over the S2M,
+ * nor on M2S traffic.
+ *
+ * Note that when a PF()_STOPREQ is set, none of the associated
+ * PEM()_FLR_PF()_VF_STOPREQ[VF_STOPREQ]
+ * will be set.
+ */
+union cvmx_spemx_flr_pf_stopreq {
+	uint64_t u64;
+	struct cvmx_spemx_flr_pf_stopreq_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_3_63                : 61;
+	uint64_t pf2_stopreq                  : 1;  /**< PF2 STOPREQ bit. */
+	uint64_t pf1_stopreq                  : 1;  /**< PF1 STOPREQ bit. */
+	uint64_t pf0_stopreq                  : 1;  /**< PF0 STOPREQ bit. */
+#else
+	uint64_t pf0_stopreq                  : 1;
+	uint64_t pf1_stopreq                  : 1;
+	uint64_t pf2_stopreq                  : 1;
+	uint64_t reserved_3_63                : 61;
+#endif
+	} s;
+	struct cvmx_spemx_flr_pf_stopreq_s    cn73xx;
+};
+typedef union cvmx_spemx_flr_pf_stopreq cvmx_spemx_flr_pf_stopreq_t;
+
+/**
+ * cvmx_spem#_flr_zombie_ctl
+ *
+ * Function Level Reset Global Zombie Counter Control Register
+ *
+ */
+union cvmx_spemx_flr_zombie_ctl {
+	uint64_t u64;
+	struct cvmx_spemx_flr_zombie_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_10_63               : 54;
+	uint64_t exp                          : 10; /**< The expiration value for the inbound shared global zombie counter.  The global zombie
+                                                         counter
+                                                         continously counts the number of cycles where the PCIe Core was allowed to send
+                                                         either a Posted request or a Completion to the PEM.  When the global zombie counter
+                                                         reaches expiration (EXP), it resets to zero and all the non-zero per PCIe tag zombie
+                                                         counters are decremented.  When a per PCIe tag zombie counter decrements to zero, a
+                                                         SWI_RSP_ERROR is
+                                                         sent to the M2S bus and its associated PCIe tag is returned to the pool.
+                                                         This field allows software programmability control of the zombie counter expiration. */
+#else
+	uint64_t exp                          : 10;
+	uint64_t reserved_10_63               : 54;
+#endif
+	} s;
+	struct cvmx_spemx_flr_zombie_ctl_s    cn73xx;
+};
+typedef union cvmx_spemx_flr_zombie_ctl cvmx_spemx_flr_zombie_ctl_t;
+
+/**
+ * cvmx_spem#_inb_read_credits
+ *
+ * This register contains the number of in-flight read operations from PCIe core to SLI.
+ *
+ */
+union cvmx_spemx_inb_read_credits {
+	uint64_t u64;
+	struct cvmx_spemx_inb_read_credits_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_7_63                : 57;
+	uint64_t num                          : 7;  /**< The number of reads that may be in flight from the PCIe core to the SLI. Minimum number is
+                                                         6; maximum number is 64. */
+#else
+	uint64_t num                          : 7;
+	uint64_t reserved_7_63                : 57;
+#endif
+	} s;
+	struct cvmx_spemx_inb_read_credits_s  cn73xx;
+};
+typedef union cvmx_spemx_inb_read_credits cvmx_spemx_inb_read_credits_t;
+
+/**
+ * cvmx_spem#_int_sum
+ *
+ * This register contains the different interrupt summary bits of the SPEM.
+ *
+ */
+union cvmx_spemx_int_sum {
+	uint64_t u64;
+	struct cvmx_spemx_int_sum_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. This is a level-sensitive interrupt. This
+                                                         should be ignored in EP mode.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_INTD. */
+	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. This is a level-sensitive interrupt. This
+                                                         should be ignored in EP mode.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_INTC. */
+	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. This is a level-sensitive interrupt. This
+                                                         should be ignored in EP mode.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_INTB. */
+	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. This is a level-sensitive interrupt. This
+                                                         should be ignored in EP mode.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_INTA. */
+	uint64_t reserved_14_59               : 46;
+	uint64_t crs_dr                       : 1;  /**< Had a CRS timeout when retries were disabled. This should be ignored in EP mode.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_CRS_DR. */
+	uint64_t crs_er                       : 1;  /**< Had a CRS timeout when retries were enabled. This should be ignored in EP mode.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_CRS_ER. */
+	uint64_t rdlk                         : 1;  /**< Received read lock TLP.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_RDLK. */
+	uint64_t un_bx                        : 1;  /**< Received N-TLP for unknown BAR.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_UN_BX. */
+	uint64_t un_b2                        : 1;  /**< Received N-TLP for BAR2 when BAR2 is disabled.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_UN_B2. */
+	uint64_t un_b1                        : 1;  /**< Received N-TLP for BAR1 when BAR1 index valid is not set.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_UN_B1. */
+	uint64_t up_bx                        : 1;  /**< Received P-TLP for an unknown BAR.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_UP_BX. */
+	uint64_t up_b2                        : 1;  /**< Received P-TLP for BAR2 when BAR2 is disabled.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_UP_B2. */
+	uint64_t up_b1                        : 1;  /**< Received P-TLP for BAR1 when BAR1 index valid is not set.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_UP_B1. */
+	uint64_t pf2_pmei                     : 1;  /**< PF2 PME interrupt. This is a level-sensitive interrupt.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_PF2_PMEI.
+                                                         INTERNAL: cfg_pme_int */
+	uint64_t pf1_pmei                     : 1;  /**< PF1 PME interrupt. This is a level-sensitive interrupt.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_PF1_PMEI.
+                                                         INTERNAL: cfg_pme_int */
+	uint64_t pf0_pmei                     : 1;  /**< PF0 PME interrupt. This is a level-sensitive interrupt.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_PF0_PMEI.
+                                                         INTERNAL: cfg_pme_int */
+	uint64_t se                           : 1;  /**< System error, RC mode only.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_SE.
+                                                         INTERNAL: cfg_sys_err_rc */
+	uint64_t aeri                         : 1;  /**< Advanced error reporting interrupt, RC mode only.
+                                                         This is a level-sensitive interrupt.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM()_ERROR_AERI.
+                                                         INTERNAL: cfg_aer_rc_err_int */
+#else
+	uint64_t aeri                         : 1;
+	uint64_t se                           : 1;
+	uint64_t pf0_pmei                     : 1;
+	uint64_t pf1_pmei                     : 1;
+	uint64_t pf2_pmei                     : 1;
+	uint64_t up_b1                        : 1;
+	uint64_t up_b2                        : 1;
+	uint64_t up_bx                        : 1;
+	uint64_t un_b1                        : 1;
+	uint64_t un_b2                        : 1;
+	uint64_t un_bx                        : 1;
+	uint64_t rdlk                         : 1;
+	uint64_t crs_er                       : 1;
+	uint64_t crs_dr                       : 1;
+	uint64_t reserved_14_59               : 46;
+	uint64_t inta                         : 1;
+	uint64_t intb                         : 1;
+	uint64_t intc                         : 1;
+	uint64_t intd                         : 1;
+#endif
+	} s;
+	struct cvmx_spemx_int_sum_s           cn73xx;
+};
+typedef union cvmx_spemx_int_sum cvmx_spemx_int_sum_t;
+
+/**
+ * cvmx_spem#_nqm_bar0_start
+ *
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the NQM in RC mode.
+ *
+ * INTERNAL: Make this CSR visible when bug 22564 gets fixed.
+ */
+union cvmx_spemx_nqm_bar0_start {
+	uint64_t u64;
+	struct cvmx_spemx_nqm_bar0_start_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t addr                         : 47; /**< The starting address of the 128KB NQM BAR0 address space. */
+	uint64_t reserved_0_16                : 17;
+#else
+	uint64_t reserved_0_16                : 17;
+	uint64_t addr                         : 47;
+#endif
+	} s;
+	struct cvmx_spemx_nqm_bar0_start_s    cn73xx;
+};
+typedef union cvmx_spemx_nqm_bar0_start cvmx_spemx_nqm_bar0_start_t;
+
+/**
+ * cvmx_spem#_nqm_tlp_credits
+ *
+ * This register specifies the number of credits for use in moving inbound TLPs. When this
+ * register is
+ * written, the credit values are reset to the register value. A write to this register should
+ * take place before traffic flow starts.
+ */
+union cvmx_spemx_nqm_tlp_credits {
+	uint64_t u64;
+	struct cvmx_spemx_nqm_tlp_credits_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_24_63               : 40;
+	uint64_t nqm_cpl                      : 8;  /**< TLP 8B credits for completion TLPs in the NQM. Legal values are 0x24 to 0xFF. */
+	uint64_t nqm_np                       : 8;  /**< TLP 8B credits for nonposted TLPs in the NQM. Legal values are 0x4 to 0x10. */
+	uint64_t nqm_p                        : 8;  /**< TLP 8B credits for Posted TLPs in the NQM. Legal values are 0x24 to 0x3F. */
+#else
+	uint64_t nqm_p                        : 8;
+	uint64_t nqm_np                       : 8;
+	uint64_t nqm_cpl                      : 8;
+	uint64_t reserved_24_63               : 40;
+#endif
+	} s;
+	struct cvmx_spemx_nqm_tlp_credits_s   cn73xx;
+};
+typedef union cvmx_spemx_nqm_tlp_credits cvmx_spemx_nqm_tlp_credits_t;
+
+/**
+ * cvmx_spem#_on
+ *
+ * This register indicates that SPEM is configured and ready.
+ *
+ */
+union cvmx_spemx_on {
+	uint64_t u64;
+	struct cvmx_spemx_on_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_2_63                : 62;
+	uint64_t pemoor                       : 1;  /**< Indication to software that the PEM has been taken out of reset (i.e. BIST is done) and it
+                                                         is safe to configure core CSRs. */
+	uint64_t pemon                        : 1;  /**< Indication to the QLM that the PEM is out of reset, configured, and ready to send/receive
+                                                         traffic. Setting this bit takes the configured PIPE out of reset. */
+#else
+	uint64_t pemon                        : 1;
+	uint64_t pemoor                       : 1;
+	uint64_t reserved_2_63                : 62;
+#endif
+	} s;
+	struct cvmx_spemx_on_s                cn73xx;
+};
+typedef union cvmx_spemx_on cvmx_spemx_on_t;
+
+/**
+ * cvmx_spem#_p2n_bar0_start
+ *
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the SLI in RC mode.
+ */
+union cvmx_spemx_p2n_bar0_start {
+	uint64_t u64;
+	struct cvmx_spemx_p2n_bar0_start_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t addr                         : 41; /**< The starting address of the 8MB BAR0 address space. */
+	uint64_t reserved_0_22                : 23;
+#else
+	uint64_t reserved_0_22                : 23;
+	uint64_t addr                         : 41;
+#endif
+	} s;
+	struct cvmx_spemx_p2n_bar0_start_s    cn73xx;
+};
+typedef union cvmx_spemx_p2n_bar0_start cvmx_spemx_p2n_bar0_start_t;
+
+/**
+ * cvmx_spem#_p2n_bar1_start
+ *
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the SLI in RC mode.
+ */
+union cvmx_spemx_p2n_bar1_start {
+	uint64_t u64;
+	struct cvmx_spemx_p2n_bar1_start_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t addr                         : 38; /**< The starting address of the 64MB BAR1 address space. */
+	uint64_t reserved_0_25                : 26;
+#else
+	uint64_t reserved_0_25                : 26;
+	uint64_t addr                         : 38;
+#endif
+	} s;
+	struct cvmx_spemx_p2n_bar1_start_s    cn73xx;
+};
+typedef union cvmx_spemx_p2n_bar1_start cvmx_spemx_p2n_bar1_start_t;
+
+/**
+ * cvmx_spem#_p2n_bar2_start
+ *
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the SLI in RC mode.
+ */
+union cvmx_spemx_p2n_bar2_start {
+	uint64_t u64;
+	struct cvmx_spemx_p2n_bar2_start_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t addr                         : 19; /**< The starting address of the 2^45 BAR2 address space. */
+	uint64_t reserved_0_44                : 45;
+#else
+	uint64_t reserved_0_44                : 45;
+	uint64_t addr                         : 19;
+#endif
+	} s;
+	struct cvmx_spemx_p2n_bar2_start_s    cn73xx;
+};
+typedef union cvmx_spemx_p2n_bar2_start cvmx_spemx_p2n_bar2_start_t;
+
+/**
+ * cvmx_spem#_p2p_bar#_end
+ *
+ * This register specifies the ending address for memory requests that are to be forwarded to the
+ * PCIe peer port.
+ */
+union cvmx_spemx_p2p_barx_end {
+	uint64_t u64;
+	struct cvmx_spemx_p2p_barx_end_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t addr                         : 52; /**< The ending address of the address window created by this field and the
+                                                         PEM_P2P_BAR0_START[63:12] field. The full 64-bits of the address are created by:
+                                                         [ADDR[63:12], 12'b0]. */
+	uint64_t reserved_0_11                : 12;
+#else
+	uint64_t reserved_0_11                : 12;
+	uint64_t addr                         : 52;
+#endif
+	} s;
+	struct cvmx_spemx_p2p_barx_end_s      cn73xx;
+};
+typedef union cvmx_spemx_p2p_barx_end cvmx_spemx_p2p_barx_end_t;
+
+/**
+ * cvmx_spem#_p2p_bar#_start
+ *
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the PCIe peer port.
+ */
+union cvmx_spemx_p2p_barx_start {
+	uint64_t u64;
+	struct cvmx_spemx_p2p_barx_start_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t addr                         : 52; /**< The starting address of the address window created by this field and the
+                                                         PEM_P2P_BAR0_END[63:12] field. The full 64-bits of the address are created by:
+                                                         [ADDR[63:12], 12'b0]. */
+	uint64_t reserved_2_11                : 10;
+	uint64_t dst                          : 2;  /**< The destination peer of the address window created by this field and the
+                                                         PEM_P2P_BAR0_END[63:12] field. It is illegal to configure the destination peer to match
+                                                         the source. */
+#else
+	uint64_t dst                          : 2;
+	uint64_t reserved_2_11                : 10;
+	uint64_t addr                         : 52;
+#endif
+	} s;
+	struct cvmx_spemx_p2p_barx_start_s    cn73xx;
+};
+typedef union cvmx_spemx_p2p_barx_start cvmx_spemx_p2p_barx_start_t;
+
+/**
+ * cvmx_spem#_pf1_dbg_info
+ *
+ * This is PF1 debug information register of the SPEM.
+ *
+ */
+union cvmx_spemx_pf1_dbg_info {
+	uint64_t u64;
+	struct cvmx_spemx_pf1_dbg_info_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_33_63               : 31;
+	uint64_t p1_bmd_e                     : 1;  /**< A PF0 NP or P TLP was seen in the outbound path, but it was not allowed to master the bus.
+                                                         If a PF TLP and the PCIEEP()_CFG001[ME] is not set.
+                                                         For VF TLP, either the the PCIEEP()_CFG001[ME]/PCIEEPVF()_CFG001[ME] are not set.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_BMD_E. */
+	uint64_t reserved_31_31               : 1;
+	uint64_t p1_ecrc_e                    : 1;  /**< Received an PF1 ECRC error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_ECRC_E. */
+	uint64_t p1_rawwpp                    : 1;  /**< Received a PF1 write with poisoned payload.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_RAWWPP.
+                                                         INTERNAL: radm_rcvd_wreq_poisoned */
+	uint64_t p1_racpp                     : 1;  /**< Received a PF1 completion with poisoned payload.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_RACPP.
+                                                         INTERNAL: radm_rcvd_cpl_poisoned */
+	uint64_t p1_ramtlp                    : 1;  /**< Received a PF1 malformed TLP.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_RAMTLP.
+                                                         INTERNAL: radm_mlf_tlp_err */
+	uint64_t p1_rarwdns                   : 1;  /**< Received a request which device does not support.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_RARWDNS.
+                                                         INTERNAL: radm_rcvd_req_ur. */
+	uint64_t p1_caar                      : 1;  /**< Completer PF1 aborted a request. This bit is never set because CNXXXX does not generate
+                                                         completer aborts.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_CAAR. */
+	uint64_t p1_racca                     : 1;  /**< Received a PF1 completion with CA status.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_RACCA.
+                                                         INTERNAL: radm_rcvd_cpl_ca */
+	uint64_t p1_racur                     : 1;  /**< Received a PF1 completion with UR status.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_RACUR.
+                                                         INTERNAL: radm_rcvd_cpl_ur */
+	uint64_t p1_rauc                      : 1;  /**< Received an PF1 unexpected completion.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P1_RAUC.
+                                                         INTERNAL: radm_unexp_cpl_err */
+	uint64_t reserved_0_21                : 22;
+#else
+	uint64_t reserved_0_21                : 22;
+	uint64_t p1_rauc                      : 1;
+	uint64_t p1_racur                     : 1;
+	uint64_t p1_racca                     : 1;
+	uint64_t p1_caar                      : 1;
+	uint64_t p1_rarwdns                   : 1;
+	uint64_t p1_ramtlp                    : 1;
+	uint64_t p1_racpp                     : 1;
+	uint64_t p1_rawwpp                    : 1;
+	uint64_t p1_ecrc_e                    : 1;
+	uint64_t reserved_31_31               : 1;
+	uint64_t p1_bmd_e                     : 1;
+	uint64_t reserved_33_63               : 31;
+#endif
+	} s;
+	struct cvmx_spemx_pf1_dbg_info_s      cn73xx;
+};
+typedef union cvmx_spemx_pf1_dbg_info cvmx_spemx_pf1_dbg_info_t;
+
+/**
+ * cvmx_spem#_pf2_dbg_info
+ *
+ * This is PF2 debug information register of the SPEM.
+ *
+ */
+union cvmx_spemx_pf2_dbg_info {
+	uint64_t u64;
+	struct cvmx_spemx_pf2_dbg_info_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_33_63               : 31;
+	uint64_t p2_bmd_e                     : 1;  /**< A PF0 NP or P TLP was seen in the outbound path, but it was not allowed to master the bus.
+                                                         If a PF TLP and the PCIEEP()_CFG001[ME] is not set.
+                                                         For VF TLP, either the the PCIEEP()_CFG001[ME]/PCIEEPVF()_CFG001[ME] are not set.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_BMD_E. */
+	uint64_t reserved_31_31               : 1;
+	uint64_t p2_ecrc_e                    : 1;  /**< Received an PF2 ECRC error.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_ECRC_E. */
+	uint64_t p2_rawwpp                    : 1;  /**< Received a PF2 write with poisoned payload.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_RAWWPP.
+                                                         INTERNAL: radm_rcvd_wreq_poisoned */
+	uint64_t p2_racpp                     : 1;  /**< Received a PF2 completion with poisoned payload.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_RACPP.
+                                                         INTERNAL: radm_rcvd_cpl_poisoned */
+	uint64_t p2_ramtlp                    : 1;  /**< Received a PF2 malformed TLP.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_RAMTLP.
+                                                         INTERNAL: radm_mlf_tlp_err */
+	uint64_t p2_rarwdns                   : 1;  /**< Received a request which device does not support.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_RARWDNS.
+                                                         INTERNAL: radm_rcvd_req_ur. */
+	uint64_t p2_caar                      : 1;  /**< Completer PF2 aborted a request. This bit is never set because CNXXXX does not generate
+                                                         completer aborts.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_CAAR. */
+	uint64_t p2_racca                     : 1;  /**< Received a PF2 completion with CA status.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_RACCA.
+                                                         INTERNAL: radm_rcvd_cpl_ca */
+	uint64_t p2_racur                     : 1;  /**< Received a PF2 completion with UR status.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_RACUR.
+                                                         INTERNAL: radm_rcvd_cpl_ur */
+	uint64_t p2_rauc                      : 1;  /**< Received an PF2 unexpected completion.
+                                                         Throws corresponding SPEM_INTSN_E::SPEM(0)_ERROR_P2_RAUC.
+                                                         INTERNAL: radm_unexp_cpl_err */
+	uint64_t reserved_0_21                : 22;
+#else
+	uint64_t reserved_0_21                : 22;
+	uint64_t p2_rauc                      : 1;
+	uint64_t p2_racur                     : 1;
+	uint64_t p2_racca                     : 1;
+	uint64_t p2_caar                      : 1;
+	uint64_t p2_rarwdns                   : 1;
+	uint64_t p2_ramtlp                    : 1;
+	uint64_t p2_racpp                     : 1;
+	uint64_t p2_rawwpp                    : 1;
+	uint64_t p2_ecrc_e                    : 1;
+	uint64_t reserved_31_31               : 1;
+	uint64_t p2_bmd_e                     : 1;
+	uint64_t reserved_33_63               : 31;
+#endif
+	} s;
+	struct cvmx_spemx_pf2_dbg_info_s      cn73xx;
+};
+typedef union cvmx_spemx_pf2_dbg_info cvmx_spemx_pf2_dbg_info_t;
+
+/**
+ * cvmx_spem#_spi_ctl
+ */
+union cvmx_spemx_spi_ctl {
+	uint64_t u64;
+	struct cvmx_spemx_spi_ctl_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_14_63               : 50;
+	uint64_t start_busy                   : 1;  /**< Start/Busy status. When written with a one, indicates to the controller to
+                                                         start a SPI transaction. The controller clears [START_BUSY] when the
+                                                         write/read operation has completed. If the operation was a read, the
+                                                         contents of PEM()_SPI_DATA are valid once hardware clears this bit. */
+	uint64_t tvalid                       : 1;  /**< Reads 1 if at least one valid entry was read (preamble was valid) from EEPROM
+                                                         and written to corresponding PEM()_SPI_DATA. Write to clear status. */
+	uint64_t cmd                          : 3;  /**< SPI commands. The commands are the following:
+                                                         0x0 = Reserved.
+                                                         0x1 = WRSR: write status register. A single-byte write of
+                                                               corresponding PEM()_SPI_DATA[DATA<7:0>] to the register.
+                                                         0x2 = WRITE: an eight-byte page-mode write of the 64-bits of corresponding
+                                                               PEM()_SPI_DATA to the memory array.
+                                                         0x3 = READ: an eight-byte page-mode read access from the memory array
+                                                               with result in the 64-bits of corresponding PEM()_SPI_DATA.
+                                                         0x4 = WRDI: clear the write-enable latch (i.e. write protect the device).
+                                                         0x5 = RDSR: Read status register. A single-byte read access from
+                                                               the register with result in corresponding PEM()_SPI_DATA[DATA<7:0>].
+                                                         0x6 = WREN: set the write-enable latch (i.e. allow writes to occur)
+                                                         0x7 = Reserved. */
+	uint64_t adr                          : 9;  /**< EEPROM read/write address. the byte address offset for the serial EEPROM access.
+                                                         Since accesses are eight-byte aligned entries, <2:0> must be zero. */
+#else
+	uint64_t adr                          : 9;
+	uint64_t cmd                          : 3;
+	uint64_t tvalid                       : 1;
+	uint64_t start_busy                   : 1;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_spemx_spi_ctl_s           cn73xx;
+};
+typedef union cvmx_spemx_spi_ctl cvmx_spemx_spi_ctl_t;
+
+/**
+ * cvmx_spem#_spi_data
+ *
+ * This register contains the most recently read or written SPI data and is unpredictable upon
+ * power-up.
+ */
+union cvmx_spemx_spi_data {
+	uint64_t u64;
+	struct cvmx_spemx_spi_data_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t preamble                     : 16; /**< EEPROM PREAMBLE read or write data:
+                                                            valid entry  = 0x9DA1
+                                                            end-of-table = 0x6A5D
+                                                            null         = 0xFFFF
+                                                         Unpredictable after a PEM()_SPI_CTL[CMD]=RDSR. */
+	uint64_t reserved_45_47               : 3;
+	uint64_t cs2                          : 1;  /**< EEPROM CS2 bit. See PEM()_CFG_WR[ADDR<31>]. The [CS2] from
+                                                         a valid EEPROM entry selects the type of write. When clear, an ordinary
+                                                         configuration write. When set, a configuration mask write.
+                                                         Unpredictable after a PEM()_SPI_CTL[CMD]=RDSR. */
+	uint64_t adr                          : 12; /**< EEPROM configuration register address. See PEM()_CFG_WR[ADDR<11:0>].
+                                                         The [ADR] from a valid EEPROM entry selects which configuration register
+                                                         will be written. Note that PEM()_CFG_WR[ADDR<30:12>] of the effective
+                                                         write are all zeroes.
+                                                         Unpredictable after a PEM()_SPI_CTL[CMD]=RDSR. */
+	uint64_t data                         : 32; /**< EEPROM configuration register data. See PEM()_CFG_WR[DATA].
+                                                         HW writes the [DATA] from a valid EEPROM entry to the selected register.
+                                                         [DATA<31:8>] are unpredictable after a PEM()_SPI_CTL[CMD]=RDSR. */
+#else
+	uint64_t data                         : 32;
+	uint64_t adr                          : 12;
+	uint64_t cs2                          : 1;
+	uint64_t reserved_45_47               : 3;
+	uint64_t preamble                     : 16;
+#endif
+	} s;
+	struct cvmx_spemx_spi_data_s          cn73xx;
+};
+typedef union cvmx_spemx_spi_data cvmx_spemx_spi_data_t;
+
+/**
+ * cvmx_spem#_strap
+ */
+union cvmx_spemx_strap {
+	uint64_t u64;
+	struct cvmx_spemx_strap_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_5_63                : 59;
+	uint64_t miopem2dlm5sel               : 1;  /**< The value of the BOOT_AD[13] pin via MIO, which is captured on chip cold reset. It is not
+                                                         affected by any other reset.  Only used for PEM2.  When set, PEM2 is configured to
+                                                         DLM5 and PEM()_QLM[PEMDLMSEL] will be set, the Mac will be confifgured for 2 lanes.
+                                                         When clear, PEM2 is configured to QLM2. */
+	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin, which is captured on chip cold reset. It is not
+                                                         affected by any other reset.  When set, lane swapping is performed to/from the
+                                                         SerDes. When clear, no lane swapping is performed. */
+	uint64_t pilanes8                     : 1;  /**< The value of the pi_select_8lanes pin, which is captured on chip cold reset. It is not
+                                                         affected by any other reset.  When set, the PEM is configured for a maximum of
+                                                         8-lanes, When clear, the PEM is configured for a maximum of 4-lanes. */
+	uint64_t pimode                       : 2;  /**< The value of the pi_select_mode[1:0] pins, which are captured on chip cold reset. They are
+                                                         not affected by any other reset.
+                                                         0x0 = EP mode, Gen1 speed.
+                                                         0x1 = EP mode, Gen2 speed.
+                                                         0x2 = EP mode, Gen3 speed.
+                                                         0x3 = RC mode, defaults to Gen3 speed. */
+#else
+	uint64_t pimode                       : 2;
+	uint64_t pilanes8                     : 1;
+	uint64_t pilaneswap                   : 1;
+	uint64_t miopem2dlm5sel               : 1;
+	uint64_t reserved_5_63                : 59;
+#endif
+	} s;
+	struct cvmx_spemx_strap_s             cn73xx;
+};
+typedef union cvmx_spemx_strap cvmx_spemx_strap_t;
+
+/**
+ * cvmx_spem#_tlp_credits
+ *
+ * This register specifies the number of credits for use in moving inbound TLPs to the SLI
+ * including peer. When this register is written, the credit values are reset to the register
+ * value. A write to this register should take place before traffic flow starts.
+ */
+union cvmx_spemx_tlp_credits {
+	uint64_t u64;
+	struct cvmx_spemx_tlp_credits_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t pem_cpl                      : 8;  /**< TLP 16B credits for completion TLPs in the peer. Legal values are 0x12 to 0x40. */
+	uint64_t pem_np                       : 8;  /**< TLP 16B credits for nonposted TLPs in the peer. Legal values are 0x4 to 0x8. */
+	uint64_t pem_p                        : 8;  /**< TLP 16B credits for posted TLPs in the peer. Legal values are 0x12 to 0x40. */
+	uint64_t sli_cpl                      : 8;  /**< TLP 8B credits for completion TLPs in the SLI. Legal values are 0x24 to
+                                                         0xFF. Pairs of PEMs share a single SLI interface. SPEM(0) and PEM(1) share one
+                                                         SLI interface, while PEM(2) and PEM(3) share the other. When both PEMs of a pair
+                                                         are configured, the sum of both PEMs' SLI_CPL fields must not exceed 0x100. The
+                                                         reset value for this register assumes the minimum (e.g. 4-lane)
+                                                         configuration. This ensures that for configurations where the total number of
+                                                         lanes for a pair of PEMs exceeds 8, the total allocated credits does not
+                                                         oversubscribe the SLI.
+                                                         For configurations other than two 4-lane PEMs connected to a single SLI port,
+                                                         software may safely reprogram this register (i.e. increase the value) to achieve
+                                                         optimal performance.  See the following table of example configurations of PEM
+                                                         pairs for recommended credit values.
+                                                         <pre>
+                                                            Configuration  PEM  Lanes  Typical [SLI_CPL]
+                                                            --------------------------------------------
+                                                            1 8-ln PEM     n    8             0xFF
+                                                            2 4-ln PEMs    n    4             0x80
+                                                                          n+1   4             0x80
+                                                            1 4-ln PEM     n    4             0xFF
+                                                            1 8-ln PEM,    n    8             0xAA
+                                                            1 4-ln PEM    n+1   4             0x55
+                                                         </pre> */
+	uint64_t sli_np                       : 8;  /**< TLP 8B credits for nonposted TLPs in the SLI. Legal values are 0x4 to
+                                                         0x20. Pairs of PEMs share a single SLI interface. SPEM(0) and PEM(1) share one
+                                                         SLI interface, while PEM(2) and PEM(3) share the other. When both PEMs of a pair
+                                                         are configured, the sum of both PEMs' SLI_NP fields must not exceed 0x20. The
+                                                         reset value for this register assumes the minimum (e.g. 4-lane)
+                                                         configuration. This ensures that for configurations where the total number of
+                                                         lanes for a pair of PEMs exceeds 8, the total allocated credits does not
+                                                         oversubscribe the SLI.
+                                                         For configurations other than two 4-lane PEMs connected to a single SLI port,
+                                                         software may safely reprogram this register (i.e. increase the value) to achieve
+                                                         optimal performance.  See the following table of example configurations of PEM
+                                                         pairs for recommended credit values.
+                                                         <pre>
+                                                            Configuration  PEM  Lanes  Typical [SLI_CPL]
+                                                            --------------------------------------------
+                                                            1 8-ln PEM     n    8             0x20
+                                                            2 4-ln PEMs    n    4             0x10
+                                                                          n+1   4             0x10
+                                                            1 4-ln PEM     n    4             0x20
+                                                            1 8-ln PEM,    n    8             0x15
+                                                            1 4-ln PEM    n+1   4             0x0B
+                                                         </pre> */
+	uint64_t sli_p                        : 8;  /**< TLP 8B credits for Posted TLPs in the SLI. Legal values are 0x24 to 0xFF. Pairs
+                                                         of PEMs share a single SLI interface. SPEM(0) and PEM(1) share one SLI interface,
+                                                         while PEM(2) and PEM(3) share the other. When both PEMs of a pair are
+                                                         configured, the sum of both PEMs' SLI_P fields must not exceed 0x100. The reset
+                                                         value for this register assumes the minimum (e.g. 4-lane) configuration. This
+                                                         ensures that for configurations where the total number of lanes for a pair of
+                                                         PEMs exceeds 8, the total allocated credits does not oversubscribe the SLI.
+                                                         For configurations other than two 4-lane PEMs connected to a single SLI port,
+                                                         software may safely reprogram this register (i.e. increase the value) to achieve
+                                                         optimal performance.  See the following table of example configurations of PEM
+                                                         pairs for recommended credit values.
+                                                         <pre>
+                                                            Configuration  PEM  Lanes  Typical [SLI_CPL]
+                                                            --------------------------------------------
+                                                            1 8-ln PEM     n    8             0xFF
+                                                            2 4-ln PEMs    n    4             0x80
+                                                                          n+1   4             0x80
+                                                            1 4-ln PEM     n    4             0xFF
+                                                            1 8-ln PEM,    n    8             0xAA
+                                                            1 4-ln PEM    n+1   4             0x55
+                                                         </pre> */
+#else
+	uint64_t sli_p                        : 8;
+	uint64_t sli_np                       : 8;
+	uint64_t sli_cpl                      : 8;
+	uint64_t pem_p                        : 8;
+	uint64_t pem_np                       : 8;
+	uint64_t pem_cpl                      : 8;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} s;
+	struct cvmx_spemx_tlp_credits_s       cn73xx;
+};
+typedef union cvmx_spemx_tlp_credits cvmx_spemx_tlp_credits_t;
+
+#endif
-- 
2.6.2

