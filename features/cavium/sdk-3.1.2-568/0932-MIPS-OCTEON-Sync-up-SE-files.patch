From b5aa07aacbec6774657c688803ae8548d7f43f01 Mon Sep 17 00:00:00 2001
From: Chandrakala Chavva <cchavva@caviumnetworks.com>
Date: Sun, 27 Jul 2014 18:05:50 -0700
Subject: [PATCH 932/974] MIPS: OCTEON: Sync-up SE files

Signed-off-by: Chandrakala Chavva <cchavva@caviumnetworks.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 .../mips/cavium-octeon/executive/cvmx-helper-agl.c |   7 +
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c | 473 ++++++++-----
 .../cavium-octeon/executive/cvmx-helper-board.c    | 406 ++++++++++-
 .../mips/cavium-octeon/executive/cvmx-helper-cfg.c |  79 ++-
 .../cavium-octeon/executive/cvmx-helper-xaui.c     |  73 +-
 arch/mips/cavium-octeon/executive/cvmx-helper.c    | 103 +--
 arch/mips/cavium-octeon/executive/cvmx-ila.c       |  42 +-
 arch/mips/cavium-octeon/executive/cvmx-lap.c       |   7 +-
 arch/mips/cavium-octeon/executive/cvmx-ocla.c      |  43 ++
 arch/mips/cavium-octeon/executive/cvmx-pcie.c      |  16 +-
 arch/mips/cavium-octeon/executive/cvmx-pki.c       |  22 +-
 arch/mips/include/asm/octeon/cvmx-app-init.h       |   4 +-
 arch/mips/include/asm/octeon/cvmx-bgxx-defs.h      |  21 +-
 arch/mips/include/asm/octeon/cvmx-dpi-defs.h       |  36 +-
 arch/mips/include/asm/octeon/cvmx-gserx-defs.h     | 772 +++++++++++++--------
 arch/mips/include/asm/octeon/cvmx-helper-bgx.h     |  19 +
 arch/mips/include/asm/octeon/cvmx-helper-board.h   |  38 +-
 arch/mips/include/asm/octeon/cvmx-helper-cfg.h     |  57 ++
 arch/mips/include/asm/octeon/cvmx-helper-util.h    |   3 +-
 arch/mips/include/asm/octeon/cvmx-helper-xaui.h    |  29 +-
 arch/mips/include/asm/octeon/cvmx-ila.h            |  11 +
 arch/mips/include/asm/octeon/cvmx-lmcx-defs.h      | 258 ++++---
 arch/mips/include/asm/octeon/cvmx-mio-defs.h       |  13 +-
 arch/mips/include/asm/octeon/cvmx-ocla.h           |   3 +
 arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h   |   2 +-
 arch/mips/include/asm/octeon/cvmx-pemx-defs.h      |  35 +-
 arch/mips/include/asm/octeon/cvmx-pki-defs.h       |  25 +-
 arch/mips/include/asm/octeon/cvmx-pko-defs.h       |  66 +-
 arch/mips/include/asm/octeon/cvmx-pow.h            | 211 +++++-
 arch/mips/include/asm/octeon/cvmx-qlm.h            |   3 +-
 arch/mips/include/asm/octeon/cvmx-sli-defs.h       | 112 ++-
 arch/mips/include/asm/octeon/cvmx-spemx-defs.h     |  16 +-
 .../mips/include/asm/octeon/cvmx-sriomaintx-defs.h |  35 +-
 arch/mips/include/asm/octeon/cvmx-sriox-defs.h     | 325 +--------
 arch/mips/include/asm/octeon/cvmx-uahcx-defs.h     |  10 +-
 arch/mips/include/asm/octeon/cvmx-xcv-defs.h       |   6 +-
 36 files changed, 2207 insertions(+), 1174 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c b/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
index 93e19ca..ca8ce63 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
@@ -140,11 +140,18 @@ int __cvmx_helper_agl_probe(int interface)
 
 
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
+		bool tx_enable_bypass;
+		int tx_delay;
 		agl_prtx_ctl.s.refclk_sel = 0;
 		agl_prtx_ctl.s.clkrx_set =
 			cvmx_helper_get_agl_rx_clock_skew(interface, port);
 		agl_prtx_ctl.s.clkrx_byp =
 			cvmx_helper_get_agl_rx_clock_delay_bypass(interface, port);
+		cvmx_helper_cfg_get_rgmii_tx_clk_delay(interface, port,
+						       &tx_enable_bypass,
+						       &tx_delay);
+		agl_prtx_ctl.s.clktx_byp = tx_enable_bypass;
+		agl_prtx_ctl.s.clktx_set = tx_delay;
 	}
 	cvmx_write_csr(CVMX_AGL_PRTX_CTL(port), agl_prtx_ctl.u64);
 	/* Force write out before wait */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
index 4ec8e31..ea7f815 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -163,6 +163,9 @@ static cvmx_helper_interface_mode_t cvmx_helper_bgx_get_mode(int xiface, int ind
 		else
 			return CVMX_HELPER_INTERFACE_MODE_XLAUI;
 		break;
+	case 5:
+		return CVMX_HELPER_INTERFACE_MODE_RGMII;
+		break;
 	default:
 		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
 		break;
@@ -187,6 +190,9 @@ void cvmx_helper_bgx_disable(int xipd_port)
 	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_0) || index)
 		cmr_config.s.enable = 0;
+	if (debug)
+		cvmx_dprintf("%s: Disabling tx and rx packets on xipd port 0x%x\n",
+			     __func__, xipd_port);
 	cmr_config.s.data_pkt_tx_en = 0;
 	cmr_config.s.data_pkt_rx_en = 0;
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
@@ -214,7 +220,14 @@ static int __cvmx_helper_bgx_rgmii_speed(cvmx_helper_link_info_t link_info)
 	xcv_ctl.u64 = cvmx_read_csr(CVMX_XCV_CTL);
 	do_credits = up && !xcv_reset.s.enable;
 
+	if (xcv_ctl.s.lpbk_int) {
+		xcv_reset.s.clkrst = 0;
+		cvmx_write_csr(CVMX_XCV_RESET, xcv_reset.u64);
+	}
+
 	if (up && (!xcv_reset.s.enable || (xcv_ctl.s.speed != speed))) {
+		if (debug)
+			cvmx_dprintf("%s: *** Enabling XCV block\n", __func__);
 		/* Enable the XCV block */
 		xcv_reset.u64 = cvmx_read_csr(CVMX_XCV_RESET);
 		xcv_reset.s.enable = 1;
@@ -226,11 +239,11 @@ static int __cvmx_helper_bgx_rgmii_speed(cvmx_helper_link_info_t link_info)
 		cvmx_write_csr(CVMX_XCV_CTL, xcv_ctl.u64);
 
 		/* Configure DLL - enable or bypass bypass */
+		/* TX no bypass, RX bypass */
 		dll_ctl.u64 = cvmx_read_csr(CVMX_XCV_DLL_CTL);
 		dll_ctl.s.clkrx_set = 0;
-		dll_ctl.s.clktx_set = 31;  /* FIXME */
 		dll_ctl.s.clkrx_byp = 1;
-		dll_ctl.s.clktx_byp = 1;
+		dll_ctl.s.clktx_byp = 0;
 		cvmx_write_csr(CVMX_XCV_DLL_CTL, dll_ctl.u64);
 
 		/* Enable */
@@ -241,6 +254,9 @@ static int __cvmx_helper_bgx_rgmii_speed(cvmx_helper_link_info_t link_info)
 		xcv_reset.s.dllrst = 0;
 		cvmx_write_csr(CVMX_XCV_RESET, xcv_reset.u64);
 
+		/* Delay deems to be need so XCV_DLL_CTL[CLK_SET] works */
+		cvmx_wait_usec(10);
+
 		comp_ctl.u64 = cvmx_read_csr(CVMX_XCV_COMP_CTL);
 		//comp_ctl.s.drv_pctl = 0;
 		//comp_ctl.s.drv_nctl = 0;
@@ -254,7 +270,7 @@ static int __cvmx_helper_bgx_rgmii_speed(cvmx_helper_link_info_t link_info)
 
 		/* setup the RXC */
 		xcv_reset.u64 = cvmx_read_csr(CVMX_XCV_RESET);
-		xcv_reset.s.clkrst = 1;
+		xcv_reset.s.clkrst = !xcv_ctl.s.lpbk_int;
 		cvmx_write_csr(CVMX_XCV_RESET, xcv_reset.u64);
 
 		/* datapaths come out of the reset
@@ -267,6 +283,11 @@ static int __cvmx_helper_bgx_rgmii_speed(cvmx_helper_link_info_t link_info)
 		xcv_reset.s.tx_dat_rst_n = 1;
 		xcv_reset.s.rx_dat_rst_n = 1;
 		cvmx_write_csr(CVMX_XCV_RESET, xcv_reset.u64);
+	} else if (debug) {
+		cvmx_dprintf("%s: *** Not enabling XCV\n", __func__);
+		cvmx_dprintf("  up: %s, xcv_reset.s.enable: %d, xcv_ctl.s.speed: %d, speed: %d\n",
+			     up ? "true" : "false", xcv_reset.s.enable,
+			     xcv_ctl.s.speed, speed);
 	}
 
 	/* enable the packet flow
@@ -281,6 +302,8 @@ static int __cvmx_helper_bgx_rgmii_speed(cvmx_helper_link_info_t link_info)
 
 	/* Full reset when link is down */
 	if (!up) {
+		if (debug)
+			cvmx_dprintf("%s: *** Disabling XCV reset\n", __func__);
 		/* wait 2*MTU in time */
 		cvmx_wait_usec(10000);
 		/* reset the world */
@@ -294,7 +317,7 @@ static int __cvmx_helper_bgx_rgmii_speed(cvmx_helper_link_info_t link_info)
 		cvmx_write_csr(CVMX_XCV_BATCH_CRD_RET, crd_ret.u64);
 	}
 
-	return link_info.s.speed;
+	return 0;
 }
 
 static void __cvmx_bgx_common_init_pknd(int xiface, int index)
@@ -339,36 +362,6 @@ static void __cvmx_bgx_common_init_pknd(int xiface, int index)
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_BP_ON(index, xi.interface), bgx_rx_bp_on.u64);
 }
 
-static void __cvmx_helper_bgx_adjust_index(int xiface, int *start, int *end)
-{
-	int qlm = cvmx_qlm_lmac(xiface, 0);
-	int num_ports = cvmx_helper_ports_on_interface(xiface);
-
-	if (OCTEON_IS_MODEL(OCTEON_CN73XX)) {
-		if (qlm <= 3) {
-			*start = 0;
-			*end = num_ports;
-		} else if (qlm == 5 || qlm == 6) {
-			cvmx_gserx_cfg_t gser1, gser2;
-			gser1.u64 = cvmx_read_csr(CVMX_GSERX_CFG(5));
-			gser2.u64 = cvmx_read_csr(CVMX_GSERX_CFG(6));
-			if (gser1.s.bgx && gser2.s.bgx) {
-				*start = 0;
-				*end = num_ports;
-			} else if (gser1.s.bgx) {
-				*start = 0;
-				*end = 2;
-			} else if (gser2.s.bgx) {
-				*start = 2;
-				*end = num_ports;
-			}
-		}
-	} else {
-		*start = 0;
-		*end = num_ports;
-	}
-}
-
 /**
  * @INTERNAL
  * Probe a SGMII interface and determine the number of ports
@@ -481,18 +474,20 @@ static int __cvmx_helper_bgx_sgmii_hardware_init(int xiface, int num_ports)
 {
 	int index;
 	int do_link_set = 1;
-	int start, end;
-
-	__cvmx_helper_bgx_adjust_index(xiface, &start, &end);
 
-	for (index = start; index < end; index++) {
+	for (index = 0; index < num_ports; index++) {
 		int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
+		cvmx_helper_interface_mode_t mode;
 
 		if (!cvmx_helper_is_port_valid(xiface, index))
 			continue;
 
 		__cvmx_helper_bgx_port_init(xipd_port, 0);
 
+		mode = cvmx_helper_bgx_get_mode(xiface, index);
+		if (mode == CVMX_HELPER_INTERFACE_MODE_RGMII)
+			continue;
+
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 		/*
 		 * Linux kernel driver will call ....link_set with the
@@ -546,6 +541,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
 {
 	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+	cvmx_bgxx_cmrx_config_t cmr_config;
 	int phy_mode, mode_1000x;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
@@ -573,11 +569,13 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
 		}
 	}
 
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+
 	/* Write GMP_PCS_MR*_CONTROL[RST_AN]=1 to ensure a fresh SGMII
 	   negotiation starts. */
 	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
 	gmp_control.s.rst_an = 1;
-	gmp_control.s.an_en = 1;
+	gmp_control.s.an_en = (cmr_config.s.lmac_type != 5);
 	gmp_control.s.pwr_dn = 0;
 	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface),
 		       gmp_control.u64);
@@ -601,6 +599,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
 	   ethernet link, but a link between OCTEON and PHY. */
 
 	if ((cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) &&
+	    (cmr_config.s.lmac_type != 5) &&
 	     CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_STATUS(index, xi.interface),
 				   cvmx_bgxx_gmp_pcs_mrx_status_t, an_cpt,
 				   ==, 1, 10000)) {
@@ -719,21 +718,26 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int xiface,
 		       gmp_miscx_ctl.u64);
 
 	/* Write the new GMX settings with the port still disabled */
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface), gmp_prtx_cfg.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface),
+			    gmp_prtx_cfg.u64);
 
 	/* Read GMX CFG again to make sure the config completed */
 	cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface));
 
 	/* Restore the enabled/disabled state */
 	/* bgx-22429 */
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	cmr_config.u64 = cvmx_read_csr_node(node,
+					    CVMX_BGXX_CMRX_CONFIG(index,
+								  xi.interface));
 	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X) || index)
 		cmr_config.s.enable = is_enabled;
-#ifndef CVMX_BUILD_FOR_UBOOT
+	if (debug)
+		cvmx_dprintf("%s: Enabling tx and rx packets on %d:%d\n",
+			     __func__, xi.interface, index);
 	cmr_config.s.data_pkt_tx_en = 1;
 	cmr_config.s.data_pkt_rx_en = 1;
-#endif
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface),
+			    cmr_config.u64);
 
 	return 0;
 }
@@ -778,7 +782,9 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 		return result;
 	}
 
-	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
+	gmp_control.u64 = cvmx_read_csr_node(node,
+					     CVMX_BGXX_GMP_PCS_MRX_CONTROL(index,
+									   xi.interface));
 	if (gmp_control.s.loopbck1) {
 		int qlm = cvmx_qlm_lmac(xiface, index);
 		int speed;
@@ -793,7 +799,9 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 		return result;
 	}
 
-	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node,
+					      CVMX_BGXX_GMP_PCS_MISCX_CTL(index,
+									  xi.interface));
 	if (gmp_misc_ctl.s.mac_phy ||
 	    cvmx_helper_get_port_force_link_up(xiface, index)) {
 		int qlm = cvmx_qlm_lmac(xiface, index);
@@ -816,6 +824,15 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 	return result;
 }
 
+/**
+ * This works around an errata where disabling LMAC 0 resets the RX_FIFO read
+ * pointers for all LMACs.  This only affects CN78XX pass 1.0 and 1.1.
+ *
+ * @param xipd_port	ipd port number
+ * @param link_up	1 if link isup, 0 if link down
+ *
+ * @return	0 for success, -1 on error
+ */
 int cvmx_helper_bgx_errata_22429(int xipd_port, int link_up)
 {
 	cvmx_bgxx_cmrx_config_t cmr_config;
@@ -853,6 +870,98 @@ int cvmx_helper_bgx_errata_22429(int xipd_port, int link_up)
 }
 
 /**
+ * This sequence brings down the link for the XCV RGMII interface
+ *
+ * @param interface	Interface (BGX) number.  Port index is always 0
+ */
+static void __cvmx_helper_bgx_rgmii_link_set_down(int interface)
+{
+	union cvmx_xcv_reset xcv_reset;
+	union cvmx_bgxx_cmrx_config cmr_config;
+	union cvmx_bgxx_gmp_pcs_mrx_control mr_control;
+	union cvmx_bgxx_cmrx_rx_fifo_len rx_fifo_len;
+	union cvmx_bgxx_cmrx_tx_fifo_len tx_fifo_len;
+
+	xcv_reset.u64 = cvmx_read_csr(CVMX_XCV_RESET);
+	xcv_reset.s.rx_pkt_rst_n = 0;
+	cvmx_write_csr(CVMX_XCV_RESET, xcv_reset.u64);
+	cvmx_read_csr(CVMX_XCV_RESET);
+	cvmx_wait_usec(10000);	/* Wait for 1 MTU */
+
+	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(0, interface));
+	cmr_config.s.data_pkt_rx_en = 0;
+	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(0, interface), cmr_config.u64);
+
+	/* Wait for RX and TX to be idle */
+	do {
+		rx_fifo_len.u64 =
+			cvmx_read_csr(CVMX_BGXX_CMRX_RX_FIFO_LEN(0, interface));
+		tx_fifo_len.u64 =
+			cvmx_read_csr(CVMX_BGXX_CMRX_TX_FIFO_LEN(0, interface));
+	} while (rx_fifo_len.s.fifo_len > 0 && tx_fifo_len.s.lmac_idle != 1);
+
+	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(0, interface));
+	cmr_config.s.data_pkt_tx_en = 0;
+	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(0, interface), cmr_config.u64);
+
+	xcv_reset.u64 = cvmx_read_csr(CVMX_XCV_RESET);
+	xcv_reset.s.tx_pkt_rst_n = 0;
+	cvmx_write_csr(CVMX_XCV_RESET, xcv_reset.u64);
+	mr_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(0, interface));
+	mr_control.s.pwr_dn = 1;
+	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(0, interface),
+		       mr_control.u64);
+
+	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(0, interface));
+	cmr_config.s.enable = 0;
+	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(0, interface), cmr_config.u64);
+}
+
+/**
+ * Sets a BGS SGMII link down.
+ *
+ * @param node	Octeon node number
+ * @param iface	BGX interface number
+ * @param index	BGX port index
+ */
+static void __cvmx_helper_bgx_sgmii_link_set_down(int node, int iface,
+						  int index)
+{
+	union cvmx_bgxx_gmp_pcs_miscx_ctl gmp_misc_ctl;
+	union cvmx_bgxx_gmp_pcs_mrx_control gmp_control;
+	union cvmx_bgxx_cmrx_config cmr_config;
+
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index,
+									iface));
+	cmr_config.s.data_pkt_tx_en = 0;
+	cmr_config.s.data_pkt_rx_en = 0;
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, iface),
+			    cmr_config.u64);
+
+	gmp_misc_ctl.u64 =
+		cvmx_read_csr_node(node,
+				   CVMX_BGXX_GMP_PCS_MISCX_CTL(index, iface));
+
+	/* Disable autonegotiation only when in MAC mode. */
+	if (gmp_misc_ctl.s.mac_phy == 0) {
+		gmp_control.u64 =
+			cvmx_read_csr_node(node,
+					   CVMX_BGXX_GMP_PCS_MRX_CONTROL(index,
+									 iface));
+		gmp_control.s.an_en = 0;
+		cvmx_write_csr_node(node,
+				    CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, iface),
+				    gmp_control.u64);
+	}
+
+	/* Use GMXENO to force the link down.  It will get reenabled later... */
+	gmp_misc_ctl.s.gmxeno = 1;
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, iface),
+		     gmp_misc_ctl.u64);
+	cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, iface));
+}
+
+/**
  * @INTERNAL
  * Configure an IPD/PKO port for the specified link state. This
  * function does not influence auto negotiation at the PHY level.
@@ -867,7 +976,7 @@ int cvmx_helper_bgx_errata_22429(int xipd_port, int link_up)
  * @return Zero on success, negative on failure
  */
 int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
-				 cvmx_helper_link_info_t link_info)
+				     cvmx_helper_link_info_t link_info)
 {
 	cvmx_bgxx_cmrx_config_t cmr_config;
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
@@ -875,6 +984,7 @@ int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
 	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
+	const int iface = xi.interface;
 	int rc = 0;
 
 	if (!cvmx_helper_is_port_valid(xiface, index))
@@ -888,41 +998,25 @@ int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 		cvmx_helper_bgx_errata_22429(xipd_port, link_info.s.link_up);
 	}
 
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index,
+									iface));
 	if (link_info.s.link_up) {
 		cmr_config.s.enable = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, iface),
+				    cmr_config.u64);
 		__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
-	} else {
-		cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
-		cmr_config.s.data_pkt_tx_en = 0;
-		cmr_config.s.data_pkt_rx_en = 0;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
-		gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
-
-		/* Disable autonegotiation only when MAC mode. */
-		if (gmp_misc_ctl.s.mac_phy == 0) {
-			cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
-
-			gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
-			gmp_control.s.an_en = 0;
-			cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface), gmp_control.u64);
-			cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
-		}
-		/*
-		 * Use GMXENO to force the link down it will get
-		 * reenabled later...
-		 */
-		gmp_misc_ctl.s.gmxeno = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface),
-			       gmp_misc_ctl.u64);
-		cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
-		if (index == 0 && cmr_config.s.lmac_type == 5)
-			__cvmx_helper_bgx_rgmii_speed(link_info);
+	} else if (cvmx_helper_bgx_is_rgmii(xi.interface, index)) {
+		if (debug)
+			cvmx_dprintf("%s: Bringing down XCV RGMII interface %d\n",
+				     __func__, xi.interface);
+		__cvmx_helper_bgx_rgmii_link_set_down(xi.interface);
+	} else { /* Link is down, not RGMII */
+		__cvmx_helper_bgx_sgmii_link_set_down(node, iface, index);
 		return 0;
 	}
-	rc = __cvmx_helper_bgx_sgmii_hardware_init_link_speed(xiface, index, link_info);
-	if (index == 0 && cmr_config.s.lmac_type == 5)
+	rc = __cvmx_helper_bgx_sgmii_hardware_init_link_speed(xiface, index,
+							      link_info);
+	if (cvmx_helper_bgx_is_rgmii(xiface, index))
 		rc = __cvmx_helper_bgx_rgmii_speed(link_info);
 
 	return rc;
@@ -968,9 +1062,6 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	    || mode == CVMX_HELPER_INTERFACE_MODE_40G_KR4)
 		use_auto_neg = 1;
 
-	if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X))
-		use_auto_neg = 0;
-
 	/* NOTE: This code was moved first, out of order compared to the HRM
 	   because the RESET causes all SPU registers to loose their value */
 	/* 4. Next, bring up the SMU/SPU and the BGX reconciliation layer logic: */
@@ -1033,7 +1124,8 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 
 		/* 4c. For 10GBASE-KR or 40GBASE-KR, enable link training by writing
 		     BGX(0..5)_SPU(0..3)_BR_PMD_CONTROL[TRAIN_EN] = 1. */
-		if (use_auto_neg) {
+
+		if (use_auto_neg && !OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
 			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LP_CUP(index, interface), 0);
 			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_CUP(index, interface), 0);
 			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_LD_REP(index, interface), 0);
@@ -1135,7 +1227,6 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	return 0;
 }
 
-#if 0
 static void __cvmx_bgx_start_training(int node, int unit, int index)
 {
 	cvmx_bgxx_spux_int_t spu_int;
@@ -1170,7 +1261,6 @@ static void __cvmx_bgx_start_training(int node, int unit, int index)
 	pmd_control.s.train_restart = 1;
 	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, unit), pmd_control.u64);
 }
-#endif
 
 static void __cvmx_bgx_restart_training(int node, int unit, int index)
 {
@@ -1211,8 +1301,6 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
-	int interface = xi.interface;
-	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_helper_interface_mode_t mode;
 
@@ -1224,7 +1312,8 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 
 	__cvmx_bgx_common_init_pknd(xiface, index);
 
-	if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII) {
+	if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII
+	    || mode == CVMX_HELPER_INTERFACE_MODE_RGMII) {
 		cvmx_bgxx_gmp_gmi_txx_thresh_t gmi_tx_thresh;
 		cvmx_bgxx_gmp_gmi_txx_append_t gmp_txx_append;
 		cvmx_bgxx_gmp_gmi_txx_sgmii_ctl_t gmp_sgmii_ctl;
@@ -1232,23 +1321,34 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 		/* Set TX Threshold */
 		gmi_tx_thresh.u64 = 0;
 		gmi_tx_thresh.s.cnt = 0x20;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_THRESH(index, xi.interface),
+		cvmx_write_csr_node(xi.node, CVMX_BGXX_GMP_GMI_TXX_THRESH(index, xi.interface),
 				    gmi_tx_thresh.u64);
 		__cvmx_helper_bgx_sgmii_hardware_init_one_time(xiface, index);
-		gmp_txx_append.u64 = cvmx_read_csr_node(node,
+		gmp_txx_append.u64 = cvmx_read_csr_node(xi.node,
 					CVMX_BGXX_GMP_GMI_TXX_APPEND(index, xi.interface));
-		gmp_sgmii_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, xi.interface));
+		gmp_sgmii_ctl.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, xi.interface));
 		gmp_sgmii_ctl.s.align = gmp_txx_append.s.preamble ? 0 : 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, xi.interface),
+		cvmx_write_csr_node(xi.node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, xi.interface),
 			    gmp_sgmii_ctl.u64);
-
+		if (mode == CVMX_HELPER_INTERFACE_MODE_RGMII) {
+			/* Disable XCV interface when initialized */
+			union cvmx_xcv_reset xcv_reset;
+			if (debug)
+				cvmx_dprintf("%s: Disabling RGMII XCV interface\n",
+					     __func__);
+			xcv_reset.u64 = cvmx_read_csr(CVMX_XCV_RESET);
+			xcv_reset.s.enable = 0;
+			xcv_reset.s.tx_pkt_rst_n = 0;
+			xcv_reset.s.rx_pkt_rst_n = 0;
+			cvmx_write_csr(CVMX_XCV_RESET, xcv_reset.u64);
+		}
 	} else {
 		int res;
 		cvmx_bgxx_smux_tx_thresh_t smu_tx_thresh;
 
 		res = __cvmx_helper_bgx_xaui_init(index, xiface);
 		if (res == -1) {
-			cvmx_dprintf("Failed to enable XAUI for %d:BGX(%d,%d)\n", node, interface, index);
+			/*cvmx_dprintf("Failed to enable XAUI for %d:BGX(%d,%d)\n", xi.node, xi.interface, index);*/
 			return res;
 		}
 
@@ -1257,16 +1357,16 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 		* big to adversly effect shaping.
 		*/
 		smu_tx_thresh.s.cnt = 0x100;
-		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_THRESH(index, xi.interface),
+		cvmx_write_csr_node(xi.node, CVMX_BGXX_SMUX_TX_THRESH(index, xi.interface),
 				    smu_tx_thresh.u64);
 		/* Set disparity for RXAUI interface as described in the
 		Marvell RXAUI Interface specification. */
 		if (mode == CVMX_HELPER_INTERFACE_MODE_RXAUI && phy_pres) {
 			cvmx_bgxx_spux_misc_control_t misc_control;
-			misc_control.u64 = cvmx_read_csr_node(node,
+			misc_control.u64 = cvmx_read_csr_node(xi.node,
 					CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface));
 			misc_control.s.intlv_rdisp = 1;
-			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface),
+			cvmx_write_csr_node(xi.node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface),
 					    misc_control.u64);
 		}
 	}
@@ -1308,15 +1408,31 @@ int __cvmx_helper_bgx_sgmii_configure_loopback(int xipd_port, int enable_interna
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	gmp_mrx_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
-	gmp_mrx_control.s.loopbck1 = enable_internal;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface), gmp_mrx_control.u64);
+	if (cvmx_helper_bgx_is_rgmii(xi.interface, index)) {
+		cvmx_xcv_ctl_t xcv_ctl;
+		cvmx_helper_link_info_t link_info;
 
-	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
-	gmp_misc_ctl.s.loopbck2 = enable_external;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface), gmp_misc_ctl.u64);
+		xcv_ctl.u64 = cvmx_read_csr(CVMX_XCV_CTL);
+		xcv_ctl.s.lpbk_int = enable_internal;
+		xcv_ctl.s.lpbk_ext = enable_external;
+		cvmx_write_csr(CVMX_XCV_CTL, xcv_ctl.u64);
+
+		/* Initialize link and speed */
+		__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
+		link_info = __cvmx_helper_bgx_sgmii_link_get(xipd_port);
+		__cvmx_helper_bgx_sgmii_hardware_init_link_speed(xiface, index, link_info);
+		__cvmx_helper_bgx_rgmii_speed(link_info);
+	} else {
+		gmp_mrx_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface));
+		gmp_mrx_control.s.loopbck1 = enable_internal;
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, xi.interface), gmp_mrx_control.u64);
+
+		gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface));
+		gmp_misc_ctl.s.loopbck2 = enable_external;
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, xi.interface), gmp_misc_ctl.u64);
+		__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
+	}
 
-	__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
 
 	return 0;
 }
@@ -1339,8 +1455,7 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(0, xi.interface));
-	rgmii_first = (cmr_config.s.lmac_type == 5);
+	rgmii_first = cvmx_helper_bgx_is_rgmii(interface, index);
 
 	mode = cvmx_helper_bgx_get_mode(xiface, index);
 	if (mode == CVMX_HELPER_INTERFACE_MODE_10G_KR
@@ -1357,25 +1472,51 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		cvmx_bgxx_spux_an_control_t spu_an_control;
 		cvmx_bgxx_spux_an_status_t spu_an_status;
+		cvmx_bgxx_spux_br_pmd_control_t pmd_control;
 
 		spu_an_control.u64 = cvmx_read_csr_node(node,
 					CVMX_BGXX_SPUX_AN_CONTROL(index, interface));
 		if (spu_an_control.s.an_en) {
-			spu_an_status.u64 = cvmx_read_csr_node(node,
+			if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
+				cvmx_bgxx_spux_int_t spu_int;
+				spu_int.u64 = cvmx_read_csr_node(node,
+						CVMX_BGXX_SPUX_INT(index, interface));
+				if (!spu_int.s.an_link_good) {
+					/* Clear the auto negotiation (W1C) */
+					spu_int.u64 = 0;
+					spu_int.s.an_complete = 1;
+					spu_int.s.an_link_good = 1;
+					spu_int.s.an_page_rx = 1;
+					cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, interface), spu_int.u64);
+					/* Restart auto negotiation */
+					spu_an_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, interface));
+					spu_an_control.s.an_restart = 1;
+					cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, interface), spu_an_control.u64);
+					return -1;
+				}
+			} else {
+				spu_an_status.u64 = cvmx_read_csr_node(node,
 						CVMX_BGXX_SPUX_AN_STATUS(index, interface));
-			if (!spu_an_status.s.an_complete) {
-				/* Restart auto negotiation */
-				spu_an_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, interface));
-				spu_an_control.s.an_restart = 1;
-				cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, interface), spu_an_control.u64);
-				return -1;
+				if (!spu_an_status.s.an_complete) {
+					/* Restart auto negotiation */
+					spu_an_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, interface));
+					spu_an_control.s.an_restart = 1;
+					cvmx_write_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, interface), spu_an_control.u64);
+					return -1;
+				}
 			}
 		}
 
 		if (use_training) {
 			spu_int.u64 = cvmx_read_csr_node(node,
 						  CVMX_BGXX_SPUX_INT(index, interface));
-			if (spu_int.s.training_failure) {
+			pmd_control.u64 = cvmx_read_csr_node(node,
+						CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface));
+			if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)
+			    && pmd_control.s.train_en == 0) {
+				__cvmx_bgx_start_training(node, interface, index);
+				return -1;
+			} else if (spu_int.s.training_failure) {
 				__cvmx_bgx_restart_training(node, interface, index);
 				return -1;
 			}
@@ -1429,7 +1570,6 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 			return -1;
 		}
 
-
 		if (mode == CVMX_HELPER_INTERFACE_MODE_XFI
 		    || mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
 		    || mode == CVMX_HELPER_INTERFACE_MODE_10G_KR
@@ -1458,6 +1598,10 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 		if (spu_status2.s.rcvflt) {
 			cvmx_dprintf("ERROR: %d:BGX%d:%d: Receive fault, need to retry\n",
 					node, interface, index);
+			if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X) && use_training)
+				__cvmx_bgx_restart_training(node, interface, index);
+			/* cvmx_dprintf("training restarting\n"); */
+			return -1;
 		}
 
 		/* Wait for MAC RX to be ready */
@@ -1505,10 +1649,13 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 	spu_misc_control.s.rx_packet_dis = 0;
 	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, xi.interface), spu_misc_control.u64);
 
+	if (debug)
+		cvmx_dprintf("%s: Enabling tx and rx data packets\n", __func__);
 	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 	cmr_config.s.data_pkt_tx_en = 1;
 	cmr_config.s.data_pkt_rx_en = 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface),
+			    cmr_config.u64);
 
 	return 0;
 }
@@ -1516,15 +1663,10 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 int __cvmx_helper_bgx_xaui_enable(int xiface)
 {
 	int index;
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	int interface = xi.interface;
-	int node = xi.node;
 	cvmx_helper_interface_mode_t mode;
-	int start = 0, end = 0;
-
-	__cvmx_helper_bgx_adjust_index(xiface, &start, &end);
+	int num_ports = cvmx_helper_ports_on_interface(xiface);
 
-	for (index = start; index < end; index++) {
+	for (index = 0; index < num_ports; index++) {
 		int res;
 		int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
 		int phy_pres;
@@ -1542,7 +1684,10 @@ int __cvmx_helper_bgx_xaui_enable(int xiface)
 
 		res = __cvmx_helper_bgx_xaui_link_init(index, xiface);
 		if (res == -1) {
-			cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", node, interface, index);
+			if (debug) {
+				struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+				cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", xi.node, xi.interface, index);
+			}
 			continue;
 		}
 	}
@@ -1554,8 +1699,6 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
-	int interface = xi.interface;
-	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_bgxx_spux_status1_t spu_status1;
 	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
@@ -1569,9 +1712,9 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 		cvmx_dprintf("%s: interface %u:%d/%d\n",
 		__func__, xi.node, xi.interface, index);
 
-	spu_status1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_STATUS1(index, xi.interface));
-	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, xi.interface));
-	smu_rx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(index, xi.interface));
+	spu_status1.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_SPUX_STATUS1(index, xi.interface));
+	smu_tx_ctl.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_SMUX_TX_CTL(index, xi.interface));
+	smu_rx_ctl.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_SMUX_RX_CTL(index, xi.interface));
 
 	if ((smu_tx_ctl.s.ls == 0)     &&
 	    (smu_rx_ctl.s.status == 0) &&
@@ -1582,11 +1725,11 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 		result.s.link_up = 1;
 		result.s.full_duplex = 1;
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-			speed = cvmx_qlm_get_gbaud_mhz_node(node, qlm);
+			speed = cvmx_qlm_get_gbaud_mhz_node(xi.node, qlm);
 		else
 			speed = cvmx_qlm_get_gbaud_mhz(qlm);
 
-		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+		cmr_config.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
 		switch(cmr_config.s.lmac_type) {
 		default:
 		case 1:  // XAUI
@@ -1616,7 +1759,8 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 		int res;
 		res = __cvmx_helper_bgx_xaui_link_init(index, xiface);
 		if (res == -1) {
-			cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", node, interface, index);
+			if (debug)
+				cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", xi.node, xi.interface, index);
 			return result;
 		}
 	}
@@ -1688,9 +1832,6 @@ int __cvmx_helper_bgx_mixed_enable(int xiface)
 {
 	int index;
 	int num_ports = cvmx_helper_ports_on_interface(xiface);
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	int interface = xi.interface;
-	int node = xi.node;
 	cvmx_helper_interface_mode_t mode;
 
 	for (index = 0; index < num_ports; index++) {
@@ -1710,8 +1851,11 @@ int __cvmx_helper_bgx_mixed_enable(int xiface)
 		if (__cvmx_helper_bgx_port_init(xipd_port, phy_pres))
 			continue;
 
-		/* Call SGMII init code for lmac_type = 0 */
-		if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII) {
+		/* For RGMII interface, initialize the link after PKO is setup */
+		if (mode == CVMX_HELPER_INTERFACE_MODE_RGMII)
+			continue;
+		/* Call SGMII init code for lmac_type = 0|5 */
+		else if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII) {
 			int do_link_set = 1;
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 			if (!(cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM))
@@ -1724,7 +1868,10 @@ int __cvmx_helper_bgx_mixed_enable(int xiface)
 		/* All other lmac type call XAUI init code */
 		} else {
 			if (__cvmx_helper_bgx_xaui_link_init(index, xiface)) {
-				cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", node, interface, index);
+				if (debug) {
+					struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+					cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", xi.node, xi.interface, index);
+				}
 				continue;
 			}
 		}
@@ -1734,13 +1881,13 @@ int __cvmx_helper_bgx_mixed_enable(int xiface)
 
 cvmx_helper_link_info_t __cvmx_helper_bgx_mixed_link_get(int xipd_port)
 {
-	cvmx_bgxx_cmrx_config_t cmr_config;
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int index = cvmx_helper_get_interface_index_num(xipd_port);
+	cvmx_helper_interface_mode_t mode;
 
-	cmr_config.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
-	if (cmr_config.s.lmac_type == 0)
+	mode = cvmx_helper_bgx_get_mode(xiface, index);
+	if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII
+	    || mode == CVMX_HELPER_INTERFACE_MODE_RGMII)
 		return __cvmx_helper_bgx_sgmii_link_get(xipd_port);
 	else
 		return __cvmx_helper_bgx_xaui_link_get(xipd_port);
@@ -1748,13 +1895,13 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_mixed_link_get(int xipd_port)
 
 int __cvmx_helper_bgx_mixed_link_set(int xipd_port, cvmx_helper_link_info_t link_info)
 {
-	cvmx_bgxx_cmrx_config_t cmr_config;
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int index = cvmx_helper_get_interface_index_num(xipd_port);
+	cvmx_helper_interface_mode_t mode;
 
-	cmr_config.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
-	if (cmr_config.s.lmac_type == 0)
+	mode = cvmx_helper_bgx_get_mode(xiface, index);
+	if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII
+	    || mode == CVMX_HELPER_INTERFACE_MODE_RGMII)
 		return __cvmx_helper_bgx_sgmii_link_set(xipd_port, link_info);
 	else
 		return __cvmx_helper_bgx_xaui_link_set(xipd_port, link_info);
@@ -1764,13 +1911,13 @@ int __cvmx_helper_bgx_mixed_configure_loopback(int xipd_port,
 						     int enable_internal,
 						     int enable_external)
 {
-	cvmx_bgxx_cmrx_config_t cmr_config;
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int index = cvmx_helper_get_interface_index_num(xipd_port);
+	cvmx_helper_interface_mode_t mode;
 
-	cmr_config.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
-	if (cmr_config.s.lmac_type == 0)
+	mode = cvmx_helper_bgx_get_mode(xiface, index);
+	if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII
+	    || mode == CVMX_HELPER_INTERFACE_MODE_RGMII)
 		return __cvmx_helper_bgx_sgmii_configure_loopback(xipd_port,
 						enable_internal, enable_external);
 	else
@@ -1898,8 +2045,10 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 		return;
 
 	if (debug)
-		cvmx_dprintf("%s: interface %u:%d/%d\n",
-		__func__, xi.node, xi.interface, index);
+		cvmx_dprintf("%s: interface %u:%d/%d, fcs: %s, pad: %s\n",
+			     __func__, xi.node, xi.interface, index,
+			     fcs_enable ? "true" : "false",
+			     pad_enable ? "true" : "false");
 
 	cmr_config.u64 = cvmx_read_csr_node(node,
 		CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
@@ -2054,8 +2203,8 @@ void cvmx_helper_bgx_set_jabber(int xiface, unsigned index,
 	unsigned size)
 {
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	cvmx_bgxx_cmrx_config_t cmr_config;
 	int node;
+	cvmx_helper_interface_mode_t mode;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_BGX))
 		return;
@@ -2065,12 +2214,11 @@ void cvmx_helper_bgx_set_jabber(int xiface, unsigned index,
 
 	node = xi.node;
 
-	/* Get LMAC type from common config */
-	cmr_config.u64 = cvmx_read_csr_node(node,
-		CVMX_BGXX_CMRX_CONFIG(index, xi.interface));
+	mode = cvmx_helper_bgx_get_mode(xiface, index);
 
 	/* Set GMI or SMUX register based on lmac_type */
-	if (cmr_config.s.lmac_type == 0) {
+	if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII
+	    || mode == CVMX_HELPER_INTERFACE_MODE_RGMII) {
 		cvmx_write_csr_node(node,
 				CVMX_BGXX_GMP_GMI_RXX_JABBER(index, xi.interface), size);
 	} else {
@@ -2112,7 +2260,8 @@ int cvmx_helper_bgx_shutdown_port(int xiface, int index)
 	/* Clear pending common interrupts */
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_INT(index, xi.interface), 0x7);
 
-	if (cmr_config.s.lmac_type == 0) {	/* SGMII */
+	if (cmr_config.s.lmac_type == 0
+	    || cmr_config.s.lmac_type == 5) {	/* SGMII */
 		/* Clear GMP interrupts */
 		cvmx_write_csr_node(node,
 			CVMX_BGXX_GMP_GMI_RXX_INT(index, xi.interface), 0xfff);
@@ -2133,6 +2282,7 @@ int cvmx_helper_bgx_shutdown_port(int xiface, int index)
 		/* Read GMX CFG again to make sure the disable completed */
 		cvmx_read_csr_node(node,
 			CVMX_BGXX_GMP_GMI_PRTX_CFG(index, xi.interface));
+		/* FIXME Disable RGMII interface */
 	} else {		/* XAUI/XFI/10-KR */
 		/* Clear all pending SMUX interrupts */
 		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_INT(index, xi.interface),
@@ -2357,13 +2507,13 @@ do {									\
  * SGMII or 1000BASE-X type and skip XFI LMAC)
  */
 /* The following funcs are implemented in this section */
-const char * get_lmac_type_name(uint8_t lmac_type, uint8_t pcs_misc_ctl_mode);
+const char *get_lmac_type_name(uint8_t lmac_type, uint8_t pcs_misc_ctl_mode);
 int get_num_pcs_lanes(uint8_t lmac_type);
-const char * get_bind_lanes_per_lmac(uint8_t ind, uint8_t lmac_type, uint8_t lane_to_sds);
+const char *get_bind_lanes_per_lmac(uint8_t ind, uint8_t lmac_type, uint8_t lane_to_sds);
 int cvmx_helper_bgx_link_status(int node, int bgx, unsigned N);
 
 /* return name of interface type ("SGMII", "XAUI", etc. */
-const char * get_lmac_type_name(uint8_t lmac_type, uint8_t pcs_misc_ctl_mode)
+const char *get_lmac_type_name(uint8_t lmac_type, uint8_t pcs_misc_ctl_mode)
 {
 	static char *lmac_types[] = {
 		"  SGMII   ",
@@ -2397,7 +2547,8 @@ int get_num_pcs_lanes(uint8_t lmac_type)
 /* return SerDes lanes connected to lmac - string (up to 7 chars '0,1,2,3')
  * or up to 9 chars "RGMII/XCV" for RGMII(lmac_type=5)
  */
-const char * get_bind_lanes_per_lmac(uint8_t ind, uint8_t lmac_type, uint8_t lane_to_sds)
+const char *get_bind_lanes_per_lmac(uint8_t ind, uint8_t lmac_type,
+				     uint8_t lane_to_sds)
 {
 	static char tmp[4][9], bind_lanes_per_lmac[4][9];
 	uint8_t i, n;
@@ -2409,7 +2560,7 @@ const char * get_bind_lanes_per_lmac(uint8_t ind, uint8_t lmac_type, uint8_t lan
 	if (ind == 0 && lmac_type == 5/*RGMII*/)
 		return "RGMII/XCV";	/* Only LMAC0 can connect to RGMII/XCV */
 	bind_lanes_per_lmac[ind][0] = 0;
-	for (i=0; i < get_num_pcs_lanes(lmac_type); i++) {
+	for (i = 0; i < get_num_pcs_lanes(lmac_type); i++) {
 		sprintf(tmp[ind], ",%1d", (lane_to_sds >> (/*2*i*/i<<1)) & 3);
 		strcat( bind_lanes_per_lmac[ind], tmp[ind]);
 	}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
index 7bfee97..a2001b8 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
@@ -73,6 +73,7 @@
 #include "cvmx-bootmem.h"
 
 #ifdef __U_BOOT__
+# include <malloc.h>
 # include "cvmx-helper-fdt.h"
 #else
 # include "libfdt/cvmx-helper-fdt.h"
@@ -759,6 +760,265 @@ int __cvmx_helper_78xx_parse_phy(struct cvmx_phy_info *phy_info, int ipd_port)
 	return 0;
 }
 
+void cvmx_rx_activity_led(int xiface, int index)
+{
+
+}
+
+/**
+ * Wrapper to allocate the LED data structure for SE, Linux and U-Boot
+ *
+ * @param[in]	leds	Pointer to LED data structure (checks if NULL to allocate)
+ *
+ * @return	pointer to existing LED data structure or to new LED data
+ *		structure or NULL if out of memory.
+ */
+static struct cvmx_phy_gpio_leds *__alloc_leds(struct cvmx_phy_gpio_leds *leds)
+{
+	if (leds)
+		return leds;
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+	leds = (struct cvmx_phy_gpio_leds *)kmalloc(sizeof(*leds), GFP_KERNEL);
+#elif defined(__U_BOOT__)
+	leds = (struct cvmx_phy_gpio_leds *)malloc(sizeof(*leds));
+#else
+	leds = (struct cvmx_phy_gpio_leds *)cvmx_bootmem_alloc(sizeof(*leds), 0);
+#endif
+	if (leds) {
+		memset(leds, 0, sizeof(*leds));
+		leds->error_gpio = -1;
+		leds->link_status_gpio = -1;
+		leds->rx_activity_gpio = -1;
+		leds->tx_activity_gpio = -1;
+		leds->error_gpio = -1;
+		leds->rx_gpio_timer = -1;
+		leds->tx_gpio_timer = -1;
+		leds->link_poll_interval_ms = 1000;
+		leds->activity_poll_interval_ms = 250;
+	} else {
+		cvmx_dprintf("%s: Out of memory!\n", __func__);
+	}
+	return leds;
+}
+
+/**
+ * Wrapper to free LED data structure
+ *
+ * @param[in]	leds	pointer to free
+ */
+static inline void __free_leds(struct cvmx_phy_gpio_leds *leds)
+{
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+	if (!leds)
+		return;
+	kfree(leds);
+#elif defined(__U_BOOT__)
+	free(leds);
+#endif
+}
+
+/**
+ * Gets all of the LED information for the specified LED
+ *
+ * @param[in]	fdt_addr	FDT address
+ * @param	led_node	led node offset in device tree
+ * @param[out]	active_low	set true if LED is active low
+ * @param[out]	cpu_node	CPU node number GPIO is attached to
+ * @param[out]	gpio		GPIO pin number
+ *
+ * @return	0 for success, -1 on error
+ */
+static int __get_led_gpio(void *fdt_addr, int led_node,
+			  bool *active_low, int *cpu_node, int *gpio)
+{
+	int parent_node;
+	int gpio_node;
+	const int *val;
+	int len = 0;
+
+	parent_node = fdt_parent_offset(fdt_addr, led_node);
+	if (parent_node < 0) {
+		cvmx_dprintf("%s: Invalid parent node\n", __func__);
+		return -1;
+	}
+	if (fdt_node_check_compatible(fdt_addr, parent_node, "gpio-leds")) {
+		cvmx_dprintf("%s: LEDs not compatible\n", __func__);
+		return -1;
+	}
+
+	val = fdt_getprop(fdt_addr, led_node, "gpios", &len);
+	if (len < (int)(3 * sizeof(int))) {
+		cvmx_dprintf("%s Invalid GPIO in device tree for LED\n", __func__);
+	}
+	gpio_node = fdt_node_offset_by_phandle(fdt_addr, val[0]);
+	if (gpio_node < 0) {
+		cvmx_dprintf("%s: Invalid GPIO phandle\n", __func__);
+		return -1;
+	}
+	if (fdt_node_check_compatible(fdt_addr, gpio_node,
+				      "cavium,octeon-3860-gpio") &&
+	    fdt_node_check_compatible(fdt_addr, gpio_node,
+				      "cavium,octeon-7890-gpio")) {
+		cvmx_dprintf("%s: Error: Only native OCTEON GPIOs can be used for network LEDs\n",
+			     __func__);
+		return -1;
+	}
+	*gpio = fdt32_to_cpu(val[1]);
+	*active_low = !!(fdt32_to_cpu(val[2]) & 1);
+	*cpu_node = cvmx_fdt_get_cpu_node(fdt_addr, gpio_node);
+	if (*cpu_node < 0) {
+		cvmx_dprintf("%s: Could not get GPIO CPU node number\n",
+			     __func__);
+		return -1;
+	}
+	if (device_tree_dbg)
+		cvmx_dprintf("Parsed LED label %s, CPU node: %d, GPIO pin %d, active %s\n",
+			     (char *)fdt_getprop(fdt_addr, led_node, "label",
+						 NULL),
+			     *cpu_node, *gpio, *active_low ? "low" : "high");
+
+	return 0;
+}
+
+/**
+ * Parses an Ethernet port for LEDs hooked up to GPIO pins
+ *
+ * @param[in]	fdt_addr	Address of flat device tree
+ * @param	port_node	FDT node offset for the port
+ *
+ * @return	Pointer to LED data structure or NULL if error or if LEDs are
+ *		not used.
+ */
+struct cvmx_phy_gpio_leds *
+__cvmx_helper_parse_gpio_leds(void *fdt_addr, int port_node)
+{
+	struct cvmx_phy_gpio_leds *leds = NULL;
+	int led_node;
+	int cpu_node = 0;
+	int def_timer = 3;
+
+	/* Get link status LED */
+	led_node = cvmx_fdt_lookup_phandle(fdt_addr, port_node,
+					   "cavium,link-status-led");
+	if (led_node >= 0) {
+		leds = __alloc_leds(leds);
+		if (!leds)
+			return NULL;
+		if (__get_led_gpio(fdt_addr, led_node,
+				   &leds->link_status_active_low, &cpu_node,
+				   &leds->link_status_gpio)) {
+			cvmx_dprintf("%s: Error getting link status LED\n",
+				     __func__);
+			__free_leds(leds);
+			return NULL;
+		}
+	}
+
+	/* Get RX activity LED */
+	led_node = cvmx_fdt_lookup_phandle(fdt_addr, port_node,
+					   "cavium,rx-activity-led");
+	if (led_node >= 0) {
+		leds = __alloc_leds(leds);
+		if (!leds)
+			return NULL;
+		if (__get_led_gpio(fdt_addr, led_node,
+				   &leds->rx_activity_active_low, &cpu_node,
+				   &leds->rx_activity_gpio)) {
+			cvmx_dprintf("%s: Error getting RX activity LED\n",
+				     __func__);
+			__free_leds(leds);
+			return NULL;
+		}
+		leds->rx_activity_gpio |= (cpu_node << 8);
+		leds->rx_activity_hz = cvmx_fdt_get_int(fdt_addr, port_node,
+							"cavium,rx-activity-blink-rate",
+							0);
+		leds->rx_gpio_timer = cvmx_fdt_get_int(fdt_addr, port_node,
+						       "cavium,rx-timer", 3);
+		if (leds->rx_gpio_timer > 3 || leds->rx_gpio_timer < 0) {
+			cvmx_printf("Error: RX GPIO timer in device tree is out of range!  Must be 0..3\n");
+			leds->rx_gpio_timer = 3;
+		}
+	}
+
+	/* Get TX activity LED */
+	led_node = cvmx_fdt_lookup_phandle(fdt_addr, port_node,
+					   "cavium,tx-activity-led");
+	if (led_node >= 0) {
+		leds = __alloc_leds(leds);
+		if (!leds)
+			return NULL;
+		if (__get_led_gpio(fdt_addr, led_node,
+				   &leds->tx_activity_active_low, &cpu_node,
+				   &leds->tx_activity_gpio)) {
+			cvmx_dprintf("%s: Error getting TX activity LED\n",
+				     __func__);
+			__free_leds(leds);
+			return NULL;
+		}
+		leds->tx_activity_gpio |= (cpu_node << 8);
+		leds->tx_activity_hz = cvmx_fdt_get_int(fdt_addr, port_node,
+							"cavium,tx-activity-blink-rate",
+							0);
+		if ((leds->tx_activity_hz == leds->rx_activity_hz) ||
+		    leds->rx_activity_hz == 0)
+			def_timer = 3;
+		else
+			def_timer = 2;
+		leds->tx_gpio_timer = cvmx_fdt_get_int(fdt_addr, port_node,
+						       "cavium,tx-timer",
+						       def_timer);
+		if (leds->tx_gpio_timer > 3 || leds->tx_gpio_timer < 0) {
+			cvmx_printf("Error: TX GPIO timer in device tree is out of range!  Must be 0..3\n");
+			leds->tx_gpio_timer = 3;
+		}
+	}
+
+	/* Get Error LED */
+	led_node = cvmx_fdt_lookup_phandle(fdt_addr, port_node,
+					   "cavium,error-led");
+	if (led_node >= 0) {
+		leds = __alloc_leds(leds);
+		if (!leds)
+			return NULL;
+		if (__get_led_gpio(fdt_addr, led_node,
+				   &leds->error_active_low, &cpu_node,
+				   &leds->error_gpio)) {
+			cvmx_dprintf("%s: Error getting TX activity LED\n",
+				     __func__);
+			__free_leds(leds);
+			return NULL;
+		}
+		leds->error_gpio |= (cpu_node << 8);
+	}
+	if (leds) {
+		if (leds->rx_activity_hz > 0 && leds->rx_gpio_timer >= 0)
+			/* Set the GPIO frequency and select the timer used */
+			cvmx_gpio_set_freq(leds->rx_activity_gpio >> 8,
+					   leds->rx_gpio_timer,
+					   leds->rx_activity_hz);
+
+		/* It doesn't matter if it's the same timer as RX since it means
+		 * the values are the same anyway.
+		 */
+		if (leds->tx_activity_hz > 0 && leds->tx_gpio_timer >= 0)
+			cvmx_gpio_set_freq(leds->tx_activity_gpio >> 8,
+					   leds->tx_gpio_timer,
+					   leds->tx_activity_hz);
+
+		leds->link_poll_interval_ms =
+			cvmx_fdt_get_int(fdt_addr, port_node,
+					 "cavium,link-poll-interval-ms",
+					 leds->link_poll_interval_ms);
+		leds->activity_poll_interval_ms =
+			cvmx_fdt_get_int(fdt_addr, port_node,
+					 "cavium,activity-poll-interval-ms",
+					 leds->activity_poll_interval_ms);
+	}
+	return leds;
+}
+
 /**
  * @INTERNAL
  * Parse the device tree and set whether a port is valid or not.
@@ -777,6 +1037,7 @@ int __cvmx_helper_parse_bgx_dt(void *fdt_addr)
 	int fdt_phy_node;
 	uint64_t reg_addr;
 	int xiface;
+	struct cvmx_phy_gpio_leds *gpio_leds = NULL;
 
 	while ((fdt_port_node = fdt_node_offset_by_compatible(fdt_addr, fdt_port_node,
 					"cavium,octeon-7890-bgx-port")) >= 0) {
@@ -853,6 +1114,10 @@ int __cvmx_helper_parse_bgx_dt(void *fdt_addr)
 					     __func__, xiface, port_index, fdt_phy_node);
 			cvmx_helper_set_port_phy_present(xiface, port_index, false);
 		}
+		gpio_leds = __cvmx_helper_parse_gpio_leds(fdt_addr, fdt_port_node);
+		if (gpio_leds)
+			cvmx_helper_set_port_phy_leds(xiface, port_index,
+						      gpio_leds);
 	}
 	return 0;
 }
@@ -991,7 +1256,7 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 	cvmx_helper_interface_mode_t mode;
 	int xiface = cvmx_helper_get_interface_num(ipd_port);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	uint32_t *val;
+	uint32_t val;
 	int phy_node_offset;
 
 	if (octeon_has_feature(OCTEON_FEATURE_BGX)) {
@@ -1104,6 +1369,7 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 		cvmx_helper_set_port_autonegotiation(xiface, port_index, true);
 
 	if (mode == CVMX_HELPER_INTERFACE_MODE_AGL) {
+		bool tx_bypass = false;
 		if (fdt_getprop(fdt_addr, eth, "cavium,rx-clk-delay-bypass", NULL))
 			cvmx_helper_set_agl_rx_clock_delay_bypass(xiface,
 								  port_index,
@@ -1113,13 +1379,19 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 								  port_index,
 								  false);
 
-		val = (uint32_t *)fdt_getprop(fdt_addr, eth,
-					      "cavium,rx-clk-skew", NULL);
+		val = cvmx_fdt_get_int(fdt_addr, eth, "cavium,rx-clk-skew", 0);
+		cvmx_helper_set_agl_rx_clock_skew(xiface, port_index, val);
+
+		if (fdt_getprop(fdt_addr, eth,
+				"cavium,tx-clk-delay-bypass", NULL))
+			tx_bypass = true;
 
-		cvmx_helper_set_agl_rx_clock_skew(xiface, port_index,
-						  (val) ?
-						  fdt32_to_cpu(*val) : 0);
+		val = cvmx_fdt_get_int(fdt_addr, eth, "tx-clk-delay", 0);
+		cvmx_helper_cfg_set_rgmii_tx_clk_delay(xiface,
+						       port_index,
+						       tx_bypass, val);
 	}
+
 	return (eth >= 0);
 }
 
@@ -2350,6 +2622,103 @@ static int __switch_mdio_mux(const cvmx_phy_info_t *phy_info)
 
 /**
  * @INTERNAL
+ * Updates any GPIO link LEDs if present
+ *
+ * @param xiface	Interface number
+ * @param index		Port index
+ * @param result	Link status result
+ */
+void __cvmx_update_link_led(int xiface, int index,
+			    cvmx_helper_link_info_t result)
+{
+	struct cvmx_phy_gpio_leds *gpio_leds;
+	uint32_t mask;
+	int node;
+
+	/* Set link status LEDs if present */
+	gpio_leds = cvmx_helper_get_port_phy_leds(xiface, index);
+	if (gpio_leds && gpio_leds->link_status_gpio >= 0) {
+		node = gpio_leds->link_status_gpio >> 8;
+		mask = 1 << gpio_leds->link_status_gpio & 0xff;
+		if (result.s.link_up) {
+			if (gpio_leds->link_status_active_low)
+				cvmx_gpio_clear_node(node, mask);
+			else
+				cvmx_gpio_set_node(node, mask);
+		} else {
+			if (gpio_leds->link_status_active_low)
+				cvmx_gpio_set_node(node, mask);
+			else
+				cvmx_gpio_clear_node(node, mask);
+		}
+	}
+}
+
+/**
+ * Update the RX activity LED for the specified interface and port index
+ *
+ * @param xiface	Interface number
+ * @param index		Port index
+ * @param check_time	Check if the time has expired
+ */
+void cvmx_update_rx_activity_led(int xiface, int index, bool check_time)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	uint64_t rx_packets;
+	struct cvmx_phy_gpio_leds *leds = cvmx_helper_get_port_phy_leds(xiface,
+									index);
+	static uint64_t tm_interval;
+
+	if (!leds)
+		return;
+
+	if (check_time) {
+		uint64_t current_time;
+
+		if (!tm_interval)
+			tm_interval = leds->activity_poll_interval_ms * cvmx_clock_get_rate(CVMX_CLOCK_CORE) / 1000;
+		current_time = cvmx_clock_get_count(CVMX_CLOCK_CORE);
+
+		if (current_time < leds->last_activity_poll_time + tm_interval)
+			return;
+	}
+
+	if (octeon_has_feature(OCTEON_FEATURE_BGX)) {
+		rx_packets = cvmx_read_csr_node(xi.node,
+						CVMX_BGXX_CMRX_RX_STAT0(index,
+									xi.interface));
+	} else if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
+		int pknd = cvmx_helper_get_pknd(xi.interface, index);
+		rx_packets = cvmx_read_csr(CVMX_PIP_STAT_INB_PKTS_PKNDX(pknd));
+
+	} else {
+		int port_num = cvmx_helper_get_ipd_port(xiface, index);
+		rx_packets = cvmx_read_csr(CVMX_PIP_STAT_INB_PKTSX(port_num));
+	}
+
+	if (rx_packets != leds->last_rx_count) {
+		cvmx_gpio_set_node(leds->rx_activity_gpio >> 8,
+				   1 << (leds->rx_activity_gpio & 0xff));
+		cvmx_gpio_cfg_sel(leds->rx_activity_gpio >> 8,
+				  leds->rx_activity_gpio,
+				  0x10 + leds->rx_gpio_timer);
+		/*cvmx_gpio_set_node(leds->rx_activity_gpio >> 8,
+				   1 << (leds->rx_activity_gpio & 0xff));*/
+
+	} else {
+		cvmx_gpio_cfg_sel(leds->rx_activity_gpio >> 8,
+				  leds->rx_activity_gpio, 0);
+		cvmx_gpio_clear_node(leds->rx_activity_gpio >> 8,
+				     1 << (leds->rx_activity_gpio & 0xff));
+	}
+	leds->last_rx_count = rx_packets;
+	if (check_time)
+		leds->last_activity_poll_time =
+					cvmx_clock_get_count(CVMX_CLOCK_CORE);
+}
+
+/**
+ * @INTERNAL
  * This function is used ethernet ports link speed. This functions uses the
  * device tree information to determine the phy address and type of PHY.
  * The only supproted PHYs are Marvell and Broadcom.
@@ -2360,13 +2729,12 @@ static int __switch_mdio_mux(const cvmx_phy_info_t *phy_info)
  * @return The ports link status. If the link isn't fully resolved, this must
  *         return zero.
  */
-
 cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 {
 	cvmx_helper_link_info_t result;
 	cvmx_phy_info_t *phy_info = NULL;
 	cvmx_phy_info_t local_phy_info;
-	int xiface, index;
+	int xiface = 0, index = 0;
 	bool use_inband = false;
 
 	result.u64 = 0;
@@ -2407,6 +2775,7 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 			default:
 				break;
 			}
+			__cvmx_update_link_led(xiface, index, result);
 			return result;
 		}
 		phy_info = cvmx_helper_get_port_phy_info(xiface, index);
@@ -2460,6 +2829,8 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 			result.s.link_up = 1;
 			result.s.speed = 1000;
 		}
+		if (ipd_port >= 0)
+			__cvmx_update_link_led(xiface, index, result);
 		return result;
 	}
 
@@ -2484,6 +2855,8 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 	else
 		result = cvmx_helper_link_get(ipd_port);
 
+	if (ipd_port >= 0)
+		__cvmx_update_link_led(xiface, index, result);
 	return result;
 
 }
@@ -2519,6 +2892,12 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get(int ipd_port)
 	int is_vitesse_phy = 0;
 	int is_cortina_phy = 0;
 	int is_ti_phy;
+	int xiface = 0, index = 0;
+
+	if (ipd_port >= 0) {
+		xiface = cvmx_helper_get_interface_num(ipd_port);
+		index = cvmx_helper_get_interface_index_num(ipd_port);
+	}
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 	if (cvmx_sysinfo_get()->fdt_addr) {
@@ -2527,8 +2906,13 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get(int ipd_port)
 #endif
 
 	/* Give the user a chance to override the processing of this function */
-	if (cvmx_override_board_link_get)
-		return cvmx_override_board_link_get(ipd_port);
+	if (cvmx_override_board_link_get) {
+		result = cvmx_override_board_link_get(ipd_port);
+		if (ipd_port >= 0)
+			__cvmx_update_link_led(xiface, index, result);
+
+		return result;
+	}
 
 	/* Unless we fix it later, all links are defaulted to down */
 	result.u64 = 0;
@@ -2685,6 +3069,8 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get(int ipd_port)
 	if (!result.s.link_up)
 		result.u64 = 0;
 
+	if (ipd_port >= 0)
+		__cvmx_update_link_led(xiface, index, result);
 	return result;
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
index 3e13adb..8197031 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
@@ -101,7 +101,9 @@ CVMX_SHARED struct cvmx_cfg_port_param cvmx_cfg_port[CVMX_MAX_NODES][CVMX_HELPER
 				.force_link_up = false,
 				.disable_an = false,
 				.link_down_pwr_dn = false,
-				.phy_present = false
+				.phy_present = false,
+				.tx_clk_delay_bypass = false,
+				.rgmii_tx_clk_delay = 0,
 			}
 		}
 	};
@@ -1258,3 +1260,78 @@ cvmx_helper_get_port_phy_info(int xiface, int index)
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	return cvmx_cfg_port[xi.node][xi.interface][index].phy_info;
 }
+
+/**
+ * @INTERNAL
+ * Returns a pointer to the PHY LED configuration (if local GPIOs drive them)
+ *
+ * @param xiface	node and interface
+ * @param index		portindex
+ *
+ * @return pointer to the PHY LED information data structure or NULL if not
+ *	   present
+ */
+struct cvmx_phy_gpio_leds *cvmx_helper_get_port_phy_leds(int xiface, int index)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].gpio_leds;
+}
+
+/**
+ * @INTERNAL
+ * Sets a pointer to the PHY LED configuration (if local GPIOs drive them)
+ *
+ * @param xiface	node and interface
+ * @param index		portindex
+ * @param leds		pointer to led data structure
+ */
+void cvmx_helper_set_port_phy_leds(int xiface, int index,
+				   struct cvmx_phy_gpio_leds *leds)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	cvmx_cfg_port[xi.node][xi.interface][index].gpio_leds = leds;
+}
+
+/**
+ * @INTERNAL
+ * Disables RGMII TX clock bypass and sets delay value
+ *
+ * @param xiface	node and interface
+ * @param index		portindex
+ * @param bypass	Set true to enable the clock bypass and false
+ *			to sync clock and data synchronously.
+ *			Default is false.
+ * @param clk_delay	Delay value to skew TXC from TXD
+ */
+void cvmx_helper_cfg_set_rgmii_tx_clk_delay(int xiface, int index,
+					    bool bypass, int clk_delay)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	cvmx_cfg_port[xi.node][xi.interface][index].tx_clk_delay_bypass =
+									bypass;
+	cvmx_cfg_port[xi.node][xi.interface][index].rgmii_tx_clk_delay =
+								     clk_delay;
+}
+
+/**
+ * @INTERNAL
+ * Gets RGMII TX clock bypass and delay value
+ *
+ * @param xiface	node and interface
+ * @param index		portindex
+ * @param bypass	Set true to enable the clock bypass and false
+ *			to sync clock and data synchronously.
+ *			Default is false.
+ * @param clk_delay	Delay value to skew TXC from TXD, default is 0.
+ */
+void cvmx_helper_cfg_get_rgmii_tx_clk_delay(int xiface, int index,
+					    bool *bypass,
+					    int *clk_delay)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	*bypass =
+		cvmx_cfg_port[xi.node][xi.interface][index].tx_clk_delay_bypass;
+
+	*clk_delay =
+		cvmx_cfg_port[xi.node][xi.interface][index].rgmii_tx_clk_delay;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
index 0ad39c1..1dd8cc1 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 106932 $<hr>
+ * <hr>$Revision: 123496 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -192,7 +192,7 @@ int __cvmx_helper_xaui_probe(int xiface)
 
 /**
  * @INTERNAL
- * Bringup XAUI interface. After this call packet I/O should be 
+ * Bringup XAUI interface. After this call packet I/O should be
  * fully functional.
  *
  * @param interface Interface to bring up
@@ -339,6 +339,75 @@ int __cvmx_helper_xaui_link_init(int interface)
 }
 
 /**
+ * Reinitialize XAUI interface.  Does a probe without changing the hardware
+ * state.
+ *
+ * @param interface	Interface to reinitialize
+ *
+ * @return	0 on success, negative on failure
+ */
+int cvmx_helper_xaui_link_reinit(int interface)
+{
+	const int num_ports = 1, has_fcs = 0;
+
+	return __cvmx_helper_init_interface(interface, num_ports, has_fcs,
+					    CVMX_PKO_PADDING_60);
+}
+
+/**
+ * Retrain XAUI interface.
+ *
+ * GMX is disabled as part of retraining.
+ * While GMX is disabled, new recieved packets are dropped.
+ * If GMX was in the middle of recieving a packet when disabled,
+ * that packet will be recieved before GMX idles.
+ * Transmitted packets are buffered normally, but not sent.
+ * If GMX was in the middle of transmitting a packet when disabled,
+ * that packet will be transmitted before GMX idles.
+ *
+ * @param interface Interface to retrain
+ *
+ * @return Zero on success, negative on failure
+ */
+int cvmx_helper_xaui_link_retrain(int interface)
+{
+	union cvmx_gmxx_prtx_cfg gmx_cfg;
+	union cvmx_pcsxx_misc_ctl_reg misc_ctl;
+	int status;
+
+	/* Disable GMX (packet recieve and transmit) */
+	gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(0, interface));
+	gmx_cfg.s.en = 0;
+	cvmx_write_csr(CVMX_GMXX_PRTX_CFG(0, interface), gmx_cfg.u64);
+
+	/* This call doesn't properly disable GMX despite its comment
+	 * It waits for GMX to appear idle
+	 * It enables GMX if it succeeds
+	 */
+	status = __cvmx_helper_xaui_link_init(interface);
+
+	/* Cleanup after a failed retrain */
+	if (cvmx_unlikely(status != 0)) {
+		/* Clear all error interrupts we could've caused */
+		cvmx_write_csr(CVMX_GMXX_RXX_INT_REG(0, interface), ~0x0ull);
+		cvmx_write_csr(CVMX_GMXX_TX_INT_REG(interface), ~0x0ull);
+		cvmx_write_csr(CVMX_PCSXX_INT_REG(interface), ~0x0ull);
+
+		/* Disable GMX enable override */
+		misc_ctl.u64 = cvmx_read_csr(CVMX_PCSXX_MISC_CTL_REG(interface));
+		misc_ctl.s.gmxeno = 0;
+		cvmx_write_csr(CVMX_PCSXX_MISC_CTL_REG(interface), misc_ctl.u64);
+
+		/* Enable GMX */
+		gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(0, interface));
+		gmx_cfg.s.en = 1;
+		cvmx_write_csr(CVMX_GMXX_PRTX_CFG(0, interface), gmx_cfg.u64);
+	}
+
+	return status;
+}
+
+/**
  * @INTERNAL
  * Bringup and enable a XAUI interface. After this call packet
  * I/O should be fully functional. This is called with IPD
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper.c b/arch/mips/cavium-octeon/executive/cvmx-helper.c
index a41264a..43e21522 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper.c
@@ -1545,51 +1545,53 @@ EXPORT_SYMBOL(cvmx_helper_interface_probe);
 
 /**
  * @INTERNAL
- * Setup global backpressure setting.
+ * Setup backpressure.
  *
  * @return Zero on success, negative on failure
  */
 static int __cvmx_helper_global_setup_backpressure(int node)
 {
-	if (cvmx_rgmii_backpressure_dis) {
-		/* Disable backpressure if configured to do so */
-		/* Disable backpressure (pause frame) generation */
-		int num_interfaces = cvmx_helper_get_number_of_interfaces();
-		int interface;
-		for (interface = 0; interface < num_interfaces; interface++) {
-			int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
-			switch (cvmx_helper_interface_get_mode(xiface)) {
-			case CVMX_HELPER_INTERFACE_MODE_DISABLED:
-			case CVMX_HELPER_INTERFACE_MODE_PCIE:
-			case CVMX_HELPER_INTERFACE_MODE_SRIO:
-			case CVMX_HELPER_INTERFACE_MODE_ILK:
-			case CVMX_HELPER_INTERFACE_MODE_NPI:
-			case CVMX_HELPER_INTERFACE_MODE_LOOP:
-			case CVMX_HELPER_INTERFACE_MODE_XAUI:
-			case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-			case CVMX_HELPER_INTERFACE_MODE_XLAUI:
-			case CVMX_HELPER_INTERFACE_MODE_XFI:
-			case CVMX_HELPER_INTERFACE_MODE_10G_KR:
-			case CVMX_HELPER_INTERFACE_MODE_40G_KR4:
-				break;
-			case CVMX_HELPER_INTERFACE_MODE_RGMII:
-			case CVMX_HELPER_INTERFACE_MODE_GMII:
-			case CVMX_HELPER_INTERFACE_MODE_SPI:
-			case CVMX_HELPER_INTERFACE_MODE_SGMII:
-			case CVMX_HELPER_INTERFACE_MODE_QSGMII:
-			case CVMX_HELPER_INTERFACE_MODE_PICMG:
-			case CVMX_HELPER_INTERFACE_MODE_MIXED:
-				if (octeon_has_feature(OCTEON_FEATURE_BGX))
-					cvmx_bgx_set_backpressure_override(xiface, 0xf);
-				else
-					cvmx_gmx_set_backpressure_override(interface, 0xf);
-				break;
-			case CVMX_HELPER_INTERFACE_MODE_AGL:
-				cvmx_agl_set_backpressure_override(interface, 0x1);
-				break;
-			}
+	unsigned int bpmask;
+	int interface;
+	int num_interfaces = cvmx_helper_get_number_of_interfaces();
+
+	for (interface = 0; interface < num_interfaces; interface++) {
+		int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
+		switch (cvmx_helper_interface_get_mode(xiface)) {
+		case CVMX_HELPER_INTERFACE_MODE_DISABLED:
+		case CVMX_HELPER_INTERFACE_MODE_PCIE:
+		case CVMX_HELPER_INTERFACE_MODE_SRIO:
+		case CVMX_HELPER_INTERFACE_MODE_ILK:
+		case CVMX_HELPER_INTERFACE_MODE_NPI:
+		case CVMX_HELPER_INTERFACE_MODE_LOOP:
+		case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+		case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+		case CVMX_HELPER_INTERFACE_MODE_XFI:
+		case CVMX_HELPER_INTERFACE_MODE_10G_KR:
+		case CVMX_HELPER_INTERFACE_MODE_40G_KR4:
+			bpmask = (cvmx_rgmii_backpressure_dis) ? 0xF : 0;
+			if (octeon_has_feature(OCTEON_FEATURE_BGX))
+				cvmx_bgx_set_backpressure_override(xiface, bpmask);
+			break;
+		case CVMX_HELPER_INTERFACE_MODE_RGMII:
+		case CVMX_HELPER_INTERFACE_MODE_GMII:
+		case CVMX_HELPER_INTERFACE_MODE_SPI:
+		case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		case CVMX_HELPER_INTERFACE_MODE_QSGMII:
+		case CVMX_HELPER_INTERFACE_MODE_PICMG:
+		case CVMX_HELPER_INTERFACE_MODE_MIXED:
+			bpmask = (cvmx_rgmii_backpressure_dis) ? 0xF : 0;
+			if (octeon_has_feature(OCTEON_FEATURE_BGX))
+				cvmx_bgx_set_backpressure_override(xiface, bpmask);
+			else
+				cvmx_gmx_set_backpressure_override(interface, bpmask);
+			break;
+		case CVMX_HELPER_INTERFACE_MODE_AGL:
+			bpmask = (cvmx_rgmii_backpressure_dis) ? 0x1 : 0;
+			cvmx_agl_set_backpressure_override(interface, bpmask);
+			break;
 		}
-		//cvmx_dprintf("Disabling backpressure\n");
 	}
 	return 0;
 }
@@ -2030,12 +2032,16 @@ int cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
 		if (num_ports > 4)
 			num_ports = 4;
 
-		cvmx_bgx_set_backpressure_override(xiface, (1<<num_ports)-1);
+		cvmx_bgx_set_backpressure_override(xiface, 0);
 		for (index = 0; index < num_ports; index++) {
+			cvmx_helper_link_info_t link_info;
 			if (!cvmx_helper_is_port_valid(xiface, index))
 				continue;
 
 			cvmx_helper_bgx_shutdown_port(xiface, index);
+			/* Turn off link LEDs */
+			link_info.u64 = 0;
+			__cvmx_update_link_led(xiface, index, link_info);
 		}
 	}
 
@@ -2095,6 +2101,20 @@ int cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
 		}
 	}
 
+	for (interface = 0; interface < num_interfaces; interface++) {
+		int index;
+		int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
+		int num_ports = cvmx_helper_ports_on_interface(xiface);
+
+		for (index = 0; index < num_ports; index++) {
+			/* Doing this twice should clear it since no packets
+			 * can be received.
+			 */
+			cvmx_update_rx_activity_led(xiface, index, false);
+			cvmx_update_rx_activity_led(xiface, index, false);
+		}
+	}
+
 	/* Shutdown the PKO unit */
 	result = cvmx_helper_pko3_shutdown(node);
 
@@ -2601,6 +2621,9 @@ cvmx_helper_link_info_t cvmx_helper_link_get(int xipd_port)
 	if (iface_node_ops[xi.node][xi.interface]->link_get)
 		result = iface_node_ops[xi.node][xi.interface]->link_get(xipd_port);
 
+	if (xipd_port >= 0)
+		__cvmx_update_link_led(xiface, index, result);
+
 	return result;
 }
 EXPORT_SYMBOL(cvmx_helper_link_get);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ila.c b/arch/mips/cavium-octeon/executive/cvmx-ila.c
index cab3ede..d1212c8 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ila.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ila.c
@@ -67,7 +67,7 @@ CVMX_SHARED int cvmx_ila_chans = 2;
  *
  * @return Link state
  */
-static cvmx_helper_link_info_t __cvmx_ila_link_get(int lane_mask)
+cvmx_helper_link_info_t __cvmx_ila_link_get(int lane_mask)
 {
 	cvmx_helper_link_info_t result;
 	int node = cvmx_get_node_num();
@@ -80,7 +80,7 @@ static cvmx_helper_link_info_t __cvmx_ila_link_get(int lane_mask)
 
 retry:
 	retry_count++;
-	if (retry_count > 10)
+	if (retry_count > 100)
 		goto fail;
 
 	/* Read RX config and status bits */
@@ -88,6 +88,17 @@ retry:
 	rx_int.u64 = cvmx_read_csr_node(node, CVMX_ILA_RXX_INT(0));
 
 	if (rx_cfg1.s.rx_bdry_lock_ena == 0) {
+		/* (GSER-21957) GSER RX Equalization may make >= 5gbaud non-KR
+		   channel better */
+		if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
+			int qlm;
+			for (qlm = 2; qlm < 4; qlm++) {
+				if ((qlm == 2) && (lane_mask & 0xf))
+					__cvmx_qlm_rx_equalization(node, qlm, (lane_mask & 0xf));
+				if ((qlm == 3) && (lane_mask & 0xf0))
+					__cvmx_qlm_rx_equalization(node, qlm, (lane_mask >> 4) & 0xf);
+			}
+		}
 		/* Clear the boundary lock status bit */
 		rx_int.u64 = 0;
 		rx_int.s.word_sync_done = 1;
@@ -140,7 +151,7 @@ retry:
 		for (i = 0; i < 8; i++) {
 			if ((1 << i) & lane_mask) {
 				/* Clear pending interrupts */
-				cvmx_write_csr_node(node, CVMX_ILA_RX_LNEX_INT(i), 0x3ff);
+				cvmx_write_csr_node(node, CVMX_ILA_RX_LNEX_INT(i), 0x17f);
 				/* Enable bad_64b67b, bdry_sync_loss, crc32_err, dskew_fifo_ovfl,
  *                                    scrm_sync_loss, serdes_lock_loss, stat_msg, ukwn_cntl_word */
 			}
@@ -149,6 +160,10 @@ retry:
 		//cvmx_dprintf("ILK-LA: Lane alignment complete\n");
 	}
 
+	if (!rx_int.s.lane_align_done) {
+		goto retry;
+	}
+
 	result.u64 = 0;
 	result.s.link_up = 1;
 	result.s.full_duplex = 1;
@@ -184,27 +199,14 @@ int cvmx_ila_initialize(int lane_mask)
 	cvmx_ila_txx_cha_xon_t tx_cha_xon;
 	cvmx_ila_ser_cfg_t ser_cfg;
 	int node = cvmx_get_node_num();
-	int lane0 = 0, lane1 = 0;
 	cvmx_helper_link_info_t result;
 	int retry_count = 0;
 
 	ser_cfg.u64 = cvmx_read_csr_node(node, CVMX_ILA_SER_CFG);
-	ser_cfg.s.ser_rxpol_auto = 1;
-	cvmx_write_csr_node(node, CVMX_ILA_SER_CFG, ser_cfg.u64);
-
-	if (cvmx_qlm_get_mode_cn78xx(node, 2) == CVMX_QLM_MODE_ILK)
-		lane0 = 0xf;
-
-	if (cvmx_qlm_get_mode_cn78xx(node, 3) == CVMX_QLM_MODE_ILK)
-		lane1 = 0xf;
-
-	if ((lane_mask & 0xf) != lane0) {
-		cvmx_dprintf("ERROR: Invalid configuration for QLM2\n");
-		return -1;
-	}
-	if (((lane_mask >> 4) & 0xf) == lane1) {
-		cvmx_dprintf("ERROR: Invalid configuration for QLM3\n");
-		return -1;
+	if (ser_cfg.s.ser_reset_n == 0) {
+		ser_cfg.s.ser_rxpol_auto = 1;
+		ser_cfg.s.ser_reset_n = lane_mask;
+		cvmx_write_csr_node(node, CVMX_ILA_SER_CFG, ser_cfg.u64);
 	}
 
 	/* Enable RX lanes */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-lap.c b/arch/mips/cavium-octeon/executive/cvmx-lap.c
index 948c61b..1147b88 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-lap.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-lap.c
@@ -303,8 +303,13 @@ int cvmx_lap_init(int lap_num, cvmx_lap_config_t *lap_config)
 		break;
 	}
  
-	/* enable */ 
+	/* Return if LAP already initialized */
 	lap_cfg.u64 = cvmx_read_csr(CVMX_LAPX_CFG(lap_num));
+	if (lap_cfg.s.ena) {
+		cvmx_dprintf("LAP%d is already enabled\n", lap_num);
+		return 0;
+	}
+	/* enable */
 	lap_cfg.s.ooo = lap_config->ooo;
 	lap_cfg.s.lab_size =  lap_config->lab_size;
 	lap_cfg.s.ena = 1;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ocla.c b/arch/mips/cavium-octeon/executive/cvmx-ocla.c
index dedfc6b..c6be231 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ocla.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ocla.c
@@ -144,6 +144,44 @@ static struct dtx_reg_addr_rule dtx_regs_78xx[] = {
 	{INVALID_BLOCK_ID, 0,			0,		0}
 };
 
+/* DTX registers on the 73xx */
+static struct dtx_reg_addr_rule dtx_regs_73xx[] = {
+	{BCH,		0x00011800FE388000ull,	0,		8},
+	{BGX,		0x00011800FE700000ull,	0x8000,		8},
+	{CIU,		0x00011800FE808000ull,	0,		8},
+	{DFA,		0x00011800FE1B8000ull,	0,		8},
+	{DPI,		0x00011800FEEF8000ull,	0,		8},
+	{FPA,		0x00011800FE940000ull,	0,		8},
+	{GSER,		0x00011800FE480000ull,	0x8000,		8},
+	{HNA,		0x00011800FE238000ull,	0,		8},
+	{IOBN,		0x00011800FE780000ull,	0,		8},
+	{IOBP,		0x00011800FE7A0000ull,	0,		8},
+	{L2C_CBC,	0x00011800FE420000ull,	0x8000,		8},
+	{L2C_MCI,	0x00011800FE2E0000ull,	0x8000,		8},
+	{L2C_TAD,	0x00011800FE240000ull,	0x8000,		8},
+	{LBK,		0x00011800FE090000ull,	0,		8},
+	{LMC,		0x00011800FE440000ull,	0x8000,		8},
+	{MIO,		0x00011800FE000000ull,	0,		8},
+	{OSM,		0x00011800FE6E0000ull,	0,		8},
+	{PEM,		0x00011800FE600000ull,	0x8000,		8},
+	{PKI_PBE,	0x00011800FE228000ull,	0,		8},
+	{PKI_PFE,	0x00011800FE220000ull,	0,		8},
+	{PKI_PIX,	0x00011800FE230000ull,	0,		8},
+	{PKO,		0x00011800FEAA0000ull,	0,		8},
+	{RAD,		0x00011800FE380000ull,	0,		8},
+	{RNM,		0x00011800FE200000ull,	0,		8},
+	{RST,		0x00011800FE030000ull,	0,		8},
+	{SATA,		0x00011800FE360000ull,	0,		8},
+	{SLI,		0x00011800FE8F8000ull,	0,		8},
+	{SPEM,		0x00011800FE600000ull,	0,		8},
+	{SSO,		0x00011800FEB38000ull,	0,		8},
+	{TIM,		0x00011800FE2C0000ull,	0,		8},
+	{USBDRD,	0x00011800FE340000ull,	0,		8},
+	{XCV,		0x00011800FE6D8000ull,	0,		8},
+	{ZIP,		0x00011800FE1C0000ull,	0,		8},
+	{INVALID_BLOCK_ID, 0,			0,		0}
+};
+
 /* Must keep track of which fsm AND terms are in use */
 static uint16_t		and_terms[CVMX_MAX_NODES][MAX_COMPLEXES];
 
@@ -172,6 +210,8 @@ static uint64_t cvmx_get_dtx_reg_addr(cvmx_dtx_id_t	block_id,
 
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX))
 		regs = dtx_regs_70xx;
+	else if (OCTEON_IS_MODEL(OCTEON_CN73XX))
+		regs = dtx_regs_73xx;
 
 	while ((block_id != regs->id) && (regs->id != INVALID_BLOCK_ID))
 		regs++;
@@ -219,6 +259,9 @@ int cvmx_dtx_reset(void)
 	}
 
 	for (node = 0; node < CVMX_MAX_NODES; node++) {
+		if (!OCTEON_IS_MODEL(OCTEON_CN78XX) && node)
+			continue;
+
 		/* Initialize broadcast */
 		bcst_rsp.u64 = 0;
 		bcst_rsp.s.ena = 1;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pcie.c b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
index 5fdfb0d..8c8a6ad 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pcie.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 122729 $<hr>
+ * <hr>$Revision: 124105 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -780,7 +780,7 @@ static int cfg_retries(void)
 
 	if (cfg_ticks < 0) {
 		uint64_t nS = cfg_timeout * 1000000;
-		const int ceiling = 0xfffff;
+		const int ceiling = 0xffff;
 
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 		cfg_ticks = nS / (octeon_get_io_clock_rate() >> 16);
@@ -1174,8 +1174,8 @@ retry:
 	/* Display the link status */
 	pciercx_cfg032.u32 = cvmx_pcie_cfgx_read(pcie_port,
 						 CVMX_PCIERCX_CFG032(pcie_port));
-	cvmx_printf("PCIe: Port %d link active, %d lanes\n",
-		    pcie_port, pciercx_cfg032.s.nlw);
+	cvmx_printf("PCIe: Port %d link active, %d lanes, speed gen%d \n",
+		    pcie_port, pciercx_cfg032.s.nlw, pciercx_cfg032.s.ls);
 
 	return 0;
 }
@@ -1289,7 +1289,7 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int node, int pcie_port)
 				cvmx_gserx_lanex_pwr_ctrl_t pwr_ctrl;
 
 				misc_ovrrd.u64 = CVMX_READ_CSR(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm));
-				misc_ovrrd.s.cfg_rx_dll_locken_ovvrd_en = 1;
+				misc_ovrrd.s.cfg_rx_dll_locken_ovrrd_en = 1;
 				CVMX_WRITE_CSR(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm), misc_ovrrd.u64);
 				pwr_ctrl.u64 = CVMX_READ_CSR(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm));
 				pwr_ctrl.s.rx_resetn_ovrrd_en = 1;
@@ -1302,7 +1302,7 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int node, int pcie_port)
 				cvmx_gserx_lanex_pwr_ctrl_t pwr_ctrl;
 
 				misc_ovrrd.u64 = CVMX_READ_CSR(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm));
-				misc_ovrrd.s.cfg_rx_dll_locken_ovvrd_en = 0;
+				misc_ovrrd.s.cfg_rx_dll_locken_ovrrd_en = 0;
 				CVMX_WRITE_CSR(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm), misc_ovrrd.u64);
 				pwr_ctrl.u64 = CVMX_READ_CSR(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm));
 				pwr_ctrl.s.rx_resetn_ovrrd_en = 0;
@@ -1811,8 +1811,8 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	/* Display the link status */
 	pciercx_cfg032.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 						 CVMX_PCIERCX_CFG032(pcie_port));
-	cvmx_printf("%d:PCIe: Port %d link active, %d lanes\n",
-		    node, pcie_port, pciercx_cfg032.s.nlw);
+	cvmx_printf("PCIe: Port %d link active, %d lanes, speed gen%d \n",
+		    pcie_port, pciercx_cfg032.s.nlw, pciercx_cfg032.s.ls);
 
 	return 0;
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki.c b/arch/mips/cavium-octeon/executive/cvmx-pki.c
index a7233f9..fe6e1da 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki.c
@@ -425,7 +425,7 @@ void cvmx_pki_read_tag_config(int node, int style, uint64_t cluster_mask,
 	/* Custom-Mask Tag: */
 	tag_sel.u64 = cvmx_read_csr_node(node, CVMX_PKI_STYLEX_TAG_SEL(style));
 	for (mask = 0; mask < 4; mask++) {
-		tag_cfg->mask_tag[mask].enable |= (style_cfg2_reg.s.tag_inc & (1 << mask)) != 0;
+		tag_cfg->mask_tag[mask].enable = (style_cfg2_reg.s.tag_inc & (1 << mask)) != 0;
 		switch (mask) {
 		case 0: tag_idx = tag_sel.s.tag_idx0; break;
 		case 1: tag_idx = tag_sel.s.tag_idx1; break;
@@ -1381,29 +1381,29 @@ int cvmx_pki_config_dump(unsigned node)
 			(pkstyle[__i].s.pm & (1 << 4)) ? '-' : 'E', (pkstyle[__i].s.pm & (1 << 5)) ? '-' : 'F',
 			(pkstyle[__i].s.pm & (1 << 6)) ? '-' : 'G'));
 		NMPRINT(nclusters, mask, __i, 1, "Initial Parse Mode", "%*s", lines[__i]);
-		NMPRINT(nclusters, mask, __i, 1, "INST skip", "%*d", pkskip[__i].s.inst_skip);
+		NMPRINT(nclusters, mask, __i, 1, "INST skip (bytes)", "%*d", pkskip[__i].s.inst_skip);
 		if (NMCMPEQ(0, pkcfg[__i].s.inst_hdr, nclusters, mask, __i) != 0)
 			NMPRINT(nclusters, mask, __i, 1, "INST Header present", "%*s", pkcfg[__i].s.inst_hdr ? "Yes" : "No");
-		NMPRINT(nclusters, mask, __i, 1, "FCS skip", "%*d", pkskip[__i].s.fcs_skip);
-		NMPRINT(nclusters, mask, __i, 1, "FCS present", "%*s", pkcfg[__i].s.fcs_pres ? "On":"Off");
+		NMPRINT(nclusters, mask, __i, 1, "FCS skip (bytes)", "%*d", pkskip[__i].s.fcs_skip);
+		NMPRINT(nclusters, mask, __i, 1, "FCS present", "%*s", pkcfg[__i].s.fcs_pres ? "Yes" : "No");
 		if (NMCMPEQ(0, pkl2cust[__i].s.valid, nclusters, mask, __i) != 0) {
-			NMPRINT(nclusters, mask, __i, 1, "L2 custom match", "%*s", pkl2cust[__i].s.valid ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "L2 custom match", "%*s", pkl2cust[__i].s.valid ? "On" : "Off");
 			NMPRINT(nclusters, mask, __i, 1, "L2 Custom offset", "%*d", pkl2cust[__i].s.offset);
 		}
 		if (NMCMPEQ(0, pkcfg[__i].s.lg_custom, nclusters, mask, __i) != 0) {
-			NMPRINT(nclusters, mask, __i, 1, "LG custom match", "%*s", pkcfg[__i].s.lg_custom ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "LG custom match", "%*s", pkcfg[__i].s.lg_custom ? "On" : "Off");
 			NMPRINT(nclusters, mask, __i, 1, "LG Custom offset", "%*d", pklgcust[__i].s.offset);
 		}
 		if (NMCMPEQ(0, pkcfg[__i].s.mpls_en, nclusters, mask, __i) != 0)
-			NMPRINT(nclusters, mask, __i, 1, "MPLS parsing", "%*s", pkcfg[__i].s.mpls_en ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "MPLS parsing", "%*s", pkcfg[__i].s.mpls_en ? "On" : "Off");
 		if (NMCMPEQ(0, pkcfg[__i].s.dsa_en, nclusters, mask, __i) != 0)
-			NMPRINT(nclusters, mask, __i, 1, "DSA parsing", "%*s", pkcfg[__i].s.dsa_en ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "DSA parsing", "%*s", pkcfg[__i].s.dsa_en ? "On" : "Off");
 		if (NMCMPEQ(0, pkcfg[__i].s.hg_en, nclusters, mask, __i) != 0)
-			NMPRINT(nclusters, mask, __i, 1, "HG parsing", "%*s", pkcfg[__i].s.hg_en ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "HG parsing", "%*s", pkcfg[__i].s.hg_en ? "On" : "Off");
 		if (NMCMPEQ(0, pkcfg[__i].s.hg2_en, nclusters, mask, __i) != 0)
-			NMPRINT(nclusters, mask, __i, 1, "HG2 parsing", "%*s", pkcfg[__i].s.hg2_en ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "HG2 parsing", "%*s", pkcfg[__i].s.hg2_en ? "On" : "Off");
 		if (NMCMPEQ(0, pkcfg[__i].s.fulc_en, nclusters, mask, __i) != 0)
-			NMPRINT(nclusters, mask, __i, 1, "Fulcrum Header parsing", "%*s", pkcfg[__i].s.fulc_en ? "On":"Off");
+			NMPRINT(nclusters, mask, __i, 1, "Fulcrum Header parsing", "%*s", pkcfg[__i].s.fulc_en ? "On" : "Off");
 	}
 	if ((pkind - 1) != ibase)
 		cvmx_printf("\nPKIND(s) %02d-%02d -- same as PKIND %02d\n", pkind - 1, ibase + 1, ibase);
diff --git a/arch/mips/include/asm/octeon/cvmx-app-init.h b/arch/mips/include/asm/octeon/cvmx-app-init.h
index a0afda2..4a965ee 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-init.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-init.h
@@ -41,7 +41,7 @@
  * @file
  * Header file for simple executive application initialization.  This defines
  * part of the ABI between the bootloader and the application.
- * <hr>$Revision: 122068 $<hr>
+ * <hr>$Revision: 123622 $<hr>
  *
  */
 
@@ -294,6 +294,7 @@ enum cvmx_board_types_enum {
 	CVMX_BOARD_TYPE_EBB7304 = 76,
 	CVMX_BOARD_TYPE_NIC73 = 77,	/* Liquid I/O */
 	CVMX_BOARD_TYPE_NIAGARA830_IM13166 = 78,
+	CVMX_BOARD_TYPE_NIC25E = 79,
 	CVMX_BOARD_TYPE_MAX,
 	/* NOTE:  256-257 are being used by a customer. */
 
@@ -440,6 +441,7 @@ static inline const char *cvmx_board_type_to_string(enum cvmx_board_types_enum t
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB7304)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC73)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIAGARA830_IM13166)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC25E)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MAX)
 
 		/* Customer boards listed here */
diff --git a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
index 117ef13..9f51164e 100644
--- a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
@@ -3623,7 +3623,7 @@ union cvmx_bgxx_cmr_chan_msk_and {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t msk_and                      : 64; /**< Assert physical backpressure when the backpressure channel vector combined with MSK_AND
                                                          indicates backpressure as follows:
-                                                         _ phys_bp_msk_and = (CHAN_VECTOR<x:y> & MSK_AND<x:y>) == MSK_AND<x:y>
+                                                         _ phys_bp_msk_and = MSK_AND<x:y> != 0 && (CHAN_VECTOR<x:y> & MSK_AND<x:y>) == MSK_AND<x:y>
                                                          _ phys_bp = phys_bp_msk_or || phys_bp_msk_and
                                                          In single LMAC configurations, x = 63, y = 0.
                                                          In multi-LMAC configurations, x/y are set as follows:
@@ -3651,7 +3651,7 @@ union cvmx_bgxx_cmr_chan_msk_or {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t msk_or                       : 64; /**< Assert physical backpressure when the backpressure channel vector combined with MSK_OR
                                                          indicates backpressure as follows:
-                                                         _ phys_bp_msk_or = (CHAN_VECTOR<x:y> & MSK_AND<x:y>) & MSK_OR<x:y>
+                                                         _ phys_bp_msk_or = (CHAN_VECTOR<x:y> & MSK_OR<x:y>) != 0
                                                          _ phys_bp = phys_bp_msk_or || phys_bp_msk_and
                                                          In single LMAC configurations, x = 63, y = 0.
                                                          In multi-LMAC configurations, x/y are set as follows:
@@ -4083,18 +4083,19 @@ typedef union cvmx_bgxx_gmp_gmi_prtx_cfg cvmx_bgxx_gmp_gmi_prtx_cfg_t;
  * optional UDD skip data (BGX()_GMP_GMI_RX()_UDD_SKP[LEN]).
  * When BGX()_GMP_GMI_RX()_FRM_CTL[PRE_CHK] is clear, PREAMBLE+SFD are prepended to the
  * packet and would require UDD skip length to account for them.
- * Port Mode
- * - Full Duplex
- *     L2 Size <  BGX_RX_DECISION - Accept packet. No filtering is applied
- *     L2 Size >= BGX_RX_DECISION - Apply filter. Accept packet based on PAUSE packet filter
- * - Half Duplex
- *     L2 Size <  BGX_RX_DECISION - Drop packet. Packet is unconditionally dropped.
- *     L2 Size >= BGX_RX_DECISION - Accept packet.
+ *
+ * Full Duplex:
+ * _   L2 Size <  BGX_RX_DECISION - Accept packet. No filtering is applied.
+ * _   L2 Size >= BGX_RX_DECISION - Apply filter. Accept packet based on PAUSE packet filter.
+ *
+ * Half Duplex:
+ * _   L2 Size <  BGX_RX_DECISION - Drop packet. Packet is unconditionally dropped.
+ * _   L2 Size >= BGX_RX_DECISION - Accept packet.
  *
  * where L2_size = MAX(0, total_packet_size - BGX()_GMP_GMI_RX()_UDD_SKP[LEN] -
  *                        ((BGX()_GMP_GMI_RX()_FRM_CTL[PRE_CHK]==1)*8))
  *
- * BGX()_GMP_GMI_RX()_DECISION = The byte count to decide when to accept or filter a packet
+ * BGX()_GMP_GMI_RX()_DECISION = The byte count to decide when to accept or filter a packet.
  */
 union cvmx_bgxx_gmp_gmi_rxx_decision {
 	uint64_t u64;
diff --git a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
index f04deb3..c09e1a7 100644
--- a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
@@ -661,8 +661,8 @@ union cvmx_dpi_bist_status {
 	uint64_t u64;
 	struct cvmx_dpi_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_59_63               : 5;
-	uint64_t bist                         : 59; /**< BIST results. Hardware sets a bit in BIST for memory that fails.
+	uint64_t reserved_57_63               : 7;
+	uint64_t bist                         : 57; /**< BIST results. Hardware sets a bit in BIST for memory that fails.
                                                          INTERNAL:
                                                            dpi.dma.csr.r_pkt__csr_bstatus_summary,    56    -- from the packet logic
                                                            dpi.dma.csr.spi__csr_bist_status[7:0],     55:48
@@ -676,8 +676,8 @@ union cvmx_dpi_bist_status {
                                                            dpi.dma.csr.ncbib__csr_bist_status[3:0],    7:4
                                                            dpi.dma.csr.ncbia__csr_bist_status[3:0]     3:0 */
 #else
-	uint64_t bist                         : 59;
-	uint64_t reserved_59_63               : 5;
+	uint64_t bist                         : 57;
+	uint64_t reserved_57_63               : 7;
 #endif
 	} s;
 	struct cvmx_dpi_bist_status_cn61xx {
@@ -718,27 +718,7 @@ union cvmx_dpi_bist_status {
 	struct cvmx_dpi_bist_status_cn63xx    cn68xxp1;
 	struct cvmx_dpi_bist_status_cn61xx    cn70xx;
 	struct cvmx_dpi_bist_status_cn61xx    cn70xxp1;
-	struct cvmx_dpi_bist_status_cn73xx {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_57_63               : 7;
-	uint64_t bist                         : 57; /**< BIST results. Hardware sets a bit in BIST for memory that fails.
-                                                         INTERNAL:
-                                                           dpi.dma.csr.r_pkt__csr_bstatus_summary,    56    -- from the packet logic
-                                                           dpi.dma.csr.spi__csr_bist_status[7:0],     55:48
-                                                           dpi.dma.csr.r_rdb_buff__bist_status[23:0], 47:24
-                                                           dpi.dma.csr.rdb_tmem__bist_status,         23
-                                                           dpi.dma.csr.req_mem__bist_status[1:0],     22:21
-                                                           dpi.dma.csr.req_ctl__bist_status[1:0],     20:19 -- these bits are tied off to zero
-                                                           dpi.dma.csr.dsi1__bist_status[3:0],        18:15
-                                                           dpi.dma.csr.dsi0__bist_status[3:0],        14:11
-                                                           dpi.dma.csr.ncbo__bist_status[2:0],        10:8
-                                                           dpi.dma.csr.ncbib__csr_bist_status[3:0],    7:4
-                                                           dpi.dma.csr.ncbia__csr_bist_status[3:0]     3:0 */
-#else
-	uint64_t bist                         : 57;
-	uint64_t reserved_57_63               : 7;
-#endif
-	} cn73xx;
+	struct cvmx_dpi_bist_status_s         cn73xx;
 	struct cvmx_dpi_bist_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
@@ -762,7 +742,7 @@ union cvmx_dpi_bist_status {
 	} cn78xx;
 	struct cvmx_dpi_bist_status_s         cn78xxp2;
 	struct cvmx_dpi_bist_status_cn61xx    cnf71xx;
-	struct cvmx_dpi_bist_status_cn73xx    cnf75xx;
+	struct cvmx_dpi_bist_status_s         cnf75xx;
 };
 typedef union cvmx_dpi_bist_status cvmx_dpi_bist_status_t;
 
@@ -2862,7 +2842,7 @@ union cvmx_dpi_sli_prtx_cfg {
                                                          reads and DPI_HDR_XTYPE_E::INBOUND L2/DRAM writes. DPI_DMA_INSTR_HDR_S[LPORT]
                                                          selects which DPI_SLI_PRT()_CFG[NCBSEL] is used for a DPI DMA instruction.
                                                          In the normal case (DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] clear),
-                                                            [NCBSEL] XOR DPI_DMA_INSTR_HDR_S[FPORT<0>]
+                                                         _   [NCBSEL] XOR DPI_DMA_INSTR_HDR_S[FPORT<0>]
                                                          determines the IOI/NCB that DPI uses.
                                                          0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for DPI_HDR_XTYPE_E::OUTBOUND and
                                                              DPI_HDR_XTYPE_E::INBOUND DPI DMA instructions.
@@ -3235,7 +3215,7 @@ union cvmx_dpi_sli_prtx_cfg {
                                                          reads and DPI_HDR_XTYPE_E::INBOUND L2/DRAM writes. DPI_DMA_INSTR_HDR_S[LPORT]
                                                          selects which DPI_SLI_PRT()_CFG[NCBSEL] is used for a DPI DMA instruction.
                                                          In the normal case (DPI_NCB_CTL[NCBSEL_PRT_XOR_DIS] clear),
-                                                            [NCBSEL] XOR DPI_DMA_INSTR_HDR_S[FPORT<0>]
+                                                         _   [NCBSEL] XOR DPI_DMA_INSTR_HDR_S[FPORT<0>]
                                                          determines the IOI/NCB that DPI uses.
                                                          0 = DPI uses IOBI2/IOBO2 (aka NCBI2/NCBO2) for DPI_HDR_XTYPE_E::OUTBOUND and
                                                              DPI_HDR_XTYPE_E::INBOUND DPI DMA instructions.
diff --git a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
index a06fad0..9305b8d 100644
--- a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
@@ -131,6 +131,17 @@ static inline uint64_t CVMX_GSERX_BR_TXX_CUR(unsigned long offset, unsigned long
 #define CVMX_GSERX_BR_TXX_CUR(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000438ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_BR_TXX_INI(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_BR_TXX_INI(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090000448ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
+}
+#else
+#define CVMX_GSERX_BR_TXX_INI(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000448ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_BR_TXX_TAP(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -538,6 +549,7 @@ static inline uint64_t CVMX_GSERX_EQ_WAIT_TIME(unsigned long offset)
 static inline uint64_t CVMX_GSERX_GLBL_MISC_CONFIG_1(unsigned long offset)
 {
 	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_GLBL_MISC_CONFIG_1(%lu) is invalid on this chip\n", offset);
@@ -550,7 +562,9 @@ static inline uint64_t CVMX_GSERX_GLBL_MISC_CONFIG_1(unsigned long offset)
 static inline uint64_t CVMX_GSERX_GLBL_PLL_CFG_0(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_GLBL_PLL_CFG_0(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090460000ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -561,7 +575,9 @@ static inline uint64_t CVMX_GSERX_GLBL_PLL_CFG_0(unsigned long offset)
 static inline uint64_t CVMX_GSERX_GLBL_PLL_CFG_1(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_GLBL_PLL_CFG_1(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090460008ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -572,7 +588,9 @@ static inline uint64_t CVMX_GSERX_GLBL_PLL_CFG_1(unsigned long offset)
 static inline uint64_t CVMX_GSERX_GLBL_PLL_CFG_2(unsigned long offset)
 {
 	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13)))))
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_GLBL_PLL_CFG_2(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001180090460010ull) + ((offset) & 15) * 0x1000000ull;
 }
@@ -583,6 +601,7 @@ static inline uint64_t CVMX_GSERX_GLBL_PLL_CFG_2(unsigned long offset)
 static inline uint64_t CVMX_GSERX_GLBL_PLL_CFG_3(unsigned long offset)
 {
 	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN73XX) && ((offset <= 6))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 13))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF75XX) && ((offset <= 8)))))
 		cvmx_warn("CVMX_GSERX_GLBL_PLL_CFG_3(%lu) is invalid on this chip\n", offset);
@@ -2583,6 +2602,46 @@ union cvmx_gserx_br_txx_cur {
 typedef union cvmx_gserx_br_txx_cur cvmx_gserx_br_txx_cur_t;
 
 /**
+ * cvmx_gser#_br_tx#_ini
+ *
+ * GSER Base-R Link Training Tx Taps equalization Initialize value. When Base-R hardware link
+ * training is enabled the transmitter
+ * equalizer taps (Pre/Swing/Post) are initialized with the values in this register.  Also,
+ * during 10GBase-KR hardware link training if a
+ * coefficient update request message is received from the link partner with the Initialize
+ * control bit set the local device transmitter
+ * taps (Pre/Swing/Post) will be updated with the values in this register.
+ * Added in pass 2.
+ */
+union cvmx_gserx_br_txx_ini {
+	uint64_t u64;
+	struct cvmx_gserx_br_txx_ini_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_14_63               : 50;
+	uint64_t txt_post_init                : 5;  /**< During TX Base-R Link Training, this is the Tx POST Tap value that is used
+                                                         when the INITIALIZE coefficients update is received. It is also the Tx POST Tap
+                                                         value used when the Base-R Link Training begins.
+                                                         For diagnostic use only. */
+	uint64_t txt_swing_init               : 5;  /**< During TX Base-R Link Training, this is the Tx SWING Tap value that is used
+                                                         when the INITIALIZE coefficients update is received. It is also the Tx SWING Tap
+                                                         value used when the Base-R Link Training begins.
+                                                         For diagnostic use only. */
+	uint64_t txt_pre_init                 : 4;  /**< During TX Base-R Link Training, this is the Tx PRE Tap value that is used
+                                                         when the INITIALIZE coefficients update is received. It is also the Tx PRE Tap
+                                                         value used when the Base-R Link Training begins.
+                                                         For diagnostic use only. */
+#else
+	uint64_t txt_pre_init                 : 4;
+	uint64_t txt_swing_init               : 5;
+	uint64_t txt_post_init                : 5;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_gserx_br_txx_ini_s        cn78xxp2;
+};
+typedef union cvmx_gserx_br_txx_ini cvmx_gserx_br_txx_ini_t;
+
+/**
  * cvmx_gser#_br_tx#_tap
  *
  * Added in pass 2.
@@ -2626,24 +2685,29 @@ union cvmx_gserx_cfg {
 	struct cvmx_gserx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t rmac_pipe                    : 1;  /**< Indicates the RMAC is configured for PIPE mode when GSER(6..8)_CFG[RMAC]
-                                                         is also set.  Lanes 0 and 1 of the 2-lane SerDes are used in PIPE mode. */
-	uint64_t rmac                         : 1;  /**< Indicates GSER(6..8) is configured for RMAC mode. Only one of the BGX, PCIE, SRIO, or
-                                                         RMAC modes can be set at any one time. */
-	uint64_t srio                         : 1;  /**< Indicates GSER(2..3) is configured for SRIO mode. GSER(2..3) will power-up with
-                                                         GSER(2..3)_CFG[SRIO] bit set by the hardware.  Only one of the BGX, PCIE, SRIO, or RMAC
-                                                         modes can be set at any one time. */
+	uint64_t rmac_pipe                    : 1;  /**< When set, indicates the RMAC is configured for PIPE mode - the two lanes of
+                                                         the DLM are used in PIPE mode. [RMAC_PIPE] must only be set when [RMAC] is set.
+                                                         INTERNAL: The hardware ignores [RMAC_PIPE] when [RMAC] is clear. */
+	uint64_t rmac                         : 1;  /**< When set, indicates the GSER is configured for RMAC mode. [RMAC] must not be set
+                                                         when any of [BGX,PCIE,SRIO] are set. [RMAC] must only be set for DLM6, DLM7, and
+                                                         DLM8 (i.e. GSER6, GSER7, and GSER8). */
+	uint64_t srio                         : 1;  /**< When set, indicates the GSER is configured for SRIO mode. [SRIO] must not be set
+                                                         when any of [BGX,PCIE,RMAC] are set. [BGX] must only be set for QLM2 and QLM3
+                                                         (i.e. GSER2 and GSER3). */
 	uint64_t sata                         : 1;  /**< Reserved. */
-	uint64_t bgx_quad                     : 1;  /**< Indicates the BGX is in quad aggregation mode when GSER(4..5)_CFG[BGX]
-                                                         is also set. A single controller is used for all four lanes. */
-	uint64_t bgx_dual                     : 1;  /**< Indicates the BGX is in dual aggregation mode when GSER(4..5)_CFG[BGX]
-                                                         is also set. A single controller is used for lanes 0 and 1 and another controller is used
-                                                         for lanes 2 and 3. */
-	uint64_t bgx                          : 1;  /**< Indicates GSER(4..5) is configured for BGX mode. Only one of the BGX,
-                                                         PCIE, SRIO, or RMAC modes can be set at any one time. */
+	uint64_t bgx_quad                     : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         XAUI/DXAUI/XLAUI not supported on o75. */
+	uint64_t bgx_dual                     : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         RXAUI not supported on o75. */
+	uint64_t bgx                          : 1;  /**< When set, indicates the GSER is configured for BGX mode. [BGX] must not be set
+                                                         when any of [SRIO,PCIE,RMAC] are set. [BGX] must only be set for DLM4 and DLM5
+                                                         (i.e. GSER4 and GSER5). */
 	uint64_t ila                          : 1;  /**< Reserved. */
-	uint64_t pcie                         : 1;  /**< Indicates GSER(0..1) is configured for PCIE mode. Only one of the BGX,
-                                                         PCIE, SRIO, or RMAC modes can be set at any one time. */
+	uint64_t pcie                         : 1;  /**< Indicates the GSER is configured for PCIE mode. [PCIE] must not be set when
+                                                         any of [BGX,SRIO,RMAC] are set. [PCIE] must only be set for DLM0 and DLM1
+                                                         (i.e. GSER0 and GSER1). */
 #else
 	uint64_t pcie                         : 1;
 	uint64_t ila                          : 1;
@@ -2660,18 +2724,32 @@ union cvmx_gserx_cfg {
 	struct cvmx_gserx_cfg_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
-	uint64_t sata                         : 1;  /**< Indicates the GSER is configured for SATA mode. Only one of the BGX, SATA, or PCIE
-                                                         modes can be set at any one time. */
-	uint64_t bgx_quad                     : 1;  /**< Indicates the BGX is in quad aggregation mode when GSER(2..3,5)_CFG[BGX]
-                                                         is also set. A single controller is used for all four lanes. */
-	uint64_t bgx_dual                     : 1;  /**< Indicates the BGX is in dual aggregation mode when GSER()_CFG[BGX]
-                                                         is also set. A single controller is used for lanes 0 and 1 and another controller is used
-                                                         for lanes 2 and 3. */
-	uint64_t bgx                          : 1;  /**< Indicates the GSER is configured for BGX mode. Only one of the BGX,
-                                                         SATA, or PCIE modes can be set at any one time. */
+	uint64_t sata                         : 1;  /**< When set, indicates the GSER is configured for SATA mode. [SATA] must not be set
+                                                         when either of [BGX,PCIE] are set. [SATA] must only be set for DLM4 (i.e. GSER4). */
+	uint64_t bgx_quad                     : 1;  /**< When set, indicates the QLM is in BGX quad aggregation mode. [BGX_QUAD] must only be
+                                                         set when [BGX] is set and [BGX_DUAL] is clear.
+                                                         When [BGX_QUAD] is set, GSER bundles all four lanes for one BGX controller.
+                                                         [BGX_QUAD] must only be set for the XAUI/DXAUI and XLAUI protocols.
+                                                         [BGX_QUAD] must not be set in a DLM.
+                                                         INTERNAL:
+                                                         There is hardware to pair DLM 5 and 6 together when [BGX_QUAD] is set in DLM5.
+                                                         But we currently do not support XAUI/DXAUI/XLAUI on DLM's. */
+	uint64_t bgx_dual                     : 1;  /**< When set, indicates the QLM is in BGX dual aggregation mode. [BGX_DUAL] must only be
+                                                         set when [BGX] is also set and [BGX_QUAD] is clear.
+                                                         When [BGX_DUAL] is set, GSER bundles lanes 0 and 1 for one BGX controller and bundles
+                                                         lanes 2 and 3 for another BGX controller. [BGX_DUAL] must only be set for the RXAUI
+                                                         protocol.
+                                                         [BGX_DUAL] must not be set in a DLM.
+                                                         INTERNAL:
+                                                         [BGX_DUAL] should work in a DLM (lanes 0 and 1 bundled for one BGX controller), but
+                                                         we currently do not support RXAUI in a DLM. */
+	uint64_t bgx                          : 1;  /**< When set, indicates the GSER is configured for BGX mode. [BGX] must not be set
+                                                         when either of [SATA,PCIE] are set.
+                                                         When [BGX] is set and both [BGX_DUAL,BGX_QUAD] are clear, GSER exposes each lane to an
+                                                         independent BGX controller. */
 	uint64_t ila                          : 1;  /**< Reserved. */
-	uint64_t pcie                         : 1;  /**< Indicates the GSER is configured for PCIE mode. Only one of the BGX,
-                                                         SATA, or PCIE modes can be set at any one time. */
+	uint64_t pcie                         : 1;  /**< Indicates the GSER is configured for PCIE mode. [PCIE] must not be set when
+                                                         either of [SATA,BGX] are set. */
 #else
 	uint64_t pcie                         : 1;
 	uint64_t ila                          : 1;
@@ -2685,19 +2763,28 @@ union cvmx_gserx_cfg {
 	struct cvmx_gserx_cfg_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t bgx_quad                     : 1;  /**< For non-CCPI links, indicates the BGX is in quad aggregation mode when GSER()_CFG[BGX]
-                                                         is also set. A single controller is used for all four lanes. For CCPI links, this bit has
-                                                         no meaning. */
-	uint64_t bgx_dual                     : 1;  /**< For non-CCPI links, indicates the BGX is in dual aggregation mode when GSER()_CFG[BGX]
-                                                         is also set. A single controller is used for lanes 0 and 1 and another controller is used
-                                                         for lanes 2 and 3. For CCPI links, this bit has no meaning. */
-	uint64_t bgx                          : 1;  /**< For non-CCPI links, indicates the GSER is configured for BGX mode. Only one of the BGX,
-                                                         ILA, or PCIE modes can be set at any one time. For CCPI links, this bit has no meaning. */
-	uint64_t ila                          : 1;  /**< For non-CCPI links, indicates the GSER is configured for ILK/ILA mode. For CCPI links this
-                                                         bit will be set. Only one of the BGX, ILA, or PCIE modes can be set at any one time. For
-                                                         CCPI links, this bit has no meaning. */
-	uint64_t pcie                         : 1;  /**< For non-CCPI links, indicates the GSER is configured for PCIE mode. Only one of the BGX,
-                                                         ILA, or PCIE modes can be set at any one time. For CCPI links, this bit has no meaning. */
+	uint64_t bgx_quad                     : 1;  /**< When set, indicates the QLM is in BGX quad aggregation mode. [BGX_QUAD] must only be
+                                                         set when [BGX] is set and [BGX_DUAL] is clear.
+                                                         When [BGX_QUAD] is set, GSER bundles all four lanes for one BGX controller.
+                                                         [BGX_QUAD] must only be set for the XAUI/DXAUI and XLAUI protocols.
+                                                         INTERNAL: Not used in CCPI QLMs. */
+	uint64_t bgx_dual                     : 1;  /**< When set, indicates the QLM is in BGX dual aggregation mode. [BGX_DUAL] must only be
+                                                         set when [BGX] is also set and [BGX_QUAD] is clear.
+                                                         When [BGX_DUAL] is set, GSER bundles lanes 0 and 1 for one BGX controller and bundles
+                                                         lanes 2 and 3 for another BGX controller. [BGX_DUAL] must only be set for the RXAUI
+                                                         protocol.
+                                                         INTERNAL: Not used in CCPI QLMs. */
+	uint64_t bgx                          : 1;  /**< When set, indicates the GSER is configured for BGX mode. [BGX] must not be set
+                                                         when either of [ILA,PCIE] are set. For CCPI links, [BGX] must be clear.
+                                                         When [BGX] is set and both [BGX_DUAL,BGX_QUAD] are clear, GSER exposes each lane to an
+                                                         independent BGX controller.
+                                                         INTERNAL: Not used in CCPI QLMs. */
+	uint64_t ila                          : 1;  /**< When set, indicates the GSER is configured for ILK/ILA/CCPI mode. [ILA] must not be set
+                                                         when either of [BGX,PCIE] are set. For CCPI QLMs, [ILA] must be set.
+                                                         INTERNAL: [ILA] will be set for CCPI QLMs, but isn't used. */
+	uint64_t pcie                         : 1;  /**< When set, indicates the GSER is configured for PCIE mode. [PCIE] must not be
+                                                         set when either of [ILA,BGX] are set. For CCPI QLMs, [PCIE] must be clear.
+                                                         INTERNAL: Not used in CCPI QLMs. */
 #else
 	uint64_t pcie                         : 1;
 	uint64_t ila                          : 1;
@@ -3652,6 +3739,7 @@ union cvmx_gserx_glbl_misc_config_1 {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} s;
+	struct cvmx_gserx_glbl_misc_config_1_s cn73xx;
 	struct cvmx_gserx_glbl_misc_config_1_s cn78xx;
 	struct cvmx_gserx_glbl_misc_config_1_s cn78xxp2;
 	struct cvmx_gserx_glbl_misc_config_1_s cnf75xx;
@@ -3690,8 +3778,10 @@ union cvmx_gserx_glbl_pll_cfg_0 {
 	uint64_t reserved_14_63               : 50;
 #endif
 	} s;
+	struct cvmx_gserx_glbl_pll_cfg_0_s    cn73xx;
 	struct cvmx_gserx_glbl_pll_cfg_0_s    cn78xx;
 	struct cvmx_gserx_glbl_pll_cfg_0_s    cn78xxp2;
+	struct cvmx_gserx_glbl_pll_cfg_0_s    cnf75xx;
 };
 typedef union cvmx_gserx_glbl_pll_cfg_0 cvmx_gserx_glbl_pll_cfg_0_t;
 
@@ -3727,8 +3817,10 @@ union cvmx_gserx_glbl_pll_cfg_1 {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} s;
+	struct cvmx_gserx_glbl_pll_cfg_1_s    cn73xx;
 	struct cvmx_gserx_glbl_pll_cfg_1_s    cn78xx;
 	struct cvmx_gserx_glbl_pll_cfg_1_s    cn78xxp2;
+	struct cvmx_gserx_glbl_pll_cfg_1_s    cnf75xx;
 };
 typedef union cvmx_gserx_glbl_pll_cfg_1 cvmx_gserx_glbl_pll_cfg_1_t;
 
@@ -3791,8 +3883,10 @@ union cvmx_gserx_glbl_pll_cfg_2 {
 	uint64_t reserved_15_63               : 49;
 #endif
 	} s;
+	struct cvmx_gserx_glbl_pll_cfg_2_s    cn73xx;
 	struct cvmx_gserx_glbl_pll_cfg_2_s    cn78xx;
 	struct cvmx_gserx_glbl_pll_cfg_2_s    cn78xxp2;
+	struct cvmx_gserx_glbl_pll_cfg_2_s    cnf75xx;
 };
 typedef union cvmx_gserx_glbl_pll_cfg_2 cvmx_gserx_glbl_pll_cfg_2_t;
 
@@ -3812,8 +3906,8 @@ union cvmx_gserx_glbl_pll_cfg_3 {
                                                          For diagnostic use only.
                                                          0x0 = Add 25 uA.
                                                          0x1 = OFF (default).
-                                                         0x2 = Sink 25uA.
-                                                         0x3 = Sink 50uA. */
+                                                         0x2 = Sink 25 uA.
+                                                         0x3 = Sink 50 uA. */
 	uint64_t pll_bypass_uq                : 1;  /**< PLL bypass enable. When asserted, multiplexes in the feedback divider clock.
                                                          For diagnostic use only. */
 	uint64_t pll_vctrl_sel_ovrrd_en       : 1;  /**< Override enable for selecting current for Vctrl in open loop operation.
@@ -3834,6 +3928,7 @@ union cvmx_gserx_glbl_pll_cfg_3 {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} s;
+	struct cvmx_gserx_glbl_pll_cfg_3_s    cn73xx;
 	struct cvmx_gserx_glbl_pll_cfg_3_s    cn78xx;
 	struct cvmx_gserx_glbl_pll_cfg_3_s    cn78xxp2;
 	struct cvmx_gserx_glbl_pll_cfg_3_s    cnf75xx;
@@ -3930,10 +4025,10 @@ union cvmx_gserx_glbl_tad {
                                                          can be observed on DMON and DMONB
                                                          respectively.  sds_vss can be observed on AMON. GSER()_GLBL_TM_ADMON[AMON_ON]
                                                          must not be set.
-                                                         0x10: PLL_CLK 0 degree.
-                                                         0x11: Sds_tst_fb_clk.
-                                                         0x12: Buffered refclk.
-                                                         0x13: Div 8 of core clock (core_clk_out).
+                                                         0x10 = PLL_CLK 0 degree.
+                                                         0x11 = Sds_tst_fb_clk.
+                                                         0x12 = Buffered refclk.
+                                                         0x13 = Div 8 of core clock (core_clk_out).
                                                          0x14-0x1F: Reserved. */
 #else
 	uint64_t pcs_sds_tad_4_0              : 5;
@@ -4293,7 +4388,8 @@ union cvmx_gserx_lanex_pcs_ctlifc_0 {
 	uint64_t cfg_tx_vboost_en_ovrrd_val   : 1;  /**< Specifies TX VBOOST Enable request when its override bit
                                                          is asserted GSER()_LANE()_PCS_CTLIFC_2[CFG_TX_VBOOST_EN_OVRRD_EN]. */
 	uint64_t cfg_tx_coeff_req_ovrrd_val   : 1;  /**< Specifies TX Coefficient request when its override bit
-                                                         is asserted GSER()_LANE()_PCS_CTLIFC_2[CFG_TX_COEFF_REQ_OVRRD_EN]. */
+                                                         is asserted GSER()_LANE()_PCS_CTLIFC_2[CFG_TX_COEFF_REQ_OVRRD_EN].
+                                                         See GSER()_LANE()_PCS_CTLIFC_2[CTLIFC_OVRRD_REQ]. */
 	uint64_t cfg_rx_cdr_coast_req_ovrrd_val : 1;/**< Specifies RX CDR Coast request when its override bit
                                                          is asserted GSER()_LANE()_PCS_CTLIFC_2[CFG_RX_COAST_REQ_OVRRD_EN]. */
 	uint64_t cfg_tx_detrx_en_req_ovrrd_val : 1; /**< Specifies TX Detect RX request when its override bit
@@ -4399,12 +4495,19 @@ union cvmx_gserx_lanex_pcs_ctlifc_2 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t ctlifc_ovrrd_req             : 1;  /**< Writing to set this bit initiates a state machine interface request
                                                          for GSER()_LANE()_PCS_CTLIFC_0 and GSER()_LANE()_PCS_CTLIFC_1
-                                                         override values. */
+                                                         override values.
+                                                         [CTLIFC_OVRRD_REQ] should be written with a one (with
+                                                         [CFG_TX_COEFF_REQ_OVRRD_EN]=1 and
+                                                         GSER()_LANE()_PCS_CTLIFC_0[CFG_TX_COEFF_REQ_OVRRD_VAL]=1) to initiate
+                                                         a control interface configuration over-ride after manually programming
+                                                         transmitter settings. See GSER()_LANE()_TX_PRE_EMPHASIS[CFG_TX_PREMPTAP]
+                                                         and GSER()_LANE()_TX_CFG_0[CFG_TX_SWING]. */
 	uint64_t reserved_9_14                : 6;
 	uint64_t cfg_tx_vboost_en_ovrrd_en    : 1;  /**< Override mac_pcs_txX vboost_en signal with the value specified in
                                                          GSER()_LANE()_PCS_CTLIFC_2[CFG_TX_VBOOST_EN_OVRRD_VAL]. */
 	uint64_t cfg_tx_coeff_req_ovrrd_en    : 1;  /**< Override mac_pcs_txX_coeff_req signal with the value specified in
-                                                         GSER()_LANE()_PCS_CTLIFC_0[CFG_TX_COEFF_REQ_OVRRD_VAL]. */
+                                                         GSER()_LANE()_PCS_CTLIFC_0[CFG_TX_COEFF_REQ_OVRRD_VAL]. See
+                                                         [CTLIFC_OVRRD_REQ]. */
 	uint64_t cfg_rx_cdr_coast_req_ovrrd_en : 1; /**< Override mac_pcs_rxX_cdr_coast signal with the value specified in
                                                          GSER()_LANE()_PCS_CTLIFC_2[CFG_RX_COAST_REQ_OVRRD_VAL]. */
 	uint64_t cfg_tx_detrx_en_req_ovrrd_en : 1;  /**< Override mac_pcs_txX_detrx_en signal with the value specified in
@@ -4447,12 +4550,19 @@ union cvmx_gserx_lanex_pcs_ctlifc_2 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t ctlifc_ovrrd_req             : 1;  /**< Writing to set this bit initiates a state machine interface request
                                                          for GSER()_LANE()_PCS_CTLIFC_0 and GSER()_LANE()_PCS_CTLIFC_1
-                                                         override values. */
+                                                         override values.
+                                                         [CTLIFC_OVRRD_REQ] should be written with a one (with
+                                                         [CFG_TX_COEFF_REQ_OVRRD_EN]=1 and
+                                                         GSER()_LANE()_PCS_CTLIFC_0[CFG_TX_COEFF_REQ_OVRRD_VAL]=1) to initiate
+                                                         a control interface configuration over-ride after manually programming
+                                                         transmitter settings. See GSER()_LANE()_TX_PRE_EMPHASIS[CFG_TX_PREMPTAP]
+                                                         and GSER()_LANE()_TX_CFG_0[CFG_TX_SWING]. */
 	uint64_t reserved_14_9                : 6;
 	uint64_t cfg_tx_vboost_en_ovrrd_en    : 1;  /**< Override mac_pcs_txX vboost_en signal with the value specified in
                                                          GSER()_LANE()_PCS_CTLIFC_2[CFG_TX_VBOOST_EN_OVRRD_VAL]. */
 	uint64_t cfg_tx_coeff_req_ovrrd_en    : 1;  /**< Override mac_pcs_txX_coeff_req signal with the value specified in
-                                                         GSER()_LANE()_PCS_CTLIFC_0[CFG_TX_COEFF_REQ_OVRRD_VAL]. */
+                                                         GSER()_LANE()_PCS_CTLIFC_0[CFG_TX_COEFF_REQ_OVRRD_VAL]. See
+                                                         [CTLIFC_OVRRD_REQ]. */
 	uint64_t cfg_rx_cdr_coast_req_ovrrd_en : 1; /**< Override mac_pcs_rxX_cdr_coast signal with the value specified in
                                                          GSER()_LANE()_PCS_CTLIFC_2[CFG_RX_COAST_REQ_OVRRD_VAL]. */
 	uint64_t cfg_tx_detrx_en_req_ovrrd_en : 1;  /**< Override mac_pcs_txX_detrx_en signal with the value specified in
@@ -4573,9 +4683,9 @@ union cvmx_gserx_lanex_pwr_ctrl {
 	struct cvmx_gserx_lanex_pwr_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t tx_sds_fifo_reset_ovrrd_en   : 1;  /**< When asserted, TX_SDS_FIFO_RESET_OVVRD_VAL is used to specify the value of the reset
+	uint64_t tx_sds_fifo_reset_ovrrd_en   : 1;  /**< When asserted, TX_SDS_FIFO_RESET_OVRRD_VAL is used to specify the value of the reset
                                                          signal for the TX FIFO supplying data to the SerDes p2s interface. */
-	uint64_t tx_sds_fifo_reset_ovrrd_val  : 1;  /**< When asserted, TX_SDS_FIFO_RESET_OVVRD_EN is asserted, this field is
+	uint64_t tx_sds_fifo_reset_ovrrd_val  : 1;  /**< When asserted, TX_SDS_FIFO_RESET_OVRRD_EN is asserted, this field is
                                                          used to specify the value of the reset
                                                          signal for the TX FIFO supplying data to the SerDes p2s interface. */
 	uint64_t tx_pcs_reset_ovrrd_val       : 1;  /**< When TX_PCS_RESET_OVRRD_EN is
@@ -4637,9 +4747,9 @@ union cvmx_gserx_lanex_pwr_ctrl {
 	struct cvmx_gserx_lanex_pwr_ctrl_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t tx_sds_fifo_reset_ovrrd_en   : 1;  /**< When asserted, TX_SDS_FIFO_RESET_OVVRD_VAL is used to specify the value of the reset
+	uint64_t tx_sds_fifo_reset_ovrrd_en   : 1;  /**< When asserted, TX_SDS_FIFO_RESET_OVRRD_VAL is used to specify the value of the reset
                                                          signal for the TX FIFO supplying data to the SerDes p2s interface. */
-	uint64_t tx_sds_fifo_reset_ovrrd_val  : 1;  /**< When asserted, TX_SDS_FIFO_RESET_OVVRD_EN is asserted, this field is
+	uint64_t tx_sds_fifo_reset_ovrrd_val  : 1;  /**< When asserted, TX_SDS_FIFO_RESET_OVRRD_EN is asserted, this field is
                                                          used to specify the value of the reset
                                                          signal for the TX FIFO supplying data to the SerDes p2s interface. */
 	uint64_t tx_pcs_reset_ovrrd_val       : 1;  /**< When TX_PCS_RESET_OVRRD_EN is
@@ -4944,7 +5054,7 @@ union cvmx_gserx_lanex_rx_cfg_0 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t rx_datarate_ovrrd_en         : 1;  /**< Override enable for RX Power State Machine data rate signal. */
 	uint64_t reserved_14_14               : 1;
-	uint64_t rx_resetn_ovvrd_val          : 1;  /**< This value overrides the RX Power State machine rx_resetn control
+	uint64_t rx_resetn_ovrrd_val          : 1;  /**< This value overrides the RX Power State machine rx_resetn control
                                                          signal when GSER()_LANE()_PWR_CTRL[RX_RESETN_OVRRD_EN] is set. */
 	uint64_t pcs_sds_rx_eyemon_en         : 1;  /**< RX eyemon test enable. */
 	uint64_t pcs_sds_rx_pcm_ctrl          : 4;  /**< <11>: Reserved
@@ -4968,7 +5078,7 @@ union cvmx_gserx_lanex_rx_cfg_0 {
 	uint64_t rx_datarate_ovrrd_val        : 2;
 	uint64_t pcs_sds_rx_pcm_ctrl          : 4;
 	uint64_t pcs_sds_rx_eyemon_en         : 1;
-	uint64_t rx_resetn_ovvrd_val          : 1;
+	uint64_t rx_resetn_ovrrd_val          : 1;
 	uint64_t reserved_14_14               : 1;
 	uint64_t rx_datarate_ovrrd_en         : 1;
 	uint64_t reserved_16_63               : 48;
@@ -4979,7 +5089,7 @@ union cvmx_gserx_lanex_rx_cfg_0 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t rx_datarate_ovrrd_en         : 1;  /**< Override enable for RX Power State Machine data rate signal. */
 	uint64_t pcs_rx_tristate_enable       : 1;  /**< RX termination high-Z enable. */
-	uint64_t rx_resetn_ovvrd_val          : 1;  /**< This value overrides the RX Power State machine rx_resetn control
+	uint64_t rx_resetn_ovrrd_val          : 1;  /**< This value overrides the RX Power State machine rx_resetn control
                                                          signal when GSER()_LANE()_PWR_CTRL[RX_RESETN_OVRRD_EN] is set. */
 	uint64_t pcs_sds_rx_eyemon_en         : 1;  /**< RX eyemon test enable. */
 	uint64_t pcs_sds_rx_pcm_ctrl          : 4;  /**< <11>: Reserved
@@ -5003,7 +5113,7 @@ union cvmx_gserx_lanex_rx_cfg_0 {
 	uint64_t rx_datarate_ovrrd_val        : 2;
 	uint64_t pcs_sds_rx_pcm_ctrl          : 4;
 	uint64_t pcs_sds_rx_eyemon_en         : 1;
-	uint64_t rx_resetn_ovvrd_val          : 1;
+	uint64_t rx_resetn_ovrrd_val          : 1;
 	uint64_t pcs_rx_tristate_enable       : 1;
 	uint64_t rx_datarate_ovrrd_en         : 1;
 	uint64_t reserved_16_63               : 48;
@@ -5014,7 +5124,7 @@ union cvmx_gserx_lanex_rx_cfg_0 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t rx_datarate_ovrrd_en         : 1;  /**< Override enable for RX Power State Machine data rate signal. */
 	uint64_t pcs_sds_rx_tristate_enable   : 1;  /**< RX termination high-Z enable. */
-	uint64_t rx_resetn_ovvrd_val          : 1;  /**< This value overrides the RX Power State machine rx_resetn control
+	uint64_t rx_resetn_ovrrd_val          : 1;  /**< This value overrides the RX Power State machine rx_resetn control
                                                          signal when GSER()_LANE()_PWR_CTRL[RX_RESETN_OVRRD_EN] is set. */
 	uint64_t pcs_sds_rx_eyemon_en         : 1;  /**< RX eyemon test enable. */
 	uint64_t pcs_sds_rx_pcm_ctrl          : 4;  /**< <11>: Reserved
@@ -5038,7 +5148,7 @@ union cvmx_gserx_lanex_rx_cfg_0 {
 	uint64_t rx_datarate_ovrrd_val        : 2;
 	uint64_t pcs_sds_rx_pcm_ctrl          : 4;
 	uint64_t pcs_sds_rx_eyemon_en         : 1;
-	uint64_t rx_resetn_ovvrd_val          : 1;
+	uint64_t rx_resetn_ovrrd_val          : 1;
 	uint64_t pcs_sds_rx_tristate_enable   : 1;
 	uint64_t rx_datarate_ovrrd_en         : 1;
 	uint64_t reserved_16_63               : 48;
@@ -5063,11 +5173,11 @@ union cvmx_gserx_lanex_rx_cfg_1 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t rx_chpd_ovrrd_val            : 1;  /**< Not supported. */
 	uint64_t pcs_sds_rx_os_men            : 1;  /**< RX Offset manual enable. */
-	uint64_t eie_en_ovvrd_en              : 1;  /**< Override enable for Electrical-Idle-Exit circuit. */
-	uint64_t eie_en_ovvrd_val             : 1;  /**< Override value for Electrical-Idle-Exit circuit. */
+	uint64_t eie_en_ovrrd_en              : 1;  /**< Override enable for Electrical-Idle-Exit circuit. */
+	uint64_t eie_en_ovrrd_val             : 1;  /**< Override value for Electrical-Idle-Exit circuit. */
 	uint64_t reserved_11_11               : 1;
-	uint64_t rx_pcie_mode_ovvrd_en        : 1;  /**< Override enable for RX_PCIE_MODE_OVVRD_VAL. */
-	uint64_t rx_pcie_mode_ovvrd_val       : 1;  /**< Override value for RX_PCIE_MODE_OVVRD_VAL;
+	uint64_t rx_pcie_mode_ovrrd_en        : 1;  /**< Override enable for RX_PCIE_MODE_OVRRD_VAL. */
+	uint64_t rx_pcie_mode_ovrrd_val       : 1;  /**< Override value for RX_PCIE_MODE_OVRRD_VAL;
                                                          selects between RX terminations.
                                                          0x0 = pcs_sds_rx_terminate_to_vdda.
                                                          0x1 = VDDA. */
@@ -5081,11 +5191,11 @@ union cvmx_gserx_lanex_rx_cfg_1 {
 #else
 	uint64_t pcs_sds_rx_cdr_ssc_mode      : 8;
 	uint64_t cfg_rx_dll_locken            : 1;
-	uint64_t rx_pcie_mode_ovvrd_val       : 1;
-	uint64_t rx_pcie_mode_ovvrd_en        : 1;
+	uint64_t rx_pcie_mode_ovrrd_val       : 1;
+	uint64_t rx_pcie_mode_ovrrd_en        : 1;
 	uint64_t reserved_11_11               : 1;
-	uint64_t eie_en_ovvrd_val             : 1;
-	uint64_t eie_en_ovvrd_en              : 1;
+	uint64_t eie_en_ovrrd_val             : 1;
+	uint64_t eie_en_ovrrd_en              : 1;
 	uint64_t pcs_sds_rx_os_men            : 1;
 	uint64_t rx_chpd_ovrrd_val            : 1;
 	uint64_t reserved_16_63               : 48;
@@ -5118,26 +5228,26 @@ union cvmx_gserx_lanex_rx_cfg_2 {
 	uint64_t pcs_sds_rx_sampler_boost_en  : 1;  /**< Faster sampler c2q.
                                                          For diagnostic use only. */
 	uint64_t reserved_10_10               : 1;
-	uint64_t rx_sds_rx_agc_mval           : 10; /**< AGC manual value used when GSERX_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL]
+	uint64_t rx_sds_rx_agc_mval           : 10; /**< AGC manual value used when GSERX_LANE()_RX_CFG_5[RX_AGC_MEN_OVRRD_EN,RX_AGC_MEN_OVRRD_VAL]
                                                          are set.
                                                          <9:8>: Reserved.
                                                          <7:4>: Pre-CTLE (continuous time linear equalizer) gain (steps of approximately 0.75dB):
-                                                         - 0x0 = -6dB
-                                                         - 0x1 = -5dB
-                                                         - 0xF = +5dB.
+                                                         _ 0x0 = -6dB
+                                                         _ 0x1 = -5dB
+                                                         _ 0xF = +5dB.
                                                          <3:0>: Post-CTLE gain (steps of 0.0875):
-                                                         - 0x0 = lowest
-                                                         - 0xf = lowest * 2.3125.
+                                                         _ 0x0 = lowest
+                                                         _ 0xF = lowest * 2.3125.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <
                                                          5Gbaud, pre-CTLE, post-CTLE, and peaking control settings should be manually
-                                                         configured. GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL]
+                                                         configured. GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVRRD_EN,RX_AGC_MEN_OVRRD_VAL]
                                                          should both be set, [RX_SDS_RX_AGC_MVAL] has the pre and post settings,
                                                          and GSER()_LANE()_RX_CTLE_CTRL[PCS_SDS_RX_CTLE_ZERO] controls equalizer
                                                          peaking.
                                                          The [RX_SDS_RX_AGC_MVAL] settings should be derived from signal integrity
                                                          simulations with the IBIS-AMI model supplied by Cavium when
-                                                         GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL] are set.
+                                                         GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVRRD_EN,RX_AGC_MEN_OVRRD_VAL] are set.
                                                          INTERNAL: reset value may be reasonable default settings. */
 #else
 	uint64_t rx_sds_rx_agc_mval           : 10;
@@ -5243,33 +5353,33 @@ union cvmx_gserx_lanex_rx_cfg_5 {
 	struct cvmx_gserx_lanex_rx_cfg_5_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t rx_agc_men_ovvrd_en          : 1;  /**< Override enable for AGC manual mode.
+	uint64_t rx_agc_men_ovrrd_en          : 1;  /**< Override enable for AGC manual mode.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <
                                                          5Gbaud, pre-CTLE, post-CTLE, and peaking control settings should be manually
-                                                         configured. [RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL] should both be set,
+                                                         configured. [RX_AGC_MEN_OVRRD_EN,RX_AGC_MEN_OVRRD_VAL] should both be set,
                                                          GSER()_LANE()_RX_CFG_2[RX_SDS_RX_AGC_MVAL] has the pre and post settings,
                                                          and GSER()_LANE()_RX_CTLE_CTRL[PCS_SDS_RX_CTLE_ZERO] controls equalizer
                                                          peaking. */
-	uint64_t rx_agc_men_ovvrd_val         : 1;  /**< Override value for AGC manual mode.
+	uint64_t rx_agc_men_ovrrd_val         : 1;  /**< Override value for AGC manual mode.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <
                                                          5Gbaud, pre-CTLE, post-CTLE, and peaking control settings should be manually
-                                                         configured. [RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL] should both be set,
+                                                         configured. [RX_AGC_MEN_OVRRD_EN,RX_AGC_MEN_OVRRD_VAL] should both be set,
                                                          GSER()_LANE()_RX_CFG_2[RX_SDS_RX_AGC_MVAL] has the pre and post settings,
                                                          and GSER()_LANE()_RX_CTLE_CTRL[PCS_SDS_RX_CTLE_ZERO] controls equalizer
                                                          peaking. */
-	uint64_t rx_widthsel_ovvrd_en         : 1;  /**< Override enable for RX width select to the SerDes pcs_sds_rx_widthsel. */
-	uint64_t rx_widthsel_ovvrd_val        : 2;  /**< Override value for RX width select to the SerDes pcs_sds_rx_widthsel.
+	uint64_t rx_widthsel_ovrrd_en         : 1;  /**< Override enable for RX width select to the SerDes pcs_sds_rx_widthsel. */
+	uint64_t rx_widthsel_ovrrd_val        : 2;  /**< Override value for RX width select to the SerDes pcs_sds_rx_widthsel.
                                                          0x0 = 8-bit raw data.
                                                          0x1 = 10-bit raw data.
                                                          0x2 = 16-bit raw data.
                                                          0x3 = 20-bit raw data. */
 #else
-	uint64_t rx_widthsel_ovvrd_val        : 2;
-	uint64_t rx_widthsel_ovvrd_en         : 1;
-	uint64_t rx_agc_men_ovvrd_val         : 1;
-	uint64_t rx_agc_men_ovvrd_en          : 1;
+	uint64_t rx_widthsel_ovrrd_val        : 2;
+	uint64_t rx_widthsel_ovrrd_en         : 1;
+	uint64_t rx_agc_men_ovrrd_val         : 1;
+	uint64_t rx_agc_men_ovrrd_en          : 1;
 	uint64_t reserved_5_63                : 59;
 #endif
 	} s;
@@ -5299,9 +5409,9 @@ union cvmx_gserx_lanex_rx_ctle_ctrl {
                                                          0x3 = +10%. */
 	uint64_t pcs_sds_rx_ctle_zero         : 4;  /**< Equalizer peaking control.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <
                                                          5Gbaud, pre-CTLE, post-CTLE, and peaking control settings should be manually
-                                                         configured. GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVVRD_EN,RX_AGC_MEN_OVVRD_VAL]
+                                                         configured. GSER()_LANE()_RX_CFG_5[RX_AGC_MEN_OVRRD_EN,RX_AGC_MEN_OVRRD_VAL]
                                                          should both be set, GSER()_LANE()_RX_CFG_2[RX_SDS_RX_AGC_MVAL] has the
                                                          pre and post settings, and [PCS_SDS_RX_CTLE_ZERO] controls equalizer
                                                          peaking.
@@ -5364,7 +5474,17 @@ union cvmx_gserx_lanex_rx_loop_ctrl {
                                                          <7> = ofst_cncl_rstn_byp.
                                                          <8> = lctrl_men.
                                                          <9> = Reserved.
-                                                         GSER()_LANE()_PWR_CTRL[RX_LCTRL_OVRRD_EN] controls <9:7> and <3:0>. */
+                                                         GSER()_LANE()_PWR_CTRL[RX_LCTRL_OVRRD_EN] controls <9:7> and <3:0>.
+                                                         Recommended settings:
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
+                                                         5Gbaud, the DFE should be completely disabled by setting all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL],
+                                                         setting [CFG_RX_LCTRL<8>], clearing [CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER(0..6)_LANE(0..3)_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,
+                                                         DFE_C4_MVAL,DFE_C4_MSGN], and clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
+                                                         DFE_C1_MVAL,DFE_C1_MSGN]. */
 #else
 	uint64_t cfg_rx_lctrl                 : 10;
 	uint64_t fast_ofst_cncl               : 1;
@@ -5397,17 +5517,17 @@ union cvmx_gserx_lanex_rx_misc_ovrrd {
                                                          Detect Enable. */
 	uint64_t cfg_rx_eie_det_ovrrd_en      : 1;  /**< Override enable for RX Electrical-Idle-Exit
                                                          Detect Enable. */
-	uint64_t cfg_rx_cdr_ctrl_ovvrd_en     : 1;  /**< Not supported. */
+	uint64_t cfg_rx_cdr_ctrl_ovrrd_en     : 1;  /**< Not supported. */
 	uint64_t cfg_rx_eq_eval_ovrrd_val     : 1;  /**< Training mode control in override mode. */
 	uint64_t cfg_rx_eq_eval_ovrrd_en      : 1;  /**< Override enable for RX-EQ Eval
                                                          When asserted, training mode is controlled by
                                                          CFG_RX_EQ_EVAL_OVRRD_VAL. */
 	uint64_t reserved_6_6                 : 1;
-	uint64_t cfg_rx_dll_locken_ovvrd_en   : 1;  /**< When asserted, override DLL lock enable
+	uint64_t cfg_rx_dll_locken_ovrrd_en   : 1;  /**< When asserted, override DLL lock enable
                                                          signal from the RX Power State machine with
                                                          CFG_RX_DLL_LOCKEN in register
                                                          GSER()_LANE()_RX_CFG_1. */
-	uint64_t cfg_rx_errdet_ctrl_ovvrd_en  : 1;  /**< When asserted, pcs_sds_rx_err_det_ctrl is set
+	uint64_t cfg_rx_errdet_ctrl_ovrrd_en  : 1;  /**< When asserted, pcs_sds_rx_err_det_ctrl is set
                                                          to cfg_rx_errdet_ctrl in registers
                                                          GSER()_LANE()_RX_CFG_3 and GSER()_LANE()_RX_CFG_4. */
 	uint64_t reserved_1_3                 : 3;
@@ -5416,12 +5536,12 @@ union cvmx_gserx_lanex_rx_misc_ovrrd {
 #else
 	uint64_t cfg_rxeq_eval_restore_en     : 1;
 	uint64_t reserved_1_3                 : 3;
-	uint64_t cfg_rx_errdet_ctrl_ovvrd_en  : 1;
-	uint64_t cfg_rx_dll_locken_ovvrd_en   : 1;
+	uint64_t cfg_rx_errdet_ctrl_ovrrd_en  : 1;
+	uint64_t cfg_rx_dll_locken_ovrrd_en   : 1;
 	uint64_t reserved_6_6                 : 1;
 	uint64_t cfg_rx_eq_eval_ovrrd_en      : 1;
 	uint64_t cfg_rx_eq_eval_ovrrd_val     : 1;
-	uint64_t cfg_rx_cdr_ctrl_ovvrd_en     : 1;
+	uint64_t cfg_rx_cdr_ctrl_ovrrd_en     : 1;
 	uint64_t cfg_rx_eie_det_ovrrd_en      : 1;
 	uint64_t cfg_rx_eie_det_ovrrd_val     : 1;
 	uint64_t cfg_rx_oob_clk_en_ovrrd_en   : 1;
@@ -5438,17 +5558,17 @@ union cvmx_gserx_lanex_rx_misc_ovrrd {
                                                          Detect Enable. */
 	uint64_t cfg_rx_eie_det_ovrrd_en      : 1;  /**< Override enable for RX Electrical-Idle-Exit
                                                          Detect Enable. */
-	uint64_t cfg_rx_cdr_ctrl_ovvrd_en     : 1;  /**< Not supported. */
+	uint64_t cfg_rx_cdr_ctrl_ovrrd_en     : 1;  /**< Not supported. */
 	uint64_t cfg_rx_eq_eval_ovrrd_val     : 1;  /**< Training mode control in override mode. */
 	uint64_t cfg_rx_eq_eval_ovrrd_en      : 1;  /**< Override enable for RX-EQ Eval
                                                          When asserted, training mode is controlled by
                                                          CFG_RX_EQ_EVAL_OVRRD_VAL. */
 	uint64_t reserved_6_6                 : 1;
-	uint64_t cfg_rx_dll_locken_ovvrd_en   : 1;  /**< When asserted, override DLL lock enable
+	uint64_t cfg_rx_dll_locken_ovrrd_en   : 1;  /**< When asserted, override DLL lock enable
                                                          signal from the RX Power State machine with
                                                          CFG_RX_DLL_LOCKEN in register
                                                          GSER()_LANE()_RX_CFG_1. */
-	uint64_t cfg_rx_errdet_ctrl_ovvrd_en  : 1;  /**< When asserted, pcs_sds_rx_err_det_ctrl is set
+	uint64_t cfg_rx_errdet_ctrl_ovrrd_en  : 1;  /**< When asserted, pcs_sds_rx_err_det_ctrl is set
                                                          to cfg_rx_errdet_ctrl in registers
                                                          GSER()_LANE()_RX_CFG_3 and GSER()_LANE()_RX_CFG_4. */
 	uint64_t reserved_3_1                 : 3;
@@ -5457,12 +5577,12 @@ union cvmx_gserx_lanex_rx_misc_ovrrd {
 #else
 	uint64_t cfg_rxeq_eval_restore_en     : 1;
 	uint64_t reserved_3_1                 : 3;
-	uint64_t cfg_rx_errdet_ctrl_ovvrd_en  : 1;
-	uint64_t cfg_rx_dll_locken_ovvrd_en   : 1;
+	uint64_t cfg_rx_errdet_ctrl_ovrrd_en  : 1;
+	uint64_t cfg_rx_dll_locken_ovrrd_en   : 1;
 	uint64_t reserved_6_6                 : 1;
 	uint64_t cfg_rx_eq_eval_ovrrd_en      : 1;
 	uint64_t cfg_rx_eq_eval_ovrrd_val     : 1;
-	uint64_t cfg_rx_cdr_ctrl_ovvrd_en     : 1;
+	uint64_t cfg_rx_cdr_ctrl_ovrrd_en     : 1;
 	uint64_t cfg_rx_eie_det_ovrrd_en      : 1;
 	uint64_t cfg_rx_eie_det_ovrrd_val     : 1;
 	uint64_t cfg_rx_oob_clk_en_ovrrd_en   : 1;
@@ -5479,28 +5599,28 @@ union cvmx_gserx_lanex_rx_misc_ovrrd {
                                                          Detect Enable. */
 	uint64_t cfg_rx_eie_det_ovrrd_en      : 1;  /**< Override enable for RX Electrical-Idle-Exit
                                                          Detect Enable. */
-	uint64_t cfg_rx_cdr_ctrl_ovvrd_en     : 1;  /**< Not supported. */
+	uint64_t cfg_rx_cdr_ctrl_ovrrd_en     : 1;  /**< Not supported. */
 	uint64_t cfg_rx_eq_eval_ovrrd_val     : 1;  /**< Training mode control in override mode. */
 	uint64_t cfg_rx_eq_eval_ovrrd_en      : 1;  /**< Override enable for RX-EQ Eval
                                                          When asserted, training mode is controlled by
                                                          CFG_RX_EQ_EVAL_OVRRD_VAL. */
 	uint64_t reserved_6_6                 : 1;
-	uint64_t cfg_rx_dll_locken_ovvrd_en   : 1;  /**< When asserted, override DLL lock enable
+	uint64_t cfg_rx_dll_locken_ovrrd_en   : 1;  /**< When asserted, override DLL lock enable
                                                          signal from the RX Power State machine with
                                                          CFG_RX_DLL_LOCKEN in register
                                                          GSER()_LANE()_RX_CFG_1. */
-	uint64_t cfg_rx_errdet_ctrl_ovvrd_en  : 1;  /**< When asserted, pcs_sds_rx_err_det_ctrl is set
+	uint64_t cfg_rx_errdet_ctrl_ovrrd_en  : 1;  /**< When asserted, pcs_sds_rx_err_det_ctrl is set
                                                          to cfg_rx_errdet_ctrl in registers
                                                          GSER()_LANE()_RX_CFG_3 and GSER()_LANE()_RX_CFG_4. */
 	uint64_t reserved_0_3                 : 4;
 #else
 	uint64_t reserved_0_3                 : 4;
-	uint64_t cfg_rx_errdet_ctrl_ovvrd_en  : 1;
-	uint64_t cfg_rx_dll_locken_ovvrd_en   : 1;
+	uint64_t cfg_rx_errdet_ctrl_ovrrd_en  : 1;
+	uint64_t cfg_rx_dll_locken_ovrrd_en   : 1;
 	uint64_t reserved_6_6                 : 1;
 	uint64_t cfg_rx_eq_eval_ovrrd_en      : 1;
 	uint64_t cfg_rx_eq_eval_ovrrd_val     : 1;
-	uint64_t cfg_rx_cdr_ctrl_ovvrd_en     : 1;
+	uint64_t cfg_rx_cdr_ctrl_ovrrd_en     : 1;
 	uint64_t cfg_rx_eie_det_ovrrd_en      : 1;
 	uint64_t cfg_rx_eie_det_ovrrd_val     : 1;
 	uint64_t cfg_rx_oob_clk_en_ovrrd_en   : 1;
@@ -5593,41 +5713,49 @@ union cvmx_gserx_lanex_rx_valbbd_ctrl_0 {
 	uint64_t dfe_c5_mval                  : 4;  /**< DFE Tap5 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN] and clearing all of
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN], and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c5_msgn                  : 1;  /**< DFE Tap5 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN] and clearing all of
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN], and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c4_mval                  : 4;  /**< DFE Tap4 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN] and clearing all of
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN], and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c4_msgn                  : 1;  /**< DFE Tap4 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN] and clearing all of
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         [DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,DFE_C4_MSGN], and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 #else
@@ -5661,61 +5789,73 @@ union cvmx_gserx_lanex_rx_valbbd_ctrl_1 {
 	uint64_t dfe_c3_mval                  : 4;  /**< DFE Tap3 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN],
                                                          and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c3_msgn                  : 1;  /**< DFE Tap3 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN],
                                                          and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c2_mval                  : 4;  /**< DFE Tap2 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN],
                                                          and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c2_msgn                  : 1;  /**< DFE Tap2 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN],
                                                          and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c1_mval                  : 4;  /**< DFE Tap1 manual value when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN],
                                                          and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c1_msgn                  : 1;  /**< DFE Tap1 manual sign when GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN] and
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_C5_OVRD_VAL] are both set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_2[DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,
-                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN]
+                                                         DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL,FE_C4_MSGN],
                                                          and clearing all of [DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 #else
@@ -5751,61 +5891,73 @@ union cvmx_gserx_lanex_rx_valbbd_ctrl_2 {
                                                          used for controlling the DFE tap manual mode, instead the manual mode signal indexed by
                                                          GSER()_LANE_MODE[LMODE].
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
-                                                         DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN],
                                                          and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c5_ovrd_val              : 1;  /**< Override value for DFE Tap5 manual enable. Used when [DFE_OVRD_EN] is set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
-                                                         DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN],
                                                          and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c4_ovrd_val              : 1;  /**< Override value for DFE Tap4 manual enable. Used when [DFE_OVRD_EN] is set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
-                                                         DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN],
                                                          and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c3_ovrd_val              : 1;  /**< Override value for DFE Tap3 manual enable. Used when [DFE_OVRD_EN] is set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
-                                                         DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN],
                                                          and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c2_ovrd_val              : 1;  /**< Override value for DFE Tap2 manual enable. Used when [DFE_OVRD_EN] is set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
-                                                         DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN],
                                                          and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
 	uint64_t dfe_c1_ovrd_val              : 1;  /**< Override value for DFE Tap1 manual enable. Used when [DFE_OVRD_EN] is set.
                                                          Recommended settings:
-                                                         When auto-negotiated link training is not present and link speed <=
+                                                         When auto-negotiated link training is not present, non-PCIe, and link speed <=
                                                          5Gbaud, the DFE should be completely disabled by setting all of
                                                          [DFE_OVRD_EN,DFE_C5_OVRD_VAL,DFE_C4_OVRD_VAL,DFE_C3_OVRD_VAL,DFE_C2_OVRD_VAL,
-                                                         DFE_C1_OVRD_VAL] and clearing all of
-                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN]
+                                                         DFE_C1_OVRD_VAL], setting
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<8>], clearing
+                                                         GSER()_LANE()_RX_LOOP_CTRL[CFG_RX_LCTRL<1>], clearing all of
+                                                         GSER()_LANE()_RX_VALBBD_CTRL_0[DFE_C5_MVAL,DFE_C5_MSGN,DFE_C4_MVAL, FE_C4_MSGN],
                                                          and clearing all of
                                                          GSER()_LANE()_RX_VALBBD_CTRL_1[DFE_C3_MVAL,DFE_C3_MSGN,DFE_C2_MVAL,DFE_C2_MSGN,
                                                          DFE_C1_MVAL,DFE_C1_MSGN]. */
@@ -6100,10 +6252,13 @@ union cvmx_gserx_lanex_tx_cfg_0 {
 	struct cvmx_gserx_lanex_tx_cfg_0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t tx_tristate_en_ovrd_val      : 1;  /**< TX termination high-Z enable. */
-	uint64_t tx_chpd_ovrd_val             : 1;  /**< TX lane power down. */
+	uint64_t tx_tristate_en_ovrrd_val     : 1;  /**< TX termination high-Z enable. Override value when
+                                                         GSER()_LANE()_PWR_CTRL[TX_TRISTATE_EN_OVRRD_EN] is set. */
+	uint64_t tx_chpd_ovrrd_val            : 1;  /**< TX lane power down. Active high. Override value when
+                                                         GSER()_LANE()_PWR_CTRL[TX_PD_OVRRD_EN] is set. */
 	uint64_t reserved_10_13               : 4;
-	uint64_t tx_resetn_ovrd_val           : 1;  /**< TX P2S rest. */
+	uint64_t tx_resetn_ovrrd_val          : 1;  /**< TX P2S reset. Active high. Override value when
+                                                         GSER()_LANE()_PWR_CTRL[TX_P2S_RESET_OVRRD_EN] is set. */
 	uint64_t tx_cm_mode                   : 1;  /**< Assert to enable fast Common-Mode charge up. For simulation purposes only. */
 	uint64_t cfg_tx_swing                 : 5;  /**< TX output swing control.
                                                          Default swing encoding when GSER()_LANE()_TX_CFG_1[TX_SWING_OVRRD_EN] is
@@ -6111,8 +6266,10 @@ union cvmx_gserx_lanex_tx_cfg_0 {
                                                          Recommended settings:
                                                          When auto-negotiated link training is not present, including XFI and all
                                                          protocols <= 6.25Gbaud except PCIe, the transmit swing should be manually
-                                                         over-ridden. GSER()_LANE()_TX_CFG_1[TX_SWING_OVRD_EN] should be set
-                                                         and [CFG_TX_SWING] configures the swing.
+                                                         over-ridden. GSER()_LANE()_TX_CFG_1[TX_SWING_OVRRD_EN] should be set
+                                                         and [CFG_TX_SWING] configures the swing. A transmit swing change should be
+                                                         followed by a control interface configuration over-ride to force the
+                                                         new setting - see GSER()_LANE()_PCS_CTLIFC_2[CTLIFC_OVRRD_REQ].
                                                          [CFG_TX_SWING] should be derived from signal integrity simulations
                                                          with the IBIS-AMI model supplied by Cavium when auto-negotiated link
                                                          training is not present and link speed <= 6.25Gbaud.
@@ -6132,20 +6289,23 @@ union cvmx_gserx_lanex_tx_cfg_0 {
 	uint64_t fast_rdet_mode               : 1;
 	uint64_t cfg_tx_swing                 : 5;
 	uint64_t tx_cm_mode                   : 1;
-	uint64_t tx_resetn_ovrd_val           : 1;
+	uint64_t tx_resetn_ovrrd_val          : 1;
 	uint64_t reserved_10_13               : 4;
-	uint64_t tx_chpd_ovrd_val             : 1;
-	uint64_t tx_tristate_en_ovrd_val      : 1;
+	uint64_t tx_chpd_ovrrd_val            : 1;
+	uint64_t tx_tristate_en_ovrrd_val     : 1;
 	uint64_t reserved_16_63               : 48;
 #endif
 	} s;
 	struct cvmx_gserx_lanex_tx_cfg_0_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t tx_tristate_en_ovrd_val      : 1;  /**< TX termination high-Z enable. */
-	uint64_t tx_chpd_ovrd_val             : 1;  /**< TX lane power down. */
+	uint64_t tx_tristate_en_ovrrd_val     : 1;  /**< TX termination high-Z enable. Override value when
+                                                         GSER()_LANE()_PWR_CTRL[TX_TRISTATE_EN_OVRRD_EN] is set. */
+	uint64_t tx_chpd_ovrrd_val            : 1;  /**< TX lane power down. Active high. Override value when
+                                                         GSER()_LANE()_PWR_CTRL[TX_PD_OVRRD_EN] is set. */
 	uint64_t reserved_13_10               : 4;
-	uint64_t tx_resetn_ovrd_val           : 1;  /**< TX P2S rest. */
+	uint64_t tx_resetn_ovrrd_val          : 1;  /**< TX P2S reset. Active high. Override value when
+                                                         GSER()_LANE()_PWR_CTRL[TX_P2S_RESET_OVRRD_EN] is set. */
 	uint64_t tx_cm_mode                   : 1;  /**< Assert to enable fast Common-Mode charge up. For simulation purposes only. */
 	uint64_t cfg_tx_swing                 : 5;  /**< TX output swing control.
                                                          Default swing encoding when GSER()_LANE()_TX_CFG_1[TX_SWING_OVRRD_EN] is
@@ -6153,8 +6313,10 @@ union cvmx_gserx_lanex_tx_cfg_0 {
                                                          Recommended settings:
                                                          When auto-negotiated link training is not present, including XFI and all
                                                          protocols <= 6.25Gbaud except PCIe, the transmit swing should be manually
-                                                         over-ridden. GSER()_LANE()_TX_CFG_1[TX_SWING_OVRD_EN] should be set
-                                                         and [CFG_TX_SWING] configures the swing.
+                                                         over-ridden. GSER()_LANE()_TX_CFG_1[TX_SWING_OVRRD_EN] should be set
+                                                         and [CFG_TX_SWING] configures the swing. A transmit swing change should be
+                                                         followed by a control interface configuration over-ride to force the
+                                                         new setting - see GSER()_LANE()_PCS_CTLIFC_2[CTLIFC_OVRRD_REQ].
                                                          [CFG_TX_SWING] should be derived from signal integrity simulations
                                                          with the IBIS-AMI model supplied by Cavium when auto-negotiated link
                                                          training is not present and link speed <= 6.25Gbaud.
@@ -6174,10 +6336,10 @@ union cvmx_gserx_lanex_tx_cfg_0 {
 	uint64_t fast_rdet_mode               : 1;
 	uint64_t cfg_tx_swing                 : 5;
 	uint64_t tx_cm_mode                   : 1;
-	uint64_t tx_resetn_ovrd_val           : 1;
+	uint64_t tx_resetn_ovrrd_val          : 1;
 	uint64_t reserved_13_10               : 4;
-	uint64_t tx_chpd_ovrd_val             : 1;
-	uint64_t tx_tristate_en_ovrd_val      : 1;
+	uint64_t tx_chpd_ovrrd_val            : 1;
+	uint64_t tx_tristate_en_ovrrd_val     : 1;
 	uint64_t reserved_16_63               : 48;
 #endif
 	} cn73xx;
@@ -6199,59 +6361,63 @@ union cvmx_gserx_lanex_tx_cfg_1 {
 	struct cvmx_gserx_lanex_tx_cfg_1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t tx_widthsel_ovrd_en          : 1;  /**< Override enable for pcs_sds_txX_widthsel, TX parallel interface width setting. */
-	uint64_t tx_widthsel_ovrd_val         : 2;  /**< Override value for pcs_sds_widthsel, TX parallel interface width setting.
+	uint64_t tx_widthsel_ovrrd_en         : 1;  /**< Override enable for pcs_sds_txX_widthsel, TX parallel interface width setting. */
+	uint64_t tx_widthsel_ovrrd_val        : 2;  /**< Override value for pcs_sds_widthsel, TX parallel interface width setting.
                                                          0x0 = 8-bit (not supported).
                                                          0x1 = 10-bit (not supported).
                                                          0x2 = 16-bit (for PCIe Gen3 8Gb only).
                                                          0x3 = 20-bit. */
 	uint64_t tx_vboost_en_ovrrd_en        : 1;  /**< Override enable for pcs_sds_txX_vboost_en, TX  vboost mode enable. */
 	uint64_t tx_turbo_en_ovrrd_en         : 1;  /**< Override enable for pcs_sds_txX_turbo_en, Turbo mode enable. */
-	uint64_t tx_swing_ovrd_en             : 1;  /**< Override enable for pcs_sds_txX_swing, TX swing.
+	uint64_t tx_swing_ovrrd_en            : 1;  /**< Override enable for pcs_sds_txX_swing, TX swing.
                                                          Recommended settings:
                                                          When auto-negotiated link training is not present, including XFI and all
                                                          protocols <= 6.25Gbaud except PCIe, the transmit swing should be manually
-                                                         over-ridden. [TX_SWING_OVRD_EN] should be set and
-                                                         GSER()_LANE()_TX_CFG_0[CFG_TX_SWING] configures the swing. */
-	uint64_t tx_premptap_ovrd_val         : 1;  /**< Override enable for pcs_sds_txX_preemptap, preemphasis control.
+                                                         over-ridden. [TX_SWING_OVRRD_EN] should be set and
+                                                         GSER()_LANE()_TX_CFG_0[CFG_TX_SWING] configures the swing. A transmit swing
+                                                         change should be followed by a control interface configuration over-ride to
+                                                         force the new setting - see GSER()_LANE()_PCS_CTLIFC_2[CTLIFC_OVRRD_REQ]. */
+	uint64_t tx_premptap_ovrrd_val        : 1;  /**< Override enable for pcs_sds_txX_preemptap, preemphasis control.
                                                          Recommended settings:
                                                          When auto-negotiated link training is not present, including XFI and all
                                                          protocols <= 6.25Gbaud except PCIe, the transmit preemphasis pre and post
-                                                         cursor values should be manually over-ridden.  [TX_PREMPTAP_OVRD_VAL] should
+                                                         cursor values should be manually over-ridden.  [TX_PREMPTAP_OVRRD_VAL] should
                                                          be set and GSER()_LANE()_TX_PRE_EMPHASIS[CFG_TX_PREMPTAP] has the pre and post
-                                                         cursor values. */
+                                                         cursor values. A preemphasis control change should be followed by a control
+                                                         interface configuration over-ride to force the new setting - see
+                                                         GSER()_LANE()_PCS_CTLIFC_2[CTLIFC_OVRRD_REQ]. */
 	uint64_t tx_elec_idle_ovrrd_en        : 1;  /**< Override enable for pcs_sds_txX_elec_idle, TX electrical idle. */
-	uint64_t smpl_rate_ovrd_en            : 1;  /**< Override enable for TX Power state machine sample rate. When asserted, the TX sample is
-                                                         specified from SMPL_RATE_OVRD_VAL and the TX Power state machine control signal is
+	uint64_t smpl_rate_ovrrd_en           : 1;  /**< Override enable for TX Power state machine sample rate. When asserted, the TX sample is
+                                                         specified from SMPL_RATE_OVRRD_VAL and the TX Power state machine control signal is
                                                          ignored. */
-	uint64_t smpl_rate_ovrd_val           : 3;  /**< Specifies the sample rate (strobe assertion) relative to mac_pcs_txX_clk when
-                                                         SMPL_RATE_OVRD_EN is asserted.
+	uint64_t smpl_rate_ovrrd_val          : 3;  /**< Specifies the sample rate (strobe assertion) relative to mac_pcs_txX_clk when
+                                                         SMPL_RATE_OVRRD_EN is asserted.
                                                          0x0 = full rate.
                                                          0x1 = 1/2 data rate.
                                                          0x2 = 1/4 data rate.
                                                          0x3 = 1/8 data rate.
                                                          0x4 = 1/18 data rate.
                                                          0x5-7 = Reserved. */
-	uint64_t tx_datarate_ovrd_en          : 1;  /**< Override enable for RX Power state machine data rate signal. When set, rx_datarate is
-                                                         specified from TX_DATA_RATE_OVRD_VAL and the RX Power State Machine control signal is
+	uint64_t tx_datarate_ovrrd_en         : 1;  /**< Override enable for RX Power state machine data rate signal. When set, rx_datarate is
+                                                         specified from TX_DATA_RATE_OVRRD_VAL and the RX Power State Machine control signal is
                                                          ignored. */
-	uint64_t tx_datarate_ovrd_val         : 2;  /**< Specifies the TX data rate when TX_DATARATE_OVRD_EN is asserted.
+	uint64_t tx_datarate_ovrrd_val        : 2;  /**< Specifies the TX data rate when TX_DATARATE_OVRRD_EN is asserted.
                                                          0x0 = full rate.
                                                          0x1 = 1/2 data rate.
                                                          0x2 = 1/4 data rate.
                                                          0x3 = 1/8 data rate. */
 #else
-	uint64_t tx_datarate_ovrd_val         : 2;
-	uint64_t tx_datarate_ovrd_en          : 1;
-	uint64_t smpl_rate_ovrd_val           : 3;
-	uint64_t smpl_rate_ovrd_en            : 1;
+	uint64_t tx_datarate_ovrrd_val        : 2;
+	uint64_t tx_datarate_ovrrd_en         : 1;
+	uint64_t smpl_rate_ovrrd_val          : 3;
+	uint64_t smpl_rate_ovrrd_en           : 1;
 	uint64_t tx_elec_idle_ovrrd_en        : 1;
-	uint64_t tx_premptap_ovrd_val         : 1;
-	uint64_t tx_swing_ovrd_en             : 1;
+	uint64_t tx_premptap_ovrrd_val        : 1;
+	uint64_t tx_swing_ovrrd_en            : 1;
 	uint64_t tx_turbo_en_ovrrd_en         : 1;
 	uint64_t tx_vboost_en_ovrrd_en        : 1;
-	uint64_t tx_widthsel_ovrd_val         : 2;
-	uint64_t tx_widthsel_ovrd_en          : 1;
+	uint64_t tx_widthsel_ovrrd_val        : 2;
+	uint64_t tx_widthsel_ovrrd_en         : 1;
 	uint64_t reserved_15_63               : 49;
 #endif
 	} s;
@@ -6276,14 +6442,14 @@ union cvmx_gserx_lanex_tx_cfg_2 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t pcs_sds_tx_dcc_en            : 1;  /**< DCC Enable. */
 	uint64_t reserved_3_14                : 12;
-	uint64_t rcvr_test_ovrd_en            : 1;  /**< Override RX detect disable and test pulse. */
-	uint64_t rcvr_test_ovrd_val           : 1;  /**< Override value for RX detect test pulse; used to create a pulse during which the receiver
+	uint64_t rcvr_test_ovrrd_en           : 1;  /**< Override RX detect disable and test pulse. */
+	uint64_t rcvr_test_ovrrd_val          : 1;  /**< Override value for RX detect test pulse; used to create a pulse during which the receiver
                                                          detect test operation is performed. */
-	uint64_t tx_rx_detect_dis_ovrd_val    : 1;  /**< Override value of RX detect disable. */
+	uint64_t tx_rx_detect_dis_ovrrd_val   : 1;  /**< Override value of RX detect disable. */
 #else
-	uint64_t tx_rx_detect_dis_ovrd_val    : 1;
-	uint64_t rcvr_test_ovrd_val           : 1;
-	uint64_t rcvr_test_ovrd_en            : 1;
+	uint64_t tx_rx_detect_dis_ovrrd_val   : 1;
+	uint64_t rcvr_test_ovrrd_val          : 1;
+	uint64_t rcvr_test_ovrrd_en           : 1;
 	uint64_t reserved_3_14                : 12;
 	uint64_t pcs_sds_tx_dcc_en            : 1;
 	uint64_t reserved_16_63               : 48;
@@ -6294,14 +6460,14 @@ union cvmx_gserx_lanex_tx_cfg_2 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t pcs_sds_tx_dcc_en            : 1;  /**< DCC Enable. */
 	uint64_t reserved_14_3                : 12;
-	uint64_t rcvr_test_ovrd_en            : 1;  /**< Override RX detect disable and test pulse. */
-	uint64_t rcvr_test_ovrd_val           : 1;  /**< Override value for RX detect test pulse; used to create a pulse during which the receiver
+	uint64_t rcvr_test_ovrrd_en           : 1;  /**< Override RX detect disable and test pulse. */
+	uint64_t rcvr_test_ovrrd_val          : 1;  /**< Override value for RX detect test pulse; used to create a pulse during which the receiver
                                                          detect test operation is performed. */
-	uint64_t tx_rx_detect_dis_ovrd_val    : 1;  /**< Override value of RX detect disable. */
+	uint64_t tx_rx_detect_dis_ovrrd_val   : 1;  /**< Override value of RX detect disable. */
 #else
-	uint64_t tx_rx_detect_dis_ovrd_val    : 1;
-	uint64_t rcvr_test_ovrd_val           : 1;
-	uint64_t rcvr_test_ovrd_en            : 1;
+	uint64_t tx_rx_detect_dis_ovrrd_val   : 1;
+	uint64_t rcvr_test_ovrrd_val          : 1;
+	uint64_t rcvr_test_ovrrd_en           : 1;
 	uint64_t reserved_14_3                : 12;
 	uint64_t pcs_sds_tx_dcc_en            : 1;
 	uint64_t reserved_16_63               : 48;
@@ -6377,15 +6543,18 @@ union cvmx_gserx_lanex_tx_pre_emphasis {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
 	uint64_t cfg_tx_premptap              : 9;  /**< Override preemphasis control. Applies when
-                                                         GSER()_LANE()_TX_CFG_3[TX_PREMPTAP_OVRD_EN] is asserted.
+                                                         GSER()_LANE()_TX_CFG_3[TX_PREMPTAP_OVRRD_EN] is asserted.
                                                          <8:4> = Post-cursor.
                                                          <3:0> = Pre-cursor.
                                                          Recommended settings:
                                                          When auto-negotiated link training is not present, including XFI and all
                                                          protocols <= 6.25Gbaud except PCIe, the transmit preemphasis pre and post
                                                          cursor values should be manually over-ridden.
-                                                         GSER()_LANE()_TX_CFG_1[TX_PREMPTAP_OVRD_VAL] should be set
-                                                         and [CFG_TX_PREMPTAP] has the pre and post cursor values.
+                                                         GSER()_LANE()_TX_CFG_1[TX_PREMPTAP_OVRRD_VAL] should be set
+                                                         and [CFG_TX_PREMPTAP] has the pre and post cursor values. A preemphasis
+                                                         control change should be followed by a control interface configuration
+                                                         over-ride to force the new setting - see
+                                                         GSER()_LANE()_PCS_CTLIFC_2[CTLIFC_OVRRD_REQ].
                                                          [CFG_TX_PREMPTAP] should be derived from signal integrity simulations
                                                          with the IBIS-AMI model supplied by Cavium when auto-negotiated link
                                                          training is not present and link speed <= 6.25Gbaud.
@@ -6548,19 +6717,18 @@ union cvmx_gserx_lane_px_mode_0 {
                                                          0x3 = 1/8 data rate.
                                                          Recommended settings:
                                                          <pre>
-                                                                                     SATA   non-SATA
-                                                         _ R_25G_REFCLK100:           0x0    0x1
-                                                         _ R_5G_REFCLK100:            0x0    0x0
-                                                         _ R_8G_REFCLK100:            0x0    0x0
-                                                         _ R_125G_REFCLK15625_KX:     NS     0x2
-                                                         _ R_3125G_REFCLK15625_XAUI:  NS     0x1
-                                                         _ R_103125G_REFCLK15625_KR:  NS     0x0
-                                                         _ R_125G_REFCLK15625_SGMII:  NS     0x2
-                                                         _ R_5G_REFCLK15625_QSGMII:   NS     0x0
-                                                         _ R_625G_REFCLK15625_RXAUI:  NS     0x0
-                                                         _ R_25G_REFCLK125:           NS     0x1
-                                                         _ R_5G_REFCLK125:            NS     0x0
-                                                         _ R_8G_REFCLK125:            NS     0x0
+                                                         _ R_25G_REFCLK100:          0x1
+                                                         _ R_5G_REFCLK100:           0x0
+                                                         _ R_8G_REFCLK100:           0x0
+                                                         _ R_125G_REFCLK15625_KX:    0x2
+                                                         _ R_3125G_REFCLK15625_XAUI: 0x1
+                                                         _ R_103125G_REFCLK15625_KR: 0x0
+                                                         _ R_125G_REFCLK15625_SGMII: 0x2
+                                                         _ R_5G_REFCLK15625_QSGMII:  0x0
+                                                         _ R_625G_REFCLK15625_RXAUI: 0x0
+                                                         _ R_25G_REFCLK125:          0x1
+                                                         _ R_5G_REFCLK125:           0x0
+                                                         _ R_8G_REFCLK125:           0x0
                                                          </pre>
                                                          A 'NS' indicates that the rate is not supported at the specified reference clock. */
 	uint64_t rx_ldiv                      : 2;  /**< Configures clock divider used to determine the receive rate.
@@ -6570,19 +6738,18 @@ union cvmx_gserx_lane_px_mode_0 {
                                                          0x3 = 1/8 data rate
                                                          Recommended settings:
                                                          <pre>
-                                                                                     SATA   non-SATA
-                                                         _ R_25G_REFCLK100:           0x2    0x1
-                                                         _ R_5G_REFCLK100:            0x1    0x0
-                                                         _ R_8G_REFCLK100:            0x0    0x0
-                                                         _ R_125G_REFCLK15625_KX:     NS     0x2
-                                                         _ R_3125G_REFCLK15625_XAUI:  NS     0x1
-                                                         _ R_103125G_REFCLK15625_KR:  NS     0x0
-                                                         _ R_125G_REFCLK15625_SGMII:  NS     0x2
-                                                         _ R_5G_REFCLK15625_QSGMII:   NS     0x0
-                                                         _ R_625G_REFCLK15625_RXAUI:  NS     0x0
-                                                         _ R_25G_REFCLK125:           NS     0x1
-                                                         _ R_5G_REFCLK125:            NS     0x0
-                                                         _ R_8G_REFCLK125:            NS     0x0
+                                                         _ R_25G_REFCLK100:          0x1
+                                                         _ R_5G_REFCLK100:           0x0
+                                                         _ R_8G_REFCLK100:           0x0
+                                                         _ R_125G_REFCLK15625_KX:    0x2
+                                                         _ R_3125G_REFCLK15625_XAUI: 0x1
+                                                         _ R_103125G_REFCLK15625_KR: 0x0
+                                                         _ R_125G_REFCLK15625_SGMII: 0x2
+                                                         _ R_5G_REFCLK15625_QSGMII:  0x0
+                                                         _ R_625G_REFCLK15625_RXAUI: 0x0
+                                                         _ R_25G_REFCLK125:          0x1
+                                                         _ R_5G_REFCLK125:           0x0
+                                                         _ R_8G_REFCLK125:           0x0
                                                          </pre>
                                                          A 'NS' indicates that the rate is not supported at the specified reference clock. */
 	uint64_t srate                        : 3;  /**< Sample rate, used to generate strobe to effectively divide the clock down to a slower
@@ -6593,18 +6760,18 @@ union cvmx_gserx_lane_px_mode_0 {
                                                          0x3 = 1/8 data rate
                                                          0x4 = 1/16 data rate
                                                          else = Reserved.
-                                                         This field should always be cleared to zero (full rate). */
+                                                         This field should always be cleared to zero (i.e. full rate selected). */
 	uint64_t reserved_4_4                 : 1;
 	uint64_t tx_mode                      : 2;  /**< TX data width:
                                                          0x0 = 8-bit raw data (not supported).
                                                          0x1 = 10-bit raw data (not supported).
-                                                         0x2 = 16-bit raw data (for PCIe Gen3 8Gb only).
-                                                         0x3 = 20-bit raw data. */
+                                                         0x2 = 16-bit raw data (for PCIe Gen3 8Gb only - software should normally not select this).
+                                                         0x3 = 20-bit raw data (anything software-configured). */
 	uint64_t rx_mode                      : 2;  /**< RX data width:
                                                          0x0 = 8-bit raw data (not supported).
                                                          0x1 = 10-bit raw data (not supported).
-                                                         0x2 = 16-bit raw data (for PCIe Gen3 8Gb only).
-                                                         0x3 = 20-bit raw data. */
+                                                         0x2 = 16-bit raw data (for PCIe Gen3 8Gb only - software should normally not select this).
+                                                         0x3 = 20-bit raw data (anything software-configured). */
 #else
 	uint64_t rx_mode                      : 2;
 	uint64_t tx_mode                      : 2;
@@ -6640,11 +6807,11 @@ union cvmx_gserx_lane_px_mode_1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t vma_fine_cfg_sel             : 1;  /**< Recommended settings:
-                                                         1 = Enabled. Fine step adaptation selected (10.3125 Gbaud rate).
-                                                         0 = Disabled. Coarse step adaptation selected (rates lower than 10.3125 Gbaud). */
+                                                         0 = Disabled. Coarse step adaptation selected (rates lower than 10.3125 Gbaud).
+                                                         1 = Enabled. Fine step adaptation selected (10.3125 Gbaud rate). */
 	uint64_t vma_mm                       : 1;  /**< Manual DFE verses adaptive DFE mode.
                                                          Recommended settings:
-                                                         0 = Adaptive DFE (5 Gbaud and higher)
+                                                         0 = Adaptive DFE (5 Gbaud and higher).
                                                          1 = Manual DFE, fixed tap (3.125 Gbaud and lower). */
 	uint64_t cdr_fgain                    : 4;  /**< CDR frequency gain.
                                                          Recommended settings:
@@ -6665,21 +6832,19 @@ union cvmx_gserx_lane_px_mode_1 {
 	uint64_t ph_acc_adj                   : 10; /**< Phase accumulator adjust.
                                                          Recommended settings:
                                                          <pre>
-                                                                                     SATA   non-SATA
-                                                         _ R_25G_REFCLK100:           0x15   0x14
-                                                         _ R_5G_REFCLK100:            0x15   0x14
-                                                         _ R_8G_REFCLK100:            0x15   0x23
-                                                         _ R_125G_REFCLK15625_KX:     NS     0x1E
-                                                         _ R_3125G_REFCLK15625_XAUI:  NS     0x1E
-                                                         _ R_103125G_REFCLK15625_KR:  NS     0xF
-                                                         _ R_125G_REFCLK15625_SGMII:  NS     0x1E
-                                                         _ R_5G_REFCLK15625_QSGMII:   NS     0x1E
-                                                         _ R_625G_REFCLK15625_RXAUI:  NS     0x14
-                                                         _ R_25G_REFCLK125:           NS     0x14
-                                                         _ R_5G_REFCLK125:            NS     0x14
-                                                         _ R_8G_REFCLK125:            NS     0x23
-                                                         </pre>
-                                                         A 'NS' indicates that the rate is not supported at the specified reference clock. */
+                                                         _ R_25G_REFCLK100:          0x14
+                                                         _ R_5G_REFCLK100:           0x14
+                                                         _ R_8G_REFCLK100:           0x23
+                                                         _ R_125G_REFCLK15625_KX:    0x1E
+                                                         _ R_3125G_REFCLK15625_XAUI: 0x1E
+                                                         _ R_103125G_REFCLK15625_KR: 0xF
+                                                         _ R_125G_REFCLK15625_SGMII: 0x1E
+                                                         _ R_5G_REFCLK15625_QSGMII:  0x1E
+                                                         _ R_625G_REFCLK15625_RXAUI: 0x14
+                                                         _ R_25G_REFCLK125:          0x14
+                                                         _ R_5G_REFCLK125:           0x14
+                                                         _ R_8G_REFCLK125:           0x23
+                                                         </pre> */
 #else
 	uint64_t ph_acc_adj                   : 10;
 	uint64_t cdr_fgain                    : 4;
@@ -8136,42 +8301,39 @@ union cvmx_gserx_pll_px_mode_0 {
 	uint64_t pll_icp                      : 4;  /**< PLL charge pump enable.
                                                          Recommended settings, which are based on the reference clock speed:
                                                          <pre>
-                                                                  100Mhz  100MHz   125MHz   156.25MHz
-                                                                  SATA    non-SATA non-SATA non-SATA
-                                                         1.25G:    NS     0x1      0x1      0x1
-                                                         2.5G:     0x1    0x4      0x3      0x3
-                                                         3.125G:   NS     NS       0x1      0x1
-                                                         5.0G:     0x1    0x4      0x3      0x3
-                                                         6.25G:    NS     NS       0x1      0x1
-                                                         8.0G:     0x1    0x3      0x2      NS
-                                                         10.3125G: NS     NS       NS       0x1
+                                                                  100MHz 125MHz 156.25MHz
+                                                         1.25G:    0x1    0x1    0x1
+                                                         2.5G:     0x4    0x3    0x3
+                                                         3.125G:   NS     0x1    0x1
+                                                         5.0G:     0x4    0x3    0x3
+                                                         6.25G:    NS     0x1    0x1
+                                                         8.0G:     0x3    0x2    NS
+                                                         10.3125G: NS     NS     0x1
                                                          </pre>
                                                          A 'NS' indicates that the rate is not supported at the specified reference clock. */
 	uint64_t pll_rloop                    : 3;  /**< Loop resistor tuning.
                                                          Recommended settings:
                                                          <pre>
-                                                                     SATA    non-SATA
-                                                         _ 1.25G:     NS      0x3
-                                                         _ 2.5G:      0x3     0x3
-                                                         _ 3.125G:    NS      0x3
-                                                         _ 5.0G:      0x3     0x3
-                                                         _ 6.25G:     NS      0x3
-                                                         _ 8.0G:      0x5     0x5
-                                                         _ 10.3125G:  NS      0x5
-                                                         </pre>
-                                                         A 'NS' indicates that the rate is not supported at the specified reference clock. */
+                                                         _ 1.25G:    0x3
+                                                         _ 2.5G:     0x3
+                                                         _ 3.125G:   0x3
+                                                         _ 5.0G:     0x3
+                                                         _ 6.25G:    0x3
+                                                         _ 8.0G:     0x5
+                                                         _ 10.3125G: 0x5
+                                                         </pre> */
 	uint64_t pll_pcs_div                  : 9;  /**< The divider that generates PCS_MAC_TX_CLK. The frequency of the clock is (pll_frequency /
                                                          PLL_PCS_DIV).
                                                          Recommended settings:
                                                          <pre>
-                                                                     SATA    PCIE   Other
-                                                         _ 1.25G:     NS      NS     0x28
-                                                         _ 2.5G:      0x5     0x5    0x5
-                                                         _ 3.125G:    NS      NS     0x14
-                                                         _ 5.0G:      0x5     0x5    0xA
-                                                         _ 6.25G:     NS      NS     0xA
-                                                         _ 8.0G:      0x5     0x8    0xA
-                                                         _ 10.3125G:  NS      NS     0xA
+                                                                     PCIE   Other
+                                                         _ 1.25G:     NS     0x28
+                                                         _ 2.5G:      0x5    0x5
+                                                         _ 3.125G:    NS     0x14
+                                                         _ 5.0G:      0x5    0xA
+                                                         _ 6.25G:     NS     0xA
+                                                         _ 8.0G:      0x8    0xA
+                                                         _ 10.3125G:  NS     0xA
                                                          </pre>
                                                          A 'NS' indicates that the rate is not supported at the specified reference clock. */
 #else
@@ -8234,22 +8396,19 @@ union cvmx_gserx_pll_px_mode_1 {
                                                          0 = Any rate other than 8 Gbaud.
                                                          1 = Rate is equal to 8 Gbaud. */
 	uint64_t pll_opr                      : 1;  /**< PLL op range:
-                                                         0 = Use Ring Oscillator VCO.
-                                                         Recommended for rates 6.25 Gbaud and lower and for SATA.
-                                                         1 = Use LC-tank VCO.
-                                                         Recommended for non-SATA rates 8 Gbaud and higher. */
+                                                         0 = Use Ring Oscillator VCO. Recommended for rates 6.25 Gbaud and lower.
+                                                         1 = Use LC-tank VCO. Recommended for rates 8 Gbaud and higher. */
 	uint64_t pll_div                      : 9;  /**< PLL divider in feedback path which sets the PLL frequency.
                                                          Recommended settings:
                                                          <pre>
-                                                                  100Mhz  100MHz   125MHz   156.25MHz
-                                                                  SATA    non-SATA non-SATA non-SATA
-                                                         1.25G:    NS      0x19   0x14    0x10
-                                                         2.5G:     0x1E    0x19   0x14    0x10
-                                                         3.125G:   NS      NS     0x19    0x14
-                                                         5.0G:     0x1E    0x19   0x14    0x10
-                                                         6.25G:    NS      NS     0x19    0x14
-                                                         8.0G:     0x1E    0x28   0x20    NS
-                                                         10.3125G: NS      NS     NS      0x21
+                                                                  100MHz 125MHz 156.25MHz
+                                                         1.25G:    0x19   0x14    0x10
+                                                         2.5G:     0x19   0x14    0x10
+                                                         3.125G:   NS     0x19    0x14
+                                                         5.0G:     0x19   0x14    0x10
+                                                         6.25G:    NS     0x19    0x14
+                                                         8.0G:     0x28   0x20    NS
+                                                         10.3125G: NS     NS      0x21
                                                          </pre>
                                                          A 'NS' indicates that the rate is not supported at the specified reference clock. */
 #else
@@ -8419,7 +8578,8 @@ union cvmx_gserx_refclk_sel {
                                                          links, this bit is loaded with the PCIEn_COM0_CLK_EN pin at cold reset. */
 	uint64_t use_com1                     : 1;  /**< This bit controls the external mux select. When set, QLMC_REF_CLK1_N/P
                                                          are selected as the reference clock. When clear, QLMC_REF_CLK0_N/P are selected as the
-                                                         reference clock. INTERNAL: For non-CCPI links. */
+                                                         reference clock.
+                                                         INTERNAL: For non-CCPI links. */
 #else
 	uint64_t use_com1                     : 1;
 	uint64_t com_clk_sel                  : 1;
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
index 3d9cf53..5be2726 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
@@ -274,6 +274,24 @@ extern void cvmx_helper_bgx_set_jabber(int xiface, unsigned index, unsigned size
 extern int cvmx_helper_bgx_shutdown_port(int xiface, int index);
 extern int cvmx_bgx_set_backpressure_override(int xiface, unsigned port_mask);
 
+/**
+ * Returns if an interface is RGMII or not
+ *
+ * @param xiface	xinterface to check
+ * @param index		port index (must be 0 for rgmii)
+ *
+ * @return	true if RGMII, false otherwise
+ */
+static inline bool cvmx_helper_bgx_is_rgmii(int xiface, int index)
+{
+	union cvmx_bgxx_cmrx_config cmr_config;
+
+	if (!OCTEON_IS_MODEL(OCTEON_CN73XX) || index != 0)
+		return false;
+	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, xiface));
+	return cmr_config.s.lmac_type == 5;
+}
+
 #ifdef CVMX_DUMP_BGX
 /**
  * Dump BGX configuration for node 0
@@ -291,6 +309,7 @@ int cvmx_dump_bgx_config_node(unsigned node, unsigned bgx);
  * Dump BGX status
  */
 int cvmx_dump_bgx_status_node(unsigned node, unsigned bgx);
+
 #endif
 
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-board.h b/arch/mips/include/asm/octeon/cvmx-helper-board.h
index 9aa4b92..2b5bfe0 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-board.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-board.h
@@ -43,7 +43,7 @@
  * Helper functions to abstract board specific data about
  * network ports from the rest of the cvmx-helper files.
  *
- * <hr>$Revision: 121712 $<hr>
+ * <hr>$Revision: 122844 $<hr>
  */
 #ifndef __CVMX_HELPER_BOARD_H__
 #define __CVMX_HELPER_BOARD_H__
@@ -126,19 +126,23 @@ typedef enum {
 typedef struct cvmx_phy_gpio_leds {
 	uint64_t last_rx_count;		/** Counters used to check for activity */
 	uint64_t last_tx_count;		/** Counters used to check for activity */
-	int link_polling_interval_ms;	/** Link polling interval in ms */
+	uint64_t last_activity_poll_time;/** Last time activity was polled */
+	uint64_t last_link_poll_time;	/** Last time link was polled */
+	int link_poll_interval_ms;	/** Link polling interval in ms */
+	int activity_poll_interval_ms;	/** Activity polling interval in ms */
 	int link_status_gpio;		/** Link status LED GPIO, -1 if not used */
 	int error_gpio;			/** Error status LED GPIO, -1 if not used */
 	int rx_activity_gpio;		/** RX activity LED GPIO, -1 if not used */
 	int tx_activity_gpio;		/** TX activity LED GPIO, -1 if not used */
-	uint16_t rx_activity_on_ms;	/** RX activity on time in ms */
-	uint16_t rx_activity_off_ms;	/** RX activity off time in ms */
-	uint16_t tx_activity_on_ms;	/** TX activity on time in ms */
-	uint16_t tx_activity_off_ms;	/** TX activity off time in ms */
+	uint16_t rx_activity_hz;	/** RX activity blink time in hz */
+	uint16_t tx_activity_hz;	/** TX activity blink time in hz */
 	bool link_status_active_low;	/** True if active link is active low */
-	bool err_active_low;		/** True if error is active low */
+	bool error_status_active_low;	/** True if error LED is active low */
+	bool error_active_low;		/** True if error is active low */
 	bool rx_activity_active_low;	/** True if rx activity is active low */
 	bool tx_activity_active_low;	/** True if tx activity is active low */
+	int8_t rx_gpio_timer;		/** GPIO clock generator timer [0-3] */
+	int8_t tx_gpio_timer;		/** GPIO clock generator timer [0-3] */
 } cvmx_phy_gpio_leds_t;
 
 /**
@@ -369,6 +373,26 @@ int __cvmx_helper_parse_bgx_dt(void *fdt_addr);
  * @return 0 for success, -1 on error.
  */
 int __cvmx_helper_parse_bgx_rgmii_dt(const void *fdt_addr);
+
+/**
+ * @INTERNAL
+ * Updates any GPIO link LEDs if present
+ *
+ * @param xiface	Interface number
+ * @param index		Port index
+ * @param result	Link status result
+ */
+void __cvmx_update_link_led(int xiface, int index,
+			    cvmx_helper_link_info_t result);
+/**
+ * Update the RX activity LED for the specified interface and port index
+ *
+ * @param xiface	Interface number
+ * @param index		Port index
+ * @parma check_time	True if we should bail out before the polling interval
+ */
+void cvmx_update_rx_activity_led(int xiface, int index, bool check_time);
+
 #endif
 
 #ifdef	__cplusplus
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
index bdb0cda..2ec9dd6 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
@@ -136,6 +136,7 @@ struct cvmx_cfg_port_param {
 	int8_t ccpp_pko_port_base;
 	int8_t ccpp_pko_num_ports;
 	uint8_t agl_rx_clk_skew;	/** AGL rx clock skew setting (default 0) */
+	uint8_t rgmii_tx_clk_delay;	/** RGMII TX clock delay value if not bypassed */
 	bool valid:1;			/** 1 = port valid, 0 = invalid */
 	bool sgmii_phy_mode:1;		/** 1 = port in PHY mode, 0 = MAC mode */
 	bool sgmii_1000x_mode:1;	/** 1 = 1000Base-X mode, 0 = SGMII mode */
@@ -144,6 +145,9 @@ struct cvmx_cfg_port_param {
 	bool disable_an:1;		/** true to disable autonegotiation */
 	bool link_down_pwr_dn:1;	/** Power PCS off when link is down */
 	bool phy_present:1;		/** true if PHY is present */
+	bool tx_clk_delay_bypass;	/** True to bypass the TX clock delay */
+	/** Set if local (non-PHY) LEDs are used */
+	struct cvmx_phy_gpio_leds *gpio_leds;
 };
 
 /*
@@ -611,6 +615,59 @@ extern void cvmx_helper_set_port_phy_info(int xiface, int index,
  */
 extern struct cvmx_phy_info *cvmx_helper_get_port_phy_info(int xiface, int index);
 
+/**
+ * @INTERNAL
+ * Returns a pointer to the PHY LED configuration (if local GPIOs drive them)
+ *
+ * @param xiface	node and interface
+ * @param index		portindex
+ *
+ * @return pointer to the PHY LED information data structure or NULL if not
+ *	   present
+ */
+extern struct cvmx_phy_gpio_leds *cvmx_helper_get_port_phy_leds(int xiface,
+								int index);
+
+/**
+ * @INTERNAL
+ * Sets a pointer to the PHY LED configuration (if local GPIOs drive them)
+ *
+ * @param xiface	node and interface
+ * @param index		portindex
+ * @param leds		pointer to led data structure
+ */
+extern void cvmx_helper_set_port_phy_leds(int xiface, int index,
+					  struct cvmx_phy_gpio_leds *leds);
+
+/**
+ * @INTERNAL
+ * Disables RGMII TX clock bypass and sets delay value
+ *
+ * @param xiface	node and interface
+ * @param index		portindex
+ * @param bypass	Set true to enable the clock bypass and false
+ *			to sync clock and data synchronously.
+ *			Default is false.
+ * @param clk_delay	Delay value to skew TXC from TXD
+ */
+void cvmx_helper_cfg_set_rgmii_tx_clk_delay( int xiface, int index,
+					     bool bypass, int clk_delay);
+
+/**
+ * @INTERNAL
+ * Gets RGMII TX clock bypass and delay value
+ *
+ * @param xiface	node and interface
+ * @param index		portindex
+ * @param bypass	Set true to enable the clock bypass and false
+ *			to sync clock and data synchronously.
+ *			Default is false.
+ * @param clk_delay	Delay value to skew TXC from TXD, default is 0.
+ */
+void cvmx_helper_cfg_get_rgmii_tx_clk_delay(int xiface, int index,
+					    bool *bypass,
+					    int *clk_delay);
+
 /*
  * Initializes cvmx with user specified config info.
  */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-util.h b/arch/mips/include/asm/octeon/cvmx-helper-util.h
index b10f4e6..e2e31ea 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-util.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-util.h
@@ -42,7 +42,7 @@
  *
  * Small helper utilities.
  *
- * <hr>$Revision: 111417 $<hr>
+ * <hr>$Revision: 123112 $<hr>
  */
 
 #ifndef __CVMX_HELPER_UTIL_H__
@@ -69,6 +69,7 @@ typedef char cvmx_bpid_t;
 #define	CVMX_PKO3_IPD_NUM_MAX	0x1000	//FIXME- take it from someplace else ?
 
 #define CVMX_PKO3_IPD_PORT_NULL (CVMX_PKO3_IPD_NUM_MAX-1)
+#define CVMX_PKO3_IPD_PORT_LOOP 0
 
 struct cvmx_xport {
 	int node;
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-xaui.h b/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
index cf01529..69bfdb1 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 106932 $<hr>
+ * <hr>$Revision: 123496 $<hr>
  */
 #ifndef __CVMX_HELPER_XAUI_H__
 #define __CVMX_HELPER_XAUI_H__
@@ -74,6 +74,33 @@ extern int __cvmx_helper_xaui_enumerate(int xiface);
 extern int __cvmx_helper_xaui_enable(int xiface);
 
 /**
+ * Retrain XAUI interface.
+ *
+ * GMX is disabled as part of retraining.
+ * While GMX is disabled, new recieved packets are dropped.
+ * If GMX was in the middle of recieving a packet when disabled,
+ * that packet will be recieved before GMX idles.
+ * Transmitted packets are buffered normally, but not sent.
+ * If GMX was in the middle of transmitting a packet when disabled,
+ * that packet will be transmitted before GMX idles.
+ *
+ * @param interface Interface to retrain
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int cvmx_helper_xaui_link_retrain(int interface);
+
+/**
+ * Reinitialize XAUI interface.  Does a probe without changing the hardware
+ * state.
+ *
+ * @param interface	Interface to reinitialize
+ *
+ * @return	0 on success, negative on failure
+ */
+extern int cvmx_helper_xaui_link_reinit(int interface);
+
+/**
  * @INTERNAL
  * Return the link state of an IPD/PKO port as returned by
  * auto negotiation. The result of this function may not match
diff --git a/arch/mips/include/asm/octeon/cvmx-ila.h b/arch/mips/include/asm/octeon/cvmx-ila.h
index 82db35d..f76844f 100644
--- a/arch/mips/include/asm/octeon/cvmx-ila.h
+++ b/arch/mips/include/asm/octeon/cvmx-ila.h
@@ -50,6 +50,7 @@
 #ifndef __CVMX_HELPER_ILA_H__
 #define __CVMX_HELPER_ILA_H__
 
+#include "cvmx-helper.h"
 #include "cvmx-ilk.h"
 
 #ifdef	__cplusplus
@@ -101,6 +102,16 @@ typedef union {
 extern int cvmx_ila_initialize(int lane_mask);
 
 /**
+ * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by ILK-LA link status.
+ *
+ * @param lane_mask lane_mask
+ *
+ * @return Link state
+ */
+extern cvmx_helper_link_info_t __cvmx_ila_link_get(int lane_mask);
+
+/**
  * Enable or disable LA mode in ILK header.
  *
  * @param channel channel
diff --git a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
index e10ff6a..90359ac 100644
--- a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
@@ -2944,7 +2944,8 @@ union cvmx_lmcx_config {
 	uint64_t u64;
 	struct cvmx_lmcx_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t lrdimm_ena                   : 1;  /**< Load Reduced DIMM Enable. When set allows the use of JEDEC DDR4 LRDIMMs. */
+	uint64_t lrdimm_ena                   : 1;  /**< Reserved.
+                                                         INTERNAL: Load Reduced DIMM Enable. When set allows the use of JEDEC DDR4 LRDIMMs. */
 	uint64_t bg2_enable                   : 1;  /**< BG1 enable bit. Only has an effect when LMC()_CONFIG[MODEDDR4] = 1.
                                                          Set to 1 when using DDR4 x4 or x8 parts.
                                                          Clear to 0 when using DDR4 x16 parts. */
@@ -3060,6 +3061,7 @@ union cvmx_lmcx_config {
                                                          16. So, row = mem_adr<29:16>.
                                                          With RANK_ENA = 0, PBANK_LSB = 2.
                                                          With RANK_ENA = 1, PBANK_LSB = 3.
+                                                         INTERNAL:
                                                          When interfacing with 8H 3DS, set this 0xA regardless of RANK_ENA value. */
 	uint64_t row_lsb                      : 3;  /**< "Row address bit select.
                                                          0x0 = Address bit 14 is LSB.
@@ -4263,7 +4265,8 @@ union cvmx_lmcx_config {
 	struct cvmx_lmcx_config_cn70xx        cn70xxp1;
 	struct cvmx_lmcx_config_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t lrdimm_ena                   : 1;  /**< Load Reduced DIMM Enable. When set allows the use of JEDEC DDR4 LRDIMMs. */
+	uint64_t lrdimm_ena                   : 1;  /**< Reserved.
+                                                         INTERNAL: Load Reduced DIMM Enable. When set allows the use of JEDEC DDR4 LRDIMMs. */
 	uint64_t bg2_enable                   : 1;  /**< BG1 enable bit. Only has an effect when LMC()_CONFIG[MODEDDR4] = 1.
                                                          Set to 1 when using DDR4 x4 or x8 parts.
                                                          Clear to 0 when using DDR4 x16 parts. */
@@ -4398,6 +4401,7 @@ union cvmx_lmcx_config {
                                                          16. So, row = mem_adr<29:16>.
                                                          With RANK_ENA = 0, PBANK_LSB = 2.
                                                          With RANK_ENA = 1, PBANK_LSB = 3.
+                                                         INTERNAL:
                                                          When interfacing with 8H 3DS, set this 0xA regardless of RANK_ENA value. */
 	uint64_t row_lsb                      : 3;  /**< "Row address bit select.
                                                          0x0 = Address bit 14 is LSB.
@@ -5715,6 +5719,8 @@ typedef union cvmx_lmcx_ctl1 cvmx_lmcx_ctl1_t;
 /**
  * cvmx_lmc#_dbtrain_ctl
  *
+ * Reserved.
+ * INTERNAL:
  * This register contains control bits that are used during the Data Buffer
  * training sequence in DDR4 LRDIMM mode. When one of the data buffer training
  * sequence is initiated, it uses the contents of this register to control
@@ -5725,16 +5731,20 @@ union cvmx_lmcx_dbtrain_ctl {
 	struct cvmx_lmcx_dbtrain_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_62_63               : 2;
-	uint64_t cmd_count_ext                : 2;  /**< Extension bits to the field DBTRAIN_CTL[READ_CMD_COUNT]. This enables the data
-                                                         buffer training sequence to send up to 128 read commmands. */
-	uint64_t db_output_impedance          : 3;  /**< Host Interface DQ/DQS Output Driver Impedance control.
+	uint64_t cmd_count_ext                : 2;  /**< Extension bits to the field DBTRAIN_CTL[READ_CMD_COUNT]. This enables
+                                                         up to 128 read and write commmands. */
+	uint64_t db_output_impedance          : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Host Interface DQ/DQS Output Driver Impedance control.
                                                          This is the default value used during Host Interface Write Leveling in LRDIMM
                                                          environment, i.e., CONFIG[LRDIMM_ENA] = 1, SEQ_CTL[SEQ_SEL] = 0x6.
                                                          0x0 = RZQ/6 (40 ohm).
                                                          0x1 = RZQ/7 (34 ohm).
                                                          0x2 = RZQ/5 (48 ohm).
                                                          0x3-0x7 = Reserved. */
-	uint64_t db_sel                       : 1;  /**< Used when running Host Interface Write Leveling.
+	uint64_t db_sel                       : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Used when running Host Interface Write Leveling.
                                                          0 = selects DIMM0's Data Buffer.
                                                          1 = selects DIMM1's Data Buffer. */
 	uint64_t tccd_sel                     : 1;  /**< When set, the sequence uses MODEREG_PARAMS3[TCCD_L] to space out
@@ -5743,7 +5753,7 @@ union cvmx_lmcx_dbtrain_ctl {
                                                          While in DRAM MPR mode, reads from Page 0 may use tCCD_S or tCCD_L.
                                                          Reads from Pages 1, 2 or 3 however must use tCCD_L, thereby requring
                                                          this bit to be set. */
-	uint64_t rw_train                     : 1;  /**< When set, the DBTRAIN sequence will perform a Write to the DRAM
+	uint64_t rw_train                     : 1;  /**< When set, the sequence will perform a Write to the DRAM
                                                          memory array using burst patern that are set in the CSRs
                                                          LMC()_GENERAL_PURPOSE0[DATA]<61:0>, LMC()_GENERAL_PURPOSE1[DATA]<61:0> and
                                                          LMC()_GENERAL_PURPOSE2[DATA]<15:0>.
@@ -5752,26 +5762,31 @@ union cvmx_lmcx_dbtrain_ctl {
                                                          the data coming back with this pattern.
                                                          The bit-wise comparison result gets stored in
                                                          LMC()_MPR_DATA0[MPR_DATA]<63:0> and LMC()_MPR_DATA1[MPR_DATA]<7:0>. */
-	uint64_t read_dq_count                : 7;  /**< The amount of cycles until a pulse is issued to sample the DQ into the
+	uint64_t read_dq_count                : 7;  /**< Reserved.
+                                                         INTERNAL:
+                                                         The amount of cycles until a pulse is issued to sample the DQ into the
                                                          MPR register. This bits control the timing of when to sample the data
                                                          buffer training result. */
-	uint64_t read_cmd_count               : 5;  /**< The amount of Read Commands to be sent during the data buffer training.
+	uint64_t read_cmd_count               : 5;  /**< The amount of Read and Write Commands to be sent during the R/W training.
+                                                         INTERNAL:
                                                          This can be set to zero in which case the sequence does not send any
                                                          Read commands to accommodate for the DWL training mode. */
-	uint64_t write_ena                    : 1;  /**< Enables the write operation. This is mainly used to accomplish the MWD
+	uint64_t write_ena                    : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Enables the write operation. This is mainly used to accomplish the MWD
                                                          training sequence of the data buffer.
                                                          LMC()_DBTRAIN_CTL[ACTIVATE] must be set to 1 for this to take effect. */
-	uint64_t activate                     : 1;  /**< Enables the activate command during the data buffer training sequence. */
-	uint64_t prank                        : 2;  /**< Physical Rank bits for Read/Write/Activate operation during the data buffer
-                                                         training. */
-	uint64_t lrank                        : 3;  /**< Logical Rank bits for Read/Write/Activate operation during the data buffer
-                                                         training. */
-	uint64_t row_a                        : 18; /**< The row address for the Activate command during dbtrain. */
-	uint64_t bg                           : 2;  /**< The Bank Group that the commands are directed to while in data buffer
-                                                         training sequence. */
-	uint64_t ba                           : 2;  /**< The bank address for the commands while in data buffer training sequence. */
-	uint64_t column_a                     : 13; /**< Column address for the Read/Write operation during the data buffer
+	uint64_t activate                     : 1;  /**< Reserved.
+                                                         INTERNAL: Enables the activate command during the data buffer training sequence. */
+	uint64_t prank                        : 2;  /**< Physical Rank bits for Read/Write/Activate operation. */
+	uint64_t lrank                        : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Logical Rank bits for Read/Write/Activate operation during the data buffer
                                                          training. */
+	uint64_t row_a                        : 18; /**< The row address for the Activate command. */
+	uint64_t bg                           : 2;  /**< The bank group that the R/W commands are directed to. */
+	uint64_t ba                           : 2;  /**< The bank address for the R/W commands are directed to. */
+	uint64_t column_a                     : 13; /**< Column address for the R/W operation. */
 #else
 	uint64_t column_a                     : 13;
 	uint64_t ba                           : 2;
@@ -5794,14 +5809,18 @@ union cvmx_lmcx_dbtrain_ctl {
 	struct cvmx_lmcx_dbtrain_ctl_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
-	uint64_t db_output_impedance          : 3;  /**< Host Interface DQ/DQS Output Driver Impedance control.
+	uint64_t db_output_impedance          : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Host Interface DQ/DQS Output Driver Impedance control.
                                                          This is the default value used during Host Interface Write Leveling in LRDIMM
                                                          environment, i.e., LMC()_CONFIG[LRDIMM_ENA] = 1, LMC()_SEQ_CTL[SEQ_SEL] = 0x6.
                                                          0x0 = RZQ/6 (40 ohm).
                                                          0x1 = RZQ/7 (34 ohm).
                                                          0x2 = RZQ/5 (48 ohm).
                                                          0x3-0x7 = Reserved. */
-	uint64_t db_sel                       : 1;  /**< Used when running Host Interface Write Leveling.
+	uint64_t db_sel                       : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Used when running Host Interface Write Leveling.
                                                          0 = selects DIMM0's Data Buffer.
                                                          1 = selects DIMM1's Data Buffer. */
 	uint64_t tccd_sel                     : 1;  /**< When set, the sequence uses MODEREG_PARAMS3[TCCD_L] to space out
@@ -5810,7 +5829,7 @@ union cvmx_lmcx_dbtrain_ctl {
                                                          While in DRAM MPR mode, reads from Page 0 may use tCCD_S or tCCD_L.
                                                          Reads from Pages 1, 2 or 3 however must use tCCD_L, thereby requring
                                                          this bit to be set. */
-	uint64_t rw_train                     : 1;  /**< When set, the DBTRAIN sequence will perform a Write to the DRAM
+	uint64_t rw_train                     : 1;  /**< When set, the sequence will perform a Write to the DRAM
                                                          memory array using burst patern that are set in the CSRs
                                                          LMC()_GENERAL_PURPOSE0[DATA]<61:0>, LMC()_GENERAL_PURPOSE1[DATA]<61:0> and
                                                          LMC()_GENERAL_PURPOSE2[DATA]<15:0>.
@@ -5822,23 +5841,26 @@ union cvmx_lmcx_dbtrain_ctl {
 	uint64_t read_dq_count                : 7;  /**< The amount of cycles until a pulse is issued to sample the DQ into the
                                                          MPR register. This bits control the timing of when to sample the data
                                                          buffer training result. */
-	uint64_t read_cmd_count               : 5;  /**< The amount of Read Commands to be sent during the data buffer training.
+	uint64_t read_cmd_count               : 5;  /**< The amount of Read and Write Commands to be sent during the R/W training.
+                                                         INTERNAL:
                                                          This can be set to zero in which case the sequence does not send any
                                                          Read commands to accommodate for the DWL training mode. */
-	uint64_t write_ena                    : 1;  /**< Enables the write operation. This is mainly used to accomplish the MWD
+	uint64_t write_ena                    : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Enables the write operation. This is mainly used to accomplish the MWD
                                                          training sequence of the data buffer.
                                                          LMC()_DBTRAIN_CTL[ACTIVATE] must be set to 1 for this to take effect. */
-	uint64_t activate                     : 1;  /**< Enables the activate command during the data buffer training sequence. */
-	uint64_t prank                        : 2;  /**< Physical Rank bits for Read/Write/Activate operation during the data buffer
-                                                         training. */
-	uint64_t lrank                        : 3;  /**< Logical Rank bits for Read/Write/Activate operation during the data buffer
-                                                         training. */
-	uint64_t row_a                        : 18; /**< The row address for the Activate command during dbtrain. */
-	uint64_t bg                           : 2;  /**< The Bank Group that the commands are directed to while in data buffer
-                                                         training sequence. */
-	uint64_t ba                           : 2;  /**< The bank address for the commands while in data buffer training sequence. */
-	uint64_t column_a                     : 13; /**< Column address for the Read/Write operation during the data buffer
+	uint64_t activate                     : 1;  /**< Reserved.
+                                                         INTERNAL: Enables the activate command during the data buffer training sequence. */
+	uint64_t prank                        : 2;  /**< Physical Rank bits for Read/Write/Activate operation. */
+	uint64_t lrank                        : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Logical Rank bits for Read/Write/Activate operation during the data buffer
                                                          training. */
+	uint64_t row_a                        : 18; /**< The row address for the Activate command. */
+	uint64_t bg                           : 2;  /**< The bank group that the R/W commands are directed to. */
+	uint64_t ba                           : 2;  /**< The bank address that the R/W commands are directed to. */
+	uint64_t column_a                     : 13; /**< Column address for the R/W operation. */
 #else
 	uint64_t column_a                     : 13;
 	uint64_t ba                           : 2;
@@ -6245,13 +6267,14 @@ typedef union cvmx_lmcx_ddr2_ctl cvmx_lmcx_ddr2_ctl_t;
  *
  * Bits 0-21 of this register is used only when LMC()_CONTROL[RDIMM_ENA] = 1.
  *
- * Bits 22-27 is used only when LMC()_CONFIG[LRDIMM_ENA] = 1 AND
- * LMC()_MR_MPR_CTL[MR_WR_PBA_ENABLE] = 1.
- *
  * During an RCW initialization sequence, bits 0-21 controls LMC's write
  * operations to the extended DDR4 control words in the JEDEC standard
  * registering clock driver on an RDIMM.
  *
+ * INTERNAL:
+ * Bits 22-27 is used only when LMC()_CONFIG[LRDIMM_ENA] = 1 AND
+ * LMC()_MR_MPR_CTL[MR_WR_PBA_ENABLE] = 1.
+ *
  * During PBA mode of an MRW sequence, bits 22-27 controls the Buffer Configuration
  * Control Word F0BC1x settings during the BCW write.
  */
@@ -6260,16 +6283,28 @@ union cvmx_lmcx_ddr4_dimm_ctl {
 	struct cvmx_lmcx_ddr4_dimm_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_28_63               : 36;
-	uint64_t rank_timing_enable           : 1;  /**< Package Rank Timing Alignment Enable bit for the DDR4 LRDIMM Buffer Configuration Control
+	uint64_t rank_timing_enable           : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Package Rank Timing Alignment Enable bit for the DDR4 LRDIMM Buffer Configuration Control
                                                          Word F0BC1x DA[7]. Used during PBA BCW Write through the MRW sequence. */
-	uint64_t bodt_trans_mode              : 1;  /**< BODT input handling in Transparent Mode for the DDR4 LRDIMM Buffer Conifguration Control
+	uint64_t bodt_trans_mode              : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         BODT input handling in Transparent Mode for the DDR4 LRDIMM Buffer Conifguration Control
                                                          Word F0BC1x. Used during PBA BCW Write through the MRW sequence. */
-	uint64_t trans_mode_ena               : 1;  /**< Transparent Mode Enable bit for DDR4 LRDIMM Buffer Configuration Control Word
+	uint64_t trans_mode_ena               : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Transparent Mode Enable bit for DDR4 LRDIMM Buffer Configuration Control Word
                                                          F0BC1x DA[5]. Used during PBA BCW Write through the MRW sequence. */
-	uint64_t read_preamble_mode           : 1;  /**< Read Preamble Training Mode Enable bit for DDR4 LRDIMM Buffer Configuration Control Word
+	uint64_t read_preamble_mode           : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Read Preamble Training Mode Enable bit for DDR4 LRDIMM Buffer Configuration Control Word
                                                          F0BC1x DA[4]. Used during PBA BCW Write through the MRW sequence. */
-	uint64_t buff_config_da3              : 1;  /**< Reserved setting value in F0BC1x DA3. Used during PBA BCW Write through the MRW sequence. */
-	uint64_t mpr_over_ena                 : 1;  /**< MPR Override Mode Enable bit for the DDR4 LRDIMM Buffer Configuration Control Word
+	uint64_t buff_config_da3              : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Reserved setting value in F0BC1x DA3. Used during PBA BCW Write through the MRW sequence. */
+	uint64_t mpr_over_ena                 : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         MPR Override Mode Enable bit for the DDR4 LRDIMM Buffer Configuration Control Word
                                                          F0BC1x DA[1]. Used during PBA BCW Write through the MRW sequence. */
 	uint64_t ddr4_dimm1_wmask             : 11; /**< DIMM1 write mask. If (DIMM1_WMASK[n] = 1), write DIMM1.RCn. */
 	uint64_t ddr4_dimm0_wmask             : 11; /**< DIMM0 write mask. If (DIMM0_WMASK[n] = 1), write DIMM0.RCn. */
@@ -7465,9 +7500,9 @@ union cvmx_lmcx_ext_config {
                                                          allow refresh sequence to start when LMC()_REF_STATUS[REF_COUNT] has
                                                          reached the maximum value of 0x7. */
 	uint64_t mrs_side                     : 1;  /**< Only applies when EXT_CONFIG[MRS_ONE_SIDE] is set.
-                                                         0 = MRS command is sent to the A side of an RDIMM/LRDIMM.
-                                                         1 = MRS command is sent to the B side of an RDIMM/LRDIMM. */
-	uint64_t mrs_one_side                 : 1;  /**< Only applies to DDR4 RDIMM/LRDIMM.
+                                                         0 = MRS command is sent to the A side of an RDIMM.
+                                                         1 = MRS command is sent to the B side of an RDIMM. */
+	uint64_t mrs_one_side                 : 1;  /**< Only applies to DDR4 RDIMM.
                                                          When set, MRS commands are directed to either the A or B
                                                          side of the RCD.
                                                          PDA operation is NOT allowed when this bit is set. In
@@ -7476,7 +7511,7 @@ union cvmx_lmcx_ext_config {
                                                          bit turned on. */
 	uint64_t mrs_bside_invert_disable     : 1;  /**< When set, the command decoder cancels the auto inversion of
                                                          A3-A9, A11, A13, A17, BA0, BA1 and BG0 during MRS/MRS_PDA
-                                                         command to the B side of the RDIMM/LRDIMM.
+                                                         command to the B side of the RDIMM.
                                                          When set, make sure that the RCD's control word
                                                          RC00 DA[0] = 1 so that the output inversion is disabled in
                                                          the DDR4 RCD. */
@@ -7493,8 +7528,10 @@ union cvmx_lmcx_ext_config {
 	uint64_t coalesce_address_mode        : 1;  /**< When set to 1, LMC coalesces the L2C+LMC internal address mapping
                                                          to create a uniform memory space that are free from holes in
                                                          between ranks. When different size DIMMs are used, the DIMM with
-                                                         the smaller size is mapped to the lower address space. */
-	uint64_t dimm1_cid                    : 2;  /**< DIMM1 configuration bits that represent the number of Chip
+                                                         the higher capacity is mapped to the lower address space. */
+	uint64_t dimm1_cid                    : 2;  /**< Reserved.
+                                                         INTERNAL:
+                                                         DIMM1 configuration bits that represent the number of Chip
                                                          ID of the DRAM. This value is use for decoding address
                                                          as well as routing Chip IDs to the appropriate output
                                                          pins.
@@ -7502,7 +7539,9 @@ union cvmx_lmcx_ext_config {
                                                          0x1 = 1 Chip ID  (2H 3DS).
                                                          0x2 = 2 Chip IDs (4H 3DS).
                                                          0x3 = 3 Chip IDs (8H 3DS). */
-	uint64_t dimm0_cid                    : 2;  /**< DIMM0 configuration bits that represent the number of Chip
+	uint64_t dimm0_cid                    : 2;  /**< Reserved.
+                                                         INTERNAL:
+                                                         DIMM0 configuration bits that represent the number of Chip
                                                          ID of the DRAM. This value is use for decoding address
                                                          as well as routing Chip IDs to the appropriate output
                                                          pins.
@@ -7814,7 +7853,9 @@ union cvmx_lmcx_fadr {
 	struct cvmx_lmcx_fadr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t fcid                         : 3;  /**< Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
+	uint64_t fcid                         : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
                                                          either
                                                          LMC()_EXT_CONFIG[DIMM0_CID] or LMC()_EXT_CONFIG[DIMM1_CID] is non-zero). Returns a value
                                                          of zero
@@ -7910,7 +7951,9 @@ union cvmx_lmcx_fadr {
 	struct cvmx_lmcx_fadr_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t fcid                         : 3;  /**< Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
+	uint64_t fcid                         : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
                                                          either
                                                          LMC()_EXT_CONFIG[DIMM0_CID] or LMC()_EXT_CONFIG[DIMM1_CID] is non-zero). Returns a value
                                                          of zero
@@ -9173,7 +9216,9 @@ union cvmx_lmcx_modereg_params1 {
 	uint64_t rtt_wr_10_ext                : 1;  /**< RTT_WR rank 2 extension bit for DDR4. */
 	uint64_t rtt_wr_01_ext                : 1;  /**< RTT_WR rank 1 extension bit for DDR4. */
 	uint64_t rtt_wr_00_ext                : 1;  /**< RTT_WR rank 0 extension bit for DDR4. */
-	uint64_t db_output_impedance          : 3;  /**< Host Interface DQ/DQS Output Driver Impedance control for DIMM0's Data Buffer.
+	uint64_t db_output_impedance          : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Host Interface DQ/DQS Output Driver Impedance control for DIMM0's Data Buffer.
                                                          This is the default value used during Host Interface Write Leveling in LRDIMM
                                                          environment, i.e., LMC()_CONFIG[LRDIMM_ENA] = 1, LMC()_SEQ_CTL[SEQ_SEL] = 0x6.
                                                          0x0 = RZQ/6 (40 ohm).
@@ -9638,9 +9683,13 @@ union cvmx_lmcx_modereg_params3 {
 	struct cvmx_lmcx_modereg_params3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_39_63               : 25;
-	uint64_t xrank_add_tccd_l             : 3;  /**< Add additional cycles on top of the 4 cycles applied to tCCD_L
+	uint64_t xrank_add_tccd_l             : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Add additional cycles on top of the 4 cycles applied to tCCD_L
                                                          when crossing logical rank (to the same bank group) of a 3DS DRAM. */
-	uint64_t xrank_add_tccd_s             : 3;  /**< Add additional cycles on top of the 4 cycles applied to tCCD_S
+	uint64_t xrank_add_tccd_s             : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Add additional cycles on top of the 4 cycles applied to tCCD_S
                                                          when crossing logical rank (to a different bank group) of a 3DS DRAM. */
 	uint64_t mpr_fmt                      : 2;  /**< MPR format. */
 	uint64_t wr_cmd_lat                   : 2;  /**< Write command latency when CRC and DM are both enabled. */
@@ -9772,9 +9821,8 @@ union cvmx_lmcx_mpr_data0 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t mpr_data                     : 64; /**< MPR data bits<63:0>. Bits<7:0> represent the MPR data for the lowest-order *4 device (*4
                                                          device 0); bits<15:8> represent *4 device 1; ..., bits<63:56> are for *4 device 7.
-                                                         This field is also used to store the results after running the Data Buffer Training
-                                                         sequence
-                                                         (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
+                                                         This field is also used to store the results after running the General R/W Training
+                                                         sequence (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
                                                          The format of the stored results is controlled by the CSR LMC()_DBTRAIN_CTL[RW_TRAIN].
                                                          When LMC()_DBTRAIN_CTL[RW_TRAIN] = 1, this field stores the R/W comparison output
                                                          from all DQ63 - DQ0.
@@ -9805,9 +9853,8 @@ union cvmx_lmcx_mpr_data1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t mpr_data                     : 64; /**< MPR data bits<127:64>. Bits<7:0> represent the MPR data for *4 device 8; bits<15:8>
                                                          represent *4 device 9; ...; bits<63:56> are for *4 device 15.
-                                                         This field is also used to store the results after running the Data Buffer Training
-                                                         sequence
-                                                         (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
+                                                         This field is also used to store the results after running the General R/W Training
+                                                         sequence (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
                                                          The format of the stored results is controlled by the CSR LMC()_DBTRAIN_CTL[RW_TRAIN].
                                                          When LMC()_DBTRAIN_CTL[RW_TRAIN] = 1, this field stores the R/W comparison output
                                                          from the ECC byte (DQ71 - DQ64).
@@ -9840,9 +9887,8 @@ union cvmx_lmcx_mpr_data2 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t mpr_data                     : 16; /**< MPR data bits<143:128>. Bits<7:0> represent the MPR data for *4 device 16; bits<15:8>
                                                          represent *4 device 17.
-                                                         This field is also used to store the results after running the Data Buffer Training
-                                                         sequence
-                                                         (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
+                                                         This field is also used to store the results after running the General R/W Training
+                                                         sequence (LMC()_SEQ_CTL[SEQ_SEL] = 0xe).
                                                          The format of the stored results is controlled by the CSR LMC()_DBTRAIN_CTL[RW_TRAIN].
                                                          When LMC()_DBTRAIN_CTL[RW_TRAIN] = 1, this field is not used.
                                                          When LMC()_DBTRAIN_CTL[RW_TRAIN] = 0, MPR_DATA<15:0> stores the negative edge read data
@@ -9883,7 +9929,9 @@ union cvmx_lmcx_mr_mpr_ctl {
 	uint64_t mpr_sample_dq_enable         : 1;  /**< Reserved. INTERNAL: No longer used due to logic change from
                                                          initial design. */
 	uint64_t pda_early_dqx                : 1;  /**< When set, it enables lmc_dqx early for PDA/PBA operation. */
-	uint64_t mr_wr_pba_enable             : 1;  /**< Per Buffer Addressability write enable. When set, MRW operations use PBA, enabled by
+	uint64_t mr_wr_pba_enable             : 1;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Per Buffer Addressability write enable. When set, MRW operations use PBA, enabled by
                                                          MR_WR_PDA_MASK per buffer.
                                                          Only available for DDR4 LRDIMM. */
 	uint64_t mr_wr_use_default_value      : 1;  /**< When set, write the value to the MR that is computed from the value set in various CSR
@@ -10055,12 +10103,14 @@ union cvmx_lmcx_nxm {
                                                          If DIMM1 is dual-sided, this should be set to
                                                          NXM[MEM_MSB_D1_R0]. If CONFIG[RANK_ENA] is cleared, this field is ignored. */
 	uint64_t mem_msb_d1_r0                : 4;  /**< Maximum row MSB for DIMM1, RANK0.
+                                                         INTERNAL:
                                                          if DIMM1 contains 3DS DRAMs, this would point to
                                                          the logical rank's most significant bit. */
 	uint64_t mem_msb_d0_r1                : 4;  /**< Maximum row MSB for DIMM0, RANK1/DIMM0 in single ranked.
                                                          If DIMM0 is dual-sided, this should be set to
                                                          NXM[MEM_MSB_D0_R0]. If CONFIG[RANK_ENA] is cleared, this field is ignored. */
 	uint64_t mem_msb_d0_r0                : 4;  /**< Maximum row MSB for DIMM0, RANK0.
+                                                         INTERNAL:
                                                          If DIMM0 contains 3DS DRAMs, this would point to
                                                          the logical rank's most significant bit. */
 	uint64_t cs_mask                      : 8;  /**< Chip select mask. This mask corresponds to the four chip selects for a memory
@@ -10329,7 +10379,8 @@ union cvmx_lmcx_phy_ctl {
                                                          DQ against each DQS edge seperately. This is done at the clock rate. */
 	uint64_t dq_shallow_loopback          : 1;  /**< Reserved. INTERNAL: DQ shallow loopback, working in conjunction with LOOPBACK assertion.
                                                          When asserted, even DQ inputs can be loop-backed out through its adjacent odd DQ outputs
-                                                         without being flop'd by DQS. */
+                                                         without being flop'd by DQS. Need to make sure LMC()_PHY_CTL[PHY_DSK_BYP] is set and
+                                                         LMC()_PHY_CTL[INT_PHY_LOOPBACK_ENA] is unset. */
 	uint64_t dm_disable                   : 1;  /**< Write to 1 to disable the DRAM Data Mask feature by having LMC driving a constant value on
                                                          the
                                                          DDRX_DQS<17:9>_P pins of the chip during write operations. LMC drives a constant 0 in DDR3
@@ -10337,12 +10388,16 @@ union cvmx_lmcx_phy_ctl {
                                                          Note that setting this field high is NOT allowed when LMC has the Write DBI feature turned
                                                          on
                                                          (MODEREG_PARAMS3[WR_DBI]=1). */
-	uint64_t c1_sel                       : 2;  /**< 0x0 = C1 is not routed to any output pin.
+	uint64_t c1_sel                       : 2;  /**< Reserved.
+                                                         INTERNAL:
+                                                         0x0 = C1 is not routed to any output pin.
                                                          0x1 = C1 is routed to CS3.
                                                          0x2 = C1 is routed to A17 address pin.
                                                          0x3 = C1 is not routed to any output pin.
                                                          Set to 0x0 if not interfacing with 3DS DRAM. */
-	uint64_t c0_sel                       : 2;  /**< 0x0 = C0 is not routed to any output pin.
+	uint64_t c0_sel                       : 2;  /**< Reserved.
+                                                         INTERNAL:
+                                                         0x0 = C0 is not routed to any output pin.
                                                          0x1 = C0 is routed to CS2.
                                                          0x2 = C0 is routed to TEN output pin.
                                                          0x3 = C0 is not routed to any output pin.
@@ -10398,8 +10453,17 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t ck_dlyout1                   : 4;  /**< Reserved; must be zero. INTERNAL: Clock delay out. */
 	uint64_t ck_tune0                     : 1;  /**< Reserved; must be zero. INTERNAL: Clock tune. */
 	uint64_t ck_dlyout0                   : 4;  /**< Reserved; must be zero. INTERNAL: Clock delay out. */
-	uint64_t loopback                     : 1;  /**< Reserved; must be zero. INTERNAL: Loopback enable. */
-	uint64_t loopback_pos                 : 1;  /**< Reserved; must be zero. INTERNAL: Loopback pos mode. */
+	uint64_t loopback                     : 1;  /**< Reserved; must be zero.
+                                                         INTERNAL: external loopback enable. when asserted, Rx is on at DQS0 and data at even DQ
+                                                         bits
+                                                         are loop-backed out through odd DQ bits. For DQS, when LMC_PHY_CTL[PHY_DSK_BYP] and
+                                                         LMC_MEM_CFG0[MODE_X4DEV] are asserted along with LOOPBACK, DQS0 input of a given byte
+                                                         can be loop-backed out through DQS1 of the same byte. For DQ, when
+                                                         LMC()_PHY_CTL[DQ_SHALLOW_LOOPBACK] is asserted, DQ bits are loop-backed out without being
+                                                         flop'd by incoming DQS. When LMC()_PHY_CTL[DQ_SHALLOW_LOOPBACK] is deasserted, DQ bits are
+                                                         loop-backed out after being flop'd by incoming DQS. */
+	uint64_t loopback_pos                 : 1;  /**< Reserved; must be zero. INTERNAL: Loopback pos mode. This works in conjunction with
+                                                         LMC()_PHY_CTL[LOOPBACK] mentioned above. */
 	uint64_t ts_stagger                   : 1;  /**< TS stagger mode. This mode configures output drivers with two-stage drive strength to
                                                          avoid undershoot issues on the bus when strong drivers are suddenly turned on. When this
                                                          mode is asserted, CNXXXX will configure output drivers to be weak drivers (60ohm output
@@ -10606,7 +10670,8 @@ union cvmx_lmcx_phy_ctl {
                                                          DQ against each DQS edge seperately. This is done at the clock rate. */
 	uint64_t dq_shallow_loopback          : 1;  /**< Reserved. INTERNAL: DQ shallow loopback, working in conjunction with LOOPBACK assertion.
                                                          When asserted, even DQ inputs can be loop-backed out through its adjacent odd DQ outputs
-                                                         without being flop'd by DQS. */
+                                                         without being flop'd by DQS. Need to make sure LMC()_PHY_CTL[PHY_DSK_BYP] is set and
+                                                         LMC()_PHY_CTL[INT_PHY_LOOPBACK_ENA] is unset. */
 	uint64_t dm_disable                   : 1;  /**< Write to 1 to disable the DRAM Data Mask feature by having LMC driving a constant value on
                                                          the
                                                          DDRX_DQS<17:9>_P pins of the chip during write operations. LMC drives a constant 0 in DDR3
@@ -10614,12 +10679,16 @@ union cvmx_lmcx_phy_ctl {
                                                          Note that setting this field high is NOT allowed when LMC has the Write DBI feature turned
                                                          on
                                                          (MODEREG_PARAMS3[WR_DBI]=1). */
-	uint64_t c1_sel                       : 2;  /**< 0x0 = C1 is not routed to any output pin.
+	uint64_t c1_sel                       : 2;  /**< Reserved.
+                                                         INTERNAL:
+                                                         0x0 = C1 is not routed to any output pin.
                                                          0x1 = C1 is routed to CS3.
                                                          0x2 = C1 is routed to A17 address pin.
                                                          0x3 = C1 is not routed to any output pin.
                                                          Set to 0x0 if not interfacing with 3DS DRAM. */
-	uint64_t c0_sel                       : 2;  /**< 0x0 = C0 is not routed to any output pin.
+	uint64_t c0_sel                       : 2;  /**< Reserved.
+                                                         INTERNAL:
+                                                         0x0 = C0 is not routed to any output pin.
                                                          0x1 = C0 is routed to CS2.
                                                          0x2 = C0 is routed to TEN output pin.
                                                          0x3 = C0 is not routed to any output pin.
@@ -10675,8 +10744,17 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t ck_dlyout1                   : 4;  /**< Reserved; must be zero. INTERNAL: Clock delay out. */
 	uint64_t ck_tune0                     : 1;  /**< Reserved; must be zero. INTERNAL: Clock tune. */
 	uint64_t ck_dlyout0                   : 4;  /**< Reserved; must be zero. INTERNAL: Clock delay out. */
-	uint64_t loopback                     : 1;  /**< Reserved; must be zero. INTERNAL: Loopback enable. */
-	uint64_t loopback_pos                 : 1;  /**< Reserved; must be zero. INTERNAL: Loopback pos mode. */
+	uint64_t loopback                     : 1;  /**< Reserved; must be zero.
+                                                         INTERNAL: external loopback enable. when asserted, Rx is on at DQS0 and data at even DQ
+                                                         bits
+                                                         are loop-backed out through odd DQ bits. For DQS, when LMC_PHY_CTL[PHY_DSK_BYP] and
+                                                         LMC_MEM_CFG0[MODE_X4DEV] are asserted along with LOOPBACK, DQS0 input of a given byte
+                                                         can be loop-backed out through DQS1 of the same byte. For DQ, when
+                                                         LMC()_PHY_CTL[DQ_SHALLOW_LOOPBACK] is asserted, DQ bits are loop-backed out without being
+                                                         flop'd by incoming DQS. When LMC()_PHY_CTL[DQ_SHALLOW_LOOPBACK] is deasserted, DQ bits are
+                                                         loop-backed out after being flop'd by incoming DQS. */
+	uint64_t loopback_pos                 : 1;  /**< Reserved; must be zero. INTERNAL: Loopback pos mode. This works in conjunction with
+                                                         LMC()_PHY_CTL[LOOPBACK] mentioned above. */
 	uint64_t ts_stagger                   : 1;  /**< TS stagger mode. This mode configures output drivers with two-stage drive strength to
                                                          avoid undershoot issues on the bus when strong drivers are suddenly turned on. When this
                                                          mode is asserted, CNXXXX will configure output drivers to be weak drivers (60ohm output
@@ -11943,7 +12021,9 @@ union cvmx_lmcx_scrambled_fadr {
 	struct cvmx_lmcx_scrambled_fadr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t fcid                         : 3;  /**< Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
+	uint64_t fcid                         : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
                                                          either
                                                          LMC()_EXT_CONFIG[DIMM0_CID] or LMC()_EXT_CONFIG[DIMM1_CID] is non-zero). Returns a value
                                                          of zero
@@ -12008,7 +12088,9 @@ union cvmx_lmcx_scrambled_fadr {
 	struct cvmx_lmcx_scrambled_fadr_cn73xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t fcid                         : 3;  /**< Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
+	uint64_t fcid                         : 3;  /**< Reserved.
+                                                         INTERNAL:
+                                                         Failing CID number. This field is only valid when interfacing with 3DS DRAMs (i.e., when
                                                          either
                                                          LMC()_EXT_CONFIG[DIMM0_CID] or LMC()_EXT_CONFIG[DIMM1_CID] is non-zero). Returns a value
                                                          of zero
@@ -12092,8 +12174,7 @@ union cvmx_lmcx_seq_ctl {
                                                          LMC(0..0)_EXT_CONFIG[VREFINT_SEQ_DESKEW] is set.
                                                          0xb = Offset Training
                                                          Offset training sequence.
-                                                         0xe = Data Buffer Training. Configurable to run different modes of Data Buffer
-                                                         training on DDR4 LRDIMM. See LMC()_DBTRAIN_CTL for more detail.
+                                                         0xe = General R/W Training.
                                                          0xf = DDR4 Post Package Repair sequence. See LMC()_PPR_CTL for more detail.
                                                          Self-refresh entry SEQ_SEL's may also be automatically
                                                          generated by hardware upon a chip warm or soft reset
@@ -12108,7 +12189,10 @@ union cvmx_lmcx_seq_ctl {
                                                          through the remainder of the first and the second power-up/init.
                                                          If DDR_CKE* deactivation and reactivation is needed for
                                                          a second power-up/init, a DRESET assertion is required
-                                                         between the first and the second." */
+                                                         between the first and the second."
+                                                         INTERNAL:
+                                                         0xe = Data Buffer Training. Configurable to run different modes of Data Buffer
+                                                         training on DDR4 LRDIMM. See LMC()_DBTRAIN_CTL for more detail. */
 	uint64_t init_start                   : 1;  /**< A 0->1 transition starts the DDR memory sequence that is selected by
                                                          LMC()_SEQ_CTL[SEQ_SEL].
                                                          This register is a one-shot and clears itself each time it is set. */
@@ -12772,9 +12856,8 @@ union cvmx_lmcx_timing_params1 {
 	uint64_t trcd_ext                     : 1;  /**< A 1-bit extension to the TRCD register. */
 	uint64_t tpdm_full_cycle_ena          : 1;  /**< When set, this field enables the addition of one-cycle delay to the
                                                          Write/Read latency calculation. This is to compensate the case when
-                                                         tPDM delay in the RCD of an RDIMM/LRDIMM is greater than one-cycle.
-                                                         Only valid in RDIMM  (LMC()_CTL[RDIMM_ENA]=1) or LRDIMM
-                                                         (LMC()_CONFIG[LRDIMM_ENA=1) mode. */
+                                                         tPDM delay in the RCD of an RDIMM is greater than one-cycle.
+                                                         Only valid in RDIMM  (LMC()_CTL[RDIMM_ENA]=1). */
 	uint64_t trfc_dlr                     : 7;  /**< Indicates TRFC_DLR constraints. Set this field as follows:
                                                          _ RNDUP[TRFC_DLR(ns) / (8 * TCYC(ns))]
                                                          where TRFC_DLR is from the JEDEC 3D Stacked SDRAM spec, and TCYC(ns) is the DDR clock
@@ -13139,9 +13222,8 @@ union cvmx_lmcx_timing_params1 {
 	uint64_t trcd_ext                     : 1;  /**< A 1-bit extension to the TRCD register. */
 	uint64_t tpdm_full_cycle_ena          : 1;  /**< When set, this field enables the addition of one-cycle delay to the
                                                          Write/Read latency calculation. This is to compensate the case when
-                                                         tPDM delay in the RCD of an RDIMM/LRDIMM is greater than one-cycle.
-                                                         Only valid in RDIMM  (LMC()_CTL[RDIMM_ENA]=1) or LRDIMM
-                                                         (LMC()_CONFIG[LRDIMM_ENA=1) mode. */
+                                                         tPDM delay in the RCD of an RDIMM is greater than one-cycle.
+                                                         Only valid in RDIMM  (LMC()_CTL[RDIMM_ENA]=1). */
 	uint64_t trfc_dlr                     : 7;  /**< Indicates TRFC_DLR constraints. Set this field as follows:
                                                          _ RNDUP[TRFC_DLR(ns) / (8 * TCYC(ns))]
                                                          where TRFC_DLR is from the JEDEC 3D Stacked SDRAM spec, and TCYC(ns) is the DDR clock
@@ -13165,6 +13247,7 @@ union cvmx_lmcx_timing_params1 {
                                                          where TFAW is from the JEDEC DDR3/DDR4 spec, and TCYC(ns) is the DDR clock
                                                          frequency (not data rate).
                                                          TYP = 30-40 ns
+                                                         INTERNAL:
                                                          When interfacing with DIMMs that contain 3DS DRAMs, set this field as follows:
                                                          _ RNDUP[TFAW_SLR(ns) / (4 * TCYC(ns))]
                                                          where TFAW_SLR is the Four activate window to the same logical rank from the
@@ -13444,6 +13527,7 @@ union cvmx_lmcx_wlevel_ctl {
                                                          0x5 = LMC writes 0x6 (Rsvd) to MR1[Rtt_Nom].
                                                          0x6 = LMC writes 0x7 (Rsvd) to MR1[Rtt_Nom].
                                                          0x7 = LMC writes 0x0 (Disabled) to MR1[Rtt_Nom].
+                                                         INTERNAL:
                                                          In DDR4 LRDIMM application, this is used to program the Data Buffer Control Word BC00
                                                          during the Host Interface Write Leveling Mode:
                                                          0x0 = LMC writes 0x1 (RZQ/4).
diff --git a/arch/mips/include/asm/octeon/cvmx-mio-defs.h b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
index 896f06f..d6e2a78 100644
--- a/arch/mips/include/asm/octeon/cvmx-mio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
@@ -2566,7 +2566,7 @@ typedef union cvmx_mio_boot_bist_stat cvmx_mio_boot_bist_stat_t;
 /**
  * cvmx_mio_boot_comp
  *
- * This register sets the termination of boot-bus output pins.
+ * This register sets the output impedance of boot-bus output pins.
  *
  */
 union cvmx_mio_boot_comp {
@@ -3388,7 +3388,7 @@ union cvmx_mio_boot_pin_defs {
                                                          1 = PCIe2 is mapped to DLM5. */
 	uint64_t dmack_p1                     : 1;  /**< BOOT_DMACK<1> default polarity. */
 	uint64_t dmack_p0                     : 1;  /**< BOOT_DMACK<0> default polarity. */
-	uint64_t term                         : 2;  /**< Selects default boot-bus driver termination.
+	uint64_t term                         : 2;  /**< Selects default boot-bus driver termination (output impedance).
                                                          0x0 = 40 ohm (full strength).
                                                          0x1 = 30 ohm.
                                                          0x2 = 60 ohm.
@@ -3442,7 +3442,7 @@ union cvmx_mio_boot_pin_defs {
 	uint64_t user13                       : 1;  /**< BOOT_AD<13> latched during power up. */
 	uint64_t dmack_p1                     : 1;  /**< BOOT_DMACK<1> default polarity. */
 	uint64_t dmack_p0                     : 1;  /**< BOOT_DMACK<0> default polarity. */
-	uint64_t term                         : 2;  /**< Selects default boot-bus driver termination.
+	uint64_t term                         : 2;  /**< Selects default boot-bus driver termination (output impedance).
                                                          0x0 = 40 ohm (full strength).
                                                          0x1 = 30 ohm.
                                                          0x2 = 60 ohm.
@@ -3910,8 +3910,11 @@ union cvmx_mio_emm_cfg {
                                                          Setting bit2 of BUS_ENA causes EMMC_CMD[2] to become dedicated eMMC bus 2 command (i.e.
                                                          disabling any NOR use).
                                                          Bit3 of BUS_ENA is reserved.
-                                                         Setting any bit of BUS_ENA causes EMMC_CLK to become the eMMC clock for both bus0 and
-                                                         bus1. */
+                                                         Clearing all bits of this field will reset the other MIO_EMM_* registers.  It might be
+                                                         necessary
+                                                         to set and and clear the bits several times to insure the MIO_EMM_* registers have been
+                                                         reset properly.
+                                                         Setting one or more bits will enable EMMC_CLK operation. */
 #else
 	uint64_t bus_ena                      : 4;
 	uint64_t reserved_4_15                : 12;
diff --git a/arch/mips/include/asm/octeon/cvmx-ocla.h b/arch/mips/include/asm/octeon/cvmx-ocla.h
index a6af40a..fde2642 100644
--- a/arch/mips/include/asm/octeon/cvmx-ocla.h
+++ b/arch/mips/include/asm/octeon/cvmx-ocla.h
@@ -173,6 +173,7 @@
 typedef enum {
 	AGL,
 	ASE,
+	BCH,
 	BGX,
 	CIU,
 	DFA,
@@ -211,10 +212,12 @@ typedef enum {
 	RST,
 	SATA,
 	SLI,
+	SPEM,
 	SSO,
 	TIM,
 	USBH,
 	USBDRD,
+	XCV,
 	ZIP,
 	INVALID_BLOCK_ID = -1
 } cvmx_dtx_id_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
index a216b76..b6bbda5 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
@@ -9852,7 +9852,7 @@ union cvmx_pcieepx_cfg099 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t vfs                          : 16; /**< VF stride.
                                                          There are two VF Stride registers;  one for each ARI Capable
-                                                         and non-ARI Capable Hierarchies.  The PCIEP()_CFG096[ARI] determines which one is
+                                                         and non-ARI Capable Hierarchies.  The PCIEP()_CFG096[ACH] determines which one is
                                                          being used for SR-IOV, and which one is accessed by a read request.
                                                          This field is writable through PEM()_CFG_WR, PEM()_CFG_WR[ADDR[31]] determines
                                                          which VFS register is updated.
diff --git a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
index 7639b8a..4a2e26f 100644
--- a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
@@ -1655,11 +1655,14 @@ union cvmx_pemx_ctl_status {
                                                          PCIERC(0..3)_CFG006[PBNUM]. In EP mode, the bus number latched
                                                          on any type 0 configuration write. */
 	uint64_t reserved_32_33               : 2;
-	uint64_t cfg_rtry                     : 16; /**< The time * 0x10000 in coprocessor clocks to wait for a CPL to a configuration read that
-                                                         does not carry a retry status. Until such time that the timeout occurs and retry status is
-                                                         received for a configuration read, the read will be resent. A value of 0 disables retries
-                                                         and treats a CPL Retry as a CPL UR. When enabled, only one CFG RD may be issued until
-                                                         either successful completion or CPL UR. */
+	uint64_t cfg_rtry                     : 16; /**< The time times 0x10000 coprocessor-clocks to wait for a CPL to a configuration
+                                                         read that does not carry a retry status. Until such time that the timeout occurs
+                                                         and retry status is received for a configuration read, the read will be
+                                                         resent. A value of 0 disables retries and treats a CPL Retry as a CPL UR.
+                                                         To use, it is recommended CFG_RTRY be set value corresponding to 200ms or less, although
+                                                         the PCI Express Base Specification allows up to 900ms for a device to send a successful
+                                                         completion.  When enabled, only one CFG RD may be issued until either successful
+                                                         completion or CPL UR. */
 	uint64_t reserved_12_15               : 4;
 	uint64_t pm_xtoff                     : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_turnoff port. RC mode. */
 	uint64_t pm_xpme                      : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_pme port. EP mode. */
@@ -1773,11 +1776,14 @@ union cvmx_pemx_ctl_status {
                                                          PCIERC(0..3)_CFG006[PBNUM]. In EP mode, the bus number latched
                                                          on any type 0 configuration write. */
 	uint64_t reserved_32_33               : 2;
-	uint64_t cfg_rtry                     : 16; /**< The time * 0x10000 in coprocessor clocks to wait for a CPL to a configuration read that
-                                                         does not carry a retry status. Until such time that the timeout occurs and retry status is
-                                                         received for a configuration read, the read will be resent. A value of 0 disables retries
-                                                         and treats a CPL Retry as a CPL UR. When enabled, only one CFG RD may be issued until
-                                                         either successful completion or CPL UR. */
+	uint64_t cfg_rtry                     : 16; /**< The time times 0x10000 coprocessor-clocks to wait for a CPL to a configuration
+                                                         read that does not carry a retry status. Until such time that the timeout occurs
+                                                         and retry status is received for a configuration read, the read will be
+                                                         resent. A value of 0 disables retries and treats a CPL Retry as a CPL UR.
+                                                         To use, it is recommended CFG_RTRY be set value corresponding to 200ms or less, although
+                                                         the PCI Express Base Specification allows up to 900ms for a device to send a successful
+                                                         completion.  When enabled, only one CFG RD may be issued until either successful
+                                                         completion or CPL UR. */
 	uint64_t reserved_12_15               : 4;
 	uint64_t pm_xtoff                     : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_turnoff port. RC mode. */
 	uint64_t pm_xpme                      : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_pme port. EP mode. */
@@ -4208,15 +4214,16 @@ union cvmx_pemx_strap {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
 	uint64_t miopem2dlm5sel               : 1;  /**< The value of the BOOT_AD[13] pin via MIO, which is captured on chip cold reset. It is not
-                                                         affected by any other reset.  Only used for PEM2.  When set, PEM2 is configured to
-                                                         DLM5 and PEM()_QLM[PEMDLMSEL] will be set, the Mac will be confifgured for 2 lanes.
+                                                         affected by any other reset.  Only used for PEM2 and PEM3.  When set, PEM2/PEM3 are
+                                                         configured to
+                                                         DLM5/DLM6 and PEM()_QLM[PEMDLMSEL] will be set, the Mac will be confifgured for 2 lanes.
                                                          When clear, PEM2 is configured to QLM2. */
 	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin, which is captured on chip cold reset. It is not
                                                          affected by any other reset.  When set, lane swapping is performed to/from the
                                                          SerDes. When clear, no lane swapping is performed. */
 	uint64_t pilanes8                     : 1;  /**< The value of the pi_select_8lanes pin, which is captured on chip cold reset. It is not
-                                                         affected by any other reset.  When set, the PEM is configured for a maximum of
-                                                         8-lanes, When clear, the PEM is configured for a maximum of 4-lanes. */
+                                                         affected by any other reset.  When set, the PEM0/PEM2 are configured for a maximum of
+                                                         8-lanes, When clear, the PEM0/PEM2 are configured for a maximum of 4-lanes. */
 	uint64_t pimode                       : 2;  /**< The value of the pi_select_mode[1:0] pins, which are captured on chip cold reset. They are
                                                          not affected by any other reset.
                                                          0x0 = EP mode, Gen1 speed.
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-defs.h b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
index c2ea598..9c1053b 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
@@ -3551,22 +3551,27 @@ typedef union cvmx_pki_pkt_err cvmx_pki_pkt_err_t;
 /**
  * cvmx_pki_ptag_avail
  *
- * This register configures tag management. It is suggested that this
- * register only be written when PKI_BUF_CTL[PKI_EN] is clear and must not be reconfigured
- * without soft resetting PKI.
- * INTERNAL: Therefore do not put other fields into this register unless the same constraint
- * applies.
+ * For diagnostic use. INTERNAL: This register configures tag management. It is
+ * suggested that this register only be written when PKI_BUF_CTL[PKI_EN] is clear and
+ * must not be reconfigured without soft resetting PKI. While PKI is tolerant of
+ * changes to this register and programing restrictions are not necessary for the
+ * general case, the suggestion is to simplify verification. Therefore do not put other
+ * fields into this register unless the same constraint applies. When the number of
+ * tags available increases, PKI will simply have more resources. When the number of
+ * tags available decreases, PKI will use less resources and may begin to assert BP if
+ * the current tags in use exceeds the programmed value.
  */
 union cvmx_pki_ptag_avail {
 	uint64_t u64;
 	struct cvmx_pki_ptag_avail_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t avail                        : 8;  /**< Number of ptags available for use. Decreasing the number of ptags will
-                                                         reduce the number of packets waiting for parsing, which will lead to
-                                                         sooner backpressure/packet drop, but will decrease the small-packet
-                                                         latency of PKI by reducing buffer-bloat.  AVAIL must be at least as
-                                                         great as the number of reassembly-IDs used by the system. */
+	uint64_t avail                        : 8;  /**< Number of ptags available for use. Decreasing the number of ptags will reduce
+                                                         the number of packets waiting for parsing, which will lead to sooner
+                                                         backpressure/packet drop, but will decrease the small-packet latency of PKI by
+                                                         reducing buffer-bloat. AVAIL must be at least as great as the number of
+                                                         reassembly-IDs used by the system intends to use or the PTAGS can be exhausted
+                                                         and PKI will hang. */
 #else
 	uint64_t avail                        : 8;
 	uint64_t reserved_8_63                : 56;
diff --git a/arch/mips/include/asm/octeon/cvmx-pko-defs.h b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
index 566a87b..101848a 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
@@ -3546,6 +3546,8 @@ union cvmx_pko_dqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 48 clocks (SCLK). For the other levels a
@@ -3556,7 +3558,9 @@ union cvmx_pko_dqx_cir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -3774,6 +3778,8 @@ union cvmx_pko_dqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 48 clocks (SCLK). For the other levels a
@@ -3784,7 +3790,9 @@ union cvmx_pko_dqx_pir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -4402,6 +4410,8 @@ union cvmx_pko_l1_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 48 clocks (SCLK). For the other levels a
@@ -4412,7 +4422,9 @@ union cvmx_pko_l1_sqx_cir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -5254,6 +5266,8 @@ union cvmx_pko_l2_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 48 clocks (SCLK). For the other levels a
@@ -5264,7 +5278,9 @@ union cvmx_pko_l2_sqx_cir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -5424,6 +5440,8 @@ union cvmx_pko_l2_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 48 clocks (SCLK). For the other levels a
@@ -5434,7 +5452,9 @@ union cvmx_pko_l2_sqx_pir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -5983,6 +6003,8 @@ union cvmx_pko_l3_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 48 clocks (SCLK). For the other levels a
@@ -5993,7 +6015,9 @@ union cvmx_pko_l3_sqx_cir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -6161,6 +6185,8 @@ union cvmx_pko_l3_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 48 clocks (SCLK). For the other levels a
@@ -6171,7 +6197,9 @@ union cvmx_pko_l3_sqx_pir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -6641,6 +6669,8 @@ union cvmx_pko_l4_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
@@ -6651,7 +6681,9 @@ union cvmx_pko_l4_sqx_cir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -6797,6 +6829,8 @@ union cvmx_pko_l4_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
@@ -6807,7 +6841,9 @@ union cvmx_pko_l4_sqx_pir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -7175,6 +7211,8 @@ union cvmx_pko_l5_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
@@ -7185,7 +7223,9 @@ union cvmx_pko_l5_sqx_cir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
@@ -7331,6 +7371,8 @@ union cvmx_pko_l5_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
+                                                         RATE_DIVIDER_EXPONENT should be used to specify data rates lower than ~10 Kbps and
+                                                         RATE_EXPONENT should be set to zero whenever it is used.
                                                          The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
                                                          RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
                                                          Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
@@ -7341,7 +7383,9 @@ union cvmx_pko_l5_sqx_pir {
                                                          For L[5:2]_SQ: RATE (bytes/second) =
                                                            (SCLK_FREQUENCY / 768) * ((1.RATE_MANTISSA) << RATE_EXPONENT) / (1 <<
                                                          RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
+	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT.
+                                                         RATE_EXPONENT should be used to specify data rates higher than ~10 Kbps and
+                                                         RATE_DIVIDER_EXPONENT should be set to zero whenever it is non-zero. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
 #else
diff --git a/arch/mips/include/asm/octeon/cvmx-pow.h b/arch/mips/include/asm/octeon/cvmx-pow.h
index 98c9cd5..fe018c4 100644
--- a/arch/mips/include/asm/octeon/cvmx-pow.h
+++ b/arch/mips/include/asm/octeon/cvmx-pow.h
@@ -2308,6 +2308,81 @@ static inline void cvmx_pow_tag_sw_full(cvmx_wqe_t * wqp, uint32_t tag, cvmx_pow
 }
 
 /**
+ * Executes SWTAG_FULL SSO command.
+ * This is similiar to cvmx_pow_tag_sw_full() function, but uses linear
+ * (vs. integrated group-qos) group index.
+ */
+static inline void cvmx_pow_tag_sw_full_node(cvmx_wqe_t * wqp, uint32_t tag, cvmx_pow_tag_type_t tag_type, uint64_t xgrp, int node)
+{
+	union cvmx_pow_tag_req_addr ptr;
+	cvmx_pow_tag_req_t tag_req;
+	int group;
+
+	if (CVMX_ENABLE_POW_CHECKS)
+		__cvmx_pow_warn_if_pending_switch(__func__);
+
+	/* Ensure that there is not a pending tag switch, as a tag switch cannot be started
+	 ** if a previous switch is still pending.  */
+	CVMX_SYNCWS;
+	cvmx_pow_tag_sw_wait();
+
+	if (CVMX_ENABLE_POW_CHECKS) {
+		cvmx_pow_tag_info_t current_tag;
+		__cvmx_pow_warn_if_pending_switch(__func__);
+		current_tag = cvmx_pow_get_current_tag();
+		cvmx_warn_if(current_tag.tag_type == CVMX_POW_TAG_TYPE_NULL_NULL, "%s called with NULL_NULL tag\n", __func__);
+		cvmx_warn_if((current_tag.tag_type == tag_type) && (current_tag.tag == tag), "%s called to perform a tag switch to the same tag\n", __func__);
+		cvmx_warn_if(tag_type == CVMX_POW_TAG_TYPE_NULL, "%s called to perform a tag switch to NULL. Use cvmx_pow_tag_sw_null() instead\n", __func__);
+		if ((wqp != cvmx_phys_to_ptr(0x80)) && cvmx_pow_get_current_wqp())
+			cvmx_warn_if(wqp != cvmx_pow_get_current_wqp(), "%s passed WQE(%p) doesn't match the address in the POW(%p)\n", __func__, wqp, cvmx_pow_get_current_wqp());
+	}
+	/* Note that WQE in DRAM is not updated here, as the POW does not read from DRAM
+	 * once the WQE is in flight.
+	 */
+	group = xgrp & 0xff;
+	tag_req.u64 = 0;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		uint64_t wqp_phys = cvmx_ptr_to_phys(wqp);
+
+		if(wqp_phys!= 0x80) {
+			wqp->word1.cn78xx.grp = group;
+			wqp->word1.cn78xx.tag = tag;
+			wqp->word1.cn78xx.tag_type = tag_type;
+			CVMX_SYNCWS;
+		}
+		tag_req.s_cn78xx_other.op = CVMX_POW_TAG_OP_SWTAG_FULL;
+		tag_req.s_cn78xx_other.type = tag_type;
+		tag_req.s_cn78xx_other.grp = group;
+		tag_req.s_cn78xx_other.wqp = wqp_phys;
+	}
+	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
+		tag_req.s_cn68xx_other.op = CVMX_POW_TAG_OP_SWTAG_FULL;
+		tag_req.s_cn68xx_other.tag = tag;
+		tag_req.s_cn68xx_other.type = tag_type;
+		tag_req.s_cn68xx_other.grp = group;
+	} else {
+		tag_req.s_cn38xx.op = CVMX_POW_TAG_OP_SWTAG_FULL;
+		tag_req.s_cn38xx.tag = tag;
+		tag_req.s_cn38xx.type = tag_type;
+		tag_req.s_cn38xx.grp = group;
+	}
+	ptr.u64 = 0;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		ptr.s_cn78xx.mem_region = CVMX_IO_SEG;
+		ptr.s_cn78xx.is_io = 1;
+		ptr.s_cn78xx.did = CVMX_OCT_DID_TAG_SWTAG;
+		ptr.s_cn78xx.node = node;
+		ptr.s_cn78xx.tag  = tag;
+	} else {
+		ptr.s.mem_region = CVMX_IO_SEG;
+		ptr.s.is_io = 1;
+		ptr.s.did = CVMX_OCT_DID_TAG_SWTAG;
+		ptr.s.addr = cvmx_ptr_to_phys(wqp);
+	}
+	cvmx_write_io(ptr.u64, tag_req.u64);
+}
+
+/**
  * Switch to a NULL tag, which ends any ordering or
  * synchronization provided by the POW for the current
  * work queue entry.  This operation completes immediately,
@@ -2646,27 +2721,22 @@ static inline void cvmx_pow_set_group_mask(uint64_t core_num, uint64_t mask)
 }
 
 /**
- * This function sets the group mask for a core.  The group mask
- * indicates which groups each core will accept work from. There are
- * 256 groups in 78xx.
- *
- * @param core_num   	processor core to apply mask to
- * @param mask_set	78XX has 2 set of masks per core each with 256 groups.
- *                      Bit 0 represents the first mask set, bit 1 the second,
- * 			when set a each member of 'xgrp_mask' will be added
- * 			to the core, when cleared, each of the groups in
- * 			'xgrp_mask' will be removed from the mask set.
- * @param xgrp_mask   	Group mask. There are 256 groups, divided in 4 of 64 bit mask sets.
- * 	        	Each 1 bit in the mask enables the core to accept work from
- *      	        the corresponding group.
- *
- * Note: each core can be configured to accept work in accordance to both
+ * This function sets the group mask for a core.  The group mask bits
+ * indicate which groups each core will accept work from.
+ *
+ * @param core_num 	Processor core to apply mask to.
+ * @param mask_set	7XXX has 2 sets of masks per core.
+ *                  Bit 0 represents the first mask set, bit 1 -- the second.
+ * @param xgrp_mask	Group mask array.
+ *                  Total number of groups is divided into a number of
+ *                  64-bits mask sets. Each bit in the mask, if set, enables
+ *                  the core to accept work from the corresponding group.
+ *
+ * NOTE: Each core can be configured to accept work in accordance to both
  * mask sets, with the first having higher precedence over the second,
  * or to accept work in accordance to just one of the two mask sets.
  * The 'core_num' argument represents a processor core on any node
  * in a coherent multi-chip system.
- *
- * TBD: function to configure which mask_set is applied to a core.
  */
 static inline void cvmx_pow_set_xgrp_mask( uint64_t core_num,
 		uint8_t mask_set, const uint64_t xgrp_mask[])
@@ -2680,7 +2750,6 @@ static inline void cvmx_pow_set_xgrp_mask( uint64_t core_num,
 			__FUNCTION__);
 		return;
 	}
-
 	node = cvmx_coremask_core_to_node(core_num);
 	core = cvmx_coremask_core_on_node(core_num);
 
@@ -2688,23 +2757,15 @@ static inline void cvmx_pow_set_xgrp_mask( uint64_t core_num,
 		uint64_t reg_addr;
 
 		reg_addr = CVMX_SSO_PPX_SX_GRPMSKX(core, 0, grp),
-		grp_msk.u64 = cvmx_read_csr_node(node,reg_addr);
-
+		grp_msk.u64 = 0;
 		if (mask_set & 1)
-			grp_msk.s.grp_msk |= xgrp_mask[grp];
-		else
-			grp_msk.s.grp_msk &= ~xgrp_mask[grp];
-
+			grp_msk.s.grp_msk = xgrp_mask[grp];
 		cvmx_write_csr_node(node, reg_addr, grp_msk.u64);
 
 		reg_addr = CVMX_SSO_PPX_SX_GRPMSKX(core, 1, grp),
-		grp_msk.u64 = cvmx_read_csr_node(node,reg_addr);
-
+		grp_msk.u64 = 0;
 		if (mask_set & 2)
-			grp_msk.s.grp_msk |= xgrp_mask[grp];
-		else
-			grp_msk.s.grp_msk &= ~xgrp_mask[grp];
-
+			grp_msk.s.grp_msk = xgrp_mask[grp];
 		cvmx_write_csr_node(node, reg_addr, grp_msk.u64);
 	}
 }
@@ -2959,13 +3020,22 @@ static inline void cvmx_pow_tag_sw_desched_nocheck(uint32_t tag, cvmx_pow_tag_ty
 
 	tag_req.u64 = 0;
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_t *wqp = cvmx_pow_get_current_wqp();
+		if (wqp == NULL) {
+			cvmx_dprintf("ERROR: Failed to get WQE, %s\n", __func__);
+			return;
+		}
 		group &= 0x1f;
+		wqp->word1.cn78xx.tag = tag;
+		wqp->word1.cn78xx.tag_type = tag_type;
+		wqp->word1.cn78xx.grp = group << 3;
+		CVMX_SYNCWS;
 		tag_req.s_cn78xx_other.op = CVMX_POW_TAG_OP_SWTAG_DESCH;
 		tag_req.s_cn78xx_other.type = tag_type;
 		tag_req.s_cn78xx_other.grp = group << 3;
-		tag_req.s_cn68xx_other.no_sched = no_sched;
+		tag_req.s_cn78xx_other.no_sched = no_sched;
 	}
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
+	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		group &= 0x3f;
 		tag_req.s_cn68xx_other.op = CVMX_POW_TAG_OP_SWTAG_DESCH;
 		tag_req.s_cn68xx_other.tag = tag;
@@ -3051,6 +3121,83 @@ static inline void cvmx_pow_tag_sw_desched(uint32_t tag, cvmx_pow_tag_type_t tag
 }
 
 /**
+ * Performs a SWTAG_DESCHED SSO operation.
+ * This is similar to the cvmx_pow_tag_sw_desched() function, but uses linear
+ * (vs. unified group-qos) group index.
+ */
+static inline void cvmx_pow_tag_sw_desched_node(uint32_t tag, cvmx_pow_tag_type_t tag_type, uint64_t xgrp, uint64_t no_sched, int node)
+{
+	union cvmx_pow_tag_req_addr ptr;
+	cvmx_pow_tag_req_t tag_req;
+	int group;
+
+	if (CVMX_ENABLE_POW_CHECKS)
+		__cvmx_pow_warn_if_pending_switch(__func__);
+
+	/* Need to make sure any writes to the work queue entry are complete */
+	CVMX_SYNCWS;
+	/* Ensure that there is not a pending tag switch, as a tag switch cannot be started
+	 ** if a previous switch is still pending.  */
+	cvmx_pow_tag_sw_wait();
+
+	if (CVMX_ENABLE_POW_CHECKS) {
+		cvmx_pow_tag_info_t current_tag;
+		__cvmx_pow_warn_if_pending_switch(__func__);
+		current_tag = cvmx_pow_get_current_tag();
+		cvmx_warn_if(current_tag.tag_type == CVMX_POW_TAG_TYPE_NULL_NULL, "%s called with NULL_NULL tag\n", __func__);
+		cvmx_warn_if(current_tag.tag_type == CVMX_POW_TAG_TYPE_NULL, "%s called with NULL tag. Deschedule not allowed from NULL state\n", __func__);
+		cvmx_warn_if((current_tag.tag_type != CVMX_POW_TAG_TYPE_ATOMIC)
+			     && (tag_type != CVMX_POW_TAG_TYPE_ATOMIC), "%s called where neither the before or after tag is ATOMIC\n", __func__);
+	}
+	group = xgrp;
+	tag_req.u64 = 0;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_t *wqp = cvmx_pow_get_current_wqp();
+		if (wqp == NULL) {
+			cvmx_dprintf("ERROR: Failed to get WQE, %s\n", __func__);
+			return;
+		}
+		group &= 0xff;
+		wqp->word1.cn78xx.tag = tag;
+		wqp->word1.cn78xx.tag_type = tag_type;
+		wqp->word1.cn78xx.grp = group;
+		CVMX_SYNCWS;
+		tag_req.s_cn78xx_other.op = CVMX_POW_TAG_OP_SWTAG_DESCH;
+		tag_req.s_cn78xx_other.type = tag_type;
+		tag_req.s_cn78xx_other.grp = group;
+		tag_req.s_cn78xx_other.no_sched = no_sched;
+	}
+	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
+		group &= 0x3f;
+		tag_req.s_cn68xx_other.op = CVMX_POW_TAG_OP_SWTAG_DESCH;
+		tag_req.s_cn68xx_other.tag = tag;
+		tag_req.s_cn68xx_other.type = tag_type;
+		tag_req.s_cn68xx_other.grp = group;
+		tag_req.s_cn68xx_other.no_sched = no_sched;
+	} else {
+		group &= 0x0f;
+		tag_req.s_cn38xx.op = CVMX_POW_TAG_OP_SWTAG_DESCH;
+		tag_req.s_cn38xx.tag = tag;
+		tag_req.s_cn38xx.type = tag_type;
+		tag_req.s_cn38xx.grp = group;
+		tag_req.s_cn38xx.no_sched = no_sched;
+	}
+	ptr.u64 = 0;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		ptr.s.mem_region = CVMX_IO_SEG;
+		ptr.s.is_io = 1;
+		ptr.s.did = CVMX_OCT_DID_TAG_TAG3;
+		ptr.s_cn78xx.node =  node;
+		ptr.s_cn78xx.tag  = tag;
+	} else {
+		ptr.s.mem_region = CVMX_IO_SEG;
+		ptr.s.is_io = 1;
+		ptr.s.did = CVMX_OCT_DID_TAG_TAG3;
+	}
+	cvmx_write_io(ptr.u64, tag_req.u64);
+}
+
+/**
  * Descchedules the current work queue entry.
  *
  * @param no_sched no schedule flag value to be set on the work queue entry.  If this is set
diff --git a/arch/mips/include/asm/octeon/cvmx-qlm.h b/arch/mips/include/asm/octeon/cvmx-qlm.h
index 24e8bc7..b2ae632 100644
--- a/arch/mips/include/asm/octeon/cvmx-qlm.h
+++ b/arch/mips/include/asm/octeon/cvmx-qlm.h
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 122066 $<hr>
+ * <hr>$Revision: 123908 $<hr>
  */
 
 #ifndef __CVMX_QLM_H__
@@ -232,6 +232,7 @@ enum cvmx_qlm_mode {
 	CVMX_QLM_MODE_10G_KR_1X2, /* Configure BGX2 separate for DLM5 & DLM6 */
 	CVMX_QLM_MODE_XFI_1X2,    /* Configure BGX2 separate for DLM5 & DLM6 */
 	CVMX_QLM_MODE_RGMII_SGMII_1X1, /* Configure BGX2, applies to DLM5 */
+	CVMX_QLM_MODE_RGMII_SGMII_2X1, /* Configure BGX2, applies to DLM6 */
 	CVMX_QLM_MODE_RGMII_10G_KR_1X1, /* Configure BGX2, applies to DLM6 */
 	CVMX_QLM_MODE_RGMII_XFI_1X1, /* Configure BGX2, applies to DLM6 */
 	CVMX_QLM_MODE_OCI
diff --git a/arch/mips/include/asm/octeon/cvmx-sli-defs.h b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
index 0b14bb8..a553cf4 100644
--- a/arch/mips/include/asm/octeon/cvmx-sli-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
@@ -4357,7 +4357,7 @@ union cvmx_sli_data_out_cnt {
 	uint64_t p1_ucnt                      : 16; /**< FIFO1 unload count. This counter is incremented by 1 every time a word is removed from
                                                          data out FIFO1, whose count is shown in P1_FCNT. */
 	uint64_t p1_fcnt                      : 6;  /**< FIFO1 data out count. Number of address data words presently buffered in the FIFO1. MACs
-                                                         associated with FIFO1: PCIe2, PCIe3. */
+                                                         associated with FIFO1: PCIe2, PCIe3, SRIO2, SRIO3. */
 	uint64_t p0_ucnt                      : 16; /**< FIFO0 unload count. This counter is incremented by 1 every time a word is removed from
                                                          data out FIFO0, whose count is shown in P0_FCNT. */
 	uint64_t p0_fcnt                      : 6;  /**< FIFO0 data out count. Number of address data words presently buffered in the FIFO0. MACs
@@ -4477,7 +4477,7 @@ union cvmx_sli_dmax_cnt {
                                                          counter after completing an OUTBOUND or EXTERNAL-ONLY DMA instruction
                                                          with DPI_DMA_INSTR_HDR_S[CA] set DPI_DMA_INSTR_HDR_S[CSEL] equal to this
                                                          CSR index. These increments may cause interrupts.
-                                                         See SLI_DMA()_INT_LEVEL and SLI_INT_SUM[DCNT,DTIME]. */
+                                                         See SLI_DMA()_INT_LEVEL and SLI_MAC()_PF()_INT_SUM[DCNT,DTIME]. */
 #else
 	uint64_t cnt                          : 32;
 	uint64_t reserved_32_63               : 32;
@@ -4509,11 +4509,12 @@ union cvmx_sli_dmax_int_level {
 	uint64_t u64;
 	struct cvmx_sli_dmax_int_level_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t time                         : 32; /**< Whenever the SLI_DMA()_TIM[TIM] timer exceeds this value, SLI_INT_SUM[DTIME<x>] is
-                                                         set. The SLI_DMA()_TIM[TIM] timer increments every SLI clock whenever
-                                                         SLI_DMA()_CNT[CNT] != 0, and is cleared when SLI_INT_SUM[DTIME<x>] is written with
-                                                         one. */
-	uint64_t cnt                          : 32; /**< Whenever SLI_DMA()_CNT[CNT] exceeds this value, SLI_INT_SUM[DCNT<x>] is set. */
+	uint64_t time                         : 32; /**< Whenever the SLI_DMA()_TIM[TIM] timer exceeds this value,
+                                                         SLI_MAC()_PF()_INT_SUM[DTIME<x>] is set. The SLI_DMA()_TIM[TIM] timer
+                                                         increments every SLI clock whenever SLI_DMA()_CNT[CNT] != 0, and is cleared
+                                                         when SLI_MAC()_PF()_INT_SUM[DTIME<x>] is written with one. */
+	uint64_t cnt                          : 32; /**< Whenever SLI_DMA()_CNT[CNT] exceeds this value, SLI_MAC()_PF()_INT_SUM[DCNT<x>]
+                                                         is set. */
 #else
 	uint64_t cnt                          : 32;
 	uint64_t time                         : 32;
@@ -6836,7 +6837,7 @@ typedef union cvmx_sli_last_win_rdata3 cvmx_sli_last_win_rdata3_t;
  *
  * When an error response is received for a VF DMA transaction read, the appropriate VF indexed
  * bit is set.  The appropriate PF should read the appropriate register.
- * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ * These registers are only valid for PEM0
  */
 union cvmx_sli_macx_pfx_dma_vf_int {
 	uint64_t u64;
@@ -6857,7 +6858,7 @@ typedef union cvmx_sli_macx_pfx_dma_vf_int cvmx_sli_macx_pfx_dma_vf_int_t;
 /**
  * cvmx_sli_mac#_pf#_dma_vf_int_enb
  *
- * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ * These registers are only valid for PEM0 PF0
  *
  */
 union cvmx_sli_macx_pfx_dma_vf_int_enb {
@@ -6878,7 +6879,7 @@ typedef union cvmx_sli_macx_pfx_dma_vf_int_enb cvmx_sli_macx_pfx_dma_vf_int_enb_
  * cvmx_sli_mac#_pf#_flr_vf_int
  *
  * When a
- * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ * These registers are only valid for PEM0 PF0
  */
 union cvmx_sli_macx_pfx_flr_vf_int {
 	uint64_t u64;
@@ -7087,10 +7088,8 @@ typedef union cvmx_sli_macx_pfx_int_sum cvmx_sli_macx_pfx_int_sum_t;
 /**
  * cvmx_sli_mac#_pf#_mbox_int
  *
- * When an VF wants to communicate to a PF it writes its SLI_PKT(0..63)_PF_VF_MBOX_SIG(0..1)
- * register the appropriate Ring indexed bit is set.  The PF should then read the appropriate
- * SLI_PKT()_PF_VF_MBOX_SIG() indexed register.
- * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ * These registers are only valid for PEM0 PF0
+ *
  */
 union cvmx_sli_macx_pfx_mbox_int {
 	uint64_t u64;
@@ -7115,7 +7114,7 @@ typedef union cvmx_sli_macx_pfx_mbox_int cvmx_sli_macx_pfx_mbox_int_t;
  * overflow for a ring associated with a VF occurs or an illegal memory access from a VF occurs,
  * the appropriate VF indexed bit is set.  The appropriate PF should read the appropriate
  * register.
- * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ * These registers are only valid for PEM0 PF0
  */
 union cvmx_sli_macx_pfx_pkt_vf_int {
 	uint64_t u64;
@@ -7136,7 +7135,7 @@ typedef union cvmx_sli_macx_pfx_pkt_vf_int cvmx_sli_macx_pfx_pkt_vf_int_t;
 /**
  * cvmx_sli_mac#_pf#_pkt_vf_int_enb
  *
- * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ * These registers are only valid for PEM0 PF0
  *
  */
 union cvmx_sli_macx_pfx_pkt_vf_int_enb {
@@ -7158,7 +7157,7 @@ typedef union cvmx_sli_macx_pfx_pkt_vf_int_enb cvmx_sli_macx_pfx_pkt_vf_int_enb_
  *
  * When an error response is received for a VF PP transaction read, the appropriate VF indexed
  * bit is set.  The appropriate PF should read the appropriate register.
- * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ * These registers are only valid for PEM0 PF0
  */
 union cvmx_sli_macx_pfx_pp_vf_int {
 	uint64_t u64;
@@ -7179,7 +7178,7 @@ typedef union cvmx_sli_macx_pfx_pp_vf_int cvmx_sli_macx_pfx_pp_vf_int_t;
 /**
  * cvmx_sli_mac#_pf#_pp_vf_int_enb
  *
- * These registers are only valid for PEM0 PF0, PEM0 PF1, PEM2 PF0
+ * These registers are only valid for PEM0 PF0
  *
  */
 union cvmx_sli_macx_pfx_pp_vf_int_enb {
@@ -7425,7 +7424,7 @@ union cvmx_sli_mem_access_subidx {
                                                          with SR-IOV enabled. */
 	uint64_t reserved_43_43               : 1;
 	uint64_t zero                         : 1;  /**< Causes all byte read operations to be zero-length read operations. Returns 0s to the EXEC
-                                                         for all read data. */
+                                                         for all read data. This must be zero for SRIO ports. */
 	uint64_t port                         : 3;  /**< The MAC that the reads/writes/atomics are sent to. */
 	uint64_t nmerge                       : 1;  /**< When set, no merging is allowed in this window. Applicable to writes only. */
 	uint64_t esr                          : 2;  /**< Endian swap for read operations. ES<1:0> for read operations to this subID. ES<1:0> is the
@@ -7437,12 +7436,18 @@ union cvmx_sli_mem_access_subidx {
                                                          and IOBDMAs.
                                                          Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t wtype                        : 2;  /**< Write type. ADDRTYPE<1:0> for write operations to this subID.
-                                                         * ADDRTYPE<0> is the relaxed-order attribute.
-                                                         * ADDRTYPE<1> is the no-snoop attribute.
+                                                         For PCIE:
+                                                           * ADDRTYPE<0> is the relaxed-order attribute.
+                                                           * ADDRTYPE<1> is the no-snoop attribute.
+                                                         For SRIO:
+                                                           * ADDRTYPE<1:0> help select an SRIO*_S2M_TYPE* entry.
                                                          Not used for reads and IOBDMAs. */
 	uint64_t rtype                        : 2;  /**< Read type. ADDRTYPE<1:0> for read operations to this subID.
-                                                         * ADDRTYPE<0> is the relaxed-order attribute.
-                                                         * ADDRTYPE<1> is the no-snoop attribute.
+                                                         For PCIE:
+                                                           * ADDRTYPE<0> is the relaxed-order attribute.
+                                                           * ADDRTYPE<1> is the no-snoop attribute.
+                                                         For SRIO:
+                                                           * ADDRTYPE<1:0> help select an SRIO*_S2M_TYPE* entry.
                                                          Not used for writes and atomics. */
 	uint64_t reserved_0_29                : 30;
 #else
@@ -8522,7 +8527,7 @@ typedef union cvmx_sli_pcie_msi_rcv cvmx_sli_pcie_msi_rcv_t;
  *
  * This register is where MSI write operations are directed from the MAC. This register can be
  * used by
- * the PCIe MACs.
+ * the PCIe and SRIO MACs.
  */
 union cvmx_sli_pcie_msi_rcv_b1 {
 	uint64_t u64;
@@ -8560,7 +8565,7 @@ typedef union cvmx_sli_pcie_msi_rcv_b1 cvmx_sli_pcie_msi_rcv_b1_t;
  *
  * This register is where MSI write operations are directed from the MAC.  This register can be
  * used
- * by PCIe MACs.
+ * by PCIe and SRIO MACs.
  */
 union cvmx_sli_pcie_msi_rcv_b2 {
 	uint64_t u64;
@@ -8598,7 +8603,7 @@ typedef union cvmx_sli_pcie_msi_rcv_b2 cvmx_sli_pcie_msi_rcv_b2_t;
  *
  * This register is where MSI write operations are directed from the MAC. This register can be
  * used by
- * PCIe MACs.
+ * PCIe and SRIO MACs.
  */
 union cvmx_sli_pcie_msi_rcv_b3 {
 	uint64_t u64;
@@ -8813,33 +8818,7 @@ union cvmx_sli_pktx_error_info {
 #endif
 	} s;
 	struct cvmx_sli_pktx_error_info_s     cn73xx;
-	struct cvmx_sli_pktx_error_info_cnf75xx {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_7_63                : 57;
-	uint64_t nobdell_err                  : 1;  /**< A VF has no slists doorbell pointers for an outbound packet that is ready
-                                                         to be sent. */
-	uint64_t pins_err                     : 1;  /**< Packet instruction read error. When a read error occurs on a packet instruction, this bit
-                                                         is set. */
-	uint64_t pop_err                      : 1;  /**< Packet scatter pointer pair error. When a read error occurs on a packet scatter pointer
-                                                         pair, this bit is set. */
-	uint64_t pdi_err                      : 1;  /**< Packet data read error. When a read error occurs on a packet data read, this bit is set. */
-	uint64_t pgl_err                      : 1;  /**< Packet gather list read error. When a read error occurs on a packet gather list read, this
-                                                         bit is set. */
-	uint64_t psldbof                      : 1;  /**< Packet scatter list doorbell count overflowed. Which doorbell can be found in
-                                                         DPI_PINT_INFO[PSLDBOF]. */
-	uint64_t pidbof                       : 1;  /**< Packet instruction doorbell count overflowed. Which doorbell can be found in
-                                                         DPI_PINT_INFO[PIDBOF]. */
-#else
-	uint64_t pidbof                       : 1;
-	uint64_t psldbof                      : 1;
-	uint64_t pgl_err                      : 1;
-	uint64_t pdi_err                      : 1;
-	uint64_t pop_err                      : 1;
-	uint64_t pins_err                     : 1;
-	uint64_t nobdell_err                  : 1;
-	uint64_t reserved_7_63                : 57;
-#endif
-	} cnf75xx;
+	struct cvmx_sli_pktx_error_info_s     cnf75xx;
 };
 typedef union cvmx_sli_pktx_error_info cvmx_sli_pktx_error_info_t;
 
@@ -8928,6 +8907,7 @@ union cvmx_sli_pktx_input_control {
 	uint64_t pbp_dhi                      : 13; /**< Not used by hardware, but may be cleared by hardware when [RST] is set. */
 	uint64_t d_nsr                        : 1;  /**< If [USE_CSR]=1, [D_NSR] is ADDRTYPE<1> for First Direct and Gather DPTR
                                                          reads. ADDRTYPE<1> is the no-snoop attribute for PCIe. (DPTR Format 0)
+                                                         ADDRTYPE<1> helps select an SRIO*_S2M_TYPE* entry with sRIO.
                                                          If [USE_CSR]=0, [D_NSR] is MACADD<61> for First Direct and Gather DPTR
                                                          reads. (ADDRTYPE<1> comes from DPTR<61> in these cases when [USE_CSR]=0.)
                                                          (DPTR Format 1) */
@@ -8940,6 +8920,7 @@ union cvmx_sli_pktx_input_control {
                                                          (DPTR Format 1) */
 	uint64_t d_ror                        : 1;  /**< If [USE_CSR]=1, [D_ROR] is ADDRTYPE<0> for First Direct and Gather DPTR
                                                          reads. ADDRTYPE<0> is the relaxed-order attribute for PCIe. (DPTR Format 0)
+                                                         It helps select an SRIO*_S2M_TYPE* entry with sRIO.
                                                          If [USE_CSR]=0, [D_NSR] is MACADD<60> for First Direct and Gather DPTR
                                                          reads. (ADDRTYPE<0> comes from DPTR<60> in these cases when [USE_CSR]=0.)
                                                          (DPTR Format 1) */
@@ -8949,14 +8930,16 @@ union cvmx_sli_pktx_input_control {
                                                          and NSR become bits <63:60> of the address used to fetch packet data. */
 	uint64_t nsr                          : 1;  /**< [NSR] is ADDRTYPE<1> for input instruction reads (from
                                                          SLI_PKT()_INSTR_BADDR+) and First Indirect DPTR reads. ADDRTYPE<1>
-                                                         is the no-snoop attribute for PCIe. */
+                                                         is the no-snoop attribute for PCIe.
+                                                         [NSR] helps select an SRIO*_S2M_TYPE* entry with sRIO. */
 	uint64_t esr                          : 2;  /**< [ESR] is ES<1:0> for input instruction reads (from
                                                          SLI_PKT()_INSTR_BADDR+) and First Indirect DPTR reads. ES<1:0> is
                                                          the endian-swap attribute for these MAC memory space reads.
                                                          Enumerated by SLI_ENDIANSWAP_E. */
 	uint64_t ror                          : 1;  /**< [ROR] is ADDRTYPE<0> for input instruction reads (from
                                                          SLI_PKT()_INSTR_BADDR+) and First Indirect DPTR reads.
-                                                         ADDRTYPE<0> is the relaxed-order attribute for PCIe. */
+                                                         ADDRTYPE<0> is the relaxed-order attribute for PCIe.
+                                                         It helps select an SRIO*_S2M_TYPE* entry with sRIO. */
 #else
 	uint64_t ror                          : 1;
 	uint64_t esr                          : 2;
@@ -9631,20 +9614,19 @@ union cvmx_sli_pktx_output_control {
 	uint64_t reserved_14_63               : 50;
 	uint64_t tenb                         : 1;  /**< SLI_MAC()_PF()_INT_SUM[PTIME] interrupt enable for this ring i. When [TENB] is set
                                                          and (SLI_PKT(i)_CNTS[TIMER] > SLI_PKT(i)_INT_LEVELS[TIME]),
-                                                         SLI_MAC()_PF()_INT_SUM[PTIME]
-                                                         will be set, and SLI_MAC()_PF()_INT_SUM interrupts can occur if
-                                                         SLI_MAC()_PF()_INT_SUM[PTIME] is enabled to generate interrupts.
-                                                         When [TENB] is clear, SLI_MAC()_PF()_INT_SUM[PTIME] will never assert due to ring
-                                                         i.
+                                                         SLI_MAC()_PF()_INT_SUM[PTIME] will be set, and SLI_MAC()_PF()_INT_SUM interrupts
+                                                         can occur if corresponding SLI_MAC()_PF()_INT_SUM[PTIME] is set.
+                                                         When [TENB] is clear, SLI_MAC()_PF()_INT_SUM[PTIME] will never assert due to
+                                                         ring i.
                                                          [TENB] is RO when accessed via BAR0 of a virtual function, and R/W otherwise.
                                                          [TENB] has no effect on SLI_PKT_TIME_INT or SLI_PKT_INT, and
                                                          has no effect on any non-SLI_MAC()_PF()_INT_SUM interrupt. */
 	uint64_t cenb                         : 1;  /**< SLI_MAC()_PF()_INT_SUM[PCNT] interrupt enable for this ring i. When [CENB] is set
                                                          and (SLI_PKT(i)_CNTS[TIMER] > SLI_PKT(i)_INT_LEVELS[TIME]),
-                                                         SLI_MAC()_PF()_INT_SUM[PCNT]
-                                                         will be set, and SLI_INT_SUM interrupts can occur if SLI_MAC()_PF()_INT_SUM[PCNT]
-                                                         is enabled to generate interrupts.
-                                                         When [CENB] is clear, SLI_INT_SUM[PCNT] will never assert due to ring i.
+                                                         SLI_MAC()_PF()_INT_SUM[PCNT] will be set, and SLI_INT_SUM interrupts
+                                                         can occur if corresponding SLI_MAC()_PF()_INT_SUM[PCNT] is set.
+                                                         When [CENB] is clear, SLI_MAC()_PF()_INT_SUM[PCNT] will never assert due to
+                                                         ring i.
                                                          [CENB] is RO when accessed via BAR0 of a virtual function, and R/W otherwise.
                                                          [CENB] has no effect on SLI_PKT_CNT_INT or SLI_PKT_INT, and
                                                          has no effect on any non-SLI_MAC()_PF()_INT_SUM interrupt. */
@@ -10507,7 +10489,7 @@ union cvmx_sli_pkt_in_jabber {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
 	uint64_t size                         : 32; /**< Byte count for limiting sizes of packet sizes that are allowed for sli packet inbound
-                                                         packets. */
+                                                         packets.  This byte limit does not include FSZ bytes of a packet. */
 #else
 	uint64_t size                         : 32;
 	uint64_t reserved_32_63               : 32;
diff --git a/arch/mips/include/asm/octeon/cvmx-spemx-defs.h b/arch/mips/include/asm/octeon/cvmx-spemx-defs.h
index 7320dcf..49dc0ae 100644
--- a/arch/mips/include/asm/octeon/cvmx-spemx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-spemx-defs.h
@@ -814,8 +814,11 @@ union cvmx_spemx_ctl_status {
 	uint64_t cfg_rtry                     : 16; /**< The time * 0x10000 in coprocessor clocks to wait for a CPL to a configuration read that
                                                          does not carry a retry status. Until such time that the timeout occurs and retry status is
                                                          received for a configuration read, the read will be resent. A value of 0 disables retries
-                                                         and treats a CPL Retry as a CPL UR. When enabled, only one CFG RD may be issued until
-                                                         either successful completion or CPL UR. */
+                                                         and treats a CPL Retry as a CPL UR.
+                                                         To use, it is recommended CFG_RTRY be set value corresponding to 200ms or less, although
+                                                         the PCI Express Base Specification allows up to 900ms for a device to send a successful
+                                                         completion.  When enabled, only one CFG RD may be issued until either successful
+                                                         completion or CPL UR. */
 	uint64_t reserved_14_15               : 2;
 	uint64_t pm_pf_xpme                   : 2;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_pme port.
                                                          EP mode.
@@ -2012,15 +2015,16 @@ union cvmx_spemx_strap {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
 	uint64_t miopem2dlm5sel               : 1;  /**< The value of the BOOT_AD[13] pin via MIO, which is captured on chip cold reset. It is not
-                                                         affected by any other reset.  Only used for PEM2.  When set, PEM2 is configured to
-                                                         DLM5 and PEM()_QLM[PEMDLMSEL] will be set, the Mac will be confifgured for 2 lanes.
+                                                         affected by any other reset.  Only used for PEM2 and PEM3.  When set, PEM2/PEM3 are
+                                                         configured to
+                                                         DLM5/DLM6 and PEM()_QLM[PEMDLMSEL] will be set, the Mac will be confifgured for 2 lanes.
                                                          When clear, PEM2 is configured to QLM2. */
 	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin, which is captured on chip cold reset. It is not
                                                          affected by any other reset.  When set, lane swapping is performed to/from the
                                                          SerDes. When clear, no lane swapping is performed. */
 	uint64_t pilanes8                     : 1;  /**< The value of the pi_select_8lanes pin, which is captured on chip cold reset. It is not
-                                                         affected by any other reset.  When set, the PEM is configured for a maximum of
-                                                         8-lanes, When clear, the PEM is configured for a maximum of 4-lanes. */
+                                                         affected by any other reset.  When set, the PEM0/PEM2 are configured for a maximum of
+                                                         8-lanes, When clear, the PEM0/PEM2 are configured for a maximum of 4-lanes. */
 	uint64_t pimode                       : 2;  /**< The value of the pi_select_mode[1:0] pins, which are captured on chip cold reset. They are
                                                          not affected by any other reset.
                                                          0x0 = EP mode, Gen1 speed.
diff --git a/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h b/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
index c07def3..97731cd 100644
--- a/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
@@ -5542,22 +5542,25 @@ typedef union cvmx_sriomaintx_port_rt_ctl cvmx_sriomaintx_port_rt_ctl_t;
 /**
  * cvmx_sriomaint#_port_ttl_ctl
  *
- * This register controls the timeout for outgoing packets. It is used to make sure
- * packets are being transmitted and acknowledged within a reasonable period of
- * time. The timeout value corresponds to TIMEOUT x 200ns and a value of 0 disables the
- * timer. The actualy value of the should be greater than the physical layer timout
- * specified in SRIOMAINT()_PORT_LT_CTL and is typically a less SRIOMAINT()_PORT_LT_CTL
- * timeout than the response timeout specified in SRIOMAINT()_PORT_RT_CTL. A second
- * application of this timer is to remove all the packets waiting to be transmitted
- * including those already in flight. This may necessary in the case of a link going
- * down (see SRIO()_INT_REG[LINK_DWN]). This can accomplished by setting the TIMEOUT to
- * small value all so that all TX packets can be dropped. In either case, when the
- * timeout expires the TTL interrupt is asserted, any packets currently being
- * transmitted are dropped, the SRIOMAINT()_TX_DROP[DROP] bit is set (causing any
- * scheduled packets to be dropped), the SRIOMAINT()_TX_DROP[DROP_CNT] is incremented
- * for each packet and the SRIO output state is set to IDLE (all errors are
- * cleared). Software must clear the SRIOMAINT()_TX_DROP[DROP] bit to resume
- * transmitting packets.
+ * This register controls the timeout for outgoing packets. It is primilarly
+ * used to make sure packets are being transmitted and acknowledged within a
+ * reasonable period of time. The timeout value corresponds to TIMEOUT x 200ns
+ * and a value of 0 disables the timer. The actual value should be greater
+ * than the physical layer timeout specified in SRIOMAINT()_PORT_LT_CTL and
+ * is typically a less than the response timeout specified in
+ * SRIOMAINT()_PORT_RT_CTL.
+ * A second application of this timer is to remove all the packets waiting
+ * to be transmitted including those already in flight. This may by necessary
+ * for the case of a link going down (see SRIO()_INT_REG[LINK_DWN]).  Packet
+ * removal can accomplished by setting the TIMEOUT value to small number so
+ * that all TX packets can be dropped.
+ *
+ * In both cases, when the timeout expires the TTL interrupt is asserted, any
+ * packets currently being transmitted are dropped, the SRIOMAINT()_TX_DROP[DROP]
+ * bit is set (causing any scheduled packets to be dropped), the
+ * SRIOMAINT()_TX_DROP[DROP_CNT] is incremented for each packet and the SRIO
+ * output state is set to IDLE (all errors are cleared). Software must clear
+ * the SRIOMAINT()_TX_DROP[DROP] bit to resume transmitting packets.
  */
 union cvmx_sriomaintx_port_ttl_ctl {
 	uint32_t u32;
diff --git a/arch/mips/include/asm/octeon/cvmx-sriox-defs.h b/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
index 8a2c1e5..e0a7d65 100644
--- a/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
@@ -1328,8 +1328,8 @@ union cvmx_sriox_ecc_ctrl {
                                                           - 25:24 = fc.core.roc.srio.sli.ofifo.sh_bulk.m2.
                                                           - 23:22 = fc.core.roc.srio.sli.ofifo.sh_bulk.m1.
                                                           - 21:20 = fc.core.roc.srio.sli.ofifo.sh_bulk.m0.
-                                                          - 19:18 = fc.core.roc.srio.sli.oarb.cmd_fifo.m1.
-                                                          - 17:16 = fc.core.roc.srio.sli.oarb.cmd_fifo.m0.
+                                                          - 19:18 = Reserved.
+                                                          - 17:16 = Reserved.
                                                           - 15:14 = fc.core.roc.srio.omsg.sil.mem.
                                                           - 13:12 = fc.core.roc.srio.omsg.fif1.mem2.
                                                           - 11:10 = fc.core.roc.srio.omsg.fif1.mem0_l.
@@ -1373,8 +1373,8 @@ union cvmx_sriox_ecc_status {
                                                          44 = fc.core.roc.srio.sli.ofifo.sh_bulk.m2.
                                                          43 = fc.core.roc.srio.sli.ofifo.sh_bulk.m1.
                                                          42 = fc.core.roc.srio.sli.ofifo.sh_bulk.m0.
-                                                         41 = fc.core.roc.srio.sli.oarb.cmd_fifo.m1.
-                                                         40 = fc.core.roc.srio.sli.oarb.cmd_fifo.m0.
+                                                         41 = Reserved.
+                                                         40 = Reserved.
                                                          39 = fc.core.roc.srio.omsg.sil.mem.
                                                          38 = fc.core.roc.srio.omsg.fif1.mem2.
                                                          37 = fc.core.roc.srio.omsg.fif1.mem0_l.
@@ -1398,8 +1398,8 @@ union cvmx_sriox_ecc_status {
                                                          12 = fc.core.roc.srio.sli.ofifo.sh_bulk.m2.
                                                          11 = fc.core.roc.srio.sli.ofifo.sh_bulk.m1.
                                                          10 = fc.core.roc.srio.sli.ofifo.sh_bulk.m0.
-                                                         9 = fc.core.roc.srio.sli.oarb.cmd_fifo.m1.
-                                                         8 = fc.core.roc.srio.sli.oarb.cmd_fifo.m0.
+                                                         9 = Reserved.
+                                                         8 = Reserved.
                                                          7 = fc.core.roc.srio.omsg.sil.mem.
                                                          6 = fc.core.roc.srio.omsg.fif1.mem2.
                                                          5 = fc.core.roc.srio.omsg.fif1.mem0_l.
@@ -1804,12 +1804,13 @@ union cvmx_sriox_imsg_vport_thr {
                                                          Default is 8 (to 51) for SRIO0 and 52 (to 95) for SRIO1. */
 	uint64_t reserved_54_55               : 2;
 	uint64_t max_tot                      : 6;  /**< Sets max number of vports available to this SRIO MAC.  Maximum value supported by
-                                                         hardware is 47.  The total number of vports available to SRIO MACs by the 75xx is 94
-                                                         but depends on configuration.  Default is 44 vports each. */
+                                                         hardware is 47 with SP_VPORT set or 46 with SP_VPORT clear.  The total number of
+                                                         vports available to SRIO MACs by the 75xx is 94 but the number available to SRIO
+                                                         depends on the configuration of other blocks.  Default is 44 vports each. */
 	uint64_t reserved_46_47               : 2;
-	uint64_t max_s1                       : 6;  /**< Reserved. */
+	uint64_t max_s1                       : 6;  /**< Diagnostic Use only.  Must be written to 0x30 for normal operation. */
 	uint64_t reserved_38_39               : 2;
-	uint64_t max_s0                       : 6;  /**< Reserved. */
+	uint64_t max_s0                       : 6;  /**< Diagnostic Use only.  Must be written to 0x30 for normal operation. */
 	uint64_t sp_vport                     : 1;  /**< Single-segment vport pre-allocation.
                                                          When set, single-segment messages use pre-allocated
                                                          vport slots and a single port is removed from the
@@ -4107,210 +4108,9 @@ union cvmx_sriox_s2m_typex {
 	struct cvmx_sriox_s2m_typex_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_19_63               : 45;
-	uint64_t wr_op                        : 3;  /**< sRIO operation for SLI/DPI writes.
-                                                         SLI/DPI hardware break MAC memory space writes
-                                                         that they generate into pieces of maximum size
-                                                         256B. For NWRITE/NWRITE_R/SWRITE WR_OP variants
-                                                         below, SRIO will, if necessary to obey sRIO
-                                                         requirements, automatically break the write into
-                                                         even smaller writes. The same is not true for
-                                                         MAINTENANCE writes and port-writes. Additional
-                                                         SW/usage restrictions are required for these
-                                                         MAINTENANCE WR_OP's to work correctly. SW must
-                                                         restrict the alignment and length of DPI pointers,
-                                                         limit the store sizes that the cores issue, and
-                                                         possibly also set SLI_MEM_ACCESS_SUBID()[NMERGE]
-                                                         so that all MAC memory space writes with
-                                                         MAINTENANCE write and port-write WR_OP's can be
-                                                         serviced in a single sRIO operation.
-                                                         SRIO always sends the write data (64-bit) words
-                                                         out in order.
-                                                         WR_OP = 0 = Normal Write (NWRITE)
-                                                         SRIO breaks a MAC memory space write into
-                                                         the minimum number of required sRIO NWRITE
-                                                         operations. This will be 1-5 total NWRITEs,
-                                                         depending on endian-swap, alignment, and
-                                                         length.
-                                                         WR_OP = 1 = Normal Write w/Response (NWRITE_R)
-                                                         SRIO breaks a MAC memory space write into
-                                                         the minimum number of required sRIO
-                                                         NWRITE_R operations. This will be 1-5 total
-                                                         NWRITE_R's, depending on endian-swap,
-                                                         alignment, and length.
-                                                         SRIO sets SRIO()_INT_REG[WR_DONE] after it
-                                                         receives the DONE response for the last
-                                                         NWRITE_R sent.
-                                                         WR_OP = 2 = NWRITE, Streaming write (SWRITE),
-                                                         NWRITE
-                                                         SRIO attempts to turn the MAC memory space
-                                                         write into an SWRITE operation. There will
-                                                         be 1-5 total sRIO operations (0-2 NWRITE's
-                                                         followed by 0-1 SWRITE's followed by 0-2
-                                                         NWRITE's) generated to complete the MAC
-                                                         memory space write, depending on
-                                                         endian-swap, alignment, and length.
-                                                         If the starting address is not 64-bit
-                                                         aligned, SRIO first creates 1-4 NWRITE's to
-                                                         either align it or complete the write. Then
-                                                         SRIO creates a SWRITE including all aligned
-                                                         64-bit words. (SRIO won't create an SWRITE
-                                                         when there are none.) If store data
-                                                         remains, SRIO finally creates another 1 or
-                                                         2 NWRITE's.
-                                                         WR_OP = 3 = NWRITE, SWRITE, NWRITE_R
-                                                         SRIO attempts to turn the MAC memory space
-                                                         write into an SWRITE operation followed by
-                                                         a NWRITE_R operation. The last operation
-                                                         is always NWRITE_R. There will be 1-5
-                                                         total sRIO operations (0-2 NWRITE's,
-                                                         followed by 0-1 SWRITE, followed by 1-4
-                                                         NWRITE_R's) generated to service the MAC
-                                                         memory space write, depending on
-                                                         endian-swap, alignment, and length.
-                                                         If the write is contained in one aligned
-                                                         64-bit word, SRIO will completely service
-                                                         the MAC memory space write with 1-4
-                                                         NWRITE_R's.
-                                                         Otherwise, if the write spans multiple
-                                                         words, SRIO services the write as follows.
-                                                         First, if the start of the write is not
-                                                         word-aligned, SRIO creates 1 or 2 NWRITE's
-                                                         to align it. Then SRIO creates an SWRITE
-                                                         that includes all aligned 64-bit words,
-                                                         leaving data for the final NWRITE_R(s).
-                                                         (SRIO won't create the SWRITE when there is
-                                                         no data for it.) Then SRIO finally creates
-                                                         1 or 2 NWRITE_R's.
-                                                         In any case, SRIO sets
-                                                         SRIO()_INT_REG[WR_DONE] after it receives
-                                                         the DONE response for the last NWRITE_R
-                                                         sent.
-                                                         WR_OP = 4 = NWRITE, NWRITE_R
-                                                         SRIO attempts to turn the MAC memory space
-                                                         write into an NWRITE operation followed by
-                                                         a NWRITE_R operation. The last operation
-                                                         is always NWRITE_R. There will be 1-5
-                                                         total sRIO operations (0-3 NWRITE's
-                                                         followed by 1-4 NWRITE_R's) generated to
-                                                         service the MAC memory space write,
-                                                         depending on endian-swap, alignment, and
-                                                         length.
-                                                         If the write is contained in one aligned
-                                                         64-bit word, SRIO will completely service
-                                                         the MAC memory space write with 1-4
-                                                         NWRITE_R's.
-                                                         Otherwise, if the write spans multiple
-                                                         words, SRIO services the write as follows.
-                                                         First, if the start of the write is not
-                                                         word-aligned, SRIO creates 1 or 2 NWRITE's
-                                                         to align it. Then SRIO creates an NWRITE
-                                                         that includes all aligned 64-bit words,
-                                                         leaving data for the final NWRITE_R(s).
-                                                         (SRIO won't create this NWRITE when there
-                                                         is no data for it.) Then SRIO finally
-                                                         creates 1 or 2 NWRITE_R's.
-                                                         In any case, SRIO sets
-                                                         SRIO()_INT_REG[WR_DONE] after it receives
-                                                         the DONE response for the last NWRITE_R
-                                                         sent.
-                                                         WR_OP = 5 = Reserved
-                                                         WR_OP = 6 = Maintenance Write
-                                                         - SRIO will create one sRIO MAINTENANCE write
-                                                         operation to service the MAC memory space
-                                                         write
-                                                         - IAOW_SEL must be zero. (see description
-                                                         below.)
-                                                         - MDS must be zero. (MDS is MACADD[63:62] -
-                                                         see IAOW_SEL description below.)
-                                                         - Hop Cnt is MACADD[31:24]/SRIOAddress[31:24]
-                                                         - MACADD[23:0]/SRIOAddress[23:0] selects
-                                                         maintenance register (i.e. config_offset)
-                                                         - sRIODestID[15:0] is MACADD[49:34].
-                                                         (MACADD[49:42] unused when ID16=0)
-                                                         - Write size/alignment must obey sRIO rules
-                                                         (4, 8, 16, 24, 32, 40, 48, 56 and 64 byte
-                                                         lengths allowed)
-                                                         WR_OP = 7 = Maintenance Port Write
-                                                         - SRIO will create one sRIO MAINTENANCE port
-                                                         write operation to service the MAC memory
-                                                         space write
-                                                         - IAOW_SEL must be zero. (see description
-                                                         below.)
-                                                         - MDS must be zero. (MDS is MACADD[63:62] -
-                                                         see IAOW_SEL description below.)
-                                                         - Hop Cnt is MACADD[31:24]/sRIOAddress[31:24]
-                                                         - MACADD[23:0]/sRIOAddress[23:0] MBZ
-                                                         (config_offset field reserved by sRIO)
-                                                         - sRIODestID[15:0] is MACADD[49:34].
-                                                         (MACADD[49:42] unused when ID16=0)
-                                                         - Write size/alignment must obey sRIO rules
-                                                         (4, 8, 16, 24, 32, 40, 48, 56 and 64 byte
-                                                         lengths allowed) */
+	uint64_t wr_op                        : 3;  /**< Write Operation.  See SRIO_WR_OP_E for details. */
 	uint64_t reserved_15_15               : 1;
-	uint64_t rd_op                        : 3;  /**< sRIO operation for SLI/DPI reads
-                                                         SLI/DPI hardware and sRIO configuration
-                                                         restrictions guarantee that SRIO can service any
-                                                         MAC memory space read that it receives from SLI/DPI
-                                                         with a single NREAD, assuming that RD_OP selects
-                                                         NREAD. DPI will break a read into multiple MAC
-                                                         memory space reads to ensure this holds. The same
-                                                         is not true for the ATOMIC and MAINTENANCE RD_OP
-                                                         values. Additional SW/usage restrictions are
-                                                         required for ATOMIC and MAINTENANCE RD_OP to work
-                                                         correctly. SW must restrict the alignment and
-                                                         length of DPI pointers and limit the load sizes
-                                                         that the cores issue such that all MAC memory space
-                                                         reads with ATOMIC and MAINTENANCE RD_OP's can be
-                                                         serviced in a single sRIO operation.
-                                                         RD_OP = 0 = Normal Read (NREAD)
-                                                         - SRIO will create one sRIO NREAD
-                                                         operation to service the MAC memory
-                                                         space read
-                                                         - Read size/alignment must obey sRIO rules
-                                                         (up to 256 byte lengths). (This requirement
-                                                         is guaranteed by SLI/DPI usage restrictions
-                                                         and configuration.)
-                                                         RD_OP = 1 = Reserved
-                                                         RD_OP = 2 = Atomic Set
-                                                         - SRIO will create one sRIO ATOMIC set
-                                                         operation to service the MAC memory
-                                                         space read
-                                                         - Read size/alignment must obey sRIO rules
-                                                         (1, 2, and 4 byte lengths allowed)
-                                                         RD_OP = 3 = Atomic Clear
-                                                         - SRIO will create one sRIO ATOMIC clr
-                                                         operation to service the MAC memory
-                                                         space read
-                                                         - Read size/alignment must obey sRIO rules
-                                                         (1, 2, and 4 byte lengths allowed)
-                                                         RD_OP = 4 = Atomic Increment
-                                                         - SRIO will create one sRIO ATOMIC inc
-                                                         operation to service the MAC memory
-                                                         space read
-                                                         - Read size/alignment must obey sRIO rules
-                                                         (1, 2, and 4 byte lengths allowed)
-                                                         RD_OP = 5 = Atomic Decrement
-                                                         - SRIO will create one sRIO ATOMIC dec
-                                                         operation to service the MAC memory
-                                                         space read
-                                                         - Read size/alignment must obey sRIO rules
-                                                         (1, 2, and 4 byte lengths allowed)
-                                                         RD_OP = 6 = Maintenance Read
-                                                         - SRIO will create one sRIO MAINTENANCE read
-                                                         operation to service the MAC memory
-                                                         space read
-                                                         - IAOW_SEL must be zero. (see description
-                                                         below.)
-                                                         - MDS must be zero. (MDS is MACADD[63:62] -
-                                                         see IAOW_SEL description below.)
-                                                         - Hop Cnt is MACADD[31:24]/sRIOAddress[31:24]
-                                                         - MACADD[23:0]/sRIOAddress[23:0] selects
-                                                         maintenance register (i.e. config_offset)
-                                                         - sRIODestID[15:0] is MACADD[49:34].
-                                                         (MACADD[49:42] unused when ID16=0)
-                                                         - Read size/alignment must obey sRIO rules
-                                                         (4, 8, 16, 32 and 64 byte lengths allowed)
-                                                         RD_OP = 7 = Reserved */
+	uint64_t rd_op                        : 3;  /**< Read Operation.  see SRIO_RD_OP_E for details. */
 	uint64_t wr_prior                     : 2;  /**< Transaction priority 0-3 used for writes. */
 	uint64_t rd_prior                     : 2;  /**< Transaction priority 0-3 used for reads/ATOMICs */
 	uint64_t reserved_6_7                 : 2;
@@ -4324,104 +4124,7 @@ union cvmx_sriox_s2m_typex {
 	uint64_t id16                         : 1;  /**< SRIO TT ID 0=8bit, 1=16-bit.
                                                          IAOW_SEL must not be 2 when ID16=1. */
 	uint64_t reserved_2_3                 : 2;
-	uint64_t iaow_sel                     : 2;  /**< Internal address offset width select.
-                                                         IAOW_SEL determines how to convert the
-                                                         MACADD[63:62,58:51,49:0] recieved from SLI/DPI with
-                                                         read/write into an sRIO address (sRIOAddress[...])
-                                                         and sRIO destination ID (sRIODestID[...]). The sRIO
-                                                         address width mode (SRIOMAINT_PE_LLC[EX_ADDR]) and
-                                                         ID16, determine the  width of the sRIO address and
-                                                         ID in the outgoing request(s), respectively.
-                                                         MACADD[61:60] is always unused.
-                                                         MACADD[59] is always TYPEIDX[3]
-                                                         MACADD[50] is always TYPEIDX[2]
-                                                         (TYPEIDX[3:0] selects one of these
-                                                         SRIO()_S2M_TYPE* table entries.)
-                                                         MACADD[17:0] always becomes sRIOAddress[17:0].
-                                                         IAOW_SEL = 0 = 34-bit Address Offset
-                                                         Must be used when sRIO link is in 34-bit
-                                                         address width mode.
-                                                         When sRIO is in 50-bit address width mode,
-                                                         sRIOAddress[49:34]=0 in the outgoing request.
-                                                         When sRIO is in 66-bit address width mode,
-                                                         sRIOAddress[65:34]=0 in the outgoing request.
-                                                         Usage of the SLI/DPI MAC address when
-                                                         IAOW_SEL = 0:
-                                                         MACADD[63:62] = Multi-Device Swap (MDS)
-                                                         MDS value affects MACADD[49:18] usage
-                                                         MACADD[58:51] => unused
-                                                         MACADD[49:18] usage depends on MDS value
-                                                         MDS = 0
-                                                         MACADD[49:34] => sRIODestID[15:0]
-                                                         (MACADD[49:42] unused when ID16=0)
-                                                         MACADD[33:18] => sRIOAddress[33:18]
-                                                         MDS = 1
-                                                         MACADD[49:42] => sRIODestID[15:8]
-                                                         (MACADD[49:42] unused when ID16 = 0)
-                                                         MACADD[41:34] => sRIOAddress[33:26]
-                                                         MACADD[33:26] => sRIODestID[7:0]
-                                                         MACADD[25:18] => sRIOAddress[25:18]
-                                                         MDS = 2
-                                                         ID16 must be one.
-                                                         MACADD[49:34] => sRIOAddress[33:18]
-                                                         MACADD[33:18] => sRIODestID[15:0]
-                                                         MDS = 3 = Reserved
-                                                         IAOW_SEL = 1 = 42-bit Address Offset
-                                                         Must not be used when sRIO link is in 34-bit
-                                                         address width mode.
-                                                         When sRIO is in 50-bit address width mode,
-                                                         sRIOAddress[49:42]=0 in the outgoing request.
-                                                         When sRIO is in 66-bit address width mode,
-                                                         sRIOAddress[65:42]=0 in the outgoing request.
-                                                         Usage of the SLI/DPI MAC address when
-                                                         IAOW_SEL = 1:
-                                                         MACADD[63:62] => Multi-Device Swap (MDS)
-                                                         MDS value affects MACADD[58:51,49:42,33:18]
-                                                         use
-                                                         MACADD[41:34] => sRIOAddress[41:34]
-                                                         MACADD[58:51,49:42,33:18] usage depends on
-                                                         MDS value:
-                                                         MDS = 0
-                                                         MACADD[58:51] => sRIODestID[15:8]
-                                                         MACADD[49:42] => sRIODestID[7:0]
-                                                         (MACADD[58:51] unused when ID16=0)
-                                                         MACADD[33:18] => sRIOAddress[33:18]
-                                                         MDS = 1
-                                                         MACADD[58:51] => sRIODestID[15:8]
-                                                         (MACADD[58:51] unused when ID16 = 0)
-                                                         MACADD[49:42] => sRIOAddress[33:26]
-                                                         MACADD[33:26] => sRIODestID[7:0]
-                                                         MACADD[25:18] => sRIOAddress[25:18]
-                                                         MDS = 2
-                                                         ID16 must be one.
-                                                         MACADD[58:51] => sRIOAddress[33:26]
-                                                         MACADD[49:42] => sRIOAddress[25:18]
-                                                         MACADD[33:18] => sRIODestID[15:0]
-                                                         MDS = 3 = Reserved
-                                                         IAOW_SEL = 2 = 50-bit Address Offset
-                                                         Must not be used when sRIO link is in 34-bit
-                                                         address width mode.
-                                                         Must not be used when ID16=1.
-                                                         When sRIO is in 66-bit address width mode,
-                                                         sRIOAddress[65:50]=0 in the outgoing request.
-                                                         Usage of the SLI/DPI MAC address when
-                                                         IAOW_SEL = 2:
-                                                         MACADD[63:62] => Multi-Device Swap (MDS)
-                                                         MDS value affects MACADD[58:51,33:26] use
-                                                         MDS value 3 is reserved
-                                                         MACADD[49:34] => sRIOAddress[49:34]
-                                                         MACADD[25:18] => sRIOAddress[25:18]
-                                                         MACADD[58:51,33:26] usage depends on
-                                                         MDS value:
-                                                         MDS = 0
-                                                         MACADD[58:51] => sRIODestID[7:0]
-                                                         MACADD[33:26] => sRIOAddress[33:26]
-                                                         MDS = 1
-                                                         MACADD[58:51] => sRIOAddress[33:26]
-                                                         MACADD[33:26] => sRIODestID[7:0]
-                                                         MDS = 2 = Reserved
-                                                         MDS = 3 = Reserved
-                                                         IAOW_SEL = 3 = Reserved */
+	uint64_t iaow_sel                     : 2;  /**< Internal address offset width select.  See SRIO_IAOW_E for details. */
 #else
 	uint64_t iaow_sel                     : 2;
 	uint64_t reserved_2_3                 : 2;
diff --git a/arch/mips/include/asm/octeon/cvmx-uahcx-defs.h b/arch/mips/include/asm/octeon/cvmx-uahcx-defs.h
index bb6b566..a5b70a9 100644
--- a/arch/mips/include/asm/octeon/cvmx-uahcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-uahcx-defs.h
@@ -4534,12 +4534,12 @@ union cvmx_uahcx_gusb2phycfgx {
                                                          times. The application must program this field based on the speed of connection.
                                                          The number of bit times added per PHY clock are:
                                                          * High-speed operation:
-                                                         - one 30-MHz PHY clock = 16 bit times.
-                                                         - one 60-MHz PHY clock = 8 bit times.
+                                                         _ one 30-MHz PHY clock = 16 bit times.
+                                                         _ one 60-MHz PHY clock = 8 bit times.
                                                          * Full-speed operation:
-                                                         - one 30-MHz PHY clock = 0.4 bit times.
-                                                         - one 60-MHz PHY clock = 0.2 bit times.
-                                                         - one 48-MHz PHY clock = 0.25 bit times. */
+                                                         _ one 30-MHz PHY clock = 0.4 bit times.
+                                                         _ one 60-MHz PHY clock = 0.2 bit times.
+                                                         _ one 48-MHz PHY clock = 0.25 bit times. */
 #else
 	uint32_t toutcal                      : 3;
 	uint32_t phyif                        : 1;
diff --git a/arch/mips/include/asm/octeon/cvmx-xcv-defs.h b/arch/mips/include/asm/octeon/cvmx-xcv-defs.h
index 1bf9b5a..aff8b60 100644
--- a/arch/mips/include/asm/octeon/cvmx-xcv-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-xcv-defs.h
@@ -294,7 +294,8 @@ union cvmx_xcv_dll_ctl {
 	uint64_t u64;
 	struct cvmx_xcv_dll_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_31_63               : 33;
+	uint64_t reserved_32_63               : 32;
+	uint64_t lock                         : 1;  /**< Reserved. */
 	uint64_t clk_set                      : 7;  /**< The clock delay as determined by the on board HW DLL. */
 	uint64_t clkrx_byp                    : 1;  /**< Bypass the RX clock delay setting.
                                                          Skews RXC from RXD, RXCTL.
@@ -329,7 +330,8 @@ union cvmx_xcv_dll_ctl {
 	uint64_t clkrx_set                    : 7;
 	uint64_t clkrx_byp                    : 1;
 	uint64_t clk_set                      : 7;
-	uint64_t reserved_31_63               : 33;
+	uint64_t lock                         : 1;
+	uint64_t reserved_32_63               : 32;
 #endif
 	} s;
 	struct cvmx_xcv_dll_ctl_s             cn73xx;
-- 
2.6.2

