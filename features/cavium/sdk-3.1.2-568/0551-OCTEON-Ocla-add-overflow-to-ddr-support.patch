From f073d8f172dc1bf02b6ff8dfc6c371bcb1a75a19 Mon Sep 17 00:00:00 2001
From: Carlos Munoz <cmunoz@caviumnetworks.com>
Date: Sat, 22 Feb 2014 13:46:59 -0800
Subject: [PATCH 551/974] OCTEON: Ocla: add overflow to ddr support.

Signed-off-by: Carlos Munoz <cmunoz@caviumnetworks.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/cavium-octeon/executive/cvmx-ocla.c |  75 ++--
 arch/mips/include/asm/octeon/cvmx-ocla.h      |  24 +-
 drivers/char/octeon-ocla.c                    | 494 +++++++++++++++++++++++---
 3 files changed, 507 insertions(+), 86 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-ocla.c b/arch/mips/cavium-octeon/executive/cvmx-ocla.c
index 21f71ca..c909a30 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ocla.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ocla.c
@@ -342,6 +342,7 @@ int cvmx_ocla_reset(int	node,
 	state_int.u64 = 0;
 	state_int.s.fsm0_int = 1;
 	state_int.s.fsm1_int = 1;
+	state_int.s.trigfull = 1;
 	cvmx_write_csr_node(node, CVMX_OCLAX_STATE_INT(ix), state_int.u64);
 
 	/* Enable ocla */
@@ -375,6 +376,7 @@ int cvmx_ocla_clear_interrupts(int	node,
 	state_int.u64 = 0;
 	state_int.s.fsm0_int = 1;
 	state_int.s.fsm1_int = 1;
+	state_int.s.trigfull = 1;
 	cvmx_write_csr_node(node, CVMX_OCLAX_STATE_INT(ix), state_int.u64);
 
 	return 0;
@@ -413,6 +415,8 @@ EXPORT_SYMBOL(cvmx_ocla_disable);
  *
  * @param node		Node ocla complex is on.
  * @param ix		OCLA complex to initialize.
+ * @param buf		Pointer to ddr buffer to use as capture buffer.
+ * @param buf_size	Size of ddr capture buffer.
  * @param num_entries	Number of entries to capture. Zero for wrapping mode.
  * @param lo_cap	Selects when to capture the lower 36-bit debug bus half.
  * @param hi_cap	Selects when to capture the upper 36-bit debug bus half.
@@ -421,12 +425,13 @@ EXPORT_SYMBOL(cvmx_ocla_disable);
  */
 int cvmx_ocla_init(int			node,
 		   int			ix,
+		   uint64_t		buf,
+		   uint			buf_size,
 		   int			num_entries,
 		   cvmx_cap_sel_t	lo_cap,
 		   cvmx_cap_sel_t	hi_cap)
 {
 	cvmx_oclax_time_t		time;
-	cvmx_oclax_const_t		constant;
 	cvmx_oclax_fifo_trig_t		fifo_trig;
 	cvmx_oclax_cdhx_ctl_t		cdhx_ctl;
 
@@ -444,19 +449,36 @@ int cvmx_ocla_init(int			node,
 	time.s.cycle = 0;
 	cvmx_write_csr_node(node, CVMX_OCLAX_TIME(ix), time.u64);
 
-	/*
-	 * Set the number of entries to collect after trigger event to the size
-	 * of ram.
-	 */
-	fifo_trig.u64 = 0;
-	if (num_entries) {
-		int	max_entries;
+	/* Use the ddr buffer if present */
+	if (buf && buf_size) {
+		cvmx_oclax_stack_base_t	base;
+		cvmx_oclax_stack_top_t	top;
+		cvmx_oclax_stack_cur_t	cur;
+		cvmx_oclax_fifo_limit_t	limit;
+
+		base.u64 = 0;
+		base.s.ptr = buf >> 7;
+		cvmx_write_csr_node(node, CVMX_OCLAX_STACK_BASE(ix), base.u64);
+
+		top.u64 = 0;
+		top.s.ptr = (buf + buf_size + CVMX_CACHE_LINE_SIZE) >> 7;
+		cvmx_write_csr_node(node, CVMX_OCLAX_STACK_TOP(ix), top.u64);
+
+		cur.u64 = 0;
+		cur.s.ptr = buf >> 7;
+		cvmx_write_csr_node(node, CVMX_OCLAX_STACK_CUR(ix), cur.u64);
+
+		cvmx_write_csr_node(node, CVMX_OCLAX_STACK_WRAP(ix), 0);
+		cvmx_write_csr_node(node, CVMX_OCLAX_STACK_STORE_CNT(ix), 0);
 
-		constant.u64 = cvmx_read_csr_node(node, CVMX_OCLAX_CONST(ix));
-		max_entries = constant.s.dat_size - 5;
-		fifo_trig.s.limit = num_entries <= max_entries ? num_entries :
-			max_entries;
+		limit.u64 = cvmx_read_csr_node(node, CVMX_OCLAX_FIFO_LIMIT(ix));
+		limit.s.ddr = 0;
+		cvmx_write_csr_node(node, CVMX_OCLAX_FIFO_LIMIT(ix), limit.u64);
 	}
+
+	/* Stop capture after num_entries entries have been captured */
+	fifo_trig.u64 = 0;
+	fifo_trig.s.limit = num_entries;
 	cvmx_write_csr_node(node, CVMX_OCLAX_FIFO_TRIG(ix), fifo_trig.u64);
 
 	/* Configure when to capture for both the lower and upper 36 bits */
@@ -733,32 +755,3 @@ int cvmx_ocla_get_packet(int		node,
 	return rc;
 }
 EXPORT_SYMBOL(cvmx_ocla_get_packet);
-
-/**
- * Check if the ocla fifo is full.
- *
- * @param node		Node ocla complex is on.
- * @param ix		OCLA complex whose fifo is to be checked.
- * 
- * @return Returned value. Zero if fifo is not full, 1 if it's full.
- */
-int cvmx_is_fifo_full(int	node,
-		      int	ix)
-{
-	cvmx_oclax_fifo_trig_t	fifo_trig;
-	int			rc;
-
-	fifo_trig.u64 = cvmx_read_csr_node(node, CVMX_OCLAX_FIFO_TRIG(ix));
-
-	/*
-	 * When wrapping is enabled, the fifo never fills. Well.. it does fill
-	 * but capturing never stops and the fifo wraps forever.
-	 */
-	if (!fifo_trig.s.limit)
-		rc = 0;
-	else
-		rc = fifo_trig.s.cnt >= fifo_trig.s.limit;
-
-	return rc;
-}
-EXPORT_SYMBOL(cvmx_is_fifo_full);
diff --git a/arch/mips/include/asm/octeon/cvmx-ocla.h b/arch/mips/include/asm/octeon/cvmx-ocla.h
index b625d6f..a6af40a 100644
--- a/arch/mips/include/asm/octeon/cvmx-ocla.h
+++ b/arch/mips/include/asm/octeon/cvmx-ocla.h
@@ -248,8 +248,25 @@ struct cap_req {
 	uint			ix;
 };
 
+/**
+ * Capture ddr buffer request. The kernel must fulfill the request as a
+ * physical address is needed by ocla.
+ *
+ *  node:			Node to capture data on.
+ *  ix:				Ocla complex index.
+ *  size:			Size of ddr buffer.
+ *  pbuf:			Pointer to physicall address of ddr buffer.
+ */
+struct ddr_buf_req {
+	uint			node;
+	uint			ix;
+	uint			size;
+	uint64_t		pbuf;
+};
+
 /* Ioctl commands */
 #define OCLA_CAP_REQ		_IOW('o', 0x01, struct cap_req)
+#define OCLA_DDR_BUF_REQ	_IOWR('o', 0x02, struct ddr_buf_req)
 
 /**
  * Selects what causes data to be captured.
@@ -356,14 +373,17 @@ extern int cvmx_ocla_disable(int node, int ix);
  *
  * @param node		Node ocla complex is on.
  * @param ix		OCLA complex to initialize.
+ * @param buf		Pointer to ddr buffer to use as capture buffer.
+ * @param buf_size	Size of ddr capture buffer.
  * @param num_entries	Number of entries to capture. Zero for wrapping mode.
  * @param lo_cap	Selects when to capture the lower 36-bit debug bus half.
  * @param hi_cap	Selects when to capture the upper 36-bit debug bus half.
  * 
  * @return Returned value. Zero on success, -1 otherwise.
  */
-extern int cvmx_ocla_init(int node, int ix, int num_entries,
-			  cvmx_cap_sel_t lo_cap, cvmx_cap_sel_t hi_cap);
+extern int cvmx_ocla_init(int node, int ix, uint64_t buf, uint buf_size,
+			  int num_entries, cvmx_cap_sel_t lo_cap,
+			  cvmx_cap_sel_t hi_cap);
 
 /**
  * Initialize the OCLA matchers hardware.
diff --git a/drivers/char/octeon-ocla.c b/drivers/char/octeon-ocla.c
index 93a07c9..8234000 100644
--- a/drivers/char/octeon-ocla.c
+++ b/drivers/char/octeon-ocla.c
@@ -36,9 +36,11 @@
 #include <linux/of_irq.h>
 #include <linux/of_address.h>
 #include <linux/interrupt.h>
+#include <linux/slab.h>
 
 #include <asm/octeon/octeon.h>
 #include <asm/octeon/cvmx-ocla.h>
+#include <asm/octeon/cvmx-oclax-defs.h>
 
 MODULE_LICENSE("GPL");
 MODULE_AUTHOR("Carlos Munoz <cmunoz@caviumnetworks.com>");
@@ -50,7 +52,8 @@ MODULE_SUPPORTED_DEVICE("cn70xx/cn78xx");
 #define OCLA_MAJOR		0
 
 #define DEVICE_NAME		"octeon-ocla"
-#define MAX_OCLA_IRQS		2
+#define MAX_OCLA_IRQS		3
+#define MAX_CAP_BUF_SIZE	(1024 * 1024 * 100)
 
 
 /* Ocla comlex states */
@@ -83,8 +86,18 @@ struct irq_info {
  *  waitq:			Wait queue to support blocking io.
  *  pdev:			Pointer to platform device structure for this
  *				ocla complex.
- *  irqs:			IRQs used by this ocla complex.
  *  lock:			Spin lock.
+ *  irqs:			IRQs used by this ocla complex.
+ *  vbuf:			Virtual address of capture buffer.
+ *  pbuf:			Physical address of capture buffer (cache line
+ *				aligned)
+ *  rd_line:			Capture buffer address of next cache line to
+ *				read.
+ *  wr_line:			DDR capture buffer address of next cache line to
+ *				be written by ocla hardware.
+ *  line_cnt:			Number of capture buffer cache lines processed.
+ *  cur_entry:			Next entry within cache line to be processed.
+ *  buf_size:			Size of capture buffer.
  */
 struct ocla_complex {
 	int			node;
@@ -95,8 +108,84 @@ struct ocla_complex {
 	struct platform_device	*pdev;
 	spinlock_t		lock;
 	struct irq_info		irqs[MAX_OCLA_IRQS];
+	void			*vbuf;
+	uint64_t		pbuf;
+	void			*rd_line;
+	void			*wr_line;
+	int			line_cnt;
+	int			cur_entry;
+	uint			buf_size;
 };
 
+/*
+ * ddr_line:			Format of the cache line worth of entries.
+ *
+ *  timestamp:			Time at which the entry was written.
+ *  rsvd:			Not used.
+ *  entry0..25:			The 26 entries.
+ */
+struct ddr_line {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t		entry25:38;
+	uint64_t		entry24:38;
+	uint64_t		entry23:38;
+	uint64_t		entry22:38;
+	uint64_t		entry21:38;
+	uint64_t		entry20:38;
+	uint64_t		entry19:38;
+	uint64_t		entry18:38;
+	uint64_t		entry17:38;
+	uint64_t		entry16:38;
+	uint64_t		entry15:38;
+	uint64_t		entry14:38;
+	uint64_t		entry13:38;
+	uint64_t		entry12:38;
+	uint64_t		entry11:38;
+	uint64_t		entry10:38;
+	uint64_t		entry9:38;
+	uint64_t		entry8:38;
+	uint64_t		entry7:38;
+	uint64_t		entry6:38;
+	uint64_t		entry5:38;
+	uint64_t		entry4:38;
+	uint64_t		entry3:38;
+	uint64_t		entry2:38;
+	uint64_t		entry1:38;
+	uint64_t		entry0:38;
+	uint64_t		rsvd:4;
+	uint64_t		timestamp:32;
+#else
+	uint64_t		timestamp:32;
+	uint64_t		rsvd:4;
+	uint64_t		entry0:38;
+	uint64_t		entry1:38;
+	uint64_t		entry2:38;
+	uint64_t		entry3:38;
+	uint64_t		entry4:38;
+	uint64_t		entry5:38;
+	uint64_t		entry6:38;
+	uint64_t		entry7:38;
+	uint64_t		entry8:38;
+	uint64_t		entry9:38;
+	uint64_t		entry10:38;
+	uint64_t		entry11:38;
+	uint64_t		entry12:38;
+	uint64_t		entry13:38;
+	uint64_t		entry14:38;
+	uint64_t		entry15:38;
+	uint64_t		entry16:38;
+	uint64_t		entry17:38;
+	uint64_t		entry18:38;
+	uint64_t		entry19:38;
+	uint64_t		entry20:38;
+	uint64_t		entry21:38;
+	uint64_t		entry22:38;
+	uint64_t		entry23:38;
+	uint64_t		entry24:38;
+	uint64_t		entry25:38;
+#endif
+} __packed __aligned(128);
+
 
 static int ocla_major = OCLA_MAJOR;
 static DEFINE_SEMAPHORE(complexes_sem);
@@ -111,14 +200,9 @@ static struct ocla_complex ocla_complexes[CVMX_MAX_NODES][MAX_COMPLEXES] = {
 
 /*
  * Process ocla interrutps.
- * To mitigate interrupt overhead an approach similar to the one use by NAPI is
- * implemented:
- * 	. Readers enable the ocla interrupts and block waiting for captured
- *	  entries.
- *	. The interrupt handler is invoked when there's captured data. It
- *	  disables the interrupt and wakes up any blocked readers.
- *	. The readers read all entries. Enable the ocla interrupts and block
- *	  again.
+ * This handler is called either when the stop trigger occurs or when the
+ * capture buffer fills. It disables the interrupt and wakes up any blocked
+ * readers.
  *
  *  irq:			Interrupt to process.
  *  dev_id:			Pointer to ocla complex.
@@ -153,15 +237,258 @@ static irqreturn_t  ocla_irq_handler(int	irq,
 }
 
 /*
+ * Read an entry from the ddr buffer.
+ *
+ *  complex:			Ocla complex.
+ *  data:			Updated with entry read.
+ *
+ *  returns:			Entry.
+ */
+static uint64_t get_entry_from_line(struct ddr_line	*line,
+				    int			entry_ix)
+{
+	uint64_t	data;
+
+	switch (entry_ix) {
+	case 0:
+		data = line->entry0;
+		break;
+	case 1:
+		data = line->entry1;
+		break;
+	case 2:
+		data = line->entry2;
+		break;
+	case 3:
+		data = line->entry3;
+		break;
+	case 4:
+		data = line->entry4;
+		break;
+	case 5:
+		data = line->entry5;
+		break;
+	case 6:
+		data = line->entry6;
+		break;
+	case 7:
+		data = line->entry7;
+		break;
+	case 8:
+		data = line->entry8;
+		break;
+	case 9:
+		data = line->entry9;
+		break;
+	case 10:
+		data = line->entry10;
+		break;
+	case 11:
+		data = line->entry11;
+		break;
+	case 12:
+		data = line->entry12;
+		break;
+	case 13:
+		data = line->entry13;
+		break;
+	case 14:
+		data = line->entry14;
+		break;
+	case 15:
+		data = line->entry15;
+		break;
+	case 16:
+		data = line->entry16;
+		break;
+	case 17:
+		data = line->entry17;
+		break;
+	case 18:
+		data = line->entry18;
+		break;
+	case 19:
+		data = line->entry19;
+		break;
+	case 20:
+		data = line->entry20;
+		break;
+	case 21:
+		data = line->entry21;
+		break;
+	case 22:
+		data = line->entry22;
+		break;
+	case 23:
+		data = line->entry23;
+		break;
+	case 24:
+		data = line->entry24;
+		break;
+	case 25:
+		data = line->entry25;
+		break;
+	default:
+		data = -1;
+		break;
+	}
+
+	return data;
+}
+
+/*
+ * Swap a ddr line worth of entries to match the format expected by
+ * 'struct ddr_line'.
+ *
+ *  line:			Pointer to ddr line to swap.
+ *
+ *  returns:			Zero on success, error otherwise.
+ */
+static int swap_ddr_line(void	*line)
+{
+	uint64_t	*ptr;
+	uint64_t	tmp;
+	int		num_elem;
+	int		end_ix;
+	int		i;
+
+	num_elem = CVMX_CACHE_LINE_SIZE / sizeof(uint64_t);
+	end_ix = num_elem - 1;
+	ptr = (uint64_t *)line;
+
+	for (i = 0; i < num_elem / 2; i++, end_ix--) {
+		tmp = ptr[i];
+		ptr[i] = ptr[end_ix];
+		ptr[end_ix] = tmp;
+	}
+
+	return 0;
+}
+
+/*
+ * Get the next entry from the ddr capture buffer.
+ *
+ *  complex:			Ocla complex.
+ *  data:			Updated with entry read.
+ *
+ *  returns:			Zero on success, error otherwise.
+ */
+static int get_ddr_buf_entry(struct ocla_complex	*complex,
+			     uint64_t			*data)
+{
+	int	node;
+	int	ix;
+	void	*ptr;
+	int	rc = 0;
+
+	node = complex->node;
+	ix = complex->ix;
+
+	/* Check if the buffer has been completetly read */
+	if (complex->rd_line == complex->wr_line) {
+		/* Read any entries not flushed to the ddr buffer */
+		rc = cvmx_ocla_get_packet(node, ix, data);
+	} else {
+		*data = get_entry_from_line((struct ddr_line *)complex->rd_line,
+					    complex->cur_entry);
+
+		complex->cur_entry++;
+		if (complex->cur_entry == 26) {
+			complex->cur_entry = 0;
+			complex->line_cnt++;
+			complex->rd_line += CVMX_CACHE_LINE_SIZE;
+
+			ptr = cvmx_phys_to_ptr(complex->pbuf);
+			if (complex->rd_line >= ptr + complex->buf_size)
+				complex->rd_line = ptr;
+
+			swap_ddr_line(complex->rd_line);
+		}
+	}
+
+	return rc;
+}
+
+/*
+ * Read the capture fifo or ddr buffer.
+ *
+ *  complex:			Ocla complex.
+ *  buf:			Buffer to fill with the captured entries.
+ *  count:			Size of buf.
+ *
+ *  returns:			Number of bytes read, or error.
+ */
+static ssize_t ocla_read_fifo(struct ocla_complex	*complex,
+			      char __user		*buf,
+			      size_t			count)
+{
+	ssize_t		read_cnt = 0;
+	int		node;
+	int		ix;
+	uint64_t	data;
+
+	node = complex->node;
+	ix = complex->ix;
+
+	/* If a ddr buffer is in used, initialize variables */
+	if (complex->vbuf && complex->buf_size && complex->line_cnt == 0) {
+		cvmx_oclax_stack_base_t	base;
+		cvmx_oclax_stack_cur_t	cur;
+		cvmx_oclax_stack_wrap_t	wrap;
+		void			*ptr;
+
+		base.u64 = cvmx_read_csr_node(node, CVMX_OCLAX_STACK_BASE(ix));
+		cur.u64 = cvmx_read_csr_node(node, CVMX_OCLAX_STACK_CUR(ix));
+		wrap.u64 = cvmx_read_csr_node(node, CVMX_OCLAX_STACK_WRAP(ix));
+
+		/* Get the address of the ddr buffer */
+		ptr = cvmx_phys_to_ptr(complex->pbuf);
+
+		complex->wr_line = ptr + (cur.u64 - base.u64);
+		if (complex->wr_line >= ptr + complex->buf_size) {
+			complex->wr_line = ptr + complex->buf_size -
+				CVMX_CACHE_LINE_SIZE;
+		}
+
+		if (wrap.s.wraps) {
+			complex->rd_line = complex->wr_line +
+				CVMX_CACHE_LINE_SIZE;
+			if (complex->rd_line >= ptr + complex->buf_size)
+				complex->rd_line = ptr;
+		} else
+			complex->rd_line = ptr;
+
+		complex->cur_entry = 0;
+		complex->line_cnt = 1;
+		swap_ddr_line(complex->rd_line);
+	}
+
+	/* Try to read as many entries as possible */
+	while (read_cnt <= count - 8) {
+		if (complex->vbuf && complex->buf_size) {
+			if (get_ddr_buf_entry(complex, &data) < 0)
+				break;
+		} else {
+			if (cvmx_ocla_get_packet(node, ix, &data) < 0)
+				break;
+		}
+
+		if (copy_to_user(buf + read_cnt, (char *)&data, 8))
+			return -EFAULT;
+		read_cnt += 8;
+	}
+
+	return read_cnt;
+}
+
+/*
  * Read captured entries.
- * To mitigate interrupt overhead an approach similar to the one use by NAPI is
- * implemented:
- * 	. Readers enable the ocla interrupts and block waiting for captured
- *	  entries.
- *	. The interrupt handler is invoked when there's captured data. It
- *	  disables the interrupt and wakes up any blocked readers.
- *	. The readers read all entries, enable interrupts again when there
- *	  are no more entries to read, and block waiting for new enties.
+ * To keep ocla from interfering with the test, the reader blocks until capture
+ * is complete. Once capture completes, the reader is woken up and the captured
+ * entries read.
+ *
+ * Capture is deemed complete when the capture fifo/buffer fills or when the
+ * user stops the capture via CTRl_C.
  *
  *  file:			Pointer to file structure.
  *  buf:			Buffer to fill with the captured entries.
@@ -176,7 +503,6 @@ static ssize_t ocla_read(struct file *file, char __user *buf, size_t count,
 	struct ocla_complex	*complex;
 	ssize_t			read_cnt = 0;
 	unsigned long		flags;
-	uint64_t		data;
 	int			node;
 	int			ix;
 	int			i;
@@ -210,30 +536,32 @@ static ssize_t ocla_read(struct file *file, char __user *buf, size_t count,
 		spin_unlock_irqrestore(&complex->lock, flags);
 
 		if (wait_event_interruptible(complex->waitq,
-					     complex->data_avail == 1))
+					     complex->data_avail == 1)) {
+			/*
+			 * Interrupted. Disable interrutps and read the entries
+			 * captured.
+			 */
+			spin_lock_irqsave(&complex->lock, flags);
+			for (i = 0; i < MAX_OCLA_IRQS; i++) {
+				if (!complex->irqs[i].en) {
+					disable_irq(complex->irqs[i].irq);
+					complex->irqs[i].en = 0;
+				}
+			}
+			spin_unlock_irqrestore(&complex->lock, flags);
+			complex->data_avail = 1;
 			return -ERESTARTSYS;
+		}
 	}
 
-	/* Indicate data is not available before trying to empty the fifo */
-	complex->data_avail = 0;
-
-	/* Try to read as many entries as possible */
-	while (read_cnt <= count - 8) {
-		if (cvmx_ocla_get_packet(node, ix, &data) < 0)
-			break;
-		if (copy_to_user(buf + read_cnt, (char *)&data, 8))
-			return -EFAULT;
-		read_cnt += 8;
-	}
+	/* Read the fifo/buffer */
+	read_cnt = ocla_read_fifo(complex, buf, count);
 
-	/* Indicate data is available if the fifo is not yet empty */
-	if (read_cnt)
-		complex->data_avail = 1;
+	/* Indicate no more data is available */
+	if (!read_cnt)
+		complex->data_avail = 0;
 
 	*off += read_cnt;
-	/* If the buffer is full, we've reached the end of file */
-	if (!read_cnt && cvmx_is_fifo_full(node, ix))
-		read_cnt = -ENOSPC;
 
 	return read_cnt;
 }
@@ -255,13 +583,69 @@ static long ioctl_cap_req(struct file		*file,
 	if (req->node >= CVMX_MAX_NODES || req->ix >= MAX_COMPLEXES)
 		return -EINVAL;
 
+	if (file->private_data == NULL)
+		complex = &ocla_complexes[req->node][req->ix];
+	else
+		complex = file->private_data;
+
 	/* Make sure complex is available */
-	complex = &ocla_complexes[req->node][req->ix];
 	if (complex->state != COMPLEX_FREE)
-		return -EINVAL;
+		return -EBUSY;
 
 	complex->state = COMPLEX_IN_USE;
-	file->private_data = complex;
+
+	if (file->private_data == NULL)
+		file->private_data = complex;
+
+	return 0;
+}
+
+/*
+ * Process a ddr buffer request. Allocate a kernel buffer and return its
+ * physical address to the application.
+ *
+ *  file:			Pointer to file structure.
+ *  req:			Capture buffer request.
+ *
+ *  returns:			0 on success, error otherwise.
+ */
+static long ioctl_ddr_buf_req(struct file		*file,
+			      struct ddr_buf_req	*req)
+{
+	struct ocla_complex	*complex;
+	uint64_t		ptr;
+
+	/* Verify arguments */
+	if (req->node >= CVMX_MAX_NODES || req->ix >= MAX_COMPLEXES ||
+	    req->size > MAX_CAP_BUF_SIZE ||
+	    req->size & (CVMX_CACHE_LINE_SIZE - 1))
+		return -EINVAL;
+
+	if (file->private_data == NULL)
+		complex = &ocla_complexes[req->node][req->ix];
+	else
+		complex = file->private_data;
+
+	/* Make sure complex is available */
+	if (complex->state != COMPLEX_FREE)
+		return -EBUSY;
+
+	/*
+	 * Allocate the caputure buffer, if not already. Must be cache line
+	 * aligned.
+	 */
+	if (complex->vbuf == NULL) {
+		complex->vbuf = kzalloc_node(req->size + CVMX_CACHE_LINE_SIZE,
+					     GFP_ATOMIC, complex->node);
+		ptr = (((uint64_t)complex->vbuf + CVMX_CACHE_LINE_SIZE - 1) &
+		       ~(CVMX_CACHE_LINE_SIZE - 1));
+		complex->pbuf = cvmx_ptr_to_phys((void *)ptr);
+		complex->buf_size = req->size;
+	}
+	req->pbuf = complex->pbuf;
+
+	if (file->private_data == NULL)
+		file->private_data = complex;
 
 	return 0;
 }
@@ -279,8 +663,9 @@ static long ocla_ioctl(struct file	*file,
 		       unsigned int 	cmd,
 		       unsigned long	arg)
 {
-	struct cap_req	req;
-	long		rc = 0;
+	struct cap_req		req;
+	struct ddr_buf_req	breq;
+	long			rc = 0;
 
 	switch (cmd) {
 	case OCLA_CAP_REQ:
@@ -290,8 +675,18 @@ static long ocla_ioctl(struct file	*file,
 		rc = ioctl_cap_req(file, &req);
 		break;
 
+	case OCLA_DDR_BUF_REQ:
+		if (copy_from_user(&breq, (void __user *)arg, sizeof(breq)))
+			return -EFAULT;
+
+		rc = ioctl_ddr_buf_req(file, &breq);
+
+		if (copy_to_user((void __user *)arg, &breq, sizeof(breq)))
+			rc = -EFAULT;
+		break;
+
 	default:
-		printk(KERN_ERR "OCLA: Invalid ioctl cmd [%x]\n", cmd);
+		pr_err("OCLA: Invalid ioctl cmd [%d]\n", _IOC_NR(cmd));
 		rc = -EINVAL;
 		break;
 	}
@@ -345,6 +740,15 @@ static int ocla_release(struct inode *inode, struct file *file)
 		complex->data_avail = 0;
 		spin_unlock_irqrestore(&complex->lock, flags);
 
+		/* Free the capture buffer if available */
+		if (complex->vbuf) {
+			kfree(complex->vbuf);
+			complex->vbuf = NULL;
+			complex->pbuf = 0;
+			complex->line_cnt = 0;
+			complex->buf_size = 0;
+		}
+
 		complex->state = COMPLEX_FREE;
 	}
 
@@ -397,6 +801,10 @@ static int ocla_probe(struct platform_device *pdev)
 	init_waitqueue_head(&complex->waitq);
 	complex->pdev = pdev;
 	spin_lock_init(&complex->lock);
+	complex->vbuf = NULL;
+	complex->pbuf = 0;
+	complex->line_cnt = 0;
+	complex->buf_size = 0;
 
 	/* Register the interrupt handlers */
 	for (i = 0; i < pdev->num_resources; i++) {
-- 
2.6.2

