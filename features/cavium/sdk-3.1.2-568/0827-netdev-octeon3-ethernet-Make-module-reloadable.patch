From 94d386b15254a87df4129e2069562b6c464a0d06 Mon Sep 17 00:00:00 2001
From: Carlos Munoz <cmunoz@caviumnetworks.com>
Date: Mon, 28 Jul 2014 18:05:50 -0700
Subject: [PATCH 827/974] netdev: octeon3-ethernet: Make module reloadable.

Signed-off-by: Carlos Munoz <cmunoz@caviumnetworks.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 .../mips/cavium-octeon/executive/cvmx-helper-pki.c |   2 +
 .../cavium-octeon/executive/cvmx-helper-pko3.c     |   2 +
 drivers/net/ethernet/octeon/octeon-bgx-port.c      |   8 +-
 drivers/net/ethernet/octeon/octeon3-ethernet.c     | 227 ++++++++++++++++++---
 4 files changed, 211 insertions(+), 28 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
index a5a5958..02c428c 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
@@ -542,6 +542,7 @@ int cvmx_helper_pki_port_shutdown(int ipd_port)
 	/* __cvmx_pki_port_rsrc_free(node); */
 	return 0;
 }
+EXPORT_SYMBOL(cvmx_helper_pki_port_shutdown);
 
 /**
  * This function shuts down complete PKI hardware
@@ -561,6 +562,7 @@ void cvmx_helper_pki_shutdown(int node)
 	except fpa pools & aura which will be done in fpa block */
 	__cvmx_pki_global_rsrc_free(node);
 }
+EXPORT_SYMBOL(cvmx_helper_pki_shutdown);
 
 /**
  * This function calculates how mant qpf entries will be needed for
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
index dd63171..4e96e83 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
@@ -1303,6 +1303,7 @@ int cvmx_helper_pko3_shut_interface(int xiface)
 
 	return 0;
 }
+EXPORT_SYMBOL(cvmx_helper_pko3_shut_interface);
 
 /**
  * Shutdown PKO3
@@ -1343,3 +1344,4 @@ int cvmx_helper_pko3_shutdown(unsigned int node)
 #endif /* CVMX_BUILD_FOR_LINUX_KERNEL */
 	return res;
 }
+EXPORT_SYMBOL(cvmx_helper_pko3_shutdown);
diff --git a/drivers/net/ethernet/octeon/octeon-bgx-port.c b/drivers/net/ethernet/octeon/octeon-bgx-port.c
index cd4435d..aa03aad 100644
--- a/drivers/net/ethernet/octeon/octeon-bgx-port.c
+++ b/drivers/net/ethernet/octeon/octeon-bgx-port.c
@@ -72,9 +72,13 @@ static struct bgx_port_priv *bgx_port_netdev2priv(struct net_device *netdev)
 
 void bgx_port_set_netdev(struct device *dev, struct net_device *netdev)
 {
-	struct bgx_port_netdev_priv *nd_priv = netdev_priv(netdev);
 	struct bgx_port_priv *priv = dev_get_drvdata(dev);
-	nd_priv->bgx_priv = priv;
+
+	if (netdev) {
+		struct bgx_port_netdev_priv *nd_priv = netdev_priv(netdev);
+		nd_priv->bgx_priv = priv;
+	}
+
 	priv->netdev = netdev;
 }
 EXPORT_SYMBOL(bgx_port_set_netdev);
diff --git a/drivers/net/ethernet/octeon/octeon3-ethernet.c b/drivers/net/ethernet/octeon/octeon3-ethernet.c
index 488eb1d..60c9250 100644
--- a/drivers/net/ethernet/octeon/octeon3-ethernet.c
+++ b/drivers/net/ethernet/octeon/octeon3-ethernet.c
@@ -243,6 +243,9 @@ struct octeon3_ethernet_node {
 	cvmx_fpa3_pool_t  pki_packet_pool;
 	cvmx_fpa3_pool_t sso_pool;
 	cvmx_fpa3_pool_t pko_pool;
+	void *sso_pool_stack;
+	void *pko_pool_stack;
+	void *pki_packet_pool_stack;
 	cvmx_fpa3_gaura_t sso_aura;
 	cvmx_fpa3_gaura_t pko_aura;
 	int tx_complete_grp;
@@ -393,9 +396,10 @@ static void octeon3_eth_gen_affinity(int node, cpumask_t *mask)
 	cpumask_set_cpu(cpu, mask);
 }
 
-static int octeon3_eth_fpa_pool_init(cvmx_fpa3_pool_t pool, int num_ptrs)
+static int octeon3_eth_fpa_pool_init(cvmx_fpa3_pool_t	pool,
+				     void		**pool_stack,
+				     int		num_ptrs)
 {
-	void *pool_stack;
 	u64 pool_stack_start, pool_stack_end;
 	union cvmx_fpa_poolx_end_addr limit_addr;
 	union cvmx_fpa_poolx_cfg cfg;
@@ -407,11 +411,11 @@ static int octeon3_eth_fpa_pool_init(cvmx_fpa3_pool_t pool, int num_ptrs)
 	limit_addr.cn78xx.addr = ~0ll;
 	cvmx_write_csr_node(pool.node, CVMX_FPA_POOLX_END_ADDR(pool.lpool), limit_addr.u64);
 
-	pool_stack = kmalloc_node(stack_size, GFP_KERNEL, pool.node);
-	if (!pool_stack)
+	*pool_stack = kmalloc_node(stack_size, GFP_KERNEL, pool.node);
+	if (!*pool_stack)
 		return -ENOMEM;
 
-	pool_stack_start = virt_to_phys(pool_stack);
+	pool_stack_start = virt_to_phys(*pool_stack);
 	pool_stack_end = round_down(pool_stack_start + stack_size, 128);
 	pool_stack_start = round_up(pool_stack_start, 128);
 
@@ -491,7 +495,9 @@ static int octeon3_eth_sso_init(unsigned int node, int aura)
 		}
 		phys = virt_to_phys(mem);
 		cvmx_write_csr_node(node, CVMX_SSO_XAQX_HEAD_PTR(i), phys);
+		cvmx_write_csr_node(node, CVMX_SSO_XAQX_HEAD_NEXT(i), phys);
 		cvmx_write_csr_node(node, CVMX_SSO_XAQX_TAIL_PTR(i), phys);
+		cvmx_write_csr_node(node, CVMX_SSO_XAQX_TAIL_NEXT(i), phys);
 		/* SSO-18678 */
 		cvmx_write_csr_node(node, CVMX_SSO_GRPX_PRI(i), grp_pri.u64);
 	}
@@ -506,6 +512,67 @@ err:
 	return rv;
 }
 
+/* octeon3_eth_sso_shutdown:		Shutdown the sso. It undoes what
+ *					octeon3_eth_sso_init() did.
+ *
+ *  node:				Node where sso to disable is.
+ */
+static void octeon3_eth_sso_shutdown(unsigned int node)
+{
+	struct octeon3_ethernet_node	*oen;
+	union cvmx_sso_aw_cfg		aw_cfg;
+	cvmx_sso_grpx_aq_cnt_t		aq_cnt;
+	cvmx_sso_aw_status_t		aw_status;
+	int				i;
+
+	oen = octeon3_eth_node + node;
+
+	/* Disable sso */
+	aw_cfg.u64 = cvmx_read_csr_node(node, CVMX_SSO_AW_CFG);
+	aw_cfg.s.xaq_byp_dis = 1;
+	aw_cfg.s.xaq_alloc_dis = 1;
+	aw_cfg.s.rwen = 0;
+	cvmx_write_csr_node(node, CVMX_SSO_AW_CFG, aw_cfg.u64);
+
+	/* Extract the fpa buffers */
+	for (i = 0; i < 256; i++) {
+		cvmx_sso_xaqx_head_ptr_t	head;
+		cvmx_sso_xaqx_tail_ptr_t	tail;
+		u64				addr;
+		void				*ptr;
+
+		head.u64 = cvmx_read_csr_node(node, CVMX_SSO_XAQX_HEAD_PTR(i));
+		tail.u64 = cvmx_read_csr_node(node, CVMX_SSO_XAQX_TAIL_PTR(i));
+		aq_cnt.u64 = cvmx_read_csr_node(node, CVMX_SSO_GRPX_AQ_CNT(i));
+
+		/* Verify pointers */
+		if (head.s.ptr != tail.s.ptr) {
+			pr_err("WARNING: octeon3_eth_sso_shutdown bad ptr\n");
+			continue;
+		}
+
+		/* This sso group should have no pending entries */
+		if (aq_cnt.s.aq_cnt != 0)
+			pr_err("WARNING: octeon3_eth_sso_shutdown not empty\n");
+
+		addr = head.s.ptr;
+		addr <<= 7;
+		ptr = phys_to_virt(addr);
+		cvmx_fpa3_free(ptr, oen->sso_aura, 0);
+
+		/* Clear pointers */
+		cvmx_write_csr_node(node, CVMX_SSO_XAQX_HEAD_PTR(i), 0);
+		cvmx_write_csr_node(node, CVMX_SSO_XAQX_HEAD_NEXT(i), 0);
+		cvmx_write_csr_node(node, CVMX_SSO_XAQX_TAIL_PTR(i), 0);
+		cvmx_write_csr_node(node, CVMX_SSO_XAQX_TAIL_NEXT(i), 0);
+	}
+
+	/* Make sure all buffers drained */
+	do
+		aw_status.u64 = cvmx_read_csr_node(node, CVMX_SSO_AW_STATUS);
+	while (aw_status.s.xaq_buf_cached);
+}
+
 static void octeon3_eth_sso_irq_set_armed(int node, int grp, bool v)
 {
 	union cvmx_sso_grpx_int_thr grp_int_thr;
@@ -620,7 +687,7 @@ static void octeon3_eth_replenish_rx(struct octeon3_ethernet *priv, int count)
 
 static bool octeon3_eth_tx_complete_runnable(struct octeon3_ethernet_worker *worker)
 {
-	return atomic_read(&worker->kick) != 0;
+	return atomic_read(&worker->kick) != 0 || kthread_should_stop();
 }
 
 static int octeon3_eth_replenish_all(struct octeon3_ethernet_node *oen)
@@ -653,7 +720,7 @@ static int octeon3_eth_tx_complete_worker(void *data)
 	int backlog_stop_thresh = order == 0 ? 31 : order * 80;
 	int i;
 
-	for (;;) {
+	while (!kthread_should_stop()) {
 		/*
 		 * replaced by wait_event to avoid warnings like
 		 * "task oct3_eth/0:2:1250 blocked for more than 120 seconds."
@@ -768,9 +835,11 @@ static int octeon3_eth_global_init(unsigned int node)
 	       oen->sso_pool.lpool, oen->sso_aura.laura,
 	       oen->pko_pool.lpool, oen->pko_aura.laura);
 
-	octeon3_eth_fpa_pool_init(oen->sso_pool, 40960);
-	octeon3_eth_fpa_pool_init(oen->pko_pool, 40960);
-	octeon3_eth_fpa_pool_init(oen->pki_packet_pool, 64 * num_packet_buffers);
+	octeon3_eth_fpa_pool_init(oen->sso_pool, &oen->sso_pool_stack, 40960);
+	octeon3_eth_fpa_pool_init(oen->pko_pool, &oen->pko_pool_stack, 40960);
+	octeon3_eth_fpa_pool_init(oen->pki_packet_pool,
+				  &oen->pki_packet_pool_stack,
+				  64 * num_packet_buffers);
 	octeon3_eth_fpa_aura_init(oen->sso_pool, oen->sso_aura, 20480);
 	octeon3_eth_fpa_aura_init(oen->pko_pool, oen->pko_aura, 20480);
 
@@ -1484,7 +1553,7 @@ static int octeon3_eth_ndo_init(struct net_device *netdev)
 		&priv->buffers_needed;
 
 	base_rx_grp = -1;
-	r = cvmx_sso_allocate_group_range(priv->numa_node, &base_rx_grp, rx_contexts);
+	r = cvmx_sso_reserve_group_range(priv->numa_node, &base_rx_grp, rx_contexts);
 	if (r) {
 		dev_err(netdev->dev.parent, "Failed to allocated SSO group\n");
 		return -ENODEV;
@@ -1520,6 +1589,7 @@ static int octeon3_eth_ndo_init(struct net_device *netdev)
 	prt_schd->qpg_qos = CVMX_PKI_QPG_QOS_NONE;
 
 	cvmx_helper_pki_init_port(ipd_port, prt_schd);
+	kfree(prt_schd);
 	cvmx_pki_get_port_config(ipd_port, &pki_prt_cfg);
 
 	pki_prt_cfg.style_cfg.parm_cfg.ip6_udp_opt = false;
@@ -1620,8 +1690,6 @@ static int octeon3_eth_ndo_init(struct net_device *netdev)
 	/* Register ethtool methods */
 	SET_ETHTOOL_OPS(netdev, &octeon3_ethtool_ops);
 
-	__cvmx_export_config();
-
 	return 0;
 err:
 	kfree(prt_schd);
@@ -1630,6 +1698,23 @@ err:
 
 static void octeon3_eth_ndo_uninit(struct net_device *netdev)
 {
+	struct octeon3_ethernet	*priv = netdev_priv(netdev);
+	int			ipd_port;
+
+	/* Shutdwon pki for this interface */
+	ipd_port = cvmx_helper_get_ipd_port(priv->xiface, priv->port_index);
+	cvmx_helper_pki_port_shutdown(ipd_port);
+	cvmx_fpa3_release_aura(__cvmx_fpa3_gaura(priv->numa_node,
+						 priv->pki_laura));
+	aura2bufs_needed[priv->numa_node][priv->pki_laura] = NULL;
+
+	/* Shutdown pko for this interface */
+	cvmx_helper_pko3_shut_interface(priv->xiface);
+
+	/* Free the receive contexts sso groups */
+	cvmx_sso_release_group_range(priv->numa_node, priv->rx_cxt[0].rx_grp,
+				     rx_contexts);
+
 	return;
 }
 
@@ -1707,7 +1792,6 @@ static int octeon3_eth_ndo_open(struct net_device *netdev)
 	octeon3_eth_replenish_rx(priv, priv->rx_buf_count);
 
 	r = bgx_port_enable(netdev);
-	__cvmx_export_config();
 
 	return r;
 
@@ -1744,24 +1828,29 @@ static int octeon3_eth_ndo_stop(struct net_device *netdev)
 	if (r)
 		goto err;
 
+	/* Allow enough time for ingress in transit packets to be drained */
 	msleep(20);
 
+	/* Wait until sso has no more work for this interface */
 	for (i = 0; i < priv->num_rx_cxt; i++) {
 		rx = priv->rx_cxt + i;
-		/* Wait for SSO to drain */
 		while (cvmx_read_csr_node(priv->numa_node, CVMX_SSO_GRPX_AQ_CNT(rx->rx_grp)))
 			msleep(20);
 	}
 
+	/* Free the irq and napi context for each rx context */
 	for (i = 0; i < priv->num_rx_cxt; i++) {
 		rx = priv->rx_cxt + i;
 		octeon3_eth_sso_irq_set_armed(priv->numa_node, rx->rx_grp, false);
-
 		irq_set_affinity_hint(rx->rx_irq, NULL);
 		free_irq(rx->rx_irq, rx);
+		irq_dispose_mapping(rx->rx_irq);
 		rx->rx_irq = 0;
+
+		octeon3_rm_napi_from_cxt(priv->numa_node, rx->napiw);
+		rx->napiw = NULL;
+		BUG_ON(!__bitmap_empty(rx->napi_idx_bitmap, CVMX_MAX_CORES));
 	}
-	msleep(20);
 
 	/* Free the packet buffers */
 	for (;;) {
@@ -1772,13 +1861,6 @@ static int octeon3_eth_ndo_stop(struct net_device *netdev)
 		dev_kfree_skb(skb);
 	}
 
-	/* Free the napis */
-	for (i = 0; i < priv->num_rx_cxt; i++) {
-		octeon3_rm_napi_from_cxt(priv->numa_node,
-					 priv->rx_cxt[i].napiw);
-		priv->rx_cxt[i].napiw = NULL;
-	}
-
 err:
 	return r;
 }
@@ -2184,10 +2266,103 @@ static int octeon3_eth_probe(struct platform_device *pdev)
 	return 0;
 }
 
+/*
+ * octeon3_eth_global_exit:	Free all the used resources and restore the
+ *				hardware to the default state.
+ *
+ *  node:			Node to free/reset.
+ *
+ *  Returns:			Zero on success, error otherwise.
+ */
+static int octeon3_eth_global_exit(int node)
+{
+	struct octeon3_ethernet_node	*oen = octeon3_eth_node + node;
+	int				i;
+
+	/* Free the tx_complete irq */
+	octeon3_eth_sso_irq_set_armed(node, oen->tx_complete_grp, false);
+	irq_set_affinity_hint(oen->tx_irq, NULL);
+	free_irq(oen->tx_irq, oen);
+	irq_dispose_mapping(oen->tx_irq);
+	oen->tx_irq = 0;
+
+	/* Stop the worker threads */
+	for (i = 0; i < ARRAY_SIZE(oen->workers); i++)
+		kthread_stop(oen->workers[i].task);
+
+	/* Shutdown pki */
+	cvmx_helper_pki_shutdown(node);
+	cvmx_fpa3_release_pool(oen->pki_packet_pool);
+	kfree(oen->pki_packet_pool_stack);
+
+	/* Shutdown pko */
+	cvmx_helper_pko3_shutdown(node);
+	for (;;) {
+		void **w;
+
+		w = cvmx_fpa3_alloc(oen->pko_aura);
+		if (!w)
+			break;
+		kmem_cache_free(octeon3_eth_sso_pko_cache, w);
+	}
+	cvmx_fpa3_release_aura(oen->pko_aura);
+	cvmx_fpa3_release_pool(oen->pko_pool);
+	kfree(oen->pko_pool_stack);
+
+	/* Shutdown sso */
+	cvmx_sso_release_group(node, oen->tx_complete_grp);
+	octeon3_eth_sso_shutdown(node);
+	for (;;) {
+		void **w;
+
+		w = cvmx_fpa3_alloc(oen->sso_aura);
+		if (!w)
+			break;
+		kmem_cache_free(octeon3_eth_sso_pko_cache, w);
+	}
+	cvmx_fpa3_release_aura(oen->sso_aura);
+	cvmx_fpa3_release_pool(oen->sso_pool);
+	kfree(oen->sso_pool_stack);
+
+	/* Destroy the memory cache used by sso and pko */
+	kmem_cache_destroy(octeon3_eth_sso_pko_cache);
+
+	return 0;
+}
+
 static int octeon3_eth_remove(struct platform_device *pdev)
 {
-//	struct net_device *netdev = dev_get_drvdata(&pdev->dev);
-//	struct octeon3_ethernet *priv = netdev_priv(netdev);
+	struct net_device		*netdev = dev_get_drvdata(&pdev->dev);
+	struct octeon3_ethernet		*priv = netdev_priv(netdev);
+	int				node = priv->numa_node;
+	struct octeon3_ethernet_node	*oen = octeon3_eth_node + node;
+
+	unregister_netdev(netdev);
+	bgx_port_set_netdev(pdev->dev.parent, NULL);
+	dev_set_drvdata(&pdev->dev, NULL);
+	free_netdev(netdev);
+
+	/* Free all resources when there are no more devices */
+	mutex_lock(&octeon3_eth_init_mutex);
+	mutex_lock(&oen->device_list_lock);
+	list_del_rcu(&priv->list);
+	if (oen->init_done && list_empty(&oen->device_list)) {
+		int	i;
+
+		octeon3_eth_global_exit(node);
+
+		for (i = 0; i < MAX_NAPIS_PER_NODE; i++) {
+			napi_disable(&napi_wrapper[node][i].napi);
+			netif_napi_del(&napi_wrapper[node][i].napi);
+		}
+
+		oen->init_done = false;
+		oen->napi_init_done = false;
+	}
+
+	mutex_unlock(&oen->device_list_lock);
+	mutex_unlock(&octeon3_eth_init_mutex);
+
 	return 0;
 }
 
-- 
2.6.2

