From ccb7c0404d3231bb074e50e83a3b51dc437ad4c6 Mon Sep 17 00:00:00 2001
From: Peter Swain <peter.swain@cavium.com>
Date: Tue, 25 Feb 2014 13:46:59 -0800
Subject: [PATCH 506/974] MMC: octeon_mmc multi-block dma

octeon_mmc's DMA engine doesn't do scatter-gather, so use a linear-mapped
bounce buffer to allow multi-sector mode.  Default size 256k gives a 2x
speedup on a Sony UHS-1 eMMC 16GB card (11.3MB/s, up from 5.3).
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 drivers/mmc/host/octeon_mmc.c | 311 +++++++++++++++++++++---------------------
 1 file changed, 152 insertions(+), 159 deletions(-)

diff --git a/drivers/mmc/host/octeon_mmc.c b/drivers/mmc/host/octeon_mmc.c
index b38e1ee..f17a241 100644
--- a/drivers/mmc/host/octeon_mmc.c
+++ b/drivers/mmc/host/octeon_mmc.c
@@ -58,7 +58,6 @@
 #define OCT_MIO_EMM_BUF_DAT		0xe8
 
 struct octeon_mmc_host {
-	spinlock_t		lock;
 	struct mmc_host         *mmc;
 	u64	base;
 	u64	ndf_base;
@@ -66,6 +65,8 @@ struct octeon_mmc_host {
 	int	last_slot;
 
 	struct mmc_request	*current_req;
+	unsigned int		linear_buf_size;
+	void			*linear_buf;
 	struct sg_mapping_iter smi;
 	int sg_idx;
 	bool dma_active;
@@ -100,16 +101,16 @@ struct octeon_mmc_slot {
 	bool			pwr_gpio_low;
 };
 
-static int limit_max_blk = -1;
-module_param(limit_max_blk, int, S_IRUGO);
+static int bb_size = 1 << 18;
+module_param(bb_size, int, S_IRUGO);
 MODULE_PARM_DESC(limit_max_blk,
-		 "Set an upper limit on the number of blocks in a single transfer.");
-
-static int force_no_multi;
-module_param(force_no_multi, int, S_IRUGO);
-MODULE_PARM_DESC(force_no_multi,
-		 "Force the interface to emulate multi-block transfers as a series of single block transfres.");
+		 "Size of DMA linearizing buffer (max transfer size).");
 
+#if 1
+#define octeon_mmc_dbg trace_printk
+#else
+static inline octeon_mmc_dbg(const char *s, ...) { }
+#endif
 
 static void octeon_mmc_acquire_bus(void)
 {
@@ -274,30 +275,6 @@ static unsigned int octeon_mmc_timeout_to_wdog(struct octeon_mmc_slot *slot,
 	return (unsigned int)(bt / 1000000000);
 }
 
-static void octeon_mmc_dma_next(struct octeon_mmc_slot	*slot)
-{
-	struct octeon_mmc_host *host = slot->host;
-	struct scatterlist *sg;
-	struct mmc_data *data;
-	union cvmx_mio_ndf_dma_cfg dma_cfg;
-
-	data = host->current_req->data;
-	sg = data->sg + host->sg_idx;
-
-	dma_cfg.u64 = 0;
-	dma_cfg.s.en = 1;
-	dma_cfg.s.rw = (data->flags & MMC_DATA_WRITE) ? 1 : 0;
-#ifdef __LITTLE_ENDIAN
-	dma_cfg.s.endian = 1;
-#endif
-	dma_cfg.s.size = (sg->length / 8) - 1;
-	dma_cfg.s.adr = sg_phys(sg);
-
-	host->sg_idx++;
-
-	cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_CFG, dma_cfg.u64);
-}
-
 static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 {
 	struct octeon_mmc_host *host = dev_id;
@@ -305,22 +282,18 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 	struct mmc_request	*req;
 	bool host_done;
 	union cvmx_mio_emm_rsp_sts rsp_sts;
-	unsigned long flags;
 
-	spin_lock_irqsave(&host->lock, flags);
 	emm_int.u64 = cvmx_read_csr(host->base + OCT_MIO_EMM_INT);
 	req = host->current_req;
 	cvmx_write_csr(host->base + OCT_MIO_EMM_INT, emm_int.u64);
 
-	pr_debug("Got interrupt: EMM_INT = 0x%llx\n", emm_int.u64);
+	octeon_mmc_dbg("Got interrupt: EMM_INT = 0x%llx\n", emm_int.u64);
 
-	if (!req) {
-		spin_unlock_irqrestore(&host->lock, flags);
+	if (!req)
 		goto out;
-	}
 
 	rsp_sts.u64 = cvmx_read_csr(host->base + OCT_MIO_EMM_RSP_STS);
-	pr_debug("octeon_mmc_interrupt  MIO_EMM_RSP_STS 0x%llx\n", rsp_sts.u64);
+	octeon_mmc_dbg("octeon_mmc_interrupt  MIO_EMM_RSP_STS 0x%llx\n", rsp_sts.u64);
 
 	if (host->dma_err_pending) {
 		host->current_req = NULL;
@@ -329,40 +302,46 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 		goto no_req_done;
 	}
 
-	if (!host->dma_active && emm_int.s.buf_done && req->cmd->data &&
-	    ((rsp_sts.u64 >> 7) & 3) == 1) {
-		/* Read */
-		int dbuf = rsp_sts.s.dbuf;
-		struct sg_mapping_iter *smi = &host->smi;
-		unsigned int bytes_xfered = 0;
-		u64 dat = 0;
-		int shift = -1;
-
-		/* Auto inc from offset zero */
-		cvmx_write_csr(host->base + OCT_MIO_EMM_BUF_IDX, (u64)(0x10000 | (dbuf << 6)));
-
-		for (;;) {
-			if (smi->consumed >= smi->length) {
-				if (!sg_miter_next(smi))
-					break;
-				smi->consumed = 0;
-			}
-			if (shift < 0) {
-				dat = cvmx_read_csr(host->base + OCT_MIO_EMM_BUF_DAT);
-				shift = 56;
-			}
+	if (!host->dma_active && emm_int.s.buf_done && req->data) {
+		unsigned int type = (rsp_sts.u64 >> 7) & 3;
+		if (type == 1) {
+			/* Read */
+			int dbuf = rsp_sts.s.dbuf;
+			struct sg_mapping_iter *smi = &host->smi;
+			unsigned int data_len = req->data->blksz * req->data->blocks;
+			unsigned int bytes_xfered;
+			u64 dat = 0;
+			int shift = -1;
+
+			/* Auto inc from offset zero */
+			cvmx_write_csr(host->base + OCT_MIO_EMM_BUF_IDX, (u64)(0x10000 | (dbuf << 6)));
+
+			for (bytes_xfered = 0; bytes_xfered < data_len;) {
+				if (smi->consumed >= smi->length) {
+					if (!sg_miter_next(smi))
+						break;
+					smi->consumed = 0;
+				}
+				if (shift < 0) {
+					dat = cvmx_read_csr(host->base + OCT_MIO_EMM_BUF_DAT);
+					shift = 56;
+				}
 
-			while (smi->consumed < smi->length && shift >= 0) {
-				*(u8 *)(smi->addr) = (dat >> shift) & 0xff;
-				bytes_xfered++;
-				smi->addr++;
-				smi->consumed++;
-				shift -= 8;
+				while (smi->consumed < smi->length && shift >= 0) {
+					((u8 *)(smi->addr))[smi->consumed] = (dat >> shift) & 0xff;
+					bytes_xfered++;
+					smi->consumed++;
+					shift -= 8;
+				}
 			}
+			sg_miter_stop(smi);
+			req->data->bytes_xfered = bytes_xfered;
+			req->data->error = 0;
+		} else if (type == 2) {
+			/* write */
+			req->data->bytes_xfered = req->data->blksz * req->data->blocks;
+			req->data->error = 0;
 		}
-		sg_miter_stop(smi);
-		req->cmd->data->bytes_xfered = bytes_xfered;
-		req->cmd->data->error = 0;
 	}
 	host_done = emm_int.s.cmd_done || emm_int.s.dma_done ||
 		emm_int.s.cmd_err || emm_int.s.dma_err;
@@ -378,9 +357,14 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 			req->cmd->error = 0;
 		}
 
-		if (host->dma_active && req->cmd->data) {
-			req->cmd->data->error = 0;
-			req->cmd->data->bytes_xfered = req->cmd->data->blocks * req->cmd->data->blksz;
+		if (host->dma_active && req->data) {
+			req->data->error = 0;
+			req->data->bytes_xfered = req->data->blocks * req->data->blksz;
+			if (!(req->data->flags & MMC_DATA_WRITE) && req->data->sg_len > 1) {
+				size_t r = sg_copy_from_buffer(req->data->sg, req->data->sg_len,
+							       host->linear_buf, host->linear_buf_size);
+				WARN_ON(r != req->data->bytes_xfered);
+			}
 		}
 		if (rsp_sts.s.rsp_val) {
 			u64 rsp_hi;
@@ -402,13 +386,13 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 				req->cmd->resp[0] = (rsp_hi >> 32) & 0xffffffff;
 				break;
 			default:
-				pr_debug("octeon_mmc_interrupt unhandled rsp_val %d\n",
-					 rsp_sts.s.rsp_type);
+				octeon_mmc_dbg("octeon_mmc_interrupt unhandled rsp_val %d\n",
+					       rsp_sts.s.rsp_type);
 				break;
 			}
-			pr_debug("octeon_mmc_interrupt  resp %08x %08x %08x %08x\n",
-				 req->cmd->resp[0], req->cmd->resp[1],
-				 req->cmd->resp[2], req->cmd->resp[3]);
+			octeon_mmc_dbg("octeon_mmc_interrupt  resp %08x %08x %08x %08x\n",
+				       req->cmd->resp[0], req->cmd->resp[1],
+				       req->cmd->resp[2], req->cmd->resp[3]);
 		}
 		if (emm_int.s.dma_err && rsp_sts.s.dma_pend) {
 			/* Try to clean up failed DMA */
@@ -433,7 +417,6 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 		req->done(req);
 	}
 no_req_done:
-	spin_unlock_irqrestore(&host->lock, flags);
 	if (host_done)
 		octeon_mmc_release_bus();
 out:
@@ -447,13 +430,14 @@ static void octeon_mmc_switch_to(struct octeon_mmc_slot	*slot)
 	union cvmx_mio_emm_switch sw;
 	union cvmx_mio_emm_sample samp;
 
-	if (host->last_slot < 0 || slot->bus_id == host->last_slot)
+	if (slot->bus_id == host->last_slot)
 		goto out;
 
-	old_slot = host->slot[host->last_slot];
-	old_slot->cached_switch = cvmx_read_csr(host->base + OCT_MIO_EMM_SWITCH);
-	old_slot->cached_rca = cvmx_read_csr(host->base + OCT_MIO_EMM_RCA);
-
+	if (host->last_slot >= 0) {
+		old_slot = host->slot[host->last_slot];
+		old_slot->cached_switch = cvmx_read_csr(host->base + OCT_MIO_EMM_SWITCH);
+		old_slot->cached_rca = cvmx_read_csr(host->base + OCT_MIO_EMM_RCA);
+	}
 	cvmx_write_csr(host->base + OCT_MIO_EMM_RCA, slot->cached_rca);
 	sw.u64 = slot->cached_switch;
 	sw.s.bus_id = 0;
@@ -463,7 +447,7 @@ static void octeon_mmc_switch_to(struct octeon_mmc_slot	*slot)
 
 	samp.u64 = 0;
 	samp.s.cmd_cnt = slot->cmd_cnt;
-	samp.s.cmd_cnt = slot->cmd_cnt;
+	samp.s.dat_cnt = slot->dat_cnt;
 	cvmx_write_csr(host->base + OCT_MIO_EMM_SAMPLE, samp.u64);
 out:
 	host->last_slot = slot->bus_id;
@@ -478,7 +462,7 @@ static void octeon_mmc_dma_request(struct mmc_host *mmc,
 	struct mmc_data *data;
 	union cvmx_mio_emm_int emm_int;
 	union cvmx_mio_emm_dma emm_dma;
-	unsigned long flags;
+	union cvmx_mio_ndf_dma_cfg dma_cfg;
 
 	cmd = mrq->cmd;
 	if (mrq->data == NULL || mrq->data->sg == NULL || !mrq->data->sg_len ||
@@ -504,11 +488,10 @@ static void octeon_mmc_dma_request(struct mmc_host *mmc,
 	if (data->timeout_ns) {
 		cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 			       octeon_mmc_timeout_to_wdog(slot, data->timeout_ns));
-		pr_debug("OCT_MIO_EMM_WDOG %llu\n",
-			 cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
+		octeon_mmc_dbg("OCT_MIO_EMM_WDOG %llu\n",
+			       cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
 	}
 
-	spin_lock_irqsave(&host->lock, flags);
 	WARN_ON(host->current_req);
 	host->current_req = mrq;
 
@@ -517,15 +500,35 @@ static void octeon_mmc_dma_request(struct mmc_host *mmc,
 	/* Clear any pending irqs */
 	cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_INT, 1);
 
-	octeon_mmc_dma_next(slot);
+	WARN_ON(data->blksz * data->blocks > host->linear_buf_size);
+
+	if ((data->flags & MMC_DATA_WRITE) && data->sg_len > 1) {
+		size_t r = sg_copy_to_buffer(data->sg, data->sg_len,
+					     host->linear_buf, host->linear_buf_size);
+		WARN_ON(data->blksz * data->blocks != r);
+	}
+
+	dma_cfg.u64 = 0;
+	dma_cfg.s.en = 1;
+	dma_cfg.s.rw = (data->flags & MMC_DATA_WRITE) ? 1 : 0;
+#ifdef __LITTLE_ENDIAN
+	dma_cfg.s.endian = 1;
+#endif
+	dma_cfg.s.size = ((data->blksz * data->blocks) / 8) - 1;
+	if (data->sg_len > 1)
+		dma_cfg.s.adr = virt_to_phys(host->linear_buf);
+	else
+		dma_cfg.s.adr = sg_phys(data->sg);
+	cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_CFG, dma_cfg.u64);
+	trace_printk("MIO_NDF_DMA_CFG: %016llx\n", (unsigned long long)dma_cfg.u64);
+
 	emm_dma.u64 = 0;
 	emm_dma.s.bus_id = slot->bus_id;
 	emm_dma.s.dma_val = 1;
 	emm_dma.s.sector = mmc_card_blockaddr(mmc->card) ? 1 : 0;
 	emm_dma.s.rw = (data->flags & MMC_DATA_WRITE) ? 1 : 0;
-	if (!force_no_multi &&
-	    (mmc_card_mmc(mmc->card) ||	(mmc_card_sd(mmc->card) &&
-					 (mmc->card->scr.cmds & SD_SCR_CMD23_SUPPORT))))
+	if (mmc_card_mmc(mmc->card) ||
+	    (mmc_card_sd(mmc->card) && (mmc->card->scr.cmds & SD_SCR_CMD23_SUPPORT)))
 		emm_dma.s.multi = 1;
 	emm_dma.s.block_cnt = data->blocks;
 	emm_dma.s.card_addr = cmd->arg;
@@ -539,12 +542,12 @@ static void octeon_mmc_dma_request(struct mmc_host *mmc,
 	cvmx_write_csr(host->base + OCT_MIO_EMM_INT_EN, emm_int.u64);
 	host->dma_active = true;
 
-	spin_unlock_irqrestore(&host->lock, flags);
-
-	cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0xe4f90080ull);
-	cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0);
+	if (mmc->card && mmc_card_sd(mmc->card))
+		cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0x00b00000ull);
+	else
+		cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0xe4f90080ull);
 	cvmx_write_csr(host->base + OCT_MIO_EMM_DMA, emm_dma.u64);
-	pr_debug("Send the dma command: %llx\n", emm_dma.u64);
+	octeon_mmc_dbg("MIO_EMM_DMA: %llx\n", emm_dma.u64);
 }
 
 static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
@@ -555,7 +558,6 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	union cvmx_mio_emm_int emm_int;
 	union cvmx_mio_emm_cmd emm_cmd;
 	struct octeon_mmc_cr_mods mods;
-	unsigned long flags;
 
 	cmd = mrq->cmd;
 
@@ -574,7 +576,6 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 
 	octeon_mmc_switch_to(slot);
 
-	spin_lock_irqsave(&host->lock, flags);
 	WARN_ON(host->current_req);
 	host->current_req = mrq;
 
@@ -582,24 +583,23 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	emm_int.s.cmd_done = 1;
 	emm_int.s.cmd_err = 1;
 	if (cmd->data) {
-		pr_debug("command has data\n");
-		cmd->error = -EINPROGRESS;
+		octeon_mmc_dbg("command has data\n");
 		if (cmd->data->flags & MMC_DATA_READ) {
-			emm_int.s.buf_done = 1;
-			sg_miter_start(&host->smi, mrq->cmd->data->sg,
-				       mrq->cmd->data->sg_len, SG_MITER_ATOMIC | SG_MITER_TO_SG);
+			sg_miter_start(&host->smi, mrq->data->sg,
+				       mrq->data->sg_len, SG_MITER_ATOMIC | SG_MITER_TO_SG);
 		} else {
 			struct sg_mapping_iter *smi = &host->smi;
-			unsigned int bytes_xfered = 0;
+			unsigned int data_len = mrq->data->blksz * mrq->data->blocks;
+			unsigned int bytes_xfered;
 			u64 dat = 0;
 			int shift = 56;
 			/* Copy data to the xmit buffer before issuing the command */
-			sg_miter_start(smi, mrq->cmd->data->sg,
-				       mrq->cmd->data->sg_len, SG_MITER_TO_SG);
+			sg_miter_start(smi, mrq->data->sg,
+				       mrq->data->sg_len, SG_MITER_FROM_SG);
 			/* Auto inc from offset zero, dbuf zero */
 			cvmx_write_csr(host->base + OCT_MIO_EMM_BUF_IDX, 0x10000ull);
 
-			for (;;) {
+			for (bytes_xfered = 0; bytes_xfered < data_len;) {
 				if (smi->consumed >= smi->length) {
 					if (!sg_miter_next(smi))
 						break;
@@ -607,9 +607,8 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 				}
 
 				while (smi->consumed < smi->length && shift >= 0) {
-					dat |= (u64)(*(u8 *)(smi->addr)) << shift;
+					dat |= (u64)(((u8 *)(smi->addr))[smi->consumed]) << shift;
 					bytes_xfered++;
-					smi->addr++;
 					smi->consumed++;
 					shift -= 8;
 				}
@@ -620,26 +619,23 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 				}
 			}
 			sg_miter_stop(smi);
-			cmd->data->bytes_xfered = bytes_xfered;
-			cmd->data->error = 0;
 		}
 		if (cmd->data->timeout_ns) {
 			cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 				       octeon_mmc_timeout_to_wdog(slot, cmd->data->timeout_ns));
-			pr_debug("OCT_MIO_EMM_WDOG %llu\n",
-				 cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
+			octeon_mmc_dbg("OCT_MIO_EMM_WDOG %llu\n",
+				       cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
 		}
 	} else {
 		cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 			       ((u64)slot->clock * 850ull) / 1000ull);
-		pr_debug("OCT_MIO_EMM_WDOG %llu\n",
-			 cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
+		octeon_mmc_dbg("OCT_MIO_EMM_WDOG %llu\n",
+			       cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
 	}
 	/* Clear the bit. */
 	cvmx_write_csr(host->base + OCT_MIO_EMM_INT, emm_int.u64);
 	cvmx_write_csr(host->base + OCT_MIO_EMM_INT_EN, emm_int.u64);
 	host->dma_active = false;
-	spin_unlock_irqrestore(&host->lock, flags);
 
 	emm_cmd.u64 = 0;
 	emm_cmd.s.cmd_val = 1;
@@ -652,7 +648,7 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	emm_cmd.s.arg = cmd->arg;
 	cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0);
 	cvmx_write_csr(host->base + OCT_MIO_EMM_CMD, emm_cmd.u64);
-	pr_debug("Send the command: %llx\n", emm_cmd.u64);
+	octeon_mmc_dbg("MIO_EMM_CMD: %llx\n", emm_cmd.u64);
 }
 
 static void octeon_mmc_reset_bus(struct octeon_mmc_slot *slot, int preserve)
@@ -667,15 +663,6 @@ static void octeon_mmc_reset_bus(struct octeon_mmc_slot *slot, int preserve)
 		wdog = cvmx_read_csr(slot->host->base + OCT_MIO_EMM_WDOG);
 	}
 
-	/* Reset the bus */
-	emm_cfg.u64 &= ~0xfull;
-	cvmx_write_csr(slot->host->base + OCT_MIO_EMM_CFG, emm_cfg.u64);
-	msleep(10);  /* Wait 10ms */
-	emm_cfg.u64 |= 1 << slot->bus_id;
-	cvmx_write_csr(slot->host->base + OCT_MIO_EMM_CFG, emm_cfg.u64);
-
-	msleep(10);
-
 	/* Restore switch settings */
 	if (preserve) {
 		emm_switch.s.switch_exe = 0;
@@ -717,13 +704,13 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 
 	octeon_mmc_switch_to(slot);
 
-	pr_debug("Calling set_ios: slot: clk = 0x%x, bus_width = %d\n",
-		 slot->clock, slot->bus_width);
-	pr_debug("Calling set_ios: ios: clk = 0x%x, vdd = %u, bus_width = %u, power_mode = %u, timing = %u\n",
-		 ios->clock, ios->vdd, ios->bus_width, ios->power_mode,
-		 ios->timing);
-	pr_debug("Calling set_ios: mmc: caps = 0x%x, bus_width = %d\n",
-		 mmc->caps, mmc->ios.bus_width);
+	octeon_mmc_dbg("Calling set_ios: slot: clk = 0x%x, bus_width = %d\n",
+		       slot->clock, slot->bus_width);
+	octeon_mmc_dbg("Calling set_ios: ios: clk = 0x%x, vdd = %u, bus_width = %u, power_mode = %u, timing = %u\n",
+		       ios->clock, ios->vdd, ios->bus_width, ios->power_mode,
+		       ios->timing);
+	octeon_mmc_dbg("Calling set_ios: mmc: caps = 0x%x, bus_width = %d\n",
+		       mmc->caps, mmc->ios.bus_width);
 
 	/*
 	 * Reset the chip on each power off
@@ -750,7 +737,7 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		bus_width = 0;
 		break;
 	default:
-		pr_debug("unknown bus width %d\n", ios->bus_width);
+		octeon_mmc_dbg("unknown bus width %d\n", ios->bus_width);
 		bus_width = 0;
 		break;
 	}
@@ -774,16 +761,16 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		emm_switch.s.clk_lo = clk_period;
 
 		if (!octeon_mmc_switch_val_changed(slot, emm_switch.u64)) {
-			pr_debug("No change from 0x%llx mio_emm_switch, returning.\n",
-				 emm_switch.u64);
+			octeon_mmc_dbg("No change from 0x%llx mio_emm_switch, returning.\n",
+				       emm_switch.u64);
 			goto out;
 		}
 
-		pr_debug("Writing 0x%llx to mio_emm_wdog\n",
-			 ((u64)clock * 850ull) / 1000ull);
+		octeon_mmc_dbg("Writing 0x%llx to mio_emm_wdog\n",
+			       ((u64)clock * 850ull) / 1000ull);
 		cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 			       ((u64)clock * 850ull) / 1000ull);
-		pr_debug("Writing 0x%llx to mio_emm_switch\n", emm_switch.u64);
+		octeon_mmc_dbg("Writing 0x%llx to mio_emm_switch\n", emm_switch.u64);
 
 		cvmx_write_csr(host->base + OCT_MIO_EMM_SWITCH, emm_switch.u64);
 		emm_switch.s.bus_id = slot->bus_id;
@@ -798,8 +785,8 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		} while (timeout-- > 0);
 
 		if (timeout <= 0) {
-			pr_debug("%s: switch command timed out, status=0x%llx\n",
-				 __func__, emm_sts.u64);
+			octeon_mmc_dbg("switch command timed out, status=0x%llx\n",
+				       emm_sts.u64);
 			goto out;
 		}
 	}
@@ -879,7 +866,7 @@ static int octeon_mmc_initlowlevel(struct octeon_mmc_slot *slot,
 	cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 		       ((u64)slot->clock * 850ull) / 1000ull);
 	cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0xe4f90080ull);
-
+	cvmx_write_csr(host->base + OCT_MIO_EMM_RCA, 1);
 	return 0;
 }
 
@@ -946,8 +933,8 @@ static int __init octeon_init_slot(struct octeon_mmc_host *host, int id,
 				gpio_free(slot->cd_gpio);
 			return ret;
 		}
-		pr_debug("%s: Shutting off power to slot %d via gpio %d\n",
-			 DRV_NAME, slot->bus_id, slot->pwr_gpio);
+		octeon_mmc_dbg("%s: Shutting off power to slot %d via gpio %d\n",
+			       DRV_NAME, slot->bus_id, slot->pwr_gpio);
 		gpio_direction_output(slot->pwr_gpio,
 				      slot->pwr_gpio_low);
 	}
@@ -964,14 +951,11 @@ static int __init octeon_init_slot(struct octeon_mmc_host *host, int id,
 			 MMC_VDD_30_31 | MMC_VDD_31_32 | MMC_VDD_32_33 |
 			 MMC_VDD_33_34 | MMC_VDD_34_35 | MMC_VDD_35_36;
 
-	mmc->max_segs = 1;
-	mmc->max_seg_size = (1 << 23) - 8;
-	mmc->max_req_size = mmc->max_seg_size;
+	mmc->max_segs = 64;
+	mmc->max_seg_size = host->linear_buf_size;
+	mmc->max_req_size = host->linear_buf_size;
 	mmc->max_blk_size = 512;
 	mmc->max_blk_count = mmc->max_req_size / 512;
-	if (limit_max_blk >= 1)
-		mmc->max_blk_count = min_t(unsigned int, limit_max_blk, mmc->max_blk_count);
-
 
 	slot->clock = mmc->f_min;
 	slot->sclock = octeon_get_io_clock_rate();
@@ -982,6 +966,7 @@ static int __init octeon_init_slot(struct octeon_mmc_host *host, int id,
 
 	slot->bus_width = bus_width;
 	slot->bus_id = id;
+	slot->cached_rca = 1;
 
 	/* Only a single user of the bootbus at a time. */
 	octeon_mmc_acquire_bus();
@@ -994,7 +979,7 @@ static int __init octeon_init_slot(struct octeon_mmc_host *host, int id,
 
 	host->slot[id] = slot;
 	ret = mmc_add_host(mmc);
-	pr_debug("mmc_add_host returned %d\n", ret);
+	octeon_mmc_dbg("mmc_add_host returned %d\n", ret);
 
 	return 0;
 }
@@ -1025,6 +1010,16 @@ static int octeon_mmc_probe(struct platform_device *pdev)
 		goto err;
 	}
 	host->last_slot = -1;
+	if (bb_size > 512 && bb_size < (1 << 24))
+		host->linear_buf_size = bb_size;
+	else
+		host->linear_buf_size = 1 << 18;
+	host->linear_buf = devm_kzalloc(&pdev->dev, host->linear_buf_size, GFP_KERNEL);
+	if (!host->linear_buf) {
+		dev_err(&pdev->dev, "devm_kzalloc failed\n");
+		ret = -ENOMEM;
+		goto err;
+	}
 
 	host->pdev = pdev;
 
@@ -1094,8 +1089,6 @@ static int octeon_mmc_probe(struct platform_device *pdev)
 				      !host->global_pwr_gpio_low);
 	}
 
-	spin_lock_init(&host->lock);
-
 	platform_set_drvdata(pdev, host);
 
 	node = of_get_next_child(pdev->dev.of_node, NULL);
@@ -1151,7 +1144,7 @@ static int octeon_mmc_probe(struct platform_device *pdev)
 			ret = octeon_init_slot(host, slot, bus_width, max_freq,
 					       ro_gpio, cd_gpio, pwr_gpio,
 					       ro_low, cd_low, pwr_low, cmd_skew, dat_skew);
-			pr_debug("init slot %d, ret = %d\n", slot, ret);
+			octeon_mmc_dbg("init slot %d, ret = %d\n", slot, ret);
 			if (ret)
 				goto err;
 		}
@@ -1250,10 +1243,10 @@ static int __init octeon_mmc_init(void)
 {
 	int ret;
 
-	pr_debug("calling octeon_mmc_init\n");
+	octeon_mmc_dbg("calling octeon_mmc_init\n");
 
 	ret = platform_driver_register(&octeon_mmc_driver);
-	pr_debug("driver probe returned %d\n", ret);
+	octeon_mmc_dbg("driver probe returned %d\n", ret);
 
 	if (ret)
 		pr_err("%s: Failed to register driver\n", DRV_NAME);
-- 
2.6.2

