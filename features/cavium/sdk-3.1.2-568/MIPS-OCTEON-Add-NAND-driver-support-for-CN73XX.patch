From 20303a9bb05e93f9551a00cfe97964ce6eb123a4 Mon Sep 17 00:00:00 2001
From: Quanyang Wang <quanyang.wang@windriver.com>
Date: Wed, 6 Apr 2016 09:41:43 +0800
Subject: [PATCH] MIPS: OCTEON: Add NAND driver support for CN73XX

[Original patch taken from patch set 4 for OCTEON SDK 3.1.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/cavium-octeon/executive/cvmx-bch.c  |   29 +++++++++---
 arch/mips/cavium-octeon/executive/cvmx-nand.c |   63 ++++++++++++++++++++++++-
 arch/mips/cavium-octeon/octeon-nand.c         |    2 +-
 arch/mips/include/asm/octeon/octeon-feature.h |    1 +
 4 files changed, 85 insertions(+), 10 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-bch.c b/arch/mips/cavium-octeon/executive/cvmx-bch.c
index 7d7fe64..77531ea 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-bch.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-bch.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2013-2016  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -88,9 +88,9 @@ CVMX_SHARED cvmx_bch_app_config_t bch_config = {
 	.aura = 6
 };
 
+const unsigned bch_buf_count = 16;
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 extern int cvm_oct_alloc_fpa_pool(int pool, int size);
-const unsigned bch_buf_count = 16;
 #endif
 
 /**
@@ -109,17 +109,31 @@ int cvmx_bch_initialize(void)
 
 	/* Initialize FPA pool for BCH pool buffers */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	bch_pool = CVMX_FPA_OUTPUT_BUFFER_POOL;
+	/* Dynamically allocate pool */
+	bch_pool = -1;
 	bch_pool_size = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE;
 	buf_cnt = bch_buf_count;
 
 	debug("pool: %d, pool size: %llu, bufcount %d\n",
 		bch_pool, bch_pool_size, buf_cnt);
 	/* Setup the FPA */
-	if (octeon_has_feature(OCTEON_FEATURE_FPA3))
-		/* FIXME */
+	if (octeon_has_feature(OCTEON_FEATURE_FPA3)) {
+		cvmx_fpa3_pool_t cmd_pool;
+		cvmx_fpa3_gaura_t cmd_aura;
+		struct kmem_cache *cmd_pool_cache;
+		void *cmd_pool_stack;
+		octeon_fpa3_init(0);
+		octeon_fpa3_pool_init(0, bch_pool, &cmd_pool, &cmd_pool_stack, 4096);
+		octeon_fpa3_aura_init(cmd_pool, bch_pool, &cmd_aura, buf_cnt, 20480);
+		bch_pool = cmd_aura.laura;
+		cmd_pool_cache = kmem_cache_create("bch_cmd", bch_pool_size, 128, 0, NULL);
+		if (!cmd_pool_cache) {
+			printk("cvm_oct_alloc_fpa_pool(%d, %lld)\n",
+						bch_pool, bch_pool_size);
 		return -ENOMEM;
-	else
+		}
+		octeon_mem_fill_fpa3(0, cmd_pool_cache, cmd_aura, 128);
+	} else {
 		cvmx_fpa1_enable();
 
 	bch_pool = cvm_oct_alloc_fpa_pool(bch_pool, bch_pool_size);
@@ -131,10 +145,11 @@ int cvmx_bch_initialize(void)
 
 	for (i = 0; i < buf_cnt; i++)
 		cvmx_fpa_free(kmalloc(bch_pool_size, GFP_KERNEL), bch_pool, 0);
+	}
 #else
 	bch_pool = (int)cvmx_fpa_get_bch_pool();
 	bch_pool_size = cvmx_fpa_get_bch_pool_block_size();
-	i = buf_cnt = bch_config.command_queue_pool.buffer_count;
+	i = buf_cnt = bch_buf_count;
 
 	debug("%s: pool: %d, pool size: %llu, buffer count: %llu\n", __func__,
 	      bch_pool, bch_pool_size, buf_cnt);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-nand.c b/arch/mips/cavium-octeon/executive/cvmx-nand.c
index b9f9ce5..03d8403 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-nand.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-nand.c
@@ -681,10 +681,14 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 
 	/* Clear the interrupt state */
 	cvmx_write_csr(CVMX_NDF_INT, cvmx_read_csr(CVMX_NDF_INT));
+	if (OCTEON_IS_MODEL(OCTEON_CN73XX) || OCTEON_IS_MODEL(OCTEON_CNF75XX))
+		cvmx_write_csr(CVMX_NDF_INT_W1S, 0);
+	else {
 	cvmx_write_csr(CVMX_NDF_INT_EN, 0);
 	cvmx_write_csr(CVMX_MIO_NDF_DMA_INT,
 		       cvmx_read_csr(CVMX_MIO_NDF_DMA_INT));
 	cvmx_write_csr(CVMX_MIO_NDF_DMA_INT_EN, 0);
+	}
 
 	/* The simulator crashes if you access non existant devices. Assume
 	   only chip select 1 is connected to NAND */
@@ -1371,13 +1375,29 @@ static inline void __cvmx_nand_setup_dma(int chip, int is_write,
 					 uint64_t buffer_address,
 					 int buffer_length)
 {
-	union cvmx_mio_ndf_dma_cfg ndf_dma_cfg;
 	CVMX_NAND_LOG_CALLED();
 	CVMX_NAND_LOG_PARAM("%d", chip);
 	CVMX_NAND_LOG_PARAM("%d", is_write);
 	CVMX_NAND_LOG_PARAM("0x%llx", CAST_ULL(buffer_address));
 	CVMX_NAND_LOG_PARAM("%d", buffer_length);
 
+	if (OCTEON_IS_MODEL(OCTEON_CN73XX)
+	    || OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		union cvmx_ndf_dma_cfg ndf_dma_cfg;
+		union cvmx_ndf_dma_adr ndf_dma_adr;
+		ndf_dma_cfg.u64 = 0;
+		ndf_dma_cfg.s.en = 1;
+		/* is_write - one means DMA reads from memory and writes to flash */
+		ndf_dma_cfg.s.rw = is_write;
+		ndf_dma_cfg.s.clr = 0;
+		ndf_dma_cfg.s.size = ((buffer_length + 7) >> 3) - 1;
+		ndf_dma_adr.u64 = 0;
+		ndf_dma_adr.s.adr = (buffer_address >> 3);
+		CVMX_SYNCWS;
+		cvmx_write_csr(CVMX_NDF_DMA_ADR, ndf_dma_adr.u64);
+		cvmx_write_csr(CVMX_NDF_DMA_CFG, ndf_dma_cfg.u64);
+	} else {
+		union cvmx_mio_ndf_dma_cfg ndf_dma_cfg;
 	ndf_dma_cfg.u64 = 0;
 	ndf_dma_cfg.s.en = 1;
 	/* is_write - one means DMA reads from memory and writes to flash */
@@ -1387,6 +1407,7 @@ static inline void __cvmx_nand_setup_dma(int chip, int is_write,
 	ndf_dma_cfg.s.adr = buffer_address;
 	CVMX_SYNCWS;
 	cvmx_write_csr(CVMX_MIO_NDF_DMA_CFG, ndf_dma_cfg.u64);
+	}
 
 	CVMX_NAND_RETURN_NOTHING();
 }
@@ -1448,7 +1469,6 @@ static inline int __cvmx_nand_low_level_read(int chip,
 					     int buffer_length)
 {
 	cvmx_nand_cmd_t cmd;
-	union cvmx_mio_ndf_dma_cfg ndf_dma_cfg;
 	int bytes;
 	int nand_selected;
 	int status = CVMX_NAND_ERROR;
@@ -1529,6 +1549,22 @@ static inline int __cvmx_nand_low_level_read(int chip,
 
 	WATCHDOG_RESET();
 
+	if (OCTEON_IS_MODEL(OCTEON_CN73XX)
+	    || OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		union cvmx_ndf_dma_adr ndf_dma_adr;
+		/* Wait for the DMA to complete */
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_NDF_DMA_CFG,
+				  union cvmx_ndf_dma_cfg,
+				  en, ==, 0, NAND_TIMEOUT_USECS_READ)) {
+			WATCHDOG_RESET();
+			status = CVMX_NAND_TIMEOUT;
+			goto error;
+		}
+		/* Return the number of bytes transfered */
+		ndf_dma_adr.u64 = cvmx_read_csr(CVMX_NDF_DMA_ADR);
+		bytes = (ndf_dma_adr.s.adr << 3) - buffer_address;
+	} else {
+		union cvmx_mio_ndf_dma_cfg ndf_dma_cfg;
 	/* Wait for the DMA to complete */
 	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_NDF_DMA_CFG,
 				  union cvmx_mio_ndf_dma_cfg,
@@ -1540,6 +1576,7 @@ static inline int __cvmx_nand_low_level_read(int chip,
 	/* Return the number of bytes transfered */
 	ndf_dma_cfg.u64 = cvmx_read_csr(CVMX_MIO_NDF_DMA_CFG);
 	bytes = ndf_dma_cfg.s.adr - buffer_address;
+	}
 
 	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
 		__cvmx_nand_hex_dump(buffer_address, bytes);
@@ -1760,6 +1797,16 @@ cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
 
 	/* Wait for the DMA to complete */
 	WATCHDOG_RESET();
+	if (OCTEON_IS_MODEL(OCTEON_CN73XX)
+	    || OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_NDF_DMA_CFG,
+				  union cvmx_ndf_dma_cfg, en, ==, 0,
+				  NAND_TIMEOUT_USECS_WRITE)) {
+			WATCHDOG_RESET();
+			status = CVMX_NAND_TIMEOUT;
+			goto done;
+		}
+	} else {
 	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_NDF_DMA_CFG,
 				  union cvmx_mio_ndf_dma_cfg, en, ==, 0,
 				  NAND_TIMEOUT_USECS_WRITE)) {
@@ -1767,6 +1814,7 @@ cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
 		status = CVMX_NAND_TIMEOUT;
 		goto done;
 	}
+	}
 		
 	/* Data transfer is done but NDF is not, it is waiting for R/B# */
 	WATCHDOG_RESET();
@@ -2063,6 +2111,16 @@ cvmx_nand_status_t cvmx_nand_set_feature(int chip, uint8_t feat_num,
 	if (status)
 		goto done;
 
+	if (OCTEON_IS_MODEL(OCTEON_CN73XX)
+	    || OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_NDF_DMA_CFG,
+				  union cvmx_ndf_dma_cfg, en, ==, 0,
+				  NAND_TIMEOUT_USECS_WRITE)) {
+			WATCHDOG_RESET();
+			status = CVMX_NAND_TIMEOUT;
+			goto done;
+		}
+	} else {
 	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_NDF_DMA_CFG,
 				  union cvmx_mio_ndf_dma_cfg, en, ==, 0,
 				  NAND_TIMEOUT_USECS_WRITE)) {
@@ -2070,6 +2128,7 @@ cvmx_nand_status_t cvmx_nand_set_feature(int chip, uint8_t feat_num,
 		status = CVMX_NAND_TIMEOUT;
 		goto done;
 	}
+	}
 done:
 	__cvmx_nand_select(nand_selected);
 	CVMX_NAND_RETURN(status);
diff --git a/arch/mips/cavium-octeon/octeon-nand.c b/arch/mips/cavium-octeon/octeon-nand.c
index 4dbddf8..262d785 100644
--- a/arch/mips/cavium-octeon/octeon-nand.c
+++ b/arch/mips/cavium-octeon/octeon-nand.c
@@ -1176,7 +1176,7 @@ static int octeon_nand_hw_bch_init(struct octeon_nand *priv)
 	uint8_t erased_ecc[eccbytes];
 
 	/* Without HW BCH, the ECC callbacks would have not been installed */
-	if (!octeon_has_feature(OCTEON_FEATURE_BCH))
+	if (priv->nand.ecc.mode != NAND_ECC_HW_SYNDROME)
 		return 0;
 
 	priv->eccmask = NULL;
diff --git a/arch/mips/include/asm/octeon/octeon-feature.h b/arch/mips/include/asm/octeon/octeon-feature.h
index e887822..4af9292 100644
--- a/arch/mips/include/asm/octeon/octeon-feature.h
+++ b/arch/mips/include/asm/octeon/octeon-feature.h
@@ -400,6 +400,7 @@ static inline int octeon_has_feature_OCTEON_FEATURE_NAND(void)
 		|| OCTEON_IS_MODEL(OCTEON_CN63XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN66XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN68XX)
+		|| OCTEON_IS_MODEL(OCTEON_CN73XX)
 		|| OCTEON_IS_MODEL(OCTEON_CNF75XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN70XX));
 }
-- 
1.7.5.4

