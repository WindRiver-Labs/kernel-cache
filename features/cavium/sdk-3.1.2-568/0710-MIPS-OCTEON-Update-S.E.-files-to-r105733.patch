From 0d499f8c90e0479ec9e8358175d29ac08a0b4a51 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Wed, 9 Jul 2014 18:05:50 -0700
Subject: [PATCH 710/974] MIPS: OCTEON: Update S.E. files to r105733

Signed-off-by: David Daney <david.daney@cavium.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 .../executive/cvmx-appcfg-transport.c              |  12 +
 .../executive/cvmx-global-resources.c              |  20 +-
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c | 104 ++---
 .../cavium-octeon/executive/cvmx-helper-board.c    | 146 +++----
 .../mips/cavium-octeon/executive/cvmx-helper-cfg.c |  11 +-
 .../cavium-octeon/executive/cvmx-helper-sgmii.c    |   6 +-
 .../cavium-octeon/executive/cvmx-helper-util.c     |  63 +--
 .../cavium-octeon/executive/cvmx-helper-xaui.c     |   6 +-
 arch/mips/cavium-octeon/executive/cvmx-l2c.c       |  21 +-
 arch/mips/cavium-octeon/executive/cvmx-pcie.c      | 422 +++++++++++----------
 .../mips/cavium-octeon/executive/cvmx-pko3-queue.c |   6 +
 arch/mips/cavium-octeon/executive/cvmx-pko3.c      |  31 +-
 arch/mips/cavium-octeon/executive/cvmx-qlm.c       |   4 +-
 arch/mips/cavium-octeon/executive/octeon-model.c   |  22 +-
 arch/mips/include/asm/octeon/cvmx-app-config.h     |   2 +
 arch/mips/include/asm/octeon/cvmx-app-init.h       |  16 +-
 arch/mips/include/asm/octeon/cvmx-l2c.h            |  31 +-
 arch/mips/include/asm/octeon/cvmx-pcie.h           |  20 +-
 arch/mips/include/asm/octeon/cvmx-pki-cluster.h    |   2 +-
 arch/mips/include/asm/octeon/cvmx-wqe.h            |  30 +-
 20 files changed, 553 insertions(+), 422 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-appcfg-transport.c b/arch/mips/cavium-octeon/executive/cvmx-appcfg-transport.c
index 3b14fc6..b8f1e32 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-appcfg-transport.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-appcfg-transport.c
@@ -332,6 +332,18 @@ void __cvmx_export_app_config_cleanup(void)
 EXPORT_SYMBOL(__cvmx_export_app_config_cleanup);
 
 /**
+ * Called by kernel modules to update appconfig
+ * @return 0 if export successful, -1 on failure
+ */
+int __cvmx_export_config(void)
+{
+	if (cvmx_export_app_config)
+		return (*cvmx_export_app_config)();
+	return -1;
+}
+EXPORT_SYMBOL(__cvmx_export_config);
+
+/**
  * @INTERNAL
  * Imports fpa config using named block.
  *
diff --git a/arch/mips/cavium-octeon/executive/cvmx-global-resources.c b/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
index 65f5581..7d3f0f6 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
@@ -254,7 +254,8 @@ static uint64_t __cvmx_global_resources_init(void)
 							      CVMX_GLOBAL_RESOURCES_DATA_NAME,
 							      CVMX_BOOTMEM_FLAG_NO_LOCKING);
 		if (tmp_phys < 0) {
-			cvmx_dprintf("ERROR : failed to allocate global resource name block. sz=%d \n", sz);
+			cvmx_printf("ERROR: %s: failed to allocate global resource name block. sz=%d\n",
+				__func__, sz);
 			goto end;
 		}
 		__cvmx_global_resources_addr = (uint64_t) tmp_phys;
@@ -346,7 +347,11 @@ uint64_t cvmx_create_global_resource(struct global_resource_tag tag, uint64_t si
 	*new = 1;
 	entry_count = CVMX_GLOBAL_RESOURCES_GET_FIELD(entry_cnt);
 	if (entry_count >= CVMX_MAX_GLOBAL_RESOURCES) {
-		cvmx_dprintf("ERROR: reached max global resources limit\n");
+		char tagname[MAX_RESOURCE_TAG_LEN+1];
+
+		__cvmx_get_tagname(&tag, tagname);
+		cvmx_printf("ERROR: %s: reached global resources limit for %s\n",
+			__func__, tagname);
 		phys_addr = 0;
 		goto end;
 	}
@@ -354,7 +359,11 @@ uint64_t cvmx_create_global_resource(struct global_resource_tag tag, uint64_t si
         /* Allocate bootmem for the resource*/
 	phys_addr = __cvmx_alloc_bootmem_for_global_resources(size);
 	if (!phys_addr) {
-		cvmx_dprintf("ERROR: unable to bootmem size=%d \n", (int) size);
+		char tagname[MAX_RESOURCE_TAG_LEN+1];
+
+		__cvmx_get_tagname(&tag, tagname);
+		cvmx_dprintf("ERROR: %s: out of memory %s, size=%d\n",
+			__func__, tagname, (int) size);
 		goto end;
 	}
 
@@ -407,7 +416,8 @@ int cvmx_allocate_global_resource_range(struct global_resource_tag tag, uint64_t
 	if (addr == 0) {
 		char tagname[256];
 		__cvmx_get_tagname(&tag, tagname);
-		cvmx_dprintf("ERROR: cannot find resource %s\n", tagname);
+		cvmx_printf("ERROR: %s: cannot find resource %s\n", 
+			__func__, tagname);
 		return -1;
 	}
 	__cvmx_global_resource_lock();
@@ -570,8 +580,6 @@ void cvmx_global_resources_show(void)
 	entry_cnt = CVMX_GLOBAL_RESOURCES_GET_FIELD(entry_cnt);
 	memset (tagname, 0, MAX_RESOURCE_TAG_LEN + 1);
 
-	if (dbg)
-		cvmx_dprintf("%s: cvmx-global-resources: \n", __func__);
 	for (count = 0; count < entry_cnt; count++) {
 		p = CVMX_GET_RESOURCE_ENTRY(count);
 		phys_addr = CVMX_RESOURCE_ENTRY_GET_FIELD(p, phys_addr);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
index 5e27fe9..b1b6694 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -129,14 +129,13 @@ void cvmx_helper_bgx_disable(int xipd_port)
  *
  * @param mode      Mode to configure the bgx mac as
  */
-static void __cvmx_helper_bgx_common_init(int xiface)
+static void __cvmx_bgx_common_init(int xiface, int index)
 {
 	cvmx_bgxx_cmrx_config_t	cmr_config;
 	cvmx_bgxx_cmr_rx_lmacs_t bgx_cmr_rx_lmacs;
 	cvmx_bgxx_cmr_tx_lmacs_t bgx_cmr_tx_lmacs;
 	cvmx_helper_interface_mode_t mode;
 	int num_ports;
-	int index;
 	int lmac_type = 0;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
@@ -173,27 +172,26 @@ static void __cvmx_helper_bgx_common_init(int xiface)
 	}
 
 	/* Set mode and lanes for all interface ports */
-	for (index = 0; index < num_ports; index++) {
-		cmr_config.u64 =
-			cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
-		cmr_config.s.enable = 0;
-		cmr_config.s.data_pkt_tx_en = 0;
-		cmr_config.s.data_pkt_rx_en = 0;
-		cmr_config.s.lmac_type = lmac_type;
-		cmr_config.s.lane_to_sds = ((lane_to_sds == 1) ? index
-					     : ((lane_to_sds == 0)
-						 ? (index ? 0xe : 4) : lane_to_sds));
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
-	}
-
-	bgx_cmr_rx_lmacs.u64 = 0;
-	bgx_cmr_rx_lmacs.s.lmacs = num_ports;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_LMACS(interface), bgx_cmr_rx_lmacs.u64);
+	cmr_config.u64 =
+		cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.s.enable = 0;
+	cmr_config.s.data_pkt_tx_en = 0;
+	cmr_config.s.data_pkt_rx_en = 0;
+	cmr_config.s.lmac_type = lmac_type;
+	cmr_config.s.lane_to_sds = ((lane_to_sds == 1) ? index
+				: ((lane_to_sds == 0)
+				? (index ? 0xe : 4) : lane_to_sds));
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
-	bgx_cmr_tx_lmacs.u64 = 0;
-	bgx_cmr_tx_lmacs.s.lmacs = num_ports;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMR_TX_LMACS(interface), bgx_cmr_tx_lmacs.u64);
+	if (index == 0) {
+		bgx_cmr_rx_lmacs.u64 = 0;
+		bgx_cmr_rx_lmacs.s.lmacs = num_ports;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_LMACS(interface), bgx_cmr_rx_lmacs.u64);
 
+		bgx_cmr_tx_lmacs.u64 = 0;
+		bgx_cmr_tx_lmacs.s.lmacs = num_ports;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMR_TX_LMACS(interface), bgx_cmr_tx_lmacs.u64);
+	}
 }
 
 static void __cvmx_bgx_common_init_pknd(int xiface, int index)
@@ -244,7 +242,11 @@ static void __cvmx_bgx_common_init_pknd(int xiface, int index)
  */
 int __cvmx_helper_bgx_probe(int xiface)
 {
-	__cvmx_helper_bgx_common_init(xiface);
+	int num_ports = cvmx_helper_ports_on_interface(xiface);
+	int index;
+
+	for (index = 0; index < num_ports; index++)
+		__cvmx_bgx_common_init(xiface, index);
 	return __cvmx_helper_bgx_enumerate(xiface);
 }
 EXPORT_SYMBOL(__cvmx_helper_bgx_probe);
@@ -581,8 +583,10 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int xiface,
 	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X) || index)
 		cmr_config.s.enable = is_enabled;
+#ifndef CVMX_BUILD_FOR_UBOOT
 	cmr_config.s.data_pkt_tx_en = 1;
 	cmr_config.s.data_pkt_rx_en = 1;
+#endif
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
 	return 0;
@@ -869,6 +873,10 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface), spu_br_pmd_control.u64);
 
 		}
+	} else { /* enable for simulator */
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+		cmr_config.s.enable = 1;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 	}
 
 	/* 4d. Program all other relevant BGX configuration while
@@ -957,46 +965,9 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 	int interface = xi.interface;
 	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
-	int lmac_type = 0;
-	int lane_to_sds = 0;
 	cvmx_helper_interface_mode_t mode;
-	cvmx_bgxx_cmrx_config_t cmr_config;
 
 	mode = cvmx_helper_interface_get_mode(xiface);
-	switch (mode) {
-	case CVMX_HELPER_INTERFACE_MODE_SGMII:
-		lmac_type = 0;
-		lane_to_sds = 1;
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_XAUI:
-		lmac_type = 1;
-		lane_to_sds = 0xe4;
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-		lmac_type = 2;
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_XFI:
-	case CVMX_HELPER_INTERFACE_MODE_10G_KR:
-		lmac_type = 3;
-		lane_to_sds = 1;
-		break;
-	case CVMX_HELPER_INTERFACE_MODE_XLAUI:
-	case CVMX_HELPER_INTERFACE_MODE_40G_KR4:
-		lmac_type = 4;
-		lane_to_sds = 0xe4;
-		break;
-	default:
-		break;
-	}
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
-	cmr_config.s.enable = 0;
-	cmr_config.s.data_pkt_tx_en = 0;
-	cmr_config.s.data_pkt_rx_en = 0;
-	cmr_config.s.lmac_type = lmac_type;
-	cmr_config.s.lane_to_sds = ((lane_to_sds == 1) ? index
-	: ((lane_to_sds == 0)
-			? (index ? 0xe : 4) : lane_to_sds));
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
 	__cvmx_bgx_common_init_pknd(xiface, index);
 
@@ -1010,7 +981,7 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 		gmi_tx_thresh.s.cnt = 0x20;
 		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_THRESH(index, interface),
 				    gmi_tx_thresh.u64);
-		__cvmx_helper_bgx_sgmii_hardware_init_one_time(interface, index);
+		__cvmx_helper_bgx_sgmii_hardware_init_one_time(xiface, index);
 		gmp_txx_append.u64 = cvmx_read_csr_node(node,
 					CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface));
 		gmp_sgmii_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface));
@@ -1022,6 +993,12 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 		int res;
 		cvmx_bgxx_smux_tx_thresh_t smu_tx_thresh;
 
+		res = __cvmx_helper_bgx_xaui_init(index, xiface);
+		if (res == -1) {
+			cvmx_dprintf("Failed to enable XAUI for %d:BGX(%d,%d)\n", node, interface, index);
+			return res;
+		}
+
 		smu_tx_thresh.u64 = 0;
 		/* Hopefully big enough to avoid underrun, but not too
 		* big to adversly effect shaping.
@@ -1039,11 +1016,6 @@ int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
 			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface),
 					    misc_control.u64);
 		}
-		res = __cvmx_helper_bgx_xaui_init(index, xiface);
-		if (res == -1) {
-			cvmx_dprintf("Failed to enable XAUI for %d:BGX(%d,%d)\n", node, interface, index);
-			return res;
-		}
 	}
 	return 0;
 }
@@ -1261,7 +1233,7 @@ int __cvmx_helper_bgx_xaui_enable(int xiface)
 		int phy_pres;
 
 		/* Set disparity for RXAUI interface as described in the
-		Marvell RXAUI Interface specification. */
+		   Marvell RXAUI Interface specification. */
 		if (mode == CVMX_HELPER_INTERFACE_MODE_RXAUI &&
 				  (cvmx_helper_get_port_phy_present(xiface, index)))
 			phy_pres = 1;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
index 3efa293..daa365e 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
@@ -90,7 +90,7 @@
 CVMX_SHARED cvmx_helper_link_info_t(*cvmx_override_board_link_get)(int ipd_port) = NULL;
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-
+/** Set this to 1 to enable lots of debugging output */
 static const int device_tree_dbg = 0;
 #endif
 
@@ -195,7 +195,8 @@ int __pip_eth_node(const void *fdt_addr, int aliases, int ipd_port)
 	}
 	pip = fdt_path_offset(fdt_addr, pip_path);
 	if (dbg)
-		cvmx_dprintf("ipdd_port=%d pip_path=%s pip=%d ", ipd_port, pip_path, pip);
+		cvmx_dprintf("ipdd_port=%d pip_path=%s pip=%d ",
+			     ipd_port, pip_path, pip);
 	if (pip < 0) {
 		cvmx_dprintf("ERROR: pip not found in device tree\n");
 		if (dbg)
@@ -272,51 +273,38 @@ static int __get_muxed_mdio_info_from_dt(cvmx_phy_info_t *phy_info,
 					 int mdio_offset, int mux_offset)
 {
 	static void *fdt_addr = 0;
-	uint32_t *psmi_handle;
 	int phandle;
-	uint32_t *pgpio_handle;
 	int smi_offset;
 	int gpio_offset;
-	uint64_t *smi_addrp;
 	uint64_t smi_addr = 0;
 	int len;
+	uint32_t *pgpio_handle;
 	int gpio_count = 0;
 	uint32_t *prop_val;
 	int offset;
 	const char *prop_name;
 
+	if (device_tree_dbg)
+		cvmx_dprintf("%s(%p, 0x%x, 0x%x)\n", __func__, phy_info,
+			     mdio_offset, mux_offset);
 	if (fdt_addr == 0)
 		fdt_addr = __cvmx_phys_addr_to_ptr(cvmx_sysinfo_get()->fdt_addr,
 						   OCTEON_FDT_MAX_SIZE);
 
-	prop_val = (uint32_t *)fdt_getprop(fdt_addr, mdio_offset, "reg", NULL);
-	if (!prop_val) {
-		cvmx_dprintf("Could not get register value for muxed MDIO bus from DT\n");
-		return -1;
-	}
 	/* Get register value to put onto the GPIO lines to select */
-	phy_info->gpio_value = fdt32_to_cpu(*prop_val);
-
-	psmi_handle = (uint32_t *)fdt_getprop(fdt_addr, mux_offset,
-					      "mdio-parent-bus", NULL);
-	if (psmi_handle == NULL) {
-		cvmx_dprintf("Could not get MDIO parent bus for multiplexed bus from device tree\n");
+	phy_info->gpio_value = cvmx_fdt_get_int(fdt_addr, mdio_offset, "reg", -1);
+	if (phy_info->gpio_value < 0) {
+		cvmx_dprintf("Could not get register value for muxed MDIO bus from DT\n");
 		return -1;
 	}
 
-	phandle = fdt32_to_cpu(*psmi_handle);
-	smi_offset = fdt_node_offset_by_phandle(fdt_addr, phandle);
+	smi_offset = cvmx_fdt_lookup_phandle(fdt_addr, mux_offset,
+					   "mdio-parent-bus");
 	if (smi_offset < 0) {
 		cvmx_dprintf("Invalid SMI offset for muxed MDIO interface in device tree\n");
 		return -1;
 	}
-	smi_addrp = (uint64_t *)fdt_getprop(fdt_addr, smi_offset, "reg", &len);
-	if ((len < (int)sizeof(uint64_t)) || smi_addrp == NULL) {
-		cvmx_dprintf("Could not get register information for SMI interface from DT\n");
-		return -1;
-	}
-	memcpy(&smi_addr, smi_addrp, sizeof(uint64_t));
-	smi_addr = fdt64_to_cpu(smi_addr);
+	smi_addr = cvmx_fdt_get_uint64(fdt_addr, smi_offset, "reg", 0);
 
 	/* Convert SMI address to a MDIO interface */
 	switch (smi_addr) {
@@ -510,7 +498,7 @@ static int __cvmx_helper_dt_process_mdio_mux(void *fdt_addr, int mdio_offset,
 	}
 	mux_info->direct_connect = 0;
 
-	smi_offset = cvmx_fdt_lookup_phandle(fdt_addr, mux_offset,
+	smi_offset = (fdt_addr, mux_offset,
 					     "mdio-parent-bus");
 	if (smi_offset < 0) {
 		cvmx_printf("Could not get parent mdio bus\n");
@@ -972,20 +960,15 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 {
 	static void *fdt_addr = 0;
-	uint32_t *phy_handle;
-	int aliases, eth, phy, phy_parent, phandle, ret, len, i;
+	int aliases, eth, phy, phy_parent, ret, i;
 	int mdio_parent;
 	const char *phy_compatible_str;
 	const char *host_mode_str = NULL;
-	uint32_t *phy_addr_ptr;
-	uint32_t *psmi_handle;
-	int smi_offset;
-	uint64_t *smi_addrp;
-	uint64_t smi_addr = 0;
 	int dbg = device_tree_dbg;
 	int interface;
+	int phy_addr_offset = 0;
 
-	if (device_tree_dbg)
+	if (dbg)
 		cvmx_dprintf("%s(%p, %d)\n", __func__, phy_info, ipd_port);
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
@@ -995,8 +978,6 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 		fdt_addr = __cvmx_phys_addr_to_ptr(cvmx_sysinfo_get()->fdt_addr,
 						   OCTEON_FDT_MAX_SIZE);
 
-	if (device_tree_dbg)
-		cvmx_dprintf("%s(%p, %d)\n", __func__, phy_info, ipd_port);
 	phy_info->phy_addr = -1;
 	phy_info->phy_sub_addr = 0;
 	phy_info->ipd_port = ipd_port;
@@ -1034,12 +1015,15 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 
 	interface = cvmx_helper_get_interface_num(ipd_port);
 	/* Get handle to phy */
-	phy_handle = (uint32_t *) fdt_getprop(fdt_addr, eth, "phy-handle", NULL);
-	if (!phy_handle) {
+	phy = cvmx_fdt_lookup_phandle(fdt_addr, eth, "phy-handle");
+	if (phy < 0) {
 		cvmx_helper_interface_mode_t if_mode;
 		/* Note that it's OK for RXAUI and ILK to not have a PHY
 		 * connected (i.e. EBB boards in loopback).
 		 */
+		if (dbg)
+			cvmx_dprintf("Cannot get phy-handle for ipd_port: %d\n",
+				     ipd_port);
 		if_mode = cvmx_helper_interface_get_mode(interface);
 		if (if_mode != CVMX_HELPER_INTERFACE_MODE_RXAUI &&
 		    if_mode != CVMX_HELPER_INTERFACE_MODE_ILK) {
@@ -1051,13 +1035,6 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 			return -2;
 		}
 	}
-	phandle = fdt32_to_cpu(*phy_handle);
-	phy = fdt_node_offset_by_phandle(fdt_addr, phandle);
-	if (phy < 0) {
-		cvmx_dprintf("ERROR : cannot find phy for ipd_port=%d ret=%d\n",
-			     ipd_port, phy);
-		return -1;
-	}
 
 	phy_compatible_str = (const char *)fdt_getprop(fdt_addr, phy,
 						       "compatible", NULL);
@@ -1065,11 +1042,11 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 		cvmx_dprintf("ERROR: no compatible prop in phy\n");
 		return -1;
 	}
-	if (device_tree_dbg)
+	if (dbg)
 		cvmx_dprintf("Checking compatible string \"%s\" for ipd port %d\n",
 			     phy_compatible_str, ipd_port);
 	if (!memcmp("marvell", phy_compatible_str, strlen("marvell"))) {
-		if (device_tree_dbg)
+		if (dbg)
 			cvmx_dprintf("Marvell PHY detected for ipd_port %d\n",
 				     ipd_port);
 		phy_info->phy_type = MARVELL_GENERIC_PHY;
@@ -1077,25 +1054,25 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 	} else if (!memcmp("broadcom", phy_compatible_str, strlen("broadcom"))) {
 		phy_info->phy_type = BROADCOM_GENERIC_PHY;
 		phy_info->link_function = __get_broadcom_phy_link_state;
-		if (device_tree_dbg)
+		if (dbg)
 			cvmx_dprintf("Broadcom PHY detected for ipd_port %d\n",
 				     ipd_port);
 	} else if (!memcmp("vitesse", phy_compatible_str, strlen("vitesse"))) {
-		if (device_tree_dbg)
+		if (dbg)
 			cvmx_dprintf("Vitesse PHY detected for ipd_port %d\n",
 				     ipd_port);
 		if (!fdt_node_check_compatible(fdt_addr, phy,
 					       "ethernet-phy-ieee802.3-c22")) {
 			phy_info->phy_type = GENERIC_8023_C22_PHY;
 			phy_info->link_function =
-					__get_generic_8023_c45_phy_link_state;
-			if (device_tree_dbg)
+					__cvmx_get_generic_8023_c22_phy_link_state;
+			if (dbg)
 				cvmx_dprintf("Vitesse 802.3 c22 detected\n");
 		} else {
 			phy_info->phy_type = GENERIC_8023_C45_PHY;
 			phy_info->link_function =
-				__cvmx_get_generic_8023_c22_phy_link_state;
-			if (device_tree_dbg)
+				__get_generic_8023_c45_phy_link_state;
+			if (dbg)
 				cvmx_dprintf("Vitesse 802.3 c45 detected\n");
 		}
 	} else if (!memcmp("cortina", phy_compatible_str, strlen("cortina"))) {
@@ -1104,13 +1081,13 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 		host_mode_str = (const char *)fdt_getprop(fdt_addr, phy,
 							  "cortina,host-mode",
 							  NULL);
-		if (device_tree_dbg)
+		if (dbg)
 			cvmx_dprintf("Cortina PHY detected for ipd_port %d\n",
 				     ipd_port);
 	} else if (!memcmp("ti", phy_compatible_str, strlen("ti"))) {
 		phy_info->phy_type = GENERIC_8023_C45_PHY;
 		phy_info->link_function = __get_generic_8023_c45_phy_link_state;
-		if (device_tree_dbg)
+		if (dbg)
 			cvmx_dprintf("TI PHY detected for ipd_port %d\n",
 				     ipd_port);
 	} else if (!fdt_node_check_compatible(fdt_addr, phy, "atheros,ar8334") ||
@@ -1119,20 +1096,20 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 		   !fdt_node_check_compatible(fdt_addr, phy, "qualcomm,qca8337")) {
 		phy_info->phy_type = QUALCOMM_S17;
 		phy_info->link_function = __cvmx_get_qualcomm_s17_phy_link_state;
-		if (device_tree_dbg)
+		if (dbg)
 			cvmx_dprintf("Qualcomm QCA833X switch detected\n");
 	} else if (!fdt_node_check_compatible(fdt_addr, phy,
 					      "ethernet-phy-ieee802.3-c22")) {
 		phy_info->phy_type = GENERIC_8023_C22_PHY;
 		phy_info->link_function =
 				__cvmx_get_generic_8023_c22_phy_link_state;
-		if (device_tree_dbg)
+		if (dbg)
 			cvmx_dprintf("Generic 802.3 c22 PHY detected\n");
 	} else if (!fdt_node_check_compatible(fdt_addr, phy,
 					      "ethernet-phy-ieee802.3-c45")) {
 		phy_info->phy_type = GENERIC_8023_C45_PHY;
 		phy_info->link_function = __get_generic_8023_c45_phy_link_state;
-		if (device_tree_dbg)
+		if (dbg)
 			cvmx_dprintf("Generic 802.3 c45 PHY detected\n");
 	} else {
 		cvmx_dprintf("Unknown PHY compatibility\n");
@@ -1166,8 +1143,12 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 	/* For multi-phy devices and devices on a MUX, go to the parent */
 	ret = fdt_node_check_compatible(fdt_addr, phy_parent,
 					"ethernet-phy-nexus");
-	if (ret == 0)
+	if (ret == 0) {
+		/* It's a nexus so check the grandparent. */
+		phy_addr_offset = cvmx_fdt_get_int(fdt_addr, phy_parent,
+						 "reg", 0);
 		phy_parent = fdt_parent_offset(fdt_addr, phy_parent);
+	}
 
 	/* Check for a muxed MDIO interface */
 	mdio_parent = fdt_parent_offset(fdt_addr, phy_parent);
@@ -1176,36 +1157,18 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 	if (ret == 0) {
 		ret = __get_muxed_mdio_info_from_dt(phy_info, phy_parent,
 						    mdio_parent);
-		/* Find the parent MDIO bus */
-		psmi_handle = (uint32_t *)fdt_getprop(fdt_addr, mdio_parent,
-						      "mdio-parent-bus", NULL);
-		if (psmi_handle) {
-			phandle = fdt32_to_cpu(*psmi_handle);
-			smi_offset = fdt_node_offset_by_phandle(fdt_addr,
-								phandle);
-			if (smi_offset > 0) {
-				smi_addrp = (uint64_t *)fdt_getprop(fdt_addr,
-								    smi_offset,
-								    "reg",
-								    &len);
-				if (smi_addrp != NULL && len > 8) {
-					memcpy(&smi_addr, smi_addrp,
-					       sizeof(uint64_t));
-					smi_addr = fdt64_to_cpu(smi_addr);
-				}
-			} else {
-				cvmx_dprintf("Could not find SMI handler for mux\n");
-			}
-		} else {
-			cvmx_dprintf("%s: Could not get parent mdio bus\n",
-				     __func__);
+		if (ret) {
+			printf("Error reading mdio mux information for ipd port %d\n",
+			       ipd_port);
+			return -1;
 		}
-		/* Find the GPIO MUX controller */
 	}
 	ret = fdt_node_check_compatible(fdt_addr, phy_parent,
 					"cavium,octeon-3860-mdio");
 	if (ret == 0) {
-		uint32_t *mdio_reg_base = (uint32_t *) fdt_getprop(fdt_addr, phy_parent, "reg", 0);
+		uint32_t *mdio_reg_base = (uint32_t *) fdt_getprop(fdt_addr,
+								   phy_parent,
+								   "reg", 0);
 		phy_info->direct_connect = 1;
 		if (mdio_reg_base == 0) {
 			cvmx_dprintf("ERROR : unable to get reg property in phy mdio\n");
@@ -1230,13 +1193,16 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 				      __func__, phy_info->phy_addr);
 	}
 
-	phy_addr_ptr = (uint32_t *) fdt_getprop(fdt_addr, phy, "reg", NULL);
-	if (!phy_addr_ptr) {
+	phy_info->phy_addr = cvmx_fdt_get_int(fdt_addr, phy, "reg", -1);
+	if (phy_info->phy_addr < 0) {
 		cvmx_dprintf("ERROR: Could not read phy address from reg in DT\n");
 		return -1;
 	}
-	phy_info->phy_addr = fdt32_to_cpu(*phy_addr_ptr) |
-				phy_info->mdio_unit << 8;
+	phy_info->phy_addr += phy_addr_offset;
+	phy_info->phy_addr |= phy_info->mdio_unit << 8;
+	if (dbg)
+		cvmx_dprintf("%s(%p, %d) => 0x%x\n", __func__,
+			     phy_info, ipd_port, phy_info->phy_addr);
 	return phy_info->phy_addr;
 }
 
@@ -2113,6 +2079,7 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 			case CVMX_HELPER_INTERFACE_MODE_GMII:
 			case CVMX_HELPER_INTERFACE_MODE_SGMII:
 			case CVMX_HELPER_INTERFACE_MODE_QSGMII:
+			case CVMX_HELPER_INTERFACE_MODE_AGL:
 			case CVMX_HELPER_INTERFACE_MODE_SPI:
 				result.s.speed = 1000;
 				break;
@@ -2122,6 +2089,7 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 				result.s.speed = 10000;
 				break;
 			case CVMX_HELPER_INTERFACE_MODE_XFI:
+			case CVMX_HELPER_INTERFACE_MODE_XLAUI:
 			case CVMX_HELPER_INTERFACE_MODE_40G_KR4:
 				result.s.speed = 40000;
 				break;
@@ -2771,7 +2739,6 @@ cvmx_helper_board_usb_clock_types_t __cvmx_helper_board_usb_get_clock_type(void)
 		return USB_CLOCK_TYPE_CRYSTAL_12;
 	return USB_CLOCK_TYPE_REF_48;
 }
-EXPORT_SYMBOL(__cvmx_helper_board_usb_get_clock_type);
 
 /**
  * @INTERNAL
@@ -2799,4 +2766,3 @@ int __cvmx_helper_board_usb_get_num_ports(int supported_ports)
 
 	return supported_ports;
 }
-EXPORT_SYMBOL(__cvmx_helper_board_usb_get_num_ports);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
index 4832c43..a1cc29e 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
@@ -472,8 +472,10 @@ void cvmx_helper_cfg_init_pko_port_map(void)
 		for (j = 0; j < cvmx_helper_interface_enumerate(i); j++) {
 			pko_port_base = cvmx_cfg_port[0][i][j].ccpp_pko_port_base;
 			pko_port_max = pko_port_base + cvmx_cfg_port[0][i][j].ccpp_pko_num_ports;
-			cvmx_helper_cfg_assert(pko_port_base != CVMX_HELPER_CFG_INVALID_VALUE);
-			cvmx_helper_cfg_assert(pko_port_max >= pko_port_base);
+			if (!octeon_has_feature(OCTEON_FEATURE_PKO3)) {
+				cvmx_helper_cfg_assert(pko_port_base != CVMX_HELPER_CFG_INVALID_VALUE);
+				cvmx_helper_cfg_assert(pko_port_max >= pko_port_base);
+			}
 			for (k = pko_port_base; k < pko_port_max; k++) {
 				cvmx_cfg_pko_port_map[k].ccppl_interface = i;
 				cvmx_cfg_pko_port_map[k].ccppl_index = j;
@@ -493,7 +495,8 @@ void cvmx_helper_cfg_init_pko_port_map(void)
 	/*
 	 * Legal pko_eids [0, 0x13] should not be exhausted.
 	 */
-	cvmx_helper_cfg_assert(pko_eid <= 0x14);
+	if (!octeon_has_feature(OCTEON_FEATURE_PKO3))
+		cvmx_helper_cfg_assert(pko_eid <= 0x14);
 
 	cvmx_cfg_max_pko_engines = pko_eid;
 }
@@ -700,7 +703,7 @@ int cvmx_helper_cfg_ipd2pko_port_num(int ipd_port)
 	int ipd_y, ipd_x;
 
 	ipd_y = IPD2PKO_CACHE_Y(ipd_port);
-	ipd_x = IPD2PKO_CACHE_X(ipd_port);
+	ipd_x = __cvmx_helper_cfg_ipd2pko_cachex(ipd_port);
 
 	return ipd2pko_port_cache[ipd_y][ipd_x].ccppp_nports;
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
index 68238f2..7832f55 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 102466 $<hr>
+ * <hr>$Revision: 105303 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -156,9 +156,7 @@ static int __cvmx_helper_sgmii_hardware_init_one_time(int interface, int index)
 static int __cvmx_helper_need_g15618(void)
 {
 	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM ||
-	    OCTEON_IS_MODEL(OCTEON_CN63XX_PASS1_X) ||
-	    OCTEON_IS_MODEL(OCTEON_CN63XX_PASS2_0) ||
-	    OCTEON_IS_MODEL(OCTEON_CN63XX_PASS2_1) ||
+	    OCTEON_IS_MODEL(OCTEON_CN63XX) ||
 	    OCTEON_IS_MODEL(OCTEON_CN66XX_PASS1_X) ||
 	    OCTEON_IS_MODEL(OCTEON_CN68XX_PASS1_X))
 		return 1;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
index 025f397..0649216 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
@@ -364,7 +364,7 @@ static int __cvmx_ipd_mode_no_wptr(void)
 }
 
 static CVMX_TLS cvmx_buf_ptr_t __cvmx_packet_short_ptr[4];
-static CVMX_TLS uint8_t __cvmx_wqe_pool;
+static CVMX_TLS int8_t __cvmx_wqe_pool = -1;
 
 /**
  * @INTERNAL
@@ -560,26 +560,26 @@ cvmx_buf_ptr_t cvmx_wqe_get_packet_ptr(cvmx_wqe_t *work)
 
 void cvmx_wqe_free(cvmx_wqe_t *work)
 {
-	unsigned ncl = 1;
-	cvmx_wqe_78xx_t * wqe = (void *) work;
+	unsigned bufs, ncl = 1;
+	uint64_t paddr, paddr1;
 
-	/* Free native untranslated 78xx WQE */
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
-		!wqe->pki_wqe_translated) {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t * wqe = (void *) work;
+		cvmx_fpa3_gaura_t aura;
 		cvmx_buf_ptr_pki_t bptr;
 
-		bptr = wqe->packet_ptr;
+		bufs = wqe->word0.bufs;
 
-		/* Do nothing if the first packet buffer shares WQE buffer */
-		if (!bptr.packet_outside_wqe)
-			return;
-	} else {
-		uint64_t paddr, paddr1;
+		if (!wqe->pki_wqe_translated && bufs != 0) {
+			/* Handle cn78xx native untralsated WQE */
 
-		/* check for unconverted RS */
-		if (cvmx_likely(work->word2.s_cn38xx.bufs != 0)) {
+			bptr = wqe->packet_ptr;
 
-			/* Check if the first data buffer is inside WQE */
+			/* Do nothing - first packet buffer shares WQE buffer */
+			if (!bptr.packet_outside_wqe)
+				return;
+		} else if (cvmx_likely(bufs != 0)) {
+			/* Handle translated 78XX WQE */
 			paddr = (work->packet_ptr.s.addr & (~0x7full)) -
 				(work->packet_ptr.s.back << 7);
 			paddr1 = cvmx_ptr_to_phys(work);
@@ -589,20 +589,31 @@ void cvmx_wqe_free(cvmx_wqe_t *work)
 				return;
 		}
 
-		cvmx_fpa1_free(work, __cvmx_wqe_pool, ncl);
-		return;
-	}
-
-	/* At this point it is clear the WQE needs to be freed */
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		cvmx_fpa3_gaura_t aura =
-			__cvmx_fpa3_gaura(
+		/* WQE is separate from packet buffer, free it */
+		aura = __cvmx_fpa3_gaura(
 				wqe->word0.aura >> 10,
 				wqe->word0.aura * 0x3ff);
-		/* First buffer outside WQE, but WQE comes from the same AURA */
-		/* Only a few words have been touched, not entire buf */
-		ncl = 1;
+
 		cvmx_fpa3_free(work, aura, ncl);
+	} else {
+		/* handle legacy WQE */
+		bufs = work->word2.s_cn38xx.bufs;
+
+		if (cvmx_likely(bufs != 0)) {
+			/* Check if the first data buffer is inside WQE */
+			paddr = (work->packet_ptr.s.addr & (~0x7full)) -
+				(work->packet_ptr.s.back << 7);
+			paddr1 = cvmx_ptr_to_phys(work);
+
+			/* do not free WQE if contains first data buffer */
+			if (paddr == paddr1)
+				return;
+		}
+
+		/* precalculate packet_ptr, WQE pool number */
+		if (cvmx_unlikely(__cvmx_wqe_pool < 0))
+			cvmx_packet_short_ptr_calculate();
+		cvmx_fpa1_free(work, __cvmx_wqe_pool, ncl);
 	}
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
index 8cdd9b5..d1a01d4 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 100545 $<hr>
+ * <hr>$Revision: 105303 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -238,9 +238,7 @@ int __cvmx_helper_xaui_link_init(int interface)
 	 * Errata G-15618 requires disabling PCS soft reset in some
 	 * OCTEON II models.
 	 */
-	if (!OCTEON_IS_MODEL(OCTEON_CN63XX_PASS1_X) &&
-	    !OCTEON_IS_MODEL(OCTEON_CN63XX_PASS2_0) &&
-	    !OCTEON_IS_MODEL(OCTEON_CN63XX_PASS2_1) &&
+	if (!OCTEON_IS_MODEL(OCTEON_CN63XX) &&
 	    !OCTEON_IS_MODEL(OCTEON_CN66XX_PASS1_X) &&
 	    !OCTEON_IS_MODEL(OCTEON_CN68XX))
 		xaui_ctl.s.reset = 1;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-l2c.c b/arch/mips/cavium-octeon/executive/cvmx-l2c.c
index c5ef6b7..1da4117 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-l2c.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-l2c.c
@@ -43,7 +43,7 @@
  * Implementation of the Level 2 Cache (L2C) control,
  * measurement, and debugging facilities.
  *
- * <hr>$Revision: 97778 $<hr>
+ * <hr>$Revision: 105520 $<hr>
  *
  */
 
@@ -1062,6 +1062,7 @@ int cvmx_l2c_get_num_sets(void)
 int cvmx_l2c_get_num_assoc(void)
 {
 	int l2_assoc;
+
 	if (OCTEON_IS_MODEL(OCTEON_CN56XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN52XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN58XX)
@@ -1202,10 +1203,11 @@ void cvmx_l2c_flush_line(uint32_t assoc, uint32_t index)
  * Initialize the BIG address in L2C+DRAM to generate proper error
  * on reading/writing to an non-existant memory location.
  *
+ * @param node      OCX CPU node number
  * @param mem_size  Amount of DRAM configured in MB.
  * @param mode      Allow/Disallow reporting errors L2C_INT_SUM[BIGRD,BIGWR].
  */
-void cvmx_l2c_set_big_size(uint64_t mem_size, int mode)
+void cvmx_l2c_set_big_size_node(int node, uint64_t mem_size, int mode)
 {
 	if ((OCTEON_IS_OCTEON2() || OCTEON_IS_OCTEON3())
 	    && !OCTEON_IS_MODEL(OCTEON_CN63XX_PASS1_X)) {
@@ -1242,10 +1244,23 @@ void cvmx_l2c_set_big_size(uint64_t mem_size, int mode)
 		big_ctl.u64 = 0;
 		big_ctl.s.maxdram = bits - 9;
 		big_ctl.cn61xx.disable = mode;
-		cvmx_write_csr(CVMX_L2C_BIG_CTL, big_ctl.u64);
+		cvmx_write_csr_node(node, CVMX_L2C_BIG_CTL, big_ctl.u64);
 	}
 }
 
+/**
+ * Initialize the BIG address in L2C+DRAM to generate proper error
+ * on reading/writing to an non-existant memory location.
+ *
+ * @param mem_size  Amount of DRAM configured in MB.
+ * @param mode      Allow/Disallow reporting errors L2C_INT_SUM[BIGRD,BIGWR].
+ */
+void cvmx_l2c_set_big_size(uint64_t mem_size, int mode)
+{
+	cvmx_l2c_set_big_size_node(0, mem_size, mode);
+}
+
+
 #if !defined(CVMX_BUILD_FOR_LINUX_HOST) && !defined(CVMX_BUILD_FOR_LINUX_KERNEL)
 /* L2C Virtualization APIs. These APIs are based on Octeon II documentation. */
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pcie.c b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
index b369cc5..e73b40b 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pcie.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 103829 $<hr>
+ * <hr>$Revision: 104992 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -109,6 +109,11 @@
 #define _CVMX_PCIE_ES 0
 #endif
 
+#define CVMX_READ_CSR(addr)		cvmx_read_csr_node(node,addr)
+#define CVMX_WRITE_CSR(addr,val)	cvmx_write_csr_node(node,addr,val)
+#define CVMX_PCIE_CFGX_READ(p,addr)	cvmx_pcie_cfgx_read_node(node,p,addr)
+#define CVMX_PCIE_CFGX_WRITE(p,addr,val)	cvmx_pcie_cfgx_write_node(node,p,addr,val)
+
 /**
  * Return the Core virtual base address for PCIe IO access. IOs are
  * read/written as an offset from this address.
@@ -125,8 +130,9 @@ uint64_t cvmx_pcie_get_io_base_address(int pcie_port)
 	pcie_addr.io.io = 1;
 	pcie_addr.io.did = 3;
 	pcie_addr.io.subdid = 2;
+	pcie_addr.io.node = (pcie_port >> 4) & 0x3;
 	pcie_addr.io.es = _CVMX_PCIE_ES;
-	pcie_addr.io.port = pcie_port;
+	pcie_addr.io.port = (pcie_port & 0x3);
 	return pcie_addr.u64;
 }
 
@@ -158,7 +164,8 @@ uint64_t cvmx_pcie_get_mem_base_address(int pcie_port)
 	pcie_addr.mem.upper = 0;
 	pcie_addr.mem.io = 1;
 	pcie_addr.mem.did = 3;
-	pcie_addr.mem.subdid = 3 + pcie_port;
+	pcie_addr.mem.subdid = 3 + (pcie_port & 0x3);
+	pcie_addr.mem.node = (pcie_port >> 4) & 0x3;
 	return pcie_addr.u64;
 }
 
@@ -181,7 +188,7 @@ uint64_t cvmx_pcie_get_mem_size(int pcie_port)
  *
  * @param pcie_port PCIe port to initialize
  */
-static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
+static void __cvmx_pcie_rc_initialize_config_space(int node, int pcie_port)
 {
 	/* Max Payload Size (PCIE*_CFG030[MPS]) */
 	/* Max Read Request Size (PCIE*_CFG030[MRRS]) */
@@ -189,7 +196,7 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 	/* Error Message Enables (PCIE*_CFG030[CE_EN,NFE_EN,FE_EN,UR_EN]) */
 	{
 		cvmx_pciercx_cfg030_t pciercx_cfg030;
-		pciercx_cfg030.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg030.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG030(pcie_port));
 		if (OCTEON_IS_MODEL(OCTEON_CN5XXX)) {
 			pciercx_cfg030.s.mps = MPS_CN5XXX;
@@ -204,7 +211,7 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 		pciercx_cfg030.s.nfe_en = 1;	/* Non-fatal error reporting enable. */
 		pciercx_cfg030.s.fe_en = 1;	/* Fatal error reporting enable. */
 		pciercx_cfg030.s.ur_en = 1;	/* Unsupported request reporting enable. */
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG030(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG030(pcie_port),
 				     pciercx_cfg030.u32);
 	}
 
@@ -212,7 +219,7 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 		/* Max Payload Size (NPEI_CTL_STATUS2[MPS]) must match PCIE*_CFG030[MPS] */
 		/* Max Read Request Size (NPEI_CTL_STATUS2[MRRS]) must not exceed PCIE*_CFG030[MRRS] */
 		cvmx_npei_ctl_status2_t npei_ctl_status2;
-		npei_ctl_status2.u64 = cvmx_read_csr(CVMX_PEXP_NPEI_CTL_STATUS2);
+		npei_ctl_status2.u64 = CVMX_READ_CSR(CVMX_PEXP_NPEI_CTL_STATUS2);
 		npei_ctl_status2.s.mps = MPS_CN5XXX;	/* Max payload size = 128 bytes for best Octeon DMA performance */
 		npei_ctl_status2.s.mrrs = MRRS_CN5XXX;	/* Max read request size = 128 bytes for best Octeon DMA performance */
 		if (pcie_port)
@@ -220,32 +227,32 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 		else
 			npei_ctl_status2.s.c0_b1_s = 3;	/* Port0 BAR1 Size 256MB */
 
-		cvmx_write_csr(CVMX_PEXP_NPEI_CTL_STATUS2, npei_ctl_status2.u64);
+		CVMX_WRITE_CSR(CVMX_PEXP_NPEI_CTL_STATUS2, npei_ctl_status2.u64);
 	} else {
 		/* Max Payload Size (DPI_SLI_PRTX_CFG[MPS]) must match PCIE*_CFG030[MPS] */
 		/* Max Read Request Size (DPI_SLI_PRTX_CFG[MRRS]) must not exceed PCIE*_CFG030[MRRS] */
 		cvmx_dpi_sli_prtx_cfg_t prt_cfg;
 		cvmx_sli_s2m_portx_ctl_t sli_s2m_portx_ctl;
-		prt_cfg.u64 = cvmx_read_csr(CVMX_DPI_SLI_PRTX_CFG(pcie_port));
+		prt_cfg.u64 = CVMX_READ_CSR(CVMX_DPI_SLI_PRTX_CFG(pcie_port));
 		prt_cfg.s.mps = MPS_CN6XXX;
 		prt_cfg.s.mrrs = MRRS_CN6XXX;
 		/* Max outstanding load request. */
 		prt_cfg.s.molr = 32;
-		cvmx_write_csr(CVMX_DPI_SLI_PRTX_CFG(pcie_port), prt_cfg.u64);
+		CVMX_WRITE_CSR(CVMX_DPI_SLI_PRTX_CFG(pcie_port), prt_cfg.u64);
 
-		sli_s2m_portx_ctl.u64 = cvmx_read_csr(CVMX_PEXP_SLI_S2M_PORTX_CTL(pcie_port));
+		sli_s2m_portx_ctl.u64 = CVMX_READ_CSR(CVMX_PEXP_SLI_S2M_PORTX_CTL(pcie_port));
 		sli_s2m_portx_ctl.cn61xx.mrrs = MRRS_CN6XXX;
-		cvmx_write_csr(CVMX_PEXP_SLI_S2M_PORTX_CTL(pcie_port), sli_s2m_portx_ctl.u64);
+		CVMX_WRITE_CSR(CVMX_PEXP_SLI_S2M_PORTX_CTL(pcie_port), sli_s2m_portx_ctl.u64);
 	}
 
 	/* ECRC Generation (PCIE*_CFG070[GE,CE]) */
 	{
 		cvmx_pciercx_cfg070_t pciercx_cfg070;
-		pciercx_cfg070.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg070.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG070(pcie_port));
 		pciercx_cfg070.s.ge = 1;	/* ECRC generation enable. */
 		pciercx_cfg070.s.ce = 1;	/* ECRC check enable. */
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG070(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG070(pcie_port),
 				     pciercx_cfg070.u32);
 	}
 
@@ -255,29 +262,29 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 	/* System Error Message Enable (PCIE*_CFG001[SEE]) */
 	{
 		cvmx_pciercx_cfg001_t pciercx_cfg001;
-		pciercx_cfg001.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg001.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG001(pcie_port));
 		pciercx_cfg001.s.msae = 1;	/* Memory space enable. */
 		pciercx_cfg001.s.me = 1;	/* Bus master enable. */
 		pciercx_cfg001.s.i_dis = 1;	/* INTx assertion disable. */
 		pciercx_cfg001.s.see = 1;	/* SERR# enable */
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG001(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG001(pcie_port),
 				     pciercx_cfg001.u32);
 	}
 
 	/* Advanced Error Recovery Message Enables */
 	/* (PCIE*_CFG066,PCIE*_CFG067,PCIE*_CFG069) */
-	cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG066(pcie_port), 0);
+	CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG066(pcie_port), 0);
 	/* Use CVMX_PCIERCX_CFG067 hardware default */
-	cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG069(pcie_port), 0);
+	CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG069(pcie_port), 0);
 
 	/* Active State Power Management (PCIE*_CFG032[ASLPC]) */
 	{
 		cvmx_pciercx_cfg032_t pciercx_cfg032;
-		pciercx_cfg032.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg032.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG032(pcie_port));
 		pciercx_cfg032.s.aslpc = 0;	/* Active state Link PM control. */
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG032(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG032(pcie_port),
 				     pciercx_cfg032.u32);
 	}
 
@@ -294,7 +301,7 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 		pciercx_cfg006.s.pbnum = 1;
 		pciercx_cfg006.s.sbnum = 1;
 		pciercx_cfg006.s.subbnum = 1;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG006(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG006(pcie_port),
 				     pciercx_cfg006.u32);
 	}
 
@@ -306,7 +313,7 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 		pciercx_cfg008.u32 = 0;
 		pciercx_cfg008.s.mb_addr = 0x100;
 		pciercx_cfg008.s.ml_addr = 0;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG008(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG008(pcie_port),
 				     pciercx_cfg008.u32);
 	}
 
@@ -318,21 +325,21 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 		cvmx_pciercx_cfg009_t pciercx_cfg009;
 		cvmx_pciercx_cfg010_t pciercx_cfg010;
 		cvmx_pciercx_cfg011_t pciercx_cfg011;
-		pciercx_cfg009.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg009.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG009(pcie_port));
-		pciercx_cfg010.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg010.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG010(pcie_port));
-		pciercx_cfg011.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg011.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG011(pcie_port));
 		pciercx_cfg009.s.lmem_base = 0x100;
 		pciercx_cfg009.s.lmem_limit = 0;
 		pciercx_cfg010.s.umem_base = 0x100;
 		pciercx_cfg011.s.umem_limit = 0;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG009(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG009(pcie_port),
 				     pciercx_cfg009.u32);
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG010(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG010(pcie_port),
 				     pciercx_cfg010.u32);
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG011(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG011(pcie_port),
 				     pciercx_cfg011.u32);
 	}
 
@@ -340,13 +347,13 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 	/* PME Interrupt Enables (PCIERCn_CFG035[PMEIE]) */
 	{
 		cvmx_pciercx_cfg035_t pciercx_cfg035;
-		pciercx_cfg035.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg035.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG035(pcie_port));
 		pciercx_cfg035.s.secee = 1;	/* System error on correctable error enable. */
 		pciercx_cfg035.s.sefee = 1;	/* System error on fatal error enable. */
 		pciercx_cfg035.s.senfee = 1;	/* System error on non-fatal error enable. */
 		pciercx_cfg035.s.pmeie = 1;	/* PME interrupt enable. */
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG035(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG035(pcie_port),
 				     pciercx_cfg035.u32);
 	}
 
@@ -354,12 +361,12 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 	/* (PCIERCn_CFG075[CERE,NFERE,FERE]) */
 	{
 		cvmx_pciercx_cfg075_t pciercx_cfg075;
-		pciercx_cfg075.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg075.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG075(pcie_port));
 		pciercx_cfg075.s.cere = 1;	/* Correctable error reporting enable. */
 		pciercx_cfg075.s.nfere = 1;	/* Non-fatal error reporting enable. */
 		pciercx_cfg075.s.fere = 1;	/* Fatal error reporting enable. */
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG075(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG075(pcie_port),
 				     pciercx_cfg075.u32);
 	}
 
@@ -367,12 +374,12 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 	/* PCIERCn_CFG034[DLLS_EN,CCINT_EN]) */
 	{
 		cvmx_pciercx_cfg034_t pciercx_cfg034;
-		pciercx_cfg034.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg034.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG034(pcie_port));
 		pciercx_cfg034.s.hpint_en = 1;	/* Hot-plug interrupt enable. */
 		pciercx_cfg034.s.dlls_en = 1;	/* Data Link Layer state changed enable */
 		pciercx_cfg034.s.ccint_en = 1;	/* Command completed interrupt enable. */
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG034(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG034(pcie_port),
 				     pciercx_cfg034.u32);
 	}
 
@@ -387,39 +394,39 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
   		   its going to try */
 		switch(speed) {
 		case 2500: /* Gen1 */
-			pem_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(pcie_port));
+			pem_cfg.u64 = CVMX_READ_CSR(CVMX_PEMX_CFG(pcie_port));
 			pem_cfg.s.md = 0;
-			cvmx_write_csr(CVMX_PEMX_CFG(pcie_port), pem_cfg.u64);
+			CVMX_WRITE_CSR(CVMX_PEMX_CFG(pcie_port), pem_cfg.u64);
 
 			/* Set the target link speed */
-			cfg040.u32 = cvmx_pcie_cfgx_read(pcie_port,
+			cfg040.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 						CVMX_PCIERCX_CFG040(pcie_port));	
 			cfg040.s.tls = 1;
-			cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG040(pcie_port),
+			CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG040(pcie_port),
 						cfg040.u32);
 			break;
 		case 5000: /* Gen2 */
-			pem_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(pcie_port));
+			pem_cfg.u64 = CVMX_READ_CSR(CVMX_PEMX_CFG(pcie_port));
 			pem_cfg.s.md = 1;
-			cvmx_write_csr(CVMX_PEMX_CFG(pcie_port), pem_cfg.u64);
+			CVMX_WRITE_CSR(CVMX_PEMX_CFG(pcie_port), pem_cfg.u64);
 
 			/* Set the target link speed */
-			cfg040.u32 = cvmx_pcie_cfgx_read(pcie_port,
+			cfg040.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 						CVMX_PCIERCX_CFG040(pcie_port));	
 			cfg040.s.tls = 2;
-			cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG040(pcie_port),
+			CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG040(pcie_port),
 						cfg040.u32);
 			break;
 		case 8000: /* Gen3 */
-			pem_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(pcie_port));
+			pem_cfg.u64 = CVMX_READ_CSR(CVMX_PEMX_CFG(pcie_port));
 			pem_cfg.s.md = 2;
-			cvmx_write_csr(CVMX_PEMX_CFG(pcie_port), pem_cfg.u64);
+			CVMX_WRITE_CSR(CVMX_PEMX_CFG(pcie_port), pem_cfg.u64);
 
 			/* Set the target link speed */
-			cfg040.u32 = cvmx_pcie_cfgx_read(pcie_port,
+			cfg040.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 						CVMX_PCIERCX_CFG040(pcie_port));	
 			cfg040.s.tls = 3;
-			cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG040(pcie_port),
+			CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG040(pcie_port),
 						cfg040.u32);
 			break;
 		default:
@@ -427,10 +434,10 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 		}
 		
 		/* Link Width Mode (PCIERCn_CFG452[LME]) */
-		pem_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(pcie_port));
-		cfg452.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG452(pcie_port));	
+		pem_cfg.u64 = CVMX_READ_CSR(CVMX_PEMX_CFG(pcie_port));
+		cfg452.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG452(pcie_port));	
 		cfg452.s.lme = (pem_cfg.cn78xx.lanes8) ? 0xf : 0x7;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG452(pcie_port), cfg452.u32);
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG452(pcie_port), cfg452.u32);
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_0)) {
@@ -443,45 +450,45 @@ static void __cvmx_pcie_rc_initialize_config_space(int pcie_port)
 		/* The starting equalization hints are incorrect on CN78XX pass 1.x. Fix
 		them for the 8 possible lanes. It doesn't hurt to program them even for
 		lanes not in use */
-		cfg089.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG089(pcie_port));
+		cfg089.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG089(pcie_port));
 		cfg089.s.l1urph= 2;
 		cfg089.s.l1utp = 7;
 		cfg089.s.l0urph = 2;
 		cfg089.s.l0utp = 7;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG089(pcie_port), cfg089.u32);
-		cfg090.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG090(pcie_port));
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG089(pcie_port), cfg089.u32);
+		cfg090.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG090(pcie_port));
 		cfg090.s.l3urph= 2;
 		cfg090.s.l3utp = 7;
 		cfg090.s.l2urph = 2;
 		cfg090.s.l2utp = 7;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG090(pcie_port), cfg090.u32);
-		cfg091.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG091(pcie_port));
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG090(pcie_port), cfg090.u32);
+		cfg091.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG091(pcie_port));
 		cfg091.s.l5urph= 2;
 		cfg091.s.l5utp = 7;
 		cfg091.s.l4urph = 2;
 		cfg091.s.l4utp = 7;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG091(pcie_port), cfg091.u32);
-		cfg092.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG092(pcie_port));
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG091(pcie_port), cfg091.u32);
+		cfg092.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG092(pcie_port));
 		cfg092.s.l7urph= 2;
 		cfg092.s.l7utp = 7;
 		cfg092.s.l6urph = 2;
 		cfg092.s.l6utp = 7;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG092(pcie_port), cfg092.u32);
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG092(pcie_port), cfg092.u32);
 		/* FIXME: Disable phase 2 and phase 3 equalization */
-		cfg548.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG548(pcie_port));
+		cfg548.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG548(pcie_port));
 		cfg548.s.ep2p3d = 1;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG548(pcie_port), cfg548.u32);
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG548(pcie_port), cfg548.u32);
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
 		cvmx_pciercx_cfg554_t cfg554;
 		/* Errata (GSER-21331) GEN3 Equalization may fail */
 		/* Disable preset #10 and disable the 2ms timeout */
-		cfg554.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG554(pcie_port));
+		cfg554.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG554(pcie_port));
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 			cfg554.s.p23td = 1;
 		cfg554.s.prv = 0x3ff;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG554(pcie_port), cfg554.u32);
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG554(pcie_port), cfg554.u32);
 	}
 }
 
@@ -788,7 +795,7 @@ retry:
 			    pcie_port, CAST64(pescx_bist_status.u64));
 
 	/* Initialize the config space CSRs */
-	__cvmx_pcie_rc_initialize_config_space(pcie_port);
+	__cvmx_pcie_rc_initialize_config_space(0, pcie_port);
 
 	/* Bring the link up */
 	if (__cvmx_pcie_rc_initialize_link_gen1(pcie_port)) {
@@ -996,7 +1003,7 @@ retry:
  *
  * @return Zero on success
  */
-static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
+static int __cvmx_pcie_rc_initialize_link_gen2(int node, int pcie_port)
 {
 	uint64_t start_cycle;
 	int try_gen3;
@@ -1008,32 +1015,33 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 	cvmx_pciercx_cfg448_t pciercx_cfg448;
 
 	if (OCTEON_IS_OCTEON3()) {
-		if (CVMX_WAIT_FOR_FIELD64(CVMX_PEMX_ON(pcie_port), cvmx_pemx_on_t, pemoor, ==, 1, 100000)) {
-			cvmx_printf("PCIe: Port %d PEM not on, skipping\n", pcie_port);
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_PEMX_ON(pcie_port), cvmx_pemx_on_t, pemoor, ==, 1, 100000)) {
+			cvmx_printf("%d:PCIe: Port %d PEM not on, skipping\n", node, pcie_port);
 			return -1;
 		}
 	}
 
 	/* Remember if the link should try Gen3. This is needed for the CN78XX
 	pass 1.x workaround below */
-	pciercx_cfg031.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG031(pcie_port));
+	pciercx_cfg031.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG031(pcie_port));
 	try_gen3 = (pciercx_cfg031.s.mls == 3);
 
 	/* Errata (GSER-21178) PCIe gen3 doesn't work */
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_0) && try_gen3) {
 		/* Force Gen1 for initial link bringup. We'll fix it later */
-		pciercx_cfg031.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG031(pcie_port));
+		pciercx_cfg031.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG031(pcie_port));
 		pciercx_cfg031.s.mls = 1;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG031(pcie_port), pciercx_cfg031.u32);
-		pciercx_cfg040.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG040(pcie_port));
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG031(pcie_port), pciercx_cfg031.u32);
+		pciercx_cfg040.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG040(pcie_port));
 		pciercx_cfg040.s.tls = 1;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG040(pcie_port), pciercx_cfg040.u32);
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG040(pcie_port), pciercx_cfg040.u32);
 	}
 
 	/* Bring up the link */
-	pem_ctl_status.u64 = cvmx_read_csr(CVMX_PEMX_CTL_STATUS(pcie_port));
+	pem_ctl_status.u64 = CVMX_READ_CSR(CVMX_PEMX_CTL_STATUS(pcie_port));
 	pem_ctl_status.s.lnk_enb = 1;
-	cvmx_write_csr(CVMX_PEMX_CTL_STATUS(pcie_port), pem_ctl_status.u64);
+	CVMX_WRITE_CSR(CVMX_PEMX_CTL_STATUS(pcie_port), pem_ctl_status.u64);
+//printf("try_gen3 = %d, lnk_en = 0x%llx\n", try_gen3, CVMX_READ_CSR(CVMX_PEMX_CTL_STATUS(pcie_port)));
 
 	/* Wait for the link to come up */
 	start_cycle = cvmx_get_cycle();
@@ -1041,7 +1049,7 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 		if (cvmx_get_cycle() - start_cycle > cvmx_clock_get_rate(CVMX_CLOCK_CORE))
 			return -1;
 		cvmx_wait(10000);
-		pciercx_cfg032.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pciercx_cfg032.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG032(pcie_port));
 	} while ((pciercx_cfg032.s.dlla == 0) || (pciercx_cfg032.s.lt == 1));
 
@@ -1056,16 +1064,16 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 		int qlm, lane;
 
 		/* Enable gen3 speed selection */
-		cfg031.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG031(pcie_port));
+		cfg031.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG031(pcie_port));
 		cfg031.s.mls = 3;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG031(pcie_port), cfg031.u32);
-		cfg040.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG040(pcie_port));
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG031(pcie_port), cfg031.u32);
+		cfg040.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG040(pcie_port));
 		cfg040.s.tls = 3;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG040(pcie_port), cfg040.u32);
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG040(pcie_port), cfg040.u32);
 		/* Force a demand speed change */
-		cfg515.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG515(pcie_port));
+		cfg515.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG515(pcie_port));
 		cfg515.s.dsc = 1;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG515(pcie_port), cfg515.u32);
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG515(pcie_port), cfg515.u32);
 		cvmx_wait_usec(500);
 
 		/* Wait up to 10ms for the link speed change to complete */
@@ -1074,11 +1082,11 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 			if (cvmx_get_cycle() - start_cycle > cvmx_clock_get_rate(CVMX_CLOCK_CORE))
 				return -1;
 			cvmx_wait(10000);
-			pciercx_cfg032.u32 = cvmx_pcie_cfgx_read(pcie_port,
+			pciercx_cfg032.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG032(pcie_port));
 		} while (pciercx_cfg032.s.ls != 3);
 
-		pem_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(pcie_port));
+		pem_cfg.u64 = CVMX_READ_CSR(CVMX_PEMX_CFG(pcie_port));
 		low_qlm = pcie_port;  /* FIXME */
 		high_qlm = (pem_cfg.cn78xx.lanes8) ? low_qlm+1 : low_qlm;
 
@@ -1089,12 +1097,12 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 				cvmx_gserx_lanex_rx_misc_ovrrd_t misc_ovrrd;
 				cvmx_gserx_lanex_pwr_ctrl_t pwr_ctrl;
 
-				misc_ovrrd.u64 = cvmx_read_csr(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm));
+				misc_ovrrd.u64 = CVMX_READ_CSR(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm));
 				misc_ovrrd.s.cfg_rx_dll_locken_ovvrd_en = 1;
-				cvmx_write_csr(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm), misc_ovrrd.u64);
-				pwr_ctrl.u64 = cvmx_read_csr(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm));
+				CVMX_WRITE_CSR(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm), misc_ovrrd.u64);
+				pwr_ctrl.u64 = CVMX_READ_CSR(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm));
 				pwr_ctrl.s.rx_resetn_ovrrd_en = 1;
-				cvmx_write_csr(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm), pwr_ctrl.u64);
+				CVMX_WRITE_CSR(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm), pwr_ctrl.u64);
 			}
 		}
 		for (qlm = low_qlm; qlm <= high_qlm; qlm++) {
@@ -1102,12 +1110,12 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 				cvmx_gserx_lanex_rx_misc_ovrrd_t misc_ovrrd;
 				cvmx_gserx_lanex_pwr_ctrl_t pwr_ctrl;
 
-				misc_ovrrd.u64 = cvmx_read_csr(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm));
+				misc_ovrrd.u64 = CVMX_READ_CSR(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm));
 				misc_ovrrd.s.cfg_rx_dll_locken_ovvrd_en = 0;
-				cvmx_write_csr(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm), misc_ovrrd.u64);
-				pwr_ctrl.u64 = cvmx_read_csr(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm));
+				CVMX_WRITE_CSR(CVMX_GSERX_LANEX_RX_MISC_OVRRD(lane, qlm), misc_ovrrd.u64);
+				pwr_ctrl.u64 = CVMX_READ_CSR(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm));
 				pwr_ctrl.s.rx_resetn_ovrrd_en = 0;
-				cvmx_write_csr(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm), pwr_ctrl.u64);
+				CVMX_WRITE_CSR(CVMX_GSERX_LANEX_PWR_CTRL(lane, qlm), pwr_ctrl.u64);
 			}
 		}
 
@@ -1117,7 +1125,7 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 			if (cvmx_clock_get_count(CVMX_CLOCK_CORE) - start_cycle > cvmx_clock_get_rate(CVMX_CLOCK_CORE))
 				return -1;
 			cvmx_wait_usec(1000);
-			cfg032.u32 = cvmx_pcie_cfgx_read(pcie_port, CVMX_PCIERCX_CFG032(pcie_port));
+			cfg032.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG032(pcie_port));
 		} while ((cfg032.s.dlla == 0) || (cfg032.s.lt == 1));
 	}
 
@@ -1127,7 +1135,7 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 	 * for a 512 byte MPS instead of our actual 256 byte MPS. The numbers
 	 * below are directly from the PCIe spec table 3-4
 	 */
-	pciercx_cfg448.u32 = cvmx_pcie_cfgx_read(pcie_port,
+	pciercx_cfg448.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 						 CVMX_PCIERCX_CFG448(pcie_port));
 	switch (pciercx_cfg032.s.nlw) {
 	case 1:		/* 1 lane */
@@ -1143,7 +1151,7 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 		pciercx_cfg448.s.rtl = 258;
 		break;
 	}
-	cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG448(pcie_port),
+	CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG448(pcie_port),
 			     pciercx_cfg448.u32);
 
 	return 0;
@@ -1218,12 +1226,15 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	cvmx_pemx_bar1_indexx_t bar1_index;
 	uint64_t ciu_soft_prst_reg, rst_ctl_reg;
 	int ep_mode;
-	int qlm = pcie_port;
+	int qlm;
+	int node = (pcie_port >> 4) & 0x3;
 	int connected_pcie_reset = -1;
 	enum cvmx_qlm_mode mode = CVMX_QLM_MODE_DISABLED;
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 	static void *fdt_addr = 0;
 #endif
+	pcie_port &= 0x3;
+	qlm = pcie_port;
 
 	if (pcie_port >= CVMX_PCIE_PORTS) {
 		//cvmx_dprintf("Invalid PCIe%d port\n", pcie_port);
@@ -1254,33 +1265,36 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		else if (OCTEON_IS_MODEL(OCTEON_CNF71XX))
 			qlm = 1;
 
-		mode = cvmx_qlm_get_mode(qlm);
+		if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+			mode = cvmx_qlm_get_mode_cn78xx(node, qlm);
+		else
+			mode = cvmx_qlm_get_mode(qlm);
 		if (mode == CVMX_QLM_MODE_SRIO_1X4 ||
 		    mode == CVMX_QLM_MODE_SRIO_2X2 ||
 		    mode == CVMX_QLM_MODE_SRIO_4X1) {
-			cvmx_printf("PCIe: Port %d is SRIO, skipping.\n",
-				    pcie_port);
+			cvmx_printf("%d:PCIe: Port %d is SRIO, skipping.\n",
+				    node, pcie_port);
 			return -1;
 		} else if (mode == CVMX_QLM_MODE_SGMII) {
-			cvmx_printf("PCIe: Port %d is SGMII, skipping.\n",
-				    pcie_port);
+			cvmx_printf("%d:PCIe: Port %d is SGMII, skipping.\n",
+				    node, pcie_port);
 			return -1;
 		} else if (mode == CVMX_QLM_MODE_XAUI ||
 			   mode == CVMX_QLM_MODE_RXAUI) {
-			cvmx_printf("PCIe: Port %d is XAUI, skipping.\n",
-				    pcie_port);
+			cvmx_printf("%d:PCIe: Port %d is XAUI, skipping.\n",
+				    node, pcie_port);
 			return -1;
 		} else if (mode == CVMX_QLM_MODE_ILK) {
-			cvmx_printf("PCIe: Port %d is ILK, skipping.\n",
-				    pcie_port);
+			cvmx_printf("%d:PCIe: Port %d is ILK, skipping.\n",
+				    node, pcie_port);
 			return -1;
 		} else if (mode != CVMX_QLM_MODE_PCIE &&
 			   mode != CVMX_QLM_MODE_PCIE_1X8 &&
 			   mode != CVMX_QLM_MODE_PCIE_1X2 &&
 			   mode != CVMX_QLM_MODE_PCIE_2X1 &&
 			   mode != CVMX_QLM_MODE_PCIE_1X1) {
-			cvmx_printf("PCIe: Port %d is unknown, skipping.\n",
-				    pcie_port);
+			cvmx_printf("%d:PCIe: Port %d is unknown, skipping.\n",
+				    node, pcie_port);
 			return -1;
 		}
 	}
@@ -1315,7 +1329,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		rst_ctl_reg = CVMX_MIO_RST_CTLX(pcie_port);
 	}
 
-	mio_rst_ctl.u64 = cvmx_read_csr(rst_ctl_reg);
+	mio_rst_ctl.u64 = CVMX_READ_CSR(rst_ctl_reg);
 	ep_mode = ((OCTEON_IS_MODEL(OCTEON_CN61XX) ||
 		    OCTEON_IS_MODEL(OCTEON_CNF71XX))
 		? (mio_rst_ctl.s.prtmode != 1) : (!mio_rst_ctl.s.host_mode));
@@ -1330,12 +1344,12 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		cvmx_write_csr(CVMX_DTX_PEMX_SELX(0, pcie_port), 0x17);
-		cvmx_write_csr(CVMX_DTX_PEMX_SELX(1, pcie_port), 0);
+		CVMX_WRITE_CSR(CVMX_DTX_PEMX_SELX(0, pcie_port), 0x17);
+		CVMX_WRITE_CSR(CVMX_DTX_PEMX_SELX(1, pcie_port), 0);
 	}
 
 	if (ep_mode) {
-		cvmx_printf("PCIe: Port %d in endpoint mode.\n", pcie_port);
+		cvmx_printf("%d:PCIe: Port %d in endpoint mode.\n", node, pcie_port);
 		return -1;
 	}
 #if 0
@@ -1418,56 +1432,56 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	switch (connected_pcie_reset) {
 	case 0:
 		if (pcie_port == 1 &&
-		    (cvmx_read_csr(CVMX_MIO_QLMX_CFG(1)) & 0x3) == 1) {
-			ciu_soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST);
+		    (CVMX_READ_CSR(CVMX_MIO_QLMX_CFG(1)) & 0x3) == 1) {
+			ciu_soft_prst.u64 = CVMX_READ_CSR(CVMX_CIU_SOFT_PRST);
 			if (ciu_soft_prst.s.soft_prst == 0) {
 				/* Reset the port */
 				ciu_soft_prst.s.soft_prst = 1;
-				cvmx_write_csr(CVMX_CIU_SOFT_PRST,
+				CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST,
 					ciu_soft_prst.u64);
 				/* Wait until pcie resets the ports. */
 				cvmx_wait_usec(2000);
-				cvmx_write_csr(CVMX_CIU_SOFT_PRST1,
+				CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST1,
 					ciu_soft_prst.u64);
 				/* Wait until pcie resets the ports. */
 				cvmx_wait_usec(2000);
 			}
-			ciu_soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST);
+			ciu_soft_prst.u64 = CVMX_READ_CSR(CVMX_CIU_SOFT_PRST);
 			ciu_soft_prst.s.soft_prst = 0;
-			cvmx_write_csr(CVMX_CIU_SOFT_PRST, ciu_soft_prst.u64);
-			ciu_soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST1);
+			CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST, ciu_soft_prst.u64);
+			ciu_soft_prst.u64 = CVMX_READ_CSR(CVMX_CIU_SOFT_PRST1);
 			ciu_soft_prst.s.soft_prst = 0;
-			cvmx_write_csr(CVMX_CIU_SOFT_PRST1, ciu_soft_prst.u64);
+			CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST1, ciu_soft_prst.u64);
 		}
 		break;
 	case 1:
 		if (pcie_port == 0 &&
-		    (cvmx_read_csr(CVMX_MIO_QLMX_CFG(1)) & 0x3) == 1) {
-			ciu_soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST1);
+		    (CVMX_READ_CSR(CVMX_MIO_QLMX_CFG(1)) & 0x3) == 1) {
+			ciu_soft_prst.u64 = CVMX_READ_CSR(CVMX_CIU_SOFT_PRST1);
 			if (ciu_soft_prst.s.soft_prst == 0) {
 				/* Reset the port */
 				ciu_soft_prst.s.soft_prst = 1;
-				cvmx_write_csr(CVMX_CIU_SOFT_PRST1,
+				CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST1,
 					ciu_soft_prst.u64);
 				/* Wait until pcie resets the ports. */
 				cvmx_wait_usec(2000);
-				cvmx_write_csr(CVMX_CIU_SOFT_PRST,
+				CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST,
 					ciu_soft_prst.u64);
 				/* Wait until pcie resets the ports. */
 				cvmx_wait_usec(2000);
 			}
-			ciu_soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST1);
+			ciu_soft_prst.u64 = CVMX_READ_CSR(CVMX_CIU_SOFT_PRST1);
 			ciu_soft_prst.s.soft_prst = 0;
-			cvmx_write_csr(CVMX_CIU_SOFT_PRST1, ciu_soft_prst.u64);
-			ciu_soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST);
+			CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST1, ciu_soft_prst.u64);
+			ciu_soft_prst.u64 = CVMX_READ_CSR(CVMX_CIU_SOFT_PRST);
 			ciu_soft_prst.s.soft_prst = 0;
-			cvmx_write_csr(CVMX_CIU_SOFT_PRST, ciu_soft_prst.u64);
+			CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST, ciu_soft_prst.u64);
 		}
 		break;
 	case -1:
 	default:
 		/* Bring the PCIe out of reset */
-		ciu_soft_prst.u64 = cvmx_read_csr(ciu_soft_prst_reg);
+		ciu_soft_prst.u64 = CVMX_READ_CSR(ciu_soft_prst_reg);
 		/* After a chip reset the PCIe will also be in reset. If it
 		 * isn't, most likely someone is trying to init it again
 		 * without a proper PCIe reset.
@@ -1475,13 +1489,13 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		if (ciu_soft_prst.s.soft_prst == 0) {
 			/* Reset the port */
 			ciu_soft_prst.s.soft_prst = 1;
-			cvmx_write_csr(ciu_soft_prst_reg, ciu_soft_prst.u64);
+			CVMX_WRITE_CSR(ciu_soft_prst_reg, ciu_soft_prst.u64);
 			/* Wait until pcie resets the ports. */
 			cvmx_wait_usec(2000);
 		}
-		ciu_soft_prst.u64 = cvmx_read_csr(ciu_soft_prst_reg);
+		ciu_soft_prst.u64 = CVMX_READ_CSR(ciu_soft_prst_reg);
 		ciu_soft_prst.s.soft_prst = 0;
-		cvmx_write_csr(ciu_soft_prst_reg, ciu_soft_prst.u64);
+		CVMX_WRITE_CSR(ciu_soft_prst_reg, ciu_soft_prst.u64);
 	}
 
 	/* Wait for PCIe reset to complete */
@@ -1496,57 +1510,57 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	/* Check and make sure PCIe came out of reset. If it doesn't the board
 	   probably hasn't wired the clocks up and the interface should be
 	   skipped */
-	if (CVMX_WAIT_FOR_FIELD64(rst_ctl_reg, cvmx_mio_rst_ctlx_t,
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, rst_ctl_reg, cvmx_mio_rst_ctlx_t,
 				  rst_done, ==, 1, 10000)) {
-		cvmx_printf("PCIe: Port %d stuck in reset, skipping.\n",
-			    pcie_port);
+		cvmx_printf("%d:PCIe: Port %d stuck in reset, skipping.\n",
+			    node, pcie_port);
 		return -1;
 	}
 
 	/* Check BIST status */
-	pemx_bist_status.u64 = cvmx_read_csr(CVMX_PEMX_BIST_STATUS(pcie_port));
+	pemx_bist_status.u64 = CVMX_READ_CSR(CVMX_PEMX_BIST_STATUS(pcie_port));
 	if (pemx_bist_status.u64)
-		cvmx_printf("PCIe: BIST FAILED for port %d (0x%016llx)\n",
-			    pcie_port, CAST64(pemx_bist_status.u64));
+		cvmx_printf("%d:PCIe: BIST FAILED for port %d (0x%016llx)\n",
+			    node, pcie_port, CAST64(pemx_bist_status.u64));
 	/* BIST_STATUS2 is not present on 78xx */
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 		pemx_bist_status2.u64 = 0;
 	else
-		pemx_bist_status2.u64 = cvmx_read_csr(CVMX_PEMX_BIST_STATUS2(pcie_port));
+		pemx_bist_status2.u64 = CVMX_READ_CSR(CVMX_PEMX_BIST_STATUS2(pcie_port));
 	/* Errata PCIE-14766 may cause the lower 6 bits to be randomly set on CN63XXp1 */
 	if (OCTEON_IS_MODEL(OCTEON_CN63XX_PASS1_X))
 		pemx_bist_status2.u64 &= ~0x3full;
 	if (pemx_bist_status2.u64)
-		cvmx_printf("PCIe: BIST2 FAILED for port %d (0x%016llx)\n",
-			    pcie_port, CAST64(pemx_bist_status2.u64));
+		cvmx_printf("%d:PCIe: BIST2 FAILED for port %d (0x%016llx)\n",
+			    node, pcie_port, CAST64(pemx_bist_status2.u64));
 
 	/* Initialize the config space CSRs */
-	__cvmx_pcie_rc_initialize_config_space(pcie_port);
+	__cvmx_pcie_rc_initialize_config_space(node, pcie_port);
 
 	/* Enable gen2 speed selection */
-	pciercx_cfg515.u32 = cvmx_pcie_cfgx_read(pcie_port,
+	pciercx_cfg515.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 						 CVMX_PCIERCX_CFG515(pcie_port));
 	pciercx_cfg515.s.dsc = 1;
-	cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG515(pcie_port),
+	CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG515(pcie_port),
 			     pciercx_cfg515.u32);
 
 	/* Bring the link up */
-	if (__cvmx_pcie_rc_initialize_link_gen2(pcie_port)) {
+	if (__cvmx_pcie_rc_initialize_link_gen2(node, pcie_port)) {
 		/* Some gen1 devices don't handle the gen 2 training correctly.
 		 * Disable gen2 and try again with only gen1
 		 */
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-			cvmx_printf("PCIe: Link timeout on port %d, probably the slot is empty\n",
-				    pcie_port);
+			cvmx_printf("%d:PCIe: Link timeout on port %d, probably the slot is empty\n",
+				    node, pcie_port);
 			return -1;
 		} else {
 			cvmx_pciercx_cfg031_t pciercx_cfg031;
-			pciercx_cfg031.u32 = cvmx_pcie_cfgx_read(pcie_port,
+			pciercx_cfg031.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIERCX_CFG031(pcie_port));
 			pciercx_cfg031.s.mls = 1;
-			cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG031(pcie_port),
+			CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG031(pcie_port),
 				     		pciercx_cfg031.u32);
-			if (__cvmx_pcie_rc_initialize_link_gen2(pcie_port)) {
+			if (__cvmx_pcie_rc_initialize_link_gen2(node, pcie_port)) {
 				cvmx_printf("PCIe: Link timeout on port %d, probably the slot is empty\n",
 					    pcie_port);
 				return -1;
@@ -1555,10 +1569,10 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	}
 
 	/* Store merge control (SLI_MEM_ACCESS_CTL[TIMER,MAX_WORD]) */
-	sli_mem_access_ctl.u64 = cvmx_read_csr(CVMX_PEXP_SLI_MEM_ACCESS_CTL);
+	sli_mem_access_ctl.u64 = CVMX_READ_CSR(CVMX_PEXP_SLI_MEM_ACCESS_CTL);
 	sli_mem_access_ctl.s.max_word = 0;	/* Allow 16 words to combine */
 	sli_mem_access_ctl.s.timer = 127;	/* Wait up to 127 cycles for more data */
-	cvmx_write_csr(CVMX_PEXP_SLI_MEM_ACCESS_CTL, sli_mem_access_ctl.u64);
+	CVMX_WRITE_CSR(CVMX_PEXP_SLI_MEM_ACCESS_CTL, sli_mem_access_ctl.u64);
 
 	/* Setup Mem access SubDIDs */
 	mem_access_subid.u64 = 0;
@@ -1578,7 +1592,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	 * bits of address space
 	 */
 	for (i = 12 + pcie_port * 4; i < 16 + pcie_port * 4; i++) {
-		cvmx_write_csr(CVMX_PEXP_SLI_MEM_ACCESS_SUBIDX(i),
+		CVMX_WRITE_CSR(CVMX_PEXP_SLI_MEM_ACCESS_SUBIDX(i),
 			       mem_access_subid.u64);
 		/* Set each SUBID to extend the addressable range */
 		__cvmx_increment_ba(&mem_access_subid);
@@ -1593,40 +1607,40 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		 * addresses to the PCIe busses
 		 */
 		for (i = 0; i < 4; i++) {
-			cvmx_write_csr(CVMX_PEMX_P2P_BARX_START(i, pcie_port), -1);
-			cvmx_write_csr(CVMX_PEMX_P2P_BARX_END(i, pcie_port), -1);
+			CVMX_WRITE_CSR(CVMX_PEMX_P2P_BARX_START(i, pcie_port), -1);
+			CVMX_WRITE_CSR(CVMX_PEMX_P2P_BARX_END(i, pcie_port), -1);
 		}
 	}
 
 	/* Set Octeon's BAR0 to decode 0-16KB. It overlaps with Bar2 */
-	cvmx_write_csr(CVMX_PEMX_P2N_BAR0_START(pcie_port), 0);
+	CVMX_WRITE_CSR(CVMX_PEMX_P2N_BAR0_START(pcie_port), 0);
 
 	/* Set Octeon's BAR2 to decode 0-2^41. Bar0 and Bar1 take precedence
 	 * where they overlap. It also overlaps with the device addresses, so
 	 * make sure the peer to peer forwarding is set right
 	 */
-	cvmx_write_csr(CVMX_PEMX_P2N_BAR2_START(pcie_port), 0);
+	CVMX_WRITE_CSR(CVMX_PEMX_P2N_BAR2_START(pcie_port), 0);
 
 	/* Setup BAR2 attributes */
 	/* Relaxed Ordering (NPEI_CTL_PORTn[PTLP_RO,CTLP_RO, WAIT_COM]) */
 	/*  PTLP_RO,CTLP_RO should normally be set (except for debug). */
 	/*  WAIT_COM=0 will likely work for all applications. */
 	/* Load completion relaxed ordering (NPEI_CTL_PORTn[WAITL_COM]) */
-	pemx_bar_ctl.u64 = cvmx_read_csr(CVMX_PEMX_BAR_CTL(pcie_port));
+	pemx_bar_ctl.u64 = CVMX_READ_CSR(CVMX_PEMX_BAR_CTL(pcie_port));
 	pemx_bar_ctl.s.bar1_siz = 3;	/* 256MB BAR1 */
 	pemx_bar_ctl.s.bar2_enb = 1;
 	pemx_bar_ctl.s.bar2_esx = _CVMX_PCIE_ES;
 	pemx_bar_ctl.s.bar2_cax = 0;
-	cvmx_write_csr(CVMX_PEMX_BAR_CTL(pcie_port), pemx_bar_ctl.u64);
-	sli_ctl_portx.u64 = cvmx_read_csr(CVMX_PEXP_SLI_CTL_PORTX(pcie_port));
+	CVMX_WRITE_CSR(CVMX_PEMX_BAR_CTL(pcie_port), pemx_bar_ctl.u64);
+	sli_ctl_portx.u64 = CVMX_READ_CSR(CVMX_PEXP_SLI_CTL_PORTX(pcie_port));
 	sli_ctl_portx.s.ptlp_ro = 1;
 	sli_ctl_portx.s.ctlp_ro = 1;
 	sli_ctl_portx.s.wait_com = 0;
 	sli_ctl_portx.s.waitl_com = 0;
-	cvmx_write_csr(CVMX_PEXP_SLI_CTL_PORTX(pcie_port), sli_ctl_portx.u64);
+	CVMX_WRITE_CSR(CVMX_PEXP_SLI_CTL_PORTX(pcie_port), sli_ctl_portx.u64);
 
 	/* BAR1 follows BAR2 */
-	cvmx_write_csr(CVMX_PEMX_P2N_BAR1_START(pcie_port),
+	CVMX_WRITE_CSR(CVMX_PEMX_P2N_BAR1_START(pcie_port),
 		       CVMX_PCIE_BAR1_RC_BASE);
 
 	bar1_index.u64 = 0;
@@ -1636,22 +1650,22 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	bar1_index.s.addr_v = 1;	/* Valid entry */
 
 	for (i = 0; i < 16; i++) {
-		cvmx_write_csr(CVMX_PEMX_BAR1_INDEXX(i, pcie_port),
+		CVMX_WRITE_CSR(CVMX_PEMX_BAR1_INDEXX(i, pcie_port),
 			       bar1_index.u64);
 		/* 256MB / 16 >> 22 == 4 */
 		bar1_index.s.addr_idx += (((1ull << 28) / 16ull) >> 22);
 	}
 
 	/* Value is recommended in CSR files */
-	pemx_ctl_status.u64 = cvmx_read_csr(CVMX_PEMX_CTL_STATUS(pcie_port));
+	pemx_ctl_status.u64 = CVMX_READ_CSR(CVMX_PEMX_CTL_STATUS(pcie_port));
 	pemx_ctl_status.cn63xx.cfg_rtry = 32;
-	cvmx_write_csr(CVMX_PEMX_CTL_STATUS(pcie_port), pemx_ctl_status.u64);
+	CVMX_WRITE_CSR(CVMX_PEMX_CTL_STATUS(pcie_port), pemx_ctl_status.u64);
 
 	/* Display the link status */
-	pciercx_cfg032.u32 = cvmx_pcie_cfgx_read(pcie_port,
+	pciercx_cfg032.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 						 CVMX_PCIERCX_CFG032(pcie_port));
-	cvmx_printf("PCIe: Port %d link active, %d lanes, speed gen%d\n",
-		    pcie_port, pciercx_cfg032.s.nlw, pciercx_cfg032.s.ls);
+	cvmx_printf("%d:PCIe: Port %d link active, %d lanes, speed gen%d\n",
+		    node, pcie_port, pciercx_cfg032.s.nlw, pciercx_cfg032.s.ls);
 
 	return 0;
 }
@@ -1659,7 +1673,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 /**
  * Initialize a PCIe port for use in host(RC) mode. It doesn't enumerate the bus.
  *
- * @param pcie_port PCIe port to initialize
+ * @param pcie_port PCIe port to initialize for a node
  *
  * @return Zero on success
  */
@@ -1681,12 +1695,14 @@ int cvmx_pcie_rc_initialize(int pcie_port)
 /**
  * Shutdown a PCIe port and put it in reset
  *
- * @param pcie_port PCIe port to shutdown
+ * @param pcie_port PCIe port to shutdown for a node
  *
  * @return Zero on success
  */
 int cvmx_pcie_rc_shutdown(int pcie_port)
 {
+	int node = (pcie_port >> 4) & 0x3;
+	pcie_port &= 0x3;
 #if !defined(CVMX_BUILD_FOR_LINUX_KERNEL) || defined(CONFIG_CAVIUM_DECODE_RSL)
 	cvmx_error_disable_group(CVMX_ERROR_GROUP_PCI, pcie_port);
 #endif
@@ -1697,7 +1713,7 @@ int cvmx_pcie_rc_shutdown(int pcie_port)
 			cvmx_dprintf("PCIe: Port %d shutdown timeout\n",
 				     pcie_port);
 	} else {
-		if (CVMX_WAIT_FOR_FIELD64(CVMX_PEMX_CPL_LUT_VALID(pcie_port),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_PEMX_CPL_LUT_VALID(pcie_port),
 					  cvmx_pemx_cpl_lut_valid_t, tag, ==,
 					  0, 2000))
 			cvmx_dprintf("PCIe: Port %d shutdown timeout\n",
@@ -1707,14 +1723,14 @@ int cvmx_pcie_rc_shutdown(int pcie_port)
 	/* Force reset */
 	if (pcie_port) {
 		cvmx_ciu_soft_prst_t ciu_soft_prst;
-		ciu_soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST1);
+		ciu_soft_prst.u64 = CVMX_READ_CSR(CVMX_CIU_SOFT_PRST1);
 		ciu_soft_prst.s.soft_prst = 1;
-		cvmx_write_csr(CVMX_CIU_SOFT_PRST1, ciu_soft_prst.u64);
+		CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST1, ciu_soft_prst.u64);
 	} else {
 		cvmx_ciu_soft_prst_t ciu_soft_prst;
-		ciu_soft_prst.u64 = cvmx_read_csr(CVMX_CIU_SOFT_PRST);
+		ciu_soft_prst.u64 = CVMX_READ_CSR(CVMX_CIU_SOFT_PRST);
 		ciu_soft_prst.s.soft_prst = 1;
-		cvmx_write_csr(CVMX_CIU_SOFT_PRST, ciu_soft_prst.u64);
+		CVMX_WRITE_CSR(CVMX_CIU_SOFT_PRST, ciu_soft_prst.u64);
 	}
 	return 0;
 }
@@ -1731,7 +1747,7 @@ int cvmx_pcie_rc_shutdown(int pcie_port)
  *
  * @return 64bit Octeon IO address
  */
-static inline uint64_t __cvmx_pcie_build_config_addr(int pcie_port, int bus,
+static inline uint64_t __cvmx_pcie_build_config_addr(int node, int pcie_port, int bus,
 						     int dev, int fn, int reg)
 {
 	cvmx_pcie_address_t pcie_addr;
@@ -1747,6 +1763,7 @@ static inline uint64_t __cvmx_pcie_build_config_addr(int pcie_port, int bus,
 	pcie_addr.config.io = 1;
 	pcie_addr.config.did = 3;
 	pcie_addr.config.subdid = 1;
+	pcie_addr.config.node = node;
 	pcie_addr.config.es = _CVMX_PCIE_ES;
 	pcie_addr.config.port = pcie_port;
 	pcie_addr.config.ty = (bus > pciercx_cfg006.s.pbnum);
@@ -1770,7 +1787,10 @@ static inline uint64_t __cvmx_pcie_build_config_addr(int pcie_port, int bus,
  */
 uint8_t cvmx_pcie_config_read8(int pcie_port, int bus, int dev, int fn, int reg)
 {
-	uint64_t address = __cvmx_pcie_build_config_addr(pcie_port, bus, dev,
+	uint64_t address;
+	int node = (pcie_port >> 4) & 0x3;
+	pcie_port &= 0x3;
+	address = __cvmx_pcie_build_config_addr(node, pcie_port, bus, dev,
 							 fn, reg);
 	if (address)
 		return cvmx_read64_uint8(address);
@@ -1792,7 +1812,10 @@ uint8_t cvmx_pcie_config_read8(int pcie_port, int bus, int dev, int fn, int reg)
 uint16_t cvmx_pcie_config_read16(int pcie_port, int bus, int dev,
 				 int fn, int reg)
 {
-	uint64_t address = __cvmx_pcie_build_config_addr(pcie_port, bus, dev,
+	uint64_t address;
+	int node = (pcie_port >> 4) & 0x3;
+	pcie_port &= 0x3;
+	address = __cvmx_pcie_build_config_addr(node, pcie_port, bus, dev,
 							 fn, reg);
 	if (address)
 		return cvmx_le16_to_cpu(cvmx_read64_uint16(address));
@@ -1814,7 +1837,10 @@ uint16_t cvmx_pcie_config_read16(int pcie_port, int bus, int dev,
 uint32_t cvmx_pcie_config_read32(int pcie_port, int bus, int dev,
 				 int fn, int reg)
 {
-	uint64_t address = __cvmx_pcie_build_config_addr(pcie_port, bus, dev,
+	uint64_t address;
+	int node = (pcie_port >> 4) & 0x3;
+	pcie_port &= 0x3;
+	address = __cvmx_pcie_build_config_addr(node, pcie_port, bus, dev,
 							 fn, reg);
 	if (address)
 		return cvmx_le32_to_cpu(cvmx_read64_uint32(address));
@@ -1835,7 +1861,10 @@ uint32_t cvmx_pcie_config_read32(int pcie_port, int bus, int dev,
 void cvmx_pcie_config_write8(int pcie_port, int bus, int dev, int fn,
 			     int reg, uint8_t val)
 {
-	uint64_t address = __cvmx_pcie_build_config_addr(pcie_port, bus, dev,
+	uint64_t address;
+	int node = (pcie_port >> 4) & 0x3;
+	pcie_port &= 0x3;
+	address = __cvmx_pcie_build_config_addr(node, pcie_port, bus, dev,
 							 fn, reg);
 	if (address)
 		cvmx_write64_uint8(address, val);
@@ -1854,7 +1883,10 @@ void cvmx_pcie_config_write8(int pcie_port, int bus, int dev, int fn,
 void cvmx_pcie_config_write16(int pcie_port, int bus, int dev, int fn,
 			      int reg, uint16_t val)
 {
-	uint64_t address = __cvmx_pcie_build_config_addr(pcie_port, bus, dev,
+	uint64_t address;
+	int node = (pcie_port >> 4) & 0x3;
+	pcie_port &= 0x3;
+	address = __cvmx_pcie_build_config_addr(node, pcie_port, bus, dev,
 							 fn, reg);
 	if (address)
 		cvmx_write64_uint16(address, cvmx_cpu_to_le16(val));
@@ -1873,7 +1905,10 @@ void cvmx_pcie_config_write16(int pcie_port, int bus, int dev, int fn,
 void cvmx_pcie_config_write32(int pcie_port, int bus, int dev, int fn,
 			      int reg, uint32_t val)
 {
-	uint64_t address = __cvmx_pcie_build_config_addr(pcie_port, bus, dev,
+	uint64_t address;
+	int node = (pcie_port >> 4) & 0x3;
+	pcie_port &= 0x3;
+	address = __cvmx_pcie_build_config_addr(node, pcie_port, bus, dev,
 							 fn, reg);
 	if (address)
 		cvmx_write64_uint32(address, cvmx_cpu_to_le32(val));
@@ -1906,8 +1941,8 @@ uint32_t cvmx_pcie_cfgx_read_node(int node, int pcie_port, uint32_t cfg_offset)
 		cvmx_pemx_cfg_rd_t pemx_cfg_rd;
 		pemx_cfg_rd.u64 = 0;
 		pemx_cfg_rd.s.addr = cfg_offset;
-		cvmx_write_csr_node(node, CVMX_PEMX_CFG_RD(pcie_port), pemx_cfg_rd.u64);
-		pemx_cfg_rd.u64 = cvmx_read_csr_node(node, CVMX_PEMX_CFG_RD(pcie_port));
+		CVMX_WRITE_CSR(CVMX_PEMX_CFG_RD(pcie_port), pemx_cfg_rd.u64);
+		pemx_cfg_rd.u64 = CVMX_READ_CSR(CVMX_PEMX_CFG_RD(pcie_port));
 		return pemx_cfg_rd.s.data;
 	}
 }
@@ -1938,7 +1973,7 @@ void cvmx_pcie_cfgx_write_node(int node, int pcie_port, uint32_t cfg_offset, uin
 		pemx_cfg_wr.u64 = 0;
 		pemx_cfg_wr.s.addr = cfg_offset;
 		pemx_cfg_wr.s.data = val;
-		cvmx_write_csr_node(node, CVMX_PEMX_CFG_WR(pcie_port), pemx_cfg_wr.u64);
+		CVMX_WRITE_CSR(CVMX_PEMX_CFG_WR(pcie_port), pemx_cfg_wr.u64);
 	}
 }
 
@@ -1947,15 +1982,18 @@ extern int cvmx_pcie_is_host_mode(int pcie_port);
 /**
  * Initialize a PCIe port for use in target(EP) mode.
  *
- * @param pcie_port PCIe port to initialize
+ * @param pcie_port PCIe port to initialize for a node
  *
  * @return Zero on success
  */
 int cvmx_pcie_ep_initialize(int pcie_port)
 {
+	int node = (pcie_port >> 4) & 0x3;
 	if (cvmx_pcie_is_host_mode(pcie_port))
 		return -1;
 
+	pcie_port &= 0x3;
+
 	/* CN63XX Pass 1.0 errata G-14395 requires the QLM De-emphasis be
 	 * programmed
 	 */
@@ -1978,7 +2016,7 @@ int cvmx_pcie_ep_initialize(int pcie_port)
 	}
 
 	/* Enable bus master and memory */
-	cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIEEPX_CFG001(pcie_port), 0x6);
+	CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIEEPX_CFG001(pcie_port), 0x6);
 
 	/* Max Payload Size (PCIE*_CFG030[MPS]) */
 	/* Max Read Request Size (PCIE*_CFG030[MRRS]) */
@@ -1986,7 +2024,7 @@ int cvmx_pcie_ep_initialize(int pcie_port)
 	/* Error Message Enables (PCIE*_CFG030[CE_EN,NFE_EN,FE_EN,UR_EN]) */
 	{
 		cvmx_pcieepx_cfg030_t pcieepx_cfg030;
-		pcieepx_cfg030.u32 = cvmx_pcie_cfgx_read(pcie_port,
+		pcieepx_cfg030.u32 = CVMX_PCIE_CFGX_READ(pcie_port,
 							 CVMX_PCIEEPX_CFG030(pcie_port));
 		if (OCTEON_IS_MODEL(OCTEON_CN5XXX)) {
 			pcieepx_cfg030.s.mps = MPS_CN5XXX;
@@ -2001,7 +2039,7 @@ int cvmx_pcie_ep_initialize(int pcie_port)
 		pcieepx_cfg030.s.nfe_en = 1;	/* Non-fatal error reporting enable. */
 		pcieepx_cfg030.s.fe_en = 1;	/* Fatal error reporting enable. */
 		pcieepx_cfg030.s.ur_en = 1;	/* Unsupported request reporting enable. */
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIEEPX_CFG030(pcie_port),
+		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIEEPX_CFG030(pcie_port),
 				     pcieepx_cfg030.u32);
 	}
 
@@ -2026,16 +2064,16 @@ int cvmx_pcie_ep_initialize(int pcie_port)
 		 */
 		cvmx_dpi_sli_prtx_cfg_t prt_cfg;
 		cvmx_sli_s2m_portx_ctl_t sli_s2m_portx_ctl;
-		prt_cfg.u64 = cvmx_read_csr(CVMX_DPI_SLI_PRTX_CFG(pcie_port));
+		prt_cfg.u64 = CVMX_READ_CSR(CVMX_DPI_SLI_PRTX_CFG(pcie_port));
 		prt_cfg.s.mps = MPS_CN6XXX;
 		prt_cfg.s.mrrs = MRRS_CN6XXX;
 		/* Max outstanding load request. */
 		prt_cfg.s.molr = 32;
-		cvmx_write_csr(CVMX_DPI_SLI_PRTX_CFG(pcie_port), prt_cfg.u64);
+		CVMX_WRITE_CSR(CVMX_DPI_SLI_PRTX_CFG(pcie_port), prt_cfg.u64);
 
-		sli_s2m_portx_ctl.u64 = cvmx_read_csr(CVMX_PEXP_SLI_S2M_PORTX_CTL(pcie_port));
+		sli_s2m_portx_ctl.u64 = CVMX_READ_CSR(CVMX_PEXP_SLI_S2M_PORTX_CTL(pcie_port));
 		sli_s2m_portx_ctl.cn61xx.mrrs = MRRS_CN6XXX;
-		cvmx_write_csr(CVMX_PEXP_SLI_S2M_PORTX_CTL(pcie_port), sli_s2m_portx_ctl.u64);
+		CVMX_WRITE_CSR(CVMX_PEXP_SLI_S2M_PORTX_CTL(pcie_port), sli_s2m_portx_ctl.u64);
 	}
 
 	/* Setup Mem access SubDID 12 to access Host memory */
@@ -2066,7 +2104,7 @@ int cvmx_pcie_ep_initialize(int pcie_port)
 			mem_access_subid.cn68xx.ba = 0;
 		else
 			mem_access_subid.cn63xx.ba = 0;
-		cvmx_write_csr(CVMX_PEXP_SLI_MEM_ACCESS_SUBIDX(12 + pcie_port * 4), mem_access_subid.u64);
+		CVMX_WRITE_CSR(CVMX_PEXP_SLI_MEM_ACCESS_SUBIDX(12 + pcie_port * 4), mem_access_subid.u64);
 	}
 	return 0;
 }
@@ -2157,9 +2195,11 @@ void cvmx_pcie_wait_for_pending(int pcie_port)
  */
 int cvmx_pcie_is_host_mode(int pcie_port)
 {
+	int node = (pcie_port >> 4) & 0x3;
+	pcie_port &= 0x3;
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		cvmx_pemx_strap_t strap;
-		strap.u64 = cvmx_read_csr(CVMX_PEMX_STRAP(pcie_port));
+		strap.u64 = CVMX_READ_CSR(CVMX_PEMX_STRAP(pcie_port));
 		return (strap.cn78xx.pimode != 3);
 	} else if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
 		cvmx_rst_ctlx_t rst_ctl;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
index 52c2167..e1f7192 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
@@ -1261,6 +1261,12 @@ void cvmx_pko3_dq_red(unsigned node, unsigned dq_num, red_action_t red_act,
 	dq_num &= (1<<10)-1;
 
 	dqx_shape.u64 = 0;
+
+        if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
+		if (len_adjust < 0)
+			len_adjust = 0;
+	}
+
         dqx_shape.s.adjust = len_adjust;
 
 	switch(red_act) {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
index 487471e..b421905 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
@@ -1156,8 +1156,10 @@ int cvmx_pko3_pdesc_from_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
 	hdr_s->s.format = 0;	/* Only 0 works for Pass1 */
 	hdr_s->s.ds = 0;	/* don't send, never used */
 
-	/* TODO: n2 is not currently supported in simulator */
-	hdr_s->s.n2 = 0;	/* No L2 allocate */
+        if(OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X))
+		hdr_s->s.n2 = 0;	/* L2 allocate everything */
+	else
+		hdr_s->s.n2 = 1;	/* No L2 allocate works faster */
 
 	/* Default buffer freeing setting, may be overriden by "i" */
 	hdr_s->s.df = !free_bufs;
@@ -1378,6 +1380,31 @@ int cvmx_pko3_pdesc_transmit(cvmx_pko3_pdesc_t *pdesc, uint16_t dq)
 	return -1;
 }
 
+int cvmx_pko3_pdesc_append_free(cvmx_pko3_pdesc_t *pdesc, uint64_t addr,
+			     unsigned gaura)
+{
+	cvmx_pko_send_free_t free_s;
+	cvmx_pko_send_aura_t aura_s;
+
+	if (pdesc->last_aura != (short) gaura) {	
+		aura_s.s.aura = gaura;
+		aura_s.s.offset = 0;
+		aura_s.s.alg = AURAALG_NOP;
+		aura_s.s.subdc4 = CVMX_PKO_SENDSUBDC_AURA;
+		pdesc->last_aura = gaura;
+		if (cvmx_pko3_pdesc_subdc_add(pdesc, aura_s.u64) < 0)
+			return -1;
+	}
+
+	free_s.u64 = 0;
+	free_s.s.subdc4 = CVMX_PKO_SENDSUBDC_FREE;
+	free_s.s.addr = addr;
+	if (pdesc->last_aura == -1)
+		pdesc->last_aura = gaura;
+
+	return cvmx_pko3_pdesc_subdc_add(pdesc, free_s.u64);
+}
+
 /**
  * Append a packet segment to a packet descriptor
  *
diff --git a/arch/mips/cavium-octeon/executive/cvmx-qlm.c b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
index 80c2858..c36ed9f 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-qlm.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 103883 $<hr>
+ * <hr>$Revision: 105514 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -293,7 +293,7 @@ void cvmx_qlm_init(void)
 	int qlm;
 	int qlm_jtag_length;
 	char *qlm_jtag_name = "cvmx_qlm_jtag";
-	int qlm_jtag_size = CVMX_QLM_JTAG_UINT32 * 8 * sizeof(uint32_t);
+	int qlm_jtag_size = CVMX_QLM_JTAG_UINT32 * 8 * sizeof(uint32_t) * 5;
 	static uint64_t qlm_base = 0;
 	const cvmx_bootmem_named_block_desc_t *desc;
 
diff --git a/arch/mips/cavium-octeon/executive/octeon-model.c b/arch/mips/cavium-octeon/executive/octeon-model.c
index af95856..008c7c7 100644
--- a/arch/mips/cavium-octeon/executive/octeon-model.c
+++ b/arch/mips/cavium-octeon/executive/octeon-model.c
@@ -43,7 +43,7 @@
  * File defining functions for working with different Octeon
  * models.
  *
- * <hr>$Revision: 102057 $<hr>
+ * <hr>$Revision: 105060 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/octeon.h>
@@ -188,6 +188,12 @@ const char *octeon_model_get_string_buffer(uint32_t chip_id, char *buffer)
 	case 48:
 		core_model = "90";
 		break;
+	case 44:
+		core_model = "88";
+		break;
+	case 40:
+		core_model = "85";
+		break;
 	case 32:
 		core_model = "80";
 		break;
@@ -442,8 +448,18 @@ const char *octeon_model_get_string_buffer(uint32_t chip_id, char *buffer)
 			family = "77";
 		if (fus_dat3.cn78xx.nozip
 		    && fus_dat3.cn78xx.nodfa_dte
-		    && fus_dat3.cn78xx.nohna_dte)
-			suffix = "SCP";
+		    && fus_dat3.cn78xx.nohna_dte) {
+			if (fus_dat3.cn78xx.nozip && 
+				!fus_dat2.cn78xx.raid_en &&
+				fus_dat3.cn78xx.nohna_dte) {
+				suffix = "CP";
+			}
+			else {
+				suffix = "SCP";
+			}
+		}
+		else if (fus_dat2.cn78xx.raid_en == 0)
+			suffix = "HCP";
 		else
 			suffix = "AAP";
 		break;
diff --git a/arch/mips/include/asm/octeon/cvmx-app-config.h b/arch/mips/include/asm/octeon/cvmx-app-config.h
index 75dd539..de8424a 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-config.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-config.h
@@ -89,6 +89,8 @@ int __cvmx_import_app_config_from_named_block(char * block_name);
  */
 void __cvmx_export_app_config_cleanup(void);
 
+int __cvmx_export_config(void);
+
 #ifdef  __cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-app-init.h b/arch/mips/include/asm/octeon/cvmx-app-init.h
index f3eb084..dbe212e 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-init.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-init.h
@@ -41,7 +41,7 @@
  * @file
  * Header file for simple executive application initialization.  This defines
  * part of the ABI between the bootloader and the application.
- * <hr>$Revision: 101905 $<hr>
+ * <hr>$Revision: 105233 $<hr>
  *
  */
 
@@ -280,8 +280,14 @@ enum cvmx_board_types_enum {
 	CVMX_BOARD_TYPE_NIC401NVG = 62,
 	CVMX_BOARD_TYPE_NIC210NVG = 63,
 	CVMX_BOARD_TYPE_SFF7000 = 64,
-	CVMX_BOARD_TYPE_EBB7800_CFG1 = 65,
+	CVMX_BOARD_TYPE_EBB7800_CFG1 = 65, /* Only required to support cn78xx p1.0 */
 	CVMX_BOARD_TYPE_TB7600 = 66,
+	CVMX_BOARD_TYPE_EBB7804 = 67,
+	CVMX_BOARD_TYPE_EBB7804_CFG1 = 68, /* Only required to support cn78xx p1.0 */
+	CVMX_BOARD_TYPE_TB7000 = 69,
+	CVMX_BOARD_TYPE_EBB7800_CFG0 = 70, /* Only required to support cn78xx p1.0 */
+	CVMX_BOARD_TYPE_EBB7804_CFG0 = 71, /* Only required to support cn78xx p1.0 */
+	CVMX_BOARD_TYPE_SWORDFISH = 72,
 	CVMX_BOARD_TYPE_MAX,
 	/* NOTE:  256-257 are being used by a customer. */
 
@@ -416,6 +422,12 @@ static inline const char *cvmx_board_type_to_string(enum cvmx_board_types_enum t
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SFF7000)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB7800_CFG1)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_TB7600)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB7804)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB7804_CFG1)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_TB7000)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB7800_CFG0)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB7804_CFG0)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SWORDFISH)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MAX)
 
 		/* Customer boards listed here */
diff --git a/arch/mips/include/asm/octeon/cvmx-l2c.h b/arch/mips/include/asm/octeon/cvmx-l2c.h
index f89ab21..7e107d0 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2c.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2c.h
@@ -43,7 +43,7 @@
  * Interface to the Level 2 Cache (L2C) control, measurement, and debugging
  * facilities.
  *
- * <hr>$Revision: 92683 $<hr>
+ * <hr>$Revision: 105520 $<hr>
  *
  */
 
@@ -376,8 +376,8 @@ int cvmx_l2c_unlock_mem_region(uint64_t start, uint64_t len);
  * @param index  Which way to read from.
  *
  * @return l2c tag structure for line requested.
- * 
- * NOTE: This function is deprecated and cannot be used on devices with 
+ *
+ * NOTE: This function is deprecated and cannot be used on devices with
  *       multiple L2C interfaces such as the OCTEON CN68XX.
  *       Please use cvmx_l2c_get_tag_v2 instead.
  */
@@ -391,7 +391,7 @@ cvmx_l2c_tag_t cvmx_l2c_get_tag(uint32_t association, uint32_t index)
  * @param association
  *               Which association to read line from
  * @param index  Which way to read from.
- * 
+ *
  * @param tad    Which TAD to read from, set to 0 except on OCTEON CN68XX.
  *
  * @return l2c tag structure for line requested.
@@ -402,7 +402,7 @@ cvmx_l2c_tag_t cvmx_l2c_get_tag_v2(uint32_t association, uint32_t index, uint32_
  * Find the TAD for the specified address
  *
  * @param addr   physical address to get TAD for
- * 
+ *
  * @return TAD number for address.
  */
 int cvmx_l2c_address_to_tad(uint64_t addr);
@@ -433,6 +433,14 @@ uint32_t cvmx_l2c_v2_address_to_tag(uint64_t addr);
 void cvmx_l2c_flush(void);
 
 /**
+ * Flushes (and unlocks) the entire L2 cache.  Unlike cvmx_l2c_flush this
+ * function also flushes and unlocks the remote L2 cache.
+ * IMPORTANT: Must only be run by one core at a time due to use
+ * of L2C debug features.
+ */
+void cvmx_l2c_flush_ocx(void);
+
+/**
  *
  * @return Returns the size of the L2 cache in bytes,
  * -1 on error (unrecognized model)
@@ -451,6 +459,7 @@ int cvmx_l2c_get_num_sets(void);
  * @return
  */
 int cvmx_l2c_get_set_bits(void);
+
 /**
  * Return the number of associations in the L2 Cache
  *
@@ -470,13 +479,23 @@ void cvmx_l2c_flush_line(uint32_t assoc, uint32_t index);
 
 /**
  * Initialize the BIG address in L2C+DRAM to generate proper error
- * on reading/writing to an non-existant memory location. 
+ * on reading/writing to an non-existant memory location.
  *
  * @param mem_size  Amount of DRAM configured in MB.
  * @param mode      Allow/Disallow reporting errors L2C_INT_SUM[BIGRD,BIGWR].
  */
 void cvmx_l2c_set_big_size(uint64_t mem_size, int mode);
 
+/**
+ * Initialize the BIG address in L2C+DRAM to generate proper error
+ * on reading/writing to an non-existant memory location.
+ *
+ * @param node      OCX CPU node number
+ * @param mem_size  Amount of DRAM configured in MB.
+ * @param mode      Allow/Disallow reporting errors L2C_INT_SUM[BIGRD,BIGWR].
+ */
+void cvmx_l2c_set_big_size_node(int node, uint64_t mem_size, int mode);
+
 #if !defined(CVMX_BUILD_FOR_LINUX_HOST) && !defined(CVMX_BUILD_FOR_LINUX_KERNEL)
 
 /*
diff --git a/arch/mips/include/asm/octeon/cvmx-pcie.h b/arch/mips/include/asm/octeon/cvmx-pcie.h
index 69440b0..093c132 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcie.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcie.h
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 102522 $<hr>
+ * <hr>$Revision: 104992 $<hr>
  */
 
 #ifndef __CVMX_PCIE_H__
@@ -89,7 +89,8 @@ typedef union {
 		uint64_t io:1;	/* 1 for IO space access */
 		uint64_t did:5;	/* PCIe DID = 3 */
 		uint64_t subdid:3;	/* PCIe SubDID = 1 */
-		uint64_t reserved_36_39:4;	/* Must be zero */
+		uint64_t reserved_38_39:2;	/* Must be zero */
+		uint64_t node:2;		/* Numa node number */
 		uint64_t es:2;	/* Endian swap = 1 */
 		uint64_t port:2;	/* PCIe port 0,1 */
 		uint64_t reserved_29_31:3;	/* Must be zero */
@@ -106,7 +107,8 @@ typedef union {
 		uint64_t io:1;	/* 1 for IO space access */
 		uint64_t did:5;	/* PCIe DID = 3 */
 		uint64_t subdid:3;	/* PCIe SubDID = 2 */
-		uint64_t reserved_36_39:4;	/* Must be zero */
+		uint64_t reserved_38_39:4;	/* Must be zero */
+		uint64_t node:2;		/* Numa node number */
 		uint64_t es:2;	/* Endian swap = 1 */
 		uint64_t port:2;	/* PCIe port 0,1 */
 		uint64_t address:32;	/* PCIe IO address */
@@ -117,7 +119,8 @@ typedef union {
 		uint64_t io:1;	/* 1 for IO space access */
 		uint64_t did:5;	/* PCIe DID = 3 */
 		uint64_t subdid:3;	/* PCIe SubDID = 3-6 */
-		uint64_t reserved_36_39:4;	/* Must be zero */
+		uint64_t reserved_38_39:2;	/* Must be zero */
+		uint64_t node:2;		/* Numa node number */
 		uint64_t address:36;	/* PCIe Mem address */
 	} mem;
 #else
@@ -130,7 +133,8 @@ typedef union {
 		uint64_t reserved_29_31:3;
 		uint64_t port:2;
 		uint64_t es:2;
-		uint64_t reserved_36_39:4;
+		uint64_t node:2;
+		uint64_t reserved_38_39:4;
 		uint64_t subdid:3;
 		uint64_t did:5;
 		uint64_t io:1;
@@ -141,7 +145,8 @@ typedef union {
 		uint64_t address:32;
 		uint64_t port:2;
 		uint64_t es:2;
-		uint64_t reserved_36_39:4;
+		uint64_t node:2;
+		uint64_t reserved_38_39:4;
 		uint64_t subdid:3;
 		uint64_t did:5;
 		uint64_t io:1;
@@ -150,7 +155,8 @@ typedef union {
 	} io;
 	struct {
 		uint64_t address:36;
-		uint64_t reserved_36_39:4;
+		uint64_t node:2;
+		uint64_t reserved_38_39:4;
 		uint64_t subdid:3;
 		uint64_t did:5;
 		uint64_t io:1;
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-cluster.h b/arch/mips/include/asm/octeon/cvmx-pki-cluster.h
index 15541a1..186ec45 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-cluster.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-cluster.h
@@ -1,4 +1,4 @@
-/* This file is autgenerated from obj/ipemainc.elf */
+/* This file is autogenerated from obj/ipemainc.elf */
 const int cvmx_pki_cluster_code_length = 673;
 const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000000000a000000ull,
diff --git a/arch/mips/include/asm/octeon/cvmx-wqe.h b/arch/mips/include/asm/octeon/cvmx-wqe.h
index aba88f3..52eb9e3 100644
--- a/arch/mips/include/asm/octeon/cvmx-wqe.h
+++ b/arch/mips/include/asm/octeon/cvmx-wqe.h
@@ -1079,7 +1079,7 @@ static inline void cvmx_wqe_set_xgrp(cvmx_wqe_t *work, int grp)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		work->word1.cn78xx.grp = grp;
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
+	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		work->word1.cn68xx.grp = grp;
 	else
 		work->word1.cn38xx.grp = grp;
@@ -1395,13 +1395,32 @@ static inline int cvmx_wqe_is_l2_mcast(cvmx_wqe_t *work)
 		return (work->word2.s_cn38xx.is_mcast);
 }
 
+static inline void cvmx_wqe_set_l2_bcast(cvmx_wqe_t *work, bool bcast)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		wqe->word2.is_l2_bcast = bcast;
+	} else
+		work->word2.s_cn38xx.is_bcast = bcast;
+}
+
+static inline void cvmx_wqe_set_l2_mcast(cvmx_wqe_t *work, bool mcast)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		wqe->word2.is_l2_mcast = mcast;
+	} else
+		work->word2.s_cn38xx.is_mcast = mcast;
+}
+
 static inline int cvmx_wqe_is_l3_bcast(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
 		return (wqe->word2.is_l3_bcast);
-	} else
-		cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
+	}
+	cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
+	return 0;
 }
 
 static inline int cvmx_wqe_is_l3_mcast(cvmx_wqe_t *work)
@@ -1409,8 +1428,9 @@ static inline int cvmx_wqe_is_l3_mcast(cvmx_wqe_t *work)
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)){
 		cvmx_wqe_78xx_t* wqe = (void *)work;
 		return (wqe->word2.is_l3_mcast);
-	} else
-		cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
+	}
+	cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
+	return 0;
 }
 
 /**
-- 
2.6.2

