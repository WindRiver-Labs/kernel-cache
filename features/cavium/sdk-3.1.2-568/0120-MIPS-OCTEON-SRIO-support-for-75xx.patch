From 49f91b24f59b010b888ada7dd87c3e1fef279fd8 Mon Sep 17 00:00:00 2001
From: Carlos Munoz <cmunoz@caviumnetworks.com>
Date: Fri, 15 May 2015 16:37:51 -0700
Subject: [PATCH 120/184] MIPS: OCTEON: SRIO support for 75xx.

Source: Cavium Networks, Inc.
MR: 00000
Type: Integration
Disposition: Merged from Octeon Tree
ChangeID: c674e43cc3804b9889b7685b73513c7fc84e0e71
Description:

Signed-off-by: Carlos Munoz <cmunoz@caviumnetworks.com>
Signed-off-by: Corey Minyard <cminyard@mvista.com>
[Original patch taken from octeon-linux-kernel-patches-SDK-3.1.2-release]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/cavium-octeon/octeon-rapidio.c | 615 ++++++++++++++++++++++++-------
 1 file changed, 483 insertions(+), 132 deletions(-)

diff --git a/arch/mips/cavium-octeon/octeon-rapidio.c b/arch/mips/cavium-octeon/octeon-rapidio.c
index 80976de..600987d2 100644
--- a/arch/mips/cavium-octeon/octeon-rapidio.c
+++ b/arch/mips/cavium-octeon/octeon-rapidio.c
@@ -38,16 +38,40 @@
 
 #define OCTEON_RIO_ID 0 /* Which source ID to use. 0=Primary, 1=Secondary */
 #define OCTEON_RIO_DOORBELL_PRIORITY 0 /* Priority for sent doorbells (0-3) */
+#define MAX_SRIO_PORTS			4
+
+#define SRIO_75XX_INTS			6
+#define SRIO_MAX_INTS			SRIO_75XX_INTS
+#define SRIO_INTSN_E			0xc8
+#define SRIO_INT_NAME_LEN		32
+
+struct octeon_srio_port_ints {
+	int			mport_id;
+	int			intsn;
+	int			irq;
+	char			name[SRIO_INT_NAME_LEN];
+	struct work_struct	work;
+};
 
-struct octeon_rio_port {
-	struct rio_mport mport;
-	struct work_struct work;
-	spinlock_t lock;
+struct octeon_srio_port {
+	struct rio_mport		mport;
+	spinlock_t			lock;
+	int				qlm;
+	int				num_ints;
+	struct octeon_srio_port_ints	ints[SRIO_MAX_INTS];
 };
 
-static struct octeon_rio_port * mport2oct(struct rio_mport *mport)
+static struct octeon_srio_port srio_ports[MAX_SRIO_PORTS];
+
+/* Pool/aura used by the dma engine */
+static cvmx_fpa3_pool_t cmd_pool;
+static cvmx_fpa3_gaura_t cmd_aura;
+static void *cmd_pool_stack;
+static struct kmem_cache *cmd_pool_cache;
+
+static struct octeon_srio_port * mport2oct(struct rio_mport *mport)
 {
-	return container_of(mport, struct octeon_rio_port, mport);
+	return container_of(mport, struct octeon_srio_port, mport);
 }
 
 /**
@@ -606,28 +630,15 @@ static void octeon_rio_tx_doorbell(struct rio_mport *mport)
  */
 static void octeon_rio_irq_set_enable(struct rio_mport *mport, int enable)
 {
-	union cvmx_sriox_int_enable int_enable;
-	/* Enable the interrupts we care about */
-	int_enable.u64 = cvmx_read_csr(CVMX_SRIOX_INT_ENABLE(mport->id));
-	SET_IRQ_FIELD_BITS(int_enable, enable);
-	cvmx_write_csr(CVMX_SRIOX_INT_ENABLE(mport->id), int_enable.u64);
-}
-
-/**
- * Translate an SRIO master port ID to Octeon IRQ number.
- *
- * @mport:  SRIO master port
- *
- * Returns IRQ number. -1 if mismatch.
- */
-static int octeon_rio_mport2irq(struct rio_mport *mport)
-{
-	switch (mport->id) {
-	case 0: return OCTEON_IRQ_SRIO0;
-	case 1: return OCTEON_IRQ_SRIO1;
-	case 2: return OCTEON_IRQ_SRIO2;
-	case 3: return OCTEON_IRQ_SRIO3;
-	default: return -1;
+	/* The 75xx interrupts are enabled via the ciu */
+	if (!OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		union cvmx_sriox_int_enable int_enable;
+		/* Enable the interrupts we care about */
+		int_enable.u64 =
+			cvmx_read_csr(CVMX_SRIOX_INT_ENABLE(mport->id));
+		SET_IRQ_FIELD_BITS(int_enable, enable);
+		cvmx_write_csr(CVMX_SRIOX_INT_ENABLE(mport->id),
+			       int_enable.u64);
 	}
 }
 
@@ -638,12 +649,15 @@ static int octeon_rio_mport2irq(struct rio_mport *mport)
  */
 static void octeon_rio_work(struct work_struct *work)
 {
-	struct octeon_rio_port *my_port = container_of(work,
-						       struct octeon_rio_port,
-						       work);
-	struct rio_mport *mport = &my_port->mport;
-	union cvmx_sriox_int_reg int_reg;
-	union cvmx_sriox_int_reg int_reg_clear;
+	struct octeon_srio_port_ints	*port_int;
+	struct octeon_srio_port		*sport;
+	struct rio_mport		*mport;
+	union cvmx_sriox_int_reg	int_reg;
+	union cvmx_sriox_int_reg	int_reg_clear;
+
+	port_int = container_of(work, struct octeon_srio_port_ints, work);
+	sport = &srio_ports[port_int->mport_id];
+	mport = &sport->mport;
 
 	/* Get which interrupt fired */
 	int_reg.u64 = cvmx_read_csr(CVMX_SRIOX_INT_REG(mport->id));
@@ -682,11 +696,96 @@ static void octeon_rio_work(struct work_struct *work)
 	if (int_reg.s.bell_err || int_reg.s.txbell)
 		octeon_rio_tx_doorbell(mport);
 
-	enable_irq(octeon_rio_mport2irq(mport));
+	enable_irq(sport->ints[0].irq);
 	octeon_rio_irq_set_enable(mport, 1);
 }
 
 /**
+ * Delayed work to handle outgoing doorbell complete interrupts.
+ *
+ * @work:   Work to process.
+ */
+static void octeon_rio_txbell_work(struct work_struct *work)
+{
+	struct octeon_srio_port_ints	*port_int;
+
+	port_int = container_of(work, struct octeon_srio_port_ints, work);
+	octeon_rio_tx_doorbell(&srio_ports[port_int->mport_id].mport);
+	enable_irq(port_int->irq);
+}
+
+/**
+ * Delayed work to handle outgoing doorbell timeout interrupts.
+ *
+ * @work:   Work to process.
+ */
+static void octeon_rio_bell_err_work(struct work_struct *work)
+{
+	struct octeon_srio_port_ints	*port_int;
+
+	port_int = container_of(work, struct octeon_srio_port_ints, work);
+	octeon_rio_tx_doorbell(&srio_ports[port_int->mport_id].mport);
+	enable_irq(port_int->irq);
+}
+
+/**
+ * Delayed work to handle incoming doorbell received interrupt.
+ *
+ * @work:   Work to process.
+ */
+static void octeon_rio_rxbell_work(struct work_struct *work)
+{
+	struct octeon_srio_port_ints	*port_int;
+
+	port_int = container_of(work, struct octeon_srio_port_ints, work);
+	octeon_rio_rx_doorbell(&srio_ports[port_int->mport_id].mport);
+	enable_irq(port_int->irq);
+}
+
+/**
+ * Delayed work to handle incoming packet received by soft packet FIFO
+ * interrupt.
+ *
+ * @work:   Work to process.
+ */
+static void octeon_rio_soft_rx_work(struct work_struct *work)
+{
+	struct octeon_srio_port_ints	*port_int;
+
+	port_int = container_of(work, struct octeon_srio_port_ints, work);
+	octeon_rio_rx_soft_fifo(&srio_ports[port_int->mport_id].mport);
+	enable_irq(port_int->irq);
+}
+
+/**
+ * Delayed work to handle link going from active to inactive interrupt.
+ *
+ * @work:   Work to process.
+ */
+static void octeon_rio_link_down_work(struct work_struct *work)
+{
+	struct octeon_srio_port_ints	*port_int;
+
+	port_int = container_of(work, struct octeon_srio_port_ints, work);
+	DEBUG_IRQ(&srio_ports[port_int->mport_id].mport, "Link down\n");
+	enable_irq(port_int->irq);
+}
+
+/**
+ * Delayed work to handle oink going from inactive to active interrupt.
+ *
+ * @work:   Work to process.
+ */
+static void octeon_rio_link_up_work(struct work_struct *work)
+{
+	struct octeon_srio_port_ints	*port_int;
+
+	port_int = container_of(work, struct octeon_srio_port_ints, work);
+	DEBUG_IRQ(&srio_ports[port_int->mport_id].mport, "Link up\n");
+	enable_irq(port_int->irq);
+}
+
+/**
  * Interrupt handler for SRIO.
  *
  * @irq:     IRQ number
@@ -696,29 +795,330 @@ static void octeon_rio_work(struct work_struct *work)
  */
 static irqreturn_t octeon_rio_irq(int irq, void *irq_arg)
 {
-	struct rio_mport *mport = (struct rio_mport *)irq_arg;
-	struct octeon_rio_port *my_port = container_of(mport,
-						       struct octeon_rio_port,
-						       mport);
+	struct octeon_srio_port_ints	*ints;
+	struct rio_mport		*mport;
+
+	ints = (struct octeon_srio_port_ints *)irq_arg;
+	mport = &srio_ports[ints->mport_id].mport;
 
 	octeon_rio_irq_set_enable(mport, 0);
 	disable_irq_nosync(irq);
-	schedule_work(&my_port->work);
+
+	/* Defer the work for later */
+	schedule_work(&ints->work);
+
 	return IRQ_HANDLED;
 }
 
-extern int cvm_oct_mem_fill_fpa(int pool, int elements);
-extern int cvm_oct_alloc_fpa_pool(int pool, int size);
-
 static struct rio_ops octeon_rio_ops = {
-	.lcread = octeon_rio_lcread,
-	.lcwrite = octeon_rio_lcwrite,
-	.cread = octeon_rio_cread,
-	.cwrite = octeon_rio_cwrite,
-	.dsend = octeon_rio_dsend,
+	.lcread			= octeon_rio_lcread,
+	.lcwrite		= octeon_rio_lcwrite,
+	.cread			= octeon_rio_cread,
+	.cwrite			= octeon_rio_cwrite,
+	.dsend			= octeon_rio_dsend,
+	.add_outb_message	= rio_hw_add_outb_message,
+	.add_inb_buffer		= rio_hw_add_inb_buffer,
+	.get_inb_message	= rio_hw_get_inb_message,
 };
 
-static struct octeon_rio_port srio_ports[4];
+/**
+ * Verify the srio port is supported by the hardware.
+ *
+ * @srio_port:	Srio port to validate
+ *
+ * Returns One on success, zero on failure.
+ */
+static int octeon_is_srio_port_valid(int srio_port)
+{
+	int	rc = 1;
+
+	/*
+	 * The 66xx suports up to 3 srio ports. The number of srio ports
+	 * supported depends on the qlm configuration. Note that port 1 is
+	 * not supported.
+	 */
+	if (OCTEON_IS_MODEL(OCTEON_CN66XX)) {
+		enum cvmx_qlm_mode mode = cvmx_qlm_get_mode(0);
+
+		switch (srio_port) {
+		case 0:
+			/* Port 0 can be used for these configurations */
+			if (mode != CVMX_QLM_MODE_SRIO_1X4 &&
+			    mode != CVMX_QLM_MODE_SRIO_2X2 &&
+			    mode != CVMX_QLM_MODE_SRIO_4X1)
+				rc = 0;
+			break;
+		case 2:
+			/* Port 1 can be used for these configurations */
+			if (mode != CVMX_QLM_MODE_SRIO_2X2 &&
+			    mode != CVMX_QLM_MODE_SRIO_4X1)
+				rc = 0;
+			break;
+		case 3:
+			/* Port 3 can be used for these configurations */
+			if (mode != CVMX_QLM_MODE_SRIO_4X1)
+				rc = 0;
+			break;
+		default:
+			rc = 0;
+		}
+	} else {
+		union cvmx_sriox_status_reg	status;
+
+		/* All other socs support 2 ports */
+		if (srio_port < 0 || srio_port > 1)
+			rc = 0;
+		else {
+			/* Make sure the port is configured for srio */
+			status.u64 =
+				cvmx_read_csr(CVMX_SRIOX_STATUS_REG(srio_port));
+			if (!status.s.srio)
+				rc = 0;
+		}
+	}
+
+	return rc;
+}
+
+/**
+ * Initialize the srio_ports[] structure.
+ *
+ * @srio_port:	Srio port to initialize.
+ *
+ * Returns Zero on success, error otherwise.
+ */
+static void octeon_srio_ports_init(int srio_port)
+{
+	struct octeon_srio_port *sport;
+	int			host;
+
+	sport = &srio_ports[srio_port];
+
+	if (OCTEON_IS_MODEL(OCTEON_CN66XX)) {
+		/* All srio ports connect to qlm0 */
+		sport->qlm = 0;
+	} else if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		/* srio0 ---> qlm2, srio1 ---> qlm3 */
+		sport->qlm = srio_port + 2;
+	} else {
+		/* One to one mapping */
+		sport->qlm = srio_port;
+	}
+
+	/* Get the mode (host or endpoint) the srio port is configured as */
+	if (OCTEON_IS_MODEL(OCTEON_CNF75XX)) {
+		cvmx_rst_ctlx_t		rst_ctl;
+
+		rst_ctl.u64 = cvmx_read_csr(CVMX_RST_CTLX(sport->qlm));
+		host = rst_ctl.s.host_mode;
+	} else {
+		union cvmx_mio_rst_ctlx	mio_rst_ctl;
+
+		mio_rst_ctl.u64 = cvmx_read_csr(CVMX_MIO_RST_CNTLX(sport->qlm));
+		host = mio_rst_ctl.s.prtmode;
+	}
+
+	/* Only host mode ports enumerate. Endpoint does discovery */
+	if (host)
+		sport->mport.host_deviceid = srio_port;
+	else
+		sport->mport.host_deviceid = -1;
+
+	sport->mport.ops = &octeon_rio_ops;
+	sport->mport.id = srio_port;
+	sport->mport.index = 0;
+	sport->mport.sys_size = 0;
+	sport->mport.iores.start =
+		CVMX_SRIOX_STATUS_REG(srio_port) & ((1ull << 49) - 1);
+	sport->mport.iores.end = sport->mport.iores.start + 256;
+	sport->mport.iores.flags = IORESOURCE_MEM;
+	sport->mport.iores.name = "SRIO CSRs";
+	sport->mport.phy_type = RIO_PHY_SERIAL;
+
+	INIT_LIST_HEAD(&sport->mport.dbells);
+	rio_init_dbell_res(&sport->mport.riores[RIO_DOORBELL_RESOURCE], 0,
+			   0xffff);
+	rio_init_mbox_res(&sport->mport.riores[RIO_INB_MBOX_RESOURCE], 0, 0);
+	rio_init_mbox_res(&sport->mport.riores[RIO_OUTB_MBOX_RESOURCE], 0, 0);
+	sprintf(sport->mport.name, "SRIO%d", srio_port);
+	spin_lock_init(&sport->lock);
+	RIO_PRINTK(&sport->mport, "Registering port\n");
+}
+
+/**
+ * Configure the srio interrupts for a given 75xx port.
+ *
+ * @srio_port:	Srio port to initialize.
+ */
+static void octeon_srio_interrupt_75xx_cfg(int srio_port)
+{
+	struct octeon_srio_port 	*sport;
+	struct irq_domain		*domain;
+	struct octeon_srio_port_ints	*ints;
+	char				name[SRIO_INT_NAME_LEN];
+	int				len;
+	int				i;
+
+	sport = &srio_ports[srio_port];
+	sport->num_ints = SRIO_75XX_INTS;
+	ints = sport->ints;
+
+	/* Each port uses several interrupts */
+	for (i = 0; i < SRIO_75XX_INTS; i++) {
+		strncpy(name, sport->mport.name, SRIO_INT_NAME_LEN);
+		name[SRIO_INT_NAME_LEN - 1] = 0;
+		len = SRIO_INT_NAME_LEN - strlen(name) - 1;
+		strncat(name, "-", len);
+		len = SRIO_INT_NAME_LEN - strlen(name) - 1;
+
+		switch (i) {
+		case 0:
+			ints[i].intsn = srio_port ? 0xc9000 : 0xc8000;
+			strncat(name, "TXBELL", len);
+			strcpy(ints[i].name, name);
+			INIT_WORK(&sport->ints[i].work, octeon_rio_txbell_work);
+			break;
+		case 1:
+			ints[i].intsn = srio_port ? 0xc9001 : 0xc8001;
+			strncat(name, "BELL_ERR", len);
+			strcpy(ints[i].name, name);
+			INIT_WORK(&sport->ints[i].work,
+				  octeon_rio_bell_err_work);
+			break;
+		case 2:
+			ints[i].intsn = srio_port ? 0xc9002 : 0xc8002;
+			strncat(name, "RXBELL", len);
+			strcpy(ints[i].name, name);
+			INIT_WORK(&sport->ints[i].work, octeon_rio_rxbell_work);
+			break;
+		case 3:
+			ints[i].intsn = srio_port ? 0xc900b : 0xc800b;
+			strncat(name, "SOFT_RX", len);
+			strcpy(ints[i].name, name);
+			INIT_WORK(&sport->ints[i].work,
+				  octeon_rio_soft_rx_work);
+			break;
+		case 4:
+			ints[i].intsn = srio_port ? 0xc900e : 0xc800e;
+			strncat(name, "LINK_DWN", len);
+			strcpy(ints[i].name, name);
+			INIT_WORK(&sport->ints[i].work,
+				  octeon_rio_link_down_work);
+			break;
+		case 5:
+			ints[i].intsn = srio_port ? 0xc900f : 0xc800f;
+			strncat(name, "LINK_UP", len);
+			strcpy(ints[i].name, name);
+			INIT_WORK(&sport->ints[i].work,
+				  octeon_rio_link_up_work);
+			break;
+		}
+
+		ints[i].mport_id = srio_port;
+		domain = octeon_irq_get_block_domain(0, SRIO_INTSN_E);
+		ints[i].irq = irq_create_mapping(domain, ints[i].intsn);
+	}
+}
+
+/**
+ * Configure the srio interrupts for a given port.
+ *
+ * @srio_port:	Srio port to initialize.
+ */
+static void octeon_srio_interrupt_cfg(int srio_port)
+{
+	struct octeon_srio_port 	*sport;
+	struct octeon_srio_port_ints	*ints;
+
+	sport = &srio_ports[srio_port];
+	sport->num_ints = 1;
+	ints = sport->ints;
+
+	/* Each port uses a single irq */
+	strncpy(ints[0].name, sport->mport.name, SRIO_INT_NAME_LEN);
+	ints[0].name[SRIO_INT_NAME_LEN - 1] = 0;
+
+	switch (srio_port) {
+	case 0:
+		ints[0].irq = OCTEON_IRQ_SRIO0;
+		break;
+	case 1:
+		ints[0].irq = OCTEON_IRQ_SRIO1;
+		break;
+	case 2:
+		ints[0].irq = OCTEON_IRQ_SRIO2;
+		break;
+	case 3:
+		ints[0].irq = OCTEON_IRQ_SRIO3;
+		break;
+	default:
+		ints[0].irq = -1;
+		break;
+	}
+
+	ints[0].mport_id = srio_port;
+	INIT_WORK(&sport->ints[0].work, octeon_rio_work);
+}
+
+/**
+ * Initialize the srio interrupts of a given port.
+ *
+ * @srio_port:	Srio port to initialize.
+ *
+ * Returns Zero on success, error otherwise.
+ */
+static int octeon_srio_interrupt_init(int srio_port)
+{
+	struct octeon_srio_port *sport;
+	int			i;
+
+	sport = &srio_ports[srio_port];
+
+	if (OCTEON_IS_MODEL(OCTEON_CNF75XX))
+		octeon_srio_interrupt_75xx_cfg(srio_port);
+	else
+		octeon_srio_interrupt_cfg(srio_port);
+
+	/* Request and enable all interrupts for this port */
+	for (i = 0; i < sport->num_ints; i++) {
+		if (request_irq(sport->ints[i].irq, octeon_rio_irq, IRQF_SHARED,
+				sport->ints[i].name, &sport->ints[i])) {
+			RIO_PRINTK(&srio_ports[srio_port].mport,
+				   "Failed to register IRQ handler\n");
+		} else
+			octeon_rio_irq_set_enable(&sport->mport, 1);
+	}
+
+	return 0;
+}
+
+/**
+ * Initialize the dma command pool and fill it with buffers.
+ *
+ * Returns Zero on success, error otherwise.
+ */
+static int octeon_rio_dma_cmd_pool_init(void)
+{
+	int	node = cvmx_get_node_num();
+
+	octeon_fpa3_init(node);
+	octeon_fpa3_pool_init(node, CVMX_FPA_OUTPUT_BUFFER_POOL, &cmd_pool,
+			      &cmd_pool_stack, 4096);
+	octeon_fpa3_aura_init(cmd_pool, CVMX_FPA_OUTPUT_BUFFER_POOL, &cmd_aura,
+			      128, 20480);
+
+	cmd_pool_cache = kmem_cache_create("dma cmd",
+					   CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE,
+					   128, 0, NULL);
+	if (!cmd_pool_cache)
+		return -ENOMEM;
+
+	return octeon_mem_fill_fpa3(node, cmd_pool_cache, cmd_aura, 128);
+}
+
+
+extern int cvm_oct_mem_fill_fpa(int pool, int elements);
+extern int cvm_oct_alloc_fpa_pool(int pool, int size);
 
 /**
  * Initialize the RapidIO system
@@ -728,8 +1128,7 @@ static struct octeon_rio_port srio_ports[4];
 static int __init octeon_rio_init(void)
 {
 	int count = 0;
-	int port_index = (OCTEON_IS_MODEL(OCTEON_CN66XX) ? 4 : 2);
-	union cvmx_mio_rst_ctlx mio_rst_ctl;
+	struct octeon_srio_port *sport;
 	int srio_port;
 
 	if (octeon_is_simulation())
@@ -738,90 +1137,42 @@ static int __init octeon_rio_init(void)
 	if (!octeon_has_feature(OCTEON_FEATURE_SRIO))
 		return 0;
 
-	for (srio_port = 0; srio_port < port_index; srio_port++) {
-		if (OCTEON_IS_MODEL(OCTEON_CN66XX)) {
-			enum cvmx_qlm_mode mode = cvmx_qlm_get_mode(0);
-
-			switch (srio_port) {
-			case 0:  /* 1x4 lane */
-				if (mode != CVMX_QLM_MODE_SRIO_1X4 &&
-				    mode != CVMX_QLM_MODE_SRIO_2X2 &&
-				    mode != CVMX_QLM_MODE_SRIO_4X1)
-					continue;
-				break;
-
-			case 2:  /* 2x2 lane */
-				if (mode != CVMX_QLM_MODE_SRIO_2X2 &&
-				    mode != CVMX_QLM_MODE_SRIO_4X1)
-					continue;
-				break;
-
-			case 3:
-				if (mode != CVMX_QLM_MODE_SRIO_4X1)
-					continue;
-				break;
-
-			default:
-				continue;
-			}
-			mio_rst_ctl.u64 = cvmx_read_csr(CVMX_MIO_RST_CNTLX(0));
-		} else {
-			union cvmx_sriox_status_reg sriox_status_reg;
-			sriox_status_reg.u64 =
-				cvmx_read_csr(CVMX_SRIOX_STATUS_REG(srio_port));
-			if (!sriox_status_reg.s.srio)
-				continue;
-			mio_rst_ctl.u64 = cvmx_read_csr(CVMX_MIO_RST_CTLX(srio_port));
-		}
-		INIT_WORK(&srio_ports[srio_port].work, octeon_rio_work);
-		/* Only host mode ports enumerate. Endpoint does discovery */
-		if (mio_rst_ctl.s.prtmode)
-			srio_ports[srio_port].mport.host_deviceid = srio_port;
-		else
-			srio_ports[srio_port].mport.host_deviceid = -1;
-		srio_ports[srio_port].mport.ops = &octeon_rio_ops;
-		srio_ports[srio_port].mport.id = srio_port;
-		srio_ports[srio_port].mport.index = 0;
-		srio_ports[srio_port].mport.sys_size = 0;
-		srio_ports[srio_port].mport.iores.start =
-			CVMX_SRIOX_STATUS_REG(srio_port) & ((1ull << 49) - 1);
-		srio_ports[srio_port].mport.iores.end =
-			srio_ports[srio_port].mport.iores.start + 256;
-		srio_ports[srio_port].mport.iores.flags = IORESOURCE_MEM;
-		srio_ports[srio_port].mport.iores.name = "SRIO CSRs";
-		srio_ports[srio_port].mport.phy_type = RIO_PHY_SERIAL;
-		INIT_LIST_HEAD(&srio_ports[srio_port].mport.dbells);
-		rio_init_dbell_res(&srio_ports[srio_port].mport.riores[
-			RIO_DOORBELL_RESOURCE], 0, 0xffff);
-		rio_init_mbox_res(&srio_ports[srio_port].mport.riores[
-			RIO_INB_MBOX_RESOURCE], 0, 0);
-		rio_init_mbox_res(&srio_ports[srio_port].mport.riores[
-			RIO_OUTB_MBOX_RESOURCE], 0, 0);
-		sprintf(srio_ports[srio_port].mport.name, "SRIO%d", srio_port);
-		spin_lock_init(&srio_ports[srio_port].lock);
-		RIO_PRINTK(&srio_ports[srio_port].mport, "Registering port\n");
-		if (cvmx_srio_initialize(srio_port, 0) == 0) {
-			count++;
-			rio_register_mport(&srio_ports[srio_port].mport);
-			if (request_irq(octeon_rio_mport2irq(
-				&srio_ports[srio_port].mport),
-				octeon_rio_irq, IRQF_SHARED,
-				srio_ports[srio_port].mport.name,
-				&srio_ports[srio_port].mport)) {
-				RIO_PRINTK(&srio_ports[srio_port].mport,
-					"Failed to register IRQ handler\n");
-			} else
-				octeon_rio_irq_set_enable(&srio_ports[srio_port].mport, 1);
-		}
+	for (srio_port = 0; srio_port < MAX_SRIO_PORTS; srio_port++) {
+		sport = &srio_ports[srio_port];
+
+		/* Verify the srio port is supported and configured properly */
+		if (!octeon_is_srio_port_valid(srio_port))
+			continue;
+
+		/* Initialize the srio_ports[] structure */
+		octeon_srio_ports_init(srio_port);
+
+		/* Initialize the hardware */
+		if (cvmx_srio_initialize(srio_port, 0))
+			continue;
+
+		rio_register_mport(&sport->mport);
+
+		/* Initialize the interrupts */
+		if (octeon_srio_interrupt_init(srio_port))
+			continue;
+
+		count++;
 	}
+
 	if (count) {
-		int r;
-		cvmx_fpa1_enable();
-		r = cvm_oct_alloc_fpa_pool(CVMX_FPA_OUTPUT_BUFFER_POOL,
+		if ((octeon_has_feature(OCTEON_FEATURE_FPA3)))
+			octeon_rio_dma_cmd_pool_init();
+		else {
+			int r;
+			cvmx_fpa1_enable();
+			r = cvm_oct_alloc_fpa_pool(CVMX_FPA_OUTPUT_BUFFER_POOL,
 					   CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE);
-		if (r < 0)
-			panic("cvm_oct_alloc_fpa_pool() failed.");
-		cvm_oct_mem_fill_fpa(CVMX_FPA_OUTPUT_BUFFER_POOL, 128);
+			if (r < 0)
+				panic("cvm_oct_alloc_fpa_pool() failed.");
+			cvm_oct_mem_fill_fpa(CVMX_FPA_OUTPUT_BUFFER_POOL, 128);
+		}
+
 		cvmx_dma_engine_initialize();
 	}
 
-- 
1.9.1

