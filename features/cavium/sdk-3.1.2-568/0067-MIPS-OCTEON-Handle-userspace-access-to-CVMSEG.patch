From 944c0beb6ba0d0f759027ee797445d1e7f3acbb0 Mon Sep 17 00:00:00 2001
From: David Daney <ddaney@caviumnetworks.com>
Date: Fri, 14 May 2010 14:25:12 -0700
Subject: [PATCH 067/974] MIPS: OCTEON: Handle userspace access to CVMSEG

'Fault in' access to CVMSEG.

Signed-off-by: David Daney <ddaney@caviumnetworks.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/kernel/unaligned.c | 43 +++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 43 insertions(+)

diff --git a/arch/mips/kernel/unaligned.c b/arch/mips/kernel/unaligned.c
index eeea73e..f79beb8 100644
--- a/arch/mips/kernel/unaligned.c
+++ b/arch/mips/kernel/unaligned.c
@@ -1553,6 +1553,49 @@ asmlinkage void do_ade(struct pt_regs *regs)
 	unsigned int __user *pc;
 	mm_segment_t seg;
 
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) && (CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE > 0)
+	/*
+	 * Allows tasks to access CVMSEG addresses. These are special
+	 * addresses into the Octeon L1 Cache that can be used as fast
+	 * scratch memory. By default access to this memory is
+	 * disabled so we don't have to save it on context
+	 * switch. When a userspace task references one of these
+	 * addresses, we enable the region and size it to match the
+	 * app.
+	 */
+	const unsigned long CVMSEG_BASE	= 0xffffffffffff8000ul;
+	const unsigned long CVMSEG_IO	= 0xffffffffffffa200ul;
+	u64 cvmmemctl			= __read_64bit_c0_register($11, 7);
+	unsigned long cvmseg_size	= (cvmmemctl & 0x3f) * 128;
+
+	if ((regs->cp0_badvaddr == CVMSEG_IO) ||
+	    ((regs->cp0_badvaddr >= CVMSEG_BASE) &&
+	     (regs->cp0_badvaddr < CVMSEG_BASE + cvmseg_size))) {
+		preempt_disable();
+		cvmmemctl = __read_64bit_c0_register($11, 7);
+		/* Make sure all async operations are done */
+		asm volatile ("synciobdma" ::: "memory");
+		/* Enable userspace access to CVMSEG */
+		cvmmemctl |= 1 << 6;
+		__write_64bit_c0_register($11, 7, cvmmemctl);
+# ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		/*
+		 * Restore the processes CVMSEG data. Leave off the
+		 * last 8 bytes since the kernel stores the thread
+		 * pointer there.
+		 */
+		memcpy((void *)CVMSEG_BASE, current->thread.cvmseg.cvmseg,
+		       cvmseg_size - 8);
+# else
+		/* Restore the processes CVMSEG data */
+		memcpy((void *)CVMSEG_BASE, current->thread.cvmseg.cvmseg,
+		       cvmseg_size);
+# endif
+		preempt_enable();
+		return;
+	}
+#endif
+
 	perf_sw_event(PERF_COUNT_SW_ALIGNMENT_FAULTS,
 			1, regs, regs->cp0_badvaddr);
 	/*
-- 
2.6.2

