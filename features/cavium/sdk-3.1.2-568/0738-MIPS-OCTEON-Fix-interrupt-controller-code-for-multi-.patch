From b5d57844d9a9186c3f7ba9d67412c984129b4a48 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Thu, 3 Jul 2014 18:05:50 -0700
Subject: [PATCH 738/974] MIPS: OCTEON: Fix interrupt controller code for
 multi-node/NUMA

We will use CONFIG_SPARSE_IRQ in the NUMA case.

Signed-off-by: David Daney <david.daney@cavium.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/Kconfig                    |  1 +
 arch/mips/cavium-octeon/octeon-irq.c | 52 ++++++++++++++++++++++++++++++------
 2 files changed, 45 insertions(+), 8 deletions(-)

diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
index efcefe6..0424cb8 100644
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -769,6 +769,7 @@ config CAVIUM_OCTEON_SOC
 	select NR_CPUS_DEFAULT_64
 	select MIPS_NR_CPU_NR_MAP_1024
 	select SYS_SUPPORTS_NUMA
+	select SPARSE_IRQ if NUMA
 	help
 	  This option supports all of the Octeon SoCs and reference
 	  boards from Cavium, Inc. The Cavium Octeon processor is a
diff --git a/arch/mips/cavium-octeon/octeon-irq.c b/arch/mips/cavium-octeon/octeon-irq.c
index fcdfafc..b975b82 100644
--- a/arch/mips/cavium-octeon/octeon-irq.c
+++ b/arch/mips/cavium-octeon/octeon-irq.c
@@ -119,6 +119,11 @@ void octeon_irq_free_cd(struct irq_domain *d, unsigned int irq)
 static int octeon_irq_force_ciu_mapping(struct irq_domain *domain,
 					int irq, int line, int bit)
 {
+	int r;
+
+	r = irq_alloc_desc_at(irq, 0);
+	WARN_ON(r < 0);
+
 	return irq_domain_associate(domain, irq, line << 6 | bit);
 }
 
@@ -252,7 +257,6 @@ static void __init octeon_irq_init_core(void)
 
 static int next_cpu_for_irq(struct irq_data *data)
 {
-
 #ifdef CONFIG_SMP
 	int cpu;
 	int weight = cpumask_weight(data->affinity);
@@ -261,7 +265,11 @@ static int next_cpu_for_irq(struct irq_data *data)
 	if (weight > 1) {
 		cpu = cd->current_cpu;
 		for (;;) {
+#ifdef CONFIG_NUMA
+			cpu = cpumask_next_and(cpu, data->affinity, cpumask_of_node(cd->ciu_node));
+#else
 			cpu = cpumask_next(cpu, data->affinity);
+#endif
 			if (cpu >= nr_cpu_ids) {
 				cpu = -1;
 				continue;
@@ -270,9 +278,19 @@ static int next_cpu_for_irq(struct irq_data *data)
 			}
 		}
 	} else if (weight == 1) {
+#ifdef CONFIG_NUMA
+		cpu = cpumask_first_and(data->affinity, cpumask_of_node(cd->ciu_node));
+		if (cpu >= nr_cpu_ids)
+			cpu = cpumask_first(cpumask_of_node(cd->ciu_node));
+#else
 		cpu = cpumask_first(data->affinity);
+#endif
 	} else {
+#ifdef CONFIG_NUMA
+		cpu = cpumask_first(cpumask_of_node(cd->ciu_node));
+#else
 		cpu = smp_processor_id();
+#endif
 	}
 	cd->current_cpu = cpu;
 	return cpu;
@@ -1450,6 +1468,9 @@ static int __init octeon_irq_init_ciu(struct device_node *ciu_node, struct devic
 			goto err;
 	}
 
+	r = irq_alloc_descs_from(OCTEON_IRQ_MBOX0, 2, 0);
+	WARN_ON(r < 0);
+
 	r = octeon_irq_set_ciu_mapping(OCTEON_IRQ_MBOX0, 0, 32, 0, chip_mbox, handle_percpu_irq);
 	if (r)
 		goto err;
@@ -1479,6 +1500,8 @@ static int __init octeon_irq_init_ciu(struct device_node *ciu_node, struct devic
 	}
 
 	/* CIU_1 */
+	r = irq_alloc_descs_from(OCTEON_IRQ_WDOG0, 16, 0);
+	WARN_ON(r < 0);
 	for (i = 0; i < 16; i++) {
 		r = octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_WDOG0, 1, i + 0, 0, chip_wd, handle_level_irq);
 		if (r)
@@ -1486,6 +1509,8 @@ static int __init octeon_irq_init_ciu(struct device_node *ciu_node, struct devic
 	}
 
 	if (octeon_has_feature(OCTEON_FEATURE_SRIO)) {
+		r = irq_alloc_descs_from(OCTEON_IRQ_SRIO0, 4, 0);
+		WARN_ON(r < 0);
 		r = octeon_irq_set_ciu_mapping(OCTEON_IRQ_SRIO0, 1, 50, 0, chip, handle_level_irq);
 		if (r)
 			goto err;
@@ -1979,6 +2004,8 @@ static int __init octeon_irq_init_ciu2(struct device_node *ciu_node, struct devi
 			goto err;
 	}
 
+	r = irq_alloc_descs_from(OCTEON_IRQ_WDOG0, 32, 0);
+	WARN_ON(r < 0);
 	for (i = 0; i < 32; i++) {
 		r = octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_WDOG0, 1, i, 0,
 					       &octeon_irq_chip_ciu2_wd, handle_level_irq);
@@ -2004,6 +2031,8 @@ static int __init octeon_irq_init_ciu2(struct device_node *ciu_node, struct devi
 			goto err;
 	}
 
+	r = irq_alloc_descs_from(OCTEON_IRQ_MBOX0, 4, 0);
+	WARN_ON(r < 0);
 	irq_set_chip_and_handler(OCTEON_IRQ_MBOX0, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);
 	irq_set_chip_and_handler(OCTEON_IRQ_MBOX1, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);
 	irq_set_chip_and_handler(OCTEON_IRQ_MBOX2, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);
@@ -2688,8 +2717,9 @@ static int __init octeon_irq_init_ciu3(struct device_node *ciu_node,
 	u64 base_addr;
 	union cvmx_ciu3_const consts;
 
-	ciu3_info = kzalloc_node(sizeof(*ciu3_info), GFP_KERNEL,
-				 of_node_to_nid(ciu_node));
+	node = of_node_to_nid(ciu_node);
+	ciu3_info = kzalloc_node(sizeof(*ciu3_info), GFP_KERNEL, node);
+
 	if (!ciu3_info)
 		return -ENOMEM;
 
@@ -2699,7 +2729,6 @@ static int __init octeon_irq_init_ciu3(struct device_node *ciu_node,
 
 	base_addr = of_translate_address(ciu_node, zero_addr);
 	base_addr = (u64)phys_to_virt(base_addr);
-	node = (base_addr >> 36) & 3;
 
 	ciu3_info->ciu3_addr = base_addr;
 	ciu3_info->node = node;
@@ -2712,11 +2741,18 @@ static int __init octeon_irq_init_ciu3(struct device_node *ciu_node,
 	octeon_irq_ip3 = octeon_irq_ciu3_mbox;
 	octeon_irq_ip4 = octeon_irq_ciu3_ip4;
 
-	/* Mips internal */
-	octeon_irq_init_core();
+	if (node == cvmx_get_node_num()) {
+		/* Mips internal */
+		octeon_irq_init_core();
+
+		/* Only do per CPU things if it is the CIU of the boot node. */
+		i = irq_alloc_descs_from(OCTEON_IRQ_MBOX0, 8, node);
+		WARN_ON(i < 0);
 
-	for (i = 0; i < 8; i++)
-		irq_set_chip_and_handler(i + OCTEON_IRQ_MBOX0, &octeon_irq_chip_ciu3_mbox, handle_percpu_irq);
+		for (i = 0; i < 8; i++)
+			irq_set_chip_and_handler(i + OCTEON_IRQ_MBOX0,
+						 &octeon_irq_chip_ciu3_mbox, handle_percpu_irq);
+	}
 
 	/*
 	 * Initialize all domains to use the default domain. Specific major
-- 
2.6.2

