From e1df252a23f7cab2c133e03530759f9c8510c0f3 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Thu, 6 Feb 2014 13:46:59 -0800
Subject: [PATCH 471/974] MIPS/OCTEON: Update S.E. to r94829

Signed-off-by: David Daney <david.daney@cavium.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/cavium-octeon/executive/Makefile         |    3 +-
 arch/mips/cavium-octeon/executive/cvmx-bootmem.c   |   10 +-
 arch/mips/cavium-octeon/executive/cvmx-clock.c     |   32 +-
 arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c |    2 +-
 arch/mips/cavium-octeon/executive/cvmx-core.c      |  149 --
 .../mips/cavium-octeon/executive/cvmx-debug-uart.c |    5 +-
 arch/mips/cavium-octeon/executive/cvmx-debug.c     |   26 +-
 .../mips/cavium-octeon/executive/cvmx-dma-engine.c |  110 +-
 .../cavium-octeon/executive/cvmx-error-trees.c     |  206 --
 .../cavium-octeon/executive/cvmx-fpa-resource.c    |   56 +-
 .../executive/cvmx-global-resources.c              |    9 +-
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c |  980 ++++++++
 .../cavium-octeon/executive/cvmx-helper-board.c    |  165 +-
 .../mips/cavium-octeon/executive/cvmx-helper-cfg.c |  133 +-
 .../cavium-octeon/executive/cvmx-helper-errata.c   |    4 +-
 .../mips/cavium-octeon/executive/cvmx-helper-ilk.c |  109 +-
 .../cavium-octeon/executive/cvmx-helper-loop.c     |   31 +-
 .../mips/cavium-octeon/executive/cvmx-helper-npi.c |   42 +-
 .../mips/cavium-octeon/executive/cvmx-helper-pki.c |  533 ++++
 .../mips/cavium-octeon/executive/cvmx-helper-pko.c |  301 +++
 .../cavium-octeon/executive/cvmx-helper-pko3.c     |  903 +++++++
 .../cavium-octeon/executive/cvmx-helper-sgmii.c    |  138 +-
 .../cavium-octeon/executive/cvmx-helper-util.c     |  372 +--
 .../cavium-octeon/executive/cvmx-helper-xaui.c     |  146 +-
 arch/mips/cavium-octeon/executive/cvmx-helper.c    |  901 ++++---
 arch/mips/cavium-octeon/executive/cvmx-ilk.c       |   74 +-
 arch/mips/cavium-octeon/executive/cvmx-ipd.c       |  240 +-
 arch/mips/cavium-octeon/executive/cvmx-l2c.c       |   32 +-
 arch/mips/cavium-octeon/executive/cvmx-nand.c      |  142 +-
 arch/mips/cavium-octeon/executive/cvmx-pcie.c      |   15 +-
 .../cavium-octeon/executive/cvmx-pki-resources.c   |  308 ++-
 arch/mips/cavium-octeon/executive/cvmx-pki.c       | 1374 ++++-------
 arch/mips/cavium-octeon/executive/cvmx-pko.c       |  660 +++--
 .../mips/cavium-octeon/executive/cvmx-pko3-queue.c |  775 ++++++
 .../cavium-octeon/executive/cvmx-pko3-resources.c  |  173 ++
 arch/mips/cavium-octeon/executive/cvmx-pko3.c      |  817 +++++++
 arch/mips/cavium-octeon/executive/cvmx-qlm.c       |  177 +-
 arch/mips/cavium-octeon/executive/cvmx-range.c     |    7 +-
 arch/mips/cavium-octeon/executive/cvmx-srio.c      |    7 +-
 arch/mips/cavium-octeon/executive/octeon-feature.c |    3 +
 arch/mips/cavium-octeon/executive/octeon-model.c   |  111 +-
 arch/mips/cavium-octeon/octeon-rapidio.c           |   10 +-
 arch/mips/include/asm/octeon/cvmx-agl-defs.h       |   52 +-
 arch/mips/include/asm/octeon/cvmx-app-hotplug.h    |    6 +-
 arch/mips/include/asm/octeon/cvmx-app-init.h       |    4 +-
 arch/mips/include/asm/octeon/cvmx-ase-defs.h       |   12 +-
 arch/mips/include/asm/octeon/cvmx-asm.h            |   78 +-
 arch/mips/include/asm/octeon/cvmx-bgxx-defs.h      |   13 +-
 arch/mips/include/asm/octeon/cvmx-bootmem.h        |   15 +-
 arch/mips/include/asm/octeon/cvmx-ciu-defs.h       |  491 ++--
 arch/mips/include/asm/octeon/cvmx-ciu3-defs.h      |   62 +-
 arch/mips/include/asm/octeon/cvmx-coremask.h       |   40 +-
 arch/mips/include/asm/octeon/cvmx-dma-engine.h     |  199 +-
 arch/mips/include/asm/octeon/cvmx-dpi-defs.h       |  103 +-
 arch/mips/include/asm/octeon/cvmx-fau.h            |  107 +-
 arch/mips/include/asm/octeon/cvmx-fpa-defs.h       |   60 +-
 arch/mips/include/asm/octeon/cvmx-fpa.h            |  501 ++--
 .../include/asm/octeon/cvmx-global-resources.h     |    9 +-
 arch/mips/include/asm/octeon/cvmx-gmx.h            |    6 +-
 arch/mips/include/asm/octeon/cvmx-gpio-defs.h      |   73 +-
 arch/mips/include/asm/octeon/cvmx-gserx-defs.h     | 1002 ++++++--
 arch/mips/include/asm/octeon/cvmx-helper-bgx.h     |  190 ++
 arch/mips/include/asm/octeon/cvmx-helper-board.h   |    5 +-
 arch/mips/include/asm/octeon/cvmx-helper-cfg.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-helper-fpa.h     |   41 +-
 arch/mips/include/asm/octeon/cvmx-helper-npi.h     |    8 +-
 arch/mips/include/asm/octeon/cvmx-helper-pki.h     |  113 +
 arch/mips/include/asm/octeon/cvmx-helper-pko.h     |  127 +
 arch/mips/include/asm/octeon/cvmx-helper-pko3.h    |   97 +
 arch/mips/include/asm/octeon/cvmx-helper-sgmii.h   |   77 +-
 arch/mips/include/asm/octeon/cvmx-helper-util.h    |  159 +-
 arch/mips/include/asm/octeon/cvmx-helper-xaui.h    |   73 +-
 arch/mips/include/asm/octeon/cvmx-helper.h         |   73 +-
 arch/mips/include/asm/octeon/cvmx-hna-defs.h       | 1093 +++++----
 arch/mips/include/asm/octeon/cvmx-ila-defs.h       |   50 +-
 arch/mips/include/asm/octeon/cvmx-ilk-defs.h       |   34 +-
 arch/mips/include/asm/octeon/cvmx-ilk.h            |    2 +-
 arch/mips/include/asm/octeon/cvmx-iobn-defs.h      |  150 +-
 arch/mips/include/asm/octeon/cvmx-ipd-defs.h       |    4 +-
 arch/mips/include/asm/octeon/cvmx-ipd.h            |   64 +-
 arch/mips/include/asm/octeon/cvmx-l2c-defs.h       |  656 +++--
 arch/mips/include/asm/octeon/cvmx-lapx-defs.h      |   70 +-
 arch/mips/include/asm/octeon/cvmx-lmcx-defs.h      |  263 +-
 arch/mips/include/asm/octeon/cvmx-mio-defs.h       |  623 +++--
 arch/mips/include/asm/octeon/cvmx-mixx-defs.h      |   19 +-
 arch/mips/include/asm/octeon/cvmx-mpi-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-nand.h           |  423 ++--
 arch/mips/include/asm/octeon/cvmx-oclax-defs.h     |   23 +-
 arch/mips/include/asm/octeon/cvmx-ocx-defs.h       |  201 +-
 arch/mips/include/asm/octeon/cvmx-packet.h         |   24 +-
 arch/mips/include/asm/octeon/cvmx-pcie.h           |   21 +-
 arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h | 1523 +++++-------
 arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h   | 1004 ++++----
 arch/mips/include/asm/octeon/cvmx-pciercx-defs.h   |  857 +++----
 arch/mips/include/asm/octeon/cvmx-pemx-defs.h      |  751 +++---
 arch/mips/include/asm/octeon/cvmx-pip.h            |  224 +-
 arch/mips/include/asm/octeon/cvmx-pki-cluster.h    |  171 +-
 arch/mips/include/asm/octeon/cvmx-pki-defs.h       |  245 +-
 arch/mips/include/asm/octeon/cvmx-pki-resources.h  |   56 +-
 arch/mips/include/asm/octeon/cvmx-pki.h            | 1267 +++++-----
 arch/mips/include/asm/octeon/cvmx-pko-defs.h       | 2569 +++++++++++---------
 .../asm/octeon/cvmx-pko-internal-ports-range.h     |    2 +
 arch/mips/include/asm/octeon/cvmx-pko.h            |  178 +-
 arch/mips/include/asm/octeon/cvmx-pko3-queue.h     |  262 ++
 arch/mips/include/asm/octeon/cvmx-pko3-resources.h |   82 +
 arch/mips/include/asm/octeon/cvmx-pko3.h           |  551 +++++
 arch/mips/include/asm/octeon/cvmx-pow.h            |  407 +++-
 arch/mips/include/asm/octeon/cvmx-qlm.h            |   10 +-
 arch/mips/include/asm/octeon/cvmx-rst-defs.h       |   22 +-
 arch/mips/include/asm/octeon/cvmx-sli-defs.h       |  127 +-
 arch/mips/include/asm/octeon/cvmx-sso-defs.h       |   36 +-
 arch/mips/include/asm/octeon/cvmx-uart.h           |    4 +-
 arch/mips/include/asm/octeon/cvmx-uctlx-defs.h     |   90 +-
 arch/mips/include/asm/octeon/cvmx-wqe.h            |  590 ++++-
 arch/mips/include/asm/octeon/octeon-boot-info.h    |    8 +-
 arch/mips/include/asm/octeon/octeon-feature.h      |   33 +-
 arch/mips/include/asm/octeon/octeon-model.h        |    7 +-
 drivers/net/ethernet/octeon/ethernet-napi.c        |    4 +-
 drivers/net/ethernet/octeon/ethernet-tx.c          |    2 +-
 drivers/net/ethernet/octeon/ethernet-xmit.c        |   16 +-
 drivers/net/ethernet/octeon/ethernet.c             |    4 +-
 drivers/net/ethernet/octeon/octeon-ethernet.h      |    6 +-
 122 files changed, 18646 insertions(+), 10273 deletions(-)
 delete mode 100644 arch/mips/cavium-octeon/executive/cvmx-core.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-helper-pko.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-pko3-resources.c
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-pko3.c
 create mode 100644 arch/mips/include/asm/octeon/cvmx-helper-bgx.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-helper-pki.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-helper-pko.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-helper-pko3.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-pko3-queue.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-pko3-resources.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-pko3.h

diff --git a/arch/mips/cavium-octeon/executive/Makefile b/arch/mips/cavium-octeon/executive/Makefile
index 9023f08..166b521 100644
--- a/arch/mips/cavium-octeon/executive/Makefile
+++ b/arch/mips/cavium-octeon/executive/Makefile
@@ -20,7 +20,8 @@ obj-y += cvmx-pko.o cvmx-spi.o cvmx-cmd-queue.o cvmx-helper-cfg.o	\
 	cvmx-helper-board.o cvmx-helper.o cvmx-helper-xaui.o \
 	cvmx-helper-rgmii.o cvmx-helper-sgmii.o cvmx-helper-npi.o \
 	cvmx-helper-loop.o cvmx-helper-spi.o cvmx-helper-util.o	\
-	cvmx-pki-resources.o cvmx-gser.o cvmx-bgx.o
+	cvmx-pki-resources.o cvmx-gser.o cvmx-bgx.o cvmx-pko3-queue.o cvmx-helper-bgx.o \
+	cvmx-pko3.o cvmx-helper-pki.o cvmx-helper-pko3.o cvmx-pko3-resources.o cvmx-helper-pko.o
 
 obj-y += cvmx-helper-errata.o cvmx-helper-jtag.o
 obj-y += cvmx-pcie.o
diff --git a/arch/mips/cavium-octeon/executive/cvmx-bootmem.c b/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
index e59f4fa..1c45f68 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
@@ -42,7 +42,7 @@
  * Simple allocate only memory allocator.  Used to allocate memory at
  * application start time.
  *
- * <hr>$Revision: 84899 $<hr>
+ * <hr>$Revision: 94463 $<hr>
  *
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
@@ -528,6 +528,14 @@ void *cvmx_bootmem_alloc_address(uint64_t size, uint64_t address,
 					address + size);
 }
 
+void *cvmx_bootmem_alloc_node(uint64_t node, uint64_t size, uint64_t alignment)
+{
+	return cvmx_bootmem_alloc_range(size, alignment,
+					node << CVMX_NODE_MEM_SHIFT,
+					((node + 1) << CVMX_NODE_MEM_SHIFT) - 1);
+}
+EXPORT_SYMBOL(cvmx_bootmem_alloc_node);
+
 void *cvmx_bootmem_alloc(uint64_t size, uint64_t alignment)
 {
 	return cvmx_bootmem_alloc_range(size, alignment, 0, 0);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-clock.c b/arch/mips/cavium-octeon/executive/cvmx-clock.c
index a5d484c..f0ea278 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-clock.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-clock.c
@@ -54,6 +54,7 @@
 #include <asm/octeon/cvmx-dbg-defs.h>
 #include <asm/octeon/cvmx-rst-defs.h>
 #elif defined(CVMX_BUILD_FOR_UBOOT)
+#include <common.h>
 #include <asm/arch/cvmx.h>
 #include <asm/arch/cvmx-access.h>
 #else
@@ -61,6 +62,10 @@
 #include "cvmx-access.h"
 #endif
 
+#ifdef CVMX_BUILD_FOR_UBOOT
+DECLARE_GLOBAL_DATA_PTR;
+#endif
+
 #ifndef CVMX_BUILD_FOR_UBOOT
 static uint64_t rate_eclk = 0;
 static uint64_t rate_sclk = 0;
@@ -76,14 +81,9 @@ static uint64_t rate_dclk = 0;
  */
 uint64_t cvmx_clock_get_rate_node(int node, cvmx_clock_t clock)
 {
+#ifndef CVMX_BUILD_FOR_UBOOT
 	const uint64_t REF_CLOCK = 50000000;
 
-#ifdef CVMX_BUILD_FOR_UBOOT
-	uint64_t rate_eclk = 0;
-	uint64_t rate_sclk = 0;
-	uint64_t rate_dclk = 0;
-#endif
-
 	if (cvmx_unlikely(!rate_eclk)) {
 		/* Note: The order of these checks is important.
 		 ** octeon_has_feature(OCTEON_FEATURE_PCIE) is true for both 6XXX
@@ -122,14 +122,26 @@ uint64_t cvmx_clock_get_rate_node(int node, cvmx_clock_t clock)
 		return rate_eclk;
 
 	case CVMX_CLOCK_DDR:
-#if !defined(CVMX_BUILD_FOR_LINUX_HOST) && !defined(CVMX_BUILD_FOR_TOOLCHAIN)
+# if !defined(CVMX_BUILD_FOR_LINUX_HOST) && !defined(CVMX_BUILD_FOR_TOOLCHAIN)
 		if (cvmx_unlikely(!rate_dclk))
 			rate_dclk = cvmx_sysinfo_get()->dram_data_rate_hz;
-#endif
+# endif
 		return rate_dclk;
 	}
-
-	cvmx_dprintf("cvmx_clock_get_rate: Unknown clock type\n");
+#else
+	switch (clock) {
+	case CVMX_CLOCK_SCLK:
+	case CVMX_CLOCK_TIM:
+	case CVMX_CLOCK_IPD:
+		return gd->bus_clk;
+	case CVMX_CLOCK_RCLK:
+	case CVMX_CLOCK_CORE:
+		return gd->cpu_clk;
+	case CVMX_CLOCK_DDR:
+		return gd->mem_clk * 1000000;
+	}
+#endif
+	cvmx_dprintf("cvmx_clock_get_rate: Unknown clock type %d\n", clock);
 	return 0;
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c b/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
index 8d98a6a..2c474f3 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
@@ -43,7 +43,7 @@
  * Support functions for managing command queues used for
  * various hardware blocks.
  *
- * <hr>$Revision: 91009 $<hr>
+ * <hr>$Revision: 90763 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
diff --git a/arch/mips/cavium-octeon/executive/cvmx-core.c b/arch/mips/cavium-octeon/executive/cvmx-core.c
deleted file mode 100644
index 3e4d643..0000000
--- a/arch/mips/cavium-octeon/executive/cvmx-core.c
+++ /dev/null
@@ -1,149 +0,0 @@
-/***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
- * reserved.
- *
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are
- * met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *
- *   * Redistributions in binary form must reproduce the above
- *     copyright notice, this list of conditions and the following
- *     disclaimer in the documentation and/or other materials provided
- *     with the distribution.
-
- *   * Neither the name of Cavium Inc. nor the names of
- *     its contributors may be used to endorse or promote products
- *     derived from this software without specific prior written
- *     permission.
-
- * This Software, including technical data, may be subject to U.S. export  control
- * laws, including the U.S. Export Administration Act and its  associated
- * regulations, and may be subject to export or import  regulations in other
- * countries.
-
- * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
- * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
- * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
- * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
- * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
- * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
- * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
- * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
- * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
- * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
- ***********************license end**************************************/
-
-/**
- * @file
- *
- * Module to support operations on core such as TLB config, etc.
- *
- * <hr>$Revision: 82832 $<hr>
- *
- */
-
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-#include <linux/module.h>
-#include <asm/octeon/cvmx.h>
-#include <asm/octeon/cvmx-core.h>
-#else
-#include "cvmx.h"
-#include "cvmx-core.h"
-#endif
-
-/**
- * Adds a wired TLB entry, and returns the index of the entry added.
- * Parameters are written to TLB registers without further processing.
- *
- * @param hi     HI register value
- * @param lo0    lo0 register value
- * @param lo1    lo1 register value
- * @param page_mask   pagemask register value
- *
- * @return Success: TLB index used (0-31 Octeon, 0-63 Octeon+, or 0-127
- *         Octeon2). Failure: -1
- */
-int cvmx_core_add_wired_tlb_entry(uint64_t hi, uint64_t lo0, uint64_t lo1, cvmx_tlb_pagemask_t page_mask)
-{
-	uint32_t index;
-
-	CVMX_MF_TLB_WIRED(index);
-	if (index >= (unsigned int)cvmx_core_get_tlb_entries() - 1) {
-		return (-1);
-	}
-	CVMX_MT_ENTRY_HIGH(hi);
-	CVMX_MT_ENTRY_LO_0(lo0);
-	CVMX_MT_ENTRY_LO_1(lo1);
-	CVMX_MT_PAGEMASK(page_mask);
-	CVMX_MT_TLB_INDEX(index);
-	CVMX_MT_TLB_WIRED(index + 1);
-	CVMX_EHB;
-	CVMX_TLBWI;
-	CVMX_EHB;
-	return (index);
-}
-
-/**
- * Adds a fixed (wired) TLB mapping.  Returns TLB index used or -1 on error.
- * This is a wrapper around cvmx_core_add_wired_tlb_entry()
- *
- * @param vaddr      Virtual address to map
- * @param page0_addr page 0 physical address, with low 3 bits representing the DIRTY, VALID, and GLOBAL bits
- * @param page1_addr page1 physical address, with low 3 bits representing the DIRTY, VALID, and GLOBAL bits
- * @param page_mask  page mask.
- *
- * @return Success: TLB index used (0-31)
- *         Failure: -1
- */
-int cvmx_core_add_fixed_tlb_mapping_bits(uint64_t vaddr, uint64_t page0_addr, uint64_t page1_addr, cvmx_tlb_pagemask_t page_mask)
-{
-
-	if ((vaddr & (page_mask | 0x7ff))
-	    || ((page0_addr & ~0x7ULL) & ((page_mask | 0x7ff) >> 1))
-	    || ((page1_addr & ~0x7ULL) & ((page_mask | 0x7ff) >> 1))) {
-		cvmx_dprintf("Error adding tlb mapping: invalid address alignment at vaddr: 0x%llx\n", (unsigned long long)vaddr);
-		return (-1);
-	}
-
-	return (cvmx_core_add_wired_tlb_entry(vaddr, (page0_addr >> 6) | (page0_addr & 0x7), (page1_addr >> 6) | (page1_addr & 0x7), page_mask));
-
-}
-
-/**
- * Adds a fixed (wired) TLB mapping.  Returns TLB index used or -1 on error.
- * Assumes both pages are valid.  Use cvmx_core_add_fixed_tlb_mapping_bits for more control.
- * This is a wrapper around cvmx_core_add_wired_tlb_entry()
- *
- * @param vaddr      Virtual address to map
- * @param page0_addr page 0 physical address
- * @param page1_addr page1 physical address
- * @param page_mask  page mask.
- *
- * @return Success: TLB index used (0-31)
- *         Failure: -1
- */
-int cvmx_core_add_fixed_tlb_mapping(uint64_t vaddr, uint64_t page0_addr, uint64_t page1_addr, cvmx_tlb_pagemask_t page_mask)
-{
-
-	return (cvmx_core_add_fixed_tlb_mapping_bits(vaddr, page0_addr | TLB_DIRTY | TLB_VALID | TLB_GLOBAL, page1_addr | TLB_DIRTY | TLB_VALID | TLB_GLOBAL, page_mask));
-
-}
-
-/**
- * Return number of TLB entries.
- */
-int cvmx_core_get_tlb_entries(void)
-{
-	if (OCTEON_IS_MODEL(OCTEON_CN3XXX))
-		return 32;
-	else if (OCTEON_IS_MODEL(OCTEON_CN5XXX))
-		return 64;
-	else if (OCTEON_IS_OCTEON2())
-		return 128;
-	else
-		return 256;
-}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-debug-uart.c b/arch/mips/cavium-octeon/executive/cvmx-debug-uart.c
index c8ab820..54441c6 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-debug-uart.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-debug-uart.c
@@ -79,11 +79,10 @@ static CVMX_SHARED cvmx_spinlock_t cvmx_debug_uart_lock;
 /**
  * Interrupt handler for debugger Control-C interrupts.
  *
- * @param irq_number IRQ interrupt number
+ * @param uart_number UART generating the IRQ
  * @param registers  CPU registers at the time of the interrupt
- * @param user_arg   Unused user argument
  */
-void cvmx_debug_uart_process_debug_interrupt(int irq_number, uint64_t registers[32], void *user_arg)
+void cvmx_debug_uart_process_debug_interrupt(int uart_number, uint64_t registers[32])
 {
 	cvmx_uart_lsr_t lsrval;
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-debug.c b/arch/mips/cavium-octeon/executive/cvmx-debug.c
index 548d2ae..d10a37c 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-debug.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-debug.c
@@ -286,9 +286,29 @@ static void cvmx_debug_init_globals(void)
 
 	if (cvmx_debug_globals)
 		return;
-	ptr = cvmx_bootmem_alloc_named_range_once(sizeof(cvmx_debug_globals_t), 0,
-						  /* KSEG0 max, 512MB= */ 0 /*1024*1024*512 */ , 8,
-						  CVMX_DEBUG_GLOBALS_BLOCK_NAME, cvmx_debug_init_global_ptr);
+
+	/*
+	 *  For CVMX_ABI_N32, __cvmx_validate_mem_range() will limit the
+	 * range to KSEG0, i.3. 512MB
+	 */
+	ptr = cvmx_bootmem_alloc_named_range_once(
+			sizeof(cvmx_debug_globals_t), 
+			0,	/* min addr */
+			0,	/* max addr */
+			8,	/* align */
+			CVMX_DEBUG_GLOBALS_BLOCK_NAME,	/* name */
+			cvmx_debug_init_global_ptr);	/* init func */
+
+	if(ptr == NULL) {
+		cvmx_dprintf("Failed allocating debug globals, spinining.\n");
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+		panic("cvmx_debug_global alloc failure.\n");
+#endif
+		while (1) ;
+
+	}
+
+
 	phys = cvmx_ptr_to_phys(ptr);
 
 	/* Since TLBs are not always mapped 1 to 1, we should just use access via KSEG0 for n32
diff --git a/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c b/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
index a2a733b..c931ca5 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -43,7 +43,7 @@
  * Interface to the PCI / PCIe DMA engines. These are only avialable
  * on chips with PCI / PCIe.
  *
- * <hr>$Revision: 84896 $<hr>
+ * <hr>$Revision: 94747 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
@@ -59,6 +59,7 @@
 #include <asm/octeon/cvmx-helper-cfg.h>
 #else
 #include "cvmx.h"
+#include "cvmx-bootmem.h"
 #include "cvmx-cmd-queue.h"
 #include "cvmx-dma-engine.h"
 #include "cvmx-helper-cfg.h"
@@ -92,21 +93,26 @@ int cvmx_dma_engine_get_num(void)
 int cvmx_dma_engine_initialize(void)
 {
 	int engine;
-	int outputbuffer_pool = (int)cvmx_fpa_get_dma_pool();
-	uint64_t outputbuffer_pool_size = cvmx_fpa_get_dma_pool_block_size();
+	int pool = (int)cvmx_fpa_get_dma_pool();
+	uint64_t pool_size = cvmx_fpa_get_dma_pool_block_size();
 
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+	int buffer_cnt = dma_config.command_queue_pool.buffer_count;
+	
 	/** It allocate pools for dma command queues
 	 */
-#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 	cvmx_fpa_global_initialize();
-	if(dma_config.command_queue_pool.buffer_count != 0)
-		__cvmx_helper_initialize_fpa_pool(outputbuffer_pool, outputbuffer_pool_size,
-			  dma_config.command_queue_pool.buffer_count, "Dma Cmd Buffers");
+	if(buffer_cnt != 0) {
+		if (!OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+			__cvmx_helper_initialize_fpa_pool(pool, pool_size,
+						buffer_cnt, "Dma Cmd Buffers");
+		}
+	}
 #endif
 
 	for (engine = 0; engine < cvmx_dma_engine_get_num(); engine++) {
 		cvmx_cmd_queue_result_t result;
-		result = cvmx_cmd_queue_initialize(CVMX_CMD_QUEUE_DMA(engine), 0, outputbuffer_pool, outputbuffer_pool_size);
+		result = cvmx_cmd_queue_initialize(CVMX_CMD_QUEUE_DMA(engine), 0, pool, pool_size);
 		if (result != CVMX_CMD_QUEUE_SUCCESS)
 			return -1;
 		if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
@@ -117,7 +123,7 @@ int cvmx_dma_engine_initialize(void)
 		} else if (octeon_has_feature(OCTEON_FEATURE_PCIE)) {
 			cvmx_dpi_dmax_ibuff_saddr_t dpi_dmax_ibuff_saddr;
 			dpi_dmax_ibuff_saddr.u64 = 0;
-			dpi_dmax_ibuff_saddr.s.csize = outputbuffer_pool_size / 8;
+			dpi_dmax_ibuff_saddr.s.csize = pool_size / 8;
 			if (OCTEON_IS_OCTEON3())
 				dpi_dmax_ibuff_saddr.cn78xx.saddr = cvmx_ptr_to_phys(cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_DMA(engine))) >> 7;
 			else
@@ -143,9 +149,9 @@ int cvmx_dma_engine_initialize(void)
 		dma_control.s.dma0_enb = 1;
 		dma_control.s.o_mode = 1;	/* Pull NS and RO from this register, not the pointers */
 		//dma_control.s.dwb_denb = 1;
-		//dma_control.s.dwb_ichk = outputbuffer_pool_size/128;
-		dma_control.s.fpa_que = outputbuffer_pool;
-		dma_control.s.csize = outputbuffer_pool_size / 8;
+		dma_control.s.dwb_ichk = pool_size/128;
+		dma_control.s.fpa_que = pool;
+		dma_control.s.csize = pool_size / 8;
 		cvmx_write_csr(CVMX_PEXP_NPEI_DMA_CONTROL, dma_control.u64);
 		/* As a workaround for errata PCIE-811 we only allow a single
 		   outstanding DMA read over PCIe at a time. This limits performance,
@@ -183,15 +189,17 @@ int cvmx_dma_engine_initialize(void)
 		cvmx_write_csr(CVMX_DPI_ENGX_BUF(5), dpi_engx_buf.u64);
 
 		dma_control.u64 = cvmx_read_csr(CVMX_DPI_DMA_CONTROL);
-		dma_control.s.pkt_hp = 1;
 		dma_control.s.pkt_en = 1;
 		dma_control.s.dma_enb = 0x1f;
-		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-			/* FIXME */
+		if (octeon_has_feature(OCTEON_FEATURE_FPA3)) {
+			dma_control.cn78xx.ldwb = cvmx_helper_cfg_opt_get(CVMX_HELPER_CFG_OPT_USE_DWB);
+			dma_control.cn78xx.aura_ichk = pool;
+
 		} else {
+			dma_control.cn61xx.pkt_hp = 1;
 			dma_control.cn61xx.dwb_denb = cvmx_helper_cfg_opt_get(CVMX_HELPER_CFG_OPT_USE_DWB);
-			dma_control.cn61xx.dwb_ichk = outputbuffer_pool_size / 128;
-			dma_control.cn61xx.fpa_que = outputbuffer_pool;
+			dma_control.cn61xx.dwb_ichk = pool_size / 128;
+			dma_control.cn61xx.fpa_que = pool;
 		}
 		dma_control.s.o_mode = 1;
 		cvmx_write_csr(CVMX_DPI_DMA_CONTROL, dma_control.u64);
@@ -204,12 +212,12 @@ int cvmx_dma_engine_initialize(void)
 		cvmx_npi_dma_control_t dma_control;
 		dma_control.u64 = 0;
 		//dma_control.s.dwb_denb = 1;
-		//dma_control.s.dwb_ichk = outputbuffer_pool_size/128;
+		dma_control.s.dwb_ichk = pool_size/128;
 		dma_control.s.o_add1 = 1;
-		dma_control.s.fpa_que = outputbuffer_pool;
+		dma_control.s.fpa_que = pool;
 		dma_control.s.hp_enb = 1;
 		dma_control.s.lp_enb = 1;
-		dma_control.s.csize = outputbuffer_pool_size / 8;
+		dma_control.s.csize = pool_size / 8;
 		cvmx_write_csr(CVMX_NPI_DMA_CONTROL, dma_control.u64);
 	}
 
@@ -298,17 +306,23 @@ int cvmx_dma_engine_submit(int engine, cvmx_dma_engine_header_t header, int num_
 {
 	cvmx_cmd_queue_result_t result;
 	int cmd_count = 1;
-	uint64_t cmds[num_buffers + 1];
+	uint64_t cmds[num_buffers + 2];
 
 	if (OCTEON_IS_MODEL(OCTEON_CN56XX_PASS1_X)) {
 		/* Check for Errata PCIe-604 */
-		if ((header.s.nfst > 11) || (header.s.nlst > 11) || (header.s.nfst + header.s.nlst > 15)) {
+		if ((header.word0.cn38xx.nfst > 11)
+		     || (header.word0.cn38xx.nlst > 11)
+		     || (header.word0.cn38xx.nfst + header.word0.cn38xx.nlst > 15)) {
 			cvmx_dprintf("DMA engine submit too large\n");
 			return -1;
 		}
 	}
 
-	cmds[0] = header.u64;
+	cmds[0] = header.word0.u64;
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		cmds[1] = header.word1.u64;
+		cmd_count = 2;
+	}
 	while (num_buffers--) {
 		cmds[cmd_count++] = buffers->u64;
 		buffers++;
@@ -363,8 +377,13 @@ static inline int __cvmx_dma_engine_build_internal_pointers(cvmx_dma_engine_buff
 		if (chunk > 8191)
 			chunk = 8191;
 		buffers[segments].u64 = 0;
-		buffers[segments].internal.size = chunk;
-		buffers[segments].internal.addr = address;
+		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+			buffers[segments].internal_cn78xx.size = chunk;
+			buffers[segments].internal_cn78xx.addr = address;
+		} else {
+			buffers[segments].internal.size = chunk;
+			buffers[segments].internal.addr = address;
+		}
 		address += chunk;
 		size -= chunk;
 		segments++;
@@ -482,30 +501,43 @@ int cvmx_dma_engine_transfer(int engine, cvmx_dma_engine_header_t header, uint64
 {
 	cvmx_dma_engine_buffer_t buffers[32];
 	int words = 0;
+	uint32_t nfst, nlst;
+	cvmx_dma_engine_transfer_t type;
 
-	switch (header.s.type) {
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		type = header.word0.cn78xx.type;
+	else
+		type = header.word0.cn38xx.type;
+	switch (type) {
 	case CVMX_DMA_ENGINE_TRANSFER_INTERNAL:
-		header.s.nfst = __cvmx_dma_engine_build_internal_pointers(buffers, first_address, size);
-		words += header.s.nfst;
-		header.s.nlst = __cvmx_dma_engine_build_internal_pointers(buffers + words, last_address, size);
-		words += header.s.nlst;
+		nfst = __cvmx_dma_engine_build_internal_pointers(buffers, first_address, size);
+		words += (nfst & 0xf);
+		nlst = __cvmx_dma_engine_build_internal_pointers(buffers + words, last_address, size);
+		words += (nlst & 0xf);
 		break;
 	case CVMX_DMA_ENGINE_TRANSFER_INBOUND:
 	case CVMX_DMA_ENGINE_TRANSFER_OUTBOUND:
-		header.s.nfst = __cvmx_dma_engine_build_internal_pointers(buffers, first_address, size);
-		words += header.s.nfst;
-		header.s.nlst = __cvmx_dma_engine_build_external_pointers(buffers + words, last_address, size);
-		words += header.s.nlst + ((header.s.nlst - 1) >> 2) + 1;
+		nfst = __cvmx_dma_engine_build_internal_pointers(buffers, first_address, size);
+		words += (nfst & 0xf);
+		nlst = __cvmx_dma_engine_build_external_pointers(buffers + words, last_address, size);
+		words += nlst + ((nlst - 1) >> 2) + 1;
 		break;
 	case CVMX_DMA_ENGINE_TRANSFER_EXTERNAL:
-		header.s.nfst = __cvmx_dma_engine_build_external_pointers(buffers, first_address, size);
-		words += header.s.nfst + ((header.s.nfst - 1) >> 2) + 1;
-		header.s.nlst = __cvmx_dma_engine_build_external_pointers(buffers + words, last_address, size);
-		words += header.s.nlst + ((header.s.nlst - 1) >> 2) + 1;
+		nfst = __cvmx_dma_engine_build_external_pointers(buffers, first_address, size);
+		words += nfst + ((nfst - 1) >> 2) + 1;
+		nlst = __cvmx_dma_engine_build_external_pointers(buffers + words, last_address, size);
+		words += nlst + ((nlst - 1) >> 2) + 1;
 		break;
 	default:
 		return -1;
 	}
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		header.word0.cn78xx.nlst = nlst;
+		header.word0.cn78xx.nfst = nfst;
+	} else {
+		header.word0.cn38xx.nlst = nlst;
+		header.word0.cn38xx.nfst = nfst;
+	}
 	return cvmx_dma_engine_submit(engine, header, words, buffers);
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-error-trees.c b/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
index 0e8d81c..cd7f735 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
@@ -2645,40 +2645,6 @@ static struct cvmx_error_muxchild error_tree_cn30xx =
 						{0}}
 					},
 					{0}}},
-				{1, 57 /* pcm */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_ENA(0) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(0)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(0)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(0)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(0)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_ENA(1) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(1)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(1)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(1)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(1)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_ENA(2) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(2)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(2)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(2)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(2)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_SUM(3) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_ENA(3) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(3)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(3)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(3)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(3)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{0}}},
 				{0}}
 			},
 			{0}}},
@@ -2990,40 +2956,6 @@ static struct cvmx_error_muxchild error_tree_cn50xx =
 						{0}}
 					},
 					{0}}},
-				{1, 57 /* pcm */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_ENA(0) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(0)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(0)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(0)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(0)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_ENA(1) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(1)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(1)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(1)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(1)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_ENA(2) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(2)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(2)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(2)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(2)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_SUM(3) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_ENA(3) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(3)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(3)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(3)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(3)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{0}}},
 				{0}}
 			},
 			{0}}},
@@ -3695,40 +3627,6 @@ static struct cvmx_error_muxchild error_tree_cn70xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
-				{1, 57 /* pcm */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_ENA(0) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(0)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(0)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(0)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(0)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_ENA(1) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(1)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(1)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(1)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(1)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_ENA(2) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(2)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(2)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(2)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(2)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_SUM(3) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_ENA(3) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(3)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(3)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(3)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(3)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{0}}},
 				{0}}
 			},
 			{CVMX_ADD_IO_SEG(0x0001070000000108ull) /* CVMX_CIU_INT_SUM1 */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
@@ -4445,10 +4343,8 @@ static struct cvmx_error_muxchild error_tree_cn70xx =
 				{1, 34 /* sli */, (struct cvmx_error_muxchild[]){
 					{CVMX_ADD_IO_SEG(0x00011F0000010330ull) /* CVMX_PEXP_SLI_INT_SUM */, CVMX_ADD_IO_SEG(0x00011F0000013CD0ull) /* CVMX_PEXP_SLI_INT_ENB_CIU */, (struct cvmx_error_regbit[]){
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PEXP_SLI_INT_SUM[RML_TO]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, NULL},
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "PEXP_SLI_INT_SUM[BAR0_TO]"},
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "PEXP_SLI_INT_SUM[IOB2BIG]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, NULL},
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "PEXP_SLI_INT_SUM[M0_UP_B0]"},
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "PEXP_SLI_INT_SUM[M0_UP_WI]"},
 							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 10, 0, "PEXP_SLI_INT_SUM[M0_UN_B0]"},
@@ -5851,40 +5747,6 @@ static struct cvmx_error_muxchild error_tree_cn31xx =
 						{0}}
 					},
 					{0}}},
-				{1, 57 /* pcm */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_ENA(0) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(0)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(0)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(0)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(0)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_ENA(1) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(1)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(1)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(1)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(1)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_ENA(2) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(2)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(2)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(2)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(2)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_SUM(3) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_ENA(3) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(3)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(3)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(3)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(3)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{0}}},
 				{0}}
 			},
 			{0}}},
@@ -8792,40 +8654,6 @@ static struct cvmx_error_muxchild error_tree_cn61xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
-				{1, 57 /* pcm */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_ENA(0) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(0)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(0)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(0)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(0)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_ENA(1) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(1)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(1)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(1)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(1)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_ENA(2) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(2)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(2)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(2)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(2)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_SUM(3) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_ENA(3) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(3)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(3)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(3)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(3)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{0}}},
 				{0}}
 			},
 			{CVMX_ADD_IO_SEG(0x0001070000000108ull) /* CVMX_CIU_INT_SUM1 */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
@@ -9585,40 +9413,6 @@ static struct cvmx_error_muxchild error_tree_cnf71xx =
 						NULL /*cvmx_error_childbit*/
 					},
 					{0}}},
-				{1, 57 /* pcm */, (struct cvmx_error_muxchild[]){
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((0) & 3) * 16384 /* CVMX_PCMX_INT_ENA(0) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(0)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(0)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(0)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(0)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((1) & 3) * 16384 /* CVMX_PCMX_INT_ENA(1) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(1)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(1)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(1)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(1)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((2) & 3) * 16384 /* CVMX_PCMX_INT_ENA(2) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(2)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(2)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(2)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(2)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{CVMX_ADD_IO_SEG(0x0001070000010028ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_SUM(3) */, CVMX_ADD_IO_SEG(0x0001070000010020ull) + ((3) & 3) * 16384 /* CVMX_PCMX_INT_ENA(3) */, (struct cvmx_error_regbit[]){
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PCMX_INT_SUM(3)[FSYNCMISSED]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PCMX_INT_SUM(3)[FSYNCEXTRA]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PCMX_INT_SUM(3)[TXEMPTY]"},
-							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PCMX_INT_SUM(3)[RXOVF]"},
-							{0}},
-						NULL /*cvmx_error_childbit*/
-					},
-					{0}}},
 				{0}}
 			},
 			{CVMX_ADD_IO_SEG(0x0001070000000108ull) /* CVMX_CIU_INT_SUM1 */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
diff --git a/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c b/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
index 30ba22f..282962b 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
@@ -46,6 +46,7 @@
 #include "cvmx.h"
 #include "cvmx-fpa.h"
 #include "cvmx-global-resources.h"
+#include "cvmx-sysinfo.h"
 #endif
 
 /** Allocates the pool from global resources and reserves them
@@ -88,7 +89,7 @@ static inline struct global_resource_tag get_fpa_resourse_tag(int node)
 		return cvmx_get_gr_tag('c','v','m','_','f','p','a','_','0','3','.','.','.','.','.','.');
 	default:
 		/* Add a panic?? */
-		return cvmx_get_gr_tag('i','n','v','a','l','i','d','.','.','.','.','.','.','.','.','.'); 
+		return cvmx_get_gr_tag('i','n','v','a','l','i','d','.','.','.','.','.','.','.','.','.');
 	}
 }
 
@@ -106,39 +107,63 @@ static inline struct global_resource_tag get_aura_resourse_tag(int node)
 		return cvmx_get_gr_tag('c','v','m','_','a','u','r','a','_','0','_','3','.','.','.','.');
 	default:
 		/* Add a panic?? */
-		return cvmx_get_gr_tag('i','n','v','a','l','i','d','.','.','.','.','.','.','.','.','.'); 
+		return cvmx_get_gr_tag('i','n','v','a','l','i','d','.','.','.','.','.','.','.','.','.');
 	}
 }
 
+int cvmx_fpa_reserve_compat(int node)
+{
+	int pool_num = 1, aura_num = 1;
+
+	if (!octeon_has_feature(OCTEON_FEATURE_FPA3))
+		return 0;
+
+	if (node == -1) node = cvmx_get_node_num();
+
+	if (cvmx_sysinfo_get()->init_core != cvmx_get_core_num())
+		return 0;
+	cvmx_fpa_allocate_fpa_pools(node, &pool_num, 4);
+	cvmx_fpa_allocate_auras(node, &aura_num, 4);
+
+	return 0;
+}
+
+
 
 /**
- * This will allocate count number of FPA pools on the specified node to the
+ * This will allocate/reserve count number of FPA pools on the specified node to the
  * calling application. These pools will be for exclusive use of the application
  * until they are freed.
  * @param pools_allocated is an array of length count allocated by the application
  * before invoking the cvmx_allocate_fpa_pool call. On return it will contain the
  * index numbers of the pools allocated.
+ * If -1 it finds the empty pool to allocate otherwise it reserves the specified pool.
  * @return 0 on success and -1 on failure.
  */
 int cvmx_fpa_allocate_fpa_pools(int node, int pools_allocated[], int count)
 {
 	int num_pools = CVMX_FPA_NUM_POOLS;
 	uint64_t owner = 0;
-	int rv;
+	int rv = 0;
 	struct global_resource_tag tag = get_fpa_resourse_tag(node);
 
-	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		num_pools = CVMX_FPA_NUM_POOLS_78XX;
-	}
+	if (octeon_has_feature(OCTEON_FEATURE_FPA3))
+		num_pools = CVMX_FPA3_NUM_POOLS;
 
 	if (cvmx_create_global_resource_range(tag, num_pools) != 0) {
 		cvmx_dprintf("ERROR: failed to create FPA global resource for"
 			     " node=%d\n", node);
 		return -1;
 	}
-	rv = cvmx_resource_alloc_many(tag, owner,
-				      count,
-				      pools_allocated);
+
+	if (pools_allocated[0] >= 0) {
+		while (count--)
+			rv = cvmx_reserve_global_resource_range(tag, owner, pools_allocated[count], 1);
+	} else {
+		rv = cvmx_resource_alloc_many(tag, owner,
+						       count,
+						       pools_allocated);
+	}
 	return rv;
 }
 
@@ -160,7 +185,7 @@ int cvmx_fpa_allocate_auras(int node, int auras_allocated[], int count)
 {
 	int num_aura = CVMX_FPA_AURA_NUM;
 	uint64_t owner = 0;
-	int rv;
+	int rv = 0;
 	struct global_resource_tag tag = get_aura_resourse_tag(node);
 
 	if (!OCTEON_IS_MODEL(OCTEON_CN78XX)) {
@@ -173,9 +198,12 @@ int cvmx_fpa_allocate_auras(int node, int auras_allocated[], int count)
 			     " node=%d\n", node);
 		return -1;
 	}
-	rv = cvmx_resource_alloc_many(tag, owner,
-				      count,
-				      auras_allocated);
+	if (auras_allocated[0] >= 0) {
+		while (count--)
+			rv = cvmx_reserve_global_resource_range(tag, owner, auras_allocated[count], 1);
+	} else
+		rv = cvmx_resource_alloc_many(tag, owner, count,
+					auras_allocated);
 	return rv;
 
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-global-resources.c b/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
index 7f08f55..9a870e0 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
@@ -497,11 +497,8 @@ int free_global_resources(void)
 	int i, entry_cnt;
 	uint64_t resource_entry_addr, phys_addr, size;
 
-	if (!__cvmx_global_resources_addr) {
-		if (dbg)
-			cvmx_dprintf("%s: __cvmx_global_resources_addr is null\n", __FUNCTION__);
-		return 0;
-	}
+	if (__cvmx_global_resources_addr == 0)
+		__cvmx_global_resources_init();
 
 	__cvmx_global_resource_lock();
 
@@ -525,6 +522,8 @@ int free_global_resources(void)
 	if (dbg)
 		cvmx_dprintf("freed global resources named block rc=%d \n",rc);
 
+	__cvmx_global_resources_addr = 0;
+
 	return 0;
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
new file mode 100644
index 0000000..c31b651
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -0,0 +1,980 @@
+/***********************license start***************
+ * Copyright (c) 2014  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Functions to configure the BGX MAC.
+ *
+ * <hr>$Revision$<hr>
+ */
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-helper.h>
+#include <asm/octeon/cvmx-clock.h>
+#include <asm/octeon/cvmx-qlm.h>
+#include <asm/octeon/cvmx-helper-bgx.h>
+#include <asm/octeon/cvmx-helper-board.h>
+#include <asm/octeon/cvmx-helper-cfg.h>
+#include <asm/octeon/cvmx-bgxx-defs.h>
+#else
+#include "cvmx.h"
+#include "cvmx-helper.h"
+#include "cvmx-helper-bgx.h"
+#include "cvmx-helper-board.h"
+#include "cvmx-helper-cfg.h"
+#include "cvmx-qlm.h"
+#endif
+
+int __cvmx_helper_bgx_enumerate(int interface)
+{
+	int qlm;
+	enum cvmx_qlm_mode mode;
+
+	/*
+	 * Check the QLM is configured correctly for SGMII, verify the
+	 * speed as well as the mode.
+	 */
+	qlm = cvmx_qlm_interface(interface);
+	if (qlm == -1)
+		return 0;
+
+	mode = cvmx_qlm_get_mode(qlm);
+	if (mode == CVMX_QLM_MODE_SGMII) {
+	/* FIXME: Check here if SGMII is a MIX interface */
+		return 4;
+	} else if (mode == CVMX_QLM_MODE_XAUI
+		   || mode == CVMX_QLM_MODE_XLAUI) {
+		return 1;
+	} else if (mode == CVMX_QLM_MODE_RXAUI) {
+		return 2;
+	} else if (mode == CVMX_QLM_MODE_XFI) {
+		return 4;
+	} else
+		return 0;
+}
+
+/**
+ * @INTERNAL
+ * Configure the bgx mac.
+ *
+ * @param interface Interface to bring up
+ *
+ * @param mode      Mode to configure the bgx mac as
+ */
+static void __cvmx_bgx_common_init(int interface)
+{
+	cvmx_bgxx_cmrx_config_t	cmr_config;
+	cvmx_bgxx_cmr_rx_lmacs_t bgx_cmr_rx_lmacs;
+	cvmx_bgxx_cmr_tx_lmacs_t bgx_cmr_tx_lmacs;
+	cvmx_helper_interface_mode_t mode;
+	int num_ports;
+	int index;
+	int lmac_type = 0;
+
+	num_ports = cvmx_helper_ports_on_interface(interface);
+	mode = cvmx_helper_interface_get_mode(interface);
+
+	switch (mode) {
+	case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		lmac_type = 0;
+		break;
+	case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		lmac_type = 1;
+		break;
+	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+		lmac_type = 2;
+		break;
+	case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+		lmac_type = 4;
+		break;
+	case CVMX_HELPER_INTERFACE_MODE_XFI:
+		lmac_type = 3;
+		break;
+	default:
+		break;
+	}
+
+	/* Set mode and lanes for all interface ports */
+	for (index = 0; index < num_ports; index++) {
+		cmr_config.u64 =
+			cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+		cmr_config.s.enable = 0;
+		cmr_config.s.lmac_type = lmac_type;
+		cmr_config.s.lane_to_sds = ((mode == CVMX_HELPER_INTERFACE_MODE_SGMII)
+					     ? index : ((mode == CVMX_HELPER_INTERFACE_MODE_RXAUI)
+						     ? (index ? 0xe : 4) : 0xe4));
+		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	}
+
+	bgx_cmr_rx_lmacs.u64 = 0;
+	bgx_cmr_rx_lmacs.s.lmacs = num_ports;
+	cvmx_write_csr(CVMX_BGXX_CMR_RX_LMACS(interface), bgx_cmr_rx_lmacs.u64);
+
+	bgx_cmr_tx_lmacs.u64 = 0;
+	bgx_cmr_tx_lmacs.s.lmacs = num_ports;
+	cvmx_write_csr(CVMX_BGXX_CMR_TX_LMACS(interface), bgx_cmr_tx_lmacs.u64);
+
+	for (index = 0; index < num_ports; index++) {
+		/* Setup pkind */
+		int pknd = cvmx_helper_get_pknd(interface, index);
+		cvmx_bgxx_cmrx_rx_id_map_t cmr_rx_id_map;
+		cvmx_bgxx_cmr_chan_msk_and_t chan_msk_and;
+		cvmx_bgxx_cmr_chan_msk_or_t chan_msk_or;
+		cmr_rx_id_map.u64 = 0;
+		cmr_rx_id_map.s.rid = 2 + index;
+		cmr_rx_id_map.s.pknd = pknd;
+		cvmx_write_csr(CVMX_BGXX_CMRX_RX_ID_MAP(index, interface),
+			       cmr_rx_id_map.u64);
+
+		/* Set backpressure channel mask AND/OR registers */
+		chan_msk_and.u64 = cvmx_read_csr(CVMX_BGXX_CMR_CHAN_MSK_AND(interface));
+		chan_msk_or.u64 = cvmx_read_csr(CVMX_BGXX_CMR_CHAN_MSK_OR(interface));
+		chan_msk_and.s.msk_and &= ~(0xffull << index);
+		chan_msk_or.s.msk_or |= (0xffull << index);
+		cvmx_write_csr(CVMX_BGXX_CMR_CHAN_MSK_AND(interface), chan_msk_and.u64);
+		cvmx_write_csr(CVMX_BGXX_CMR_CHAN_MSK_OR(interface), chan_msk_or.u64);
+	}
+
+#if 0
+	/* FIXME for MIX configuration */
+	/* Check if interface 0 or 1 must be routed to the mix */
+	if ((interface == 0 && MUX_78XX_IFACE0) ||
+	    (interface == 1 && MUX_78XX_IFACE1))
+		val = 1;
+	else
+		val = 0;
+
+	bgx_cmr_global_config.u64 = 0;
+	bgx_cmr_global_config.s.pmux_sds_sel = val;
+	cvmx_write_csr(CVMX_BGXX_CMR_GLOBAL_CONFIG(interface),
+		       bgx_cmr_global_config.u64);
+#endif
+}
+
+/**
+ * @INTERNAL
+ * Probe a SGMII interface and determine the number of ports
+ * connected to it. The SGMII interface should still be down after
+ * this call. This is used by interfaces using the bgx mac.
+ *
+ * @param interface Interface to probe
+ *
+ * @return Number of ports on the interface. Zero to disable.
+ */
+int __cvmx_helper_bgx_probe(int interface)
+{
+	return __cvmx_helper_bgx_enumerate(interface);
+}
+
+/**
+ * @INTERNAL
+ * Perform initialization required only once for an SGMII port.
+ *
+ * @param interface Interface to init
+ * @param index     Index of prot on the interface
+ *
+ * @return Zero on success, negative on failure
+ */
+static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int interface, int index)
+{
+	const uint64_t clock_mhz = cvmx_clock_get_rate(CVMX_CLOCK_SCLK) / 1000000;
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+	cvmx_bgxx_gmp_pcs_linkx_timer_t gmp_timer;
+
+	if (!cvmx_helper_is_port_valid(interface, index))
+		return 0;
+
+	/* Disable BGX */
+	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.s.enable = 0;
+	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
+	/*
+	 * Write PCS*_LINK*_TIMER_COUNT_REG[COUNT] with the
+	 * appropriate value. 1000BASE-X specifies a 10ms
+	 * interval. SGMII specifies a 1.6ms interval.
+	 */
+	gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	/* Adjust the MAC mode if requested by device tree */
+	gmp_misc_ctl.s.mac_phy =
+		cvmx_helper_get_mac_phy_mode(interface, index);
+	gmp_misc_ctl.s.mode =
+		cvmx_helper_get_1000x_mode(interface, index);
+	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+
+	gmp_timer.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, interface));
+	if (gmp_misc_ctl.s.mode)
+		/* 1000BASE-X */
+		gmp_timer.s.count = (10000ull * clock_mhz) >> 10;
+	else
+		/* SGMII */
+		gmp_timer.s.count = (1600ull * clock_mhz) >> 10;
+
+	cvmx_write_csr(CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, interface), gmp_timer.u64);
+
+	/*
+	 * Write the advertisement register to be used as the
+	 * tx_Config_Reg<D15:D0> of the autonegotiation.  In
+	 * 1000BASE-X mode, tx_Config_Reg<D15:D0> is PCS*_AN*_ADV_REG.
+	 * In SGMII PHY mode, tx_Config_Reg<D15:D0> is
+	 * PCS*_SGM*_AN_ADV_REG.  In SGMII MAC mode,
+	 * tx_Config_Reg<D15:D0> is the fixed value 0x4001, so this
+	 * step can be skipped.
+	 */
+	if (gmp_misc_ctl.s.mode) {
+		/* 1000BASE-X */
+		cvmx_bgxx_gmp_pcs_anx_adv_t gmp_an_adv;
+		gmp_an_adv.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_ANX_ADV(index, interface));
+		gmp_an_adv.s.rem_flt = 0;
+		gmp_an_adv.s.pause = 3;
+		gmp_an_adv.s.hfd = 1;
+		gmp_an_adv.s.fd = 1;
+		cvmx_write_csr(CVMX_BGXX_GMP_PCS_ANX_ADV(index, interface), gmp_an_adv.u64);
+	} else {
+		if (gmp_misc_ctl.s.mac_phy) {
+			/* PHY Mode */
+			cvmx_bgxx_gmp_pcs_sgmx_an_adv_t gmp_sgmx_an_adv;
+			gmp_sgmx_an_adv.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(index, interface));
+			gmp_sgmx_an_adv.s.dup = 1;
+			gmp_sgmx_an_adv.s.speed = 2;
+			cvmx_write_csr(CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(index, interface),
+				       gmp_sgmx_an_adv.u64);
+		} else {
+			/* MAC Mode - Nothing to do */
+		}
+	}
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Bring up the SGMII interface to be ready for packet I/O but
+ * leave I/O disabled using the GMX override. This function
+ * follows the bringup documented in 10.6.3 of the manual.
+ *
+ * @param interface Interface to bringup
+ * @param num_ports Number of ports on the interface
+ *
+ * @return Zero on success, negative on failure
+ */
+static int __cvmx_helper_bgx_sgmii_hardware_init(int interface, int num_ports)
+{
+	int index;
+	int do_link_set = 1;
+
+	__cvmx_bgx_common_init(interface);
+
+	for (index = 0; index < num_ports; index++) {
+		int ipd_port = cvmx_helper_get_ipd_port(interface, index);
+		cvmx_bgxx_gmp_gmi_txx_thresh_t gmi_tx_thresh;
+
+		if (!cvmx_helper_is_port_valid(interface, index))
+			continue;
+		__cvmx_helper_bgx_sgmii_hardware_init_one_time(interface, index);
+
+		/* Set TX Threshold */
+		gmi_tx_thresh.u64 = 0;
+		gmi_tx_thresh.s.cnt = 0x1ff; /* has 4 ports */
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_THRESH(index, interface),
+					gmi_tx_thresh.u64);
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+		/*
+		 * Linux kernel driver will call ....link_set with the
+		 * proper link state. In the simulator there is no
+		 * link state polling and hence it is set from
+		 * here.
+		 */
+		if (!(cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM))
+			do_link_set = 0;
+#endif
+		if (do_link_set)
+			__cvmx_helper_bgx_sgmii_link_set(ipd_port,
+					__cvmx_helper_bgx_sgmii_link_get(ipd_port));
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Bringup and enable a SGMII interface. After this call packet
+ * I/O should be fully functional. This is called with IPD
+ * enabled but PKO disabled. This is used by interfaces using
+ * the bgx mac.
+ *
+ * @param interface Interface to bring up
+ *
+ * @return Zero on success, negative on failure
+ */
+int __cvmx_helper_bgx_sgmii_enable(int interface)
+{
+	//cvmx_bgxx_cmrx_rx_id_map_t cmr_rx_id_map;
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	//cvmx_bgxx_cmr_chan_msk_and_t chan_msk_and;
+	//cvmx_bgxx_cmr_chan_msk_or_t chan_msk_or;
+	cvmx_bgxx_gmp_gmi_txx_append_t gmp_txx_append;
+	cvmx_bgxx_gmp_gmi_txx_sgmii_ctl_t gmp_sgmii_ctl;
+	int num_ports;
+	int index;
+
+	num_ports = cvmx_helper_ports_on_interface(interface);
+
+	__cvmx_helper_bgx_sgmii_hardware_init(interface, num_ports);
+
+	for (index = 0; index < num_ports; index++) {
+		gmp_txx_append.u64 = cvmx_read_csr(CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface));
+		gmp_txx_append.s.fcs = 0;
+		gmp_txx_append.s.pad = 0;
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface), gmp_txx_append.u64);
+		
+		gmp_sgmii_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface));
+		gmp_sgmii_ctl.s.align = gmp_txx_append.s.preamble ? 0 : 1;
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface),
+				gmp_sgmii_ctl.u64);
+
+		cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+		cmr_config.s.enable = 1;
+		cmr_config.s.data_pkt_tx_en = 1;
+		cmr_config.s.data_pkt_rx_en = 1;
+		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Initialize the SERTES link for the first time or after a loss
+ * of link.
+ *
+ * @param interface Interface to init
+ * @param index     Index of prot on the interface
+ *
+ * @return Zero on success, negative on failure
+ */
+static int __cvmx_helper_bgx_sgmii_hardware_init_link(int interface, int index)
+{
+	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+	int phy_mode, mode_1000x;
+
+	if (!cvmx_helper_is_port_valid(interface, index))
+		return 0;
+
+	gmp_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	/* Take PCS through a reset sequence */
+	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+		gmp_control.s.reset = 1;
+		cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+		       					     gmp_control.u64);
+
+		/* Wait until GMP_PCS_MRX_CONTROL[reset] comes out of reset */
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+				cvmx_bgxx_gmp_pcs_mrx_control_t, reset, ==, 0, 10000)) {
+			cvmx_dprintf("SGMII%d: Timeout waiting for port %d to finish reset\n", interface, index);
+			return -1;
+		}
+	}
+
+	/* Write GMP_PCS_MR*_CONTROL[RST_AN]=1 to ensure a fresh SGMII
+	   negotiation starts. */
+	gmp_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	gmp_control.s.rst_an = 1;
+	gmp_control.s.an_en = 1;
+	gmp_control.s.pwr_dn = 0;
+	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+		       gmp_control.u64);
+
+
+	phy_mode = cvmx_helper_get_mac_phy_mode(interface, index);
+	mode_1000x = cvmx_helper_get_1000x_mode(interface, index);
+
+	gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_misc_ctl.s.mac_phy = phy_mode;
+	gmp_misc_ctl.s.mode = mode_1000x;
+	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+	
+	if (phy_mode)
+		/* In PHY mode we can't query the link status so we just
+		   assume that the link is up */
+		return 0;
+
+	/* Wait for GMP_PCS_MRX_CONTROL[an_cpt] to be set, indicating that
+	   SGMII autonegotiation is complete. In MAC mode this isn't an
+	   ethernet link, but a link between OCTEON and PHY. */
+
+	if ((cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) &&
+	     CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_PCS_MRX_STATUS(index, interface),
+				   cvmx_bgxx_gmp_pcs_mrx_status_t, an_cpt,
+				   ==, 1, 10000)) {
+		cvmx_dprintf("SGMII%d: Port %d link timeout\n", interface, index);
+		return -1;
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Configure an SGMII link to the specified speed after the SERTES
+ * link is up.
+ *
+ * @param interface Interface to init
+ * @param index     Index of prot on the interface
+ * @param link_info Link state to configure
+ *
+ * @return Zero on success, negative on failure
+ */
+static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int interface,
+							    int index,
+							    cvmx_helper_link_info_t link_info)
+{
+	int is_enabled;
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_miscx_ctl;
+	cvmx_bgxx_gmp_gmi_prtx_cfg_t gmp_prtx_cfg;
+
+	if (!cvmx_helper_is_port_valid(interface, index))
+		return 0;
+
+	/* Disable GMX before we make any changes. Remember the enable state */
+	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+	is_enabled = cmr_config.s.enable;
+	cmr_config.s.enable = 0;
+	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
+	/* Wait for GMX to be idle */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
+				  cvmx_bgxx_gmp_gmi_prtx_cfg_t, rx_idle, ==, 1, 10000) ||
+	    CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
+				  cvmx_bgxx_gmp_gmi_prtx_cfg_t, tx_idle, ==, 1, 10000)) {
+		cvmx_dprintf("SGMII%d: Timeout waiting for port %d to be idle\n",
+			     interface, index);
+		return -1;
+	}
+
+	/* Read GMX CFG again to make sure the disable completed */
+	gmp_prtx_cfg.u64 = cvmx_read_csr(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface));
+
+	/*
+	 * Get the misc control for PCS. We will need to set the
+	 * duplication amount.
+	 */
+	gmp_miscx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+
+	/*
+	 * Use GMXENO to force the link down if the status we get says
+	 * it should be down.
+	 */
+	gmp_miscx_ctl.s.gmxeno = !link_info.s.link_up;
+
+	/* Only change the duplex setting if the link is up */
+	if (link_info.s.link_up)
+		gmp_prtx_cfg.s.duplex = link_info.s.full_duplex;
+
+	/* Do speed based setting for GMX */
+	switch (link_info.s.speed) {
+	case 10:
+		gmp_prtx_cfg.s.speed = 0;
+		gmp_prtx_cfg.s.speed_msb = 1;
+		gmp_prtx_cfg.s.slottime = 0;
+		/* Setting from GMX-603 */
+		gmp_miscx_ctl.s.samp_pt = 25;
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 64);
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
+		break;
+	case 100:
+		gmp_prtx_cfg.s.speed = 0;
+		gmp_prtx_cfg.s.speed_msb = 0;
+		gmp_prtx_cfg.s.slottime = 0;
+		gmp_miscx_ctl.s.samp_pt = 0x5;
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 64);
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
+		break;
+	case 1000:
+		gmp_prtx_cfg.s.speed = 1;
+		gmp_prtx_cfg.s.speed_msb = 0;
+		gmp_prtx_cfg.s.slottime = 1;
+		gmp_miscx_ctl.s.samp_pt = 1;
+		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 512);
+		if (gmp_prtx_cfg.s.duplex)
+			/* full duplex */
+			cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
+		else
+			/* half duplex */
+			cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 8192);
+		break;
+	default:
+		break;
+	}
+
+	/* Write the new misc control for PCS */
+	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface),
+		       gmp_miscx_ctl.u64);
+
+	/* Write the new GMX settings with the port still disabled */
+	cvmx_write_csr(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface), gmp_prtx_cfg.u64);
+
+	/* Read GMX CFG again to make sure the config completed */
+	cvmx_read_csr(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface));
+
+	/* Restore the enabled / disabled state */
+	cmr_config.s.enable = is_enabled;
+	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set(). This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
+cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port)
+{
+	cvmx_helper_link_info_t result;
+	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	int speed = 1000;
+
+	result.u64 = 0;
+
+	if (!cvmx_helper_is_port_valid(interface, index))
+		return result;
+
+	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM) {
+		/* The simulator gives you a simulated 1Gbps full duplex link */
+		result.s.link_up = 1;
+		result.s.full_duplex = 1;
+		result.s.speed = speed;
+		return result;
+	}
+
+	//speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
+
+	gmp_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	if (gmp_control.s.loopbck1) {
+		/* Force 1Gbps full duplex link for internal loopback */
+		result.s.link_up = 1;
+		result.s.full_duplex = 1;
+		result.s.speed = speed;
+		return result;
+	}
+
+	gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	if (gmp_misc_ctl.s.mac_phy) {
+		/* PHY Mode */
+		/* Note that this also works for 1000base-X mode */
+
+		result.s.speed = speed;
+		result.s.full_duplex = 1;
+		result.s.link_up = 1;
+		return result;
+	} else {
+		/* MAC Mode */
+		result = __cvmx_helper_board_link_get(ipd_port);
+	}
+	return result;
+}
+
+/**
+ * @INTERNAL
+ * Configure an IPD/PKO port for the specified link state. This
+ * function does not influence auto negotiation at the PHY level.
+ * The passed link state must always match the link state returned
+ * by cvmx_helper_link_get(). It is normally best to use
+ * cvmx_helper_link_autoconf() instead. This is used by interfaces
+ * using the bgx mac.
+ *
+ * @param ipd_port  IPD/PKO port to configure
+ * @param link_info The new link state
+ *
+ * @return Zero on success, negative on failure
+ */
+int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
+				 cvmx_helper_link_info_t link_info)
+{
+	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int index = cvmx_helper_get_interface_index_num(ipd_port);
+
+	if (!cvmx_helper_is_port_valid(interface, index))
+		return 0;
+
+	if (link_info.s.link_up) {
+		__cvmx_helper_bgx_sgmii_hardware_init_link(interface, index);
+	} else {
+		cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+
+		gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+
+		/* Disable autonegotiation only when MAC mode. */
+		if (gmp_misc_ctl.s.mac_phy == 0) {
+			cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
+
+			gmp_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+			gmp_control.s.an_en = 0;
+			cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_control.u64);
+			cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+		}
+		/*
+		 * Use GMXENO to force the link down it will get
+		 * reenabled later...
+		 */
+		gmp_misc_ctl.s.gmxeno = 1;
+		cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface),
+			       gmp_misc_ctl.u64);
+		cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+		return 0;
+	}
+	return __cvmx_helper_bgx_sgmii_hardware_init_link_speed(interface, index, link_info);
+}
+
+/**
+ * @INTERNAL
+ * Configure a port for internal and/or external loopback. Internal loopback
+ * causes packets sent by the port to be received by Octeon. External loopback
+ * causes packets received from the wire to sent out again. This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to loopback.
+ * @param enable_internal
+ *                 Non zero if you want internal loopback
+ * @param enable_external
+ *                 Non zero if you want external loopback
+ *
+ * @return Zero on success, negative on failure.
+ */
+int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port, int enable_internal,
+					   int enable_external)
+{
+	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_mrx_control;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+
+	if (!cvmx_helper_is_port_valid(interface, index))
+		return 0;
+
+	gmp_mrx_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	gmp_mrx_control.s.loopbck1 = enable_internal;
+	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_mrx_control.u64);
+
+	gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_misc_ctl.s.loopbck2 = enable_external;
+	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+
+	__cvmx_helper_bgx_sgmii_hardware_init_link(interface, index);
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Bringup XAUI interface. After this call packet I/O should be 
+ * fully functional.
+ *
+ * @param interface Interface to bring up
+ *
+ * @return Zero on success, negative on failure
+ */
+static int __cvmx_helper_bgx_xaui_link_init(int index, int interface)
+{
+	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
+	cvmx_bgxx_spux_misc_control_t spu_misc_control;
+	cvmx_bgxx_spux_control1_t spu_control1;
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	cvmx_helper_interface_mode_t mode;
+	mode = cvmx_helper_interface_get_mode(interface);
+
+	/* (1) Interface has already been enabled. */
+
+	/* (2) Disable BGX. */
+	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.s.enable = 0;
+	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
+	/* (3) Disable GMX and PCSX interrupts. */
+	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+		cvmx_write_csr(CVMX_BGXX_SMUX_RX_INT(index, interface), 0x0);
+		cvmx_write_csr(CVMX_BGXX_SMUX_TX_INT(index, interface), 0x0);
+		cvmx_write_csr(CVMX_BGXX_SPUX_INT(index, interface), 0x0);
+	}
+
+	/* Enable link training for 10GBASE-KR and 40GBASE-KR */
+	if (mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
+	    || mode == CVMX_HELPER_INTERFACE_MODE_XFI) {
+		cvmx_bgxx_spux_br_pmd_control_t spu_pmd_control;
+		spu_pmd_control.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface));
+		spu_pmd_control.s.train_en = 1;
+		cvmx_write_csr(CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface),
+				       spu_pmd_control.u64);
+	}
+
+	spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface));
+	spu_control1.s.lo_pwr = 0;
+	cvmx_write_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
+	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+		/* (4)a Take SMU/SPU through a reset sequence */
+		/* (4)a Set polarity and lane swapping. */
+		spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface));
+		spu_control1.s.reset = 1;
+		cvmx_write_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
+
+		spu_misc_control.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_MISC_CONTROL(index, interface));
+		spu_misc_control.s.rx_packet_dis = 1;
+		cvmx_write_csr(CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
+
+		/* Wait for PCS to come out of reset */
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_CONTROL1(index, interface),
+					 cvmx_bgxx_spux_control1_t, reset, ==, 0, 10000))
+			return -1;
+	}
+
+	/* 4d. Select Deficit Idle Count mode and unidirection mode */
+	smu_tx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_TX_CTL(index, interface));
+	/* Enable better IFG packing and improves performance */
+	smu_tx_ctl.s.dic_en = 1;
+	smu_tx_ctl.s.uni_en = 0;
+	cvmx_write_csr(CVMX_BGXX_SMUX_TX_CTL(index, interface), smu_tx_ctl.u64);
+
+	if (mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
+	    || mode == CVMX_HELPER_INTERFACE_MODE_XFI) {
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_INT(index, interface),
+					  cvmx_bgxx_spux_int_t, training_done, ==, 1, 10000))
+                	return -1;
+	}
+
+	/* (5) Check to make sure that the link appears up and stable. */
+	/* Wait for PCS to be aligned */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_BX_STATUS(index, interface),
+				  cvmx_bgxx_spux_bx_status_t, alignd, ==, 1, 10000))
+		return -1;
+
+	/* Wait for RX to be ready */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SMUX_RX_CTL(index, interface),
+					  cvmx_bgxx_smux_rx_ctl_t, status, ==, 0, 10000))
+		return -1;
+
+	/* Clear all error interrupts before enabling the interface. */
+	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+		cvmx_write_csr(CVMX_BGXX_SMUX_RX_INT(index, interface), ~0x0ull);
+		cvmx_write_csr(CVMX_BGXX_SMUX_TX_INT(index, interface), ~0x0ull);
+		cvmx_write_csr(CVMX_BGXX_SPUX_INT(index, interface), ~0x0ull);
+	}
+
+	/* Wait for GMX RX to be idle */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SMUX_CTRL(index, interface),
+				  cvmx_bgxx_smux_ctrl_t, rx_idle, ==, 1, 10000))
+		return -1;
+
+	/* Wait for GMX TX to be idle */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SMUX_CTRL(index, interface),
+				  cvmx_bgxx_smux_ctrl_t, tx_idle, ==, 1, 10000))
+		return -1;
+
+	/* Wait for receive link */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_BR_STATUS1(index, interface),
+				  cvmx_bgxx_spux_br_status1_t, rcv_lnk, ==, 1, 10000))
+		return -1;
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_STATUS2(index, interface),
+				  cvmx_bgxx_spux_status2_t, xmtflt, ==, 0, 10000))
+		return -1;
+
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_STATUS2(index, interface),
+				  cvmx_bgxx_spux_status2_t, rcvflt, ==, 0, 10000))
+		return -1;
+	
+	/* (7) Enable packet transmit and receive */
+	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.s.data_pkt_tx_en = 1;
+	cmr_config.s.data_pkt_rx_en = 1;
+	cmr_config.s.enable = 1;
+	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
+	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+		spu_misc_control.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_MISC_CONTROL(index, interface));
+		spu_misc_control.s.rx_packet_dis = 0;
+		cvmx_write_csr(CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
+	}
+
+	return 0;
+}
+
+int __cvmx_helper_bgx_xaui_enable(int interface)
+{
+	cvmx_bgxx_smux_tx_append_t smu_tx_append;
+	cvmx_bgxx_smux_tx_thresh_t smu_tx_thresh;
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	int index;
+	int num_ports = cvmx_helper_ports_on_interface(interface);
+	cvmx_helper_interface_mode_t mode;
+	mode = cvmx_helper_interface_get_mode(interface);
+
+	__cvmx_bgx_common_init(interface);
+	for (index = 0; index < num_ports; index++) {
+		int res = __cvmx_helper_bgx_xaui_link_init(index, interface);
+		if (res == -1) {
+			cvmx_dprintf("Failed to enable XAUI for BGX(%d,%d)\n", interface, index);
+			return res;
+		}
+		smu_tx_append.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_TX_APPEND(index, interface));
+		smu_tx_append.s.fcs_c = 0;
+		smu_tx_append.s.fcs_d = 0;
+		smu_tx_append.s.pad = 0;
+		cvmx_write_csr(CVMX_BGXX_SMUX_TX_APPEND(index, interface), smu_tx_append.u64);
+		smu_tx_thresh.u64 = 0;
+		if (mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
+		    || mode == CVMX_HELPER_INTERFACE_MODE_XFI)
+			smu_tx_thresh.s.cnt = 0x100;
+		else if (num_ports == 2)
+			smu_tx_thresh.s.cnt = 0x3ff;
+		else
+			smu_tx_thresh.s.cnt = 0x7ff;
+		cvmx_write_csr(CVMX_BGXX_SMUX_TX_THRESH(index, interface),
+					smu_tx_thresh.u64);
+		
+		cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+		cmr_config.s.enable = 1;
+		cmr_config.s.data_pkt_tx_en = 1;
+		cmr_config.s.data_pkt_rx_en = 1;
+		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	}
+	return 0;
+}
+
+cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port)
+{
+	cvmx_helper_link_info_t result;
+	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
+	cvmx_bgxx_smux_rx_ctl_t smu_rx_ctl;
+	cvmx_bgxx_spux_br_status1_t spu_status1;
+
+	smu_tx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_TX_CTL(index, interface));
+	smu_rx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_RX_CTL(index, interface));
+	spu_status1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_BR_STATUS1(index, interface));
+	result.u64 = 0;
+
+	/* Only return a link if both RX and TX are happy */
+	if ((smu_tx_ctl.s.ls == 0) &&
+	    (smu_rx_ctl.s.status == 0) &&
+	    (spu_status1.s.rcv_lnk == 1)) {
+		cvmx_bgxx_cmrx_config_t cmr_config;
+		cvmx_bgxx_spux_control1_t spu_control1;
+		spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface));
+		result.s.link_up = 1;
+		result.s.full_duplex = 1;
+		if (spu_control1.s.spd == 3)
+			result.s.speed = 40000;
+		else
+			result.s.speed = 10000;
+		cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+		if (cmr_config.s.enable) {
+			int res;
+			res = __cvmx_helper_bgx_xaui_link_init(index, interface);
+			if (res == -1)
+				cvmx_dprintf("Failed to get BGX(%d,%d) link\n", interface, index);
+		}
+	} else {
+		/* Disable GMX and PCSX interrupts. */
+		if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+			cvmx_write_csr(CVMX_BGXX_SMUX_RX_INT(index, interface), ~0x0ull);
+			cvmx_write_csr(CVMX_BGXX_SMUX_TX_INT(index, interface), ~0x0ull);
+			cvmx_write_csr(CVMX_BGXX_SPUX_INT(index, interface), ~0x0ull);
+		}
+	}
+
+	return result;
+}
+
+int __cvmx_helper_bgx_xaui_link_set(int ipd_port, cvmx_helper_link_info_t link_info)
+{
+	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
+	cvmx_bgxx_smux_rx_ctl_t smu_rx_ctl;
+	//cvmx_bgxx_spux_br_status1_t spu_status1;
+
+	smu_tx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_TX_CTL(index, interface));
+	smu_rx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_RX_CTL(index, interface));
+
+	/* If the link shouldn't be up, then just return */
+	if (!link_info.s.link_up)
+		return 0;
+
+	/* Do nothing if both RX and TX are happy */
+	if ((smu_tx_ctl.s.ls == 0) && (smu_rx_ctl.s.status == 0))
+		return 0;
+
+	/* Bring the link up */
+	return __cvmx_helper_bgx_xaui_link_init(index, interface);
+}
+
+int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port, 
+						     int enable_internal, 
+						     int enable_external)
+{
+	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	cvmx_bgxx_spux_control1_t spu_control1;
+	cvmx_bgxx_smux_ext_loopback_t smu_ext_loopback;
+
+	/* Set the internal loop */
+	spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface));
+	spu_control1.s.loopbck = enable_internal;
+	cvmx_write_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
+	/* Set the external loop */
+	smu_ext_loopback.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_EXT_LOOPBACK(index, interface));
+	smu_ext_loopback.s.en = enable_external;
+	cvmx_write_csr(CVMX_BGXX_SMUX_EXT_LOOPBACK(index, interface), smu_ext_loopback.u64);
+
+	return __cvmx_helper_bgx_xaui_link_init(index, interface);
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
index ddf7511..a91c1fb 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
@@ -90,7 +90,7 @@ CVMX_SHARED cvmx_helper_link_info_t(*cvmx_override_board_link_get) (int ipd_port
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 
-static int device_tree_dbg = 0;
+static const int device_tree_dbg = 0;
 
 static void cvmx_retry_i2c_write(int twsi_id, uint8_t dev_addr,
 				 uint16_t internal_addr, int num_bytes,
@@ -156,10 +156,9 @@ int __pip_eth_node(const void *fdt_addr, int aliases, int ipd_port)
 	if (dbg)
 		cvmx_dprintf("iface=%d ", iface);
 	if (iface < 0) {
-		cvmx_dprintf("ERROR : pip intf %d not found in device tree \n",
-			     interface_num);
 		if (dbg)
-			cvmx_dprintf("\n");
+			cvmx_dprintf("ERROR : pip intf %d not found in device tree\n",
+			     interface_num);
 		return -1;
 	}
 	snprintf(name_buffer, sizeof(name_buffer), "ethernet@%x", interface_index);
@@ -375,6 +374,7 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 	int pip, iface, eth;
 	int dbg = device_tree_dbg;
 	cvmx_helper_interface_mode_t mode;
+	uint32_t *val;
 
 	interface_num = cvmx_helper_get_interface_num(ipd_port);
 	mode = cvmx_helper_interface_get_mode(interface_num);
@@ -388,6 +388,9 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
         case CVMX_HELPER_INTERFACE_MODE_SGMII:
 	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
         case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+	case CVMX_HELPER_INTERFACE_MODE_AGL:
+	case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+	case CVMX_HELPER_INTERFACE_MODE_XFI:
 		aliases = 1;
 		break;
 	default:
@@ -430,7 +433,7 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 		cvmx_dprintf("%s: eth subnode offset %d from %s\n",
 			     __func__, eth, name_buffer);
 
-	if (eth < 0) 
+	if (eth < 0)
 		return -1;
 
 	if (fdt_getprop(fdt_addr, eth, "cavium,sgmii-mac-phy-mode", NULL))
@@ -443,6 +446,24 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 	else
 		cvmx_helper_set_1000x_mode(interface_num, port_index, false);
 
+	if (mode == CVMX_HELPER_INTERFACE_MODE_AGL) {
+		if (fdt_getprop(fdt_addr, eth,
+				"cavium,rx-clk-delay-bypass", NULL))
+			cvmx_helper_set_agl_rx_clock_delay_bypass(interface_num,
+								  port_index,
+								  true);
+		else
+			cvmx_helper_set_agl_rx_clock_delay_bypass(interface_num,
+								  port_index,
+								  false);
+
+		val = (uint32_t *)fdt_getprop(fdt_addr, eth,
+					      "cavium,rx-clk-skew", NULL);
+
+		cvmx_helper_set_agl_rx_clock_skew(interface_num, port_index,
+						  (val) ?
+						  fdt32_to_cpu(*val) : 0);
+	}
 	return (eth >= 0);
 }
 
@@ -458,11 +479,6 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 {
 	static void *fdt_addr = 0;
-
-	if (fdt_addr == 0)
-		fdt_addr = __cvmx_phys_addr_to_ptr(cvmx_sysinfo_get()->fdt_addr,
-						   OCTEON_FDT_MAX_SIZE);
-
 	uint32_t *phy_handle;
 	int aliases, eth, phy, phy_parent, phandle, ret, len, i;
 	int mdio_parent;
@@ -476,6 +492,10 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 	int dbg = device_tree_dbg;
 	int interface;
 
+	if (fdt_addr == 0)
+		fdt_addr = __cvmx_phys_addr_to_ptr(cvmx_sysinfo_get()->fdt_addr,
+						   OCTEON_FDT_MAX_SIZE);
+
 	phy_info->phy_addr = -1;
 	phy_info->direct_connect = -1;
 	phy_info->phy_type = (cvmx_phy_type_t) -1;
@@ -535,22 +555,46 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 			     ipd_port, phy);
 		return -1;
 	}
-	phy_compatible_str = (const char *)fdt_getprop(fdt_addr, phy, "compatible", NULL);
+
+	phy_compatible_str = (const char *)fdt_getprop(fdt_addr, phy,
+						       "compatible", NULL);
 	if (!phy_compatible_str) {
-		cvmx_dprintf("ERROR : no compatible prop in phy\n");
+		cvmx_dprintf("ERROR: no compatible prop in phy\n");
 		return -1;
 	}
-	if (memcmp("marvell", phy_compatible_str, strlen("marvell")) == 0) {
+	if (!memcmp("marvell", phy_compatible_str, strlen("marvell"))) {
 		phy_info->phy_type = MARVELL_GENERIC_PHY;
-	} else if (memcmp("broadcom", phy_compatible_str, strlen("broadcom")) == 0) {
+	} else if (!memcmp("broadcom", phy_compatible_str, strlen("broadcom"))) {
 		phy_info->phy_type = BROADCOM_GENERIC_PHY;
-	} else if (memcmp("vitesse", phy_compatible_str, strlen("vitesse")) == 0) {
-		phy_info->phy_type = VITESSE_GENERIC_PHY;
-	} else if (memcmp("cortina", phy_compatible_str, strlen("cortina")) == 0) {
+	} else if (!memcmp("vitesse", phy_compatible_str, strlen("vitesse"))) {
+		if (!fdt_node_check_compatible(fdt_addr, phy,
+					       "ethernet-phy-ieee802.3-c22")) {
+			phy_info->phy_type = GENERIC_8023_C22_PHY;
+			if (device_tree_dbg)
+				cvmx_dprintf("Vitesse 802.3 c22 detected\n");
+		} else {
+			phy_info->phy_type = GENERIC_8023_C45_PHY;
+			if (device_tree_dbg)
+				cvmx_dprintf("Vitesse 802.3 c45 detected\n");
+		}
+	} else if (!memcmp("cortina", phy_compatible_str, strlen("cortina"))) {
 		phy_info->phy_type = CORTINA_PHY;
 		host_mode_str = (const char *)fdt_getprop(fdt_addr, phy,
 							  "cortina,host-mode",
 							  NULL);
+	} else if (!memcmp("ti", phy_compatible_str, strlen("ti"))) {
+		phy_info->phy_type = GENERIC_8023_C45_PHY;
+
+	} else if (!fdt_node_check_compatible(fdt_addr, phy,
+					      "ethernet-phy-ieee802.3-c22")) {
+		phy_info->phy_type = GENERIC_8023_C22_PHY;
+		if (device_tree_dbg)
+			cvmx_dprintf("Generic 802.3 c22 PHY detected\n");
+	} else if (!fdt_node_check_compatible(fdt_addr, phy,
+					      "ethernet-phy-ieee802.3-c45")) {
+		phy_info->phy_type = GENERIC_8023_C45_PHY;
+		if (device_tree_dbg)
+			cvmx_dprintf("Generic 802.3 c45 PHY detected\n");
 	} else {
 		cvmx_dprintf("Unknown PHY compatibility\n");
 		phy_info->phy_type = -1;
@@ -620,8 +664,8 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 	}
 	ret = fdt_node_check_compatible(fdt_addr, phy_parent, "cavium,octeon-3860-mdio");
 	if (ret == 0) {
-		phy_info->direct_connect = 1;
 		uint32_t *mdio_reg_base = (uint32_t *) fdt_getprop(fdt_addr, phy_parent, "reg", 0);
+		phy_info->direct_connect = 1;
 		if (mdio_reg_base == 0) {
 			cvmx_dprintf("ERROR : unable to get reg property in phy mdio\n");
 			return -1;
@@ -1026,9 +1070,10 @@ cvmx_helper_link_info_t __cvmx_get_cortina_phy_link_state(int phy_addr)
 
 /**
  * @INTERNAL
- * Get link state of Vitesse PHY
+ * Get link state of generic C45 compliant PHYs
  */
-static cvmx_helper_link_info_t __get_vitesse_phy_link_state(int phy_addr)
+static cvmx_helper_link_info_t
+__get_generic_8023_c45_phy_link_state(int phy_addr)
 {
 	cvmx_helper_link_info_t result;
 	int phy_status;
@@ -1158,6 +1203,71 @@ static cvmx_helper_link_info_t __get_broadcom_phy_link_state(int phy_addr)
 	return result;
 }
 
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+/**
+ * @INTERNAL
+ * Get link state of generic gigabit PHY
+ *
+ * @param phy_addr - address of PHY
+ *
+ * @returns link status of the PHY
+ */
+static cvmx_helper_link_info_t
+__cvmx_get_generic_8023_c22_phy_link_state(int phy_addr)
+{
+	cvmx_helper_link_info_t result;
+	int phy_basic_control;	/* Register 0x0 */
+	int phy_basic_status;	/* Register 0x1 */
+	int phy_anog_adv;	/* Register 0x4 */
+	int phy_link_part_avail;/* Register 0x5 */
+	int phy_control;	/* Register 0x9 */
+	int phy_status;		/* Register 0xA */
+
+	result.u64 = 0;
+
+	phy_basic_status = cvmx_mdio_read(phy_addr >> 8, phy_addr & 0xff, 1);
+	if (!(phy_basic_status & 0x4))	/* Check if link is up */
+		return result;			/* Link is down, return link down */
+
+	result.s.link_up = 1;
+	phy_basic_control = cvmx_mdio_read(phy_addr >> 8, phy_addr & 0xff, 0);
+	/* Check if autonegotiation is enabled and completed */
+	if ((phy_basic_control & (1 << 12)) && (phy_basic_status & (1 << 5))) {
+		phy_status = cvmx_mdio_read(phy_addr >> 8, phy_addr & 0xff, 0xA);
+		phy_control = cvmx_mdio_read(phy_addr >> 8, phy_addr & 0xff, 0x9);
+
+		phy_status &= phy_control << 2;
+		phy_link_part_avail = cvmx_mdio_read(phy_addr >> 8,
+						     phy_addr & 0xff, 0x5);
+		phy_anog_adv = cvmx_mdio_read(phy_addr >> 8,
+					      phy_addr & 0xff, 0x4);
+		phy_link_part_avail &= phy_anog_adv;
+
+		if (phy_status & 0xC00) {	/* Gigabit full or half */
+			result.s.speed = 1000;
+			result.s.full_duplex = !!(phy_status & 0x800);
+		} else if (phy_link_part_avail & 0x0180) { /* 100 full or half */
+			result.s.speed = 100;
+			result.s.full_duplex = !!(phy_link_part_avail & 0x100);
+		} else if (phy_link_part_avail & 0x0060) {
+			result.s.speed = 10;
+			result.s.full_duplex = !!(phy_link_part_avail & 0x0040);
+		}
+	} else {
+		/* Not autonegotiated */
+		result.s.full_duplex = !!(phy_basic_control & (1 << 8));
+
+		if (phy_basic_control & (1 << 6))
+			result.s.speed = 1000;
+		else if (phy_basic_control & (1 << 13))
+			result.s.speed = 100;
+		else
+			result.s.speed = 10;
+	}
+	return result;
+}
+#endif
+
 /**
  * @INTERNAL
  * Get link state using inband status
@@ -1367,8 +1477,8 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 	}
 
 	switch (phy_info.phy_type) {
-	case VITESSE_GENERIC_PHY:
-		result = __get_vitesse_phy_link_state(phy_info.phy_addr);
+	case GENERIC_8023_C45_PHY:
+		result = __get_generic_8023_c45_phy_link_state(phy_info.phy_addr);
 		break;
 	case BROADCOM_GENERIC_PHY:
 		result = __get_broadcom_phy_link_state(phy_info.phy_addr);
@@ -1379,6 +1489,9 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get_from_dt(int ipd_port)
 	case CORTINA_PHY:
 		result = __cvmx_get_cortina_phy_link_state(phy_info.phy_addr);
 		break;
+	case GENERIC_8023_C22_PHY:
+		result = __cvmx_get_generic_8023_c22_phy_link_state(phy_info.phy_addr);
+		break;
 	case INBAND_PHY:
 	default:
 		if (OCTEON_IS_OCTEON1() ||
@@ -1428,6 +1541,7 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get(int ipd_port)
 	int is_broadcom_phy = 0;
 	int is_vitesse_phy = 0;
 	int is_cortina_phy = 0;
+	int is_ti_phy;
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 	if (cvmx_sysinfo_get()->fdt_addr) {
@@ -1527,6 +1641,7 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get(int ipd_port)
 		break;
 	case CVMX_BOARD_TYPE_SNIC10E:
 		is_vitesse_phy = 1;
+		is_ti_phy = 1;
 		break;
 	case CVMX_BOARD_TYPE_NIC10E_66:
 		if (cvmx_sysinfo_get()->board_rev_major >= 3)
@@ -1545,8 +1660,8 @@ cvmx_helper_link_info_t __cvmx_helper_board_link_get(int ipd_port)
 			result = __cvmx_get_cortina_phy_link_state(phy_addr);
 		} else if (is_broadcom_phy) {
 			result = __get_broadcom_phy_link_state(phy_addr);
-		} else if (is_vitesse_phy) {
-			result = __get_vitesse_phy_link_state(phy_addr);
+		} else if (is_vitesse_phy || is_ti_phy) {
+			result = __get_generic_8023_c45_phy_link_state(phy_addr);
 		} else {
 			/* This code assumes we are using a Marvell Gigabit PHY. */
 			result = __get_marvell_phy_link_state(phy_addr);
@@ -1907,7 +2022,6 @@ cvmx_helper_board_usb_clock_types_t __cvmx_helper_board_usb_get_clock_type(void)
 		return USB_CLOCK_TYPE_CRYSTAL_12;
 	return USB_CLOCK_TYPE_REF_48;
 }
-EXPORT_SYMBOL(__cvmx_helper_board_usb_get_clock_type);
 
 /**
  * @INTERNAL
@@ -1935,4 +2049,3 @@ int __cvmx_helper_board_usb_get_num_ports(int supported_ports)
 
 	return supported_ports;
 }
-EXPORT_SYMBOL(__cvmx_helper_board_usb_get_num_ports);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
index ff60dde1..7a75784 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
@@ -84,7 +84,7 @@ CVMX_SHARED struct cvmx_cfg_port_param cvmx_cfg_port[CVMX_HELPER_MAX_IFACE][CVMX
 				      	      { CVMX_HELPER_CFG_INVALID_VALUE, CVMX_HELPER_CFG_INVALID_VALUE,
 				                CVMX_HELPER_CFG_INVALID_VALUE, CVMX_HELPER_CFG_INVALID_VALUE,
 	                                        CVMX_HELPER_CFG_INVALID_VALUE, 0,
-	                                        0}}};
+	                                        0, 0, 0}}};
 
 /*
  * Indexed by the pko_port number
@@ -223,12 +223,12 @@ int cvmx_pko_queue_init_from_cvmx_config_non_pknd(void)
 	uint64_t count, start, end;
 
 	start = 0;
-	end   = __cvmx_pko_queue_static_config.non_pknd.max_ports_per_interface[0];
+	end   = __cvmx_pko_queue_static_config.non_pknd.pko_ports_per_interface[0];
 	count = __cvmx_pko_queue_static_config.non_pknd. pko_queues_per_port_interface[0];
 	cvmx_pko_queue_grp_alloc(start,end,count);
 
-	start = end;
-	end = start + __cvmx_pko_queue_static_config.non_pknd.max_ports_per_interface[1];
+	start = 16;
+	end = start + __cvmx_pko_queue_static_config.non_pknd.pko_ports_per_interface[1];
 	count = __cvmx_pko_queue_static_config.non_pknd.pko_queues_per_port_interface[1];
 	ret_val = cvmx_pko_queue_grp_alloc(start,end,count);
 	if (ret_val != 0)
@@ -464,54 +464,83 @@ void cvmx_helper_cfg_set_jabber_and_frame_max()
 {
 	int interface, port;
 
-	/*Set the frame max size and jabber size to 65535. */
-	for (interface = 0; interface < cvmx_helper_get_number_of_interfaces(); interface++) {
-		/* Set the frame max size and jabber size to 65535, as the defaults
-		   are too small. */
-		cvmx_helper_interface_mode_t imode = cvmx_helper_interface_get_mode(interface);
-		int num_ports = cvmx_helper_ports_on_interface(interface);
-
-		switch (imode) {
-		case CVMX_HELPER_INTERFACE_MODE_SGMII:
-		case CVMX_HELPER_INTERFACE_MODE_QSGMII:
-		case CVMX_HELPER_INTERFACE_MODE_XAUI:
-		case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-			for (port = 0; port < num_ports; port++)
-				cvmx_write_csr(CVMX_GMXX_RXX_JABBER(port, interface), 65535);
-			/* Set max and min value for frame check */
-			cvmx_pip_set_frame_check(interface, -1);
-			break;
-
-		case CVMX_HELPER_INTERFACE_MODE_RGMII:
-		case CVMX_HELPER_INTERFACE_MODE_GMII:
-			/* Set max and min value for frame check */
-			cvmx_pip_set_frame_check(interface, -1);
-			for (port = 0; port < num_ports; port++) {
-				if (!OCTEON_IS_MODEL(OCTEON_CN50XX))
-					cvmx_write_csr(CVMX_GMXX_RXX_FRM_MAX(port, interface), 65535);
-				cvmx_write_csr(CVMX_GMXX_RXX_JABBER(port, interface), 65535);
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		/*Set the frame max size and jabber size to 65535. */
+		for (interface = 0; interface < cvmx_helper_get_number_of_interfaces(); interface++) {
+			/* Set the frame max size and jabber size to 65535, as the defaults
+		   	are too small. */
+			cvmx_helper_interface_mode_t imode = cvmx_helper_interface_get_mode(interface);
+			int num_ports = cvmx_helper_ports_on_interface(interface);
+
+			switch (imode) {
+			case CVMX_HELPER_INTERFACE_MODE_SGMII:
+				cvmx_pip_set_frame_check(interface, -1);
+				for (port = 0; port < num_ports; port++)
+					cvmx_write_csr(CVMX_BGXX_GMP_GMI_RXX_JABBER(port, interface), 65535);
+				break;
+			case CVMX_HELPER_INTERFACE_MODE_XAUI:
+			case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+			case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+			case CVMX_HELPER_INTERFACE_MODE_XFI:
+				cvmx_pip_set_frame_check(interface, -1);
+				for (port = 0; port < num_ports; port++)
+					cvmx_write_csr(CVMX_BGXX_SMUX_RX_JABBER(port, interface), 65535);
+				break;
+			default:
+				break;
 			}
-			break;
-		case CVMX_HELPER_INTERFACE_MODE_ILK:
-			/* Set max and min value for frame check */
-			cvmx_pip_set_frame_check(interface, -1);
-			for (port = 0; port < num_ports; port++) {
-				int ipd_port = cvmx_helper_get_ipd_port(interface, port);
-				cvmx_ilk_enable_la_header(ipd_port, 0);
+		}
+	} else {
+
+		/*Set the frame max size and jabber size to 65535. */
+		for (interface = 0; interface < cvmx_helper_get_number_of_interfaces(); interface++) {
+			/* Set the frame max size and jabber size to 65535, as the defaults
+		   	are too small. */
+			cvmx_helper_interface_mode_t imode = cvmx_helper_interface_get_mode(interface);
+			int num_ports = cvmx_helper_ports_on_interface(interface);
+
+			switch (imode) {
+			case CVMX_HELPER_INTERFACE_MODE_SGMII:
+			case CVMX_HELPER_INTERFACE_MODE_QSGMII:
+			case CVMX_HELPER_INTERFACE_MODE_XAUI:
+			case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+				for (port = 0; port < num_ports; port++)
+					cvmx_write_csr(CVMX_GMXX_RXX_JABBER(port, interface), 65535);
+				/* Set max and min value for frame check */
+				cvmx_pip_set_frame_check(interface, -1);
+				break;
+
+			case CVMX_HELPER_INTERFACE_MODE_RGMII:
+			case CVMX_HELPER_INTERFACE_MODE_GMII:
+				/* Set max and min value for frame check */
+				cvmx_pip_set_frame_check(interface, -1);
+				for (port = 0; port < num_ports; port++) {
+					if (!OCTEON_IS_MODEL(OCTEON_CN50XX))
+						cvmx_write_csr(CVMX_GMXX_RXX_FRM_MAX(port, interface), 65535);
+					cvmx_write_csr(CVMX_GMXX_RXX_JABBER(port, interface), 65535);
+				}
+				break;
+			case CVMX_HELPER_INTERFACE_MODE_ILK:
+				/* Set max and min value for frame check */
+				cvmx_pip_set_frame_check(interface, -1);
+				for (port = 0; port < num_ports; port++) {
+					int ipd_port = cvmx_helper_get_ipd_port(interface, port);
+					cvmx_ilk_enable_la_header(ipd_port, 0);
+				}
+				break;
+			case CVMX_HELPER_INTERFACE_MODE_SRIO:
+				/* Set max and min value for frame check */
+				cvmx_pip_set_frame_check(interface, -1);
+				break;
+			case CVMX_HELPER_INTERFACE_MODE_AGL:
+				/* Set max and min value for frame check */
+				cvmx_pip_set_frame_check(interface, -1);
+				cvmx_write_csr(CVMX_AGL_GMX_RXX_FRM_MAX(0), 65535);
+				cvmx_write_csr(CVMX_AGL_GMX_RXX_JABBER(0), 65535);
+				break;
+			default:
+				break;
 			}
-			break;
-		case CVMX_HELPER_INTERFACE_MODE_SRIO:
-			/* Set max and min value for frame check */
-			cvmx_pip_set_frame_check(interface, -1);
-			break;
-		case CVMX_HELPER_INTERFACE_MODE_AGL:
-			/* Set max and min value for frame check */
-			cvmx_pip_set_frame_check(interface, -1);
-			cvmx_write_csr(CVMX_AGL_GMX_RXX_FRM_MAX(0), 65535);
-			cvmx_write_csr(CVMX_AGL_GMX_RXX_JABBER(0), 65535);
-			break;
-		default:
-			break;
 		}
 	}
 }
@@ -587,6 +616,10 @@ int cvmx_helper_cfg_ipd2pko_port_base(int ipd_port)
 {
 	int ipd_y, ipd_x;
 
+	/* Internal PKO ports are not present in PKO3 */
+	if(OCTEON_IS_MODEL(OCTEON_CN78XX))
+		return ipd_port;
+
 	ipd_y = IPD2PKO_CACHE_Y(ipd_port);
 	ipd_x = IPD2PKO_CACHE_X(ipd_port);
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-errata.c b/arch/mips/cavium-octeon/executive/cvmx-helper-errata.c
index 3567de1..4052c51 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-errata.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-errata.c
@@ -45,7 +45,7 @@
  * chip errata. For the most part, code doesn't need to call
  * these functions directly.
  *
- * <hr>$Revision: 78395 $<hr>
+ * <hr>$Revision: 94793 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -189,7 +189,7 @@ int __cvmx_helper_errata_fix_ipd_ptr_alignment(void)
 		cvmx_write_csr(CVMX_GMXX_RXX_FRM_MAX(INDEX(FIX_IPD_OUTPORT), INTERFACE(FIX_IPD_OUTPORT)), 65392 - 14 - 4);
 
 		cvmx_pko_send_packet_prepare(FIX_IPD_OUTPORT, cvmx_pko_get_base_queue(FIX_IPD_OUTPORT), CVMX_PKO_LOCK_CMD_QUEUE);
-		cvmx_pko_send_packet_finish(FIX_IPD_OUTPORT, cvmx_pko_get_base_queue(FIX_IPD_OUTPORT), pko_command, g_buffer, CVMX_PKO_LOCK_CMD_QUEUE);
+		cvmx_hwpko_send_packet_finish(FIX_IPD_OUTPORT, cvmx_pko_get_base_queue(FIX_IPD_OUTPORT), pko_command, g_buffer, CVMX_PKO_LOCK_CMD_QUEUE);
 
 		CVMX_SYNC;
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
index 5950725..19c6e7d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
@@ -78,12 +78,48 @@ int __cvmx_helper_ilk_enumerate(int interface)
 
 /**
  * @INTERNAL
- * Initialize all calendar entries to the xoff state. This
- * means no data is sent or received.
+ * Initialize all tx calendar entries to the xoff state.
+ * Initialize all rx calendar entries to the xon state. The rx calendar entries 
+ * must be in the xon state to allow new pko pipe assignments. If a calendar
+ * entry is assigned a different pko pipe while in the xoff state, the old pko 
+ * pipe will stay in the xoff state even when no longer used by ilk.
  *
  * @param interface Interface whose calendar are to be initialized.
  */
-void __cvmx_ilk_init_cal(int interface)
+void __cvmx_78xx_ilk_init_cal(int interface)
+{
+	cvmx_ilk_txx_cal_entryx_t	tx_entry;
+	cvmx_ilk_rxx_cal_entryx_t	rx_entry;
+	int				i;
+
+	/* Initialize all tx calendar entries to off */
+	tx_entry.u64 = 0;
+	tx_entry.s.ctl = XOFF;
+	for (i = 0; i < CVMX_ILK_MAX_CAL_IDX; i++) {
+		cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(i, interface),
+			       tx_entry.u64);
+	}
+
+	/* Initialize all rx calendar entries to on */
+	rx_entry.u64 = 0;
+	rx_entry.s.ctl = XON;
+	for (i = 0; i < CVMX_ILK_MAX_CAL_IDX; i++) {
+		cvmx_write_csr(CVMX_ILK_RXX_CAL_ENTRYX(i, interface),
+			       rx_entry.u64);
+	}
+}
+
+/**
+ * @INTERNAL
+ * Initialize all tx calendar entries to the xoff state.
+ * Initialize all rx calendar entries to the xon state. The rx calendar entries 
+ * must be in the xon state to allow new pko pipe assignments. If a calendar
+ * entry is assigned a different pko pipe while in the xoff state, the old pko 
+ * pipe will stay in the xoff state even when no longer used by ilk.
+ *
+ * @param interface Interface whose calendar are to be initialized.
+ */
+void __cvmx_68xx_ilk_init_cal(int interface)
 {
 	cvmx_ilk_txx_idx_cal_t	tx_idx;
 	cvmx_ilk_txx_mem_cal0_t tx_cal0;
@@ -128,7 +164,7 @@ void __cvmx_ilk_init_cal(int interface)
 	rx_idx.s.inc = 1;
 	cvmx_write_csr(CVMX_ILK_RXX_IDX_CAL(interface), rx_idx.u64);
 
-	/* Set state to xoff for all entries */
+	/* Set state to xon for all entries */
 	rx_cal0.u64 = 0;
 	rx_cal0.s.entry_ctl0 = XON;
 	rx_cal0.s.entry_ctl1 = XON;
@@ -150,6 +186,20 @@ void __cvmx_ilk_init_cal(int interface)
 
 /**
  * @INTERNAL
+ * Initialize all calendar entries.
+ *
+ * @param interface Interface whose calendar is to be initialized.
+ */
+void __cvmx_ilk_init_cal(int interface)
+{
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		__cvmx_68xx_ilk_init_cal(interface);
+	else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		__cvmx_78xx_ilk_init_cal(interface);
+}
+
+/**
+ * @INTERNAL
  * Setup the channel's tx calendar entry.
  *
  * @param interface Interface channel belongs to
@@ -350,8 +400,7 @@ int __cvmx_helper_ilk_probe(int interface)
 {
 	int res = 0;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	interface -= CVMX_ILK_GBL_BASE();
@@ -389,16 +438,16 @@ static int __cvmx_helper_ilk_init_port(int interface)
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		if (pipe_base == 0)
 			pipe_base = __cvmx_pko_get_pipe(interface + CVMX_ILK_GBL_BASE(), 0);
-	
+
 		if (pipe_base == -1) {
 			pipe_base = 0;
 			return 0;
 		}
-	
+
 		res = cvmx_ilk_set_pipe(interface, pipe_base, cvmx_ilk_chans[interface]);
 		if (res < 0)
 			return 0;
-	
+
 		/* set up pipe to channel mapping */
 		i = pipe_base;
 		if (pch == NULL) {
@@ -411,7 +460,7 @@ static int __cvmx_helper_ilk_init_port(int interface)
 			if (pch == NULL)
 				return 0;
 		}
-	
+
 		memset(pch, 0, CVMX_ILK_MAX_CHANS * sizeof(cvmx_ilk_pipe_chan_t));
 		tmp = pch;
 		for (j = 0; j < cvmx_ilk_chans[interface]; j++) {
@@ -430,15 +479,8 @@ static int __cvmx_helper_ilk_init_port(int interface)
 	/* set up channel to pkind mapping */
 	if (pknd_base == 0)
 		pknd_base = cvmx_helper_get_pknd(interface + CVMX_ILK_GBL_BASE(), 0);
-	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		/*
-		 * Must initialize pknd_base here until the pko initializion is
-		 * complete. This must be removed once the pko initialization is
-		 * working. TODO
-		 */
-		pknd_base = 0;
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 		pipe_base = pknd_base + cvmx_ilk_chans[interface];
-	}
 
 	i = pknd_base;
 	if (chpknd == NULL) {
@@ -523,6 +565,8 @@ static int __cvmx_helper_ilk_init_port(int interface)
 	}
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		enable_rx_cal = 1;
+		//FIXME: Comfigure CVMX_ILK_RID_CFG for RID range 
+		//using global resources and #RIDs = #chans for iface
 	}
 	res = cvmx_ilk_cal_setup_rx(interface, cvmx_ilk_chans[interface], calent, CVMX_ILK_RX_FIFO_WM, enable_rx_cal);
 	if (res < 0) {
@@ -653,12 +697,23 @@ retry:
 		ilk_rxx_cfg1.s.pkt_ena = ilk_txx_cfg1.s.pkt_ena;
 		cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 
-		/* Enable rxf_ctl_perr, rxf_lnk0_perr, rxf_lnk1_perr, pop_empty, push_full */
-		cvmx_write_csr(CVMX_ILK_GBL_INT_EN, 0x1f);
-		/* Enable bad_pipe, bad_seq, txf_err */
-		cvmx_write_csr(CVMX_ILK_TXX_INT_EN(interface), 0x7);
-		/* Enable crc24_err, lane_bad_word, pkt_drop_{rid,rxf,sop} */
-		cvmx_write_csr(CVMX_ILK_RXX_INT_EN(interface), 0x1e2);
+		if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+			/*
+			 * Enable rxf_ctl_perr, rxf_lnk0_perr, rxf_lnk1_perr,
+			 * pop_empty, push_full.
+			 */
+			cvmx_write_csr(CVMX_ILK_GBL_INT_EN, 0x1f);
+			/* Enable bad_pipe, bad_seq, txf_err */
+			cvmx_write_csr(CVMX_ILK_TXX_INT_EN(interface), 0x7);
+
+			/*
+			 * Enable crc24_err, lane_bad_word,
+			 * pkt_drop_{rid,rxf,sop}
+			 */
+			cvmx_write_csr(CVMX_ILK_RXX_INT_EN(interface), 0x1e2);
+		}
+		else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+			cvmx_write_csr(CVMX_ILK_GBL_INT, 0x18);
 
 		for (i = 0; i < CVMX_ILK_MAX_LANES(); i++) {
 			if ((1 << i) & lane_mask) {
@@ -666,7 +721,8 @@ retry:
 				cvmx_write_csr(CVMX_ILK_RX_LNEX_INT(i), 0x1ff);
 				/* Enable bad_64b67b, bdry_sync_loss, crc32_err, dskew_fifo_ovfl,
 				   scrm_sync_loss, serdes_lock_loss, stat_msg, ukwn_cntl_word */
-				cvmx_write_csr(CVMX_ILK_RX_LNEX_INT_EN(i), 0x1ff);
+				if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+					cvmx_write_csr(CVMX_ILK_RX_LNEX_INT_EN(i), 0x1ff);
 			}
 		}
 
@@ -692,7 +748,8 @@ fail:
 			   scrm_sync_loss, serdes_lock_loss, stat_msg, ukwn_cntl_word */
 			if ((1 << i) & lane_mask) {
 				cvmx_write_csr(CVMX_ILK_RX_LNEX_INT(i), 0x1ff);
-				cvmx_write_csr(CVMX_ILK_RX_LNEX_INT_EN(i), ~0x1ff);
+				if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+					cvmx_write_csr(CVMX_ILK_RX_LNEX_INT_EN(i), ~0x1ff);
 			}
 		}
 	}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-loop.c b/arch/mips/cavium-octeon/executive/cvmx-helper-loop.c
index 1b49428..869180f 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-loop.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-loop.c
@@ -43,17 +43,19 @@
  * Functions for LOOP initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 75749 $<hr>
+ * <hr>$Revision: 94747 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-helper.h>
 #include <asm/octeon/cvmx-pip-defs.h>
 #include <asm/octeon/cvmx-pko-defs.h>
+#include <asm/octeon/cvmx-lbk-defs.h>
+#include <asm/octeon/cvmx-pki.h>
 #else
-
 #include "cvmx.h"
 #include "cvmx-helper.h"
+#include "cvmx-pki.h"
 #endif
 
 int __cvmx_helper_loop_enumerate(int interface)
@@ -94,17 +96,22 @@ int __cvmx_helper_loop_enable(int interface)
 
 	num_ports = __cvmx_helper_get_num_ipd_ports(interface);
 
-	/* 
+	/*
 	 * We need to disable length checking so packet < 64 bytes and jumbo
 	 * frames don't get errors
 	 */
 	for (index = 0; index < num_ports; index++) {
 		offset = ((octeon_has_feature(OCTEON_FEATURE_PKND)) ? cvmx_helper_get_pknd(interface, index) : cvmx_helper_get_ipd_port(interface, index));
 
-		port_cfg.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(offset));
-		port_cfg.s.maxerr_en = 0;
-		port_cfg.s.minerr_en = 0;
-		cvmx_write_csr(CVMX_PIP_PRT_CFGX(offset), port_cfg.u64);
+		if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+			int node = cvmx_get_node_num();
+			cvmx_pki_endis_l2_errs(node, offset, 1, 0, 0);
+		} else {
+			port_cfg.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(offset));
+			port_cfg.s.maxerr_en = 0;
+			port_cfg.s.minerr_en = 0;
+			cvmx_write_csr(CVMX_PIP_PRT_CFGX(offset), port_cfg.u64);
+		}
 	}
 
 	/*
@@ -120,7 +127,7 @@ int __cvmx_helper_loop_enable(int interface)
 	/*
  	 * Set PKND and BPID for loopback ports.
  	 */
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		cvmx_pko_reg_loopback_pkind_t lp_pknd;
 		cvmx_pko_reg_loopback_bpid_t lp_bpid;
 
@@ -171,6 +178,14 @@ int __cvmx_helper_loop_enable(int interface)
 			cvmx_write_csr(CVMX_PKO_REG_LOOPBACK_PKIND, lp_pknd.u64);
 			cvmx_write_csr(CVMX_PKO_REG_LOOPBACK_BPID, lp_bpid.u64);
 		}
+	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		cvmx_lbk_chx_pkind_t lbk_pkind;
+
+		for (index = 0; index < num_ports; index++) {
+			lbk_pkind.u64 = 0;
+			lbk_pkind.s.pkind = cvmx_helper_get_pknd(interface, index);
+			cvmx_write_csr(CVMX_LBK_CHX_PKIND(index), lbk_pkind.u64);
+		}
 	}
 
 	return 0;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c b/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
index d26f3d6..1ae9423 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
@@ -43,7 +43,7 @@
  * Functions for NPI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 88039 $<hr>
+ * <hr>$Revision: 94257 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -52,12 +52,24 @@
 #include <asm/octeon/cvmx-pexp-defs.h>
 #include <asm/octeon/cvmx-sli-defs.h>
 #include <asm/octeon/cvmx-pip-defs.h>
+#include <asm/octeon/cvmx-pki.h>
 #else
 #include "cvmx.h"
 #include "cvmx-pko.h"
 #include "cvmx-helper.h"
+#include "cvmx-pki.h"
 #endif
 
+int CVMX_SHARED cvmx_npi_num_pipes = -1;
+
+/**
+ * Sets the number of pipe used by SLI packet output in the variable,
+ * which then later used for setting it up in HW
+ */
+void cvmx_npi_config_set_num_pipes(int num_pipes)
+{
+	cvmx_npi_num_pipes = num_pipes;
+}
 
 /**
  * @INTERNAL
@@ -71,11 +83,9 @@
  */
 int __cvmx_helper_npi_probe(int interface)
 {
-	/* TODO: When using config language what do we return? */
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 			return 32;
-	}
-	else if (!(OCTEON_IS_MODEL(OCTEON_CN52XX_PASS1_X) ||
+	} else if (!(OCTEON_IS_MODEL(OCTEON_CN52XX_PASS1_X) ||
 		   OCTEON_IS_MODEL(OCTEON_CN56XX_PASS1_X) ||
 		   OCTEON_IS_MODEL(OCTEON_CN31XX) ||
 		   OCTEON_IS_MODEL(OCTEON_CN50XX) ||
@@ -115,13 +125,19 @@ int __cvmx_helper_npi_enable(int interface)
 	 */
 	for (port = 0; port < num_ports; port++) {
 		union cvmx_pip_prt_cfgx port_cfg;
-		int ipd_port = (OCTEON_IS_MODEL(OCTEON_CN68XX)) ? cvmx_helper_get_pknd(interface, port) : cvmx_helper_get_ipd_port(interface, port);
-		port_cfg.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(ipd_port));
-		port_cfg.s.lenerr_en = 0;
-		port_cfg.s.maxerr_en = 0;
-		port_cfg.s.minerr_en = 0;
-		cvmx_write_csr(CVMX_PIP_PRT_CFGX(ipd_port), port_cfg.u64);
+		int ipd_port = (octeon_has_feature(OCTEON_FEATURE_PKND)) ?
+				cvmx_helper_get_pknd(interface, port) : cvmx_helper_get_ipd_port(interface, port);
+		if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+			unsigned int node = cvmx_get_node_num();
+			cvmx_pki_endis_l2_errs(node, ipd_port, 0, 0, 0);
 
+		} else {
+			port_cfg.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(ipd_port));
+			port_cfg.s.lenerr_en = 0;
+			port_cfg.s.maxerr_en = 0;
+			port_cfg.s.minerr_en = 0;
+			cvmx_write_csr(CVMX_PIP_PRT_CFGX(ipd_port), port_cfg.u64);
+		}
 		if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 			/* Set up pknd and bpid */
 			union cvmx_sli_portx_pkind config;
@@ -139,11 +155,7 @@ int __cvmx_helper_npi_enable(int interface)
 		union cvmx_sli_tx_pipe config;
 		config.u64 = cvmx_read_csr(CVMX_PEXP_SLI_TX_PIPE);
 		config.s.base = __cvmx_pko_get_pipe(interface, 0);
-#ifdef CVMX_HELPER_NPI_MAX_PIPES
-		config.s.nump = CVMX_HELPER_NPI_MAX_PIPES;
-#else
-		config.s.nump = num_ports;
-#endif
+		config.s.nump = cvmx_npi_num_pipes < 0 ? num_ports : cvmx_npi_num_pipes;
 		cvmx_write_csr(CVMX_PEXP_SLI_TX_PIPE, config.u64);
 	}
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
new file mode 100644
index 0000000..c86f6ad
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
@@ -0,0 +1,533 @@
+/***********************license start***************
+ * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * PKI helper functions.
+ */
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <linux/module.h>
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-pki-defs.h>
+#include <asm/octeon/cvmx-pki.h>
+#include <asm/octeon/cvmx-pow.h>
+#include <asm/octeon/cvmx-pki-resources.h>
+#include <asm/octeon/cvmx-helper-util.h>
+#include <asm/octeon/cvmx-ipd.h>
+#include <asm/octeon/cvmx-global-resources.h>
+#else
+#include "cvmx.h"
+#include "cvmx-version.h"
+#include "cvmx-error.h"
+#include "cvmx-pki-defs.h"
+#include "cvmx-pki.h"
+#include "cvmx-fpa.h"
+#include "cvmx-helper-pki.h"
+#include "cvmx-pki-resources.h"
+#include "cvmx-pow.h"
+#include "cvmx-helper-util.h"
+#include "cvmx-global-resources.h"
+#endif
+
+static int pki_helper_debug;
+
+struct cvmx_pki_global_config pki_dflt_gblcfg[CVMX_MAX_NODES] = {
+	{.cluster_mask = {0xf, 0, 0, 0},
+	.stat_mode = CVMX_PKI_STAT_MODE_PKIND,
+	.gbl_pen = {0, 0, 0, 1, 0, 1, 0, 0, 0, 0},
+	.frm_len = { {0x600, 0x40}, {0x600, 0x40} },
+	.pki_enable = 1},
+	{.cluster_mask = {0xf, 0, 0, 0},
+	.stat_mode = CVMX_PKI_STAT_MODE_PKIND,
+	.gbl_pen = {0, 0, 0, 1, 0, 1, 0, 0, 0, 0},
+	.frm_len = { {0x600, 0x40}, {0x600, 0x40} },
+	.pki_enable = 1} };
+
+struct cvmx_pki_cluster_grp_config pki_dflt_clgrp[CVMX_MAX_NODES] = {
+	{0, 0xf},
+	{0, 0xf} };
+
+struct cvmx_pki_pool_config pki_dflt_pool[CVMX_MAX_NODES] = {
+	{.pool_num = 0, .buffer_size = 2048, .buffer_count = 1000},
+	{.pool_num = 0, .buffer_size = 2048, .buffer_count = 1000} };
+
+struct cvmx_pki_aura_config pki_dflt_aura[CVMX_MAX_NODES] = {
+	{.aura_num = 0, .pool_num = 0, .buffer_count = 1000},
+	{.aura_num = 0, .pool_num = 0, .buffer_count = 1000} };
+
+struct cvmx_pki_style_config pki_dflt_style[CVMX_MAX_NODES] = {
+	{.parm_cfg = {.lenerr_en = 1, .maxerr_en = 1, .minerr_en = 1,
+	.fcs_strip = 1, .fcs_chk = 1, .first_skip = 40, .mbuff_size = 2048},
+	.tag_cfg = {.tag_fields = {.input_port = 1} } },
+	{.parm_cfg = {.lenerr_en = 1, .maxerr_en = 1, .minerr_en = 1,
+	.fcs_strip = 1, .fcs_chk = 1, .first_skip = 40, .mbuff_size = 2048},
+	.tag_cfg = {.tag_fields = {.input_port = 1} } } };
+
+struct cvmx_pki_sso_grp_config pki_dflt_sso_grp[CVMX_MAX_NODES];
+struct cvmx_pki_qpg_config pki_dflt_qpg[CVMX_MAX_NODES];
+struct cvmx_pki_pkind_config pki_dflt_pkind[CVMX_MAX_NODES];
+uint64_t pkind_style_map[CVMX_MAX_NODES][CVMX_PKI_NUM_PKIND];
+
+int __cvmx_helper_setup_pki_cluster_groups(int node)
+{
+	uint64_t cl_mask;
+	int cl_group;
+
+
+	cl_group = cvmx_pki_alloc_cluster_group(node, pki_dflt_clgrp[node].grp_num);
+	if (cl_group == -1) {
+		if (pki_dflt_clgrp[node].grp_num == -1)
+			return -1;
+		else
+			return 0; /* cluster already configured, share it */
+	}
+	cl_mask = pki_dflt_clgrp[node].cluster_mask;
+	if (pki_helper_debug)
+		cvmx_dprintf("pki-helper: setup pki cluster grp %d with cl_mask 0x%llx\n",
+			     (int)cl_group, (unsigned long long)cl_mask);
+	cvmx_pki_attach_cluster_to_group(node, cl_group, cl_mask);
+	return 0;
+}
+
+/**
+ * This function sets up pools/auras to be used by PKI
+ * @param node    node number
+ */
+int __cvmx_helper_pki_setup_sso_groups(int node)
+{
+	cvmx_coremask_t core_mask = CVMX_COREMASK_EMPTY;
+	cvmx_xgrp_t xgrp;
+	int grp;
+	int priority;
+	int weight;
+	int affinity;
+	uint64_t modify_mask;
+	uint8_t core_mask_set;
+
+	/* try to reserve sso groups and configure them if they are not configured */
+	/* vinita_to_do uncomment below when sso resource alloc is ready */
+#if 1
+	grp = pki_dflt_sso_grp[node].sso_grp_num;
+#else
+	grp = cvmx_sso_alloc_grp(node, pki_dflt_sso_grp[node].sso_grp_num);
+	if (grp == CVMX_RESOURCE_ALLOC_FAILED)
+		return -1;
+	else if (grp == CVMX_RESOURCE_ALREADY_RESERVED)
+		return 0; /* sso group already configured, share it */
+
+#endif
+	xgrp.xgrp = grp;
+	priority = pki_dflt_sso_grp[node].priority;
+	weight = pki_dflt_sso_grp[node].weight;
+	affinity = pki_dflt_sso_grp[node].affinity;
+	core_mask_set = pki_dflt_sso_grp[node].core_mask_set;
+	cvmx_coremask_set64_node(&core_mask, node, pki_dflt_sso_grp[node].core_mask);
+	modify_mask = CVMX_SSO_MODIFY_GROUP_PRIORITY |
+			CVMX_SSO_MODIFY_GROUP_WEIGHT |
+			CVMX_SSO_MODIFY_GROUP_AFFINITY;
+	if (pki_helper_debug)
+		cvmx_dprintf("pki-helper: set sso grp %d with priority %d \
+				weight %d core_mask 0x%llx\n", grp, priority, weight,
+			     (unsigned long long)pki_dflt_sso_grp[node].core_mask);
+	cvmx_sso_set_group_priority(node, xgrp, priority, weight,
+				    affinity, modify_mask);
+	cvmx_sso_set_group_core_affinity(xgrp, &core_mask, core_mask_set);
+	return 0;
+}
+
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+/**
+ * This function sets up pools/auras to be used by PKI
+ * @param node    node number
+ */
+int __cvmx_helper_pki_setup_fpa_pools(int node)
+{
+	int rs;
+	uint64_t buffer_count;
+	uint64_t buffer_size;
+
+	buffer_count = pki_dflt_pool[node].buffer_count;
+	if (buffer_count != 0) {
+		rs = cvmx_fpa_allocate_fpa_pools(node, &pki_dflt_pool[node].pool_num, 1);
+		if (rs == -1) {
+			if (pki_dflt_pool[node].pool_num == -1) {
+				cvmx_dprintf("ERROR: Failed to allocate pool %d\n", pki_dflt_pool[node].pool_num);
+				return -1;
+			}
+		} else {
+			buffer_size = pki_dflt_pool[node].buffer_size;
+			if (pki_helper_debug)
+				cvmx_dprintf("pki-helper: set fpa pool %d with \
+					buffer size %d buffer cnt %d\n",
+			pki_dflt_pool[node].pool_num, (int)buffer_size, (int)buffer_count);
+			cvmx_fpa_pool_stack_init(node, pki_dflt_pool[node].pool_num, "PKI Pools", 0,
+						 buffer_count, FPA_NATURAL_ALIGNMENT,
+						 buffer_size);
+		}
+	}
+	buffer_count = pki_dflt_aura[node].buffer_count;
+	if (buffer_count != 0) {
+		rs = cvmx_fpa_allocate_auras(node, &pki_dflt_aura[node].aura_num, 1);
+		if (rs == -1) {
+			if (pki_dflt_aura[node].aura_num == -1) {
+				cvmx_dprintf("ERROR: Failed to allocate aura %d\n", pki_dflt_aura[node].aura_num);
+				return -1;
+			} else
+				return 0; /* aura already configured, share it */
+		}
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+		if (pki_helper_debug)
+			cvmx_dprintf("pki-helper: set fpa aura %d in pool %d with buffer cnt %d\n",
+				     pki_dflt_aura[node].aura_num, pki_dflt_aura[node].pool_num,
+				     (int)buffer_count);
+		cvmx_fpa_assign_aura(node, pki_dflt_aura[node].aura_num, pki_dflt_pool[node].pool_num);
+		cvmx_fpa_aura_init(node, pki_dflt_aura[node].aura_num, "PKI Aura", 0, NULL, buffer_count, 0);
+#endif
+	}
+	return 0;
+}
+#endif
+
+
+int __cvmx_helper_setup_pki_qpg_table(int node)
+{
+	int offset;
+
+	offset = cvmx_pki_alloc_qpg_entry(node, pki_dflt_qpg[node].base_offset, 1);
+	if (offset == CVMX_RESOURCE_ALLOC_FAILED)
+		return -1;
+	else if (offset == CVMX_RESOURCE_ALREADY_RESERVED)
+		return 0; /* share the qpg table entry */
+	if (pki_helper_debug)
+		cvmx_dprintf("pki-helper: set qpg entry at offset %d with port add %d aura %d \
+				grp_ok %d grp_bad %d\n", offset, pki_dflt_qpg[node].port_add,
+				pki_dflt_qpg[node].aura, pki_dflt_qpg[node].grp_ok, pki_dflt_qpg[node].grp_bad);
+	cvmx_pki_write_qpg_entry(node, offset, pki_dflt_qpg[node].port_add, pki_dflt_qpg[node].aura,
+				 pki_dflt_qpg[node].grp_ok, pki_dflt_qpg[node].grp_bad);
+	return 0;
+}
+
+
+#if 0
+int __cvmx_helper_setup_pki_pcam_table(int node)
+{
+	uint64_t index;
+	int bank;
+
+	struct cvmx_pki_pcam_config *pcam_cfg;
+	index = pki_profiles[node].pcam_list.index;
+
+	while (index--) {
+		pcam_cfg = &pki_profiles[node].pcam_list.pcam_cfg[index];
+		bank = pcam_cfg->pcam_input.field % 2;
+		pcam_cfg->entry_num = cvmx_pki_pcam_alloc_entry(node, pcam_cfg->entry_num, bank, pcam_cfg->cluster_mask);
+		if (pcam_cfg->entry_num == -1) {
+			cvmx_dprintf("ERROR: Allocating pcam entry\n");
+			return -1;
+		}
+		cvmx_pki_pcam_write_entry(node, pcam_cfg->entry_num,
+					  pcam_cfg->cluster_mask, pcam_cfg->pcam_input,
+					  pcam_cfg->pcam_action);
+	}
+	return 0;
+}
+#endif
+
+/**
+ * This function installs the default VLAN entries to identify
+ * the VLAN and set WQE[vv], WQE[vs] if VLAN is found. In 78XX
+ * hardware (PKI) is not hardwired to recognize any 802.1Q VLAN
+ * Ethertypes
+ *
+ * @param node    node number
+ */
+int __cvmx_helper_pki_install_default_vlan(int node)
+{
+	struct cvmx_pki_pcam_input pcam_input;
+	struct cvmx_pki_pcam_action pcam_action;
+	enum cvmx_pki_term field;
+	int index;
+	int bank;
+	uint64_t cl_mask = CVMX_PKI_CLUSTER_ALL;
+
+	for (field = CVMX_PKI_PCAM_TERM_E_ETHTYPE0; field < CVMX_PKI_PCAM_TERM_E_ETHTYPE2; field++) {
+		bank = field & 0x01;
+
+		index = cvmx_pki_pcam_alloc_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
+		if (index < 0) {
+			cvmx_dprintf("ERROR: Allocating pcam entry node=%d bank=%d\n", node, bank);
+			return -1;
+		}
+		pcam_input.style = 0;
+		pcam_input.style_mask = 0;
+		pcam_input.field = field;
+		pcam_input.field_mask = 0xfd;
+		pcam_input.data = 0x81000000;
+		pcam_input.data_mask = 0xffff0000;
+		pcam_action.parse_mode_chg = CVMX_PKI_PARSE_NO_CHG;
+		pcam_action.layer_type_set = CVMX_PKI_LTYPE_E_VLAN;
+		pcam_action.style_add = 0;
+		pcam_action.pointer_advance = 4;
+		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input, pcam_action);/*vinita_to_do, cluster_mask*/
+
+		index = cvmx_pki_pcam_alloc_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
+		if (index < 0) {
+			cvmx_dprintf("ERROR: Allocating pcam entry node=%d bank=%d\n", node, bank);
+			return -1;
+		}
+		pcam_input.data = 0x88a80000;
+		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input, pcam_action);/*vinita_to_do, cluster_mask*/
+
+		index = cvmx_pki_pcam_alloc_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
+		if (index < 0) {
+			cvmx_dprintf("ERROR: Allocating pcam entry node=%d bank=%d\n", node, bank);
+			return -1;
+		}
+		pcam_input.data = 0x92000000;
+		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input, pcam_action);/*vinita_to_do, cluster_mask*/
+
+		index = cvmx_pki_pcam_alloc_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
+		if (index < 0) {
+			cvmx_dprintf("ERROR: Allocating pcam entry node=%d bank=%d\n", node, bank);
+			return -1;
+		}
+		pcam_input.data = 0x91000000;
+		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input, pcam_action);/*vinita_to_do, cluster_mask*/
+	}
+	return 0;
+}
+
+int __cvmx_helper_global_setup_pki(int node)
+{
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+	/* Setup the packet pools*/
+	__cvmx_helper_pki_setup_fpa_pools(node);
+#endif
+	/* __cvmx_helper_setup_global_cfg(node);*/ /* vinita_to_do */
+	/*set up default cluster*/
+	__cvmx_helper_setup_pki_cluster_groups(node);
+	/*set up default vlan */
+	__cvmx_helper_pki_install_default_vlan(node);
+	cvmx_pki_setup_clusters(node);
+	__cvmx_helper_pki_setup_sso_groups(node);
+	__cvmx_helper_setup_pki_qpg_table(node);
+	/* __cvmx_helper_setup_pki_pcam_table(node); *//* vinita_to_do */
+	cvmx_pki_enable_backpressure(node);
+	return 0;
+}
+
+int cvmx_helper_pki_get_num_qos_entry(enum cvmx_pki_qpg_qos qpg_qos)
+{
+	if (qpg_qos == CVMX_PKI_QPG_QOS_NONE)
+		return 1;
+	else if (qpg_qos == CVMX_PKI_QPG_QOS_VLAN || qpg_qos == CVMX_PKI_QPG_QOS_DSA_SRC
+		       || qpg_qos == CVMX_PKI_QPG_QOS_MPLS)
+		return 8;
+	else if (qpg_qos == CVMX_PKI_QPG_QOS_HIGIG) /*vinita_to_do for higig2*/
+		return 32;
+	else if (qpg_qos == CVMX_PKI_QPG_QOS_DIFFSERV)
+		return 64;
+	else {
+		cvmx_dprintf("ERROR: unrecognized qpg_qos = %d", qpg_qos);
+		return 0;
+	}
+	/* vinita_to_do add port_sh and port_msb too */
+}
+
+int __cvmx_helper_port_setup_pki(int node, int ipd_port)
+{
+	int interface, index;
+	int pknd, style_num;
+	int rs;
+	struct cvmx_pki_pkind_config pkind_cfg;
+
+	interface = cvmx_helper_get_interface_num(ipd_port);
+	index = cvmx_helper_get_interface_index_num(ipd_port);
+
+	pknd = cvmx_helper_get_pknd(interface, index);
+	style_num = pkind_style_map[node][pknd];
+
+	/* try to reserve the style, if it is not configured already, reserve
+	and configure it */
+	rs = cvmx_pki_alloc_style(node, style_num);
+	if (rs < 0) {
+		if (rs == CVMX_RESOURCE_ALLOC_FAILED)
+			return -1;
+	} else {
+		if (pki_helper_debug)
+			cvmx_dprintf("pki-helper: set style %d with default parameters\n", style_num);
+		/* configure style with default parameters */
+		cvmx_pki_write_style(node, style_num, CVMX_PKI_CLUSTER_ALL,
+				     &pki_dflt_style[node]);
+	}
+	if (pki_helper_debug)
+		cvmx_dprintf("pki-helper: set pkind %d with initial style %d\n", pknd, style_num);
+	/* write pkind configuration */
+	pkind_cfg = pki_dflt_pkind[node];
+	pkind_cfg.initial_style = style_num;
+	cvmx_pki_write_pkind(node, pknd, &pkind_cfg);
+	return 0;
+}
+
+int cvmx_helper_pki_setup_qpg_table(int node, int num_entries, int port_addr[],
+				    uint64_t aura[], uint64_t sso_grp_ok[], uint64_t sso_grp_bad[])
+{
+	int base_offset;
+	int entry;
+
+	base_offset = cvmx_pki_alloc_qpg_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, num_entries);
+	if (base_offset == -1) {
+		cvmx_dprintf("ERROR:setup_qpg_table: entries not available in qpg table\n");
+		return -1;
+	}
+	for (entry = 0; entry < num_entries; entry++, base_offset++) {
+		cvmx_pki_write_qpg_entry(node, base_offset, port_addr[entry], aura[entry],
+					 sso_grp_ok[entry], sso_grp_bad[entry]);
+	}
+	return base_offset - num_entries;
+}
+
+void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs)
+{
+	int index;
+	int pknd;
+	int cluster = 0;
+	cvmx_pki_clx_pkindx_cfg_t pkind_cfg;
+
+	for (index = 0; index < nports; index++) {
+		pknd = cvmx_helper_get_pknd(interface, index);
+		/*vinita_to_do; find the cluster in use*/
+		pkind_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pknd, cluster));
+		pkind_cfg.s.fcs_pres = has_fcs;
+		cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pknd, cluster), pkind_cfg.u64);
+	}
+}
+
+void cvmx_helper_pki_set_dflt_pool(int node, int pool, int buffer_size, int buffer_count)
+{
+	pki_dflt_pool[node].pool_num = pool;
+	pki_dflt_pool[node].buffer_size = buffer_size;
+	pki_dflt_pool[node].buffer_count = buffer_count;
+}
+
+void cvmx_helper_pki_set_dflt_aura(int node, int aura, int pool, int buffer_count)
+{
+	pki_dflt_aura[node].aura_num = aura;
+	pki_dflt_aura[node].pool_num = pool;
+	pki_dflt_aura[node].buffer_count = buffer_count;
+}
+
+void cvmx_helper_pki_set_dflt_pool_buffer(int node, int buffer_count)
+{
+	pki_dflt_pool[node].buffer_count = buffer_count;
+}
+void cvmx_helper_pki_set_dflt_aura_buffer(int node, int buffer_count)
+{
+	pki_dflt_aura[node].buffer_count = buffer_count;
+}
+
+void cvmx_helper_pki_set_dflt_style(int node, struct cvmx_pki_style_config *style_cfg)
+{
+	pki_dflt_style[node] = *style_cfg;
+}
+
+void cvmx_helper_pki_get_dflt_style(int node, struct cvmx_pki_style_config *style_cfg)
+{
+	*style_cfg = pki_dflt_style[node];
+}
+
+void cvmx_helper_pki_set_dflt_qpg(int node, struct cvmx_pki_qpg_config *qpg_cfg)
+{
+	pki_dflt_qpg[node] = *qpg_cfg;
+}
+
+void cvmx_helper_pki_get_dflt_qpg(int node, struct cvmx_pki_qpg_config *qpg_cfg)
+{
+	*qpg_cfg = pki_dflt_qpg[node];
+}
+
+/**
+ * This function sets up aura QOS for RED, backpressure and tail-drop.
+ *
+ * @param node       node number.
+ * @param aura       aura to configure.
+ * @param ena_red       enable RED based on [DROP] and [PASS] levels
+ *			1: enable 0:disable
+ * @param pass_thresh   pass threshold for RED.
+ * @param drop_thresh   drop threshold for RED
+ * @param ena_bp        enable backpressure based on [BP] level.
+ *			1:enable 0:disable
+ * @param bp_thresh     backpressure threshold.
+ * @param ena_drop      enable tail drop.
+ *			1:enable 0:disable
+ * @return Zero on success. Negative on failure
+ */
+int cvmx_helper_setup_aura_qos(int node, int aura, bool ena_red, bool ena_drop,
+			       uint64_t pass_thresh, uint64_t drop_thresh,
+			       bool ena_bp, uint64_t bp_thresh)
+{
+	ena_red = ena_red | ena_drop;
+	cvmx_fpa_setup_aura_qos(node, aura, ena_red, pass_thresh, drop_thresh,
+				ena_bp, bp_thresh);
+	cvmx_pki_enable_aura_qos(node, aura, ena_red, ena_drop, ena_bp);
+	return 0;
+}
+
+/**
+ * This function maps specified bpid to all the auras from which it can receive bp and
+ * then maps that bpid to all the channels, that bpid can asserrt bp on.
+ *
+ * @param node          node number.
+ * @param aura_map      array of auras to map to that bpid.
+ * @param aura_cnt      number of auras to map to the bpid
+ * @param chl_map       array of channels to map to that bpid.
+ * @param chl_cnt       number of channels to map to the bpid
+ * @param bpid          bpid to map
+ * @return Zero on success. Negative on failure
+ */
+int cvmx_helper_map_aura_channel_bpid(int node, int aura_map[], int aura_cnt,
+				      int chl_map[], int chl_cnt, int bpid)
+{
+	while (aura_cnt--)
+		cvmx_pki_write_aura_bpid(node, aura_map[aura_cnt], bpid);
+	while (chl_cnt--)
+		cvmx_pki_write_channel_bpid(node, chl_map[chl_cnt], bpid);
+	return 0;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pko.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pko.c
new file mode 100644
index 0000000..64b3c76
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pko.c
@@ -0,0 +1,301 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Helper Functions for the PKO
+ *
+ * $Id: cvmx-helper-pko.c 94829 2014-03-06 19:36:22Z ddaney $
+ */
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/octeon.h>
+#include <asm/octeon/cvmx-pko.h>
+#include <asm/octeon/cvmx-fpa.h>
+#include <asm/octeon/cvmx-clock.h>
+#include <asm/octeon/cvmx-helper-cfg.h>
+#else
+#include "cvmx.h"
+#include "cvmx-bootmem.h"
+#include "cvmx-helper.h"
+#include "cvmx-helper-ilk.h"
+#include "cvmx-ipd.h"
+#include "cvmx-pko.h"
+#include "cvmx-global-resources.h"
+#endif
+
+//XXX- these config data structures will go away soon!
+CVMX_SHARED cvmx_fpa_pool_config_t pko_fpa_config = {2,1024,0};
+
+/**
+ * cvmx_override_pko_queue_priority(int pko_port, uint64_t
+ * priorities[16]) is a function pointer. It is meant to allow
+ * customization of the PKO queue priorities based on the port
+ * number. Users should set this pointer to a function before
+ * calling any cvmx-helper operations.
+ */
+CVMX_SHARED void (*cvmx_override_pko_queue_priority) (int ipd_port, uint8_t *priorities) = NULL;
+EXPORT_SYMBOL(cvmx_override_pko_queue_priority);
+
+
+void cvmx_pko_set_cmd_que_pool_config(int64_t pool, uint64_t buffer_size,
+				    uint64_t buffer_count)
+{
+	pko_fpa_config.pool_num = pool;
+	pko_fpa_config.buffer_size = buffer_size;
+	pko_fpa_config.buffer_count = buffer_count;
+}
+EXPORT_SYMBOL(cvmx_pko_set_cmd_que_pool_config);
+
+void cvmx_pko_set_cmd_queue_pool_buffer_count(uint64_t buffer_count)
+{
+	pko_fpa_config.buffer_count = buffer_count;
+}
+
+void cvmx_pko_get_cmd_que_pool_config(cvmx_fpa_pool_config_t *pko_pool)
+{
+	*pko_pool = pko_fpa_config;
+}
+
+
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+/**
+ * Initialize PKO command queue buffer pool
+ */
+static int cvmx_helper_pko_pool_init(void)
+{
+	uint8_t pool;
+	unsigned buf_count;
+	unsigned pkt_buf_count;
+	int rc;
+
+	/* Reserve pool */
+	pool = cvmx_fpa_get_pko_pool();
+
+	/* Avoid redundant pool creation */
+	if (cvmx_fpa_get_block_size(pool) > 0) {
+		cvmx_dprintf("WARNING: %s: "
+			"pool %d already initialized\n",
+			__func__, pool);
+		return pool;
+	}
+
+	/* Calculate buffer count: one per queue + 3-word-cmds * max_pkts */
+	pkt_buf_count = cvmx_fpa_get_packet_pool_buffer_count();
+	buf_count = CVMX_PKO_MAX_OUTPUT_QUEUES + (pkt_buf_count * 3) / 8;
+
+	/* Allocate pools for pko command queues */
+	rc = __cvmx_helper_initialize_fpa_pool(pool,
+				cvmx_fpa_get_pko_pool_block_size(),
+				buf_count, "PKO Cmd-bufs");
+
+	if (rc < 0)
+		cvmx_dprintf("%s: ERROR: in PKO buffer pool\n", __func__);
+
+	return pool;
+}
+#endif
+
+
+/**
+ * Initialize the PKO
+ *
+ */
+int cvmx_helper_pko_init(void)
+{
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+	int rc;
+
+	rc = cvmx_helper_pko_pool_init();
+	if (rc < 0)
+		return rc;
+#else
+	//#	error "Pool number in kernel not implemented"
+#endif
+
+	__cvmx_helper_init_port_config_data();
+
+
+	cvmx_pko_hw_init(
+		cvmx_fpa_get_pko_pool(),
+		cvmx_fpa_get_pko_pool_block_size()
+		);
+	return 0;
+
+}
+
+/**
+ * @INTERNAL
+ * Setup the PKO for the ports on an interface. The number of
+ * queues per port and the priority of each PKO output queue
+ * is set here. PKO must be disabled when this function is called.
+ *
+ * @param interface Interface to setup PKO for
+ *
+ * @return Zero on success, negative on failure
+ *
+ * FIXME: This is for PKO1 only.
+ */
+int __cvmx_helper_interface_setup_pko(int interface)
+{
+	/*
+	 * Each packet output queue has an associated priority. The
+	 * higher the priority, the more often it can send a packet. A
+	 * priority of 8 means it can send in all 8 rounds of
+	 * contention. We're going to make each queue one less than
+	 * the last.  The vector of priorities has been extended to
+	 * support CN5xxx CPUs, where up to 16 queues can be
+	 * associated to a port.  To keep backward compatibility we
+	 * don't change the initial 8 priorities and replicate them in
+	 * the second half.  With per-core PKO queues (PKO lockless
+	 * operation) all queues have the same priority.
+	 */
+	/* uint8_t priorities[16] = {8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1}; */
+	uint8_t priorities[16] = {[0 ... 15] = 8 };
+
+	/*
+	 * Setup the IPD/PIP and PKO for the ports discovered
+	 * above. Here packet classification, tagging and output
+	 * priorities are set.
+	 */
+	int num_ports = cvmx_helper_ports_on_interface(interface);
+	while (num_ports--) {
+		int ipd_port;
+
+		if (!cvmx_helper_is_port_valid(interface, num_ports))
+			continue;
+
+		ipd_port = cvmx_helper_get_ipd_port(interface, num_ports);
+		/*
+		 * Give the user a chance to override the per queue
+		 * priorities.
+		 */
+		if (cvmx_override_pko_queue_priority)
+			cvmx_override_pko_queue_priority(ipd_port, priorities);
+
+		cvmx_pko_config_port(ipd_port,
+				     cvmx_pko_get_base_queue(ipd_port),
+				     cvmx_pko_get_num_queues(ipd_port),
+				     priorities);
+		ipd_port++;
+	}
+	return 0;
+//NOTE:
+// Now this function is called for all chips including 68xx,
+// but on the 68xx it does not enable multiple pko_iports per
+// eport, while before it was doing 3 pko_iport per eport
+// buf the reason for that is not clear.
+}
+
+/**
+ * wait for the pko queue to drain
+ *
+ * @param queue a valid pko queue
+ * @return count is the length of the queue after calling this
+ * function
+ */
+static int cvmx_helper_wait_pko_queue_drain(int queue)
+{
+	const int timeout = 5;	/* Wait up to 5 seconds for timeouts */
+	int count;
+	uint64_t start_cycle, stop_cycle;
+
+	count = cvmx_pko_queue_pend_count(queue);
+	if (count < 0)
+		return count;
+
+	start_cycle = cvmx_get_cycle();
+	stop_cycle = start_cycle + cvmx_clock_get_rate(CVMX_CLOCK_CORE) * timeout;
+	while (count > 0 && (cvmx_get_cycle() < stop_cycle)) {
+		cvmx_wait(10000);
+		count = cvmx_pko_queue_pend_count(queue);
+	}
+
+	return count;
+}
+
+/**
+ * @INTERNAL
+ *
+ * Drain and wait until all PKO queues are empty.
+ */
+int __cvmx_helper_pko_drain(void)
+{
+	int result = 0;
+
+	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
+		int queue, max_queue;
+
+		/* PKO2 */
+		max_queue = __cvmx_helper_cfg_pko_max_queue();
+		for (queue = 0; queue < max_queue; queue++) {
+			if (cvmx_helper_wait_pko_queue_drain(queue)) {
+				result = -1;
+				return result;
+			}
+		}
+	} else {
+		int num_interfaces = cvmx_helper_get_number_of_interfaces();
+		int interface, num_ports, index;
+
+		/* PKO1 */
+		for (interface = 0; interface < num_interfaces; interface++) {
+			num_ports = cvmx_helper_ports_on_interface(interface);
+			for (index = 0; index < num_ports; index++) {
+				int pko_port;
+				int queue;
+				int max_queue;
+				if (!cvmx_helper_is_port_valid(interface, index))
+					continue;
+				pko_port = cvmx_helper_get_ipd_port(interface, index);
+				queue = cvmx_pko_get_base_queue(pko_port);
+				max_queue = queue + cvmx_pko_get_num_queues(pko_port);
+				while (queue < max_queue) {
+					if (cvmx_helper_wait_pko_queue_drain(queue)) {
+						result = -1;
+						return result;
+					}
+					queue++;
+				}
+			}
+		}
+	}
+	return result;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
new file mode 100644
index 0000000..a1992f1
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
@@ -0,0 +1,903 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/*
+ * File version info: $Rev$
+ *
+ * PKOv3 helper file
+ */
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <linux/module.h>
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-clock.h>
+#include <asm/octeon/cvmx-ilk.h>
+#include <asm/octeon/cvmx-pko3.h>
+#include <asm/octeon/cvmx-pko3-resources.h>
+#include <asm/octeon/cvmx-helper.h>
+#include <asm/octeon/cvmx-helper-pko3.h>
+#include <asm/octeon/cvmx-helper-cfg.h>
+#else
+#include "cvmx.h"
+#include "cvmx-ilk.h"
+#include "cvmx-pko3.h"
+#include "cvmx-pko3-resources.h"
+#include "cvmx-helper.h"
+#include "cvmx-helper-pko3.h"
+#include "cvmx-helper-cfg.h"
+#endif
+
+/*
+ * PKO3 requires 4 buffers for each active Descriptor Queue,
+ * and because it is not known how many DQs will in fact be used
+ * when the PKO pool is populated, it is allocated the maximum
+ * number it may required.
+ * The additional 1K buffers are provisioned to acomodate longer
+ * descriptor queues, and jump buffers used by the legacy transmit
+ * function.
+ */
+#ifndef CVMX_PKO3_POOL_BUFFERS
+#define CVMX_PKO3_POOL_BUFFERS (1024*4+1024)
+#endif
+
+/* channels are present at L2 queue level by default */
+static const int cvmx_pko_default_channel_level = 0;
+
+static const int debug = 0;
+
+/* These global variables are relevant for boot CPU only */
+uint16_t __cvmx_pko3_aura_num = -1;
+uint16_t __cvmx_pko3_pool_num = -1;
+
+/* This constant can not be modified, defined here for clarity only */
+#define CVMX_PKO3_POOL_BUFFER_SIZE 4096 /* 78XX PKO requires 4KB */
+
+/**
+ * @INTERNAL
+ *
+ * Build an owner tag based on interface/port
+ */
+static int __cvmx_helper_pko3_res_owner(unsigned node, uint16_t ipd_port)
+{
+	int res_owner;
+	const int res_owner_pfix = 0x19d0 << 12;
+
+	ipd_port &= 0xfff;	/* 12-bit for local CHAN_E value */
+
+	res_owner = res_owner_pfix | ipd_port | (node << 10);
+
+	return res_owner;
+}
+
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+/**
+ * Configure an AURA/POOL designated for PKO internal use.
+ *
+ * This pool is used for (a) memory buffers that store PKO descriptor queues,
+ * (b) buffers for use with PKO_SEND_JUMP_S sub-header.
+ *
+ * The buffers of type (a) are never accessed by software, and their number
+ * should be at least equal to 4 times the number of descriptor queues
+ * in use.
+ *
+ * Type (b) buffers are consumed by PKO3 command-composition code,
+ * and are released by the hardware upon completion of transmission.
+ *
+ * @returns -1 if the pool could not be established or 12-bit AURA
+ * that includes the node number for use in PKO3 intialization call.
+ *
+ * NOTE: Linux kernel should pass its own aura to PKO3 initialization
+ * function so that the buffers can be mapped into kernel space
+ * for when software needs to adccess their contents.
+ */
+static int __cvmx_pko3_config_memory(unsigned node)
+{
+	int pool_num = 2, aura_num = 2;
+	int res;
+
+	/* Reserve PKO Aura and Pool number */
+	res = cvmx_fpa_allocate_fpa_pools(node, &pool_num, 1);
+	if(res < 0)
+		return res;
+
+	res = cvmx_fpa_allocate_auras(node, &aura_num, 1);
+	if(res < 0)
+		return res;
+
+	/* fpa pool intialization for pko command buffers */
+	res = cvmx_fpa_pool_stack_init(node, pool_num,
+				"PKO Pool", 0, //XXX- use local memory ?
+				CVMX_PKO3_POOL_BUFFERS,
+				FPA_NATURAL_ALIGNMENT,
+				CVMX_PKO3_POOL_BUFFER_SIZE);
+
+	res = cvmx_fpa_assign_aura(node, aura_num, pool_num);
+
+	res = cvmx_fpa_aura_init(node, aura_num,"PKO Aura", 0, NULL,
+			   CVMX_PKO3_POOL_BUFFERS, 0);
+
+	/* Store numbers e.g. for destruction */
+	__cvmx_pko3_pool_num = pool_num;
+	__cvmx_pko3_aura_num = aura_num;
+
+	/* Combine LAURA with NODE */
+	aura_num |= node << 10;
+
+	return aura_num;
+}
+#endif
+
+/** Initialize a single ILK link
+ *
+ * Each ILK link is one interface, the port portion of IPD
+ * represents a logical channel.
+ * The number of channels for each interface is derived from the ILK
+ * module configuration.
+ */
+static int __cvmx_pko3_config_ilk_interface(unsigned interface)
+{
+	int l1_q_num;
+	int l2_q_num;
+	int res;
+	int pko_mac_num;
+	unsigned num_chans;
+	unsigned node = cvmx_get_node_num();
+	uint16_t ipd_port;
+	int res_owner;
+	unsigned i;
+	const int num_dq = 1;	/* # of DQs per channel */
+
+	/* NOTE: changing `num_dq` to 8 will create 8 DQs per channel
+	 * to represent static priorities, but will be ordered by
+	 * system priority, not PCP QoS value. Probably not what we want.
+	 */
+
+	num_chans = __cvmx_helper_ilk_enumerate(interface);
+
+	if(debug)
+		cvmx_dprintf("%s: configuring iface %u with %u ILK channels\n",
+			__FUNCTION__, interface, num_chans);
+
+	/* ILK channels all go to the same mac */
+	pko_mac_num = __cvmx_pko_get_mac_num(interface, 0);
+	if (pko_mac_num < 0) {
+                cvmx_dprintf ("%s: ERROR Invalid interface\n", __FUNCTION__);
+		return -1;
+	}
+
+	/* Resources of all channels on this link have common owner */
+	ipd_port = cvmx_helper_get_ipd_port(interface, 0);
+
+	/* Build an identifiable owner */
+	res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+
+	/* Reserve port queue to make sure the MAC is not already configured */
+	l1_q_num = pko_mac_num;
+        l1_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_PORT_QUEUES,
+				res_owner, l1_q_num, 1);
+
+	if (l1_q_num != pko_mac_num) {
+                cvmx_dprintf ("%s: ERROR Reserving L1 PQ\n", __FUNCTION__);
+		return -1;
+	}
+
+
+        /* allocate level 2 queues, one per channel */
+        l2_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_L2_QUEUES, res_owner,
+                                           -1, num_chans);
+        if (l2_q_num < 0) {
+                cvmx_dprintf ("%s: ERROR allocation L2 SQ\n", __FUNCTION__);
+                return -1;
+        }
+
+
+	/* Configre <num_chans> children for MAC, with Fair-RR scheduling */
+	res = cvmx_pko3_pq_config_children(
+			pko_mac_num, l2_q_num, num_chans, -1);
+
+	if (res < 0) {
+		cvmx_dprintf("%s: ERROR: Could not setup ILK Channel queues\n",
+			__FUNCTION__);
+		return -1;
+	}
+
+	/* Configure children with one DQ per channel */
+	for (i = 0; i < num_chans; i++) {
+		int l3_q, l4_q, l5_q, dq, res;
+
+		l3_q = l4_q = l5_q = dq = -1;
+		ipd_port = cvmx_helper_get_ipd_port(interface, i);
+
+		/* map channels to l2 queues */
+		cvmx_pko3_map_channel(node, l1_q_num, l2_q_num+i, ipd_port);
+
+		//FIXME- can not convert it to a loop because
+		// of CVMX_PKO_Lx_QUEUES are enumerated
+
+		l3_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L3_QUEUES,
+			res_owner, -1, 1);
+		if(l3_q < 0) goto _fail;
+
+		res = cvmx_pko3_sq_config_children(2, l2_q_num+i, l3_q, 1, 1);
+		if(res < 0) goto _fail;
+
+		l4_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L4_QUEUES,
+			res_owner, -1, 1);
+		if(l4_q < 0) goto _fail;
+		res = cvmx_pko3_sq_config_children(3, l3_q, l4_q, 1, 1);
+		if(res < 0) goto _fail;
+
+		l5_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L5_QUEUES,
+			res_owner, -1, 1);
+		if(l5_q < 0) goto _fail;
+		res = cvmx_pko3_sq_config_children(4, l4_q, l5_q, 1, 1);
+		if(res < 0) goto _fail;
+
+		dq = cvmx_pko_alloc_queues(node, CVMX_PKO_DESCR_QUEUES,
+			res_owner, -1, num_dq);
+		if(dq < 0) goto _fail;
+
+		res = cvmx_pko3_sq_config_children(5, l5_q, dq, num_dq, num_dq);
+		if(res < 0) goto _fail;
+
+		/* register DQ range with the translation table */
+		res = __cvmx_pko3_ipd_dq_register(interface,i,dq, num_dq);
+		if(res < 0) goto _fail;
+	}
+
+	return 0;
+  _fail:
+	cvmx_dprintf("%s: ERROR:configuring queues for iface %u chan %u\n",
+		__FILE__, interface, i);
+	return -1;
+}
+
+#ifdef	__SUPPORT_PFC_ON_XAUI
+/** Initialize a single Ethernet port with PFC-style channels
+ *
+ * One interface can contain multiple ports, this function is per-port
+ * Here, a physical port is allocated 8 logical channel, one per VLAN
+ * tag priority, one DQ is assigned to each channel, and all 8 DQs
+ * are registered for that IPD port.
+ * Note that the DQs are arrange such that the Ethernet QoS/PCP field
+ * can be used as an offset to the value returned by cvmx_pko_base_queue_get().
+ *
+ * For HighGig2 mode, 16 channels may be desired, instead of 8,
+ * but this function does not support that.
+ */
+static int __cvmx_pko3_config_pfc_interface(unsigned interface, unsigned port)
+{
+	int l1_q_num;
+	int l2_q_num;
+	int res;
+	int pko_mac_num;
+	int l3_q, l4_q, l5_q, dq;
+	const unsigned num_chans = 8;
+	unsigned node = cvmx_get_node_num();
+	uint16_t ipd_port;
+	int res_owner;
+	unsigned i;
+
+	if(debug)
+		cvmx_dprintf("%s: configuring iface %u port %u with %u PFC channels\n",
+			__FUNCTION__, interface, port, num_chans);
+
+	/* Get MAC number for the iface/port */
+	pko_mac_num = __cvmx_pko_get_mac_num(interface, port);
+	if (pko_mac_num < 0) {
+		cvmx_dprintf ("%s: ERROR Invalid interface\n", __FUNCTION__);
+		return -1;
+	}
+
+	ipd_port = cvmx_helper_get_ipd_port(interface, port);
+
+	/* Build an identifiable owner identifier */
+	res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+
+	/* Allocate port queue to make sure the MAC is not already configured */
+	l1_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_PORT_QUEUES,
+				res_owner, pko_mac_num, 1);
+
+	if (l1_q_num != pko_mac_num) {
+		cvmx_dprintf ("%s: ERROR allocation L1 SQ\n", __FUNCTION__);
+		return -1;
+	}
+
+
+	/* allocate or reserve level 2 queues */
+	l2_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_L2_QUEUES, res_owner,
+					 -1, num_chans);
+	if (l2_q_num < 0) {
+		cvmx_dprintf ("%s: ERROR allocation L2 SQ\n", __FUNCTION__);
+		return -1;
+	}
+
+
+	/* Configre <num_chans> children for MAC, with static priority */
+	res = cvmx_pko3_pq_config_children(
+			pko_mac_num, l2_q_num, num_chans, num_chans);
+
+	if (res < 0) {
+		cvmx_dprintf("Error: Could not setup PFC Channel queues\n");
+		return -1;
+	}
+
+	/* Allocate all SQ levels at once to assure contigous range */
+	l3_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L3_QUEUES,
+			res_owner, -1, num_chans);
+	l4_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L4_QUEUES,
+			res_owner, -1, num_chans);
+	l5_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L5_QUEUES,
+			res_owner, -1, num_chans);
+	dq = cvmx_pko_alloc_queues(node, CVMX_PKO_DESCR_QUEUES,
+			res_owner, -1, num_chans);
+	if (l3_q < 0 || l4_q < 0 || l5_q < 0 ||dq < 0) {
+		cvmx_dprintf("%s: ERROR:could not allocate queues, "
+			"interface %u port %u\n",
+			__FUNCTION__, interface, port);
+		return -1;
+	}
+
+	/* Configure children with one DQ per channel */
+	for (i = 0; i < num_chans; i++) {
+		uint16_t chan, dq_num;
+		/* <i> moves in priority order, 0=highest, 7=lowest */
+
+		/* Get CHAN_E value for this PFC channel, PCP in low 3 bits */
+		chan = ipd_port | cvmx_helper_prio2qos(i);
+
+		/* map channels to L2 queues */
+		cvmx_pko3_map_channel(node, l1_q_num, l2_q_num+i, chan);
+
+		cvmx_pko3_sq_config_children(2, l2_q_num+i, l3_q+i, 1, 1);
+
+		cvmx_pko3_sq_config_children(3, l3_q+i, l4_q+i, 1, 1);
+
+		cvmx_pko3_sq_config_children(4, l4_q+i, l5_q+i, 1, 1);
+
+		/* Configure DQs in QoS order, so that QoS/PCP can be index */
+		dq_num = dq + cvmx_helper_prio2qos(i);
+		cvmx_pko3_sq_config_children(5, l5_q+i, dq_num, 1, 1);
+	}
+
+	/* register entire DQ range with the IPD translation table */
+	__cvmx_pko3_ipd_dq_register(interface,port, dq, num_chans);
+
+	return 0;
+}
+#endif
+
+/** Initialize a simple interface with a single descriptor queue */
+static int __cvmx_pko3_config_gen_interface(unsigned interface, unsigned port)
+{
+	int l1_q_num;
+	int l2_q_num;
+	int res, res_owner;
+	int pko_mac_num;
+	int l3_q, l4_q, l5_q, dq;
+	unsigned node = cvmx_get_node_num();
+	uint16_t ipd_port;
+
+	if(debug)
+		cvmx_dprintf("%s: configuring iface %u port %u\n",
+			__FUNCTION__, interface, port );
+
+	/* Get MAC number for the iface/port */
+	pko_mac_num = __cvmx_pko_get_mac_num(interface, port);
+	if (pko_mac_num < 0) {
+		cvmx_dprintf ("%s: ERROR Invalid interface\n", __FUNCTION__);
+		return -1;
+	}
+
+	ipd_port = cvmx_helper_get_ipd_port(interface, port);
+
+	/* Build an identifiable owner identifier */
+	res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+
+	/* Reserve port queue to make sure the MAC is not already configured */
+	l1_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_PORT_QUEUES,
+				res_owner, pko_mac_num, 1);
+
+	if (l1_q_num != pko_mac_num) {
+		cvmx_dprintf ("%s: ERROR allocation L1 SQ\n", __FUNCTION__);
+		return -1;
+	}
+
+	/* allocate or reserve level 2 queues */
+	l2_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_L2_QUEUES, res_owner,
+				-1, 1);
+	if (l2_q_num < 0) {
+		cvmx_dprintf ("%s: ERROR allocation L2 SQ\n", __FUNCTION__);
+		return -1;
+	}
+
+
+	/* Configre L2 SQ */
+	res = cvmx_pko3_pq_config_children( pko_mac_num, l2_q_num, 1, 1);
+
+	if (res < 0) {
+		cvmx_dprintf("Error: Could not setup ILK Channel queues\n");
+		return -1;
+	}
+
+	l3_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L3_QUEUES, res_owner,-1, 1);
+	l4_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L4_QUEUES, res_owner,-1, 1);
+	l5_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L5_QUEUES, res_owner,-1, 1);
+	dq = cvmx_pko_alloc_queues(node,CVMX_PKO_DESCR_QUEUES, res_owner,-1, 1);
+	if (dq < 0) {
+		cvmx_dprintf("%s: ERROR: could not allocate DQs\n",
+			__FUNCTION__);
+		return -1;
+	}
+
+	/* Configure hierarchy */
+	cvmx_pko3_sq_config_children(2, l2_q_num, l3_q, 1, 1);
+	cvmx_pko3_sq_config_children(3, l3_q, l4_q, 1, 1);
+	cvmx_pko3_sq_config_children(4, l4_q, l5_q, 1, 1);
+	cvmx_pko3_sq_config_children(5, l5_q, dq, 1, 1);
+
+	/* map IPD/channel to L2 queues */
+	cvmx_pko3_map_channel(node, l1_q_num, l2_q_num, ipd_port);
+
+	/* register DQ/IPD translation */
+	__cvmx_pko3_ipd_dq_register(interface, port, dq, 1);
+
+	return 0;
+}
+
+/** Initialize the NULL interface
+ *
+ * A NULL interface is a special case in that it is not
+ * one of the enumerated interfaces in the system, and does
+ * not apply to input either. Still, it can be very handy
+ * for dealing with packets that should be discarded in
+ * a generic, streamlined way.
+ *
+ * The Descriptor Queue 0 will be reserved for the NULL interface
+ * and the normalized (i.e. IPD) port number has the all-ones value.
+ */
+static int __cvmx_pko3_config_null_interface(void)
+{
+	int l1_q_num;
+	int l2_q_num;
+	int l3_q, l4_q, l5_q;
+	int res, res_owner;
+	unsigned node = cvmx_get_node_num();
+
+	const int dq = 0;	/* Reserve DQ#0 for NULL */
+	const int pko_mac_num = 0x1C; /* MAC# 28 virtual MAC for NULL */
+	const uint16_t ipd_port = 0xfff;
+
+	if(debug)
+		cvmx_dprintf("%s: configuring null interface\n", __FUNCTION__);
+
+	/* Build an identifiable owner identifier by MAC# for easy release */
+	res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+	if (res_owner < 0) {
+		cvmx_dprintf ("%s: ERROR Invalid interface\n", __FUNCTION__);
+		return -1;
+	}
+
+	/* Reserve port queue to make sure the MAC is not already configured */
+	l1_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_PORT_QUEUES,
+				res_owner, pko_mac_num, 1);
+
+	if (l1_q_num != pko_mac_num) {
+		cvmx_dprintf ("%s: ERROR reserving L1 SQ\n", __FUNCTION__);
+		return -1;
+	}
+
+	/* allocate or reserve level 2 queues */
+	l2_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_L2_QUEUES, res_owner,
+				-1, 1);
+	if (l2_q_num < 0) {
+		cvmx_dprintf ("%s: ERROR allocating L2 SQ\n", __FUNCTION__);
+		return -1;
+	}
+
+
+	/* Configre L2 SQ */
+	res = cvmx_pko3_pq_config_children( pko_mac_num, l2_q_num, 1, 1);
+
+	if (res < 0) {
+		cvmx_dprintf("%s: ERROR: L2 queue\n", __FUNCTION__);
+		return -1;
+	}
+
+	l3_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L3_QUEUES, res_owner,-1, 1);
+	l4_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L4_QUEUES, res_owner,-1, 1);
+	l5_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L5_QUEUES, res_owner,-1, 1);
+
+	/* Reserve DQ at 0 by convention */
+	res = cvmx_pko_alloc_queues(node,CVMX_PKO_DESCR_QUEUES, res_owner,
+		dq, 1);
+	if (dq != res) {
+		cvmx_dprintf("%s: ERROR: could not reserve DQs\n",
+			__FUNCTION__);
+		return -1;
+	}
+
+	/* Configure hierarchy */
+	cvmx_pko3_sq_config_children(2, l2_q_num, l3_q, 1, 1);
+	cvmx_pko3_sq_config_children(3, l3_q, l4_q, 1, 1);
+	cvmx_pko3_sq_config_children(4, l4_q, l5_q, 1, 1);
+	cvmx_pko3_sq_config_children(5, l5_q, dq, 1, 1);
+
+	/* NULL interface does not need to map to a CHAN_E */
+
+	/* register DQ/IPD translation */
+	__cvmx_pko3_ipd_dq_register(-1, 0, dq, 1);
+
+	/* open the null DQ here */
+	res = cvmx_pko_dq_open(node, dq);
+
+	return 0;
+}
+
+/** Open all descriptor queues belonging to an interface/port
+ * @INTERNAL
+ */
+static int __cvmx_pko3_helper_dqs_activate(int interface, int port)
+{
+	unsigned node = cvmx_get_node_num();
+	int  ipd_port,dq_base, dq_count, i;
+	bool min_pad = __cvmx_helper_get_pko_padding(interface);
+
+	/* Get local IPD port for the interface */
+	ipd_port = cvmx_helper_get_ipd_port(interface, port);
+	if(ipd_port < 0) {
+		cvmx_dprintf("%s: ERROR: No IPD port "
+			"for interface %d port %d\n",
+			__FUNCTION__, interface, port);
+		return -1;
+	}
+
+	/* Make the IPD port global */
+	ipd_port |= node << 12;
+
+	/* Get DQ# range for the IPD port */
+	dq_base = cvmx_pko3_get_queue_base(ipd_port);
+	dq_count = cvmx_pko3_get_queue_num(ipd_port);
+	if( dq_base < 0 || dq_count <= 0) {
+		cvmx_dprintf("%s: ERROR: No descriptor queues "
+				"for interface %d port %d\n",
+				__FUNCTION__, interface, port);
+		return -1;
+	}
+
+	/* Mask out node from global DQ# */
+	dq_base &= (1<<10)-1;
+
+	for(i = 0; i < dq_count; i++) {
+		cvmx_pko_dq_open(node, dq_base + i);
+		cvmx_pko3_dq_options(node, dq_base + i, min_pad);
+	}
+
+
+	return i;
+}
+
+/** Conhfigure and initialize PKO3 for an interface
+ *
+ * @param interface is the interface number to configure
+ * @return 0 on success.
+ *
+ */
+int cvmx_helper_pko3_init_interface(unsigned interface)
+{
+	unsigned node = cvmx_get_node_num();
+	cvmx_helper_interface_mode_t mode;
+	int port, num_ports;
+	int res;
+
+	mode = cvmx_helper_interface_get_mode(interface);
+	num_ports = cvmx_helper_interface_enumerate(interface);
+
+	/* Override port-count for some interface types */
+	if ((mode == CVMX_HELPER_INTERFACE_MODE_NPI) ||
+		(mode == CVMX_HELPER_INTERFACE_MODE_LOOP))
+		num_ports = 1;
+
+	/* For ILK there is one IPD port per channel */
+	if ((mode == CVMX_HELPER_INTERFACE_MODE_ILK))
+		num_ports =  __cvmx_helper_ilk_enumerate(interface);
+
+	/* Skip non-existent interfaces */
+	if(num_ports < 1) {
+		cvmx_dprintf("%s: ERROR invalid interface %u\n",
+			__FUNCTION__, interface );
+		return -1;
+	}
+
+	/* ILK-specific queue configuration */
+	if (mode == CVMX_HELPER_INTERFACE_MODE_ILK) {
+		res = __cvmx_pko3_config_ilk_interface(interface);
+#ifdef	__SUPPORT_PFC_ON_XAUI
+	/* Setup all XAUI interfaces for PFC */
+	} else if (mode == CVMX_HELPER_INTERFACE_MODE_XAUI) {
+		res = -1;
+		for (port = 0; port < num_ports; port++) {
+			res = __cvmx_pko3_config_pfc_interface(
+				interface, port);
+			if (res < 0) {
+				goto __cfg_error;
+			}
+		}
+	/* All other interfaces are configured with a single DQ/port */
+#endif
+	} else {
+		res = -1;
+		for (port = 0; port < num_ports; port++) {
+			res = __cvmx_pko3_config_gen_interface(
+				interface, port);
+			if (res < 0) {
+				goto __cfg_error;
+			}
+		}
+	}
+
+	if(debug)
+		cvmx_dprintf("%s: FCS=%d pad=%d\n",__func__,
+			__cvmx_helper_get_has_fcs(interface),
+			__cvmx_helper_get_pko_padding(interface));
+
+	/* Setup interface options */
+	for (port = 0; port < num_ports; port++) {
+		res = cvmx_pko3_interface_options(node, interface, port,
+			__cvmx_helper_get_has_fcs(interface),	/*fcs_enable*/
+			__cvmx_helper_get_pko_padding(interface),/*pad_enable*/
+			0	/*fcs_sof_offset*/
+		);
+		if(res < 0)
+			cvmx_dprintf("%s: WARNING: failed to set options for interface %d port %d\n",
+				     __func__, interface, port);
+
+		/* Open interface/port DQs to allow transmission to begin */
+		res = __cvmx_pko3_helper_dqs_activate(interface, port);
+		if (res < 0)
+			goto __cfg_error;
+	}
+	return 0;
+
+  __cfg_error:
+	cvmx_dprintf("%s: ERROR configuring interface %u port %u\n",
+		__FUNCTION__, interface, port);
+	return -1;
+}
+
+/**
+ * Global initialization for PKO3
+ *
+ * Should only be called once on each node
+ *
+ * TBD: Resolve the kernel case.
+ * When Linux eats up the entire memory, bootmem will be unable to
+ * satisfy our request, and the memory needs to come from Linux free pages.
+ */
+int cvmx_helper_pko3_init_global(void)
+{
+	uint16_t aura = -1;
+	unsigned node = cvmx_get_node_num();
+	int res;
+
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+	/* Allocate memory required by PKO3 */
+	res = __cvmx_pko3_config_memory(node);
+	if(res < 0) {
+		cvmx_dprintf("%s: ERROR: PKO3 memory allocation error\n",
+			__FUNCTION__);
+		return res;
+	}
+	aura = res;
+#else
+	//# warning Do not have the AURA for PKO3 internal use
+#endif
+
+	res = cvmx_pko3_hw_init_global(node, aura);
+	if(res < 0) {
+		cvmx_dprintf("%s: ERROR: failed block initialization\n",
+			__FUNCTION__);
+		return res;
+	}
+
+	/* configure channel level */
+	cvmx_pko_setup_channel_credit_level(node,
+		cvmx_pko_default_channel_level);
+
+	/* add NULL MAC/DQ setup */
+	res = __cvmx_pko3_config_null_interface();
+	if (res < 0)
+		cvmx_dprintf("%s: ERROR creating NULL interface\n",
+			__FUNCTION__);
+
+	return res;
+}
+
+/**
+ * Uninitialize PKO3 interface
+ *
+ * Release all resources held by PKO for an interface.
+ * The shutdown code is the same for all supported interfaces.
+ *
+ * NOTE: The NULL virtual interface is identified by interface
+ * number -1, which translates into IPD port 0xfff, MAC#28. [Kludge]
+ */
+int cvmx_helper_pko3_shut_interface(int interface)
+{
+	unsigned node = cvmx_get_node_num();
+	int port, num_ports;
+	int dq_base, dq_count;
+	uint16_t ipd_port;
+	int i, res_owner, res;
+	uint64_t cycles;
+	const unsigned timeout = 10;	/* milliseconds */
+
+	if(interface == -1) {
+		/* Special case for interface=-1 is NULL interface */
+		num_ports = 1;
+	} else {
+		cvmx_helper_interface_mode_t mode;
+		mode = cvmx_helper_interface_get_mode(interface);
+		num_ports = cvmx_helper_interface_enumerate(interface);
+
+		/* Override port-count for some interface types */
+		if ((mode == CVMX_HELPER_INTERFACE_MODE_NPI) ||
+			(mode == CVMX_HELPER_INTERFACE_MODE_LOOP))
+			num_ports = 1;
+	}
+
+	/* Skip non-existent interfaces silently */
+	if(num_ports < 1) {
+		return -1;
+	}
+
+	if (debug)
+		cvmx_dprintf("%s: interface %d ports %d\n",
+			__func__, interface, num_ports);
+
+	for (port = 0; port < num_ports; port ++) {
+
+		ipd_port = cvmx_helper_get_ipd_port(interface, port);
+		ipd_port &= (CVMX_PKO3_IPD_NUM_MAX-1);
+
+		/* Retreive DQ range for the port */
+                dq_base = cvmx_pko3_get_queue_base(ipd_port);
+                dq_count = cvmx_pko3_get_queue_num(ipd_port);
+
+                if( dq_base < 0 || dq_count < 0) {
+                        cvmx_dprintf("%s: ERROR: No descriptor queues for interface %d port %d\n",
+                                __FUNCTION__, interface, port);
+			continue;
+		}
+
+		/* Get rid of node-number in DQ# */
+		dq_base &= (1 << 10)-1;
+
+		/* Unregister the DQs for the port, should stop traffic */
+		res = __cvmx_pko3_ipd_dq_unregister(interface, port);
+		if(res < 0) {
+                        cvmx_dprintf("%s: ERROR: can not unregister queues "
+                                "for interface %d port %d\n",
+                                __FUNCTION__, interface, port);
+			continue;
+		}
+
+		/* Begin draining all queues */
+		for(i = 0; i < dq_count; i++) {
+			cvmx_pko3_dq_drain(node, dq_base + i);
+		}
+
+		/* Wait for all queues to drain, and close them */
+		for(i = 0; i < dq_count; i++) {
+			/* Prepare timeout */
+			cycles = cvmx_get_cycle();
+			cycles +=
+				cvmx_clock_get_rate(CVMX_CLOCK_CORE)/1000 *
+					timeout;
+
+			/* Wait for queue to drain */
+			do {
+				res = cvmx_pko3_dq_query(node, dq_base + i);
+				if (cycles < cvmx_get_cycle())
+					break;
+			} while(res > 0);
+
+			if (res != 0)
+				cvmx_dprintf("%s: ERROR: querying queue %u\n",
+					__FUNCTION__, dq_base + i);
+
+			/* Close the queue, free internal buffers */
+			res = cvmx_pko3_dq_close(node, dq_base + i);
+
+			if (res < 0)
+				cvmx_dprintf("%s: ERROR: closing queue %u\n",
+					__FUNCTION__, dq_base + i);
+
+		}
+
+		/* Release all global resources owned by this interface/port */
+
+		res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+		if (res_owner < 0) {
+			cvmx_dprintf ("%s: ERROR no resource owner ticket\n",
+				__FUNCTION__);
+			continue;
+		}
+
+		cvmx_pko_free_queues(node,CVMX_PKO_DESCR_QUEUES, res_owner);
+		cvmx_pko_free_queues(node,CVMX_PKO_L5_QUEUES, res_owner);
+		cvmx_pko_free_queues(node,CVMX_PKO_L4_QUEUES, res_owner);
+		cvmx_pko_free_queues(node,CVMX_PKO_L3_QUEUES, res_owner);
+		cvmx_pko_free_queues(node,CVMX_PKO_L2_QUEUES, res_owner);
+		cvmx_pko_free_queues(node,CVMX_PKO_PORT_QUEUES, res_owner);
+
+	} /* for port */
+
+	return 0;
+}
+
+/**
+ * Shutdown PKO3
+ *
+ * Should be called after all interfaces have been shut down on the PKO3.
+ *
+ * Disables the PKO, frees all its buffers.
+ */
+int cvmx_helper_pko3_shutdown(void)
+{
+	unsigned node = cvmx_get_node_num();
+	unsigned dq;
+	int res;
+
+	 /* destroy NULL interface here, only PKO knows about it */
+	 cvmx_helper_pko3_shut_interface(-1);
+
+	 /* Check that all DQs are closed */
+	for(dq =0; dq < (1<<10); dq++) {
+		res = cvmx_pko3_dq_close(node, dq);
+		if (res != 0) {
+			cvmx_dprintf("%s: ERROR: PKO3 descriptor queue %u "
+				"could not be closed\n",
+				__FUNCTION__, dq);
+			return -1;
+		}
+	}
+
+	return cvmx_pko3_hw_disable(node);
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
index dac8e71..25c5a0a 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 89030 $<hr>
+ * <hr>$Revision: 93962 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -52,14 +52,10 @@
 #include <asm/octeon/cvmx-helper.h>
 #include <asm/octeon/cvmx-helper-board.h>
 #include <asm/octeon/cvmx-helper-cfg.h>
-#include <asm/octeon/cvmx-bgxx-defs.h>
 #include <asm/octeon/cvmx-gserx-defs.h>
 #include <asm/octeon/cvmx-pcsx-defs.h>
 #include <asm/octeon/cvmx-gmxx-defs.h>
 #include <asm/octeon/cvmx-ciu-defs.h>
-#include <asm/octeon/cvmx-bgxx-defs.h>
-#include <asm/octeon/cvmx-gser.h>
-#include <asm/octeon/cvmx-bgx.h>
 #else
 
 #include "cvmx.h"
@@ -69,8 +65,6 @@
 #include "cvmx-helper-board.h"
 #include "cvmx-helper-cfg.h"
 #include "cvmx-qlm.h"
-#include "cvmx-gser.h"
-#include "cvmx-bgx.h"
 #endif
 
 
@@ -756,131 +750,3 @@ int __cvmx_helper_sgmii_configure_loopback(int ipd_port, int enable_internal,
 	return 0;
 }
 
-/**
- * @INTERNAL
- * Probe a SGMII interface and determine the number of ports
- * connected to it. The SGMII interface should still be down after
- * this call. This is used by interfaces using the bgx mac.
- *
- * @param interface Interface to probe
- *
- * @return Number of ports on the interface. Zero to disable.
- */
-int __cvmx_helper_bgx_sgmii_probe(int interface)
-{
-	int	qlm;
-
-	/*
-	 * Check the QLM is configured correctly for SGMII, verify the
-	 * speed as well as the mode.
-	 */
-	qlm = cvmx_qlm_interface(interface);
-	if (cvmx_qlm_get_mode(qlm) != CVMX_QLM_MODE_SGMII)
-		return 0;
-
-	return __cvmx_helper_sgmii_enumerate(interface);
-}
-
-/**
- * @INTERNAL
- * Bringup and enable a SGMII interface. After this call packet
- * I/O should be fully functional. This is called with IPD
- * enabled but PKO disabled. This is used by interfaces using
- * the bgx mac.
- *
- * @param interface Interface to bring up
- *
- * @return Zero on success, negative on failure
- */
-int __cvmx_helper_bgx_sgmii_enable(int interface)
-{
-	cvmx_bgxx_cmrx_rx_id_map_t	bgx_cmr_rx_id_map;
-	int				num_ports;
-	int				pknd;
-	int				i;
-
-	num_ports = cvmx_helper_ports_on_interface(interface);
-
-	/* Configure the gser */
-	gser_init(interface, CVMX_HELPER_INTERFACE_MODE_SGMII);
-
-	/* Configure the bgx mac */
-	bgx_init(interface, CVMX_HELPER_INTERFACE_MODE_SGMII);
-
-	/* Setup pkind */
-	for (i = 0; i < num_ports; i++) {
-		pknd = cvmx_helper_get_pknd(interface, i);
-		bgx_cmr_rx_id_map.u64 = 0;
-		bgx_cmr_rx_id_map.s.rid = 2 + i;
-		bgx_cmr_rx_id_map.s.pknd = pknd;
-		cvmx_write_csr(CVMX_BGXX_CMRX_RX_ID_MAP(i, interface),
-			       bgx_cmr_rx_id_map.u64);
-	}
-
-	return 0;
-}
-
-/**
- * @INTERNAL
- * Return the link state of an IPD/PKO port as returned by
- * auto negotiation. The result of this function may not match
- * Octeon's link config if auto negotiation has changed since
- * the last call to cvmx_helper_link_set(). This is used by
- * interfaces using the bgx mac.
- *
- * @param ipd_port IPD/PKO port to query
- *
- * @return Link state
- */
-cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port)
-{
-	cvmx_helper_link_info_t result;
-
-	/* Hardcoded for now. TODO */
-	result.s.link_up = 1;
-	result.s.full_duplex = 1;
-	result.s.speed = 1000;
-
-	return result;
-}
-
-/**
- * @INTERNAL
- * Configure an IPD/PKO port for the specified link state. This
- * function does not influence auto negotiation at the PHY level.
- * The passed link state must always match the link state returned
- * by cvmx_helper_link_get(). It is normally best to use
- * cvmx_helper_link_autoconf() instead. This is used by interfaces
- * using the bgx mac.
- *
- * @param ipd_port  IPD/PKO port to configure
- * @param link_info The new link state
- *
- * @return Zero on success, negative on failure
- */
-int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
-				 cvmx_helper_link_info_t link_info)
-{
-	return 0;
-}
-
-/**
- * @INTERNAL
- * Configure a port for internal and/or external loopback. Internal loopback
- * causes packets sent by the port to be received by Octeon. External loopback
- * causes packets received from the wire to sent out again. This is used by
- * interfaces using the bgx mac.
- *
- * @param ipd_port IPD/PKO port to loopback.
- * @param enable_internal
- *                 Non zero if you want internal loopback
- * @param enable_external
- *                 Non zero if you want external loopback
- *
- * @return Zero on success, negative on failure.
- */
-int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port, int enable_internal,
-					   int enable_external)
-{
-	return 0;
-}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
index 911fe20..a255ffe 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
@@ -91,13 +91,16 @@
  *	This type is used for npi interfaces.
  * @param LB
  *	This type is used for loopback interfaces.
+ * @param INVALID_IF_TYPE
+ *	This type indicates the interface hasn't been configured.
  */
-typedef enum {
+enum port_map_if_type {
+	INVALID_IF_TYPE = 0,
 	GMII,
 	ILK,
 	NPI,
 	LB
-} port_map_if_type_t;
+};
 
 /**
  * @INTERNAL
@@ -110,12 +113,12 @@ typedef enum {
  * @param last_ipd_port
  *	Last IPD port number assigned to this interface.
  * @param ipd_port_adj
- *	Different octeon chips require different ipd ports for the 
+ *	Different octeon chips require different ipd ports for the
  *	same interface port/mode configuration. This value is used
  *	to account for that difference.
  */
 struct ipd_port_map {
-	port_map_if_type_t	type;
+	enum port_map_if_type	type;
 	int			first_ipd_port;
 	int			last_ipd_port;
 	int			ipd_port_adj;
@@ -140,18 +143,22 @@ static const struct ipd_port_map ipd_port_map_68xx[CVMX_HELPER_MAX_IFACE] = {
 /**
  * @INTERNAL
  * Interface number to ipd port map for the octeon 78xx.
+ *
+ * This mapping corresponds to WQE(CHAN) enumeration in
+ * HRM Sections 11.15, MKI_CHAN_E, Section 11.6
+ *
  */
 static const struct ipd_port_map ipd_port_map_78xx[CVMX_HELPER_MAX_IFACE] = {
-	{GMII,	0x800,	0x8ff,	0x00},		/* Interface 0 */
-	{GMII,	0x900,	0x9ff,	0x00},		/* Interface 1 */
-	{GMII,	0xa00,	0xaff,	0x00},		/* Interface 2 */
-	{GMII,	0xb00,	0xbff,	0x00},		/* Interface 3 */
-	{GMII,	0xc00,	0xcff,	0x00},		/* Interface 4 */
-	{GMII,	0xd00,	0xdff,	0x00},		/* Interface 5 */
-	{ILK,	0x400,	0x4ff,	0x00},		/* Interface 6 */
-	{ILK,	0x500,	0x5ff,	0x00},		/* Interface 7 */
-	{NPI,	0x100,	0x120,	0x00},		/* Interface 8 */
-	{LB,	0x000,	0x008,	0x00},		/* Interface 9 */
+	{GMII,	0x800,	0x83f,	0x00},		/* Interface 0 - BGX0 */
+	{GMII,	0x900,	0x93f,	0x00},		/* Interface 1  -BGX1 */
+	{GMII,	0xa00,	0xa3f,	0x00},		/* Interface 2  -BGX2 */
+	{GMII,	0xb00,	0xb3f,	0x00},		/* Interface 3 - BGX3 */
+	{GMII,	0xc00,	0xc3f,	0x00},		/* Interface 4 - BGX4 */
+	{GMII,	0xd00,	0xd3f,	0x00},		/* Interface 5 - BGX5 */
+	{ILK,	0x400,	0x4ff,	0x00},		/* Interface 6 - ILK0 */
+	{ILK,	0x500,	0x5ff,	0x00},		/* Interface 7 - ILK1 */
+	{NPI,	0x100,	0x13f,	0x00},		/* Interface 8 - DPI */
+	{LB,	0x000,	0x03f,	0x00},		/* Interface 9 - LOOPBACK */
 };
 
 struct cvmx_iface {
@@ -220,6 +227,10 @@ const char *cvmx_helper_interface_mode_to_string(cvmx_helper_interface_mode_t mo
 		return "ILK";
 	case CVMX_HELPER_INTERFACE_MODE_AGL:
 		return "AGL";
+	case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+		return "XLAUI";
+	case CVMX_HELPER_INTERFACE_MODE_XFI:
+		return "XFI";
 	}
 	return "UNKNOWN";
 }
@@ -235,6 +246,8 @@ int cvmx_helper_dump_packet(cvmx_wqe_t *work)
 	uint64_t count;
 	uint64_t remaining_bytes;
 	union cvmx_buf_ptr buffer_ptr;
+	cvmx_buf_ptr_pki_t bptr;
+	cvmx_wqe_78xx_t *wqe = (void *) work;
 	uint64_t start_of_buffer;
 	uint8_t *data_address;
 	uint8_t *end_of_data;
@@ -249,16 +262,18 @@ int cvmx_helper_dump_packet(cvmx_wqe_t *work)
 		cvmx_dprintf("    Style:       %u\n", cvmx_wqe_get_style(work));
 		cvmx_dprintf("    Aura:        %u\n", cvmx_wqe_get_aura(work));
 		cvmx_dprintf("    Group:       %u\n", cvmx_wqe_get_grp(work));
-	}
-	else
+	} else
 		cvmx_dprintf("    QoS:         %u\n", cvmx_wqe_get_qos(work));
 	cvmx_dprintf("    Buffers:     %u\n", cvmx_wqe_get_bufs(work));
-
 	if (cvmx_wqe_get_bufs(work) == 0) {
-		cvmx_ipd_wqe_fpa_queue_t wqe_pool;
-		wqe_pool.u64 = cvmx_read_csr(CVMX_IPD_WQE_FPA_QUEUE);
+		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+			cvmx_dprintf("%s: ERROR: Unexpected bufs==0 in WQE\n",
+				__func__);
+		} else {
+		int wqe_pool = (int)cvmx_fpa_get_wqe_pool();
 		buffer_ptr.u64 = 0;
-		buffer_ptr.s.pool = wqe_pool.s.wqe_pool;
+		buffer_ptr.s.pool = wqe_pool;
+
 		buffer_ptr.s.size = 128;
 		buffer_ptr.s.addr = cvmx_ptr_to_phys(work->packet_data);
 		if (cvmx_likely(!work->word2.s.not_IP)) {
@@ -277,21 +292,27 @@ int cvmx_helper_dump_packet(cvmx_wqe_t *work)
 			pip_gbl_cfg.u64 = cvmx_read_csr(CVMX_PIP_GBL_CFG);
 			buffer_ptr.s.addr += pip_gbl_cfg.s.nip_shf;
 		}
+		}
 	} else {
 		buffer_ptr = work->packet_ptr;
 	}
 	remaining_bytes = cvmx_wqe_get_len(work);
 
 	while (remaining_bytes) {
-		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)){
-			start_of_buffer = (buffer_ptr.s_cn78xx.addr >> 7) << 7;
-			cvmx_dprintf("    Buffer Start:%llx\n", (unsigned long long)start_of_buffer);
-			cvmx_dprintf("    Buffer Data: %llx\n", (unsigned long long)buffer_ptr.s_cn78xx.addr);
-			cvmx_dprintf("    Buffer Size: %u\n", buffer_ptr.s_cn78xx.size);
-			data_address = (uint8_t *) cvmx_phys_to_ptr(buffer_ptr.s_cn78xx.addr);
-			end_of_data = data_address + buffer_ptr.s_cn78xx.size;
-		}
-		else {
+		/* native cn78xx buffer format, unless legacy-translated */
+		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
+		    !wqe->pki_wqe_translated) {
+			bptr.u64 = buffer_ptr.u64;
+			/* XXX- assumes cache-line aligned buffer */
+			start_of_buffer = (bptr.s_cn78xx.addr >> 7) << 7;
+			cvmx_dprintf("    Buffer Start:%llx\n",
+				(unsigned long long)start_of_buffer);
+			cvmx_dprintf("    Buffer Data: %llx\n",
+				(unsigned long long)bptr.s_cn78xx.addr);
+			cvmx_dprintf("    Buffer Size: %u\n", bptr.s_cn78xx.size);
+			data_address = (uint8_t *) cvmx_phys_to_ptr(bptr.s_cn78xx.addr);
+			end_of_data = data_address + bptr.s_cn78xx.size;
+		} else {
 			start_of_buffer = ((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back) << 7;
 			cvmx_dprintf("    Buffer Start:%llx\n", (unsigned long long)start_of_buffer);
 			cvmx_dprintf("    Buffer I   : %u\n", buffer_ptr.s.i);
@@ -322,224 +343,19 @@ int cvmx_helper_dump_packet(cvmx_wqe_t *work)
 		cvmx_dprintf("\n");
 
 		if (remaining_bytes) {
-			if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
-				buffer_ptr = *(cvmx_buf_ptr_t *) cvmx_phys_to_ptr(buffer_ptr.s_cn78xx.addr - 8);
+			if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
+			    !wqe->word2.pki.software)
+				buffer_ptr.u64 = *(uint64_t *)
+					cvmx_phys_to_ptr(bptr.s_cn78xx.addr-8);
 			else
-				buffer_ptr = *(cvmx_buf_ptr_t *) cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
-		}
-	}
-	return 0;
-}
-
-/**
- * Setup Random Early Drop on a specific input queue
- *
- * @param queue  Input queue to setup RED on (0-7)
- * @param pass_thresh
- *               Packets will begin slowly dropping when there are less than
- *               this many packet buffers free in FPA 0.
- * @param drop_thresh
- *               All incomming packets will be dropped when there are less
- *               than this many free packet buffers in FPA 0.
- * @return Zero on success. Negative on failure
- */
-int cvmx_helper_setup_red_queue(int queue, int pass_thresh, int drop_thresh)
-{
-	union cvmx_ipd_qosx_red_marks red_marks;
-	union cvmx_ipd_red_quex_param red_param;
-
-	/*
-	 * Set RED to begin dropping packets when there are
-	 * pass_thresh buffers left. It will linearly drop more
-	 * packets until reaching drop_thresh buffers.
-	 */
-	red_marks.u64 = 0;
-	red_marks.s.drop = drop_thresh;
-	red_marks.s.pass = pass_thresh;
-	cvmx_write_csr(CVMX_IPD_QOSX_RED_MARKS(queue), red_marks.u64);
-
-	/* Use the actual queue 0 counter, not the average */
-	red_param.u64 = 0;
-	red_param.s.prb_con = (255ul << 24) / (red_marks.s.pass - red_marks.s.drop);
-	red_param.s.avg_con = 1;
-	red_param.s.new_con = 255;
-	red_param.s.use_pcnt = 1;
-	cvmx_write_csr(CVMX_IPD_RED_QUEX_PARAM(queue), red_param.u64);
-	return 0;
-}
-
-/**
- * Setup Random Early Drop to automatically begin dropping packets.
- *
- * @param pass_thresh
- *               Packets will begin slowly dropping when there are less than
- *               this many packet buffers free in FPA 0.
- * @param drop_thresh
- *               All incomming packets will be dropped when there are less
- *               than this many free packet buffers in FPA 0.
- * @return Zero on success. Negative on failure
- */
-int cvmx_helper_setup_red(int pass_thresh, int drop_thresh)
-{
-	int queue;
-	int interface;
-	int port;
-
-	/*
-	 * Disable backpressure based on queued buffers. It needs SW support
-	 */
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		int bpid;
-		for (interface = 0; interface < CVMX_HELPER_MAX_GMX; interface++) {
-			int num_ports;
-
-			num_ports = cvmx_helper_ports_on_interface(interface);
-			for (port = 0; port < num_ports; port++) {
-				bpid = cvmx_helper_get_bpid(interface, port);
-				if (bpid == CVMX_INVALID_BPID)
-					cvmx_dprintf("setup_red: cvmx_helper_get_bpid(%d, %d) = %d\n",
-						     interface, port,
-						     cvmx_helper_get_bpid(interface, port));
-				else
-					cvmx_write_csr(CVMX_IPD_BPIDX_MBUF_TH(bpid), 0);
-			}
-		}
-	} else {
-		union cvmx_ipd_portx_bp_page_cnt page_cnt;
-
-		page_cnt.u64 = 0;
-		page_cnt.s.bp_enb = 0;
-		page_cnt.s.page_cnt = 100;
-		for (interface = 0; interface < CVMX_HELPER_MAX_GMX; interface++) {
-			for (port = cvmx_helper_get_first_ipd_port(interface); port < cvmx_helper_get_last_ipd_port(interface); port++)
-				cvmx_write_csr(CVMX_IPD_PORTX_BP_PAGE_CNT(port), page_cnt.u64);
-		}
-	}
-
-	for (queue = 0; queue < 8; queue++)
-		cvmx_helper_setup_red_queue(queue, pass_thresh, drop_thresh);
-
-	/*
-	 * Shutoff the dropping based on the per port page count. SW isn't
-	 * decrementing it right now
-	 */
-	if (octeon_has_feature(OCTEON_FEATURE_PKND))
-		cvmx_write_csr(CVMX_IPD_ON_BP_DROP_PKTX(0), 0);
-	else
-		cvmx_write_csr(CVMX_IPD_BP_PRT_RED_END, 0);
-
-#define IPD_RED_AVG_DLY	1000
-#define IPD_RED_PRB_DLY	1000
-	/*
-	 * Setting up avg_dly and prb_dly, enable bits
-	 */
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		union cvmx_ipd_red_delay red_delay;
-		union cvmx_ipd_red_bpid_enablex red_bpid_enable;
-
-		red_delay.u64 = 0;
-		red_delay.s.avg_dly = IPD_RED_AVG_DLY;
-		red_delay.s.prb_dly = IPD_RED_PRB_DLY;
-		cvmx_write_csr(CVMX_IPD_RED_DELAY, red_delay.u64);
-
-		/*
-		 * Only enable the gmx ports
-		 */
-		red_bpid_enable.u64 = 0;
-		for (interface = 0; interface < CVMX_HELPER_MAX_GMX; interface++) {
-			int num_ports = cvmx_helper_ports_on_interface(interface);
-			for (port = 0; port < num_ports; port++)
-				red_bpid_enable.u64 |= (((uint64_t) 1) << cvmx_helper_get_bpid(interface, port));
-		}
-		cvmx_write_csr(CVMX_IPD_RED_BPID_ENABLEX(0), red_bpid_enable.u64);
-	} else {
-		union cvmx_ipd_red_port_enable red_port_enable;
-
-		red_port_enable.u64 = 0;
-		red_port_enable.s.prt_enb = 0xfffffffffull;
-		red_port_enable.s.avg_dly = IPD_RED_AVG_DLY;
-		red_port_enable.s.prb_dly = IPD_RED_PRB_DLY;
-		cvmx_write_csr(CVMX_IPD_RED_PORT_ENABLE, red_port_enable.u64);
-
-		/*
-		 * Shutoff the dropping of packets based on RED for SRIO ports
-		 */
-		if (octeon_has_feature(OCTEON_FEATURE_SRIO)) {
-			union cvmx_ipd_red_port_enable2 red_port_enable2;
-			red_port_enable2.u64 = 0;
-			red_port_enable2.s.prt_enb = 0xf0;
-			cvmx_write_csr(CVMX_IPD_RED_PORT_ENABLE2, red_port_enable2.u64);
+				buffer_ptr.u64 = *(uint64_t *)
+					cvmx_phys_to_ptr(buffer_ptr.s.addr-8);
 		}
 	}
-
-	return 0;
-}
-EXPORT_SYMBOL(cvmx_helper_setup_red);
-
-/**
- * This function sets up aura QOS for RED, backpressure and tail-drop.
- *
- * @param node       node number.
- * @param aura       aura to configure.
- * @param ena_red       enable RED based on [DROP] and [PASS] levels
-                        1: enable 0:disable
- * @param pass_thresh   pass threshold for RED.
- * @param drop_thresh   drop threshold for RED
- * @param ena_bp        enable backpressure based on [BP] level.
-                        1:enable 0:disable
- * @param bp_thresh     backpressure threshold.
- * @param ena_drop      enable tail drop.
- *                      1:enable 0:disable
- * @return Zero on success. Negative on failure
- */
-int cvmx_helper_setup_aura_qos(int node, int aura, bool ena_red,bool ena_drop,
-			       uint64_t pass_thresh, uint64_t drop_thresh,
-			       bool ena_bp,uint64_t bp_thresh)
-{
-	ena_red = ena_red | ena_drop;
-	cvmx_fpa_setup_aura_qos(node,aura,ena_red,pass_thresh,drop_thresh,
-				ena_bp,bp_thresh);
-	cvmx_pki_enable_aura_qos(node,aura,ena_red,ena_drop,ena_bp);
 	return 0;
 }
 
 /**
- * This function maps specified bpid to all the auras from which it can receive bp and
- * then maps that bpid to all the channels, that bpid can asserrt bp on.
- *
- * @param node          node number.
- * @param aura_map      array of auras to map to that bpid.
- * @param aura_cnt      number of auras to map to the bpid
- * @param chl_map       array of channels to map to that bpid.
- * @param chl_cnt       number of channels to map to the bpid
- * @param bpid          bpid to map
- * @return Zero on success. Negative on failure
- */
-int cvmx_helper_map_aura_channel_bpid(int node, int aura_map[], int aura_cnt,
-				      int chl_map[],int chl_cnt, int bpid)
-{
-	while(aura_cnt--) {
-		cvmx_pki_write_aura_bpid(node,aura_map[aura_cnt],bpid);
-	}
-	while(chl_cnt--) {
-		cvmx_pki_write_channel_bpid(node,chl_map[chl_cnt],bpid);
-	}
-	return 0;
-}
-
-void cvmx_helper_read_bp_config(int node, int aura)
-{
-	cvmx_dprintf("\nnode %d QoS Config\n",node);
-	cvmx_dprintf("PKI_BUF_CTL=0x%lx\n", (unsigned long)cvmx_read_csr_node(node,CVMX_PKI_BUF_CTL));
-	cvmx_dprintf("PKI_CHAN1024_CONFIG=0x%lx\n", (unsigned long)cvmx_read_csr_node(node,CVMX_PKI_CHANX_CFG(1024)));
-	cvmx_dprintf("PKI_AURA0_CONFIG=0x%lx\n", (unsigned long)cvmx_read_csr_node(node,CVMX_PKI_AURAX_CFG(aura)));
-	cvmx_dprintf("FPA_GEN_CFG=0x%lx\n", (unsigned long)cvmx_read_csr_node(node,CVMX_FPA_GEN_CFG));
-	cvmx_dprintf("FPA_RED_DELAY=0x%lx\n", (unsigned long)cvmx_read_csr_node(node,CVMX_FPA_RED_DELAY));
-	cvmx_dprintf("FPA_AURA0_CFG=0x%lx\n", (unsigned long)cvmx_read_csr_node(node,CVMX_FPA_AURAX_CFG(aura)));
-	cvmx_dprintf("FPA_AURA0_CNT_LVL=0x%lx\n", (unsigned long)cvmx_read_csr_node(node,CVMX_FPA_AURAX_CNT_LEVELS(aura)));
-}
-
-/**
  * @INTERNAL
  * Setup the common GMX settings that determine the number of
  * ports. These setting apply to almost all configurations of all
@@ -558,6 +374,11 @@ int __cvmx_helper_setup_gmx(int interface, int num_ports)
 	union cvmx_gmxx_txx_thresh gmx_tx_thresh;
 	int index;
 
+	/* The common BGX settings are already done in the appropriate
+	   enable functions, nothing to do here. */
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		return 0;
+
 	/* Tell GMX the number of TX ports on this interface */
 	gmx_tx_prts.u64 = cvmx_read_csr(CVMX_GMXX_TX_PRTS(interface));
 	gmx_tx_prts.s.prts = num_ports;
@@ -706,8 +527,7 @@ int cvmx_helper_get_ipd_port(int interface, int port)
 			    mode == CVMX_HELPER_INTERFACE_MODE_RXAUI) {
 				ipd_port += port_map[interface].ipd_port_adj;
 				return ipd_port;
-			}
-			else
+			} else
 				return ipd_port + (port * 16);
 		} else if (port_map[interface].type == ILK)
 			return ipd_port + port;
@@ -803,8 +623,7 @@ int __cvmx_helper_init_interface(int interface, int num_ipd_ports,
 	addr = CAST64(cvmx_bootmem_alloc_named_range_once(sz, 0, 0, 128, name, NULL));
 	piface->cvif_ipd_port_link_info = (cvmx_helper_link_info_t *) __cvmx_phys_addr_to_ptr(addr, sz);
 #endif
-	if (!piface->cvif_ipd_port_link_info)
-	{
+	if (!piface->cvif_ipd_port_link_info) {
 		if (sz != 0)
 			cvmx_dprintf("iface %d failed to alloc link info\n",
 			    interface);
@@ -934,10 +753,16 @@ void cvmx_helper_show_stats(int port)
 	if (octeon_has_feature(OCTEON_FEATURE_ILK))
 		__cvmx_helper_ilk_show_stats();
 
-	/* PIP stats */
-	cvmx_pip_get_port_status(port, 0, &status);
-	cvmx_dprintf("port %d: the number of packets - ipd: %d\n",
-		     port, (int)status.packets);
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		unsigned int node = cvmx_get_node_num();
+		cvmx_pki_get_port_stats(node, port, (struct cvmx_pki_port_stats *)&status);
+		cvmx_dprintf("port %d: the number of packets - pki: %d\n",
+			     port, (int)status.packets);
+	} else { /* PIP stats */
+		cvmx_pip_get_port_stats(port, 0, &status);
+		cvmx_dprintf("port %d: the number of packets - ipd: %d\n",
+			     port, (int)status.packets);
+	}
 
 	/* PKO stats */
 	cvmx_pko_get_port_status(port, 0, &pko_status);
@@ -1012,19 +837,48 @@ EXPORT_SYMBOL(cvmx_helper_get_interface_num);
 int cvmx_helper_get_interface_index_num(int ipd_port)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		if (ipd_port >= 0x800 && ipd_port < 0xd00) {
-			int port = ((ipd_port & 0xff) >> 6);
+		const struct ipd_port_map	*port_map;
+		int				port;
+		enum port_map_if_type		type = INVALID_IF_TYPE;
+		int				i;
+		int				num_interfaces;
+
+		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+			port_map = ipd_port_map_68xx;
+		else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+			port_map = ipd_port_map_78xx;
+		else
+			return -1;
+
+		num_interfaces = cvmx_helper_get_number_of_interfaces();
+
+		/* Get the interface type of the ipd port */
+		for (i = 0; i < num_interfaces; i++) {
+			if (ipd_port >= port_map[i].first_ipd_port &&
+			    ipd_port <= port_map[i].last_ipd_port) {
+				type = port_map[i].type;
+				break;
+			}
+		}
+
+		/* Convert the ipd port to the interface port */
+		switch (type) {
+		case GMII:
+			port = ((ipd_port & 0xff) >> 6);
 			return port ? (port - 1) : ((ipd_port & 0xff) >> 4);
-		} else if (ipd_port >= 0x400 && ipd_port < 0x600)
-			return ipd_port & 0xff;
-		else if (ipd_port >= 0x100 && ipd_port < 0x120)
+			break;
+
+		case ILK:
+		case NPI:
+		case LB:
 			return ipd_port & 0xff;
-		else if (ipd_port < 8)
-			return ipd_port;
-		else
-			cvmx_dprintf("cvmx_helper_get_interface_index_num: Illegal IPD port number %d\n",
-				     ipd_port);
-		return -1;
+			break;
+
+		default:
+			cvmx_dprintf("cvmx_helper_get_interface_index_num: "
+				     "Illegal IPD port number %d\n", ipd_port);
+			return -1;
+		}
 	}
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX))
 		return ipd_port & 3;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
index a355e03..0dafaff 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 88172 $<hr>
+ * <hr>$Revision: 94326 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -56,16 +56,12 @@
 #include <asm/octeon/cvmx-pcsxx-defs.h>
 #include <asm/octeon/cvmx-ciu-defs.h>
 #include <asm/octeon/cvmx-bgxx-defs.h>
-#include <asm/octeon/cvmx-gser.h>
-#include <asm/octeon/cvmx-bgx.h>
 #else
 
 #include "cvmx.h"
 #include "cvmx-helper.h"
 #include "cvmx-helper-cfg.h"
 #include "cvmx-qlm.h"
-#include "cvmx-gser.h"
-#include "cvmx-bgx.h"
 #endif
 
 
@@ -80,8 +76,6 @@ int __cvmx_helper_xaui_enumerate(int interface)
 			return 1;
 		return 0;
 		/* FIXME for higig2 */
-	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		return 1;
 	}
 	/* If HiGig2 is enabled return 16 ports, otherwise return 1 port */
 	gmx_hg2_control.u64 = cvmx_read_csr(CVMX_GMXX_HG2_CONTROL(interface));
@@ -389,6 +383,14 @@ int __cvmx_helper_xaui_enable(int interface)
 			       gmxx_txx_append_cfg.u64);
 	}
 
+	/* 70XX eval boards use Marvel phy, set disparity accordingly. */
+	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_EVB7000) {
+		union cvmx_gmxx_rxaui_ctl rxaui_ctl;
+		rxaui_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXAUI_CTL(interface));
+		rxaui_ctl.s.disparity = 1;
+		cvmx_write_csr(CVMX_GMXX_RXAUI_CTL(interface), rxaui_ctl.u64);
+	}
+
 	__cvmx_helper_xaui_link_init(interface);
 
 	return 0;
@@ -524,133 +526,3 @@ extern int __cvmx_helper_xaui_configure_loopback(int ipd_port,
 	/* Take the link through a reset */
 	return __cvmx_helper_xaui_link_init(interface);
 }
-
-/**
- * @INTERNAL
- * Probe a XAUI interface and determine the number of ports
- * connected to it. The XAUI interface should still be down
- * after this call.
- *
- * @param interface Interface to probe
- *
- * @return Number of ports on the interface. Zero to disable.
- */
-int __cvmx_helper_bgx_xaui_probe(int interface)
-{
-	int	qlm;
-
-	/*
-	 * Check the QLM is configured correctly for XAUI, verify the
-	 * speed as well as the mode.
-	 */
-	qlm = cvmx_qlm_interface(interface);
-	if (cvmx_qlm_get_mode(qlm) != CVMX_QLM_MODE_XAUI)
-		return 0;
-
-	return __cvmx_helper_xaui_enumerate(interface);
-}
-
-/**
- * @INTERNAL
- * Bringup and enable a XAUI interface. After this call packet
- * I/O should be fully functional. This is called with IPD
- * enabled but PKO disabled.
- *
- * @param interface Interface to bring up
- *
- * @return Zero on success, negative on failure
- */
-int __cvmx_helper_bgx_xaui_enable(int interface)
-{
-	cvmx_bgxx_cmrx_rx_id_map_t	bgx_cmr_rx_id_map;
-	int				num_ports;
-	int				pknd;
-	int				i;
-
-	num_ports = cvmx_helper_ports_on_interface(interface);
-
-	/* Configure the gser */
-	gser_init(interface, CVMX_HELPER_INTERFACE_MODE_XAUI);
-
-	/* Configure the bgx mac */
-	bgx_init(interface, CVMX_HELPER_INTERFACE_MODE_XAUI);
-
-	/*
-	 * Must hardcode the port kind here until the pko initializion is
-	 * complete. This must be removed once the pko initialization is
-	 * working. TODO
-	 */
-	pknd = 50 + (num_ports * interface);
-	for (i = 0; i < num_ports; i++) {
-		bgx_cmr_rx_id_map.u64 = 0;
-		bgx_cmr_rx_id_map.s.rid = 2 + i;
-		bgx_cmr_rx_id_map.s.pknd = pknd + i;
-		cvmx_write_csr(CVMX_BGXX_CMRX_RX_ID_MAP(i, interface),
-			       bgx_cmr_rx_id_map.u64);
-	}
-
-	return 0;
-}
-
-/**
- * @INTERNAL
- * Return the link state of an IPD/PKO port as returned by
- * auto negotiation. The result of this function may not match
- * Octeon's link config if auto negotiation has changed since
- * the last call to cvmx_helper_link_set().
- *
- * @param ipd_port IPD/PKO port to query
- *
- * @return Link state
- */
-cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port)
-{
-	cvmx_helper_link_info_t result;
-
-	/* Hardcoded for now. TODO */
-	result.s.link_up = 1;
-	result.s.full_duplex = 1;
-	result.s.speed = 10000;
-
-	return result;
-}
-
-/**
- * @INTERNAL
- * Configure an IPD/PKO port for the specified link state. This
- * function does not influence auto negotiation at the PHY level.
- * The passed link state must always match the link state returned
- * by cvmx_helper_link_get(). It is normally best to use
- * cvmx_helper_link_autoconf() instead.
- *
- * @param ipd_port  IPD/PKO port to configure
- * @param link_info The new link state
- *
- * @return Zero on success, negative on failure
- */
-int __cvmx_helper_bgx_xaui_link_set(int				ipd_port,
-				    cvmx_helper_link_info_t	link_info)
-{
-	return 0;
-}
-
-/**
- * @INTERNAL
- * Configure a port for internal and/or external loopback. Internal loopback
- * causes packets sent by the port to be received by Octeon. External loopback
- * causes packets received from the wire to sent out again.
- *
- * @param ipd_port IPD/PKO port to loopback.
- * @param enable_internal
- *                 Non zero if you want internal loopback
- * @param enable_external
- *                 Non zero if you want external loopback
- *
- * @return Zero on success, negative on failure.
- */
-extern int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port,
-						     int enable_internal,
-						     int enable_external)
-{
-	return 0;
-}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper.c b/arch/mips/cavium-octeon/executive/cvmx-helper.c
index 6afe4ef..6e8db91 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -47,6 +47,7 @@
 #include <linux/export.h>
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-bootmem.h>
+#include <asm/octeon/cvmx-bgxx-defs.h>
 #include <asm/octeon/cvmx-sriox-defs.h>
 #include <asm/octeon/cvmx-npi-defs.h>
 #include <asm/octeon/cvmx-mio-defs.h>
@@ -63,14 +64,20 @@
 #include <asm/octeon/cvmx-fpa.h>
 #include <asm/octeon/cvmx-pip.h>
 #include <asm/octeon/cvmx-pko.h>
+#include <asm/octeon/cvmx-pko3.h>
 #include <asm/octeon/cvmx-ipd.h>
 #include <asm/octeon/cvmx-qlm.h>
 #include <asm/octeon/cvmx-spi.h>
 #include <asm/octeon/cvmx-clock.h>
 #include <asm/octeon/cvmx-helper.h>
+#include <asm/octeon/cvmx-helper-bgx.h>
 #include <asm/octeon/cvmx-helper-board.h>
 #include <asm/octeon/cvmx-helper-errata.h>
 #include <asm/octeon/cvmx-helper-cfg.h>
+#include <asm/octeon/cvmx-helper-pki.h>
+#include <asm/octeon/cvmx-pki.h>
+#include <asm/octeon/cvmx-helper-pko.h>
+#include <asm/octeon/cvmx-helper-pko3.h>
 #else
 #include "cvmx.h"
 #include "cvmx-sysinfo.h"
@@ -82,13 +89,19 @@
 #include "cvmx-fpa.h"
 #include "cvmx-pip.h"
 #include "cvmx-pko.h"
+#include "cvmx-pko3.h"
 #include "cvmx-ipd.h"
 #include "cvmx-qlm.h"
 #include "cvmx-spi.h"
 #include "cvmx-helper.h"
+#include "cvmx-helper-bgx.h"
 #include "cvmx-helper-board.h"
 #include "cvmx-helper-errata.h"
 #include "cvmx-helper-cfg.h"
+#include "cvmx-helper-pki.h"
+#include "cvmx-pki.h"
+#include "cvmx-helper-pko.h"
+#include "cvmx-helper-pko3.h"
 #endif
 
 
@@ -184,8 +197,8 @@ static const struct iface_ops_s iface_ops_sgmii = {
  */
 static const struct iface_ops_s iface_ops_bgx_sgmii = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_SGMII,
-	.enumerate	= __cvmx_helper_sgmii_enumerate,
-	.probe		= __cvmx_helper_bgx_sgmii_probe,
+	.enumerate	= __cvmx_helper_bgx_enumerate,
+	.probe		= __cvmx_helper_bgx_probe,
 	.enable		= __cvmx_helper_bgx_sgmii_enable,
 	.link_get	= __cvmx_helper_bgx_sgmii_link_get,
 	.link_set	= __cvmx_helper_bgx_sgmii_link_set,
@@ -225,12 +238,12 @@ static const struct iface_ops_s iface_ops_xaui = {
 /**
  * @INTERNAL
  * This structure specifies the interface methods used by interfaces
- * configured as xaui using the bgx mac.
+ * configured as xaui using the gmx mac.
  */
 static const struct iface_ops_s iface_ops_bgx_xaui = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_XAUI,
-	.enumerate	= __cvmx_helper_xaui_enumerate,
-	.probe		= __cvmx_helper_bgx_xaui_probe,
+	.enumerate	= __cvmx_helper_bgx_enumerate,
+	.probe		= __cvmx_helper_bgx_probe,
 	.enable		= __cvmx_helper_bgx_xaui_enable,
 	.link_get	= __cvmx_helper_bgx_xaui_link_get,
 	.link_set	= __cvmx_helper_bgx_xaui_link_set,
@@ -255,6 +268,51 @@ static const struct iface_ops_s iface_ops_rxaui = {
 /**
  * @INTERNAL
  * This structure specifies the interface methods used by interfaces
+ * configured as xaui using the gmx mac.
+ */
+static const struct iface_ops_s iface_ops_bgx_rxaui = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_RXAUI,
+	.enumerate	= __cvmx_helper_bgx_enumerate,
+	.probe		= __cvmx_helper_bgx_probe,
+	.enable		= __cvmx_helper_bgx_xaui_enable,
+	.link_get	= __cvmx_helper_bgx_xaui_link_get,
+	.link_set	= __cvmx_helper_bgx_xaui_link_set,
+	.loopback	= __cvmx_helper_bgx_xaui_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as xlaui.
+ */
+static const struct iface_ops_s iface_ops_bgx_xlaui = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_XLAUI,
+	.enumerate	= __cvmx_helper_bgx_enumerate,
+	.probe		= __cvmx_helper_bgx_probe,
+	.enable		= __cvmx_helper_bgx_xaui_enable,
+	.link_get	= __cvmx_helper_bgx_xaui_link_get,
+	.link_set	= __cvmx_helper_bgx_xaui_link_set,
+	.loopback	= __cvmx_helper_bgx_xaui_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
+ * configured as xfi.
+ */
+static const struct iface_ops_s iface_ops_bgx_xfi = {
+	.mode		= CVMX_HELPER_INTERFACE_MODE_XFI,
+	.enumerate	= __cvmx_helper_bgx_enumerate,
+	.probe		= __cvmx_helper_bgx_probe,
+	.enable		= __cvmx_helper_bgx_xaui_enable,
+	.link_get	= __cvmx_helper_bgx_xaui_link_get,
+	.link_set	= __cvmx_helper_bgx_xaui_link_set,
+	.loopback	= __cvmx_helper_bgx_xaui_configure_loopback,
+};
+
+/**
+ * @INTERNAL
+ * This structure specifies the interface methods used by interfaces
  * configured as ilk.
  */
 static const struct iface_ops_s iface_ops_ilk = {
@@ -350,10 +408,10 @@ CVMX_SHARED const struct iface_ops_s *iface_ops[CVMX_HELPER_MAX_IFACE] = {
 	[0 ... CVMX_HELPER_MAX_IFACE - 1] = NULL
 };
 
-CVMX_SHARED uint64_t  cvmx_rgmii_backpressure_dis=1;
+CVMX_SHARED uint64_t  cvmx_rgmii_backpressure_dis = 1;
 
 typedef int (*cvmx_export_config_t)(void);
-cvmx_export_config_t cvmx_export_app_config = NULL;
+cvmx_export_config_t cvmx_export_app_config;
 
 void cvmx_rgmii_set_back_pressure(uint64_t backpressure_dis)
 {
@@ -366,17 +424,6 @@ void cvmx_rgmii_set_back_pressure(uint64_t backpressure_dis)
  */
 extern cvmx_helper_link_info_t __cvmx_helper_get_link_info(int interface, int port);
 
-
-/**
- * cvmx_override_pko_queue_priority(int pko_port, uint64_t
- * priorities[16]) is a function pointer. It is meant to allow
- * customization of the PKO queue priorities based on the port
- * number. Users should set this pointer to a function before
- * calling any cvmx-helper operations.
- */
-CVMX_SHARED void (*cvmx_override_pko_queue_priority) (int ipd_port, uint64_t *priorities) = NULL;
-EXPORT_SYMBOL(cvmx_override_pko_queue_priority);
-
 /**
  * cvmx_override_iface_phy_mode(int interface, int index) is a function pointer.
  * It is meant to allow customization of interfaces which do not have a PHY.
@@ -490,7 +537,7 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn70xx(int interface)
 		prtx_ctl.u64 = cvmx_read_csr(CVMX_AGL_PRTX_CTL(0));
 		if (prtx_ctl.s.mode == 0)
 			iface_ops[interface] = &iface_ops_agl;
-		else 
+		else
 			iface_ops[interface] = &iface_ops_dis;
 	}
 	else
@@ -505,49 +552,50 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn70xx(int interface)
  */
 static cvmx_helper_interface_mode_t __cvmx_get_mode_cn78xx(int interface)
 {
-	/*
-	 * Until gser configuration is in place, we hard code the interface
-	 * mode here. This means that for the time being, this function and 
-	 * cvmx_qlm_get_mode() have to be in sync since they are both hard
-	 * coded.
-	 */
-	switch (interface) {
-	case 0:
-	case 1:
-		iface_ops[interface] = &iface_ops_bgx_sgmii;
-		break;
+	/* SGMII/RXAUI/XAUI */
+	if (interface < 6) {
+		int qlm = cvmx_qlm_interface(interface);
+		enum cvmx_qlm_mode qlm_mode;
 
-	case 2:
-		/*
-		 * Interface 2's qlm is used by ilk so it can never be
-		 * connected to a bgx mac. Disable it for now.
-		 */
-		iface_ops[interface] = &iface_ops_dis;
-		break;
-
-	case 3:
-	case 4:
-	case 5:
-		iface_ops[interface] = &iface_ops_bgx_xaui;
-		break;
-
-	case 6:
-	case 7:
-		iface_ops[interface] = &iface_ops_ilk;
-		break;
-
-	case 8:
-		iface_ops[interface] = &iface_ops_dis;
-		break;
+		if (qlm == -1) {
+			iface_ops[interface] = &iface_ops_dis;
+			return iface_ops[interface]->mode;
+		}
+		qlm_mode = cvmx_qlm_get_mode(qlm);
 
-	case 9:
+		if (qlm_mode == CVMX_QLM_MODE_SGMII)
+			iface_ops[interface] = &iface_ops_bgx_sgmii;
+		else if (qlm_mode == CVMX_QLM_MODE_XAUI)
+			iface_ops[interface] = &iface_ops_bgx_xaui;
+		else if (qlm_mode == CVMX_QLM_MODE_XLAUI)
+			iface_ops[interface] = &iface_ops_bgx_xlaui;
+		else if (qlm_mode == CVMX_QLM_MODE_XFI)
+			iface_ops[interface] = &iface_ops_bgx_xfi;
+		else if (qlm_mode == CVMX_QLM_MODE_RXAUI)
+			iface_ops[interface] = &iface_ops_bgx_rxaui;
+		else
+			iface_ops[interface] = &iface_ops_dis;
+	} else if (interface < 8) {
+		enum cvmx_qlm_mode qlm_mode;
+		if (interface == 6) {
+			qlm_mode = cvmx_qlm_get_mode(4);
+			if (qlm_mode == CVMX_QLM_MODE_ILK)
+				iface_ops[interface] = &iface_ops_ilk;
+			else
+				iface_ops[interface] = &iface_ops_dis;
+		} else if (interface == 7) {
+			qlm_mode = cvmx_qlm_get_mode(5);
+			if (qlm_mode == CVMX_QLM_MODE_ILK)
+				iface_ops[interface] = &iface_ops_ilk;
+			else
+				iface_ops[interface] = &iface_ops_dis;
+		}
+	} else if (interface == 8) { /* DPI */
+		iface_ops[interface] = &iface_ops_npi;
+	} else if (interface == 9) { /* LOOP */
 		iface_ops[interface] = &iface_ops_loop;
-		break;
-
-	default:
+	} else
 		iface_ops[interface] = &iface_ops_dis;
-		break;
-	}
 
 	return iface_ops[interface]->mode;
 }
@@ -675,7 +723,7 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_octeon2(int interface)
 			 */
 			iface_ops[interface] = &iface_ops_dis;
 		else {
-			sriox_status_reg.u64 = 
+			sriox_status_reg.u64 =
 				cvmx_read_csr(CVMX_SRIOX_STATUS_REG(interface - 4));
 			if (sriox_status_reg.s.srio)
 				iface_ops[interface] = &iface_ops_srio;
@@ -975,9 +1023,14 @@ static int cvmx_helper_fcs_op(int interface, int nports, int has_fcs)
 	int pknd;
 	union cvmx_pip_sub_pkind_fcsx pkind_fcsx;
 	union cvmx_pip_prt_cfgx port_cfg;
+	unsigned int node = cvmx_get_node_num();
 
 	if (!octeon_has_feature(OCTEON_FEATURE_PKND))
 		return 0;
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		cvmx_helper_pki_set_fcs_op(node, interface, nports, has_fcs);
+		return 0;
+	}
 
 	port_bit = 0;
 	for (index = 0; index < nports; index++)
@@ -1060,6 +1113,8 @@ int cvmx_helper_interface_probe(int interface)
 		/* XAUI is a single high speed port */
 	case CVMX_HELPER_INTERFACE_MODE_XAUI:
 	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+	case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+	case CVMX_HELPER_INTERFACE_MODE_XFI:
 		has_fcs = 1;
 		padding = CVMX_PKO_PADDING_60;
 		break;
@@ -1136,19 +1191,21 @@ int cvmx_helper_interface_probe(int interface)
  */
 static int __cvmx_helper_interface_setup_ipd(int interface)
 {
-
 	cvmx_helper_interface_mode_t mode;
 	int ipd_port = cvmx_helper_get_ipd_port(interface, 0);
 	int num_ports = cvmx_helper_ports_on_interface(interface);
 	int delta;
+	unsigned int node = cvmx_get_node_num();
 
 	if (num_ports == CVMX_HELPER_CFG_INVALID_VALUE)
 		return 0;
 
 	mode = cvmx_helper_interface_get_mode(interface);
 
-	if (mode == CVMX_HELPER_INTERFACE_MODE_LOOP)
-		__cvmx_helper_loop_enable(interface);
+	if (!octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		if (mode == CVMX_HELPER_INTERFACE_MODE_LOOP)
+			__cvmx_helper_loop_enable(interface);
+	}
 
 	delta = 1;
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
@@ -1159,7 +1216,10 @@ static int __cvmx_helper_interface_setup_ipd(int interface)
 	while (num_ports--) {
 		if (!cvmx_helper_is_port_valid(interface, num_ports))
 			continue;
-		__cvmx_helper_port_setup_ipd(ipd_port);
+		if (octeon_has_feature(OCTEON_FEATURE_PKI))
+			__cvmx_helper_port_setup_pki(node, ipd_port);
+		else
+			__cvmx_helper_port_setup_ipd(ipd_port);
 		ipd_port += delta;
 	}
 
@@ -1178,11 +1238,11 @@ static int __cvmx_helper_interface_setup_ipd(int interface)
 int __cvmx_helper_ipd_setup_fpa_pools(void)
 {
 	cvmx_fpa_global_initialize();
-	if(cvmx_ipd_cfg.packet_pool.buffer_count == 0)
+	if (cvmx_ipd_cfg.packet_pool.buffer_count == 0)
 		return 0;
 		__cvmx_helper_initialize_fpa_pool(cvmx_ipd_cfg.packet_pool.pool_num, cvmx_ipd_cfg.packet_pool.buffer_size,
 					  cvmx_ipd_cfg.packet_pool.buffer_count, "Packet Buffers");
-	if(cvmx_ipd_cfg.wqe_pool.buffer_count == 0)
+	if (cvmx_ipd_cfg.wqe_pool.buffer_count == 0)
 		return 0;
 		__cvmx_helper_initialize_fpa_pool(cvmx_ipd_cfg.wqe_pool.pool_num, cvmx_ipd_cfg.wqe_pool.buffer_size,
 			cvmx_ipd_cfg.wqe_pool.buffer_count, "WQE Buffers");
@@ -1216,94 +1276,6 @@ static int __cvmx_helper_global_setup_ipd(void)
 	return 0;
 }
 
-/**
- * @INTERNAL
- * Setup the PKO for the ports on an interface. The number of
- * queues per port and the priority of each PKO output queue
- * is set here. PKO must be disabled when this function is called.
- *
- * @param interface Interface to setup PKO for
- *
- * @return Zero on success, negative on failure
- */
-static int __cvmx_helper_interface_setup_pko(int interface)
-{
-	/*
-	 * Each packet output queue has an associated priority. The
-	 * higher the priority, the more often it can send a packet. A
-	 * priority of 8 means it can send in all 8 rounds of
-	 * contention. We're going to make each queue one less than
-	 * the last.  The vector of priorities has been extended to
-	 * support CN5xxx CPUs, where up to 16 queues can be
-	 * associated to a port.  To keep backward compatibility we
-	 * don't change the initial 8 priorities and replicate them in
-	 * the second half.  With per-core PKO queues (PKO lockless
-	 * operation) all queues have the same priority.
-	 */
-	/* uint64_t priorities[16] = {8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1}; */
-	uint64_t priorities[16] = {[0 ... 15] = 8 };
-
-	/*
-	 * Setup the IPD/PIP and PKO for the ports discovered
-	 * above. Here packet classification, tagging and output
-	 * priorities are set.
-	 */
-	int ipd_port = cvmx_helper_get_ipd_port(interface, 0);
-	int num_ports = cvmx_helper_ports_on_interface(interface);
-	while (num_ports--) {
-		if (!cvmx_helper_is_port_valid(interface, num_ports))
-			continue;
-		/*
-		 * Give the user a chance to override the per queue
-		 * priorities.
-		 */
-		if (cvmx_override_pko_queue_priority)
-			cvmx_override_pko_queue_priority(ipd_port, priorities);
-
-		cvmx_pko_config_port(ipd_port,
-				     cvmx_pko_get_base_queue(ipd_port),
-				     cvmx_pko_get_num_queues(ipd_port),
-				     priorities);
-		ipd_port++;
-	}
-	return 0;
-}
-
-/**
- * @INTERNAL
- * Setup global setting for PKO not related to a specific
- * interface or port. This must be called before PKO is enabled.
- *
- * @return Zero on success, negative on failure.
- */
-static int __cvmx_helper_global_setup_pko(void)
-{
-	/*
-	 * Disable tagwait FAU timeout. This needs to be done before
-	 * anyone might start packet output using tags.
-	 */
-	union cvmx_iob_fau_timeout fau_to;
-	fau_to.u64 = 0;
-	fau_to.s.tout_val = 0xfff;
-	fau_to.s.tout_enb = 0;
-	cvmx_write_csr(CVMX_IOB_FAU_TIMEOUT, fau_to.u64);
-
-	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
-		union cvmx_pko_reg_min_pkt min_pkt;
-
-		min_pkt.u64 = 0;
-		min_pkt.s.size1 = 59;
-		min_pkt.s.size2 = 59;
-		min_pkt.s.size3 = 59;
-		min_pkt.s.size4 = 59;
-		min_pkt.s.size5 = 59;
-		min_pkt.s.size6 = 59;
-		min_pkt.s.size7 = 59;
-		cvmx_write_csr(CVMX_PKO_REG_MIN_PKT, min_pkt.u64);
-	}
-
-	return 0;
-}
 
 /**
  * @INTERNAL
@@ -1313,8 +1285,7 @@ static int __cvmx_helper_global_setup_pko(void)
  */
 static int __cvmx_helper_global_setup_backpressure(void)
 {
-	if (cvmx_rgmii_backpressure_dis)
-	{
+	if (cvmx_rgmii_backpressure_dis) {
 		/* Disable backpressure if configured to do so */
 		/* Disable backpressure (pause frame) generation */
 		int num_interfaces = cvmx_helper_get_number_of_interfaces();
@@ -1329,6 +1300,8 @@ static int __cvmx_helper_global_setup_backpressure(void)
 			case CVMX_HELPER_INTERFACE_MODE_LOOP:
 			case CVMX_HELPER_INTERFACE_MODE_XAUI:
 			case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+			case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+			case CVMX_HELPER_INTERFACE_MODE_XFI:
 				break;
 			case CVMX_HELPER_INTERFACE_MODE_RGMII:
 			case CVMX_HELPER_INTERFACE_MODE_GMII:
@@ -1336,7 +1309,10 @@ static int __cvmx_helper_global_setup_backpressure(void)
 			case CVMX_HELPER_INTERFACE_MODE_SGMII:
 			case CVMX_HELPER_INTERFACE_MODE_QSGMII:
 			case CVMX_HELPER_INTERFACE_MODE_PICMG:
-				cvmx_gmx_set_backpressure_override(interface, 0xf);
+				if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+					cvmx_bgx_set_backpressure_override(interface, 0xf);
+				else
+					cvmx_gmx_set_backpressure_override(interface, 0xf);
 				break;
 			case CVMX_HELPER_INTERFACE_MODE_AGL:
 				cvmx_agl_set_backpressure_override(interface, 0x1);
@@ -1361,8 +1337,15 @@ int __cvmx_helper_backpressure_is_misaligned(void)
 	uint64_t bp_status1;
 	const int port0 = 0;
 	const int port1 = 16;
-	cvmx_helper_interface_mode_t mode0 = cvmx_helper_interface_get_mode(0);
-	cvmx_helper_interface_mode_t mode1 = cvmx_helper_interface_get_mode(1);
+	cvmx_helper_interface_mode_t mode0, mode1;
+
+	mode0 = cvmx_helper_interface_get_mode(0);
+	mode1 = cvmx_helper_interface_get_mode(1);
+
+	if (!((cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) &&
+	     (OCTEON_IS_MODEL(OCTEON_CN3XXX) ||
+	      OCTEON_IS_MODEL(OCTEON_CN5XXX))))
+		return 0;
 
 	/* Disable error interrupts while we check backpressure */
 	ipd_int_enb = cvmx_read_csr(CVMX_IPD_INT_ENB);
@@ -1496,8 +1479,13 @@ int cvmx_helper_ipd_and_packet_input_enable(void)
 	int interface;
 	int num_ports;
 
-	/* Enable IPD */
-	cvmx_ipd_enable();
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		unsigned int node = cvmx_get_node_num();
+		cvmx_pki_parse_enable(node, 0);
+		cvmx_pki_enable(node);
+	} else
+		/* Enable IPD */
+		cvmx_ipd_enable();
 
 	/*
 	 * Time to enable hardware ports packet input and output. Note
@@ -1512,7 +1500,19 @@ int cvmx_helper_ipd_and_packet_input_enable(void)
 	}
 
 	/* Finally enable PKO now that the entire path is up and running */
-	cvmx_pko_enable();
+	/* enable pko */
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		; // cvmx_pko_enable_78xx(0); already enabled
+	} else {
+		/* FIXME:
+		 * 		 This call was in cvmx-pko.c,
+		 * 		 not sure if this is right either
+		 */
+#ifdef CVMX_BUILD_FOR_STANDALONE
+		__cvmx_install_gmx_error_handler_for_xaui();
+#endif
+		cvmx_pko_enable();
+	}
 
 	if ((OCTEON_IS_MODEL(OCTEON_CN31XX_PASS1) ||
 	     OCTEON_IS_MODEL(OCTEON_CN30XX_PASS1)) &&
@@ -1522,225 +1522,6 @@ int cvmx_helper_ipd_and_packet_input_enable(void)
 }
 EXPORT_SYMBOL(cvmx_helper_ipd_and_packet_input_enable);
 
-#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-
-int cvmx_initialize_sso_78xx(void)
-{
-#define SSO_POOL_NUM 1
-#define SSO_AURA_NUM 1
-
-	int grp;
-	/* Setup an FPA pool to store the SSO queues */
-	const int MAX_SSO_ENTRIES = 4096;
-	int num_blocks = 256 + 48 + ((MAX_SSO_ENTRIES+25)/26);
-	int node = 0;
-	const int aura = SSO_AURA_NUM;
-	cvmx_sso_xaq_aura_t aura_reg;
-	cvmx_sso_nw_tim_t nw_tim;
-	cvmx_sso_aw_cfg_t aw_cfg;
-
-	cvmx_fpa_pool_stack_init(node, SSO_POOL_NUM, "SSO Pool", 0,
-			MAX_SSO_ENTRIES, FPA_NATURAL_ALIGNMENT, 4096);
-	cvmx_fpa_assign_aura(node, SSO_AURA_NUM, SSO_POOL_NUM);
-	cvmx_fpa_aura_init(node, aura, "SSO Aura", 0, num_blocks, 0);
-
-	/* Initialize the 256 group/qos queues */
-	for (grp=0; grp<256; grp++)
-        {
-		cvmx_sso_xaqx_head_ptr_t ptr;
-		cvmx_sso_xaqx_head_next_t next;
-		cvmx_sso_xaqx_tail_next_t tail;
-		cvmx_sso_grpx_pref_t pref;
-		uint64_t addr;
-		void *buffer = cvmx_fpa_alloc_aura(node, SSO_AURA_NUM, 0);
-
-		if (buffer == NULL)
-		{
-			cvmx_dprintf("ERROR: Failed to allocate buffer\n");
-			return -1;
-		}
-		addr = cvmx_ptr_to_phys(buffer);
-		ptr.u64 = 0;
-		next.u64 = 0;
-		tail.u64 = 0;
-		ptr.s.ptr = addr;
-		next.s.ptr = addr;
-		tail.s.ptr = addr;
-
-		cvmx_write_csr_node(node, CVMX_SSO_XAQX_HEAD_PTR(grp), ptr.u64);
-		cvmx_write_csr_node(node, CVMX_SSO_XAQX_HEAD_NEXT(grp), next.u64);
-		cvmx_write_csr_node(node, CVMX_SSO_XAQX_TAIL_NEXT(grp), tail.u64);
-		/* Prefetch one cache line into L1 when a core gets work */
-		pref.u64 = 0;
-		pref.s.clines = 1;
-		cvmx_write_csr_node(node, CVMX_SSO_GRPX_PREF(grp), pref.u64);
-	}
-	/* Set the aura number */
-	aura_reg.u64 = 0;
-	aura_reg.s.laura = SSO_AURA_NUM;
-	aura_reg.s.node = node;
-	cvmx_write_csr_node(node, CVMX_SSO_XAQ_AURA, aura_reg.u64);
-
-	/* Set work timeout to 1023 * 1k cycles */
-	nw_tim.u64 = 0;
-	nw_tim.s.nw_tim = 1023;
-	cvmx_write_csr_node(node, CVMX_SSO_NW_TIM, nw_tim.u64);
-
-	aw_cfg.u64 = cvmx_read_csr_node(node, CVMX_SSO_AW_CFG);
-	aw_cfg.s.rwen = 1;
-	cvmx_write_csr_node(node, CVMX_SSO_AW_CFG, aw_cfg.u64);
-	return 0;
-
-}
-
-#define __CVMX_SSO_RWQ_SIZE 256
-
-int cvmx_helper_initialize_sso(int wqe_entries)
-{
-	int cvm_oct_sso_number_rwq_bufs;
-	char *mem;
-	int i;
-	cvmx_sso_cfg_t sso_cfg;
-	cvmx_fpa_fpfx_marks_t fpa_marks;
-
-	if (!OCTEON_IS_MODEL(OCTEON_CN68XX))
-		return 0;
-
-	/*
-	 * CN68XX-P1 may reset with the wrong values, put in
-	 * the correct values (FPA-15816).
-	 */
-	if (OCTEON_IS_MODEL(OCTEON_CN68XX_PASS1_X)) {
-		fpa_marks.u64 = 0;
-		fpa_marks.s.fpf_wr = 0xa4;
-		fpa_marks.s.fpf_rd = 0x40;
-		cvmx_write_csr(CVMX_FPA_FPF8_MARKS, fpa_marks.u64);
-	}
-
-	cvm_oct_sso_number_rwq_bufs = ((wqe_entries - 1) / 26) + 1 + 48 + 8;
-
-	mem = cvmx_bootmem_alloc(__CVMX_SSO_RWQ_SIZE * cvm_oct_sso_number_rwq_bufs, CVMX_CACHE_LINE_SIZE);
-	if (mem == NULL) {
-		cvmx_dprintf("Out of memory initializing sso pool\n");
-		return -1;
-	}
-	/* Make sure RWI/RWO is disabled. */
-	sso_cfg.u64 = cvmx_read_csr(CVMX_SSO_CFG);
-	sso_cfg.s.rwen = 0;
-	cvmx_write_csr(CVMX_SSO_CFG, sso_cfg.u64);
-
-	for (i = cvm_oct_sso_number_rwq_bufs - 8; i > 0; i--) {
-		cvmx_sso_rwq_psh_fptr_t fptr;
-
-		for (;;) {
-			fptr.u64 = cvmx_read_csr(CVMX_SSO_RWQ_PSH_FPTR);
-			if (!fptr.s.full)
-				break;
-			cvmx_wait(1000);
-		}
-		fptr.s.fptr = cvmx_ptr_to_phys(mem) >> 7;
-		cvmx_write_csr(CVMX_SSO_RWQ_PSH_FPTR, fptr.u64);
-		mem = mem + __CVMX_SSO_RWQ_SIZE;
-	}
-
-	for (i = 0; i < 8; i++) {
-		cvmx_sso_rwq_head_ptrx_t head_ptr;
-		cvmx_sso_rwq_tail_ptrx_t tail_ptr;
-
-		head_ptr.u64 = 0;
-		tail_ptr.u64 = 0;
-		head_ptr.s.ptr = cvmx_ptr_to_phys(mem) >> 7;
-		tail_ptr.s.ptr = head_ptr.s.ptr;
-		cvmx_write_csr(CVMX_SSO_RWQ_HEAD_PTRX(i), head_ptr.u64);
-		cvmx_write_csr(CVMX_SSO_RWQ_TAIL_PTRX(i), tail_ptr.u64);
-		mem = mem + __CVMX_SSO_RWQ_SIZE;
-	}
-
-	sso_cfg.u64 = cvmx_read_csr(CVMX_SSO_CFG);
-	sso_cfg.s.rwen = 1;
-	sso_cfg.s.dwb = cvmx_helper_cfg_opt_get(CVMX_HELPER_CFG_OPT_USE_DWB);
-	sso_cfg.s.rwq_byp_dis = 0;
-	sso_cfg.s.rwio_byp_dis = 0;
-	cvmx_write_csr(CVMX_SSO_CFG, sso_cfg.u64);
-
-	return 0;
-}
-
-int cvmx_helper_uninitialize_sso(void)
-{
-	cvmx_fpa_quex_available_t queue_available;
-	cvmx_sso_cfg_t sso_cfg;
-	cvmx_sso_rwq_pop_fptr_t pop_fptr;
-	cvmx_sso_rwq_psh_fptr_t fptr;
-	cvmx_sso_fpage_cnt_t fpage_cnt;
-	int num_to_transfer, i;
-
-	if (!OCTEON_IS_MODEL(OCTEON_CN68XX))
-		return 0;
-
-	sso_cfg.u64 = cvmx_read_csr(CVMX_SSO_CFG);
-	sso_cfg.s.rwen = 0;
-	sso_cfg.s.rwq_byp_dis = 1;
-	cvmx_write_csr(CVMX_SSO_CFG, sso_cfg.u64);
-	cvmx_read_csr(CVMX_SSO_CFG);
-	queue_available.u64 = cvmx_read_csr(CVMX_FPA_QUEX_AVAILABLE(8));
-
-	/* Make CVMX_FPA_QUEX_AVAILABLE(8) % 16 == 0 */
-	for (num_to_transfer = (16 - queue_available.s.que_siz) % 16; num_to_transfer > 0; num_to_transfer--) {
-		do {
-			pop_fptr.u64 = cvmx_read_csr(CVMX_SSO_RWQ_POP_FPTR);
-		} while (!pop_fptr.s.val);
-		for (;;) {
-			fptr.u64 = cvmx_read_csr(CVMX_SSO_RWQ_PSH_FPTR);
-			if (!fptr.s.full)
-				break;
-			cvmx_wait(1000);
-		}
-		fptr.s.fptr = pop_fptr.s.fptr;
-		cvmx_write_csr(CVMX_SSO_RWQ_PSH_FPTR, fptr.u64);
-	}
-	cvmx_read_csr(CVMX_SSO_CFG);
-
-	do {
-		queue_available.u64 = cvmx_read_csr(CVMX_FPA_QUEX_AVAILABLE(8));
-	} while (queue_available.s.que_siz % 16);
-
-	sso_cfg.s.rwen = 1;
-	sso_cfg.s.rwq_byp_dis = 0;
-	cvmx_write_csr(CVMX_SSO_CFG, sso_cfg.u64);
-
-	for (i = 0; i < 8; i++) {
-		cvmx_sso_rwq_head_ptrx_t head_ptr;
-		cvmx_sso_rwq_tail_ptrx_t tail_ptr;
-
-		head_ptr.u64 = cvmx_read_csr(CVMX_SSO_RWQ_HEAD_PTRX(i));
-		tail_ptr.u64 = cvmx_read_csr(CVMX_SSO_RWQ_TAIL_PTRX(i));
-		if (head_ptr.s.ptr != tail_ptr.s.ptr) {
-			cvmx_dprintf("head_ptr.s.ptr != tail_ptr.s.ptr, idx: %d\n", i);
-		}
-
-		cvmx_phys_to_ptr(((uint64_t) head_ptr.s.ptr) << 7);
-		/* Leak the memory */
-	}
-
-	do {
-		do {
-			pop_fptr.u64 = cvmx_read_csr(CVMX_SSO_RWQ_POP_FPTR);
-			if (pop_fptr.s.val) {
-				cvmx_phys_to_ptr(((uint64_t) pop_fptr.s.fptr) << 7);
-				/* Leak the memory */
-			}
-		} while (pop_fptr.s.val);
-		fpage_cnt.u64 = cvmx_read_csr(CVMX_SSO_FPAGE_CNT);
-	} while (fpage_cnt.s.fpage_cnt);
-
-	sso_cfg.s.rwen = 0;
-	sso_cfg.s.rwq_byp_dis = 0;
-	cvmx_write_csr(CVMX_SSO_CFG, sso_cfg.u64);
-
-	return 0;
-}
-#endif /* CVMX_BUILD_FOR_LINUX_KERNEL */
 /**
  * Initialize the PIP, IPD, and PKO hardware to support
  * simple priority based queues for the ethernet ports. Each
@@ -1759,6 +1540,7 @@ int cvmx_helper_initialize_packet_io_global(void)
 	union cvmx_smix_en smix_en;
 #endif
 	const int num_interfaces = cvmx_helper_get_number_of_interfaces();
+	unsigned int node = cvmx_get_node_num();
 
 	/*
 	 * CN52XX pass 1: Due to a bug in 2nd order CDR, it needs to
@@ -1787,15 +1569,18 @@ int cvmx_helper_initialize_packet_io_global(void)
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
-		int smi_inf = 1;
+		int smi_inf;
 		int i;
 
 		/* Newer chips have more than one SMI/MDIO interface */
-		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		if (OCTEON_IS_MODEL(OCTEON_CN68XX) ||
+		    OCTEON_IS_MODEL(OCTEON_CN78XX))
 			smi_inf = 4;
-		else if (!OCTEON_IS_MODEL(OCTEON_CN3XXX)
-			 && !OCTEON_IS_MODEL(OCTEON_CN58XX)
-			 && !OCTEON_IS_MODEL(OCTEON_CN50XX))
+		else if (OCTEON_IS_MODEL(OCTEON_CN3XXX) ||
+			 OCTEON_IS_MODEL(OCTEON_CN58XX) ||
+			 OCTEON_IS_MODEL(OCTEON_CN50XX))
+			smi_inf = 1;
+		else
 			smi_inf = 2;
 
 		for (i = 0; i < smi_inf; i++) {
@@ -1814,20 +1599,36 @@ int cvmx_helper_initialize_packet_io_global(void)
 	for (interface = 0; interface < num_interfaces; interface++)
 		result |= cvmx_helper_interface_probe(interface);
 
-	cvmx_pko_initialize_global();
+	/* PKO3 init precedes that of interfaces */
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		//FIXME- ILK needs this config data for now - must fix!
+		__cvmx_helper_init_port_config_data();
+		cvmx_helper_pko3_init_global();
+	} 
+	else {
+		cvmx_helper_pko_init();
+	}
+
 	for (interface = 0; interface < num_interfaces; interface++) {
-		if (cvmx_helper_ports_on_interface(interface) > 0)
-			cvmx_dprintf("Interface %d has %d ports (%s)\n",
-				     interface,
-				     cvmx_helper_ports_on_interface(interface),
-				     cvmx_helper_interface_mode_to_string(cvmx_helper_interface_get_mode(interface)));
-		result |= __cvmx_helper_interface_setup_ipd(interface);
-		if (!OCTEON_IS_MODEL(OCTEON_CN68XX))
+		/* Skip invalid/disabled interfaces */
+		if (cvmx_helper_ports_on_interface(interface) <= 0)
+			continue;
+		cvmx_dprintf("Interface %d has %d ports (%s)\n",
+		     interface,
+		     cvmx_helper_ports_on_interface(interface),
+		     cvmx_helper_interface_mode_to_string(cvmx_helper_interface_get_mode(interface)));
+
+		result |= __cvmx_helper_interface_setup_ipd(interface);/* vinita_to_do separate pki */
+		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+			result |= cvmx_helper_pko3_init_interface(interface);
+		else
 			result |= __cvmx_helper_interface_setup_pko(interface);
 	}
 
-	result |= __cvmx_helper_global_setup_ipd();
-	result |= __cvmx_helper_global_setup_pko();
+	if (octeon_has_feature(OCTEON_FEATURE_PKI))
+		result |= __cvmx_helper_global_setup_pki(node);
+	else
+		result |= __cvmx_helper_global_setup_ipd();
 
 	/* Enable any flow control and backpressure */
 	result |= __cvmx_helper_global_setup_backpressure();
@@ -1850,33 +1651,8 @@ EXPORT_SYMBOL(cvmx_helper_initialize_packet_io_global);
  */
 int cvmx_helper_initialize_packet_io_local(void)
 {
-	return cvmx_pko_initialize_local();
-}
-
-/**
- * wait for the pko queue to drain
- *
- * @param queue a valid pko queue
- * @return count is the length of the queue after calling this
- * function
- */
-static int cvmx_helper_wait_pko_queue_drain(int queue)
-{
-	const int timeout = 5;	/* Wait up to 5 seconds for timeouts */
-	int count;
-	uint64_t start_cycle, stop_cycle;
-
-	count = cvmx_cmd_queue_length(CVMX_CMD_QUEUE_PKO(queue));
-	start_cycle = cvmx_get_cycle();
-	stop_cycle = start_cycle + cvmx_clock_get_rate(CVMX_CLOCK_CORE) * timeout;
-	while (count && (cvmx_get_cycle() < stop_cycle)) {
-		cvmx_wait(10000);
-		count = cvmx_cmd_queue_length(CVMX_CMD_QUEUE_PKO(queue));
-	}
-
-	return count;
+	return 0;
 }
-
 struct cvmx_buffer_list {
 	struct cvmx_buffer_list *next;
 };
@@ -1899,14 +1675,15 @@ int cvmx_gmx_set_backpressure_override(uint32_t interface, uint32_t port_mask)
 	union cvmx_gmxx_tx_ovr_bp gmxx_tx_ovr_bp;
 	/* Check for valid arguments */
 	if (port_mask & ~0xf || interface & ~0x1)
-		return (-1);
+		return -1;
 	if (interface >= CVMX_HELPER_MAX_GMX)
 		return -1;
+
 	gmxx_tx_ovr_bp.u64 = 0;
 	gmxx_tx_ovr_bp.s.en = port_mask;	/* Per port Enable back pressure override */
 	gmxx_tx_ovr_bp.s.ign_full = port_mask;	/* Ignore the RX FIFO full when computing BP */
 	cvmx_write_csr(CVMX_GMXX_TX_OVR_BP(interface), gmxx_tx_ovr_bp.u64);
-	return (0);
+	return 0;
 }
 
 /**
@@ -1935,7 +1712,177 @@ int cvmx_agl_set_backpressure_override(uint32_t interface, uint32_t port_mask)
 	/* Ignore the RX FIFO full when computing BP */
 	agl_gmx_tx_ovr_bp.s.ign_full = port_mask;
 	cvmx_write_csr(CVMX_GMXX_TX_OVR_BP(port), agl_gmx_tx_ovr_bp.u64);
-	return (0);
+	return 0;
+}
+
+/**
+ * Disables the sending of flow control (pause) frames on the specified
+ * BGX port(s).
+ *
+ * @param interface Which interface (0 or 1)
+ * @param port_mask Mask (4bits) of which ports on the interface to disable
+ *                  backpressure on.
+ *                  1 => disable backpressure
+ *                  0 => enable backpressure
+ *
+ * @return 0 on success
+ *         -1 on error
+ */
+int cvmx_bgx_set_backpressure_override(uint32_t interface, uint32_t port_mask)
+{
+	cvmx_bgxx_cmr_rx_ovr_bp_t rx_ovr_bp;
+
+	/* Check for valid arguments */
+	rx_ovr_bp.u64 = 0;
+	rx_ovr_bp.s.en = port_mask;	/* Per port Enable back pressure override */
+	rx_ovr_bp.s.ign_fifo_bp = port_mask;	/* Ignore the RX FIFO full when computing BP */
+	cvmx_write_csr(CVMX_BGXX_CMR_RX_OVR_BP(interface), rx_ovr_bp.u64);
+	return 0;
+}
+
+/**
+ * Helper function for global packet IO shutdown
+ */
+static int __cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
+{
+	int num_interfaces = cvmx_helper_get_number_of_interfaces();
+	int interface;
+	int result = 0;
+
+	/* Shut down all interfaces and disable TX and RX on all ports */
+	for (interface = 0; interface < num_interfaces; interface++) {
+		switch (cvmx_helper_interface_get_mode(interface)) {
+		case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+		case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+		case CVMX_HELPER_INTERFACE_MODE_XFI:
+		{
+			cvmx_bgxx_cmrx_config_t cmr_config;
+			int index;
+			int num_ports = cvmx_helper_ports_on_interface(interface);
+			if (num_ports > 4)
+				num_ports = 4;
+
+			cvmx_bgx_set_backpressure_override(interface, 0xf);
+			for (index = 0; index < num_ports; index++) {
+				if (!cvmx_helper_is_port_valid(interface, index))
+					continue;
+
+				/* Disable GMX before we make any changes. Remember the enable state */
+				cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+				cmr_config.s.enable = 0;
+				cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
+				/* Clear all error interrupts before enabling the interface. */
+				if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+					cvmx_write_csr(CVMX_BGXX_SMUX_RX_INT(index, interface), ~0x0ull);
+					cvmx_write_csr(CVMX_BGXX_SMUX_TX_INT(index, interface), ~0x0ull);
+					cvmx_write_csr(CVMX_BGXX_SPUX_INT(index, interface), ~0x0ull);
+				}
+
+				/* Wait for GMX RX to be idle */
+				if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SMUX_CTRL(index, interface),
+				  			cvmx_bgxx_smux_ctrl_t, rx_idle, ==, 1, 10000))
+					return -1;
+
+				/* Wait for GMX TX to be idle */
+				if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SMUX_CTRL(index, interface),
+				  			cvmx_bgxx_smux_ctrl_t, tx_idle, ==, 1, 10000))
+					return -1;
+
+
+			}
+			break;
+		}
+		case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		{
+			cvmx_bgxx_cmrx_config_t cmr_config;
+			int index;
+			int num_ports = cvmx_helper_ports_on_interface(interface);
+			if (num_ports > 4)
+				num_ports = 4;
+
+			cvmx_bgx_set_backpressure_override(interface, 0xf);
+			for (index = 0; index < num_ports; index++) {
+				if (!cvmx_helper_is_port_valid(interface, index))
+					continue;
+		//FIXME: Move this code to cvmx-bgxx.c
+				/* Disable GMX before we make any changes. Remember the enable state */
+				cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+				cmr_config.s.enable = 0;
+				cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
+				/* Wait for GMX to be idle */
+				if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
+				  		cvmx_bgxx_gmp_gmi_prtx_cfg_t, rx_idle, ==, 1, 10000) ||
+	    		    	CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
+						cvmx_bgxx_gmp_gmi_prtx_cfg_t, tx_idle, ==, 1, 10000)) {
+					cvmx_dprintf("SGMII%d: Timeout waiting for port %d to be idle\n",
+			     				interface, index);
+					return -1;
+				}
+
+				/* Read GMX CFG again to make sure the disable completed */
+				cvmx_read_csr(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface));
+			}
+			break;
+		}
+		default:
+			break;
+		}
+	}
+
+	/* Disable PKI */
+	cvmx_pki_disable(node);
+	/* Free all prefetched buffers */
+	__cvmx_pki_free_ptr(node);
+	/* Reset PKI */
+	cvmx_pki_reset(node);
+
+	/* Shutdown PKO interfaces */
+	for (interface = 0; interface < num_interfaces; interface++)
+		cvmx_helper_pko3_shut_interface(interface);
+
+	/* Disable MAC address filtering */
+	for (interface = 0; interface < num_interfaces; interface++) {
+		switch (cvmx_helper_interface_get_mode(interface)) {
+		case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+		case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+		case CVMX_HELPER_INTERFACE_MODE_XFI:
+		case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		{
+			cvmx_bgxx_cmr_rx_adrx_cam_t cmr_rx_adr;
+			int index;
+			int num_ports = cvmx_helper_ports_on_interface(interface);
+			if (num_ports > 4)
+				num_ports = 4;
+
+			for (index = 0; index < num_ports; index++) {
+				if (!cvmx_helper_is_port_valid(interface, index))
+					continue;
+				cmr_rx_adr.u64 = 0;
+				cmr_rx_adr.s.id = index;
+				cmr_rx_adr.s.en = 0;
+				cvmx_write_csr(CVMX_BGXX_CMR_RX_ADRX_CAM(index * 8, interface),
+					       cmr_rx_adr.u64);
+				/* Disable multicast and broadcast packets */
+				cvmx_write_csr(CVMX_BGXX_CMRX_RX_ADR_CTL(index, interface), 0);
+			}
+			break;
+		}
+		default:
+			break;
+		}
+	}
+
+	/* Shutdown the PKO unit */
+	result = cvmx_helper_pko3_shutdown();
+
+	/* Release interface structures */
+	__cvmx_helper_shutdown_interfaces();
+
+	return result;
 }
 
 /**
@@ -1961,9 +1908,13 @@ int cvmx_helper_shutdown_packet_io_global(void)
 	struct cvmx_buffer_list *pool0_buffers_tail;
 	cvmx_wqe_t *work;
 	union cvmx_ipd_ctl_status ipd_ctl_status;
-    int packet_pool = (int)cvmx_fpa_get_packet_pool();
-    uint64_t packet_pool_size = cvmx_fpa_get_packet_pool_block_size();
-    int wqe_pool = (int)cvmx_fpa_get_wqe_pool();
+	int packet_pool = (int)cvmx_fpa_get_packet_pool();
+	uint64_t packet_pool_size = cvmx_fpa_get_packet_pool_block_size();
+	int wqe_pool = (int)cvmx_fpa_get_wqe_pool();
+	int node = cvmx_get_node_num();
+
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		return __cvmx_helper_shutdown_packet_io_global_cn78xx(node);
 
 	/* Step 1: Disable all backpressure */
 	for (interface = 0; interface < num_interfaces; interface++) {
@@ -1976,40 +1927,12 @@ int cvmx_helper_shutdown_packet_io_global(void)
 
 step2:
 	/* Step 2: Wait for the PKO queues to drain */
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		int queue, max_queue;
+	result = __cvmx_helper_pko_drain();
+	if (result < 0)
+		cvmx_dprintf("WARNING: %s: "
+			"Failed to drain some PKO queues\n",
+			__func__);
 
-		max_queue = __cvmx_helper_cfg_pko_max_queue();
-		for (queue = 0; queue < max_queue; queue++) {
-			if (cvmx_helper_wait_pko_queue_drain(queue)) {
-				result = -1;
-				goto step3;
-			}
-		}
-	} else {
-		for (interface = 0; interface < num_interfaces; interface++) {
-			num_ports = cvmx_helper_ports_on_interface(interface);
-			for (index = 0; index < num_ports; index++) {
-				int pko_port;
-				int queue;
-				int max_queue;
-				if (!cvmx_helper_is_port_valid(interface, index))
-					continue;
-				pko_port = cvmx_helper_get_ipd_port(interface, index);
-				queue = cvmx_pko_get_base_queue(pko_port);
-				max_queue = queue + cvmx_pko_get_num_queues(pko_port);
-				while (queue < max_queue) {
-					if (cvmx_helper_wait_pko_queue_drain(queue)) {
-						result = -1;
-						goto step3;
-					}
-					queue++;
-				}
-			}
-		}
-	}
-
-step3:
 	/* Step 3: Disable TX and RX on all ports */
 	for (interface = 0; interface < num_interfaces; interface++) {
 		switch (cvmx_helper_interface_get_mode(interface)) {
@@ -2124,6 +2047,8 @@ step3:
 				}
 			}
 			break;
+		default:
+			break;
 		}
 	}
 
@@ -2169,7 +2094,7 @@ step3:
 					__cvmx_helper_rgmii_configure_loopback(port, 1, 0);
 					while (to_add--) {
 						cvmx_pko_send_packet_prepare(port, queue, CVMX_PKO_LOCK_CMD_QUEUE);
-						if (cvmx_pko_send_packet_finish(port, queue, pko_command, packet, CVMX_PKO_LOCK_CMD_QUEUE)) {
+						if (cvmx_hwpko_send_packet_finish(port, queue, pko_command, packet, CVMX_PKO_LOCK_CMD_QUEUE)) {
 							cvmx_dprintf("ERROR: Unable to align IPD counters (PKO failed)\n");
 							break;
 						}
@@ -2252,6 +2177,8 @@ step3:
 				cvmx_write_csr(CVMX_AGL_GMX_RXX_ADR_CAM5(port), 0);
 			}
 			break;
+		default:
+			break;
 		}
 	}
 
@@ -2347,6 +2274,22 @@ step3:
 
 EXPORT_SYMBOL(cvmx_helper_shutdown_packet_io_global);
 
+int cvmx_helper_shutdown_fpa_pools(int node)
+{
+	int result = 0;
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+	uint64_t pool;
+
+	if (!octeon_has_feature(OCTEON_FEATURE_FPA3)) { /*vinita_to_do implement for 78xx */
+		for (pool = 0; pool < CVMX_FPA_NUM_POOLS; pool++) {
+			if (cvmx_fpa_get_block_size(pool) > 0)
+				result |= cvmx_fpa_shutdown_pool(pool);
+		}
+	}
+#endif
+	return result;
+}
+
 /**
  * Does core local shutdown of packet io
  *
@@ -2506,3 +2449,37 @@ int cvmx_helper_configure_loopback(int ipd_port, int enable_internal,
 	return result;
 }
 
+void cvmx_helper_setup_simulator_io_buffer_counts(int node, int num_packet_buffers,
+					    int pko_buffers)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		cvmx_helper_pki_set_dflt_pool_buffer(node, num_packet_buffers);
+		cvmx_helper_pki_set_dflt_aura_buffer(node, num_packet_buffers);
+
+	} else {
+		cvmx_ipd_set_packet_pool_buffer_count(num_packet_buffers);
+		cvmx_ipd_set_wqe_pool_buffer_count(num_packet_buffers);
+		cvmx_pko_set_cmd_queue_pool_buffer_count(pko_buffers);
+	}
+}
+
+void cvmx_helper_set_wqe_no_ptr_mode(bool mode)
+{
+	if (!octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		cvmx_ipd_ctl_status_t ipd_ctl_status;
+		ipd_ctl_status.u64 = cvmx_read_csr(CVMX_IPD_CTL_STATUS);
+		ipd_ctl_status.s.no_wptr = mode;
+		cvmx_write_csr(CVMX_IPD_CTL_STATUS, ipd_ctl_status.u64);
+	}
+}
+
+void cvmx_helper_set_pkt_wqe_le_mode(bool mode)
+{
+	if (!octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		cvmx_ipd_ctl_status_t ipd_ctl_status;
+		ipd_ctl_status.u64 = cvmx_read_csr(CVMX_IPD_CTL_STATUS);
+		ipd_ctl_status.s.pkt_lend = mode;
+		ipd_ctl_status.s.wqe_lend = mode;
+		cvmx_write_csr(CVMX_IPD_CTL_STATUS, ipd_ctl_status.u64);
+	}
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
index e924068..f24fcac 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
@@ -198,8 +198,7 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 	cvmx_ilk_ser_cfg_t ilk_ser_cfg;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -255,15 +254,14 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 		cvmx_gserx_cfg_t	cvmx_gserx_cfg;
 		cvmx_gserx_phy_ctl_t	cvmx_gserx_phy_ctl;
 
-		for (i = 0, qlm = CVMX_ILK_QLM_BASE(); i < 4; i++, qlm++)
-			mio_qlmx_cfg[i].u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(qlm));
-
 		/*
 		 * QLM registers are not modelled yet. So hardcore the expected
 		 * value here. This must be removed once the hardware is ready
 		 * or the simulator has qlm support. TODO
 		 */
-		mio_qlmx_cfg[0].s.qlm_cfg = 1;
+		for (i = 0, qlm = CVMX_ILK_QLM_BASE(); i < 4; i++, qlm++)
+			mio_qlmx_cfg[i].s.qlm_cfg = 1;
+
 		if (interface == 0) {
 			if ((uni_mask <= 0xf && mio_qlmx_cfg[0].s.qlm_cfg != 1) ||
 			    (uni_mask == 0xff &&
@@ -510,8 +508,7 @@ int cvmx_ilk_rx_set_pknd(int interface, cvmx_ilk_chan_pknd_t * chpknd, unsigned
 	cvmx_ilk_rxf_idx_pmap_t ilk_rxf_idx_pmap;
 	unsigned int i;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -562,8 +559,7 @@ int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 	int num_entries;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -639,8 +635,7 @@ int cvmx_ilk_rx_set_hwm(int interface, int hi_wm)
 	int res = -1;
 	cvmx_ilk_rxx_cfg1_t ilk_rxx_cfg1;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -674,8 +669,7 @@ int cvmx_ilk_rx_cal_ena(int interface, unsigned char cal_ena)
 	int res = -1;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -712,8 +706,7 @@ int cvmx_ilk_cal_setup_rx(int interface, int cal_depth, cvmx_ilk_cal_entry_t * p
 {
 	int res = -1;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -751,8 +744,7 @@ int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 	int num_entries;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -795,7 +787,8 @@ int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 			txx_cal_entryx.s.ctl = pent->ent_ctrl;
 			txx_cal_entryx.s.channel = pent->pipe_bpid;
 
-			cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(i, interface), txx_cal_entryx.u64);
+			cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(i, interface),
+				       txx_cal_entryx.u64);
 			pent++;
 		}
 	}
@@ -819,8 +812,7 @@ int cvmx_ilk_tx_cal_ena(int interface, unsigned char cal_ena)
 	int res = -1;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -853,8 +845,7 @@ int cvmx_ilk_cal_setup_tx(int interface, int cal_depth, cvmx_ilk_cal_entry_t * p
 {
 	int res = -1;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -1129,8 +1120,7 @@ int cvmx_ilk_enable(int interface)
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 #endif
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -1218,8 +1208,7 @@ int cvmx_ilk_disable(int interface)
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 #endif
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -1398,8 +1387,7 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 	cvmx_ilk_txx_mem_stat0_t ilk_txx_mem_stat0;
 	cvmx_ilk_txx_mem_stat1_t ilk_txx_mem_stat1;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
@@ -1410,8 +1398,8 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 
 	/* discrete channels */
 	if (pstats->chan_list != NULL) {
+		unsigned int *chan_list = pstats->chan_list;
 		for (i = 0; i < pstats->num_chans; i++) {
-
 			if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 				/* get the number of rx packets */
 				ilk_rxx_idx_stat0.u64 = 0;
@@ -1422,22 +1410,21 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 	
 				/* get the number of rx bytes */
 				ilk_rxx_idx_stat1.u64 = 0;
-				ilk_rxx_idx_stat1.s.index = *pstats->chan_list;
+				ilk_rxx_idx_stat1.s.index = *chan_list;
 				ilk_rxx_idx_stat1.s.clr = pstats->clr_on_rd;
 				cvmx_write_csr(CVMX_ILK_RXX_IDX_STAT1(interface), ilk_rxx_idx_stat1.u64);
 				ilk_rxx_mem_stat1.u64 = cvmx_read_csr(CVMX_ILK_RXX_MEM_STAT1(interface));
 
 				cvmx_dprintf("ILK%d Channel%d Rx: %d packets %d bytes\n", interface,
-					     *pstats->chan_list, ilk_rxx_mem_stat0.s.rx_pkt, (unsigned int)ilk_rxx_mem_stat1.s.rx_bytes);
+					     *chan_list, ilk_rxx_mem_stat0.s.rx_pkt, (unsigned int)ilk_rxx_mem_stat1.s.rx_bytes);
 			}
 			if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 				cvmx_ilk_rxx_pkt_cntx_t rxx_pkt_cntx;
 				cvmx_ilk_rxx_byte_cntx_t rxx_byte_cntx;
-
-				rxx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_PKT_CNTX(*pstats->chan_list, interface));
-				rxx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_BYTE_CNTX(*pstats->chan_list, interface));
+				rxx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_PKT_CNTX(*chan_list, interface));
+				rxx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_BYTE_CNTX(*chan_list, interface));
 				cvmx_dprintf("ILK%d Channel%d Rx: %llu packets %llu bytes\n", interface,
-					     *pstats->chan_list, 
+					     *chan_list, 
 					     (unsigned long long)rxx_pkt_cntx.s.rx_pkt,
 					     (unsigned long long)rxx_byte_cntx.s.rx_bytes);
 			}
@@ -1445,7 +1432,7 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 			if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 				/* get the number of tx packets */
 				ilk_txx_idx_stat0.u64 = 0;
-				ilk_txx_idx_stat0.s.index = *pstats->chan_list;
+				ilk_txx_idx_stat0.s.index = *chan_list;
 				ilk_txx_idx_stat0.s.clr = pstats->clr_on_rd;
 				cvmx_write_csr(CVMX_ILK_TXX_IDX_STAT0(interface), ilk_txx_idx_stat0.u64);
 				ilk_txx_mem_stat0.u64 = cvmx_read_csr(CVMX_ILK_TXX_MEM_STAT0(interface));
@@ -1458,21 +1445,21 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 				ilk_txx_mem_stat1.u64 = cvmx_read_csr(CVMX_ILK_TXX_MEM_STAT1(interface));
 	
 				cvmx_dprintf("ILK%d Channel%d Tx: %d packets %d bytes\n", interface,
-					     *pstats->chan_list, ilk_txx_mem_stat0.s.tx_pkt, (unsigned int)ilk_txx_mem_stat1.s.tx_bytes);
+					     *chan_list, ilk_txx_mem_stat0.s.tx_pkt, (unsigned int)ilk_txx_mem_stat1.s.tx_bytes);
 			}
 			if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 				cvmx_ilk_txx_pkt_cntx_t txx_pkt_cntx;
 				cvmx_ilk_txx_byte_cntx_t txx_byte_cntx;
 
-				txx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_PKT_CNTX(*pstats->chan_list, interface));
-				txx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_BYTE_CNTX(*pstats->chan_list, interface));
+				txx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_PKT_CNTX(*chan_list, interface));
+				txx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_BYTE_CNTX(*chan_list, interface));
 				cvmx_dprintf("ILK%d Channel%d Tx: %llu packets %llu bytes\n", interface,
-					     *pstats->chan_list,
+					     *chan_list,
 					     (unsigned long long)txx_pkt_cntx.s.tx_pkt,
 					     (unsigned long long)txx_byte_cntx.s.tx_bytes);
 			}
 
-			pstats++;
+			chan_list++;
 		}
 		return;
 	}
@@ -1553,8 +1540,7 @@ int cvmx_ilk_lpbk(int interface, cvmx_ilk_lpbk_ena_t enable, cvmx_ilk_lpbk_mode_
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 
-	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)) &&
-	    !(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
 	if (interface >= CVMX_NUM_ILK_INTF)
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ipd.c b/arch/mips/cavium-octeon/executive/cvmx-ipd.c
index d4c53fe..ca8e479 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ipd.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ipd.c
@@ -42,7 +42,6 @@
  *
  * IPD Support.
  *
- * <hr>$Revision: 58943 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/module.h>
@@ -58,16 +57,17 @@
 #include <asm/octeon/cvmx-clock.h>
 #include <asm/octeon/cvmx-helper-errata.h>
 #include <asm/octeon/cvmx-helper-cfg.h>
+#include <asm/octeon/cvmx-helper-pki.h>
 #else
 #include "cvmx.h"
 #include "cvmx-sysinfo.h"
 #include "cvmx-bootmem.h"
 #include "cvmx-version.h"
 #include "cvmx-error.h"
-
 #include "cvmx-fpa.h"
 #include "cvmx-wqe.h"
 #include "cvmx-ipd.h"
+#include "cvmx-helper-pki.h"
 #include "cvmx-helper-errata.h"
 #include "cvmx-helper-cfg.h"
 #endif
@@ -80,15 +80,63 @@ CVMX_SHARED cvmx_ipd_config_t cvmx_ipd_cfg = {.first_mbuf_skip = 184,
 						.port_config = { CVMX_PIP_PORT_CFG_MODE_SKIPL2,
 								CVMX_POW_TAG_TYPE_ORDERED,
 								CVMX_PIP_TAG_MODE_TUPLE,
-								.tag_fields = {0,0,0,0,0,0,0,0,0,0,1 }
+								.tag_fields = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1 }
 						}
 					};
 EXPORT_SYMBOL(cvmx_ipd_cfg);
 
+/* FIXME- review these values, convert to params ? */
+#define IPD_RED_AVG_DLY	1000
+#define IPD_RED_PRB_DLY	1000
+
+void cvmx_ipd_convert_to_newcfg(cvmx_ipd_config_t ipd_config)
+{
+	int pkind;
+	unsigned int node = cvmx_get_node_num();
+
+	/*Set all the styles to same parameters since old config does not have per port config*/
+	pki_dflt_style[node].parm_cfg.cache_mode = ipd_config.cache_mode;
+	pki_dflt_style[node].parm_cfg.first_skip = ipd_config.first_mbuf_skip;
+	pki_dflt_style[node].parm_cfg.later_skip = ipd_config.not_first_mbuf_skip;
+	pki_dflt_style[node].parm_cfg.mbuff_size = ipd_config.packet_pool.buffer_size;
+	pki_dflt_style[node].parm_cfg.tag_type = ipd_config.port_config.tag_type;
+
+	pki_dflt_style[node].tag_cfg.tag_fields.layer_c_src = ipd_config.port_config.tag_fields.ipv6_src_ip |
+			ipd_config.port_config.tag_fields.ipv4_src_ip;
+	pki_dflt_style[node].tag_cfg.tag_fields.layer_c_dst = ipd_config.port_config.tag_fields.ipv6_dst_ip |
+			ipd_config.port_config.tag_fields.ipv4_dst_ip;
+	pki_dflt_style[node].tag_cfg.tag_fields.ip_prot_nexthdr = ipd_config.port_config.tag_fields.ipv6_next_header |
+			ipd_config.port_config.tag_fields.ipv4_protocol;
+	pki_dflt_style[node].tag_cfg.tag_fields.layer_d_src = ipd_config.port_config.tag_fields.ipv6_src_port |
+			ipd_config.port_config.tag_fields.ipv4_src_port;
+	pki_dflt_style[node].tag_cfg.tag_fields.layer_d_dst = ipd_config.port_config.tag_fields.ipv6_dst_port |
+			ipd_config.port_config.tag_fields.ipv4_dst_port;
+	pki_dflt_style[node].tag_cfg.tag_fields.input_port = ipd_config.port_config.tag_fields.input_port;
+
+	if (ipd_config.port_config.parse_mode == 0x1)
+		pki_dflt_pkind[node].initial_parse_mode = CVMX_PKI_PARSE_LA_TO_LG;
+	else if (ipd_config.port_config.parse_mode == 0x2)
+		pki_dflt_pkind[node].initial_parse_mode = CVMX_PKI_PARSE_LC_TO_LG;
+	else
+		pki_dflt_pkind[node].initial_parse_mode = CVMX_PKI_PARSE_NOTHING;
+
+	/* For compatibility make style = pkind so old software can modify style */
+	for (pkind = 0; pkind < CVMX_PKI_NUM_PKIND; pkind++)
+		pkind_style_map[node][pkind] = pkind;
+	/*setup packet pool*/
+	cvmx_helper_pki_set_dflt_pool(node, ipd_config.packet_pool.pool_num,
+					 ipd_config.packet_pool.buffer_size, ipd_config.packet_pool.buffer_count);
+	cvmx_helper_pki_set_dflt_aura(node, ipd_config.packet_pool.pool_num,
+					 ipd_config.packet_pool.pool_num, ipd_config.packet_pool.buffer_count);
+}
+
+
 
 int cvmx_ipd_set_config(cvmx_ipd_config_t ipd_config)
 {
 	cvmx_ipd_cfg = ipd_config;
+	if (octeon_has_feature(OCTEON_FEATURE_PKI))
+		cvmx_ipd_convert_to_newcfg(ipd_config);
 	return 0;
 }
 
@@ -97,15 +145,32 @@ void cvmx_ipd_get_config(cvmx_ipd_config_t *ipd_config)
 	*ipd_config = cvmx_ipd_cfg;
 }
 
-void cvmx_ipd_set_packet_pool_config(int64_t pool, uint64_t buffer_size,
-				        uint64_t buffer_count)
+void cvmx_ipd_set_packet_pool_buffer_count(uint64_t buffer_count)
 {
-	cvmx_ipd_cfg.packet_pool.pool_num = pool;
-	cvmx_ipd_cfg.packet_pool.buffer_size = buffer_size;
 	cvmx_ipd_cfg.packet_pool.buffer_count = buffer_count;
 }
+
+void cvmx_ipd_set_packet_pool_config(int64_t pool, uint64_t buffer_size,
+				     uint64_t buffer_count)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		int node = cvmx_get_node_num();
+		int64_t aura = pool;
+		cvmx_helper_pki_set_dflt_pool(node, pool, buffer_size, buffer_count);
+		cvmx_helper_pki_set_dflt_aura(node, aura, pool, buffer_count);
+	} else {
+		cvmx_ipd_cfg.packet_pool.pool_num = pool;
+		cvmx_ipd_cfg.packet_pool.buffer_size = buffer_size;
+		cvmx_ipd_cfg.packet_pool.buffer_count = buffer_count;
+	}
+}
 EXPORT_SYMBOL(cvmx_ipd_set_packet_pool_config);
 
+void cvmx_ipd_set_wqe_pool_buffer_count(uint64_t buffer_count)
+{
+	cvmx_ipd_cfg.wqe_pool.buffer_count = buffer_count;
+}
+
 void cvmx_ipd_set_wqe_pool_config(int64_t pool, uint64_t buffer_size,
 				       uint64_t buffer_count)
 {
@@ -121,7 +186,7 @@ static void __cvmx_ipd_free_ptr_v1(void)
 	int i;
 	union cvmx_ipd_ptr_count ptr_count;
 	union cvmx_ipd_prc_port_ptr_fifo_ctl prc_port_fifo;
-        int packet_pool = (int)cvmx_fpa_get_packet_pool();
+	int packet_pool = (int)cvmx_fpa_get_packet_pool();
 
 	/* Only CN38XXp{1,2} cannot read pointer out of the IPD */
 	if (OCTEON_IS_MODEL(OCTEON_CN38XX_PASS2))
@@ -402,10 +467,156 @@ void cvmx_ipd_config(uint64_t mbuff_size,
 	ipd_ctl_reg.s.pbp_en = back_pres_enable_flag;
 	cvmx_write_csr(CVMX_IPD_CTL_STATUS, ipd_ctl_reg.u64);
 
-	/* Note: the example RED code that used to be here has been moved to
-	   cvmx_helper_setup_red */
+	/* Note: the example RED code is below */
 }
 
+
+/**
+ * Setup Random Early Drop on a specific input queue
+ *
+ * @param queue  Input queue to setup RED on (0-7)
+ * @param pass_thresh
+ *               Packets will begin slowly dropping when there are less than
+ *               this many packet buffers free in FPA 0.
+ * @param drop_thresh
+ *               All incomming packets will be dropped when there are less
+ *               than this many free packet buffers in FPA 0.
+ * @return Zero on success. Negative on failure
+ */
+int cvmx_ipd_setup_red_queue(int queue, int pass_thresh, int drop_thresh)
+{
+	union cvmx_ipd_qosx_red_marks red_marks;
+	union cvmx_ipd_red_quex_param red_param;
+
+	/*
+	 * Set RED to begin dropping packets when there are
+	 * pass_thresh buffers left. It will linearly drop more
+	 * packets until reaching drop_thresh buffers.
+	 */
+	red_marks.u64 = 0;
+	red_marks.s.drop = drop_thresh;
+	red_marks.s.pass = pass_thresh;
+	cvmx_write_csr(CVMX_IPD_QOSX_RED_MARKS(queue), red_marks.u64);
+
+	/* Use the actual queue 0 counter, not the average */
+	red_param.u64 = 0;
+	red_param.s.prb_con = (255ul << 24) / (red_marks.s.pass - red_marks.s.drop);
+	red_param.s.avg_con = 1;
+	red_param.s.new_con = 255;
+	red_param.s.use_pcnt = 1;
+	cvmx_write_csr(CVMX_IPD_RED_QUEX_PARAM(queue), red_param.u64);
+	return 0;
+}
+
+/**
+ * Setup Random Early Drop to automatically begin dropping packets.
+ *
+ * @param pass_thresh
+ *               Packets will begin slowly dropping when there are less than
+ *               this many packet buffers free in FPA 0.
+ * @param drop_thresh
+ *               All incomming packets will be dropped when there are less
+ *               than this many free packet buffers in FPA 0.
+ * @return Zero on success. Negative on failure
+ */
+int cvmx_ipd_setup_red(int pass_thresh, int drop_thresh)
+{
+	int queue;
+	int interface;
+	int port;
+
+	/*vinita_to_do modify for 78xx*/
+	if (octeon_has_feature(OCTEON_FEATURE_PKI))
+		return -1;
+	/*
+	 * Disable backpressure based on queued buffers. It needs SW support
+	 */
+	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
+		int bpid;
+		for (interface = 0; interface < CVMX_HELPER_MAX_GMX; interface++) {
+			int num_ports;
+
+			num_ports = cvmx_helper_ports_on_interface(interface);
+			for (port = 0; port < num_ports; port++) {
+				bpid = cvmx_helper_get_bpid(interface, port);
+				if (bpid == CVMX_INVALID_BPID)
+					cvmx_dprintf("setup_red: cvmx_helper_get_bpid(%d, %d) = %d\n",
+						     interface, port,
+						     cvmx_helper_get_bpid(interface, port));
+				else
+					cvmx_write_csr(CVMX_IPD_BPIDX_MBUF_TH(bpid), 0);
+			}
+		}
+	} else {
+		union cvmx_ipd_portx_bp_page_cnt page_cnt;
+
+		page_cnt.u64 = 0;
+		page_cnt.s.bp_enb = 0;
+		page_cnt.s.page_cnt = 100;
+		for (interface = 0; interface < CVMX_HELPER_MAX_GMX; interface++) {
+			for (port = cvmx_helper_get_first_ipd_port(interface); port < cvmx_helper_get_last_ipd_port(interface); port++)
+				cvmx_write_csr(CVMX_IPD_PORTX_BP_PAGE_CNT(port), page_cnt.u64);
+		}
+	}
+
+	for (queue = 0; queue < 8; queue++)
+		cvmx_ipd_setup_red_queue(queue, pass_thresh, drop_thresh);
+
+	/*
+	 * Shutoff the dropping based on the per port page count. SW isn't
+	 * decrementing it right now
+	 */
+	if (octeon_has_feature(OCTEON_FEATURE_PKND))
+		cvmx_write_csr(CVMX_IPD_ON_BP_DROP_PKTX(0), 0);
+	else
+		cvmx_write_csr(CVMX_IPD_BP_PRT_RED_END, 0);
+
+	/*
+	 * Setting up avg_dly and prb_dly, enable bits
+	 */
+	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
+		union cvmx_ipd_red_delay red_delay;
+		union cvmx_ipd_red_bpid_enablex red_bpid_enable;
+
+		red_delay.u64 = 0;
+		red_delay.s.avg_dly = IPD_RED_AVG_DLY;
+		red_delay.s.prb_dly = IPD_RED_PRB_DLY;
+		cvmx_write_csr(CVMX_IPD_RED_DELAY, red_delay.u64);
+
+		/*
+		 * Only enable the gmx ports
+		 */
+		red_bpid_enable.u64 = 0;
+		for (interface = 0; interface < CVMX_HELPER_MAX_GMX; interface++) {
+			int num_ports = cvmx_helper_ports_on_interface(interface);
+			for (port = 0; port < num_ports; port++)
+				red_bpid_enable.u64 |= (((uint64_t) 1) << cvmx_helper_get_bpid(interface, port));
+		}
+		cvmx_write_csr(CVMX_IPD_RED_BPID_ENABLEX(0), red_bpid_enable.u64);
+	} else {
+		union cvmx_ipd_red_port_enable red_port_enable;
+
+		red_port_enable.u64 = 0;
+		red_port_enable.s.prt_enb = 0xfffffffffull;
+		red_port_enable.s.avg_dly = IPD_RED_AVG_DLY;
+		red_port_enable.s.prb_dly = IPD_RED_PRB_DLY;
+		cvmx_write_csr(CVMX_IPD_RED_PORT_ENABLE, red_port_enable.u64);
+
+		/*
+		 * Shutoff the dropping of packets based on RED for SRIO ports
+		 */
+		if (octeon_has_feature(OCTEON_FEATURE_SRIO)) {
+			union cvmx_ipd_red_port_enable2 red_port_enable2;
+			red_port_enable2.u64 = 0;
+			red_port_enable2.s.prt_enb = 0xf0;
+			cvmx_write_csr(CVMX_IPD_RED_PORT_ENABLE2, red_port_enable2.u64);
+		}
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(cvmx_ipd_setup_red);
+
 /**
  * Enable IPD
  */
@@ -427,8 +638,7 @@ void cvmx_ipd_enable(void)
 
 	ipd_reg.s.ipd_en = 1;
 
-
-	if(cvmx_ipd_cfg.enable_len_M8_fix) {
+	if (cvmx_ipd_cfg.enable_len_M8_fix) {
 		if (!OCTEON_IS_MODEL(OCTEON_CN38XX_PASS2))
 			ipd_reg.s.len_m8 = 1;
 	}
@@ -443,6 +653,12 @@ EXPORT_SYMBOL(cvmx_ipd_enable);
 void cvmx_ipd_disable(void)
 {
 	cvmx_ipd_ctl_status_t ipd_reg;
+
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		unsigned int node = cvmx_get_node_num();
+		cvmx_pki_disable(node);
+		return;
+	}
 	ipd_reg.u64 = cvmx_read_csr(CVMX_IPD_CTL_STATUS);
 	ipd_reg.s.ipd_en = 0;
 	cvmx_write_csr(CVMX_IPD_CTL_STATUS, ipd_reg.u64);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-l2c.c b/arch/mips/cavium-octeon/executive/cvmx-l2c.c
index 609fb97..25c6d99 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-l2c.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-l2c.c
@@ -43,7 +43,7 @@
  * Implementation of the Level 2 Cache (L2C) control,
  * measurement, and debugging facilities.
  *
- * <hr>$Revision: 92683 $<hr>
+ * <hr>$Revision: 94422 $<hr>
  *
  */
 
@@ -388,12 +388,12 @@ int cvmx_l2c_lock_line(uint64_t addr)
 				 && l2c_tadx_tag.cn70xx.valid
 				 && l2c_tadx_tag.cn70xx.tag == tag)
 				break;
-			else if (l2c_tadx_tag.cn78xx.ts == 0
+			else if (l2c_tadx_tag.cn78xx.ts != 0
 				 && l2c_tadx_tag.cn78xx.tag == tag)
 			        break;
 
-			/* cvmx_dprintf("caddr=%lx tad=%d tagu64=%lx valid=%x tag=%x \n", caddr,
-			   tad, l2c_tadx_tag.u64, l2c_tadx_tag.s.valid, l2c_tadx_tag.s.tag); */
+			 /* cvmx_dprintf("caddr=%lx tad=%d tagu64=%lx valid=%x tag=%x \n", caddr,
+			   tad, l2c_tadx_tag.u64, l2c_tadx_tag.cn70xx.valid, l2c_tadx_tag.cn70xx.tag); */
 		}
 
 		/* Check if a valid line is found */
@@ -770,9 +770,9 @@ union cvmx_l2c_tag cvmx_l2c_get_tag_v2(uint32_t association, uint32_t index, uin
 		l2c_tadx_tag.u64 = cvmx_read_csr(CVMX_L2C_TADX_TAG(tad));
 
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-			if (l2c_tadx_tag.cn78xx.ts == 0)
+			if (l2c_tadx_tag.cn78xx.ts != 0)
 				tag.s.V = 1;
-			tag.s.D = l2c_tadx_tag.cn78xx.sblkdty; /* FIXME */
+			tag.s.D = l2c_tadx_tag.cn78xx.sblkdty;
 			tag.s.L = l2c_tadx_tag.cn78xx.lock;
 			tag.s.U = l2c_tadx_tag.cn78xx.used;
 			tag.s.addr = l2c_tadx_tag.cn78xx.tag;
@@ -865,7 +865,7 @@ union cvmx_l2c_tag cvmx_l2c_get_tag(uint32_t association, uint32_t index)
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 			if (l2c_tadx_tag.cn78xx.ts == 0)
 				tag.s.V = 1;
-			tag.s.D = l2c_tadx_tag.cn78xx.sblkdty; /* FIXME */
+			tag.s.D = l2c_tadx_tag.cn78xx.sblkdty;
 			tag.s.L = l2c_tadx_tag.cn78xx.lock;
 			tag.s.U = l2c_tadx_tag.cn78xx.used;
 			tag.s.addr = l2c_tadx_tag.cn78xx.tag;
@@ -936,6 +936,14 @@ int cvmx_l2c_address_to_tad(uint64_t addr)
 		} else {
 			tad = (addr >> 7) & 3;
 		}
+	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		cvmx_l2c_ctl_t l2c_ctl;
+		l2c_ctl.u64 = cvmx_read_csr(CVMX_L2C_CTL);
+		if (!l2c_ctl.s.disidxalias) {
+			tad = ((addr >> 7) ^ (addr >> 12) ^ (addr >> 20)) & 7;
+		} else {
+			tad = (addr >> 7) & 7;
+		}
 	} else {
 		tad = 0;
 	}
@@ -974,12 +982,18 @@ uint32_t cvmx_l2c_address_to_index(uint64_t addr)
 	}
 
 	if (indxalias) {
-		if (OCTEON_IS_MODEL(OCTEON_CN68XX)
-		    || OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 			uint32_t a_14_12 = (idx / (CVMX_L2C_MEMBANK_SELECT_SIZE / (1 << CVMX_L2C_IDX_ADDR_SHIFT))) & 0x7;
 			idx ^= (idx / cvmx_l2c_get_num_sets()) & 0x3ff;
 			idx ^= a_14_12 & 0x3;
 			idx ^= a_14_12 << 2;
+		} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+			uint32_t a_14_12 = (idx / (CVMX_L2C_MEMBANK_SELECT_SIZE / (1 << CVMX_L2C_IDX_ADDR_SHIFT))) & 0x7;
+			uint64_t above_normal_index = (idx / cvmx_l2c_get_num_sets()) & 0xff;	// A<27:20>
+			idx ^= above_normal_index;		  // XOR in A<27:20>
+			idx ^= (above_normal_index & 0x1F) << 8;  // XOR in A<24:20>
+			idx ^= a_14_12;				  // XOR in A<14:12>
+			idx ^= (a_14_12 & 0x3) << 3;		  // XOR in A<13:12>
 		} else if (OCTEON_IS_OCTEON2()
 			   || OCTEON_IS_MODEL(OCTEON_CN70XX)) {
 			uint32_t a_14_12 = (idx / (CVMX_L2C_MEMBANK_SELECT_SIZE / (1 << CVMX_L2C_IDX_ADDR_SHIFT))) & 0x7;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-nand.c b/arch/mips/cavium-octeon/executive/cvmx-nand.c
index c576582..8c48ebc 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-nand.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-nand.c
@@ -170,32 +170,11 @@ typedef struct {
  * Array indexed by bootbus chip select with information
  * about NAND devices.
  */
-#if defined(__U_BOOT__)
-/* For u-boot nand boot we need to play some tricks to be able
-* to use this early in boot.  We put them in a special section that is merged
-* with the text segment.  (Using the text segment directly results in an
-* assembler warning.)
-*/
-/*#define USE_DATA_IN_TEXT*/
-#endif
-
-#ifdef USE_DATA_IN_TEXT
-static uint8_t cvmx_nand_buffer[CVMX_NAND_MAX_PAGE_AND_OOB_SIZE]
-	__attribute__ ((aligned(8))) __attribute__ ((section(".data_in_text")));
-static cvmx_nand_state_t cvmx_nand_state[8]
-	__attribute__ ((section(".data_in_text")));
-static cvmx_nand_state_t cvmx_nand_default
-	__attribute__ ((section(".data_in_text")));
-static cvmx_nand_initialize_flags_t cvmx_nand_flags
-	__attribute__ ((section(".data_in_text")));
-static int debug_indent __attribute__ ((section(".data_in_text")));
-#else
 static CVMX_SHARED cvmx_nand_state_t cvmx_nand_state[8];
 static CVMX_SHARED cvmx_nand_state_t cvmx_nand_default;
 static CVMX_SHARED cvmx_nand_initialize_flags_t cvmx_nand_flags;
 static CVMX_SHARED uint8_t *cvmx_nand_buffer;
 static int debug_indent;
-#endif
 
 static CVMX_SHARED const char *cvmx_nand_opcode_labels[] = {
 	"NOP",			/* 0 */
@@ -361,15 +340,23 @@ static inline uint64_t __cvmx_nand_adjust_address(int chip,
  */
 static inline int __cvmx_nand_get_column_bits(int chip)
 {
-	/* Numonyx devices are rather strange in that they use different read
-	 * commands to start at offsets 256 and for the OOB area.
-	 */
-	if (cvmx_nand_state[chip].flags & CVMX_NAND_NUMONYX)
-		return 8;
 	return cvmx_pop(cvmx_nand_state[chip].page_size - 1);
 }
 
 /**
+ * Normally we would use fls, but this is not defined for simple exec.
+ * Find last set bit in word (most significant bit set)
+ *
+ * @param x value to check
+ *
+ * @return most significant bit number set (1 to 32) or 0 if x is zero.
+ */
+static inline int __cvmx_fls(int x)
+{
+	return (sizeof(x) * 8 - __builtin_clz(x));
+}
+
+/**
  * @INTERNAL
  * Get the number of bits required to encode the row bits. This
  * does not include padding to align on a byte boundary.
@@ -380,8 +367,8 @@ static inline int __cvmx_nand_get_column_bits(int chip)
  */
 static inline int __cvmx_nand_get_row_bits(int chip)
 {
-	return cvmx_pop(cvmx_nand_state[chip].blocks - 1)
-	       + cvmx_pop(cvmx_nand_state[chip].pages_per_block - 1);
+	return (__cvmx_fls(cvmx_nand_state[chip].blocks) - 1) +
+		(__cvmx_fls(cvmx_nand_state[chip].pages_per_block) - 1);
 }
 
 /**
@@ -467,7 +454,8 @@ cvmx_nand_onfi_process(cvmx_nand_onfi_param_page_t param_page[3])
 		nand_debug("%*srevision_number = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].revision_number));
 		nand_debug("%*sfeatures = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].features));
 		nand_debug("%*soptional_commands = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].optional_commands));
-
+		nand_debug("%*sextended_param_page_len = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].extended_param_page_len));
+		nand_debug("%*snum_param_pages = 0x%x\n", 2 * debug_indent, "", param_page[index].num_param_pages);
 		nand_debug("%*smanufacturer = %12.12s\n", 2 * debug_indent, "", param_page[index].manufacturer);
 		nand_debug("%*smodel = %20.20s\n", 2 * debug_indent, "", param_page[index].model);
 		nand_debug("%*sjedec_id = 0x%x\n", 2 * debug_indent, "", param_page[index].jedec_id);
@@ -643,7 +631,6 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 
 	memset(&cvmx_nand_state, 0, sizeof(cvmx_nand_state));
 
-#ifndef USE_DATA_IN_TEXT
 	/* cvmx_nand_buffer is statically allocated in the TEXT_IN_DATA case */
 	if (!cvmx_nand_buffer)
 		cvmx_nand_buffer =
@@ -661,7 +648,6 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 
 	if (!cvmx_nand_buffer)
 		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
-#endif
 
 	nand_selected = __cvmx_nand_select(1);
 
@@ -1010,89 +996,6 @@ cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
 				 */
 				continue;
 			}
-			case 0x20: {
-				/* We have a Micron/Numonyx part */
-				/* NOTE: Currently there are still issues with
-				 * these devices since they don't seem to
-				 * follow the standard commands.
-				 */
-				uint64_t nand_size_bits = -1;
-				cvmx_nand_state[chip].page_size = 0x200;
-				cvmx_nand_state[chip].oob_size = 16;
-				cvmx_nand_state[chip].pages_per_block = 32;
-				switch (nand_id_buffer[1]) {
-				case 0x73:
-					nand_size_bits = 128 << 20;
-					cvmx_nand_state[chip].onfi_timing = 9;
-					break;
-				case 0x35:
-				case 0x45:
-					nand_size_bits = 256 << 20;
-					cvmx_nand_state[chip].onfi_timing = 10;
-					break;
-				case 0x55:
-				case 0x75:
-					nand_size_bits = 256 << 20;
-					cvmx_nand_state[chip].onfi_timing = 9;
-					break;
-				case 0x76:	/* 3.3v, 8-bit */
-				case 0x56:	/* 3.3v 16-bit */
-					nand_size_bits = 512 << 20;
-					cvmx_nand_state[chip].onfi_timing = 7;
-					break;
-				case 0x36:
-				case 0x46:
-					nand_size_bits = 512 << 20;
-					cvmx_nand_state[chip].onfi_timing = 8;
-					break;
-				default:
-					nand_debug("%s: Unknown Micron chip ID 0x%02x\n",
-						     __func__, nand_id_buffer[1]);
-					__cvmx_nand_select(nand_selected);
-					return CVMX_NAND_ERROR;
-				}
-				cvmx_nand_state[chip].flags |= CVMX_NAND_NUMONYX;
-				cvmx_nand_state[chip].blocks =
-					nand_size_bits /
-						(8 * cvmx_nand_state[chip].page_size * cvmx_nand_state[chip].pages_per_block);
-				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
-					nand_debug("%s: Micron/Numonyx NAND chip detected, using parameters decoded from ID bytes.\n",
-						     __func__);
-					nand_debug("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, part size: %d MBytes, timing mode: %d\n",
-						     __func__,
-						     cvmx_nand_state[chip].page_size,
-						     cvmx_nand_state[chip].oob_size,
-						     cvmx_nand_state[chip].pages_per_block,
-						     (int)(nand_size_bits / (8 * 1024 * 1024)),
-						     cvmx_nand_state[chip].onfi_timing);
-					nand_debug("%s: Address cycles: %d, column bits: %d, row bits: %d, block count: %d\n",
-						     __func__,
-						     __cvmx_nand_get_address_cycles(chip),
-						     __cvmx_nand_get_column_bits(chip),
-						     __cvmx_nand_get_row_bits(chip),
-						     cvmx_nand_state[chip].blocks);
-				}
-
-				__set_onfi_timing_mode(cvmx_nand_state[chip].tim_par,
-						       clocks_us,
-						       cvmx_nand_state[chip].onfi_timing);
-				if ((cvmx_nand_state[chip].page_size +
-				     cvmx_nand_state[chip].oob_size) >
-				    CVMX_NAND_MAX_PAGE_AND_OOB_SIZE) {
-					nand_debug("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
-						     __func__,
-						     cvmx_nand_state[chip].page_size,
-						     cvmx_nand_state[chip].oob_size,
-						     CVMX_NAND_MAX_PAGE_AND_OOB_SIZE);
-					__cvmx_nand_select(nand_selected);
-					return CVMX_NAND_ERROR;
-				}
-
-				/* We have completed setup for this Samsung
-				 * chip, so go on to next chip.
-				 */
-				continue;
-			}
 			default:
 				break;
 			}
@@ -1350,11 +1253,7 @@ static inline cvmx_nand_status_t __cvmx_nand_build_pre_cmd(int chip,
 	if (num_address_cycles) {
 		memset(&cmd, 0, sizeof(cmd));
 		cmd.ale.adr_byte_num = num_address_cycles;
-		if (cvmx_nand_state[chip].flags & CVMX_NAND_NUMONYX) {
-			nand_address /= cvmx_nand_state[chip].page_size;
-			cmd.ale.adr_bytes_l = nand_address;
-			cmd.ale.adr_bytes_h = nand_address >> 32;
-		} else if (num_address_cycles < __cvmx_nand_get_address_cycles(chip)) {
+		if (num_address_cycles < __cvmx_nand_get_address_cycles(chip)) {
 			cmd.ale.adr_bytes_l = nand_address;
 			cmd.ale.adr_bytes_h = nand_address >> 32;
 		} else {
@@ -1654,10 +1553,7 @@ int cvmx_nand_page_read(int chip, uint64_t nand_address,
 	if (!buffer_length)
 		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
 
-	if (cvmx_nand_state[chip].flags & CVMX_NAND_NUMONYX)
-		command2 = 0;
-	else
-		command2 = NAND_COMMAND_READ_FIN;
+	command2 = NAND_COMMAND_READ_FIN;
 
 	nand_address = __cvmx_nand_adjust_address(chip, nand_address);
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pcie.c b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
index 21ae773..2870cc2 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pcie.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium, Inc. <support@cavium.com>.  All rights
+ * Copyright (c) 2003-2014  Cavium, Inc. <support@cavium.com>.  All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 91009 $<hr>
+ * <hr>$Revision: 93891 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -1140,7 +1140,10 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	pemx_bist_status.u64 = cvmx_read_csr(CVMX_PEMX_BIST_STATUS(pcie_port));
 	if (pemx_bist_status.u64)
 		cvmx_dprintf("PCIe: BIST FAILED for port %d (0x%016llx)\n", pcie_port, CAST64(pemx_bist_status.u64));
-	pemx_bist_status2.u64 = cvmx_read_csr(CVMX_PEMX_BIST_STATUS2(pcie_port));
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		pemx_bist_status2.u64 = 0;
+	else
+		pemx_bist_status2.u64 = cvmx_read_csr(CVMX_PEMX_BIST_STATUS2(pcie_port));
 	/* Errata PCIE-14766 may cause the lower 6 bits to be randomly set on CN63XXp1 */
 	if (OCTEON_IS_MODEL(OCTEON_CN63XX_PASS1_X))
 		pemx_bist_status2.u64 &= ~0x3full;
@@ -1722,7 +1725,11 @@ void cvmx_pcie_wait_for_pending(int pcie_port)
  */
 int cvmx_pcie_is_host_mode(int pcie_port)
 {
-	if (OCTEON_IS_OCTEON3()) {
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		cvmx_pemx_strap_t strap;
+		strap.u64 = cvmx_read_csr(CVMX_PEMX_STRAP(pcie_port));
+		return (strap.cn78xx.pimode != 3);
+	} else if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
 		cvmx_rst_ctlx_t rst_ctl;
 		rst_ctl.u64 = cvmx_read_csr(CVMX_RST_CTLX(pcie_port));
 		return !!rst_ctl.s.host_mode;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
index 6a2b1ef..57a759b 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
@@ -60,162 +60,202 @@
 
 /**
  * This function allocates/reserves a style from pool of global styles per node.
- * @param node	 node to allocate style from.
- * @param style	 style to allocate, if -1 it will be allocated
-                 first available style from style resource. If index is positive
-		 number and in range, it will try to allocate specified style.
- * @return 	 style number on success, -1 on failure.
+ * @param node	node to allocate style from.
+ * @param style	style to allocate, if -1 it will be allocated
+ *		first available style from style resource. If index is positive
+ *		number and in range, it will try to allocate specified style.
+ * @return 	style number on success,
+ *		-1 on alloc failure.
+ *		-2 on resource already reserved.
  */
 int cvmx_pki_alloc_style(int node, int style)
 {
-	if(cvmx_create_global_resource_range(CVMX_GR_TAG_STYLE(node),CVMX_PKI_NUM_INTERNAL_STYLES)) {
+	if (cvmx_create_global_resource_range(CVMX_GR_TAG_STYLE(node), CVMX_PKI_NUM_INTERNAL_STYLES)) {
 		cvmx_dprintf("\nERROR: Failed to create styles global resource\n");
 		return -1;
 	}
-	if(style >= 0) {
-		style = cvmx_reserve_global_resource_range(CVMX_GR_TAG_STYLE(node), style, style,1);
-		if(style == -1){
-			cvmx_dprintf("\nERROR: Failed to reserve style %d\n", (int)style);
-			return -1;
+	if (style >= 0) {
+		style = cvmx_reserve_global_resource_range(CVMX_GR_TAG_STYLE(node), style, style, 1);
+		if (style == -1) {
+			cvmx_dprintf("\nINFO: style %d is already reserved\n", (int)style);
+			return CVMX_RESOURCE_ALREADY_RESERVED;
 		}
-	}
-	else {
-		style = cvmx_allocate_global_resource_range(CVMX_GR_TAG_STYLE(node), style, 1,1);
-		if(style == -1){
+	} else {
+		style = cvmx_allocate_global_resource_range(CVMX_GR_TAG_STYLE(node), style, 1, 1);
+		if (style == -1) {
 			cvmx_dprintf("ERROR: Failed to allocate style %d\n", (int)style);
-			//vinita, define enum later
-			return -1;
+			return CVMX_RESOURCE_ALLOC_FAILED;
 		}
 	}
 	return style;
 }
 
 /**
+ * This function frees a style from pool of global styles per node.
+ * @param node	 node to free style from.
+ * @param style	 style to free
+ * @return 	 0 on success, -1 on failure.
+ */
+int cvmx_pki_free_style(int node, int style)
+{
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_STYLE(node), style, 1) == -1) {
+		cvmx_dprintf("\nERROR Failed to release style %d", (int)style);
+		return -1;
+	}
+	return 0;
+}
+
+
+/**
  * This function allocates/reserves a cluster group from per node
    cluster group resources.
  * @param node	 	node to allocate cluster group from.
    @param cl_grp	cluster group to allocate/reserve, if -1 ,
-                        allocate any available cluster group.
- * @param num_clusters	number of clusters that will be attached to
-			the cluster group.
- * @param parsing_mask  mask of parsing that will be enabled on the cluster group.
- * @return 	 	cluster group number or -1 on failure
+ *			allocate any available cluster group.
+ * @return 	 	cluster group number
+ *			-1 on alloc failure.
+ *			-2 on resource already reserved.
  */
-int cvmx_pki_alloc_cluster_group(int node, int cl_grp, int num_clusters,
-				 uint64_t parsing_mask, uint64_t *cluster_mask)
+int cvmx_pki_alloc_cluster_group(int node, int cl_grp)
 {
-	int cluster = 0;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
+	if (node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d", node);
 		return -1;
 	}
-
-	if(cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTERS(node),CVMX_PKI_NUM_CLUSTERS)) {
-		cvmx_dprintf("Failed to create Clusters global resource\n");
-		return -1;
-	}
-	if(cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node),CVMX_PKI_NUM_CLUSTER_GROUP)) {
+	if (cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node), CVMX_PKI_NUM_CLUSTER_GROUP)) {
 		cvmx_dprintf("Failed to create Cluster group global resource\n");
 		return -1;
 	}
-
-	if( cl_grp >=0 )
-		cl_grp = cvmx_reserve_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node),0,cl_grp,1);
-
-	else {
-		cl_grp = cvmx_allocate_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node),0,1,1);
-
-		if(cl_grp == -1) {
-			cvmx_dprintf("Warning: Failed to alloc cluster grp %d\n", cl_grp);
-			return -1;
+	if (cl_grp >= 0) {
+		cl_grp = cvmx_reserve_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node), 0, cl_grp, 1);
+		if (cl_grp == -1) {
+			cvmx_dprintf("\nINFO: cl_grp %d is already reserved\n", (int)cl_grp);
+			return CVMX_RESOURCE_ALREADY_RESERVED;
 		}
 	}
-	if(cl_grp >= CVMX_PKI_NUM_CLUSTER_GROUP) {
-		cvmx_dprintf("ERROR: Invalid cluster group %d got allocated\n",cl_grp);
-		return -1;
-	}
-	if(cl_grp == -1) {
-		cvmx_dprintf("Warning: Failed to alloc cluster grp sharing the cluster grp\n");
-		//vinita cl_grp = cvmx_find_global_resource_range_owner(CVMX_GR_TAG_CLUSTER_GRP(node), num_clusters);
-		return -1; //vinita
-	}
 	else {
-		cluster = cvmx_allocate_global_resource_range(CVMX_GR_TAG_CLUSTERS(node),
-				cl_grp, num_clusters, 1);
-		if(cluster >= CVMX_PKI_NUM_CLUSTERS) {
-			cvmx_dprintf("ERROR: Invalid clusters %d got allocated\n", (int)cluster);
-			return -1;
-		}
-		if(cluster == -1) {
-			cvmx_dprintf("Warning: Failed to allocate clusters %d sharing the clusters \n", (int)num_clusters);
-			//vinita cl_grp = cvmx_find_global_resource_range_owner(CVMX_GR_TAG_CLUSTERS(node), num_clusters);
-			//to_do vinita cluster = cvmx_find_global_resource_owner_range(CVMX_GR_TAG_CLUSTERS(node), cl_grp);
-			return -1; //vinita
+		cl_grp = cvmx_allocate_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node), 0, 1, 1);
+		if (cl_grp == -1) {
+			cvmx_dprintf("Warning: Failed to alloc cluster grp %d\n", cl_grp);
+			return CVMX_RESOURCE_ALLOC_FAILED;
 		}
 	}
-	if(cl_grp == -1 || cluster == -1){
-			cvmx_dprintf("Failed to allocate Cluster group global resource\n");
-		return -1;
-	}
-	else {
-		*cluster_mask = cvmx_build_mask((uint64_t)((num_clusters-(uint64_t)cluster+1) << cluster));
-		return cl_grp;
-	}
+	return cl_grp;
 }
 
-int cvmx_pki_free_cluster_group(int node, int grp_index)
+/**
+ * This function frees a cluster group from per node
+   cluster group resources.
+ * @param node	 	node to free cluster group from.
+   @param cl_grp	cluster group to free
+ * @return 	 	0 on success
+ *			-1 on alloc failure.
+ *			-2 on resource already reserved.
+ */
+int cvmx_pki_free_cluster_group(int node, int cl_grp)
 {
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_CLUSTER_GRP(node), cl_grp, 1) == -1) {
+		cvmx_dprintf("\nERROR Failed to release cluster group %d", (int)cl_grp);
 		return -1;
 	}
+	return 0;
+}
+
+/**
+ * This function allocates/reserves a cluster from per node
+ * cluster resources.
+ * @param node	 	node to allocate cluster group from.
+ * @param cluster_mask	mask of clusters  to allocate/reserve, if -1 ,
+ *			allocate any available clusters.
+ * @param num_clusters	number of clusters that will be allocated
+ */
+int cvmx_pki_alloc_clusters(int node, int num_clusters, uint64_t *cluster_mask)
+{
+	int cluster = 0;
+	int clusters[CVMX_PKI_NUM_CLUSTERS];
 
-	//spinlock it
-	if (--pki_config[node].cluster_cfg[grp_index].users) {
-		cvmx_dprintf("ERROR: cluster group %d is in use, can't free it\n", (int)grp_index);
+	if (node >= CVMX_MAX_NODES) {
+		cvmx_dprintf("Invalid node number %d", node);
 		return -1;
 	}
-	if (grp_index >= CVMX_PKI_NUM_CLUSTER_GROUP) {
-		cvmx_dprintf("ERROR: Invalid cluster group %d in cvmx_pki_free_cluster_group\n", (int)grp_index);
+	if (cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTERS(node), CVMX_PKI_NUM_CLUSTERS)) {
+		cvmx_dprintf("Failed to create Clusters global resource\n");
 		return -1;
 	}
-	if (cvmx_free_global_resource_range_with_owner(CVMX_GR_TAG_CLUSTER_GRP(node), grp_index) == -1) {
-		cvmx_dprintf("ERROR Failed to release cluster group %d\n", (int)grp_index);
-		return -1;
+	if (*cluster_mask > 0) {
+		while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+			if (*cluster_mask & (0x01L << cluster)) {
+				if (cvmx_reserve_global_resource_range(CVMX_GR_TAG_CLUSTERS(node), 0, cluster, 1) == -1) {
+					cvmx_dprintf("ERROR: allocating cluster %d\n", cluster);
+					return -1;
+				}
+			}
+			cluster++;
+		}
+	} else {
+		if (cvmx_resource_alloc_many(CVMX_GR_TAG_CLUSTERS(node), 0, num_clusters, clusters) == -1) {
+			   cvmx_dprintf("ERROR: allocating clusters\n");
+			   return -1;
+		}
+		*cluster_mask = 0;
+		while (num_clusters--)
+			*cluster_mask |= (0x1ul << clusters[num_clusters]);
+	}
+	return 0;
+}
+
+/**
+ * This function frees  clusters  from per node
+   clusters resources.
+ * @param node	 	node to free clusters from.
+ * @param cluster_mask  mask of clusters need freeing
+ * @return 	 	0 on success or -1 on failure
+ */
+int cvmx_pki_free_clusters(int node, uint64_t cluster_mask)
+{
+	int cluster = 0;
+	if (cluster_mask > 0) {
+		while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+			if (cluster_mask & (0x01L << cluster)) {
+				if (cvmx_free_global_resource_range_with_base(
+						CVMX_GR_TAG_CLUSTERS(node), cluster, 1) == -1) {
+					cvmx_dprintf("ERROR: freeing cluster %d\n", cluster);
+					return -1;
+				}
+			}
+			cluster++;
+		}
 	}
-	//spinlock it
-	pki_config[node].cluster_cfg[grp_index].users--;
 	return 0;
 }
 
 /**
  * This function allocates/reserves a pcam entry from node
  * @param node	 	node to allocate pcam entry from.
-   @param index  	index of pacm entry (0-191), if -1 ,
-                        allocate any available pcam entry.
+ * @param index  	index of pacm entry (0-191), if -1 ,
+ *			allocate any available pcam entry.
  * @param bank		pcam bank where to allocate/reserve pcan entry from
  * @param cluster_mask  mask of clusters from which pcam entry is needed.
  * @return 	 	pcam entry of -1 on failure
  */
 int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_mask)
 {
-	uint64_t cluster=0;
+	uint64_t cluster = 0;
 
-	while( cluster < CVMX_PKI_NUM_CLUSTERS) {
-		if(cluster_mask & (0x01L << cluster)) {
-			if (cvmx_create_global_resource_range(CVMX_GR_TAG_PCAM(node,cluster,bank),
-			    	CVMX_PKI_TOTAL_PCAM_ENTRY)) {
+	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if (cluster_mask & (0x01L << cluster)) {
+			if (cvmx_create_global_resource_range(CVMX_GR_TAG_PCAM(node, cluster, bank),
+				CVMX_PKI_TOTAL_PCAM_ENTRY)) {
 				cvmx_dprintf("\nFailed to create pki pcam global resource");
 				return -1;
 			}
 			if (index >= 0)
-				index = cvmx_reserve_global_resource_range(CVMX_GR_TAG_PCAM(node,cluster,bank),
+				index = cvmx_reserve_global_resource_range(CVMX_GR_TAG_PCAM(node, cluster, bank),
 						cluster, index, 1);
 			else
-				index = cvmx_allocate_global_resource_range(CVMX_GR_TAG_PCAM(node,cluster,bank),
+				index = cvmx_allocate_global_resource_range(CVMX_GR_TAG_PCAM(node, cluster, bank),
 						cluster, 1, 1);
-			if(index == -1) {
+			if (index == -1) {
 				cvmx_dprintf("Error:index %d not available in cluster %d bank %d",
 						(int)index, (int)cluster, bank);
 				return -1;
@@ -223,39 +263,67 @@ int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_ma
 			cluster++;
 		}
 	}
-	//vinita to_do , implement cluster handle, for now assume
-	//all clusters will have same base index
+	/*vinita to_do , implement cluster handle, for now assume
+	all clusters will have same base index*/
 	return index;
 }
 
 /**
+ * This function frees a pcam entry from node
+ * @param node	 	node to allocate pcam entry from.
+   @param index  	index of pacm entry (0-191) needs to be freed.
+ * @param bank		pcam bank where to free pcam entry from
+ * @param cluster_mask  mask of clusters from which pcam entry is freed.
+ * @return 	 	0 on success OR -1 on failure
+ */
+int cvmx_pki_pcam_free_entry(int node, int index, int bank, uint64_t cluster_mask)
+{
+	uint64_t cluster = 0;
+
+	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if (cluster_mask & (0x01L << cluster)) {
+			if (cvmx_free_global_resource_range_with_base (
+						CVMX_GR_TAG_PCAM(node, cluster, bank), index, 1) == -1) {
+				cvmx_dprintf("ERROR: freeing cluster %d\n", (int)cluster);
+				return -1;
+			}
+			cluster++;
+		}
+	}
+	return 0;
+}
+
+
+/**
  * This function allocates/reserves QPG table entries per node.
  * @param node	 	node number.
  * @param base_offset	base_offset in qpg table. If -1, first available
-			qpg base_offset will be allocated. If base_offset is positive
-		 	number and in range, it will try to allocate specified base_offset.
-   @param count		number of consecutive qpg entries to allocate. They will be consecutive
-                        from base offset.
- * @return 	 	qpg table base offset number on success, -1 on failure.
+ *			qpg base_offset will be allocated. If base_offset is positive
+ *		 	number and in range, it will try to allocate specified base_offset.
+ * @param count		number of consecutive qpg entries to allocate. They will be consecutive
+ *                       from base offset.
+ * @return 	 	qpg table base offset number on success
+ *			-1 on alloc failure.
+ *			-2 on resource already reserved.
  */
-int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count )
+int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count)
 {
-	if(cvmx_create_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node),CVMX_PKI_NUM_QPG_ENTRY)) {
+	if (cvmx_create_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), CVMX_PKI_NUM_QPG_ENTRY)) {
 		cvmx_dprintf("\nERROR: Failed to create qpg_entry global resource\n");
 		return -1;
 	}
-	if(base_offset >= 0) {
-		base_offset = cvmx_reserve_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), base_offset, base_offset,count);
-		if(base_offset == -1){
-			cvmx_dprintf("\nERROR: Failed to reserve qpg entry %d\n", (int)base_offset);
-			return -1;
+	if (base_offset >= 0) {
+		base_offset = cvmx_reserve_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node),
+				base_offset, base_offset, count);
+		if (base_offset == -1) {
+			cvmx_dprintf("\nINFO: qpg entry %d is already reserved\n", (int)base_offset);
+			return CVMX_RESOURCE_ALREADY_RESERVED;
 		}
-	}
-	else {
-		base_offset = cvmx_allocate_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), base_offset, count,1);
-		if(base_offset == -1){
+	} else {
+		base_offset = cvmx_allocate_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), base_offset, count, 1);
+		if (base_offset == -1) {
 			cvmx_dprintf("ERROR: Failed to allocate qpg entry %d\n", (int)base_offset);
-			return -1;
+			return CVMX_RESOURCE_ALLOC_FAILED;
 		}
 	}
 	return base_offset;
@@ -265,14 +333,14 @@ int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count )
  * This function frees QPG table entries per node.
  * @param node	 	node number.
  * @param base_offset	base_offset in qpg table. If -1, first available
-			qpg base_offset will be allocated. If base_offset is positive
-		 	number and in range, it will try to allocate specified base_offset.
-   @param count		number of consecutive qpg entries to allocate. They will be consecutive
-                        from base offset.
+ *			qpg base_offset will be allocated. If base_offset is positive
+ *		 	number and in range, it will try to allocate specified base_offset.
+ * @param count		number of consecutive qpg entries to allocate. They will be consecutive
+ *			from base offset.
  * @return 	 	qpg table base offset number on success, -1 on failure.
  */
-int cvmx_pki_free_qpg_entry(int node, int base_offset, int count )
+int cvmx_pki_free_qpg_entry(int node, int base_offset, int count)
 {
 	return 0;
-	//vinita_to_do
+	/*vinita_to_do*/
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki.c b/arch/mips/cavium-octeon/executive/cvmx-pki.c
index bda29bd..b636b31 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki.c
@@ -61,12 +61,10 @@
 #include "cvmx-pki-cluster.h"
 #endif
 
-CVMX_SHARED struct cvmx_pki_config pki_config[CVMX_MAX_NODES];
-CVMX_SHARED struct cvmx_pki_profiles pki_profiles[CVMX_MAX_NODES];
 
 /**
  * This function enables pki
- * @param node	 	node to enable pki in.
+ * @param node	node to enable pki in.
  */
 void cvmx_pki_enable(int node)
 {
@@ -74,10 +72,10 @@ void cvmx_pki_enable(int node)
 	cvmx_pki_sft_rst_t pki_sft_rst;
 	cvmx_pki_buf_ctl_t pki_en;
 
-	pki_sft_rst.u64 = cvmx_read_csr_node(node,CVMX_PKI_SFT_RST);
+	pki_sft_rst.u64 = cvmx_read_csr_node(node, CVMX_PKI_SFT_RST);
 
 	while (pki_sft_rst.s.busy != 0)
-		pki_sft_rst.u64 = cvmx_read_csr_node(node,CVMX_PKI_SFT_RST);
+		pki_sft_rst.u64 = cvmx_read_csr_node(node, CVMX_PKI_SFT_RST);
 
 	pki_en.u64 = cvmx_read_csr_node(node, CVMX_PKI_BUF_CTL);
 	if (pki_en.s.pki_en)
@@ -85,14 +83,14 @@ void cvmx_pki_enable(int node)
 
 	pki_en.s.pki_en = 1;
 
-	cvmx_write_csr_node(node,CVMX_PKI_BUF_CTL, pki_en.u64);
+	cvmx_write_csr_node(node, CVMX_PKI_BUF_CTL, pki_en.u64);
 
 }
 EXPORT_SYMBOL(cvmx_pki_enable);
 
 /**
  * This function disables pki
- * @param node	 	node to disable pki in.
+ * @param node	node to disable pki in.
  */
 void cvmx_pki_disable(int node)
 {
@@ -105,14 +103,33 @@ void cvmx_pki_disable(int node)
 EXPORT_SYMBOL(cvmx_pki_disable);
 
 /**
+ * This function soft resets pki
+ * @param node	node to enable pki in.
+ */
+void cvmx_pki_reset(int node)
+{
+	cvmx_pki_sft_rst_t pki_sft_rst;
+
+	pki_sft_rst.u64 = cvmx_read_csr_node(node, CVMX_PKI_SFT_RST);
+
+	while (pki_sft_rst.s.active != 0)
+		pki_sft_rst.u64 = cvmx_read_csr_node(node, CVMX_PKI_SFT_RST);
+	pki_sft_rst.s.rst = 1;
+	cvmx_write_csr_node(node, CVMX_PKI_SFT_RST, pki_sft_rst.u64);
+	while (pki_sft_rst.s.busy != 0)
+		pki_sft_rst.u64 = cvmx_read_csr_node(node, CVMX_PKI_SFT_RST);
+}
+
+/**
  * This function sets the clusters in PKI
- * @param node	 	node to set clusters in.
+ * @param node	node to set clusters in.
  */
 int cvmx_pki_setup_clusters(int node)
 {
 	int i;
-	for(i=0; i< cvmx_pki_cluster_code_length; i++)
-		cvmx_write_csr_node(node, CVMX_PKI_IMEMX(i),cvmx_pki_cluster_code_default[i]);
+
+	for (i = 0; i < cvmx_pki_cluster_code_length; i++)
+		cvmx_write_csr_node(node, CVMX_PKI_IMEMX(i), cvmx_pki_cluster_code_default[i]);
 
 	return 0;
 }
@@ -123,110 +140,150 @@ int cvmx_pki_setup_clusters(int node)
  * all FPA buffers out of the PKI. After this function
  * completes, all FPA buffers that were prefetched by PKI
  * wil be in the apropriate FPA pool. This functions does not reset
- * PKI as FPA pool zero must be empty before the reset can
- * be performed. WARNING: It is very important that PKI be
+ * PKI.
+ * WARNING: It is very important that PKI be
  * reset soon after a call to this function.
- *IT IS STILL TBD IN 78XX_HRM., INPLEMENT ONCE DEFINED
  */
-void __cvmx_pki_free_ptr(void)
+void __cvmx_pki_free_ptr(int node)
 {
-	/*TBD, IMPLEMENT ONCE DEFINED IN HRM*/
+	cvmx_pki_buf_ctl_t buf_ctl;
+	buf_ctl.u64 = cvmx_read_csr_node(node, CVMX_PKI_BUF_CTL);
+	/*Disable buffering any data*/
+	buf_ctl.s.pkt_off = 1;
+	/*diable caching of any data and return all the prefetched buffers to fpa*/
+	buf_ctl.s.fpa_cac_dis = 1;
+	cvmx_write_csr_node(node, CVMX_PKI_BUF_CTL, buf_ctl.u64);
 }
 
-/**
- * This function writes max and min frame lengths to hardware which can be used
- * to check the size of frame arrived.There are 2 possible combination which are
- * indicated by id field.
- * @param node	 	      node number.
- * @param id		      choose which frame len register to write to
- * @param maxframesize        Byte count for max-sized frame check.
- * @param minframesize        Byte count for min-sized frame check.
- *
- */
-int cvmx_pki_write_frame_len(int node, int id, int maxframesize, int minframesize)
+void cvmx_pki_write_global_cfg(int node, struct cvmx_pki_global_config *gbl_cfg)
 {
-	cvmx_pki_frm_len_chkx_t frame_len_chk;
-
-	if(maxframesize > CVMX_PKI_MAX_FRAME_SIZE ||
-		  minframesize > CVMX_PKI_MAX_FRAME_SIZE){
-		cvmx_dprintf("ERROR: invalid frame size maxframe =%d minframe=%d\n",
-			     maxframesize, minframesize);
-		return -1;
-	}
-	if(id >= CVMX_PKI_NUM_FRAME_SIZE_ID) {
-		cvmx_dprintf("ERROR: invalid id %d in write frame len",id);
-		return -1;	;
-	}
-	frame_len_chk.u64 = cvmx_read_csr_node(node, CVMX_PKI_FRM_LEN_CHKX(id));
-	frame_len_chk.s.maxlen = maxframesize;
-	frame_len_chk.s.minlen = minframesize;
-	cvmx_write_csr_node(node, CVMX_PKI_FRM_LEN_CHKX(id),frame_len_chk.u64);
+	int cl_grp;
 
-	return 0;
+	for (cl_grp = 0; cl_grp < CVMX_PKI_NUM_CLUSTER_GROUP; cl_grp++)
+		cvmx_pki_attach_cluster_to_group(node, cl_grp, gbl_cfg->cluster_mask[cl_grp]);
+	cvmx_pki_write_stats_mode(node, gbl_cfg->stat_mode);
+	cvmx_pki_write_global_parse(node, gbl_cfg->gbl_pen);
+	cvmx_pki_write_tag_secret(node, gbl_cfg->tag_secret);
+	cvmx_pki_write_frame_len(node, 0, gbl_cfg->frm_len[0]);
+	cvmx_pki_write_frame_len(node, 1, gbl_cfg->frm_len[1]);
+	/* vinita_to_do remaining parameters */
 }
 
-
 /**
  * This function writes per pkind parameters in hardware which defines how
   the incoming packet is processed.
- * @param node	 	      node number.
+ * @param node		      node number.
  * @param pkind               PKI supports a large number of incoming interfaces
  *                            and packets arriving on different interfaces or channels
  *                            may want to be processed differently. PKI uses the pkind to
  *                            determine how the incoming packet is processed.
- * @param cluster_group       Which cluster group to use. Application would choose the cluster
- *                            group depending on number of clusters it want to use for that pkind.
- * @param initial_parse_mode  Which initial parsing stage is expected.
- * @param initial_style       Which initial style to assign to this pkind. Style also go as one of
- *                            the inputs to match in the pcam table. If no match is found this initial
- *                            style will be the final style.
+ * @param pkind_cfg	      struct conatining pkind configuration need to be written to hw
  */
-int cvmx_pki_write_pkind(int node, int pkind, int cluster_group,
-				     int initial_parse_mode, int initial_style )
+int cvmx_pki_write_pkind(int node, int pkind, struct cvmx_pki_pkind_config *pkind_cfg)
 {
+	int cluster = 0;
 	uint64_t cluster_mask;
-	int cluster=0;
+
 	cvmx_pki_pkindx_icgsel_t pkind_clsel;
 	cvmx_pki_clx_pkindx_style_t pkind_cfg_style;
 	cvmx_pki_icgx_cfg_t pki_cl_grp;
+	cvmx_pki_clx_pkindx_cfg_t pknd_cfg_reg;
 
 
-	if(pkind >= CVMX_PKI_NUM_PKIND || cluster_group >= CVMX_PKI_NUM_CLUSTER_GROUP
-		  || initial_style >= CVMX_PKI_NUM_FINAL_STYLES) {
+	if (pkind >= CVMX_PKI_NUM_PKIND || pkind_cfg->cluster_grp >= CVMX_PKI_NUM_CLUSTER_GROUP
+		  || pkind_cfg->initial_style >= CVMX_PKI_NUM_FINAL_STYLES) {
 		cvmx_dprintf("ERROR: Configuring PKIND pkind = %d cluster_group = %d style = %d",
-			     pkind, cluster_group, initial_style);
+			     pkind, pkind_cfg->cluster_grp, pkind_cfg->initial_style);
 		return -1;
 	}
-	pkind_clsel.u64 = cvmx_read_csr_node(node,CVMX_PKI_PKINDX_ICGSEL(pkind));
-	pkind_clsel.s.icg = cluster_group;
-	cvmx_write_csr_node(node,CVMX_PKI_PKINDX_ICGSEL(pkind), pkind_clsel.u64);
+	pkind_clsel.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKINDX_ICGSEL(pkind));
+	pkind_clsel.s.icg = pkind_cfg->cluster_grp;
+	cvmx_write_csr_node(node, CVMX_PKI_PKINDX_ICGSEL(pkind), pkind_clsel.u64);
 
-	pki_cl_grp.u64 = cvmx_read_csr_node(node,CVMX_PKI_ICGX_CFG(cluster_group));
+	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(pkind_cfg->cluster_grp));
 	cluster_mask = (uint64_t)pki_cl_grp.s.clusters;
-
-	while( cluster < CVMX_PKI_NUM_CLUSTERS) {
-		if(cluster_mask & (0x01L << cluster)) {
+	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if (cluster_mask & (0x01L << cluster)) {
 			pkind_cfg_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(pkind, cluster));
-			pkind_cfg_style.s.pm = initial_parse_mode;
-			pkind_cfg_style.s.style = initial_style;
+			pkind_cfg_style.s.pm = pkind_cfg->initial_parse_mode;
+			pkind_cfg_style.s.style = pkind_cfg->initial_style;
 			cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(pkind, cluster), pkind_cfg_style.u64);
 		}
 		cluster++;
 	}
-	cvmx_pki_mark_style_in_use(node,initial_style);
+
+	pknd_cfg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pkind, cluster));
+	pknd_cfg_reg.s.fcs_pres = pkind_cfg->fcs_pres;
+	pknd_cfg_reg.s.inst_hdr = pkind_cfg->parse_en.inst_hdr;
+	pknd_cfg_reg.s.mpls_en = pkind_cfg->parse_en.mpls_en;
+	pknd_cfg_reg.s.lg_custom = pkind_cfg->parse_en.lg_custom;
+	pknd_cfg_reg.s.fulc_en = pkind_cfg->parse_en.fulc_en;
+	pknd_cfg_reg.s.dsa_en = pkind_cfg->parse_en.dsa_en;
+	pknd_cfg_reg.s.hg2_en = pkind_cfg->parse_en.hg2_en;
+	pknd_cfg_reg.s.hg_en = pkind_cfg->parse_en.hg_en;
+	cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pkind, cluster), pknd_cfg_reg.u64);
+
 	return 0;
+}
 
+/**
+ * This function writes/configures parameters associated with tag configuration in hardware.
+ * @param node	              node number.
+ * @param style		      style to configure tag for
+ * @param cluster_mask	      Mask of clusters to configure the style for.
+ * @param tag_cfg	      pointer to taf configuration struct.
+ */
+void cvmx_pki_write_tag_config(int node, int style, uint64_t cluster_mask,
+			       struct cvmx_pki_style_tag_cfg *tag_cfg)
+{
+	cvmx_pki_clx_stylex_cfg2_t style_cfg2_reg;
+	cvmx_pki_clx_stylex_alg_t style_alg_reg;
+	int cluster = 0;
+
+	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if (cluster_mask & (0x01L << cluster)) {
+			style_cfg2_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster));
+			style_cfg2_reg.s.tag_src_lg = tag_cfg->tag_fields.layer_g_src;
+			style_cfg2_reg.s.tag_src_lf = tag_cfg->tag_fields.layer_f_src;
+			style_cfg2_reg.s.tag_src_le = tag_cfg->tag_fields.layer_e_src;
+			style_cfg2_reg.s.tag_src_ld = tag_cfg->tag_fields.layer_d_src;
+			style_cfg2_reg.s.tag_src_lc = tag_cfg->tag_fields.layer_c_src;
+			style_cfg2_reg.s.tag_src_lb = tag_cfg->tag_fields.layer_b_src;
+			style_cfg2_reg.s.tag_dst_lg = tag_cfg->tag_fields.layer_g_dst;
+			style_cfg2_reg.s.tag_dst_lf = tag_cfg->tag_fields.layer_f_dst;
+			style_cfg2_reg.s.tag_dst_le = tag_cfg->tag_fields.layer_e_dst;
+			style_cfg2_reg.s.tag_dst_ld = tag_cfg->tag_fields.layer_d_dst;
+			style_cfg2_reg.s.tag_dst_lc = tag_cfg->tag_fields.layer_c_dst;
+			style_cfg2_reg.s.tag_dst_lb = tag_cfg->tag_fields.layer_b_dst;
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster), style_cfg2_reg.u64);
+			style_alg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(style, cluster));
+			style_alg_reg.s.tag_vni = tag_cfg->tag_fields.tag_vni;
+			style_alg_reg.s.tag_gtp = tag_cfg->tag_fields.tag_gtp;
+			style_alg_reg.s.tag_spi = tag_cfg->tag_fields.tag_spi;
+			style_alg_reg.s.tag_syn = tag_cfg->tag_fields.tag_sync;
+			style_alg_reg.s.tag_pctl = tag_cfg->tag_fields.ip_prot_nexthdr;
+			style_alg_reg.s.tag_vs1 = tag_cfg->tag_fields.second_vlan;
+			style_alg_reg.s.tag_vs0 = tag_cfg->tag_fields.first_vlan;
+			style_alg_reg.s.tag_mpls0 = tag_cfg->tag_fields.mpls_label;
+			style_alg_reg.s.tag_prt = tag_cfg->tag_fields.input_port;
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(style, cluster), style_alg_reg.u64);
+
+			/* vinita_to_do add mask tag */
+		}
+		cluster++;
+	}
 }
 
+
 /**
  * This function writes/configures parameters associated with style in hardware.
  * @param node	              node number.
  * @param style		      style to configure.
  * @param cluster_mask	      Mask of clusters to configure the style for.
- * @param style_cfg 	      parameters to configure for style passed in struct.
+ * @param style_cfg	      pointer to style config struct.
  */
 void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
-			    struct cvmx_pki_style_config style_cfg)
+			    struct cvmx_pki_style_config *style_cfg)
 {
 	cvmx_pki_clx_stylex_cfg_t style_cfg_reg;
 	cvmx_pki_clx_stylex_cfg2_t style_cfg2_reg;
@@ -234,64 +291,256 @@ void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
 	cvmx_pki_stylex_buf_t     style_buf_reg;
 	int cluster = 0;
 
-	//vinita to_do break it differnt functions
-	while( cluster < CVMX_PKI_NUM_CLUSTERS) {
-		if(cluster_mask & (0x01L << cluster)) {
+	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if (cluster_mask & (0x01L << cluster)) {
 			style_cfg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster));
+			style_cfg_reg.s.ip6_udp_opt = style_cfg->parm_cfg.ip6_udp_opt;
+			style_cfg_reg.s.lenerr_en = style_cfg->parm_cfg.lenerr_en;
+			style_cfg_reg.s.lenerr_eqpad = style_cfg->parm_cfg.lenerr_eqpad;
+			style_cfg_reg.s.maxerr_en = style_cfg->parm_cfg.maxerr_en;
+			style_cfg_reg.s.minerr_en = style_cfg->parm_cfg.minerr_en;
+			style_cfg_reg.s.fcs_chk = style_cfg->parm_cfg.fcs_chk;
+			style_cfg_reg.s.fcs_strip = style_cfg->parm_cfg.fcs_strip;
+			style_cfg_reg.s.minmax_sel = style_cfg->parm_cfg.minmax_sel;
+			style_cfg_reg.s.qpg_base = style_cfg->parm_cfg.qpg_base;
+			style_cfg_reg.s.qpg_dis_padd = style_cfg->parm_cfg.qpg_dis_padd;
+			style_cfg_reg.s.qpg_dis_aura = style_cfg->parm_cfg.qpg_dis_aura;
+			style_cfg_reg.s.qpg_dis_grp = style_cfg->parm_cfg.qpg_dis_grp;
+			style_cfg_reg.s.qpg_dis_grptag = style_cfg->parm_cfg.qpg_dis_grptag;
+			style_cfg_reg.s.rawdrp = style_cfg->parm_cfg.rawdrp;
+			style_cfg_reg.s.drop = style_cfg->parm_cfg.force_drop;
+			style_cfg_reg.s.nodrop = style_cfg->parm_cfg.nodrop;
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster), style_cfg_reg.u64);
 
-			//style_cfg_reg.s.lenerr_en = style_cfg.en_l2_lenchk;
-			//style_cfg_reg.s.lenerr_eqpad = style_cfg.l2_lenchk_mode;
-			//style_cfg_reg.s.maxerr_en = style_cfg.en_maxframe_errchk;
-			//style_cfg_reg.s.minerr_en = style_cfg.en_minframe_errchk;
-			//style_cfg_reg.s.fcs_chk = style_cfg.en_FCS_chk;
-			//style_cfg_reg.s.strip_FCS = style_cfg.strip_l2_FCS;
-			//style_cfg_reg.s.minmax_sel = style_cfg.max_min_frame_sel;
-			style_cfg_reg.s.qpg_base = style_cfg.qpg_base_offset;
-			style_cfg_reg.s.qpg_dis_padd = style_cfg.qpg_calc_port_addr;
-			style_cfg_reg.s.qpg_dis_aura = style_cfg.qpg_calc_aura;
-			style_cfg_reg.s.qpg_dis_grp = style_cfg.qpg_calc_group;
-			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster),style_cfg_reg.u64);
+			style_cfg2_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster));
+			style_cfg2_reg.s.len_lg = style_cfg->parm_cfg.len_lg;
+			style_cfg2_reg.s.len_lf = style_cfg->parm_cfg.len_lf;
+			style_cfg2_reg.s.len_le = style_cfg->parm_cfg.len_le;
+			style_cfg2_reg.s.len_ld = style_cfg->parm_cfg.len_ld;
+			style_cfg2_reg.s.len_lc = style_cfg->parm_cfg.len_lc;
+			style_cfg2_reg.s.len_lb = style_cfg->parm_cfg.len_lb;
+			style_cfg2_reg.s.csum_lg = style_cfg->parm_cfg.csum_lg;
+			style_cfg2_reg.s.csum_lf = style_cfg->parm_cfg.csum_lf;
+			style_cfg2_reg.s.csum_le = style_cfg->parm_cfg.csum_le;
+			style_cfg2_reg.s.csum_ld = style_cfg->parm_cfg.csum_ld;
+			style_cfg2_reg.s.csum_lc = style_cfg->parm_cfg.csum_lc;
+			style_cfg2_reg.s.csum_lb = style_cfg->parm_cfg.csum_lb;
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster), style_cfg2_reg.u64);
 
 			style_alg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(style, cluster));
-
-			style_alg_reg.s.qpg_qos = style_cfg.qpg_qos;
-			style_alg_reg.s.tag_vni = style_cfg.tag_fields.tag_vni;
-			style_alg_reg.s.tag_gtp = style_cfg.tag_fields.tag_gtp;
-			style_alg_reg.s.tag_spi = style_cfg.tag_fields.tag_spi;
-			style_alg_reg.s.tag_syn = style_cfg.tag_fields.tag_sync;
-			style_alg_reg.s.tag_pctl = style_cfg.tag_fields.ip_prot_nexthdr;
-			style_alg_reg.s.tag_vs1 = style_cfg.tag_fields.second_vlan;
-			style_alg_reg.s.tag_vs0 = style_cfg.tag_fields.first_vlan;
-			style_alg_reg.s.tag_mpls0 = style_cfg.tag_fields.mpls_label;
-			style_alg_reg.s.tag_prt = style_cfg.tag_fields.input_port;
-			style_alg_reg.s.tt = style_cfg.tag_type;
+			style_alg_reg.s.qpg_qos = style_cfg->parm_cfg.qpg_qos;
+			style_alg_reg.s.tt = style_cfg->parm_cfg.tag_type;
+			style_alg_reg.s.apad_nip = style_cfg->parm_cfg.apad_nip;
+			style_alg_reg.s.qpg_port_sh = style_cfg->parm_cfg.qpg_port_sh;
+			style_alg_reg.s.qpg_port_msb = style_cfg->parm_cfg.qpg_port_msb;
+			style_alg_reg.s.wqe_vs = style_cfg->parm_cfg.wqe_vs;
 			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(style, cluster), style_alg_reg.u64);
 
-			style_cfg2_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster));
-			style_cfg2_reg.s.tag_src_lg = style_cfg.tag_fields.layer_G_src;
-			style_cfg2_reg.s.tag_src_lf = style_cfg.tag_fields.layer_F_src;
-			style_cfg2_reg.s.tag_src_le = style_cfg.tag_fields.layer_E_src;
-			style_cfg2_reg.s.tag_src_ld = style_cfg.tag_fields.layer_D_src;
-			style_cfg2_reg.s.tag_src_lc = style_cfg.tag_fields.layer_C_src;
-			style_cfg2_reg.s.tag_src_lb = style_cfg.tag_fields.layer_B_src;
-			style_cfg2_reg.s.tag_dst_lg = style_cfg.tag_fields.layer_G_dst;
-			style_cfg2_reg.s.tag_dst_lf = style_cfg.tag_fields.layer_F_dst;
-			style_cfg2_reg.s.tag_dst_le = style_cfg.tag_fields.layer_E_dst;
-			style_cfg2_reg.s.tag_dst_ld = style_cfg.tag_fields.layer_D_dst;
-			style_cfg2_reg.s.tag_dst_lc = style_cfg.tag_fields.layer_C_dst;
-			style_cfg2_reg.s.tag_dst_lb = style_cfg.tag_fields.layer_B_dst;
-			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster), style_cfg2_reg.u64);
-
+			cvmx_pki_write_tag_config(node, style, cluster_mask, &style_cfg->tag_cfg);
 		}
 		cluster++;
 	}
 	style_buf_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_STYLEX_BUF(style));
-	style_buf_reg.s.first_skip = (style_cfg.first_mbuf_skip)/8;
-	style_buf_reg.s.later_skip = style_cfg.later_mbuf_skip/8;
-	style_buf_reg.s.opc_mode = style_cfg.cache_mode;
-	style_buf_reg.s.mb_size = (style_cfg.mbuff_size)/8;
-	style_buf_reg.s.dis_wq_dat = 0;
-	cvmx_write_csr_node(node,CVMX_PKI_STYLEX_BUF(style), style_buf_reg.u64);
+	style_buf_reg.s.pkt_lend = style_cfg->parm_cfg.pkt_lend;
+	style_buf_reg.s.wqe_hsz = style_cfg->parm_cfg.wqe_hsz;
+	style_buf_reg.s.wqe_skip = (style_cfg->parm_cfg.wqe_skip)/128;
+	style_buf_reg.s.first_skip = (style_cfg->parm_cfg.first_skip)/8;
+	style_buf_reg.s.later_skip = style_cfg->parm_cfg.later_skip/8;
+	style_buf_reg.s.opc_mode = style_cfg->parm_cfg.cache_mode;
+	style_buf_reg.s.mb_size = (style_cfg->parm_cfg.mbuff_size)/8;
+	style_buf_reg.s.dis_wq_dat = style_cfg->parm_cfg.dis_wq_dat;
+	cvmx_write_csr_node(node, CVMX_PKI_STYLEX_BUF(style), style_buf_reg.u64);
+}
+
+
+void cvmx_pki_get_tag_config(int node, int style, uint64_t cluster_mask,
+			       struct cvmx_pki_style_tag_cfg *tag_cfg)
+{
+	cvmx_pki_clx_stylex_cfg2_t style_cfg2_reg;
+	cvmx_pki_clx_stylex_alg_t style_alg_reg;
+	int cluster = __builtin_ffsll(cluster_mask) - 1;
+
+	style_cfg2_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster));
+	style_alg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(style, cluster));
+
+	tag_cfg->tag_fields.layer_g_src = style_cfg2_reg.s.tag_src_lg;
+	tag_cfg->tag_fields.layer_f_src = style_cfg2_reg.s.tag_src_lf;
+	tag_cfg->tag_fields.layer_e_src = style_cfg2_reg.s.tag_src_le;
+	tag_cfg->tag_fields.layer_d_src = style_cfg2_reg.s.tag_src_ld;
+	tag_cfg->tag_fields.layer_c_src = style_cfg2_reg.s.tag_src_lc;
+	tag_cfg->tag_fields.layer_b_src = style_cfg2_reg.s.tag_src_lb;
+	tag_cfg->tag_fields.layer_g_dst = style_cfg2_reg.s.tag_dst_lg;
+	tag_cfg->tag_fields.layer_f_dst = style_cfg2_reg.s.tag_dst_lf;
+	tag_cfg->tag_fields.layer_e_dst = style_cfg2_reg.s.tag_dst_le;
+	tag_cfg->tag_fields.layer_d_dst = style_cfg2_reg.s.tag_dst_ld;
+	tag_cfg->tag_fields.layer_c_dst = style_cfg2_reg.s.tag_dst_lc;
+	tag_cfg->tag_fields.layer_b_dst = style_cfg2_reg.s.tag_dst_lb;
+	tag_cfg->tag_fields.tag_vni = style_alg_reg.s.tag_vni;
+	tag_cfg->tag_fields.tag_gtp = style_alg_reg.s.tag_gtp;
+	tag_cfg->tag_fields.tag_spi = style_alg_reg.s.tag_spi;
+	tag_cfg->tag_fields.tag_sync = style_alg_reg.s.tag_syn;
+	tag_cfg->tag_fields.ip_prot_nexthdr = style_alg_reg.s.tag_pctl;
+	tag_cfg->tag_fields.second_vlan = style_alg_reg.s.tag_vs1;
+	tag_cfg->tag_fields.first_vlan = style_alg_reg.s.tag_vs0;
+	tag_cfg->tag_fields.mpls_label = style_alg_reg.s.tag_mpls0;
+	tag_cfg->tag_fields.input_port = style_alg_reg.s.tag_prt;
+
+	/** vinita_to_do get mask tag*/
+}
+
+
+void cvmx_pki_get_style_config(int node, int style, uint64_t cluster_mask,
+			       struct cvmx_pki_style_config *style_cfg)
+{
+	cvmx_pki_clx_stylex_cfg_t style_cfg_reg;
+	cvmx_pki_clx_stylex_cfg2_t style_cfg2_reg;
+	cvmx_pki_clx_stylex_alg_t style_alg_reg;
+	cvmx_pki_stylex_buf_t     style_buf_reg;
+	int cluster = __builtin_ffsll(cluster_mask) - 1;
+
+	style_cfg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster));
+	style_cfg2_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster));
+	style_alg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(style, cluster));
+	style_buf_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster));
+
+	style_cfg->parm_cfg.ip6_udp_opt = style_cfg_reg.s.ip6_udp_opt;
+	style_cfg->parm_cfg.lenerr_en = style_cfg_reg.s.lenerr_en;
+	style_cfg->parm_cfg.lenerr_eqpad = style_cfg_reg.s.lenerr_eqpad;
+	style_cfg->parm_cfg.maxerr_en = style_cfg_reg.s.maxerr_en;
+	style_cfg->parm_cfg.minerr_en = style_cfg_reg.s.minerr_en;
+	style_cfg->parm_cfg.fcs_chk = style_cfg_reg.s.fcs_chk;
+	style_cfg->parm_cfg.fcs_strip = style_cfg_reg.s.fcs_strip;
+	style_cfg->parm_cfg.minmax_sel = style_cfg_reg.s.minmax_sel;
+	style_cfg->parm_cfg.qpg_base = style_cfg_reg.s.qpg_base;
+	style_cfg->parm_cfg.qpg_dis_padd = style_cfg_reg.s.qpg_dis_padd;
+	style_cfg->parm_cfg.qpg_dis_aura = style_cfg_reg.s.qpg_dis_aura;
+	style_cfg->parm_cfg.qpg_dis_grp = style_cfg_reg.s.qpg_dis_grp;
+	style_cfg->parm_cfg.qpg_dis_grptag = style_cfg_reg.s.qpg_dis_grptag;
+	style_cfg->parm_cfg.rawdrp = style_cfg_reg.s.rawdrp;
+	style_cfg->parm_cfg.force_drop = style_cfg_reg.s.drop;
+	style_cfg->parm_cfg.nodrop = style_cfg_reg.s.nodrop;
+
+	style_cfg->parm_cfg.len_lg = style_cfg2_reg.s.len_lg;
+	style_cfg->parm_cfg.len_lf = style_cfg2_reg.s.len_lf;
+	style_cfg->parm_cfg.len_le = style_cfg2_reg.s.len_le;
+	style_cfg->parm_cfg.len_ld = style_cfg2_reg.s.len_ld;
+	style_cfg->parm_cfg.len_lc = style_cfg2_reg.s.len_lc;
+	style_cfg->parm_cfg.len_lb = style_cfg2_reg.s.len_lb;
+	style_cfg->parm_cfg.csum_lg = style_cfg2_reg.s.csum_lg;
+	style_cfg->parm_cfg.csum_lf = style_cfg2_reg.s.csum_lf;
+	style_cfg->parm_cfg.csum_le = style_cfg2_reg.s.csum_le;
+	style_cfg->parm_cfg.csum_ld = style_cfg2_reg.s.csum_ld;
+	style_cfg->parm_cfg.csum_lc = style_cfg2_reg.s.csum_lc;
+	style_cfg->parm_cfg.csum_lb = style_cfg2_reg.s.csum_lb;
+
+	style_cfg->parm_cfg.qpg_qos = style_alg_reg.s.qpg_qos;
+	style_cfg->parm_cfg.tag_type = style_alg_reg.s.tt;
+	style_cfg->parm_cfg.apad_nip = style_alg_reg.s.apad_nip;
+	style_cfg->parm_cfg.qpg_port_sh = style_alg_reg.s.qpg_port_sh;
+	style_cfg->parm_cfg.qpg_port_msb = style_alg_reg.s.qpg_port_msb;
+	style_cfg->parm_cfg.wqe_vs = style_alg_reg.s.wqe_vs;
+
+	style_cfg->parm_cfg.pkt_lend = style_buf_reg.s.pkt_lend;
+	style_cfg->parm_cfg.wqe_hsz = style_buf_reg.s.wqe_hsz;
+	style_cfg->parm_cfg.wqe_skip = style_buf_reg.s.wqe_skip * 128;
+	style_cfg->parm_cfg.first_skip = style_buf_reg.s.first_skip * 8;
+	style_cfg->parm_cfg.later_skip = style_buf_reg.s.later_skip * 8;
+	style_cfg->parm_cfg.cache_mode = style_buf_reg.s.opc_mode;
+	style_cfg->parm_cfg.mbuff_size = style_buf_reg.s.mb_size * 8;
+	style_cfg->parm_cfg.dis_wq_dat = style_buf_reg.s.dis_wq_dat;
+
+	cvmx_pki_get_tag_config(node, style, cluster_mask, &style_cfg->tag_cfg);
+}
+
+int cvmx_pki_get_pkind_config(int node, int pkind, struct cvmx_pki_pkind_config *pkind_cfg)
+{
+	int cluster = 0;
+	uint64_t cl_mask;
+	cvmx_pki_pkindx_icgsel_t pkind_clsel;
+	cvmx_pki_clx_pkindx_style_t pkind_cfg_style;
+	cvmx_pki_icgx_cfg_t pki_cl_grp;
+	cvmx_pki_clx_pkindx_cfg_t pknd_cfg_reg;
+
+	pkind_clsel.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKINDX_ICGSEL(pkind));
+	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(pkind_clsel.s.icg));
+	cl_mask = (uint64_t)pki_cl_grp.s.clusters;
+	cluster = __builtin_ffsll(cl_mask) - 1;
+
+	pkind_cfg_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(pkind, cluster));
+	pkind_cfg->initial_parse_mode = pkind_cfg_style.s.pm;
+	pkind_cfg->initial_style = pkind_cfg_style.s.style;
+
+	pknd_cfg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pkind, cluster));
+	pkind_cfg->fcs_pres = pknd_cfg_reg.s.fcs_pres;
+	pkind_cfg->parse_en.inst_hdr = pknd_cfg_reg.s.inst_hdr;
+	pkind_cfg->parse_en.mpls_en = pknd_cfg_reg.s.mpls_en;
+	pkind_cfg->parse_en.lg_custom = pknd_cfg_reg.s.lg_custom;
+	pkind_cfg->parse_en.fulc_en = pknd_cfg_reg.s.fulc_en;
+	pkind_cfg->parse_en.dsa_en = pknd_cfg_reg.s.dsa_en;
+	pkind_cfg->parse_en.hg2_en = pknd_cfg_reg.s.hg2_en;
+	pkind_cfg->parse_en.hg_en = pknd_cfg_reg.s.hg_en;
+	return 0;
+}
+
+void cvmx_pki_config_port(int node, int ipd_port, struct cvmx_pki_port_config *port_cfg)
+{
+	int interface, index, pknd;
+	int style, cl_mask;
+	cvmx_pki_icgx_cfg_t pki_cl_msk;
+
+	/* get the pkind used by this ipd port */
+	interface = cvmx_helper_get_interface_num(ipd_port);
+	index = cvmx_helper_get_interface_index_num(ipd_port);
+	pknd = cvmx_helper_get_pknd(interface, index);
+
+	cvmx_pki_write_pkind(node, pknd, &port_cfg->pkind_cfg);
+	style = port_cfg->pkind_cfg.initial_style;
+	pki_cl_msk.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(port_cfg->pkind_cfg.cluster_grp));
+	cl_mask = pki_cl_msk.s.clusters;
+	cvmx_pki_write_style(node, style, cl_mask, &port_cfg->style_cfg);
+}
+
+void cvmx_pki_get_port_config(int node, int ipd_port, struct cvmx_pki_port_config *port_cfg)
+{
+	int interface, index, pknd;
+	int style, cl_mask;
+	cvmx_pki_icgx_cfg_t pki_cl_msk;
+
+	/* get the pkind used by this ipd port */
+	interface = cvmx_helper_get_interface_num(ipd_port);
+	index = cvmx_helper_get_interface_index_num(ipd_port);
+	pknd = cvmx_helper_get_pknd(interface, index);
+
+	cvmx_pki_get_pkind_config(node, pknd, &port_cfg->pkind_cfg);
+	style = port_cfg->pkind_cfg.initial_style;
+	pki_cl_msk.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(port_cfg->pkind_cfg.cluster_grp));
+	cl_mask = pki_cl_msk.s.clusters;
+	cvmx_pki_get_style_config(node, style, cl_mask, &port_cfg->style_cfg);
+}
+
+/**
+ * This function sets the wqe buffer mode. First packet data buffer can reside
+ * either in same buffer as wqe OR it can go in separate buffer. If used the later mode,
+ * make sure software allocate enough buffers to now have wqe separate from packet data.
+ * @param node	              node number.
+ * @param style		      style to configure.
+ * @param pkt_outside_wqe.	0 = The packet link pointer will be at word [FIRST_SKIP]
+ *				    immediately followed by packet data, in the same buffer
+ *				    as the work queue entry.
+ *				1 = The packet link pointer will be at word [FIRST_SKIP] in a new
+ *				    buffer separate from the work queue entry. Words following the
+ *				    WQE in the same cache line will be zeroed, other lines in the
+ *				    buffer will not be modified and will retain stale data (from the
+ * 				    buffers previous use). This setting may decrease the peak PKI
+ *				    performance by up to half on small packets.
+ */
+void cvmx_pki_set_wqe_mode(int node, uint64_t style, bool pkt_outside_wqe)
+{
+	cvmx_pki_stylex_buf_t     style_buf_reg;
+
+	style_buf_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_STYLEX_BUF(style));
+	style_buf_reg.s.dis_wq_dat = pkt_outside_wqe;
+	cvmx_write_csr_node(node, CVMX_PKI_STYLEX_BUF(style), style_buf_reg.u64);
 }
 
 
@@ -310,38 +559,35 @@ int cvmx_pki_pcam_write_entry(int node, int index, uint64_t cluster_mask,
 				struct cvmx_pki_pcam_action action)
 {
 	int bank;
-	int cluster=0;
+	int cluster = 0;
 	cvmx_pki_clx_pcamx_termx_t	pcam_term;
 	cvmx_pki_clx_pcamx_matchx_t	pcam_match;
 	cvmx_pki_clx_pcamx_actionx_t	pcam_action;
 
-	if(index >= CVMX_PKI_TOTAL_PCAM_ENTRY) {
+	if (index >= CVMX_PKI_TOTAL_PCAM_ENTRY) {
 		cvmx_dprintf("\nERROR: Invalid pcam entry %d", index);
 		return -1;
 	}
 	bank = (int)(input.field & 0x01);
-	while( cluster < CVMX_PKI_NUM_CLUSTERS) {
-		if(cluster_mask & (0x01L << cluster)) {
-			pcam_match.u64 = cvmx_read_csr_node(node,CVMX_PKI_CLX_PCAMX_MATCHX(cluster, bank, index));
+	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if (cluster_mask & (0x01L << cluster)) {
+			pcam_match.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PCAMX_MATCHX(cluster, bank, index));
 			pcam_match.s.data1 = input.data & input.data_mask;
 			pcam_match.s.data0 = (~input.data) & input.data_mask;
-			//cvmx_dprintf("\ncl%d bank%d index%d pcam_match=%lx",cluster,bank,index,pcam_match.u64);
 			cvmx_write_csr_node(node, CVMX_PKI_CLX_PCAMX_MATCHX(cluster, bank, index), pcam_match.u64);
-			pcam_action.u64 = cvmx_read_csr_node(node,CVMX_PKI_CLX_PCAMX_ACTIONX(cluster, bank, index));
+			pcam_action.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PCAMX_ACTIONX(cluster, bank, index));
 			pcam_action.s.pmc = action.parse_mode_chg;
 			pcam_action.s.style_add = action.style_add;
 			pcam_action.s.pf = action.parse_flag_set;
 			pcam_action.s.setty = action.layer_type_set;
 			pcam_action.s.advance = action.pointer_advance;
-			//cvmx_dprintf("\ncl%d bank%d index%d pcam_action=%lx",cluster,bank,index,pcam_action.u64);
-			cvmx_write_csr_node(node,CVMX_PKI_CLX_PCAMX_ACTIONX(cluster, bank, index), pcam_action.u64);
-			pcam_term.u64 = cvmx_read_csr_node(node,CVMX_PKI_CLX_PCAMX_TERMX(cluster, bank, index));
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_PCAMX_ACTIONX(cluster, bank, index), pcam_action.u64);
+			pcam_term.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PCAMX_TERMX(cluster, bank, index));
 			pcam_term.s.term1 = input.field & input.field_mask;
 			pcam_term.s.term0 = (~input.field) & input.field_mask;
 			pcam_term.s.style1 = input.style & input.style_mask;
 			pcam_term.s.style0 = (~input.style) & input.style_mask;
 			pcam_term.s.valid = 1;
-			//cvmx_dprintf("\ncl%d bank%d index%d pcam_term=%lx",cluster,bank,index,pcam_term.u64);
 			cvmx_write_csr_node(node, CVMX_PKI_CLX_PCAMX_TERMX(cluster, bank, index), pcam_term.u64);
 		}
 		cluster++;
@@ -368,15 +614,15 @@ int cvmx_pki_enable_aura_qos(int node, int aura, bool ena_red,
 {
 	cvmx_pki_aurax_cfg_t pki_aura_cfg;
 
-	if( aura >= CVMX_PKI_NUM_AURA) {
-		cvmx_dprintf("ERROR: PKI config aura_qos aura = %d",aura);
+	if (aura >= CVMX_PKI_NUM_AURA) {
+		cvmx_dprintf("ERROR: PKI config aura_qos aura = %d", aura);
 		return -1;
 	}
 	pki_aura_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_AURAX_CFG(aura));
 	pki_aura_cfg.s.ena_red = ena_red;
 	pki_aura_cfg.s.ena_drop = ena_drop;
 	pki_aura_cfg.s.ena_bp = ena_bp;
-	cvmx_write_csr_node(node, CVMX_PKI_AURAX_CFG(aura),pki_aura_cfg.u64);
+	cvmx_write_csr_node(node, CVMX_PKI_AURAX_CFG(aura), pki_aura_cfg.u64);
 	return 0;
 }
 
@@ -393,13 +639,13 @@ int cvmx_pki_write_aura_bpid(int node, int aura, int bpid)
 {
 	cvmx_pki_aurax_cfg_t pki_aura_cfg;
 
-	if( aura >= CVMX_PKI_NUM_AURA || bpid >= CVMX_PKI_NUM_BPID) {
-		cvmx_dprintf("ERROR: PKI config aura_bp aura = %d bpid = %d",aura, bpid);
+	if (aura >= CVMX_PKI_NUM_AURA || bpid >= CVMX_PKI_NUM_BPID) {
+		cvmx_dprintf("ERROR: PKI config aura_bp aura = %d bpid = %d", aura, bpid);
 		return -1;
 	}
 	pki_aura_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_AURAX_CFG(aura));
 	pki_aura_cfg.s.bpid = bpid;
-	cvmx_write_csr_node(node, CVMX_PKI_AURAX_CFG(aura),pki_aura_cfg.u64 );
+	cvmx_write_csr_node(node, CVMX_PKI_AURAX_CFG(aura), pki_aura_cfg.u64);
 	return 0;
 }
 
@@ -416,760 +662,93 @@ int cvmx_pki_write_channel_bpid(int node, int channel, int bpid)
 {
 	cvmx_pki_chanx_cfg_t pki_chan_cfg;
 
-	if( channel >= CVMX_PKI_NUM_CHANNELS || bpid >= CVMX_PKI_NUM_BPID) {
-		cvmx_dprintf("ERROR: PKI config channel_bp channel = %d bpid = %d",channel, bpid);
+	if (channel >= CVMX_PKI_NUM_CHANNELS || bpid >= CVMX_PKI_NUM_BPID) {
+		cvmx_dprintf("ERROR: PKI config channel_bp channel = %d bpid = %d", channel, bpid);
 		return -1;
 	}
 
 	pki_chan_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CHANX_CFG(channel));
 	pki_chan_cfg.s.bpid = bpid;
-	cvmx_write_csr_node(node, CVMX_PKI_CHANX_CFG(channel),pki_chan_cfg.u64 );
-	return 0;
-}
-
-int cvmx_pki_frame_len_check(int node, int id, int maxframesize, int minframesize)
-{
-	cvmx_pki_frm_len_chkx_t frame_len_chk;
-
-	frame_len_chk.u64 = cvmx_read_csr_node(node, CVMX_PKI_FRM_LEN_CHKX(id));
-	if(maxframesize && minframesize) {
-		if(frame_len_chk.s.maxlen != maxframesize ||
-				 frame_len_chk.s.minlen != minframesize)
-			return -1;
-	}
-	else if(maxframesize && frame_len_chk.s.maxlen != maxframesize)
-		return -1;
-	else if(minframesize && frame_len_chk.s.minlen != minframesize)
-		return -1;
+	cvmx_write_csr_node(node, CVMX_PKI_CHANX_CFG(channel), pki_chan_cfg.u64);
 	return 0;
 }
 
-int cvmx_pki_set_l2_frame_len(int node, uint64_t maxframesize, uint64_t minframesize)
-{
-	if (cvmx_pki_frame_len_check(node,0,maxframesize, minframesize)) {
-		if (cvmx_pki_frame_len_check(node,1,maxframesize, minframesize)) {
-			cvmx_dprintf("ERROR: No frame len match");
-			return -1;
-		}
-		return 1;
-	}
-	else
-		return 0;
-}
-
-/**
- * This function finds if cluster profile with name already exist
- * @param node  node number
- * @param name  profile name to look for
- * @return 	profile index in cluster list on SUCCESS
-                -1 if profile not found in cluster list
- */
-int cvmx_pki_cluster_profile_exist(int node, char *name)
-{
-	int index = pki_profiles[node].cl_profile_list.index;
-
-	while(index--)
-	{
-		if(strcmp(name,pki_profiles[node].cl_profile_list.cl_profile[index].name) == 0)
-			return index;
-	}
-	return -1;
-}
-
-/**
- * This function finds cluster mask associated with
- * given cluster profile name.
- * @param node  node number
- * @param name  profile name to look for
- * @return 	cluster_mask on SUCCESS
-                -1 if profile not found in cluster list
- */
-int cvmx_pki_find_cluster_mask(int node, char *name)
-{
-	int index;
-	int cl_grp;
-
-	if((index = cvmx_pki_cluster_profile_exist(node,name)) == -1)
-		return -1;
-
-	cl_grp = pki_profiles[node].cl_profile_list.cl_profile[index].cluster_group;
-	return pki_config[node].cluster_cfg[cl_grp].cluster_mask;
-
-}
-
-/**
- * This function finds cluster group associated with
- * given cluster profile name
- * @param node  node number
- * @param name  profile name to look for
- * @return 	cluster group number on SUCCESS
-                -1 if profile not found in cluster list
- */
-int cvmx_pki_find_cluster_group(int node, char *name)
-{
-	int index;
-
-	if((index = cvmx_pki_cluster_profile_exist(node,name)) == -1)
-		return -1;
-	return pki_profiles[node].cl_profile_list.cl_profile[index].cluster_group;
-}
-
-/**
- * This function finds if fpa pool profile with
- * name already exist
- * @param node  node number
- * @param name  profile name to look for
- * @return 	profile index in pool list on SUCCESS
-                -1 if profile not found in pool list
- */
-int cvmx_pki_pool_profile_exist(int node, char *name)
-{
-	int index = pki_profiles[node].pool_profile_list.index;
-
-	while(index--)
-	{
-		if(strcmp(name,pki_profiles[node].pool_profile_list.pool_profile[index].pool_name) == 0) {
-			return index;
-		}
-	}
-	return -1;
-}
-
-/**
- * This function finds if fpa pool number associated with
- * given profile name
- * @param node  node number
- * @param name  profile name to look for
- * @return 	pool number on SUCCESS
-                -1 if profile not found in pool list
- */
-int cvmx_pki_find_pool(int node, char *name)
-{
-	int index;
-
-	if((index = cvmx_pki_pool_profile_exist(node,name)) == -1)
-		return -1;
-	return pki_profiles[node].pool_profile_list.pool_profile[index].pool_cfg.pool_num;
-}
-
-/**
- * This function finds if fpa aura with given name
- * exist in aura list
- * @param node  node number
- * @param name  profile name to look for
- * @return 	aura index in aura list on SUCCESS
-                -1 if profile not found in aura list
- */
-int cvmx_pki_aura_profile_exist(int node, char *name)
-{
-	int index = pki_profiles[node].aura_profile_list.index;
-
-	while(index--)
-	{
-		if(strcmp(name,pki_profiles[node].aura_profile_list.aura_profile[index].aura_name) == 0)
-			return index;
-	}
-	return -1;
-}
-
-/**
- * This function finds aura number associated with
- * given aura name.
- * @param node  node number
- * @param name  profile name to look for
- * @return 	aura number in aura list on SUCCESS
-                -1 if profile not found in aura list
- */
-int cvmx_pki_find_aura(int node, char *name)
-{
-	int index;
-
-	if((index = cvmx_pki_aura_profile_exist(node,name)) == -1)
-		return -1;
-	return pki_profiles[node].aura_profile_list.aura_profile[index].aura_num;
-}
-
 /**
- * This function finds if group with given name
- * exist in group list
- * @param node  node number
- * @param name  profile name to look for
- * @return 	index in group list on SUCCESS
-                -1 if profile not found in group list
+ * Enables/Disables fcs check and fcs stripping on the pkind.
+ * @param node		node number
+ * @param pknd		pkind to apply settings on.
+ * @param fcs_chk	enable/disable fcs check.
+ *			1 -- enable fcs error check.
+ *			0 -- disable fcs error check.
+ * @param fcs_strip	Strip L2 FCS bytes from packet, decrease WQE[LEN] by 4 bytes
+ *			1 -- strip L2 FCS.
+ *			0 -- Do not strip L2 FCS.
  */
-int cvmx_pki_group_profile_exist(int node, char *name)
+void cvmx_pki_endis_fcs_check(int node, int pknd, bool fcs_chk, bool fcs_strip)
 {
-	int index = pki_profiles[node].sso_grp_profile_list.index;
-
-	while(index--)
-	{
-		if(strcmp(name,pki_profiles[node].sso_grp_profile_list.grp_profile[index].grp_name) == 0)
-			return index;
-	}
-	return -1;
-}
-
-/**
- * This function finds group number associated with
- * given group profile name
- * @param node  node number
- * @param name  profile name to look for
- * @return 	group number on SUCCESS
-                -1 if profile not found in group list
- */
-int cvmx_pki_find_group(int node, char *name)
-{
-	int index;
-
-	if((index = cvmx_pki_group_profile_exist(node,name)) == -1)
-		return -1;
-	return pki_profiles[node].sso_grp_profile_list.grp_profile[index].grp_num;
-}
-
-/**
- * This function finds if qpg profile with given name
- * exist in qpg list
- * @param node  node number
- * @param name  profile name to look for
- * @return 	index in qpg list on SUCCESS
-                -1 if profile not found in qpg list
- */
-int cvmx_pki_qpg_profile_exist(int node, char *name)
-{
-	int index = pki_profiles[node].qpg_profile_list.index;
-
-	while(index--)
-	{
-		if(strcmp(name,pki_profiles[node].qpg_profile_list.qpg_profile[index].qpg_name) == 0)
-			return index;
-	}
-	return -1;
-}
-
-/**
- * This function finds qpg base offset associated with
- * given qpg profile name.
- * @param node  node number
- * @param name  profile name to look for
- * @return 	qpg base offset on SUCCESS
-                -1 if profile not found in qpg list
- */
-int cvmx_pki_find_qpg_base_offset(int node, char *name)
-{
-	int index;
-
-	if((index = cvmx_pki_qpg_profile_exist(node,name)) == -1)
-		return -1;
-	return pki_profiles[node].qpg_profile_list.qpg_profile[index].base_offset;
-}
-
-/**
- * This function get the buffer size of the given pool number
- * @param node  node number
- * @param pool  fpa pool number
- * @return 	buffer size SUCCESS
-                -1 if pool number is not found in pool list
- */
-int cvmx_pki_get_pool_buffer_size(int node,int pool)
-{
-	int index = pki_profiles[node].aura_profile_list.index;
-
-	while(index--)
-	{
-		if(pki_profiles[node].pool_profile_list.pool_profile[index].pool_cfg.pool_num == pool) {
-			return pki_profiles[node].pool_profile_list.pool_profile[index].pool_cfg.buffer_size;
-		}
-	}
-	return -1;
-}
-
-/**
- * This function get the buffer size of the given aura number
- * @param node  node number
- * @param pool  fpa aura number
- * @return 	buffer size SUCCESS
-                -1 if aura number is not found in aura list
- */
-int cvmx_pki_get_aura_buffer_size(int node, int aura)
-{
-	int index = pki_profiles[node].aura_profile_list.index;
-	int pool_num;
-
-	while(index--)
-	{
-		if(pki_profiles[node].aura_profile_list.aura_profile[index].aura_num == aura) {
-			pool_num = pki_profiles[node].aura_profile_list.aura_profile[index].pool_num;
-			return cvmx_pki_get_pool_buffer_size(node,pool_num);
-		}
-	}
-	return -1;
-}
-
-int cvmx_pki_get_mbuff_size (int node, int base_offset)
-{
-	int index = pki_profiles[node].qpg_profile_list.index;
-	int aura;
-	int min_size;
-	int aura_size;
-	int i;
-
-	while(index--)
-	{
-		if(pki_profiles[node].qpg_profile_list.qpg_profile[index].base_offset == base_offset) {
-			int num_entry = pki_profiles[node].qpg_profile_list.qpg_profile[index].num_entries;
-			aura = pki_config[node].qpg_cfg[base_offset].aura;
-			min_size = cvmx_pki_get_aura_buffer_size(node,aura);
-			for(i=1; i < num_entry; i++) {
-				aura = pki_config[node].qpg_cfg[base_offset+i].aura;
-				aura_size = cvmx_pki_get_aura_buffer_size(node,aura);
-				if(min_size > aura_size)
-					min_size = aura_size;
-			}
-			return min_size;
-		}
-	}
-	return -1;
-}
-
-/**
- * This function finds if style profile with given name
- * exist in style list
- * @param node  node number
- * @param name  profile name to look for
- * @return 	index into style list on SUCCESS
-                -1 if profile not found in style list
- */
-int cvmx_pki_style_profile_exist(int node, char *name)
-{
-	int index = pki_profiles[node].style_profile_list.index;
-
-	while(index--)
-	{
-		if(strcmp(name,pki_profiles[node].style_profile_list.style_profile[index].name) == 0)
-			return index;
-	}
-	return -1;
-}
-
-/**
- * This function finds style number associated with
- * given style profile name.
- * @param node  node number
- * @param name  profile name to look for
- * @return 	style number on SUCCESS
-                -1 if profile not found in style list
- */
-int cvmx_pki_find_style(int node, char *name)
-{
-	int index;
-
-	if((index = cvmx_pki_style_profile_exist(node,name)) == -1)
-		return -1;
-	return pki_profiles[node].style_profile_list.style_profile[index].style_num;
-}
-
-/**
- * This function stores the cluster configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param name  	name associated with this config
- * @param cl_profile    structure containing cluster profile parameters below
- * 			-cluster_group (-1 if needs to be allocated)
- * 			-num_cluster   (number of cluster in the cluster group)
- * 			-parsing_mask  (parsing mask for the cluster group)
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_cluster_config(int node, struct cvmx_pki_cluster_profile cl_profile)
-{
-	int index;
-	int cluster_group;
-	uint64_t cluster_mask;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-	if(cvmx_pki_cluster_profile_exist(node,cl_profile.name) >= 0) {
-		cvmx_dprintf("ERROR:cluster profile already exist with name %s",cl_profile.name);
-		return -1;
-	}
-	if((cluster_group = cvmx_pki_alloc_cluster_group(node, cl_profile.cluster_group,
-	    cl_profile.num_clusters, cl_profile.parsing_mask, &cluster_mask)) == -1) {
-		cvmx_dprintf("ERROR:allocating cluster_group\n");
-		return -1;
-	}
-	cl_profile.cluster_group = cluster_group;
-	//spinlock it
-	index = pki_profiles[node].cl_profile_list.index;
-
-	if(index >= CVMX_PKI_MAX_CLUSTER_PROFILES) {
-		cvmx_dprintf("ERROR: Max cluster profiles %d reached\n", index);
-		return -1;
-	}
-	pki_profiles[node].cl_profile_list.index++;
-	//spinlock free
-
-	pki_profiles[node].cl_profile_list.cl_profile[index] = cl_profile;
-	pki_config[node].cluster_cfg[cluster_group].cluster_mask = cluster_mask;
-	return 0;
-}
-
-/**
- * This function stores the pool configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pool_name  	name associated with this config
- * @param pool_numb     pool number (-1 if need to be allocated)
- * @param buffer_size	size of buffers in specified pool
- * @param num_buffers	numberof buffers in specified pool
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_pool_config(int node, char* pool_name, int pool_num,
-			     uint64_t buffer_size, uint64_t num_buffers)
-{
-	uint64_t index;
-	struct cvmx_pki_pool_profile* pool_profile;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-	if(cvmx_pki_pool_profile_exist(node, pool_name) >= 0) {
-		cvmx_dprintf("ERROR:pool profile already exist with name %s",pool_name);
-		return -1;
-	}
-	if(cvmx_fpa_allocate_fpa_pools(node,&pool_num,1) == -1) {
-		cvmx_dprintf("ERROR:allocating pool for pool_config\n");
-		return -1;
-	}
-
-	//spinlock it
-	index = pki_profiles[node].pool_profile_list.index;
-	if(index >= CVMX_PKI_MAX_POOL_PROFILES) {
-		cvmx_dprintf("ERROR: Max pool profile %d reached\n", (int)index);
-		return -1;
-
-	}
-	pki_profiles[node].pool_profile_list.index++;
-	//spinlock free
-
-	pool_profile = &pki_profiles[node].pool_profile_list.pool_profile[index];
-	strcpy(pool_profile->pool_name, pool_name);
-	pool_profile->pool_cfg.pool_num = pool_num;
-	pool_profile->pool_cfg.buffer_size = buffer_size;
-	pool_profile->pool_cfg.buffer_count = num_buffers;
-	return 0;
-}
-
-/**
- * This function stores the aura configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param aura_name  	name associated with this config
- * @param aura_num      aura number (-1 if need to be allocated)
- * @param pool  	pool to which aura is mapped
- * @param num_buffers	number of buffers to allocate to aura.
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_aura_config(int node, char* aura_name, int aura_num, int pool,
-			      int num_buffers)
-{
-	uint64_t index;
-	struct cvmx_pki_aura_profile* aura_profile;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-	if(cvmx_pki_aura_profile_exist(node,aura_name) >= 0) {
-		cvmx_dprintf("ERROR:aura profile already exist with name %s",aura_name);
-		return -1;
-	}
-	if((aura_num = cvmx_fpa_allocate_auras(node,&aura_num,1)) == -1) {
-		cvmx_dprintf("ERROR:allocating aura for aura_config\n");
-		return -1;
-	}
-	//spinlock it
-	index = pki_profiles[node].aura_profile_list.index;
-	if(index >= CVMX_PKI_MAX_AURA_PROFILES) {
-		cvmx_dprintf("ERROR: Max aura profile %d reached\n", (int)index);
-		return -1;
-
-	}
-	pki_profiles[node].aura_profile_list.index++;
-	//spinlock free
-
-	aura_profile = &pki_profiles[node].aura_profile_list.aura_profile[index];
-	strcpy(aura_profile->aura_name, aura_name);
-	aura_profile->aura_num = aura_num;
-	aura_profile->pool_num = pool;
-	aura_profile->buffer_count = num_buffers;
-	return 0;
-}
-
-/**
- * This function stores the group configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param grp_profile	struct to SSO group profile to configure
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_sso_group_config(int node, struct cvmx_pki_sso_grp_profile grp_profile)
-{
-	uint64_t index;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-	if(cvmx_pki_group_profile_exist(node, grp_profile.grp_name) >= 0) {
-		cvmx_dprintf("ERROR:group profile already exist with name %s",grp_profile.grp_name);
-		return -1;
-	}
-#if 0 //vinita_to_do uncomment when group_alloc is ready
-	if((group = cvmx_pki_allocate_group(node,group)) == -1) {
-		cvmx_dprintf("ERROR:allocating group for group_config\n");
-		return -1;
-	}
-#endif
-
-	//spinlock it
-	index = pki_profiles[node].sso_grp_profile_list.index;
-	if(index >= CVMX_PKI_MAX_SSO_GROUP_PROFILES) {
-		cvmx_dprintf("ERROR: Max group profile %d reached\n", (int)index);
-		return -1;
-
-	}
-	pki_profiles[node].sso_grp_profile_list.index++;
-	//spinlock free
-
-	pki_profiles[node].sso_grp_profile_list.grp_profile[index] = grp_profile;
-	return 0;
-
-}
-
-/**
- * This function stores the qpg configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param name  	name associated with this config
- * @param base_offset	offset in QPG table (-1 if needs to be allocated)
- * @param num_entries	total number of indexes needs to be allocated from
- *                      base_offset.
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_qpg_profile(int node, char* name, int base_offset, int num_entries)
-{
-	int64_t index;
-	struct cvmx_pki_qpg_profile* qpg_profile;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-	if(cvmx_pki_qpg_profile_exist(node,name) >= 0) {
-		cvmx_dprintf("ERROR:qpg profile already exist with name %s",name);
-		return -1;
-	}
-	if((base_offset = cvmx_pki_alloc_qpg_entry(node,base_offset,num_entries)) == -1) {
-		cvmx_dprintf("ERROR:allocating entry for qpg_table\n");
-		return -1;
-	}
-
-	//spinlock it
-	index = pki_profiles[node].qpg_profile_list.index;
-	if(index >= CVMX_PKI_MAX_QPG_PROFILES) {
-		cvmx_dprintf("ERROR: Max qpg profile %d reached\n", (int)index);
-		return -1;
-
-	}
-	pki_profiles[node].qpg_profile_list.index++;
-	//spinlock free
-
-	qpg_profile = &pki_profiles[node].qpg_profile_list.qpg_profile[index];
-	strcpy(qpg_profile->qpg_name, name);
-	qpg_profile->base_offset = base_offset;
-	qpg_profile->num_entries = num_entries;
-	return 0;
-}
-
-/**
- * This function stores the group configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param aura_name  	name associated with this config
- * @param group		SSO group number (-1 if needs to be allocated)
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_qpg_config(int node, char* name, int entry_start,
-			    int entry_end, struct cvmx_pki_qpg_config qpg_config)
-{
-	int index;
-	int base_offset;
-	int num_entry;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-	if((index = cvmx_pki_qpg_profile_exist(node,name)) < 0) {
-		cvmx_dprintf("ERROR:qpg profile %s not found\n",name);
-		return -1;
-	}
-	if ((base_offset = pki_profiles[node].qpg_profile_list.qpg_profile[index].base_offset) < 0) {
-		cvmx_dprintf("ERROR: invalid base offset %d in qpg profile %s",base_offset,name);
-		return -1;
-	}
-	num_entry = pki_profiles[node].qpg_profile_list.qpg_profile[index].num_entries;
-	if(entry_start > num_entry || entry_end > num_entry) {
-		cvmx_dprintf("ERROR: start_entry %llu or end_entry %llu is > %llu for qpg_profile %s",
-			     (unsigned long long)entry_start,(unsigned long long)entry_end,(unsigned long long)num_entry,name);
-	}
-	while(entry_start <= entry_end) {
-		pki_config[node].qpg_cfg[base_offset + entry_start] = qpg_config;
-		entry_start++;
-	}
-	return 0;
-}
-
-/**
- * This function stores the style configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param aura_name  	name associated with this config
- * @param style_num	style number (-1 if needs to be allocated)
- * @param style_cfg	pointer to struct which has parameters related
- *                      to style config
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_style_config(int node, char* style_name, int style_num,
-			       struct cvmx_pki_style_config* style_cfg)
-{
-	uint64_t index;
-	struct cvmx_pki_style_profile* style_profile;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-	if(cvmx_pki_style_profile_exist(node,style_name) > 0) {
-		cvmx_dprintf("ERROR: style profile already exist with name %s",style_name);
-		return -1;
-	}
-	if((style_num = cvmx_pki_alloc_style(node,style_num)) == -1) {
-		cvmx_dprintf("ERROR:allocating style for style_config\n");
-		return -1;
-	}
-
-	//spinlock it
-	index = pki_profiles[node].style_profile_list.index;
-	if(index >= CVMX_PKI_MAX_STYLE_PROFILES) {
-		cvmx_dprintf("ERROR: Max style profile %d reached\n", (int)index);
-		return -1;
+	int style;
+	int cluster = 0;
+	cvmx_pki_clx_pkindx_style_t pkind_style;
+	cvmx_pki_clx_stylex_cfg_t style_cfg;
 
-	}
-	pki_profiles[node].style_profile_list.index++;
-	//spinlock free
-
-	style_profile = &pki_profiles[node].style_profile_list.style_profile[index];
-	strcpy(style_profile->name, style_name);
-	style_profile->style_num = style_num;
-	memcpy(&pki_config[node].style_cfg[style_num], style_cfg, sizeof(struct cvmx_pki_style_config));
-	return index;
+	/*vinita_to_do; find the cluster in use*/
+	pkind_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pknd, cluster));
+	style = pkind_style.s.style;
+	style_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster));
+	style_cfg.s.fcs_chk = fcs_chk;
+	style_cfg.s.fcs_strip = fcs_strip;
+	cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster), style_cfg.u64);
 }
 
 /**
- * This function stores the pkind style configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pkind  	pkind number
- * @param style		style number which need to be assigned to pkind
- * @return 		0 on SUCCESS
-                        -1 on failure
+ * Enables/Disables l2 length error check and max & min frame length checks
+ * @param node		node number
+ * @param pknd		pkind to disable error for.
+ * @param l2len_err	L2 length error check enable.
+ * @param maxframe_err	Max frame error check enable.
+ * @param minframe_err	Min frame error check enable.
+ *			1 -- Enabel err checks
+ *			0 -- Disable error checks
  */
-int cvmx_pki_set_pkind_style(int node, int pkind, int style)
+void cvmx_pki_endis_l2_errs(int node, int pknd, bool l2len_err,
+			 bool maxframe_err, bool minframe_err)
 {
-	pki_config[node].pkind_cfg[pkind].initial_style = style;
-	pki_config[node].style_cfg[style].cluster_mask = pki_config[node].pkind_cfg[pkind].cluster_mask;
-	return 0;
-}
+	int style;
+	int cluster = 0;
+	cvmx_pki_clx_pkindx_style_t pkind_style;
+	cvmx_pki_clx_stylex_cfg_t style_cfg;
 
-/**
- * This function stores the pkind initial parse mode in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pkind  	pkind number
- * @param parse_mode    parse mode to assign to specified pkind.
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-void cvmx_pki_set_pkind_initial_parse_mode(int node, int pkind, int parse_mode)
-{
-	pki_config[node].pkind_cfg[pkind].parsing_mode=parse_mode;
+	/*vinita_to_do; find the cluster in use*/
+	pkind_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pknd, cluster));
+	style = pkind_style.s.style;
+	style_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster));
+	style_cfg.s.lenerr_en = l2len_err;
+	style_cfg.s.maxerr_en = maxframe_err;
+	style_cfg.s.minerr_en = minframe_err;
+	cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster), style_cfg.u64);
 }
 
 /**
- * This function stores the pkind cluster configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pkind  	pkind number
- * @param style_name	pointer to style name which need to be assigned to pkind
- * @return 		0 on SUCCESS
-                        -1 on failure
+ * Disables maximum & minimum frame length checks
+ * @param node   node number
+ * @param pknd	 pkind to disable error for.
  */
-void cvmx_pki_set_pkind_cluster_config(int node, int pkind,
-					   int cl_grp, uint64_t cl_mask)
+void cvmx_pki_dis_frame_len_chk(int node, int pknd)
 {
-	pki_config[node].pkind_cfg[pkind].cluster_grp = cl_grp;
-	pki_config[node].pkind_cfg[pkind].cluster_mask = cl_mask;
+	int style;
+	int cluster = 0;
+	cvmx_pki_clx_pkindx_style_t pkind_style;
+	cvmx_pki_clx_stylex_cfg_t style_cfg;
 
+	/*vinita_to_do; find the cluster in use*/
+	pkind_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pknd, cluster));
+	style = pkind_style.s.style;
+	style_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster));
+	style_cfg.s.maxerr_en = 0;
+	style_cfg.s.minerr_en = 0;
+	cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster), style_cfg.u64);
 }
 
-/**
- * This function stores the pcam entry in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pcam_index	which pcam entry to configure (-1 to allocate from available entries)
- * @param cluster_mask	Mask of clusters on which the entry meeds to be appiled.
- * @param input		structure of pcam input parameter which defines matching creteria.
- * @param action	structure of pcam action parameters which aill be applied if match is found.
- * @return              0 on scuccess
- *			-1 on failure
- */
-int cvmx_pki_set_pcam_entry(int node, int pcam_index, uint64_t cl_mask,
-			       struct cvmx_pki_pcam_input input,
-			       struct cvmx_pki_pcam_action action)
-{
-	uint64_t index;
-
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-
-	//spinlock it
-	index = pki_profiles[node].pcam_list.index;
-	if(index >= CVMX_PKI_TOTAL_PCAM_ENTRY) {
-		cvmx_dprintf("ERROR: Max pcam lists %d reached\n", (int)index);
-		return -1;
-
-	}
-	pki_profiles[node].pcam_list.index++;
-	//spinlock free
-
-	pki_profiles[node].pcam_list.pcam_cfg[index].cluster_mask = cl_mask;
-	pki_profiles[node].pcam_list.pcam_cfg[index].entry_num = pcam_index;
-	pki_profiles[node].pcam_list.pcam_cfg[index].pcam_input = input;
-	pki_profiles[node].pcam_list.pcam_cfg[index].pcam_action = action;
-	return 0;
-}
 
 /**
  * This function shows the pcam table in raw format,
@@ -1182,18 +761,18 @@ void cvmx_pki_show_pcam_entries(int node)
 	int index;
 	int bank;
 
-	for(cluster=0; cluster<4; cluster++) {
-		for(bank=0; bank<2; bank++) {
-			cvmx_dprintf("\n--------------Cluster %1d Bank %1d-------------\n",cluster,bank);
+	for (cluster = 0; cluster < 4; cluster++) {
+		for (bank = 0; bank < 2; bank++) {
+			cvmx_dprintf("\n--------------Cluster %1d Bank %1d-------------\n", cluster, bank);
 			cvmx_dprintf("index         TERM                 DATA,                ACTION");
-			for(index=0; index<CVMX_PKI_NUM_PCAM_ENTRY; index++) {
-				cvmx_dprintf("\n%d",index);
+			for (index = 0; index < CVMX_PKI_NUM_PCAM_ENTRY; index++) {
+				cvmx_dprintf("\n%d", index);
 				cvmx_dprintf("             %-16lx",
-					     (unsigned long)cvmx_read_csr_node(node,CVMX_PKI_CLX_PCAMX_TERMX(cluster, bank, index)));
-			        cvmx_dprintf("     %-16lx",
-					     (unsigned long)cvmx_read_csr_node(node,CVMX_PKI_CLX_PCAMX_MATCHX(cluster, bank, index)));
-			        cvmx_dprintf("     %-16lx",
-					     (unsigned long)cvmx_read_csr_node(node,CVMX_PKI_CLX_PCAMX_ACTIONX(cluster, bank, index)));
+				     (unsigned long)cvmx_read_csr_node(node, CVMX_PKI_CLX_PCAMX_TERMX(cluster, bank, index)));
+				cvmx_dprintf("     %-16lx",
+					     (unsigned long)cvmx_read_csr_node(node, CVMX_PKI_CLX_PCAMX_MATCHX(cluster, bank, index)));
+				cvmx_dprintf("     %-16lx",
+					     (unsigned long)cvmx_read_csr_node(node, CVMX_PKI_CLX_PCAMX_ACTIONX(cluster, bank, index)));
 			}
 		}
 	}
@@ -1213,27 +792,27 @@ void cvmx_pki_show_valid_pcam_entries(int node)
 	cvmx_pki_clx_pcamx_matchx_t	pcam_match;
 	cvmx_pki_clx_pcamx_actionx_t	pcam_action;
 
-	//vinita_to_do, later modify to use/t/t etc
-	for(cluster=0; cluster<4; cluster++) {
-		for(bank=0; bank<2; bank++) {
-			cvmx_dprintf("\n--------------Cluster %1d Bank %1d-----------------------------------------------\n",cluster,bank);
-			cvmx_dprintf("%-10s%-17s%-19s%-18s","index",
-				     "TERM1:TERM0","Style1:Style0","Data1:Data0");
-			cvmx_dprintf("%-6s","ACTION[pmc:style_add:pf:setty:advance]");
-			for(index=0; index < CVMX_PKI_NUM_PCAM_ENTRY; index++) {
+	/*vinita_to_do, later modify to use/t/t etc*/
+	for (cluster = 0; cluster < 4; cluster++) {
+		for (bank = 0; bank < 2; bank++) {
+			cvmx_dprintf("\n--------------Cluster %1d Bank %1d---------------------\n", cluster, bank);
+			cvmx_dprintf("%-10s%-17s%-19s%-18s", "index",
+				     "TERM1:TERM0", "Style1:Style0", "Data1:Data0");
+			cvmx_dprintf("%-6s", "ACTION[pmc:style_add:pf:setty:advance]");
+			for (index = 0; index < CVMX_PKI_NUM_PCAM_ENTRY; index++) {
 				pcam_term.u64 = cvmx_read_csr_node(node,
 						CVMX_PKI_CLX_PCAMX_TERMX(cluster, bank, index));
-				if(pcam_term.s.valid) {
+				if (pcam_term.s.valid) {
 					pcam_match.u64 = cvmx_read_csr_node(node,
 							CVMX_PKI_CLX_PCAMX_MATCHX(cluster, bank, index));
 					pcam_action.u64 = cvmx_read_csr_node(node,
 							CVMX_PKI_CLX_PCAMX_ACTIONX(cluster, bank, index));
-					cvmx_dprintf("\n%-13d",index);
-					cvmx_dprintf("%-2x:%x",pcam_term.s.term1,pcam_term.s.term0);
-					cvmx_dprintf("     	      %-2x:%x",pcam_term.s.style1, pcam_term.s.style0);
-					cvmx_dprintf("        %-8x:%x",pcam_match.s.data1,pcam_match.s.data0);
+					cvmx_dprintf("\n%-13d", index);
+					cvmx_dprintf("%-2x:%x", pcam_term.s.term1, pcam_term.s.term0);
+					cvmx_dprintf("     	      %-2x:%x", pcam_term.s.style1, pcam_term.s.style0);
+					cvmx_dprintf("        %-8x:%x", pcam_match.s.data1, pcam_match.s.data0);
 					cvmx_dprintf("            %-2x:%-2x       :%-1x :%2x   :%-2x",
-						pcam_action.s.pmc,pcam_action.s.style_add, pcam_action.s.pf,pcam_action.s.setty, pcam_action.s.advance);
+						pcam_action.s.pmc, pcam_action.s.style_add, pcam_action.s.pf, pcam_action.s.setty, pcam_action.s.advance);
 
 				}
 			}
@@ -1248,7 +827,7 @@ void cvmx_pki_show_valid_pcam_entries(int node)
  */
 void cvmx_pki_show_pkind_attributes(int node, int pkind)
 {
-	int cluster=0;
+	int cluster = 0;
 	int index;
 	cvmx_pki_pkindx_icgsel_t pkind_clsel;
 	cvmx_pki_clx_pkindx_style_t pkind_cfg_style;
@@ -1256,20 +835,20 @@ void cvmx_pki_show_pkind_attributes(int node, int pkind)
 	cvmx_pki_clx_stylex_cfg_t style_cfg;
 	cvmx_pki_clx_stylex_alg_t style_alg;
 
-	if(pkind >= CVMX_PKI_NUM_PKIND) {
+	if (pkind >= CVMX_PKI_NUM_PKIND) {
 		cvmx_dprintf("ERROR: PKIND %d is beyond range\n", pkind);
 		return;
 	}
 	pkind_clsel.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKINDX_ICGSEL(pkind));
 	cvmx_dprintf("cluster group:	%d\n", pkind_clsel.s.icg);
 	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(pkind_clsel.s.icg));
-	cvmx_dprintf("cluster mask of the group:	0x%x\n",pki_cl_grp.s.clusters);
+	cvmx_dprintf("cluster mask of the group:	0x%x\n", pki_cl_grp.s.clusters);
 
-	while( cluster < CVMX_PKI_NUM_CLUSTERS) {
-		if(pki_cl_grp.s.clusters & (0x01L << cluster)) {
-			//vinita_to_do later modify in human readble format or now just print register value
+	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		if (pki_cl_grp.s.clusters & (0x01L << cluster)) {
+			/*vinita_to_do later modify in human readble format or now just print register value*/
 			pkind_cfg_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(pkind, cluster));
-			cvmx_dprintf("initial parse Mode: %d\n",pkind_cfg_style.s.pm);
+			cvmx_dprintf("initial parse Mode: %d\n", pkind_cfg_style.s.pm);
 			cvmx_dprintf("initial_style: %d\n", pkind_cfg_style.s.style);
 			style_alg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(pkind_cfg_style.s.style, cluster));
 			cvmx_dprintf("style_alg: 0x%llx\n", (unsigned long long)style_alg.u64);
@@ -1282,10 +861,13 @@ void cvmx_pki_show_pkind_attributes(int node, int pkind)
 			break;
 		}
 	}
-	cvmx_dprintf("qpg base: %d\n",style_cfg.s.qpg_base);
-	cvmx_dprintf("qpg qos: %d\n",style_alg.s.qpg_qos);
-	for(index=0; index < 8; index++) {
+	cvmx_dprintf("qpg base: %d\n", style_cfg.s.qpg_base);
+	cvmx_dprintf("qpg qos: %d\n", style_alg.s.qpg_qos);
+	for (index = 0; index < 8; index++) {
 		cvmx_dprintf("qpg index %d: 0x%llx\n", (index+style_cfg.s.qpg_base),
 			     (unsigned long long)cvmx_read_csr_node(node, CVMX_PKI_QPG_TBLX(style_cfg.s.qpg_base+index)));
 	}
 }
+
+
+
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko.c b/arch/mips/cavium-octeon/executive/cvmx-pko.c
index ef78318..90bcebe 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko.c
@@ -41,12 +41,13 @@
  *
  * Support library for the hardware Packet Output unit.
  *
- * <hr>$Revision: 84412 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-pko.h>
+#include <asm/octeon/cvmx-pko3.h>
+#include <asm/octeon/cvmx-pko3-queue.h>
 #include <asm/octeon/cvmx-helper.h>
 #include <asm/octeon/cvmx-helper-cfg.h>
 #include <asm/octeon/cvmx-helper-util.h>
@@ -65,36 +66,26 @@
 #endif
 #endif
 
-/* #define PKO_DEBUG */
-
 #define CVMX_PKO_NQ_PER_PORT_MAX	32
 
+static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port,
+	int base_queue, int num_queues, const uint8_t priority[]);
+
+static const int debug = 0;
+
 /**
  * Internal state of packet output
  */
 
 /*
  * PKO port iterator
+ * XXX this macro only works for 68XX
  */
 
 #define pko_for_each_port(__p)					\
     for (__p = 0; __p < CVMX_HELPER_CFG_MAX_PKO_PORT; __p++)	\
 	if (__cvmx_helper_cfg_pko_queue_base(__p) != CVMX_HELPER_CFG_INVALID_VALUE)
 
-CVMX_SHARED cvmx_fpa_pool_config_t pko_fpa_config = {2,1024,0};
-void cvmx_pko_set_cmd_que_pool_config(int64_t pool, uint64_t buffer_size,
-				    uint64_t buffer_count)
-{
-	pko_fpa_config.pool_num = pool;
-	pko_fpa_config.buffer_size = buffer_size;
-	pko_fpa_config.buffer_count = buffer_count;
-}
-EXPORT_SYMBOL(cvmx_pko_set_cmd_que_pool_config);
-
-void cvmx_pko_get_cmd_que_pool_config(cvmx_fpa_pool_config_t *pko_pool)
-{
-	*pko_pool = pko_fpa_config;
-}
 
 /*
  * @INTERNAL
@@ -104,6 +95,8 @@ void cvmx_pko_get_cmd_que_pool_config(cvmx_fpa_pool_config_t *pko_pool)
  * @param interface
  * @param index
  * @return the INT value on success and -1 on error
+ *
+ * This function is only for CN68XX.
  */
 static int __cvmx_pko_int(int interface, int index)
 {
@@ -145,7 +138,9 @@ static int __cvmx_pko_int(int interface, int index)
 
 int cvmx_pko_get_base_pko_port(int interface, int index)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKND))
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		return cvmx_helper_get_ipd_port(interface, index);
+	else if (octeon_has_feature(OCTEON_FEATURE_PKND))
 		return __cvmx_helper_cfg_pko_port_base(interface, index);
 	else
 		return cvmx_helper_get_ipd_port(interface, index);
@@ -154,6 +149,8 @@ EXPORT_SYMBOL(cvmx_pko_get_base_pko_port);
 
 int cvmx_pko_get_num_pko_ports(int interface, int index)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		return 1;
 	if (octeon_has_feature(OCTEON_FEATURE_PKND))
 		return __cvmx_helper_cfg_pko_port_num(interface, index);
 	else
@@ -163,7 +160,9 @@ EXPORT_SYMBOL(cvmx_pko_get_num_pko_ports);
 
 int cvmx_pko_get_base_queue(int port)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		return cvmx_pko3_get_queue_base(port);
+	else if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		return __cvmx_helper_cfg_pko_queue_base(cvmx_helper_cfg_ipd2pko_port_base(port));
 	} else {
 		if (port < 48)
@@ -183,6 +182,8 @@ EXPORT_SYMBOL(cvmx_pko_get_base_queue);
  */
 int cvmx_pko_get_base_queue_pkoid(int pko_port)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		return cvmx_pko3_get_queue_base(pko_port);
 	return __cvmx_helper_cfg_pko_queue_base(pko_port);
 }
 
@@ -195,12 +196,16 @@ int cvmx_pko_get_base_queue_pkoid(int pko_port)
  */
 int cvmx_pko_get_num_queues_pkoid(int pko_port)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		return cvmx_pko3_get_queue_num(pko_port);
 	return __cvmx_helper_cfg_pko_queue_num(pko_port);
 }
 
 int cvmx_pko_get_num_queues(int port)
 {
-	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		return cvmx_pko3_get_queue_num(port);
+	else if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		return __cvmx_helper_cfg_pko_queue_num(cvmx_helper_cfg_ipd2pko_port_base(port));
 	} else {
 		if (port < 48)
@@ -210,199 +215,42 @@ int cvmx_pko_get_num_queues(int port)
 }
 EXPORT_SYMBOL(cvmx_pko_get_num_queues);
 
-#ifdef PKO_DEBUG
 /**
  * Show queues for the internal ports
  */
 void cvmx_pko_show_queue_map(void)
 {
-	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_dprintf("%s: not supported on this chip\n",__FUNCTION__);
+		return;
+	} else if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		int port;
 		pko_for_each_port(port) {
 			cvmx_dprintf("pko_port %d (interface%d index%d) has %d queues (queue base = %d)\n",
-				     port,
-				     __cvmx_helper_cfg_pko_port_interface(port),
-				     __cvmx_helper_cfg_pko_port_index(port), __cvmx_helper_cfg_pko_queue_num(port), __cvmx_helper_cfg_pko_queue_base(port));
+				port,
+				__cvmx_helper_cfg_pko_port_interface(port),
+				__cvmx_helper_cfg_pko_port_index(port),
+				__cvmx_helper_cfg_pko_queue_num(port),
+				__cvmx_helper_cfg_pko_queue_base(port));
 		}
 	} else {
 		int port;
 		int pko_output_ports;
-		pko_output_ports = 36;
+		pko_output_ports = 40;
 		cvmx_dprintf("pko queue info \n");
 		for (port = 0; port < pko_output_ports; port++) {
-			cvmx_dprintf("%3d=%3d ", port, cvmx_pko_get_base_queue(port));
-			if (((port+1) % 8) == 0)
+			cvmx_dprintf("%3d=%3d-%3d ",
+				port,
+				cvmx_pko_get_base_queue(port),
+				cvmx_pko_get_base_queue(port)+
+					cvmx_pko_get_num_queues(port)-1
+				);
+			if (((port+1) % 4) == 0)
 				cvmx_dprintf("\n");
 		}
 		cvmx_dprintf("\n");
 	}
 }
-#endif /* PKO_DEBUG */
-
-/*
- * Configure queues for an internal port.
- * @INTERNAL
- * @param pko_port PKO internal port number
- * Note: o68 only
- */
-static void __cvmx_pko_iport_config(int pko_port)
-{
-	int queue, base_queue, num_queues;
-	int static_priority_base;
-	int static_priority_end;
-	union cvmx_pko_mem_iqueue_ptrs config;
-	uint64_t *buf_ptr = NULL;
-	uint64_t priorities[CVMX_PKO_NQ_PER_PORT_MAX] = {
-		[0 ... CVMX_PKO_NQ_PER_PORT_MAX - 1] = 8
-	};
-	int outputbuffer_pool = (int)cvmx_fpa_get_pko_pool();
-	uint64_t outputbuffer_pool_size = cvmx_fpa_get_pko_pool_block_size();
-
-	static_priority_base = -1;
-	static_priority_end = -1;
-	base_queue = __cvmx_helper_cfg_pko_queue_base(pko_port);
-	num_queues = __cvmx_helper_cfg_pko_queue_num(pko_port);
-
-	/*
-	 * Give the user a chance to override the per queue priorities.
-	 */
-	if (cvmx_override_pko_queue_priority)
-		cvmx_override_pko_queue_priority(pko_port, &priorities[0]);
-
-	/*
-	 * static queue priority validation
-	 */
-	for (queue = 0; queue < num_queues; queue++) {
-		if (static_priority_base == -1 && priorities[queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY)
-			static_priority_base = queue;
-
-		if (static_priority_base != -1 && static_priority_end == -1 && priorities[queue] != CVMX_PKO_QUEUE_STATIC_PRIORITY && queue)
-			static_priority_end = queue - 1;
-		else if (static_priority_base != -1 && static_priority_end == -1 && queue == num_queues - 1)
-			static_priority_end = queue;	/* all queues are static priority */
-
-		/*
-		 * Check to make sure all static priority queues are contiguous.
-		 * Also catches some cases of static priorites not starting from
-		 * queue 0.
-		 */
-		if (static_priority_end != -1 && (int)queue > static_priority_end && priorities[queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY) {
-			cvmx_dprintf("ERROR: __cvmx_pko_iport_config: Static priority "
-				     "queues aren't contiguous or don't start at base queue. " "q: %d, eq: %d\n", (int)queue, static_priority_end);
-		}
-		if (static_priority_base > 0) {
-			cvmx_dprintf("ERROR: __cvmx_pko_iport_config: Static priority " "queues don't start at base queue. sq: %d\n", static_priority_base);
-		}
-	}
-
-	/*
-	 * main loop to set the fields of CVMX_PKO_MEM_IQUEUE_PTRS for
-	 * each queue
-	 */
-	for (queue = 0; queue < num_queues; queue++) {
-		config.u64 = 0;
-		config.s.index = queue;
-		config.s.qid = base_queue + queue;
-		config.s.ipid = pko_port;
-		config.s.tail = (queue == (num_queues - 1));
-		config.s.s_tail = (queue == static_priority_end);
-		config.s.static_p = (static_priority_base >= 0);
-		config.s.static_q = (queue <= static_priority_end);
-
-		/*
-		 * Convert the priority into an enable bit field.
-		 * Try to space the bits out evenly so the packet
-		 * don't get grouped up.
-		 */
-		switch ((int)priorities[queue]) {
-		case 0:
-			config.s.qos_mask = 0x00;
-			break;
-		case 1:
-			config.s.qos_mask = 0x01;
-			break;
-		case 2:
-			config.s.qos_mask = 0x11;
-			break;
-		case 3:
-			config.s.qos_mask = 0x49;
-			break;
-		case 4:
-			config.s.qos_mask = 0x55;
-			break;
-		case 5:
-			config.s.qos_mask = 0x57;
-			break;
-		case 6:
-			config.s.qos_mask = 0x77;
-			break;
-		case 7:
-			config.s.qos_mask = 0x7f;
-			break;
-		case 8:
-			config.s.qos_mask = 0xff;
-			break;
-		case CVMX_PKO_QUEUE_STATIC_PRIORITY:
-			config.s.qos_mask = 0xff;
-			break;
-		default:
-			cvmx_dprintf("ERROR: __cvmx_pko_iport_config: " "Invalid priority %llu\n",
-				     (unsigned long long)priorities[queue]);
-			config.s.qos_mask = 0xff;
-			break;
-		}
-
-		/*
-		 * The command queues
-		 */
-		{
-			cvmx_cmd_queue_result_t cmd_res;
-
-			cmd_res = cvmx_cmd_queue_initialize(CVMX_CMD_QUEUE_PKO(base_queue + queue),
-							    CVMX_PKO_MAX_QUEUE_DEPTH,
-							    outputbuffer_pool,
-							    (outputbuffer_pool_size - CVMX_PKO_COMMAND_BUFFER_SIZE_ADJUST * 8));
-
-			if (cmd_res != CVMX_CMD_QUEUE_SUCCESS) {
-				switch (cmd_res) {
-				case CVMX_CMD_QUEUE_NO_MEMORY:
-					cvmx_dprintf("ERROR: __cvmx_pko_iport_config: Unable to allocate output buffer.");
-					break;
-				case CVMX_CMD_QUEUE_ALREADY_SETUP:
-					cvmx_dprintf("ERROR: __cvmx_pko_iport_config: Port already setup");
-					break;
-				case CVMX_CMD_QUEUE_INVALID_PARAM:
-				default:
-					cvmx_dprintf("ERROR: __cvmx_pko_iport_config: Command queue initialization failed.");
-					break;
-				}
-				cvmx_dprintf(" pko_port%d base_queue%d num_queues%d queue%d.\n",
-					     pko_port, base_queue, num_queues, queue);
-			}
-
-			buf_ptr = (uint64_t *) cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_PKO(base_queue + queue));
-			config.s.buf_ptr = cvmx_ptr_to_phys(buf_ptr) >> 7;
-		}
-
-		CVMX_SYNCWS;
-		cvmx_write_csr(CVMX_PKO_MEM_IQUEUE_PTRS, config.u64);
-	}
-}
-
-/*
- * Allocate queues for the PKO internal ports.
- * @INTERNAL
- *
- */
-static void __cvmx_pko_queue_alloc_o68(void)
-{
-	int port;
-
-	pko_for_each_port(port) {
-		__cvmx_pko_iport_config(port);
-	}
-
-}
 
 /*
  * Allocate memory for PKO engines.
@@ -437,10 +285,10 @@ static int __cvmx_pko_memory_per_engine_o68(int engine)
 }
 
 /*
- * Setup one-to-one mapping between PKO iport and eport.
+ * Setup one-to-one mapping between PKO2 iport and eport.
  * @INTERNAL
  */
-static void __cvmx_pko_port_map_o68(void)
+static void __cvmx_pko2_chip_init(void)
 {
 	int i;
 	int interface, index, port;
@@ -450,9 +298,9 @@ static void __cvmx_pko_port_map_o68(void)
 	/*
 	 * Initialize every iport with the invalid eid.
 	 */
-#define CVMX_O68_PKO_INVALID_EID	31
+#define CVMX_O68_PKO2_INVALID_EID	31
 	config.u64 = 0;
-	config.s.eid = CVMX_O68_PKO_INVALID_EID;
+	config.s.eid = CVMX_O68_PKO2_INVALID_EID;
 	for (i = 0; i < CVMX_HELPER_CFG_MAX_PKO_PORT; i++) {
 		config.s.ipid = i;
 		cvmx_write_csr(CVMX_PKO_MEM_IPORT_PTRS, config.u64);
@@ -489,22 +337,30 @@ int __cvmx_pko_get_pipe(int interface, int index)
 	return cvmx_helper_get_pko_port(interface, index);
 }
 
-/*
- * chip-specific setup
- * @INTERNAL
- */
-static void __cvmx_pko_chip_init(void)
+static void __cvmx_pko1_chip_init(void)
 {
-	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
-		__cvmx_pko_port_map_o68();
-		__cvmx_pko_queue_alloc_o68();
-	} else {
-		int i;
-		uint64_t priority = 8;
+	int queue;
+	union cvmx_pko_mem_queue_ptrs config;
+	union cvmx_pko_reg_queue_ptrs1 config1;
+	const int port = CVMX_PKO_MEM_QUEUE_PTRS_ILLEGAL_PID;
+
+	/* Initialize all queues to connect to port 63 (ILLEGAL_PID) */
+	for (queue = 0; queue < CVMX_PKO_MAX_OUTPUT_QUEUES; queue++) {
+		config1.u64 = 0;
+		config1.s.idx3 = 0;
+		config1.s.qid7 = queue >> 7;
 
-		/*Initialize queues. */
-		for (i = 0; i < CVMX_PKO_MAX_OUTPUT_QUEUES; i++)
-			cvmx_pko_config_port(CVMX_PKO_MEM_QUEUE_PTRS_ILLEGAL_PID, i, 1, &priority);
+		config.u64 = 0;
+		config.s.tail = 1;
+		config.s.index = 0;
+		config.s.port = port;
+		config.s.queue = queue;
+		config.s.buf_ptr = 0;
+
+		if (!OCTEON_IS_MODEL(OCTEON_CN3XXX)) {
+			cvmx_write_csr(CVMX_PKO_REG_QUEUE_PTRS1, config1.u64);
+		}
+		cvmx_write_csr(CVMX_PKO_MEM_QUEUE_PTRS, config.u64);
 	}
 }
 
@@ -513,40 +369,54 @@ static void __cvmx_pko_chip_init(void)
  * output system.  This does chip global config, and should only be
  * done by one core.
  */
-
-void cvmx_pko_initialize_global(void)
+void cvmx_pko_hw_init(uint8_t pool, unsigned bufsize)
 {
 	union cvmx_pko_reg_cmd_buf config;
+	union cvmx_iob_fau_timeout fau_to;
 	int i;
-    	int outputbuffer_pool = (int)cvmx_fpa_get_pko_pool();
-    	uint64_t outputbuffer_pool_size = cvmx_fpa_get_pko_pool_block_size();
-	uint64_t outputbuffer_pool_count;
-
-	outputbuffer_pool_count = cvmx_fpa_get_pko_pool_buffer_count();
-	/** It allocate pools for pko command queues */
-#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	cvmx_fpa_global_initialize();
-	if(outputbuffer_pool_count != 0)
-		__cvmx_helper_initialize_fpa_pool(outputbuffer_pool, outputbuffer_pool_size,
-			outputbuffer_pool_count, "Pko Cmd Buffers");
-#endif
 
-#ifdef CVMX_BUILD_FOR_STANDALONE
-	__cvmx_install_gmx_error_handler_for_xaui();
-#endif
-	__cvmx_helper_init_port_config_data();
+	if (debug)
+		cvmx_dprintf("%s: pool=%u bufsz=%u\n", __func__, pool, bufsize);
+
+	/* chip-specific setup. */
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+		__cvmx_pko2_chip_init();
+	} else {
+		__cvmx_pko1_chip_init();
+	}
+
 	/*
 	 * Set the size of the PKO command buffers to an odd number of
 	 * 64bit words. This allows the normal two word send to stay
 	 * aligned and never span a command word buffer.
 	 */
 	config.u64 = 0;
-	config.s.pool = outputbuffer_pool;
-	config.s.size = outputbuffer_pool_size / 8 - 1;
+	config.s.pool = pool;
+	config.s.size = bufsize / 8 - 1;
 	cvmx_write_csr(CVMX_PKO_REG_CMD_BUF, config.u64);
 
-	/* chip-specific setup. */
-	__cvmx_pko_chip_init();
+	/*
+	 * Disable tagwait FAU timeout. This needs to be done before
+	 * anyone might start packet output using tags.
+	 */
+	fau_to.u64 = 0;
+	fau_to.s.tout_val = 0xfff;
+	fau_to.s.tout_enb = 0;
+	cvmx_write_csr(CVMX_IOB_FAU_TIMEOUT, fau_to.u64);
+
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+		union cvmx_pko_reg_min_pkt min_pkt;
+
+		min_pkt.u64 = 0;
+		min_pkt.s.size1 = 59;
+		min_pkt.s.size2 = 59;
+		min_pkt.s.size3 = 59;
+		min_pkt.s.size4 = 59;
+		min_pkt.s.size5 = 59;
+		min_pkt.s.size6 = 59;
+		min_pkt.s.size7 = 59;
+		cvmx_write_csr(CVMX_PKO_REG_MIN_PKT, min_pkt.u64);
+	}
 
 	/*
 	 * If we aren't using all of the queues optimize PKO's
@@ -606,20 +476,6 @@ void cvmx_pko_initialize_global(void)
 }
 
 /**
- * This function does per-core initialization required by the PKO routines.
- * This must be called on all cores that will do packet output, and must
- * be called after the FPA has been initialized and filled with pages.
- *
- * @return 0 on success
- *         !0 on failure
- */
-int cvmx_pko_initialize_local(void)
-{
-	/* Nothing to do */
-	return 0;
-}
-
-/**
  * Enables the packet output hardware. It must already be
  * configured.
  */
@@ -703,6 +559,7 @@ void cvmx_pko_shutdown(void)
 	}
 
 	__cvmx_pko_reset();
+	cvmx_pko_queue_free_all();
 }
 
 /**
@@ -722,12 +579,12 @@ void cvmx_pko_shutdown(void)
  *                   queues have higher priority than higher numbered queues.
  *                   There must be num_queues elements in the array.
  */
-cvmx_pko_return_value_t cvmx_pko_config_port(uint64_t port, uint64_t base_queue,
-				       uint64_t num_queues,
-				       const uint64_t priority[])
+cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue,
+				       int num_queues,
+				       const uint8_t priority[])
 {
 	cvmx_pko_return_value_t result_code;
-	uint64_t queue;
+	int queue;
 	union cvmx_pko_mem_queue_ptrs config;
 	union cvmx_pko_reg_queue_ptrs1 config1;
 	int static_priority_base = -1;
@@ -735,19 +592,34 @@ cvmx_pko_return_value_t cvmx_pko_config_port(uint64_t port, uint64_t base_queue,
 	int outputbuffer_pool = (int)cvmx_fpa_get_pko_pool();
 	uint64_t outputbuffer_pool_size = cvmx_fpa_get_pko_pool_block_size();
 
+	/* This function is not used for CN68XX */
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
-		return CVMX_PKO_SUCCESS;
+		return  cvmx_pko2_config_port(port, base_queue, num_queues, priority);
+
+	if (debug)
+		cvmx_dprintf("%s: port=%d queue=%d-%d pri %#x %#x %#x %#x\n",
+			__func__,
+			port, base_queue, (base_queue+num_queues-1),
+			priority[0],priority[1], priority[2], priority[3]);
+
+	/* FIXME: the need to handle ILLEGAL_PID port argument
+	 * is obsolete now, the code here can be simplified.
+	 */
 
 	if ((port >= CVMX_PKO_NUM_OUTPUT_PORTS) &&
 	    (port != CVMX_PKO_MEM_QUEUE_PTRS_ILLEGAL_PID)) {
-		cvmx_dprintf("ERROR: cvmx_pko_config_port: Invalid port %llu\n",
+		cvmx_dprintf("ERROR: %s: Invalid port %llu\n", __func__,
 			     (unsigned long long)port);
 		return CVMX_PKO_INVALID_PORT;
 	}
 
 	if (base_queue + num_queues > CVMX_PKO_MAX_OUTPUT_QUEUES) {
-		cvmx_dprintf("ERROR: cvmx_pko_config_port: Invalid queue range port = %lld base=%llu numques=%lld\n",
-			     (unsigned long long) port, (unsigned long long) base_queue, (unsigned long long) num_queues);
+		cvmx_dprintf("ERROR: %s: "
+			"Invalid queue range port = %lld base=%llu numques=%lld\n",
+			__func__,
+			(unsigned long long) port,
+			(unsigned long long) base_queue,
+			(unsigned long long) num_queues);
 		return CVMX_PKO_INVALID_QUEUE;
 	}
 
@@ -869,14 +741,20 @@ cvmx_pko_return_value_t cvmx_pko_config_port(uint64_t port, uint64_t base_queue,
 			if (cmd_res != CVMX_CMD_QUEUE_SUCCESS) {
 				switch (cmd_res) {
 				case CVMX_CMD_QUEUE_NO_MEMORY:
-					cvmx_dprintf("ERROR: cvmx_pko_config_port: " "Unable to allocate output buffer.\n");
+					cvmx_dprintf("ERROR: %s: "
+					"Unable to allocate output buffer\n",
+					__func__);
 					return (CVMX_PKO_NO_MEMORY);
 				case CVMX_CMD_QUEUE_ALREADY_SETUP:
-					cvmx_dprintf("ERROR: cvmx_pko_config_port: " "Port already setup. port=%d \n", (int) port);
+					cvmx_dprintf("ERROR: %s: "
+					"Port already setup. port=%d \n",
+					__func__, (int) port);
 					return (CVMX_PKO_PORT_ALREADY_SETUP);
 				case CVMX_CMD_QUEUE_INVALID_PARAM:
 				default:
-					cvmx_dprintf("ERROR: cvmx_pko_config_port: " "Command queue initialization failed.\n");
+					cvmx_dprintf("ERROR: %s: "
+					"Command queue initialization failed.\n",
+					__func__);
 					return (CVMX_PKO_CMD_QUEUE_INIT_ERROR);
 				}
 			}
@@ -898,6 +776,160 @@ cvmx_pko_return_value_t cvmx_pko_config_port(uint64_t port, uint64_t base_queue,
 	return result_code;
 }
 
+/*
+ * Configure queues for an internal port.
+ * @INTERNAL
+ * @param pko_port PKO internal port number
+ * FIXME: for PKO2 only, equivalent to cvmx_pko_config_port()
+ */
+static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port, int base_queue,
+				       int num_queues,
+				       const uint8_t priority[])
+{
+	int queue, pko_port;
+	int static_priority_base;
+	int static_priority_end;
+	union cvmx_pko_mem_iqueue_ptrs config;
+	uint64_t *buf_ptr = NULL;
+	int outputbuffer_pool = (int)cvmx_fpa_get_pko_pool();
+	uint64_t outputbuffer_pool_size = cvmx_fpa_get_pko_pool_block_size();
+
+	pko_port = cvmx_helper_cfg_ipd2pko_port_base(ipd_port);
+
+	if (debug)
+		cvmx_dprintf("%s: ipd_port %d pko_iport %d qbase %d qnum %d\n",
+		__func__, ipd_port, pko_port, base_queue, num_queues );
+
+	static_priority_base = -1;
+	static_priority_end = -1;
+
+	/*
+	 * static queue priority validation
+	 */
+	for (queue = 0; queue < num_queues; queue++) {
+		if (static_priority_base == -1 && priority[queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY)
+			static_priority_base = queue;
+
+		if (static_priority_base != -1 && static_priority_end == -1 && priority[queue] != CVMX_PKO_QUEUE_STATIC_PRIORITY && queue)
+			static_priority_end = queue - 1;
+		else if (static_priority_base != -1 && static_priority_end == -1 && queue == num_queues - 1)
+			static_priority_end = queue;	/* all queues are static priority */
+
+		/*
+		 * Check to make sure all static priority queues are contiguous.
+		 * Also catches some cases of static priorites not starting from
+		 * queue 0.
+		 */
+		if (static_priority_end != -1 && (int)queue > static_priority_end && priority[queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY) {
+			cvmx_dprintf("ERROR: %s: Static priority "
+			     "queues aren't contiguous or don't start at base queue. "
+		"q: %d, eq: %d\n", __func__, (int)queue, static_priority_end);
+		}
+		if (static_priority_base > 0) {
+			cvmx_dprintf("ERROR: %s: Static priority " "queues don't start at base queue. sq: %d\n", __func__, static_priority_base);
+		}
+	}
+
+	/*
+	 * main loop to set the fields of CVMX_PKO_MEM_IQUEUE_PTRS for
+	 * each queue
+	 */
+	for (queue = 0; queue < num_queues; queue++) {
+		config.u64 = 0;
+		config.s.index = queue;
+		config.s.qid = base_queue + queue;
+		config.s.ipid = pko_port;
+		config.s.tail = (queue == (num_queues - 1));
+		config.s.s_tail = (queue == static_priority_end);
+		config.s.static_p = (static_priority_base >= 0);
+		config.s.static_q = (queue <= static_priority_end);
+
+		/*
+		 * Convert the priority into an enable bit field.
+		 * Try to space the bits out evenly so the packet
+		 * don't get grouped up.
+		 */
+		switch ((int)priority[queue]) {
+		case 0:
+			config.s.qos_mask = 0x00;
+			break;
+		case 1:
+			config.s.qos_mask = 0x01;
+			break;
+		case 2:
+			config.s.qos_mask = 0x11;
+			break;
+		case 3:
+			config.s.qos_mask = 0x49;
+			break;
+		case 4:
+			config.s.qos_mask = 0x55;
+			break;
+		case 5:
+			config.s.qos_mask = 0x57;
+			break;
+		case 6:
+			config.s.qos_mask = 0x77;
+			break;
+		case 7:
+			config.s.qos_mask = 0x7f;
+			break;
+		case 8:
+			config.s.qos_mask = 0xff;
+			break;
+		case CVMX_PKO_QUEUE_STATIC_PRIORITY:
+			config.s.qos_mask = 0xff;
+			break;
+		default:
+			cvmx_dprintf("ERROR: %s: " "Invalid priority %llu\n",
+				__func__,
+				     (unsigned long long)priority[queue]);
+			config.s.qos_mask = 0xff;
+			break;
+		}
+
+		/*
+		 * The command queues
+		 */
+		{
+			cvmx_cmd_queue_result_t cmd_res;
+
+			cmd_res = cvmx_cmd_queue_initialize(CVMX_CMD_QUEUE_PKO(base_queue + queue),
+							    CVMX_PKO_MAX_QUEUE_DEPTH,
+							    outputbuffer_pool,
+							    (outputbuffer_pool_size - CVMX_PKO_COMMAND_BUFFER_SIZE_ADJUST * 8));
+
+			if (cmd_res != CVMX_CMD_QUEUE_SUCCESS) {
+				switch (cmd_res) {
+				case CVMX_CMD_QUEUE_NO_MEMORY:
+					cvmx_dprintf("ERROR: %s: Unable to allocate output buffer\n",__func__);
+					break;
+				case CVMX_CMD_QUEUE_ALREADY_SETUP:
+					cvmx_dprintf("ERROR: %s: Port already setup\n",__func__);
+					break;
+				case CVMX_CMD_QUEUE_INVALID_PARAM:
+				default:
+					cvmx_dprintf("ERROR: %s: "
+					"Command queue initialization failed.",
+					__func__);
+					break;
+				}
+				cvmx_dprintf(" pko_port%d base_queue%d num_queues%d queue%d.\n",
+					     pko_port, base_queue, num_queues, queue);
+			}
+
+			buf_ptr = (uint64_t *) cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_PKO(base_queue + queue));
+			config.s.buf_ptr = cvmx_ptr_to_phys(buf_ptr) >> 7;
+		}
+
+		CVMX_SYNCWS;
+		cvmx_write_csr(CVMX_PKO_MEM_IQUEUE_PTRS, config.u64);
+	}
+
+// FIXME: detect errors
+	return 0;
+}
+
 /**
  * Rate limit a PKO port to a max packets/sec. This function is only
  * supported on CN51XX and higher, excluding CN58XX.
@@ -967,3 +999,113 @@ int cvmx_pko_rate_limit_bits(int port, uint64_t bits_s, int burst)
 	cvmx_write_csr(CVMX_PKO_MEM_PORT_RATE1, pko_mem_port_rate1.u64);
 	return 0;
 }
+
+/**
+ * Get the status counters for a port.
+ *
+ * @param ipd_port Port number (ipd_port) to get statistics for.
+ * @param clear    Set to 1 to clear the counters after they are read
+ * @param status   Where to put the results.
+ *
+ * Note:
+ *     - Only the doorbell for the base queue of the ipd_port is
+ *       collected.
+ *     - Retrieving the stats involves writing the index through
+ *       CVMX_PKO_REG_READ_IDX and reading the stat CSRs, in that
+ *       order. It is not MP-safe and caller should guarantee
+ *       atomicity.
+ */
+void cvmx_pko_get_port_status(uint64_t ipd_port, uint64_t clear, cvmx_pko_port_status_t * status)
+{
+	cvmx_pko_reg_read_idx_t pko_reg_read_idx;
+	cvmx_pko_mem_count0_t pko_mem_count0;
+	cvmx_pko_mem_count1_t pko_mem_count1;
+	int pko_port, port_base, port_limit;
+
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_pko3_get_legacy_port_stats(ipd_port, clear, status);
+		return;
+	} else if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
+		int interface = cvmx_helper_get_interface_num(ipd_port);
+		int index = cvmx_helper_get_interface_index_num(ipd_port);
+		port_base = cvmx_helper_get_pko_port(interface, index);
+		if (port_base == -1)
+			cvmx_dprintf("Warning: Invalid port_base\n");
+		port_limit = port_base + cvmx_pko_get_num_pko_ports(interface, index);
+	} else {
+		port_base = ipd_port;
+		port_limit = port_base + 1;
+	}
+
+	/*
+	 * status->packets and status->octets
+	 */
+	status->packets = 0;
+	status->octets = 0;
+	pko_reg_read_idx.u64 = 0;
+
+	for (pko_port = port_base; pko_port < port_limit; pko_port++) {
+
+		/*
+		 * In theory, one doesn't need to write the index csr every
+		 * time as he can set pko_reg_read_idx.s.inc to increment
+		 * the index automatically. Need to find out exactly how XXX.
+		 */
+		pko_reg_read_idx.s.index = pko_port;
+		cvmx_write_csr(CVMX_PKO_REG_READ_IDX, pko_reg_read_idx.u64);
+
+		pko_mem_count0.u64 = cvmx_read_csr(CVMX_PKO_MEM_COUNT0);
+		status->packets += pko_mem_count0.s.count;
+		if (clear) {
+			pko_mem_count0.s.count = pko_port;
+			cvmx_write_csr(CVMX_PKO_MEM_COUNT0, pko_mem_count0.u64);
+		}
+
+		pko_mem_count1.u64 = cvmx_read_csr(CVMX_PKO_MEM_COUNT1);
+		status->octets += pko_mem_count1.s.count;
+		if (clear) {
+			pko_mem_count1.s.count = pko_port;
+			cvmx_write_csr(CVMX_PKO_MEM_COUNT1, pko_mem_count1.u64);
+		}
+	}
+
+	/*
+	 * status->doorbell
+	 */
+	if (OCTEON_IS_MODEL(OCTEON_CN3XXX)) {
+		cvmx_pko_mem_debug9_t debug9;
+		pko_reg_read_idx.s.index = cvmx_pko_get_base_queue(ipd_port);
+		cvmx_write_csr(CVMX_PKO_REG_READ_IDX, pko_reg_read_idx.u64);
+		debug9.u64 = cvmx_read_csr(CVMX_PKO_MEM_DEBUG9);
+		status->doorbell = debug9.cn38xx.doorbell;
+	} else {
+		cvmx_pko_mem_debug8_t debug8;
+		pko_reg_read_idx.s.index = cvmx_pko_get_base_queue(ipd_port);
+		cvmx_write_csr(CVMX_PKO_REG_READ_IDX, pko_reg_read_idx.u64);
+		debug8.u64 = cvmx_read_csr(CVMX_PKO_MEM_DEBUG8);
+		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+			status->doorbell = debug8.cn68xx.doorbell;
+		else
+			status->doorbell = debug8.cn58xx.doorbell;
+	}
+}
+EXPORT_SYMBOL(cvmx_pko_get_port_status);
+
+/*
+ * Obtain the number of PKO commands pending in a queue
+ *
+ * @param queue is the queue identifier to be queried
+ * @return the number of commands pending transmission or -1 on error
+ */
+int cvmx_pko_queue_pend_count( cvmx_cmd_queue_id_t queue)
+{
+	int count;
+
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		int node = cvmx_get_node_num();
+		count = cvmx_pko3_dq_query(node,queue);
+	} else {
+		count = cvmx_cmd_queue_length(CVMX_CMD_QUEUE_PKO(queue));
+	}
+	return count;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
new file mode 100644
index 0000000..952635f
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
@@ -0,0 +1,775 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+
+/*
+ * File version info: $Rev:$
+ *
+ */
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <linux/module.h>
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-pko3.h>
+#include <asm/octeon/cvmx-helper-pko3.h>
+#include <asm/octeon/cvmx-bootmem.h>
+#else
+#include "cvmx.h"
+#include "cvmx-pko3.h"
+#include "cvmx-helper-pko3.h"
+#include "cvmx-bootmem.h"
+#endif
+
+
+
+/* Smalles Round-Robin quantum to use +1 */
+#define	CVMX_PKO3_RR_QUANTUM_MIN	0x10
+
+static int debug = 0;
+
+/*
+ * @INTERNAL
+ * Descriptor Queue to IPD port mapping table.
+ *
+ * This pointer is per-core, contains the virtual address
+ * of a global named block which has 2^12 entries per each
+ * possible node.
+ */
+struct cvmx_pko3_dq_s *__cvmx_pko3_dq_table = NULL;
+
+/**
+ * @INTERNAL
+ *
+ * Initialize port/dq table contents
+ */
+static void __cvmx_pko3_dq_table_init(void *ptr)
+{
+	unsigned size =
+		sizeof(struct cvmx_pko3_dq_s) *
+		CVMX_PKO3_IPD_NUM_MAX * CVMX_MAX_NODES;
+
+	memset(ptr, 0, size);
+}
+
+/**
+ * @INTERNAL
+ *
+ * Find or allocate global port/dq map table
+ * which is a named table, contains entries for
+ * all possible OCI nodes.
+ *
+ * The table global pointer is stored in core-local variable
+ * so that every core will call this function once, on first use.
+ */
+int __cvmx_pko3_dq_table_setup(void)
+{
+	void *ptr;
+
+	ptr = cvmx_bootmem_alloc_named_range_once(
+		/* size */
+		sizeof(struct cvmx_pko3_dq_s) *
+			CVMX_PKO3_IPD_NUM_MAX * CVMX_MAX_NODES,
+		/* min_addr, max_addr, align */
+		0ull, 0ull, sizeof(struct cvmx_pko3_dq_s),
+		/* name */
+		"cvmx_pko3_global_dq_table",
+		__cvmx_pko3_dq_table_init);
+
+	if(ptr == NULL)
+		return -1;
+
+	__cvmx_pko3_dq_table = ptr;
+	return 0;
+}
+
+/*
+ * @INTERNAL
+ * Register a range of Descriptor Queues wth an interface port
+ *
+ * This function poulates the DQ-to-IPD translation table
+ * used by the application to retreive the DQ range (typically ordered
+ * by priority) for a given IPD-port, which is either a physical port,
+ * or a channel on a channelized interface (i.e. ILK).
+ *
+ * @param interface is the physical interface number
+ * @param port is either a physical port on an interface
+ * @param or a channel of an ILK interface
+ * @param dq_base is the first Descriptor Queue number in a consecutive range
+ * @param dq_count is the number of consecutive Descriptor Queues leading
+ * @param the same channel or port.
+ *
+ * Only a consecurive range of Descriptor Queues can be associated with any
+ * given channel/port, and usually they are ordered from most to least
+ * in terms of scheduling priority.
+ *
+ * Note: thus function only populates the node-local translation table.
+ *
+ * @returns 0 on success, -1 on failure.
+ */
+int __cvmx_pko3_ipd_dq_register(unsigned interface, unsigned port,
+		unsigned dq_base, unsigned dq_count)
+{
+	struct cvmx_pko3_dq_s *dq_table;
+	uint16_t ipd_port = cvmx_helper_get_ipd_port(interface, port);
+	unsigned node = cvmx_get_node_num();
+	unsigned i;
+
+	i = CVMX_PKO3_SWIZZLE_IPD ^ (ipd_port & (CVMX_PKO3_IPD_NUM_MAX-1));
+
+	/* get per-node table */
+	if(__cvmx_pko3_dq_table == NULL)
+		__cvmx_pko3_dq_table_setup();
+
+	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * node;
+
+	/* Check the IPD port has not already been configured */
+	if(dq_table[i].dq_count > 0 ) {
+		cvmx_dprintf("%s: ERROR: IPD %#x already registered\n",
+			__FUNCTION__, ipd_port);
+		return -1;
+	}
+
+	/* Store DQ# range in the queue lookup table */
+	dq_table[i].dq_base = dq_base;
+	dq_table[i].dq_count = dq_count;
+
+	if(debug)
+		cvmx_dprintf("%s: ipd=%#x dq %u cnt %u\n",
+			__FUNCTION__, ipd_port, dq_base, dq_count);
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ *
+ * Unregister DQs associated with CHAN_E (IPD port)
+ */
+int __cvmx_pko3_ipd_dq_unregister(unsigned interface, unsigned port)
+{
+	struct cvmx_pko3_dq_s *dq_table;
+	uint16_t ipd_port = cvmx_helper_get_ipd_port(interface, port);
+	unsigned node = cvmx_get_node_num();
+	unsigned i;
+
+	i = CVMX_PKO3_SWIZZLE_IPD ^ (ipd_port & (CVMX_PKO3_IPD_NUM_MAX-1));
+
+	/* get per-node table */
+	if(__cvmx_pko3_dq_table == NULL)
+		__cvmx_pko3_dq_table_setup();
+
+	/* get per-node table */
+	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * node;
+
+	if(debug)
+		cvmx_dprintf("%s:ipd=%#x release dq %u cnt %u\n",
+			__FUNCTION__, ipd_port, 
+			dq_table[i].dq_base, 
+			dq_table[i].dq_count);
+
+	dq_table[i].dq_count = 0;
+
+	return 0;
+}
+
+/*
+ * @INTERNAL
+ * Convert normal CHAN_E (i.e. IPD port) value to compressed channel form
+ * that is used to populate PKO_LUT.
+ *
+ * Note: This code may be CN78XX specific, not the same for all PKO3
+ * implementations.
+ */
+static uint16_t cvmx_pko3_chan_2_xchan(uint16_t ipd_port)
+{
+	uint16_t xchan;
+	uint8_t off;
+	static const uint8_t xchan_base[16] = {
+		/* IPD 0x000 */ 0x3c0 >> 4,	/* LBK */
+		/* IPD 0x100 */ 0x380 >> 4,	/* DPI */
+		/* IPD 0x200 */ 0xff,		/* not used */
+		/* IPD 0x300 */ 0xff,		/* not used */
+		/* IPD 0x400 */ 0x000 >> 4,	/* ILK0 */
+		/* IPD 0x500 */ 0x100 >> 4,	/* ILK1 */
+		/* IPD 0x600 */ 0xfff >> 4,	/* not used */
+		/* IPD 0x700 */ 0xfff >> 4,	/* not used */
+		/* IPD 0x800 */ 0x200 >> 4,	/* BGX0 */
+		/* IPD 0x900 */ 0x240 >> 4,	/* BGX1 */
+		/* IPD 0xa00 */ 0x280 >> 4,	/* BGX2 */
+		/* IPD 0xb00 */ 0x2c0 >> 4,	/* BGX3 */
+		/* IPD 0xc00 */ 0x300 >> 4,	/* BGX4 */
+		/* IPD 0xd00 */ 0x340 >> 4,	/* BGX5 */
+		/* IPD 0xe00 */ 0xff,		/* not used */
+		/* IPD 0xf00 */ 0xff		/* not used */
+	};
+
+	xchan = ipd_port >> 8;
+
+	/* ILKx has 8 bits logican channels, others just 6 */
+	if (((xchan & 0xfe) == 0x04))
+		off = ipd_port & 0xff;
+	else
+		off = ipd_port & 0x3f;
+
+	xchan = xchan_base[ xchan & 0xF ];
+
+	if(xchan == 0xff)
+		return 0xffff;
+	else
+		return (xchan << 4) | off;
+}
+
+/*
+ * Map channel number in PKO 
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param pq_num specifies the Port Queue (i.e. L1) queue number.
+ * @param l2_l3_q_num  specifies L2/L3 queue number.
+ * @param channel specifies the channel number to map to the queue.
+ *
+ * The channel assignment applies to L2 or L3 Shaper Queues depending
+ * on the setting of channel credit level.
+ *
+ * @return returns none.
+ */
+void cvmx_pko3_map_channel(unsigned node,
+	unsigned pq_num, unsigned l2_l3_q_num, uint16_t channel)
+{
+	union cvmx_pko_l3_l2_sqx_channel sqx_channel;
+	cvmx_pko_lutx_t lutx;
+	uint16_t xchan;
+
+	sqx_channel.u64 = cvmx_read_csr_node(node,
+		CVMX_PKO_L3_L2_SQX_CHANNEL(l2_l3_q_num));
+
+	sqx_channel.s.cc_channel = channel;
+
+	cvmx_write_csr_node(node,
+		CVMX_PKO_L3_L2_SQX_CHANNEL(l2_l3_q_num), sqx_channel.u64);
+
+	/* Convert CHAN_E into compressed channel */
+	xchan =  cvmx_pko3_chan_2_xchan(channel);
+
+	if(xchan & 0xf000) {
+		cvmx_dprintf("%s: ERROR: channel %#x not recognized\n",
+			__FUNCTION__, channel);
+		return;
+	}
+
+	lutx.u64 = 0;
+	lutx.s.valid = 1;
+	lutx.s.pq_idx = pq_num;
+	lutx.s.queue_number = l2_l3_q_num;
+
+	cvmx_write_csr_node(node, CVMX_PKO_LUTX(xchan), lutx.u64);
+
+	if (debug)
+		cvmx_dprintf("%s: channel %#x (compressed=%#x) mapped "
+				"L2/L3 SQ=%u, PQ=%u\n",
+			__FUNCTION__, channel, xchan, l2_l3_q_num, pq_num);
+}
+
+/*
+ * @INTERNAL
+ * This function configures port queue scheduling and topology parameters
+ * in hardware.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param port_queue is the port queue number to be configured.
+ * @param child_base is the first child queue number in the static prioriy childs.
+ * @param child_rr_prio is the round robin childs priority.
+ * @param mac_num is the mac number of the mac that will be tied to this port_queue.
+ * @return returns none.
+ */
+static void cvmx_pko_configure_port_queue(int node, int port_queue,
+					 int child_base, int child_rr_prio,
+					 int mac_num)
+{
+	cvmx_pko_l1_sqx_topology_t pko_l1_topology;
+	cvmx_pko_l1_sqx_shape_t pko_l1_shape;
+	cvmx_pko_l1_sqx_link_t pko_l1_link;
+
+	pko_l1_topology.u64 = 0;
+	pko_l1_topology.s.prio_anchor = child_base;
+	pko_l1_topology.s.link = mac_num;
+	pko_l1_topology.s.rr_prio = child_rr_prio;
+	cvmx_write_csr_node(node, CVMX_PKO_L1_SQX_TOPOLOGY(port_queue), pko_l1_topology.u64);
+
+	pko_l1_shape.u64 = 0;
+	pko_l1_shape.s.link = mac_num;
+	cvmx_write_csr_node(node, CVMX_PKO_L1_SQX_SHAPE(port_queue), pko_l1_shape.u64);
+
+	pko_l1_link.u64 = 0;
+	pko_l1_link.s.link = mac_num;
+	cvmx_write_csr_node(node, CVMX_PKO_L1_SQX_LINK(port_queue), pko_l1_link.u64);
+}
+
+/*
+ * @INTERNAL
+ * This function configures level 2 queues scheduling and topology parameters
+ * in hardware.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param queue is the level2 queue number to be configured.
+ * @param parent_queue is the parent queue at next level for this l2 queue.
+ * @param prio is this queue's priority in parent's scheduler.
+ * @param rr_quantum is this queue's round robin quantum value.
+ * @return returns none.
+ */
+static void cvmx_pko_configure_l2_queue(int node, int queue, int parent_queue,
+					       int prio, int rr_quantum)
+{
+	cvmx_pko_l2_sqx_schedule_t pko_sq_sched;
+	cvmx_pko_l2_sqx_topology_t pko_sq_topology;
+
+	/* scheduler configuration for this sq in the parent queue */
+	pko_sq_sched.u64 = 0;
+	pko_sq_sched.s.prio = prio;
+	pko_sq_sched.s.rr_quantum = rr_quantum;
+	cvmx_write_csr_node(node, CVMX_PKO_L2_SQX_SCHEDULE(queue), pko_sq_sched.u64);
+
+	/* topology configuration */
+	pko_sq_topology.u64 = 0;
+	pko_sq_topology.s.parent = parent_queue;
+	cvmx_write_csr_node(node, CVMX_PKO_L2_SQX_TOPOLOGY(queue), pko_sq_topology.u64);
+
+}
+
+/*
+ * @INTERNAL
+ * This function configures level 3 queues scheduling and topology parameters
+ * in hardware.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param queue is the level3 queue number to be configured.
+ * @param parent_queue is the parent queue at next level for this l3 queue.
+ * @param prio is this queue's priority in parent's scheduler.
+ * @param rr_quantum is this queue's round robin quantum value.
+ * @param child_base is the first child queue number in the static prioriy childs.
+ * @param child_rr_prio is the round robin childs priority.
+ * @return returns none.
+ */
+static void cvmx_pko_configure_l3_queue(int node, int queue, int parent_queue,
+					       int prio, int rr_quantum,
+					       int child_base, int child_rr_prio)
+{
+	cvmx_pko_l3_sqx_schedule_t pko_sq_sched;
+	cvmx_pko_l3_sqx_topology_t pko_child_topology;
+	cvmx_pko_l2_sqx_topology_t pko_parent_topology;
+
+	/* parent topology configuration */
+	pko_parent_topology.u64 = cvmx_read_csr_node(node,
+			CVMX_PKO_L2_SQX_TOPOLOGY(parent_queue));
+	pko_parent_topology.s.prio_anchor = child_base;
+	pko_parent_topology.s.rr_prio = child_rr_prio;
+	cvmx_write_csr_node(node,
+			CVMX_PKO_L2_SQX_TOPOLOGY(parent_queue),
+			pko_parent_topology.u64);
+
+	/* scheduler configuration for this sq in the parent queue */
+	pko_sq_sched.u64 = 0;
+	pko_sq_sched.s.prio = prio;
+	pko_sq_sched.s.rr_quantum = rr_quantum;
+	cvmx_write_csr_node(node, CVMX_PKO_L3_SQX_SCHEDULE(queue), pko_sq_sched.u64);
+
+	/* child topology configuration */
+	pko_child_topology.u64 = 0;
+	pko_child_topology.s.parent = parent_queue;
+	cvmx_write_csr_node(node, CVMX_PKO_L3_SQX_TOPOLOGY(queue), pko_child_topology.u64);
+
+}
+
+/*
+ * @INTERNAL
+ * This function configures level 4 queues scheduling and topology parameters
+ * in hardware.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param queue is the level4 queue number to be configured.
+ * @param parent_queue is the parent queue at next level for this l4 queue.
+ * @param prio is this queue's priority in parent's scheduler.
+ * @param rr_quantum is this queue's round robin quantum value.
+ * @param child_base is the first child queue number in the static prioriy childs.
+ * @param child_rr_prio is the round robin childs priority.
+ * @return returns none.
+ */
+static void cvmx_pko_configure_l4_queue(int node, int queue, int parent_queue,
+					       int prio, int rr_quantum,
+					       int child_base, int child_rr_prio)
+{
+	cvmx_pko_l4_sqx_schedule_t pko_sq_sched;
+	cvmx_pko_l4_sqx_topology_t pko_child_topology;
+	cvmx_pko_l3_sqx_topology_t pko_parent_topology;
+
+	/* parent topology configuration */
+	pko_parent_topology.u64 = cvmx_read_csr_node(node,
+			CVMX_PKO_L3_SQX_TOPOLOGY(parent_queue));
+	pko_parent_topology.s.prio_anchor = child_base;
+	pko_parent_topology.s.rr_prio = child_rr_prio;
+	cvmx_write_csr_node(node,
+			CVMX_PKO_L3_SQX_TOPOLOGY(parent_queue),
+			pko_parent_topology.u64);
+
+	/* scheduler configuration for this sq in the parent queue */
+	pko_sq_sched.u64 = 0;
+	pko_sq_sched.s.prio = prio;
+	pko_sq_sched.s.rr_quantum = rr_quantum;
+	cvmx_write_csr_node(node, CVMX_PKO_L4_SQX_SCHEDULE(queue), pko_sq_sched.u64);
+
+	/* topology configuration */
+	pko_child_topology.u64 = 0;
+	pko_child_topology.s.parent = parent_queue;
+	cvmx_write_csr_node(node, CVMX_PKO_L4_SQX_TOPOLOGY(queue), pko_child_topology.u64);
+}
+
+/*
+ * @INTERNAL
+ * This function configures level 5 queues scheduling and topology parameters
+ * in hardware.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param queue is the level5 queue number to be configured.
+ * @param parent_queue is the parent queue at next level for this l5 queue.
+ * @param prio is this queue's priority in parent's scheduler.
+ * @param rr_quantum is this queue's round robin quantum value.
+ * @param child_base is the first child queue number in the static prioriy childs.
+ * @param child_rr_prio is the round robin childs priority.
+ * @return returns none.
+ */
+static void cvmx_pko_configure_l5_queue(int node, int queue, int parent_queue,
+					       int prio, int rr_quantum,
+					       int child_base, int child_rr_prio)
+{
+	cvmx_pko_l5_sqx_schedule_t pko_sq_sched;
+	cvmx_pko_l4_sqx_topology_t pko_parent_topology;
+	cvmx_pko_l5_sqx_topology_t pko_child_topology;
+
+	/* parent topology configuration */
+	pko_parent_topology.u64 = cvmx_read_csr_node(node,
+			CVMX_PKO_L4_SQX_TOPOLOGY(parent_queue));
+	pko_parent_topology.s.prio_anchor = child_base;
+	pko_parent_topology.s.rr_prio = child_rr_prio;
+	cvmx_write_csr_node(node,
+			CVMX_PKO_L4_SQX_TOPOLOGY(parent_queue),
+			pko_parent_topology.u64);
+
+	/* scheduler configuration for this sq in the parent queue */
+	pko_sq_sched.u64 = 0;
+	pko_sq_sched.s.prio = prio;
+	pko_sq_sched.s.rr_quantum = rr_quantum;
+	cvmx_write_csr_node(node, CVMX_PKO_L5_SQX_SCHEDULE(queue), pko_sq_sched.u64);
+
+	/* topology configuration */
+	pko_child_topology.u64 = 0;
+	pko_child_topology.s.parent = parent_queue;
+	cvmx_write_csr_node(node, CVMX_PKO_L5_SQX_TOPOLOGY(queue), pko_child_topology.u64);
+}
+
+/*
+ * @INTERNAL
+ * This function configures descriptor queues scheduling and topology parameters
+ * in hardware.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param dq is the descriptor queue number to be configured.
+ * @param parent_queue is the parent queue at next level for this dq.
+ * @param prio is this queue's priority in parent's scheduler.
+ * @param rr_quantum is this queue's round robin quantum value.
+ * @param child_base is the first child queue number in the static prioriy childs.
+ * @param child_rr_prio is the round robin childs priority.
+ * @return returns none.
+ */
+static void cvmx_pko_configure_dq(int node, int dq, int parent_queue,
+				int prio, int rr_quantum,
+			       	int child_base, int child_rr_prio)
+{
+	cvmx_pko_dqx_schedule_t pko_dq_sched;
+	cvmx_pko_dqx_topology_t pko_dq_topology;
+	cvmx_pko_l5_sqx_topology_t pko_parent_topology;
+	cvmx_pko_dqx_wm_ctl_t pko_dq_wm_ctl;
+
+	/* parent topology configuration */
+	pko_parent_topology.u64 = cvmx_read_csr_node(node,
+			CVMX_PKO_L5_SQX_TOPOLOGY(parent_queue));
+	pko_parent_topology.s.prio_anchor = child_base;
+	pko_parent_topology.s.rr_prio = child_rr_prio;
+	cvmx_write_csr_node(node,
+			CVMX_PKO_L5_SQX_TOPOLOGY(parent_queue),
+			pko_parent_topology.u64);
+
+	/* scheduler configuration for this dq in the parent queue */
+	pko_dq_sched.u64 = 0;
+	pko_dq_sched.s.prio = prio;
+	pko_dq_sched.s.rr_quantum = rr_quantum;
+	cvmx_write_csr_node(node, CVMX_PKO_DQX_SCHEDULE(dq), pko_dq_sched.u64);
+
+	/* topology configuration */
+	pko_dq_topology.u64 = 0;
+	pko_dq_topology.s.parent = parent_queue;
+	cvmx_write_csr_node(node, CVMX_PKO_DQX_TOPOLOGY(dq), pko_dq_topology.u64);
+
+	/* configure for counting packets, not bytes at this level */
+	pko_dq_wm_ctl.u64 = 0;
+	pko_dq_wm_ctl.s.kind = 1;
+	pko_dq_wm_ctl.s.enable = 0;
+	cvmx_write_csr_node(node, CVMX_PKO_DQX_WM_CTL(dq), pko_dq_wm_ctl.u64);
+}
+
+
+/*
+ * @INTERNAL
+ * The following structure selects the Scheduling Queue configuration
+ * routine for each of the supported levels.
+ * The initial content of the table will be setup in accordance
+ * to the specific SoC model and its implemented resources
+ */
+static const struct {
+	unsigned sq_level_base,
+		sq_level_count;
+	/* 4 function pointers for L3 .. L6=DQ */
+	void (*cfg_sq_func[])(
+			int node, int queue, int parent_queue,
+			int prio, int rr_quantum,
+			int child_base, int child_rr_prio);
+} __cvmx_pko3_sq_config_table = {
+	3, 4,
+	{
+	cvmx_pko_configure_l3_queue,
+	cvmx_pko_configure_l4_queue,
+	cvmx_pko_configure_l5_queue,
+	cvmx_pko_configure_dq
+	}
+};
+
+/*
+ * Configure Port Queue and its children Scheduler Queue
+ *
+ * Port Queues (a.k.a L1) are assigned 1-to-1 to MACs.
+ * L2 Scheduler Queues are used for specifying channels, and thus there
+ * could be multiple L2 SQs attached to a single L1 PQ, either in a
+ * fair round-robin scheduling, or with static and/or round-robin priorities.
+ *
+ * @param mac_num is the LMAC number to that is associated with the Port Queue,
+ * @param which is identical to the Port Queue number that is configured
+ * @param child_base is the number of the first L2 SQ attached to the PQ
+ * @param child_count is the number of L2 SQ children to attach to PQ
+ * @param stat_prio_count is the priority setting for the children L2 SQs
+ *
+ * If <stat_prio_count> is -1, the L2 children will have equal Round-Robin
+ * relationship with eachother. If <stat_prio_count> is 0, all L2 children
+ * will be arranged in Weighted-Round-Robin, with the first having the most
+ * precedence. If <stat_prio_count> is between 1 and 8, it indicates how
+ * many children will have static priority settings (with the first having
+ * the most precedence), with the remaining L2 children having WRR scheduling.
+ *
+ * @returns 0 on success, -1 on failure.
+ *
+ * Note: this function supports the configuration of node-local unit.
+ */
+int cvmx_pko3_pq_config_children(unsigned mac_num, unsigned child_base,
+			unsigned child_count, int stat_prio_count)
+{
+	unsigned node = cvmx_get_node_num();
+
+	unsigned pq_num;
+	unsigned rr_quantum, rr_count;
+	unsigned child, prio, rr_prio;
+
+	/* L1/PQ number is 1-to-1 from MAC number */
+	pq_num = mac_num;
+
+	/* First static priority is 0 - wuth the most precedence */
+	prio = 0;
+
+	if (stat_prio_count > (signed) child_count)
+		stat_prio_count = child_count;
+
+	/* Valid PRIO field is 0..9, limit maximum static priorities */
+	if (stat_prio_count > 9)
+		stat_prio_count = 9;
+
+	/* Special case of a single child */
+	if (child_count == 1) {
+		rr_count = 0;
+		rr_prio = 0xF;
+	/* Special case for Fair-RR */
+	} else if (stat_prio_count < 0) {
+		rr_count = child_count;
+		rr_prio = 0;
+	} else {
+		rr_count = child_count - stat_prio_count;
+		rr_prio = stat_prio_count;
+	}
+
+	/* Compute highest RR_QUANTUM */
+	if (stat_prio_count > 0)
+		rr_quantum = CVMX_PKO3_RR_QUANTUM_MIN * rr_count;
+	else
+		rr_quantum = CVMX_PKO3_RR_QUANTUM_MIN;
+
+	if(debug)
+		cvmx_dprintf("%s: L1/PQ%02u MAC%02u child_base %u rr_pri %u\n",
+		__FUNCTION__, pq_num, mac_num, child_base, rr_prio);
+
+	cvmx_pko_configure_port_queue(node,
+		pq_num, child_base, rr_prio, mac_num);
+
+
+	for(child = child_base; child < (child_base + child_count); child ++) {
+		if (debug)
+			cvmx_dprintf("%s: "
+				"L2/SQ%u->PQ%02u prio %u rr_quantum %#x\n",
+				__FUNCTION__,
+				child, pq_num, prio, rr_quantum);
+
+		cvmx_pko_configure_l2_queue(node,
+			child, pq_num, prio, rr_quantum);
+
+		if (prio < rr_prio)
+			prio ++;
+		else if (stat_prio_count > 0)
+			rr_quantum -= CVMX_PKO3_RR_QUANTUM_MIN;
+	} /* for child */
+
+	return 0;
+}
+
+/*
+ * Configure L3 through L5 Scheduler Queues and Descriptor Queues
+ *
+ * The Scheduler Queues in Levels 3 to 5 and Descriptor Queues are
+ * configured one-to-one or many-to-one to a single parent Scheduler
+ * Queues. The level of the parent SQ is specified in an argument,
+ * as well as the number of childer to attach to the specific parent.
+ * The children can have fair round-robin or priority-based scheduling
+ * when multiple children are assigned a single parent.
+ *
+ * @param parent_level is the level of the parent queue, 2 to 5.
+ * @param parent_queue is the number of the parent Scheduler Queue
+ * @param child_base is the number of the first child SQ or DQ to assign to
+ * @param parent
+ * @param child_count is the number of consecutive children to assign
+ * @param stat_prio_count is the priority setting for the children L2 SQs
+ *
+ * If <stat_prio_count> is -1, the Ln children will have equal Round-Robin
+ * relationship with eachother. If <stat_prio_count> is 0, all Ln children
+ * will be arranged in Weighted-Round-Robin, with the first having the most
+ * precedence. If <stat_prio_count> is between 1 and 8, it indicates how
+ * many children will have static priority settings (with the first having
+ * the most precedence), with the remaining Ln children having WRR scheduling.
+ *
+ * @returns 0 on success, -1 on failure.
+ *
+ * Note: this function supports the configuration of node-local unit.
+ */
+int cvmx_pko3_sq_config_children(unsigned parent_level,
+			unsigned parent_queue, unsigned child_base,
+			unsigned child_count, int stat_prio_count)
+{
+	unsigned node = cvmx_get_node_num();
+	unsigned child_level;
+	unsigned rr_quantum, rr_count;
+	unsigned child, prio, rr_prio;
+	unsigned func_idx;
+
+	child_level = parent_level + 1;
+
+	if (child_level < __cvmx_pko3_sq_config_table.sq_level_base ||
+	    child_level >= __cvmx_pko3_sq_config_table.sq_level_base +
+			__cvmx_pko3_sq_config_table.sq_level_count)
+		return -1;
+
+	func_idx = child_level - __cvmx_pko3_sq_config_table.sq_level_base;
+
+	/* First static priority is 0 - top precedence */
+	prio = 0;
+
+	if (stat_prio_count > (signed) child_count)
+		stat_prio_count = child_count;
+
+	/* Valid PRIO field is 0..9, limit maximum static priorities */
+	if (stat_prio_count > 9)
+		stat_prio_count = 9;
+
+	/* Special case of a single child */
+	if (child_count == 1) {
+		rr_count = 0;
+		rr_prio = 0xF;
+	/* Special case for Fair-RR */
+	} else if (stat_prio_count < 0) {
+		rr_count = child_count;
+		rr_prio = 0;
+	} else {
+		rr_count = child_count - stat_prio_count;
+		rr_prio = stat_prio_count;
+	}
+
+	/* Compute highest RR_QUANTUM */
+	if (stat_prio_count > 0)
+		rr_quantum = CVMX_PKO3_RR_QUANTUM_MIN * rr_count;
+	else
+		rr_quantum = CVMX_PKO3_RR_QUANTUM_MIN;
+
+	if(debug)
+		cvmx_dprintf("%s: Parent L%u/SQ%02u child_base %u rr_pri %u\n",
+		__FUNCTION__, parent_level, parent_queue, child_base, rr_prio);
+
+	// Parent is configured with child
+
+	for(child = child_base; child < (child_base + child_count); child ++) {
+		if (debug)
+			cvmx_dprintf("%s: "
+				"L%u/SQ%u->L%u/SQ%u prio %u rr_quantum %#x\n",
+				__FUNCTION__,
+				child_level, child,
+				parent_level, parent_queue,
+				prio, rr_quantum);
+
+		__cvmx_pko3_sq_config_table.cfg_sq_func[func_idx](
+			node, child, parent_queue, prio, rr_quantum,
+			child_base, rr_prio);
+
+		if (prio < rr_prio)
+			prio ++;
+		else if (stat_prio_count > 0)
+			rr_quantum -= CVMX_PKO3_RR_QUANTUM_MIN;
+	} /* for child */
+
+	return 0;
+}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3-resources.c b/arch/mips/cavium-octeon/executive/cvmx-pko3-resources.c
new file mode 100644
index 0000000..d3043af
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3-resources.c
@@ -0,0 +1,173 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * PKO resources.
+ */
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <linux/module.h>
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-pko3.h>
+#include "asm/octeon/cvmx-global-resources.h"
+#include <asm/octeon/cvmx-pko3-resources.h>
+#include "asm/octeon/cvmx-range.h"
+#else
+#include "cvmx.h"
+#include "cvmx-pko3.h"
+#include "cvmx-global-resources.h"
+#include "cvmx-pko3-resources.h"
+#include "cvmx-range.h"
+#endif
+
+#define CVMX_GR_TAG_PKO_PORT_QUEUES(x)   cvmx_get_gr_tag('c','v','m','_','p','k','o','p','o','q','_',(x+'0'),'.','.','.','.')
+#define CVMX_GR_TAG_PKO_L2_QUEUES(x)   	 cvmx_get_gr_tag('c','v','m','_','p','k','o','l','2','q','_',(x+'0'),'.','.','.','.')
+#define CVMX_GR_TAG_PKO_L3_QUEUES(x)     cvmx_get_gr_tag('c','v','m','_','p','k','o','l','3','q','_',(x+'0'),'.','.','.','.')
+#define CVMX_GR_TAG_PKO_L4_QUEUES(x)     cvmx_get_gr_tag('c','v','m','_','p','k','o','l','4','q','_',(x+'0'),'.','.','.','.')
+#define CVMX_GR_TAG_PKO_L5_QUEUES(x)     cvmx_get_gr_tag('c','v','m','_','p','k','o','l','5','q','_',(x+'0'),'.','.','.','.')
+#define CVMX_GR_TAG_PKO_DESCR_QUEUES(x)  cvmx_get_gr_tag('c','v','m','_','p','k','o','d','e','q','_',(x+'0'),'.','.','.','.')
+#define CVMX_GR_TAG_PKO_PORT_INDEX(x)  	 cvmx_get_gr_tag('c','v','m','_','p','k','o','p','i','d','_',(x+'0'),'.','.','.','.')
+
+const int cvmx_pko_num_queues_78XX[CVMX_PKO_NUM_QUEUE_LEVELS] = 
+{
+	[CVMX_PKO_PORT_QUEUES] = 32,
+	[CVMX_PKO_L2_QUEUES] = 512,
+	[CVMX_PKO_L3_QUEUES] = 512,
+	[CVMX_PKO_L4_QUEUES] = 1024,
+	[CVMX_PKO_L5_QUEUES] = 1024,
+	[CVMX_PKO_DESCR_QUEUES] = 1024
+};
+
+static inline int __cvmx_pko3_get_num_queues(int level)
+{
+	if(OCTEON_IS_MODEL(OCTEON_CN78XX))
+		return cvmx_pko_num_queues_78XX[level];
+	return -1;
+}
+
+static inline struct global_resource_tag __cvmx_pko_get_queues_resource_tag(int node, int queue_level)
+{
+	switch(queue_level) {
+		case CVMX_PKO_PORT_QUEUES:
+			return CVMX_GR_TAG_PKO_PORT_QUEUES(node);
+		case CVMX_PKO_L2_QUEUES:
+			return CVMX_GR_TAG_PKO_L2_QUEUES(node);
+		case CVMX_PKO_L3_QUEUES:
+			return CVMX_GR_TAG_PKO_L3_QUEUES(node);
+		case CVMX_PKO_L4_QUEUES:
+			return CVMX_GR_TAG_PKO_L4_QUEUES(node);
+		case CVMX_PKO_L5_QUEUES:
+			return CVMX_GR_TAG_PKO_L5_QUEUES(node);
+		case CVMX_PKO_DESCR_QUEUES:
+			return CVMX_GR_TAG_PKO_DESCR_QUEUES(node);
+		default:
+			return CVMX_GR_TAG_INVALID;
+	}
+}
+
+/**
+ * Allocate or reserve a pko resource - called by wrapper functions
+ * @param tag processed global resource tag
+ * @param base_queue if specified the queue to reserve
+ * @param owner to be specified for resource
+ * @param num_queues to allocate
+ * @param max_num_queues for global resource
+ */
+int cvmx_pko_alloc_global_resource(struct global_resource_tag tag, int base_queue, int owner, int num_queues, int max_num_queues)
+{
+	int res;
+	if(cvmx_create_global_resource_range(tag, max_num_queues)) {
+		cvmx_dprintf("ERROR: Failed to create PKO3 resource: %lx-%lx\n",
+			(unsigned long) tag.hi, (unsigned long) tag.lo);
+		return -1;
+	}
+	if(base_queue >= 0) {
+		res = cvmx_reserve_global_resource_range(tag, owner, base_queue, num_queues);
+	} else {
+		res = cvmx_allocate_global_resource_range(tag, owner, num_queues, 1);
+	}
+	if(res < 0) {
+		cvmx_dprintf("ERROR: Failed to %s PKO3 tag %lx:%lx, %i %i %i %i.\n",
+			((base_queue < 0) ? "allocate" : "reserve"),
+			(unsigned long) tag.hi, (unsigned long) tag.lo,
+			base_queue, owner, num_queues, max_num_queues);
+		return -1;
+	}
+
+	return res;
+}
+
+/**
+ * Allocate or reserve PKO queues - wrapper for cvmx_pko_alloc_global_resource
+ *
+ * @param node on which to allocate/reserve PKO queues
+ * @param level of PKO queue
+ * @param owner of reserved/allocated resources
+ * @param base_queue to start reservation/allocatation
+ * @param num_queues number of queues to be allocated
+ * @return 0 on success, -1 on failure
+ */
+int cvmx_pko_alloc_queues(int node, int level, int owner, int base_queue, int num_queues)
+{
+	struct global_resource_tag tag = __cvmx_pko_get_queues_resource_tag(node, level);
+	int max_num_queues = __cvmx_pko3_get_num_queues(level);
+
+	return cvmx_pko_alloc_global_resource(tag, base_queue, owner, num_queues, max_num_queues);
+}
+EXPORT_SYMBOL(cvmx_pko_alloc_queues);
+
+/**
+ * Free an allocated/reserved PKO queues for a certain level and owner
+ *
+ * @param node on which to allocate/reserve PKO queues
+ * @param level of PKO queue
+ * @param owner of reserved/allocated resources
+ * @return 0 on success, -1 on failure
+ */
+int cvmx_pko_free_queues(int node, int level, int owner)
+{
+	struct global_resource_tag tag = __cvmx_pko_get_queues_resource_tag(node, level);
+
+	return cvmx_free_global_resource_range_with_owner(tag, owner);
+}
+EXPORT_SYMBOL(cvmx_pko_free_queues);
+
+
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
new file mode 100644
index 0000000..eee8e82
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
@@ -0,0 +1,817 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <linux/module.h>
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-fpa.h>
+#include <asm/octeon/cvmx-clock.h>
+#include <asm/octeon/cvmx-pko.h>
+#include <asm/octeon/cvmx-pko3.h>
+#include <asm/octeon/cvmx-helper-pko3.h>
+#else
+#include "cvmx.h"
+#include "cvmx-pko.h"	/* For legacy support */
+#include "cvmx-pko3.h"
+#include "cvmx-fpa.h"
+#include "cvmx-helper-pko3.h"
+#endif
+
+static const int debug = 0;
+
+static int cvmx_pko_setup_macs(int node);
+
+/*
+ * PKO descriptor queue operation error string
+ *
+ * @param dqstatus is the enumeration returned from hardware,
+ * 	  PKO_QUERY_RTN_S[DQSTATUS].
+ *
+ * @return static constant string error description
+ */
+const char * pko_dqstatus_error(pko_query_dqstatus_t dqstatus)
+{
+	char * str = "PKO Undefined error";
+
+	switch(dqstatus) {
+	case PKO_DQSTATUS_PASS :
+		str = "No error";
+		break;
+	case PKO_DQSTATUS_BADSTATE :
+		str = "PKO queue not ready";
+		break;
+	case PKO_DQSTATUS_NOFPABUF :
+		str ="PKO failed to allocate buffer from FPA";
+		break;
+	case PKO_DQSTATUS_NOPKOBUF :
+		str = "PKO out of buffers";
+		break;
+	case PKO_DQSTATUS_FAILRTNPTR :
+		str = "PKO failed to return buffer to FPA";
+		break;
+	case PKO_DQSTATUS_ALREADY :
+		str = "PKO queue already opened";
+		break;
+	case PKO_DQSTATUS_NOTCREATED:
+		str = "PKO queue has not been created";
+		break;
+	case PKO_DQSTATUS_NOTEMPTY :
+		str = "PKO queue is not empty";
+		break;
+	case PKO_DQSTATUS_SENDPKTDROP :
+		str = "Illegal PKO command construct";
+		break;
+	}
+	return str;
+}
+
+/*
+ * PKO global intialization for 78XX.
+ *
+ * @param node is the node on which PKO block is initialized.
+ * @return none.
+ */
+int cvmx_pko3_hw_init_global(int node, uint16_t aura)
+{
+	cvmx_pko_dpfi_flush_t pko_flush;
+	cvmx_pko_dpfi_fpa_aura_t pko_aura;
+	cvmx_pko_dpfi_ena_t dpfi_enable;
+	cvmx_pko_ptf_iobp_cfg_t ptf_iobp_cfg;
+	cvmx_pko_enable_t pko_enable;
+
+	/* Clear FLUSH command to be sure */
+	pko_flush.u64 = 0;
+	pko_flush.s.flush_en = 0;
+	cvmx_write_csr_node(node, CVMX_PKO_DPFI_FLUSH, pko_flush.u64);
+
+	/* set the aura number in pko, use aura node from parameter */
+	pko_aura.u64 = 0;
+	pko_aura.s.node = aura >> 10;
+	pko_aura.s.laura = aura & (CVMX_FPA_AURA_NUM-1);
+	cvmx_write_csr_node(node, CVMX_PKO_DPFI_FPA_AURA, pko_aura.u64);
+
+	dpfi_enable.u64 = 0;
+	dpfi_enable.s.enable = 1;
+	cvmx_write_csr_node(node, CVMX_PKO_DPFI_ENA, dpfi_enable.u64);
+
+	/* set max outstanding requests in IOBP for any FIFO */
+	ptf_iobp_cfg.u64 = 0;
+	ptf_iobp_cfg.s.max_read_size = 72;	//HRM: typical=0x48
+	cvmx_write_csr_node(node, CVMX_PKO_PTF_IOBP_CFG, ptf_iobp_cfg.u64);
+
+	/* Initialize MACs and FIFOs */
+	cvmx_pko_setup_macs(node);
+
+	//FIXME- error checking
+
+
+	/* enable PKO, although interfaces and queues are not up yet */
+	pko_enable.u64 = 0;
+	pko_enable.s.enable = 1;
+	cvmx_write_csr_node(node, CVMX_PKO_ENABLE, pko_enable.u64);
+
+	return 0;
+}
+
+/**
+ * Shutdown the entire PKO
+ */
+int cvmx_pko3_hw_disable(int node)
+{
+	cvmx_pko_dpfi_flush_t pko_flush;
+	cvmx_pko_dpfi_status_t pko_status;
+	cvmx_pko_dpfi_ena_t dpfi_enable;
+	cvmx_pko_enable_t pko_enable;
+	uint64_t cycles;
+	const unsigned timeout = 100;	/* 100 milliseconds */
+
+	/* Set FLUSH_EN to return cached pointers to FPA */
+	pko_flush.u64 = 0;
+	pko_flush.s.flush_en = 1;
+	cvmx_write_csr_node(node, CVMX_PKO_DPFI_FLUSH, pko_flush.u64);
+
+	/* Prepare timeout */
+        cycles = cvmx_get_cycle();
+        cycles += cvmx_clock_get_rate(CVMX_CLOCK_CORE)/1000 * timeout;
+
+	/* Wait until all pointers have been returned */
+	do {
+		pko_status.u64 = cvmx_read_csr_node(node, CVMX_PKO_DPFI_STATUS);
+		if (cycles > cvmx_get_cycle())
+			break;
+	} while (!pko_status.s.cache_flushed);
+
+	/* disable PKO - all packets should be out by now */
+	pko_enable.u64 = 0;
+	pko_enable.s.enable = 0;
+	cvmx_write_csr_node(node, CVMX_PKO_ENABLE, pko_enable.u64);
+
+	/* disable PKO buffer manager, should return all buffers to FPA */
+	dpfi_enable.u64 = 0;
+	dpfi_enable.s.enable = 0;
+	cvmx_write_csr_node(node, CVMX_PKO_DPFI_ENA, dpfi_enable.u64);
+
+	/* Clear the FLISH_EN bit, as we are done */
+	pko_flush.u64 = 0;
+	cvmx_write_csr_node(node, CVMX_PKO_DPFI_FLUSH, pko_flush.u64);
+
+	if (pko_status.s.cache_flushed == 0) {
+		cvmx_dprintf("%s: ERROR: timeout waiting for PKO3 ptr flush\n",
+			__FUNCTION__);
+		return -1;
+	}
+
+	return 0;
+}
+
+/*
+ * Transmit packets through pko on specified node and queue.
+ *
+ * @param dq is the queue to write the commands to.
+ * @param bufptr specifies packet in linked or gather mode.
+ * @param packet_len is the total packet len of the packet in bufptr.
+ * @param aura_free is the aura to free packet buffers after trasnmit.
+ * @return returns 0 if successful and -1 on failure.
+ *
+ * NOTE: This is a tentative API, and supports a rather limitted
+ * subset of PKO3 functionality. It only uses 2-word commands.
+ */
+int cvmx_pko_transmit_packet(int dq, cvmx_buf_ptr_pki_t bufptr,
+			     int packet_len, int aura_free)
+{
+
+	unsigned port_node;
+	cvmx_pko_send_hdr_t pko_send_hdr;
+	cvmx_pko_query_rtn_s_t pko_status;
+	uint64_t words[2];
+
+	port_node = dq >> 14;
+	dq &= (1<<10)-1;
+
+	pko_send_hdr.u64 = 0;
+	pko_send_hdr.s.aura = aura_free;
+	/* TODO: n2 is not currently supported in simulator */
+	pko_send_hdr.s.n2 = 0;
+	pko_send_hdr.s.total = packet_len;
+
+	words[0] = pko_send_hdr.u64;
+	words[1] = bufptr.u64;
+
+	pko_status = __cvmx_pko3_do_dma(port_node, dq,
+		words, 2, CVMX_PKO_DQ_SEND);
+
+	if (pko_status.s.dqstatus != PKO_DQSTATUS_PASS) {
+		cvmx_dprintf("%s: ERROR: failed to enqueue: %s\n",
+				__FUNCTION__,
+				pko_dqstatus_error(pko_status.s.dqstatus));
+		return -1;
+	}
+	return 0;
+}
+
+ /** Open configured descriptor queues before queueing packets into them.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param dq is the descriptor queue number to be opened.
+ * @return returns 0 on sucess or -1 on failure.
+ */
+int cvmx_pko_dq_open(int node, int dq)
+{
+	cvmx_pko_query_rtn_s_t pko_status;
+	pko_query_dqstatus_t dqstatus;
+
+	pko_status = __cvmx_pko3_do_dma(node, dq, NULL, 0, CVMX_PKO_DQ_OPEN);
+
+	dqstatus = pko_status.s.dqstatus;
+
+	if (dqstatus == PKO_DQSTATUS_ALREADY)
+		return 0;
+	if (dqstatus != PKO_DQSTATUS_PASS) {
+		cvmx_dprintf("%s: ERROR: Failed to open dq :%u: %s\n",
+				__FUNCTION__, dq,
+				pko_dqstatus_error(dqstatus));
+		return -1;
+	}
+
+	return 0;
+}
+
+
+ /*
+ * Close a descriptor queue
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param dq is the descriptor queue number to be opened.
+ * @return returns 0 on sucess or -1 on failure.
+ *
+ * This should be called before changing the DQ parent link, topology,
+ * or when shutting down the PKO.
+ */
+int cvmx_pko3_dq_close(int node, int dq)
+{
+	cvmx_pko_query_rtn_s_t pko_status;
+	pko_query_dqstatus_t dqstatus;
+
+	pko_status = __cvmx_pko3_do_dma(node, dq, NULL, 0, CVMX_PKO_DQ_CLOSE);
+
+	dqstatus = pko_status.s.dqstatus;
+
+	if (dqstatus == PKO_DQSTATUS_NOTCREATED)
+		return 0;
+	if (dqstatus != PKO_DQSTATUS_PASS) {
+		cvmx_dprintf("%s: ERROR: Failed to close dq :%u: %s\n",
+				__FUNCTION__, dq,
+				pko_dqstatus_error(dqstatus));
+		return -1;
+	}
+	return 0;
+}
+
+/**
+ * Drain a descriptor queue
+ *
+ * Before closing a DQ, this call will drain all pending traffic
+ * on the DQ to the NULL MAC, which will circumvent any traffic
+ * shaping and flow control to quickly reclaim all packet buffers.
+ */
+void cvmx_pko3_dq_drain(int node, int dq)
+{
+#ifdef	__SIM78XX_FIXED	//Until implemented in simulator
+	cvmx_pko_dqx_sw_xoff_t rxoff;
+
+	rxoff.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_SW_XOFF(dq));
+
+	rxoff.s.drain_null_link = 1;
+	rxoff.s.drain = 1;
+
+	cvmx_write_csr_node(node, CVMX_PKO_DQX_SW_XOFF(dq), rxoff.u64);
+#endif
+}
+
+ /**
+ * Query a descriptor queue
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param dq is the descriptor queue number to be opened.
+ * @return returns the descriptor queue depth on sucess or -1 on failure.
+ *
+ * This should be called before changing the DQ parent link, topology,
+ * or when shutting down the PKO.
+ */
+int cvmx_pko3_dq_query(int node, int dq)
+{
+	cvmx_pko_query_rtn_s_t pko_status;
+	pko_query_dqstatus_t dqstatus;
+
+	pko_status = __cvmx_pko3_do_dma(node, dq, NULL, 0, CVMX_PKO_DQ_QUERY);
+
+	dqstatus = pko_status.s.dqstatus;
+
+	if (dqstatus != PKO_DQSTATUS_PASS) {
+		cvmx_dprintf("%s: ERROR: Failed to query dq :%u: %s\n",
+				__FUNCTION__, dq,
+				pko_dqstatus_error(dqstatus));
+		return -1;
+	}
+
+	return pko_status.s.depth;
+}
+
+static struct cvmx_pko3_mac_s {
+	cvmx_helper_interface_mode_t mac_mode;
+	uint8_t fifo_cnt;
+	uint8_t fifo_id;
+	uint8_t pri;
+	//FIXME- MAC speed needs more work to be accurate !
+} cvmx_pko3_mac_table[ CVMX_PKO_MAX_MACS ];
+
+/*
+ * PKO initialization of MACs and FIFOs
+ *
+ * All MACs are configured and assigned a specific FIFO,
+ * and each FIFO is configured with size for a best utilization
+ * of available FIFO resources.
+ *
+ * @param node is to specify which node's pko block for this setup.
+ * @return returns 0 if successful and -1 on failure.
+ */
+static int cvmx_pko_setup_macs(int node)
+{
+	unsigned interface;
+	unsigned port, num_ports;
+	unsigned mac_num, fifo, pri, cnt;
+	cvmx_helper_interface_mode_t mode;
+        const unsigned num_interfaces = cvmx_helper_get_number_of_interfaces();
+	uint8_t fifo_group_cfg[8];
+	uint8_t fifo_group_spd[8];
+	unsigned fifo_count = 0;
+
+	/* Initialize FIFO allocation table */
+	memset(&fifo_group_cfg, 0, sizeof(fifo_group_cfg));
+
+	/* Initialize all MACs as disabled */
+	for(mac_num = 0; mac_num < CVMX_PKO_MAX_MACS; mac_num++) {
+		cvmx_pko3_mac_table[mac_num].mac_mode =
+			CVMX_HELPER_INTERFACE_MODE_DISABLED;
+		cvmx_pko3_mac_table[mac_num].pri = 0;
+		cvmx_pko3_mac_table[mac_num].fifo_cnt = 0;
+		cvmx_pko3_mac_table[mac_num].fifo_id = 0x1f;
+	}
+
+	for(interface = 0; interface < num_interfaces; interface ++) {
+		mode = cvmx_helper_interface_get_mode(interface);
+		num_ports = cvmx_helper_interface_enumerate(interface);
+
+		if(mode == CVMX_HELPER_INTERFACE_MODE_DISABLED)
+			continue;
+		/*
+		 * ILK returns 8 ports, LOOP 4 ports, NPI ?? ports
+		 * but each of them only uses a single MAC really
+		 */
+		if ((mode == CVMX_HELPER_INTERFACE_MODE_ILK) ||
+			(mode == CVMX_HELPER_INTERFACE_MODE_NPI) ||
+			(mode == CVMX_HELPER_INTERFACE_MODE_LOOP))
+			num_ports = 1;
+
+		for (port = 0; port < num_ports; port++) {
+			int i;
+
+			/* convert interface/port to mac number */
+			i = __cvmx_pko_get_mac_num(interface, port);
+			if (i < 0 || i>= CVMX_PKO_MAX_MACS)
+				continue;
+
+			cvmx_pko3_mac_table[i].mac_mode = mode;
+			if(mode == CVMX_HELPER_INTERFACE_MODE_RXAUI) {
+				cvmx_pko3_mac_table[i].fifo_cnt = 4;
+				cvmx_pko3_mac_table[i].pri = 2;
+			} else if (mode == CVMX_HELPER_INTERFACE_MODE_XAUI) {
+				cvmx_pko3_mac_table[i].fifo_cnt = 4;
+				cvmx_pko3_mac_table[i].pri = 3;
+			} else if (mode == CVMX_HELPER_INTERFACE_MODE_ILK) {
+				cvmx_pko3_mac_table[i].fifo_cnt = 4;
+				cvmx_pko3_mac_table[i].pri = 4;
+			} else {
+				cvmx_pko3_mac_table[i].fifo_cnt = 1;
+				cvmx_pko3_mac_table[i].pri = 1;
+			}
+
+			if(debug)
+				cvmx_dprintf("%s: intf %u port %u %s "
+				"mac %02u cnt %u\n",
+				__FUNCTION__, interface, port,
+				cvmx_helper_interface_mode_to_string(mode),
+				i, cvmx_pko3_mac_table[i].fifo_cnt);
+
+		} /* for port */
+	} /* for interface */
+
+	/* Count the number of requested FIFOs */
+	for(fifo_count = mac_num = 0; mac_num < CVMX_PKO_MAX_MACS; mac_num ++)
+		fifo_count += cvmx_pko3_mac_table[mac_num].fifo_cnt;
+
+	if(debug)
+		cvmx_dprintf("%s: initial FIFO count %u\n",
+			__FUNCTION__, fifo_count);
+
+	/* Heuristically trim FIFO count to fit in available number */
+	pri = 1; cnt = 4;
+	while(fifo_count > 28) {
+		for(mac_num=0; mac_num < CVMX_PKO_MAX_MACS; mac_num ++) {
+			if (cvmx_pko3_mac_table[mac_num].fifo_cnt == cnt &&
+			    cvmx_pko3_mac_table[mac_num].pri <= pri) {
+				cvmx_pko3_mac_table[mac_num].fifo_cnt >>= 1;
+				fifo_count -=
+					cvmx_pko3_mac_table[mac_num].fifo_cnt;
+			}
+			if (fifo_count <= 28)
+				break;
+		}
+		if (pri >= 4) {
+			pri = 1;
+			cnt >>= 1;
+		} else
+			pri ++;
+		if( cnt == 0)
+			break;
+	}
+
+	if(debug)
+		cvmx_dprintf("%s: adjusted FIFO count %u\n",
+			__FUNCTION__, fifo_count);
+
+
+	/* Special case for NULL Virtual FIFO */
+	fifo_group_cfg[28 >> 2] = 0;
+	//FIXME- there is no MAC connected to NULL FIFO
+
+	/* Configure MAC units, and attach a FIFO to each */
+	for(fifo = 0, cnt = 4; cnt > 0; cnt >>= 1 ) {
+		unsigned g;
+		for(mac_num = 0; mac_num < CVMX_PKO_MAX_MACS; mac_num++) {
+			if(cvmx_pko3_mac_table[mac_num].fifo_cnt < cnt ||
+			  cvmx_pko3_mac_table[mac_num].fifo_id != 0x1f)
+				continue;
+
+			cvmx_pko3_mac_table[mac_num].fifo_id = fifo;
+			g = fifo >> 2;
+			if(cnt == 4)
+				fifo_group_cfg[g] = 4; /* 10k,0,0,0 */
+			else if(cnt == 2 && (fifo & 0x3) == 0)
+				fifo_group_cfg[g] = 3; /* 5k,0,5k,0 */
+			else if(cnt == 1 && fifo & 0x2 && fifo_group_cfg[g])
+				fifo_group_cfg[g] = 1; /* 5k,0,2.5k 2.5k*/
+			else
+				fifo_group_cfg[g] = 0; /* 2.5k x 4 */
+
+			fifo_group_spd[g] += cnt * 5;
+			fifo += cnt;
+		}
+	}
+
+	/* Check if there was no error in FIFO allocation */
+	if( fifo > 28 ){
+		cvmx_dprintf("%s: ERROR: Internal error FIFO %u\n",
+			__FUNCTION__, fifo);
+		return -1;
+	}
+
+	if(debug)
+		cvmx_dprintf("%s: used %u of FIFOs\n",
+			__FUNCTION__, fifo);
+
+	/* Now configure all FIFO groups */
+	for(fifo = 0; fifo < 8; fifo++) {
+		cvmx_pko_ptgfx_cfg_t pko_ptgfx_cfg;
+
+		pko_ptgfx_cfg.u64 =
+			cvmx_read_csr_node(node, CVMX_PKO_PTGFX_CFG(fifo));
+		if( pko_ptgfx_cfg.s.size != fifo_group_cfg[fifo])
+			pko_ptgfx_cfg.s.reset = 1;
+		pko_ptgfx_cfg.s.size = fifo_group_cfg[fifo] ;
+		if( fifo_group_spd[fifo] >= 40 )
+			pko_ptgfx_cfg.s.rate = 3;	/* 50 Gbps */
+		else if( fifo_group_spd[fifo] >= 20 )
+			pko_ptgfx_cfg.s.rate = 2;	/* 25 Gbps */
+		else if( fifo_group_spd[fifo] >= 10 )
+			pko_ptgfx_cfg.s.rate = 1;	/* 12.5 Gbps */
+		else
+			pko_ptgfx_cfg.s.rate = 0;	/* 6.25 Gbps */
+
+		if(debug) cvmx_dprintf("%s: fifo group %#x size=%u rate=%d\n",
+			__FUNCTION__, fifo, pko_ptgfx_cfg.s.size,
+			pko_ptgfx_cfg.s.rate);
+
+		cvmx_write_csr_node(node, CVMX_PKO_PTGFX_CFG(fifo),
+					pko_ptgfx_cfg.u64);
+		pko_ptgfx_cfg.s.reset = 0;
+		cvmx_write_csr_node(node, CVMX_PKO_PTGFX_CFG(fifo),
+					pko_ptgfx_cfg.u64);
+	}
+
+	/* Configure all 28 MACs assigned FIFO number */
+	for(mac_num = 0; mac_num < CVMX_PKO_MAX_MACS; mac_num++) {
+		cvmx_pko_macx_cfg_t pko_mac_cfg;
+
+		if(debug)
+			cvmx_dprintf("%s: mac#%02u: fifo=%#x cnt=%u\n",
+			__FUNCTION__, mac_num,
+			cvmx_pko3_mac_table[mac_num].fifo_id,
+			cvmx_pko3_mac_table[mac_num].fifo_cnt);
+
+		pko_mac_cfg.u64 =
+			cvmx_read_csr_node(node, CVMX_PKO_MACX_CFG(mac_num));
+		pko_mac_cfg.s.fifo_num = cvmx_pko3_mac_table[mac_num].fifo_id;
+		cvmx_write_csr_node(node, CVMX_PKO_MACX_CFG(mac_num),
+			pko_mac_cfg.u64);
+	}
+
+
+	/* Setup PKO MCI0/MCI1 credits */
+	for(mac_num = 0; mac_num < CVMX_PKO_MAX_MACS; mac_num++) {
+		cvmx_pko_mci0_max_credx_t pko_mci0_max_cred;
+		cvmx_pko_mci1_max_credx_t pko_mci1_max_cred;
+		unsigned credit, mac_credit, fifo_req_size, fifo_size;
+
+		/* FIXME- this section has no basis in HRM, revisit */
+		/* Loosely based on packet/clear78.x */
+		fifo_req_size = cvmx_pko3_mac_table[mac_num].fifo_cnt;
+
+		/* Skip unused MACs */
+		if (fifo_req_size == 0)
+			continue;
+
+		/* Check for sanity */
+		if (fifo_req_size > 4)
+			fifo_req_size = 1;
+
+		fifo_size = (2 * 1024) + (1024 / 2); /* 2.5KiB */
+		credit = fifo_req_size * fifo_size;
+
+		/* FIXME- This code is chip-dependent, not portable! */
+		switch (mac_num) {
+			case 0: /* loopback */
+				mac_credit = 4096; /* From HRM Sec 13.0 */
+				break;
+			case 1: /* DPI */
+				mac_credit = 2 * 1024;
+				break;
+			case 2: /* ILK0 */
+			case 3: /* ILK1 */
+				mac_credit = 4 * 1024; /* 4KB fifo */
+				break;
+			default: /* BGX */
+				mac_credit = fifo_req_size * 8 * 1024;
+				break;
+		} /* switch mac_num */
+
+		credit += mac_credit;
+
+		if(debug)
+			cvmx_dprintf(
+				"%s: mac %u "
+				"mci0.max_cred=%u mci1.max_cred=%u\n",
+				__FUNCTION__, mac_num, credit, mac_credit);
+
+		pko_mci0_max_cred.u64 = 0;
+		pko_mci0_max_cred.s.max_cred_lim = credit / 16;
+
+		/* Check for overflow */
+		if (pko_mci0_max_cred.s.max_cred_lim != (credit / 16)) {
+			cvmx_dprintf("%s: MCI0 credit overflow\n",__FUNCTION__);
+			pko_mci0_max_cred.s.max_cred_lim = 0xfff;
+		}
+
+		cvmx_write_csr_node(node, CVMX_PKO_MCI0_MAX_CREDX(mac_num),
+					pko_mci0_max_cred.u64);
+
+		pko_mci1_max_cred.u64 = 0;
+		pko_mci1_max_cred.s.max_cred_lim = (mac_credit / 16);
+
+		/* Check for overflow */
+		if (pko_mci1_max_cred.s.max_cred_lim != (mac_credit / 16)) {
+			cvmx_dprintf("%s: MCI1 credit overflow\n",__FUNCTION__);
+			pko_mci1_max_cred.s.max_cred_lim = 0xfff;
+		}
+
+		cvmx_write_csr_node(node, CVMX_PKO_MCI1_MAX_CREDX(mac_num),
+					pko_mci1_max_cred.u64);
+	} /* for mac_num */
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
+ * Backward compatibility for collecting statistics from PKO3
+ *
+ * NOTE:
+ * The good stats are in BGX block.
+ */
+void cvmx_pko3_get_legacy_port_stats(uint16_t ipd_port,
+	unsigned clear, cvmx_pko_port_status_t * stats)
+{
+	unsigned dq, dq_base, dq_num;
+	unsigned node = cvmx_get_node_num();
+
+	dq_base = cvmx_pko3_get_queue_base(ipd_port);
+	dq_num = cvmx_pko3_get_queue_num(ipd_port);
+
+	stats->packets = 0;
+	stats->octets = 0;
+	stats->doorbell = 0;	/* NOTE: PKO3 does not have a doorbell */
+
+	for(dq = dq_base; dq < (dq_base+dq_num); dq++ ) {
+		cvmx_pko_dqx_packets_t pkts;
+		cvmx_pko_dqx_bytes_t byts;
+
+		/* NOTE: clearing of these counters is non-atomic */
+		pkts.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_PACKETS(dq));
+		if(clear)
+			cvmx_write_csr_node(node,CVMX_PKO_DQX_PACKETS(dq),0ull);
+
+		byts.u64 = cvmx_read_csr_node(node, CVMX_PKO_DQX_BYTES(dq));
+		if(clear)
+			cvmx_write_csr_node(node, CVMX_PKO_DQX_BYTES(dq), 0ull);
+
+		stats->packets  += pkts.s.count;
+		stats->octets  += byts.s.count;
+	} /* for dq */
+
+}
+
+/** Set MAC options
+ *
+ * The options supported are the parameters below:
+ *
+ * @param node The OCI node number of the interface
+ * @param interface The physical interface number
+ * @param port The physical sub-interface port
+ * @param fcs_enable Enable FCS generation
+ * @param pad_enable Enable padding to minimum packet size
+ * @param fcs_sop_off Number of bytes at start of packet to exclude from FCS
+ *
+ * The typical use for `fcs_sop_off` is when the interface is configured
+ * to use a header such as HighGig to precede every Ethernet packet,
+ * such a header usually does not partake in the CRC32 computation stream,
+ * and its size muet be set with this parameter.
+ *
+ * @return Returns 0 on success, -1 if interface/port is invalid.
+ */
+int cvmx_pko3_interface_options(int node, int interface, int port,
+			bool fcs_enable, bool pad_enable,
+			unsigned fcs_sop_off)
+{
+	int mac_num;
+	cvmx_pko_macx_cfg_t pko_mac_cfg;
+
+	mac_num = __cvmx_pko_get_mac_num(interface, port);
+	if(mac_num < 0)
+		return -1;
+
+	pko_mac_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKO_MACX_CFG(mac_num));
+
+	/* If MAC is not assigned, return an error */
+	if (pko_mac_cfg.s.fifo_num == 0x1f)
+		return -1;
+
+	pko_mac_cfg.s.min_pad_ena = pad_enable;
+	pko_mac_cfg.s.fcs_ena = fcs_enable;
+	pko_mac_cfg.s.fcs_sop_off = fcs_sop_off;
+
+	cvmx_write_csr_node(node, CVMX_PKO_MACX_CFG(mac_num), pko_mac_cfg.u64);
+
+	return 0;
+}
+
+/** Set Descriptor Queue options
+ *
+ * The `min_pad` parameter must be in agreement with the interface-level
+ * padding option for all descriptor queues assigned to that particular
+ * interface/port.
+ */
+void cvmx_pko3_dq_options(unsigned node, unsigned dq, bool min_pad)
+{
+	cvmx_pko_pdm_dqx_minpad_t reg;
+
+	dq &= (1<<10)-1;
+	reg.u64 = cvmx_read_csr_node(node, CVMX_PKO_PDM_DQX_MINPAD(dq));
+	reg.s.minpad = min_pad;
+	cvmx_write_csr_node(node, CVMX_PKO_PDM_DQX_MINPAD(dq), reg.u64);
+}
+
+//
+// Add new native API:
+//
+// define packet descriptor, one cache line, 16 words, simple, opaque
+typedef struct cvmx_pko3_pdesc_s {
+	// PKO3 command buffer:
+	uint64_t word[16];
+	// Bookkeeping fields:
+	unsigned num_words	:4,
+		last_aura	:12,
+		flags		:3;
+} cvmx_pko3_pdesc_t;
+
+// function to create a pkt_desc from WQE
+int cvmx_pko3_pdesc_from_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
+	bool free_bufs)
+{
+return -1;
+}
+
+// function to prepend data to packet (i.e. push header
+// data bytes will be copied into pdesc
+int cvmx_pko3_pdesc_prepend(cvmx_pko3_pdesc_t *pdesc, const void *p_data, unsigned data_bytes)
+{
+
+
+return -1;
+}
+
+// function to append a gather buffer to end of packet
+// the buffer can be optionally freed by PKO
+int cvmx_pko3_pdesc_buf_append(cvmx_pko3_pdesc_t *pdesc, const void *p_data,
+		unsigned data_bytes, unsigned buffer_aura, bool free_buf)
+{
+
+return -1;
+}
+
+
+// function to remote data from head of packet (i.e. pop header)
+int cvmx_pko3_pdesc_trim(cvmx_pko3_pdesc_t *pdesc, unsigned num_bytes)
+{
+
+
+return -1;
+}
+
+// function to add completion indication via SSO
+int cvmx_pko3_pdesc_notify_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
+	unsigned node, unsigned group, unsigned tag, unsigned tt)
+{
+
+
+return -1;
+}
+
+// function to add completion indication via atomic counter
+// p_count type should be __atomic__
+int cvmx_pko3_pdesc_notify_decrement(cvmx_pko3_pdesc_t *pdesc,
+	volatile uint64_t *p_counter)
+{
+
+return -1;
+}
+
+// function to initiate transmission of a pkt_desc
+int cvmx_pko3_pdesc_transmit(cvmx_pko3_pdesc_t *pdesc, uint16_t dq)
+{
+
+return -1;
+}
+
+// function to create an empty pkt_desc
+void cvmx_pko3_pdesc_init(cvmx_pko3_pdesc_t *pdesc)
+{
+
+
+}
+
diff --git a/arch/mips/cavium-octeon/executive/cvmx-qlm.c b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
index bf9dfb7..9b24d05 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-qlm.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 90025 $<hr>
+ * <hr>$Revision: 94747 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -50,6 +50,7 @@
 #include <asm/octeon/cvmx-helper-jtag.h>
 #include <asm/octeon/cvmx-qlm.h>
 #include <asm/octeon/cvmx-clock.h>
+#include <asm/octeon/cvmx-bgxx-defs.h>
 #include <asm/octeon/cvmx-gmxx-defs.h>
 #include <asm/octeon/cvmx-gserx-defs.h>
 #include <asm/octeon/cvmx-sriox-defs.h>
@@ -125,6 +126,8 @@ int cvmx_qlm_get_num(void)
 #endif
 	else if (OCTEON_IS_MODEL(OCTEON_CNF71XX))
 		return 2;
+	else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		return 8;
 	//cvmx_dprintf("Warning: cvmx_qlm_get_num: This chip does not have QLMs\n");
 	return 0;
 }
@@ -146,19 +149,33 @@ int cvmx_qlm_interface(int interface)
 		else
 			cvmx_dprintf("Warning: cvmx_qlm_interface: Invalid interface %d\n", interface);
 	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		switch (interface) {
-		case 0:
-			return MUX_78XX_IFACE0 ? 2 : 0;
-		case 1:
-			return MUX_78XX_IFACE1 ? 3 : 1;
-		case 2:
-		case 3:
-		case 4:
-		case 5:
-			return interface + 2;
-		default:
-			break;
+		cvmx_bgxx_cmr_global_config_t gconfig;
+		cvmx_gserx_phy_ctl_t phy_ctl;
+		cvmx_gserx_cfg_t gserx_cfg;
+		int qlm;
+
+		gconfig.u64 = cvmx_read_csr(CVMX_BGXX_CMR_GLOBAL_CONFIG(interface));
+		if (gconfig.s.pmux_sds_sel) { /* Only QLM2 * QLM3 present */
+			if (interface < 2)
+				qlm = interface + 2;
+			else
+				qlm = -1;
+		} else { /* QLM0, QLM1, QLM4 - QLM7 are present */
+			if (interface < 2)
+				qlm = interface;
+			else
+				qlm = interface + 2;
+		}
+		/* make sure the QLM is powered up and out of reset */
+		if (qlm != -1) {
+			phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
+			if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
+				return -1;
+			gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
+			if (gserx_cfg.s.bgx)
+				return qlm;
 		}
+		return -1;
 	} else {
 		/* Must be cn68XX */
 		switch (interface) {
@@ -523,8 +540,8 @@ void __cvmx_qlm_speed_tweak(void)
 				cvmx_qlm_jtag_set(qlm, -1, "tcoeff_hf_ls_byp", 0);
 				cvmx_qlm_jtag_set(qlm, -1, "tcoeff_lf_ls_byp", 0);
 				cvmx_qlm_jtag_set(qlm, -1, "tcoeff_lf_byp", 0);
-				cvmx_qlm_jtag_set(qlm, -1, "rx_cap_gen2", 0);
-				cvmx_qlm_jtag_set(qlm, -1, "rx_eq_gen2", 11);
+				cvmx_qlm_jtag_set(qlm, -1, "rx_cap_gen2", 1);
+				cvmx_qlm_jtag_set(qlm, -1, "rx_eq_gen2", 8);
 				cvmx_qlm_jtag_set(qlm, -1, "serdes_tx_byp", 1);
 			}
 		}
@@ -1062,25 +1079,104 @@ static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn6xxx(int qlm)
 
 static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn78xx(int qlm)
 {
-	/*
-	 * Until gser configuration is in place, we hard code the
-	 * qlm mode here. This means that for the time being, this
-	 * function and __cvmx_get_mode_cn78xx() have to be in sync
-	 * since they are both hard coded. Note that register
-	 * CVMX_MIO_QLMX_CFG is not yet modeled by the simulator.
-	 */
-	switch(qlm) {
-	case 0:
-	case 1:
-		return CVMX_QLM_MODE_SGMII;
-	case 4:
+	cvmx_gserx_cfg_t gserx_cfg;
+
+	if (qlm >= 8)
+		return CVMX_QLM_MODE_OCI;
+
+	gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
+	if (gserx_cfg.s.pcie) {
+		switch (qlm) {
+		case 0: /* Either PEM0 x4 or PEM0 x8 */
+		{
+			cvmx_pemx_cfg_t pemx_cfg;
+			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(0));
+			if (pemx_cfg.cn78xx.lanes8)
+				return CVMX_QLM_MODE_PCIE_1X8; /* PEM0 x8 */
+			else
+				return CVMX_QLM_MODE_PCIE;     /* PEM0 x4 */
+		}
+		case 1: /* Either PEM0 x8 or PEM1 x4 */
+		{
+			cvmx_pemx_cfg_t pemx_cfg;
+			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(0));
+			if (pemx_cfg.cn78xx.lanes8)
+				return CVMX_QLM_MODE_DISABLED; /* PEM0 x8 */
+			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(1));
+			if (pemx_cfg.cn78xx.lanes8 == 0)
+				return CVMX_QLM_MODE_PCIE;     /* PEM1 x4 */
+			else
+				return CVMX_QLM_MODE_DISABLED; /* PEM0 x8 */
+		}
+		case 2: /* Either PEM2 x4 or PEM2 x8 */
+		{
+			cvmx_pemx_cfg_t pemx_cfg;
+			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(2));
+			if (pemx_cfg.cn78xx.lanes8)
+				return CVMX_QLM_MODE_PCIE_1X8;  /* PEM2 x8 */
+			else
+				return CVMX_QLM_MODE_PCIE;      /* PEM2 x4 */
+		}
+		case 3: /* Either PEM2 x8 or PEM3 x4 */
+		{
+			cvmx_pemx_cfg_t pemx_cfg;
+			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(2));
+			if (pemx_cfg.cn78xx.lanes8)
+				return CVMX_QLM_MODE_DISABLED;  /* PEM2 x8 */
+
+			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(3));
+			if (pemx_cfg.cn78xx.lanes8 == 0) {
+				if (cvmx_read_csr(CVMX_PEMX_QLM(3)) == 0)
+					return CVMX_QLM_MODE_PCIE; /* PEM3 x4 */
+			}
+			return CVMX_QLM_MODE_DISABLED;  /* PEM2 x8 or uses QLM4 */
+		}
+		case 4: /* PEM3 x4 */
+		{
+			cvmx_pemx_cfg_t pemx_cfg;
+			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(3));
+			if (pemx_cfg.cn78xx.lanes8 == 0) {
+				if (cvmx_read_csr(CVMX_PEMX_QLM(3)))
+					return CVMX_QLM_MODE_PCIE; /* PEM3 x4 */
+			}
+			return CVMX_QLM_MODE_DISABLED;  /* PEM2 x8 or uses QLM3 */
+		}
+		default:
+			return CVMX_QLM_MODE_DISABLED;
+		}
+	} else if (gserx_cfg.s.ila) {
 		return CVMX_QLM_MODE_ILK;
-	case 5:
-	case 6:
-	case 7:
-		return CVMX_QLM_MODE_XAUI;
-	}
-	return CVMX_QLM_MODE_DISABLED;
+	} else if (gserx_cfg.s.bgx) {
+		cvmx_gserx_lane_mode_t lane_mode;
+		lane_mode.u64 = cvmx_read_csr(CVMX_GSERX_LANE_MODE(qlm));
+		switch(lane_mode.s.lmode) {
+		case 0x0: /* R_25G_REFCLK100 */
+		case 0x1: /* R_5G_REFCLK100 */
+		case 0x2: /* R_8G_REFCLK100 */
+		case 0x3: /* R_125G_REFCLK15625_KX */
+			return CVMX_QLM_MODE_DISABLED;
+		case 0x4: /* R_3125G_REFCLK15625_XAUI */
+			return CVMX_QLM_MODE_XAUI;
+		case 0x5: /* R_103215G_REFCLK15625_KR */
+			if (gserx_cfg.s.bgx_quad)
+				return CVMX_QLM_MODE_XLAUI;
+			else
+				return CVMX_QLM_MODE_XFI;
+		case 0x6: /* R_125G_REFCLK15625_SGMII */
+			return CVMX_QLM_MODE_SGMII;
+		case 0x7: /* R_5G_REFCLK15625_QSGMII */
+			return CVMX_QLM_MODE_DISABLED;
+		case 0x8: /* R_625G_REFCLK15625_RXAUI */
+			return CVMX_QLM_MODE_RXAUI;
+		case 0x9: /* R_25G_REFCLK125 */
+		case 0xa: /* R_5G_REFCLK125 */
+		case 0xb: /* R_8G_REFCLK125 */
+			return CVMX_QLM_MODE_DISABLED;
+		default:
+			return CVMX_QLM_MODE_DISABLED;
+		}
+	} else
+		return CVMX_QLM_MODE_DISABLED;
 }
 
 /*
@@ -1110,10 +1206,18 @@ int cvmx_qlm_measure_clock(int qlm)
 	cvmx_mio_ptp_clock_cfg_t ptp_clock;
 	uint64_t count;
 	uint64_t start_cycle, stop_cycle;
+	int evcnt_offset = 0x10;
+	static int ref_clock[16] = {0};
+
+	if (ref_clock[qlm])
+		return ref_clock[qlm];
 
 	if (OCTEON_IS_MODEL(OCTEON_CN3XXX) || OCTEON_IS_MODEL(OCTEON_CN5XXX))
 		return -1;
 
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		evcnt_offset = 0x20;
+
 	/* Force the reference to 156.25Mhz when running in simulation.
 	   This supports the most speeds */
 #ifdef CVMX_BUILD_FOR_UBOOT
@@ -1123,6 +1227,8 @@ int cvmx_qlm_measure_clock(int qlm)
 	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM)
 		return 156250000;
 #endif
+	/* Fix reference clock for OCI QLMs */
+
 	/* Disable the PTP event counter while we configure it */
 	ptp_clock.u64 = cvmx_read_csr(CVMX_MIO_PTP_CLOCK_CFG);	/* For CN63XXp1 errata */
 	ptp_clock.s.evcnt_en = 0;
@@ -1130,7 +1236,7 @@ int cvmx_qlm_measure_clock(int qlm)
 	/* Count on rising edge, Choose which QLM to count */
 	ptp_clock.u64 = cvmx_read_csr(CVMX_MIO_PTP_CLOCK_CFG);	/* For CN63XXp1 errata */
 	ptp_clock.s.evcnt_edge = 0;
-	ptp_clock.s.evcnt_in = 0x10 + qlm;
+	ptp_clock.s.evcnt_in = evcnt_offset + qlm;
 	cvmx_write_csr(CVMX_MIO_PTP_CLOCK_CFG, ptp_clock.u64);
 	/* Clear MIO_PTP_EVT_CNT */
 	cvmx_read_csr(CVMX_MIO_PTP_EVT_CNT);	/* For CN63XXp1 errata */
@@ -1156,7 +1262,8 @@ int cvmx_qlm_measure_clock(int qlm)
 	/* Clock counted down, so reverse it */
 	count = 1000000000 - count;
 	/* Return the rate */
-	return count * cvmx_clock_get_rate(CVMX_CLOCK_CORE) / (stop_cycle - start_cycle);
+	ref_clock[qlm] = count * cvmx_clock_get_rate(CVMX_CLOCK_CORE) / (stop_cycle - start_cycle);
+	return ref_clock[qlm];
 }
 
 void cvmx_qlm_display_registers(int qlm)
diff --git a/arch/mips/cavium-octeon/executive/cvmx-range.c b/arch/mips/cavium-octeon/executive/cvmx-range.c
index 6917eef..62c4662 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-range.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-range.c
@@ -155,7 +155,7 @@ int cvmx_range_reserve(uint64_t range_addr, uint64_t owner, uint64_t base, uint6
 	uint64_t up = base + cnt;
 
 	size = cvmx_read64_uint64(addr_of_size(range_addr));
-	if (up >= size) {
+	if (up > size) {
 		cvmx_dprintf("ERROR: invalid base or cnt size=%d base+cnt=%d \n", (int) size, (int)up);
 		return -1;
 	}
@@ -163,8 +163,7 @@ int cvmx_range_reserve(uint64_t range_addr, uint64_t owner, uint64_t base, uint6
 		r_owner = cvmx_read64_uint64(addr_of_element(range_addr,i));
 		//cvmx_dprintf("%d: %llx\n", (int) i,(unsigned long long) r_owner);
 		if (r_owner != CVMX_RANGE_AVAILABLE) {
-			cvmx_dprintf("ERROR: failed to reserve base+cnt=%d \n", (int)i);
-			cvmx_range_show(range_addr);
+			cvmx_dprintf("INFO: resource already reserved base+cnt=%d %llu %llu %llx %llx %llx\n", (int)i, (unsigned long long)cnt, (unsigned long long)base, (unsigned long long)r_owner, (unsigned long long)range_addr, (unsigned long long)owner);
 			return -1;
 		}
 	}
@@ -236,7 +235,7 @@ int cvmx_range_free_with_base(uint64_t range_addr, int base, int cnt)
 	uint64_t up = base + cnt;
 
 	size = cvmx_read64_uint64(addr_of_size(range_addr));
-	if (up >= size) {
+	if (up > size) {
 		cvmx_dprintf("ERROR: invalid base or cnt size=%d base+cnt=%d \n", (int) size, (int)up);
 		return -1;
 	}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-srio.c b/arch/mips/cavium-octeon/executive/cvmx-srio.c
index 8a2bfce..4b0553b 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-srio.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-srio.c
@@ -967,7 +967,7 @@ int _cvmx_srio_config_read32(int srio_port, int srcid_index, int destid, int is1
 				cvmx_dprintf("SRIO%d: Remote read [id=0x%04x hop=%3d offset=0x%06x] <= ", srio_port, destid, hopcount, (unsigned int)offset);
 
 			/* Finally do the maintenance read to complete the config request */
-#ifdef __LITTLE_ENDIAN
+#if defined(CVMX_BUILD_FOR_LINUX_KERNEL) &&  defined(__LITTLE_ENDIAN)
 			/*
 			 * When running in little endian mode, the cpu xor's bit
 			 * 2 of the address. We need to xor it here to cancel it
@@ -1158,7 +1158,7 @@ int _cvmx_srio_config_write32(int srio_port, int srcid_index, int destid, int is
 					     (unsigned int)data);
 
 			/* Finally do the maintenance write to complete the config request */
-#ifdef __LITTLE_ENDIAN
+#if defined(CVMX_BUILD_FOR_LINUX_KERNEL) &&  defined(__LITTLE_ENDIAN)
 			/*
 			 * When running in little endian mode, the cpu xor's bit
 			 * 2 of the address. We need to xor it here to cancel it
@@ -1557,7 +1557,8 @@ int cvmx_srio_physical_unmap(uint64_t physical_address, uint64_t size)
 	   Type[1] is mapped to the No Snoop
 	   Type[2] is mapped directly to bit 50 of the SLI address
 	   Type[3] is mapped directly to bit 59 of the SLI address */
-	read_s2m_type = ((subid.cn63xx.ba >> (50 - 34)) & 1 << 2) | ((subid.cn63xx.ba >> (59 - 34)) & 1 << 3);
+	read_s2m_type = (((subid.cn63xx.ba >> (50 - 34)) & 1) << 2) | 
+		(((subid.cn63xx.ba >> (59 - 34)) & 1) << 3);
 	read_s2m_type |= subid.s.rtype;
 	__cvmx_srio_free_subid(mem_index);
 	__cvmx_srio_free_s2m(subid.s.port, read_s2m_type);
diff --git a/arch/mips/cavium-octeon/executive/octeon-feature.c b/arch/mips/cavium-octeon/executive/octeon-feature.c
index 858bf56..4b0d8df 100644
--- a/arch/mips/cavium-octeon/executive/octeon-feature.c
+++ b/arch/mips/cavium-octeon/executive/octeon-feature.c
@@ -136,6 +136,9 @@ void __init octeon_feature_init(void)
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_CN78XX_WQE);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_SPI);
 	OCTEON_FEATURE_SET(OCTEON_FEATURE_BCH);
+	OCTEON_FEATURE_SET(OCTEON_FEATURE_PKI);
+	OCTEON_FEATURE_SET(OCTEON_FEATURE_OCLA);
+	OCTEON_FEATURE_SET(OCTEON_FEATURE_FAU);
 
 	val = OCTEON_FEATURE_SUCCESS;
 
diff --git a/arch/mips/cavium-octeon/executive/octeon-model.c b/arch/mips/cavium-octeon/executive/octeon-model.c
index f3331a6..9b1d3e4 100644
--- a/arch/mips/cavium-octeon/executive/octeon-model.c
+++ b/arch/mips/cavium-octeon/executive/octeon-model.c
@@ -43,7 +43,7 @@
  * File defining functions for working with different Octeon
  * models.
  *
- * <hr>$Revision: 83576 $<hr>
+ * <hr>$Revision: 93822 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/octeon.h>
@@ -139,7 +139,8 @@ const char *octeon_model_get_string_buffer(uint32_t chip_id, char *buffer)
 	cvmx_mio_fus_dat2_t fus_dat2;
 	cvmx_mio_fus_dat3_t fus_dat3;
 	char fuse_model[10];
-	uint32_t fuse_data = 0;
+	char fuse_suffix[4] = {0};
+	uint64_t fuse_data = 0;
 
 	fus3.u64 = 0;
 	if (OCTEON_IS_MODEL(OCTEON_CN3XXX) || OCTEON_IS_MODEL(OCTEON_CN5XXX))
@@ -441,7 +442,11 @@ const char *octeon_model_get_string_buffer(uint32_t chip_id, char *buffer)
 		break;
 	case 0x96:		/* CN70XX */
 		family = "70";
-		if (fus_dat3.cn70xx.nozip)
+		if (cvmx_read_csr(CVMX_MIO_FUS_PDF) & (0x1ULL << 32))
+			family = "71";
+		if (fus_dat2.cn70xx.nocrypto)
+			suffix = "CP";
+		else if (fus_dat2.cn70xx.nodfa_cp2)
 			suffix = "SCP";
 		else
 			suffix = "AAP";
@@ -459,34 +464,82 @@ const char *octeon_model_get_string_buffer(uint32_t chip_id, char *buffer)
 #endif
 
 	if (family[0] != '3') {
-		int fuse_base = 384 / 8;
-		if (family[0] == '6')
-			fuse_base = 832 / 8;
+		if (OCTEON_IS_OCTEON1PLUS() || OCTEON_IS_OCTEON2()) {
+			int fuse_base = 384 / 8;
+			if (family[0] == '6' || OCTEON_IS_OCTEON3())
+				fuse_base = 832 / 8;
+			/* Check for model in fuses, overrides normal decode */
+			/* This is _not_ valid for Octeon CN3XXX models */
+			fuse_data |= cvmx_fuse_read_byte(fuse_base + 5);
+			fuse_data = fuse_data << 8;
+			fuse_data |= cvmx_fuse_read_byte(fuse_base + 4);
+			fuse_data = fuse_data << 8;
+			fuse_data |= cvmx_fuse_read_byte(fuse_base + 3);
+			fuse_data = fuse_data << 8;
+			fuse_data |= cvmx_fuse_read_byte(fuse_base + 2);
+			fuse_data = fuse_data << 8;
+			fuse_data |= cvmx_fuse_read_byte(fuse_base + 1);
+			fuse_data = fuse_data << 8;
+			fuse_data |= cvmx_fuse_read_byte(fuse_base);
+			if (fuse_data & 0x7ffff) {
+				int model = fuse_data & 0x3fff;
+				int suffix = (fuse_data >> 14) & 0x1f;
+				if (suffix && model) {      /* Have both number and suffix in fuses, so both */
+					sprintf(fuse_model, "%d%c", model, 'A' + suffix - 1);
+					core_model = "";
+					family = fuse_model;
+				} else if (suffix && !model) {      /* Only have suffix, so add suffix to 'normal' model number */
+					sprintf(fuse_model, "%s%c", core_model, 'A' + suffix - 1);
+					core_model = fuse_model;
+				} else {    /* Don't have suffix, so just use model from fuses */
 
-		/* Check for model in fuses, overrides normal decode */
-		/* This is _not_ valid for Octeon CN3XXX models */
-		fuse_data |= cvmx_fuse_read_byte(fuse_base + 3);
-		fuse_data = fuse_data << 8;
-		fuse_data |= cvmx_fuse_read_byte(fuse_base + 2);
-		fuse_data = fuse_data << 8;
-		fuse_data |= cvmx_fuse_read_byte(fuse_base + 1);
-		fuse_data = fuse_data << 8;
-		fuse_data |= cvmx_fuse_read_byte(fuse_base);
-		if (fuse_data & 0x7ffff) {
-			int model = fuse_data & 0x3fff;
-			int suffix = (fuse_data >> 14) & 0x1f;
-			if (suffix && model) {	/* Have both number and suffix in fuses, so both */
-				sprintf(fuse_model, "%d%c", model, 'A' + suffix - 1);
-				core_model = "";
-				family = fuse_model;
-			} else if (suffix && !model) {	/* Only have suffix, so add suffix to 'normal' model number */
-				sprintf(fuse_model, "%s%c", core_model, 'A' + suffix - 1);
-				core_model = fuse_model;
-			} else {	/* Don't have suffix, so just use model from fuses */
+					sprintf(fuse_model, "%d", model);
+					core_model = "";
+					family = fuse_model;
+				}
+			}
+		} else {
+			/* Format for Octeon 3. */
+			fuse_data = cvmx_read_csr(CVMX_MIO_FUS_PDF);
+			if (fuse_data & ((1ULL << 48) - 1)) {
+				char suffix_str[4] = {0};
+				int i;
+				int model = fuse_data & ((1ULL << 17) - 1);
+				int suf_bits = (fuse_data >> 17) & ((1ULL << 15) - 1);
+				for (i = 0; i < 3; i++) {
+					/* A-Z are encoded 1-26, 27-31 are
+					   reserved values. */
+					if ((suf_bits & 0x1f) && (suf_bits & 0x1f) <= 26)
+						suffix_str[i] = 'A' + (suf_bits & 0x1f) - 1;
+					suf_bits = suf_bits >> 5;
+				}
+				if (strlen(suffix_str) && model) {      /* Have both number and suffix in fuses, so both */
+					sprintf(fuse_model, "%d%s", model, suffix_str);
+					core_model = "";
+					family = fuse_model;
+				} else if (strlen(suffix_str) && !model) {      /* Only have suffix, so add suffix to 'normal' model number */
+					sprintf(fuse_model, "%s%s", core_model, suffix_str);
+					core_model = fuse_model;
+				} else if (model) {    /* Don't have suffix, so just use model from fuses */
+					sprintf(fuse_model, "%d", model);
+					core_model = "";
+					family = fuse_model;
+				}
+				/* in case of invalid model suffix bits
+				   only set, we do nothing. */
 
-				sprintf(fuse_model, "%d", model);
-				core_model = "";
-				family = fuse_model;
+				/* Check to see if we have a custom type
+				   suffix. */
+				suf_bits = (fuse_data >> 33) & ((1ULL << 15) - 1);
+				for (i = 0; i < 3; i++) {
+					/* A-Z are encoded 1-26, 27-31 are
+					   reserved values. */
+					if ((suf_bits & 0x1f) && (suf_bits & 0x1f) <= 26)
+						fuse_suffix[i] = 'A' + (suf_bits & 0x1f) - 1;
+					suf_bits = suf_bits >> 5;
+				}
+				if (strlen(fuse_suffix))
+					suffix = fuse_suffix;
 			}
 		}
 	}
diff --git a/arch/mips/cavium-octeon/octeon-rapidio.c b/arch/mips/cavium-octeon/octeon-rapidio.c
index aa55b41..2976984 100644
--- a/arch/mips/cavium-octeon/octeon-rapidio.c
+++ b/arch/mips/cavium-octeon/octeon-rapidio.c
@@ -315,12 +315,12 @@ int octeon_rio_dma_mem(struct rio_dev *rdev, u64 local_addr,
 	sli_address += memmap & 0x3ffffffffull;
 
 	/* Create the DMA header */
-	header.u64 = 0;
-	header.s.fport = 0;
-	header.s.lport = rdev->net->hport->id;
-	header.s.type = (is_outbound) ? CVMX_DMA_ENGINE_TRANSFER_OUTBOUND :
+	header.word0.u64 = 0;
+	header.word0.cn38xx.fport = 0;
+	header.word0.cn38xx.lport = rdev->net->hport->id;
+	header.word0.cn38xx.type = (is_outbound) ? CVMX_DMA_ENGINE_TRANSFER_OUTBOUND :
 		CVMX_DMA_ENGINE_TRANSFER_INBOUND;
-	header.s.addr = virt_to_phys(&dma_busy);
+	header.word0.cn38xx.addr = virt_to_phys(&dma_busy);
 
 	/* Do the DMA */
 	result = cvmx_dma_engine_transfer(0, header, local_addr,
diff --git a/arch/mips/include/asm/octeon/cvmx-agl-defs.h b/arch/mips/include/asm/octeon/cvmx-agl-defs.h
index 800d4ab..e0a11f8 100644
--- a/arch/mips/include/asm/octeon/cvmx-agl-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-agl-defs.h
@@ -5119,20 +5119,20 @@ union cvmx_agl_prtx_ctl {
 	uint64_t u64;
 	struct cvmx_agl_prtx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t drv_byp                      : 1;  /**< Bypass the compensation controller and use
+	uint64_t drv_byp                      : 1;  /**< When set, bypass the compensation controller and use
                                                          DRV_NCTL and DRV_PCTL */
 	uint64_t reserved_62_62               : 1;
-	uint64_t cmp_pctl                     : 6;  /**< PCTL drive strength from the compensation ctl */
+	uint64_t cmp_pctl                     : 6;  /**< PCTL drive strength from the HW compensation controller */
 	uint64_t reserved_54_55               : 2;
-	uint64_t cmp_nctl                     : 6;  /**< NCTL drive strength from the compensation ctl */
+	uint64_t cmp_nctl                     : 6;  /**< NCTL drive strength from the HW compensation controller */
 	uint64_t reserved_46_47               : 2;
-	uint64_t drv_pctl                     : 6;  /**< PCTL drive strength to use in bypass mode
-                                                         Reset value of 19 is for 50 ohm termination */
+	uint64_t drv_pctl                     : 6;  /**< PCTL drive strength to use in bypass mode.
+                                                         Reset value of 13 is for 50 ohm termination */
 	uint64_t reserved_38_39               : 2;
-	uint64_t drv_nctl                     : 6;  /**< NCTL drive strength to use in bypass mode
-                                                         Reset value of 15 is for 50 ohm termination */
+	uint64_t drv_nctl                     : 6;  /**< NCTL drive strength to use in bypass mode.
+                                                         Reset value of 12 is for 50 ohm termination */
 	uint64_t reserved_31_31               : 1;
-	uint64_t clk_set                      : 7;  /**< The clock delay as determined by the DLL */
+	uint64_t clk_set                      : 7;  /**< The clock delay as determined by the on board HW DLL */
 	uint64_t clkrx_byp                    : 1;  /**< Bypass the RX clock delay setting
                                                          Skews RXC from RXD,RXCTL
                                                          By default, HW internally shifts the RXC clock
@@ -5147,11 +5147,11 @@ union cvmx_agl_prtx_ctl {
 	uint64_t clktx_set                    : 7;  /**< TX clock delay setting to use in bypass mode
                                                          Skews TXC from TXD */
 	uint64_t refclk_sel                   : 2;  /**< Select the refclk to use.  Normal RGMII specification requires a 125MHz oscillator.  In
-                                                         order to save some system cost, a 500MHz coprocessor clock can be divided down and remove
-                                                         the requirements for the external oscillator.  Additionally, in some well defined systems,
-                                                         the link partner may be able to source the RXC.  The RGMII would operate correctly in
-                                                         1000Mbs mode only.  (INTERNAL: Some programming magic could allow for 10/100
-                                                         operation if critical).
+                                                         order to reduce system cost, a 500MHz coprocessor clock can be divided down and remove the
+                                                         requirements for the external oscillator.  Additionally, in some well defined systems, the
+                                                         link partner may be able to source the RXC.  The RGMII would operate correctly in 1000Mbs
+                                                         mode only.  (INTERNAL: Some programming magic could allow for 10/100 operation if
+                                                         critical).
                                                          0 = RGMII REFCLK
                                                          1 = RGMII RXC (1000Mbs only) (INTERNAL: some programming restrictions apply for 10/100)
                                                          2 = divided coprocessor clk
@@ -5263,20 +5263,20 @@ union cvmx_agl_prtx_ctl {
 	struct cvmx_agl_prtx_ctl_cn61xx       cn68xxp1;
 	struct cvmx_agl_prtx_ctl_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t drv_byp                      : 1;  /**< Bypass the compensation controller and use
+	uint64_t drv_byp                      : 1;  /**< When set, bypass the compensation controller and use
                                                          DRV_NCTL and DRV_PCTL */
 	uint64_t reserved_61_62               : 2;
-	uint64_t cmp_pctl                     : 5;  /**< PCTL drive strength from the compensation ctl */
+	uint64_t cmp_pctl                     : 5;  /**< PCTL drive strength from the HW compensation controller */
 	uint64_t reserved_53_55               : 3;
-	uint64_t cmp_nctl                     : 5;  /**< NCTL drive strength from the compensation ctl */
+	uint64_t cmp_nctl                     : 5;  /**< NCTL drive strength from the HW compensation controller */
 	uint64_t reserved_45_47               : 3;
-	uint64_t drv_pctl                     : 5;  /**< PCTL drive strength to use in bypass mode
-                                                         Reset value of 19 is for 50 ohm termination */
+	uint64_t drv_pctl                     : 5;  /**< PCTL drive strength to use in bypass mode.
+                                                         Reset value of 13 is for 50 ohm termination */
 	uint64_t reserved_37_39               : 3;
-	uint64_t drv_nctl                     : 5;  /**< NCTL drive strength to use in bypass mode
-                                                         Reset value of 15 is for 50 ohm termination */
+	uint64_t drv_nctl                     : 5;  /**< NCTL drive strength to use in bypass mode.
+                                                         Reset value of 12 is for 50 ohm termination */
 	uint64_t reserved_31_31               : 1;
-	uint64_t clk_set                      : 7;  /**< The clock delay as determined by the DLL */
+	uint64_t clk_set                      : 7;  /**< The clock delay as determined by the on board HW DLL */
 	uint64_t clkrx_byp                    : 1;  /**< Bypass the RX clock delay setting
                                                          Skews RXC from RXD,RXCTL
                                                          By default, HW internally shifts the RXC clock
@@ -5291,11 +5291,11 @@ union cvmx_agl_prtx_ctl {
 	uint64_t clktx_set                    : 7;  /**< TX clock delay setting to use in bypass mode
                                                          Skews TXC from TXD */
 	uint64_t refclk_sel                   : 2;  /**< Select the refclk to use.  Normal RGMII specification requires a 125MHz oscillator.  In
-                                                         order to save some system cost, a 500MHz coprocessor clock can be divided down and remove
-                                                         the requirements for the external oscillator.  Additionally, in some well defined systems,
-                                                         the link partner may be able to source the RXC.  The RGMII would operate correctly in
-                                                         1000Mbs mode only.  (INTERNAL: Some programming magic could allow for 10/100
-                                                         operation if critical).
+                                                         order to reduce system cost, a 500MHz coprocessor clock can be divided down and remove the
+                                                         requirements for the external oscillator.  Additionally, in some well defined systems, the
+                                                         link partner may be able to source the RXC.  The RGMII would operate correctly in 1000Mbs
+                                                         mode only.  (INTERNAL: Some programming magic could allow for 10/100 operation if
+                                                         critical).
                                                          0 = RGMII REFCLK
                                                          1 = RGMII RXC (1000Mbs only) (INTERNAL: some programming restrictions apply for 10/100)
                                                          2 = divided coprocessor clk
diff --git a/arch/mips/include/asm/octeon/cvmx-app-hotplug.h b/arch/mips/include/asm/octeon/cvmx-app-hotplug.h
index dc308d3..87c9877 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-hotplug.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-hotplug.h
@@ -86,8 +86,8 @@ extern "C" {
 */
 typedef struct cvmx_app_hotplug_callbacks {
 	void (*hotplug_start) (void *ptr);
-	void (*cores_added_callback) (uint32_t, void *ptr);
-	void (*cores_removed_callback) (uint32_t, void *ptr);
+	void (*cores_added_callback) (cvmx_coremask_t *, void *ptr);
+	void (*cores_removed_callback) (cvmx_coremask_t *, void *ptr);
 	void (*shutdown_callback) (void *ptr);
 	void (*unplug_core_callback) (void *ptr);
 } cvmx_app_hotplug_callbacks_t;
@@ -154,7 +154,7 @@ typedef struct cvmx_app_hotplug_global cvmx_app_hotplug_global_t;
 
 int is_core_being_hot_plugged(void);
 int is_app_under_boot_or_shutdown(void);
-void set_app_unber_boot(int val);
+void set_app_under_boot(int val);
 void set_app_under_shutdown(int val);
 int cvmx_app_hotplug_shutdown_request(const struct cvmx_coremask *, int);
 int cvmx_app_hotplug_unplug_cores(int index, const struct cvmx_coremask *pcm,
diff --git a/arch/mips/include/asm/octeon/cvmx-app-init.h b/arch/mips/include/asm/octeon/cvmx-app-init.h
index 1f75ff4..b80285f 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-init.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-init.h
@@ -41,7 +41,7 @@
  * @file
  * Header file for simple executive application initialization.  This defines
  * part of the ABI between the bootloader and the application.
- * <hr>$Revision: 88298 $<hr>
+ * <hr>$Revision: 88720 $<hr>
  *
  */
 
@@ -273,6 +273,7 @@ enum cvmx_board_types_enum {
 	CVMX_BOARD_TYPE_MOONSHOT = 54,
 	CVMX_BOARD_TYPE_EVB7000_INTERPOSER = 55,
 	CVMX_BOARD_TYPE_EVB7000 = 56,
+	CVMX_BOARD_TYPE_EVB7000_SFF = 57,
 	CVMX_BOARD_TYPE_MAX,
 	/* NOTE:  256-257 are being used by a customer. */
 
@@ -397,6 +398,7 @@ static inline const char *cvmx_board_type_to_string(enum cvmx_board_types_enum t
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MOONSHOT)
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_INTERPOSER)
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000)
+		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_SFF)
 		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MAX)
 
 		    /* Customer boards listed here */
diff --git a/arch/mips/include/asm/octeon/cvmx-ase-defs.h b/arch/mips/include/asm/octeon/cvmx-ase-defs.h
index 5111139..144a3c1 100644
--- a/arch/mips/include/asm/octeon/cvmx-ase-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ase-defs.h
@@ -964,15 +964,15 @@ union cvmx_ase_lue_config {
 	uint64_t pfcache_en                   : 1;  /**< Enable bucket entry PFLEN caching. When clear, if PFLEN < OSM-line, PFLEN BE caching is
                                                          disabled, and a BEREQ is made for each PFLEN group of BEs processed. When set, if PFLEN <
                                                          OSM-line, only a single BEREQ is made for the OSM-line which caches all of the BEs. */
-	uint64_t pfab_en                      : 1;  /**< Enable bucket entry prefetch phase A/B request scheme. When clear, each Bucket Walk Engine
+	uint64_t pfab_en                      : 1;  /**< Enable bucket entry prefetch phase A/B request scheme. When clear, each bucket walk engine
                                                          is allowed to have a maximum of 8 outstanding rule read requests in progress at a time.
-                                                         When set, each Bucket Walk Engine is allowed to have a maximum of 16 outstanding rule read
-                                                         requests in progress at a time, split in to two groups of 8 (Phases A and B). After the
+                                                         When set, each bucket walk engine is allowed to have a maximum of 16 outstanding rule read
+                                                         requests in progress at a time, split into two groups of 8 (Phases A and B). After the
                                                          initial 8 bucket entries, the next set of [up to] 8 bucket entries are speculatively read
-                                                         and submitted to the Rule Walk Engine. Subsequent speculative reads are performed once all
+                                                         and submitted to the rule walk engine. Subsequent speculative reads are performed once all
                                                          outstanding requests for a phase have completed. */
 	uint64_t reserved_20_31               : 12;
-	uint64_t twc_strspsta_rr              : 1;  /**< Within the TWC block, configures the arbiter which selects between Pending TWE or BWE
+	uint64_t twc_strspsta_rr              : 1;  /**< Within the TWC block, configures the arbiter which selects between pending TWE or BWE
                                                          STRSPs. When clear, fixed priority arbitration is selected, which gives BWEs higher
                                                          priority over TWEs. When set, round robin arbitration is selected which ensures fairness
                                                          across the TWE and BWE STRSPs. */
@@ -983,7 +983,7 @@ union cvmx_ase_lue_config {
                                                          requests and lookup requests. When configured for fixed priority, host accesses have
                                                          higher priority. If enabled, use round-robin. If disabled, use fixed priority. */
 	uint64_t reserved_4_16                : 13;
-	uint64_t rme_enable                   : 4;  /**< Each bit, when set, enables rule processing by a local Rule Match Engine. */
+	uint64_t rme_enable                   : 4;  /**< Each bit, when set, enables rule processing by a local rule match engine. */
 #else
 	uint64_t rme_enable                   : 4;
 	uint64_t reserved_4_16                : 13;
diff --git a/arch/mips/include/asm/octeon/cvmx-asm.h b/arch/mips/include/asm/octeon/cvmx-asm.h
index 2755a0f..914e924 100644
--- a/arch/mips/include/asm/octeon/cvmx-asm.h
+++ b/arch/mips/include/asm/octeon/cvmx-asm.h
@@ -42,7 +42,7 @@
  *
  * This is file defines ASM primitives for the executive.
 
- * <hr>$Revision: 86220 $<hr>
+ * <hr>$Revision: 90510 $<hr>
  *
  *
  */
@@ -102,8 +102,12 @@
 #define COP0_DEPC	$24,0	/* Debug PC */
 #define COP0_PERFCONTROL0 $25,0	/* Performance counter control */
 #define COP0_PERFCONTROL1 $25,2	/* Performance counter control */
+#define COP0_PERFCONTROL2 $25,4	/* Performance counter control */
+#define COP0_PERFCONTROL3 $25,6	/* Performance counter control */
 #define COP0_PERFVALUE0	$25,1	/* Performance counter */
 #define COP0_PERFVALUE1	$25,3	/* Performance counter */
+#define COP0_PERFVALUE2	$25,5	/* Performance counter */
+#define COP0_PERFVALUE3	$25,7	/* Performance counter */
 #define COP0_ERRCTL	$26,0	/* Cache error status (OIII) */
 #define COP0_CACHEERRI	$27,0	/* I cache error status */
 #define COP0_CACHEERRD	$27,1	/* D cache error status */
@@ -249,6 +253,7 @@ extern "C" {
 #define CVMX_CACHE_WBIL2(address, offset) CVMX_CACHE(23, address, offset)	// unlock the state.
 #define CVMX_CACHE_WBIL2I(address, offset) CVMX_CACHE(3, address, offset)	// invalidate the cache block and clear the USED bits for the block
 #define CVMX_CACHE_LTGL2I(address, offset) CVMX_CACHE(7, address, offset)	// load virtual tag and data for the L2 cache block into L2C_TAD0_TAG register
+#define CVMX_CACHE_L2HWB(address, offset) CVMX_CACHE(27, address, offset)	// L2 cache hit writeback (no invalidate)
 
 /* new instruction to make RC4 run faster */
 #define CVMX_BADDU(result, input1, input2) asm ("baddu %[rd],%[rs],%[rt]" : [rd] "=d" (result) : [rs] "d" (input1) , [rt] "d" (input2))
@@ -360,6 +365,13 @@ extern "C" {
 #define CVMX_EHB asm volatile ("ehb")
 
 /* mul stuff */
+#define CVMX_MTM0_V3(m0, m3) asm volatile (".set push\n.set arch=octeon3\nmtm0 %[rs], %[rt]\n.set pop" : : [rs] "d" (m0), [rt] "d" (m3))
+#define CVMX_MTM1_V3(m1, m4) asm volatile (".set push\n.set arch=octeon3\nmtm1 %[rs], %[rt]\n.set pop" : : [rs] "d" (m1), [rt] "d" (m4))
+#define CVMX_MTM2_V3(m2, m5) asm volatile (".set push\n.set arch=octeon3\nmtm2 %[rs], %[rt]\n.set pop" : : [rs] "d" (m2), [rt] "d" (m5))
+#define CVMX_MTP0_V3(p0, p3) asm volatile (".set push\n.set arch=octeon3\nmtp0 %[rs], %[rt]\n.set pop" : : [rs] "d" (p0), [rt] "d" (p3))
+#define CVMX_MTP1_V3(p1, p4) asm volatile (".set push\n.set arch=octeon3\nmtp1 %[rs], %[rt]\n.set pop" : : [rs] "d" (p1), [rt] "d" (p4))
+#define CVMX_MTP2_V3(p2, p5) asm volatile (".set push\n.set arch=octeon3\nmtp2 %[rs], %[rt]\n.set pop" : : [rs] "d" (p2), [rt] "d" (p5))
+
 #define CVMX_MTM0(m) asm volatile ("mtm0 %[rs]" : : [rs] "d" (m))
 #define CVMX_MTM1(m) asm volatile ("mtm1 %[rs]" : : [rs] "d" (m))
 #define CVMX_MTM2(m) asm volatile ("mtm2 %[rs]" : : [rs] "d" (m))
@@ -586,6 +598,70 @@ extern "C" {
 // pos can be 0-1
 #define CVMX_MT_SMS4_RESINP(val,pos)	asm volatile ("dmtc2 %[rt],0x0100+"CVMX_TMP_STR(pos) : : [rt] "d" (val))
 
+// CAMELLIA
+
+// pos can be 0-1
+#define CVMX_MT_CAMELLIA_RESINP(val,pos) CVMX_MT_AES_RESULT(val,pos)
+#define CVMX_MT_CAMELLIA_ROUND(val)      asm volatile ("dmtc2 %[rt],0x3114" : : [rt] "d" (val))
+#define CVMX_MT_CAMELLIA_FL(val)         asm volatile ("dmtc2 %[rt],0x115" : : [rt] "d" (val))
+#define CVMX_MT_CAMELLIA_FLINV(val)      asm volatile ("dmtc2 %[rt],0x116" : : [rt] "d" (val))
+
+// pos can be 0-1
+#define CVMX_MF_CAMELLIA_RESINP(val,pos) CVMX_MF_AES_RESULT(val,pos)
+
+// ZUC
+
+// pos can be 0-7  (0-6 normally used) pos=i has LFSR_s(2*i) in msbs,
+// LFSR_s(2*i + 1) in lsbs, <63> and <31> are unused
+#define CVMX_MT_ZUC_LFSR(val,pos) CVMX_MT_HSH_DATW(val,pos)
+// pos can be 0-1  (not normally used) pos=0 has F_R1 in lsbs, pos=1 has F_R2 in lsbs
+#define CVMX_MT_ZUC_FSM(val,pos)  CVMX_MT_HSH_IVW(val,(pos)+1)
+#define CVMX_MT_ZUC_RESULT(val)   CVMX_MT_HSH_IVW(val,0)
+#define CVMX_MT_ZUC_START(val)    asm volatile ("dmtc2 %[rt],0x4055" : : [rt] "d" (val))
+#define CVMX_MT_ZUC_MORE_NO_T     asm volatile ("dmtc2    $0,0x4056" : :)
+#define CVMX_MT_ZUC_MORE(val)     asm volatile ("dmtc2 %[rt],0x4056" : : [rt] "d" (val))
+
+// pos can be 0-7  (not normally used) pos=i has LFSR_s(2*i) in msbs,
+// LFSR_s(2*i + 1) in lsbs, <63> and <31> are unpredictable after ops
+#define CVMX_MF_ZUC_LFSR(val,pos) CVMX_MF_HSH_DATW(val,pos)
+// pos can be 0-1  (not normally used) pos=0 has F_R1 in lsbs, pos=1 has F_R2 in lsbs
+#define CVMX_MF_ZUC_FSM(val,pos)  CVMX_MF_HSH_IVW(val,(pos)+1)
+// when T can be used, it is in <31:0> and <63:32> are zero
+#define CVMX_MF_ZUC_TRESULT(val)  CVMX_MF_HSH_IVW(val,3)
+#define CVMX_MF_ZUC_RESULT(val)   CVMX_MF_HSH_IVW(val,0)
+
+// SHA3 (Keccak)
+
+// pos can be 0-24
+#define CVMX_MT_SHA3_DAT(val,pos)   {                                        \
+    if(pos <= 14)                                                           \
+        CVMX_MT_HSH_DATW(val,pos);                                           \
+    else if(pos == 15)                                                      \
+        asm volatile ("dmtc2 %[rt],0x51" : : [rt] "d" (val));               \
+    else if(pos <= 23)                                                      \
+        CVMX_MT_HSH_IVW(val,pos-16);                                         \
+    else                                                                    \
+        asm volatile ("dmtc2 %[rt],0x50" : : [rt] "d" (val));               \
+    }
+
+// pos can be 0-17 (use 0-8 for SHA3-512, 0-12 for SHA3-384, 0-16 for
+// SHA3-256, and 0-17 for SHA3-224)
+#define CVMX_MT_SHA3_XORDAT(val,pos) asm volatile ("dmtc2 %[rt],0x02C0+" CVMX_TMP_STR(pos) : : [rt] "d" (val))
+// works for all of SHA3-512, SHA3-384, SHA3-256, and SHA3-224
+#define CVMX_MT_SHA3_STARTOP         asm volatile ("dmtc2 $0,0x4052")
+
+// pos can be 0-24
+#define CVMX_MF_SHA3_DAT(val,pos)   {                                        \
+    if(pos <= 14)                                                           \
+        CVMX_MF_HSH_DATW(val,pos);                                           \
+    else if(pos == 15)                                                      \
+        asm volatile ("dmfc2 %[rt],0x24F" : [rt] "=d" (val) :);             \
+    else if(pos <= 23)                                                      \
+        CVMX_MF_HSH_IVW(val,pos-16);                                         \
+    else                                                                    \
+        asm volatile ("dmfc2 %[rt],0x50" : [rt] "=d" (val) : );             \
+    }
+
 /* check_ordering stuff */
 #if 0
 #define CVMX_MF_CHORD(dest)         asm volatile ("dmfc2 %[rt],0x400" : [rt] "=d" (dest) : )
diff --git a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
index af45ce9..11fb314 100644
--- a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
@@ -2224,7 +2224,8 @@ union cvmx_bgxx_cmrx_rx_id_map {
                                                          RID reset value = 4*(BGX_ID + 1) + LMAC_ID
                                                          Changes to RID must only occur when the LMAC is quiescent (i.e. the LMAC receive interface
                                                          is down and the RX FIFO is empty). */
-	uint64_t pknd                         : 8;  /**< Port kind for this LMAC */
+	uint64_t pknd                         : 8;  /**< Port kind for this LMAC.  Only bits [5:0] are used.  Bits [7:6] are not used and should
+                                                         not be changed from the reset value of 0. */
 #else
 	uint64_t pknd                         : 8;
 	uint64_t rid                          : 7;
@@ -2492,8 +2493,8 @@ typedef union cvmx_bgxx_cmrx_rx_stat7 cvmx_bgxx_cmrx_rx_stat7_t;
  * either due to the DMAC filter or lack of room in the receive FIFO.
  * This does not include packets which were counted in
  * BGX(0..5)_CMR(0..3)_RX_STAT2, BGX(0..5)_CMR(0..3)_RX_STAT4 nor
- * BGX(0..5)_CMR(0..3)_RX_STAT6 nor BGX(0..5)_CMR(0..3)_RX_STAT8.
- * Which statistics are updated on errors and drops are shown below:
+ * BGX(0..5)_CMR(0..3)_RX_STAT6.
+ * Which statistics are updated on control packet errors and drops are shown below:
  * if dropped [
  *   if !errored STAT8
  *   if overflow STAT6
@@ -3854,17 +3855,13 @@ union cvmx_bgxx_gmp_gmi_rxx_udd_skp {
 	uint64_t fcssel                       : 1;  /**< Include the skip bytes in the FCS calculation.
                                                          0 = all skip bytes are included in FCS
                                                          1 = the skip bytes are not included in FCS
-                                                         When BGX(0..5)_GMP_GMI_TX(0..3)_CTL[HG_EN] is set, this field must be 0.
                                                          The skip bytes are part of the packet and are sent through the IOI packet interface and
                                                          are handled by PKI. The system can determine if the UDD bytes are included in the FCS
                                                          check by using the FCSSEL field, if the FCS check is enabled. */
 	uint64_t reserved_7_7                 : 1;
 	uint64_t len                          : 7;  /**< Amount of user-defined data before the start of the L2C data, in bytes.
                                                          Setting to 0 means L2C comes first; maximum value is 64.
-                                                         LEN must be 0x0 in half-duplex operation.
-                                                         When BGX(0..5)_GMP_GMI_TX(0..3)_CTL[HG_EN] is set, this field must be set to 12 or 16
-                                                         (depending on HiGig header size) to account for the HiGig header.
-                                                         LEN = 12 selects HiGig/HiGig+; LEN = 16 selects HiGig2. */
+                                                         LEN must be 0x0 in half-duplex operation. */
 #else
 	uint64_t len                          : 7;
 	uint64_t reserved_7_7                 : 1;
diff --git a/arch/mips/include/asm/octeon/cvmx-bootmem.h b/arch/mips/include/asm/octeon/cvmx-bootmem.h
index 8f0fe36..a247ae99 100644
--- a/arch/mips/include/asm/octeon/cvmx-bootmem.h
+++ b/arch/mips/include/asm/octeon/cvmx-bootmem.h
@@ -42,7 +42,7 @@
  * Simple allocate only memory allocator.  Used to allocate memory at application
  * start time.
  *
- * <hr>$Revision: 83129 $<hr>
+ * <hr>$Revision: 94463 $<hr>
  *
  */
 
@@ -184,6 +184,19 @@ extern int cvmx_bootmem_init(uint64_t mem_desc_addr);
 extern void *cvmx_bootmem_alloc(uint64_t size, uint64_t alignment);
 
 /**
+ * Allocate a block of memory from the free list that was passed
+ * to the application by the bootloader from a specific node.
+ * This is an allocate-only algorithm, so freeing memory is not possible.
+ *
+ * @param node	The node to allocate memory from
+ * @param size  Size in bytes of block to allocate
+ * @param alignment Alignment required - must be power of 2
+ *
+ * @return pointer to block of memory, NULL on error
+ */
+extern void *cvmx_bootmem_alloc_node(uint64_t node, uint64_t size, uint64_t alignment);
+
+/**
  * Allocate a block of memory from the free list that was
  * passed to the application by the bootloader at a specific
  * address. This is an allocate-only algorithm, so
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
index 7a99cc6..d4a1e12 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
@@ -1972,29 +1972,52 @@ union cvmx_ciu_cib_l2c_rawx {
 	struct cvmx_ciu_cib_l2c_rawx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_23_63               : 41;
-	uint64_t cbcx_int_ioccmddbe           : 1;  /**< Set when L2C_CBC(0..0)_INT[IOCCMDDBE] set. */
-	uint64_t cbcx_int_ioccmdsbe           : 1;  /**< Set when L2C_CBC(0..0)_INT[IOCCMDSBE] set. */
-	uint64_t cbcx_int_rsddbe              : 1;  /**< Set when L2C_CBC(0..0)_INT[RSDDBE] set. */
-	uint64_t cbcx_int_rsdsbe              : 1;  /**< Set when L2C_CBC(0..0)_INT[RSDSBE] set. */
-	uint64_t mcix_int_vbfdbe              : 1;  /**< Set when L2C_MCI(0..0)_INT[VBFDBE] set. */
-	uint64_t mcix_int_vbfsbe              : 1;  /**< Set when L2C_MCI(0..0)_INT[VBFSBE] set. */
-	uint64_t tadx_int_rtgdbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[RTGDBE] set. */
-	uint64_t tadx_int_rtgsbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[RTGSBE] set. */
-	uint64_t tadx_int_rddislmc            : 1;  /**< Set when L2C_TAD(0..0)_INT[RDDISLMC] set. */
-	uint64_t tadx_int_wrdislmc            : 1;  /**< Set when L2C_TAD(0..0)_INT[WRDISLMC] set. */
-	uint64_t tadx_int_bigrd               : 1;  /**< Set when L2C_TAD(0..0)_INT[BIGRD] set. */
-	uint64_t tadx_int_bigwr               : 1;  /**< Set when L2C_TAD(0..0)_INT[BIGWR] set. */
-	uint64_t tadx_int_holerd              : 1;  /**< Set when L2C_TAD(0..0)_INT[HOLERD] set. */
-	uint64_t tadx_int_holewr              : 1;  /**< Set when L2C_TAD(0..0)_INT[HOLEWR] set. */
-	uint64_t tadx_int_noway               : 1;  /**< Set when L2C_TAD(0..0)_INT[NOWAY] set. */
-	uint64_t tadx_int_tagdbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[TAGDBE] set. */
-	uint64_t tadx_int_tagsbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[TAGSBE] set. */
-	uint64_t tadx_int_fbfdbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[FBFDBE] set. */
-	uint64_t tadx_int_fbfsbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[FBFSBE] set. */
-	uint64_t tadx_int_sbfdbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[SBFDBE] set. */
-	uint64_t tadx_int_sbfsbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[SBFSBE] set. */
-	uint64_t tadx_int_l2ddbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[L2DDBE] set. */
-	uint64_t tadx_int_l2dsbe              : 1;  /**< Set when L2C_TAD(0..0)_INT[L2DSBE] set. */
+	uint64_t cbcx_int_ioccmddbe           : 1;  /**< Set when L2C_CBC0_INT[IOCCMDDBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [CBCX_INT_IOCCMDDBE] before clearing L2C_CBC0_INT[IOCCMDDBE]. */
+	uint64_t cbcx_int_ioccmdsbe           : 1;  /**< Set when L2C_CBC0_INT[IOCCMDSBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [CBCX_INT_IOCCMDSBE] before clearing L2C_CBC0_INT[IOCCMDSBE]. */
+	uint64_t cbcx_int_rsddbe              : 1;  /**< Set when L2C_CBC0_INT[RSDDBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [CBCX_INT_RSDDBE] before clearing L2C_CBC0_INT[RSDDBE]. */
+	uint64_t cbcx_int_rsdsbe              : 1;  /**< Set when L2C_CBC0_INT[RSDSBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [CBCX_INT_RSDSBE] before clearing L2C_CBC0_INT[RSDSBE]. */
+	uint64_t mcix_int_vbfdbe              : 1;  /**< Set when L2C_MCI0_INT[VBFDBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [MCIX_INT_VBFDBE] before clearing L2C_MCI0_INT[VBFDBE]. */
+	uint64_t mcix_int_vbfsbe              : 1;  /**< Set when L2C_MCI0_INT[VBFSBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [MCIX_INT_VBFSBE] before clearing L2C_MCI0_INT[VBFSBE]. */
+	uint64_t tadx_int_rtgdbe              : 1;  /**< Set when L2C_TAD0_INT[RTGDBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_RTGDBE] before clearing L2C_TAD0_INT[RTGDBE]. */
+	uint64_t tadx_int_rtgsbe              : 1;  /**< Set when L2C_TAD0_INT[RTGSBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_RTGSBE] before clearing L2C_TAD0_INT[RTGSBE]. */
+	uint64_t tadx_int_rddislmc            : 1;  /**< Set when L2C_TAD0_INT[RDDISLMC] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_RDDISLMC] before clearing L2C_TAD0_INT[RDDISLMC]. */
+	uint64_t tadx_int_wrdislmc            : 1;  /**< Set when L2C_TAD0_INT[WRDISLMC] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_WRDISLMC] before clearing L2C_TAD0_INT[WRDISLMC]. */
+	uint64_t tadx_int_bigrd               : 1;  /**< Set when L2C_TAD0_INT[BIGRD] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_BIGRD] before clearing L2C_TAD0_INT[BIGRD]. */
+	uint64_t tadx_int_bigwr               : 1;  /**< Set when L2C_TAD0_INT[BIGWR] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_BIGWR] before clearing L2C_TAD0_INT[BIGWR]. */
+	uint64_t tadx_int_holerd              : 1;  /**< Set when L2C_TAD0_INT[HOLERD] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_HOLERD] before clearing L2C_TAD0_INT[HOLERD]. */
+	uint64_t tadx_int_holewr              : 1;  /**< Set when L2C_TAD0_INT[HOLEWR] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_HOLEWR] before clearing L2C_TAD0_INT[HOLEWR]. */
+	uint64_t tadx_int_noway               : 1;  /**< Set when L2C_TAD0_INT[NOWAY] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_NOWAY] before clearing L2C_TAD0_INT[NOWAY]. */
+	uint64_t tadx_int_tagdbe              : 1;  /**< Set when L2C_TAD0_INT[TAGDBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_TAGDBE] before clearing L2C_TAD0_INT[TAGDBE]. */
+	uint64_t tadx_int_tagsbe              : 1;  /**< Set when L2C_TAD0_INT[TAGSBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_TAGSBE] before clearing L2C_TAD0_INT[TAGSBE]. */
+	uint64_t tadx_int_fbfdbe              : 1;  /**< Set when L2C_TAD0_INT[FBFDBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_FBFDBE] before clearing L2C_TAD0_INT[FBFDBE]. */
+	uint64_t tadx_int_fbfsbe              : 1;  /**< Set when L2C_TAD0_INT[FBFSBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_FBFSBE] before clearing L2C_TAD0_INT[FBFSBE]. */
+	uint64_t tadx_int_sbfdbe              : 1;  /**< Set when L2C_TAD0_INT[SBFDBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_SBFDBE] before clearing L2C_TAD0_INT[SBFDBE]. */
+	uint64_t tadx_int_sbfsbe              : 1;  /**< Set when L2C_TAD0_INT[SBFSBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_SBFSBE] before clearing L2C_TAD0_INT[SBFSBE]. */
+	uint64_t tadx_int_l2ddbe              : 1;  /**< Set when L2C_TAD0_INT[L2DDBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_L2DDBE] before clearing L2C_TAD0_INT[L2DDBE]. */
+	uint64_t tadx_int_l2dsbe              : 1;  /**< Set when L2C_TAD0_INT[L2DSBE] set. Edge-sensitive interrupt, so software should clear
+                                                         [TADX_INT_L2DSBE] before clearing L2C_TAD0_INT[L2DSBE]. */
 #else
 	uint64_t tadx_int_l2dsbe              : 1;
 	uint64_t tadx_int_l2ddbe              : 1;
@@ -2062,12 +2085,18 @@ union cvmx_ciu_cib_lmcx_rawx {
 	struct cvmx_ciu_cib_lmcx_rawx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t int_ddr_err                  : 1;  /**< Set when LMC(0..0)_INT[DDR_ERR] set. */
-	uint64_t int_dlc_ded                  : 1;  /**< Set when LMC(0..0)_INT[DLCRAM_DED_ERR] set. */
-	uint64_t int_dlc_sec                  : 1;  /**< Set when LMC(0..0)_INT[DLCRAM_SEC_ERR] set. */
-	uint64_t int_ded_errx                 : 4;  /**< Set when LMC(0..0)_INT[DED_ERR<b>] set. */
-	uint64_t int_sec_errx                 : 4;  /**< Set when LMC(0..0)_INT[SEC_ERR<b>] set. */
-	uint64_t int_nxm_wr_err               : 1;  /**< Set when LMC(0..0)_INT[NXM_WR_ERR] set. */
+	uint64_t int_ddr_err                  : 1;  /**< Set when LMC0_INT[DDR_ERR] set. Edge-sensitive interrupt, so software should clear
+                                                         [INT_DDR_ERR] before clearing LMC0_INT[DDR_ERR]. */
+	uint64_t int_dlc_ded                  : 1;  /**< Set when LMC0_INT[DLCRAM_DED_ERR] set. Edge-sensitive interrupt, so software should clear
+                                                         [INT_DLC_DED] before clearing LMC0_INT[DLCRAM_DED_ERR]. */
+	uint64_t int_dlc_sec                  : 1;  /**< Set when LMC0_INT[DLCRAM_SEC_ERR] set. Edge-sensitive interrupt, so software should clear
+                                                         [INT_DLC_SEC] before clearing LMC0_INT[DLCRAM_SEC_ERR]. */
+	uint64_t int_ded_errx                 : 4;  /**< Set when LMC0_INT[DED_ERR<b>] set. Edge-sensitive interrupts, so software should clear
+                                                         [INT_DED_ERRX<b>] before clearing LMC0_INT[DED_ERR<b>]. */
+	uint64_t int_sec_errx                 : 4;  /**< Set when LMC0_INT[SEC_ERR<b>] set. Edge-sensitive interrupts, so software should clear
+                                                         [INT_SEC_ERRX<b>] before clearing LMC0_INT[SEC_ERR<b>]. */
+	uint64_t int_nxm_wr_err               : 1;  /**< Set when LMC0_INT[NXM_WR_ERR] set. Edge-sensitive interrupt, so software should clear
+                                                         [INT_NXM_WR_ERR] before clearing LMC0_INT[NXM_WR_ERR]. */
 #else
 	uint64_t int_nxm_wr_err               : 1;
 	uint64_t int_sec_errx                 : 4;
@@ -2126,16 +2155,26 @@ union cvmx_ciu_cib_oclax_rawx {
 	struct cvmx_ciu_cib_oclax_rawx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t state_ddrfull                : 1;  /**< Set when OCLA(0)_STATE_INT[DDRFULL] set. */
-	uint64_t state_wmark                  : 1;  /**< Set when OCLA(0)_STATE_INT[WMARK] set. */
-	uint64_t state_overfull               : 1;  /**< Set when OCLA(0)_STATE_INT[OVERFULL] set. */
-	uint64_t state_trigfull               : 1;  /**< Set when OCLA(0)_STATE_INT[TRIGFULL] set. */
-	uint64_t state_captured               : 1;  /**< Set when OCLA(0)_STATE_INT[CAPTURED] set. */
-	uint64_t state_fsm1_int               : 1;  /**< Set when OCLA(0)_STATE_INT[FSM1_INT] set. */
-	uint64_t state_fsm0_int               : 1;  /**< Set when OCLA(0)_STATE_INT[FSM0_INT] set. */
-	uint64_t state_mcdx                   : 3;  /**< Set when OCLA(0)_STATE_INT[MCD<b>] set. */
-	uint64_t state_trig                   : 1;  /**< Set when OCLA(0)_STATE_INT[TRIG] set. */
-	uint64_t state_ovflx                  : 4;  /**< Set when OCLA(0)_STATE_INT[OVFL<b>] set. */
+	uint64_t state_ddrfull                : 1;  /**< Set when OCLA0_STATE_INT[DDRFULL] set. Edge-sensitive interrupt, so software should clear
+                                                         [STATE_DDRFULL] before clearing OCLA0_STATE_INT[DDRFULL]. */
+	uint64_t state_wmark                  : 1;  /**< Set when OCLA0_STATE_INT[WMARK] set. Edge-sensitive interrupt, so software should clear
+                                                         [STATE_WMARK] before clearing OCLA0_STATE_INT[WMARK]. */
+	uint64_t state_overfull               : 1;  /**< Set when OCLA0_STATE_INT[OVERFULL] set. Edge-sensitive interrupt, so software should clear
+                                                         [STATE_OVERFULL] before clearing OCLA0_STATE_INT[OVERFULL]. */
+	uint64_t state_trigfull               : 1;  /**< Set when OCLA0_STATE_INT[TRIGFULL] set. Edge-sensitive interrupt, so software should clear
+                                                         [STATE_TRIGFULL] before clearing OCLA0_STATE_INT[TRIGFULL]. */
+	uint64_t state_captured               : 1;  /**< Set when OCLA0_STATE_INT[CAPTURED] set. Edge-sensitive interrupt, so software should clear
+                                                         [STATE_CAPTURED] before clearing OCLA0_STATE_INT[CAPTURED]. */
+	uint64_t state_fsm1_int               : 1;  /**< Set when OCLA0_STATE_INT[FSM1_INT] set. Edge-sensitive interrupt, so software should clear
+                                                         [STATE_FSM1_INT] before clearing OCLA0_STATE_INT[FSM1_INT]. */
+	uint64_t state_fsm0_int               : 1;  /**< Set when OCLA0_STATE_INT[FSM0_INT] set. Edge-sensitive interrupt, so software should clear
+                                                         [STATE_FSM0_INT] before clearing OCLA0_STATE_INT[FSM0_INT]. */
+	uint64_t state_mcdx                   : 3;  /**< Set when OCLA0_STATE_INT[MCD<b>] set. Edge-sensitive interrupts, so software should clear
+                                                         [STATE_MCDX<b>] before clearing OCLA0_STATE_INT[MCD<b>]. */
+	uint64_t state_trig                   : 1;  /**< Set when OCLA0_STATE_INT[TRIG] set. Edge-sensitive interrupt, so software should clear
+                                                         [STATE_TRIG] before clearing OCLA0_STATE_INT[TRIG]. */
+	uint64_t state_ovflx                  : 4;  /**< Set when OCLA0_STATE_INT[OVFL<b>] set. Edge-sensitive interrupts, so software should clear
+                                                         [STATE_OVFLX<b>] before clearing OCLA0_STATE_INT[OVFL<b>]. */
 #else
 	uint64_t state_ovflx                  : 4;
 	uint64_t state_trig                   : 1;
@@ -2182,8 +2221,10 @@ union cvmx_ciu_cib_rst_rawx {
 	struct cvmx_ciu_cib_rst_rawx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
-	uint64_t int_perstx                   : 3;  /**< Set when RST_INT[PERST<a>] set. */
-	uint64_t int_linkx                    : 3;  /**< Set when RST_INT[RST_LINK<a>] set. */
+	uint64_t int_perstx                   : 3;  /**< Set when RST_INT[PERST<a>] set. Edge-sensitive interrupts, so software should clear
+                                                         [INT_PERSTX<a>] before clearing RST_INT[PERST<a>]. */
+	uint64_t int_linkx                    : 3;  /**< Set when RST_INT[RST_LINK<a>] set. Edge-sensitive interrupts, so software should clear
+                                                         [INT_LINKX<a>] before clearing RST_INT[RST_LINK<a>]. */
 #else
 	uint64_t int_linkx                    : 3;
 	uint64_t int_perstx                   : 3;
@@ -2226,14 +2267,27 @@ union cvmx_ciu_cib_sata_rawx {
 	struct cvmx_ciu_cib_sata_rawx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t uahc_pme_req_ip              : 1;  /**< Set when SATA_UAHC_PX_IS[CPDS],
-                                                         SATA_UAHC_PX_IS[DMPS],
-                                                         SATA_UAHC_PX_IS[PCS],
-                                                         SATA_UAHC_PX_IS[SDBS], or
-                                                         SATA_UAHC_PX_SNTF[PMN] set. */
-	uint64_t uahc_intrq_ip                : 1;  /**< Set when SATA_UAHC_GBL_IS[IPS] or SATA_UAHC_PX_IS set. */
-	uint64_t intstat_xm_bad_dma           : 1;  /**< Set when SATA_UCTL_INTSTAT[XM_BAD_DMA] set. */
-	uint64_t intstat_xs_ncb_oob           : 1;  /**< Set when SATA_UCTL_INTSTAT[XS_NCB_OOB] set. */
+	uint64_t uahc_pme_req_ip              : 1;  /**< Summary for chip-internal level-sensitive interrupt that is asserted any of
+                                                         SATA_UAHC_P_IS[CPDS,DMPS,PCS] are set, and also asserts when both SATA_UAHC_P_IS[SDBS] and
+                                                         SATA_UAHC_PX_SNTF[PMN] are set.
+                                                         Hardware sets [UAHC_PME_REQ_IP] sometime after the underlying interrupt condition changes
+                                                         from de-asserting to asserting, and clears [UAHC_PME_REQ_IP] sometime after the underlying
+                                                         interrupt condition changes from asserting to de-asserting.
+                                                         R/W1C, but software need not clear [UAHC_PME_REQ_IP], and perhaps should only ever clear
+                                                         [UAHC_PME_REQ_IP]
+                                                         when the underlying interrupt condition is known to be asserted. */
+	uint64_t uahc_intrq_ip                : 1;  /**< Summary for chip-internal level-sensitive interrupt that is asserted when any bit in
+                                                         SATA_UAHC_GBL_IS[IPS] is set.
+                                                         Hardware sets [UAHC_INTRQ_IP] sometime after the underlying interrupt condition changes
+                                                         from de-asserting to asserting, and clears [UAHC_INTRQ_IP] sometime after the underlying
+                                                         interrupt condition changes from asserting to de-asserting.
+                                                         R/W1C, but software need not clear [UAHC_INTRQ_IP], and perhaps should only ever clear
+                                                         [UAHC_INTRQ_IP]
+                                                         when the underlying interrupt condition is known to be asserted. */
+	uint64_t intstat_xm_bad_dma           : 1;  /**< Set when SATA_UCTL_INTSTAT[XM_BAD_DMA] set. Edge-sensitive interrupt, so software should
+                                                         clear [INTSTAT_XM_BAD_DMA] before clearing SATA_UCTL_INTSTAT[XM_BAD_DMA]. */
+	uint64_t intstat_xs_ncb_oob           : 1;  /**< Set when SATA_UCTL_INTSTAT[XS_NCB_OOB] set. Edge-sensitive interrupt, so software should
+                                                         clear [INTSTAT_XS_NCB_OOB] before clearing SATA_UCTL_INTSTAT[XS_NCB_OOB]. */
 #else
 	uint64_t intstat_xs_ncb_oob           : 1;
 	uint64_t intstat_xm_bad_dma           : 1;
@@ -2292,17 +2346,57 @@ union cvmx_ciu_cib_usbdrdx_rawx {
 	struct cvmx_ciu_cib_usbdrdx_rawx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_11_63               : 53;
-	uint64_t uahc_dev_int                 : 1;  /**< Set when USBDRD(0..1)_UAHC_GEVNTCOUNT[EVNTCOUNT] */
-	uint64_t uahc_imanx_ip                : 1;  /**< Set when USBDRD(0..1)_UAHC_IMAN(0..0)[IP] set. */
-	uint64_t uahc_usbsts_hse              : 1;  /**< Set when USBDRD(0..1)_UAHC_USBSTS[HSE] set. */
-	uint64_t intstat_ram2_dbe             : 1;  /**< Set when USBDRD(0..1)_UCTL_INTSTAT[RAM2_DBE] set. */
-	uint64_t intstat_ram2_sbe             : 1;  /**< Set when USBDRD(0..1)_UCTL_INTSTAT[RAM2_SBE] set. */
-	uint64_t intstat_ram1_dbe             : 1;  /**< Set when USBDRD(0..1)_UCTL_INTSTAT[RAM1_DBE] set. */
-	uint64_t intstat_ram1_sbe             : 1;  /**< Set when USBDRD(0..1)_UCTL_INTSTAT[RAM1_SBE] set. */
-	uint64_t intstat_ram0_dbe             : 1;  /**< Set when USBDRD(0..1)_UCTL_INTSTAT[RAM0_DBE] set. */
-	uint64_t intstat_ram0_sbe             : 1;  /**< Set when USBDRD(0..1)_UCTL_INTSTAT[RAM0_SBE] set. */
-	uint64_t intstat_xm_bad_dma           : 1;  /**< Set when USBDRD(0..1)_UCTL_INTSTAT[XM_BAD_DMA] set. */
-	uint64_t intstat_xs_ncb_oob           : 1;  /**< Set when USBDRD(0..1)_UCTL_INTSTAT[XS_NCB_OOB] set. */
+	uint64_t uahc_dev_int                 : 1;  /**< Summary for chip-internal level-sensitive interrupt that is asserted when corresponding
+                                                         (USBDRD(0..1)_UAHC_GEVNTCOUNT[EVNTCOUNT]!=0).
+                                                         Hardware sets [UAHC_DEV_INT] sometime after corresponding
+                                                         USBDRD(0..1)_UAHC_GEVNTCOUNT[EVNTCOUNT] changes
+                                                         from zero, and clears [UAHC_DEV_INT] sometime after corresponding
+                                                         USBDRD(0..1)_UAHC_GEVNTCOUNT[EVNTCOUNT] changes to zero.
+                                                         R/W1C, but software need not clear [UAHC_DEV_INT], and perhaps should only ever clear
+                                                         [UAHC_DEV_INT]
+                                                         when corresponding USBDRD(0..1)_UAHC_GEVNTCOUNT[EVNTCOUNT] is known to be non-zero. */
+	uint64_t uahc_imanx_ip                : 1;  /**< Summary for chip-internal level-sensitive interrupt that is asserted when corresponding
+                                                         USBDRD(0..1)_UAHC_IMAN(0..0)[IP] is set.
+                                                         Hardware sets [UAHC_IMANX_IP] sometime after corresponding
+                                                         USBDRD(0..1)_UAHC_IMAN(0..0)[IP] changes
+                                                         0->1, and clears [UAHC_IMANX_IP] sometime after corresponding
+                                                         USBDRD(0..1)_UAHC_IMAN(0..0)[IP] changes 1->0.
+                                                         R/W1C, but software need not clear [UAHC_IMANX_IP], and perhaps should only ever clear
+                                                         [UAHC_IMANX_IP]
+                                                         when corresponding USBDRD(0..1)_UAHC_IMAN(0..0)[IP] is known to be set. */
+	uint64_t uahc_usbsts_hse              : 1;  /**< Summary for chip-internal level-sensitive interrupt that is asserted when corresponding
+                                                         USBDRD(0..1)_UAHC_USBSTS[HSE] is set.
+                                                         Hardware sets [UAHC_USBSTS_HSE] sometime after corresponding USBDRD(0..1)_UAHC_USBSTS[HSE]
+                                                         changes
+                                                         0->1, and clears [UAHC_USBSTS_HSE] sometime after corresponding
+                                                         USBDRD(0..1)_UAHC_USBSTS[HSE] changes 1->0.
+                                                         R/W1C, but software need not clear [UAHC_USBSTS_HSE], and perhaps should only ever clear
+                                                         [UAHC_USBSTS_HSE]
+                                                         when corresponding USBDRD(0..1)_UAHC_USBSTS[HSE] is known to be set. */
+	uint64_t intstat_ram2_dbe             : 1;  /**< Set when corresponding USBDRD(0..1)_UCTL_INTSTAT[RAM2_DBE] set. Edge-sensitive interrupt,
+                                                         so software should clear [INTSTAT_RAM2_DBE] before clearing corresponding
+                                                         USBDRD(0..1)_UCTL_INTSTAT[RAM2_DBE]. */
+	uint64_t intstat_ram2_sbe             : 1;  /**< Set when corresponding USBDRD(0..1)_UCTL_INTSTAT[RAM2_SBE] set. Edge-sensitive interrupt,
+                                                         so software should clear [INTSTAT_RAM2_SBE] before clearing corresponding
+                                                         USBDRD(0..1)_UCTL_INTSTAT[RAM2_SBE]. */
+	uint64_t intstat_ram1_dbe             : 1;  /**< Set when corresponding USBDRD(0..1)_UCTL_INTSTAT[RAM1_DBE] set. Edge-sensitive interrupt,
+                                                         so software should clear [INTSTAT_RAM1_DBE] before clearing corresponding
+                                                         USBDRD(0..1)_UCTL_INTSTAT[RAM1_DBE]. */
+	uint64_t intstat_ram1_sbe             : 1;  /**< Set when corresponding USBDRD(0..1)_UCTL_INTSTAT[RAM1_SBE] set. Edge-sensitive interrupt,
+                                                         so software should clear [INTSTAT_RAM1_SBE] before clearing corresponding
+                                                         USBDRD(0..1)_UCTL_INTSTAT[RAM1_SBE]. */
+	uint64_t intstat_ram0_dbe             : 1;  /**< Set when corresponding USBDRD(0..1)_UCTL_INTSTAT[RAM0_DBE] set. Edge-sensitive interrupt,
+                                                         so software should clear [INTSTAT_RAM0_DBE] before clearing corresponding
+                                                         USBDRD(0..1)_UCTL_INTSTAT[RAM0_DBE]. */
+	uint64_t intstat_ram0_sbe             : 1;  /**< Set when corresponding USBDRD(0..1)_UCTL_INTSTAT[RAM0_SBE] set. Edge-sensitive interrupt,
+                                                         so software should clear [INTSTAT_RAM0_SBE] before clearing corresponding
+                                                         USBDRD(0..1)_UCTL_INTSTAT[RAM0_SBE]. */
+	uint64_t intstat_xm_bad_dma           : 1;  /**< Set when corresponding USBDRD(0..1)_UCTL_INTSTAT[XM_BAD_DMA] set. Edge-sensitive
+                                                         interrupt, so software should clear [INTSTAT_XM_BAD_DMA] before clearing corresponding
+                                                         USBDRD(0..1)_UCTL_INTSTAT[XM_BAD_DMA]. */
+	uint64_t intstat_xs_ncb_oob           : 1;  /**< Set when corresponding USBDRD(0..1)_UCTL_INTSTAT[XS_NCB_OOB] set. Edge-sensitive
+                                                         interrupt, so software should clear [INTSTAT_XS_NCB_OOB] before clearing corresponding
+                                                         USBDRD(0..1)_UCTL_INTSTAT[XS_NCB_OOB]. */
 #else
 	uint64_t intstat_xs_ncb_oob           : 1;
 	uint64_t intstat_xm_bad_dma           : 1;
@@ -2428,7 +2522,7 @@ union cvmx_ciu_en2_iox_int {
 	uint64_t bch                          : 1;  /**< BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< SATA_UNTL interrupt enable */
+	uint64_t sata                         : 1;  /**< SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< EOI rsl interrupt enable */
@@ -2467,7 +2561,7 @@ union cvmx_ciu_en2_iox_int {
 	uint64_t bch                          : 1;  /**< BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< SATA_UNTL interrupt enable */
+	uint64_t sata                         : 1;  /**< SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< General timer 4-9 interrupt enable */
 	uint64_t reserved_0_3                 : 4;
@@ -2516,7 +2610,7 @@ union cvmx_ciu_en2_iox_int_w1c {
 	uint64_t bch                          : 1;  /**< Write 1 to clear BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to clear AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to clear OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to clear SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to clear SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< Write 1 to clear ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< Write 1 to clear EOI rsl interrupt enable */
@@ -2555,7 +2649,7 @@ union cvmx_ciu_en2_iox_int_w1c {
 	uint64_t bch                          : 1;  /**< Write 1 to clear BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to clear AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to clear OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to clear SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to clear SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< Write 1 to clear General timer 4-9 interrupt enable */
 	uint64_t reserved_0_3                 : 4;
@@ -2604,7 +2698,7 @@ union cvmx_ciu_en2_iox_int_w1s {
 	uint64_t bch                          : 1;  /**< Write 1 to set BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to set AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to set OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to set SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to set SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< Write 1 to set ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< Write 1 to set EOI rsl interrupt enable */
@@ -2643,7 +2737,7 @@ union cvmx_ciu_en2_iox_int_w1s {
 	uint64_t bch                          : 1;  /**< Write 1 to set BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to set AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to set OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to set SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to set SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< Write 1 to set General timer 4-9 interrupt enables */
 	uint64_t reserved_0_3                 : 4;
@@ -2693,7 +2787,7 @@ union cvmx_ciu_en2_ppx_ip2 {
 	uint64_t bch                          : 1;  /**< BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< SATA_UNTL interrupt enable */
+	uint64_t sata                         : 1;  /**< SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< EOI rsl interrupt enable */
@@ -2732,7 +2826,7 @@ union cvmx_ciu_en2_ppx_ip2 {
 	uint64_t bch                          : 1;  /**< BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< SATA_UNTL interrupt enable */
+	uint64_t sata                         : 1;  /**< SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< General timer 4-9 interrupt enable */
 	uint64_t reserved_0_3                 : 4;
@@ -2781,7 +2875,7 @@ union cvmx_ciu_en2_ppx_ip2_w1c {
 	uint64_t bch                          : 1;  /**< Write 1 to clear BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to clear AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to clear OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to clear SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to clear SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< Write 1 to clear ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< Write 1 to clear EOI rsl interrupt enable */
@@ -2820,7 +2914,7 @@ union cvmx_ciu_en2_ppx_ip2_w1c {
 	uint64_t bch                          : 1;  /**< Write 1 to clear BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to clear AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to clear OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to clear SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to clear SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< Write 1 to clear General timer 4-9 interrupt enable */
 	uint64_t reserved_0_3                 : 4;
@@ -2869,7 +2963,7 @@ union cvmx_ciu_en2_ppx_ip2_w1s {
 	uint64_t bch                          : 1;  /**< Write 1 to set BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to set AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to set OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to set SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to set SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< Write 1 to set ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< Write 1 to set EOI rsl interrupt enable */
@@ -2908,7 +3002,7 @@ union cvmx_ciu_en2_ppx_ip2_w1s {
 	uint64_t bch                          : 1;  /**< Write 1 to set BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to set AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to set OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to set SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to set SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< Write 1 to set General timer 4-9 interrupt enables */
 	uint64_t reserved_0_3                 : 4;
@@ -2958,7 +3052,7 @@ union cvmx_ciu_en2_ppx_ip3 {
 	uint64_t bch                          : 1;  /**< BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< SATA_UNTL interrupt enable */
+	uint64_t sata                         : 1;  /**< SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< EOI rsl interrupt enable */
@@ -2997,7 +3091,7 @@ union cvmx_ciu_en2_ppx_ip3 {
 	uint64_t bch                          : 1;  /**< BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< SATA_UNTL interrupt enable */
+	uint64_t sata                         : 1;  /**< SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< General timer 4-9 interrupt enable */
 	uint64_t reserved_0_3                 : 4;
@@ -3047,7 +3141,7 @@ union cvmx_ciu_en2_ppx_ip3_w1c {
 	uint64_t bch                          : 1;  /**< Write 1 to clear BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to clear AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to clear OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to clear SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to clear SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< Write 1 to clear ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< Write 1 to clear EOI rsl interrupt enable */
@@ -3086,7 +3180,7 @@ union cvmx_ciu_en2_ppx_ip3_w1c {
 	uint64_t bch                          : 1;  /**< Write 1 to clear BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to clear AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to clear OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to clear SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to clear SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< Write 1 to clear General timer 4-9 interrupt enable */
 	uint64_t reserved_0_3                 : 4;
@@ -3136,7 +3230,7 @@ union cvmx_ciu_en2_ppx_ip3_w1s {
 	uint64_t bch                          : 1;  /**< Write 1 to set BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to set AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to set OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to set SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to set SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< Write 1 to set ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< Write 1 to set EOI rsl interrupt enable */
@@ -3175,7 +3269,7 @@ union cvmx_ciu_en2_ppx_ip3_w1s {
 	uint64_t bch                          : 1;  /**< Write 1 to set BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to set AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to set OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to set SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to set SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< Write 1 to set General timer 4-9 interrupt enables */
 	uint64_t reserved_0_3                 : 4;
@@ -3225,7 +3319,7 @@ union cvmx_ciu_en2_ppx_ip4 {
 	uint64_t bch                          : 1;  /**< BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< SATA_UNTL interrupt enable */
+	uint64_t sata                         : 1;  /**< SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< EOI rsl interrupt enable */
@@ -3264,7 +3358,7 @@ union cvmx_ciu_en2_ppx_ip4 {
 	uint64_t bch                          : 1;  /**< BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< SATA_UNTL interrupt enable */
+	uint64_t sata                         : 1;  /**< SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< General timer 4-9 interrupt enable */
 	uint64_t reserved_0_3                 : 4;
@@ -3314,7 +3408,7 @@ union cvmx_ciu_en2_ppx_ip4_w1c {
 	uint64_t bch                          : 1;  /**< Write 1 to clear BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to clear AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to clear OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to clear SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to clear SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< Write 1 to clear ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< Write 1 to clear EOI rsl interrupt enable */
@@ -3353,7 +3447,7 @@ union cvmx_ciu_en2_ppx_ip4_w1c {
 	uint64_t bch                          : 1;  /**< Write 1 to clear BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to clear AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to clear OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to clear SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to clear SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< Write 1 to clear General timer 4-9 interrupt enable */
 	uint64_t reserved_0_3                 : 4;
@@ -3403,7 +3497,7 @@ union cvmx_ciu_en2_ppx_ip4_w1s {
 	uint64_t bch                          : 1;  /**< Write 1 to set BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to set AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to set OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to set SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to set SATA interrupt enable */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< Write 1 to set ENDOR PHY interrupts enable */
 	uint64_t eoi                          : 1;  /**< Write 1 to set EOI rsl interrupt enable */
@@ -3442,7 +3536,7 @@ union cvmx_ciu_en2_ppx_ip4_w1s {
 	uint64_t bch                          : 1;  /**< Write 1 to set BCH interrupt enable */
 	uint64_t agl_drp                      : 1;  /**< Write 1 to set AGL_DRP interrupt enable */
 	uint64_t ocla                         : 1;  /**< Write 1 to set OCLA interrupt enable */
-	uint64_t sata                         : 1;  /**< Write 1 to set SATA_UCTL interrupt enable */
+	uint64_t sata                         : 1;  /**< Write 1 to set SATA interrupt enable */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< Write 1 to set General timer 4-9 interrupt enables */
 	uint64_t reserved_0_3                 : 4;
@@ -11556,8 +11650,8 @@ union cvmx_ciu_int_sum1 {
                                                          See  EMMC interrupt */
 	uint64_t mii1                         : 1;  /**< RGMII/MII/MIX Interface 1 Interrupt
                                                          See MIX1_ISR */
-	uint64_t usb1                         : 1;  /**< USBDRD1 Interrupt.  (CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0])
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0] */
+	uint64_t usb1                         : 1;  /**< USBDRD1 Interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t uart2                        : 1;  /**< Third UART interrupt */
 	uint64_t wdog                         : 16; /**< Per PP watchdog interrupts */
 #else
@@ -11987,11 +12081,11 @@ union cvmx_ciu_int_sum1 {
 	} cn66xx;
 	struct cvmx_ciu_int_sum1_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t rst                          : 1;  /**< MIO RST interrupt. |(CIU_CIB_RST_RAW(0) & CIU_CIB_RST_EN(0))
-                                                         See CIU_CIB_RST_RAW(0) and CIU_CIB_RST_EN(0) */
+	uint64_t rst                          : 1;  /**< RST interrupt. Value equals ((CIU_CIB_RST_RAW & CIU_CIB_RST_EN) != 0).
+                                                         See CIU_CIB_RST_RAW and CIU_CIB_RST_EN. */
 	uint64_t reserved_53_62               : 10;
-	uint64_t lmc0                         : 1;  /**< LMC0 interrupt. |(CIU_CIB_LMC(0)_RAW[0] & CIU_CIB_LMC(0)_EN[0])
-                                                         See CIU_CIB_LMC(0)_RAW[0] and CIU_CIB_LMC(0)_EN[0] */
+	uint64_t lmc0                         : 1;  /**< LMC0 interrupt. Value equals ((CIU_CIB_LMC(0)_RAW & CIU_CIB_LMC(0)_EN) != 0).
+                                                         See CIU_CIB_LMC(0)_RAW and CIU_CIB_LMC(0)_EN. */
 	uint64_t reserved_51_51               : 1;
 	uint64_t pem2                         : 1;  /**< PEM2 interrupt
                                                          See PEM2_INT_SUM (enabled by PEM2_INT_ENB) */
@@ -12014,8 +12108,8 @@ union cvmx_ciu_int_sum1 {
                                                          See DPI_INT_REG */
 	uint64_t sli                          : 1;  /**< SLI interrupt
                                                          See SLI_INT_SUM (enabled by SLI_INT_ENB_CIU) */
-	uint64_t usb                          : 1;  /**< USBDRD0 Interrupt.  (CIU_CIB_USBDRD(0)_RAW[0] & CIU_CIB_USBDRD(0)_EN)
-                                                         See CIU_CIB_USBDRD(0)_RAW[0] and CIU_CIB_USBDRD(0)_EN[0] */
+	uint64_t usb                          : 1;  /**< USBDRD0 Interrupt.  Value equals ((CIU_CIB_USBDRD(0)_RAW & CIU_CIB_USBDRD(0)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(0)_RAW and CIU_CIB_USBDRD(0)_EN. */
 	uint64_t dfa                          : 1;  /**< DFA interrupt
                                                          See DFA_ERROR */
 	uint64_t key                          : 1;  /**< KEY interrupt
@@ -12031,8 +12125,8 @@ union cvmx_ciu_int_sum1 {
                                                          See PIP_INT_REG */
 	uint64_t ipd                          : 1;  /**< IPD interrupt
                                                          See IPD_INT_SUM */
-	uint64_t l2c                          : 1;  /**< L2C interrupt. |(CIU_CIB_L2C_RAW[0..2] & CIU_CIB_L2C_EN[0..2])
-                                                         See CIU_CIB_L2C_RAW[0..2] and CIU_CIB_L2C_EN[0..2]. */
+	uint64_t l2c                          : 1;  /**< L2C interrupt. Value equals ((CIU_CIB_L2C_RAW & CIU_CIB_L2C_EN) != 0).
+                                                         See CIU_CIB_L2C_RAW and CIU_CIB_L2C_EN. */
 	uint64_t pow                          : 1;  /**< POW err interrupt
                                                          See POW_ECC_ERR */
 	uint64_t fpa                          : 1;  /**< FPA interrupt
@@ -12044,8 +12138,8 @@ union cvmx_ciu_int_sum1 {
 	uint64_t nand                         : 1;  /**< NAND / EMMC Controller interrupt
                                                          See  NAND / EMMC interrupt */
 	uint64_t reserved_18_18               : 1;
-	uint64_t usb1                         : 1;  /**< USBDRD1 Interrupt.  (CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0])
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0] */
+	uint64_t usb1                         : 1;  /**< USBDRD1 Interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_4_16                : 13;
 	uint64_t wdog                         : 4;  /**< Watchdog interrupts. Bit 0 for PP0 watchdog, and Bit n for PPn. */
 #else
@@ -12564,7 +12658,7 @@ typedef union cvmx_ciu_pp_pokex cvmx_ciu_pp_pokex_t;
  * Resets to all 1's when REMOTE_BOOT is enabled, 0xe otherwise.  Writes to this register should
  * occur
  * only if the CIU_PP_RST_PENDING register is cleared.
- * On pass 2, RST_PP_POWER register can be statically set and writes to this register will
+ * On 70XX pass 2, RST_PP_POWER register can be statically set and writes to this register will
  * automatically enable/disable power
  * saving when RST_PP_POWER[GATE] is enabled.
  */
@@ -12684,7 +12778,8 @@ typedef union cvmx_ciu_pp_rst cvmx_ciu_pp_rst_t;
  *
  * This register contains the reset status for each core. A 1 indicated the core is waiting to
  * change it's reset state.
- * (Pass 2) Normally a reset change occurs immediately but if RST_PP_POWER[GATE] bit is set and
+ * On 70XX pass 2, normally a reset change occurs immediately but if RST_PP_POWER[GATE] bit is
+ * set and
  * the core is released from reset
  * a delay of 64K core clocks per PP will occur to satisify power management.
  */
@@ -13602,8 +13697,8 @@ union cvmx_ciu_sum1_iox_int {
                                                          See EMMC interrupt */
 	uint64_t mii1                         : 1;  /**< RGMII/MII/MIX Interface 1 Interrupt
                                                          See MIX1_ISR */
-	uint64_t usb1                         : 1;  /**< USBDRD1 interrupts. |(CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0]).
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0]. */
+	uint64_t usb1                         : 1;  /**< USBDRD1 interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_10_16               : 7;
 	uint64_t wdog                         : 10; /**< Per PP watchdog interrupts */
 #else
@@ -13861,11 +13956,11 @@ union cvmx_ciu_sum1_iox_int {
 	} cn66xx;
 	struct cvmx_ciu_sum1_iox_int_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t rst                          : 1;  /**< MIO RST interrupt
-                                                         See MIO_RST_INT */
+	uint64_t rst                          : 1;  /**< RST interrupt. Value equals ((CIU_CIB_RST_RAW & CIU_CIB_RST_EN) != 0).
+                                                         See CIU_CIB_RST_RAW and CIU_CIB_RST_EN. */
 	uint64_t reserved_53_62               : 10;
-	uint64_t lmc0                         : 1;  /**< LMC0 interrupt
-                                                         See LMC0_INT */
+	uint64_t lmc0                         : 1;  /**< LMC0 interrupt. Value equals ((CIU_CIB_LMC(0)_RAW & CIU_CIB_LMC(0)_EN) != 0).
+                                                         See CIU_CIB_LMC(0)_RAW and CIU_CIB_LMC(0)_EN. */
 	uint64_t reserved_51_51               : 1;
 	uint64_t pem2                         : 1;  /**< PEM2 interrupt
                                                          See PEM2_INT_SUM (enabled by PEM2_INT_ENB) */
@@ -13880,7 +13975,7 @@ union cvmx_ciu_sum1_iox_int {
 	uint64_t reserved_41_45               : 5;
 	uint64_t dpi_dma                      : 1;  /**< DPI DMA instruction completion interrupt.
                                                          This bit is different for each CIU_SUM1_PPx.
-                                                         TBD, See DPI DMA instruction completion */
+                                                         See DPI_DMA_PP*_CNT. */
 	uint64_t reserved_38_39               : 2;
 	uint64_t agx1                         : 1;  /**< GMX1 interrupt
                                                          See GMX1_RX*_INT_REG, GMX1_TX_INT_REG,
@@ -13892,8 +13987,8 @@ union cvmx_ciu_sum1_iox_int {
                                                          See DPI_INT_REG */
 	uint64_t sli                          : 1;  /**< SLI interrupt
                                                          See SLI_INT_SUM (enabled by SLI_INT_ENB_CIU) */
-	uint64_t usb                          : 1;  /**< USBDRD0 interrupt. (CIU_CIB_USBDRD(0)_RAW[0] & CIU_CIB_USBDRD(0)_EN(0))
-                                                         See CIU_CIB_USBDRD(0)_RAW[0] and CIU_CIB_USBDRD(0)_EN(0) */
+	uint64_t usb                          : 1;  /**< USBDRD0 interrupt.  Value equals ((CIU_CIB_USBDRD(0)_RAW & CIU_CIB_USBDRD(0)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(0)_RAW and CIU_CIB_USBDRD(0)_EN. */
 	uint64_t dfa                          : 1;  /**< DFA interrupt
                                                          See DFA_ERROR */
 	uint64_t key                          : 1;  /**< KEY interrupt
@@ -13909,8 +14004,8 @@ union cvmx_ciu_sum1_iox_int {
                                                          See PIP_INT_REG */
 	uint64_t ipd                          : 1;  /**< IPD interrupt
                                                          See IPD_INT_SUM */
-	uint64_t l2c                          : 1;  /**< L2C interrupt
-                                                         See L2C_INT_REG */
+	uint64_t l2c                          : 1;  /**< L2C interrupt. Value equals ((CIU_CIB_L2C_RAW & CIU_CIB_L2C_EN) != 0).
+                                                         See CIU_CIB_L2C_RAW and CIU_CIB_L2C_EN. */
 	uint64_t pow                          : 1;  /**< POW err interrupt
                                                          See POW_ECC_ERR */
 	uint64_t fpa                          : 1;  /**< FPA interrupt
@@ -13922,8 +14017,8 @@ union cvmx_ciu_sum1_iox_int {
 	uint64_t nand                         : 1;  /**< NAND / EMMC Controller interrupt
                                                          See NAND / EMMC interrupt */
 	uint64_t reserved_18_18               : 1;
-	uint64_t usb1                         : 1;  /**< USBDRD1 interrupts. |(CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0]).
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0]. */
+	uint64_t usb1                         : 1;  /**< USBDRD1 interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_4_16                : 13;
 	uint64_t wdog                         : 4;  /**< Watchdog interrupts, bit 0 is watchdog for PP0, ..., bit x for PPx. */
 #else
@@ -14136,8 +14231,8 @@ union cvmx_ciu_sum1_ppx_ip2 {
                                                          See EMMC interrupt */
 	uint64_t mii1                         : 1;  /**< RGMII/MII/MIX Interface 1 Interrupt
                                                          See MIX1_ISR */
-	uint64_t usb1                         : 1;  /**< USBDRD1 interrupts. |(CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0]).
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0]. */
+	uint64_t usb1                         : 1;  /**< USBDRD1 interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_10_16               : 7;
 	uint64_t wdog                         : 10; /**< Per PP watchdog interrupts */
 #else
@@ -14395,11 +14490,11 @@ union cvmx_ciu_sum1_ppx_ip2 {
 	} cn66xx;
 	struct cvmx_ciu_sum1_ppx_ip2_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t rst                          : 1;  /**< MIO RST interrupt
-                                                         See MIO_RST_INT */
+	uint64_t rst                          : 1;  /**< RST interrupt. Value equals ((CIU_CIB_RST_RAW & CIU_CIB_RST_EN) != 0).
+                                                         See CIU_CIB_RST_RAW and CIU_CIB_RST_EN. */
 	uint64_t reserved_53_62               : 10;
-	uint64_t lmc0                         : 1;  /**< LMC0 interrupt
-                                                         See LMC0_INT */
+	uint64_t lmc0                         : 1;  /**< LMC0 interrupt. Value equals ((CIU_CIB_LMC(0)_RAW & CIU_CIB_LMC(0)_EN) != 0).
+                                                         See CIU_CIB_LMC(0)_RAW and CIU_CIB_LMC(0)_EN. */
 	uint64_t reserved_51_51               : 1;
 	uint64_t pem2                         : 1;  /**< PEM2 interrupt
                                                          See PEM2_INT_SUM (enabled by PEM2_INT_ENB) */
@@ -14414,7 +14509,7 @@ union cvmx_ciu_sum1_ppx_ip2 {
 	uint64_t reserved_41_45               : 5;
 	uint64_t dpi_dma                      : 1;  /**< DPI DMA instruction completion interrupt.
                                                          This bit is different for each CIU_SUM1_PPx.
-                                                         TBD, See DPI DMA instruction completion */
+                                                         See DPI_DMA_PP*_CNT. */
 	uint64_t reserved_38_39               : 2;
 	uint64_t agx1                         : 1;  /**< GMX1 interrupt
                                                          See GMX1_RX*_INT_REG, GMX1_TX_INT_REG,
@@ -14426,8 +14521,8 @@ union cvmx_ciu_sum1_ppx_ip2 {
                                                          See DPI_INT_REG */
 	uint64_t sli                          : 1;  /**< SLI interrupt
                                                          See SLI_INT_SUM (enabled by SLI_INT_ENB_CIU) */
-	uint64_t usb                          : 1;  /**< USBDRD0 interrupt. (CIU_CIB_USBDRD(0)_RAW[0] & CIU_CIB_USBDRD(0)_EN(0))
-                                                         See CIU_CIB_USBDRD(0)_RAW[0] and CIU_CIB_USBDRD(0)_EN(0) */
+	uint64_t usb                          : 1;  /**< USBDRD0 interrupt.  Value equals ((CIU_CIB_USBDRD(0)_RAW & CIU_CIB_USBDRD(0)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(0)_RAW and CIU_CIB_USBDRD(0)_EN. */
 	uint64_t dfa                          : 1;  /**< DFA interrupt
                                                          See DFA_ERROR */
 	uint64_t key                          : 1;  /**< KEY interrupt
@@ -14443,8 +14538,8 @@ union cvmx_ciu_sum1_ppx_ip2 {
                                                          See PIP_INT_REG */
 	uint64_t ipd                          : 1;  /**< IPD interrupt
                                                          See IPD_INT_SUM */
-	uint64_t l2c                          : 1;  /**< L2C interrupt
-                                                         See L2C_INT_REG */
+	uint64_t l2c                          : 1;  /**< L2C interrupt. Value equals ((CIU_CIB_L2C_RAW & CIU_CIB_L2C_EN) != 0).
+                                                         See CIU_CIB_L2C_RAW and CIU_CIB_L2C_EN. */
 	uint64_t pow                          : 1;  /**< POW err interrupt
                                                          See POW_ECC_ERR */
 	uint64_t fpa                          : 1;  /**< FPA interrupt
@@ -14456,8 +14551,8 @@ union cvmx_ciu_sum1_ppx_ip2 {
 	uint64_t nand                         : 1;  /**< NAND / EMMC Controller interrupt
                                                          See NAND / EMMC interrupt */
 	uint64_t reserved_18_18               : 1;
-	uint64_t usb1                         : 1;  /**< USBDRD1 interrupts. |(CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0]).
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0]. */
+	uint64_t usb1                         : 1;  /**< USBDRD1 interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_4_16                : 13;
 	uint64_t wdog                         : 4;  /**< Watchdog interrupts, bit 0 is watchdog for PP0, ..., bit x for PPx. */
 #else
@@ -14671,8 +14766,8 @@ union cvmx_ciu_sum1_ppx_ip3 {
                                                          See EMMC interrupt */
 	uint64_t mii1                         : 1;  /**< RGMII/MII/MIX Interface 1 Interrupt
                                                          See MIX1_ISR */
-	uint64_t usb1                         : 1;  /**< USBDRD1 interrupts. |(CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0]).
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0]. */
+	uint64_t usb1                         : 1;  /**< USBDRD1 interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_10_16               : 7;
 	uint64_t wdog                         : 10; /**< Per PP watchdog interrupts */
 #else
@@ -14930,11 +15025,11 @@ union cvmx_ciu_sum1_ppx_ip3 {
 	} cn66xx;
 	struct cvmx_ciu_sum1_ppx_ip3_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t rst                          : 1;  /**< MIO RST interrupt
-                                                         See MIO_RST_INT */
+	uint64_t rst                          : 1;  /**< RST interrupt. Value equals ((CIU_CIB_RST_RAW & CIU_CIB_RST_EN) != 0).
+                                                         See CIU_CIB_RST_RAW and CIU_CIB_RST_EN. */
 	uint64_t reserved_53_62               : 10;
-	uint64_t lmc0                         : 1;  /**< LMC0 interrupt
-                                                         See LMC0_INT */
+	uint64_t lmc0                         : 1;  /**< LMC0 interrupt. Value equals ((CIU_CIB_LMC(0)_RAW & CIU_CIB_LMC(0)_EN) != 0).
+                                                         See CIU_CIB_LMC(0)_RAW and CIU_CIB_LMC(0)_EN. */
 	uint64_t reserved_51_51               : 1;
 	uint64_t pem2                         : 1;  /**< PEM2 interrupt
                                                          See PEM2_INT_SUM (enabled by PEM2_INT_ENB) */
@@ -14949,7 +15044,7 @@ union cvmx_ciu_sum1_ppx_ip3 {
 	uint64_t reserved_41_45               : 5;
 	uint64_t dpi_dma                      : 1;  /**< DPI DMA instruction completion interrupt.
                                                          This bit is different for each CIU_SUM1_PPx.
-                                                         TBD, See DPI DMA instruction completion */
+                                                         See DPI_DMA_PP*_CNT. */
 	uint64_t reserved_38_39               : 2;
 	uint64_t agx1                         : 1;  /**< GMX1 interrupt
                                                          See GMX1_RX*_INT_REG, GMX1_TX_INT_REG,
@@ -14961,8 +15056,8 @@ union cvmx_ciu_sum1_ppx_ip3 {
                                                          See DPI_INT_REG */
 	uint64_t sli                          : 1;  /**< SLI interrupt
                                                          See SLI_INT_SUM (enabled by SLI_INT_ENB_CIU) */
-	uint64_t usb                          : 1;  /**< USBDRD0 interrupt. (CIU_CIB_USBDRD(0)_RAW[0] & CIU_CIB_USBDRD(0)_EN(0))
-                                                         See CIU_CIB_USBDRD(0)_RAW[0] and CIU_CIB_USBDRD(0)_EN(0) */
+	uint64_t usb                          : 1;  /**< USBDRD0 interrupt.  Value equals ((CIU_CIB_USBDRD(0)_RAW & CIU_CIB_USBDRD(0)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(0)_RAW and CIU_CIB_USBDRD(0)_EN. */
 	uint64_t dfa                          : 1;  /**< DFA interrupt
                                                          See DFA_ERROR */
 	uint64_t key                          : 1;  /**< KEY interrupt
@@ -14978,8 +15073,8 @@ union cvmx_ciu_sum1_ppx_ip3 {
                                                          See PIP_INT_REG */
 	uint64_t ipd                          : 1;  /**< IPD interrupt
                                                          See IPD_INT_SUM */
-	uint64_t l2c                          : 1;  /**< L2C interrupt
-                                                         See L2C_INT_REG */
+	uint64_t l2c                          : 1;  /**< L2C interrupt. Value equals ((CIU_CIB_L2C_RAW & CIU_CIB_L2C_EN) != 0).
+                                                         See CIU_CIB_L2C_RAW and CIU_CIB_L2C_EN. */
 	uint64_t pow                          : 1;  /**< POW err interrupt
                                                          See POW_ECC_ERR */
 	uint64_t fpa                          : 1;  /**< FPA interrupt
@@ -14991,8 +15086,8 @@ union cvmx_ciu_sum1_ppx_ip3 {
 	uint64_t nand                         : 1;  /**< NAND / EMMC Controller interrupt
                                                          See NAND / EMMC interrupt */
 	uint64_t reserved_18_18               : 1;
-	uint64_t usb1                         : 1;  /**< USBDRD1 interrupts. |(CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0]).
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0]. */
+	uint64_t usb1                         : 1;  /**< USBDRD1 interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_4_16                : 13;
 	uint64_t wdog                         : 4;  /**< Watchdog interrupts, bit 0 is watchdog for PP0, ..., bit x for PPx. */
 #else
@@ -15206,8 +15301,8 @@ union cvmx_ciu_sum1_ppx_ip4 {
                                                          See EMMC interrupt */
 	uint64_t mii1                         : 1;  /**< RGMII/MII/MIX Interface 1 Interrupt
                                                          See MIX1_ISR */
-	uint64_t usb1                         : 1;  /**< USBDRD1 interrupts. |(CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0]).
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0]. */
+	uint64_t usb1                         : 1;  /**< USBDRD1 interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_10_16               : 7;
 	uint64_t wdog                         : 10; /**< Per PP watchdog interrupts */
 #else
@@ -15465,11 +15560,11 @@ union cvmx_ciu_sum1_ppx_ip4 {
 	} cn66xx;
 	struct cvmx_ciu_sum1_ppx_ip4_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t rst                          : 1;  /**< MIO RST interrupt
-                                                         See MIO_RST_INT */
+	uint64_t rst                          : 1;  /**< RST interrupt. Value equals ((CIU_CIB_RST_RAW & CIU_CIB_RST_EN) != 0).
+                                                         See CIU_CIB_RST_RAW and CIU_CIB_RST_EN. */
 	uint64_t reserved_53_62               : 10;
-	uint64_t lmc0                         : 1;  /**< LMC0 interrupt
-                                                         See LMC0_INT */
+	uint64_t lmc0                         : 1;  /**< LMC0 interrupt. Value equals ((CIU_CIB_LMC(0)_RAW & CIU_CIB_LMC(0)_EN) != 0).
+                                                         See CIU_CIB_LMC(0)_RAW and CIU_CIB_LMC(0)_EN. */
 	uint64_t reserved_51_51               : 1;
 	uint64_t pem2                         : 1;  /**< PEM2 interrupt
                                                          See PEM2_INT_SUM (enabled by PEM2_INT_ENB) */
@@ -15484,7 +15579,7 @@ union cvmx_ciu_sum1_ppx_ip4 {
 	uint64_t reserved_41_45               : 5;
 	uint64_t dpi_dma                      : 1;  /**< DPI DMA instruction completion interrupt.
                                                          This bit is different for each CIU_SUM1_PPx.
-                                                         TBD, See DPI DMA instruction completion */
+                                                         See DPI_DMA_PP*_CNT. */
 	uint64_t reserved_38_39               : 2;
 	uint64_t agx1                         : 1;  /**< GMX1 interrupt
                                                          See GMX1_RX*_INT_REG, GMX1_TX_INT_REG,
@@ -15496,8 +15591,8 @@ union cvmx_ciu_sum1_ppx_ip4 {
                                                          See DPI_INT_REG */
 	uint64_t sli                          : 1;  /**< SLI interrupt
                                                          See SLI_INT_SUM (enabled by SLI_INT_ENB_CIU) */
-	uint64_t usb                          : 1;  /**< USBDRD0 interrupt. (CIU_CIB_USBDRD(0)_RAW[0] & CIU_CIB_USBDRD(0)_EN(0))
-                                                         See CIU_CIB_USBDRD(0)_RAW[0] and CIU_CIB_USBDRD(0)_EN(0) */
+	uint64_t usb                          : 1;  /**< USBDRD0 interrupt.  Value equals ((CIU_CIB_USBDRD(0)_RAW & CIU_CIB_USBDRD(0)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(0)_RAW and CIU_CIB_USBDRD(0)_EN. */
 	uint64_t dfa                          : 1;  /**< DFA interrupt
                                                          See DFA_ERROR */
 	uint64_t key                          : 1;  /**< KEY interrupt
@@ -15513,8 +15608,8 @@ union cvmx_ciu_sum1_ppx_ip4 {
                                                          See PIP_INT_REG */
 	uint64_t ipd                          : 1;  /**< IPD interrupt
                                                          See IPD_INT_SUM */
-	uint64_t l2c                          : 1;  /**< L2C interrupt
-                                                         See L2C_INT_REG */
+	uint64_t l2c                          : 1;  /**< L2C interrupt. Value equals ((CIU_CIB_L2C_RAW & CIU_CIB_L2C_EN) != 0).
+                                                         See CIU_CIB_L2C_RAW and CIU_CIB_L2C_EN. */
 	uint64_t pow                          : 1;  /**< POW err interrupt
                                                          See POW_ECC_ERR */
 	uint64_t fpa                          : 1;  /**< FPA interrupt
@@ -15526,8 +15621,8 @@ union cvmx_ciu_sum1_ppx_ip4 {
 	uint64_t nand                         : 1;  /**< NAND / EMMC Controller interrupt
                                                          See NAND / EMMC interrupt */
 	uint64_t reserved_18_18               : 1;
-	uint64_t usb1                         : 1;  /**< USBDRD1 interrupts. |(CIU_CIB_USBDRD(1)_RAW[0] & CIU_CIB_USBDRD1(1)_EN[0]).
-                                                         See CIU_CIB_USBDRD(1)_RAW[0] and CIU_CIB_USBDRD(1)_EN[0]. */
+	uint64_t usb1                         : 1;  /**< USBDRD1 interrupt.  Value equals ((CIU_CIB_USBDRD(1)_RAW & CIU_CIB_USBDRD(1)_EN) != 0).
+                                                         See CIU_CIB_USBDRD(1)_RAW and CIU_CIB_USBDRD(1)_EN. */
 	uint64_t reserved_4_16                : 13;
 	uint64_t wdog                         : 4;  /**< Watchdog interrupts, bit 0 is watchdog for PP0, ..., bit x for PPx. */
 #else
@@ -15670,12 +15765,12 @@ union cvmx_ciu_sum2_iox_int {
 	struct cvmx_ciu_sum2_iox_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t bch                          : 1;  /**< BCH interrupt. TBD. */
-	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. TBD. */
-	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. |(CIU_CIB_OCLA(0)_RAW[0] & CIU_CIB_OCLA(0)_EN[0]).
-                                                         See  CIU_CIB_OCLA(0)_RAW[0]  and  CIU_CIB_OCLA(0)_EN[0]. */
-	uint64_t sata                         : 1;  /**< SATA interrupt summary. |(CIU_CIB_SATA(0)_RAW[0] & CIU_CIB_SATA(0)_EN(0)).
-                                                         See  CIU_CIB_SATA(0)_RAW[0]  and  CIU_CIB_SATA(0)_EN(0). */
+	uint64_t bch                          : 1;  /**< BCH interrupt. See BCH_GEN_INT. */
+	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. Set any time AGL drops a packet. */
+	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. Value equals ((CIU_CIB_OCLA(0)_RAW & CIU_CIB_OCLA(0)_EN) != 0).
+                                                         See CIU_CIB_OCLA(0)_RAW and CIU_CIB_OCLA(0)_EN. */
+	uint64_t sata                         : 1;  /**< SATA interrupt summary. Value equals ((CIU_CIB_SATA(0)_RAW & CIU_CIB_SATA(0)_EN) != 0).
+                                                         See CIU_CIB_SATA(0)_RAW and CIU_CIB_SATA(0)_EN. */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< ENDOR PHY interrupts, see ENDOR interrupt status
                                                          register ENDOR_RSTCLK_INTR0(1)_STATUS for details */
@@ -15730,12 +15825,12 @@ union cvmx_ciu_sum2_iox_int {
 	struct cvmx_ciu_sum2_iox_int_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t bch                          : 1;  /**< BCH interrupt. TBD. */
-	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. TBD. */
-	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. |(CIU_CIB_OCLA(0)_RAW[0] & CIU_CIB_OCLA(0)_EN[0]).
-                                                         See  CIU_CIB_OCLA(0)_RAW[0]  and  CIU_CIB_OCLA(0)_EN[0]. */
-	uint64_t sata                         : 1;  /**< SATA interrupt summary. |(CIU_CIB_SATA(0)_RAW[0] & CIU_CIB_SATA(0)_EN(0)).
-                                                         See  CIU_CIB_SATA(0)_RAW[0]  and  CIU_CIB_SATA(0)_EN(0). */
+	uint64_t bch                          : 1;  /**< BCH interrupt. See BCH_GEN_INT. */
+	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. Set any time AGL drops a packet. */
+	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. Value equals ((CIU_CIB_OCLA(0)_RAW & CIU_CIB_OCLA(0)_EN) != 0).
+                                                         See CIU_CIB_OCLA(0)_RAW and CIU_CIB_OCLA(0)_EN. */
+	uint64_t sata                         : 1;  /**< SATA interrupt summary. Value equals ((CIU_CIB_SATA(0)_RAW & CIU_CIB_SATA(0)_EN) != 0).
+                                                         See CIU_CIB_SATA(0)_RAW and CIU_CIB_SATA(0)_EN. */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< General timer 4-9 interrupts.
                                                          When CIU_TIM_MULTI_CAST[EN] == 0, this interrupt is
@@ -15800,12 +15895,12 @@ union cvmx_ciu_sum2_ppx_ip2 {
 	struct cvmx_ciu_sum2_ppx_ip2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t bch                          : 1;  /**< BCH interrupt. TBD. */
-	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. TBD. */
-	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. |(CIU_CIB_OCLA(0)_RAW[0] & CIU_CIB_OCLA(0)_EN[0]).
-                                                         See  CIU_CIB_OCLA(0)_RAW[0]  and  CIU_CIB_OCLA(0)_EN[0]. */
-	uint64_t sata                         : 1;  /**< SATA interrupt summary. |(CIU_CIB_SATA(0)_RAW[0] & CIU_CIB_SATA(0)_EN(0)).
-                                                         See  CIU_CIB_SATA(0)_RAW[0]  and  CIU_CIB_SATA(0)_EN(0). */
+	uint64_t bch                          : 1;  /**< BCH interrupt. See BCH_GEN_INT. */
+	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. Set any time AGL drops a packet. */
+	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. Value equals ((CIU_CIB_OCLA(0)_RAW & CIU_CIB_OCLA(0)_EN) != 0).
+                                                         See CIU_CIB_OCLA(0)_RAW and CIU_CIB_OCLA(0)_EN. */
+	uint64_t sata                         : 1;  /**< SATA interrupt summary. Value equals ((CIU_CIB_SATA(0)_RAW & CIU_CIB_SATA(0)_EN) != 0).
+                                                         See CIU_CIB_SATA(0)_RAW and CIU_CIB_SATA(0)_EN. */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< ENDOR PHY interrupts, see ENDOR interrupt status
                                                          register ENDOR_RSTCLK_INTR0(1)_STATUS for details */
@@ -15860,12 +15955,12 @@ union cvmx_ciu_sum2_ppx_ip2 {
 	struct cvmx_ciu_sum2_ppx_ip2_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t bch                          : 1;  /**< BCH interrupt. TBD. */
-	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. TBD. */
-	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. |(CIU_CIB_OCLA(0)_RAW[0] & CIU_CIB_OCLA(0)_EN[0]).
-                                                         See  CIU_CIB_OCLA(0)_RAW[0]  and  CIU_CIB_OCLA(0)_EN[0]. */
-	uint64_t sata                         : 1;  /**< SATA interrupt summary. |(CIU_CIB_SATA(0)_RAW[0] & CIU_CIB_SATA(0)_EN(0)).
-                                                         See  CIU_CIB_SATA(0)_RAW[0]  and  CIU_CIB_SATA(0)_EN(0). */
+	uint64_t bch                          : 1;  /**< BCH interrupt. See BCH_GEN_INT. */
+	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. Set any time AGL drops a packet. */
+	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. Value equals ((CIU_CIB_OCLA(0)_RAW & CIU_CIB_OCLA(0)_EN) != 0).
+                                                         See CIU_CIB_OCLA(0)_RAW and CIU_CIB_OCLA(0)_EN. */
+	uint64_t sata                         : 1;  /**< SATA interrupt summary. Value equals ((CIU_CIB_SATA(0)_RAW & CIU_CIB_SATA(0)_EN) != 0).
+                                                         See CIU_CIB_SATA(0)_RAW and CIU_CIB_SATA(0)_EN. */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< General timer 4-9 interrupts.
                                                          When CIU_TIM_MULTI_CAST[EN] == 0, this interrupt is
@@ -15931,12 +16026,12 @@ union cvmx_ciu_sum2_ppx_ip3 {
 	struct cvmx_ciu_sum2_ppx_ip3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t bch                          : 1;  /**< BCH interrupt. TBD. */
-	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. TBD. */
-	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. |(CIU_CIB_OCLA(0)_RAW[0] & CIU_CIB_OCLA(0)_EN[0]).
-                                                         See  CIU_CIB_OCLA(0)_RAW[0]  and  CIU_CIB_OCLA(0)_EN[0]. */
-	uint64_t sata                         : 1;  /**< SATA interrupt summary. |(CIU_CIB_SATA(0)_RAW[0] & CIU_CIB_SATA(0)_EN(0)).
-                                                         See  CIU_CIB_SATA(0)_RAW[0]  and  CIU_CIB_SATA(0)_EN(0). */
+	uint64_t bch                          : 1;  /**< BCH interrupt. See BCH_GEN_INT. */
+	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. Set any time AGL drops a packet. */
+	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. Value equals ((CIU_CIB_OCLA(0)_RAW & CIU_CIB_OCLA(0)_EN) != 0).
+                                                         See CIU_CIB_OCLA(0)_RAW and CIU_CIB_OCLA(0)_EN. */
+	uint64_t sata                         : 1;  /**< SATA interrupt summary. Value equals ((CIU_CIB_SATA(0)_RAW & CIU_CIB_SATA(0)_EN) != 0).
+                                                         See CIU_CIB_SATA(0)_RAW and CIU_CIB_SATA(0)_EN. */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< ENDOR PHY interrupts, see ENDOR interrupt status
                                                          register ENDOR_RSTCLK_INTR0(1)_STATUS for details */
@@ -15991,12 +16086,12 @@ union cvmx_ciu_sum2_ppx_ip3 {
 	struct cvmx_ciu_sum2_ppx_ip3_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t bch                          : 1;  /**< BCH interrupt. TBD. */
-	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. TBD. */
-	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. |(CIU_CIB_OCLA(0)_RAW[0] & CIU_CIB_OCLA(0)_EN[0]).
-                                                         See  CIU_CIB_OCLA(0)_RAW[0]  and  CIU_CIB_OCLA(0)_EN[0]. */
-	uint64_t sata                         : 1;  /**< SATA interrupt summary. |(CIU_CIB_SATA(0)_RAW[0] & CIU_CIB_SATA(0)_EN(0)).
-                                                         See  CIU_CIB_SATA(0)_RAW[0]  and  CIU_CIB_SATA(0)_EN(0). */
+	uint64_t bch                          : 1;  /**< BCH interrupt. See BCH_GEN_INT. */
+	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. Set any time AGL drops a packet. */
+	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. Value equals ((CIU_CIB_OCLA(0)_RAW & CIU_CIB_OCLA(0)_EN) != 0).
+                                                         See CIU_CIB_OCLA(0)_RAW and CIU_CIB_OCLA(0)_EN. */
+	uint64_t sata                         : 1;  /**< SATA interrupt summary. Value equals ((CIU_CIB_SATA(0)_RAW & CIU_CIB_SATA(0)_EN) != 0).
+                                                         See CIU_CIB_SATA(0)_RAW and CIU_CIB_SATA(0)_EN. */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< General timer 4-9 interrupts.
                                                          When CIU_TIM_MULTI_CAST[EN] == 0, this interrupt is
@@ -16062,12 +16157,12 @@ union cvmx_ciu_sum2_ppx_ip4 {
 	struct cvmx_ciu_sum2_ppx_ip4_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t bch                          : 1;  /**< BCH interrupt. TBD. */
-	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. TBD. */
-	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. |(CIU_CIB_OCLA(0)_RAW[0] & CIU_CIB_OCLA(0)_EN[0]).
-                                                         See  CIU_CIB_OCLA(0)_RAW[0]  and  CIU_CIB_OCLA(0)_EN[0]. */
-	uint64_t sata                         : 1;  /**< SATA interrupt summary. |(CIU_CIB_SATA(0)_RAW[0] & CIU_CIB_SATA(0)_EN(0)).
-                                                         See  CIU_CIB_SATA(0)_RAW[0]  and  CIU_CIB_SATA(0)_EN(0). */
+	uint64_t bch                          : 1;  /**< BCH interrupt. See BCH_GEN_INT. */
+	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. Set any time AGL drops a packet. */
+	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. Value equals ((CIU_CIB_OCLA(0)_RAW & CIU_CIB_OCLA(0)_EN) != 0).
+                                                         See CIU_CIB_OCLA(0)_RAW and CIU_CIB_OCLA(0)_EN. */
+	uint64_t sata                         : 1;  /**< SATA interrupt summary. Value equals ((CIU_CIB_SATA(0)_RAW & CIU_CIB_SATA(0)_EN) != 0).
+                                                         See CIU_CIB_SATA(0)_RAW and CIU_CIB_SATA(0)_EN. */
 	uint64_t reserved_15_15               : 1;
 	uint64_t endor                        : 2;  /**< ENDOR PHY interrupts, see ENDOR interrupt status
                                                          register ENDOR_RSTCLK_INTR0(1)_STATUS for details */
@@ -16122,12 +16217,12 @@ union cvmx_ciu_sum2_ppx_ip4 {
 	struct cvmx_ciu_sum2_ppx_ip4_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t bch                          : 1;  /**< BCH interrupt. TBD. */
-	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. TBD. */
-	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. |(CIU_CIB_OCLA(0)_RAW[0] & CIU_CIB_OCLA(0)_EN[0]).
-                                                         See  CIU_CIB_OCLA(0)_RAW[0]  and  CIU_CIB_OCLA(0)_EN[0]. */
-	uint64_t sata                         : 1;  /**< SATA interrupt summary. |(CIU_CIB_SATA(0)_RAW[0] & CIU_CIB_SATA(0)_EN(0)).
-                                                         See  CIU_CIB_SATA(0)_RAW[0]  and  CIU_CIB_SATA(0)_EN(0). */
+	uint64_t bch                          : 1;  /**< BCH interrupt. See BCH_GEN_INT. */
+	uint64_t agl_drp                      : 1;  /**< AGL parket drop interrupt. Set any time AGL drops a packet. */
+	uint64_t ocla                         : 1;  /**< OCLA interrupt summary. Value equals ((CIU_CIB_OCLA(0)_RAW & CIU_CIB_OCLA(0)_EN) != 0).
+                                                         See CIU_CIB_OCLA(0)_RAW and CIU_CIB_OCLA(0)_EN. */
+	uint64_t sata                         : 1;  /**< SATA interrupt summary. Value equals ((CIU_CIB_SATA(0)_RAW & CIU_CIB_SATA(0)_EN) != 0).
+                                                         See CIU_CIB_SATA(0)_RAW and CIU_CIB_SATA(0)_EN. */
 	uint64_t reserved_10_15               : 6;
 	uint64_t timer                        : 6;  /**< General timer 4-9 interrupts.
                                                          When CIU_TIM_MULTI_CAST[EN] == 0, this interrupt is
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
index e5a3b59..4b5ac3e 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
@@ -311,10 +311,10 @@ static inline uint64_t CVMX_CIU3_PP_RST_PENDING_FUNC(void)
 {
 	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
 		cvmx_warn("CVMX_CIU3_PP_RST_PENDING not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001010000000108ull);
+	return CVMX_ADD_IO_SEG(0x0001010000000110ull);
 }
 #else
-#define CVMX_CIU3_PP_RST_PENDING (CVMX_ADD_IO_SEG(0x0001010000000108ull))
+#define CVMX_CIU3_PP_RST_PENDING (CVMX_ADD_IO_SEG(0x0001010000000110ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_CIU3_SISCX(unsigned long offset)
@@ -410,10 +410,10 @@ union cvmx_ciu3_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
 	uint64_t mcd_sel                      : 2;  /**< When a MCD interrupt is requested via the IDT, which MCD number to pulse:
-                                                         0x0 = MCD0
-                                                         0x1 = MCD1
-                                                         0x2 = MCD2
-                                                         0x3 = Reserved */
+                                                         0x0 = MCD0.
+                                                         0x1 = MCD1.
+                                                         0x2 = MCD2.
+                                                         0x3 = Reserved. */
 	uint64_t iscmem_le                    : 1;  /**< CIU3_ISCMEM_BASE points to a little-endian table. */
 	uint64_t seq_dis                      : 1;  /**< Disable running sequencer only when required to reduce power, and run continuously. For
                                                          diagnostic use only. */
@@ -560,17 +560,17 @@ union cvmx_ciu3_idtx_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_52_63               : 12;
 	uint64_t intsn                        : 20; /**< Interrupt source number causing the current interrupt, or most recent interrupt if INTR is
-                                                         clear. INTERNAL: HW does not store the 20 bit INTSN here; it instead stores the sparse 12
-                                                         bit PINTSN, and maps it to INTSN on a read. */
+                                                         clear. INTERNAL: Hardware does not store the 20 bit INTSN here; it instead stores the
+                                                         sparse 12 bit PINTSN, and maps it to INTSN on a read. */
 	uint64_t reserved_4_31                : 28;
 	uint64_t intr                         : 1;  /**< Interrupt pending */
 	uint64_t newint                       : 1;  /**< New interrupt to be delivered. Internal state, for diagnostic use only. */
 	uint64_t ip_num                       : 2;  /**< Destination interrupt priority level to receive this interrupt. Only used for core
                                                          interrupts; for IO interrupts this level must be zero.
-                                                         0 = IP2, or I/O interrupt
-                                                         1 = IP3
-                                                         2 = IP4
-                                                         3 = reserved */
+                                                         0x0 = IP2, or I/O interrupt.
+                                                         0x1 = IP3.
+                                                         0x2 = IP4.
+                                                         0x3 = Reserved. */
 #else
 	uint64_t ip_num                       : 2;
 	uint64_t newint                       : 1;
@@ -616,7 +616,7 @@ union cvmx_ciu3_idtx_ppx {
 	struct cvmx_ciu3_idtx_ppx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t pp                           : 48; /**< Cores to receive interrupts via this IDT. */
+	uint64_t pp                           : 48; /**< Bitmask of which cores receive interrupts via this IDT. */
 #else
 	uint64_t pp                           : 48;
 	uint64_t reserved_48_63               : 16;
@@ -691,7 +691,7 @@ union cvmx_ciu3_intr_ready {
 	uint64_t reserved_46_63               : 18;
 	uint64_t index                        : 14; /**< Scanner index. If [READY] set, the current index, else the index the scanner stopped at.
                                                          For diagnostic use only. */
-	uint64_t sso_cnt                      : 16; /**< Number of SSO events waiting to be sent to SSO. */
+	uint64_t sso_cnt                      : 16; /**< Reserved. INTERNAL: Deprecated. Number of SSO events waiting to be sent to SSO. */
 	uint64_t reserved_1_15                : 15;
 	uint64_t ready                        : 1;  /**< CIU is idle. If clear, CIU is performing a background scan searching for secondary
                                                          interrupts. Write one to force a new scan. For diagnostic use only. */
@@ -717,13 +717,10 @@ union cvmx_ciu3_intr_slowdown {
 	uint64_t reserved_3_63                : 61;
 	uint64_t ctl                          : 3;  /**< Slow down CIU interrupt walker processing time. IRQ2/3/4 for all cores are sent to the
                                                          core (MRC) in a serial bus to reduce global routing. There is no backpressure mechanism
-                                                         designed for this scheme. It will only be a problem when SCLK is faster; this Control will
-                                                         process 1 interrupt in 4*2^CTL SCLK cycles. With different a setting, clock rate ratio can
-                                                         handle:
-                                                         SLOWDOWN sclk_freq/aclk_freq ratio
-                                                         0 4
-                                                         1 8
-                                                         n 4*2^n */
+                                                         designed for this scheme. It will only be a problem when SCLK is faster; this control will
+                                                         process 1 interrupt in 4*(2^CTL) SCLK cycles. For example:
+                                                         0x0 = sclk_freq/aclk_freq ratio is 4.
+                                                         0x1 = sclk_freq/aclk_freq ratio is 8. */
 #else
 	uint64_t ctl                          : 3;
 	uint64_t reserved_3_63                : 61;
@@ -753,12 +750,12 @@ union cvmx_ciu3_iscx_ctl {
                                                          any INTSN, and as such are not implemented.
                                                          1 = This index is implemented, and the bits are R/W.
                                                          0 = This index is not implemented, all bits will return as zero. */
-	uint64_t sso_pend                     : 1;  /**< Transaction needs to be sent to SSO. CIU internal state for diagnostic use. [SSO_PEND]
-                                                         will be cleared when the entry is transmitted to SSO, or by a software clear of [SSO],
-                                                         [RAW] or [EN]. */
+	uint64_t sso_pend                     : 1;  /**< Reserved. INTERNAL: Deprecated. Transaction needs to be sent to SSO. CIU internal state
+                                                         for diagnostic use. [SSO_PEND] will be cleared when the entry is transmitted to SSO, or by
+                                                         a software clear of [SSO], [RAW] or [EN]. */
 	uint64_t reserved_3_13                : 11;
-	uint64_t sso                          : 1;  /**< Use SSO delivery. */
-	uint64_t en                           : 1;  /**< Enable interrupt delivery. Must be set for PP_NUM and IP_NUM to have effect. */
+	uint64_t sso                          : 1;  /**< Reserved. INTERNAL: Deprecated. Use SSO delivery. */
+	uint64_t en                           : 1;  /**< Enable interrupt delivery. */
 	uint64_t raw                          : 1;  /**< Interrupt pending before masking. Note read only, must use CIU3_ISC(0..1048575)_W1C/_W1S to toggle. */
 #else
 	uint64_t raw                          : 1;
@@ -783,7 +780,7 @@ union cvmx_ciu3_iscx_w1c {
 	struct cvmx_ciu3_iscx_w1c_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t sso                          : 1;  /**< Use SSO work-queue-entry delivery. */
+	uint64_t sso                          : 1;  /**< Reserved. INTERNAL: Deprecated. Use SSO work-queue-entry delivery. */
 	uint64_t en                           : 1;  /**< Clear enable interrupt delivery. See CIU3_ISC(0..1048575)_CTL[EN]. */
 	uint64_t raw                          : 1;  /**< Clear interrupt pending. See CIU3_ISC(0..1048575)_CTL[RAW]. */
 #else
@@ -805,7 +802,7 @@ union cvmx_ciu3_iscx_w1s {
 	struct cvmx_ciu3_iscx_w1s_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t sso                          : 1;  /**< Use SSO work-queue-entry delivery. */
+	uint64_t sso                          : 1;  /**< Reserved. INTERNAL: Deprecated. Use SSO work-queue-entry delivery. */
 	uint64_t en                           : 1;  /**< Set enable interrupt delivery. See CIU3_ISC(0..1048575)_CTL[EN]. */
 	uint64_t raw                          : 1;  /**< Set interrupt pending. See CIU3_ISC(0..1048575)_CTL[RAW]. */
 #else
@@ -974,7 +971,8 @@ union cvmx_ciu3_timx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_37_63               : 27;
 	uint64_t one_shot                     : 1;  /**< One-shot mode when LEN != 0x0:
-                                                         1 = timer is in one-shot mode, 0 = timer is in periodic mode. */
+                                                         0 = timer is in periodic mode.
+                                                         1 = timer is in one-shot mode. */
 	uint64_t len                          : 36; /**< Time-out length in coprocessor clock cycles. The timer disabled when LEN = 0x0. Periodic
                                                          interrupts will occur every LEN+1 coprocessor clock cycles when ONE_SHOT = 0 */
 #else
@@ -1004,8 +1002,10 @@ union cvmx_ciu3_wdogx {
 	uint64_t state                        : 2;  /**< Watchdog state. The number of watchdog time expirations since last core poke. Cleared on
                                                          write to associated CIU3_PP_POKE(0..47) register. */
 	uint64_t mode                         : 2;  /**< Watchdog mode:
-                                                         0x0 = Off 0x2 = Interrupt + NMI
-                                                         0x1 = Interrupt only 0x3 = Interrupt + NMI + soft reset */
+                                                         0x0 = Off.
+                                                         0x1 = Interrupt only.
+                                                         0x2 = Interrupt + NMI.
+                                                         0x3 = Interrupt + NMI + soft reset. */
 #else
 	uint64_t mode                         : 2;
 	uint64_t state                        : 2;
diff --git a/arch/mips/include/asm/octeon/cvmx-coremask.h b/arch/mips/include/asm/octeon/cvmx-coremask.h
index 64cc999..578f7ae 100644
--- a/arch/mips/include/asm/octeon/cvmx-coremask.h
+++ b/arch/mips/include/asm/octeon/cvmx-coremask.h
@@ -60,7 +60,7 @@
  * provide future compatibility if more cores are added to future processors
  * or more nodes are supported.
  *
- * <hr>$Revision: 87873 $<hr>
+ * <hr>$Revision: 92640 $<hr>
  *
  */
 
@@ -375,10 +375,7 @@ static inline int cvmx_coremask_cmp(const cvmx_coremask_t *pcm1,
 	/* Start from highest node for arithemtically correct result */
 	for ( i = CVMX_COREMASK_USED_BMPSZ-1; i >= 0 ; i-- )
 		if( pcm1->coremask_bitmap[i] != pcm2->coremask_bitmap[i] )
-			return (
-				pcm1->coremask_bitmap[i] -
-				pcm2->coremask_bitmap[i] 
-				);
+			return (pcm1->coremask_bitmap[i] > pcm2->coremask_bitmap[i]) ? 1 : -1;
 
 	return 0;
 }
@@ -482,6 +479,39 @@ static inline int cvmx_coremask_lowest_bit(cvmx_coremask_holder_t h)
 	return __builtin_ctzll(h);
 }
 
+/*
+ * Returns the index of the highest bit in a coremask holder.
+ */
+static inline int cvmx_coremask_highest_bit(cvmx_coremask_holder_t h)
+{
+	return (64 - __builtin_clzll(h));
+}
+
+/**
+ * Returns the last core within the coremask and -1 when the coremask
+ * is empty.
+ *
+ * @param[in] pcm - pointer to coremask
+ * @returns last core set in the coremask or -1 if all clear
+ *
+ */
+static inline int cvmx_coremask_get_last_core(const cvmx_coremask_t *pcm)
+{
+	int i;
+	int found = -1;
+
+	for (i = 0; i < CVMX_COREMASK_USED_BMPSZ; i++) {
+		if (pcm->coremask_bitmap[i])
+			found = i;
+	}
+
+	if (found == -1)
+		return -1;
+
+	return found * CVMX_COREMASK_HLDRSZ +
+	     cvmx_coremask_highest_bit(pcm->coremask_bitmap[found]);
+}
+
 /**
  * Returns the first core within the coremask and -1 when the coremask
  * is empty.
diff --git a/arch/mips/include/asm/octeon/cvmx-dma-engine.h b/arch/mips/include/asm/octeon/cvmx-dma-engine.h
index 1143c08..079a61a 100644
--- a/arch/mips/include/asm/octeon/cvmx-dma-engine.h
+++ b/arch/mips/include/asm/octeon/cvmx-dma-engine.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -43,7 +43,7 @@
  * Interface to the PCI / PCIe DMA engines. These are only avialable
  * on chips with PCI / PCIe.
  *
- * <hr>$Revision: 79788 $<hr>
+ * <hr>$Revision: 93682 $<hr>
  */
 
 #ifndef __CVMX_DMA_ENGINES_H__
@@ -179,7 +179,141 @@ typedef union {
                                                 case.
                                                 When PTR = 0x0, the hardware performs no operation after the PCI DMA
                                                 operation is complete. */
+	} cn38xx;
+	struct {
+		uint64_t reserved_62_63:2;
+					    /**< Must be zero */
+		uint64_t lport:2;	    /**< Last port. LPort indicates the physical MAC port used for the
+                                                MAC memory space pointers in the LAST POINTERS block in the
+                                                OUTBOUND, INBOUND, and EXTERNAL-ONLY cases. Must be zero in the
+                                                INTERNAL-ONLY case. */
+		uint64_t reserved_58_59:2;
+		uint64_t fport:2;	    /**< First port. FPort indicates the physical MAC port used for the
+                                                MAC memory space pointers in the FIRST POINTERS block in the
+                                                EXTERNAL-ONLY case. Must be zero in the OUTBOUND, INBOUND and
+                                                INTERNAL-ONLY cases. Must be zero on chips with PCI */
+		uint64_t reserved_54_55:2;
+		cvmx_dma_engine_transfer_t type:2;
+					      /**< Type  A given DMA transfer is either OUTBOUND (read from L2/DRAM,
+                                                write into MAC memory space), INBOUND (read from MAC memory space, write
+                                                into L2/DRAM), INTERNAL-ONLY (read from L2/DRAM, write into L2/DRAM), or
+                                                EXTERNAL-ONLY (read from PCIe memory space, write into PCIe memory space). */
+		uint64_t csel:1;	      /**< CSEL  Counter. 1 = use counter 1, 0 = use counter 0.
+                                                The CSEL bit selects between the two counters (SLI_DMA(0..1)_CNT[CNT])
+                                                that DPI can optionally be updated after an OUTBOUND or EXTERNAL-ONLY
+                                                transfer, and also selects between the two forced-interrupt bits
+                                                (SLI_DMA(0..1)_CNT[CNT] that can optionally be set after an
+                                                OUTBOUND or EXTERNAL-ONLY transfer. C must be zero for INBOUND or
+                                                INTERNAL-ONLY transfers. */
+		uint64_t ca:1;		    /**< CA  Counter add.
+                                                When CA = 1, DPI updated the selected counter after it completed the
+                                                DMA OUTBOUND or EXTERNAL-ONLY Instruction.
+                                                    - If C = 0, DPI updated SLI_DMA0_CNT[CNT]
+                                                    - If C = 1, DPI updated SLI_DMA1_CNT[CNT]
+                                                Note that this update may indirectly cause
+                                                SLI_INT_SUM[DCNT,DTIME] to become set (depending
+                                                on the SLI_DMA(0..1)_INT_LEVEL settings), so may cause
+						interrupts to occur on a remote MAC host.
+                                                    - If DPI_DMA_CONTROL[O_ADD1] = 1, the counter is updated by 1.
+                                                    - If DPI_DMA_CONTROL[O_ADD1] = 0, the counter is updated by the total
+                                                    bytes in the transfer.
+                                                When CA = 0, DPI does not update any counters.
+                                                For an INBOUND or INTERNAL-ONLY DMA transfer, CA must never be
+                                                set, and DPI never adds to the counters. */
+		uint64_t fi:1;		    /**< FI  Force interrupt.
+                                                When FI is set for an OUTBOUND or EXTERNAL-ONLY transfer, the hardware
+                                                sets a forced interrupt bit after it completes the PCI DMA Instruction. If C = 0,
+                                                SLI_INT_SUM[DMAFI] is set, else SLI_INT_SUMn[DMA1FI] is set. For
+                                                an INBOUND or INTERNAL-ONLY DMA operation, FI must never be set,
+                                                and DPI never generates interrupts. */
+		uint64_t ii:1;		    /**< II Ignore the I bit (i.e. the I bit of the DPI DMA instruction local pointer).
+                                                For OUTBOUND transfers when II = 1, ignore the I bit and the FL bit in the
+                                                DMA HDR alone determines whether the hardware frees any/all of the local
+                                                buffers in the FIRST POINTERS area:
+                                                    - when FL = 1, the hardware frees the local buffer when II=1.
+                                                    - when FL = 0, the hardware does not free the local buffer when II=1.
+                                                For OUTBOUND transfers when II = 0, the I bit in the local pointer selects
+                                                whether local buffers are freed on a pointer-by-pointer basis:
+                                                    - when (FL  I) is true, the hardware frees the local buffer when II=0.
+                                                For INBOUND, INTERNAL-ONLY, and EXTERNAL-ONLY PCI DMA transfers,
+                                                II must never be set, and local buffers are never freed. */
+		uint64_t fl:1;		    /**< FL  Free local buffer.
+                                                When FL = 1, for an OUTBOUND operation, it indicates that the local buffers in
+                                                the FIRST BUFFERS area should be freed.
+                                                If II = 1, the FL bit alone indicates whether the local buffer should be freed:
+                                                    - when FL = 1, DPI frees the local buffer when II=1.
+                                                    - when FL = 0, DPI does not free the local buffer when II=1.
+                                                If II = 0, the I bit in the local pointer (refer to Section 9.5.2) determines whether
+                                                the local buffer is freed:
+                                                    - when (FL  I) is true, DPI frees the local buffer when II=0.
+                                                For an INBOUND, INTERNAL-ONLY, or EXTERNAL-ONLY PCI DMA transfer,
+                                                FL must never be set, and local buffers are never freed. */
+		uint64_t reserved_46:1;
+		uint64_t pt:2;		    /**< PT  Pointer Type.
+						- 0 = PTR<41:0> is byte address for ZBW with cache allocate.
+						- 1 = PTR<41:0> is byte address for ZBW with no cache allocate.
+						- 2 = PTR<41:0> is QW address for SSO PTR
+						- 3 = PTR<5:0> is CNT(0..47) to increment */
+		uint64_t dealloce:1;	    /**< DEALLOCE  Deallocation value enable. When set, use the
+						DEALLOCV to decrement the aura count on the instructions final pointer return. */
+		uint64_t reserved_48:1;	    /**< Must be zero */
+		uint64_t nlst:4;	    /**< NLST  Number Last pointers.
+                                                The number of pointers in the LAST POINTERS area.
+                                                In the INBOUND, OUTBOUND, and EXTERNAL-ONLY cases, the LAST
+                                                POINTERS area contains DPI components, and the number of 64-bit words
+                                                required in the LAST POINTERS area is:
+                                                    - HDR.NLST + ((HDR.NLST + 3)/4) where the division removes the fraction.
+                                                In the INTERNAL-ONLY case, the LAST POINTERS area contains local
+                                                pointers, and the number of 64-bit words required in the LAST POINTERS area is:
+                                                    - HDR.NLST
+                                                Note that the sum of the number of 64-bit words in the LAST POINTERS and
+                                                FIRST POINTERS area must never exceed 31. */
+		uint64_t reserved_36_37:2;
+		uint64_t nfst:4;	    /**< NFST  Number First pointers.
+                                                The number of pointers in the FIRST POINTERS area.
+                                                In the INBOUND, OUTBOUND, and INTERNAL-ONLY cases, the FIRST
+                                                POINTERS area contains local pointers, and the number of 64-bit words required
+                                                in the FIRST POINTERS area is:
+                                                    - HDR.NFST
+                                                In the EXTERNAL-ONLY case, the FIRST POINTERS area contains PCI
+                                                components, and the number of 64-bit words required in the FIRST POINTERS
+                                                area is:
+                                                    - HDR.NFST + ((HDR.NFST + 3)/4) where the division removes the fraction. */
+		uint64_t reserved_28_31:4;
+		uint64_t grp:10;	    /**< GRP  Group. */
+		uint64_t tt:2;		    /**< TT  SSO Tag Type. Sent to SSO upon instruction completion if
+						PT == DPI_HDR_PT_WQP. */
+		uint64_t reserved_12_15:4;
+		uint64_t aura:12;	    /**< AURA  Aura to free to, including FPA node number. */
+	} cn78xx;
+} cvmx_dma_engine_header_word0_t;
+
+
+typedef union {
+	uint64_t u64;
+	struct {
+		uint64_t deallocv:16;	    /**< DEALLOCV  Deallocation value to decrement the aura count
+						on the instruction's final pointer return. */
+		uint64_t reserved_42_47:6;
+		uint64_t ptr:42;	    /**< PTR  Pointer, 
+                                                When PT = 2 and PTR != 0x0, DPI inserts the work-queue entry
+                                                indicated by PTR into a SSO input queue after the DMA operation is
+                                                complete. (Section 5.4 describes the work queue entry requirements in this
+                                                case.) When WQP = 1, PTR<2:0> must be 0x0.
+                                                When PT = 0 and PTR != 0x0, DPI writes the single byte in local
+                                                memory indicated by PTR to 0x0 after the DMA operation is complete.
+                                                NPI_DMA_CONTROL[B0_LEND] selects the endian-ness of PTR in this
+                                                case.
+                                                When PT = 3 and PTR != 0x0, PTR < 48, DPI increments the
+						DPI_DMA_PPn_CNT[CNT], where the value for core n is PTR<5:0>-1.
+                                                When PTR = 0x0, DPI performs no operation after the DMA
+                                                operation is complete. */
 	} s;
+} cvmx_dma_engine_header_word1_t;
+
+typedef struct cvmx_dma_engine_header {
+	cvmx_dma_engine_header_word0_t word0;
+	cvmx_dma_engine_header_word1_t word1;
 } cvmx_dma_engine_header_t;
 
 typedef union {
@@ -239,6 +373,44 @@ typedef union {
                                                 pointer when L is clear, a little-endian byte pointer when L is set. */
 	} internal;
 	struct {
+		uint64_t i:1;		    /**< I  Invert free.
+                                                This bit gives the software the ability to free buffers independently for an
+                                                OUTBOUND DMA transfer. I is not used by DPI when II is set. I
+                                                must not be set, and buffers are never freed, for INBOUND, INTERNAL-ONLY,
+                                                and EXTERNAL-ONLY DMA transfers. */
+		uint64_t f:1;		    /**< F  Full-block writes are allowed.
+                                                When set, the hardware is permitted to write all the bytes in the cache blocks
+                                                covered by ptr, ptr + Size - 1. This can improve memory system performance
+                                                when the write misses in the L2 cache.
+                                                F can only be set for local pointers that can be written to:
+                                                    - The local pointers in the FIRST POINTERS area that are write pointers for
+                                                    INBOUND transfers.
+                                                    - The local pointers in the LAST POINTERS area that are always write
+                                                    pointers (when present for INTERNAL-ONLY transfers).
+                                                F must not be set for local pointers that are not written to:
+                                                    - The local pointers in the FIRST POINTERS area for OUTBOUND and
+                                                    INTERNAL-ONLY transfers. */
+		uint64_t ac:1;		    /**< AC  Allocate L2.
+                                                This is a hint to DPI that the cache blocks should be allocated in the L2
+                                                cache (if they were not already). */
+		uint64_t size:13;	    /**< Size  Size in bytes of the contiguous space specified by ptr. A Size value of 0 is
+                                                illegal. Note that the sum of the sizes in the FIRST POINTERS area must always
+                                                exactly equal the sum of the sizes/lengths in the LAST POINTERS area:
+                                                    - In the OUTBOUND and INBOUND cases, the HDR.NFST size fields in the
+                                                    local pointers in the FIRST POINTERS area must exactly equal the lengths
+                                                    of the HDR.NLST fragments in the PCI components in the LAST POINTERS
+                                                    area.
+                                                    - In the INTERNAL-ONLY case, the HDR.NFST size fields in the local
+                                                    pointers in the FIRST POINTERS area must equal the HDR.NLST size
+                                                    fields in the local pointers in the LAST POINTERS area. */
+		uint64_t l:1;		    /**< L  Little-endian.
+                                                When L is set, the data at ptr is in little-endian format rather than big-endian. */
+		uint64_t reserved_42_46:5;
+		uint64_t addr:42;	    /**< L2/DRAM byte pointer. Points to where the packet data starts.
+                                                Ptr can be any byte alignment. Note that ptr is interpreted as a big-endian byte
+                                                pointer when L is clear, a little-endian byte pointer when L is set. */
+	} internal_cn78xx;
+	struct {
 		uint64_t len0:16;	    /**< Length of PCI / PCIe memory for address 0 */
 		uint64_t len1:16;	    /**< Length of PCI / PCIe memory for address 1 */
 		uint64_t len2:16;	    /**< Length of PCI / PCIe memory for address 2 */
@@ -253,7 +425,7 @@ typedef union {
 typedef struct
 {
 	cvmx_fpa_pool_config_t command_queue_pool;
-}cvmx_dma_config_t;
+} cvmx_dma_config_t;
 
 extern CVMX_SHARED cvmx_dma_config_t dma_config;
 
@@ -366,8 +538,13 @@ int cvmx_dma_engine_transfer(int engine, cvmx_dma_engine_header_t header, uint64
 static inline int cvmx_dma_engine_memcpy(int engine, void *dest, void *source, int length)
 {
 	cvmx_dma_engine_header_t header;
-	header.u64 = 0;
-	header.s.type = CVMX_DMA_ENGINE_TRANSFER_INTERNAL;
+	header.word0.u64 = 0;
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		header.word1.u64 = 0;
+		header.word0.cn78xx.type = CVMX_DMA_ENGINE_TRANSFER_INTERNAL;
+		header.word0.cn78xx.aura = cvmx_fpa_get_dma_pool(); /* FIXME: get aura from resources */
+	} else
+		header.word0.cn38xx.type = CVMX_DMA_ENGINE_TRANSFER_INTERNAL;
 	return cvmx_dma_engine_transfer(engine, header, cvmx_ptr_to_phys(source), cvmx_ptr_to_phys(dest), length);
 }
 
@@ -390,16 +567,20 @@ static inline int cvmx_dma_engine_memcpy(int engine, void *dest, void *source, i
  */ static inline int cvmx_dma_engine_memcpy_zero_byte(int engine, void *dest, void *source, int length, int core)
 {
 	cvmx_dma_engine_header_t header;
-	header.u64 = 0;
-	header.s.type = CVMX_DMA_ENGINE_TRANSFER_INTERNAL;
+	header.word0.u64 = 0;
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		header.word1.u64 = 0;
+		header.word0.cn78xx.type = CVMX_DMA_ENGINE_TRANSFER_INTERNAL;
+	} else
+		header.word0.cn38xx.type = CVMX_DMA_ENGINE_TRANSFER_INTERNAL;
 	/* If dici_mode is set, DPI increments the DPI_DMA_PPn_CNT[CNT], where the
 	   value of core n is PTR<5:0>-1 when WQP=0 and PTR != 0 && PTR < 64. */
 	if (octeon_has_feature(OCTEON_FEATURE_DICI_MODE)) {
 		cvmx_dpi_dma_control_t dma_control;
 		dma_control.u64 = cvmx_read_csr(CVMX_DPI_DMA_CONTROL);
 		if (dma_control.s.dici_mode) {
-			header.s.wqp = 0;	// local memory pointer
-			header.s.addr = core + 1;
+			header.word0.cn38xx.wqp = 0;	// local memory pointer
+			header.word0.cn38xx.addr = core + 1;
 		}
 	}
 	return cvmx_dma_engine_transfer(engine, header, cvmx_ptr_to_phys(source), cvmx_ptr_to_phys(dest), length);
diff --git a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
index f6ee9f7..d75cddb 100644
--- a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
@@ -592,8 +592,8 @@ static inline uint64_t CVMX_DPI_SWA_Q_VMID_FUNC(void)
 /**
  * cvmx_dpi_bist_status
  *
- * This is the built-in self-test (BIST) status register.
- *
+ * This is the built-in self-test (BIST) status register. Each bit is the BIST result of an
+ * individual memory (per bit, 0 = pass and 1 = fail).
  */
 union cvmx_dpi_bist_status {
 	uint64_t u64;
@@ -1039,10 +1039,10 @@ union cvmx_dpi_dmax_reqq_ctl {
 	uint64_t reserved_2_7                 : 6;
 	uint64_t ld_cmd                       : 2;  /**< When DPI issues a load command to the L2C that is to be cached, this field select the type
                                                          of load command to use:
-                                                         0 = LDD.
-                                                         1 = LDI.
-                                                         2 = LDE.
-                                                         3 = LDY. */
+                                                         0x0 = LDD.
+                                                         0x1 = LDI.
+                                                         0x2 = LDE.
+                                                         0x3 = LDY. */
 #else
 	uint64_t ld_cmd                       : 2;
 	uint64_t reserved_2_7                 : 6;
@@ -1082,23 +1082,23 @@ union cvmx_dpi_dma_control {
                                                          fairness. */
 	uint64_t commit_mode                  : 1;  /**< DMA Engine Commit Mode
 
-                                                         When COMMIT_MODE=0, DPI considers an instruction
+                                                         When COMMIT_MODE=1, DPI considers an instruction
                                                          complete when the HW internally generates the
                                                          final write for the current instruction.
 
-                                                         When COMMIT_MODE=1, DPI additionally waits for
+                                                         When COMMIT_MODE=0, DPI additionally waits for
                                                          the final write to reach the interface coherency
                                                          point to declare the instructions complete.
 
-                                                         Please note: when COMMIT_MODE == 0, DPI may not
+                                                         Please note: when COMMIT_MODE == 1, DPI may not
                                                          follow the HRM ordering rules.
 
                                                          DPI hardware performance may be better with
-                                                         COMMIT_MODE == 0 than with COMMIT_MODE == 1 due
+                                                         COMMIT_MODE == 1 than with COMMIT_MODE == 0 due
                                                          to the relaxed ordering rules.
 
                                                          If the HRM ordering rules are required, set
-                                                         COMMIT_MODE == 1. */
+                                                         COMMIT_MODE == 0. */
 	uint64_t pkt_hp                       : 1;  /**< High-Priority Mode for Packet Interface.
                                                          This mode has been deprecated. */
 	uint64_t pkt_en                       : 1;  /**< Enables 1st the packet interface.
@@ -1174,23 +1174,23 @@ union cvmx_dpi_dma_control {
                                                          fairness. */
 	uint64_t commit_mode                  : 1;  /**< DMA Engine Commit Mode
 
-                                                         When COMMIT_MODE=0, DPI considers an instruction
+                                                         When COMMIT_MODE=1, DPI considers an instruction
                                                          complete when the HW internally generates the
                                                          final write for the current instruction.
 
-                                                         When COMMIT_MODE=1, DPI additionally waits for
+                                                         When COMMIT_MODE=0, DPI additionally waits for
                                                          the final write to reach the interface coherency
                                                          point to declare the instructions complete.
 
-                                                         Please note: when COMMIT_MODE == 0, DPI may not
+                                                         Please note: when COMMIT_MODE == 1, DPI may not
                                                          follow the HRM ordering rules.
 
                                                          DPI hardware performance may be better with
-                                                         COMMIT_MODE == 0 than with COMMIT_MODE == 1 due
+                                                         COMMIT_MODE == 1 than with COMMIT_MODE == 0 due
                                                          to the relaxed ordering rules.
 
                                                          If the HRM ordering rules are required, set
-                                                         COMMIT_MODE == 1. */
+                                                         COMMIT_MODE == 0. */
 	uint64_t pkt_hp                       : 1;  /**< High-Priority Mode for Packet Interface.
                                                          This mode has been deprecated. */
 	uint64_t pkt_en                       : 1;  /**< Enables 1st the packet interface.
@@ -1356,23 +1356,23 @@ union cvmx_dpi_dma_control {
 	uint64_t reserved_59_63               : 5;
 	uint64_t commit_mode                  : 1;  /**< DMA Engine Commit Mode
 
-                                                         When COMMIT_MODE=0, DPI considers an instruction
+                                                         When COMMIT_MODE=1, DPI considers an instruction
                                                          complete when the HW internally generates the
                                                          final write for the current instruction.
 
-                                                         When COMMIT_MODE=1, DPI additionally waits for
+                                                         When COMMIT_MODE=0, DPI additionally waits for
                                                          the final write to reach the interface coherency
                                                          point to declare the instructions complete.
 
-                                                         Please note: when COMMIT_MODE == 0, DPI may not
+                                                         Please note: when COMMIT_MODE == 1, DPI may not
                                                          follow the HRM ordering rules.
 
                                                          DPI hardware performance may be better with
-                                                         COMMIT_MODE == 0 than with COMMIT_MODE == 1 due
+                                                         COMMIT_MODE == 1 than with COMMIT_MODE == 0 due
                                                          to the relaxed ordering rules.
 
                                                          If the HRM ordering rules are required, set
-                                                         COMMIT_MODE == 1. */
+                                                         COMMIT_MODE == 0. */
 	uint64_t pkt_hp                       : 1;  /**< High-Priority Mode for Packet Interface.
                                                          Engine 5 will be serviced more frequently to
                                                          deliver more bandwidth to packet interface.
@@ -1445,13 +1445,13 @@ union cvmx_dpi_dma_control {
                                                          hardware detects that particular engines are not able to make requests to an interface,
                                                          the hardware will periodically trade-off throughput for fairness. */
 	uint64_t commit_mode                  : 1;  /**< DMA engine commit mode.
-                                                         When COMMIT_MODE=0, DPI considers an instruction complete when the hardware internally
+                                                         When COMMIT_MODE=1, DPI considers an instruction complete when the hardware internally
                                                          generates the final write for the current instruction.
-                                                         When COMMIT_MODE=1, DPI additionally waits for the final write to reach the interface
+                                                         When COMMIT_MODE=0, DPI additionally waits for the final write to reach the interface
                                                          coherency point to declare the instructions complete.
-                                                         Please note: when COMMIT_MODE == 0, DPI may not follow the HRM ordering rules. DPI
-                                                         hardware performance may be better with COMMIT_MODE == 0 than with COMMIT_MODE == 1 due to
-                                                         the relaxed ordering rules. If the HRM ordering rules are required, set COMMIT_MODE == 1. */
+                                                         Please note: when COMMIT_MODE == 1, DPI may not follow the HRM ordering rules. DPI
+                                                         hardware performance may be better with COMMIT_MODE == 1 than with COMMIT_MODE == 0 due to
+                                                         the relaxed ordering rules. If the HRM ordering rules are required, set COMMIT_MODE == 0. */
 	uint64_t reserved_57_57               : 1;
 	uint64_t pkt_en                       : 1;  /**< Enables the packet interface. When the packet interface is enabled, engines 4 and 5 are
                                                          used for packets and are not available for DMA. When PKT_EN=1, then DMA_ENB<5>=0 and
@@ -1463,13 +1463,12 @@ union cvmx_dpi_dma_control {
 	uint64_t reserved_34_47               : 14;
 	uint64_t b0_lend                      : 1;  /**< Little-endian. When set to 1 and the DPI is in the mode to write 0 to L2C when a DMA
                                                          transaction is done, the address to be written is treated as a little-endian address. */
-	uint64_t ldwb                         : 1;  /**< Load Dont Write Back
-                                                         When set, the HW will be able to issue LDWB commands to the cache.  As
-                                                         a result the line will not be written back when replaced.  When clear,
-                                                         the HW will issue regular load commands to the cache which will cause
-                                                         the line to be written back before being replaced. */
-	uint64_t aura_ichk                    : 12; /**< The AURA that the Instruction Chunk for DMA operations page will be
-                                                         returned to when freed. */
+	uint64_t ldwb                         : 1;  /**< Load don't write back. When set, the hardware is able to issue LDWB commands to the cache.
+                                                         As a result, the line will not be written back when replaced. When clear, the hardware
+                                                         issues regular load commands to the cache which cause the line to be written back before
+                                                         being replaced. */
+	uint64_t aura_ichk                    : 12; /**< AURA instruction chunk. The AURA that the instruction chunk for DMA operations page will
+                                                         be returned to when freed. */
 	uint64_t o_add1                       : 1;  /**< Add one.
                                                          1 = add 1 to the SLI SLI_DMA*_CNT DMA counters
                                                          0 = the number of bytes in the DMA transfer is added to SLI_DMA*_CNT. */
@@ -1586,7 +1585,7 @@ union cvmx_dpi_dma_pp_int {
 	struct cvmx_dpi_dma_pp_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t complete                     : 48; /**< DPI DMA per-core instruction completion interrupt.  See DPI_DMA_PP(0..47)_CNT. */
+	uint64_t complete                     : 48; /**< DPI DMA per-core instruction completion interrupt. See DPI_DMA_PP(0..47)_CNT. */
 #else
 	uint64_t complete                     : 48;
 	uint64_t reserved_48_63               : 16;
@@ -1609,10 +1608,10 @@ union cvmx_dpi_ecc_ctl {
 	uint64_t reserved_33_63               : 31;
 	uint64_t ram_cdis                     : 1;  /**< RDB RAM ECC correction disable. Each bit corresponds to a different RAM. */
 	uint64_t reserved_17_31               : 15;
-	uint64_t ram_flip1                    : 1;  /**< Flip syndrome bits on write. Flip syndrome bits <1> on writes to the corresponding RDB ram
+	uint64_t ram_flip1                    : 1;  /**< Flip syndrome bits on write. Flip syndrome bits <1> on writes to the corresponding RDB RAM
                                                          to test single-bit or double-bit error handling. */
 	uint64_t reserved_1_15                : 15;
-	uint64_t ram_flip0                    : 1;  /**< Flip syndrome bits on write. Flip syndrome bits <0> on writes to the corresponding RDB ram
+	uint64_t ram_flip0                    : 1;  /**< Flip syndrome bits on write. Flip syndrome bits <0> on writes to the corresponding RDB RAM
                                                          to test single-bit or double-bit error handling. */
 #else
 	uint64_t ram_flip0                    : 1;
@@ -1638,10 +1637,10 @@ union cvmx_dpi_ecc_int {
 	struct cvmx_dpi_ecc_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_47_63               : 17;
-	uint64_t ram_sbe                      : 15; /**< Set when a single-bit error is detected in the corresponding ram. Throws
+	uint64_t ram_sbe                      : 15; /**< Set when a single-bit error is detected in the corresponding RAM. Throws
                                                          DPI_INTSN_E::DPI_ERR_RAM_SBE. */
 	uint64_t reserved_15_31               : 17;
-	uint64_t ram_dbe                      : 15; /**< Set when a double-bit error is detected in the corresponding ram. Throws
+	uint64_t ram_dbe                      : 15; /**< Set when a double-bit error is detected in the corresponding RAM. Throws
                                                          DPI_INTSN_E::DPI_ERR_RAM_DBE. */
 #else
 	uint64_t ram_dbe                      : 15;
@@ -2050,6 +2049,9 @@ typedef union cvmx_dpi_ncbx_cfg cvmx_dpi_ncbx_cfg_t;
 
 /**
  * cvmx_dpi_ncb_ctl
+ *
+ * This register provides NCB unit control.
+ *
  */
 union cvmx_dpi_ncb_ctl {
 	uint64_t u64;
@@ -2537,7 +2539,7 @@ union cvmx_dpi_sli_prtx_cfg {
                                                          4B granularity.  In this mode, the HW may break
                                                          a given read into 3 operations to satisify
                                                          PCIe rules.
-                                                         If the port is a SRIO port, the HW follows the
+                                                         INTERNAL: If the port is a SRIO port, the HW follows the
                                                          SRIO read rules from the SRIO specification and
                                                          only issues 32*n, 16, and 8 byte  operations
                                                          on the SRIO bus.
@@ -2576,7 +2578,7 @@ union cvmx_dpi_sli_prtx_cfg {
                                                          1 = 256B
                                                          For PCIe MACs, this MPS size must not exceed
                                                          the size selected by PCIE*_CFG030[MPS].
-                                                         For sRIO MACs, all MPS values are allowed. */
+                                                         INTERNAL: For sRIO MACs, all MPS values are allowed. */
 	uint64_t mrrs_lim                     : 1;  /**< MAC memory space read requests cannot cross the
                                                          (naturally-aligned) MRRS boundary.
                                                          When clear, DPI is allowed to issue a MAC memory
@@ -2595,7 +2597,7 @@ union cvmx_dpi_sli_prtx_cfg {
                                                          3 = 1024B
                                                          For PCIe MACs, this MRRS size must not exceed
                                                          the size selected by PCIE*_CFG030[MRRS].
-                                                         For sRIO MACs, this MRRS size must be <= 256B. */
+                                                         INTERNAL: For sRIO MACs, this MRRS size must be <= 256B. */
 #else
 	uint64_t mrrs                         : 2;
 	uint64_t reserved_2_2                 : 1;
@@ -2744,22 +2746,19 @@ typedef union cvmx_dpi_sli_prtx_err_info cvmx_dpi_sli_prtx_err_info_t;
 
 /**
  * cvmx_dpi_swa_q_vmid
- *
- * This register defines.
- *
  */
 union cvmx_dpi_swa_q_vmid {
 	uint64_t u64;
 	struct cvmx_dpi_swa_q_vmid_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t vmid7                        : 8;  /**< The SWA VMID for Queue 7. */
-	uint64_t vmid6                        : 8;  /**< The SWA VMID for Queue 6. */
-	uint64_t vmid5                        : 8;  /**< The SWA VMID for Queue 5. */
-	uint64_t vmid4                        : 8;  /**< The SWA VMID for Queue 4. */
-	uint64_t vmid3                        : 8;  /**< The SWA VMID for Queue 3. */
-	uint64_t vmid2                        : 8;  /**< The SWA VMID for Queue 2. */
-	uint64_t vmid1                        : 8;  /**< The SWA VMID for Queue 1. */
-	uint64_t vmid0                        : 8;  /**< The SWA VMID for Queue 0. */
+	uint64_t vmid7                        : 8;  /**< The SWA VMID for queue 7. */
+	uint64_t vmid6                        : 8;  /**< The SWA VMID for queue 6. */
+	uint64_t vmid5                        : 8;  /**< The SWA VMID for queue 5. */
+	uint64_t vmid4                        : 8;  /**< The SWA VMID for queue 4. */
+	uint64_t vmid3                        : 8;  /**< The SWA VMID for queue 3. */
+	uint64_t vmid2                        : 8;  /**< The SWA VMID for queue 2. */
+	uint64_t vmid1                        : 8;  /**< The SWA VMID for queue 1. */
+	uint64_t vmid0                        : 8;  /**< The SWA VMID for queue 0. */
 #else
 	uint64_t vmid0                        : 8;
 	uint64_t vmid1                        : 8;
diff --git a/arch/mips/include/asm/octeon/cvmx-fau.h b/arch/mips/include/asm/octeon/cvmx-fau.h
index ccaae1d..0613c9c 100644
--- a/arch/mips/include/asm/octeon/cvmx-fau.h
+++ b/arch/mips/include/asm/octeon/cvmx-fau.h
@@ -42,7 +42,6 @@
  *
  * Interface to the hardware Fetch and Add Unit.
  *
- * <hr>$Revision: 78319 $<hr>
  */
 
 #ifndef __CVMX_FAU_H__
@@ -53,6 +52,7 @@ typedef int cvmx_fau_reg32_t;
 typedef int cvmx_fau_reg16_t;
 typedef int cvmx_fau_reg8_t;
 
+#define CVMX_FAU_REG_ANY 	-1
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
@@ -157,9 +157,11 @@ typedef union {
  *               - Step by 8 for 64 bit access.
  * @return Address to store for atomic update
  */
-static inline uint64_t __cvmx_fau_store_address(uint64_t noadd, uint64_t reg)
+static inline uint64_t __cvmx_hwfau_store_address(uint64_t noadd, uint64_t reg)
 {
-	return (CVMX_ADD_IO_SEG(CVMX_FAU_LOAD_IO_ADDRESS) | cvmx_build_bits(CVMX_FAU_BITS_NOADD, noadd) | cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
+	return (CVMX_ADD_IO_SEG(CVMX_FAU_LOAD_IO_ADDRESS) |
+		cvmx_build_bits(CVMX_FAU_BITS_NOADD, noadd) |
+		cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
 }
 
 /**
@@ -178,10 +180,12 @@ static inline uint64_t __cvmx_fau_store_address(uint64_t noadd, uint64_t reg)
  *                Note: When performing 32 and 64 bit access, only the low
  *                22 bits are available.
  * @return Address to read from for atomic update
- */ static inline uint64_t __cvmx_fau_atomic_address(uint64_t tagwait, uint64_t reg, int64_t value)
+ */ static inline uint64_t __cvmx_hwfau_atomic_address(uint64_t tagwait, uint64_t reg, int64_t value)
 {
 	return (CVMX_ADD_IO_SEG(CVMX_FAU_LOAD_IO_ADDRESS) |
-		cvmx_build_bits(CVMX_FAU_BITS_INEVAL, value) | cvmx_build_bits(CVMX_FAU_BITS_TAGWAIT, tagwait) | cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
+		cvmx_build_bits(CVMX_FAU_BITS_INEVAL, value) |
+		cvmx_build_bits(CVMX_FAU_BITS_TAGWAIT, tagwait) |
+		cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
 }
 
 /**
@@ -193,9 +197,9 @@ static inline uint64_t __cvmx_fau_store_address(uint64_t noadd, uint64_t reg)
  *                Note: Only the low 22 bits are available.
  * @return Value of the register before the update
  */
-static inline int64_t cvmx_fau_fetch_and_add64(cvmx_fau_reg64_t reg, int64_t value)
+static inline int64_t cvmx_hwfau_fetch_and_add64(cvmx_fau_reg64_t reg, int64_t value)
 {
-	return cvmx_read64_int64(__cvmx_fau_atomic_address(0, reg, value));
+	return cvmx_read64_int64(__cvmx_hwfau_atomic_address(0, reg, value));
 }
 
 /**
@@ -207,10 +211,10 @@ static inline int64_t cvmx_fau_fetch_and_add64(cvmx_fau_reg64_t reg, int64_t val
  *                Note: Only the low 22 bits are available.
  * @return Value of the register before the update
  */
-static inline int32_t cvmx_fau_fetch_and_add32(cvmx_fau_reg32_t reg, int32_t value)
+static inline int32_t cvmx_hwfau_fetch_and_add32(cvmx_fau_reg32_t reg, int32_t value)
 {
 	reg ^= SWIZZLE_32;
-	return cvmx_read64_int32(__cvmx_fau_atomic_address(0, reg, value));
+	return cvmx_read64_int32(__cvmx_hwfau_atomic_address(0, reg, value));
 }
 
 /**
@@ -221,10 +225,10 @@ static inline int32_t cvmx_fau_fetch_and_add32(cvmx_fau_reg32_t reg, int32_t val
  * @param value   Signed value to add.
  * @return Value of the register before the update
  */
-static inline int16_t cvmx_fau_fetch_and_add16(cvmx_fau_reg16_t reg, int16_t value)
+static inline int16_t cvmx_hwfau_fetch_and_add16(cvmx_fau_reg16_t reg, int16_t value)
 {
 	reg ^= SWIZZLE_16;
-	return cvmx_read64_int16(__cvmx_fau_atomic_address(0, reg, value));
+	return cvmx_read64_int16(__cvmx_hwfau_atomic_address(0, reg, value));
 }
 
 /**
@@ -234,10 +238,10 @@ static inline int16_t cvmx_fau_fetch_and_add16(cvmx_fau_reg16_t reg, int16_t val
  * @param value   Signed value to add.
  * @return Value of the register before the update
  */
-static inline int8_t cvmx_fau_fetch_and_add8(cvmx_fau_reg8_t reg, int8_t value)
+static inline int8_t cvmx_hwfau_fetch_and_add8(cvmx_fau_reg8_t reg, int8_t value)
 {
 	reg ^= SWIZZLE_8;
-	return cvmx_read64_int8(__cvmx_fau_atomic_address(0, reg, value));
+	return cvmx_read64_int8(__cvmx_hwfau_atomic_address(0, reg, value));
 }
 
 /**
@@ -252,13 +256,14 @@ static inline int8_t cvmx_fau_fetch_and_add8(cvmx_fau_reg8_t reg, int8_t value)
  *         the value of the register before the update will be
  *         returned
  */
-static inline cvmx_fau_tagwait64_t cvmx_fau_tagwait_fetch_and_add64(cvmx_fau_reg64_t reg, int64_t value)
+static inline cvmx_fau_tagwait64_t cvmx_hwfau_tagwait_fetch_and_add64(cvmx_fau_reg64_t reg, int64_t value)
 {
 	union {
 		uint64_t i64;
 		cvmx_fau_tagwait64_t t;
 	} result;
-	result.i64 = cvmx_read64_int64(__cvmx_fau_atomic_address(1, reg, value));
+	result.i64 = cvmx_read64_int64(__cvmx_hwfau_atomic_address(1, reg, value));
+		
 	return result.t;
 }
 
@@ -274,14 +279,14 @@ static inline cvmx_fau_tagwait64_t cvmx_fau_tagwait_fetch_and_add64(cvmx_fau_reg
  *         the value of the register before the update will be
  *         returned
  */
-static inline cvmx_fau_tagwait32_t cvmx_fau_tagwait_fetch_and_add32(cvmx_fau_reg32_t reg, int32_t value)
+static inline cvmx_fau_tagwait32_t cvmx_hwfau_tagwait_fetch_and_add32(cvmx_fau_reg32_t reg, int32_t value)
 {
 	union {
 		uint64_t i32;
 		cvmx_fau_tagwait32_t t;
 	} result;
 	reg ^= SWIZZLE_32;
-	result.i32 = cvmx_read64_int32(__cvmx_fau_atomic_address(1, reg, value));
+	result.i32 = cvmx_read64_int32(__cvmx_hwfau_atomic_address(1, reg, value));
 	return result.t;
 }
 
@@ -296,14 +301,14 @@ static inline cvmx_fau_tagwait32_t cvmx_fau_tagwait_fetch_and_add32(cvmx_fau_reg
  *         the value of the register before the update will be
  *         returned
  */
-static inline cvmx_fau_tagwait16_t cvmx_fau_tagwait_fetch_and_add16(cvmx_fau_reg16_t reg, int16_t value)
+static inline cvmx_fau_tagwait16_t cvmx_hwfau_tagwait_fetch_and_add16(cvmx_fau_reg16_t reg, int16_t value)
 {
 	union {
 		uint64_t i16;
 		cvmx_fau_tagwait16_t t;
 	} result;
 	reg ^= SWIZZLE_16;
-	result.i16 = cvmx_read64_int16(__cvmx_fau_atomic_address(1, reg, value));
+	result.i16 = cvmx_read64_int16(__cvmx_hwfau_atomic_address(1, reg, value));
 	return result.t;
 }
 
@@ -317,14 +322,14 @@ static inline cvmx_fau_tagwait16_t cvmx_fau_tagwait_fetch_and_add16(cvmx_fau_reg
  *         the value of the register before the update will be
  *         returned
  */
-static inline cvmx_fau_tagwait8_t cvmx_fau_tagwait_fetch_and_add8(cvmx_fau_reg8_t reg, int8_t value)
+static inline cvmx_fau_tagwait8_t cvmx_hwfau_tagwait_fetch_and_add8(cvmx_fau_reg8_t reg, int8_t value)
 {
 	union {
 		uint64_t i8;
 		cvmx_fau_tagwait8_t t;
 	} result;
 	reg ^= SWIZZLE_8;
-	result.i8 = cvmx_read64_int8(__cvmx_fau_atomic_address(1, reg, value));
+	result.i8 = cvmx_read64_int8(__cvmx_hwfau_atomic_address(1, reg, value));
 	return result.t;
 }
 
@@ -357,7 +362,9 @@ static inline uint64_t __cvmx_fau_iobdma_data(uint64_t scraddr, int64_t value, u
 		cvmx_build_bits(CVMX_FAU_BITS_SCRADDR, scraddr >> 3) |
 		cvmx_build_bits(CVMX_FAU_BITS_LEN, 1) |
 		cvmx_build_bits(CVMX_FAU_BITS_INEVAL, value) |
-		cvmx_build_bits(CVMX_FAU_BITS_TAGWAIT, tagwait) | cvmx_build_bits(CVMX_FAU_BITS_SIZE, size) | cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
+		cvmx_build_bits(CVMX_FAU_BITS_TAGWAIT, tagwait) |
+		cvmx_build_bits(CVMX_FAU_BITS_SIZE, size) |
+		cvmx_build_bits(CVMX_FAU_BITS_REGISTER, reg));
 }
 
 /**
@@ -372,7 +379,7 @@ static inline uint64_t __cvmx_fau_iobdma_data(uint64_t scraddr, int64_t value, u
  *                Note: Only the low 22 bits are available.
  * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_fetch_and_add64(uint64_t scraddr, cvmx_fau_reg64_t reg, int64_t value)
+static inline void cvmx_hwfau_async_fetch_and_add64(uint64_t scraddr, cvmx_fau_reg64_t reg, int64_t value)
 {
 	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 0, CVMX_FAU_OP_SIZE_64, reg));
 }
@@ -389,7 +396,7 @@ static inline void cvmx_fau_async_fetch_and_add64(uint64_t scraddr, cvmx_fau_reg
  *                Note: Only the low 22 bits are available.
  * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_fetch_and_add32(uint64_t scraddr, cvmx_fau_reg32_t reg, int32_t value)
+static inline void cvmx_hwfau_async_fetch_and_add32(uint64_t scraddr, cvmx_fau_reg32_t reg, int32_t value)
 {
 	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 0, CVMX_FAU_OP_SIZE_32, reg));
 }
@@ -405,7 +412,7 @@ static inline void cvmx_fau_async_fetch_and_add32(uint64_t scraddr, cvmx_fau_reg
  * @param value   Signed value to add.
  * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_fetch_and_add16(uint64_t scraddr, cvmx_fau_reg16_t reg, int16_t value)
+static inline void cvmx_hwfau_async_fetch_and_add16(uint64_t scraddr, cvmx_fau_reg16_t reg, int16_t value)
 {
 	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 0, CVMX_FAU_OP_SIZE_16, reg));
 }
@@ -420,7 +427,7 @@ static inline void cvmx_fau_async_fetch_and_add16(uint64_t scraddr, cvmx_fau_reg
  * @param value   Signed value to add.
  * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_fetch_and_add8(uint64_t scraddr, cvmx_fau_reg8_t reg, int8_t value)
+static inline void cvmx_hwfau_async_fetch_and_add8(uint64_t scraddr, cvmx_fau_reg8_t reg, int8_t value)
 {
 	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 0, CVMX_FAU_OP_SIZE_8, reg));
 }
@@ -440,7 +447,7 @@ static inline void cvmx_fau_async_fetch_and_add8(uint64_t scraddr, cvmx_fau_reg8
  *                Note: Only the low 22 bits are available.
  * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_tagwait_fetch_and_add64(uint64_t scraddr, cvmx_fau_reg64_t reg, int64_t value)
+static inline void cvmx_hwfau_async_tagwait_fetch_and_add64(uint64_t scraddr, cvmx_fau_reg64_t reg, int64_t value)
 {
 	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 1, CVMX_FAU_OP_SIZE_64, reg));
 }
@@ -460,7 +467,7 @@ static inline void cvmx_fau_async_tagwait_fetch_and_add64(uint64_t scraddr, cvmx
  *                Note: Only the low 22 bits are available.
  * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_tagwait_fetch_and_add32(uint64_t scraddr, cvmx_fau_reg32_t reg, int32_t value)
+static inline void cvmx_hwfau_async_tagwait_fetch_and_add32(uint64_t scraddr, cvmx_fau_reg32_t reg, int32_t value)
 {
 	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 1, CVMX_FAU_OP_SIZE_32, reg));
 }
@@ -479,7 +486,7 @@ static inline void cvmx_fau_async_tagwait_fetch_and_add32(uint64_t scraddr, cvmx
  * @param value   Signed value to add.
  * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_tagwait_fetch_and_add16(uint64_t scraddr, cvmx_fau_reg16_t reg, int16_t value)
+static inline void cvmx_hwfau_async_tagwait_fetch_and_add16(uint64_t scraddr, cvmx_fau_reg16_t reg, int16_t value)
 {
 	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 1, CVMX_FAU_OP_SIZE_16, reg));
 }
@@ -497,7 +504,7 @@ static inline void cvmx_fau_async_tagwait_fetch_and_add16(uint64_t scraddr, cvmx
  * @param value   Signed value to add.
  * @return Placed in the scratch pad register
  */
-static inline void cvmx_fau_async_tagwait_fetch_and_add8(uint64_t scraddr, cvmx_fau_reg8_t reg, int8_t value)
+static inline void cvmx_hwfau_async_tagwait_fetch_and_add8(uint64_t scraddr, cvmx_fau_reg8_t reg, int8_t value)
 {
 	cvmx_send_single(__cvmx_fau_iobdma_data(scraddr, value, 1, CVMX_FAU_OP_SIZE_8, reg));
 }
@@ -509,9 +516,9 @@ static inline void cvmx_fau_async_tagwait_fetch_and_add8(uint64_t scraddr, cvmx_
  *                - Step by 8 for 64 bit access.
  * @param value   Signed value to add.
  */
-static inline void cvmx_fau_atomic_add64(cvmx_fau_reg64_t reg, int64_t value)
+static inline void cvmx_hwfau_atomic_add64(cvmx_fau_reg64_t reg, int64_t value)
 {
-	cvmx_write64_int64(__cvmx_fau_store_address(0, reg), value);
+	cvmx_write64_int64(__cvmx_hwfau_store_address(0, reg), value);
 }
 
 /**
@@ -521,10 +528,10 @@ static inline void cvmx_fau_atomic_add64(cvmx_fau_reg64_t reg, int64_t value)
  *                - Step by 4 for 32 bit access.
  * @param value   Signed value to add.
  */
-static inline void cvmx_fau_atomic_add32(cvmx_fau_reg32_t reg, int32_t value)
+static inline void cvmx_hwfau_atomic_add32(cvmx_fau_reg32_t reg, int32_t value)
 {
 	reg ^= SWIZZLE_32;
-	cvmx_write64_int32(__cvmx_fau_store_address(0, reg), value);
+	cvmx_write64_int32(__cvmx_hwfau_store_address(0, reg), value);
 }
 
 /**
@@ -534,10 +541,10 @@ static inline void cvmx_fau_atomic_add32(cvmx_fau_reg32_t reg, int32_t value)
  *                - Step by 2 for 16 bit access.
  * @param value   Signed value to add.
  */
-static inline void cvmx_fau_atomic_add16(cvmx_fau_reg16_t reg, int16_t value)
+static inline void cvmx_hwfau_atomic_add16(cvmx_fau_reg16_t reg, int16_t value)
 {
 	reg ^= SWIZZLE_16;
-	cvmx_write64_int16(__cvmx_fau_store_address(0, reg), value);
+	cvmx_write64_int16(__cvmx_hwfau_store_address(0, reg), value);
 }
 
 /**
@@ -546,10 +553,10 @@ static inline void cvmx_fau_atomic_add16(cvmx_fau_reg16_t reg, int16_t value)
  * @param reg     FAU atomic register to access. 0 <= reg < 2048.
  * @param value   Signed value to add.
  */
-static inline void cvmx_fau_atomic_add8(cvmx_fau_reg8_t reg, int8_t value)
+static inline void cvmx_hwfau_atomic_add8(cvmx_fau_reg8_t reg, int8_t value)
 {
 	reg ^= SWIZZLE_8;
-	cvmx_write64_int8(__cvmx_fau_store_address(0, reg), value);
+	cvmx_write64_int8(__cvmx_hwfau_store_address(0, reg), value);
 }
 
 /**
@@ -559,9 +566,9 @@ static inline void cvmx_fau_atomic_add8(cvmx_fau_reg8_t reg, int8_t value)
  *                - Step by 8 for 64 bit access.
  * @param value   Signed value to write.
  */
-static inline void cvmx_fau_atomic_write64(cvmx_fau_reg64_t reg, int64_t value)
+static inline void cvmx_hwfau_atomic_write64(cvmx_fau_reg64_t reg, int64_t value)
 {
-	cvmx_write64_int64(__cvmx_fau_store_address(1, reg), value);
+	cvmx_write64_int64(__cvmx_hwfau_store_address(1, reg), value);
 }
 
 /**
@@ -571,10 +578,10 @@ static inline void cvmx_fau_atomic_write64(cvmx_fau_reg64_t reg, int64_t value)
  *                - Step by 4 for 32 bit access.
  * @param value   Signed value to write.
  */
-static inline void cvmx_fau_atomic_write32(cvmx_fau_reg32_t reg, int32_t value)
+static inline void cvmx_hwfau_atomic_write32(cvmx_fau_reg32_t reg, int32_t value)
 {
 	reg ^= SWIZZLE_32;
-	cvmx_write64_int32(__cvmx_fau_store_address(1, reg), value);
+	cvmx_write64_int32(__cvmx_hwfau_store_address(1, reg), value);
 }
 
 /**
@@ -584,10 +591,10 @@ static inline void cvmx_fau_atomic_write32(cvmx_fau_reg32_t reg, int32_t value)
  *                - Step by 2 for 16 bit access.
  * @param value   Signed value to write.
  */
-static inline void cvmx_fau_atomic_write16(cvmx_fau_reg16_t reg, int16_t value)
+static inline void cvmx_hwfau_atomic_write16(cvmx_fau_reg16_t reg, int16_t value)
 {
 	reg ^= SWIZZLE_16;
-	cvmx_write64_int16(__cvmx_fau_store_address(1, reg), value);
+	cvmx_write64_int16(__cvmx_hwfau_store_address(1, reg), value);
 }
 
 /**
@@ -596,31 +603,31 @@ static inline void cvmx_fau_atomic_write16(cvmx_fau_reg16_t reg, int16_t value)
  * @param reg     FAU atomic register to access. 0 <= reg < 2048.
  * @param value   Signed value to write.
  */
-static inline void cvmx_fau_atomic_write8(cvmx_fau_reg8_t reg, int8_t value)
+static inline void cvmx_hwfau_atomic_write8(cvmx_fau_reg8_t reg, int8_t value)
 {
 	reg ^= SWIZZLE_8;
-	cvmx_write64_int8(__cvmx_fau_store_address(1, reg), value);
+	cvmx_write64_int8(__cvmx_hwfau_store_address(1, reg), value);
 }
 
 /** Allocates 64bit FAU register.
  *  @return value is the base address of allocated FAU register
  */
-extern int cvmx_fau64_alloc(void);
+extern int cvmx_fau64_alloc(int reserve);
 
 /** Allocates 32bit FAU register.
  *  @return value is the base address of allocated FAU register
  */
-extern int cvmx_fau32_alloc(void);
+extern int cvmx_fau32_alloc(int reserve);
 
 /** Allocates 16bit FAU register.
  *  @return value is the base address of allocated FAU register
  */
-extern int cvmx_fau16_alloc(void);
+extern int cvmx_fau16_alloc(int reserve);
 
 /** Allocates 8bit FAU register.
  *  @return value is the base address of allocated FAU register
  */
-extern int cvmx_fau8_alloc(void);
+extern int cvmx_fau8_alloc(int reserve);
 
 /** Frees the specified FAU register.
  *  @param Base address of register to release.
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa-defs.h b/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
index 3441908..0fe81af 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
@@ -811,9 +811,15 @@ union cvmx_fpa_aurax_cfg {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
 	uint64_t ptr_dis                      : 1;  /**< Disable aura tracking pointer allocates/returns.
-                                                         0 = When FPA allocates a pointer from this aura, increment the count. When a pointer is
-                                                         returned to FPA for this aura, decrement the count.
-                                                         1 = Pointer allocations/returns will not change the count. */
+                                                         0 = When FPA allocates a pointer from this aura (including coprocessor or core requests),
+                                                         increment the count. When a pointer is returned to FPA for this aura (including
+                                                         coprocessor or core requests), decrement the count. Note that PKI may prefetch buffers it
+                                                         later returns, this may result in the count intermittently being higher than the number of
+                                                         buffers actually in use by packets visible to software.
+                                                         1 = Pointer allocations/returns will not automatically change the count.
+                                                         Note specific requests to change the count, including FPA_AURA(0..1023)_CNT_ADD,
+                                                         PKO_SEND_AURA_S, or PKI_AURA(0..1023)_CFG[PKT_ADD] will be applied regardless of the
+                                                         setting of this bit. */
 	uint64_t avg_con                      : 9;  /**< This value controls how much of each present average resource level is used to calculate
                                                          the new resource level. The value is a number from 0 to 256, which represents AVG_CON/256
                                                          of the average resource level that will be used in the calculation:
@@ -879,8 +885,11 @@ union cvmx_fpa_aurax_cnt_levels {
 	struct cvmx_fpa_aurax_cnt_levels_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_40_63               : 24;
-	uint64_t bp_ena                       : 1;  /**< Enable backpressure based on [BP] level. If set FPA_GEN_CFG[LVL_DLY] must be nonzero. */
-	uint64_t red_ena                      : 1;  /**< Enable RED based on [DROP] and [PASS] levels. If set FPA_GEN_CFG[LVL_DLY] must be nonzero. */
+	uint64_t bp_ena                       : 1;  /**< Enable backpressure based on [BP] level. If set FPA_GEN_CFG[LVL_DLY] must be nonzero.
+                                                         PKI_AURA(0..1023)_CFG[ENA_BP] must also be set for backpressure to propagate through PKI. */
+	uint64_t red_ena                      : 1;  /**< Enable RED based on [DROP] and [PASS] levels. If set FPA_GEN_CFG[LVL_DLY] must be nonzero.
+                                                         If set, RED is performed on core requests with FPA_ALLOC_LD_S[RED] set, and/or PKI
+                                                         requests if PKI_AURA(0..1023)_CFG[ENA_BP] is set. */
 	uint64_t shift                        : 6;  /**< Right shift to apply to FPA_AURA(0..1023)_CNT to result in a 8-bit relative depth to be
                                                          used for [DROP/PASS/LEVEL]. See Aura Counts. */
 	uint64_t bp                           : 8;  /**< Backpressure will be applied if the immediate shifted level is equal to or greater than this value. */
@@ -933,8 +942,8 @@ union cvmx_fpa_aurax_cnt_threshold {
 	uint64_t reserved_40_63               : 24;
 	uint64_t thresh                       : 40; /**< When FPA_AURA(0..1023)_CNT, after being modified, is equal to or crosses this value (i.e.
                                                          value was greater than, then becomes less than, or the value was less than and becomes
-                                                         greater than) the corresponding bit in FPA_AURA(0..1023)_INT is set. See Aura Quality of
-                                                         Service. */
+                                                         greater than) the corresponding bit in FPA_AURA(0..1023)_INT is set. See Aura Count
+                                                         Threshold Interrupts. */
 #else
 	uint64_t thresh                       : 40;
 	uint64_t reserved_40_63               : 24;
@@ -955,7 +964,7 @@ union cvmx_fpa_aurax_int {
 	uint64_t thresh                       : 1;  /**< Watermark interrupt pending. Set and throws FPA_INTSN_E::FPA_AURA(0..1024)_THRESH when
                                                          FPA_AURA(0..1023)_INT, after being modified, is equal to or crosses
                                                          FPA_AURA(0..1023)_CNT_THRESHOLD (i.e. value was greater than, then becomes less then, or
-                                                         value was less than, and becomes greater than). See Aura Count Threshold Interrupts */
+                                                         value was less than, and becomes greater than). See Aura Count Threshold Interrupts. */
 #else
 	uint64_t thresh                       : 1;
 	uint64_t reserved_1_63                : 63;
@@ -998,8 +1007,7 @@ union cvmx_fpa_aurax_pool_levels {
 	uint64_t red_ena                      : 1;  /**< Enable RED based on [DROP] and [PASS] levels. If set FPA_GEN_CFG[LVL_DLY] must be nonzero. */
 	uint64_t shift                        : 6;  /**< Right shift to apply to FPA_POOL(0..63)_AVAILABLE to result in a 8-bit relative depth to
                                                          be used for [DROP/PASS/LEVEL]. See Aura Counts. */
-	uint64_t bp                           : 8;  /**< Backpressure will be indicated if the average shifted level is equal to or less than this
-                                                         value. (It may be desirable to configure fast or no averaging when using backpressure.) */
+	uint64_t bp                           : 8;  /**< Backpressure will be indicated if the immediate shifted level is equal to or less than this value. */
 	uint64_t drop                         : 8;  /**< Packet will be dropped if the average shifted level is equal to or less than this value. */
 	uint64_t pass                         : 8;  /**< Packet will be passed if the average shifted level is larger than this value. */
 	uint64_t level                        : 8;  /**< Current shifted level, averaged with FPA_POOL(0..63)_AVAILABLE[AVG_CON].
@@ -1071,7 +1079,7 @@ union cvmx_fpa_bist_status {
 	struct cvmx_fpa_bist_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_38_63               : 26;
-	uint64_t status                       : 38; /**< Memory BIST status */
+	uint64_t status                       : 38; /**< Memory BIST status. */
 #else
 	uint64_t status                       : 38;
 	uint64_t reserved_38_63               : 26;
@@ -1237,10 +1245,10 @@ union cvmx_fpa_ecc_int {
 	struct cvmx_fpa_ecc_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_52_63               : 12;
-	uint64_t ram_dbe                      : 20; /**< Set when a single-bit error is detected in the corresponding ram. Throws
+	uint64_t ram_dbe                      : 20; /**< Set when a double-bit error is detected in the corresponding RAM. Throws
                                                          FPA_INTSN_E::FPA_ECC_RAM_DBE. */
 	uint64_t reserved_20_31               : 12;
-	uint64_t ram_sbe                      : 20; /**< Set when a double-bit error is detected in the corresponding ram. Throws
+	uint64_t ram_sbe                      : 20; /**< Set when a single-bit error is detected in the corresponding RAM. Throws
                                                          FPA_INTSN_E::FPA_ECC_RAM_SBE. */
 #else
 	uint64_t ram_sbe                      : 20;
@@ -1575,9 +1583,9 @@ union cvmx_fpa_gen_cfg {
                                                          0x3 = Reserved */
 	uint64_t avg_en                       : 1;  /**< QoS averaging enable. When set, compute average buffer levels, and [LVL_DLY] must be non-
                                                          zero. When clear, do not compute averages and save a few mW of power. */
-	uint64_t reserved_0_0                 : 1;
+	uint64_t clk_override                 : 1;  /**< Conditional clock override. */
 #else
-	uint64_t reserved_0_0                 : 1;
+	uint64_t clk_override                 : 1;
 	uint64_t avg_en                       : 1;
 	uint64_t pools                        : 2;
 	uint64_t lvl_dly                      : 6;
@@ -3143,13 +3151,13 @@ union cvmx_fpa_poolx_cfg {
                                                          two's complement numbers may be used to do subtractions. See Buffer Alignment. */
 	uint64_t reserved_5_15                : 11;
 	uint64_t l_type                       : 2;  /**< Type of load to send to L2.
-                                                         0x0 = LDD
-                                                         0x1 = LDT
-                                                         0x2 = Load with DWB
-                                                         0x3 = Reserved */
+                                                         0x0 = LDD.
+                                                         0x1 = LDT.
+                                                         0x2 = Load with DWB.
+                                                         0x3 = Reserved. */
 	uint64_t s_type                       : 1;  /**< Type of store to use when sending pages to L2:
-                                                         0 = use STF
-                                                         1 = use STT */
+                                                         0 = use STF.
+                                                         1 = use STT. */
 	uint64_t nat_align                    : 1;  /**< Returning buffers should be rounded to the nearest natural alignment specified with
                                                          [BUF_SIZE]. See Buffer Alignment. */
 	uint64_t ena                          : 1;  /**< Enable. Must be set after writing pool configuration, if clear any allocations will fail
@@ -3202,7 +3210,7 @@ union cvmx_fpa_poolx_end_addr {
 	struct cvmx_fpa_poolx_end_addr_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
-	uint64_t addr                         : 35; /**< Address */
+	uint64_t addr                         : 35; /**< Address. */
 	uint64_t reserved_0_6                 : 7;
 #else
 	uint64_t reserved_0_6                 : 7;
@@ -3229,8 +3237,7 @@ union cvmx_fpa_poolx_fpf_marks {
                                                          page pointers in DRAM, the FPA reads one page of pointers from DRAM. The recommended value
                                                          for this field is:
                                                          fpf_sz * 0.75
-                                                         where,
-                                                         fpf_sz = 320*(2^FPA_GEN_CFG[POOLS]).
+                                                         where, fpf_sz = 320 * 2^FPA_GEN_CFG[POOLS].
                                                          The maximum value is fpf_sz - 48.
                                                          It is recommended that software APIs represent this value as a percentage of fpf_sz, as
                                                          fpf_sz may vary between products.
@@ -3307,7 +3314,7 @@ union cvmx_fpa_poolx_stack_addr {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
 	uint64_t addr                         : 35; /**< Next address. The address of the next stack write. Must be initialized to
-                                                         FPA_POOL(0..63)_STACK_BASE when stack is createdFPA_POOL(0..63)_STACK_BASE. */
+                                                         FPA_POOL(0..63)_STACK_BASE[ADDR] when stack is createdFPA_POOL(0..63)_STACK_BASE. */
 	uint64_t reserved_0_6                 : 7;
 #else
 	uint64_t reserved_0_6                 : 7;
@@ -3689,7 +3696,8 @@ union cvmx_fpa_red_delay {
 	uint64_t avg_dly                      : 14; /**< Average-queue-size delay. The number of levelizer-clock cycles to wait (1024 *
                                                          ([AVG_DLY]+1) * (FPA_GEN_CFG[LVL_DLY]+1)) coprocessor clocks) between calculating the
                                                          moving average for each aura level. Note the minimum value of 2048 cycles implies that at
-                                                         100 M packets/sec, approximately 160 packets may arrive between average calculations.
+                                                         100 M packets/sec, 1.2 GHz coprocessor clock, approximately 160 packets may arrive between
+                                                         average calculations.
                                                          Larger FPA_GEN_CFG[LVL_DLY] values cause the backpressure indications and moving averages
                                                          of all aura levels to track changes in the actual free space more slowly. Larger AVG_DLY
                                                          also causes the moving averages of all aura levels to track changes in the actual free
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa.h b/arch/mips/include/asm/octeon/cvmx-fpa.h
index 311cebd..cf9b50c 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa.h
@@ -42,7 +42,7 @@
  *
  * Interface to the hardware Free Pool Allocator.
  *
- * <hr>$Revision: 86473 $<hr>
+ * <hr>$Revision: 94697 $<hr>
  *
  */
 
@@ -65,7 +65,7 @@ extern "C" {
 #endif
 
 #define CVMX_FPA_NUM_POOLS      8
-#define CVMX_FPA_NUM_POOLS_78XX 64
+#define CVMX_FPA3_NUM_POOLS	64
 #define CVMX_FPA_AURA_NUM       1024
 #define CVMX_FPA_MIN_BLOCK_SIZE 128
 #define CVMX_FPA_ALIGNMENT      128
@@ -79,44 +79,88 @@ typedef union {
 	uint64_t u64;
 	struct {
 #ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t scraddr:8; /**< the (64-bit word) location in scratchpad to write to (if len != 0) */
-		uint64_t len:8;     /**< the number of words in the response (0 => no response) */
-		uint64_t did:8;     /**< the ID of the device on the non-coherent bus */
-		uint64_t addr:40;   /**< the address that will appear in the first tick on the NCB bus */
+		uint64_t scraddr:8;	/**
+					 * the (64-bit word) location in
+					 * scratchpad to write to (if len != 0)
+					 */
+		uint64_t len:8;		/**
+					 * the number of words in the response
+					 * (0 => no response)
+					 */
+		uint64_t did:8;		/**
+					 * the ID of the device on the
+					 * non-coherent bus
+					 */
+		uint64_t addr:40;	/**
+					 * the address that will appear in the
+					 * first tick on the NCB bus
+					 */
 #else
-		uint64_t addr:40;   /**< the address that will appear in the first tick on the NCB bus */
-		uint64_t did:8;     /**< the ID of the device on the non-coherent bus */
-		uint64_t len:8;     /**< the number of words in the response (0 => no response) */
-		uint64_t scraddr:8; /**< the (64-bit word) location in scratchpad to write to (if len != 0) */
+		uint64_t addr:40;	/**
+					 * the address that will appear in the
+					 * first tick on the NCB bus
+					 */
+		uint64_t did:8;		/**
+					 * the ID of the device on the
+					 * non-coherent bus
+					 */
+		uint64_t len:8;		/**
+					 * the number of words in the response
+					 * (0 => no response)
+					 */
+		uint64_t scraddr:8;	/**
+					 * the (64-bit word) location in
+					 * scratchpad to write to (if len != 0)
+					 */
 #endif
 	} s;
 	struct {
 #ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t scraddr:8;     /**< the (64-bit word) location in scratchpad to write to (if len != 0) */
-		uint64_t len:8;		/**< length of return in workds, must be one. If the pool has
-					     no availale pts in the selected pool, then the ptr
-					     returned for the IOBDMA operation are 0s, indicating that
-					     the pool does not have an adequate number of ptrs to
-					     satisfy the IOBDMA. */
-		uint64_t did:8;		/**< the ID of the device on the non-coherent bus */
-		uint64_t node:4;	/**< OCI node number */
-		uint64_t red:1;		/**< Perform RED on allocation */
-		uint64_t reserved2:9;   /**< Reserved */
-		uint64_t aura:10;	/**< Aura number */
-		uint64_t reserved3:16;	/**< Reserved */
+		uint64_t scraddr:8;     /**
+					 * the (64-bit word) location in
+					 * scratchpad to write to (if len != 0)
+					 */
+		uint64_t len:8;		/**
+					 * length of return in workds, must be
+					 * one.  If the pool has no availale pts
+					 * in the selected pool then the ptr
+					 * returned for the IOBDMA operation are
+					 * 0s, indicating that the pool does not
+					 * have an adequate number of ptrs to
+					 * satisfy the IOBDMA.
+					 */
+		uint64_t did:8;		/**
+					 * the ID of the device on the
+					 * non-coherent bus
+					 */
+		uint64_t node:4;	/** OCI node number */
+		uint64_t red:1;		/** Perform RED on allocation */
+		uint64_t reserved2:9;   /** Reserved */
+		uint64_t aura:10;	/** Aura number */
+		uint64_t reserved3:16;	/** Reserved */
 #else
-		uint64_t reserved3:16;	/**< Reserved */
-		uint64_t aura:10;	/**< Aura number */
-		uint64_t reserved2:9;   /**< Reserved */
-		uint64_t red:1;		/**< Perform RED on allocation */
-		uint64_t node:4;	/**< OCI node number */
-		uint64_t did:8;		/**< the ID of the device on the non-coherent bus */
-		uint64_t len:8;		/**< length of return in workds, must be one. If the pool has
-					     no availale pts in the selected pool, then the ptr
-					     returned for the IOBDMA operation are 0s, indicating that
-					     the pool does not have an adequate number of ptrs to
-					     satisfy the IOBDMA. */
-		uint64_t scraddr:8;	/**< the (64-bit word) location in scratchpad to write to (if len != 0) */
+		uint64_t reserved3:16;	/** Reserved */
+		uint64_t aura:10;	/** Aura number */
+		uint64_t reserved2:9;   /** Reserved */
+		uint64_t red:1;		/** Perform RED on allocation */
+		uint64_t node:4;	/** OCI node number */
+		uint64_t did:8;		/**
+					 * the ID of the device on the
+					 * non-coherent bus
+					 */
+		uint64_t len:8;		/**
+					 * length of return in workds, must be
+					 * one.  If the pool has no availale pts
+					 * in the selected pool then the ptr
+					 * returned for the IOBDMA operation are
+					 * 0s, indicating that the pool does not
+					 * have an adequate number of ptrs to
+					 * satisfy the IOBDMA.
+					 */
+		uint64_t scraddr:8;	/**
+					 * the (64-bit word) location in
+					 * scratchpad to write to (if len != 0)
+					 */
 #endif
 	} cn78xx;
 } cvmx_fpa_iobdma_data_t;
@@ -129,21 +173,27 @@ typedef union {
 	struct {
 #ifdef __BIG_ENDIAN_BITFIELD
 		uint64_t reserved1:15;
-		uint64_t io:1;		/**< Indicates I/O space */
-		uint64_t did:8;		/**< the ID of the device on the non-coherent bus */
-		uint64_t node:4;	/**< OCI node number */
-		uint64_t red:1;		/**< Perform RED on allocation */
-		uint64_t reserved2:9;   /**< Reserved */
-		uint64_t aura:10;	/**< Aura number */
-		uint64_t reserved3:16;	/**< Reserved */
+		uint64_t io:1;		/** Indicates I/O space */
+		uint64_t did:8;		/**
+					 * the ID of the device on the
+					 * non-coherent bus
+					 */
+		uint64_t node:4;	/** OCI node number */
+		uint64_t red:1;		/** Perform RED on allocation */
+		uint64_t reserved2:9;   /** Reserved */
+		uint64_t aura:10;	/** Aura number */
+		uint64_t reserved3:16;	/** Reserved */
 #else
-		uint64_t reserved3:16;	/**< Reserved */
-		uint64_t aura:10;	/**< Aura number */
-		uint64_t reserved2:9;   /**< Reserved */
-		uint64_t red:1;		/**< Perform RED on allocation */
-		uint64_t node:4;	/**< OCI node number */
-		uint64_t did:8;		/**< the ID of the device on the non-coherent bus */
-		uint64_t io:1;		/**< Indicates I/O space */
+		uint64_t reserved3:16;	/** Reserved */
+		uint64_t aura:10;	/** Aura number */
+		uint64_t reserved2:9;   /** Reserved */
+		uint64_t red:1;		/** Perform RED on allocation */
+		uint64_t node:4;	/** OCI node number */
+		uint64_t did:8;		/**
+					 * the ID of the device on the
+					 * non-coherent bus
+					 */
+		uint64_t io:1;		/** Indicates I/O space */
 		uint64_t reserved1:15;
 
 #endif
@@ -158,27 +208,39 @@ typedef union {
 	struct {
 #ifdef __BIG_ENDIAN_BITFIELD
 		uint64_t reserved1:15;
-		uint64_t io:1;		/**< Indicates I/O space */
-		uint64_t did:8;		/**< the ID of the device on the non-coherent bus */
-		uint64_t node:4;	/**< OCI node number */
-		uint64_t reserved2:10;  /**< Reserved */
-		uint64_t aura:10;	/**< Aura number */
-		uint64_t fabs:1;	/**< free absolute */
-		uint64_t reserved3:3;	/**< Reserved */
-		uint64_t dwb_count:9;	/**< Number of cache lines for which the hardware should
-					     try to execute 'don't-write-back' commands. */
-		uint64_t reserved4:3;	/**< Reserved */
+		uint64_t io:1;		/** Indicates I/O space */
+		uint64_t did:8;		/**
+					 * the ID of the device on the
+					 * non-coherent bus
+					 */
+		uint64_t node:4;	/** OCI node number */
+		uint64_t reserved2:10;  /** Reserved */
+		uint64_t aura:10;	/** Aura number */
+		uint64_t fabs:1;	/** free absolute */
+		uint64_t reserved3:3;	/** Reserved */
+		uint64_t dwb_count:9;	/**
+					 * Number of cache lines for which the
+					 * hardware should try to execute
+					 * 'don't-write-back' commands.
+					 */
+		uint64_t reserved4:3;	/** Reserved */
 #else
-		uint64_t reserved4:3;	/**< Reserved */
-		uint64_t dwb_count:9;	/**< Number of cache lines for which the hardware should
-					     try to execute 'don't-write-back' commands. */
-		uint64_t reserved3:3;	/**< Reserved */
-		uint64_t fabs:1;	/**< free absolute */
-		uint64_t aura:10;	/**< Aura number */
-		uint64_t reserved2:10;  /**< Reserved */
-		uint64_t node:4;	/**< OCI node number */
-		uint64_t did:8;		/**< the ID of the device on the non-coherent bus */
-		uint64_t io:1;		/**< Indicates I/O space */
+		uint64_t reserved4:3;	/** Reserved */
+		uint64_t dwb_count:9;	/**
+					 * Number of cache lines for which the
+					 * hardware should try to execute
+					 * 'don't-write-back' commands.
+					 */
+		uint64_t reserved3:3;	/** Reserved */
+		uint64_t fabs:1;	/** free absolute */
+		uint64_t aura:10;	/** Aura number */
+		uint64_t reserved2:10;  /** Reserved */
+		uint64_t node:4;	/** OCI node number */
+		uint64_t did:8;		/**
+					 * the ID of the device on the
+					 * non-coherent bus
+					 */
+		uint64_t io:1;		/** Indicates I/O space */
 		uint64_t reserved1:15;
 #endif
 	} cn78xx;
@@ -194,13 +256,25 @@ enum fpa_pool_alignment {
  * Structure describing the current state of a FPA pool.
  */
 typedef struct {
-	char name[CVMX_FPA_POOL_NAME_LEN];	/**< FPA Pool Name */
-	uint64_t size;			/**< Size of each block */
-	void *base;			/**< The base memory address of whole block */
-	uint64_t stack_base;               /**< Base address of stack of FPA pool */
-	uint64_t starting_element_count;/**< The number of elements in the pool at creation */
-	uint64_t max_buffer_cnt;        /**< Maximum amount of buffers than can held in this
-					     FPA pool*/
+	char name[CVMX_FPA_POOL_NAME_LEN];	/** FPA Pool Name */
+	uint64_t size;				/** Size of each block */
+	void *base;				/**
+						 * The base memory address of
+						 * whole block
+						 */
+	uint64_t stack_base;			/**
+						 * Base address of stack of FPA
+						 * pool
+						 */
+	uint64_t starting_element_count;	/**
+						 * The number of elements in the
+						 * pool at creation
+						 */
+	uint64_t max_buffer_cnt;		/**
+						 * Maximum amount of buffers
+						 * that can be held in this
+						 * FPA pool
+						 */
 } cvmx_fpa_pool_info_t;
 
 
@@ -222,15 +296,80 @@ typedef struct cvmx_fpa_pool_config
 	uint64_t buffer_count;
 }cvmx_fpa_pool_config_t;
 
+int cvmx_fpa_allocate_auras(int node, int auras_allocated[], int count);
+int cvmx_fpa_free_auras(int node, int *pools_allocated, int count);
 /**
  * Current state of all the pools. Use access functions
  * instead of using it directly.
  */
-extern CVMX_SHARED cvmx_fpa_pool_info_t cvmx_fpa_pool_info[CVMX_MAX_NODES][CVMX_FPA_NUM_POOLS_78XX];
+extern CVMX_SHARED cvmx_fpa_pool_info_t
+cvmx_fpa_pool_info[CVMX_MAX_NODES][CVMX_FPA3_NUM_POOLS];
 
 /* CSR typedefs have been moved to cvmx-fpa-defs.h */
 
 /**
+ * Get a new block from the FPA Aura
+ *
+ * @param node  - node number
+ * @param aura  - aura to get the block from
+ * @return pointer to the block or NULL on failure
+ */
+static inline void *cvmx_fpa_alloc_aura(int node, int aura)
+{
+	uint64_t address;
+	cvmx_fpa_load_data_t load_addr;
+
+	load_addr.u64 = 0;
+	load_addr.cn78xx.io = 1;
+	load_addr.cn78xx.did = 0x29;    /* Device ID. Indicates FPA. */
+	load_addr.cn78xx.node = node;   /* OCI node number */
+	load_addr.cn78xx.red = 0;       /* Perform RED on allocation.
+					 * FIXME to use config option
+					 */
+	load_addr.cn78xx.aura = aura;   /* Aura number */
+
+	address = cvmx_read_csr((CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+					      load_addr.u64)));
+	if (!address)
+		return NULL;
+	return cvmx_phys_to_ptr(address);
+}
+
+/**
+ * Free a pointer back to the aura.
+ *
+ * @param node   node number
+ * @param aura   aura number
+ * @param ptr    physical address of block to free.
+ * @param num_cache_lines Cache lines to invalidate
+ */
+static inline void cvmx_fpa_free_aura(void *ptr, uint64_t node, int aura,
+				      uint64_t num_cache_lines)
+{
+	cvmx_fpa_store_addr_t newptr;
+	cvmx_addr_t newdata;
+
+	newdata.u64 = cvmx_ptr_to_phys(ptr);
+
+	newptr.u64 = 2ull<<62;
+	newptr.cn78xx.io = 1;
+	newptr.cn78xx.did = 0x29;    /* Device id, indicates FPA */
+	newptr.cn78xx.node = node;   /* OCI node number. */
+	newptr.cn78xx.aura = aura;   /* Aura number */
+	newptr.cn78xx.fabs = 0;	/* Free absolute. FIXME to use config option */
+	newptr.cn78xx.dwb_count = num_cache_lines;
+
+	/*cvmx_dprintf("aura = %d ptr_to_phys(ptr) = 0x%llx newptr.u64 = 0x%llx"
+		     " ptr = %p \n", ptr, aura, (ULL) newptr.u64
+		     (ULL) cvmx_ptr_to_phys(ptr)); */
+	/* Make sure that any previous writes to memory go out before we free
+	   this buffer. This also serves as a barrier to prevent GCC from
+	   reordering operations to after the free. */
+	CVMX_SYNCWS;
+        cvmx_write_io(newptr.u64, newdata.u64);
+}
+
+/**
  * Return the name of the pool
  *
  * @param pool   Pool to get the name of
@@ -263,7 +402,9 @@ static inline const char *cvmx_fpa_get_name(uint64_t pool)
 static inline int cvmx_fpa_is_member(uint64_t pool, void *ptr)
 {
 	return ((ptr >= cvmx_fpa_pool_info[0][pool].base) &&
-		((char *)ptr < ((char *)(cvmx_fpa_pool_info[0][pool].base)) + cvmx_fpa_pool_info[0][pool].size * cvmx_fpa_pool_info[0][pool].starting_element_count));
+		((char *)ptr < ((char *)(cvmx_fpa_pool_info[0][pool].base))
+		 + (cvmx_fpa_pool_info[0][pool].size
+		    * cvmx_fpa_pool_info[0][pool].starting_element_count)));
 }
 
 /**
@@ -274,19 +415,21 @@ static inline void cvmx_fpa_enable(void)
 {
 	cvmx_fpa_ctl_status_t status;
 
-	status.u64 = cvmx_read_csr(CVMX_FPA_CTL_STATUS);
-	if (status.s.enb) {
-		/*
-		 * CN68XXP1 should not reset the FPA (doing so may break the
-		 * SSO, so we may end up enabling it more than once.  Just
-		 * return and don't spew messages.
-		 */
-		return;
-	}
+	if (!octeon_has_feature(OCTEON_FEATURE_FPA3)) {
+		status.u64 = cvmx_read_csr(CVMX_FPA_CTL_STATUS);
+		if (status.s.enb) {
+			/*
+		 	* CN68XXP1 should not reset the FPA (doing so may break
+			* the SSO, so we may end up enabling it more than once.
+			* Just return and don't spew messages.
+		 	*/
+			return;
+		}
 
-	status.u64 = 0;
-	status.s.enb = 1;
-	cvmx_write_csr(CVMX_FPA_CTL_STATUS, status.u64);
+		status.u64 = 0;
+		status.s.enb = 1;
+		cvmx_write_csr(CVMX_FPA_CTL_STATUS, status.u64);
+	}
 }
 
 /**
@@ -312,8 +455,15 @@ static inline void *cvmx_fpa_alloc(uint64_t pool)
 {
 	uint64_t address;
 
+	/* FPA3 is handled differently */
+	if ((octeon_has_feature(OCTEON_FEATURE_FPA3))) {
+		/* We use the pool as the aura */
+		return cvmx_fpa_alloc_aura(0, (int)pool);
+	}
+
 	for (;;) {
-		address = cvmx_read_csr(CVMX_ADDR_DID(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool)));
+		address = cvmx_read_csr(CVMX_ADDR_DID(CVMX_FULL_DID(CVMX_OCT_DID_FPA,
+								    pool)));
 		if (cvmx_likely(address)) {
 			return cvmx_phys_to_ptr(address);
 		} else {
@@ -332,21 +482,32 @@ static inline void *cvmx_fpa_alloc(uint64_t pool)
  * The result of cvmx_fpa_async_alloc() may be retrieved using
  * cvmx_fpa_async_alloc_finish().
  *
- * @param scr_addr Local scratch address to put response in.  This is a byte address,
- *                  but must be 8 byte aligned.
+ * @param scr_addr Local scratch address to put response in.  This is a byte
+ *		   address but must be 8 byte aligned.
  * @param pool      Pool to get the block from
  */
 static inline void cvmx_fpa_async_alloc(uint64_t scr_addr, uint64_t pool)
 {
 	cvmx_fpa_iobdma_data_t data;
 
-	/* Hardware only uses 64 bit aligned locations, so convert from byte address
-	 ** to 64-bit index
+	/* Hardware only uses 64 bit aligned locations, so convert from byte
+	 * address to 64-bit index
 	 */
-	data.s.scraddr = scr_addr >> 3;
-	data.s.len = 1;
-	data.s.did = CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool);
-	data.s.addr = 0;
+	data.u64 = 0ull;
+	if (octeon_has_feature(OCTEON_FEATURE_FPA3)) {
+		data.cn78xx.scraddr = scr_addr >> 3;
+		data.cn78xx.len = 1;
+		data.cn78xx.did = 0x29;
+		data.cn78xx.node = cvmx_get_node_num();
+		data.cn78xx.aura = pool;
+	} else {
+		data.s.scraddr = scr_addr >> 3;
+		data.s.len = 1;
+		data.s.did = CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool);
+		data.s.addr = 0;
+	}
+	cvmx_scratch_write64(scr_addr, 0ull);
+	CVMX_SYNCW;
 	cvmx_send_single(data.u64);
 }
 
@@ -376,19 +537,23 @@ static inline void *cvmx_fpa_async_alloc_finish(uint64_t scr_addr, uint64_t pool
 
 /**
  * Free a block allocated with a FPA pool.
- * Does NOT provide memory ordering in cases where the memory block was modified by the core.
+ * Does NOT provide memory ordering in cases where the memory block was
+ * modified by the core.
  *
  * @param ptr    Block to free
  * @param pool   Pool to put it in
  * @param num_cache_lines
  *               Cache lines to invalidate
  */
-static inline void cvmx_fpa_free_nosync(void *ptr, uint64_t pool, uint64_t num_cache_lines)
+static inline void cvmx_fpa_free_nosync(void *ptr, uint64_t pool,
+					uint64_t num_cache_lines)
 {
 	cvmx_addr_t newptr;
 	newptr.u64 = cvmx_ptr_to_phys(ptr);
-	newptr.sfilldidspace.didspace = CVMX_ADDR_DIDSPACE(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool));
-	asm volatile ("":::"memory");	/* Prevent GCC from reordering around free */
+	newptr.sfilldidspace.didspace =
+		CVMX_ADDR_DIDSPACE(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool));
+	/* Prevent GCC from reordering around free */
+	asm volatile ("":::"memory");
 	/* value written is number of cache lines not written back */
 	cvmx_write_io(newptr.u64, num_cache_lines);
 }
@@ -402,21 +567,33 @@ static inline void cvmx_fpa_free_nosync(void *ptr, uint64_t pool, uint64_t num_c
  * @param num_cache_lines
  *               Cache lines to invalidate
  */
-static inline void cvmx_fpa_free(void *ptr, uint64_t pool, uint64_t num_cache_lines)
+static inline void cvmx_fpa_free(void *ptr, uint64_t pool,
+				 uint64_t num_cache_lines)
 {
 	cvmx_addr_t newptr;
+
+	/* FPA3 is handled differently */
+	if ((octeon_has_feature(OCTEON_FEATURE_FPA3))) {
+		/* We use the pool as the aura, assume node=0 */
+		cvmx_fpa_free_aura(ptr, 0, (int)pool, num_cache_lines);
+		return;
+	}
+
 	newptr.u64 = cvmx_ptr_to_phys(ptr);
-	newptr.sfilldidspace.didspace = CVMX_ADDR_DIDSPACE(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool));
-	/* Make sure that any previous writes to memory go out before we free this buffer.
-	 ** This also serves as a barrier to prevent GCC from reordering operations to after
-	 ** the free. */
+	newptr.sfilldidspace.didspace =
+		CVMX_ADDR_DIDSPACE(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool));
+	/* Make sure that any previous writes to memory go out before we free
+	 * this buffer.  This also serves as a barrier to prevent GCC from
+	 * reordering operations to after the free.
+	 */
 	CVMX_SYNCWS;
 	/* value written is number of cache lines not written back */
 	cvmx_write_io(newptr.u64, num_cache_lines);
 }
 
 
-static inline void __cvmx_fpa_aura_cfg(int node, int aura, int pool, int buffers_cnt, int ptr_dis)
+static inline void __cvmx_fpa_aura_cfg(int node, int aura, int pool,
+				       int buffers_cnt, int ptr_dis)
 {
        cvmx_fpa_aurax_cfg_t aura_cfg;
        uint64_t pool64 = pool;
@@ -446,7 +623,8 @@ static inline void __cvmx_fpa_aura_cfg(int node, int aura, int pool, int buffers
  *
  */
 static inline void cvmx_fpa_setup_aura_qos(int node, int aura, bool ena_red,
-					   uint64_t pass_thresh,uint64_t drop_thresh,
+					   uint64_t pass_thresh,
+					   uint64_t drop_thresh,
 					   bool ena_bp,uint64_t bp_thresh)
 {
 	uint64_t shift=0;
@@ -471,66 +649,6 @@ static inline void cvmx_fpa_setup_aura_qos(int node, int aura, bool ena_red,
 }
 
 /**
- * Get a new block from the FPA Aura
- *
- * @param node  - node number
- * @param aura  - aura to get the block from
- * @return pointer to the block or NULL on failure
- */
-static inline void *cvmx_fpa_alloc_aura(int node, int aura, uint64_t num_cache_lines)
-{
-	uint64_t address;
-	cvmx_fpa_load_data_t load_addr;
-
-	load_addr.u64 = 0;
-	load_addr.cn78xx.io = 1;
-	load_addr.cn78xx.did = 0x29;    /* Device ID. Indicates FPA. */
-	load_addr.cn78xx.node = node;   /* OCI node number */
-	load_addr.cn78xx.red = 0;       /* Perform RED on allocation. FIXME to use config option */
-	load_addr.cn78xx.aura = aura;   /* Aura number */
-
-	address = cvmx_read_csr((CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS, load_addr.u64)));
-	return cvmx_phys_to_ptr(address);
-
-
-}
-
-/**
- * Free a pointer back to the aura.
- *
- * @param node   node number
- * @param aura   aura number
- * @param ptr    physical address of block to free.
- * @param num_cache_lines Cache lines to invalidate
- */
-static inline void cvmx_fpa_free_aura(void *ptr, uint64_t node, int aura,
-				      uint64_t num_cache_lines)
-{
-	cvmx_fpa_store_addr_t newptr;
-	cvmx_addr_t newdata;
-
-	newdata.u64 = cvmx_ptr_to_phys(ptr);
-
-	newptr.u64 = 2ull<<62;
-	newptr.cn78xx.io = 1;
-	newptr.cn78xx.did = 0x29;    /* Device id, indicates FPA */
-	newptr.cn78xx.node = node;   /* OCI node number. */
-	newptr.cn78xx.aura = aura;   /* Aura number */
-	newptr.cn78xx.fabs = 0;	/* Free absolute. FIXME to use config option */
-	newptr.cn78xx.dwb_count = num_cache_lines;
-
-	/*cvmx_dprintf("aura = %d ptr_to_phys(ptr) = 0x%llx newptr.u64 = 0x%llx"
-		     " ptr = %p \n", ptr, aura, (ULL) newptr.u64
-		     (ULL) cvmx_ptr_to_phys(ptr)); */
-	/* Make sure that any previous writes to memory go out before we free
-	   this buffer. This also serves as a barrier to prevent GCC from
-	   reordering operations to after the free. */
-	CVMX_SYNCWS;
-        cvmx_write_io(newptr.u64, newdata.u64);
-}
-
-
-/**
  * Setup a FPA pool to control a new block of memory.
  * This can only be called once per pool. Make sure proper
  * locking enforces this.
@@ -547,7 +665,8 @@ static inline void cvmx_fpa_free_aura(void *ptr, uint64_t node, int aura,
  * @return 0 on Success,
  *         -1 on failure
  */
-extern int cvmx_fpa_setup_pool(uint64_t pool, const char *name, void *buffer, uint64_t block_size, uint64_t num_blocks);
+extern int cvmx_fpa_setup_pool(uint64_t pool, const char *name, void *buffer,
+			       uint64_t block_size, uint64_t num_blocks);
 
 /**
  * Shutdown a Memory pool and validate that it had all of
@@ -581,6 +700,11 @@ extern uint64_t cvmx_fpa_get_block_size(uint64_t pool);
 int cvmx_fpa_global_initialize(void);
 
 /**
+ * Initialize global configuration for FPA block for specified node.
+ */
+int cvmx_fpa_global_init_node(int node);
+
+/**
  * Allocate or reserve  the specified fpa pool.
  *
  * @param pool	  FPA pool to allocate/reserve. If -1 it
@@ -620,9 +744,9 @@ int cvmx_fpa_release_pool(int pool);
  *                         to specify the size of each buffer in the FPA .
  *
  */
-int cvmx_fpa_pool_stack_init(int node, int pool, char *name, int mem_node,
-		int max_buffer_cnt, enum fpa_pool_alignment align,
-		int buffer_sz);
+int cvmx_fpa_pool_stack_init(int node, int pool, const char *name, int mem_node,
+			     int max_buffer_cnt, enum fpa_pool_alignment align,
+			     int buffer_sz);
 
 /**
  * This call will allocated buffers_cnt number of buffers from  the bootmemory
@@ -638,13 +762,19 @@ int cvmx_fpa_pool_stack_init(int node, int pool, char *name, int mem_node,
  * @param name     - specifies the name of aura to be initalized.
  * @param mem_node - specifies the node from which the memory for the buffers
  *                   is allocated.
- * @param ptr_dis - Need to look into this more but is on the lines of of whether
- * the hardware checks double frees.
+ * @param buffers  - Block of memory to use for the aura buffers. If NULL,
+ *                   aura memory is allocated.
+ * @param ptr_dis - Need to look into this more but is on the lines of of
+ *		    whether the hardware checks double frees.
  */
-int cvmx_fpa_aura_init(int node, int aura, char *name, int mem_node,
-		int buffers_cnt, int ptr_dis);
-int cvmx_fpa_config_red_params(int node, int qos_avg_en, int red_lvl_dly, int avg_dly);
-
+int cvmx_fpa_aura_init(int node, int aura, const char *name, int mem_node,
+		       void *buffers, int buffers_cnt, int ptr_dis);
+int cvmx_fpa_pool_init(int pool_id, int num_blocks, int block_size,
+		       void *buffer, const char *name);
+int cvmx_fpa_config_red_params(int node, int qos_avg_en, int red_lvl_dly,
+			       int avg_dly);
+
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 /**
  * This will map auras specified in the auras_index[] array to specified
  * FPA pool_index.
@@ -663,19 +793,22 @@ static inline int cvmx_fpa_assign_aura(int node, int aura, int pool_index)
 	auras[0] = aura;
 	return cvmx_fpa_assign_auras(node, auras, 1, pool_index);
 }
+#endif
 
-int cvmx_fpa_allocate_auras(int node, int auras_allocated[], int count);
-int cvmx_fpa_free_auras(int node, int *pools_allocated, int count);
 /**
  * This will allocate count number of FPA pools on the specified node to the
  * calling application. These pools will be for exclusive use of the application
  * until they are freed.
- * @param pools_allocated is an array of length count allocated by the application
- * before invoking the cvmx_allocate_fpa_pool call. On return it will contain the
- * index numbers of the pools allocated.
+ * @param pools_allocated is an array of length count allocated by
+ *			  the application before invoking the
+ *			  cvmx_allocate_fpa_pool call.  On return it will
+ *			  contain the index numbers of the pools allocated.
  * @return 0 on success and -1 on failure.
  */
 int cvmx_fpa_allocate_fpa_pools(int node, int pools_allocated[], int count);
+
+int cvmx_fpa_reserve_compat(int node);
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-global-resources.h b/arch/mips/include/asm/octeon/cvmx-global-resources.h
index e12d06d..3d5eeb6 100644
--- a/arch/mips/include/asm/octeon/cvmx-global-resources.h
+++ b/arch/mips/include/asm/octeon/cvmx-global-resources.h
@@ -4,13 +4,13 @@
 #define CVMX_GLOBAL_RESOURCES_DATA_NAME "cvmx-global-resources"
 
 /*In macros below abbreviation GR stands for global resources. */
+#define CVMX_GR_TAG_INVALID cvmx_get_gr_tag('i','n','v','a','l','i','d','.','.','.','.','.','.','.','.','.')
 /*Tag for pko que table range. */
 #define CVMX_GR_TAG_PKO_QUEUES cvmx_get_gr_tag('c','v','m','_','p','k','o','_','q','u','e','u','s','.','.','.')
 /*Tag for a pko internal ports range */
 #define CVMX_GR_TAG_PKO_IPORTS cvmx_get_gr_tag('c','v','m','_','p','k','o','_','i','p','o','r','t','.','.','.')
 #define CVMX_GR_TAG_FPA        cvmx_get_gr_tag('c','v','m','_','f','p','a','.','.','.','.','.','.','.','.','.')
 #define CVMX_GR_TAG_FAU        cvmx_get_gr_tag('c','v','m','_','f','a','u','.','.','.','.','.','.','.','.','.')
-#define CVMX_GR_TAG_FPA        cvmx_get_gr_tag('c','v','m','_','f','p','a','.','.','.','.','.','.','.','.','.')
 #define CVMX_GR_TAG_CLUSTERS(x)	    cvmx_get_gr_tag('c','v','m','_','c','l','u','s','t','e','r','_',(x+'0'),'.','.','.')
 #define CVMX_GR_TAG_CLUSTER_GRP(x)  cvmx_get_gr_tag('c','v','m','_','c','l','g','r','p','_',(x+'0'),'.','.','.','.','.')
 #define CVMX_GR_TAG_STYLE(x)        cvmx_get_gr_tag('c','v','m','_','s','t','y','l','e','_',(x+'0'),'.','.','.','.','.')
@@ -26,7 +26,6 @@
 #define CVMX_GR_TAG_CIU3_SWINTSN(_n) \
 	cvmx_get_gr_tag('c','v','m','_','c','i','u','3','_', ((_n) + '0'),'_','s','w','i','s','n')
 
-
 #define TAG_INIT_PART(A,B,C,D,E,F,G,H) ( \
 	(((uint64_t)(A) & 0xff) << 56) | (((uint64_t)(B) & 0xff) << 48) | (((uint64_t)(C) & 0xff) << 40)  | (((uint64_t)(D) & 0xff) << 32) | \
 	(((uint64_t)(E) & 0xff) << 24) | (((uint64_t)(F) & 0xff) << 16) | (((uint64_t)(G) & 0xff) << 8)   | (((uint64_t)(H) & 0xff)))
@@ -37,6 +36,12 @@ struct global_resource_tag
 	uint64_t hi;
 };
 
+enum cvmx_resource_err
+{
+	CVMX_RESOURCE_ALLOC_FAILED = -1,
+	CVMX_RESOURCE_ALREADY_RESERVED = -2
+};
+
 /*
  * @INTERNAL
  * Creates a tag from the specified characters.
diff --git a/arch/mips/include/asm/octeon/cvmx-gmx.h b/arch/mips/include/asm/octeon/cvmx-gmx.h
index 40bb9e4..bd95280 100644
--- a/arch/mips/include/asm/octeon/cvmx-gmx.h
+++ b/arch/mips/include/asm/octeon/cvmx-gmx.h
@@ -42,7 +42,7 @@
  *
  * Interface to the GMX hardware.
  *
- * <hr>$Revision: 74168 $<hr>
+ * <hr>$Revision: 94283 $<hr>
  */
 
 #ifndef __CVMX_GMX_H__
@@ -58,6 +58,10 @@ extern "C" {
 
 int cvmx_gmx_set_backpressure_override(uint32_t interface, uint32_t port_mask);
 
+int cvmx_agl_set_backpressure_override(uint32_t interface, uint32_t port_mask);
+
+int cvmx_bgx_set_backpressure_override(uint32_t interface, uint32_t port_mask);
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-gpio-defs.h b/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
index 29639a0..9205d3cd 100644
--- a/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
@@ -451,30 +451,7 @@ union cvmx_gpio_bit_cfgx {
 	uint64_t reserved_21_63               : 43;
 #endif
 	} cn70xx;
-	struct cvmx_gpio_bit_cfgx_cn78xx {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_21_63               : 43;
-	uint64_t output_sel                   : 5;  /**< Selects GPIO output. When [TX_OE] is set, selects what output data is driven. Enumerated
-                                                         by GPIO_OUTSEL_E. */
-	uint64_t reserved_12_15               : 4;
-	uint64_t fil_sel                      : 4;  /**< Filter select. Global counter bit-select (controls sample rate). */
-	uint64_t fil_cnt                      : 4;  /**< Filter count. Specifies the number of consecutive samples to change state. */
-	uint64_t int_type                     : 1;  /**< Type of interrupt when pin is an input. When set, rising edge interrupt, else level interrupt. */
-	uint64_t reserved_2_2                 : 1;
-	uint64_t rx_xor                       : 1;  /**< Receive inversion. When set to 1, inverts the received GPIO signal. */
-	uint64_t tx_oe                        : 1;  /**< Transmit output enable. When set to 1, the GPIO pin is driven as an output pin. */
-#else
-	uint64_t tx_oe                        : 1;
-	uint64_t rx_xor                       : 1;
-	uint64_t reserved_2_2                 : 1;
-	uint64_t int_type                     : 1;
-	uint64_t fil_cnt                      : 4;
-	uint64_t fil_sel                      : 4;
-	uint64_t reserved_12_15               : 4;
-	uint64_t output_sel                   : 5;
-	uint64_t reserved_21_63               : 43;
-#endif
-	} cn78xx;
+	struct cvmx_gpio_bit_cfgx_cn70xx      cn78xx;
 	struct cvmx_gpio_bit_cfgx_cn61xx      cnf71xx;
 };
 typedef union cvmx_gpio_bit_cfgx cvmx_gpio_bit_cfgx_t;
@@ -631,19 +608,31 @@ typedef union cvmx_gpio_clk_qlmx cvmx_gpio_clk_qlmx_t;
 /**
  * cvmx_gpio_clk_synce#
  *
- * A QLM can be configured as a clock source. The following table shows the clock speed output
- * for different modes.
+ * A QLM can be configured as a clock source. The GPIO block can support up to two unique clocks
+ * to send out any GPIO pin as configured by GPIO_BIT_CFG(0..19)[SYNCE_SEL]. The clock can be
+ * divided by 2, 4, 8 or 16 of the selected RX lane clock. The following table shows the clock
+ * speed output for different modes.
  */
 union cvmx_gpio_clk_syncex {
 	uint64_t u64;
 	struct cvmx_gpio_clk_syncex_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t div                          : 2;  /**< Internal clock divider. 0 = DIV2, 1 = DIV4, 2 = DIV8, 3 = DIV16. */
-	uint64_t lane_sel                     : 2;  /**< Selects which RX lane clock from QLMx to use as the GPIO internal QLMx clock. The GPIO
-                                                         block can support up to two unique clocks to send out any GPIO pin as configured by
-                                                         GPIO_BIT_CFG(0..19)[SYNCE_SEL]. The clock can be divided by 2, 4, 8 or 16 of the selected
-                                                         RX lane clock. */
+	uint64_t div                          : 2;  /**< GPIO internal clock divider setting relative to QLM SERDES CLOCK_SYNCE.
+                                                         The maximum supported GPIO output frequency is 125 MHz.
+                                                         0x0 = Divide by 20.
+                                                         0x1 = Divide by 40.
+                                                         0x2 = Divide by 80.
+                                                         0x3 = Divide by 160.
+                                                         Speed    DIV20   DIV40   DIV80   DIV160
+                                                         [GHz]      [MHz]   [MHz]   [MHz]   [MHz]
+                                                         1.2500   62.50   31.25   15.63    7.81
+                                                         2.5000   125.00  62.50   31.25   15.63
+                                                         3.1250    ---    78.13   39.06   19.53
+                                                         5.0000    ---      125.00  62.50   31.25
+                                                         6.2500    ---      ---     78.13   39.06
+                                                         10.3125   ---      ---     ---     64.45 */
+	uint64_t lane_sel                     : 2;  /**< Selects which RX lane clock from QLMx to use as the GPIO internal QLMx clock. */
 #else
 	uint64_t lane_sel                     : 2;
 	uint64_t div                          : 2;
@@ -684,11 +673,21 @@ union cvmx_gpio_clk_syncex {
 	uint64_t reserved_12_63               : 52;
 	uint64_t qlm_sel                      : 4;  /**< Selects which QLM(0..7) to select from. */
 	uint64_t reserved_4_7                 : 4;
-	uint64_t div                          : 2;  /**< Internal clock divider. 0 = DIV2, 1 = DIV4, 2 = DIV8, 3 = DIV16. */
-	uint64_t lane_sel                     : 2;  /**< Selects which RX lane clock from QLMx to use as the GPIO internal QLMx clock. The GPIO
-                                                         block can support up to two unique clocks to send out any GPIO pin as configured by
-                                                         GPIO_BIT_CFG(0..19)[SYNCE_SEL]. The clock can be divided by 2, 4, 8 or 16 of the selected
-                                                         RX lane clock. */
+	uint64_t div                          : 2;  /**< GPIO internal clock divider setting relative to QLM SERDES CLOCK_SYNCE.
+                                                         The maximum supported GPIO output frequency is 125 MHz.
+                                                         0x0 = Divide by 20.
+                                                         0x1 = Divide by 40.
+                                                         0x2 = Divide by 80.
+                                                         0x3 = Divide by 160.
+                                                         Speed    DIV20   DIV40   DIV80   DIV160
+                                                         [GHz]      [MHz]   [MHz]   [MHz]   [MHz]
+                                                         1.2500   62.50   31.25   15.63    7.81
+                                                         2.5000   125.00  62.50   31.25   15.63
+                                                         3.1250    ---    78.13   39.06   19.53
+                                                         5.0000    ---      125.00  62.50   31.25
+                                                         6.2500    ---      ---     78.13   39.06
+                                                         10.3125   ---      ---     ---     64.45 */
+	uint64_t lane_sel                     : 2;  /**< Selects which RX lane clock from QLMx to use as the GPIO internal QLMx clock. */
 #else
 	uint64_t lane_sel                     : 2;
 	uint64_t div                          : 2;
@@ -871,7 +870,7 @@ union cvmx_gpio_ocla_exten_trig {
 	struct cvmx_gpio_ocla_exten_trig_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
-	uint64_t m_trig                       : 1;  /**< Manual Trigger. Used only when SEL=0x1F. */
+	uint64_t m_trig                       : 1;  /**< Manual trigger. Used only when SEL=0x1F. */
 	uint64_t sel                          : 5;  /**< Selects the GPIO(0..19) input pin to use, or 0x1F for manual trigger, to use in the OCLA
                                                          coprocessor for GPIO-based triggering. */
 #else
diff --git a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
index c2e533b..ef9aa82 100644
--- a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
@@ -933,6 +933,17 @@ static inline uint64_t CVMX_GSERX_PHYX_IDCODE_LO(unsigned long offset, unsigned
 #define CVMX_GSERX_PHYX_IDCODE_LO(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090400000ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE0_LOOPBACK(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE0_LOOPBACK(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408170ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE0_LOOPBACK(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408170ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_PHYX_LANE0_RX_LBERT_CTL(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -955,6 +966,17 @@ static inline uint64_t CVMX_GSERX_PHYX_LANE0_RX_LBERT_ERR(unsigned long offset,
 #define CVMX_GSERX_PHYX_LANE0_RX_LBERT_ERR(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904080B8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE0_RX_OVRD_IN_LO(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE0_RX_OVRD_IN_LO(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408028ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE0_RX_OVRD_IN_LO(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408028ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_PHYX_LANE0_TXDEBUG(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -977,6 +999,39 @@ static inline uint64_t CVMX_GSERX_PHYX_LANE0_TX_LBERT_CTL(unsigned long offset,
 #define CVMX_GSERX_PHYX_LANE0_TX_LBERT_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904080A8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE0_TX_OVRD_IN_HI(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE0_TX_OVRD_IN_HI(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408008ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE0_TX_OVRD_IN_HI(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408008ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE0_TX_OVRD_IN_LO(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE0_TX_OVRD_IN_LO(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408000ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE0_TX_OVRD_IN_LO(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408000ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE1_LOOPBACK(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE1_LOOPBACK(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408970ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE1_LOOPBACK(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408970ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_PHYX_LANE1_RX_LBERT_CTL(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -999,6 +1054,17 @@ static inline uint64_t CVMX_GSERX_PHYX_LANE1_RX_LBERT_ERR(unsigned long offset,
 #define CVMX_GSERX_PHYX_LANE1_RX_LBERT_ERR(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904088B8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE1_RX_OVRD_IN_LO(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE1_RX_OVRD_IN_LO(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408828ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE1_RX_OVRD_IN_LO(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408828ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_PHYX_LANE1_TXDEBUG(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -1021,6 +1087,39 @@ static inline uint64_t CVMX_GSERX_PHYX_LANE1_TX_LBERT_CTL(unsigned long offset,
 #define CVMX_GSERX_PHYX_LANE1_TX_LBERT_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904088A8ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE1_TX_OVRD_IN_HI(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE1_TX_OVRD_IN_HI(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408808ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE1_TX_OVRD_IN_HI(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408808ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_LANE1_TX_OVRD_IN_LO(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_LANE1_TX_OVRD_IN_LO(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090408800ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_LANE1_TX_OVRD_IN_LO(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090408800ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_PHYX_OVRD_IN_LO(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && (((offset <= 2)) && ((block_id == 0))))))
+		cvmx_warn("CVMX_GSERX_PHYX_OVRD_IN_LO(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090400088ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288;
+}
+#else
+#define CVMX_GSERX_PHYX_OVRD_IN_LO(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090400088ull) + (((offset) & 3) + ((block_id) & 0) * 0x0ull) * 524288)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_PHY_CTL(unsigned long block_id)
 {
 	if (!(
@@ -1318,6 +1417,17 @@ static inline uint64_t CVMX_GSERX_SATA_TX_INVERT(unsigned long block_id)
 #define CVMX_GSERX_SATA_TX_INVERT(block_id) (CVMX_ADD_IO_SEG(0x0001180090100220ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_SCRATCH(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 13)))))
+		cvmx_warn("CVMX_GSERX_SCRATCH(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180090000020ull) + ((block_id) & 15) * 0x1000000ull;
+}
+#else
+#define CVMX_GSERX_SCRATCH(block_id) (CVMX_ADD_IO_SEG(0x0001180090000020ull) + ((block_id) & 15) * 0x1000000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_SPD(unsigned long block_id)
 {
 	if (!(
@@ -1620,16 +1730,17 @@ union cvmx_gserx_cfg {
 	struct cvmx_gserx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t bgx_quad                     : 1;  /**< For non-OCI links, indicates the BGX is in quad aggregation mode when GSER(0..13)_CFG[BGX]
+	uint64_t bgx_quad                     : 1;  /**< For non-OCI links, indicates the BGX is in quad aggregation mode when GSER(0..7)_CFG[BGX]
                                                          is also set. A single controller is used for all four lanes. For OCI links, this bit has
                                                          no meaning. */
-	uint64_t bgx_dual                     : 1;  /**< For non-OCI links, indicates the BGX is in dual aggregation mode when GSER(0..13)_CFG[BGX]
+	uint64_t bgx_dual                     : 1;  /**< For non-OCI links, indicates the BGX is in dual aggregation mode when GSER(0..7)_CFG[BGX]
                                                          is also set. A single controller is used for lanes 0 and 1 and another controller is used
                                                          for lanes 2 and 3. For OCI links, this bit has no meaning. */
 	uint64_t bgx                          : 1;  /**< For non-OCI links, indicates the GSER is configured for BGX mode. Only one of the BGX,
                                                          ILA, or PCIE modes can be set at any one time. For OCI links, this bit has no meaning. */
-	uint64_t ila                          : 1;  /**< For non-OCI links, indicates the GSER is configured for ILK/ILA mode. Only one of the BGX,
-                                                         ILA, or PCIE modes can be set at any one time. For OCI links, this bit has no meaning. */
+	uint64_t ila                          : 1;  /**< For non-OCI links, indicates the GSER is configured for ILK/ILA mode. For OCI links
+                                                         this bit will be set.  Only one of the BGX, ILA, or PCIE modes can be set at any
+                                                         one time. For OCI links, this bit has no meaning. */
 	uint64_t pcie                         : 1;  /**< For non-OCI links, indicates the GSER is configured for PCIE mode. Only one of the BGX,
                                                          ILA, or PCIE modes can be set at any one time. For OCI links, this bit has no meaning. */
 #else
@@ -1948,7 +2059,8 @@ union cvmx_gserx_dlmx_ref_use_pad {
 	uint64_t ref_use_pad                  : 1;  /**< When asserted, selects the external ref_pad_clk_[p,m]
                                                          inputs as the reference clock sourse.  When deasserted,
                                                          ref_alt_clk_[p,m] are selected from an on-chip
-                                                         source of the reference clock. */
+                                                         source of the reference clock. REF_USE_PAD must be
+                                                         clear for DLM1 and DLM2. */
 #else
 	uint64_t ref_use_pad                  : 1;
 	uint64_t reserved_1_63                : 63;
@@ -2490,6 +2602,9 @@ typedef union cvmx_gserx_dlmx_tx_term_offset cvmx_gserx_dlmx_tx_term_offset_t;
 
 /**
  * cvmx_gser#_iddq_mode
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_iddq_mode {
 	uint64_t u64;
@@ -2509,8 +2624,12 @@ typedef union cvmx_gserx_iddq_mode cvmx_gserx_iddq_mode_t;
 /**
  * cvmx_gser#_lane#_p#_mode_0
  *
- * These are the RAW PCS per-lane global settings mode 0 registers. The Protocol selects the
- * specific protocol register as enumerated by GSER_LMODE_E.
+ * These are the RAW PCS per lane settings mode 0 registers. There is one register per
+ * lane (0..3) per GSER per GSER_LMODE_E (0..11). Only one entry is used at any given
+ * time in a given GSER lane - the one selected by the corresponding
+ * GSER(0..13)_LANE_MODE[LMODE].
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_px_mode_0 {
 	uint64_t u64;
@@ -2523,79 +2642,79 @@ union cvmx_gserx_lanex_px_mode_0 {
                                                          0x2 = ~15dB of peaking at 5.5 GHz
                                                          0x3 = ~20dB of peaking at 6 GHz (Maximum bandwidth).
                                                          Recommended settings:
-                                                         R_25G_REFCLK100: 0x0
-                                                         R_5G_REFCLK100: 0x0
-                                                         R_8G_REFCLK100: 0x3
-                                                         R_125G_REFCLK15625_KX: 0x0
+                                                         R_25G_REFCLK100:          0x0
+                                                         R_5G_REFCLK100:           0x0
+                                                         R_8G_REFCLK100:           0x3
+                                                         R_125G_REFCLK15625_KX:    0x0
                                                          R_3125G_REFCLK15625_XAUI: 0x0
-                                                         R_103215G_REFCLK15625_KR: 0x3
+                                                         R_103125G_REFCLK15625_KR: 0x3
                                                          R_125G_REFCLK15625_SGMII: 0x0
-                                                         R_5G_REFCLK15625_QSGMII: 0x0
+                                                         R_5G_REFCLK15625_QSGMII:  0x0
                                                          R_625G_REFCLK15625_RXAUI: 0x0
-                                                         R_25G_REFCLK125: 0x0
-                                                         R_5G_REFCLK125: 0x0
-                                                         R_8G_REFCLK125: 0x3 */
+                                                         R_25G_REFCLK125:          0x0
+                                                         R_5G_REFCLK125:           0x0
+                                                         R_8G_REFCLK125:           0x3 */
 	uint64_t pcie                         : 1;  /**< Selects between RX terminations.
                                                          - 0: Differential termination
                                                          - 1: Termination between pad and SDS_VDDS.
                                                           Recommended settings:
-                                                          R_25G_REFCLK100: 0x1
-                                                          R_5G_REFCLK100: 0x1
-                                                          R_8G_REFCLK100: 0x0
-                                                          R_125G_REFCLK15625_KX: 0x0
+                                                          R_25G_REFCLK100:          0x1
+                                                          R_5G_REFCLK100:           0x1
+                                                          R_8G_REFCLK100:           0x0
+                                                          R_125G_REFCLK15625_KX:    0x0
                                                           R_3125G_REFCLK15625_XAUI: 0x0
-                                                          R_103215G_REFCLK15625_KR: 0x0
+                                                          R_103125G_REFCLK15625_KR: 0x0
                                                           R_125G_REFCLK15625_SGMII: 0x0
-                                                          R_5G_REFCLK15625_QSGMII: 0x0
+                                                          R_5G_REFCLK15625_QSGMII:  0x0
                                                           R_625G_REFCLK15625_RXAUI: 0x0
-                                                          R_25G_REFCLK125: 0x1
-                                                          R_5G_REFCLK125: 0x1
-                                                          R_8G_REFCLK125: 0x0 */
-	uint64_t tx_ldiv                      : 2;  /**< Configures clock divider used to determine the receive rate. Encoding is:
+                                                          R_25G_REFCLK125:          0x1
+                                                          R_5G_REFCLK125:           0x1
+                                                          R_8G_REFCLK125:           0x0 */
+	uint64_t tx_ldiv                      : 2;  /**< Configures clock divider used to determine the receive rate.
                                                          0x0 = full data rate.
                                                          0x1 = 1/2 data rate.
                                                          0x2 = 1/4 data rate.
                                                          0x3 = 1/8 data rate.
                                                          Recommended settings:
-                                                         R_25G_REFCLK100: 0x1
-                                                         R_5G_REFCLK100: 0x0
-                                                         R_8G_REFCLK100: 0x0
-                                                         R_125G_REFCLK15625_KX: 0x2
+                                                         R_25G_REFCLK100:          0x1
+                                                         R_5G_REFCLK100:           0x0
+                                                         R_8G_REFCLK100:           0x0
+                                                         R_125G_REFCLK15625_KX:    0x2
                                                          R_3125G_REFCLK15625_XAUI: 0x1
-                                                         R_103215G_REFCLK15625_KR: 0x0
+                                                         R_103125G_REFCLK15625_KR: 0x0
                                                          R_125G_REFCLK15625_SGMII: 0x2
-                                                         R_5G_REFCLK15625_QSGMII: 0x0
+                                                         R_5G_REFCLK15625_QSGMII:  0x0
                                                          R_625G_REFCLK15625_RXAUI: 0x0
-                                                         R_25G_REFCLK125: 0x1
-                                                         R_5G_REFCLK125: 0x0
-                                                         R_8G_REFCLK125: 0x0 */
-	uint64_t rx_ldiv                      : 2;  /**< Configures clock divider used to determine the receive rate. Encoding is:
+                                                         R_25G_REFCLK125:          0x1
+                                                         R_5G_REFCLK125:           0x0
+                                                         R_8G_REFCLK125:           0x0 */
+	uint64_t rx_ldiv                      : 2;  /**< Configures clock divider used to determine the receive rate.
                                                          0x0 = full data rate
                                                          0x1 = 1/2 data rate
                                                          0x2 = 1/4 data rate
                                                          0x3 = 1/8 data rate
                                                          Recommended settings:
-                                                         R_25G_REFCLK100: 0x1
-                                                         R_5G_REFCLK100: 0x0
-                                                         R_8G_REFCLK100: 0x0
-                                                         R_125G_REFCLK15625_KX: 0x2
+                                                         R_25G_REFCLK100:          0x1
+                                                         R_5G_REFCLK100:           0x0
+                                                         R_8G_REFCLK100:           0x0
+                                                         R_125G_REFCLK15625_KX:    0x2
                                                          R_3125G_REFCLK15625_XAUI: 0x1
-                                                         R_103215G_REFCLK15625_KR: 0x0
+                                                         R_103125G_REFCLK15625_KR: 0x0
                                                          R_125G_REFCLK15625_SGMII: 0x2
-                                                         R_5G_REFCLK15625_QSGMII: 0x0
+                                                         R_5G_REFCLK15625_QSGMII:  0x0
                                                          R_625G_REFCLK15625_RXAUI: 0x0
-                                                         R_25G_REFCLK125: 0x1
-                                                         R_5G_REFCLK125: 0x0
-                                                         R_8G_REFCLK125: 0x0 */
+                                                         R_25G_REFCLK125:          0x1
+                                                         R_5G_REFCLK125:           0x0
+                                                         R_8G_REFCLK125:           0x0 */
 	uint64_t srate                        : 3;  /**< Sample rate, used to generate strobe to effectively divide the clock down to a slower
-                                                         rate. Encoding is:
+                                                         rate.
                                                          0x0 = Full rate
                                                          0x1 = 1/2 data rate
                                                          0x2 = 1/4 data rate
                                                          0x3 = 1/8 data rate
                                                          0x4 = 1/16 data rate
                                                          else = Reserved.
-                                                         This field should always be set to zero (full rate). */
+                                                         This field should always be cleared to zero (full rate). */
 	uint64_t reserved_4_4                 : 1;
 	uint64_t tx_mode                      : 2;  /**< TX data width:
                                                          0x0 = 8-bit raw data (not supported).
@@ -2626,46 +2745,53 @@ typedef union cvmx_gserx_lanex_px_mode_0 cvmx_gserx_lanex_px_mode_0_t;
 /**
  * cvmx_gser#_lane#_p#_mode_1
  *
- * The Protocol selects the specific protocol register as enumerated by GSER_LMODE_E.
- *
+ * These are the RAW PCS per lane settings mode 1 registers. There is one register per
+ * lane (0..3) per GSER per GSER_LMODE_E (0..11). Only one entry is used at any given
+ * time in a given GSER lane - the one selected by the corresponding
+ * GSER(0..13)_LANE_MODE[LMODE].
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_px_mode_1 {
 	uint64_t u64;
 	struct cvmx_gserx_lanex_px_mode_1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t vma_fine_cfg_sel             : 1;  /**< Values at reset:
+	uint64_t vma_fine_cfg_sel             : 1;  /**< Recommended settings:
                                                          1 = Enabled. Fine step adaptation selected (10.3125 Gbps rate).
                                                          0 = Disabled. Coarse step adaptation selected (rates lower than 10.3125 Gbps). */
-	uint64_t vma_mm                       : 1;  /**< Manual DFE verses adaptive DFE mode. Recommended settings:
+	uint64_t vma_mm                       : 1;  /**< Manual DFE verses adaptive DFE mode.
+                                                         Recommended settings:
                                                          0 = Adaptive DFE (5 Gbps and higher)
                                                          1 = Manual DFE, fixed tap (3.125 Gbps and lower). */
-	uint64_t cdr_fgain                    : 4;  /**< CDR frequency gain. Values at reset:
-                                                         R_25G_REFCLK100: 0xA
-                                                         R_5G_REFCLK100: 0xA
-                                                         R_8G_REFCLK100: 0xB
-                                                         R_125G_REFCLK15625_KX: 0xC
+	uint64_t cdr_fgain                    : 4;  /**< CDR frequency gain.
+                                                         Recommended settings:
+                                                         R_25G_REFCLK100:          0xA
+                                                         R_5G_REFCLK100:           0xA
+                                                         R_8G_REFCLK100:           0xB
+                                                         R_125G_REFCLK15625_KX:    0xC
                                                          R_3125G_REFCLK15625_XAUI: 0xC
-                                                         R_103215G_REFCLK15625_KR: 0xA
+                                                         R_103125G_REFCLK15625_KR: 0xA
                                                          R_125G_REFCLK15625_SGMII: 0xC
-                                                         R_5G_REFCLK15625_QSGMII: 0xC
+                                                         R_5G_REFCLK15625_QSGMII:  0xC
                                                          R_625G_REFCLK15625_RXAUI: 0xA
-                                                         R_25G_REFCLK125: 0xA
-                                                         R_5G_REFCLK125: 0xA
-                                                         R_8G_REFCLK125: 0xB */
-	uint64_t ph_acc_adj                   : 10; /**< Phase accumulator adjust. Values at reset:
-                                                         R_25G_REFCLK100: 0x14
-                                                         R_5G_REFCLK100: 0x14
-                                                         R_8G_REFCLK100: 0x23
-                                                         R_125G_REFCLK15625_KX: 0x1E
+                                                         R_25G_REFCLK125:          0xA
+                                                         R_5G_REFCLK125:           0xA
+                                                         R_8G_REFCLK125:           0xB */
+	uint64_t ph_acc_adj                   : 10; /**< Phase accumulator adjust.
+                                                         Recommended settings:
+                                                         R_25G_REFCLK100:          0x14
+                                                         R_5G_REFCLK100:           0x14
+                                                         R_8G_REFCLK100:           0x23
+                                                         R_125G_REFCLK15625_KX:    0x1E
                                                          R_3125G_REFCLK15625_XAUI: 0x1E
-                                                         R_103215G_REFCLK15625_KR: 0xF
+                                                         R_103125G_REFCLK15625_KR: 0xF
                                                          R_125G_REFCLK15625_SGMII: 0x1E
-                                                         R_5G_REFCLK15625_QSGMII: 0x1E
+                                                         R_5G_REFCLK15625_QSGMII:  0x1E
                                                          R_625G_REFCLK15625_RXAUI: 0x14
-                                                         R_25G_REFCLK125: 0x14
-                                                         R_5G_REFCLK125: 0x14
-                                                         R_8G_REFCLK125: 0x23 */
+                                                         R_25G_REFCLK125:          0x14
+                                                         R_5G_REFCLK125:           0x14
+                                                         R_8G_REFCLK125:           0x23 */
 #else
 	uint64_t ph_acc_adj                   : 10;
 	uint64_t cdr_fgain                    : 4;
@@ -2682,7 +2808,8 @@ typedef union cvmx_gserx_lanex_px_mode_1 cvmx_gserx_lanex_px_mode_1_t;
  * cvmx_gser#_lane#_rx_ctle_ctrl
  *
  * These are the RAW PCS per-lane RX CTLE control registers.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_ctle_ctrl {
 	uint64_t u64;
@@ -2728,6 +2855,8 @@ typedef union cvmx_gserx_lanex_rx_ctle_ctrl cvmx_gserx_lanex_rx_ctle_ctrl_t;
  *
  * These are the RAW PCS per-lane RX precorrelation control registers. These registers are for
  * diagnostic use only.
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_precorr_ctrl {
 	uint64_t u64;
@@ -2756,6 +2885,9 @@ typedef union cvmx_gserx_lanex_rx_precorr_ctrl cvmx_gserx_lanex_rx_precorr_ctrl_
 
 /**
  * cvmx_gser#_lane#_rx_valbbd_ctrl_0
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_valbbd_ctrl_0 {
 	uint64_t u64;
@@ -2792,6 +2924,9 @@ typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_0 cvmx_gserx_lanex_rx_valbbd_ctrl_
 
 /**
  * cvmx_gser#_lane#_rx_valbbd_ctrl_1
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_valbbd_ctrl_1 {
 	uint64_t u64;
@@ -2836,6 +2971,9 @@ typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_1 cvmx_gserx_lanex_rx_valbbd_ctrl_
 
 /**
  * cvmx_gser#_lane#_rx_valbbd_ctrl_2
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_valbbd_ctrl_2 {
 	uint64_t u64;
@@ -2887,6 +3025,8 @@ typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_2 cvmx_gserx_lanex_rx_valbbd_ctrl_
  *
  * These are the RAW PCS per-lane RX VMA control registers. These registers are for diagnostic
  * use only.
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_vma_ctrl {
 	uint64_t u64;
@@ -2924,7 +3064,8 @@ typedef union cvmx_gserx_lanex_rx_vma_ctrl cvmx_gserx_lanex_rx_vma_ctrl_t;
  * cvmx_gser#_lane#_vma_coarse_ctrl_0
  *
  * These registers are for diagnostic use only.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_vma_coarse_ctrl_0 {
 	uint64_t u64;
@@ -2954,7 +3095,8 @@ typedef union cvmx_gserx_lanex_vma_coarse_ctrl_0 cvmx_gserx_lanex_vma_coarse_ctr
  * cvmx_gser#_lane#_vma_coarse_ctrl_1
  *
  * These registers are for diagnostic use only.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_vma_coarse_ctrl_1 {
 	uint64_t u64;
@@ -2979,7 +3121,8 @@ typedef union cvmx_gserx_lanex_vma_coarse_ctrl_1 cvmx_gserx_lanex_vma_coarse_ctr
  * cvmx_gser#_lane#_vma_coarse_ctrl_2
  *
  * These registers are for diagnostic use only.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_vma_coarse_ctrl_2 {
 	uint64_t u64;
@@ -3004,7 +3147,8 @@ typedef union cvmx_gserx_lanex_vma_coarse_ctrl_2 cvmx_gserx_lanex_vma_coarse_ctr
  * cvmx_gser#_lane#_vma_fine_ctrl_0
  *
  * These registers are for diagnostic use only.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_vma_fine_ctrl_0 {
 	uint64_t u64;
@@ -3044,7 +3188,8 @@ typedef union cvmx_gserx_lanex_vma_fine_ctrl_0 cvmx_gserx_lanex_vma_fine_ctrl_0_
  * cvmx_gser#_lane#_vma_fine_ctrl_1
  *
  * These registers are for diagnostic use only.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_vma_fine_ctrl_1 {
 	uint64_t u64;
@@ -3074,7 +3219,8 @@ typedef union cvmx_gserx_lanex_vma_fine_ctrl_1 cvmx_gserx_lanex_vma_fine_ctrl_1_
  * cvmx_gser#_lane#_vma_fine_ctrl_2
  *
  * These registers are for diagnostic use only.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_vma_fine_ctrl_2 {
 	uint64_t u64;
@@ -3103,6 +3249,9 @@ typedef union cvmx_gserx_lanex_vma_fine_ctrl_2 cvmx_gserx_lanex_vma_fine_ctrl_2_
 
 /**
  * cvmx_gser#_lane_lpbken
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lane_lpbken {
 	uint64_t u64;
@@ -3126,6 +3275,9 @@ typedef union cvmx_gserx_lane_lpbken cvmx_gserx_lane_lpbken_t;
 
 /**
  * cvmx_gser#_lane_mode
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lane_mode {
 	uint64_t u64;
@@ -3138,17 +3290,21 @@ union cvmx_gserx_lane_mode {
                                                          0x0: R_25G_REFCLK100
                                                          0x1: R_5G_REFCLK100
                                                          0x2: R_8G_REFCLK100
-                                                         0x3: R_125G_REFCLK15625_KX
+                                                         0x3: R_125G_REFCLK15625_KX (not supported)
                                                          0x4: R_3125G_REFCLK15625_XAUI
-                                                         0x5: R_103215G_REFCLK15625_KR
+                                                              For XAUI applications.
+                                                         0x5: R_103125G_REFCLK15625_KR
+                                                              For XFI, XLAUI, KR applications
                                                          0x6: R_125G_REFCLK15625_SGMII
-                                                         0x7: R_5G_REFCLK15625_QSGMII
+                                                              For SGMII applications
+                                                         0x7: R_5G_REFCLK15625_QSGMII (not supported)
                                                          0x8: R_625G_REFCLK15625_RXAUI
+                                                              For RXAUI, DXAUI applications
                                                          0x9: R_25G_REFCLK125
                                                          0xA: R_5G_REFCLK125
                                                          0xB: R_8G_REFCLK125
                                                          0xC - 0xF: reserved
-                                                         This register is not used for PCIE configurations. For non-OCI links, this registers
+                                                         This register is not used for PCIE configurations. For non-OCI links, this register
                                                          defaults to R_625G_REFCLK15625_RXAUI. For OCI links, the value is mapped at reset from the
                                                          GSER_SPD and the appropriate table updates are performed so the rate is obtained for the
                                                          particular reference clock.
@@ -3160,10 +3316,11 @@ union cvmx_gserx_lane_mode {
                                                          selected LMODE must be updated to reflect the reference clock speed. Refer to the register
                                                          description and index into the table using the rate and reference speed to obtain the
                                                          recommended values.
-                                                         Write GSER(0..13)_PLL_P(0..11)_MODE_0.
-                                                         Write GSER(0..13)_PLL_P(0..11)_MODE_1.
-                                                         Write GSER(0..13)_LANE(0..3)_P(0..11)_MODE_0.
-                                                         Write GSER(0..13)_LANE(0..3)_P(0..11)_MODE_1. */
+                                                          Write GSER(0..13)_PLL_P(Z)_MODE_0.
+                                                          Write GSER(0..13)_PLL_P(Z)_MODE_1.
+                                                          Write GSER(0..13)_LANE(0..3)_P(Z)_MODE_0.
+                                                          Write GSER(0..13)_LANE(0..3)_P(Z)_MODE_1.
+                                                         where Z equals LMODE. */
 #else
 	uint64_t lmode                        : 4;
 	uint64_t reserved_4_63                : 60;
@@ -3175,6 +3332,9 @@ typedef union cvmx_gserx_lane_mode cvmx_gserx_lane_mode_t;
 
 /**
  * cvmx_gser#_lane_poff
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lane_poff {
 	uint64_t u64;
@@ -3198,6 +3358,9 @@ typedef union cvmx_gserx_lane_poff cvmx_gserx_lane_poff_t;
 
 /**
  * cvmx_gser#_lane_srst
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lane_srst {
 	uint64_t u64;
@@ -3678,6 +3841,41 @@ union cvmx_gserx_phyx_idcode_lo {
 typedef union cvmx_gserx_phyx_idcode_lo cvmx_gserx_phyx_idcode_lo_t;
 
 /**
+ * cvmx_gser#_phy#_lane0_loopback
+ *
+ * PHY Lane 0 Loopback Control.
+ *
+ */
+union cvmx_gserx_phyx_lane0_loopback {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane0_loopback_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_8_63                : 56;
+	uint64_t ovrd_tx_lb                   : 1;  /**< Enables override of tx_lb_en pin. */
+	uint64_t tx_lb_en_reg                 : 1;  /**< Value of tx_lb_en pin when OVRD_TX_LB is enabled. */
+	uint64_t atb_vptx                     : 1;  /**< Places vptx0 on atb_s_p and gd on atb_s_m. */
+	uint64_t atb_vreg_tx                  : 1;  /**< Places vreg_tx on atb_s_p and gd on atb_s_m. */
+	uint64_t atb_vdccp                    : 1;  /**< Places vddc_m on atb_s_p. */
+	uint64_t atb_vdccm                    : 1;  /**< Places vdcc_m on atb_s_m. */
+	uint64_t reserved_1_1                 : 1;
+	uint64_t sel_pmix_clk                 : 1;  /**< Selects pmix_clk for Tx clock for ATE test mode. */
+#else
+	uint64_t sel_pmix_clk                 : 1;
+	uint64_t reserved_1_1                 : 1;
+	uint64_t atb_vdccm                    : 1;
+	uint64_t atb_vdccp                    : 1;
+	uint64_t atb_vreg_tx                  : 1;
+	uint64_t atb_vptx                     : 1;
+	uint64_t tx_lb_en_reg                 : 1;
+	uint64_t ovrd_tx_lb                   : 1;
+	uint64_t reserved_8_63                : 56;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane0_loopback_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane0_loopback cvmx_gserx_phyx_lane0_loopback_t;
+
+/**
  * cvmx_gser#_phy#_lane0_rx_lbert_ctl
  *
  * PHY LANE0 RX LBERT Control.
@@ -3741,6 +3939,53 @@ union cvmx_gserx_phyx_lane0_rx_lbert_err {
 typedef union cvmx_gserx_phyx_lane0_rx_lbert_err cvmx_gserx_phyx_lane0_rx_lbert_err_t;
 
 /**
+ * cvmx_gser#_phy#_lane0_rx_ovrd_in_lo
+ *
+ * PHY LANE0 TX Override Input Low
+ *
+ */
+union cvmx_gserx_phyx_lane0_rx_ovrd_in_lo {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane0_rx_ovrd_in_lo_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_14_63               : 50;
+	uint64_t rx_los_en_ovrd               : 1;  /**< Override enable for rx_los_en. */
+	uint64_t rx_los_en                    : 1;  /**< Override value for rx_los_en. */
+	uint64_t rx_term_en_ovrd              : 1;  /**< Override enable for rx_term_en. */
+	uint64_t rx_term_en                   : 1;  /**< Override value for rx_term_en. */
+	uint64_t rx_bit_shift_ovrd            : 1;  /**< Override enable for rx_bit_shift. */
+	uint64_t rx_bit_shift_en              : 1;  /**< Override value for rx_bit_shift. */
+	uint64_t rx_align_en_ovrd             : 1;  /**< Override enable for rx_align_en. */
+	uint64_t rx_align_en                  : 1;  /**< Override value for rx_align_en. */
+	uint64_t rx_data_en_ovrd              : 1;  /**< Override enable for rx_data_en. */
+	uint64_t rx_data_en                   : 1;  /**< Override value for rx_data_en. */
+	uint64_t rx_pll_en_ovrd               : 1;  /**< Override enable for rx_pll_en. */
+	uint64_t rx_pll_en                    : 1;  /**< Override value for rx_pll_en. */
+	uint64_t rx_invert_ovrd               : 1;  /**< Override enable for rx_invert. */
+	uint64_t rx_invert                    : 1;  /**< Override value for rx_invert. */
+#else
+	uint64_t rx_invert                    : 1;
+	uint64_t rx_invert_ovrd               : 1;
+	uint64_t rx_pll_en                    : 1;
+	uint64_t rx_pll_en_ovrd               : 1;
+	uint64_t rx_data_en                   : 1;
+	uint64_t rx_data_en_ovrd              : 1;
+	uint64_t rx_align_en                  : 1;
+	uint64_t rx_align_en_ovrd             : 1;
+	uint64_t rx_bit_shift_en              : 1;
+	uint64_t rx_bit_shift_ovrd            : 1;
+	uint64_t rx_term_en                   : 1;
+	uint64_t rx_term_en_ovrd              : 1;
+	uint64_t rx_los_en                    : 1;
+	uint64_t rx_los_en_ovrd               : 1;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane0_rx_ovrd_in_lo_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane0_rx_ovrd_in_lo cvmx_gserx_phyx_lane0_rx_ovrd_in_lo_t;
+
+/**
  * cvmx_gser#_phy#_lane0_tx_lbert_ctl
  *
  * PHY LANE0 TX LBERT Control.
@@ -3778,6 +4023,86 @@ union cvmx_gserx_phyx_lane0_tx_lbert_ctl {
 typedef union cvmx_gserx_phyx_lane0_tx_lbert_ctl cvmx_gserx_phyx_lane0_tx_lbert_ctl_t;
 
 /**
+ * cvmx_gser#_phy#_lane0_tx_ovrd_in_hi
+ *
+ * PHY LANE0 TX Override Input High
+ *
+ */
+union cvmx_gserx_phyx_lane0_tx_ovrd_in_hi {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane0_tx_ovrd_in_hi_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_10_63               : 54;
+	uint64_t tx_vboost_en_ovrd            : 1;  /**< Override enable for tx_vboost_en. */
+	uint64_t tx_vboost_en                 : 1;  /**< Override value for tx_vboost_en. */
+	uint64_t tx_reset_ovrd                : 1;  /**< Override enable for tx_reset. */
+	uint64_t tx_reset                     : 1;  /**< Override value for tx_reset. */
+	uint64_t tx_nyquist_data              : 1;  /**< Overrides incoming data to nyquist. */
+	uint64_t tx_clk_out_en_ovrd           : 1;  /**< Override enable for tx_clk_out_en. */
+	uint64_t tx_clk_out_en                : 1;  /**< Override value for tx_clk_out_en. */
+	uint64_t tx_rate_ovrd                 : 1;  /**< Override enable for tx lane rate. */
+	uint64_t tx_rate                      : 2;  /**< Override value for tx_rate. */
+#else
+	uint64_t tx_rate                      : 2;
+	uint64_t tx_rate_ovrd                 : 1;
+	uint64_t tx_clk_out_en                : 1;
+	uint64_t tx_clk_out_en_ovrd           : 1;
+	uint64_t tx_nyquist_data              : 1;
+	uint64_t tx_reset                     : 1;
+	uint64_t tx_reset_ovrd                : 1;
+	uint64_t tx_vboost_en                 : 1;
+	uint64_t tx_vboost_en_ovrd            : 1;
+	uint64_t reserved_10_63               : 54;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane0_tx_ovrd_in_hi_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane0_tx_ovrd_in_hi cvmx_gserx_phyx_lane0_tx_ovrd_in_hi_t;
+
+/**
+ * cvmx_gser#_phy#_lane0_tx_ovrd_in_lo
+ *
+ * PHY LANE0 TX Override Input Low
+ *
+ */
+union cvmx_gserx_phyx_lane0_tx_ovrd_in_lo {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane0_tx_ovrd_in_lo_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t tx_beacon_en_ovrd            : 1;  /**< Override enable for tx_beacon_en. */
+	uint64_t tx_beacon_en                 : 1;  /**< Override value for tx_beacon_en. */
+	uint64_t tx_cm_en_ovrd                : 1;  /**< Override enable for tx_cm_en. */
+	uint64_t tx_cm_en                     : 1;  /**< Override value for tx_cm_en. */
+	uint64_t tx_en_ovrd                   : 1;  /**< Override enable for tx_en. */
+	uint64_t tx_en                        : 1;  /**< Override value for tx_en. */
+	uint64_t tx_data_en_ovrd              : 1;  /**< Override enable for tx_data_en. */
+	uint64_t tx_data_en                   : 1;  /**< Override value for tx_data_en. */
+	uint64_t tx_invert_ovrd               : 1;  /**< Override enable for tx_invert. */
+	uint64_t tx_invert                    : 1;  /**< Override value for tx_invert. */
+	uint64_t loopbk_en_ovrd               : 1;  /**< Override enable for loopbk_en. */
+	uint64_t loopbk_en                    : 1;  /**< Override value for loopbk_en. */
+#else
+	uint64_t loopbk_en                    : 1;
+	uint64_t loopbk_en_ovrd               : 1;
+	uint64_t tx_invert                    : 1;
+	uint64_t tx_invert_ovrd               : 1;
+	uint64_t tx_data_en                   : 1;
+	uint64_t tx_data_en_ovrd              : 1;
+	uint64_t tx_en                        : 1;
+	uint64_t tx_en_ovrd                   : 1;
+	uint64_t tx_cm_en                     : 1;
+	uint64_t tx_cm_en_ovrd                : 1;
+	uint64_t tx_beacon_en                 : 1;
+	uint64_t tx_beacon_en_ovrd            : 1;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane0_tx_ovrd_in_lo_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane0_tx_ovrd_in_lo cvmx_gserx_phyx_lane0_tx_ovrd_in_lo_t;
+
+/**
  * cvmx_gser#_phy#_lane0_txdebug
  *
  * PHY LANE0 TX DEBUG.
@@ -3803,6 +4128,41 @@ union cvmx_gserx_phyx_lane0_txdebug {
 typedef union cvmx_gserx_phyx_lane0_txdebug cvmx_gserx_phyx_lane0_txdebug_t;
 
 /**
+ * cvmx_gser#_phy#_lane1_loopback
+ *
+ * PHY Lane 1 Loopback Control.
+ *
+ */
+union cvmx_gserx_phyx_lane1_loopback {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane1_loopback_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_8_63                : 56;
+	uint64_t ovrd_tx_lb                   : 1;  /**< Enables override of tx_lb_en pin. */
+	uint64_t tx_lb_en_reg                 : 1;  /**< Value of tx_lb_en pin when OVRD_TX_LB is enabled. */
+	uint64_t atb_vptx                     : 1;  /**< Places vptx0 on atb_s_p and gd on atb_s_m. */
+	uint64_t atb_vreg_tx                  : 1;  /**< Places vreg_tx on atb_s_p and gd on atb_s_m. */
+	uint64_t atb_vdccp                    : 1;  /**< Places vddc_m on atb_s_p. */
+	uint64_t atb_vdccm                    : 1;  /**< Places vdcc_m on atb_s_m. */
+	uint64_t reserved_1_1                 : 1;
+	uint64_t sel_pmix_clk                 : 1;  /**< Selects pmix_clk for Tx clock for ATE test mode. */
+#else
+	uint64_t sel_pmix_clk                 : 1;
+	uint64_t reserved_1_1                 : 1;
+	uint64_t atb_vdccm                    : 1;
+	uint64_t atb_vdccp                    : 1;
+	uint64_t atb_vreg_tx                  : 1;
+	uint64_t atb_vptx                     : 1;
+	uint64_t tx_lb_en_reg                 : 1;
+	uint64_t ovrd_tx_lb                   : 1;
+	uint64_t reserved_8_63                : 56;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane1_loopback_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane1_loopback cvmx_gserx_phyx_lane1_loopback_t;
+
+/**
  * cvmx_gser#_phy#_lane1_rx_lbert_ctl
  *
  * PHY LANE1 TX LBERT Control.
@@ -3812,12 +4172,12 @@ union cvmx_gserx_phyx_lane1_rx_lbert_ctl {
 	uint64_t u64;
 	struct cvmx_gserx_phyx_lane1_rx_lbert_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_4_63                : 60;
+	uint64_t reserved_5_63                : 59;
 	uint64_t sync                         : 1;  /**< Synchronizes pattern matcher with incoming data.  A write of a 1
                                                          to this bit resets the error counter and starts a synchronization of
                                                          the PM.  Once this bit is set, there is no need to write the field back
                                                          to a zero. */
-	uint64_t mode                         : 3;  /**< Pattern to match.  When changing modes, the field must be set to zero
+	uint64_t mode                         : 4;  /**< Pattern to match.  When changing modes, the field must be set to zero
                                                           first.  This field should match what was configured for the TX LBERT
                                                           Control register.
                                                          - 0: disabled
@@ -3827,11 +4187,12 @@ union cvmx_gserx_phyx_lane1_rx_lbert_ctl {
                                                          - 4: lfsr7      X^7 + X^6 + 1
                                                          - 5: d[n] = d[n-10]
                                                          - 6: d[n] = !d[n-10]
-                                                         - 7: d[n] = !d[n-20] */
+                                                         - 7: d[n] = !d[n-20]
+                                                          - 15-8: Reserved. */
 #else
-	uint64_t mode                         : 3;
+	uint64_t mode                         : 4;
 	uint64_t sync                         : 1;
-	uint64_t reserved_4_63                : 60;
+	uint64_t reserved_5_63                : 59;
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_rx_lbert_ctl_s cn70xx;
@@ -3865,6 +4226,53 @@ union cvmx_gserx_phyx_lane1_rx_lbert_err {
 typedef union cvmx_gserx_phyx_lane1_rx_lbert_err cvmx_gserx_phyx_lane1_rx_lbert_err_t;
 
 /**
+ * cvmx_gser#_phy#_lane1_rx_ovrd_in_lo
+ *
+ * PHY LANE1 TX Override Input Low
+ *
+ */
+union cvmx_gserx_phyx_lane1_rx_ovrd_in_lo {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane1_rx_ovrd_in_lo_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_14_63               : 50;
+	uint64_t rx_los_en_ovrd               : 1;  /**< Override enable for rx_los_en. */
+	uint64_t rx_los_en                    : 1;  /**< Override value for rx_los_en. */
+	uint64_t rx_term_en_ovrd              : 1;  /**< Override enable for rx_term_en. */
+	uint64_t rx_term_en                   : 1;  /**< Override value for rx_term_en. */
+	uint64_t rx_bit_shift_ovrd            : 1;  /**< Override enable for rx_bit_shift. */
+	uint64_t rx_bit_shift_en              : 1;  /**< Override value for rx_bit_shift. */
+	uint64_t rx_align_en_ovrd             : 1;  /**< Override enable for rx_align_en. */
+	uint64_t rx_align_en                  : 1;  /**< Override value for rx_align_en. */
+	uint64_t rx_data_en_ovrd              : 1;  /**< Override enable for rx_data_en. */
+	uint64_t rx_data_en                   : 1;  /**< Override value for rx_data_en. */
+	uint64_t rx_pll_en_ovrd               : 1;  /**< Override enable for rx_pll_en. */
+	uint64_t rx_pll_en                    : 1;  /**< Override value for rx_pll_en. */
+	uint64_t rx_invert_ovrd               : 1;  /**< Override enable for rx_invert. */
+	uint64_t rx_invert                    : 1;  /**< Override value for rx_invert. */
+#else
+	uint64_t rx_invert                    : 1;
+	uint64_t rx_invert_ovrd               : 1;
+	uint64_t rx_pll_en                    : 1;
+	uint64_t rx_pll_en_ovrd               : 1;
+	uint64_t rx_data_en                   : 1;
+	uint64_t rx_data_en_ovrd              : 1;
+	uint64_t rx_align_en                  : 1;
+	uint64_t rx_align_en_ovrd             : 1;
+	uint64_t rx_bit_shift_en              : 1;
+	uint64_t rx_bit_shift_ovrd            : 1;
+	uint64_t rx_term_en                   : 1;
+	uint64_t rx_term_en_ovrd              : 1;
+	uint64_t rx_los_en                    : 1;
+	uint64_t rx_los_en_ovrd               : 1;
+	uint64_t reserved_14_63               : 50;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane1_rx_ovrd_in_lo_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane1_rx_ovrd_in_lo cvmx_gserx_phyx_lane1_rx_ovrd_in_lo_t;
+
+/**
  * cvmx_gser#_phy#_lane1_tx_lbert_ctl
  *
  * PHY LANE1 RX LBERT Control.
@@ -3902,6 +4310,86 @@ union cvmx_gserx_phyx_lane1_tx_lbert_ctl {
 typedef union cvmx_gserx_phyx_lane1_tx_lbert_ctl cvmx_gserx_phyx_lane1_tx_lbert_ctl_t;
 
 /**
+ * cvmx_gser#_phy#_lane1_tx_ovrd_in_hi
+ *
+ * PHY LANE1 TX Override Input High
+ *
+ */
+union cvmx_gserx_phyx_lane1_tx_ovrd_in_hi {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane1_tx_ovrd_in_hi_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_10_63               : 54;
+	uint64_t tx_vboost_en_ovrd            : 1;  /**< Override enable for tx_vboost_en. */
+	uint64_t tx_vboost_en                 : 1;  /**< Override value for tx_vboost_en. */
+	uint64_t tx_reset_ovrd                : 1;  /**< Override enable for tx_reset. */
+	uint64_t tx_reset                     : 1;  /**< Override value for tx_reset. */
+	uint64_t tx_nyquist_data              : 1;  /**< Overrides incoming data to nyquist. */
+	uint64_t tx_clk_out_en_ovrd           : 1;  /**< Override enable for tx_clk_out_en. */
+	uint64_t tx_clk_out_en                : 1;  /**< Override value for tx_clk_out_en. */
+	uint64_t tx_rate_ovrd                 : 1;  /**< Override enable for tx lane rate. */
+	uint64_t tx_rate                      : 2;  /**< Override value for tx_rate. */
+#else
+	uint64_t tx_rate                      : 2;
+	uint64_t tx_rate_ovrd                 : 1;
+	uint64_t tx_clk_out_en                : 1;
+	uint64_t tx_clk_out_en_ovrd           : 1;
+	uint64_t tx_nyquist_data              : 1;
+	uint64_t tx_reset                     : 1;
+	uint64_t tx_reset_ovrd                : 1;
+	uint64_t tx_vboost_en                 : 1;
+	uint64_t tx_vboost_en_ovrd            : 1;
+	uint64_t reserved_10_63               : 54;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane1_tx_ovrd_in_hi_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane1_tx_ovrd_in_hi cvmx_gserx_phyx_lane1_tx_ovrd_in_hi_t;
+
+/**
+ * cvmx_gser#_phy#_lane1_tx_ovrd_in_lo
+ *
+ * PHY LANE1 TX Override Input Low
+ *
+ */
+union cvmx_gserx_phyx_lane1_tx_ovrd_in_lo {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_lane1_tx_ovrd_in_lo_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t tx_beacon_en_ovrd            : 1;  /**< Override enable for tx_beacon_en. */
+	uint64_t tx_beacon_en                 : 1;  /**< Override value for tx_beacon_en. */
+	uint64_t tx_cm_en_ovrd                : 1;  /**< Override enable for tx_cm_en. */
+	uint64_t tx_cm_en                     : 1;  /**< Override value for tx_cm_en. */
+	uint64_t tx_en_ovrd                   : 1;  /**< Override enable for tx_en. */
+	uint64_t tx_en                        : 1;  /**< Override value for tx_en. */
+	uint64_t tx_data_en_ovrd              : 1;  /**< Override enable for tx_data_en. */
+	uint64_t tx_data_en                   : 1;  /**< Override value for tx_data_en. */
+	uint64_t tx_invert_ovrd               : 1;  /**< Override enable for tx_invert. */
+	uint64_t tx_invert                    : 1;  /**< Override value for tx_invert. */
+	uint64_t loopbk_en_ovrd               : 1;  /**< Override enable for loopbk_en. */
+	uint64_t loopbk_en                    : 1;  /**< Override value for loopbk_en. */
+#else
+	uint64_t loopbk_en                    : 1;
+	uint64_t loopbk_en_ovrd               : 1;
+	uint64_t tx_invert                    : 1;
+	uint64_t tx_invert_ovrd               : 1;
+	uint64_t tx_data_en                   : 1;
+	uint64_t tx_data_en_ovrd              : 1;
+	uint64_t tx_en                        : 1;
+	uint64_t tx_en_ovrd                   : 1;
+	uint64_t tx_cm_en                     : 1;
+	uint64_t tx_cm_en_ovrd                : 1;
+	uint64_t tx_beacon_en                 : 1;
+	uint64_t tx_beacon_en_ovrd            : 1;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_lane1_tx_ovrd_in_lo_s cn70xx;
+};
+typedef union cvmx_gserx_phyx_lane1_tx_ovrd_in_lo cvmx_gserx_phyx_lane1_tx_ovrd_in_lo_t;
+
+/**
  * cvmx_gser#_phy#_lane1_txdebug
  *
  * PHY LANE1 TX DEBUG.
@@ -3927,10 +4415,60 @@ union cvmx_gserx_phyx_lane1_txdebug {
 typedef union cvmx_gserx_phyx_lane1_txdebug cvmx_gserx_phyx_lane1_txdebug_t;
 
 /**
+ * cvmx_gser#_phy#_ovrd_in_lo
+ *
+ * PHY Overide Input Low Register.
+ *
+ */
+union cvmx_gserx_phyx_ovrd_in_lo {
+	uint64_t u64;
+	struct cvmx_gserx_phyx_ovrd_in_lo_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t res_ack_in_ovrd              : 1;  /**< Overide enable for RES_ACK_IN input.
+                                                         It is not expected SW will need to set this bit. */
+	uint64_t res_ack_in                   : 1;  /**< Overide value for RES_ACK_IN input.
+                                                         It is not expected SW will need to set this bit. */
+	uint64_t res_req_in_ovrd              : 1;  /**< Overide enable for RES_REW_IN input.
+                                                         It is not expected SW will need to set this bit. */
+	uint64_t res_req_in                   : 1;  /**< Overide value for RES_REQ_IN input.
+                                                         It is not expected SW will need to set this bit. */
+	uint64_t rtune_req_ovrd               : 1;  /**< Overide enable for RTUNE_REQ input.
+                                                         It is not expected SW will need to set this bit. */
+	uint64_t rtune_req                    : 1;  /**< Overide value for RTUNE_REQ input.
+                                                         It is not expected SW will need to set this bit. */
+	uint64_t mpll_multiplier_ovrd         : 1;  /**< Overide enable for MPLL_MULTIPLIER.
+                                                         It is not expected SW will need to set this bit. */
+	uint64_t mpll_multiplier              : 7;  /**< Overide value for MPLL_MULTIPLIER inputs.
+                                                         It is not expected SW will need to set these bits. */
+	uint64_t mpll_en_ovrd                 : 1;  /**< Overide enable for MPLL_EN input.
+                                                         For EP Mode PEMs, SW should set this bit after reset. */
+	uint64_t mpll_en                      : 1;  /**< Overide value for MPLL_EN input.
+                                                         For EP Mode PEMs, SW should set this bit after reset. */
+#else
+	uint64_t mpll_en                      : 1;
+	uint64_t mpll_en_ovrd                 : 1;
+	uint64_t mpll_multiplier              : 7;
+	uint64_t mpll_multiplier_ovrd         : 1;
+	uint64_t rtune_req                    : 1;
+	uint64_t rtune_req_ovrd               : 1;
+	uint64_t res_req_in                   : 1;
+	uint64_t res_req_in_ovrd              : 1;
+	uint64_t res_ack_in                   : 1;
+	uint64_t res_ack_in_ovrd              : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_phyx_ovrd_in_lo_s   cn70xx;
+};
+typedef union cvmx_gserx_phyx_ovrd_in_lo cvmx_gserx_phyx_ovrd_in_lo_t;
+
+/**
  * cvmx_gser#_phy_ctl
  *
  * This register contains general PHY/PLL control of the RAW PCS.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_phy_ctl {
 	uint64_t u64;
@@ -3938,9 +4476,9 @@ union cvmx_gserx_phy_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
 	uint64_t phy_reset                    : 1;  /**< When asserted, the PHY is held in reset. This bit is initialized as follows:
-                                                         0 (not reset): Bootable PCIe, or OCI when GSER(0..13)_SPD[SPD] comes up in a bootable
+                                                         0 (not reset): Bootable PCIe, or OCI when GSER(8..13)_SPD[SPD] comes up in a bootable
                                                          mode.
-                                                         1 (reset): Non-bootable PCIe, BGX/ILK, or OCI when GSER(0..13)_SPD[SPD] comes up in
+                                                         1 (reset): Non-bootable PCIe, BGX/ILK, or OCI when GSER(8..13)_SPD[SPD] comes up in
                                                          SW_MODE. */
 	uint64_t phy_pd                       : 1;  /**< When asserted, the PHY is powered down. */
 #else
@@ -3962,7 +4500,8 @@ union cvmx_gserx_pipe_lpbk {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
 	uint64_t pcie_lpbk                    : 1;  /**< For links that are in PCIE mode, places the PHY in serial loopback mode, where the
-                                                         QLMn_TXN/QLMn_TXP data are looped back to the QLMn_RXN/QLMn_RXP. */
+                                                         QLMn_TXN/QLMn_TXP data are looped back to the QLMn_RXN/QLMn_RXP.
+                                                         This register has no meaning for links that don't support PCIe i.e. GSER(5..13). */
 #else
 	uint64_t pcie_lpbk                    : 1;
 	uint64_t reserved_1_63                : 63;
@@ -3975,48 +4514,48 @@ typedef union cvmx_gserx_pipe_lpbk cvmx_gserx_pipe_lpbk_t;
 /**
  * cvmx_gser#_pll_p#_mode_0
  *
- * These are the RAW PCS PLL global settings mode 0 registers. Global registers are shared across
- * the entire PCS. The Protocol selects the specific protocol register as enumerated by
- * GSER_LMODE_E.
+ * These are the RAW PCS PLL global settings mode 0 registers. There is one register per
+ * GSER per GSER_LMODE_E (0..11). Only one entry is used at any given time in a given GSER -
+ * the one selected by the corresponding GSER(0..13)_LANE_MODE[LMODE].
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during subsequent chip warm or
+ * soft resets.
  */
 union cvmx_gserx_pll_px_mode_0 {
 	uint64_t u64;
 	struct cvmx_gserx_pll_px_mode_0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t pll_icp                      : 4;  /**< PLL charge pump enable. This field must be set appropriately if running a
-                                                         GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock. A 'NS' indicates that the
-                                                         rate is not supported at the specified reference clock. Recommended settings:
-                                                                         100Mhz          125Mhz          156.25Mhz
-                                                         1.25G:          0x1             0x1             0x1
-                                                         2.5G:           0x4             0x3             0x3
-                                                         3.125G:         NS              0x1             0x1
-                                                         5.0G:           0x4             0x3             0x3
-                                                         6.25G:          NS              0x1             0x1
-                                                         8.0G:           0x3             0x2             NS
-                                                         10.3215G:       NS              NS              0x1 */
-	uint64_t pll_rloop                    : 3;  /**< Loop resistor tuning. This field must be set appropriately if running a
-                                                         GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock. A 'NS' indicates that the
-                                                         rate is not supported at the specified reference clock. Recommended settings:
-                                                         1.25G: 0x3
-                                                         2.5G: 0x3
-                                                         3.125G: 0x3
-                                                         5.0G: 0x3
-                                                         6.25G: 0x3
-                                                         8.0G: 0x5
-                                                         10.3215G: 0x5 */
+	uint64_t pll_icp                      : 4;  /**< PLL charge pump enable.
+                                                         Recommended settings, which is based on the reference clock speed:
+                                                                  100MHz 125MHz 156.25MHz
+                                                         1.25G:    0x1    0x1    0x1
+                                                         2.5G:     0x4    0x3    0x3
+                                                         3.125G:   NS     0x1    0x1
+                                                         5.0G:     0x4    0x3    0x3
+                                                         6.25G:    NS     0x1    0x1
+                                                         8.0G:     0x3    0x2    NS
+                                                         10.3125G: NS     NS     0x1
+                                                         A 'NS' indicates that the rate is not supported at the specified reference clock. */
+	uint64_t pll_rloop                    : 3;  /**< Loop resistor tuning.
+                                                         Recommended settings:
+                                                         1.25G:    0x3
+                                                         2.5G:     0x3
+                                                         3.125G:   0x3
+                                                         5.0G:     0x3
+                                                         6.25G:    0x3
+                                                         8.0G:     0x5
+                                                         10.3125G: 0x5 */
 	uint64_t pll_pcs_div                  : 9;  /**< The divider that generates PCS_MAC_TX_CLK. The frequency of the clock is (pll_frequency /
-                                                         PLL_PCS_DIV). This field must be set appropriately if running a
-                                                         GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock or doesn't default to a
-                                                         20-bit RX/TX data path. A 'NS' indicates that the rate is not supported at the specified
-                                                         reference clock. Recommended settings:
-                                                         1.25G: 0x28
-                                                         2.5G: 0x5
-                                                         3.125G: 0x24
-                                                         5.0G: 0xA
-                                                         6.25G: 0xA
-                                                         8.0G: 0xA
-                                                         10.3215G: 0x24 */
+                                                         PLL_PCS_DIV).
+                                                         Recommended settings:
+                                                         1.25G:    0x28
+                                                         2.5G:     0x5
+                                                         3.125G:   0x24
+                                                         5.0G:     0xA
+                                                         6.25G:    0xA
+                                                         8.0G:     0xA
+                                                         10.3125G: 0x24 */
 #else
 	uint64_t pll_pcs_div                  : 9;
 	uint64_t pll_rloop                    : 3;
@@ -4031,55 +4570,58 @@ typedef union cvmx_gserx_pll_px_mode_0 cvmx_gserx_pll_px_mode_0_t;
 /**
  * cvmx_gser#_pll_p#_mode_1
  *
- * Global registers are shared across the entire PCS. The Protocol selects the specific protocol
- * register as enumerated by GSER_LMODE_E.
+ * These are the RAW PCS PLL global settings mode 1 registers. There is one register per
+ * GSER per GSER_LMODE_E (0..11). Only one entry is used at any given time in a given GSER -
+ * the one selected by the corresponding GSER(0..13)_LANE_MODE[LMODE].
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in this register do not change during subsequent chip warm or
+ * soft resets.
  */
 union cvmx_gserx_pll_px_mode_1 {
 	uint64_t u64;
 	struct cvmx_gserx_pll_px_mode_1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t pll_16p5en                   : 1;  /**< Enable for the DIV 16.5 divided down clock. This field must be set appropriately if
-                                                         running a GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock. A 'NS'
-                                                         indicates that the rate is not supported at the specified reference clock. Recommended
-                                                         settings:
-                                                                         100Mhz          125Mhz          156.25Mhz
-                                                         1.25G:          0x1             0x1             0x1
-                                                         2.5G:           0x0             0x0             0x0
-                                                         3.125G:         NS              0x1             0x1
-                                                         5.0G:           0x0             0x0             0x0
-                                                         6.25G:          NS              0x0             0x0
-                                                         8.0G:           0x0             0x0             NS
-                                                         10.3215G:       NS              NS              0x1 */
-	uint64_t pll_cpadj                    : 2;  /**< PLL charge adjust. This field must be set appropriately if running a
-                                                         GSER(0..13)_LANE_MODE[LMODE] with a non-default reference clock. A 'NS' indicates that the
-                                                         rate is not supported at the specified reference clock. Recommended settings:
-                                                                         100Mhz          125Mhz          156.25Mhz
-                                                         1.25G:          0x2             0x2             0x3
-                                                         2.5G:           0x2             0x1             0x2
-                                                         3.125G:         NS              0x2             0x2
-                                                         5.0G:           0x2             0x1             0x2
-                                                         6.25G:          NS              0x2             0x2
-                                                         8.0G:           0x2             0x1             NS
-                                                         10.3215G:       NS              NS              0x2 */
-	uint64_t pll_pcie3en                  : 1;  /**< Enable PCIE3 mode. Recommended settings:
+	uint64_t pll_16p5en                   : 1;  /**< Enable for the DIV 16.5 divided down clock.
+                                                         Recommended settings, based on the reference clock speed:
+                                                                  100MHz 125MHz 156.25MHz
+                                                         1.25G:    0x1    0x1     0x1
+                                                         2.5G:     0x0    0x0     0x0
+                                                         3.125G:   NS     0x1     0x1
+                                                         5.0G:     0x0    0x0     0x0
+                                                         6.25G:    NS     0x0     0x0
+                                                         8.0G:     0x0    0x0     NS
+                                                         10.3125G: NS     NS      0x1
+                                                         A 'NS' indicates that the rate is not supported at the specified reference clock. */
+	uint64_t pll_cpadj                    : 2;  /**< PLL charge adjust.
+                                                         Recommended settings, based on the reference clock speed:
+                                                                   100MHz 125MHz 156.25MHz
+                                                         1.25G:     0x2     0x2    0x3
+                                                         2.5G:      0x2     0x1    0x2
+                                                         3.125G:    NS      0x2    0x2
+                                                         5.0G:      0x2     0x1    0x2
+                                                         6.25G:     NS      0x2    0x2
+                                                         8.0G:      0x2     0x1    NS
+                                                         10.3125G:  NS      NS     0x2
+                                                         A 'NS' indicates that the rate is not supported at the specified reference clock. */
+	uint64_t pll_pcie3en                  : 1;  /**< Enable PCIE3 mode.
+                                                         Recommended settings:
                                                          0 = Any rate other than 8 Gbps.
                                                          1 = Rate is equal to 8 Gbps. */
 	uint64_t pll_opr                      : 1;  /**< PLL op range:
                                                          0 = Use Ring Oscillator VCO. Recommended for rates 6.25 Gbps and lower.
                                                          1 = Use LC-tank VCO. Recommended for rates 8 Gbps and higher. */
-	uint64_t pll_div                      : 9;  /**< PLL divider in feedback path which sets the PLL frequency. This field must be set
-                                                         appropriately if running a GSER(0..13)_LANE_MODE[LMODE] with a non-default reference
-                                                         clock. A 'NS' indicates that the rate is not supported at the specified reference clock.
+	uint64_t pll_div                      : 9;  /**< PLL divider in feedback path which sets the PLL frequency.
                                                          Recommended settings:
-                                                                         100Mhz          125Mhz          156.25Mhz
-                                                         1.25G:          0x19            0x14            0x10
-                                                         2.5G:           0x19            0x14            0x10
-                                                         3.125G:         NS              0x19            0xa
-                                                         5.0G:           0x19            0x14            0x10
-                                                         6.25G:          NS              0x19            0x14
-                                                         8.0G:           0x28            0x20            NS
-                                                         10.3215G:       NS              NS              0x21 */
+                                                                  100MHz 125MHz 156.25MHz
+                                                         1.25G:    0x19   0x14    0x10
+                                                         2.5G:     0x19   0x14    0x10
+                                                         3.125G:   NS     0x19    0x14
+                                                         5.0G:     0x19   0x14    0x10
+                                                         6.25G:    NS     0x19    0x14
+                                                         8.0G:     0x28   0x20    NS
+                                                         10.3125G: NS     NS      0x21
+                                                         A 'NS' indicates that the rate is not supported at the specified reference clock. */
 #else
 	uint64_t pll_div                      : 9;
 	uint64_t pll_opr                      : 1;
@@ -4136,7 +4678,8 @@ typedef union cvmx_gserx_qlm_stat cvmx_gserx_qlm_stat_t;
  * cvmx_gser#_refclk_sel
  *
  * This register selects the reference clock.
- *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_refclk_sel {
 	uint64_t u64;
@@ -4165,6 +4708,9 @@ typedef union cvmx_gserx_refclk_sel cvmx_gserx_refclk_sel_t;
 
 /**
  * cvmx_gser#_rx_coast
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_rx_coast {
 	uint64_t u64;
@@ -4192,6 +4738,9 @@ typedef union cvmx_gserx_rx_coast cvmx_gserx_rx_coast_t;
 
 /**
  * cvmx_gser#_rx_eie_deten
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_rx_eie_deten {
 	uint64_t u64;
@@ -4273,19 +4822,20 @@ union cvmx_gserx_rx_eie_filter {
 	uint64_t eii_filt                     : 16; /**< The GSER uses electrical idle inference to determine when a RX lane has reentered
                                                          electrical IDLE (EI). The PHY electrical IDLE exit detection supports a minimum pulse
                                                          width of 400ps, therefore configurations that run faster than 2.5G can indicate EI when
-                                                         the serial lines are still driven. For rates faster than 2.5G, it takes 16000 UI of
-                                                         consecutive deasserted GSER(0..13)_RX_EIE_DETSTS[EIESTS] for the GSER to infer EI and
-                                                         begin invalidating RX data. In the event of electrical IDLE inference, the following
-                                                         happens:
-                                                         GSER(0..13)_RX_EIE_DETSTS[CDRLOCK]<lane> is zeroed
-                                                         GSER(0..13)_RX_EIE_DETSTS[EIELTCH]<lane> is zeroed
-                                                         GSER(0..13)_RX_EIE_DETSTS[EIESTS]<lane> is zeroed
-                                                         GSER(0..13)_RX_COAST[COAST]<lane> is asserted to prevent the CDR from trying to lock on
+                                                         the serial lines are still driven. For rates faster than 2.5G, it takes 16K * 8 UI of
+                                                         consecutive deasserted GSER(0..13)_RX_EIE_DETSTS[EIESTS] for the GSER to infer EI.
+                                                         In the event of electrical IDLE inference, the following happens:
+                                                         * GSER(0..13)_RX_EIE_DETSTS[CDRLOCK]<lane> is zeroed
+                                                         * GSER(0..13)_RX_EIE_DETSTS[EIELTCH]<lane> is zeroed
+                                                         * GSER(0..13)_RX_EIE_DETSTS[EIESTS]<lane> is zeroed
+                                                         * GSER(0..13)_RX_COAST[COAST]<lane> is asserted to prevent the CDR from trying to lock on
                                                          the incoming data stream.
-                                                         The lane incoming RX data is invalidated.
+                                                         * GSER(0..13)_RX_EIE_DETEN[EIEDE]<lane> deasserts for a short period of time, and then is
+                                                         asserted to begin looking for the Electical IDLE Exit condition.
                                                          Writing this register to a non-zero value causes the electrical idle inference to use the
                                                          EII_FILT count instead of the default settings. Each EII_FILT count represents 20 ns of
-                                                         incremental EI inference time. */
+                                                         incremental EI inference time.
+                                                         It is not expected that Software will need to use the Electrical Idle Inference logic. */
 #else
 	uint64_t eii_filt                     : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4297,6 +4847,9 @@ typedef union cvmx_gserx_rx_eie_filter cvmx_gserx_rx_eie_filter_t;
 
 /**
  * cvmx_gser#_rx_polarity
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_rx_polarity {
 	uint64_t u64;
@@ -4321,6 +4874,9 @@ typedef union cvmx_gserx_rx_polarity cvmx_gserx_rx_polarity_t;
 
 /**
  * cvmx_gser#_rx_pstate
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_rx_pstate {
 	uint64_t u64;
@@ -4690,38 +5246,73 @@ union cvmx_gserx_sata_tx_invert {
 typedef union cvmx_gserx_sata_tx_invert cvmx_gserx_sata_tx_invert_t;
 
 /**
+ * cvmx_gser#_scratch
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ */
+union cvmx_gserx_scratch {
+	uint64_t u64;
+	struct cvmx_gserx_scratch_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t scratch                      : 16; /**< General purpose scratch register. */
+#else
+	uint64_t scratch                      : 16;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_scratch_s           cn78xx;
+};
+typedef union cvmx_gserx_scratch cvmx_gserx_scratch_t;
+
+/**
  * cvmx_gser#_spd
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_spd {
 	uint64_t u64;
 	struct cvmx_gserx_spd_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t spd                          : 4;  /**< For OCI links, these bits are loaded at cold reset from the OCI_SPD<3:0> pins and
-                                                         configure the GSER to a rate/reference clock. This field can be reconfigured and the new
-                                                         GSER(0..13)_LANE_MODE[LMODE] clock takes affect on the next warm reset.
+	uint64_t spd                          : 4;  /**< For OCI links (i.e. GSER8..13), the hardware loads this CSR field from the
+                                                         OCI_SPD<3:0> pins during chip cold reset. For non-OCI links, this field is not used.
                                                          For SPD settings that configure a non-default reference clock, hardware updates the PLL
                                                          settings of the specific lane mode (LMODE) table entry to derive the correct link rate.
-                                                         For non-OCI links, this field is not used.
-                                                         config  refclk      link rate       LMODE
-                                                         0x0:    100Mhz      1.25Gbps        R_125G_REFCLK15625_KX
-                                                         0x1:    100Mhz      2.5Gbps         R_25G_REFCLK100
-                                                         0x2:    100Mhz      5Gbps           R_5G_REFCLK100
-                                                         0x3:    100Mhz      8Gbps           R_8G_REFCLK100
-                                                         0x4:    125Mhz      1.25Gbps        R_125G_REFCLK15625_KX
-                                                         0x5:    125Mhz      2.5Gbps         R_25G_REFCLK125
-                                                         0x6:    125Mhz      3.125Gbps       R_3125G_REFCLK15625_XAUI
-                                                         0x7:    125Mhz      5Gbps           R_5G_REFCLK125
-                                                         0x8:    125Mhz      6.25Gbps        R_625G_REFCLK15625_RXAUI
-                                                         0x9:    125Mhz      8Gbps           R_8G_REFCLK125
-                                                         0xA:    156.25Mhz   2.5Gbps         R_25G_REFCLK100
-                                                         0xB:    156.25Mhz   3.125Gbps       R_3125G_REFCLK15625_XAUI
-                                                         0xC:    156.25Mhz   5Gbps           R_5G_REFCLK125
-                                                         0xD:    156.25Mhz   6.25Gbps        R_625G_REFCLK15625_RXAUI
-                                                         0xE:    126.25Mhz   10.3125Gbps     R_103215G_REFCLK15625_KR
-                                                         0xF:    SW_MODE
-                                                         Note that a value of 0xF is called SW_MODE. The OCI link does not come up configured.
-                                                         Software can come up and configure the interface at a later time. */
+                                                         SPD     REFCLK     Link rate    LMODE
+                                                         0x0:    100 MHz    1.25 Gbps    R_125G_REFCLK15625_KX
+                                                         0x1:    100 MHz    2.5Gbps      R_25G_REFCLK100
+                                                         0x2:    100 MHz    5Gbps        R_5G_REFCLK100
+                                                         0x3:    100 MHz    8Gbps        R_8G_REFCLK100
+                                                         0x4:    125 MHz    1.25Gbps     R_125G_REFCLK15625_KX
+                                                         0x5:    125 MHz    2.5Gbps      R_25G_REFCLK125
+                                                         0x6:    125 MHz    3.125Gbps    R_3125G_REFCLK15625_XAUI
+                                                         0x7:    125 MHz    5Gbps        R_5G_REFCLK125
+                                                         0x8:    125 MHz    6.25Gbps     R_625G_REFCLK15625_RXAUI
+                                                         0x9:    125 MHz    8Gbps        R_8G_REFCLK125
+                                                         0xA:    156.25 MHz 2.5Gbps      R_25G_REFCLK100
+                                                         0xB:    156.25 MHz 3.125Gbps    R_3125G_REFCLK15625_XAUI
+                                                         0xC:    156.25 MHz 5Gbps        R_5G_REFCLK125
+                                                         0xD:    156.25 MHz 6.25Gbps     R_625G_REFCLK15625_RXAUI
+                                                         0xE:    126.25 MHz 10.3125Gbps  R_103125G_REFCLK15625_KR
+                                                         0xF:               SW_MODE
+                                                         Note that a value of 0xF is called SW_MODE. The OCI link does not come up configured in
+                                                         SW_MODE.
+                                                         (Software must do all the OCI GSER configuration to use OCI in the case of SW_MODE.)
+                                                         When SPD!=SW_MODE after a chip cold reset, the hardware has initialized the following
+                                                         registers
+                                                         (based on the OCI_SPD selection):
+                                                          o GSER(8..13)_LANE_MODE[LMODE]=Z
+                                                          o GSER(8..13)_PLL_P(Z)_MODE_0
+                                                          o GSER(8..13)_PLL_P(Z)_MODE_1
+                                                          o GSER(8..13)_LANE(0..3)_P(Z)_MODE_0
+                                                          o GSER(8..13)_LANE(0..3)_P(Z)_MODE_1
+                                                          o GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_0
+                                                          o GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_1
+                                                          o GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         where Z is the LMODE indicated by the prior table. */
 #else
 	uint64_t spd                          : 4;
 	uint64_t reserved_4_63                : 60;
@@ -4733,6 +5324,9 @@ typedef union cvmx_gserx_spd cvmx_gserx_spd_t;
 
 /**
  * cvmx_gser#_srst
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_srst {
 	uint64_t u64;
@@ -4752,6 +5346,9 @@ typedef union cvmx_gserx_srst cvmx_gserx_srst_t;
 
 /**
  * cvmx_gser#_tx_pstate
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_tx_pstate {
 	uint64_t u64;
@@ -4777,6 +5374,9 @@ typedef union cvmx_gserx_tx_pstate cvmx_gserx_tx_pstate_t;
 
 /**
  * cvmx_gser#_tx_vboost
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_tx_vboost {
 	uint64_t u64;
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
new file mode 100644
index 0000000..ae370e2
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
@@ -0,0 +1,190 @@
+/***********************license start***************
+ * Copyright (c) 2014  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Functions to configure the BGX MAC.
+ *
+ * <hr>$Revision$<hr>
+ */
+
+#ifndef __CVMX_HELPER_BGX_H__
+#define __CVMX_HELPER_BGX_H__
+
+extern int __cvmx_helper_bgx_enumerate(int interface);
+
+/**
+ * @INTERNAL
+ * Probe a SGMII interface and determine the number of ports
+ * connected to it. The SGMII/XAUI interface should still be down after
+ * this call. This is used by interfaces using the bgx mac.
+ *
+ * @param interface Interface to probe
+ *
+ * @return Number of ports on the interface. Zero to disable.
+ */
+extern int __cvmx_helper_bgx_probe(int interface);
+
+/**
+ * @INTERNAL
+ * Bringup and enable a SGMII interface. After this call packet
+ * I/O should be fully functional. This is called with IPD
+ * enabled but PKO disabled. This is used by interfaces using the
+ * bgx mac.
+ *
+ * @param interface Interface to bring up
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int __cvmx_helper_bgx_sgmii_enable(int interface);
+
+/**
+ * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set(). This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
+extern cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port);
+
+/**
+ * @INTERNAL
+ * Configure an IPD/PKO port for the specified link state. This
+ * function does not influence auto negotiation at the PHY level.
+ * The passed link state must always match the link state returned
+ * by cvmx_helper_link_get(). It is normally best to use
+ * cvmx_helper_link_autoconf() instead. This is used by interfaces
+ * using the bgx mac.
+ *
+ * @param ipd_port  IPD/PKO port to configure
+ * @param link_info The new link state
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port, 
+					    cvmx_helper_link_info_t link_info);
+
+/**
+ * @INTERNAL
+ * Configure a port for internal and/or external loopback. Internal loopback
+ * causes packets sent by the port to be received by Octeon. External loopback
+ * causes packets received from the wire to sent out again. This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to loopback.
+ * @param enable_internal
+ *                 Non zero if you want internal loopback
+ * @param enable_external
+ *                 Non zero if you want external loopback
+ *
+ * @return Zero on success, negative on failure.
+ */
+extern int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port, 
+						      int enable_internal, 
+						      int enable_external);
+
+/**
+ * @INTERNAL
+ * Bringup and enable a XAUI interface. After this call packet
+ * I/O should be fully functional. This is called with IPD
+ * enabled but PKO disabled. This is used by interfaces using the
+ * bgx mac.
+ *
+ * @param interface Interface to bring up
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int __cvmx_helper_bgx_xaui_enable(int interface);
+
+/**
+ * @INTERNAL
+ * Return the link state of an IPD/PKO port as returned by
+ * auto negotiation. The result of this function may not match
+ * Octeon's link config if auto negotiation has changed since
+ * the last call to cvmx_helper_link_set(). This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to query
+ *
+ * @return Link state
+ */
+extern cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port);
+
+/**
+ * @INTERNAL
+ * Configure an IPD/PKO port for the specified link state. This
+ * function does not influence auto negotiation at the PHY level.
+ * The passed link state must always match the link state returned
+ * by cvmx_helper_link_get(). It is normally best to use
+ * cvmx_helper_link_autoconf() instead. This is used by interfaces
+ * using the bgx mac.
+ *
+ * @param ipd_port  IPD/PKO port to configure
+ * @param link_info The new link state
+ *
+ * @return Zero on success, negative on failure
+ */
+extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port, 
+					   cvmx_helper_link_info_t link_info);
+
+/**
+ * @INTERNAL
+ * Configure a port for internal and/or external loopback. Internal loopback
+ * causes packets sent by the port to be received by Octeon. External loopback
+ * causes packets received from the wire to sent out again. This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to loopback.
+ * @param enable_internal
+ *                 Non zero if you want internal loopback
+ * @param enable_external
+ *                 Non zero if you want external loopback
+ *
+ * @return Zero on success, negative on failure.
+ */
+extern int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port, 
+						     int enable_internal, 
+						     int enable_external);
+#endif
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-board.h b/arch/mips/include/asm/octeon/cvmx-helper-board.h
index c36798e..1d744d1 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-board.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-board.h
@@ -43,7 +43,7 @@
  * Helper functions to abstract board specific data about
  * network ports from the rest of the cvmx-helper files.
  *
- * <hr>$Revision: 86922 $<hr>
+ * <hr>$Revision: 93549 $<hr>
  */
 #ifndef __CVMX_HELPER_BOARD_H__
 #define __CVMX_HELPER_BOARD_H__
@@ -64,8 +64,9 @@ typedef enum {
 typedef enum {
 	BROADCOM_GENERIC_PHY,
 	MARVELL_GENERIC_PHY,
- 	VITESSE_GENERIC_PHY,
 	CORTINA_PHY,
+	GENERIC_8023_C22_PHY,
+	GENERIC_8023_C45_PHY,
  	INBAND_PHY,
 } cvmx_phy_type_t;
 
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
index 8b8b4b4..8e480a4 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
@@ -166,7 +166,7 @@ typedef union cvmx_user_static_pko_queue_config
 	} pknd;
 	struct
 	{
-		int max_ports_per_interface[2];
+		int pko_ports_per_interface[2];
 		int pko_queues_per_port_interface[2];
 		int pko_queues_per_port_loop;
 		int pko_queues_per_port_pci;
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-fpa.h b/arch/mips/include/asm/octeon/cvmx-helper-fpa.h
index ff421b0..91e915a 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-fpa.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-fpa.h
@@ -70,8 +70,45 @@
  *               number should work.
  * @return Zero on success, non-zero if out of memory
  */
-extern int cvmx_helper_initialize_fpa(int packet_buffers, int work_queue_entries, int pko_buffers, int tim_buffers, int dfa_buffers);
+extern int cvmx_helper_initialize_fpa(int packet_buffers,
+				      int work_queue_entries, int pko_buffers,
+				      int tim_buffers, int dfa_buffers);
+
+/**
+ * @INTERNAL
+ * Setup a FPA3 pool and aura to control a new block of memory. This
+ * function is called by legacy code.
+ *
+ * @param pool       Pool to initialize
+ * @param name       Pool name
+ * @param buffers    Pointer to block of memory to use for the aura buffers
+ * @param block_size Size of the aura buffers
+ * @param num_blocks Number of aura buffers
+ *
+ * @return 0 on Success, -1 on failure
+ */
+/*int __cvmx_fpa3_setup_pool(uint64_t pool, const char *name, void *buffer,
+			   uint64_t block_size, uint64_t num_blocks);*/
+
+extern int __cvmx_helper_initialize_fpa_pool(int pool, uint64_t buffer_size,
+					     uint64_t buffers,
+					     const char *name);
+
+extern void cvmx_fpa_show_stats(void);
+
+/**
+ * Setup an FPA pool (and/or aura) to control a block of memory.
+ *
+ * @param pool_num 		Pointer to pool id to initialize or -1 to allocate
+ * @param aura_id		Pointer to aura id to initialize or -1 to allocate (ignored for legacy hardware)
+ * @param block_size 	Size of the aura buffers
+ * @param num_blocks 	Number of aura buffers
+ * @param name			Name to assign fpa pool
+ * @param buffers		Pointer to buffer memory to use
+ */
+extern int cvmx_helper_fpa_init(int node, int *pool_num, int *aura_id, int block_size,
+						int num_blocks, const char *name, void **buffers);
+
 
-extern int __cvmx_helper_initialize_fpa_pool(int pool, uint64_t buffer_size, uint64_t buffers, const char *name);
 
 #endif /* __CVMX_HELPER_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-npi.h b/arch/mips/include/asm/octeon/cvmx-helper-npi.h
index f7c4ee1..7bfa3ba 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-npi.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-npi.h
@@ -43,7 +43,7 @@
  * Functions for NPI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 73842 $<hr>
+ * <hr>$Revision: 89425 $<hr>
  */
 #ifndef __CVMX_HELPER_NPI_H__
 #define __CVMX_HELPER_NPI_H__
@@ -76,4 +76,10 @@ static inline int __cvmx_helper_npi_enumerate(int interface)
  */
 extern int __cvmx_helper_npi_enable(int interface);
 
+/**
+ * Sets the number of pipe used by SLI packet output in the variable,
+ * which then later used for setting it up in HW
+ */
+void cvmx_npi_config_set_num_pipes(int num_pipes);
+
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-pki.h b/arch/mips/include/asm/octeon/cvmx-helper-pki.h
new file mode 100644
index 0000000..2c93981
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-helper-pki.h
@@ -0,0 +1,113 @@
+/***********************license start***************
+ * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * Helper functions for PKI
+ */
+
+#ifndef __CVMX_HELPER_PKI_H__
+#define __CVMX_HELPER_PKI_H__
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-pki.h>
+#else
+#include "cvmx-pki.h"
+#endif
+
+#ifdef __cplusplus
+/* *INDENT-OFF* */
+extern "C" {
+/* *INDENT-ON* */
+#endif
+
+extern struct cvmx_pki_global_config pki_dflt_gblcfg[CVMX_MAX_NODES];
+extern struct cvmx_pki_pool_config pki_dflt_pool[CVMX_MAX_NODES];
+extern struct cvmx_pki_aura_config pki_dflt_aura[CVMX_MAX_NODES];
+extern struct cvmx_pki_sso_grp_config pki_dflt_sso_grp[CVMX_MAX_NODES];
+extern struct cvmx_pki_qpg_config pki_dflt_qpg[CVMX_MAX_NODES];
+extern uint64_t style_qpg_base_map[CVMX_MAX_NODES];
+extern struct cvmx_pki_style_config pki_dflt_style[CVMX_MAX_NODES];
+extern struct cvmx_pki_pkind_config pki_dflt_pkind[CVMX_MAX_NODES];
+extern uint64_t pkind_style_map[CVMX_MAX_NODES][CVMX_PKI_NUM_PKIND];
+
+int cvmx_helper_setup_pki_port(int node, int pknd);
+int cvmx_helper_global_setup_pki(int node);
+int cvmx_helper_pki_setup_qpg_table(int node, int num_entries, int port_addr[],
+				    uint64_t aura[], uint64_t sso_grp_ok[], uint64_t sso_grp_bad[]);
+void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs);
+int __cvmx_helper_port_setup_pki(int node, int pknd);
+int __cvmx_helper_global_setup_pki(int node);
+void cvmx_helper_pki_set_dflt_pool(int node, int pool,
+				   int buffer_size, int buffer_count);
+void cvmx_helper_pki_set_dflt_aura(int node, int aura,
+				   int pool, int buffer_count);
+void cvmx_helper_pki_set_dflt_pool_buffer(int node, int buffer_count);
+void cvmx_helper_pki_set_dflt_aura_buffer(int node, int buffer_count);
+
+/**
+ * This function sets up aura QOS for RED, backpressure and tail-drop.
+ *
+ * @param node       node number.
+ * @param aura       aura to configure.
+ * @param ena_red       enable RED based on [DROP] and [PASS] levels
+ *			1: enable 0:disable
+ * @param pass_thresh   pass threshold for RED.
+ * @param drop_thresh   drop threshold for RED
+ * @param ena_bp        enable backpressure based on [BP] level.
+ *			1:enable 0:disable
+ * @param bp_thresh     backpressure threshold.
+ * @param ena_drop      enable tail drop.
+ *                      1:enable 0:disable
+ * @return Zero on success. Negative on failure
+ */
+int cvmx_helper_setup_aura_qos(int node, int aura, bool ena_red, bool ena_drop,
+			       uint64_t pass_thresh, uint64_t drop_thresh,
+			       bool ena_bp, uint64_t bp_thresh);
+int cvmx_helper_map_aura_channel_bpid(int node, int aura_map[], int aura_cnt,
+				      int chl_map[], int chl_cnt, int bpid);
+
+#ifdef __cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
+#endif
+#endif /* __CVMX_HELPER_PKI_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-pko.h b/arch/mips/include/asm/octeon/cvmx-helper-pko.h
new file mode 100644
index 0000000..f7f4c63
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-helper-pko.h
@@ -0,0 +1,127 @@
+/***********************license start***************
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * PKO helper, configuration API
+ */
+
+#ifndef __CVMX_HELPER_PKO_H__
+#define __CVMX_HELPER_PKO_H__
+
+/* CSR typedefs have been moved to cvmx-pko-defs.h */
+
+#if 0	// XXX Not clear what this is intended for !
+/**
+ * Definition of internal state for Packet output processing
+ */
+typedef struct {
+	uint64_t *start_ptr;		/**< ptr to start of buffer, offset kept in FAU reg */
+} cvmx_pko_state_elem_t;
+#endif
+
+/**
+ * cvmx_override_pko_queue_priority(int ipd_port, uint64_t
+ * priorities[16]) is a function pointer. It is meant to allow
+ * customization of the PKO queue priorities based on the port
+ * number. Users should set this pointer to a function before
+ * calling any cvmx-helper operations.
+ */
+extern CVMX_SHARED void (*cvmx_override_pko_queue_priority) (int ipd_port, uint8_t * priorities);
+
+
+extern CVMX_SHARED cvmx_fpa_pool_config_t pko_fpa_config;
+
+/**
+ * Gets the fpa pool number of pko pool
+ */
+static inline int64_t cvmx_fpa_get_pko_pool(void)
+{
+	return (pko_fpa_config.pool_num);
+}
+
+/**
+ * Gets the buffer size of pko pool
+ */
+static inline uint64_t cvmx_fpa_get_pko_pool_block_size(void)
+{
+	return (pko_fpa_config.buffer_size);
+}
+
+/**
+ * Gets the buffer size  of pko pool
+ */
+static inline uint64_t cvmx_fpa_get_pko_pool_buffer_count(void)
+{
+	return (pko_fpa_config.buffer_count);
+}
+
+/**
+ * Sets the internal PKO pool data structure for command queue pool.
+ * @param pool	fpa pool number yo use
+ * @param buffer_size	buffer size of pool
+ * @param buffer_count	number of buufers to allocate to pool
+ */
+void cvmx_helper_set_pko_fpa_config(int64_t pool, uint64_t buffer_size,
+				    uint64_t buffer_count);
+
+/**
+ * Gets up the pko FPA pool data from internal data structure
+ * @param pko_pool pointer to the fpa data structure to copy data
+ */
+void cvmx_pko_get_cmd_que_pool_config(cvmx_fpa_pool_config_t *pko_pool);
+
+
+int cvmx_helper_pko_init(void);
+
+/*
+ * This function is a no-op
+ * included here for backwards compatibility only.
+ */
+static inline  int cvmx_pko_initialize_local(void)
+{
+    return 0;
+}
+
+extern int __cvmx_helper_pko_drain(void);
+
+extern int __cvmx_helper_interface_setup_pko(int interface);
+
+#endif /* __CVMX_HELPER_PKO_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-pko3.h b/arch/mips/include/asm/octeon/cvmx-helper-pko3.h
new file mode 100644
index 0000000..76da789a
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-helper-pko3.h
@@ -0,0 +1,97 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * <hr>$Revision: 0 $<hr>
+ */
+
+#ifndef __CVMX_HELPER_PKO3_H__
+#define __CVMX_HELPER_PKO3_H__
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+extern "C" {
+/* *INDENT-ON* */
+#endif
+
+/*
+ * Initialize PKO3 unit on the current node.
+ *
+ * Covers the common hardware, memory and global configuration.
+ * Per-interface intialization is performed separately.
+ *
+ * @return 0 on success.
+ *
+ */
+extern int cvmx_helper_pko3_init_global(void);
+
+/*
+ * Conhfigure and initialize PKO3 for an interface
+ *
+ * @param interface is the interface number to configure
+ * @return 0 on success.
+ *
+ */
+extern int cvmx_helper_pko3_init_interface(unsigned interface);
+
+/**
+ * Uninitialize PKO3 interface
+ *
+ * Release all resources held by PKO for an interface.
+ * The shutdown code is the same for all supported interfaces.
+ */
+extern int cvmx_helper_pko3_shut_interface(int interface);
+
+/**
+ * Shutdown PKO3
+ *
+ * Should be called after all interfaces have been shut down on the PKO3.
+ *
+ * Disables the PKO, frees all its buffers.
+ */
+extern int cvmx_helper_pko3_shutdown(void);
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
+#endif
+#endif /* __CVMX_HELPER_PKO3_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h b/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
index 9317f8a..6e48669 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 86626 $<hr>
+ * <hr>$Revision: 93962 $<hr>
  */
 #ifndef __CVMX_HELPER_SGMII_H__
 #define __CVMX_HELPER_SGMII_H__
@@ -117,79 +117,4 @@ extern int __cvmx_helper_sgmii_link_set(int ipd_port, cvmx_helper_link_info_t li
  */
 extern int __cvmx_helper_sgmii_configure_loopback(int ipd_port, int enable_internal, int enable_external);
 
-/**
- * @INTERNAL
- * Probe a SGMII interface and determine the number of ports
- * connected to it. The SGMII interface should still be down after
- * this call. This is used by interfaces using the bgx mac.
- *
- * @param interface Interface to probe
- *
- * @return Number of ports on the interface. Zero to disable.
- */
-extern int __cvmx_helper_bgx_sgmii_probe(int interface);
-
-/**
- * @INTERNAL
- * Bringup and enable a SGMII interface. After this call packet
- * I/O should be fully functional. This is called with IPD
- * enabled but PKO disabled. This is used by interfaces using the
- * bgx mac.
- *
- * @param interface Interface to bring up
- *
- * @return Zero on success, negative on failure
- */
-extern int __cvmx_helper_bgx_sgmii_enable(int interface);
-
-/**
- * @INTERNAL
- * Return the link state of an IPD/PKO port as returned by
- * auto negotiation. The result of this function may not match
- * Octeon's link config if auto negotiation has changed since
- * the last call to cvmx_helper_link_set(). This is used by
- * interfaces using the bgx mac.
- *
- * @param ipd_port IPD/PKO port to query
- *
- * @return Link state
- */
-extern cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port);
-
-/**
- * @INTERNAL
- * Configure an IPD/PKO port for the specified link state. This
- * function does not influence auto negotiation at the PHY level.
- * The passed link state must always match the link state returned
- * by cvmx_helper_link_get(). It is normally best to use
- * cvmx_helper_link_autoconf() instead. This is used by interfaces
- * using the bgx mac.
- *
- * @param ipd_port  IPD/PKO port to configure
- * @param link_info The new link state
- *
- * @return Zero on success, negative on failure
- */
-extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port, 
-					    cvmx_helper_link_info_t link_info);
-
-/**
- * @INTERNAL
- * Configure a port for internal and/or external loopback. Internal loopback
- * causes packets sent by the port to be received by Octeon. External loopback
- * causes packets received from the wire to sent out again. This is used by
- * interfaces using the bgx mac.
- *
- * @param ipd_port IPD/PKO port to loopback.
- * @param enable_internal
- *                 Non zero if you want internal loopback
- * @param enable_external
- *                 Non zero if you want external loopback
- *
- * @return Zero on success, negative on failure.
- */
-extern int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port, 
-						      int enable_internal, 
-						      int enable_external);
-
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-util.h b/arch/mips/include/asm/octeon/cvmx-helper-util.h
index 7c67709..9dfd2c5 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-util.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-util.h
@@ -42,7 +42,7 @@
  *
  * Small helper utilities.
  *
- * <hr>$Revision: 86308 $<hr>
+ * <hr>$Revision: 94787 $<hr>
  */
 
 #ifndef __CVMX_HELPER_UTIL_H__
@@ -50,6 +50,7 @@
 
 #include "cvmx.h"
 #include "cvmx-mio-defs.h"
+#include "cvmx-helper.h"
 
 
 typedef char cvmx_pknd_t;
@@ -60,7 +61,7 @@ typedef char cvmx_bpid_t;
 #define CVMX_MAX_PKND		((cvmx_pknd_t) 64)
 #define CVMX_MAX_BPID		((cvmx_bpid_t) 64)
 
-#define CVMX_HELPER_MAX_IFACE		10
+#define CVMX_HELPER_MAX_IFACE		11
 #define CVMX_HELPER_MAX_PORTS		16
 
 /**
@@ -78,34 +79,7 @@ extern const char *cvmx_helper_interface_mode_to_string(cvmx_helper_interface_mo
  * @param work   Work queue entry containing the packet to dump
  * @return
  */
-extern int cvmx_helper_dump_packet(cvmx_wqe_t * work);
-
-/**
- * Setup Random Early Drop on a specific input queue
- *
- * @param queue  Input queue to setup RED on (0-7)
- * @param pass_thresh
- *               Packets will begin slowly dropping when there are less than
- *               this many packet buffers free in FPA 0.
- * @param drop_thresh
- *               All incomming packets will be dropped when there are less
- *               than this many free packet buffers in FPA 0.
- * @return Zero on success. Negative on failure
- */
-extern int cvmx_helper_setup_red_queue(int queue, int pass_thresh, int drop_thresh);
-
-/**
- * Setup Random Early Drop to automatically begin dropping packets.
- *
- * @param pass_thresh
- *               Packets will begin slowly dropping when there are less than
- *               this many packet buffers free in FPA 0.
- * @param drop_thresh
- *               All incomming packets will be dropped when there are less
- *               than this many free packet buffers in FPA 0.
- * @return Zero on success. Negative on failure
- */
-extern int cvmx_helper_setup_red(int pass_thresh, int drop_thresh);
+extern int cvmx_helper_dump_packet(cvmx_wqe_t *work);
 
 /**
  * Get the version of the CVMX libraries.
@@ -259,49 +233,96 @@ static inline int cvmx_helper_get_last_ipd_port(int interface)
 /**
  * Free the packet buffers contained in a work queue entry.
  * The work queue entry is not freed.
+ * Note that this function will not free the work queue entry
+ * even if it contains a non-redundant data packet, and hence
+ * it is not really comparable to how the PKO would free a packet
+ * buffers if requested.
  *
  * @param work   Work queue entry with packet to free
  */
-static inline void cvmx_helper_free_packet_data(cvmx_wqe_t * work)
+static inline void cvmx_helper_free_packet_data(cvmx_wqe_t *work)
 {
 	uint64_t number_buffers;
-	cvmx_buf_ptr_t buffer_ptr;
-	cvmx_buf_ptr_t next_buffer_ptr;
 	uint64_t start_of_buffer;
+	uint64_t next_buffer_ptr;
+	unsigned ncl;
+	cvmx_buf_ptr_t buffer_ptr;
+	cvmx_buf_ptr_pki_t bptr;
+	cvmx_wqe_78xx_t *wqe = (void *) work;
 
 	number_buffers = cvmx_wqe_get_bufs(work);
+
+	buffer_ptr.u64 = work->packet_ptr.u64;
+
+	/* Zero-out WQE WORD3 so that the WQE is freed by cvmx_wqe_free() */
+	work->packet_ptr.u64 = 0;
+
 	if (number_buffers == 0)
 		return;
-	buffer_ptr = work->packet_ptr;
-
-	/* Since the number of buffers is not zero, we know this is not a dynamic
-	   short packet. We need to check if it is a packet received with
-	   IPD_CTL_STATUS[NO_WPTR]. If this is true, we need to free all buffers
-	   except for the first one. The caller doesn't expect their WQE pointer
-	   to be freed */
-	start_of_buffer = ((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back) << 7;
-	if (cvmx_ptr_to_phys(work) == start_of_buffer) {
-		next_buffer_ptr = *(cvmx_buf_ptr_t *) cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
-		buffer_ptr = next_buffer_ptr;
-		number_buffers--;
-	}
 
+	/* Interpret PKI-style bufptr unless it has been translated */
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
+	    !wqe->pki_wqe_translated) {
+		bptr.u64 = buffer_ptr.u64;
+		next_buffer_ptr = *(uint64_t *)
+			cvmx_phys_to_ptr(bptr.s_cn78xx.addr - 8);
+		if (!bptr.s_cn78xx.packet_outside_wqe) {
+			buffer_ptr.u64 = next_buffer_ptr;
+			number_buffers--;
+		}
+	} else {
+		start_of_buffer =
+			((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back) << 7;
+		next_buffer_ptr = *(uint64_t *)
+			cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
+		/* Since the number of buffers is not zero, we know this is not a dynamic
+		short packet. We need to check if it is a packet received with
+		IPD_CTL_STATUS[NO_WPTR]. If this is true, we need to free all buffers
+		except for the first one. The caller doesn't expect their WQE pointer
+		to be freed */
+		if (cvmx_ptr_to_phys(work) == start_of_buffer) {
+			buffer_ptr.u64 = next_buffer_ptr;
+			number_buffers--;
+		}
+	}
 	while (number_buffers--) {
-		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-			start_of_buffer = (buffer_ptr.s.addr >> 7) << 7;
+		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
+		    !wqe->pki_wqe_translated) {
+			unsigned aura = cvmx_wqe_get_aura(work);
+			bptr.u64 = buffer_ptr.u64;
+
+			ncl = (bptr.s_cn78xx.size + CVMX_CACHE_LINE_SIZE-1)/
+				CVMX_CACHE_LINE_SIZE;
+
+			/* XXX- assumes the buffer is cache-line aligned */
+			start_of_buffer = (bptr.s_cn78xx.addr >> 7) << 7;
+
 			/* Read pointer to next buffer before we free the current buffer. */
-			next_buffer_ptr = *(cvmx_buf_ptr_t *) cvmx_phys_to_ptr(buffer_ptr.s_cn78xx.addr - 8);
-			cvmx_fpa_free(cvmx_phys_to_ptr(start_of_buffer), cvmx_wqe_get_aura(work), 0);
+			next_buffer_ptr = *(uint64_t *)
+				cvmx_phys_to_ptr(bptr.s_cn78xx.addr - 8);
+			/* FPA AURA comes from WQE, includes node */
+			cvmx_fpa_free_aura(cvmx_phys_to_ptr(start_of_buffer),
+				aura >> 10, aura & ((1<<10)-1), ncl);
+		} else {
+			ncl = (buffer_ptr.s.size + CVMX_CACHE_LINE_SIZE-1)/
+				CVMX_CACHE_LINE_SIZE + buffer_ptr.s.back;
+			/* Calculate buffer start using "back" offset,
+			   Remember the back pointer is in cache lines,
+			   not 64bit words */
+			start_of_buffer =
+				((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back)
+					<< 7;
+			/* Read pointer to next buffer before we free
+			the current buffer. */
+			next_buffer_ptr = *(uint64_t *)
+				cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
+			/* FPA pool comes from buf_ptr itself */
+			cvmx_fpa_free(cvmx_phys_to_ptr(start_of_buffer),
+				buffer_ptr.s.pool, ncl);
 		}
-		else {
-		/* Remember the back pointer is in cache lines, not 64bit words */
-		start_of_buffer = ((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back) << 7;
-		/* Read pointer to next buffer before we free the current buffer. */
-		next_buffer_ptr = *(cvmx_buf_ptr_t *) cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
-		cvmx_fpa_free(cvmx_phys_to_ptr(start_of_buffer), buffer_ptr.s.pool, 0);
-		}
-		buffer_ptr = next_buffer_ptr;
+		buffer_ptr.u64 = next_buffer_ptr;
 	}
+
 }
 
 
@@ -352,26 +373,4 @@ extern void __cvmx_helper_shutdown_interfaces(void);
 
 extern void cvmx_helper_show_stats(int port);
 
-/**
- * This function sets up aura QOS for RED, backpressure and tail-drop.
- *
- * @param node       node number.
- * @param aura       aura to configure.
- * @param ena_red       enable RED based on [DROP] and [PASS] levels
-                        1: enable 0:disable
- * @param pass_thresh   pass threshold for RED.
- * @param drop_thresh   drop threshold for RED
- * @param ena_bp        enable backpressure based on [BP] level.
-                        1:enable 0:disable
- * @param bp_thresh     backpressure threshold.
- * @param ena_drop      enable tail drop.
- *                      1:enable 0:disable
- * @return Zero on success. Negative on failure
- */
-int cvmx_helper_setup_aura_qos(int node, int aura, bool ena_red,bool ena_drop,
-			       uint64_t pass_thresh, uint64_t drop_thresh,
-			       bool ena_bp,uint64_t bp_thresh);
-int cvmx_helper_map_aura_channel_bpid(int node, int aura_map[], int aura_cnt,
-				      int chl_map[],int chl_cnt, int bpid);
-
 #endif /* __CVMX_HELPER_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-xaui.h b/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
index 99af3db..d4464e7 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 86925 $<hr>
+ * <hr>$Revision: 94200 $<hr>
  */
 #ifndef __CVMX_HELPER_XAUI_H__
 #define __CVMX_HELPER_XAUI_H__
@@ -63,18 +63,6 @@ extern int __cvmx_helper_xaui_enumerate(int interface);
 
 /**
  * @INTERNAL
- * Probe a XAUI interface and determine the number of ports
- * connected to it. The XAUI interface should still be down
- * after this call.
- *
- * @param interface Interface to probe
- *
- * @return Number of ports on the interface. Zero to disable.
- */
-extern int __cvmx_helper_bgx_xaui_probe(int interface);
-
-/**
- * @INTERNAL
  * Bringup and enable a XAUI interface. After this call packet
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
@@ -87,18 +75,6 @@ extern int __cvmx_helper_xaui_enable(int interface);
 
 /**
  * @INTERNAL
- * Bringup and enable a XAUI interface. After this call packet
- * I/O should be fully functional. This is called with IPD
- * enabled but PKO disabled.
- *
- * @param interface Interface to bring up
- *
- * @return Zero on success, negative on failure
- */
-extern int __cvmx_helper_bgx_xaui_enable(int interface);
-
-/**
- * @INTERNAL
  * Return the link state of an IPD/PKO port as returned by
  * auto negotiation. The result of this function may not match
  * Octeon's link config if auto negotiation has changed since
@@ -112,19 +88,6 @@ extern cvmx_helper_link_info_t __cvmx_helper_xaui_link_get(int ipd_port);
 
 /**
  * @INTERNAL
- * Return the link state of an IPD/PKO port as returned by
- * auto negotiation. The result of this function may not match
- * Octeon's link config if auto negotiation has changed since
- * the last call to cvmx_helper_link_set().
- *
- * @param ipd_port IPD/PKO port to query
- *
- * @return Link state
- */
-extern cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port);
-
-/**
- * @INTERNAL
  * Configure an IPD/PKO port for the specified link state. This
  * function does not influence auto negotiation at the PHY level.
  * The passed link state must always match the link state returned
@@ -140,22 +103,6 @@ extern int __cvmx_helper_xaui_link_set(int ipd_port, cvmx_helper_link_info_t lin
 
 /**
  * @INTERNAL
- * Configure an IPD/PKO port for the specified link state. This
- * function does not influence auto negotiation at the PHY level.
- * The passed link state must always match the link state returned
- * by cvmx_helper_link_get(). It is normally best to use
- * cvmx_helper_link_autoconf() instead.
- *
- * @param ipd_port  IPD/PKO port to configure
- * @param link_info The new link state
- *
- * @return Zero on success, negative on failure
- */
-extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port,
-					   cvmx_helper_link_info_t link_info);
-
-/**
- * @INTERNAL
  * Configure a port for internal and/or external loopback. Internal loopback
  * causes packets sent by the port to be received by Octeon. External loopback
  * causes packets received from the wire to sent out again.
@@ -170,22 +117,4 @@ extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port,
  */
 extern int __cvmx_helper_xaui_configure_loopback(int ipd_port, int enable_internal, int enable_external);
 
-/**
- * @INTERNAL
- * Configure a port for internal and/or external loopback. Internal loopback
- * causes packets sent by the port to be received by Octeon. External loopback
- * causes packets received from the wire to sent out again.
- *
- * @param ipd_port IPD/PKO port to loopback.
- * @param enable_internal
- *                 Non zero if you want internal loopback
- * @param enable_external
- *                 Non zero if you want external loopback
- *
- * @return Zero on success, negative on failure.
- */
-extern int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port,
-						     int enable_internal,
-						     int enable_external);
-
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-helper.h b/arch/mips/include/asm/octeon/cvmx-helper.h
index 5ea02cd..90c3029 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper.h
@@ -42,7 +42,7 @@
  *
  * Helper functions for common, but complicated tasks.
  *
- * <hr>$Revision: 86434 $<hr>
+ * <hr>$Revision: 94800 $<hr>
  */
 
 #ifndef __CVMX_HELPER_H__
@@ -128,6 +128,8 @@ typedef enum {
 	CVMX_HELPER_INTERFACE_MODE_RXAUI,
 	CVMX_HELPER_INTERFACE_MODE_QSGMII,
 	CVMX_HELPER_INTERFACE_MODE_AGL,
+	CVMX_HELPER_INTERFACE_MODE_XLAUI,
+	CVMX_HELPER_INTERFACE_MODE_XFI,
 } cvmx_helper_interface_mode_t;
 
 typedef union {
@@ -163,15 +165,6 @@ void cvmx_rgmii_set_back_pressure(uint64_t backpressure_dis);
 #include "cvmx-helper-xaui.h"
 
 /**
- * cvmx_override_pko_queue_priority(int ipd_port, uint64_t
- * priorities[16]) is a function pointer. It is meant to allow
- * customization of the PKO queue priorities based on the port
- * number. Users should set this pointer to a function before
- * calling any cvmx-helper operations.
- */
-extern CVMX_SHARED void (*cvmx_override_pko_queue_priority) (int ipd_port, uint64_t * priorities);
-
-/**
  * cvmx_override_iface_phy_mode(int interface, int index) is a function pointer.
  * It is meant to allow customization of interfaces which do not have a PHY.
  *
@@ -381,6 +374,66 @@ extern int cvmx_helper_configure_loopback(int ipd_port, int enable_internal, int
  */
 int __cvmx_helper_early_ports_on_interface(int interface);
 
+void cvmx_helper_setup_simulator_io_buffer_counts(int node, int num_packet_buffers,
+		int pko_buffers);
+
+void cvmx_helper_set_wqe_no_ptr_mode(bool mode);
+void cvmx_helper_set_pkt_wqe_le_mode(bool mode);
+int cvmx_helper_shutdown_fpa_pools(int node);
+
+
+/**
+ * Convert Ethernet QoS/PCP value to system-level priority
+ *
+ * In OCTEON, highest priority is 0, in Ethernet 802.1p PCP field
+ * the highest priority is 7, lowest is 1. Here is the full conversion
+ * table between QoS (PCP) and OCTEON priority values, per IEEE 802.1Q-2005:
+ *
+ * PCP 	Priority 	Acronym 	Traffic Types
+ * 1 	7 (lowest) 	BK 	Background
+ * 0 	6 	BE 	Best Effort
+ * 2 	5 	EE 	Excellent Effort
+ * 3 	4 	CA 	Critical Applications
+ * 4 	3 	VI 	Video, < 100 ms latency and jitter
+ * 5 	2 	VO 	Voice, < 10 ms latency and jitter
+ * 6 	1 	IC 	Internetwork Control
+ * 7 	0 (highest) 	NC 	Network Control
+ */
+static inline uint8_t cvmx_helper_qos2prio(uint8_t qos)
+{
+	static const unsigned pcp_map =
+		6 << (4 * 0) |
+		7 << (4 * 1) |
+		5 << (4 * 2) |
+		4 << (4 * 3) |
+		3 << (4 * 4) |
+		2 << (4 * 5) |
+		1 << (4 * 6) |
+		0 << (4 * 7);
+
+	return (pcp_map >> ((qos & 0x7) << 2)) & 0x7;
+}
+
+/**
+ * Convert system-level priority to Ethernet QoS/PCP value
+ *
+ * Calculate the reverse of cvmx_helper_qos2prio() per IEEE 802.1Q-2005.
+ */
+static inline uint8_t cvmx_helper_prio2qos(uint8_t prio)
+{
+	static const unsigned prio_map =
+		7 << (4 * 0) |
+		6 << (4 * 1) |
+		5 << (4 * 2) |
+		4 << (4 * 3) |
+		3 << (4 * 4) |
+		2 << (4 * 5) |
+		0 << (4 * 6) |
+		1 << (4 * 7);
+
+	return (prio_map >> ((prio & 0x7) << 2)) & 0x7;
+}
+
 #ifdef  __cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-hna-defs.h b/arch/mips/include/asm/octeon/cvmx-hna-defs.h
index b802478..dc853dd 100644
--- a/arch/mips/include/asm/octeon/cvmx-hna-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-hna-defs.h
@@ -141,6 +141,72 @@ static inline uint64_t CVMX_HNA_ERROR_FUNC(void)
 #define CVMX_HNA_ERROR (CVMX_ADD_IO_SEG(0x0001180047000028ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_ERROR_CAPTURE_DATA CVMX_HNA_ERROR_CAPTURE_DATA_FUNC()
+static inline uint64_t CVMX_HNA_ERROR_CAPTURE_DATA_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_ERROR_CAPTURE_DATA not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000038ull);
+}
+#else
+#define CVMX_HNA_ERROR_CAPTURE_DATA (CVMX_ADD_IO_SEG(0x0001180047000038ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_HNA_ERROR_CAPTURE_INFO CVMX_HNA_ERROR_CAPTURE_INFO_FUNC()
+static inline uint64_t CVMX_HNA_ERROR_CAPTURE_INFO_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_HNA_ERROR_CAPTURE_INFO not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180047000030ull);
+}
+#else
+#define CVMX_HNA_ERROR_CAPTURE_INFO (CVMX_ADD_IO_SEG(0x0001180047000030ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_HNA_HNC0_RAM1X(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 63)))))
+		cvmx_warn("CVMX_HNA_HNC0_RAM1X(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001470400000000ull) + ((offset) & 63) * 8;
+}
+#else
+#define CVMX_HNA_HNC0_RAM1X(offset) (CVMX_ADD_IO_SEG(0x0001470400000000ull) + ((offset) & 63) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_HNA_HNC0_RAM2X(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 63)))))
+		cvmx_warn("CVMX_HNA_HNC0_RAM2X(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001470400040000ull) + ((offset) & 63) * 8;
+}
+#else
+#define CVMX_HNA_HNC0_RAM2X(offset) (CVMX_ADD_IO_SEG(0x0001470400040000ull) + ((offset) & 63) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_HNA_HNC1_RAM1X(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 63)))))
+		cvmx_warn("CVMX_HNA_HNC1_RAM1X(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001470400400000ull) + ((offset) & 63) * 8;
+}
+#else
+#define CVMX_HNA_HNC1_RAM1X(offset) (CVMX_ADD_IO_SEG(0x0001470400400000ull) + ((offset) & 63) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_HNA_HNC1_RAM2X(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 63)))))
+		cvmx_warn("CVMX_HNA_HNC1_RAM2X(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001470400440000ull) + ((offset) & 63) * 8;
+}
+#else
+#define CVMX_HNA_HNC1_RAM2X(offset) (CVMX_ADD_IO_SEG(0x0001470400440000ull) + ((offset) & 63) * 8)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_HNA_HPU_CSR CVMX_HNA_HPU_CSR_FUNC()
 static inline uint64_t CVMX_HNA_HPU_CSR_FUNC(void)
 {
@@ -320,29 +386,21 @@ static inline uint64_t CVMX_HNA_SBD_DBG3_FUNC(void)
 /**
  * cvmx_hna_bist0
  *
- * Description:
- *
+ * This register shows the result of the BIST run on the HNA (per-HPU).
+ * 1 = BIST error, 0 = BIST passed, is in progress, or never ran.
  */
 union cvmx_hna_bist0 {
 	uint64_t u64;
 	struct cvmx_hna_bist0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
-	uint64_t hpc3                         : 12; /**< Bist Results for HPC3 RAM(s) (per-HPU)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
+	uint64_t hpc3                         : 12; /**< BIST results for HPC3 RAM(s) (per-HPU). */
 	uint64_t reserved_44_47               : 4;
-	uint64_t hpc2                         : 12; /**< Bist Results for HPC2 RAM(s) (per-HPU)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
+	uint64_t hpc2                         : 12; /**< BIST results for HPC2 RAM(s) (per-HPU). */
 	uint64_t reserved_28_31               : 4;
-	uint64_t hpc1                         : 12; /**< Bist Results for HPC1 RAM(s) (per-HPU)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
+	uint64_t hpc1                         : 12; /**< BIST results for HPC1 RAM(s) (per-HPU). */
 	uint64_t reserved_12_15               : 4;
-	uint64_t hpc0                         : 12; /**< Bist Results for HPC0 RAM(s) (per-HPU)
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
+	uint64_t hpc0                         : 12; /**< BIST results for HPC0 RAM(s) (per-HPU). */
 #else
 	uint64_t hpc0                         : 12;
 	uint64_t reserved_12_15               : 4;
@@ -361,30 +419,20 @@ typedef union cvmx_hna_bist0 cvmx_hna_bist0_t;
 /**
  * cvmx_hna_bist1
  *
- * Description:
- *
+ * This register shows the result of the BIST run on the HNA (globals).
+ * 1 = BIST error, 0 = BIST passed, is in progress, or never ran.
  */
 union cvmx_hna_bist1 {
 	uint64_t u64;
 	struct cvmx_hna_bist1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_7_63                : 57;
-	uint64_t hnc1                         : 1;  /**< "SC1 Bist Results for cumulative HNC1 RAMs
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t hnc0                         : 1;  /**< "SC0 Bist Results for cumulative HNC0 RAMs
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD" */
-	uint64_t mrp1                         : 1;  /**< Bist Results for DSM-DLC:MRP1 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
-	uint64_t mrp0                         : 1;  /**< Bist Results for DSM-DLC:MRP0 RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
+	uint64_t hnc1                         : 1;  /**< SC1 BIST results for cumulative HNC1 RAMs. */
+	uint64_t hnc0                         : 1;  /**< SC0 BIST results for cumulative HNC0 RAMs. */
+	uint64_t mrp1                         : 1;  /**< BIST results for DSM-DLC:MRP1 RAM. */
+	uint64_t mrp0                         : 1;  /**< BIST results for DSM-DLC:MRP0 RAM. */
 	uint64_t reserved_1_2                 : 2;
-	uint64_t gib                          : 1;  /**< Bist Results for GIB RAM
-                                                         - 0: GOOD (or bist in progress/never run)
-                                                         - 1: BAD */
+	uint64_t gib                          : 1;  /**< BIST results for GIB RAM. */
 #else
 	uint64_t gib                          : 1;
 	uint64_t reserved_1_2                 : 2;
@@ -410,101 +458,81 @@ union cvmx_hna_config {
 	struct cvmx_hna_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
-	uint64_t stk_ll_dis                   : 1;  /**< Stack Linked-List Disable.
-                                                         When set, the linked-list mechanism for run stack
-                                                         and save stack structures will be disabled.  In this mode,
-                                                         the linked-list chunk boundary checking is not done, and
-                                                         therefore the previous/next pointers are non-existent.  The
-                                                         stacks are effectively in an infinite linear buffer, bounded
-                                                         only by the maximum sizes provided in the instruction
-                                                         (IWORD3[RUNSTACKSZ] and IWORD6[SVSTACKSZ]).  There is no
-                                                         space reserved for the previous and next pointers, and
-                                                         [STK_CHKSZ] will be ignored.
-                                                         When the STK_LL_DIS is cleared, the stack linked-list mechanism
-                                                         will operate as per spec. */
+	uint64_t stk_ll_dis                   : 1;  /**< Stack linked-list disable. When set, the linked-list mechanism for run stack and save
+                                                         stack structures is disabled. In this mode, the linked-list chunk boundary checking is not
+                                                         done, and therefore the previous/next pointers are non-existent. The stacks are
+                                                         effectively in an infinite linear buffer, bounded only by the maximum sizes provided in
+                                                         the instruction (IWORD3[RUNSTACKSZ] and IWORD6[SVSTACKSZ]). There is no space reserved for
+                                                         the previous and next pointers, and [STK_CHKSZ] is ignored.
+                                                         When the STK_LL_DIS is cleared, the stack linked-list mechanism operates as per spec. */
 	uint64_t reserved_23_23               : 1;
-	uint64_t stk_chksz                    : 3;  /**< Stack Chunk Size
-                                                          This encoded value specifies the chunk size for both the RNSTK/SVSTK data structures.
-                                                          The RNSTK/SVSTK use a doubly linked list where EACH Chunk's first two 64bit
-                                                          entries contain the PREVIOUS and NEXT chunk pointers.
-                                                         - 0: 32 entries or 256 bytes
-                                                         - 1: 64 entries or 512 Bytes
-                                                         - 2: 128 entries or 1K bytes
-                                                         - 3: 256 entries or 2K bytes    <= DEFAULT power on
-                                                         - 4: 512 entries or 4K bytes
-                                                         - 5: 1024 entries or 8K bytes
-                                                         - 6: 2048 entries or 16K bytes
-                                                         - 7: 4096 entries or 32K bytes
-                                                          NOTE: This field can only be changed at initialization/power on time before
-                                                          the HNA is fed instructions. */
-	uint64_t rnstk_lwm                    : 4;  /**< "RNSTK Low Water Mark
-                                                         This field specifies the low watermark for the run stack. Valid Range: [0..15]
-                                                         Once the run stack goes below the low water mark, HNA will fill entries from the
-                                                         global run stack head to the local run stack tail.
-                                                         The granularity of this field is represented as number of 128B cachelines.
-                                                         NOTE: This field can only be changed at initialization/power on time before
-                                                         the HNA is fed instructions." */
-	uint64_t rnstk_hwm                    : 4;  /**< "RNSTK High Water Mark
-                                                         This field specifies the hi watermark for the run stack. Valid Range: [0..15]
-                                                         Once the local run stack level goes above the hi water mark, the HNA will spill
-                                                         entries from the local run stack tail to the global run stack head (in DDR memory).
-                                                         The granularity of this field is represented as number of 128B cachelines.
-                                                         NOTE: This field can only be changed at initialization/power on time before
-                                                         the HNA is fed instructions." */
+	uint64_t stk_chksz                    : 3;  /**< Stack chunk size. This encoded value specifies the chunk size for both the RNSTK/SVSTK
+                                                         data structures. The RNSTK/SVSTK use a doubly linked list where each chunk's first two
+                                                         64-bit entries contain the previous and next chunk pointers.
+                                                         0x0 = 32 entries or 256 bytes
+                                                         0x1 = 64 entries or 512 bytes
+                                                         0x2 = 128 entries or 1K bytes
+                                                         0x3 = 256 entries or 2K bytes -> default power on
+                                                         0x4 = 512 entries or 4K bytes
+                                                         0x5 = 1024 entries or 8K bytes
+                                                         0x6 = 2048 entries or 16K bytes
+                                                         0x7 = 4096 entries or 32K bytes
+                                                         NOTE: This field can only be changed at initialization/power on time before the HNA is fed
+                                                         instructions. */
+	uint64_t rnstk_lwm                    : 4;  /**< RNSTK low watermark. This field specifies the low watermark for the run stack. Valid
+                                                         range: 0-15.
+                                                         Once the run stack goes below the low watermark, HNA fills entries from the global run
+                                                         stack head to the local run stack tail. The granularity of this field is represented as
+                                                         number of 128B cachelines.
+                                                         NOTE: This field can only be changed at initialization/power on time before the HNA is fed
+                                                         instructions. */
+	uint64_t rnstk_hwm                    : 4;  /**< RNSTK high watermark. This field specifies the high watermark for the run stack. Valid
+                                                         range: 0-15.
+                                                         Once the local run stack level goes above the high watermark, the HNA spills entries from
+                                                         the local run stack tail to the global run stack head (in DDR memory). The granularity of
+                                                         this field is represented as number of 128B cachelines.
+                                                         NOTE: This field can only be changed at initialization/power on time before the HNA is fed
+                                                         instructions. */
 	uint64_t reserved_9_11                : 3;
-	uint64_t ecccordis                    : 1;  /**< ECC Correction Disable
-                                                         When set, all HNA ECC protected data structures will disable their ECC correction
-                                                         logic. When clear (default) ECC correction is always enabled. */
-	uint64_t clmskcrip                    : 4;  /**< Cluster Cripple Mask
-                                                         A one in each bit of the mask represents which HPC cluster to
-                                                         cripple. o78 HNA has 4 clusters, where all CLMSKCRIP mask bits are used.
-                                                         SWNOTE: The MIO_FUS___HNA_CLMASK_CRIPPLE[3:0] fuse bits will
-                                                         be forced into this register at reset. Any fuse bits that
-                                                         contain '1' will be disallowed during a write and will always
-                                                         be read as '1'. */
-	uint64_t hpu_clcrip                   : 3;  /**< "HPU Cluster Cripple
-                                                         Encoding which represents number of HPUs to cripple for each
-                                                         cluster. Typically HPU_CLCRIP=0 which enables all HPUs
-                                                         within each cluster. However, when the HNA performance
-                                                         counters are used, SW may want to limit the number of HPUs
-                                                         per cluster available, as there are only 4 parallel
-                                                         performance counters.
-                                                         HPU_CLCRIP | \#HPUs crippled(per cluster)
-                                                         -----------+-----------------------------
-                                                            0       |  0      HPU[9:0]:ON                   All engines enabled
-                                                            1       |  1      HPU[9]:OFF    /HPU[8:0]:ON    (n-1) engines enabled
-                                                            2       |  3      HPU[9:7]:OFF  /HPU[6:0]:ON    (n-3) engines enabled
-                                                            3       |  4      HPU[9:6]:OFF  /HPU[5:0]:ON    (n-4) engines enabled
-                                                            4       |  5      HPU[9:5]:OFF  /HPU[4:0]:ON    (n-5) engines enabled
-                                                            5       |  6      HPU[9:4]:OFF  /HPU[3:0]:ON    (n-6) engines enabled
-                                                            6       |  8      HPU[9:2]:OFF  /HPU[1:0]:ON    (n-8) engines enabled
-                                                            7       |  9      HPU[9:1]:OFF  /HPU[0]:ON      (n-9) single engine enabled
-                                                         NOTE: Higher numbered HPUs are crippled first. For instance,
-                                                         on o78 (with 10 HPUs/cluster), if HPU_CLCRIP=0x1, then
-                                                         HPU#s [9] within the cluster are crippled and only
+	uint64_t ecccordis                    : 1;  /**< ECC correction disable. When set, all HNA ECC protected data structures disable their ECC
+                                                         correction logic. When clear (default) ECC correction is always enabled. */
+	uint64_t clmskcrip                    : 4;  /**< Cluster cripple mask. A one in each bit of the mask represents which HPC cluster to
+                                                         cripple. CN78XX HNA has 4 clusters, where all CLMSKCRIP mask bits are used.
+                                                         Software NOTE: The MIO_FUS___HNA_CLMASK_CRIPPLE[3:0] fuse bits are forced into this
+                                                         register at reset. Any fuse bits that contain 1 are disallowed during a write and are
+                                                         always read as 1. */
+	uint64_t hpu_clcrip                   : 3;  /**< "HPU cluster cripple. Encoding which represents number of HPUs to cripple for each
+                                                         cluster. Typically HPU_CLCRIP=0x0, which enables all HPUs within each cluster. However,
+                                                         when the HNA performance counters are used, software may want to limit the number of HPUs
+                                                         per cluster available, as there are only 4 parallel performance counters.
+                                                         HPU_CLCRIP \#HPUs crippled (per cluster)
+                                                         0x0 0 HPU[9:0]:ON, All engines enabled
+                                                         0x1 1 HPU[9]:OFF /HPU[8:0]:ON, (n-1) engines enabled
+                                                         0x2 3 HPU[9:7]:OFF /HPU[6:0]:ON, (n-3) engines enabled
+                                                         0x3 4 HPU[9:6]:OFF /HPU[5:0]:ON, (n-4) engines enabled
+                                                         0x4 5 HPU[9:5]:OFF /HPU[4:0]:ON, (n-5) engines enabled
+                                                         0x5 6 HPU[9:4]:OFF /HPU[3:0]:ON, (n-6) engines enabled
+                                                         0x6 8 HPU[9:2]:OFF /HPU[1:0]:ON, (n-8) engines enabled
+                                                         0x7 9 HPU[9:1]:OFF /HPU[0]:ON, (n-9) 1 engine enabled
+                                                         NOTE: Higher numbered HPUs are crippled first. For instance, on CN78XX (with 10
+                                                         HPUs/cluster), if HPU_CLCRIP=0x1, then HPU \#s [9] within the cluster are crippled and only
                                                          HPU#s [8:0] are available.
-                                                         IMPNOTE: The encodings are done in such a way as to later
-                                                         be used with fuses (for future revisions which will disable
-                                                         some number of HPUs). Blowing a fuse has the effect that there will
-                                                         always be fewer HPUs available. [ie: we never want a customer
-                                                         to blow additional fuses to get more HPUs].
-                                                         SWNOTE: The MIO_FUS___HNA_NUMHPU_CRIPPLE[2:0] fuse bits will
-                                                         be forced into this register at reset. Any fuse bits that
-                                                         contain '1' will be disallowed during a write and will always
-                                                         be read as '1'." */
-	uint64_t hpuclkdis                    : 1;  /**< HNA Clock Disable Source
-                                                         When SET, the HNA clocks for HPU(thread engine)
-                                                         operation are disabled (to conserve overall chip clocking
-                                                         power when the HNA function is not used).
-                                                         NOTE: When SET, SW MUST NEVER issue NCB-Direct CSR
-                                                         operations to the HNA (will result in NCB Bus Timeout
-                                                         errors).
-                                                         NOTE: This should only be written to a different value
-                                                         during power-on SW initialization.
-                                                         SWNOTE: The MIO_FUS___HNA_HPU_DISABLE fuse bit will
-                                                         be forced into this register at reset. If the fuse bit
-                                                         contains '1', writes to HPUCLKDIS are disallowed and
-                                                         will always be read as '1'. */
+                                                         IMPNOTE: The encodings are done in such a way as to later be used with fuses (for future
+                                                         revisions which will disable some number of HPUs). Blowing a fuse has the effect that
+                                                         there will always be fewer HPUs available. [i.e: we never want a customer to blow
+                                                         additional fuses to get more HPUs].
+                                                         Software NOTE: The MIO_FUS___HNA_NUMHPU_CRIPPLE[2:0] fuse bits are forced into this
+                                                         register at reset. Any fuse bits that contain 1 are disallowed during a write and are
+                                                         always read as 1." */
+	uint64_t hpuclkdis                    : 1;  /**< HNA clock disable source. When set, the HNA clocks for HPU (thread engine) operation are
+                                                         disabled (to conserve overall chip clocking power when the HNA function is not used).
+                                                         NOTE: When set, software must never issue NCB-direct CSR operations to the HNA (will
+                                                         result in NCB bus timeout errors).
+                                                         NOTE: This should only be written to a different value during power-on software
+                                                         initialization.
+                                                         Software NOTE: The MIO_FUS___HNA_HPU_DISABLE fuse bit is forced into this register at
+                                                         reset. If the fuse bit contains 1, writes to HPUCLKDIS are disallowed and are always read
+                                                         as 1. */
 #else
 	uint64_t hpuclkdis                    : 1;
 	uint64_t hpu_clcrip                   : 3;
@@ -534,38 +562,28 @@ union cvmx_hna_control {
 	struct cvmx_hna_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
-	uint64_t frcperr                      : 1;  /**< Force Parity Error during CLOAD (HNC-write)
-                                                         When SET, a parity error is forced during the HNC CLOAD
-                                                         instruction. SW can force a single line in the HNC to contain
-                                                         a parity error by setting this bit and performance a CLOAD
-                                                         for a single line (DLEN=32), then clearing the bit. */
-	uint64_t sbdnum                       : 6;  /**< "SBD Debug Entry#
-                                                         INTERNAL:
-                                                         HNA Scoreboard debug control
-                                                         Selects which one of 48 HNA Scoreboard entries is
-                                                         latched into the HNA_SBD_DBG[0-3] registers." */
-	uint64_t sbdlck                       : 1;  /**< HNA Scoreboard LOCK Strobe
-                                                         INTERNAL:
-                                                         HNA Scoreboard debug control
-                                                         When written with a '1', the HNA Scoreboard Debug
-                                                         registers (HNA_SBD_DBG[0-3]) are all locked down.
-                                                         This allows SW to lock down the contents of the entire
-                                                         SBD for a single instant in time. All subsequent reads
-                                                         of the HNA scoreboard registers will return the data
-                                                         from that instant in time. */
+	uint64_t frcperr                      : 1;  /**< Force parity error during an OCM load. When set, a parity error is forced during the OCM
+                                                         load instruction. Software can force a single line to contain a parity error by setting
+                                                         this bit and performance a OCM load for a single line (DLEN=32), then clearing the bit. */
+	uint64_t sbdnum                       : 6;  /**< Reserved. SBD debug entry number.
+                                                         INTERNAL: HNA Scoreboard debug control. Selects which one of 48 HNA Scoreboard entries is
+                                                         latched into the HNA_SBD_DBG[0-3] registers. */
+	uint64_t sbdlck                       : 1;  /**< Reserved. HNA scoreboard lock strobe. INTERNAL: HNA Scoreboard debug control. When written
+                                                         with a '1', the HNA Scoreboard Debug registers (HNA_SBD_DBG[0-3]) are all locked down.
+                                                         This allows SW to lock down the contents of the entire SBD for a single instant in time.
+                                                         All subsequent reads of the HNA scoreboard registers will return the data from that
+                                                         instant in time. */
 	uint64_t reserved_3_4                 : 2;
-	uint64_t pmode                        : 1;  /**< NCB-NRP Arbiter Mode
-                                                         (0=Fixed Priority [LP=DFF,HP=RGF]/1=RR
-                                                         NOTE: This should only be written to a different value
-                                                         during power-on SW initialization. */
-	uint64_t qmode                        : 1;  /**< NCB-NRQ Arbiter Mode
-                                                         (0=Fixed Priority [LP=NPF,IRF,WRF,PRF,RSRF,HP=SLL]/1=RR
-                                                         NOTE: This should only be written to a different value
-                                                         during power-on SW initialization. */
-	uint64_t imode                        : 1;  /**< NCB-Inbound Arbiter
-                                                         (0=FP [LP=NRQ,HP=NRP], 1=RR)
-                                                         NOTE: This should only be written to a different value
-                                                         during power-on SW initialization. */
+	uint64_t pmode                        : 1;  /**< Reserved. NCB-NRP arbiter mode. (0=Fixed Priority [LP=DFF,HP=RGF]/1=RR
+                                                         NOTE: This should only be written to a different value during power-on software
+                                                         initialization. */
+	uint64_t qmode                        : 1;  /**< Reserved. NCB-NRQ arbiter mode. 0 = Fixed priority (LP = NPF, IRF, WRF, PRF, RSRF, HP =
+                                                         SLL); 1 = Round robin.
+                                                         NOTE: This should only be written to a different value during power-on software
+                                                         initialization. */
+	uint64_t imode                        : 1;  /**< Reserved. NCB-inbound arbiter. 0 = Fixed priority (LP = NRQ, HP = NRP); 1 = Round robin).
+                                                         NOTE: This should only be written to a different value during power-on software
+                                                         initialization. */
 #else
 	uint64_t imode                        : 1;
 	uint64_t qmode                        : 1;
@@ -584,33 +602,25 @@ typedef union cvmx_hna_control cvmx_hna_control_t;
 /**
  * cvmx_hna_dbell
  *
- * Description:
- * NOTE: To write to the HNA_DBELL register, a device would issue an IOBST directed at the HNA
- * with addr[34:32] = 0x0 or 0x1.
- * To read the HNA_DBELL register, a device would issue an IOBLD64 directed at the HNA with
- * addr[34:32] = 0x0 or 0x1.
- * NOTE: If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to the HNA_DBELL
+ * To write to the HNA_DBELL register, a device issues an IOBST directed at the HNA with
+ * addr[34:32] = 0x0 or 0x1. To read the HNA_DBELL register, a device issues an IOBLD64 directed
+ * at the HNA with addr[34:32] = 0x0 or 0x1.
+ * If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to the HNA_DBELL register
+ * do not take effect. If FUSE[TBD] = 'HNA HPU disable' is blown, reads/writes to the HNA_DBELL
  * register do not take effect.
- * NOTE: If FUSE[TBD]="HNA HPU disable" is blown, reads/writes to the HNA_DBELL register do not
- * take effect.
  */
 union cvmx_hna_dbell {
 	uint64_t u64;
 	struct cvmx_hna_dbell_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t dbell                        : 20; /**< Represents the cumulative total of pending
-                                                         HNA instructions which SW has previously written
-                                                         into the HNA Instruction FIFO (DIF) in main memory.
-                                                         Each HNA instruction contains a fixed size 64B
-                                                         instruction word which is executed by the HNA HW.
-                                                         The DBELL field can hold up to 1M-1 (2^20-1)
-                                                         pending HNA instruction requests.
-                                                         During a read (by SW), the 'most recent' contents
-                                                         of the HNA_DBELL register are returned at the time
-                                                         the NCB-INB bus is driven.
-                                                         NOTE: Since HNA HW updates this register, its
-                                                         contents are unpredictable in SW. */
+	uint64_t dbell                        : 20; /**< Represents the cumulative total of pending HNA instructions that software has previously
+                                                         written into the HNA instruction FIFO (DIF) in main memory. Each HNA instruction contains
+                                                         a fixed size 64B instruction word which is executed by the HNA hardware. The DBELL field
+                                                         can hold up to 1M-1 (2^20-1) pending HNA instruction requests. During a software read, the
+                                                         most recent contents of HNA_DBELL are returned at the time the NCB-INB bus is driven.
+                                                         NOTE: Since HNA hardware updates this register, its contents are unpredictable in
+                                                         software. */
 #else
 	uint64_t dbell                        : 20;
 	uint64_t reserved_20_63               : 44;
@@ -623,49 +633,37 @@ typedef union cvmx_hna_dbell cvmx_hna_dbell_t;
 /**
  * cvmx_hna_difctl
  *
- * Description:
- * NOTE: To write to the HNA_DIFCTL register, a device would issue an IOBST directed at the HNA
- * with addr[34:32]=0x6.
- * To read the HNA_DIFCTL register, a device would issue an IOBLD64 directed at the HNA with
- * addr[34:32]=0x6.
- * NOTE: This register is intended to ONLY be written once (at power-up). Any future writes could
- * cause the HNA and FPA HW to become unpredictable.
- * NOTE: If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to the HNA_DIFCTL
- * register do not take effect.
- * NOTE: If FUSE[TBD]="HNA HPU disable" is blown, reads/writes to the HNA_DIFCTL register do not
- * take effect.
+ * To write to the HNA_DIFCTL register, a device issues an IOBST directed at the HNA with
+ * addr[34:32]=0x6. To read the HNA_DIFCTL register, a device issues an IOBLD64 directed at the
+ * HNA with addr[34:32]=0x6.
+ * This register is intended to only be written once (at power-up). Any future writes could cause
+ * the HNA and FPA hardware to become unpredictable. If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks
+ * disabled), reads/writes to HNA_DIFCTL do not take effect. If FUSE[TBD] = 'HNA HPU disable' is
+ * blown, reads/writes to HNA_DIFCTL do not take effect.
  */
 union cvmx_hna_difctl {
 	uint64_t u64;
 	struct cvmx_hna_difctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
-	uint64_t aura                         : 16; /**< Represents the 16bit Aura-id  used by HNA HW
-                                                         when the HNA instruction chunk is recycled back
-                                                         to the Free Page List maintained by the FPA HW
-                                                         (once the HNA instruction has been issued). */
+	uint64_t aura                         : 16; /**< Represents the 16-bit Aura ID used by HNA hardware when the HNA instruction chunk is
+                                                         recycled back to the Free Page List maintained by FPA (once the HNA instruction has been
+                                                         issued). */
 	uint64_t reserved_13_25               : 13;
-	uint64_t ldwb                         : 1;  /**< Load Don't Write Back.
-                                                         When set, the HW will issue LDWB command towards the cache when
-                                                         fetching last word of instructions, as a result the line will not be written back when
-                                                         replaced.
-                                                         When clear, the HW will issue regular load towards cache which will cause
-                                                         the line to be written back before being replaced. */
+	uint64_t ldwb                         : 1;  /**< Load Don't Write Back. When set, the hardware issues LDWB command towards the cache when
+                                                         fetching last word of instructions; as a result the line is not written back when
+                                                         replaced. When clear, the hardware issues regular load towards cache which will cause the
+                                                         line to be written back before being replaced. */
 	uint64_t reserved_9_11                : 3;
-	uint64_t size                         : 9;  /**< "Represents the number of 64B instructions contained
-                                                         within each HNA instruction chunk. At Power-on,
-                                                         SW will seed the SIZE register with a fixed
-                                                         chunk-size. (Must be at least 3)
-                                                         HNA HW uses this field to determine the size
-                                                         of each HNA instruction chunk, in order to:
-                                                         a) determine when to read the next HNA
-                                                         instruction chunk pointer which is
-                                                         written by SW at the end of the current
-                                                         HNA instruction chunk (see HNA description
-                                                         of next chunk buffer Ptr for format).
-                                                         b) determine when a HNA instruction chunk
-                                                         can be returned to the Free Page List
-                                                         maintained by the FPA HW." */
+	uint64_t size                         : 9;  /**< Represents the number of 64B instructions contained within each HNA instruction chunk. At
+                                                         power-on, software seeds the SIZE register with a fixed chunk size (must be at least 3).
+                                                         HNA hardware uses this field to determine the size of each HNA instruction chunk, in order
+                                                         to:
+                                                         a) determine when to read the next HNA instruction chunk pointer which is written by
+                                                         software at the end of the current HNA instruction chunk (see HNA description of next
+                                                         chunk buffer Ptr for format).
+                                                         b) determine when a HNA instruction chunk can be returned to the Free Page List maintained
+                                                         by FPA */
 #else
 	uint64_t size                         : 9;
 	uint64_t reserved_9_11                : 3;
@@ -682,36 +680,26 @@ typedef union cvmx_hna_difctl cvmx_hna_difctl_t;
 /**
  * cvmx_hna_difrdptr
  *
- * Description:
- * NOTE: To write to the HNA_DIFRDPTR register, a device would issue an IOBST directed at the HNA
- * with addr[34:32] = 0x2 or 0x3.
- * To read the HNA_DIFRDPTR register, a device would issue an IOBLD64 directed at the HNA with
- * addr[34:32] = 0x2 or 0x3.
- * NOTE: If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to the HNA_DIFRDPTR
- * register do not take effect.
- * NOTE: If FUSE[TBD]="HNA HPU disable" is blown, reads/writes to the HNA_DIFRDPTR register do
- * not take effect.
+ * To write to the HNA_DIFRDPTR register, a device issues an IOBST directed at the HNA with
+ * addr[34:32] = 0x2 or 0x3. To read the HNA_DIFRDPTR register, a device issues an IOBLD64
+ * directed at the HNA with addr[34:32] = 0x2 or 0x3.
+ * If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to HNA_DIFRDPTR do not take
+ * effect. If FUSE[TBD] = 'HNA HPU disable' is blown, reads/writes to HNA_DIFRDPTR do not take
+ * effect.
  */
 union cvmx_hna_difrdptr {
 	uint64_t u64;
 	struct cvmx_hna_difrdptr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
-	uint64_t rdptr                        : 36; /**< Represents the 64B-aligned address of the current
-                                                         instruction in the HNA Instruction FIFO in main
-                                                         memory. The RDPTR must be seeded by software at
-                                                         boot time, and is then maintained thereafter
-                                                         by HNA HW.
-                                                         During the seed write (by SW), RDPTR[6]=0,
-                                                         since HNA instruction chunks must be 128B aligned.
-                                                         During a read (by SW), the 'most recent' contents
-                                                         of the RDPTR register are returned at the time
-                                                         the NCB-INB bus is driven.
-                                                         NOTE: Since HNA HW updates this register, its
-                                                         contents are unpredictable in SW (unless
-                                                         its guaranteed that no new DoorBell register
-                                                         writes have occurred and the DoorBell register is
-                                                         read as zero). */
+	uint64_t rdptr                        : 36; /**< Represents the 64B-aligned address of the current instruction in the HNA Instruction FIFO
+                                                         in main memory. The RDPTR must be seeded by software at boot time, and is then maintained
+                                                         thereafter by HNA hardware. During the software seed write, RDPTR[6]=0, since HNA
+                                                         instruction chunks must be 128B aligned. During a software read, the most recent contents
+                                                         of RDPTR are returned at the time the NCB-INB bus is driven.
+                                                         NOTE: Since HNA hardware updates this register, its contents are unpredictable in software
+                                                         (unless it is guaranteed that no new doorbell register writes have occurred and HNA_DBELL
+                                                         is read as zero). */
 	uint64_t reserved_0_5                 : 6;
 #else
 	uint64_t reserved_0_5                 : 6;
@@ -733,82 +721,76 @@ union cvmx_hna_error {
 	uint64_t u64;
 	struct cvmx_hna_error_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_20_63               : 44;
-	uint64_t osmerr                       : 1;  /**< OSM reported an Error with the response data. */
-	uint64_t replerr                      : 1;  /**< HNA Illegal Replication Factor Error
-                                                         HNA only supports 1x, 2x, and 4x port replication.
-                                                         Legal configurations for memory are to support 2 port or
-                                                         4 port configurations.
-                                                         The REPLERR interrupt will be set in the following illegal
-                                                         configuration cases:
-                                                         1) An 8x replication factor is detected for any memory reference.
-                                                         2) A 4x replication factor is detected for any memory reference
-                                                         when only 2 memory ports are enabled.
-                                                         NOTE: If REPLERR is set during a HNA Graph Walk operation,
-                                                         then the walk will prematurely terminate with RWORD0[REA]=ERR.
-                                                         If REPLERR is set during a NCB-Direct CSR read access to HNA
-                                                         Memory REGION, then the CSR read response data is UNPREDICTABLE. */
-	uint64_t hnanxm                       : 1;  /**< HNA Non-existent Memory Access
-                                                         HPUs (and backdoor CSR HNA Memory REGION reads)
-                                                         have access to the following 40bit L2/DRAM address space
-                                                         which maps to a 38bit physical DDR3 SDRAM address space [256GB(max)].
-                                                         see:
+	uint64_t reserved_21_63               : 43;
+	uint64_t hnc_parerr                   : 1;  /**< HNC reported parity error with the response data. */
+	uint64_t osmerr                       : 1;  /**< OSM reported an error with the response data. */
+	uint64_t replerr                      : 1;  /**< HNA illegal replication factor error. HNA only supports 1*, 2*, and 4* port replication.
+                                                         Legal configurations for memory are 2-port or 4-port configurations. The REPLERR interrupt
+                                                         is set in the following illegal configuration cases:
+                                                         1) An 8* replication factor is detected for any memory reference.
+                                                         2) A 4* replication factor is detected for any memory reference when only 2 memory ports
+                                                         are enabled.
+                                                         NOTE: If REPLERR is set during a HNA Graph Walk operation, the walk will prematurely
+                                                         terminate with RWORD0[REA] = ERR. */
+	uint64_t hnanxm                       : 1;  /**< HNA non-existent memory access. HPUs (and backdoor CSR HNA memory region reads) have
+                                                         access to the following 40-bit L2/DRAM address space which maps to a 38-bit physical
+                                                         DDR3/4 SDRAM address space (256 GB max).
                                                          DR0: 0x0 0000 0000 0000 to 0x0 0000 0FFF FFFF
-                                                         maps to lower 256MB of physical DDR3 SDRAM
+                                                         maps to lower 256MB of physical DDR3/4 SDRAM
                                                          DR1: 0x0 0000 2000 0000 to 0x0 0020 0FFF FFFF
-                                                         maps to upper 127.75GB of DDR3 SDRAM
-                                                         NOTE: the 2nd 256MB HOLE maps to IO and is unused(nonexistent) for memory.
-                                                         L2/DRAM address space                     Physical DDR3 SDRAM Address space
-                                                         (40bit address)                           (38bit address)
-                                                         +-----------+ 0x0040.0FFF.FFFF
-                                                         |   DR1     |                            +-----------+ 0x003F.FFFF.FFFF
-                                                         |           | (256GB-256MB)
-                                                         |           |                     =>     |   DR1
-                                                         +-----------+ 0x0000.1FFF.FFFF           |           | (256GB-256MB)
-                                                         |   HOLE    | 256MB (DO NOT USE)
-                                                         +-----------+ 0x0000.0FFF.FFFF           +-----------+ 0x0000.0FFF.FFFF
-                                                         |    DR0    | 256MB                      |   DR0     | (256MB)
-                                                         +-----------+ 0x0000.0000.0000           +-----------+ 0x0000.0000.0000
-                                                         In the event the HNA generates a reference to the L2/DRAM
-                                                         address hole (0x0000.0FFF.FFFF - 0x0000.1FFF.FFFF) the HNANXM
-                                                         programmable interrupt bit will be set.
-                                                         SWNOTE: Both the 1) SW HNA Graph compiler and the 2) SW NCB-Direct CSR
-                                                         accesses to HNA Memory REGION MUST avoid making references
-                                                         to this 2nd 256MB HOLE which is non-existent memory region.
-                                                         NOTE: If HNANXM is set during a HNA Graph Walk operation,
-                                                         then the walk will prematurely terminate with RWORD0[REA]=ERR.
-                                                         If HNANXM is set during a NCB-Direct CSR read access to HNA
-                                                         Memory REGION, then the CSR read response data is forced to
-                                                         128'hBADE_FEED_DEAD_BEEF_FACE_CAFE_BEAD_C0DE. (NOTE: the QW
-                                                         being accessed, either the upper or lower QW will be returned). */
-	uint64_t reserved_15_16               : 2;
-	uint64_t dlc1_ovferr                  : 1;  /**< DLC1 Fifo Overflow Error Detected
-                                                         This condition should NEVER architecturally occur, and
-                                                         is here in case HW credit/debit scheme is not working. */
-	uint64_t dlc0_ovferr                  : 1;  /**< DLC0 Fifo Overflow Error Detected
-                                                         This condition should NEVER architecturally occur, and
-                                                         is here in case HW credit/debit scheme is not working. */
-	uint64_t reserved_1_12                : 12;
-	uint64_t dblovf                       : 1;  /**< Doorbell Overflow detected - Status bit
-                                                         When set, the 20b accumulated doorbell register
-                                                         had overflowed (SW wrote too many doorbell requests).
-                                                         If the DBLINA had previously been enabled(set),
-                                                         an interrupt will be posted. Software can clear
-                                                         the interrupt by writing a 1 to this register bit.
-                                                         NOTE: Detection of a Doorbell Register overflow
-                                                         is a catastrophic error which may leave the HNA
-                                                         HW in an unrecoverable state.
-                                                         Throws HNA_INTSN_E::HNA_ERROR_DBLOVF. */
+                                                         maps to upper 127.75GB of DDR3/4 SDRAM
+                                                         NOTE: the 2nd 256MB hole maps to I/O and is unused (nonexistent) for memory.
+                                                         In the event the HNA generates a reference to the L2/DRAM address hole (0x0000.0FFF.FFFF -
+                                                         0x0000.1FFF.FFFF), the HNANXM programmable interrupt bit will be set.
+                                                         Software Note:
+                                                         The HNA Graph compiler must avoid making references to this 2nd 256MB HOLE which is a non-
+                                                         existent memory region.
+                                                         NOTE: If HNANXM is set during a HNA Graph Walk operation, then the walk will prematurely
+                                                         terminate with RWORD0[REAS]=MEMERR. */
+	uint64_t dlc1_dbe                     : 1;  /**< A DLC1 response indicated a double-bit ECC error (DBE). */
+	uint64_t dlc0_dbe                     : 1;  /**< A DLC0 response indicated a double-bit ECC error (DBE). */
+	uint64_t dlc1_ovferr                  : 1;  /**< DLC1 FIFO overflow error detected. This condition should never architecturally occur, and
+                                                         is here in case hardware credit/debit scheme is not working. */
+	uint64_t dlc0_ovferr                  : 1;  /**< DLC0 FIFO overflow error detected. This condition should never architecturally occur, and
+                                                         is here in case hardware credit/debit scheme is not working. */
+	uint64_t hnc_ovferr                   : 1;  /**< HNC (RAM1) address overflow error detected.
+                                                         This condition is signaled by the HPU when an node access is made to RAM1 outside the size
+                                                         of the RAM. */
+	uint64_t hna_inst_err                 : 1;  /**< Instruction field ITYPE is not GWALK or CLOAD. */
+	uint64_t reserved_6_10                : 5;
+	uint64_t hpu_pdb_par_err              : 1;  /**< A parity error was detected in a packet data buffer in one of the HNA engines. This is not
+                                                         self-correcting, and the HPU behavior is undefined. */
+	uint64_t hpu_rnstck_dbe               : 1;  /**< A double-bit ECC (DBE) error was detected in the run stack of an HPU. This is not self-
+                                                         correcting, and the HPU behavior is undefined. */
+	uint64_t hpu_rnstck_sbe               : 1;  /**< A single-bit ECC (SBE) error was detected in the run stack of an HPU. This is self-
+                                                         correcting, and the HPU should continue to operate normally. */
+	uint64_t hpu_svstck_dbe               : 1;  /**< A double-bit ECC (DBE) error was detected in the save stack / result buffer of an HPU.
+                                                         This is not self-correcting, and the HPU behavior is undefined. */
+	uint64_t hpu_svstck_sbe               : 1;  /**< A single-bit ECC (SBE) error was detected in the save stack / result buffer of an HPU.
+                                                         This is self-correcting, and the HPU should continue to operate normally. */
+	uint64_t dblovf                       : 1;  /**< Doorbell overflow detected - status bit. When set, the 20-bit accumulated doorbell
+                                                         register had overflowed (software wrote too many doorbell requests).
+                                                         NOTE: Detection of a doorbell register overflow is a catastrophic error which may leave
+                                                         the HNA hardware in an unrecoverable state. */
 #else
 	uint64_t dblovf                       : 1;
-	uint64_t reserved_1_12                : 12;
+	uint64_t hpu_svstck_sbe               : 1;
+	uint64_t hpu_svstck_dbe               : 1;
+	uint64_t hpu_rnstck_sbe               : 1;
+	uint64_t hpu_rnstck_dbe               : 1;
+	uint64_t hpu_pdb_par_err              : 1;
+	uint64_t reserved_6_10                : 5;
+	uint64_t hna_inst_err                 : 1;
+	uint64_t hnc_ovferr                   : 1;
 	uint64_t dlc0_ovferr                  : 1;
 	uint64_t dlc1_ovferr                  : 1;
-	uint64_t reserved_15_16               : 2;
+	uint64_t dlc0_dbe                     : 1;
+	uint64_t dlc1_dbe                     : 1;
 	uint64_t hnanxm                       : 1;
 	uint64_t replerr                      : 1;
 	uint64_t osmerr                       : 1;
-	uint64_t reserved_20_63               : 44;
+	uint64_t hnc_parerr                   : 1;
+	uint64_t reserved_21_63               : 43;
 #endif
 	} s;
 	struct cvmx_hna_error_s               cn78xx;
@@ -816,20 +798,183 @@ union cvmx_hna_error {
 typedef union cvmx_hna_error cvmx_hna_error_t;
 
 /**
+ * cvmx_hna_error_capture_data
+ *
+ * This register holds the HPU_STATUS data captured during HNA_ERROR events.
+ *
+ */
+union cvmx_hna_error_capture_data {
+	uint64_t u64;
+	struct cvmx_hna_error_capture_data_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t hpu_stat                     : 64; /**< HPU_STATUS data captured during HNA_ERROR events. It will preserve the HPU_STATUS from the
+                                                         first error event that is detected, until the VLD bit in the HNA_ERROR_CAPTURE_INFO
+                                                         register is cleared. If multiple error events occur before the VLD bit is cleared, the
+                                                         subsequent HPU_STATUS information will be lost. The error capture is triggered by the
+                                                         following error conditions:
+                                                         * HPU memory errors (SBE or DBE on svstk/rnstk/rwb, or parity error on PDB)
+                                                         * external memory errors (OSM/DLC)
+                                                         * bad node detected in HPU
+                                                         * bad address in HPU
+                                                         * bad stack entry in HPU
+                                                         * HNC parity error
+                                                         * RAM1 address overflow
+                                                         The HPU STATUS format is as follows:
+                                                         [63:60]   4'h0
+                                                         [60:40]   failing address                 Last fetched node
+                                                         [39:36]   4'h0
+                                                         [35:28]   svstck_synd
+                                                         [27]        svstck_dbe                      Interrupt
+                                                         [26]        svstck_sbe                       Interrupt
+                                                         [25:18]   rnstck_synd
+                                                         [17]        rnstck_dbe                      Interrupt
+                                                         [16]        rnstck_sbe                      Interrupt
+                                                         [15:11]   Current opcode
+                                                         [10]        1'b0
+                                                         [9]          OSM or DLC Response Error       REASON MEMERR
+                                                         [8]          Bad node                        REASON BADNODE
+                                                         [7]          Graph location is in RAM2       REASON BADADR
+                                                         [6]          Bad stack entry                 REASON BAD STACKENTRY
+                                                         [5]          Svstck full                     REASON SVSTACK FULL
+                                                         [4]          Rwb full                        REASON RWB FULL
+                                                         [3]          Rnstck full                     REASON RUN STACK FULL
+                                                         [2]          Packet data parity error               Interrupt
+                                                         [1]          RAM1 or RAM2 parity error       REASON MEMERR
+                                                         [0]          Ram1 overflow error             REASON MEMERR */
+#else
+	uint64_t hpu_stat                     : 64;
+#endif
+	} s;
+	struct cvmx_hna_error_capture_data_s  cn78xx;
+};
+typedef union cvmx_hna_error_capture_data cvmx_hna_error_capture_data_t;
+
+/**
+ * cvmx_hna_error_capture_info
+ *
+ * This register holds the meta-data for the HPU_STATUS captured during HNA_ERROR events.
+ *
+ */
+union cvmx_hna_error_capture_info {
+	uint64_t u64;
+	struct cvmx_hna_error_capture_info_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_10_63               : 54;
+	uint64_t cl_id                        : 2;  /**< Cluster which was the source of the HPU_STATUS. */
+	uint64_t hpu_id                       : 4;  /**< HPU which was the source of the HPU_STATUS. */
+	uint64_t reserved_2_3                 : 2;
+	uint64_t ovf                          : 1;  /**< The OVF bit indicates that at least one HNA_ERROR condition has occurred while the
+                                                         CAPTURE_DATA register contained data, resulting in lost HPU_STATUS information. This bit
+                                                         will be cleared when the VLD bit is written to 1." */
+	uint64_t vld                          : 1;  /**< The VLD bit indicates that an HNA_ERROR has occurred and the HPU_STATUS has been captured
+                                                         in the HNA_ERROR_CAPTURE_DATA register. The first such HPU_STATUS will be stored until
+                                                         this bit is cleared by writing a 1. */
+#else
+	uint64_t vld                          : 1;
+	uint64_t ovf                          : 1;
+	uint64_t reserved_2_3                 : 2;
+	uint64_t hpu_id                       : 4;
+	uint64_t cl_id                        : 2;
+	uint64_t reserved_10_63               : 54;
+#endif
+	} s;
+	struct cvmx_hna_error_capture_info_s  cn78xx;
+};
+typedef union cvmx_hna_error_capture_info cvmx_hna_error_capture_info_t;
+
+/**
+ * cvmx_hna_hnc0_ram1#
+ *
+ * This address space allows read-only access to HNC0 RAM1 for diagnostic use. It is defined here
+ * to contain 64 words (16 RAM lines) for basic DV testing, but the actual address space spans
+ * the entire RAM1, 8192 lines.
+ */
+union cvmx_hna_hnc0_ram1x {
+	uint64_t u64;
+	struct cvmx_hna_hnc0_ram1x_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t ram1_data                    : 64; /**< 64-bit chunk of RAM1. */
+#else
+	uint64_t ram1_data                    : 64;
+#endif
+	} s;
+	struct cvmx_hna_hnc0_ram1x_s          cn78xx;
+};
+typedef union cvmx_hna_hnc0_ram1x cvmx_hna_hnc0_ram1x_t;
+
+/**
+ * cvmx_hna_hnc0_ram2#
+ *
+ * This address space allows read-only access to HNC0 RAM2 for diagnostic use. It is defined here
+ * to contain 64 words (16 RAM lines) for basic DV testing, but the actual address space spans
+ * the entire RAM2, 512 lines.
+ */
+union cvmx_hna_hnc0_ram2x {
+	uint64_t u64;
+	struct cvmx_hna_hnc0_ram2x_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t ram2_data                    : 64; /**< 64-bit chunk of RAM2. */
+#else
+	uint64_t ram2_data                    : 64;
+#endif
+	} s;
+	struct cvmx_hna_hnc0_ram2x_s          cn78xx;
+};
+typedef union cvmx_hna_hnc0_ram2x cvmx_hna_hnc0_ram2x_t;
+
+/**
+ * cvmx_hna_hnc1_ram1#
+ *
+ * This address space allows read-only access to HNC1 RAM1 for diagnostic use. It is defined here
+ * to contain 64 words (16 RAM lines) for basic DV testing, but the actual address space spans
+ * the entire RAM1, 8192 lines.
+ */
+union cvmx_hna_hnc1_ram1x {
+	uint64_t u64;
+	struct cvmx_hna_hnc1_ram1x_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t ram1_data                    : 64; /**< 64-bit chunk of RAM1. */
+#else
+	uint64_t ram1_data                    : 64;
+#endif
+	} s;
+	struct cvmx_hna_hnc1_ram1x_s          cn78xx;
+};
+typedef union cvmx_hna_hnc1_ram1x cvmx_hna_hnc1_ram1x_t;
+
+/**
+ * cvmx_hna_hnc1_ram2#
+ *
+ * This address space allows read-only access to HNC1 RAM2 for diagnostic use. It is defined here
+ * to contain 64 words (16 RAM lines) for basic DV testing, but the actual address space spans
+ * the entire RAM1, 512 lines.
+ */
+union cvmx_hna_hnc1_ram2x {
+	uint64_t u64;
+	struct cvmx_hna_hnc1_ram2x_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t ram2_data                    : 64; /**< 64-bit chunk of RAM2. */
+#else
+	uint64_t ram2_data                    : 64;
+#endif
+	} s;
+	struct cvmx_hna_hnc1_ram2x_s          cn78xx;
+};
+typedef union cvmx_hna_hnc1_ram2x cvmx_hna_hnc1_ram2x_t;
+
+/**
  * cvmx_hna_hpu_csr
  *
- * "To read one of the HPU internal CSRs for debug (ie: HPU_STATUS, DBG_CURSTK,
- * DBG_GENERAL),
- * first a CSR WRITE of the HNA_HPU_DBG is done to specify the HPU CSR#, cluster#=CLID and
- * HPU#=HPUID,
- * which is followed by a CSR READ of the HPA_HPU_CSR which returns the contents of the specified
- * HPU CSR."
+ * To read one of the HPU internal CSRs for debug (i.e. HPU_STATUS, DBG_CURSTK, DBG_GENERAL),
+ * first a CSR write of the HNA_HPU_DBG is done to specify the HPU CSR number, cluster number =
+ * CLID, and HPU number = HPUID, which is followed by a CSR read of the HPA_HPU_CSR which returns
+ * the contents of the specified HPU CSR.
  */
 union cvmx_hna_hpu_csr {
 	uint64_t u64;
 	struct cvmx_hna_hpu_csr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t csrdat                       : 64; /**< HPU CSR contents specified by the HNA_HPU_DBG CSR. */
+	uint64_t csrdat                       : 64; /**< HPU CSR contents specified by HNA_HPU_DBG. */
 #else
 	uint64_t csrdat                       : 64;
 #endif
@@ -841,20 +986,20 @@ typedef union cvmx_hna_hpu_csr cvmx_hna_hpu_csr_t;
 /**
  * cvmx_hna_hpu_dbg
  *
- * "This register specifies the HPU CSR#, cluster#=CLID and HPU#=HPUID used during a
- * a CSR READ of the HNA_HPU_CSR register."
+ * This register specifies the HPU CSR number, cluster number = CLID and HPU number = HPUID used
+ * during a a CSR read of the HNA_HPU_CSR register.
  */
 union cvmx_hna_hpu_dbg {
 	uint64_t u64;
 	struct cvmx_hna_hpu_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t csrnum                       : 2;  /**< "HPU CSR#
-                                                         - 0: HPU_STATUS
-                                                         - 1: DBG_CURSTK
-                                                         - 2: DBG_GENERAL" */
-	uint64_t clid                         : 2;  /**< HPC Cluster# Valid Range=[0..3] */
-	uint64_t hpuid                        : 4;  /**< HPU Engine ID# Valid Range=[0..11] */
+	uint64_t csrnum                       : 2;  /**< HPU CSR number
+                                                         0x0 = HPU_STATUS
+                                                         0x1 = DBG_CURSTK
+                                                         0x2 = DBG_GENERAL */
+	uint64_t clid                         : 2;  /**< Cluster number. Valid range is 0-3. */
+	uint64_t hpuid                        : 4;  /**< HPU engine ID. Valid range 0-11. */
 #else
 	uint64_t hpuid                        : 4;
 	uint64_t clid                         : 2;
@@ -869,32 +1014,25 @@ typedef union cvmx_hna_hpu_dbg cvmx_hna_hpu_dbg_t;
 /**
  * cvmx_hna_hpu_eir
  *
- * "Used by SW to force Parity or ECC errors on some internal HPU data structures.
- * A CSR WRITE of this register will force either a Parity or ECC error on the next access
- * at cluster#=CLID, HPU#=HPUID."
+ * Used by software to force parity or ECC errors on some internal HPU data structures. A CSR
+ * write of this register forces either a parity or ECC error on the next access at cluster
+ * number = CLID, HPU number = HPUID.
  */
 union cvmx_hna_hpu_eir {
 	uint64_t u64;
 	struct cvmx_hna_hpu_eir_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t wrdone                       : 1;  /**< When the HNA_HPU_EIR register is written, this bit will
-                                                         be cleared by HW. When the targeted HPU has received
-                                                         the error injection command (ie: error injection armed),
-                                                         the WRDONE bit will be SET.
-                                                         SW will first write the HNA_HPU_EIR register, then do a
-                                                         polling read of the WRDONE bit (until it becomes 1),
-                                                         before issueing an HNA instruction to the targeted HPU
-                                                         which will inject the intended error type for a single
-                                                         occurrence (one-shot). */
-	uint64_t pdperr                       : 1;  /**< Packet Data buffer Parity error
-                                                         Forces parity error on next Packet data buffer read. */
-	uint64_t svflipsyn                    : 2;  /**< Save stack flip syndrome control.
-                                                         Forces 1-bit/2-bit errors on next save stack read. */
-	uint64_t rsflipsyn                    : 2;  /**< Run stack flip syndrome control.
-                                                         Forces 1-bit/2-bit errors on next run stack read. */
-	uint64_t clid                         : 2;  /**< HPC Cluster# Valid Range=[0..3] */
-	uint64_t hpuid                        : 4;  /**< HPU Engine ID# Valid Range=[0..11] */
+	uint64_t wrdone                       : 1;  /**< When HNA_HPU_EIR is written, this bit is cleared by hardware. When the targeted HPU has
+                                                         received the error injection command (i.e. error injection armed), the WRDONE bit is SET.
+                                                         Software first writes HNA_HPU_EIR, then does a polling read of the WRDONE bit (until it
+                                                         becomes 1), before issuing an HNA instruction to the targeted HPU which will inject the
+                                                         intended error type for a single occurrence (one-shot). */
+	uint64_t pdperr                       : 1;  /**< Packet data buffer parity error. Forces parity error on next packet data buffer read. */
+	uint64_t svflipsyn                    : 2;  /**< Save stack flip syndrome control. Forces 1-bit/2-bit errors on next save stack read. */
+	uint64_t rsflipsyn                    : 2;  /**< Run stack flip syndrome control. Forces 1-bit/2-bit errors on next run stack read. */
+	uint64_t clid                         : 2;  /**< HPC cluster number. Valid range is 0-3. */
+	uint64_t hpuid                        : 4;  /**< HPU engine ID. Valid range is 0-11. */
 #else
 	uint64_t hpuid                        : 4;
 	uint64_t clid                         : 2;
@@ -916,12 +1054,9 @@ union cvmx_hna_pfc0_cnt {
 	uint64_t u64;
 	struct cvmx_hna_pfc0_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pfcnt                        : 64; /**< "HNA Performance Counter 0.
-                                                         When HNA_PFC_GCTL[CNT0ENA]=1, the event selected
-                                                         by HNA_PFC0_CTL[EVSEL] is counted.
-                                                         See also HNA_PFC_GCTL[CNT0WCLR] and HNA_PFC_GCTL
-                                                         [CNT0RCLR] for special clear count cases available
-                                                         for SW data collection." */
+	uint64_t pfcnt                        : 64; /**< HNA performance counter 0. When HNA_PFC_GCTL[CNT0ENA]=1, the event selected by
+                                                         HNA_PFC0_CTL[EVSEL] is counted. See also HNA_PFC_GCTL[CNT0WCLR] and HNA_PFC_GCTL
+                                                         [CNT0RCLR] for special clear count cases available for software data collection. */
 #else
 	uint64_t pfcnt                        : 64;
 #endif
@@ -938,16 +1073,15 @@ union cvmx_hna_pfc0_ctl {
 	struct cvmx_hna_pfc0_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t evsel                        : 6;  /**< Performance Counter#0 Event Selector (64 total) */
+	uint64_t evsel                        : 6;  /**< Performance counter 0 event selector (64 total). Enumerated by HNA_PFC_SEL_E. */
 	uint64_t reserved_6_7                 : 2;
-	uint64_t clhpu                        : 4;  /**< "Performance Counter 0 Cluster HPU Selector.
-                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
+	uint64_t clhpu                        : 4;  /**< "Performance counter 0 cluster HPU selector. When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU),
+                                                         this field
                                                          is used to select/monitor the cluster's HPU# for all events
-                                                         associated with Performance Counter#0." */
-	uint64_t clnum                        : 2;  /**< "Performance Counter 0 Cluster Selector.
-                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
-                                                         is used to select/monitor the cluster# for all events
-                                                         associated with Performance Counter#0." */
+                                                         associated with performance counter \#0." */
+	uint64_t clnum                        : 2;  /**< "Performance counter 0 cluster selector. When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU),
+                                                         this field is used to select/monitor the cluster# for all events associated with
+                                                         performance counter \#0." */
 #else
 	uint64_t clnum                        : 2;
 	uint64_t clhpu                        : 4;
@@ -967,12 +1101,9 @@ union cvmx_hna_pfc1_cnt {
 	uint64_t u64;
 	struct cvmx_hna_pfc1_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pfcnt                        : 64; /**< "HNA Performance Counter 1.
-                                                         When HNA_PFC_GCTL[CNT1ENA]=1, the event selected
-                                                         by HNA_PFC1_CTL[EVSEL] is counted.
-                                                         See also HNA_PFC_GCTL[CNT1WCLR] and HNA_PFC_GCTL
-                                                         [CNT1RCLR] for special clear count cases available
-                                                         for SW data collection." */
+	uint64_t pfcnt                        : 64; /**< HNA performance counter 1. When HNA_PFC_GCTL[CNT1ENA]=1, the event selected by
+                                                         HNA_PFC1_CTL[EVSEL] is counted. See also HNA_PFC_GCTL[CNT1WCLR] and HNA_PFC_GCTL
+                                                         [CNT1RCLR] for special clear count cases available for software data collection. */
 #else
 	uint64_t pfcnt                        : 64;
 #endif
@@ -989,16 +1120,14 @@ union cvmx_hna_pfc1_ctl {
 	struct cvmx_hna_pfc1_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t evsel                        : 6;  /**< Performance Counter#1 Event Selector (64 total) */
+	uint64_t evsel                        : 6;  /**< Performance counter 1 event selector (64 total). Enumerated by HNA_PFC_SEL_E. */
 	uint64_t reserved_6_7                 : 2;
-	uint64_t clhpu                        : 4;  /**< "Performance Counter 1 Cluster HPU Selector.
-                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
-                                                         is used to select/monitor the cluster's HPU# for all events
-                                                         associated with Performance Counter#1." */
-	uint64_t clnum                        : 2;  /**< "Performance Counter 1 Cluster Selector.
-                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
-                                                         is used to select/monitor the cluster# for all events
-                                                         associated with Performance Counter#1." */
+	uint64_t clhpu                        : 4;  /**< "Performance counter 1 cluster HPU selector. When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU),
+                                                         this field is used to select/monitor the cluster's HPU# for all events associated with
+                                                         performance counter 1." */
+	uint64_t clnum                        : 2;  /**< "Performance counter 1 cluster selector. When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU),
+                                                         this field is used to select/monitor the cluster# for all events associated with
+                                                         performance counter 1." */
 #else
 	uint64_t clnum                        : 2;
 	uint64_t clhpu                        : 4;
@@ -1018,12 +1147,9 @@ union cvmx_hna_pfc2_cnt {
 	uint64_t u64;
 	struct cvmx_hna_pfc2_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pfcnt                        : 64; /**< "HNA Performance Counter 2.
-                                                         When HNA_PFC_GCTL[CNT2ENA]=1, the event selected
-                                                         by HNA_PFC2_CTL[EVSEL] is counted.
-                                                         See also HNA_PFC_GCTL[CNT2WCLR] and HNA_PFC_GCTL
-                                                         [CNT2RCLR] for special clear count cases available
-                                                         for SW data collection." */
+	uint64_t pfcnt                        : 64; /**< HNA performance counter 2. When HNA_PFC_GCTL[CNT2ENA]=1, the event selected by
+                                                         HNA_PFC2_CTL[EVSEL] is counted. See also HNA_PFC_GCTL[CNT2WCLR] and HNA_PFC_GCTL
+                                                         [CNT2RCLR] for special clear count cases available for software data collection. */
 #else
 	uint64_t pfcnt                        : 64;
 #endif
@@ -1040,16 +1166,14 @@ union cvmx_hna_pfc2_ctl {
 	struct cvmx_hna_pfc2_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t evsel                        : 6;  /**< Performance Counter#2 Event Selector (64 total) */
+	uint64_t evsel                        : 6;  /**< Performance counter \#2 event selector (64 total). Enumerated by HNA_PFC_SEL_E. */
 	uint64_t reserved_6_7                 : 2;
-	uint64_t clhpu                        : 4;  /**< "Performance Counter#2 Cluster HPU Selector.
-                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
-                                                         is used to select/monitor the cluster's HPU# for all events
-                                                         associated with Performance Counter#2." */
-	uint64_t clnum                        : 2;  /**< "Performance Counter#2 Cluster Selector.
-                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
-                                                         is used to select/monitor the cluster# for all events
-                                                         associated with Performance Counter#2." */
+	uint64_t clhpu                        : 4;  /**< "Performance counter \#2 cluster HPU Selector. When HNA_PFC_GCTL[PMODE]=0 (per-cluster
+                                                         HPU), this field is used to select/monitor the cluster's HPU# for all events associated
+                                                         with performance counter \#2." */
+	uint64_t clnum                        : 2;  /**< "Performance counter \#2 cluster selector. When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU),
+                                                         this field is used to select/monitor the cluster# for all events associated with
+                                                         performance counter \#2." */
 #else
 	uint64_t clnum                        : 2;
 	uint64_t clhpu                        : 4;
@@ -1069,12 +1193,9 @@ union cvmx_hna_pfc3_cnt {
 	uint64_t u64;
 	struct cvmx_hna_pfc3_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pfcnt                        : 64; /**< "HNA Performance Counter 3.
-                                                         When HNA_PFC_GCTL[CNT3ENA]=1, the event selected
-                                                         by HNA_PFC3_CTL[EVSEL] is counted.
-                                                         See also HNA_PFC_GCTL[CNT3WCLR] and HNA_PFC_GCTL
-                                                         [CNT3RCLR] for special clear count cases available
-                                                         for SW data collection." */
+	uint64_t pfcnt                        : 64; /**< HNA performance counter 3. When HNA_PFC_GCTL[CNT3ENA]=1, the event selected by
+                                                         HNA_PFC3_CTL[EVSEL] is counted. See also HNA_PFC_GCTL[CNT3WCLR] and HNA_PFC_GCTL
+                                                         [CNT3RCLR] for special clear count cases available for software data collection. */
 #else
 	uint64_t pfcnt                        : 64;
 #endif
@@ -1091,16 +1212,14 @@ union cvmx_hna_pfc3_ctl {
 	struct cvmx_hna_pfc3_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t evsel                        : 6;  /**< Performance Counter 3 Event Selector (64 total) */
+	uint64_t evsel                        : 6;  /**< Performance counter 3 event selector (64 total). Enumerated by HNA_PFC_SEL_E. */
 	uint64_t reserved_6_7                 : 2;
-	uint64_t clhpu                        : 4;  /**< "Performance Counter 3 Cluster HPU Selector.
-                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
-                                                         is used to select/monitor the cluster's HPU# for all events
-                                                         associated with Performance Counter#3." */
-	uint64_t clnum                        : 2;  /**< "Performance Counter 3 Cluster Selector.
-                                                         When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU), this field
-                                                         is used to select/monitor the cluster# for all events
-                                                         associated with Performance Counter 3." */
+	uint64_t clhpu                        : 4;  /**< "Performance counter 3 cluster HPU selector. When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU),
+                                                         this field is used to select/monitor the cluster's HPU# for all events associated with
+                                                         performance counter \#3." */
+	uint64_t clnum                        : 2;  /**< "Performance counter 3 cluster selector. When HNA_PFC_GCTL[PMODE]=0 (per-cluster HPU),
+                                                         this field is used to select/monitor the cluster# for all events associated with
+                                                         performance counter 3." */
 #else
 	uint64_t clnum                        : 2;
 	uint64_t clhpu                        : 4;
@@ -1124,54 +1243,34 @@ union cvmx_hna_pfc_gctl {
 	struct cvmx_hna_pfc_gctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t cnt3rclr                     : 1;  /**< "Performance Counter 3 Read Clear.
-                                                         If this bit is set, CSR reads to the HNA_PFC3_CNT
-                                                         will clear the count value. This allows SW to maintain
-                                                         'cumulative' counters to avoid HW wraparound." */
-	uint64_t cnt2rclr                     : 1;  /**< "Performance Counter 2 Read Clear.
-                                                         If this bit is set, CSR reads to the HNA_PFC2_CNT
-                                                         will clear the count value. This allows SW to maintain
-                                                         'cumulative' counters to avoid HW wraparound." */
-	uint64_t cnt1rclr                     : 1;  /**< "Performance Counter 1 Read Clear.
-                                                         If this bit is set, CSR reads to the HNA_PFC1_CNT
-                                                         will clear the count value. This allows SW to maintain
-                                                         'cumulative' counters to avoid HW wraparound." */
-	uint64_t cnt0rclr                     : 1;  /**< "Performance Counter 0 Read Clear.
-                                                         If this bit is set, CSR reads to the HNA_PFC0_CNT
-                                                         will clear the count value. This allows SW to maintain
-                                                         'cumulative' counters to avoid HW wraparound." */
-	uint64_t cnt3wclr                     : 1;  /**< "Performance Counter 3 Write Clear.
-                                                         If this bit is set, CSR writes to the HNA_PFC3_CNT
-                                                         will clear the count value.
-                                                         If this bit is clear, CSR writes to the HNA_PFC3_CNT
-                                                         will continue the count from the written value." */
-	uint64_t cnt2wclr                     : 1;  /**< "Performance Counter 2 Write Clear.
-                                                         If this bit is set, CSR writes to the HNA_PFC2_CNT
-                                                         will clear the count value.
-                                                         If this bit is clear, CSR writes to the HNA_PFC2_CNT
-                                                         will continue the count from the written value." */
-	uint64_t cnt1wclr                     : 1;  /**< "Performance Counter 1 Write Clear.
-                                                         If this bit is set, CSR writes to the HNA_PFC1_CNT
-                                                         will clear the count value.
-                                                         If this bit is clear, CSR writes to the HNA_PFC1_CNT
-                                                         will continue the count from the written value." */
-	uint64_t cnt0wclr                     : 1;  /**< "Performance Counter 0 Write Clear.
-                                                         If this bit is set, CSR writes to the HNA_PFC0_CNT
-                                                         will clear the count value.
-                                                         If this bit is clear, CSR writes to the HNA_PFC0_CNT
-                                                         will continue the count from the written value." */
-	uint64_t cnt3ena                      : 1;  /**< "Performance Counter 3 Enable.
-                                                         When this bit is set, the performance counter \#3
-                                                         is enabled." */
-	uint64_t cnt2ena                      : 1;  /**< "Performance Counter 2 Enable.
-                                                         When this bit is set, the performance counter \#2
-                                                         is enabled." */
-	uint64_t cnt1ena                      : 1;  /**< "Performance Counter 1 Enable.
-                                                         When this bit is set, the performance counter \#1
-                                                         is enabled." */
-	uint64_t cnt0ena                      : 1;  /**< "Performance Counter 0 Enable.
-                                                         When this bit is set, the performance counter \#0
-                                                         is enabled." */
+	uint64_t cnt3rclr                     : 1;  /**< Performance counter 3 read clear. If this bit is set, CSR reads to the HNA_PFC3_CNT will
+                                                         clear the count value. This allows software to maintain 'cumulative' counters to avoid
+                                                         hardware wraparound. */
+	uint64_t cnt2rclr                     : 1;  /**< Performance counter 2 read clear. If this bit is set, CSR reads to the HNA_PFC2_CNT will
+                                                         clear the count value. This allows software to maintain 'cumulative' counters to avoid
+                                                         hardware wraparound. */
+	uint64_t cnt1rclr                     : 1;  /**< Performance counter 1 read clear. If this bit is set, CSR reads to the HNA_PFC1_CNT will
+                                                         clear the count value. This allows software to maintain 'cumulative' counters to avoid
+                                                         hardware wraparound. */
+	uint64_t cnt0rclr                     : 1;  /**< Performance counter 0 read clear. If this bit is set, CSR reads to the HNA_PFC0_CNT will
+                                                         clear the count value. This allows software to maintain 'cumulative' counters to avoid
+                                                         hardware wraparound. */
+	uint64_t cnt3wclr                     : 1;  /**< Performance counter 3 write clear. If this bit is set, CSR writes to the HNA_PFC3_CNT will
+                                                         clear the count value. If this bit is clear, CSR writes to the HNA_PFC3_CNT will continue
+                                                         the count from the written value. */
+	uint64_t cnt2wclr                     : 1;  /**< Performance counter 2 write clear. If this bit is set, CSR writes to the HNA_PFC2_CNT will
+                                                         clear the count value. If this bit is clear, CSR writes to the HNA_PFC2_CNT will continue
+                                                         the count from the written value. */
+	uint64_t cnt1wclr                     : 1;  /**< Performance counter 1 write clear. If this bit is set, CSR writes to the HNA_PFC1_CNT will
+                                                         clear the count value. If this bit is clear, CSR writes to the HNA_PFC1_CNT will continue
+                                                         the count from the written value. */
+	uint64_t cnt0wclr                     : 1;  /**< Performance counter 0 write clear. If this bit is set, CSR writes to the HNA_PFC0_CNT will
+                                                         clear the count value. If this bit is clear, CSR writes to the HNA_PFC0_CNT will continue
+                                                         the count from the written value. */
+	uint64_t cnt3ena                      : 1;  /**< Performance counter 3 enable. When this bit is set, the performance counter 3 is enabled. */
+	uint64_t cnt2ena                      : 1;  /**< Performance counter 2 enable. When this bit is set, the performance counter 2 is enabled. */
+	uint64_t cnt1ena                      : 1;  /**< Performance counter 1 enable. When this bit is set, the performance counter 1 is enabled. */
+	uint64_t cnt0ena                      : 1;  /**< Performance counter 0 enable. When this bit is set, the performance counter 0 is enabled. */
 #else
 	uint64_t cnt0ena                      : 1;
 	uint64_t cnt1ena                      : 1;
@@ -1195,41 +1294,40 @@ typedef union cvmx_hna_pfc_gctl cvmx_hna_pfc_gctl_t;
 /**
  * cvmx_hna_sbd_dbg0
  *
- * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
- * are locked down. Otherwise, the contents of this register are the 'active' contents of the
- * HNA Scoreboard at the time of the CSR read.
- * INTERNAL: VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the
- * behavioral
- * model) on the reads unless the HPU Engine specified by HNA_CONTROL[SBDNUM] has previously been
- * assigned an instruction.
+ * When the HNA_CONTROL[SBDLCK] bit is written to 1, the contents of this register are locked
+ * down. Otherwise, the contents of this register are the active contents of the HNA scoreboard
+ * at the time of the CSR read.
  */
 union cvmx_hna_sbd_dbg0 {
 	uint64_t u64;
 	struct cvmx_hna_sbd_dbg0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sbd                          : 64; /**< "HNA ScoreBoard 0 Data.
-                                                         [63:38]   (26) rptr[28:3]: Result Base Pointer (QW-aligned)
-                                                         [37:22]   (16) Cumulative Result Write Counter (for HDR write)
-                                                         [21]       (1) Waiting for GRdRsp EOT
-                                                         [20]       (1) Waiting for GRdReq Issue (to NRQ)
-                                                         [19]       (1) GLPTR/GLCNT Valid
-                                                         [18]       (1) Completion Mark Detected
-                                                         [17:15]    (3) Completion Code [0=PDGONE/1=PERR/2=RFULL/3=TERM]
-                                                         [14]       (1) Completion Detected
+	uint64_t sbd                          : 64; /**< HNA Scoreboard 0 data.
+                                                         [63]       (1) Unused
+                                                         [62]       (1) llptr_gntd
+                                                         [61]       (1) llptr_fetch
+                                                         [60]       (1) spill_req_1a
+                                                         [59:54]    (6) hpu_svstk_lvl[5:0]
+                                                         [53:36]   (18) svstk_len[17:0]
+                                                         [35:20]   (16) Cumulative result write counter (for HDR write)
+                                                         [19]       (1) Unused
+                                                         [18:15]    (4) Completion code
+                                                         [14]       (1) Completion detected
                                                          [13]       (1) Waiting for HDR RWrCmtRsp
-                                                         [12]       (1) Waiting for LAST RESULT RWrCmtRsp
+                                                         [12]       (1) 1st (of 2) RWORD0(HDR) writes (w/ DONE=0) has been issued
                                                          [11]       (1) Waiting for HDR RWrReq
-                                                         [10]        (1) Waiting for RWrReq
+                                                         [10]       (1) Waiting for RWrReq
                                                          [9]        (1) Waiting for WQWrReq issue
                                                          [8]        (1) Waiting for PRdRsp EOT
                                                          [7]        (1) Waiting for PRdReq Issue (to NRQ)
-                                                         [6]        (1) Packet Data Valid
+                                                         [6]        (1) Packet data valid
                                                          [5]        (1) WQVLD
-                                                         [4]        (1) WQ Done Point (either WQWrReq issued (for WQPTR<>0) OR HDR RWrCmtRsp)
+                                                         [4]        (1) WQ done point (either WQWrReq issued (for WQPTR<>0) OR HDR RWrCmtRsp
+                                                         completed)
                                                          [3]        (1) Resultant write STF/P Mode
-                                                         [2]        (1) Packet Data LDT mode
-                                                         [1]        (1) Gather Mode
-                                                         [0]        (1) Valid" */
+                                                         [2]        (1) Packet data LDT mode
+                                                         [1]        (1) Unused
+                                                         [0]        (1) Valid */
 #else
 	uint64_t sbd                          : 64;
 #endif
@@ -1241,22 +1339,19 @@ typedef union cvmx_hna_sbd_dbg0 cvmx_hna_sbd_dbg0_t;
 /**
  * cvmx_hna_sbd_dbg1
  *
- * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
- * are locked down. Otherwise, the contents of this register are the 'active' contents of the
- * HNA Scoreboard at the time of the CSR read.
- * INTERNAL: VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the
- * behavioral
- * model) on the reads unless the HPU Engine specified by HNA_CONTROL[SBDNUM] has previously been
- * assigned an instruction.
+ * When the HNA_CONTROL[SBDLCK] bit is written to 1, the contents of this register are locked
+ * down. Otherwise, the contents of this register are the 'active' contents of the HNA scoreboard
+ * at the time of the CSR read.
  */
 union cvmx_hna_sbd_dbg1 {
 	uint64_t u64;
 	struct cvmx_hna_sbd_dbg1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sbd                          : 64; /**< "HNA ScoreBoard 1 Data.
-                                                         [63:56]   (8) UNUSED
-                                                         [55:16]  (40) Packet Data Pointer
-                                                         [15:0]   (16) Packet Data Counter" */
+	uint64_t sbd                          : 64; /**< HNA Scoreboard 1 data.
+                                                         [63:58]    (6) Reserved
+                                                         [57:16]   (42) Packet data pointer
+                                                         [15]       (1) Unused
+                                                         [14:0]    (15) Packet data counter */
 #else
 	uint64_t sbd                          : 64;
 #endif
@@ -1268,23 +1363,19 @@ typedef union cvmx_hna_sbd_dbg1 cvmx_hna_sbd_dbg1_t;
 /**
  * cvmx_hna_sbd_dbg2
  *
- * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
- * are locked down. Otherwise, the contents of this register are the 'active' contents of the
- * HNA Scoreboard at the time of the CSR read.
- * INTERNAL: VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the
- * behavioral
- * model) on the reads unless the HPU Engine specified by HNA_CONTROL[SBDNUM] has previously been
- * assigned an instruction.
+ * When the HNA_CONTROL[SBDLCK] bit is written to 1, the contents of this register are locked
+ * down. Otherwise, the contents of this register are the actives contents of the HNA scoreboard
+ * at the time of the CSR read.
  */
 union cvmx_hna_sbd_dbg2 {
 	uint64_t u64;
 	struct cvmx_hna_sbd_dbg2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sbd                          : 64; /**< "HNA ScoreBoard 2 Data.
-                                                         [63:45] (19) UNUSED
-                                                         [44:42]  (3) Instruction Type
-                                                         [41:5]  (37) rwptr[39:3]: Result Write Pointer
-                                                         [4:0]    (5) prwcnt[4:0]: Pending Result Write Counter" */
+	uint64_t sbd                          : 64; /**< HNA Scoreboard 2 data.
+                                                         [63:48]   (16) Reserved
+                                                         [47:45]    (3) ITYPE
+                                                         [44:6]    (39) Result write pointer
+                                                         [5:0]      (6) Pending result write counter */
 #else
 	uint64_t sbd                          : 64;
 #endif
@@ -1296,22 +1387,26 @@ typedef union cvmx_hna_sbd_dbg2 cvmx_hna_sbd_dbg2_t;
 /**
  * cvmx_hna_sbd_dbg3
  *
- * When the HNA_CONTROL[SBDLCK] bit is written '1', the contents of this register
- * are locked down. Otherwise, the contents of this register are the 'active' contents of the
- * HNA Scoreboard at the time of the CSR read.
- * INTERNAL: VERIFICATION NOTE: Read data is unsafe. X's(undefined data) can propagate (in the
- * behavioral
- * model) on the reads unless the HPU Engine specified by HNA_CONTROL[SBDNUM] has previously been
- * assigned an instruction.
+ * When the HNA_CONTROL[SBDLCK] bit is written 1, the contents of this register are locked down.
+ * Otherwise, the contents of this register are the 'active' contents of the HNA Scoreboard at
+ * the time of the CSR read.
  */
 union cvmx_hna_sbd_dbg3 {
 	uint64_t u64;
 	struct cvmx_hna_sbd_dbg3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sbd                          : 64; /**< "HNA ScoreBoard 3 Data.
-                                                         [63:52] (11) rptr[39:29]: Result Base Pointer (QW-aligned)
-                                                         [52:16] (37) glptr[39:3]: Gather List Pointer
-                                                         [15:0]  (16) glcnt Gather List Counter" */
+	uint64_t sbd                          : 64; /**< HNA Scoreboard 3 data.
+                                                         [63:48]   (16) RESERVED
+                                                         [47]       (1) fill_start_1a
+                                                         [46]       (1) spill_start_1a
+                                                         [45]       (1) fill_en
+                                                         [44]       (1) chunk_ptr_addr_match_1a
+                                                         [43]       (1) rnstk_ptrupdate_1a
+                                                         [42]       (1) svllrd
+                                                         [41:38]    (4) state[3:0]
+                                                         [37:29]    (9) hpu_rnstk_lvl[8:0]
+                                                         [28:11]   (18) ext_rnstk_lvl[17:0]
+                                                         [10:0]    (11) rnstk_addr[10:0] */
 #else
 	uint64_t sbd                          : 64;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-ila-defs.h b/arch/mips/include/asm/octeon/cvmx-ila-defs.h
index efed1f5..20d6960 100644
--- a/arch/mips/include/asm/octeon/cvmx-ila-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ila-defs.h
@@ -631,11 +631,11 @@ union cvmx_ila_lnex_trn_ld {
 	struct cvmx_ila_lnex_trn_ld_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_49_63               : 15;
-	uint64_t ld_cu_val                    : 1;  /**< Local device coefficient update field valid */
-	uint64_t ld_cu_dat                    : 16; /**< Local device coefficient update field data */
+	uint64_t ld_cu_val                    : 1;  /**< Local device coefficient update field valid. */
+	uint64_t ld_cu_dat                    : 16; /**< Local device coefficient update field data. */
 	uint64_t reserved_17_31               : 15;
-	uint64_t ld_sr_val                    : 1;  /**< Local device status report field valid */
-	uint64_t ld_sr_dat                    : 16; /**< Local device status report field data */
+	uint64_t ld_sr_val                    : 1;  /**< Local device status report field valid. */
+	uint64_t ld_sr_dat                    : 16; /**< Local device status report field data. */
 #else
 	uint64_t ld_sr_dat                    : 16;
 	uint64_t ld_sr_val                    : 1;
@@ -657,11 +657,11 @@ union cvmx_ila_lnex_trn_lp {
 	struct cvmx_ila_lnex_trn_lp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_49_63               : 15;
-	uint64_t lp_cu_val                    : 1;  /**< Link partner coefficient update field valid */
-	uint64_t lp_cu_dat                    : 16; /**< Link partner coefficient update field data */
+	uint64_t lp_cu_val                    : 1;  /**< Link partner coefficient update field valid. */
+	uint64_t lp_cu_dat                    : 16; /**< Link partner coefficient update field data. */
 	uint64_t reserved_17_31               : 15;
-	uint64_t lp_sr_val                    : 1;  /**< Link partner status report field valid */
-	uint64_t lp_sr_dat                    : 16; /**< Link partner status report field data */
+	uint64_t lp_sr_val                    : 1;  /**< Link partner status report field valid. */
+	uint64_t lp_sr_dat                    : 16; /**< Link partner status report field data. */
 #else
 	uint64_t lp_sr_dat                    : 16;
 	uint64_t lp_sr_val                    : 1;
@@ -839,8 +839,8 @@ union cvmx_ila_rxx_cfg1 {
 	struct cvmx_ila_rxx_cfg1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_22_63               : 42;
-	uint64_t pkt_flush                    : 1;  /**< Packet receive flush. Setting this bit to1 causes all open packets to be error-out, just
-                                                         as though the link went down. */
+	uint64_t pkt_flush                    : 1;  /**< Packet receive flush. Setting this bit causes all open packets to be error-out, just as
+                                                         though the link went down. */
 	uint64_t pkt_ena                      : 1;  /**< Packet receive enable. When set to 0, any received SOP causes the entire packet to be dropped. */
 	uint64_t reserved_19_19               : 1;
 	uint64_t tx_link_fc                   : 1;  /**< Link flow-control status transmitted by the TX-link XON (=1) when RX_FIFO_CNT <=
@@ -904,7 +904,7 @@ union cvmx_ila_rxx_int {
 	uint64_t lane_align_done              : 1;  /**< Lane alignment successful. */
 	uint64_t word_sync_done               : 1;  /**< All enabled lanes have achieved word-boundary lock and scrambler synchronization. Lane
                                                          alignment may now be enabled. */
-	uint64_t crc24_err                    : 1;  /**< Burst CRC24 error.  All open packets receive an error. */
+	uint64_t crc24_err                    : 1;  /**< Burst CRC24 error. All open packets receive an error. */
 	uint64_t lane_align_fail              : 1;  /**< Lane alignment fails after four tries. Hardware repeats lane alignment until is succeeds
                                                          or until ILA_RX(0)_CFG1[RX_ALIGN_ENA] = 0. */
 #else
@@ -1519,9 +1519,11 @@ union cvmx_ila_txx_cfg0 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_63_63               : 1;
 	uint64_t ext_lpbk                     : 1;  /**< Enable RX-TX data external loopback. Note that with differing transmit and receive clocks,
-                                                         skip word are inserted/deleted. */
+                                                         skip word are inserted/deleted. Must set ILA_TX(0)_CFG1[RX_LINK_FC_IGN] whenever enabling
+                                                         external loopback. */
 	uint64_t int_lpbk                     : 1;  /**< Enable TX-RX internal loopback. */
-	uint64_t reserved_56_60               : 5;
+	uint64_t txf_byp_dis                  : 1;  /**< Disable TXF bypass. */
+	uint64_t reserved_56_59               : 4;
 	uint64_t lnk_stats_rdclr              : 1;  /**< CSR read to ILA_TXx_STAT* clears the counter after returning its current value. */
 	uint64_t lnk_stats_ena                : 1;  /**< Enable link statistics counters */
 	uint64_t reserved_52_53               : 2;
@@ -1560,7 +1562,8 @@ union cvmx_ila_txx_cfg0 {
 	uint64_t reserved_52_53               : 2;
 	uint64_t lnk_stats_ena                : 1;
 	uint64_t lnk_stats_rdclr              : 1;
-	uint64_t reserved_56_60               : 5;
+	uint64_t reserved_56_59               : 4;
+	uint64_t txf_byp_dis                  : 1;
 	uint64_t int_lpbk                     : 1;
 	uint64_t ext_lpbk                     : 1;
 	uint64_t reserved_63_63               : 1;
@@ -1577,8 +1580,7 @@ union cvmx_ila_txx_cfg1 {
 	uint64_t u64;
 	struct cvmx_ila_txx_cfg1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_44_63               : 20;
-	uint64_t txf_byp_dis                  : 1;  /**< TX-FIFO bypass disable. */
+	uint64_t reserved_43_63               : 21;
 	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes. If 0x0, hardware
                                                          will compute it. Otherwise, SER_LIMIT must be set as follows:
                                                          SER_LIMIT >= 148 + (BAUD / SCLK) * (12 + NUM_LANES)
@@ -1592,21 +1594,29 @@ union cvmx_ila_txx_cfg1 {
                                                          Software should first write
                                                          PKT_ENA = 0 and wait for PKT_BUSY = 0. */
 	uint64_t pkt_ena                      : 1;  /**< Packet transmit enable. When zero, the TX-link stops transmitting packets, as per RX_LINK_FC_PKT. */
-	uint64_t reserved_9_19                : 11;
+	uint64_t la_mode                      : 1;  /**< Enable Interlaken look-aside traffic. Used to set the protocol type of idle words. */
+	uint64_t reserved_12_18               : 7;
+	uint64_t tx_link_fc_jam               : 1;  /**< Reserved. */
+	uint64_t rx_link_fc_pkt               : 1;  /**< Flow-control received in burst/idle control words cause TX-link to stop transmitting at
+                                                         the end of a packet instead of the end of a burst. */
+	uint64_t rx_link_fc_ign               : 1;  /**< Ignore flow-control status received in burst/idle control words. */
 	uint64_t rmatch                       : 1;  /**< Enable rate-matching circuitry. */
 	uint64_t reserved_0_7                 : 8;
 #else
 	uint64_t reserved_0_7                 : 8;
 	uint64_t rmatch                       : 1;
-	uint64_t reserved_9_19                : 11;
+	uint64_t rx_link_fc_ign               : 1;
+	uint64_t rx_link_fc_pkt               : 1;
+	uint64_t tx_link_fc_jam               : 1;
+	uint64_t reserved_12_18               : 7;
+	uint64_t la_mode                      : 1;
 	uint64_t pkt_ena                      : 1;
 	uint64_t pkt_flush                    : 1;
 	uint64_t skip_cnt                     : 4;
 	uint64_t reserved_26_31               : 6;
 	uint64_t pkt_busy                     : 1;
 	uint64_t ser_limit                    : 10;
-	uint64_t txf_byp_dis                  : 1;
-	uint64_t reserved_44_63               : 20;
+	uint64_t reserved_43_63               : 21;
 #endif
 	} s;
 	struct cvmx_ila_txx_cfg1_s            cn78xx;
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
index 57a70899..8640e8a 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
@@ -1616,9 +1616,9 @@ union cvmx_ilk_lnex_trn_ctl {
 	struct cvmx_ilk_lnex_trn_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t trn_lock                     : 1;  /**< Link training RX frame lock */
-	uint64_t trn_done                     : 1;  /**< Link training done */
-	uint64_t trn_ena                      : 1;  /**< Link training enable */
+	uint64_t trn_lock                     : 1;  /**< Link training RX frame lock. */
+	uint64_t trn_done                     : 1;  /**< Link training done. */
+	uint64_t trn_ena                      : 1;  /**< Link training enable. */
 	uint64_t eie_det                      : 1;  /**< Reserved. */
 #else
 	uint64_t eie_det                      : 1;
@@ -1640,11 +1640,11 @@ union cvmx_ilk_lnex_trn_ld {
 	struct cvmx_ilk_lnex_trn_ld_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_49_63               : 15;
-	uint64_t ld_cu_val                    : 1;  /**< Local device coefficient update field valid */
-	uint64_t ld_cu_dat                    : 16; /**< Local device coefficient update field data */
+	uint64_t ld_cu_val                    : 1;  /**< Local device coefficient update field valid. */
+	uint64_t ld_cu_dat                    : 16; /**< Local device coefficient update field data. */
 	uint64_t reserved_17_31               : 15;
-	uint64_t ld_sr_val                    : 1;  /**< Local device status report field valid */
-	uint64_t ld_sr_dat                    : 16; /**< Local device status report field data */
+	uint64_t ld_sr_val                    : 1;  /**< Local device status report field valid. */
+	uint64_t ld_sr_dat                    : 16; /**< Local device status report field data. */
 #else
 	uint64_t ld_sr_dat                    : 16;
 	uint64_t ld_sr_val                    : 1;
@@ -1666,11 +1666,11 @@ union cvmx_ilk_lnex_trn_lp {
 	struct cvmx_ilk_lnex_trn_lp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_49_63               : 15;
-	uint64_t lp_cu_val                    : 1;  /**< Link partner coefficient update field valid */
-	uint64_t lp_cu_dat                    : 16; /**< Link partner coefficient update field data */
+	uint64_t lp_cu_val                    : 1;  /**< Link partner coefficient update field valid. */
+	uint64_t lp_cu_dat                    : 16; /**< Link partner coefficient update field data. */
 	uint64_t reserved_17_31               : 15;
-	uint64_t lp_sr_val                    : 1;  /**< Link partner status report field valid */
-	uint64_t lp_sr_dat                    : 16; /**< Link partner status report field data */
+	uint64_t lp_sr_val                    : 1;  /**< Link partner status report field valid. */
+	uint64_t lp_sr_dat                    : 16; /**< Link partner status report field data. */
 #else
 	uint64_t lp_sr_dat                    : 16;
 	uint64_t lp_sr_val                    : 1;
@@ -1866,7 +1866,7 @@ union cvmx_ilk_rxx_cal_entryx {
                                                          3 = XON
                                                          This field applies to one of bits <55>, <47>, or <31> in the Interlaken control word. */
 	uint64_t reserved_8_31                : 24;
-	uint64_t channel                      : 8;  /**< PKO channel for the calendar table entry. Unused if CTL != 0x0. */
+	uint64_t channel                      : 8;  /**< PKO channel for the calendar table entry. Unused if CTL == 0x1. */
 #else
 	uint64_t channel                      : 8;
 	uint64_t reserved_8_31                : 24;
@@ -2133,8 +2133,8 @@ union cvmx_ilk_rxx_cfg1 {
 	uint64_t rx_fifo_max                  : 13; /**< Specifies the maximum number of 64-bit words consumed by this link in the RX FIFO. The sum
                                                          of all links should be equal to 4096 (32KB). LSB must be zero. Typically set to
                                                          RX_FIFO_HWM * 2. */
-	uint64_t pkt_flush                    : 1;  /**< Packet receive flush. Setting this bit to1 causes all open packets to be error-out, just
-                                                         as though the link went down. */
+	uint64_t pkt_flush                    : 1;  /**< Packet receive flush. Setting this bit causes all open packets to be error-out, just as
+                                                         though the link went down. */
 	uint64_t pkt_ena                      : 1;  /**< Packet receive enable. When set to 0, any received SOP causes the entire packet to be dropped. */
 	uint64_t la_mode                      : 1;  /**< Reserved. */
 	uint64_t tx_link_fc                   : 1;  /**< Link flow-control status transmitted by the TX-link XON (=1) when RX_FIFO_CNT <=
@@ -3888,7 +3888,7 @@ union cvmx_ilk_ser_cfg {
                                                          SER_TXPOL[13] = QLM7 lane 1
                                                          SER_TXPOL[14] = QLM7 lane 2
                                                          SER_TXPOL[15] = QLM7 lane 3 */
-	uint64_t ser_reset_n                  : 16; /**< Reserved. */
+	uint64_t ser_reset_n                  : 16; /**< SerDes lane reset. */
 	uint64_t ser_pwrup                    : 4;  /**< Reserved. */
 	uint64_t ser_haul                     : 4;  /**< Reserved. */
 #else
@@ -4017,8 +4017,8 @@ union cvmx_ilk_txx_cfg0 {
                                                          entry 18 = backpressure ID 16
                                                          - ...
                                                          This continues until the calendar depth is reached.
-                                                         To disable backpressure completely, enable the calendar table
-                                                         and program each calendar table entry to transmit XON */
+                                                         To disable backpressure completely, enable the calendar table and program each calendar
+                                                         table entry to transmit XON. */
 	uint64_t mfrm_len                     : 13; /**< The quantity of data sent on each lane including one sync word, scrambler state, diag
                                                          word, zero or more skip words, and the data payload. Must be large than
                                                          ILK_TX(0..1)_CFG1[SKIP_CNT] + 32.
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk.h b/arch/mips/include/asm/octeon/cvmx-ilk.h
index 815fed1..a037e3f 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk.h
@@ -106,7 +106,7 @@ typedef struct {
 
 #define CVMX_ILK_MAX_PIPES 45
 /* Max number of channels allowed */
-#define CVMX_ILK_MAX_CHANS 8
+#define CVMX_ILK_MAX_CHANS 8	//FIXME: increase for CN78XX !
 
 extern CVMX_SHARED unsigned char cvmx_ilk_chans[CVMX_NUM_ILK_INTF];
 extern unsigned char cvmx_ilk_chan_map[CVMX_NUM_ILK_INTF][CVMX_ILK_MAX_CHANS];
diff --git a/arch/mips/include/asm/octeon/cvmx-iobn-defs.h b/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
index 30b0e39..9fdab1f 100644
--- a/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
@@ -130,6 +130,17 @@ static inline uint64_t CVMX_IOBN_ECC_FUNC(void)
 #define CVMX_IOBN_ECC (CVMX_ADD_IO_SEG(0x00011800F0000010ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_IOBN_GBL_DLL CVMX_IOBN_GBL_DLL_FUNC()
+static inline uint64_t CVMX_IOBN_GBL_DLL_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_IOBN_GBL_DLL not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800F0001000ull);
+}
+#else
+#define CVMX_IOBN_GBL_DLL (CVMX_ADD_IO_SEG(0x00011800F0001000ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_IOBN_HIGH_PRIORITY CVMX_IOBN_HIGH_PRIORITY_FUNC()
 static inline uint64_t CVMX_IOBN_HIGH_PRIORITY_FUNC(void)
 {
@@ -247,20 +258,18 @@ union cvmx_iobn_chip_cur_pwr {
 	struct cvmx_iobn_chip_cur_pwr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
-	uint64_t current_power_setting        : 8;  /**< Global throttling value currently being used.
-                                                         Throttling can force units (CPU cores, in particular) idle for a
-                                                         portion of time, which will reduce power consumption.  When
-                                                         CURRENT_POWER_SETTING is equal to zero, the unit is idle most
-                                                         of the time and consumes minimum power. When CURRENT_POWER_SETTING
-                                                         is equal to 0xFF, units are never idled to reduce power.
-                                                         The hardware generally uses a CURRENT_POWER_SETTING value that
-                                                         is as large as possible (in order to maximize performance) subject
-                                                         to the following constraints (in priority order):
-                                                           - PWR_MIN <= CURRENT_POWER_SETTING <= PWR_MAX
-                                                           - Power limits from the PWR_SETTING feedback control system
-                                                         In the case of the CPU cores, CURRENT_POWER_SETTING effectively
-                                                         limits the CP0 PowThrottle[POWLIM] value:
-                                                           effective POWLIM = MINIMUM(CURRENT_POWER_SETTING,PowThrottle[POWLIM]) */
+	uint64_t current_power_setting        : 8;  /**< Global throttling value currently being used. Throttling can force units (CPU cores, in
+                                                         particular) idle for a portion of time, which will reduce power consumption. When
+                                                         CURRENT_POWER_SETTING is equal to zero, the unit is idle most of the time and consumes
+                                                         minimum power. When CURRENT_POWER_SETTING is equal to 0xFF, units are never idled to
+                                                         reduce power. The hardware generally uses a CURRENT_POWER_SETTING value that is as large
+                                                         as possible (in order to maximize performance) subject to the following constraints (in
+                                                         priority order):
+                                                         * PWR_MIN <= CURRENT_POWER_SETTING <=PWR_MAX
+                                                         * Power limits from the PWR_SETTING feedback control system
+                                                         In the case of the CPU cores, CURRENT_POWER_SETTING effectively limits the CP0
+                                                         PowThrottle[POWLIM] value: effective POWLIM = MINIMUM(CURRENT_POWER_SETTING,
+                                                         PowThrottle[POWLIM]) */
 #else
 	uint64_t current_power_setting        : 8;
 	uint64_t reserved_8_63                : 56;
@@ -281,37 +290,25 @@ union cvmx_iobn_chip_glb_pwr_throttle {
 	struct cvmx_iobn_chip_glb_pwr_throttle_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
-	uint64_t pwr_bw                       : 2;  /**< Configures the reaction time of the closed-loop feedback
-                                                         control system for the AVG_CHIP_POWER power approximation.
-                                                         Higher numbers decrease bandwidth, reducing response time,
-                                                         which could lead to greater tracking error, but reduce
-                                                         ringing. */
-	uint64_t pwr_max                      : 8;  /**< Maximum allowed CURRENT_POWER_SETTING value. PWR_MAX must
-                                                         be >= PWR_MIN. */
-	uint64_t pwr_min                      : 8;  /**< Minimum allowed CURRENT_POWER_SETTING value. PWR_MIN must
-                                                         be <= PWR_MAX.
-                                                         We recommend a PWR_MIN value larger than zero to set a
-                                                         minimum performance level in case PWR_SETTING is set to
-                                                         an unreachable goal. See the CPU CP0 PowThrottle description.
-                                                         PWR_MIN = 50% of PowThrottle[MAXPOW] could be a good
-                                                         choice, for example. */
-	uint64_t pwr_setting                  : 16; /**< A power limiter for the chip.
-                                                         A limiter of the power consumption of the chip. This power
-                                                         limiting is implemented by a closed-loop feedback control
-                                                         system for the AVG_CHIP_POWER power approximation. The
-                                                         direct output of the PWR_SETTING feedback control system
-                                                         is the CURRENT_POWER_SETTING value. The power consumed
-                                                         by the chip (estimated currently by the AVG_CHIP_POWER
-                                                         value) is an indirect output of the PWR_SETTING feedback
-                                                         control system.
-                                                         PWR_SETTING is not used by the hardware when PWR_MIN equals
-                                                         PWR_MAX. PWR_MIN and PWR_MAX threshold requirements always
-                                                         supercede PWR_SETTING limits. (For maximum PWR_SETTING
+	uint64_t pwr_bw                       : 2;  /**< Configures the reaction time of the closed-loop feedback control system for the
+                                                         AVG_CHIP_POWER power approximation. Higher numbers decrease bandwidth, reducing response
+                                                         time, which could lead to greater tracking error, but reduce ringing. */
+	uint64_t pwr_max                      : 8;  /**< Maximum allowed CURRENT_POWER_SETTING value. PWR_MAX must be >= PWR_MIN. */
+	uint64_t pwr_min                      : 8;  /**< Minimum allowed CURRENT_POWER_SETTING value. PWR_MIN must be <= PWR_MAX. We recommend a
+                                                         PWR_MIN value larger than zero to set a minimum performance level in case PWR_SETTING is
+                                                         set to an unreachable goal. See the CPU CP0 PowThrottle description. PWR_MIN = 50% of
+                                                         PowThrottle[MAXPOW] could be a good choice, for example. */
+	uint64_t pwr_setting                  : 16; /**< A power limiter for the chip. A limiter of the power consumption of the chip. This power
+                                                         limiting is implemented by a closed-loop feedback control system for the AVG_CHIP_POWER
+                                                         power approximation. The direct output of the PWR_SETTING feedback control system is the
+                                                         CURRENT_POWER_SETTING value. The power consumed by the chip (estimated currently by the
+                                                         AVG_CHIP_POWER value) is an indirect output of the PWR_SETTING feedback control system.
+                                                         PWR_SETTING is not used by the hardware when PWR_MIN equals PWR_MAX. PWR_MIN and PWR_MAX
+                                                         threshold requirements always supercede PWR_SETTING limits. (For maximum PWR_SETTING
                                                          feedback control freedom, set PWR_MIN=0 and PWR_MAX=0xff.)
-                                                         PWR_SETTING equal to 0 forces the chip to consume near
-                                                         minimum power. Increasing PWR_SETTING value from 0 to
-                                                         0xffff increases the power that the chip is alloed to
-                                                         consume linearly (roughly) from minimum to maximum. */
+                                                         PWR_SETTING equal to 0 forces the chip to consume near minimum power. Increasing
+                                                         PWR_SETTING value from 0 to 0xFFFF increases the power that the chip is allowed to consume
+                                                         linearly (roughly) from minimum to maximum. */
 #else
 	uint64_t pwr_setting                  : 16;
 	uint64_t pwr_min                      : 8;
@@ -334,21 +331,17 @@ union cvmx_iobn_chip_pwr_out {
 	uint64_t u64;
 	struct cvmx_iobn_chip_pwr_out_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t cpu_pwr                      : 16; /**< An estimate of the current CPU core complex power consumption.
-                                                         The CPU core complex includes the caches and DRAM controller(s),
-                                                         as well as all CPU cores. Linearly larger values indicate linearly
-                                                         higher power consumption. This power consumption estimate is
+	uint64_t cpu_pwr                      : 16; /**< An estimate of the current CPU core complex power consumption. The CPU core complex
+                                                         includes the caches and DRAM controller(s), as well as all CPU cores. Linearly larger
+                                                         values indicate linearly higher power consumption. This power consumption estimate is
                                                          energy per core clock. */
-	uint64_t chip_power                   : 16; /**< An estimate of the current total power consumption by the chip.
-                                                         Linearly larger values indicate linearly higher power consumption.
-                                                         CHIP_POWER is the sum of CPU_POWER and COPROC_POWER. */
-	uint64_t coproc_power                 : 16; /**< An estimate of the current coprocessor power consumption.
-                                                         Linearly larger values indicate linearly higher power consumption.
-                                                         This estimate is energy per core clock, and will
-                                                         generally decrease as the ratio of core to coprocessor clock
-                                                         speed increases. */
-	uint64_t avg_chip_power               : 16; /**< An average of CHIP_POWER, calculated using an IIR filter with
-                                                         an average weight of 16K core clocks. */
+	uint64_t chip_power                   : 16; /**< An estimate of the current total power consumption by the chip. Linearly larger values
+                                                         indicate linearly higher power consumption. CHIP_POWER is the sum of CPU_POWER and
+                                                         COPROC_POWER. */
+	uint64_t coproc_power                 : 16; /**< An estimate of the current coprocessor power consumption. Linearly larger values indicate
+                                                         linearly higher power consumption. This estimate is energy per core clock, and will
+                                                         generally decrease as the ratio of core to coprocessor clock speed increases. */
+	uint64_t avg_chip_power               : 16; /**< An average of CHIP_POWER, calculated using an IIR filter with an average weight of 16K core clocks. */
 #else
 	uint64_t avg_chip_power               : 16;
 	uint64_t coproc_power                 : 16;
@@ -475,7 +468,7 @@ union cvmx_iobn_ecc {
 	uint64_t rsd2_fs                      : 2;  /**< Used to flip the syndrome for NCBO2 response data. */
 	uint64_t rsd1_ecc                     : 1;  /**< When set, NCBO1 response data has ECC generated and checked. */
 	uint64_t rsd1_fs                      : 2;  /**< Used to flip the syndrome for NCBO1 response data. */
-	uint64_t rsd0_ecc                     : 1;  /**< When set NCBO0 response data have an ECC generated and checked. */
+	uint64_t rsd0_ecc                     : 1;  /**< When set, NCBO0 response data have an ECC generated and checked. */
 	uint64_t rsd0_fs                      : 2;  /**< Used to flip the syndrome for NCBO0 response data. */
 	uint64_t xmc3_ecc                     : 1;  /**< When set, NCBI0 commands to L2C have ECC generated and checked. */
 	uint64_t xmc3_fs                      : 2;  /**< Used to flip the syndrome for commands from NCBI0 to the L2C. */
@@ -538,6 +531,45 @@ union cvmx_iobn_ecc {
 typedef union cvmx_iobn_ecc cvmx_iobn_ecc_t;
 
 /**
+ * cvmx_iobn_gbl_dll
+ *
+ * Status of the global core-clock DLL.
+ *
+ */
+union cvmx_iobn_gbl_dll {
+	uint64_t u64;
+	struct cvmx_iobn_gbl_dll_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_20_63               : 44;
+	uint64_t pdr_rclk_refclk              : 1;  /**< Synchronized pdr_rclk_refclk from global core-clock DLL cmb0 phase detectors. */
+	uint64_t pdl_rclk_refclk              : 1;  /**< Synchronized pdl_rclk_refclk from global core-clock DLL cmb0 phase detectors. */
+	uint64_t pd_pos_rclk_refclk           : 1;  /**< Synchronized pd_pos_rclk_refclk from global core-clock DLL cmb0 phase detectors. */
+	uint64_t dll_fsm_state_a              : 3;  /**< State for the global core-clock DLL, from the positive edge of refclk.
+                                                         0x0 = TMD_IDLE
+                                                         0x1 = TMD_STATE1
+                                                         0x2 = TMD_STATE2
+                                                         0x3 = TMD_STATE3
+                                                         0x4 = TMD_STATE4
+                                                         0x5 = TMD_LOCKED */
+	uint64_t dll_lock                     : 1;  /**< The dll_lock signal from global core-clock DLL, from the positive edge of refclk. */
+	uint64_t dll_clk_invert_out           : 1;  /**< The clk_invert setting from the global core-clock DLL, from the negative edge of refclk. */
+	uint64_t dll_setting                  : 12; /**< The global core-clock DLL, from the negative edge of refclk. */
+#else
+	uint64_t dll_setting                  : 12;
+	uint64_t dll_clk_invert_out           : 1;
+	uint64_t dll_lock                     : 1;
+	uint64_t dll_fsm_state_a              : 3;
+	uint64_t pd_pos_rclk_refclk           : 1;
+	uint64_t pdl_rclk_refclk              : 1;
+	uint64_t pdr_rclk_refclk              : 1;
+	uint64_t reserved_20_63               : 44;
+#endif
+	} s;
+	struct cvmx_iobn_gbl_dll_s            cn78xx;
+};
+typedef union cvmx_iobn_gbl_dll cvmx_iobn_gbl_dll_t;
+
+/**
  * cvmx_iobn_high_priority
  *
  * For NCB0, this register sets which of the NCB devices (0-15) receive high-priority status for
diff --git a/arch/mips/include/asm/octeon/cvmx-ipd-defs.h b/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
index 26fce64..75583c0 100644
--- a/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
@@ -348,7 +348,7 @@ static inline uint64_t CVMX_IPD_PORT_QOS_INTX(unsigned long offset)
 	      (OCTEON_IS_MODEL(OCTEON_CN63XX) && ((offset == 0) || (offset == 4) || (offset == 5))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN66XX) && ((offset == 0) || (offset == 2) || (offset == 4) || (offset == 5))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN68XX) && ((offset <= 7))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((offset == 0) || (offset == 2) || (offset == 3) || (offset == 4) || (offset == 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((offset == 0) || (offset == 2) || (offset == 3) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset == 0) || (offset == 2) || (offset == 4) || (offset == 5)))))
 		cvmx_warn("CVMX_IPD_PORT_QOS_INTX(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00014F0000000808ull) + ((offset) & 7) * 8;
@@ -366,7 +366,7 @@ static inline uint64_t CVMX_IPD_PORT_QOS_INT_ENBX(unsigned long offset)
 	      (OCTEON_IS_MODEL(OCTEON_CN63XX) && ((offset == 0) || (offset == 4) || (offset == 5))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN66XX) && ((offset == 0) || (offset == 2) || (offset == 4) || (offset == 5))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CN68XX) && ((offset <= 7))) ||
-	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((offset == 0) || (offset == 2) || (offset == 3) || (offset == 4) || (offset == 5))) ||
+	      (OCTEON_IS_MODEL(OCTEON_CN70XX) && ((offset == 0) || (offset == 2) || (offset == 3) || (offset == 4))) ||
 	      (OCTEON_IS_MODEL(OCTEON_CNF71XX) && ((offset == 0) || (offset == 2) || (offset == 4) || (offset == 5)))))
 		cvmx_warn("CVMX_IPD_PORT_QOS_INT_ENBX(%lu) is invalid on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x00014F0000000848ull) + ((offset) & 7) * 8;
diff --git a/arch/mips/include/asm/octeon/cvmx-ipd.h b/arch/mips/include/asm/octeon/cvmx-ipd.h
index 41608cf..fac5406 100644
--- a/arch/mips/include/asm/octeon/cvmx-ipd.h
+++ b/arch/mips/include/asm/octeon/cvmx-ipd.h
@@ -42,7 +42,7 @@
  *
  * Interface to the hardware Input Packet Data unit.
  *
- * <hr>$Revision: 79509 $<hr>
+ * <hr>$Revision: 94747 $<hr>
  */
 
 #ifndef __CVMX_IPD_H__
@@ -51,11 +51,12 @@
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-ipd-defs.h>
+#include <asm/octeon/cvmx-helper-pki.h>
 #else
-#ifndef CVMX_DONT_INCLUDE_CONFIG
-#endif
+#include "cvmx-helper-pki.h"
 #endif
 
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 extern "C" {
@@ -108,6 +109,10 @@ extern CVMX_SHARED cvmx_ipd_config_t cvmx_ipd_cfg;
  */
 static inline int64_t cvmx_fpa_get_packet_pool(void)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		int node = cvmx_get_node_num();
+		return pki_dflt_pool[node].pool_num;
+	}
 	return (cvmx_ipd_cfg.packet_pool.pool_num);
 }
 
@@ -116,6 +121,10 @@ static inline int64_t cvmx_fpa_get_packet_pool(void)
  */
 static inline uint64_t cvmx_fpa_get_packet_pool_block_size(void)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		int node = cvmx_get_node_num();
+		return pki_dflt_pool[node].buffer_size;
+	}
 	return (cvmx_ipd_cfg.packet_pool.buffer_size);
 }
 
@@ -124,6 +133,10 @@ static inline uint64_t cvmx_fpa_get_packet_pool_block_size(void)
  */
 static inline uint64_t cvmx_fpa_get_packet_pool_buffer_count(void)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		int node = cvmx_get_node_num();
+		return pki_dflt_pool[node].buffer_count;
+	}
 	return (cvmx_ipd_cfg.packet_pool.buffer_count);
 }
 
@@ -132,6 +145,10 @@ static inline uint64_t cvmx_fpa_get_packet_pool_buffer_count(void)
  */
 static inline int64_t cvmx_fpa_get_wqe_pool(void)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		int node = cvmx_get_node_num();
+		return pki_dflt_pool[node].pool_num;
+	}
 	return (cvmx_ipd_cfg.wqe_pool.pool_num);
 }
 
@@ -140,6 +157,10 @@ static inline int64_t cvmx_fpa_get_wqe_pool(void)
  */
 static inline uint64_t cvmx_fpa_get_wqe_pool_block_size(void)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		int node = cvmx_get_node_num();
+		return pki_dflt_pool[node].buffer_size;
+	}
 	return (cvmx_ipd_cfg.wqe_pool.buffer_size);
 }
 
@@ -148,6 +169,10 @@ static inline uint64_t cvmx_fpa_get_wqe_pool_block_size(void)
  */
 static inline uint64_t cvmx_fpa_get_wqe_pool_buffer_count(void)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		int node = cvmx_get_node_num();
+		return pki_dflt_pool[node].buffer_count;
+	}
 	return (cvmx_ipd_cfg.wqe_pool.buffer_count);
 }
 
@@ -215,6 +240,39 @@ void cvmx_ipd_disable(void);
 
 void __cvmx_ipd_free_ptr(void);
 
+void cvmx_ipd_set_packet_pool_buffer_count(uint64_t buffer_count);
+void cvmx_ipd_set_wqe_pool_buffer_count(uint64_t buffer_count);
+
+/**
+ * Setup Random Early Drop on a specific input queue
+ *
+ * @param queue  Input queue to setup RED on (0-7)
+ * @param pass_thresh
+ *               Packets will begin slowly dropping when there are less than
+ *               this many packet buffers free in FPA 0.
+ * @param drop_thresh
+ *               All incomming packets will be dropped when there are less
+ *               than this many free packet buffers in FPA 0.
+ * @return Zero on success. Negative on failure
+ */
+extern int cvmx_ipd_setup_red_queue(int queue, int pass_thresh, int drop_thresh);
+
+/**
+ * Setup Random Early Drop to automatically begin dropping packets.
+ *
+ * @param pass_thresh
+ *               Packets will begin slowly dropping when there are less than
+ *               this many packet buffers free in FPA 0.
+ * @param drop_thresh
+ *               All incomming packets will be dropped when there are less
+ *               than this many free packet buffers in FPA 0.
+ * @return Zero on success. Negative on failure
+ */
+extern int cvmx_ipd_setup_red(int pass_thresh, int drop_thresh);
+
+/* Legacy name */
+#define cvmx_helper_setup_red(p,d) cvmx_ipd_setup_red(p, d)
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-l2c-defs.h b/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
index cc005b1..270ced1 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
@@ -176,6 +176,17 @@ static inline uint64_t CVMX_L2C_CBCX_DLL(unsigned long block_id)
 #define CVMX_L2C_CBCX_DLL(block_id) (CVMX_ADD_IO_SEG(0x0001180080E00018ull) + ((block_id) & 3) * 0x40000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_L2C_CBCX_HOLEERR(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
+		cvmx_warn("CVMX_L2C_CBCX_HOLEERR(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180080E007D0ull) + ((block_id) & 3) * 0x40000ull;
+}
+#else
+#define CVMX_L2C_CBCX_HOLEERR(block_id) (CVMX_ADD_IO_SEG(0x0001180080E007D0ull) + ((block_id) & 3) * 0x40000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_L2C_CBCX_INT(unsigned long block_id)
 {
 	if (!(
@@ -200,6 +211,17 @@ static inline uint64_t CVMX_L2C_CBCX_IOCERR(unsigned long block_id)
 #define CVMX_L2C_CBCX_IOCERR(block_id) (CVMX_ADD_IO_SEG(0x0001180080E007E8ull) + ((block_id) & 3) * 0x40000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_L2C_CBCX_IODISOCIERR(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 3)))))
+		cvmx_warn("CVMX_L2C_CBCX_IODISOCIERR(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180080E007D8ull) + ((block_id) & 3) * 0x40000ull;
+}
+#else
+#define CVMX_L2C_CBCX_IODISOCIERR(block_id) (CVMX_ADD_IO_SEG(0x0001180080E007D8ull) + ((block_id) & 3) * 0x40000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_L2C_CBCX_MIBERR(unsigned long block_id)
 {
 	if (!(
@@ -1124,6 +1146,28 @@ static inline uint64_t CVMX_L2C_TADX_TAG(unsigned long block_id)
 #define CVMX_L2C_TADX_TAG(block_id) (CVMX_ADD_IO_SEG(0x0001180080A00010ull) + ((block_id) & 7) * 0x40000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_L2C_TADX_TIMEOUT(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 7)))))
+		cvmx_warn("CVMX_L2C_TADX_TIMEOUT(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180080A007C8ull) + ((block_id) & 7) * 0x40000ull;
+}
+#else
+#define CVMX_L2C_TADX_TIMEOUT(block_id) (CVMX_ADD_IO_SEG(0x0001180080A007C8ull) + ((block_id) & 7) * 0x40000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_L2C_TADX_TIMETWO(unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 7)))))
+		cvmx_warn("CVMX_L2C_TADX_TIMETWO(%lu) is invalid on this chip\n", block_id);
+	return CVMX_ADD_IO_SEG(0x0001180080A007C0ull) + ((block_id) & 7) * 0x40000ull;
+}
+#else
+#define CVMX_L2C_TADX_TIMETWO(block_id) (CVMX_ADD_IO_SEG(0x0001180080A007C0ull) + ((block_id) & 7) * 0x40000ull)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_L2C_TAD_CTL CVMX_L2C_TAD_CTL_FUNC()
 static inline uint64_t CVMX_L2C_TAD_CTL_FUNC(void)
 {
@@ -1521,13 +1565,11 @@ union cvmx_l2c_big_ctl {
                                                          0xA = 256 GB.
                                                          0xB = 512 GB.
                                                          0xC-0xF= reserved.
-                                                         Violations of this limit causes L2C to set L2C_INT_REG[BIGRD/BIGWR].
+                                                         Violations of this limit causes L2C to set L2C_TAD*_INT[BIGRD/BIGWR].
                                                          BIGRD interrupts can occur during normal operation as the cores are allowed to prefetch to
                                                          nonexistent memory locations. Therefore, BIGRD is for informational purposes only.
                                                          When a HOLERD/BIGRD occurs or HOLEWR/BIGWR blocks a store operation, L2C_TAD(0..0)_ERR is
-                                                         loaded. L2C_TAD(0..0)_ERR is not locked for a BIGRD, however.
-                                                         The BIG logic only applies to local addresses. A command for a remote address does not
-                                                         cause a BIGRD/BIGWR on the requesting node. */
+                                                         loaded. L2C_TAD(0..0)_ERR is not locked for a BIGRD, however. */
 	uint64_t reserved_1_3                 : 3;
 	uint64_t disbig                       : 1;  /**< Disable the BIG/HOLE logic. When set, the BIG/HOLE is logic disabled completely. When
                                                          clear, BIGWR and HOLEWR block stores and BIGRD/HOLERD is reported. */
@@ -2259,15 +2301,11 @@ union cvmx_l2c_cbcx_bist_status {
 	uint64_t u64;
 	struct cvmx_l2c_cbcx_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_39_63               : 25;
-	uint64_t mibfl                        : 5;  /**< BIST failure status for various MIB memories. ([XMD, IPM, IRM, MXD, MXN]) */
-	uint64_t ioccmdfl                     : 2;  /**< BIST failure status for IOCCMD0-1. */
+	uint64_t reserved_32_63               : 32;
 	uint64_t rsdfl                        : 32; /**< BIST failure status for RSDQW0-31. */
 #else
 	uint64_t rsdfl                        : 32;
-	uint64_t ioccmdfl                     : 2;
-	uint64_t mibfl                        : 5;
-	uint64_t reserved_39_63               : 25;
+	uint64_t reserved_32_63               : 32;
 #endif
 	} s;
 	struct cvmx_l2c_cbcx_bist_status_cn70xx {
@@ -2281,7 +2319,17 @@ union cvmx_l2c_cbcx_bist_status {
 	uint64_t reserved_34_63               : 30;
 #endif
 	} cn70xx;
-	struct cvmx_l2c_cbcx_bist_status_s    cn78xx;
+	struct cvmx_l2c_cbcx_bist_status_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_37_63               : 27;
+	uint64_t mibfl                        : 5;  /**< BIST failure status for various MIB memories. ([XMD, IPM, IRM, MXD, MXN]) */
+	uint64_t rsdfl                        : 32; /**< BIST failure status for RSDQW0-31. */
+#else
+	uint64_t rsdfl                        : 32;
+	uint64_t mibfl                        : 5;
+	uint64_t reserved_37_63               : 27;
+#endif
+	} cn78xx;
 };
 typedef union cvmx_l2c_cbcx_bist_status cvmx_l2c_cbcx_bist_status_t;
 
@@ -2321,6 +2369,41 @@ union cvmx_l2c_cbcx_dll {
 typedef union cvmx_l2c_cbcx_dll cvmx_l2c_cbcx_dll_t;
 
 /**
+ * cvmx_l2c_cbc#_holeerr
+ *
+ * This register records error information for HOLE* interrupts. The first HOLEWR error locks the
+ * register until the logged error type is cleared; HOLERD never locks the register.
+ */
+union cvmx_l2c_cbcx_holeerr {
+	uint64_t u64;
+	struct cvmx_l2c_cbcx_holeerr_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t holerd                       : 1;  /**< Logged information is for a HOLERD error. */
+	uint64_t holewr                       : 1;  /**< Logged information is for a HOLEWR error. */
+	uint64_t reserved_59_61               : 3;
+	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. */
+	uint64_t source                       : 7;  /**< XMC 'source' of request causing error. If SOURCE<6>==0, then SOURCE<5:0> is PPID, else
+                                                         SOURCE<3:0> is BUSID of the IOB which made the request. */
+	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error.
+                                                         For HOLE* errors, is the NODE the request is directed to. */
+	uint64_t addr                         : 40; /**< XMC address causing the error. This field is the physical address after hole removal and
+                                                         index aliasing (if enabled). (The hole is between DR0 and DR1. Remove the hole by
+                                                         subtracting 256MB from all L2/DRAM physical addresses >= 512 MB.) */
+#else
+	uint64_t addr                         : 40;
+	uint64_t node                         : 4;
+	uint64_t source                       : 7;
+	uint64_t cmd                          : 8;
+	uint64_t reserved_59_61               : 3;
+	uint64_t holewr                       : 1;
+	uint64_t holerd                       : 1;
+#endif
+	} s;
+	struct cvmx_l2c_cbcx_holeerr_s        cn78xx;
+};
+typedef union cvmx_l2c_cbcx_holeerr cvmx_l2c_cbcx_holeerr_t;
+
+/**
  * cvmx_l2c_cbc#_int
  *
  * This register is for CBC-based interrupts.
@@ -2330,7 +2413,15 @@ union cvmx_l2c_cbcx_int {
 	uint64_t u64;
 	struct cvmx_l2c_cbcx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_6_63                : 58;
+	uint64_t reserved_10_63               : 54;
+	uint64_t holerd                       : 1;  /**< Read reference to 256MB hole occurred. */
+	uint64_t holewr                       : 1;  /**< Write reference to 256MB hole occurred. */
+	uint64_t iowrdisoci                   : 1;  /**< Illegal I/O write operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. See
+                                                         L2C_CBC(0..3)_IODISOCIERR for logged information. This interrupt applies to IOBST8,
+                                                         IOBST16, IOBST32, IOBST64, IOBADDR, LMTST, and LMTDMA XMC commands. */
+	uint64_t iorddisoci                   : 1;  /**< Illegal I/O read operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. See
+                                                         L2C_CBC(0..3)_IODISOCIERR for logged information. This interrupt applies to IOBLD8,
+                                                         IOBLD16, IOBLD32, IOBLD64, IOBDMA, and LMTDMA XMC commands. */
 	uint64_t mibdbe                       : 1;  /**< MIB double-bit error occurred. See L2C_CBC(2..3)_MIBERR for logged information. */
 	uint64_t mibsbe                       : 1;  /**< MIB double-bit error occurred. See L2C_CBC(2..3)_MIBERR for logged information. */
 	uint64_t ioccmddbe                    : 1;  /**< IOCCMD double-bit error occurred. See L2C_CBC(0..3)_IOCERR for logged information. */
@@ -2344,7 +2435,11 @@ union cvmx_l2c_cbcx_int {
 	uint64_t ioccmddbe                    : 1;
 	uint64_t mibsbe                       : 1;
 	uint64_t mibdbe                       : 1;
-	uint64_t reserved_6_63                : 58;
+	uint64_t iorddisoci                   : 1;
+	uint64_t iowrdisoci                   : 1;
+	uint64_t holewr                       : 1;
+	uint64_t holerd                       : 1;
+	uint64_t reserved_10_63               : 54;
 #endif
 	} s;
 	struct cvmx_l2c_cbcx_int_cn70xx {
@@ -2362,19 +2457,43 @@ union cvmx_l2c_cbcx_int {
 	uint64_t reserved_4_63                : 60;
 #endif
 	} cn70xx;
-	struct cvmx_l2c_cbcx_int_s            cn78xx;
+	struct cvmx_l2c_cbcx_int_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_10_63               : 54;
+	uint64_t holerd                       : 1;  /**< Read reference to 256MB hole occurred. */
+	uint64_t holewr                       : 1;  /**< Write reference to 256MB hole occurred. */
+	uint64_t iowrdisoci                   : 1;  /**< Illegal I/O write operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. See
+                                                         L2C_CBC(0..3)_IODISOCIERR for logged information. This interrupt applies to IOBST8,
+                                                         IOBST16, IOBST32, IOBST64, IOBADDR, LMTST, and LMTDMA XMC commands. */
+	uint64_t iorddisoci                   : 1;  /**< Illegal I/O read operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. See
+                                                         L2C_CBC(0..3)_IODISOCIERR for logged information. This interrupt applies to IOBLD8,
+                                                         IOBLD16, IOBLD32, IOBLD64, IOBDMA, and LMTDMA XMC commands. */
+	uint64_t mibdbe                       : 1;  /**< MIB double-bit error occurred. See L2C_CBC(2..3)_MIBERR for logged information. */
+	uint64_t mibsbe                       : 1;  /**< MIB double-bit error occurred. See L2C_CBC(2..3)_MIBERR for logged information. */
+	uint64_t reserved_2_3                 : 2;
+	uint64_t rsddbe                       : 1;  /**< RSD double-bit error occurred. See L2C_CBC(0..3)_RSDERR for logged information. */
+	uint64_t rsdsbe                       : 1;  /**< RSD single-bit error occurred. See L2C_CBC(0..3)_RSDERR for logged information. */
+#else
+	uint64_t rsdsbe                       : 1;
+	uint64_t rsddbe                       : 1;
+	uint64_t reserved_2_3                 : 2;
+	uint64_t mibsbe                       : 1;
+	uint64_t mibdbe                       : 1;
+	uint64_t iorddisoci                   : 1;
+	uint64_t iowrdisoci                   : 1;
+	uint64_t holewr                       : 1;
+	uint64_t holerd                       : 1;
+	uint64_t reserved_10_63               : 54;
+#endif
+	} cn78xx;
 };
 typedef union cvmx_l2c_cbcx_int cvmx_l2c_cbcx_int_t;
 
 /**
  * cvmx_l2c_cbc#_iocerr
  *
- * This register records error information for all CBC IOC errors.
- * An error locks the INDEX, and SYN fields and set the bit corresponding to the error received.
- * CMDDBE errors take priority and overwrite an earlier logged CMDSBE error. Only one of
- * CMDSBE/CMDDBE is set at any given time and serves to document which error the INDEX/SYN is
- * associated with.
- * The syndrome is recorded for DBE errors, though the utility of the value is not clear.
+ * Reserved.
+ *
  */
 union cvmx_l2c_cbcx_iocerr {
 	uint64_t u64;
@@ -2396,19 +2515,56 @@ union cvmx_l2c_cbcx_iocerr {
 #endif
 	} s;
 	struct cvmx_l2c_cbcx_iocerr_s         cn70xx;
-	struct cvmx_l2c_cbcx_iocerr_s         cn78xx;
+	struct cvmx_l2c_cbcx_iocerr_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_0_63                : 64;
+#else
+	uint64_t reserved_0_63                : 64;
+#endif
+	} cn78xx;
 };
 typedef union cvmx_l2c_cbcx_iocerr cvmx_l2c_cbcx_iocerr_t;
 
 /**
+ * cvmx_l2c_cbc#_iodisocierr
+ *
+ * This register records error information associated with IORDDISOCI/IOWRDISOCI interrupts.
+ * IOWRDISOCI events take priority over previously captured IORDDISOCI events. Of the available
+ * I/O transactions, some commands will either set IORDDISOCI, set IOWRDISOCI, or set both
+ * IORDDISOCI and IOWRDISOCI. See L2C_CBC(0..3)_INT for information about which I/O transactions
+ * may result in IORDDISOCI/IOWRDISOCI interrupts.
+ */
+union cvmx_l2c_cbcx_iodisocierr {
+	uint64_t u64;
+	struct cvmx_l2c_cbcx_iodisocierr_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_59_63               : 5;
+	uint64_t cmd                          : 7;  /**< Encoding of XMC command. */
+	uint64_t ppvid                        : 6;  /**< CMB source PPVID. */
+	uint64_t node                         : 2;  /**< Destination node ID. */
+	uint64_t did                          : 8;  /**< Destination device ID. */
+	uint64_t addr                         : 36; /**< I/O address. */
+#else
+	uint64_t addr                         : 36;
+	uint64_t did                          : 8;
+	uint64_t node                         : 2;
+	uint64_t ppvid                        : 6;
+	uint64_t cmd                          : 7;
+	uint64_t reserved_59_63               : 5;
+#endif
+	} s;
+	struct cvmx_l2c_cbcx_iodisocierr_s    cn78xx;
+};
+typedef union cvmx_l2c_cbcx_iodisocierr cvmx_l2c_cbcx_iodisocierr_t;
+
+/**
  * cvmx_l2c_cbc#_miberr
  *
- * This register records error information for all CBC MIB errors.
- * An error locks the INDEX, and SYN fields and set the bit corresponding to the error received.
- * MIBDBE errors take priority and overwrite an earlier logged MIBSBE error. Only one of
- * MIBSBE/MIBDBE is set at any given time and serves to document which error the INDEX/SYN is
- * associated with.
- * The syndrome is recorded for DBE errors, though the utility of the value is not clear.
+ * This register records error information for all CBC MIB errors. An error locks the INDEX, and
+ * SYN fields and set the bit corresponding to the error received. MIBDBE errors take priority
+ * and overwrite an earlier logged MIBSBE error. Only one of MIBSBE/MIBDBE is set at any given
+ * time and serves to document which error the INDEX/SYN is associated with. The syndrome is
+ * recorded for DBE errors, though the utility of the value is not clear.
  */
 union cvmx_l2c_cbcx_miberr {
 	uint64_t u64;
@@ -3719,8 +3875,8 @@ union cvmx_l2c_ctl {
 	uint64_t reserved_4_5                 : 2;
 	uint64_t disldwb                      : 1;  /**< Suppresses the DWB functionality of any received LDWB, effectively turning them into LDTs. */
 	uint64_t dissblkdty                   : 1;  /**< Disable bandwidth optimization between L2 and LMC and MOB which only transfers modified
-                                                         sub-blocks when possible. NOTE: in an OCI system all nodes must use the same setting of
-                                                         DISSBLKDTY or operation is undefined. FIXME: should reset to 0, once verif supports it. */
+                                                         sub-blocks when possible. In an OCI system all nodes must use the same setting of
+                                                         DISSBLKDTY or operation is undefined. */
 	uint64_t disecc                       : 1;  /**< Tag and data ECC disable. */
 	uint64_t disidxalias                  : 1;  /**< Index alias disable. */
 #else
@@ -4377,9 +4533,9 @@ typedef union cvmx_l2c_dut_mapx cvmx_l2c_dut_mapx_t;
  * Flip ECC bits to generate single-bit or double-bit ECC errors in all instances of a given
  * memory type. Encodings are as follows.
  * 0x0 = No error.
- * 0x1 = Single-bit error on ecc[0].
- * 0x2 = Single-bit error on ecc[1].
- * 0x3 = Double-bit error on ecc[1:0].
+ * 0x1 = Single-bit error on ECC[0].
+ * 0x2 = Single-bit error on ECC[1].
+ * 0x3 = Double-bit error on ECC[1:0].
  * L2DFLIP allows software to generate L2DSBE, L2DDBE, VBFSBE, and VBFDBE errors for the purposes
  * of testing error handling code. When one (or both) of these bits are set, a PL2 that misses in
  * the L2 will fill with the appropriate error in the first two OWs of the fill. Software can
@@ -4430,7 +4586,25 @@ union cvmx_l2c_ecc_ctl {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} cn70xx;
-	struct cvmx_l2c_ecc_ctl_s             cn78xx;
+	struct cvmx_l2c_ecc_ctl_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_12_63               : 52;
+	uint64_t mibflip                      : 2;  /**< Generate an ECC error in the MIB. See note above. */
+	uint64_t l2dflip                      : 2;  /**< Generate an ECC error in the L2D. See note above. */
+	uint64_t l2tflip                      : 2;  /**< Generate an ECC error in the L2T. */
+	uint64_t rdfflip                      : 2;  /**< Generate an ECC error in RDF memory. */
+	uint64_t xmdflip                      : 2;  /**< Generate an ECC error in all corresponding CBC XMD memories. */
+	uint64_t reserved_0_1                 : 2;
+#else
+	uint64_t reserved_0_1                 : 2;
+	uint64_t xmdflip                      : 2;
+	uint64_t rdfflip                      : 2;
+	uint64_t l2tflip                      : 2;
+	uint64_t l2dflip                      : 2;
+	uint64_t mibflip                      : 2;
+	uint64_t reserved_12_63               : 52;
+#endif
+	} cn78xx;
 };
 typedef union cvmx_l2c_ecc_ctl cvmx_l2c_ecc_ctl_t;
 
@@ -5960,52 +6134,90 @@ union cvmx_l2c_oci_ctl {
 	uint64_t u64;
 	struct cvmx_l2c_oci_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_17_63               : 47;
+	uint64_t reserved_30_63               : 34;
+	uint64_t lock_local_cas               : 1;  /**< When set, L2 CAS operations to remote addresses which miss at the requester will be
+                                                         performed
+                                                         locally (if possible) on the requesting node. Default operation will instead send the CAS
+                                                         request
+                                                         to be performed on the home node. For STC ops LOCK_LOCAL_STC. */
+	uint64_t lock_local_stc               : 1;  /**< When set, L2 STC operations to remote addresses which miss at the requester will be
+                                                         performed
+                                                         locally (if possible) on the requesting node. Default operation will instead send the STC
+                                                         request
+                                                         to be performed on the home node. For CAS ops LOCK_LOCAL_CAS. */
+	uint64_t lock_local_pp                : 1;  /**< When clear, L2 atomic operations (excluding CAS/STC) pp initiated requests to remote
+                                                         addresses
+                                                         which miss at the requester will send the atomic request to be performed on the home node.
+                                                         Default operation will instead  be performed locally on the requesting node.
+                                                         For request initiated by IOB & for STC & CAS ops, see
+                                                         LOCK_LOCAL_IOB/LOCK_LOCAL_STC/LOCK_LOCAL_CAS. */
+	uint64_t lngtolen                     : 5;  /**< Selects the bit in the counter for the long timeout value (timeout used when SHTO bit is
+                                                         clear). Values supported are between 11 and 29 (for a timeout values between 2^11 and
+                                                         2^29). Actual timeout is between 1x and 2x this interval. For example if LNGTOLEN = 28
+                                                         (the reset value), the timeout is between 256M and 512M core clocks. Note: a value of 0
+                                                         disables this timer. */
+	uint64_t shtolen                      : 5;  /**< Selects the bit in the counter for the short timeout value (timeout used when SHTO bit is
+                                                         set). Values supported are between 9 and 29 (for a timeout values between 2^9 and 2^29).
+                                                         Actual timeout is between 1x and 2x this interval. For example if SHTOLEN = 14 (the reset
+                                                         value), the timeout is between 16K and 32K core clocks. Note: a value of 0 disables this
+                                                         timer. */
 	uint64_t shtoioen                     : 1;  /**< When set, any PP issues any of an IO load, acking store, IOBDMA, LMTDMA, acking IOBADDR,
-                                                         or acking LMTST to a node that doesn't exist (existence defined by the ENAOCI bits),
-                                                         then the hardware sets the SHTO CSR field. */
+                                                         or acking LMTST to a node that doesn't exist (existence defined by the ENAOCI bits), then
+                                                         the hardware sets the SHTO CSR field. */
 	uint64_t shtoen                       : 3;  /**< When set, if the corresponding OCI link is down, the hardware sets the SHTO CSR field. */
-	uint64_t shto                         : 1;  /**< Use short timeout intervals. When set, PP will use SDIDTTO for both DID and commit counter
+	uint64_t shto                         : 1;  /**< Use short timeout intervals. When set, core uses SDIDTTO for both DID and commit counter
                                                          timeouts, rather than DIDTTO/DIDTTO2. Similarly, L2C will use short instead of long
-                                                         timeout (FIXME -  more info needed) */
+                                                         timeout. */
 	uint64_t inv_mode                     : 2;  /**< Describes how aggressive to be when waiting for local invalidates before sending OCI
-                                                         responses which act like commits at the remote. 0 - conservative mode, waits until all
-                                                         local invalidates have been sent by their respective CBCs to the PPs. 1 - moderate mode,
-                                                         waits until all local invalidates have been sent to their respective CBCs, but not
-                                                         necessarily actually sent to the PPs themselves. 2 - aggressive mode, does not wait for
-                                                         local invalidates to begin their processing. */
+                                                         responses which act like commits at the remote.
+                                                         0x0 = Conservative mode, waits until all local invalidates have been sent by their
+                                                         respective CBCs to the cores.
+                                                         0x1 = Moderate mode, waits until all local invalidates have been sent to their respective
+                                                         CBCs, but not necessarily actually sent to the cores themselves.
+                                                         0x2 = Aggressive mode, does not wait for local invalidates to begin their processing. */
 	uint64_t cas_fdx                      : 1;  /**< When set, L2 STC/CAS operations performed at the home will immediately bring the block
                                                          exclusive into the home. Default operation is to first request the block shared and only
                                                          invalidate the remote if the compare succeeds. */
-	uint64_t rldd_psha                    : 1;  /**< When set, RLDD will be assumed to return a shared response (PSHA). Default operation will
-                                                         assume an exclusive response (PEMD). Note that an incorrect assumption only causes an
-                                                         extra tag write to be done upon receiving the response. */
-	uint64_t lock_local                   : 1;  /**< When set, L2 atomic operations (excluding CAS/STC) to remote addresses which miss at the
-                                                         requester will be performed locally on the requesting node. Default operation will instead
-                                                         send the atomic request to be performed on the home node. Note that CAS/STC operations
-                                                         which miss at the requester will always be performed at the home node regardless of this
-                                                         setting. */
+	uint64_t rldd_psha                    : 1;  /**< When set, RLDD is assumed to return a shared response (PSHA). Default operation assumes an
+                                                         exclusive response (PEMD). Note that an incorrect assumption only causes an extra tag
+                                                         write to be done upon receiving the response. */
+	uint64_t lock_local_iob               : 1;  /**< When set, L2 atomic operations (excluding CAS/STC) initiated by IOB to remote addresses
+                                                         which miss at the requester will be performed locally on the requesting node. When clear
+                                                         the
+                                                         operation will instead send the atomic request to be performed on the home node.
+                                                         For request initiated by PP & for STC & CAS ops see
+                                                         LOCK_LOCAL_PP/LOCK_LOCAL_STC/LOCK_LOCAL_CAS.
+                                                         Default is set to 1 (local locks). */
 	uint64_t iofrcl                       : 1;  /**< When set, L2C services all I/O read and write operations on the local node, regardless of
                                                          the value of the node ID bits in the physical address. During normal operation this bit is
-                                                         expected to be 0. */
+                                                         expected to be 0. Will only transition from 1 to 0, never from 0 to 1. */
 	uint64_t gksegnode                    : 2;  /**< Initialized to the OCX_COM_NODE[ID] value on reset, which will equal the OCI_NODE_ID pins
                                                          on a cold reset, but could be something else on a chip warm or soft reset; writable by
                                                          software. */
-	uint64_t enaoci                       : 4;  /**< Enable OCI processing (one per node_id). When set, perform OCI processing. When clear, OCI
-                                                         references cause
-                                                         RDDISOCI/WRDISOCI interrupts (NYI). */
+	uint64_t enaoci                       : 4;  /**< Enable OCI processing (one bit per node_id). When set, perform OCI processing. When clear,
+                                                         OCI memory writes are blocked and OCI memory reads return unpredictable data. When clear,
+                                                         OCI I/O requests and MOC references are processed and sent to OCX where they are
+                                                         ultimately discarded. RDDISOCI/WRDISOCI/IORDDISOCI/IOWRDISOCI interrupts occur if and only
+                                                         if the corresponding ENAOCI[node] bit is clear. References to the local node (configured
+                                                         via OCX_COM_NODE[ID]) ignore the value of ENAOCI[node] because no OCI processing is
+                                                         required. */
 #else
 	uint64_t enaoci                       : 4;
 	uint64_t gksegnode                    : 2;
 	uint64_t iofrcl                       : 1;
-	uint64_t lock_local                   : 1;
+	uint64_t lock_local_iob               : 1;
 	uint64_t rldd_psha                    : 1;
 	uint64_t cas_fdx                      : 1;
 	uint64_t inv_mode                     : 2;
 	uint64_t shto                         : 1;
 	uint64_t shtoen                       : 3;
 	uint64_t shtoioen                     : 1;
-	uint64_t reserved_17_63               : 47;
+	uint64_t shtolen                      : 5;
+	uint64_t lngtolen                     : 5;
+	uint64_t lock_local_pp                : 1;
+	uint64_t lock_local_stc               : 1;
+	uint64_t lock_local_cas               : 1;
+	uint64_t reserved_30_63               : 34;
 #endif
 	} s;
 	struct cvmx_l2c_oci_ctl_s             cn78xx;
@@ -6906,7 +7118,7 @@ typedef union cvmx_l2c_spar4 cvmx_l2c_spar4_t;
 /**
  * cvmx_l2c_tad#_dll
  *
- * Register for DLL observability
+ * This register provides the parameters for DLL observability.
  *
  */
 union cvmx_l2c_tadx_dll {
@@ -6921,7 +7133,7 @@ union cvmx_l2c_tadx_dll {
 	uint64_t dly_elem_enable              : 16; /**< Delay element enable. */
 	uint64_t dll_setting                  : 12; /**< DLL setting. */
 	uint64_t dll_state                    : 3;  /**< DLL state. */
-	uint64_t dll_lock                     : 1;  /**< DLL locked. */
+	uint64_t dll_lock                     : 1;  /**< DLL lock: 1 = locked, 0 = unlocked. */
 #else
 	uint64_t dll_lock                     : 1;
 	uint64_t dll_state                    : 3;
@@ -6939,7 +7151,7 @@ union cvmx_l2c_tadx_dll {
 	uint64_t reserved_16_63               : 48;
 	uint64_t dll_setting                  : 12; /**< DLL setting. */
 	uint64_t dll_state                    : 3;  /**< DLL state. */
-	uint64_t dll_lock                     : 1;  /**< DLL locked. */
+	uint64_t dll_lock                     : 1;  /**< DLL lock: 1 = locked, 0 = unlocked. */
 #else
 	uint64_t dll_lock                     : 1;
 	uint64_t dll_state                    : 3;
@@ -7034,9 +7246,11 @@ typedef union cvmx_l2c_tadx_ecc1 cvmx_l2c_tadx_ecc1_t;
 /**
  * cvmx_l2c_tad#_err
  *
- * This register records error information for HOLE* and BIG* interrupts. The first non-BIGRD
- * error will lock the register until the logged error type is cleared; BIGRD never locks the
- * register.
+ * This register records error information for *DISOCI and BIG* interrupts. The BIG logic only
+ * applies to local addresses. A command for a remote address does not cause a BIGRD/BIGWR on the
+ * requesting node. Similary RDDISOCI/WRDISOCI is always for a remote address. The first
+ * WRDISOCI/BIGWR error will lock the register until the logged error type is cleared;
+ * RDDISOCI/BIGRD never locks the register.
  */
 union cvmx_l2c_tadx_err {
 	uint64_t u64;
@@ -7044,15 +7258,15 @@ union cvmx_l2c_tadx_err {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bigrd                        : 1;  /**< Logged information is for a BIGRD error. */
 	uint64_t bigwr                        : 1;  /**< Logged information is for a BIGWR error. */
-	uint64_t holerd                       : 1;  /**< Logged information is for a HOLERD error. */
-	uint64_t holewr                       : 1;  /**< Logged information is for a HOLEWR error. */
-	uint64_t reserved_59_59               : 1;
-	uint64_t cmd                          : 8;  /**< XMC command of request causing error. FIXME, needs better description for OCI */
-	uint64_t source                       : 7;  /**< XMC 'source' of request causing error. If SOURCE<6>==0, SOURCE<5:0> = PPID else
-                                                         SOURCE<3:0> is BUSID of IOB which made the request. */
-	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error. For BIG* errors NODE will always be the node
-                                                         logging the error (BIG* errors are logged at the home node). For HOLE* errors, NODE could
-                                                         be any OCI node in the system (HOLE* errors are logged at the requester node). */
+	uint64_t reserved_59_61               : 3;
+	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. */
+	uint64_t source                       : 7;  /**< XMC source of request causing error. If SOURCE<6>==0, then SOURCE<5:0> is PPID, else
+                                                         SOURCE<3:0> is BUSID of the IOB which made the request. If CMD[7]==0, this field is
+                                                         unpredictable. */
+	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error. For BIG* errors NODE is always the node that
+                                                         generated request causing the error (BIG* errors are logged at the home node). For *DISOCI
+                                                         errors, is the NODE the request is directed to (DISOCI request is always the current
+                                                         Node). */
 	uint64_t addr                         : 40; /**< XMC address causing the error. This field is the physical address after hole removal and
                                                          index aliasing (if enabled). (The hole is between DR0 and DR1. Remove the hole by
                                                          subtracting 256MB from all L2/DRAM physical addresses >= 512 MB.) */
@@ -7061,9 +7275,7 @@ union cvmx_l2c_tadx_err {
 	uint64_t node                         : 4;
 	uint64_t source                       : 7;
 	uint64_t cmd                          : 8;
-	uint64_t reserved_59_59               : 1;
-	uint64_t holewr                       : 1;
-	uint64_t holerd                       : 1;
+	uint64_t reserved_59_61               : 3;
 	uint64_t bigwr                        : 1;
 	uint64_t bigrd                        : 1;
 #endif
@@ -7078,9 +7290,7 @@ union cvmx_l2c_tadx_err {
 	uint64_t cmd                          : 7;  /**< XMC command of request causing error. */
 	uint64_t source                       : 7;  /**< XMC 'source' of request causing error. If SOURCE<6>==0, SOURCE<5:0> = PPID else
                                                          SOURCE<3:0> is BUSID of IOB which made the request. */
-	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error. For BIG* errors NODE will always be the node
-                                                         logging the error (BIG* errors are logged at the home node). For HOLE* errors, NODE could
-                                                         be any OCI node in the system (HOLE* errors are logged at the requester node). */
+	uint64_t node                         : 4;  /**< Always zero. */
 	uint64_t addr                         : 40; /**< XMC address causing the error. This field is the physical address after hole removal and
                                                          index aliasing (if enabled). (The hole is between DR0 and DR1. Remove the hole by
                                                          subtracting 256MB from all L2/DRAM physical addresses >= 512 MB.) */
@@ -7096,7 +7306,36 @@ union cvmx_l2c_tadx_err {
 	uint64_t bigrd                        : 1;
 #endif
 	} cn70xx;
-	struct cvmx_l2c_tadx_err_s            cn78xx;
+	struct cvmx_l2c_tadx_err_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t bigrd                        : 1;  /**< Logged information is for a BIGRD error. */
+	uint64_t bigwr                        : 1;  /**< Logged information is for a BIGWR error. */
+	uint64_t rddisoci                     : 1;  /**< Logged information is for a RDDISOCI error. */
+	uint64_t wrdisoci                     : 1;  /**< Logged information is for a WRDISOCI error. */
+	uint64_t reserved_59_59               : 1;
+	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. */
+	uint64_t source                       : 7;  /**< XMC source of request causing error. If SOURCE<6>==0, then SOURCE<5:0> is PPID, else
+                                                         SOURCE<3:0> is BUSID of the IOB which made the request. If CMD[7]==0, this field is
+                                                         unpredictable. */
+	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error. For BIG* errors NODE is always the node that
+                                                         generated request causing the error (BIG* errors are logged at the home node). For *DISOCI
+                                                         errors, is the NODE the request is directed to (DISOCI request is always the current
+                                                         Node). */
+	uint64_t addr                         : 40; /**< XMC address causing the error. This field is the physical address after hole removal and
+                                                         index aliasing (if enabled). (The hole is between DR0 and DR1. Remove the hole by
+                                                         subtracting 256MB from all L2/DRAM physical addresses >= 512 MB.) */
+#else
+	uint64_t addr                         : 40;
+	uint64_t node                         : 4;
+	uint64_t source                       : 7;
+	uint64_t cmd                          : 8;
+	uint64_t reserved_59_59               : 1;
+	uint64_t wrdisoci                     : 1;
+	uint64_t rddisoci                     : 1;
+	uint64_t bigwr                        : 1;
+	uint64_t bigrd                        : 1;
+#endif
+	} cn78xx;
 };
 typedef union cvmx_l2c_tadx_err cvmx_l2c_tadx_err_t;
 
@@ -7206,13 +7445,26 @@ union cvmx_l2c_tadx_int {
 	struct cvmx_l2c_tadx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t wrdisoci                     : 1;  /**< (NYI) Illegal write operation to a remote node with L2C_TAD_CTL[ENAOCI] clear. */
-	uint64_t rddisoci                     : 1;  /**< (NYI) Illegal read operation to a remote node with L2C_TAD_CTL[ENAOCI] clear. */
-	uint64_t rtgdbe                       : 1;  /**< RTG double-bit error */
-	uint64_t rtgsbe                       : 1;  /**< RTG single-bit error */
-	uint64_t reserved_15_31               : 17;
-	uint64_t bigrd                        : 1;  /**< Read reference past L2C_BIG_CTL[MAXDRAM] occurred. */
-	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. */
+	uint64_t wrdisoci                     : 1;  /**< Illegal write operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. See
+                                                         L2C_TAD(0..7)_ERR for for logged information. */
+	uint64_t rddisoci                     : 1;  /**< Illegal read operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. Note
+                                                         RDDISOCI interrupts can occur during normal operation as the cores are allowed to prefetch
+                                                         to nonexistent memory locations. Therefore, RDDISOCI is for informational purposes
+                                                         only. See L2C_TAD(0..7)_ERR for for logged information. */
+	uint64_t rtgdbe                       : 1;  /**< RTG double-bit error. */
+	uint64_t rtgsbe                       : 1;  /**< RTG single-bit error. */
+	uint64_t reserved_18_31               : 14;
+	uint64_t lfbto                        : 1;  /**< An LFB entry (or more) has encountered a timeout condition When LFBTO timeout condition
+                                                         occurs L2C_TAD(0..7)_TIMEOUT is loaded. L2C_TAD(0..7)_TIMEOUT is loaded with info from the
+                                                         first LFB that timed out. if multiple LFB timed out simultaneously, then the it will
+                                                         capture info from the lowest LFB number that timed out. */
+	uint64_t reserved_15_16               : 2;
+	uint64_t bigrd                        : 1;  /**< Read reference past L2C_BIG_CTL[MAXDRAM] occurred. BIGRD interrupts can occur during
+                                                         normal operation as the cores are allowed to prefetch to nonexistent memory
+                                                         locations. Therefore, BIGRD is for informational purposes only. See L2C_TAD(0..7)_ERR for
+                                                         logged information. */
+	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. See L2C_TAD(0..7)_ERR for for logged
+                                                         information. */
 	uint64_t holerd                       : 1;  /**< Read reference to 256MB hole occurred. */
 	uint64_t holewr                       : 1;  /**< Write reference to 256MB hole occurred. */
 	uint64_t reserved_2_10                : 9;
@@ -7230,7 +7482,9 @@ union cvmx_l2c_tadx_int {
 	uint64_t holerd                       : 1;
 	uint64_t bigwr                        : 1;
 	uint64_t bigrd                        : 1;
-	uint64_t reserved_15_31               : 17;
+	uint64_t reserved_15_16               : 2;
+	uint64_t lfbto                        : 1;
+	uint64_t reserved_18_31               : 14;
 	uint64_t rtgsbe                       : 1;
 	uint64_t rtgdbe                       : 1;
 	uint64_t rddisoci                     : 1;
@@ -7338,17 +7592,28 @@ union cvmx_l2c_tadx_int {
 	struct cvmx_l2c_tadx_int_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t wrdisoci                     : 1;  /**< (NYI) Illegal write operation to a remote node with L2C_TAD_CTL[ENAOCI] clear. */
-	uint64_t rddisoci                     : 1;  /**< (NYI) Illegal read operation to a remote node with L2C_TAD_CTL[ENAOCI] clear. */
-	uint64_t rtgdbe                       : 1;  /**< RTG double-bit error */
-	uint64_t rtgsbe                       : 1;  /**< RTG single-bit error */
-	uint64_t reserved_17_31               : 15;
-	uint64_t wrdislmc                     : 1;  /**< Illegal write to disabled LMC error. A DRAM write arrived before the LMC(s) were enabled. */
-	uint64_t rddislmc                     : 1;  /**< Illegal read to disabled LMC error. A DRAM read arrived before the LMC(s) were enabled. */
-	uint64_t bigrd                        : 1;  /**< Read reference past L2C_BIG_CTL[MAXDRAM] occurred. */
-	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. */
-	uint64_t holerd                       : 1;  /**< Read reference to 256MB hole occurred. */
-	uint64_t holewr                       : 1;  /**< Write reference to 256MB hole occurred. */
+	uint64_t wrdisoci                     : 1;  /**< Illegal write operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. See
+                                                         L2C_TAD(0..7)_ERR for for logged information. */
+	uint64_t rddisoci                     : 1;  /**< Illegal read operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. Note
+                                                         RDDISOCI interrupts can occur during normal operation as the cores are allowed to prefetch
+                                                         to nonexistent memory locations. Therefore, RDDISOCI is for informational purposes
+                                                         only. See L2C_TAD(0..7)_ERR for for logged information. */
+	uint64_t rtgdbe                       : 1;  /**< RTG double-bit error. */
+	uint64_t rtgsbe                       : 1;  /**< RTG single-bit error. */
+	uint64_t reserved_18_31               : 14;
+	uint64_t lfbto                        : 1;  /**< An LFB entry (or more) has encountered a timeout condition When LFBTO timeout condition
+                                                         occurs L2C_TAD(0..7)_TIMEOUT is loaded. L2C_TAD(0..7)_TIMEOUT is loaded with info from the
+                                                         first LFB that timed out. if multiple LFB timed out simultaneously, then the it will
+                                                         capture info from the lowest LFB number that timed out. */
+	uint64_t wrdislmc                     : 1;  /**< Illegal write to disabled LMC error. A DRAM write arrived before the LMC was enabled. */
+	uint64_t rddislmc                     : 1;  /**< Illegal read to disabled LMC error. A DRAM read arrived before the LMC was enabled. */
+	uint64_t bigrd                        : 1;  /**< Read reference past L2C_BIG_CTL[MAXDRAM] occurred. BIGRD interrupts can occur during
+                                                         normal operation as the cores are allowed to prefetch to nonexistent memory
+                                                         locations. Therefore, BIGRD is for informational purposes only. See L2C_TAD(0..7)_ERR for
+                                                         logged information. */
+	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. See L2C_TAD(0..7)_ERR for for logged
+                                                         information. */
+	uint64_t reserved_11_12               : 2;
 	uint64_t noway                        : 1;  /**< No way was available for allocation. L2C sets NOWAY during its processing of a transaction
                                                          whenever it needed/wanted to allocate a WAY in the L2 cache, but was unable to. When this
                                                          bit = 1, it is (generally) not an indication that L2C failed to complete transactions.
@@ -7377,13 +7642,13 @@ union cvmx_l2c_tadx_int {
 	uint64_t tagsbe                       : 1;
 	uint64_t tagdbe                       : 1;
 	uint64_t noway                        : 1;
-	uint64_t holewr                       : 1;
-	uint64_t holerd                       : 1;
+	uint64_t reserved_11_12               : 2;
 	uint64_t bigwr                        : 1;
 	uint64_t bigrd                        : 1;
 	uint64_t rddislmc                     : 1;
 	uint64_t wrdislmc                     : 1;
-	uint64_t reserved_17_31               : 15;
+	uint64_t lfbto                        : 1;
+	uint64_t reserved_18_31               : 14;
 	uint64_t rtgsbe                       : 1;
 	uint64_t rtgdbe                       : 1;
 	uint64_t rddisoci                     : 1;
@@ -7515,50 +7780,8 @@ typedef union cvmx_l2c_tadx_pfc3 cvmx_l2c_tadx_pfc3_t;
 /**
  * cvmx_l2c_tad#_prf
  *
- * "(1) All four counters are equivalent and can use any of the defined selects.
- * (2) the CNTnSEL legal values are:
- * 0x00 -Nothing (disabled)
- * 0x01 -L2 Tag Hit
- * 0x02 -L2 Tag Miss
- * 0x03 -L2 Tag NoAlloc (forced no-allocate)
- * 0x04 -L2 Victim
- * 0x05 -SC Fail
- * 0x06 -SC Pass
- * 0x07 -LFB Occupancy (each cycle adds \# of LFBs valid)
- * 0x08 -LFB Wait LFB (each cycle adds \# LFBs waiting for other LFBs)
- * 0x09 -LFB Wait VAB (each cycle adds \# LFBs waiting for VAB)
- * 0x80 -Quad 0 index bus inuse
- * 0x81 -Quad 0 read data bus inuse
- * 0x82 -Quad 0 \# banks inuse (0-4/cycle)
- * 0x83 -Quad 0 wdat flops inuse (0-4/cycle)
- * 0x90 -Quad 1 index bus inuse
- * 0x91 -Quad 1 read data bus inuse
- * 0x92 -Quad 1 \# banks inuse (0-4/cycle)
- * 0x93 -Quad 1 wdat flops inuse (0-4/cycle)
- * 0xA0 -Quad 2 index bus inuse
- * 0xA1 -Quad 2 read data bus inuse
- * 0xA2 -Quad 2 \# banks inuse (0-4/cycle)
- * 0xA3 -Quad 2 wdat flops inuse (0-4/cycle)
- * 0xB0 -Quad 3 index bus inuse
- * 0xB1 -Quad 3 read data bus inuse
- * 0xB2 -Quad 3 \# banks inuse (0-4/cycle)
- * 0xB3 -Quad 3 wdat flops inuse (0-4/cycle)
- * 0xC0 -Quad 4 index bus inuse
- * 0xC1 -Quad 4 read data bus inuse
- * 0xC2 -Quad 4 \# banks inuse (0-4/cycle)
- * 0xC3 -Quad 4 wdat flops inuse (0-4/cycle)
- * 0xD0 -Quad 5 index bus inuse
- * 0xD1 -Quad 5 read data bus inuse
- * 0xD2 -Quad 5 \# banks inuse (0-4/cycle)
- * 0xD3 -Quad 5 wdat flops inuse (0-4/cycle)
- * 0xE0 -Quad 6 index bus inuse
- * 0xE1 -Quad 6 read data bus inuse
- * 0xE2 -Quad 6 \# banks inuse (0-4/cycle)
- * 0xE3 -Quad 6 wdat flops inuse (0-4/cycle)
- * 0xF0 -Quad 7 index bus inuse
- * 0xF1 -Quad 7 read data bus inuse
- * 0xF2 -Quad 7 \# banks inuse (0-4/cycle)
- * 0xF3 -Quad 7 wdat flops inuse (0-4/cycle)"
+ * All four counters are equivalent and can use any of the defined selects.
+ *
  */
 union cvmx_l2c_tadx_prf {
 	uint64_t u64;
@@ -7599,12 +7822,17 @@ union cvmx_l2c_tadx_tag {
 	uint64_t u64;
 	struct cvmx_l2c_tadx_tag_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits.  Ignored/loaded with 0 for RTG accesses. */
-	uint64_t reserved_1_59                : 59;
+	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits. Ignored/loaded with 0 for RTG accesses. If TS is Invalid (0) SBLKDTY
+                                                         must be 0 or operation is undefined. */
+	uint64_t reserved_6_59                : 54;
+	uint64_t node                         : 2;  /**< The node ID for the remote node which holds this block. Ignored/loaded with 0 for TAG accesses. */
+	uint64_t reserved_1_3                 : 3;
 	uint64_t lock                         : 1;  /**< The lock bit */
 #else
 	uint64_t lock                         : 1;
-	uint64_t reserved_1_59                : 59;
+	uint64_t reserved_1_3                 : 3;
+	uint64_t node                         : 2;
+	uint64_t reserved_6_59                : 54;
 	uint64_t sblkdty                      : 4;
 #endif
 	} s;
@@ -7673,28 +7901,33 @@ union cvmx_l2c_tadx_tag {
 	} cn70xx;
 	struct cvmx_l2c_tadx_tag_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits.  Ignored/loaded with 0 for RTG accesses. */
+	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits. Ignored/loaded with 0 for RTG accesses. If TS is Invalid (0) SBLKDTY
+                                                         must be 0 or operation is undefined. */
 	uint64_t reserved_58_59               : 2;
 	uint64_t businfo                      : 9;  /**< The bus information bits.  Ignored/loaded with 0 for RTG accesses. */
 	uint64_t ecc                          : 7;  /**< The tag ECC. This field is undefined if L2C_CTL[DISECC] is not 1 when the LTGL2I reads the
                                                          tags. */
 	uint64_t tag                          : 22; /**< The tag. TAG[39:20] is the corresponding bits from the L2C+LMC internal L2/DRAM byte
                                                          address. TAG[41:40] is the OCI node of the address. The RTG must always have the
-                                                         TAG[41:40] == to
-                                                         the current node or operation is undefined. */
-	uint64_t reserved_4_19                : 16;
+                                                         TAG[41:40] == to the current node or operation is undefined. */
+	uint64_t reserved_6_19                : 14;
+	uint64_t node                         : 2;  /**< The node ID for the remote node which holds this block. Ignored/loaded with 0 for TAG accesses. */
+	uint64_t ts                           : 2;  /**< The tag state.
+                                                         0x0 = Invalid.
+                                                         0x1 = Shared.
+                                                         0x2 = Exclusive.
+                                                         Note that a local address will never have the value of exclusive as that state is incloded
+                                                         as shared in the TAG and invalid in the RTG. */
 	uint64_t used                         : 1;  /**< The LRU use bit. If setting the LOCK bit, the USE bit should also be set or the operation
                                                          is undefined.  Ignored/loaded with 0 for RTG accesses. */
-	uint64_t ts                           : 2;  /**< The TAG state. 0 - Invalid; 1 - Shared; 2 - Exclusive. Note that a local address will
-                                                         never have the value of 2 (Exclusive) as that state is encoded as Shared in the TAG and
-                                                         Invalid in the RTG. */
 	uint64_t lock                         : 1;  /**< The lock bit. If setting the LOCK bit, the USE bit should also be set or the operation is
                                                          undefined.  Ignored/loaded with 0 for RTG accesses. */
 #else
 	uint64_t lock                         : 1;
-	uint64_t ts                           : 2;
 	uint64_t used                         : 1;
-	uint64_t reserved_4_19                : 16;
+	uint64_t ts                           : 2;
+	uint64_t node                         : 2;
+	uint64_t reserved_6_19                : 14;
 	uint64_t tag                          : 22;
 	uint64_t ecc                          : 7;
 	uint64_t businfo                      : 9;
@@ -7707,20 +7940,107 @@ union cvmx_l2c_tadx_tag {
 typedef union cvmx_l2c_tadx_tag cvmx_l2c_tadx_tag_t;
 
 /**
+ * cvmx_l2c_tad#_timeout
+ *
+ * This register records error information for an LFBTO (LFB TimeOut). The first LFBTO
+ * error will lock the register until the logged error type s cleared. If multiple
+ * LFBs timed out simultaneously, then this will contain the information form the
+ * lowest LFB number that has timed-out. The address can be for the original transaction address
+ * or the replacement address (if both could have timed out, then the transaction address will
+ * be here).
+ */
+union cvmx_l2c_tadx_timeout {
+	uint64_t u64;
+	struct cvmx_l2c_tadx_timeout_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t infolfb                      : 1;  /**< Logged address information is for the LFB original transation. */
+	uint64_t infovab                      : 1;  /**< Logged address information is for the VAB (replacement). If both this and INFOLFB is set,
+                                                         then both could have timed out, but info captured is from the original LFB. */
+	uint64_t reserved_57_61               : 5;
+	uint64_t lfbnum                       : 5;  /**< The LFB number of the entry that timed out, and have its info captures in this register. */
+	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. */
+	uint64_t node                         : 4;  /**< Home Node of the address causing the error. Similar the ADDR below, this can be the
+                                                         request address
+                                                         (if INFOLFB is set), else it is the replacement address (if INFOLFB is clear & INFOVAB is
+                                                         set). */
+	uint64_t addr                         : 33; /**< Cache line address causing the error. This can be either the request address or the
+                                                         replacement
+                                                         (if INFOLFB is set), else it is the replacement address (if INFOLFB is clear & INFOVAB is
+                                                         set).
+                                                         This address is a physical address. L2C performs hole removal and index aliasing (if
+                                                         enabled)
+                                                         on the written address and uses that for the command. This hole-removed/index-aliased
+                                                         address
+                                                         is what is returned on a read of L2C_XMC_CMD. */
+	uint64_t reserved_0_6                 : 7;
+#else
+	uint64_t reserved_0_6                 : 7;
+	uint64_t addr                         : 33;
+	uint64_t node                         : 4;
+	uint64_t cmd                          : 8;
+	uint64_t lfbnum                       : 5;
+	uint64_t reserved_57_61               : 5;
+	uint64_t infovab                      : 1;
+	uint64_t infolfb                      : 1;
+#endif
+	} s;
+	struct cvmx_l2c_tadx_timeout_s        cn78xx;
+};
+typedef union cvmx_l2c_tadx_timeout cvmx_l2c_tadx_timeout_t;
+
+/**
+ * cvmx_l2c_tad#_timetwo
+ *
+ * This register records the number of LFB entries that have timed out.
+ *
+ */
+union cvmx_l2c_tadx_timetwo {
+	uint64_t u64;
+	struct cvmx_l2c_tadx_timetwo_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_33_63               : 31;
+	uint64_t sid                          : 4;  /**< Source id of the original request, that is 'source' of request. This is only valid if
+                                                         the request is a local request (valid if  L2C_TAD(0..7)_TIMEOUT[CMD] is an  XMC request
+                                                         and not relevant if it is an OCI request). */
+	uint64_t busid                        : 4;  /**< Busid of the original request, that is 'source' of request. */
+	uint64_t vabst                        : 3;  /**< this is the LFB internal state if INFOLFB is set, else will contain VAB internal state if
+                                                         INFOVAB is set. */
+	uint64_t lfbst                        : 14; /**< this is the LFB internal state if INFOLFB is set, else will contain VAB internal state if
+                                                         INFOVAB is set. */
+	uint64_t tocnt                        : 8;  /**< This is a running count of the LFB that has timed out ... the count will saturate at 0xFF.
+                                                         Will clear when the  LFBTO interrupt is cleared. */
+#else
+	uint64_t tocnt                        : 8;
+	uint64_t lfbst                        : 14;
+	uint64_t vabst                        : 3;
+	uint64_t busid                        : 4;
+	uint64_t sid                          : 4;
+	uint64_t reserved_33_63               : 31;
+#endif
+	} s;
+	struct cvmx_l2c_tadx_timetwo_s        cn78xx;
+};
+typedef union cvmx_l2c_tadx_timetwo cvmx_l2c_tadx_timetwo_t;
+
+/**
  * cvmx_l2c_tad_ctl
  *
  * On CN78XX, MAXLFB, EXLRQ, EXRRQ, EXFWD, EXVIC refer to half-TAD LFBs/VABs. Therefore, even
- * though there are 32 LFBs/VABs in a full TAD, the number applies to both halves.
- * If MAXLFB is != 0, VBF_THRESH should be less than MAXLFB.
- * If MAXVBF is != 0, VBF_THRESH should be less than MAXVBF.
- * If MAXLFB = 0, EXLRQ + EXRRQ + EXFWD + EXVIC must be less than or equal to 13.
- * If MAXLFB != 0, EXLRQ + EXRRQ + EXFWD + EXVIC must be less than or equal to MAXLFB - 3.
+ * though there are 24 LFBs/VABs in a full TAD, the number applies to both halves.
+ * * If MAXLFB is written to 0 or 13-15 operation is undefined. (CN78XX pass 1.0)
+ * * If MAXLFB is != 0, VBF_THRESH should be less than MAXLFB.
+ * * If MAXVBF is != 0, VBF_THRESH should be less than MAXVBF.
+ * * If MAXLFB != 0, EXLRQ + EXRRQ + EXFWD + EXVIC must be less than or equal to MAXLFB - 3.
  */
 union cvmx_l2c_tad_ctl {
 	uint64_t u64;
 	struct cvmx_l2c_tad_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_28_63               : 36;
+	uint64_t reserved_32_63               : 32;
+	uint64_t disrstp                      : 1;  /**< When set, if the L2 receives an RSTP XMC command, it treats it as a STP. */
+	uint64_t wtlmcwrdn                    : 1;  /**< Be more conservative with LFB done relative to LMC writes. */
+	uint64_t wtinvdn                      : 1;  /**< Be more conservative with LFB done relative to invalidates. */
+	uint64_t wtfilldn                     : 1;  /**< Be more conservative with LFB done relative to fills. */
 	uint64_t exlrq                        : 4;  /**< Extra LFBs to reserve for locally generated XMC commands. None are reserved for functional
                                                          correctness. Ignored if L2C_OCI_CTL[ENAOCI] is 0. */
 	uint64_t exrrq                        : 4;  /**< Extra LFBs to reserve for Rxxx OCI commands beyond the 1 required for OCI protocol
@@ -7732,7 +8052,7 @@ union cvmx_l2c_tad_ctl {
 	uint64_t vbf_thresh                   : 4;  /**< VBF threshold. When the number of in-use VBFs exceeds this number the L2C TAD increases
                                                          the priority of all its write operations in the LMC. */
 	uint64_t maxvbf                       : 4;  /**< Maximum VBFs in use at once (0 means 16, 1-15 as expected). */
-	uint64_t maxlfb                       : 4;  /**< Maximum VABs/LFBs in use at once (0 means 16, 1-15 as expected). */
+	uint64_t maxlfb                       : 4;  /**< Maximum VABs/LFBs in use at once (0, 13-15 illegal, 1-12 as expected). */
 #else
 	uint64_t maxlfb                       : 4;
 	uint64_t maxvbf                       : 4;
@@ -7741,7 +8061,11 @@ union cvmx_l2c_tad_ctl {
 	uint64_t exfwd                        : 4;
 	uint64_t exrrq                        : 4;
 	uint64_t exlrq                        : 4;
-	uint64_t reserved_28_63               : 36;
+	uint64_t wtfilldn                     : 1;
+	uint64_t wtinvdn                      : 1;
+	uint64_t wtlmcwrdn                    : 1;
+	uint64_t disrstp                      : 1;
+	uint64_t reserved_32_63               : 32;
 #endif
 	} s;
 	struct cvmx_l2c_tad_ctl_cn70xx {
@@ -8485,7 +8809,7 @@ union cvmx_l2c_xmc_cmd {
 	uint64_t cmd                          : 7;  /**< Command to use for simulated ADD bus request. A new request can be accepted. */
 	uint64_t reserved_47_55               : 9;
 	uint64_t qos                          : 3;  /**< QOS level to use for simulated ADD bus request. */
-	uint64_t node                         : 4;  /**< OCI node to use for simulated ADD bus request. */
+	uint64_t node                         : 4;  /**< Must be zero. */
 	uint64_t addr                         : 40; /**< Address to use for simulated ADD bus request. (The address written to L2C_XMC_CMD is a
                                                          physical address. L2C performs hole removal and index aliasing (if enabled) on the written
                                                          address and uses that for the command. This hole-removed/index-aliased address is what is
diff --git a/arch/mips/include/asm/octeon/cvmx-lapx-defs.h b/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
index d3e35ff..cbcc374 100644
--- a/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
@@ -337,10 +337,10 @@ union cvmx_lapx_cfg {
                                                          When ENA transitions from 0 to 1, LAP will build the free list and empty all queue lists.
                                                          Results are unpredictable if ENA is toggled with traffic outstanding. */
 	uint64_t lab_size                     : 3;  /**< Number of LABs versus size of each LAB. This register may only be changed when [ENA]=0.
-                                                         0x0 = 128 LABs, 16 words/LAB (1024 bits)
-                                                         0x1 = 170 LABs, 12 words/LAB (768 bits)
-                                                         0x2 = 256 LABs, 8 words/LAB (512 bits)
-                                                         0x3-0x7 Reserved */
+                                                         0x0 = 128 LABs, 16 words/LAB (1024 bits).
+                                                         0x1 = 170 LABs, 12 words/LAB (768 bits).
+                                                         0x2 = 256 LABs, 8 words/LAB (512 bits).
+                                                         0x3-0x7 Reserved. */
 #else
 	uint64_t lab_size                     : 3;
 	uint64_t ena                          : 1;
@@ -357,6 +357,9 @@ typedef union cvmx_lapx_cfg cvmx_lapx_cfg_t;
 
 /**
  * cvmx_lap#_edat_err_st
+ *
+ * This register is for diagnostic use only.
+ *
  */
 union cvmx_lapx_edat_err_st {
 	uint64_t u64;
@@ -366,8 +369,8 @@ union cvmx_lapx_edat_err_st {
 	uint64_t fsyn                         : 8;  /**< Syndrome of last Expected Mask Ram ECC error. Latched when LAP(0..1)_GEN_INT[EDAT_SBE] or
                                                          [EDAT_DBE] set */
 	uint64_t reserved_4_15                : 12;
-	uint64_t fadr                         : 4;  /**< Address of last Expected Mask Ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[EDAT_SBE] or [EDAT_DBE] set. */
+	uint64_t fadr                         : 4;  /**< Address of last Expected Mask Ram ECC error. Latched when LAP(0..1)_GEN_INT[EDAT_SBE] or
+                                                         [EDAT_DBE] set. */
 #else
 	uint64_t fadr                         : 4;
 	uint64_t reserved_4_15                : 12;
@@ -381,17 +384,20 @@ typedef union cvmx_lapx_edat_err_st cvmx_lapx_edat_err_st_t;
 
 /**
  * cvmx_lap#_emsk_err_st
+ *
+ * This register is for diagnostic use only.
+ *
  */
 union cvmx_lapx_emsk_err_st {
 	uint64_t u64;
 	struct cvmx_lapx_emsk_err_st_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_24_63               : 40;
-	uint64_t fsyn                         : 8;  /**< Syndrome of last Expected Data Ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[EMSK_SBE] or [EMSK_DBE] set */
+	uint64_t fsyn                         : 8;  /**< Syndrome of last Expected Data Ram ECC error. Latched when LAP(0..1)_GEN_INT[EMSK_SBE] or
+                                                         [EMSK_DBE] set */
 	uint64_t reserved_4_15                : 12;
-	uint64_t fadr                         : 4;  /**< Address of last Expected Data Ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[EMSK_SBE] or [EMSK_DBE] set. */
+	uint64_t fadr                         : 4;  /**< Address of last Expected Data Ram ECC error. Latched when LAP(0..1)_GEN_INT[EMSK_SBE] or
+                                                         [EMSK_DBE] set. */
 #else
 	uint64_t fadr                         : 4;
 	uint64_t reserved_4_15                : 12;
@@ -602,8 +608,8 @@ typedef union cvmx_lapx_gen_int cvmx_lapx_gen_int_t;
 /**
  * cvmx_lap#_lab#_state
  *
- * This register indicates the state of the LAB. This is intended for diagnostics and hypervisor
- * resource recovery; IOBDMA Read operations would normally be used to read this state instead.
+ * This register indicates the state of the LAB. This is intended for diagnostics and resource
+ * recovery; IOBDMA Read operations would normally be used to read this state instead.
  */
 union cvmx_lapx_labx_state {
 	uint64_t u64;
@@ -660,11 +666,9 @@ union cvmx_lapx_lab_err_st {
 	struct cvmx_lapx_lab_err_st_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_26_63               : 38;
-	uint64_t fsyn                         : 10; /**< Syndrome of last LAB data ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[LAB_SBE] or [LAB_DBE] set */
+	uint64_t fsyn                         : 10; /**< Syndrome of last LAB data ram ECC error. Latched when LAP(0..1)_GEN_INT[LAB_SBE] or [LAB_DBE] set */
 	uint64_t reserved_10_15               : 6;
-	uint64_t fadr                         : 10; /**< Address of last LAB data ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[LAB_SBE] or [LAB_DBE] set. */
+	uint64_t fadr                         : 10; /**< Address of last LAB data ram ECC error. Latched when LAP(0..1)_GEN_INT[LAB_SBE] or [LAB_DBE] set. */
 #else
 	uint64_t fadr                         : 10;
 	uint64_t reserved_10_15               : 6;
@@ -678,17 +682,20 @@ typedef union cvmx_lapx_lab_err_st cvmx_lapx_lab_err_st_t;
 
 /**
  * cvmx_lap#_nxt_err_st
+ *
+ * This register is for diagnostic use only.
+ *
  */
 union cvmx_lapx_nxt_err_st {
 	uint64_t u64;
 	struct cvmx_lapx_nxt_err_st_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_21_63               : 43;
-	uint64_t fsyn                         : 5;  /**< Syndrome of last Next Pointer Ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[NXT_SBE] or [NXT_DBE] set */
+	uint64_t fsyn                         : 5;  /**< Syndrome of last Next Pointer Ram ECC error. Latched when LAP(0..1)_GEN_INT[NXT_SBE] or
+                                                         [NXT_DBE] set */
 	uint64_t reserved_8_15                : 8;
-	uint64_t fadr                         : 8;  /**< Address of last Next Pointer Ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[NXT_SBE] or [NXT_DBE] set. */
+	uint64_t fadr                         : 8;  /**< Address of last Next Pointer Ram ECC error. Latched when LAP(0..1)_GEN_INT[NXT_SBE] or
+                                                         [NXT_DBE] set. */
 #else
 	uint64_t fadr                         : 8;
 	uint64_t reserved_8_15                : 8;
@@ -813,17 +820,18 @@ typedef union cvmx_lapx_sft_rst cvmx_lapx_sft_rst_t;
 
 /**
  * cvmx_lap#_sta_err_st
+ *
+ * This register is for diagnostic use only.
+ *
  */
 union cvmx_lapx_sta_err_st {
 	uint64_t u64;
 	struct cvmx_lapx_sta_err_st_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_23_63               : 41;
-	uint64_t fsyn                         : 7;  /**< Syndrome of last LAB state ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[STA_SBE] or [STA_DBE] set */
+	uint64_t fsyn                         : 7;  /**< Syndrome of last LAB state ram ECC error. Latched when LAP(0..1)_GEN_INT[STA_SBE] or [STA_DBE] set */
 	uint64_t reserved_8_15                : 8;
-	uint64_t fadr                         : 8;  /**< Address of last LAB state ram ECC error. Latched when
-                                                         LAP(0..1)_GEN_INT[STA_SBE] or [STA_DBE] set. */
+	uint64_t fadr                         : 8;  /**< Address of last LAB state ram ECC error. Latched when LAP(0..1)_GEN_INT[STA_SBE] or [STA_DBE] set. */
 #else
 	uint64_t fadr                         : 8;
 	uint64_t reserved_8_15                : 8;
@@ -846,17 +854,17 @@ union cvmx_lapx_timeout {
 	uint64_t iobdma                       : 8;  /**< Timeout waiting for an IOBDMA in number of SCLKs minus one divided by 256. After between
                                                          one and two times this interval an IOBDMA request waiting for a packet will return no-data
                                                          as defined in Interlaken Control Word.
-                                                         0x0 = Timeout between 256 and 511 cycles
-                                                         0x1 = Timeout between 512 and 1023 cycles
-                                                         0x2 = Timeout between 768 and 1535 cycles
+                                                         0x0 = Timeout between 256 and 511 cycles.
+                                                         0x1 = Timeout between 512 and 1023 cycles.
+                                                         0x2 = Timeout between 768 and 1535 cycles.
                                                          etc. */
 	uint64_t reserved_12_15               : 4;
-	uint64_t resp                         : 12; /**< Timeout waiting for a response in number of sclks minus one divided by 256. After between
+	uint64_t resp                         : 12; /**< Timeout waiting for a response in number of SCLKs minus one divided by 256. After between
                                                          one and two times this interval an in-flight LAB will be considered lost and marked as
                                                          RECEIVED with error. RESP must be set to >= (2 * LAP(0..1)_TIMEOUT[IOBDMA] + 1).
-                                                         0x0 = Timeout between 256 and 511 cycles
-                                                         0x1 = Timeout between 512 and 1023 cycles
-                                                         0x2 = Timeout between 768 and 1535 cycles
+                                                         0x0 = Timeout between 256 and 511 cycles.
+                                                         0x1 = Timeout between 512 and 1023 cycles.
+                                                         0x2 = Timeout between 768 and 1535 cycles.
                                                          etc. */
 #else
 	uint64_t resp                         : 12;
diff --git a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
index 3ce2632..4e0e93b 100644
--- a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
@@ -1949,16 +1949,14 @@ union cvmx_lmcx_char_mask4 {
 	uint64_t u64;
 	struct cvmx_lmcx_char_mask4_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ref_pin_on_mask              : 9;  /**< INTERNAL: This mask is applied to the REF_PIN_ON signals that go to
-                                                         the PHY, so that each byte lane can selectively turn off or on the signals
-                                                         once the master signals is enabled.  Using the symbol R, the mask looks
-                                                         like this:
+	uint64_t ref_pin_on_mask              : 9;  /**< This mask is applied to the REF_PIN_ON signals that go to the PHY, so that each byte lane
+                                                         can selectively turn off or on the signals once the master signals are enabled. Using the
+                                                         symbol R, the mask looks like this:
                                                          RRRRRRRRR
                                                          876543210 */
-	uint64_t dac_on_mask                  : 9;  /**< INTERNAL: This mask is applied to the DAC_ON signals that go to
-                                                         the PHY, so that each byte lane can selectively turn off or on the signals
-                                                         once the master signals are enabled.  Using the symbols D  for DAC_ON,
-                                                         the mask looks like this:
+	uint64_t dac_on_mask                  : 9;  /**< This mask is applied to the DAC_ON signals that go to the PHY, so that each byte lane can
+                                                         selectively turn off or on the signals once the master signals are enabled. Using the
+                                                         symbol D for DAC_ON, the mask looks like this:
                                                          DDDDDDDDD
                                                          876543210 */
 	uint64_t reserved_45_45               : 1;
@@ -2395,13 +2393,41 @@ typedef union cvmx_lmcx_comp_ctl2 cvmx_lmcx_comp_ctl2_t;
  *
  * This register controls certain parameters required for memory configuration. Note the
  * following:
- * Priority order for hardware write operations to
+ * * Priority order for hardware write operations to
  * LMC(0..3)_CONFIG/LMC(0..3)_FADR/LMC(0..3)_ECC_SYND: DED error > SEC error.
- * The self-refresh entry sequence(s) power the DLL up/down (depending on
+ * * The self-refresh entry sequence(s) power the DLL up/down (depending on
  * LMC(0..3)_MODEREG_PARAMS0[DLL]) when LMC(0..3)_CONFIG[SREF_WITH_DLL] is set.
- * Prior to the self-refresh exit sequence, LMC(0..3)_MODEREG_PARAMS0 should be reprogrammed (if
- * needed) to the appropriate values.
+ * * Prior to the self-refresh exit sequence, LMC(0..3)_MODEREG_PARAMS0 should be reprogrammed
+ * (if needed) to the appropriate values.
  * See LMC Initialization Sequence for the LMC bring-up sequence.
+ * LMC Initialization Sequence:
+ * 1. SW must ensure there are no pending DRAM transactions and that the DDR PLL and the DLL have
+ * been initialized.
+ * 2. Write LMC*_COMP_CTL2, LMC*_CONTROL, LMC*_WODT_MASK, LMC*_DUAL_MEMCFG, LMC*_TIMING_PARAMS0,
+ * LMC*_TIMING_PARAMS1, LMC*_MODEREG_PARAMS0, LMC*_MODEREG_PARAMS1, LMC*_RESET_CTL (with
+ * DDR3RST=0), LMC*_CONFIG with appropriate values, if necessary.
+ * 3. Wait 200us, then write LMC*_RESET_CTL[DDR3RST] = 1.
+ * 4. Initialize all ranks at once by writing LMC*_CONFIG[RANKMASK][n] = 1,
+ * LMC*_SEQ_CTL[SEQ_SEL]= 6, LMC*_SEQ_CTL[INIT_START] = 1, where n is a valid rank index for the
+ * specific board configuration.
+ * 5. for each rank n to be write-leveled [
+ * if auto write-leveling is desired [
+ * write LMC*_CONFIG[RANKMASK][n] = 1, LMC*_WLEVEL_CTL appropriately, LMC*_SEQ_CTL[SEQ_SEL]=6,
+ * and LMC*_CONFIG[INIT_START]= 1
+ * wait until LMC*_WLEVEL_RANKn[STATUS] = 3
+ * ] else [
+ * write LMC*_WLEVEL_RANKn with appropriate values
+ * ]
+ * ]
+ * 6. for each rank n to be read-leveled [
+ * if auto read-leveling is desired [
+ * write LMC*_CONFIG[RANKMASK][n] = 1, LMC*_RLEVEL_CTL appropriately, LMC*_SEQ_CTL[SEQ_SEL] = 1,
+ * and LMC*_CONFIG[INIT_START] = 1
+ * wait until LMC*_RLEVEL_RANKn[STATUS] = 3
+ * ] else [
+ * write LMC*_RLEVEL_RANKn with appropriate values
+ * ]
+ * ]
  */
 union cvmx_lmcx_config {
 	uint64_t u64;
@@ -5423,7 +5449,8 @@ union cvmx_lmcx_ddr_pll_ctl {
 	uint64_t u64;
 	struct cvmx_lmcx_ddr_pll_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_32_63               : 32;
+	uint64_t reserved_44_63               : 20;
+	uint64_t bwadj                        : 12; /**< Bandwidth control for DCLK PLLs. */
 	uint64_t dclk_invert                  : 1;  /**< Invert dclk that feeds LMC/DDR at the south side of the chip. */
 	uint64_t phy_dcok                     : 1;  /**< Set to power up PHY logic after setting LMC(0..3)_DDR_PLL_CTL[DDR4_MODE]. */
 	uint64_t ddr4_mode                    : 1;  /**< DDR4 mode select: 1 = DDR4, 0 = DDR3. */
@@ -5450,7 +5477,8 @@ union cvmx_lmcx_ddr_pll_ctl {
 	uint64_t ddr4_mode                    : 1;
 	uint64_t phy_dcok                     : 1;
 	uint64_t dclk_invert                  : 1;
-	uint64_t reserved_32_63               : 32;
+	uint64_t bwadj                        : 12;
+	uint64_t reserved_44_63               : 20;
 #endif
 	} s;
 	struct cvmx_lmcx_ddr_pll_ctl_cn61xx {
@@ -5575,7 +5603,8 @@ union cvmx_lmcx_ddr_pll_ctl {
 	} cn70xx;
 	struct cvmx_lmcx_ddr_pll_ctl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_32_63               : 32;
+	uint64_t reserved_44_63               : 20;
+	uint64_t bwadj                        : 12; /**< Bandwidth control for DCLK PLLs. */
 	uint64_t dclk_invert                  : 1;  /**< Invert dclk that feeds LMC/DDR at the south side of the chip. */
 	uint64_t phy_dcok                     : 1;  /**< Set to power up PHY logic after setting LMC(0..3)_DDR_PLL_CTL[DDR4_MODE]. */
 	uint64_t ddr4_mode                    : 1;  /**< DDR4 mode select: 1 = DDR4, 0 = DDR3. */
@@ -5592,22 +5621,17 @@ union cvmx_lmcx_ddr_pll_ctl {
                                                          jtg_test_mode) by about 160 microseconds to ensure that lock is achieved. */
 	uint64_t ddr_div_reset                : 1;  /**< DDR postscalar divider reset. */
 	uint64_t ddr_ps_en                    : 4;  /**< DDR postscalar divide ratio. Determines the LMC CK speed.
-                                                         0x0 = divide LMC PLL by TBD.
-                                                         0x1 = divide LMC PLL by TBD.
-                                                         0x2 = divide LMC PLL by TBD.
-                                                         0x3 = divide LMC PLL by TBD.
-                                                         0x4 = divide LMC PLL by TBD.
-                                                         0x5 = divide LMC PLL by TBD.
-                                                         0x6 = divide LMC PLL by TBD.
-                                                         0x7 = divide LMC PLL by TBD.
-                                                         0x8 = divide LMC PLL by TBD.
-                                                         0x9 = divide LMC PLL by TBD.
-                                                         0xA = divide LMC PLL by TBD.
-                                                         0xB = divide LMC PLL by TBD.
-                                                         0xC = divide LMC PLL by TBD.
-                                                         0xD = divide LMC PLL by TBD.
-                                                         0xE = divide LMC PLL by TBD.
-                                                         0xF = divide LMC PLL by TBD.
+                                                         0x0 = Divide LMC PLL by 1.
+                                                         0x1 = Divide LMC PLL by 2.
+                                                         0x2 = Divide LMC PLL by 3.
+                                                         0x3 = Divide LMC PLL by 4.
+                                                         0x4 = Divide LMC PLL by 5.
+                                                         0x5 = Divide LMC PLL by 6.
+                                                         0x6 = Divide LMC PLL by 7.
+                                                         0x7 = Divide LMC PLL by 8.
+                                                         0x8 = Divide LMC PLL by 10.
+                                                         0x9 = Divide LMC PLL by 12.
+                                                         0xA-0xF = Reserved.
                                                          DDR_PS_EN is not used when DDR_DIV_RESET = 1 */
 	uint64_t reserved_9_17                : 9;
 	uint64_t clkf_ext                     : 1;  /**< A 1-bit extension to the CLKF register to support for DDR4-2666. */
@@ -5629,7 +5653,8 @@ union cvmx_lmcx_ddr_pll_ctl {
 	uint64_t ddr4_mode                    : 1;
 	uint64_t phy_dcok                     : 1;
 	uint64_t dclk_invert                  : 1;
-	uint64_t reserved_32_63               : 32;
+	uint64_t bwadj                        : 12;
+	uint64_t reserved_44_63               : 20;
 #endif
 	} cn78xx;
 	struct cvmx_lmcx_ddr_pll_ctl_cn61xx   cnf71xx;
@@ -6202,10 +6227,12 @@ union cvmx_lmcx_dll_ctl3 {
                                                          every LMC(0..0)_CONFIG[REF_ZQCS_INT] CK cycles. */
 	uint64_t dll_mode                     : 1;  /**< Reserved; must be zero. INTERNAL: DLL mode. */
 	uint64_t dll90_byte_sel               : 4;  /**< Observe DLL settings for selected byte.
-                                                         - 0001: byte 0
-                                                         - ...
-                                                         - 1001: byte 8
-                                                         0000,1010-1111: Reserved */
+                                                         - 0011: byte 4
+                                                         - 0100: byte 3
+                                                         - 0101: byte 2
+                                                         - 0110: byte 1
+                                                         - 0111: byte 0
+                                                         0000-0010,1000-1111: Reserved */
 	uint64_t offset_ena                   : 1;  /**< Reserved; must be zero. INTERNAL: Offset enable. 1=enable. */
 	uint64_t load_offset                  : 1;  /**< Reserved; must be zero. INTERNAL: Load offset. 0=disable, 1=generate a one cycle pulse to
                                                          the PHY. This field is a oneshot and clears itself each time it is set. */
@@ -6248,9 +6275,10 @@ typedef union cvmx_lmcx_dll_ctl3 cvmx_lmcx_dll_ctl3_t;
  * LMC(0..3)_CONTROL[XOR_BANK], LMC(0..3)_CONFIG [PBANK_LSB], LMC(0..3)_CONFIG[RANK_ENA], and all
  * timing parameters.
  * In this description:
- * config0 refers to the normal memory configuration that is defined by the
+ * * config0 refers to the normal memory configuration that is defined by the
  * LMC*_CONFIG[ROW_LSB] parameter
- * config1 refers to the dual (or second) memory configuration that is defined by this register.
+ * * config1 refers to the dual (or second) memory configuration that is defined by this
+ * register.
  * Enable-mask to chip-select mapping is shown below:
  */
 union cvmx_lmcx_dual_memcfg {
@@ -6336,14 +6364,13 @@ typedef union cvmx_lmcx_dual_memcfg cvmx_lmcx_dual_memcfg_t;
 /**
  * cvmx_lmc#_ecc_parity_test
  *
- * This register has bits to control the ECC and CA Parity errors creation during test modes.
- * ECC error is generated by enabling the CA_PARITY_CORRUPT_ENA bit of this register and
- * selecting any ECC_CORRUPT_IDX index of the dataword from the cacheline to be
- * corrupted. User can select which bit of the 128-bits dataword to corrupt by asserting
- * any of the CHAR_MASK0 and CHAR_MASK2 bits. (CHAR_MASK0 and CHAR_MASK2 corresponds to the
- * lower and upper 64-bit signal that can corrupt any individual bit of the data).
- *
- * CA Parity error is generated by enabling CA_PARITY_CORRUPT_ENA bit of this register and
+ * This register has bits to control the ECC and CA parity errors creation during test modes. ECC
+ * error is generated by enabling the CA_PARITY_CORRUPT_ENA bit of this register and selecting
+ * any ECC_CORRUPT_IDX index of the dataword from the cacheline to be corrupted. User can select
+ * which bit of the 128-bits dataword to corrupt by asserting any of the CHAR_MASK0 and
+ * CHAR_MASK2 bits. (CHAR_MASK0 and CHAR_MASK2 corresponds to the lower and upper 64-bit signal
+ * that can corrupt any individual bit of the data).
+ * CA parity error is generated by enabling CA_PARITY_CORRUPT_ENA bit of this register and
  * selecting the DDR command that the parity is to be corrupted with through CA_PARITY_SEL.
  */
 union cvmx_lmcx_ecc_parity_test {
@@ -6351,11 +6378,11 @@ union cvmx_lmcx_ecc_parity_test {
 	struct cvmx_lmcx_ecc_parity_test_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t ecc_corrupt_ena              : 1;  /**< enables the ECC data corruption. */
-	uint64_t ecc_corrupt_idx              : 3;  /**< selects the cacheline index that the dataword is to be corrupted with */
+	uint64_t ecc_corrupt_ena              : 1;  /**< Enables the ECC data corruption. */
+	uint64_t ecc_corrupt_idx              : 3;  /**< Selects the cacheline index that the dataword is to be corrupted with. */
 	uint64_t reserved_6_7                 : 2;
-	uint64_t ca_parity_corrupt_ena        : 1;  /**< enables the CA Parity bit corruption. */
-	uint64_t ca_parity_sel                : 5;  /**< selects the type of DDR command to corrupt the parity bit. */
+	uint64_t ca_parity_corrupt_ena        : 1;  /**< Enables the CA parity bit corruption. */
+	uint64_t ca_parity_sel                : 5;  /**< Selects the type of DDR command to corrupt the parity bit. */
 #else
 	uint64_t ca_parity_sel                : 5;
 	uint64_t ca_parity_corrupt_ena        : 1;
@@ -6441,42 +6468,48 @@ union cvmx_lmcx_ext_config {
 	uint64_t u64;
 	struct cvmx_lmcx_ext_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_46_63               : 18;
-	uint64_t error_alert_n_sample         : 1;  /**< Read to get a sample of the DRAM error_alert_n pin. */
-	uint64_t ea_int_polarity              : 1;  /**< Set to invert error_alert_n interrupt polarity.  When clear, interrupt will be signaled
-                                                         on the rising edge of error_alert_n.  When set, interrupt will be signeld on the falling
-                                                         edge of error_alert_n. */
+	uint64_t reserved_49_63               : 15;
+	uint64_t rcd_parity_check             : 1;  /**< Enables the one cycle delay of the CA parity output. This MUST be set to 1 when using DDR4
+                                                         RDIMM AND parity checking in RCD is enabled (RC0E DA0 = 1). Set this to 0 otherwise.
+                                                         To enable the parity checking in RCD, set this bit first BEFORE issuing the RCW write RC0E
+                                                         DA0 = 1. */
+	uint64_t reserved_46_47               : 2;
+	uint64_t error_alert_n_sample         : 1;  /**< Read to get a sample of the DDR*_ERROR_ALERT_L signal. */
+	uint64_t ea_int_polarity              : 1;  /**< Set to invert DDR*_ERROR_ALERT_L interrupt polarity. When clear, interrupt is signaled on
+                                                         the rising edge of DDR*_ERROR_ALERT_L. When set, interrupt is signalled on the falling
+                                                         edge of DDR*_ERROR_ALERT_L. */
 	uint64_t reserved_43_43               : 1;
-	uint64_t par_addr_mask                : 3;  /**< Mask applied to parity for address bits 14, 13, and 12.  Clear to exclude these
-                                                         address bits from the parity calculation, necessary if the DRAM device does not
-                                                         have these pins. */
+	uint64_t par_addr_mask                : 3;  /**< Mask applied to parity for address bits 14, 13, and 12. Clear to exclude these address
+                                                         bits from the parity calculation, necessary if the DRAM device does not have these pins. */
 	uint64_t reserved_38_39               : 2;
 	uint64_t mrs_cmd_override             : 1;  /**< Set to override behavior of MRS and RCS DRAM operations. */
-	uint64_t mrs_cmd_select               : 1;  /**< When LMC(0..3)_EXT_CONFIG[MRS_CMD_OVERRIDE] is set, use this bit to select which
-                                                         style of operation for MRS and RCW commands.  If clear, select operation where
-                                                         signals other than CS are active before and after the CS_N active cycle.  When set,
-                                                         select operation where the other command signals (RAS_N,CAS_N,WE_n,ADDR,etc) all are
-                                                         active only during the cycle where the CS_N is also active. */
+	uint64_t mrs_cmd_select               : 1;  /**< When MRS_CMD_OVERRIDE is set, use this bit to select which style of operation for MRS and
+                                                         RCW commands.
+                                                         If this bit is clear, select operation where signals other than CS are active before and
+                                                         after the CS_N active cycle.
+                                                         When this bit is set, select the operation where the other command signals (DDR*_RAS_L,
+                                                         DDR*_CAS_L, DDR*_WE_L, DDR*_A<15:0>, etc) all are active only during the cycle where the
+                                                         CS_N is also active. */
 	uint64_t reserved_33_35               : 3;
-	uint64_t invert_data                  : 1;  /**< Set this bit to cause all data to be inverted before writing or reading to/from
-                                                         DRAM - this effectively uses the scramble logic to instead invert all the data,
-                                                         so this bit must not be set if data scrambling is enabled.  May be useful if
-                                                         data inversion will result in lower power. */
+	uint64_t invert_data                  : 1;  /**< Set this bit to cause all data to be inverted before writing or reading to/from DRAM. This
+                                                         effectively uses the scramble logic to instead invert all the data, so this bit must not
+                                                         be set if data scrambling is enabled. May be useful if data inversion will result in lower
+                                                         power. */
 	uint64_t reserved_30_31               : 2;
-	uint64_t cmd_rti                      : 1;  /**< Set this bit to change the behavior of the LMC to return to a completely
-                                                         idle command (no CS active, no command pins active, and address/ba/bg all low)
-                                                         on the interface after an active command, rather than only forcing the CS
-                                                         inactive between commands. */
-	uint64_t cal_ena                      : 1;  /**< Set to cause LMC to operate in CAL mode.  DRAM mode registers must first be
-                                                         programmed into CAL mode, then set CAL_ENABLE. */
+	uint64_t cmd_rti                      : 1;  /**< Set this bit to change the behavior of the LMC to return to a completely idle command (no
+                                                         CS active, no command pins active, and address/bank address/bank group all low) on the
+                                                         interface after an active command, rather than only forcing the CS inactive between
+                                                         commands. */
+	uint64_t cal_ena                      : 1;  /**< Set to cause LMC to operate in CAL mode. First set LMC(0..3)_MODEREG_PARAMS3[CAL], then
+                                                         set CAL_ENA. */
 	uint64_t reserved_27_27               : 1;
 	uint64_t par_include_a17              : 1;  /**< If set, include A17 in parity calculations in DDR4 mode. */
 	uint64_t par_include_bg1              : 1;  /**< If set, include BG1 in parity calculations in DDR4 mode. */
-	uint64_t gen_par                      : 1;  /**< Enable parity generation in the DRAM commands, must be set prior to enabling
-                                                         parity in register or DRAM devices */
+	uint64_t gen_par                      : 1;  /**< Enable parity generation in the DRAM commands; must be set prior to enabling parity in
+                                                         register or DRAM devices. */
 	uint64_t reserved_21_23               : 3;
-	uint64_t vrefint_seq_deskew           : 1;  /**< Personality bit to change the operation of what is normally the internal
-                                                         vref training sequence into the deskew training sequence. */
+	uint64_t vrefint_seq_deskew           : 1;  /**< Personality bit to change the operation of what is normally the internal Vref training
+                                                         sequence into the deskew training sequence. */
 	uint64_t read_ena_bprch               : 1;  /**< Enable pad receiver one cycle longer than normal during read operations. */
 	uint64_t read_ena_fprch               : 1;  /**< Enable pad receiver starting one cycle earlier than normal during read operations. */
 	uint64_t slot_ctl_reset_force         : 1;  /**< Write 1 to reset the slot-control override for all slot-control registers. After writing a
@@ -6524,7 +6557,9 @@ union cvmx_lmcx_ext_config {
 	uint64_t reserved_43_43               : 1;
 	uint64_t ea_int_polarity              : 1;
 	uint64_t error_alert_n_sample         : 1;
-	uint64_t reserved_46_63               : 18;
+	uint64_t reserved_46_47               : 2;
+	uint64_t rcd_parity_check             : 1;
+	uint64_t reserved_49_63               : 15;
 #endif
 	} s;
 	struct cvmx_lmcx_ext_config_cn70xx {
@@ -6580,7 +6615,7 @@ typedef union cvmx_lmcx_ext_config cvmx_lmcx_ext_config_t;
  * bank, etc). If scrambling is off, then LMC(0..3)_FADR will also capture the failing physical
  * location in the DRAM parts. LMC(0..3)_SCRAMBLED_FADR captures the actual failing address
  * location in the physical DRAM parts, i.e.,
- * If scrambling is on, LMC(0..3)_SCRAMBLED_FADR contains the failing physical location in the
+ * * If scrambling is on, LMC(0..3)_SCRAMBLED_FADR contains the failing physical location in the
  * DRAM parts (split into DIMM, bunk, bank, etc.)
  * If scrambling is off, the pre-scramble and post-scramble addresses are the same; and so the
  * contents of LMC(0..3)_SCRAMBLED_FADR match the contents of LMC(0..3)_FADR.
@@ -7805,7 +7840,8 @@ union cvmx_lmcx_modereg_params2 {
 	uint64_t u64;
 	struct cvmx_lmcx_modereg_params2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_40_63               : 24;
+	uint64_t reserved_41_63               : 23;
+	uint64_t vrefdq_train_en              : 1;  /**< Vref training mode enable, used for all ranks. */
 	uint64_t vref_range_11                : 1;  /**< VREF range for rank 3. */
 	uint64_t vref_value_11                : 6;  /**< VREF value for rank 3. */
 	uint64_t rtt_park_11                  : 3;  /**< RTT park value for rank 3. */
@@ -7831,7 +7867,8 @@ union cvmx_lmcx_modereg_params2 {
 	uint64_t rtt_park_11                  : 3;
 	uint64_t vref_value_11                : 6;
 	uint64_t vref_range_11                : 1;
-	uint64_t reserved_40_63               : 24;
+	uint64_t vrefdq_train_en              : 1;
+	uint64_t reserved_41_63               : 23;
 #endif
 	} s;
 	struct cvmx_lmcx_modereg_params2_s    cn70xx;
@@ -7982,12 +8019,12 @@ union cvmx_lmcx_mr_mpr_ctl {
 	struct cvmx_lmcx_mr_mpr_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_57_63               : 7;
-	uint64_t mr_wr_bg1                    : 1;  /**< BG1 part of address select for MRS in DDR4 mode. */
+	uint64_t mr_wr_bg1                    : 1;  /**< BG1 part of the address select for MRS in DDR4 mode. */
 	uint64_t reserved_53_55               : 3;
 	uint64_t mr_wr_use_default_value      : 1;  /**< When set, write the value to the MR that is computed from the value set in various CSR
                                                          fields that would be used during initialization, rather that using the value in the
-                                                         LMC(0..3)_MR_MPR_CTL[MR_WR_ADDR] CSR field.  Useful to re-write the same value or
-                                                         to change single bits without having to compute a whole new value for the MR. */
+                                                         LMC(0..3)_MR_MPR_CTL[MR_WR_ADDR]. Useful to rewrite the same value or to change single
+                                                         bits without having to compute a whole new value for the MR. */
 	uint64_t mpr_whole_byte_enable        : 1;  /**< Reserved. INTERNAL: Select a whole byte of DRAM data to read when whole-byte mode enabled. */
 	uint64_t mpr_byte_select              : 4;  /**< Reserved. INTERNAL: Select a whole byte of DRAM data to read when whole-byte mode enabled. */
 	uint64_t mpr_bit_select               : 2;  /**< Select which of four bits to read for each nibble of DRAM data. Typically all four bits
@@ -8319,7 +8356,7 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t dsk_dbg_rd_start             : 1;  /**< Reserved. INTERNAL: Write 1 to start deskew data read operation, will automatically clear
                                                          to 0. Write to 1 will also clear the complete bit. */
 	uint64_t dsk_dbg_clk_scaler           : 2;  /**< Reserved. INTERNAL: Adjust clock toggle rate for reading deskew debug information:
-                                                         0 = Deskew read clock toggles every 4 DCLK
+                                                         0 = Deskew read clock toggles every 4 DCLKs
                                                          1 = Deskew read clock toggles every 8 DCLKs
                                                          2 = Deskew read clock toggles every 12 DCLKs
                                                          3 = Deskew read clock toggles every 16 DCLKs */
@@ -8327,8 +8364,8 @@ union cvmx_lmcx_phy_ctl {
                                                          DDR PHY. */
 	uint64_t dsk_dbg_num_bits_sel         : 1;  /**< Reserved. INTERNAL: Deskew debug, select number of bits per byte lane.
                                                          0 = 8 bits per byte lane, no DBI
-                                                         1 = 9 bits ber byte lane, including DBI */
-	uint64_t dsk_dbg_byte_sel             : 4;  /**< Reserved. INTERNAL: Deskew debug byte select for read operation.  Values 0-3 correspond to
+                                                         1 = 9 bits per byte lane, including DBI */
+	uint64_t dsk_dbg_byte_sel             : 4;  /**< Reserved. INTERNAL: Deskew debug byte select for read operation. Values 0-3 correspond to
                                                          byte lanes 0-3, 4 is for ECC, 5-8 are byte lanes 4-7. */
 	uint64_t dsk_dbg_bit_sel              : 4;  /**< Reserved. INTERNAL: Deskew debug bit select for dsk read operation. */
 	uint64_t dbi_mode_ena                 : 1;  /**< Enable DBI mode for PHY. */
@@ -8337,7 +8374,7 @@ union cvmx_lmcx_phy_ctl {
 	uint64_t dac_on                       : 1;  /**< Reserved. INTERNAL: PHY DAC on. */
 	uint64_t int_pad_loopback_ena         : 1;  /**< DDR pad loopback enable. */
 	uint64_t int_phy_loopback_ena         : 1;  /**< Internal PHY loopback enable. */
-	uint64_t phy_dsk_reset                : 1;  /**< PHY deskew reset. When set, the deskew reset signal goes active if the vrefint/deskew
+	uint64_t phy_dsk_reset                : 1;  /**< PHY deskew reset. When set, the deskew reset signal goes active if the Vrefint/deskew
                                                          training sequence is in the idle state. */
 	uint64_t phy_dsk_byp                  : 1;  /**< PHY deskew bypass. */
 	uint64_t phy_pwr_save_disable         : 1;  /**< DDR PHY power save disable. */
@@ -8808,31 +8845,8 @@ typedef union cvmx_lmcx_read_level_rankx cvmx_lmcx_read_level_rankx_t;
 /**
  * cvmx_lmc#_reset_ctl
  *
- * "Specify the RSL base addresses for the block.
- * INTERNAL: DDR3RST DDR3 DRAM parts have a RESET# pin that wasn't present in DDR2 parts. The
- * DDR3RST CSR field controls the assertion of the 7xxx pin that attaches to RESET#. When DDR3RST
- * is set, 6xxx asserts RESET#. When DDR3RST is clear, 6xxx de-asserts RESET#. DDR3RST is set on
- * a cold reset. Warm and soft chip resets do not affect the DDR3RST value. Outside of cold
- * reset, only software CSR writes change the DDR3RST value. DDR3PWARM Enables preserve mode
- * during a warm reset. When set, the DDR3 controller hardware automatically puts the attached
- * DDR3 DRAM parts into self refresh (see LMC*CONFIG[SEQ_SEL] below) at the beginning of a warm
- * reset sequence, provided that the DDR3 controller is up. When clear, the DDR3 controller
- * hardware does not put the attached DDR3 DRAM parts into self-refresh during a warm reset
- * sequence. DDR3PWARM is cleared on a cold reset. Warm and soft chip resets do not affect the
- * DDR3PWARM value. Outside of cold reset, only software CSR writes change the DDR3PWARM value.
- * Note that if a warm reset follows a soft reset, DDR3PWARM has no effect, as the DDR3
- * controller is no longer up after any cold/warm/soft reset sequence. DDR3PSOFT Enables preserve
- * mode during a soft reset. When set, the DDR3 controller hardware automatically puts the
- * attached DDR3 DRAM parts into self refresh (see LMC*CONFIG[SEQ_SEL] below) at the beginning of
- * a soft reset sequence, provided that the DDR3 controller is up. When clear, the DDR3
- * controller hardware does not put the attached DDR3 DRAM parts into self-refresh during a soft
- * reset sequence. DDR3PSOFT is cleared on a cold reset. Warm and soft chip resets do not affect
- * the DDR3PSOFT value. Outside of cold reset, only software CSR writes change the DDR3PSOFT
- * value. DDR3PSV May be useful for system software to determine when the DDR3 contents have been
- * preserved. Cleared by hardware during a cold reset. Never cleared by hardware during a
- * warm/soft reset. Set by hardware during a warm/soft reset if the hardware automatically put
- * the DDR3 DRAM into self-refresh during the reset sequence. Can also be written by software (to
- * any value)."
+ * Specify the RSL base addresses for the block.
+ *
  */
 union cvmx_lmcx_reset_ctl {
 	uint64_t u64;
@@ -9037,8 +9051,8 @@ typedef union cvmx_lmcx_rlevel_dbg cvmx_lmcx_rlevel_dbg_t;
 /**
  * cvmx_lmc#_rlevel_rank#
  *
- * Four of these CSRs exist per LMC, one for each rank. Deskew setting is measured in units of
- * 1/2 CK, so the BYTEn values can range over 16 CK cycles. Each CSR is written by hardware
+ * Four of these CSRs exist per LMC, one for each rank. Read level setting is measured in units
+ * of 1/4 CK, so the BYTEn values can range over 16 CK cycles. Each CSR is written by hardware
  * during a read-leveling sequence for the rank. (Hardware sets STATUS to 3 after hardware read-
  * leveling completes for the rank.)
  * If hardware is unable to find a match per LMC(0..3)_RLEVEL_CTL[OFFSET_EN] and
@@ -9354,7 +9368,7 @@ typedef union cvmx_lmcx_scramble_cfg1 cvmx_lmcx_scramble_cfg1_t;
  * bank, etc). If scrambling is off, LMC(0..3)_FADR also captures the failing physical location
  * in the DRAM parts. LMC(0..3)_SCRAMBLED_FADR captures the actual failing address location in
  * the physical DRAM parts, i.e.:
- * If scrambling is on, LMC(0..3)_SCRAMBLED_FADR contains the failing physical location in the
+ * * If scrambling is on, LMC(0..3)_SCRAMBLED_FADR contains the failing physical location in the
  * DRAM parts (split into DIMM, bunk, bank, etc);
  * If scrambling is off, the pre-scramble and post-scramble addresses are the same, and so the
  * contents of LMC(0..3)_SCRAMBLED_FADR match the contents of LMC(0..3)_FADR.
@@ -9450,8 +9464,7 @@ union cvmx_lmcx_seq_ctl {
                                                          control words 0-15 are written to LMC(0..3)_CONFIG[RANKMASK]-selected RDIMMs when
                                                          LMC(0..3)_CONTROL[RDIMM_ENA] = 1 and corresponding LMC(0..3)_DIMM_CTL[DIMM*_WMASK] bits
                                                          are set. (Refer to LMC(0..3)_DIMM(0..1)_PARAMS and LMC(0..3)_DIMM_CTL descriptions for
-                                                         more
-                                                         details.)
+                                                         more details.)
                                                          The DRAM registers MR0, MR1, MR2, and MR3 are written in the selected ranks.
                                                          0x1 = Read-leveling:
                                                          LMC(0..3)_CONFIG[RANKMASK] selects the rank to be read-leveled. MR3 written in the
@@ -9499,8 +9512,8 @@ typedef union cvmx_lmcx_seq_ctl cvmx_lmcx_seq_ctl_t;
  * change. Ideally, only read this register after LMC has been initialized and
  * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
  * The interpretation of the fields in this register depends on LMC(0)_CONFIG[DDR2T]:
- * If LMC(0..3)_CONFIG[DDR2T]=1, (FieldValue + 4) is the minimum CK cycles between when the DRAM
- * part registers CAS commands of the 1
+ * * If LMC(0..3)_CONFIG[DDR2T]=1, (FieldValue + 4) is the minimum CK cycles between when the
+ * DRAM part registers CAS commands of the 1
  * st and 2
  * nd types from different cache blocks.
  * If LMC(0..3)_CONFIG[DDR2T]=0, (FieldValue + 3) is the minimum CK cycles between when the DRAM
@@ -9591,8 +9604,8 @@ typedef union cvmx_lmcx_slot_ctl0 cvmx_lmcx_slot_ctl0_t;
  * Ideally, only read this register after LMC has been initialized and
  * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
  * The interpretation of the fields in this CSR depends on LMC(0)_CONFIG[DDR2T]:
- * If LMC(0..3)_CONFIG[DDR2T]=1, (FieldValue + 4) is the minimum CK cycles between when the DRAM
- * part registers CAS commands of the 1
+ * * If LMC(0..3)_CONFIG[DDR2T]=1, (FieldValue + 4) is the minimum CK cycles between when the
+ * DRAM part registers CAS commands of the 1
  * st and 2
  * nd types from different cache blocks.
  * If LMC(0..3)_CONFIG[DDR2T]=0, (FieldValue + 3) is the minimum CK cycles between when the DRAM
@@ -9649,7 +9662,7 @@ typedef union cvmx_lmcx_slot_ctl1 cvmx_lmcx_slot_ctl1_t;
  * Ideally, only read this register after LMC has been initialized and
  * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
  * The interpretation of the fields in this CSR depends on LMC(0)_CONFIG[DDR2T]:
- * If LMC(0..3)_CONFIG[DDR2T] = 1, (FieldValue + 4) is the minimum CK cycles between when the
+ * * If LMC(0..3)_CONFIG[DDR2T] = 1, (FieldValue + 4) is the minimum CK cycles between when the
  * DRAM part registers CAS commands of the 1
  * st and 2
  * nd types from different cache blocks.
@@ -10503,8 +10516,8 @@ typedef union cvmx_lmcx_wlevel_dbg cvmx_lmcx_wlevel_dbg_t;
 /**
  * cvmx_lmc#_wlevel_rank#
  *
- * Four of these CSRs exist per LMC, one for each rank. Deskew setting is measured in units of
- * 1/8 CK, so the below BYTEn values can range over 4 CK cycles. Assuming
+ * Four of these CSRs exist per LMC, one for each rank. Write level setting is measured in units
+ * of 1/8 CK, so the below BYTEn values can range over 4 CK cycles. Assuming
  * LMC(0..3)_WLEVEL_CTL[SSET]=0, the BYTEn<2:0> values are not used during write-leveling, and
  * they are overwritten by the hardware as part of the write-leveling sequence. (Hardware sets
  * STATUS to 3 after hardware write-leveling completes for the rank). Software needs to set
diff --git a/arch/mips/include/asm/octeon/cvmx-mio-defs.h b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
index 10e915b..642c573 100644
--- a/arch/mips/include/asm/octeon/cvmx-mio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
@@ -246,6 +246,17 @@ static inline uint64_t CVMX_MIO_BOOT_REG_TIMX(unsigned long offset)
 #endif
 #define CVMX_MIO_BOOT_THR (CVMX_ADD_IO_SEG(0x00011800000000B0ull))
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_MIO_EMM_ACCESS_WDOG CVMX_MIO_EMM_ACCESS_WDOG_FUNC()
+static inline uint64_t CVMX_MIO_EMM_ACCESS_WDOG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_MIO_EMM_ACCESS_WDOG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00011800000020F0ull);
+}
+#else
+#define CVMX_MIO_EMM_ACCESS_WDOG (CVMX_ADD_IO_SEG(0x00011800000020F0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_MIO_EMM_BUF_DAT CVMX_MIO_EMM_BUF_DAT_FUNC()
 static inline uint64_t CVMX_MIO_EMM_BUF_DAT_FUNC(void)
 {
@@ -323,6 +334,39 @@ static inline uint64_t CVMX_MIO_EMM_DMA_CFG_FUNC(void)
 #define CVMX_MIO_EMM_DMA_CFG (CVMX_ADD_IO_SEG(0x0001180000000180ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_MIO_EMM_DMA_FIFO_ADR CVMX_MIO_EMM_DMA_FIFO_ADR_FUNC()
+static inline uint64_t CVMX_MIO_EMM_DMA_FIFO_ADR_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_MIO_EMM_DMA_FIFO_ADR not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180000000170ull);
+}
+#else
+#define CVMX_MIO_EMM_DMA_FIFO_ADR (CVMX_ADD_IO_SEG(0x0001180000000170ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_MIO_EMM_DMA_FIFO_CFG CVMX_MIO_EMM_DMA_FIFO_CFG_FUNC()
+static inline uint64_t CVMX_MIO_EMM_DMA_FIFO_CFG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_MIO_EMM_DMA_FIFO_CFG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180000000160ull);
+}
+#else
+#define CVMX_MIO_EMM_DMA_FIFO_CFG (CVMX_ADD_IO_SEG(0x0001180000000160ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_MIO_EMM_DMA_FIFO_CMD CVMX_MIO_EMM_DMA_FIFO_CMD_FUNC()
+static inline uint64_t CVMX_MIO_EMM_DMA_FIFO_CMD_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_MIO_EMM_DMA_FIFO_CMD not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180000000178ull);
+}
+#else
+#define CVMX_MIO_EMM_DMA_FIFO_CMD (CVMX_ADD_IO_SEG(0x0001180000000178ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_MIO_EMM_DMA_INT CVMX_MIO_EMM_DMA_INT_FUNC()
 static inline uint64_t CVMX_MIO_EMM_DMA_INT_FUNC(void)
 {
@@ -2197,11 +2241,11 @@ union cvmx_mio_boot_bist_stat {
 	} cn70xx;
 	struct cvmx_mio_boot_bist_stat_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_7_63                : 57;
-	uint64_t stat                         : 7;  /**< BIST status. */
+	uint64_t reserved_8_63                : 56;
+	uint64_t stat                         : 8;  /**< BIST status. */
 #else
-	uint64_t stat                         : 7;
-	uint64_t reserved_7_63                : 57;
+	uint64_t stat                         : 8;
+	uint64_t reserved_8_63                : 56;
 #endif
 	} cn78xx;
 	struct cvmx_mio_boot_bist_stat_cn61xx cnf71xx;
@@ -2335,7 +2379,15 @@ typedef union cvmx_mio_boot_dma_adrx cvmx_mio_boot_dma_adrx_t;
  * cvmx_mio_boot_dma_cfg#
  *
  * This is the DMA engine n configuration register (one register for each of two engines).
- *
+ * Care must be taken to insure that the DMA duration not exceed the processor timeout of 2^29
+ * core clocks or the RML timeout specified in SLI_WINDOW_CTL[TIME] coprocessor clocks if
+ * accesses to the bootbus occur while DMA operations are in progress.
+ * The DMA operation duration in coprocessor clocks as:
+ * MIO_BOOT_DMA_CFGn[SIZE] * MIO_BOOT_DMA_TIMn[TIM_MULT] * CYCLE_TIME.
+ * Where:
+ * CYCLE_TIME = MIO_BOOT_DMA_TIMn[RD_DLY+PAUSE+DMACK_H+WE_N+WE_A+OE_N+OE_A+DMACK_S].
+ * Coprocessor clocks can be converted to core clocks by multiplying the value by the clock ratio
+ * MIO_RST_BOOT[C_MUL] / MIO_RST_BOOT[PNR_MUL]
  */
 union cvmx_mio_boot_dma_cfgx {
 	uint64_t u64;
@@ -2898,24 +2950,24 @@ union cvmx_mio_boot_pin_defs {
 	uint64_t vrm_disable                  : 1;  /**< VRM disabled */
 	uint64_t user1                        : 13; /**< BOOT_AD<31:19> latched during power up */
 	uint64_t device                       : 3;  /**< BOOT_AD<18:16> latched during power up. Indicates boot device:
-                                                         0 = Parallel NOR.
-                                                         1 = Reserved.
-                                                         2 = eMMC/SD.
-                                                         3 = Reserved.
-                                                         4 = SPI Boot (16-bit address).
-                                                         5 = SPI Boot (24-bit address).
-                                                         6 = SPI Boot (32-bit address).
-                                                         7 = Reserved. */
+                                                         0x0 = Parallel NOR.
+                                                         0x1 = Reserved.
+                                                         0x2 = eMMC/SD.
+                                                         0x3 = Reserved.
+                                                         0x4 = SPI Boot (16-bit address).
+                                                         0x5 = SPI Boot (24-bit address).
+                                                         0x6 = SPI Boot (32-bit address).
+                                                         0x7 = Reserved. */
 	uint64_t ale                          : 1;  /**< Region 0 default ALE mode */
 	uint64_t width                        : 1;  /**< Region 0 default bus width */
 	uint64_t user13                       : 1;  /**< BOOT_AD<13> latched during power up */
 	uint64_t dmack_p1                     : 1;  /**< BOOT_DMACK<1> default polarity */
 	uint64_t dmack_p0                     : 1;  /**< BOOT_DMACK<0> default polarity */
 	uint64_t term                         : 2;  /**< Selects default boot-bus driver termination.
-                                                         00 = full strength
-                                                         01 = 25ohm
-                                                         10 = 50ohm
-                                                         11 = 65ohm */
+                                                         0x0 = full strength
+                                                         0x1 = 25ohm
+                                                         0x2 = 50ohm
+                                                         0x3 = 65ohm */
 	uint64_t user0                        : 9;  /**< BOOT_AD<8:0> latched during power up */
 #else
 	uint64_t user0                        : 9;
@@ -3221,6 +3273,27 @@ union cvmx_mio_boot_thr {
 typedef union cvmx_mio_boot_thr cvmx_mio_boot_thr_t;
 
 /**
+ * cvmx_mio_emm_access_wdog
+ */
+union cvmx_mio_emm_access_wdog {
+	uint64_t u64;
+	struct cvmx_mio_emm_access_wdog_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t clk_cnt                      : 32; /**< Number of SCLKs to allow for a DMA operation to complete before hardware will halt the
+                                                         operation.
+                                                         Hardware will inject and error on the next 512-byte block boundary.   The pending DMA
+                                                         operation can be resumed or terminated. A value of zero disables timer. */
+#else
+	uint64_t clk_cnt                      : 32;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} s;
+	struct cvmx_mio_emm_access_wdog_s     cn78xx;
+};
+typedef union cvmx_mio_emm_access_wdog cvmx_mio_emm_access_wdog_t;
+
+/**
  * cvmx_mio_emm_buf_dat
  *
  * MIO_EMM_BUF_DAT = MIO EMMC Data buffer access Register
@@ -3289,52 +3362,11 @@ union cvmx_mio_emm_cfg {
 	uint64_t boot_fail                    : 1;  /**< SW should set BOOT_FAIL when an unrecoverable error occurs
                                                          while attempt to boot from eMMC or NOR Flash.   When set, the
                                                          following pattern will be output:
-                                                           BOOT_AD[7:0] pulled up to 1
-                                                           BOOT_CE_N[7:0] driven to 1
-                                                           BOOT_ALE driven to 0
-                                                           BOOT_OE_L driven to 1
-                                                           BOOT_WE_L driven to 1 */
-	uint64_t reserved_5_15                : 11;
-	uint64_t lockout                      : 1;  /**< eMMC Lockout.  Setting this bit keeps the eMMC controller from
-                                                         requesting the boot bus.  This setting will allow NDF
-                                                         even when the BUS_ENA bits have been set.  Care must be taken
-                                                         to only set this bit when both the eMMC controller and the
-                                                         shared NDF DMA engine are idle. */
-	uint64_t bus_ena                      : 4;  /**< eMMC bus enable mask.
-
-                                                         Setting bit0 of BUS_ENA causes BOOT_CE[1] to become dedicated
-                                                         eMMC bus 0 command (ie. disabling any NOR use)
-
-                                                         Setting bit1 of BUS_ENA causes BOOT_CE[2] to become dedicated
-                                                         eMMC bus 1 command (ie. disabling any NOR use).
-
-                                                         Setting bit2 of BUS_ENA causes BOOT_CE[3] to become dedicated
-                                                         eMMC bus 2 command (ie. disabling any NOR use).
-
-                                                         Setting bit3 of BUS_ENA causes BOOT_CE[4] to become dedicated
-                                                         eMMC bus 3 command (ie. disabling any NOR use).
-
-                                                         Setting any bit of BUS_ENA causes BOOT_CE[5] to become the eMMC
-                                                         clock for both bus0 and bus1. */
-#else
-	uint64_t bus_ena                      : 4;
-	uint64_t lockout                      : 1;
-	uint64_t reserved_5_15                : 11;
-	uint64_t boot_fail                    : 1;
-	uint64_t reserved_17_63               : 47;
-#endif
-	} s;
-	struct cvmx_mio_emm_cfg_cn61xx {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_17_63               : 47;
-	uint64_t boot_fail                    : 1;  /**< SW should set BOOT_FAIL when an unrecoverable error occurs
-                                                         while attempt to boot from eMMC or NOR Flash.   When set, the
-                                                         following pattern will be output:
-                                                           BOOT_AD[7:0] pulled up to 1
+                                                           BOOT_AD[31:0] driven to a 0
                                                            BOOT_CE_N[7:0] driven to 1
-                                                           BOOT_ALE driven to 0
-                                                           BOOT_OE_L driven to 1
-                                                           BOOT_WE_L driven to 1 */
+                                                           BOOT_ALE driven to 1
+                                                           BOOT_OE_L driven to 0
+                                                           BOOT_WE_L driven to 0 */
 	uint64_t reserved_4_15                : 12;
 	uint64_t bus_ena                      : 4;  /**< eMMC bus enable mask.
 
@@ -3358,10 +3390,11 @@ union cvmx_mio_emm_cfg {
 	uint64_t boot_fail                    : 1;
 	uint64_t reserved_17_63               : 47;
 #endif
-	} cn61xx;
+	} s;
+	struct cvmx_mio_emm_cfg_s             cn61xx;
 	struct cvmx_mio_emm_cfg_s             cn70xx;
-	struct cvmx_mio_emm_cfg_cn61xx        cn78xx;
-	struct cvmx_mio_emm_cfg_cn61xx        cnf71xx;
+	struct cvmx_mio_emm_cfg_s             cn78xx;
+	struct cvmx_mio_emm_cfg_s             cnf71xx;
 };
 typedef union cvmx_mio_emm_cfg cvmx_mio_emm_cfg_t;
 
@@ -3375,6 +3408,55 @@ union cvmx_mio_emm_cmd {
 	uint64_t u64;
 	struct cvmx_mio_emm_cmd_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_63_63               : 1;
+	uint64_t skip_busy                    : 1;  /**< Controls when command is completed.
+                                                         0 = Command doesn't complete until card has dropped the BUSY signal.
+                                                         1 = Complete command regardless of the BUSY signal. Status of signal can be read in
+                                                         MIO_EMM_RSP_STS[RSP_BUSYBIT]. */
+	uint64_t bus_id                       : 2;  /**< Specify the eMMC bus */
+	uint64_t cmd_val                      : 1;  /**< Request valid.  SW writes this bit to a 1.   HW clears it when
+                                                         the operation completes. */
+	uint64_t reserved_56_58               : 3;
+	uint64_t dbuf                         : 1;  /**< Specify the data buffer to be used for a block transfer. */
+	uint64_t offset                       : 6;  /**< Debug only.  Specify the number of 8 byte transfers in the
+                                                         used in the command.  Value is 64-OFFSET.  The block transfer
+                                                         will still start at the first btye in the 512B data buffer.
+                                                         SW must ensure CMD16 has updated the card block length. */
+	uint64_t reserved_43_48               : 6;
+	uint64_t ctype_xor                    : 2;  /**< Command Type Override.  Typically Zero.  Value is XOR'd with
+                                                         default command type.  See table of Command Types per CMD#.
+                                                          Types are:  00 = No Data
+                                                                      01 = Read data into Dbuf
+                                                                      10 = Write data from Dbuf
+                                                                      11 = Reserved */
+	uint64_t rtype_xor                    : 3;  /**< Response Type Override.  Typically Zero.  Value is XOR'd with
+                                                         default response type.  See table of Response Types per CMD#.
+                                                          Types are 000 = No Response
+                                                                    001 = R1, 48 bits,
+                                                                    010 = R2, 136 bits
+                                                                    011 = R3, 48 bits,
+                                                                    100 = R4, 48 bits,
+                                                                    101 = R5, 48 bits,
+                                                                    110, 111 = Reserved */
+	uint64_t cmd_idx                      : 6;  /**< eMMC command */
+	uint64_t arg                          : 32; /**< eMMC command argument */
+#else
+	uint64_t arg                          : 32;
+	uint64_t cmd_idx                      : 6;
+	uint64_t rtype_xor                    : 3;
+	uint64_t ctype_xor                    : 2;
+	uint64_t reserved_43_48               : 6;
+	uint64_t offset                       : 6;
+	uint64_t dbuf                         : 1;
+	uint64_t reserved_56_58               : 3;
+	uint64_t cmd_val                      : 1;
+	uint64_t bus_id                       : 2;
+	uint64_t skip_busy                    : 1;
+	uint64_t reserved_63_63               : 1;
+#endif
+	} s;
+	struct cvmx_mio_emm_cmd_cn61xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_62_63               : 2;
 	uint64_t bus_id                       : 2;  /**< Specify the eMMC bus */
 	uint64_t cmd_val                      : 1;  /**< Request valid.  SW writes this bit to a 1.   HW clears it when
@@ -3416,11 +3498,10 @@ union cvmx_mio_emm_cmd {
 	uint64_t bus_id                       : 2;
 	uint64_t reserved_62_63               : 2;
 #endif
-	} s;
-	struct cvmx_mio_emm_cmd_s             cn61xx;
-	struct cvmx_mio_emm_cmd_s             cn70xx;
+	} cn61xx;
+	struct cvmx_mio_emm_cmd_cn61xx        cn70xx;
 	struct cvmx_mio_emm_cmd_s             cn78xx;
-	struct cvmx_mio_emm_cmd_s             cnf71xx;
+	struct cvmx_mio_emm_cmd_cn61xx        cnf71xx;
 };
 typedef union cvmx_mio_emm_cmd cvmx_mio_emm_cmd_t;
 
@@ -3434,6 +3515,51 @@ union cvmx_mio_emm_dma {
 	uint64_t u64;
 	struct cvmx_mio_emm_dma_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_63_63               : 1;
+	uint64_t skip_busy                    : 1;  /**< Controls when DMA is completed.
+                                                         0 = DMA doesn't complete until card has dropped the BUSY signal.
+                                                         1 = Complete DMA after last transfer regardless of the BUSY signal. Status of signal can
+                                                         be read in MIO_EMM_RSP_STS[RSP_BUSYBIT]. */
+	uint64_t bus_id                       : 2;  /**< Specify the eMMC bus */
+	uint64_t dma_val                      : 1;  /**< SW writes this bit to a 1 to indicate that HW should perform
+                                                         the DMA transfer.   HW clears when DMA operation completes or
+                                                         is terminated. */
+	uint64_t sector                       : 1;  /**< Specify CARD_ADDR and eMMC are using sector (512B) addressing. */
+	uint64_t dat_null                     : 1;  /**< Do not perform any eMMC commands.   A DMA read will return all
+                                                         0s.  A DMA write tosses the data.  In the case of a failure,
+                                                         this can be used to unwind the DMA engine. */
+	uint64_t thres                        : 6;  /**< Number of 8B blocks of data that must exist in the DBUF before
+                                                         the starting the 512B block transfer.  0 indicates to wait for
+                                                         the entire block. */
+	uint64_t rel_wr                       : 1;  /**< Set the reliable write parameter when performing CMD23
+                                                         (SET_BLOCK_COUNT) for a multiple block */
+	uint64_t rw                           : 1;  /**< R/W bit (0 = read, 1 = write) */
+	uint64_t multi                        : 1;  /**< Perform operation using a multiple block command instead of a
+                                                         series of single block commands. */
+	uint64_t block_cnt                    : 16; /**< Number of blocks to read/write.  Hardware decrements the block
+                                                         count after each successful block transfer. */
+	uint64_t card_addr                    : 32; /**< Data address for media =<2GB is a 32bit byte address and data
+                                                         address for media > 2GB is a 32bit sector (512B) address.
+                                                         Hardware advances the card address after each successful block
+                                                         transfer by 512 for byte addressing and by 1 for sector
+                                                         addressing. */
+#else
+	uint64_t card_addr                    : 32;
+	uint64_t block_cnt                    : 16;
+	uint64_t multi                        : 1;
+	uint64_t rw                           : 1;
+	uint64_t rel_wr                       : 1;
+	uint64_t thres                        : 6;
+	uint64_t dat_null                     : 1;
+	uint64_t sector                       : 1;
+	uint64_t dma_val                      : 1;
+	uint64_t bus_id                       : 2;
+	uint64_t skip_busy                    : 1;
+	uint64_t reserved_63_63               : 1;
+#endif
+	} s;
+	struct cvmx_mio_emm_dma_cn61xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_62_63               : 2;
 	uint64_t bus_id                       : 2;  /**< Specify the eMMC bus */
 	uint64_t dma_val                      : 1;  /**< SW writes this bit to a 1 to indicate that HW should perform
@@ -3471,11 +3597,10 @@ union cvmx_mio_emm_dma {
 	uint64_t bus_id                       : 2;
 	uint64_t reserved_62_63               : 2;
 #endif
-	} s;
-	struct cvmx_mio_emm_dma_s             cn61xx;
-	struct cvmx_mio_emm_dma_s             cn70xx;
+	} cn61xx;
+	struct cvmx_mio_emm_dma_cn61xx        cn70xx;
 	struct cvmx_mio_emm_dma_s             cn78xx;
-	struct cvmx_mio_emm_dma_s             cnf71xx;
+	struct cvmx_mio_emm_dma_cn61xx        cnf71xx;
 };
 typedef union cvmx_mio_emm_dma cvmx_mio_emm_dma_t;
 
@@ -3503,8 +3628,8 @@ typedef union cvmx_mio_emm_dma_adr cvmx_mio_emm_dma_adr_t;
 /**
  * cvmx_mio_emm_dma_cfg
  *
- * This register controls the DMA engine used with the eMMC/SD flash controller. Sixty-four-bit
- * operations must be used to access this register.
+ * This register controls the internal DMA engine used with the eMMC/SD flash controller.
+ * Sixty-four-bit operations must be used to access this register.
  */
 union cvmx_mio_emm_dma_cfg {
 	uint64_t u64;
@@ -3539,6 +3664,105 @@ union cvmx_mio_emm_dma_cfg {
 typedef union cvmx_mio_emm_dma_cfg cvmx_mio_emm_dma_cfg_t;
 
 /**
+ * cvmx_mio_emm_dma_fifo_adr
+ *
+ * This register specifies the internal address that is loaded into the eMMC internal DMA FIFO.
+ * The FIFO is used to
+ * queue up operations for the MIO_EMM_DMA_CFG/MIO_EMM_DMA_ADR when the DMA completes
+ * successfully.
+ */
+union cvmx_mio_emm_dma_fifo_adr {
+	uint64_t u64;
+	struct cvmx_mio_emm_dma_fifo_adr_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_42_63               : 22;
+	uint64_t adr                          : 42; /**< DMA engine address. Must be 64-bit aligned. */
+#else
+	uint64_t adr                          : 42;
+	uint64_t reserved_42_63               : 22;
+#endif
+	} s;
+	struct cvmx_mio_emm_dma_fifo_adr_s    cn78xx;
+};
+typedef union cvmx_mio_emm_dma_fifo_adr cvmx_mio_emm_dma_fifo_adr_t;
+
+/**
+ * cvmx_mio_emm_dma_fifo_cfg
+ *
+ * This register controls DMA FIFO Operations.
+ *
+ */
+union cvmx_mio_emm_dma_fifo_cfg {
+	uint64_t u64;
+	struct cvmx_mio_emm_dma_fifo_cfg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_17_63               : 47;
+	uint64_t clr                          : 1;  /**< DMA FIFO Clear.  When set erases all commands in the DMA FIFO.  Must be zero for normal operation. */
+	uint64_t reserved_13_15               : 3;
+	uint64_t int_lvl                      : 5;  /**< Interrupt threshold that specifes the number of entries remaining in the DMA FIFO.  A
+                                                         value of 16 or more
+                                                         disables the interrupt.  See MIO_EMM_DMA_INT[FIFO]. */
+	uint64_t reserved_5_7                 : 3;
+	uint64_t count                        : 5;  /**< Number of entries in the DMA FIFO.  This count is incremented by writes to the
+                                                         MIO_EMM_DMA_FIFO_CMD register and
+                                                         decremented each time the internal DMA engine completes the previous command successfully.
+                                                         Up to 16 entries
+                                                         can be placed in the FIFO.  Entries written to a full FIFO will be ignored. */
+#else
+	uint64_t count                        : 5;
+	uint64_t reserved_5_7                 : 3;
+	uint64_t int_lvl                      : 5;
+	uint64_t reserved_13_15               : 3;
+	uint64_t clr                          : 1;
+	uint64_t reserved_17_63               : 47;
+#endif
+	} s;
+	struct cvmx_mio_emm_dma_fifo_cfg_s    cn78xx;
+};
+typedef union cvmx_mio_emm_dma_fifo_cfg cvmx_mio_emm_dma_fifo_cfg_t;
+
+/**
+ * cvmx_mio_emm_dma_fifo_cmd
+ *
+ * This register specifies a command that is loaded into the eMMC internal DMA FIFO.  The FIFO is
+ * used to queue up operations for the MIO_EMM_DMA_CFG/MIO_EMM_DMA_ADR when the DMA completes
+ * successfully.  Writes to this register store both the MIO_EMM_DMA_FIFO_CMD and the
+ * MIO_EMM_DMA_FIFO_ADR contents into the FIFO and increment the MIO_DMA_FIFO_CFG[COUNT] field.
+ * Note:  This register has a similar format to the MIO_EMM_DMA_CFG register
+ * with the exception that the EN and CLR fields are absent.  These are supported in the
+ * MIO_EMM_DMA_FIFO_CFG.
+ */
+union cvmx_mio_emm_dma_fifo_cmd {
+	uint64_t u64;
+	struct cvmx_mio_emm_dma_fifo_cmd_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_63_63               : 1;
+	uint64_t rw                           : 1;  /**< DMA engine R/W bit: 0 = read, 1 = write. */
+	uint64_t reserved_60_61               : 2;
+	uint64_t swap32                       : 1;  /**< DMA engine 32-bit swap. */
+	uint64_t swap16                       : 1;  /**< DMA engine enable 16-bit swap. */
+	uint64_t swap8                        : 1;  /**< DMA engine enable 8-bit swap. */
+	uint64_t endian                       : 1;  /**< DMA engine endian mode: 0 = big-endian, 1 = little-endian. */
+	uint64_t size                         : 20; /**< DMA engine size. Specified in the number of 64-bit transfers (encoded in -1 notation). For
+                                                         example, to transfer 512 bytes, SIZE = 64 - 1 = 63. */
+	uint64_t reserved_0_35                : 36;
+#else
+	uint64_t reserved_0_35                : 36;
+	uint64_t size                         : 20;
+	uint64_t endian                       : 1;
+	uint64_t swap8                        : 1;
+	uint64_t swap16                       : 1;
+	uint64_t swap32                       : 1;
+	uint64_t reserved_60_61               : 2;
+	uint64_t rw                           : 1;
+	uint64_t reserved_63_63               : 1;
+#endif
+	} s;
+	struct cvmx_mio_emm_dma_fifo_cmd_s    cn78xx;
+};
+typedef union cvmx_mio_emm_dma_fifo_cmd cvmx_mio_emm_dma_fifo_cmd_t;
+
+/**
  * cvmx_mio_emm_dma_int
  *
  * Sixty-four-bit operations must be used to access this register.
@@ -3548,11 +3772,15 @@ union cvmx_mio_emm_dma_int {
 	uint64_t u64;
 	struct cvmx_mio_emm_dma_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
-	uint64_t done                         : 1;  /**< DMA engine request completion interrupt. Throws MIO_EMM_INTSN_E::MIO_EMM_DMA_DONE. */
+	uint64_t reserved_2_63                : 62;
+	uint64_t fifo                         : 1;  /**< Internal DMA FIFO has dropped to level specified by MIO_DMA_FIFO_CFG[INT_LVL].  Throws
+                                                         MIO_EMM_INTSN_E::MIO_EMM_DMA_FIFO. */
+	uint64_t done                         : 1;  /**< Internal DMA engine request completion interrupt. Throws
+                                                         MIO_EMM_INTSN_E::MIO_EMM_DMA_DONE. */
 #else
 	uint64_t done                         : 1;
-	uint64_t reserved_1_63                : 63;
+	uint64_t fifo                         : 1;
+	uint64_t reserved_2_63                : 62;
 #endif
 	} s;
 	struct cvmx_mio_emm_dma_int_s         cn78xx;
@@ -3820,6 +4048,84 @@ union cvmx_mio_emm_rsp_sts {
                                                          SW can terminate the transfer by writing MIO_EMM_DMA[DMA_VAL]=1
                                                          and MIO_EMM_DMA[DAT_NULL]=1.   HW will clear DMA_PEND and
                                                          perform the DMA operation. */
+	uint64_t acc_timeout                  : 1;  /**< The DMA store operation took longer than MIO_EMM_ACCESS_WDOG[CLK_CNT] sclks to complete.
+                                                         Valid when DMA_PEND=1. */
+	uint64_t reserved_29_54               : 26;
+	uint64_t dbuf_err                     : 1;  /**< For CMD_TYPE=1, indicates a DMA read data arrived from card
+                                                         without a free DBUF.
+
+                                                         For CMD_TYPE=2, indicates a DBUF underflow occurred during a
+                                                         DMA write.    See MIO_EMM_DMA[THRES]. */
+	uint64_t reserved_24_27               : 4;
+	uint64_t dbuf                         : 1;  /**< DBUF corresponding to the most recently attempted block
+                                                         transfer. */
+	uint64_t blk_timeout                  : 1;  /**< Timeout waiting for read data or 3bit CRC token */
+	uint64_t blk_crc_err                  : 1;  /**< For CMD_TYPE=1, indicates a card read data CRC mismatch.
+                                                         MIO_EMM_RSP_STS[DBUF] indicates the failing data buffer.
+
+                                                         For CMD_TYPE=2, indicates card returned 3-bit CRC status token
+                                                         indicating the card encountered a write data CRC check
+                                                         mismatch.  MIO_EMM_RSP_STS[DBUF] indicates the failing data
+                                                         buffer. */
+	uint64_t rsp_busybit                  : 1;  /**< Debug only.  eMMC protocol utilizes DAT0 as a busy signal
+                                                         during block writes and R1b responses. */
+	uint64_t stp_timeout                  : 1;  /**< Stop transmission response timeout. */
+	uint64_t stp_crc_err                  : 1;  /**< Stop transmission response had a CRC error */
+	uint64_t stp_bad_sts                  : 1;  /**< Stop transmission response had bad status. */
+	uint64_t stp_val                      : 1;  /**< Stop transmission response valid. */
+	uint64_t rsp_timeout                  : 1;  /**< Response timeout */
+	uint64_t rsp_crc_err                  : 1;  /**< Response CRC error */
+	uint64_t rsp_bad_sts                  : 1;  /**< Response bad status */
+	uint64_t rsp_val                      : 1;  /**< Response id.   See MIO_EMM_RSP_HI/LO */
+	uint64_t rsp_type                     : 3;  /**< Indicates the response type. See MIO_EMM_RSP_HI/LO */
+	uint64_t cmd_type                     : 2;  /**< eMMC command type (0=no data, 1=read, 2=write) */
+	uint64_t cmd_idx                      : 6;  /**< eMMC command index most recently attempted */
+	uint64_t cmd_done                     : 1;  /**< eMMC command completed.   Once the command has complete, the
+                                                         status is final and can be examined by SW. */
+#else
+	uint64_t cmd_done                     : 1;
+	uint64_t cmd_idx                      : 6;
+	uint64_t cmd_type                     : 2;
+	uint64_t rsp_type                     : 3;
+	uint64_t rsp_val                      : 1;
+	uint64_t rsp_bad_sts                  : 1;
+	uint64_t rsp_crc_err                  : 1;
+	uint64_t rsp_timeout                  : 1;
+	uint64_t stp_val                      : 1;
+	uint64_t stp_bad_sts                  : 1;
+	uint64_t stp_crc_err                  : 1;
+	uint64_t stp_timeout                  : 1;
+	uint64_t rsp_busybit                  : 1;
+	uint64_t blk_crc_err                  : 1;
+	uint64_t blk_timeout                  : 1;
+	uint64_t dbuf                         : 1;
+	uint64_t reserved_24_27               : 4;
+	uint64_t dbuf_err                     : 1;
+	uint64_t reserved_29_54               : 26;
+	uint64_t acc_timeout                  : 1;
+	uint64_t dma_pend                     : 1;
+	uint64_t dma_val                      : 1;
+	uint64_t switch_val                   : 1;
+	uint64_t cmd_val                      : 1;
+	uint64_t bus_id                       : 2;
+	uint64_t reserved_62_63               : 2;
+#endif
+	} s;
+	struct cvmx_mio_emm_rsp_sts_cn61xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_62_63               : 2;
+	uint64_t bus_id                       : 2;  /**< eMMC bus id to which the response status corresponds. */
+	uint64_t cmd_val                      : 1;  /**< Read-only copy of MIO_EMM_CMD[CMD_VAL].  CMD_VAL=1 indicates a
+                                                         direct operation is in progress. */
+	uint64_t switch_val                   : 1;  /**< Read-only copy of MIO_EMM_SWITCH[SWITCH_EXE].   SWITCH_VAL=1
+                                                         indicates a switch operation is in progress. */
+	uint64_t dma_val                      : 1;  /**< Read-only copy of MIO_EMM_DMA[DMA_VAL].   DMA_VAL=1 indicates a
+                                                         DMA operation is in progress. */
+	uint64_t dma_pend                     : 1;  /**< The DMA engine has a pending transfer resulting from an error.
+                                                         SW can resume the transfer by writing MIO_EMM_DMA[DMA_VAL]=1.
+                                                         SW can terminate the transfer by writing MIO_EMM_DMA[DMA_VAL]=1
+                                                         and MIO_EMM_DMA[DAT_NULL]=1.   HW will clear DMA_PEND and
+                                                         perform the DMA operation. */
 	uint64_t reserved_29_55               : 27;
 	uint64_t dbuf_err                     : 1;  /**< For CMD_TYPE=1, indicates a DMA read data arrived from card
                                                          without a free DBUF.
@@ -3879,11 +4185,10 @@ union cvmx_mio_emm_rsp_sts {
 	uint64_t bus_id                       : 2;
 	uint64_t reserved_62_63               : 2;
 #endif
-	} s;
-	struct cvmx_mio_emm_rsp_sts_s         cn61xx;
-	struct cvmx_mio_emm_rsp_sts_s         cn70xx;
+	} cn61xx;
+	struct cvmx_mio_emm_rsp_sts_cn61xx    cn70xx;
 	struct cvmx_mio_emm_rsp_sts_s         cn78xx;
-	struct cvmx_mio_emm_rsp_sts_s         cnf71xx;
+	struct cvmx_mio_emm_rsp_sts_cn61xx    cnf71xx;
 };
 typedef union cvmx_mio_emm_rsp_sts cvmx_mio_emm_rsp_sts_t;
 
@@ -4564,7 +4869,7 @@ union cvmx_mio_fus_dat2 {
                                                          DORM_CRYPTO = 0, NOCRYPTO = 0 AES/DES/HASH enabled.
                                                          DORM_CRYPTO = 0, NOCRYPTO = 1 AES/DES/HASH disabled.
                                                          DORM_CRYPTO = 1, NOCRYPTO = 0 Dormant encryption enable.
-                                                         DORM_CRYPTO = 1, NOCRYPTO = 1 Authenik mode. */
+                                                         DORM_CRYPTO = 1, NOCRYPTO = 1 Authentik mode. */
 	uint64_t reserved_24_25               : 2;
 	uint64_t chip_id                      : 8;  /**< Fuse information - chip ID. */
 	uint64_t reserved_0_15                : 16;
@@ -4597,7 +4902,8 @@ union cvmx_mio_fus_dat3 {
 	uint64_t u64;
 	struct cvmx_mio_fus_dat3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. */
+	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. INTERNAL: dflt value is 0x02. Soft or hard blow of these fuses
+                                                         will XOR with this value. */
 	uint64_t pll_ctl                      : 10; /**< Fuse information - PLL control */
 	uint64_t dfa_info_dte                 : 3;  /**< Fuse information - DFA information (DTE) */
 	uint64_t dfa_info_clm                 : 4;  /**< Fuse information - DFA information (Cluster mask) */
@@ -4804,7 +5110,8 @@ union cvmx_mio_fus_dat3 {
 	struct cvmx_mio_fus_dat3_cn61xx       cn68xxp1;
 	struct cvmx_mio_fus_dat3_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. */
+	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. INTERNAL: dflt value is 0x02. Soft or hard blow
+                                                         of these fuses will XOR with this value. */
 	uint64_t pll_ctl                      : 10; /**< Fuse information - PLL control. */
 	uint64_t dfa_info_dte                 : 3;  /**< Fuse information - HFA information (HTE). */
 	uint64_t dfa_info_clm                 : 4;  /**< Fuse information - HFA information (cluster mask). */
@@ -4825,7 +5132,8 @@ union cvmx_mio_fus_dat3 {
 	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore */
 	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable */
 	uint64_t nodfa_dte                    : 1;  /**< Fuse information - HFA disable (HTE) */
-	uint64_t ema1                         : 6;  /**< Fuse information - EMA1. */
+	uint64_t ema1                         : 6;  /**< Fuse information - EMA1. INTERNAL: dflt value is 0x11. Soft or hard blow
+                                                         of these fuses will XOR with this value. */
 	uint64_t reserved_0_17                : 18;
 #else
 	uint64_t reserved_0_17                : 18;
@@ -4850,7 +5158,8 @@ union cvmx_mio_fus_dat3 {
 	} cn70xx;
 	struct cvmx_mio_fus_dat3_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. */
+	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. INTERNAL: dflt value is 0x02. Soft or hard blow of these fuses
+                                                         will XOR with this value. */
 	uint64_t pll_ctl                      : 10; /**< Fuse information - PLL control. */
 	uint64_t dfa_info_dte                 : 3;  /**< Fuse information - HFA information (HTE). */
 	uint64_t dfa_info_clm                 : 4;  /**< Fuse information - HFA information (cluster mask). */
@@ -4865,13 +5174,14 @@ union cvmx_mio_fus_dat3 {
                                                          0x3 = 1/4 ways (4-way, 4MB)
                                                          0x4-0x7 = Reserved */
 	uint64_t reserved_31_31               : 1;
-	uint64_t zip_info                     : 2;  /**< Fuse information - Zip information */
-	uint64_t bar2_en                      : 1;  /**< Fuse information - BAR2 present (when blown `1') */
-	uint64_t efus_lck                     : 1;  /**< Fuse information - efuse lockdown */
-	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore */
-	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable */
-	uint64_t nodfa_dte                    : 1;  /**< Fuse information - HFA disable (HTE) */
-	uint64_t ema1                         : 6;  /**< Fuse information - EMA1. */
+	uint64_t zip_info                     : 2;  /**< Fuse information - Zip information. */
+	uint64_t bar2_en                      : 1;  /**< Fuse information - BAR2 present (when blown `1'). */
+	uint64_t efus_lck                     : 1;  /**< Fuse information - efuse lockdown. */
+	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore. */
+	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable. */
+	uint64_t nodfa_dte                    : 1;  /**< Fuse information - HFA disable (HTE). */
+	uint64_t ema1                         : 6;  /**< Fuse information - EMA1. INTERNAL: Default value is 0x11. Soft or hard blow of these fuses
+                                                         will XOR with this value. */
 	uint64_t nohna_dte                    : 1;  /**< Fuse information - HNA disable (DTE). */
 	uint64_t hna_info_dte                 : 3;  /**< Fuse information - HNA information (DTE). */
 	uint64_t hna_info_clm                 : 4;  /**< Fuse information - HNA information (cluster mask). */
@@ -4911,7 +5221,8 @@ union cvmx_mio_fus_dat4 {
 	uint64_t u64;
 	struct cvmx_mio_fus_dat4_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_52_63               : 12;
+	uint64_t global_rclk_byp_select       : 1;  /**< Reserved. */
+	uint64_t global_rclk_byp_setting      : 11; /**< Bits 11:1. Reserved. */
 	uint64_t east_rclk_byp_select         : 1;  /**< Reserved. */
 	uint64_t east_rclk_byp_setting        : 12; /**< Reserved. */
 	uint64_t cmb_rclk_byp_select          : 1;  /**< Reserved. */
@@ -4929,7 +5240,8 @@ union cvmx_mio_fus_dat4 {
 	uint64_t cmb_rclk_byp_select          : 1;
 	uint64_t east_rclk_byp_setting        : 12;
 	uint64_t east_rclk_byp_select         : 1;
-	uint64_t reserved_52_63               : 12;
+	uint64_t global_rclk_byp_setting      : 11;
+	uint64_t global_rclk_byp_select       : 1;
 #endif
 	} s;
 	struct cvmx_mio_fus_dat4_s            cn70xx;
@@ -5213,6 +5525,28 @@ union cvmx_mio_fus_prog {
 	uint64_t u64;
 	struct cvmx_mio_fus_prog_s {
 #ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t prog                         : 1;  /**< Blow the fuse bank
+                                                         SW will set PROG, and then the HW will clear
+                                                         when the program operation is complete */
+#else
+	uint64_t prog                         : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_mio_fus_prog_s            cn30xx;
+	struct cvmx_mio_fus_prog_s            cn31xx;
+	struct cvmx_mio_fus_prog_s            cn38xx;
+	struct cvmx_mio_fus_prog_s            cn38xxp2;
+	struct cvmx_mio_fus_prog_s            cn50xx;
+	struct cvmx_mio_fus_prog_s            cn52xx;
+	struct cvmx_mio_fus_prog_s            cn52xxp1;
+	struct cvmx_mio_fus_prog_s            cn56xx;
+	struct cvmx_mio_fus_prog_s            cn56xxp1;
+	struct cvmx_mio_fus_prog_s            cn58xx;
+	struct cvmx_mio_fus_prog_s            cn58xxp1;
+	struct cvmx_mio_fus_prog_cn61xx {
+#ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
 	uint64_t soft                         : 1;  /**< When set with PROG, causes only the local storeage
                                                          to change.  Will not really blow any fuses.  HW
@@ -5225,36 +5559,33 @@ union cvmx_mio_fus_prog {
 	uint64_t soft                         : 1;
 	uint64_t reserved_2_63                : 62;
 #endif
-	} s;
-	struct cvmx_mio_fus_prog_cn30xx {
+	} cn61xx;
+	struct cvmx_mio_fus_prog_cn61xx       cn63xx;
+	struct cvmx_mio_fus_prog_cn61xx       cn63xxp1;
+	struct cvmx_mio_fus_prog_cn61xx       cn66xx;
+	struct cvmx_mio_fus_prog_cn61xx       cn68xx;
+	struct cvmx_mio_fus_prog_cn61xx       cn68xxp1;
+	struct cvmx_mio_fus_prog_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
-	uint64_t prog                         : 1;  /**< Blow the fuse
-                                                         SW will set PROG, hold it for 10us, then clear it */
+	uint64_t reserved_2_63                : 62;
+	uint64_t sft                          : 1;  /**< INTERNAL: When set with PROG, causes only the local storage to change and will not blow
+                                                         any fuses. Hardware will clear when the program operation is complete. */
+	uint64_t prog                         : 1;  /**< INTERNAL: When written to one by software, blow the fuse bank. Hardware will clear when
+                                                         the program operation is complete.
+                                                         To write a bank of fuses, software must set MIO_FUS_WADR[ADDR] to the bank to be
+                                                         programmed and then set each bit within MIO_FUS_BNK_DATX to indicate which fuses to blow.
+                                                         Once ADDR, and DAT are setup, SW can write to MIO_FUS_PROG[PROG] to start the bank write
+                                                         and poll on PROG. Once PROG is clear, the bank write is complete. A soft blow is still
+                                                         subject to lockdown fuses. After a soft/warm reset, the chip will behave as though the
+                                                         fuses were actually blown. A cold reset restores the actual fuse values. */
 #else
 	uint64_t prog                         : 1;
-	uint64_t reserved_1_63                : 63;
+	uint64_t sft                          : 1;
+	uint64_t reserved_2_63                : 62;
 #endif
-	} cn30xx;
-	struct cvmx_mio_fus_prog_cn30xx       cn31xx;
-	struct cvmx_mio_fus_prog_cn30xx       cn38xx;
-	struct cvmx_mio_fus_prog_cn30xx       cn38xxp2;
-	struct cvmx_mio_fus_prog_cn30xx       cn50xx;
-	struct cvmx_mio_fus_prog_cn30xx       cn52xx;
-	struct cvmx_mio_fus_prog_cn30xx       cn52xxp1;
-	struct cvmx_mio_fus_prog_cn30xx       cn56xx;
-	struct cvmx_mio_fus_prog_cn30xx       cn56xxp1;
-	struct cvmx_mio_fus_prog_cn30xx       cn58xx;
-	struct cvmx_mio_fus_prog_cn30xx       cn58xxp1;
-	struct cvmx_mio_fus_prog_s            cn61xx;
-	struct cvmx_mio_fus_prog_s            cn63xx;
-	struct cvmx_mio_fus_prog_s            cn63xxp1;
-	struct cvmx_mio_fus_prog_s            cn66xx;
-	struct cvmx_mio_fus_prog_s            cn68xx;
-	struct cvmx_mio_fus_prog_s            cn68xxp1;
-	struct cvmx_mio_fus_prog_s            cn70xx;
-	struct cvmx_mio_fus_prog_s            cn78xx;
-	struct cvmx_mio_fus_prog_s            cnf71xx;
+	} cn70xx;
+	struct cvmx_mio_fus_prog_cn70xx       cn78xx;
+	struct cvmx_mio_fus_prog_cn61xx       cnf71xx;
 };
 typedef union cvmx_mio_fus_prog cvmx_mio_fus_prog_t;
 
@@ -5813,9 +6144,8 @@ typedef union cvmx_mio_fus_spr_repair_sum cvmx_mio_fus_spr_repair_sum_t;
 /**
  * cvmx_mio_fus_tgg
  *
- * Notes:
- * The TGG fuses are fuses[831:768].  The valid bit (TGG[63]) is fuse[831].
- *
+ * This register exists to support Authentik. Authentik code should read this register, then
+ * clear VAL to prevent other software from observing the value of the TGG fuses.
  */
 union cvmx_mio_fus_tgg {
 	uint64_t u64;
@@ -6517,9 +6847,9 @@ union cvmx_mio_ptp_clock_cfg {
                                                          0x21      : GPIO[17]
                                                          0x22      : GPIO[18]
                                                          0x23      : GPIO[19]
-                                                         0x10      : QLM0_REF_CLK
-                                                         0x11      : QLM1_REF_CLK
-                                                         0x12      : QLM2_REF_CLK
+                                                         0x10      : DLM0_REF_CLK
+                                                         0x11      : DLM1_REF_CLK
+                                                         0x12      : DLM2_REF_CLK
                                                          0x13-0x1f : Reserved
                                                          0x24-0x3f : Reserved */
 	uint64_t evcnt_edge                   : 1;  /**< Event counter input edge
@@ -6532,9 +6862,9 @@ union cvmx_mio_ptp_clock_cfg {
                                                          0x21      : GPIO[17]
                                                          0x22      : GPIO[18]
                                                          0x23      : GPIO[19]
-                                                         0x10      : QLM0_REF_CLK
-                                                         0x11      : QLM1_REF_CLK
-                                                         0x12      : QLM2_REF_CLK
+                                                         0x10      : DLM0_REF_CLK
+                                                         0x11      : DLM1_REF_CLK
+                                                         0x12      : DLM2_REF_CLK
                                                          0x13-0x1f : Reserved
                                                          0x24-0x3f : Reserved */
 	uint64_t tstmp_edge                   : 1;  /**< External timestamp input edge
@@ -6547,9 +6877,9 @@ union cvmx_mio_ptp_clock_cfg {
                                                          0x21      : GPIO[17]
                                                          0x22      : GPIO[18]
                                                          0x23      : GPIO[19]
-                                                         0x10      : QLM0_EF_CLK
-                                                         0x11      : QLM1_REF_CLK
-                                                         0x12      : QLM2_REF_CLK
+                                                         0x10      : DLM0_REF_CLK
+                                                         0x11      : DLM1_REF_CLK
+                                                         0x12      : DLM2_REF_CLK
                                                          0x13-0x1f : Reserved
                                                          0x24-0x3f : Reserved */
 	uint64_t ext_clk_en                   : 1;  /**< Use external clock */
@@ -6584,8 +6914,8 @@ typedef union cvmx_mio_ptp_clock_cfg cvmx_mio_ptp_clock_cfg_t;
 /**
  * cvmx_mio_ptp_clock_comp
  *
- * This register provides the compensation value the PTP clock.
- *
+ * This register provides the compensation value the PTP clock. MIO_PTP_CLOCK_CFG[PTP_EN] needs
+ * to be enabled before writing this register.
  */
 union cvmx_mio_ptp_clock_comp {
 	uint64_t u64;
@@ -6615,6 +6945,7 @@ typedef union cvmx_mio_ptp_clock_comp cvmx_mio_ptp_clock_comp_t;
  *
  * This register provides bits<95:32> of the PTP clock. Writes to MIO_PTP_CLOCK_HI also clear
  * MIO_PTP_CLOCK_LO. To update all 96 bits, write MIO_PTP_CLOCK_HI followed by MIO_PTP_CLOCK_LO.
+ * MIO_PTP_CLOCK_CFG[PTP_EN] needs to be enabled before writing this register.
  */
 union cvmx_mio_ptp_clock_hi {
 	uint64_t u64;
@@ -6640,8 +6971,8 @@ typedef union cvmx_mio_ptp_clock_hi cvmx_mio_ptp_clock_hi_t;
 /**
  * cvmx_mio_ptp_clock_lo
  *
- * This register provides bits<31:0> of the PTP clock.
- *
+ * This register provides bits<31:0> of the PTP clock.  MIO_PTP_CLOCK_CFG[PTP_EN] needs to be
+ * enabled before writing this register.
  */
 union cvmx_mio_ptp_clock_lo {
 	uint64_t u64;
@@ -8500,9 +8831,9 @@ union cvmx_mio_twsx_int {
 	uint64_t reserved_3_7                 : 5;
 	uint64_t core_int                     : 1;  /**< TWSI core interrupt. Ignored when the HLC is enabled. Throws
                                                          TWS_INTSN_E::MIO_TWS_INT_CORE. */
-	uint64_t ts_int                       : 1;  /**< MIO_TWS_TWSI_SW register-update interrupt. Ignored when the HLC is disabled. Throws
+	uint64_t ts_int                       : 1;  /**< MIO_TWS(0..1)_TWSI_SW register-update interrupt. Ignored when the HLC is disabled. Throws
                                                          TWS_INTSN_E::MIO_TWS_INT_TS. */
-	uint64_t st_int                       : 1;  /**< MIO_TWS_SW_TWSI register-update interrupt. Ignored when the HLC is disabled. Throws
+	uint64_t st_int                       : 1;  /**< MIO_TWS(0..1)_SW_TWSI register-update interrupt. Ignored when the HLC is disabled. Throws
                                                          TWS_INTSN_E::MIO_TWS_INT_ST. */
 #else
 	uint64_t st_int                       : 1;
@@ -8663,9 +8994,9 @@ typedef union cvmx_mio_twsx_sw_twsi cvmx_mio_twsx_sw_twsi_t;
  * This register contains an additional byte of internal address and four additional bytes of
  * data to be used with TWSI master-mode operations.
  * The IA field is sent as the first byte of internal address when performing master-mode
- * combined-read/write-with-IA operations and MIO_TWS_SW_TWSI[EIA] is set. The D field extends
- * the data field of MIO_TWS_SW_TWSI for a total of 8 bytes (SOVR must be set to perform
- * operations greater than 4 bytes).
+ * combined-read/write-with-IA operations and MIO_TWS(0..1)_SW_TWSI[EIA] is set. The D field
+ * extends the data field of MIO_TWS(0..1)_SW_TWSI for a total of 8 bytes (SOVR must be set to
+ * perform operations greater than 4 bytes).
  */
 union cvmx_mio_twsx_sw_twsi_ext {
 	uint64_t u64;
@@ -9013,9 +9344,9 @@ typedef cvmx_mio_uartx_htx_t cvmx_uart_htx_t;
  *
  * The interrupt-enable register is a read/write register that contains four bits that enable the
  * generation of interrupts:
- * enable received data available interrupt (ERBFI)
- * enable transmitter holding register empty interrupt (ETBEI)
- * enable receiver line status interrupt (ELSI)
+ * * enable received data available interrupt (ERBFI)
+ * * enable transmitter holding register empty interrupt (ETBEI)
+ * * enable receiver line status interrupt (ELSI)
  * enable modem status interrupt (EDSSI).
  * The IER also contains the enable bit for the programmable transmit holding register empty
  * (THRE) interrupt mode (PTIME).
diff --git a/arch/mips/include/asm/octeon/cvmx-mixx-defs.h b/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
index 07a6fee..5eb183f 100644
--- a/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
@@ -396,7 +396,7 @@ union cvmx_mixx_ctl {
                                                          requests on the IOI. MIX completes any requests that are currently pending for the IOI. */
 	uint64_t reset                        : 1;  /**< MIX soft reset. When software writes a 1 to this field, the MIX logic executes a soft
                                                          reset.
-                                                         During a soft reset, CSR accesses are not effected. However, the values of the fields are
+                                                         During a soft reset, CSR accesses are not affected. However, the values of the fields are
                                                          affected by soft reset (except
                                                          MIX(0..1)_CTL[RESET] itself).
                                                          After power-on, the MIX-BGX are held in reset until RESET is written to 0. Software must
@@ -724,8 +724,8 @@ union cvmx_mixx_irhwm {
 	uint64_t ibplwm                       : 20; /**< I-Ring backpressure low-watermark threshold.
                                                          When the number of available I-Ring entries (IDBELL) is less than IBPLWM, the BGX-MAC does
                                                          the following:
-                                                         in full-duplex mode: send periodic PAUSE packets.
-                                                         in half-duplex mode: force collisions.
+                                                         * in full-duplex mode: send periodic PAUSE packets.
+                                                         * in half-duplex mode: force collisions.
                                                          This programmable mechanism is provided as a means to backpressure input traffic early
                                                          enough so that packets are not dropped by CN78XX. */
 	uint64_t irhwm                        : 20; /**< I-Ring entry high-watermark threshold. Used to determine when the number of inbound
@@ -820,8 +820,8 @@ union cvmx_mixx_iring1 {
                                                          large as 1MB entries.
                                                          This CSR must be setup written by software poweron (when IDBELL/IRCNT=0). */
 	uint64_t reserved_42_43               : 2;
-	uint64_t ibase                        : 39; /**< Represents the 8-byte aligned base address of the first inbound ring (I-Ring) entry in
-                                                         system memory.
+	uint64_t ibase                        : 39; /**< Represents the 8-byte aligned base address of the first inbound ring
+                                                         (I-Ring) entry in system memory.
                                                          Software must only write to this register during power-on/boot code. */
 	uint64_t reserved_0_2                 : 3;
 #else
@@ -915,16 +915,19 @@ union cvmx_mixx_isr {
                                                          event does occur, DATA_DRP is set and the interrupt is generated. */
 	uint64_t irthresh                     : 1;  /**< Inbound ring packet threshold exceeded. Throws MIX_INTSN_E::MIX(0..1)_INT_IRTHRESH. When
                                                          the pending number of inbound packets in system memory (IRCNT) has exceeded a programmable
-                                                         threshold (IRHWM), this bit is set and the interrupt is generated. */
+                                                         threshold (IRHWM), this bit is set and the interrupt is generated. To service this
+                                                         interrupt, the IRCNT must first be lowered below the IRHWM before the W1C to this field. */
 	uint64_t orthresh                     : 1;  /**< Outbound ring packet threshold exceeded. Throws MIX_INTSN_E::MIX(0..1)_INT_ORTHRESH. When
                                                          the pending number of outbound packets in system memory (ORCNT) has exceeded a
-                                                         programmable threshold (ORHWM), this bit is set and the interrupt is generated. */
+                                                         programmable threshold (ORHWM), this bit is set and the interrupt is generated. To service
+                                                         this interrupt, the ORCNT must first be lowered below the ORHWM before the W1C to this
+                                                         field. */
 	uint64_t idblovf                      : 1;  /**< "Inbound doorbell (IDBELL) overflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_IDBLOVF.
                                                          If software attempts to write to the MIX(0..1)_IRING2[IDBELL] with a value greater than
                                                          the remaining number of I-Ring buffer entries
                                                          (MIX(0..1)_REMCNT[IREMCNT]), then the following occurs:
                                                          The MIX(0..1)_IRING2[IDBELL] write is IGNORED
-                                                         The ODBLOVF is set and an interrupt is generated.
+                                                         IDBLOVF is set and the interrupt is generated.
                                                          Software should keep track of the \# of I-Ring entries in use (i.e. the cumulative number
                                                          of IDBELL write operations), and ensure that future IDBELL write operations don't exceed
                                                          the size of the I-Ring Buffer (MIX(0..1)_IRING2[ISIZE]). Software must reclaim I-Ring
diff --git a/arch/mips/include/asm/octeon/cvmx-mpi-defs.h b/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
index 996f9fd..e3b6de1 100644
--- a/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
@@ -533,7 +533,7 @@ union cvmx_mpi_cfg {
                                                          1=BOOT_CE_N<6>/SPI_CS0_L pin is MPI/SPI pin
                                                          SPI_CS0_L drives BOOT_CE_N<6>/SPI_CS0_L. */
 	uint64_t cslate                       : 1;  /**< SPI_CSn_L late.
-                                                         0 = SPI_CSn_L asserts 1/4 coprocessor-clock cycle before the transaction.
+                                                         0 = SPI_CSn_L asserts 1/2 coprocessor-clock cycle before the transaction.
                                                          1 = SPI_CSn_L asserts coincident with the transaction. */
 	uint64_t tritx                        : 1;  /**< Tristate TX. Used only when WIREOR = 1
                                                          0 = SPI_DO pin is driven when slave is not expected to be driving.
diff --git a/arch/mips/include/asm/octeon/cvmx-nand.h b/arch/mips/include/asm/octeon/cvmx-nand.h
index 4a84297..c0de76f 100644
--- a/arch/mips/include/asm/octeon/cvmx-nand.h
+++ b/arch/mips/include/asm/octeon/cvmx-nand.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com).  All rights
  * reserved.
  *
  *
@@ -20,7 +20,7 @@
  *     derived from this software without specific prior written
  *     permission.
 
- * This Software, including technical data, may be subject to U.S. export  control
+ * This Software, including technical data, may be subject to U.S. export control
  * laws, including the U.S. Export Administration Act and its  associated
  * regulations, and may be subject to export or import  regulations in other
  * countries.
@@ -361,136 +361,212 @@ typedef union {
 } cvmx_nand_cmd_t;
 
 typedef struct __attribute__ ((packed)) {
-	char onfi[4];		    /**< Bytes 0-3: The ASCII characters 'O', 'N', 'F', 'I' */
-	uint16_t revision_number;
-				    /**< Bytes 4-5: ONFI revision number
-                                        - 2-15 Reserved (0)
-                                        - 1    1 = supports ONFI version 1.0
-                                        - 0    Reserved (0) */
-	uint16_t features;	    /**< Bytes 6-7: Features supported
-                                        - 5-15    Reserved (0)
-                                        - 4       1 = supports odd to even page Copyback
-                                        - 3       1 = supports interleaved operations
-                                        - 2       1 = supports non-sequential page programming
-                                        - 1       1 = supports multiple LUN operations
-                                        - 0       1 = supports 16-bit data bus width */
-	uint16_t optional_commands;
-				    /**< Bytes 8-9: Optional commands supported
-                                        - 6-15   Reserved (0)
-                                        - 5      1 = supports Read Unique ID
-                                        - 4      1 = supports Copyback
-                                        - 3      1 = supports Read Status Enhanced
-                                        - 2      1 = supports Get Features and Set Features
-                                        - 1      1 = supports Read Cache commands
-                                        - 0      1 = supports Page Cache Program command */
-	uint8_t reserved_10_31[22];
-				    /**< Bytes 10-31: Reserved */
-
-	char manufacturer[12];
-				    /**< Bytes 32-43: Device manufacturer (12 ASCII characters) */
-	char model[20];		    /**< Bytes 40-63: Device model (20 ASCII characters) */
-	uint8_t jedec_id;	    /**< Byte 64: JEDEC manufacturer ID */
-	uint16_t date_code;	    /**< Byte 65-66: Date code */
-	uint8_t reserved_67_79[13];
-				    /**< Bytes 67-79: Reserved */
-
-	uint32_t page_data_bytes;
-				    /**< Bytes 80-83: Number of data bytes per page */
-	uint16_t page_spare_bytes;
-				    /**< Bytes 84-85: Number of spare bytes per page */
-	uint32_t partial_page_data_bytes;
-				      /**< Bytes 86-89: Number of data bytes per partial page */
-	uint16_t partial_page_spare_bytes;
-				       /**< Bytes 90-91: Number of spare bytes per partial page */
-	uint32_t pages_per_block;
-				    /**< Bytes 92-95: Number of pages per block */
-	uint32_t blocks_per_lun;
-				    /**< Bytes 96-99: Number of blocks per logical unit (LUN) */
-	uint8_t number_lun;	    /**< Byte 100: Number of logical units (LUNs) */
-	uint8_t address_cycles;
-				    /**< Byte 101: Number of address cycles
-                                        - 4-7     Column address cycles
-                                        - 0-3     Row address cycles */
-	uint8_t bits_per_cell;
-				    /**< Byte 102: Number of bits per cell */
-	uint16_t bad_block_per_lun;
-				    /**< Bytes 103-104: Bad blocks maximum per LUN */
-	uint16_t block_endurance;
-				    /**< Bytes 105-106: Block endurance */
-	uint8_t good_blocks;	    /**< Byte 107: Guaranteed valid blocks at beginning of target */
-	uint16_t good_block_endurance;
-				    /**< Bytes 108-109: Block endurance for guaranteed valid blocks */
-	uint8_t programs_per_page;
-				    /**< Byte 110: Number of programs per page */
-	uint8_t partial_program_attrib;
-				    /**< Byte 111: Partial programming attributes
-                                        - 5-7    Reserved
-                                        - 4      1 = partial page layout is partial page data followed by partial page spare
-                                        - 1-3    Reserved
-                                        - 0      1 = partial page programming has constraints */
-	uint8_t bits_ecc;	    /**< Byte 112: Number of bits ECC correctability */
-	uint8_t interleaved_address_bits;
-					/**< Byte 113: Number of interleaved address bits
-                                            - 4-7    Reserved (0)
-                                            - 0-3    Number of interleaved address bits */
-	uint8_t interleaved_attrib;
-				    /**< Byte 114: Interleaved operation attributes
-                                        - 4-7    Reserved (0)
-                                        - 3      Address restrictions for program cache
-                                        - 2      1 = program cache supported
-                                        - 1      1 = no block address restrictions
-                                        - 0      Overlapped / concurrent interleaving support */
-	uint8_t reserved_115_127[13];
-				    /**< Bytes 115-127: Reserved (0) */
-
-	uint8_t pin_capacitance;
-				    /**< Byte 128: I/O pin capacitance */
-	uint16_t timing_mode;
-				    /**< Byte 129-130: Timing mode support
-                                        - 6-15   Reserved (0)
-                                        - 5      1 = supports timing mode 5
-                                        - 4      1 = supports timing mode 4
-                                        - 3      1 = supports timing mode 3
-                                        - 2      1 = supports timing mode 2
-                                        - 1      1 = supports timing mode 1
-                                        - 0      1 = supports timing mode 0, shall be 1 */
-	uint16_t cache_timing_mode;
-				    /**< Byte 131-132: Program cache timing mode support
-                                        - 6-15   Reserved (0)
-                                        - 5      1 = supports timing mode 5
-                                        - 4      1 = supports timing mode 4
-                                        - 3      1 = supports timing mode 3
-                                        - 2      1 = supports timing mode 2
-                                        - 1      1 = supports timing mode 1
-                                        - 0      1 = supports timing mode 0 */
-	uint16_t t_prog;	    /**< Byte 133-134: Maximum page program time (us) */
-	uint16_t t_bers;	    /**< Byte 135-136: Maximum block erase time (us) */
-	uint16_t t_r;		    /**< Byte 137-148: Maximum page read time (us) */
-	uint16_t t_ccs;		    /**< Byte 139-140: Minimum change column setup time (ns) */
-	uint8_t reserved_141_163[23];
-				    /**< Byte 141-163: Reserved (0) */
-
-	uint16_t vendor_revision;
-				    /**< Byte 164-165: Vendor specific Revision number */
-	uint8_t vendor_specific[88];
-				    /**< Byte 166-253: Vendor specific */
-	uint16_t crc;		    /**< Byte 254-255: Integrity CRC */
+	char onfi[4];			/**
+					 * Bytes 0-3: The ASCII characters
+					 * 'O', 'N', 'F', 'I'
+					 */
+	uint16_t revision_number;	/**
+					 * Bytes 4-5: ONFI revision number
+                                         * - 2-15 Reserved (0)
+                                         * - 1    1 = supports ONFI version 1.0
+                                         * - 0    Reserved (0)
+                                         */
+	uint16_t features;		/**
+					 * Bytes 6-7: Features supported
+                                         * - 5-15    Reserved (0)
+                                         * - 4       1 = supports odd to even
+                                         *		 page Copyback
+                                         * - 3       1 = supports interleaved
+                                         *		 operations
+                                         * - 2       1 = supports non-sequential
+                                         *		 page programming
+                                         * - 1       1 = supports multiple LUN
+                                         *		 operations
+                                         * - 0       1 = supports 16-bit data
+                                         *		 bus width
+                                         */
+	uint16_t optional_commands;	/**
+					 * Bytes 8-9: Optional commands
+					 * supported
+					 *   - 6-15   Reserved (0)
+					 *   - 5      1 = supports Read Unique
+					 *		  ID
+					 *   - 4      1 = supports Copyback
+					 *   - 3      1 = supports Read Status
+					 *		  Enhanced
+					 *   - 2      1 = supports Get Features
+					 *		  and Set Features
+					 *   - 1      1 = supports Read Cache
+					 *		  commands
+					 *   - 0      1 = supports Page Cache
+					 *		  Program command
+					 */
+	uint8_t reserved_10_11[2]; 	/** Bytes 10-11: Reserved */
+	uint16_t extended_param_page_len;/** Extended parameter page length */
+	uint8_t num_param_pages;	/** Number of parameter pages */
+	uint8_t reserved_15_31[17];	/** Bytes 15-31: Reserved */
+	char manufacturer[12];		/**
+					 * Bytes 32-43: Device manufacturer
+					 * (12 ASCII characters)
+					 */
+	char model[20];			/**
+					 * Bytes 40-63: Device model
+					 * (20 ASCII characters)
+					 */
+	uint8_t jedec_id;	    	/** Byte 64: JEDEC manufacturer ID */
+	uint16_t date_code;	    	/** Byte 65-66: Date code */
+	uint8_t reserved_67_79[13];	/** Bytes 67-79: Reserved */
+	uint32_t page_data_bytes;	/**
+					 * Bytes 80-83: Number of data bytes per
+					 * page
+					 */
+	uint16_t page_spare_bytes;	/**
+					 * Bytes 84-85: Number of spare bytes
+					 * per page
+					 */
+	uint32_t partial_page_data_bytes;	/**
+						* Bytes 86-89: Number of data
+						* bytes per partial page
+						*/
+	uint16_t partial_page_spare_bytes;	/**
+						 * Bytes 90-91: Number of spare
+						 * bytes per partial page
+						 */
+	uint32_t pages_per_block;	/**
+					 * Bytes 92-95: Number of pages per
+					 * block
+					 */
+	uint32_t blocks_per_lun;	/**
+					 * Bytes 96-99: Number of blocks per
+					 * logical unit (LUN)
+					 */
+	uint8_t number_lun;		/**
+					 * Byte 100: Number of logical units
+					 * (LUNs)
+					 */
+	uint8_t address_cycles;		/**
+					 * Byte 101: Number of address cycles
+                                         * - 4-7     Column address cycles
+                                         * - 0-3     Row address cycles
+                                         */
+	uint8_t bits_per_cell;		/** Byte 102: Number of bits per cell */
+	uint16_t bad_block_per_lun;	/**
+					 *  Bytes 103-104: Bad blocks maximum
+					 * per LUN
+					 */
+	uint16_t block_endurance;	/** Bytes 105-106: Block endurance */
+	uint8_t good_blocks;		/**
+					 * Byte 107: Guaranteed valid blocks at
+					 * beginning of target
+					 */
+	uint16_t good_block_endurance;	/**
+					 * Bytes 108-109: Block endurance for
+					 * guaranteed valid blocks
+					 */
+	uint8_t programs_per_page;	/**
+					 * Byte 110: Number of programs per page
+					 */
+	uint8_t partial_program_attrib;	/**
+					 * Byte 111: Partial programming
+					 * attributes
+					 * - 5-7    Reserved
+					 * - 4      1 = partial page layout is
+					 *		partial page data
+					 *		followed by partial
+					 *		page spare
+					 * - 1-3    Reserved
+					 * - 0      1 = partial page programming
+					 *		has constraints
+					 */
+	uint8_t bits_ecc;		/**
+					 * Byte 112: Number of bits ECC
+					 * correctability
+					 */
+	uint8_t interleaved_address_bits;	/**
+						 * Byte 113: Number of
+						 * interleaved address bits
+						 * - 4-7    Reserved (0)
+						 * - 0-3    Number of
+						 *	    interleaved address
+						 *	    bits
+						 */
+	uint8_t interleaved_attrib;	/**
+					 * Byte 114: Interleaved operation
+					 * attributes
+					 * - 4-7    Reserved (0)
+					 * - 3      Address restrictions for
+					 *	    program cache
+					 * - 2      1 = program cache supported
+					 * - 1      1 = no block address
+					 *		restrictions
+					 * - 0      Overlapped / concurrent
+					 *	    interleaving support
+					 */
+	uint8_t reserved_115_127[13];	/** Bytes 115-127: Reserved (0) */
+
+	uint8_t pin_capacitance;	/** Byte 128: I/O pin capacitance */
+	uint16_t timing_mode;		/**
+					 * Byte 129-130: Timing mode support
+					 * - 6-15   Reserved (0)
+					 * - 5      1 = supports timing mode 5
+					 * - 4      1 = supports timing mode 4
+					 * - 3      1 = supports timing mode 3
+					 * - 2      1 = supports timing mode 2
+					 * - 1      1 = supports timing mode 1
+					 * - 0      1 = supports timing mode 0,
+					 *		shall be 1
+					 */
+	uint16_t cache_timing_mode;	/**
+					 * Byte 131-132: Program cache timing
+					 * mode support
+					 * - 6-15   Reserved (0)
+					 * - 5      1 = supports timing mode 5
+					 * - 4      1 = supports timing mode 4
+					 * - 3      1 = supports timing mode 3
+					 * - 2      1 = supports timing mode 2
+					 * - 1      1 = supports timing mode 1
+					 * - 0      1 = supports timing mode 0
+					 */
+	uint16_t t_prog;		/**
+					 * Byte 133-134: Maximum page program
+					 * time (us)
+					 */
+	uint16_t t_bers;		/**
+					 * Byte 135-136: Maximum block erase
+					 * time (us)
+					 */
+	uint16_t t_r;			/**
+					 * Byte 137-148: Maximum page read time
+					 * (us)
+					 */
+	uint16_t t_ccs;			/**
+					 * Byte 139-140: Minimum change column
+					 * setup time (ns)
+					 */
+	uint8_t reserved_141_163[23];	/** Byte 141-163: Reserved (0) */
+	uint16_t vendor_revision;	/**
+					 * Byte 164-165: Vendor specific
+					 * Revision number
+					 */
+	uint8_t vendor_specific[88];	/** Byte 166-253: Vendor specific */
+	uint16_t crc;			/** Byte 254-255: Integrity CRC */
 } cvmx_nand_onfi_param_page_t;
 
 /**
- * Called to initialize the NAND controller for use. Note that
- * you must be running out of L2 or memory and not NAND before
- * calling this function.
- * When probing for NAND chips, this function attempts to autoconfigure based on the NAND parts detected.
- * It currently supports autodetection for ONFI parts (with valid parameter pages), and some Samsung NAND
- * parts (decoding ID bits.)  If autoconfiguration fails, the defaults set with __set_chip_defaults()
- * prior to calling cvmx_nand_initialize() are used.
- * If defaults are set and the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is provided, the defaults are used
- * for all chips in the active_chips mask.
+ * Called to initialize the NAND controller for use.  Note that you must be
+ * running out of L2 or memory and not NAND before calling this function.
+ * When probing for NAND chips, this function attempts to autoconfigure based
+ * on the NAND parts detected.  It currently supports autodetection for ONFI
+ * parts (with valid parameter pages), and some Samsung NAND parts (decoding ID
+ * bits).  If autoconfiguration fails, the defaults set with
+ * __set_chip_defaults() prior to calling cvmx_nand_initialize() are used.
+ * If defaults are set and the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is
+ * provided, the defaults are used for all chips in the active_chips mask.
  *
  * @param flags  Optional initialization flags
- *               If the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is passed, chips are not probed,
- *               and the default parameters (if set with cvmx_nand_set_defaults) are used for all chips
+ *               If the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is passed,
+ *		 chips are not probed and the default parameters, if set with
+ *		 cvmx_nand_set_defaults, are used for all chips
  *               in the active_chips mask.
  * @param active_chips
  *               Each bit in this parameter represents a chip select that might
@@ -500,17 +576,20 @@ typedef struct __attribute__ ((packed)) {
  *
  * @return Zero on success, a negative cvmx_nand_status_t error code on failure
  */
-extern cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags, int active_chips);
+extern cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags,
+					       int active_chips);
 
 /**
- * This function may be called before cvmx_nand_initialize to set default values that will be used
- * for NAND chips that do not identify themselves in a way that allows autoconfiguration. (ONFI chip with
- * missing parameter page, for example.)
- * The parameters set by this function will be used by _all_ non-autoconfigured NAND chips.
+ * This function may be called before cvmx_nand_initialize to set default values
+ * that will be used for NAND chips that do not identify themselves in a way
+ * that allows autoconfiguration. (ONFI chip with missing parameter page, for
+ * example).
+ * The parameters set by this function will be used by _all_ non-autoconfigured
+ * NAND chips.
  *
  *
- *   NOTE:  This function signature is _NOT_ stable, and will change in the future as required to support
- *          various NAND chips.
+ *   NOTE:  This function signature is _NOT_ stable, and will change in the
+ *          future as required to support various NAND chips.
  *
  * @param page_size page size in bytes
  * @param oob_size  Out of band size in bytes (per page)
@@ -522,7 +601,10 @@ extern cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flag
  *
  * @return Zero on success, a negative cvmx_nand_status_t error code on failure
  */
-extern cvmx_nand_status_t cvmx_nand_set_defaults(int page_size, int oob_size, int pages_per_block, int blocks, int onfi_timing_mode);
+extern cvmx_nand_status_t cvmx_nand_set_defaults(int page_size, int oob_size,
+						 int pages_per_block,
+						 int blocks,
+						 int onfi_timing_mode);
 
 /**
  * Call to shutdown the NAND controller after all transactions
@@ -533,10 +615,10 @@ extern cvmx_nand_status_t cvmx_nand_set_defaults(int page_size, int oob_size, in
 extern cvmx_nand_status_t cvmx_nand_shutdown(void);
 
 /**
- * Returns a bitmask representing the chip selects that are
- * connected to NAND chips. This can be called after the
- * initialize to determine the actual number of NAND chips
- * found. Each bit in the response coresponds to a chip select.
+ * Returns a bitmask representing the chip selects that are connected to NAND
+ * chips.  This can be called after initializing to determine the actual
+ * number of NAND chips found.  Each bit in the response coresponds to a chip
+ * select.
  *
  * @return Zero if no NAND chips were found. Otherwise a bit is set for
  *         each chip select (1<<chip).
@@ -556,7 +638,10 @@ extern int cvmx_nand_get_active_chips(void);
  *
  * @return Zero on success, a negative cvmx_nand_status_t error code on failure
  */
-extern cvmx_nand_status_t cvmx_nand_set_timing(int chip, int tim_mult, int tim_par[7], int clen[4], int alen[4], int rdn[4], int wrn[2]);
+extern cvmx_nand_status_t cvmx_nand_set_timing(int chip, int tim_mult,
+					       int tim_par[7], int clen[4],
+					       int alen[4], int rdn[4],
+					       int wrn[2]);
 
 /**
  * Submit a command to the NAND command queue. Generally this
@@ -581,9 +666,11 @@ extern cvmx_nand_status_t cvmx_nand_submit(cvmx_nand_cmd_t cmd);
  * @param buffer_length
  *               Number of bytes to read
  *
- * @return Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ * @return Bytes read on success, a negative cvmx_nand_status_t error code on
+ *	   failure
  */
-extern int cvmx_nand_page_read(int chip, uint64_t nand_address, uint64_t buffer_address, int buffer_length);
+extern int cvmx_nand_page_read(int chip, uint64_t nand_address,
+			       uint64_t buffer_address, int buffer_length);
 
 /**
  * Read random data from NAND.  This adjusts the column address before starting
@@ -616,7 +703,8 @@ extern int cvmx_nand_random_data_out(int chip, uint64_t nand_address,
  *
  * @return Zero on success, a negative cvmx_nand_status_t error code on failure
  */
-extern cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address, uint64_t buffer_address);
+extern cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address,
+					       uint64_t buffer_address);
 
 /**
  * Erase a NAND block. A single block contains multiple pages.
@@ -634,15 +722,18 @@ extern cvmx_nand_status_t cvmx_nand_block_erase(int chip, uint64_t nand_address)
  *
  * @param chip   Chip select for NAND flash
  * @param nand_address
- *               NAND address to read ID from. Usually this is either 0x0 or 0x20.
+ *               NAND address to read ID from. Usually this is either 0x0 or
+ *		 0x20.
  * @param buffer_address
  *               Physical address to store data in
  * @param buffer_length
  *               Length of the buffer. Usually this is 4 bytes
  *
- * @return Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ * @return Bytes read on success, a negative cvmx_nand_status_t error code on
+ *         failure
  */
-extern int cvmx_nand_read_id(int chip, uint64_t nand_address, uint64_t buffer_address, int buffer_length);
+extern int cvmx_nand_read_id(int chip, uint64_t nand_address,
+			     uint64_t buffer_address, int buffer_length);
 
 /**
  * Read the NAND parameter page
@@ -653,21 +744,25 @@ extern int cvmx_nand_read_id(int chip, uint64_t nand_address, uint64_t buffer_ad
  * @param buffer_length
  *               Length of the buffer. Usually this is 4 bytes
  *
- * @return Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ * @return Bytes read on success, a negative cvmx_nand_status_t error code on
+ *         failure
  */
-extern int cvmx_nand_read_param_page(int chip, uint64_t buffer_address, int buffer_length);
+extern int cvmx_nand_read_param_page(int chip, uint64_t buffer_address,
+				     int buffer_length);
 
 /**
- * Validate the ONFI parameter page and return a pointer to
- * the config values.
+ * Validate the ONFI parameter page and return a pointer to the config values.
  *
- * @param param_page Pointer to the raw NAND data returned after a parameter page read. It will
- *                   contain at least 3 copies of the parameter structure.
+ * @param param_page Pointer to the raw NAND data returned after a parameter
+ *                   page read.  It will contain at least 3 copies of the
+ *                   parameter structure.
  *
- * @return Pointer to a validated paramter page, or NULL if one couldn't be found.
+ * @return Pointer to a validated paramter page, or NULL if one couldn't be
+ *         found.
  */
 extern cvmx_nand_onfi_param_page_t *
-	cvmx_nand_onfi_process(cvmx_nand_onfi_param_page_t param_page[3]);
+cvmx_nand_onfi_process(cvmx_nand_onfi_param_page_t param_page[3]);
+
 /**
  * Get the status of the NAND flash
  *
@@ -679,11 +774,11 @@ extern int cvmx_nand_get_status(int chip);
 
 /**
  * Gets the specified feature number
- * 
+ *
  * @param chip     Chip select for NAND flash
  * @param feat_num Feature number to get
  * @param feature  P1 - P4 of the feature data
- * 
+ *
  * @return cvmx_nand_status_t error code
  */
 cvmx_nand_status_t cvmx_nand_get_feature(int chip, uint8_t feat_num,
@@ -691,11 +786,11 @@ cvmx_nand_status_t cvmx_nand_get_feature(int chip, uint8_t feat_num,
 
 /**
  * Sets the specified feature number
- * 
+ *
  * @param chip     Chip select for NAND flash
  * @param feat_num Feature number to get
  * @param feature  P1 - P4 of the feature data
- * 
+ *
  * @return cvmx_nand_status_t error code
  */
 cvmx_nand_status_t cvmx_nand_set_feature(int chip, uint8_t feat_num,
@@ -707,7 +802,8 @@ cvmx_nand_status_t cvmx_nand_set_feature(int chip, uint8_t feat_num,
  *
  * @param chip   Chip select for NAND flash
  *
- * @return Page size in bytes or a negative cvmx_nand_status_t error code on failure
+ * @return Page size in bytes or a negative cvmx_nand_status_t error code on
+ *         failure
  */
 extern int cvmx_nand_get_page_size(int chip);
 
@@ -725,7 +821,8 @@ extern int cvmx_nand_get_oob_size(int chip);
  *
  * @param chip   Chip select for NAND flash
  *
- * @return Numboer of pages in each block or a negative cvmx_nand_status_t error code on failure
+ * @return Numboer of pages in each block or a negative cvmx_nand_status_t
+ *         error code on failure
  */
 extern int cvmx_nand_get_pages_per_block(int chip);
 
@@ -734,7 +831,8 @@ extern int cvmx_nand_get_pages_per_block(int chip);
  *
  * @param chip   Chip select for NAND flash
  *
- * @return Number of blocks or a negative cvmx_nand_status_t error code on failure
+ * @return Number of blocks or a negative cvmx_nand_status_t error code on
+ *         failure
  */
 extern int cvmx_nand_get_blocks(int chip);
 
@@ -754,7 +852,8 @@ extern cvmx_nand_status_t cvmx_nand_reset(int chip);
  * @param block  pointer to 256 bytes of data
  * @param eccp   pointer to where 8 bytes of ECC data will be stored
  */
-extern void cvmx_nand_compute_boot_ecc(unsigned char *block, unsigned char *eccp);
+extern void cvmx_nand_compute_boot_ecc(unsigned char *block,
+				       unsigned char *eccp);
 
 extern int cvmx_nand_correct_boot_ecc(uint8_t *block);
 #ifdef	__cplusplus
diff --git a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
index ff2d96c..27c81d3 100644
--- a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
@@ -447,18 +447,18 @@ union cvmx_oclax_cdhx_ctl {
 	uint64_t dis_stamp                    : 1;  /**< Remove time stamps from data stream. */
 	uint64_t cap_ctl                      : 4;  /**< Minterms that will cause data to be captured. These minterms are the four inputs to a 4-1
                                                          mux selected by PLA1 and 0. The output is thus calulated from the equation:
-                                                         fsmcap0 = OCLA(0..4)_FSM(0)_STATE[state0][CAP]
-                                                         fsmcap1 = OCLA(0..4)_FSM(1)_STATE[state1][CAP]
+                                                         fsmcap0 = OCLA(0..4)_FSM(0)_STATE[state0][CAP].
+                                                         fsmcap1 = OCLA(0..4)_FSM(1)_STATE[state1][CAP].
                                                          out = (    (<3> & fsmcap0 & fsmcap0)
                                                          || (<2> & fsmcap1 & !fsmcap0)
                                                          || (<1> & !fsmcap1 & fsmcap0)
-                                                         || (<0> & !fsmcap1 & !fsmcap0))
+                                                         || (<0> & !fsmcap1 & !fsmcap0)).
                                                          Common examples:
-                                                         0x0 = No capture
-                                                         0x2 = Capture when fsmcap0 requests capture
-                                                         0x4 = Capture when fsmcap1 requests capture
-                                                         0x6 = Capture on fsmcap0 | fsmcap1
-                                                         0x8 = Capture on fsmcap0 & fsmcap1
+                                                         0x0 = No capture.
+                                                         0x2 = Capture when fsmcap0 requests capture.
+                                                         0x4 = Capture when fsmcap1 requests capture.
+                                                         0x6 = Capture on fsmcap0 | fsmcap1.
+                                                         0x8 = Capture on fsmcap0 & fsmcap1.
                                                          0xF = Always capture. */
 #else
 	uint64_t cap_ctl                      : 4;
@@ -825,7 +825,9 @@ union cvmx_oclax_matx_maskx {
 	struct cvmx_oclax_matx_maskx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t mask                         : 36; /**< Bitmask of which bits in OCLA(0..4)_MAT(0..3)_VALUE(0..1) are to be compared. */
+	uint64_t mask                         : 36; /**< Bitmask of which bits in OCLA(0..4)_MAT(0..3)_VALUE(0..1) are to be compared.
+                                                         0 = Do not compare bit.
+                                                         1 = Compare bit. */
 #else
 	uint64_t mask                         : 36;
 	uint64_t reserved_36_63               : 28;
@@ -864,7 +866,8 @@ union cvmx_oclax_matx_valuex {
 	struct cvmx_oclax_matx_valuex_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t mask                         : 36; /**< Data value to compare against when corresponding bits of OCLA(0..4)_MAT(0..3)_MASK(0..1) are set. */
+	uint64_t mask                         : 36; /**< Data value to compare against when corresponding bits of OCLA(0..4)_MAT(0..3)_MASK(0..1)
+                                                         are set. Value may be updated with OCLA(0..4)_FSM(0..1)_STATE(0..15)[SET_VAL]. */
 #else
 	uint64_t mask                         : 36;
 	uint64_t reserved_36_63               : 28;
diff --git a/arch/mips/include/asm/octeon/cvmx-ocx-defs.h b/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
index f3b26d3..e3438e2 100644
--- a/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
@@ -837,33 +837,33 @@ static inline uint64_t CVMX_OCX_WIN_WR_DATA_FUNC(void)
 /**
  * cvmx_ocx_com_bist_status
  *
- * Contains Status from last Memory BIST for all RX FIFO Memories.  BIST status for TX FIFO
- * Memories
- * and REPLAY Memories are organized by link and are located in OCX_TLK(0..2)_BIST_STATUS.
+ * Contains status from last memory BIST for all RX FIFO memories. BIST status for TX FIFO
+ * memories and REPLAY Memories are organized by link and are located in
+ * OCX_TLK(0..2)_BIST_STATUS.
  */
 union cvmx_ocx_com_bist_status {
 	uint64_t u64;
 	struct cvmx_ocx_com_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t status                       : 36; /**< 35:34 - Link 2 VC4/VC2      RX FIFOs
-                                                         - 33:32 - Link 2 VC10/VC8/VC6 RX FIFOs
-                                                         - 31:30 - Link 1 VC4/VC2      RX FIFOs
-                                                         - 29:28 - Link 1 VC10/VC8/VC6 RX FIFOs
-                                                         - 27:26 - Link 0 VC4/VC2      RX FIFOs
-                                                         - 25:24 - Link 0 VC10/VC8/VC6 RX FIFOs
-                                                         - 23:22 - Link 2 VC12         RX FIFOs
-                                                         - 21:20 - Link 2 VC1/VC0      RX FIFOs
-                                                         - 19:18 - Link 2 VC5/VC3      RX FIFOs
-                                                         - 17:16 - Link 2 VC11/VC9/VC7 RX FIFOs
-                                                         - 15:14 - Link 1 VC12         RX FIFOs
-                                                         - 13:12 - Link 1 VC1/VC0      RX FIFOs
-                                                         - 11:10 - Link 1 VC5/VC3      RX FIFOs
-                                                         - 9: 8 - Link 1 VC11/VC9/VC7 RX FIFOs
-                                                         - 7: 6 - Link 0 VC12         RX FIFOs
-                                                         - 5: 4 - Link 0 VC1/VC0      RX FIFOs
-                                                         - 3: 2 - Link 0 VC5/VC3      RX FIFOs
-                                                         - 1: 0 - Link 0 VC11/VC9/VC7 RX FIFOs */
+	uint64_t status                       : 36; /**< 35:34   - Link 2 VC4/VC2         RX FIFOs
+                                                          - 33:32   - Link 2 VC10/VC8/VC6    RX FIFOs
+                                                          - 31:30   - Link 1 VC4/VC2         RX FIFOs
+                                                          - 29:28   - Link 1 VC10/VC8/VC6    RX FIFOs
+                                                          - 27:26   - Link 0 VC4/VC2         RX FIFOs
+                                                          - 25:24   - Link 0 VC10/VC8/VC6    RX FIFOs
+                                                          - 23:22   - Link 2 VC12            RX FIFOs
+                                                          - 21:20   - Link 2 VC1/VC0         RX FIFOs
+                                                          - 19:18   - Link 2 VC5/VC3         RX FIFOs
+                                                          - 17:16   - Link 2 VC11/VC9/VC7    RX FIFOs
+                                                          - 15:14   - Link 1 VC12            RX FIFOs
+                                                          - 13:12   - Link 1 VC1/VC0         RX FIFOs
+                                                          - 11:10   - Link 1 VC5/VC3         RX FIFOs
+                                                         - 9:8   - Link 1 VC11/VC9/VC7    RX FIFOs
+                                                         - 7:6   - Link 0 VC12            RX FIFOs
+                                                         - 5:4   - Link 0 VC1/VC0         RX FIFOs
+                                                         - 3:2   - Link 0 VC5/VC3         RX FIFOs
+                                                         - 1:0   - Link 0 VC11/VC9/VC7    RX FIFOs */
 #else
 	uint64_t status                       : 36;
 	uint64_t reserved_36_63               : 28;
@@ -884,7 +884,8 @@ union cvmx_ocx_com_dual_sort {
 	uint64_t sort                         : 2;  /**< Sorting procedure for multiple links to same node:
                                                          00 = All to lowest link number.
                                                          01 = Split by top/bottom L2C buses. (top to lowest link number).
-                                                         1x = IOC 1st, IOR 2nd, Mem VCs to either based on most room in TX FIFOs. */
+                                                         10 = IOC 1st, IOR 2nd, Mem VCs to either based on most room in TX FIFOs.
+                                                         11 = Illegal */
 #else
 	uint64_t sort                         : 2;
 	uint64_t reserved_2_63                : 62;
@@ -924,7 +925,7 @@ union cvmx_ocx_com_int {
 	uint64_t win_rsp                      : 1;  /**< A response to a previous window request or core request has been received. A new command
                                                          may be issued. */
 	uint64_t reserved_24_47               : 24;
-	uint64_t rx_lane                      : 24; /**< SerDes RX lane interrupt. See OCX_LNE_STATUS[23..0] for more information. */
+	uint64_t rx_lane                      : 24; /**< SerDes RX lane interrupt. See OCX_LNE(0..23)_INT for more information. */
 #else
 	uint64_t rx_lane                      : 24;
 	uint64_t reserved_24_47               : 24;
@@ -952,7 +953,7 @@ union cvmx_ocx_com_linkx_ctl {
 	uint64_t reserved_9_63                : 55;
 	uint64_t loopback                     : 1;  /**< Reserved. INTERNAL: Diagnostic data loopback.Set to force outgoing link to inbound port.
                                                          All data and link credits are returned and appear to come from link partner. Typically
-                                                         SERDES should be disabled during this operation. */
+                                                         SerDes should be disabled during this operation. */
 	uint64_t reinit                       : 1;  /**< Reinitialize Link. Setting bit forces link back into init state and also sets DROP bit.
                                                          Bit must be cleared for link to operate normally. */
 	uint64_t gate                         : 1;  /**< Enable clock gating on this link to save power. */
@@ -962,7 +963,7 @@ union cvmx_ocx_com_linkx_ctl {
                                                          reinitialized. Cleared by software once pending link traffic is removed. (See
                                                          OCX_TLK[0..2]_FIFO[0..13]_CNT.) */
 	uint64_t up                           : 1;  /**< Link is operating normally. */
-	uint64_t valid                        : 1;  /**< Link has valid lanes and is exchanging information.  This bit will never be set if
+	uint64_t valid                        : 1;  /**< Link has valid lanes and is exchanging information. This bit will never be set if
                                                          OCX_LNK(0..2)_CFG[QLM_SELECT] is zero. */
 	uint64_t id                           : 2;  /**< This ID is used to sort traffic by link. If more than one link has the same value, the
                                                          OCX_COM_DUAL_SORT[SORT] field and traffic VC are used to choose a link. This field is only
@@ -1041,7 +1042,7 @@ union cvmx_ocx_com_link_timer {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_24_63               : 40;
 	uint64_t tout                         : 24; /**< Number of unacknowledged retry requests issued before link stops operation and
-                                                         OCX_LNK(0..2)_INT[STOP] is asserted. */
+                                                         OCX_COM_LINK(0..2)_INT[STOP] is asserted. */
 #else
 	uint64_t tout                         : 24;
 	uint64_t reserved_24_63               : 40;
@@ -1062,19 +1063,17 @@ union cvmx_ocx_com_node {
 	uint64_t fixed_pin                    : 1;  /**< The current value of the OCI_FIXED_ID pin. */
 	uint64_t fixed                        : 1;  /**< ID Valid associated with the chip. This register is used by the link initialization
                                                          software to help assign IDs and is transmitted over OCI. The FIXED field set during a cold
-                                                         reset to the value of the OCI_FIXED_ID pin. The value is also be readable in the
-                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT[2]] for each lane.
-                                                         The FIXED field of the link partner can be examined by locally reading the
-                                                         OCX_LNE(0..23)_STS_MSG[RX_META_DAT[2]] on each valid lane or remotely reading the
-                                                         OCX_COM_NODE[FIXED] on the link partner. */
+                                                         reset to the value of the OCI_FIXED_ID pin. The value is also readable in the
+                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT[2]] for each lane. The FIXED field of the link partner
+                                                         can be examined by locally reading the OCX_LNE(0..23)_STS_MSG[RX_META_DAT[2]] on each
+                                                         valid lane or remotely reading the OCX_COM_NODE[FIXED] on the link partner. */
 	uint64_t id                           : 2;  /**< Node ID associated with the chip. This register is used by the rest of the chip to
                                                          determine what traffic is transmitted over OCI. The value should not match the
                                                          OCX_COM_LINK(0..2)_CTL[ID] of any active link. The ID field is set during a cold reset to
-                                                         the value of the OCI_NODE_ID pins. The value is also be readable in the
-                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT[1:0]] for each lane.
-                                                         The ID field of the link partner can be examined by locally reading the
-                                                         OCX_LNE(0..23)_STS_MSG[RX_META_DAT[1:0]] on each valid lane or remotely reading the
-                                                         OCX_COM_NODE[ID] on the link partner. */
+                                                         the value of the OCI_NODE_ID pins. The value is also readable in the
+                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT[1:0]] for each lane. The ID field of the link partner
+                                                         can be examined by locally reading the OCX_LNE(0..23)_STS_MSG[RX_META_DAT[1:0]] on each
+                                                         valid lane or remotely reading the OCX_COM_NODE[ID] on the link partner. */
 #else
 	uint64_t id                           : 2;
 	uint64_t fixed                        : 1;
@@ -1257,9 +1256,8 @@ union cvmx_ocx_lnex_int {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
 	uint64_t disp_err                     : 1;  /**< RX disparity error encountered. */
-	uint64_t bad_64b67b                   : 1;  /**< Bad 64B/67B codeword encountered. Once the bad word reaches the burst control unit, as
-                                                         denoted by OCX_RXx_INT[LANE_BAD_WORD], it is tossed and all open packets will receive an
-                                                         error. */
+	uint64_t bad_64b67b                   : 1;  /**< Bad 64B/67B codeword encountered. Once the bad word reaches link, as
+                                                         denoted by OCX_COM_LINK(0..2)_INT[BAD_WORD], a retry handshake is initiated. */
 	uint64_t stat_cnt_ovfl                : 1;  /**< RX lane statistic counter overflow. */
 	uint64_t stat_msg                     : 1;  /**< Status bits for the link or a lane transitioned from a 1 (healthy) to a 0 (problem). */
 	uint64_t dskew_fifo_ovfl              : 1;  /**< RX deskew FIFO overflow occurred. */
@@ -1295,7 +1293,7 @@ union cvmx_ocx_lnex_int_en {
 	struct cvmx_ocx_lnex_int_en_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
-	uint64_t bad_64b67b                   : 1;  /**< Enable bit for Bad 64B/67B codeword encountered. */
+	uint64_t bad_64b67b                   : 1;  /**< Enable bit for bad 64B/67B codeword encountered. */
 	uint64_t stat_cnt_ovfl                : 1;  /**< Enable bit for RX lane statistic counter overflow. */
 	uint64_t stat_msg                     : 1;  /**< Enable bit for status bits for the link or a lane transitioned from a 1 (healthy) to a 0 (problem). */
 	uint64_t dskew_fifo_ovfl              : 1;  /**< Enable bit for RX deskew FIFO overflow occurred. */
@@ -1331,7 +1329,7 @@ union cvmx_ocx_lnex_stat00 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t ser_lock_loss_cnt            : 18; /**< Number of times the lane lost clock-data-recovery. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1. */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t ser_lock_loss_cnt            : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1350,7 +1348,7 @@ union cvmx_ocx_lnex_stat01 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t bdry_sync_loss_cnt           : 18; /**< Number of times a lane lost word boundary synchronization. Saturates. Interrupt on
-                                                         saturation if OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1. */
+                                                         saturation if OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t bdry_sync_loss_cnt           : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1369,7 +1367,7 @@ union cvmx_ocx_lnex_stat02 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t syncw_bad_cnt                : 18; /**< Number of bad synchronization words. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1. */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t syncw_bad_cnt                : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1388,7 +1386,7 @@ union cvmx_ocx_lnex_stat03 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t syncw_good_cnt               : 18; /**< Number of good synchronization words. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1. */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t syncw_good_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1407,7 +1405,7 @@ union cvmx_ocx_lnex_stat04 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t bad_64b67b_cnt               : 18; /**< Number of bad 64B/67B words, meaning bit 65 or 64 has been corrupted. Saturates. Interrupt
-                                                         on saturation if OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1. */
+                                                         on saturation if OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t bad_64b67b_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1426,7 +1424,7 @@ union cvmx_ocx_lnex_stat05 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_27_63               : 37;
 	uint64_t data_word_cnt                : 27; /**< Number of data words received. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1 */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t data_word_cnt                : 27;
 	uint64_t reserved_27_63               : 37;
@@ -1445,7 +1443,7 @@ union cvmx_ocx_lnex_stat06 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_27_63               : 37;
 	uint64_t cntl_word_cnt                : 27; /**< Number of control words received. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1 */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t cntl_word_cnt                : 27;
 	uint64_t reserved_27_63               : 37;
@@ -1464,7 +1462,7 @@ union cvmx_ocx_lnex_stat07 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t unkwn_word_cnt               : 18; /**< Number of unknown control words. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1 */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t unkwn_word_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1484,7 +1482,7 @@ union cvmx_ocx_lnex_stat08 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t scrm_sync_loss_cnt           : 18; /**< Number of times scrambler synchronization was lost (due to either 4 consecutive bad sync
                                                          words or 3 consecutive scrambler state mismatches). Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1 */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t scrm_sync_loss_cnt           : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1503,7 +1501,7 @@ union cvmx_ocx_lnex_stat09 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t scrm_match_cnt               : 18; /**< Number of scrambler state matches received. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1 */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t scrm_match_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1522,7 +1520,7 @@ union cvmx_ocx_lnex_stat10 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t skipw_good_cnt               : 18; /**< Number of good skip words. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1 */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t skipw_good_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1541,7 +1539,7 @@ union cvmx_ocx_lnex_stat11 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_27_63               : 37;
 	uint64_t crc32_err_cnt                : 27; /**< Number of errors in the lane CRC. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1 */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t crc32_err_cnt                : 27;
 	uint64_t reserved_27_63               : 37;
@@ -1560,7 +1558,7 @@ union cvmx_ocx_lnex_stat12 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_27_63               : 37;
 	uint64_t crc32_match_cnt              : 27; /**< Number of CRC32 matches received. Saturates. Interrupt on saturation if
-                                                         OCX_OLE_LNEx_INT_EN[STAT_CNT_OVFL]=1 */
+                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t crc32_match_cnt              : 27;
 	uint64_t reserved_27_63               : 37;
@@ -1578,7 +1576,8 @@ union cvmx_ocx_lnex_stat13 {
 	struct cvmx_ocx_lnex_stat13_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t trn_bad_cnt                  : 16; /**< N/A */
+	uint64_t trn_bad_cnt                  : 16; /**< Number of training frames received with an invalid control channel.
+                                                         Saturates. Interrupt on saturation if OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t trn_bad_cnt                  : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1596,7 +1595,8 @@ union cvmx_ocx_lnex_stat14 {
 	struct cvmx_ocx_lnex_stat14_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t trn_prbs_bad_cnt             : 16; /**< N/A */
+	uint64_t trn_prbs_bad_cnt             : 16; /**< Number of training frames received with a bad PRBS pattern.
+                                                         Saturates. Interrupt on saturation if OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t trn_prbs_bad_cnt             : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1614,7 +1614,7 @@ union cvmx_ocx_lnex_status {
 	struct cvmx_ocx_lnex_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t rx_trn_val                   : 1;  /**< The control channel of a link training was recieved without any errors. */
+	uint64_t rx_trn_val                   : 1;  /**< The control channel of a link training was received without any errors. */
 	uint64_t rx_scrm_sync                 : 1;  /**< RX scrambler synchronization status. One when synchronization achieved. */
 	uint64_t rx_bdry_sync                 : 1;  /**< RX word boundary sync status. One when synchronization achieved. */
 #else
@@ -1725,17 +1725,20 @@ union cvmx_ocx_lne_dbg {
 	uint64_t u64;
 	struct cvmx_ocx_lne_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_38_63               : 26;
+	uint64_t timeout                      : 24; /**< Number of core clocks (RCLKs) used by the bad lane timer. If this timer expires before all
+                                                         enabled lanes can be made ready, then any lane which is not ready is disabled via
+                                                         OCX_QLM(0..5)_CFG[SER_LANE_BAD]. For diagnostic use only. */
+	uint64_t reserved_38_39               : 2;
 	uint64_t frc_stats_ena                : 1;  /**< Enable FRC statistic counters. */
 	uint64_t rx_dis_psh_skip              : 1;  /**< When RX_DIS_PSH_SKIP=0, skip words are de-stripped. When RX_DIS_PSH_SKIP=1, skip words are
                                                          discarded in the lane logic. If the lane is in internal loopback mode, RX_DIS_PSH_SKIP is
                                                          ignored and skip words are always discarded in the lane logic. */
 	uint64_t rx_mfrm_len                  : 2;  /**< The quantity of data received on each lane including one sync word, scrambler state, diag
                                                          word, zero or more skip words, and the data payload.
-                                                         0 = 2048 words.
-                                                         1 = 1024 words.
-                                                         2 = 512 words.
-                                                         3 = 128 words. */
+                                                         0x0 = 2048 words.
+                                                         0x1 = 1024 words.
+                                                         0x2 = 512 words.
+                                                         0x3 = 128 words. */
 	uint64_t rx_dis_ukwn                  : 1;  /**< Disable normal response to unknown words. They are still logged but do not cause an error
                                                          to all open channels. */
 	uint64_t rx_dis_scram                 : 1;  /**< Disable lane scrambler. */
@@ -1745,10 +1748,10 @@ union cvmx_ocx_lne_dbg {
                                                          LANE_REV. */
 	uint64_t tx_mfrm_len                  : 2;  /**< The quantity of data sent on each lane including one sync word, scrambler state, diag
                                                          word, zero or more skip words, and the data payload.
-                                                         0 = 2048 words.
-                                                         1 = 1024 words.
-                                                         2 = 512 words.
-                                                         3 = 128 words. */
+                                                         0x0 = 2048 words.
+                                                         0x1 = 1024 words.
+                                                         0x2 = 512 words.
+                                                         0x3 = 128 words. */
 	uint64_t tx_dis_dispr                 : 1;  /**< Disparity disable. */
 	uint64_t tx_dis_scram                 : 1;  /**< Scrambler disable. */
 #else
@@ -1762,7 +1765,8 @@ union cvmx_ocx_lne_dbg {
 	uint64_t rx_mfrm_len                  : 2;
 	uint64_t rx_dis_psh_skip              : 1;
 	uint64_t frc_stats_ena                : 1;
-	uint64_t reserved_38_63               : 26;
+	uint64_t reserved_38_39               : 2;
+	uint64_t timeout                      : 24;
 #endif
 	} s;
 	struct cvmx_ocx_lne_dbg_s             cn78xx;
@@ -1808,6 +1812,8 @@ union cvmx_ocx_lnkx_cfg {
                                                          LINK 0 may not select QLM4, QLM5.
                                                          LINK 1 may not select QLM0, QLM1, QLM4, QLM5.
                                                          LINK 2 may not select QLM0, QLM1.
+                                                         LINK 2 may not select QLM2 or QLM3 when LINK1 selects any QLM.
+                                                         LINK 0 may not select QLM2 or QLM3 when LINK1 selects any QLM.
                                                          LINK 0 automatically selects QLM0 when QLM_MANUAL[0]=0
                                                          LINK 0 automatically selects QLM1 when QLM_MANUAL[1]=0
                                                          LINK 0 automatically selects QLM2 when QLM_MANUAL[2]=0 and OCX_QLM2_CFG.SER_LOCAL=0
@@ -1816,7 +1822,7 @@ union cvmx_ocx_lnkx_cfg {
                                                          LINK 2 automatically selects QLM3 when QLM_MANUAL[3]=0 and OCX_QLM3_CFG.SER_LOCAL=0
                                                          LINK 3 automatically selects QLM4 when QLM_MANUAL[4]=0
                                                          LINK 3 automatically selects QLM5 when QLM_MANUAL[5]=0
-                                                         NOTE:  A link with QLM_SELECT = 000000 is invalid and will never exchange traffic with the
+                                                         NOTE: A link with QLM_SELECT = 000000 is invalid and will never exchange traffic with the
                                                          link partner */
 	uint64_t reserved_10_31               : 22;
 	uint64_t lane_align_dis               : 1;  /**< Disable the RX lane alignment. */
@@ -1862,18 +1868,18 @@ union cvmx_ocx_pp_cmd {
                                                          0x1 = Load 2-bytes
                                                          0x2 = Load 4-bytes
                                                          0x3 = Load 8-bytes */
-	uint64_t ld_op                        : 1;  /**< Operation Type 0=Store 1=Load Operation. */
+	uint64_t ld_op                        : 1;  /**< Operation Type 0=Store 1=Load operation. */
 	uint64_t addr                         : 48; /**< The address used in both the load and store operations
                                                          <47:40> = NCB_ID
-                                                         <39:38> = 0, Not Used
+                                                         <39:38> = 0, Not used
                                                          <37:36> = OCI_ID
                                                          <35:0> = Address
                                                          When <47:43> == SLI & <42:40> == 0 bits <39:0> are:
-                                                         <39:38> = 0, Not Used
+                                                         <39:38> = 0, Not used
                                                          <37:36> = OCI_ID
-                                                         <35:32> = 0, Not Used
+                                                         <35:32> = 0, Not used
                                                          <31:24> = RSL_ID
-                                                         <23:0> = RSL Register Offset
+                                                         <23:0> = RSL register offset
                                                          Note: <2:0> are ignored in a store operation */
 #else
 	uint64_t addr                         : 48;
@@ -1957,9 +1963,9 @@ union cvmx_ocx_qlmx_cfg {
                                                          1 = TX with inversion. */
 	uint64_t reserved_1_2                 : 2;
 	uint64_t ser_local                    : 1;  /**< Auto initialization may set OCX_LNK0_CFG[QLM_SELECT<2>] = 1 only if
-                                                         OCX_QLM2_CFG[SER_LOCAL] = 1.
-                                                         Auto initialization may set OCX_LNK1_CFG[QLM_SELECT<2>] = 1 only if
                                                          OCX_QLM2_CFG[SER_LOCAL] = 0.
+                                                         Auto initialization may set OCX_LNK1_CFG[QLM_SELECT<2>] = 1 only if
+                                                         OCX_QLM2_CFG[SER_LOCAL] = 1.
                                                          Auto initialization may set OCX_LNK1_CFG[QLM_SELECT<3>] = 1 only if
                                                          OCX_QLM3_CFG[SER_LOCAL] = 1.
                                                          Auto initialization may set OCX_LNK2_CFG[QLM_SELECT<3>] = 1 only if
@@ -1970,7 +1976,9 @@ union cvmx_ocx_qlmx_cfg {
                                                          OCX_QLM4/5_CFG[SER_LOCAL] has no effect.
                                                          During a cold reset, initialized as follows:
                                                          OCX_QLM2_CFG.SER_LOCAL = pi_oci2_link1
-                                                         OCX_QLM3_CFG.SER_LOCAL = pi_oci3_link1 */
+                                                         OCX_QLM3_CFG.SER_LOCAL = pi_oci3_link1
+                                                         The combo of pi_oci2_link1=1 and pi_oci3_link1=0 is illegal.
+                                                         The combo of OCX_QLM2_CFG.SER_LOCAL=1 and OCX_QLM3_CFG.SER_LOCAL=0 is illegal. */
 #else
 	uint64_t ser_local                    : 1;
 	uint64_t reserved_1_2                 : 2;
@@ -2068,9 +2076,8 @@ union cvmx_ocx_rlkx_enables {
 	struct cvmx_ocx_rlkx_enables_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t mcd                          : 1;  /**< Master enable for all inbound MCD bits. This bit should always be enabled by software once
-                                                         any
-                                                         Authentik validation has occured and before any MCD traffic is generated.  MCD traffic is
+	uint64_t mcd                          : 1;  /**< Master enable for all inbound MCD bits. This bit must be enabled by software. once any
+                                                         Authentik validation has occured and before any MCD traffic is generated. MCD traffic is
                                                          typically controlled by the OCX_TLK(0..2)_MCD_CTL register. */
 	uint64_t m_req                        : 1;  /**< Master enable for all inbound memory requests. This bit is typically set at reset but is
                                                          cleared when operating in Authentik mode and must be enabled by software. */
@@ -2101,8 +2108,8 @@ union cvmx_ocx_rlkx_fifox_cnt {
 	struct cvmx_ocx_rlkx_fifox_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t count                        : 16; /**< RX FIFO count of 64-bit words to send to core.  VC13 traffic is used immediately so
-                                                         the FIFO count is always 0. (see OCX_RLK(0..2)_LNK_DATA) */
+	uint64_t count                        : 16; /**< RX FIFO count of 64-bit words to send to core. VC13 traffic is used immediately so the
+                                                         FIFO count is always 0. (see OCX_RLK(0..2)_LNK_DATA). */
 #else
 	uint64_t count                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2137,10 +2144,9 @@ typedef union cvmx_ocx_rlkx_lnk_data cvmx_ocx_rlkx_lnk_data_t;
 /**
  * cvmx_ocx_rlk#_mcd_ctl
  *
- * This debug register captures which new MCD bits have been received from the link partner.  The
- * MCD bits are
- * received when the both the OCX_RLK(0..2)_ENABLES[MCD] bit is set and the MCD was not
- * previously transmitted.
+ * This debug register captures which new MCD bits have been received from the link partner. The
+ * MCD bits are received when the both the OCX_RLK(0..2)_ENABLES[MCD] bit is set and the MCD was
+ * not previously transmitted.
  */
 union cvmx_ocx_rlkx_mcd_ctl {
 	uint64_t u64;
@@ -2161,9 +2167,8 @@ typedef union cvmx_ocx_rlkx_mcd_ctl cvmx_ocx_rlkx_mcd_ctl_t;
 /**
  * cvmx_ocx_tlk#_bist_status
  *
- * Contains Status from last Memory BIST for all TX FIFO Memories and REPLAY Memories in this
- * link.
- * RX FIFO Status can be found in OCX_COM_BIST_STATUS
+ * Contains status from last memory BIST for all TX FIFO memories and REPLAY memories in this
+ * link. RX FIFO status can be found in OCX_COM_BIST_STATUS.
  */
 union cvmx_ocx_tlkx_bist_status {
 	uint64_t u64;
@@ -2256,7 +2261,7 @@ union cvmx_ocx_tlkx_lnk_vcx_cnt {
 	struct cvmx_ocx_tlkx_lnk_vcx_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t count                        : 16; /**< Link VC credits available for use.  VC13 always reads 1 since credits are not required. */
+	uint64_t count                        : 16; /**< Link VC credits available for use. VC13 always reads 1 since credits are not required. */
 #else
 	uint64_t count                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2271,7 +2276,7 @@ typedef union cvmx_ocx_tlkx_lnk_vcx_cnt cvmx_ocx_tlkx_lnk_vcx_cnt_t;
  *
  * This register controls which MCD bits are transported via the link. For proper operation
  * only one link must be enabled in both directions between each pair of link partners.
- * Internal:  If N chips are connected over OCX, N-1 links should have MCD enabled.
+ * INTERNAL: If N chips are connected over OCX, N-1 links should have MCD enabled.
  * A single "central" chip should connect all MCD buses and have a single MCD enabled link
  * to each of the other chips.  No MCD enabled links should connect between chips that don't
  * include the "central" chip.
@@ -2299,7 +2304,7 @@ union cvmx_ocx_tlkx_rtn_vcx_cnt {
 	struct cvmx_ocx_tlkx_rtn_vcx_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t count                        : 16; /**< Link VC credits to return.  VC13 always reads 0 since credits are never returned. */
+	uint64_t count                        : 16; /**< Link VC credits to return. VC13 always reads 0 since credits are never returned. */
 #else
 	uint64_t count                        : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2339,7 +2344,7 @@ union cvmx_ocx_tlkx_stat_data_cnt {
 	uint64_t u64;
 	struct cvmx_ocx_tlkx_stat_data_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t count                        : 64; /**< Number of Data blocks transferred over the OCI Link while OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+	uint64_t count                        : 64; /**< Number of data blocks transferred over the OCI Link while OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2445,7 +2450,7 @@ union cvmx_ocx_tlkx_stat_sync_cnt {
 	uint64_t u64;
 	struct cvmx_ocx_tlkx_stat_sync_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t count                        : 64; /**< Number of sync (control) blocks transferred over the OCI Link while
+	uint64_t count                        : 64; /**< Number of sync (control) blocks transferred over the OCI link while
                                                          OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
 #else
 	uint64_t count                        : 64;
@@ -2463,7 +2468,7 @@ union cvmx_ocx_tlkx_stat_vcx_cmd {
 	struct cvmx_ocx_tlkx_stat_vcx_cmd_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t count                        : 64; /**< Number of commands on this VC that have been transfered over the OCI link while
-                                                         OCX_TLK(a)_STAT_CTL[ENABLE] has been set.  For VCs 6 thru 13 the number of commands is
+                                                         OCX_TLK(a)_STAT_CTL[ENABLE] has been set. For VCs 6 thru 13 the number of commands is
                                                          equal to the number of packets. */
 #else
 	uint64_t count                        : 64;
@@ -2571,18 +2576,18 @@ union cvmx_ocx_win_cmd {
                                                          0x1 = Load 2-bytes
                                                          0x2 = Load 4-bytes
                                                          0x3 = Load 8-bytes */
-	uint64_t ld_op                        : 1;  /**< Operation Type 0=Store 1=Load Operation. */
+	uint64_t ld_op                        : 1;  /**< Operation Type 0=Store 1=Load operation. */
 	uint64_t addr                         : 48; /**< The address used in both the load and store operations
                                                          <47:40> = NCB_ID
-                                                         <39:38> = 0, Not Used
+                                                         <39:38> = 0, Not used
                                                          <37:36> = OCI_ID
                                                          <35:0> = Address
                                                          When <47:43> == SLI & <42:40> == 0 bits <39:0> are:
-                                                         <39:38> = 0, Not Used
+                                                         <39:38> = 0, Not used
                                                          <37:36> = OCI_ID
-                                                         <35:32> = 0, Not Used
+                                                         <35:32> = 0, Not used
                                                          <31:24> = RSL_ID
-                                                         <23:0> = RSL Register Offset
+                                                         <23:0> = RSL register offset
                                                          Note: <2:0> are ignored in a store operation */
 #else
 	uint64_t addr                         : 48;
diff --git a/arch/mips/include/asm/octeon/cvmx-packet.h b/arch/mips/include/asm/octeon/cvmx-packet.h
index 3ab2fd1..fb9e3af 100644
--- a/arch/mips/include/asm/octeon/cvmx-packet.h
+++ b/arch/mips/include/asm/octeon/cvmx-packet.h
@@ -42,7 +42,7 @@
  *
  * Packet buffer defines.
  *
- * <hr>$Revision: 83289 $<hr>
+ * <hr>$Revision: 93476 $<hr>
  *
  */
 
@@ -82,6 +82,7 @@ union cvmx_buf_ptr {
 		uint64_t i:1;
 #endif
 	} s;
+#if 0
 	struct {
 #ifdef __BIG_ENDIAN_BITFIELD
 		uint64_t size:16;
@@ -98,10 +99,31 @@ union cvmx_buf_ptr {
 		uint64_t size:16;
 #endif
 	} s_cn78xx;
+#endif
 };
 
 typedef union cvmx_buf_ptr cvmx_buf_ptr_t;
 
+typedef	union {
+	uint64_t u64;
+	struct cvmx_buf_ptr_pki_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t size:16;
+		/**< The size of the segment pointed to by addr (in bytes) */
+		uint64_t packet_outside_wqe:1;
+		/**< sets is packet is not stored in same buffer as WQE*/
+		uint64_t rsvd0:5;
+		uint64_t addr:42;
+		/**< Pointer to the first byte of the data, NOT buffer */
+#else
+		uint64_t addr:42;
+		uint64_t rsvd0:5;
+		uint64_t packet_outside_wqe:1;
+		uint64_t size:16;
+#endif
+	} s_cn78xx;
+} cvmx_buf_ptr_pki_t;
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-pcie.h b/arch/mips/include/asm/octeon/cvmx-pcie.h
index daa4222..4a85ae5 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcie.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcie.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 88161 $<hr>
+ * <hr>$Revision: 93533 $<hr>
  */
 
 #ifndef __CVMX_PCIE_H__
@@ -56,12 +56,16 @@ extern "C" {
 
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
+#elif defined(__U_BOOT__)
+#include <asm/arch/cvmx.h>
 #else
 #include <cvmx.h>
 #endif
 
-#define CVMX_PCIE_MAX_PORTS	3
-#define CVMX_PCIE_PORTS		(OCTEON_IS_OCTEON3() ? CVMX_PCIE_MAX_PORTS : 2)
+#define CVMX_PCIE_MAX_PORTS	4
+#define CVMX_PCIE_PORTS		(OCTEON_IS_MODEL(OCTEON_CN78XX) 	\
+				  ? CVMX_PCIE_MAX_PORTS 		\
+				   : (OCTEON_IS_MODEL(OCTEON_CN70XX) ? 3 : 2))
 
 /*
  * The physical memory base mapped by BAR1.  256MB at the end of the
@@ -352,6 +356,15 @@ int cvmx_pcie_ep_initialize(int pcie_port);
  */
 void cvmx_pcie_wait_for_pending(int pcie_port);
 
+/**
+ * Returns if a PCIe port is in host or target mode.
+ *
+ * @param pcie_port PCIe port number (PEM number)
+ *
+ * @return 0 if PCIe port is in target mode, !0 if in host mode.
+ */
+int cvmx_pcie_is_host_mode(int pcie_port);
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
index fbdbbaf..bc3054d 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
@@ -694,15 +694,15 @@ static inline uint64_t CVMX_PCIEEPVFX_CFG517(unsigned long block_id)
 /**
  * cvmx_pcieepvf#_cfg000
  *
- * PCIE_CFG000 = First 32-bits of PCIE type 0 config space (Device ID and Vendor ID Register)
+ * This register contains the first 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg000 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg000_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t devid                        : 16; /**< Device ID */
-	uint32_t vendid                       : 16; /**< Vendor ID */
+	uint32_t devid                        : 16; /**< Device ID. */
+	uint32_t vendid                       : 16; /**< Vendor ID. */
 #else
 	uint32_t vendid                       : 16;
 	uint32_t devid                        : 16;
@@ -715,47 +715,37 @@ typedef union cvmx_pcieepvfx_cfg000 cvmx_pcieepvfx_cfg000_t;
 /**
  * cvmx_pcieepvf#_cfg001
  *
- * PCIE_CFG001 = Second 32-bits of PCIE type 0 config space (Command/Status Register)
+ * This register contains the second 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg001 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg001_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t dpe                          : 1;  /**< Detected Parity Error */
-	uint32_t sse                          : 1;  /**< Signaled System Error */
-	uint32_t rma                          : 1;  /**< Received Master Abort */
-	uint32_t rta                          : 1;  /**< Received Target Abort */
-	uint32_t sta                          : 1;  /**< Signaled Target Abort */
-	uint32_t devt                         : 2;  /**< DEVSEL Timing
-                                                         Not applicable for PCI Express. Hardwired to 0. */
-	uint32_t mdpe                         : 1;  /**< Master Data Parity Error */
-	uint32_t fbb                          : 1;  /**< Fast Back-to-Back Capable
-                                                         Not applicable for PCI Express. Hardwired to 0. */
+	uint32_t dpe                          : 1;  /**< Detected parity error. */
+	uint32_t sse                          : 1;  /**< Signaled system error. */
+	uint32_t rma                          : 1;  /**< Received master abort. */
+	uint32_t rta                          : 1;  /**< Received target abort. */
+	uint32_t sta                          : 1;  /**< Signaled target abort. */
+	uint32_t devt                         : 2;  /**< DEVSEL timing. Not applicable for PCI Express. Hardwired to 0x0. */
+	uint32_t mdpe                         : 1;  /**< Master data parity error. */
+	uint32_t fbb                          : 1;  /**< Fast back-to-back capable. Not applicable for PCI Express. Hardwired to 0. */
 	uint32_t reserved_22_22               : 1;
-	uint32_t m66                          : 1;  /**< 66 MHz Capable
-                                                         Not applicable for PCI Express. Hardwired to 0. */
-	uint32_t cl                           : 1;  /**< Capabilities List
-                                                         Indicates presence of an extended capability item.
-                                                         Hardwired to 1. */
-	uint32_t i_stat                       : 1;  /**< INTx Status */
+	uint32_t m66                          : 1;  /**< 66 MHz capable. Not applicable for PCI Express. Hardwired to 0. */
+	uint32_t cl                           : 1;  /**< Capabilities list. Indicates presence of an extended capability item. Hardwired to 1. */
+	uint32_t i_stat                       : 1;  /**< INTx status. */
 	uint32_t reserved_11_18               : 8;
-	uint32_t i_dis                        : 1;  /**< INTx Assertion Disable */
-	uint32_t fbbe                         : 1;  /**< Fast Back-to-Back Enable
-                                                         Not applicable for PCI Express. Must be hardwired to 0. */
-	uint32_t see                          : 1;  /**< SERR# Enable */
-	uint32_t ids_wcc                      : 1;  /**< IDSEL Stepping/Wait Cycle Control
-                                                         Not applicable for PCI Express. Must be hardwired to 0 */
-	uint32_t per                          : 1;  /**< Parity Error Response */
-	uint32_t vps                          : 1;  /**< VGA Palette Snoop
-                                                         Not applicable for PCI Express. Must be hardwired to 0. */
-	uint32_t mwice                        : 1;  /**< Memory Write and Invalidate
-                                                         Not applicable for PCI Express. Must be hardwired to 0. */
-	uint32_t scse                         : 1;  /**< Special Cycle Enable
-                                                         Not applicable for PCI Express. Must be hardwired to 0. */
-	uint32_t me                           : 1;  /**< Bus Master Enable */
-	uint32_t msae                         : 1;  /**< Memory Space Enable */
-	uint32_t isae                         : 1;  /**< I/O Space Enable */
+	uint32_t i_dis                        : 1;  /**< INTx assertion disable. */
+	uint32_t fbbe                         : 1;  /**< Fast back-to-back transaction enable. Not applicable for PCI Express. Must be hardwired to 0. */
+	uint32_t see                          : 1;  /**< SERR# enable. */
+	uint32_t ids_wcc                      : 1;  /**< IDSEL stepping/wait cycle control. Not applicable for PCI Express. Must be hardwired to 0. */
+	uint32_t per                          : 1;  /**< Parity error response. */
+	uint32_t vps                          : 1;  /**< VGA palette snoop. */
+	uint32_t mwice                        : 1;  /**< Memory write & invalidate command enable. Not applicable for PCI Express. Must be hardwired to 0. */
+	uint32_t scse                         : 1;  /**< Special cycle snooping enable. Not applicable for PCI Express. Must be hardwired to 0. */
+	uint32_t me                           : 1;  /**< Bus master enable. */
+	uint32_t msae                         : 1;  /**< Memory space access enable. */
+	uint32_t isae                         : 1;  /**< I/O space access enable. */
 #else
 	uint32_t isae                         : 1;
 	uint32_t msae                         : 1;
@@ -790,17 +780,17 @@ typedef union cvmx_pcieepvfx_cfg001 cvmx_pcieepvfx_cfg001_t;
 /**
  * cvmx_pcieepvf#_cfg002
  *
- * PCIE_CFG002 = Third 32-bits of PCIE type 0 config space (Revision ID/Class Code Register)
+ * This register contains the third 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg002 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg002_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t bcc                          : 8;  /**< Base Class Code */
-	uint32_t sc                           : 8;  /**< Subclass Code */
-	uint32_t pi                           : 8;  /**< Programming Interface */
-	uint32_t rid                          : 8;  /**< Revision ID */
+	uint32_t bcc                          : 8;  /**< Base class code. */
+	uint32_t sc                           : 8;  /**< Subclass code. */
+	uint32_t pi                           : 8;  /**< Programming interface. */
+	uint32_t rid                          : 8;  /**< Revision ID. */
 #else
 	uint32_t rid                          : 8;
 	uint32_t pi                           : 8;
@@ -815,24 +805,21 @@ typedef union cvmx_pcieepvfx_cfg002 cvmx_pcieepvfx_cfg002_t;
 /**
  * cvmx_pcieepvf#_cfg003
  *
- * PCIE_CFG003 = Fourth 32-bits of PCIE type 0 config space (Cache Line Size/Master Latency
- * Timer/Header Type Register/BIST Register)
+ * This register contains the fourth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg003 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg003_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t bist                         : 8;  /**< The BIST register functions are not supported.
-                                                         All 8 bits of the BIST register are hardwired to 0. */
-	uint32_t mfd                          : 1;  /**< Multi Function Device */
-	uint32_t chf                          : 7;  /**< Configuration Header Format
-                                                         Hardwired to 0 for type 0. */
-	uint32_t lt                           : 8;  /**< Master Latency Timer
-                                                         Not applicable for PCI Express, hardwired to 0. */
-	uint32_t cls                          : 8;  /**< Cache Line Size
-                                                         The Cache Line Size register is RW for legacy compatibility
-                                                         purposes and is not applicable to PCI Express device
-                                                         functionality. */
+	uint32_t bist                         : 8;  /**< The BIST register functions are not supported. All 8 bits of the BIST register are
+                                                         hardwired to 0x0. */
+	uint32_t mfd                          : 1;  /**< Multi function device. */
+	uint32_t chf                          : 7;  /**< Configuration header format. Hardwired to 0x0 for type 0. */
+	uint32_t lt                           : 8;  /**< Master latency timer. Not applicable for PCI Express, hardwired to 0x0. */
+	uint32_t cls                          : 8;  /**< Cache line size. The cache line size register is R/W for legacy compatibility purposes and
+                                                         is not applicable to PCI Express device functionality. Writing to the cache line size
+                                                         register does not impact functionality of the PCI Express bus. */
 #else
 	uint32_t cls                          : 8;
 	uint32_t lt                           : 8;
@@ -848,7 +835,7 @@ typedef union cvmx_pcieepvfx_cfg003 cvmx_pcieepvfx_cfg003_t;
 /**
  * cvmx_pcieepvf#_cfg004
  *
- * PCIE_CFG004 = Fifth 32-bits of PCIE type 0 config space (Base Address Register 0 - Low)
+ * This register contains the fifth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg004 {
@@ -867,7 +854,7 @@ typedef union cvmx_pcieepvfx_cfg004 cvmx_pcieepvfx_cfg004_t;
 /**
  * cvmx_pcieepvf#_cfg005
  *
- * PCIE_CFG005 = Sixth 32-bits of PCIE type 0 config space (Base Address Register 0 - High)
+ * This register contains the sixth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg005 {
@@ -886,7 +873,7 @@ typedef union cvmx_pcieepvfx_cfg005 cvmx_pcieepvfx_cfg005_t;
 /**
  * cvmx_pcieepvf#_cfg006
  *
- * PCIE_CFG006 = Seventh 32-bits of PCIE type 0 config space (Base Address Register 1 - Low)
+ * This register contains the seventh 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg006 {
@@ -905,7 +892,7 @@ typedef union cvmx_pcieepvfx_cfg006 cvmx_pcieepvfx_cfg006_t;
 /**
  * cvmx_pcieepvf#_cfg007
  *
- * PCIE_CFG007 = Eighth 32-bits of PCIE type 0 config space (Base Address Register 1 - High)
+ * This register contains the eighth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg007 {
@@ -924,7 +911,7 @@ typedef union cvmx_pcieepvfx_cfg007 cvmx_pcieepvfx_cfg007_t;
 /**
  * cvmx_pcieepvf#_cfg008
  *
- * PCIE_CFG008 = Ninth 32-bits of PCIE type 0 config space (Base Address Register 2 - Low)
+ * This register contains the ninth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg008 {
@@ -943,7 +930,7 @@ typedef union cvmx_pcieepvfx_cfg008 cvmx_pcieepvfx_cfg008_t;
 /**
  * cvmx_pcieepvf#_cfg009
  *
- * PCIE_CFG009 = Tenth 32-bits of PCIE type 0 config space (Base Address Register 2 - High)
+ * This register contains the tenth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg009 {
@@ -962,14 +949,14 @@ typedef union cvmx_pcieepvfx_cfg009 cvmx_pcieepvfx_cfg009_t;
 /**
  * cvmx_pcieepvf#_cfg010
  *
- * PCIE_CFG010 = Eleventh 32-bits of PCIE type 0 config space (CardBus CIS Pointer Register)
+ * This register contains the eleventh 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg010 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg010_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t cisp                         : 32; /**< CardBus CIS Pointer */
+	uint32_t cisp                         : 32; /**< CardBus CIS pointer. */
 #else
 	uint32_t cisp                         : 32;
 #endif
@@ -981,17 +968,15 @@ typedef union cvmx_pcieepvfx_cfg010 cvmx_pcieepvfx_cfg010_t;
 /**
  * cvmx_pcieepvf#_cfg011
  *
- * PCIE_CFG011 = Twelfth 32-bits of PCIE type 0 config space (Subsystem ID and Subsystem Vendor
- * ID Register)
+ * This register contains the twelfth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg011 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg011_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t ssid                         : 16; /**< Subsystem ID
-                                                         Assigned by PCI-SIG */
-	uint32_t ssvid                        : 16; /**< Subsystem Vendor ID
-                                                         Assigned by PCI-SIG */
+	uint32_t ssid                         : 16; /**< Subsystem ID. Assigned by PCI-SIG. */
+	uint32_t ssvid                        : 16; /**< Subsystem vendor ID. Assigned by PCI-SIG. */
 #else
 	uint32_t ssvid                        : 16;
 	uint32_t ssid                         : 16;
@@ -1004,16 +989,16 @@ typedef union cvmx_pcieepvfx_cfg011 cvmx_pcieepvfx_cfg011_t;
 /**
  * cvmx_pcieepvf#_cfg012
  *
- * PCIE_CFG012 = Thirteenth 32-bits of PCIE type 0 config space (Expansion ROM Base Address Register)
+ * This register contains the thirteenth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg012 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg012_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t eraddr                       : 16; /**< Expansion ROM Address */
+	uint32_t eraddr                       : 16; /**< Expansion ROM address. */
 	uint32_t reserved_1_15                : 15;
-	uint32_t er_en                        : 1;  /**< Expansion ROM Enable */
+	uint32_t er_en                        : 1;  /**< Expansion ROM enable. */
 #else
 	uint32_t er_en                        : 1;
 	uint32_t reserved_1_15                : 15;
@@ -1027,7 +1012,7 @@ typedef union cvmx_pcieepvfx_cfg012 cvmx_pcieepvfx_cfg012_t;
 /**
  * cvmx_pcieepvf#_cfg013
  *
- * PCIE_CFG013 = Fourteenth 32-bits of PCIE type 0 config space (Capability Pointer Register)
+ * This register contains the fourteenth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg013 {
@@ -1035,8 +1020,7 @@ union cvmx_pcieepvfx_cfg013 {
 	struct cvmx_pcieepvfx_cfg013_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_8_31                : 24;
-	uint32_t cp                           : 8;  /**< First Capability Pointer.
-                                                         Points to the PCI Express Capability Pointer structure (VF's) */
+	uint32_t cp                           : 8;  /**< First capability pointer. Points to the PCI Express Capability Pointer structure (VF's). */
 #else
 	uint32_t cp                           : 8;
 	uint32_t reserved_8_31                : 24;
@@ -1049,17 +1033,17 @@ typedef union cvmx_pcieepvfx_cfg013 cvmx_pcieepvfx_cfg013_t;
 /**
  * cvmx_pcieepvf#_cfg015
  *
- * PCIE_CFG015 = Sixteenth 32-bits of PCIE type 0 config space (Interrupt Line Register/Interrupt
- * Pin/Bridge Control Register)
+ * This register contains the sixteenth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg015 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg015_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t ml                           : 8;  /**< Maximum Latency     (Hardwired to 0) */
-	uint32_t mg                           : 8;  /**< Minimum Grant       (Hardwired to 0) */
-	uint32_t inta                         : 8;  /**< Interrupt Pin */
-	uint32_t il                           : 8;  /**< Interrupt Line */
+	uint32_t ml                           : 8;  /**< Maximum latency (hardwired to 0x0). */
+	uint32_t mg                           : 8;  /**< Minimum grant (hardwired to 0x0). */
+	uint32_t inta                         : 8;  /**< Interrupt pin. */
+	uint32_t il                           : 8;  /**< Interrupt line. */
 #else
 	uint32_t il                           : 8;
 	uint32_t inta                         : 8;
@@ -1074,22 +1058,20 @@ typedef union cvmx_pcieepvfx_cfg015 cvmx_pcieepvfx_cfg015_t;
 /**
  * cvmx_pcieepvf#_cfg028
  *
- * PCIE_CFG028 = Twenty-ninth 32-bits of PCIE type 0 config space
- * (PCI Express Capabilities List Register/
- * PCI Express Capabilities Register)
+ * This register contains the twenty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg028 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg028_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_30_31               : 2;
-	uint32_t imn                          : 5;  /**< Interrupt Message Number */
-	uint32_t si                           : 1;  /**< Slot Implemented */
-	uint32_t dpt                          : 4;  /**< Device Port Type */
-	uint32_t pciecv                       : 4;  /**< PCI Express Capability Version */
-	uint32_t ncp                          : 8;  /**< Next Capability Pointer
-                                                         Points to the MSI-X Capabilities by default, */
-	uint32_t pcieid                       : 8;  /**< PCIE Capability ID */
+	uint32_t imn                          : 5;  /**< Interrupt message number. */
+	uint32_t si                           : 1;  /**< Slot implemented. */
+	uint32_t dpt                          : 4;  /**< Device port type. */
+	uint32_t pciecv                       : 4;  /**< PCI Express capability version. */
+	uint32_t ncp                          : 8;  /**< Next capability pointer. Points to the MSI-X capabilities by default. */
+	uint32_t pcieid                       : 8;  /**< PCI Express capability ID. */
 #else
 	uint32_t pcieid                       : 8;
 	uint32_t ncp                          : 8;
@@ -1107,7 +1089,7 @@ typedef union cvmx_pcieepvfx_cfg028 cvmx_pcieepvfx_cfg028_t;
 /**
  * cvmx_pcieepvf#_cfg029
  *
- * PCIE_CFG029 = Thirtieth 32-bits of PCIE type 0 config space (Device Capabilities Register)
+ * This register contains the thirtieth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepvfx_cfg029 {
@@ -1115,20 +1097,17 @@ union cvmx_pcieepvfx_cfg029 {
 	struct cvmx_pcieepvfx_cfg029_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_29_31               : 3;
-	uint32_t flr_cap                      : 1;  /**< Function Level Reset Capable
-                                                         o 1 for SRIOV core */
-	uint32_t cspls                        : 2;  /**< Captured Slot Power Limit Scale
-                                                         From Message from RC, upstream port only. */
-	uint32_t csplv                        : 8;  /**< Captured Slot Power Limit Value
-                                                         From Message from RC, upstream port only. */
+	uint32_t flr_cap                      : 1;  /**< Function level reset capability. Set to 1 for SR-IOV core. */
+	uint32_t cspls                        : 2;  /**< Captured slot power limit scale. From message from RC, upstream port only. */
+	uint32_t csplv                        : 8;  /**< Captured slot power limit value. From message from RC, upstream port only. */
 	uint32_t reserved_16_17               : 2;
-	uint32_t rber                         : 1;  /**< Role-Based Error Reporting */
+	uint32_t rber                         : 1;  /**< Role-based error reporting. */
 	uint32_t reserved_12_14               : 3;
-	uint32_t el1al                        : 3;  /**< Endpoint L1 Acceptable Latency */
-	uint32_t el0al                        : 3;  /**< Endpoint L0s Acceptable Latency */
-	uint32_t etfs                         : 1;  /**< Extended Tag Field Supported */
-	uint32_t pfs                          : 2;  /**< Phantom Function Supported */
-	uint32_t mpss                         : 3;  /**< Max_Payload_Size Supported */
+	uint32_t el1al                        : 3;  /**< Endpoint L1 acceptable latency. */
+	uint32_t el0al                        : 3;  /**< Endpoint L0s acceptable latency. */
+	uint32_t etfs                         : 1;  /**< Extended tag field supported. */
+	uint32_t pfs                          : 2;  /**< Phantom function supported. */
+	uint32_t mpss                         : 3;  /**< Max_Payload_Size supported. */
 #else
 	uint32_t mpss                         : 3;
 	uint32_t pfs                          : 2;
@@ -1151,64 +1130,50 @@ typedef union cvmx_pcieepvfx_cfg029 cvmx_pcieepvfx_cfg029_t;
 /**
  * cvmx_pcieepvf#_cfg030
  *
- * PCIE_CFG030 = Thirty-first 32-bits of PCIE type 0 config space
- * (Device Control Register/Device Status Register)
+ * This register contains the thirty-first 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg030 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg030_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_22_31               : 10;
-	uint32_t tp                           : 1;  /**< Transaction Pending
-                                                         Set to 1 when Non-Posted Requests are not yet completed
-                                                         and clear when they are completed. */
-	uint32_t ap_d                         : 1;  /**< Aux Power Detected
-                                                         Set to 1 if Aux power detected. */
-	uint32_t ur_d                         : 1;  /**< Unsupported Request Detected
-                                                         Errors are logged in this register regardless of whether
-                                                         error reporting is enabled in the Device Control register.
-                                                         UR_D occurs when we receive something we don't support.
-                                                         Unsupported requests are Nonfatal errors, so UR_D should
-                                                         cause NFE_D.  Receiving a  vendor defined message should
-                                                         cause an unsupported request. */
-	uint32_t fe_d                         : 1;  /**< Fatal Error Detected
-                                                         All fatal errors re non-function specific and get
-                                                         reported only in the PF. */
-	uint32_t nfe_d                        : 1;  /**< Non-Fatal Error detected
-                                                         Errors are logged in this register regardless of whether
-                                                         error reporting is enabled in the Device Control register.
-                                                         NFE_D is set if we receive any of the errors in PCIE_CFG066
-                                                         that has a severity set to Nonfatal and does NOT meet Advisory
-                                                         Nonfatal criteria , which
-                                                         most poisoned TLP's should be. */
-	uint32_t ce_d                         : 1;  /**< Correctable Error Detected
-                                                         All correctable errors re non-function specific and get
+	uint32_t tp                           : 1;  /**< Transaction pending. Set to 1 when nonposted requests are not yet completed and set to 0
+                                                         when they are completed. */
+	uint32_t ap_d                         : 1;  /**< Aux power detected. Set to 1 if Aux power detected. */
+	uint32_t ur_d                         : 1;  /**< Unsupported request detected. Errors are logged in this register regardless of whether or
+                                                         not error reporting is enabled in the device control register. UR_D occurs when we receive
+                                                         something unsupported. Unsupported requests are nonfatal errors, so UR_D should cause
+                                                         NFE_D. Receiving a vendor-defined message should cause an unsupported request. */
+	uint32_t fe_d                         : 1;  /**< Fatal error detected. All fatal errors are non-function specific and get reported only in the PF. */
+	uint32_t nfe_d                        : 1;  /**< Nonfatal error detected. Errors are logged in this register regardless of whether or not
+                                                         error reporting is enabled in the device control register. This field is set if we receive
+                                                         any of the errors in
+                                                         PCIEEP(0..3)_CFG066 that has a severity set to nonfatal and does not meet advisory
+                                                         nonfatal criteria, which most poisoned TLPs should. */
+	uint32_t ce_d                         : 1;  /**< Correctable error detected. All correctable errors are non-function specific and get
                                                          reported only in the PF. */
-	uint32_t i_flr                        : 1;  /**< Initiate Function Level Reset
-                                                         (Not Supported) */
-	uint32_t mrrs                         : 3;  /**< Max Read Request Size
-                                                         0 = 128B
-                                                         1 = 256B
-                                                         2 = 512B
-                                                         3 = 1024B
-                                                         4 = 2048B
-                                                         5 = 4096B */
-	uint32_t ns_en                        : 1;  /**< Enable No Snoop */
-	uint32_t ap_en                        : 1;  /**< AUX Power PM Enable */
-	uint32_t pf_en                        : 1;  /**< Phantom Function Enable */
-	uint32_t etf_en                       : 1;  /**< Extended Tag Field Enable */
-	uint32_t mps                          : 3;  /**< "Max Payload Size.
-                                                         Legal values:
-                                                         0  = 128B
-                                                         1  = 256B
-                                                         Larger sizes not supported by OCTEON.
-                                                         Note: DPI_SLI_PRT#_CFG[MPS] must be set to the same
-                                                         value for proper functionality." */
-	uint32_t ro_en                        : 1;  /**< Enable Relaxed Ordering */
-	uint32_t ur_en                        : 1;  /**< Unsupported Request Reporting Enable */
-	uint32_t fe_en                        : 1;  /**< Fatal Error Reporting Enable */
-	uint32_t nfe_en                       : 1;  /**< Non-Fatal Error Reporting Enable */
-	uint32_t ce_en                        : 1;  /**< Correctable Error Reporting Enable */
+	uint32_t i_flr                        : 1;  /**< Initiate function level reset (not supported). */
+	uint32_t mrrs                         : 3;  /**< Max read request size.
+                                                         0x0 = 128 B.
+                                                         0x1 = 256 B.
+                                                         0x2 = 512 B.
+                                                         0x3 = 1024 B.
+                                                         0x4 = 2048 B.
+                                                         0x5 = 4096 B. */
+	uint32_t ns_en                        : 1;  /**< Enable no snoop. */
+	uint32_t ap_en                        : 1;  /**< AUX power PM enable. */
+	uint32_t pf_en                        : 1;  /**< Phantom function enable. */
+	uint32_t etf_en                       : 1;  /**< Extended tag field enable. */
+	uint32_t mps                          : 3;  /**< Max payload size. Legal values: 0x0 = 128B, 0x1 = 256B.
+                                                         Larger sizes are not supported by CN78XX.
+                                                         DPI_SLI_PRT(0..3)_CFG[MPS] must be set to the same value as this field for proper
+                                                         functionality. */
+	uint32_t ro_en                        : 1;  /**< Enable relaxed ordering. */
+	uint32_t ur_en                        : 1;  /**< Unsupported request reporting enable. */
+	uint32_t fe_en                        : 1;  /**< Fatal error reporting enable. */
+	uint32_t nfe_en                       : 1;  /**< Nonfatal error reporting enable. */
+	uint32_t ce_en                        : 1;  /**< Correctable error reporting enable. */
 #else
 	uint32_t ce_en                        : 1;
 	uint32_t nfe_en                       : 1;
@@ -1238,46 +1203,40 @@ typedef union cvmx_pcieepvfx_cfg030 cvmx_pcieepvfx_cfg030_t;
 /**
  * cvmx_pcieepvf#_cfg031
  *
- * PCIE_CFG031 = Thirty-second 32-bits of PCIE type 0 config space
- * (Link Capabilities Register)
+ * This register contains the thirty-second 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg031 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg031_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t pnum                         : 8;  /**< Port Number */
+	uint32_t pnum                         : 8;  /**< Port number. */
 	uint32_t reserved_23_23               : 1;
-	uint32_t aspm                         : 1;  /**< ASPM Optionality Compliance */
-	uint32_t lbnc                         : 1;  /**< Link Bandwidth Notification Capability
-                                                         Set 0 for Endpoint devices. */
-	uint32_t dllarc                       : 1;  /**< Data Link Layer Active Reporting Capable */
-	uint32_t sderc                        : 1;  /**< Surprise Down Error Reporting Capable
-                                                         Not supported, hardwired to 0x0. */
-	uint32_t cpm                          : 1;  /**< Clock Power Management
-                                                         The default value is the value you specify during hardware
-                                                         configuration */
-	uint32_t l1el                         : 3;  /**< L1 Exit Latency
-                                                         The default value is the value you specify during hardware
-                                                         configuration */
-	uint32_t l0el                         : 3;  /**< L0s Exit Latency
-                                                         The default value is the value you specify during hardware
-                                                         configuration */
-	uint32_t aslpms                       : 2;  /**< Active State Link PM Support
-                                                         The default value is the value you specify during hardware
-                                                         configuration */
-	uint32_t mlw                          : 6;  /**< Maximum Link Width
-                                                         The default value is the value you specify during hardware
-                                                         configuration (x1, x4, x8, or x16) */
-	uint32_t mls                          : 4;  /**< "Maximum Link Speed
-                                                         The reset value of this field is controlled by the value read from
-                                                         the PEM csr PEM(0..3)_CFG.MD.
-                                                         PEM(0..2)_CFG.MD  RST_VALUE   NOTE
-                                                         00                0001b       2.5 GHz supported
-                                                         01                0010b       5.0 GHz and 2.5 GHz supported
-                                                         10                0011b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported
-                                                         11                0011b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported (RC Mode)
-                                                         This field is writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t aspm                         : 1;  /**< ASPM optionality compliance. */
+	uint32_t lbnc                         : 1;  /**< Link bandwidth notification capability. Set to 0 for endpoint devices. */
+	uint32_t dllarc                       : 1;  /**< Data link layer active reporting capable. */
+	uint32_t sderc                        : 1;  /**< Surprise down error reporting capable. Not supported; hardwired to 0. */
+	uint32_t cpm                          : 1;  /**< Clock power management. The default value is the value that software specifies during
+                                                         hardware configuration. */
+	uint32_t l1el                         : 3;  /**< L1 exit latency. The default value is the value that software specifies during hardware
+                                                         configuration. */
+	uint32_t l0el                         : 3;  /**< L0s exit latency. The default value is the value that software specifies during hardware
+                                                         configuration. */
+	uint32_t aslpms                       : 2;  /**< Active state link PM support. The default value is the value that software specifies
+                                                         during hardware configuration. */
+	uint32_t mlw                          : 6;  /**< Maximum link width. The default value is the value that software specifies during hardware
+                                                         configuration (*1, *4, *8, *16). */
+	uint32_t mls                          : 4;  /**< Maximum link speed.The reset value of this field is controlled by the value read from
+                                                         PEM(0..3)_CFG[MD].
+                                                         PEM*_CFG
+                                                         [MD] RST_VALUE NOTE
+                                                         0x0 0001b 2.5 GHz supported
+                                                         0x1 0010b 5.0 GHz and 2.5 GHz supported
+                                                         0x2 0011b 8.0 Ghz, 5.0 GHz and 2.5 GHz supported
+                                                         0x3 0011b 8.0 Ghz, 5.0 GHz and 2.5 GHz supported
+                                                         (RC Mode)
+                                                         This field is writable through PEM(0..3)_CFG_WR. However, the application must not change
+                                                         this field. */
 #else
 	uint32_t mls                          : 4;
 	uint32_t mlw                          : 6;
@@ -1300,52 +1259,40 @@ typedef union cvmx_pcieepvfx_cfg031 cvmx_pcieepvfx_cfg031_t;
 /**
  * cvmx_pcieepvf#_cfg032
  *
- * PCIE_CFG032 = Thirty-third 32-bits of PCIE type 0 config space
- * (Link Control Register/Link Status Register)
+ * This register contains the thirty-third 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg032 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg032_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t lab                          : 1;  /**< Link Autonomous Bandwidth Status */
-	uint32_t lbm                          : 1;  /**< Link Bandwidth Management Status */
-	uint32_t dlla                         : 1;  /**< Data Link Layer Active
-                                                         Not applicable for an upstream Port or Endpoint device,
-                                                         hardwired to 0. */
-	uint32_t scc                          : 1;  /**< Slot Clock Configuration
-                                                         Indicates that the component uses the same physical reference
+	uint32_t lab                          : 1;  /**< Link autonomous bandwidth status. */
+	uint32_t lbm                          : 1;  /**< Link bandwidth management status. */
+	uint32_t dlla                         : 1;  /**< Data link layer active. Not applicable for an upstream port or endpoint device, hardwired to 0. */
+	uint32_t scc                          : 1;  /**< Slot clock configuration. Indicates that the component uses the same physical reference
                                                          clock that the platform provides on the connector. */
-	uint32_t lt                           : 1;  /**< Link Training
-                                                         Not applicable for an upstream Port or Endpoint device,
-                                                         hardwired to 0. */
+	uint32_t lt                           : 1;  /**< Link training. Not applicable for an upstream port or endpoint device, hardwired to 0. */
 	uint32_t reserved_26_26               : 1;
-	uint32_t nlw                          : 6;  /**< Negotiated Link Width
-                                                         Set automatically by hardware after Link initialization. */
-	uint32_t ls                           : 4;  /**< Link Speed
-                                                         1 == The negotiated Link speed: 2.5 Gbps
-                                                         2 == The negotiated Link speed: 5.0 Gbps
-                                                         4 == The negotiated Link speed: 8.0 Gbps */
+	uint32_t nlw                          : 6;  /**< Negotiated link width. Set automatically by hardware after Link initialization. */
+	uint32_t ls                           : 4;  /**< Link speed.
+                                                         0x1 = The negotiated link speed: 2.5 Gbps
+                                                         0x2 = The negotiated link speed: 5.0 Gbps
+                                                         0x4 = The negotiated link speed: 8.0 Gbps */
 	uint32_t reserved_12_15               : 4;
-	uint32_t lab_int_enb                  : 1;  /**< Link Autonomous Bandwidth Interrupt Enable
-                                                         This bit is not applicable and is reserved for endpoints */
-	uint32_t lbm_int_enb                  : 1;  /**< Link Bandwidth Management Interrupt Enable
-                                                         This bit is not applicable and is reserved for endpoints */
-	uint32_t hawd                         : 1;  /**< Hardware Autonomous Width Disable
-                                                         (Not Supported) */
-	uint32_t ecpm                         : 1;  /**< Enable Clock Power Management
-                                                         Hardwired to 0 if Clock Power Management is disabled in
-                                                         the Link Capabilities register. */
-	uint32_t es                           : 1;  /**< Extended Synch */
-	uint32_t ccc                          : 1;  /**< Common Clock Configuration */
-	uint32_t rl                           : 1;  /**< Retrain Link
-                                                         Not applicable for an upstream Port or Endpoint device,
-                                                         hardwired to 0. */
-	uint32_t ld                           : 1;  /**< Link Disable
-                                                         Not applicable for an upstream Port or Endpoint device,
-                                                         hardwired to 0. */
-	uint32_t rcb                          : 1;  /**< Read Completion Boundary (RCB) */
+	uint32_t lab_int_enb                  : 1;  /**< Link autonomous bandwidth interrupt enable. This bit is not applicable and is reserved for
+                                                         endpoints. */
+	uint32_t lbm_int_enb                  : 1;  /**< Link bandwidth management interrupt enable. This bit is not applicable and is reserved for
+                                                         endpoints. */
+	uint32_t hawd                         : 1;  /**< Hardware autonomous width disable (not supported). */
+	uint32_t ecpm                         : 1;  /**< Enable clock power management. Hardwired to 0 if clock power management is disabled in the
+                                                         link capabilities register. */
+	uint32_t es                           : 1;  /**< Extended synch. */
+	uint32_t ccc                          : 1;  /**< Common clock configuration. */
+	uint32_t rl                           : 1;  /**< Retrain link. Not applicable for an upstream port or endpoint device. Hardwired to 0. */
+	uint32_t ld                           : 1;  /**< Link disable. Not applicable for an upstream port or endpoint device. Hardwired to 0. */
+	uint32_t rcb                          : 1;  /**< Read completion boundary (RCB). */
 	uint32_t reserved_2_2                 : 1;
-	uint32_t aslpc                        : 2;  /**< Active State Link PM Control */
+	uint32_t aslpc                        : 2;  /**< Active state Link PM control. */
 #else
 	uint32_t aslpc                        : 2;
 	uint32_t reserved_2_2                 : 1;
@@ -1376,41 +1323,33 @@ typedef union cvmx_pcieepvfx_cfg032 cvmx_pcieepvfx_cfg032_t;
 /**
  * cvmx_pcieepvf#_cfg037
  *
- * PCIE_CFG037 = Thirty-eighth 32-bits of PCIE type 0 config space
- * (Device Capabilities 2 Register)
+ * This register contains the thirty-eighth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg037 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg037_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t meetp                        : 2;  /**< "Max End-End TLP Prefixes
-                                                         o 01b: 1
-                                                         o 10b: 2
-                                                         o 11b: 3
-                                                         o 00b: 4" */
-	uint32_t eetps                        : 1;  /**< End-End TLP Prefix Supported */
-	uint32_t effs                         : 1;  /**< Extended Fmt Field Supported */
-	uint32_t obffs                        : 2;  /**< Optimized Buffer Flush Fill (OBFF) Supported
-                                                         (Not Supported) */
+	uint32_t meetp                        : 2;  /**< Max end-end TLP prefixes.
+                                                         0x1 = 1
+                                                         0x2 = 2
+                                                         0x3 = 3
+                                                         0x0 = 4 */
+	uint32_t eetps                        : 1;  /**< End-end TLP prefix supported. */
+	uint32_t effs                         : 1;  /**< Extended Fmt field supported. */
+	uint32_t obffs                        : 2;  /**< Optimized buffer flush fill (OBFF) supported (not supported). */
 	uint32_t reserved_14_17               : 4;
-	uint32_t tphs                         : 2;  /**< TPH Completer Supported
-                                                         (Not Supported) */
-	uint32_t ltrs                         : 1;  /**< Latency Tolerance Reporting (LTR) Mechanism Supported
-                                                         (Not Supported) */
-	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR Passing
-                                                         (This bit applies to RCs) */
-	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp Supported
-                                                         (Not Supported) */
-	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp Supported
-                                                         (Not Supported) */
-	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp Supported
-                                                         (Not Supported) */
-	uint32_t atom_ops                     : 1;  /**< AtomicOp Routing Supported
-                                                         (Not Applicable for EP) */
-	uint32_t ari                          : 1;  /**< Alternate Routing ID Forwarding Supported */
-	uint32_t ctds                         : 1;  /**< Completion Timeout Disable Supported */
-	uint32_t ctrs                         : 4;  /**< Completion Timeout Ranges Supported */
+	uint32_t tphs                         : 2;  /**< TPH completer supported (not supported). */
+	uint32_t ltrs                         : 1;  /**< Latency tolerance reporting (LTR) mechanism supported (not supported). */
+	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR passing. (This bit applies to RCs.) */
+	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp supported (not supported). */
+	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported (not supported). */
+	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported (not supported). */
+	uint32_t atom_ops                     : 1;  /**< AtomicOp routing supported (not applicable for EP). */
+	uint32_t ari                          : 1;  /**< Alternate routing ID forwarding supported. */
+	uint32_t ctds                         : 1;  /**< Completion timeout disable supported. */
+	uint32_t ctrs                         : 4;  /**< Completion timeout ranges supported. */
 #else
 	uint32_t ctrs                         : 4;
 	uint32_t ctds                         : 1;
@@ -1437,31 +1376,25 @@ typedef union cvmx_pcieepvfx_cfg037 cvmx_pcieepvfx_cfg037_t;
 /**
  * cvmx_pcieepvf#_cfg038
  *
- * PCIE_CFG038 = Thirty-ninth 32-bits of PCIE type 0 config space
- * (Device Control 2 Register/Device Status 2 Register)
+ * This register contains the thirty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg038 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg038_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_16_31               : 16;
-	uint32_t eetpb                        : 1;  /**< Unsupported End-End TLP Prefix Blocking */
-	uint32_t obffe                        : 2;  /**< Optimized Buffer Flush Fill (OBFF) Enable
-                                                         (Not Supported) */
+	uint32_t eetpb                        : 1;  /**< Unsupported end-end TLP prefix blocking. */
+	uint32_t obffe                        : 2;  /**< Optimized buffer flush fill (OBFF) enable (not supported). */
 	uint32_t reserved_10_12               : 3;
-	uint32_t id0_cp                       : 1;  /**< ID Based Ordering Completion Enable
-                                                         (Not Supported) */
-	uint32_t id0_rq                       : 1;  /**< ID Based Ordering Request Enable
-                                                         (Not Supported) */
-	uint32_t atom_op_eb                   : 1;  /**< AtomicOp Egress Blocking
-                                                         (Not Supported)m */
-	uint32_t atom_op                      : 1;  /**< AtomicOp Requester Enable
-                                                         (Not Supported) */
-	uint32_t ari                          : 1;  /**< Alternate Routing ID Forwarding Supported */
-	uint32_t ctd                          : 1;  /**< Completion Timeout Disable */
-	uint32_t ctv                          : 4;  /**< Completion Timeout Value
-                                                         Completion Timeout Programming is not supported
-                                                         Completion timeout is the range of 16 ms to 55 ms. */
+	uint32_t id0_cp                       : 1;  /**< ID based ordering completion enable (not supported). */
+	uint32_t id0_rq                       : 1;  /**< ID based ordering request enable (not supported). */
+	uint32_t atom_op_eb                   : 1;  /**< AtomicOp egress blocking (not supported). */
+	uint32_t atom_op                      : 1;  /**< AtomicOp requester enable (not supported). */
+	uint32_t ari                          : 1;  /**< Alternate routing ID forwarding supported (not supported). */
+	uint32_t ctd                          : 1;  /**< Completion timeout disable. */
+	uint32_t ctv                          : 4;  /**< Completion timeout value. Completion timeout programming is not supported. Completion
+                                                         timeout is the range of 16 ms to 55 ms. */
 #else
 	uint32_t ctv                          : 4;
 	uint32_t ctd                          : 1;
@@ -1483,32 +1416,30 @@ typedef union cvmx_pcieepvfx_cfg038 cvmx_pcieepvfx_cfg038_t;
 /**
  * cvmx_pcieepvf#_cfg039
  *
- * PCIE_CFG039 = Fortieth 32-bits of PCIE type 0 config space
- * (Link Capabilities 2 Register)
+ * This register contains the fortieth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg039 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg039_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_9_31                : 23;
-	uint32_t cls                          : 1;  /**< Crosslink Supported */
-	uint32_t slsv                         : 7;  /**< "Supported Link Speeds Vector
-                                                         Indicates the supported Link speeds of the associated Port.
-                                                         For each bit, a value of 1b indicates that the cooresponding
-                                                         Link speed is supported; otherwise, the Link speed is not
-                                                         supported.
-                                                         Bit definitions are:
-                                                         Bit 1 2.5 GT/s
-                                                         Bit 2 5.0 GT/s
-                                                         Bit 3 8.0 GT/s
-                                                         Bits 7:4 reserved
-                                                         The reset value of this field is controlled by a value read from
-                                                         the PEM csr PEM(0..3)_CFG.MD.
-                                                         PEM(0..3)_CFG.MD   RST_VALUE   NOTE
-                                                         00                 0001b       2.5 GHz supported
-                                                         01                 0011b       5.0 GHz and 2.5 GHz supported
-                                                         10                 0111b       8.0 GHz, 5.0 GHz and 2.5 GHz supported
-                                                         11                 0111b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported (RC Mode)" */
+	uint32_t cls                          : 1;  /**< Crosslink supported. */
+	uint32_t slsv                         : 7;  /**< Supported link speeds vector. Indicates the supported link speeds of the associated port.
+                                                         For each bit, a value of 1b indicates that the corresponding link speed is supported;
+                                                         otherwise, the link speed is not supported. Bit definitions are:
+                                                         Bit <1> = 2.5 GT/s
+                                                         Bit <2> = 5.0 GT/s
+                                                         Bit <3> = 8.0 GT/s
+                                                         Bits <7:4> are reserved
+                                                         The reset value of this field is controlled by the value read from PEM(0..3)_CFG[MD].
+                                                         PEM*_CFG
+                                                         [MD] RST_VALUE NOTE
+                                                         0x0 0001b 2.5 GHz supported
+                                                         0x1 0011b 5.0 GHz and 2.5 GHz supported
+                                                         0x2 0111b 8.0 Ghz, 5.0 GHz and 2.5 GHz supported
+                                                         0x3 0111b 8.0 Ghz, 5.0 GHz and 2.5 GHz supported
+                                                         (RC Mode) */
 	uint32_t reserved_0_0                 : 1;
 #else
 	uint32_t reserved_0_0                 : 1;
@@ -1524,90 +1455,67 @@ typedef union cvmx_pcieepvfx_cfg039 cvmx_pcieepvfx_cfg039_t;
 /**
  * cvmx_pcieepvf#_cfg040
  *
- * PCIE_CFG040 = Forty-first 32-bits of PCIE type 0 config space
- * (Link Control 2 Register/Link Status 2 Register)
+ * This register contains the forty-first 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg040 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg040_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_17_31               : 15;
-	uint32_t cdl                          : 1;  /**< Current De-emphasis Level
-                                                         When the Link is operating at 5 GT/s speed, this bit
-                                                         reflects the level of de-emphasis. Encodings:
-                                                         1b: -3.5 dB
-                                                         0b: -6 dB
-                                                         Note: The value in this bit is undefined when the Link is
-                                                         operating at 2.5 GT/s speed */
+	uint32_t cdl                          : 1;  /**< Current deemphasis level. When the link is operating at 5 GT/s speed, this bit reflects
+                                                         the level of deemphasis. Encodings:
+                                                         1 = -3.5 dB
+                                                         0 = -6 dB
+                                                         The value in this bit is undefined when the link is operating at 2.5 GT/s speed. */
 	uint32_t reserved_13_15               : 3;
-	uint32_t cde                          : 1;  /**< Compliance De-emphasis
-                                                         This bit sets the de-emphasis level in Polling. Compliance
-                                                         state if the entry occurred due to the Tx Compliance
-                                                         Receive bit being 1b. Encodings:
-                                                         1b: -3.5 dB
-                                                         0b: -6 dB
-                                                         Note: When the Link is operating at 2.5 GT/s, the setting
-                                                         of this bit has no effect. */
-	uint32_t csos                         : 1;  /**< Compliance SOS
-                                                         When set to 1b, the LTSSM is required to send SKP
-                                                         Ordered Sets periodically in between the (modified)
-                                                         compliance patterns.
-                                                         Note: When the Link is operating at 2.5 GT/s, the setting
-                                                         of this bit has no effect. */
-	uint32_t emc                          : 1;  /**< Enter Modified Compliance
-                                                         When this bit is set to 1b, the device transmits a modified
-                                                         compliance pattern if the LTSSM enters Polling.
-                                                         Compliance state. */
-	uint32_t tm                           : 3;  /**< Transmit Margin
-                                                         This field controls the value of the non-de-emphasized
-                                                         voltage level at the Transmitter pins:
-                                                         - 000: 800-1200 mV for full swing 400-600 mV for half-swing
-                                                         - 001-010: values must be monotonic with a non-zero slope
-                                                         - 011: 200-400 mV for full-swing and 100-200 mV for halfswing
-                                                         - 100-111: reserved
-                                                         This field is reset to 000b on entry to the LTSSM Polling.
-                                                         Compliance substate.
-                                                         When operating in 5.0 GT/s mode with full swing, the
-                                                         de-emphasis ratio must be maintained within +/- 1 dB
-                                                         from the specification-defined operational value
-                                                         either -3.5 or -6 dB). */
-	uint32_t sde                          : 1;  /**< Selectable De-emphasis
-                                                         Not applicable for an upstream Port or Endpoint device.
-                                                         Hardwired to 0. */
-	uint32_t hasd                         : 1;  /**< Hardware Autonomous Speed Disable
-                                                         When asserted, the
-                                                         application must disable hardware from changing the Link
-                                                         speed for device-specific reasons other than attempting to
-                                                         correct unreliable Link operation by reducing Link speed.
-                                                         Initial transition to the highest supported common link
-                                                         speed is not blocked by this signal. */
-	uint32_t ec                           : 1;  /**< Enter Compliance
-                                                         Software is permitted to force a link to enter Compliance
-                                                         mode at the speed indicated in the Target Link Speed
-                                                         field by setting this bit to 1b in both components on a link
-                                                         and then initiating a hot reset on the link. */
-	uint32_t tls                          : 4;  /**< "Target Link Speed
-                                                         For Downstream ports, this field sets an upper limit on link
-                                                         operational speed by restricting the values advertised by
-                                                         the upstream component in its training sequences:
-                                                         - 0001: 2.5Gb/s Target Link Speed
-                                                         - 0010: 5Gb/s Target Link Speed
-                                                         - 0100: 8Gb/s Target Link Speed (Not Supported)
+	uint32_t cde                          : 1;  /**< Compliance deemphasis. This bit sets the deemphasis level in polling. Compliance state if
+                                                         the entry occurred due to the Tx compliance receive bit being 1. Encodings:
+                                                         1 =  -3.5 dB
+                                                         0 =  -6 dB
+                                                         When the link is operating at 2.5 GT/s, the setting of this bit has no effect. */
+	uint32_t csos                         : 1;  /**< Compliance SOS. When set to 1, the LTSSM is required to send SKP ordered sets periodically
+                                                         in between the (modified) compliance patterns.
+                                                         When the link is operating at 2.5 GT/s, the setting of this bit has no effect. */
+	uint32_t emc                          : 1;  /**< Enter modified compliance. When this bit is set to 1, the device transmits a modified
+                                                         compliance pattern if the LTSSM enters polling.Compliance state. */
+	uint32_t tm                           : 3;  /**< Transmit margin. This field controls the value of the non-deemphasized voltage level at
+                                                         the transmitter pins:
+                                                         0x0 =  800-1200 mV for full swing 400-600 mV for half-swing
+                                                         0x1-0x2 = Values must be monotonic with a nonzero slope
+                                                         0x3 = 200-400 mV for full-swing and 100-200 mV for halfswing
+                                                         0x4-0x7 = Reserved
+                                                         This field is reset to 0x0 on entry to the LTSSM polling compliance substate. When
+                                                         operating in 5.0 GT/s mode with full swing, the deemphasis ratio must be maintained within
+                                                         +/- 1 dB from the specification-defined operational value either -3.5 or -6 dB. */
+	uint32_t sde                          : 1;  /**< Selectable deemphasis. Not applicable for an upstream port or endpoint device. Hardwired to 0. */
+	uint32_t hasd                         : 1;  /**< Hardware autonomous speed disable. When asserted, the application must disable hardware
+                                                         from changing the link speed for device-specific reasons other than attempting to correct
+                                                         unreliable link operation by reducing link speed. Initial transition to the highest
+                                                         supported common link speed is not blocked by this signal. */
+	uint32_t ec                           : 1;  /**< Enter compliance. Software is permitted to force a link to enter compliance mode at the
+                                                         speed indicated in the target link speed field by setting this bit to 1 in both components
+                                                         on a link and then initiating a hot reset on the link. */
+	uint32_t tls                          : 4;  /**< Target link speed. For downstream ports, this field sets an upper limit on link
+                                                         operational speed by restricting the values advertised by the upstream component in its
+                                                         training sequences:
+                                                         0x1: 2.5 Gb/s target link speed
+                                                         0x2: 5 Gb/s target link speed
+                                                         0x4: 8Gb/s target link speed (not supported)
                                                          All other encodings are reserved.
-                                                         If a value is written to this field that does not correspond to
-                                                         a speed included in the Supported Link Speeds field, the
-                                                         result is undefined.
-                                                         For both Upstream and Downstream ports, this field is
-                                                         used to set the target compliance mode speed when
-                                                         software is using the Enter Compliance bit to force a link
-                                                         into compliance mode.
-                                                         The reset value of this field is controlled by the value read from
-                                                         the PEM csr PEM(0..3)_CFG.MD.
-                                                         PEM(0..2)_CFG.MD  RST_VALUE   NOTE
-                                                         00                0001b       2.5 GHz supported
-                                                         01                0010b       5.0 GHz and 2.5 GHz supported
-                                                         10                0011b       8.0 GHz, 5.0 GHz and 2.5 GHz supported
-                                                         11                0011b       8.0 Ghz, 5.0 GHz and 2.5 GHz supported (RC Mode)" */
+                                                         If a value is written to this field that does not correspond to a speed included in the
+                                                         supported link speeds field, the result is undefined.
+                                                         For both upstream and downstream ports, this field is used to set the target compliance
+                                                         mode speed when software is using the enter compliance bit to force a link into compliance
+                                                         mode.
+                                                         The reset value of this field is controlled by the value read from PEM(0..3)_CFG[MD].
+                                                         PEM*_CFG
+                                                         [MD] RST_VALUE NOTE
+                                                         00 0001b 2.5 GHz supported
+                                                         01 0010b 5.0 GHz and 2.5 GHz supported
+                                                         10 0011b 8.0 Ghz, 5.0 GHz and 2.5 GHz supported
+                                                         11 0011b 8.0 Ghz, 5.0 GHz and 2.5 GHz supported
+                                                         (RC Mode) */
 #else
 	uint32_t tls                          : 4;
 	uint32_t ec                           : 1;
@@ -1629,28 +1537,22 @@ typedef union cvmx_pcieepvfx_cfg040 cvmx_pcieepvfx_cfg040_t;
 /**
  * cvmx_pcieepvf#_cfg044
  *
- * PCIE_CFG044 = Forty-fifth 32-bits of PCIE type 0 config space
- * (MSI-X Capability ID/
- * MSI-X Next Item Pointer/
- * MSI-X Control Register)
+ * This register contains the forty-fifth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg044 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg044_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixen                       : 1;  /**< MSI-X Enable
-                                                         If MSI-X is enabled, MIS and INTx must be disabled. */
-	uint32_t funm                         : 1;  /**< Function Mask
-                                                         1b: All vectors associated with the function are masked,
-                                                         regardless of their respective per-vector mask bits.
-                                                         0b: Each vectors Mask bit determines whether the vector
-                                                         is masked or not. */
+	uint32_t msixen                       : 1;  /**< MSI-X enable. If MSI-X is enabled, MSI and INTx must be disabled. */
+	uint32_t funm                         : 1;  /**< Function mask.
+                                                         0 = Each vectors mask bit determines whether the vector is masked or not.
+                                                         1 = All vectors associated with the function are masked, regardless of their respective
+                                                         per-vector mask bits. */
 	uint32_t reserved_27_29               : 3;
-	uint32_t msixts                       : 11; /**< MSI-X Table Size
-                                                         Encoded as (Table Size - 1) */
-	uint32_t ncp                          : 8;  /**< Next Capability Pointer
-                                                         Points to the PCI Power Management Capability Registers */
-	uint32_t msixcid                      : 8;  /**< MSI-X Capability ID */
+	uint32_t msixts                       : 11; /**< MSI-X table size encoded as (table size - 1). */
+	uint32_t ncp                          : 8;  /**< Next capability pointer. Points to the PCI power management capability registers. */
+	uint32_t msixcid                      : 8;  /**< MSI-X Capability ID. */
 #else
 	uint32_t msixcid                      : 8;
 	uint32_t ncp                          : 8;
@@ -1667,21 +1569,19 @@ typedef union cvmx_pcieepvfx_cfg044 cvmx_pcieepvfx_cfg044_t;
 /**
  * cvmx_pcieepvf#_cfg045
  *
- * PCIE_CFG045 = Forty-sixth 32-bits of PCIE type 0 config space
- * (MSI-X Table Offset and BIR Register)
+ * This register contains the forty-sixth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg045 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg045_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixtoffs                    : 29; /**< MSI-X Table Offset Register
-                                                         Base address of the MSI-X Table, as an offset from the base
-                                                         address of te BAR indicated by the Table BIR bits. */
-	uint32_t msixtbir                     : 3;  /**< "MSI-X Table BAR Indicator Register (BIR)
-                                                         Indicates which BAR is used to map the MSI-X Table
-                                                         into memory space
-                                                         000 - 100: BAR#
-                                                         110 - 111: Reserved" */
+	uint32_t msixtoffs                    : 29; /**< MSI-X table offset register. Base address of the MSI-X Table, as an offset from the base
+                                                         address of the BAR indicated by the Table BIR bits. */
+	uint32_t msixtbir                     : 3;  /**< "MSI-X table BAR indicator register (BIR). Indicates which BAR is used to map the MSI-X
+                                                         table into memory space.
+                                                         0x0 - 0x4 = BAR#
+                                                         0x6 - 0x7 = Reserved" */
 #else
 	uint32_t msixtbir                     : 3;
 	uint32_t msixtoffs                    : 29;
@@ -1694,25 +1594,20 @@ typedef union cvmx_pcieepvfx_cfg045 cvmx_pcieepvfx_cfg045_t;
 /**
  * cvmx_pcieepvf#_cfg046
  *
- * PCIE_CFG046 = Forty-seventh 32-bits of PCIE type 0 config space
- * (MSI-X PBA Offset and BIR Register)
+ * This register contains the forty-seventh 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg046 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg046_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixpoffs                    : 29; /**< "MSI-X Table Offset Register
-                                                         Base address of the MSI-X PBA, as an offset from the base
-                                                         address of te BAR indicated by the Table PBA bits.
-                                                         writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t msixpbir                     : 3;  /**< "MSI-X PBA BAR Indicator Register (BIR)
-                                                         Indicates which BAR is used to map the MSI-X Pending Bit Array
-                                                         into memory space
-                                                         000 - 100: BAR#
-                                                         110 - 111: Reserved
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t msixpoffs                    : 29; /**< MSI-X table offset register. Base address of the MSI-X PBA, as an offset from the base
+                                                         address of the BAR indicated by the table PBA bits. */
+	uint32_t msixpbir                     : 3;  /**< "MSI-X PBA BAR indicator register (BIR). Indicates which BAR is used to map the MSI-X
+                                                         pending bit array                                                  into memory space.
+                                                         0x0 - 0x4 = BAR#
+                                                         0x6 - 0x7 = Reserved
+                                                         Writable through PEM(0..3)_CFG_WR. However, the application must not change this field." */
 #else
 	uint32_t msixpbir                     : 3;
 	uint32_t msixpoffs                    : 29;
@@ -1725,30 +1620,28 @@ typedef union cvmx_pcieepvfx_cfg046 cvmx_pcieepvfx_cfg046_t;
 /**
  * cvmx_pcieepvf#_cfg048
  *
- * PCIE_CFG048 = Forty-ninth 32-bits of PCIE type 0 config space
- * (Power Management Capability ID/
- * Power Management Next Item Pointer/
- * Power Management Capabilities Register)
+ * This register contains the forty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg048 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg048_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t pmes                         : 5;  /**< PME_Support
-                                                         o Bit 11: If set, PME Messages can be generated from D0
-                                                         o Bit 12: If set, PME Messages can be generated from D1
-                                                         o Bit 13: If set, PME Messages can be generated from D2
-                                                         o Bit 14: If set, PME Messages can be generated from D3hot
-                                                         o Bit 15: always zero.   VF's do not support D3cold */
-	uint32_t d2s                          : 1;  /**< D2 Support */
-	uint32_t d1s                          : 1;  /**< D1 Support */
-	uint32_t auxc                         : 3;  /**< AUX Current */
-	uint32_t dsi                          : 1;  /**< Device Specific Initialization (DSI) */
+	uint32_t pmes                         : 5;  /**< PME_Support.
+                                                         Bit 11: If set, PME messages can be generated from D0
+                                                         Bit 12: If set, PME messages can be generated from D1
+                                                         Bit 13: If set, PME messages can be generated from D2
+                                                         Bit 14: If set, PME messages can be generated from D3hot
+                                                         Bit 15: Always zero. VFs do not support D3cold */
+	uint32_t d2s                          : 1;  /**< D2 support. */
+	uint32_t d1s                          : 1;  /**< D1 support. */
+	uint32_t auxc                         : 3;  /**< AUX current. */
+	uint32_t dsi                          : 1;  /**< Device specific initialization (DSI). */
 	uint32_t reserved_20_20               : 1;
-	uint32_t pme_clock                    : 1;  /**< PME Clock, hardwired to 0 */
-	uint32_t pmsv                         : 3;  /**< Power Management Specification Version */
-	uint32_t ncp                          : 8;  /**< Next Capability Pointer */
-	uint32_t pmcid                        : 8;  /**< Power Management Capability ID */
+	uint32_t pme_clock                    : 1;  /**< PME clock, hardwired to 0. */
+	uint32_t pmsv                         : 3;  /**< Power management specification version. */
+	uint32_t ncp                          : 8;  /**< Next capability pointer. */
+	uint32_t pmcid                        : 8;  /**< Power management capability ID. */
 #else
 	uint32_t pmcid                        : 8;
 	uint32_t ncp                          : 8;
@@ -1769,35 +1662,30 @@ typedef union cvmx_pcieepvfx_cfg048 cvmx_pcieepvfx_cfg048_t;
 /**
  * cvmx_pcieepvf#_cfg049
  *
- * PCIE_CFG049 = Fiftieth 32-bits of PCIE type 0 config space (Power Management Control and
- * Status Register)
+ * This register contains the fiftieth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg049 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg049_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t pmdia                        : 8;  /**< Data register for additional information (not supported) */
-	uint32_t bpccee                       : 1;  /**< Bus Power/Clock Control Enable, hardwired to 0 */
-	uint32_t bd3h                         : 1;  /**< B2/B3 Support, hardwired to 0 */
+	uint32_t bpccee                       : 1;  /**< Bus power/clock control enable, hardwired to 0. */
+	uint32_t bd3h                         : 1;  /**< B2/B3 support, hardwired to 0. */
 	uint32_t reserved_16_21               : 6;
-	uint32_t pmess                        : 1;  /**< PME Status
-                                                         Indicates if a previously enabled PME event occurred or not. */
-	uint32_t pmedsia                      : 2;  /**< Data Scale (not supported) */
-	uint32_t pmds                         : 4;  /**< Data Select (not supported) */
-	uint32_t pmeens                       : 1;  /**< PME Enable
-                                                         A value of 1 indicates that the device is enabled to
-                                                         generate PME. */
+	uint32_t pmess                        : 1;  /**< PME status. Indicates whether or not a previously enabled PME event occurred. */
+	uint32_t pmedsia                      : 2;  /**< Data scale (not supported). */
+	uint32_t pmds                         : 4;  /**< Data select (not supported). */
+	uint32_t pmeens                       : 1;  /**< PME enable. A value of 1 indicates that the device is enabled to generate PME. */
 	uint32_t reserved_4_7                 : 4;
-	uint32_t nsr                          : 1;  /**< No Soft Reset */
+	uint32_t nsr                          : 1;  /**< No soft reset. */
 	uint32_t reserved_2_2                 : 1;
-	uint32_t ps                           : 2;  /**< Power State
-                                                         Controls the device power state:
-                                                         o 00b: D0
-                                                         o 01b: D1
-                                                         o 10b: D2
-                                                         o 11b: D3
-                                                         The written value is ignored if the specific state is
-                                                         not supported. */
+	uint32_t ps                           : 2;  /**< Power state. Controls the device power state:
+                                                         0x0 = D0
+                                                         0x1 = D1
+                                                         0x2 = D2
+                                                         0x3 = D3
+                                                         The written value is ignored if the specific state is not supported. */
 #else
 	uint32_t ps                           : 2;
 	uint32_t reserved_2_2                 : 1;
@@ -1820,17 +1708,16 @@ typedef union cvmx_pcieepvfx_cfg049 cvmx_pcieepvfx_cfg049_t;
 /**
  * cvmx_pcieepvf#_cfg064
  *
- * PCIE_CFG064 = Sixty-fifth 32-bits of PCIE type 0 config space
- * (PCI Express Extended Capability Header)
+ * This register contains the sixty-fifth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg064 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg064_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t nco                          : 12; /**< Next Capability Offset
-                                                         Points to the ARI Capabilities by default, */
-	uint32_t cv                           : 4;  /**< Capability Version */
-	uint32_t pcieec                       : 16; /**< PCIE Express Extended Capability ID */
+	uint32_t nco                          : 12; /**< Next capability offset. Points to the ARI capabilities by default. */
+	uint32_t cv                           : 4;  /**< Capability version */
+	uint32_t pcieec                       : 16; /**< PCI Express extended capability */
 #else
 	uint32_t pcieec                       : 16;
 	uint32_t cv                           : 4;
@@ -1844,16 +1731,16 @@ typedef union cvmx_pcieepvfx_cfg064 cvmx_pcieepvfx_cfg064_t;
 /**
  * cvmx_pcieepvf#_cfg082
  *
- * PCIE_CFG082 = Eighty-third 32-bits of PCIE type 0 config space
- * (PCI Express ARI Capability Header)
+ * This register contains the eighty-third 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg082 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg082_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t nco                          : 12; /**< Next Capability Offset */
-	uint32_t cv                           : 4;  /**< Capability Version */
-	uint32_t ariid                        : 16; /**< PCIE Express Extended Capability */
+	uint32_t nco                          : 12; /**< Next capability offset */
+	uint32_t cv                           : 4;  /**< Capability version */
+	uint32_t ariid                        : 16; /**< PCIE Express extended capability */
 #else
 	uint32_t ariid                        : 16;
 	uint32_t cv                           : 4;
@@ -1867,23 +1754,22 @@ typedef union cvmx_pcieepvfx_cfg082 cvmx_pcieepvfx_cfg082_t;
 /**
  * cvmx_pcieepvf#_cfg083
  *
- * PCIE_CFG083 = Eighty-fourth 32-bits of PCIE type 0 config space
- * (PCI Express ARI Capability Register/
- * PCI Express ARI Control Register)
+ * This register contains the eighty-fourth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg083 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg083_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t fg                           : 4;  /**< Function Group */
+	uint32_t fg                           : 4;  /**< Function group. */
 	uint32_t reserved_18_19               : 2;
-	uint32_t acsfge                       : 1;  /**< ACS Function Groups Enable (A) */
-	uint32_t mfvcfge                      : 1;  /**< MFVC Function Groups Enable (M) */
-	uint32_t nfn                          : 8;  /**< Next Function Number */
+	uint32_t acsfge                       : 1;  /**< ACS function groups enable (A). */
+	uint32_t mfvcfge                      : 1;  /**< MFVC function groups enable (M). */
+	uint32_t nfn                          : 8;  /**< Next function number. */
 	uint32_t reserved_2_7                 : 6;
-	uint32_t acsfgc                       : 1;  /**< ACS Function Groups Capability */
-	uint32_t mfvcfgc                      : 1;  /**< MFVC Function Groups Capability */
+	uint32_t acsfgc                       : 1;  /**< ACS function groups capability. */
+	uint32_t mfvcfgc                      : 1;  /**< MFVC function groups capability. */
 #else
 	uint32_t mfvcfgc                      : 1;
 	uint32_t acsfgc                       : 1;
@@ -1903,29 +1789,22 @@ typedef union cvmx_pcieepvfx_cfg083 cvmx_pcieepvfx_cfg083_t;
 /**
  * cvmx_pcieepvf#_cfg448
  *
- * PCIE_CFG448 = Four hundred forty-ninth 32-bits of PCIE type 0 config space
- * (Ack Latency Timer and Replay Timer Register)
+ * This register contains the four hundred forty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg448 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg448_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t rtl                          : 16; /**< Replay Time Limit
-                                                         The replay timer expires when it reaches this limit. The PCI
-                                                         Express bus initiates a replay upon reception of a Nak or when
-                                                         the replay timer expires.
-                                                         This value will be set correctly by the hardware out of reset
-                                                         or when the negotiated Link-Width or Payload-Size changes. If
-                                                         the user changes this value through a CSR write or by an
-                                                         EEPROM load then they should refer to the PCIe Specification
-                                                         for the correct value. */
-	uint32_t rtltl                        : 16; /**< Round Trip Latency Time Limit
-                                                         The Ack/Nak latency timer expires when it reaches this limit.
-                                                         This value will be set correctly by the hardware out of reset
-                                                         or when the negotiated Link-Width or Payload-Size changes. If
-                                                         the user changes this value through a CSR write or by an
-                                                         EEPROM load then they should refer to the PCIe Specification
-                                                         for the correct value. */
+	uint32_t rtl                          : 16; /**< Replay time limit. The replay timer expires when it reaches this limit. The PCI Express
+                                                         bus initiates a replay upon reception of a nak or when the replay timer expires. This
+                                                         value is set correctly by the hardware out of reset or when the negotiated link width or
+                                                         payload size changes. If the user changes this value through a CSR write or by an EEPROM
+                                                         load, they should refer to the PCIe Specification for the correct value. */
+	uint32_t rtltl                        : 16; /**< Round trip latency time limit. The ack/nak latency timer expires when it reaches this
+                                                         limit. This value is set correctly by the hardware out of reset or when the negotiated
+                                                         link width or payload size changes. If the user changes this value through a CSR write or
+                                                         by an EEPROM load, they should refer to the PCIe specification for the correct value. */
 #else
 	uint32_t rtltl                        : 16;
 	uint32_t rtl                          : 16;
@@ -1938,25 +1817,21 @@ typedef union cvmx_pcieepvfx_cfg448 cvmx_pcieepvfx_cfg448_t;
 /**
  * cvmx_pcieepvf#_cfg449
  *
- * PCIE_CFG449 = Four hundred fiftieth 32-bits of PCIE type 0 config space
- * (Other Message Register)
+ * This register contains the four hundred fiftieth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg449 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg449_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t omr                          : 32; /**< Other Message Register
-                                                         This register can be used for either of the following purposes:
-                                                         o To send a specific PCI Express Message, the application
-                                                         writes the payload of the Message into this register, then
-                                                         sets bit 0 of the Port Link Control Register to send the
-                                                         Message.
-                                                         o To store a corruption pattern for corrupting the LCRC on all
-                                                         TLPs, the application places a 32-bit corruption pattern into
-                                                         this register and enables this function by setting bit 25 of
-                                                         the Port Link Control Register. When enabled, the transmit
-                                                         LCRC result is XOR'd with this pattern before inserting
-                                                         it into the packet. */
+	uint32_t omr                          : 32; /**< Other message register. This register can be used for either of the following purposes:
+                                                         * To send a specific PCI Express message, the application writes the payload of the
+                                                         message into this register, then sets bit 0 of the port link control register to send the
+                                                         message.
+                                                         * To store a corruption pattern for corrupting the LCRC on all TLPs, the application
+                                                         places a 32-bit corruption pattern into this register and enables this function by setting
+                                                         bit 25 of the port link control register. When enabled, the transmit LCRC result is XORed
+                                                         with this pattern before inserting it into the packet. */
 #else
 	uint32_t omr                          : 32;
 #endif
@@ -1968,66 +1843,43 @@ typedef union cvmx_pcieepvfx_cfg449 cvmx_pcieepvfx_cfg449_t;
 /**
  * cvmx_pcieepvf#_cfg450
  *
- * PCIE_CFG450 = Four hundred fifty-first 32-bits of PCIE type 0 config space
- * (Port Force Link Register)
+ * This register contains the four hundred fifty-first 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg450 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg450_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t lpec                         : 8;  /**< Low Power Entrance Count
-                                                         The Power Management state will wait for this many clock cycles
-                                                         for the associated completion of a CfgWr to PCIE_CFG017 register
-                                                         Power State (PS) field register to go low-power. This register
-                                                         is intended for applications that do not let the PCI Express
-                                                         bus handle a completion for configuration request to the
-                                                         Power Management Control and Status (PCIE_CFG017) register. */
+	uint32_t lpec                         : 8;  /**< Low power entrance count. The power management state waits this many clock cycles for the
+                                                         associated completion of a CfgWr to PCIE_CFG017 register, power state (PS) field register
+                                                         to go low-power. This register is intended for applications that do not let the PCI
+                                                         Express bus handle a completion for configuration request to the power management control
+                                                         and status (PCIE_CFG017) register. */
 	uint32_t reserved_22_23               : 2;
-	uint32_t link_state                   : 6;  /**< Link State
-                                                         The Link state that the PCI Express Bus will be forced to
-                                                         when bit 15 (Force Link) is set.
-                                                         State encoding:
-                                                         o DETECT_QUIET              00h
-                                                         o DETECT_ACT                01h
-                                                         o POLL_ACTIVE               02h
-                                                         o POLL_COMPLIANCE           03h
-                                                         o POLL_CONFIG               04h
-                                                         o PRE_DETECT_QUIET          05h
-                                                         o DETECT_WAIT               06h
-                                                         o CFG_LINKWD_START          07h
-                                                         o CFG_LINKWD_ACEPT          08h
-                                                         o CFG_LANENUM_WAIT          09h
-                                                         o CFG_LANENUM_ACEPT         0Ah
-                                                         o CFG_COMPLETE              0Bh
-                                                         o CFG_IDLE                  0Ch
-                                                         o RCVRY_LOCK                0Dh
-                                                         o RCVRY_SPEED               0Eh
-                                                         o RCVRY_RCVRCFG             0Fh
-                                                         o RCVRY_IDLE                10h
-                                                         o L0                        11h
-                                                         o L0S                       12h
-                                                         o L123_SEND_EIDLE           13h
-                                                         o L1_IDLE                   14h
-                                                         o L2_IDLE                   15h
-                                                         o L2_WAKE                   16h
-                                                         o DISABLED_ENTRY            17h
-                                                         o DISABLED_IDLE             18h
-                                                         o DISABLED                  19h
-                                                         o LPBK_ENTRY                1Ah
-                                                         o LPBK_ACTIVE               1Bh
-                                                         o LPBK_EXIT                 1Ch
-                                                         o LPBK_EXIT_TIMEOUT         1Dh
-                                                         o HOT_RESET_ENTRY           1Eh
-                                                         o HOT_RESET                 1Fh */
-	uint32_t force_link                   : 1;  /**< Force Link
-                                                         Forces the Link to the state specified by the Link State field.
-                                                         The Force Link pulse will trigger Link re-negotiation.
-                                                         * As the The Force Link is a pulse, writing a 1 to it does
-                                                         trigger the forced link state event, even thought reading it
-                                                         always returns a 0. */
+	uint32_t link_state                   : 6;  /**< Link state. The link state that the PCI Express bus is forced to when bit 15 (force link)
+                                                         is set. State encoding:
+                                                         0x0: DETECT_QUIET. 0x10: RCVRY_IDLE.
+                                                         0x1: DETECT_ACT. 0x11: L0.
+                                                         0x2: POLL_ACTIVE. 0x12: L0S.
+                                                         0x3: POLL_COMPLIANCE. 0x13: L123_SEND_EIDLE.
+                                                         0x4: POLL_CONFIG. 0x14: L1_IDLE.
+                                                         0x5: PRE_DETECT_QUIET. 0x15: L2_IDLE.
+                                                         0x6: DETECT_WAIT. 0x16: L2_WAKE.
+                                                         0x7: CFG_LINKWD_START. 0x17: DISABLED_ENTRY.
+                                                         0x8: CFG_LINKWD_ACEPT. 0x18: DISABLED_IDLE.
+                                                         0x9: CFG_LANENUM_WAIT. 0x19: DISABLED.
+                                                         0xA: CFG_LANENUM_ACEPT. 0x1A: LPBK_ENTRY.
+                                                         0xB: CFG_COMPLETE. 0x1B: LPBK_ACTIVE.
+                                                         0xC: CFG_IDLE. 0x1C: LPBK_EXIT.
+                                                         0xD: RCVRY_LOCK. 0x1D: LPBK_EXIT_TIMEOUT.
+                                                         0xE: RCVRY_SPEED. 0x1E: HOT_RESET_ENTRY.
+                                                         0xF: RCVRY_RCVRCFG. 0x1F: HOT_RESET. */
+	uint32_t force_link                   : 1;  /**< Force link. Forces the link to the state specified by the LINK_STATE field. The force link
+                                                         pulse triggers link renegotiation.
+                                                         As the force link is a pulse, writing a 1 to it does trigger the forced link state event,
+                                                         even though reading it always returns a 0. */
 	uint32_t reserved_8_14                : 7;
-	uint32_t link_num                     : 8;  /**< Link Number
-                                                         Not used for Endpoint */
+	uint32_t link_num                     : 8;  /**< Link number. Not used for endpoint. */
 #else
 	uint32_t link_num                     : 8;
 	uint32_t reserved_8_14                : 7;
@@ -2044,54 +1896,45 @@ typedef union cvmx_pcieepvfx_cfg450 cvmx_pcieepvfx_cfg450_t;
 /**
  * cvmx_pcieepvf#_cfg451
  *
- * PCIE_CFG451 = Four hundred fifty-second 32-bits of PCIE type 0 config space
- * (Ack Frequency Register)
+ * This register contains the four hundred fifty-second 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg451 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg451_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t easpml1                      : 1;  /**< Enter ASPM L1 without receive in L0s
-                                                         Allow core to enter ASPM L1 even when link partner did
-                                                         not go to L0s (receive is not in L0s).
-                                                         When not set, core goes to ASPM L1 only after idle period
-                                                         during which both receive and transmit are in L0s. */
-	uint32_t l1el                         : 3;  /**< L1 Entrance Latency
-                                                         Values correspond to:
-                                                         o 000: 1 ms
-                                                         o 001: 2 ms
-                                                         o 010: 4 ms
-                                                         o 011: 8 ms
-                                                         o 100: 16 ms
-                                                         o 101: 32 ms
-                                                         o 110 or 111: 64 ms */
-	uint32_t l0el                         : 3;  /**< L0s Entrance Latency
-                                                         Values correspond to:
-                                                         o 000: 1 ms
-                                                         o 001: 2 ms
-                                                         o 010: 3 ms
-                                                         o 011: 4 ms
-                                                         o 100: 5 ms
-                                                         o 101: 6 ms
-                                                         o 110 or 111: 7 ms */
+	uint32_t easpml1                      : 1;  /**< Enter ASPM L1 without receive in L0s. Allow core to enter ASPM L1 even when link partner
+                                                         did not go to L0s (receive is not in L0s). When not set, core goes to ASPM L1 only after
+                                                         idle period, during which both receive and transmit are in L0s. */
+	uint32_t l1el                         : 3;  /**< L1 entrance latency. Values correspond to:
+                                                         0x0 = 1 ms
+                                                         0x1 = 2 ms
+                                                         0x2 = 4 ms
+                                                         0x3 = 8 ms
+                                                         0x4 = 16 ms
+                                                         0x5 = 32 ms
+                                                         0x6 or 0x7 = 64 ms */
+	uint32_t l0el                         : 3;  /**< L0s entrance latency. Values correspond to:
+                                                         0x0 = 1 ms
+                                                         0x1 = 2 ms
+                                                         0x2 = 3 ms
+                                                         0x3 = 4 ms
+                                                         0x4 = 5 ms
+                                                         0x5 = 6 ms
+                                                         0x6 or 0x7 = 7 ms */
 	uint32_t n_fts_cc                     : 8;  /**< N_FTS when common clock is used.
-                                                         The number of Fast Training Sequence ordered sets to be
-                                                         transmitted when transitioning from L0s to L0. The maximum
-                                                         number of FTS ordered-sets that a component can request is 255.
-                                                         Note: A value of zero is not supported; a value of
-                                                         zero can cause the LTSSM to go into the recovery state
-                                                         when exiting from L0s. */
-	uint32_t n_fts                        : 8;  /**< N_FTS
-                                                         The number of Fast Training Sequence ordered sets to be
-                                                         transmitted when transitioning from L0s to L0. The maximum
-                                                         number of FTS ordered-sets that a component can request is 255.
-                                                         Note: A value of zero is not supported; a value of
-                                                         zero can cause the LTSSM to go into the recovery state
-                                                         when exiting from L0s. */
-	uint32_t ack_freq                     : 8;  /**< Ack Frequency
-                                                         The number of pending Ack's specified here (up to 255) before
-                                                         sending an Ack. */
+                                                         The number of fast training sequence (FTS) ordered sets to be transmitted when
+                                                         transitioning from L0s to L0. The maximum number of FTS ordered sets that a component can
+                                                         request is 255.
+                                                         A value of zero is not supported; a value of zero can cause the LTSSM to go into the
+                                                         recovery state when exiting from L0s. */
+	uint32_t n_fts                        : 8;  /**< N_FTS. The number of fast training sequence (FTS) ordered sets to be transmitted when
+                                                         transitioning from L0s to L0. The maximum number of FTS ordered sets that a component can
+                                                         request is 255.
+                                                         A value of zero is not supported; a value of zero can cause the LTSSM to go into the
+                                                         recovery state when exiting from L0s. */
+	uint32_t ack_freq                     : 8;  /**< Ack frequency. The number of pending Acks specified here (up to 255) before sending an Ack. */
 #else
 	uint32_t ack_freq                     : 8;
 	uint32_t n_fts                        : 8;
@@ -2109,59 +1952,47 @@ typedef union cvmx_pcieepvfx_cfg451 cvmx_pcieepvfx_cfg451_t;
 /**
  * cvmx_pcieepvf#_cfg452
  *
- * PCIE_CFG452 = Four hundred fifty-third 32-bits of PCIE type 0 config space
- * (Port Link Control Register)
+ * This register contains the four hundred fifty-third 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg452 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg452_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_22_31               : 10;
-	uint32_t lme                          : 6;  /**< Link Mode Enable
-                                                         o 000001: x1
-                                                         o 000011: x2
-                                                         o 000111: x4
-                                                         o 001111: x8  (not supported)
-                                                         o 011111: x16 (not supported)
-                                                         o 111111: x32 (not supported)
-                                                         This field indicates the MAXIMUM number of lanes supported
-                                                         by the PCIe port. The value can be set less than 0x7
-                                                         to limit the number of lanes the PCIe will attempt to use.
-                                                         If the value of 0xF set by the HW is not desired,
-                                                         this field can be programmed to a smaller value (i.e. EEPROM)
-                                                         See also MLW.
-                                                         (Note: The value of this field does NOT indicate the number
-                                                         of lanes in use by the PCIe. LME sets the max number of lanes
-                                                         in the PCIe core that COULD be used. As per the PCIe specs,
-                                                         the PCIe core can negotiate a smaller link width, so all
-                                                         of x8, x4, x2, and x1 are supported when LME=0xF,
-                                                         for example.) */
+	uint32_t lme                          : 6;  /**< Link mode enable set as follows:
+                                                         000001 (0x1) =  *1
+                                                         000011 (0x3) =  *2
+                                                         000111 (0x7) =  *4
+                                                         001111 (0xF) =  *8 (not supported)
+                                                         011111 (0x1F) =  *16 (not supported)
+                                                         111111 (0x3F) =  *32 (not supported)
+                                                         This field indicates the maximum number of lanes supported by the PCIe port. The value can
+                                                         be set less than 0x7 to limit the number of lanes that the PCIe will attempt to use. If
+                                                         the value of 0xF set by the hardware is not desired, this field can be programmed to a
+                                                         smaller value (i.e. EEPROM). See also PCIEEP(0..3)_CFG031[MLW].
+                                                         The value of this field does not indicate the number of lanes in use by the PCIe. This
+                                                         field sets the maximum number of lanes in the PCIe core that could be used. As per the
+                                                         PCIe specification, the PCIe core can negotiate a smaller link width, so all of *8, *4,
+                                                         *2, and *1 are supported when LME = 0xF, for example. */
 	uint32_t reserved_12_15               : 4;
 	uint32_t link_rate                    : 4;  /**< Reserved. */
-	uint32_t flm                          : 1;  /**< Fast Link Mode
-                                                         Sets all internal timers to fast mode for simulation purposes.
-                                                         If during an eeprom load, the first word loaded is 0xffffffff,
-                                                         then the EEPROM load will be terminated and this bit will be set. */
+	uint32_t flm                          : 1;  /**< Fast link mode. Sets all internal timers to fast mode for simulation purposes. If during
+                                                         an EEPROM load, the first word loaded is 0xFFFFFFFF, the EEPROM load is terminated and
+                                                         this bit is set. */
 	uint32_t reserved_6_6                 : 1;
-	uint32_t dllle                        : 1;  /**< DLL Link Enable
-                                                         Enables Link initialization. If DLL Link Enable = 0, the PCI
-                                                         Express bus does not transmit InitFC DLLPs and does not
-                                                         establish a Link. */
+	uint32_t dllle                        : 1;  /**< DLL link enable. Enables Link initialization. If DLL Link Enable = 0, the PCI Express bus
+                                                         does not transmit InitFC DLLPs and does not establish a Link. */
 	uint32_t reserved_4_4                 : 1;
-	uint32_t ra                           : 1;  /**< Reset Assert
-                                                         Triggers a recovery and forces the LTSSM to the Hot Reset
-                                                         state (downstream port only). */
-	uint32_t le                           : 1;  /**< Loopback Enable
-                                                         Initiate loopback mode as a master. On a 0->1 transition,
-                                                         the PCIe core sends TS ordered sets with the loopback bit set
-                                                         to cause the link partner to enter into loopback mode as a
-                                                         slave. Normal transmission is not possible when LE=1. To exit
-                                                         loopback mode, take the link through a reset sequence. */
-	uint32_t sd                           : 1;  /**< Scramble Disable
-                                                         Turns off data scrambling. */
-	uint32_t omr                          : 1;  /**< Other Message Request
-                                                         When software writes a `1' to this bit, the PCI Express bus
-                                                         transmits the Message contained in the Other Message register. */
+	uint32_t ra                           : 1;  /**< Reset assert. Triggers a recovery and forces the LTSSM to the hot reset state (downstream
+                                                         port only). */
+	uint32_t le                           : 1;  /**< Loopback enable. Initiate loopback mode as a master. On a 0->1 transition, the PCIe core
+                                                         sends TS ordered sets with the loopback bit set to cause the link partner to enter into
+                                                         loopback mode as a slave. Normal transmission is not possible when LE=1. To exit loopback
+                                                         mode, take the link through a reset sequence. */
+	uint32_t sd                           : 1;  /**< Scramble disable. Setting this bit turns off data scrambling. */
+	uint32_t omr                          : 1;  /**< Other message request. When software writes a 1 to this bit, the PCI Express bus transmits
+                                                         the message contained in the other message register. */
 #else
 	uint32_t omr                          : 1;
 	uint32_t sd                           : 1;
@@ -2184,26 +2015,21 @@ typedef union cvmx_pcieepvfx_cfg452 cvmx_pcieepvfx_cfg452_t;
 /**
  * cvmx_pcieepvf#_cfg453
  *
- * PCIE_CFG453 = Four hundred fifty-fourth 32-bits of PCIE type 0 config space
- * (Lane Skew Register)
+ * This register contains the four hundred fifty-fourth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg453 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg453_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t dlld                         : 1;  /**< Disable Lane-to-Lane Deskew
-                                                         Disables the internal Lane-to-Lane deskew logic. */
+	uint32_t dlld                         : 1;  /**< Disable lane-to-lane deskew. Disables the internal lane-to-lane deskew logic. */
 	uint32_t reserved_26_30               : 5;
-	uint32_t ack_nak                      : 1;  /**< Ack/Nak Disable
-                                                         Prevents the PCI Express bus from sending Ack and Nak DLLPs. */
-	uint32_t fcd                          : 1;  /**< Flow Control Disable
-                                                         Prevents the PCI Express bus from sending FC DLLPs. */
-	uint32_t ilst                         : 24; /**< Insert Lane Skew for Transmit
-                                                         Causes skew between lanes for test purposes. There are three
-                                                         bits per Lane. The value is in units of one symbol time. For
-                                                         example, the value 010b for a Lane forces a skew of two symbol
-                                                         times for that Lane. The maximum skew value for any Lane is 5
-                                                         symbol times. */
+	uint32_t ack_nak                      : 1;  /**< Ack/Nak disable. Prevents the PCI Express bus from sending Ack and Nak DLLPs. */
+	uint32_t fcd                          : 1;  /**< Flow control disable. Prevents the PCI Express bus from sending FC DLLPs. */
+	uint32_t ilst                         : 24; /**< Insert lane skew for transmit. Causes skew between lanes for test purposes. There are
+                                                         three bits per lane. The value is in units of one symbol time. For example, the value 010b
+                                                         for a lane forces a skew of two symbol times for that lane. The maximum skew value for any
+                                                         lane is 5 symbol times. */
 #else
 	uint32_t ilst                         : 24;
 	uint32_t fcd                          : 1;
@@ -2219,25 +2045,23 @@ typedef union cvmx_pcieepvfx_cfg453 cvmx_pcieepvfx_cfg453_t;
 /**
  * cvmx_pcieepvf#_cfg454
  *
- * PCIE_CFG454 = Four hundred fifty-fifth 32-bits of PCIE type 0 config space
- * (Symbol Number Register)
+ * This register contains the four hundred fifty-fifth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg454 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg454_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_29_31               : 3;
-	uint32_t tmfcwt                       : 5;  /**< Used to be "Timer Modifier for Flow Control Watchdog Timer"
-                                                         No longer used. Repl and enhanced func moved to "Queue Status"
-                                                         register - CFG463. Kept for now to prevent s/w from breaking. */
-	uint32_t tmanlt                       : 5;  /**< Timer Modifier for Ack/Nak Latency Timer
-                                                         Increases the timer value for the Ack/Nak latency timer, in
+	uint32_t tmfcwt                       : 5;  /**< Used to be "timer modifier for flow control watchdog timer." No longer used. Repl and
+                                                         enhanced func moved to "queue status" register - CFG463. Kept for now to prevent software
+                                                         from breaking. */
+	uint32_t tmanlt                       : 5;  /**< Timer modifier for Ack/Nak latency timer. Increases the timer value for the Ack/Nak
+                                                         latency timer, in increments of 64 clock cycles. */
+	uint32_t tmrt                         : 5;  /**< Timer modifier for replay timer. Increases the timer value for the replay timer, in
                                                          increments of 64 clock cycles. */
-	uint32_t tmrt                         : 5;  /**< Timer Modifier for Replay Timer
-                                                         Increases the timer value for the replay timer, in increments
-                                                         of 64 clock cycles. */
 	uint32_t reserved_8_13                : 6;
-	uint32_t mfuncn                       : 8;  /**< Max Number of Functions Supported */
+	uint32_t mfuncn                       : 8;  /**< Max number of functions supported. */
 #else
 	uint32_t mfuncn                       : 8;
 	uint32_t reserved_8_13                : 6;
@@ -2254,33 +2078,32 @@ typedef union cvmx_pcieepvfx_cfg454 cvmx_pcieepvfx_cfg454_t;
 /**
  * cvmx_pcieepvf#_cfg455
  *
- * PCIE_CFG455 = Four hundred fifty-sixth 32-bits of PCIE type 0 config space
- * (Symbol Timer Register/Filter Mask Register 1)
+ * This register contains the four hundred fifty-sixth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg455 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg455_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t m_cfg0_filt                  : 1;  /**< Mask filtering of received Configuration Requests (RC mode only) */
-	uint32_t m_io_filt                    : 1;  /**< Mask filtering of received I/O Requests (RC mode only) */
-	uint32_t msg_ctrl                     : 1;  /**< Message Control
-                                                         The application must not change this field. */
-	uint32_t m_cpl_ecrc_filt              : 1;  /**< Mask ECRC error filtering for Completions */
-	uint32_t m_ecrc_filt                  : 1;  /**< Mask ECRC error filtering */
-	uint32_t m_cpl_len_err                : 1;  /**< Mask Length mismatch error for received Completions */
-	uint32_t m_cpl_attr_err               : 1;  /**< Mask Attributes mismatch error for received Completions */
-	uint32_t m_cpl_tc_err                 : 1;  /**< Mask Traffic Class mismatch error for received Completions */
-	uint32_t m_cpl_fun_err                : 1;  /**< Mask function mismatch error for received Completions */
-	uint32_t m_cpl_rid_err                : 1;  /**< Mask Requester ID mismatch error for received Completions */
-	uint32_t m_cpl_tag_err                : 1;  /**< Mask Tag error rules for received Completions */
-	uint32_t m_lk_filt                    : 1;  /**< Mask Locked Request filtering */
-	uint32_t m_cfg1_filt                  : 1;  /**< Mask Type 1 Configuration Request filtering */
-	uint32_t m_bar_match                  : 1;  /**< Mask BAR match filtering */
-	uint32_t m_pois_filt                  : 1;  /**< Mask poisoned TLP filtering */
-	uint32_t m_fun                        : 1;  /**< Mask function */
-	uint32_t dfcwt                        : 1;  /**< Disable FC Watchdog Timer */
+	uint32_t m_cfg0_filt                  : 1;  /**< Mask filtering of received configuration requests (RC mode only). */
+	uint32_t m_io_filt                    : 1;  /**< Mask filtering of received I/O requests (RC mode only). */
+	uint32_t msg_ctrl                     : 1;  /**< Message control. The application must not change this field. */
+	uint32_t m_cpl_ecrc_filt              : 1;  /**< Mask ECRC error filtering for completions. */
+	uint32_t m_ecrc_filt                  : 1;  /**< Mask ECRC error filtering. */
+	uint32_t m_cpl_len_err                : 1;  /**< Mask length mismatch error for received completions. */
+	uint32_t m_cpl_attr_err               : 1;  /**< Mask attributes mismatch error for received completions. */
+	uint32_t m_cpl_tc_err                 : 1;  /**< Mask traffic class mismatch error for received completions. */
+	uint32_t m_cpl_fun_err                : 1;  /**< Mask function mismatch error for received completions. */
+	uint32_t m_cpl_rid_err                : 1;  /**< Mask requester ID mismatch error for received completions. */
+	uint32_t m_cpl_tag_err                : 1;  /**< Mask tag error rules for received completions. */
+	uint32_t m_lk_filt                    : 1;  /**< Mask locked request filtering. */
+	uint32_t m_cfg1_filt                  : 1;  /**< Mask Type 1 configuration request filtering */
+	uint32_t m_bar_match                  : 1;  /**< Mask BAR match filtering. */
+	uint32_t m_pois_filt                  : 1;  /**< Mask poisoned TLP filtering. */
+	uint32_t m_fun                        : 1;  /**< Mask function. */
+	uint32_t dfcwt                        : 1;  /**< Disable FC watchdog timer. */
 	uint32_t reserved_11_14               : 4;
-	uint32_t skpiv                        : 11; /**< SKP Interval Value */
+	uint32_t skpiv                        : 11; /**< SKP interval value. */
 #else
 	uint32_t skpiv                        : 11;
 	uint32_t reserved_11_14               : 4;
@@ -2310,18 +2133,18 @@ typedef union cvmx_pcieepvfx_cfg455 cvmx_pcieepvfx_cfg455_t;
 /**
  * cvmx_pcieepvf#_cfg456
  *
- * PCIE_CFG456 = Four hundred fifty-seventh 32-bits of PCIE type 0 config space
- * (Filter Mask Register 2)
+ * This register contains the four hundred fifty-seventh 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg456 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg456_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_4_31                : 28;
-	uint32_t m_handle_flush               : 1;  /**< Mask Core Filter to handle flush request */
+	uint32_t m_handle_flush               : 1;  /**< Mask core filter to handle flush request. */
 	uint32_t m_dabort_4ucpl               : 1;  /**< Mask DLLP abort for unexpected CPL */
-	uint32_t m_vend1_drp                  : 1;  /**< Mask Vendor MSG Type 1 dropped silently */
-	uint32_t m_vend0_drp                  : 1;  /**< Mask Vendor MSG Type 0 dropped with UR error reporting. */
+	uint32_t m_vend1_drp                  : 1;  /**< Mask vendor MSG Type 1 dropped silently. */
+	uint32_t m_vend0_drp                  : 1;  /**< Mask vendor MSG Type 0 dropped with UR error reporting. */
 #else
 	uint32_t m_vend0_drp                  : 1;
 	uint32_t m_vend1_drp                  : 1;
@@ -2337,14 +2160,14 @@ typedef union cvmx_pcieepvfx_cfg456 cvmx_pcieepvfx_cfg456_t;
 /**
  * cvmx_pcieepvf#_cfg458
  *
- * PCIE_CFG458 = Four hundred fifty-ninth 32-bits of PCIE type 0 config space
- * (Debug Register 0)
+ * This register contains the four hundred fifty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg458 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg458_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t dbg_info_l32                 : 32; /**< Debug Info Lower 32 Bits */
+	uint32_t dbg_info_l32                 : 32; /**< Debug info lower 32 bits. */
 #else
 	uint32_t dbg_info_l32                 : 32;
 #endif
@@ -2356,14 +2179,14 @@ typedef union cvmx_pcieepvfx_cfg458 cvmx_pcieepvfx_cfg458_t;
 /**
  * cvmx_pcieepvf#_cfg459
  *
- * PCIE_CFG459 = Four hundred sixtieth 32-bits of PCIE type 0 config space
- * (Debug Register 1)
+ * This register contains the four hundred sixtieth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg459 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg459_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t dbg_info_u32                 : 32; /**< Debug Info Upper 32 Bits */
+	uint32_t dbg_info_u32                 : 32; /**< Debug info upper 32 bits. */
 #else
 	uint32_t dbg_info_u32                 : 32;
 #endif
@@ -2375,20 +2198,18 @@ typedef union cvmx_pcieepvfx_cfg459 cvmx_pcieepvfx_cfg459_t;
 /**
  * cvmx_pcieepvf#_cfg460
  *
- * PCIE_CFG460 = Four hundred sixty-first 32-bits of PCIE type 0 config space
- * (Transmit Posted FC Credit Status)
+ * This register contains the four hundred sixty-first 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg460 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg460_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_20_31               : 12;
-	uint32_t tphfcc                       : 8;  /**< Transmit Posted Header FC Credits
-                                                         The Posted Header credits advertised by the receiver at the
-                                                         other end of the Link, updated with each UpdateFC DLLP. */
-	uint32_t tpdfcc                       : 12; /**< Transmit Posted Data FC Credits
-                                                         The Posted Data credits advertised by the receiver at the other
-                                                         end of the Link, updated with each UpdateFC DLLP. */
+	uint32_t tphfcc                       : 8;  /**< Transmit posted header FC Credits. The posted header credits advertised by the receiver at
+                                                         the other end of the link, updated with each UpdateFC DLLP. */
+	uint32_t tpdfcc                       : 12; /**< Transmit posted data FC credits. The posted data credits advertised by the receiver at the
+                                                         other end of the link, updated with each UpdateFC DLLP. */
 #else
 	uint32_t tpdfcc                       : 12;
 	uint32_t tphfcc                       : 8;
@@ -2402,20 +2223,18 @@ typedef union cvmx_pcieepvfx_cfg460 cvmx_pcieepvfx_cfg460_t;
 /**
  * cvmx_pcieepvf#_cfg461
  *
- * PCIE_CFG461 = Four hundred sixty-second 32-bits of PCIE type 0 config space
- * (Transmit Non-Posted FC Credit Status)
+ * This register contains the four hundred sixty-second 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg461 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg461_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_20_31               : 12;
-	uint32_t tchfcc                       : 8;  /**< Transmit Non-Posted Header FC Credits
-                                                         The Non-Posted Header credits advertised by the receiver at the
-                                                         other end of the Link, updated with each UpdateFC DLLP. */
-	uint32_t tcdfcc                       : 12; /**< Transmit Non-Posted Data FC Credits
-                                                         The Non-Posted Data credits advertised by the receiver at the
-                                                         other end of the Link, updated with each UpdateFC DLLP. */
+	uint32_t tchfcc                       : 8;  /**< Transmit nonposted header FC credits. The nonposted header credits advertised by the
+                                                         receiver at the other end of the link, updated with each UpdateFC DLLP. */
+	uint32_t tcdfcc                       : 12; /**< Transmit nonposted data FC credits. The nonposted data credits advertised by the receiver
+                                                         at the other end of the link, updated with each UpdateFC DLLP. */
 #else
 	uint32_t tcdfcc                       : 12;
 	uint32_t tchfcc                       : 8;
@@ -2429,20 +2248,18 @@ typedef union cvmx_pcieepvfx_cfg461 cvmx_pcieepvfx_cfg461_t;
 /**
  * cvmx_pcieepvf#_cfg462
  *
- * PCIE_CFG462 = Four hundred sixty-third 32-bits of PCIE type 0 config space
- * (Transmit Completion FC Credit Status )
+ * This register contains the four hundred sixty-third 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg462 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg462_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_20_31               : 12;
-	uint32_t tchfcc                       : 8;  /**< Transmit Completion Header FC Credits
-                                                         The Completion Header credits advertised by the receiver at the
-                                                         other end of the Link, updated with each UpdateFC DLLP. */
-	uint32_t tcdfcc                       : 12; /**< Transmit Completion Data FC Credits
-                                                         The Completion Data credits advertised by the receiver at the
-                                                         other end of the Link, updated with each UpdateFC DLLP. */
+	uint32_t tchfcc                       : 8;  /**< Transmit completion header FC credits. The completion header credits advertised by the
+                                                         receiver at the other end of the link, updated with each UpdateFC DLLP. */
+	uint32_t tcdfcc                       : 12; /**< Transmit completion data FC credits. The completion data credits advertised by the
+                                                         receiver at the other end of the link, updated with each UpdateFC DLLP. */
 #else
 	uint32_t tcdfcc                       : 12;
 	uint32_t tchfcc                       : 8;
@@ -2456,32 +2273,26 @@ typedef union cvmx_pcieepvfx_cfg462 cvmx_pcieepvfx_cfg462_t;
 /**
  * cvmx_pcieepvf#_cfg463
  *
- * PCIE_CFG463 = Four hundred sixty-fourth 32-bits of PCIE type 0 config space
- * (Queue Status)
+ * This register contains the four hundred sixty-fourth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg463 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg463_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t fcltoe                       : 1;  /**< FC Latency Timer Override Enable
-                                                         When this bit is set, the value from the "FC Latency Timer Override
-                                                         Value" field in this register will override the FC latency timer
-                                                         value that the core calculates according to the PCIe specification. */
+	uint32_t fcltoe                       : 1;  /**< FC latency timer override enable. When this bit is set, the value from
+                                                         PCIEEPVF(0..3)_CFG463[FCLTOV] will override the FC latency timer value that the core
+                                                         calculates according to the PCIe specification. */
 	uint32_t reserved_29_30               : 2;
-	uint32_t fcltov                       : 13; /**< FC Latency Timer Override Value
-                                                         When you set the "FC Latency Timer Override Enable" in this register,
-                                                         the value in this field will override the FC latency timer value
-                                                         that the core calculates according to the PCIe specification. */
+	uint32_t fcltov                       : 13; /**< FC latency timer override value. When you set
+                                                         PCIEEPVF(0..3)_CFG463[FCLTOE], the value in this field will override the FC latency timer
+                                                         value that the core calculates according to the PCIe specification. */
 	uint32_t reserved_3_15                : 13;
-	uint32_t rqne                         : 1;  /**< Received Queue Not Empty
-                                                         Indicates there is data in one or more of the receive buffers. */
-	uint32_t trbne                        : 1;  /**< Transmit Retry Buffer Not Empty
-                                                         Indicates that there is data in the transmit retry buffer. */
-	uint32_t rtlpfccnr                    : 1;  /**< Received TLP FC Credits Not Returned
-                                                         Indicates that the PCI Express bus has sent a TLP but has not
-                                                         yet received an UpdateFC DLLP indicating that the credits for
-                                                         that TLP have been restored by the receiver at the other end of
-                                                         the Link. */
+	uint32_t rqne                         : 1;  /**< Received queue not empty. Indicates there is data in one or more of the receive buffers. */
+	uint32_t trbne                        : 1;  /**< Transmit retry buffer not empty. Indicates that there is data in the transmit retry buffer. */
+	uint32_t rtlpfccnr                    : 1;  /**< Received TLP FC credits not returned. Indicates that the PCI Express bus has sent a TLP
+                                                         but has not yet received an UpdateFC DLLP indicating that the credits for that TLP have
+                                                         been restored by the receiver at the other end of the link. */
 #else
 	uint32_t rtlpfccnr                    : 1;
 	uint32_t trbne                        : 1;
@@ -2499,17 +2310,17 @@ typedef union cvmx_pcieepvfx_cfg463 cvmx_pcieepvfx_cfg463_t;
 /**
  * cvmx_pcieepvf#_cfg464
  *
- * PCIE_CFG464 = Four hundred sixty-fifth 32-bits of PCIE type 0 config space
- * (VC Transmit Arbitration Register 1)
+ * This register contains the four hundred sixty-fifth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg464 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg464_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t wrr_vc3                      : 8;  /**< WRR Weight for VC3 */
-	uint32_t wrr_vc2                      : 8;  /**< WRR Weight for VC2 */
-	uint32_t wrr_vc1                      : 8;  /**< WRR Weight for VC1 */
-	uint32_t wrr_vc0                      : 8;  /**< WRR Weight for VC0 */
+	uint32_t wrr_vc3                      : 8;  /**< WRR Weight for VC3. */
+	uint32_t wrr_vc2                      : 8;  /**< WRR Weight for VC2. */
+	uint32_t wrr_vc1                      : 8;  /**< WRR Weight for VC1. */
+	uint32_t wrr_vc0                      : 8;  /**< WRR Weight for VC0. */
 #else
 	uint32_t wrr_vc0                      : 8;
 	uint32_t wrr_vc1                      : 8;
@@ -2524,17 +2335,17 @@ typedef union cvmx_pcieepvfx_cfg464 cvmx_pcieepvfx_cfg464_t;
 /**
  * cvmx_pcieepvf#_cfg465
  *
- * PCIE_CFG465 = Four hundred sixty-sixth 32-bits of PCIE type 0 config space
- * (VC Transmit Arbitration Register 2)
+ * This register contains the four hundred sixty-sixth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg465 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg465_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t wrr_vc7                      : 8;  /**< WRR Weight for VC7 */
-	uint32_t wrr_vc6                      : 8;  /**< WRR Weight for VC6 */
-	uint32_t wrr_vc5                      : 8;  /**< WRR Weight for VC5 */
-	uint32_t wrr_vc4                      : 8;  /**< WRR Weight for VC4 */
+	uint32_t wrr_vc7                      : 8;  /**< WRR Weight for VC7. */
+	uint32_t wrr_vc6                      : 8;  /**< WRR Weight for VC6. */
+	uint32_t wrr_vc5                      : 8;  /**< WRR Weight for VC5. */
+	uint32_t wrr_vc4                      : 8;  /**< WRR Weight for VC4. */
 #else
 	uint32_t wrr_vc4                      : 8;
 	uint32_t wrr_vc5                      : 8;
@@ -2549,50 +2360,34 @@ typedef union cvmx_pcieepvfx_cfg465 cvmx_pcieepvfx_cfg465_t;
 /**
  * cvmx_pcieepvf#_cfg466
  *
- * PCIE_CFG466 = Four hundred sixty-seventh 32-bits of PCIE type 0 config space
- * (VC0 Posted Receive Queue Control)
+ * This register contains the four hundred sixty-seventh 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg466 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg466_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t rx_queue_order               : 1;  /**< "VC Ordering for Receive Queues
-                                                         Determines the VC ordering rule for the receive queues, used
-                                                         only in the segmented-buffer configuration,
-                                                         writable through PEM#_CFG_WR:
-                                                         o 1: Strict ordering, higher numbered VCs have higher priority
-                                                         o 0: Round robin
-                                                         However, the application must not change this field." */
-	uint32_t type_ordering                : 1;  /**< "TLP Type Ordering for VC0
-                                                         Determines the TLP type ordering rule for VC0 receive queues,
-                                                         used only in the segmented-buffer configuration,
-                                                         through PEM#_CFG_WR:
-                                                         o 1: Ordering of received TLPs follows the rules in
-                                                         PCI Express Base Specification
-                                                         o 0: Strict ordering for received TLPs: Posted, then
-                                                         Completion, then Non-Posted
-                                                         However, the application must not change this field." */
+	uint32_t rx_queue_order               : 1;  /**< VC ordering for receive queues. Determines the VC ordering rule for the receive queues,
+                                                         used only in the segmented-buffer configuration, writable through PEM(0..3)_CFG_WR:
+                                                         0 = Round robin.
+                                                         1 = Strict ordering, higher numbered VCs have higher priority. */
+	uint32_t type_ordering                : 1;  /**< TLP type ordering for VC0. Determines the TLP type ordering rule for VC0 receive queues,
+                                                         used only in the segmented-buffer configuration:
+                                                         0 = Strict ordering for received TLPs: Posted, then Completion, then Nonposted.
+                                                         1 = Ordering of received TLPs follows the rules in PCI Express Base Specification */
 	uint32_t reserved_24_29               : 6;
-	uint32_t queue_mode                   : 3;  /**< "VC0 Posted TLP Queue Mode
-                                                         The operating mode of the Posted receive queue for VC0, used
-                                                         only in the segmented-buffer configuration, writable through
-                                                         PEM#_CFG_WR.
+	uint32_t queue_mode                   : 3;  /**< VC0 posted TLP queue mode. The operating mode of the posted receive queue for VC0, used
+                                                         only in the segmented-buffer configuration, writable through PEM(0..3)_CFG_WR.
                                                          However, the application must not change this field.
                                                          Only one bit can be set at a time:
-                                                         o Bit 23: Bypass
-                                                         o Bit 22: Cut-through
-                                                         o Bit 21: Store-and-forward" */
+                                                         Bit 23 = Bypass
+                                                         Bit 22 = Cut-through
+                                                         Bit 21 = Store-and-forward */
 	uint32_t reserved_20_20               : 1;
-	uint32_t header_credits               : 8;  /**< "VC0 Posted Header Credits
-                                                         The number of initial Posted header credits for VC0, used for
-                                                         all receive queue buffer configurations.
-                                                         This field is writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t data_credits                 : 12; /**< "VC0 Posted Data Credits
-                                                         The number of initial Posted data credits for VC0, used for all
-                                                         receive queue buffer configurations.
-                                                         This field is writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t header_credits               : 8;  /**< VC0 posted header credits. The number of initial posted header credits for VC0, used for
+                                                         all receive queue buffer configurations. */
+	uint32_t data_credits                 : 12; /**< VC0 posted data credits. The number of initial posted data credits for VC0, used for all
+                                                         receive queue buffer configurations. */
 #else
 	uint32_t data_credits                 : 12;
 	uint32_t header_credits               : 8;
@@ -2610,34 +2405,28 @@ typedef union cvmx_pcieepvfx_cfg466 cvmx_pcieepvfx_cfg466_t;
 /**
  * cvmx_pcieepvf#_cfg467
  *
- * PCIE_CFG467 = Four hundred sixty-eighth 32-bits of PCIE type 0 config space
- * (VC0 Non-Posted Receive Queue Control)
+ * This register contains the four hundred sixty-eighth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg467 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg467_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t queue_mode                   : 3;  /**< "VC0 Non-Posted TLP Queue Mode
-                                                         The operating mode of the Non-Posted receive queue for VC0,
-                                                         used only in the segmented-buffer configuration, writable
-                                                         through PEM#_CFG_WR.
+	uint32_t queue_mode                   : 3;  /**< VC0 nonposted TLP queue mode. The operating mode of the nonposted receive queue for VC0,
+                                                         used only in the segmented-buffer configuration. This field is writable through
+                                                         PEM(0..3)_CFG_WR. However, the application must not change this field.
                                                          Only one bit can be set at a time:
-                                                         o Bit 23: Bypass
-                                                         o Bit 22: Cut-through
-                                                         o Bit 21: Store-and-forward
-                                                         However, the application must not change this field." */
+                                                         Bit 23 = Bypass
+                                                         Bit 22 = Cut-through
+                                                         Bit 21 = Store-and-forward */
 	uint32_t reserved_20_20               : 1;
-	uint32_t header_credits               : 8;  /**< "VC0 Non-Posted Header Credits
-                                                         The number of initial Non-Posted header credits for VC0, used
-                                                         for all receive queue buffer configurations.
-                                                         This field is writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t data_credits                 : 12; /**< "VC0 Non-Posted Data Credits
-                                                         The number of initial Non-Posted data credits for VC0, used for
-                                                         all receive queue buffer configurations.
-                                                         This field is writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t header_credits               : 8;  /**< VC0 nonposted header credits. The number of initial nonposted header credits for VC0, used
+                                                         for all receive queue buffer configurations. This field is writable through
+                                                         PEM(0..3)_CFG_WR. However, the application must not change this field. */
+	uint32_t data_credits                 : 12; /**< VC0 non-posted data credits. The number of initial nonposted data credits for VC0, used
+                                                         for all receive queue buffer configurations. This field is writable through
+                                                         PEM(0..3)_CFG_WR. However, the application must not change this field. */
 #else
 	uint32_t data_credits                 : 12;
 	uint32_t header_credits               : 8;
@@ -2653,34 +2442,29 @@ typedef union cvmx_pcieepvfx_cfg467 cvmx_pcieepvfx_cfg467_t;
 /**
  * cvmx_pcieepvf#_cfg468
  *
- * PCIE_CFG468 = Four hundred sixty-ninth 32-bits of PCIE type 0 config space
- * (VC0 Completion Receive Queue Control)
+ * This register contains the four hundred sixty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg468 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg468_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t queue_mode                   : 3;  /**< "VC0 Completion TLP Queue Mode
-                                                         The operating mode of the Completion receive queue for VC0,
-                                                         used only in the segmented-buffer configuration, writable
-                                                         through PEM#_CFG_WR.
+	uint32_t queue_mode                   : 3;  /**< VC0 completion TLP queue mode. The operating mode of the completion receive queue for VC0,
+                                                         used only in the segmented-buffer configuration.
                                                          Only one bit can be set at a time:
-                                                         o Bit 23: Bypass
-                                                         o Bit 22: Cut-through
-                                                         o Bit 21: Store-and-forward
-                                                         However, the application must not change this field." */
+                                                         Bit 23 = Bypass
+                                                         Bit 22 = Cut-through
+                                                         Bit 21 = Store-and-forward
+                                                         This field is writable through PEM(0..3)_CFG_WR. However, the application must not change
+                                                         this field. */
 	uint32_t reserved_20_20               : 1;
-	uint32_t header_credits               : 8;  /**< "VC0 Completion Header Credits
-                                                         The number of initial Completion header credits for VC0, used
-                                                         for all receive queue buffer configurations.
-                                                         This field is writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t data_credits                 : 12; /**< "VC0 Completion Data Credits
-                                                         The number of initial Completion data credits for VC0, used for
-                                                         all receive queue buffer configurations.
-                                                         This field is writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t header_credits               : 8;  /**< VC0 completion header credits. The number of initial completion header credits for VC0,
+                                                         used for all receive queue buffer configurations. This field is writable through
+                                                         PEM(0..3)_CFG_WR. However, the application must not change this field. */
+	uint32_t data_credits                 : 12; /**< VC0 completion data credits. The number of initial completion data credits for VC0, used
+                                                         for all receive queue buffer configurations. This field is writable through
+                                                         PEM(0..3)_CFG_WR. However, the application must not change this field. */
 #else
 	uint32_t data_credits                 : 12;
 	uint32_t header_credits               : 8;
@@ -2696,21 +2480,19 @@ typedef union cvmx_pcieepvfx_cfg468 cvmx_pcieepvfx_cfg468_t;
 /**
  * cvmx_pcieepvf#_cfg490
  *
- * PCIE_CFG490 = Four hundred ninety-first 32-bits of PCIE type 0 config space
- * (VC0 Posted Buffer Depth)
+ * This register contains the four hundred ninety-first 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg490 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg490_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t header_depth                 : 10; /**< VC0 Posted Header Queue Depth
-                                                         Sets the number of entries in the Posted header queue for VC0
-                                                         when using the segmented-buffer configuration */
+	uint32_t header_depth                 : 10; /**< VC0 posted header queue depth. Sets the number of entries in the posted header queue for
+                                                         VC0 when using the segmented-buffer configuration. */
 	uint32_t reserved_14_15               : 2;
-	uint32_t data_depth                   : 14; /**< VC0 Posted Data Queue Depth
-                                                         Sets the number of entries in the Posted data queue for VC0
-                                                         when using the segmented-buffer configuration */
+	uint32_t data_depth                   : 14; /**< VC0 posted data queue depth. Sets the number of entries in the posted data queue for VC0
+                                                         when using the segmented-buffer configuration. */
 #else
 	uint32_t data_depth                   : 14;
 	uint32_t reserved_14_15               : 2;
@@ -2725,21 +2507,19 @@ typedef union cvmx_pcieepvfx_cfg490 cvmx_pcieepvfx_cfg490_t;
 /**
  * cvmx_pcieepvf#_cfg491
  *
- * PCIE_CFG491 = Four hundred ninety-second 32-bits of PCIE type 0 config space
- * (VC0 Non-Posted Buffer Depth)
+ * This register contains the four hundred ninety-second 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg491 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg491_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t header_depth                 : 10; /**< VC0 Non-Posted Header Queue Depth
-                                                         Sets the number of entries in the Non-Posted header queue for
-                                                         VC0 when using the segmented-buffer configuration */
+	uint32_t header_depth                 : 10; /**< VC0 nonposted header queue depth. Sets the number of entries in the nonposted header queue
+                                                         for VC0 when using the segmented-buffer configuration. */
 	uint32_t reserved_14_15               : 2;
-	uint32_t data_depth                   : 14; /**< VC0 Non-Posted Data Queue Depth
-                                                         Sets the number of entries in the Non-Posted data queue for VC0
-                                                         when using the segmented-buffer configuration */
+	uint32_t data_depth                   : 14; /**< VC0 nonposted data queue depth. Sets the number of entries in the nonposted data queue for
+                                                         VC0 when using the segmented-buffer configuration. */
 #else
 	uint32_t data_depth                   : 14;
 	uint32_t reserved_14_15               : 2;
@@ -2754,21 +2534,19 @@ typedef union cvmx_pcieepvfx_cfg491 cvmx_pcieepvfx_cfg491_t;
 /**
  * cvmx_pcieepvf#_cfg492
  *
- * PCIE_CFG492 = Four hundred ninety-third 32-bits of PCIE type 0 config space
- * (VC0 Completion Buffer Depth)
+ * This register contains the four hundred ninety-third 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg492 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg492_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t header_depth                 : 10; /**< VC0 Completion Header Queue Depth
-                                                         Sets the number of entries in the Completion header queue for
-                                                         VC0 when using the segmented-buffer configuration */
+	uint32_t header_depth                 : 10; /**< VC0 completion header queue depth. Sets the number of entries in the completion header
+                                                         queue for VC0 when using the segmented-buffer configuration. */
 	uint32_t reserved_14_15               : 2;
-	uint32_t data_depth                   : 14; /**< VC0 Completion Data Queue Depth
-                                                         Sets the number of entries in the Completion data queue for VC0
-                                                         when using the segmented-buffer configuration */
+	uint32_t data_depth                   : 14; /**< VC0 completion data queue depth. Sets the number of entries in the completion data queue
+                                                         for VC0 when using the segmented-buffer configuration. */
 #else
 	uint32_t data_depth                   : 14;
 	uint32_t reserved_14_15               : 2;
@@ -2783,40 +2561,29 @@ typedef union cvmx_pcieepvfx_cfg492 cvmx_pcieepvfx_cfg492_t;
 /**
  * cvmx_pcieepvf#_cfg515
  *
- * PCIE_CFG515 = Five hundred sixteenth 32-bits of PCIE type 0 config space
- * (Port Logic Register (Gen2))
+ * This register contains the five hundred sixteenth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg515 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg515_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_21_31               : 11;
-	uint32_t s_d_e                        : 1;  /**< SEL_DE_EMPHASIS
-                                                         Used to set the de-emphasis level for upstream ports. */
-	uint32_t ctcrb                        : 1;  /**< Config Tx Compliance Receive Bit
-                                                         When set to 1, signals LTSSM to transmit TS ordered sets
+	uint32_t s_d_e                        : 1;  /**< SEL_DE_EMPHASIS. Used to set the deemphasis level for upstream ports. */
+	uint32_t ctcrb                        : 1;  /**< Config Tx compliance receive bit. When set to 1, signals LTSSM to transmit TS ordered sets
                                                          with the compliance receive bit assert (equal to 1). */
-	uint32_t cpyts                        : 1;  /**< Config PHY Tx Swing
-                                                         Indicates the voltage level the PHY should drive. When set to
-                                                         1, indicates Full Swing. When set to 0, indicates Low Swing */
-	uint32_t dsc                          : 1;  /**< Directed Speed Change
-                                                         o a write of '1' will initiate a speed change
-                                                         o always reads a zero */
-	uint32_t le                           : 9;  /**< Lane Enable
-                                                         Indicates the number of lanes to check for exit from electrical
-                                                         idle in Polling.Active and Polling.Compliance. 1 = x1, 2 = x2,
-                                                         etc. Used to limit the maximum link width to ignore broken
-                                                         lanes that detect a receiver, but will not exit electrical
-                                                         idle and
-                                                         would otherwise prevent a valid link from being configured. */
-	uint32_t n_fts                        : 8;  /**< N_FTS
-                                                         Sets the Number of Fast Training Sequences (N_FTS) that
-                                                         the core advertises as its N_FTS during GEN2 Link training.
-                                                         This value is used to inform the Link partner about the PHYs
-                                                         ability to recover synchronization after a low power state.
-                                                         Note: Do not set N_FTS to zero; doing so can cause the
-                                                         LTSSM to go into the recovery state when exiting from
-                                                         L0s. */
+	uint32_t cpyts                        : 1;  /**< Config PHY Tx swing. Indicates the voltage level that the PHY should drive. When set to 1,
+                                                         indicates full swing. When set to 0, indicates low swing. */
+	uint32_t dsc                          : 1;  /**< Directed speed change. A write of 1 initiates a speed change; always reads as zero. */
+	uint32_t le                           : 9;  /**< Lane enable. Indicates the number of lanes to check for exit from electrical idle in
+                                                         Polling.Active and Polling.Compliance. 0x1 = *1, 0x2 = *2, etc. Used to limit the maximum
+                                                         link width to ignore broken lanes that detect a receiver, but will not exit electrical
+                                                         idle and would otherwise prevent a valid link from being configured. */
+	uint32_t n_fts                        : 8;  /**< N_FTS. Sets the number of fast training sequences (N_FTS) that the core advertises as its
+                                                         N_FTS during GEN2 Link training. This value is used to inform the link partner about the
+                                                         PHY's ability to recover synchronization after a low power state.
+                                                         Do not set N_FTS to zero; doing so can cause the LTSSM to go into the recovery state when
+                                                         exiting from L0s. */
 #else
 	uint32_t n_fts                        : 8;
 	uint32_t le                           : 9;
@@ -2834,14 +2601,14 @@ typedef union cvmx_pcieepvfx_cfg515 cvmx_pcieepvfx_cfg515_t;
 /**
  * cvmx_pcieepvf#_cfg516
  *
- * PCIE_CFG516 = Five hundred seventeenth 32-bits of PCIE type 0 config space
- * (PHY Status Register)
+ * This register contains the five hundred seventeenth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg516 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg516_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t phy_stat                     : 32; /**< PHY Status */
+	uint32_t phy_stat                     : 32; /**< PHY status. */
 #else
 	uint32_t phy_stat                     : 32;
 #endif
@@ -2853,14 +2620,14 @@ typedef union cvmx_pcieepvfx_cfg516 cvmx_pcieepvfx_cfg516_t;
 /**
  * cvmx_pcieepvf#_cfg517
  *
- * PCIE_CFG517 = Five hundred eighteenth 32-bits of PCIE type 0 config space
- * (PHY Control Register)
+ * This register contains the five hundred eighteenth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepvfx_cfg517 {
 	uint32_t u32;
 	struct cvmx_pcieepvfx_cfg517_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t phy_ctrl                     : 32; /**< PHY Control */
+	uint32_t phy_ctrl                     : 32; /**< PHY control. */
 #else
 	uint32_t phy_ctrl                     : 32;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
index 624cb7d..d4c1521 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
@@ -4204,7 +4204,7 @@ static inline uint64_t CVMX_PCIEEPX_CFG558(unsigned long block_id)
 /**
  * cvmx_pcieep#_cfg000
  *
- * PCIE_CFG000 = First 32-bits of PCIE type 0 config space (Device ID and Vendor ID Register)
+ * This register contains the first 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg000 {
@@ -4245,7 +4245,7 @@ typedef union cvmx_pcieepx_cfg000 cvmx_pcieepx_cfg000_t;
 /**
  * cvmx_pcieep#_cfg001
  *
- * PCIE_CFG001 = Second 32-bits of PCIE type 0 config space (Command/Status Register)
+ * This register contains the second 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg001 {
@@ -4332,7 +4332,7 @@ typedef union cvmx_pcieepx_cfg001 cvmx_pcieepx_cfg001_t;
 /**
  * cvmx_pcieep#_cfg002
  *
- * PCIE_CFG002 = Third 32-bits of PCIE type 0 config space (Revision ID/Class Code Register)
+ * This register contains the third 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg002 {
@@ -4373,8 +4373,8 @@ typedef union cvmx_pcieepx_cfg002 cvmx_pcieepx_cfg002_t;
 /**
  * cvmx_pcieep#_cfg003
  *
- * PCIE_CFG003 = Fourth 32-bits of PCIE type 0 config space (Cache Line Size/Master Latency
- * Timer/Header Type Register/BIST Register)
+ * This register contains the fourth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg003 {
 	uint32_t u32;
@@ -4423,7 +4423,7 @@ typedef union cvmx_pcieepx_cfg003 cvmx_pcieepx_cfg003_t;
 /**
  * cvmx_pcieep#_cfg004
  *
- * PCIE_CFG004 = Fifth 32-bits of PCIE type 0 config space (Base Address Register 0 - Low)
+ * This register contains the fifth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepx_cfg004 {
@@ -4472,9 +4472,8 @@ typedef union cvmx_pcieepx_cfg004 cvmx_pcieepx_cfg004_t;
 /**
  * cvmx_pcieep#_cfg004_mask
  *
- * "PCIE_CFG004_MASK (BAR Mask 0 - Low)
  * The BAR 0 Mask register is invisible to host software and not readable from the application.
- * The BAR 0 Mask register is only writable through PEM#_CFG_WR."
+ * The BAR 0 Mask register is only writable through PEM(0..3)_CFG_WR.
  */
 union cvmx_pcieepx_cfg004_mask {
 	uint32_t u32;
@@ -4512,7 +4511,7 @@ typedef union cvmx_pcieepx_cfg004_mask cvmx_pcieepx_cfg004_mask_t;
 /**
  * cvmx_pcieep#_cfg005
  *
- * PCIE_CFG005 = Sixth 32-bits of PCIE type 0 config space (Base Address Register 0 - High)
+ * This register contains the sixth 32-bits of type 0 PCIe configuration space.
  *
  */
 union cvmx_pcieepx_cfg005 {
@@ -4543,9 +4542,8 @@ typedef union cvmx_pcieepx_cfg005 cvmx_pcieepx_cfg005_t;
 /**
  * cvmx_pcieep#_cfg005_mask
  *
- * "PCIE_CFG005_MASK = (BAR Mask 0 - High)
  * The BAR 0 Mask register is invisible to host software and not readable from the application.
- * The BAR 0 Mask register is only writable through PEM#_CFG_WR."
+ * The BAR 0 Mask register is only writable through PEM(0..3)_CFG_WR.
  */
 union cvmx_pcieepx_cfg005_mask {
 	uint32_t u32;
@@ -4575,7 +4573,7 @@ typedef union cvmx_pcieepx_cfg005_mask cvmx_pcieepx_cfg005_mask_t;
 /**
  * cvmx_pcieep#_cfg006
  *
- * PCIE_CFG006 = Seventh 32-bits of PCIE type 0 config space (Base Address Register 1 - Low)
+ * This register contains the seventh 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg006 {
@@ -4624,9 +4622,8 @@ typedef union cvmx_pcieepx_cfg006 cvmx_pcieepx_cfg006_t;
 /**
  * cvmx_pcieep#_cfg006_mask
  *
- * "PCIE_CFG006_MASK (BAR Mask 1 - Low)
  * The BAR 1 Mask register is invisible to host software and not readable from the application.
- * The BAR 1 Mask register is only writable through PEM#_CFG_WR."
+ * The BAR 1 Mask register is only writable through PEM(0..3)_CFG_WR.
  */
 union cvmx_pcieepx_cfg006_mask {
 	uint32_t u32;
@@ -4664,7 +4661,7 @@ typedef union cvmx_pcieepx_cfg006_mask cvmx_pcieepx_cfg006_mask_t;
 /**
  * cvmx_pcieep#_cfg007
  *
- * PCIE_CFG007 = Eighth 32-bits of PCIE type 0 config space (Base Address Register 1 - High)
+ * This register contains the eighth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg007 {
@@ -4695,9 +4692,8 @@ typedef union cvmx_pcieepx_cfg007 cvmx_pcieepx_cfg007_t;
 /**
  * cvmx_pcieep#_cfg007_mask
  *
- * "PCIE_CFG007_MASK (BAR Mask 1 - High)
  * The BAR 1 Mask register is invisible to host software and not readable from the application.
- * The BAR 1 Mask register is only writable through PEM#_CFG_WR."
+ * The BAR 1 Mask register is only writable through PEM(0..3)_CFG_WR.
  */
 union cvmx_pcieepx_cfg007_mask {
 	uint32_t u32;
@@ -4727,7 +4723,7 @@ typedef union cvmx_pcieepx_cfg007_mask cvmx_pcieepx_cfg007_mask_t;
 /**
  * cvmx_pcieep#_cfg008
  *
- * PCIE_CFG008 = Ninth 32-bits of PCIE type 0 config space (Base Address Register 2 - Low)
+ * This register contains the ninth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg008 {
@@ -4798,9 +4794,8 @@ typedef union cvmx_pcieepx_cfg008 cvmx_pcieepx_cfg008_t;
 /**
  * cvmx_pcieep#_cfg008_mask
  *
- * "PCIE_CFG008_MASK (BAR Mask 2 - Low)
  * The BAR 2 Mask register is invisible to host software and not readable from the application.
- * The BAR 2 Mask register is only writable through PEM#_CFG_WR."
+ * The BAR 2 Mask register is only writable through PEM(0..3)_CFG_WR.
  */
 union cvmx_pcieepx_cfg008_mask {
 	uint32_t u32;
@@ -4838,7 +4833,7 @@ typedef union cvmx_pcieepx_cfg008_mask cvmx_pcieepx_cfg008_mask_t;
 /**
  * cvmx_pcieep#_cfg009
  *
- * PCIE_CFG009 = Tenth 32-bits of PCIE type 0 config space (Base Address Register 2 - High)
+ * This register contains the tenth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg009 {
@@ -4891,9 +4886,8 @@ typedef union cvmx_pcieepx_cfg009 cvmx_pcieepx_cfg009_t;
 /**
  * cvmx_pcieep#_cfg009_mask
  *
- * "PCIE_CFG009_MASK (BAR Mask 2 - High)
  * The BAR 2 Mask register is invisible to host software and not readable from the application.
- * The BAR 2 Mask register is only writable through PEM#_CFG_WR."
+ * The BAR 2 Mask register is only writable through PEM(0..3)_CFG_WR.
  */
 union cvmx_pcieepx_cfg009_mask {
 	uint32_t u32;
@@ -4923,7 +4917,7 @@ typedef union cvmx_pcieepx_cfg009_mask cvmx_pcieepx_cfg009_mask_t;
 /**
  * cvmx_pcieep#_cfg010
  *
- * PCIE_CFG010 = Eleventh 32-bits of PCIE type 0 config space (CardBus CIS Pointer Register)
+ * This register contains the eleventh 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg010 {
@@ -4955,8 +4949,8 @@ typedef union cvmx_pcieepx_cfg010 cvmx_pcieepx_cfg010_t;
 /**
  * cvmx_pcieep#_cfg011
  *
- * PCIE_CFG011 = Twelfth 32-bits of PCIE type 0 config space (Subsystem ID and Subsystem Vendor
- * ID Register)
+ * This register contains the twelfth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg011 {
 	uint32_t u32;
@@ -4991,7 +4985,7 @@ typedef union cvmx_pcieepx_cfg011 cvmx_pcieepx_cfg011_t;
 /**
  * cvmx_pcieep#_cfg012
  *
- * PCIE_CFG012 = Thirteenth 32-bits of PCIE type 0 config space (Expansion ROM Base Address Register)
+ * This register contains the thirteenth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg012 {
@@ -5026,9 +5020,8 @@ typedef union cvmx_pcieepx_cfg012 cvmx_pcieepx_cfg012_t;
 /**
  * cvmx_pcieep#_cfg012_mask
  *
- * "PCIE_CFG012_MASK (Exapansion ROM BAR Mask)
- * The ROM Mask register is invisible to host software and not readable from the application.
- * The ROM Mask register is only writable through PEM#_CFG_WR."
+ * The ROM Mask register is invisible to host software and not readable from the application. The
+ * ROM Mask register is only writable through PEM(0..3)_CFG_WR.
  */
 union cvmx_pcieepx_cfg012_mask {
 	uint32_t u32;
@@ -5066,7 +5059,7 @@ typedef union cvmx_pcieepx_cfg012_mask cvmx_pcieepx_cfg012_mask_t;
 /**
  * cvmx_pcieep#_cfg013
  *
- * PCIE_CFG013 = Fourteenth 32-bits of PCIE type 0 config space (Capability Pointer Register)
+ * This register contains the fourteenth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg013 {
@@ -5102,8 +5095,8 @@ typedef union cvmx_pcieepx_cfg013 cvmx_pcieepx_cfg013_t;
 /**
  * cvmx_pcieep#_cfg015
  *
- * PCIE_CFG015 = Sixteenth 32-bits of PCIE type 0 config space (Interrupt Line Register/Interrupt
- * Pin/Bridge Control Register)
+ * This register contains the sixteenth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepx_cfg015 {
 	uint32_t u32;
@@ -5144,10 +5137,8 @@ typedef union cvmx_pcieepx_cfg015 cvmx_pcieepx_cfg015_t;
 /**
  * cvmx_pcieep#_cfg016
  *
- * PCIE_CFG016 = Seventeenth 32-bits of PCIE type 0 config space
- * (Power Management Capability ID/
- * Power Management Next Item Pointer/
- * Power Management Capabilities Register)
+ * This register contains the seventeenth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg016 {
 	uint32_t u32;
@@ -5210,8 +5201,8 @@ typedef union cvmx_pcieepx_cfg016 cvmx_pcieepx_cfg016_t;
 /**
  * cvmx_pcieep#_cfg017
  *
- * PCIE_CFG017 = Eighteenth 32-bits of PCIE type 0 config space (Power Management Control and
- * Status Register)
+ * This register contains the eighteenth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg017 {
 	uint32_t u32;
@@ -5274,10 +5265,8 @@ typedef union cvmx_pcieepx_cfg017 cvmx_pcieepx_cfg017_t;
 /**
  * cvmx_pcieep#_cfg020
  *
- * PCIE_CFG020 = Twenty-first 32-bits of PCIE type 0 config space
- * (MSI Capability ID/
- * MSI Next Item Pointer/
- * MSI Control Register)
+ * This register contains the twenty-first 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg020 {
 	uint32_t u32;
@@ -5357,8 +5346,8 @@ typedef union cvmx_pcieepx_cfg020 cvmx_pcieepx_cfg020_t;
 /**
  * cvmx_pcieep#_cfg021
  *
- * PCIE_CFG021 = Twenty-second 32-bits of PCIE type 0 config space (MSI Lower 32 Bits Address
- * Register)
+ * This register contains the twenty-second 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg021 {
 	uint32_t u32;
@@ -5390,7 +5379,7 @@ typedef union cvmx_pcieepx_cfg021 cvmx_pcieepx_cfg021_t;
 /**
  * cvmx_pcieep#_cfg022
  *
- * PCIE_CFG022 = Twenty-third 32-bits of PCIE type 0 config space (MSI Upper 32 bits Address Register)
+ * This register contains the twenty-third 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg022 {
@@ -5421,7 +5410,7 @@ typedef union cvmx_pcieepx_cfg022 cvmx_pcieepx_cfg022_t;
 /**
  * cvmx_pcieep#_cfg023
  *
- * PCIE_CFG023 = Twenty-fourth 32-bits of PCIE type 0 config space (MSI Data Register)
+ * This register contains the twenty-fourth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg023 {
@@ -5456,16 +5445,15 @@ typedef union cvmx_pcieepx_cfg023 cvmx_pcieepx_cfg023_t;
 /**
  * cvmx_pcieep#_cfg024
  *
- * PCIE_CFG024 = Twenty-fifth 32-bits of PCIE type 0 config space (MSI Mask Bits Register)
+ * This register contains the twenty-fifth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg024 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg024_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msimm                        : 32; /**< MSI
-                                                         For each mask bit that is set, the function is prohibited from
-                                                         sending the associated message. */
+	uint32_t msimm                        : 32; /**< MSI mask bits. For each mask bit that is set, the function is prohibited from sending the
+                                                         associated message. */
 #else
 	uint32_t msimm                        : 32;
 #endif
@@ -5478,16 +5466,14 @@ typedef union cvmx_pcieepx_cfg024 cvmx_pcieepx_cfg024_t;
 /**
  * cvmx_pcieep#_cfg025
  *
- * PCIE_CFG025 = Twenty-sixth 32-bits of PCIE type 0 config space (MSI Pending Bits Register)
+ * This register contains the twenty-sixth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg025 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg025_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msimp                        : 32; /**< MSI
-                                                         For each pending bit that is set, the function has a pending
-                                                         associated message. */
+	uint32_t msimp                        : 32; /**< MSI pending bits. For each pending bit that is set, the function has a pending associated message. */
 #else
 	uint32_t msimp                        : 32;
 #endif
@@ -5500,9 +5486,8 @@ typedef union cvmx_pcieepx_cfg025 cvmx_pcieepx_cfg025_t;
 /**
  * cvmx_pcieep#_cfg028
  *
- * PCIE_CFG028 = Twenty-ninth 32-bits of PCIE type 0 config space
- * (PCI Express Capabilities List Register/
- * PCI Express Capabilities Register)
+ * This register contains the twenty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepx_cfg028 {
 	uint32_t u32;
@@ -5552,7 +5537,7 @@ typedef union cvmx_pcieepx_cfg028 cvmx_pcieepx_cfg028_t;
 /**
  * cvmx_pcieep#_cfg029
  *
- * PCIE_CFG029 = Thirtieth 32-bits of PCIE type 0 config space (Device Capabilities Register)
+ * This register contains the thirtieth 32-bits of PCIe type 0 configuration space.
  *
  */
 union cvmx_pcieepx_cfg029 {
@@ -5700,8 +5685,8 @@ typedef union cvmx_pcieepx_cfg029 cvmx_pcieepx_cfg029_t;
 /**
  * cvmx_pcieep#_cfg030
  *
- * PCIE_CFG030 = Thirty-first 32-bits of PCIE type 0 config space
- * (Device Control Register/Device Status Register)
+ * This register contains the thirty-first 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepx_cfg030 {
 	uint32_t u32;
@@ -5906,8 +5891,8 @@ typedef union cvmx_pcieepx_cfg030 cvmx_pcieepx_cfg030_t;
 /**
  * cvmx_pcieep#_cfg031
  *
- * PCIE_CFG031 = Thirty-second 32-bits of PCIE type 0 config space
- * (Link Capabilities Register)
+ * This register contains the thirty-second 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg031 {
 	uint32_t u32;
@@ -6034,8 +6019,8 @@ typedef union cvmx_pcieepx_cfg031 cvmx_pcieepx_cfg031_t;
 /**
  * cvmx_pcieep#_cfg032
  *
- * PCIE_CFG032 = Thirty-third 32-bits of PCIE type 0 config space
- * (Link Control Register/Link Status Register)
+ * This register contains the thirty-third 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepx_cfg032 {
 	uint32_t u32;
@@ -6371,23 +6356,21 @@ typedef union cvmx_pcieepx_cfg034 cvmx_pcieepx_cfg034_t;
 /**
  * cvmx_pcieep#_cfg037
  *
- * PCIE_CFG037 = Thirty-eighth 32-bits of PCIE type 0 config space
- * (Device Capabilities 2 Register)
+ * This register contains the thirty-eighth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg037 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg037_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t meetp                        : 2;  /**< Max End-End TLP Prefixes
-                                                         o 01: 1
-                                                         o 10: 2
-                                                         o 11: 3
-                                                         0 00: 4 */
-	uint32_t eetps                        : 1;  /**< End-End TLP Prefix Supported
-                                                         (Not Supported) */
-	uint32_t effs                         : 1;  /**< Extended Fmt Field Supported
-                                                         (Not Supported) */
+	uint32_t meetp                        : 2;  /**< Max end-end TLP prefixes.
+                                                         0x1 = 1
+                                                         0x2 = 2
+                                                         0x3 = 3
+                                                         0x4 = 4 */
+	uint32_t eetps                        : 1;  /**< End-end TLP prefix supported (not supported). */
+	uint32_t effs                         : 1;  /**< Extended fmt field supported (not supported). */
 	uint32_t obffs                        : 2;  /**< Optimized Buffer Flush Fill (OBFF) Supported
                                                          (Not Supported) */
 	uint32_t reserved_12_17               : 6;
@@ -6485,33 +6468,25 @@ union cvmx_pcieepx_cfg037 {
 	struct cvmx_pcieepx_cfg037_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t meetp                        : 2;  /**< Max End-End TLP Prefixes
-                                                         o 01: 1
-                                                         o 10: 2
-                                                         o 11: 3
-                                                         0 00: 4 */
-	uint32_t eetps                        : 1;  /**< End-End TLP Prefix Supported
-                                                         (Not Supported) */
-	uint32_t effs                         : 1;  /**< Extended Fmt Field Supported
-                                                         (Not Supported) */
-	uint32_t obffs                        : 2;  /**< Optimized Buffer Flush Fill (OBFF) Supported
-                                                         (Not Supported) */
+	uint32_t meetp                        : 2;  /**< Max end-end TLP prefixes.
+                                                         0x1 = 1
+                                                         0x2 = 2
+                                                         0x3 = 3
+                                                         0x4 = 4 */
+	uint32_t eetps                        : 1;  /**< End-end TLP prefix supported (not supported). */
+	uint32_t effs                         : 1;  /**< Extended fmt field supported (not supported). */
+	uint32_t obffs                        : 2;  /**< Optimized buffer flush fill (OBFF) supported (not supported). */
 	uint32_t reserved_14_17               : 4;
-	uint32_t tphs                         : 2;  /**< TPH Completer Supported
-                                                         (Not Supported) */
-	uint32_t ltrs                         : 1;  /**< Latency Tolerance Reporting (LTR) Mechanism Supported
-                                                         (Not Supported) */
-	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR Passing
-                                                         (This bit applies to RCs) */
-	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp Supported
-                                                         (Not Supported) */
-	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp Supported */
-	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp Supported */
-	uint32_t atom_ops                     : 1;  /**< AtomicOp Routing Supported
-                                                         (Not Applicable for EP) */
-	uint32_t ari                          : 1;  /**< Alternate Routing ID Forwarding Supported */
-	uint32_t ctds                         : 1;  /**< Completion Timeout Disable Supported */
-	uint32_t ctrs                         : 4;  /**< Completion Timeout Ranges Supported */
+	uint32_t tphs                         : 2;  /**< TPH completer supported (not supported). */
+	uint32_t ltrs                         : 1;  /**< Latency tolerance reporting (LTR) mechanism supported (not supported). */
+	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR passing (This bit applies to RCs). */
+	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp supported (not supported). */
+	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported. */
+	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported. */
+	uint32_t atom_ops                     : 1;  /**< AtomicOp routing supported (not applicable for EP). */
+	uint32_t ari                          : 1;  /**< Alternate routing ID forwarding supported (not supported). */
+	uint32_t ctds                         : 1;  /**< Completion timeout disable supported. */
+	uint32_t ctrs                         : 4;  /**< Completion timeout ranges supported. */
 #else
 	uint32_t ctrs                         : 4;
 	uint32_t ctds                         : 1;
@@ -6577,15 +6552,15 @@ typedef union cvmx_pcieepx_cfg037 cvmx_pcieepx_cfg037_t;
 /**
  * cvmx_pcieep#_cfg038
  *
- * PCIE_CFG038 = Thirty-ninth 32-bits of PCIE type 0 config space
- * (Device Control 2 Register/Device Status 2 Register)
+ * This register contains the thirty-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg038 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg038_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_16_31               : 16;
-	uint32_t eetpb                        : 1;  /**< Unsupported End-End TLP Prefix Blocking */
+	uint32_t eetpb                        : 1;  /**< Unsupported end-end TLP prefix blocking. */
 	uint32_t obffe                        : 2;  /**< Optimized Buffer Flush Fill (OBFF) Enable
                                                          (Not Supported) */
 	uint32_t reserved_11_12               : 2;
@@ -6713,8 +6688,8 @@ typedef union cvmx_pcieepx_cfg038 cvmx_pcieepx_cfg038_t;
 /**
  * cvmx_pcieep#_cfg039
  *
- * PCIE_CFG039 = Fourtieth 32-bits of PCIE type 0 config space
- * (Link Capabilities 2 Register)
+ * This register contains the fortieth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg039 {
 	uint32_t u32;
@@ -6770,19 +6745,19 @@ typedef union cvmx_pcieepx_cfg039 cvmx_pcieepx_cfg039_t;
 /**
  * cvmx_pcieep#_cfg040
  *
- * PCIE_CFG040 = Fourty-first 32-bits of PCIE type 0 config space
- * (Link Control 2 Register/Link Status 2 Register)
+ * This register contains the forty-first 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pcieepx_cfg040 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg040_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_22_31               : 10;
-	uint32_t ler                          : 1;  /**< Link Equalization Request */
-	uint32_t ep3s                         : 1;  /**< Equalization Phase 3 Successful */
-	uint32_t ep2s                         : 1;  /**< Equalization Phase 2 Successful */
-	uint32_t ep1s                         : 1;  /**< Equalization Phase 1 Successful */
-	uint32_t eqc                          : 1;  /**< Equalization Complete */
+	uint32_t ler                          : 1;  /**< Link equalization request */
+	uint32_t ep3s                         : 1;  /**< Equalization phase 3 successful */
+	uint32_t ep2s                         : 1;  /**< Equalization phase 2 successful */
+	uint32_t ep1s                         : 1;  /**< Equalization phase 1 successful */
+	uint32_t eqc                          : 1;  /**< Equalization complete */
 	uint32_t cdl                          : 1;  /**< Current De-emphasis Level
                                                          When the Link is operating at 5 GT/s speed, this bit
                                                          reflects the level of de-emphasis. Encodings:
@@ -7037,28 +7012,22 @@ typedef union cvmx_pcieepx_cfg042 cvmx_pcieepx_cfg042_t;
 /**
  * cvmx_pcieep#_cfg044
  *
- * PCIE_CFG044 = Fourty-fifth 32-bits of PCIE type 0 config space
- * (MSI-X Capability ID/
- * MSI-X Next Item Pointer/
- * MSI-X Control Register)
+ * This register contains the forty-fifth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg044 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg044_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixen                       : 1;  /**< MSI-X Enable
-                                                         If MSI-X is enabled, MSI and INTx must be disabled. */
-	uint32_t funm                         : 1;  /**< Function Mask
-                                                         1b: All vectors associated with the function are masked,
-                                                         regardless of their respective per-vector mask bits.
-                                                         0b: Each vectors Mask bit determines whether the vector
-                                                         is masked or not. */
+	uint32_t msixen                       : 1;  /**< MSI-X enable. If MSI-X is enabled, MSI and INTx must be disabled. */
+	uint32_t funm                         : 1;  /**< Function mask.
+                                                         0 = Each vectors mask bit determines whether the vector is masked or not.
+                                                         1 = All vectors associated with the function are masked, regardless of their respective
+                                                         per-vector mask bits. */
 	uint32_t reserved_27_29               : 3;
-	uint32_t msixts                       : 11; /**< "MSI-X Table Size
-                                                         Encoded as (Table Size - 1)
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t ncp                          : 8;  /**< Next Capability Pointer */
+	uint32_t msixts                       : 11; /**< MSI-X table size encoded as (table size - 1). Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
+	uint32_t ncp                          : 8;  /**< Next capability pointer */
 	uint32_t msixcid                      : 8;  /**< MSI-X Capability ID */
 #else
 	uint32_t msixcid                      : 8;
@@ -7076,25 +7045,21 @@ typedef union cvmx_pcieepx_cfg044 cvmx_pcieepx_cfg044_t;
 /**
  * cvmx_pcieep#_cfg045
  *
- * PCIE_CFG045 = Fourty-sixth 32-bits of PCIE type 0 config space
- * (MSI-X Table Offset and BIR Register)
+ * This register contains the forty-sixth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg045 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg045_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixtoffs                    : 29; /**< "MSI-X Table Offset Register
-                                                         Base address of the MSI-X Table, as an offset from the base
-                                                         address of te BAR indicated by the Table BIR bits.
-                                                         writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t msixtbir                     : 3;  /**< "MSI-X Table BAR Indicator Register (BIR)
-                                                         Indicates which BAR is used to map the MSI-X Table
-                                                         into memory space
-                                                         000 - 100: BAR#
-                                                         110 - 111: Reserved
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t msixtoffs                    : 29; /**< "MSI-X table offset register. Base address of the MSI-X Table, as an offset from the base
+                                                         address of the BAR indicated by the Table BIR bits. Writable through PEM#_CFG_WR. However,
+                                                         the application must not change this field." */
+	uint32_t msixtbir                     : 3;  /**< "MSI-X table BAR indicator register (BIR). Indicates which BAR is used to map the MSI-X
+                                                         table into memory space.
+                                                         000 - 100 = BAR#
+                                                         110 - 111 = Reserved
+                                                         Writable through PEM#_CFG_WR. However, the application must not change this field." */
 #else
 	uint32_t msixtbir                     : 3;
 	uint32_t msixtoffs                    : 29;
@@ -7107,25 +7072,21 @@ typedef union cvmx_pcieepx_cfg045 cvmx_pcieepx_cfg045_t;
 /**
  * cvmx_pcieep#_cfg046
  *
- * PCIE_CFG046 = Fourty-seventh 32-bits of PCIE type 0 config space
- * (MSI-X PBA Offset and BIR Register)
+ * This register contains the forty-seventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg046 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg046_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixpoffs                    : 29; /**< "MSI-X Table Offset Register
-                                                         Base address of the MSI-X PBA, as an offset from the base
-                                                         address of te BAR indicated by the Table PBA bits.
-                                                         writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t msixpbir                     : 3;  /**< "MSI-X PBA BAR Indicator Register (BIR)
-                                                         Indicates which BAR is used to map the MSI-X Pending Bit Array
-                                                         into memory space
-                                                         000 - 100: BAR#
-                                                         110 - 111: Reserved
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t msixpoffs                    : 29; /**< "MSI-X table offset register. Base address of the MSI-X PBA, as an offset from the base
+                                                         address of the BAR indicated by the table PBA bits. Writable through PEM#_CFG_WR. However,
+                                                         the application must not change this field." */
+	uint32_t msixpbir                     : 3;  /**< "MSI-X PBA BAR indicator register (BIR). Indicates which BAR is used to map the MSI-X
+                                                         pending bit array                                                  into memory space.
+                                                         0x0 - 0x4 = BAR#
+                                                         0x6 - 0x7 = Reserved
+                                                         Writable through PEM(0..3)_CFG_WR. However, the application must not change this field." */
 #else
 	uint32_t msixpbir                     : 3;
 	uint32_t msixpoffs                    : 29;
@@ -7138,8 +7099,8 @@ typedef union cvmx_pcieepx_cfg046 cvmx_pcieepx_cfg046_t;
 /**
  * cvmx_pcieep#_cfg064
  *
- * PCIE_CFG064 = Sixty-fifth 32-bits of PCIE type 0 config space
- * (PCI Express Extended Capability Header)
+ * This register contains the sixty-fifth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg064 {
 	uint32_t u32;
@@ -7173,15 +7134,15 @@ typedef union cvmx_pcieepx_cfg064 cvmx_pcieepx_cfg064_t;
 /**
  * cvmx_pcieep#_cfg065
  *
- * PCIE_CFG065 = Sixty-sixth 32-bits of PCIE type 0 config space
- * (Uncorrectable Error Status Register)
+ * This register contains the sixty-sixth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg065 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg065_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Status */
+	uint32_t tpbes                        : 1;  /**< Unsupported TLP prefix blocked error status. */
 	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Status */
 	uint32_t reserved_23_23               : 1;
 	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Status */
@@ -7343,22 +7304,22 @@ union cvmx_pcieepx_cfg065 {
 	struct cvmx_pcieepx_cfg065_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Status */
-	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Status */
+	uint32_t tpbes                        : 1;  /**< Unsupported TLP prefix blocked error status. */
+	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp egress blocked status. */
 	uint32_t reserved_23_23               : 1;
-	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Status */
+	uint32_t ucies                        : 1;  /**< Uncorrectable internal error status. */
 	uint32_t reserved_21_21               : 1;
-	uint32_t ures                         : 1;  /**< Unsupported Request Error Status */
-	uint32_t ecrces                       : 1;  /**< ECRC Error Status */
-	uint32_t mtlps                        : 1;  /**< Malformed TLP Status */
-	uint32_t ros                          : 1;  /**< Receiver Overflow Status */
-	uint32_t ucs                          : 1;  /**< Unexpected Completion Status */
-	uint32_t cas                          : 1;  /**< Completer Abort Status */
-	uint32_t cts                          : 1;  /**< Completion Timeout Status */
-	uint32_t fcpes                        : 1;  /**< Flow Control Protocol Error Status */
-	uint32_t ptlps                        : 1;  /**< Poisoned TLP Status */
+	uint32_t ures                         : 1;  /**< Unsupported request error status. */
+	uint32_t ecrces                       : 1;  /**< ECRC error status. */
+	uint32_t mtlps                        : 1;  /**< Malformed TLP status. */
+	uint32_t ros                          : 1;  /**< Receiver overflow status. */
+	uint32_t ucs                          : 1;  /**< Unexpected completion status. */
+	uint32_t cas                          : 1;  /**< Completer abort status. */
+	uint32_t cts                          : 1;  /**< Completion timeout status. */
+	uint32_t fcpes                        : 1;  /**< Flow control protocol error status. */
+	uint32_t ptlps                        : 1;  /**< Poisoned TLP status. */
 	uint32_t reserved_5_11                : 7;
-	uint32_t dlpes                        : 1;  /**< Data Link Protocol Error Status */
+	uint32_t dlpes                        : 1;  /**< Data link protocol error status. */
 	uint32_t reserved_0_3                 : 4;
 #else
 	uint32_t reserved_0_3                 : 4;
@@ -7426,15 +7387,15 @@ typedef union cvmx_pcieepx_cfg065 cvmx_pcieepx_cfg065_t;
 /**
  * cvmx_pcieep#_cfg066
  *
- * PCIE_CFG066 = Sixty-seventh 32-bits of PCIE type 0 config space
- * (Uncorrectable Error Mask Register)
+ * This register contains the sixty-seventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg066 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg066_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbem                        : 1;  /**< Unsupported TLP Prefix Blocked Error Mask */
+	uint32_t tpbem                        : 1;  /**< Unsupported TLP prefix blocked error mask. */
 	uint32_t uatombm                      : 1;  /**< Unsupported AtomicOp Egress Blocked Mask */
 	uint32_t reserved_23_23               : 1;
 	uint32_t uciem                        : 1;  /**< Uncorrectable Internal Error Mask */
@@ -7596,22 +7557,22 @@ union cvmx_pcieepx_cfg066 {
 	struct cvmx_pcieepx_cfg066_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbem                        : 1;  /**< Unsupported TLP Prefix Blocked Error Mask */
-	uint32_t uatombm                      : 1;  /**< Unsupported AtomicOp Egress Blocked Mask */
+	uint32_t tpbem                        : 1;  /**< Unsupported TLP prefix blocked error mask. */
+	uint32_t uatombm                      : 1;  /**< Unsupported AtomicOp egress blocked mask. */
 	uint32_t reserved_23_23               : 1;
-	uint32_t uciem                        : 1;  /**< Uncorrectable Internal Error Mask */
+	uint32_t uciem                        : 1;  /**< Uncorrectable internal error mask. */
 	uint32_t reserved_21_21               : 1;
-	uint32_t urem                         : 1;  /**< Unsupported Request Error Mask */
-	uint32_t ecrcem                       : 1;  /**< ECRC Error Mask */
-	uint32_t mtlpm                        : 1;  /**< Malformed TLP Mask */
-	uint32_t rom                          : 1;  /**< Receiver Overflow Mask */
-	uint32_t ucm                          : 1;  /**< Unexpected Completion Mask */
-	uint32_t cam                          : 1;  /**< Completer Abort Mask */
-	uint32_t ctm                          : 1;  /**< Completion Timeout Mask */
-	uint32_t fcpem                        : 1;  /**< Flow Control Protocol Error Mask */
-	uint32_t ptlpm                        : 1;  /**< Poisoned TLP Mask */
+	uint32_t urem                         : 1;  /**< Unsupported request error mask. */
+	uint32_t ecrcem                       : 1;  /**< ECRC error mask. */
+	uint32_t mtlpm                        : 1;  /**< Malformed TLP mask. */
+	uint32_t rom                          : 1;  /**< Receiver overflow mask. */
+	uint32_t ucm                          : 1;  /**< Unexpected completion mask. */
+	uint32_t cam                          : 1;  /**< Completer abort mask. */
+	uint32_t ctm                          : 1;  /**< Completion timeout mask. */
+	uint32_t fcpem                        : 1;  /**< Flow control protocol error mask. */
+	uint32_t ptlpm                        : 1;  /**< Poisoned TLP mask. */
 	uint32_t reserved_5_11                : 7;
-	uint32_t dlpem                        : 1;  /**< Data Link Protocol Error Mask */
+	uint32_t dlpem                        : 1;  /**< Data link protocol error mask. */
 	uint32_t reserved_0_3                 : 4;
 #else
 	uint32_t reserved_0_3                 : 4;
@@ -7679,15 +7640,15 @@ typedef union cvmx_pcieepx_cfg066 cvmx_pcieepx_cfg066_t;
 /**
  * cvmx_pcieep#_cfg067
  *
- * PCIE_CFG067 = Sixty-eighth 32-bits of PCIE type 0 config space
- * (Uncorrectable Error Severity Register)
+ * This register contains the sixty-eighth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg067 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg067_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Severity */
+	uint32_t tpbes                        : 1;  /**< Unsupported TLP prefix blocked error severity. */
 	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Severity */
 	uint32_t reserved_23_23               : 1;
 	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Severity */
@@ -7849,22 +7810,22 @@ union cvmx_pcieepx_cfg067 {
 	struct cvmx_pcieepx_cfg067_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Severity */
-	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Severity */
+	uint32_t tpbes                        : 1;  /**< Unsupported TLP prefix blocked error severity. */
+	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp egress blocked severity. */
 	uint32_t reserved_23_23               : 1;
-	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Severity */
+	uint32_t ucies                        : 1;  /**< Uncorrectable internal error severity. */
 	uint32_t reserved_21_21               : 1;
-	uint32_t ures                         : 1;  /**< Unsupported Request Error Severity */
-	uint32_t ecrces                       : 1;  /**< ECRC Error Severity */
-	uint32_t mtlps                        : 1;  /**< Malformed TLP Severity */
-	uint32_t ros                          : 1;  /**< Receiver Overflow Severity */
-	uint32_t ucs                          : 1;  /**< Unexpected Completion Severity */
-	uint32_t cas                          : 1;  /**< Completer Abort Severity */
-	uint32_t cts                          : 1;  /**< Completion Timeout Severity */
-	uint32_t fcpes                        : 1;  /**< Flow Control Protocol Error Severity */
-	uint32_t ptlps                        : 1;  /**< Poisoned TLP Severity */
+	uint32_t ures                         : 1;  /**< Unsupported request error severity. */
+	uint32_t ecrces                       : 1;  /**< ECRC error severity. */
+	uint32_t mtlps                        : 1;  /**< Malformed TLP severity. */
+	uint32_t ros                          : 1;  /**< Receiver overflow severity. */
+	uint32_t ucs                          : 1;  /**< Unexpected completion severity. */
+	uint32_t cas                          : 1;  /**< Completer abort severity. */
+	uint32_t cts                          : 1;  /**< Completion timeout severity. */
+	uint32_t fcpes                        : 1;  /**< Flow control protocol error severity. */
+	uint32_t ptlps                        : 1;  /**< Poisoned TLP severity. */
 	uint32_t reserved_5_11                : 7;
-	uint32_t dlpes                        : 1;  /**< Data Link Protocol Error Severity */
+	uint32_t dlpes                        : 1;  /**< Data link protocol error severity. */
 	uint32_t reserved_0_3                 : 4;
 #else
 	uint32_t reserved_0_3                 : 4;
@@ -7932,8 +7893,8 @@ typedef union cvmx_pcieepx_cfg067 cvmx_pcieepx_cfg067_t;
 /**
  * cvmx_pcieep#_cfg068
  *
- * PCIE_CFG068 = Sixty-ninth 32-bits of PCIE type 0 config space
- * (Correctable Error Status Register)
+ * This register contains the sixty-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg068 {
 	uint32_t u32;
@@ -8003,8 +7964,8 @@ typedef union cvmx_pcieepx_cfg068 cvmx_pcieepx_cfg068_t;
 /**
  * cvmx_pcieep#_cfg069
  *
- * PCIE_CFG069 = Seventieth 32-bits of PCIE type 0 config space
- * (Correctable Error Mask Register)
+ * This register contains the seventieth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg069 {
 	uint32_t u32;
@@ -8074,15 +8035,15 @@ typedef union cvmx_pcieepx_cfg069 cvmx_pcieepx_cfg069_t;
 /**
  * cvmx_pcieep#_cfg070
  *
- * PCIE_CFG070 = Seventy-first 32-bits of PCIE type 0 config space
- * (Advanced Error Capabilities and Control Register)
+ * This register contains the seventy-first 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg070 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg070_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_12_31               : 20;
-	uint32_t tlp_plp                      : 1;  /**< TLP Prefix Log Present (Not Supported) */
+	uint32_t tlp_plp                      : 1;  /**< TLP prefix log present (not supported). */
 	uint32_t reserved_9_10                : 2;
 	uint32_t ce                           : 1;  /**< ECRC Check Enable */
 	uint32_t cc                           : 1;  /**< ECRC Check Capable */
@@ -8135,8 +8096,8 @@ typedef union cvmx_pcieepx_cfg070 cvmx_pcieepx_cfg070_t;
 /**
  * cvmx_pcieep#_cfg071
  *
- * PCIE_CFG071 = Seventy-second 32-bits of PCIE type 0 config space
- * (Header Log Register 1)
+ * This register contains the seventy-second 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg071 {
 	uint32_t u32;
@@ -8166,8 +8127,8 @@ typedef union cvmx_pcieepx_cfg071 cvmx_pcieepx_cfg071_t;
 /**
  * cvmx_pcieep#_cfg072
  *
- * PCIE_CFG072 = Seventy-third 32-bits of PCIE type 0 config space
- * (Header Log Register 2)
+ * This register contains the seventy-third 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg072 {
 	uint32_t u32;
@@ -8197,8 +8158,8 @@ typedef union cvmx_pcieepx_cfg072 cvmx_pcieepx_cfg072_t;
 /**
  * cvmx_pcieep#_cfg073
  *
- * PCIE_CFG073 = Seventy-fourth 32-bits of PCIE type 0 config space
- * (Header Log Register 3)
+ * This register contains the seventy-fourth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg073 {
 	uint32_t u32;
@@ -8228,8 +8189,8 @@ typedef union cvmx_pcieepx_cfg073 cvmx_pcieepx_cfg073_t;
 /**
  * cvmx_pcieep#_cfg074
  *
- * PCIE_CFG074 = Seventy-fifth 32-bits of PCIE type 0 config space
- * (Header Log Register 4)
+ * This register contains the seventy-fifth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg074 {
 	uint32_t u32;
@@ -8259,14 +8220,14 @@ typedef union cvmx_pcieepx_cfg074 cvmx_pcieepx_cfg074_t;
 /**
  * cvmx_pcieep#_cfg078
  *
- * PCIE_CFG078 = Seventy-ninth 32-bits of PCIE type 0 config space
- * (TLP Prefix Log Register)
+ * This register contains the seventy-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg078 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg078_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t tlp_pfx_log                  : 32; /**< TLP Prefix Log Register */
+	uint32_t tlp_pfx_log                  : 32; /**< TLP prefix log register. */
 #else
 	uint32_t tlp_pfx_log                  : 32;
 #endif
@@ -8278,16 +8239,15 @@ typedef union cvmx_pcieepx_cfg078 cvmx_pcieepx_cfg078_t;
 /**
  * cvmx_pcieep#_cfg082
  *
- * PCIE_CFG082 = Eighty-third 32-bits of PCIE type 0 config space
- * (PCI Express ARI Capability Header)
+ * This register contains the eighty-third 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg082 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg082_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t nco                          : 12; /**< Next Capability Offset
-                                                         Points to the Secondary PCI Express Capabilities by default */
-	uint32_t cv                           : 4;  /**< Capability Version */
+	uint32_t nco                          : 12; /**< Next capability offset. Points to the secondary PCI Express capabilities by default. */
+	uint32_t cv                           : 4;  /**< Capability version. */
 	uint32_t reserved_0_15                : 16;
 #else
 	uint32_t reserved_0_15                : 16;
@@ -8308,10 +8268,9 @@ union cvmx_pcieepx_cfg082 {
 	} cn70xx;
 	struct cvmx_pcieepx_cfg082_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t nco                          : 12; /**< Next Capability Offset
-                                                         Points to the Secondary PCI Express Capabilities by default */
-	uint32_t cv                           : 4;  /**< Capability Version */
-	uint32_t ariid                        : 16; /**< PCIE Express Extended Capability */
+	uint32_t nco                          : 12; /**< Next capability offset. Points to the secondary PCI Express capabilities by default. */
+	uint32_t cv                           : 4;  /**< Capability version. */
+	uint32_t ariid                        : 16; /**< PCI Express extended capability. */
 #else
 	uint32_t ariid                        : 16;
 	uint32_t cv                           : 4;
@@ -8324,17 +8283,16 @@ typedef union cvmx_pcieepx_cfg082 cvmx_pcieepx_cfg082_t;
 /**
  * cvmx_pcieep#_cfg083
  *
- * PCIE_CFG083 = Eighty-fourth 32-bits of PCIE type 0 config space
- * (PCI Express ARI Capability Register/
- * PCI Express ARI Control Register)
+ * This register contains the eighty-fourth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg083 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg083_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_2_31                : 30;
-	uint32_t acsfgc                       : 1;  /**< ACS Function Groups Capability */
-	uint32_t mfvcfgc                      : 1;  /**< MFVC Function Groups Capability */
+	uint32_t acsfgc                       : 1;  /**< ACS function groups capability. */
+	uint32_t mfvcfgc                      : 1;  /**< MFVC function groups capability. */
 #else
 	uint32_t mfvcfgc                      : 1;
 	uint32_t acsfgc                       : 1;
@@ -8360,14 +8318,14 @@ union cvmx_pcieepx_cfg083 {
 	struct cvmx_pcieepx_cfg083_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_23_31               : 9;
-	uint32_t fg                           : 3;  /**< Function Group */
+	uint32_t fg                           : 3;  /**< Function group. */
 	uint32_t reserved_18_19               : 2;
-	uint32_t acsfge                       : 1;  /**< ACS Function Groups Enable (A) */
-	uint32_t mfvcfge                      : 1;  /**< MFVC Function Groups Enable (M) */
-	uint32_t nfn                          : 8;  /**< Next Function Number */
+	uint32_t acsfge                       : 1;  /**< ACS function groups enable (A). */
+	uint32_t mfvcfge                      : 1;  /**< MFVC function groups enable (M). */
+	uint32_t nfn                          : 8;  /**< Next function number. */
 	uint32_t reserved_2_7                 : 6;
-	uint32_t acsfgc                       : 1;  /**< ACS Function Groups Capability */
-	uint32_t mfvcfgc                      : 1;  /**< MFVC Function Groups Capability */
+	uint32_t acsfgc                       : 1;  /**< ACS function groups capability. */
+	uint32_t mfvcfgc                      : 1;  /**< MFVC function groups capability. */
 #else
 	uint32_t mfvcfgc                      : 1;
 	uint32_t acsfgc                       : 1;
@@ -8416,17 +8374,16 @@ typedef union cvmx_pcieepx_cfg084 cvmx_pcieepx_cfg084_t;
 /**
  * cvmx_pcieep#_cfg086
  *
- * PCIE_CFG086 = Eighty-seventh 32-bits of PCIE type 0 config space
- * (PCI Express Secondary Capability (Gen3) Header)
+ * This register contains the eighty-seventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg086 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg086_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t nco                          : 12; /**< Next Capability Offset
-                                                         Points to the PCI Express SR-IOV Capability Header by default */
-	uint32_t cv                           : 4;  /**< Capability Version */
-	uint32_t pcieec                       : 16; /**< PCIE Express Extended Capability */
+	uint32_t nco                          : 12; /**< Next capability offset. Points to the PCI Express SR-IOV capability header by default. */
+	uint32_t cv                           : 4;  /**< Capability version */
+	uint32_t pcieec                       : 16; /**< PCIE Express extended capability */
 #else
 	uint32_t pcieec                       : 16;
 	uint32_t cv                           : 4;
@@ -8440,16 +8397,16 @@ typedef union cvmx_pcieepx_cfg086 cvmx_pcieepx_cfg086_t;
 /**
  * cvmx_pcieep#_cfg087
  *
- * PCIE_CFG087 = Eighty-eighth 32-bits of PCIE type 0 config space
- * (Link Control 3)
+ * This register contains the eighty-eighth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg087 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg087_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_2_31                : 30;
-	uint32_t ler                          : 1;  /**< Link Equalization Request Interrupt Enable */
-	uint32_t pe                           : 1;  /**< Perform Equalization */
+	uint32_t ler                          : 1;  /**< Link equalization request interrupt enable. */
+	uint32_t pe                           : 1;  /**< Perform equalization. */
 #else
 	uint32_t pe                           : 1;
 	uint32_t ler                          : 1;
@@ -8463,15 +8420,15 @@ typedef union cvmx_pcieepx_cfg087 cvmx_pcieepx_cfg087_t;
 /**
  * cvmx_pcieep#_cfg088
  *
- * PCIE_CFG088 = Eighty-ninth 32-bits of PCIE type 0 config space
- * (Lane Error Status)
+ * This register contains the eighty-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg088 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg088_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_8_31                : 24;
-	uint32_t les                          : 8;  /**< Lane Error Status Bits */
+	uint32_t les                          : 8;  /**< Lane error status bits. */
 #else
 	uint32_t les                          : 8;
 	uint32_t reserved_8_31                : 24;
@@ -8484,28 +8441,23 @@ typedef union cvmx_pcieepx_cfg088 cvmx_pcieepx_cfg088_t;
 /**
  * cvmx_pcieep#_cfg089
  *
- * PCIE_CFG089 = Ninetieth 32-bits of PCIE type 0 config space
- * (Equalization Control Lane 0/
- * Equalization Control Lane 1)
+ * This register contains the ninetieth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg089 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg089_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l1dph                        : 3;  /**< "Lane 1 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l1dtp                        : 4;  /**< "Lane 1 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l1dph                        : 3;  /**< Lane 1 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l1dtp                        : 4;  /**< Lane 1 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_15_23               : 9;
-	uint32_t l0dph                        : 3;  /**< "Lane 0 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l0dtp                        : 4;  /**< "Lane 0 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l0dph                        : 3;  /**< Lane 0 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l0dtp                        : 4;  /**< Lane 0 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_0_7                 : 8;
 #else
 	uint32_t reserved_0_7                 : 8;
@@ -8524,28 +8476,23 @@ typedef union cvmx_pcieepx_cfg089 cvmx_pcieepx_cfg089_t;
 /**
  * cvmx_pcieep#_cfg090
  *
- * PCIE_CFG090 = Ninety-first 32-bits of PCIE type 0 config space
- * (Equalization Control Lane 2/
- * Equalization Control Lane 3)
+ * This register contains the ninety-first 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg090 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg090_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l3dph                        : 3;  /**< "Lane 3 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l3dtp                        : 4;  /**< "Lane 3 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l3dph                        : 3;  /**< Lane 3 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l3dtp                        : 4;  /**< Lane 3 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_15_23               : 9;
-	uint32_t l2dph                        : 3;  /**< "Lane 2 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l2dtp                        : 4;  /**< "Lane 2 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l2dph                        : 3;  /**< Lane 2 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l2dtp                        : 4;  /**< Lane 2 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_0_7                 : 8;
 #else
 	uint32_t reserved_0_7                 : 8;
@@ -8564,28 +8511,23 @@ typedef union cvmx_pcieepx_cfg090 cvmx_pcieepx_cfg090_t;
 /**
  * cvmx_pcieep#_cfg091
  *
- * PCIE_CFG091 = Ninety-second 32-bits of PCIE type 0 config space
- * (Equalization Control Lane 4/
- * Equalization Control Lane 5)
+ * This register contains the ninety-second 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg091 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg091_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l5dph                        : 3;  /**< "Lane 5 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l5dtp                        : 4;  /**< "Lane 5 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l5dph                        : 3;  /**< Lane 5 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l5dtp                        : 4;  /**< Lane 5 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_15_23               : 9;
-	uint32_t l4dph                        : 3;  /**< "Lane 4 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l4dtp                        : 4;  /**< "Lane 4 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l4dph                        : 3;  /**< Lane 4 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l4dtp                        : 4;  /**< Lane 4 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_0_7                 : 8;
 #else
 	uint32_t reserved_0_7                 : 8;
@@ -8604,28 +8546,23 @@ typedef union cvmx_pcieepx_cfg091 cvmx_pcieepx_cfg091_t;
 /**
  * cvmx_pcieep#_cfg092
  *
- * PCIE_CFG092 = Ninety-third 32-bits of PCIE type 0 config space
- * (Equalization Control Lane 6/
- * Equalization Control Lane 7)
+ * This register contains the ninety-fourth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg092 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg092_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l7dph                        : 3;  /**< "Lane 7 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l7dtp                        : 4;  /**< "Lane 7 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l7dph                        : 3;  /**< Lane 7 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l7dtp                        : 4;  /**< Lane 7 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_15_23               : 9;
-	uint32_t l6dph                        : 3;  /**< "Lane 6 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l6dtp                        : 4;  /**< "Lane 6 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l6dph                        : 3;  /**< Lane 6 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l6dtp                        : 4;  /**< Lane 6 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_0_7                 : 8;
 #else
 	uint32_t reserved_0_7                 : 8;
@@ -8644,17 +8581,16 @@ typedef union cvmx_pcieepx_cfg092 cvmx_pcieepx_cfg092_t;
 /**
  * cvmx_pcieep#_cfg094
  *
- * PCIE_CFG094 = Ninety-fifth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV Capability Header)
+ * This register contains the ninety-fifth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg094 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg094_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t nco                          : 12; /**< Next Capability Offset
-                                                         Points to the Resizable BAR Capabilities by default */
-	uint32_t cv                           : 4;  /**< Capability Version */
-	uint32_t pcieec                       : 16; /**< PCIE Express Extended Capability */
+	uint32_t nco                          : 12; /**< Next capability offset. Points to the resizable BAR capabilities by default */
+	uint32_t cv                           : 4;  /**< Capability version. */
+	uint32_t pcieec                       : 16; /**< PCIE Express extended capability. */
 #else
 	uint32_t pcieec                       : 16;
 	uint32_t cv                           : 4;
@@ -8668,19 +8604,18 @@ typedef union cvmx_pcieepx_cfg094 cvmx_pcieepx_cfg094_t;
 /**
  * cvmx_pcieep#_cfg095
  *
- * PCIE_CFG095 = Ninety-sixth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV Capability Register)
+ * This register contains the ninety-sixth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg095 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg095_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t vfmimn                       : 11; /**< VF Migration Interrupt Message Number */
+	uint32_t vfmimn                       : 11; /**< VF migration interrupt message number. */
 	uint32_t reserved_2_20                : 19;
-	uint32_t arichp                       : 1;  /**< "ARI Capable Hiearchy Preserved
-                                                         writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t vfmc                         : 1;  /**< VF Migration Capable */
+	uint32_t arichp                       : 1;  /**< "ARI capable hierarchy preserved. Writable through PEM#_CFG_WR. However, the application
+                                                         must not change this field." */
+	uint32_t vfmc                         : 1;  /**< VF migration capable. */
 #else
 	uint32_t vfmc                         : 1;
 	uint32_t arichp                       : 1;
@@ -8695,26 +8630,24 @@ typedef union cvmx_pcieepx_cfg095 cvmx_pcieepx_cfg095_t;
 /**
  * cvmx_pcieep#_cfg096
  *
- * PCIE_CFG096 = Ninety-seventh 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV Control Register/
- * PCI Express SR-IOV Status Register)
+ * This register contains the ninety-seventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg096 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg096_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_17_31               : 15;
-	uint32_t ms                           : 1;  /**< VF Migration Status */
+	uint32_t ms                           : 1;  /**< VF migration status. */
 	uint32_t reserved_5_15                : 11;
-	uint32_t ach                          : 1;  /**< ARI Capable Hiearchy
-                                                         0b: All PF's have non-ARI Capable Hierarchy
-                                                         1b: All PF's have ARI Capable Hierarchy
-                                                         The value in this field in PF0 is used for all other
-                                                         physical functions. */
-	uint32_t mse                          : 1;  /**< VF MSE */
-	uint32_t mie                          : 1;  /**< VF Migration Interrupt Enable */
-	uint32_t me                           : 1;  /**< VF Migration Enable */
-	uint32_t vfe                          : 1;  /**< VF Enable */
+	uint32_t ach                          : 1;  /**< ARI capable hierarchy.
+                                                         0b = All PFs have non-ARI capable hierarchy
+                                                         1b = All PFs have ARI capable hierarchy
+                                                         The value in this field in PF0 is used for all other physical functions. */
+	uint32_t mse                          : 1;  /**< VF MSE. */
+	uint32_t mie                          : 1;  /**< VF migration interrupt enable. */
+	uint32_t me                           : 1;  /**< VF migration enable. */
+	uint32_t vfe                          : 1;  /**< VF enable. */
 #else
 	uint32_t vfe                          : 1;
 	uint32_t me                           : 1;
@@ -8733,16 +8666,15 @@ typedef union cvmx_pcieepx_cfg096 cvmx_pcieepx_cfg096_t;
 /**
  * cvmx_pcieep#_cfg097
  *
- * PCIE_CFG097 = Ninety-eighth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV Initial VFs Register/
- * PCI Express SR-IOV Total VFs Register)
+ * This register contains the ninety-eighth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg097 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg097_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t tvf                          : 16; /**< Total VFs */
-	uint32_t ivf                          : 16; /**< Initial VFs */
+	uint32_t tvf                          : 16; /**< Total VFs. */
+	uint32_t ivf                          : 16; /**< Initial VFs. */
 #else
 	uint32_t ivf                          : 16;
 	uint32_t tvf                          : 16;
@@ -8755,18 +8687,16 @@ typedef union cvmx_pcieepx_cfg097 cvmx_pcieepx_cfg097_t;
 /**
  * cvmx_pcieep#_cfg098
  *
- * PCIE_CFG098 = Ninety-ninth  32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV Number of VFs Register/
- * PCI Express SR-IOV Function Dependency Link Register)
+ * This register contains the ninety-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg098 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg098_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t fdl                          : 8;  /**< Function Dependency Link
-                                                         Enables support for VF dependency link. */
-	uint32_t nvf                          : 16; /**< Number of VFs that are visible */
+	uint32_t fdl                          : 8;  /**< Function dependency link. Enables support for VF dependency link. */
+	uint32_t nvf                          : 16; /**< Number of VFs that are visible. */
 #else
 	uint32_t nvf                          : 16;
 	uint32_t fdl                          : 8;
@@ -8780,16 +8710,15 @@ typedef union cvmx_pcieepx_cfg098 cvmx_pcieepx_cfg098_t;
 /**
  * cvmx_pcieep#_cfg099
  *
- * PCIE_CFG099 = One hundredth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV First VF Offset Register/
- * PCI Express SR-IOV VF Stride Register)
+ * This register contains the one hundredth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg099 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg099_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t vfs                          : 16; /**< VF Stride */
-	uint32_t fo                           : 16; /**< First VF Offset */
+	uint32_t vfs                          : 16; /**< VF stride. */
+	uint32_t fo                           : 16; /**< First VF offset. */
 #else
 	uint32_t fo                           : 16;
 	uint32_t vfs                          : 16;
@@ -8802,14 +8731,14 @@ typedef union cvmx_pcieepx_cfg099 cvmx_pcieepx_cfg099_t;
 /**
  * cvmx_pcieep#_cfg100
  *
- * PCIE_CFG100 = One hundred first 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV VF Device ID Register)
+ * This register contains the one hundred first 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg100 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg100_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t vfdev                        : 16; /**< VF Device ID */
+	uint32_t vfdev                        : 16; /**< VF device ID. */
 	uint32_t reserved_0_15                : 16;
 #else
 	uint32_t reserved_0_15                : 16;
@@ -8823,14 +8752,14 @@ typedef union cvmx_pcieepx_cfg100 cvmx_pcieepx_cfg100_t;
 /**
  * cvmx_pcieep#_cfg101
  *
- * PCIE_CFG101 = One hundred second 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV Supported Page Sizes Register)
+ * This register contains the one hundred second 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg101 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg101_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t supps                        : 32; /**< Supported Page Sizes */
+	uint32_t supps                        : 32; /**< Supported page sizes. */
 #else
 	uint32_t supps                        : 32;
 #endif
@@ -8842,14 +8771,14 @@ typedef union cvmx_pcieepx_cfg101 cvmx_pcieepx_cfg101_t;
 /**
  * cvmx_pcieep#_cfg102
  *
- * PCIE_CFG102 = One hundred third 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV System Page Size Register)
+ * This register contains the one hundred third 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg102 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg102_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t ps                           : 32; /**< System Page Size */
+	uint32_t ps                           : 32; /**< System page size. */
 #else
 	uint32_t ps                           : 32;
 #endif
@@ -8861,22 +8790,22 @@ typedef union cvmx_pcieepx_cfg102 cvmx_pcieepx_cfg102_t;
 /**
  * cvmx_pcieep#_cfg103
  *
- * PCIE_CFG103 = One hundred fourth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV BAR 0 Register)
+ * This register contains the one hundred fourth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg103 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg103_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t lbab                         : 18; /**< Lower bits of the VF BAR 0 base address */
+	uint32_t lbab                         : 18; /**< Lower bits of the VF BAR 0 base address. */
 	uint32_t reserved_4_13                : 10;
-	uint32_t pf                           : 1;  /**< Prefetchable */
+	uint32_t pf                           : 1;  /**< Prefetchable. */
 	uint32_t typ                          : 2;  /**< BAR type
-                                                         o 00 = 32-bit BAR
-                                                         o 10 = 64-bit BAR */
-	uint32_t mspc                         : 1;  /**< Memory Space Indicator
-                                                         o 0 = BAR 0 is a memory BAR
-                                                         o 1 = BAR 0 is an I/O BAR */
+                                                         0x0 = 32-bit BAR.
+                                                         0x2 = 64-bit BAR. */
+	uint32_t mspc                         : 1;  /**< Memory space indicator
+                                                         0 = BAR 0 is a memory BAR.
+                                                         1 = BAR 0 is an I/O BAR. */
 #else
 	uint32_t mspc                         : 1;
 	uint32_t typ                          : 2;
@@ -8892,14 +8821,14 @@ typedef union cvmx_pcieepx_cfg103 cvmx_pcieepx_cfg103_t;
 /**
  * cvmx_pcieep#_cfg104
  *
- * PCIE_CFG104 = One hundred fifth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV BAR 1 Register)
+ * This register contains the one hundred seventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg104 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg104_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t ubab                         : 32; /**< Upper bits of the VF BAR 0 base address */
+	uint32_t ubab                         : 32; /**< Upper bits of the VF BAR 0 base address. */
 #else
 	uint32_t ubab                         : 32;
 #endif
@@ -8911,8 +8840,8 @@ typedef union cvmx_pcieepx_cfg104 cvmx_pcieepx_cfg104_t;
 /**
  * cvmx_pcieep#_cfg105
  *
- * PCIE_CFG105 = One hundred sixth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV BAR 2 Register)
+ * This register contains the one hundred sixth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg105 {
 	uint32_t u32;
@@ -8930,8 +8859,8 @@ typedef union cvmx_pcieepx_cfg105 cvmx_pcieepx_cfg105_t;
 /**
  * cvmx_pcieep#_cfg106
  *
- * PCIE_CFG106 = One hundred seventh 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV BAR 3 Register)
+ * This register contains the one hundred seventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg106 {
 	uint32_t u32;
@@ -8949,8 +8878,8 @@ typedef union cvmx_pcieepx_cfg106 cvmx_pcieepx_cfg106_t;
 /**
  * cvmx_pcieep#_cfg107
  *
- * PCIE_CFG107 = One hundred eighth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV BAR 4 Register)
+ * This register contains the one hundred eighth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg107 {
 	uint32_t u32;
@@ -8968,8 +8897,8 @@ typedef union cvmx_pcieepx_cfg107 cvmx_pcieepx_cfg107_t;
 /**
  * cvmx_pcieep#_cfg108
  *
- * PCIE_CFG108 = One hundred eleventh 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV BAR 5 Register)
+ * This register contains the one hundred ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg108 {
 	uint32_t u32;
@@ -8987,15 +8916,15 @@ typedef union cvmx_pcieepx_cfg108 cvmx_pcieepx_cfg108_t;
 /**
  * cvmx_pcieep#_cfg109
  *
- * PCIE_CFG109 = One hundred tenth 32-bits of PCIE type 0 config space
- * (PCI Express SR-IOV migration State Array Offset Register)
+ * This register contains the one hundred tenth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg109 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg109_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t mso                          : 29; /**< VF Migration State Offset */
-	uint32_t msbir                        : 3;  /**< VF Migration State BIR */
+	uint32_t mso                          : 29; /**< VF migration state offset. */
+	uint32_t msbir                        : 3;  /**< VF migration state BIR. */
 #else
 	uint32_t msbir                        : 3;
 	uint32_t mso                          : 29;
@@ -9008,16 +8937,16 @@ typedef union cvmx_pcieepx_cfg109 cvmx_pcieepx_cfg109_t;
 /**
  * cvmx_pcieep#_cfg110
  *
- * PCIE_CFG110 = One hundred eleventh 32-bits of PCIE type 0 config space
- * (PCI Express Resizable BAR (RBAR) Capability Header)
+ * This register contains the one hundred eleventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg110 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg110_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t nco                          : 12; /**< Next Capability Offset */
-	uint32_t cv                           : 4;  /**< Capability Version */
-	uint32_t pcieec                       : 16; /**< PCIE Express Extended Capability */
+	uint32_t nco                          : 12; /**< Next capability offset. */
+	uint32_t cv                           : 4;  /**< Capability version. */
+	uint32_t pcieec                       : 16; /**< PCI Express extended capability. */
 #else
 	uint32_t pcieec                       : 16;
 	uint32_t cv                           : 4;
@@ -9031,20 +8960,18 @@ typedef union cvmx_pcieepx_cfg110 cvmx_pcieepx_cfg110_t;
 /**
  * cvmx_pcieep#_cfg111
  *
- * PCIE_CFG111 = One hundred twelvth 32-bits of PCIE type 0 config space
- * (PCI Express Resizable BAR (RBAR) Capability Register)
+ * This register contains the one hundred twelfth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg111 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg111_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_30_31               : 2;
-	uint32_t srs                          : 26; /**< "Supported Resource Sizes
-                                                         The OCTEON advertises the maximum allowable BAR size (512GB - 0xf_ffff)
-                                                         when the fus__bar2_size_conf is intact. When the fuse is blown,
-                                                         the OCTEON advertised a BAR size of 32TB (0x3ff_ffff).
-                                                         The BAR is disabled at runtime by writing all zeros through
-                                                         PEM#_CFG_WR to this field" */
+	uint32_t srs                          : 26; /**< "Supported resource sizes. PEM advertises the maximum allowable BAR size (512 GB -
+                                                         0xF_FFFF) when the fus__bar2_size_conf is in tact. When the fuse is blown, the CN78XX
+                                                         advertises a BAR size of 32TB (0x3FF_FFFF). The BAR is disabled at runtime by writing all
+                                                         zeros through PEM#_CFG_WR to this field." */
 	uint32_t reserved_0_3                 : 4;
 #else
 	uint32_t reserved_0_3                 : 4;
@@ -9059,21 +8986,19 @@ typedef union cvmx_pcieepx_cfg111 cvmx_pcieepx_cfg111_t;
 /**
  * cvmx_pcieep#_cfg112
  *
- * PCIE_CFG112 = One hundred thirteenth 32-bits of PCIE type 0 config space
- * (PCI Express Resizable BAR (RBAR) Control Register)
+ * This register contains the one hundred thirteenth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg112 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg112_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_13_31               : 19;
-	uint32_t rbars                        : 5;  /**< BAR Size
-                                                         The OCTEON advertises the minimum allowable BAR size of 0x0 (1MB)
-                                                         but will accept values as large as 0x19 (32TB) */
-	uint32_t nrbar                        : 3;  /**< Number of Resizable BARs */
+	uint32_t rbars                        : 5;  /**< BAR Size. PEM advertises the minimum allowable BAR size of 0x0 (1MB) but will accept
+                                                         values as large as 0x19 (32TB). */
+	uint32_t nrbar                        : 3;  /**< Number of resizable BARs */
 	uint32_t reserved_3_4                 : 2;
-	uint32_t rbari                        : 3;  /**< BAR Index
-                                                         Points to the BAR located at offset 0x18 (BAR2) */
+	uint32_t rbari                        : 3;  /**< BAR Index. Points to the BAR located at offset 0x18 (BAR2). */
 #else
 	uint32_t rbari                        : 3;
 	uint32_t reserved_3_4                 : 2;
@@ -9089,8 +9014,8 @@ typedef union cvmx_pcieepx_cfg112 cvmx_pcieepx_cfg112_t;
 /**
  * cvmx_pcieep#_cfg448
  *
- * PCIE_CFG448 = Four hundred forty-ninth 32-bits of PCIE type 0 config space
- * (Ack Latency Timer and Replay Timer Register)
+ * This register contains the four hundred forty-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg448 {
 	uint32_t u32;
@@ -9136,8 +9061,8 @@ typedef union cvmx_pcieepx_cfg448 cvmx_pcieepx_cfg448_t;
 /**
  * cvmx_pcieep#_cfg449
  *
- * PCIE_CFG449 = Four hundred fiftieth 32-bits of PCIE type 0 config space
- * (Other Message Register)
+ * This register contains the four hundred fiftieth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg449 {
 	uint32_t u32;
@@ -9178,8 +9103,8 @@ typedef union cvmx_pcieepx_cfg449 cvmx_pcieepx_cfg449_t;
 /**
  * cvmx_pcieep#_cfg450
  *
- * PCIE_CFG450 = Four hundred fifty-first 32-bits of PCIE type 0 config space
- * (Port Force Link Register)
+ * This register contains the four hundred fifty-first 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg450 {
 	uint32_t u32;
@@ -9349,8 +9274,8 @@ typedef union cvmx_pcieepx_cfg450 cvmx_pcieepx_cfg450_t;
 /**
  * cvmx_pcieep#_cfg451
  *
- * PCIE_CFG451 = Four hundred fifty-second 32-bits of PCIE type 0 config space
- * (Ack Frequency Register)
+ * This register contains the four hundred fifty-second 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg451 {
 	uint32_t u32;
@@ -9472,8 +9397,8 @@ typedef union cvmx_pcieepx_cfg451 cvmx_pcieepx_cfg451_t;
 /**
  * cvmx_pcieep#_cfg452
  *
- * PCIE_CFG452 = Four hundred fifty-third 32-bits of PCIE type 0 config space
- * (Port Link Control Register)
+ * This register contains the four hundred fifty-third 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg452 {
 	uint32_t u32;
@@ -9752,8 +9677,8 @@ typedef union cvmx_pcieepx_cfg452 cvmx_pcieepx_cfg452_t;
 /**
  * cvmx_pcieep#_cfg453
  *
- * PCIE_CFG453 = Four hundred fifty-fourth 32-bits of PCIE type 0 config space
- * (Lane Skew Register)
+ * This register contains the four hundred fifty-fourth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg453 {
 	uint32_t u32;
@@ -9799,8 +9724,8 @@ typedef union cvmx_pcieepx_cfg453 cvmx_pcieepx_cfg453_t;
 /**
  * cvmx_pcieep#_cfg454
  *
- * PCIE_CFG454 = Four hundred fifty-fifth 32-bits of PCIE type 0 config space
- * (Symbol Number Register)
+ * This register contains the four hundred fifty-fifth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg454 {
 	uint32_t u32;
@@ -9915,18 +9840,15 @@ union cvmx_pcieepx_cfg454 {
 	struct cvmx_pcieepx_cfg454_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_29_31               : 3;
-	uint32_t tmfcwt                       : 5;  /**< Used to be "Timer Modifier for Flow Control Watchdog Timer"
-                                                         No longer used. Repl and enhanced func moved to "Queue Status"
-                                                         register - CFG463. Kept for now to prevent s/w from breaking. */
-	uint32_t tmanlt                       : 5;  /**< Timer Modifier for Ack/Nak Latency Timer
-                                                         Increases the timer value for the Ack/Nak latency timer, in
+	uint32_t tmfcwt                       : 5;  /**< Used to be 'timer modifier for flow control watchdog timer.' This field is no longer used.
+                                                         and has moved to the queue status register -- PCIEEP*_CFG463. This field remains to
+                                                         prevent software from breaking. */
+	uint32_t tmanlt                       : 5;  /**< Timer modifier for Ack/Nak latency timer. Increases the timer value for the Ack/Nak
+                                                         latency timer, in increments of 64 clock cycles. */
+	uint32_t tmrt                         : 5;  /**< Timer modifier for replay timer. Increases the timer value for the replay timer, in
                                                          increments of 64 clock cycles. */
-	uint32_t tmrt                         : 5;  /**< Timer Modifier for Replay Timer
-                                                         Increases the timer value for the replay timer, in increments
-                                                         of 64 clock cycles. */
 	uint32_t reserved_8_13                : 6;
-	uint32_t mfuncn                       : 8;  /**< Max Number of Functions Supported
-                                                         Used for SR-IOV */
+	uint32_t mfuncn                       : 8;  /**< Max number of functions supported. Used for SR-IOV. */
 #else
 	uint32_t mfuncn                       : 8;
 	uint32_t reserved_8_13                : 6;
@@ -9943,8 +9865,8 @@ typedef union cvmx_pcieepx_cfg454 cvmx_pcieepx_cfg454_t;
 /**
  * cvmx_pcieep#_cfg455
  *
- * PCIE_CFG455 = Four hundred fifty-sixth 32-bits of PCIE type 0 config space
- * (Symbol Timer Register/Filter Mask Register 1)
+ * This register contains the four hundred fifty-sixth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg455 {
 	uint32_t u32;
@@ -10011,8 +9933,8 @@ typedef union cvmx_pcieepx_cfg455 cvmx_pcieepx_cfg455_t;
 /**
  * cvmx_pcieep#_cfg456
  *
- * PCIE_CFG456 = Four hundred fifty-seventh 32-bits of PCIE type 0 config space
- * (Filter Mask Register 2)
+ * This register contains the four hundred fifty-seventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg456 {
 	uint32_t u32;
@@ -10060,8 +9982,8 @@ typedef union cvmx_pcieepx_cfg456 cvmx_pcieepx_cfg456_t;
 /**
  * cvmx_pcieep#_cfg458
  *
- * PCIE_CFG458 = Four hundred fifty-ninth 32-bits of PCIE type 0 config space
- * (Debug Register 0)
+ * This register contains the four hundred fifty-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg458 {
 	uint32_t u32;
@@ -10091,8 +10013,8 @@ typedef union cvmx_pcieepx_cfg458 cvmx_pcieepx_cfg458_t;
 /**
  * cvmx_pcieep#_cfg459
  *
- * PCIE_CFG459 = Four hundred sixtieth 32-bits of PCIE type 0 config space
- * (Debug Register 1)
+ * This register contains the four hundred sixtieth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg459 {
 	uint32_t u32;
@@ -10122,8 +10044,8 @@ typedef union cvmx_pcieepx_cfg459 cvmx_pcieepx_cfg459_t;
 /**
  * cvmx_pcieep#_cfg460
  *
- * PCIE_CFG460 = Four hundred sixty-first 32-bits of PCIE type 0 config space
- * (Transmit Posted FC Credit Status)
+ * This register contains the four hundred sixty-first 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg460 {
 	uint32_t u32;
@@ -10161,8 +10083,8 @@ typedef union cvmx_pcieepx_cfg460 cvmx_pcieepx_cfg460_t;
 /**
  * cvmx_pcieep#_cfg461
  *
- * PCIE_CFG461 = Four hundred sixty-second 32-bits of PCIE type 0 config space
- * (Transmit Non-Posted FC Credit Status)
+ * This register contains the four hundred sixty-second 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg461 {
 	uint32_t u32;
@@ -10200,8 +10122,8 @@ typedef union cvmx_pcieepx_cfg461 cvmx_pcieepx_cfg461_t;
 /**
  * cvmx_pcieep#_cfg462
  *
- * PCIE_CFG462 = Four hundred sixty-third 32-bits of PCIE type 0 config space
- * (Transmit Completion FC Credit Status )
+ * This register contains the four hundred sixty-third 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg462 {
 	uint32_t u32;
@@ -10239,22 +10161,20 @@ typedef union cvmx_pcieepx_cfg462 cvmx_pcieepx_cfg462_t;
 /**
  * cvmx_pcieep#_cfg463
  *
- * PCIE_CFG463 = Four hundred sixty-fourth 32-bits of PCIE type 0 config space
- * (Queue Status)
+ * This register contains the four hundred sixty-fourth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg463 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg463_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t fcltoe                       : 1;  /**< FC Latency Timer Override Enable
-                                                         When this bit is set, the value from the "FC Latency Timer Override
-                                                         Value" field in this register will override the FC latency timer
-                                                         value that the core calculates according to the PCIe specification. */
+	uint32_t fcltoe                       : 1;  /**< FC latency timer override enable. When this bit is set, the value in
+                                                         PCIEEP*_CFG463[FCLTOV] will override the FC latency timer value that the core calculates
+                                                         according to the PCIe specification. */
 	uint32_t reserved_29_30               : 2;
-	uint32_t fcltov                       : 13; /**< FC Latency Timer Override Value
-                                                         When you set the "FC Latency Timer Override Enable" in this register,
-                                                         the value in this field will override the FC latency timer value
-                                                         that the core calculates according to the PCIe specification. */
+	uint32_t fcltov                       : 13; /**< FC latency timer override value. When you set PCIEEP*_CFG463[FCLTOE], the value in this
+                                                         field will override the FC latency timer value that the core calculates according to the
+                                                         PCIe specification. */
 	uint32_t reserved_3_15                : 13;
 	uint32_t rqne                         : 1;  /**< Received Queue Not Empty
                                                          Indicates there is data in one or more of the receive buffers. */
@@ -10312,8 +10232,8 @@ typedef union cvmx_pcieepx_cfg463 cvmx_pcieepx_cfg463_t;
 /**
  * cvmx_pcieep#_cfg464
  *
- * PCIE_CFG464 = Four hundred sixty-fifth 32-bits of PCIE type 0 config space
- * (VC Transmit Arbitration Register 1)
+ * This register contains the four hundred sixty-fifth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg464 {
 	uint32_t u32;
@@ -10349,8 +10269,8 @@ typedef union cvmx_pcieepx_cfg464 cvmx_pcieepx_cfg464_t;
 /**
  * cvmx_pcieep#_cfg465
  *
- * PCIE_CFG465 = Four hundred sixty-sixth 32-bits of PCIE type 0 config space
- * (VC Transmit Arbitration Register 2)
+ * This register contains the four hundred sixty-sixth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg465 {
 	uint32_t u32;
@@ -10386,8 +10306,8 @@ typedef union cvmx_pcieepx_cfg465 cvmx_pcieepx_cfg465_t;
 /**
  * cvmx_pcieep#_cfg466
  *
- * PCIE_CFG466 = Four hundred sixty-seventh 32-bits of PCIE type 0 config space
- * (VC0 Posted Receive Queue Control)
+ * This register contains the four hundred sixty-seventh 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg466 {
 	uint32_t u32;
@@ -10459,8 +10379,8 @@ typedef union cvmx_pcieepx_cfg466 cvmx_pcieepx_cfg466_t;
 /**
  * cvmx_pcieep#_cfg467
  *
- * PCIE_CFG467 = Four hundred sixty-eighth 32-bits of PCIE type 0 config space
- * (VC0 Non-Posted Receive Queue Control)
+ * This register contains the four hundred sixty-eighth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg467 {
 	uint32_t u32;
@@ -10514,8 +10434,8 @@ typedef union cvmx_pcieepx_cfg467 cvmx_pcieepx_cfg467_t;
 /**
  * cvmx_pcieep#_cfg468
  *
- * PCIE_CFG468 = Four hundred sixty-ninth 32-bits of PCIE type 0 config space
- * (VC0 Completion Receive Queue Control)
+ * This register contains the four hundred sixty-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg468 {
 	uint32_t u32;
@@ -10701,8 +10621,8 @@ typedef union cvmx_pcieepx_cfg492 cvmx_pcieepx_cfg492_t;
 /**
  * cvmx_pcieep#_cfg515
  *
- * PCIE_CFG515 = Five hundred sixteenth 32-bits of PCIE type 0 config space
- * (Port Logic Register (Gen2))
+ * This register contains the five hundred sixteenth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg515 {
 	uint32_t u32;
@@ -10760,8 +10680,8 @@ typedef union cvmx_pcieepx_cfg515 cvmx_pcieepx_cfg515_t;
 /**
  * cvmx_pcieep#_cfg516
  *
- * PCIE_CFG516 = Five hundred seventeenth 32-bits of PCIE type 0 config space
- * (PHY Status Register)
+ * This register contains the five hundred seventeenth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg516 {
 	uint32_t u32;
@@ -10791,8 +10711,8 @@ typedef union cvmx_pcieepx_cfg516 cvmx_pcieepx_cfg516_t;
 /**
  * cvmx_pcieep#_cfg517
  *
- * PCIE_CFG517 = Five hundred eighteenth 32-bits of PCIE type 0 config space
- * (PHY Control Register)
+ * This register contains the five hundred eighteenth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg517 {
 	uint32_t u32;
@@ -10822,33 +10742,27 @@ typedef union cvmx_pcieepx_cfg517 cvmx_pcieepx_cfg517_t;
 /**
  * cvmx_pcieep#_cfg548
  *
- * PCIE_CFG548 = Five hundred forty ninth 32-bits of PCIE type 0 config space
- * (Gen3 Control Register)
+ * This register contains the five hundred forty-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg548 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg548_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_19_31               : 13;
-	uint32_t dcbd                         : 1;  /**< Disable Balance Disable
-                                                         Disable DC Balance feature */
-	uint32_t dtdd                         : 1;  /**< DLLP Transmission Delay Disable
-                                                         Disable delay transmission of DLLPs before Equalization */
-	uint32_t ed                           : 1;  /**< Equalization Disable
-                                                         Disable Equalization feature */
+	uint32_t dcbd                         : 1;  /**< Disable balance disable. Disable DC balance feature. */
+	uint32_t dtdd                         : 1;  /**< DLLP transmission delay disable. Disable delay transmission of DLLPs before equalization. */
+	uint32_t ed                           : 1;  /**< Equalization disable. Disable equalization feature. */
 	uint32_t reserved_12_15               : 4;
-	uint32_t erd                          : 1;  /**< Equalization Redo Disable
-                                                         Disable requesting reset of EIEOS count during Equalization */
-	uint32_t ecrd                         : 1;  /**< Equalization EIEOS Count Reset Disable
-                                                         Disable requesting reset of EIEOS count during Equalization */
-	uint32_t ep2p3d                       : 1;  /**< Equalization Phase 2 and Phase 3 Disable
-                                                         This applies to Downstream Ports only */
-	uint32_t dsg3                         : 1;  /**< Disable Scrambler for Gen3 Data Rate
-                                                         The Gen3 scrambler/descrambler within the core needs to be
-                                                         disabled when the scrambling function is implemented outside
-                                                         of the core (within the PHY) */
+	uint32_t erd                          : 1;  /**< Equalization redo disable. Disable requesting reset of EIEOS count during equalization. */
+	uint32_t ecrd                         : 1;  /**< Equalization EIEOS count reset disable. Disable requesting reset of EIEOS count during
+                                                         equalization. */
+	uint32_t ep2p3d                       : 1;  /**< Equalization phase 2 and phase 3 disable. This applies to downstream ports only. */
+	uint32_t dsg3                         : 1;  /**< Disable scrambler for Gen3 data rate. The Gen3 scrambler/descrambler within the core needs
+                                                         to be disabled when the scrambling function is implemented outside of the core (within the
+                                                         PHY). */
 	uint32_t reserved_1_7                 : 7;
-	uint32_t grizdnc                      : 1;  /**< Gen3 Receiver Impedance ZRX-DC Not Compliant. */
+	uint32_t grizdnc                      : 1;  /**< Gen3 receiver impedance ZRX-DC not compliant. */
 #else
 	uint32_t grizdnc                      : 1;
 	uint32_t reserved_1_7                 : 7;
@@ -10870,62 +10784,52 @@ typedef union cvmx_pcieepx_cfg548 cvmx_pcieepx_cfg548_t;
 /**
  * cvmx_pcieep#_cfg554
  *
- * PCIE_CFG554 = Five hundred fifty fifth 32-bits of PCIE type 0 config space
- * (Gen3 EQ Control Register)
+ * This register contains the five hundred fifty-fifth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg554 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg554_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t prv                          : 16; /**< Preset Request Vector
-                                                         Requesting of Presets during the intial part of the EQ Master
-                                                         Phase. Encoding Scheme as follows:
-                                                         Bit [15:0] = 0x0: No preset will be requested and evaluated
-                                                         in the EQ Master Phase
-                                                         Bit [i] = 1: Preset=i will be requested and evaluated in the
-                                                         EQ Master Phase
-                                                         o 0000000000000000: No preset req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxxxxxx1: Preset 0 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxxxxx1x: Preset 1 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxxxx1xx: Preset 2 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxxx1xxx: Preset 3 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxx1xxxx: Preset 4 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxx1xxxxx: Preset 5 req/evaluated in EQ Master Phase
-                                                         o 00000xxxx1xxxxxx: Preset 6 req/evaluated in EQ Master Phase
-                                                         o 00000xxx1xxxxxxx: Preset 7 req/evaluated in EQ Master Phase
-                                                         o 00000xx1xxxxxxxx: Preset 8 req/evaluated in EQ Master Phase
-                                                         o 00000x1xxxxxxxxx: Preset 9 req/evaluated in EQ Master Phase
-                                                         o 000001xxxxxxxxxx: Preset 10 req/evaluated in EQ Master Phase
-                                                         o all other encodings: Reserved */
+	uint32_t prv                          : 16; /**< Preset request vector. Requesting of presets during the initial part of the EQ master
+                                                         phase. Encoding scheme as follows:
+                                                         Bit [15:0] = 0x0: No preset is requested and evaluated in the EQ master phase
+                                                         Bit [i] = 1: Preset=i is requested and evaluated in the EQ master phase
+                                                         - 0000000000000000: No preset req/evaluated in EQ master phase
+                                                         00000xxxxxxxxxx1: Preset 0 req/evaluated in EQ master phase
+                                                         00000xxxxxxxxx1x: Preset 1 req/evaluated in EQ master phase
+                                                         00000xxxxxxxx1xx: Preset 2 req/evaluated in EQ master phase
+                                                         00000xxxxxxx1xxx: Preset 3 req/evaluated in EQ master phase
+                                                         00000xxxxxx1xxxx: Preset 4 req/evaluated in EQ master phase
+                                                         00000xxxxx1xxxxx: Preset 5 req/evaluated in EQ master phase
+                                                         00000xxxx1xxxxxx: Preset 6 req/evaluated in EQ master phase
+                                                         00000xxx1xxxxxxx: Preset 7 req/evaluated in EQ master phase
+                                                         00000xx1xxxxxxxx: Preset 8 req/evaluated in EQ master phase
+                                                         00000x1xxxxxxxxx: Preset 9 req/evaluated in EQ master phase
+                                                         000001xxxxxxxxxx: Preset 10 req/evaluated in EQ master phase
+                                                         All other encodings: Reserved */
 	uint32_t reserved_6_7                 : 2;
-	uint32_t p23td                        : 1;  /**< Phase2_3 2 ms Timeout Disable
-                                                         Determine behavior in Phase2 for USP (Phase3 if DSP) when the
-                                                         PHY does not respond within 2ms to the assertion of RxEqEval:
-                                                         o 0: abort the current evaluation, stop any attempt to
-                                                         modify the remote transmitter settings, Phase2 will be
-                                                         terminated by the 24ms timeout
-                                                         o 1: ignore the 2ms timeout and continue as normal. This is
-                                                         used to support PHYs that require more than 2ms to
-                                                         respond to the assertion of RxEqEval. */
-	uint32_t bt                           : 1;  /**< Behavior After 24ms Timeout (When Optimal settings are not found)
-                                                         FOR a USP:
-                                                         Determine the next LTSSM state from Phase2
-                                                         o 0: Recovery.Speed
-                                                         o 1: Recovry.Equalization.Phase3
-                                                         FOR a DSP:
-                                                         Determine the next LTSSM state from Phase3
-                                                         o 0: Recovery.Speed
-                                                         o 1: Recovry.Equalization.RcrLock
-                                                         When optimal settings are not found then
-                                                         o Equalization Phase 3 Successful status bit is not set in the
-                                                         Link Status Register
-                                                         o Equalization Phase 3 Complete status bit is set in the
-                                                         Link Status Register */
-	uint32_t fm                           : 4;  /**< Feedback Mode
-                                                         - 0: Direction of Change
-                                                         - 1: Figure of Merit
-                                                         - 2-15: Reserved */
+	uint32_t p23td                        : 1;  /**< Phase2_3 2 ms timeout disable. Determine behavior in Phase2 for USP (Phase3 if DSP) when
+                                                         the PHY does not respond within 2 ms to the assertion of RxEqEval:
+                                                         0 = Abort the current evaluation; stop any attempt to modify the remote transmitter
+                                                         settings. Phase2 will be terminated by the 24 ms timeout.
+                                                         1 = Ignore the 2 ms timeout and continue as normal. This is used to support PHYs that
+                                                         require more than 2 ms to respond to the assertion of RxEqEval. */
+	uint32_t bt                           : 1;  /**< Behavior after 24 ms timeout (when optimal settings are not found).
+                                                         FOR a USP: determine the next LTSSM state from Phase2
+                                                         0 = Recovery.Speed
+                                                         1 = Recovry.Equalization.Phase3
+                                                         FOR a DSP: determine the next LTSSM state from Phase3
+                                                         0 = Recovery.Speed
+                                                         1 = Recovry.Equalization.RcrLock
+                                                         When optimal settings are not found:
+                                                         * Equalization phase 3 successful status bit is not set in the Link Status Register
+                                                         * Equalization phase 3 complete status bit is set in the Link Status Register */
+	uint32_t fm                           : 4;  /**< Feedback mode.
+                                                         0 = Direction of change.
+                                                         1 = Figure of merit.
+                                                         2-15 = Reserved. */
 #else
 	uint32_t fm                           : 4;
 	uint32_t bt                           : 1;
@@ -10942,14 +10846,14 @@ typedef union cvmx_pcieepx_cfg554 cvmx_pcieepx_cfg554_t;
 /**
  * cvmx_pcieep#_cfg558
  *
- * PCIE_CFG558 = Five hundred fifty ninth 32-bits of PCIE type 0 config space
- * (Gen3 PIPE Loopback Register)
+ * This register contains the five hundred fifty-ninth 32-bits of PCIe type 0 configuration space.
+ *
  */
 union cvmx_pcieepx_cfg558 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg558_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t ple                          : 1;  /**< Pipe Loopback Enable */
+	uint32_t ple                          : 1;  /**< Pipe loopback enable. */
 	uint32_t rxstatus                     : 31; /**< Reserved. */
 #else
 	uint32_t rxstatus                     : 31;
diff --git a/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h b/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
index 89a7667..f51083f 100644
--- a/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
@@ -3719,7 +3719,7 @@ static inline uint64_t CVMX_PCIERCX_CFG558(unsigned long block_id)
 /**
  * cvmx_pcierc#_cfg000
  *
- * PCIE_CFG000 = First 32-bits of PCIE type 1 config space (Device ID and Vendor ID Register)
+ * This register contains the first 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg000 {
@@ -3754,7 +3754,7 @@ typedef union cvmx_pciercx_cfg000 cvmx_pciercx_cfg000_t;
 /**
  * cvmx_pcierc#_cfg001
  *
- * PCIE_CFG001 = Second 32-bits of PCIE type 1 config space (Command/Status Register)
+ * This register contains the second 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg001 {
@@ -3841,7 +3841,7 @@ typedef union cvmx_pciercx_cfg001 cvmx_pciercx_cfg001_t;
 /**
  * cvmx_pcierc#_cfg002
  *
- * PCIE_CFG002 = Third 32-bits of PCIE type 1 config space (Revision ID/Class Code Register)
+ * This register contains the third 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg002 {
@@ -3882,8 +3882,8 @@ typedef union cvmx_pciercx_cfg002 cvmx_pciercx_cfg002_t;
 /**
  * cvmx_pcierc#_cfg003
  *
- * PCIE_CFG003 = Fourth 32-bits of PCIE type 1 config space (Cache Line Size/Master Latency
- * Timer/Header Type Register/BIST Register)
+ * This register contains the fourth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg003 {
 	uint32_t u32;
@@ -3930,7 +3930,7 @@ typedef union cvmx_pciercx_cfg003 cvmx_pciercx_cfg003_t;
 /**
  * cvmx_pcierc#_cfg004
  *
- * PCIE_CFG004 = Fifth 32-bits of PCIE type 1 config space (Base Address Register 0 - Low)
+ * This register contains the fifth 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg004 {
@@ -3961,7 +3961,7 @@ typedef union cvmx_pciercx_cfg004 cvmx_pciercx_cfg004_t;
 /**
  * cvmx_pcierc#_cfg005
  *
- * PCIE_CFG005 = Sixth 32-bits of PCIE type 1 config space (Base Address Register 0 - High)
+ * This register contains the sixth 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg005 {
@@ -3992,7 +3992,7 @@ typedef union cvmx_pciercx_cfg005 cvmx_pciercx_cfg005_t;
 /**
  * cvmx_pcierc#_cfg006
  *
- * PCIE_CFG006 = Seventh 32-bits of PCIE type 1 config space (Bus Number Registers)
+ * This register contains the seventh 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg006 {
@@ -4030,8 +4030,8 @@ typedef union cvmx_pciercx_cfg006 cvmx_pciercx_cfg006_t;
 /**
  * cvmx_pcierc#_cfg007
  *
- * PCIE_CFG007 = Eighth 32-bits of PCIE type 1 config space (IO Base and IO Limit/Secondary
- * Status Register)
+ * This register contains the eighth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg007 {
 	uint32_t u32;
@@ -4103,7 +4103,7 @@ typedef union cvmx_pciercx_cfg007 cvmx_pciercx_cfg007_t;
 /**
  * cvmx_pcierc#_cfg008
  *
- * PCIE_CFG008 = Ninth 32-bits of PCIE type 1 config space (Memory Base and Memory Limit Register)
+ * This register contains the ninth 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg008 {
@@ -4140,8 +4140,8 @@ typedef union cvmx_pciercx_cfg008 cvmx_pciercx_cfg008_t;
 /**
  * cvmx_pcierc#_cfg009
  *
- * PCIE_CFG009 = Tenth 32-bits of PCIE type 1 config space (Prefetchable Memory Base and Limit
- * Register)
+ * This register contains the tenth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg009 {
 	uint32_t u32;
@@ -4190,8 +4190,8 @@ typedef union cvmx_pciercx_cfg009 cvmx_pciercx_cfg009_t;
 /**
  * cvmx_pcierc#_cfg010
  *
- * PCIE_CFG010 = Eleventh 32-bits of PCIE type 1 config space (Prefetchable Base Upper 32 Bits
- * Register)
+ * This register contains the eleventh 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg010 {
 	uint32_t u32;
@@ -4223,8 +4223,8 @@ typedef union cvmx_pciercx_cfg010 cvmx_pciercx_cfg010_t;
 /**
  * cvmx_pcierc#_cfg011
  *
- * PCIE_CFG011 = Twelfth 32-bits of PCIE type 1 config space (Prefetchable Limit Upper 32 Bits
- * Register)
+ * This register contains the twelfth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg011 {
 	uint32_t u32;
@@ -4256,8 +4256,8 @@ typedef union cvmx_pciercx_cfg011 cvmx_pciercx_cfg011_t;
 /**
  * cvmx_pcierc#_cfg012
  *
- * PCIE_CFG012 = Thirteenth 32-bits of PCIE type 1 config space (IO Base and Limit Upper 16 Bits
- * Register)
+ * This register contains the thirteenth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg012 {
 	uint32_t u32;
@@ -4291,7 +4291,7 @@ typedef union cvmx_pciercx_cfg012 cvmx_pciercx_cfg012_t;
 /**
  * cvmx_pcierc#_cfg013
  *
- * PCIE_CFG013 = Fourteenth 32-bits of PCIE type 1 config space (Capability Pointer Register)
+ * This register contains the fourteenth 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg013 {
@@ -4327,7 +4327,7 @@ typedef union cvmx_pciercx_cfg013 cvmx_pciercx_cfg013_t;
 /**
  * cvmx_pcierc#_cfg014
  *
- * PCIE_CFG014 = Fifteenth 32-bits of PCIE type 1 config space (Expansion ROM Base Address Register)
+ * This register contains the fifteenth 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg014 {
@@ -4358,8 +4358,8 @@ typedef union cvmx_pciercx_cfg014 cvmx_pciercx_cfg014_t;
 /**
  * cvmx_pcierc#_cfg015
  *
- * PCIE_CFG015 = Sixteenth 32-bits of PCIE type 1 config space (Interrupt Line Register/Interrupt
- * Pin/Bridge Control Register)
+ * This register contains the sixteenth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg015 {
 	uint32_t u32;
@@ -4434,10 +4434,8 @@ typedef union cvmx_pciercx_cfg015 cvmx_pciercx_cfg015_t;
 /**
  * cvmx_pcierc#_cfg016
  *
- * PCIE_CFG016 = Seventeenth 32-bits of PCIE type 1 config space
- * (Power Management Capability ID/
- * Power Management Next Item Pointer/
- * Power Management Capabilities Register)
+ * This register contains the seventeenth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg016 {
 	uint32_t u32;
@@ -4502,8 +4500,8 @@ typedef union cvmx_pciercx_cfg016 cvmx_pciercx_cfg016_t;
 /**
  * cvmx_pcierc#_cfg017
  *
- * PCIE_CFG017 = Eighteenth 32-bits of PCIE type 1 config space (Power Management Control and
- * Status Register)
+ * This register contains the eighteenth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg017 {
 	uint32_t u32;
@@ -4566,10 +4564,8 @@ typedef union cvmx_pciercx_cfg017 cvmx_pciercx_cfg017_t;
 /**
  * cvmx_pcierc#_cfg020
  *
- * PCIE_CFG020 = Twenty-first 32-bits of PCIE type 1 config space
- * (MSI Capability ID/
- * MSI Next Item Pointer/
- * MSI Control Register)
+ * This register contains the twenty-first 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg020 {
 	uint32_t u32;
@@ -4650,25 +4646,20 @@ union cvmx_pciercx_cfg020 {
 	struct cvmx_pciercx_cfg020_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_25_31               : 7;
-	uint32_t pvms                         : 1;  /**< PCI PVM Support */
-	uint32_t m64                          : 1;  /**< "64-bit Address Capable, writable through PEM#_CFG_WR
-                                                         However, the application must not change this field." */
-	uint32_t mme                          : 3;  /**< Multiple Message Enabled
-                                                         Indicates that multiple Message mode is enabled by system
-                                                         software. The number of Messages enabled must be less than
-                                                         or equal to the Multiple Message Capable value. */
-	uint32_t mmc                          : 3;  /**< "Multiple Message Capable, writable through PEM#_CFG_WR
-                                                         However, the application must not change this field." */
-	uint32_t msien                        : 1;  /**< MSI Enabled
-                                                         When set, INTx must be disabled.
-                                                         This bit must never be set, as internal-MSI is not supported in
-                                                         RC mode. (Note that this has no effect on external MSI, which
-                                                         will be commonly used in RC mode.) */
-	uint32_t ncp                          : 8;  /**< "Next Capability Pointer
-                                                         Points to PCI Express Capabilities by default,
-                                                         writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t msicid                       : 8;  /**< MSI Capability ID */
+	uint32_t pvms                         : 1;  /**< PCI PVM support. */
+	uint32_t m64                          : 1;  /**< 64-bit address capable, writable through PEM(0..3)_CFG_WR. However, the application must
+                                                         not change this field. */
+	uint32_t mme                          : 3;  /**< Multiple message enabled. Indicates that multiple message mode is enabled by system
+                                                         software. The number of messages enabled must be less than or equal to the multiple
+                                                         message capable (MMC) value. */
+	uint32_t mmc                          : 3;  /**< Multiple message capable, writable through PEM(0..3)_CFG_WR. However, the application must
+                                                         not change this field. */
+	uint32_t msien                        : 1;  /**< MSI enabled. When set, INTx must be disabled. This bit must never be set, as internal-MSI
+                                                         is not supported in RC mode. (Note that this has no effect on external MSI, which is
+                                                         commonly used in RC mode.) */
+	uint32_t ncp                          : 8;  /**< Next capability pointer. Points to PCI Express capabilities by default, writable through
+                                                         PEM(0..3)_CFG_WR. However, the application must not change this field. */
+	uint32_t msicid                       : 8;  /**< MSI capability ID. */
 #else
 	uint32_t msicid                       : 8;
 	uint32_t ncp                          : 8;
@@ -4687,8 +4678,8 @@ typedef union cvmx_pciercx_cfg020 cvmx_pciercx_cfg020_t;
 /**
  * cvmx_pcierc#_cfg021
  *
- * PCIE_CFG021 = Twenty-second 32-bits of PCIE type 1 config space (MSI Lower 32 Bits Address
- * Register)
+ * This register contains the twenty-second 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg021 {
 	uint32_t u32;
@@ -4720,7 +4711,7 @@ typedef union cvmx_pciercx_cfg021 cvmx_pciercx_cfg021_t;
 /**
  * cvmx_pcierc#_cfg022
  *
- * PCIE_CFG022 = Twenty-third 32-bits of PCIE type 1 config space (MSI Upper 32 bits Address Register)
+ * This register contains the twenty-third 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg022 {
@@ -4751,7 +4742,7 @@ typedef union cvmx_pciercx_cfg022 cvmx_pciercx_cfg022_t;
 /**
  * cvmx_pcierc#_cfg023
  *
- * PCIE_CFG023 = Twenty-fourth 32-bits of PCIE type 1 config space (MSI Data Register)
+ * This register contains the twenty-fourth 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg023 {
@@ -4786,9 +4777,8 @@ typedef union cvmx_pciercx_cfg023 cvmx_pciercx_cfg023_t;
 /**
  * cvmx_pcierc#_cfg028
  *
- * PCIE_CFG028 = Twenty-ninth 32-bits of PCIE type 1 config space
- * (PCI Express Capabilities List Register/
- * PCI Express Capabilities Register)
+ * This register contains the twenty-ninth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg028 {
 	uint32_t u32;
@@ -4838,7 +4828,7 @@ typedef union cvmx_pciercx_cfg028 cvmx_pciercx_cfg028_t;
 /**
  * cvmx_pcierc#_cfg029
  *
- * PCIE_CFG029 = Thirtieth 32-bits of PCIE type 1 config space (Device Capabilities Register)
+ * This register contains the thirtieth 32-bits of type 1 PCIe configuration space.
  *
  */
 union cvmx_pciercx_cfg029 {
@@ -4902,8 +4892,8 @@ typedef union cvmx_pciercx_cfg029 cvmx_pciercx_cfg029_t;
 /**
  * cvmx_pcierc#_cfg030
  *
- * PCIE_CFG030 = Thirty-first 32-bits of PCIE type 1 config space
- * (Device Control Register/Device Status Register)
+ * This register contains the thirty-first 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg030 {
 	uint32_t u32;
@@ -5018,8 +5008,8 @@ typedef union cvmx_pciercx_cfg030 cvmx_pciercx_cfg030_t;
 /**
  * cvmx_pcierc#_cfg031
  *
- * PCIE_CFG031 = Thirty-second 32-bits of PCIE type 1 config space
- * (Link Capabilities Register)
+ * This register contains the thirty-second 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg031 {
 	uint32_t u32;
@@ -5148,8 +5138,8 @@ typedef union cvmx_pciercx_cfg031 cvmx_pciercx_cfg031_t;
 /**
  * cvmx_pcierc#_cfg032
  *
- * PCIE_CFG032 = Thirty-third 32-bits of PCIE type 1 config space
- * (Link Control Register/Link Status Register)
+ * This register contains the thirty-third 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg032 {
 	uint32_t u32;
@@ -5250,8 +5240,8 @@ typedef union cvmx_pciercx_cfg032 cvmx_pciercx_cfg032_t;
 /**
  * cvmx_pcierc#_cfg033
  *
- * PCIE_CFG033 = Thirty-fourth 32-bits of PCIE type 1 config space
- * (Slot Capabilities Register)
+ * This register contains the thirty-fourth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg033 {
 	uint32_t u32;
@@ -5313,8 +5303,8 @@ typedef union cvmx_pciercx_cfg033 cvmx_pciercx_cfg033_t;
 /**
  * cvmx_pcierc#_cfg034
  *
- * PCIE_CFG034 = Thirty-fifth 32-bits of PCIE type 1 config space
- * (Slot Control Register/Slot Status Register)
+ * This register contains the thirty-fifth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg034 {
 	uint32_t u32;
@@ -5386,8 +5376,8 @@ typedef union cvmx_pciercx_cfg034 cvmx_pciercx_cfg034_t;
 /**
  * cvmx_pcierc#_cfg035
  *
- * PCIE_CFG035 = Thirty-sixth 32-bits of PCIE type 1 config space
- * (Root Control Register/Root Capabilities Register)
+ * This register contains the thirty-sixth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg035 {
 	uint32_t u32;
@@ -5433,8 +5423,8 @@ typedef union cvmx_pciercx_cfg035 cvmx_pciercx_cfg035_t;
 /**
  * cvmx_pcierc#_cfg036
  *
- * PCIE_CFG036 = Thirty-seventh 32-bits of PCIE type 1 config space
- * (Root Status Register)
+ * This register contains the thirty-seventh 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg036 {
 	uint32_t u32;
@@ -5470,23 +5460,21 @@ typedef union cvmx_pciercx_cfg036 cvmx_pciercx_cfg036_t;
 /**
  * cvmx_pcierc#_cfg037
  *
- * PCIE_CFG037 = Thirty-eighth 32-bits of PCIE type 1 config space
- * (Device Capabilities 2 Register)
+ * This register contains the thirty-eighth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg037 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg037_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t meetp                        : 2;  /**< Max End-End TLP Prefixes
-                                                         o 01: 1
-                                                         o 10: 2
-                                                         o 11: 3
-                                                         0 00: 4 */
-	uint32_t eetps                        : 1;  /**< End-End TLP Prefix Supported
-                                                         (Not Supported) */
-	uint32_t effs                         : 1;  /**< Extended Fmt Field Supported
-                                                         (Not Supported) */
+	uint32_t meetp                        : 2;  /**< Max end-end TLP prefixes.
+                                                         0x1 = 1.
+                                                         0x2 = 2.
+                                                         0x3 = 3.
+                                                         0x0 = 4. */
+	uint32_t eetps                        : 1;  /**< End-end TLP prefix supported (not supported). */
+	uint32_t effs                         : 1;  /**< Extended fmt field supported (not supported). */
 	uint32_t obffs                        : 2;  /**< Optimized Buffer Flush Fill (OBFF) Supported
                                                          (Not Supported) */
 	uint32_t reserved_12_17               : 6;
@@ -5619,33 +5607,26 @@ union cvmx_pciercx_cfg037 {
 	struct cvmx_pciercx_cfg037_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t meetp                        : 2;  /**< Max End-End TLP Prefixes
-                                                         o 01: 1
-                                                         o 10: 2
-                                                         o 11: 3
-                                                         0 00: 4 */
-	uint32_t eetps                        : 1;  /**< End-End TLP Prefix Supported
-                                                         (Not Supported) */
-	uint32_t effs                         : 1;  /**< Extended Fmt Field Supported
-                                                         (Not Supported) */
-	uint32_t obffs                        : 2;  /**< Optimized Buffer Flush Fill (OBFF) Supported
-                                                         (Not Supported) */
+	uint32_t meetp                        : 2;  /**< Max end-end TLP prefixes.
+                                                         0x1 = 1.
+                                                         0x2 = 2.
+                                                         0x3 = 3.
+                                                         0x0 = 4. */
+	uint32_t eetps                        : 1;  /**< End-end TLP prefix supported (not supported). */
+	uint32_t effs                         : 1;  /**< Extended fmt field supported (not supported). */
+	uint32_t obffs                        : 2;  /**< Optimized buffer flush fill (OBFF) supported (not supported). */
 	uint32_t reserved_14_17               : 4;
-	uint32_t tph                          : 2;  /**< TPH Completer Supported
-                                                         (Not Supported) */
-	uint32_t ltrs                         : 1;  /**< Latency Tolerance Reporting (LTR) Mechanism Supported
-                                                         (Not Supported) */
-	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR Passing
-                                                         When set, the routing element never carries out the passing
-                                                         permitted in the Relaxed Ordering Model. */
-	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp Supported
-                                                         (Not Supported) */
-	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp Supported */
-	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp Supported */
-	uint32_t atom_ops                     : 1;  /**< AtomicOp Routing Supported */
-	uint32_t ari_fw                       : 1;  /**< ARI Forwarding Supported */
-	uint32_t ctds                         : 1;  /**< Completion Timeout Disable Supported */
-	uint32_t ctrs                         : 4;  /**< Completion Timeout Ranges Supported */
+	uint32_t tph                          : 2;  /**< TPH completer supported (not supported). */
+	uint32_t ltrs                         : 1;  /**< Latency tolerance reporting (LTR) mechanism supported (not supported). */
+	uint32_t noroprpr                     : 1;  /**< No RO-enabled PR-PR passing. When set, the routing element never carries out the passing
+                                                         permitted in the relaxed ordering model. */
+	uint32_t atom128s                     : 1;  /**< 128-bit AtomicOp supported (not supported). */
+	uint32_t atom64s                      : 1;  /**< 64-bit AtomicOp supported. */
+	uint32_t atom32s                      : 1;  /**< 32-bit AtomicOp supported. */
+	uint32_t atom_ops                     : 1;  /**< AtomicOp routing supported. */
+	uint32_t ari_fw                       : 1;  /**< Alternate routing ID forwarding supported. */
+	uint32_t ctds                         : 1;  /**< Completion timeout disable supported. */
+	uint32_t ctrs                         : 4;  /**< Completion timeout ranges supported. */
 #else
 	uint32_t ctrs                         : 4;
 	uint32_t ctds                         : 1;
@@ -5712,15 +5693,15 @@ typedef union cvmx_pciercx_cfg037 cvmx_pciercx_cfg037_t;
 /**
  * cvmx_pcierc#_cfg038
  *
- * PCIE_CFG038 = Thirty-ninth 32-bits of PCIE type 1 config space
- * (Device Control 2 Register)
+ * This register contains the thirty-ninth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg038 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg038_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_16_31               : 16;
-	uint32_t eetpb                        : 1;  /**< Unsupported End-End TLP Prefix Blocking */
+	uint32_t eetpb                        : 1;  /**< Unsupported end-end TLP prefix blocking. */
 	uint32_t obffe                        : 2;  /**< Optimized Buffer Flush Fill (OBFF) Enable
                                                          (Not Supported) */
 	uint32_t reserved_11_12               : 2;
@@ -5872,8 +5853,8 @@ typedef union cvmx_pciercx_cfg038 cvmx_pciercx_cfg038_t;
 /**
  * cvmx_pcierc#_cfg039
  *
- * PCIE_CFG039 = Fourtieth 32-bits of PCIE type 1 config space
- * (Link Capabilities 2 Register)
+ * This register contains the fortieth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg039 {
 	uint32_t u32;
@@ -5929,19 +5910,19 @@ typedef union cvmx_pciercx_cfg039 cvmx_pciercx_cfg039_t;
 /**
  * cvmx_pcierc#_cfg040
  *
- * PCIE_CFG040 = Fourty-first 32-bits of PCIE type 1 config space
- * (Link Control 2 Register/Link Status 2 Register)
+ * This register contains the forty-first 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg040 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg040_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_22_31               : 10;
-	uint32_t ler                          : 1;  /**< Link Equalization Request */
-	uint32_t ep3s                         : 1;  /**< Equalization Phase 3 Successful */
-	uint32_t ep2s                         : 1;  /**< Equalization Phase 2 Successful */
-	uint32_t ep1s                         : 1;  /**< Equalization Phase 1 Successful */
-	uint32_t eqc                          : 1;  /**< Equalization Complete */
+	uint32_t ler                          : 1;  /**< Link equalization request */
+	uint32_t ep3s                         : 1;  /**< Equalization phase 3 successful */
+	uint32_t ep2s                         : 1;  /**< Equalization phase 2 successful */
+	uint32_t ep1s                         : 1;  /**< Equalization phase 1 successful */
+	uint32_t eqc                          : 1;  /**< Equalization complete */
 	uint32_t cdl                          : 1;  /**< Current De-emphasis Level
                                                          When the Link is operating at 5 GT/s speed, this bit
                                                          reflects the level of de-emphasis. Encodings:
@@ -6156,8 +6137,8 @@ typedef union cvmx_pciercx_cfg040 cvmx_pciercx_cfg040_t;
 /**
  * cvmx_pcierc#_cfg041
  *
- * PCIE_CFG041 = Fourty-second 32-bits of PCIE type 1 config space
- * (Slot Capabilities 2 Register)
+ * This register contains the forty-second 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg041 {
 	uint32_t u32;
@@ -6187,8 +6168,8 @@ typedef union cvmx_pciercx_cfg041 cvmx_pciercx_cfg041_t;
 /**
  * cvmx_pcierc#_cfg042
  *
- * PCIE_CFG042 = Fourty-third 32-bits of PCIE type 1 config space
- * (Slot Control 2 Register/Slot Status 2 Register)
+ * This register contains the forty-third 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg042 {
 	uint32_t u32;
@@ -6218,29 +6199,23 @@ typedef union cvmx_pciercx_cfg042 cvmx_pciercx_cfg042_t;
 /**
  * cvmx_pcierc#_cfg044
  *
- * PCIE_CFG044 = Fourty-fifth 32-bits of PCIE type 1 config space
- * (MSI-X Capability ID/
- * MSI-X Next Item Pointer/
- * MSI-X Control Register)
+ * This register contains the forty-fifth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg044 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg044_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixen                       : 1;  /**< MSI-X Enable
-                                                         If MSI-X is enabled, MIS and INTx must be disabled. */
-	uint32_t funm                         : 1;  /**< Function Mask
-                                                         1b: All vectors associated with the function are masked,
-                                                         regardless of their respective per-vector mask bits.
-                                                         0b: Each vectors Mask bit determines whether the vector
-                                                         is masked or not. */
+	uint32_t msixen                       : 1;  /**< MSI-X enable. If MSI-X is enabled, MSI and INTx must be disabled. */
+	uint32_t funm                         : 1;  /**< Function mask.
+                                                         0 = Each vectors mask bit determines whether the vector is masked or not.
+                                                         1 = All vectors associated with the function are masked, regardless of their respective
+                                                         per-vector mask bits. */
 	uint32_t reserved_27_29               : 3;
-	uint32_t msixts                       : 11; /**< MSI-X Table Size
-                                                         Encoded as (Table Size - 1) */
-	uint32_t ncp                          : 8;  /**< "Next Capability Pointer
-                                                         writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t msixcid                      : 8;  /**< MSI-X Capability ID */
+	uint32_t msixts                       : 11; /**< MSI-X table size encoded as (table size - 1). */
+	uint32_t ncp                          : 8;  /**< "Next capability pointer. Writable through PEM#_CFG_WR. However, the application must not
+                                                         change this field." */
+	uint32_t msixcid                      : 8;  /**< MSI-X capability ID. */
 #else
 	uint32_t msixcid                      : 8;
 	uint32_t ncp                          : 8;
@@ -6257,25 +6232,21 @@ typedef union cvmx_pciercx_cfg044 cvmx_pciercx_cfg044_t;
 /**
  * cvmx_pcierc#_cfg045
  *
- * PCIE_CFG045 = Fourty-sixth 32-bits of PCIE type 1 config space
- * (MSI-X Table Offset and BIR Register)
+ * This register contains the forty-sixth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg045 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg045_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixtoffs                    : 29; /**< "MSI-X Table Offset Register
-                                                         Base address of the MSI-X Table, as an offset from the base
-                                                         address of te BAR indicated by the Table BIR bits.
-                                                         writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t msixtbir                     : 3;  /**< "MSI-X Table BAR Indicator Register (BIR)
-                                                         Indicates which BAR is used to map the MSI-X Table
-                                                         into memory space
-                                                         000 - 100: BAR#
-                                                         110 - 111: Reserved
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t msixtoffs                    : 29; /**< MSI-X table offset register. Base address of the MSI-X Table, as an offset from the base
+                                                         address of the BAR indicated by the table BIR bits. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t msixtbir                     : 3;  /**< "MSI-X table BAR indicator register (BIR). Indicates which BAR is used to map the MSI-X
+                                                         table into memory space.
+                                                         0x0 - 0x4 = BAR#
+                                                         0x6 - 0x7 = Reserved
+                                                         Writable through PEM(0..3)_CFG_WR. However, the application must not change this field." */
 #else
 	uint32_t msixtbir                     : 3;
 	uint32_t msixtoffs                    : 29;
@@ -6288,25 +6259,21 @@ typedef union cvmx_pciercx_cfg045 cvmx_pciercx_cfg045_t;
 /**
  * cvmx_pcierc#_cfg046
  *
- * PCIE_CFG046 = Fourty-seventh 32-bits of PCIE type 1 config space
- * (MSI-X PBA Offset and BIR Register)
+ * This register contains the forty-seventh 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg046 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg046_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t msixpoffs                    : 29; /**< "MSI-X Table Offset Register
-                                                         Base address of the MSI-X PBA, as an offset from the base
-                                                         address of te BAR indicated by the Table PBA bits.
-                                                         writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t msixpbir                     : 3;  /**< "MSI-X PBA BAR Indicator Register (BIR)
-                                                         Indicates which BAR is used to map the MSI-X Pending Bit Array
-                                                         into memory space
-                                                         000 - 100: BAR#
-                                                         110 - 111: Reserved
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t msixpoffs                    : 29; /**< MSI-X table offset register. Base address of the MSI-X PBA, as an offset from the base
+                                                         address of the BAR indicated by the table PBA bits. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t msixpbir                     : 3;  /**< "MSI-X PBA BAR indicator register (BIR). Indicates which BAR is used to map the MSI-X
+                                                         pending bit array                                                  into memory space.
+                                                         0x0 - 0x4 = BAR#
+                                                         0x6 - 0x7 = Reserved
+                                                         Writable through PEM(0..3)_CFG_WR. However, the application must not change this field." */
 #else
 	uint32_t msixpbir                     : 3;
 	uint32_t msixpoffs                    : 29;
@@ -6319,8 +6286,8 @@ typedef union cvmx_pciercx_cfg046 cvmx_pciercx_cfg046_t;
 /**
  * cvmx_pcierc#_cfg064
  *
- * PCIE_CFG064 = Sixty-fifth 32-bits of PCIE type 1 config space
- * (PCI Express Extended Capability Header)
+ * This register contains the sixty-fifth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg064 {
 	uint32_t u32;
@@ -6354,15 +6321,15 @@ typedef union cvmx_pciercx_cfg064 cvmx_pciercx_cfg064_t;
 /**
  * cvmx_pcierc#_cfg065
  *
- * PCIE_CFG065 = Sixty-sixth 32-bits of PCIE type 1 config space
- * (Uncorrectable Error Status Register)
+ * This register contains the sixty-sixth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg065 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg065_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Status */
+	uint32_t tpbes                        : 1;  /**< Unsupported TLP prefix blocked error status. */
 	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Status */
 	uint32_t reserved_23_23               : 1;
 	uint32_t ucies                        : 1;  /**< Uncorrectable Internal Error Status */
@@ -6529,15 +6496,15 @@ typedef union cvmx_pciercx_cfg065 cvmx_pciercx_cfg065_t;
 /**
  * cvmx_pcierc#_cfg066
  *
- * PCIE_CFG066 = Sixty-seventh 32-bits of PCIE type 1 config space
- * (Uncorrectable Error Mask Register)
+ * This register contains the sixty-seventh 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg066 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg066_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbem                        : 1;  /**< Unsupported TLP Prefix Blocked Error Mask */
+	uint32_t tpbem                        : 1;  /**< Unsupported TLP prefix blocked error mask. */
 	uint32_t uatombm                      : 1;  /**< Unsupported AtomicOp Egress Blocked Mask */
 	uint32_t reserved_23_23               : 1;
 	uint32_t uciem                        : 1;  /**< Uncorrectable Internal Error Mask */
@@ -6704,15 +6671,15 @@ typedef union cvmx_pciercx_cfg066 cvmx_pciercx_cfg066_t;
 /**
  * cvmx_pcierc#_cfg067
  *
- * PCIE_CFG067 = Sixty-eighth 32-bits of PCIE type 1 config space
- * (Uncorrectable Error Severity Register)
+ * This register contains the sixty-eighth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg067 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg067_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Severity */
+	uint32_t tpbes                        : 1;  /**< Unsupported TLP prefix blocked error severity. */
 	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Severity */
 	uint32_t reserved_21_23               : 3;
 	uint32_t ures                         : 1;  /**< Unsupported Request Error Severity */
@@ -6870,21 +6837,21 @@ union cvmx_pciercx_cfg067 {
 	struct cvmx_pciercx_cfg067_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
-	uint32_t tpbes                        : 1;  /**< Unsupported TLP Prefix Blocked Error Severity */
-	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp Egress Blocked Severity */
+	uint32_t tpbes                        : 1;  /**< Unsupported TLP prefix blocked error severity. */
+	uint32_t uatombs                      : 1;  /**< Unsupported AtomicOp egress blocked severity. */
 	uint32_t unsuperr                     : 3;  /**< Reserved. */
-	uint32_t ures                         : 1;  /**< Unsupported Request Error Severity */
-	uint32_t ecrces                       : 1;  /**< ECRC Error Severity */
-	uint32_t mtlps                        : 1;  /**< Malformed TLP Severity */
-	uint32_t ros                          : 1;  /**< Receiver Overflow Severity */
-	uint32_t ucs                          : 1;  /**< Unexpected Completion Severity */
-	uint32_t cas                          : 1;  /**< Completer Abort Severity */
-	uint32_t cts                          : 1;  /**< Completion Timeout Severity */
-	uint32_t fcpes                        : 1;  /**< Flow Control Protocol Error Severity */
-	uint32_t ptlps                        : 1;  /**< Poisoned TLP Severity */
+	uint32_t ures                         : 1;  /**< Unsupported request error severity. */
+	uint32_t ecrces                       : 1;  /**< ECRC error severity. */
+	uint32_t mtlps                        : 1;  /**< Malformed TLP severity. */
+	uint32_t ros                          : 1;  /**< Receiver overflow severity. */
+	uint32_t ucs                          : 1;  /**< Unexpected completion severity. */
+	uint32_t cas                          : 1;  /**< Completer abort severity. */
+	uint32_t cts                          : 1;  /**< Completion timeout severity. */
+	uint32_t fcpes                        : 1;  /**< Flow control protocol error severity. */
+	uint32_t ptlps                        : 1;  /**< Poisoned TLP severity. */
 	uint32_t reserved_6_11                : 6;
-	uint32_t sdes                         : 1;  /**< Surprise Down Error Severity (not supported) */
-	uint32_t dlpes                        : 1;  /**< Data Link Protocol Error Severity */
+	uint32_t sdes                         : 1;  /**< Surprise down error severity (not supported). */
+	uint32_t dlpes                        : 1;  /**< Data link protocol error severity. */
 	uint32_t reserved_0_3                 : 4;
 #else
 	uint32_t reserved_0_3                 : 4;
@@ -6913,8 +6880,8 @@ typedef union cvmx_pciercx_cfg067 cvmx_pciercx_cfg067_t;
 /**
  * cvmx_pcierc#_cfg068
  *
- * PCIE_CFG068 = Sixty-ninth 32-bits of PCIE type 1 config space
- * (Correctable Error Status Register)
+ * This register contains the sixty-ninth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg068 {
 	uint32_t u32;
@@ -6984,8 +6951,8 @@ typedef union cvmx_pciercx_cfg068 cvmx_pciercx_cfg068_t;
 /**
  * cvmx_pcierc#_cfg069
  *
- * PCIE_CFG069 = Seventieth 32-bits of PCIE type 1 config space
- * (Correctable Error Mask Register)
+ * This register contains the seventieth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg069 {
 	uint32_t u32;
@@ -7055,15 +7022,15 @@ typedef union cvmx_pciercx_cfg069 cvmx_pciercx_cfg069_t;
 /**
  * cvmx_pcierc#_cfg070
  *
- * PCIE_CFG070 = Seventy-first 32-bits of PCIE type 1 config space
- * (Advanced Capabilities and Control Register)
+ * This register contains the seventy-first 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg070 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg070_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_12_31               : 20;
-	uint32_t tplp                         : 1;  /**< TLP Prefix Log Present */
+	uint32_t tplp                         : 1;  /**< TLP prefix log present. */
 	uint32_t reserved_9_10                : 2;
 	uint32_t ce                           : 1;  /**< ECRC Check Enable */
 	uint32_t cc                           : 1;  /**< ECRC Check Capable */
@@ -7116,9 +7083,8 @@ typedef union cvmx_pciercx_cfg070 cvmx_pciercx_cfg070_t;
 /**
  * cvmx_pcierc#_cfg071
  *
- * PCIE_CFG071 = Seventy-second 32-bits of PCIE type 1 config space
- * (Header Log Register 1)
- * The Header Log registers collect the header for the TLP corresponding to a detected error.
+ * This register contains the seventy-second 32-bits of type 1 PCIe configuration space.  The
+ * header log registers collect the header for the TLP corresponding to a detected error.
  */
 union cvmx_pciercx_cfg071 {
 	uint32_t u32;
@@ -7148,9 +7114,8 @@ typedef union cvmx_pciercx_cfg071 cvmx_pciercx_cfg071_t;
 /**
  * cvmx_pcierc#_cfg072
  *
- * PCIE_CFG072 = Seventy-third 32-bits of PCIE type 1 config space
- * (Header Log Register 2)
- * The Header Log registers collect the header for the TLP corresponding to a detected error.
+ * This register contains the seventy-third 32-bits of type 1 PCIe configuration space.  The
+ * header log registers collect the header for the TLP corresponding to a detected error.
  */
 union cvmx_pciercx_cfg072 {
 	uint32_t u32;
@@ -7180,9 +7145,8 @@ typedef union cvmx_pciercx_cfg072 cvmx_pciercx_cfg072_t;
 /**
  * cvmx_pcierc#_cfg073
  *
- * PCIE_CFG073 = Seventy-fourth 32-bits of PCIE type 1 config space
- * (Header Log Register 3)
- * The Header Log registers collect the header for the TLP corresponding to a detected error.
+ * This register contains the seventy-fourth 32-bits of type 1 PCIe configuration space.  The
+ * header log registers collect the header for the TLP corresponding to a detected error.
  */
 union cvmx_pciercx_cfg073 {
 	uint32_t u32;
@@ -7212,9 +7176,8 @@ typedef union cvmx_pciercx_cfg073 cvmx_pciercx_cfg073_t;
 /**
  * cvmx_pcierc#_cfg074
  *
- * PCIE_CFG074 = Seventy-fifth 32-bits of PCIE type 1 config space
- * (Header Log Register 4)
- * The Header Log registers collect the header for the TLP corresponding to a detected error.
+ * This register contains the seventy-fifth 32-bits of type 1 PCIe configuration space.  The
+ * header log registers collect the header for the TLP corresponding to a detected error.
  */
 union cvmx_pciercx_cfg074 {
 	uint32_t u32;
@@ -7244,8 +7207,8 @@ typedef union cvmx_pciercx_cfg074 cvmx_pciercx_cfg074_t;
 /**
  * cvmx_pcierc#_cfg075
  *
- * PCIE_CFG075 = Seventy-sixth 32-bits of PCIE type 1 config space
- * (Root Error Command Register)
+ * This register contains the seventy-sixth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg075 {
 	uint32_t u32;
@@ -7281,8 +7244,8 @@ typedef union cvmx_pciercx_cfg075 cvmx_pciercx_cfg075_t;
 /**
  * cvmx_pcierc#_cfg076
  *
- * PCIE_CFG076 = Seventy-seventh 32-bits of PCIE type 1 config space
- * (Root Error Status Register)
+ * This register contains the seventy-seventh 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg076 {
 	uint32_t u32;
@@ -7329,8 +7292,8 @@ typedef union cvmx_pciercx_cfg076 cvmx_pciercx_cfg076_t;
 /**
  * cvmx_pcierc#_cfg077
  *
- * PCIE_CFG077 = Seventy-eighth 32-bits of PCIE type 1 config space
- * (Error Source Identification Register)
+ * This register contains the seventy-eighth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg077 {
 	uint32_t u32;
@@ -7362,16 +7325,16 @@ typedef union cvmx_pciercx_cfg077 cvmx_pciercx_cfg077_t;
 /**
  * cvmx_pcierc#_cfg086
  *
- * PCIE_CFG086 = Eighty-seventh 32-bits of PCIE type 0 config space
- * (PCI Express Secondary Capability (Gen3) Header)
+ * This register contains the eighty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg086 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg086_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t nco                          : 12; /**< Next Capability Offset */
-	uint32_t cv                           : 4;  /**< Capability Version */
-	uint32_t pcieec                       : 16; /**< PCIE Express Extended Capability */
+	uint32_t nco                          : 12; /**< Next capability offset. */
+	uint32_t cv                           : 4;  /**< Capability version. */
+	uint32_t pcieec                       : 16; /**< PCIE Express extended capability. */
 #else
 	uint32_t pcieec                       : 16;
 	uint32_t cv                           : 4;
@@ -7385,16 +7348,16 @@ typedef union cvmx_pciercx_cfg086 cvmx_pciercx_cfg086_t;
 /**
  * cvmx_pcierc#_cfg087
  *
- * PCIE_CFG087 = Eighty-eighth 32-bits of PCIE type 0 config space
- * (Link Control 3)
+ * This register contains the eighty-eighth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg087 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg087_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_2_31                : 30;
-	uint32_t ler                          : 1;  /**< Link Equalization Request Interrupt Enable */
-	uint32_t pe                           : 1;  /**< Perform Equalization */
+	uint32_t ler                          : 1;  /**< Link equalization request interrupt enable. */
+	uint32_t pe                           : 1;  /**< Perform equalization. */
 #else
 	uint32_t pe                           : 1;
 	uint32_t ler                          : 1;
@@ -7408,15 +7371,15 @@ typedef union cvmx_pciercx_cfg087 cvmx_pciercx_cfg087_t;
 /**
  * cvmx_pcierc#_cfg088
  *
- * PCIE_CFG088 = Eighty-ninth 32-bits of PCIE type 0 config space
- * (Lane Error Status)
+ * This register contains the eighty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg088 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg088_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_8_31                : 24;
-	uint32_t les                          : 8;  /**< Lane Error Status Bits */
+	uint32_t les                          : 8;  /**< Lane error status bits. */
 #else
 	uint32_t les                          : 8;
 	uint32_t reserved_8_31                : 24;
@@ -7429,42 +7392,33 @@ typedef union cvmx_pciercx_cfg088 cvmx_pciercx_cfg088_t;
 /**
  * cvmx_pcierc#_cfg089
  *
- * PCIE_CFG089 = Ninetieth 32-bits of PCIE type 0 config space
- * (Equalization Control Lane 0/
- * Equalization Control Lane 1)
+ * This register contains the ninetieth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg089 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg089_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l1urph                       : 3;  /**< "Lane 1 Upstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l1utp                        : 4;  /**< "Lane 1 Upstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l1urph                       : 3;  /**< Lane 1 upstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l1utp                        : 4;  /**< Lane 1 upstream component transmitter preset. Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
 	uint32_t reserved_23_23               : 1;
-	uint32_t l1drph                       : 3;  /**< "Lane 1 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l1ddtp                       : 4;  /**< "Lane 1 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l1drph                       : 3;  /**< Lane 1 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l1ddtp                       : 4;  /**< Lane 1 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_15_15               : 1;
-	uint32_t l0urph                       : 3;  /**< "Lane 0 Upstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l0utp                        : 4;  /**< "Lane 0 Upstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l0urph                       : 3;  /**< Lane 0 upstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l0utp                        : 4;  /**< Lane 0 upstream component transmitter preset. Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
 	uint32_t reserved_7_7                 : 1;
-	uint32_t l0drph                       : 3;  /**< "Lane 0 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l0dtp                        : 4;  /**< "Lane 0 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l0drph                       : 3;  /**< Lane 0 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l0dtp                        : 4;  /**< Lane 0 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 #else
 	uint32_t l0dtp                        : 4;
 	uint32_t l0drph                       : 3;
@@ -7487,42 +7441,33 @@ typedef union cvmx_pciercx_cfg089 cvmx_pciercx_cfg089_t;
 /**
  * cvmx_pcierc#_cfg090
  *
- * PCIE_CFG090 = Ninety-first 32-bits of PCIE type 0 config space
- * (Equalization Control Lane 2/
- * Equalization Control Lane 3)
+ * This register contains the ninety-first 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg090 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg090_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l3urph                       : 3;  /**< "Lane 3 Upstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l3utp                        : 4;  /**< "Lane 3 Upstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l3urph                       : 3;  /**< Lane 3 upstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l3utp                        : 4;  /**< Lane 3 upstream component transmitter preset. Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
 	uint32_t reserved_23_23               : 1;
-	uint32_t l3drph                       : 3;  /**< "Lane 3 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l3dtp                        : 4;  /**< "Lane 3 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l3drph                       : 3;  /**< Lane 3 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l3dtp                        : 4;  /**< Lane 3 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_15_15               : 1;
-	uint32_t l2urph                       : 3;  /**< "Lane 2 Upstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l2utp                        : 4;  /**< "Lane 2 Upstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l2urph                       : 3;  /**< Lane 2 upstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l2utp                        : 4;  /**< Lane 2 upstream component transmitter preset. Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
 	uint32_t reserved_7_7                 : 1;
-	uint32_t l2drph                       : 3;  /**< "Lane 2 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l2dtp                        : 4;  /**< "Lane 2 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l2drph                       : 3;  /**< Lane 2 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l2dtp                        : 4;  /**< Lane 2 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 #else
 	uint32_t l2dtp                        : 4;
 	uint32_t l2drph                       : 3;
@@ -7545,42 +7490,33 @@ typedef union cvmx_pciercx_cfg090 cvmx_pciercx_cfg090_t;
 /**
  * cvmx_pcierc#_cfg091
  *
- * PCIE_CFG091 = Ninety-second 32-bits of PCIE type 0 config space
- * (Equalization Control Lane 4/
- * Equalization Control Lane 5)
+ * This register contains the ninety-second 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg091 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg091_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l5urph                       : 3;  /**< "Lane 5 Upstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l5utp                        : 4;  /**< "Lane 5 Upstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l5urph                       : 3;  /**< Lane 5 upstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l5utp                        : 4;  /**< Lane 5 upstream component transmitter preset. Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
 	uint32_t reserved_23_23               : 1;
-	uint32_t l5drph                       : 3;  /**< "Lane 5 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l5dtp                        : 4;  /**< "Lane 5 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l5drph                       : 3;  /**< Lane 5 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l5dtp                        : 4;  /**< Lane 5 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_15_15               : 1;
-	uint32_t l4urph                       : 3;  /**< "Lane 4 Upstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l4utp                        : 4;  /**< "Lane 4 Upstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l4urph                       : 3;  /**< Lane 4 upstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l4utp                        : 4;  /**< Lane 4 upstream component transmitter preset. Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
 	uint32_t reserved_7_7                 : 1;
-	uint32_t l4drph                       : 3;  /**< "Lane 4 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l4dtp                        : 4;  /**< "Lane 4 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l4drph                       : 3;  /**< Lane 4 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l4dtp                        : 4;  /**< Lane 4 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 #else
 	uint32_t l4dtp                        : 4;
 	uint32_t l4drph                       : 3;
@@ -7603,42 +7539,33 @@ typedef union cvmx_pciercx_cfg091 cvmx_pciercx_cfg091_t;
 /**
  * cvmx_pcierc#_cfg092
  *
- * PCIE_CFG092 = Ninety-third 32-bits of PCIE type 0 config space
- * (Equalization Control Lane 6/
- * Equalization Control Lane 7)
+ * This register contains the ninety-third 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg092 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg092_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_31_31               : 1;
-	uint32_t l7urph                       : 3;  /**< "Lane 7 Upstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l7utp                        : 4;  /**< "Lane 7 Upstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l7urph                       : 3;  /**< Lane 7 upstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l7utp                        : 4;  /**< Lane 7 upstream component transmitter preset. Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
 	uint32_t reserved_23_23               : 1;
-	uint32_t l7drph                       : 3;  /**< "Lane 7 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l7dtp                        : 4;  /**< "Lane 7 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l7drph                       : 3;  /**< Lane 7 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l7dtp                        : 4;  /**< Lane 7 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 	uint32_t reserved_15_15               : 1;
-	uint32_t l6urph                       : 3;  /**< "Lane 6 Upstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l6utp                        : 4;  /**< "Lane 6 Upstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l6urph                       : 3;  /**< Lane 6 upstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l6utp                        : 4;  /**< Lane 6 upstream component transmitter preset. Writable through PEM(0..3)_CFG_WR. However,
+                                                         the application must not change this field. */
 	uint32_t reserved_7_7                 : 1;
-	uint32_t l6drph                       : 3;  /**< "Lane 6 Downstream Component Receiver Preset Hint
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
-	uint32_t l6dtp                        : 4;  /**< "Lane 6 Downstream Component Transmitter Preset
-                                                         Writable through PEM#_CFG_WR.
-                                                         However, the application must not change this field." */
+	uint32_t l6drph                       : 3;  /**< Lane 6 downstream component receiver preset hint. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t l6dtp                        : 4;  /**< Lane 6 downstream component transmitter preset. Writable through PEM(0..3)_CFG_WR.
+                                                         However, the application must not change this field. */
 #else
 	uint32_t l6dtp                        : 4;
 	uint32_t l6drph                       : 3;
@@ -7661,8 +7588,8 @@ typedef union cvmx_pciercx_cfg092 cvmx_pciercx_cfg092_t;
 /**
  * cvmx_pcierc#_cfg448
  *
- * PCIE_CFG448 = Four hundred forty-ninth 32-bits of PCIE type 1 config space
- * (Ack Latency Timer and Replay Timer Register)
+ * This register contains the four hundred forty-ninth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg448 {
 	uint32_t u32;
@@ -7708,8 +7635,8 @@ typedef union cvmx_pciercx_cfg448 cvmx_pciercx_cfg448_t;
 /**
  * cvmx_pcierc#_cfg449
  *
- * PCIE_CFG449 = Four hundred fiftieth 32-bits of PCIE type 1 config space
- * (Other Message Register)
+ * This register contains the four hundred fiftieth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg449 {
 	uint32_t u32;
@@ -7750,8 +7677,8 @@ typedef union cvmx_pciercx_cfg449 cvmx_pciercx_cfg449_t;
 /**
  * cvmx_pcierc#_cfg450
  *
- * PCIE_CFG450 = Four hundred fifty-first 32-bits of PCIE type 1 config space
- * (Port Force Link Register)
+ * This register contains the four hundred fifty-first 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg450 {
 	uint32_t u32;
@@ -7919,8 +7846,8 @@ typedef union cvmx_pciercx_cfg450 cvmx_pciercx_cfg450_t;
 /**
  * cvmx_pcierc#_cfg451
  *
- * PCIE_CFG451 = Four hundred fifty-second 32-bits of PCIE type 1 config space
- * (Ack Frequency Register)
+ * This register contains the four hundred fifty-second 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg451 {
 	uint32_t u32;
@@ -8042,8 +7969,8 @@ typedef union cvmx_pciercx_cfg451 cvmx_pciercx_cfg451_t;
 /**
  * cvmx_pcierc#_cfg452
  *
- * PCIE_CFG452 = Four hundred fifty-third 32-bits of PCIE type 1 config space
- * (Port Link Control Register)
+ * This register contains the four hundred fifty-third 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg452 {
 	uint32_t u32;
@@ -8314,8 +8241,8 @@ typedef union cvmx_pciercx_cfg452 cvmx_pciercx_cfg452_t;
 /**
  * cvmx_pcierc#_cfg453
  *
- * PCIE_CFG453 = Four hundred fifty-fourth 32-bits of PCIE type 1 config space
- * (Lane Skew Register)
+ * This register contains the four hundred fifty-fourth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg453 {
 	uint32_t u32;
@@ -8361,8 +8288,8 @@ typedef union cvmx_pciercx_cfg453 cvmx_pciercx_cfg453_t;
 /**
  * cvmx_pcierc#_cfg454
  *
- * PCIE_CFG454 = Four hundred fifty-fifth 32-bits of PCIE type 1 config space
- * (Symbol Number Register)
+ * This register contains the four hundred fifty-fifth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg454 {
 	uint32_t u32;
@@ -8477,17 +8404,15 @@ union cvmx_pciercx_cfg454 {
 	struct cvmx_pciercx_cfg454_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_29_31               : 3;
-	uint32_t tmfcwt                       : 5;  /**< Used to be "Timer Modifier for Flow Control Watchdog Timer"
-                                                         No longer used. Repl and enhanced func moved to "Queue Status"
-                                                         register - CFG463. Kept for now to prevent s/w from breaking. */
-	uint32_t tmanlt                       : 5;  /**< Timer Modifier for Ack/Nak Latency Timer
-                                                         Increases the timer value for the Ack/Nak latency timer, in
+	uint32_t tmfcwt                       : 5;  /**< Used to be 'timer modifier for flow control watchdog timer.' This field is no longer used.
+                                                         and has moved to the queue status register -- PCIEEP*_CFG463. This field remains to
+                                                         prevent software from breaking. */
+	uint32_t tmanlt                       : 5;  /**< Timer modifier for Ack/Nak latency timer. Increases the timer value for the Ack/Nak
+                                                         latency timer, in increments of 64 clock cycles. */
+	uint32_t tmrt                         : 5;  /**< Timer modifier for replay timer. Increases the timer value for the replay timer, in
                                                          increments of 64 clock cycles. */
-	uint32_t tmrt                         : 5;  /**< Timer Modifier for Replay Timer
-                                                         Increases the timer value for the replay timer, in increments
-                                                         of 64 clock cycles. */
 	uint32_t reserved_8_13                : 6;
-	uint32_t mfuncn                       : 8;  /**< Max Number of Functions Supported */
+	uint32_t mfuncn                       : 8;  /**< Max number of functions supported. */
 #else
 	uint32_t mfuncn                       : 8;
 	uint32_t reserved_8_13                : 6;
@@ -8504,8 +8429,8 @@ typedef union cvmx_pciercx_cfg454 cvmx_pciercx_cfg454_t;
 /**
  * cvmx_pcierc#_cfg455
  *
- * PCIE_CFG455 = Four hundred fifty-sixth 32-bits of PCIE type 1 config space
- * (Symbol Timer Register/Filter Mask Register 1)
+ * This register contains the four hundred fifty-sixth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg455 {
 	uint32_t u32;
@@ -8572,8 +8497,8 @@ typedef union cvmx_pciercx_cfg455 cvmx_pciercx_cfg455_t;
 /**
  * cvmx_pcierc#_cfg456
  *
- * PCIE_CFG456 = Four hundred fifty-seventh 32-bits of PCIE type 1 config space
- * (Filter Mask Register 2)
+ * This register contains the four hundred fifty-seventh 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg456 {
 	uint32_t u32;
@@ -8621,8 +8546,8 @@ typedef union cvmx_pciercx_cfg456 cvmx_pciercx_cfg456_t;
 /**
  * cvmx_pcierc#_cfg458
  *
- * PCIE_CFG458 = Four hundred fifty-ninth 32-bits of PCIE type 1 config space
- * (Debug Register 0)
+ * This register contains the four hundred fifty-ninth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg458 {
 	uint32_t u32;
@@ -8652,8 +8577,8 @@ typedef union cvmx_pciercx_cfg458 cvmx_pciercx_cfg458_t;
 /**
  * cvmx_pcierc#_cfg459
  *
- * PCIE_CFG459 = Four hundred sixtieth 32-bits of PCIE type 1 config space
- * (Debug Register 1)
+ * This register contains the four hundred sixtieth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg459 {
 	uint32_t u32;
@@ -8683,8 +8608,8 @@ typedef union cvmx_pciercx_cfg459 cvmx_pciercx_cfg459_t;
 /**
  * cvmx_pcierc#_cfg460
  *
- * PCIE_CFG460 = Four hundred sixty-first 32-bits of PCIE type 1 config space
- * (Transmit Posted FC Credit Status)
+ * This register contains the four hundred sixty-first 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg460 {
 	uint32_t u32;
@@ -8722,8 +8647,8 @@ typedef union cvmx_pciercx_cfg460 cvmx_pciercx_cfg460_t;
 /**
  * cvmx_pcierc#_cfg461
  *
- * PCIE_CFG461 = Four hundred sixty-second 32-bits of PCIE type 1 config space
- * (Transmit Non-Posted FC Credit Status)
+ * This register contains the four hundred sixty-second 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg461 {
 	uint32_t u32;
@@ -8761,8 +8686,8 @@ typedef union cvmx_pciercx_cfg461 cvmx_pciercx_cfg461_t;
 /**
  * cvmx_pcierc#_cfg462
  *
- * PCIE_CFG462 = Four hundred sixty-third 32-bits of PCIE type 1 config space
- * (Transmit Completion FC Credit Status )
+ * This register contains the four hundred sixty-third 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg462 {
 	uint32_t u32;
@@ -8800,22 +8725,20 @@ typedef union cvmx_pciercx_cfg462 cvmx_pciercx_cfg462_t;
 /**
  * cvmx_pcierc#_cfg463
  *
- * PCIE_CFG463 = Four hundred sixty-fourth 32-bits of PCIE type 1 config space
- * (Queue Status)
+ * This register contains the four hundred sixty-fourth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg463 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg463_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t fcltoe                       : 1;  /**< FC Latency Timer Override Enable
-                                                         When this bit is set, the value from the "FC Latency Timer Override
-                                                         Value" field in this register will override the FC latency timer
-                                                         value that the core calculates according to the PCIe specification. */
+	uint32_t fcltoe                       : 1;  /**< FC latency timer override enable. When this bit is set, the value in
+                                                         PCIERC(0..3)_CFG453[FCLTOV] will override the FC latency timer value that the core
+                                                         calculates according to the PCIe specification. */
 	uint32_t reserved_29_30               : 2;
-	uint32_t fcltov                       : 13; /**< FC Latency Timer Override Value
-                                                         When you set the "FC Latency Timer Override Enable" in this register,
-                                                         the value in this field will override the FC latency timer value
-                                                         that the core calculates according to the PCIe specification. */
+	uint32_t fcltov                       : 13; /**< FC latency timer override value. When you set PCIERC(0..3)_CFG453[FCLTOE], the value in
+                                                         this field will override the FC latency timer value that the core calculates according to
+                                                         the PCIe specification. */
 	uint32_t reserved_3_15                : 13;
 	uint32_t rqne                         : 1;  /**< Received Queue Not Empty
                                                          Indicates there is data in one or more of the receive buffers. */
@@ -8873,8 +8796,8 @@ typedef union cvmx_pciercx_cfg463 cvmx_pciercx_cfg463_t;
 /**
  * cvmx_pcierc#_cfg464
  *
- * PCIE_CFG464 = Four hundred sixty-fifth 32-bits of PCIE type 1 config space
- * (VC Transmit Arbitration Register 1)
+ * This register contains the four hundred sixty-fifth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg464 {
 	uint32_t u32;
@@ -8910,8 +8833,8 @@ typedef union cvmx_pciercx_cfg464 cvmx_pciercx_cfg464_t;
 /**
  * cvmx_pcierc#_cfg465
  *
- * PCIE_CFG465 = Four hundred sixty-sixth 32-bits of config space
- * (VC Transmit Arbitration Register 2)
+ * This register contains the four hundred sixty-sixth 32-bits of configuration space.
+ *
  */
 union cvmx_pciercx_cfg465 {
 	uint32_t u32;
@@ -8947,8 +8870,8 @@ typedef union cvmx_pciercx_cfg465 cvmx_pciercx_cfg465_t;
 /**
  * cvmx_pcierc#_cfg466
  *
- * PCIE_CFG466 = Four hundred sixty-seventh 32-bits of PCIE type 1 config space
- * (VC0 Posted Receive Queue Control)
+ * This register contains the four hundred sixty-seventh 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg466 {
 	uint32_t u32;
@@ -9020,8 +8943,8 @@ typedef union cvmx_pciercx_cfg466 cvmx_pciercx_cfg466_t;
 /**
  * cvmx_pcierc#_cfg467
  *
- * PCIE_CFG467 = Four hundred sixty-eighth 32-bits of PCIE type 1 config space
- * (VC0 Non-Posted Receive Queue Control)
+ * This register contains the four hundred sixty-eighth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg467 {
 	uint32_t u32;
@@ -9075,8 +8998,8 @@ typedef union cvmx_pciercx_cfg467 cvmx_pciercx_cfg467_t;
 /**
  * cvmx_pcierc#_cfg468
  *
- * PCIE_CFG468 = Four hundred sixty-ninth 32-bits of PCIE type 1 config space
- * (VC0 Completion Receive Queue Control)
+ * This register contains the four hundred sixty-ninth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg468 {
 	uint32_t u32;
@@ -9262,8 +9185,8 @@ typedef union cvmx_pciercx_cfg492 cvmx_pciercx_cfg492_t;
 /**
  * cvmx_pcierc#_cfg515
  *
- * PCIE_CFG515 = Five hundred sixteenth 32-bits of PCIE type 1 config space
- * (Port Logic Register (Gen2))
+ * This register contains the five hundred sixteenth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg515 {
 	uint32_t u32;
@@ -9321,8 +9244,8 @@ typedef union cvmx_pciercx_cfg515 cvmx_pciercx_cfg515_t;
 /**
  * cvmx_pcierc#_cfg516
  *
- * PCIE_CFG516 = Five hundred seventeenth 32-bits of PCIE type 1 config space
- * (PHY Status Register)
+ * This register contains the five hundred seventeenth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg516 {
 	uint32_t u32;
@@ -9352,8 +9275,8 @@ typedef union cvmx_pciercx_cfg516 cvmx_pciercx_cfg516_t;
 /**
  * cvmx_pcierc#_cfg517
  *
- * PCIE_CFG517 = Five hundred eighteenth 32-bits of PCIE type 1 config space
- * (PHY Control Register)
+ * This register contains the five hundred eighteenth 32-bits of type 1 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg517 {
 	uint32_t u32;
@@ -9383,33 +9306,27 @@ typedef union cvmx_pciercx_cfg517 cvmx_pciercx_cfg517_t;
 /**
  * cvmx_pcierc#_cfg548
  *
- * PCIE_CFG548 = Five hundred forty ninth 32-bits of PCIE type 0 config space
- * (Gen3 Control Register)
+ * This register contains the five hundred forty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg548 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg548_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_19_31               : 13;
-	uint32_t dcbd                         : 1;  /**< Disable Balance Disable
-                                                         Disable DC Balance feature */
-	uint32_t dtdd                         : 1;  /**< DLLP Transmission Delay Disable
-                                                         Disable delay transmission of DLLPs before Equalization */
-	uint32_t ed                           : 1;  /**< Equalization Disable
-                                                         Disable Equalization feature */
+	uint32_t dcbd                         : 1;  /**< Disable balance disable. Disable DC balance feature. */
+	uint32_t dtdd                         : 1;  /**< DLLP transmission delay disable. Disable delay transmission of DLLPs before equalization. */
+	uint32_t ed                           : 1;  /**< Equalization disable. Disable equalization feature. */
 	uint32_t reserved_12_15               : 4;
-	uint32_t erd                          : 1;  /**< Equalization Redo Disable
-                                                         Disable requesting reset of EIEOS count during Equalization */
-	uint32_t ecrd                         : 1;  /**< Equalization EIEOS Count Reset Disable
-                                                         Disable requesting reset of EIEOS count during Equalization */
-	uint32_t ep2p3d                       : 1;  /**< Equalization Phase 2 and Phase 3 Disable
-                                                         This applies to Downstream Ports only */
-	uint32_t dsg3                         : 1;  /**< Disable Scrambler for Gen3 Data Rate
-                                                         The Gen3 scrambler/descrambler within the core needs to be
-                                                         disabled when the scrambling function is implemented outside
-                                                         of the core (within the PHY) */
+	uint32_t erd                          : 1;  /**< Equalization redo disable. Disable requesting reset of EIEOS count during equalization. */
+	uint32_t ecrd                         : 1;  /**< Equalization EIEOS count reset disable. Disable requesting reset of EIEOS count during
+                                                         equalization. */
+	uint32_t ep2p3d                       : 1;  /**< Equalization phase 2 and phase 3 disable. This applies to downstream ports only. */
+	uint32_t dsg3                         : 1;  /**< Disable scrambler for Gen3 data rate. The Gen3 scrambler/descrambler within the core needs
+                                                         to be disabled when the scrambling function is implemented outside of the core (within the
+                                                         PHY). */
 	uint32_t reserved_1_7                 : 7;
-	uint32_t grizdnc                      : 1;  /**< Gen3 Receiver Impedance ZRX-DC Not Compliant. */
+	uint32_t grizdnc                      : 1;  /**< Gen3 receiver impedance ZRX-DC not compliant. */
 #else
 	uint32_t grizdnc                      : 1;
 	uint32_t reserved_1_7                 : 7;
@@ -9431,62 +9348,52 @@ typedef union cvmx_pciercx_cfg548 cvmx_pciercx_cfg548_t;
 /**
  * cvmx_pcierc#_cfg554
  *
- * PCIE_CFG554 = Five hundred fifty fifth 32-bits of PCIE type 0 config space
- * (Gen3 EQ Control Register)
+ * This register contains the five hundred fifty-fifth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg554 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg554_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
-	uint32_t prv                          : 16; /**< Preset Request Vector
-                                                         Requesting of Presets during the intial part of the EQ Master
-                                                         Phase. Encoding Scheme as follows:
-                                                         Bit [15:0] = 0x0: No preset will be requested and evaluated
-                                                         in the EQ Master Phase
-                                                         Bit [i] = 1: Preset=i will be requested and evaluated in the
-                                                         EQ Master Phase
-                                                         o 0000000000000000: No preset req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxxxxxx1: Preset 0 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxxxxx1x: Preset 1 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxxxx1xx: Preset 2 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxxx1xxx: Preset 3 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxxx1xxxx: Preset 4 req/evaluated in EQ Master Phase
-                                                         o 00000xxxxx1xxxxx: Preset 5 req/evaluated in EQ Master Phase
-                                                         o 00000xxxx1xxxxxx: Preset 6 req/evaluated in EQ Master Phase
-                                                         o 00000xxx1xxxxxxx: Preset 7 req/evaluated in EQ Master Phase
-                                                         o 00000xx1xxxxxxxx: Preset 8 req/evaluated in EQ Master Phase
-                                                         o 00000x1xxxxxxxxx: Preset 9 req/evaluated in EQ Master Phase
-                                                         o 000001xxxxxxxxxx: Preset 10 req/evaluated in EQ Master Phase
-                                                         o all other encodings: Reserved */
+	uint32_t prv                          : 16; /**< Preset request vector. Requesting of presets during the initial part of the EQ master
+                                                         phase. Encoding scheme as follows:
+                                                         Bit [15:0] = 0x0: No preset is requested and evaluated in the EQ master phase
+                                                         Bit [i] = 1: Preset=i is requested and evaluated in the EQ master phase
+                                                         - 0000000000000000: No preset req/evaluated in EQ master phase
+                                                         00000xxxxxxxxxx1: Preset 0 req/evaluated in EQ master phase
+                                                         00000xxxxxxxxx1x: Preset 1 req/evaluated in EQ master phase
+                                                         00000xxxxxxxx1xx: Preset 2 req/evaluated in EQ master phase
+                                                         00000xxxxxxx1xxx: Preset 3 req/evaluated in EQ master phase
+                                                         00000xxxxxx1xxxx: Preset 4 req/evaluated in EQ master phase
+                                                         00000xxxxx1xxxxx: Preset 5 req/evaluated in EQ master phase
+                                                         00000xxxx1xxxxxx: Preset 6 req/evaluated in EQ master phase
+                                                         00000xxx1xxxxxxx: Preset 7 req/evaluated in EQ master phase
+                                                         00000xx1xxxxxxxx: Preset 8 req/evaluated in EQ master phase
+                                                         00000x1xxxxxxxxx: Preset 9 req/evaluated in EQ master phase
+                                                         000001xxxxxxxxxx: Preset 10 req/evaluated in EQ master phase
+                                                         All other encodings: Reserved */
 	uint32_t reserved_6_7                 : 2;
-	uint32_t p23td                        : 1;  /**< Phase2_3 2 ms Timeout Disable
-                                                         Determine behavior in Phase2 for USP (Phase3 if DSP) when the
-                                                         PHY does not respond within 2ms to the assertion of RxEqEval:
-                                                         o 0: abort the current evaluation, stop any attempt to
-                                                         modify the remote transmitter settings, Phase2 will be
-                                                         terminated by the 24ms timeout
-                                                         o 1: ignore the 2ms timeout and continue as normal. This is
-                                                         used to support PHYs that require more than 2ms to
-                                                         respond to the assertion of RxEqEval. */
-	uint32_t bt                           : 1;  /**< Behavior After 24ms Timeout (When Optimal settings are not found)
-                                                         FOR a USP:
-                                                         Determine the next LTSSM state from Phase2
-                                                         o 0: Recovery.Speed
-                                                         o 1: Recovry.Equalization.Phase3
-                                                         FOR a DSP:
-                                                         Determine the next LTSSM state from Phase3
-                                                         o 0: Recovery.Speed
-                                                         o 1: Recovry.Equalization.RcrLock
-                                                         When optimal settings are not found then
-                                                         o Equalization Phase 3 Successful status bit is not set in the
-                                                         Link Status Register
-                                                         o Equalization Phase 3 Complete status bit is set in the
-                                                         Link Status Register */
-	uint32_t fm                           : 4;  /**< Feedback Mode
-                                                         - 0: Direction of Change
-                                                         - 1: Figure of Merit
-                                                         - 2-15: Reserved */
+	uint32_t p23td                        : 1;  /**< Phase2_3 2 ms timeout disable. Determine behavior in Phase2 for USP (Phase3 if DSP) when
+                                                         the PHY does not respond within 2 ms to the assertion of RxEqEval:
+                                                         0 = Abort the current evaluation; stop any attempt to modify the remote transmitter
+                                                         settings. Phase2 will be terminated by the 24 ms timeout.
+                                                         1 = Ignore the 2 ms timeout and continue as normal. This is used to support PHYs that
+                                                         require more than 2 ms to respond to the assertion of RxEqEval. */
+	uint32_t bt                           : 1;  /**< Behavior after 24 ms timeout (when optimal settings are not found).
+                                                         FOR a USP: determine the next LTSSM state from Phase2
+                                                         0 = Recovery.Speed
+                                                         1 = Recovry.Equalization.Phase3
+                                                         FOR a DSP: determine the next LTSSM state from Phase3
+                                                         0 = Recovery.Speed
+                                                         1 = Recovry.Equalization.RcrLock
+                                                         When optimal settings are not found:
+                                                         * Equalization Phase 3 Successful status bit is not set in the link Status Register
+                                                         * Equalization Phase 3 Complete status bit is set in the link Status Register */
+	uint32_t fm                           : 4;  /**< Feedback mode.
+                                                         0 = Direction of change.
+                                                         1 = Figure of merit.
+                                                         2-15 = Reserved. */
 #else
 	uint32_t fm                           : 4;
 	uint32_t bt                           : 1;
@@ -9503,14 +9410,14 @@ typedef union cvmx_pciercx_cfg554 cvmx_pciercx_cfg554_t;
 /**
  * cvmx_pcierc#_cfg558
  *
- * PCIE_CFG558 = Five hundred fifty ninth 32-bits of PCIE type 0 config space
- * (Gen3 PIPE Loopback Register)
+ * This register contains the five hundred fifty-ninth 32-bits of type 0 PCIe configuration space.
+ *
  */
 union cvmx_pciercx_cfg558 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg558_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t ple                          : 1;  /**< Pipe Loopback Enable */
+	uint32_t ple                          : 1;  /**< Pipe loopback enable */
 	uint32_t rxstatus                     : 31; /**< Reserved. */
 #else
 	uint32_t rxstatus                     : 31;
diff --git a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
index d013afd..a24e051 100644
--- a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
@@ -801,8 +801,8 @@ static inline uint64_t CVMX_PEMX_TLP_CREDITS(unsigned long block_id)
 /**
  * cvmx_pem#_bar1_index#
  *
- * Contains address index and control bits for access to memory ranges of BAR-1. Index is build
- * from supplied address [25:22].
+ * This register contains the address index and control bits for access to memory ranges of BAR1.
+ * The index is built from supplied address [25:22].
  */
 union cvmx_pemx_bar1_indexx {
 	uint64_t u64;
@@ -850,8 +850,8 @@ typedef union cvmx_pemx_bar1_indexx cvmx_pemx_bar1_indexx_t;
 /**
  * cvmx_pem#_bar2_mask
  *
- * The mask pattern that is ANDED with the address from PCIe core for BAR2 hits.
- *
+ * This register contains the mask pattern that is ANDed with the address from the PCIe core for
+ * BAR2 hits.
  */
 union cvmx_pemx_bar2_mask {
 	uint64_t u64;
@@ -891,7 +891,7 @@ typedef union cvmx_pemx_bar2_mask cvmx_pemx_bar2_mask_t;
 /**
  * cvmx_pem#_bar_ctl
  *
- * Contains control for BAR accesses.
+ * This register contains control for BAR accesses.
  *
  */
 union cvmx_pemx_bar_ctl {
@@ -932,32 +932,32 @@ typedef union cvmx_pemx_bar_ctl cvmx_pemx_bar_ctl_t;
 /**
  * cvmx_pem#_bist_status
  *
- * "PEM#_BIST_STATUS2 = PEM BIST Status Register
- * Results from BIST runs of PEM's memories."
+ * This register contains results from BIST runs of PEM's memories.
+ *
  */
 union cvmx_pemx_bist_status {
 	uint64_t u64;
 	struct cvmx_pemx_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_26_63               : 38;
-	uint64_t retryc                       : 1;  /**< Retry Buffer Memory C */
+	uint64_t retryc                       : 1;  /**< Retry buffer memory C. */
 	uint64_t reserved_24_24               : 1;
-	uint64_t rqhdrb0                      : 1;  /**< Rx Queue Header Memory Buffer 0 */
-	uint64_t rqhdrb1                      : 1;  /**< Rx Queue Header Memory Buffer 1 */
-	uint64_t rqdatab0                     : 1;  /**< Rx Queue Data Buffer 0 */
-	uint64_t rqdatab1                     : 1;  /**< Rx Queue Data Buffer 1 */
-	uint64_t tlpan_d0                     : 1;  /**< BIST Status for the tlp_n_afifo_data0 */
-	uint64_t tlpan_d1                     : 1;  /**< BIST Status for the tlp_n_afifo_data1 */
-	uint64_t tlpan_ctl                    : 1;  /**< BIST Status for the tlp_n_afifo_ctl */
-	uint64_t tlpap_d0                     : 1;  /**< BIST Status for the tlp_p_afifo_data0 */
-	uint64_t tlpap_d1                     : 1;  /**< BIST Status for the tlp_p_afifo_data1 */
-	uint64_t tlpap_ctl                    : 1;  /**< BIST Status for the tlp_p_afifo_ctl */
-	uint64_t tlpac_d0                     : 1;  /**< BIST Status for the tlp_c_afifo_data0 */
-	uint64_t tlpac_d1                     : 1;  /**< BIST Status for the tlp_c_afifo_data1 */
-	uint64_t tlpac_ctl                    : 1;  /**< BIST Status for the tlp_c_afifo_ctl */
-	uint64_t peai_p2e                     : 1;  /**< BIST Status for the peai__pesc_fifo */
-	uint64_t tlpn_d0                      : 1;  /**< BIST Status for the tlp_n_fifo_data0 */
-	uint64_t tlpn_d1                      : 1;  /**< BIST Status for the tlp_n_fifo_data1 */
+	uint64_t rqhdrb0                      : 1;  /**< Rx queue header memory buffer 0. */
+	uint64_t rqhdrb1                      : 1;  /**< Rx queue header memory buffer 1. */
+	uint64_t rqdatab0                     : 1;  /**< Rx queue data buffer 0. */
+	uint64_t rqdatab1                     : 1;  /**< Rx queue data buffer 1. */
+	uint64_t tlpan_d0                     : 1;  /**< BIST Status for the tlp_n_afifo_data0. */
+	uint64_t tlpan_d1                     : 1;  /**< BIST Status for the tlp_n_afifo_data1. */
+	uint64_t tlpan_ctl                    : 1;  /**< BIST Status for the tlp_n_afifo_ctl. */
+	uint64_t tlpap_d0                     : 1;  /**< BIST Status for the tlp_p_afifo_data0. */
+	uint64_t tlpap_d1                     : 1;  /**< BIST Status for the tlp_p_afifo_data1. */
+	uint64_t tlpap_ctl                    : 1;  /**< BIST Status for the tlp_p_afifo_ctl. */
+	uint64_t tlpac_d0                     : 1;  /**< BIST Status for the tlp_c_afifo_data0. */
+	uint64_t tlpac_d1                     : 1;  /**< BIST Status for the tlp_c_afifo_data1. */
+	uint64_t tlpac_ctl                    : 1;  /**< BIST Status for the tlp_c_afifo_ctl. */
+	uint64_t peai_p2e                     : 1;  /**< BIST Status for the peai__pesc_fifo. */
+	uint64_t tlpn_d0                      : 1;  /**< BIST Status for the tlp_n_fifo_data0. */
+	uint64_t tlpn_d1                      : 1;  /**< BIST Status for the tlp_n_fifo_data1. */
 	uint64_t reserved_0_7                 : 8;
 #else
 	uint64_t reserved_0_7                 : 8;
@@ -1032,32 +1032,32 @@ union cvmx_pemx_bist_status {
 	struct cvmx_pemx_bist_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_26_63               : 38;
-	uint64_t retryc                       : 1;  /**< Retry Buffer Memory C */
-	uint64_t sot                          : 1;  /**< Start of Transfer Memory */
-	uint64_t rqhdrb0                      : 1;  /**< Rx Queue Header Memory Buffer 0 */
-	uint64_t rqhdrb1                      : 1;  /**< Rx Queue Header Memory Buffer 1 */
-	uint64_t rqdatab0                     : 1;  /**< Rx Queue Data Buffer 0 */
-	uint64_t rqdatab1                     : 1;  /**< Rx Queue Data Buffer 1 */
-	uint64_t tlpan_d0                     : 1;  /**< BIST Status for the tlp_n_afifo_data0 */
-	uint64_t tlpan_d1                     : 1;  /**< BIST Status for the tlp_n_afifo_data1 */
-	uint64_t tlpan_ctl                    : 1;  /**< BIST Status for the tlp_n_afifo_ctl */
-	uint64_t tlpap_d0                     : 1;  /**< BIST Status for the tlp_p_afifo_data0 */
-	uint64_t tlpap_d1                     : 1;  /**< BIST Status for the tlp_p_afifo_data1 */
-	uint64_t tlpap_ctl                    : 1;  /**< BIST Status for the tlp_p_afifo_ctl */
-	uint64_t tlpac_d0                     : 1;  /**< BIST Status for the tlp_c_afifo_data0 */
-	uint64_t tlpac_d1                     : 1;  /**< BIST Status for the tlp_c_afifo_data1 */
-	uint64_t tlpac_ctl                    : 1;  /**< BIST Status for the tlp_c_afifo_ctl */
-	uint64_t peai_p2e                     : 1;  /**< BIST Status for the peai__pesc_fifo */
-	uint64_t tlpn_d0                      : 1;  /**< BIST Status for the tlp_n_fifo_data0 */
-	uint64_t tlpn_d1                      : 1;  /**< BIST Status for the tlp_n_fifo_data1 */
-	uint64_t tlpn_ctl                     : 1;  /**< BIST Status for the tlp_n_fifo_ctl */
-	uint64_t tlpp_d0                      : 1;  /**< BIST Status for the tlp_p_fifo_data0 */
-	uint64_t tlpp_d1                      : 1;  /**< BIST Status for the tlp_p_fifo_data1 */
-	uint64_t tlpp_ctl                     : 1;  /**< BIST Status for the tlp_p_fifo_ctl */
-	uint64_t tlpc_d0                      : 1;  /**< BIST Status for the tlp_c_fifo_data0 */
-	uint64_t tlpc_d1                      : 1;  /**< BIST Status for the tlp_c_fifo_data1 */
-	uint64_t tlpc_ctl                     : 1;  /**< BIST Status for the tlp_c_fifo_ctl */
-	uint64_t m2s                          : 1;  /**< BIST Status for the m2s_fifo */
+	uint64_t retryc                       : 1;  /**< Retry buffer memory C. */
+	uint64_t sot                          : 1;  /**< Start of transfer memory. */
+	uint64_t rqhdrb0                      : 1;  /**< Rx queue header memory buffer 0. */
+	uint64_t rqhdrb1                      : 1;  /**< Rx queue header memory buffer 1. */
+	uint64_t rqdatab0                     : 1;  /**< Rx queue data buffer 0. */
+	uint64_t rqdatab1                     : 1;  /**< Rx queue data buffer 1. */
+	uint64_t tlpan_d0                     : 1;  /**< BIST Status for the tlp_n_afifo_data0. */
+	uint64_t tlpan_d1                     : 1;  /**< BIST Status for the tlp_n_afifo_data1. */
+	uint64_t tlpan_ctl                    : 1;  /**< BIST Status for the tlp_n_afifo_ctl. */
+	uint64_t tlpap_d0                     : 1;  /**< BIST Status for the tlp_p_afifo_data0. */
+	uint64_t tlpap_d1                     : 1;  /**< BIST Status for the tlp_p_afifo_data1. */
+	uint64_t tlpap_ctl                    : 1;  /**< BIST Status for the tlp_p_afifo_ctl. */
+	uint64_t tlpac_d0                     : 1;  /**< BIST Status for the tlp_c_afifo_data0. */
+	uint64_t tlpac_d1                     : 1;  /**< BIST Status for the tlp_c_afifo_data1. */
+	uint64_t tlpac_ctl                    : 1;  /**< BIST Status for the tlp_c_afifo_ctl. */
+	uint64_t peai_p2e                     : 1;  /**< BIST Status for the peai__pesc_fifo. */
+	uint64_t tlpn_d0                      : 1;  /**< BIST Status for the tlp_n_fifo_data0. */
+	uint64_t tlpn_d1                      : 1;  /**< BIST Status for the tlp_n_fifo_data1. */
+	uint64_t tlpn_ctl                     : 1;  /**< BIST Status for the tlp_n_fifo_ctl. */
+	uint64_t tlpp_d0                      : 1;  /**< BIST Status for the tlp_p_fifo_data0. */
+	uint64_t tlpp_d1                      : 1;  /**< BIST Status for the tlp_p_fifo_data1. */
+	uint64_t tlpp_ctl                     : 1;  /**< BIST Status for the tlp_p_fifo_ctl. */
+	uint64_t tlpc_d0                      : 1;  /**< BIST Status for the tlp_c_fifo_data0. */
+	uint64_t tlpc_d1                      : 1;  /**< BIST Status for the tlp_c_fifo_data1. */
+	uint64_t tlpc_ctl                     : 1;  /**< BIST Status for the tlp_c_fifo_ctl. */
+	uint64_t m2s                          : 1;  /**< BIST Status for the m2s_fifo. */
 #else
 	uint64_t m2s                          : 1;
 	uint64_t tlpc_ctl                     : 1;
@@ -1189,7 +1189,7 @@ typedef union cvmx_pemx_bist_status2 cvmx_pemx_bist_status2_t;
 /**
  * cvmx_pem#_cfg
  *
- * Configuration of the PCIe Application
+ * Configuration of the PCIe Application.
  *
  */
 union cvmx_pemx_cfg {
@@ -1197,15 +1197,15 @@ union cvmx_pemx_cfg {
 	struct cvmx_pemx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t laneswap                     : 1;  /**< This field will overwrite the pin setting for lane swapping.
-                                                         When set, lane swapping is performed to/from the SerDes.
-                                                         When clear, no lane swapping is performed. */
+	uint64_t laneswap                     : 1;  /**< This field overwrites the signal setting for lane swapping. When set, lane swapping is
+                                                         performed to/from the SerDes. When clear, no lane swapping is performed. */
 	uint64_t reserved_2_3                 : 2;
-	uint64_t md                           : 2;  /**< This field will overwrite the pin settings for speed.
-                                                         00 - EP Mode, Gen1 Speed
-                                                         01 - EP Mode, Gen2 Speed
-                                                         10 - EP Mode, Gen3 Speed
-                                                         11 - Rsvd */
+	uint64_t md                           : 2;  /**< This field overwrites the signal settings for speed. Root complex configuration when the
+                                                         MD field is changed.
+                                                         0x0 = Gen1 speed.
+                                                         0x1 = Gen2 speed.
+                                                         0x2 = Gen3 speed.
+                                                         0x3 = Reserved. */
 #else
 	uint64_t md                           : 2;
 	uint64_t reserved_2_3                 : 2;
@@ -1249,25 +1249,22 @@ union cvmx_pemx_cfg {
 	struct cvmx_pemx_cfg_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t laneswap                     : 1;  /**< This field will overwrite the pin setting for lane swapping.
-                                                         When set, lane swapping is performed to/from the SerDes.
-                                                         When clear, no lane swapping is performed. */
-	uint64_t lanes8                       : 1;  /**< This field will overwrite the pin setting for number of lanes.
-                                                         When set, the PEM is configured for a maximum of 8-lanes,
-                                                         When clear, the PEM is configured for a maximum of 4-lanes.
-                                                         This value is used to set the Maximum Link Width field in the
-                                                         core's Link Capabilities Register (CFG031) to indicate the
-                                                         maximum number of lanes supported. Note that less lanes than
-                                                         the specified maximum can be configured for use via the core's
-                                                         Link Control Register (CFG032) Negotiated Link Width field. */
-	uint64_t hostmd                       : 1;  /**< This field will overwrite the pin settings for host mode.
-                                                         When set, the PEM is configured to be a Root Complex.
-                                                         When clear, the PEM is configured to be an End Point. */
-	uint64_t md                           : 2;  /**< This field will overwrite the pin settings for speed.
-                                                         00 - EP Mode, Gen1 Speed
-                                                         01 - EP Mode, Gen2 Speed
-                                                         10 - EP Mode, Gen3 Speed
-                                                         11 - Rsvd */
+	uint64_t laneswap                     : 1;  /**< This field overwrites the signal setting for lane swapping. When set, lane swapping is
+                                                         performed to/from the SerDes. When clear, no lane swapping is performed. */
+	uint64_t lanes8                       : 1;  /**< This field overwrites the signal setting for number of lanes.
+                                                         When set, the PEM is configured for a maximum of 8 lanes. When clear, the PEM is
+                                                         configured for a maximum of 4 lanes. This value is used to set the maximum link width
+                                                         field in the core's link capabilities register (CFG031) to indicate the maximum number of
+                                                         lanes supported. Note that less lanes than the specified maximum can be configured for use
+                                                         via the core's link control register (CFG032) negotiated link width field. */
+	uint64_t hostmd                       : 1;  /**< This field overwrites the signal settings for host mode. When set, the PEM is configured
+                                                         to be a root complex. When clear, the PEM is configured to be an end point. */
+	uint64_t md                           : 2;  /**< This field overwrites the signal settings for speed. Root complex configuration when the
+                                                         MD field is changed.
+                                                         0x0 = Gen1 speed.
+                                                         0x1 = Gen2 speed.
+                                                         0x2 = Gen3 speed.
+                                                         0x3 = Reserved. */
 #else
 	uint64_t md                           : 2;
 	uint64_t hostmd                       : 1;
@@ -1282,7 +1279,7 @@ typedef union cvmx_pemx_cfg cvmx_pemx_cfg_t;
 /**
  * cvmx_pem#_cfg_rd
  *
- * Allows read access to the configuration in the PCIe Core.
+ * This register allows read access to the configuration in the PCIe core.
  *
  */
 union cvmx_pemx_cfg_rd {
@@ -1312,7 +1309,7 @@ typedef union cvmx_pemx_cfg_rd cvmx_pemx_cfg_rd_t;
 /**
  * cvmx_pem#_cfg_wr
  *
- * Allows write access to the configuration in the PCIe Core.
+ * This register allows write access to the configuration in the PCIe core.
  *
  */
 union cvmx_pemx_cfg_wr {
@@ -1343,7 +1340,7 @@ typedef union cvmx_pemx_cfg_wr cvmx_pemx_cfg_wr_t;
 /**
  * cvmx_pem#_clk_en
  *
- * Clock Enable for ECLK and PCE_CLK
+ * This register contains the clock enable for ECLK and PCE_CLK.
  *
  */
 union cvmx_pemx_clk_en {
@@ -1351,10 +1348,8 @@ union cvmx_pemx_clk_en {
 	struct cvmx_pemx_clk_en_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t pceclk_gate                  : 1;  /**< When set, pce_clk is gated off.
-                                                         When clear, pce_clk is enabled. */
-	uint64_t csclk_gate                   : 1;  /**< When set, eclk is gated off.
-                                                         When clear, eclk is enabled. */
+	uint64_t pceclk_gate                  : 1;  /**< When set, PCE_CLK is gated off. When clear, PCE_CLK is enabled. */
+	uint64_t csclk_gate                   : 1;  /**< When set, ECLK is gated off. When clear, ECLK is enabled. */
 #else
 	uint64_t csclk_gate                   : 1;
 	uint64_t pceclk_gate                  : 1;
@@ -1369,7 +1364,7 @@ typedef union cvmx_pemx_clk_en cvmx_pemx_clk_en_t;
 /**
  * cvmx_pem#_cpl_lut_valid
  *
- * Bit set for outstanding tag read.
+ * This register specifies the bit set for an outstanding tag read.
  *
  */
 union cvmx_pemx_cpl_lut_valid {
@@ -1406,7 +1401,7 @@ typedef union cvmx_pemx_cpl_lut_valid cvmx_pemx_cpl_lut_valid_t;
 /**
  * cvmx_pem#_ctl_status
  *
- * General control and status of the PEM.
+ * This is a general control and status register of the PEM.
  *
  */
 union cvmx_pemx_ctl_status {
@@ -1414,9 +1409,8 @@ union cvmx_pemx_ctl_status {
 	struct cvmx_pemx_ctl_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
-	uint64_t inv_dpar                     : 1;  /**< Invert the generated parity to be written into the
-                                                         the most significant Data Queue Buffer ram block
-                                                         to force a parity error when it is later read. */
+	uint64_t inv_dpar                     : 1;  /**< Invert the generated parity to be written into the most significant data queue buffer RAM
+                                                         block to force a parity error when it is later read. */
 	uint64_t inv_hpar                     : 1;  /**< Invert the generated parity to be written into the
                                                          most significant Header Queue Buffer ram block
                                                          to force a parity error when it is later read. */
@@ -1544,42 +1538,32 @@ union cvmx_pemx_ctl_status {
 	struct cvmx_pemx_ctl_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
-	uint64_t inv_dpar                     : 1;  /**< Invert the generated parity to be written into the
-                                                         the most significant Data Queue Buffer ram block
-                                                         to force a parity error when it is later read. */
+	uint64_t inv_dpar                     : 1;  /**< Invert the generated parity to be written into the most significant data queue buffer RAM
+                                                         block to force a parity error when it is later read. */
 	uint64_t reserved_48_49               : 2;
-	uint64_t auto_sd                      : 1;  /**< Link Hardware Autonomous Speed Disable. */
+	uint64_t auto_sd                      : 1;  /**< Link hardware autonomous speed disable. */
 	uint64_t dnum                         : 5;  /**< Primary bus device number. */
 	uint64_t pbus                         : 8;  /**< Primary bus number. */
 	uint64_t reserved_32_33               : 2;
-	uint64_t cfg_rtry                     : 16; /**< The time x 0x10000 in core clocks to wait for a
-                                                         CPL to a CFG RD that does not carry a Retry Status.
-                                                         Until such time that the timeout occurs and Retry
-                                                         Status is received for a CFG RD, the Read CFG Read
-                                                         will be resent. A value of 0 disables retries and
-                                                         treats a CPL Retry as a CPL UR.
-                                                         When enabled only one CFG RD may be issued until
+	uint64_t cfg_rtry                     : 16; /**< The time * 0x10000 in coprocessor clocks to wait for a CPL to a configuration read that
+                                                         does not carry a retry status. Until such time that the timeout occurs and retry status is
+                                                         received for a configuration read, the read will be resent. A value of 0 disables retries
+                                                         and treats a CPL Retry as a CPL UR. When enabled, only one CFG RD may be issued until
                                                          either successful completion or CPL UR. */
 	uint64_t reserved_12_15               : 4;
-	uint64_t pm_xtoff                     : 1;  /**< When WRITTEN with a '1' a single cycle pulse is
-                                                         to the PCIe core pm_xmt_turnoff port. RC mode. */
-	uint64_t pm_xpme                      : 1;  /**< When WRITTEN with a '1' a single cycle pulse is
-                                                         to the PCIe core pm_xmt_pme port. EP mode. */
-	uint64_t ob_p_cmd                     : 1;  /**< When WRITTEN with a '1' a single cycle pulse is
-                                                         to the PCIe core outband_pwrup_cmd port. EP mode. */
+	uint64_t pm_xtoff                     : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_turnoff port. RC mode. */
+	uint64_t pm_xpme                      : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core pm_xmt_pme port. EP mode. */
+	uint64_t ob_p_cmd                     : 1;  /**< When written with one, a single cycle pulse is sent to the PCIe core outband_pwrup_cmd
+                                                         port. EP mode. */
 	uint64_t reserved_7_8                 : 2;
 	uint64_t nf_ecrc                      : 1;  /**< Do not forward peer-to-peer ECRC TLPs. */
-	uint64_t dly_one                      : 1;  /**< When set the output client state machines will
-                                                         wait one cycle before starting a new TLP out. */
-	uint64_t lnk_enb                      : 1;  /**< When set '1' the link is enabled when '0' the
-                                                         link is disabled. This bit only is active when in
-                                                         RC mode. */
-	uint64_t ro_ctlp                      : 1;  /**< When set '1' C-TLPs that have the RO bit set will
-                                                         not wait for P-TLPs that normaly would be sent
-                                                         first. */
-	uint64_t fast_lm                      : 1;  /**< When '1' forces fast link mode. */
-	uint64_t inv_ecrc                     : 1;  /**< When '1' causes the LSB of the ECRC to be inverted. */
-	uint64_t inv_lcrc                     : 1;  /**< When '1' causes the LSB of the LCRC to be inverted. */
+	uint64_t dly_one                      : 1;  /**< When set the output client state machines will wait one cycle before starting a new TLP out. */
+	uint64_t lnk_enb                      : 1;  /**< When set, the link is enabled; when clear (0) the link is disabled. This bit only is
+                                                         active when in RC mode. */
+	uint64_t ro_ctlp                      : 1;  /**< When set, C-TLPs that have the RO bit set will not wait for P-TLPs that are normally sent first. */
+	uint64_t fast_lm                      : 1;  /**< When set, forces fast link mode. */
+	uint64_t inv_ecrc                     : 1;  /**< When set, causes the LSB of the ECRC to be inverted. */
+	uint64_t inv_lcrc                     : 1;  /**< When set, causes the LSB of the LCRC to be inverted. */
 #else
 	uint64_t inv_lcrc                     : 1;
 	uint64_t inv_ecrc                     : 1;
@@ -1610,7 +1594,7 @@ typedef union cvmx_pemx_ctl_status cvmx_pemx_ctl_status_t;
 /**
  * cvmx_pem#_ctl_status2
  *
- * Additional general control and status of the PEM.
+ * This register contains additional general control and status of the PEM.
  *
  */
 union cvmx_pemx_ctl_status2 {
@@ -1618,16 +1602,12 @@ union cvmx_pemx_ctl_status2 {
 	struct cvmx_pemx_ctl_status2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t no_fwd_prg                   : 16; /**< The time x 0x10000 in core clocks to wait for the
-                                                         TLP FIFOs to be able to unload an entry. If there is
-                                                         no forward progress, such that the timeout occurs,
-                                                         credits will be returned to the SLI and an interrupt
-                                                         (if enabled) will be asserted. Any more TLPs received
-                                                         will be dropped on the floor and the credits
-                                                         associated with those TLPs will be returned, as well.
-                                                         Note that 0xFFFF is a reserved value that will put
-                                                         the PEM in the 'forward progress stopped' state immediately.
-                                                         This state will hold until a mac reset is received. */
+	uint64_t no_fwd_prg                   : 16; /**< The time * 0x10000 in core clocks to wait for the TLP FIFOs to be able to unload an entry.
+                                                         If there is no forward progress, such that the timeout occurs, credits are returned to the
+                                                         SLI and an interrupt (if enabled) is asserted. Any more TLPs received are dropped on the
+                                                         floor and the credits associated with those TLPs are returned as well. Note that 0xFFFF is
+                                                         a reserved value that will put the PEM in the 'forward progress stopped' state
+                                                         immediately. This state holds until a MAC reset is received. */
 #else
 	uint64_t no_fwd_prg                   : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1640,27 +1620,27 @@ typedef union cvmx_pemx_ctl_status2 cvmx_pemx_ctl_status2_t;
 /**
  * cvmx_pem#_dbg_info
  *
- * "PEM#_DBG_INFO = PEM Debug Information
- * General debug info."
+ * This is a debug information register of the PEM.
+ *
  */
 union cvmx_pemx_dbg_info {
 	uint64_t u64;
 	struct cvmx_pemx_dbg_info_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_58_63               : 6;
-	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a Core Header Queue Bank1 double bit error */
-	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a Core Header Queue Bank1 single bit error */
-	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a Core Header Queue Bank0 double bit error */
-	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a Core Header Queue Bank0 single bit error */
-	uint64_t rtry_dbe                     : 1;  /**< Detected a Core Retry RAM double bit error */
-	uint64_t rtry_sbe                     : 1;  /**< Detected a Core Retry RAM single bit error */
+	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a core header queue bank1 double bit error. */
+	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a core header queue bank1 single bit error. */
+	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a core header queue bank0 double bit error. */
+	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a core header queue bank0 single bit error. */
+	uint64_t rtry_dbe                     : 1;  /**< Detected a core retry RAM double bit error. */
+	uint64_t rtry_sbe                     : 1;  /**< Detected a core retry RAM single bit error. */
 	uint64_t reserved_50_51               : 2;
-	uint64_t c_d1_dbe                     : 1;  /**< Detected a TLP CPL Fifo data1 double bit error */
-	uint64_t c_d1_sbe                     : 1;  /**< Detected a TLP CPL Fifo data1 single bit error */
-	uint64_t c_d0_dbe                     : 1;  /**< Detected a TLP CPL Fifo data0 double bit error */
-	uint64_t c_d0_sbe                     : 1;  /**< Detected a TLP CPL Fifo data0 single bit error */
+	uint64_t c_d1_dbe                     : 1;  /**< Detected a TLP CPL FIFO data1 double bit error. */
+	uint64_t c_d1_sbe                     : 1;  /**< Detected a TLP CPL FIFO data1 single bit error. */
+	uint64_t c_d0_dbe                     : 1;  /**< Detected a TLP CPL FIFO data0 double bit error. */
+	uint64_t c_d0_sbe                     : 1;  /**< Detected a TLP CPL FIFO data0 single bit error. */
 	uint64_t reserved_34_45               : 12;
-	uint64_t datq_pe                      : 1;  /**< Detected a Data Queue RAM parity error */
+	uint64_t datq_pe                      : 1;  /**< Detected a data queue RAM parity error. */
 	uint64_t hdrq_pe                      : 1;  /**< Detected a Header Queue RAM parity error */
 	uint64_t reserved_31_31               : 1;
 	uint64_t ecrc_e                       : 1;  /**< Received a ECRC error.
@@ -2000,8 +1980,7 @@ union cvmx_pemx_dbg_info {
                                                          this bit is set as well. */
 	uint64_t spoison                      : 1;  /**< Poisoned TLP sent
                                                          peai__client0_tlp_ep & peai__client0_tlp_hv
-                                                         peai__client1_tlp_ep & peai__client1_tlp_hv (atomic_op).
-                                                         Throws PEM_INTSN_E::PEM(0..2)_ERROR_SPOISON. */
+                                                         peai__client1_tlp_ep & peai__client1_tlp_hv (atomic_op). */
 #else
 	uint64_t spoison                      : 1;
 	uint64_t rtlpmal                      : 1;
@@ -2055,111 +2034,72 @@ union cvmx_pemx_dbg_info {
 	struct cvmx_pemx_dbg_info_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_58_63               : 6;
-	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a Core Header Queue Bank1 double bit error */
-	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a Core Header Queue Bank1 single bit error */
-	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a Core Header Queue Bank0 double bit error */
-	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a Core Header Queue Bank0 single bit error */
-	uint64_t rtry_dbe                     : 1;  /**< Detected a Core Retry RAM double bit error */
-	uint64_t rtry_sbe                     : 1;  /**< Detected a Core Retry RAM single bit error */
-	uint64_t c_c_dbe                      : 1;  /**< Detected a TLP CPL Fifo ctrl double bit error */
-	uint64_t c_c_sbe                      : 1;  /**< Detected a TLP CPL Fifo ctrl single bit error */
-	uint64_t c_d1_dbe                     : 1;  /**< Detected a TLP CPL Fifo data1 double bit error */
-	uint64_t c_d1_sbe                     : 1;  /**< Detected a TLP CPL Fifo data1 single bit error */
-	uint64_t c_d0_dbe                     : 1;  /**< Detected a TLP CPL Fifo data0 double bit error */
-	uint64_t c_d0_sbe                     : 1;  /**< Detected a TLP CPL Fifo data0 single bit error */
-	uint64_t n_c_dbe                      : 1;  /**< Detected a TLP NP Fifo ctrl double bit error */
-	uint64_t n_c_sbe                      : 1;  /**< Detected a TLP NP Fifo ctrl single bit error */
-	uint64_t n_d1_dbe                     : 1;  /**< Detected a TLP NP Fifo data1 double bit error */
-	uint64_t n_d1_sbe                     : 1;  /**< Detected a TLP NP Fifo data1 single bit error */
-	uint64_t n_d0_dbe                     : 1;  /**< Detected a TLP NP Fifo data0 double bit error */
-	uint64_t n_d0_sbe                     : 1;  /**< Detected a TLP NP fifo data0 single bit error */
-	uint64_t p_c_dbe                      : 1;  /**< Detected a TLP Posted Fifo ctrl double bit error */
-	uint64_t p_c_sbe                      : 1;  /**< Detected a TLP Posted Fifo ctrl single bit error */
-	uint64_t p_d1_dbe                     : 1;  /**< Detected a TLP Posted Fifo data1 double bit error */
-	uint64_t p_d1_sbe                     : 1;  /**< Detected a TLP Posted Fifo data1 single bit error */
-	uint64_t p_d0_dbe                     : 1;  /**< Detected a TLP Posted Fifo data0 double bit error */
-	uint64_t p_d0_sbe                     : 1;  /**< Detected a TLP Posted Fifo data0 single bit error */
-	uint64_t datq_pe                      : 1;  /**< Detected a Data Queue RAM parity error */
+	uint64_t qhdr_b1_dbe                  : 1;  /**< Detected a core header queue bank1 double bit error. */
+	uint64_t qhdr_b1_sbe                  : 1;  /**< Detected a core header queue bank1 single bit error. */
+	uint64_t qhdr_b0_dbe                  : 1;  /**< Detected a core header queue bank0 double bit error. */
+	uint64_t qhdr_b0_sbe                  : 1;  /**< Detected a core header queue bank0 single bit error. */
+	uint64_t rtry_dbe                     : 1;  /**< Detected a core retry RAM double bit error. */
+	uint64_t rtry_sbe                     : 1;  /**< Detected a core retry RAM single bit error. */
+	uint64_t c_c_dbe                      : 1;  /**< Detected a TLP CPL FIFO control double bit error. */
+	uint64_t c_c_sbe                      : 1;  /**< Detected a TLP CPL FIFO control single bit error. */
+	uint64_t c_d1_dbe                     : 1;  /**< Detected a TLP CPL FIFO data1 double bit error. */
+	uint64_t c_d1_sbe                     : 1;  /**< Detected a TLP CPL FIFO data1 single bit error. */
+	uint64_t c_d0_dbe                     : 1;  /**< Detected a TLP CPL FIFO data0 double bit error. */
+	uint64_t c_d0_sbe                     : 1;  /**< Detected a TLP CPL FIFO data0 single bit error. */
+	uint64_t n_c_dbe                      : 1;  /**< Detected a TLP NP FIFO control double bit error. */
+	uint64_t n_c_sbe                      : 1;  /**< Detected a TLP NP FIFO control single bit error. */
+	uint64_t n_d1_dbe                     : 1;  /**< Detected a TLP NP FIFO data1 double bit error. */
+	uint64_t n_d1_sbe                     : 1;  /**< Detected a TLP NP FIFO data1 single bit error. */
+	uint64_t n_d0_dbe                     : 1;  /**< Detected a TLP NP FIFO data0 double bit error. */
+	uint64_t n_d0_sbe                     : 1;  /**< Detected a TLP NP FIFO data0 single bit error. */
+	uint64_t p_c_dbe                      : 1;  /**< Detected a TLP posted FIFO control double bit error. */
+	uint64_t p_c_sbe                      : 1;  /**< Detected a TLP posted FIFO control single bit error. */
+	uint64_t p_d1_dbe                     : 1;  /**< Detected a TLP posted FIFO data1 double bit error. */
+	uint64_t p_d1_sbe                     : 1;  /**< Detected a TLP posted FIFO data1 single bit error. */
+	uint64_t p_d0_dbe                     : 1;  /**< Detected a TLP posted FIFO data0 double bit error. */
+	uint64_t p_d0_sbe                     : 1;  /**< Detected a TLP posted FIFO data0 single bit error. */
+	uint64_t datq_pe                      : 1;  /**< Detected a data queue RAM parity error. */
 	uint64_t reserved_32_32               : 1;
-	uint64_t lofp                         : 1;  /**< Lack of Forward Progress at TLP FIFOs timeout occured. */
-	uint64_t ecrc_e                       : 1;  /**< Received a ECRC error.
-                                                         radm_ecrc_err */
-	uint64_t rawwpp                       : 1;  /**< Received a write with poisoned payload
-                                                         radm_rcvd_wreq_poisoned */
-	uint64_t racpp                        : 1;  /**< Received a completion with poisoned payload
-                                                         radm_rcvd_cpl_poisoned */
-	uint64_t ramtlp                       : 1;  /**< Received a malformed TLP
-                                                         radm_mlf_tlp_err */
-	uint64_t rarwdns                      : 1;  /**< Recieved a request which device does not support
-                                                         radm_rcvd_ur_req */
-	uint64_t caar                         : 1;  /**< Completer aborted a request
-                                                         radm_rcvd_ca_req
-                                                         This bit will never be set because Octeon does
-                                                         not generate Completer Aborts. */
-	uint64_t racca                        : 1;  /**< Received a completion with CA status
-                                                         radm_rcvd_cpl_ca */
-	uint64_t racur                        : 1;  /**< Received a completion with UR status
-                                                         radm_rcvd_cpl_ur */
-	uint64_t rauc                         : 1;  /**< Received an unexpected completion
-                                                         radm_unexp_cpl_err */
-	uint64_t rqo                          : 1;  /**< Receive queue overflow. Normally happens only when
-                                                         flow control advertisements are ignored
-                                                         radm_qoverflow */
-	uint64_t fcuv                         : 1;  /**< Flow Control Update Violation (opt. checks)
-                                                         int_xadm_fc_prot_err */
-	uint64_t rpe                          : 1;  /**< When the PHY reports 8B/10B decode error
-                                                         (RxStatus = 3b100) or disparity error
-                                                         (RxStatus = 3b111), the signal rmlh_rcvd_err will
-                                                         be asserted.
-                                                         rmlh_rcvd_err */
-	uint64_t fcpvwt                       : 1;  /**< Flow Control Protocol Violation (Watchdog Timer)
-                                                         rtlh_fc_prot_err */
-	uint64_t dpeoosd                      : 1;  /**< DLLP protocol error (out of sequence DLLP)
-                                                         rdlh_prot_err */
-	uint64_t rtwdle                       : 1;  /**< Received TLP with DataLink Layer Error
-                                                         rdlh_bad_tlp_err */
-	uint64_t rdwdle                       : 1;  /**< Received DLLP with DataLink Layer Error
-                                                         rdlh_bad_dllp_err */
-	uint64_t mre                          : 1;  /**< Max Retries Exceeded
-                                                         xdlh_replay_num_rlover_err */
-	uint64_t rte                          : 1;  /**< Replay Timer Expired
-                                                         xdlh_replay_timeout_err
-                                                         This bit is set when the REPLAY_TIMER expires in
-                                                         the PCIE core. The probability of this bit being
-                                                         set will increase with the traffic load. */
-	uint64_t acto                         : 1;  /**< A Completion Timeout Occured
-                                                         pedc_radm_cpl_timeout */
-	uint64_t rvdm                         : 1;  /**< Received Vendor-Defined Message
-                                                         pedc_radm_vendor_msg */
-	uint64_t rumep                        : 1;  /**< Received Unlock Message (EP Mode Only)
-                                                         pedc_radm_msg_unlock */
-	uint64_t rptamrc                      : 1;  /**< Received PME Turnoff Acknowledge Message
-                                                         (RC Mode only)
-                                                         pedc_radm_pm_to_ack */
-	uint64_t rpmerc                       : 1;  /**< Received PME Message (RC Mode only)
-                                                         pedc_radm_pm_pme */
-	uint64_t rfemrc                       : 1;  /**< Received Fatal Error Message (RC Mode only)
-                                                         pedc_radm_fatal_err
-                                                         Bit set when a message with ERR_FATAL is set. */
-	uint64_t rnfemrc                      : 1;  /**< Received Non-Fatal Error Message (RC Mode only)
-                                                         pedc_radm_nonfatal_err */
-	uint64_t rcemrc                       : 1;  /**< Received Correctable Error Message (RC Mode only)
-                                                         pedc_radm_correctable_err */
-	uint64_t rpoison                      : 1;  /**< Received Poisoned TLP
-                                                         pedc__radm_trgt1_poisoned & pedc__radm_trgt1_hv */
-	uint64_t recrce                       : 1;  /**< Received ECRC Error
-                                                         pedc_radm_trgt1_ecrc_err & pedc__radm_trgt1_eot */
-	uint64_t rtlplle                      : 1;  /**< Received TLP has link layer error
-                                                         pedc_radm_trgt1_dllp_abort & pedc__radm_trgt1_eot */
-	uint64_t rtlpmal                      : 1;  /**< Received TLP is malformed or a message.
-                                                         pedc_radm_trgt1_tlp_abort & pedc__radm_trgt1_eot
-                                                         If the core receives a MSG (or Vendor Message)
-                                                         or if a received AtomicOp viloates address/length rules,
-                                                         this bit is set as well. */
-	uint64_t spoison                      : 1;  /**< Poisoned TLP sent
-                                                         peai__client0_tlp_ep & peai__client0_tlp_hv
-                                                         peai__client1_tlp_ep & peai__client1_tlp_hv (atomic_op).
-                                                         Throws PEM_INTSN_E::PEM(0..3)_ERROR_SPOISON. */
+	uint64_t lofp                         : 1;  /**< Lack of forward progress at TLP FIFOs timeout occurred. */
+	uint64_t ecrc_e                       : 1;  /**< Received an ECRC error. */
+	uint64_t rawwpp                       : 1;  /**< Received a write with poisoned payload. radm_rcvd_wreq_poisoned */
+	uint64_t racpp                        : 1;  /**< Received a completion with poisoned payload. radm_rcvd_cpl_poisoned */
+	uint64_t ramtlp                       : 1;  /**< Received a malformed TLP. radm_mlf_tlp_err */
+	uint64_t rarwdns                      : 1;  /**< Received a request which device does not support. radm_rcvd_ur_req */
+	uint64_t caar                         : 1;  /**< Completer aborted a request. This bit is never set because CN78XX does not generate
+                                                         completer aborts. radm_rcvd_ca_req */
+	uint64_t racca                        : 1;  /**< Received a completion with CA status. radm_rcvd_cpl_ca */
+	uint64_t racur                        : 1;  /**< Received a completion with UR status. radm_rcvd_cpl_ur */
+	uint64_t rauc                         : 1;  /**< Received an unexpected completion. radm_unexp_cpl_err */
+	uint64_t rqo                          : 1;  /**< Receive queue overflow. Normally happens only when flow control advertisements are
+                                                         ignored. radm_qoverflow */
+	uint64_t fcuv                         : 1;  /**< Flow control update violation. (opt. checks) int_xadm_fc_prot_err */
+	uint64_t rpe                          : 1;  /**< PHY reported an 8B/10B decode error (RxStatus = 3b100) or disparity error (RxStatus =
+                                                         3b111), the signal rmlh_rcvd_err will be asserted. rmlh_rcvd_err */
+	uint64_t fcpvwt                       : 1;  /**< Flow control protocol violation (watchdog timer). rtlh_fc_prot_err */
+	uint64_t dpeoosd                      : 1;  /**< DLLP protocol error (out of sequence DLLP). rdlh_prot_err */
+	uint64_t rtwdle                       : 1;  /**< Received TLP with datalink layer error. rdlh_bad_tlp_err */
+	uint64_t rdwdle                       : 1;  /**< Received DLLP with datalink layer error. rdlh_bad_dllp_err */
+	uint64_t mre                          : 1;  /**< Maximum number of retries exceeded. xdlh_replay_num_rlover_err */
+	uint64_t rte                          : 1;  /**< Replay timer expired. This bit is set when the REPLAY_TIMER expires in the PCIe core. The
+                                                         probability of this bit being set increases with the traffic load. xdlh_replay_timeout_err */
+	uint64_t acto                         : 1;  /**< A completion timeout occurred. pedc_radm_cpl_timeout */
+	uint64_t rvdm                         : 1;  /**< Received vendor-defined message. pedc_radm_vendor_msg */
+	uint64_t rumep                        : 1;  /**< Received unlock message (EP mode only). pedc_radm_msg_unlock */
+	uint64_t rptamrc                      : 1;  /**< Received PME turnoff acknowledge message (RC mode only). pedc_radm_pm_to_ack */
+	uint64_t rpmerc                       : 1;  /**< Received PME message (RC mode only). pedc_radm_pm_pme */
+	uint64_t rfemrc                       : 1;  /**< Received fatal-error message (RC mode only). This bit is set when a message with ERR_FATAL
+                                                         is set. pedc_radm_fatal_err */
+	uint64_t rnfemrc                      : 1;  /**< Received nonfatal error message (RC mode only). pedc_radm_nonfatal_err */
+	uint64_t rcemrc                       : 1;  /**< Received correctable error message (RC mode only). pedc_radm_correctable_err */
+	uint64_t rpoison                      : 1;  /**< Received poisoned TLP. pedc__radm_trgt1_poisoned & pedc__radm_trgt1_hv */
+	uint64_t recrce                       : 1;  /**< Received ECRC error. pedc_radm_trgt1_ecrc_err & pedc__radm_trgt1_eot */
+	uint64_t rtlplle                      : 1;  /**< Received TLP has link layer error. pedc_radm_trgt1_dllp_abort & pedc__radm_trgt1_eot */
+	uint64_t rtlpmal                      : 1;  /**< Received TLP is malformed or a message. If the core receives a MSG (or Vendor Message) or
+                                                         if a received AtomicOp viloates address/length rules, this bit is set as well.
+                                                         pedc_radm_trgt1_tlp_abort & pedc__radm_trgt1_eot */
+	uint64_t spoison                      : 1;  /**< Poisoned TLP sent. Throws PEM_INTSN_E::PEM(0..3)_ERROR_SPOISON. peai__client0_tlp_ep &
+                                                         peai__client0_tlp_hv or peai__client1_tlp_ep & peai__client1_tlp_hv (atomic_op). */
 #else
 	uint64_t spoison                      : 1;
 	uint64_t rtlpmal                      : 1;
@@ -2415,14 +2355,15 @@ typedef union cvmx_pemx_dbg_info_en cvmx_pemx_dbg_info_en_t;
 /**
  * cvmx_pem#_diag_status
  *
- * Selection control for the cores diagnostic bus.
+ * This register contains selection control for the core diagnostic bus.
  *
  */
 union cvmx_pemx_diag_status {
 	uint64_t u64;
 	struct cvmx_pemx_diag_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_6_63                : 58;
+	uint64_t reserved_9_63                : 55;
+	uint64_t pwrdwn                       : 3;  /**< Current mac_phy_powerdown state. */
 	uint64_t pm_dst                       : 3;  /**< Current power management DSTATE. */
 	uint64_t pm_stat                      : 1;  /**< Power Management Status. */
 	uint64_t pm_en                        : 1;  /**< Power Management Event Enable. */
@@ -2432,7 +2373,8 @@ union cvmx_pemx_diag_status {
 	uint64_t pm_en                        : 1;
 	uint64_t pm_stat                      : 1;
 	uint64_t pm_dst                       : 3;
-	uint64_t reserved_6_63                : 58;
+	uint64_t pwrdwn                       : 3;
+	uint64_t reserved_9_63                : 55;
 #endif
 	} s;
 	struct cvmx_pemx_diag_status_cn61xx {
@@ -2455,7 +2397,21 @@ union cvmx_pemx_diag_status {
 	struct cvmx_pemx_diag_status_cn61xx   cn66xx;
 	struct cvmx_pemx_diag_status_cn61xx   cn68xx;
 	struct cvmx_pemx_diag_status_cn61xx   cn68xxp1;
-	struct cvmx_pemx_diag_status_s        cn70xx;
+	struct cvmx_pemx_diag_status_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_6_63                : 58;
+	uint64_t pm_dst                       : 3;  /**< Current power management DSTATE. */
+	uint64_t pm_stat                      : 1;  /**< Power Management Status. */
+	uint64_t pm_en                        : 1;  /**< Power Management Event Enable. */
+	uint64_t aux_en                       : 1;  /**< Auxilary Power Enable. */
+#else
+	uint64_t aux_en                       : 1;
+	uint64_t pm_en                        : 1;
+	uint64_t pm_stat                      : 1;
+	uint64_t pm_dst                       : 3;
+	uint64_t reserved_6_63                : 58;
+#endif
+	} cn70xx;
 	struct cvmx_pemx_diag_status_s        cn78xx;
 	struct cvmx_pemx_diag_status_cn61xx   cnf71xx;
 };
@@ -2464,7 +2420,7 @@ typedef union cvmx_pemx_diag_status cvmx_pemx_diag_status_t;
 /**
  * cvmx_pem#_ecc_ena
  *
- * Contains enables for TLP FIFO ECC RAMs
+ * Contains enables for TLP FIFO ECC RAMs.
  *
  */
 union cvmx_pemx_ecc_ena {
@@ -2472,13 +2428,13 @@ union cvmx_pemx_ecc_ena {
 	struct cvmx_pemx_ecc_ena_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_35_63               : 29;
-	uint64_t qhdr_b1_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank1 RAM */
-	uint64_t qhdr_b0_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank0 RAM */
-	uint64_t rtry_ena                     : 1;  /**< ECC enable for Core's RETRY RAM */
+	uint64_t qhdr_b1_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank1 RAM. */
+	uint64_t qhdr_b0_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank0 RAM. */
+	uint64_t rtry_ena                     : 1;  /**< ECC enable for Core's RETRY RA. */
 	uint64_t reserved_9_31                : 23;
-	uint64_t c_c_ena                      : 1;  /**< ECC enable for TLP CPL ctl Fifo */
-	uint64_t c_d1_ena                     : 1;  /**< ECC enable for TLP CPL data1 Fifo */
-	uint64_t c_d0_ena                     : 1;  /**< ECC enable for TLP CPL data0 Fifo */
+	uint64_t c_c_ena                      : 1;  /**< ECC enable for TLP CPL control FIFO. */
+	uint64_t c_d1_ena                     : 1;  /**< ECC enable for TLP CPL data1 FIFO. */
+	uint64_t c_d0_ena                     : 1;  /**< ECC enable for TLP CPL data0 FIFO. */
 	uint64_t reserved_0_5                 : 6;
 #else
 	uint64_t reserved_0_5                 : 6;
@@ -2514,19 +2470,19 @@ union cvmx_pemx_ecc_ena {
 	struct cvmx_pemx_ecc_ena_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_35_63               : 29;
-	uint64_t qhdr_b1_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank1 RAM */
-	uint64_t qhdr_b0_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank0 RAM */
-	uint64_t rtry_ena                     : 1;  /**< ECC enable for Core's RETRY RAM */
+	uint64_t qhdr_b1_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank1 RAM. */
+	uint64_t qhdr_b0_ena                  : 1;  /**< ECC enable for Core's Q HDR Bank0 RAM. */
+	uint64_t rtry_ena                     : 1;  /**< ECC enable for Core's RETRY RA. */
 	uint64_t reserved_9_31                : 23;
-	uint64_t c_c_ena                      : 1;  /**< ECC enable for TLP CPL ctl Fifo */
-	uint64_t c_d1_ena                     : 1;  /**< ECC enable for TLP CPL data1 Fifo */
-	uint64_t c_d0_ena                     : 1;  /**< ECC enable for TLP CPL data0 Fifo */
-	uint64_t n_c_ena                      : 1;  /**< ECC enable for TLP NP ctl Fifo */
-	uint64_t n_d1_ena                     : 1;  /**< ECC enable for TLP NP data1 Fifo */
-	uint64_t n_d0_ena                     : 1;  /**< ECC enable for TLP NP data0 Fifo */
-	uint64_t p_c_ena                      : 1;  /**< ECC enable for TLP Posted ctl Fifo */
-	uint64_t p_d1_ena                     : 1;  /**< ECC enable for TLP Posted data1 Fifo */
-	uint64_t p_d0_ena                     : 1;  /**< ECC enable for TLP Posted data0 ifo */
+	uint64_t c_c_ena                      : 1;  /**< ECC enable for TLP CPL control FIFO. */
+	uint64_t c_d1_ena                     : 1;  /**< ECC enable for TLP CPL data1 FIFO. */
+	uint64_t c_d0_ena                     : 1;  /**< ECC enable for TLP CPL data0 FIFO. */
+	uint64_t n_c_ena                      : 1;  /**< ECC enable for TLP NP control FIFO. */
+	uint64_t n_d1_ena                     : 1;  /**< ECC enable for TLP NP data1 FIFO. */
+	uint64_t n_d0_ena                     : 1;  /**< ECC enable for TLP NP data0 FIFO. */
+	uint64_t p_c_ena                      : 1;  /**< ECC enable for TLP posted control FIFO. */
+	uint64_t p_d1_ena                     : 1;  /**< ECC enable for TLP posted data1 FIFO. */
+	uint64_t p_d0_ena                     : 1;  /**< ECC enable for TLP posted data0 FIFO. */
 #else
 	uint64_t p_d0_ena                     : 1;
 	uint64_t p_d1_ena                     : 1;
@@ -2550,21 +2506,21 @@ typedef union cvmx_pemx_ecc_ena cvmx_pemx_ecc_ena_t;
 /**
  * cvmx_pem#_ecc_synd_ctrl
  *
- * PEM_ECC_SYND_CTL
- * Contains Syndrome Control for TLP FIFO ECC RAMs
+ * This register contains syndrome control for TLP FIFO ECC RAMs.
+ *
  */
 union cvmx_pemx_ecc_synd_ctrl {
 	uint64_t u64;
 	struct cvmx_pemx_ecc_synd_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_38_63               : 26;
-	uint64_t qhdr_b1_syn                  : 2;  /**< Syndrome Flip bits for Core's Q HDR Bank1 RAM */
-	uint64_t qhdr_b0_syn                  : 2;  /**< Syndrome Flip bits for Core's Q HDR Bank0 RAM */
-	uint64_t rtry_syn                     : 2;  /**< Syndrome Flip bits for Core's RETRY RAM */
+	uint64_t qhdr_b1_syn                  : 2;  /**< Syndrome flip bits for Core's Q HDR Bank1 RAM. */
+	uint64_t qhdr_b0_syn                  : 2;  /**< Syndrome flip bits for Core's Q HDR Bank0 RAM. */
+	uint64_t rtry_syn                     : 2;  /**< Syndrome flip bits for Core's RETRY RAM. */
 	uint64_t reserved_18_31               : 14;
-	uint64_t c_c_syn                      : 2;  /**< Syndrome Flip bits for TLP CPL ctl Fifo */
-	uint64_t c_d1_syn                     : 2;  /**< Syndrome Flip bits for TLP CPL data1 Fifo */
-	uint64_t c_d0_syn                     : 2;  /**< Syndrome Flip bits for TLP CPL data0 Fifo */
+	uint64_t c_c_syn                      : 2;  /**< Syndrome flip bits for TLP CPL control FIFO. */
+	uint64_t c_d1_syn                     : 2;  /**< Syndrome flip bits for TLP CPL data1 FIFO. */
+	uint64_t c_d0_syn                     : 2;  /**< Syndrome flip bits for TLP CPL data0 FIFO. */
 	uint64_t reserved_0_11                : 12;
 #else
 	uint64_t reserved_0_11                : 12;
@@ -2600,19 +2556,19 @@ union cvmx_pemx_ecc_synd_ctrl {
 	struct cvmx_pemx_ecc_synd_ctrl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_38_63               : 26;
-	uint64_t qhdr_b1_syn                  : 2;  /**< Syndrome Flip bits for Core's Q HDR Bank1 RAM */
-	uint64_t qhdr_b0_syn                  : 2;  /**< Syndrome Flip bits for Core's Q HDR Bank0 RAM */
-	uint64_t rtry_syn                     : 2;  /**< Syndrome Flip bits for Core's RETRY RAM */
+	uint64_t qhdr_b1_syn                  : 2;  /**< Syndrome flip bits for Core's Q HDR Bank1 RAM. */
+	uint64_t qhdr_b0_syn                  : 2;  /**< Syndrome flip bits for Core's Q HDR Bank0 RAM. */
+	uint64_t rtry_syn                     : 2;  /**< Syndrome flip bits for Core's RETRY RAM. */
 	uint64_t reserved_18_31               : 14;
-	uint64_t c_c_syn                      : 2;  /**< Syndrome Flip bits for TLP CPL ctl Fifo */
-	uint64_t c_d1_syn                     : 2;  /**< Syndrome Flip bits for TLP CPL data1 Fifo */
-	uint64_t c_d0_syn                     : 2;  /**< Syndrome Flip bits for TLP CPL data0 Fifo */
-	uint64_t n_c_syn                      : 2;  /**< Syndrome Flip bits for TLP NP ctl Fifo */
-	uint64_t n_d1_syn                     : 2;  /**< Syndrome Flip bits for TLP NP data1 Fifo */
-	uint64_t n_d0_syn                     : 2;  /**< Syndrome Flip bits for TLP NP data0 Fifo */
-	uint64_t p_c_syn                      : 2;  /**< Syndrome Flip bits for TLP Posted ctl Fifo */
-	uint64_t p_d1_syn                     : 2;  /**< Syndrome Flip bits for TLP Posted data1 Fifo */
-	uint64_t p_d0_syn                     : 2;  /**< Syndrome Flip bits for TLP Posted data0 Fifo */
+	uint64_t c_c_syn                      : 2;  /**< Syndrome flip bits for TLP CPL control FIFO. */
+	uint64_t c_d1_syn                     : 2;  /**< Syndrome flip bits for TLP CPL data1 FIFO. */
+	uint64_t c_d0_syn                     : 2;  /**< Syndrome flip bits for TLP CPL data0 FIFO. */
+	uint64_t n_c_syn                      : 2;  /**< Syndrome flip bits for TLP NP control FIFO. */
+	uint64_t n_d1_syn                     : 2;  /**< Syndrome flip bits for TLP NP data1 FIFO. */
+	uint64_t n_d0_syn                     : 2;  /**< Syndrome flip bits for TLP NP data0 FIFO. */
+	uint64_t p_c_syn                      : 2;  /**< Syndrome flip bits for TLP posted control FIFO. */
+	uint64_t p_d1_syn                     : 2;  /**< Syndrome flip bits for TLP posted data1 FIFO. */
+	uint64_t p_d0_syn                     : 2;  /**< Syndrome flip bits for TLP posted data0 FIFO. */
 #else
 	uint64_t p_d0_syn                     : 2;
 	uint64_t p_d1_syn                     : 2;
@@ -2636,7 +2592,7 @@ typedef union cvmx_pemx_ecc_synd_ctrl cvmx_pemx_ecc_synd_ctrl_t;
 /**
  * cvmx_pem#_inb_read_credits
  *
- * The number of in flight reads from PCIe core to SLI
+ * This register contains the number of in-flight read operations from PCIe core to SLI.
  *
  */
 union cvmx_pemx_inb_read_credits {
@@ -2810,8 +2766,8 @@ typedef union cvmx_pemx_int_enb_int cvmx_pemx_int_enb_int_t;
 /**
  * cvmx_pem#_int_sum
  *
- * "PEM#_INT_SUM = PEM Interrupt Summary
- * Interrupt conditions for the PEM."
+ * This register contains the different interrupt summary bits of the PEM.
+ *
  */
 union cvmx_pemx_int_sum {
 	uint64_t u64;
@@ -2922,25 +2878,20 @@ union cvmx_pemx_int_sum {
 	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. */
 	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. */
 	uint64_t reserved_14_59               : 46;
-	uint64_t crs_dr                       : 1;  /**< Had a CRS Timeout when Retries were disabled. */
-	uint64_t crs_er                       : 1;  /**< Had a CRS Timeout when Retries were enabled. */
-	uint64_t rdlk                         : 1;  /**< Received Read Lock TLP. */
+	uint64_t crs_dr                       : 1;  /**< Had a CRS timeout when retries were disabled. */
+	uint64_t crs_er                       : 1;  /**< Had a CRS timeout when retries were enabled. */
+	uint64_t rdlk                         : 1;  /**< Received read lock TLP. */
 	uint64_t reserved_10_10               : 1;
-	uint64_t un_bx                        : 1;  /**< Received N-TLP for an unknown Bar. */
-	uint64_t un_b2                        : 1;  /**< Received N-TLP for Bar2 when bar2 is disabled. */
-	uint64_t un_b1                        : 1;  /**< Received N-TLP for Bar1 when bar1 index valid
-                                                         is not set. */
-	uint64_t up_bx                        : 1;  /**< Received P-TLP for an unknown Bar. */
-	uint64_t up_b2                        : 1;  /**< Received P-TLP for Bar2 when bar2 is disabeld. */
-	uint64_t up_b1                        : 1;  /**< Received P-TLP for Bar1 when bar1 index valid
-                                                         is not set. */
+	uint64_t un_bx                        : 1;  /**< Received N-TLP for unknown BAR. */
+	uint64_t un_b2                        : 1;  /**< Received N-TLP for BAR2 when BAR2 is disabled. */
+	uint64_t un_b1                        : 1;  /**< Received N-TLP for BAR1 when BAR1 index valid is not set. */
+	uint64_t up_bx                        : 1;  /**< Received P-TLP for an unknown BAR. */
+	uint64_t up_b2                        : 1;  /**< Received P-TLP for BAR2 when BAR2 is disabled. */
+	uint64_t up_b1                        : 1;  /**< Received P-TLP for BAR1 when BAR1 index valid is not set. */
 	uint64_t reserved_3_3                 : 1;
-	uint64_t pmei                         : 1;  /**< PME Interrupt.
-                                                         (cfg_pme_int) */
-	uint64_t se                           : 1;  /**< System Error, RC DEode Only.
-                                                         (cfg_sys_err_rc) */
-	uint64_t aeri                         : 1;  /**< Advanced Error Reporting Interrupt, RC Mode Only.
-                                                         (cfg_aer_rc_err_int). */
+	uint64_t pmei                         : 1;  /**< PME interrupt. (cfg_pme_int) */
+	uint64_t se                           : 1;  /**< System error, RC DEode Only.  (cfg_sys_err_rc) */
+	uint64_t aeri                         : 1;  /**< Advanced error reporting interrupt, RC mode only. (cfg_aer_rc_err_int). */
 #else
 	uint64_t aeri                         : 1;
 	uint64_t se                           : 1;
@@ -2970,7 +2921,7 @@ typedef union cvmx_pemx_int_sum cvmx_pemx_int_sum_t;
 /**
  * cvmx_pem#_on
  *
- * PEM is configured and ready
+ * This register indicates that PEM is configured and ready.
  *
  */
 union cvmx_pemx_on {
@@ -2978,11 +2929,10 @@ union cvmx_pemx_on {
 	struct cvmx_pemx_on_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t pemoor                       : 1;  /**< Indication to software that the PEM has been taken out of
-                                                         reset (ie bist is done) and it is safe to configure core CSRs. */
-	uint64_t pemon                        : 1;  /**< Indication to the QLM that the PEM is out of reset, configured
-                                                         and ready to send/receive traffic.  Setting this bit will take
-                                                         the configured PIPE out of reset. */
+	uint64_t pemoor                       : 1;  /**< Indication to software that the PEM has been taken out of reset (i.e. BIST is done) and it
+                                                         is safe to configure core CSRs. */
+	uint64_t pemon                        : 1;  /**< Indication to the QLM that the PEM is out of reset, configured, and ready to send/receive
+                                                         traffic. Setting this bit takes the configured PIPE out of reset. */
 #else
 	uint64_t pemon                        : 1;
 	uint64_t pemoor                       : 1;
@@ -2997,8 +2947,8 @@ typedef union cvmx_pemx_on cvmx_pemx_on_t;
 /**
  * cvmx_pem#_p2n_bar0_start
  *
- * The starting address for addresses to forwarded to the SLI in RC Mode.
- *
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the SLI in RC mode.
  */
 union cvmx_pemx_p2n_bar0_start {
 	uint64_t u64;
@@ -3027,8 +2977,8 @@ typedef union cvmx_pemx_p2n_bar0_start cvmx_pemx_p2n_bar0_start_t;
 /**
  * cvmx_pem#_p2n_bar1_start
  *
- * The starting address for addresses to forwarded to the SLI in RC Mode.
- *
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the SLI in RC mode.
  */
 union cvmx_pemx_p2n_bar1_start {
 	uint64_t u64;
@@ -3057,8 +3007,8 @@ typedef union cvmx_pemx_p2n_bar1_start cvmx_pemx_p2n_bar1_start_t;
 /**
  * cvmx_pem#_p2n_bar2_start
  *
- * The starting address for addresses to forwarded to the SLI in RC Mode.
- *
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the SLI in RC mode.
  */
 union cvmx_pemx_p2n_bar2_start {
 	uint64_t u64;
@@ -3087,8 +3037,7 @@ union cvmx_pemx_p2n_bar2_start {
 	struct cvmx_pemx_p2n_bar2_start_cn61xx cn70xx;
 	struct cvmx_pemx_p2n_bar2_start_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t addr                         : 19; /**< The starting address of the 2^45 address space
-                                                         that is the BAR2 address space. */
+	uint64_t addr                         : 19; /**< The starting address of the 2^45 BAR2 address space. */
 	uint64_t reserved_0_44                : 45;
 #else
 	uint64_t reserved_0_44                : 45;
@@ -3102,16 +3051,15 @@ typedef union cvmx_pemx_p2n_bar2_start cvmx_pemx_p2n_bar2_start_t;
 /**
  * cvmx_pem#_p2p_bar#_end
  *
- * "PEM_P2P_BAR#_END = PEM Peer-To-Peer BAR0 End
- * The ending address for addresses to forwarded to the PCIe peer port."
+ * This register specifies the ending address for memory requests that are to be forwarded to the
+ * PCIe peer port.
  */
 union cvmx_pemx_p2p_barx_end {
 	uint64_t u64;
 	struct cvmx_pemx_p2p_barx_end_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t addr                         : 52; /**< The ending address of the address window created
-                                                         this field and the PEM_P2P_BAR0_START[63:12]
-                                                         field. The full 64-bits of address are created by:
+	uint64_t addr                         : 52; /**< The ending address of the address window created by this field and the
+                                                         PEM_P2P_BAR0_START[63:12] field. The full 64-bits of the address are created by:
                                                          [ADDR[63:12], 12'b0]. */
 	uint64_t reserved_0_11                : 12;
 #else
@@ -3131,22 +3079,20 @@ typedef union cvmx_pemx_p2p_barx_end cvmx_pemx_p2p_barx_end_t;
 /**
  * cvmx_pem#_p2p_bar#_start
  *
- * "PEM_P2P_BAR#_START = PEM Peer-To-Peer BAR0 Start
- * The starting address and enable for addresses to forwarded to the PCIe peer port."
+ * This register specifies the starting address for memory requests that are to be forwarded to
+ * the PCIe peer port.
  */
 union cvmx_pemx_p2p_barx_start {
 	uint64_t u64;
 	struct cvmx_pemx_p2p_barx_start_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t addr                         : 52; /**< The starting address of the address window created
-                                                         by this field and the PEM_P2P_BAR0_END[63:12]
-                                                         field. The full 64-bits of address are created by:
+	uint64_t addr                         : 52; /**< The starting address of the address window created by this field and the
+                                                         PEM_P2P_BAR0_END[63:12] field. The full 64-bits of the address are created by:
                                                          [ADDR[63:12], 12'b0]. */
 	uint64_t reserved_2_11                : 10;
-	uint64_t dst                          : 2;  /**< The destination peer of the address window created
-                                                         by this field and the PEM_P2P_BAR0_END[63:12]
-                                                         field. It is illegal to configure the destination peer
-                                                         to match the source. */
+	uint64_t dst                          : 2;  /**< The destination peer of the address window created by this field and the
+                                                         PEM_P2P_BAR0_END[63:12] field. It is illegal to configure the destination peer to match
+                                                         the source. */
 #else
 	uint64_t dst                          : 2;
 	uint64_t reserved_2_11                : 10;
@@ -3176,7 +3122,7 @@ typedef union cvmx_pemx_p2p_barx_start cvmx_pemx_p2p_barx_start_t;
 /**
  * cvmx_pem#_qlm
  *
- * Configuration of the PEM3 QLM
+ * This register configures the PEM3 QLM.
  *
  */
 union cvmx_pemx_qlm {
@@ -3184,12 +3130,11 @@ union cvmx_pemx_qlm {
 	struct cvmx_pemx_qlm_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t pem3qlm                      : 1;  /**< " When set, PEM3 is configured to send/receive traffic to QLM4.
-                                                         When clear, PEM3 is configured to send/receive traffic to QLM3.
-                                                         Note that this bit can only be set for PEM3, for all other
-                                                         PEMs it has no function.
-                                                         Note that this bit must only be set when the associated PHYs
-                                                         are in reset and PEM3 is receiving no clocks." */
+	uint64_t pem3qlm                      : 1;  /**< When set, PEM3 is configured to send/receive traffic to QLM4. When clear, PEM3 is
+                                                         configured to send/receive traffic to QLM3. Note that this bit can only be set for PEM3,
+                                                         for all other PEMs it has no function. Note that this bit must only be set when both the
+                                                         associated PHYs and PEM3 are in reset. These conditions can be assured by setting the
+                                                         PEM(3)_ON[PEMON] bit after setting this bit. */
 #else
 	uint64_t pem3qlm                      : 1;
 	uint64_t reserved_1_63                : 63;
@@ -3210,10 +3155,10 @@ union cvmx_pemx_spi_ctl {
 	struct cvmx_pemx_spi_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_14_63               : 50;
-	uint64_t start_busy                   : 1;  /**< Start/Busy status. Starts SPI xctn when written, reads 1 when EEPROM busy, 0 when complete. */
+	uint64_t start_busy                   : 1;  /**< Start/Busy status. Starts SPI xctn when written; reads 1 when EEPROM busy, 0 when complete. */
 	uint64_t tvalid                       : 1;  /**< Reads 1 if at least one valid entry was read from EEPROM and written to a CSR. Write to
                                                          clear status. */
-	uint64_t cmd                          : 3;  /**< SPI commands; WREN(110), WRDI(100), READ(011), WRITE(010), RDSR(101), WRSR(001) */
+	uint64_t cmd                          : 3;  /**< SPI commands; WREN (110), WRDI (100), READ (011), WRITE (010), RDSR (101), WRSR (001) */
 	uint64_t adr                          : 9;  /**< EEPROM read/write address. */
 #else
 	uint64_t adr                          : 9;
@@ -3231,8 +3176,8 @@ typedef union cvmx_pemx_spi_ctl cvmx_pemx_spi_ctl_t;
 /**
  * cvmx_pem#_spi_data
  *
- * "PEM#_SPI read/write data register. Contains most recently read or written data and is
- * unpredictable upon power-up"
+ * This register contains the most recently read or written SPI data and is unpredictable upon
+ * power-up.
  */
 union cvmx_pemx_spi_data {
 	uint64_t u64;
@@ -3267,7 +3212,8 @@ union cvmx_pemx_strap {
 	struct cvmx_pemx_strap_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin */
+	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin. When set, lane swapping is performed to/from the
+                                                         SerDes. When clear, no lane swapping is performed. */
 	uint64_t reserved_0_2                 : 3;
 #else
 	uint64_t reserved_0_2                 : 3;
@@ -3289,9 +3235,15 @@ union cvmx_pemx_strap {
 	struct cvmx_pemx_strap_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin */
-	uint64_t pilanes8                     : 1;  /**< The value of the pi_select_8lanes pin */
-	uint64_t pimode                       : 2;  /**< The value of the pi_select_mode[1:0] pins */
+	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin. When set, lane swapping is performed to/from the
+                                                         SerDes. When clear, no lane swapping is performed. */
+	uint64_t pilanes8                     : 1;  /**< The value of the pi_select_8lanes pin. When set, the PEM is configured for a maximum of
+                                                         8-lanes, When clear, the PEM is configured for a maximum of 4-lanes. */
+	uint64_t pimode                       : 2;  /**< The value of the pi_select_mode[1:0] pins:
+                                                         0x0 = EP mode, Gen1 speed.
+                                                         0x1 = EP mode, Gen2 speed.
+                                                         0x2 = EP mode, Gen3 speed.
+                                                         0x3 = RC mode, defaults to Gen3 speed. */
 #else
 	uint64_t pimode                       : 2;
 	uint64_t pilanes8                     : 1;
@@ -3305,10 +3257,9 @@ typedef union cvmx_pemx_strap cvmx_pemx_strap_t;
 /**
  * cvmx_pem#_tlp_credits
  *
- * Specifies the number of credits the PEM for use in moving TLPs. When this register is written
- * the credit values are
- * reset to the register value. A write to this register should take place BEFORE traffic flow
- * starts.
+ * This register specifies the number of credits for use in moving TLPs. When this register is
+ * written, the credit values are reset to the register value. A write to this register should
+ * take place before traffic flow starts.
  */
 union cvmx_pemx_tlp_credits {
 	uint64_t u64;
@@ -3319,12 +3270,9 @@ union cvmx_pemx_tlp_credits {
                                                          The value in this register should not be changed.
                                                          Values other than 0x80 can lead to unpredictable
                                                          behavior */
-	uint64_t pem_cpl                      : 8;  /**< TLP 16B credits for Completion TLPs in the Peer.
-                                                         Legal values are 0x12 to 0x40. */
-	uint64_t pem_np                       : 8;  /**< TLP 16B credits for Non-Posted TLPs in the Peer.
-                                                         Legal values are 0x4 to 0x8. */
-	uint64_t pem_p                        : 8;  /**< TLP 16B credits for Posted TLPs in the Peer.
-                                                         Legal values are 0x12 to 0x40. */
+	uint64_t pem_cpl                      : 8;  /**< TLP 16B credits for completion TLPs in the peer. Legal values are 0x12 to 0x40. */
+	uint64_t pem_np                       : 8;  /**< TLP 16B credits for nonposted TLPs in the peer. Legal values are 0x4 to 0x8. */
+	uint64_t pem_p                        : 8;  /**< TLP 16B credits for posted TLPs in the peer. Legal values are 0x12 to 0x40. */
 	uint64_t sli_cpl                      : 8;  /**< TLP credits for Completion TLPs in the SLI.
                                                          Legal values are 0x24 to 0x80. */
 	uint64_t sli_np                       : 8;  /**< TLP credits for Non-Posted TLPs in the SLI.
@@ -3374,51 +3322,36 @@ union cvmx_pemx_tlp_credits {
 	struct cvmx_pemx_tlp_credits_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t pem_cpl                      : 8;  /**< TLP 16B credits for Completion TLPs in the Peer.
-                                                         Legal values are 0x12 to 0x40. */
-	uint64_t pem_np                       : 8;  /**< TLP 16B credits for Non-Posted TLPs in the Peer.
-                                                         Legal values are 0x4 to 0x8. */
-	uint64_t pem_p                        : 8;  /**< TLP 16B credits for Posted TLPs in the Peer.
-                                                         Legal values are 0x12 to 0x40. */
-	uint64_t sli_cpl                      : 8;  /**< TLP 8B credits for Completion TLPs in the SLI.
-                                                         Legal values are 0x24 to 0x80. When multiple PEMS
-                                                         are wire-OR'd together, the sum of all PEMs' SLI_CPL
-                                                         fields must not exceed 0x80. The reset value for this
-                                                         register is based on the pi_select_8lanes and the
-                                                         pi_select_mode straps. For EP mode PEMs, the 8lanes strap
-                                                         determines the credits reset value; 1'b0 = 4 lanes = 64
-                                                         credits, 1'b1 = 8 lanes = 128 credits. For RC mode PEMs,
-                                                         the credits are reset assuming a 4 lane configuration.
-                                                         SW can bump this value up in the case of 8 lane RC mode
-                                                         PEMS. SW may need to reprogram this register for performance
-                                                         reasons (configured as the only PEM, but as 4-lane - in
-                                                         this case, this PEM can take all of the credits). */
-	uint64_t sli_np                       : 8;  /**< TLP 8B credits for Non-Posted TLPs in the SLI.
-                                                         Legal values are 0x8 to 0x10. When multiple PEMS
-                                                         are wire-OR'd together, the sum of all PEMs' SLI_CPL
-                                                         fields must not exceed 0x80. The reset value for this
-                                                         register is based on the pi_select_8lanes and the
-                                                         pi_select_mode straps. For EP mode PEMs, the 8lanes strap
-                                                         determines the credits reset value; 1'b0 = 4 lanes = 8
-                                                         credits, 1'b1 = 8 lanes = 16 credits. For RC mode PEMs,
-                                                         the credits are reset assuming a 4 lane configuration.
-                                                         SW can bump this value up in the case of 8 lane RC mode
-                                                         PEMS. SW may need to reprogram this register for performance
-                                                         reasons (configured as the only PEM, but as 4-lane - in
-                                                         this case, this PEM can take all of the credits). */
-	uint64_t sli_p                        : 8;  /**< TLP 8B credits for Posted TLPs in the SLI.
-                                                         Legal values are 0x24 to 0x80. When multiple PEMS
-                                                         are wire-OR'd together, the sum of all PEMs' SLI_CPL
-                                                         fields must not exceed 0x80. The reset value for this
-                                                         register is based on the pi_select_8lanes and the
-                                                         pi_select_mode straps. For EP mode PEMs, the 8lanes strap
-                                                         determines the credits reset value; 1'b0 = 4 lanes = 64
-                                                         credits, 1'b1 = 8 lanes = 128 credits. For RC mode PEMs,
-                                                         the credits are reset assuming a 4 lane configuration.
-                                                         SW can bump this value up in the case of 8 lane RC mode
-                                                         PEMS. SW may need to reprogram this register for performance
-                                                         reasons (configured as the only PEM, but as 4-lane - in
-                                                         this case, this PEM can take all of the credits). */
+	uint64_t pem_cpl                      : 8;  /**< TLP 16B credits for completion TLPs in the peer. Legal values are 0x12 to 0x40. */
+	uint64_t pem_np                       : 8;  /**< TLP 16B credits for nonposted TLPs in the peer. Legal values are 0x4 to 0x8. */
+	uint64_t pem_p                        : 8;  /**< TLP 16B credits for posted TLPs in the peer. Legal values are 0x12 to 0x40. */
+	uint64_t sli_cpl                      : 8;  /**< TLP 8B credits for completion TLPs in the SLI. Legal values are 0x24 to 0x80. When
+                                                         multiple PEMs are wire-OR'd together, the sum of all PEMs' SLI_CPL fields must not exceed
+                                                         0x80. The reset value for this register is based on the pi_select_8lanes and the
+                                                         PCIE0/2_MODE<1:0> straps. For EP mode PEMs, the 8-lanes strap determines the credits reset
+                                                         value; 1'b0 = 4 lanes = 64 credits, 1'b1 = 8 lanes = 128 credits. For RC mode PEMs, the
+                                                         credits are reset assuming a 4-lane configuration. Software can bump this value up in the
+                                                         case of 8-lane RC mode PEMS. Software may need to reprogram this register for performance
+                                                         reasons (configured as the only PEM, but as 4-lane -- in this case, this PEM can take all
+                                                         of the credits). */
+	uint64_t sli_np                       : 8;  /**< TLP 8B credits for nonposted TLPs in the SLI. Legal values are 0x8 to 0x10. When multiple
+                                                         PEMS are wire-OR'd together, the sum of all PEMs' SLI_CPL fields must not exceed 0x80. The
+                                                         reset value for this register is based on the pi_select_8lanes and the pi_select_mode
+                                                         straps. For EP mode PEMs, the 8lanes strap determines the credits reset value; 1'b0 = 4
+                                                         lanes = 8 credits, 1'b1 = 8 lanes = 16 credits. For RC mode PEMs, the credits are reset
+                                                         assuming a 4 lane configuration. software can bump this value up in the case of 8 lane RC
+                                                         mode PEMS. software may need to reprogram this register for performance reasons
+                                                         (configured as the only PEM, but as 4-lane - in this case, this PEM can take all of the
+                                                         credits). */
+	uint64_t sli_p                        : 8;  /**< TLP 8B credits for Posted TLPs in the SLI. Legal values are 0x24 to 0x80. When multiple
+                                                         PEMs are wire-OR'd together, the sum of all PEMs' SLI_CPL fields must not exceed 0x80. The
+                                                         reset value for this register is based on the pi_select_8lanes and the PCIE0/2_MODE<1:0>
+                                                         straps. For EP mode PEMs, the 8-lanes strap determines the credits reset value; 1'b0 = 4
+                                                         lanes = 64 credits, 1'b1 = 8 lanes = 128 credits. For RC mode PEMs, the credits are reset
+                                                         assuming a 4-lane configuration. Software can bump this value up in the case of 8-lane RC
+                                                         mode PEMS. Software may need to reprogram this register for performance reasons
+                                                         (configured as the only PEM, but as 4-lane -- in this case, this PEM can take all of the
+                                                         credits). */
 #else
 	uint64_t sli_p                        : 8;
 	uint64_t sli_np                       : 8;
diff --git a/arch/mips/include/asm/octeon/cvmx-pip.h b/arch/mips/include/asm/octeon/cvmx-pip.h
index bc38770..0b1d321 100644
--- a/arch/mips/include/asm/octeon/cvmx-pip.h
+++ b/arch/mips/include/asm/octeon/cvmx-pip.h
@@ -42,7 +42,7 @@
  *
  * Interface to the hardware Packet Input Processing unit.
  *
- * <hr>$Revision: 82059 $<hr>
+ * <hr>$Revision: 94787 $<hr>
  */
 
 #ifndef __CVMX_PIP_H__
@@ -50,11 +50,9 @@
 
 #include "cvmx-wqe.h"
 #include "cvmx-fpa.h"
+#include "cvmx-pki.h"
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include "cvmx-pip-defs.h"
-#else
-#ifndef CVMX_DONT_INCLUDE_CONFIG
-#endif
 #endif
 
 #include "cvmx-helper.h"
@@ -174,14 +172,14 @@ typedef struct {
 	uint32_t packets;		/**< Number of packets processed by PIP */
 	uint32_t multicast_packets;
 					/**< Number of indentified L2 multicast packets.
-                                            Does not include broadcast packets.
-                                            Only includes packets whose parse mode is
-                                            SKIP_TO_L2 */
+					Does not include broadcast packets.
+					Only includes packets whose parse mode is
+					SKIP_TO_L2 */
 	uint32_t broadcast_packets;
 					/**< Number of indentified L2 broadcast packets.
-                                            Does not include multicast packets.
-                                            Only includes packets whose parse mode is
-                                            SKIP_TO_L2 */
+					Does not include multicast packets.
+					Only includes packets whose parse mode is
+					SKIP_TO_L2 */
 	uint32_t len_64_packets;	/**< Number of 64B packets */
 	uint32_t len_65_127_packets;
 					/**< Number of 65-127B packets */
@@ -209,42 +207,42 @@ typedef struct {
 	uint16_t inb_errors;		/**< Number of packets with GMX/SPX/PCI errors received by PIP */
 	uint32_t mcast_l2_red_packets;
 					/**< Number of packets with L2 Multicast DMAC
-                                             that were dropped due to RED.
-                                             The HW will consider a packet to be an L2
-                                             multicast packet when the least-significant bit
-                                             of the first byte of the DMAC is set and the
-                                             packet is not an L2 broadcast packet.
-                                             Only applies when the parse mode for the packets
-                                             is SKIP-TO-L2 */
+					that were dropped due to RED.
+					The HW will consider a packet to be an L2
+					multicast packet when the least-significant bit
+					of the first byte of the DMAC is set and the
+					packet is not an L2 broadcast packet.
+					Only applies when the parse mode for the packets
+					is SKIP-TO-L2 */
 	uint32_t bcast_l2_red_packets;
 					/**< Number of packets with L2 Broadcast DMAC
-                                             that were dropped due to RED.
-                                             The HW will consider a packet to be an L2
-                                             broadcast packet when the 48-bit DMAC is all 1's.
-                                             Only applies when the parse mode for the packets
-                                             is SKIP-TO-L2 */
+					that were dropped due to RED.
+					The HW will consider a packet to be an L2
+					broadcast packet when the 48-bit DMAC is all 1's.
+					Only applies when the parse mode for the packets
+					is SKIP-TO-L2 */
 	uint32_t mcast_l3_red_packets;
 					/**< Number of packets with L3 Multicast Dest Address
-                                             that were dropped due to RED.
-                                             The HW considers an IPv4 packet to be multicast
-                                             when the most-significant nibble of the 32-bit
-                                             destination address is 0xE (i.e it is a class D
-                                             address). The HW considers an IPv6 packet to be 
-                                             multicast when the most-significant byte of the
-                                             128-bit destination address is all 1's.
-                                             Only applies when the parse mode for the packets
-                                             is SKIP-TO-L2 and the packet is IP or the parse
-                                             mode for the packet is SKIP-TO-IP */
+					that were dropped due to RED.
+					The HW considers an IPv4 packet to be multicast
+					when the most-significant nibble of the 32-bit
+					destination address is 0xE (i.e it is a class D
+					address). The HW considers an IPv6 packet to be
+					multicast when the most-significant byte of the
+					128-bit destination address is all 1's.
+					Only applies when the parse mode for the packets
+					is SKIP-TO-L2 and the packet is IP or the parse
+					mode for the packet is SKIP-TO-IP */
 	uint32_t bcast_l3_red_packets;
 					/**< Number of packets with L3 Broadcast Dest Address
-                                             that were dropped due to RED.
-                                             The HW considers an IPv4 packet to be broadcast
-                                             when all bits are set in the MSB of the
-                                             destination address. IPv6 does not have the 
-                                             concept of a broadcast packets.
-                                             Only applies when the parse mode for the packet
-                                             is SKIP-TO-L2 and the packet is IP or the parse
-                                             mode for the packet is SKIP-TO-IP */
+					that were dropped due to RED.
+					The HW considers an IPv4 packet to be broadcast
+					when all bits are set in the MSB of the
+					destination address. IPv6 does not have the
+					concept of a broadcast packets.
+					Only applies when the parse mode for the packet
+					is SKIP-TO-L2 and the packet is IP or the parse
+					mode for the packet is SKIP-TO-IP */
 } cvmx_pip_port_status_t;
 
 /**
@@ -255,31 +253,31 @@ typedef union {
 	uint64_t u64;
 	struct {
 		uint64_t rawfull:1;			/**< Documented as R - Set if the Packet is RAWFULL. If set,
-                                                            this header must be the full 8 bytes */
+							this header must be the full 8 bytes */
 		uint64_t reserved0:5;			/**< Must be zero */
 		cvmx_pip_port_parse_mode_t parse_mode:2;
 							/**< PIP parse mode for this packet */
 		uint64_t reserved1:1;			/**< Must be zero */
 		uint64_t skip_len:7;			/**< Skip amount, including this header, to the beginning of the packet */
 		uint64_t grpext:2;			/**< These bits get concatenated with the
-                                                             PKT_INST_HDR[GRP] bits, creating a 6-bit
-                                                             GRP field. Added in pass2. */
+							PKT_INST_HDR[GRP] bits, creating a 6-bit
+							GRP field. Added in pass2. */
 		uint64_t nqos:1;			/**< Must be 0 when PKT_INST_HDR[R] = 0.
-                                                             When set to 1, NQOS prevents PIP from directly using
-                                                             PKT_INST_HDR[QOS] for the QOS value in WQE.
-                                                             When PIP_GBL_CTL[IHMSK_DIS] = 1, Octeon2 does not use NQOS */
+							When set to 1, NQOS prevents PIP from directly using
+							PKT_INST_HDR[QOS] for the QOS value in WQE.
+							When PIP_GBL_CTL[IHMSK_DIS] = 1, Octeon2 does not use NQOS */
 		uint64_t ngrp:1;			/**< Must be 0 when PKT_INST_HDR[R] = 0.
-                                                             When set to 1, NGPR prevents PIP from directly using
-                                                             PKT_INST_HDR[GPR] for the GPR value in WQE.
-                                                             When PIP_GBL_CTL[IHMSK_DIS] = 1, Octeon2 does not use NGRP */
+							When set to 1, NGPR prevents PIP from directly using
+							PKT_INST_HDR[GPR] for the GPR value in WQE.
+							When PIP_GBL_CTL[IHMSK_DIS] = 1, Octeon2 does not use NGRP */
 		uint64_t ntt:1;				/**< Must be 0 when PKT_INST_HDR[R] = 0.
-                                                             When set to 1, NTT prevents PIP from directly using
-                                                             PKT_INST_HDR[TT] for the TT value in WQE.
-                                                             When PIP_GBL_CTL[IHMSK_DIS] = 1, Octeon2 does not use NTT */
+							When set to 1, NTT prevents PIP from directly using
+							PKT_INST_HDR[TT] for the TT value in WQE.
+							When PIP_GBL_CTL[IHMSK_DIS] = 1, Octeon2 does not use NTT */
 		uint64_t ntag:1;			/**< Must be 0 when PKT_INST_HDR[R] = 0.
-                                                             When set to 1, NTAG prevents PIP from directly using
-                                                             PKT_INST_HDR[TAG] for the TAG value in WQE.
-                                                             When PIP_GBL_CTL[IHMSK_DIS] = 1, Octeon2 does not use NTAG */
+							When set to 1, NTAG prevents PIP from directly using
+							PKT_INST_HDR[TAG] for the TAG value in WQE.
+							When PIP_GBL_CTL[IHMSK_DIS] = 1, Octeon2 does not use NTAG */
 		uint64_t qos:3;				/**< POW input queue for this packet */
 		uint64_t grp:4;				/**< POW input group for this packet */
 		uint64_t rs:1;				/**< Flag to store this packet in the work queue entry, if possible */
@@ -300,6 +298,50 @@ typedef union {
  */
 static inline void cvmx_pip_config_port(uint64_t port_num, cvmx_pip_prt_cfgx_t port_cfg, cvmx_pip_prt_tagx_t port_tag_cfg)
 {
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		int node = cvmx_get_node_num();
+		struct cvmx_pki_port_config pki_prt_cfg;
+
+		cvmx_pki_get_port_config(node, port_num, &pki_prt_cfg);
+		if (port_cfg.s.ih_pri || port_cfg.s.pad_len || port_cfg.s.vlan_len)
+			cvmx_dprintf("Warning: 78xx: use different config for this option\n");
+		pki_prt_cfg.style_cfg.parm_cfg.minmax_sel = port_cfg.s.len_chk_sel;
+		pki_prt_cfg.style_cfg.parm_cfg.lenerr_en = port_cfg.s.lenerr_en;
+		pki_prt_cfg.style_cfg.parm_cfg.maxerr_en = port_cfg.s.maxerr_en;
+		pki_prt_cfg.style_cfg.parm_cfg.minerr_en = port_cfg.s.minerr_en;
+		if (port_cfg.s.grp_wat_47 || port_cfg.s.qos_wat_47)
+			cvmx_dprintf("Warning: 78xx use different method for grp and qos watchers\n");
+		pki_prt_cfg.style_cfg.parm_cfg.rawdrp = port_cfg.s.rawdrp;
+		pki_prt_cfg.style_cfg.tag_cfg.tag_fields.layer_c_src = port_tag_cfg.s.ip6_src_flag |
+				port_tag_cfg.s.ip4_src_flag;
+		pki_prt_cfg.style_cfg.tag_cfg.tag_fields.layer_c_dst = port_tag_cfg.s.ip6_dst_flag |
+				port_tag_cfg.s.ip4_dst_flag;
+		pki_prt_cfg.style_cfg.tag_cfg.tag_fields.ip_prot_nexthdr = port_tag_cfg.s.ip6_nxth_flag |
+				port_tag_cfg.s.ip4_pctl_flag;
+		pki_prt_cfg.style_cfg.tag_cfg.tag_fields.layer_d_src = port_tag_cfg.s.ip6_sprt_flag |
+				port_tag_cfg.s.ip4_sprt_flag;
+		pki_prt_cfg.style_cfg.tag_cfg.tag_fields.layer_d_dst = port_tag_cfg.s.ip6_dprt_flag |
+				port_tag_cfg.s.ip4_dprt_flag;
+		pki_prt_cfg.style_cfg.tag_cfg.tag_fields.input_port = port_tag_cfg.s.inc_prt_flag;
+		pki_prt_cfg.style_cfg.tag_cfg.tag_fields.first_vlan = port_tag_cfg.s.inc_vlan;
+		pki_prt_cfg.style_cfg.tag_cfg.tag_fields.second_vlan = port_tag_cfg.s.inc_vs;
+		if (port_tag_cfg.s.tcp6_tag_type || port_tag_cfg.s.tcp4_tag_type ||
+				 port_tag_cfg.s.ip6_tag_type || port_tag_cfg.s.ip4_tag_type)
+			cvmx_dprintf("Warning: 78xx use different method for tcp/ip tag type\n");
+		if (port_tag_cfg.s.grp)
+			cvmx_dprintf("Warning: 78xx use different method for sso group scheduling\n");
+		if (port_tag_cfg.s.portadd_en)
+			cvmx_dprintf("Warning: 78xx use different method for portadd_en\n");
+		if (port_cfg.s.mode == 0x1)
+			pki_prt_cfg.pkind_cfg.initial_parse_mode = CVMX_PKI_PARSE_LA_TO_LG;
+		else if (port_cfg.s.mode == 0x2)
+			pki_prt_cfg.pkind_cfg.initial_parse_mode = CVMX_PKI_PARSE_LC_TO_LG;
+		else
+			pki_prt_cfg.pkind_cfg.initial_parse_mode = CVMX_PKI_PARSE_NOTHING;
+
+		/* This is only for backward compatibility, not all the parameters are supported in 78xx */
+		cvmx_pki_config_port(node, port_num, &pki_prt_cfg);
+	}
 
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		int interface, index, pknd;
@@ -310,7 +352,6 @@ static inline void cvmx_pip_config_port(uint64_t port_num, cvmx_pip_prt_cfgx_t p
 
 		port_num = pknd;	/* overload port_num with pknd */
 	}
-
 	cvmx_write_csr(CVMX_PIP_PRT_CFGX(port_num), port_cfg.u64);
 	cvmx_write_csr(CVMX_PIP_PRT_TAGX(port_num), port_tag_cfg.u64);
 }
@@ -353,13 +394,13 @@ static inline void cvmx_pip_config_diffserv_qos(uint64_t diffserv, uint64_t qos)
 }
 
 /**
- * Get the status counters for a port.
+ * Get the status counters for a port for older non PKI chips.
  *
  * @param port_num Port number (ipd_port) to get statistics for.
  * @param clear    Set to 1 to clear the counters after they are read
  * @param status   Where to put the results.
  */
-static inline void cvmx_pip_get_port_status(uint64_t port_num, uint64_t clear, cvmx_pip_port_status_t * status)
+static inline void cvmx_pip_get_port_stats(uint64_t port_num, uint64_t clear, cvmx_pip_port_status_t *status)
 {
 	cvmx_pip_stat_ctl_t pip_stat_ctl;
 	cvmx_pip_stat0_prtx_t stat0;
@@ -483,6 +524,23 @@ static inline void cvmx_pip_get_port_status(uint64_t port_num, uint64_t clear, c
 }
 
 /**
+ * Get the status counters for a port.
+ *
+ * @param port_num Port number (ipd_port) to get statistics for.
+ * @param clear    Set to 1 to clear the counters after they are read
+ * @param status   Where to put the results.
+ */
+static inline void cvmx_pip_get_port_status(uint64_t port_num, uint64_t clear, cvmx_pip_port_status_t *status)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		unsigned int node = cvmx_get_node_num();
+		cvmx_pki_get_port_stats(node, port_num, (struct cvmx_pki_port_stats *)status);
+	} else {
+		cvmx_pip_get_port_stats(port_num, clear, status);
+	}
+}
+
+/**
  * Configure the hardware CRC engine
  *
  * @param interface Interface to configure (0 or 1)
@@ -572,18 +630,20 @@ static inline void cvmx_pip_set_frame_check(int interface, uint32_t max_size)
 	   PIP_PRT_CFG[len_chk_sel] selects which set of
 	   MAXLEN/MINLEN to use. */
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		cvmx_pip_prt_cfgx_t config;
-		int port;
-		int num_ports = cvmx_helper_ports_on_interface(interface);
-		for (port = 0; port < num_ports; port++) {
-			int pknd = cvmx_helper_get_pknd(interface, port);
-			int sel;
-
-			config.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(pknd));
-			sel = config.s.len_chk_sel;
-			frm_len.u64 = cvmx_read_csr(CVMX_PIP_FRM_LEN_CHKX(sel));
-			frm_len.s.maxlen = max_size;
-			cvmx_write_csr(CVMX_PIP_FRM_LEN_CHKX(sel), frm_len.u64);
+		if (!OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+			cvmx_pip_prt_cfgx_t config;
+			int port;
+			int num_ports = cvmx_helper_ports_on_interface(interface);
+			for (port = 0; port < num_ports; port++) {
+				int pknd = cvmx_helper_get_pknd(interface, port);
+				int sel;
+
+				config.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(pknd));
+				sel = config.s.len_chk_sel;
+				frm_len.u64 = cvmx_read_csr(CVMX_PIP_FRM_LEN_CHKX(sel));
+				frm_len.s.maxlen = max_size;
+				cvmx_write_csr(CVMX_PIP_FRM_LEN_CHKX(sel), frm_len.u64);
+			}
 		}
 	}
 	/* Update for each interface */
@@ -606,7 +666,7 @@ static inline void cvmx_pip_set_frame_check(int interface, uint32_t max_size)
 /**
  * Initialize Bit Select Extractor config. Their are 8 bit positions and valids
  * to be used when using the corresponding extractor.
- * 
+ *
  * @param bit     Bit Select Extractor to use
  * @param pos     Which position to update
  * @param val     The value to update the position with
@@ -668,10 +728,10 @@ static inline void cvmx_pip_set_bsel_pos(int bit, int pos, int val)
 /**
  * Initialize offset and skip values to use by bit select extractor.
 
- * @param bit     Bit Select Extractor to use
- * @param offset  Offset to add to extractor mem addr to get final address
-                  to lookup table.
- * @param skip    Number of bytes to skip from start of packet 0-64
+ * @param bit     	Bit Select Extractor to use
+ * @param offset	Offset to add to extractor mem addr to get final address
+ *			to lookup table.
+ * @param skip		Number of bytes to skip from start of packet 0-64
  */
 static inline void cvmx_pip_bsel_config(int bit, int offset, int skip)
 {
@@ -688,11 +748,11 @@ static inline void cvmx_pip_bsel_config(int bit, int offset, int skip)
 }
 
 /**
- * Get the entry for the Bit Select Extractor Table. 
+ * Get the entry for the Bit Select Extractor Table.
  * @param work   pointer to work queue entry
  * @return       Index of the Bit Select Extractor Table
  */
-static inline int cvmx_pip_get_bsel_table_index(cvmx_wqe_t * work)
+static inline int cvmx_pip_get_bsel_table_index(cvmx_wqe_t *work)
 {
 	int bit = cvmx_wqe_get_port(work) & 0x3;
 	/* Get the Bit select table index. */
@@ -756,7 +816,7 @@ static inline int cvmx_pip_get_bsel_table_index(cvmx_wqe_t * work)
 	return index;
 }
 
-static inline int cvmx_pip_get_bsel_qos(cvmx_wqe_t * work)
+static inline int cvmx_pip_get_bsel_qos(cvmx_wqe_t *work)
 {
 	int index = cvmx_pip_get_bsel_table_index(work);
 	cvmx_pip_bsel_tbl_entx_t bsel_tbl;
@@ -770,7 +830,7 @@ static inline int cvmx_pip_get_bsel_qos(cvmx_wqe_t * work)
 	return bsel_tbl.s.qos;
 }
 
-static inline int cvmx_pip_get_bsel_grp(cvmx_wqe_t * work)
+static inline int cvmx_pip_get_bsel_grp(cvmx_wqe_t *work)
 {
 	int index = cvmx_pip_get_bsel_table_index(work);
 	cvmx_pip_bsel_tbl_entx_t bsel_tbl;
@@ -784,7 +844,7 @@ static inline int cvmx_pip_get_bsel_grp(cvmx_wqe_t * work)
 	return bsel_tbl.s.grp;
 }
 
-static inline int cvmx_pip_get_bsel_tt(cvmx_wqe_t * work)
+static inline int cvmx_pip_get_bsel_tt(cvmx_wqe_t *work)
 {
 	int index = cvmx_pip_get_bsel_table_index(work);
 	cvmx_pip_bsel_tbl_entx_t bsel_tbl;
@@ -798,7 +858,7 @@ static inline int cvmx_pip_get_bsel_tt(cvmx_wqe_t * work)
 	return bsel_tbl.s.tt;
 }
 
-static inline int cvmx_pip_get_bsel_tag(cvmx_wqe_t * work)
+static inline int cvmx_pip_get_bsel_tag(cvmx_wqe_t *work)
 {
 	int index = cvmx_pip_get_bsel_table_index(work);
 	int port = cvmx_wqe_get_port(work);
@@ -818,7 +878,7 @@ static inline int cvmx_pip_get_bsel_tag(cvmx_wqe_t * work)
 	prt_tag.u64 = cvmx_read_csr(CVMX_PIP_PRT_TAGX(port));
 	if (prt_tag.s.inc_prt_flag == 0)
 		upper_tag = bsel_cfg.s.upper_tag;
-	return (bsel_tbl.s.tag | ((bsel_cfg.s.tag << 8) & 0xff00) | ((upper_tag << 16) & 0xffff0000));
+	return bsel_tbl.s.tag | ((bsel_cfg.s.tag << 8) & 0xff00) | ((upper_tag << 16) & 0xffff0000);
 }
 
 #ifdef	__cplusplus
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-cluster.h b/arch/mips/include/asm/octeon/cvmx-pki-cluster.h
index 66cd876..d18b38a 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-cluster.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-cluster.h
@@ -1,5 +1,5 @@
 /* This file is autgenerated from obj/ipemainc.elf */
-const int cvmx_pki_cluster_code_length = 632;
+const int cvmx_pki_cluster_code_length = 653;
 const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000000000a000000ull,
     0x0000413a68024070ull,
@@ -10,9 +10,9 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x00045fba46010000ull,
     0x9046898120002000ull,
     0x0004418068010028ull,
-    0x90665326680100f0ull,
+    0x90665300680100f0ull,
     0x0004413f68004070ull,
-    0x000653a7680100f0ull,
+    0x00065380680100f0ull,
     0x00045dbb6803a0f0ull,
     0x000401bb48000001ull,
     0x00045cb968030870ull,
@@ -37,6 +37,10 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x0004552a4e09312dull,
     0x00045cb968082868ull,
     0x0004410246090000ull,
+    0x0000813800800080ull,
+    0x000401a486000005ull,
+    0x000615ab74000123ull,
+    0x0007122448000004ull,
     0x0000813901000000ull,
     0x000481b800010001ull,
     0x000685b800020002ull,
@@ -62,8 +66,9 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x9000813901000000ull,
     0x0004c639ff000a00ull,
     0x0004400072010000ull,
-    0x00048181ffffffffull,
+    0x00048181ff00ff00ull,
     0x0007820101000100ull,
+    0x0006898100ff00ffull,
     0x00048301ffff0180ull,
     0x0008d5ab10001000ull,
     0x0004d4a900010001ull,
@@ -275,13 +280,14 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x00068581ffff0800ull,
     0x00068581ffff86ddull,
     0x0008d4a907c00200ull,
+    0x0009dcb97c007c00ull,
     0x0007823d00200020ull,
     0x000685bd00200020ull,
     0x0008d4a907c00140ull,
     0x0006010240000002ull,
-    0x8001c00000000000ull,
     0x0006593268020070ull,
-    0x000315ab74000227ull,
+    0x000042a486020000ull,
+    0x000a15ab74000124ull,
     0x9000813904000000ull,
     0x0001c00000000000ull,
     0x00048181f0004000ull,
@@ -290,20 +296,20 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x00068201ff000000ull,
     0xa40815ab74000345ull,
     0x0009debd01000100ull,
-    0x0009418068010038ull,
+    0xa429418068010038ull,
+    0x00095a3468010870ull,
     0x0009028386000005ull,
-    0xac8a15ab74000343ull,
-    0x000b5a3468010870ull,
+    0xac8a068186000014ull,
+    0x000a15ab74000343ull,
     0x000b5a3468010070ull,
     0xac6b8203000f0005ull,
     0x0009d4a907c00240ull,
-    0x000b820120000000ull,
-    0x000886011fff0000ull,
-    0x0009552a6801000dull,
+    0x000b82013fff0000ull,
+    0x0009d52a00010001ull,
     0x0009d4a9f8006800ull,
     0x0009593268020870ull,
     0x0006418068030230ull,
-    0x0006410242030000ull,
+    0x0006410240030000ull,
     0x9c01c00000000000ull,
     0x0001c00000000000ull,
     0x00078201f0006000ull,
@@ -331,6 +337,7 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000a593268020870ull,
     0x000ad52a00010001ull,
     0x000a5a3468010078ull,
+    0x000a410244010000ull,
     0x0007debd01000100ull,
     0x000481bd01000100ull,
     0x0006c639ff002300ull,
@@ -342,20 +349,20 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000082aa00010001ull,
     0x000a86ab00ff0045ull,
     0x000adcb978007800ull,
-    0x00008229fa006a00ull,
+    0x0000822902000200ull,
+    0x00088a3908000000ull,
     0x00065cb942080000ull,
     0x0006552a4e09312dull,
     0x00065cb968082868ull,
     0x0006410246090000ull,
-    0x8001c00000000000ull,
-    0x00088a3908000000ull,
-    0xa02315ab74000343ull,
+    0x000042a486020000ull,
+    0xa02a15ab74000343ull,
     0x000881b400ff0011ull,
     0x00068981ffff2118ull,
     0x0006593268020870ull,
     0x0006d4a9f8009800ull,
-    0x9c26debd02000200ull,
-    0x0007813400ff002full,
+    0xa026debd02000200ull,
+    0x0008813400ff002full,
     0x00048901ffff6558ull,
     0x0004593268020870ull,
     0x0004d4a9f800a800ull,
@@ -366,7 +373,7 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000a418368010878ull,
     0x000a400172030000ull,
     0x000a5bb768030078ull,
-    0x000a5b36680100f0ull,
+    0x000a5b00680100f0ull,
     0x0001c00000000000ull,
     0x0001c00000000000ull,
     0x0001c00000000000ull,
@@ -375,20 +382,20 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000a552a4e09312dull,
     0x000a5cb968082868ull,
     0x000a410246090000ull,
-    0x0000812907c004c0ull,
-    0x0004852907c00540ull,
+    0x00008129f8009800ull,
+    0x00048529f800a800ull,
     0x9004893910000000ull,
     0x0001c00000000000ull,
     0x00048181f0004000ull,
     0x988658b168020070ull,
     0x0006d428001f0008ull,
-    0x00068201ff000000ull,
-    0xa40815ab74000545ull,
-    0x0009debd04000400ull,
+    0xa4068201ff000000ull,
+    0x000815ab74000545ull,
     0x0009418068010038ull,
-    0x0009028384000004ull,
-    0xac8a15ab74000543ull,
-    0x000b5a3468010870ull,
+    0xa429028384000005ull,
+    0x0009debd04000400ull,
+    0xac8a068184000014ull,
+    0x000a15ab74000543ull,
     0x000b5a3468010070ull,
     0xac6b8303000f0005ull,
     0x000dd428001f0009ull,
@@ -398,13 +405,12 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000d58b168020870ull,
     0x000ddcb960006000ull,
     0x0006418068030230ull,
-    0x0006410242030000ull,
+    0x0006410240030000ull,
     0x9c01c00000000000ull,
     0x0001c00000000000ull,
     0x00078201f0006000ull,
-    0x000858b168020070ull,
-    0xa068d428001f000aull,
-    0x00085a3468010874ull,
+    0xa06858b168020070ull,
+    0x0008d428001f000aull,
     0x0008818100ff0000ull,
     0x000615ab74000545ull,
     0x00075a3468010078ull,
@@ -433,7 +439,7 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000641a868034840ull,
     0x0006403472030001ull,
     0x0004822902000200ull,
-    0x000815ab74000541ull,
+    0x000915ab74000541ull,
     0x000082ab00ff0045ull,
     0x000adcb960006000ull,
     0x0001c00000000000ull,
@@ -442,9 +448,8 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x0006552a4e09312dull,
     0x00065cb968082868ull,
     0x0006410246090000ull,
-    0x8001c00000000000ull,
-    0x0001c00000000000ull,
-    0x000315ab74000561ull,
+    0x000042a486020000ull,
+    0x000a15ab74000543ull,
     0x0000813920000000ull,
     0x000481b400ff006cull,
     0x0006d42803e001c0ull,
@@ -452,29 +457,37 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x0007823400ff0032ull,
     0xa048863400ff0033ull,
     0x0008d42803e00180ull,
-    0xa0685ab5680100f0ull,
+    0xa0685a80680100f0ull,
     0x000858b168020870ull,
-    0x00085dbb680100f0ull,
+    0x00085d80680100f0ull,
     0x986981b400ff002full,
     0x0006d42803e00280ull,
-    0x00065ab5680100f0ull,
+    0x00065a80680100f0ull,
     0x000658b168020870ull,
-    0x0004823400ff0011ull,
-    0x0008d42803e00220ull,
     0x000481b400ff0084ull,
-    0x0008863400ff0084ull,
     0x0006d42803e00240ull,
-    0x000481b400ff0006ull,
-    0x98c8863400ff0006ull,
+    0x0004823400ff0011ull,
+    0x0008d42803e00220ull,
+    0x98c481b400ff0006ull,
     0x0006d42803e00200ull,
-    0x90265ebd68010b31ull,
+    0x00065ebd68010b31ull,
+    0x000641806801003cull,
+    0x0006028386000005ull,
+    0x000a15ab74000661ull,
+    0x0006418068030230ull,
+    0x0008c180ffff0008ull,
+    0x0008863400ff0006ull,
+    0x0008418240030000ull,
+    0x000842a486030000ull,
+    0x000a15ab74000661ull,
+    0x9028863400ff0084ull,
     0x0004c639ff003000ull,
     0x0004403472010000ull,
-    0x000858b168020870ull,
+    0xa00858b168020870ull,
     0x00088181ffff0000ull,
+    0x00088281ffff0000ull,
     0x000615ab74000664ull,
-    0x0001c00000000000ull,
-    0x0001c00000000000ull,
+    0x000a15ab74000664ull,
     0x000081b800100010ull,
     0x00045cb942080000ull,
     0x0004552a4e09312dull,
@@ -483,10 +496,12 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000483891f000000ull,
     0x000f542868090a48ull,
     0x000f583068020070ull,
+    0x000042a486020000ull,
+    0x000a15ab74000661ull,
     0x000689b940004000ull,
     0x000689a803e00000ull,
     0x000641b168004078ull,
-    0x0006413842030000ull,
+    0x0006413840030000ull,
     0x9801c00000000000ull,
     0x9821c00000000000ull,
     0x00064180680100f0ull,
@@ -519,14 +534,15 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x0006898180008000ull,
     0x000652a56801001dull,
     0x000456ad68090b5bull,
-    0x000556ad680900f0ull,
-    0x0000562c680800f0ull,
+    0x00055680680900f0ull,
+    0x0005debd00400040ull,
+    0x00005600680800f0ull,
     0x0000833d00200020ull,
     0x000c872907c00000ull,
     0x000dd62c20000000ull,
     0x0000822902800280ull,
     0x000841b268034070ull,
-    0x000982a802800280ull,
+    0x000982a8000a000aull,
     0x000a41b168034070ull,
     0x000b822907c00000ull,
     0x0000003f70000800ull,
@@ -543,6 +559,7 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x000841bc68034078ull,
     0x000941bc68034070ull,
     0x000a583068030870ull,
+    0x0000813d00400000ull,
     0x0005c180ffff0000ull,
     0x00058288001e0000ull,
     0x000b8208001e0008ull,
@@ -585,20 +602,22 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0x00088a0900200020ull,
     0x0008413c68024078ull,
     0xa021c00000000000ull,
-    0x000c828901000100ull,
+    0x000c8b0900400040ull,
     0x0008dc01f0008000ull,
     0x000841b84c03ffffull,
-    0x000a823400ff0033ull,
-    0x000841bb4c03ffffull,
-    0x0008863400ff0014ull,
-    0x000841b54c03ffffull,
-    0x000c828900400040ull,
-    0x000a41b44c0300ffull,
+    0x000c8b2a00010000ull,
+    0x000c41b44c0300ffull,
     0x000682a9f800a800ull,
     0x000a86a9f8009800ull,
     0x000a8a8904000400ull,
     0x000a41b74c0300ffull,
     0x000a41b64c03ffffull,
+    0x0000828901000100ull,
+    0x000a822803e00180ull,
+    0x00088a3400ff0033ull,
+    0x000841bb4c03ffffull,
+    0x0008862803e00280ull,
+    0x000841b54c03ffffull,
     0x000682287c005800ull,
     0x00088a0902000200ull,
     0x0008413068024070ull,
@@ -609,28 +628,30 @@ const uint64_t cvmx_pki_cluster_code_default[] = {
     0xa861c00000000000ull,
     0x000a41814c03ffffull,
     0x000a41814c03ffffull,
-    0x000653a7680300f0ull,
+    0x00065380680300f0ull,
     0x000c5321680040b0ull,
     0x000dd3260fff0fffull,
+    0x0006810900800080ull,
     0x0000003f70000400ull,
-    0x0001c00000000000ull,
-    0x0001c00000000000ull,
     0x000082a902000200ull,
     0x000a413268024070ull,
     0xa50a822902800280ull,
-    0x0006828900800080ull,
-    0x00098301ffffffffull,
-    0xb12d8381f000e000ull,
+    0x0004893d08000800ull,
+    0xb1298301ffffffffull,
+    0x00098381f000e000ull,
+    0xa18c8b01ffffffffull,
+    0x000cd5ab80008000ull,
+    0x00088a01ff00ff00ull,
+    0x0008d5ab40004000ull,
     0x000ed5ab40004000ull,
-    0xa18c8381ffffffffull,
-    0x000a8abd08000800ull,
-    0x000e8781ff00ff00ull,
-    0x000ed5ab80008000ull,
-    0x000a8abd40000000ull,
-    0x0000572e680800f0ull,
-    0x000057af680900f0ull,
-    0x0007d72ef0ff0000ull,
+    0x0004893d40000000ull,
+    0x00005700680800f0ull,
+    0x00005780680900f0ull,
+    0x0007d72ef1ff0000ull,
     0x0007d7aff0000000ull,
-    0x000ad72e00fc0000ull,
-    0x0000000008000000ull
+    0x0004d72e00fc0000ull,
+    0x0000000008000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull,
+    0x0001c00000000000ull
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-defs.h b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
index dcdef0e..7062c55 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
@@ -526,6 +526,17 @@ static inline uint64_t CVMX_PKI_PFE_DIAG_FUNC(void)
 #define CVMX_PKI_PFE_DIAG (CVMX_ADD_IO_SEG(0x0001180044000560ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKI_PIX_CLKEN CVMX_PKI_PIX_CLKEN_FUNC()
+static inline uint64_t CVMX_PKI_PIX_CLKEN_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKI_PIX_CLKEN not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001180044000600ull);
+}
+#else
+#define CVMX_PKI_PIX_CLKEN (CVMX_ADD_IO_SEG(0x0001180044000600ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKI_PIX_DIAG CVMX_PKI_PIX_DIAG_FUNC()
 static inline uint64_t CVMX_PKI_PIX_DIAG_FUNC(void)
 {
@@ -1110,9 +1121,12 @@ union cvmx_pki_aurax_cfg {
                                                          WQE[BUFS]+1, else WQE[BUFS].
                                                          3 = WQE[LEN] (i.e. the packet length). */
 	uint64_t reserved_19_29               : 11;
-	uint64_t ena_red                      : 1;  /**< Enable RED drop between PASS and DROP levels. */
-	uint64_t ena_drop                     : 1;  /**< Enable tail drop when maximum DROP level exceeded. */
-	uint64_t ena_bp                       : 1;  /**< Enable asserting backpressure on BPID when maximum DROP level exceeded. */
+	uint64_t ena_red                      : 1;  /**< Enable RED drop between PASS and DROP levels. See also
+                                                         FPA_AURA(0..1023)_POOL_LEVELS[RED_ENA] and FPA_AURA(0..1023)_CNT_LEVELS[RED_ENA]. */
+	uint64_t ena_drop                     : 1;  /**< Enable tail drop when maximum DROP level exceeded. See also
+                                                         FPA_AURA(0..1023)_POOL_LEVELS[DROP] and FPA_AURA(0..1023)_CNT_LEVELS[DROP]. */
+	uint64_t ena_bp                       : 1;  /**< Enable asserting backpressure on BPID when maximum DROP level exceeded. See also
+                                                         FPA_AURA(0..1023)_POOL_LEVELS[RED_ENA] and FPA_AURA(0..1023)_CNT_LEVELS[RED_ENA]. */
 	uint64_t reserved_10_15               : 6;
 	uint64_t bpid                         : 10; /**< Bpid to assert backpressure on. */
 #else
@@ -1140,14 +1154,13 @@ union cvmx_pki_bist_status0 {
 	uint64_t u64;
 	struct cvmx_pki_bist_status0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_33_63               : 31;
-	uint64_t bist                         : 33; /**< BIST results. Hardware sets a bit in BIST for memory that fails BIST. INTERNAL: This
+	uint64_t reserved_31_63               : 33;
+	uint64_t bist                         : 31; /**< BIST results. Hardware sets a bit in BIST for memory that fails BIST. INTERNAL: This
                                                          register collects status for PKI_PFE.
-                                                         <32> - INB_ERRS
-                                                         <31> - INB OCTS
-                                                         <30> - INB PKTS
-                                                         <29> - LD FIF
-                                                         <28..27> - RD FIF
+                                                         <30> - INB_ERRS
+                                                         <29> - INB OCTS
+                                                         <28> - INB PKTS
+                                                         <27> - LD FIF
                                                          <26> - PBE STATE
                                                          <25> - WADR STATE
                                                          <24> - NXT PTAG
@@ -1158,8 +1171,8 @@ union cvmx_pki_bist_status0 {
                                                          <19..16> - KMEM
                                                          <15..0> - ASM BUFF */
 #else
-	uint64_t bist                         : 33;
-	uint64_t reserved_33_63               : 31;
+	uint64_t bist                         : 31;
+	uint64_t reserved_31_63               : 33;
 #endif
 	} s;
 	struct cvmx_pki_bist_status0_s        cn78xx;
@@ -1176,12 +1189,30 @@ union cvmx_pki_bist_status1 {
 	uint64_t u64;
 	struct cvmx_pki_bist_status1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_20_63               : 44;
-	uint64_t bist                         : 20; /**< BIST results. Hardware sets a bit in BIST for memory that fails BIST. INTERNAL: This
-                                                         register collects status for PKI_PBE. */
-#else
-	uint64_t bist                         : 20;
-	uint64_t reserved_20_63               : 44;
+	uint64_t reserved_21_63               : 43;
+	uint64_t bist                         : 21; /**< BIST results. Hardware sets a bit in BIST for memory that fails BIST. INTERNAL: This
+                                                         register collects status for PKI_PBE.
+                                                         <20>: STATS_MEM0
+                                                         <19>: STATS_MEM1
+                                                         <18>: STATS_MEM2
+                                                         <17>: STATS_MEM3
+                                                         <16>: SWS
+                                                         <15>: WQEOUT
+                                                         <14>: DOA
+                                                         <13>: BPID
+                                                         <12:10>: Reserved
+                                                         <9>: PLC
+                                                         <8>: PKTWQ
+                                                         <7:6>: Reserved
+                                                         <5>: TAG
+                                                         <4>: AURA
+                                                         <3>: CHAN
+                                                         <2>: PBTAG
+                                                         <1>: STYLEWQ
+                                                         <0>: QPG */
+#else
+	uint64_t bist                         : 21;
+	uint64_t reserved_21_63               : 43;
 #endif
 	} s;
 	struct cvmx_pki_bist_status1_s        cn78xx;
@@ -1325,7 +1356,8 @@ union cvmx_pki_clx_ecc_ctl {
 	uint64_t u64;
 	struct cvmx_pki_clx_ecc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_24_63               : 40;
+	uint64_t pcam_en                      : 1;  /**< PCAM ECC checking enable. INTERNAL: This enables the PCAM scrubber. */
+	uint64_t reserved_24_62               : 39;
 	uint64_t pcam1_flip                   : 2;  /**< PCAM1 flip syndrome bits on write. */
 	uint64_t pcam0_flip                   : 2;  /**< PCAM  flip syndrome bits on write. */
 	uint64_t smem_flip                    : 2;  /**< SMEM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram to
@@ -1350,7 +1382,8 @@ union cvmx_pki_clx_ecc_ctl {
 	uint64_t smem_flip                    : 2;
 	uint64_t pcam0_flip                   : 2;
 	uint64_t pcam1_flip                   : 2;
-	uint64_t reserved_24_63               : 40;
+	uint64_t reserved_24_62               : 39;
+	uint64_t pcam_en                      : 1;
 #endif
 	} s;
 	struct cvmx_pki_clx_ecc_ctl_s         cn78xx;
@@ -1397,17 +1430,20 @@ union cvmx_pki_clx_int {
 	struct cvmx_pki_clx_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t trapz                        : 1;  /**< PCAM sequencer trapz interrupt. Throws PKI_INTSN_E::PKI_CL(0..3)_INT_TRAPZ. INTERNAL:
-                                                         Caused by TRAP sequence state, may indicate PKI enabled without proper sequencer code
-                                                         loaded in PKI_IMEM(0..2047). */
+	uint64_t trapz                        : 1;  /**< Reserved. INTERNAL: Deprecated. PCAM sequencer trapz interrupt. Throws
+                                                         PKI_INTSN_E::PKI_CL(0..3)_INT_TRAPZ. Caused by TRAP sequence state, may indicate PKI
+                                                         enabled without proper sequencer code loaded in PKI_IMEM(0..2047). Based on PCAM sequencer
+                                                         execution, will likely throw an additional IPTINT interrupt. */
 	uint64_t iptint                       : 1;  /**< PCAM sequencer debug interrupt. Throws PKI_INTSN_E::PKI_CL(0..3)_INT_IPTINT. INTERNAL:
                                                          Caused by TRAP or INTR sequence state. */
 	uint64_t sched_conf                   : 1;  /**< PCAM/SMEM internal port conflict. Internal error, should not occur. Throws
                                                          PKI_INTSN_E::PKI_CL(0..3)_INT_SCHED_CONF. INTERNAL: Sequencer mis-scheduled PCAM or SMEM
                                                          ops with overlapping accesses. */
-	uint64_t pcam_conf                    : 2;  /**< PCAM(0..1) match hit multiple rows, indicating a programming error in
-                                                         PKI_CL(0..3)_PCAM(0..1)_MATCH(0..191) or related registers. Throws
-                                                         PKI_INTSN_E::PKI_CL(0..3)_INT_PCAM_CONF(0..1). */
+	uint64_t pcam_conf                    : 2;  /**< PCAM(0..1) match hit multiple rows, indicating either a soft error in the PCAM or a
+                                                         programming error in PKI_CL(0..3)_PCAM(0..1)_MATCH(0..191) or related registers. Throws
+                                                         PKI_INTSN_E::PKI_CL(0..3)_INT_PCAM_CONF(0..1). Once a conflict is detected, the PCAM state
+                                                         is unpredictable and is required to be fully reconfigured before further valid processing
+                                                         can take place. */
 #else
 	uint64_t pcam_conf                    : 2;
 	uint64_t sched_conf                   : 1;
@@ -2022,28 +2058,28 @@ union cvmx_pki_ecc_ctl0 {
 	struct cvmx_pki_ecc_ctl0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_24_63               : 40;
-	uint64_t ldfif_flip                   : 2;  /**< LDFIF RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram
+	uint64_t ldfif_flip                   : 2;  /**< LDFIF RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the LDFIF ram
                                                          to test single-bit or double-bit error handling. */
 	uint64_t ldfif_cdis                   : 1;  /**< LDFIF RAM ECC correction disable. */
-	uint64_t rdfif_flip                   : 2;  /**< RDFIF RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram
-                                                         to test single-bit or double-bit error handling. */
-	uint64_t rdfif_cdis                   : 1;  /**< RDFIF RAM ECC correction disable. */
-	uint64_t wadr_flip                    : 2;  /**< WADR RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram
+	uint64_t pbe_flip                     : 2;  /**< PBE state RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the PBE
+                                                         ram to test single-bit or double-bit error handling. */
+	uint64_t pbe_cdis                     : 1;  /**< PBE state RAM ECC correction disable. */
+	uint64_t wadr_flip                    : 2;  /**< WADR RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the WADR ram
                                                          to test single-bit or double-bit error handling. */
 	uint64_t wadr_cdis                    : 1;  /**< WADR RAM ECC correction disable. */
-	uint64_t nxtptag_flip                 : 2;  /**< NXTPTAG RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM
+	uint64_t nxtptag_flip                 : 2;  /**< NXTPTAG RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the NXTPTAG
                                                          ram to test single-bit or double-bit error handling. */
 	uint64_t nxtptag_cdis                 : 1;  /**< NXTPTAG RAM ECC correction disable. */
-	uint64_t curptag_flip                 : 2;  /**< CURPTAG RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM
+	uint64_t curptag_flip                 : 2;  /**< CURPTAG RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the CURPTAG
                                                          ram to test single-bit or double-bit error handling. */
 	uint64_t curptag_cdis                 : 1;  /**< CURPTAG RAM ECC correction disable. */
-	uint64_t nxtblk_flip                  : 2;  /**< NXTBLK RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram
-                                                         to test single-bit or double-bit error handling. */
+	uint64_t nxtblk_flip                  : 2;  /**< NXTBLK RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the NXTBLK
+                                                         ram to test single-bit or double-bit error handling. */
 	uint64_t nxtblk_cdis                  : 1;  /**< NXTBLK RAM ECC correction disable. */
 	uint64_t kmem_flip                    : 2;  /**< KMEM RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram
                                                          to test single-bit or double-bit error handling. */
 	uint64_t kmem_cdis                    : 1;  /**< KMEM RAM ECC correction disable. */
-	uint64_t asm_flip                     : 2;  /**< ASM RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the KMEM ram to
+	uint64_t asm_flip                     : 2;  /**< ASM RAM flip syndrome bits on write. Flip syndrome bits <1:0> on writes to the ASM ram to
                                                          test single-bit or double-bit error handling. */
 	uint64_t asm_cdis                     : 1;  /**< ASM RAM ECC correction disable. */
 #else
@@ -2059,8 +2095,8 @@ union cvmx_pki_ecc_ctl0 {
 	uint64_t nxtptag_flip                 : 2;
 	uint64_t wadr_cdis                    : 1;
 	uint64_t wadr_flip                    : 2;
-	uint64_t rdfif_cdis                   : 1;
-	uint64_t rdfif_flip                   : 2;
+	uint64_t pbe_cdis                     : 1;
+	uint64_t pbe_flip                     : 2;
 	uint64_t ldfif_cdis                   : 1;
 	uint64_t ldfif_flip                   : 2;
 	uint64_t reserved_24_63               : 40;
@@ -2080,7 +2116,18 @@ union cvmx_pki_ecc_ctl1 {
 	uint64_t u64;
 	struct cvmx_pki_ecc_ctl1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_27_63               : 37;
+	uint64_t reserved_51_63               : 13;
+	uint64_t sws_flip                     : 2;  /**< SWS flip syndrome bits on write. */
+	uint64_t sws_cdis                     : 1;  /**< SWS ECC correction disable. */
+	uint64_t wqeout_flip                  : 2;  /**< WQEOUT flip syndrome bits on write. */
+	uint64_t wqeout_cdis                  : 1;  /**< WQEOUT ECC correction disable. */
+	uint64_t doa_flip                     : 2;  /**< DOA flip syndrome bits on write. */
+	uint64_t doa_cdis                     : 1;  /**< DOA ECC correction disable. */
+	uint64_t bpid_flip                    : 2;  /**< BPID flip syndrome bits on write. */
+	uint64_t bpid_cdis                    : 1;  /**< BPID ECC correction disable. */
+	uint64_t reserved_30_38               : 9;
+	uint64_t plc_flip                     : 2;  /**< PLC flip syndrome bits on write. */
+	uint64_t plc_cdis                     : 1;  /**< PLC ECC correction disable. */
 	uint64_t pktwq_flip                   : 2;  /**< PKTWQ flip syndrome bits on write. */
 	uint64_t pktwq_cdis                   : 1;  /**< PKTWQ ECC correction disable. */
 	uint64_t reserved_18_23               : 6;
@@ -2112,7 +2159,18 @@ union cvmx_pki_ecc_ctl1 {
 	uint64_t reserved_18_23               : 6;
 	uint64_t pktwq_cdis                   : 1;
 	uint64_t pktwq_flip                   : 2;
-	uint64_t reserved_27_63               : 37;
+	uint64_t plc_cdis                     : 1;
+	uint64_t plc_flip                     : 2;
+	uint64_t reserved_30_38               : 9;
+	uint64_t bpid_cdis                    : 1;
+	uint64_t bpid_flip                    : 2;
+	uint64_t doa_cdis                     : 1;
+	uint64_t doa_flip                     : 2;
+	uint64_t wqeout_cdis                  : 1;
+	uint64_t wqeout_flip                  : 2;
+	uint64_t sws_cdis                     : 1;
+	uint64_t sws_flip                     : 2;
+	uint64_t reserved_51_63               : 13;
 #endif
 	} s;
 	struct cvmx_pki_ecc_ctl1_s            cn78xx;
@@ -2153,8 +2211,8 @@ union cvmx_pki_ecc_int0 {
 	uint64_t reserved_16_63               : 48;
 	uint64_t ldfif_dbe                    : 1;  /**< LDFIF ECC double bit error. Throws PKI_INTSN_E::PKI_ECC0_LDFIF_DBE. */
 	uint64_t ldfif_sbe                    : 1;  /**< LDFIF ECC single bit error. Throws PKI_INTSN_E::PKI_ECC0_LDFIF_SBE. */
-	uint64_t rdfif_dbe                    : 1;  /**< RDFIF ECC double bit error. Throws PKI_INTSN_E::PKI_ECC0_RDFIF_DBE. */
-	uint64_t rdfif_sbe                    : 1;  /**< RDFIF ECC single bit error. Throws PKI_INTSN_E::PKI_ECC0_RDFIF_SBE. */
+	uint64_t pbe_dbe                      : 1;  /**< PBE ECC double bit error. Throws PKI_INTSN_E::PKI_ECC0_PBE_DBE. */
+	uint64_t pbe_sbe                      : 1;  /**< PBE ECC single bit error. Throws PKI_INTSN_E::PKI_ECC0_PBE_SBE. */
 	uint64_t wadr_dbe                     : 1;  /**< WADR ECC double bit error. Throws PKI_INTSN_E::PKI_ECC0_WADR_DBE. */
 	uint64_t wadr_sbe                     : 1;  /**< WADR ECC single bit error. Throws PKI_INTSN_E::PKI_ECC0_WADR_SBE. */
 	uint64_t nxtptag_dbe                  : 1;  /**< NXTPTAG ECC double bit error. Throws PKI_INTSN_E::PKI_ECC0_NXTPTAG_DBE. */
@@ -2180,8 +2238,8 @@ union cvmx_pki_ecc_int0 {
 	uint64_t nxtptag_dbe                  : 1;
 	uint64_t wadr_sbe                     : 1;
 	uint64_t wadr_dbe                     : 1;
-	uint64_t rdfif_sbe                    : 1;
-	uint64_t rdfif_dbe                    : 1;
+	uint64_t pbe_sbe                      : 1;
+	uint64_t pbe_dbe                      : 1;
 	uint64_t ldfif_sbe                    : 1;
 	uint64_t ldfif_dbe                    : 1;
 	uint64_t reserved_16_63               : 48;
@@ -2198,7 +2256,18 @@ union cvmx_pki_ecc_int1 {
 	uint64_t u64;
 	struct cvmx_pki_ecc_int1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_18_63               : 46;
+	uint64_t reserved_34_63               : 30;
+	uint64_t sws_dbe                      : 1;  /**< PLC ECC double bit error. Throws PKI_INTSN_E::PKI_ECC1_SWS_DBE. */
+	uint64_t sws_sbe                      : 1;  /**< PLC ECC single bit error. Throws PKI_INTSN_E::PKI_ECC1_SWS_SBE. */
+	uint64_t wqeout_dbe                   : 1;  /**< PLC ECC double bit error. Throws PKI_INTSN_E::PKI_ECC1_WQEOUT_DBE. */
+	uint64_t wqeout_sbe                   : 1;  /**< PLC ECC single bit error. Throws PKI_INTSN_E::PKI_ECC1_WQEOUT_SBE. */
+	uint64_t doa_dbe                      : 1;  /**< PLC ECC double bit error. Throws PKI_INTSN_E::PKI_ECC1_DOA_DBE. */
+	uint64_t doa_sbe                      : 1;  /**< PLC ECC single bit error. Throws PKI_INTSN_E::PKI_ECC1_DOA_SBE. */
+	uint64_t bpid_dbe                     : 1;  /**< PLC ECC double bit error. Throws PKI_INTSN_E::PKI_ECC1_BPID_DBE. */
+	uint64_t bpid_sbe                     : 1;  /**< PLC ECC single bit error. Throws PKI_INTSN_E::PKI_ECC1_BPID_SBE. */
+	uint64_t reserved_20_25               : 6;
+	uint64_t plc_dbe                      : 1;  /**< PLC ECC double bit error. Throws PKI_INTSN_E::PKI_ECC1_PLC_DBE. */
+	uint64_t plc_sbe                      : 1;  /**< PLC ECC single bit error. Throws PKI_INTSN_E::PKI_ECC1_PLC_SBE. */
 	uint64_t pktwq_dbe                    : 1;  /**< PKTWQ ECC double bit error. Throws PKI_INTSN_E::PKI_ECC1_PKTWQ_DBE. */
 	uint64_t pktwq_sbe                    : 1;  /**< PKTWQ ECC single bit error. Throws PKI_INTSN_E::PKI_ECC1_PKTWQ_SBE. */
 	uint64_t reserved_12_15               : 4;
@@ -2230,7 +2299,18 @@ union cvmx_pki_ecc_int1 {
 	uint64_t reserved_12_15               : 4;
 	uint64_t pktwq_sbe                    : 1;
 	uint64_t pktwq_dbe                    : 1;
-	uint64_t reserved_18_63               : 46;
+	uint64_t plc_sbe                      : 1;
+	uint64_t plc_dbe                      : 1;
+	uint64_t reserved_20_25               : 6;
+	uint64_t bpid_sbe                     : 1;
+	uint64_t bpid_dbe                     : 1;
+	uint64_t doa_sbe                      : 1;
+	uint64_t doa_dbe                      : 1;
+	uint64_t wqeout_sbe                   : 1;
+	uint64_t wqeout_dbe                   : 1;
+	uint64_t sws_sbe                      : 1;
+	uint64_t sws_dbe                      : 1;
+	uint64_t reserved_34_63               : 30;
 #endif
 	} s;
 	struct cvmx_pki_ecc_int1_s            cn78xx;
@@ -2370,12 +2450,7 @@ union cvmx_pki_gen_int {
 	uint64_t bckprs                       : 1;  /**< PKI asserted backpressure. Set when PKI was unable to accept the next valid data from
                                                          BGX/DPI/ILK etc. over X2P due to all internal resources being used up, and PKI will
                                                          backpressure X2P. Throws PKI_INTSN_E::PKI_GEN_BCKPRS. */
-	uint64_t crcerr                       : 1;  /**< PKI calculated bad CRC. If the packet arrived via a BGX interface, the packet had an FCS
-                                                         error. If the packet arrived via PKO internal loopback, the packet had one or more parity
-                                                         errors. Not applicable when the packet arrived via the DPI interface. For ILK interfaces,
-                                                         the following ILK errors can cause packets to terminate with this error code:
-                                                         SERDES_LOCK_LOSS, BDRY_SYNC_LOSS, SCRM_SYNC_LOSS, LANE_ALIGN_FAIL, DESKEW_FIFO_OVFL,
-                                                         CRC24_ERR, UKWN_CNTL_WORD, and BAD_64B67B. Throws PKI_INTSN_E::PKI_GEN_CRCERR. */
+	uint64_t crcerr                       : 1;  /**< PKI calculated bad CRC in the L2 frame. Throws PKI_INTSN_E::PKI_GEN_CRCERR. */
 	uint64_t pktdrp                       : 1;  /**< Packet dropped due to QOS. If the QOS algorithm decides to drop a packet, PKI asserts this
                                                          interrupt. Throws PKI_INTSN_E::PKI_GEN_PKTDRP. */
 #else
@@ -2528,8 +2603,9 @@ union cvmx_pki_pcam_result {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_41_63               : 23;
 	uint64_t match                        : 1;  /**< Resulting match. */
-	uint64_t entry                        : 8;  /**< Resulting matching entry number, unpredictable unless [MATCH] set. */
-	uint64_t result                       : 32; /**< Resulting data from matching line's PKI_CL(0..3)_PCAM(0..1)_ACTION(0..191), or zero if no match. */
+	uint64_t entry                        : 8;  /**< Resulting matching entry number, unpredictable unless [MATCH] set and [CONFLICT] is clear. */
+	uint64_t result                       : 32; /**< Resulting data from matching line's PKI_CL(0..3)_PCAM(0..1)_ACTION(0..191), or zero if no
+                                                         match. Unpredictable unless [CONFLICT] is clear. */
 #else
 	uint64_t result                       : 32;
 	uint64_t entry                        : 8;
@@ -2540,11 +2616,12 @@ union cvmx_pki_pcam_result {
 	struct cvmx_pki_pcam_result_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t conflict                     : 1;  /**< Conflict. The lookup resulted in multiple entries matching PKI_PCAM_LOOKUP[DATA], [TERM]
-                                                         and [STYLE], or zero if no match. */
+                                                         and [STYLE], or zero if no conflict. */
 	uint64_t reserved_41_62               : 22;
 	uint64_t match                        : 1;  /**< Resulting match. */
-	uint64_t entry                        : 8;  /**< Resulting matching entry number, unpredictable unless [MATCH] set. */
-	uint64_t result                       : 32; /**< Resulting data from matching line's PKI_CL(0..3)_PCAM(0..1)_ACTION(0..191), or zero if no match. */
+	uint64_t entry                        : 8;  /**< Resulting matching entry number, unpredictable unless [MATCH] set and [CONFLICT] is clear. */
+	uint64_t result                       : 32; /**< Resulting data from matching line's PKI_CL(0..3)_PCAM(0..1)_ACTION(0..191), or zero if no
+                                                         match. Unpredictable unless [CONFLICT] is clear. */
 #else
 	uint64_t result                       : 32;
 	uint64_t entry                        : 8;
@@ -2575,6 +2652,28 @@ union cvmx_pki_pfe_diag {
 typedef union cvmx_pki_pfe_diag cvmx_pki_pfe_diag_t;
 
 /**
+ * cvmx_pki_pix_clken
+ */
+union cvmx_pki_pix_clken {
+	uint64_t u64;
+	struct cvmx_pki_pix_clken_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_17_63               : 47;
+	uint64_t mech                         : 1;  /**< When set, force the conditional clocks on for mech. */
+	uint64_t reserved_4_15                : 12;
+	uint64_t cls                          : 4;  /**< When set, force the conditional clocks on for this cluster. */
+#else
+	uint64_t cls                          : 4;
+	uint64_t reserved_4_15                : 12;
+	uint64_t mech                         : 1;
+	uint64_t reserved_17_63               : 47;
+#endif
+	} s;
+	struct cvmx_pki_pix_clken_s           cn78xx;
+};
+typedef union cvmx_pki_pix_clken cvmx_pki_pix_clken_t;
+
+/**
  * cvmx_pki_pix_diag
  */
 union cvmx_pki_pix_diag {
@@ -3048,8 +3147,8 @@ union cvmx_pki_statx_stat13 {
 	struct cvmx_pki_statx_stat13_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t spec                         : 48; /**< Number of packets, dropped or non-dropped, with special handling. For profiling and
-                                                         diagnostic use only.
+	uint64_t spec                         : 48; /**< Number of non-dropped packets with special handling. For profiling and diagnostic use
+                                                         only.
                                                          INTERNAL: Counts packets completing IPE processing with WQE[SH] set. */
 #else
 	uint64_t spec                         : 48;
@@ -3068,8 +3167,8 @@ union cvmx_pki_statx_stat14 {
 	struct cvmx_pki_statx_stat14_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t drp_bcast                    : 48; /**< Number of packets with L2 broadcast DMAC that were dropped due to RED or buffer
-                                                         exhaustion. See WQE[L2B] for the definition of L2 broadcast. */
+	uint64_t drp_bcast                    : 48; /**< Number of packets with L2 broadcast DMAC that were dropped by RED, buffer exhaustion, or
+                                                         PKI_CL(0..3)_STYLE(0..63)_CFG[DROP]. See WQE[L2B] for the definition of L2 broadcast. */
 #else
 	uint64_t drp_bcast                    : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3087,8 +3186,8 @@ union cvmx_pki_statx_stat15 {
 	struct cvmx_pki_statx_stat15_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t drp_mcast                    : 48; /**< Number of packets with L2 multicast DMAC that were dropped due to RED or buffer
-                                                         exhaustion. See WQE[L2M] for the definition of L2 multicast. */
+	uint64_t drp_mcast                    : 48; /**< Number of packets with L2 multicast DMAC that were dropped by RED, buffer exhaustion, or
+                                                         PKI_CL(0..3)_STYLE(0..63)_CFG[DROP]. See WQE[L2M] for the definition of L2 multicast. */
 #else
 	uint64_t drp_mcast                    : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3181,7 +3280,7 @@ union cvmx_pki_statx_stat3 {
 	struct cvmx_pki_statx_stat3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t drp_pkts                     : 48; /**< Inbound packets dropped by RED or buffer exhaustion. */
+	uint64_t drp_pkts                     : 48; /**< Inbound packets dropped by RED, buffer exhaustion, or PKI_CL(0..3)_STYLE(0..63)_CFG[DROP]. */
 #else
 	uint64_t drp_pkts                     : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3199,7 +3298,7 @@ union cvmx_pki_statx_stat4 {
 	struct cvmx_pki_statx_stat4_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t drp_octs                     : 48; /**< Inbound octets dropped by RED or buffer exhaustion. */
+	uint64_t drp_octs                     : 48; /**< Inbound octets dropped by RED, buffer exhaustion, or PKI_CL(0..3)_STYLE(0..63)_CFG[DROP]. */
 #else
 	uint64_t drp_octs                     : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3350,11 +3449,11 @@ union cvmx_pki_stylex_buf {
 	uint64_t first_skip                   : 6;  /**< The number of eight-byte words from the top of the first MBUF that the PKI stores the next
                                                          pointer. If [DIS_WQ_DAT]=1, any value is legal. If [DIS_WQ_DAT]=0, legal values must
                                                          satisfy:
-                                                         FIRST_SKIP <= PKI_STYLE(0..63)_BUF[MB_SIZE] - 18.
-                                                         FIRST_SKIP must be at least 0x4, but 0x5 is recommended minimum. 0x4 will drop WQE WORD4,
-                                                         for use in backward compatible applications.
-                                                         WQE_SKIP * (128/8) + 4 <= FIRST_SKIP, to insure the minimum of four work-queue entry words
-                                                         will fit within FIRST_SKIP. */
+                                                         * FIRST_SKIP <= PKI_STYLE(0..63)_BUF[MB_SIZE] - 18.
+                                                         * FIRST_SKIP must be at least 0x4, but 0x5 is recommended minimum. 0x4 will drop WQE
+                                                         WORD4, for use in backward compatible applications.
+                                                         * WQE_SKIP * (128/8) + 4 <= FIRST_SKIP, to insure the minimum of four work-queue entry
+                                                         words will fit within FIRST_SKIP. */
 	uint64_t later_skip                   : 6;  /**< The number of eight-byte words from the top of any MBUF that is not the first MBUF that
                                                          PKI writes the next-pointer to. Legal values are 0 to PKI_STYLE(0..63)_BUF[MB_SIZE] - 18. */
 	uint64_t opc_mode                     : 2;  /**< Select the style of write to the L2C.
@@ -3372,9 +3471,9 @@ union cvmx_pki_stylex_buf {
                                                          lines in the buffer will not be modified and will retain stale data (from the buffer's
                                                          previous use). This setting may decrease the peak PKI performance by up to half on small
                                                          packets. */
-	uint64_t mb_size                      : 13; /**< The number of eight-byte words to store into a buffer. This must be in the range of 32 to
-                                                         4096. This must be less than or equal to the maximum size of every free page in every FPA
-                                                         pool this style may use. */
+	uint64_t mb_size                      : 13; /**< The number of eight-byte words to store into a buffer. This must be even, in the range of
+                                                         32 to 4096. This must be less than or equal to the maximum size of every free page in
+                                                         every FPA pool this style may use. */
 #else
 	uint64_t mb_size                      : 13;
 	uint64_t dis_wq_dat                   : 1;
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-resources.h b/arch/mips/include/asm/octeon/cvmx-pki-resources.h
index f68f527..a1ff50c 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-resources.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-resources.h
@@ -72,13 +72,20 @@ int cvmx_pki_alloc_style(int node, int style);
  * @param node	 	node to allocate cluster group from.
    @param cl_grp	cluster group to allocate/reserve, if -1 ,
                         allocate any available cluster group.
- * @param num_clusters	number of clusters that will be attached to
-			the cluster group.
- * @param parsing_mask  mask of parsing that will be enabled on the cluster gro.
  * @return 	 	cluster group number or -1 on failure
  */
-int cvmx_pki_alloc_cluster_group(int node, int cl_grp, int num_clusters,
-				 uint64_t parsing_mask, uint64_t *cluster_mask);
+int cvmx_pki_alloc_cluster_group(int node, int cl_grp);
+
+/**
+ * This function allocates/reserves a cluster from per node
+   cluster resources.
+ * @param node	 	node to allocate cluster group from.
+   @param cluster_mask	mask of clusters  to allocate/reserve, if -1 ,
+                        allocate any available clusters.
+ * @param num_clusters	number of clusters that will be allocated
+ */
+int cvmx_pki_alloc_clusters(int node, int num_clusters, uint64_t *cluster_mask);
+
 
 /**
  * This function allocates/reserves a pcam entry from node
@@ -103,10 +110,47 @@ int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_ma
  */
 int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count );
 
+/**
+ * This function frees a style from pool of global styles per node.
+ * @param node	 node to free style from.
+ * @param style	 style to free
+ * @return 	 0 on success, -1 on failure.
+ */
+int cvmx_pki_free_style(int node, int style);
+
+
+/**
+ * This function frees a cluster group from per node
+   cluster group resources.
+ * @param node	 	node to free cluster group from.
+   @param cl_grp	cluster group to free
+ * @return 	 	0 on success or -1 on failure
+ */
+int cvmx_pki_free_cluster_group(int node, int cl_grp);
+
+/**
+ * This function frees  clusters  from per node
+   clusters resources.
+ * @param node	 	node to free clusters from.
+ * @param cluster_mask  mask of clusters need freeing
+ * @return 	 	0 on success or -1 on failure
+ */
+int cvmx_pki_free_clusters(int node, uint64_t cluster_mask);
+
+/**
+ * This function frees a pcam entry from node
+ * @param node	 	node to allocate pcam entry from.
+   @param index  	index of pacm entry (0-191) needs to be freed.
+ * @param bank		pcam bank where to free pcam entry from
+ * @param cluster_mask  mask of clusters from which pcam entry is freed.
+ * @return 	 	0 on success OR -1 on failure
+ */
+int cvmx_pki_pcam_free_entry(int node, int index, int bank, uint64_t cluster_mask);
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
 /* *INDENT-ON* */
 #endif
 
-#endif /*  __CVM_PKI_RESOURCES_H__ */
\ No newline at end of file
+#endif /*  __CVM_PKI_RESOURCES_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-pki.h b/arch/mips/include/asm/octeon/cvmx-pki.h
index 3ca9528..5d885fa 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki.h
@@ -50,8 +50,12 @@
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-pki-defs.h>
 #include <asm/octeon/cvmx-fpa.h>
+#include <asm/octeon/cvmx-helper-util.h>
+#include <asm/octeon/cvmx-helper-cfg.h>
 #else
 #include "cvmx-fpa.h"
+#include "cvmx-helper-util.h"
+#include "cvmx-helper-cfg.h"
 #endif
 
 #ifdef	__cplusplus
@@ -61,30 +65,26 @@ extern "C" {
 #endif
 
 #define CVMX_PKI_NUM_CHANNEL		(4096)
-#define CVMX_PKI_NUM_AURA       	(1024)
-#define CVMX_PKI_NUM_BPID 	      	(1024)
+#define CVMX_PKI_NUM_AURA		(1024)
+#define CVMX_PKI_NUM_BPID		(1024)
 #define CVMX_PKI_NUM_PKIND		(64)
 #define CVMX_PKI_NUM_INTERNAL_STYLES    (256)
 #define CVMX_PKI_NUM_FINAL_STYLES	(64)
 #define CVMX_PKI_NUM_QPG_ENTRY		(2048)
-#define CVMX_PKI_NUM_FRAME_CHECK_VALUES	(2)
 #define CVMX_PKI_NUM_LTYPES		(32)
 #define CVMX_PKI_NUM_CLUSTERS		(4)
 #define CVMX_PKI_NUM_CLUSTER_GROUP      (4)
 #define CVMX_PKI_NUM_PCAM_BANK		(2)
 #define CVMX_PKI_NUM_PCAM_ENTRY		(192)
 #define CVMX_PKI_NUM_QPG_STYLE_INDEX	(8)
-#define CVMX_PKI_NUM_FRAME_SIZE_ID	(2)
+#define CVMX_PKI_NUM_FRAME_CHECK	(2)
 #define CVMX_PKI_NUM_CHANNELS		(4096)
 #define CVMX_PKI_NUM_BPID		(1024)
+#define CVMX_PKI_NUM_SSO_GROUP		(256)
+#define CVMX_PKI_NUM_BELTYPE		(32)
 #define CVMX_PKI_MAX_FRAME_SIZE		(65535)
 #define CVMX_PKI_FIND_AVAL_ENTRY        (-1)
-#define CVMX_PKI_MAX_CLUSTER_PROFILES   (4)
-#define CVMX_PKI_MAX_STYLE_PROFILES	(256)
-#define CVMX_PKI_MAX_NAME		(16)
-#define CVMX_PKI_MAX_POOL_PROFILES	(64) //modify it later
-#define CVMX_PKI_MAX_AURA_PROFILES	(256) //modify it later
-#define CVMX_PKI_MAX_SSO_GROUP_PROFILES	(256)
+#define CVMX_PKI_CLUSTER_ALL		(0xf)
 
 #ifdef CVMX_SUPPORT_SEPARATE_CLUSTER_CONFIG
 #define CVMX_PKI_TOTAL_PCAM_ENTRY	((CVMX_PKI_NUM_CLUSTERS) * (CVMX_PKI_NUM_PCAM_BANK) *\
@@ -93,245 +93,370 @@ extern "C" {
 #define CVMX_PKI_TOTAL_PCAM_ENTRY	(CVMX_PKI_NUM_PCAM_BANK * CVMX_PKI_NUM_PCAM_ENTRY)
 #endif
 
-#define CVMX_PKI_MAX_QPG_PROFILES	(2048)
+#define CVMX_PKI_MAX_NAME               (16)
 #define CVMX_PKI_NOT_ASSIGNED		(-88)
 
 
-struct cvmx_pki_cluster_profile
-{
-	char		name[CVMX_PKI_MAX_NAME];
-	int 		num_clusters;
-	int 		cluster_group;
-#define CVMX_PKI_PARSE_DSP		0x01
-#define CVMX_PKI_PARSE_FULCRUM		0x02
-#define CVMX_PKI_PARSE_MPLS		0x04
-#define CVMX_PKI_PARSE_L3		0x08
-#define CVMX_PKI_PARSE_IL3		0x10
-#define CVMX_PKI_PARSE_L4 		0x20
-#define CVMX_PKI_PARSE_CUSTOM_L2	0x40
-#define CVMX_PKI_PARSE_CUSTOM_LG	0x80
-#define CVMX_PKI_PARSE_VIRTUALIZATION	0x100
-#define CVMX_PKI_CLUSTER_ALL            0xf
-	uint64_t        parsing_mask;
 
+enum cvmx_pki_pkind_parse_mode {
+	CVMX_PKI_PARSE_LA_TO_LG = 0,	/* parse LA(L2) to LG */
+	CVMX_PKI_PARSE_LB_TO_LG = 1,	/* parse LB(custom) to LG */
+	CVMX_PKI_PARSE_LC_TO_LG = 3,	/* parse LC(L3) to LG */
+	CVMX_PKI_PARSE_LG = 0x3f,	/* parse LG */
+	CVMX_PKI_PARSE_NOTHING = 0x7f	/* parse nothing */
 };
 
-struct cvmx_pki_cluster_list
-{
-	int index;
-	struct cvmx_pki_cluster_profile cl_profile[CVMX_PKI_MAX_CLUSTER_PROFILES];
+enum cvmx_pki_parse_mode_chg {
+	CVMX_PKI_PARSE_NO_CHG = 0x0,
+	CVMX_PKI_PARSE_SKIP_TO_LB = 0x1,
+	CVMX_PKI_PARSE_SKIP_TO_LC = 0x3,
+	CVMX_PKI_PARSE_SKIP_TO_LD = 0x7,
+	CVMX_PKI_PARSE_SKIP_TO_LG = 0x3f,
+	CVMX_PKI_PARSE_SKIP_ALL = 0x7f,
 };
 
-struct cvmx_pki_pool_profile
-{
-	char pool_name[CVMX_PKI_MAX_NAME];
-	cvmx_fpa_pool_config_t	pool_cfg;
+enum cvmx_pki_l2_len_mode {
+	PKI_L2_LENCHK_EQUAL_GREATER = 0,
+	PKI_L2_LENCHK_EQUAL_ONLY
 };
 
-struct cvmx_pki_pool_list
-{
-	int index;
-	struct cvmx_pki_pool_profile pool_profile[CVMX_PKI_MAX_POOL_PROFILES];
+enum cvmx_pki_cache_mode {
+	CVMX_PKI_OPC_MODE_STT = 0LL,	/* All blocks write through DRAM,*/
+	CVMX_PKI_OPC_MODE_STF = 1LL,	/* All blocks into L2 */
+	CVMX_PKI_OPC_MODE_STF1_STT = 2LL,	/* 1st block L2, rest DRAM */
+	CVMX_PKI_OPC_MODE_STF2_STT = 3LL	/* 1st, 2nd blocks L2, rest DRAM */
 };
 
-struct cvmx_pki_aura_profile
-{
-	char aura_name[CVMX_PKI_MAX_NAME];
-	int aura_num;
-	int pool_num;
-	int buffer_count;
+/**
+ * Tag type definitions
+ */
+enum cvmx_sso_tag_type {
+	CVMX_SSO_TAG_TYPE_ORDERED = 0L,	/**< Tag ordering is maintained */
+	CVMX_SSO_TAG_TYPE_ATOMIC = 1L,	/**< Tag ordering is maintained, and at most one PP has the tag */
+	CVMX_SSO_TAG_TYPE_UNTAGGED = 2L,	/**< The work queue entry from the order
+	- NEVER tag switch from NULL to NULL */
+	CVMX_SSO_TAG_TYPE_EMPTY = 3L/**< A tag switch to NULL, and there is no space reserved in POW
+			- NEVER tag switch to NULL_NULL
+			- NEVER tag switch from NULL_NULL
+			- NULL_NULL is entered at the beginning of time and on a deschedule.
+			- NULL_NULL can be exited by a new work request. A NULL_SWITCH load can also switch the state to NULL */
 };
 
-struct cvmx_pki_aura_list
-{
-	int index;
-	struct cvmx_pki_aura_profile aura_profile[CVMX_PKI_MAX_AURA_PROFILES];
+enum cvmx_pki_qpg_qos {
+	CVMX_PKI_QPG_QOS_NONE = 0,
+	CVMX_PKI_QPG_QOS_VLAN,
+	CVMX_PKI_QPG_QOS_MPLS,
+	CVMX_PKI_QPG_QOS_DSA_SRC,
+	CVMX_PKI_QPG_QOS_DIFFSERV,
+	CVMX_PKI_QPG_QOS_HIGIG,
 };
 
-struct cvmx_pki_sso_grp_profile
-{
-	char grp_name[CVMX_PKI_MAX_NAME];
-	int grp_num;
-	int priority;
-	int weight;
-	int affinity;
-	uint64_t core_affinity_mask;
-	uint64_t core_affinity_mask_set;
+enum cvmx_pki_wqe_vlan {
+	CVMX_PKI_USE_FIRST_VLAN = 0,
+	CVMX_PKI_USE_SECOND_VLAN
 };
-struct cvmx_pki_sso_grp_list
-{
-	int index;
-	struct cvmx_pki_sso_grp_profile grp_profile[CVMX_PKI_MAX_SSO_GROUP_PROFILES];
+
+/**
+ * Controls how the PKI statistics counters are handled
+ * The PKI_STAT*_X registers can be indexed either by port kind (pkind), or
+ * final style. (Does not apply to the PKI_STAT_INB* registers.)
+ *    0 = X represents the packets pkind
+ *    1 = X represents the low 6-bits of packets final style
+ */
+enum cvmx_pki_stats_mode {
+	CVMX_PKI_STAT_MODE_PKIND,
+	CVMX_PKI_STAT_MODE_STYLE
 };
 
-struct cvmx_pki_qpg_profile
-{
-	char qpg_name[CVMX_PKI_MAX_NAME];
-	int base_offset;
-	int num_entries;
+#define PKI_BELTYPE_E__NONE_M                              (0x0)
+#define PKI_BELTYPE_E__MISC_M                              (0x1)
+#define PKI_BELTYPE_E__IP4_M                               (0x2)
+#define PKI_BELTYPE_E__IP6_M                               (0x3)
+#define PKI_BELTYPE_E__TCP_M                               (0x4)
+#define PKI_BELTYPE_E__UDP_M                               (0x5)
+#define PKI_BELTYPE_E__SCTP_M                              (0x6)
+#define PKI_BELTYPE_E__SNAP_M                              (0x7)
+
+enum cvmx_pki_beltype { /* PKI_BELTYPE_E_t */
+	CVMX_PKI_BELTYPE_NONE	= PKI_BELTYPE_E__NONE_M,
+	CVMX_PKI_BELTYPE_MISC	= PKI_BELTYPE_E__MISC_M,
+	CVMX_PKI_BELTYPE_IP4	= PKI_BELTYPE_E__IP4_M,
+	CVMX_PKI_BELTYPE_IP6    = PKI_BELTYPE_E__IP6_M,
+	CVMX_PKI_BELTYPE_TCP    = PKI_BELTYPE_E__TCP_M,
+	CVMX_PKI_BELTYPE_UDP    = PKI_BELTYPE_E__UDP_M,
+	CVMX_PKI_BELTYPE_SCTP   = PKI_BELTYPE_E__SCTP_M,
+	CVMX_PKI_BELTYPE_SNAP   = PKI_BELTYPE_E__SNAP_M
 };
 
-struct cvmx_pki_qpg_list
-{
-	int index;
-	struct cvmx_pki_qpg_profile qpg_profile[CVMX_PKI_MAX_QPG_PROFILES];
+struct cvmx_pki_frame_len {
+	uint16_t	maxlen;
+	uint16_t	minlen;
 };
 
-struct cvmx_pki_style_profile
-{
-	char				name[CVMX_PKI_MAX_NAME];
-	int				style_num;
+struct cvmx_pki_tag_fields {
+	uint64_t layer_g_src:1;
+	uint64_t layer_f_src:1;
+	uint64_t layer_e_src:1;
+	uint64_t layer_d_src:1;
+	uint64_t layer_c_src:1;
+	uint64_t layer_b_src:1;
+	uint64_t layer_g_dst:1;
+	uint64_t layer_f_dst:1;
+	uint64_t layer_e_dst:1;
+	uint64_t layer_d_dst:1;
+	uint64_t layer_c_dst:1;
+	uint64_t layer_b_dst:1;
+	uint64_t input_port:1;
+	uint64_t mpls_label:1;
+	uint64_t first_vlan:1;
+	uint64_t second_vlan:1;
+	uint64_t ip_prot_nexthdr:1;
+	uint64_t tag_sync:1;
+	uint64_t tag_spi:1;
+	uint64_t tag_gtp:1;
+	uint64_t tag_vni:1;
 };
 
-struct cvmx_pki_style_list
-{
-	int    index;
-	struct cvmx_pki_style_profile style_profile[CVMX_PKI_MAX_STYLE_PROFILES];
+struct cvmx_pki_pkind_parse {
+	uint64_t mpls_en:1;	/**< Enable MPLS parsing.
+				0 = Any MPLS labels are ignored, but may be handled by custom Ethertype PCAM matchers.
+				1 = MPLS label stacks are parsed and skipped over. PKI_GBL_PEN[MPLS_PEN] must be set. */
+	uint64_t inst_hdr:1;	/**< INST header. When set, the eight-byte INST_HDR is present on all packets (except incoming
+				packets on the DPI ports). */
+	uint64_t lg_custom:1;	/**< Layer G Custom Match Enable.
+				0 = Disable custom LG header extraction
+				1 = Enable custom LG header extraction.*/
+	uint64_t fulc_en:1;	/**< Enable Fulcrum tag parsing.
+				0 = Any Fulcrum header is ignored.
+				1 = Fulcrum header is parsed.*/
+	uint64_t dsa_en:1;	/**< Enable DSA parsing. This field should not be set for DPI ports.
+				0 = Any DSA header is ignored.
+				1 = DSA is parsed. */
+	uint64_t hg2_en:1;	/**< Enable HiGig 2 parsing. This field should not be set for DPI ports.
+				0 = Any HiGig2 header is ignored.
+				1 = HiGig2 is parsed. PKI_GBL_PEN[HG_PEN] must be set. */
+	uint64_t hg_en:1;	/**< Enable HiGig parsing. This field should not be set for DPI ports.
+				0 = Any HiGig header is ignored.
+				1 = HiGig is parsed. PKI_GBL_PEN[HG_PEN] must be set.
+				At most one of FULC_EN, DSA_EN or HG_EN may be set. */
 };
 
-struct cvmx_pki_framelen_chk {
-	uint16_t	maxlen;
-	uint16_t	minlen;
+struct cvmx_pki_cluster_grp_config {
+	int grp_num;
+	uint64_t cluster_mask; /* bit mask of cluster assigned to this cluster group */
 };
 
-struct cvmx_pki_global_config
-{
-	uint64_t			parsing_mask;
-	uint64_t			clusters_in_use_mask;
-	struct cvmx_pki_framelen_chk    frame_len_chk[CVMX_PKI_NUM_FRAME_SIZE_ID];
-	//enum cvmx_pki_bel		bel_type_map[CVMX_PKI_MAX_LTYPE];
+struct cvmx_pki_sso_grp_config {
+	int sso_grp_num;
+	int priority;
+	int weight;
+	int affinity;
+	uint64_t core_mask;
+	uint8_t core_mask_set;
 };
 
-struct cvmx_pki_qpg_config
-{
+struct cvmx_pki_pool_config {
+	int pool_num;
+	uint64_t buffer_size;
+	uint64_t buffer_count;
+};
+
+struct cvmx_pki_aura_config {
+	int aura_num;
+	int pool_num;
+	int buffer_count;
+};
+
+struct cvmx_pki_qpg_config {
+	int  base_offset;
 	int  port_add;
 	int  aura;
-	int  group_ok;
-	int  group_bad;
+	int  grp_ok;
+	int  grp_bad;
 };
 
-struct cvmx_pki_clustergrp_config
-{
-	int		users;
-	uint64_t	cluster_mask;
-};
 
-enum cvmx_pki_pkind_parse_mode{
-	CVMX_PKI_PARSE_LA_TO_LG = 0,
-	CVMX_PKI_PARSE_LB_TO_LG = 1,
-	CVMX_PKI_PARSE_LC_TO_LG = 3,
-	CVMX_PKI_PARSE_LG = 0x3f,
-	CVMX_PKI_PARSE_NOTHING = 0x7f,
+/* This is per style structure for configuring port parameters, it is kind of of profile
+   which can be assigned to any port. If multiple ports are assigned same style be aware
+   that modiying that style will modify the respective parameters for all the ports which
+   are using this style */
+struct cvmx_pki_style_parm {
+
+	bool ip6_udp_opt;	/**< IPv6/UDP checksum is optional. IPv4 allows an optional UDP checksum by sending the all-0s
+					patterns. IPv6 outlaws this and the spec says to always check UDP checksum.
+					0 = Spec compliant, do not allow optional code.
+					1 = Treat IPv6 as IPv4; */
+	bool lenerr_en;         /**< L2 length error check enable. Check if frame was received with L2 length error. */
+	bool maxerr_en;         /**< Max frame error check enable. */
+	bool minerr_en;	        /**< Min frame error check enable. */
+
+	uint8_t lenerr_eqpad;	/**< L2 length checks exact pad size.
+					0 = Length check uses greater then or equal comparison.
+					1 = Length check uses equal comparison.*/
+	uint8_t minmax_sel;	/**< Selects which PKI_FRM_LEN_CHK(0..1) register is used for this pkind for MINERR and MAXERR */
+	bool qpg_dis_grptag;	/**< Disable computing group using WQE[TAG]. 1 -- Disable 0 -- Enable */
+	bool fcs_strip;         /**< Strip L2 FCS bytes from packet, decrease WQE[LEN] by 4 bytes.*/
+	bool fcs_chk;           /**< FCS checking enabled.*/
+	bool rawdrp;		/**< Allow RAW packet drop
+					0 = Never drop packets with WQE[RAW] set.
+					1 = Allow the PKI to drop RAW packets based on PKI_AURA(0..1023)_CFG[ENA_RED/ENA_DROP]. */
+	bool force_drop;	/**< Force packet dropping.
+					0 = Drop packet based on PKI_AURA(0..1023)_CFG[ENA_RED/ENA_DROP].
+					1 = Always drop the packet. Overrides NODROP, RAWDRP. */
+	bool nodrop;            /**< Disable QoS packet drop.
+					0 = Allowed to drop packet based on PKI_AURA(0..1023)_CFG[ENA_RED/ENA_DROP].
+					1 = Never drop the packet. Overrides RAWDRP. */
+	bool qpg_dis_padd;	/**< Disable computing port adder by QPG algorithm. */
+	bool qpg_dis_grp;       /**< Disable computing group by QPG algorithm. */
+	bool qpg_dis_aura;      /**< Disable computing aura by QPG algorithm. */
+	uint8_t qpg_base;	/**< Base index into PKI_QPG_TBL(0..2047)*/
+	enum cvmx_pki_qpg_qos	qpg_qos;	/**< Algorithm to select QoS field in QPG calculation */
+	uint8_t			qpg_port_sh;	/**< MSB to take from port number in QPG calculation
+							0 = Exclude port number from QPG.
+							4 = Include port<3:0>.
+							8 = Include port<7:0>.*/
+	uint8_t			qpg_port_msb;	/**< Number of bits to shift port number in QPG */
+	uint8_t apad_nip;			/**< Value for WQE[APAD] when packet is not IP. */
+	uint8_t wqe_vs;				/**< Which VLAN to put into WQE[VLPTR] when VLAN stacking.
+							0 = Use the first (in network order) VLAN or DSA VID.
+							1 = Use the second (in network order) VLAN. */
+
+	enum cvmx_sso_tag_type	tag_type;	/**< SSO tag type to schedule to */
+	bool pkt_lend;				/**< Packet little-endian.write operations of packet data to L2C to be in LE */
+	uint8_t wqe_hsz;			/**< Work queue header size:
+							0x0 = WORD0..4, standard WQE_S. Note FIRST_SKIP may be set to not include WORD4 in memory.
+							0x1 = WORD0..5
+							0x2 = WORD0..6
+							0x3 = WORD0..7
+							else = Reserved */
+	uint8_t wqe_skip;			/**< in bytes, WQE start offset. The number of 128-byte cache lines to skip between the buffer
+							Pointer and WORD0 of the work-queue entry.*/
+	uint8_t first_skip;			/**< in bytes, The number of eight-byte words from the top of the first MBUF
+							that the PKI stores the next pointer.*/
+	uint8_t later_skip;			/**< in bytes, The number of eight-byte words from the top of any MBUF
+							that is not the first MBUF that PKI writes next-pointer to.*/
+	enum cvmx_pki_cache_mode cache_mode;;	/**< Select the style of write to the L2C.
+							0 = all packet data and next-buffer pointers are written through to memory.
+							1 = all packet data and next-buffer pointers are written into the cache.
+							2 = the first aligned cache block holding the WQE and/or front packet data are written to
+							    the L2 cache. All remaining cache blocks are not written to the L2 cache.
+							3 = the first two aligned cache blocks holding the WQE and front packet data are written
+							    to the L2 cache. All remaining cache blocks are not written to the L2 cache. */
+	uint8_t dis_wq_dat;			/**< Separate first data buffer from the work queue entry.
+							0 = The packet link pointer will be at word [FIRST_SKIP] immediately followed by packet
+							    data, in the same buffer as the work queue entry.
+							1 = The packet link pointer will be at word [FIRST_SKIP] in a new buffer separate from the
+							    work queue entry.*/
+	uint64_t mbuff_size;			/**< The number of eight-byte words to store into a buffer. This must be even, in the range of
+						     32 to 4096. This must be less than or equal to the maximum size of every free page in
+						     every FPA pool this style may use. */
+	bool len_lg;				/**< Check length of Layer G. */
+	bool len_lf;				/**< Check length of Layer F. */
+	bool len_le;				/**< Check length of Layer E. */
+	bool len_ld;				/**< Check length of Layer D. */
+	bool len_lc;				/**< Check length of Layer C. */
+	bool len_lb;				/**< Check length of Layer B. */
+	bool csum_lg;				/**< Compute checksum on Layer G. */
+	bool csum_lf;				/**< Compute checksum on Layer F. */
+	bool csum_le;				/**< Compute checksum on Layer E. */
+	bool csum_ld;				/**< Compute checksum on Layer D. */
+	bool csum_lc;				/**< Compute checksum on Layer C. */
+	bool csum_lb;				/**< Compute checksum on Layer B. */
 };
 
-enum cvmx_pki_parse_mode_chg {
-	CVMX_PKI_PARSE_NO_CHG = 0x0,
-	CVMX_PKI_PARSE_SKIP_TO_LB = 0x1,
-	CVMX_PKI_PARSE_SKIP_TO_LC = 0x3,
-	CVMX_PKI_PARSE_SKIP_TO_LD = 0x7,
-	CVMX_PKI_PARSE_SKIP_TO_LG = 0x3f,
-	CVMX_PKI_PARSE_SKIP_ALL = 0x7f,
+/* This is per style structure for configuring port's tag configuration, it is kind of of profile
+   which can be assigned to any port. If multiple ports are assigned same style be aware
+   that modiying that style will modify the respective parameters for all the ports which
+   are using this style */
+
+struct cvmx_pki_mask_tag {
+	uint64_t tag_inc;			/**< Include masked tags using PKI_TAG_INC(0..31)_MASK. Each bit indicates to include the
+						     corresponding PKI_TAG_INC_MASK range. */
+	uint64_t tag_masken;			/**< Apply PKI_STYLE(0..63)_TAG_MASK to computed tag.*/
+	uint64_t mask;				/**< When set, each bit excludes corresponding bit of the tuple computed tag from being
+						     included in the final tag. PKI_CL(0..3)_STYLE(0..63)_CFG2 [TAG_MASKEN] must be set. Does
+						     not affect tags from packets with a PKI_INST_HDR_S when PKI_INST_HDR[UTAG] is set */
+	uint64_t tag_idx[4];			/**< Index 0-3 for TAG_INC<3>. This value is multipled by 4 to index into PKI_TAG_INC(0..31)_MASK.
+						     See WQE[TAG]. */
 };
 
-struct cvmx_pki_pkind_config
-{
-	int				users;
-	enum cvmx_pki_pkind_parse_mode	parsing_mode;
-	uint64_t 			cluster_mask;
-	uint64_t 			l2_parsing_mask;
-	int	 			initial_style;
-	int				cluster_grp;
+struct cvmx_pki_style_tag_cfg {
+	struct cvmx_pki_tag_fields tag_fields;
+	struct cvmx_pki_mask_tag   mask_tag;
 };
 
-struct cvmx_pki_tag_fields
-{
-	uint64_t layer_G_src:1;
-	uint64_t layer_F_src:1;
-	uint64_t layer_E_src:1;
-	uint64_t layer_D_src:1;
-	uint64_t layer_C_src:1;
-	uint64_t layer_B_src:1;
-	uint64_t layer_G_dst:1;
-	uint64_t layer_F_dst:1;
-	uint64_t layer_E_dst:1;
-	uint64_t layer_D_dst:1;
-	uint64_t layer_C_dst:1;
-	uint64_t layer_B_dst:1;
-	uint64_t input_port:1;
-	uint64_t mpls_label:1;
-	uint64_t first_vlan:1;
-	uint64_t second_vlan:1;
-	uint64_t ip_prot_nexthdr:1;
-	uint64_t tag_sync:1;
-	uint64_t tag_spi:1;
-	uint64_t tag_gtp:1;
-	uint64_t tag_vni:1;
+struct cvmx_pki_style_config {
+	struct cvmx_pki_style_parm parm_cfg;		/**< General parameter configuration. */
+	struct cvmx_pki_style_tag_cfg  tag_cfg;		/**< Tag parameter configuration. */
 };
 
-enum cvmx_pki_l2_len_mode {
-	PKI_L2_LENCHK_EQUAL_GREATER = 0,
-	PKI_L2_LENCHK_EQUAL_ONLY
+struct cvmx_pki_pkind_config {
+	uint8_t cluster_grp;		/**< cluster group that will service traffic on this pkind */
+	bool fcs_pres;			/**< FCS present.
+					0 = FCS not present. FCS may not be checked nor stripped.
+					1 = FCS present; the last four bytes of the packet are part of the FCS and may not be
+					considered part of a IP, TCP or other header for length error checks.*/
+	struct cvmx_pki_pkind_parse parse_en;
+	enum cvmx_pki_pkind_parse_mode	initial_parse_mode;
+	int initial_style;
+	bool custom_l2_hdr;		/**< Valid.custom L2 hesder extraction
+					0 = Disable custom L2 header extraction.
+					1 = Enable custom L2 header extraction.
+					PKI_GBL_PEN[CLG_PEN] must be set. */
+	uint8_t l2_scan_offset;		/**< Scan offset for custom L2 header.
+					Pointer to first byte of 32-bit custom extraction header, as absolute number
+					of bytes from beginning of packet. If PTP_MODE, the 8-byte timestamp is prepended to the
+					packet, and must be included in counting offset bytes. */
+	uint64_t lg_scan_offset;	/**< Scan offset for custom lg header.
+					Pointer to first byte of 32-bit custom extraction header, as relative number
+					of bytes from WQE[LFPTR]. */
 };
 
-enum cvmx_pki_cache_mode {
-	CVMX_PKI_OPC_MODE_STT = 0LL,	/* All blocks write through DRAM,*/
-	CVMX_PKI_OPC_MODE_STF = 1LL,	/* All blocks into L2 */
-	CVMX_PKI_OPC_MODE_STF1_STT = 2LL,	/* 1st block L2, rest DRAM */
-	CVMX_PKI_OPC_MODE_STF2_STT = 3LL	/* 1st, 2nd blocks L2, rest DRAM */
+struct cvmx_pki_port_config {
+	struct cvmx_pki_pkind_config pkind_cfg;		/**< Parameters can be configure per pkind */
+	struct cvmx_pki_style_config style_cfg;           /**< Parameters are configured per style, style is a profile
+						     which can be applied to multiple ports which have same configuration
+						     and packet processing */
 };
 
-/**
- * Tag type definitions
- */
-enum cvmx_sso_tag_type{
-	CVMX_SSO_TAG_TYPE_ORDERED = 0L,	/**< Tag ordering is maintained */
-	CVMX_SSO_TAG_TYPE_ATOMIC = 1L,	/**< Tag ordering is maintained, and at most one PP has the tag */
-	CVMX_SSO_TAG_TYPE_UNTAGGED = 2L,	/**< The work queue entry from the order
-	- NEVER tag switch from NULL to NULL */
-	CVMX_SSO_TAG_TYPE_EMPTY = 3L/**< A tag switch to NULL, and there is no space reserved in POW
-			- NEVER tag switch to NULL_NULL
-			- NEVER tag switch from NULL_NULL
-			- NULL_NULL is entered at the beginning of time and on a deschedule.
-			- NULL_NULL can be exited by a new work request. A NULL_SWITCH load can also switch the state to NULL */
+struct cvmx_pki_global_parse {
+	uint64_t virt_pen:1;	/**< Virtualization parsing enable.*/
+	uint64_t clg_pen:1;	/**< Custom LG parsing enable. */
+	uint64_t cl2_pen:1;	/**< Custom L2 parsing enable.*/
+	uint64_t l4_pen:1;	/**< L4 parsing enable.*/
+	uint64_t il3_pen:1;	/**< L3 inner parsing enable. Must be zero if L3_PEN is zero. */
+	uint64_t l3_pen:1;	/**< L3 parsing enable.*/
+	uint64_t mpls_pen:1;	/**< MPLS parsing enable.*/
+	uint64_t fulc_pen:1;	/**< Fulcrum parsing enable.*/
+	uint64_t dsa_pen:1;	/**< DSA parsing enable. Must be zero if HG_PEN is set.*/
+	uint64_t hg_pen:1;	/**< HiGig parsing enable. Must be zero if DSA_PEN is set.*/
 };
 
-enum cvmx_pki_qpg_qos {
-	CVMX_PKI_QPG_QOS_NONE = 0,
-	CVMX_PKI_QPG_QOS_VLAN,
-	CVMX_PKI_QPG_QOS_MPLS,
-	CVMX_PKI_QPG_QOS_DSA_SRC,
-	CVMX_PKI_QPG_QOS_DIFFSERV,
-	CVMX_PKI_QPG_QOS_HIGIG
+struct cvmx_pki_tag_sec {
+	uint16_t dst6;				/**< Secret for the destination tuple IPv6 tag CRC calculation. Typically identical to SRC6 to						insure tagging is symmetric between source/destination flows. Typically different from DST
+						for maximum security. */
+	uint16_t src6;				/**< Secret for the source tuple IPv6 tag CRC calculation. Typically different from SRC for
+						maximum security. */
+	uint16_t dst;				/**< Secret for the destination tuple tag CRC calculation. Typically identical to DST6 to
+						insure tagging is symmetric between source/destination flows. */
+	uint16_t src;				/**< Secret for the source tuple tag CRC calculation. */
 };
 
-struct cvmx_pki_style_config
-{
-	int				users;
-	bool				en_l2_lenchk;
-	uint64_t			cluster_mask;
-	enum cvmx_pki_l2_len_mode	l2_lenchk_mode;
-	bool 				en_maxframe_errchk;
-	bool 				en_minframe_errchk;
-	int	 			max_min_frame_sel;
-	bool 				strip_l2_fcs;
-	bool 				en_fcs_check;
-	int	 			wqe_header_size;
-	int 				wqe_start_offset;
-	int 				first_mbuf_skip;
-	int	 			later_mbuf_skip;
-	int				mbuff_size;
-	enum cvmx_pki_cache_mode 	cache_mode;
-	bool 				data_wqe_buf_diff;
-	int				wqe_vlan;
-	int				qpg_base_offset;
-	bool 				qpg_calc_port_addr;
-	bool 				qpg_calc_aura;
-	bool 				qpg_calc_group;
-	enum cvmx_pki_qpg_qos		qpg_qos;
-	int				qpg_port_msb;
-	int				qpg_port_shift;
-	enum cvmx_sso_tag_type	 	tag_type;
-	struct cvmx_pki_tag_fields 	tag_fields;
+struct cvmx_pki_global_config {
+	uint64_t cluster_mask[CVMX_PKI_NUM_CLUSTER_GROUP];	/**< Mask of clusters associated with that cluster group,
+								there are 4 cluster groups and 4 clusters which can be assigned
+								to cluster groups */
+	enum cvmx_pki_stats_mode stat_mode;			/**< The PKI_STAT*_X registers can be indexed either by pkind or final style.
+								(Does not apply to the PKI_STAT_INB* registers.)
+								0 = X represents the packet's pkind
+								1 = X represents the low 6-bits of packet's final style */
+	struct cvmx_pki_global_parse gbl_pen;			/**< Controls Global parsing options for chip */
+	struct cvmx_pki_tag_sec tag_secret;			/**< Secret value for src/dst tag tuple to reduce cache collision attacks */
+	struct cvmx_pki_frame_len frm_len[CVMX_PKI_NUM_FRAME_CHECK]; /**< values for max and min frame length to check against,2 combination */
+	enum cvmx_pki_beltype ltype_map[CVMX_PKI_NUM_BELTYPE];	/**< Map of which protocol maps to what layer */
+	/* struct cvmx_pki_tag_ctl  tag_ctl[32]; */
+	/* cvmx_pki_tag_incx_mask_t tag_mask[32]; */
+	int pki_enable;
 };
 
 #define CVMX_PKI_PCAM_TERM_E_NONE_M                            (0x0)
@@ -352,7 +477,7 @@ struct cvmx_pki_style_config
 #define CVMX_PKI_PCAM_TERM_E_L4_PORT_M                         (0x30)
 #define CVMX_PKI_PCAM_TERM_E_LG_CUSTOM_M                       (0x39)
 
-enum cvmx_pki_term { // CVMX_PKI_PCAM_TERM_E_t
+enum cvmx_pki_term {
 	CVMX_PKI_PCAM_TERM_E_NONE                    = CVMX_PKI_PCAM_TERM_E_NONE_M,
 	CVMX_PKI_PCAM_TERM_E_L2_CUSTOM               = CVMX_PKI_PCAM_TERM_E_L2_CUSTOM_M,
 	CVMX_PKI_PCAM_TERM_E_HIGIG                   = CVMX_PKI_PCAM_TERM_E_HIGIG_M,
@@ -372,71 +497,16 @@ enum cvmx_pki_term { // CVMX_PKI_PCAM_TERM_E_t
 	CVMX_PKI_PCAM_TERM_E_LG_CUSTOM               = CVMX_PKI_PCAM_TERM_E_LG_CUSTOM_M
 };
 
-struct cvmx_pki_pcam_input
-{
-	uint64_t 		style;
+struct cvmx_pki_pcam_input {
+	uint64_t		style;
 	uint64_t		style_mask;
 	enum cvmx_pki_term	field;
-	uint32_t 		field_mask;
-	uint64_t 		data;
-	uint64_t 		data_mask;
-};
-
-#define CVMX_PKI_LTYPE_E_NONE_M                                (0x0)
-#define CVMX_PKI_LTYPE_E_ENET_M                                (0x1)
-#define CVMX_PKI_LTYPE_E_VLAN_M                                (0x2)
-#define CVMX_PKI_LTYPE_E_SNAP_PAYLD_M                          (0x5)
-#define CVMX_PKI_LTYPE_E_ARP_M                                 (0x6)
-#define CVMX_PKI_LTYPE_E_RARP_M                                (0x7)
-#define CVMX_PKI_LTYPE_E_IP4_M                                 (0x8)
-#define CVMX_PKI_LTYPE_E_IP4_OPT_M                             (0x9)
-#define CVMX_PKI_LTYPE_E_IP6_M                                 (0xA)
-#define CVMX_PKI_LTYPE_E_IP6_OPT_M                             (0xB)
-#define CVMX_PKI_LTYPE_E_IPSEC_ESP_M                           (0xC)
-#define CVMX_PKI_LTYPE_E_IPFRAG_M                              (0xD)
-#define CVMX_PKI_LTYPE_E_IPCOMP_M                              (0xE)
-#define CVMX_PKI_LTYPE_E_TCP_M                                 (0x10)
-#define CVMX_PKI_LTYPE_E_UDP_M                                 (0x11)
-#define CVMX_PKI_LTYPE_E_SCTP_M                                (0x12)
-#define CVMX_PKI_LTYPE_E_UDP_VXLAN_M                           (0x13)
-#define CVMX_PKI_LTYPE_E_GRE_M                                 (0x14)
-#define CVMX_PKI_LTYPE_E_NVGRE_M                               (0x15)
-#define CVMX_PKI_LTYPE_E_GTP_M                                 (0x16)
-#define CVMX_PKI_LTYPE_E_SW28_M                                (0x1C)
-#define CVMX_PKI_LTYPE_E_SW29_M                                (0x1D)
-#define CVMX_PKI_LTYPE_E_SW30_M                                (0x1E)
-#define CVMX_PKI_LTYPE_E_SW31_M                                (0x1F)
-
-enum cvmx_pki_layer_type{ // PKI_LTYPE_E_t
-	CVMX_PKI_LTYPE_E_NONE                        = CVMX_PKI_LTYPE_E_NONE_M,
-	CVMX_PKI_LTYPE_E_ENET                        = CVMX_PKI_LTYPE_E_ENET_M,
-	CVMX_PKI_LTYPE_E_VLAN                        = CVMX_PKI_LTYPE_E_VLAN_M,
-	CVMX_PKI_LTYPE_E_SNAP_PAYLD                  = CVMX_PKI_LTYPE_E_SNAP_PAYLD_M,
-	CVMX_PKI_LTYPE_E_ARP                         = CVMX_PKI_LTYPE_E_ARP_M,
-	CVMX_PKI_LTYPE_E_RARP                        = CVMX_PKI_LTYPE_E_RARP_M,
-	CVMX_PKI_LTYPE_E_IP4                         = CVMX_PKI_LTYPE_E_IP4_M,
-	CVMX_PKI_LTYPE_E_IP4_OPT                     = CVMX_PKI_LTYPE_E_IP4_OPT_M,
-	CVMX_PKI_LTYPE_E_IP6                         = CVMX_PKI_LTYPE_E_IP6_M,
-	CVMX_PKI_LTYPE_E_IP6_OPT                     = CVMX_PKI_LTYPE_E_IP6_OPT_M,
-	CVMX_PKI_LTYPE_E_IPSEC_ESP                   = CVMX_PKI_LTYPE_E_IPSEC_ESP_M,
-	CVMX_PKI_LTYPE_E_IPFRAG                      = CVMX_PKI_LTYPE_E_IPFRAG_M,
-	CVMX_PKI_LTYPE_E_IPCOMP                      = CVMX_PKI_LTYPE_E_IPCOMP_M,
-	CVMX_PKI_LTYPE_E_TCP                         = CVMX_PKI_LTYPE_E_TCP_M,
-	CVMX_PKI_LTYPE_E_UDP                         = CVMX_PKI_LTYPE_E_UDP_M,
-	CVMX_PKI_LTYPE_E_SCTP                        = CVMX_PKI_LTYPE_E_SCTP_M,
-	CVMX_PKI_LTYPE_E_UDP_VXLAN                   = CVMX_PKI_LTYPE_E_UDP_VXLAN_M,
-	CVMX_PKI_LTYPE_E_GRE                         = CVMX_PKI_LTYPE_E_GRE_M,
-	CVMX_PKI_LTYPE_E_NVGRE                       = CVMX_PKI_LTYPE_E_NVGRE_M,
-	CVMX_PKI_LTYPE_E_GTP                         = CVMX_PKI_LTYPE_E_GTP_M,
-	CVMX_PKI_LTYPE_E_SW28                        = CVMX_PKI_LTYPE_E_SW28_M,
-	CVMX_PKI_LTYPE_E_SW29                        = CVMX_PKI_LTYPE_E_SW29_M,
-	CVMX_PKI_LTYPE_E_SW30                        = CVMX_PKI_LTYPE_E_SW30_M,
-	CVMX_PKI_LTYPE_E_SW31                        = CVMX_PKI_LTYPE_E_SW31_M
+	uint32_t		field_mask;
+	uint64_t		data;
+	uint64_t		data_mask;
 };
 
-
-struct cvmx_pki_pcam_action
-{
+struct cvmx_pki_pcam_action {
 	enum cvmx_pki_parse_mode_chg	parse_mode_chg;
 	enum cvmx_pki_layer_type	layer_type_set;
 	int				style_add;
@@ -444,47 +514,82 @@ struct cvmx_pki_pcam_action
 	int				pointer_advance;
 };
 
-struct cvmx_pki_pcam_config
-{
+struct cvmx_pki_pcam_config {
 	int				in_use;
-	int 				entry_num;
+	int				entry_num;
 	uint64_t			cluster_mask;
 	struct cvmx_pki_pcam_input	pcam_input;
 	struct cvmx_pki_pcam_action	pcam_action;
 };
 
-struct cvmx_pki_pcam_list
-{
-	int	 			index;
-	struct cvmx_pki_pcam_config	pcam_cfg[CVMX_PKI_TOTAL_PCAM_ENTRY];
-};
-
-/** PKI block configuration*/
-struct cvmx_pki_config
-{
-	struct cvmx_pki_global_config		global_cfg;
-	struct cvmx_pki_clustergrp_config	cluster_cfg[CVMX_PKI_NUM_CLUSTER_GROUP];
-	struct cvmx_pki_pkind_config		pkind_cfg[CVMX_PKI_NUM_PKIND];
-	struct cvmx_pki_style_config		style_cfg[CVMX_PKI_NUM_FINAL_STYLES];
-	struct cvmx_pki_qpg_config		qpg_cfg[CVMX_PKI_NUM_QPG_ENTRY];
-	//struct cvmx_fpa_pool_config_t		pool_cfg[CVMX_FPA_NUM_POOLS_78XX];
-	//struct cvmx_pki_aura_config		aura_cfg[CVMX_FPA_AURA_NUM];//fpa should have aura config defined but it does not
-};
 
-/** Mapping of profile names to their respective config number*/
-struct cvmx_pki_profiles
-{
-	struct cvmx_pki_pcam_list		pcam_list;
-	struct cvmx_pki_cluster_list    	cl_profile_list;
-	struct cvmx_pki_style_list		style_profile_list;
-	struct cvmx_pki_pool_list		pool_profile_list;
-	struct cvmx_pki_aura_list		aura_profile_list;
-	struct cvmx_pki_sso_grp_list	        sso_grp_profile_list;
-	struct cvmx_pki_qpg_list	        qpg_profile_list;
+/**
+ * Status statistics for a port
+ */
+struct cvmx_pki_port_stats {
+	uint32_t dropped_octets;	/**< Inbound octets marked to be dropped by the IPD */
+	uint32_t dropped_packets;	/**< Inbound packets marked to be dropped by the IPD */
+	uint32_t pci_raw_packets;	/**< RAW PCI Packets received by PKI per port */
+	uint32_t octets;		/**< Number of octets processed by PKI */
+	uint32_t packets;		/**< Number of packets processed by PKI */
+	uint32_t multicast_packets;	/**< Number of indentified L2 multicast packets.
+					Does not include broadcast packets.
+					Only includes packets whose parse mode is
+					SKIP_TO_L2 */
+	uint32_t broadcast_packets;	/**< Number of indentified L2 broadcast packets.
+					Does not include multicast packets.
+					Only includes packets whose parse mode is
+					SKIP_TO_L2 */
+	uint32_t len_64_packets;	/**< Number of 64B packets */
+	uint32_t len_65_127_packets;	/**< Number of 65-127B packets */
+	uint32_t len_128_255_packets;	/**< Number of 128-255B packets */
+	uint32_t len_256_511_packets;	/**< Number of 256-511B packets */
+	uint32_t len_512_1023_packets;	/**< Number of 512-1023B packets */
+	uint32_t len_1024_1518_packets;	/**< Number of 1024-1518B packets */
+	uint32_t len_1519_max_packets;	/**< Number of 1519-max packets */
+	uint32_t fcs_align_err_packets;	/**< Number of packets with FCS or Align opcode errors */
+	uint32_t runt_packets;		/**< Number of packets with length < min */
+	uint32_t runt_crc_packets;	/**< Number of packets with length < min and FCS error */
+	uint32_t oversize_packets;	/**< Number of packets with length > max */
+	uint32_t oversize_crc_packets;	/**< Number of packets with length > max and FCS error */
+	uint32_t inb_packets;		/**< Number of packets without GMX/SPX/PCI errors received by PKI */
+	uint64_t inb_octets;		/**< Total number of octets from all packets received by PKI, including CRC */
+	uint16_t inb_errors;		/**< Number of packets with GMX/SPX/PCI errors received by PKI */
+	uint32_t mcast_l2_red_packets;	/**< Number of packets with L2 Multicast DMAC
+					that were dropped due to RED.
+					The HW will consider a packet to be an L2
+					multicast packet when the least-significant bit
+					of the first byte of the DMAC is set and the
+					packet is not an L2 broadcast packet.
+					Only applies when the parse mode for the packets
+					is SKIP-TO-L2 */
+	uint32_t bcast_l2_red_packets;	/**< Number of packets with L2 Broadcast DMAC	that were dropped due to RED.
+					The HW will consider a packet to be an L2
+					broadcast packet when the 48-bit DMAC is all 1's.
+					Only applies when the parse mode for the packets
+					is SKIP-TO-L2 */
+	uint32_t mcast_l3_red_packets;	/**< Number of packets with L3 Multicast Dest Address
+					that were dropped due to RED.
+					The HW considers an IPv4 packet to be multicast
+					when the most-significant nibble of the 32-bit
+					destination address is 0xE (i.e it is a class D
+					address). The HW considers an IPv6 packet to be
+					multicast when the most-significant byte of the
+					128-bit destination address is all 1's.
+					Only applies when the parse mode for the packets
+					is SKIP-TO-L2 and the packet is IP or the parse
+					mode for the packet is SKIP-TO-IP */
+	uint32_t bcast_l3_red_packets;	/**< Number of packets with L3 Broadcast Dest Address
+					that were dropped due to RED.
+					The HW considers an IPv4 packet to be broadcast
+					when all bits are set in the MSB of the
+					destination address. IPv6 does not have the
+					concept of a broadcast packets.
+					Only applies when the parse mode for the packet
+					is SKIP-TO-L2 and the packet is IP or the parse
+					mode for the packet is SKIP-TO-IP */
 };
 
-extern CVMX_SHARED struct cvmx_pki_config pki_config[CVMX_MAX_NODES];
-extern CVMX_SHARED struct cvmx_pki_profiles pki_profiles[CVMX_MAX_NODES];
 
 /**
  * This function writes qpg entry at specified offset in hardware
@@ -525,23 +630,80 @@ static inline int cvmx_pki_attach_cluster_to_group(int node, uint64_t cluster_gr
 {
 	cvmx_pki_icgx_cfg_t pki_cl_grp;
 
-	if(node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d",node);
-		return -1;
-	}
-
-	if( cluster_group >= CVMX_PKI_NUM_CLUSTER_GROUP ) {
+	if (cluster_group >= CVMX_PKI_NUM_CLUSTER_GROUP) {
 		cvmx_dprintf("ERROR: config cluster group %d", (int)cluster_group);
 		return -1;
 	}
-	pki_cl_grp.u64 = cvmx_read_csr_node(node,CVMX_PKI_ICGX_CFG(cluster_group));
+	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(cluster_group));
 	pki_cl_grp.s.clusters = cluster_mask;
-	cvmx_write_csr_node(node,CVMX_PKI_ICGX_CFG(cluster_group), pki_cl_grp.u64);
-	pki_config[node].global_cfg.clusters_in_use_mask |= cluster_mask;
-	pki_config[node].cluster_cfg[cluster_group].cluster_mask = cluster_mask;
+	cvmx_write_csr_node(node, CVMX_PKI_ICGX_CFG(cluster_group), pki_cl_grp.u64);
 	return 0;
 }
 
+static inline void cvmx_pki_write_stats_mode(int node, enum cvmx_pki_stats_mode mode)
+{
+	cvmx_pki_stat_ctl_t stat_ctl;
+	stat_ctl.u64 = cvmx_read_csr_node(node, CVMX_PKI_STAT_CTL);
+	stat_ctl.s.mode = mode;
+	cvmx_write_csr_node(node, CVMX_PKI_STAT_CTL, stat_ctl.u64);
+}
+
+static inline void cvmx_pki_write_global_parse(int node, struct cvmx_pki_global_parse gbl_pen)
+{
+	cvmx_pki_gbl_pen_t gbl_pen_reg;
+	gbl_pen_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_GBL_PEN);
+	gbl_pen_reg.s.virt_pen = gbl_pen.virt_pen;
+	gbl_pen_reg.s.clg_pen = gbl_pen.clg_pen;
+	gbl_pen_reg.s.cl2_pen = gbl_pen.cl2_pen;
+	gbl_pen_reg.s.l4_pen = gbl_pen.l4_pen;
+	gbl_pen_reg.s.il3_pen = gbl_pen.il3_pen;
+	gbl_pen_reg.s.l3_pen = gbl_pen.l3_pen;
+	gbl_pen_reg.s.mpls_pen = gbl_pen.mpls_pen;
+	gbl_pen_reg.s.fulc_pen = gbl_pen.fulc_pen;
+	gbl_pen_reg.s.dsa_pen = gbl_pen.dsa_pen;
+	gbl_pen_reg.s.hg_pen = gbl_pen.hg_pen;
+	cvmx_write_csr_node(node, CVMX_PKI_GBL_PEN, gbl_pen_reg.u64);
+}
+
+static inline void cvmx_pki_write_tag_secret(int node, struct cvmx_pki_tag_sec tag_secret)
+{
+	cvmx_pki_tag_secret_t tag_secret_reg;
+	tag_secret_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_TAG_SECRET);
+	tag_secret_reg.s.dst6 = tag_secret.dst6;
+	tag_secret_reg.s.src6 = tag_secret.src6;
+	tag_secret_reg.s.dst = tag_secret.dst;
+	tag_secret_reg.s.src = tag_secret.src;
+	cvmx_write_csr_node(node, CVMX_PKI_TAG_SECRET, tag_secret_reg.u64);
+}
+
+/**
+ * This function writes max and min frame lengths to hardware which can be used
+ * to check the size of frame arrived.There are 2 possible combination which are
+ * indicated by id field.
+ * @param node		node number.
+ * @param id		choose which frame len register to write to
+ * @param len_chk	struct containing Byte count for max-sized/min-sized frame check.
+ *
+ */
+static inline void cvmx_pki_write_frame_len(int node, int id,
+					   struct cvmx_pki_frame_len len_chk)
+{
+	cvmx_pki_frm_len_chkx_t frm_len_chk;
+	frm_len_chk.u64 = cvmx_read_csr_node(node, CVMX_PKI_FRM_LEN_CHKX(id));
+	frm_len_chk.s.maxlen = len_chk.maxlen;
+	frm_len_chk.s.minlen = len_chk.minlen;
+	cvmx_write_csr_node(node, CVMX_PKI_FRM_LEN_CHKX(id), frm_len_chk.u64);
+}
+
+static inline void cvmx_pki_write_ltype_map(int node, enum cvmx_pki_layer_type layer,
+					    enum cvmx_pki_beltype backend)
+{
+	cvmx_pki_ltypex_map_t ltype_map;
+	ltype_map.u64 = cvmx_read_csr_node(node, CVMX_PKI_LTYPEX_MAP(layer));
+	ltype_map.s.beltype = backend;
+	cvmx_write_csr_node(node, CVMX_PKI_LTYPEX_MAP(layer), ltype_map.u64);
+}
+
 /**
  * This function enables the cluster group to start parsing
  *
@@ -553,13 +715,13 @@ static inline int cvmx_pki_parse_enable(int node, int cl_grp)
 {
 	cvmx_pki_icgx_cfg_t pki_cl_grp;
 
-	if( cl_grp >= CVMX_PKI_NUM_CLUSTER_GROUP ) {
+	if (cl_grp >= CVMX_PKI_NUM_CLUSTER_GROUP) {
 		cvmx_dprintf("ERROR: pki parse en group %d", (int)cl_grp);
 		return -1;
 	}
-	pki_cl_grp.u64 = cvmx_read_csr_node(node,CVMX_PKI_ICGX_CFG(cl_grp));
+	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(cl_grp));
 	pki_cl_grp.s.pena = 1;
-	cvmx_write_csr_node(node,CVMX_PKI_ICGX_CFG(cl_grp), pki_cl_grp.u64);
+	cvmx_write_csr_node(node, CVMX_PKI_ICGX_CFG(cl_grp), pki_cl_grp.u64);
 	return 0;
 }
 
@@ -574,20 +736,151 @@ static inline void cvmx_pki_enable_backpressure(int node)
 
 	pki_buf_ctl.u64 = cvmx_read_csr_node(node, CVMX_PKI_BUF_CTL);
 	pki_buf_ctl.s.pbp_en = 1;
-	cvmx_write_csr_node(node,CVMX_PKI_BUF_CTL, pki_buf_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_PKI_BUF_CTL, pki_buf_ctl.u64);
 }
 
-static inline void cvmx_pki_mark_style_in_use(int node, int style)
+
+/**
+ * Get the status counters for index from PKI.
+ *
+ * @param node	   node number
+ * @param index    pkind number (if PKI_STATS_CTL:mode=0) or
+ *		   style(flow) number (if PKI_STATS_CTL:mode=1)
+ * @param status   Where to put the results.
+ */
+static inline void cvmx_pki_get_stats(int node, int index, struct cvmx_pki_port_stats *status)
 {
-#define CVMX_PKI_MANAGE_RESOURCES 1 //vinita_to_do, later make it global option
-#if CVMX_PKI_MANAGE_RESOURCES
+	cvmx_pki_statx_stat0_t stat0;
+	cvmx_pki_statx_stat1_t stat1;
+	cvmx_pki_statx_stat2_t stat2;
+	cvmx_pki_statx_stat3_t stat3;
+	cvmx_pki_statx_stat4_t stat4;
+	cvmx_pki_statx_stat5_t stat5;
+	cvmx_pki_statx_stat6_t stat6;
+	cvmx_pki_statx_stat7_t stat7;
+	cvmx_pki_statx_stat8_t stat8;
+	cvmx_pki_statx_stat9_t stat9;
+	cvmx_pki_statx_stat10_t stat10;
+	cvmx_pki_statx_stat11_t stat11;
+	cvmx_pki_statx_stat14_t stat14;
+	cvmx_pki_statx_stat15_t stat15;
+	cvmx_pki_statx_stat16_t stat16;
+	cvmx_pki_statx_stat17_t stat17;
+	cvmx_pki_statx_hist0_t hist0;
+	cvmx_pki_statx_hist1_t hist1;
+	cvmx_pki_statx_hist2_t hist2;
+	cvmx_pki_statx_hist3_t hist3;
+	cvmx_pki_statx_hist4_t hist4;
+	cvmx_pki_statx_hist5_t hist5;
+	cvmx_pki_statx_hist6_t hist6;
+	cvmx_pki_pkndx_inb_stat0_t pki_pknd_inb_stat0;
+	cvmx_pki_pkndx_inb_stat1_t pki_pknd_inb_stat1;
+	cvmx_pki_pkndx_inb_stat2_t pki_pknd_inb_stat2;
+
+	stat0.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT0(index));
+	stat1.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT1(index));
+	stat2.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT2(index));
+	stat3.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT3(index));
+	stat4.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT4(index));
+	stat5.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT5(index));
+	stat6.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT6(index));
+	stat7.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT7(index));
+	stat8.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT8(index));
+	stat9.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT9(index));
+	stat10.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT10(index));
+	stat11.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT11(index));
+	stat14.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT14(index));
+	stat15.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT15(index));
+	stat16.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT16(index));
+	stat17.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT17(index));
+	hist0.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST0(index));
+	hist1.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST1(index));
+	hist2.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST2(index));
+	hist3.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST3(index));
+	hist4.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST4(index));
+	hist5.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST5(index));
+	hist6.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST6(index));
+	pki_pknd_inb_stat0.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKNDX_INB_STAT0(index));
+	pki_pknd_inb_stat1.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKNDX_INB_STAT1(index));
+	pki_pknd_inb_stat2.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKNDX_INB_STAT2(index));
+
+	status->dropped_octets = stat4.s.drp_octs;
+	status->dropped_packets = stat3.s.drp_pkts;
+	status->octets = stat1.s.octs;
+	status->pci_raw_packets = stat2.s.raw;
+	status->packets = stat0.s.pkts;
+	status->multicast_packets = stat6.s.mcast;
+	status->broadcast_packets = stat5.s.bcast;
+	status->len_64_packets = hist0.s.h1to63;
+	status->len_65_127_packets = hist1.s.h64to127;
+	status->len_128_255_packets = hist2.s.h128to255;
+	status->len_256_511_packets = hist3.s.h256to511;
+	status->len_512_1023_packets = hist4.s.h512to1023;
+	status->len_1024_1518_packets = hist5.s.h1024to1518;
+	status->len_1519_max_packets = hist6.s.h1519;
+	status->fcs_align_err_packets = stat7.s.fcs;
+	status->runt_packets = stat9.s.undersz;
+	status->runt_crc_packets = stat8.s.frag;
+	status->oversize_packets = stat11.s.oversz;
+	status->oversize_crc_packets = stat10.s.jabber;
+	status->mcast_l2_red_packets = stat15.s.drp_mcast;
+	status->bcast_l2_red_packets = stat14.s.drp_bcast;
+	status->mcast_l3_red_packets = stat17.s.drp_mcast;
+	status->bcast_l3_red_packets = stat16.s.drp_bcast;
+	status->inb_packets = pki_pknd_inb_stat0.s.pkts;
+	status->inb_octets = pki_pknd_inb_stat1.s.octs;
+	status->inb_errors = pki_pknd_inb_stat2.s.errs;
+}
 
-	//vinita_to_do spinlock
-	pki_config[node].style_cfg[style].users++;
-#else
-#endif
+/**
+ * Get the statistics counters for a port.
+ *
+ * @param node	   node number
+ * @param port_num Port number (ipd_port) to get statistics for.
+ *		   Make sure PKI_STATS_CTL:mode is set to 0 for
+ *		   collecting per port/pkind stats.
+ * @param status   Where to put the results.
+ */
+static inline void cvmx_pki_get_port_stats(int node, uint64_t port, struct cvmx_pki_port_stats *status)
+{
+	int interface = cvmx_helper_get_interface_num(port);
+	int index = cvmx_helper_get_interface_index_num(port);
+	int pknd = cvmx_helper_get_pknd(interface, index);
+
+	cvmx_pki_get_stats(node, pknd, status);
 }
 
+/**
+ * Get the statistics counters for a flow represented by style in PKI.
+ *
+ * @param node	   node number
+ * @param style	   style number to get statistics for.
+ *		   Make sure PKI_STATS_CTL:mode is set to 1 for
+ *		   collecting per style/flow stats.
+ * @param status   Where to put the results.
+ */
+static inline void cvmx_pki_get_flow_stats(int node, uint64_t style_num, struct cvmx_pki_port_stats *status)
+{
+	cvmx_pki_get_stats(node, style_num, status);
+}
+
+/**
+ * Controls how the PKI statistics counters are handled
+ * The PKI_STAT*_X registers can be indexed either by port kind (pkind), or
+ * final style. (Does not apply to the PKI_STAT_INB* registers.)
+ * @param node		node number
+ * @param mode          mode to index counter with
+ *			0 =  collect counter per packets pkind
+ *			1 =  collect counter per packets final style
+ */
+static inline void cvmx_pki_set_stats_mode(int node, enum cvmx_pki_stats_mode mode)
+{
+	cvmx_pki_stat_ctl_t stat_ctl;
+
+	stat_ctl.u64 = cvmx_read_csr_node(node, CVMX_PKI_STAT_CTL);
+	stat_ctl.s.mode = mode;
+	cvmx_write_csr_node(node, CVMX_PKI_STAT_CTL, stat_ctl.u64);
+}
 
 /**
  * This function enables pki
@@ -597,46 +890,50 @@ void cvmx_pki_enable(int node);
 
 /**
  * This function disables pki
- * @param node	 	node to disable pki in.
+ * @param node	node to disable pki in.
  */
 void cvmx_pki_disable(int node);
 
 /**
  * This function writes per pkind parameters in hardware which defines how
   the incoming packet is processed.
- * @param node	 	      node to which pkind belongs.
+ * @param node		      node number.
  * @param pkind               PKI supports a large number of incoming interfaces
  *                            and packets arriving on different interfaces or channels
  *                            may want to be processed differently. PKI uses the pkind to
  *                            determine how the incoming packet is processed.
- * @param cluster_group       Which cluster group to use. Application would choose the cluster
- *                            group depending on number of clusters it want to use for that pkind.
- * @param initial_parse_mode  Which initial parsing stage is expected.
- * @param initial_style       Which initial style to assign to this pkind. Style also go as one of
- *                            the inputs to match in the pcam table. If no match is found this initial
- *                            style will be the final style.
+ * @param pkind_cfg	      struct conatining pkind configuration need to be written to hw
  */
-int cvmx_pki_write_pkind(int node, int pkind, int cluster_group,
-			   int initial_parse_mode, int initial_style);
+int cvmx_pki_write_pkind(int node, int pkind, struct cvmx_pki_pkind_config *pkind_cfg);
+
+/**
+ * This function writes/configures parameters associated with tag configuration in hardware.
+ * @param node	              node number.
+ * @param style		      style to configure tag for
+ * @param cluster_mask	      Mask of clusters to configure the style for.
+ * @param tag_cfg	      pointer to taf configuration struct.
+ */
+void cvmx_pki_write_tag_config(int node, int style, uint64_t cluster_mask,
+			       struct cvmx_pki_style_tag_cfg *tag_cfg);
 
 /**
  * This function writes/configures parameters associated with style in hardware.
  * @param node	              node to which style belong.
  * @param style		      style to configure.
  * @param cluster_mask	      Mask of clusters to configure the style for.
- * @param style_cfg 	      parameters to configure for style passed in struct.
+ * @param style_cfg	      parameters to configure for style passed in struct.
  */
 void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
-			    struct cvmx_pki_style_config style_cfg);
+			    struct cvmx_pki_style_config *style_cfg);
 
 /**
  * This function writes pcam entry at given offset in pcam table in hardware
  *
- * @param node	              node number.
- * @param index		      offset in pcam table.
- * @param cluster_mask	      Mask of clusters in which to write pcam entry.
- * @param input 	      input keys to pcam match passed as struct.
- * @param action	      pcam match action passed as struct
+ * @param node			node number.
+ * @param index			offset in pcam table.
+ * @param cluster_mask		Mask of clusters in which to write pcam entry.
+ * @param input			input keys to pcam match passed as struct.
+ * @param action		pcam match action passed as struct
  *
  */
 int cvmx_pki_pcam_write_entry(int node, int index, uint64_t cluster_mask,
@@ -683,293 +980,75 @@ int cvmx_pki_enable_aura_qos(int node, int aura, bool ena_red,
 			      bool ena_drop, bool ena_bp);
 
 /**
- * This function finds if cluster profile with name already exist
- * @param node  node number
- * @param name  profile name to look for
- * @return 	profile index in cluster list on SUCCESS
-                -1 if profile not found in cluster list
- */
-int cvmx_pki_cluster_profile_exist(int node, char *name);
-
-/**
- * This function finds cluster mask associated with
- * given cluster profile name.
- * @param node  node number
- * @param name  profile name to look for
- * @return 	cluster_mask on SUCCESS
-                -1 if profile not found in cluster list
- */
-int cvmx_pki_find_cluster_mask(int node, char *name);
-
-/**
- * This function finds cluster group associated with
- * given cluster profile name
- * @param node  node number
- * @param name  profile name to look for
- * @return 	cluster group number on SUCCESS
-                -1 if profile not found in cluster list
- */
-int cvmx_pki_find_cluster_group(int node, char *name);
-
-/**
- * This function finds if fpa pool profile with
- * name already exist
- * @param node  node number
- * @param name  profile name to look for
- * @return 	profile index in pool list on SUCCESS
-                -1 if profile not found in pool list
- */
-int cvmx_pki_pool_profile_exist(int node, char *name);
-
-/**
- * This function finds if fpa pool number associated with
- * given profile name
- * @param node  node number
- * @param name  profile name to look for
- * @return 	pool number on SUCCESS
-                -1 if profile not found in pool list
- */
-int cvmx_pki_find_pool(int node, char *name);
-
-/**
- * This function finds if fpa aura with given name
- * exist in aura list
- * @param node  node number
- * @param name  profile name to look for
- * @return 	aura index in aura list on SUCCESS
-                -1 if profile not found in aura list
- */
-int cvmx_pki_aura_profile_exist(int node, char *name);
-
-/**
- * This function finds aura number associated with
- * given aura name.
- * @param node  node number
- * @param name  profile name to look for
- * @return 	aura number in aura list on SUCCESS
-                -1 if profile not found in aura list
- */
-int cvmx_pki_find_aura(int node, char *name);
-
-/**
- * This function finds if group with given name
- * exist in group list
- * @param node  node number
- * @param name  profile name to look for
- * @return 	index in group list on SUCCESS
-                -1 if profile not found in group list
- */
-int cvmx_pki_group_profile_exist(int node, char *name);
-
-/**
- * This function finds group number associated with
- * given group profile name
- * @param node  node number
- * @param name  profile name to look for
- * @return 	group number on SUCCESS
-                -1 if profile not found in group list
- */
-int cvmx_pki_find_group(int node, char *name);
-
-/**
- * This function finds if qpg profile with given name
- * exist in qpg list
- * @param node  node number
- * @param name  profile name to look for
- * @return 	index in qpg list on SUCCESS
-                -1 if profile not found in qpg list
- */
-int cvmx_pki_qpg_profile_exist(int node, char *name);
-
-/**
- * This function finds qpg base offset associated with
- * given qpg profile name.
- * @param node  node number
- * @param name  profile name to look for
- * @return 	qpg base offset on SUCCESS
-                -1 if profile not found in qpg list
- */
-int cvmx_pki_find_qpg_base_offset(int node, char *name);
-
-/**
  * This function get the buffer size of the given pool number
  * @param node  node number
  * @param pool  fpa pool number
- * @return 	buffer size SUCCESS
-                -1 if pool number is not found in pool list
+ * @return	buffer size SUCCESS
+ *		-1 if pool number is not found in pool list
  */
-int cvmx_pki_get_pool_buffer_size(int node,int pool);
+int cvmx_pki_get_pool_buffer_size(int node, int pool);
 
 /**
  * This function get the buffer size of the given aura number
  * @param node  node number
  * @param pool  fpa aura number
- * @return 	buffer size SUCCESS
-                -1 if aura number is not found in aura list
+ * @return	buffer size SUCCESS
+ *		-1 if aura number is not found in aura list
  */
 int cvmx_pki_get_aura_buffer_size(int node, int aura);
 
-int cvmx_pki_get_mbuff_size (int node, int base_offset);
+int cvmx_pki_get_mbuff_size(int node, int base_offset);
 
-/**
- * This function finds if style profile with given name
- * exist in style list
- * @param node  node number
- * @param name  profile name to look for
- * @return 	index into style list on SUCCESS
-                -1 if profile not found in style list
- */
-int cvmx_pki_style_profile_exist(int node, char *name);
-
-/**
- * This function finds style number associated with
- * given style profile name.
- * @param node  node number
- * @param name  profile name to look for
- * @return 	style number on SUCCESS
-                -1 if profile not found in style list
- */
-int cvmx_pki_find_style(int node, char *name);
-
-
-/**
- * This function stores the cluster configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param name  	name associated with this config
- * @param cl_profile    structure containing cluster profile parameters below
- * 			-cluster_group (-1 if needs to be allocated)
- * 			-num_cluster   (number of cluster in the cluster group)
- * 			-parsing_mask  (parsing mask for the cluster group)
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_cluster_config(int node, struct cvmx_pki_cluster_profile cl_profile);
-
-/**
- * This function stores the pool configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pool_name  	name associated with this config
- * @param pool_numb     pool number (-1 if need to be allocated)
- * @param buffer_size	size of buffers in specified pool
- * @param num_buffers	numberof buffers in specified pool
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_pool_config(int node, char* pool_name, int pool_num,
-			     uint64_t buffer_size, uint64_t num_buffers);
-
-/**
- * This function stores the aura configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param aura_name  	name associated with this config
- * @param aura_num      aura number (-1 if need to be allocated)
- * @param pool  	pool to which aura is mapped
- * @param num_buffers	number of buffers to allocate to aura.
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_aura_config(int node, char* aura_name, int aura_num, int pool,
-			     int num_buffers);
-
-/**
- * This function stores the group configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param grp_profile	struct to SSO group profile to configure
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_sso_group_config(int node, struct cvmx_pki_sso_grp_profile grp_profile);
 
 /**
- * This function stores the qpg configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param name  	name associated with this config
- * @param base_offset	offset in QPG table (-1 if needs to be allocated)
- * @param num_entries	total number of indexes needs to be allocated from
- *                      base_offset.
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_qpg_profile(int node, char* name, int base_offset, int num_entries);
-
-/**
- * This function stores the group configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param aura_name  	name associated with this config
- * @param group		SSO group number (-1 if needs to be allocated)
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_qpg_config(int node, char* name, int entry_start,
-			    int entry_end, struct cvmx_pki_qpg_config qpg_config);
-
-/**
- * This function stores the style configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param aura_name  	name associated with this config
- * @param style_num	style number (-1 if needs to be allocated)
- * @param style_cfg	pointer to struct which has parameters related
- *                      to style config
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_style_config(int node, char* style_name, int style_num,
-			      struct cvmx_pki_style_config* style_cfg);
-
-/**
- * This function stores the pkind style configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pkind  	pkind number
- * @param style_name	pointer to style name which need to be assigned to pkind
- * @return 		0 on SUCCESS
-                        -1 on failure
- */
-int cvmx_pki_set_pkind_style(int node, int pkind, int style_name);
-
-/**
- * This function stores the pkind initial parse mode in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pkind  	pkind number
- * @param parse_mode    parse mode to assign to specified pkind.
- * @return 		0 on SUCCESS
-                        -1 on failure
+ * This function sets the wqe buffer mode. First packet data buffer can reside
+ * either in same buffer as wqe OR it can go in separate buffer. If used the later mode,
+ * make sure software allocate enough buffers to now have wqe separate from packet data.
+ * @param node	              node number.
+ * @param style		      style to configure.
+ * @param pkt_outside_wqe.	0 = The packet link pointer will be at word [FIRST_SKIP]
+ *				    immediately followed by packet data, in the same buffer
+ *				    as the work queue entry.
+ *				1 = The packet link pointer will be at word [FIRST_SKIP] in a new
+ *				    buffer separate from the work queue entry. Words following the
+ *				    WQE in the same cache line will be zeroed, other lines in the
+ *				    buffer will not be modified and will retain stale data (from the
+ *				    buffers previous use). This setting may decrease the peak PKI
+ *				    performance by up to half on small packets.
  */
-void cvmx_pki_set_pkind_initial_parse_mode(int node, int pkind, int parse_mode);
+void cvmx_pki_set_wqe_mode(int node, uint64_t style, bool pkt_outside_wqe);
 
 /**
- * This function stores the pkind cluster configuration in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param pkind  	pkind number
- * @param style_name	pointer to style name which need to be assigned to pkind
- * @return 		0 on SUCCESS
-                        -1 on failure
+ * Enables/Disables l2 length error check and max & min frame length checks
+ * @param node		node number
+ * @param pknd		pkind to disable error for.
+ * @param l2len_err	L2 length error check enable.
+ * @param maxframe_err	Max frame error check enable.
+ * @param minframe_err	Min frame error check enable.
+ *			1 -- Enabel err checks
+ *			0 -- Disable error checks
  */
-void cvmx_pki_set_pkind_cluster_config(int node, int pkind,
-				       int cl_grp, uint64_t cl_mask);
+void cvmx_pki_endis_l2_errs(int node, int pknd, bool l2len_err,
+			    bool maxframe_err, bool minframe_err);
 
 /**
- * This function stores the pcam entry in data structure
- * which is then used to program the hardware.
- * @param node  	node number
- * @param cluster_mask	Mask of clusters on which the entry meeds to be appiled.
- * @param input		structure of pcam input parameter which defines matching creteria.
- * @param action	structure of pcam action parameters which aill be applied if match is found.
- * @return              0 on scuccess
- *			-1 on failure
+ * Enables/Disables fcs check and fcs stripping on the pkind.
+ * @param node		node number
+ * @param pknd		pkind to apply settings on.
+ * @param fcs_chk	enable/disable fcs check.
+ *			1 -- enable fcs error check.
+ *			0 -- disable fcs error check.
+ * @param fcs_strip	Strip L2 FCS bytes from packet, decrease WQE[LEN] by 4 bytes
+ *			1 -- strip L2 FCS.
+ *			0 -- Do not strip L2 FCS.
  */
-int cvmx_pki_set_pcam_entry(int node, int pcam_index, uint64_t cl_mask,
-			    struct cvmx_pki_pcam_input input,
-			    struct cvmx_pki_pcam_action action);
+void cvmx_pki_endis_fcs_check(int node, int pknd, bool fcs_chk, bool fcs_strip);
+void cvmx_pki_get_style_config(int node, int style, uint64_t cl_mask,
+			       struct cvmx_pki_style_config *style_cfg);
+void cvmx_pki_config_port(int node, int ipd_port, struct cvmx_pki_port_config *port_cfg);
+void cvmx_pki_get_port_config(int node, int ipd_port, struct cvmx_pki_port_config *port_cfg);
+void cvmx_pki_reset(int node);
+void __cvmx_pki_free_ptr(int node);
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
diff --git a/arch/mips/include/asm/octeon/cvmx-pko-defs.h b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
index 22c7fa1..c5f6238 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
@@ -306,6 +306,17 @@ static inline uint64_t CVMX_PKO_DQX_WM_CTL_W1C(unsigned long offset)
 #define CVMX_PKO_DQX_WM_CTL_W1C(offset) (CVMX_ADD_IO_SEG(0x0001540000000048ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_DQ_CSR_BUS_DEBUG CVMX_PKO_DQ_CSR_BUS_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_DQ_CSR_BUS_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_DQ_CSR_BUS_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400003001F8ull);
+}
+#else
+#define CVMX_PKO_DQ_CSR_BUS_DEBUG (CVMX_ADD_IO_SEG(0x00015400003001F8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_DQ_DEBUG CVMX_PKO_DQ_DEBUG_FUNC()
 static inline uint64_t CVMX_PKO_DQ_DEBUG_FUNC(void)
 {
@@ -581,6 +592,17 @@ static inline uint64_t CVMX_PKO_L1_SQX_YELLOW_PACKETS(unsigned long offset)
 #define CVMX_PKO_L1_SQX_YELLOW_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L1_SQ_CSR_BUS_DEBUG CVMX_PKO_L1_SQ_CSR_BUS_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L1_SQ_CSR_BUS_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L1_SQ_CSR_BUS_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400000801F8ull);
+}
+#else
+#define CVMX_PKO_L1_SQ_CSR_BUS_DEBUG (CVMX_ADD_IO_SEG(0x00015400000801F8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_L2_SQA_DEBUG CVMX_PKO_L2_SQA_DEBUG_FUNC()
 static inline uint64_t CVMX_PKO_L2_SQA_DEBUG_FUNC(void)
 {
@@ -746,6 +768,17 @@ static inline uint64_t CVMX_PKO_L2_SQX_YELLOW(unsigned long offset)
 #define CVMX_PKO_L2_SQX_YELLOW(offset) (CVMX_ADD_IO_SEG(0x0001540000100060ull) + ((offset) & 511) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L2_SQ_CSR_BUS_DEBUG CVMX_PKO_L2_SQ_CSR_BUS_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L2_SQ_CSR_BUS_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L2_SQ_CSR_BUS_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400001001F8ull);
+}
+#else
+#define CVMX_PKO_L2_SQ_CSR_BUS_DEBUG (CVMX_ADD_IO_SEG(0x00015400001001F8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L3_L2_SQX_CHANNEL(unsigned long offset)
 {
 	if (!(
@@ -922,6 +955,17 @@ static inline uint64_t CVMX_PKO_L3_SQX_YELLOW(unsigned long offset)
 #define CVMX_PKO_L3_SQX_YELLOW(offset) (CVMX_ADD_IO_SEG(0x0001540000180060ull) + ((offset) & 511) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L3_SQ_CSR_BUS_DEBUG CVMX_PKO_L3_SQ_CSR_BUS_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L3_SQ_CSR_BUS_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L3_SQ_CSR_BUS_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400001801F8ull);
+}
+#else
+#define CVMX_PKO_L3_SQ_CSR_BUS_DEBUG (CVMX_ADD_IO_SEG(0x00015400001801F8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_L4_SQA_DEBUG CVMX_PKO_L4_SQA_DEBUG_FUNC()
 static inline uint64_t CVMX_PKO_L4_SQA_DEBUG_FUNC(void)
 {
@@ -1087,6 +1131,17 @@ static inline uint64_t CVMX_PKO_L4_SQX_YELLOW(unsigned long offset)
 #define CVMX_PKO_L4_SQX_YELLOW(offset) (CVMX_ADD_IO_SEG(0x0001540000200060ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L4_SQ_CSR_BUS_DEBUG CVMX_PKO_L4_SQ_CSR_BUS_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L4_SQ_CSR_BUS_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L4_SQ_CSR_BUS_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400002001F8ull);
+}
+#else
+#define CVMX_PKO_L4_SQ_CSR_BUS_DEBUG (CVMX_ADD_IO_SEG(0x00015400002001F8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_L5_SQA_DEBUG CVMX_PKO_L5_SQA_DEBUG_FUNC()
 static inline uint64_t CVMX_PKO_L5_SQA_DEBUG_FUNC(void)
 {
@@ -1252,6 +1307,17 @@ static inline uint64_t CVMX_PKO_L5_SQX_YELLOW(unsigned long offset)
 #define CVMX_PKO_L5_SQX_YELLOW(offset) (CVMX_ADD_IO_SEG(0x0001540000280060ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_L5_SQ_CSR_BUS_DEBUG CVMX_PKO_L5_SQ_CSR_BUS_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_L5_SQ_CSR_BUS_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_L5_SQ_CSR_BUS_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400002801F8ull);
+}
+#else
+#define CVMX_PKO_L5_SQ_CSR_BUS_DEBUG (CVMX_ADD_IO_SEG(0x00015400002801F8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_LUTX(unsigned long offset)
 {
 	if (!(
@@ -1367,10 +1433,10 @@ static inline uint64_t CVMX_PKO_MCI1_CRED_CNTX(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 27)))))
 		cvmx_warn("CVMX_PKO_MCI1_CRED_CNTX(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000AB0000ull) + ((offset) & 31) * 8;
+	return CVMX_ADD_IO_SEG(0x0001540000A80100ull) + ((offset) & 31) * 8;
 }
 #else
-#define CVMX_PKO_MCI1_CRED_CNTX(offset) (CVMX_ADD_IO_SEG(0x0001540000AB0000ull) + ((offset) & 31) * 8)
+#define CVMX_PKO_MCI1_CRED_CNTX(offset) (CVMX_ADD_IO_SEG(0x0001540000A80100ull) + ((offset) & 31) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_MCI1_MAX_CREDX(unsigned long offset)
@@ -1785,6 +1851,61 @@ static inline uint64_t CVMX_PKO_PDM_ECC_SBE_STS_CMB0_FUNC(void)
 #define CVMX_PKO_PDM_ECC_SBE_STS_CMB0 (CVMX_ADD_IO_SEG(0x00015400008FFFE8ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_FILLB_DBG0 CVMX_PKO_PDM_FILLB_DBG0_FUNC()
+static inline uint64_t CVMX_PKO_PDM_FILLB_DBG0_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_FILLB_DBG0 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008002A0ull);
+}
+#else
+#define CVMX_PKO_PDM_FILLB_DBG0 (CVMX_ADD_IO_SEG(0x00015400008002A0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_FILLB_DBG1 CVMX_PKO_PDM_FILLB_DBG1_FUNC()
+static inline uint64_t CVMX_PKO_PDM_FILLB_DBG1_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_FILLB_DBG1 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008002A8ull);
+}
+#else
+#define CVMX_PKO_PDM_FILLB_DBG1 (CVMX_ADD_IO_SEG(0x00015400008002A8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_FILLB_DBG2 CVMX_PKO_PDM_FILLB_DBG2_FUNC()
+static inline uint64_t CVMX_PKO_PDM_FILLB_DBG2_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_FILLB_DBG2 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008002B0ull);
+}
+#else
+#define CVMX_PKO_PDM_FILLB_DBG2 (CVMX_ADD_IO_SEG(0x00015400008002B0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_FLSHB_DBG0 CVMX_PKO_PDM_FLSHB_DBG0_FUNC()
+static inline uint64_t CVMX_PKO_PDM_FLSHB_DBG0_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_FLSHB_DBG0 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008002B8ull);
+}
+#else
+#define CVMX_PKO_PDM_FLSHB_DBG0 (CVMX_ADD_IO_SEG(0x00015400008002B8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PDM_FLSHB_DBG1 CVMX_PKO_PDM_FLSHB_DBG1_FUNC()
+static inline uint64_t CVMX_PKO_PDM_FLSHB_DBG1_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PDM_FLSHB_DBG1 not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400008002C0ull);
+}
+#else
+#define CVMX_PKO_PDM_FLSHB_DBG1 (CVMX_ADD_IO_SEG(0x00015400008002C0ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PDM_ISRD_DBG CVMX_PKO_PDM_ISRD_DBG_FUNC()
 static inline uint64_t CVMX_PKO_PDM_ISRD_DBG_FUNC(void)
 {
@@ -2115,6 +2236,17 @@ static inline uint64_t CVMX_PKO_PQB_DEBUG_FUNC(void)
 #define CVMX_PKO_PQB_DEBUG (CVMX_ADD_IO_SEG(0x0001540000000130ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PQ_CSR_BUS_DEBUG CVMX_PKO_PQ_CSR_BUS_DEBUG_FUNC()
+static inline uint64_t CVMX_PKO_PQ_CSR_BUS_DEBUG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PQ_CSR_BUS_DEBUG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x00015400000001F8ull);
+}
+#else
+#define CVMX_PKO_PQ_CSR_BUS_DEBUG (CVMX_ADD_IO_SEG(0x00015400000001F8ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PQ_DEBUG_GREEN CVMX_PKO_PQ_DEBUG_GREEN_FUNC()
 static inline uint64_t CVMX_PKO_PQ_DEBUG_GREEN_FUNC(void)
 {
@@ -2932,8 +3064,8 @@ union cvmx_pko_dpfi_flush {
 	struct cvmx_pko_dpfi_flush_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
-	uint64_t flush_en                     : 1;  /**< Pointer cache flush enable. When set, this flag commands the DPFI logic to flush all
-                                                         valid pointers from the pointer cache and return them to the FPA. The flush operation is
+	uint64_t flush_en                     : 1;  /**< Pointer cache flush enable. When set, this flag commands the DPFI logic to flush all valid
+                                                         pointers from the pointer cache and return them to the FPA. The flush operation is
                                                          complete when the CACHE_FLUSHED flag in PKO_DPFI_STATUS is set. Clearing the FLUSH_EN flag
                                                          results in the DPFI reloading its pointer cache. This flush mechanism should only be
                                                          enabled when the PKO is quiescent and all DQs have been closed. */
@@ -2973,8 +3105,8 @@ union cvmx_pko_dpfi_status {
 	uint64_t u64;
 	struct cvmx_pko_dpfi_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ptr_cnt                      : 32; /**< The number of pointers currently in use for storing descriptors
-                                                         and meta-packets plus those available in the DPFI pointer cache. */
+	uint64_t ptr_cnt                      : 32; /**< The number of pointers currently in use for storing descriptors and meta-packets plus
+                                                         those available in the DPFI pointer cache. */
 	uint64_t reserved_13_31               : 19;
 	uint64_t isrd_ptr1_rtn_full           : 1;  /**< ISRD pointer return register 1 contains a valid pointer. */
 	uint64_t isrd_ptr0_rtn_full           : 1;  /**< ISRD pointer return register 0 contains a valid pointer. */
@@ -2989,8 +3121,8 @@ union cvmx_pko_dpfi_status {
 	uint64_t fpa_empty                    : 1;  /**< 1 = FPA responded to pointer request with 'no pointers available.'
                                                          0 = FPA is providing pointers when requested. */
 	uint64_t dpfi_empty                   : 1;  /**< DPFI pointer cache is empty. */
-	uint64_t cache_flushed                : 1;  /**< 1 = Cache flush has completed. PKO_DPFI_STATUS[PTR_CNT] will read zero if all
-                                                             outstanding pointers have been returned to the FPA.
+	uint64_t cache_flushed                : 1;  /**< 1 = Cache flush has completed. PKO_DPFI_STATUS[PTR_CNT] will read zero if all outstanding
+                                                         pointers have been returned to the FPA.
                                                          0 = Cache flush not enabled or in-progress. */
 #else
 	uint64_t cache_flushed                : 1;
@@ -3016,6 +3148,9 @@ typedef union cvmx_pko_dpfi_status cvmx_pko_dpfi_status_t;
 
 /**
  * cvmx_pko_dq#_bytes
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_BYTES.
+ *
  */
 union cvmx_pko_dqx_bytes {
 	uint64_t u64;
@@ -3034,6 +3169,9 @@ typedef union cvmx_pko_dqx_bytes cvmx_pko_dqx_bytes_t;
 
 /**
  * cvmx_pko_dq#_cir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
+ *
  */
 union cvmx_pko_dqx_cir {
 	uint64_t u64;
@@ -3045,8 +3183,14 @@ union cvmx_pko_dqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -3067,6 +3211,9 @@ typedef union cvmx_pko_dqx_cir cvmx_pko_dqx_cir_t;
 
 /**
  * cvmx_pko_dq#_dropped_bytes
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_BYTES.
+ *
  */
 union cvmx_pko_dqx_dropped_bytes {
 	uint64_t u64;
@@ -3085,6 +3232,9 @@ typedef union cvmx_pko_dqx_dropped_bytes cvmx_pko_dqx_dropped_bytes_t;
 
 /**
  * cvmx_pko_dq#_dropped_packets
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_PACKETS.
+ *
  */
 union cvmx_pko_dqx_dropped_packets {
 	uint64_t u64;
@@ -3125,6 +3275,9 @@ typedef union cvmx_pko_dqx_fifo cvmx_pko_dqx_fifo_t;
 
 /**
  * cvmx_pko_dq#_packets
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_PACKETS.
+ *
  */
 union cvmx_pko_dqx_packets {
 	uint64_t u64;
@@ -3143,6 +3296,9 @@ typedef union cvmx_pko_dqx_packets cvmx_pko_dqx_packets_t;
 
 /**
  * cvmx_pko_dq#_pick
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PICK.
+ *
  */
 union cvmx_pko_dqx_pick {
 	uint64_t u64;
@@ -3150,9 +3306,9 @@ union cvmx_pko_dqx_pick {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
-	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
-                                                         result is connected in a flow that extends through the child result, this is the
-                                                         index of that child result. */
+	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this result is
+                                                         connected in a flow that extends through the child result, this is the index of that child
+                                                         result. */
 	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
 	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
 	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
@@ -3189,6 +3345,9 @@ typedef union cvmx_pko_dqx_pick cvmx_pko_dqx_pick_t;
 
 /**
  * cvmx_pko_dq#_pir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ *
  */
 union cvmx_pko_dqx_pir {
 	uint64_t u64;
@@ -3200,8 +3359,14 @@ union cvmx_pko_dqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -3222,6 +3387,9 @@ typedef union cvmx_pko_dqx_pir cvmx_pko_dqx_pir_t;
 
 /**
  * cvmx_pko_dq#_pointers
+ *
+ * This register has the same bit fields as PKO_L4_SQ(0..1023)_POINTERS.
+ *
  */
 union cvmx_pko_dqx_pointers {
 	uint64_t u64;
@@ -3244,6 +3412,9 @@ typedef union cvmx_pko_dqx_pointers cvmx_pko_dqx_pointers_t;
 
 /**
  * cvmx_pko_dq#_sched_state
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SCHED_STATE.
+ *
  */
 union cvmx_pko_dqx_sched_state {
 	uint64_t u64;
@@ -3262,6 +3433,9 @@ typedef union cvmx_pko_dqx_sched_state cvmx_pko_dqx_sched_state_t;
 
 /**
  * cvmx_pko_dq#_schedule
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SCHEDULE.
+ *
  */
 union cvmx_pko_dqx_schedule {
 	uint64_t u64;
@@ -3287,6 +3461,9 @@ typedef union cvmx_pko_dqx_schedule cvmx_pko_dqx_schedule_t;
 
 /**
  * cvmx_pko_dq#_shape
+ *
+ * This register has the same bit fields as PKO_L5_SQ(0..1023)_SHAPE.
+ *
  */
 union cvmx_pko_dqx_shape {
 	uint64_t u64;
@@ -3317,6 +3494,9 @@ typedef union cvmx_pko_dqx_shape cvmx_pko_dqx_shape_t;
 
 /**
  * cvmx_pko_dq#_shape_state
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ *
  */
 union cvmx_pko_dqx_shape_state {
 	uint64_t u64;
@@ -3325,10 +3505,10 @@ union cvmx_pko_dqx_shape_state {
 	uint64_t reserved_60_63               : 4;
 	uint64_t tw_timestamp                 : 6;  /**< Time-wheel timestamp. Debug access to the live time-wheel timestamp. */
 	uint64_t color                        : 2;  /**< Shaper color status. Debug access to the live shaper state.
-                                                         0 = Green - operating in 'committed' range
-                                                         1 = Yellow - operating in 'excess/peak' range
-                                                         2 = Red - operating in 'oversubscribed' range
-                                                         3 = Reserved */
+                                                         0x0 = Green - operating in 'committed' range
+                                                         0x1 = Yellow - operating in 'excess/peak' range
+                                                         0x2 = Red - operating in 'oversubscribed' range
+                                                         0x3 = Reserved */
 	uint64_t pir_accum                    : 26; /**< Peak information rate accumulator. Debug access to the live PIR accumulator. */
 	uint64_t cir_accum                    : 26; /**< Committed information rate accumulator. Debug access to the live CIR accumulator. */
 #else
@@ -3345,6 +3525,9 @@ typedef union cvmx_pko_dqx_shape_state cvmx_pko_dqx_shape_state_t;
 
 /**
  * cvmx_pko_dq#_sw_xoff
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SW_XOFF.
+ *
  */
 union cvmx_pko_dqx_sw_xoff {
 	uint64_t u64;
@@ -3358,10 +3541,10 @@ union cvmx_pko_dqx_sw_xoff {
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
                                                          be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
-	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
+	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is deasserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
-                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configure can result in modifying the software
+                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configured can result in modifying the software
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
@@ -3404,7 +3587,7 @@ union cvmx_pko_dqx_wm_cnt {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t count                        : 48; /**< Watermark count. The running value of the watermark counter. This value is a count of
-                                                         bytes or packets as specified in PKO_DQ(0..1023)_WM_CONTROL[KIND]. */
+                                                         bytes or packets as specified in PKO_DQ(0..1023)_WM_CTL[KIND]. */
 #else
 	uint64_t count                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3423,14 +3606,13 @@ union cvmx_pko_dqx_wm_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
 	uint64_t enable                       : 1;  /**< Watermark enable. */
-	uint64_t kind                         : 1;  /**< Watermark kind. The watermark logic can use a byte count or packet count.
-                                                         0 = Byte count
-                                                         1 = Packet count */
+	uint64_t kind                         : 1;  /**< Watermark kind. The watermark logic can use a byte count or packet count. 0 = Byte count;
+                                                         1 = Packet count. */
 	uint64_t intr                         : 1;  /**< Watermark Interrupt. The interrupt bit is asserted and an interrupt message to the CIU is
                                                          generated when the specified threshold is reached or crossed. Subsequent interrupt
                                                          messages are only generated after this bit has been cleared. */
 	uint64_t threshold                    : 48; /**< Watermark Threshold. This threshold is compared to the watermark count of
-                                                         PKO_DQ(0..1023)_WM_COUNT[COUNT] and an interrupt is generated when the count reaches or
+                                                         PKO_DQ(0..1023)_WM_CNT[COUNT] and an interrupt is generated when the count reaches or
                                                          crosses the threshold. */
 #else
 	uint64_t threshold                    : 48;
@@ -3467,6 +3649,22 @@ union cvmx_pko_dqx_wm_ctl_w1c {
 typedef union cvmx_pko_dqx_wm_ctl_w1c cvmx_pko_dqx_wm_ctl_w1c_t;
 
 /**
+ * cvmx_pko_dq_csr_bus_debug
+ */
+union cvmx_pko_dq_csr_bus_debug {
+	uint64_t u64;
+	struct cvmx_pko_dq_csr_bus_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t csr_bus_debug                : 64; /**< -- */
+#else
+	uint64_t csr_bus_debug                : 64;
+#endif
+	} s;
+	struct cvmx_pko_dq_csr_bus_debug_s    cn78xx;
+};
+typedef union cvmx_pko_dq_csr_bus_debug cvmx_pko_dq_csr_bus_debug_t;
+
+/**
  * cvmx_pko_dq_debug
  */
 union cvmx_pko_dq_debug {
@@ -3492,8 +3690,8 @@ union cvmx_pko_drain_irq {
 	uint64_t reserved_1_63                : 63;
 	uint64_t intr                         : 1;  /**< Interrupt. The interrupt bit is asserted and an interrupt message to the CIU is generated
                                                          when the DRAIN command reaches the PQ level. Subsequent interrupt messages are only
-                                                         generated
-                                                         after this bit has been cleared by writing 1. Throws PKO_INTSN_E::PKO_PSE_PQ_DRAIN. */
+                                                         generated after this bit has been cleared by writing 1. Throws
+                                                         PKO_INTSN_E::PKO_PSE_PQ_DRAIN. */
 #else
 	uint64_t intr                         : 1;
 	uint64_t reserved_1_63                : 63;
@@ -3562,8 +3760,14 @@ union cvmx_pko_l1_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -3584,6 +3788,9 @@ typedef union cvmx_pko_l1_sqx_cir cvmx_pko_l1_sqx_cir_t;
 
 /**
  * cvmx_pko_l1_sq#_dropped_bytes
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_BYTES.
+ *
  */
 union cvmx_pko_l1_sqx_dropped_bytes {
 	uint64_t u64;
@@ -3602,6 +3809,9 @@ typedef union cvmx_pko_l1_sqx_dropped_bytes cvmx_pko_l1_sqx_dropped_bytes_t;
 
 /**
  * cvmx_pko_l1_sq#_dropped_packets
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_PACKETS.
+ *
  */
 union cvmx_pko_l1_sqx_dropped_packets {
 	uint64_t u64;
@@ -3693,19 +3903,18 @@ union cvmx_pko_l1_sqx_link {
 	uint64_t reserved_49_63               : 15;
 	uint64_t link                         : 5;  /**< Link index. Must match PKO_L1_SQ(0..31)_TOPOLOGY[LINK]. */
 	uint64_t reserved_32_43               : 12;
-	uint64_t cc_word_cnt                  : 20; /**< Channel credit word count.
-                                                         This value, plus 1 MTU, represents the maximum outstanding aggregate word count (words are
-                                                         16 bytes) for all channels feeding into this PQ.
-                                                         Note that this 20-bit field represents a signed value that decrements towards zero as
-                                                         credits are used. Packets are not allowed to flow when the count is less than zero. As
-                                                         such, the most significant bit should normally be programmed as zero (positive count).
-                                                         This gives a maximum value for this field of 2^19 - 1. */
+	uint64_t cc_word_cnt                  : 20; /**< Channel credit word count. This value, plus 1 MTU, represents the maximum outstanding
+                                                         aggregate word count (words are 16 bytes) for all channels feeding into this PQ. Note that
+                                                         this 20-bit field represents a signed value that decrements towards zero as credits are
+                                                         used. Packets are not allowed to flow when the count is less than zero. As such, the most
+                                                         significant bit should normally be programmed as zero (positive count). This gives a
+                                                         maximum value for this field of 2^19 - 1. */
 	uint64_t cc_packet_cnt                : 10; /**< Channel credit packet count. This value, plus 1, represents the maximum outstanding
-                                                         aggregate packet count for all channels feeding into this PQ.
-                                                         Note that this 10-bit field represents a signed value that decrements towards zero as
-                                                         credits are used. Packets are not allowed to flow when the count is less than zero. As
-                                                         such the most significant bit should normally be programmed as zero (positive count). This
-                                                         gives a maximum value for this field of 2^9 - 1. */
+                                                         aggregate packet count for all channels feeding into this PQ. Note that this 10-bit field
+                                                         represents a signed value that decrements towards zero as credits are used. Packets are
+                                                         not allowed to flow when the count is less than zero. As such the most significant bit
+                                                         should normally be programmed as zero (positive count). This gives a maximum value for
+                                                         this field of 2^9 - 1. */
 	uint64_t cc_enable                    : 1;  /**< Channel credit enable. Enables CC_WORD_CNT and CC_PACKET_CNT aggregate credit processing. */
 	uint64_t reserved_0_0                 : 1;
 #else
@@ -3731,9 +3940,9 @@ union cvmx_pko_l1_sqx_pick {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
-	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
-                                                         result is connected in a flow that extends through the child result, this is the
-                                                         index of that child result. */
+	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this result is
+                                                         connected in a flow that extends through the child result, this is the index of that child
+                                                         result. */
 	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
 	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
 	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
@@ -3770,6 +3979,9 @@ typedef union cvmx_pko_l1_sqx_pick cvmx_pko_l1_sqx_pick_t;
 
 /**
  * cvmx_pko_l1_sq#_pir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
+ *
  */
 union cvmx_pko_l1_sqx_pir {
 	uint64_t u64;
@@ -3781,8 +3993,14 @@ union cvmx_pko_l1_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -3803,6 +4021,9 @@ typedef union cvmx_pko_l1_sqx_pir cvmx_pko_l1_sqx_pir_t;
 
 /**
  * cvmx_pko_l1_sq#_red
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_YELLOW.
+ *
  */
 union cvmx_pko_l1_sqx_red {
 	uint64_t u64;
@@ -3825,6 +4046,9 @@ typedef union cvmx_pko_l1_sqx_red cvmx_pko_l1_sqx_red_t;
 
 /**
  * cvmx_pko_l1_sq#_red_bytes
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_BYTES.
+ *
  */
 union cvmx_pko_l1_sqx_red_bytes {
 	uint64_t u64;
@@ -3843,6 +4067,9 @@ typedef union cvmx_pko_l1_sqx_red_bytes cvmx_pko_l1_sqx_red_bytes_t;
 
 /**
  * cvmx_pko_l1_sq#_red_packets
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_PACKETS.
+ *
  */
 union cvmx_pko_l1_sqx_red_packets {
 	uint64_t u64;
@@ -3866,13 +4093,13 @@ union cvmx_pko_l1_sqx_shape {
 	uint64_t u64;
 	struct cvmx_pko_l1_sqx_shape_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_17_63               : 47;
-	uint64_t link                         : 4;  /**< Link index. Must match PKO_L1_SQ(0..31)_TOPOLOGY[LINK]. */
+	uint64_t reserved_18_63               : 46;
+	uint64_t link                         : 5;  /**< Link index. Must match PKO_L1_SQ(0..31)_TOPOLOGY[LINK]. */
 	uint64_t reserved_0_12                : 13;
 #else
 	uint64_t reserved_0_12                : 13;
-	uint64_t link                         : 4;
-	uint64_t reserved_17_63               : 47;
+	uint64_t link                         : 5;
+	uint64_t reserved_18_63               : 46;
 #endif
 	} s;
 	struct cvmx_pko_l1_sqx_shape_s        cn78xx;
@@ -3889,10 +4116,10 @@ union cvmx_pko_l1_sqx_shape_state {
 	uint64_t reserved_60_63               : 4;
 	uint64_t tw_timestamp                 : 6;  /**< Time-wheel timestamp. Debug access to the live time-wheel timestamp. */
 	uint64_t color                        : 2;  /**< Shaper color status. Debug access to the live shaper state.
-                                                         0 = Green - operating in 'committed' range
-                                                         1 = Yellow - operating in 'excess/peak' range
-                                                         2 = Red - operating in 'oversubscribed' range
-                                                         3 = Reserved */
+                                                         0x0 = Green - operating in 'committed' range
+                                                         0x1 = Yellow - operating in 'excess/peak' range
+                                                         0x2 = Red - operating in 'oversubscribed' range
+                                                         0x3 = Reserved */
 	uint64_t pir_accum                    : 26; /**< Peak information rate accumulator. Debug access to the live PIR accumulator. */
 	uint64_t cir_accum                    : 26; /**< Committed information rate accumulator. Debug access to the live CIR accumulator. */
 #else
@@ -3922,10 +4149,10 @@ union cvmx_pko_l1_sqx_sw_xoff {
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
                                                          be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
-	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
+	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is deasserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
-                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configure can result in modifying the software
+                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configured can result in modifying the software
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
@@ -3947,33 +4174,28 @@ union cvmx_pko_l1_sqx_topology {
 	struct cvmx_pko_l1_sqx_topology_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_41_63               : 23;
-	uint64_t prio_anchor                  : 9;  /**< Priority Anchor. The base index positioning the static priority child
-                                                         queues of this shaper. A higher-level queue is a child queue of this
-                                                         shaper when its PKO_*_TOPOLOGY[PARENT] selects this shaper, and it
-                                                         further is a static priority child queue when its
-                                                         PKO_*_SQn_SCHEDULE[PRIO] does not equal RR_PRIO.
-                                                         A static priority child queue with priority PRIO must be located at
-                                                         n=PRIO_ANCHOR+PRIO, where PRIO=PKO_*_SQn_SCHEDULE[PRIO].
-                                                         There can be at most one static priority child queue at each
-                                                         priority. When there are no static priority child queues attached
-                                                         at any priority, or if this shaper isn't used, the hardware does
-                                                         not use PRIO_ANCHOR. In this case, we recommend PRIO_ANCHOR be
-                                                         zero. */
+	uint64_t prio_anchor                  : 9;  /**< Priority Anchor. The base index positioning the static priority child queues of this
+                                                         shaper. A higher-level queue is a child queue of this shaper when its
+                                                         PKO_*_TOPOLOGY[PARENT] selects this shaper, and it further is a static priority child
+                                                         queue when its PKO_*_SQn_SCHEDULE[PRIO] does not equal RR_PRIO. A static priority child
+                                                         queue with priority PRIO must be located at n=PRIO_ANCHOR+PRIO, where
+                                                         PRIO=PKO_*_SQn_SCHEDULE[PRIO]. There can be at most one static priority child queue at
+                                                         each priority. When there are no static priority child queues attached at any priority, or
+                                                         if this shaper isn't used, the hardware does not use PRIO_ANCHOR. In this case, we
+                                                         recommend PRIO_ANCHOR be zero. Note that there are 10 available priorities, 0 through 9,
+                                                         with priority 0 being the highest and priority 9 being the lowest. */
 	uint64_t reserved_21_31               : 11;
 	uint64_t link                         : 5;  /**< Link index. Index of the link associated with this port queue. */
 	uint64_t reserved_5_15                : 11;
-	uint64_t rr_prio                      : 4;  /**< Round-robin priority. The priority assigned to the round-robin scheduler.
-                                                         A higher-level queue is a child queue of this shaper when its
-                                                         PKO_*_TOPOLOGY[PARENT] selects this shaper, and it further is a
-                                                         round robin child queue when its PKO_*_SQn_SCHEDULE[PRIO] equals
-                                                         RR_PRIO. All round-robin queues attached to this shaper must
-                                                         have the same priority. But the number of round-robin child queues
-                                                         attached (at this priority) is limited only by the number of
-                                                         higher-level queues. When this shaper is not used, we recommend
-                                                         RR_PRIO be zero. When a shaper is used, RR_PRIO should be 0xF
-                                                         when there are no priorities with more than one child
-                                                         queue (i.e. when there are no round-robin child queues), and
-                                                         should otherwise be a legal priority (values 0-9). */
+	uint64_t rr_prio                      : 4;  /**< Round-robin priority. The priority assigned to the round-robin scheduler. A higher-level
+                                                         queue is a child queue of this shaper when its PKO_*_TOPOLOGY[PARENT] selects this shaper,
+                                                         and it further is a round robin child queue when its PKO_*_SQn_SCHEDULE[PRIO] equals
+                                                         RR_PRIO. All round-robin queues attached to this shaper must have the same priority. But
+                                                         the number of round-robin child queues attached (at this priority) is limited only by the
+                                                         number of higher-level queues. When this shaper is not used, we recommend RR_PRIO be zero.
+                                                         When a shaper is used, RR_PRIO should be 0xF when there are no priorities with more than
+                                                         one child queue (i.e. when there are no round-robin child queues), and should otherwise be
+                                                         a legal priority (values 0-9). */
 	uint64_t reserved_0_0                 : 1;
 #else
 	uint64_t reserved_0_0                 : 1;
@@ -4013,6 +4235,9 @@ typedef union cvmx_pko_l1_sqx_yellow cvmx_pko_l1_sqx_yellow_t;
 
 /**
  * cvmx_pko_l1_sq#_yellow_bytes
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_BYTES.
+ *
  */
 union cvmx_pko_l1_sqx_yellow_bytes {
 	uint64_t u64;
@@ -4031,6 +4256,9 @@ typedef union cvmx_pko_l1_sqx_yellow_bytes cvmx_pko_l1_sqx_yellow_bytes_t;
 
 /**
  * cvmx_pko_l1_sq#_yellow_packets
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN_PACKETS.
+ *
  */
 union cvmx_pko_l1_sqx_yellow_packets {
 	uint64_t u64;
@@ -4048,7 +4276,26 @@ union cvmx_pko_l1_sqx_yellow_packets {
 typedef union cvmx_pko_l1_sqx_yellow_packets cvmx_pko_l1_sqx_yellow_packets_t;
 
 /**
+ * cvmx_pko_l1_sq_csr_bus_debug
+ */
+union cvmx_pko_l1_sq_csr_bus_debug {
+	uint64_t u64;
+	struct cvmx_pko_l1_sq_csr_bus_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t csr_bus_debug                : 64; /**< -- */
+#else
+	uint64_t csr_bus_debug                : 64;
+#endif
+	} s;
+	struct cvmx_pko_l1_sq_csr_bus_debug_s cn78xx;
+};
+typedef union cvmx_pko_l1_sq_csr_bus_debug cvmx_pko_l1_sq_csr_bus_debug_t;
+
+/**
  * cvmx_pko_l1_sqa_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l1_sqa_debug {
 	uint64_t u64;
@@ -4065,6 +4312,9 @@ typedef union cvmx_pko_l1_sqa_debug cvmx_pko_l1_sqa_debug_t;
 
 /**
  * cvmx_pko_l1_sqb_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l1_sqb_debug {
 	uint64_t u64;
@@ -4081,6 +4331,9 @@ typedef union cvmx_pko_l1_sqb_debug cvmx_pko_l1_sqb_debug_t;
 
 /**
  * cvmx_pko_l2_sq#_cir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
+ *
  */
 union cvmx_pko_l2_sqx_cir {
 	uint64_t u64;
@@ -4092,8 +4345,14 @@ union cvmx_pko_l2_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -4114,6 +4373,9 @@ typedef union cvmx_pko_l2_sqx_cir cvmx_pko_l2_sqx_cir_t;
 
 /**
  * cvmx_pko_l2_sq#_green
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_GREEN.
+ *
  */
 union cvmx_pko_l2_sqx_green {
 	uint64_t u64;
@@ -4143,6 +4405,9 @@ typedef union cvmx_pko_l2_sqx_green cvmx_pko_l2_sqx_green_t;
 
 /**
  * cvmx_pko_l2_sq#_pick
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PICK.
+ *
  */
 union cvmx_pko_l2_sqx_pick {
 	uint64_t u64;
@@ -4150,9 +4415,9 @@ union cvmx_pko_l2_sqx_pick {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
-	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
-                                                         result is connected in a flow that extends through the child result, this is the
-                                                         index of that child result. */
+	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this result is
+                                                         connected in a flow that extends through the child result, this is the index of that child
+                                                         result. */
 	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
 	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
 	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
@@ -4189,6 +4454,9 @@ typedef union cvmx_pko_l2_sqx_pick cvmx_pko_l2_sqx_pick_t;
 
 /**
  * cvmx_pko_l2_sq#_pir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ *
  */
 union cvmx_pko_l2_sqx_pir {
 	uint64_t u64;
@@ -4200,8 +4468,14 @@ union cvmx_pko_l2_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -4244,6 +4518,9 @@ typedef union cvmx_pko_l2_sqx_pointers cvmx_pko_l2_sqx_pointers_t;
 
 /**
  * cvmx_pko_l2_sq#_red
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_RED.
+ *
  */
 union cvmx_pko_l2_sqx_red {
 	uint64_t u64;
@@ -4322,11 +4599,11 @@ union cvmx_pko_l2_sqx_shape {
 	uint64_t red_disable                  : 1;  /**< Disable red transitions. Disables green-to-red and yellow-to-red packet color marking
                                                          transitions when set. */
 	uint64_t red_algo                     : 2;  /**< Shaper red state algorithm.
-                                                         0 = Stall packets while in RED state until YELLOW or GREEN state is reached (aka never
+                                                         0x0 = Stall packets while in RED state until YELLOW or GREEN state is reached (aka never
                                                          send RED packets).
-                                                         1 = Send packets while in RED state.
-                                                         2 = Same as 0 above (stall).
-                                                         3 = Discard packets while in RED state (red packets are converted to drop packets). */
+                                                         0x1 = Send packets while in RED state.
+                                                         0x2 = Same as 0 above (stall).
+                                                         0x3 = Discard packets while in RED state (red packets are converted to drop packets). */
 	uint64_t adjust                       : 9;  /**< Shaping calculation adjustment. This 9-bit signed values allows +/- 256 bytes to be added
                                                          to the packet length for the shaping calculations. */
 #else
@@ -4345,6 +4622,9 @@ typedef union cvmx_pko_l2_sqx_shape cvmx_pko_l2_sqx_shape_t;
 
 /**
  * cvmx_pko_l2_sq#_shape_state
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ *
  */
 union cvmx_pko_l2_sqx_shape_state {
 	uint64_t u64;
@@ -4353,10 +4633,10 @@ union cvmx_pko_l2_sqx_shape_state {
 	uint64_t reserved_60_63               : 4;
 	uint64_t tw_timestamp                 : 6;  /**< Time-wheel timestamp. Debug access to the live time-wheel timestamp. */
 	uint64_t color                        : 2;  /**< Shaper color status. Debug access to the live shaper state.
-                                                         0 = Green - operating in 'committed' range
-                                                         1 = Yellow - operating in 'excess/peak' range
-                                                         2 = Red - operating in 'oversubscribed' range
-                                                         3 = Reserved */
+                                                         0x0 = Green - operating in 'committed' range
+                                                         0x1 = Yellow - operating in 'excess/peak' range
+                                                         0x2 = Red - operating in 'oversubscribed' range
+                                                         0x3 = Reserved */
 	uint64_t pir_accum                    : 26; /**< Peak information rate accumulator. Debug access to the live PIR accumulator. */
 	uint64_t cir_accum                    : 26; /**< Committed information rate accumulator. Debug access to the live CIR accumulator. */
 #else
@@ -4373,6 +4653,9 @@ typedef union cvmx_pko_l2_sqx_shape_state cvmx_pko_l2_sqx_shape_state_t;
 
 /**
  * cvmx_pko_l2_sq#_sw_xoff
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SW_XOFF.
+ *
  */
 union cvmx_pko_l2_sqx_sw_xoff {
 	uint64_t u64;
@@ -4386,10 +4669,10 @@ union cvmx_pko_l2_sqx_sw_xoff {
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
                                                          be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
-	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
+	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is deasserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
-                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configure can result in modifying the software
+                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configured can result in modifying the software
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
@@ -4414,10 +4697,10 @@ union cvmx_pko_l2_sqx_topology {
 	uint64_t prio_anchor                  : 9;  /**< See PKO_L1_SQ(0..31)_TOPOLOGY[PRIO_ANCHOR]. */
 	uint64_t reserved_21_31               : 11;
 	uint64_t parent                       : 5;  /**< Parent queue index. The index of the shaping element at the next lower hierarchical level
-                                                         that accepts this shaping element's outputs. Refer to the
-                                                         PKO_*_SQn_TOPOLOGY[PRIO_ANCHOR,RR_PRIO] descriptions for constraints on which child queues
-                                                         can attach to which shapers at the next lower level. When this shaper is unused, we
-                                                         recommend that PARENT be zero. */
+                                                         that accepts this shaping element's outputs. Refer to the PKO_*_SQn_TOPOLOGY
+                                                         [PRIO_ANCHOR,RR_PRIO] descriptions for constraints on which child queues can attach to
+                                                         which shapers at the next lower level. When this shaper is unused, we recommend that
+                                                         PARENT be zero. */
 	uint64_t reserved_5_15                : 11;
 	uint64_t rr_prio                      : 4;  /**< See PKO_L1_SQ(0..31)_TOPOLOGY[RR_PRIO]. */
 	uint64_t reserved_0_0                 : 1;
@@ -4437,6 +4720,9 @@ typedef union cvmx_pko_l2_sqx_topology cvmx_pko_l2_sqx_topology_t;
 
 /**
  * cvmx_pko_l2_sq#_yellow
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_YELLOW.
+ *
  */
 union cvmx_pko_l2_sqx_yellow {
 	uint64_t u64;
@@ -4458,7 +4744,26 @@ union cvmx_pko_l2_sqx_yellow {
 typedef union cvmx_pko_l2_sqx_yellow cvmx_pko_l2_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l2_sq_csr_bus_debug
+ */
+union cvmx_pko_l2_sq_csr_bus_debug {
+	uint64_t u64;
+	struct cvmx_pko_l2_sq_csr_bus_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t csr_bus_debug                : 64; /**< -- */
+#else
+	uint64_t csr_bus_debug                : 64;
+#endif
+	} s;
+	struct cvmx_pko_l2_sq_csr_bus_debug_s cn78xx;
+};
+typedef union cvmx_pko_l2_sq_csr_bus_debug cvmx_pko_l2_sq_csr_bus_debug_t;
+
+/**
  * cvmx_pko_l2_sqa_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l2_sqa_debug {
 	uint64_t u64;
@@ -4475,6 +4780,9 @@ typedef union cvmx_pko_l2_sqa_debug cvmx_pko_l2_sqa_debug_t;
 
 /**
  * cvmx_pko_l2_sqb_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l2_sqb_debug {
 	uint64_t u64;
@@ -4505,11 +4813,10 @@ union cvmx_pko_l3_l2_sqx_channel {
                                                          be programmed as zero (positive count). This gives a maximum value for this field of 2^18
                                                          - 1. */
 	uint64_t cc_packet_cnt                : 10; /**< Channel credit packet count. This value, plus 1, represents the maximum outstanding packet
-                                                         count for this channel.
-                                                         Note that this 10-bit field represents a signed value that decrements towards zero as
-                                                         credits are used. Packets are not allowed to flow when the count is less than zero. As
-                                                         such the most significant bit should normally be programmed as zero (positive count). This
-                                                         gives a maximum value for this field of 2^9 - 1. */
+                                                         count for this channel. Note that this 10-bit field represents a signed value that
+                                                         decrements towards zero as credits are used. Packets are not allowed to flow when the
+                                                         count is less than zero. As such the most significant bit should normally be programmed as
+                                                         zero (positive count). This gives a maximum value for this field of 2^9 - 1. */
 	uint64_t cc_enable                    : 1;  /**< Channel credit enable. Enables CC_WORD_CNT and CC_PACKET_CNT credit processing. */
 	uint64_t hw_xoff                      : 1;  /**< Hardware XOFF status. The status of hardware XON/XOFF. This is writable to get around LUT
                                                          issues and for reconfiguration. */
@@ -4528,6 +4835,9 @@ typedef union cvmx_pko_l3_l2_sqx_channel cvmx_pko_l3_l2_sqx_channel_t;
 
 /**
  * cvmx_pko_l3_sq#_cir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
+ *
  */
 union cvmx_pko_l3_sqx_cir {
 	uint64_t u64;
@@ -4539,8 +4849,14 @@ union cvmx_pko_l3_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -4586,6 +4902,9 @@ typedef union cvmx_pko_l3_sqx_green cvmx_pko_l3_sqx_green_t;
 
 /**
  * cvmx_pko_l3_sq#_pick
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PICK.
+ *
  */
 union cvmx_pko_l3_sqx_pick {
 	uint64_t u64;
@@ -4593,9 +4912,9 @@ union cvmx_pko_l3_sqx_pick {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
-	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
-                                                         result is connected in a flow that extends through the child result, this is the
-                                                         index of that child result. */
+	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this result is
+                                                         connected in a flow that extends through the child result, this is the index of that child
+                                                         result. */
 	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
 	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
 	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
@@ -4632,6 +4951,9 @@ typedef union cvmx_pko_l3_sqx_pick cvmx_pko_l3_sqx_pick_t;
 
 /**
  * cvmx_pko_l3_sq#_pir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ *
  */
 union cvmx_pko_l3_sqx_pir {
 	uint64_t u64;
@@ -4643,8 +4965,14 @@ union cvmx_pko_l3_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -4665,6 +4993,9 @@ typedef union cvmx_pko_l3_sqx_pir cvmx_pko_l3_sqx_pir_t;
 
 /**
  * cvmx_pko_l3_sq#_pointers
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_POINTERS.
+ *
  */
 union cvmx_pko_l3_sqx_pointers {
 	uint64_t u64;
@@ -4687,6 +5018,9 @@ typedef union cvmx_pko_l3_sqx_pointers cvmx_pko_l3_sqx_pointers_t;
 
 /**
  * cvmx_pko_l3_sq#_red
+ *
+ * This register has the same bit fields as PKO_L3_SQ(0..511)_YELLOW.
+ *
  */
 union cvmx_pko_l3_sqx_red {
 	uint64_t u64;
@@ -4707,6 +5041,9 @@ typedef union cvmx_pko_l3_sqx_red cvmx_pko_l3_sqx_red_t;
 
 /**
  * cvmx_pko_l3_sq#_sched_state
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SCHED_STATE.
+ *
  */
 union cvmx_pko_l3_sqx_sched_state {
 	uint64_t u64;
@@ -4725,6 +5062,9 @@ typedef union cvmx_pko_l3_sqx_sched_state cvmx_pko_l3_sqx_sched_state_t;
 
 /**
  * cvmx_pko_l3_sq#_schedule
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SCHEDULE.
+ *
  */
 union cvmx_pko_l3_sqx_schedule {
 	uint64_t u64;
@@ -4780,6 +5120,9 @@ typedef union cvmx_pko_l3_sqx_shape cvmx_pko_l3_sqx_shape_t;
 
 /**
  * cvmx_pko_l3_sq#_shape_state
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ *
  */
 union cvmx_pko_l3_sqx_shape_state {
 	uint64_t u64;
@@ -4788,10 +5131,10 @@ union cvmx_pko_l3_sqx_shape_state {
 	uint64_t reserved_60_63               : 4;
 	uint64_t tw_timestamp                 : 6;  /**< Time-wheel timestamp. Debug access to the live time-wheel timestamp. */
 	uint64_t color                        : 2;  /**< Shaper color status. Debug access to the live shaper state.
-                                                         0 = Green - operating in 'committed' range
-                                                         1 = Yellow - operating in 'excess/peak' range
-                                                         2 = Red - operating in 'oversubscribed' range
-                                                         3 = Reserved */
+                                                         0x0 = Green - operating in 'committed' range
+                                                         0x1 = Yellow - operating in 'excess/peak' range
+                                                         0x2 = Red - operating in 'oversubscribed' range
+                                                         0x3 = Reserved */
 	uint64_t pir_accum                    : 26; /**< Peak information rate accumulator. Debug access to the live PIR accumulator. */
 	uint64_t cir_accum                    : 26; /**< Committed information rate accumulator. Debug access to the live CIR accumulator. */
 #else
@@ -4808,6 +5151,9 @@ typedef union cvmx_pko_l3_sqx_shape_state cvmx_pko_l3_sqx_shape_state_t;
 
 /**
  * cvmx_pko_l3_sq#_sw_xoff
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SW_XOFF
+ *
  */
 union cvmx_pko_l3_sqx_sw_xoff {
 	uint64_t u64;
@@ -4821,10 +5167,10 @@ union cvmx_pko_l3_sqx_sw_xoff {
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
                                                          be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
-	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
+	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is deasserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
-                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configure can result in modifying the software
+                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configured can result in modifying the software
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
@@ -4887,7 +5233,26 @@ union cvmx_pko_l3_sqx_yellow {
 typedef union cvmx_pko_l3_sqx_yellow cvmx_pko_l3_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l3_sq_csr_bus_debug
+ */
+union cvmx_pko_l3_sq_csr_bus_debug {
+	uint64_t u64;
+	struct cvmx_pko_l3_sq_csr_bus_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t csr_bus_debug                : 64; /**< -- */
+#else
+	uint64_t csr_bus_debug                : 64;
+#endif
+	} s;
+	struct cvmx_pko_l3_sq_csr_bus_debug_s cn78xx;
+};
+typedef union cvmx_pko_l3_sq_csr_bus_debug cvmx_pko_l3_sq_csr_bus_debug_t;
+
+/**
  * cvmx_pko_l3_sqa_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l3_sqa_debug {
 	uint64_t u64;
@@ -4904,6 +5269,9 @@ typedef union cvmx_pko_l3_sqa_debug cvmx_pko_l3_sqa_debug_t;
 
 /**
  * cvmx_pko_l3_sqb_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l3_sqb_debug {
 	uint64_t u64;
@@ -4920,6 +5288,9 @@ typedef union cvmx_pko_l3_sqb_debug cvmx_pko_l3_sqb_debug_t;
 
 /**
  * cvmx_pko_l4_sq#_cir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
+ *
  */
 union cvmx_pko_l4_sqx_cir {
 	uint64_t u64;
@@ -4931,8 +5302,14 @@ union cvmx_pko_l4_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -4953,6 +5330,9 @@ typedef union cvmx_pko_l4_sqx_cir cvmx_pko_l4_sqx_cir_t;
 
 /**
  * cvmx_pko_l4_sq#_green
+ *
+ * This register has the same bit fields as PKO_L3_SQ(0..511)_GREEN.
+ *
  */
 union cvmx_pko_l4_sqx_green {
 	uint64_t u64;
@@ -4978,6 +5358,9 @@ typedef union cvmx_pko_l4_sqx_green cvmx_pko_l4_sqx_green_t;
 
 /**
  * cvmx_pko_l4_sq#_pick
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PICK.
+ *
  */
 union cvmx_pko_l4_sqx_pick {
 	uint64_t u64;
@@ -4985,9 +5368,9 @@ union cvmx_pko_l4_sqx_pick {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
-	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
-                                                         result is connected in a flow that extends through the child result, this is the
-                                                         index of that child result. */
+	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this result is
+                                                         connected in a flow that extends through the child result, this is the index of that child
+                                                         result. */
 	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
 	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
 	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
@@ -5024,6 +5407,9 @@ typedef union cvmx_pko_l4_sqx_pick cvmx_pko_l4_sqx_pick_t;
 
 /**
  * cvmx_pko_l4_sq#_pir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ *
  */
 union cvmx_pko_l4_sqx_pir {
 	uint64_t u64;
@@ -5035,8 +5421,14 @@ union cvmx_pko_l4_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -5079,6 +5471,9 @@ typedef union cvmx_pko_l4_sqx_pointers cvmx_pko_l4_sqx_pointers_t;
 
 /**
  * cvmx_pko_l4_sq#_red
+ *
+ * This register has the same bit fields as PKO_L3_SQ(0..511)_YELLOW.
+ *
  */
 union cvmx_pko_l4_sqx_red {
 	uint64_t u64;
@@ -5099,6 +5494,9 @@ typedef union cvmx_pko_l4_sqx_red cvmx_pko_l4_sqx_red_t;
 
 /**
  * cvmx_pko_l4_sq#_sched_state
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SCHED_STATE.
+ *
  */
 union cvmx_pko_l4_sqx_sched_state {
 	uint64_t u64;
@@ -5117,6 +5515,9 @@ typedef union cvmx_pko_l4_sqx_sched_state cvmx_pko_l4_sqx_sched_state_t;
 
 /**
  * cvmx_pko_l4_sq#_schedule
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SCHEDULE.
+ *
  */
 union cvmx_pko_l4_sqx_schedule {
 	uint64_t u64;
@@ -5142,6 +5543,9 @@ typedef union cvmx_pko_l4_sqx_schedule cvmx_pko_l4_sqx_schedule_t;
 
 /**
  * cvmx_pko_l4_sq#_shape
+ *
+ * This register has the same bit fields as PKO_L3_SQ(0..511)_SHAPE.
+ *
  */
 union cvmx_pko_l4_sqx_shape {
 	uint64_t u64;
@@ -5172,6 +5576,9 @@ typedef union cvmx_pko_l4_sqx_shape cvmx_pko_l4_sqx_shape_t;
 
 /**
  * cvmx_pko_l4_sq#_shape_state
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ *
  */
 union cvmx_pko_l4_sqx_shape_state {
 	uint64_t u64;
@@ -5180,10 +5587,10 @@ union cvmx_pko_l4_sqx_shape_state {
 	uint64_t reserved_60_63               : 4;
 	uint64_t tw_timestamp                 : 6;  /**< Time-wheel timestamp. Debug access to the live time-wheel timestamp. */
 	uint64_t color                        : 2;  /**< Shaper color status. Debug access to the live shaper state.
-                                                         0 = Green - operating in 'committed' range
-                                                         1 = Yellow - operating in 'excess/peak' range
-                                                         2 = Red - operating in 'oversubscribed' range
-                                                         3 = Reserved */
+                                                         0x0 = Green - operating in 'committed' range
+                                                         0x1 = Yellow - operating in 'excess/peak' range
+                                                         0x2 = Red - operating in 'oversubscribed' range
+                                                         0x3 = Reserved */
 	uint64_t pir_accum                    : 26; /**< Peak information rate accumulator. Debug access to the live PIR accumulator. */
 	uint64_t cir_accum                    : 26; /**< Committed information rate accumulator. Debug access to the live CIR accumulator. */
 #else
@@ -5200,6 +5607,9 @@ typedef union cvmx_pko_l4_sqx_shape_state cvmx_pko_l4_sqx_shape_state_t;
 
 /**
  * cvmx_pko_l4_sq#_sw_xoff
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SW_XOFF.
+ *
  */
 union cvmx_pko_l4_sqx_sw_xoff {
 	uint64_t u64;
@@ -5213,10 +5623,10 @@ union cvmx_pko_l4_sqx_sw_xoff {
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
                                                          be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
-	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
+	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is deasserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
-                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configure can result in modifying the software
+                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configured can result in modifying the software
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
@@ -5260,6 +5670,9 @@ typedef union cvmx_pko_l4_sqx_topology cvmx_pko_l4_sqx_topology_t;
 
 /**
  * cvmx_pko_l4_sq#_yellow
+ *
+ * This register has the same bit fields as PKO_L3_SQ(0..511)_YELLOW.
+ *
  */
 union cvmx_pko_l4_sqx_yellow {
 	uint64_t u64;
@@ -5279,7 +5692,26 @@ union cvmx_pko_l4_sqx_yellow {
 typedef union cvmx_pko_l4_sqx_yellow cvmx_pko_l4_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l4_sq_csr_bus_debug
+ */
+union cvmx_pko_l4_sq_csr_bus_debug {
+	uint64_t u64;
+	struct cvmx_pko_l4_sq_csr_bus_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t csr_bus_debug                : 64; /**< -- */
+#else
+	uint64_t csr_bus_debug                : 64;
+#endif
+	} s;
+	struct cvmx_pko_l4_sq_csr_bus_debug_s cn78xx;
+};
+typedef union cvmx_pko_l4_sq_csr_bus_debug cvmx_pko_l4_sq_csr_bus_debug_t;
+
+/**
  * cvmx_pko_l4_sqa_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l4_sqa_debug {
 	uint64_t u64;
@@ -5296,6 +5728,9 @@ typedef union cvmx_pko_l4_sqa_debug cvmx_pko_l4_sqa_debug_t;
 
 /**
  * cvmx_pko_l4_sqb_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l4_sqb_debug {
 	uint64_t u64;
@@ -5312,6 +5747,9 @@ typedef union cvmx_pko_l4_sqb_debug cvmx_pko_l4_sqb_debug_t;
 
 /**
  * cvmx_pko_l5_sq#_cir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
+ *
  */
 union cvmx_pko_l5_sqx_cir {
 	uint64_t u64;
@@ -5323,8 +5761,14 @@ union cvmx_pko_l5_sqx_cir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -5345,6 +5789,9 @@ typedef union cvmx_pko_l5_sqx_cir cvmx_pko_l5_sqx_cir_t;
 
 /**
  * cvmx_pko_l5_sq#_green
+ *
+ * This register has the same bit fields as PKO_L3_SQ(0..511)_GREEN.
+ *
  */
 union cvmx_pko_l5_sqx_green {
 	uint64_t u64;
@@ -5370,6 +5817,9 @@ typedef union cvmx_pko_l5_sqx_green cvmx_pko_l5_sqx_green_t;
 
 /**
  * cvmx_pko_l5_sq#_pick
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PICK.
+ *
  */
 union cvmx_pko_l5_sqx_pick {
 	uint64_t u64;
@@ -5377,9 +5827,9 @@ union cvmx_pko_l5_sqx_pick {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t dq                           : 10; /**< Descriptor queue. Index of originating descriptor queue. */
 	uint64_t color                        : 2;  /**< See PKO_L2_SQ(0..511)_SHAPE[COLOR]. */
-	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this
-                                                         result is connected in a flow that extends through the child result, this is the
-                                                         index of that child result. */
+	uint64_t child                        : 10; /**< Child index. When the C_CON bit of this result is set, indicating that this result is
+                                                         connected in a flow that extends through the child result, this is the index of that child
+                                                         result. */
 	uint64_t bubble                       : 1;  /**< This metapacket is a fake passed forward after a prune. */
 	uint64_t p_con                        : 1;  /**< Parent connected flag. This pick has more picks in front of it. */
 	uint64_t c_con                        : 1;  /**< Child connected flag. This pick has more picks behind it. */
@@ -5416,6 +5866,9 @@ typedef union cvmx_pko_l5_sqx_pick cvmx_pko_l5_sqx_pick_t;
 
 /**
  * cvmx_pko_l5_sq#_pir
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ *
  */
 union cvmx_pko_l5_sqx_pir {
 	uint64_t u64;
@@ -5427,8 +5880,14 @@ union cvmx_pko_l5_sqx_pir {
 	uint64_t reserved_17_28               : 12;
 	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
                                                          specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_COUNT_EXPONENT). The supported range for RATE_DIVIDER_EXPONENT
-                                                         is 0 to 11. Programmed values greater than 11 are treated as 11. */
+                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
+                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
+                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
+                                                         time-wheel turn is 768 clocks (SCLK).
+                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 <<RATE_DIVIDER_EXPONENT)
+                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
+                                                         (1 << RATE_DIVIDER_EXPONENT) */
 	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
 	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
@@ -5449,6 +5908,9 @@ typedef union cvmx_pko_l5_sqx_pir cvmx_pko_l5_sqx_pir_t;
 
 /**
  * cvmx_pko_l5_sq#_pointers
+ *
+ * This register has the same bit fields as PKO_L4_SQ(0..1023)_POINTERS.
+ *
  */
 union cvmx_pko_l5_sqx_pointers {
 	uint64_t u64;
@@ -5471,6 +5933,9 @@ typedef union cvmx_pko_l5_sqx_pointers cvmx_pko_l5_sqx_pointers_t;
 
 /**
  * cvmx_pko_l5_sq#_red
+ *
+ * This register has the same bit fields as PKO_L3_SQ(0..511)_YELLOW.
+ *
  */
 union cvmx_pko_l5_sqx_red {
 	uint64_t u64;
@@ -5491,6 +5956,9 @@ typedef union cvmx_pko_l5_sqx_red cvmx_pko_l5_sqx_red_t;
 
 /**
  * cvmx_pko_l5_sq#_sched_state
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SCHED_STATE.
+ *
  */
 union cvmx_pko_l5_sqx_sched_state {
 	uint64_t u64;
@@ -5509,6 +5977,9 @@ typedef union cvmx_pko_l5_sqx_sched_state cvmx_pko_l5_sqx_sched_state_t;
 
 /**
  * cvmx_pko_l5_sq#_schedule
+ *
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SCHEDULE.
+ *
  */
 union cvmx_pko_l5_sqx_schedule {
 	uint64_t u64;
@@ -5564,6 +6035,9 @@ typedef union cvmx_pko_l5_sqx_shape cvmx_pko_l5_sqx_shape_t;
 
 /**
  * cvmx_pko_l5_sq#_shape_state
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ *
  */
 union cvmx_pko_l5_sqx_shape_state {
 	uint64_t u64;
@@ -5572,10 +6046,10 @@ union cvmx_pko_l5_sqx_shape_state {
 	uint64_t reserved_60_63               : 4;
 	uint64_t tw_timestamp                 : 6;  /**< Time-wheel timestamp. Debug access to the live time-wheel timestamp. */
 	uint64_t color                        : 2;  /**< Shaper color status. Debug access to the live shaper state.
-                                                         0 = Green - operating in 'committed' range
-                                                         1 = Yellow - operating in 'excess/peak' range
-                                                         2 = Red - operating in 'oversubscribed' range
-                                                         3 = Reserved */
+                                                         0x0 = Green - operating in 'committed' range
+                                                         0x1 = Yellow - operating in 'excess/peak' range
+                                                         0x2 = Red - operating in 'oversubscribed' range
+                                                         0x3 = Reserved */
 	uint64_t pir_accum                    : 26; /**< Peak information rate accumulator. Debug access to the live PIR accumulator. */
 	uint64_t cir_accum                    : 26; /**< Committed information rate accumulator. Debug access to the live CIR accumulator. */
 #else
@@ -5592,6 +6066,9 @@ typedef union cvmx_pko_l5_sqx_shape_state cvmx_pko_l5_sqx_shape_state_t;
 
 /**
  * cvmx_pko_l5_sq#_sw_xoff
+ *
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_SW_XOFF.
+ *
  */
 union cvmx_pko_l5_sqx_sw_xoff {
 	uint64_t u64;
@@ -5605,10 +6082,10 @@ union cvmx_pko_l5_sqx_sw_xoff {
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
                                                          be used in combination with DRAIN_NULL_LINK and DRAIN_IRQ. */
-	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is de-asserted.
+	uint64_t xoff                         : 1;  /**< XOFF. The PQ is disabled when XOFF is asserted. PQ is enabled when XOFF is deasserted.
                                                          NOTE: The associated PKO_L1_SQ(0..31)_TOPOLOGY[LINK] must be configured before using this
                                                          register field. Writing to this register field before the associated
-                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configure can result in modifying the software
+                                                         PKO_L1_SQ(0..31)_TOPOLOGY[LINK] value is configured can result in modifying the software
                                                          XOFF state of the wrong SQ. */
 #else
 	uint64_t xoff                         : 1;
@@ -5652,7 +6129,10 @@ typedef union cvmx_pko_l5_sqx_topology cvmx_pko_l5_sqx_topology_t;
 
 /**
  * cvmx_pko_l5_sq#_yellow
- */
+ *
+ * This register has the same bit fields as PKO_L3_SQ(0..511)_YELLOW.
+ *
+ */
 union cvmx_pko_l5_sqx_yellow {
 	uint64_t u64;
 	struct cvmx_pko_l5_sqx_yellow_s {
@@ -5671,7 +6151,26 @@ union cvmx_pko_l5_sqx_yellow {
 typedef union cvmx_pko_l5_sqx_yellow cvmx_pko_l5_sqx_yellow_t;
 
 /**
+ * cvmx_pko_l5_sq_csr_bus_debug
+ */
+union cvmx_pko_l5_sq_csr_bus_debug {
+	uint64_t u64;
+	struct cvmx_pko_l5_sq_csr_bus_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t csr_bus_debug                : 64; /**< -- */
+#else
+	uint64_t csr_bus_debug                : 64;
+#endif
+	} s;
+	struct cvmx_pko_l5_sq_csr_bus_debug_s cn78xx;
+};
+typedef union cvmx_pko_l5_sq_csr_bus_debug cvmx_pko_l5_sq_csr_bus_debug_t;
+
+/**
  * cvmx_pko_l5_sqa_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l5_sqa_debug {
 	uint64_t u64;
@@ -5688,6 +6187,9 @@ typedef union cvmx_pko_l5_sqa_debug cvmx_pko_l5_sqa_debug_t;
 
 /**
  * cvmx_pko_l5_sqb_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_l5_sqb_debug {
 	uint64_t u64;
@@ -5711,13 +6213,13 @@ union cvmx_pko_lutx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t valid                        : 1;  /**< Declares if the index in the LUT is valid. */
-	uint64_t level                        : 1;  /**< 0 = level2, 1 = level3. */
+	uint64_t reserved_14_14               : 1;
 	uint64_t pq_idx                       : 5;  /**< PQ index for channel return processing in the PSE. */
 	uint64_t queue_number                 : 9;  /**< Mapping from this channel to the programmed queue number. */
 #else
 	uint64_t queue_number                 : 9;
 	uint64_t pq_idx                       : 5;
-	uint64_t level                        : 1;
+	uint64_t reserved_14_14               : 1;
 	uint64_t valid                        : 1;
 	uint64_t reserved_16_63               : 48;
 #endif
@@ -5771,8 +6273,7 @@ union cvmx_pko_lut_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_lut_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t c2q_lut_ram_dbe              : 1;  /**< Double-bit error for C2Q_LUT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t c2q_lut_ram_dbe              : 1;  /**< Double-bit error for C2Q_LUT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.pko_c2q_lut.pko_c2q_lut_ram_i */
 	uint64_t reserved_0_62                : 63;
 #else
@@ -5791,11 +6292,9 @@ union cvmx_pko_lut_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_lut_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t lut_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_LUT_ECC_DBE_STS.
-                                                         To clear this bit, software must clear bits in PKO_LUT_ECC_DBE_STS.
-                                                         When this bit is set, the corresponding interrupt is set.
-                                                         Throws PKO_INTSN_E::PKO_LUT_DBE_CMB0.
-                                                         INTERNAL: Instances:
+	uint64_t lut_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_LUT_ECC_DBE_STS. To clear this bit, software
+                                                         must clear bits in PKO_LUT_ECC_DBE_STS. When this bit is set, the corresponding interrupt
+                                                         is set. Throws PKO_INTSN_E::PKO_LUT_DBE_CMB0. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.pko_c2q_lut.pko_c2q_lut_ram_i */
 	uint64_t reserved_0_62                : 63;
 #else
@@ -5814,8 +6313,7 @@ union cvmx_pko_lut_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_lut_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t c2q_lut_ram_sbe              : 1;  /**< Single-bit error for C2Q_LUT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t c2q_lut_ram_sbe              : 1;  /**< Single-bit error for C2Q_LUT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.pko_c2q_lut.pko_c2q_lut_ram_i */
 	uint64_t reserved_0_62                : 63;
 #else
@@ -5834,11 +6332,9 @@ union cvmx_pko_lut_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_lut_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t lut_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_LUT_ECC_SBE_STS.
-                                                         To clear this bit, software must clear bits in PKO_LUT_ECC_SBE_STS.
-                                                         When this bit is set, the corresponding interrupt is set.
-                                                         Throws PKO_INTSN_E::PKO_LUT_SBE_CMB0.
-                                                         INTERNAL: Instances:
+	uint64_t lut_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_LUT_ECC_SBE_STS. To clear this bit, software
+                                                         must clear bits in PKO_LUT_ECC_SBE_STS. When this bit is set, the corresponding interrupt
+                                                         is set. Throws PKO_INTSN_E::PKO_LUT_SBE_CMB0. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.pko_c2q_lut.pko_c2q_lut_ram_i */
 	uint64_t reserved_0_62                : 63;
 #else
@@ -5860,14 +6356,14 @@ union cvmx_pko_macx_cfg {
 	uint64_t reserved_17_63               : 47;
 	uint64_t min_pad_ena                  : 1;  /**< Minimum padding is enabled for this MAC/FIFO */
 	uint64_t fcs_ena                      : 1;  /**< Enable outside FCS for this MAC/FIFO */
-	uint64_t fcs_sop_off                  : 8;  /**< FCS start of packet offset.  For this MAC, the number of bytes in the front
-                                                         of each packet to exclude from FCS. */
+	uint64_t fcs_sop_off                  : 8;  /**< FCS start of packet offset. For this MAC, the number of bytes in the front of each packet
+                                                         to exclude from FCS. */
 	uint64_t skid_max_cnt                 : 2;  /**< Maximum number of SKID credits. 0x0 = 16; 0x1 = 32; 0x2 = 64. */
 	uint64_t fifo_num                     : 5;  /**< The PEB TX FIFO number assigned to the given MAC. A value of 0x1F means unassigned. Unused
                                                          MACs must be assigned a FIFO_NUM = 0x1F. For each active MAC, a unique FIFO_NUM must be
                                                          assigned. Legal values depend on the values in PKO_PTGF(0..7)_CFG[SIZE]. Assigning the
-                                                         same FIFO_NUM to more than a single active MAC will have unpredictable results.  FIFOs
-                                                         0x1E and 0x1D are invalid and will cause unpredictable results if used. */
+                                                         same FIFO_NUM to more than a single active MAC will have unpredictable results. FIFOs 0x1E
+                                                         and 0x1D are invalid and will cause unpredictable results if used. */
 #else
 	uint64_t fifo_num                     : 5;
 	uint64_t skid_max_cnt                 : 2;
@@ -6135,8 +6631,8 @@ typedef union cvmx_pko_mem_debug1 cvmx_pko_mem_debug1_t;
  * cvmx_pko_mem_debug10
  *
  * Notes:
- * Internal per-port state intended for debug use only - pko.dat.ptr.ptrs1, pko.dat.ptr.ptrs2
- * This CSR is a memory of 44 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
+ * Internal per-engine state intended for debug use only - pko.dat.ptr.ptrs1, pko.dat.ptr.ptrs2
+ * This CSR is a memory of 10 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
  * CSR read operations to this address can be performed.
  */
 union cvmx_pko_mem_debug10 {
@@ -6198,8 +6694,8 @@ typedef union cvmx_pko_mem_debug10 cvmx_pko_mem_debug10_t;
  * cvmx_pko_mem_debug11
  *
  * Notes:
- * Internal per-port state intended for debug use only - pko.out.sta.state[22:0]
- * This CSR is a memory of 44 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
+ * Internal per-engine state intended for debug use only - pko.out.sta.state[22:0]
+ * This CSR is a memory of 10 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
  * CSR read operations to this address can be performed.
  */
 union cvmx_pko_mem_debug11 {
@@ -6279,8 +6775,8 @@ typedef union cvmx_pko_mem_debug11 cvmx_pko_mem_debug11_t;
  * cvmx_pko_mem_debug12
  *
  * Notes:
- * Internal per-port state intended for debug use only - pko.out.ctl.cmnd[63:0]
- * This CSR is a memory of 44 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
+ * Internal per-engine x4 state intended for debug use only - pko.out.ctl.cmnd[63:0]
+ * This CSR is a memory of 40 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
  * CSR read operations to this address can be performed.
  */
 union cvmx_pko_mem_debug12 {
@@ -6342,8 +6838,8 @@ typedef union cvmx_pko_mem_debug12 cvmx_pko_mem_debug12_t;
  * cvmx_pko_mem_debug13
  *
  * Notes:
- * Internal per-port state intended for debug use only - pko.out.ctl.head[63:0]
- * This CSR is a memory of 44 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
+ * Internal per-engine x4 state intended for debug use only - pko.out.ctl.head[63:0]
+ * This CSR is a memory of 40 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
  * CSR read operations to this address can be performed.
  */
 union cvmx_pko_mem_debug13 {
@@ -6671,8 +7167,36 @@ union cvmx_pko_mem_debug4 {
 	struct cvmx_pko_mem_debug4_cn52xx     cn63xx;
 	struct cvmx_pko_mem_debug4_cn52xx     cn63xxp1;
 	struct cvmx_pko_mem_debug4_cn52xx     cn66xx;
-	struct cvmx_pko_mem_debug4_cn52xx     cn68xx;
-	struct cvmx_pko_mem_debug4_cn52xx     cn68xxp1;
+	struct cvmx_pko_mem_debug4_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t curr_siz                     : 9;  /**< Internal state */
+	uint64_t curr_off                     : 16; /**< Internal state */
+	uint64_t cmnd_segs                    : 6;  /**< Internal state */
+	uint64_t cmnd_siz                     : 16; /**< Internal state */
+	uint64_t cmnd_off                     : 6;  /**< Internal state */
+	uint64_t dread_sop                    : 1;  /**< Internal state */
+	uint64_t init_dwrite                  : 1;  /**< Internal state */
+	uint64_t chk_once                     : 1;  /**< Internal state */
+	uint64_t chk_mode                     : 1;  /**< Internal state */
+	uint64_t reserved_6_6                 : 1;
+	uint64_t minor                        : 2;  /**< Internal state */
+	uint64_t major                        : 4;  /**< Internal state */
+#else
+	uint64_t major                        : 4;
+	uint64_t minor                        : 2;
+	uint64_t reserved_6_6                 : 1;
+	uint64_t chk_mode                     : 1;
+	uint64_t chk_once                     : 1;
+	uint64_t init_dwrite                  : 1;
+	uint64_t dread_sop                    : 1;
+	uint64_t cmnd_off                     : 6;
+	uint64_t cmnd_siz                     : 16;
+	uint64_t cmnd_segs                    : 6;
+	uint64_t curr_off                     : 16;
+	uint64_t curr_siz                     : 9;
+#endif
+	} cn68xx;
+	struct cvmx_pko_mem_debug4_cn68xx     cn68xxp1;
 	struct cvmx_pko_mem_debug4_cn52xx     cn70xx;
 	struct cvmx_pko_mem_debug4_cn52xx     cnf71xx;
 };
@@ -6795,19 +7319,17 @@ union cvmx_pko_mem_debug5 {
 	struct cvmx_pko_mem_debug5_cn68xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_57_63               : 7;
-	uint64_t uid_2                        : 1;  /**< Internal state */
+	uint64_t uid                          : 3;  /**< Internal state */
 	uint64_t ptp                          : 1;  /**< Internal state */
-	uint64_t major_3                      : 1;  /**< Internal state */
 	uint64_t nxt_inflt                    : 6;  /**< Internal state */
 	uint64_t curr_ptr                     : 40; /**< Internal state */
-	uint64_t curr_siz                     : 8;  /**< Internal state */
+	uint64_t curr_siz                     : 7;  /**< Internal state */
 #else
-	uint64_t curr_siz                     : 8;
+	uint64_t curr_siz                     : 7;
 	uint64_t curr_ptr                     : 40;
 	uint64_t nxt_inflt                    : 6;
-	uint64_t major_3                      : 1;
 	uint64_t ptp                          : 1;
-	uint64_t uid_2                        : 1;
+	uint64_t uid                          : 3;
 	uint64_t reserved_57_63               : 7;
 #endif
 	} cn68xx;
@@ -6829,31 +7351,13 @@ union cvmx_pko_mem_debug6 {
 	uint64_t u64;
 	struct cvmx_pko_mem_debug6_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_37_63               : 27;
-	uint64_t qid_offres                   : 4;  /**< Internal state */
-	uint64_t qid_offths                   : 4;  /**< Internal state */
-	uint64_t preempter                    : 1;  /**< Internal state */
-	uint64_t preemptee                    : 1;  /**< Internal state */
-	uint64_t preempted                    : 1;  /**< Internal state */
-	uint64_t active                       : 1;  /**< Internal state */
-	uint64_t reserved_24_24               : 1;
-	uint64_t qos                          : 3;  /**< Internal state */
-	uint64_t qcb_ridx                     : 5;  /**< Internal state */
-	uint64_t qid_offmax                   : 4;  /**< Internal state */
-	uint64_t reserved_0_11                : 12;
+	uint64_t reserved_38_63               : 26;
+	uint64_t qos_active                   : 1;  /**< Internal state */
+	uint64_t reserved_0_36                : 37;
 #else
-	uint64_t reserved_0_11                : 12;
-	uint64_t qid_offmax                   : 4;
-	uint64_t qcb_ridx                     : 5;
-	uint64_t qos                          : 3;
-	uint64_t reserved_24_24               : 1;
-	uint64_t active                       : 1;
-	uint64_t preempted                    : 1;
-	uint64_t preemptee                    : 1;
-	uint64_t preempter                    : 1;
-	uint64_t qid_offths                   : 4;
-	uint64_t qid_offres                   : 4;
-	uint64_t reserved_37_63               : 27;
+	uint64_t reserved_0_36                : 37;
+	uint64_t qos_active                   : 1;
+	uint64_t reserved_38_63               : 26;
 #endif
 	} s;
 	struct cvmx_pko_mem_debug6_cn30xx {
@@ -6927,8 +7431,36 @@ union cvmx_pko_mem_debug6 {
 	struct cvmx_pko_mem_debug6_cn52xx     cn63xx;
 	struct cvmx_pko_mem_debug6_cn52xx     cn63xxp1;
 	struct cvmx_pko_mem_debug6_cn52xx     cn66xx;
-	struct cvmx_pko_mem_debug6_cn52xx     cn68xx;
-	struct cvmx_pko_mem_debug6_cn52xx     cn68xxp1;
+	struct cvmx_pko_mem_debug6_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_38_63               : 26;
+	uint64_t qos_active                   : 1;  /**< Internal state */
+	uint64_t qid_offths                   : 5;  /**< Internal state */
+	uint64_t preempter                    : 1;  /**< Internal state */
+	uint64_t preemptee                    : 1;  /**< Internal state */
+	uint64_t active                       : 1;  /**< Internal state */
+	uint64_t static_p                     : 1;  /**< Internal state */
+	uint64_t qos                          : 3;  /**< Internal state */
+	uint64_t qcb_ridx                     : 7;  /**< Internal state */
+	uint64_t qid_offmax                   : 5;  /**< Internal state */
+	uint64_t qid_off                      : 5;  /**< Internal state */
+	uint64_t qid_base                     : 8;  /**< Internal state */
+#else
+	uint64_t qid_base                     : 8;
+	uint64_t qid_off                      : 5;
+	uint64_t qid_offmax                   : 5;
+	uint64_t qcb_ridx                     : 7;
+	uint64_t qos                          : 3;
+	uint64_t static_p                     : 1;
+	uint64_t active                       : 1;
+	uint64_t preemptee                    : 1;
+	uint64_t preempter                    : 1;
+	uint64_t qid_offths                   : 5;
+	uint64_t qos_active                   : 1;
+	uint64_t reserved_38_63               : 26;
+#endif
+	} cn68xx;
+	struct cvmx_pko_mem_debug6_cn68xx     cn68xxp1;
 	struct cvmx_pko_mem_debug6_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_37_63               : 27;
@@ -7026,19 +7558,15 @@ union cvmx_pko_mem_debug7 {
 	struct cvmx_pko_mem_debug7_cn50xx     cn66xx;
 	struct cvmx_pko_mem_debug7_cn68xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t qos                          : 3;  /**< QOS mask to enable the queue when set */
-	uint64_t tail                         : 1;  /**< This queue is the last (tail) in the queue array */
-	uint64_t buf_siz                      : 13; /**< Command buffer remaining size in words */
-	uint64_t buf_ptr                      : 33; /**< Command word pointer */
-	uint64_t qcb_widx                     : 7;  /**< Buffer write index for QCB */
-	uint64_t qcb_ridx                     : 7;  /**< Buffer read  index for QCB */
+	uint64_t buf_siz                      : 11; /**< Command buffer remaining size in words */
+	uint64_t buf_ptr                      : 37; /**< Command word pointer */
+	uint64_t qcb_widx                     : 8;  /**< Buffer write index for QCB */
+	uint64_t qcb_ridx                     : 8;  /**< Buffer read  index for QCB */
 #else
-	uint64_t qcb_ridx                     : 7;
-	uint64_t qcb_widx                     : 7;
-	uint64_t buf_ptr                      : 33;
-	uint64_t buf_siz                      : 13;
-	uint64_t tail                         : 1;
-	uint64_t qos                          : 3;
+	uint64_t qcb_ridx                     : 8;
+	uint64_t qcb_widx                     : 8;
+	uint64_t buf_ptr                      : 37;
+	uint64_t buf_siz                      : 11;
 #endif
 	} cn68xx;
 	struct cvmx_pko_mem_debug7_cn68xx     cn68xxp1;
@@ -7061,11 +7589,9 @@ union cvmx_pko_mem_debug8 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_59_63               : 5;
 	uint64_t tail                         : 1;  /**< This queue is the last (tail) in the queue array */
-	uint64_t buf_siz                      : 13; /**< Command buffer remaining size in words */
-	uint64_t reserved_0_44                : 45;
+	uint64_t reserved_0_57                : 58;
 #else
-	uint64_t reserved_0_44                : 45;
-	uint64_t buf_siz                      : 13;
+	uint64_t reserved_0_57                : 58;
 	uint64_t tail                         : 1;
 	uint64_t reserved_59_63               : 5;
 #endif
@@ -7171,25 +7697,25 @@ union cvmx_pko_mem_debug8 {
 	struct cvmx_pko_mem_debug8_cn61xx     cn66xx;
 	struct cvmx_pko_mem_debug8_cn68xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_37_63               : 27;
+	uint64_t reserved_50_63               : 14;
+	uint64_t qid_qqos                     : 8;  /**< Queue QOS */
+	uint64_t qid_idx                      : 5;  /**< Queue index in queue array for the port */
 	uint64_t preempter                    : 1;  /**< Preempter */
 	uint64_t doorbell                     : 20; /**< Doorbell count */
 	uint64_t reserved_9_15                : 7;
-	uint64_t preemptee                    : 1;  /**< Preemptee */
-	uint64_t static_p                     : 1;  /**< Static priority */
-	uint64_t s_tail                       : 1;  /**< Static tail */
-	uint64_t static_q                     : 1;  /**< Static priority */
-	uint64_t qos                          : 5;  /**< QOS mask to enable the queue when set */
+	uint64_t qid_qos                      : 6;  /**< QOS mask[5:0] to enable the queue when set */
+	uint64_t qid_tail                     : 1;  /**< This queue is the last (tail) in the queue array */
+	uint64_t buf_siz                      : 2;  /**< Command buffer remaining size in words */
 #else
-	uint64_t qos                          : 5;
-	uint64_t static_q                     : 1;
-	uint64_t s_tail                       : 1;
-	uint64_t static_p                     : 1;
-	uint64_t preemptee                    : 1;
+	uint64_t buf_siz                      : 2;
+	uint64_t qid_tail                     : 1;
+	uint64_t qid_qos                      : 6;
 	uint64_t reserved_9_15                : 7;
 	uint64_t doorbell                     : 20;
 	uint64_t preempter                    : 1;
-	uint64_t reserved_37_63               : 27;
+	uint64_t qid_idx                      : 5;
+	uint64_t qid_qqos                     : 8;
+	uint64_t reserved_50_63               : 14;
 #endif
 	} cn68xx;
 	struct cvmx_pko_mem_debug8_cn68xx     cn68xxp1;
@@ -7202,8 +7728,8 @@ typedef union cvmx_pko_mem_debug8 cvmx_pko_mem_debug8_t;
  * cvmx_pko_mem_debug9
  *
  * Notes:
- * Internal per-port state intended for debug use only - pko.dat.ptr.ptrs0, pko.dat.ptr.ptrs3
- * This CSR is a memory of 44 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
+ * Internal per-engine state intended for debug use only - pko.dat.ptr.ptrs0, pko.dat.ptr.ptrs3
+ * This CSR is a memory of 10 entries, and thus, the PKO_REG_READ_IDX CSR must be written before any
  * CSR read operations to this address can be performed.
  */
 union cvmx_pko_mem_debug9 {
@@ -8028,20 +8554,15 @@ union cvmx_pko_ncb_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_ncb_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ncbi_l2_out_ram_dbe          : 1;  /**< Double-bit error for NCBI_L2_OUT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbi_l2_out_ram_dbe          : 1;  /**< Double-bit error for NCBI_L2_OUT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.l2_out_fifo */
-	uint64_t ncbi_pp_out_ram_dbe          : 1;  /**< Double-bit error for NCBI_PP_OUT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbi_pp_out_ram_dbe          : 1;  /**< Double-bit error for NCBI_PP_OUT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.pp_out_fifo */
-	uint64_t ncbo_pdm_cmd_dat_ram_dbe     : 1;  /**< Double-bit error for NCBO_PDM_CMD_DAT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbo_pdm_cmd_dat_ram_dbe     : 1;  /**< Double-bit error for NCBO_PDM_CMD_DAT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.ncb__pdm_cmnd_data_fifo */
-	uint64_t ncbi_l2_pdm_pref_ram_dbe     : 1;  /**< Double-bit error for NCBI_L2_PDM_PREF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbi_l2_pdm_pref_ram_dbe     : 1;  /**< Double-bit error for NCBI_L2_PDM_PREF_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_l2_pipe.pdm_prefbuf_fifo */
-	uint64_t ncbo_pp_fif_ram_dbe          : 1;  /**< Double-bit error for NCBO_PP_FIF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbo_pp_fif_ram_dbe          : 1;  /**< Double-bit error for NCBO_PP_FIF_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.pp_fifo */
 	uint64_t reserved_0_58                : 59;
 #else
@@ -8064,11 +8585,9 @@ union cvmx_pko_ncb_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_ncb_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ncb_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_NCB_ECC_DBE_STS.
-                                                         To clear this bit, software must clear bits in PKO_NCB_ECC_DBE_STS.
-                                                         When this bit is set, the corresponding interrupt is set.
-                                                         Throws PKO_INTSN_E::PKO_NCB_DBE_CMB0.
-                                                         INTERNAL: Instances:
+	uint64_t ncb_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_NCB_ECC_DBE_STS. To clear this bit, software
+                                                         must clear bits in PKO_NCB_ECC_DBE_STS. When this bit is set, the corresponding interrupt
+                                                         is set. Throws PKO_INTSN_E::PKO_NCB_DBE_CMB0. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.l2_out_fifo
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.pp_out_fifo
                                                          pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.ncb__pdm_cmnd_data_fifo
@@ -8091,20 +8610,15 @@ union cvmx_pko_ncb_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_ncb_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ncbi_l2_out_ram_sbe          : 1;  /**< Single-bit error for NCBI_L2_OUT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbi_l2_out_ram_sbe          : 1;  /**< Single-bit error for NCBI_L2_OUT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.l2_out_fifo */
-	uint64_t ncbi_pp_out_ram_sbe          : 1;  /**< Single-bit error for NCBI_PP_OUT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbi_pp_out_ram_sbe          : 1;  /**< Single-bit error for NCBI_PP_OUT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.pp_out_fifo */
-	uint64_t ncbo_pdm_cmd_dat_ram_sbe     : 1;  /**< Single-bit error for NCBO_PDM_CMD_DAT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbo_pdm_cmd_dat_ram_sbe     : 1;  /**< Single-bit error for NCBO_PDM_CMD_DAT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.ncb__pdm_cmnd_data_fifo */
-	uint64_t ncbi_l2_pdm_pref_ram_sbe     : 1;  /**< Single-bit error for NCBI_L2_PDM_PREF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbi_l2_pdm_pref_ram_sbe     : 1;  /**< Single-bit error for NCBI_L2_PDM_PREF_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_l2_pipe.pdm_prefbuf_fifo */
-	uint64_t ncbo_pp_fif_ram_sbe          : 1;  /**< Single-bit error for NCBO_PP_FIF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ncbo_pp_fif_ram_sbe          : 1;  /**< Single-bit error for NCBO_PP_FIF_RAM. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.pp_fifo */
 	uint64_t reserved_0_58                : 59;
 #else
@@ -8127,11 +8641,9 @@ union cvmx_pko_ncb_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_ncb_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ncb_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_NCB_ECC_SBE_STS.
-                                                         To clear this bit, software must clear bits in PKO_NCB_ECC_SBE_STS.
-                                                         When this bit is set, the corresponding interrupt is set.
-                                                         Throws PKO_INTSN_E::PKO_NCB_SBE_CMB0.
-                                                         INTERNAL: Instances:
+	uint64_t ncb_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_NCB_ECC_SBE_STS. To clear this bit, software
+                                                         must clear bits in PKO_NCB_ECC_SBE_STS. When this bit is set, the corresponding interrupt
+                                                         is set. Throws PKO_INTSN_E::PKO_NCB_SBE_CMB0. INTERNAL: Instances:
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.l2_out_fifo
                                                          pko_pnr2.nonpse.ncb.pko_ncbi_outb.ncbi_txr.pp_out_fifo
                                                          pko_pnr2.nonpse.ncb.pko_ncbo_inb.splitter.ncb__pdm_cmnd_data_fifo
@@ -8204,7 +8716,7 @@ union cvmx_pko_ncb_tx_err_word {
 	struct cvmx_pko_ncb_tx_err_word_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t err_word                     : 64; /**< PKO NCB error word (first word of erroneous transaction).
-                                                         Note: This is only the 64-bit data word; the NCB info that goes with it is in
+                                                         Note: this is only the 64-bit data word; the NCB info that goes with it is in
                                                          PKO_NCB_TX_ERR_INFO. */
 #else
 	uint64_t err_word                     : 64;
@@ -8297,12 +8809,11 @@ union cvmx_pko_pdm_cfg {
                                                          FPD bit from PEB, which is a performance penalty when the time is large for the PEB
                                                          request to make it back to PDM. For diagnostic use only. */
 	uint64_t en_fr_w2r_ptr_swp            : 1;  /**< Set to enable pointer swap on a fill response when we go in-sync (only one cacheline in
-                                                         DQ).
-                                                         For diagnostic use only. */
+                                                         DQ). For diagnostic use only. */
 	uint64_t dis_flsh_cache               : 1;  /**< Set to disable the flush buffer's cache. This makes all fills require full memory latency.
                                                          For diagnostic use only. */
 	uint64_t pko_pad_minlen               : 7;  /**< Minimum frame padding min length. */
-	uint64_t diag_mode                    : 1;  /**< Set to enable read/write to memories in PDM through CSR interface.  For diagnostic use only. */
+	uint64_t diag_mode                    : 1;  /**< Set to enable read/write to memories in PDM through CSR interface. For diagnostic use only. */
 	uint64_t alloc_lds                    : 1;  /**< Allocate LDS. This signal prevents the loads to IOBP from being allocated in on-chip cache
                                                          (LDWB vs. LDD). Two modes as follows: 0 = No allocate (LDWB); 1 = Allocate (LDD). */
 	uint64_t alloc_sts                    : 1;  /**< Allocate STS. This signal prevents the stores to NCB from being allocated in on-chip cache
@@ -8354,11 +8865,11 @@ union cvmx_pko_pdm_cp_dbg {
 	uint64_t stateless_fif_cnt            : 6;  /**< Stateless fifo count. */
 	uint64_t reserved_5_9                 : 5;
 	uint64_t op_fif_not_full              : 5;  /**< Output fifo not full signals. The order of the bits is:
-                                                         - 4: ISR CMD FIFO not full
-                                                         - 3: DESC DAT FIFO HIGH not full
-                                                         - 2: DESC DAT FIFO LOW not full
-                                                         - 1: MP DAT FIFO not full
-                                                         - 0: PSE CMD RESP FIFO has credit */
+                                                         0x4 = ISR CMD FIFO not full
+                                                         0x3 = DESC DAT FIFO HIGH not full
+                                                         0x2 = DESC DAT FIFO LOW not full
+                                                         0x1 = MP DAT FIFO not full
+                                                         0x0 = PSE CMD RESP FIFO has credit */
 #else
 	uint64_t op_fif_not_full              : 5;
 	uint64_t reserved_5_9                 : 5;
@@ -8380,7 +8891,7 @@ union cvmx_pko_pdm_dqx_minpad {
 	uint64_t reserved_1_63                : 63;
 	uint64_t minpad                       : 1;  /**< MINPAD setting per DQ. Each DQ has a separate CSR address; and bit 0 of the data
                                                          read/write value is the MINPAD bit. When MINPAD is set, the send-packet header has the
-                                                         total field adjusted by MINLEN (PKO_PDM_CFG.PKO_PAD_MINLEN) as follows:
+                                                         total field adjusted by MINLEN (PKO_PDM_CFG[PKO_PAD_MINLEN]) as follows:
                                                          if (MINPAD)
                                                          if (send_hdr.total < MINLEN) send_hdr.total = MINLEN */
 #else
@@ -8410,7 +8921,10 @@ union cvmx_pko_pdm_drpbuf_dbg {
 	uint64_t reserved_17_20               : 4;
 	uint64_t mem_addr                     : 13; /**< Memory address for pbuf ram. */
 	uint64_t mem_en                       : 4;  /**< Memory write/chip enable signals. The order of the bits is:
-                                                         - 3: low wen; 2: low cen; 1: high wen; 0: high cen. */
+                                                         0x3 = low wen
+                                                         0x2 = low cen
+                                                         0x1 = high wen
+                                                         0x0 = high cen. */
 #else
 	uint64_t mem_en                       : 4;
 	uint64_t mem_addr                     : 13;
@@ -8447,7 +8961,10 @@ union cvmx_pko_pdm_dwpbuf_dbg {
 	uint64_t reserved_17_20               : 4;
 	uint64_t mem_addr                     : 13; /**< Memory address for pbuf ram. */
 	uint64_t mem_en                       : 4;  /**< Memory write/chip enable signals. The order of the bits is:
-                                                         - 3: low wen; 2: low cen; 1: high wen; 0: high cen. */
+                                                         0x3 = low wen
+                                                         0x2 = low cen
+                                                         0x1 = high wen
+                                                         0x0 = high cen. */
 #else
 	uint64_t mem_en                       : 4;
 	uint64_t mem_addr                     : 13;
@@ -8593,72 +9110,49 @@ union cvmx_pko_pdm_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pdm_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t flshb_cache_lo_ram_dbe       : 1;  /**< Double-bit error for FLSHB_CACHE_LO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t flshb_cache_lo_ram_dbe       : 1;  /**< Double-bit error for FLSHB_CACHE_LO_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_lo */
-	uint64_t flshb_cache_hi_ram_dbe       : 1;  /**< Double-bit error for FLSHB_CACHE_HI_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t flshb_cache_hi_ram_dbe       : 1;  /**< Double-bit error for FLSHB_CACHE_HI_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_hi */
-	uint64_t isrm_ca_iinst_ram_dbe        : 1;  /**< Double-bit error for ISRM_CA_IINST_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_ca_iinst_ram_dbe        : 1;  /**< Double-bit error for ISRM_CA_IINST_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.iinst_in_fif */
-	uint64_t isrm_ca_cm_ram_dbe           : 1;  /**< Double-bit error for ISRM_CA_CM_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_ca_cm_ram_dbe           : 1;  /**< Double-bit error for ISRM_CA_CM_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.cred_accum_ctrlr_and_mem.cred_accum_spr */
-	uint64_t isrm_st_ram2_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM2.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_st_ram2_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM2. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem2 */
-	uint64_t isrm_st_ram1_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM1.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_st_ram1_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM1. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem1 */
-	uint64_t isrm_st_ram0_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM0.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_st_ram0_dbe             : 1;  /**< Double-bit error for ISRM_ST_RAM0. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0 */
-	uint64_t isrd_st_ram3_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM3.
-                                                         INTERNAL: Instances:
+	uint64_t isrd_st_ram3_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM3. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem3 */
-	uint64_t isrd_st_ram2_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM2.
-                                                         INTERNAL: Instances:
+	uint64_t isrd_st_ram2_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM2. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem2 */
-	uint64_t isrd_st_ram1_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM1.
-                                                         INTERNAL: Instances:
+	uint64_t isrd_st_ram1_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM1. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem1 */
-	uint64_t isrd_st_ram0_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM0.
-                                                         INTERNAL: Instances:
+	uint64_t isrd_st_ram0_dbe             : 1;  /**< Double-bit error for ISRD_ST_RAM0. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem0 */
-	uint64_t drp_hi_ram_dbe               : 1;  /**< Double-bit error for DRP_HI_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t drp_hi_ram_dbe               : 1;  /**< Double-bit error for DRP_HI_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_1 */
-	uint64_t drp_lo_ram_dbe               : 1;  /**< Double-bit error for DRP_LO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t drp_lo_ram_dbe               : 1;  /**< Double-bit error for DRP_LO_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_2 */
-	uint64_t dwp_hi_ram_dbe               : 1;  /**< Double-bit error for DWP_HI_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t dwp_hi_ram_dbe               : 1;  /**< Double-bit error for DWP_HI_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_high */
-	uint64_t dwp_lo_ram_dbe               : 1;  /**< Double-bit error for DWP_LO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t dwp_lo_ram_dbe               : 1;  /**< Double-bit error for DWP_LO_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_low */
-	uint64_t mwp_hi_ram_dbe               : 1;  /**< Double-bit error for MWP_HI_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t mwp_hi_ram_dbe               : 1;  /**< Double-bit error for MWP_HI_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_high */
-	uint64_t mwp_lo_ram_dbe               : 1;  /**< Double-bit error for MWP_LO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t mwp_lo_ram_dbe               : 1;  /**< Double-bit error for MWP_LO_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_low */
-	uint64_t fillb_m_rsp_ram_hi_dbe       : 1;  /**< Double-bit error for FILLB_M_DAT_RAM_HI.
-                                                         INTERNAL: Instances:
+	uint64_t fillb_m_rsp_ram_hi_dbe       : 1;  /**< Double-bit error for FILLB_M_DAT_RAM_HI. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_ram_hi */
-	uint64_t fillb_m_rsp_ram_lo_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_LO.
-                                                         INTERNAL: Instances:
+	uint64_t fillb_m_rsp_ram_lo_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_LO. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_ram_lo */
-	uint64_t fillb_d_rsp_ram_hi_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_HI.
-                                                         INTERNAL: Instances:
+	uint64_t fillb_d_rsp_ram_hi_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_HI. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_hi */
-	uint64_t fillb_d_rsp_ram_lo_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_LO.
-                                                         INTERNAL: Instances:
+	uint64_t fillb_d_rsp_ram_lo_dbe       : 1;  /**< Double-bit error for FILLB_D_DAT_RAM_LO. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_lo */
-	uint64_t minpad_ram_dbe               : 1;  /**< Double-bit error for MINPAD_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr1.pko_pnr1_pdm.cp.minpad_ram */
+	uint64_t minpad_ram_dbe               : 1;  /**< Double-bit error for MINPAD_RAM. INTERNAL: Instances: pko_pnr1.pko_pnr1_pdm.cp.minpad_ram */
 	uint64_t reserved_0_41                : 42;
 #else
 	uint64_t reserved_0_41                : 42;
@@ -8697,17 +9191,14 @@ union cvmx_pko_pdm_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pdm_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pdm_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PDM_ECC_DBE_STS.
-                                                         To clear this bit, software must clear bits in PKO_PDM_ECC_DBE_STS.
-                                                         When this bit is set, the corresponding interrupt is set.
-                                                         Throws PKO_INTSN_E::PKO_PDM_DBE_CMB0.
-                                                         INTERNAL: Instances:
+	uint64_t pdm_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PDM_ECC_DBE_STS. To clear this bit, software
+                                                         must clear bits in PKO_PDM_ECC_DBE_STS. When this bit is set, the corresponding interrupt
+                                                         is set. Throws PKO_INTSN_E::PKO_PDM_DBE_CMB0. INTERNAL: Instances:
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_hi
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_lo
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.iinst_in_fif
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.cred_accum_ctrlr_and_mem.cred_
-                                                         accum_spr
-                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0
+                                                         accum_spr fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem1
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem2
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem0
@@ -8741,72 +9232,49 @@ union cvmx_pko_pdm_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pdm_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t flshb_cache_lo_ram_sbe       : 1;  /**< Single-bit error for FLSHB_CACHE_LO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t flshb_cache_lo_ram_sbe       : 1;  /**< Single-bit error for FLSHB_CACHE_LO_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_lo */
-	uint64_t flshb_cache_hi_ram_sbe       : 1;  /**< Single-bit error for FLSHB_CACHE_HI_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t flshb_cache_hi_ram_sbe       : 1;  /**< Single-bit error for FLSHB_CACHE_HI_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_hi */
-	uint64_t isrm_ca_iinst_ram_sbe        : 1;  /**< Single-bit error for ISRM_CA_IINST_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_ca_iinst_ram_sbe        : 1;  /**< Single-bit error for ISRM_CA_IINST_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.iinst_in_fif */
-	uint64_t isrm_ca_cm_ram_sbe           : 1;  /**< Single-bit error for ISRM_CA_CM_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_ca_cm_ram_sbe           : 1;  /**< Single-bit error for ISRM_CA_CM_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.cred_accum_ctrlr_and_mem.cred_accum_spr */
-	uint64_t isrm_st_ram2_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM2.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_st_ram2_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM2. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem2 */
-	uint64_t isrm_st_ram1_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM1.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_st_ram1_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM1. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem1 */
-	uint64_t isrm_st_ram0_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM0.
-                                                         INTERNAL: Instances:
+	uint64_t isrm_st_ram0_sbe             : 1;  /**< Single-bit error for ISRM_ST_RAM0. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0 */
-	uint64_t isrd_st_ram3_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM3.
-                                                         INTERNAL: Instances:
+	uint64_t isrd_st_ram3_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM3. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem3 */
-	uint64_t isrd_st_ram2_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM2.
-                                                         INTERNAL: Instances:
+	uint64_t isrd_st_ram2_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM2. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem2 */
-	uint64_t isrd_st_ram1_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM1.
-                                                         INTERNAL: Instances:
+	uint64_t isrd_st_ram1_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM1. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem1 */
-	uint64_t isrd_st_ram0_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM0.
-                                                         INTERNAL: Instances:
+	uint64_t isrd_st_ram0_sbe             : 1;  /**< Single-bit error for ISRD_ST_RAM0. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem0 */
-	uint64_t drp_hi_ram_sbe               : 1;  /**< Single-bit error for DRP_HI_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t drp_hi_ram_sbe               : 1;  /**< Single-bit error for DRP_HI_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_1 */
-	uint64_t drp_lo_ram_sbe               : 1;  /**< Single-bit error for DRP_LO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t drp_lo_ram_sbe               : 1;  /**< Single-bit error for DRP_LO_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.drpbuf.ram_128k_pbuf_2 */
-	uint64_t dwp_hi_ram_sbe               : 1;  /**< Single-bit error for DWP_HI_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t dwp_hi_ram_sbe               : 1;  /**< Single-bit error for DWP_HI_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_high */
-	uint64_t dwp_lo_ram_sbe               : 1;  /**< Single-bit error for DWP_LO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t dwp_lo_ram_sbe               : 1;  /**< Single-bit error for DWP_LO_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.dwpbuf.ram_128k_pbuf_low */
-	uint64_t mwp_hi_ram_sbe               : 1;  /**< Single-bit error for MWP_HI_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t mwp_hi_ram_sbe               : 1;  /**< Single-bit error for MWP_HI_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_high */
-	uint64_t mwp_lo_ram_sbe               : 1;  /**< Single-bit error for MWP_LO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t mwp_lo_ram_sbe               : 1;  /**< Single-bit error for MWP_LO_RAM. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.mwpbuf.ram_128k_pbuf_low */
-	uint64_t fillb_m_rsp_ram_hi_sbe       : 1;  /**< Single-bit error for FILLB_M_RSP_RAM_HI.
-                                                         INTERNAL: Instances:
+	uint64_t fillb_m_rsp_ram_hi_sbe       : 1;  /**< Single-bit error for FILLB_M_RSP_RAM_HI. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_ram_hi */
-	uint64_t fillb_m_rsp_ram_lo_sbe       : 1;  /**< Single-bit error for FILLB_M_RSP_RAM_LO.
-                                                         INTERNAL: Instances:
+	uint64_t fillb_m_rsp_ram_lo_sbe       : 1;  /**< Single-bit error for FILLB_M_RSP_RAM_LO. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.fillb.m_rsp_ram_lo */
-	uint64_t fillb_d_rsp_ram_hi_sbe       : 1;  /**< Single-bit error for FILLB_D_RSP_RAM_HI.
-                                                         INTERNAL: Instances:
+	uint64_t fillb_d_rsp_ram_hi_sbe       : 1;  /**< Single-bit error for FILLB_D_RSP_RAM_HI. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_hi */
-	uint64_t fillb_d_rsp_ram_lo_sbe       : 1;  /**< Single-bit error for FILLB_D_RSP_RAM_LO.
-                                                         INTERNAL: Instances:
+	uint64_t fillb_d_rsp_ram_lo_sbe       : 1;  /**< Single-bit error for FILLB_D_RSP_RAM_LO. INTERNAL: Instances:
                                                          pko_pnr1.pko_pnr1_pdm.fillb.d_rsp_ram_lo */
-	uint64_t minpad_ram_sbe               : 1;  /**< Single-bit error for MINPAD_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr1.pko_pnr1_pdm.cp.minpad_ram */
+	uint64_t minpad_ram_sbe               : 1;  /**< Single-bit error for MINPAD_RAM. INTERNAL: Instances: pko_pnr1.pko_pnr1_pdm.cp.minpad_ram */
 	uint64_t reserved_0_41                : 42;
 #else
 	uint64_t reserved_0_41                : 42;
@@ -8845,17 +9313,14 @@ union cvmx_pko_pdm_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_pdm_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pdm_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PDM_ECC_SBE_STS.
-                                                         To clear this bit, software must clear bits in PKO_PDM_ECC_SBE_STS.
-                                                         When this bit is set, the corresponding interrupt is set.
-                                                         Throws PKO_INTSN_E::PKO_PDM_SBE_CMB0.
-                                                         INTERNAL: Instances:
+	uint64_t pdm_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PDM_ECC_SBE_STS. To clear this bit, software
+                                                         must clear bits in PKO_PDM_ECC_SBE_STS. When this bit is set, the corresponding interrupt
+                                                         is set. Throws PKO_INTSN_E::PKO_PDM_SBE_CMB0. INTERNAL: Instances:
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_hi
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.flshb.flshb_cache_lo
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.iinst_in_fif
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.cred_accum.cred_accum_ctrlr_and_mem.cred_
-                                                         accum_spr
-                                                         fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0
+                                                         accum_spr fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem0
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem1
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.mp_isr.st_mem2
                                                          fc.core.roc.pko.pko_pnr1.pko_pnr1_pdm.isr.d_isr.st_mem0
@@ -8883,6 +9348,158 @@ union cvmx_pko_pdm_ecc_sbe_sts_cmb0 {
 typedef union cvmx_pko_pdm_ecc_sbe_sts_cmb0 cvmx_pko_pdm_ecc_sbe_sts_cmb0_t;
 
 /**
+ * cvmx_pko_pdm_fillb_dbg0
+ */
+union cvmx_pko_pdm_fillb_dbg0 {
+	uint64_t u64;
+	struct cvmx_pko_pdm_fillb_dbg0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_57_63               : 7;
+	uint64_t pd_seq                       : 5;  /**< Sequence number for next packet descriptor fill request */
+	uint64_t resp_pd_seq                  : 5;  /**< Sequence number for next response to be written into packet descriptor buffer RAM */
+	uint64_t d_rsp_lo_ram_addr_sel        : 2;  /**< Source of read/write address to low PD fill buffer RAM.
+                                                         0x0 = No access.
+                                                         0x1 = Read access sourced by PD fill buffer response FIFO (feeding DRPBUF).
+                                                         0x2 = Write access sourced by IOBP0.
+                                                         0x3 = Write access sourced by flush buffer. */
+	uint64_t d_rsp_hi_ram_addr_sel        : 2;  /**< Source of read/write address to high PD fill buffer RAM.
+                                                         0x0 = No access.
+                                                         0x1 = Read access sourced by PD fill buffer response FIFO (feeding DRPBUF).
+                                                         0x2 = Write access sourced by IOBP0.
+                                                         0x3 = Write access sourced by flush buffer. */
+	uint64_t d_rsp_rd_seq                 : 5;  /**< Sequence number for next response to be read from packet descriptor buffer RAM */
+	uint64_t d_rsp_fifo_rd_seq            : 5;  /**< Sequence number for next PD fill response to be sent to DRPBUF */
+	uint64_t d_fill_req_fifo_val          : 1;  /**< Fill buffer PD read request FIFO has a valid entry */
+	uint64_t d_rsp_ram_valid              : 32; /**< Fill buffer packet descriptor RAM valid flags */
+#else
+	uint64_t d_rsp_ram_valid              : 32;
+	uint64_t d_fill_req_fifo_val          : 1;
+	uint64_t d_rsp_fifo_rd_seq            : 5;
+	uint64_t d_rsp_rd_seq                 : 5;
+	uint64_t d_rsp_hi_ram_addr_sel        : 2;
+	uint64_t d_rsp_lo_ram_addr_sel        : 2;
+	uint64_t resp_pd_seq                  : 5;
+	uint64_t pd_seq                       : 5;
+	uint64_t reserved_57_63               : 7;
+#endif
+	} s;
+	struct cvmx_pko_pdm_fillb_dbg0_s      cn78xx;
+};
+typedef union cvmx_pko_pdm_fillb_dbg0 cvmx_pko_pdm_fillb_dbg0_t;
+
+/**
+ * cvmx_pko_pdm_fillb_dbg1
+ */
+union cvmx_pko_pdm_fillb_dbg1 {
+	uint64_t u64;
+	struct cvmx_pko_pdm_fillb_dbg1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_57_63               : 7;
+	uint64_t mp_seq                       : 5;  /**< Sequence number for next meta packet cache line fill request */
+	uint64_t resp_mp_seq                  : 5;  /**< Sequence number for next response to be written into meta packet buffer RAM */
+	uint64_t m_rsp_lo_ram_addr_sel        : 2;  /**< Source of read/write address to low MP fill buffer RAM.
+                                                         0x0 = No access.
+                                                         0x1 = Read access sourced by MP fill buffer response FIFO (feeding DRPBUF).
+                                                         0x2 = Write access sourced by IOBP0.
+                                                         0x3 = Write access sourced by flush buffer. */
+	uint64_t m_rsp_hi_ram_addr_sel        : 2;  /**< Source of read/write address to high MP fill buffer RAM.
+                                                         0x0 = No access.
+                                                         0x1 = Read access sourced by MP fill buffer response FIFO (feeding DRPBUF).
+                                                         0x2 = Write access sourced by IOBP0.
+                                                         0x3 = Write access sourced by flush buffer. */
+	uint64_t m_rsp_rd_seq                 : 5;  /**< Sequence number for next response to be read from meta packet buffer RAM */
+	uint64_t m_rsp_fifo_rd_seq            : 5;  /**< Sequence number for next MP fill response to be sent to DRPBUF */
+	uint64_t m_fill_req_fifo_val          : 1;  /**< Fill buffer MP read request FIFO has a valid entry */
+	uint64_t m_rsp_ram_valid              : 32; /**< Fill buffer meta packet RAM valid flags */
+#else
+	uint64_t m_rsp_ram_valid              : 32;
+	uint64_t m_fill_req_fifo_val          : 1;
+	uint64_t m_rsp_fifo_rd_seq            : 5;
+	uint64_t m_rsp_rd_seq                 : 5;
+	uint64_t m_rsp_hi_ram_addr_sel        : 2;
+	uint64_t m_rsp_lo_ram_addr_sel        : 2;
+	uint64_t resp_mp_seq                  : 5;
+	uint64_t mp_seq                       : 5;
+	uint64_t reserved_57_63               : 7;
+#endif
+	} s;
+	struct cvmx_pko_pdm_fillb_dbg1_s      cn78xx;
+};
+typedef union cvmx_pko_pdm_fillb_dbg1 cvmx_pko_pdm_fillb_dbg1_t;
+
+/**
+ * cvmx_pko_pdm_fillb_dbg2
+ */
+union cvmx_pko_pdm_fillb_dbg2 {
+	uint64_t u64;
+	struct cvmx_pko_pdm_fillb_dbg2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_9_63                : 55;
+	uint64_t fillb_sm                     : 5;  /**< Fill buffer state machine */
+	uint64_t reserved_3_3                 : 1;
+	uint64_t iobp0_credit_cntr            : 3;  /**< IOBP0 read request credit counter */
+#else
+	uint64_t iobp0_credit_cntr            : 3;
+	uint64_t reserved_3_3                 : 1;
+	uint64_t fillb_sm                     : 5;
+	uint64_t reserved_9_63                : 55;
+#endif
+	} s;
+	struct cvmx_pko_pdm_fillb_dbg2_s      cn78xx;
+};
+typedef union cvmx_pko_pdm_fillb_dbg2 cvmx_pko_pdm_fillb_dbg2_t;
+
+/**
+ * cvmx_pko_pdm_flshb_dbg0
+ */
+union cvmx_pko_pdm_flshb_dbg0 {
+	uint64_t u64;
+	struct cvmx_pko_pdm_flshb_dbg0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_44_63               : 20;
+	uint64_t flshb_sm                     : 7;  /**< Flush buffer state machine */
+	uint64_t flshb_ctl_sm                 : 9;  /**< Flush buffer control state machine */
+	uint64_t cam_hptr                     : 5;  /**< Flush buffer CAM head pointer */
+	uint64_t cam_tptr                     : 5;  /**< Flush buffer CAM tail pointer */
+	uint64_t expected_stdns               : 6;  /**< Number of store done responses still pending */
+	uint64_t d_flshb_eot_cntr             : 3;  /**< Number of packet descriptor flush requests pending */
+	uint64_t m_flshb_eot_cntr             : 3;  /**< Number of meta packet flush requests pending */
+	uint64_t ncbi_credit_cntr             : 6;  /**< NCBI FIFO credit counter */
+#else
+	uint64_t ncbi_credit_cntr             : 6;
+	uint64_t m_flshb_eot_cntr             : 3;
+	uint64_t d_flshb_eot_cntr             : 3;
+	uint64_t expected_stdns               : 6;
+	uint64_t cam_tptr                     : 5;
+	uint64_t cam_hptr                     : 5;
+	uint64_t flshb_ctl_sm                 : 9;
+	uint64_t flshb_sm                     : 7;
+	uint64_t reserved_44_63               : 20;
+#endif
+	} s;
+	struct cvmx_pko_pdm_flshb_dbg0_s      cn78xx;
+};
+typedef union cvmx_pko_pdm_flshb_dbg0 cvmx_pko_pdm_flshb_dbg0_t;
+
+/**
+ * cvmx_pko_pdm_flshb_dbg1
+ */
+union cvmx_pko_pdm_flshb_dbg1 {
+	uint64_t u64;
+	struct cvmx_pko_pdm_flshb_dbg1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t cam_stdn                     : 32; /**< Flush buffer entry store done request flags */
+	uint64_t cam_valid                    : 32; /**< Flush buffer entry valid flags */
+#else
+	uint64_t cam_valid                    : 32;
+	uint64_t cam_stdn                     : 32;
+#endif
+	} s;
+	struct cvmx_pko_pdm_flshb_dbg1_s      cn78xx;
+};
+typedef union cvmx_pko_pdm_flshb_dbg1 cvmx_pko_pdm_flshb_dbg1_t;
+
+/**
  * cvmx_pko_pdm_isrd_dbg
  */
 union cvmx_pko_pdm_isrd_dbg {
@@ -8891,58 +9508,58 @@ union cvmx_pko_pdm_isrd_dbg {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_44_63               : 20;
 	uint64_t in_arb_reqs                  : 8;  /**< Input arbitration request signals. The order of the bits is:
-                                                         - 43: Fill response - normal path request
-                                                         - 42: Fill response - flushb path request
-                                                         - 41: CP queue-open request
-                                                         - 40: CP queue-closed request
-                                                         - 39: CP queue-query request
-                                                         - 38: CP send-packet request
-                                                         - 37: PEB fill request
-                                                         - 36: PEB read request */
+                                                         0x2B = Fill response - normal path request
+                                                         0x2A = Fill response - flushb path request
+                                                         0x29 = CP queue-open request
+                                                         0x28 = CP queue-closed request
+                                                         0x27 = CP queue-query request
+                                                         0x26 = CP send-packet request
+                                                         0x25 = PEB fill request
+                                                         0x24 = PEB read request */
 	uint64_t in_arb_gnts                  : 7;  /**< Input arbitration grant signals. The order of the bits is:
-                                                         - 35: Fill response grant
-                                                         - 34: CP - queue-open grant
-                                                         - 33: CP - queue-close grant
-                                                         - 32: CP - queue-query grant
-                                                         - 31: CP - send-packet grant
-                                                         - 30: PEB fill grant
-                                                         - 29: PEB read grant */
+                                                         0x23 = Fill response grant
+                                                         0x22 = CP - queue-open grant
+                                                         0x21 = CP - queue-close grant
+                                                         0x20 = CP - queue-query grant
+                                                         0x1F = CP - send-packet grant
+                                                         0x1E = PEB fill grant
+                                                         0x1D = PEB read grant */
 	uint64_t cmt_arb_reqs                 : 7;  /**< Commit arbitration request signals. The order of the bits is:
-                                                         - 28: Fill response grant
-                                                         - 27: CP - queue-open grant
-                                                         - 26: CP - queue-close grant
-                                                         - 25: CP - queue-query grant
-                                                         - 24: CP - send-packet grant
-                                                         - 23: PEB fill grant
-                                                         - 22: PEB read grant */
+                                                         0x1C = Fill response grant
+                                                         0x1B = CP - queue-open grant
+                                                         0x1A = CP - queue-close grant
+                                                         0x19 = CP - queue-query grant
+                                                         0x18 = CP - send-packet grant
+                                                         0x17 = PEB fill grant
+                                                         0x16 = PEB read grant */
 	uint64_t cmt_arb_gnts                 : 7;  /**< Commit arbitration grant signals. The order of the bits is:
-                                                         - 21: Fill response grant
-                                                         - 20: CP - queue-open grant
-                                                         - 19: CP - queue-close grant
-                                                         - 18: CP - queue-query grant
-                                                         - 17: CP - send-packet grant
-                                                         - 16: PEB fill grant
-                                                         - 15: PEB read grant */
+                                                         0x15 = Fill response grant
+                                                         0x14 = CP - queue-open grant
+                                                         0x13 = CP - queue-close grant
+                                                         0x12 = CP - queue-query grant
+                                                         0x11 = CP - send-packet grant
+                                                         0x10 = PEB fill grant
+                                                         0xF = PEB read grant */
 	uint64_t in_use                       : 4;  /**< In use signals indicate the execution units are in use. The order of the bits is:
-                                                         - 14: PEB fill unit
-                                                         - 13: PEB read unit
-                                                         - 12: CP unit
-                                                         - 11: Fill response unit */
+                                                         0xE = PEB fill unit
+                                                         0xD = PEB read unit
+                                                         0xC = CP unit
+                                                         0xB = Fill response unit */
 	uint64_t has_cred                     : 4;  /**< Has credit signals indicate there is sufficient credit to commit. The order of the bits
-                                                          is:
-                                                          - 10: Flush buffer has credit
-                                                         - 9: Fill buffer has credit
-                                                         - 8: DW command output FIFO has credit
-                                                         - 7: DR command output FIFO has credit */
+                                                         is:
+                                                         0xA = Flush buffer has credit
+                                                         0x9 = Fill buffer has credit
+                                                         0x8 = DW command output FIFO has credit
+                                                         0x7 = DR command output FIFO has credit */
 	uint64_t val_exec                     : 7;  /**< Valid bits for the execution units; means the unit can commit if it gets the grant of the
-                                                          commit arb and other conditions are met. The order of the bits is:
-                                                         - 6: Fill response unit
-                                                         - 5: CP unit - queue-open
-                                                         - 4: CP unit - queue-close
-                                                         - 3: CP unit - queue-probe
-                                                         - 2: CP unit - send-packet
-                                                         - 1: PEB fill unit
-                                                         - 0: PEB read unit */
+                                                         commit arb and other conditions are met. The order of the bits is:
+                                                         0x6 = Fill response unit
+                                                         0x5 = CP unit - queue-open
+                                                         0x4 = CP unit - queue-close
+                                                         0x3 = CP unit - queue-probe
+                                                         0x2 = CP unit - send-packet
+                                                         0x1 = PEB fill unit
+                                                         0x0 = PEB read unit */
 #else
 	uint64_t val_exec                     : 7;
 	uint64_t has_cred                     : 4;
@@ -8997,48 +9614,48 @@ union cvmx_pko_pdm_isrm_dbg {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_34_63               : 30;
 	uint64_t in_arb_reqs                  : 7;  /**< Input arbitration request signals. The order of the bits is:
-                                                         - 33: PSE ACK
-                                                         - 32: Fill Response - normal path request
-                                                         - 31: Fill Response - flushb path request
-                                                         - 30: CP queue-open
-                                                         - 29: CP queue-closed
-                                                         - 28: CP queue-query
-                                                         - 27: CP send-packet */
+                                                         0x21 = PSE ACK
+                                                         0x20 = Fill Response - normal path request
+                                                         0x1F = Fill Response - flushb path request
+                                                         0x1E = CP queue-open
+                                                         0x1D = CP queue-closed
+                                                         0x1C = CP queue-query
+                                                         0x1B = CP send-packet */
 	uint64_t in_arb_gnts                  : 6;  /**< Input arbitration grant signals. The order of the bits is:
-                                                         - 26: PSE ACK
-                                                         - 25: Fill Response
-                                                         - 24: CP - queue-open
-                                                         - 23: CP - queue-close
-                                                         - 22: CP - queue-query
-                                                         - 21: CP - send-packet */
+                                                         0x1A: PSE ACK
+                                                         0x19 = Fill Response
+                                                         0x18 = CP - queue-open
+                                                         0x17 = CP - queue-close
+                                                         0x16 = CP - queue-query
+                                                         0x15 = CP - send-packet */
 	uint64_t cmt_arb_reqs                 : 6;  /**< Commit arbitration request signals. The order of the bits is:
-                                                         - 20: PSE ACK
-                                                         - 19: Fill Response
-                                                         - 18: CP - queue-open
-                                                         - 17: CP - queue-close
-                                                         - 16: CP - queue-query
-                                                         - 15: CP - send-packet */
+                                                         0x14 = PSE ACK
+                                                         0x13 = Fill Response
+                                                         0x12 = CP - queue-open
+                                                         0x11 = CP - queue-close
+                                                         0x10 = CP - queue-query
+                                                         0xF CP - send-packet */
 	uint64_t cmt_arb_gnts                 : 6;  /**< Commit arbitration grant signals. The order of the bits is:
-                                                          - 14: PSE ACK
-                                                          - 13: Fill Response
-                                                          - 12: CP - queue-open
-                                                          - 11: CP - queue-close
-                                                          - 10: CP - queue-query
-                                                         - 9: CP - send-packet */
+                                                         0xE = PSE ACK
+                                                         0xD = Fill Response
+                                                         0xC = CP - queue-open
+                                                         0xB = CP - queue-close
+                                                         0xA = CP - queue-query
+                                                         0x9 = CP - send-packet */
 	uint64_t in_use                       : 3;  /**< In use signals indicate the execution units are in use. The order of the bits is:
-                                                         - 8: (PSE) ACK unit
-                                                         - 7: Fill response unit
-                                                         - 6: CP unit */
+                                                         0x8 = (PSE) ACK unit
+                                                         0x7 = Fill response unit
+                                                         0x6 = CP unit */
 	uint64_t has_cred                     : 3;  /**< Has credit signals indicate there is sufficient credit to commit. The order of the bits
-                                                          is:
-                                                         - 5: Flush buffer has credit
-                                                         - 4: Fill buffer has credit
-                                                         - 3: MWP command output FIFO has credit */
+                                                         is:
+                                                         0x5 = Flush buffer has credit
+                                                         0x4 = Fill buffer has credit
+                                                         0x3 = MWP command output FIFO has credit */
 	uint64_t val_exec                     : 3;  /**< Valid bits for the execution units; means the unit can commit if it gets the grant of the
-                                                          commit arb and other conditions are met. The order of the bits is:
-                                                         - 2: (PSE) ACK unit
-                                                         - 1: Fill response unit
-                                                         - 0: CP unit - ALL */
+                                                         commit arb and other conditions are met. The order of the bits is:
+                                                         0x2 = (PSE) ACK unit
+                                                         0x1 = Fill response unit
+                                                         0x0 = CP unit - ALL */
 #else
 	uint64_t val_exec                     : 3;
 	uint64_t has_cred                     : 3;
@@ -9114,9 +9731,9 @@ union cvmx_pko_pdm_mem_data {
 	uint64_t u64;
 	struct cvmx_pko_pdm_mem_data_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t data                         : 64; /**< Raw data to write into the memory, or the raw data read out from the memory.
-                                                         Note that the ISR RAMs are only 57 bits wide, so [56:0] are the only bits that can be read
-                                                         or written to them. The PBUFs are 64 bits wide. */
+	uint64_t data                         : 64; /**< Raw data to write into the memory, or the raw data read out from the memory. Note that the
+                                                         ISR RAMs are only 57 bits wide, so [56:0] are the only bits that can be read or written to
+                                                         them. The PBUFs are 64 bits wide. */
 #else
 	uint64_t data                         : 64;
 #endif
@@ -9181,7 +9798,10 @@ union cvmx_pko_pdm_mwpbuf_dbg {
 	uint64_t reserved_17_20               : 4;
 	uint64_t mem_addr                     : 13; /**< Memory address for pbuf ram. */
 	uint64_t mem_en                       : 4;  /**< Memory write/chip enable signals. The order of the bits is:
-                                                         - 3: low wen; 2: low cen; 1: high wen; 0: high cen. */
+                                                         0x3 = low wen
+                                                         0x2 = low cen
+                                                         0x1 = high wen
+                                                         0x0 = high cen. */
 #else
 	uint64_t mem_en                       : 4;
 	uint64_t mem_addr                     : 13;
@@ -9208,9 +9828,9 @@ union cvmx_pko_pdm_sts {
 	struct cvmx_pko_pdm_sts_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_38_63               : 26;
-	uint64_t cp_stalled_thrshld_hit       : 1;  /**< This register is set to 1 if the PDM stalls the inputs for more than
-                                                         PKO_PDM_CFG_DBG[CP_STALL_THRSHLD]. INTERNAL: Do not list field in HRM. For lab debug only;
-                                                         will likely disapear in pass 2. */
+	uint64_t cp_stalled_thrshld_hit       : 1;  /**< Reserved. INTERNAL: This register is set to 1 if the PDM stalls the inputs for more than
+                                                         PKO_PDM_CFG_DBG[CP_STALL_THRSHLD]: Do not list field in HRM. For lab debug only; will
+                                                         likely disappear in pass 2. */
 	uint64_t reserved_35_36               : 2;
 	uint64_t mwpbuf_data_val_err          : 1;  /**< Received signal that MWPBUF had data valid error. Throws
                                                          PKO_INTSN_E::PKO_MWPBUF_DATA_VAL_ERR. */
@@ -9227,7 +9847,7 @@ union cvmx_pko_pdm_sts {
                                                          PKO_PDM_STS[QCMD_IOBX_ERR_STS] contains the status code. Note that FPA being out of
                                                          pointers does not set this bit. (See PKO_FPA_NO_PTRS). Throws
                                                          PKO_INTSN_E::PKO_QCMD_IOBX_ERR. */
-	uint64_t sendpkt_lmtdma_err_sts       : 4;  /**< Status field of the command response on the LMTDMA failure indicated by
+	uint64_t sendpkt_lmtdma_err_sts       : 4;  /**< This is the status field of the command response on the LMTDMA failure indicated by
                                                          PKO_PDM_STS[SENDPKT_LMTDMA_ERR] bits being asserted. Note that if multiple errors occur,
                                                          only the first error status is captured here until PKO_PDM_STS[SENDPKT_LMTDMA_ERR] is
                                                          cleared. Enumerated by PKO_DQSTATUS_E. */
@@ -9235,23 +9855,21 @@ union cvmx_pko_pdm_sts {
                                                          PKO_PDM_STS[SENDPKT_LMTDMA_ERR_STS] contains the status code. Note that FPA being out of
                                                          pointers does not set this bit. (See PKO_FPA_NO_PTRS). Throws
                                                          PKO_INTSN_E::PKO_SENDPKT_LMTDMA_ERR. */
-	uint64_t sendpkt_lmtst_err_sts        : 4;  /**< Status field of the command response on the LMTST failure indicated by
-                                                         PKO_PDM_STS[SENDPKT_LMTST_ERR] bits being asserted.
-                                                         Note that if multiple errors occur only the first error status will be captured here until
-                                                         PKO_PDM_STS[SENDPKT_LMTST_ERR] is cleared.
-                                                         Enumerated by PKO_DQSTATUS_E. */
+	uint64_t sendpkt_lmtst_err_sts        : 4;  /**< This is the status field of the command response on the LMTST failure indicated by
+                                                         PKO_PDM_STS[SENDPKT_LMTST_ERR] bits being asserted. Note that if multiple errors occur
+                                                         only the first error status will be captured here until PKO_PDM_STS[SENDPKT_LMTST_ERR] is
+                                                         cleared. Enumerated by PKO_DQSTATUS_E. */
 	uint64_t sendpkt_lmtst_err            : 1;  /**< Send-packet of type LMTST error status occurred in PKO/PDM.
                                                          PKO_PDM_STS[SENDPKT_LMTST_ERR_STS] contains the status code. Note that FPA being out of
                                                          pointers does not set this bit. (See PKO_FPA_NO_PTRS). Throws
                                                          PKO_INTSN_E::PKO_SENDPKT_LMTST_ERR. */
-	uint64_t fpa_no_ptrs                  : 1;  /**< FPA signalled PKO that FPA can not allocate pointers. This is a fatal error.
-                                                         Throws PKO_INTSN_E::PKO_FPA_NO_PTRS. */
+	uint64_t fpa_no_ptrs                  : 1;  /**< FPA signaled PKO that FPA can not allocate pointers. This is a fatal error. Throws
+                                                         PKO_INTSN_E::PKO_FPA_NO_PTRS. */
 	uint64_t reserved_12_13               : 2;
 	uint64_t cp_sendpkt_err_no_drp_code   : 2;  /**< This field stores the error code for illegally constructed send-packets that did not drop.
                                                          Note that if multiple errors occur, only the first error code is captured here until
-                                                         PKO_PDM_STS[CP_SENDPKT_ERR_NO_DRP] is cleared. Codes:
-                                                         2'b00: NO ERROR CODE
-                                                         2'b01: SEND_JUMP not at end of descriptor. */
+                                                         PKO_PDM_STS[CP_SENDPKT_ERR_NO_DRP] is cleared. Codes: 0x0 = NO ERROR CODE. 0x1 = SEND_JUMP
+                                                         not at end of descriptor. */
 	uint64_t cp_sendpkt_err_no_drp        : 1;  /**< PKO/PDM/CP did not drop a send-packet; however, the SEND_JUMP command is not at end of the
                                                          descriptor. The error code is captured in PKO_PDM_STS[CP_SENDPKT_ERR_NO_DRP_CODE]. Throws
                                                          PKO_INTSN_E::PKO_CP_SENDPKT_ERR_NO_DRP. */
@@ -9492,71 +10110,49 @@ union cvmx_pko_peb_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_peb_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t iobp1_uid_fifo_ram_dbe       : 1;  /**< Double-bit error for IOBP1_UID_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t iobp1_uid_fifo_ram_dbe       : 1;  /**< Double-bit error for IOBP1_UID_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_uid_fifo_i */
-	uint64_t iobp0_fifo_ram_dbe           : 1;  /**< Double-bit error for IOBP0_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t iobp0_fifo_ram_dbe           : 1;  /**< Double-bit error for IOBP0_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_iobp0_fifo_i */
-	uint64_t iobp1_fifo_ram_dbe           : 1;  /**< Double-bit error for IOBP1_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t iobp1_fifo_ram_dbe           : 1;  /**< Double-bit error for IOBP1_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i */
-	uint64_t pdm_resp_buf_ram_dbe         : 1;  /**< Double-bit error for PDM_RESP_BUF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pdm_resp_buf_ram_dbe         : 1;  /**< Double-bit error for PDM_RESP_BUF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i */
-	uint64_t pdm_pse_buf_ram_dbe          : 1;  /**< Double-bit error for PDM_PSE_BUF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pdm_pse_buf_ram_dbe          : 1;  /**< Double-bit error for PDM_PSE_BUF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i */
-	uint64_t peb_sm_jmp_ram_dbe           : 1;  /**< Double-bit error for PEB_SM_JMP_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t peb_sm_jmp_ram_dbe           : 1;  /**< Double-bit error for PEB_SM_JMP_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i */
-	uint64_t peb_st_inf_ram_dbe           : 1;  /**< Double-bit error for PEB_ST_INF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t peb_st_inf_ram_dbe           : 1;  /**< Double-bit error for PEB_ST_INF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i */
-	uint64_t pd_bank3_ram_dbe             : 1;  /**< Double-bit error for PD_BANK3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_bank3_ram_dbe             : 1;  /**< Double-bit error for PD_BANK3_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank3_i */
-	uint64_t pd_bank2_ram_dbe             : 1;  /**< Double-bit error for PD_BANK2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_bank2_ram_dbe             : 1;  /**< Double-bit error for PD_BANK2_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank2_i */
-	uint64_t pd_bank1_ram_dbe             : 1;  /**< Double-bit error for PD_BANK1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_bank1_ram_dbe             : 1;  /**< Double-bit error for PD_BANK1_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank1_i */
-	uint64_t pd_bank0_ram_dbe             : 1;  /**< Double-bit error for PD_BANK0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_bank0_ram_dbe             : 1;  /**< Double-bit error for PD_BANK0_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank0_i */
-	uint64_t pd_var_bank_ram_dbe          : 1;  /**< Double-bit error for PD_VAR_BANK_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_var_bank_ram_dbe          : 1;  /**< Double-bit error for PD_VAR_BANK_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_var_mem_bank_i */
-	uint64_t tx_fifo_crc_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_CRC_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tx_fifo_crc_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_CRC_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_crc_i */
-	uint64_t tx_fifo_hdr_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_HDR_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tx_fifo_hdr_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_HDR_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_hdr_i */
-	uint64_t tx_fifo_pkt_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_PKT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tx_fifo_pkt_ram_dbe          : 1;  /**< Double-bit error for TX_FIFO_PKT_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_pkt_i */
-	uint64_t add_work_fifo_dbe            : 1;  /**< Double-bit error for ADD_WORK_FIFO.
-                                                         INTERNAL: Instances:
+	uint64_t add_work_fifo_dbe            : 1;  /**< Double-bit error for ADD_WORK_FIFO. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_add_work_fifo_i */
-	uint64_t send_mem_fifo_dbe            : 1;  /**< Double-bit error for SEND_MEM_FIFO.
-                                                         INTERNAL: Instances:
+	uint64_t send_mem_fifo_dbe            : 1;  /**< Double-bit error for SEND_MEM_FIFO. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_fifo_i */
-	uint64_t send_mem_stdn_fifo_dbe       : 1;  /**< Double-bit error for SEND_MEM_STDN_FIFO.
-                                                         INTERNAL: Instances:
+	uint64_t send_mem_stdn_fifo_dbe       : 1;  /**< Double-bit error for SEND_MEM_STDN_FIFO. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_stdn_fifo_i */
-	uint64_t send_mem_ts_fifo_dbe         : 1;  /**< Double-bit error for SEND_MEM_TS_FIFO.
-                                                         INTERNAL: Instances:
+	uint64_t send_mem_ts_fifo_dbe         : 1;  /**< Double-bit error for SEND_MEM_TS_FIFO. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_ts_fifo_i */
-	uint64_t nxt_link_ptr_ram_dbe         : 1;  /**< Double-bit error for NXT_LINK_PTR_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t nxt_link_ptr_ram_dbe         : 1;  /**< Double-bit error for NXT_LINK_PTR_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_nxt_link_ptr_mem_i */
-	uint64_t pkt_mrk_ram_dbe              : 1;  /**< Double-bit error for PKT_MRK_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pkt_mrk_ram_dbe              : 1;  /**< Double-bit error for PKT_MRK_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pkt_mrk_mem_i */
-	uint64_t ts_addwork_ram_dbe           : 1;  /**< Double-bit error for TS_ADDWORK_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ts_addwork_ram_dbe           : 1;  /**< Double-bit error for TS_ADDWORK_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_ts_addwork_mem_i */
 	uint64_t reserved_0_41                : 42;
 #else
@@ -9596,11 +10192,9 @@ union cvmx_pko_peb_ecc_dbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_peb_ecc_dbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t peb_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PEB_ECC_DBE_STS.
-                                                         To clear this bit, software must clear bits in PKO_PEB_ECC_DBE_STS.
-                                                         When this bit is set, the corresponding interrupt is set.
-                                                         Throws PKO_INTSN_E::PKO_PEB_DBE_CMB0.
-                                                         INTERNAL: Instances:
+	uint64_t peb_dbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PEB_ECC_DBE_STS. To clear this bit, software
+                                                         must clear bits in PKO_PEB_ECC_DBE_STS. When this bit is set, the corresponding interrupt
+                                                         is set. Throws PKO_INTSN_E::PKO_PEB_DBE_CMB0. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_uid_fifo_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_iobp0_fifo_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i
@@ -9640,71 +10234,49 @@ union cvmx_pko_peb_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_peb_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t iobp1_uid_fifo_ram_sbe       : 1;  /**< Single-bit error for IOBP1_UID_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t iobp1_uid_fifo_ram_sbe       : 1;  /**< Single-bit error for IOBP1_UID_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_uid_fifo_i */
-	uint64_t iobp0_fifo_ram_sbe           : 1;  /**< Single-bit error for IOBP0_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t iobp0_fifo_ram_sbe           : 1;  /**< Single-bit error for IOBP0_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_iobp0_fifo_i */
-	uint64_t iobp1_fifo_ram_sbe           : 1;  /**< Single-bit error for IOBP1_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t iobp1_fifo_ram_sbe           : 1;  /**< Single-bit error for IOBP1_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i */
-	uint64_t pdm_resp_buf_ram_sbe         : 1;  /**< Single-bit error for PDM_RESP_BUF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pdm_resp_buf_ram_sbe         : 1;  /**< Single-bit error for PDM_RESP_BUF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i */
-	uint64_t pdm_pse_buf_ram_sbe          : 1;  /**< Single-bit error for PDM_PSE_BUF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pdm_pse_buf_ram_sbe          : 1;  /**< Single-bit error for PDM_PSE_BUF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i */
-	uint64_t peb_sm_jmp_ram_sbe           : 1;  /**< Single-bit error for PEB_SM_JMP_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t peb_sm_jmp_ram_sbe           : 1;  /**< Single-bit error for PEB_SM_JMP_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i */
-	uint64_t peb_st_inf_ram_sbe           : 1;  /**< Single-bit error for PEB_ST_INF_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t peb_st_inf_ram_sbe           : 1;  /**< Single-bit error for PEB_ST_INF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i */
-	uint64_t pd_bank3_ram_sbe             : 1;  /**< Single-bit error for PD_BANK3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_bank3_ram_sbe             : 1;  /**< Single-bit error for PD_BANK3_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank3_i */
-	uint64_t pd_bank2_ram_sbe             : 1;  /**< Single-bit error for PD_BANK2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_bank2_ram_sbe             : 1;  /**< Single-bit error for PD_BANK2_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank2_i */
-	uint64_t pd_bank1_ram_sbe             : 1;  /**< Single-bit error for PD_BANK1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_bank1_ram_sbe             : 1;  /**< Single-bit error for PD_BANK1_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank1_i */
-	uint64_t pd_bank0_ram_sbe             : 1;  /**< Single-bit error for PD_BANK1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_bank0_ram_sbe             : 1;  /**< Single-bit error for PD_BANK1_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank0_i */
-	uint64_t pd_var_bank_ram_sbe          : 1;  /**< Single-bit error for PD_VAR_BANK_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pd_var_bank_ram_sbe          : 1;  /**< Single-bit error for PD_VAR_BANK_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_var_mem_bank_i */
-	uint64_t tx_fifo_crc_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_CRC_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tx_fifo_crc_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_CRC_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_crc_i */
-	uint64_t tx_fifo_hdr_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_HDR_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tx_fifo_hdr_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_HDR_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_hdr_i */
-	uint64_t tx_fifo_pkt_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_PKT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tx_fifo_pkt_ram_sbe          : 1;  /**< Single-bit error for TX_FIFO_PKT_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_tx_fifo_i.pko_peb_tx_fifo_pkt_i */
-	uint64_t add_work_fifo_sbe            : 1;  /**< Single-bit error for ADD_WORK_FIFO.
-                                                         INTERNAL: Instances:
+	uint64_t add_work_fifo_sbe            : 1;  /**< Single-bit error for ADD_WORK_FIFO. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_add_work_fifo_i */
-	uint64_t send_mem_fifo_sbe            : 1;  /**< Single-bit error for SEND_MEM_FIFO.
-                                                         INTERNAL: Instances:
+	uint64_t send_mem_fifo_sbe            : 1;  /**< Single-bit error for SEND_MEM_FIFO. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_fifo_i */
-	uint64_t send_mem_stdn_fifo_sbe       : 1;  /**< Single-bit error for SEND_MEM_STDN_FIFO.
-                                                         INTERNAL: Instances:
+	uint64_t send_mem_stdn_fifo_sbe       : 1;  /**< Single-bit error for SEND_MEM_STDN_FIFO. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_stdn_fifo_i */
-	uint64_t send_mem_ts_fifo_sbe         : 1;  /**< Single-bit error for SEND_MEM_TS_FIFO.
-                                                         INTERNAL: Instances:
+	uint64_t send_mem_ts_fifo_sbe         : 1;  /**< Single-bit error for SEND_MEM_TS_FIFO. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_sendmem_proc_i.pko_peb_send_mem_ts_fifo_i */
-	uint64_t nxt_link_ptr_ram_sbe         : 1;  /**< Single-bit error for NXT_LINK_PTR_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t nxt_link_ptr_ram_sbe         : 1;  /**< Single-bit error for NXT_LINK_PTR_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_nxt_link_ptr_mem_i */
-	uint64_t pkt_mrk_ram_sbe              : 1;  /**< Single-bit error for PKT_MRK_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pkt_mrk_ram_sbe              : 1;  /**< Single-bit error for PKT_MRK_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pkt_mrk_mem_i */
-	uint64_t ts_addwork_ram_sbe           : 1;  /**< Single-bit error for TS_ADDWORK_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t ts_addwork_ram_sbe           : 1;  /**< Single-bit error for TS_ADDWORK_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_addwork_proc_i.pko_peb_ts_addwork_mem_i */
 	uint64_t reserved_0_41                : 42;
 #else
@@ -9744,11 +10316,9 @@ union cvmx_pko_peb_ecc_sbe_sts_cmb0 {
 	uint64_t u64;
 	struct cvmx_pko_peb_ecc_sbe_sts_cmb0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t peb_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PEB_ECC_SBE_STS.
-                                                         To clear this bit, software must clear bits in PKO_PEB_ECC_SBE_STS.
-                                                         When this bit is set, the corresponding interrupt is set.
-                                                         Throws PKO_INTSN_E::PKO_PEB_SBE_CMB0.
-                                                         INTERNAL: Instances:
+	uint64_t peb_sbe_cmb0                 : 1;  /**< This bit is the logical OR of all bits in PKO_PEB_ECC_SBE_STS. To clear this bit, software
+                                                         must clear bits in PKO_PEB_ECC_SBE_STS. When this bit is set, the corresponding interrupt
+                                                         is set. Throws PKO_INTSN_E::PKO_PEB_SBE_CMB0. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_uid_fifo_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_iobp0_fifo_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i
@@ -9789,24 +10359,24 @@ union cvmx_pko_peb_err_int {
 	struct cvmx_pko_peb_err_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
-	uint64_t peb_macx_cfg_wr_err          : 1;  /**< Asserted when software writes a FIFO number to PKO_MACx_CFG when that FIFO is already
-                                                         assigned. Throws PKO_INTSN_E::PEB_MACX_CFG_WR_ERR. */
-	uint64_t peb_max_link_err             : 1;  /**< Asserted when 200 LINK segments have been followed.  Indicates likelihood of infinite
-                                                         loop.  Throws PKO_INTSN_E::PEB_MAX_LINK_ERR. */
-	uint64_t peb_subd_size_err            : 1;  /**< Asserted when a SEND_LINK/GATHER/IMM/JUMP subD has size=0.  Throws
+	uint64_t peb_macx_cfg_wr_err          : 1;  /**< Asserted when software writes a FIFO number to PKO_MAC(0..27)_CFG when that FIFO is
+                                                         already assigned. Throws PKO_INTSN_E::PEB_MACX_CFG_WR_ERR. */
+	uint64_t peb_max_link_err             : 1;  /**< Asserted when 200 LINK segments have been followed. Indicates likelihood of infinite loop.
+                                                         Throws PKO_INTSN_E::PEB_MAX_LINK_ERR. */
+	uint64_t peb_subd_size_err            : 1;  /**< Asserted when a SEND_LINK/GATHER/IMM/JUMP subD has size=0. Throws
                                                          PKO_INTSN_E::PEB_SUBD_SIZE_ERR. */
-	uint64_t peb_subd_addr_err            : 1;  /**< Asserted when the address of a FREE/MEM/LINK/LINK segment/JUMP/GATHER subD is 0x0.  Throws
+	uint64_t peb_subd_addr_err            : 1;  /**< Asserted when the address of a FREE/MEM/LINK/LINK segment/JUMP/GATHER subD is 0x0. Throws
                                                          PKO_INTSN_E::PEB_SUBD_ADDR_ERR. */
-	uint64_t peb_trunc_err                : 1;  /**< Asserted when a PD has truncated data.  Throws PKO_INTSN_E::PEB_TRUNC_ERR. */
-	uint64_t peb_pad_err                  : 1;  /**< Asserted when a PD has data padded to it (SEND_HDR[TOTAL] < sum(SEND_DATA[size])).  Throws
+	uint64_t peb_trunc_err                : 1;  /**< Asserted when a PD has truncated data. Throws PKO_INTSN_E::PEB_TRUNC_ERR. */
+	uint64_t peb_pad_err                  : 1;  /**< Asserted when a PD has data padded to it (SEND_HDR[TOTAL] < sum(SEND_DATA[size])). Throws
                                                          PKO_INTSN_E::PEB_PAD_ERR. */
 	uint64_t peb_pse_fifo_err             : 1;  /**< Asserted when PSE sends PD information for a nonconfigured FIFO. Throws
                                                          PKO_INTSN_E::PEB_PSE_FIFO_ERR. */
-	uint64_t peb_fcs_sop_err              : 1;  /**< Asserted when FCS SOP value greater than packet size detected.  Throws
+	uint64_t peb_fcs_sop_err              : 1;  /**< Asserted when FCS SOP value greater than packet size detected. Throws
                                                          PKO_INTSN_E::PEB_FCS_SOP_ERR. */
 	uint64_t peb_jump_def_err             : 1;  /**< Asserted when JUMP subdescriptor is not last in a PD. Throws
                                                          PKO_INTSN_E::PEB_JUMP_DEF_ERR. */
-	uint64_t peb_ext_hdr_def_err          : 1;  /**< Asserted when EXT_HDR is not the second sub-descriptor in a PD.  Throws
+	uint64_t peb_ext_hdr_def_err          : 1;  /**< Asserted when EXT_HDR is not the second sub-descriptor in a PD. Throws
                                                          PKO_INTSN_E::PEB_EXT_HDR_DEF_ERR. */
 #else
 	uint64_t peb_ext_hdr_def_err          : 1;
@@ -10045,6 +10615,22 @@ union cvmx_pko_peb_trunc_err_info {
 typedef union cvmx_pko_peb_trunc_err_info cvmx_pko_peb_trunc_err_info_t;
 
 /**
+ * cvmx_pko_pq_csr_bus_debug
+ */
+union cvmx_pko_pq_csr_bus_debug {
+	uint64_t u64;
+	struct cvmx_pko_pq_csr_bus_debug_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t csr_bus_debug                : 64; /**< N/A */
+#else
+	uint64_t csr_bus_debug                : 64;
+#endif
+	} s;
+	struct cvmx_pko_pq_csr_bus_debug_s    cn78xx;
+};
+typedef union cvmx_pko_pq_csr_bus_debug cvmx_pko_pq_csr_bus_debug_t;
+
+/**
  * cvmx_pko_pq_debug_green
  */
 union cvmx_pko_pq_debug_green {
@@ -10088,9 +10674,11 @@ union cvmx_pko_pq_debug_yellow {
 	struct cvmx_pko_pq_debug_yellow_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t y_valid                      : 32; /**< y_valid vector. */
-	uint64_t link_vv                      : 32; /**< link_vv vector. */
+	uint64_t reserved_28_31               : 4;
+	uint64_t link_vv                      : 28; /**< link_vv vector. */
 #else
-	uint64_t link_vv                      : 32;
+	uint64_t link_vv                      : 28;
+	uint64_t reserved_28_31               : 4;
 	uint64_t y_valid                      : 32;
 #endif
 	} s;
@@ -10116,6 +10704,9 @@ typedef union cvmx_pko_pqa_debug cvmx_pko_pqa_debug_t;
 
 /**
  * cvmx_pko_pqb_debug
+ *
+ * This register has the same bit fields as PKO_PQA_DEBUG.
+ *
  */
 union cvmx_pko_pqb_debug {
 	uint64_t u64;
@@ -10226,33 +10817,15 @@ union cvmx_pko_pse_dq_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_dq_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq_wt_ram_dbe                : 1;  /**< Double-bit error for DQ_WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.wt_sram */
-	uint64_t dq_rt7_dbe                   : 1;  /**< Double-bit error for DQ_RT7_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt7 */
-	uint64_t dq_rt6_dbe                   : 1;  /**< Double-bit error for DQ_RT6_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt6 */
-	uint64_t dq_rt5_dbe                   : 1;  /**< Double-bit error for DQ_RT5_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt5 */
-	uint64_t dq_rt4_dbe                   : 1;  /**< Double-bit error for DQ_RT4_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt4 */
-	uint64_t dq_rt3_dbe                   : 1;  /**< Double-bit error for DQ_RT3_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt3 */
-	uint64_t dq_rt2_dbe                   : 1;  /**< Double-bit error for DQ_RT2_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt2 */
-	uint64_t dq_rt1_dbe                   : 1;  /**< Double-bit error for DQ_RT1_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt1 */
-	uint64_t dq_rt0_dbe                   : 1;  /**< Double-bit error for DQ_RT0_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt0 */
+	uint64_t dq_wt_ram_dbe                : 1;  /**< Double-bit error for DQ_WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.wt_sram */
+	uint64_t dq_rt7_dbe                   : 1;  /**< Double-bit error for DQ_RT7_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt7 */
+	uint64_t dq_rt6_dbe                   : 1;  /**< Double-bit error for DQ_RT6_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt6 */
+	uint64_t dq_rt5_dbe                   : 1;  /**< Double-bit error for DQ_RT5_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt5 */
+	uint64_t dq_rt4_dbe                   : 1;  /**< Double-bit error for DQ_RT4_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt4 */
+	uint64_t dq_rt3_dbe                   : 1;  /**< Double-bit error for DQ_RT3_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt3 */
+	uint64_t dq_rt2_dbe                   : 1;  /**< Double-bit error for DQ_RT2_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt2 */
+	uint64_t dq_rt1_dbe                   : 1;  /**< Double-bit error for DQ_RT1_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt1 */
+	uint64_t dq_rt0_dbe                   : 1;  /**< Double-bit error for DQ_RT0_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt0 */
 	uint64_t reserved_0_54                : 55;
 #else
 	uint64_t reserved_0_54                : 55;
@@ -10309,33 +10882,15 @@ union cvmx_pko_pse_dq_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_dq_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t dq_wt_ram_sbe                : 1;  /**< Single-bit error for DQ_WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.wt_sram */
-	uint64_t dq_rt7_sbe                   : 1;  /**< Single-bit error for DQ_RT7_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt7 */
-	uint64_t dq_rt6_sbe                   : 1;  /**< Single-bit error for DQ_RT6_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt6 */
-	uint64_t dq_rt5_sbe                   : 1;  /**< Single-bit error for DQ_RT5_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt5 */
-	uint64_t dq_rt4_sbe                   : 1;  /**< Single-bit error for DQ_RT4_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt4 */
-	uint64_t dq_rt3_sbe                   : 1;  /**< Single-bit error for DQ_RT3_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt3 */
-	uint64_t dq_rt2_sbe                   : 1;  /**< Single-bit error for DQ_RT2_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt2 */
-	uint64_t dq_rt1_sbe                   : 1;  /**< Single-bit error for DQ_RT1_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt1 */
-	uint64_t dq_rt0_sbe                   : 1;  /**< Single-bit error for DQ_RT0_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_dq.rt0 */
+	uint64_t dq_wt_ram_sbe                : 1;  /**< Single-bit error for DQ_WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.wt_sram */
+	uint64_t dq_rt7_sbe                   : 1;  /**< Single-bit error for DQ_RT7_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt7 */
+	uint64_t dq_rt6_sbe                   : 1;  /**< Single-bit error for DQ_RT6_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt6 */
+	uint64_t dq_rt5_sbe                   : 1;  /**< Single-bit error for DQ_RT5_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt5 */
+	uint64_t dq_rt4_sbe                   : 1;  /**< Single-bit error for DQ_RT4_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt4 */
+	uint64_t dq_rt3_sbe                   : 1;  /**< Single-bit error for DQ_RT3_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt3 */
+	uint64_t dq_rt2_sbe                   : 1;  /**< Single-bit error for DQ_RT2_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt2 */
+	uint64_t dq_rt1_sbe                   : 1;  /**< Single-bit error for DQ_RT1_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt1 */
+	uint64_t dq_rt0_sbe                   : 1;  /**< Single-bit error for DQ_RT0_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_dq.rt0 */
 	uint64_t reserved_0_54                : 55;
 #else
 	uint64_t reserved_0_54                : 55;
@@ -10489,29 +11044,20 @@ union cvmx_pko_pse_pq_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_pq_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pq_cxs_ram_dbe               : 1;  /**< Double-bit error for PQ_CXS_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_cxs_ram_dbe               : 1;  /**< Double-bit error for PQ_CXS_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.cxs_sram */
-	uint64_t pq_cxd_ram_dbe               : 1;  /**< Double-bit error for PQ_CXD_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_cxd_ram_dbe               : 1;  /**< Double-bit error for PQ_CXD_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.cxd_sram */
-	uint64_t irq_fifo_sram_dbe            : 1;  /**< Double-bit error for IRQ_FIFO_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t irq_fifo_sram_dbe            : 1;  /**< Double-bit error for IRQ_FIFO_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.irq_fifo_sram */
-	uint64_t tp_sram_dbe                  : 1;  /**< Double-bit error for TP_SRAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.tp_sram */
-	uint64_t pq_std_ram_dbe               : 1;  /**< Double-bit error for PQ_STD_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp_sram_dbe                  : 1;  /**< Double-bit error for TP_SRAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.pq.tp_sram */
+	uint64_t pq_std_ram_dbe               : 1;  /**< Double-bit error for PQ_STD_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.std_sram */
-	uint64_t pq_st_ram_dbe                : 1;  /**< Double-bit error for PQ_ST_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_st_ram_dbe                : 1;  /**< Double-bit error for PQ_ST_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.st_sram */
-	uint64_t pq_wmd_ram_dbe               : 1;  /**< Double-bit error for PQ_WMD_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_wmd_ram_dbe               : 1;  /**< Double-bit error for PQ_WMD_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.wmd_sram */
-	uint64_t pq_wms_ram_dbe               : 1;  /**< Double-bit error for PQ_WMS_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_wms_ram_dbe               : 1;  /**< Double-bit error for PQ_WMS_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.wms_sram */
 	uint64_t reserved_0_55                : 56;
 #else
@@ -10567,29 +11113,20 @@ union cvmx_pko_pse_pq_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_pq_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t pq_cxs_ram_sbe               : 1;  /**< Single-bit error for PQ_CXS_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_cxs_ram_sbe               : 1;  /**< Single-bit error for PQ_CXS_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.cxs_sram */
-	uint64_t pq_cxd_ram_sbe               : 1;  /**< Single-bit error for PQ_CXD_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_cxd_ram_sbe               : 1;  /**< Single-bit error for PQ_CXD_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.cxd_sram */
-	uint64_t irq_fifo_sram_sbe            : 1;  /**< Single-bit error for IRQ_FIFO_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t irq_fifo_sram_sbe            : 1;  /**< Single-bit error for IRQ_FIFO_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.irq_fifo_sram */
-	uint64_t tp_sram_sbe                  : 1;  /**< Single-bit error for TP_SRAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.pq.tp_sram */
-	uint64_t pq_std_ram_sbe               : 1;  /**< Single-bit error for PQ_STD_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp_sram_sbe                  : 1;  /**< Single-bit error for TP_SRAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.pq.tp_sram */
+	uint64_t pq_std_ram_sbe               : 1;  /**< Single-bit error for PQ_STD_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.std_sram */
-	uint64_t pq_st_ram_sbe                : 1;  /**< Single-bit error for PQ_ST_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_st_ram_sbe                : 1;  /**< Single-bit error for PQ_ST_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.st_sram */
-	uint64_t pq_wmd_ram_sbe               : 1;  /**< Single-bit error for PQ_WMD_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_wmd_ram_sbe               : 1;  /**< Single-bit error for PQ_WMD_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.wmd_sram */
-	uint64_t pq_wms_ram_sbe               : 1;  /**< Single-bit error for PQ_WMS_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t pq_wms_ram_sbe               : 1;  /**< Single-bit error for PQ_WMS_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.pq.wms_sram */
 	uint64_t reserved_0_55                : 56;
 #else
@@ -10794,60 +11331,38 @@ union cvmx_pko_pse_sq1_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq1_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t cxs_ram_dbe                  : 1;  /**< Double-bit error for CXS_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t cxs_ram_dbe                  : 1;  /**< Double-bit error for CXS_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxs_sram */
-	uint64_t cxd_ram_dbe                  : 1;  /**< Double-bit error for CXD_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t cxd_ram_dbe                  : 1;  /**< Double-bit error for CXD_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxd_sram */
-	uint64_t vc1_sram_dbe                 : 1;  /**< Double-bit error for VC1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t vc1_sram_dbe                 : 1;  /**< Double-bit error for VC1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc1_sram */
-	uint64_t vc0_sram_dbe                 : 1;  /**< Double-bit error for VC0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t vc0_sram_dbe                 : 1;  /**< Double-bit error for VC0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc0_sram */
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.nt_sram */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.pt_sram */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.rt_sram */
-	uint64_t pc_ram_dbe                   : 1;  /**< Double-bit error for PC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pc_sram */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq1.rt_sram */
+	uint64_t pc_ram_dbe                   : 1;  /**< Double-bit error for PC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq1.pc_sram */
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_0.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_1.sq_fifo_sram */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp0_sram */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp1_sram */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts1_sram */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts0_sram */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.std1_sram */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.std0_sram */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.wt_sram */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sc_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq1.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq1.sc_sram */
 	uint64_t reserved_0_45                : 46;
 #else
 	uint64_t reserved_0_45                : 46;
@@ -10922,60 +11437,38 @@ union cvmx_pko_pse_sq1_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq1_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t cxs_ram_sbe                  : 1;  /**< Single-bit error for CXS_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t cxs_ram_sbe                  : 1;  /**< Single-bit error for CXS_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxs_sram */
-	uint64_t cxd_ram_sbe                  : 1;  /**< Single-bit error for CXD_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t cxd_ram_sbe                  : 1;  /**< Single-bit error for CXD_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.cxd_sram */
-	uint64_t vc1_sram_sbe                 : 1;  /**< Single-bit error for VC1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t vc1_sram_sbe                 : 1;  /**< Single-bit error for VC1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc0_sram */
-	uint64_t vc0_sram_sbe                 : 1;  /**< Single-bit error for VC0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t vc0_sram_sbe                 : 1;  /**< Single-bit error for VC0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.vc1_sram */
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.nt_sram */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.pt_sram */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.rt_sram */
-	uint64_t pc_ram_sbe                   : 1;  /**< Single-bit error for PC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.pc_sram */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq1.rt_sram */
+	uint64_t pc_ram_sbe                   : 1;  /**< Single-bit error for PC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq1.pc_sram */
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_0.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.tw_1.sq_fifo_sram */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp0_sram */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.tp1_sram */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts0_sram */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.sts1_sram */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.std0_sram */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.std1_sram */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.wt_sram */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq1.sc_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq1.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq1.sc_sram */
 	uint64_t reserved_0_45                : 46;
 #else
 	uint64_t reserved_0_45                : 46;
@@ -11167,45 +11660,29 @@ union cvmx_pko_pse_sq2_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq2_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.nt_sram */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.pt_sram */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.rt_sram */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq2.rt_sram */
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_1.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_0.sq_fifo_sram */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp1_sram */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp0_sram */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts1_sram */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts0_sram */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.std1_sram */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.std0_sram */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.wt_sram */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sc_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq2.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq2.sc_sram */
 	uint64_t reserved_0_50                : 51;
 #else
 	uint64_t reserved_0_50                : 51;
@@ -11270,45 +11747,29 @@ union cvmx_pko_pse_sq2_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq2_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.nt_sram */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.pt_sram */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.rt_sram */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq2.rt_sram */
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_1.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.tw_0.sq_fifo_sram */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp1_sram */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq2.tp0_sram */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts1_sram */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.sts0_sram */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.std1_sram */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq2_pq.sq1.std0_sram */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.wt_sram */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq2_pq.sq2.sc_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq2.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq2_pq.sq2.sc_sram */
 	uint64_t reserved_0_50                : 51;
 #else
 	uint64_t reserved_0_50                : 51;
@@ -11534,69 +11995,45 @@ union cvmx_pko_pse_sq3_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq3_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.nt_sram */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.pt_sram */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.rt_sram */
-	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq3.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_3.sq_fifo_sram */
-	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_2.sq_fifo_sram */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_1.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_0.sq_fifo_sram */
-	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp3_sram */
-	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp2_sram */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp1_sram */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp0_sram */
-	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts3_sram */
-	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts2_sram */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts1_sram */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts0_sram */
-	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std3_sram */
-	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std2_sram */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std1_sram */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std0_sram */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.wt_sram */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sc_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq3.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -11677,69 +12114,45 @@ union cvmx_pko_pse_sq3_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq3_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.nt_sram */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.pt_sram */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.rt_sram */
-	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq3.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_3.sq_fifo_sram */
-	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_2.sq_fifo_sram */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_1.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tw_0.sq_fifo_sram */
-	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp3_sram */
-	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp2_sram */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp1_sram */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tp0_sram */
-	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts3_sram */
-	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts2_sram */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts1_sram */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sts0_sram */
-	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std3_sram */
-	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std2_sram */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std1_sram */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.std0_sram */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.wt_sram */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sc_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq3.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -11831,7 +12244,7 @@ union cvmx_pko_pse_sq4_bist_status {
 	uint64_t tp1_sram                     : 1;  /**< SQ[5:1] topology parent configuration */
 	uint64_t tp0_sram                     : 1;  /**< SQ[5:1] topology parent configuration */
 	uint64_t reserved_18_18               : 1;
-	uint64_t rt_sram                      : 1;  /**< Result Table */
+	uint64_t rt_sram                      : 1;  /**< Result table */
 	uint64_t reserved_15_16               : 2;
 	uint64_t tw3_cmd_fifo                 : 1;  /**< SQ[5:3] time wheel 3 command FIFO SRAM */
 	uint64_t reserved_12_13               : 2;
@@ -11981,69 +12394,45 @@ union cvmx_pko_pse_sq4_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq4_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.pt_sram */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.nt_sram */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.rt_sram */
-	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq5.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_3.sq_fifo_sram */
-	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_2.sq_fifo_sram */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_1.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_0.sq_fifo_sram */
-	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp3_sram */
-	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp2_sram */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp1_sram */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp0_sram */
-	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts3_sram */
-	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts2_sram */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts1_sram */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts0_sram */
-	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std3_sram */
-	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std2_sram */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std1_sram */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std0_sram */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.wt_sram */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sc_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq4.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -12124,69 +12513,45 @@ union cvmx_pko_pse_sq4_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq4_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.nt_sram */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.pt_sram */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.rt_sram */
-	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq5.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_3.sq_fifo_sram */
-	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_2.sq_fifo_sram */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_1.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tw_0.sq_fifo_sram */
-	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp3_sram */
-	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp2_sram */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp1_sram */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq5.tp0_sram */
-	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts3_sram */
-	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts2_sram */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts1_sram */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sts0_sram */
-	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std3_sram */
-	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std2_sram */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std1_sram */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.std0_sram */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.wt_sram */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sc_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq4.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq4.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -12428,69 +12793,45 @@ union cvmx_pko_pse_sq5_ecc_dbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq5_ecc_dbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_dbe                : 1;  /**< Double-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.pt_sram */
-	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_dbe                : 1;  /**< Double-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.nt_sram */
-	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.rt_sram */
-	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_dbe                   : 1;  /**< Double-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq4.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW3_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_3.sq_fifo_sram */
-	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw2_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW2_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_2.sq_fifo_sram */
-	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw1_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_1.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_dbe         : 1;  /**< Double-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_0.sq_fifo_sram */
-	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp3_sram_dbe                 : 1;  /**< Double-bit error for TP3_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp3_sram */
-	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp2_sram_dbe                 : 1;  /**< Double-bit error for TP2_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp2_sram */
-	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_dbe                 : 1;  /**< Double-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp1_sram */
-	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_dbe                 : 1;  /**< Double-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp0_sram */
-	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts3_ram_dbe                 : 1;  /**< Double-bit error for STS3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts3_sram */
-	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts2_ram_dbe                 : 1;  /**< Double-bit error for STS2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts2_sram */
-	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_dbe                 : 1;  /**< Double-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts1_sram */
-	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_dbe                 : 1;  /**< Double-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts0_sram */
-	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std3_ram_dbe                 : 1;  /**< Double-bit error for STD3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std3_sram */
-	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std2_ram_dbe                 : 1;  /**< Double-bit error for STD2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std2_sram */
-	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_dbe                 : 1;  /**< Double-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std1_sram */
-	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_dbe                 : 1;  /**< Double-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std0_sram */
-	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.wt_sram */
-	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sc_sram */
+	uint64_t wt_ram_dbe                   : 1;  /**< Double-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq5.wt_sram */
+	uint64_t sc_ram_dbe                   : 1;  /**< Double-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -12571,69 +12912,45 @@ union cvmx_pko_pse_sq5_ecc_sbe_sts0 {
 	uint64_t u64;
 	struct cvmx_pko_pse_sq5_ecc_sbe_sts0_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_pt_ram_sbe                : 1;  /**< Single-bit error for SQ_PT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.pt_sram */
-	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sq_nt_ram_sbe                : 1;  /**< Single-bit error for SQ_NT_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.nt_sram */
-	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq4.rt_sram */
-	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t rt_ram_sbe                   : 1;  /**< Single-bit error for RT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq4.rt_sram */
+	uint64_t tw3_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW3_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_3.sq_fifo_sram */
-	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw2_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW2_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_2.sq_fifo_sram */
-	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw1_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW1_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_1.sq_fifo_sram */
-	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t tw0_cmd_fifo_ram_sbe         : 1;  /**< Single-bit error for TW0_CMD_FIFO_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.tw_0.sq_fifo_sram */
-	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp3_sram_sbe                 : 1;  /**< Single-bit error for TP3_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp3_sram */
-	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp2_sram_sbe                 : 1;  /**< Single-bit error for TP2_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp2_sram */
-	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp1_sram_sbe                 : 1;  /**< Single-bit error for TP1_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp1_sram */
-	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM.
-                                                         INTERNAL: Instances:
+	uint64_t tp0_sram_sbe                 : 1;  /**< Single-bit error for TP0_SRAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq4.tp0_sram */
-	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts3_ram_sbe                 : 1;  /**< Single-bit error for STS3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts3_sram */
-	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts2_ram_sbe                 : 1;  /**< Single-bit error for STS2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts2_sram */
-	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts1_ram_sbe                 : 1;  /**< Single-bit error for STS1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts1_sram */
-	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t sts0_ram_sbe                 : 1;  /**< Single-bit error for STS0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.sts0_sram */
-	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std3_ram_sbe                 : 1;  /**< Single-bit error for STD3_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std3_sram */
-	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std2_ram_sbe                 : 1;  /**< Single-bit error for STD2_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std2_sram */
-	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std1_ram_sbe                 : 1;  /**< Single-bit error for STD1_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std1_sram */
-	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM.
-                                                         INTERNAL: Instances:
+	uint64_t std0_ram_sbe                 : 1;  /**< Single-bit error for STD0_RAM. INTERNAL: Instances:
                                                          pko_pnr2.pko_pse.pse_sq5_sq3.sq3.std0_sram */
-	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.wt_sram */
-	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM.
-                                                         INTERNAL: Instances:
-                                                         pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sc_sram */
+	uint64_t wt_ram_sbe                   : 1;  /**< Single-bit error for WT_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq5.wt_sram */
+	uint64_t sc_ram_sbe                   : 1;  /**< Single-bit error for SC_RAM. INTERNAL: Instances: pko_pnr2.pko_pse.pse_sq5_sq3.sq5.sc_sram */
 	uint64_t reserved_0_42                : 43;
 #else
 	uint64_t reserved_0_42                : 43;
@@ -12715,13 +13032,13 @@ union cvmx_pko_ptfx_status {
 	struct cvmx_pko_ptfx_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
-	uint64_t total_in_flight_cnt          : 8;  /**< Total number of packets currently in-flight within PEB.  Useful
-                                                         both for reconfiguration (able to disable a FIFO when it is empty) and debugging. */
-	uint64_t in_flight_cnt                : 7;  /**< Number of packets currently in-flight within PEB for this link.
-                                                         Useful both for reconfiguration (able to disable a FIFO when it is empty) and debugging. */
-	uint64_t mac_num                      : 5;  /**< MAC assigned to the given PKO TX FIFO. A value of 0x1F means unassigned. These
-                                                         register values are derived automatically by the hardware from the
-                                                         PKO_MAC(0..27)_CFG[FIFO_NUM] settings. */
+	uint64_t total_in_flight_cnt          : 8;  /**< Total number of packets currently in-flight within PEB. Useful both for reconfiguration
+                                                         (able to disable a FIFO when it is empty) and debugging. */
+	uint64_t in_flight_cnt                : 7;  /**< Number of packets currently in-flight within PEB for this link. Useful both for
+                                                         reconfiguration (able to disable a FIFO when it is empty) and debugging. */
+	uint64_t mac_num                      : 5;  /**< MAC assigned to the given PKO TX FIFO. A value of 0x1F means unassigned. These register
+                                                         values are derived automatically by the hardware from the PKO_MAC(0..27)_CFG[FIFO_NUM]
+                                                         settings. */
 #else
 	uint64_t mac_num                      : 5;
 	uint64_t in_flight_cnt                : 7;
@@ -12768,33 +13085,31 @@ union cvmx_pko_ptgfx_cfg {
 	uint64_t reserved_7_63                : 57;
 	uint64_t reset                        : 1;  /**< This bit resets the address pointers for the FIFOs in this group. This should only be
                                                          performed when a PTGF is empty and the SIZE field is to be being changed. */
-	uint64_t rate                         : 3;  /**< Each PTGF can support up to 100Gbs. The total aggregate rate across all FIFOs (including
-                                                         the NULL) should never exceed 250Gbs.
-                                                         This field represents the rate for each active FIFO in PEB; thus the calculation for
-                                                         throughput is a function of the SIZE field and whether or not the FIFO is assigned to a
-                                                         MAC in PKO_MACx_CFG.
-                                                         RATE: Throughput
-                                                         ----------------
-                                                         - 000:    6.25Gbs
-                                                         - 001:   12.5 Gbs
-                                                         - 010:   25   Gbs
-                                                         - 011:   50   Gbs
-                                                         - 100:  100   Gbs
-                                                         Note: 101-111 are illegal RATE values and should not be used. */
+	uint64_t rate                         : 3;  /**< Each PTGF can support up to 100 Gb/s. The total aggregate rate across all FIFOs (including
+                                                         the NULL) should never exceed 250 Gb/s. This field represents the rate for each active
+                                                         FIFO
+                                                         in PEB; thus the calculation for throughput is a function of the SIZE field and whether or
+                                                         not the FIFO is assigned to a MAC in PKO_MAC(0..27)_CFG.
+                                                         0x0 = 6.25 Gb/s.
+                                                         0x1 = 12.5 Gb/s.
+                                                         0x2 = 25 Gb/s.
+                                                         0x3 = 50 Gb/s.
+                                                         0x4 = 100 Gb/s.
+                                                         else reserved. */
 	uint64_t size                         : 3;  /**< "PKO supports up to 29 independent TX FIFOs where 0-27 are physical and 28 is virtual. The
                                                          FIFOs are grouped into 8 sets of four contiguously numbered queues where each FIFO has a
                                                          base storage amount of 2.5K bytes of buffering.
-                                                         PKO_PTGF(0)_CFG -> FIFO#  0-3
-                                                         PKO_PTGF(1)_CFG -> FIFO#  4-7
-                                                         PKO_PTGF(2)_CFG -> FIFO#  8-11
-                                                         PKO_PTGF(3)_CFG -> FIFO#  12-15
-                                                         PKO_PTGF(4)_CFG -> FIFO#  16-19
-                                                         PKO_PTGF(5)_CFG -> FIFO#  20-23
-                                                         PKO_PTGF(6)_CFG -> FIFO#  24-27
-                                                         PKO_PTGF(7)_CFG -> FIFO#  28   (Virtual/NULL)
-                                                         Within each set, 2 or 4 FIFOs can be combined to produce a larger FIFO if desired.
-                                                         The SIZE field is used to configure the number and depth of the FIFOs in a set. The
-                                                         supported options for a FIFO set are as follows:
+                                                         PKO_PTGF(0)_CFG -> FIFO# 0-3
+                                                         PKO_PTGF(1)_CFG -> FIFO# 4-7
+                                                         PKO_PTGF(2)_CFG -> FIFO# 8-11
+                                                         PKO_PTGF(3)_CFG -> FIFO# 12-15
+                                                         PKO_PTGF(4)_CFG -> FIFO# 16-19
+                                                         PKO_PTGF(5)_CFG -> FIFO# 20-23
+                                                         PKO_PTGF(6)_CFG -> FIFO# 24-27
+                                                         PKO_PTGF(7)_CFG -> FIFO# 28 (Virtual/NULL)
+                                                         Within each set, 2 or 4 FIFOs can be combined to produce a larger FIFO if desired. The
+                                                         SIZE field is used to configure the number and depth of the FIFOs in a set. The supported
+                                                         options for a FIFO set are as follows:
                                                          SIZE: Set of 4 Contiguously Numbered FIFOs
                                                          ------------------------------------------
                                                          xxx      Queue0  Queue1  Queue2  Queue3
@@ -12811,10 +13126,10 @@ union cvmx_pko_ptgfx_cfg {
                                                          Kbytes of buffering was configured to FIFO#8.
                                                          FIFO_NUM = 28 is a virtual FIFO and is used exclusively to indicate the NULL FIFO. Packets
                                                          targeting the NULL FIFO are dropped by PKO and their buffers returned to the FPA. The SIZE
-                                                         field for PKO_PTGF(7) should always be set to zero.
-                                                         Modifications to this field require two writes. The first write must assert
-                                                         PKO_PTGFx_CFG[RESET] to reset the address pointers for the FIFOS in this group. The second
-                                                         write clears the RESET bit as well as configures the new SIZE values." */
+                                                         field for PKO_PTGF(7) should always be set to zero. Modifications to this field require
+                                                         two writes. The first write must assert PKO_PTGF(0..7)_CFG[RESET] to reset the address
+                                                         pointers for the FIFOS in this group. The second write clears the RESET bit as well as
+                                                         configures the new SIZE values." */
 #else
 	uint64_t size                         : 3;
 	uint64_t rate                         : 3;
diff --git a/arch/mips/include/asm/octeon/cvmx-pko-internal-ports-range.h b/arch/mips/include/asm/octeon/cvmx-pko-internal-ports-range.h
index 5001142..466f865 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko-internal-ports-range.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko-internal-ports-range.h
@@ -72,6 +72,8 @@ int cvmx_pko_internal_ports_free(int interface, int port);
  */
 void cvmx_pko_internal_ports_range_free_all(void);
 
+void cvmx_pko_internal_ports_range_show(void);
+
 extern int __cvmx_pko_internal_ports_range_init(void);
 
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-pko.h b/arch/mips/include/asm/octeon/cvmx-pko.h
index b61e9f0..5b61029 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko.h
@@ -66,7 +66,6 @@
  * - PKO 3 word commands are now supported. Use
  *   cvmx_pko_send_packet_finish3().
  *
- * <hr>$Revision: 82360 $<hr>
  */
 
 #ifndef __CVMX_PKO_H__
@@ -80,29 +79,31 @@
 #include <asm/octeon/cvmx-cmd-queue.h>
 #include <asm/octeon/cvmx-helper.h>
 #include <asm/octeon/cvmx-helper-cfg.h>
+#include <asm/octeon/cvmx-helper-pko.h>
 #else
-#ifndef CVMX_DONT_INCLUDE_CONFIG
-#endif
 #include "cvmx-fau.h"
 #include "cvmx-fpa.h"
 #include "cvmx-pow.h"
+#include "cvmx-pko3.h"	/* for back-comp */
 #include "cvmx-cmd-queue.h"
 #include "cvmx-helper.h"
 #include "cvmx-helper-util.h"
 #include "cvmx-helper-cfg.h"
+#include "cvmx-helper-pko.h"
 #endif
 
-/* Adjust the command buffer size by 1 word so that in the case of using only
-** two word PKO commands no command words stradle buffers.  The useful values
-** for this are 0 and 1. */
-#define CVMX_PKO_COMMAND_BUFFER_SIZE_ADJUST (1)
-
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 extern "C" {
 /* *INDENT-ON* */
 #endif
 
+/* Adjust the command buffer size by 1 word so that in the case of using only
+** two word PKO commands no command words stradle buffers.  The useful values
+** for this are 0 and 1. */
+#define CVMX_PKO_COMMAND_BUFFER_SIZE_ADJUST (1)
+
+
 #define CVMX_PKO_MAX_OUTPUT_QUEUES_STATIC 256
 #define CVMX_PKO_MAX_OUTPUT_QUEUES      ((OCTEON_IS_MODEL(OCTEON_CN31XX) || \
 					  OCTEON_IS_MODEL(OCTEON_CN3010) || \
@@ -150,7 +151,7 @@ typedef enum {
                                         mechanism */
 } cvmx_pko_lock_t;
 
-typedef struct {
+typedef struct cvmx_pko_port_status {
 	uint32_t packets;
 	uint64_t octets;
 	uint64_t doorbell;
@@ -235,62 +236,14 @@ typedef union {
 	} s;
 } cvmx_pko_command_word0_t;
 
-/* CSR typedefs have been moved to cvmx-pko-defs.h */
-
-/**
- * Definition of internal state for Packet output processing
- */
-typedef struct {
-	uint64_t *start_ptr;		/**< ptr to start of buffer, offset kept in FAU reg */
-} cvmx_pko_state_elem_t;
-
-extern CVMX_SHARED cvmx_fpa_pool_config_t pko_fpa_config;
-
-/**
- * Gets the fpa pool number of pko pool
- */
-static inline int64_t cvmx_fpa_get_pko_pool(void)
-{
-	return (pko_fpa_config.pool_num);
-}
-
-/**
- * Gets the buffer size of pko pool
- */
-static inline uint64_t cvmx_fpa_get_pko_pool_block_size(void)
-{
-	return (pko_fpa_config.buffer_size);
-}
-
-/**
- * Gets the buffer size  of pko pool
- */
-static inline uint64_t cvmx_fpa_get_pko_pool_buffer_count(void)
-{
-	return (pko_fpa_config.buffer_count);
-}
-
-/**
- * Sets the internal PKO pool data structure for command queue pool.
- * @param pool	fpa pool number yo use
- * @param buffer_size	buffer size of pool
- * @param buffer_count	number of buufers to allocate to pool
- */
-void cvmx_helper_set_pko_fpa_config(int64_t pool, uint64_t buffer_size,
-				    uint64_t buffer_count);
-
-/**
- * Gets up the pko FPA pool data from internal data structure
- * @param pko_pool pointer to the fpa data structure to copy data
- */
-void cvmx_pko_get_cmd_que_pool_config(cvmx_fpa_pool_config_t *pko_pool);
-
 /**
  * Call before any other calls to initialize the packet
  * output system.
  */
-extern void cvmx_pko_initialize_global(void);
-extern int cvmx_pko_initialize_local(void);
+// extern void cvmx_pko_initialize_global(void);
+// extern int cvmx_pko_initialize_local(void);
+
+extern void cvmx_pko_hw_init(uint8_t pool, unsigned bufsize);
 
 /**
  * Enables the packet output hardware. It must already be
@@ -320,7 +273,7 @@ extern void cvmx_pko_shutdown(void);
  *                   of a value of 1. There must be num_queues elements in the
  *                   array.
  */
-extern cvmx_pko_return_value_t cvmx_pko_config_port(uint64_t port, uint64_t base_queue, uint64_t num_queues, const uint64_t priority[]);
+extern cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue, int num_queues, const uint8_t priority[]);
 
 /**
  * Ring the packet output doorbell. This tells the packet
@@ -388,7 +341,7 @@ static inline void cvmx_pko_doorbell(uint64_t ipd_port, uint64_t queue, uint64_t
  * @param queue  Queue to use
  * @param use_locking
  *               CVMX_PKO_LOCK_NONE, CVMX_PKO_LOCK_ATOMIC_TAG, or CVMX_PKO_LOCK_CMD_QUEUE
- */ static inline void cvmx_pko_send_packet_prepare(uint64_t port, uint64_t queue, cvmx_pko_lock_t use_locking)
+ */ static inline void cvmx_pko_send_packet_prepare(uint64_t port __attribute__ ((unused)), uint64_t queue, cvmx_pko_lock_t use_locking)
 {
 	if (use_locking == CVMX_PKO_LOCK_ATOMIC_TAG) {
 		/* Must do a full switch here to handle all cases.  We use a fake WQE pointer, as the POW does
@@ -423,12 +376,14 @@ static inline void cvmx_pko_doorbell(uint64_t ipd_port, uint64_t queue, uint64_t
  *
  * @return returns CVMX_PKO_SUCCESS on success, or error code on failure of output
  */
-static inline cvmx_pko_return_value_t cvmx_pko_send_packet_finish(uint64_t ipd_port, uint64_t queue,
-							    cvmx_pko_command_word0_t pko_command, cvmx_buf_ptr_t packet, cvmx_pko_lock_t use_locking)
+static inline cvmx_pko_return_value_t cvmx_hwpko_send_packet_finish(uint64_t ipd_port, uint64_t queue,
+								    cvmx_pko_command_word0_t pko_command, cvmx_buf_ptr_t packet, cvmx_pko_lock_t use_locking)
 {
 	cvmx_cmd_queue_result_t result;
+
 	if (use_locking == CVMX_PKO_LOCK_ATOMIC_TAG)
 		cvmx_pow_tag_sw_wait();
+
 	result = cvmx_cmd_queue_write2(CVMX_CMD_QUEUE_PKO(queue), (use_locking == CVMX_PKO_LOCK_CMD_QUEUE), pko_command.u64, packet.u64);
 	if (cvmx_likely(result == CVMX_CMD_QUEUE_SUCCESS)) {
 		cvmx_pko_doorbell(ipd_port, queue, 2);
@@ -461,12 +416,13 @@ static inline cvmx_pko_return_value_t cvmx_pko_send_packet_finish(uint64_t ipd_p
  *
  * @return returns CVMX_PKO_SUCCESS on success, or error code on failure of output
  */
-static inline cvmx_pko_return_value_t cvmx_pko_send_packet_finish3(uint64_t ipd_port, uint64_t queue,
+static inline cvmx_pko_return_value_t cvmx_hwpko_send_packet_finish3(uint64_t ipd_port, uint64_t queue,
 							     cvmx_pko_command_word0_t pko_command, cvmx_buf_ptr_t packet, uint64_t addr, cvmx_pko_lock_t use_locking)
 {
 	cvmx_cmd_queue_result_t result;
 	if (use_locking == CVMX_PKO_LOCK_ATOMIC_TAG)
 		cvmx_pow_tag_sw_wait();
+
 	result = cvmx_cmd_queue_write3(CVMX_CMD_QUEUE_PKO(queue), (use_locking == CVMX_PKO_LOCK_CMD_QUEUE), pko_command.u64, packet.u64, addr);
 	if (cvmx_likely(result == CVMX_CMD_QUEUE_SUCCESS)) {
 		cvmx_pko_doorbell(ipd_port, queue, 3);
@@ -519,6 +475,9 @@ extern int cvmx_pko_get_num_queues(int port);
  */
 void cvmx_pko_set_cmd_que_pool_config(int64_t pool, uint64_t buffer_size,
 					   uint64_t buffer_count);
+//FIXME- reconsider:
+// Helper should setup the pool, then call PKO (pko_init?) with the
+// pool number to use.
 
 /**
  * Get the status counters for a port.
@@ -535,77 +494,7 @@ void cvmx_pko_set_cmd_que_pool_config(int64_t pool, uint64_t buffer_size,
  *       order. It is not MP-safe and caller should guarantee
  *       atomicity.
  */
-static inline void cvmx_pko_get_port_status(uint64_t ipd_port, uint64_t clear, cvmx_pko_port_status_t * status)
-{
-	cvmx_pko_reg_read_idx_t pko_reg_read_idx;
-	cvmx_pko_mem_count0_t pko_mem_count0;
-	cvmx_pko_mem_count1_t pko_mem_count1;
-	int pko_port, port_base, port_limit;
-
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		int interface = cvmx_helper_get_interface_num(ipd_port);
-		int index = cvmx_helper_get_interface_index_num(ipd_port);
-		port_base = cvmx_helper_get_pko_port(interface, index);
-		if (port_base == -1)
-			cvmx_dprintf("Warning: Invalid port_base\n");
-		port_limit = port_base + cvmx_pko_get_num_pko_ports(interface, index);
-	} else {
-		port_base = ipd_port;
-		port_limit = port_base + 1;
-	}
-
-	/*
-	 * status->packets and status->octets
-	 */
-	status->packets = 0;
-	status->octets = 0;
-	pko_reg_read_idx.u64 = 0;
-
-	for (pko_port = port_base; pko_port < port_limit; pko_port++) {
-
-		/*
-		 * In theory, one doesn't need to write the index csr every
-		 * time as he can set pko_reg_read_idx.s.inc to increment
-		 * the index automatically. Need to find out exactly how XXX.
-		 */
-		pko_reg_read_idx.s.index = pko_port;
-		cvmx_write_csr(CVMX_PKO_REG_READ_IDX, pko_reg_read_idx.u64);
-
-		pko_mem_count0.u64 = cvmx_read_csr(CVMX_PKO_MEM_COUNT0);
-		status->packets += pko_mem_count0.s.count;
-		if (clear) {
-			pko_mem_count0.s.count = pko_port;
-			cvmx_write_csr(CVMX_PKO_MEM_COUNT0, pko_mem_count0.u64);
-		}
-
-		pko_mem_count1.u64 = cvmx_read_csr(CVMX_PKO_MEM_COUNT1);
-		status->octets += pko_mem_count1.s.count;
-		if (clear) {
-			pko_mem_count1.s.count = pko_port;
-			cvmx_write_csr(CVMX_PKO_MEM_COUNT1, pko_mem_count1.u64);
-		}
-	}
-
-	/*
-	 * status->doorbell
-	 */
-	if (OCTEON_IS_MODEL(OCTEON_CN3XXX)) {
-		cvmx_pko_mem_debug9_t debug9;
-		pko_reg_read_idx.s.index = cvmx_pko_get_base_queue(ipd_port);
-		cvmx_write_csr(CVMX_PKO_REG_READ_IDX, pko_reg_read_idx.u64);
-		debug9.u64 = cvmx_read_csr(CVMX_PKO_MEM_DEBUG9);
-		status->doorbell = debug9.cn38xx.doorbell;
-	} else {
-		cvmx_pko_mem_debug8_t debug8;
-		pko_reg_read_idx.s.index = cvmx_pko_get_base_queue(ipd_port);
-		cvmx_write_csr(CVMX_PKO_REG_READ_IDX, pko_reg_read_idx.u64);
-		debug8.u64 = cvmx_read_csr(CVMX_PKO_MEM_DEBUG8);
-		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
-			status->doorbell = debug8.cn68xx.doorbell;
-		else
-			status->doorbell = debug8.cn58xx.doorbell;
-	}
-}
+void cvmx_pko_get_port_status(uint64_t ipd_port, uint64_t clear, cvmx_pko_port_status_t * status);
 
 /**
  * Rate limit a PKO port to a max packets/sec. This function is only
@@ -705,12 +594,13 @@ static inline void cvmx_pko_doorbell_pkoid(uint64_t pko_port, uint64_t queue, ui
  *
  * @return returns CVMX_PKO_SUCCESS on success, or error code on failure of output
  */
-static inline cvmx_pko_return_value_t cvmx_pko_send_packet_finish_pkoid(int pko_port, uint64_t queue,
+static inline cvmx_pko_return_value_t cvmx_hwpko_send_packet_finish_pkoid(int pko_port, uint64_t queue,
 								  cvmx_pko_command_word0_t pko_command, cvmx_buf_ptr_t packet, cvmx_pko_lock_t use_locking)
 {
 	cvmx_cmd_queue_result_t result;
 	if (use_locking == CVMX_PKO_LOCK_ATOMIC_TAG)
 		cvmx_pow_tag_sw_wait();
+
 	result = cvmx_cmd_queue_write2(CVMX_CMD_QUEUE_PKO(queue), (use_locking == CVMX_PKO_LOCK_CMD_QUEUE), pko_command.u64, packet.u64);
 	if (cvmx_likely(result == CVMX_CMD_QUEUE_SUCCESS)) {
 		cvmx_pko_doorbell_pkoid(pko_port, queue, 2);
@@ -738,12 +628,13 @@ static inline cvmx_pko_return_value_t cvmx_pko_send_packet_finish_pkoid(int pko_
  *
  * @return returns CVMX_PKO_SUCCESS on success, or error code on failure of output
  */
-static inline cvmx_pko_return_value_t cvmx_pko_send_packet_finish3_pkoid(uint64_t pko_port, uint64_t queue,
+static inline cvmx_pko_return_value_t cvmx_hwpko_send_packet_finish3_pkoid(uint64_t pko_port, uint64_t queue,
 								   cvmx_pko_command_word0_t pko_command, cvmx_buf_ptr_t packet, uint64_t addr, cvmx_pko_lock_t use_locking)
 {
 	cvmx_cmd_queue_result_t result;
 	if (use_locking == CVMX_PKO_LOCK_ATOMIC_TAG)
 		cvmx_pow_tag_sw_wait();
+
 	result = cvmx_cmd_queue_write3(CVMX_CMD_QUEUE_PKO(queue), (use_locking == CVMX_PKO_LOCK_CMD_QUEUE), pko_command.u64, packet.u64, addr);
 	if (cvmx_likely(result == CVMX_CMD_QUEUE_SUCCESS)) {
 		cvmx_pko_doorbell_pkoid(pko_port, queue, 3);
@@ -755,6 +646,15 @@ static inline cvmx_pko_return_value_t cvmx_pko_send_packet_finish3_pkoid(uint64_
 	}
 }
 
+/*
+ * Obtain the number of PKO commands pending in a queue
+ *
+ * @param queue is the queue identifier to be queried
+ * @return the number of commands pending transmission or -1 on error
+ */
+int cvmx_pko_queue_pend_count( cvmx_cmd_queue_id_t queue);
+
+void cvmx_pko_set_cmd_queue_pool_buffer_count(uint64_t buffer_count);
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3-queue.h b/arch/mips/include/asm/octeon/cvmx-pko3-queue.h
new file mode 100644
index 0000000..8e8d3fa
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-pko3-queue.h
@@ -0,0 +1,262 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * <hr>$Revision: 0 $<hr>
+ */
+
+#ifndef __CVMX_PKO3_QUEUE_H__
+#define __CVMX_PKO3_QUEUE_H__
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+extern "C" {
+/* *INDENT-ON* */
+#endif
+
+/* Maximum range for normalized (a.k.a. IPD) port numbers (12-bit field) */
+#define	CVMX_PKO3_IPD_NUM_MAX	0x1000	//FIXME- take it from someplace else ?
+
+/* Maximum number of DQs per CHAN_E (IPD port) is 64, although 8 is typical */
+#define	CVMX_PKO2_IPD_MAX_DQ	(1<<6)
+
+struct cvmx_pko3_dq_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	unsigned	
+			dq_count :6,	/* Number of descriptor queues */
+			dq_base :10;	/* Descriptor queue start number */
+#define	CVMX_PKO3_SWIZZLE_IPD	0x0
+#else
+	unsigned	
+			dq_base :10,	/* Descriptor queue start number */
+			dq_count :6;	/* Number of descriptor queues */
+
+#define	CVMX_PKO3_SWIZZLE_IPD	0x3
+#endif
+};
+
+extern struct cvmx_pko3_dq_s *__cvmx_pko3_dq_table;
+
+/**
+ * @INTERNAL
+ *
+ * Find or allocate global port/dq map table
+ * which is a named table, contains entries for
+ * all possible OCI nodes.
+ *
+ * The table global pointer is stored in core-local variable
+ * so that every core will call this function once, on first use.
+ */
+extern int __cvmx_pko3_dq_table_setup(void);
+
+/*
+ * Get the base Descriptor Queue number for an IPD port on the local node
+ */
+static inline int cvmx_pko3_get_queue_base(uint16_t ipd_port)
+{
+	struct cvmx_pko3_dq_s *dq_table;
+	int ret = -1;
+	unsigned i;
+	unsigned node;
+
+	/* get per-node table */
+	if(__cvmx_pko3_dq_table == NULL)
+		__cvmx_pko3_dq_table_setup();
+
+	/* extract node # from portID */
+	node = ipd_port >> 14;
+
+	i = CVMX_PKO3_SWIZZLE_IPD ^ (ipd_port & (CVMX_PKO3_IPD_NUM_MAX-1));
+
+	/* get per-node table */
+	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * node;
+
+	if(dq_table[i].dq_count > 0)
+		ret = dq_table[i].dq_base | (node << 14);
+
+	return ret;
+}
+
+/*
+ * Get the number of Descriptor Queues assigned for an IPD port
+ */
+static inline int cvmx_pko3_get_queue_num(uint16_t ipd_port)
+{
+	struct cvmx_pko3_dq_s *dq_table;
+	int ret = -1;
+	unsigned i;
+	unsigned node;
+
+	/* get per-node table */
+	if(__cvmx_pko3_dq_table == NULL)
+		__cvmx_pko3_dq_table_setup();
+
+	/* extract node # from portID */
+	node = ipd_port >> 14;
+
+	i = CVMX_PKO3_SWIZZLE_IPD ^ (ipd_port & (CVMX_PKO3_IPD_NUM_MAX-1));
+
+	/* get per-node table */
+	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * node;
+
+	if(dq_table[i].dq_count > 0)
+		ret = dq_table[i].dq_count;
+
+	return ret;
+}
+
+/*
+ * Configure Port Queue and its children Scheduler Queue
+ *
+ * Port Queues (a.k.a L1) are assigned 1-to-1 to MACs.
+ * L2 Scheduler Queues are used for specifying channels, and thus there
+ * could be multiple L2 SQs attached to a single L1 PQ, either in a
+ * fair round-robin scheduling, or with static and/or round-robin priorities.
+ *
+ * @param mac_num is the LMAC number to that is associated with the Port Queue,
+ * @param which is identical to the Port Queue number that is configured
+ * @param child_base is the number of the first L2 SQ attached to the PQ
+ * @param child_count is the number of L2 SQ children to attach to PQ
+ * @param stat_prio_count is the priority setting for the children L2 SQs
+ *
+ * If <stat_prio_count> is -1, the L2 children will have equal Round-Robin
+ * relationship with eachother. If <stat_prio_count> is 0, all L2 children
+ * will be arranged in Weighted-Round-Robin, with the first having the most
+ * precedence. If <stat_prio_count> is between 1 and 8, it indicates how
+ * many children will have static priority settings (with the first having
+ * the most precedence), with the remaining L2 children having WRR scheduling.
+ *
+ * @returns 0 on success, -1 on failure.
+ *
+ * Note: this function supports the configuration of node-local unit.
+ */
+int cvmx_pko3_pq_config_children(unsigned mac_num, unsigned child_base,
+			unsigned child_count, int stat_prio_count);
+
+/*
+ * Configure L3 through L5 Scheduler Queues and Descriptor Queues
+ *
+ * The Scheduler Queues in Levels 3 to 5 and Descriptor Queues are
+ * configured one-to-one or many-to-one to a single parent Scheduler
+ * Queues. The level of the parent SQ is specified in an argument,
+ * as well as the number of childer to attach to the specific parent.
+ * The children can have fair round-robin or priority-based scheduling
+ * when multiple children are assigned a single parent.
+ *
+ * @param parent_level is the level of the parent queue, 2 to 5.
+ * @param parent_queue is the number of the parent Scheduler Queue
+ * @param child_base is the number of the first child SQ or DQ to assign to
+ * @param parent
+ * @param child_count is the number of consecutive children to assign
+ * @param stat_prio_count is the priority setting for the children L2 SQs
+ *
+ * If <stat_prio_count> is -1, the Ln children will have equal Round-Robin
+ * relationship with eachother. If <stat_prio_count> is 0, all Ln children
+ * will be arranged in Weighted-Round-Robin, with the first having the most
+ * precedence. If <stat_prio_count> is between 1 and 8, it indicates how
+ * many children will have static priority settings (with the first having
+ * the most precedence), with the remaining Ln children having WRR scheduling.
+ *
+ * @returns 0 on success, -1 on failure.
+ *
+ * Note: this function supports the configuration of node-local unit.
+ */
+int cvmx_pko3_sq_config_children(unsigned parent_level,
+			unsigned parent_queue, unsigned child_base,
+			unsigned child_count, int stat_prio_count);
+
+/*
+ * @INTERNAL
+ * Register a range of Descriptor Queues wth an interface port
+ *
+ * This function poulates the DQ-to-IPD translation table
+ * used by the application to retreive the DQ range (typically ordered
+ * by priority) for a given IPD-port, which is either a physical port,
+ * or a channel on a channelized interface (i.e. ILK).
+ *
+ * @param interface is the physical interface number
+ * @param port is either a physical port on an interface
+ * @param or a channel of an ILK interface
+ * @param dq_base is the first Descriptor Queue number in a consecutive range
+ * @param dq_count is the number of consecutive Descriptor Queues leading
+ * @param the same channel or port.
+ *
+ * Only a consecurive range of Descriptor Queues can be associated with any
+ * given channel/port, and usually they are ordered from most to least
+ * in terms of scheduling priority.
+ *
+ * Note: thus function only populates the node-local translation table.
+ *
+ * @returns 0 on success, -1 on failure.
+ */
+int __cvmx_pko3_ipd_dq_register(unsigned interface, unsigned port,
+		unsigned dq_base, unsigned dq_count);
+
+
+/**
+ * @INTERNAL
+ *
+ * Unregister DQs associated with CHAN_E (IPD port)
+ */
+int __cvmx_pko3_ipd_dq_unregister(unsigned interface, unsigned port);
+
+/*
+ * Map channel number in PKO 
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param pq_num specifies the Port Queue (i.e. L1) queue number.
+ * @param l2_l3_q_num  specifies L2/L3 queue number.
+ * @param channel specifies the channel number to map to the queue.
+ *
+ * The channel assignment applies to L2 or L3 Shaper Queues depending
+ * on the setting of channel credit level.
+ *
+ * @return returns none.
+ */
+void cvmx_pko3_map_channel(unsigned node,
+	unsigned pq_num, unsigned l2_l3_q_num, uint16_t channel);
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
+#endif
+#endif /* __CVMX_PKO3_QUEUE_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3-resources.h b/arch/mips/include/asm/octeon/cvmx-pko3-resources.h
new file mode 100644
index 0000000..c5bad29
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-pko3-resources.h
@@ -0,0 +1,82 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * <hr>$Revision: 0 $<hr>
+ */
+
+#ifndef __CVMX_PKO3_RESOURCES_H__
+#define __CVMX_PKO3_RESOURCES_H__
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+extern "C" {
+/* *INDENT-ON* */
+#endif
+
+/*
+ * Allocate or reserve contiguous list of PKO queues.
+ *
+ * @param node is the node number for PKO queues.
+ * @param level is the PKO queue level.
+ * @param owner is the owner of PKO queue resources.
+ * @param base_queue is the PKO queue base number(specify -1 to allocate).
+ * @param num_queues is the number of PKO queues that have to be reserved or allocated.
+ * @return returns queue_base if successful or -1 on failure.
+ */
+extern int cvmx_pko_alloc_queues(int node, int level, int owner, int base_queue, int num_queues);
+
+/**
+ * Free an allocated/reserved PKO queues for a certain level and owner
+ *
+ * @param node on which to allocate/reserve PKO queues
+ * @param level of PKO queue
+ * @param owner of reserved/allocated resources
+ * @return 0 on success, -1 on failure
+ */
+extern int cvmx_pko_free_queues(int node, int level, int owner);
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
+#endif
+#endif /* __CVMX_PKO3_RESOURCES_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3.h b/arch/mips/include/asm/octeon/cvmx-pko3.h
new file mode 100644
index 0000000..85172fd
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-pko3.h
@@ -0,0 +1,551 @@
+/***********************license start***************
+ * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * <hr>$Revision: 0 $<hr>
+ */
+
+#ifndef __CVMX_PKO3_H__
+#define __CVMX_PKO3_H__
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+extern "C" {
+/* *INDENT-ON* */
+#endif
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/cvmx-pko-defs.h>
+#include <asm/octeon/cvmx-helper.h>
+#include <asm/octeon/cvmx-pko3-queue.h>
+#include <asm/octeon/cvmx-ilk.h>
+#else
+#include "cvmx-pko-defs.h"
+#include "cvmx-pko3-queue.h"
+#include "cvmx-helper.h"
+#include "cvmx-ilk.h"
+#endif
+
+/* dwords are from 1-16 */
+/* scratch line for LMT operations */
+#define CVMX_PKO_LMTLINE 2ull	//FIXME- should go somewhere else ?
+
+enum {
+	CVMX_PKO_PORT_QUEUES = 0,
+	CVMX_PKO_L2_QUEUES,
+	CVMX_PKO_L3_QUEUES,
+	CVMX_PKO_L4_QUEUES,
+	CVMX_PKO_L5_QUEUES,
+	CVMX_PKO_DESCR_QUEUES,
+	CVMX_PKO_NUM_QUEUE_LEVELS
+};
+
+#define CVMX_PKO_MAX_MACS 28
+
+enum cvmx_pko_dqop {
+	CVMX_PKO_DQ_SEND = 0ULL,
+	CVMX_PKO_DQ_OPEN = 1ULL,
+	CVMX_PKO_DQ_CLOSE = 2ULL,
+	CVMX_PKO_DQ_QUERY = 3ULL
+};
+
+union cvmx_pko_query_rtn_s {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t dqstatus	: 4,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_50_59	:10,
+		CVMX_BITFIELD_FIELD(uint64_t dqop	: 2,
+		CVMX_BITFIELD_FIELD(uint64_t depth	:48,
+			))));
+	} s;
+};
+typedef union cvmx_pko_query_rtn_s cvmx_pko_query_rtn_s_t;
+
+/* PKO_QUERY_RTN_S[DQSTATUS] - cvmx_pko_query_rtn_s_t->s.dqstatus */
+enum pko_query_dqstatus {
+	PKO_DQSTATUS_PASS = 0,		/* No error */
+	PKO_DQSTATUS_BADSTATE = 0x8,	/* queue was not ready to enqueue */
+	PKO_DQSTATUS_NOFPABUF = 0x9,	/* FPA out of buffers */
+	PKO_DQSTATUS_NOPKOBUF = 0xA,	/* PKO out of buffers */
+	PKO_DQSTATUS_FAILRTNPTR = 0xB,	/* can't return buffer ptr to FPA */
+	PKO_DQSTATUS_ALREADY = 0xC,	/* already created */
+	PKO_DQSTATUS_NOTCREATED = 0xD,	/* not created */
+	PKO_DQSTATUS_NOTEMPTY = 0xE,	/* queue not empty */
+	PKO_DQSTATUS_SENDPKTDROP = 0xF	/* packet dropped, illegal construct */
+};
+typedef	enum pko_query_dqstatus pko_query_dqstatus_t;
+
+/* Sub-command three bit codes (SUBDC3) */
+#define CVMX_PKO_SENDSUBDC_LINK		0x0
+#define CVMX_PKO_SENDSUBDC_GATHER	0x1
+#define CVMX_PKO_SENDSUBDC_JUMP		0x2
+/* Sub-command four bit codes (SUBDC4) */
+#define CVMX_PKO_SENDSUBDC_FREE		0x9
+#define CVMX_PKO_SENDSUBDC_WORK		0xA
+#define CVMX_PKO_SENDSUBDC_AURA		0xB
+#define CVMX_PKO_SENDSUBDC_MEM		0xC
+#define CVMX_PKO_SENDSUBDC_EXT		0xD
+#define CVMX_PKO_SENDSUBDC_CRC		0xE
+#define CVMX_PKO_SENDSUBDC_IMM		0xF
+
+/**
+ * pko buf ptr
+ * This is good for LINK_S, GATHER_S and PKI_BUFLINK_S structure use.
+ * It can also be used for JUMP_S with F-bit represented by "i" field,
+ * and the size limited to 8-bit.
+*/
+
+union cvmx_pko_buf_ptr {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t size	:16,
+		CVMX_BITFIELD_FIELD(uint64_t subdc3	: 3,
+		CVMX_BITFIELD_FIELD(uint64_t i		: 1,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_42_43	: 2,
+		CVMX_BITFIELD_FIELD(uint64_t addr	:42,
+			)))));
+	} s;
+};
+typedef union cvmx_pko_buf_ptr cvmx_pko_buf_ptr_t;
+
+/**
+ * pko_auraalg_e
+ */
+enum pko_auraalg_e {
+	AURAALG_NOP = 0x0,	/* aura_cnt = No change */
+	AURAALG_SUB = 0x3,	/* aura_cnt -= pko_send_aura_t.offset */
+	AURAALG_SUBLEN = 0x7,	/* aura_cnt -= pko_send_aura_t.offset +
+						pko_send_hdr_t.total_bytes */
+	AURAALG_SUBMBUF = 0xB	/* aura_cnt -= pko_send_aura_t.offset +
+						mbufs_freed */
+};
+
+/**
+ * pko_send_aura
+ */
+union cvmx_pko_send_aura {
+	uint64_t u64;
+	struct {
+                CVMX_BITFIELD_FIELD(uint64_t rsvd_60_63 : 4,
+                CVMX_BITFIELD_FIELD(uint64_t aura 	: 12, /* NODE+LAURA */
+                CVMX_BITFIELD_FIELD(uint64_t subdc4 	: 4,
+                CVMX_BITFIELD_FIELD(uint64_t alg 	: 4, /* pko_auraalg_e */
+                CVMX_BITFIELD_FIELD(uint64_t rsvd_08_39 : 32,
+                CVMX_BITFIELD_FIELD(uint64_t offset 	: 8,
+			))))));
+	} s;
+};
+typedef union cvmx_pko_send_aura cvmx_pko_send_aura_t;
+
+/* pko command descriptor */
+union cvmx_pko_send_hdr {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_60_63	:4,
+		CVMX_BITFIELD_FIELD(uint64_t aura	:12,
+		CVMX_BITFIELD_FIELD(uint64_t ckl4	:2,
+		CVMX_BITFIELD_FIELD(uint64_t ckl3	:1,
+		CVMX_BITFIELD_FIELD(uint64_t ds		:1,
+		CVMX_BITFIELD_FIELD(uint64_t le		:1,
+		CVMX_BITFIELD_FIELD(uint64_t n2		:1,
+		CVMX_BITFIELD_FIELD(uint64_t ii		:1,
+		CVMX_BITFIELD_FIELD(uint64_t df		:1,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_39	:1,
+		CVMX_BITFIELD_FIELD(uint64_t format	:7,
+		CVMX_BITFIELD_FIELD(uint64_t l4ptr	:8,
+		CVMX_BITFIELD_FIELD(uint64_t l3ptr	:8,
+		CVMX_BITFIELD_FIELD(uint64_t total	:16,
+			))))))))))))));
+	} s;
+};
+typedef union cvmx_pko_send_hdr cvmx_pko_send_hdr_t;
+
+/* PKO_MEMDSZ_E */
+enum cvmx_pko_memdsz_e {
+	MEMDSZ_B64 = 0,
+	MEMDSZ_B32 = 1,
+	MEMDSZ_B16 = 2,		/* Not in HRM, assumed unsupported */
+	MEMDSZ_B8 = 3
+};
+
+/* PKO_MEMALG_E */
+enum cvmx_pko_memalg_e {
+	MEMALG_SET = 0,		/* Set mem = PKO_SEND_MEM_S[OFFSET] */
+	MEMALG_SETTSTMP = 1,	/* Set the memory location to the timestamp
+				   PKO_SEND_MEM_S[DSZ] must be B64 and a
+				   PKO_SEND_EXT_S subdescriptor must be in
+				   the descriptor with PKO_SEND_EXT_S[TSTMP]=1
+				 */
+	MEMALG_SETRSLT = 2,	/* [DSZ] = B64; mem = PKO_MEM_RESULT_S.  */
+	MEMALG_ADD = 8,		/* mem = mem + PKO_SEND_MEM_S[OFFSET] */
+	MEMALG_SUB = 9,		/* mem = mem  PKO_SEND_MEM_S[OFFSET] */
+	MEMALG_ADDLEN = 0xA,	/* mem += [OFFSET] + PKO_SEND_HDR_S[TOTAL] */
+	MEMALG_SUBLEN = 0xB,	/* mem -= [OFFSET] + PKO_SEND_HDR_S[TOTAL] */
+	MEMALG_ADDMBUF = 0xC,	/* mem += [OFFSET] + mbufs_freed */
+	MEMALG_SUBMBUF = 0xD	/* mem -= [OFFSET] + mbufs_freed */
+};
+
+union cvmx_pko_send_mem {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_63	:1,
+		CVMX_BITFIELD_FIELD(uint64_t wmem	:1,
+		CVMX_BITFIELD_FIELD(uint64_t dsz	:2, /* PKO_MEMDSZ_E */
+		CVMX_BITFIELD_FIELD(uint64_t alg	:4, /* PKO_MEMALG_E */
+		CVMX_BITFIELD_FIELD(uint64_t offset	:8,
+		CVMX_BITFIELD_FIELD(uint64_t subdc4	:4,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_42_43	:2,
+		CVMX_BITFIELD_FIELD(uint64_t addr	:42,
+		))))))));
+	} s;
+};
+
+typedef union cvmx_pko_send_mem cvmx_pko_send_mem_t;
+
+union cvmx_pko_send_work {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_62_63	:2,
+		CVMX_BITFIELD_FIELD(uint64_t grp	:10,
+		CVMX_BITFIELD_FIELD(uint64_t tt		:2,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_48_49	:2,
+		CVMX_BITFIELD_FIELD(uint64_t subdc4	:4,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_42_43	:2,
+		CVMX_BITFIELD_FIELD(uint64_t addr	:42,
+			)))))));
+	} s;
+};
+
+typedef union cvmx_pko_send_work cvmx_pko_send_work_t;
+
+/*** PKO_SEND_DMA_S - format of IOBDMA/LTDMA data word ***/
+union cvmx_pko_lmtdma_data {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t scraddr	: 8,
+		CVMX_BITFIELD_FIELD(uint64_t rtnlen	: 8,
+		CVMX_BITFIELD_FIELD(uint64_t did	: 8, /* 0x51 */
+		CVMX_BITFIELD_FIELD(uint64_t node	: 4,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_34_35	: 2,
+		CVMX_BITFIELD_FIELD(uint64_t dqop	: 2, /* PKO_DQOP_E */
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_26_31	: 6,
+		CVMX_BITFIELD_FIELD(uint64_t dq		: 10,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_0_15	: 16,
+			)))))))));
+	} s;
+};
+typedef union cvmx_pko_lmtdma_data cvmx_pko_lmtdma_data_t;
+
+/*
+ * PKO descriptor queue operation error string
+ *
+ * @param dqstatus is the enumeration returned from hardware, 
+ * 	  PKO_QUERY_RTN_S[DQSTATUS].
+ *
+ * @return static constant string error description
+ */
+const char * pko_dqstatus_error(pko_query_dqstatus_t dqstatus);
+
+static inline uint64_t build_mask(uint64_t bits)
+{
+    return ~((~0x0ull) << bits);
+}
+
+/*
+ * This function gets PKO mac num for a interface/port.
+ *
+ * @param interface is the interface number.
+ * @param port is the port number.
+ * @return returns mac number if successful or -1 on failure.
+ */
+static inline int __cvmx_pko_get_mac_num(int interface, int port)
+{
+	cvmx_helper_interface_mode_t mode;
+	int interface_index;
+
+	mode = cvmx_helper_interface_get_mode(interface);
+	switch (mode) {
+		case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+		case CVMX_HELPER_INTERFACE_MODE_XAUI:
+			return (4 + 4 * interface + port);
+		case CVMX_HELPER_INTERFACE_MODE_LOOP:
+			return 0;
+		case CVMX_HELPER_INTERFACE_MODE_NPI:
+			return 1;
+		case CVMX_HELPER_INTERFACE_MODE_ILK:
+			interface_index = (interface - CVMX_ILK_GBL_BASE());
+			return (2 + interface_index);
+		default:
+			return -1;
+	}
+}
+
+/*
+ * Configure Channel credit level in PKO.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param level specifies the level at which pko channel queues will be configured,
+ *              level : 0 -> L2, level : 1 -> L3 queues.
+ * @return returns 0 if successful and -1 on failure.
+ */
+static inline int cvmx_pko_setup_channel_credit_level(int node, int level)
+{
+	union cvmx_pko_channel_level channel_level;
+
+	if (level != 0 || level != 1)
+		return -1;
+
+	channel_level.u64 = 0;
+	channel_level.s.cc_level = level;
+	cvmx_write_csr_node(node, CVMX_PKO_CHANNEL_LEVEL, channel_level.u64);
+
+	return 0;
+
+}
+
+/*
+ * @INTERNAL  
+ * Sends PKO descriptor commands via CVMSEG LM and LMTDMA.
+ * @param node is the destination node
+ * @param dq is the destonation descriptor queue.
+ * @param cmds[] is an array of 64-bit PKO3 headers/subheaders
+ * @param numworkds is the number of outgoing words
+ * @param dqop is the operation code 
+ * @return the PKO3 native query result structure.
+ *
+ * <numwords> must be between 1 and 15 for CVMX_PKO_DQ_SEND command
+ * otherwise it must be 0.
+ *
+ * NOTE: Internal use only.
+ */
+static inline cvmx_pko_query_rtn_s_t 
+__cvmx_pko3_do_dma(uint8_t node, uint16_t dq, uint64_t cmds[],
+	unsigned numwords, enum cvmx_pko_dqop dqop)
+{
+	const unsigned scr_base = CVMX_PKO_LMTLINE * CVMX_CACHE_LINE_SIZE;
+	cvmx_pko_query_rtn_s_t pko_status;
+	cvmx_pko_lmtdma_data_t pko_send_dma_data;
+	uint64_t dma_addr;
+	unsigned i, scr_off;
+
+	/* With 0 data to send, this is an IOBDMA, else LMTDMA operation */
+	if(numwords == 0) {
+		dma_addr = 0xffffffffffffa200ull;
+	} else {
+		/* LMTDMA address offset is (nWords-1) */
+		dma_addr = 0xffffffffffffa400ull; 
+		dma_addr += (numwords - 1) << 3;
+	}
+
+	if (numwords > 15) {
+		cvmx_dprintf("%s: ERROR: Internal error\n",
+				__FUNCTION__);
+		pko_status.u64 = ~0ull;
+		return pko_status;
+	}
+
+	/* Store the command words into CVMSEG LM */
+	for(i = 0, scr_off = scr_base; i < numwords; i++) {
+		cvmx_scratch_write64(scr_off, cmds[i]);
+		scr_off += sizeof(cmds[0]);
+	}
+
+	/* Write all-ones into the return area */
+	cvmx_scratch_write64(scr_off, ~0ull);
+
+	/* build store data for DMA */
+	pko_send_dma_data.u64 = 0;
+	pko_send_dma_data.s.scraddr = scr_off >> 3;
+	pko_send_dma_data.s.rtnlen = 1;
+	pko_send_dma_data.s.did = 0x51;
+	pko_send_dma_data.s.node = node;
+	pko_send_dma_data.s.dqop = dqop;
+	pko_send_dma_data.s.dq = dq;
+
+	/* Push all data into CVMSEG LM */
+	CVMX_SYNCW;
+
+	/* issue PKO DMA */
+	cvmx_write64_uint64(dma_addr, pko_send_dma_data.u64);
+
+	/* Wait for completion */
+	CVMX_SYNCIOBDMA;
+
+	/* Retreive result */
+	pko_status.u64 = cvmx_scratch_read64(scr_off);
+
+	return pko_status;
+}
+
+/**
+ * @INTERNAL
+ *
+ * Retreive PKO internal AURA from register.
+ */
+static inline unsigned __cvmx_pko3_aura_get(unsigned node)
+{
+	static int16_t aura = -1;
+	cvmx_pko_dpfi_fpa_aura_t pko_aura;
+
+	if (aura >= 0)
+		return aura;
+
+	pko_aura.u64 = cvmx_read_csr_node(node, CVMX_PKO_DPFI_FPA_AURA);
+
+	aura =  pko_aura.s.node << 10 | pko_aura.s.laura;
+	return aura;
+}
+
+ /** Open configured descriptor queues before queueing packets into them.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param dq is the descriptor queue number to be opened.
+ * @return returns 0 on sucess or -1 on failure.
+ */
+int cvmx_pko_dq_open(int node, int dq);
+
+ /** Close a descriptor queue
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param dq is the descriptor queue number to be opened.
+ * @return returns 0 on sucess or -1 on failure.
+ *
+ * This should be called before changing the DQ parent link, topology,
+ * or when shutting down the PKO.
+ */
+int cvmx_pko3_dq_close(int node, int dq);
+
+ /** Query a descriptor queue
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param dq is the descriptor queue number to be opened.
+ * @return returns the descriptor queue depth on sucess or -1 on failure.
+ *
+ * This should be called before changing the DQ parent link, topology,
+ * or when shutting down the PKO.
+ */
+int cvmx_pko3_dq_query(int node, int dq);
+
+/** Drain a descriptor queue
+ *
+ * Before closing a DQ, this call will drain all pending traffic
+ * on the DQ to the NULL MAC, which will circumvent any traffic
+ * shaping and flow control to quickly reclaim all packet buffers.
+ */
+void cvmx_pko3_dq_drain(int node, int dq);
+
+/*
+ * PKO global intialization for 78XX.
+ *
+ * @param node is the node on which PKO block is initialized.
+ * @param aura is the 12-bit AURA (including node) for PKO internal use.
+ * @return none.
+ */
+int cvmx_pko3_hw_init_global(int node, uint16_t aura);
+
+/**
+ * Shutdown the entire PKO
+ */
+int cvmx_pko3_hw_disable(int node);
+
+/*
+ * Transmit packets through pko on specified node and queue.
+ *
+ * @param dq is the queue to write the commands to.
+ * @param bufptr specifies packet in linked or gather mode.
+ * @param packet_len is the total packet len of the packet in bufptr.
+ * @param aura_free is the aura to free packet buffers after trasnmit.
+ * @return returns 0 if successful and -1 on failure.
+ *
+ * NOTE: This is a provisional API, and is subject to change.
+ */
+int cvmx_pko_transmit_packet(int dq, cvmx_buf_ptr_pki_t bufptr,
+			     int packet_len, int aura_free);
+
+/* Define legacy type here to break circular dependency */
+typedef struct cvmx_pko_port_status cvmx_pko_port_status_t;
+
+/**
+ * @INTERNAL
+ * Backward compatibility for collecting statistics from PKO3
+ *
+ */
+extern void cvmx_pko3_get_legacy_port_stats(uint16_t ipd_port,
+	unsigned clear, cvmx_pko_port_status_t * status);
+
+/** Set MAC options
+ *
+ * The options supported are the parameters below:
+ *
+ * @param node The OCI node number of the interface
+ * @param interface The physical interface number
+ * @param port The physical sub-interface port
+ * @param fcs_enable Enable FCS generation
+ * @param pad_enable Enable padding to minimum packet size
+ * @param fcs_sop_off Number of bytes at start of packet to exclude from FCS
+ *
+ * The typical use for `fcs_sop_off` is when the interface is configured
+ * to use a header such as HighGig to precede every Ethernet packet,
+ * such a header usually does not partake in the CRC32 computation stream,
+ * and its size muet be set with this parameter.
+ *
+ * @return Returns 0 on success, -1 if interface/port is invalid.
+ */
+extern int cvmx_pko3_interface_options(int node, int interface, int port,
+			bool fcs_enable, bool pad_enable,
+			unsigned fcs_sop_off);
+
+/** Set Descriptor Queue options
+ *
+ * The `min_pad` parameter must be in agreement with the interface-level
+ * padding option for all descriptor queues assigned to that particular
+ * interface/port.
+ */
+extern void cvmx_pko3_dq_options(unsigned node, unsigned dq, bool min_pad);
+
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
+#endif
+#endif /* __CVMX_PKO3_H__ */
+
diff --git a/arch/mips/include/asm/octeon/cvmx-pow.h b/arch/mips/include/asm/octeon/cvmx-pow.h
index 4fcd6da..e0d6fe7 100644
--- a/arch/mips/include/asm/octeon/cvmx-pow.h
+++ b/arch/mips/include/asm/octeon/cvmx-pow.h
@@ -87,8 +87,36 @@ extern "C" {
 #define CVMX_ENABLE_POW_CHECKS 1
 #endif
 
-#define CVMX_SSO_NUM_GROUPS_78XX	(256)
-#define CVMX_SSO_NUM_GROUPS_SET		(CVMX_SSO_NUM_GROUPS_78XX/64)
+/*
+ * Special type for CN78XX style SSO groups (0..255),
+ * for distinction from legacy-style groups (0..15)
+ */
+typedef union {
+	uint8_t		xgrp;
+	/* Fields that map XGRP for backwards compatibility */
+	struct __attribute__ ((__packed__)) {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint8_t	group: 5,
+			qus: 3;
+#else
+		uint8_t	qus: 3,
+			group: 5;
+#endif
+	};
+} cvmx_xgrp_t;
+
+#define CVMX_SSO_NUM_XGRP		(256)
+
+/*
+ * Softwsare-only structure to convey a return value
+ * containing multiple information fields about an work queue entry
+ */
+typedef struct {
+	uint32_t tag;
+	uint16_t index;
+	uint8_t grp;	/* Legacy group # (0..15) */
+	uint8_t tag_type;
+} cvmx_pow_tag_info_t;
 
 /**
  * Wait flag values for pow functions.
@@ -255,42 +283,36 @@ typedef union {
 
 	struct {
 #ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t unused2:3;
+		uint64_t rsvd_62_63:2;
 		/** Group that the work-queue entry will be scheduled to. Grp
 		   is used for ADDWQ, SWTAG_FULL, SWTAG_DESCH, UPD_WQP_GRP. */
-		uint64_t grp:12;
+		uint64_t grp:10; /** NODE+LGROUP */
 		cvmx_pow_tag_type_t type:2; /** The type of the tag */
 		/** Don't reschedule this entry. NOSCHED is used for
 		   SWTAG_DESCH and DESCHED.*/
 		uint64_t no_sched:1;
+		uint64_t rsvd_48:1;
 		/** the operation to perform */
 		cvmx_pow_tag_op_t op:4;
-		uint64_t unused1:2;
+		uint64_t rsvd_42_43:2;
 		/** Address of the work-queue entry. Must be aligned on a 64-bit
 		    boundary. Used for SWTAG_FULL, ADDWQ, UPD_WQP_GRP;
 		    addr<2:0> must be zero. */
 		uint64_t wqp:42;
 #else
 		uint64_t wqp:42;
-		uint64_t unused1:2;
+		uint64_t rsvd_42_43:2;
 		cvmx_pow_tag_op_t op:4; /**< the operation to perform */
+		uint64_t rsvd_48:1;
 		uint64_t no_sched:1;
 		cvmx_pow_tag_type_t type:2;
-		uint64_t grp:12;
-		uint64_t unused2:3;
+		uint64_t grp:10;
+		uint64_t rsvd_62_63:2;
 #endif
 	} s_cn78xx_other;
 
 } cvmx_pow_tag_req_t;
 
-typedef struct {
-	uint32_t tag;
-	uint16_t index;
-	uint8_t grp;
-	uint8_t tag_type;
-} cvmx_pow_tag_info_t;
-
-
 union cvmx_pow_tag_req_addr {
 	uint64_t u64;
 	struct {
@@ -299,9 +321,8 @@ union cvmx_pow_tag_req_addr {
 		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 		CVMX_BITFIELD_FIELD(uint64_t is_io:1,/**< Must be one */
 	        CVMX_BITFIELD_FIELD(uint64_t did:8,
-		CVMX_BITFIELD_FIELD(uint64_t reserved_40_37:4,
-		CVMX_BITFIELD_FIELD(uint64_t addr:36,
-				    ;))))))
+		CVMX_BITFIELD_FIELD(uint64_t addr:40,
+				    ;)))))
 	} s;
 	struct {
 		/**< Mips64 address region. Should be CVMX_IO_SEG */
@@ -1465,19 +1486,16 @@ typedef union {
 					    /**< Must be zero */
 		uint64_t is_io:1;	    /**< Must be one */
 		uint64_t did:8;		    /**< Device ID of POW.  Note that different sub-dids are used. */
-		uint64_t reserved_36_39:4;
-					    /**< Must be zero */
-		uint64_t addr:36;	    /**< Address field. addr<2:0> must be zero */
+		uint64_t addr:40;	    /**< Address field. addr<2:0> must be zero */
 #else
-		uint64_t addr:36;
-		uint64_t reserved_36_39:4;
+		uint64_t addr:40;
 		uint64_t did:8;
 		uint64_t is_io:1;
 		uint64_t reserved_49_61:13;
 		uint64_t mem_reg:2;
 #endif
 	} stag;
-} cvmx_pow_tag_store_addr_t;
+} cvmx_pow_tag_store_addr_t;	/* FIXME- this type is unused */
 
 /**
  * decode of the store data when an IOBDMA SENDSINGLE is sent to POW
@@ -1562,13 +1580,17 @@ static inline cvmx_pow_tag_info_t cvmx_pow_get_current_tag(void)
 
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_sso_sl_ppx_tag_t sl_ppx_tag;
+		cvmx_xgrp_t xgrp;
 		int node = cvmx_get_node_num();
 		int core = cvmx_get_core_num();
 		sl_ppx_tag.u64 = cvmx_read_csr_node(node, CVMX_SSO_SL_PPX_TAG(core));
-		result.grp = sl_ppx_tag.s.grp;
 		result.index = sl_ppx_tag.s.index;
 		result.tag_type = sl_ppx_tag.s.tt;
 		result.tag      = sl_ppx_tag.s.tag;
+
+		/* Return legacy style group 0..15 */
+		xgrp.xgrp -=  sl_ppx_tag.s.grp;
+		result.grp = xgrp.group;
 	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		cvmx_pow_sl_tag_resp_t load_resp;
 		load_addr.u64 = 0;
@@ -1697,13 +1719,19 @@ static inline cvmx_wqe_t *cvmx_pow_work_request_sync_nocheck(cvmx_pow_wait_t wai
 		__cvmx_pow_warn_if_pending_switch(__func__);
 
 	ptr.u64 = 0;
-	ptr.swork.mem_region = CVMX_IO_SEG;
-	ptr.swork.is_io = 1;
-	ptr.swork.did = CVMX_OCT_DID_TAG_SWTAG;
-	ptr.swork.wait = wait;
 
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		ptr.swork_78xx.node = cvmx_get_node_num();
+		ptr.swork_78xx.mem_region = CVMX_IO_SEG;
+		ptr.swork_78xx.is_io = 1;
+		ptr.swork_78xx.did = CVMX_OCT_DID_TAG_SWTAG;
+		ptr.swork_78xx.wait = wait;
+	} else {
+		ptr.swork.mem_region = CVMX_IO_SEG;
+		ptr.swork.is_io = 1;
+		ptr.swork.did = CVMX_OCT_DID_TAG_SWTAG;
+		ptr.swork.wait = wait;
+
 	}
 
 	result.u64 = cvmx_read_csr(ptr.u64);
@@ -1808,11 +1836,12 @@ static inline void cvmx_pow_work_request_async_nocheck(int scr_addr, cvmx_pow_wa
  * @param scr_addr Scratch memory address that response will be returned to,
  *                  which is either a valid WQE, or a response with the invalid bit set.
  *                  Byte address, must be 8 byte aligned.
- * @param group     group to receive work for.
+ * @param xgrp      group to receive work for (0-255).
  * @param wait      1 to cause response to wait for work to become available (or timeout)
  *                  0 to cause response to return immediately
  */
-static inline void cvmx_sso_work_request_grp_async_nocheck(int scr_addr, unsigned group, cvmx_pow_wait_t wait)
+static inline void cvmx_sso_work_request_grp_async_nocheck(int scr_addr,
+	cvmx_xgrp_t xgrp, cvmx_pow_wait_t wait)
 {
 	cvmx_pow_iobdma_store_t data;
 	if (CVMX_ENABLE_POW_CHECKS)
@@ -1826,7 +1855,7 @@ static inline void cvmx_sso_work_request_grp_async_nocheck(int scr_addr, unsigne
 		data.s_cn78xx.len = 1;
 		data.s_cn78xx.did = CVMX_OCT_DID_TAG_SWTAG;
 		data.s_cn78xx.grouped = 1;
-		data.s_cn78xx.index_grp_mask = (node << 8) | (group & 0xff);
+		data.s_cn78xx.index_grp_mask = (node << 8) | xgrp.xgrp ;
 		data.s_cn78xx.wait = wait;
 		data.s_cn78xx.node = node;
 	} else {
@@ -1942,7 +1971,6 @@ static inline void cvmx_pow_tag_sw_nocheck(uint32_t tag, cvmx_pow_tag_type_t tag
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		tag_req.s_cn78xx_other.op   = CVMX_POW_TAG_OP_SWTAG;
 		tag_req.s_cn78xx_other.type = tag_type;
-		/* FIXME: tag */
 	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		tag_req.s_cn68xx_other.op = CVMX_POW_TAG_OP_SWTAG;
 		tag_req.s_cn68xx_other.tag = tag;
@@ -2051,10 +2079,29 @@ static inline void cvmx_pow_tag_sw_full_nocheck(cvmx_wqe_t * wqp, uint32_t tag,
 
 	tag_req.u64 = 0;
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		unsigned xgrp = 0;
+		uint64_t wqp_phys;
+
+		wqp_phys = cvmx_ptr_to_phys(wqp);
+
+		/* Inherit QoS but replace grp, current node */
+		if(wqp_phys!= 0x80)
+			xgrp = wqp->word1.cn78xx.grp;
+		xgrp &= 0x7;
+		xgrp |= group << 3;
+		xgrp |= 0x300 & (cvmx_get_node_num() << 8);
+
 		tag_req.s_cn78xx_other.op = CVMX_POW_TAG_OP_SWTAG_FULL;
 		tag_req.s_cn78xx_other.type = tag_type;
-		tag_req.s_cn78xx_other.grp = group;
-		tag_req.s_cn78xx_other.wqp = CAST64(wqp); /* FIXME: phys ? */
+		tag_req.s_cn78xx_other.grp = xgrp;
+		tag_req.s_cn78xx_other.wqp = wqp_phys;
+
+		/* WQE GRP is 10 bits, includes node # */
+		if(wqp_phys != 0x80) {
+			wqp->word1.cn78xx.grp = xgrp;
+			wqp->word1.cn78xx.tag = tag;
+			wqp->word1.cn78xx.tag_type = tag_type;
+		}
 	}
 	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		tag_req.s_cn68xx_other.op = CVMX_POW_TAG_OP_SWTAG_FULL;
@@ -2079,7 +2126,7 @@ static inline void cvmx_pow_tag_sw_full_nocheck(cvmx_wqe_t * wqp, uint32_t tag,
 		ptr.s.mem_region = CVMX_IO_SEG;
 		ptr.s.is_io = 1;
 		ptr.s.did = CVMX_OCT_DID_TAG_SWTAG;
-		ptr.s.addr = CAST64(wqp);
+		ptr.s.addr = cvmx_ptr_to_phys(wqp);
 	}
 
 	/* once this store arrives at POW, it will attempt the switch
@@ -2204,15 +2251,36 @@ static inline void cvmx_pow_tag_sw_null(void)
  */
 static inline void cvmx_pow_work_submit(cvmx_wqe_t * wqp, uint32_t tag, cvmx_pow_tag_type_t tag_type, uint64_t qos, uint64_t grp)
 {
-	cvmx_addr_t ptr;
+	union cvmx_pow_tag_req_addr ptr;
 	cvmx_pow_tag_req_t tag_req;
 
 	tag_req.u64 = 0;
+	ptr.u64 = 0;
 
-	wqp->word1.tag = tag;
-	wqp->word1.tag_type = tag_type;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		unsigned node = cvmx_get_node_num();
+		unsigned xgrp;
+
+		xgrp = (grp & 0x1f) << 3 ;
+		xgrp |= (qos & 7);
+		xgrp |= 0x300 & (node << 8);
+ 
+		wqp->word1.cn78xx.rsvd_0 = 0;
+		wqp->word1.cn78xx.rsvd_1 = 0;
+		wqp->word1.cn78xx.tag = tag;
+		wqp->word1.cn78xx.tag_type = tag_type;
+		wqp->word1.cn78xx.grp = xgrp;
+
+		tag_req.s_cn78xx_other.op = CVMX_POW_TAG_OP_ADDWQ;
+		tag_req.s_cn78xx_other.type = tag_type;
+		tag_req.s_cn78xx_other.wqp = cvmx_ptr_to_phys(wqp);
 
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
+		ptr.s_cn78xx.did = 0x66; //CVMX_OCT_DID_TAG_TAG6;
+		ptr.s_cn78xx.mem_region = CVMX_IO_SEG;
+		ptr.s_cn78xx.is_io = 1;
+		ptr.s_cn78xx.node = node;
+		ptr.s_cn78xx.tag = tag;
+	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		/* Reset all reserved bits */
 		wqp->word1.cn68xx.zero_0 = 0;
 		wqp->word1.cn68xx.zero_1 = 0;
@@ -2220,29 +2288,39 @@ static inline void cvmx_pow_work_submit(cvmx_wqe_t * wqp, uint32_t tag, cvmx_pow
 		wqp->word1.cn68xx.qos = qos;
 		wqp->word1.cn68xx.grp = grp;
 
+		wqp->word1.tag = tag;
+		wqp->word1.tag_type = tag_type;
+
 		tag_req.s_cn68xx_add.op = CVMX_POW_TAG_OP_ADDWQ;
 		tag_req.s_cn68xx_add.type = tag_type;
 		tag_req.s_cn68xx_add.tag = tag;
 		tag_req.s_cn68xx_add.qos = qos;
 		tag_req.s_cn68xx_add.grp = grp;
+
+		ptr.s.mem_region = CVMX_IO_SEG;
+		ptr.s.is_io = 1;
+		ptr.s.did = CVMX_OCT_DID_TAG_TAG1;
+		ptr.s.addr = cvmx_ptr_to_phys(wqp);
 	} else {
 		/* Reset all reserved bits */
 		wqp->word1.cn38xx.zero_2 = 0;
 		wqp->word1.cn38xx.qos = qos;
 		wqp->word1.cn38xx.grp = grp;
 
+		wqp->word1.tag = tag;
+		wqp->word1.tag_type = tag_type;
+
 		tag_req.s_cn38xx.op = CVMX_POW_TAG_OP_ADDWQ;
 		tag_req.s_cn38xx.type = tag_type;
 		tag_req.s_cn38xx.tag = tag;
 		tag_req.s_cn38xx.qos = qos;
 		tag_req.s_cn38xx.grp = grp;
-	}
 
-	ptr.u64 = 0;
-	ptr.sio.mem_region = CVMX_IO_SEG;
-	ptr.sio.is_io = 1;
-	ptr.sio.did = CVMX_OCT_DID_TAG_TAG1;
-	ptr.sio.offset = cvmx_ptr_to_phys(wqp);
+		ptr.s.mem_region = CVMX_IO_SEG;
+		ptr.s.is_io = 1;
+		ptr.s.did = CVMX_OCT_DID_TAG_TAG1;
+		ptr.s.addr = cvmx_ptr_to_phys(wqp);
+	}
 
 	/* SYNC write to memory before the work submit.  This is necessary
 	 ** as POW may read values from DRAM at this time */
@@ -2256,22 +2334,51 @@ static inline void cvmx_pow_work_submit(cvmx_wqe_t * wqp, uint32_t tag, cvmx_pow
  * 16 groups.
  *
  * @param core_num   core to apply mask to
- * @param mask   Group mask. There are 16 groups, so only bits 0-15 are valid,
- *               representing groups 0-15.
+ * @param mask   Group mask, one bit for up to 64 groups.
  *               Each 1 bit in the mask enables the core to accept work from
  *               the corresponding group.
+ *               The CN68XX supports 64 groups, earlier models only support
+ *               16 groups. The CN78XX in backwards compatibility mode
+ *               allows up to 32 groups.
  */
 static inline void cvmx_pow_set_group_mask(uint64_t core_num, uint64_t mask)
 {
 
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_sso_ppx_sx_grpmskx_t grp_msk;
+		unsigned node = cvmx_get_node_num();
+		unsigned s, g, xg;
+
+		cvmx_warn_if(mask & (~0xffffffffull),
+			"%s group number range exceeded: %#llx\n",
+			__FUNCTION__, (unsigned long long) mask);
+
+		for(s = 0; s < (CVMX_SSO_NUM_XGRP/64); s ++ ) {
+			grp_msk.s.grp_msk = 0ull;
+			for(g = 0; g < 64; g++) {
+				xg = (s << 6) | g;
+				xg = (xg >> 3) & 0x1f;
+				if(mask & (1ull << xg))
+					grp_msk.s.grp_msk |= 1ull << g;
+			}
+
+			cvmx_write_csr_node(node,
+				CVMX_SSO_PPX_SX_GRPMSKX(core_num, 0, s),
+				grp_msk.u64);
+		}
+	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		cvmx_sso_ppx_grp_msk_t grp_msk;
 		grp_msk.s.grp_msk = mask;
 		cvmx_write_csr(CVMX_SSO_PPX_GRP_MSK(core_num), grp_msk.u64);
 	} else {
 		cvmx_pow_pp_grp_mskx_t grp_msk;
+
+		cvmx_warn_if(mask & ~0xffffull,
+			"%s group number range exceeded: %#llx\n",
+			__FUNCTION__, (unsigned long long) mask);
+
 		grp_msk.u64 = cvmx_read_csr(CVMX_POW_PP_GRP_MSKX(core_num));
-		grp_msk.s.grp_msk = mask;
+		grp_msk.s.grp_msk = mask & 0xffff;
 		cvmx_write_csr(CVMX_POW_PP_GRP_MSKX(core_num), grp_msk.u64);
 	}
 }
@@ -2281,34 +2388,62 @@ static inline void cvmx_pow_set_group_mask(uint64_t core_num, uint64_t mask)
  * indicates which groups each core will accept work from. There are
  * 256 groups in 78xx.
  *
- * @param node 		node number
- * @param core_num   	core to apply mask to
+ * @param core_num   	processor core to apply mask to
  * @param mask_set	78XX has 2 set of masks per core each with 256 groups.
- *                      Cores can choose which mask set to get work from when
-                        getting the work.
- * @param mask   	Group mask. There are 256 groups, divided in 4 of 64 bit mask sets.
+ *                      Bit 0 represents the first mask set, bit 1 the second,
+ * 			when set a each member of <xgrp_mask> will be added
+ * 			to the core, when cleared, each of the groups in
+ * 			<xgrp_mask> will be removed from the mask set.
+ * @param xgrp_mask   	Group mask. There are 256 groups, divided in 4 of 64 bit mask sets.
  * 	        	Each 1 bit in the mask enables the core to accept work from
  *      	        the corresponding group.
+ *
+ * Note: each core can be configured to accept work in accordance to both
+ * mask sets, with the first having higher precedence over the second,
+ * or to accept work in accordance to just one of the two mask sets.
+ * The <core_num> argument represents a processor core on any node
+ * in a coherent multi-chip system.
+ *
+ * TBD: function to configure which mask_set is applied to a core.
  */
-static inline void cvmx_pow_set_group_mask_78xx(int node, uint64_t core_num,
-		uint64_t mask_set, const uint64_t mask[])
+static inline void cvmx_pow_set_xgrp_mask( uint64_t core_num,
+		uint8_t mask_set, const uint64_t xgrp_mask[])
 {
-	int grp;
+	cvmx_sso_ppx_sx_grpmskx_t grp_msk;
+	unsigned grp, node, core;
 
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		cvmx_sso_ppx_sx_grpmskx_t grp_msk;
-		for (grp = 0; grp < CVMX_SSO_NUM_GROUPS_SET; grp++) {
-			if(mask_set & 1) {
-				grp_msk.u64 = cvmx_read_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core_num, 0, grp));
-				grp_msk.s.grp_msk |= mask[grp];
-				cvmx_write_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core_num, 0, grp), grp_msk.u64);
-			}
-			if(mask_set & 2) {
-				grp_msk.u64 = cvmx_read_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core_num, 1, grp));
-				grp_msk.s.grp_msk |= mask[grp];
-				cvmx_write_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core_num, 1, grp), grp_msk.u64);
-			}
-		}
+	if (!octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_dprintf(
+			"ERROR: %s is not supported on this chip)\n", 
+			__FUNCTION__);
+		return;
+	}
+
+	node = cvmx_coremask_core_to_node(core_num);
+	core = cvmx_coremask_core_on_node(core_num);
+
+	for (grp = 0; grp < (CVMX_SSO_NUM_XGRP >> 6); grp++) {
+		uint64_t reg_addr;
+
+		reg_addr = CVMX_SSO_PPX_SX_GRPMSKX(core, 0, grp),
+		grp_msk.u64 = cvmx_read_csr_node(node,reg_addr);
+
+		if (mask_set & 1)
+			grp_msk.s.grp_msk |= xgrp_mask[grp];
+		else
+			grp_msk.s.grp_msk &= ~xgrp_mask[grp];
+
+		cvmx_write_csr_node(node, reg_addr, grp_msk.u64);
+
+		reg_addr = CVMX_SSO_PPX_SX_GRPMSKX(core, 1, grp),
+		grp_msk.u64 = cvmx_read_csr_node(node,reg_addr);
+
+		if (mask_set & 2)
+			grp_msk.s.grp_msk |= xgrp_mask[grp];
+		else
+			grp_msk.s.grp_msk &= ~xgrp_mask[grp];
+
+		cvmx_write_csr_node(node, reg_addr, grp_msk.u64);
 	}
 }
 
@@ -2316,44 +2451,70 @@ static inline void cvmx_pow_set_group_mask_78xx(int node, uint64_t core_num,
  * This function sets the the affinity of group to the cores in 78xx.
  * It sets up all the cores in core_mask to accept work from the specified group.
  *
- * @param node 		node number
- * @param group  	group to accept work from.
+ * @param xgrp  	group to accept work from, 0 - 255.
  * @param core_mask	mask of all the cores which will accept work from this group
  * @param mask_set	every core has set of 2 masks which can be set to accept work
  *                      from 256 groups. At the time of get_work, cores can choose which
  *			mask_set to get work from.
+ * 			<mask_set> values range from 0 to 3, where
+ * 			each of the two bits represents a mask set.
+ * 			Cores will be added to the mask set whith corresponding
+ * 			bit set, and removed from the mask set with 
+ * 			corresponding bit clear.
+ *
+ * Note: cores can only accept work from SSO groups on the same node,
+ * so the node number for the group is derived from the core number.
+ *
  */
-static inline void cvmx_sso_set_group_core_affinity(int node, int group,
-		uint64_t core_mask, int mask_set)
+static inline void cvmx_sso_set_group_core_affinity(cvmx_xgrp_t xgrp,
+		const cvmx_coremask_t * core_mask, uint8_t mask_set)
 {
 	cvmx_sso_ppx_sx_grpmskx_t grp_msk;
 	int core;
-	int grp_index  = group >> 6;
-	int bit_pos = group % 64;
-
-	//cvmx_dprintf("Vinita group=%d grp_index=%d bit_pos=%d core_mask=0x%lx\n",group,grp_index,bit_pos,core_mask);
-	while((core = __builtin_ffsll(core_mask))) {
-		core--;
-		if(mask_set & 1) {
-			grp_msk.u64 = cvmx_read_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core, 0, grp_index));
-			grp_msk.s.grp_msk |= (uint64_t)(1ull << bit_pos);
-			cvmx_write_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core, 0, grp_index), grp_msk.u64);
-		}
-		if(mask_set & 2) {
-			grp_msk.u64 = cvmx_read_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core, 1, grp_index));
-			grp_msk.s.grp_msk |= (uint64_t)(1ull << bit_pos);
-			cvmx_write_csr_node(node, CVMX_SSO_PPX_SX_GRPMSKX(core, 1, grp_index), grp_msk.u64);
-		}
-		core_mask &= core_mask - 1;
+	int grp_index  = xgrp.xgrp >> 6;
+	int bit_pos = xgrp.xgrp % 64;
+
+	if (!octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_dprintf(
+			"ERROR: %s is not supported on this chip)\n", 
+			__FUNCTION__);
+		return;
 	}
 
+	cvmx_coremask_for_each_core(core, core_mask) {
+		unsigned node, ncore;
+		uint64_t reg_addr;
+
+		node = cvmx_coremask_core_to_node(core);
+		ncore = cvmx_coremask_core_on_node(core);
+
+		reg_addr = CVMX_SSO_PPX_SX_GRPMSKX(ncore, 0, grp_index);
+		grp_msk.u64 = cvmx_read_csr_node(node, reg_addr);
+
+		if(mask_set & 1) 
+			grp_msk.s.grp_msk |= (1ull << bit_pos);
+		else
+			grp_msk.s.grp_msk &= ~(1ull << bit_pos);
+		
+		cvmx_write_csr_node(node, reg_addr, grp_msk.u64);
+
+		reg_addr = CVMX_SSO_PPX_SX_GRPMSKX(ncore, 1, grp_index);
+		grp_msk.u64 = cvmx_read_csr_node(node, reg_addr);
+
+		if(mask_set & 2) 
+			grp_msk.s.grp_msk |= (1ull << bit_pos);
+		else
+			grp_msk.s.grp_msk &= ~(1ull << bit_pos);
+		
+		cvmx_write_csr_node(node, reg_addr, grp_msk.u64);
+	}
 }
 
 /**
  * This function sets the priority and group affinity arbitration for each group.
  *
  * @param node 		node number
- * @param group  	group to apply mask parameters to
+ * @param xgrp  	group 0 - 255 to apply mask parameters to
  * @param priority	priority of the group relative to other groups
  *			0x0 - highest priority
  *			0x7 - lowest priority
@@ -2370,20 +2531,27 @@ static inline void cvmx_sso_set_group_core_affinity(int node, int group,
  *                      to modify only weight   -- set bit1
  *			to modify only affinity -- set bit2
  */
-static inline void cvmx_sso_set_group_priority(int node , int group, int priority,
-					       int weight, int affinity,
-					       enum cvmx_sso_group_modify_mask modify_mask)
+static inline void cvmx_sso_set_group_priority(int node, cvmx_xgrp_t xgrp,
+			int priority, int weight, int affinity,
+		       enum cvmx_sso_group_modify_mask modify_mask)
 {
 	cvmx_sso_grpx_pri_t grp_pri;
 
-	grp_pri.u64 = cvmx_read_csr_node(node, CVMX_SSO_GRPX_PRI(group));
+	if (!octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_dprintf(
+			"ERROR: %s is not supported on this chip)\n", 
+			__FUNCTION__);
+		return;
+	}
+
+	grp_pri.u64 = cvmx_read_csr_node(node, CVMX_SSO_GRPX_PRI(xgrp.xgrp));
 	if(modify_mask & CVMX_SSO_MODIFY_GROUP_PRIORITY)
 		grp_pri.s.pri = priority;
 	if(modify_mask & CVMX_SSO_MODIFY_GROUP_WEIGHT)
 		grp_pri.s.weight = weight;
 	if(modify_mask & CVMX_SSO_MODIFY_GROUP_AFFINITY)
 		grp_pri.s.affinity = affinity;
-	cvmx_write_csr_node(node,CVMX_SSO_GRPX_PRI(group),grp_pri.u64);
+	cvmx_write_csr_node(node,CVMX_SSO_GRPX_PRI(xgrp.xgrp),grp_pri.u64);
 }
 
 /**
@@ -2405,7 +2573,7 @@ static inline void cvmx_pow_set_priority(uint64_t core_num, const uint8_t priori
 		return;
 
 	/* Detect gaps between priorities and flag error */
-	{
+	if (!octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		int i;
 		uint32_t prio_mask = 0;
 
@@ -2419,8 +2587,23 @@ static inline void cvmx_pow_set_priority(uint64_t core_num, const uint8_t priori
 		}
 	}
 
-	/* POW priorities are supported on CN5xxx and later */
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		unsigned group;
+		unsigned node = cvmx_get_node_num();
+		cvmx_sso_grpx_pri_t grp_pri;
+
+		grp_pri.s.weight = 0x3f;
+		grp_pri.s.affinity = 0xf;
+
+		for(group = 0; group < CVMX_SSO_NUM_XGRP; group ++ ) {
+			grp_pri.u64 = cvmx_read_csr_node(node,
+				CVMX_SSO_GRPX_PRI(group));
+			grp_pri.s.pri = priority[group & 0x7];
+			cvmx_write_csr_node(node,
+				CVMX_SSO_GRPX_PRI(group), grp_pri.u64);
+		}
+
+	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
 		cvmx_sso_ppx_qos_pri_t qos_pri;
 
 		qos_pri.u64 = cvmx_read_csr(CVMX_SSO_PPX_QOS_PRI(core_num));
@@ -2434,6 +2617,7 @@ static inline void cvmx_pow_set_priority(uint64_t core_num, const uint8_t priori
 		qos_pri.s.qos7_pri = priority[7];
 		cvmx_write_csr(CVMX_SSO_PPX_QOS_PRI(core_num), qos_pri.u64);
 	} else {
+		/* POW priorities on CN5xxx .. CN66XX */
 		cvmx_pow_pp_grp_mskx_t grp_msk;
 
 		grp_msk.u64 = cvmx_read_csr(CVMX_POW_PP_GRP_MSKX(core_num));
@@ -2508,18 +2692,21 @@ static inline void cvmx_pow_tag_sw_desched_nocheck(uint32_t tag, cvmx_pow_tag_ty
 
 	tag_req.u64 = 0;
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		group &= 0x1f;
 		tag_req.s_cn78xx_other.op = CVMX_POW_TAG_OP_SWTAG_DESCH;
 		tag_req.s_cn78xx_other.type = tag_type;
-		tag_req.s_cn78xx_other.grp = group;
+		tag_req.s_cn78xx_other.grp = group << 3;
 		tag_req.s_cn68xx_other.no_sched = no_sched;
 	}
 	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
+		group &= 0x3f;
 		tag_req.s_cn68xx_other.op = CVMX_POW_TAG_OP_SWTAG_DESCH;
 		tag_req.s_cn68xx_other.tag = tag;
 		tag_req.s_cn68xx_other.type = tag_type;
 		tag_req.s_cn68xx_other.grp = group;
 		tag_req.s_cn68xx_other.no_sched = no_sched;
 	} else {
+		group &= 0x0f;
 		tag_req.s_cn38xx.op = CVMX_POW_TAG_OP_SWTAG_DESCH;
 		tag_req.s_cn38xx.tag = tag;
 		tag_req.s_cn38xx.type = tag_type;
@@ -2717,13 +2904,14 @@ static inline uint32_t cvmx_pow_tag_get_hw_bits(uint64_t tag)
 
 static inline uint64_t cvmx_sso_get_total_wqe_count(void)
 {
-	if(OCTEON_IS_MODEL(OCTEON_CN78XX))
+
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 	{
 		cvmx_sso_grpx_aq_cnt_t sso_iq_com_cnt;
 		int grp = 0;
 		uint64_t cnt = 0;
 
-		for( grp = 0; grp < CVMX_SSO_NUM_GROUPS_78XX; grp++) {
+		for( grp = 0; grp < CVMX_SSO_NUM_XGRP; grp++) {
 			sso_iq_com_cnt.u64 = cvmx_read_csr_node(0,CVMX_SSO_GRPX_AQ_CNT(grp));
 			cnt += sso_iq_com_cnt.u64;
 		}
@@ -2782,4 +2970,11 @@ extern int cvmx_pow_get_num_entries(void);
 /* *INDENT-ON* */
 #endif
 
+/*
+ * TODO:
+ *
+ * WQE_ALLOC - make use of cn78xx hardware-supported feature
+ * PREP_WORK - prefetch next WQE,
+ */
+
 #endif /* __CVMX_POW_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-qlm.h b/arch/mips/include/asm/octeon/cvmx-qlm.h
index 7c8dc18..97525df 100644
--- a/arch/mips/include/asm/octeon/cvmx-qlm.h
+++ b/arch/mips/include/asm/octeon/cvmx-qlm.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2011-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2011-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 90025 $<hr>
+ * <hr>$Revision: 93892 $<hr>
  */
 
 #ifndef __CVMX_QLM_H__
@@ -166,7 +166,7 @@ enum cvmx_qlm_mode {
 	CVMX_QLM_MODE_SGMII = 1,
 	CVMX_QLM_MODE_XAUI,
 	CVMX_QLM_MODE_RXAUI,
-	CVMX_QLM_MODE_PCIE,	/* gen2 / gen1 */
+	CVMX_QLM_MODE_PCIE,	/* gen3 / gen2 / gen1 */
 	CVMX_QLM_MODE_PCIE_1X2,	/* 1x2 gen2 / gen1 */
 	CVMX_QLM_MODE_PCIE_2X1,	/* 2x1 gen2 / gen1 */
 	CVMX_QLM_MODE_PCIE_1X1,	/* 1x1 gen2 / gen1 */
@@ -185,6 +185,10 @@ enum cvmx_qlm_mode {
 	CVMX_QLM_MODE_QSGMII_SGMII,
 	CVMX_QLM_MODE_RXAUI_1X2,
 	CVMX_QLM_MODE_SATA_2X1,
+	CVMX_QLM_MODE_XLAUI,
+	CVMX_QLM_MODE_XFI,
+	CVMX_QLM_MODE_PCIE_1X8,  /* 1x8 gen3 / gen2 / gen1 */
+	CVMX_QLM_MODE_OCI
 };
 
 enum cvmx_gmx_inf_mode {
diff --git a/arch/mips/include/asm/octeon/cvmx-rst-defs.h b/arch/mips/include/asm/octeon/cvmx-rst-defs.h
index 03f830d..e996d0b 100644
--- a/arch/mips/include/asm/octeon/cvmx-rst-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-rst-defs.h
@@ -189,7 +189,7 @@ union cvmx_rst_boot {
                                                          timer is specified by RST_CKILL[TIMER]. */
 	uint64_t jtcsrdis                     : 1;  /**< When set, internal CSR access via JTAG TAP controller is disabled This field resets to 1
                                                          in Authentik mode, else 0. */
-	uint64_t ejtagdis                     : 1;  /**< When set, external EJTAG access is disabled This field resets to 1 in Authentik mode, else 0. */
+	uint64_t ejtagdis                     : 1;  /**< When set, external EJTAG access is disabled. This field resets to 1 in Authentik mode, else 0. */
 	uint64_t romen                        : 1;  /**< When set, Authentik/eMMC boot ROM is visible in the boot bus address space. This field
                                                          resets to 1 in an Authentik part or when booting from eMMC. Else, resets to 0. */
 	uint64_t ckill_ppdis                  : 1;  /**< When set, cores other than 0 are disabled during a CHIPKILL.  Writes have no effect when
@@ -316,16 +316,19 @@ union cvmx_rst_ctlx {
                                                          0. */
 	uint64_t rst_done                     : 1;  /**< Read-only access to controller reset status. RST_DONE is always zero (i.e. the controller
                                                          is held in reset) when:
-                                                         RST_SOFT_PRST*[SOFT_PRST] = 1, or
-                                                         RST_RCV = 1 and PERST*_L pin is asserted. */
+                                                         * RST_SOFT_PRST*[SOFT_PRST] = 1, or
+                                                         * RST_RCV = 1 and PERST*_L pin is asserted. */
 	uint64_t rst_link                     : 1;  /**< Reset link. Controls whether corresponding controller link-down reset or hot reset causes
                                                          a warm chip reset. On cold reset, this field is initialized as follows:
                                                          0 when RST_CTL*[HOST_MODE] = 1
                                                          1 when RST_CTL*[HOST_MODE] = 0
                                                          Note that a link-down or hot-reset event can never cause a warm chip reset when the
                                                          controller is in reset (i.e. can never cause a warm reset when RST_DONE = 0). */
-	uint64_t host_mode                    : 1;  /**< Read-only access to the corresponding straps indicating PCIE*_MODE is host. For
-                                                         controllers 2 and 3 this field is always set. */
+	uint64_t host_mode                    : 1;  /**< Read-only access to the corresponding PEM(0..3)_CFG[HOSTMD] field indicating PEMn is root
+                                                         complex (host).
+                                                         For controllers 0 and 2 the inital value is determined by straps.  For controllers 1 and 3
+                                                         these field
+                                                         is initially set as host. */
 	uint64_t reserved_4_5                 : 2;
 	uint64_t rst_drv                      : 1;  /**< Controls whether PERST*_L is driven. A warm/soft reset does not change this field. On cold
                                                          reset, this field is initialized as follows:
@@ -422,11 +425,10 @@ union cvmx_rst_int {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_11_63               : 53;
 	uint64_t perst                        : 3;  /**< PERST*_L asserted while RST_CTL*[RST_RCV] = 1 and RST_CTL*[RST_CHIP] = 0. One bit
-                                                         corresponds to each controller. Throws RST_INTSN_E::RST_INT_PERST(0..2). */
+                                                         corresponds to each controller. */
 	uint64_t reserved_3_7                 : 5;
 	uint64_t rst_link                     : 3;  /**< A controller link-down/hot-reset occurred while RST_CTL*[RST_LINK] = 0. Software must
-                                                         assert then deassert RST_SOFT_PRST*[SOFT_PRST]. One bit corresponds to each controller.
-                                                         Throws RST_INTSN_E::RST_INT_LINK(0..2). */
+                                                         assert then deassert RST_SOFT_PRST*[SOFT_PRST]. One bit corresponds to each controller. */
 #else
 	uint64_t rst_link                     : 3;
 	uint64_t reserved_3_7                 : 5;
@@ -518,8 +520,8 @@ union cvmx_rst_soft_prstx {
 	uint64_t reserved_1_63                : 63;
 	uint64_t soft_prst                    : 1;  /**< Resets the PCIe logic and corresponding common logic associated with the SLI controller in
                                                          all modes, not just RC mode.
-                                                         If the RST_CTL*[HOST_MODE] = 0, SOFT_PRST resets to 0.
-                                                         If the RST_CTL*[HOST_MODE] = 1, SOFT_PRST resets to 1.
+                                                         * If the RST_CTL*[HOST_MODE] = 0, SOFT_PRST resets to 0.
+                                                         * If the RST_CTL*[HOST_MODE] = 1, SOFT_PRST resets to 1.
                                                          When CN78XX is configured to drive PERST*_L (i.e.
                                                          RST_CTL(0..3)[RST_DRV] = 1), this controls the output value on PERST*_L. */
 #else
diff --git a/arch/mips/include/asm/octeon/cvmx-sli-defs.h b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
index 4f9cb37..86e8dd5 100644
--- a/arch/mips/include/asm/octeon/cvmx-sli-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
@@ -3266,8 +3266,7 @@ union cvmx_sli_int_enb_portx {
 	uint64_t pcnt                         : 1;  /**< Enables SLI_INT_SUM[4] to generate an
                                                          interrupt to the PCIE core for MSI/inta. */
 	uint64_t reserved_1_3                 : 3;
-	uint64_t rml_to                       : 1;  /**< Enables SLI_INT_SUM[0] to generate an
-                                                         interrupt to the PCIE core for MSI/inta. */
+	uint64_t rml_to                       : 1;  /**< Enables SLI_INT_SUM[RML_TO] to generate an interrupt to the PCIE core for MSI/INTA. */
 #else
 	uint64_t rml_to                       : 1;
 	uint64_t reserved_1_3                 : 3;
@@ -4070,12 +4069,13 @@ union cvmx_sli_int_sum {
 	uint64_t pidbof                       : 1;  /**< Packet instruction doorbell count overflowed. Which doorbell can be found in
                                                          DPI_PINT_INFO[PIDBOF]. Throws SLI_INTSN_E::SLI_INT_PIDBOF. */
 	uint64_t reserved_38_47               : 10;
-	uint64_t dtime                        : 2;  /**< Whenever SLI_DMAx_CNT[CNT] is not 0, the SLI_DMAx_TIM[TIM] timer increments every SLI
-                                                         clock. DTIME<x> is set whenever SLI_DMAx_TIM[TIM] > SLI_DMAx_INT_LEVEL[TIME]. DTIME<x> is
-                                                         normally cleared by clearing SLI_DMAx_CNT[CNT] (which also clears SLI_DMAx_TIM[TIM]).
-                                                         Throws SLI_INTSN_E::SLI_INT_DTIME. */
-	uint64_t dcnt                         : 2;  /**< DCNT<x> is set whenever SLI_DMAx_CNT[CNT] > SLI_DMAx_INT_LEVEL[CNT]. DCNT<x> is normally
-                                                         cleared by decreasing SLI_DMAx_CNT[CNT]. Throws SLI_INTSN_E::SLI_INT_DCNT. */
+	uint64_t dtime                        : 2;  /**< Whenever SLI_DMA(0..1)_CNT[CNT] is not 0, the SLI_DMA(0..1)_TIM[TIM] timer increments
+                                                         every SLI clock. DTIME<x> is set whenever SLI_DMA(0..1)_TIM[TIM] >
+                                                         SLI_DMA(0..1)_INT_LEVEL[TIME]. DTIME<x> is normally cleared by clearing
+                                                         SLI_DMA(0..1)_CNT[CNT] (which also clears SLI_DMA(0..1)_TIM[TIM]). Throws
+                                                         SLI_INTSN_E::SLI_INT_DTIME. */
+	uint64_t dcnt                         : 2;  /**< DCNT<x> is set whenever SLI_DMAx_CNT[CNT] > SLI_DMA(0..1)_INT_LEVEL[CNT]. DCNT<x> is
+                                                         normally cleared by decreasing SLI_DMA(0..1)_CNT[CNT]. Throws SLI_INTSN_E::SLI_INT_DCNT. */
 	uint64_t dmafi                        : 2;  /**< DMA set forced interrupts. Throws SLI_INTSN_E::SLI_INT_DMAFI. */
 	uint64_t reserved_29_31               : 3;
 	uint64_t vf_err                       : 1;  /**< Illegal access from VF. Throws SLI_INTSN_E::SLI_INT_VF_ERR. */
@@ -5684,16 +5684,18 @@ union cvmx_sli_pktx_input_control {
                                                          3. Start up the packet input/output again (all previous CSR setting of the packet-
                                                          input/output will be lost).
                                                          See also SLI_PKT_RING_RST[RST]. */
-	uint64_t enb                          : 1;  /**< When ENB=1, instruction input ring i is enabled. */
-	uint64_t pbp_dhi                      : 13; /**< PBP_DHI replaces address bits that are used
-                                                         for parse mode and skip-length when
-                                                         SLI_PKTi_INSTR_HEADER[PBP]=1.
-                                                         PBP_DHI becomes either MACADD<63:55> or MACADD<59:51>
-                                                         for the instruction DPTR reads in this case.
-                                                         The instruction DPTR reads are called
-                                                         "First Direct" or "First Indirect" in the HRM.
-                                                         When PBP=1, if "First Direct" and USE_CSR=0, PBP_DHI
-                                                         becomes MACADD<59:51>, else MACADD<63:55>. */
+	uint64_t enb                          : 1;  /**< Packet output enable. When ENB<i>=1, packet output ring i is enabled.
+                                                         When the ring is in reset, caused by a failing read associated with the ring, the ring
+                                                         being put into
+                                                         reset by writing the reset bit assocaited with a ring, a FLR or the MAC the ring is
+                                                         associated with
+                                                         being in reset, will cause this bit to clear and be able to be set againg till the reset
+                                                         condition is removed. */
+	uint64_t pbp_dhi                      : 13; /**< PBP_DHI replaces address bits that are used for parse mode and skip-length when
+                                                         SLI_PKTi_INSTR_HEADER[PBP] = 1. PBP_DHI becomes either MACADD<63:55> or MACADD<59:51> for
+                                                         the instruction DPTR read operations in this case. The instruction DPTR read operations
+                                                         are called first direct or first indirect. When PBP = 1, if first direct and USE_CSR = 0,
+                                                         PBP_DHI becomes MACADD<59:51>, else MACADD<63:55>. */
 	uint64_t d_nsr                        : 1;  /**< ADDRTYPE<1> or MACADD<61> for packet input data read operations. D_NSR becomes either
                                                          ADDRTYPE<1> or MACADD<61> for MAC memory space read operations of packet input data
                                                          fetched for any packet input ring. ADDRTYPE<1> if USE_CSR = 1, else MACADD<61>. In the
@@ -6006,9 +6008,9 @@ union cvmx_sli_pktx_int_levels {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_54_63               : 10;
 	uint64_t time                         : 22; /**< Output ring counter time interrupt threshold.
-                                                         SLI sets SLI_PKT_TIME_INT[PORT<i>] whenever SLI_PKTi_CNTS[TIMER] > TIME. */
+                                                         SLI sets SLI_PKT_TIME_INT[PORT<i>] whenever SLI_PKT(0..63)_CNTS[TIMER] > TIME. */
 	uint64_t cnt                          : 32; /**< Output ring counter interrupt threshold. SLI sets SLI_PKT_CNT_INT[PORT<i>] whenever
-                                                         SLI_PKTi_CNTS[CNT] > CNT. */
+                                                         SLI_PKT(0..63)_CNTS[CNT] > CNT. */
 #else
 	uint64_t cnt                          : 32;
 	uint64_t time                         : 22;
@@ -6103,8 +6105,13 @@ union cvmx_sli_pktx_output_control {
                                                          becomes ADDRTYPE<0> in DPI/SLI reads that fetch buffer/info pairs from packet output ring
                                                          (from address SLI_PKTx_SLIST_BADDR+ in MAC memory space.) ADDRTYPE<0> is the relaxed-order
                                                          attribute for PCIe. */
-	uint64_t enb                          : 1;  /**< When ENB=1, packet output ring is enabled. If an error occurs on reading pointers or a FLR
-                                                         occurs that the ring belongs to, this bit will be cleared to 0. Also see SLI_PKT_OUT_ENB. */
+	uint64_t enb                          : 1;  /**< Packet input enable. When ENB=1, packet input ring is enabled.
+                                                         When the ring is in reset, caused by a failing read associated with the ring, the ring
+                                                         being put into
+                                                         reset by writing the reset bit assocaited with a ring, a FLR or the MAC the ring is
+                                                         associated with
+                                                         being in reset, will cause this bit to clear and be able to be set againg till the reset
+                                                         condition is removed. */
 #else
 	uint64_t enb                          : 1;
 	uint64_t ror_p                        : 1;
@@ -6243,7 +6250,7 @@ typedef union cvmx_sli_pktx_vf_sig cvmx_sli_pktx_vf_sig_t;
 /**
  * cvmx_sli_pkt_cnt_int
  *
- * The packets rings that are interrupting because of Packet Counters.
+ * This register specifies which packet rings are interrupting because of packet counters.
  *
  */
 union cvmx_sli_pkt_cnt_int {
@@ -6278,7 +6285,7 @@ union cvmx_sli_pkt_cnt_int {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t ring                         : 64; /**< Output ring packet counter interrupt bits
                                                          SLI sets RING<i> whenever
-                                                         SLI_PKTi_CNTS[CNT] > SLI_PKT_INT_LEVELS[CNT].
+                                                         SLI_PKT(0..63)_CNTS[CNT] > SLI_PKT_INT_LEVELS[CNT].
                                                          SLI_PKT_CNT_INT_ENB[RING<i>] is the corresponding
                                                          enable. */
 #else
@@ -6549,9 +6556,9 @@ union cvmx_sli_pkt_in_donex_cnts {
                                                          field clears the corresponding bit in SLI_PKT_IN_INT[RING[\#]]." */
 	uint64_t reserved_49_61               : 13;
 	uint64_t cint_enb                     : 1;  /**< When set, allows corresponding bit in SLI_PKT_IN_INT[RING[\#]] to be set. */
-	uint64_t wmark                        : 16; /**< "When the value of SLI_PKT_IN_DONE#_CNTS[CNT[15:0]] is updated to be equal to
-                                                         SLI_PKT_IN_DONE#_CNTS[WMARK[15:0]] and SLI_PKT_IN_DONE#_CNTS[CINT_ENB] is also set, the
-                                                         corresponding bit in SLI_PKT_IN_INT[RING[\#]] will be set." */
+	uint64_t wmark                        : 16; /**< "When the value of SLI_PKT_IN_DONE(0..63)_CNTS[CNT[15:0]] is updated to be equal to
+                                                         SLI_PKT_IN_DONE(0..63)_CNTS[WMARK[15:0]] and SLI_PKT_IN_DONE(0..63)_CNTS[CINT_ENB] is also
+                                                         set, the corresponding bit in SLI_PKT_IN_INT[RING[\#]] will be set." */
 	uint64_t cnt                          : 32; /**< This field is incrmented by '1' when an instruction
                                                          is completed. This field is incremented as the
                                                          last of the data is read from the MAC. */
@@ -6622,16 +6629,16 @@ typedef union cvmx_sli_pkt_in_instr_counts cvmx_sli_pkt_in_instr_counts_t;
  *
  * When read by a VF, this register informs which rings owned by the VF (0 to 63) have an
  * interrupt pending. In PF mode, this register returns an unpredictable value. Writing 1s to
- * clear this register clears both packet count an packet time interrupts. The clearing of the
+ * clear this register clears both packet count and packet time interrupts. The clearing of the
  * interrupts will be reflected in SLI_PKT_CNT_INT and SLI_PKT_TIME_INT.
  */
 union cvmx_sli_pkt_in_int {
 	uint64_t u64;
 	struct cvmx_sli_pkt_in_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ring                         : 64; /**< "Set when SLI_PKT_IN_DONE#_CNTS[CNT[15:0]] is updated to be equal to
-                                                         SLI_PKT_IN_DONE#_CNTS[WMARK[15:0]] and SLI_PKT_IN_DONE#_CNTS[CINT_ENB] is set. Cleared
-                                                         when SLI_PKT_IN_DONE#_CNTS[PI_INT] is cleared." */
+	uint64_t ring                         : 64; /**< Set when SLI_PKT_IN_DONE(0..63)_CNTS[CNT[15:0]] is updated to be equal to
+                                                         SLI_PKT_IN_DONE(0..63)_CNTS[WMARK[15:0]] and SLI_PKT_IN_DONE(0..63)_CNTS[CINT_ENB] is set.
+                                                         Cleared when SLI_PKT_IN_DONE(0..63)_CNTS[PI_INT] is cleared. */
 #else
 	uint64_t ring                         : 64;
 #endif
@@ -6865,8 +6872,9 @@ typedef union cvmx_sli_pkt_input_control cvmx_sli_pkt_input_control_t;
 /**
  * cvmx_sli_pkt_instr_enb
  *
- * "This register enables the instruction fetch for a packet ring. This is the PF version also
- * see SLI_PKT#_INPUT_CONTROL[ENB]."
+ * ""This register enables the instruction fetch for a packet ring. This is the PF version also
+ * see SLI_PKT#_INPUT_CONTROL[ENB]." The bit cooresponding to the ring in reset will be
+ * cleared."
  */
 union cvmx_sli_pkt_instr_enb {
 	uint64_t u64;
@@ -6967,7 +6975,7 @@ typedef union cvmx_sli_pkt_instr_size cvmx_sli_pkt_instr_size_t;
  *
  * When read by a VF, this register informs which rings owned by the VF (0 to 63) have an
  * interrupt pending. In PF mode, this register returns an unpredictable value. Writing 1s to
- * clear this register clears both packet count an packet time interrupts. The clearing of the
+ * clear this register clears both packet count and packet time interrupts. The clearing of the
  * interrupts will be reflected in SLI_PKT_CNT_INT and SLI_PKT_TIME_INT.
  */
 union cvmx_sli_pkt_int {
@@ -7181,8 +7189,8 @@ union cvmx_sli_pkt_mem_ctl {
 	uint64_t pop1_ecc                     : 1;  /**< When set Packet Out Pointer memory1 will have an ECC not generated and checked. */
 	uint64_t pop0_fs                      : 2;  /**< Used to flip the synd for packet-out-pointer memory0. */
 	uint64_t pop0_ecc                     : 1;  /**< When set packet-out-pointer memory0 will have an ECC not generated and checked. */
-	uint64_t pfp_fs                       : 2;  /**< Used to flip the synd for packet-out-pointer memory. */
-	uint64_t pfp_ecc                      : 1;  /**< When set packet-out-pointer memory will have an ECC not generated and checked. */
+	uint64_t pfp_fs                       : 2;  /**< Reserved. INTERNAL: Placeholder. ECC not implemented due to critical path. */
+	uint64_t pfp_ecc                      : 1;  /**< Reserved. INTERNAL: Placeholder. ECC not implemented due to critical path. */
 	uint64_t pbn_fs                       : 2;  /**< Used to flip the synd for pointer-base-number memory. */
 	uint64_t pbn_ecc                      : 1;  /**< When set pointer-base-number memory will have an ECC not generated and checked. */
 	uint64_t pdf_fs                       : 2;  /**< Used to flip the synd for packet-data-info memory. */
@@ -7190,7 +7198,7 @@ union cvmx_sli_pkt_mem_ctl {
 	uint64_t psf_fs                       : 2;  /**< Used to flip the synd for PSF memory. */
 	uint64_t psf_ecc                      : 1;  /**< When set PSF memory will have an ECC not generated and checked. */
 	uint64_t poi_fs                       : 2;  /**< Used to flip the synd for packet-out-info memory. */
-	uint64_t poi_ecc                      : 1;  /**< When set Packet Out Info memory will have an ECC not generated and checked. */
+	uint64_t poi_ecc                      : 1;  /**< When set packet-out-info memory will have an ECC not generated and checked. */
 #else
 	uint64_t poi_ecc                      : 1;
 	uint64_t poi_fs                       : 2;
@@ -7296,8 +7304,8 @@ typedef union cvmx_sli_pkt_out_bp_en cvmx_sli_pkt_out_bp_en_t;
 /**
  * cvmx_sli_pkt_out_enb
  *
- * "This register enables the output packet engines. This is the PF version. Also see
- * SLI_PKT#_OUTPUT_CONTROL[ENB]."
+ * "This register enables the output packet engines.  This is the PF version. Also see
+ * SLI_PKT#_INPUT_CONTROL[ENB]. The bit corresponding to the ring in reset will be cleared."
  */
 union cvmx_sli_pkt_out_enb {
 	uint64_t u64;
@@ -7550,7 +7558,7 @@ typedef union cvmx_sli_pkt_slist_ror cvmx_sli_pkt_slist_ror_t;
 /**
  * cvmx_sli_pkt_time_int
  *
- * The packets rings that are interrupting because of Packet Timers.
+ * This register specifies which packets' rings are interrupting because of packet timers.
  *
  */
 union cvmx_sli_pkt_time_int {
@@ -7583,11 +7591,9 @@ union cvmx_sli_pkt_time_int {
 	struct cvmx_sli_pkt_time_int_cn61xx   cn70xx;
 	struct cvmx_sli_pkt_time_int_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ring                         : 64; /**< Output ring packet timer interrupt bits
-                                                         SLI sets RING<i> whenever
-                                                         SLI_PKTi_CNTS[TIMER] > SLI_PKT_INT_LEVELS[TIME].
-                                                         SLI_PKT_TIME_INT_ENB[RING<i>] is the corresponding
-                                                         enable. */
+	uint64_t ring                         : 64; /**< Output ring packet timer interrupt bits SLI sets RING<i> whenever
+                                                         SLI_PKT(0..63)_CNTS[TIMER] >
+                                                         SLI_PKT_INT_LEVELS[TIME]. SLI_PKT_TIME_INT_ENB[RING<i>] is the corresponding enable. */
 #else
 	uint64_t ring                         : 64;
 #endif
@@ -7693,7 +7699,7 @@ typedef union cvmx_sli_portx_pkind cvmx_sli_portx_pkind_t;
  * cvmx_sli_s2m_port#_ctl
  *
  * These registers contain control for access from SLI to a MAC port. Write operations to these
- * register are not ordered with write/read operations to the MAC Memory space. To ensure that a
+ * registers are not ordered with write/read operations to the MAC Memory space. To ensure that a
  * write operation has completed, read the register before making an access (i.e. MAC memory
  * space) that requires the value of this register to be updated.
  */
@@ -7775,15 +7781,15 @@ union cvmx_sli_s2m_portx_ctl {
 	uint64_t wind_d                       : 1;  /**< Window disable. When set to 1, disables access to the window registers from the MAC port. */
 	uint64_t bar0_d                       : 1;  /**< BAR0 disable. When set to 1, disables access from the MAC to BAR0 for the following
                                                          address offsets:
-                                                         0x0-0x32F
-                                                         0x3CD0
-                                                         greater than 0x3D70, excluding 0x3E00. */
+                                                         * 0x0-0x32F
+                                                         * 0x3CD0
+                                                         * greater than 0x3D70, excluding 0x3E00. */
 	uint64_t ld_cmd                       : 2;  /**< When SLI issues a load command to the L2C that is to be cached, this field selects the
                                                          type of load command to use:
-                                                         0 = LDD.
-                                                         1 = LDI.
-                                                         2 = LDE.
-                                                         3 = LDY. */
+                                                         0x0 = LDD.
+                                                         0x1 = LDI.
+                                                         0x2 = LDE.
+                                                         0x3 = LDY. */
 	uint64_t reserved_0_0                 : 1;
 #else
 	uint64_t reserved_0_0                 : 1;
@@ -7994,7 +8000,7 @@ union cvmx_sli_state3 {
 	uint64_t psm1                         : 15; /**< PSM1 state. */
 	uint64_t psm0                         : 15; /**< PSM0 state. */
 	uint64_t nsm1                         : 15; /**< NSM1 state. */
-	uint64_t nsm0                         : 15; /**< NSM0 State */
+	uint64_t nsm0                         : 15; /**< NSM0 state. */
 #else
 	uint64_t nsm0                         : 15;
 	uint64_t nsm1                         : 15;
@@ -8058,6 +8064,8 @@ typedef union cvmx_sli_tx_pipe cvmx_sli_tx_pipe_t;
  *
  * This register contains the address to be read when the SLI_WIN_RD_DATA register is read. This
  * register should NOT be used to read SLI_* registers.
+ * If SLI_S2M_PORT(0..3)_CTL[LCL_NODE] the MAC that it is set for will not be able to write
+ * RD_ADDR[37:36] which will always be written with the chips OCI-ID.
  */
 union cvmx_sli_win_rd_addr {
 	uint64_t u64;
@@ -8134,6 +8142,8 @@ typedef union cvmx_sli_win_rd_data cvmx_sli_win_rd_data_t;
  * Contains the address to be writen to when a write operation is started by writing the
  * SLI_WIN_WR_DATA register (see below).
  * This register should NOT be used to write SLI_* registers.
+ * If SLI_S2M_PORT(0..3)_CTL[LCL_NODE] the MAC that it is set for will not be able to write
+ * WR_ADDR[37:36] which will always be written with the chips OCI-ID.
  */
 union cvmx_sli_win_wr_addr {
 	uint64_t u64;
@@ -8203,7 +8213,7 @@ typedef union cvmx_sli_win_wr_data cvmx_sli_win_wr_data_t;
 /**
  * cvmx_sli_win_wr_mask
  *
- * This register contains the mask for the data in the SLI_WIN_WR_DATA Register.
+ * This register contains the mask for the data in the SLI_WIN_WR_DATA register.
  *
  */
 union cvmx_sli_win_wr_mask {
@@ -8243,10 +8253,9 @@ union cvmx_sli_window_ctl {
 	uint64_t u64;
 	struct cvmx_sli_window_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ocx_time                     : 32; /**< When a command acknowledge or a request to fetch read-data is expected from the OCI, The
-                                                         SLI will
-                                                         wait this many sclks before determining the OCI is not going to respond and timeout the
-                                                         request. */
+	uint64_t ocx_time                     : 32; /**< OCX time. When a command acknowledge or a request to fetch read data is expected from OCI,
+                                                         SLI waits this many SCLKs before determining that the OCI is not going to respond and
+                                                         timeout the request. */
 	uint64_t time                         : 32; /**< Time to wait in core clocks for a
                                                          BAR0 access to completeon the NCB
                                                          before timing out. A value of 0 will cause no
diff --git a/arch/mips/include/asm/octeon/cvmx-sso-defs.h b/arch/mips/include/asm/octeon/cvmx-sso-defs.h
index 7778474..c4b1e73 100644
--- a/arch/mips/include/asm/octeon/cvmx-sso-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sso-defs.h
@@ -2445,19 +2445,19 @@ union cvmx_sso_grpx_int {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t exe_dis                      : 1;  /**< Executable interrupt temporary disable. Corresponding [EXE_INT] bit cannot be set due to
                                                          IAQ_CNT/IAQ_THR check when this bit is set. EXE_DIS is cleared by hardware whenever:
-                                                         SSO_GRP(0..255)_INT_CNT[IAQ_CNT] is zero, or
-                                                         SSO_GRP(0..255)_INT_CNT[TC_CNT] is equal to 1 when periodic counter SSO_WQ_INT_PC[PC] is
+                                                         * SSO_GRP(0..255)_INT_CNT[IAQ_CNT] is zero, or
+                                                         * SSO_GRP(0..255)_INT_CNT[TC_CNT] is equal to 1 when periodic counter SSO_WQ_INT_PC[PC] is
                                                          equal to 0. */
 	uint64_t reserved_2_62                : 61;
 	uint64_t exe_int                      : 1;  /**< Work-executable interrupt. Generally used to indicate work is waiting for software. Throws
                                                          SSO_INTSN_E::SSO_GRP(0..255)_EXE. Set by hardware whenever:
-                                                         SSO_GRP(0..255)_INT_CNT[IAQ_CNT] >= SSO_GRP(0..255)_INT_THR [IAQ_THR] and [IAQ_THR] != 0
+                                                         * SSO_GRP(0..255)_INT_CNT[IAQ_CNT] >= SSO_GRP(0..255)_INT_THR [IAQ_THR] and [IAQ_THR] != 0
                                                          and EXE_DIS is clear.
-                                                         SSO_GRP(0..255)_INT_CNT[DS_CNT] >= SSO_GRP(0..255)_INT_THR[DS_THR] and [DS_THR] != 0 and
+                                                         * SSO_GRP(0..255)_INT_CNT[DS_CNT] >= SSO_GRP(0..255)_INT_THR[DS_THR] and [DS_THR] != 0 and
                                                          EXE_DIS is clear.
-                                                         SSO_GRP(0..255)_INT_CNT[CQ_CNT] >= SSO_GRP(0..255)_INT_THR[CQ_THR] and [CQ_THR] != 0 and
+                                                         * SSO_GRP(0..255)_INT_CNT[CQ_CNT] >= SSO_GRP(0..255)_INT_THR[CQ_THR] and [CQ_THR] != 0 and
                                                          EXE_DIS is clear.
-                                                         SSO_GRP(0..255)_INT_CNT[TC_CNT] is equal to 1 when periodic counter SSO_WQ_INT_PC[PC] is
+                                                         * SSO_GRP(0..255)_INT_CNT[TC_CNT] is equal to 1 when periodic counter SSO_WQ_INT_PC[PC] is
                                                          equal to 0 and SSO_GRP(0..255)_INT_THR[TC_EN] is set and at least one of the following is
                                                          true:
                                                          SSO_GRP(0..255)_INT_CNT[IAQ_CNT] > 0
@@ -2490,11 +2490,11 @@ union cvmx_sso_grpx_int_cnt {
 	uint64_t reserved_61_63               : 3;
 	uint64_t tc_cnt                       : 13; /**< Time counter current value for this group. Hardware sets this field to the value of
                                                          SSO_GRP(0..255)_INT_THR[TC_THR] whenever:
-                                                         Corresponding SSO_GRP(0..255)_INT_CNT[IAQ_CNT, DS_CNT and CQ_CNT] are all equal to 0.
-                                                         Corresponding SSO_GRP(0..255)_INT[EXE_INT] is written with a one to clear by software.
-                                                         Corresponding SSO_GRP(0..255)_INT[EXE_DIS] is written with a one to clear by software.
-                                                         Corresponding SSO_GRP(0..255)_INT_THR is written by software.
-                                                         TC_CNT is equal to 1 and periodic counter SSO_WQ_INT_PC[PC] is equal to 0.
+                                                         * Corresponding SSO_GRP(0..255)_INT_CNT[IAQ_CNT, DS_CNT and CQ_CNT] are all equal to 0.
+                                                         * Corresponding SSO_GRP(0..255)_INT[EXE_INT] is written with a one to clear by software.
+                                                         * Corresponding SSO_GRP(0..255)_INT[EXE_DIS] is written with a one to clear by software.
+                                                         * Corresponding SSO_GRP(0..255)_INT_THR is written by software.
+                                                         * TC_CNT is equal to 1 and periodic counter SSO_WQ_INT_PC[PC] is equal to 0.
                                                          Otherwise, hardware decrements this field whenever the periodic counter SSO_WQ_INT_PC[PC]
                                                          is equal to 0. This field is 0 whenever SSO_GRP(0..255)_INT_THR[TC_THR] is equal to 0. */
 	uint64_t reserved_45_47               : 3;
@@ -2602,8 +2602,8 @@ union cvmx_sso_grpx_pri {
 	uint64_t reserved_3_7                 : 5;
 	uint64_t pri                          : 3;  /**< Priority for this group relative to other groups. To prevent a core from receiving work on
                                                          a group use SSO_PP(0..47)_S(0..1)_GRPMSK(0..3).
-                                                         0x0: highest priority.
-                                                         0x7: lowest priority.
+                                                         0x0 = highest priority.
+                                                         0x7 = lowest priority.
                                                          Changing priority while GET_WORKs are in flight may result in a GET_WORK using either the
                                                          old or new priority, or a mix thereof. */
 #else
@@ -2942,7 +2942,7 @@ union cvmx_sso_ientx_pendtag {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_38_63               : 26;
 	uint64_t pend_switch                  : 1;  /**< Set when there is a pending non-UNTAGGED SWTAG or SWTAG_FULL and the SSO entry has not
-                                                         left the list for the original tag */
+                                                         left the list for the original tag. */
 	uint64_t reserved_34_36               : 3;
 	uint64_t pend_tt                      : 2;  /**< The next tag type for the new tag list when PEND_SWITCH is set. Enumerated by SSO_TT_E. */
 	uint64_t pend_tag                     : 32; /**< The next tag for the new tag list when PEND_SWITCH is set. */
@@ -3822,7 +3822,7 @@ union cvmx_sso_reset {
                                                          structures are initialized. This bit must read as zero before any configuration may be
                                                          done. */
 	uint64_t reserved_1_62                : 62;
-	uint64_t reset                        : 1;  /**< Reset the SSO */
+	uint64_t reset                        : 1;  /**< Reset the SSO. */
 #else
 	uint64_t reset                        : 1;
 	uint64_t reserved_1_62                : 62;
@@ -4654,7 +4654,8 @@ union cvmx_sso_ws_cfg {
                                                          <50> Work-slot CAM access. (arbc.)
                                                          <49> Work-slot RAM access. (arbr.)
                                                          <48> Work-slot pushes to AQ, CQ, DQ. (arbq.) */
-	uint64_t reserved_4_47                : 44;
+	uint64_t reserved_5_47                : 43;
+	uint64_t disable_pw                   : 1;  /**< Disable PREP_WORK operations and treat as a NOP. For diagnostic use only. */
 	uint64_t arbc_step_en                 : 1;  /**< Enable single-stepping WS CAM arbiter, twice per 16 clocks. For diagnostic use only. */
 	uint64_t ncbo_step_en                 : 1;  /**< Enable single-stepping commands from NCBO, once per 32 clocks. For diagnostic use only. */
 	uint64_t soc_ccam_dis                 : 1;  /**< Disable power saving SOC conditional CAM. */
@@ -4664,7 +4665,8 @@ union cvmx_sso_ws_cfg {
 	uint64_t soc_ccam_dis                 : 1;
 	uint64_t ncbo_step_en                 : 1;
 	uint64_t arbc_step_en                 : 1;
-	uint64_t reserved_4_47                : 44;
+	uint64_t disable_pw                   : 1;
+	uint64_t reserved_5_47                : 43;
 	uint64_t ocla_bp                      : 8;
 	uint64_t reserved_56_63               : 8;
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-uart.h b/arch/mips/include/asm/octeon/cvmx-uart.h
index 27a30d9..ae049d3 100644
--- a/arch/mips/include/asm/octeon/cvmx-uart.h
+++ b/arch/mips/include/asm/octeon/cvmx-uart.h
@@ -42,7 +42,7 @@
  *
  * interface to the serial port UART hardware
  *
- * <hr>$Revision: 73845 $<hr>
+ * <hr>$Revision: 88249 $<hr>
  *
  */
 
@@ -61,7 +61,7 @@ extern "C" {
 
 /* CSR typedefs have been moved to cvmx-uart-defs.h */
 
-typedef void (*cvmx_uart_intr_handler_t) (int, uint64_t[], void *);
+typedef void (*cvmx_uart_intr_handler_t) (int, uint64_t[]);
 
 extern void cvmx_uart_enable_intr(int, cvmx_uart_intr_handler_t);
 extern int cvmx_uart_setup2(int, int, int);
diff --git a/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h b/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
index 82342a7..14a0b9a 100644
--- a/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
@@ -675,7 +675,7 @@ union cvmx_uctlx_ctl {
                                                          must enable this feature.
                                                          This value may only be changed during UPHY_RST. */
 	uint64_t ssc_range                    : 3;  /**< Spread-spectrum clock range. Selects the range of spread-spectrum modulation when SSC_EN
-                                                         is asserted and the PHY is spreading the SuperSpeed transmit clocks.
+                                                         is asserted and the PHY is spreading the SS transmit clocks.
                                                          Applies a fixed offset to the phase accumulator.
                                                          0x0 = -4980 ppm downspread of clock
                                                          0x1 = -4492 ppm
@@ -707,11 +707,11 @@ union cvmx_uctlx_ctl {
 	uint64_t ref_clk_fsel                 : 6;  /**< Selects the reference clock frequency for the SuperSpeed and HighSpeed PLL blocks. The
                                                          legal values are as follows:
                                                          0x27 = External reference clock 100 MHz
-                                                         0x2A = External reference clock 24 MHz
-                                                         0x31 = External reference clock 20 MHz
-                                                         0x38 = External reference clock 19.2 MHz
                                                          All other values are reserved.
-                                                         This value may only be changed during UPHY_RST. */
+                                                         This value may only be changed during UPHY_RST.
+                                                         INTERNAL: 0x2A = External reference clock 24 MHz
+                                                                   0x31 = External reference clock 20 MHz
+                                                                   0x38 = External reference clock 19.2 MHz */
 	uint64_t reserved_31_31               : 1;
 	uint64_t h_clk_en                     : 1;  /**< Host-controller-clock enable. When set to 1, the host-controller clock is generated. This
                                                          also enables access to UCTL registers 0x30-0xF8. */
@@ -757,26 +757,26 @@ union cvmx_uctlx_ctl {
 	uint64_t usb2_port_perm_attach        : 1;  /**< Indicates this port is permanently attached. This is a strap signal; it should be modified
                                                          only when UPHY_RST is asserted. */
 	uint64_t reserved_19_19               : 1;
-	uint64_t usb3_port_disable            : 1;  /**< Disables the USB3 (SuperSpeed) portion of this PHY. When set to 1, this signal stops
-                                                         reporting connect/disconnect events on the port and keeps the port in disabled state. This
-                                                         could be used for security reasons where hardware can disable a port regardless of whether
-                                                         xHCI driver enables a port or not.
+	uint64_t usb3_port_disable            : 1;  /**< Disables the USB3 (SS) portion of this PHY. When set to 1, this signal stops reporting
+                                                         connect/disconnect events on the port and keeps the port in disabled state. This could be
+                                                         used for security reasons where hardware can disable a port regardless of whether xHCI
+                                                         driver enables a port or not.
                                                          UAHC(0)_HCSPARAMS1[MAXPORTS] is not affected by this signal.
                                                          This is a strap signal; it should be modified only when UPHY_RST is asserted. */
 	uint64_t reserved_17_17               : 1;
-	uint64_t usb2_port_disable            : 1;  /**< Disables USB2 (HighSpeed/FullSpeed/LowSpeed) portion of this PHY. When set to 1, this
-                                                         signal stops reporting connect/disconnect events on the port and keeps the port in
-                                                         disabled state. This could be used for security reasons where hardware can disable a port
-                                                         regardless of whether xHCI driver enables a port or not.
+	uint64_t usb2_port_disable            : 1;  /**< Disables USB2 (HS/FS/LS) portion of this PHY. When set to 1, this signal stops reporting
+                                                         connect/disconnect events on the port and keeps the port in disabled state. This could be
+                                                         used for security reasons where hardware can disable a port regardless of whether xHCI
+                                                         driver enables a port or not.
                                                          UAHC(0)_HCSPARAMS1[MAXPORTS] is not affected by this signal.
                                                          This is a strap signal; it should only be modified when UPHY_RST is asserted.
                                                          If Port0 is required to be disabled, ensure that the utmi_clk[0] is running at the normal
                                                          speed. Also, all the enabled USB2.0 ports should have the same clock frequency as Port0. */
 	uint64_t reserved_15_15               : 1;
-	uint64_t ss_power_en                  : 1;  /**< PHY SuperSpeed block power enable.
+	uint64_t ss_power_en                  : 1;  /**< PHY SS block power enable.
                                                          This is a strap signal; it should only be modified when UPHY_RST is asserted. */
 	uint64_t reserved_13_13               : 1;
-	uint64_t hs_power_en                  : 1;  /**< PHY HighSpeed block power enable
+	uint64_t hs_power_en                  : 1;  /**< PHY HS block power enable.
                                                          This is a strap signal; it should only be modified when UPHY_RST is asserted. */
 	uint64_t reserved_5_11                : 7;
 	uint64_t csclk_en                     : 1;  /**< Turns on the USB UCTL interface clock (coprocessor clock). This enables access to UAHC
@@ -840,13 +840,14 @@ typedef union cvmx_uctlx_ctl cvmx_uctlx_ctl_t;
  * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
  * This register can be used to disable ECC correction, insert ECC errors, and debug ECC
  * failures.
- * The ECC_ERR* fields are captured when there are no outstanding ECC errors indicated in INTSTAT
- * and a new ECC error arrives. Prioritization for multiple events occurring on the same cycle is
- * indicated by the ECC_ERR_SOURCE enumeration: highest encoded value has highest priority.
- * The *ECC_*_DIS fields disable ECC correction; SBE and DBE errors are still reported. If
+ * * The ECC_ERR* fields are captured when there are no outstanding ECC errors indicated in
+ * INTSTAT and a new ECC error arrives. Prioritization for multiple events occurring on the same
+ * cycle is indicated by the ECC_ERR_SOURCE enumeration: highest encoded value has highest
+ * priority.
+ * * The *ECC_*_DIS fields disable ECC correction; SBE and DBE errors are still reported. If
  * *ECC_*_DIS = 0x1, then no data-correction occurs.
- * The *ECC_FLIP_SYND fields flip the syndrome<1:0> bits to generate single-bit/double-bit error
- * for testing.
+ * * The *ECC_FLIP_SYND fields flip the syndrome<1:0> bits to generate single-bit/double-bit
+ * error for testing.
  * 0x0 = normal operation
  * 0x1 = SBE on bit[0]
  * 0x2 = SBE on bit[1]
@@ -1065,13 +1066,13 @@ union cvmx_uctlx_host_cfg {
 	uint64_t host_current_belt            : 12; /**< This signal indicates the minimum value of all received BELT values and the BELT that is
                                                          set by the Set LTV command. */
 	uint64_t reserved_38_47               : 10;
-	uint64_t fla                          : 6;  /**< HighSpeed jitter adjustment. Indicates the correction required to accommodate mac3 clock
-                                                         and utmi clock jitter to measure 125us duration. With FLA tied to 0x0, the HighSpeed
+	uint64_t fla                          : 6;  /**< High-speed jitter adjustment. Indicates the correction required to accommodate mac3 clock
+                                                         and utmi clock jitter to measure 125us duration. With FLA tied to 0x0, the high speed
                                                          125us micro-frame is counted for 123933ns. The value needs to be programmed in terms of
-                                                         HighSpeed bit times in a 30 MHz cycle. Default value that needs to be driven is 0x20
+                                                         high-speed bit times in a 30 MHz cycle. Default value that needs to be driven is 0x20
                                                          (assuming 30 MHz perfect clock).
                                                          FLA connects to the FLADJ register defined in the xHCI spec in the PCI configuration
-                                                         space. Each count is equal to 16 HighSpeed bit times. By default when this register is
+                                                         space. Each count is equal to 16 high-speed bit times. By default when this register is
                                                          set to 0x20, it gives 125us interval. Now, based on the clock accuracy, you can decrement
                                                          the count or increment the count to get the 125 us uSOF window.
                                                          This is a strap signal; it should only be modified when UAHC is in reset (soft-reset
@@ -1426,36 +1427,35 @@ union cvmx_uctlx_portx_cfg_hs {
                                                          threshold voltage level, while a negative binary bit setting change results in a -1.5%
                                                          incremental change in the threshold voltage level. */
 	uint64_t sq_rx_tune                   : 3;  /**< Squelch threshold adjustment. Adjusts the voltage level for the threshold used to detect
-                                                         valid HighSpeed data.
+                                                         valid HS data.
                                                          A positive binary bit setting change results in a -5% incremental change in threshold
                                                          voltage level, while a negative binary bit setting change results in a +5% incremental
                                                          change in threshold voltage level. */
-	uint64_t tx_fsls_tune                 : 4;  /**< FullSpeed/LowSpeed source impedance adjustment. Adjusts the LowSpeed and FullSpeed single-
-                                                         ended source
+	uint64_t tx_fsls_tune                 : 4;  /**< LS/FS source impedance adjustment. Adjusts the low- and full-speed single-ended source
                                                          impedance while driving high. This parameter control is encoded in thermometer code.
                                                          A positive thermometer code change results in a -2.5% incremental change in source
                                                          impedance. A negative thermometer code change results in +2.5% incremental change in
                                                          source impedance. Any non-thermometer code setting (that is, 0x9) is not supported and
                                                          reserved. */
 	uint64_t reserved_46_47               : 2;
-	uint64_t tx_hs_xv_tune                : 2;  /**< Transmitter HighSpeed crossover adjustment. This bus adjusts the voltage at which the DP0
-                                                         and DM0 signals cross while transmitting in HighSpeed mode.
+	uint64_t tx_hs_xv_tune                : 2;  /**< Transmitter high-speed crossover adjustment. This bus adjusts the voltage at which the DP0
+                                                         and DM0 signals cross while transmitting in HS mode.
                                                          11 = default setting
                                                          10 = +15 mV
                                                          01 = -15 mV
                                                          00 = reserved */
-	uint64_t tx_preemp_amp_tune           : 2;  /**< HighSpeed transmitter pre-emphasis current control. Controls the amount of current
-                                                         sourced to DP0 and DM0 after a J-to-K or K-to-J transition. The HighSpeed transmitter
+	uint64_t tx_preemp_amp_tune           : 2;  /**< High-speed transmitter pre-emphasis current control. Controls the amount of current
+                                                         sourced to DP0 and DM0 after a J-to-K or K-to-J transition. The high-speed transmitter
                                                          pre-emphasis current is defined in terms of unit amounts. One unit amount is approximately
                                                          600 A and is defined as 1* pre-emphasis current.
-                                                         0x3 = HighSpeed TX pre-emphasis circuit sources 3* pre-emphasis current.
-                                                         0x2 = HighSpeed TX pre-emphasis circuit sources 2* pre-emphasis current.
-                                                         0x1 = HighSpeed TX pre-emphasis circuit sources 1* pre-emphasis current.
-                                                         0x0 = HighSpeed TX pre-emphasis is disabled.
+                                                         0x3 = high-speed TX pre-emphasis circuit sources 3* pre-emphasis current.
+                                                         0x2 = high-speed TX pre-emphasis circuit sources 2* pre-emphasis current.
+                                                         0x1 = high-speed TX pre-emphasis circuit sources 1* pre-emphasis current.
+                                                         0x0 = high-speed TX pre-emphasis is disabled (design default).
                                                          If these signals are not used, set them to 0x0. */
 	uint64_t reserved_41_41               : 1;
-	uint64_t tx_preemp_pulse_tune         : 1;  /**< HighSpeed transmitter pre-emphasis duration control. Controls the duration for which the
-                                                         HighSpeed pre-emphasis current is sourced onto DP0 or DM0. The HighSpeed transmitter
+	uint64_t tx_preemp_pulse_tune         : 1;  /**< High-speed transmitter pre-emphasis duration control. Controls the duration for which the
+                                                         high-speed pre-emphasis current is sourced onto DP0 or DM0. The high-speed transmitter
                                                          pre-emphasis duration is defined in terms of unit amounts. One unit of pre-emphasis
                                                          duration is approximately 580 ps and is defined as 1* pre-emphasis duration. This signal
                                                          is valid only if either TX_PREEMP_AMP_TUNE0[1] or TX_PREEMP_AMP_TUNE0[0] is set to 1.
@@ -1472,12 +1472,12 @@ union cvmx_uctlx_portx_cfg_hs {
                                                          Any setting other than the default can result in source-impedance variation across
                                                          process, voltage, and temperature conditions that does not meet USB 2.0 specification
                                                          limits. If this bus is not used, leave it at the default setting. */
-	uint64_t tx_rise_tune                 : 2;  /**< HighSpeed transmitter rise-/fall-time adjustment. Adjusts the rise/fall times of the
-                                                         HighSpeed waveform. A positive binary bit setting change results in a -4% incremental
-                                                         change in the HighSpeed rise/fall time. A negative binary bit setting change results in a
-                                                         +4% incremental change in the HighSpeed rise/fall time. */
-	uint64_t tx_vref_tune                 : 4;  /**< HighSpeed DC voltage-level adjustment. Adjusts the HighSpeed DC level voltage.
-                                                         A positive binary bit setting change results in a +1.25% incremental change in HighSpeed
+	uint64_t tx_rise_tune                 : 2;  /**< HS transmitter rise-/fall-time adjustment. Adjusts the rise/fall times of the high-speed
+                                                         waveform. A positive binary bit setting change results in a -4% incremental change in the
+                                                         high-speed rise/fall time. A negative binary bit setting change results in a +4%
+                                                         incremental change in the HS rise/fall time. */
+	uint64_t tx_vref_tune                 : 4;  /**< High-speed DC voltage-level adjustment. Adjusts the high-speed DC level voltage.
+                                                         A positive binary bit setting change results in a +1.25% incremental change in high-speed
                                                          DC voltage level, while a negative binary bit setting change results in a -1.25%
                                                          incremental change in HighSpeed DC voltage level.
                                                          The default bit setting is intended to create a HighSpeed transmit
@@ -1488,7 +1488,7 @@ union cvmx_uctlx_portx_cfg_hs {
                                                          0x1 = test functionality enabled
                                                          0x2, 0x3 = reserved, invalid settings
                                                          See also the PHY databook for details on how to select which analog test voltage. */
-	uint64_t loopback_enable              : 1;  /**< Places the HighSpeed PHY in loopback mode, which concurrently enables HighSpeed receive
+	uint64_t loopback_enable              : 1;  /**< Places the high-speed PHY in loopback mode, which concurrently enables high-speed receive
                                                          and transmit logic. */
 	uint64_t atereset                     : 1;  /**< Per-PHY ATE reset. When the USB core is powered up (not in suspend mode), an automatic
                                                          tester can use this to disable PHYCLOCK and FREECLK, then re-enable them with an aligned
diff --git a/arch/mips/include/asm/octeon/cvmx-wqe.h b/arch/mips/include/asm/octeon/cvmx-wqe.h
index 78ef554..1cb63c1 100644
--- a/arch/mips/include/asm/octeon/cvmx-wqe.h
+++ b/arch/mips/include/asm/octeon/cvmx-wqe.h
@@ -51,7 +51,7 @@
  * This file must not depend on any other header files, except for cvmx.h!!!
  *
  *
- * <hr>$Revision: 83293 $<hr>
+ * <hr>$Revision: 94735 $<hr>
  *
  *
  */
@@ -59,6 +59,10 @@
 #ifndef __CVMX_WQE_H__
 #define __CVMX_WQE_H__
 
+#include "cvmx-fpa.h"
+#include "cvmx-pki-defs.h"
+#include "cvmx-pip-defs.h"
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 extern "C" {
@@ -70,6 +74,81 @@ extern "C" {
                                 (((x) == CVMX_POW_TAG_TYPE_NULL) ?  "NULL" : \
                                 "NULL_NULL")))
 
+/* Error levels in WQE entry word2 */
+#define PKI_ERRLEV_E__RE_M                                 (0x0)
+#define PKI_ERRLEV_E__LA_M                                 (0x1)
+#define PKI_ERRLEV_E__LB_M                                 (0x2)
+#define PKI_ERRLEV_E__LC_M                                 (0x3)
+#define PKI_ERRLEV_E__LD_M                                 (0x4)
+#define PKI_ERRLEV_E__LE_M                                 (0x5)
+#define PKI_ERRLEV_E__LF_M                                 (0x6)
+#define PKI_ERRLEV_E__LG_M                                 (0x7)
+
+enum cvmx_pki_errlevel {
+	CVMX_PKI_ERRLEV_E_RE                         = PKI_ERRLEV_E__RE_M,
+	CVMX_PKI_ERRLEV_E_LA                         = PKI_ERRLEV_E__LA_M,
+	CVMX_PKI_ERRLEV_E_LB                         = PKI_ERRLEV_E__LB_M,
+	CVMX_PKI_ERRLEV_E_LC                         = PKI_ERRLEV_E__LC_M,
+	CVMX_PKI_ERRLEV_E_LD                         = PKI_ERRLEV_E__LD_M,
+	CVMX_PKI_ERRLEV_E_LE                         = PKI_ERRLEV_E__LE_M,
+	CVMX_PKI_ERRLEV_E_LF                         = PKI_ERRLEV_E__LF_M,
+	CVMX_PKI_ERRLEV_E_LG                         = PKI_ERRLEV_E__LG_M
+};
+
+/* Layer types in pki */
+#define CVMX_PKI_LTYPE_E_NONE_M                                (0x0)
+#define CVMX_PKI_LTYPE_E_ENET_M                                (0x1)
+#define CVMX_PKI_LTYPE_E_VLAN_M                                (0x2)
+#define CVMX_PKI_LTYPE_E_SNAP_PAYLD_M                          (0x5)
+#define CVMX_PKI_LTYPE_E_ARP_M                                 (0x6)
+#define CVMX_PKI_LTYPE_E_RARP_M                                (0x7)
+#define CVMX_PKI_LTYPE_E_IP4_M                                 (0x8)
+#define CVMX_PKI_LTYPE_E_IP4_OPT_M                             (0x9)
+#define CVMX_PKI_LTYPE_E_IP6_M                                 (0xA)
+#define CVMX_PKI_LTYPE_E_IP6_OPT_M                             (0xB)
+#define CVMX_PKI_LTYPE_E_IPSEC_ESP_M                           (0xC)
+#define CVMX_PKI_LTYPE_E_IPFRAG_M                              (0xD)
+#define CVMX_PKI_LTYPE_E_IPCOMP_M                              (0xE)
+#define CVMX_PKI_LTYPE_E_TCP_M                                 (0x10)
+#define CVMX_PKI_LTYPE_E_UDP_M                                 (0x11)
+#define CVMX_PKI_LTYPE_E_SCTP_M                                (0x12)
+#define CVMX_PKI_LTYPE_E_UDP_VXLAN_M                           (0x13)
+#define CVMX_PKI_LTYPE_E_GRE_M                                 (0x14)
+#define CVMX_PKI_LTYPE_E_NVGRE_M                               (0x15)
+#define CVMX_PKI_LTYPE_E_GTP_M                                 (0x16)
+#define CVMX_PKI_LTYPE_E_SW28_M                                (0x1C)
+#define CVMX_PKI_LTYPE_E_SW29_M                                (0x1D)
+#define CVMX_PKI_LTYPE_E_SW30_M                                (0x1E)
+#define CVMX_PKI_LTYPE_E_SW31_M                                (0x1F)
+
+enum cvmx_pki_layer_type {
+	CVMX_PKI_LTYPE_E_NONE                        = CVMX_PKI_LTYPE_E_NONE_M,
+	CVMX_PKI_LTYPE_E_ENET                        = CVMX_PKI_LTYPE_E_ENET_M,
+	CVMX_PKI_LTYPE_E_VLAN                        = CVMX_PKI_LTYPE_E_VLAN_M,
+	CVMX_PKI_LTYPE_E_SNAP_PAYLD                  = CVMX_PKI_LTYPE_E_SNAP_PAYLD_M,
+	CVMX_PKI_LTYPE_E_ARP                         = CVMX_PKI_LTYPE_E_ARP_M,
+	CVMX_PKI_LTYPE_E_RARP                        = CVMX_PKI_LTYPE_E_RARP_M,
+	CVMX_PKI_LTYPE_E_IP4                         = CVMX_PKI_LTYPE_E_IP4_M,
+	CVMX_PKI_LTYPE_E_IP4_OPT                     = CVMX_PKI_LTYPE_E_IP4_OPT_M,
+	CVMX_PKI_LTYPE_E_IP6                         = CVMX_PKI_LTYPE_E_IP6_M,
+	CVMX_PKI_LTYPE_E_IP6_OPT                     = CVMX_PKI_LTYPE_E_IP6_OPT_M,
+	CVMX_PKI_LTYPE_E_IPSEC_ESP                   = CVMX_PKI_LTYPE_E_IPSEC_ESP_M,
+	CVMX_PKI_LTYPE_E_IPFRAG                      = CVMX_PKI_LTYPE_E_IPFRAG_M,
+	CVMX_PKI_LTYPE_E_IPCOMP                      = CVMX_PKI_LTYPE_E_IPCOMP_M,
+	CVMX_PKI_LTYPE_E_TCP                         = CVMX_PKI_LTYPE_E_TCP_M,
+	CVMX_PKI_LTYPE_E_UDP                         = CVMX_PKI_LTYPE_E_UDP_M,
+	CVMX_PKI_LTYPE_E_SCTP                        = CVMX_PKI_LTYPE_E_SCTP_M,
+	CVMX_PKI_LTYPE_E_UDP_VXLAN                   = CVMX_PKI_LTYPE_E_UDP_VXLAN_M,
+	CVMX_PKI_LTYPE_E_GRE                         = CVMX_PKI_LTYPE_E_GRE_M,
+	CVMX_PKI_LTYPE_E_NVGRE                       = CVMX_PKI_LTYPE_E_NVGRE_M,
+	CVMX_PKI_LTYPE_E_GTP                         = CVMX_PKI_LTYPE_E_GTP_M,
+	CVMX_PKI_LTYPE_E_SW28                        = CVMX_PKI_LTYPE_E_SW28_M,
+	CVMX_PKI_LTYPE_E_SW29                        = CVMX_PKI_LTYPE_E_SW29_M,
+	CVMX_PKI_LTYPE_E_SW30                        = CVMX_PKI_LTYPE_E_SW30_M,
+	CVMX_PKI_LTYPE_E_SW31                        = CVMX_PKI_LTYPE_E_SW31_M
+};
+
+
 typedef union {
 	uint64_t u64;
 #ifdef __BIG_ENDIAN_BITFIELD
@@ -97,7 +176,7 @@ typedef union {
 
 	};
 #endif
-}cvmx_wqe_word4_t;
+} cvmx_wqe_word4_t;
 
 /**
  * HW decode / err_code in work queue entry
@@ -586,6 +665,7 @@ typedef union {
 #endif				/* __LITTLE_ENDIAN_BITFIELD */
 } cvmx_pip_wqe_word2_t;
 
+
 typedef union {
 	uint64_t u64;
 #ifdef __BIG_ENDIAN_BITFIELD
@@ -734,6 +814,9 @@ typedef union {
 #endif
 } cvmx_pki_wqe_word0_t;
 
+/* Use reserved bit, set by HW to 0, to indicate buf_ptr legacy translation*/
+#define	pki_wqe_translated word0.pki.rsvd_1
+
 typedef union {
 	uint64_t u64;
 	cvmx_pip_wqe_word0_t pip;
@@ -854,7 +937,7 @@ typedef union {
  *
  * must be 8-byte aligned
  */
-typedef struct {
+typedef struct cvmx_wqe_s {
 
     /*****************************************************************
      * WORD 0
@@ -936,7 +1019,7 @@ typedef struct {
 	 * Pointer to the first segment of the packet.
          * WORD 3
      */
-	cvmx_buf_ptr_t packet_ptr;
+	cvmx_buf_ptr_pki_t packet_ptr;
 
     /**
          * WORD 4
@@ -952,14 +1035,30 @@ typedef struct {
 
 } CVMX_CACHE_LINE_ALIGNED cvmx_wqe_78xx_t;
 
-static inline int cvmx_wqe_get_port(cvmx_wqe_t * work)
+/*
+ * This is an accessor function into the WQE that retreives the
+ * ingress port number, which can also be used as a destination
+ * port number for the same port.
+ *
+ * @param work - Work Queue Entrey pointer
+ * @returns returns the normalized port number, also known as "ipd" port
+ *
+ */
+static inline int cvmx_wqe_get_port(cvmx_wqe_t *work)
 {
 	int port;
 
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		/* In 78xx wqe entry has channel number not port*/
-		port = work->word0.pki.channel; //vinita_to_do
-	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
+		port = work->word0.pki.channel;
+		/* For BGX interfaces (0x8xx - 0xdff) the 4 LSBs indicate
+		 * the PFC channel, must be cleared to normalize to "ipd"
+		 */
+		if (port & 0x800)
+			port &= 0xff0;
+		/* Node number is in AURA field, make it part of port # */
+		port |= (work->word0.pki.aura >> 10) << 14;
+	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		port = work->word2.s_cn68xx.port;
 	else
 		port = work->word1.cn38xx.ipprt;
@@ -968,7 +1067,7 @@ static inline int cvmx_wqe_get_port(cvmx_wqe_t * work)
 }
 
 
-static inline void cvmx_wqe_set_port(cvmx_wqe_t * work, int port)
+static inline void cvmx_wqe_set_port(cvmx_wqe_t *work, int port)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		work->word0.pki.channel = port;
@@ -978,7 +1077,7 @@ static inline void cvmx_wqe_set_port(cvmx_wqe_t * work, int port)
 		work->word1.cn38xx.ipprt = port;
 }
 
-static inline int cvmx_wqe_get_grp(cvmx_wqe_t * work)
+static inline int cvmx_wqe_get_grp(cvmx_wqe_t *work)
 {
 	int grp;
 
@@ -992,7 +1091,7 @@ static inline int cvmx_wqe_get_grp(cvmx_wqe_t * work)
 	return grp;
 }
 
-static inline void cvmx_wqe_set_grp(cvmx_wqe_t * work, int grp)
+static inline void cvmx_wqe_set_grp(cvmx_wqe_t *work, int grp)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		work->word1.cn78xx.grp = grp;
@@ -1002,10 +1101,12 @@ static inline void cvmx_wqe_set_grp(cvmx_wqe_t * work, int grp)
 		work->word1.cn38xx.grp = grp;
 }
 
-static inline int cvmx_wqe_get_qos(cvmx_wqe_t * work)
+static inline int cvmx_wqe_get_qos(cvmx_wqe_t *work)
 {
 	int qos;
 
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		qos = work->word1.cn78xx.grp & 0x7; /* convention */
 	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		qos = work->word1.cn68xx.qos;
 	else
@@ -1014,7 +1115,7 @@ static inline int cvmx_wqe_get_qos(cvmx_wqe_t * work)
 	return qos;
 }
 
-static inline void cvmx_wqe_set_qos(cvmx_wqe_t * work, int qos)
+static inline void cvmx_wqe_set_qos(cvmx_wqe_t *work, int qos)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		work->word1.cn68xx.qos = qos;
@@ -1022,7 +1123,7 @@ static inline void cvmx_wqe_set_qos(cvmx_wqe_t * work, int qos)
 		work->word1.cn38xx.qos = qos;
 }
 
-static inline int cvmx_wqe_get_len(cvmx_wqe_t * work)
+static inline int cvmx_wqe_get_len(cvmx_wqe_t *work)
 {
 	int len;
 
@@ -1036,7 +1137,7 @@ static inline int cvmx_wqe_get_len(cvmx_wqe_t * work)
 	return len;
 }
 
-static inline void cvmx_wqe_set_len(cvmx_wqe_t * work, int len)
+static inline void cvmx_wqe_set_len(cvmx_wqe_t *work, int len)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		work->word1.cn78xx.len = len;
@@ -1046,42 +1147,41 @@ static inline void cvmx_wqe_set_len(cvmx_wqe_t * work, int len)
 		work->word1.cn38xx.len = len;
 }
 
-static inline int cvmx_wqe_get_bufs(cvmx_wqe_t * work)
-{
-	int bufs;
-
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
-		bufs = work->word0.pki.bufs;
-	else
-		bufs = work->word2.s.bufs;
-
-	return bufs;
-}
-
-static inline int cvmx_wqe_get_error(cvmx_wqe_t * work)
+/**
+ * This function returns if there was L2/L1 errors detected in packet.
+ * @param work	pointer to work queue entry
+ * @return	error code -- If L2/L1 error was found in packet
+ *		0 -- If no L2/L1 error was found in packet.
+ */
+static inline int cvmx_wqe_get_rcv_err(cvmx_wqe_t *work)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
-		return (((cvmx_wqe_78xx_t*)(work))->word2.pki.err_level);
-	else
-		return (work->word2.snoip.rcv_error);
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void*)work;
+		if (wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_RE ||
+				  wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_LA)
+			return(wqe->word2.pki.err_code);
+	}
+	else if (work->word2.snoip.rcv_error)
+		return (work->word2.snoip.err_code);
+	return 0;
 }
 
-static inline uint32_t cvmx_wqe_get_tag(cvmx_wqe_t * work)
+static inline uint32_t cvmx_wqe_get_tag(cvmx_wqe_t *work)
 {
 	return work->word1.tag;
 }
 
-static inline void cvmx_wqe_set_tag(cvmx_wqe_t * work, uint32_t tag)
+static inline void cvmx_wqe_set_tag(cvmx_wqe_t *work, uint32_t tag)
 {
 	work->word1.tag = tag;
 }
 
-static inline int cvmx_wqe_get_tt(cvmx_wqe_t * work)
+static inline int cvmx_wqe_get_tt(cvmx_wqe_t *work)
 {
 	return work->word1.tag_type;
 }
 
-static inline void cvmx_wqe_set_tt(cvmx_wqe_t * work, int tt)
+static inline void cvmx_wqe_set_tt(cvmx_wqe_t *work, int tt)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		work->word1.cn78xx.tag_type = (cvmx_pow_tag_type_t) tt;
@@ -1096,7 +1196,7 @@ static inline void cvmx_wqe_set_tt(cvmx_wqe_t * work, int tt)
 	}
 }
 
-static inline int cvmx_wqe_get_unused8(cvmx_wqe_t * work)
+static inline int cvmx_wqe_get_unused8(cvmx_wqe_t *work)
 {
 	int len;
 
@@ -1108,7 +1208,7 @@ static inline int cvmx_wqe_get_unused8(cvmx_wqe_t * work)
 	return len;
 }
 
-static inline void cvmx_wqe_set_unused8(cvmx_wqe_t * work, int v)
+static inline void cvmx_wqe_set_unused8(cvmx_wqe_t *work, int v)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		work->word0.pip.cn68xx.unused1 = v;
@@ -1116,58 +1216,428 @@ static inline void cvmx_wqe_set_unused8(cvmx_wqe_t * work, int v)
 		work->word0.pip.cn38xx.unused = v;
 }
 
-static inline int cvmx_wqe_get_channel(cvmx_wqe_t * work)
+static inline int cvmx_wqe_get_channel(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		return (work->word0.pki.channel);
-	else {
-		cvmx_dprintf("ERROR: cvmx_wqe_get_channel\n");
-		return -1;
-	}
+	else
+		return cvmx_wqe_get_port(work);
+
 }
 
-static inline void cvmx_wqe_set_channel(cvmx_wqe_t * work, int channel)
+static inline void cvmx_wqe_set_channel(cvmx_wqe_t *work, int channel)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		work->word0.pki.channel = channel;
 	else
-		cvmx_dprintf("ERROR: cvmx_wqe_set_channel\n");
+		cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
 }
 
-static inline int cvmx_wqe_get_aura(cvmx_wqe_t * work)
+static inline int cvmx_wqe_get_aura(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		return (work->word0.pki.aura);
-	else {
-		cvmx_dprintf("ERROR: cvmx_wqe_get_aura\n");
-		return -1;
-	}
+	else
+		return (work->packet_ptr.s.pool);
 }
 
-static inline void cvmx_wqe_set_aura(cvmx_wqe_t * work, int aura)
+static inline void cvmx_wqe_set_aura(cvmx_wqe_t *work, int aura)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		work->word0.pki.aura = aura;
 	else
-		cvmx_dprintf("ERROR: cvmx_wqe_set_aura\n");
+		cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
 }
 
-static inline int cvmx_wqe_get_style(cvmx_wqe_t * work)
+static inline int cvmx_wqe_get_style(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		return (work->word0.pki.style);
-	else {
-		cvmx_dprintf("ERROR: cvmx_wqe_get_style\n");
-		return -1;
-	}
+	return 0;
 }
 
-static inline void cvmx_wqe_set_style(cvmx_wqe_t * work, int style)
+static inline void cvmx_wqe_set_style(cvmx_wqe_t *work, int style)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		work->word0.pki.style = style;
-	else
-		cvmx_dprintf("ERROR: cvmx_wqe_set_style\n");
+}
+
+static inline int cvmx_wqe_is_ip(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		if((wqe->word2.pki.lc_hdr_type & 0x1c) == CVMX_PKI_LTYPE_E_IP4)
+			return 1;
+		if((wqe->word2.pki.le_hdr_type & 0x1c) == CVMX_PKI_LTYPE_E_IP4)
+			return 1;
+		return 0;
+	} else
+		return !work->word2.s_cn38xx.not_IP;
+
+}
+
+static inline int cvmx_wqe_is_ipv4(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		if((wqe->word2.pki.lc_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP4)
+			return 1;
+		if((wqe->word2.pki.le_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP4)
+			return 1;
+		return 0;
+	} else
+		return (
+			!work->word2.s_cn38xx.not_IP &&
+			!work->word2.s_cn38xx.is_v6
+			);
+
+}
+
+static inline int cvmx_wqe_is_ipv6(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		if((wqe->word2.pki.lc_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP6)
+			return 1;
+		if((wqe->word2.pki.le_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP6)
+			return 1;
+		return 0;
+	} else
+		return (
+			!work->word2.s_cn38xx.not_IP &&
+			work->word2.s_cn38xx.is_v6
+			);
+}
+
+static inline int cvmx_wqe_is_l2_bcast(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		return (wqe->word2.pki.is_l2_bcast);
+	} else
+		return (work->word2.s_cn38xx.is_bcast);
+}
+
+static inline int cvmx_wqe_is_l2_mcast(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		return (wqe->word2.pki.is_l2_mcast);
+	} else
+		return (work->word2.s_cn38xx.is_mcast);
+}
+
+static inline int cvmx_wqe_is_l3_bcast(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		return (wqe->word2.pki.is_l3_bcast);
+	} else
+		cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
+}
+
+static inline int cvmx_wqe_is_l3_mcast(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)){
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		return (wqe->word2.pki.is_l3_mcast);
+	} else
+		cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
+}
+
+/**
+ * This function returns is there was IP error detected in packet.
+ * For 78XX it does not flag ipv4 options and ipv6 extensions.
+ * For older chips if PIP_GBL_CTL was proviosned to flag ip4_otions and
+ * ipv6 extension, it will be flag them.
+ * @param work	pointer to work queue entry
+ * @return	1 -- If IP error was found in packet
+ *		0 -- If no IP error was found in packet.
+ */
+static inline int cvmx_wqe_is_ip_exception(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		if (wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_LC)
+			return 1;
+		if (wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_LE)
+			return 1;
+		else
+			return 0;
+	} else
+		return work->word2.s.IP_exc;
+}
+
+static inline int cvmx_wqe_is_L4_error(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		if (wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_LF)
+			return 1;
+		else
+			return 0;
+	} else
+		return work->word2.s.L4_error;
+}
+
+static inline int cvmx_wqe_is_vlan(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+			return wqe->word2.pki.vlan_valid;
+	} else
+		return work->word2.s.vlan_valid;
+}
+
+static inline int cvmx_wqe_is_vlan_stacked(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		return wqe->word2.pki.vlan_stacked;
+	} else
+		return work->word2.s.vlan_stacked;
+}
+
+/**
+ * @INTERNAL
+ *
+ * Retreive WQE pool number from PIP/IPD register
+ */
+static inline unsigned __cvmx_ipd_wqe_pool(void)
+{
+        cvmx_ipd_wqe_fpa_queue_t wqe_pool;
+        wqe_pool.u64 = cvmx_read_csr(CVMX_IPD_WQE_FPA_QUEUE);
+        return wqe_pool.s.wqe_pool;
+}
+
+/**
+ * @INTERNAL
+ *
+ * Extract NO_WPTR mode from PIP/IPD register
+ */
+static inline int __cvmx_ipd_mode_no_wptr(void)
+{
+	cvmx_ipd_ctl_status_t ipd_ctl_status;
+
+	if (!octeon_has_feature(OCTEON_FEATURE_NO_WPTR))
+		return 0;
+
+	ipd_ctl_status.u64 = cvmx_read_csr(CVMX_IPD_CTL_STATUS);
+	return (ipd_ctl_status.s.no_wptr);
+}
+
+/**
+ * Extract packet data buffer pointer from work queue entry.
+ *
+ * Returns the legacy (Octeon1/Octeon2) buffer pointer structure
+ * for the linked buffer list.
+ * On CN78XX, the native buffer pointer structure is converted into
+ * the legacy format.
+ * The legacy buf_ptr is then stored in the WQE, and word0 reserved
+ * field is set to indicate that the buffer pointers were translated.
+ * If the packet data is only found inside the work queue entry,
+ * a standard buffer pointer structure is created for it.
+ */
+static inline cvmx_buf_ptr_t cvmx_wqe_get_packet_ptr(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t * wqe = (void *) work;
+		cvmx_buf_ptr_t optr, lptr;
+		cvmx_buf_ptr_pki_t nptr;
+		unsigned pool, bufs;
+
+		/* In case of repeated calls of this function */
+		if (wqe->pki_wqe_translated) {
+			optr.u64 = wqe->packet_ptr.u64;
+			return optr;
+		}
+
+		bufs = wqe->word0.pki.bufs;
+		pool = wqe->word0.pki.aura;
+		nptr.u64 = wqe->packet_ptr.u64;
+
+		optr.u64=0;
+		optr.s.pool = pool;
+		optr.s.addr = nptr.s_cn78xx.addr;
+		optr.s.size = nptr.s_cn78xx.size;
+
+		/* Calculate the "back" offset */
+		if (!nptr.s_cn78xx.packet_outside_wqe)
+			optr.s.back = (nptr.s_cn78xx.addr-cvmx_ptr_to_phys(wqe))
+				>> 7;
+		else
+			optr.s.back = 0; //XXX assume <128, get actual pool sz
+
+		lptr = optr;
+
+		/* Follow pointer and convert all linked pointers */
+		while (bufs > 1) {
+			void * vptr;
+
+			vptr = cvmx_phys_to_ptr(lptr.s.addr);
+
+			memcpy(&nptr, vptr - 8, 8);
+
+			lptr.u64=0;
+			lptr.s.pool = pool;
+			lptr.s.addr = nptr.s_cn78xx.addr;
+			lptr.s.size = nptr.s_cn78xx.size;
+			lptr.s.back = 0;	//XXX- not guarangeed !!
+
+			memcpy(vptr-8, &lptr, 8);
+			bufs --;
+		}
+		/* Store translated bufptr in WQE, and set indicator */
+		wqe->pki_wqe_translated = 1;
+		wqe->packet_ptr.u64 = optr.u64;
+		return optr;
+
+	} else {
+		cvmx_buf_ptr_t bptr;
+
+		if ( work->word2.s.bufs > 0)
+			return work->packet_ptr;
+
+		/* data is only in WQE, convert it into a buf_ptr */
+		bptr.u64 = 0;
+		bptr.s.size = cvmx_wqe_get_len(work);
+		bptr.s.pool = __cvmx_ipd_wqe_pool();
+		bptr.s.addr = cvmx_ptr_to_phys(work) + 32;
+
+		/* For CN68XX it could be NO_WPTR or Dynamic-Short cause */
+		if (__cvmx_ipd_mode_no_wptr()) {
+			/* Packet pool is hardwired to 0 in relevant SoCs */
+			bptr.s.pool = 0;
+		}
+
+		/* FIXME- RAWFULL case not handled yet */
+
+		if (work->word2.s_cn38xx.not_IP ||
+		    work->word2.s_cn38xx.rcv_error) {
+			/* Adjust data offset for non-IP packets */
+                        union cvmx_pip_gbl_cfg pip_gbl_cfg;
+                        pip_gbl_cfg.u64 = cvmx_read_csr(CVMX_PIP_GBL_CFG);
+                        bptr.s.addr += pip_gbl_cfg.s.nip_shf;
+		} else {
+			/* Adjust data start address for IP protocols */
+                        union cvmx_pip_ip_offset pip_ip_offset;
+                        pip_ip_offset.u64 = cvmx_read_csr(CVMX_PIP_IP_OFFSET);
+                        bptr.s.addr += (pip_ip_offset.s.offset << 3) -
+				work->word2.s.ip_offset;
+                        bptr.s.addr += (work->word2.s.is_v6 ^ 1) << 2;
+		}
+
+		/* Calculate the "back" offset in 64-bit words */
+		bptr.s.back = (bptr.s.addr -cvmx_ptr_to_phys(work)) >> 7;
+
+		/* Store the new buffer pointer back into WQE */
+		work->packet_ptr = bptr;
+
+		/* Adjust word2.bufs so that _free_data() handles it
+		 * in the same way as PKO
+		 */
+		work->word2.s.bufs = 1;
+
+		/* Returned the synthetic buffer_pointer */
+		return bptr;
+	}
+}
+
+static inline int cvmx_wqe_get_bufs(cvmx_wqe_t *work)
+{
+	int bufs;
+
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		bufs = work->word0.pki.bufs;
+	else {
+		/* Adjust for packet-in-WQE cases */
+		if(work->word2.s_cn38xx.bufs == 0)
+			(void) cvmx_wqe_get_packet_ptr(work);
+		bufs = work->word2.s_cn38xx.bufs;
+	}
+
+	return bufs;
+}
+
+/**
+ * Free Work Queue Entry memory
+ *
+ * Will return the WQE buffer to its pool, unless the WQE contains
+ * non-redundant packet data.
+ * This function is intended to be called AFTER the packet data
+ * has been passed along to PKO for transmission and release.
+ * It can also follow a call to cvmx_helper_free_packet_data()
+ * to release the WQE after associated data was released.
+ */
+static inline void cvmx_wqe_free(cvmx_wqe_t *work)
+{
+	unsigned ncl;
+	unsigned pool;
+	uint64_t paddr;
+	cvmx_wqe_78xx_t * wqe = (void *) work;
+
+	/* Free native untranslated 78xx WQE */
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
+		!wqe->pki_wqe_translated) {
+		cvmx_buf_ptr_pki_t bptr;
+
+		bptr = wqe->packet_ptr;
+
+		/* Do nothing if the first packet buffer shares WQE buffer */
+		if (!bptr.s_cn78xx.packet_outside_wqe)
+			return;
+	} else {
+		/* determine if packet is inside WQE the old way */
+		if (cvmx_wqe_get_bufs(work) > 0) {
+			/* Check if the first data buffer is inside WQE */
+			paddr = (work->packet_ptr.s.addr >> 7) -
+				work->packet_ptr.s.back;
+			paddr = paddr << 7;
+
+			/* do not free WQE if contains first data buffer */
+			if (paddr == cvmx_ptr_to_phys(work))
+				return;
+		}
+	}
+
+	/* At this point it is clear the WQE needs to be freed */
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		unsigned node, laura;
+		/* First buffer outside WQE, but WQE comes from the same AURA */
+		node = wqe->word0.pki.aura >> 10;
+		laura = wqe->word0.pki.aura & ((1<<10)-1);
+
+		/* Only a few words have been touched, not entire buf */
+		ncl = 1;
+
+		cvmx_fpa_free_aura(work, node, laura, ncl);
+	} else {
+		/* Determine FPA pool the WQE buffer belongs to */
+		if (__cvmx_ipd_mode_no_wptr()) {
+			pool = 0 ; /* Hardwired packet FPA pool */
+			ncl = (cvmx_wqe_get_len(work) + 127) >> 7;
+			ncl += 4;
+		} else {
+			pool = __cvmx_ipd_wqe_pool();
+			ncl = 1;
+		}
+
+		cvmx_fpa_free(work, pool, ncl);
+	}
+}
+
+
+/**
+ * @INTERNAL
+ *
+ * Extract the native PKI-specific buffer pointer from WQE.
+ *
+ * NOTE: Provisional, may be superceded.
+ */
+static inline cvmx_buf_ptr_pki_t cvmx_wqe_get_pki_pkt_ptr(cvmx_wqe_t *work)
+{
+	cvmx_wqe_78xx_t * wqe = (void *) work;
+	return wqe->packet_ptr;
 }
 
 #ifdef	__cplusplus
diff --git a/arch/mips/include/asm/octeon/octeon-boot-info.h b/arch/mips/include/asm/octeon/octeon-boot-info.h
index 29370be..a4135cb 100644
--- a/arch/mips/include/asm/octeon/octeon-boot-info.h
+++ b/arch/mips/include/asm/octeon/octeon-boot-info.h
@@ -118,8 +118,10 @@ typedef struct  boot_init_vector boot_init_vector_t;
 #undef GD_TMP_STR_SIZE
 #define GD_TMP_STR_SIZE 32
 
+/* FIXME: This structure is not endianness-neutral */
+/* This structure is deprecated, use sysinfo instead */
 struct linux_app_global_data {
-#ifdef __U_BOOT__
+#if	_MIPS_SZPTR == 32
 	uint32_t pad0;
 #endif
 	bd_t *bd;
@@ -144,11 +146,11 @@ struct linux_app_global_data {
 	octeon_eeprom_clock_desc_t clock_desc;
 	octeon_eeprom_mac_addr_t mac_desc;
 
-#ifdef __U_BOOT__
+#if	_MIPS_SZPTR == 32
 	uint32_t pad1;
 #endif
 	void **jt;		/* jump table, not used */
-#ifdef __U_BOOT__
+#if	_MIPS_SZPTR == 32
 	uint32_t pad2;
 #endif
 	char *err_msg;		/* pointer to error message to save
diff --git a/arch/mips/include/asm/octeon/octeon-feature.h b/arch/mips/include/asm/octeon/octeon-feature.h
index b9e45cb..718622d 100644
--- a/arch/mips/include/asm/octeon/octeon-feature.h
+++ b/arch/mips/include/asm/octeon/octeon-feature.h
@@ -162,6 +162,12 @@ typedef enum {
 				/**<  Octeon has zip first seen on 78XX */
  	OCTEON_FEATURE_BCH,
   				/**< Octeon supports BCH ECC */
+	OCTEON_FEATURE_PKI,
+  				/**< Octeon has PKI block */
+	OCTEON_FEATURE_OCLA,
+				/**<  Octeon has OCLA */
+	OCTEON_FEATURE_FAU,
+				/**<  Octeon has FAU */
 	OCTEON_MAX_FEATURE
 } octeon_feature_t;
 
@@ -172,9 +178,9 @@ static inline int octeon_has_feature_OCTEON_FEATURE_SAAD(void)
 
 static inline int octeon_has_feature_OCTEON_FEATURE_ZIP(void)
 {
-	if (OCTEON_IS_MODEL(OCTEON_CN30XX) || OCTEON_IS_MODEL(OCTEON_CN50XX)
-	    || OCTEON_IS_MODEL(OCTEON_CN52XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)
-	    || OCTEON_IS_MODEL(OCTEON_CN70XX))
+	if ((OCTEON_IS_MODEL(OCTEON_CN30XX) || OCTEON_IS_MODEL(OCTEON_CN50XX)
+	     || OCTEON_IS_MODEL(OCTEON_CN52XX) || OCTEON_IS_MODEL(OCTEON_CNF71XX)
+	     || OCTEON_IS_MODEL(OCTEON_CN70XX)) && !OCTEON_IS_MODEL(OCTEON_CN78XX))
 		return 0;
 	else
 		return !cvmx_fuse_read(121);
@@ -187,7 +193,7 @@ static inline int octeon_has_feature_OCTEON_FEATURE_ZIP3(void)
 
 static inline int octeon_has_feature_OCTEON_FEATURE_BCH(void)
 {
-	return OCTEON_IS_OCTEON3();
+	return OCTEON_IS_MODEL(OCTEON_CN70XX);
 }
 
 static inline int octeon_has_feature_OCTEON_FEATURE_CRYPTO(void)
@@ -268,7 +274,7 @@ static inline int octeon_has_feature_OCTEON_FEATURE_MGMT_PORT(void)
 static inline int octeon_has_feature_OCTEON_FEATURE_RAID(void)
 {
 	return OCTEON_IS_MODEL(OCTEON_CN56XX) || OCTEON_IS_MODEL(OCTEON_CN52XX)
-	       || !OCTEON_IS_OCTEON1PLUS();	/* OCTEON II or later */
+	       || !OCTEON_IS_OCTEON1PLUS() || OCTEON_IS_MODEL(OCTEON_CN78XX);	/* OCTEON II or later */
 }
 
 static inline int octeon_has_feature_OCTEON_FEATURE_USB(void)
@@ -430,6 +436,23 @@ static inline int octeon_has_feature_OCTEON_FEATURE_SPI(void)
 		|| OCTEON_IS_MODEL(OCTEON_CN70XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN78XX));
 }
+
+static inline int octeon_has_feature_OCTEON_FEATURE_PKI(void)
+{
+	return (OCTEON_IS_MODEL(OCTEON_CN78XX));
+}
+
+static inline int octeon_has_feature_OCTEON_FEATURE_OCLA(void)
+{
+	return (OCTEON_IS_MODEL(OCTEON_CN70XX)
+		|| OCTEON_IS_MODEL(OCTEON_CN78XX));
+}
+
+static inline int octeon_has_feature_OCTEON_FEATURE_FAU(void)
+{
+	return !(OCTEON_IS_MODEL(OCTEON_CN78XX));
+}
+
 /*
  * bit map for octeon features
  */
diff --git a/arch/mips/include/asm/octeon/octeon-model.h b/arch/mips/include/asm/octeon/octeon-model.h
index 8a51e8e..9515f30 100644
--- a/arch/mips/include/asm/octeon/octeon-model.h
+++ b/arch/mips/include/asm/octeon/octeon-model.h
@@ -43,7 +43,7 @@
  * File defining different Octeon model IDs and macros to
  * compare them.
  *
- * <hr>$Revision: 88111 $<hr>
+ * <hr>$Revision: 92253 $<hr>
  */
 
 #ifndef __OCTEON_MODEL_H__
@@ -104,8 +104,7 @@ extern "C" {
 #define OCTEON_CN70XX           (OCTEON_CN70XX_PASS1_0 | OM_IGNORE_REVISION)
 #define OCTEON_CN70XX_PASS1_X   (OCTEON_CN70XX_PASS1_0 | OM_IGNORE_MINOR_REVISION)
 
-#define OCTOEN_CN71XX		OCTEON_CN70XX
-#define OCTOEN_CN71XX_PASS1_X	OCTEON_CN70XX_PASS1_X
+#define OCTEON_CN71XX		OCTEON_CN70XX
 
 #define OCTEON_CN78XX_PASS1_0   0x000d9500
 
@@ -177,7 +176,7 @@ extern "C" {
 #define OCTEON_CN58XX_PASS2_2   0x000d030a
 #define OCTEON_CN58XX_PASS2_3   0x000d030b
 
-#define OCTEON_CN58XX           (OCTEON_CN58XX_PASS1_0 | OM_IGNORE_REVISION)
+#define OCTEON_CN58XX           (OCTEON_CN58XX_PASS2_0 | OM_IGNORE_REVISION)
 #define OCTEON_CN58XX_PASS1_X   (OCTEON_CN58XX_PASS1_0 | OM_IGNORE_MINOR_REVISION)
 #define OCTEON_CN58XX_PASS2_X   (OCTEON_CN58XX_PASS2_0 | OM_IGNORE_MINOR_REVISION)
 #define OCTEON_CN58XX_PASS1     OCTEON_CN58XX_PASS1_X
diff --git a/drivers/net/ethernet/octeon/ethernet-napi.c b/drivers/net/ethernet/octeon/ethernet-napi.c
index 281b38b..bf4ff2f 100644
--- a/drivers/net/ethernet/octeon/ethernet-napi.c
+++ b/drivers/net/ethernet/octeon/ethernet-napi.c
@@ -175,7 +175,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			/* We are done with this one, adjust the queue
 			 * depth.
 			 */
-			cvmx_fau_atomic_add32(priv->tx_queue[packet_qos].fau, -1);
+			cvmx_hwfau_atomic_add32(priv->tx_queue[packet_qos].fau, -1);
 			continue;
 		}
 		segments = work->word2.s.bufs;
@@ -440,7 +440,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 				 * the number of buffers we need to free by
 				 * one.
 				 */
-				cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
+				cvmx_hwfau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
 						      packets_to_replace);
 
 				cvmx_fpa_free(work, wqe_pool, DONT_WRITEBACK(1));
diff --git a/drivers/net/ethernet/octeon/ethernet-tx.c b/drivers/net/ethernet/octeon/ethernet-tx.c
index cd8b1e8..de47cd7 100644
--- a/drivers/net/ethernet/octeon/ethernet-tx.c
+++ b/drivers/net/ethernet/octeon/ethernet-tx.c
@@ -210,7 +210,7 @@ int cvm_oct_transmit_qos(struct net_device *dev,
 		pko_command.s.ipoffp1 = sizeof(struct ethhdr) + 1;
 
 	/* Send the packet to the output queue */
-	if (unlikely(cvmx_pko_send_packet_finish_pkoid(priv->pko_port, priv->tx_queue[qos].queue, pko_command, hw_buffer, lock_type))) {
+	if (unlikely(cvmx_hwpko_send_packet_finish_pkoid(priv->pko_port, priv->tx_queue[qos].queue, pko_command, hw_buffer, lock_type))) {
 		netdev_err(dev, "Error: Failed to send the packet\n");
 		dropped = -1;
 	}
diff --git a/drivers/net/ethernet/octeon/ethernet-xmit.c b/drivers/net/ethernet/octeon/ethernet-xmit.c
index f19d8f2..4ecf66b 100644
--- a/drivers/net/ethernet/octeon/ethernet-xmit.c
+++ b/drivers/net/ethernet/octeon/ethernet-xmit.c
@@ -79,7 +79,7 @@ CVM_OCT_XMIT
 		/* Fetch and increment the number of packets to be
 		 * freed.
 		 */
-		cvmx_fau_async_fetch_and_add32(CVMX_SCR_SCRATCH + 8,
+		cvmx_hwfau_async_fetch_and_add32(CVMX_SCR_SCRATCH + 8,
 					       FAU_NUM_PACKET_BUFFERS_TO_FREE,
 					       0);
 	}
@@ -101,7 +101,7 @@ CVM_OCT_XMIT
 		qos = 0;
 #endif
 	if (USE_ASYNC_IOBDMA) {
-		cvmx_fau_async_fetch_and_add32(CVMX_SCR_SCRATCH,
+		cvmx_hwfau_async_fetch_and_add32(CVMX_SCR_SCRATCH,
 					       priv->tx_queue[qos].fau, 1);
 	}
 
@@ -256,8 +256,8 @@ CVM_OCT_XMIT
 		buffers_to_free = cvmx_scratch_read64(CVMX_SCR_SCRATCH + 8);
 	} else {
 		/* Get the number of skbuffs in use by the hardware */
-		queue_depth = cvmx_fau_fetch_and_add32(priv->tx_queue[qos].fau, 1);
-		buffers_to_free = cvmx_fau_fetch_and_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
+		queue_depth = cvmx_hwfau_fetch_and_add32(priv->tx_queue[qos].fau, 1);
+		buffers_to_free = cvmx_hwfau_fetch_and_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
 	}
 
 	/* If we're sending faster than the receive can free them then
@@ -338,14 +338,14 @@ CVM_OCT_XMIT
 		if (timestamp_this_skb)
 			word2 |= 1ull << 40; /* Bit 40 controls timestamps */
 
-		if (unlikely(cvmx_pko_send_packet_finish3_pkoid(priv->pko_port,
+		if (unlikely(cvmx_hwpko_send_packet_finish3_pkoid(priv->pko_port,
 							  priv->tx_queue[qos].queue, pko_command, hw_buffer,
 							  word2, CVM_OCT_PKO_LOCK_TYPE))) {
 				queue_type = QUEUE_DROP;
 				netdev_err(dev, "Failed to send the packet with wqe\n");
 		}
 	} else {
-		if (unlikely(cvmx_pko_send_packet_finish_pkoid(priv->pko_port,
+		if (unlikely(cvmx_hwpko_send_packet_finish_pkoid(priv->pko_port,
 							 priv->tx_queue[qos].queue,
 							 pko_command, hw_buffer,
 							 CVM_OCT_PKO_LOCK_TYPE))) {
@@ -358,14 +358,14 @@ CVM_OCT_XMIT
 skip_xmit:
 	switch (queue_type) {
 	case QUEUE_DROP:
-		cvmx_fau_atomic_add32(priv->tx_queue[qos].fau, -1);
+		cvmx_hwfau_atomic_add32(priv->tx_queue[qos].fau, -1);
 		dev_kfree_skb_any(skb);
 		dev->stats.tx_dropped++;
 		if (work)
 			cvmx_fpa_free(work, wqe_pool, DONT_WRITEBACK(1));
 		break;
 	case QUEUE_HW:
-		cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, -buffers_being_recycled);
+		cvmx_hwfau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, -buffers_being_recycled);
 		break;
 	case QUEUE_WQE:
 		/* Cleanup is done on the RX path when the WQE returns */
diff --git a/drivers/net/ethernet/octeon/ethernet.c b/drivers/net/ethernet/octeon/ethernet.c
index cff9b4c..ae3949e 100644
--- a/drivers/net/ethernet/octeon/ethernet.c
+++ b/drivers/net/ethernet/octeon/ethernet.c
@@ -871,7 +871,7 @@ static int cvm_oct_probe(struct platform_device *pdev)
 	/* Initialize the FAU used for counting packet buffers that
 	 * need to be freed.
 	 */
-	cvmx_fau_atomic_write32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
+	cvmx_hwfau_atomic_write32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
 
 	num_interfaces = cvmx_helper_get_number_of_interfaces();
 	for (interface = 0; interface < num_interfaces; interface++) {
@@ -952,7 +952,7 @@ static int cvm_oct_probe(struct platform_device *pdev)
 				priv->tx_queue[qos].queue = base_queue + qos;
 				fau = fau - sizeof(u32);
 				priv->tx_queue[qos].fau = fau;
-				cvmx_fau_atomic_write32(priv->tx_queue[qos].fau, 0);
+				cvmx_hwfau_atomic_write32(priv->tx_queue[qos].fau, 0);
 			}
 
 			/* Cache the fact that there may be multiple queues */
diff --git a/drivers/net/ethernet/octeon/octeon-ethernet.h b/drivers/net/ethernet/octeon/octeon-ethernet.h
index f0efedc..5d00e5e 100644
--- a/drivers/net/ethernet/octeon/octeon-ethernet.h
+++ b/drivers/net/ethernet/octeon/octeon-ethernet.h
@@ -188,14 +188,14 @@ static inline void cvm_oct_rx_refill_pool(int fill_threshold)
 	int num_freed;
 	/* Refill the packet buffer pool */
 	number_to_free =
-		cvmx_fau_fetch_and_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
+		cvmx_hwfau_fetch_and_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
 
 	if (number_to_free > fill_threshold) {
-		cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
+		cvmx_hwfau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
 				      -number_to_free);
 		num_freed = cvm_oct_mem_fill_fpa(packet_pool, number_to_free);
 		if (num_freed != number_to_free) {
-			cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
+			cvmx_hwfau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
 					number_to_free - num_freed);
 		}
 	}
-- 
2.6.2

