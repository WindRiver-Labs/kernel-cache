From 727d4e32dbb8f1677d350d241e3b6ff5bdadc6a9 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Wed, 19 Feb 2014 13:46:59 -0800
Subject: [PATCH 485/974] MIPS: OCTEON: Update S.E. files to r96774.

Signed-off-by: David Daney <david.daney@cavium.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/cavium-octeon/executive/Makefile         |    3 +-
 arch/mips/cavium-octeon/executive/cvmx-agl.c       |   21 +-
 arch/mips/cavium-octeon/executive/cvmx-bch.c       |    4 +
 arch/mips/cavium-octeon/executive/cvmx-bootmem.c   |  151 ++-
 arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c |    7 +-
 .../mips/cavium-octeon/executive/cvmx-dma-engine.c |    8 +-
 .../cavium-octeon/executive/cvmx-error-trees.c     |  805 ++++++++++++++-
 .../cavium-octeon/executive/cvmx-fpa-resource.c    |  122 ++-
 .../mips/cavium-octeon/executive/cvmx-helper-agl.c |   10 +-
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c |  538 ++++++----
 .../cavium-octeon/executive/cvmx-helper-board.c    |   66 +-
 .../mips/cavium-octeon/executive/cvmx-helper-cfg.c |  134 ++-
 .../cavium-octeon/executive/cvmx-helper-errata.c   |    2 +-
 .../mips/cavium-octeon/executive/cvmx-helper-ilk.c |  166 ++-
 .../mips/cavium-octeon/executive/cvmx-helper-ipd.c |    2 +-
 .../mips/cavium-octeon/executive/cvmx-helper-pki.c |  599 +++++++++--
 .../cavium-octeon/executive/cvmx-helper-pko3.c     |  591 +++++++----
 .../cavium-octeon/executive/cvmx-helper-rgmii.c    |   11 +-
 .../cavium-octeon/executive/cvmx-helper-sgmii.c    |   37 +-
 .../mips/cavium-octeon/executive/cvmx-helper-spi.c |    7 +-
 .../cavium-octeon/executive/cvmx-helper-srio.c     |    5 +-
 .../cavium-octeon/executive/cvmx-helper-util.c     |  573 ++++++-----
 .../cavium-octeon/executive/cvmx-helper-xaui.c     |   19 +-
 arch/mips/cavium-octeon/executive/cvmx-helper.c    |  529 +++++++---
 arch/mips/cavium-octeon/executive/cvmx-ilk.c       |  225 ++--
 arch/mips/cavium-octeon/executive/cvmx-l2c.c       |    9 +-
 arch/mips/cavium-octeon/executive/cvmx-pcie.c      |   57 +-
 .../cavium-octeon/executive/cvmx-pki-resources.c   |  146 ++-
 arch/mips/cavium-octeon/executive/cvmx-pki.c       |   66 +-
 .../executive/cvmx-pko-internal-ports-range.c      |   28 +-
 arch/mips/cavium-octeon/executive/cvmx-pko.c       |   27 +-
 .../mips/cavium-octeon/executive/cvmx-pko3-queue.c |  283 ++++-
 arch/mips/cavium-octeon/executive/cvmx-pko3.c      |  509 ++++++---
 arch/mips/cavium-octeon/executive/cvmx-qlm.c       |  136 ++-
 .../cavium-octeon/executive/cvmx-sso-resources.c   |  107 ++
 arch/mips/cavium-octeon/executive/cvmx-twsi.c      |  149 ++-
 arch/mips/cavium-octeon/executive/octeon-model.c   |   11 +-
 arch/mips/include/asm/octeon/cvmx-agl-defs.h       |   75 +-
 arch/mips/include/asm/octeon/cvmx-app-init.h       |  218 ++--
 arch/mips/include/asm/octeon/cvmx-ase-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-asxx-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-bch-defs.h       |    8 +-
 arch/mips/include/asm/octeon/cvmx-bgxx-defs.h      |  865 ++++++++--------
 arch/mips/include/asm/octeon/cvmx-bootmem.h        |   23 +-
 arch/mips/include/asm/octeon/cvmx-ciu-defs.h       |  456 +++++++--
 arch/mips/include/asm/octeon/cvmx-ciu2-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-ciu3-defs.h      |  248 +----
 arch/mips/include/asm/octeon/cvmx-clock.h          |    1 +
 arch/mips/include/asm/octeon/cvmx-cmd-queue.h      |    4 +-
 arch/mips/include/asm/octeon/cvmx-dbg-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-dpi-defs.h       |   31 +-
 arch/mips/include/asm/octeon/cvmx-fpa-defs.h       |  151 +--
 arch/mips/include/asm/octeon/cvmx-fpa1.h           |   46 +-
 arch/mips/include/asm/octeon/cvmx-fpa3.h           |  258 +++--
 arch/mips/include/asm/octeon/cvmx-gmxx-defs.h      |   95 +-
 arch/mips/include/asm/octeon/cvmx-gpio-defs.h      |   66 +-
 arch/mips/include/asm/octeon/cvmx-gserx-defs.h     | 1080 ++++++++++++--------
 arch/mips/include/asm/octeon/cvmx-helper-bgx.h     |   35 +-
 arch/mips/include/asm/octeon/cvmx-helper-board.h   |    2 +-
 arch/mips/include/asm/octeon/cvmx-helper-cfg.h     |   48 +-
 arch/mips/include/asm/octeon/cvmx-helper-fpa.h     |   20 +-
 arch/mips/include/asm/octeon/cvmx-helper-ilk.h     |    4 +-
 arch/mips/include/asm/octeon/cvmx-helper-npi.h     |    6 +-
 arch/mips/include/asm/octeon/cvmx-helper-pki.h     |  107 +-
 arch/mips/include/asm/octeon/cvmx-helper-pko3.h    |   20 +-
 arch/mips/include/asm/octeon/cvmx-helper-rgmii.h   |    8 +-
 arch/mips/include/asm/octeon/cvmx-helper-sgmii.h   |    8 +-
 arch/mips/include/asm/octeon/cvmx-helper-srio.h    |    4 -
 arch/mips/include/asm/octeon/cvmx-helper-util.h    |  242 ++---
 arch/mips/include/asm/octeon/cvmx-helper.h         |  101 +-
 arch/mips/include/asm/octeon/cvmx-hna-defs.h       |   13 +-
 arch/mips/include/asm/octeon/cvmx-ila-defs.h       |   18 +-
 arch/mips/include/asm/octeon/cvmx-ilk-defs.h       |   35 +-
 arch/mips/include/asm/octeon/cvmx-ilk.h            |   13 +-
 arch/mips/include/asm/octeon/cvmx-iob-defs.h       |   29 +-
 arch/mips/include/asm/octeon/cvmx-iobn-defs.h      |   88 +-
 arch/mips/include/asm/octeon/cvmx-iobp-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-ipd-defs.h       |   38 +-
 arch/mips/include/asm/octeon/cvmx-l2c-defs.h       |  210 ++--
 arch/mips/include/asm/octeon/cvmx-l2d-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-l2t-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-lapx-defs.h      |   11 +-
 arch/mips/include/asm/octeon/cvmx-lbk-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-led-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-lmcx-defs.h      |  516 ++++++----
 arch/mips/include/asm/octeon/cvmx-mio-defs.h       |  155 ++-
 arch/mips/include/asm/octeon/cvmx-mixx-defs.h      |  185 ++--
 arch/mips/include/asm/octeon/cvmx-mpi-defs.h       |    7 +-
 arch/mips/include/asm/octeon/cvmx-ndf-defs.h       |   10 +-
 arch/mips/include/asm/octeon/cvmx-npei-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-npi-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-oclax-defs.h     |  168 +--
 arch/mips/include/asm/octeon/cvmx-ocx-defs.h       |  432 ++++----
 arch/mips/include/asm/octeon/cvmx-osm-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-packet.h         |   55 +-
 arch/mips/include/asm/octeon/cvmx-pci-defs.h       |    2 +-
 arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h |   31 +-
 arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h   |  180 +++-
 arch/mips/include/asm/octeon/cvmx-pciercx-defs.h   |   88 +-
 arch/mips/include/asm/octeon/cvmx-pcsx-defs.h      |   21 +-
 arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h     |   18 +-
 arch/mips/include/asm/octeon/cvmx-pemx-defs.h      |  104 +-
 arch/mips/include/asm/octeon/cvmx-pescx-defs.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-pexp-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-pip-defs.h       |   48 +-
 arch/mips/include/asm/octeon/cvmx-pip.h            |   21 +-
 arch/mips/include/asm/octeon/cvmx-pki-defs.h       |   13 +-
 arch/mips/include/asm/octeon/cvmx-pki-resources.h  |   24 +-
 arch/mips/include/asm/octeon/cvmx-pki.h            |   58 +-
 arch/mips/include/asm/octeon/cvmx-pko-defs.h       |  342 ++++---
 arch/mips/include/asm/octeon/cvmx-pko3-queue.h     |  127 +--
 arch/mips/include/asm/octeon/cvmx-pko3.h           |   50 +-
 arch/mips/include/asm/octeon/cvmx-pow-defs.h       |   24 +-
 arch/mips/include/asm/octeon/cvmx-pow.h            |  489 ++++-----
 arch/mips/include/asm/octeon/cvmx-qlm.h            |    3 +-
 arch/mips/include/asm/octeon/cvmx-rnm-defs.h       |   12 +-
 arch/mips/include/asm/octeon/cvmx-rst-defs.h       |   32 +-
 arch/mips/include/asm/octeon/cvmx-sli-defs.h       |  145 ++-
 arch/mips/include/asm/octeon/cvmx-smix-defs.h      |    7 +-
 arch/mips/include/asm/octeon/cvmx-spxx-defs.h      |    2 +-
 .../mips/include/asm/octeon/cvmx-sriomaintx-defs.h |    2 +-
 arch/mips/include/asm/octeon/cvmx-sriox-defs.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-srxx-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-sso-defs.h       |   90 +-
 arch/mips/include/asm/octeon/cvmx-stxx-defs.h      |    2 +-
 arch/mips/include/asm/octeon/cvmx-uctlx-defs.h     |  341 +++---
 arch/mips/include/asm/octeon/cvmx-usbcx-defs.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-usbnx-defs.h     |    2 +-
 arch/mips/include/asm/octeon/cvmx-wqe.h            |  751 +++++++-------
 arch/mips/include/asm/octeon/cvmx.h                |   21 +-
 arch/mips/include/asm/octeon/octeon-model.h        |   10 +-
 drivers/net/ethernet/octeon/ethernet.c             |    2 +-
 132 files changed, 9956 insertions(+), 5516 deletions(-)
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-sso-resources.c

diff --git a/arch/mips/cavium-octeon/executive/Makefile b/arch/mips/cavium-octeon/executive/Makefile
index cd40c05..f3f9c90 100644
--- a/arch/mips/cavium-octeon/executive/Makefile
+++ b/arch/mips/cavium-octeon/executive/Makefile
@@ -21,7 +21,8 @@ obj-y += cvmx-pko.o cvmx-spi.o cvmx-cmd-queue.o cvmx-helper-cfg.o	\
 	cvmx-helper-rgmii.o cvmx-helper-sgmii.o cvmx-helper-npi.o \
 	cvmx-helper-loop.o cvmx-helper-spi.o cvmx-helper-util.o	\
 	cvmx-pki-resources.o cvmx-gser.o cvmx-bgx.o cvmx-pko3-queue.o cvmx-helper-bgx.o \
-	cvmx-pko3.o cvmx-helper-pki.o cvmx-helper-pko3.o cvmx-pko3-resources.o cvmx-helper-pko.o cvmx-helper-ipd.o
+	cvmx-pko3.o cvmx-helper-pki.o cvmx-helper-pko3.o cvmx-pko3-resources.o \
+	cvmx-helper-pko.o cvmx-helper-ipd.o cvmx-sso-resources.o
 
 obj-y += cvmx-helper-errata.o cvmx-helper-jtag.o
 obj-y += cvmx-pcie.o
diff --git a/arch/mips/cavium-octeon/executive/cvmx-agl.c b/arch/mips/cavium-octeon/executive/cvmx-agl.c
index c8d8884..7e595f6 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-agl.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-agl.c
@@ -49,6 +49,7 @@
 #include <asm/octeon/cvmx-clock.h>
 #include <asm/octeon/cvmx-helper.h>
 #include <asm/octeon/cvmx-helper-board.h>
+#include <asm/octeon/cvmx-helper-cfg.h>
 #include <asm/octeon/cvmx-agl-defs.h>
 #include <asm/octeon/cvmx-agl.h>
 #else
@@ -56,6 +57,7 @@
 #include "cvmx-agl.h"
 #include "cvmx-helper-board.h"
 #include "cvmx-agl-defs.h"
+#include "cvmx-helper-cfg.h"
 #endif
 /*
  * @param port port to enable
@@ -92,15 +94,32 @@ int cvmx_agl_enable(int port)
 cvmx_helper_link_info_t cvmx_agl_link_get(int port)
 {
 	cvmx_helper_link_info_t result;
+	int interface, port_index;
 
-	/* Simulator does not have PHY, use some defaults. */
+	/* For simulator also set the link up */
 	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM) {
+		result.u64 = 0;
 		result.s.full_duplex = 1;
 		result.s.link_up = 1;
 		result.s.speed = 100;
 		return result;
 	}
 
+	/* Fake IPD port is used on some older models. */
+	if (port < 0)
+		return __cvmx_helper_board_link_get(port);
+
+	/* Simulator does not have PHY, use some defaults. */
+	interface = cvmx_helper_get_interface_num(port);
+	port_index = cvmx_helper_get_interface_index_num(port);
+	if (cvmx_helper_get_port_force_link_up(interface, port_index)) {
+		result.u64 = 0;
+		result.s.full_duplex = 1;
+		result.s.link_up = 1;
+		result.s.speed = 1000;
+		return result;
+	}
+
 	return __cvmx_helper_board_link_get(port);
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-bch.c b/arch/mips/cavium-octeon/executive/cvmx-bch.c
index a0628c1..c90a78d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-bch.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-bch.c
@@ -160,6 +160,7 @@ int cvmx_bch_initialize(void)
 	cvmx_read_csr(CVMX_BCH_CMD_BUF);
 	return 0;
 }
+EXPORT_SYMBOL(cvmx_bch_initialize);
 
 /**
  * Shutdown the BCH block
@@ -180,6 +181,7 @@ int cvmx_bch_shutdown(void)
 
 	return 0;
 }
+EXPORT_SYMBOL(cvmx_bch_shutdown);
 
 /**
  * Sets the internal FPA pool data structure for bch pool.
@@ -249,6 +251,7 @@ int cvmx_bch_encode(const void *block, uint16_t block_size,
 
 	return 0;
 }
+EXPORT_SYMBOL(cvmx_bch_encode);
 
 /**
  * Given a data block and ecc data correct the data block
@@ -298,3 +301,4 @@ int cvmx_bch_decode(const void *block_ecc_in, uint16_t block_size,
 	cvmx_bch_write_doorbell(1);
 	return 0;
 }
+EXPORT_SYMBOL(cvmx_bch_decode);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-bootmem.c b/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
index 1c45f68..f79a1c65 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
@@ -15,6 +15,7 @@
  *     disclaimer in the documentation and/or other materials provided
  *     with the distribution.
 
+
  *   * Neither the name of Cavium Inc. nor the names of
  *     its contributors may be used to endorse or promote products
  *     derived from this software without specific prior written
@@ -42,9 +43,10 @@
  * Simple allocate only memory allocator.  Used to allocate memory at
  * application start time.
  *
- * <hr>$Revision: 94463 $<hr>
+ * <hr>$Revision: 96308 $<hr>
  *
  */
+
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
 #include <asm/octeon/cvmx.h>
@@ -56,11 +58,17 @@
 #include <sys/mman.h>
 #endif
 
+#if defined(CVMX_BUILD_FOR_UBOOT)
+#include <common.h>
+#endif
+
 #include "cvmx.h"
 #include "cvmx-bootmem.h"
 #endif
 
-/* #define DEBUG */
+#if defined(CVMX_BUILD_FOR_UBOOT)
+	DECLARE_GLOBAL_DATA_PTR;
+#endif
 
 #undef	MAX
 #define MAX(a, b)  (((a) > (b)) ? (a) : (b))
@@ -1213,6 +1221,7 @@ void cvmx_bootmem_phy_named_block_print(void)
 		cvmx_dprintf("No named bootmem blocks exist.\n");
 }
 
+
 int64_t cvmx_bootmem_phy_mem_list_init(uint64_t mem_size,
 				       uint32_t low_reserved_bytes,
 				       cvmx_bootmem_desc_t *desc_buffer)
@@ -1320,6 +1329,144 @@ frees_done:
 	return 1;
 }
 
+
+
+int64_t cvmx_bootmem_phy_mem_list_init_multi(uint8_t node_mask,
+					     uint32_t mem_sizes[],
+					     uint32_t low_reserved_bytes,
+					     cvmx_bootmem_desc_t *desc_buffer)
+{
+	uint64_t cur_block_addr;
+	uint64_t mem_size;
+	int64_t addr;
+	int i;
+	uint64_t node;	/* Make u64 to reduce type casting */
+
+#if defined(CVMX_BUILD_FOR_UBOOT)
+	mem_sizes[0] = gd->ram_size / (1024 * 1024);
+#endif
+#ifdef DEBUG
+	cvmx_dprintf("cvmx_bootmem_phy_mem_list_init (arg desc ptr: %p, "
+		     "cvmx_bootmem_desc: 0x%llx)\n",
+		     desc_buffer, CAST_ULL(cvmx_bootmem_desc_addr));
+#endif
+	/*
+	 * Descriptor buffer needs to be in 32 bit addressable space to be
+	 * compatible with 32 bit applications
+	 */
+	if (!desc_buffer) {
+		cvmx_dprintf("ERROR: no memory for cvmx_bootmem descriptor provided\n");
+		return 0;
+	}
+	for (node = 0; node < CVMX_MAX_NODES; node++ ) {
+		if ((node_mask & (1 << node)) &&
+		    (mem_sizes[node] * (1024*1024)) > OCTEON_MAX_PHY_MEM_SIZE) {
+			mem_sizes[node] = OCTEON_MAX_PHY_MEM_SIZE / (1024*1024);
+			cvmx_dprintf("ERROR node#%lld: requested memory size too large, truncating to maximum size\n",
+				     CAST_ULL(node));
+		}
+	}
+
+	if (cvmx_bootmem_desc_addr)
+		return 1;
+
+	/* Initialize cvmx pointer to descriptor */
+#ifndef CVMX_BUILD_FOR_LINUX_HOST
+	cvmx_bootmem_init(cvmx_ptr_to_phys(desc_buffer));
+#else
+	cvmx_bootmem_init((unsigned long)desc_buffer);
+#endif
+
+	/* Fill the bootmem descriptor */
+	CVMX_BOOTMEM_DESC_SET_FIELD(lock, 0);
+	CVMX_BOOTMEM_DESC_SET_FIELD(flags, 0);
+	CVMX_BOOTMEM_DESC_SET_FIELD(head_addr, 0);
+	CVMX_BOOTMEM_DESC_SET_FIELD(major_version, CVMX_BOOTMEM_DESC_MAJ_VER);
+	CVMX_BOOTMEM_DESC_SET_FIELD(minor_version, CVMX_BOOTMEM_DESC_MIN_VER);
+	CVMX_BOOTMEM_DESC_SET_FIELD(app_data_addr, 0);
+	CVMX_BOOTMEM_DESC_SET_FIELD(app_data_size, 0);
+
+	for (node = 0; node < CVMX_MAX_NODES; node++ ) {
+		if (!(node_mask & (1 << node)))
+			continue;	/* skip undetected nodes */
+
+		if (node != 0)	/* do not reserve memory on remote nodes */
+			low_reserved_bytes = 0;
+		mem_size = (uint64_t)mem_sizes[node] * (1024*1024);	/* MBytes */
+		/*
+		* Set up global pointer to start of list, exclude low 64k for exception
+		* vectors, space for global descriptor
+		*/
+
+		cur_block_addr = (OCTEON_DDR0_BASE + low_reserved_bytes) |
+					(node << CVMX_NODE_MEM_SHIFT);
+
+		if (mem_size <= OCTEON_DDR0_SIZE) {
+			__cvmx_bootmem_phy_free(cur_block_addr,
+						mem_size - low_reserved_bytes,
+						0);
+			continue;
+		}
+
+		__cvmx_bootmem_phy_free(cur_block_addr,
+					OCTEON_DDR0_SIZE - low_reserved_bytes,
+					0);
+
+		mem_size -= OCTEON_DDR0_SIZE;
+
+		/* Add DDR2 block next if present */
+		if (mem_size > OCTEON_DDR1_SIZE) {
+			__cvmx_bootmem_phy_free(OCTEON_DDR1_BASE |
+						(node << CVMX_NODE_MEM_SHIFT),
+						OCTEON_DDR1_SIZE, 0);
+			__cvmx_bootmem_phy_free(OCTEON_DDR2_BASE |
+						(node << CVMX_NODE_MEM_SHIFT),
+						mem_size - OCTEON_DDR1_SIZE, 0);
+		} else {
+			__cvmx_bootmem_phy_free(OCTEON_DDR1_BASE |
+						(node << CVMX_NODE_MEM_SHIFT),
+						mem_size, 0);
+		}
+	}
+
+#ifdef DEBUG
+	cvmx_dprintf("%s: Initialize the named block\n", __func__);
+#endif
+	/* Initialize the named block structure */
+	CVMX_BOOTMEM_DESC_SET_FIELD(named_block_name_len, CVMX_BOOTMEM_NAME_LEN);
+	CVMX_BOOTMEM_DESC_SET_FIELD(named_block_num_blocks,
+				    CVMX_BOOTMEM_NUM_NAMED_BLOCKS);
+	CVMX_BOOTMEM_DESC_SET_FIELD(named_block_array_addr, 0);
+
+	/* Allocate this near the top of the low 256 MBytes of memory */
+	addr = cvmx_bootmem_phy_alloc(CVMX_BOOTMEM_NUM_NAMED_BLOCKS *
+				      sizeof(cvmx_bootmem_named_block_desc_t),
+				      0, 0x10000000, 0,
+				      CVMX_BOOTMEM_FLAG_END_ALLOC);
+	if (addr >= 0)
+		CVMX_BOOTMEM_DESC_SET_FIELD(named_block_array_addr, addr);
+
+#ifdef DEBUG
+	cvmx_dprintf("cvmx_bootmem_phy_mem_list_init: named_block_array_addr:"
+		     "0x%llx)\n", CAST_ULL(addr));
+#endif
+	if (!addr) {
+		cvmx_dprintf("FATAL ERROR: unable to allocate memory for "
+			     "bootmem descriptor!\n");
+		return 0;
+	}
+	for (i = 0; i < CVMX_BOOTMEM_NUM_NAMED_BLOCKS; i++) {
+		CVMX_BOOTMEM_NAMED_SET_FIELD(addr, base_addr, 0);
+		CVMX_BOOTMEM_NAMED_SET_FIELD(addr, size, 0);
+		addr += sizeof(cvmx_bootmem_named_block_desc_t);
+	}
+
+#ifdef DEBUG
+	cvmx_bootmem_phy_list_print();
+#endif
+	return 1;
+}
+
 int cvmx_bootmem_reserve_memory(uint64_t start_addr, uint64_t size,
 				const char *name, uint32_t flags)
 {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c b/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
index b60ec23..3c09cbe 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
@@ -43,7 +43,7 @@
  * Support functions for managing command queues used for
  * various hardware blocks.
  *
- * <hr>$Revision: 95258 $<hr>
+ * <hr>$Revision: 96722 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
@@ -203,6 +203,7 @@ cvmx_cmd_queue_result_t cvmx_cmd_queue_initialize(cvmx_cmd_queue_id_t queue_id,
 		return CVMX_CMD_QUEUE_SUCCESS;
 	}
 }
+EXPORT_SYMBOL(cvmx_cmd_queue_initialize);
 
 /**
  * Shutdown a queue a free it's command buffers to the FPA. The
@@ -229,7 +230,7 @@ cvmx_cmd_queue_result_t cvmx_cmd_queue_shutdown(cvmx_cmd_queue_id_t queue_id)
 	__cvmx_cmd_queue_lock(queue_id, qptr);
 	if (qptr->base_ptr_div128) {
 		if (octeon_has_feature(OCTEON_FEATURE_FPA3))
-			cvmx_fpa_free_aura(cvmx_phys_to_ptr((uint64_t) qptr->base_ptr_div128 << 7),
+			cvmx_fpa3_free_aura(cvmx_phys_to_ptr((uint64_t) qptr->base_ptr_div128 << 7),
 					   0, qptr->fpa_pool, 0);
 		else
 			cvmx_fpa1_free(cvmx_phys_to_ptr((uint64_t) qptr->base_ptr_div128 << 7),
@@ -240,6 +241,7 @@ cvmx_cmd_queue_result_t cvmx_cmd_queue_shutdown(cvmx_cmd_queue_id_t queue_id)
 
 	return CVMX_CMD_QUEUE_SUCCESS;
 }
+EXPORT_SYMBOL(cvmx_cmd_queue_shutdown);
 
 /**
  * Return the number of command words pending in the queue. This
@@ -323,3 +325,4 @@ void *cvmx_cmd_queue_buffer(cvmx_cmd_queue_id_t queue_id)
 	else
 		return NULL;
 }
+EXPORT_SYMBOL(cvmx_cmd_queue_buffer);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c b/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
index a15b31a..1f0dee3 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
@@ -43,7 +43,7 @@
  * Interface to the PCI / PCIe DMA engines. These are only avialable
  * on chips with PCI / PCIe.
  *
- * <hr>$Revision: 95258 $<hr>
+ * <hr>$Revision: 95866 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
@@ -104,10 +104,8 @@ int cvmx_dma_engine_initialize(void)
 	 */
 	cvmx_fpa_global_initialize();
 	if(buffer_cnt != 0) {
-		if (!OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-			__cvmx_helper_initialize_fpa_pool(pool, pool_size,
-						buffer_cnt, "Dma Cmd Buffers");
-		}
+		__cvmx_helper_initialize_fpa_pool(pool, pool_size,
+					buffer_cnt, "Dma Cmd Buffers");
 	}
 #endif
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-error-trees.c b/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
index cd7f735..ea927f3 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-error-trees.c
@@ -9898,6 +9898,808 @@ static struct cvmx_error_muxchild error_tree_cnf71xx =
 			{0}}},
 		{0}}
 	};
+static struct cvmx_error_muxchild error_tree_cn70xxp1 =
+	{0x0000000000000000ull /* CVMX_ROOT */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
+		{1, 0 /* root */, (struct cvmx_error_muxchild[]){
+			{CVMX_ADD_IO_SEG(0x0001070000000000ull) + ((0) & 63) * 8 /* CVMX_CIU_INTX_SUM0(0) */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
+				{1, 60 /* powiq */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001670000000238ull) /* CVMX_POW_IQ_INT */, CVMX_ADD_IO_SEG(0x0001670000000240ull) /* CVMX_POW_IQ_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "POW_IQ_INT[IQ_INT]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{0}}
+			},
+			{CVMX_ADD_IO_SEG(0x0001070000000108ull) /* CVMX_CIU_INT_SUM1 */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
+				{1, 24 /* l2c */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x000107000000E000ull) /* CVMX_CIU_CIB_L2C_RAWX(0) */, CVMX_ADD_IO_SEG(0x000107000000E100ull) /* CVMX_CIU_CIB_L2C_ENX(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_L2C, 0, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_L2DSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 1, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_L2DDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 2, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_SBFSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 3, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_SBFDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 4, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_FBFSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 5, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_FBFDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 6, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_TAGSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 7, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_TAGDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 8, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_NOWAY]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 9, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_HOLEWR]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 10, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_HOLERD]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 11, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_BIGWR]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 12, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_BIGRD]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 13, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_WRDISLMC]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 14, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_RDDISLMC]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 15, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_RTGSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 16, 0, "CIU_CIB_L2C_RAWX(0)[TADX_INT_RTGDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 17, 0, "CIU_CIB_L2C_RAWX(0)[MCIX_INT_VBFSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 18, 0, "CIU_CIB_L2C_RAWX(0)[MCIX_INT_VBFDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 19, 0, "CIU_CIB_L2C_RAWX(0)[CBCX_INT_RSDSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 20, 0, "CIU_CIB_L2C_RAWX(0)[CBCX_INT_RSDDBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 21, 0, "CIU_CIB_L2C_RAWX(0)[CBCX_INT_IOCCMDSBE]"},
+							{1, 1, CVMX_ERROR_GROUP_L2C, 22, 0, "CIU_CIB_L2C_RAWX(0)[CBCX_INT_IOCCMDDBE]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 25 /* ipd */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00014F0000000168ull) /* CVMX_IPD_INT_SUM */, CVMX_ADD_IO_SEG(0x00014F0000000160ull) /* CVMX_IPD_INT_ENB */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "IPD_INT_SUM[PRC_PAR0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "IPD_INT_SUM[PRC_PAR1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "IPD_INT_SUM[PRC_PAR2]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "IPD_INT_SUM[PRC_PAR3]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "IPD_INT_SUM[BP_SUB]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "IPD_INT_SUM[DC_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "IPD_INT_SUM[CC_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "IPD_INT_SUM[C_COLL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "IPD_INT_SUM[D_COLL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "IPD_INT_SUM[BC_OVR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 23 /* pow */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001670000000218ull) /* CVMX_POW_ECC_ERR */, CVMX_ADD_IO_SEG(0x0001670000000218ull) /* CVMX_POW_ECC_ERR */, (struct cvmx_error_regbit[]){
+							{1, 0, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "POW_ECC_ERR[SBE]"},
+							{1, 0, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "POW_ECC_ERR[DBE]"},
+							{1, 0, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "POW_ECC_ERR[RPE]"},
+							{1, 0, CVMX_ERROR_GROUP_INTERNAL, 16, 0, "POW_ECC_ERR[IOP]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 30 /* rad */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180070000088ull) /* CVMX_RAD_REG_ERROR */, CVMX_ADD_IO_SEG(0x0001180070000090ull) /* CVMX_RAD_REG_INT_MASK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "RAD_REG_ERROR[DOORBELL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 26 /* pip */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800A0000008ull) /* CVMX_PIP_INT_REG */, CVMX_ADD_IO_SEG(0x00011800A0000010ull) /* CVMX_PIP_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "PIP_INT_REG[PRTNXA]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "PIP_INT_REG[BADTAG]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "PIP_INT_REG[SKPRUNT]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "PIP_INT_REG[TODOOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "PIP_INT_REG[FEPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "PIP_INT_REG[BEPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "PIP_INT_REG[PUNYERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 27 /* pko */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180050000088ull) /* CVMX_PKO_REG_ERROR */, CVMX_ADD_IO_SEG(0x0001180050000090ull) /* CVMX_PKO_REG_INT_MASK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PKO_REG_ERROR[PARITY]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "PKO_REG_ERROR[DOORBELL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "PKO_REG_ERROR[CURRZERO]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 50 /* pem2 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800C0000428ull) + ((2) & 3) * 0x1000000ull /* CVMX_PEMX_INT_SUM(2) */, CVMX_ADD_IO_SEG(0x00011800C0000430ull) + ((2) & 3) * 0x1000000ull /* CVMX_PEMX_INT_ENB(2) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_PCI, 1, 2, "PEMX_INT_SUM(2)[SE]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 4, 2, "PEMX_INT_SUM(2)[UP_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 5, 2, "PEMX_INT_SUM(2)[UP_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 6, 2, "PEMX_INT_SUM(2)[UP_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 7, 2, "PEMX_INT_SUM(2)[UN_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 8, 2, "PEMX_INT_SUM(2)[UN_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 9, 2, "PEMX_INT_SUM(2)[UN_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 11, 2, "PEMX_INT_SUM(2)[RDLK]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 12, 2, "PEMX_INT_SUM(2)[CRS_ER]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 13, 2, "PEMX_INT_SUM(2)[CRS_DR]"},
+							{0}},
+						(struct cvmx_error_childbit[]){
+						{1, 10 /* exc */, (struct cvmx_error_muxchild[]){
+							{CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + ((2) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO(2) */, CVMX_ADD_IO_SEG(0x00011800C00000A0ull) + ((2) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO_EN(2) */, (struct cvmx_error_regbit[]){
+									{1, 1, CVMX_ERROR_GROUP_PCI, 0, 2, "PEMX_DBG_INFO(2)[SPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 2, 2, "PEMX_DBG_INFO(2)[RTLPLLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 3, 2, "PEMX_DBG_INFO(2)[RECRCE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 4, 2, "PEMX_DBG_INFO(2)[RPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 5, 2, "PEMX_DBG_INFO(2)[RCEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 6, 2, "PEMX_DBG_INFO(2)[RNFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 7, 2, "PEMX_DBG_INFO(2)[RFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 8, 2, "PEMX_DBG_INFO(2)[RPMERC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 9, 2, "PEMX_DBG_INFO(2)[RPTAMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 10, 2, "PEMX_DBG_INFO(2)[RUMEP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 11, 2, "PEMX_DBG_INFO(2)[RVDM]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 12, 2, "PEMX_DBG_INFO(2)[ACTO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 13, 2, "PEMX_DBG_INFO(2)[RTE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 14, 2, "PEMX_DBG_INFO(2)[MRE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 15, 2, "PEMX_DBG_INFO(2)[RDWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 16, 2, "PEMX_DBG_INFO(2)[RTWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 17, 2, "PEMX_DBG_INFO(2)[DPEOOSD]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 18, 2, "PEMX_DBG_INFO(2)[FCPVWT]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 19, 2, "PEMX_DBG_INFO(2)[RPE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 20, 2, "PEMX_DBG_INFO(2)[FCUV]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 21, 2, "PEMX_DBG_INFO(2)[RQO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 22, 2, "PEMX_DBG_INFO(2)[RAUC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 23, 2, "PEMX_DBG_INFO(2)[RACUR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 24, 2, "PEMX_DBG_INFO(2)[RACCA]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 25, 2, "PEMX_DBG_INFO(2)[CAAR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 26, 2, "PEMX_DBG_INFO(2)[RARWDNS]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 27, 2, "PEMX_DBG_INFO(2)[RAMTLP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 28, 2, "PEMX_DBG_INFO(2)[RACPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 29, 2, "PEMX_DBG_INFO(2)[RAWWPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 30, 2, "PEMX_DBG_INFO(2)[ECRC_E]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 31, 2, "PEMX_DBG_INFO(2)[RTRY_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 32, 2, "PEMX_DBG_INFO(2)[HDRQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 33, 2, "PEMX_DBG_INFO(2)[DATQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 34, 2, "PEMX_DBG_INFO(2)[P_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 35, 2, "PEMX_DBG_INFO(2)[P_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 36, 2, "PEMX_DBG_INFO(2)[P_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 37, 2, "PEMX_DBG_INFO(2)[P_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 38, 2, "PEMX_DBG_INFO(2)[N_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 39, 2, "PEMX_DBG_INFO(2)[N_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 40, 2, "PEMX_DBG_INFO(2)[N_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 41, 2, "PEMX_DBG_INFO(2)[N_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 42, 2, "PEMX_DBG_INFO(2)[C_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 43, 2, "PEMX_DBG_INFO(2)[C_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 44, 2, "PEMX_DBG_INFO(2)[C_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 45, 2, "PEMX_DBG_INFO(2)[C_C_DBE]"},
+									{0}},
+								NULL /*cvmx_error_childbit*/
+							},
+							{0}}},
+						{0}}
+					},
+					{0}}},
+				{1, 48 /* pem0 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800C0000428ull) + ((0) & 3) * 0x1000000ull /* CVMX_PEMX_INT_SUM(0) */, CVMX_ADD_IO_SEG(0x00011800C0000430ull) + ((0) & 3) * 0x1000000ull /* CVMX_PEMX_INT_ENB(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_PCI, 1, 0, "PEMX_INT_SUM(0)[SE]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 4, 0, "PEMX_INT_SUM(0)[UP_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 5, 0, "PEMX_INT_SUM(0)[UP_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 6, 0, "PEMX_INT_SUM(0)[UP_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 7, 0, "PEMX_INT_SUM(0)[UN_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 8, 0, "PEMX_INT_SUM(0)[UN_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 9, 0, "PEMX_INT_SUM(0)[UN_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 11, 0, "PEMX_INT_SUM(0)[RDLK]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 12, 0, "PEMX_INT_SUM(0)[CRS_ER]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 13, 0, "PEMX_INT_SUM(0)[CRS_DR]"},
+							{0}},
+						(struct cvmx_error_childbit[]){
+						{1, 10 /* exc */, (struct cvmx_error_muxchild[]){
+							{CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + ((0) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO(0) */, CVMX_ADD_IO_SEG(0x00011800C00000A0ull) + ((0) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO_EN(0) */, (struct cvmx_error_regbit[]){
+									{1, 1, CVMX_ERROR_GROUP_PCI, 0, 0, "PEMX_DBG_INFO(0)[SPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 2, 0, "PEMX_DBG_INFO(0)[RTLPLLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 3, 0, "PEMX_DBG_INFO(0)[RECRCE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 4, 0, "PEMX_DBG_INFO(0)[RPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 5, 0, "PEMX_DBG_INFO(0)[RCEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 6, 0, "PEMX_DBG_INFO(0)[RNFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 7, 0, "PEMX_DBG_INFO(0)[RFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 8, 0, "PEMX_DBG_INFO(0)[RPMERC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 9, 0, "PEMX_DBG_INFO(0)[RPTAMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 10, 0, "PEMX_DBG_INFO(0)[RUMEP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 11, 0, "PEMX_DBG_INFO(0)[RVDM]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 12, 0, "PEMX_DBG_INFO(0)[ACTO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 13, 0, "PEMX_DBG_INFO(0)[RTE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 14, 0, "PEMX_DBG_INFO(0)[MRE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 15, 0, "PEMX_DBG_INFO(0)[RDWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 16, 0, "PEMX_DBG_INFO(0)[RTWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 17, 0, "PEMX_DBG_INFO(0)[DPEOOSD]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 18, 0, "PEMX_DBG_INFO(0)[FCPVWT]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 19, 0, "PEMX_DBG_INFO(0)[RPE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 20, 0, "PEMX_DBG_INFO(0)[FCUV]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 21, 0, "PEMX_DBG_INFO(0)[RQO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 22, 0, "PEMX_DBG_INFO(0)[RAUC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 23, 0, "PEMX_DBG_INFO(0)[RACUR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 24, 0, "PEMX_DBG_INFO(0)[RACCA]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 25, 0, "PEMX_DBG_INFO(0)[CAAR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 26, 0, "PEMX_DBG_INFO(0)[RARWDNS]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 27, 0, "PEMX_DBG_INFO(0)[RAMTLP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 28, 0, "PEMX_DBG_INFO(0)[RACPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 29, 0, "PEMX_DBG_INFO(0)[RAWWPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 30, 0, "PEMX_DBG_INFO(0)[ECRC_E]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 31, 0, "PEMX_DBG_INFO(0)[RTRY_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 32, 0, "PEMX_DBG_INFO(0)[HDRQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 33, 0, "PEMX_DBG_INFO(0)[DATQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 34, 0, "PEMX_DBG_INFO(0)[P_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 35, 0, "PEMX_DBG_INFO(0)[P_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 36, 0, "PEMX_DBG_INFO(0)[P_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 37, 0, "PEMX_DBG_INFO(0)[P_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 38, 0, "PEMX_DBG_INFO(0)[N_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 39, 0, "PEMX_DBG_INFO(0)[N_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 40, 0, "PEMX_DBG_INFO(0)[N_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 41, 0, "PEMX_DBG_INFO(0)[N_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 42, 0, "PEMX_DBG_INFO(0)[C_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 43, 0, "PEMX_DBG_INFO(0)[C_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 44, 0, "PEMX_DBG_INFO(0)[C_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 45, 0, "PEMX_DBG_INFO(0)[C_C_DBE]"},
+									{0}},
+								NULL /*cvmx_error_childbit*/
+							},
+							{0}}},
+						{0}}
+					},
+					{0}}},
+				{1, 49 /* pem1 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800C0000428ull) + ((1) & 3) * 0x1000000ull /* CVMX_PEMX_INT_SUM(1) */, CVMX_ADD_IO_SEG(0x00011800C0000430ull) + ((1) & 3) * 0x1000000ull /* CVMX_PEMX_INT_ENB(1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_PCI, 1, 1, "PEMX_INT_SUM(1)[SE]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 4, 1, "PEMX_INT_SUM(1)[UP_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 5, 1, "PEMX_INT_SUM(1)[UP_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 6, 1, "PEMX_INT_SUM(1)[UP_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 7, 1, "PEMX_INT_SUM(1)[UN_B1]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 8, 1, "PEMX_INT_SUM(1)[UN_B2]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 9, 1, "PEMX_INT_SUM(1)[UN_BX]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 11, 1, "PEMX_INT_SUM(1)[RDLK]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 12, 1, "PEMX_INT_SUM(1)[CRS_ER]"},
+							{1, 1, CVMX_ERROR_GROUP_PCI, 13, 1, "PEMX_INT_SUM(1)[CRS_DR]"},
+							{0}},
+						(struct cvmx_error_childbit[]){
+						{1, 10 /* exc */, (struct cvmx_error_muxchild[]){
+							{CVMX_ADD_IO_SEG(0x00011800C00000D0ull) + ((1) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO(1) */, CVMX_ADD_IO_SEG(0x00011800C00000A0ull) + ((1) & 3) * 0x1000000ull /* CVMX_PEMX_DBG_INFO_EN(1) */, (struct cvmx_error_regbit[]){
+									{1, 1, CVMX_ERROR_GROUP_PCI, 0, 1, "PEMX_DBG_INFO(1)[SPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 2, 1, "PEMX_DBG_INFO(1)[RTLPLLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 3, 1, "PEMX_DBG_INFO(1)[RECRCE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 4, 1, "PEMX_DBG_INFO(1)[RPOISON]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 5, 1, "PEMX_DBG_INFO(1)[RCEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 6, 1, "PEMX_DBG_INFO(1)[RNFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 7, 1, "PEMX_DBG_INFO(1)[RFEMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 8, 1, "PEMX_DBG_INFO(1)[RPMERC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 9, 1, "PEMX_DBG_INFO(1)[RPTAMRC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 10, 1, "PEMX_DBG_INFO(1)[RUMEP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 11, 1, "PEMX_DBG_INFO(1)[RVDM]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 12, 1, "PEMX_DBG_INFO(1)[ACTO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 13, 1, "PEMX_DBG_INFO(1)[RTE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 14, 1, "PEMX_DBG_INFO(1)[MRE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 15, 1, "PEMX_DBG_INFO(1)[RDWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 16, 1, "PEMX_DBG_INFO(1)[RTWDLE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 17, 1, "PEMX_DBG_INFO(1)[DPEOOSD]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 18, 1, "PEMX_DBG_INFO(1)[FCPVWT]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 19, 1, "PEMX_DBG_INFO(1)[RPE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 20, 1, "PEMX_DBG_INFO(1)[FCUV]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 21, 1, "PEMX_DBG_INFO(1)[RQO]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 22, 1, "PEMX_DBG_INFO(1)[RAUC]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 23, 1, "PEMX_DBG_INFO(1)[RACUR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 24, 1, "PEMX_DBG_INFO(1)[RACCA]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 25, 1, "PEMX_DBG_INFO(1)[CAAR]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 26, 1, "PEMX_DBG_INFO(1)[RARWDNS]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 27, 1, "PEMX_DBG_INFO(1)[RAMTLP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 28, 1, "PEMX_DBG_INFO(1)[RACPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 29, 1, "PEMX_DBG_INFO(1)[RAWWPP]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 30, 1, "PEMX_DBG_INFO(1)[ECRC_E]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 31, 1, "PEMX_DBG_INFO(1)[RTRY_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 32, 1, "PEMX_DBG_INFO(1)[HDRQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 33, 1, "PEMX_DBG_INFO(1)[DATQ_PE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 34, 1, "PEMX_DBG_INFO(1)[P_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 35, 1, "PEMX_DBG_INFO(1)[P_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 36, 1, "PEMX_DBG_INFO(1)[P_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 37, 1, "PEMX_DBG_INFO(1)[P_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 38, 1, "PEMX_DBG_INFO(1)[N_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 39, 1, "PEMX_DBG_INFO(1)[N_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 40, 1, "PEMX_DBG_INFO(1)[N_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 41, 1, "PEMX_DBG_INFO(1)[N_C_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 42, 1, "PEMX_DBG_INFO(1)[C_D_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 43, 1, "PEMX_DBG_INFO(1)[C_D_DBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 44, 1, "PEMX_DBG_INFO(1)[C_C_SBE]"},
+									{1, 1, CVMX_ERROR_GROUP_PCI, 45, 1, "PEMX_DBG_INFO(1)[C_C_DBE]"},
+									{0}},
+								NULL /*cvmx_error_childbit*/
+							},
+							{0}}},
+						{0}}
+					},
+					{0}}},
+				{1, 22 /* fpa */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180028000040ull) /* CVMX_FPA_INT_SUM */, CVMX_ADD_IO_SEG(0x0001180028000048ull) /* CVMX_FPA_INT_ENB */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "FPA_INT_SUM[FED0_SBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "FPA_INT_SUM[FED0_DBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "FPA_INT_SUM[FED1_SBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "FPA_INT_SUM[FED1_DBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "FPA_INT_SUM[Q0_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "FPA_INT_SUM[Q0_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 6, 0, "FPA_INT_SUM[Q0_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 7, 0, "FPA_INT_SUM[Q1_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "FPA_INT_SUM[Q1_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "FPA_INT_SUM[Q1_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 10, 0, "FPA_INT_SUM[Q2_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 11, 0, "FPA_INT_SUM[Q2_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "FPA_INT_SUM[Q2_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 13, 0, "FPA_INT_SUM[Q3_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 14, 0, "FPA_INT_SUM[Q3_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 15, 0, "FPA_INT_SUM[Q3_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 16, 0, "FPA_INT_SUM[Q4_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 17, 0, "FPA_INT_SUM[Q4_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 18, 0, "FPA_INT_SUM[Q4_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 19, 0, "FPA_INT_SUM[Q5_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 20, 0, "FPA_INT_SUM[Q5_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 21, 0, "FPA_INT_SUM[Q5_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 22, 0, "FPA_INT_SUM[Q6_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 23, 0, "FPA_INT_SUM[Q6_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 24, 0, "FPA_INT_SUM[Q6_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 25, 0, "FPA_INT_SUM[Q7_UND]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 26, 0, "FPA_INT_SUM[Q7_COFF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 27, 0, "FPA_INT_SUM[Q7_PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 28, 0, "FPA_INT_SUM[POOL0TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 29, 0, "FPA_INT_SUM[POOL1TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 30, 0, "FPA_INT_SUM[POOL2TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 31, 0, "FPA_INT_SUM[POOL3TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 32, 0, "FPA_INT_SUM[POOL4TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 33, 0, "FPA_INT_SUM[POOL5TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 34, 0, "FPA_INT_SUM[POOL6TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 35, 0, "FPA_INT_SUM[POOL7TH]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 36, 0, "FPA_INT_SUM[FREE0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 37, 0, "FPA_INT_SUM[FREE1]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 38, 0, "FPA_INT_SUM[FREE2]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 39, 0, "FPA_INT_SUM[FREE3]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 40, 0, "FPA_INT_SUM[FREE4]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 41, 0, "FPA_INT_SUM[FREE5]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 42, 0, "FPA_INT_SUM[FREE6]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 43, 0, "FPA_INT_SUM[FREE7]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 49, 0, "FPA_INT_SUM[PADDR_E]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 20 /* mio */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800000000A0ull) /* CVMX_MIO_BOOT_ERR */, CVMX_ADD_IO_SEG(0x00011800000000A8ull) /* CVMX_MIO_BOOT_INT */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "MIO_BOOT_ERR[ADR_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "MIO_BOOT_ERR[WAIT_ERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 32 /* dfa */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180037000028ull) /* CVMX_DFA_ERROR */, CVMX_ADD_IO_SEG(0x0001180037000030ull) /* CVMX_DFA_INTMSK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DFA_ERROR[DBLOVF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "DFA_ERROR[DC0PERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 13, 0, "DFA_ERROR[DLC0_OVFERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 17, 0, "DFA_ERROR[DFANXM]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 18, 0, "DFA_ERROR[REPLERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 29 /* tim */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180058000088ull) /* CVMX_TIM_REG_ERROR */, CVMX_ADD_IO_SEG(0x0001180058000090ull) /* CVMX_TIM_REG_INT_MASK */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "TIM_REG_ERROR[MASK]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 52 /* lmc0 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x000107000000E200ull) /* CVMX_CIU_CIB_LMCX_RAWX(0,0) */, CVMX_ADD_IO_SEG(0x000107000000E300ull) /* CVMX_CIU_CIB_LMCX_ENX(0,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_LMC, 1, 0, "CIU_CIB_LMCX_RAWX(0,0)[INT_SEC_ERRX]"},
+							{1, 1, CVMX_ERROR_GROUP_LMC, 5, 0, "CIU_CIB_LMCX_RAWX(0,0)[INT_DED_ERRX]"},
+							{1, 1, CVMX_ERROR_GROUP_LMC, 0, 0, "CIU_CIB_LMCX_RAWX(0,0)[INT_NXM_WR_ERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 31 /* key */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180020000000ull) /* CVMX_KEY_INT_SUM */, CVMX_ADD_IO_SEG(0x0001180020000008ull) /* CVMX_KEY_INT_ENB */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "KEY_INT_SUM[KEY_SBE]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "KEY_INT_SUM[KEY_DBE]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 63 /* rst */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x000107000000E400ull) /* CVMX_CIU_CIB_RST_RAWX(0) */, CVMX_ADD_IO_SEG(0x000107000000E500ull) /* CVMX_CIU_CIB_RST_ENX(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "CIU_CIB_RST_RAWX(0)[INT_LINKX]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "CIU_CIB_RST_RAWX(0)[INT_PERSTX]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 21 /* iob */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800F0000058ull) /* CVMX_IOB_INT_SUM */, CVMX_ADD_IO_SEG(0x00011800F0000060ull) /* CVMX_IOB_INT_ENB */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "IOB_INT_SUM[NP_SOP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "IOB_INT_SUM[NP_EOP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "IOB_INT_SUM[P_SOP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "IOB_INT_SUM[P_EOP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 4, 0, "IOB_INT_SUM[NP_DAT]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 5, 0, "IOB_INT_SUM[P_DAT]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 46 /* agl */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011800E0000518ull) /* CVMX_AGL_GMX_BAD_REG */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 32, 0, "AGL_GMX_BAD_REG[OVRFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 33, 0, "AGL_GMX_BAD_REG[TXPOP]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 34, 0, "AGL_GMX_BAD_REG[TXPSH]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 2, 0, "AGL_GMX_BAD_REG[OUT_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 22, 0, "AGL_GMX_BAD_REG[LOSTSTAT]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800E0000000ull) + ((0) & 0) * 2048 /* CVMX_AGL_GMX_RXX_INT_REG(0) */, CVMX_ADD_IO_SEG(0x00011800E0000008ull) + ((0) & 0) * 2048 /* CVMX_AGL_GMX_RXX_INT_EN(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 8, 0, "AGL_GMX_RXX_INT_REG(0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 10, 0, "AGL_GMX_RXX_INT_REG(0)[OVRERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800E0000500ull) /* CVMX_AGL_GMX_TX_INT_REG */, CVMX_ADD_IO_SEG(0x00011800E0000508ull) /* CVMX_AGL_GMX_TX_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 0, 0, "AGL_GMX_TX_INT_REG[PKO_NXA]"},
+							{1, 1, CVMX_ERROR_GROUP_MGMT_PORT, 2, 0, "AGL_GMX_TX_INT_REG[UNDFLW]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 36 /* agx0 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180008000518ull) + ((0) & 1) * 0x8000000ull /* CVMX_GMXX_BAD_REG(0) */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "GMXX_BAD_REG(0)[OUT_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 0, "GMXX_BAD_REG(0)[LOSTSTAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 0, "GMXX_BAD_REG(0)[STATOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 0, "GMXX_BAD_REG(0)[INB_NXA]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((0) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(0,0) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((0) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(0,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 0, "GMXX_RXX_INT_REG(0,0)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 0, "GMXX_RXX_INT_REG(0,0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 0, "GMXX_RXX_INT_REG(0,0)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 0, "GMXX_RXX_INT_REG(0,0)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 0, "GMXX_RXX_INT_REG(0,0)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 0, "GMXX_RXX_INT_REG(0,0)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 0, "GMXX_RXX_INT_REG(0,0)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 0, "GMXX_RXX_INT_REG(0,0)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 0, "GMXX_RXX_INT_REG(0,0)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 0, "GMXX_RXX_INT_REG(0,0)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 0, "GMXX_RXX_INT_REG(0,0)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 0, "GMXX_RXX_INT_REG(0,0)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 0, "GMXX_RXX_INT_REG(0,0)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((1) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(1,0) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((1) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(1,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 1, "GMXX_RXX_INT_REG(1,0)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 1, "GMXX_RXX_INT_REG(1,0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 1, "GMXX_RXX_INT_REG(1,0)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 1, "GMXX_RXX_INT_REG(1,0)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 1, "GMXX_RXX_INT_REG(1,0)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 1, "GMXX_RXX_INT_REG(1,0)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 1, "GMXX_RXX_INT_REG(1,0)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 1, "GMXX_RXX_INT_REG(1,0)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 1, "GMXX_RXX_INT_REG(1,0)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 1, "GMXX_RXX_INT_REG(1,0)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 1, "GMXX_RXX_INT_REG(1,0)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 1, "GMXX_RXX_INT_REG(1,0)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 1, "GMXX_RXX_INT_REG(1,0)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((2) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(2,0) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((2) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(2,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 2, "GMXX_RXX_INT_REG(2,0)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 2, "GMXX_RXX_INT_REG(2,0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 2, "GMXX_RXX_INT_REG(2,0)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 2, "GMXX_RXX_INT_REG(2,0)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 2, "GMXX_RXX_INT_REG(2,0)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 2, "GMXX_RXX_INT_REG(2,0)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 2, "GMXX_RXX_INT_REG(2,0)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 2, "GMXX_RXX_INT_REG(2,0)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 2, "GMXX_RXX_INT_REG(2,0)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 2, "GMXX_RXX_INT_REG(2,0)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 2, "GMXX_RXX_INT_REG(2,0)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 2, "GMXX_RXX_INT_REG(2,0)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 2, "GMXX_RXX_INT_REG(2,0)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((3) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(3,0) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((3) & 3) + ((0) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(3,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 3, "GMXX_RXX_INT_REG(3,0)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 3, "GMXX_RXX_INT_REG(3,0)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 3, "GMXX_RXX_INT_REG(3,0)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 3, "GMXX_RXX_INT_REG(3,0)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 3, "GMXX_RXX_INT_REG(3,0)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 3, "GMXX_RXX_INT_REG(3,0)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 3, "GMXX_RXX_INT_REG(3,0)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 3, "GMXX_RXX_INT_REG(3,0)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 3, "GMXX_RXX_INT_REG(3,0)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 3, "GMXX_RXX_INT_REG(3,0)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 3, "GMXX_RXX_INT_REG(3,0)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 3, "GMXX_RXX_INT_REG(3,0)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 3, "GMXX_RXX_INT_REG(3,0)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000500ull) + ((0) & 1) * 0x8000000ull /* CVMX_GMXX_TX_INT_REG(0) */, CVMX_ADD_IO_SEG(0x0001180008000508ull) + ((0) & 1) * 0x8000000ull /* CVMX_GMXX_TX_INT_EN(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 0, 0, "GMXX_TX_INT_REG(0)[PKO_NXA]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "GMXX_TX_INT_REG(0)[UNDFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 0, "GMXX_TX_INT_REG(0)[PTP_LOST]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((0) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(0,0) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((0) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(0,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "PCSX_INTX_REG(0,0)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 0, "PCSX_INTX_REG(0,0)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 0, "PCSX_INTX_REG(0,0)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 0, "PCSX_INTX_REG(0,0)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 0, "PCSX_INTX_REG(0,0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 0, "PCSX_INTX_REG(0,0)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 0, "PCSX_INTX_REG(0,0)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 0, "PCSX_INTX_REG(0,0)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 0, "PCSX_INTX_REG(0,0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((1) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(1,0) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((1) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(1,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 1, "PCSX_INTX_REG(1,0)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 1, "PCSX_INTX_REG(1,0)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 1, "PCSX_INTX_REG(1,0)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 1, "PCSX_INTX_REG(1,0)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 1, "PCSX_INTX_REG(1,0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 1, "PCSX_INTX_REG(1,0)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 1, "PCSX_INTX_REG(1,0)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 1, "PCSX_INTX_REG(1,0)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 1, "PCSX_INTX_REG(1,0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((2) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(2,0) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((2) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(2,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 2, "PCSX_INTX_REG(2,0)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 2, "PCSX_INTX_REG(2,0)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 2, "PCSX_INTX_REG(2,0)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 2, "PCSX_INTX_REG(2,0)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 2, "PCSX_INTX_REG(2,0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 2, "PCSX_INTX_REG(2,0)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 2, "PCSX_INTX_REG(2,0)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 2, "PCSX_INTX_REG(2,0)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 2, "PCSX_INTX_REG(2,0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((3) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(3,0) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((3) & 3) + ((0) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(3,0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 3, "PCSX_INTX_REG(3,0)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 3, "PCSX_INTX_REG(3,0)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 3, "PCSX_INTX_REG(3,0)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 3, "PCSX_INTX_REG(3,0)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 3, "PCSX_INTX_REG(3,0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 3, "PCSX_INTX_REG(3,0)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 3, "PCSX_INTX_REG(3,0)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 3, "PCSX_INTX_REG(3,0)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 3, "PCSX_INTX_REG(3,0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0000858ull) + ((0) & 0) * 0x8000000ull /* CVMX_PCSXX_INT_REG(0) */, CVMX_ADD_IO_SEG(0x00011800B0000860ull) + ((0) & 0) * 0x8000000ull /* CVMX_PCSXX_INT_EN_REG(0) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 0, 0, "PCSXX_INT_REG(0)[TXFLT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 0, "PCSXX_INT_REG(0)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 0, "PCSXX_INT_REG(0)[RXSYNBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 0, "PCSXX_INT_REG(0)[BITLCKLS]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 0, "PCSXX_INT_REG(0)[SYNLOS]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 0, "PCSXX_INT_REG(0)[ALGNLOS]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 6, 0, "PCSXX_INT_REG(0)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 37 /* agx1 */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001180008000518ull) + ((1) & 1) * 0x8000000ull /* CVMX_GMXX_BAD_REG(1) */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 16, "GMXX_BAD_REG(1)[OUT_OVR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 16, "GMXX_BAD_REG(1)[LOSTSTAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 16, "GMXX_BAD_REG(1)[STATOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 16, "GMXX_BAD_REG(1)[INB_NXA]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((0) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(0,1) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((0) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(0,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 16, "GMXX_RXX_INT_REG(0,1)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 16, "GMXX_RXX_INT_REG(0,1)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 16, "GMXX_RXX_INT_REG(0,1)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 16, "GMXX_RXX_INT_REG(0,1)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 16, "GMXX_RXX_INT_REG(0,1)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 16, "GMXX_RXX_INT_REG(0,1)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 16, "GMXX_RXX_INT_REG(0,1)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 16, "GMXX_RXX_INT_REG(0,1)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 16, "GMXX_RXX_INT_REG(0,1)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 16, "GMXX_RXX_INT_REG(0,1)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 16, "GMXX_RXX_INT_REG(0,1)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 16, "GMXX_RXX_INT_REG(0,1)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 16, "GMXX_RXX_INT_REG(0,1)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((1) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(1,1) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((1) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(1,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 17, "GMXX_RXX_INT_REG(1,1)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 17, "GMXX_RXX_INT_REG(1,1)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 17, "GMXX_RXX_INT_REG(1,1)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 17, "GMXX_RXX_INT_REG(1,1)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 17, "GMXX_RXX_INT_REG(1,1)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 17, "GMXX_RXX_INT_REG(1,1)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 17, "GMXX_RXX_INT_REG(1,1)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 17, "GMXX_RXX_INT_REG(1,1)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 17, "GMXX_RXX_INT_REG(1,1)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 17, "GMXX_RXX_INT_REG(1,1)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 17, "GMXX_RXX_INT_REG(1,1)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 17, "GMXX_RXX_INT_REG(1,1)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 17, "GMXX_RXX_INT_REG(1,1)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((2) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(2,1) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((2) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(2,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 18, "GMXX_RXX_INT_REG(2,1)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 18, "GMXX_RXX_INT_REG(2,1)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 18, "GMXX_RXX_INT_REG(2,1)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 18, "GMXX_RXX_INT_REG(2,1)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 18, "GMXX_RXX_INT_REG(2,1)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 18, "GMXX_RXX_INT_REG(2,1)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 18, "GMXX_RXX_INT_REG(2,1)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 18, "GMXX_RXX_INT_REG(2,1)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 18, "GMXX_RXX_INT_REG(2,1)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 18, "GMXX_RXX_INT_REG(2,1)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 18, "GMXX_RXX_INT_REG(2,1)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 18, "GMXX_RXX_INT_REG(2,1)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 18, "GMXX_RXX_INT_REG(2,1)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000000ull) + (((3) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_REG(3,1) */, CVMX_ADD_IO_SEG(0x0001180008000008ull) + (((3) & 3) + ((1) & 1) * 0x10000ull) * 2048 /* CVMX_GMXX_RXX_INT_EN(3,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 1, 19, "GMXX_RXX_INT_REG(3,1)[CAREXT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 19, "GMXX_RXX_INT_REG(3,1)[SKPERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 19, "GMXX_RXX_INT_REG(3,1)[OVRERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 19, "GMXX_RXX_INT_REG(3,1)[LOC_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 21, 19, "GMXX_RXX_INT_REG(3,1)[REM_FAULT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 22, 19, "GMXX_RXX_INT_REG(3,1)[BAD_SEQ]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 23, 19, "GMXX_RXX_INT_REG(3,1)[BAD_TERM]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 24, 19, "GMXX_RXX_INT_REG(3,1)[UNSOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 25, 19, "GMXX_RXX_INT_REG(3,1)[UNEOP]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 26, 19, "GMXX_RXX_INT_REG(3,1)[UNDAT]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 27, 19, "GMXX_RXX_INT_REG(3,1)[HG2FLD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 28, 19, "GMXX_RXX_INT_REG(3,1)[HG2CC]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 29, 19, "GMXX_RXX_INT_REG(3,1)[WOL]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001180008000500ull) + ((1) & 1) * 0x8000000ull /* CVMX_GMXX_TX_INT_REG(1) */, CVMX_ADD_IO_SEG(0x0001180008000508ull) + ((1) & 1) * 0x8000000ull /* CVMX_GMXX_TX_INT_EN(1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 0, 16, "GMXX_TX_INT_REG(1)[PKO_NXA]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 16, "GMXX_TX_INT_REG(1)[UNDFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 20, 16, "GMXX_TX_INT_REG(1)[PTP_LOST]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((0) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(0,1) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((0) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(0,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 16, "PCSX_INTX_REG(0,1)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 16, "PCSX_INTX_REG(0,1)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 16, "PCSX_INTX_REG(0,1)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 16, "PCSX_INTX_REG(0,1)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 16, "PCSX_INTX_REG(0,1)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 16, "PCSX_INTX_REG(0,1)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 16, "PCSX_INTX_REG(0,1)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 16, "PCSX_INTX_REG(0,1)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 16, "PCSX_INTX_REG(0,1)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((1) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(1,1) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((1) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(1,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 17, "PCSX_INTX_REG(1,1)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 17, "PCSX_INTX_REG(1,1)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 17, "PCSX_INTX_REG(1,1)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 17, "PCSX_INTX_REG(1,1)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 17, "PCSX_INTX_REG(1,1)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 17, "PCSX_INTX_REG(1,1)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 17, "PCSX_INTX_REG(1,1)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 17, "PCSX_INTX_REG(1,1)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 17, "PCSX_INTX_REG(1,1)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((2) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(2,1) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((2) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(2,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 18, "PCSX_INTX_REG(2,1)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 18, "PCSX_INTX_REG(2,1)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 18, "PCSX_INTX_REG(2,1)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 18, "PCSX_INTX_REG(2,1)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 18, "PCSX_INTX_REG(2,1)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 18, "PCSX_INTX_REG(2,1)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 18, "PCSX_INTX_REG(2,1)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 18, "PCSX_INTX_REG(2,1)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 18, "PCSX_INTX_REG(2,1)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x00011800B0001080ull) + (((3) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_REG(3,1) */, CVMX_ADD_IO_SEG(0x00011800B0001088ull) + (((3) & 3) + ((1) & 1) * 0x20000ull) * 1024 /* CVMX_PCSX_INTX_EN_REG(3,1) */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 2, 19, "PCSX_INTX_REG(3,1)[AN_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 3, 19, "PCSX_INTX_REG(3,1)[TXFIFU]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 4, 19, "PCSX_INTX_REG(3,1)[TXFIFO]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 5, 19, "PCSX_INTX_REG(3,1)[TXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 7, 19, "PCSX_INTX_REG(3,1)[RXBAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 8, 19, "PCSX_INTX_REG(3,1)[RXLOCK]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 9, 19, "PCSX_INTX_REG(3,1)[AN_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 10, 19, "PCSX_INTX_REG(3,1)[SYNC_BAD]"},
+							{1, 1, CVMX_ERROR_GROUP_ETHERNET, 12, 19, "PCSX_INTX_REG(3,1)[DBG_SYNC]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 34 /* sli */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x00011F0000010330ull) /* CVMX_PEXP_SLI_INT_SUM */, CVMX_ADD_IO_SEG(0x00011F0000013CD0ull) /* CVMX_PEXP_SLI_INT_ENB_CIU */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "PEXP_SLI_INT_SUM[RML_TO]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 2, 0, "PEXP_SLI_INT_SUM[BAR0_TO]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 3, 0, "PEXP_SLI_INT_SUM[IOB2BIG]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "PEXP_SLI_INT_SUM[M0_UP_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 9, 0, "PEXP_SLI_INT_SUM[M0_UP_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 10, 0, "PEXP_SLI_INT_SUM[M0_UN_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 11, 0, "PEXP_SLI_INT_SUM[M0_UN_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 12, 0, "PEXP_SLI_INT_SUM[M1_UP_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 13, 0, "PEXP_SLI_INT_SUM[M1_UP_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 14, 0, "PEXP_SLI_INT_SUM[M1_UN_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 15, 0, "PEXP_SLI_INT_SUM[M1_UN_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 20, 0, "PEXP_SLI_INT_SUM[M2_UP_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 21, 0, "PEXP_SLI_INT_SUM[M2_UP_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 22, 0, "PEXP_SLI_INT_SUM[M2_UN_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 23, 0, "PEXP_SLI_INT_SUM[M2_UN_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 24, 0, "PEXP_SLI_INT_SUM[M3_UP_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 25, 0, "PEXP_SLI_INT_SUM[M3_UP_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 26, 0, "PEXP_SLI_INT_SUM[M3_UN_B0]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 27, 0, "PEXP_SLI_INT_SUM[M3_UN_WI]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 48, 0, "PEXP_SLI_INT_SUM[PIDBOF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 49, 0, "PEXP_SLI_INT_SUM[PSLDBOF]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 50, 0, "PEXP_SLI_INT_SUM[POUT_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 51, 0, "PEXP_SLI_INT_SUM[PIN_BP]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 52, 0, "PEXP_SLI_INT_SUM[PGL_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 53, 0, "PEXP_SLI_INT_SUM[PDI_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 54, 0, "PEXP_SLI_INT_SUM[POP_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 55, 0, "PEXP_SLI_INT_SUM[PINS_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 56, 0, "PEXP_SLI_INT_SUM[SPRT0_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 57, 0, "PEXP_SLI_INT_SUM[SPRT1_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 58, 0, "PEXP_SLI_INT_SUM[SPRT2_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 59, 0, "PEXP_SLI_INT_SUM[SPRT3_ERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 60, 0, "PEXP_SLI_INT_SUM[ILL_PAD]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{1, 35 /* dpi */, (struct cvmx_error_muxchild[]){
+					{CVMX_ADD_IO_SEG(0x0001DF0000000008ull) /* CVMX_DPI_INT_REG */, CVMX_ADD_IO_SEG(0x0001DF0000000010ull) /* CVMX_DPI_INT_EN */, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DPI_INT_REG[NDERR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 1, 0, "DPI_INT_REG[NFOVR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 8, 0, "DPI_INT_REG[DMADBO]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 16, 0, "DPI_INT_REG[REQ_BADADR]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 17, 0, "DPI_INT_REG[REQ_BADLEN]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 18, 0, "DPI_INT_REG[REQ_OVRFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 19, 0, "DPI_INT_REG[REQ_UNDFLW]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 20, 0, "DPI_INT_REG[REQ_ANULL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 21, 0, "DPI_INT_REG[REQ_INULL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 22, 0, "DPI_INT_REG[REQ_BADFIL]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 24, 0, "DPI_INT_REG[SPRT0_RST]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 25, 0, "DPI_INT_REG[SPRT1_RST]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 26, 0, "DPI_INT_REG[SPRT2_RST]"},
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 27, 0, "DPI_INT_REG[SPRT3_RST]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001DF0000000078ull) /* CVMX_DPI_PKT_ERR_RSP */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DPI_PKT_ERR_RSP[PKTERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001DF0000000058ull) /* CVMX_DPI_REQ_ERR_RSP */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DPI_REQ_ERR_RSP[QERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{CVMX_ADD_IO_SEG(0x0001DF0000000060ull) /* CVMX_DPI_REQ_ERR_RST */, 0, (struct cvmx_error_regbit[]){
+							{1, 1, CVMX_ERROR_GROUP_INTERNAL, 0, 0, "DPI_REQ_ERR_RST[QERR]"},
+							{0}},
+						NULL /*cvmx_error_childbit*/
+					},
+					{0}}},
+				{0}}
+			},
+			{0}}},
+		{0}}
+	};
 static struct cvmx_error_muxchild error_tree_cn63xx =
 	{0x0000000000000000ull /* CVMX_ROOT */, 0, NULL /* cvmx_error_regbit */, (struct cvmx_error_childbit[]){
 		{1, 0 /* root */, (struct cvmx_error_muxchild[]){
@@ -11803,13 +12605,14 @@ static struct cvmx_error_muxchild error_tree_cn68xx =
 
 struct cvmx_error_tree octeon_error_trees[] = {
    {&error_tree_cn38xxp2, 0xfff8, 0x0008},
+   {&error_tree_cn70xxp1, 0xff00, 0x9600},
    {&error_tree_cn68xxp1, 0xfff8, 0x9100},
    {&error_tree_cn63xxp1, 0xfff8, 0x9000},
    {&error_tree_cn58xxp1, 0xfff8, 0x0300},
    {&error_tree_cn56xxp1, 0xfff8, 0x0400},
    {&error_tree_cn52xxp1, 0xfff8, 0x0700},
    {&error_tree_cnf71xx, 0xff00, 0x9400},
-   {&error_tree_cn70xx, 0xff00, 0x9600},
+   {&error_tree_cn70xx, 0xfff8, 0x9608},
    {&error_tree_cn68xx, 0xff00, 0x9100},
    {&error_tree_cn66xx, 0xff00, 0x9200},
    {&error_tree_cn63xx, 0xff00, 0x9000},
diff --git a/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c b/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
index 87af418..abac157 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
@@ -40,45 +40,18 @@
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include "linux/export.h"
 #include "asm/octeon/cvmx.h"
-#include "asm/octeon/cvmx-fpa1.h"
 #include "asm/octeon/cvmx-fpa3.h"
+#include "asm/octeon/cvmx-fpa1.h"
 #include "asm/octeon/cvmx-global-resources.h"
 #else
 #include "cvmx.h"
-#include "cvmx-fpa1.h"
 #include "cvmx-fpa3.h"
 #include "cvmx-global-resources.h"
 #include "cvmx-sysinfo.h"
 #endif
 
-/** Allocates the pool from global resources and reserves them
-  * @param pool	    FPA pool to allocate/reserve. If -1 it
-  *                 finds the empty pool to allocate.
-  * @return         Allocated pool number OR -1 if fails to allocate
-                    the pool
-  */
-int cvmx_fpa_alloc_pool(int pool)
-{
-	if (cvmx_create_global_resource_range(CVMX_GR_TAG_FPA, CVMX_FPA3_NUM_POOLS)) {
-		cvmx_dprintf("\nFailed to create FPA global resource");
-		return -1;
-	}
-
-	if (pool >= 0)
-		pool = cvmx_reserve_global_resource_range(CVMX_GR_TAG_FPA, pool, pool, 1);
-	else
-		/* Find an empty pool */
-		pool = cvmx_allocate_global_resource_range(CVMX_GR_TAG_FPA,(uint64_t)pool, 1, 1);
-	if (pool == -1) {
-		cvmx_dprintf("Error: FPA pool is not available to use\n");
-		return -1;
-	}
-	//cvmx_dprintf("Error: FPA pool %d is free to use\n", pool);
-	return pool;
-}
-EXPORT_SYMBOL(cvmx_fpa_alloc_pool);
 
-static inline struct global_resource_tag get_fpa_resourse_tag(int node)
+static struct global_resource_tag get_fpa_resource_tag(int node)
 {
 	switch(node) {
 	case 0:
@@ -96,7 +69,7 @@ static inline struct global_resource_tag get_fpa_resourse_tag(int node)
 }
 
 
-static inline struct global_resource_tag get_aura_resourse_tag(int node)
+static struct global_resource_tag get_aura_resource_tag(int node)
 {
 	switch(node) {
 	case 0:
@@ -125,10 +98,14 @@ static inline struct global_resource_tag get_aura_resourse_tag(int node)
  */
 int cvmx_fpa_allocate_fpa_pools(int node, int pools_allocated[], int count)
 {
-	int num_pools = CVMX_FPA1_NUM_POOLS;
+	int num_pools = CVMX_FPA_NUM_POOLS;
 	uint64_t owner = 0;
 	int rv = 0;
-	struct global_resource_tag tag = get_fpa_resourse_tag(node);
+	struct global_resource_tag tag;
+
+	if (node == -1) node = cvmx_get_node_num();
+
+	tag = get_fpa_resource_tag(node);
 
 	if (octeon_has_feature(OCTEON_FEATURE_FPA3))
 		num_pools = CVMX_FPA3_NUM_POOLS;
@@ -140,19 +117,41 @@ int cvmx_fpa_allocate_fpa_pools(int node, int pools_allocated[], int count)
 	}
 
 	if (pools_allocated[0] >= 0) {
-		while (count--)
+		while (count--) {
 			rv = cvmx_reserve_global_resource_range(tag, owner, pools_allocated[count], 1);
+			if (rv == -1)
+				return CVMX_RESOURCE_ALREADY_RESERVED;
+		}
+
 	} else {
 		rv = cvmx_resource_alloc_many(tag, owner,
-						       count,
-						       pools_allocated);
+					      count,
+					      pools_allocated);
 	}
 	return rv;
 }
 
-int cvmx_fpa_reserve_compat(int node)
+/** Allocates the pool from global resources and reserves them
+  * @param pool	    FPA pool to allocate/reserve. If -1 it
+  *                 finds the empty pool to allocate.
+  * @return         Allocated pool number OR -1 if fails to allocate
+                    the pool
+  */
+int cvmx_fpa_alloc_pool(int pool)
+{
+	int pool_num = pool;
+
+	if (cvmx_fpa_allocate_fpa_pools(-1, &pool_num, 1) != 0) {
+		return -1;
+	}
+
+	return pool_num;
+}
+EXPORT_SYMBOL(cvmx_fpa_alloc_pool);
+
+int cvmx_fpa_reserve_error_pool(int node)
 {
-	int pool_num = 1, aura_num = 1;
+	int pool_num = 0;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_FPA3))
 		return 0;
@@ -161,8 +160,7 @@ int cvmx_fpa_reserve_compat(int node)
 
 	if (cvmx_sysinfo_get()->init_core != cvmx_get_core_num())
 		return 0;
-	cvmx_fpa_allocate_fpa_pools(node, &pool_num, 4);
-	cvmx_fpa3_allocate_auras(node, &aura_num, 4);
+	cvmx_fpa_allocate_fpa_pools(node, &pool_num, 1);
 
 	return 0;
 }
@@ -171,7 +169,7 @@ int cvmx_fpa_reserve_compat(int node)
   * @param pool	    Pool to free
   * @return         0 for success -1 failure
   */
-int cvmx_fpa_release_pool(int pool)
+int cvmx_fpa_release_pool(int pool) /* AJ: Gotta fix this */
 {
 	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_FPA, pool, 1) == -1) {
 		cvmx_dprintf("\nERROR Failed to release FPA pool %d", (int)pool);
@@ -179,42 +177,66 @@ int cvmx_fpa_release_pool(int pool)
 	}
 	return 0;
 }
+EXPORT_SYMBOL(cvmx_fpa_release_pool);
 
 int cvmx_fpa3_allocate_auras(int node, int auras_allocated[], int count)
 {
 	int num_aura = CVMX_FPA3_AURA_NUM;
 	uint64_t owner = 0;
 	int rv = 0;
-	struct global_resource_tag tag = get_aura_resourse_tag(node);
+	struct global_resource_tag tag = get_aura_resource_tag(node);
 
 	if (!OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		cvmx_dprintf("ERROR :  Aura allocation not supported "
-			     "on this model\n");
+		cvmx_dprintf("ERROR :  Aura allocation not supported on this model\n");
 	}
 
 	if (cvmx_create_global_resource_range(tag, num_aura) != 0) {
-		cvmx_dprintf("ERROR: failed to create aura global resource for"
-			     " node=%d\n", node);
+		cvmx_dprintf("ERROR: failed to create aura global resource for node=%d\n", node);
 		return -1;
 	}
 	if (auras_allocated[0] >= 0) {
-		while (count--)
+		while (count--) {
 			rv = cvmx_reserve_global_resource_range(tag, owner, auras_allocated[count], 1);
+			if (rv == -1)
+				return CVMX_RESOURCE_ALREADY_RESERVED;
+		}
 	} else
 		rv = cvmx_resource_alloc_many(tag, owner, count,
 					auras_allocated);
 	return rv;
 
 }
+EXPORT_SYMBOL(cvmx_fpa3_allocate_auras);
+
+int cvmx_fpa3_allocate_aura(int node)
+{
+	int r;
+	int aura = -1;
+
+	r = cvmx_fpa3_allocate_auras(node, &aura, 1);
+
+	return r == 0 ? aura : -1;
+}
+EXPORT_SYMBOL(cvmx_fpa3_allocate_aura);
 
-int cvmx_fpa3_free_auras(int node, int *pools_allocated, int count)
+int cvmx_fpa3_free_auras(int node, int *auras_allocated, int count)
 {
 	int rv;
-	struct global_resource_tag tag = get_aura_resourse_tag(node);
+	struct global_resource_tag tag = get_aura_resource_tag(node);
 
-	rv = cvmx_free_global_resource_range_multiple(tag, pools_allocated,
+	rv = cvmx_free_global_resource_range_multiple(tag, auras_allocated,
 						      count);
 	return rv;
 }
+EXPORT_SYMBOL(cvmx_fpa3_free_auras);
 
-EXPORT_SYMBOL(cvmx_fpa_release_pool);
+int cvmx_fpa3_free_pools(int node, int *pools_allocated, int count)
+{
+	int rv;
+	struct global_resource_tag tag = get_fpa_resource_tag(node);
+
+	rv = cvmx_free_global_resource_range_multiple(tag, pools_allocated,
+						      count);
+	return rv;
+}
+EXPORT_SYMBOL(cvmx_fpa3_free_pools);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c b/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
index cc81ac9..7a7d8f4 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
@@ -61,7 +61,7 @@
 #endif
 
 
-int __cvmx_helper_agl_enumerate(int interface)
+int __cvmx_helper_agl_enumerate(int xiface)
 {
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
 		union cvmx_agl_prtx_ctl agl_prtx_ctl;
@@ -79,10 +79,11 @@ int __cvmx_helper_agl_enumerate(int interface)
  * @param interface  Interface to probe
  * @return  The port corresponding to the interface
  */
-int cvmx_helper_agl_get_port(int interface)
+int cvmx_helper_agl_get_port(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX))
-		return interface - 4;
+		return xi.interface - 4;
 	return -1;
 }
 
@@ -143,8 +144,7 @@ int __cvmx_helper_agl_probe(int interface)
 		agl_prtx_ctl.s.clkrx_set =
 			cvmx_helper_get_agl_rx_clock_skew(interface, port);
 		agl_prtx_ctl.s.clkrx_byp =
-			cvmx_helper_get_agl_rx_clock_delay_bypass(interface,
-								  port);
+			cvmx_helper_get_agl_rx_clock_delay_bypass(interface, port);
 	}
 	cvmx_write_csr(CVMX_AGL_PRTX_CTL(port), agl_prtx_ctl.u64);
 	/* Force write out before wait */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
index c31b651..1edaa24 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -42,7 +42,7 @@
  *
  * Functions to configure the BGX MAC.
  *
- * <hr>$Revision$<hr>
+ * <hr>$Id$<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -62,8 +62,10 @@
 #include "cvmx-qlm.h"
 #endif
 
-int __cvmx_helper_bgx_enumerate(int interface)
+int __cvmx_helper_bgx_enumerate(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int node = xi.node;
 	int qlm;
 	enum cvmx_qlm_mode mode;
 
@@ -71,11 +73,11 @@ int __cvmx_helper_bgx_enumerate(int interface)
 	 * Check the QLM is configured correctly for SGMII, verify the
 	 * speed as well as the mode.
 	 */
-	qlm = cvmx_qlm_interface(interface);
+	qlm = cvmx_qlm_interface(xiface);
 	if (qlm == -1)
 		return 0;
 
-	mode = cvmx_qlm_get_mode(qlm);
+	mode = cvmx_qlm_get_mode_cn78xx(node, qlm);
 	if (mode == CVMX_QLM_MODE_SGMII) {
 	/* FIXME: Check here if SGMII is a MIX interface */
 		return 4;
@@ -98,18 +100,22 @@ int __cvmx_helper_bgx_enumerate(int interface)
  *
  * @param mode      Mode to configure the bgx mac as
  */
-static void __cvmx_bgx_common_init(int interface)
+static void __cvmx_bgx_common_init(int xiface)
 {
 	cvmx_bgxx_cmrx_config_t	cmr_config;
 	cvmx_bgxx_cmr_rx_lmacs_t bgx_cmr_rx_lmacs;
 	cvmx_bgxx_cmr_tx_lmacs_t bgx_cmr_tx_lmacs;
+	cvmx_bgxx_cmrx_rx_bp_on_t bgx_rx_bp_on;
 	cvmx_helper_interface_mode_t mode;
 	int num_ports;
 	int index;
 	int lmac_type = 0;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
 
-	num_ports = cvmx_helper_ports_on_interface(interface);
-	mode = cvmx_helper_interface_get_mode(interface);
+	num_ports = cvmx_helper_ports_on_interface(xiface);
+	mode = cvmx_helper_interface_get_mode(xiface);
 
 	switch (mode) {
 	case CVMX_HELPER_INTERFACE_MODE_SGMII:
@@ -134,42 +140,50 @@ static void __cvmx_bgx_common_init(int interface)
 	/* Set mode and lanes for all interface ports */
 	for (index = 0; index < num_ports; index++) {
 		cmr_config.u64 =
-			cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+			cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 		cmr_config.s.enable = 0;
 		cmr_config.s.lmac_type = lmac_type;
-		cmr_config.s.lane_to_sds = ((mode == CVMX_HELPER_INTERFACE_MODE_SGMII)
+		cmr_config.s.lane_to_sds = ((mode == CVMX_HELPER_INTERFACE_MODE_SGMII
+					     || mode == CVMX_HELPER_INTERFACE_MODE_XFI)
 					     ? index : ((mode == CVMX_HELPER_INTERFACE_MODE_RXAUI)
 						     ? (index ? 0xe : 4) : 0xe4));
-		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 	}
 
 	bgx_cmr_rx_lmacs.u64 = 0;
 	bgx_cmr_rx_lmacs.s.lmacs = num_ports;
-	cvmx_write_csr(CVMX_BGXX_CMR_RX_LMACS(interface), bgx_cmr_rx_lmacs.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_LMACS(interface), bgx_cmr_rx_lmacs.u64);
 
 	bgx_cmr_tx_lmacs.u64 = 0;
 	bgx_cmr_tx_lmacs.s.lmacs = num_ports;
-	cvmx_write_csr(CVMX_BGXX_CMR_TX_LMACS(interface), bgx_cmr_tx_lmacs.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMR_TX_LMACS(interface), bgx_cmr_tx_lmacs.u64);
+
+	/* Modify bp_on mark, depending on number of LMACS on that interface
+	and write it for every port */
+	bgx_rx_bp_on.u64 = 0;
+	bgx_rx_bp_on.s.mark = (CVMX_BGX_RX_FIFO_SIZE / (num_ports * 4 * 16));
 
 	for (index = 0; index < num_ports; index++) {
 		/* Setup pkind */
-		int pknd = cvmx_helper_get_pknd(interface, index);
+		int pknd = cvmx_helper_get_pknd(xiface, index);
 		cvmx_bgxx_cmrx_rx_id_map_t cmr_rx_id_map;
 		cvmx_bgxx_cmr_chan_msk_and_t chan_msk_and;
 		cvmx_bgxx_cmr_chan_msk_or_t chan_msk_or;
-		cmr_rx_id_map.u64 = 0;
-		cmr_rx_id_map.s.rid = 2 + index;
+		cmr_rx_id_map.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_RX_ID_MAP(index, interface));
 		cmr_rx_id_map.s.pknd = pknd;
-		cvmx_write_csr(CVMX_BGXX_CMRX_RX_ID_MAP(index, interface),
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ID_MAP(index, interface),
 			       cmr_rx_id_map.u64);
 
 		/* Set backpressure channel mask AND/OR registers */
-		chan_msk_and.u64 = cvmx_read_csr(CVMX_BGXX_CMR_CHAN_MSK_AND(interface));
-		chan_msk_or.u64 = cvmx_read_csr(CVMX_BGXX_CMR_CHAN_MSK_OR(interface));
+		chan_msk_and.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(interface));
+		chan_msk_or.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(interface));
 		chan_msk_and.s.msk_and &= ~(0xffull << index);
 		chan_msk_or.s.msk_or |= (0xffull << index);
-		cvmx_write_csr(CVMX_BGXX_CMR_CHAN_MSK_AND(interface), chan_msk_and.u64);
-		cvmx_write_csr(CVMX_BGXX_CMR_CHAN_MSK_OR(interface), chan_msk_or.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(interface), chan_msk_and.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(interface), chan_msk_or.u64);
+
+		/* set rx back pressure (bp_on) on value */
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_BP_ON(index, interface), bgx_rx_bp_on.u64);
 	}
 
 #if 0
@@ -198,9 +212,9 @@ static void __cvmx_bgx_common_init(int interface)
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-int __cvmx_helper_bgx_probe(int interface)
+int __cvmx_helper_bgx_probe(int xiface)
 {
-	return __cvmx_helper_bgx_enumerate(interface);
+	return __cvmx_helper_bgx_enumerate(xiface);
 }
 
 /**
@@ -212,9 +226,12 @@ int __cvmx_helper_bgx_probe(int interface)
  *
  * @return Zero on success, negative on failure
  */
-static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int interface, int index)
+static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int xiface, int index)
 {
-	const uint64_t clock_mhz = cvmx_clock_get_rate(CVMX_CLOCK_SCLK) / 1000000;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
+	const uint64_t clock_mhz = cvmx_clock_get_rate_node(node, CVMX_CLOCK_SCLK) / 1000000;
 	cvmx_bgxx_cmrx_config_t cmr_config;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
 	cvmx_bgxx_gmp_pcs_linkx_timer_t gmp_timer;
@@ -223,24 +240,24 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int interface, int ind
 		return 0;
 
 	/* Disable BGX */
-	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 	cmr_config.s.enable = 0;
-	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
 	/*
 	 * Write PCS*_LINK*_TIMER_COUNT_REG[COUNT] with the
 	 * appropriate value. 1000BASE-X specifies a 10ms
 	 * interval. SGMII specifies a 1.6ms interval.
 	 */
-	gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 	/* Adjust the MAC mode if requested by device tree */
 	gmp_misc_ctl.s.mac_phy =
-		cvmx_helper_get_mac_phy_mode(interface, index);
+		cvmx_helper_get_mac_phy_mode(xiface, index);
 	gmp_misc_ctl.s.mode =
-		cvmx_helper_get_1000x_mode(interface, index);
-	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+		cvmx_helper_get_1000x_mode(xiface, index);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
 
-	gmp_timer.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, interface));
+	gmp_timer.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, interface));
 	if (gmp_misc_ctl.s.mode)
 		/* 1000BASE-X */
 		gmp_timer.s.count = (10000ull * clock_mhz) >> 10;
@@ -248,7 +265,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int interface, int ind
 		/* SGMII */
 		gmp_timer.s.count = (1600ull * clock_mhz) >> 10;
 
-	cvmx_write_csr(CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, interface), gmp_timer.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, interface), gmp_timer.u64);
 
 	/*
 	 * Write the advertisement register to be used as the
@@ -262,20 +279,20 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int interface, int ind
 	if (gmp_misc_ctl.s.mode) {
 		/* 1000BASE-X */
 		cvmx_bgxx_gmp_pcs_anx_adv_t gmp_an_adv;
-		gmp_an_adv.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_ANX_ADV(index, interface));
+		gmp_an_adv.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_ANX_ADV(index, interface));
 		gmp_an_adv.s.rem_flt = 0;
 		gmp_an_adv.s.pause = 3;
 		gmp_an_adv.s.hfd = 1;
 		gmp_an_adv.s.fd = 1;
-		cvmx_write_csr(CVMX_BGXX_GMP_PCS_ANX_ADV(index, interface), gmp_an_adv.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_ANX_ADV(index, interface), gmp_an_adv.u64);
 	} else {
 		if (gmp_misc_ctl.s.mac_phy) {
 			/* PHY Mode */
 			cvmx_bgxx_gmp_pcs_sgmx_an_adv_t gmp_sgmx_an_adv;
-			gmp_sgmx_an_adv.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(index, interface));
+			gmp_sgmx_an_adv.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(index, interface));
 			gmp_sgmx_an_adv.s.dup = 1;
 			gmp_sgmx_an_adv.s.speed = 2;
-			cvmx_write_csr(CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(index, interface),
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_SGMX_AN_ADV(index, interface),
 				       gmp_sgmx_an_adv.u64);
 		} else {
 			/* MAC Mode - Nothing to do */
@@ -295,25 +312,28 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int interface, int ind
  *
  * @return Zero on success, negative on failure
  */
-static int __cvmx_helper_bgx_sgmii_hardware_init(int interface, int num_ports)
+static int __cvmx_helper_bgx_sgmii_hardware_init(int xiface, int num_ports)
 {
 	int index;
 	int do_link_set = 1;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
 
-	__cvmx_bgx_common_init(interface);
+	__cvmx_bgx_common_init(xiface);
 
 	for (index = 0; index < num_ports; index++) {
-		int ipd_port = cvmx_helper_get_ipd_port(interface, index);
+		int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
 		cvmx_bgxx_gmp_gmi_txx_thresh_t gmi_tx_thresh;
 
-		if (!cvmx_helper_is_port_valid(interface, index))
+		if (!cvmx_helper_is_port_valid(xiface, index))
 			continue;
-		__cvmx_helper_bgx_sgmii_hardware_init_one_time(interface, index);
+		__cvmx_helper_bgx_sgmii_hardware_init_one_time(xiface, index);
 
 		/* Set TX Threshold */
 		gmi_tx_thresh.u64 = 0;
 		gmi_tx_thresh.s.cnt = 0x1ff; /* has 4 ports */
-		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_THRESH(index, interface),
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_THRESH(index, interface),
 					gmi_tx_thresh.u64);
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 		/*
@@ -326,8 +346,8 @@ static int __cvmx_helper_bgx_sgmii_hardware_init(int interface, int num_ports)
 			do_link_set = 0;
 #endif
 		if (do_link_set)
-			__cvmx_helper_bgx_sgmii_link_set(ipd_port,
-					__cvmx_helper_bgx_sgmii_link_get(ipd_port));
+			__cvmx_helper_bgx_sgmii_link_set(xipd_port,
+					__cvmx_helper_bgx_sgmii_link_get(xipd_port));
 	}
 
 	return 0;
@@ -344,37 +364,38 @@ static int __cvmx_helper_bgx_sgmii_hardware_init(int interface, int num_ports)
  *
  * @return Zero on success, negative on failure
  */
-int __cvmx_helper_bgx_sgmii_enable(int interface)
+int __cvmx_helper_bgx_sgmii_enable(int xiface)
 {
-	//cvmx_bgxx_cmrx_rx_id_map_t cmr_rx_id_map;
 	cvmx_bgxx_cmrx_config_t cmr_config;
-	//cvmx_bgxx_cmr_chan_msk_and_t chan_msk_and;
-	//cvmx_bgxx_cmr_chan_msk_or_t chan_msk_or;
 	cvmx_bgxx_gmp_gmi_txx_append_t gmp_txx_append;
 	cvmx_bgxx_gmp_gmi_txx_sgmii_ctl_t gmp_sgmii_ctl;
 	int num_ports;
 	int index;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
 
-	num_ports = cvmx_helper_ports_on_interface(interface);
+	num_ports = cvmx_helper_ports_on_interface(xiface);
 
-	__cvmx_helper_bgx_sgmii_hardware_init(interface, num_ports);
+	__cvmx_helper_bgx_sgmii_hardware_init(xiface, num_ports);
 
 	for (index = 0; index < num_ports; index++) {
-		gmp_txx_append.u64 = cvmx_read_csr(CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface));
+		gmp_txx_append.u64 = cvmx_read_csr_node(node,
+					CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface));
 		gmp_txx_append.s.fcs = 0;
 		gmp_txx_append.s.pad = 0;
-		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface), gmp_txx_append.u64);
-		
-		gmp_sgmii_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface));
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface), gmp_txx_append.u64);
+
+		gmp_sgmii_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface));
 		gmp_sgmii_ctl.s.align = gmp_txx_append.s.preamble ? 0 : 1;
-		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface),
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface),
 				gmp_sgmii_ctl.u64);
 
-		cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 		cmr_config.s.enable = 1;
 		cmr_config.s.data_pkt_tx_en = 1;
 		cmr_config.s.data_pkt_rx_en = 1;
-		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 	}
 
 	return 0;
@@ -390,24 +411,27 @@ int __cvmx_helper_bgx_sgmii_enable(int interface)
  *
  * @return Zero on success, negative on failure
  */
-static int __cvmx_helper_bgx_sgmii_hardware_init_link(int interface, int index)
+static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
 {
 	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
 	int phy_mode, mode_1000x;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
 
-	if (!cvmx_helper_is_port_valid(interface, index))
+	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
 
-	gmp_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
 	/* Take PCS through a reset sequence */
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		gmp_control.s.reset = 1;
-		cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
 		       					     gmp_control.u64);
 
 		/* Wait until GMP_PCS_MRX_CONTROL[reset] comes out of reset */
-		if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
 				cvmx_bgxx_gmp_pcs_mrx_control_t, reset, ==, 0, 10000)) {
 			cvmx_dprintf("SGMII%d: Timeout waiting for port %d to finish reset\n", interface, index);
 			return -1;
@@ -416,22 +440,22 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int interface, int index)
 
 	/* Write GMP_PCS_MR*_CONTROL[RST_AN]=1 to ensure a fresh SGMII
 	   negotiation starts. */
-	gmp_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
 	gmp_control.s.rst_an = 1;
 	gmp_control.s.an_en = 1;
 	gmp_control.s.pwr_dn = 0;
-	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
 		       gmp_control.u64);
 
 
-	phy_mode = cvmx_helper_get_mac_phy_mode(interface, index);
-	mode_1000x = cvmx_helper_get_1000x_mode(interface, index);
+	phy_mode = cvmx_helper_get_mac_phy_mode(xiface, index);
+	mode_1000x = cvmx_helper_get_1000x_mode(xiface, index);
 
-	gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 	gmp_misc_ctl.s.mac_phy = phy_mode;
 	gmp_misc_ctl.s.mode = mode_1000x;
-	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
-	
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+
 	if (phy_mode)
 		/* In PHY mode we can't query the link status so we just
 		   assume that the link is up */
@@ -442,7 +466,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int interface, int index)
 	   ethernet link, but a link between OCTEON and PHY. */
 
 	if ((cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) &&
-	     CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_PCS_MRX_STATUS(index, interface),
+	     CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_STATUS(index, interface),
 				   cvmx_bgxx_gmp_pcs_mrx_status_t, an_cpt,
 				   ==, 1, 10000)) {
 		cvmx_dprintf("SGMII%d: Port %d link timeout\n", interface, index);
@@ -463,7 +487,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int interface, int index)
  *
  * @return Zero on success, negative on failure
  */
-static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int interface,
+static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int xiface,
 							    int index,
 							    cvmx_helper_link_info_t link_info)
 {
@@ -471,20 +495,23 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int interface,
 	cvmx_bgxx_cmrx_config_t cmr_config;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_miscx_ctl;
 	cvmx_bgxx_gmp_gmi_prtx_cfg_t gmp_prtx_cfg;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
 
-	if (!cvmx_helper_is_port_valid(interface, index))
+	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
 
 	/* Disable GMX before we make any changes. Remember the enable state */
-	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 	is_enabled = cmr_config.s.enable;
 	cmr_config.s.enable = 0;
-	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
 	/* Wait for GMX to be idle */
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
 				  cvmx_bgxx_gmp_gmi_prtx_cfg_t, rx_idle, ==, 1, 10000) ||
-	    CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
+	    CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
 				  cvmx_bgxx_gmp_gmi_prtx_cfg_t, tx_idle, ==, 1, 10000)) {
 		cvmx_dprintf("SGMII%d: Timeout waiting for port %d to be idle\n",
 			     interface, index);
@@ -492,13 +519,13 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int interface,
 	}
 
 	/* Read GMX CFG again to make sure the disable completed */
-	gmp_prtx_cfg.u64 = cvmx_read_csr(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface));
+	gmp_prtx_cfg.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface));
 
 	/*
 	 * Get the misc control for PCS. We will need to set the
 	 * duplication amount.
 	 */
-	gmp_miscx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_miscx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 
 	/*
 	 * Use GMXENO to force the link down if the status we get says
@@ -518,47 +545,47 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int interface,
 		gmp_prtx_cfg.s.slottime = 0;
 		/* Setting from GMX-603 */
 		gmp_miscx_ctl.s.samp_pt = 25;
-		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 64);
-		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 64);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
 		break;
 	case 100:
 		gmp_prtx_cfg.s.speed = 0;
 		gmp_prtx_cfg.s.speed_msb = 0;
 		gmp_prtx_cfg.s.slottime = 0;
 		gmp_miscx_ctl.s.samp_pt = 0x5;
-		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 64);
-		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 64);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
 		break;
 	case 1000:
 		gmp_prtx_cfg.s.speed = 1;
 		gmp_prtx_cfg.s.speed_msb = 0;
 		gmp_prtx_cfg.s.slottime = 1;
 		gmp_miscx_ctl.s.samp_pt = 1;
-		cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 512);
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SLOT(index, interface), 512);
 		if (gmp_prtx_cfg.s.duplex)
 			/* full duplex */
-			cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 0);
 		else
 			/* half duplex */
-			cvmx_write_csr(CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 8192);
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_BURST(index, interface), 8192);
 		break;
 	default:
 		break;
 	}
 
 	/* Write the new misc control for PCS */
-	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface),
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface),
 		       gmp_miscx_ctl.u64);
 
 	/* Write the new GMX settings with the port still disabled */
-	cvmx_write_csr(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface), gmp_prtx_cfg.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface), gmp_prtx_cfg.u64);
 
 	/* Read GMX CFG again to make sure the config completed */
-	cvmx_read_csr(CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface));
+	cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface));
 
 	/* Restore the enabled / disabled state */
 	cmr_config.s.enable = is_enabled;
-	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
 	return 0;
 }
@@ -575,18 +602,22 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int interface,
  *
  * @return Link state
  */
-cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port)
+cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 {
 	cvmx_helper_link_info_t result;
 	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
-	int interface = cvmx_helper_get_interface_num(ipd_port);
-	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
 	int speed = 1000;
 
 	result.u64 = 0;
 
-	if (!cvmx_helper_is_port_valid(interface, index))
+	if (!cvmx_helper_is_port_valid(xiface, index))
 		return result;
 
 	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM) {
@@ -597,9 +628,9 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port)
 		return result;
 	}
 
-	//speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
+	speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
 
-	gmp_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
 	if (gmp_control.s.loopbck1) {
 		/* Force 1Gbps full duplex link for internal loopback */
 		result.s.link_up = 1;
@@ -608,7 +639,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port)
 		return result;
 	}
 
-	gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 	if (gmp_misc_ctl.s.mac_phy) {
 		/* PHY Mode */
 		/* Note that this also works for 1000base-X mode */
@@ -619,7 +650,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port)
 		return result;
 	} else {
 		/* MAC Mode */
-		result = __cvmx_helper_board_link_get(ipd_port);
+		result = __cvmx_helper_board_link_get(xipd_port);
 	}
 	return result;
 }
@@ -638,42 +669,46 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port)
  *
  * @return Zero on success, negative on failure
  */
-int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
+int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 				 cvmx_helper_link_info_t link_info)
 {
-	int interface = cvmx_helper_get_interface_num(ipd_port);
-	int index = cvmx_helper_get_interface_index_num(ipd_port);
-
-	if (!cvmx_helper_is_port_valid(interface, index))
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
+
+	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
 
 	if (link_info.s.link_up) {
-		__cvmx_helper_bgx_sgmii_hardware_init_link(interface, index);
+		__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
 	} else {
 		cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
 
-		gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+		gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 
 		/* Disable autonegotiation only when MAC mode. */
 		if (gmp_misc_ctl.s.mac_phy == 0) {
 			cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
 
-			gmp_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+			gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
 			gmp_control.s.an_en = 0;
-			cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_control.u64);
-			cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_control.u64);
+			cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
 		}
 		/*
 		 * Use GMXENO to force the link down it will get
 		 * reenabled later...
 		 */
 		gmp_misc_ctl.s.gmxeno = 1;
-		cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface),
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface),
 			       gmp_misc_ctl.u64);
-		cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+		cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 		return 0;
 	}
-	return __cvmx_helper_bgx_sgmii_hardware_init_link_speed(interface, index, link_info);
+	return __cvmx_helper_bgx_sgmii_hardware_init_link_speed(xiface, index, link_info);
 }
 
 /**
@@ -691,184 +726,213 @@ int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
  *
  * @return Zero on success, negative on failure.
  */
-int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port, int enable_internal,
+int __cvmx_helper_bgx_sgmii_configure_loopback(int xipd_port, int enable_internal,
 					   int enable_external)
 {
-	int interface = cvmx_helper_get_interface_num(ipd_port);
-	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_mrx_control;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
 
-	if (!cvmx_helper_is_port_valid(interface, index))
+	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
 
-	gmp_mrx_control.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	gmp_mrx_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
 	gmp_mrx_control.s.loopbck1 = enable_internal;
-	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_mrx_control.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_mrx_control.u64);
 
-	gmp_misc_ctl.u64 = cvmx_read_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 	gmp_misc_ctl.s.loopbck2 = enable_external;
-	cvmx_write_csr(CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
 
-	__cvmx_helper_bgx_sgmii_hardware_init_link(interface, index);
+	__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
 
 	return 0;
 }
 
 /**
  * @INTERNAL
- * Bringup XAUI interface. After this call packet I/O should be 
+ * Bringup XAUI interface. After this call packet I/O should be
  * fully functional.
  *
  * @param interface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
-static int __cvmx_helper_bgx_xaui_link_init(int index, int interface)
+static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 {
 	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
 	cvmx_bgxx_spux_misc_control_t spu_misc_control;
 	cvmx_bgxx_spux_control1_t spu_control1;
 	cvmx_bgxx_cmrx_config_t cmr_config;
 	cvmx_helper_interface_mode_t mode;
-	mode = cvmx_helper_interface_get_mode(interface);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
+
+	mode = cvmx_helper_interface_get_mode(xiface);
 
 	/* (1) Interface has already been enabled. */
 
 	/* (2) Disable BGX. */
-	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 	cmr_config.s.enable = 0;
-	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
 	/* (3) Disable GMX and PCSX interrupts. */
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
-		cvmx_write_csr(CVMX_BGXX_SMUX_RX_INT(index, interface), 0x0);
-		cvmx_write_csr(CVMX_BGXX_SMUX_TX_INT(index, interface), 0x0);
-		cvmx_write_csr(CVMX_BGXX_SPUX_INT(index, interface), 0x0);
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_INT(index, interface), 0x0);
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_INT(index, interface), 0x0);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, interface), 0x0);
 	}
 
 	/* Enable link training for 10GBASE-KR and 40GBASE-KR */
 	if (mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
 	    || mode == CVMX_HELPER_INTERFACE_MODE_XFI) {
 		cvmx_bgxx_spux_br_pmd_control_t spu_pmd_control;
-		spu_pmd_control.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface));
+		spu_pmd_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface));
 		spu_pmd_control.s.train_en = 1;
-		cvmx_write_csr(CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface),
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface),
 				       spu_pmd_control.u64);
 	}
 
-	spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface));
+	spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface));
 	spu_control1.s.lo_pwr = 0;
-	cvmx_write_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		/* (4)a Take SMU/SPU through a reset sequence */
 		/* (4)a Set polarity and lane swapping. */
-		spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface));
+		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface));
 		spu_control1.s.reset = 1;
-		cvmx_write_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
 
-		spu_misc_control.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_MISC_CONTROL(index, interface));
+		spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface));
 		spu_misc_control.s.rx_packet_dis = 1;
-		cvmx_write_csr(CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
 
 		/* Wait for PCS to come out of reset */
-		if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_CONTROL1(index, interface),
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_CONTROL1(index, interface),
 					 cvmx_bgxx_spux_control1_t, reset, ==, 0, 10000))
 			return -1;
 	}
 
 	/* 4d. Select Deficit Idle Count mode and unidirection mode */
-	smu_tx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_TX_CTL(index, interface));
-	/* Enable better IFG packing and improves performance */
+	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, interface));
 	smu_tx_ctl.s.dic_en = 1;
 	smu_tx_ctl.s.uni_en = 0;
-	cvmx_write_csr(CVMX_BGXX_SMUX_TX_CTL(index, interface), smu_tx_ctl.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, interface), smu_tx_ctl.u64);
 
-	if (mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
-	    || mode == CVMX_HELPER_INTERFACE_MODE_XFI) {
-		if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_INT(index, interface),
+	if ((mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
+	     || mode == CVMX_HELPER_INTERFACE_MODE_XFI)
+	    && cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_INT(index, interface),
 					  cvmx_bgxx_spux_int_t, training_done, ==, 1, 10000))
+			cvmx_dprintf("ERROR: %d:BGX%d:%d: Failed link training\n", node, interface, index);
                 	return -1;
 	}
 
 	/* (5) Check to make sure that the link appears up and stable. */
 	/* Wait for PCS to be aligned */
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_BX_STATUS(index, interface),
-				  cvmx_bgxx_spux_bx_status_t, alignd, ==, 1, 10000))
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_BX_STATUS(index, interface),
+				  cvmx_bgxx_spux_bx_status_t, alignd, ==, 1, 10000)) {
+		cvmx_dprintf("ERROR: %d:BGX%d:%d: Lanes not aligned\n", node, interface, index);
 		return -1;
+}
 
 	/* Wait for RX to be ready */
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SMUX_RX_CTL(index, interface),
-					  cvmx_bgxx_smux_rx_ctl_t, status, ==, 0, 10000))
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_RX_CTL(index, interface),
+					  cvmx_bgxx_smux_rx_ctl_t, status, ==, 0, 10000)) {
+		cvmx_dprintf("ERROR: %d:BGX%d:%d: Link not up\n", node, interface, index);
 		return -1;
+}
 
 	/* Clear all error interrupts before enabling the interface. */
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
-		cvmx_write_csr(CVMX_BGXX_SMUX_RX_INT(index, interface), ~0x0ull);
-		cvmx_write_csr(CVMX_BGXX_SMUX_TX_INT(index, interface), ~0x0ull);
-		cvmx_write_csr(CVMX_BGXX_SPUX_INT(index, interface), ~0x0ull);
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_INT(index, interface), ~0x0ull);
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_INT(index, interface), ~0x0ull);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, interface), ~0x0ull);
 	}
 
 	/* Wait for GMX RX to be idle */
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SMUX_CTRL(index, interface),
-				  cvmx_bgxx_smux_ctrl_t, rx_idle, ==, 1, 10000))
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_CTRL(index, interface),
+				  cvmx_bgxx_smux_ctrl_t, rx_idle, ==, 1, 10000)) {
+		cvmx_dprintf("ERROR: %d:BGX%d:%d: RX not idle\n", node, interface, index);
 		return -1;
+}
 
 	/* Wait for GMX TX to be idle */
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SMUX_CTRL(index, interface),
-				  cvmx_bgxx_smux_ctrl_t, tx_idle, ==, 1, 10000))
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SMUX_CTRL(index, interface),
+				  cvmx_bgxx_smux_ctrl_t, tx_idle, ==, 1, 10000)) {
+		cvmx_dprintf("ERROR: %d:BGX%d:%d: RX not idle\n", node, interface, index);
 		return -1;
+}
 
 	/* Wait for receive link */
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_BR_STATUS1(index, interface),
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_BR_STATUS1(index, interface),
 				  cvmx_bgxx_spux_br_status1_t, rcv_lnk, ==, 1, 10000))
+{
+		cvmx_dprintf("ERROR: %d:BGX%d:%d: rcv_lnk not up\n", node, interface, index);
 		return -1;
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_STATUS2(index, interface),
+}
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_STATUS2(index, interface),
 				  cvmx_bgxx_spux_status2_t, xmtflt, ==, 0, 10000))
+{
+		cvmx_dprintf("ERROR: %d:BGX%d:%d: xmtflt not 0\n", node, interface, index);
 		return -1;
+}
 
-	if (CVMX_WAIT_FOR_FIELD64(CVMX_BGXX_SPUX_STATUS2(index, interface),
-				  cvmx_bgxx_spux_status2_t, rcvflt, ==, 0, 10000))
+	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_STATUS2(index, interface),
+				  cvmx_bgxx_spux_status2_t, rcvflt, ==, 0, 10000)) {
+		cvmx_dprintf("ERROR: %d:BGX%d:%d: rcvflt not latched\n", node, interface, index);
 		return -1;
-	
+}
+
 	/* (7) Enable packet transmit and receive */
-	cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 	cmr_config.s.data_pkt_tx_en = 1;
 	cmr_config.s.data_pkt_rx_en = 1;
 	cmr_config.s.enable = 1;
-	cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
-		spu_misc_control.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_MISC_CONTROL(index, interface));
+		spu_misc_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface));
 		spu_misc_control.s.rx_packet_dis = 0;
-		cvmx_write_csr(CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
 	}
 
 	return 0;
 }
 
-int __cvmx_helper_bgx_xaui_enable(int interface)
+int __cvmx_helper_bgx_xaui_enable(int xiface)
 {
 	cvmx_bgxx_smux_tx_append_t smu_tx_append;
 	cvmx_bgxx_smux_tx_thresh_t smu_tx_thresh;
 	cvmx_bgxx_cmrx_config_t cmr_config;
 	int index;
-	int num_ports = cvmx_helper_ports_on_interface(interface);
+	int num_ports = cvmx_helper_ports_on_interface(xiface);
 	cvmx_helper_interface_mode_t mode;
-	mode = cvmx_helper_interface_get_mode(interface);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
+
+	mode = cvmx_helper_interface_get_mode(xiface);
 
-	__cvmx_bgx_common_init(interface);
+	__cvmx_bgx_common_init(xiface);
 	for (index = 0; index < num_ports; index++) {
-		int res = __cvmx_helper_bgx_xaui_link_init(index, interface);
+		int res = __cvmx_helper_bgx_xaui_link_init(index, xiface);
 		if (res == -1) {
 			cvmx_dprintf("Failed to enable XAUI for BGX(%d,%d)\n", interface, index);
 			return res;
 		}
-		smu_tx_append.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_TX_APPEND(index, interface));
+		smu_tx_append.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_APPEND(index, interface));
 		smu_tx_append.s.fcs_c = 0;
 		smu_tx_append.s.fcs_d = 0;
 		smu_tx_append.s.pad = 0;
-		cvmx_write_csr(CVMX_BGXX_SMUX_TX_APPEND(index, interface), smu_tx_append.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_APPEND(index, interface), smu_tx_append.u64);
 		smu_tx_thresh.u64 = 0;
 		if (mode == CVMX_HELPER_INTERFACE_MODE_XLAUI
 		    || mode == CVMX_HELPER_INTERFACE_MODE_XFI)
@@ -877,30 +941,34 @@ int __cvmx_helper_bgx_xaui_enable(int interface)
 			smu_tx_thresh.s.cnt = 0x3ff;
 		else
 			smu_tx_thresh.s.cnt = 0x7ff;
-		cvmx_write_csr(CVMX_BGXX_SMUX_TX_THRESH(index, interface),
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_THRESH(index, interface),
 					smu_tx_thresh.u64);
-		
-		cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 		cmr_config.s.enable = 1;
 		cmr_config.s.data_pkt_tx_en = 1;
 		cmr_config.s.data_pkt_rx_en = 1;
-		cvmx_write_csr(CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 	}
 	return 0;
 }
 
-cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port)
+cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 {
 	cvmx_helper_link_info_t result;
-	int interface = cvmx_helper_get_interface_num(ipd_port);
-	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
 	cvmx_bgxx_smux_rx_ctl_t smu_rx_ctl;
 	cvmx_bgxx_spux_br_status1_t spu_status1;
 
-	smu_tx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_TX_CTL(index, interface));
-	smu_rx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_RX_CTL(index, interface));
-	spu_status1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_BR_STATUS1(index, interface));
+	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, interface));
+	smu_rx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(index, interface));
+	spu_status1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_BR_STATUS1(index, interface));
 	result.u64 = 0;
 
 	/* Only return a link if both RX and TX are happy */
@@ -908,43 +976,43 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port)
 	    (smu_rx_ctl.s.status == 0) &&
 	    (spu_status1.s.rcv_lnk == 1)) {
 		cvmx_bgxx_cmrx_config_t cmr_config;
-		cvmx_bgxx_spux_control1_t spu_control1;
-		spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface));
+		int qlm = cvmx_qlm_interface(interface);
 		result.s.link_up = 1;
 		result.s.full_duplex = 1;
-		if (spu_control1.s.spd == 3)
-			result.s.speed = 40000;
-		else
-			result.s.speed = 10000;
-		cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
+		result.s.speed = cvmx_qlm_get_gbaud_mhz(qlm) * 8 / 10;
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 		if (cmr_config.s.enable) {
 			int res;
-			res = __cvmx_helper_bgx_xaui_link_init(index, interface);
+			res = __cvmx_helper_bgx_xaui_link_init(index, xiface);
 			if (res == -1)
 				cvmx_dprintf("Failed to get BGX(%d,%d) link\n", interface, index);
 		}
 	} else {
 		/* Disable GMX and PCSX interrupts. */
 		if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
-			cvmx_write_csr(CVMX_BGXX_SMUX_RX_INT(index, interface), ~0x0ull);
-			cvmx_write_csr(CVMX_BGXX_SMUX_TX_INT(index, interface), ~0x0ull);
-			cvmx_write_csr(CVMX_BGXX_SPUX_INT(index, interface), ~0x0ull);
+			cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_INT(index, interface), ~0x0ull);
+			cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_INT(index, interface), ~0x0ull);
+			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, interface), ~0x0ull);
 		}
 	}
 
 	return result;
 }
 
-int __cvmx_helper_bgx_xaui_link_set(int ipd_port, cvmx_helper_link_info_t link_info)
+int __cvmx_helper_bgx_xaui_link_set(int xipd_port, cvmx_helper_link_info_t link_info)
 {
-	int interface = cvmx_helper_get_interface_num(ipd_port);
-	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_bgxx_smux_tx_ctl_t smu_tx_ctl;
 	cvmx_bgxx_smux_rx_ctl_t smu_rx_ctl;
 	//cvmx_bgxx_spux_br_status1_t spu_status1;
 
-	smu_tx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_TX_CTL(index, interface));
-	smu_rx_ctl.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_RX_CTL(index, interface));
+	smu_tx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_TX_CTL(index, interface));
+	smu_rx_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(index, interface));
 
 	/* If the link shouldn't be up, then just return */
 	if (!link_info.s.link_up)
@@ -955,26 +1023,86 @@ int __cvmx_helper_bgx_xaui_link_set(int ipd_port, cvmx_helper_link_info_t link_i
 		return 0;
 
 	/* Bring the link up */
-	return __cvmx_helper_bgx_xaui_link_init(index, interface);
+	return __cvmx_helper_bgx_xaui_link_init(index, xiface);
 }
 
-int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port, 
-						     int enable_internal, 
+int __cvmx_helper_bgx_xaui_configure_loopback(int xipd_port,
+						     int enable_internal,
 						     int enable_external)
 {
-	int interface = cvmx_helper_get_interface_num(ipd_port);
-	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
 	cvmx_bgxx_spux_control1_t spu_control1;
 	cvmx_bgxx_smux_ext_loopback_t smu_ext_loopback;
 
 	/* Set the internal loop */
-	spu_control1.u64 = cvmx_read_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface));
+	spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface));
 	spu_control1.s.loopbck = enable_internal;
-	cvmx_write_csr(CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
 	/* Set the external loop */
-	smu_ext_loopback.u64 = cvmx_read_csr(CVMX_BGXX_SMUX_EXT_LOOPBACK(index, interface));
+	smu_ext_loopback.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_EXT_LOOPBACK(index, interface));
 	smu_ext_loopback.s.en = enable_external;
-	cvmx_write_csr(CVMX_BGXX_SMUX_EXT_LOOPBACK(index, interface), smu_ext_loopback.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_EXT_LOOPBACK(index, interface), smu_ext_loopback.u64);
+
+	return __cvmx_helper_bgx_xaui_link_init(index, xiface);
+}
+
+/**
+ * @INTERNAL
+ * Configure Priority-Based Flow Control (a.k.a. PFC/CBFC)
+ * on a specific BGX interface/port.
+ */
+void __cvmx_helper_bgx_xaui_config_pfc(unsigned node,
+		unsigned interface, unsigned port, bool pfc_enable)
+{
+	cvmx_bgxx_smux_cbfc_ctl_t cbfc_ctl;
+
+	cbfc_ctl.u64 = cvmx_read_csr_node(node,
+		CVMX_BGXX_SMUX_CBFC_CTL(port, interface)
+		);
+
+	/* Enable all PFC controls if requiested */
+	cbfc_ctl.s.rx_en = pfc_enable;
+	cbfc_ctl.s.tx_en = pfc_enable;
+#if 0
+	cbfc_ctl.s.bck_en = 1;
+	cbfc_ctl.s.phys_en = 0xff;
+	cbfc_ctl.s.logl_en = 0xff;
+	cbfc_ctl.s.drp_en = pfc_enable;
+#endif
+#ifdef DEBUG
+	printf("%s: CVMX_BGXX_SMUX_CBFC_CTL(%d,%d)=%#llx\n",
+		__func__, port, interface, (unsigned long long)cbfc_ctl.u64);
+#endif
+	cvmx_write_csr_node(node,
+		CVMX_BGXX_SMUX_CBFC_CTL(port, interface),
+		cbfc_ctl.u64);
+}
+
+
+/**
+ * This function control how the hardware handles incoming PAUSE
+ * packets. The most common modes of operation:
+ * ctl_bck = 1, ctl_drp = 1: hardware handles everything
+ * ctl_bck = 0, ctl_drp = 0: software sees all PAUSE frames
+ * ctl_bck = 0, ctl_drp = 1: all PAUSE frames are completely ignored
+ * @param node		node number.
+ * @param interface	interface number
+ * @param port		port number
+ * @param ctl_bck	1: Forward PAUSE information to TX block
+ * @param ctl_drp	1: Drop control PAUSE frames.
+ */
+void cvmx_helper_bgx_rx_pause_ctl(unsigned node, unsigned interface,
+			unsigned port, unsigned ctl_bck, unsigned ctl_drp)
+{
+	cvmx_bgxx_smux_rx_frm_ctl_t frm_ctl;
 
-	return __cvmx_helper_bgx_xaui_link_init(index, interface);
+	frm_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(port, interface));
+	frm_ctl.s.ctl_bck = ctl_bck;
+	frm_ctl.s.ctl_drp = ctl_drp;
+	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_RX_CTL(port, interface), frm_ctl.u64);
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
index f62371a..cb9c0eb 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
@@ -367,17 +367,21 @@ static int __get_muxed_mdio_info_from_dt(cvmx_phy_info_t *phy_info,
  */
 int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 {
-	int interface_num, port_index;
+	int port_index;
 	int aliases;
 	const char *pip_path;
 	char name_buffer[24];
 	int pip, iface, eth;
 	int dbg = device_tree_dbg;
 	cvmx_helper_interface_mode_t mode;
+	int xiface = cvmx_helper_get_interface_num(ipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	uint32_t *val;
 
-	interface_num = cvmx_helper_get_interface_num(ipd_port);
-	mode = cvmx_helper_interface_get_mode(interface_num);
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		return 1;
+
+	mode = cvmx_helper_interface_get_mode(xiface);
 
         switch (mode) {
         /* Device tree has information about the following mode types. */
@@ -415,19 +419,18 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 	pip_path = fdt_getprop(fdt_addr, aliases, "pip", NULL);
 	if (!pip_path) {
 		cvmx_dprintf("%s: ERROR: "
-			"interface %u pip path not found in device tree\n",
-		         __func__, interface_num);
+			"interface %x pip path not found in device tree\n",
+		         __func__, xiface);
 		return -1;
 	}
 	pip = fdt_path_offset(fdt_addr, pip_path);
 	if (pip < 0) {
 		cvmx_dprintf("%s: ERROR: "
-			"interface %u pip not found in device tree\n",
-			__func__, interface_num);
+			"interface %x pip not found in device tree\n",
+			__func__, xiface);
 		return -1;
 	}
-	snprintf(name_buffer, sizeof(name_buffer), "interface@%d",
-		 interface_num);
+	snprintf(name_buffer, sizeof(name_buffer), "interface@%d", xi.interface);
 	iface = fdt_subnode_offset(fdt_addr, pip, name_buffer);
 	if (iface < 0)
 		return 0;
@@ -441,30 +444,34 @@ int __cvmx_helper_board_get_port_from_dt(void *fdt_addr, int ipd_port)
 		return -1;
 
 	if (fdt_getprop(fdt_addr, eth, "cavium,sgmii-mac-phy-mode", NULL))
-		cvmx_helper_set_mac_phy_mode(interface_num, port_index, true);
+		cvmx_helper_set_mac_phy_mode(xiface, port_index, true);
 	else
-		cvmx_helper_set_mac_phy_mode(interface_num, port_index, false);
+		cvmx_helper_set_mac_phy_mode(xiface, port_index, false);
+
+	if (fdt_getprop(fdt_addr, eth, "cavium,force-link-up", NULL))
+		cvmx_helper_set_port_force_link_up(xiface, port_index, true);
+	else
+		cvmx_helper_set_port_force_link_up(xiface, port_index, false);
 
 	if (fdt_getprop(fdt_addr, eth, "cavium,sgmii-mac-1000x-mode", NULL))
-		cvmx_helper_set_1000x_mode(interface_num, port_index, true);
+		cvmx_helper_set_1000x_mode(xiface, port_index, true);
 	else
-		cvmx_helper_set_1000x_mode(interface_num, port_index, false);
+		cvmx_helper_set_1000x_mode(xiface, port_index, false);
 
 	if (mode == CVMX_HELPER_INTERFACE_MODE_AGL) {
-		if (fdt_getprop(fdt_addr, eth,
-				"cavium,rx-clk-delay-bypass", NULL))
-			cvmx_helper_set_agl_rx_clock_delay_bypass(interface_num,
+		if (fdt_getprop(fdt_addr, eth, "cavium,rx-clk-delay-bypass", NULL))
+			cvmx_helper_set_agl_rx_clock_delay_bypass(xiface,
 								  port_index,
 								  true);
 		else
-			cvmx_helper_set_agl_rx_clock_delay_bypass(interface_num,
+			cvmx_helper_set_agl_rx_clock_delay_bypass(xiface,
 								  port_index,
 								  false);
 
 		val = (uint32_t *)fdt_getprop(fdt_addr, eth,
 					      "cavium,rx-clk-skew", NULL);
 
-		cvmx_helper_set_agl_rx_clock_skew(interface_num, port_index,
+		cvmx_helper_set_agl_rx_clock_skew(xiface, port_index,
 						  (val) ?
 						  fdt32_to_cpu(*val) : 0);
 	}
@@ -566,11 +573,23 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 		cvmx_dprintf("ERROR: no compatible prop in phy\n");
 		return -1;
 	}
+	if (device_tree_dbg)
+		cvmx_dprintf("Checking compatible string \"%s\" for ipd port %d\n",
+			     phy_compatible_str, ipd_port);
 	if (!memcmp("marvell", phy_compatible_str, strlen("marvell"))) {
+		if (device_tree_dbg)
+			cvmx_dprintf("Marvell PHY detected for ipd_port %d\n",
+				     ipd_port);
 		phy_info->phy_type = MARVELL_GENERIC_PHY;
 	} else if (!memcmp("broadcom", phy_compatible_str, strlen("broadcom"))) {
 		phy_info->phy_type = BROADCOM_GENERIC_PHY;
+		if (device_tree_dbg)
+			cvmx_dprintf("Broadcom PHY detected for ipd_port %d\n",
+				     ipd_port);
 	} else if (!memcmp("vitesse", phy_compatible_str, strlen("vitesse"))) {
+		if (device_tree_dbg)
+			cvmx_dprintf("Vitesse PHY detected for ipd_port %d\n",
+				     ipd_port);
 		if (!fdt_node_check_compatible(fdt_addr, phy,
 					       "ethernet-phy-ieee802.3-c22")) {
 			phy_info->phy_type = GENERIC_8023_C22_PHY;
@@ -586,9 +605,15 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
 		host_mode_str = (const char *)fdt_getprop(fdt_addr, phy,
 							  "cortina,host-mode",
 							  NULL);
+		if (device_tree_dbg)
+			cvmx_dprintf("Cortina PHY detected for ipd_port %d\n",
+				     ipd_port);
 	} else if (!memcmp("ti", phy_compatible_str, strlen("ti"))) {
 		phy_info->phy_type = GENERIC_8023_C45_PHY;
 
+		if (device_tree_dbg)
+			cvmx_dprintf("TI PHY detected for ipd_port %d\n",
+				     ipd_port);
 	} else if (!fdt_node_check_compatible(fdt_addr, phy,
 					      "ethernet-phy-ieee802.3-c22")) {
 		phy_info->phy_type = GENERIC_8023_C22_PHY;
@@ -812,7 +837,6 @@ int cvmx_helper_board_get_mii_address(int ipd_port)
 					     __func__, ipd_port);
 			return retcode;
 		}
-		//cvmx_dprintf("ipd_port=%d phy_addr=%d\n", ipd_port, phy_info.phy_addr);
 		if (phy_info.phy_addr >= 0) {
 			if (phy_info.direct_connect == 0) {
 				if (device_tree_dbg)
@@ -1749,6 +1773,7 @@ int cvmx_helper_board_link_set_phy(int phy_addr, cvmx_helper_board_set_phy_link_
 			cvmx_mdio_write(phy_addr >> 8, phy_addr & 0xff, CVMX_MDIO_PHY_REG_CONTROL_1000, reg_control_1000.u16);
 		}
 		reg_control.u16 = cvmx_mdio_read(phy_addr >> 8, phy_addr & 0xff, CVMX_MDIO_PHY_REG_CONTROL);
+		reg_control.s.reset = 1;
 		reg_control.s.autoneg_enable = 1;
 		reg_control.s.restart_autoneg = 1;
 		cvmx_mdio_write(phy_addr >> 8, phy_addr & 0xff, CVMX_MDIO_PHY_REG_CONTROL, reg_control.u16);
@@ -1788,13 +1813,16 @@ int cvmx_helper_board_link_set_phy(int phy_addr, cvmx_helper_board_set_phy_link_
 		if (reg_status.s.capable_extended_status)
 			cvmx_mdio_write(phy_addr >> 8, phy_addr & 0xff, CVMX_MDIO_PHY_REG_CONTROL_1000, reg_control_1000.u16);
 		reg_control.u16 = cvmx_mdio_read(phy_addr >> 8, phy_addr & 0xff, CVMX_MDIO_PHY_REG_CONTROL);
+		reg_control.s.reset = 1;
 		reg_control.s.autoneg_enable = 1;
 		reg_control.s.restart_autoneg = 1;
 		cvmx_mdio_write(phy_addr >> 8, phy_addr & 0xff, CVMX_MDIO_PHY_REG_CONTROL, reg_control.u16);
 	} else {
 		cvmx_mdio_phy_reg_control_t reg_control;
 		reg_control.u16 = cvmx_mdio_read(phy_addr >> 8, phy_addr & 0xff, CVMX_MDIO_PHY_REG_CONTROL);
+		reg_control.s.reset = 1;
 		reg_control.s.autoneg_enable = 0;
+		reg_control.s.reset = 1;
 		reg_control.s.restart_autoneg = 1;
 		reg_control.s.duplex = link_info.s.full_duplex;
 		if (link_info.s.speed == 1000) {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
index 45d6682..6fbf467 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
@@ -77,14 +77,12 @@
 #define min( a, b ) ( ( a ) < ( b ) ) ? ( a ) : ( b )
 #endif
 
-/* #define CVMX_HELPER_CFG_DEBUG */
-
-CVMX_SHARED struct cvmx_cfg_port_param cvmx_cfg_port[CVMX_HELPER_MAX_IFACE][CVMX_HELPER_CFG_MAX_PORT_PER_IFACE] =
-	{[0 ... CVMX_HELPER_MAX_IFACE - 1] = {[0 ... CVMX_HELPER_CFG_MAX_PORT_PER_IFACE - 1] =
+CVMX_SHARED struct cvmx_cfg_port_param cvmx_cfg_port[CVMX_MAX_NODES][CVMX_HELPER_MAX_IFACE][CVMX_HELPER_CFG_MAX_PORT_PER_IFACE] =
+	{[0 ... CVMX_MAX_NODES - 1][0 ... CVMX_HELPER_MAX_IFACE - 1] = {[0 ... CVMX_HELPER_CFG_MAX_PORT_PER_IFACE - 1] =
 				      	      { CVMX_HELPER_CFG_INVALID_VALUE, CVMX_HELPER_CFG_INVALID_VALUE,
 				                CVMX_HELPER_CFG_INVALID_VALUE, CVMX_HELPER_CFG_INVALID_VALUE,
 	                                        CVMX_HELPER_CFG_INVALID_VALUE, 0,
-	                                        0, 0, 0}}};
+	                                        0, 0, 0, false}}};
 
 /*
  * Indexed by the pko_port number
@@ -135,24 +133,28 @@ static CVMX_SHARED uint64_t cvmx_cfg_opts[CVMX_HELPER_CFG_OPT_MAX] = {[0 ... CVM
  */
 static CVMX_SHARED int cvmx_cfg_max_pko_engines;	/* # of PKO DMA engines
 							   allocated */
-int __cvmx_helper_cfg_pknd(int interface, int index)
+int __cvmx_helper_cfg_pknd(int xiface, int index)
 {
-	return cvmx_cfg_port[interface][index].ccpp_pknd;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].ccpp_pknd;
 }
 
-int __cvmx_helper_cfg_bpid(int interface, int index)
+int __cvmx_helper_cfg_bpid(int xiface, int index)
 {
-	return cvmx_cfg_port[interface][index].ccpp_bpid;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].ccpp_bpid;
 }
 
-int __cvmx_helper_cfg_pko_port_base(int interface, int index)
+int __cvmx_helper_cfg_pko_port_base(int xiface, int index)
 {
-	return cvmx_cfg_port[interface][index].ccpp_pko_port_base;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].ccpp_pko_port_base;
 }
 
-int __cvmx_helper_cfg_pko_port_num(int interface, int index)
+int __cvmx_helper_cfg_pko_port_num(int xiface, int index)
 {
-	return cvmx_cfg_port[interface][index].ccpp_pko_num_ports;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].ccpp_pko_num_ports;
 }
 
 int __cvmx_helper_cfg_pko_queue_num(int pko_port)
@@ -431,8 +433,8 @@ void cvmx_helper_cfg_init_pko_port_map(void)
 	for (i = 0; i < cvmx_helper_get_number_of_interfaces(); i++) {
 		mode = cvmx_helper_interface_get_mode(i);
 		for (j = 0; j < cvmx_helper_interface_enumerate(i); j++) {
-			pko_port_base = cvmx_cfg_port[i][j].ccpp_pko_port_base;
-			pko_port_max = pko_port_base + cvmx_cfg_port[i][j].ccpp_pko_num_ports;
+			pko_port_base = cvmx_cfg_port[0][i][j].ccpp_pko_port_base;
+			pko_port_max = pko_port_base + cvmx_cfg_port[0][i][j].ccpp_pko_num_ports;
 			cvmx_helper_cfg_assert(pko_port_base != CVMX_HELPER_CFG_INVALID_VALUE);
 			cvmx_helper_cfg_assert(pko_port_max >= pko_port_base);
 			for (k = pko_port_base; k < pko_port_max; k++) {
@@ -648,30 +650,34 @@ int cvmx_helper_cfg_ipd2pko_port_num(int ipd_port)
  * @param pko_port
  * @return the number of queues for this pko_port
  *
- * Note: This function exists for backward compatibility.
- * CVMX_PKO_QUEUES_PER_PORT_XXXX defines no of queues per HW port.
- * pko_port is equivalent in pre-o68 SDK.
  */
-int cvmx_helper_cfg_dft_nqueues(int pko_port)
+static int cvmx_helper_cfg_dft_nqueues(int pko_port)
 {
 	cvmx_helper_interface_mode_t mode;
 	int interface;
 	int n;
+	int ret;
 
-	n = 1;
 	interface = __cvmx_helper_cfg_pko_port_interface(pko_port);
-	if ((interface >= 0) && (interface <=4) )  {
-		return __cvmx_pko_queue_static_config.pknd.pko_queues_per_port_interface[interface];
-	}
-
 	mode = cvmx_helper_interface_get_mode(interface);
+
+	n = NUM_ELEMENTS(__cvmx_pko_queue_static_config.pknd.pko_cfg_iface);
+
 	if (mode == CVMX_HELPER_INTERFACE_MODE_LOOP) {
-		return __cvmx_pko_queue_static_config.pknd.pko_queues_per_port_loop;
+		ret =  __cvmx_pko_queue_static_config.pknd.pko_cfg_loop.queues_per_port;
 	}
-	if (mode == CVMX_HELPER_INTERFACE_MODE_NPI) {
-		return __cvmx_pko_queue_static_config.pknd.pko_queues_per_port_pci;
+	else if (mode == CVMX_HELPER_INTERFACE_MODE_NPI) {
+		ret =  __cvmx_pko_queue_static_config.pknd.pko_cfg_npi.queues_per_port;
 	}
-	return n;
+
+
+	else if ((interface >= 0) && (interface < n) )  {
+		ret = __cvmx_pko_queue_static_config.pknd.pko_cfg_iface[interface].queues_per_port;
+	} else {
+		/* Should never be called */
+		ret = 1;
+	}
+	return ret;
 }
 
 static int cvmx_helper_cfg_init_pko_iports_and_queues_using_static_config(void)
@@ -685,8 +691,8 @@ static int cvmx_helper_cfg_init_pko_iports_and_queues_using_static_config(void)
 	for (i = 0; i < cvmx_helper_get_number_of_interfaces(); i++) {
 		n = cvmx_helper_interface_enumerate(i);
 		for (j = 0; j < n; j++) {
-			cvmx_cfg_port[i][j].ccpp_pko_port_base = pko_port_base;
-			cvmx_cfg_port[i][j].ccpp_pko_num_ports = cvmx_cfg_default_pko_nports;
+			cvmx_cfg_port[0][i][j].ccpp_pko_port_base = pko_port_base;
+			cvmx_cfg_port[0][i][j].ccpp_pko_num_ports = cvmx_cfg_default_pko_nports;
 			/* Initalize interface early here so that the
 			   cvmx_helper_cfg_dft_nqueues() below
 			   can get the interface number corresponding to the pko port */
@@ -720,67 +726,91 @@ static int cvmx_helper_cfg_init_pko_iports_and_queues_using_static_config(void)
  *
  * @return status of the port present or not.
  */
-int cvmx_helper_is_port_valid(int interface, int index)
+int cvmx_helper_is_port_valid(int xiface, int index)
 {
-	return  cvmx_cfg_port[interface][index].valid;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return  cvmx_cfg_port[xi.node][xi.interface][index].valid;
 }
 EXPORT_SYMBOL(cvmx_helper_is_port_valid);
 
-void cvmx_helper_set_port_valid(int interface, int index, bool valid)
+void cvmx_helper_set_port_valid(int xiface, int index, bool valid)
 {
-	cvmx_cfg_port[interface][index].valid = valid;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	cvmx_cfg_port[xi.node][xi.interface][index].valid = valid;
 }
 EXPORT_SYMBOL(cvmx_helper_set_port_valid);
 
-void cvmx_helper_set_mac_phy_mode(int interface, int index, bool valid)
+void cvmx_helper_set_mac_phy_mode(int xiface, int index, bool valid)
 {
-	cvmx_cfg_port[interface][index].sgmii_phy_mode = valid;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	cvmx_cfg_port[xi.node][xi.interface][index].sgmii_phy_mode = valid;
 }
 EXPORT_SYMBOL(cvmx_helper_set_mac_phy_mode);
 
-bool cvmx_helper_get_mac_phy_mode(int interface, int index)
+bool cvmx_helper_get_mac_phy_mode(int xiface, int index)
 {
-	return cvmx_cfg_port[interface][index].sgmii_phy_mode;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].sgmii_phy_mode;
 }
 EXPORT_SYMBOL(cvmx_helper_get_mac_phy_mode);
 
-void cvmx_helper_set_1000x_mode(int interface, int index, bool valid)
+void cvmx_helper_set_1000x_mode(int xiface, int index, bool valid)
 {
-	cvmx_cfg_port[interface][index].sgmii_1000x_mode = valid;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	cvmx_cfg_port[xi.node][xi.interface][index].sgmii_1000x_mode = valid;
 }
 EXPORT_SYMBOL(cvmx_helper_set_1000x_mode);
 
-bool cvmx_helper_get_1000x_mode(int interface, int index)
+bool cvmx_helper_get_1000x_mode(int xiface, int index)
 {
-	return cvmx_cfg_port[interface][index].sgmii_1000x_mode;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].sgmii_1000x_mode;
 }
 EXPORT_SYMBOL(cvmx_helper_get_1000x_mode);
 
-void cvmx_helper_set_agl_rx_clock_delay_bypass(int interface, int index,
+void cvmx_helper_set_agl_rx_clock_delay_bypass(int xiface, int index,
 					       bool valid)
 {
-	cvmx_cfg_port[interface][index].agl_rx_clk_delay_bypass = valid;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	cvmx_cfg_port[xi.node][xi.interface][index].agl_rx_clk_delay_bypass = valid;
 }
 EXPORT_SYMBOL(cvmx_helper_set_agl_rx_clock_delay_bypass);
 
-bool cvmx_helper_get_agl_rx_clock_delay_bypass(int interface, int index)
+bool cvmx_helper_get_agl_rx_clock_delay_bypass(int xiface, int index)
 {
-	return cvmx_cfg_port[interface][index].agl_rx_clk_delay_bypass;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].agl_rx_clk_delay_bypass;
 }
 EXPORT_SYMBOL(cvmx_helper_get_agl_rx_clock_delay_bypass);
 
-void cvmx_helper_set_agl_rx_clock_skew(int interface, int index, uint8_t value)
+void cvmx_helper_set_agl_rx_clock_skew(int xiface, int index, uint8_t value)
 {
-	cvmx_cfg_port[interface][index].agl_rx_clk_skew = value;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	cvmx_cfg_port[xi.node][xi.interface][index].agl_rx_clk_skew = value;
 }
 EXPORT_SYMBOL(cvmx_helper_set_agl_rx_clock_skew);
 
-uint8_t cvmx_helper_get_agl_rx_clock_skew(int interface, int index)
+uint8_t cvmx_helper_get_agl_rx_clock_skew(int xiface, int index)
 {
-	return cvmx_cfg_port[interface][index].agl_rx_clk_skew;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].agl_rx_clk_skew;
 }
 EXPORT_SYMBOL(cvmx_helper_get_agl_rx_clock_skew);
 
+void cvmx_helper_set_port_force_link_up(int xiface, int index, bool value)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	cvmx_cfg_port[xi.node][xi.interface][index].force_link_up = value;
+}
+EXPORT_SYMBOL(cvmx_helper_set_port_force_link_up);
+
+bool cvmx_helper_get_port_force_link_up(int xiface, int index)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_cfg_port[xi.node][xi.interface][index].force_link_up;
+}
+EXPORT_SYMBOL(cvmx_helper_get_port_force_link_up);
+
 int __cvmx_helper_init_port_valid(void)
 {
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
@@ -901,8 +931,8 @@ int __cvmx_helper_init_port_config_data(void)
 		for (i = 0; i < cvmx_helper_get_number_of_interfaces(); i++) {
 			n = cvmx_helper_interface_enumerate(i);
 			for (j = 0; j < n; j++) {
-				cvmx_cfg_port[i][j].ccpp_pknd = pknd++;
-				cvmx_cfg_port[i][j].ccpp_bpid = bpid++;
+				cvmx_cfg_port[0][i][j].ccpp_pknd = pknd++;
+				cvmx_cfg_port[0][i][j].ccpp_bpid = bpid++;
 			}
 		}
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-errata.c b/arch/mips/cavium-octeon/executive/cvmx-helper-errata.c
index 0ff373d..85dc3a0 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-errata.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-errata.c
@@ -45,7 +45,7 @@
  * chip errata. For the most part, code doesn't need to call
  * these functions directly.
  *
- * <hr>$Revision: 95258 $<hr>
+ * <hr>$Revision: 95626 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
index 4fd15cd..5dea91b 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2010-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -70,10 +70,11 @@
 #endif
 
 
-int __cvmx_helper_ilk_enumerate(int interface)
+int __cvmx_helper_ilk_enumerate(int xiface)
 {
-	interface -= CVMX_ILK_GBL_BASE();
-	return cvmx_ilk_chans[interface];
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	xi.interface -= CVMX_ILK_GBL_BASE();
+	return cvmx_ilk_chans[xi.interface];
 }
 
 /**
@@ -86,7 +87,7 @@ int __cvmx_helper_ilk_enumerate(int interface)
  *
  * @param interface Interface whose calendar are to be initialized.
  */
-void __cvmx_78xx_ilk_init_cal(int interface)
+void __cvmx_ilk_init_cal_cn78xx(int interface)
 {
 	cvmx_ilk_txx_cal_entryx_t	tx_entry;
 	cvmx_ilk_rxx_cal_entryx_t	rx_entry;
@@ -119,7 +120,7 @@ void __cvmx_78xx_ilk_init_cal(int interface)
  *
  * @param interface Interface whose calendar are to be initialized.
  */
-void __cvmx_68xx_ilk_init_cal(int interface)
+void __cvmx_ilk_init_cal_cn68xx(int interface)
 {
 	cvmx_ilk_txx_idx_cal_t	tx_idx;
 	cvmx_ilk_txx_mem_cal0_t tx_cal0;
@@ -193,22 +194,14 @@ void __cvmx_68xx_ilk_init_cal(int interface)
 void __cvmx_ilk_init_cal(int interface)
 {
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
-		__cvmx_68xx_ilk_init_cal(interface);
+		__cvmx_ilk_init_cal_cn68xx(interface);
 	else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-		__cvmx_78xx_ilk_init_cal(interface);
+		__cvmx_ilk_init_cal_cn78xx(interface);
 }
 
-/**
- * @INTERNAL
- * Setup the channel's tx calendar entry.
- *
- * @param interface Interface channel belongs to
- * @param channel Channel whose calendar entry is to be updated
- * @param bpid Bpid assigned to the channel
- */
-void __cvmx_ilk_write_tx_cal_entry(int			interface,
-				   int			channel,
-				   unsigned char	bpid)
+void __cvmx_ilk_write_tx_cal_entry_cn68xx(int interface,
+					  int channel,
+					  unsigned char bpid)
 {
 	cvmx_ilk_txx_idx_cal_t	tx_idx;
 	cvmx_ilk_txx_mem_cal0_t	tx_cal0;
@@ -292,17 +285,75 @@ void __cvmx_ilk_write_tx_cal_entry(int			interface,
 	cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL1(interface), tx_cal1.u64);
 }
 
+void __cvmx_ilk_write_tx_cal_entry_cn78xx(int interface,
+					  int channel,
+					  unsigned char bpid)
+{
+	cvmx_ilk_txx_cal_entryx_t tx_cal;
+	int calender_16_block = channel / 15;
+	int calender_16_index = channel % 15 + 1;
+	int index = calender_16_block * 16 + calender_16_index;
+
+	/* Program the link status on first channel */
+	if (calender_16_index == 1) {
+		tx_cal.u64 = 0;
+		tx_cal.s.ctl = 1;
+		cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(index - 1, interface),
+				tx_cal.u64);
+	} else {
+		tx_cal.u64 = 0;
+		tx_cal.s.ctl = 0;
+		tx_cal.s.channel = channel;
+		cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(index - 1, interface),
+				tx_cal.u64);
+	}
+}
+	
 /**
  * @INTERNAL
- * Setup the channel's rx calendar entry.
+ * Setup the channel's tx calendar entry.
  *
  * @param interface Interface channel belongs to
  * @param channel Channel whose calendar entry is to be updated
- * @param pipe PKO assigned to the channel
+ * @param bpid Bpid assigned to the channel
  */
-void __cvmx_ilk_write_rx_cal_entry(int			interface,
+void __cvmx_ilk_write_tx_cal_entry(int			interface,
 				   int			channel,
-				   unsigned char	pipe)
+				   unsigned char	bpid)
+{
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		__cvmx_ilk_write_tx_cal_entry_cn68xx(interface, channel, bpid);
+	else
+		__cvmx_ilk_write_tx_cal_entry_cn78xx(interface, channel, bpid);
+}
+
+void __cvmx_ilk_write_rx_cal_entry_cn78xx(int interface,
+					  int channel,
+					  unsigned char bpid)
+{
+	cvmx_ilk_rxx_cal_entryx_t rx_cal;
+	int calender_16_block = channel / 15;
+	int calender_16_index = channel % 15 + 1;
+	int index = calender_16_block * 16 + calender_16_index;
+
+	/* Program the link status on first channel */
+	if (calender_16_index == 1) {
+		rx_cal.u64 = 0;
+		rx_cal.s.ctl = 1;
+		cvmx_write_csr(CVMX_ILK_RXX_CAL_ENTRYX(index - 1, interface),
+				rx_cal.u64);
+	} else {
+		rx_cal.u64 = 0;
+		rx_cal.s.ctl = 0;
+		rx_cal.s.channel = channel;
+		cvmx_write_csr(CVMX_ILK_RXX_CAL_ENTRYX(index - 1, interface),
+				rx_cal.u64);
+	}
+}
+
+void __cvmx_ilk_write_rx_cal_entry_cn68xx(int interface,
+					  int channel,
+					  unsigned char pipe)
 {
 	cvmx_ilk_rxx_idx_cal_t	rx_idx;
 	cvmx_ilk_rxx_mem_cal0_t	rx_cal0;
@@ -388,6 +439,24 @@ void __cvmx_ilk_write_rx_cal_entry(int			interface,
 
 /**
  * @INTERNAL
+ * Setup the channel's rx calendar entry.
+ *
+ * @param interface Interface channel belongs to
+ * @param channel Channel whose calendar entry is to be updated
+ * @param pipe PKO assigned to the channel
+ */
+void __cvmx_ilk_write_rx_cal_entry(int			interface,
+				   int			channel,
+				   unsigned char	pipe)
+{
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		__cvmx_ilk_write_rx_cal_entry_cn68xx(interface, channel, pipe);
+	else
+		__cvmx_ilk_write_rx_cal_entry_cn78xx(interface, channel, pipe);
+}
+
+/**
+ * @INTERNAL
  * Probe a ILK interface and determine the number of ports
  * connected to it. The ILK interface should still be down
  * after this call.
@@ -396,14 +465,16 @@ void __cvmx_ilk_write_rx_cal_entry(int			interface,
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-int __cvmx_helper_ilk_probe(int interface)
+int __cvmx_helper_ilk_probe(int xiface)
 {
 	int res = 0;
+	int interface;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
-	interface -= CVMX_ILK_GBL_BASE();
+	interface = xi.interface - CVMX_ILK_GBL_BASE();
 	if (interface >= CVMX_NUM_ILK_INTF)
 		return 0;
 
@@ -416,12 +487,12 @@ int __cvmx_helper_ilk_probe(int interface)
 	if (res < 0)
 		return 0;
 
-	res = __cvmx_helper_ilk_enumerate(interface + CVMX_ILK_GBL_BASE());
+	res = __cvmx_helper_ilk_enumerate(xiface);
 
 	return res;
 }
 
-static int __cvmx_helper_ilk_init_port(int interface)
+static int __cvmx_helper_ilk_init_port(int xiface)
 {
 	int i, j, res = -1;
 	static int pipe_base = 0, pknd_base = 0;
@@ -429,11 +500,17 @@ static int __cvmx_helper_ilk_init_port(int interface)
 	static cvmx_ilk_chan_pknd_t *chpknd = NULL, *tmp1;
 	static cvmx_ilk_cal_entry_t *calent = NULL, *tmp2;
 	int enable_rx_cal = 1;
+	int interface;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
-	interface -= CVMX_ILK_GBL_BASE();
+	interface = xi.interface - CVMX_ILK_GBL_BASE();
 	if (interface >= CVMX_NUM_ILK_INTF)
 		return 0;
 
+	/* set up channel to pkind mapping */
+	if (pknd_base == 0)
+		pknd_base = cvmx_helper_get_pknd(xiface, 0);
+
 	/* set up the group of pipes available to ilk */
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		if (pipe_base == 0)
@@ -474,12 +551,7 @@ static int __cvmx_helper_ilk_init_port(int interface)
 			goto err_free_pch;
 		}
 		pipe_base += cvmx_ilk_chans[interface];
-	}
-
-	/* set up channel to pkind mapping */
-	if (pknd_base == 0)
-		pknd_base = cvmx_helper_get_pknd(interface + CVMX_ILK_GBL_BASE(), 0);
-	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 		pipe_base = pknd_base + cvmx_ilk_chans[interface];
 
 	i = pknd_base;
@@ -565,8 +637,6 @@ static int __cvmx_helper_ilk_init_port(int interface)
 	}
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		enable_rx_cal = 1;
-		//FIXME: Comfigure CVMX_ILK_RID_CFG for RID range 
-		//using global resources and #RIDs = #chans for iface
 	}
 	res = cvmx_ilk_cal_setup_rx(interface, cvmx_ilk_chans[interface], calent, CVMX_ILK_RX_FIFO_WM, enable_rx_cal);
 	if (res < 0) {
@@ -611,12 +681,13 @@ out:
  *
  * @return Zero on success, negative on failure
  */
-int __cvmx_helper_ilk_enable(int interface)
+int __cvmx_helper_ilk_enable(int xiface)
 {
-	if (__cvmx_helper_ilk_init_port(interface) < 0)
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	if (__cvmx_helper_ilk_init_port(xiface) < 0)
 		return -1;
 
-	return cvmx_ilk_enable(interface - CVMX_ILK_GBL_BASE());
+	return cvmx_ilk_enable(xi.interface - CVMX_ILK_GBL_BASE());
 }
 
 /**
@@ -630,7 +701,9 @@ int __cvmx_helper_ilk_enable(int interface)
 cvmx_helper_link_info_t __cvmx_helper_ilk_link_get(int ipd_port)
 {
 	cvmx_helper_link_info_t result;
-	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(ipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface;
 	int retry_count = 0;
 	cvmx_ilk_rxx_cfg1_t ilk_rxx_cfg1;
 	cvmx_ilk_rxx_int_t ilk_rxx_int;
@@ -638,7 +711,7 @@ cvmx_helper_link_info_t __cvmx_helper_ilk_link_get(int ipd_port)
 	int i;
 
 	result.u64 = 0;
-	interface -= CVMX_ILK_GBL_BASE();
+	interface = xi.interface - CVMX_ILK_GBL_BASE();
 
 retry:
 	retry_count++;
@@ -656,7 +729,7 @@ retry:
 		cvmx_write_csr(CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
 
 		/* We need to start looking for word boundary lock */
-		ilk_rxx_cfg1.s.rx_bdry_lock_ena = cvmx_ilk_get_intf_ln_msk(interface);
+		ilk_rxx_cfg1.s.rx_bdry_lock_ena = cvmx_ilk_lane_mask[interface];
 		ilk_rxx_cfg1.s.rx_align_ena = 0;
 		cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 		//cvmx_dprintf("ILK%d: Looking for word boundary lock\n", interface);
@@ -712,8 +785,7 @@ retry:
 			 */
 			cvmx_write_csr(CVMX_ILK_RXX_INT_EN(interface), 0x1e2);
 		}
-		else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-			cvmx_write_csr(CVMX_ILK_GBL_INT, 0x18);
+		/* FIXME: Enable ILK interrupts for 78xx */
 
 		for (i = 0; i < CVMX_ILK_MAX_LANES(); i++) {
 			if ((1 << i) & lane_mask) {
@@ -731,7 +803,11 @@ retry:
 
 	result.s.link_up = 1;
 	result.s.full_duplex = 1;
-	result.s.speed = cvmx_qlm_get_gbaud_mhz(1 + interface) * 64 / 67;
+ 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		int qlm = cvmx_qlm_interface(interface);
+		result.s.speed = cvmx_qlm_get_gbaud_mhz(qlm) * 64 / 67;
+	} else
+		result.s.speed = cvmx_qlm_get_gbaud_mhz(1 + interface) * 64 / 67;
 	result.s.speed *= cvmx_pop(lane_mask);
 
 	return result;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-ipd.c b/arch/mips/cavium-octeon/executive/cvmx-helper-ipd.c
index f7c9edb..b5d66c0 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-ipd.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-ipd.c
@@ -256,7 +256,7 @@ int __cvmx_helper_ipd_setup_interface(int interface)
 
 	delta = 1;
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII)
+		if (interface < CVMX_HELPER_MAX_GMX)
 			delta = 16;
 	}
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
index 5625c90..03680f9 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
@@ -66,50 +66,55 @@
 #include "cvmx-global-resources.h"
 #endif
 
-static int pki_helper_debug;
-
-struct cvmx_pki_global_config pki_dflt_gblcfg[CVMX_MAX_NODES] = {
-	{.cluster_mask = {0xf, 0, 0, 0},
-	.stat_mode = CVMX_PKI_STAT_MODE_PKIND,
-	.gbl_pen = {0, 0, 0, 1, 0, 1, 0, 0, 0, 0},
-	.frm_len = { {0x600, 0x40}, {0x600, 0x40} },
-	.pki_enable = 1},
-	{.cluster_mask = {0xf, 0, 0, 0},
-	.stat_mode = CVMX_PKI_STAT_MODE_PKIND,
-	.gbl_pen = {0, 0, 0, 1, 0, 1, 0, 0, 0, 0},
-	.frm_len = { {0x600, 0x40}, {0x600, 0x40} },
-	.pki_enable = 1} };
-
-struct cvmx_pki_cluster_grp_config pki_dflt_clgrp[CVMX_MAX_NODES] = {
+struct cvmx_pki_cluster_grp_config {
+	int grp_num;
+	uint64_t cluster_mask; /* bit mask of cluster assigned to this cluster group */
+};
+
+struct cvmx_pki_sso_grp_config {
+	int sso_grp_num;
+	int priority;
+	int weight;
+	int affinity;
+	uint64_t core_mask;
+	uint8_t core_mask_set;
+};
+
+struct cvmx_pki_aura_config {
+	int aura_num;
+	int pool_num;
+	int buffer_count;
+};
+
+
+static CVMX_SHARED int pki_helper_debug;
+
+CVMX_SHARED bool cvmx_pki_dflt_init[CVMX_MAX_NODES] = {[0 ... CVMX_MAX_NODES-1] = 1};
+
+static CVMX_SHARED struct cvmx_pki_cluster_grp_config pki_dflt_clgrp[CVMX_MAX_NODES] = {
 	{0, 0xf},
 	{0, 0xf} };
 
-struct cvmx_pki_pool_config pki_dflt_pool[CVMX_MAX_NODES] = {
-	{.pool_num = 0, .buffer_size = 2048, .buffer_count = 1000},
-	{.pool_num = 0, .buffer_size = 2048, .buffer_count = 1000} };
-
-struct cvmx_pki_aura_config pki_dflt_aura[CVMX_MAX_NODES] = {
-	{.aura_num = 0, .pool_num = 0, .buffer_count = 1000},
-	{.aura_num = 0, .pool_num = 0, .buffer_count = 1000} };
-
-struct cvmx_pki_style_config pki_dflt_style[CVMX_MAX_NODES] = {
-	{.parm_cfg = {.lenerr_en = 1, .maxerr_en = 1, .minerr_en = 1,
-	.fcs_strip = 1, .fcs_chk = 1, .first_skip = 40, .mbuff_size = 2048},
-	.tag_cfg = {.tag_fields = {.input_port = 1} } },
-	{.parm_cfg = {.lenerr_en = 1, .maxerr_en = 1, .minerr_en = 1,
-	.fcs_strip = 1, .fcs_chk = 1, .first_skip = 40, .mbuff_size = 2048},
-	.tag_cfg = {.tag_fields = {.input_port = 1} } } };
-
-struct cvmx_pki_sso_grp_config pki_dflt_sso_grp[CVMX_MAX_NODES];
-struct cvmx_pki_qpg_config pki_dflt_qpg[CVMX_MAX_NODES];
-struct cvmx_pki_pkind_config pki_dflt_pkind[CVMX_MAX_NODES];
-uint64_t pkind_style_map[CVMX_MAX_NODES][CVMX_PKI_NUM_PKIND] = {
-	{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
-	16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
-	32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
-	48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63},
-	{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
-	16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
+CVMX_SHARED struct cvmx_pki_pool_config pki_dflt_pool[CVMX_MAX_NODES] = { [0 ... CVMX_MAX_NODES-1] = {
+	.pool_num = -1,
+	.buffer_size = 2048,
+	.buffer_count = 1000} };
+
+static CVMX_SHARED struct cvmx_pki_aura_config pki_dflt_aura[CVMX_MAX_NODES] = { [0 ... CVMX_MAX_NODES-1] = {
+	.aura_num = 0,
+	.pool_num = -1,
+	.buffer_count = 1000} };
+
+CVMX_SHARED struct cvmx_pki_style_config pki_dflt_style[CVMX_MAX_NODES] = { [0 ... CVMX_MAX_NODES-1] = {
+	.parm_cfg = {.lenerr_en = 1, .maxerr_en = 1, .minerr_en = 1,
+	.fcs_strip = 1, .fcs_chk = 1, .first_skip = 40, .mbuff_size = 2048} } };
+
+static CVMX_SHARED struct cvmx_pki_sso_grp_config pki_dflt_sso_grp[CVMX_MAX_NODES];
+static CVMX_SHARED struct cvmx_pki_qpg_config pki_dflt_qpg[CVMX_MAX_NODES];
+CVMX_SHARED struct cvmx_pki_pkind_config pki_dflt_pkind[CVMX_MAX_NODES];
+CVMX_SHARED uint64_t pkind_style_map[CVMX_MAX_NODES][CVMX_PKI_NUM_PKIND] = { [0 ... CVMX_MAX_NODES-1] = {
+	0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
+        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
 	32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
 	48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63} };
 
@@ -118,8 +123,7 @@ int __cvmx_helper_setup_pki_cluster_groups(int node)
 	uint64_t cl_mask;
 	int cl_group;
 
-
-	cl_group = cvmx_pki_alloc_cluster_group(node, pki_dflt_clgrp[node].grp_num);
+	cl_group = cvmx_pki_cluster_grp_alloc(node, pki_dflt_clgrp[node].grp_num);
 	if (cl_group == -1) {
 		if (pki_dflt_clgrp[node].grp_num == -1)
 			return -1;
@@ -154,7 +158,7 @@ int __cvmx_helper_pki_setup_sso_groups(int node)
 #if 1
 	grp = pki_dflt_sso_grp[node].sso_grp_num;
 #else
-	grp = cvmx_sso_alloc_grp(node, pki_dflt_sso_grp[node].sso_grp_num);
+	grp = cvmx_sso_grp_alloc(node, pki_dflt_sso_grp[node].sso_grp_num);
 	if (grp == CVMX_RESOURCE_ALLOC_FAILED)
 		return -1;
 	else if (grp == CVMX_RESOURCE_ALREADY_RESERVED)
@@ -171,9 +175,8 @@ int __cvmx_helper_pki_setup_sso_groups(int node)
 			CVMX_SSO_MODIFY_GROUP_WEIGHT |
 			CVMX_SSO_MODIFY_GROUP_AFFINITY;
 	if (pki_helper_debug)
-		cvmx_dprintf("pki-helper: set sso grp %d with priority %d \
-				weight %d core_mask 0x%llx\n", grp, priority, weight,
-			     (unsigned long long)pki_dflt_sso_grp[node].core_mask);
+		cvmx_dprintf("pki-helper: set sso grp %d with priority %d weight %d core_mask 0x%llx\n",
+			     grp, priority, weight, (unsigned long long)pki_dflt_sso_grp[node].core_mask);
 	cvmx_sso_set_group_priority(node, xgrp, priority, weight,
 				    affinity, modify_mask);
 	cvmx_sso_set_group_core_affinity(xgrp, &core_mask, core_mask_set);
@@ -208,11 +211,14 @@ int __cvmx_helper_pki_setup_fpa_pools(int node)
 			cvmx_fpa3_pool_stack_init(node, pki_dflt_pool[node].pool_num, "PKI Pool0", 0,
 						 buffer_count, FPA_NATURAL_ALIGNMENT,
 						 buffer_size);
+			pki_dflt_aura[node].pool_num =  pki_dflt_pool[node].pool_num;
 		}
 	}
 	buffer_count = pki_dflt_aura[node].buffer_count;
 	if (buffer_count != 0) {
-		rs = cvmx_fpa3_allocate_auras(node, &pki_dflt_aura[node].aura_num, 1);
+		rs = cvmx_helper_fpa3_add_aura_to_pool(node, pki_dflt_pool[node].pool_num,
+						       &pki_dflt_aura[node].aura_num,
+						       buffer_count, NULL, "PKI Aura0");
 		if (rs == -1) {
 			if (pki_dflt_aura[node].aura_num == -1) {
 				cvmx_dprintf("ERROR: Failed to allocate aura %d\n", pki_dflt_aura[node].aura_num);
@@ -220,25 +226,16 @@ int __cvmx_helper_pki_setup_fpa_pools(int node)
 			} else
 				return 0; /* aura already configured, share it */
 		}
-#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper: set fpa aura %d in pool %d with buffer cnt %d\n",
-				     pki_dflt_aura[node].aura_num, pki_dflt_aura[node].pool_num,
-				     (int)buffer_count);
-		cvmx_fpa3_assign_aura(node, pki_dflt_aura[node].aura_num, pki_dflt_pool[node].pool_num);
-		cvmx_fpa3_aura_init(node, pki_dflt_aura[node].aura_num, "PKI Aura0", 0, NULL, buffer_count, 0);
-#endif
-	}
+	}	
 	return 0;
 }
 #endif
 
-
 int __cvmx_helper_setup_pki_qpg_table(int node)
 {
 	int offset;
 
-	offset = cvmx_pki_alloc_qpg_entry(node, pki_dflt_qpg[node].base_offset, 1);
+	offset = cvmx_pki_qpg_entry_alloc(node, pki_dflt_qpg[node].qpg_base, 1);
 	if (offset == CVMX_RESOURCE_ALLOC_FAILED)
 		return -1;
 	else if (offset == CVMX_RESOURCE_ALREADY_RESERVED)
@@ -252,7 +249,6 @@ int __cvmx_helper_setup_pki_qpg_table(int node)
 	return 0;
 }
 
-
 #if 0
 int __cvmx_helper_setup_pki_pcam_table(int node)
 {
@@ -298,7 +294,7 @@ int __cvmx_helper_pki_install_default_vlan(int node)
 	for (field = CVMX_PKI_PCAM_TERM_E_ETHTYPE0; field < CVMX_PKI_PCAM_TERM_E_ETHTYPE2; field++) {
 		bank = field & 0x01;
 
-		index = cvmx_pki_pcam_alloc_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
+		index = cvmx_pki_pcam_entry_alloc(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
 		if (index < 0) {
 			cvmx_dprintf("ERROR: Allocating pcam entry node=%d bank=%d\n", node, bank);
 			return -1;
@@ -315,7 +311,7 @@ int __cvmx_helper_pki_install_default_vlan(int node)
 		pcam_action.pointer_advance = 4;
 		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input, pcam_action);/*vinita_to_do, cluster_mask*/
 
-		index = cvmx_pki_pcam_alloc_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
+		index = cvmx_pki_pcam_entry_alloc(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
 		if (index < 0) {
 			cvmx_dprintf("ERROR: Allocating pcam entry node=%d bank=%d\n", node, bank);
 			return -1;
@@ -323,7 +319,7 @@ int __cvmx_helper_pki_install_default_vlan(int node)
 		pcam_input.data = 0x88a80000;
 		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input, pcam_action);/*vinita_to_do, cluster_mask*/
 
-		index = cvmx_pki_pcam_alloc_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
+		index = cvmx_pki_pcam_entry_alloc(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
 		if (index < 0) {
 			cvmx_dprintf("ERROR: Allocating pcam entry node=%d bank=%d\n", node, bank);
 			return -1;
@@ -331,7 +327,7 @@ int __cvmx_helper_pki_install_default_vlan(int node)
 		pcam_input.data = 0x92000000;
 		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input, pcam_action);/*vinita_to_do, cluster_mask*/
 
-		index = cvmx_pki_pcam_alloc_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
+		index = cvmx_pki_pcam_entry_alloc(node, CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
 		if (index < 0) {
 			cvmx_dprintf("ERROR: Allocating pcam entry node=%d bank=%d\n", node, bank);
 			return -1;
@@ -342,8 +338,21 @@ int __cvmx_helper_pki_install_default_vlan(int node)
 	return 0;
 }
 
+void cvmx_helper_pki_enable(int node)
+{
+	if (pki_helper_debug)
+		cvmx_dprintf("enable PKI on node %d\n", node);
+	__cvmx_helper_pki_install_default_vlan(node);
+	cvmx_pki_setup_clusters(node);
+	cvmx_pki_enable_backpressure(node);
+	cvmx_pki_parse_enable(node, 0);
+	cvmx_pki_enable(node);
+}
+
 int __cvmx_helper_pki_global_setup(int node)
 {
+	if (!cvmx_pki_dflt_init[node])
+		return 0;
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 	/* Setup the packet pools*/
 	__cvmx_helper_pki_setup_fpa_pools(node);
@@ -351,32 +360,52 @@ int __cvmx_helper_pki_global_setup(int node)
 	/* __cvmx_helper_setup_global_cfg(node);*/ /* vinita_to_do */
 	/*set up default cluster*/
 	__cvmx_helper_setup_pki_cluster_groups(node);
-	/*set up default vlan */
-	__cvmx_helper_pki_install_default_vlan(node);
-	cvmx_pki_setup_clusters(node);
 	__cvmx_helper_pki_setup_sso_groups(node);
 	__cvmx_helper_setup_pki_qpg_table(node);
 	/* __cvmx_helper_setup_pki_pcam_table(node); *//* vinita_to_do */
-	cvmx_pki_enable_backpressure(node);
+	/*set up default vlan */
 	return 0;
 }
 
-int cvmx_helper_pki_get_num_qos_entry(enum cvmx_pki_qpg_qos qpg_qos)
+/* Frees up PKI resources consumed by that port. This function should only be called
+  if port resources (fpa pools aura, style qpg entry pcam entry etc.) are not shared */
+int cvmx_helper_pki_port_shutdown(int node)
+{
+	/* remove pcam entries */
+	/* vinita_to_do implemet later */
+	/* __cvmx_pki_port_rsrc_free(node); */
+	return 0;
+}
+
+/* Shutdown complete PKI hardware and software resources */
+void cvmx_helper_pki_shutdown(int node)
+{
+	/* remove pcam entries */
+	/* Disable PKI */
+	cvmx_pki_disable(node);
+	/* Free all prefetched buffers */
+	__cvmx_pki_free_ptr(node);
+	/* Reset PKI */
+	cvmx_pki_reset(node);
+	/* Free all the allocated PKI resources
+	except fpa pools & aura which will be done in fpa block */
+	__cvmx_pki_global_rsrc_free(node);
+}
+
+int cvmx_helper_pki_get_num_qpg_entry(enum cvmx_pki_qpg_qos qpg_qos)
 {
 	if (qpg_qos == CVMX_PKI_QPG_QOS_NONE)
 		return 1;
-	else if (qpg_qos == CVMX_PKI_QPG_QOS_VLAN || qpg_qos == CVMX_PKI_QPG_QOS_DSA_SRC
-		       || qpg_qos == CVMX_PKI_QPG_QOS_MPLS)
+	else if (qpg_qos == CVMX_PKI_QPG_QOS_VLAN || qpg_qos == CVMX_PKI_QPG_QOS_MPLS)
 		return 8;
-	else if (qpg_qos == CVMX_PKI_QPG_QOS_HIGIG) /*vinita_to_do for higig2*/
+	else if (qpg_qos == CVMX_PKI_QPG_QOS_DSA_SRC) /*vinita_to_do for higig2*/
 		return 32;
-	else if (qpg_qos == CVMX_PKI_QPG_QOS_DIFFSERV)
+	else if (qpg_qos == CVMX_PKI_QPG_QOS_DIFFSERV || qpg_qos == CVMX_PKI_QPG_QOS_HIGIG)
 		return 64;
 	else {
 		cvmx_dprintf("ERROR: unrecognized qpg_qos = %d", qpg_qos);
 		return 0;
 	}
-	/* vinita_to_do add port_sh and port_msb too */
 }
 
 int __cvmx_helper_pki_port_setup(int node, int ipd_port)
@@ -386,6 +415,8 @@ int __cvmx_helper_pki_port_setup(int node, int ipd_port)
 	int rs;
 	struct cvmx_pki_pkind_config pkind_cfg;
 
+	if (!cvmx_pki_dflt_init[node])
+		return 0;
 	interface = cvmx_helper_get_interface_num(ipd_port);
 	index = cvmx_helper_get_interface_index_num(ipd_port);
 
@@ -394,15 +425,16 @@ int __cvmx_helper_pki_port_setup(int node, int ipd_port)
 
 	/* try to reserve the style, if it is not configured already, reserve
 	and configure it */
-	rs = cvmx_pki_alloc_style(node, style_num);
+	rs = cvmx_pki_style_alloc(node, style_num);
 	if (rs < 0) {
 		if (rs == CVMX_RESOURCE_ALLOC_FAILED)
 			return -1;
 	} else {
 		if (pki_helper_debug)
 			cvmx_dprintf("pki-helper: set style %d with default parameters\n", style_num);
+		pkind_style_map[node][pknd] = style_num;
 		/* configure style with default parameters */
-		cvmx_pki_write_style(node, style_num, CVMX_PKI_CLUSTER_ALL,
+		cvmx_pki_set_style_config(node, style_num, CVMX_PKI_CLUSTER_ALL,
 				     &pki_dflt_style[node]);
 	}
 	if (pki_helper_debug)
@@ -410,26 +442,35 @@ int __cvmx_helper_pki_port_setup(int node, int ipd_port)
 	/* write pkind configuration */
 	pkind_cfg = pki_dflt_pkind[node];
 	pkind_cfg.initial_style = style_num;
-	cvmx_pki_write_pkind(node, pknd, &pkind_cfg);
+	cvmx_pki_set_pkind_config(node, pknd, &pkind_cfg);
 	return 0;
 }
 
-int cvmx_helper_pki_setup_qpg_table(int node, int num_entries, int port_addr[],
-				    uint64_t aura[], uint64_t sso_grp_ok[], uint64_t sso_grp_bad[])
+int cvmx_helper_pki_setup_qpg_table(int node, int num_entries,
+				    struct cvmx_pki_qpg_config *qpg_cfg)
 {
-	int base_offset;
 	int entry;
+	int offset;
 
-	base_offset = cvmx_pki_alloc_qpg_entry(node, CVMX_PKI_FIND_AVAL_ENTRY, num_entries);
-	if (base_offset == -1) {
-		cvmx_dprintf("ERROR:setup_qpg_table: entries not available in qpg table\n");
-		return -1;
+	if (pki_helper_debug)
+		cvmx_dprintf("allocated %d qpg entries", num_entries);
+	offset = cvmx_pki_qpg_entry_alloc(node, qpg_cfg->qpg_base, num_entries);
+	if (pki_helper_debug)
+		cvmx_dprintf("at offset %d \n", offset);
+	if (offset == CVMX_RESOURCE_ALREADY_RESERVED) {
+		cvmx_dprintf("INFO:setup_qpg_table: offset %d already reserved\n", qpg_cfg->qpg_base);
+		return CVMX_RESOURCE_ALREADY_RESERVED;
+	} else if (offset == CVMX_RESOURCE_ALLOC_FAILED) {
+		cvmx_dprintf("ERROR:setup_qpg_table: no more entries available\n");
+		return CVMX_RESOURCE_ALLOC_FAILED;
 	}
-	for (entry = 0; entry < num_entries; entry++, base_offset++) {
-		cvmx_pki_write_qpg_entry(node, base_offset, port_addr[entry], aura[entry],
-					 sso_grp_ok[entry], sso_grp_bad[entry]);
+	qpg_cfg->qpg_base = offset;
+	for (entry = 0; entry < num_entries; entry++, offset++, qpg_cfg++) {
+		cvmx_pki_write_qpg_entry(node, offset,
+					 qpg_cfg->port_add, qpg_cfg->aura,
+					 qpg_cfg->grp_ok, qpg_cfg->grp_bad);
 	}
-	return base_offset - num_entries;
+	return offset - num_entries;
 }
 
 void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs)
@@ -450,6 +491,8 @@ void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs
 
 void cvmx_helper_pki_set_dflt_pool(int node, int pool, int buffer_size, int buffer_count)
 {
+	if (pool == 0)
+		pool = -1;
 	pki_dflt_pool[node].pool_num = pool;
 	pki_dflt_pool[node].buffer_size = buffer_size;
 	pki_dflt_pool[node].buffer_count = buffer_count;
@@ -496,6 +539,11 @@ void cvmx_helper_pki_set_dflt_pkind_map(int node, int pkind, int style)
 	pkind_style_map[node][pkind] = style;
 }
 
+void cvmx_helper_pki_no_dflt_init(int node)
+{
+	cvmx_pki_dflt_init[node] = 0;
+}
+
 /**
  * This function sets up aura QOS for RED, backpressure and tail-drop.
  *
@@ -545,4 +593,379 @@ int cvmx_helper_pki_map_aura_chl_bpid(int node, int aura_map[], int aura_cnt,
 	return 0;
 }
 
+int cvmx_helper_pki_port_msb(uint16_t num_ports)
+{
+	if (num_ports == 0)
+		return 0;
+	else if (num_ports <= 16)
+		return 4;
+	else if (num_ports <= 256)
+		return 8;
+	else
+		cvmx_dprintf("num_ports %d not supported\n", num_ports);
+	return 0;
+}
+
+int cvmx_helper_pki_port_shift(enum cvmx_pki_qpg_qos qpg_qos)
+{
+	uint8_t num_qos;
+	num_qos = cvmx_helper_pki_get_num_qpg_entry(qpg_qos);
+	return ffs(num_qos) - 1;
+}
+
+int cvmx_helper_pki_init_port(int ipd_port, struct cvmx_pki_prt_schd *prtsch)
+{
+	int num_qos;
+	int qos;
+	int qpg_base;
+	struct cvmx_pki_qos_schd *qossch;
+	struct cvmx_pki_style_config style_cfg;
+	struct cvmx_pki_pkind_config pknd_cfg;
+	int xiface = cvmx_helper_get_interface_num(ipd_port);
+	int pknd;
+	int rs;
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(ipd_port);
+
+	if (prtsch->qpg_qos) {
+		num_qos = cvmx_helper_pki_get_num_qpg_entry(prtsch->qpg_qos);
+		qpg_base = cvmx_pki_qpg_entry_alloc(xp.node, -1, num_qos);
+		for (qos = 0; qos < num_qos; qos++) {
+			qossch = &prtsch->qos_s[qos];
+			cvmx_pki_write_qpg_entry(xp.node, qpg_base + qos, qossch->port_add, qossch->aura,
+						 qossch->sso_grp, qossch->sso_grp);
+		}
+	} else {
+		num_qos = 1;
+		qpg_base = cvmx_pki_qpg_entry_alloc(xp.node, -1, num_qos);
+		cvmx_pki_write_qpg_entry(xp.node, qpg_base, 0, prtsch->aura, prtsch->sso_grp, prtsch->sso_grp);
+		prtsch->qpg_base = qpg_base;
+	}
 
+	/* Allocate style here and map it to the port */
+	rs = cvmx_pki_style_alloc(xp.node, prtsch->style);
+	if (rs == CVMX_RESOURCE_ALREADY_RESERVED) {
+		cvmx_dprintf("passthrough: INFO: style will be shared\n");
+	} else if (rs == CVMX_RESOURCE_ALLOC_FAILED) {
+		cvmx_dprintf("passthrough: ERROR: style not available\n");
+		return CVMX_RESOURCE_ALLOC_FAILED;
+	} else {
+		prtsch->style = rs;
+		cvmx_pki_get_style_config(xp.node, prtsch->style,
+					  CVMX_PKI_CLUSTER_ALL, &style_cfg);
+		style_cfg.parm_cfg.qpg_qos = prtsch->qpg_qos;
+		style_cfg.parm_cfg.qpg_base = prtsch->qpg_base;
+		style_cfg.parm_cfg.qpg_port_msb = 0;
+		style_cfg.parm_cfg.qpg_port_sh = 0;
+		cvmx_pki_set_style_config(xp.node, prtsch->style,
+					  CVMX_PKI_CLUSTER_ALL, &style_cfg);
+	}
+	pknd = cvmx_helper_get_pknd(xiface, cvmx_helper_get_interface_index_num(ipd_port));
+	cvmx_pki_get_pkind_config(xp.node, pknd, &pknd_cfg);
+	pknd_cfg.initial_style = prtsch->style;
+	pknd_cfg.fcs_pres = __cvmx_helper_get_has_fcs(xiface);
+	cvmx_pki_set_pkind_config(xp.node, pknd, &pknd_cfg);
+
+	return 0;
+}
+
+#if 0
+
+int cvmx_helper_pki_set_gbl_schd(int node, struct cvmx_pki_global_schd *gblsch)
+{
+	if (gblsch->setup_pool) {
+		if (pki_helper_debug)
+			cvmx_dprintf("pki-helper: setup global pool %d buff_size %d blocks %d",
+				     gblsch->pool, (int)gblsch->pool_buff_size, (int)gblsch->pool_max_buff);
+		cvmx_helper_fpa3_init_pool(node, node, &gblsch->pool, gblsch->pool_buff_size,
+					  gblsch->pool_max_buff, gblsch->pool_name);
+		if (pki_helper_debug)
+			cvmx_dprintf("pool alloced is %d\n", gblsch->pool);
+	}
+	if (gblsch->setup_aura) {
+		if (pki_helper_debug)
+			cvmx_dprintf("pki-helper: setup global aura %d pool %d blocks %d",
+				     gblsch->aura, gblsch->pool, (int)gblsch->aura_buff_cnt);
+		cvmx_helper_fpa3_add_aura_to_pool(node, gblsch->pool, &gblsch->aura,
+				gblsch->aura_buff_cnt, NULL, gblsch->aura_name);
+		if (pki_helper_debug)
+			cvmx_dprintf("aura alloced is %d\n", gblsch->pool);
+
+	}
+	if (gblsch->setup_sso_grp) {
+		/* FIXME: add support in sso to alloc sso group */
+	}
+	return 0;
+}
+
+int cvmx_helper_pki_init_interface(int xiface,
+				   struct cvmx_pki_intf_schd *intf, struct cvmx_pki_global_schd *gbl_schd)
+{
+	const int num_ports = cvmx_helper_ports_on_interface(xiface);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	uint8_t qos;
+	int  port;
+	uint8_t port_msb = 0;
+	uint8_t port_shift = 0;
+	uint16_t num_entry = 0;
+	uint8_t num_qos;
+	int pknd;
+	int rs;
+	int has_fcs;
+	enum cvmx_pki_qpg_qos qpg_qos = CVMX_PKI_QPG_QOS_NONE;
+	struct cvmx_pki_qpg_config *qpg_cfg;
+	struct cvmx_pki_qpg_config *qpg_start;
+	struct cvmx_pki_prt_schd *prtsch;
+	struct cvmx_pki_qos_schd *qossch;
+	struct cvmx_pki_style_config style_cfg;
+	struct cvmx_pki_pkind_config pknd_cfg;
+
+
+	has_fcs = __cvmx_helper_get_has_fcs(xiface);
+
+	if (intf->pool_per_intf) {
+		if (pki_helper_debug)
+			cvmx_dprintf("pki-helper: setup intf %x pool %d buff_size %d blocks %d\n",
+				     xiface, intf->pool, (int)intf->pool_buff_size, (int)intf->pool_max_buff);
+		cvmx_helper_fpa3_init_pool(xi.node, xi.node, &intf->pool, intf->pool_buff_size,
+					  intf->pool_max_buff, intf->pool_name);
+		if (pki_helper_debug)
+			cvmx_dprintf("pool alloced is %d\n", intf->pool);
+
+	} else
+		intf->pool = gbl_schd->pool;
+	if (intf->aura_per_intf) {
+		if (pki_helper_debug)
+			cvmx_dprintf("pki-helper: setup intf %x aura %d pool %d blocks %d\n",
+				     xiface, intf->aura, intf->pool,
+				     (int)intf->aura_buff_cnt);
+		cvmx_helper_fpa3_add_aura_to_pool(xi.node, intf->pool, &intf->aura,
+				intf->aura_buff_cnt, NULL, intf->aura_name);
+		if (pki_helper_debug)
+			cvmx_dprintf("aura alloced is %d\n", intf->aura);
+	} else
+		intf->aura = gbl_schd->aura;
+	if (intf->sso_grp_per_intf) {
+		/* vinita_to_do for sso groups in here and for ports & qos */
+	} else
+		intf->sso_grp = gbl_schd->sso_grp;
+
+	for (port = 0; port < num_ports; port++) {
+		prtsch = &intf->prt_s[port];
+
+		/* Skip invalid/disabled ports */
+		if (!cvmx_helper_is_port_valid(xiface, port))
+			continue;
+
+		/* If you want to setup pool per port and assign port aura to that individual pool
+		setup pool/port call cvmx_helper_fpa_setup_pool here*/
+		if (prtsch->pool_per_prt) {
+			if (pki_helper_debug)
+				cvmx_dprintf("pki-helper: setup intf %x port %d pool %d buff_size %d blocks %d\n",
+					     xiface, port, prtsch->pool, (int)prtsch->pool_buff_size,
+					     (int)prtsch->pool_max_buff);
+			cvmx_helper_fpa3_init_pool(xi.node, xi.node, &prtsch->pool, prtsch->pool_buff_size,
+					prtsch->pool_max_buff, prtsch->pool_name);
+			if (pki_helper_debug)
+				cvmx_dprintf("pool alloced is %d\n", prtsch->pool);
+		} else
+			prtsch->pool = intf->pool;
+		if (prtsch->aura_per_prt) {
+			if (pki_helper_debug)
+				cvmx_dprintf("pki-helper: setup intf %x port %d aura %d pool %d blocks %d\n",
+					     xiface, port, prtsch->aura, prtsch->pool,
+					     (int)prtsch->aura_buff_cnt);
+			cvmx_helper_fpa3_add_aura_to_pool(xi.node, prtsch->pool,
+				&prtsch->aura, prtsch->aura_buff_cnt, NULL, prtsch->aura_name);
+			if (pki_helper_debug)
+				cvmx_dprintf("aura alloced is %d\n", prtsch->aura);
+		} else
+			prtsch->aura = intf->aura;
+		if (prtsch->sso_grp_per_prt) {
+			/* vinita_to_do for sso groups in here */
+		} else
+			prtsch->sso_grp = intf->sso_grp;
+
+		/* Port is using qpg qos to schedule packets to differnet aura or sso group */
+		num_qos = cvmx_helper_pki_get_num_qpg_entry(prtsch->qpg_qos);
+		/* All ports will share the aura from port 0 for the respective qos */
+		/* Port 0 should never have this set to TRUE **/
+		if (intf->qos_share_aura && (port != 0)) {
+			for (qos = 0; qos < num_qos; qos++) {
+				prtsch->qos_s[qos].pool = intf->prt_s[0].qos_s[qos].pool;
+				prtsch->qos_s[qos].aura = intf->prt_s[0].qos_s[qos].aura;
+			}
+
+		} else {
+			for (qos = 0; qos < num_qos; qos++) {
+				qossch = &prtsch->qos_s[qos];
+
+				/* If you want to setup pool per port and assign port aura to that individual pool
+				setup pool/port call cvmx_helper_fpa_setup_pool here*/
+				if (qossch->pool_per_qos) {
+					if (pki_helper_debug)
+						cvmx_dprintf("pki-helper: setup intf %x port %d qos %d pool %d buff_size %d blocks %d\n",
+								xiface, port, qos, qossch->pool, (int)qossch->pool_buff_size,
+								(int)qossch->pool_max_buff);
+					cvmx_helper_fpa3_init_pool(xi.node, xi.node, &qossch->pool, qossch->pool_buff_size, qossch->pool_max_buff, qossch->pool_name);
+					if (pki_helper_debug)
+						cvmx_dprintf("pool alloced is %d\n", qossch->pool);
+				} else
+					qossch->pool = prtsch->pool;
+				if (qossch->aura_per_qos) {
+					if (pki_helper_debug)
+						cvmx_dprintf("pki-helper: setup intf %x port %d qos %d aura %d pool %d blocks %d\n",
+							xiface, port, qos, qossch->aura, qossch->pool,
+							(int)qossch->aura_buff_cnt);
+					cvmx_helper_fpa3_add_aura_to_pool(xi.node, qossch->pool,
+						&qossch->aura, qossch->aura_buff_cnt, NULL,
+						qossch->aura_name);
+					if (pki_helper_debug)
+						cvmx_dprintf("aura alloced is %d\n", qossch->aura);
+				} else
+					qossch->aura = prtsch->aura;
+			}
+		}
+
+		/* All ports will share the sso grp from port 0 for the respective qos */
+		/* Port 0 should never have this set to TRUE **/
+		num_qos = cvmx_helper_pki_get_num_qpg_entry(prtsch->qpg_qos);
+		if (intf->qos_share_grp && (port != 0)) {
+			for (qos = 0; qos < num_qos; qos++) {
+				prtsch->qos_s[qos].sso_grp = intf->prt_s[0].qos_s[qos].sso_grp;
+			}
+		} else {
+			for (qos = 0; qos < num_qos; qos++) {
+				qossch = &prtsch->qos_s[qos];
+				if (qossch->sso_grp_per_qos) {
+					/* vinita_to_do for sso groups in here */
+				} else
+					qossch->sso_grp = prtsch->sso_grp;
+			}
+		}
+	}
+	/* Using port shift and port msb to schedule packets from differnt port to differnt
+	auras and different sso group */
+	/* Using QPG_QOS to schedule packets to different aura and sso group */
+	/* If ports needs to send packets to different aura and sso group
+	depending on packet qos */
+	/* We will need to set up aura and sso group for each port and each qos */
+	/* If all ports are using same style, they will be using same qpg_qos so
+	check only for port 0*/
+	if (intf->style_per_intf) {
+		if (intf->prt_s[0].qpg_qos) { /* all ports using same style will use same qos defined in port 0 config */
+			qpg_qos = intf->prt_s[0].qpg_qos;
+			num_qos = cvmx_helper_pki_get_num_qpg_entry(intf->prt_s[0].qpg_qos);
+			if (intf->qos_share_aura && intf->qos_share_grp) {
+				/* All ports will use same qpg offset so no need for
+				port_msb or port shift */
+				port_msb = 0;
+				port_shift = 0;
+				num_entry = num_qos;
+				qpg_start = malloc(sizeof(struct cvmx_pki_qpg_config) * num_qos);
+				qpg_start->qpg_base = intf->qpg_base;
+				qpg_cfg = qpg_start;
+				for (qos = 0; qos < num_qos; qos++, qpg_cfg++) {
+					qpg_cfg->port_add = intf->prt_s[0].qos_s[qos].port_add;
+					qpg_cfg->aura = intf->prt_s[0].qos_s[qos].aura;
+					qpg_cfg->grp_ok = intf->prt_s[0].qos_s[qos].sso_grp;
+					qpg_cfg->grp_bad = intf->prt_s[0].qos_s[qos].sso_grp;
+				}
+			} else {
+				port_msb = cvmx_helper_pki_port_msb(num_ports);
+				port_shift = cvmx_helper_pki_port_shift(intf->prt_s[0].qpg_qos);
+				qpg_start = malloc(num_ports * num_qos *
+						(sizeof(struct cvmx_pki_qpg_config)));
+				qpg_start->qpg_base = intf->qpg_base;
+				qpg_cfg = qpg_start;
+				num_entry = num_ports * num_qos;
+				for (port = 0; port < num_ports; port++) {
+					prtsch = &intf->prt_s[port];
+					for (qos = 0; qos < num_qos; qos++, qpg_cfg++) {
+						qossch = &prtsch->qos_s[qos];
+						qpg_cfg->port_add = qossch->port_add;
+						qpg_cfg->aura = qossch->aura;
+						qpg_cfg->grp_ok = qossch->sso_grp;
+						qpg_cfg->grp_bad = qossch->sso_grp;
+					}
+				}
+			}
+		} else if (intf->prt_s[0].aura_per_prt || intf->prt_s[0].sso_grp_per_prt) {
+			/* Every port is using their own aura or group */
+			port_msb = cvmx_helper_pki_port_msb(num_ports);
+			port_shift = 0;
+			num_entry = num_ports;
+			qpg_start = malloc(num_ports * (sizeof(struct cvmx_pki_qpg_config)));
+			qpg_start->qpg_base = intf->qpg_base;
+			qpg_cfg = qpg_start;
+			for (port = 0; port < num_ports; port++, qpg_cfg++) {
+				prtsch = &intf->prt_s[port];
+				qpg_cfg->port_add = 0;
+				qpg_cfg->aura = prtsch->aura;
+				qpg_cfg->grp_ok = prtsch->sso_grp;
+				qpg_cfg->grp_bad = prtsch->sso_grp;
+			}
+		} else { /* All ports on that intf use same port_add, aura & sso grps */
+			/* All ports will use same qpg offset so no need for
+			port_msb or port shift */
+			port_msb = 0;
+			port_shift = 0;
+			num_entry = 1;
+			qpg_start = malloc(sizeof(struct cvmx_pki_qpg_config));
+			qpg_start->qpg_base = intf->qpg_base;
+			qpg_start->port_add = 0;
+			qpg_start->aura = intf->aura;
+			qpg_start->grp_ok = intf->sso_grp;
+			qpg_start->grp_bad = intf->sso_grp;
+		}
+
+		rs = cvmx_helper_pki_setup_qpg_table(xi.node, num_entry, qpg_start);
+		if (rs == CVMX_RESOURCE_ALREADY_RESERVED) {
+			cvmx_dprintf("passthrough: INFO: qpg entries will be shared\n");
+		} else if (rs == CVMX_RESOURCE_ALLOC_FAILED) {
+			cvmx_dprintf("passthrough: ERROR: qpg entries not available\n");
+			free(qpg_start);
+			return CVMX_RESOURCE_ALLOC_FAILED;
+		} else
+			intf->qpg_base = qpg_start->qpg_base;
+
+		/* Allocate style here and map it to all ports on interface */
+		rs = cvmx_pki_style_alloc(xi.node, intf->style);
+		if (rs == CVMX_RESOURCE_ALREADY_RESERVED) {
+			cvmx_dprintf("passthrough: INFO: style will be shared\n");
+		} else if (rs == CVMX_RESOURCE_ALLOC_FAILED) {
+			cvmx_dprintf("passthrough: ERROR: style not available\n");
+			return CVMX_RESOURCE_ALLOC_FAILED;
+		} else {
+			intf->style = rs;
+			if (pki_helper_debug)
+				cvmx_dprintf("style %d allocated intf %x qpg_base %d\n", intf->style, xiface, intf->qpg_base);
+			cvmx_pki_get_style_config(xi.node, intf->style,
+					CVMX_PKI_CLUSTER_ALL, &style_cfg);
+			style_cfg.parm_cfg.qpg_qos = qpg_qos;
+			style_cfg.parm_cfg.qpg_base = intf->qpg_base;
+			style_cfg.parm_cfg.qpg_port_msb = port_msb;
+			style_cfg.parm_cfg.qpg_port_sh = port_shift;
+			cvmx_pki_set_style_config(xi.node, intf->style,
+					CVMX_PKI_CLUSTER_ALL, &style_cfg);
+		}
+		for (port = 0; port < num_ports; port++) {
+			pknd = cvmx_helper_get_pknd(xiface, port);
+			cvmx_pki_get_pkind_config(xi.node, pknd, &pknd_cfg);
+			pknd_cfg.initial_style = intf->style;
+			pknd_cfg.fcs_pres = has_fcs;
+			cvmx_pki_set_pkind_config(xi.node, pknd, &pknd_cfg);
+		}
+	} else if (intf->style_per_prt) {
+		for (port = 0; port < num_ports; port++) {
+			int r;
+			int ipd_port = cvmx_helper_get_ipd_port(xiface, port);
+			prtsch = &intf->prt_s[port];
+			r = cvmx_helper_pki_init_port(ipd_port, prtsch);
+			if (r)
+				return r;
+		}
+	}
+	return 0;
+}
+
+#endif
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
index 305cea8..064c475 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
@@ -42,6 +42,7 @@
  *
  * PKOv3 helper file
  */
+//#define	__SUPPORT_PFC_ON_XAUI
 
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/module.h>
@@ -51,7 +52,9 @@
 #include <asm/octeon/cvmx-pko3.h>
 #include <asm/octeon/cvmx-pko3-resources.h>
 #include <asm/octeon/cvmx-helper.h>
+#include <asm/octeon/cvmx-helper-pko.h>
 #include <asm/octeon/cvmx-helper-pko3.h>
+#include <asm/octeon/cvmx-helper-bgx.h>
 #include <asm/octeon/cvmx-helper-cfg.h>
 #else
 #include "cvmx.h"
@@ -60,7 +63,9 @@
 #include "cvmx-pko3.h"
 #include "cvmx-pko3-resources.h"
 #include "cvmx-helper.h"
+#include "cvmx-helper-pko.h"
 #include "cvmx-helper-pko3.h"
+#include "cvmx-helper-bgx.h"
 #include "cvmx-helper-cfg.h"
 #endif
 
@@ -69,9 +74,9 @@
  * and because it is not known how many DQs will in fact be used
  * when the PKO pool is populated, it is allocated the maximum
  * number it may required.
- * The additional 1K buffers are provisioned to acomodate longer
- * descriptor queues, and jump buffers used by the legacy transmit
- * function.
+ * The additional 1K buffers are provisioned to acomodate
+ * jump buffers for long descriptor commands, that should
+ * be rarely used.
  */
 #ifndef CVMX_PKO3_POOL_BUFFERS
 #define CVMX_PKO3_POOL_BUFFERS (1024*4+1024)
@@ -94,14 +99,14 @@ uint16_t __cvmx_pko3_pool_num = -1;
  *
  * Build an owner tag based on interface/port
  */
-static int __cvmx_helper_pko3_res_owner(unsigned node, uint16_t ipd_port)
+static int __cvmx_helper_pko3_res_owner(int ipd_port)
 {
 	int res_owner;
-	const int res_owner_pfix = 0x19d0 << 12;
+	const int res_owner_pfix = 0x19d0 << 14;
 
-	ipd_port &= 0xfff;	/* 12-bit for local CHAN_E value */
+	ipd_port &= 0x3fff;	/* 12-bit for local CHAN_E value + node */
 
-	res_owner = res_owner_pfix | ipd_port | (node << 10);
+	res_owner = res_owner_pfix | ipd_port;
 
 	return res_owner;
 }
@@ -126,32 +131,41 @@ static int __cvmx_helper_pko3_res_owner(unsigned node, uint16_t ipd_port)
  * NOTE: Linux kernel should pass its own aura to PKO3 initialization
  * function so that the buffers can be mapped into kernel space
  * for when software needs to adccess their contents.
+ *
  */
 static int __cvmx_pko3_config_memory(unsigned node)
 {
-	int pool_num = 2, aura_num = 2;
+	int pool_num = 62, aura_num = 1022;
+	int pool, block_size;
 	int res;
 
-	/* Reserve PKO Aura and Pool number */
-	res = cvmx_fpa_allocate_fpa_pools(node, &pool_num, 1);
-	if(res < 0)
-		return res;
-
-	res = cvmx_fpa3_allocate_auras(node, &aura_num, 1);
-	if(res < 0)
-		return res;
-
-	/* fpa pool intialization for pko command buffers */
-	res = cvmx_fpa3_pool_stack_init(node, pool_num,
-				"PKO Pool", 0, //XXX- use local memory ?
-				CVMX_PKO3_POOL_BUFFERS,
-				FPA_NATURAL_ALIGNMENT,
-				CVMX_PKO3_POOL_BUFFER_SIZE);
-
-	res = cvmx_fpa3_assign_aura(node, aura_num, pool_num);
+        /* Check for legacy PKO buffer pool */
+        pool = cvmx_fpa_get_pko_pool();
+	block_size = cvmx_fpa_get_block_size(pool);
+
+        /* Avoid redundant pool creation */
+        if (block_size > 0 && block_size == CVMX_PKO3_POOL_BUFFER_SIZE) {
+                cvmx_dprintf("WARNING: %s: "
+                        "Legacy PKO pool %d re-used, "
+			"buffer count may not suffice.\n",
+                        __func__, pool);
+                aura_num = pool_num = pool;
+        } else if (block_size > 0) {
+                cvmx_dprintf("WARNING: %s: "
+                        "Legacy PKO pool %d created with wrong buffer size %u, "
+			"ignored.\n",
+                        __func__, pool, block_size);
+	}
 
-	res = cvmx_fpa3_aura_init(node, aura_num,"PKO Aura", 0, NULL,
-			   CVMX_PKO3_POOL_BUFFERS, 0);
+	if (aura_num != pool) {
+		res = cvmx_helper_fpa3_init_pool(node, node, &pool_num, CVMX_PKO3_POOL_BUFFER_SIZE,
+						 CVMX_PKO3_POOL_BUFFERS, "PKO Pool");
+		if (res < 0) return res;
+		res = cvmx_helper_fpa3_add_aura_to_pool(node, pool_num, &aura_num,
+							CVMX_PKO3_POOL_BUFFERS,
+							NULL, "PKO Aura");
+		if (res < 0) return res;
+	}
 
 	/* Store numbers e.g. for destruction */
 	__cvmx_pko3_pool_num = pool_num;
@@ -171,46 +185,46 @@ static int __cvmx_pko3_config_memory(unsigned node)
  * The number of channels for each interface is derived from the ILK
  * module configuration.
  */
-static int __cvmx_pko3_config_ilk_interface(unsigned interface)
+static int __cvmx_pko3_config_ilk_interface(int xiface)
 {
 	int l1_q_num;
 	int l2_q_num;
 	int res;
 	int pko_mac_num;
 	unsigned num_chans;
-	unsigned node = cvmx_get_node_num();
 	uint16_t ipd_port;
 	int res_owner;
 	unsigned i;
 	const int num_dq = 1;	/* # of DQs per channel */
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
 	/* NOTE: changing `num_dq` to 8 will create 8 DQs per channel
 	 * to represent static priorities, but will be ordered by
 	 * system priority, not PCP QoS value. Probably not what we want.
 	 */
 
-	num_chans = __cvmx_helper_ilk_enumerate(interface);
+	num_chans = __cvmx_helper_ilk_enumerate(xiface);
 
 	if(debug)
 		cvmx_dprintf("%s: configuring iface %u with %u ILK channels\n",
-			__FUNCTION__, interface, num_chans);
+			     __FUNCTION__, (unsigned int)xiface, num_chans);
 
 	/* ILK channels all go to the same mac */
-	pko_mac_num = __cvmx_pko_get_mac_num(interface, 0);
+	pko_mac_num = __cvmx_pko3_get_mac_num(xiface, 0);
 	if (pko_mac_num < 0) {
                 cvmx_dprintf ("%s: ERROR Invalid interface\n", __FUNCTION__);
 		return -1;
 	}
 
 	/* Resources of all channels on this link have common owner */
-	ipd_port = cvmx_helper_get_ipd_port(interface, 0);
+	ipd_port = cvmx_helper_get_ipd_port(xiface, 0);
 
 	/* Build an identifiable owner */
-	res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+	res_owner = __cvmx_helper_pko3_res_owner(ipd_port);
 
 	/* Reserve port queue to make sure the MAC is not already configured */
 	l1_q_num = pko_mac_num;
-        l1_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_PORT_QUEUES,
+        l1_q_num = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_PORT_QUEUES,
 				res_owner, l1_q_num, 1);
 
 	if (l1_q_num != pko_mac_num) {
@@ -220,8 +234,8 @@ static int __cvmx_pko3_config_ilk_interface(unsigned interface)
 
 
         /* allocate level 2 queues, one per channel */
-        l2_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_L2_QUEUES, res_owner,
-                                           -1, num_chans);
+        l2_q_num = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L2_QUEUES, res_owner,
+					 -1, num_chans);
         if (l2_q_num < 0) {
                 cvmx_dprintf ("%s: ERROR allocation L2 SQ\n", __FUNCTION__);
                 return -1;
@@ -229,7 +243,7 @@ static int __cvmx_pko3_config_ilk_interface(unsigned interface)
 
 
 	/* Configre <num_chans> children for MAC, with Fair-RR scheduling */
-	res = cvmx_pko3_pq_config_children(
+	res = cvmx_pko3_pq_config_children( xi.node,
 			pko_mac_num, l2_q_num, num_chans, -1);
 
 	if (res < 0) {
@@ -243,53 +257,52 @@ static int __cvmx_pko3_config_ilk_interface(unsigned interface)
 		int l3_q, l4_q, l5_q, dq, res;
 
 		l3_q = l4_q = l5_q = dq = -1;
-		ipd_port = cvmx_helper_get_ipd_port(interface, i);
+		ipd_port = cvmx_helper_get_ipd_port(xiface, i);
 
 		/* map channels to l2 queues */
-		cvmx_pko3_map_channel(node, l1_q_num, l2_q_num+i, ipd_port);
+		cvmx_pko3_map_channel(xi.node, l1_q_num, l2_q_num+i, ipd_port);
 
 		//FIXME- can not convert it to a loop because
 		// of CVMX_PKO_Lx_QUEUES are enumerated
 
-		l3_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L3_QUEUES,
+		l3_q = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L3_QUEUES,
 			res_owner, -1, 1);
 		if(l3_q < 0) goto _fail;
 
-		res = cvmx_pko3_sq_config_children(2, l2_q_num+i, l3_q, 1, 1);
+		res = cvmx_pko3_sq_config_children(xi.node, 2, l2_q_num+i, l3_q, 1, 1);
 		if(res < 0) goto _fail;
 
-		l4_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L4_QUEUES,
+		l4_q = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L4_QUEUES,
 			res_owner, -1, 1);
 		if(l4_q < 0) goto _fail;
-		res = cvmx_pko3_sq_config_children(3, l3_q, l4_q, 1, 1);
+		res = cvmx_pko3_sq_config_children(xi.node, 3, l3_q, l4_q, 1, 1);
 		if(res < 0) goto _fail;
 
-		l5_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L5_QUEUES,
+		l5_q = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L5_QUEUES,
 			res_owner, -1, 1);
 		if(l5_q < 0) goto _fail;
-		res = cvmx_pko3_sq_config_children(4, l4_q, l5_q, 1, 1);
+		res = cvmx_pko3_sq_config_children(xi.node, 4, l4_q, l5_q, 1, 1);
 		if(res < 0) goto _fail;
 
-		dq = cvmx_pko_alloc_queues(node, CVMX_PKO_DESCR_QUEUES,
+		dq = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_DESCR_QUEUES,
 			res_owner, -1, num_dq);
 		if(dq < 0) goto _fail;
 
-		res = cvmx_pko3_sq_config_children(5, l5_q, dq, num_dq, num_dq);
+		res = cvmx_pko3_sq_config_children(xi.node, 5, l5_q, dq, num_dq, num_dq);
 		if(res < 0) goto _fail;
 
 		/* register DQ range with the translation table */
-		res = __cvmx_pko3_ipd_dq_register(interface,i,dq, num_dq);
+		res = __cvmx_pko3_ipd_dq_register(xiface, i, dq, num_dq);
 		if(res < 0) goto _fail;
 	}
 
 	return 0;
   _fail:
-	cvmx_dprintf("%s: ERROR:configuring queues for iface %u chan %u\n",
-		__FILE__, interface, i);
+	cvmx_dprintf("%s: ERROR:configuring queues for xiface %u chan %u\n",
+		     __FILE__, (unsigned int)xiface, i);
 	return -1;
 }
 
-#ifdef	__SUPPORT_PFC_ON_XAUI
 /** Initialize a single Ethernet port with PFC-style channels
  *
  * One interface can contain multiple ports, this function is per-port
@@ -302,7 +315,7 @@ static int __cvmx_pko3_config_ilk_interface(unsigned interface)
  * For HighGig2 mode, 16 channels may be desired, instead of 8,
  * but this function does not support that.
  */
-static int __cvmx_pko3_config_pfc_interface(unsigned interface, unsigned port)
+static int __cvmx_pko3_config_pfc_interface(int xiface, unsigned port)
 {
 	int l1_q_num;
 	int l2_q_num;
@@ -310,26 +323,27 @@ static int __cvmx_pko3_config_pfc_interface(unsigned interface, unsigned port)
 	int pko_mac_num;
 	int l3_q, l4_q, l5_q, dq;
 	const unsigned num_chans = 8;
-	unsigned node = cvmx_get_node_num();
+	cvmx_xiface_t xi = cvmx_helper_xiface_to_node_interface(xiface);
+	unsigned node = xi.node;
 	uint16_t ipd_port;
 	int res_owner;
 	unsigned i;
 
 	if(debug)
-		cvmx_dprintf("%s: configuring iface %u port %u with %u PFC channels\n",
-			__FUNCTION__, interface, port, num_chans);
+		cvmx_dprintf("%s: configuring xiface %u:%u port %u with %u PFC channels\n",
+			__FUNCTION__, node, xi.interface, port, num_chans);
 
 	/* Get MAC number for the iface/port */
-	pko_mac_num = __cvmx_pko_get_mac_num(interface, port);
+	pko_mac_num = __cvmx_pko3_get_mac_num(xiface, port);
 	if (pko_mac_num < 0) {
 		cvmx_dprintf ("%s: ERROR Invalid interface\n", __FUNCTION__);
 		return -1;
 	}
 
-	ipd_port = cvmx_helper_get_ipd_port(interface, port);
+	ipd_port = cvmx_helper_get_ipd_port(xiface, port);
 
 	/* Build an identifiable owner identifier */
-	res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+	res_owner = __cvmx_helper_pko3_res_owner(ipd_port);
 
 	/* Allocate port queue to make sure the MAC is not already configured */
 	l1_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_PORT_QUEUES,
@@ -351,7 +365,7 @@ static int __cvmx_pko3_config_pfc_interface(unsigned interface, unsigned port)
 
 
 	/* Configre <num_chans> children for MAC, with static priority */
-	res = cvmx_pko3_pq_config_children(
+	res = cvmx_pko3_pq_config_children( node,
 			pko_mac_num, l2_q_num, num_chans, num_chans);
 
 	if (res < 0) {
@@ -370,8 +384,8 @@ static int __cvmx_pko3_config_pfc_interface(unsigned interface, unsigned port)
 			res_owner, -1, num_chans);
 	if (l3_q < 0 || l4_q < 0 || l5_q < 0 ||dq < 0) {
 		cvmx_dprintf("%s: ERROR:could not allocate queues, "
-			"interface %u port %u\n",
-			__FUNCTION__, interface, port);
+			"xiface %u:%u port %u\n",
+			__FUNCTION__, xi.node, xi.interface, port);
 		return -1;
 	}
 
@@ -386,99 +400,144 @@ static int __cvmx_pko3_config_pfc_interface(unsigned interface, unsigned port)
 		/* map channels to L2 queues */
 		cvmx_pko3_map_channel(node, l1_q_num, l2_q_num+i, chan);
 
-		cvmx_pko3_sq_config_children(2, l2_q_num+i, l3_q+i, 1, 1);
+		cvmx_pko3_sq_config_children(node, 2, l2_q_num+i, l3_q+i, 1, 1);
 
-		cvmx_pko3_sq_config_children(3, l3_q+i, l4_q+i, 1, 1);
+		cvmx_pko3_sq_config_children(node, 3, l3_q+i, l4_q+i, 1, 1);
 
-		cvmx_pko3_sq_config_children(4, l4_q+i, l5_q+i, 1, 1);
+		cvmx_pko3_sq_config_children(node, 4, l4_q+i, l5_q+i, 1, 1);
 
 		/* Configure DQs in QoS order, so that QoS/PCP can be index */
 		dq_num = dq + cvmx_helper_prio2qos(i);
-		cvmx_pko3_sq_config_children(5, l5_q+i, dq_num, 1, 1);
+		cvmx_pko3_sq_config_children(node, 5, l5_q+i, dq_num, 1, 1);
 	}
 
 	/* register entire DQ range with the IPD translation table */
-	__cvmx_pko3_ipd_dq_register(interface,port, dq, num_chans);
+	__cvmx_pko3_ipd_dq_register(xiface, port, dq, num_chans);
 
 	return 0;
 }
-#endif
 
-/** Initialize a simple interface with a single descriptor queue */
-static int __cvmx_pko3_config_gen_interface(unsigned interface, unsigned port)
+/** 
+ * Initialize a simple interface with a a given number of
+ * fair or prioritized queues.
+ * This function will assign one channel per sub-interface.
+ */
+int __cvmx_pko3_config_gen_interface(int xiface, uint8_t subif,
+	uint8_t num_queues, bool prioritized)
 {
 	int l1_q_num;
 	int l2_q_num;
 	int res, res_owner;
 	int pko_mac_num;
 	int l3_q, l4_q, l5_q, dq;
-	unsigned node = cvmx_get_node_num();
 	uint16_t ipd_port;
+	cvmx_xiface_t xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int static_pri;
+
+	if (num_queues == 0) {
+		num_queues = 1;
+		cvmx_dprintf("%s: WARNING xiface %#x misconfigured\n",
+			__func__, xiface);
+	}
 
 	if(debug)
-		cvmx_dprintf("%s: configuring iface %u port %u\n",
-			__FUNCTION__, interface, port );
+		cvmx_dprintf("%s: configuring xiface %u:%u/%u nq=%u %s\n",
+			     __FUNCTION__, xi.node, xi.interface, subif,
+			    num_queues, (prioritized)?"qos":"fair");
 
 	/* Get MAC number for the iface/port */
-	pko_mac_num = __cvmx_pko_get_mac_num(interface, port);
+	pko_mac_num = __cvmx_pko3_get_mac_num(xiface, subif);
 	if (pko_mac_num < 0) {
-		cvmx_dprintf ("%s: ERROR Invalid interface\n", __FUNCTION__);
+		cvmx_dprintf ("%s: ERROR Invalid interface %u:%u\n",
+			__FUNCTION__, xi.node, xi.interface);
 		return -1;
 	}
 
-	ipd_port = cvmx_helper_get_ipd_port(interface, port);
+	ipd_port = cvmx_helper_get_ipd_port(xiface, subif);
+
+	if(debug)
+		cvmx_dprintf("%s: xiface %u:%u/%u ipd_port=%#03x\n",
+			     __FUNCTION__, xi.node, xi.interface, subif,
+				ipd_port);
 
 	/* Build an identifiable owner identifier */
-	res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+	res_owner = __cvmx_helper_pko3_res_owner(ipd_port);
 
 	/* Reserve port queue to make sure the MAC is not already configured */
-	l1_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_PORT_QUEUES,
-				res_owner, pko_mac_num, 1);
+	l1_q_num = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_PORT_QUEUES,
+					 res_owner, pko_mac_num, 1);
 
 	if (l1_q_num != pko_mac_num) {
-		cvmx_dprintf ("%s: ERROR allocation L1 SQ\n", __FUNCTION__);
+		cvmx_dprintf("%s: ERROR xiface %u:%u/%u"
+			" failed allocation L1 SQ\n",
+			__FUNCTION__, xi.node, xi.interface, subif);
 		return -1;
 	}
 
 	/* allocate or reserve level 2 queues */
-	l2_q_num = cvmx_pko_alloc_queues(node, CVMX_PKO_L2_QUEUES, res_owner,
+	l2_q_num = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L2_QUEUES, res_owner,
 				-1, 1);
 	if (l2_q_num < 0) {
-		cvmx_dprintf ("%s: ERROR allocation L2 SQ\n", __FUNCTION__);
+		cvmx_dprintf("%s: ERROR xiface %u:%u/%u"
+			"  failed allocation L2 SQ\n",
+			__FUNCTION__, xi.node, xi.interface, subif);
 		return -1;
 	}
 
 
 	/* Configre L2 SQ */
-	res = cvmx_pko3_pq_config_children( pko_mac_num, l2_q_num, 1, 1);
+	res = cvmx_pko3_pq_config_children(xi.node, pko_mac_num,
+				l2_q_num, 1, 1);
 
 	if (res < 0) {
-		cvmx_dprintf("Error: Could not setup ILK Channel queues\n");
+		cvmx_dprintf("%s: ERROR xiface %u:%u/%u"
+			" failed configuring PQ\n",
+			__FUNCTION__, xi.node, xi.interface, subif);
 		return -1;
 	}
 
-	l3_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L3_QUEUES, res_owner,-1, 1);
-	l4_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L4_QUEUES, res_owner,-1, 1);
-	l5_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L5_QUEUES, res_owner,-1, 1);
-	dq = cvmx_pko_alloc_queues(node,CVMX_PKO_DESCR_QUEUES, res_owner,-1, 1);
+	l3_q = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L3_QUEUES,
+				res_owner, -1, 1);
+	l4_q = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L4_QUEUES,
+				res_owner, -1, 1);
+	l5_q = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L5_QUEUES,
+				res_owner, -1, 1);
+	dq = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_DESCR_QUEUES,
+				res_owner, -1, num_queues);
 	if (dq < 0) {
-		cvmx_dprintf("%s: ERROR: could not allocate DQs\n",
-			__FUNCTION__);
+		cvmx_dprintf("%s: ERROR xiface %u:%u/%u"
+			" failed configuring DQs\n",
+			__FUNCTION__, xi.node, xi.interface, subif);
 		return -1;
 	}
 
 	/* Configure hierarchy */
-	cvmx_pko3_sq_config_children(2, l2_q_num, l3_q, 1, 1);
-	cvmx_pko3_sq_config_children(3, l3_q, l4_q, 1, 1);
-	cvmx_pko3_sq_config_children(4, l4_q, l5_q, 1, 1);
-	cvmx_pko3_sq_config_children(5, l5_q, dq, 1, 1);
+	cvmx_pko3_sq_config_children(xi.node, 2, l2_q_num, l3_q, 1, 1);
+	cvmx_pko3_sq_config_children(xi.node, 3, l3_q, l4_q, 1, 1);
+	cvmx_pko3_sq_config_children(xi.node, 4, l4_q, l5_q, 1, 1);
+
+	/* Configure DQs relative priority (a.k.a. scheduling) */
+	if (prioritized) {
+		/* With 8 queues or fewer, use static priority, else WRR */
+		static_pri = (num_queues < 9)? num_queues: 0;
+	} else {
+		/* Set equal-RR scheduling among queues */
+		static_pri = -1;
+	}
+
+	cvmx_pko3_sq_config_children(xi.node, 5, l5_q, dq,
+		num_queues, static_pri);
 
 	/* map IPD/channel to L2 queues */
-	cvmx_pko3_map_channel(node, l1_q_num, l2_q_num, ipd_port);
+	cvmx_pko3_map_channel(xi.node, l1_q_num, l2_q_num, ipd_port);
 
 	/* register DQ/IPD translation */
-	__cvmx_pko3_ipd_dq_register(interface, port, dq, 1);
+	__cvmx_pko3_ipd_dq_register(xiface, subif, dq, num_queues);
 
+	if(debug)
+		cvmx_dprintf("%s: xiface %u:%u/%u qs %u-%u\n",
+			     __FUNCTION__, xi.node, xi.interface, subif,
+				dq, dq+num_queues-1);
 	return 0;
 }
 
@@ -493,23 +552,22 @@ static int __cvmx_pko3_config_gen_interface(unsigned interface, unsigned port)
  * The Descriptor Queue 0 will be reserved for the NULL interface
  * and the normalized (i.e. IPD) port number has the all-ones value.
  */
-static int __cvmx_pko3_config_null_interface(void)
+static int __cvmx_pko3_config_null_interface(unsigned int node)
 {
 	int l1_q_num;
 	int l2_q_num;
 	int l3_q, l4_q, l5_q;
 	int res, res_owner;
-	unsigned node = cvmx_get_node_num();
+	int xiface;
 
 	const int dq = 0;	/* Reserve DQ#0 for NULL */
 	const int pko_mac_num = 0x1C; /* MAC# 28 virtual MAC for NULL */
-	const uint16_t ipd_port = 0xfff;
 
 	if(debug)
 		cvmx_dprintf("%s: configuring null interface\n", __FUNCTION__);
 
 	/* Build an identifiable owner identifier by MAC# for easy release */
-	res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+	res_owner = __cvmx_helper_pko3_res_owner(CVMX_PKO3_IPD_PORT_NULL);
 	if (res_owner < 0) {
 		cvmx_dprintf ("%s: ERROR Invalid interface\n", __FUNCTION__);
 		return -1;
@@ -534,19 +592,19 @@ static int __cvmx_pko3_config_null_interface(void)
 
 
 	/* Configre L2 SQ */
-	res = cvmx_pko3_pq_config_children( pko_mac_num, l2_q_num, 1, 1);
+	res = cvmx_pko3_pq_config_children(node, pko_mac_num, l2_q_num, 1, 1);
 
 	if (res < 0) {
 		cvmx_dprintf("%s: ERROR: L2 queue\n", __FUNCTION__);
 		return -1;
 	}
 
-	l3_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L3_QUEUES, res_owner,-1, 1);
-	l4_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L4_QUEUES, res_owner,-1, 1);
-	l5_q = cvmx_pko_alloc_queues(node,CVMX_PKO_L5_QUEUES, res_owner,-1, 1);
+	l3_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L3_QUEUES, res_owner,-1, 1);
+	l4_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L4_QUEUES, res_owner,-1, 1);
+	l5_q = cvmx_pko_alloc_queues(node, CVMX_PKO_L5_QUEUES, res_owner,-1, 1);
 
 	/* Reserve DQ at 0 by convention */
-	res = cvmx_pko_alloc_queues(node,CVMX_PKO_DESCR_QUEUES, res_owner,
+	res = cvmx_pko_alloc_queues(node, CVMX_PKO_DESCR_QUEUES, res_owner,
 		dq, 1);
 	if (dq != res) {
 		cvmx_dprintf("%s: ERROR: could not reserve DQs\n",
@@ -555,15 +613,16 @@ static int __cvmx_pko3_config_null_interface(void)
 	}
 
 	/* Configure hierarchy */
-	cvmx_pko3_sq_config_children(2, l2_q_num, l3_q, 1, 1);
-	cvmx_pko3_sq_config_children(3, l3_q, l4_q, 1, 1);
-	cvmx_pko3_sq_config_children(4, l4_q, l5_q, 1, 1);
-	cvmx_pko3_sq_config_children(5, l5_q, dq, 1, 1);
+	cvmx_pko3_sq_config_children(node, 2, l2_q_num, l3_q, 1, 1);
+	cvmx_pko3_sq_config_children(node, 3, l3_q, l4_q, 1, 1);
+	cvmx_pko3_sq_config_children(node, 4, l4_q, l5_q, 1, 1);
+	cvmx_pko3_sq_config_children(node, 5, l5_q, dq, 1, 1);
 
 	/* NULL interface does not need to map to a CHAN_E */
 
 	/* register DQ/IPD translation */
-	__cvmx_pko3_ipd_dq_register(-1, 0, dq, 1);
+	xiface = cvmx_helper_node_interface_to_xiface(node, __CVMX_XIFACE_NULL);
+	__cvmx_pko3_ipd_dq_register(xiface, 0, dq, 1);
 
 	/* open the null DQ here */
 	res = cvmx_pko_dq_open(node, dq);
@@ -574,31 +633,26 @@ static int __cvmx_pko3_config_null_interface(void)
 /** Open all descriptor queues belonging to an interface/port
  * @INTERNAL
  */
-static int __cvmx_pko3_helper_dqs_activate(int interface, int port)
+int __cvmx_pko3_helper_dqs_activate(int xiface, int index)
 {
-	unsigned node = cvmx_get_node_num();
 	int  ipd_port,dq_base, dq_count, i;
-	bool min_pad = __cvmx_helper_get_pko_padding(interface);
+	bool min_pad = __cvmx_helper_get_pko_padding(xiface);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
 	/* Get local IPD port for the interface */
-	ipd_port = cvmx_helper_get_ipd_port(interface, port);
+	ipd_port = cvmx_helper_get_ipd_port(xiface, index);
 	if(ipd_port < 0) {
-		cvmx_dprintf("%s: ERROR: No IPD port "
-			"for interface %d port %d\n",
-			__FUNCTION__, interface, port);
+		cvmx_dprintf("%s: ERROR: No IPD port for interface %d port %d\n",
+			     __FUNCTION__, xiface, index);
 		return -1;
 	}
 
-	/* Make the IPD port global */
-	ipd_port |= node << 12;
-
 	/* Get DQ# range for the IPD port */
 	dq_base = cvmx_pko3_get_queue_base(ipd_port);
 	dq_count = cvmx_pko3_get_queue_num(ipd_port);
 	if( dq_base < 0 || dq_count <= 0) {
-		cvmx_dprintf("%s: ERROR: No descriptor queues "
-				"for interface %d port %d\n",
-				__FUNCTION__, interface, port);
+		cvmx_dprintf("%s: ERROR: No descriptor queues for interface %d port %d\n",
+			     __FUNCTION__, xiface, index);
 		return -1;
 	}
 
@@ -606,30 +660,52 @@ static int __cvmx_pko3_helper_dqs_activate(int interface, int port)
 	dq_base &= (1<<10)-1;
 
 	for(i = 0; i < dq_count; i++) {
-		cvmx_pko_dq_open(node, dq_base + i);
-		cvmx_pko3_dq_options(node, dq_base + i, min_pad);
+		cvmx_pko_dq_open(xi.node, dq_base + i);
+		cvmx_pko3_dq_options(xi.node, dq_base + i, min_pad);
 	}
 
 
 	return i;
 }
 
-/** Conhfigure and initialize PKO3 for an interface
+/** Configure and initialize PKO3 for an interface
  *
+ * @param node
  * @param interface is the interface number to configure
  * @return 0 on success.
  *
  */
-int cvmx_helper_pko3_init_interface(unsigned interface)
+int cvmx_helper_pko3_init_interface(int xiface)
 {
-	unsigned node = cvmx_get_node_num();
 	cvmx_helper_interface_mode_t mode;
-	int port, num_ports;
-	int res;
-
-	mode = cvmx_helper_interface_get_mode(interface);
-	num_ports = cvmx_helper_interface_enumerate(interface);
+	int subif, num_ports;
+	bool fcs_enable, pad_enable;
+	uint8_t fcs_sof_off = 0;
+	uint8_t num_queues = 1;
+	bool qos = false, pfc = false;
+	int res = -1;
+	cvmx_xiface_t xi = cvmx_helper_xiface_to_node_interface(xiface);
+
+	mode = cvmx_helper_interface_get_mode(xiface);
+	num_ports = cvmx_helper_interface_enumerate(xiface);
+
+	if ((unsigned) xi.interface <
+		NUM_ELEMENTS(__cvmx_pko_queue_static_config
+			.pknd.pko_cfg_iface)) {
+		pfc = __cvmx_pko_queue_static_config
+			.pknd.pko_cfg_iface[xi.interface]
+			.pfc_enable;
+		num_queues =
+			__cvmx_pko_queue_static_config.
+			pknd.pko_cfg_iface[xi.interface]
+			.queues_per_port;
+		qos =
+			__cvmx_pko_queue_static_config.
+			pknd.pko_cfg_iface[xi.interface]
+			.qos_enable;
+	}
 
+	//XXX convert NPI/LB to configure channelized logical interfaces !!
 	/* Override port-count for some interface types */
 	if ((mode == CVMX_HELPER_INTERFACE_MODE_NPI) ||
 		(mode == CVMX_HELPER_INTERFACE_MODE_LOOP))
@@ -637,68 +713,117 @@ int cvmx_helper_pko3_init_interface(unsigned interface)
 
 	/* For ILK there is one IPD port per channel */
 	if ((mode == CVMX_HELPER_INTERFACE_MODE_ILK))
-		num_ports =  __cvmx_helper_ilk_enumerate(interface);
+		num_ports =  __cvmx_helper_ilk_enumerate(xiface);
 
 	/* Skip non-existent interfaces */
 	if(num_ports < 1) {
-		cvmx_dprintf("%s: ERROR invalid interface %u\n",
-			__FUNCTION__, interface );
+		cvmx_dprintf("%s: ERROR invalid interface %d\n",
+			     __FUNCTION__, xiface );
 		return -1;
 	}
 
-	/* ILK-specific queue configuration */
-	if (mode == CVMX_HELPER_INTERFACE_MODE_ILK) {
-		res = __cvmx_pko3_config_ilk_interface(interface);
-#ifdef	__SUPPORT_PFC_ON_XAUI
-	/* Setup all XAUI interfaces for PFC */
-	} else if (mode == CVMX_HELPER_INTERFACE_MODE_XAUI) {
-		res = -1;
-		for (port = 0; port < num_ports; port++) {
-			res = __cvmx_pko3_config_pfc_interface(
-				interface, port);
+	if (mode == CVMX_HELPER_INTERFACE_MODE_LOOP) {
+		num_queues =
+			__cvmx_pko_queue_static_config.
+				pknd.pko_cfg_loop.queues_per_port;
+		qos =
+			__cvmx_pko_queue_static_config.
+				pknd.pko_cfg_loop.qos_enable;
+		for (subif = 0; subif < num_ports; subif++) {
+			res = __cvmx_pko3_config_gen_interface(xiface, subif,
+				num_queues, qos);
 			if (res < 0) {
 				goto __cfg_error;
 			}
 		}
-	/* All other interfaces are configured with a single DQ/port */
-#endif
-	} else {
-		res = -1;
-		for (port = 0; port < num_ports; port++) {
-			res = __cvmx_pko3_config_gen_interface(
-				interface, port);
+	}
+
+	else if (mode == CVMX_HELPER_INTERFACE_MODE_NPI) {
+		num_queues =
+			__cvmx_pko_queue_static_config.
+				pknd.pko_cfg_npi.queues_per_port;
+		qos =
+			__cvmx_pko_queue_static_config.
+				pknd.pko_cfg_npi.qos_enable;
+		for (subif = 0; subif < num_ports; subif++) {
+			res = __cvmx_pko3_config_gen_interface(xiface, subif,
+				num_queues, qos);
+			if (res < 0) {
+				goto __cfg_error;
+			}
+		}
+	}
+
+	/* ILK-specific queue configuration */
+	else if (mode == CVMX_HELPER_INTERFACE_MODE_ILK) {
+		res = __cvmx_pko3_config_ilk_interface(xiface);
+	}
+
+	/* Setup all ethernet configured for PFC */
+	else if (pfc) {
+
+		/* PFC interfaces have 8 prioritized queues */
+		for (subif = 0; subif < num_ports; subif++) {
+			res = __cvmx_pko3_config_pfc_interface(
+				xiface, subif);
+			if (res < 0)
+				goto __cfg_error;
+
+			/* Enable PFC/CBFC on BGX */
+			__cvmx_helper_bgx_xaui_config_pfc(xi.node,
+				xi.interface, subif, true);
+		}
+	}
+
+	/* All other interfaces floolow static configuration */
+	else {
+
+		for (subif = 0; subif < num_ports; subif++) {
+			res = __cvmx_pko3_config_gen_interface(xiface, subif,
+				num_queues, qos);
 			if (res < 0) {
 				goto __cfg_error;
 			}
 		}
 	}
 
+	fcs_enable = __cvmx_helper_get_has_fcs(xiface);
+	pad_enable = __cvmx_helper_get_pko_padding(xiface);
+
 	if(debug)
-		cvmx_dprintf("%s: FCS=%d pad=%d\n",__func__,
-			__cvmx_helper_get_has_fcs(interface),
-			__cvmx_helper_get_pko_padding(interface));
+		cvmx_dprintf("%s: FCS=%d pad=%d\n",
+			__func__, fcs_enable, pad_enable);
 
 	/* Setup interface options */
-	for (port = 0; port < num_ports; port++) {
-		res = cvmx_pko3_interface_options(node, interface, port,
-			__cvmx_helper_get_has_fcs(interface),	/*fcs_enable*/
-			__cvmx_helper_get_pko_padding(interface),/*pad_enable*/
-			0	/*fcs_sof_offset*/
-		);
-		if(res < 0)
-			cvmx_dprintf("%s: WARNING: failed to set options for interface %d port %d\n",
-				     __func__, interface, port);
-
+	for (subif = 0; subif < num_ports; subif++) {
 		/* Open interface/port DQs to allow transmission to begin */
-		res = __cvmx_pko3_helper_dqs_activate(interface, port);
+		res = __cvmx_pko3_helper_dqs_activate(xiface, subif);
 		if (res < 0)
 			goto __cfg_error;
+
+		/* ILK has only one MAC, subif == logical-channel */
+		if (mode == CVMX_HELPER_INTERFACE_MODE_ILK && subif > 0)
+			continue;
+
+		/* LOOP has only one MAC, subif == logical-channel */
+		if (mode == CVMX_HELPER_INTERFACE_MODE_LOOP && subif > 0)
+			continue;
+
+		/* NPI has only one MAC, subif == 'ring' */
+		if (mode == CVMX_HELPER_INTERFACE_MODE_NPI && subif > 0)
+			continue;
+
+		res = cvmx_pko3_interface_options(xiface, subif,
+						  fcs_enable, pad_enable, fcs_sof_off);
+		if(res < 0)
+			cvmx_dprintf("%s: WARNING: failed to set options for interface %d subif %d\n",
+				     __func__, xiface, subif);
 	}
 	return 0;
 
   __cfg_error:
-	cvmx_dprintf("%s: ERROR configuring interface %u port %u\n",
-		__FUNCTION__, interface, port);
+	cvmx_dprintf("%s: ERROR configuring interface %u subif %u\n",
+		     __FUNCTION__, xiface, subif);
 	return -1;
 }
 
@@ -711,26 +836,11 @@ int cvmx_helper_pko3_init_interface(unsigned interface)
  * When Linux eats up the entire memory, bootmem will be unable to
  * satisfy our request, and the memory needs to come from Linux free pages.
  */
-int cvmx_helper_pko3_init_global(void)
+int __cvmx_helper_pko3_init_global(unsigned int node, uint16_t gaura)
 {
-	uint16_t aura = -1;
-	unsigned node = cvmx_get_node_num();
 	int res;
 
-#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	/* Allocate memory required by PKO3 */
-	res = __cvmx_pko3_config_memory(node);
-	if(res < 0) {
-		cvmx_dprintf("%s: ERROR: PKO3 memory allocation error\n",
-			__FUNCTION__);
-		return res;
-	}
-	aura = res;
-#else
-	//# warning Do not have the AURA for PKO3 internal use
-#endif
-
-	res = cvmx_pko3_hw_init_global(node, aura);
+	res = cvmx_pko3_hw_init_global(node, gaura);
 	if(res < 0) {
 		cvmx_dprintf("%s: ERROR: failed block initialization\n",
 			__FUNCTION__);
@@ -742,7 +852,7 @@ int cvmx_helper_pko3_init_global(void)
 		cvmx_pko_default_channel_level);
 
 	/* add NULL MAC/DQ setup */
-	res = __cvmx_pko3_config_null_interface();
+	res = __cvmx_pko3_config_null_interface(node);
 	if (res < 0)
 		cvmx_dprintf("%s: ERROR creating NULL interface\n",
 			__FUNCTION__);
@@ -751,6 +861,33 @@ int cvmx_helper_pko3_init_global(void)
 }
 
 /**
+ * Global initialization for PKO3
+ *
+ * Should only be called once on each node
+ *
+ * TBD: Resolve the kernel case.
+ * When Linux eats up the entire memory, bootmem will be unable to
+ * satisfy our request, and the memory needs to come from Linux free pages.
+ */
+int cvmx_helper_pko3_init_global(unsigned int node)
+{
+	uint16_t aura = -1;
+
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+	int res = 0;
+	/* Allocate memory required by PKO3 */
+	res = __cvmx_pko3_config_memory(node);
+	if(res < 0) {
+		cvmx_dprintf("%s: ERROR: PKO3 memory allocation error\n",
+			__FUNCTION__);
+		return res;
+	}
+	aura = res;
+#endif
+	return __cvmx_helper_pko3_init_global(node, aura);
+}
+
+/**
  * Uninitialize PKO3 interface
  *
  * Release all resources held by PKO for an interface.
@@ -759,23 +896,23 @@ int cvmx_helper_pko3_init_global(void)
  * NOTE: The NULL virtual interface is identified by interface
  * number -1, which translates into IPD port 0xfff, MAC#28. [Kludge]
  */
-int cvmx_helper_pko3_shut_interface(int interface)
+int cvmx_helper_pko3_shut_interface(int xiface)
 {
-	unsigned node = cvmx_get_node_num();
-	int port, num_ports;
+	int index, num_ports;
 	int dq_base, dq_count;
 	uint16_t ipd_port;
 	int i, res_owner, res;
 	uint64_t cycles;
 	const unsigned timeout = 10;	/* milliseconds */
+	cvmx_xiface_t xi = cvmx_helper_xiface_to_node_interface(xiface);
 
-	if(interface == -1) {
+	if(__cvmx_helper_xiface_is_null(xiface)) {
 		/* Special case for interface=-1 is NULL interface */
 		num_ports = 1;
 	} else {
 		cvmx_helper_interface_mode_t mode;
-		mode = cvmx_helper_interface_get_mode(interface);
-		num_ports = cvmx_helper_interface_enumerate(interface);
+		mode = cvmx_helper_interface_get_mode(xiface);
+		num_ports = cvmx_helper_interface_enumerate(xiface);
 
 		/* Override port-count for some interface types */
 		if ((mode == CVMX_HELPER_INTERFACE_MODE_NPI) ||
@@ -789,52 +926,56 @@ int cvmx_helper_pko3_shut_interface(int interface)
 	}
 
 	if (debug)
-		cvmx_dprintf("%s: interface %d ports %d\n",
-			__func__, interface, num_ports);
+		cvmx_dprintf("%s: xiface %u:%d ports %d\n",
+			__func__, xi.node, xi.interface , num_ports);
 
-	for (port = 0; port < num_ports; port ++) {
+	for (index = 0; index < num_ports; index ++) {
 
-		ipd_port = cvmx_helper_get_ipd_port(interface, port);
-		ipd_port &= (CVMX_PKO3_IPD_NUM_MAX-1);
+		if (__cvmx_helper_xiface_is_null(xiface))
+			ipd_port = CVMX_PKO3_IPD_PORT_NULL;
+		else
+			ipd_port = cvmx_helper_get_ipd_port(xiface, index);
 
-		/* Retreive DQ range for the port */
+		/* Retreive DQ range for the index */
                 dq_base = cvmx_pko3_get_queue_base(ipd_port);
                 dq_count = cvmx_pko3_get_queue_num(ipd_port);
 
                 if( dq_base < 0 || dq_count < 0) {
-                        cvmx_dprintf("%s: ERROR: No descriptor queues for interface %d port %d\n",
-                                __FUNCTION__, interface, port);
+                        cvmx_dprintf("%s: ERROR: No descriptor queues for interface %d index %d\n",
+                                __FUNCTION__, xiface, index);
 			continue;
 		}
 
 		/* Get rid of node-number in DQ# */
 		dq_base &= (1 << 10)-1;
 
+		if (debug)
+			cvmx_dprintf("%s: xiface %u:%d port %d dq %u-%u\n",
+			__func__, xi.node, xi.interface, index,
+			dq_base, dq_base + dq_count -1);
+
 		/* Unregister the DQs for the port, should stop traffic */
-		res = __cvmx_pko3_ipd_dq_unregister(interface, port);
+		res = __cvmx_pko3_ipd_dq_unregister(xiface, index);
 		if(res < 0) {
-                        cvmx_dprintf("%s: ERROR: can not unregister queues "
-                                "for interface %d port %d\n",
-                                __FUNCTION__, interface, port);
+                        cvmx_dprintf("%s: ERROR: can not unregister queues for interface %d index %d\n",
+                                __FUNCTION__, xiface, index);
 			continue;
 		}
 
 		/* Begin draining all queues */
 		for(i = 0; i < dq_count; i++) {
-			cvmx_pko3_dq_drain(node, dq_base + i);
+			cvmx_pko3_dq_drain(xi.node, dq_base + i);
 		}
 
 		/* Wait for all queues to drain, and close them */
 		for(i = 0; i < dq_count; i++) {
 			/* Prepare timeout */
 			cycles = cvmx_get_cycle();
-			cycles +=
-				cvmx_clock_get_rate(CVMX_CLOCK_CORE)/1000 *
-					timeout;
+			cycles += cvmx_clock_get_rate(CVMX_CLOCK_CORE)/1000 * timeout;
 
 			/* Wait for queue to drain */
 			do {
-				res = cvmx_pko3_dq_query(node, dq_base + i);
+				res = cvmx_pko3_dq_query(xi.node, dq_base + i);
 				if (cycles < cvmx_get_cycle())
 					break;
 			} while(res > 0);
@@ -844,7 +985,7 @@ int cvmx_helper_pko3_shut_interface(int interface)
 					__FUNCTION__, dq_base + i);
 
 			/* Close the queue, free internal buffers */
-			res = cvmx_pko3_dq_close(node, dq_base + i);
+			res = cvmx_pko3_dq_close(xi.node, dq_base + i);
 
 			if (res < 0)
 				cvmx_dprintf("%s: ERROR: closing queue %u\n",
@@ -854,19 +995,19 @@ int cvmx_helper_pko3_shut_interface(int interface)
 
 		/* Release all global resources owned by this interface/port */
 
-		res_owner = __cvmx_helper_pko3_res_owner(node, ipd_port);
+		res_owner = __cvmx_helper_pko3_res_owner(ipd_port);
 		if (res_owner < 0) {
 			cvmx_dprintf ("%s: ERROR no resource owner ticket\n",
 				__FUNCTION__);
 			continue;
 		}
 
-		cvmx_pko_free_queues(node,CVMX_PKO_DESCR_QUEUES, res_owner);
-		cvmx_pko_free_queues(node,CVMX_PKO_L5_QUEUES, res_owner);
-		cvmx_pko_free_queues(node,CVMX_PKO_L4_QUEUES, res_owner);
-		cvmx_pko_free_queues(node,CVMX_PKO_L3_QUEUES, res_owner);
-		cvmx_pko_free_queues(node,CVMX_PKO_L2_QUEUES, res_owner);
-		cvmx_pko_free_queues(node,CVMX_PKO_PORT_QUEUES, res_owner);
+		cvmx_pko_free_queues(xi.node, CVMX_PKO_DESCR_QUEUES, res_owner);
+		cvmx_pko_free_queues(xi.node, CVMX_PKO_L5_QUEUES, res_owner);
+		cvmx_pko_free_queues(xi.node, CVMX_PKO_L4_QUEUES, res_owner);
+		cvmx_pko_free_queues(xi.node, CVMX_PKO_L3_QUEUES, res_owner);
+		cvmx_pko_free_queues(xi.node, CVMX_PKO_L2_QUEUES, res_owner);
+		cvmx_pko_free_queues(xi.node, CVMX_PKO_PORT_QUEUES, res_owner);
 
 	} /* for port */
 
@@ -880,14 +1021,13 @@ int cvmx_helper_pko3_shut_interface(int interface)
  *
  * Disables the PKO, frees all its buffers.
  */
-int cvmx_helper_pko3_shutdown(void)
+int cvmx_helper_pko3_shutdown(unsigned int node)
 {
-	unsigned node = cvmx_get_node_num();
 	unsigned dq;
 	int res;
 
 	 /* destroy NULL interface here, only PKO knows about it */
-	 cvmx_helper_pko3_shut_interface(-1);
+	cvmx_helper_pko3_shut_interface(cvmx_helper_node_interface_to_xiface(node, __CVMX_XIFACE_NULL));
 
 	 /* Check that all DQs are closed */
 	for(dq =0; dq < (1<<10); dq++) {
@@ -900,5 +1040,12 @@ int cvmx_helper_pko3_shutdown(void)
 		}
 	}
 
-	return cvmx_pko3_hw_disable(node);
+	res = cvmx_pko3_hw_disable(node);
+
+#if 0
+	//XXX- shut down AURA/POOL we created, avoid warning
+	cvmx_fpa3_assign_aura(node, __cvmx_pko3_aura_num, 0);
+	cvmx_fpa3_disable_pool(node, __cvmx_pko3_pool_num);
+#endif
+	return res;
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
index e236f56..0e85399 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
@@ -43,7 +43,7 @@
  * Functions for RGMII/GMII/MII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 95258 $<hr>
+ * <hr>$Revision: 96596 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -75,11 +75,12 @@
  *
  * @return Number of RGMII/GMII/MII ports (0-4).
  */
-int __cvmx_helper_rgmii_probe(int interface)
+int __cvmx_helper_rgmii_probe(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int num_ports = 0;
 	union cvmx_gmxx_inf_mode mode;
-	mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
+	mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(xi.interface));
 
 	if (mode.s.type) {
 		if (OCTEON_IS_MODEL(OCTEON_CN38XX) ||
@@ -150,8 +151,10 @@ void cvmx_helper_rgmii_internal_loopback(int port)
  *
  * @return Zero on success
  */
-int __cvmx_helper_rgmii_enable(int interface)
+int __cvmx_helper_rgmii_enable(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
 	int num_ports = cvmx_helper_ports_on_interface(interface);
 	int port;
 	union cvmx_gmxx_inf_mode mode;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
index 25c5a0a..cfa9cc4 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 93962 $<hr>
+ * <hr>$Revision: 96598 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -204,7 +204,7 @@ static int __cvmx_helper_sgmii_hardware_init_link(int interface, int index)
 		control_reg.s.reset = 1;
 		cvmx_write_csr(CVMX_PCSX_MRX_CONTROL_REG(index, interface), control_reg.u64);
 		if (CVMX_WAIT_FOR_FIELD64(CVMX_PCSX_MRX_CONTROL_REG(index, interface), cvmx_pcsx_mrx_control_reg_t, reset, ==, 0, 10000)) {
-			cvmx_dprintf("SGMII%d: Timeout waiting for port %d to finish reset\n", interface, index);
+			cvmx_dprintf("SGMII%x: Timeout waiting for port %d to finish reset\n", interface, index);
 			return -1;
 		}
 	}
@@ -242,7 +242,7 @@ static int __cvmx_helper_sgmii_hardware_init_link(int interface, int index)
 	    CVMX_WAIT_FOR_FIELD64(CVMX_PCSX_MRX_STATUS_REG(index, interface),
 				  union cvmx_pcsx_mrx_status_reg, an_cpt, ==, 1,
 				  10000)) {
-		cvmx_dprintf("SGMII%d: Port %d link timeout\n", interface, index);
+		cvmx_dprintf("SGMII%x: Port %d link timeout\n", interface, index);
 		return -1;
 	}
 	return 0;
@@ -431,12 +431,13 @@ static int __cvmx_helper_sgmii_hardware_init(int interface, int num_ports)
 	return 0;
 }
 
-int __cvmx_helper_sgmii_enumerate(int interface)
+int __cvmx_helper_sgmii_enumerate(int xiface)
 {
 	if (OCTEON_IS_MODEL(OCTEON_CNF71XX))
 		return 2;
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
-		enum cvmx_qlm_mode qlm_mode = cvmx_qlm_get_dlm_mode(0, interface);
+		struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+		enum cvmx_qlm_mode qlm_mode = cvmx_qlm_get_dlm_mode(0, xi.interface);
 
 		if (qlm_mode == CVMX_QLM_MODE_SGMII)
 			return 1;
@@ -457,8 +458,10 @@ int __cvmx_helper_sgmii_enumerate(int interface)
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-int __cvmx_helper_sgmii_probe(int interface)
+int __cvmx_helper_sgmii_probe(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
 	union cvmx_gmxx_inf_mode mode;
 	int ports;
 
@@ -467,14 +470,14 @@ int __cvmx_helper_sgmii_probe(int interface)
 	 * speed as well as mode.
 	 */
 	if (OCTEON_IS_OCTEON2()) {
-		int qlm = cvmx_qlm_interface(interface);
+		int qlm = cvmx_qlm_interface(xiface);
 
 		if (cvmx_qlm_get_mode(qlm) != CVMX_QLM_MODE_SGMII)
 			return 0;
 	}
 
 	/* Do not enable the interface if is not in SGMII mode */
-	ports = __cvmx_helper_sgmii_enumerate(interface);
+	ports = __cvmx_helper_sgmii_enumerate(xiface);
 
 	if (ports <= 0)
 		return 0;
@@ -501,9 +504,11 @@ int __cvmx_helper_sgmii_probe(int interface)
  *
  * @return Zero on success, negative on failure
  */
-int __cvmx_helper_sgmii_enable(int interface)
+int __cvmx_helper_sgmii_enable(int xiface)
 {
-	int num_ports = cvmx_helper_ports_on_interface(interface);
+	int num_ports = cvmx_helper_ports_on_interface(xiface);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
 	int index;
 
 	/* Setup PKND and BPID */
@@ -628,7 +633,10 @@ cvmx_helper_link_info_t __cvmx_helper_sgmii_link_get(int ipd_port)
 		speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
 	} else if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
 		speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
-		speed >>= 2;
+		if (cvmx_qlm_get_dlm_mode(0, interface) == CVMX_QLM_MODE_SGMII)
+			speed >>= 1;
+		else
+			speed >>= 2;
 	}
 
 	pcsx_mrx_control_reg.u64 = cvmx_read_csr(CVMX_PCSX_MRX_CONTROL_REG(index, interface));
@@ -684,15 +692,12 @@ int __cvmx_helper_sgmii_link_set(int ipd_port,
 	} else {
 		union cvmx_pcsx_miscx_ctl_reg pcsx_miscx_ctl_reg;
 
-		pcsx_miscx_ctl_reg.u64 = cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG
-						(index, interface));
+		pcsx_miscx_ctl_reg.u64 = cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
 
 		/* Disable autonegotiation only when MAC mode. */
 		if (pcsx_miscx_ctl_reg.s.mac_phy == 0) {
 			union cvmx_pcsx_mrx_control_reg control_reg;
-			control_reg.u64 = cvmx_read_csr(
-						CVMX_PCSX_MRX_CONTROL_REG(
-							index, interface));
+			control_reg.u64 = cvmx_read_csr(CVMX_PCSX_MRX_CONTROL_REG(index, interface));
 			control_reg.s.an_en = 0;
 			cvmx_write_csr(CVMX_PCSX_MRX_CONTROL_REG(index, interface),
 					control_reg.u64);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-spi.c b/arch/mips/cavium-octeon/executive/cvmx-helper-spi.c
index 4ece3a7..c97e043 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-spi.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-spi.c
@@ -43,7 +43,7 @@
  * Functions for SPI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 78551 $<hr>
+ * <hr>$Revision: 96176 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
@@ -61,10 +61,11 @@
 #include "cvmx-helper.h"
 #endif
 
-int __cvmx_helper_spi_enumerate(int interface)
+int __cvmx_helper_spi_enumerate(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	if ((cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) &&
-	    cvmx_spi4000_is_present(interface))
+	    cvmx_spi4000_is_present(xi.interface))
 		return 10;
 	else
 		return 16;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c b/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
index 95da3e0..c0b8483 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
@@ -74,8 +74,9 @@
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-int __cvmx_helper_srio_probe(int interface)
+int __cvmx_helper_srio_probe(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	cvmx_sriox_status_reg_t srio0_status_reg;
 	cvmx_sriox_status_reg_t srio1_status_reg;
 
@@ -85,7 +86,7 @@ int __cvmx_helper_srio_probe(int interface)
 	/* Read MIO_QLMX_CFG CSRs to find SRIO mode. */
 	if (OCTEON_IS_MODEL(OCTEON_CN66XX)) {
 		enum cvmx_qlm_mode mode = cvmx_qlm_get_mode(0);
-		int srio_port = interface - 4;
+		int srio_port = xi.interface - 4;
 		switch (srio_port) {
 		case 0:	/* 1x4 lane */
 			if (mode == CVMX_QLM_MODE_SRIO_1X4 ||
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
index 82bb49a..e74cadf 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -44,7 +44,6 @@
  *
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-#include <linux/slab.h>
 #include <linux/export.h>
 
 #include <asm/octeon/cvmx.h>
@@ -161,19 +160,6 @@ static const struct ipd_port_map ipd_port_map_78xx[CVMX_HELPER_MAX_IFACE] = {
 	{LB,	0x000,	0x03f,	0x00},		/* Interface 9 - LOOPBACK */
 };
 
-struct cvmx_iface {
-	int cvif_ipd_nports;
-	int cvif_has_fcs;	/* PKO fcs for this interface. */
-	enum cvmx_pko_padding cvif_padding;
-	cvmx_helper_link_info_t *cvif_ipd_port_link_info;
-};
-
-/*
- * This has to be static as u-boot expects to probe an interface and
- * gets the number of its ports.
- */
-static CVMX_SHARED struct cvmx_iface cvmx_interfaces[CVMX_HELPER_MAX_IFACE];
-
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 /**
  * Get the version of the CVMX libraries.
@@ -234,6 +220,7 @@ const char *cvmx_helper_interface_mode_to_string(cvmx_helper_interface_mode_t mo
 	}
 	return "UNKNOWN";
 }
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 
 /**
  * Debug routine to dump the packet structure to the console
@@ -304,14 +291,14 @@ int cvmx_helper_dump_packet(cvmx_wqe_t *work)
 		    !wqe->pki_wqe_translated) {
 			bptr.u64 = buffer_ptr.u64;
 			/* XXX- assumes cache-line aligned buffer */
-			start_of_buffer = (bptr.s_cn78xx.addr >> 7) << 7;
+			start_of_buffer = (bptr.addr >> 7) << 7;
 			cvmx_dprintf("    Buffer Start:%llx\n",
 				(unsigned long long)start_of_buffer);
 			cvmx_dprintf("    Buffer Data: %llx\n",
-				(unsigned long long)bptr.s_cn78xx.addr);
-			cvmx_dprintf("    Buffer Size: %u\n", bptr.s_cn78xx.size);
-			data_address = (uint8_t *) cvmx_phys_to_ptr(bptr.s_cn78xx.addr);
-			end_of_data = data_address + bptr.s_cn78xx.size;
+				(unsigned long long)bptr.addr);
+			cvmx_dprintf("    Buffer Size: %u\n", bptr.size);
+			data_address = (uint8_t *) cvmx_phys_to_ptr(bptr.addr);
+			end_of_data = data_address + bptr.size;
 		} else {
 			start_of_buffer = ((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back) << 7;
 			cvmx_dprintf("    Buffer Start:%llx\n", (unsigned long long)start_of_buffer);
@@ -344,9 +331,9 @@ int cvmx_helper_dump_packet(cvmx_wqe_t *work)
 
 		if (remaining_bytes) {
 			if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
-			    !wqe->word2.pki.software)
+			    !wqe->word2.software)
 				buffer_ptr.u64 = *(uint64_t *)
-					cvmx_phys_to_ptr(bptr.s_cn78xx.addr-8);
+					cvmx_phys_to_ptr(bptr.addr-8);
 			else
 				buffer_ptr.u64 = *(uint64_t *)
 					cvmx_phys_to_ptr(buffer_ptr.s.addr-8);
@@ -355,6 +342,275 @@ int cvmx_helper_dump_packet(cvmx_wqe_t *work)
 	return 0;
 }
 
+/**
+ * Extract packet data buffer pointer from work queue entry.
+ *
+ * Returns the legacy (Octeon1/Octeon2) buffer pointer structure
+ * for the linked buffer list.
+ * On CN78XX, the native buffer pointer structure is converted into
+ * the legacy format.
+ * The legacy buf_ptr is then stored in the WQE, and word0 reserved
+ * field is set to indicate that the buffer pointers were translated.
+ * If the packet data is only found inside the work queue entry,
+ * a standard buffer pointer structure is created for it.
+ */
+cvmx_buf_ptr_t cvmx_wqe_get_packet_ptr(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t * wqe = (void *) work;
+		cvmx_buf_ptr_t optr, lptr;
+		cvmx_buf_ptr_pki_t nptr;
+		unsigned pool, bufs;
+
+		/* In case of repeated calls of this function */
+		if (wqe->pki_wqe_translated) {
+			optr.u64 = wqe->packet_ptr.u64;
+			return optr;
+		}
+
+		bufs = wqe->word0.bufs;
+		pool = wqe->word0.aura;
+		nptr.u64 = wqe->packet_ptr.u64;
+
+		optr.u64=0;
+		optr.s.pool = pool;
+		optr.s.addr = nptr.addr;
+		optr.s.size = nptr.size;
+
+		/* Calculate the "back" offset */
+		if (!nptr.packet_outside_wqe)
+			optr.s.back = (nptr.addr-cvmx_ptr_to_phys(wqe))
+				>> 7;
+		else
+			optr.s.back = 0; //XXX assume <128, get actual pool sz
+
+		lptr = optr;
+
+		/* Follow pointer and convert all linked pointers */
+		while (bufs > 1) {
+			void * vptr;
+
+			vptr = cvmx_phys_to_ptr(lptr.s.addr);
+
+			memcpy(&nptr, vptr - 8, 8);
+
+			lptr.u64=0;
+			lptr.s.pool = pool;
+			lptr.s.addr = nptr.addr;
+			lptr.s.size = nptr.size;
+			lptr.s.back = 0;	//XXX- not guarangeed !!
+
+			memcpy(vptr-8, &lptr, 8);
+			bufs --;
+		}
+		/* Store translated bufptr in WQE, and set indicator */
+		wqe->pki_wqe_translated = 1;
+		wqe->packet_ptr.u64 = optr.u64;
+		return optr;
+
+	} else {
+		cvmx_buf_ptr_t bptr;
+
+		if ( work->word2.s.bufs > 0)
+			return work->packet_ptr;
+
+		/* data is only in WQE, convert it into a buf_ptr */
+		bptr.u64 = 0;
+		bptr.s.size = cvmx_wqe_get_len(work);
+		bptr.s.pool = cvmx_read_csr(CVMX_IPD_WQE_FPA_QUEUE) & 7;
+		bptr.s.addr = cvmx_ptr_to_phys(work) + 32;
+
+		/* For CN68XX it could be NO_WPTR or Dynamic-Short cause */
+		if (__cvmx_ipd_mode_no_wptr()) {
+			/* Packet pool is hardwired to 0 in relevant SoCs */
+			bptr.s.pool = 0;
+		}
+
+		/* FIXME- RAWFULL case not handled yet */
+
+		if (work->word2.s_cn38xx.not_IP ||
+		    work->word2.s_cn38xx.rcv_error) {
+			/* Adjust data offset for non-IP packets */
+                        union cvmx_pip_gbl_cfg pip_gbl_cfg;
+                        pip_gbl_cfg.u64 = cvmx_read_csr(CVMX_PIP_GBL_CFG);
+                        bptr.s.addr += pip_gbl_cfg.s.nip_shf;
+		} else {
+			/* Adjust data start address for IP protocols */
+                        union cvmx_pip_ip_offset pip_ip_offset;
+                        pip_ip_offset.u64 = cvmx_read_csr(CVMX_PIP_IP_OFFSET);
+                        bptr.s.addr += (pip_ip_offset.s.offset << 3) -
+				work->word2.s.ip_offset;
+                        bptr.s.addr += (work->word2.s.is_v6 ^ 1) << 2;
+		}
+
+		/* Calculate the "back" offset in 64-bit words */
+		bptr.s.back = (bptr.s.addr -cvmx_ptr_to_phys(work)) >> 7;
+
+		/* Store the new buffer pointer back into WQE */
+		work->packet_ptr = bptr;
+
+		/* Adjust word2.bufs so that _free_data() handles it
+		 * in the same way as PKO
+		 */
+		work->word2.s.bufs = 1;
+
+		/* Returned the synthetic buffer_pointer */
+		return bptr;
+	}
+}
+
+void cvmx_wqe_free(cvmx_wqe_t *work)
+{
+	unsigned ncl;
+	unsigned pool;
+	uint64_t paddr;
+	cvmx_wqe_78xx_t * wqe = (void *) work;
+
+	/* Free native untranslated 78xx WQE */
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
+		!wqe->pki_wqe_translated) {
+		cvmx_buf_ptr_pki_t bptr;
+
+		bptr = wqe->packet_ptr;
+
+		/* Do nothing if the first packet buffer shares WQE buffer */
+		if (!bptr.packet_outside_wqe)
+			return;
+	} else {
+		/* determine if packet is inside WQE the old way */
+		if (cvmx_wqe_get_bufs(work) > 0) {
+			/* Check if the first data buffer is inside WQE */
+			paddr = (work->packet_ptr.s.addr >> 7) -
+				work->packet_ptr.s.back;
+			paddr = paddr << 7;
+
+			/* do not free WQE if contains first data buffer */
+			if (paddr == cvmx_ptr_to_phys(work))
+				return;
+		}
+	}
+
+	/* At this point it is clear the WQE needs to be freed */
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		/* First buffer outside WQE, but WQE comes from the same AURA */
+		/* Only a few words have been touched, not entire buf */
+		ncl = 1;
+		cvmx_fpa3_free_gaura(work, wqe->word0.aura, ncl);
+	} else {
+		/* Determine FPA pool the WQE buffer belongs to */
+		if (__cvmx_ipd_mode_no_wptr()) {
+			pool = 0 ; /* Hardwired packet FPA pool */
+			ncl = (cvmx_wqe_get_len(work) + 127) >> 7;
+			ncl += 4;
+		} else {
+			pool = cvmx_read_csr(CVMX_IPD_WQE_FPA_QUEUE) & 7;
+			ncl = 1;
+		}
+
+		cvmx_fpa1_free(work, pool, ncl);
+	}
+}
+
+#endif
+
+/**
+ * Free the packet buffers contained in a work queue entry.
+ * The work queue entry is not freed.
+ * Note that this function will not free the work queue entry
+ * even if it contains a non-redundant data packet, and hence
+ * it is not really comparable to how the PKO would free a packet
+ * buffers if requested.
+ *
+ * @param work   Work queue entry with packet to free
+ */
+void cvmx_helper_free_packet_data(cvmx_wqe_t *work)
+{
+	uint64_t number_buffers;
+	uint64_t start_of_buffer;
+	uint64_t next_buffer_ptr;
+	unsigned ncl;
+	cvmx_buf_ptr_t buffer_ptr;
+	cvmx_buf_ptr_pki_t bptr;
+	cvmx_wqe_78xx_t *wqe = (void *) work;
+
+	number_buffers = cvmx_wqe_get_bufs(work);
+
+	buffer_ptr.u64 = work->packet_ptr.u64;
+
+	/* Zero-out WQE WORD3 so that the WQE is freed by cvmx_wqe_free() */
+	work->packet_ptr.u64 = 0;
+
+	if (number_buffers == 0)
+		return;
+
+	/* Interpret PKI-style bufptr unless it has been translated */
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
+	    !wqe->pki_wqe_translated) {
+		bptr.u64 = buffer_ptr.u64;
+		next_buffer_ptr = *(uint64_t *)
+			cvmx_phys_to_ptr(bptr.addr - 8);
+		if (!bptr.packet_outside_wqe) {
+			buffer_ptr.u64 = next_buffer_ptr;
+			number_buffers--;
+		}
+	} else {
+		start_of_buffer =
+			((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back) << 7;
+		next_buffer_ptr = *(uint64_t *)
+			cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
+		/* Since the number of buffers is not zero, we know this is not a dynamic
+		short packet. We need to check if it is a packet received with
+		IPD_CTL_STATUS[NO_WPTR]. If this is true, we need to free all buffers
+		except for the first one. The caller doesn't expect their WQE pointer
+		to be freed */
+		if (cvmx_ptr_to_phys(work) == start_of_buffer) {
+			buffer_ptr.u64 = next_buffer_ptr;
+			number_buffers--;
+		}
+	}
+	while (number_buffers--) {
+		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
+		    !wqe->pki_wqe_translated) {
+			unsigned aura = cvmx_wqe_get_aura(work);
+			bptr.u64 = buffer_ptr.u64;
+
+			ncl = (bptr.size + CVMX_CACHE_LINE_SIZE-1)/
+				CVMX_CACHE_LINE_SIZE;
+
+			/* XXX- assumes the buffer is cache-line aligned */
+			start_of_buffer = (bptr.addr >> 7) << 7;
+
+			/* Read pointer to next buffer before we free the current buffer. */
+			next_buffer_ptr = *(uint64_t *)
+				cvmx_phys_to_ptr(bptr.addr - 8);
+			/* FPA AURA comes from WQE, includes node */
+			cvmx_fpa3_free_gaura(cvmx_phys_to_ptr(start_of_buffer),	aura, ncl);
+		} else {
+			ncl = (buffer_ptr.s.size + CVMX_CACHE_LINE_SIZE-1)/
+				CVMX_CACHE_LINE_SIZE + buffer_ptr.s.back;
+			/* Calculate buffer start using "back" offset,
+			   Remember the back pointer is in cache lines,
+			   not 64bit words */
+			start_of_buffer =
+				((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back)
+					<< 7;
+			/* Read pointer to next buffer before we free
+			the current buffer. */
+			next_buffer_ptr = *(uint64_t *)
+				cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
+			/* FPA pool comes from buf_ptr itself */
+			if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+				/* FIXME:  Which node is it? */
+				cvmx_fpa3_free_aura(cvmx_phys_to_ptr(start_of_buffer), 0, (int)buffer_ptr.s.pool, ncl);
+			else
+				cvmx_fpa1_free(cvmx_phys_to_ptr(start_of_buffer),
+					      buffer_ptr.s.pool, ncl);
+		}
+		buffer_ptr.u64 = next_buffer_ptr;
+	}
+
+}
+
 void cvmx_helper_setup_legacy_red(int pass_thresh, int drop_thresh)
 {
 	unsigned int node = cvmx_get_node_num();
@@ -420,12 +676,13 @@ EXPORT_SYMBOL(cvmx_helper_setup_red);
  *
  * @return Zero on success, negative on failure
  */
-int __cvmx_helper_setup_gmx(int interface, int num_ports)
+int __cvmx_helper_setup_gmx(int xiface, int num_ports)
 {
 	union cvmx_gmxx_tx_prts gmx_tx_prts;
 	union cvmx_gmxx_rx_prts gmx_rx_prts;
 	union cvmx_pko_reg_gmx_port_mode pko_mode;
 	union cvmx_gmxx_txx_thresh gmx_tx_thresh;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int index;
 
 	/* The common BGX settings are already done in the appropriate
@@ -434,15 +691,15 @@ int __cvmx_helper_setup_gmx(int interface, int num_ports)
 		return 0;
 
 	/* Tell GMX the number of TX ports on this interface */
-	gmx_tx_prts.u64 = cvmx_read_csr(CVMX_GMXX_TX_PRTS(interface));
+	gmx_tx_prts.u64 = cvmx_read_csr(CVMX_GMXX_TX_PRTS(xi.interface));
 	gmx_tx_prts.s.prts = num_ports;
-	cvmx_write_csr(CVMX_GMXX_TX_PRTS(interface), gmx_tx_prts.u64);
+	cvmx_write_csr(CVMX_GMXX_TX_PRTS(xi.interface), gmx_tx_prts.u64);
 
 	/*
 	 * Tell GMX the number of RX ports on this interface.  This only applies
 	 * to *GMII and XAUI ports.
 	 */
-	switch (cvmx_helper_interface_get_mode(interface)) {
+	switch (cvmx_helper_interface_get_mode(xiface)) {
 	case CVMX_HELPER_INTERFACE_MODE_RGMII:
 	case CVMX_HELPER_INTERFACE_MODE_SGMII:
 	case CVMX_HELPER_INTERFACE_MODE_QSGMII:
@@ -454,9 +711,9 @@ int __cvmx_helper_setup_gmx(int interface, int num_ports)
 			return -1;
 		}
 
-		gmx_rx_prts.u64 = cvmx_read_csr(CVMX_GMXX_RX_PRTS(interface));
+		gmx_rx_prts.u64 = cvmx_read_csr(CVMX_GMXX_RX_PRTS(xi.interface));
 		gmx_rx_prts.s.prts = num_ports;
-		cvmx_write_csr(CVMX_GMXX_RX_PRTS(interface), gmx_rx_prts.u64);
+		cvmx_write_csr(CVMX_GMXX_RX_PRTS(xi.interface), gmx_rx_prts.u64);
 		break;
 
 	default:
@@ -473,7 +730,7 @@ int __cvmx_helper_setup_gmx(int interface, int num_ports)
 	    !OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		/* Tell PKO the number of ports on this interface */
 		pko_mode.u64 = cvmx_read_csr(CVMX_PKO_REG_GMX_PORT_MODE);
-		if (interface == 0) {
+		if (xi.interface == 0) {
 			if (num_ports == 1)
 				pko_mode.s.mode0 = 4;
 			else if (num_ports == 2)
@@ -505,7 +762,7 @@ int __cvmx_helper_setup_gmx(int interface, int num_ports)
 	 * due to memory contention. Any packet that fits entirely in the
 	 * GMX FIFO can never have an under run regardless of memory load.
 	 */
-	gmx_tx_thresh.u64 = cvmx_read_csr(CVMX_GMXX_TXX_THRESH(0, interface));
+	gmx_tx_thresh.u64 = cvmx_read_csr(CVMX_GMXX_TXX_THRESH(0, xi.interface));
 	if (OCTEON_IS_MODEL(OCTEON_CN30XX) ||
 	    OCTEON_IS_MODEL(OCTEON_CN31XX) ||
 	    OCTEON_IS_MODEL(OCTEON_CN50XX)) {
@@ -531,22 +788,22 @@ int __cvmx_helper_setup_gmx(int interface, int num_ports)
 	if (num_ports > 4)
 		num_ports = 4;
 	for (index = 0; index < num_ports; index++)
-		cvmx_write_csr(CVMX_GMXX_TXX_THRESH(index, interface), gmx_tx_thresh.u64);
+		cvmx_write_csr(CVMX_GMXX_TXX_THRESH(index, xi.interface), gmx_tx_thresh.u64);
 
 	/*
 	 * For o68, we need to setup the pipes
 	 */
-	if (OCTEON_IS_MODEL(OCTEON_CN68XX) && interface < CVMX_HELPER_MAX_GMX) {
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX) && xi.interface < CVMX_HELPER_MAX_GMX) {
 		union cvmx_gmxx_txx_pipe config;
 
 		for (index = 0; index < num_ports; index++) {
 			config.u64 = 0;
 
-			if (__cvmx_helper_cfg_pko_port_base(interface, index) >= 0) {
-				config.u64 = cvmx_read_csr(CVMX_GMXX_TXX_PIPE(index, interface));
-				config.s.nump = __cvmx_helper_cfg_pko_port_num(interface, index);
-				config.s.base = __cvmx_helper_cfg_pko_port_base(interface, index);
-				cvmx_write_csr(CVMX_GMXX_TXX_PIPE(index, interface), config.u64);
+			if (__cvmx_helper_cfg_pko_port_base(xiface, index) >= 0) {
+				config.u64 = cvmx_read_csr(CVMX_GMXX_TXX_PIPE(index, xi.interface));
+				config.s.nump = __cvmx_helper_cfg_pko_port_num(xiface, index);
+				config.s.base = __cvmx_helper_cfg_pko_port_base(xiface, index);
+				cvmx_write_csr(CVMX_GMXX_TXX_PIPE(index, xi.interface), config.u64);
 			}
 		}
 	}
@@ -560,223 +817,72 @@ int cvmx_helper_get_pko_port(int interface, int port)
 }
 EXPORT_SYMBOL(cvmx_helper_get_pko_port);
 
-int cvmx_helper_get_ipd_port(int interface, int port)
+int cvmx_helper_get_ipd_port(int xiface, int index)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		const struct ipd_port_map	*port_map;
 		int				ipd_port;
 
-		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 			port_map = ipd_port_map_68xx;
-		else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+			ipd_port = 0;
+		} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 			port_map = ipd_port_map_78xx;
+			ipd_port = cvmx_helper_node_to_ipd_port(xi.node, 0);
+		}
 		else
 			return -1;
 
-		ipd_port = port_map[interface].first_ipd_port;
-		if (port_map[interface].type == GMII) {
-			cvmx_helper_interface_mode_t mode =
-				cvmx_helper_interface_get_mode(interface);
+		ipd_port += port_map[xi.interface].first_ipd_port;
+		if (port_map[xi.interface].type == GMII) {
+			cvmx_helper_interface_mode_t mode;
+			mode = cvmx_helper_interface_get_mode(xiface);
 			if (mode == CVMX_HELPER_INTERFACE_MODE_XAUI ||
 			    mode == CVMX_HELPER_INTERFACE_MODE_RXAUI) {
-				ipd_port += port_map[interface].ipd_port_adj;
+				ipd_port += port_map[xi.interface].ipd_port_adj;
 				return ipd_port;
 			} else
-				return ipd_port + (port * 16);
-		} else if (port_map[interface].type == ILK)
-			return ipd_port + port;
-		else if (port_map[interface].type == NPI)
-			return ipd_port + port;
-		else if (port_map[interface].type == LB)
-			return ipd_port + port;
+				return ipd_port + (index * 16);
+		} else if (port_map[xi.interface].type == ILK)
+			return ipd_port + index;
+		else if (port_map[xi.interface].type == NPI)
+			return ipd_port + index;
+		else if (port_map[xi.interface].type == LB)
+			return ipd_port + index;
 		else
 			return -1;
 
-	} else if (cvmx_helper_interface_get_mode(interface) ==
-			CVMX_HELPER_INTERFACE_MODE_AGL) {
+	} else if (cvmx_helper_interface_get_mode(xiface) == CVMX_HELPER_INTERFACE_MODE_AGL) {
 		return 24;
 	}
 
-	switch (interface) {
+	switch (xi.interface) {
 	case 0:
-		return port;
+		return index;
 	case 1:
-		return port + 16;
+		return index + 16;
 	case 2:
-		return port + 32;
+		return index + 32;
 	case 3:
-		return port + 36;
+		return index + 36;
 	case 4:
-		return port + 40;
+		return index + 40;
 	case 5:
-		return port + 42;
+		return index + 42;
 	case 6:
-		return port + 44;
+		return index + 44;
 	case 7:
-		return port + 46;
+		return index + 46;
 	}
 	return -1;
 }
 EXPORT_SYMBOL(cvmx_helper_get_ipd_port);
 
-int __cvmx_helper_get_num_ipd_ports(int interface)
-{
-	struct cvmx_iface *piface;
-
-	if (interface >= cvmx_helper_get_number_of_interfaces())
-		return -1;
-
-	piface = &cvmx_interfaces[interface];
-	return piface->cvif_ipd_nports;
-}
-
-enum cvmx_pko_padding __cvmx_helper_get_pko_padding(int interface)
-{
-	struct cvmx_iface *piface;
-
-	if (interface >= cvmx_helper_get_number_of_interfaces())
-		return CVMX_PKO_PADDING_NONE;
-
-	piface = &cvmx_interfaces[interface];
-	return piface->cvif_padding;
-}
-
-int __cvmx_helper_init_interface(int interface, int num_ipd_ports,
-				 int has_fcs, enum cvmx_pko_padding pad)
-{
-	struct cvmx_iface *piface;
-	cvmx_helper_link_info_t *p;
-	int i;
-	int sz;
-#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	uint64_t addr;
-	char name[32];
-#endif
-
-	if (interface >= cvmx_helper_get_number_of_interfaces())
-		return -1;
-
-	piface = &cvmx_interfaces[interface];
-	piface->cvif_ipd_nports = num_ipd_ports;
-	piface->cvif_padding = pad;
-
-	piface->cvif_has_fcs = has_fcs;
-
-	/*
-	 * allocate the per-ipd_port link_info structure
-	 */
-	sz = piface->cvif_ipd_nports * sizeof(cvmx_helper_link_info_t);
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	if (sz == 0)
-		sz = sizeof(cvmx_helper_link_info_t);
-	piface->cvif_ipd_port_link_info = (cvmx_helper_link_info_t *) kmalloc(sz, GFP_KERNEL);
-	if (ZERO_OR_NULL_PTR(piface->cvif_ipd_port_link_info))
-		panic("Cannot allocate memory in __cvmx_helper_init_interface.");
-#else
-	snprintf(name, sizeof(name), "__int_%d_link_info", interface);
-	addr = CAST64(cvmx_bootmem_alloc_named_range_once(sz, 0, 0, 128, name, NULL));
-	piface->cvif_ipd_port_link_info = (cvmx_helper_link_info_t *) __cvmx_phys_addr_to_ptr(addr, sz);
-#endif
-	if (!piface->cvif_ipd_port_link_info) {
-		if (sz != 0)
-			cvmx_dprintf("iface %d failed to alloc link info\n",
-			    interface);
-		return -1;
-	}
-
-	/* Initialize them */
-	p = piface->cvif_ipd_port_link_info;
-
-	for (i = 0; i < piface->cvif_ipd_nports; i++) {
-		(*p).u64 = 0;
-		p++;
-	}
-	return 0;
-}
-
-/*
- * Shut down the interfaces; free the resources.
- * @INTERNAL
- */
-void __cvmx_helper_shutdown_interfaces(void)
-{
-	int i;
-	int nifaces;		/* number of interfaces */
-	struct cvmx_iface *piface;
-
-	nifaces = cvmx_helper_get_number_of_interfaces();
-	for (i = 0; i < nifaces; i++) {
-		piface = cvmx_interfaces + i;
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-		if (piface->cvif_ipd_port_link_info)
-			kfree(piface->cvif_ipd_port_link_info);
-#elif defined(__U_BOOT__) && 0
-		if (piface->cvif_ipd_port_link_info) {
-			char name[32];
-			snprintf(name, sizeof(name),
-				 "__int_%d_link_info", i);
-			cvmx_bootmem_phy_named_block_free(name, 0);
-		}
-#else
-		/*
-		 * For SE apps, bootmem was meant to be allocated and never
-		 * freed.
-		 */
-#endif
-		piface->cvif_ipd_port_link_info = 0;
-	}
-}
-
-int __cvmx_helper_set_link_info(int interface, int port, cvmx_helper_link_info_t link_info)
-{
-	struct cvmx_iface *piface;
-
-	if (interface >= cvmx_helper_get_number_of_interfaces())
-		return -1;
-
-	piface = &cvmx_interfaces[interface];
-
-	if (piface->cvif_ipd_port_link_info) {
-		piface->cvif_ipd_port_link_info[port] = link_info;
-		return 0;
-	}
-
-	return -1;
-}
-
-cvmx_helper_link_info_t __cvmx_helper_get_link_info(int interface, int port)
-{
-	struct cvmx_iface *piface;
-	cvmx_helper_link_info_t err;
-
-	err.u64 = 0;
-
-	if (interface >= cvmx_helper_get_number_of_interfaces())
-		return err;
-	piface = &cvmx_interfaces[interface];
-
-	if (piface->cvif_ipd_port_link_info)
-		return piface->cvif_ipd_port_link_info[port];
-
-	return err;
-}
-
-/**
- * Returns if FCS is enabled for the specified interface and port
- *
- * @param interface - interface to check
- *
- * @return zero if FCS is not used, otherwise FCS is used.
- */
-int __cvmx_helper_get_has_fcs(int interface)
-{
-	return cvmx_interfaces[interface].cvif_has_fcs;
-}
-
-int cvmx_helper_get_pknd(int interface, int port)
+int cvmx_helper_get_pknd(int xiface, int index)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_PKND))
-		return __cvmx_helper_cfg_pknd(interface, port);
+		return __cvmx_helper_cfg_pknd(xiface, index);
 
 	return CVMX_INVALID_PKND;
 }
@@ -835,25 +941,28 @@ void cvmx_helper_show_stats(int port)
  */
 int cvmx_helper_get_interface_num(int ipd_port)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
+	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		const struct ipd_port_map	*port_map;
 		int				i;
-
-		if (OCTEON_IS_MODEL(OCTEON_CN68XX))
-			port_map = ipd_port_map_68xx;
-		else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-			port_map = ipd_port_map_78xx;
-		else
-			return -1;
-
+		struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(ipd_port);
+		port_map = ipd_port_map_68xx;
 		for (i = 0; i < CVMX_HELPER_MAX_IFACE; i++) {
-			if (ipd_port >= port_map[i].first_ipd_port &&
-			    ipd_port <= port_map[i].last_ipd_port)
+			if (xp.port >= port_map[i].first_ipd_port &&
+			    xp.port <= port_map[i].last_ipd_port)
 				return i;
 		}
-
 		return -1;
-
+	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		const struct ipd_port_map	*port_map;
+		int				i;
+		struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(ipd_port);
+		port_map = ipd_port_map_78xx;
+		for (i = 0; i < CVMX_HELPER_MAX_IFACE; i++) {
+			if (xp.port >= port_map[i].first_ipd_port &&
+			    xp.port <= port_map[i].last_ipd_port)
+				return cvmx_helper_node_interface_to_xiface(xp.node, i);
+		}
+		return -1;
 	} else if (OCTEON_IS_MODEL(OCTEON_CN70XX) && ipd_port == 24) {
 		return 4;
 	} else {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
index 0dafaff..5231d73 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 94326 $<hr>
+ * <hr>$Revision: 96589 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -65,8 +65,10 @@
 #endif
 
 
-int __cvmx_helper_xaui_enumerate(int interface)
+int __cvmx_helper_xaui_enumerate(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
 	union cvmx_gmxx_hg2_control gmx_hg2_control;
 
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX)) {
@@ -95,9 +97,11 @@ int __cvmx_helper_xaui_enumerate(int interface)
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-int __cvmx_helper_xaui_probe(int interface)
+int __cvmx_helper_xaui_probe(int xiface)
 {
 	int i, ports;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
 	union cvmx_gmxx_inf_mode mode;
 
 	/*
@@ -137,7 +141,7 @@ int __cvmx_helper_xaui_probe(int interface)
 	 * the speed as well as mode.
 	 */
 	if (OCTEON_IS_MODEL(OCTEON_CN6XXX)) {
-		int qlm = cvmx_qlm_interface(interface);
+		int qlm = cvmx_qlm_interface(xiface);
 		enum cvmx_qlm_mode mode = cvmx_qlm_get_mode(qlm);
 
 		if (mode != CVMX_QLM_MODE_XAUI &&
@@ -145,7 +149,7 @@ int __cvmx_helper_xaui_probe(int interface)
 			return 0;
 	}
 
-	ports =  __cvmx_helper_xaui_enumerate(interface);
+	ports =  __cvmx_helper_xaui_enumerate(xiface);
 
 	if (ports <= 0)
 		return 0;
@@ -349,8 +353,11 @@ int __cvmx_helper_xaui_link_init(int interface)
  *
  * @return Zero on success, negative on failure
  */
-int __cvmx_helper_xaui_enable(int interface)
+int __cvmx_helper_xaui_enable(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+
 	/* Setup PKND and BPID */
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		union cvmx_gmxx_bpid_msk bpid_msk;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper.c b/arch/mips/cavium-octeon/executive/cvmx-helper.c
index 084e0b0..7a4576a 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper.c
@@ -44,6 +44,7 @@
  *
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <linux/slab.h>
 #include <linux/export.h>
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-bootmem.h>
@@ -127,11 +128,11 @@
  *
  * @param loopback	Method to configure a port in loopback.
  */
-struct iface_ops_s {
+struct iface_ops {
 	cvmx_helper_interface_mode_t	mode;
-	int				(*enumerate)(int interface);
-	int				(*probe)(int interface);
-	int				(*enable)(int interface);
+	int				(*enumerate)(int xiface);
+	int				(*probe)(int xiface);
+	int				(*enable)(int xiface);
 	cvmx_helper_link_info_t		(*link_get)(int ipd_port);
 	int				(*link_set)(int ipd_port,
 					     cvmx_helper_link_info_t link_info);
@@ -143,7 +144,7 @@ struct iface_ops_s {
  * @INTERNAL
  * This structure is used by disabled interfaces.
  */
-static const struct iface_ops_s iface_ops_dis = {
+static const struct iface_ops iface_ops_dis = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_DISABLED,
 };
 
@@ -152,9 +153,9 @@ static const struct iface_ops_s iface_ops_dis = {
  * This structure specifies the interface methods used by interfaces
  * configured as gmii.
  */
-static const struct iface_ops_s iface_ops_gmii = {
+static const struct iface_ops iface_ops_gmii = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_GMII,
-	.enumerate	= __cvmx_helper_rgmii_enumerate,
+	.enumerate	= __cvmx_helper_rgmii_probe,
 	.probe		= __cvmx_helper_rgmii_probe,
 	.enable		= __cvmx_helper_rgmii_enable,
 	.link_get	= __cvmx_helper_gmii_link_get,
@@ -167,9 +168,9 @@ static const struct iface_ops_s iface_ops_gmii = {
  * This structure specifies the interface methods used by interfaces
  * configured as rgmii.
  */
-static const struct iface_ops_s iface_ops_rgmii = {
+static const struct iface_ops iface_ops_rgmii = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_RGMII,
-	.enumerate	= __cvmx_helper_rgmii_enumerate,
+	.enumerate	= __cvmx_helper_rgmii_probe,
 	.probe		= __cvmx_helper_rgmii_probe,
 	.enable		= __cvmx_helper_rgmii_enable,
 	.link_get	= __cvmx_helper_rgmii_link_get,
@@ -182,7 +183,7 @@ static const struct iface_ops_s iface_ops_rgmii = {
  * This structure specifies the interface methods used by interfaces
  * configured as sgmii that use the gmx mac.
  */
-static const struct iface_ops_s iface_ops_sgmii = {
+static const struct iface_ops iface_ops_sgmii = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_SGMII,
 	.enumerate	= __cvmx_helper_sgmii_enumerate,
 	.probe		= __cvmx_helper_sgmii_probe,
@@ -197,7 +198,7 @@ static const struct iface_ops_s iface_ops_sgmii = {
  * This structure specifies the interface methods used by interfaces
  * configured as sgmii that use the bgx mac.
  */
-static const struct iface_ops_s iface_ops_bgx_sgmii = {
+static const struct iface_ops iface_ops_bgx_sgmii = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_SGMII,
 	.enumerate	= __cvmx_helper_bgx_enumerate,
 	.probe		= __cvmx_helper_bgx_probe,
@@ -212,7 +213,7 @@ static const struct iface_ops_s iface_ops_bgx_sgmii = {
  * This structure specifies the interface methods used by interfaces
  * configured as qsgmii.
  */
-static const struct iface_ops_s iface_ops_qsgmii = {
+static const struct iface_ops iface_ops_qsgmii = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_QSGMII,
 	.enumerate	= __cvmx_helper_sgmii_enumerate,
 	.probe		= __cvmx_helper_sgmii_probe,
@@ -227,7 +228,7 @@ static const struct iface_ops_s iface_ops_qsgmii = {
  * This structure specifies the interface methods used by interfaces
  * configured as xaui using the gmx mac.
  */
-static const struct iface_ops_s iface_ops_xaui = {
+static const struct iface_ops iface_ops_xaui = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_XAUI,
 	.enumerate	= __cvmx_helper_xaui_enumerate,
 	.probe		= __cvmx_helper_xaui_probe,
@@ -242,7 +243,7 @@ static const struct iface_ops_s iface_ops_xaui = {
  * This structure specifies the interface methods used by interfaces
  * configured as xaui using the gmx mac.
  */
-static const struct iface_ops_s iface_ops_bgx_xaui = {
+static const struct iface_ops iface_ops_bgx_xaui = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_XAUI,
 	.enumerate	= __cvmx_helper_bgx_enumerate,
 	.probe		= __cvmx_helper_bgx_probe,
@@ -257,7 +258,7 @@ static const struct iface_ops_s iface_ops_bgx_xaui = {
  * This structure specifies the interface methods used by interfaces
  * configured as rxaui.
  */
-static const struct iface_ops_s iface_ops_rxaui = {
+static const struct iface_ops iface_ops_rxaui = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_RXAUI,
 	.enumerate	= __cvmx_helper_xaui_enumerate,
 	.probe		= __cvmx_helper_xaui_probe,
@@ -272,7 +273,7 @@ static const struct iface_ops_s iface_ops_rxaui = {
  * This structure specifies the interface methods used by interfaces
  * configured as xaui using the gmx mac.
  */
-static const struct iface_ops_s iface_ops_bgx_rxaui = {
+static const struct iface_ops iface_ops_bgx_rxaui = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_RXAUI,
 	.enumerate	= __cvmx_helper_bgx_enumerate,
 	.probe		= __cvmx_helper_bgx_probe,
@@ -287,7 +288,7 @@ static const struct iface_ops_s iface_ops_bgx_rxaui = {
  * This structure specifies the interface methods used by interfaces
  * configured as xlaui.
  */
-static const struct iface_ops_s iface_ops_bgx_xlaui = {
+static const struct iface_ops iface_ops_bgx_xlaui = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_XLAUI,
 	.enumerate	= __cvmx_helper_bgx_enumerate,
 	.probe		= __cvmx_helper_bgx_probe,
@@ -302,7 +303,7 @@ static const struct iface_ops_s iface_ops_bgx_xlaui = {
  * This structure specifies the interface methods used by interfaces
  * configured as xfi.
  */
-static const struct iface_ops_s iface_ops_bgx_xfi = {
+static const struct iface_ops iface_ops_bgx_xfi = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_XFI,
 	.enumerate	= __cvmx_helper_bgx_enumerate,
 	.probe		= __cvmx_helper_bgx_probe,
@@ -317,7 +318,7 @@ static const struct iface_ops_s iface_ops_bgx_xfi = {
  * This structure specifies the interface methods used by interfaces
  * configured as ilk.
  */
-static const struct iface_ops_s iface_ops_ilk = {
+static const struct iface_ops iface_ops_ilk = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_ILK,
 	.enumerate	= __cvmx_helper_ilk_enumerate,
 	.probe		= __cvmx_helper_ilk_probe,
@@ -331,9 +332,9 @@ static const struct iface_ops_s iface_ops_ilk = {
  * This structure specifies the interface methods used by interfaces
  * configured as npi.
  */
-static const struct iface_ops_s iface_ops_npi = {
+static const struct iface_ops iface_ops_npi = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_NPI,
-	.enumerate	= __cvmx_helper_npi_enumerate,
+	.enumerate	= __cvmx_helper_npi_probe,
 	.probe		= __cvmx_helper_npi_probe,
 	.enable		= __cvmx_helper_npi_enable,
 };
@@ -343,9 +344,9 @@ static const struct iface_ops_s iface_ops_npi = {
  * This structure specifies the interface methods used by interfaces
  * configured as srio.
  */
-static const struct iface_ops_s iface_ops_srio = {
+static const struct iface_ops iface_ops_srio = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_SRIO,
-	.enumerate	= __cvmx_helper_srio_enumerate,
+	.enumerate	= __cvmx_helper_srio_probe,
 	.probe		= __cvmx_helper_srio_probe,
 	.enable		= __cvmx_helper_srio_enable,
 	.link_get	= __cvmx_helper_srio_link_get,
@@ -357,7 +358,7 @@ static const struct iface_ops_s iface_ops_srio = {
  * This structure specifies the interface methods used by interfaces
  * configured as agl.
  */
-static const struct iface_ops_s iface_ops_agl = {
+static const struct iface_ops iface_ops_agl = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_AGL,
 	.enumerate	= __cvmx_helper_agl_enumerate,
 	.probe		= __cvmx_helper_agl_probe,
@@ -371,7 +372,7 @@ static const struct iface_ops_s iface_ops_agl = {
  * This structure specifies the interface methods used by interfaces
  * configured as picmg.
  */
-static const struct iface_ops_s iface_ops_picmg = {
+static const struct iface_ops iface_ops_picmg = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_PICMG,
 	.enumerate	= __cvmx_helper_sgmii_enumerate,
 	.probe		= __cvmx_helper_sgmii_probe,
@@ -386,7 +387,7 @@ static const struct iface_ops_s iface_ops_picmg = {
  * This structure specifies the interface methods used by interfaces
  * configured as spi.
  */
-static const struct iface_ops_s iface_ops_spi = {
+static const struct iface_ops iface_ops_spi = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_SPI,
 	.enumerate	= __cvmx_helper_spi_enumerate,
 	.probe		= __cvmx_helper_spi_probe,
@@ -400,16 +401,198 @@ static const struct iface_ops_s iface_ops_spi = {
  * This structure specifies the interface methods used by interfaces
  * configured as loop.
  */
-static const struct iface_ops_s iface_ops_loop = {
+static const struct iface_ops iface_ops_loop = {
 	.mode		= CVMX_HELPER_INTERFACE_MODE_LOOP,
 	.enumerate	= __cvmx_helper_loop_enumerate,
 	.probe		= __cvmx_helper_loop_probe,
 };
 
-CVMX_SHARED const struct iface_ops_s *iface_ops[CVMX_HELPER_MAX_IFACE] = {
-	[0 ... CVMX_HELPER_MAX_IFACE - 1] = NULL
+CVMX_SHARED const struct iface_ops *iface_node_ops[CVMX_MAX_NODES][CVMX_HELPER_MAX_IFACE];
+#define iface_ops iface_node_ops[0]
+
+struct cvmx_iface {
+	int cvif_ipd_nports;
+	int cvif_has_fcs;	/* PKO fcs for this interface. */
+	enum cvmx_pko_padding cvif_padding;
+	cvmx_helper_link_info_t *cvif_ipd_port_link_info;
 };
 
+/*
+ * This has to be static as u-boot expects to probe an interface and
+ * gets the number of its ports.
+ */
+static CVMX_SHARED struct cvmx_iface cvmx_interfaces[CVMX_MAX_NODES][CVMX_HELPER_MAX_IFACE];
+
+
+
+int __cvmx_helper_get_num_ipd_ports(int xiface)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_iface *piface;
+
+	if (xi.interface >= cvmx_helper_get_number_of_interfaces())
+		return -1;
+
+	piface = &cvmx_interfaces[xi.node][xi.interface];
+	return piface->cvif_ipd_nports;
+}
+
+enum cvmx_pko_padding __cvmx_helper_get_pko_padding(int xiface)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_iface *piface;
+
+	if (xi.interface >= cvmx_helper_get_number_of_interfaces())
+		return CVMX_PKO_PADDING_NONE;
+
+	piface = &cvmx_interfaces[xi.node][xi.interface];
+	return piface->cvif_padding;
+}
+
+int __cvmx_helper_init_interface(int xiface, int num_ipd_ports,
+				 int has_fcs, enum cvmx_pko_padding pad)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_iface *piface;
+	cvmx_helper_link_info_t *p;
+	int i;
+	int sz;
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+	uint64_t addr;
+	char name[32];
+#endif
+
+	if (xi.interface >= cvmx_helper_get_number_of_interfaces())
+		return -1;
+
+	piface = &cvmx_interfaces[xi.node][xi.interface];
+	piface->cvif_ipd_nports = num_ipd_ports;
+	piface->cvif_padding = pad;
+
+	piface->cvif_has_fcs = has_fcs;
+
+	/*
+	 * allocate the per-ipd_port link_info structure
+	 */
+	sz = piface->cvif_ipd_nports * sizeof(cvmx_helper_link_info_t);
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+	if (sz == 0)
+		sz = sizeof(cvmx_helper_link_info_t);
+	piface->cvif_ipd_port_link_info = (cvmx_helper_link_info_t *) kmalloc(sz, GFP_KERNEL);
+	if (ZERO_OR_NULL_PTR(piface->cvif_ipd_port_link_info))
+		panic("Cannot allocate memory in __cvmx_helper_init_interface.");
+#else
+	snprintf(name, sizeof(name), "__int_%d_link_info", xi.interface);
+	addr = CAST64(cvmx_bootmem_alloc_named_range_once(sz, 0, 0, 128, name, NULL));
+	piface->cvif_ipd_port_link_info = (cvmx_helper_link_info_t *) __cvmx_phys_addr_to_ptr(addr, sz);
+#endif
+	if (!piface->cvif_ipd_port_link_info) {
+		if (sz != 0)
+			cvmx_dprintf("iface %d failed to alloc link info\n",
+				     xi.interface);
+		return -1;
+	}
+
+	/* Initialize them */
+	p = piface->cvif_ipd_port_link_info;
+
+	for (i = 0; i < piface->cvif_ipd_nports; i++) {
+		(*p).u64 = 0;
+		p++;
+	}
+	return 0;
+}
+
+
+/*
+ * Shut down the interfaces; free the resources.
+ * @INTERNAL
+ */
+void __cvmx_helper_shutdown_interfaces_node(unsigned int node)
+{
+	int i;
+	int nifaces;		/* number of interfaces */
+	struct cvmx_iface *piface;
+
+	nifaces = cvmx_helper_get_number_of_interfaces();
+	for (i = 0; i < nifaces; i++) {
+		piface = &cvmx_interfaces[node][i];
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+		if (piface->cvif_ipd_port_link_info)
+			kfree(piface->cvif_ipd_port_link_info);
+#elif defined(__U_BOOT__) && 0
+		if (piface->cvif_ipd_port_link_info) {
+			char name[32];
+			snprintf(name, sizeof(name),
+				 "__int_%d_link_info", i);
+			cvmx_bootmem_phy_named_block_free(name, 0);
+		}
+#else
+		/*
+		 * For SE apps, bootmem was meant to be allocated and never
+		 * freed.
+		 */
+#endif
+		piface->cvif_ipd_port_link_info = 0;
+	}
+}
+
+void __cvmx_helper_shutdown_interfaces(void)
+{
+	unsigned int node = cvmx_get_node_num();
+	__cvmx_helper_shutdown_interfaces_node(node);
+}
+
+int __cvmx_helper_set_link_info(int xiface, int index, cvmx_helper_link_info_t link_info)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_iface *piface;
+
+	if (xi.interface >= cvmx_helper_get_number_of_interfaces())
+		return -1;
+
+	piface = &cvmx_interfaces[xi.node][xi.interface];
+
+	if (piface->cvif_ipd_port_link_info) {
+		piface->cvif_ipd_port_link_info[index] = link_info;
+		return 0;
+	}
+
+	return -1;
+}
+
+cvmx_helper_link_info_t __cvmx_helper_get_link_info(int xiface, int port)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_iface *piface;
+	cvmx_helper_link_info_t err;
+
+	err.u64 = 0;
+
+	if (xi.interface >= cvmx_helper_get_number_of_interfaces())
+		return err;
+	piface = &cvmx_interfaces[xi.node][xi.interface];
+
+	if (piface->cvif_ipd_port_link_info)
+		return piface->cvif_ipd_port_link_info[port];
+
+	return err;
+}
+
+/**
+ * Returns if FCS is enabled for the specified interface and port
+ *
+ * @param interface - interface to check
+ *
+ * @return zero if FCS is not used, otherwise FCS is used.
+ */
+int __cvmx_helper_get_has_fcs(int xiface)
+{
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	return cvmx_interfaces[xi.node][xi.interface].cvif_has_fcs;
+}
+
+
 CVMX_SHARED uint64_t  cvmx_rgmii_backpressure_dis = 1;
 
 typedef int (*cvmx_export_config_t)(void);
@@ -552,54 +735,55 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn70xx(int interface)
  * @INTERNAL
  * Return interface mode for CN78XX.
  */
-static cvmx_helper_interface_mode_t __cvmx_get_mode_cn78xx(int interface)
+static cvmx_helper_interface_mode_t __cvmx_get_mode_cn78xx(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	/* SGMII/RXAUI/XAUI */
-	if (interface < 6) {
-		int qlm = cvmx_qlm_interface(interface);
+	if (xi.interface < 6) {
+		int qlm = cvmx_qlm_interface(xiface);
 		enum cvmx_qlm_mode qlm_mode;
 
 		if (qlm == -1) {
-			iface_ops[interface] = &iface_ops_dis;
-			return iface_ops[interface]->mode;
+			iface_node_ops[xi.node][xi.interface] = &iface_ops_dis;
+			return iface_node_ops[xi.node][xi.interface]->mode;
 		}
-		qlm_mode = cvmx_qlm_get_mode(qlm);
+		qlm_mode = cvmx_qlm_get_mode_cn78xx(xi.node, qlm);
 
 		if (qlm_mode == CVMX_QLM_MODE_SGMII)
-			iface_ops[interface] = &iface_ops_bgx_sgmii;
+			iface_node_ops[xi.node][xi.interface] = &iface_ops_bgx_sgmii;
 		else if (qlm_mode == CVMX_QLM_MODE_XAUI)
-			iface_ops[interface] = &iface_ops_bgx_xaui;
+			iface_node_ops[xi.node][xi.interface] = &iface_ops_bgx_xaui;
 		else if (qlm_mode == CVMX_QLM_MODE_XLAUI)
-			iface_ops[interface] = &iface_ops_bgx_xlaui;
+			iface_node_ops[xi.node][xi.interface] = &iface_ops_bgx_xlaui;
 		else if (qlm_mode == CVMX_QLM_MODE_XFI)
-			iface_ops[interface] = &iface_ops_bgx_xfi;
+			iface_node_ops[xi.node][xi.interface] = &iface_ops_bgx_xfi;
 		else if (qlm_mode == CVMX_QLM_MODE_RXAUI)
-			iface_ops[interface] = &iface_ops_bgx_rxaui;
+			iface_node_ops[xi.node][xi.interface] = &iface_ops_bgx_rxaui;
 		else
-			iface_ops[interface] = &iface_ops_dis;
-	} else if (interface < 8) {
+			iface_node_ops[xi.node][xi.interface] = &iface_ops_dis;
+	} else if (xi.interface < 8) {
 		enum cvmx_qlm_mode qlm_mode;
-		if (interface == 6) {
-			qlm_mode = cvmx_qlm_get_mode(4);
+		if (xi.interface == 6) {
+			qlm_mode = cvmx_qlm_get_mode_cn78xx(xi.node, 4);
 			if (qlm_mode == CVMX_QLM_MODE_ILK)
-				iface_ops[interface] = &iface_ops_ilk;
+				iface_node_ops[xi.node][xi.interface] = &iface_ops_ilk;
 			else
-				iface_ops[interface] = &iface_ops_dis;
-		} else if (interface == 7) {
-			qlm_mode = cvmx_qlm_get_mode(5);
+				iface_node_ops[xi.node][xi.interface] = &iface_ops_dis;
+		} else if (xi.interface == 7) {
+			qlm_mode = cvmx_qlm_get_mode_cn78xx(xi.node, 5);
 			if (qlm_mode == CVMX_QLM_MODE_ILK)
-				iface_ops[interface] = &iface_ops_ilk;
+				iface_node_ops[xi.node][xi.interface] = &iface_ops_ilk;
 			else
-				iface_ops[interface] = &iface_ops_dis;
+				iface_node_ops[xi.node][xi.interface] = &iface_ops_dis;
 		}
-	} else if (interface == 8) { /* DPI */
-		iface_ops[interface] = &iface_ops_npi;
-	} else if (interface == 9) { /* LOOP */
-		iface_ops[interface] = &iface_ops_loop;
+	} else if (xi.interface == 8) { /* DPI */
+		iface_node_ops[xi.node][xi.interface] = &iface_ops_npi;
+	} else if (xi.interface == 9) { /* LOOP */
+		iface_node_ops[xi.node][xi.interface] = &iface_ops_loop;
 	} else
-		iface_ops[interface] = &iface_ops_dis;
+		iface_node_ops[xi.node][xi.interface] = &iface_ops_dis;
 
-	return iface_ops[interface]->mode;
+	return iface_node_ops[xi.node][xi.interface]->mode;
 }
 
 /**
@@ -823,17 +1007,18 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_octeon2(int interface)
  * chip and configuration, this function returns an enumeration
  * of the type of packet I/O supported by an interface.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Mode of the interface. Unknown or unsupported interfaces return
  *         DISABLED.
  */
-cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int interface)
+cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int xiface)
 {
 	union cvmx_gmxx_inf_mode mode;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
-	if (interface < 0 ||
-	    interface >= cvmx_helper_get_number_of_interfaces())
+	if (xi.interface < 0 ||
+	    xi.interface >= cvmx_helper_get_number_of_interfaces())
 		return CVMX_HELPER_INTERFACE_MODE_DISABLED;
 
 	/*
@@ -841,37 +1026,37 @@ cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int interface)
 	 * simply return it. Otherwise, fall through the rest of the code to
 	 * determine the interface mode and cache it in iface_ops.
 	 */
-	if (iface_ops[interface] != NULL)
-		return iface_ops[interface]->mode;
+	if (iface_node_ops[xi.node][xi.interface] != NULL)
+		return iface_node_ops[xi.node][xi.interface]->mode;
 
 	/*
 	 * OCTEON III models
 	 */
 	if (OCTEON_IS_MODEL(OCTEON_CN70XX))
-		return __cvmx_get_mode_cn70xx(interface);
+		return __cvmx_get_mode_cn70xx(xi.interface);
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-		return __cvmx_get_mode_cn78xx(interface);
+		return __cvmx_get_mode_cn78xx(xiface);
 
 	/*
 	 * Octeon II models
 	 */
 	if (OCTEON_IS_OCTEON2())
-		return __cvmx_get_mode_octeon2(interface);
+		return __cvmx_get_mode_octeon2(xi.interface);
 
 	/*
 	 * Octeon and Octeon Plus models
 	 */
-	if (interface == 2)
-		iface_ops[interface] = &iface_ops_npi;
-	else if (interface == 3) {
+	if (xi.interface == 2)
+		iface_ops[xi.interface] = &iface_ops_npi;
+	else if (xi.interface == 3) {
 		if (OCTEON_IS_MODEL(OCTEON_CN56XX)
 		    || OCTEON_IS_MODEL(OCTEON_CN52XX))
-			iface_ops[interface] = &iface_ops_loop;
+			iface_ops[xi.interface] = &iface_ops_loop;
 		else
-			iface_ops[interface] = &iface_ops_dis;
+			iface_ops[xi.interface] = &iface_ops_dis;
 	}
-	else if (interface == 0 &&
+	else if (xi.interface == 0 &&
 	    cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_CN3005_EVB_HS5 &&
 	    cvmx_sysinfo_get()->board_rev_major == 1) {
 		/*
@@ -884,56 +1069,56 @@ cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int interface)
 		 * output of this function) there is no difference in
 		 * setup between GMII and RGMII modes.
 		 */
-		iface_ops[interface] = &iface_ops_gmii;
+		iface_ops[xi.interface] = &iface_ops_gmii;
 	}
-	else if ((interface == 1)
+	else if ((xi.interface == 1)
 	    && (OCTEON_IS_MODEL(OCTEON_CN31XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN30XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN50XX)
 		|| OCTEON_IS_MODEL(OCTEON_CN52XX)))
 		/* Interface 1 is always disabled on CN31XX and CN30XX */
-		iface_ops[interface] = &iface_ops_dis;
+		iface_ops[xi.interface] = &iface_ops_dis;
 	else {
-		mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(interface));
+		mode.u64 = cvmx_read_csr(CVMX_GMXX_INF_MODE(xi.interface));
 
 		if (OCTEON_IS_MODEL(OCTEON_CN56XX) ||
 		    OCTEON_IS_MODEL(OCTEON_CN52XX)) {
 			switch (mode.cn56xx.mode) {
 			case 0:
-				iface_ops[interface] = &iface_ops_dis;
+				iface_ops[xi.interface] = &iface_ops_dis;
 				break;
 
 			case 1:
-				iface_ops[interface] = &iface_ops_xaui;
+				iface_ops[xi.interface] = &iface_ops_xaui;
 				break;
 
 			case 2:
-				iface_ops[interface] = &iface_ops_sgmii;
+				iface_ops[xi.interface] = &iface_ops_sgmii;
 				break;
 
 			case 3:
-				iface_ops[interface] = &iface_ops_picmg;
+				iface_ops[xi.interface] = &iface_ops_picmg;
 				break;
 
 			default:
-				iface_ops[interface] = &iface_ops_dis;
+				iface_ops[xi.interface] = &iface_ops_dis;
 				break;
 			}
 		} else {
 			if (!mode.s.en)
-				iface_ops[interface] = &iface_ops_dis;
+				iface_ops[xi.interface] = &iface_ops_dis;
 			else if (mode.s.type) {
 				if (OCTEON_IS_MODEL(OCTEON_CN38XX) ||
 				    OCTEON_IS_MODEL(OCTEON_CN58XX))
-					iface_ops[interface] = &iface_ops_spi;
+					iface_ops[xi.interface] = &iface_ops_spi;
 				else
-					iface_ops[interface] = &iface_ops_gmii;
+					iface_ops[xi.interface] = &iface_ops_gmii;
 			} else
-				iface_ops[interface] = &iface_ops_rgmii;
+				iface_ops[xi.interface] = &iface_ops_rgmii;
 		}
 	}
 
-	return iface_ops[interface]->mode;
+	return iface_ops[xi.interface]->mode;
 }
 EXPORT_SYMBOL(cvmx_helper_interface_get_mode);
 
@@ -945,13 +1130,14 @@ EXPORT_SYMBOL(cvmx_helper_interface_get_mode);
  *
  * @return The number of ports on the interface, negative on failure
  */
-int cvmx_helper_interface_enumerate(int interface)
+int cvmx_helper_interface_enumerate(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int	result = 0;
 
-	cvmx_helper_interface_get_mode(interface);
-	if (iface_ops[interface]->enumerate)
-		result = iface_ops[interface]->enumerate(interface);
+	cvmx_helper_interface_get_mode(xiface);
+	if (iface_node_ops[xi.node][xi.interface]->enumerate)
+		result = iface_node_ops[xi.node][xi.interface]->enumerate(xiface);
 
 	return result;
 }
@@ -968,7 +1154,7 @@ EXPORT_SYMBOL(cvmx_helper_interface_enumerate);
  *
  * @return Zero on success, negative on failure
  */
-int cvmx_helper_interface_probe(int interface)
+int cvmx_helper_interface_probe(int xiface)
 {
 	/*
 	 * At this stage in the game we don't want packets to be
@@ -979,15 +1165,16 @@ int cvmx_helper_interface_probe(int interface)
 	int nports;
 	int has_fcs;
 	enum cvmx_pko_padding padding = CVMX_PKO_PADDING_NONE;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
 	nports = -1;
 	has_fcs = 0;
 
-	cvmx_helper_interface_get_mode(interface);
-	if (iface_ops[interface]->probe)
-		nports = iface_ops[interface]->probe(interface);
+	cvmx_helper_interface_get_mode(xiface);
+	if (iface_node_ops[xi.node][xi.interface]->probe)
+		nports = iface_node_ops[xi.node][xi.interface]->probe(xiface);
 
-	switch (iface_ops[interface]->mode) {
+	switch (iface_node_ops[xi.node][xi.interface]->mode) {
 		/* These types don't support ports to IPD/PKO */
 	case CVMX_HELPER_INTERFACE_MODE_DISABLED:
 	case CVMX_HELPER_INTERFACE_MODE_PCIE:
@@ -1053,8 +1240,8 @@ int cvmx_helper_interface_probe(int interface)
 	if (!octeon_has_feature(OCTEON_FEATURE_PKND))
 		has_fcs = 0;
 
-	nports = __cvmx_helper_board_interface_probe(interface, nports);
-	__cvmx_helper_init_interface(interface, nports, has_fcs, padding);
+	nports = __cvmx_helper_board_interface_probe(xiface, nports);
+	__cvmx_helper_init_interface(xiface, nports, has_fcs, padding);
 	/* Make sure all global variables propagate to other cores */
 	CVMX_SYNCWS;
 
@@ -1240,33 +1427,38 @@ int __cvmx_helper_backpressure_is_misaligned(void)
  *
  * @return Zero on success, negative on failure
  */
-static int __cvmx_helper_packet_hardware_enable(int interface)
+int __cvmx_helper_packet_hardware_enable(int xiface)
 {
 	int result = 0;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
-	cvmx_helper_interface_get_mode(interface);
-	if (iface_ops[interface]->enable)
-		result = iface_ops[interface]->enable(interface);
-	result |= __cvmx_helper_board_hardware_enable(interface);
+	cvmx_helper_interface_get_mode(xiface);
+	if (iface_node_ops[xi.node][xi.interface]->enable)
+		result = iface_node_ops[xi.node][xi.interface]->enable(xiface);
+	result |= __cvmx_helper_board_hardware_enable(xiface);
 	return result;
 }
 
+int cvmx_helper_ipd_and_packet_input_enable(void)
+{
+	return cvmx_helper_ipd_and_packet_input_enable_node(cvmx_get_node_num());
+}
+
 /**
  * Called after all internal packet IO paths are setup. This
  * function enables IPD/PIP and begins packet input and output.
  *
  * @return Zero on success, negative on failure
  */
-int cvmx_helper_ipd_and_packet_input_enable(void)
+int cvmx_helper_ipd_and_packet_input_enable_node(int node)
 {
 	int num_interfaces;
 	int interface;
 	int num_ports;
 
 	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		unsigned int node = cvmx_get_node_num();
-		cvmx_pki_parse_enable(node, 0);
-		cvmx_pki_enable(node);
+		cvmx_helper_pki_enable(node);
+
 	} else
 		/* Enable IPD */
 		cvmx_ipd_enable();
@@ -1278,9 +1470,10 @@ int cvmx_helper_ipd_and_packet_input_enable(void)
 	 */
 	num_interfaces = cvmx_helper_get_number_of_interfaces();
 	for (interface = 0; interface < num_interfaces; interface++) {
-		num_ports = cvmx_helper_ports_on_interface(interface);
+		int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
+		num_ports = cvmx_helper_ports_on_interface(xiface);
 		if (num_ports > 0)
-			__cvmx_helper_packet_hardware_enable(interface);
+			__cvmx_helper_packet_hardware_enable(xiface);
 	}
 
 	/* Finally enable PKO now that the entire path is up and running */
@@ -1304,7 +1497,7 @@ int cvmx_helper_ipd_and_packet_input_enable(void)
 		__cvmx_helper_errata_fix_ipd_ptr_alignment();
 	return 0;
 }
-EXPORT_SYMBOL(cvmx_helper_ipd_and_packet_input_enable);
+EXPORT_SYMBOL(cvmx_helper_ipd_and_packet_input_enable_node);
 
 /**
  * Initialize the PIP, IPD, and PKO hardware to support
@@ -1315,7 +1508,7 @@ EXPORT_SYMBOL(cvmx_helper_ipd_and_packet_input_enable);
  *
  * @return Zero on success, non-zero on failure
  */
-int cvmx_helper_initialize_packet_io_global(void)
+int cvmx_helper_initialize_packet_io_node(unsigned int node)
 {
 	int result = 0;
 	int interface;
@@ -1324,7 +1517,6 @@ int cvmx_helper_initialize_packet_io_global(void)
 	union cvmx_smix_en smix_en;
 #endif
 	const int num_interfaces = cvmx_helper_get_number_of_interfaces();
-	unsigned int node = cvmx_get_node_num();
 
 	/*
 	 * CN52XX pass 1: Due to a bug in 2nd order CDR, it needs to
@@ -1340,10 +1532,10 @@ int cvmx_helper_initialize_packet_io_global(void)
 	 */
 	if (OCTEON_IS_OCTEON2() || OCTEON_IS_OCTEON3()) {
 		union cvmx_l2c_ctl l2c_ctl;
-		l2c_ctl.u64 = cvmx_read_csr(CVMX_L2C_CTL);
+		l2c_ctl.u64 = cvmx_read_csr_node(node, CVMX_L2C_CTL);
 		l2c_ctl.s.rsp_arb_mode = 1;
 		l2c_ctl.s.xmc_arb_mode = 0;
-		cvmx_write_csr(CVMX_L2C_CTL, l2c_ctl.u64);
+		cvmx_write_csr_node(node, CVMX_L2C_CTL, l2c_ctl.u64);
 	} else {
 		l2c_cfg.u64 = cvmx_read_csr(CVMX_L2C_CFG);
 		l2c_cfg.s.lrf_arb_mode = 0;
@@ -1369,10 +1561,10 @@ int cvmx_helper_initialize_packet_io_global(void)
 
 		for (i = 0; i < smi_inf; i++) {
 			/* Make sure SMI/MDIO is enabled so we can query PHYs */
-			smix_en.u64 = cvmx_read_csr(CVMX_SMIX_EN(i));
+			smix_en.u64 = cvmx_read_csr_node(node, CVMX_SMIX_EN(i));
 			if (!smix_en.s.en) {
 				smix_en.s.en = 1;
-				cvmx_write_csr(CVMX_SMIX_EN(i), smix_en.u64);
+				cvmx_write_csr_node(node, CVMX_SMIX_EN(i), smix_en.u64);
 			}
 		}
 	}
@@ -1387,7 +1579,7 @@ int cvmx_helper_initialize_packet_io_global(void)
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		//FIXME- ILK needs this config data for now - must fix!
 		__cvmx_helper_init_port_config_data();
-		cvmx_helper_pko3_init_global();
+		cvmx_helper_pko3_init_global(node);
 	}
 	else {
 		cvmx_helper_pko_init();
@@ -1404,7 +1596,7 @@ int cvmx_helper_initialize_packet_io_global(void)
 
 		result |= __cvmx_helper_ipd_setup_interface(interface);/* vinita_to_do separate pki */
 		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
-			result |= cvmx_helper_pko3_init_interface(interface);
+		  result |= cvmx_helper_pko3_init_interface(cvmx_helper_node_interface_to_xiface(node, interface));
 		else
 			result |= __cvmx_helper_interface_setup_pko(interface);
 	}
@@ -1422,10 +1614,26 @@ int cvmx_helper_initialize_packet_io_global(void)
 		result |= (*cvmx_export_app_config)();
 	}
 
-	if (cvmx_ipd_cfg.ipd_enable)
-		result |= cvmx_helper_ipd_and_packet_input_enable();
+	if (cvmx_ipd_cfg.ipd_enable && cvmx_pki_dflt_init[node])
+		result |= cvmx_helper_ipd_and_packet_input_enable_node(node);
 	return result;
 }
+EXPORT_SYMBOL(cvmx_helper_initialize_packet_io_node);
+
+/**
+ * Initialize the PIP, IPD, and PKO hardware to support
+ * simple priority based queues for the ethernet ports. Each
+ * port is configured with a number of priority queues based
+ * on CVMX_PKO_QUEUES_PER_PORT_* where each queue is lower
+ * priority than the previous.
+ *
+ * @return Zero on success, non-zero on failure
+ */
+int cvmx_helper_initialize_packet_io_global(void)
+{
+	unsigned int node = cvmx_get_node_num();
+	return cvmx_helper_initialize_packet_io_node(node);
+}
 EXPORT_SYMBOL(cvmx_helper_initialize_packet_io_global);
 
 /**
@@ -1619,20 +1827,18 @@ static int __cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
 		}
 	}
 
-	/* Disable PKI */
-	cvmx_pki_disable(node);
-	/* Free all prefetched buffers */
-	__cvmx_pki_free_ptr(node);
-	/* Reset PKI */
-	cvmx_pki_reset(node);
+	cvmx_helper_pki_shutdown(node);
 
 	/* Shutdown PKO interfaces */
-	for (interface = 0; interface < num_interfaces; interface++)
-		cvmx_helper_pko3_shut_interface(interface);
+	for (interface = 0; interface < num_interfaces; interface++) {
+		int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
+		cvmx_helper_pko3_shut_interface(xiface);
+	}
 
 	/* Disable MAC address filtering */
 	for (interface = 0; interface < num_interfaces; interface++) {
-		switch (cvmx_helper_interface_get_mode(interface)) {
+		int xiface = cvmx_helper_node_interface_to_xiface(node, interface);
+		switch (cvmx_helper_interface_get_mode(xiface)) {
 		case CVMX_HELPER_INTERFACE_MODE_XAUI:
 		case CVMX_HELPER_INTERFACE_MODE_RXAUI:
 		case CVMX_HELPER_INTERFACE_MODE_XLAUI:
@@ -1641,20 +1847,20 @@ static int __cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
 		{
 			cvmx_bgxx_cmr_rx_adrx_cam_t cmr_rx_adr;
 			int index;
-			int num_ports = cvmx_helper_ports_on_interface(interface);
+			int num_ports = cvmx_helper_ports_on_interface(xiface);
 			if (num_ports > 4)
 				num_ports = 4;
 
 			for (index = 0; index < num_ports; index++) {
-				if (!cvmx_helper_is_port_valid(interface, index))
+				if (!cvmx_helper_is_port_valid(xiface, index))
 					continue;
 				cmr_rx_adr.u64 = 0;
 				cmr_rx_adr.s.id = index;
 				cmr_rx_adr.s.en = 0;
-				cvmx_write_csr(CVMX_BGXX_CMR_RX_ADRX_CAM(index * 8, interface),
+				cvmx_write_csr_node(node, CVMX_BGXX_CMR_RX_ADRX_CAM(index * 8, interface),
 					       cmr_rx_adr.u64);
 				/* Disable multicast and broadcast packets */
-				cvmx_write_csr(CVMX_BGXX_CMRX_RX_ADR_CTL(index, interface), 0);
+				cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ADR_CTL(index, interface), 0);
 			}
 			break;
 		}
@@ -1664,7 +1870,7 @@ static int __cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
 	}
 
 	/* Shutdown the PKO unit */
-	result = cvmx_helper_pko3_shutdown();
+	result = cvmx_helper_pko3_shutdown(node);
 
 	/* Release interface structures */
 	__cvmx_helper_shutdown_interfaces();
@@ -2061,22 +2267,6 @@ step2:
 
 EXPORT_SYMBOL(cvmx_helper_shutdown_packet_io_global);
 
-int cvmx_helper_shutdown_fpa_pools(int node)
-{
-	int result = 0;
-#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	uint64_t pool;
-
-	if (!octeon_has_feature(OCTEON_FEATURE_FPA3)) { /*vinita_to_do implement for 78xx */
-		for (pool = 0; pool < CVMX_FPA1_NUM_POOLS; pool++) {
-			if (cvmx_fpa_get_block_size(pool) > 0)
-				result |= cvmx_fpa_shutdown_pool(pool);
-		}
-	}
-#endif
-	return result;
-}
-
 /**
  * Does core local shutdown of packet io
  *
@@ -2146,8 +2336,9 @@ EXPORT_SYMBOL(cvmx_helper_link_autoconf);
 cvmx_helper_link_info_t cvmx_helper_link_get(int ipd_port)
 {
 	cvmx_helper_link_info_t result;
-	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(ipd_port);
 	int index = cvmx_helper_get_interface_index_num(ipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
 	/*
 	 * The default result will be a down link unless the code
@@ -2155,13 +2346,13 @@ cvmx_helper_link_info_t cvmx_helper_link_get(int ipd_port)
 	 */
 	result.u64 = 0;
 
-	if (interface == -1 || index == -1 ||
-	    index >= cvmx_helper_ports_on_interface(interface))
+	if (__cvmx_helper_xiface_is_null(xiface) || index == -1 ||
+	    index >= cvmx_helper_ports_on_interface(xiface))
 		return result;
 
-	cvmx_helper_interface_get_mode(interface);
-	if (iface_ops[interface]->link_get)
-		result = iface_ops[interface]->link_get(ipd_port);
+	cvmx_helper_interface_get_mode(xiface);
+	if (iface_node_ops[xi.node][xi.interface]->link_get)
+		result = iface_node_ops[xi.node][xi.interface]->link_get(ipd_port);
 
 	return result;
 }
@@ -2182,16 +2373,17 @@ EXPORT_SYMBOL(cvmx_helper_link_get);
 int cvmx_helper_link_set(int ipd_port, cvmx_helper_link_info_t link_info)
 {
 	int result = -1;
-	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(ipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int index = cvmx_helper_get_interface_index_num(ipd_port);
 
-	if (interface == -1 || index == -1 ||
-	    index >= cvmx_helper_ports_on_interface(interface))
+	if (__cvmx_helper_xiface_is_null(xiface) || index == -1 ||
+	    index >= cvmx_helper_ports_on_interface(xiface))
 		return -1;
 
-	cvmx_helper_interface_get_mode(interface);
-	if (iface_ops[interface]->link_set)
-		result = iface_ops[interface]->link_set(ipd_port, link_info);
+	cvmx_helper_interface_get_mode(xiface);
+	if (iface_node_ops[xi.node][xi.interface]->link_set)
+		result = iface_node_ops[xi.node][xi.interface]->link_set(ipd_port, link_info);
 
 	/*
 	 * Set the port_link_info here so that the link status is
@@ -2199,7 +2391,7 @@ int cvmx_helper_link_set(int ipd_port, cvmx_helper_link_info_t link_info)
 	 * don't change the value if link_set failed.
 	 */
 	if (result == 0)
-		__cvmx_helper_set_link_info(interface, index, link_info);
+		__cvmx_helper_set_link_info(xiface, index, link_info);
 	return result;
 }
 EXPORT_SYMBOL(cvmx_helper_link_set);
@@ -2221,17 +2413,18 @@ int cvmx_helper_configure_loopback(int ipd_port, int enable_internal,
 				   int enable_external)
 {
 	int result = -1;
-	int interface = cvmx_helper_get_interface_num(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(ipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int index = cvmx_helper_get_interface_index_num(ipd_port);
 
-	if (index >= cvmx_helper_ports_on_interface(interface))
+	if (index >= cvmx_helper_ports_on_interface(xiface))
 		return -1;
 
-	cvmx_helper_interface_get_mode(interface);
-	if (iface_ops[interface]->loopback)
-		result = iface_ops[interface]->loopback(ipd_port,
-							enable_internal,
-							enable_external);
+	cvmx_helper_interface_get_mode(xiface);
+	if (iface_node_ops[xi.node][xi.interface]->loopback)
+		result = iface_node_ops[xi.node][xi.interface]->loopback(ipd_port,
+									 enable_internal,
+									 enable_external);
 
 	return result;
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
index 7371b2d..ed103a0 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -74,10 +74,8 @@
  * for cn68, the default is {0xf, 0xf0}. to disable the 2nd ILK, set
  * cvmx_ilk_lane_mask[CVMX_NUM_ILK_INTF] = {0xff, 0x0} and
  * cvmx_ilk_chans[CVMX_NUM_ILK_INTF] = {8, 0}
- *
- * for cn78, the default is {0xff, 0xf000}.
  */
-CVMX_SHARED unsigned short cvmx_ilk_lane_mask[CVMX_NUM_ILK_INTF] = {0xf, 0xf0};
+CVMX_SHARED unsigned short cvmx_ilk_lane_mask[CVMX_NUM_ILK_INTF] = {0x000f, 0x00f0};
 
 CVMX_SHARED unsigned char cvmx_ilk_chans[CVMX_NUM_ILK_INTF] = {8,8};
 
@@ -89,48 +87,6 @@ static cvmx_ilk_intf_t cvmx_ilk_intf_cfg[CVMX_NUM_ILK_INTF];
 
 CVMX_SHARED cvmx_ilk_LA_mode_t cvmx_ilk_LA_mode[CVMX_NUM_ILK_INTF] = {{0, 0},
 									{0, 0}};
-
-void cvmx_ilk_config_set_LA_mode(int interface, int mode)
-{
-	if(interface >= CVMX_NUM_ILK_INTF || interface < 0)
-		cvmx_dprintf("ERROR: Invalid interface=%d in cvmx_ilk_config_set_LA_mode\n",
-			     interface);
-	else
-		cvmx_ilk_LA_mode[interface].ilk_LA_mode = mode;
-}
-
-void cvmx_ilk_config_set_LA_mode_cal(int interface, int mode)
-{
-	if(interface >= CVMX_NUM_ILK_INTF || interface < 0)
-		cvmx_dprintf("ERROR: Invalid interface=%d in cvmx_ilk_config_set_LA_mode_cal\n",
-			     interface);
-	else
-		cvmx_ilk_LA_mode[interface].ilk_LA_mode_cal_ena = mode;
-}
-
-void cvmx_ilk_config_set_lane_mask(int interface, unsigned char mask)
-{
-	if(interface >= CVMX_NUM_ILK_INTF || interface < 0)
-		cvmx_dprintf("ERROR: Invalid interface=%d in cvmx_ilk_set_lane_mask\n",
-			     interface);
-	else
-		cvmx_ilk_lane_mask[interface] = mask << (4*interface);
-}
-
-void cvmx_ilk_config_set_max_channels(int interface, unsigned char channels)
-{
-	if(interface >= CVMX_NUM_ILK_INTF || interface < 0) {
-		cvmx_dprintf("ERROR: Invalid interface=%d in cvmx_ilk_config_set_max_channels\n",
-			     interface);
-		return;
-	}
-	if(channels > CVMX_ILK_MAX_CHANS){
-		cvmx_dprintf("ERROR: Invalid channel=%d in cvmx_ilk_config_set_max_channels",channels);
-		return;
-	}
-	cvmx_ilk_chans[interface] = channels;
-}
-
 /**
  * User-overrideable callback function that returns whether or not an interface
  * should use look-aside mode.
@@ -193,7 +149,6 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	int res = -1;
 	int other_intf, this_qlm, other_qlm;
 	unsigned short uni_mask;
-	cvmx_mio_qlmx_cfg_t mio_qlmx_cfg, other_mio_qlmx_cfg;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 	cvmx_ilk_ser_cfg_t ilk_ser_cfg;
@@ -210,7 +165,7 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	/* check conflicts between 2 ilk interfaces. 1 lane can be assigned to 1
 	 * interface only */
 	other_intf = !interface;
-	if (cvmx_ilk_intf_cfg[other_intf].lane_en_mask & lane_mask) {
+	if (cvmx_ilk_lane_mask[other_intf] & lane_mask) {
 		cvmx_dprintf("ILK%d: %s: lane assignment conflict\n", interface, __func__);
 		return res;
 	}
@@ -219,26 +174,15 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	 * while interface 1 can have 4 lanes at most */
 	uni_mask = lane_mask >> (interface * 4);
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
-		if ((uni_mask != 0x1 && uni_mask != 0x3 && uni_mask != 0xf && uni_mask != 0xff) || (interface == 1 && lane_mask > 0xf0)) {
+		cvmx_mio_qlmx_cfg_t mio_qlmx_cfg, other_mio_qlmx_cfg;
+		if ((uni_mask != 0x1 && uni_mask != 0x3 && uni_mask != 0xf
+		     && uni_mask != 0xff)
+		    || (interface == 1 && lane_mask > 0xf0)) {
 			cvmx_dprintf("ILK%d: %s: incorrect lane mask: 0x%x \n", interface, __func__, uni_mask);
 			return res;
 		}
-	}
-	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		if ((uni_mask != 0x1 && uni_mask != 0x3 && uni_mask != 0xf &&
-		     uni_mask != 0xff && uni_mask != 0x100 &&
-		     uni_mask != 0x300 && uni_mask != 0xf00 &&
-		     uni_mask != 0xff0 && uni_mask != 0xfff) ||
-		     (interface == 0 && lane_mask > 0xff) ||
-		     (interface == 1 && lane_mask > 0xfff0)) {
-			cvmx_dprintf("ILK%d: %s: incorrect lane mask: 0x%x \n", interface, __func__, uni_mask);
-			return res;
-		}
-	}
-
-	/* check the availability of qlms. qlm_cfg = 001 means the chip is fused
-	 * to give this qlm to ilk */
-	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
+		/* check the availability of qlms. qlm_cfg = 001 means the chip is fused
+	 	* to give this qlm to ilk */
 		this_qlm = interface + CVMX_ILK_QLM_BASE();
 		other_qlm = other_intf + CVMX_ILK_QLM_BASE();
 		mio_qlmx_cfg.u64 = cvmx_read_csr(CVMX_MIO_QLMX_CFG(this_qlm));
@@ -247,59 +191,35 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 			cvmx_dprintf("ILK%d: %s: qlm unavailable\n", interface, __func__);
 			return res;
 		}
+		/* Has 8 lanes */
+		lane_mask &= 0xff;
 	}
+
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		uint8_t 		qlm, i;
-		cvmx_mio_qlmx_cfg_t 	mio_qlmx_cfg[4];
-		cvmx_gserx_cfg_t	cvmx_gserx_cfg;
-		cvmx_gserx_phy_ctl_t	cvmx_gserx_phy_ctl;
-
-		/*
-		 * QLM registers are not modelled yet. So hardcore the expected
-		 * value here. This must be removed once the hardware is ready
-		 * or the simulator has qlm support. TODO
-		 */
-		for (i = 0, qlm = CVMX_ILK_QLM_BASE(); i < 4; i++, qlm++)
-			mio_qlmx_cfg[i].s.qlm_cfg = 1;
-
-		if (interface == 0) {
-			if ((uni_mask <= 0xf && mio_qlmx_cfg[0].s.qlm_cfg != 1) ||
-			    (uni_mask == 0xff &&
-			     (mio_qlmx_cfg[0].s.qlm_cfg != 1 || mio_qlmx_cfg[1].s.qlm_cfg != 1))) {
-				cvmx_dprintf("ILK%d: %s: qlm unavailable\n", interface, __func__);
-				return res;
-			} 
-		}
-			      
-		if (interface == 1) {
-			if ((uni_mask >= 0x100 && uni_mask <= 0xf00 && mio_qlmx_cfg[3].s.qlm_cfg != 1) ||
-			    (uni_mask == 0xff0 && 
-			     (mio_qlmx_cfg[3].s.qlm_cfg != 1 || mio_qlmx_cfg[2].s.qlm_cfg != 1)) ||
-			    (uni_mask == 0xfff &&
-			     (mio_qlmx_cfg[3].s.qlm_cfg != 1 || mio_qlmx_cfg[2].s.qlm_cfg != 1 || mio_qlmx_cfg[1].s.qlm_cfg != 1))) {
-				cvmx_dprintf("ILK%d: %s: qlm unavailable\n", interface, __func__);
-				return res;
-			} 
+		int qlm;
+		unsigned short lane_mask_all = 0;
+
+		/* QLM 4 - QLM 7 can be configured for ILK. Get the lane mask
+ 		   of all the qlms that are configured for ilk */
+		for (qlm = 4; qlm < 8; qlm++) {
+			cvmx_gserx_cfg_t gserx_cfg;
+			cvmx_gserx_phy_ctl_t phy_ctl;
+
+			/* Make sure QLM is powered and out of reset */
+			phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
+			if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
+				continue;
+
+			/* Make sure QLM is in ILK mode */
+			gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
+			if (gserx_cfg.s.ila)
+				lane_mask_all |= ((1 << 4) - 1) << (4 * (qlm - 4));	
 		}
 
-		/*
-		 * Configure the GSER.
-		 * For now, we configured the minimum needed to work with the
-		 * simulator. TODO
-		 */
-		qlm = CVMX_ILK_QLM_BASE() + interface;
-		cvmx_gserx_phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
-		cvmx_gserx_phy_ctl.s.phy_pd = 0;
-		cvmx_gserx_phy_ctl.s.phy_reset = 1;
-		cvmx_write_csr(CVMX_GSERX_PHY_CTL(qlm), cvmx_gserx_phy_ctl.u64);
-
-		cvmx_gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
-		cvmx_gserx_cfg.s.ila = 1;
-		cvmx_write_csr(CVMX_GSERX_CFG(qlm), cvmx_gserx_cfg.u64);
-
-		cvmx_gserx_phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
-		cvmx_gserx_phy_ctl.s.phy_reset = 0;
-		cvmx_write_csr(CVMX_GSERX_PHY_CTL(qlm), cvmx_gserx_phy_ctl.u64);
+		if ((lane_mask_all & lane_mask) != lane_mask) {
+			cvmx_dprintf("ILK%d: %s: incorrect lane mask: 0x%x \n", interface, __func__, lane_mask);
+			return res;
+		}
 	}
 
 	/* power up the serdes */
@@ -318,6 +238,7 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 		ilk_ser_cfg.cn78xx.ser_rxpol_auto = 1;
 		ilk_ser_cfg.cn78xx.ser_rxpol = 0;
 		ilk_ser_cfg.cn78xx.ser_txpol = 0;
+		ilk_ser_cfg.cn78xx.ser_reset_n = 0xffff;
 	}
 	cvmx_write_csr(CVMX_ILK_SER_CFG, ilk_ser_cfg.u64);
 
@@ -395,7 +316,6 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	/* write to local cache. for lane speed, if interface 0 has 8 lanes,
 	 * assume both qlms have the same speed */
 	cvmx_ilk_intf_cfg[interface].intf_en = 1;
-	cvmx_ilk_intf_cfg[interface].lane_en_mask = lane_mask;
 	res = 0;
 
 	return res;
@@ -583,7 +503,7 @@ int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 		     cvmx_ilk_la_mode_enable_rx_calendar(interface))) {
 			for (i = 0; i < cal_depth; i++) {
 				__cvmx_ilk_write_rx_cal_entry(interface, i,
-							     pent[i].pipe_bpid);
+							      pent[i].pipe_bpid);
 			}
 		}
 
@@ -600,20 +520,23 @@ int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		cvmx_ilk_rxx_cal_entryx_t rxx_cal_entryx;
-
 		ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
-		ilk_rxx_cfg0.s.cal_depth = cal_depth;
+		/* 
+		 * Make sure cal_ena is 0 for programming the calender table,
+		 * as per Errata ILK-19398
+		 */
+		ilk_rxx_cfg0.s.cal_ena = 0;
 		cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 
 		for (i = 0; i < cal_depth; i++) {
-			rxx_cal_entryx.u64 = 0;
-			rxx_cal_entryx.s.ctl = pent->ent_ctrl;
-			rxx_cal_entryx.s.channel = pent->pipe_bpid;
-
-			cvmx_write_csr(CVMX_ILK_RXX_CAL_ENTRYX(i, interface), rxx_cal_entryx.u64);
-			pent++;
+				__cvmx_ilk_write_rx_cal_entry(interface, i,
+							      pent[i].pipe_bpid);
 		}
+
+		ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+		num_entries = 1 + cal_depth + (cal_depth - 1) / 15;
+		ilk_rxx_cfg0.s.cal_depth = num_entries;
+		cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 	}
 
 	return 0;
@@ -776,21 +699,25 @@ int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		cvmx_ilk_txx_cal_entryx_t txx_cal_entryx;
-
 		ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
-		ilk_txx_cfg0.s.cal_depth = cal_depth;
+		/* 
+		 * Make sure cal_ena is 0 for programming the calender table,
+		 * as per Errata ILK-19398
+		 */
+		ilk_txx_cfg0.s.cal_ena = 0;
 		cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 
 		for (i = 0; i < cal_depth; i++) {
-			txx_cal_entryx.u64 = 0;
-			txx_cal_entryx.s.ctl = pent->ent_ctrl;
-			txx_cal_entryx.s.channel = pent->pipe_bpid;
-
-			cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(i, interface),
-				       txx_cal_entryx.u64);
+			__cvmx_ilk_write_tx_cal_entry(interface, i,
+						      pent[i].pipe_bpid);
 			pent++;
 		}
+
+		ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+		num_entries = 1 + cal_depth + (cal_depth - 1) / 15;
+		/* cal_depth[2:0] needs to be zero, round up */
+		ilk_txx_cfg0.s.cal_depth = (num_entries + 7) & 0x1f8;
+		cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 	}
 
 	return 0;
@@ -1253,19 +1180,6 @@ int cvmx_ilk_get_intf_ena(int interface)
 }
 
 /**
- * Provide interface lane mask
- *
- * @param interface The identifier of the packet interface to disable. cn68xx
- *                  has 2 interfaces: ilk0 and ilk1.
- *
- * @return lane mask
- */
-unsigned char cvmx_ilk_get_intf_ln_msk(int interface)
-{
-	return cvmx_ilk_intf_cfg[interface].lane_en_mask;
-}
-
-/**
  * Provide channel info
  *
  * @param interface The identifier of the packet interface to disable. cn68xx
@@ -1293,12 +1207,15 @@ int cvmx_ilk_get_chan_info(int interface, unsigned char **chans, unsigned char *
  *
  * @return ILK header
  */
-cvmx_ilk_la_nsp_compact_hdr_t cvmx_ilk_enable_la_header(int port, int mode)
+cvmx_ilk_la_nsp_compact_hdr_t cvmx_ilk_enable_la_header(int ipd_port, int mode)
 {
 	cvmx_ilk_la_nsp_compact_hdr_t ilk_header;
 	cvmx_pip_prt_cfgx_t pip_config;
-	int interface = cvmx_helper_get_interface_num(port);
-	int ilk_interface = interface - CVMX_ILK_GBL_BASE();
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(ipd_port);
+	int xiface = cvmx_helper_get_interface_num(ipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	
+	int ilk_interface = xi.interface - CVMX_ILK_GBL_BASE();
 	int skip = 0;
 	int crc = 1;
 	int len_chk = 1;
@@ -1312,7 +1229,7 @@ cvmx_ilk_la_nsp_compact_hdr_t cvmx_ilk_enable_la_header(int port, int mode)
 
 	if (mode) {
 		ilk_header.s.la_mode = 1;
-		ilk_header.s.ilk_channel = port & 1;
+		ilk_header.s.ilk_channel = xp.port & 1;
 		skip = sizeof(ilk_header);
 		crc = 0;
 	}
@@ -1327,8 +1244,8 @@ cvmx_ilk_la_nsp_compact_hdr_t cvmx_ilk_enable_la_header(int port, int mode)
 	}
 
 	/* SKIP ILK header only for first 2 ports */
-	if ((port & 0x7) < 2) {
-		int pknd = cvmx_helper_get_pknd(interface, port & 1);
+	if ((xp.port & 0x7) < 2) {
+		int pknd = cvmx_helper_get_pknd(xiface, xp.port & 1);
 		int ipko_port;
 		cvmx_pko_reg_read_idx_t pko_reg;
 		cvmx_pko_mem_iport_ptrs_t pko_mem_iport;
@@ -1352,7 +1269,7 @@ cvmx_ilk_la_nsp_compact_hdr_t cvmx_ilk_enable_la_header(int port, int mode)
 		ipko_port = ilk_interface + 0x1c;
 
 		pko_reg.u64 = cvmx_read_csr(CVMX_PKO_REG_READ_IDX);
-		pko_reg.s.index = cvmx_helper_get_pko_port(interface, port & 1);
+		pko_reg.s.index = cvmx_helper_get_pko_port(xiface, xp.port & 1);
 		cvmx_write_csr(CVMX_PKO_REG_READ_IDX, pko_reg.u64);
 
 		pko_mem_iport.u64 = cvmx_read_csr(CVMX_PKO_MEM_IPORT_PTRS);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-l2c.c b/arch/mips/cavium-octeon/executive/cvmx-l2c.c
index 25c6d99..d2513d8 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-l2c.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-l2c.c
@@ -43,7 +43,7 @@
  * Implementation of the Level 2 Cache (L2C) control,
  * measurement, and debugging facilities.
  *
- * <hr>$Revision: 94422 $<hr>
+ * <hr>$Revision: 95721 $<hr>
  *
  */
 
@@ -1226,6 +1226,13 @@ void cvmx_l2c_set_big_size(uint64_t mem_size, int mode)
 			return;
 		}
 
+		/*
+  		 * The BIG/HOLE is logic is not supported in pass1 as per
+		 * Errata L2C-17736
+		 */
+		if (mode == 0 && OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X))
+			mode = 1;
+
 		big_ctl.u64 = 0;
 		big_ctl.s.maxdram = bits - 9;
 		big_ctl.cn61xx.disable = mode;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pcie.c b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
index 9058eea..b8a2712 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pcie.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 95179 $<hr>
+ * <hr>$Revision: 96178 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -893,19 +893,6 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int pcie_port)
 	cvmx_pciercx_cfg032_t pciercx_cfg032;
 	cvmx_pciercx_cfg448_t pciercx_cfg448;
 
-	/* For CN7XXX we must turn the PEM on */
-	if (OCTEON_IS_OCTEON3()) {
-		cvmx_pemx_on_t pemx_on;
-
-		pemx_on.u64 = cvmx_read_csr(CVMX_PEMX_ON(pcie_port));
-		pemx_on.s.pemon = 1;
-		cvmx_write_csr(CVMX_PEMX_ON(pcie_port), pemx_on.u64);
-		if (CVMX_WAIT_FOR_FIELD64(CVMX_PEMX_ON(pcie_port), cvmx_pemx_on_t, pemoor, ==, 1, 100000)) {
-			cvmx_dprintf("PCIe: Port %d PEM not on, skipping\n", pcie_port);
-			return -1;
-		}
-	}
-
 	/* Bring up the link */
 	pem_ctl_status.u64 = cvmx_read_csr(CVMX_PEMX_CTL_STATUS(pcie_port));
 	pem_ctl_status.s.lnk_enb = 1;
@@ -977,6 +964,9 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	int qlm = pcie_port;
 	int connected_pcie_reset = -1;
 	enum cvmx_qlm_mode mode = CVMX_QLM_MODE_DISABLED;
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
+	static void *fdt_addr = 0;
+#endif
 
 	if (pcie_port >= CVMX_PCIE_PORTS) {
 		//cvmx_dprintf("Invalid PCIe%d port\n", pcie_port);
@@ -1130,8 +1120,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	 * PEM1.
 	 */
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	static void *fdt_addr = 0;
-
+	/* Note that fdr_addr is 'static' */
 	if (fdt_addr == 0 && mode == CVMX_QLM_MODE_PCIE_2X1)
 		fdt_addr = __cvmx_phys_addr_to_ptr(cvmx_sysinfo_get()->fdt_addr,
 						   OCTEON_FDT_MAX_SIZE);
@@ -1234,6 +1223,19 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	/* Wait for PCIe reset to complete */
 	cvmx_wait_usec(1000);
 
+	/* For CN7XXX we must turn the PEM on */
+	if (OCTEON_IS_OCTEON3()) {
+		cvmx_pemx_on_t pemx_on;
+
+		pemx_on.u64 = cvmx_read_csr(CVMX_PEMX_ON(pcie_port));
+		pemx_on.s.pemon = 1;
+		cvmx_write_csr(CVMX_PEMX_ON(pcie_port), pemx_on.u64);
+		if (CVMX_WAIT_FOR_FIELD64(CVMX_PEMX_ON(pcie_port), cvmx_pemx_on_t, pemoor, ==, 1, 100000)) {
+			cvmx_dprintf("PCIe: Port %d PEM not on, skipping\n", pcie_port);
+			return -1;
+		}
+	}
+
 	/* Check and make sure PCIe came out of reset. If it doesn't the board
 	   probably hasn't wired the clocks up and the interface should be
 	   skipped */
@@ -1249,6 +1251,7 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 	if (pemx_bist_status.u64)
 		cvmx_dprintf("PCIe: BIST FAILED for port %d (0x%016llx)\n",
 			     pcie_port, CAST64(pemx_bist_status.u64));
+	/* BIST_STATUS2 is not present on 78xx */
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
 		pemx_bist_status2.u64 = 0;
 	else
@@ -1275,16 +1278,22 @@ static int __cvmx_pcie_rc_initialize_gen2(int pcie_port)
 		/* Some gen1 devices don't handle the gen 2 training correctly.
 		 * Disable gen2 and try again with only gen1
 		 */
-		cvmx_pciercx_cfg031_t pciercx_cfg031;
-		pciercx_cfg031.u32 = cvmx_pcie_cfgx_read(pcie_port,
-							 CVMX_PCIERCX_CFG031(pcie_port));
-		pciercx_cfg031.s.mls = 1;
-		cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG031(pcie_port),
-				     pciercx_cfg031.u32);
-		if (__cvmx_pcie_rc_initialize_link_gen2(pcie_port)) {
+		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 			cvmx_dprintf("PCIe: Link timeout on port %d, probably the slot is empty\n",
-				     pcie_port);
+				      pcie_port);
 			return -1;
+		} else {
+			cvmx_pciercx_cfg031_t pciercx_cfg031;
+			pciercx_cfg031.u32 = cvmx_pcie_cfgx_read(pcie_port,
+							 CVMX_PCIERCX_CFG031(pcie_port));
+			pciercx_cfg031.s.mls = 1;
+			cvmx_pcie_cfgx_write(pcie_port, CVMX_PCIERCX_CFG031(pcie_port),
+				     		pciercx_cfg031.u32);
+			if (__cvmx_pcie_rc_initialize_link_gen2(pcie_port)) {
+				cvmx_dprintf("PCIe: Link timeout on port %d, probably the slot is empty\n",
+				     		pcie_port);
+				return -1;
+			}
 		}
 	}
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
index 57a759b..8d2df9f 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
@@ -68,25 +68,28 @@
  *		-1 on alloc failure.
  *		-2 on resource already reserved.
  */
-int cvmx_pki_alloc_style(int node, int style)
+int cvmx_pki_style_alloc(int node, int style)
 {
-	if (cvmx_create_global_resource_range(CVMX_GR_TAG_STYLE(node), CVMX_PKI_NUM_INTERNAL_STYLES)) {
-		cvmx_dprintf("\nERROR: Failed to create styles global resource\n");
+	int rs;
+
+	if (cvmx_create_global_resource_range(CVMX_GR_TAG_STYLE(node), CVMX_PKI_NUM_INTERNAL_STYLE)) {
+		cvmx_dprintf("ERROR: Failed to create styles global resource\n");
 		return -1;
 	}
 	if (style >= 0) {
-		style = cvmx_reserve_global_resource_range(CVMX_GR_TAG_STYLE(node), style, style, 1);
-		if (style == -1) {
-			cvmx_dprintf("\nINFO: style %d is already reserved\n", (int)style);
+		rs = cvmx_reserve_global_resource_range(CVMX_GR_TAG_STYLE(node), style, style, 1);
+		if (rs == -1) {
+			cvmx_dprintf("INFO: style %d is already reserved\n", (int)style);
 			return CVMX_RESOURCE_ALREADY_RESERVED;
 		}
 	} else {
-		style = cvmx_allocate_global_resource_range(CVMX_GR_TAG_STYLE(node), style, 1, 1);
-		if (style == -1) {
-			cvmx_dprintf("ERROR: Failed to allocate style %d\n", (int)style);
+		rs = cvmx_allocate_global_resource_range(CVMX_GR_TAG_STYLE(node), style, 1, 1);
+		if (rs == -1) {
+			cvmx_dprintf("ERROR: Failed to allocate style\n");
 			return CVMX_RESOURCE_ALLOC_FAILED;
 		}
 	}
+	style = rs;
 	return style;
 }
 
@@ -96,10 +99,10 @@ int cvmx_pki_alloc_style(int node, int style)
  * @param style	 style to free
  * @return 	 0 on success, -1 on failure.
  */
-int cvmx_pki_free_style(int node, int style)
+int cvmx_pki_style_free(int node, int style)
 {
 	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_STYLE(node), style, 1) == -1) {
-		cvmx_dprintf("\nERROR Failed to release style %d", (int)style);
+		cvmx_dprintf("ERROR Failed to release style %d\n", (int)style);
 		return -1;
 	}
 	return 0;
@@ -116,10 +119,12 @@ int cvmx_pki_free_style(int node, int style)
  *			-1 on alloc failure.
  *			-2 on resource already reserved.
  */
-int cvmx_pki_alloc_cluster_group(int node, int cl_grp)
+int cvmx_pki_cluster_grp_alloc(int node, int cl_grp)
 {
+	int rs;
+
 	if (node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d", node);
+		cvmx_dprintf("Invalid node number %d\n", node);
 		return -1;
 	}
 	if (cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node), CVMX_PKI_NUM_CLUSTER_GROUP)) {
@@ -127,19 +132,19 @@ int cvmx_pki_alloc_cluster_group(int node, int cl_grp)
 		return -1;
 	}
 	if (cl_grp >= 0) {
-		cl_grp = cvmx_reserve_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node), 0, cl_grp, 1);
-		if (cl_grp == -1) {
-			cvmx_dprintf("\nINFO: cl_grp %d is already reserved\n", (int)cl_grp);
+		rs = cvmx_reserve_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node), 0, cl_grp, 1);
+		if (rs == -1) {
+			cvmx_dprintf("INFO: cl_grp %d is already reserved\n", (int)cl_grp);
 			return CVMX_RESOURCE_ALREADY_RESERVED;
 		}
-	}
-	else {
-		cl_grp = cvmx_allocate_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node), 0, 1, 1);
-		if (cl_grp == -1) {
-			cvmx_dprintf("Warning: Failed to alloc cluster grp %d\n", cl_grp);
+	} else {
+		rs = cvmx_allocate_global_resource_range(CVMX_GR_TAG_CLUSTER_GRP(node), 0, 1, 1);
+		if (rs == -1) {
+			cvmx_dprintf("Warning: Failed to alloc cluster grp\n");
 			return CVMX_RESOURCE_ALLOC_FAILED;
 		}
 	}
+	cl_grp = rs;
 	return cl_grp;
 }
 
@@ -152,10 +157,10 @@ int cvmx_pki_alloc_cluster_group(int node, int cl_grp)
  *			-1 on alloc failure.
  *			-2 on resource already reserved.
  */
-int cvmx_pki_free_cluster_group(int node, int cl_grp)
+int cvmx_pki_cluster_grp_free(int node, int cl_grp)
 {
 	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_CLUSTER_GRP(node), cl_grp, 1) == -1) {
-		cvmx_dprintf("\nERROR Failed to release cluster group %d", (int)cl_grp);
+		cvmx_dprintf("ERROR Failed to release cluster group %d\n", (int)cl_grp);
 		return -1;
 	}
 	return 0;
@@ -169,21 +174,21 @@ int cvmx_pki_free_cluster_group(int node, int cl_grp)
  *			allocate any available clusters.
  * @param num_clusters	number of clusters that will be allocated
  */
-int cvmx_pki_alloc_clusters(int node, int num_clusters, uint64_t *cluster_mask)
+int cvmx_pki_cluster_alloc(int node, int num_clusters, uint64_t *cluster_mask)
 {
 	int cluster = 0;
-	int clusters[CVMX_PKI_NUM_CLUSTERS];
+	int clusters[CVMX_PKI_NUM_CLUSTER];
 
 	if (node >= CVMX_MAX_NODES) {
-		cvmx_dprintf("Invalid node number %d", node);
+		cvmx_dprintf("Invalid node number %d\n", node);
 		return -1;
 	}
-	if (cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTERS(node), CVMX_PKI_NUM_CLUSTERS)) {
+	if (cvmx_create_global_resource_range(CVMX_GR_TAG_CLUSTERS(node), CVMX_PKI_NUM_CLUSTER)) {
 		cvmx_dprintf("Failed to create Clusters global resource\n");
 		return -1;
 	}
 	if (*cluster_mask > 0) {
-		while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		while (cluster < CVMX_PKI_NUM_CLUSTER) {
 			if (*cluster_mask & (0x01L << cluster)) {
 				if (cvmx_reserve_global_resource_range(CVMX_GR_TAG_CLUSTERS(node), 0, cluster, 1) == -1) {
 					cvmx_dprintf("ERROR: allocating cluster %d\n", cluster);
@@ -211,11 +216,11 @@ int cvmx_pki_alloc_clusters(int node, int num_clusters, uint64_t *cluster_mask)
  * @param cluster_mask  mask of clusters need freeing
  * @return 	 	0 on success or -1 on failure
  */
-int cvmx_pki_free_clusters(int node, uint64_t cluster_mask)
+int cvmx_pki_cluster_free(int node, uint64_t cluster_mask)
 {
 	int cluster = 0;
 	if (cluster_mask > 0) {
-		while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+		while (cluster < CVMX_PKI_NUM_CLUSTER) {
 			if (cluster_mask & (0x01L << cluster)) {
 				if (cvmx_free_global_resource_range_with_base(
 						CVMX_GR_TAG_CLUSTERS(node), cluster, 1) == -1) {
@@ -238,24 +243,25 @@ int cvmx_pki_free_clusters(int node, uint64_t cluster_mask)
  * @param cluster_mask  mask of clusters from which pcam entry is needed.
  * @return 	 	pcam entry of -1 on failure
  */
-int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_mask)
+int cvmx_pki_pcam_entry_alloc(int node, int index, int bank, uint64_t cluster_mask)
 {
+	int rs = 0;
 	uint64_t cluster = 0;
 
-	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+	while (cluster < CVMX_PKI_NUM_CLUSTER) {
 		if (cluster_mask & (0x01L << cluster)) {
 			if (cvmx_create_global_resource_range(CVMX_GR_TAG_PCAM(node, cluster, bank),
 				CVMX_PKI_TOTAL_PCAM_ENTRY)) {
-				cvmx_dprintf("\nFailed to create pki pcam global resource");
+				cvmx_dprintf("Failed to create pki pcam global resource\n");
 				return -1;
 			}
 			if (index >= 0)
-				index = cvmx_reserve_global_resource_range(CVMX_GR_TAG_PCAM(node, cluster, bank),
+				rs = cvmx_reserve_global_resource_range(CVMX_GR_TAG_PCAM(node, cluster, bank),
 						cluster, index, 1);
 			else
-				index = cvmx_allocate_global_resource_range(CVMX_GR_TAG_PCAM(node, cluster, bank),
+				rs = cvmx_allocate_global_resource_range(CVMX_GR_TAG_PCAM(node, cluster, bank),
 						cluster, 1, 1);
-			if (index == -1) {
+			if (rs == -1) {
 				cvmx_dprintf("Error:index %d not available in cluster %d bank %d",
 						(int)index, (int)cluster, bank);
 				return -1;
@@ -263,6 +269,7 @@ int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_ma
 			cluster++;
 		}
 	}
+	index = rs;
 	/*vinita to_do , implement cluster handle, for now assume
 	all clusters will have same base index*/
 	return index;
@@ -276,11 +283,11 @@ int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_ma
  * @param cluster_mask  mask of clusters from which pcam entry is freed.
  * @return 	 	0 on success OR -1 on failure
  */
-int cvmx_pki_pcam_free_entry(int node, int index, int bank, uint64_t cluster_mask)
+int cvmx_pki_pcam_entry_free(int node, int index, int bank, uint64_t cluster_mask)
 {
 	uint64_t cluster = 0;
 
-	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+	while (cluster < CVMX_PKI_NUM_CLUSTER) {
 		if (cluster_mask & (0x01L << cluster)) {
 			if (cvmx_free_global_resource_range_with_base (
 						CVMX_GR_TAG_PCAM(node, cluster, bank), index, 1) == -1) {
@@ -306,26 +313,29 @@ int cvmx_pki_pcam_free_entry(int node, int index, int bank, uint64_t cluster_mas
  *			-1 on alloc failure.
  *			-2 on resource already reserved.
  */
-int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count)
+int cvmx_pki_qpg_entry_alloc(int node, int base_offset, int count)
 {
+	int rs;
+
 	if (cvmx_create_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), CVMX_PKI_NUM_QPG_ENTRY)) {
 		cvmx_dprintf("\nERROR: Failed to create qpg_entry global resource\n");
 		return -1;
 	}
 	if (base_offset >= 0) {
-		base_offset = cvmx_reserve_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node),
+		rs = cvmx_reserve_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node),
 				base_offset, base_offset, count);
-		if (base_offset == -1) {
+		if (rs == -1) {
 			cvmx_dprintf("\nINFO: qpg entry %d is already reserved\n", (int)base_offset);
 			return CVMX_RESOURCE_ALREADY_RESERVED;
 		}
 	} else {
-		base_offset = cvmx_allocate_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), base_offset, count, 1);
-		if (base_offset == -1) {
-			cvmx_dprintf("ERROR: Failed to allocate qpg entry %d\n", (int)base_offset);
+		rs = cvmx_allocate_global_resource_range(CVMX_GR_TAG_QPG_ENTRY(node), base_offset, count, 1);
+		if (rs == -1) {
+			cvmx_dprintf("ERROR: Failed to allocate qpg entry\n");
 			return CVMX_RESOURCE_ALLOC_FAILED;
 		}
 	}
+	base_offset = rs;
 	return base_offset;
 }
 
@@ -339,8 +349,52 @@ int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count)
  *			from base offset.
  * @return 	 	qpg table base offset number on success, -1 on failure.
  */
-int cvmx_pki_free_qpg_entry(int node, int base_offset, int count)
+int cvmx_pki_qpg_entry_free(int node, int base_offset, int count)
 {
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_QPG_ENTRY(node), base_offset, count) == -1) {
+		cvmx_dprintf("\nERROR Failed to release qpg offset %d", (int)base_offset);
+		return -1;
+	}
 	return 0;
-	/*vinita_to_do*/
+}
+
+/**
+ * This function frees all the PKI software resources
+ * (clusters, styles, qpg_entry, pcam_entry etc) for the specified node
+ */
+void __cvmx_pki_global_rsrc_free(int node)
+{
+	int cnt;
+	int cluster, bank;
+
+	cnt = CVMX_PKI_NUM_CLUSTER_GROUP;
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_CLUSTER_GRP(node), 0, cnt) == -1) {
+		cvmx_dprintf("pki-rsrc:ERROR Failed to release all styles\n");
+	}
+
+	cnt = CVMX_PKI_NUM_CLUSTER;
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_CLUSTERS(node), 0, cnt) == -1) {
+		cvmx_dprintf("pki-rsrc:ERROR Failed to release all clusters\n");
+	}
+
+	cnt = CVMX_PKI_NUM_FINAL_STYLE;
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_STYLE(node), 0, cnt) == -1) {
+		cvmx_dprintf("pki-rsrc:ERROR Failed to release all styles\n");
+	}
+
+	cnt = CVMX_PKI_NUM_QPG_ENTRY;
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_QPG_ENTRY(node), 0, cnt) == -1) {
+		cvmx_dprintf("pki-rsrc:ERROR Failed to release all qpg entries\n");
+	}
+
+	cnt = CVMX_PKI_NUM_PCAM_ENTRY;
+	for (cluster = 0; cluster < CVMX_PKI_NUM_CLUSTER; cluster++) {
+		for (bank = 0; bank < CVMX_PKI_NUM_PCAM_BANK; bank++) {
+			if (cvmx_free_global_resource_range_with_base (
+				CVMX_GR_TAG_PCAM(node, cluster, bank), 0, cnt) == -1) {
+				cvmx_dprintf("pki-rsrc:ERROR Failed to release all pcan entries\n");
+			}
+		}
+	}
+
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki.c b/arch/mips/cavium-octeon/executive/cvmx-pki.c
index 6fcb3e1..4f94297 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki.c
@@ -179,7 +179,7 @@ void cvmx_pki_write_global_cfg(int node, struct cvmx_pki_global_config *gbl_cfg)
  *                            determine how the incoming packet is processed.
  * @param pkind_cfg	      struct conatining pkind configuration need to be written to hw
  */
-int cvmx_pki_write_pkind(int node, int pkind, struct cvmx_pki_pkind_config *pkind_cfg)
+int cvmx_pki_set_pkind_config(int node, int pkind, struct cvmx_pki_pkind_config *pkind_cfg)
 {
 	int cluster = 0;
 	uint64_t cluster_mask;
@@ -191,8 +191,8 @@ int cvmx_pki_write_pkind(int node, int pkind, struct cvmx_pki_pkind_config *pkin
 
 
 	if (pkind >= CVMX_PKI_NUM_PKIND || pkind_cfg->cluster_grp >= CVMX_PKI_NUM_CLUSTER_GROUP
-		  || pkind_cfg->initial_style >= CVMX_PKI_NUM_FINAL_STYLES) {
-		cvmx_dprintf("ERROR: Configuring PKIND pkind = %d cluster_group = %d style = %d",
+		  || pkind_cfg->initial_style >= CVMX_PKI_NUM_FINAL_STYLE) {
+		cvmx_dprintf("ERROR: Configuring PKIND pkind = %d cluster_group = %d style = %d\n",
 			     pkind, pkind_cfg->cluster_grp, pkind_cfg->initial_style);
 		return -1;
 	}
@@ -202,7 +202,7 @@ int cvmx_pki_write_pkind(int node, int pkind, struct cvmx_pki_pkind_config *pkin
 
 	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(pkind_cfg->cluster_grp));
 	cluster_mask = (uint64_t)pki_cl_grp.s.clusters;
-	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+	while (cluster < CVMX_PKI_NUM_CLUSTER) {
 		if (cluster_mask & (0x01L << cluster)) {
 			pkind_cfg_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(pkind, cluster));
 			pkind_cfg_style.s.pm = pkind_cfg->initial_parse_mode;
@@ -212,6 +212,7 @@ int cvmx_pki_write_pkind(int node, int pkind, struct cvmx_pki_pkind_config *pkin
 		cluster++;
 	}
 
+	cluster = 0;	/* XXX: LEO: prior loop sets it out of range ! */
 	pknd_cfg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pkind, cluster));
 	pknd_cfg_reg.s.fcs_pres = pkind_cfg->fcs_pres;
 	pknd_cfg_reg.s.inst_hdr = pkind_cfg->parse_en.inst_hdr;
@@ -240,7 +241,7 @@ void cvmx_pki_write_tag_config(int node, int style, uint64_t cluster_mask,
 	cvmx_pki_clx_stylex_alg_t style_alg_reg;
 	int cluster = 0;
 
-	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+	while (cluster < CVMX_PKI_NUM_CLUSTER) {
 		if (cluster_mask & (0x01L << cluster)) {
 			style_cfg2_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG2(style, cluster));
 			style_cfg2_reg.s.tag_src_lg = tag_cfg->tag_fields.layer_g_src;
@@ -282,7 +283,7 @@ void cvmx_pki_write_tag_config(int node, int style, uint64_t cluster_mask,
  * @param cluster_mask	      Mask of clusters to configure the style for.
  * @param style_cfg	      pointer to style config struct.
  */
-void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
+void cvmx_pki_set_style_config(int node, uint64_t style, uint64_t cluster_mask,
 			    struct cvmx_pki_style_config *style_cfg)
 {
 	cvmx_pki_clx_stylex_cfg_t style_cfg_reg;
@@ -291,7 +292,7 @@ void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
 	cvmx_pki_stylex_buf_t     style_buf_reg;
 	int cluster = 0;
 
-	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+	while (cluster < CVMX_PKI_NUM_CLUSTER) {
 		if (cluster_mask & (0x01L << cluster)) {
 			style_cfg_reg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_STYLEX_CFG(style, cluster));
 			style_cfg_reg.s.ip6_udp_opt = style_cfg->parm_cfg.ip6_udp_opt;
@@ -352,7 +353,6 @@ void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
 	cvmx_write_csr_node(node, CVMX_PKI_STYLEX_BUF(style), style_buf_reg.u64);
 }
 
-
 void cvmx_pki_get_tag_config(int node, int style, uint64_t cluster_mask,
 			       struct cvmx_pki_style_tag_cfg *tag_cfg)
 {
@@ -463,6 +463,7 @@ int cvmx_pki_get_pkind_config(int node, int pkind, struct cvmx_pki_pkind_config
 
 	pkind_clsel.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKINDX_ICGSEL(pkind));
 	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(pkind_clsel.s.icg));
+	pkind_cfg->cluster_grp = (uint8_t)pkind_clsel.s.icg;
 	cl_mask = (uint64_t)pki_cl_grp.s.clusters;
 	cluster = __builtin_ffsll(cl_mask) - 1;
 
@@ -493,40 +494,42 @@ int cvmx_pki_get_pkind_style(int node, int pkind)
 	return pkind_style.s.style;
 }
 
-void cvmx_pki_config_port(int node, int ipd_port, struct cvmx_pki_port_config *port_cfg)
+void cvmx_pki_config_port(int ipd_port, struct cvmx_pki_port_config *port_cfg)
 {
 	int interface, index, pknd;
 	int style, cl_mask;
 	cvmx_pki_icgx_cfg_t pki_cl_msk;
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(ipd_port);
 
 	/* get the pkind used by this ipd port */
 	interface = cvmx_helper_get_interface_num(ipd_port);
 	index = cvmx_helper_get_interface_index_num(ipd_port);
 	pknd = cvmx_helper_get_pknd(interface, index);
 
-	cvmx_pki_write_pkind(node, pknd, &port_cfg->pkind_cfg);
+	cvmx_pki_set_pkind_config(xp.node, pknd, &port_cfg->pkind_cfg);
 	style = port_cfg->pkind_cfg.initial_style;
-	pki_cl_msk.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(port_cfg->pkind_cfg.cluster_grp));
+	pki_cl_msk.u64 = cvmx_read_csr_node(xp.node, CVMX_PKI_ICGX_CFG(port_cfg->pkind_cfg.cluster_grp));
 	cl_mask = pki_cl_msk.s.clusters;
-	cvmx_pki_write_style(node, style, cl_mask, &port_cfg->style_cfg);
+	cvmx_pki_set_style_config(xp.node, style, cl_mask, &port_cfg->style_cfg);
 }
 
-void cvmx_pki_get_port_config(int node, int ipd_port, struct cvmx_pki_port_config *port_cfg)
+void cvmx_pki_get_port_config(int ipd_port, struct cvmx_pki_port_config *port_cfg)
 {
 	int interface, index, pknd;
 	int style, cl_mask;
 	cvmx_pki_icgx_cfg_t pki_cl_msk;
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(ipd_port);
 
 	/* get the pkind used by this ipd port */
 	interface = cvmx_helper_get_interface_num(ipd_port);
 	index = cvmx_helper_get_interface_index_num(ipd_port);
 	pknd = cvmx_helper_get_pknd(interface, index);
 
-	cvmx_pki_get_pkind_config(node, pknd, &port_cfg->pkind_cfg);
+	cvmx_pki_get_pkind_config(xp.node, pknd, &port_cfg->pkind_cfg);
 	style = port_cfg->pkind_cfg.initial_style;
-	pki_cl_msk.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(port_cfg->pkind_cfg.cluster_grp));
+	pki_cl_msk.u64 = cvmx_read_csr_node(xp.node, CVMX_PKI_ICGX_CFG(port_cfg->pkind_cfg.cluster_grp));
 	cl_mask = pki_cl_msk.s.clusters;
-	cvmx_pki_get_style_config(node, style, cl_mask, &port_cfg->style_cfg);
+	cvmx_pki_get_style_config(xp.node, style, cl_mask, &port_cfg->style_cfg);
 }
 
 /**
@@ -580,7 +583,7 @@ int cvmx_pki_pcam_write_entry(int node, int index, uint64_t cluster_mask,
 		return -1;
 	}
 	bank = (int)(input.field & 0x01);
-	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+	while (cluster < CVMX_PKI_NUM_CLUSTER) {
 		if (cluster_mask & (0x01L << cluster)) {
 			pcam_match.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PCAMX_MATCHX(cluster, bank, index));
 			pcam_match.s.data1 = input.data & input.data_mask;
@@ -673,7 +676,7 @@ int cvmx_pki_write_channel_bpid(int node, int channel, int bpid)
 {
 	cvmx_pki_chanx_cfg_t pki_chan_cfg;
 
-	if (channel >= CVMX_PKI_NUM_CHANNELS || bpid >= CVMX_PKI_NUM_BPID) {
+	if (channel >= CVMX_PKI_NUM_CHANNEL || bpid >= CVMX_PKI_NUM_BPID) {
 		cvmx_dprintf("ERROR: PKI config channel_bp channel = %d bpid = %d", channel, bpid);
 		return -1;
 	}
@@ -793,6 +796,31 @@ void cvmx_pki_set_max_frm_len(int node, int ipd_port, uint32_t max_size)
 	cvmx_write_csr_node(node, CVMX_PKI_FRM_LEN_CHKX(sel), frame_len.u64);
 }
 
+/**
+ * This function shows the qpg table entries,
+ * read directly from hardware.
+ * @param node    node number
+ */
+void cvmx_pki_show_qpg_entries(int node, uint16_t num_entry)
+{
+	int index;
+	cvmx_pki_qpg_tblx_t qpg_tbl;
+
+	if (num_entry > CVMX_PKI_NUM_QPG_ENTRY)
+		num_entry = CVMX_PKI_NUM_QPG_ENTRY;
+	for (index = 0; index < num_entry; index++) {
+		qpg_tbl.u64 = cvmx_read_csr_node(node, CVMX_PKI_QPG_TBLX(index));
+		cvmx_dprintf("\n%d	", index);
+		cvmx_dprintf("PADD %-16lu",
+			     (unsigned long)qpg_tbl.s.padd);
+		cvmx_dprintf("GRP_OK %-16lu",
+			     (unsigned long)qpg_tbl.s.grp_ok);
+		cvmx_dprintf("GRP_BAD %-16lu",
+			     (unsigned long)qpg_tbl.s.grp_bad);
+		cvmx_dprintf("LAURA %-16lu",
+			     (unsigned long)qpg_tbl.s.laura);
+	}
+}
 
 /**
  * This function shows the pcam table in raw format,
@@ -888,7 +916,7 @@ void cvmx_pki_show_pkind_attributes(int node, int pkind)
 	pki_cl_grp.u64 = cvmx_read_csr_node(node, CVMX_PKI_ICGX_CFG(pkind_clsel.s.icg));
 	cvmx_dprintf("cluster mask of the group:	0x%x\n", pki_cl_grp.s.clusters);
 
-	while (cluster < CVMX_PKI_NUM_CLUSTERS) {
+	while (cluster < CVMX_PKI_NUM_CLUSTER) {
 		if (pki_cl_grp.s.clusters & (0x01L << cluster)) {
 			/*vinita_to_do later modify in human readble format or now just print register value*/
 			pkind_cfg_style.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_STYLE(pkind, cluster));
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko-internal-ports-range.c b/arch/mips/cavium-octeon/executive/cvmx-pko-internal-ports-range.c
index 5238d3c..7e1b6f6 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko-internal-ports-range.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko-internal-ports-range.c
@@ -89,13 +89,14 @@ int __cvmx_pko_internal_ports_range_init(void)
 }
 
 
-int cvmx_pko_internal_ports_alloc(int interface, int port, uint64_t count)
+int cvmx_pko_internal_ports_alloc(int xiface, int port, uint64_t count)
 {
 	int ret_val = -1;
 	union interface_port inf_port;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
 	__cvmx_pko_internal_ports_range_init();
-	inf_port.s.interface = interface;
+	inf_port.s.interface = xi.interface;
 	inf_port.s.port = port;
 	ret_val = cvmx_allocate_global_resource_range(CVMX_GR_TAG_PKO_IPORTS, inf_port.u64, count, 1);
 	if (dbg)
@@ -103,8 +104,8 @@ int cvmx_pko_internal_ports_alloc(int interface, int port, uint64_t count)
 			     (int) port, ret_val, (int) count);
 	if (ret_val == -1)
 		return ret_val;
-	cvmx_cfg_port[interface][port].ccpp_pko_port_base = ret_val;
-	cvmx_cfg_port[interface][port].ccpp_pko_num_ports  = count;
+	cvmx_cfg_port[xi.node][xi.interface][port].ccpp_pko_port_base = ret_val;
+	cvmx_cfg_port[xi.node][xi.interface][port].ccpp_pko_num_ports  = count;
 	return 0;
 }
 
@@ -116,18 +117,19 @@ int cvmx_pko_internal_ports_alloc(int interface, int port, uint64_t count)
  * @return  0 on success
  *         -1 on failure
  */
-int cvmx_pko_internal_ports_free(int interface, int port)
+int cvmx_pko_internal_ports_free(int xiface, int port)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int ret_val = -1;
 
 	__cvmx_pko_internal_ports_range_init();
 	ret_val = cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_PKO_IPORTS,
-						    cvmx_cfg_port[interface][port].ccpp_pko_port_base,
-						    cvmx_cfg_port[interface][port].ccpp_pko_num_ports);
+						    cvmx_cfg_port[xi.node][xi.interface][port].ccpp_pko_port_base,
+						    cvmx_cfg_port[xi.node][xi.interface][port].ccpp_pko_num_ports);
 	if (ret_val != 0)
 		return ret_val;
-	cvmx_cfg_port[interface][port].ccpp_pko_port_base = CVMX_HELPER_CFG_INVALID_VALUE;
-	cvmx_cfg_port[interface][port].ccpp_pko_num_ports  =  CVMX_HELPER_CFG_INVALID_VALUE;
+	cvmx_cfg_port[xi.node][xi.interface][port].ccpp_pko_port_base = CVMX_HELPER_CFG_INVALID_VALUE;
+	cvmx_cfg_port[xi.node][xi.interface][port].ccpp_pko_num_ports  =  CVMX_HELPER_CFG_INVALID_VALUE;
 
 
 	return 0;
@@ -141,7 +143,7 @@ void cvmx_pko_internal_ports_range_free_all(void)
 	for(interface = 0; interface < CVMX_HELPER_MAX_IFACE; interface++)
 		for (port = 0; port < CVMX_HELPER_CFG_MAX_PORT_PER_IFACE;
 			     port++) {
-			if (cvmx_cfg_port[interface][port].ccpp_pko_port_base !=
+			if (cvmx_cfg_port[0][interface][port].ccpp_pko_port_base !=
 				    CVMX_HELPER_CFG_INVALID_VALUE)
 				cvmx_pko_internal_ports_free(interface, port);
 		}
@@ -158,11 +160,11 @@ void cvmx_pko_internal_ports_range_show(void)
 	for(interface = 0; interface < CVMX_HELPER_MAX_IFACE; interface++)
 		for (port = 0; port < CVMX_HELPER_CFG_MAX_PORT_PER_IFACE;
 				port ++) {
-			if (cvmx_cfg_port[interface][port].ccpp_pko_port_base !=
+			if (cvmx_cfg_port[0][interface][port].ccpp_pko_port_base !=
 				    CVMX_HELPER_CFG_INVALID_VALUE)
 				cvmx_dprintf("interface=%d port=%d port_base=%d port_cnt=%d\n",
 				     interface, port,
-				     (int)cvmx_cfg_port[interface][port].ccpp_pko_port_base,
-				     (int)cvmx_cfg_port[interface][port].ccpp_pko_num_ports);
+				     (int)cvmx_cfg_port[0][interface][port].ccpp_pko_port_base,
+				     (int)cvmx_cfg_port[0][interface][port].ccpp_pko_num_ports);
 		}
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko.c b/arch/mips/cavium-octeon/executive/cvmx-pko.c
index 5c74ca1..8860608 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko.c
@@ -1,4 +1,5 @@
-/***********************license start*************** * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+/***********************license start*************** 
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -633,12 +634,13 @@ cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue,
 		 */
 		for (queue = 0; queue < num_queues; queue++) {
 			/* Find first queue of static priority */
-			if (static_priority_base == -1 && priority[queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY)
+			int p_queue = queue % 16;
+			if (static_priority_base == -1 && priority[p_queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY)
 				static_priority_base = queue;
 			/* Find last queue of static priority */
 			if (static_priority_base != -1 &&
 			    static_priority_end == -1 &&
-			    priority[queue] != CVMX_PKO_QUEUE_STATIC_PRIORITY &&
+			    priority[p_queue] != CVMX_PKO_QUEUE_STATIC_PRIORITY &&
 			    queue)
 				static_priority_end = queue - 1;
 			else if (static_priority_base != -1 &&
@@ -655,7 +657,7 @@ cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue,
 			 */
 			if (static_priority_end != -1 &&
 			    (int)queue > static_priority_end &&
-			    priority[queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY) {
+			    priority[p_queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY) {
 				cvmx_dprintf("ERROR: cvmx_pko_config_port: Static priority queues aren't contiguous or don't start at base queue. q: %d, eq: %d\n",
 					     (int)queue, static_priority_end);
 				return CVMX_PKO_INVALID_PRIORITY;
@@ -677,6 +679,7 @@ cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue,
 
 	for (queue = 0; queue < num_queues; queue++) {
 		uint64_t *buf_ptr = NULL;
+		int p_queue = queue % 16;
 
 		config1.u64 = 0;
 		config1.s.idx3 = queue >> 3;
@@ -696,7 +699,7 @@ cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue,
 		 * to space the bits out evenly so the packet don't
 		 * get grouped up.
 		 */
-		switch ((int)priority[queue]) {
+		switch ((int)priority[p_queue]) {
 		case 0:
 			config.s.qos_mask = 0x00;
 			break;
@@ -728,7 +731,7 @@ cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue,
 			config.s.qos_mask = 0xff;
 			break;
 		default:
-			cvmx_dprintf("ERROR: cvmx_pko_config_port: Invalid priority %llu\n", (unsigned long long)priority[queue]);
+			cvmx_dprintf("ERROR: cvmx_pko_config_port: Invalid priority %llu\n", (unsigned long long)priority[p_queue]);
 			config.s.qos_mask = 0xff;
 			result_code = CVMX_PKO_INVALID_PRIORITY;
 			break;
@@ -809,10 +812,11 @@ static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port, int base_qu
 	 * static queue priority validation
 	 */
 	for (queue = 0; queue < num_queues; queue++) {
-		if (static_priority_base == -1 && priority[queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY)
+		int p_queue = queue % 16;
+		if (static_priority_base == -1 && priority[p_queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY)
 			static_priority_base = queue;
 
-		if (static_priority_base != -1 && static_priority_end == -1 && priority[queue] != CVMX_PKO_QUEUE_STATIC_PRIORITY && queue)
+		if (static_priority_base != -1 && static_priority_end == -1 && priority[p_queue] != CVMX_PKO_QUEUE_STATIC_PRIORITY && queue)
 			static_priority_end = queue - 1;
 		else if (static_priority_base != -1 && static_priority_end == -1 && queue == num_queues - 1)
 			static_priority_end = queue;	/* all queues are static priority */
@@ -822,7 +826,7 @@ static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port, int base_qu
 		 * Also catches some cases of static priorites not starting from
 		 * queue 0.
 		 */
-		if (static_priority_end != -1 && (int)queue > static_priority_end && priority[queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY) {
+		if (static_priority_end != -1 && (int)queue > static_priority_end && priority[p_queue] == CVMX_PKO_QUEUE_STATIC_PRIORITY) {
 			cvmx_dprintf("ERROR: %s: Static priority "
 			     "queues aren't contiguous or don't start at base queue. "
 		"q: %d, eq: %d\n", __func__, (int)queue, static_priority_end);
@@ -837,6 +841,7 @@ static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port, int base_qu
 	 * each queue
 	 */
 	for (queue = 0; queue < num_queues; queue++) {
+		int p_queue = queue % 8;
 		config.u64 = 0;
 		config.s.index = queue;
 		config.s.qid = base_queue + queue;
@@ -851,7 +856,7 @@ static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port, int base_qu
 		 * Try to space the bits out evenly so the packet
 		 * don't get grouped up.
 		 */
-		switch ((int)priority[queue]) {
+		switch ((int)priority[p_queue]) {
 		case 0:
 			config.s.qos_mask = 0x00;
 			break;
@@ -885,7 +890,7 @@ static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port, int base_qu
 		default:
 			cvmx_dprintf("ERROR: %s: " "Invalid priority %llu\n",
 				__func__,
-				     (unsigned long long)priority[queue]);
+				     (unsigned long long)priority[p_queue]);
 			config.s.qos_mask = 0xff;
 			break;
 		}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
index 952635f..6037fca8 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
@@ -49,6 +49,7 @@
 #include <asm/octeon/cvmx-pko3.h>
 #include <asm/octeon/cvmx-helper-pko3.h>
 #include <asm/octeon/cvmx-bootmem.h>
+#include <asm/octeon/cvmx-clock.h>
 #else
 #include "cvmx.h"
 #include "cvmx-pko3.h"
@@ -63,6 +64,21 @@
 
 static int debug = 0;
 
+struct cvmx_pko3_dq {
+#ifdef __BIG_ENDIAN_BITFIELD
+	unsigned	
+			dq_count :6,	/* Number of descriptor queues */
+			dq_base :10;	/* Descriptor queue start number */
+#define	CVMX_PKO3_SWIZZLE_IPD	0x0
+#else
+	unsigned	
+			dq_base :10,	/* Descriptor queue start number */
+			dq_count :6;	/* Number of descriptor queues */
+
+#define	CVMX_PKO3_SWIZZLE_IPD	0x3
+#endif
+};
+
 /*
  * @INTERNAL
  * Descriptor Queue to IPD port mapping table.
@@ -71,7 +87,51 @@ static int debug = 0;
  * of a global named block which has 2^12 entries per each
  * possible node.
  */
-struct cvmx_pko3_dq_s *__cvmx_pko3_dq_table = NULL;
+struct cvmx_pko3_dq *__cvmx_pko3_dq_table;
+
+int cvmx_pko3_get_queue_base(int ipd_port)
+{
+	struct cvmx_pko3_dq *dq_table;
+	int ret = -1;
+	unsigned i;
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(ipd_port);
+
+	/* get per-node table */
+	if(__cvmx_pko3_dq_table == NULL)
+		__cvmx_pko3_dq_table_setup();
+
+	i = CVMX_PKO3_SWIZZLE_IPD ^ xp.port;
+
+	/* get per-node table */
+	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * xp.node;
+
+	if(dq_table[i].dq_count > 0)
+		ret = cvmx_helper_node_to_ipd_port(xp.node, dq_table[i].dq_base);
+
+	return ret;
+}
+
+int cvmx_pko3_get_queue_num(int ipd_port)
+{
+	struct cvmx_pko3_dq *dq_table;
+	int ret = -1;
+	unsigned i;
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(ipd_port);
+
+	/* get per-node table */
+	if(__cvmx_pko3_dq_table == NULL)
+		__cvmx_pko3_dq_table_setup();
+
+	i = CVMX_PKO3_SWIZZLE_IPD ^ xp.port;
+
+	/* get per-node table */
+	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * xp.node;
+
+	if(dq_table[i].dq_count > 0)
+		ret = dq_table[i].dq_count;
+
+	return ret;
+}
 
 /**
  * @INTERNAL
@@ -80,9 +140,7 @@ struct cvmx_pko3_dq_s *__cvmx_pko3_dq_table = NULL;
  */
 static void __cvmx_pko3_dq_table_init(void *ptr)
 {
-	unsigned size =
-		sizeof(struct cvmx_pko3_dq_s) *
-		CVMX_PKO3_IPD_NUM_MAX * CVMX_MAX_NODES;
+	unsigned size = sizeof(struct cvmx_pko3_dq) * CVMX_PKO3_IPD_NUM_MAX * CVMX_MAX_NODES;
 
 	memset(ptr, 0, size);
 }
@@ -103,10 +161,9 @@ int __cvmx_pko3_dq_table_setup(void)
 
 	ptr = cvmx_bootmem_alloc_named_range_once(
 		/* size */
-		sizeof(struct cvmx_pko3_dq_s) *
-			CVMX_PKO3_IPD_NUM_MAX * CVMX_MAX_NODES,
+		sizeof(struct cvmx_pko3_dq) * CVMX_PKO3_IPD_NUM_MAX * CVMX_MAX_NODES,
 		/* min_addr, max_addr, align */
-		0ull, 0ull, sizeof(struct cvmx_pko3_dq_s),
+		0ull, 0ull, sizeof(struct cvmx_pko3_dq),
 		/* name */
 		"cvmx_pko3_global_dq_table",
 		__cvmx_pko3_dq_table_init);
@@ -142,21 +199,31 @@ int __cvmx_pko3_dq_table_setup(void)
  *
  * @returns 0 on success, -1 on failure.
  */
-int __cvmx_pko3_ipd_dq_register(unsigned interface, unsigned port,
+int __cvmx_pko3_ipd_dq_register(int xiface, int index,
 		unsigned dq_base, unsigned dq_count)
 {
-	struct cvmx_pko3_dq_s *dq_table;
-	uint16_t ipd_port = cvmx_helper_get_ipd_port(interface, port);
-	unsigned node = cvmx_get_node_num();
+	struct cvmx_pko3_dq *dq_table;
+	uint16_t ipd_port;
 	unsigned i;
+	struct cvmx_xport xp;
+
+        if(__cvmx_helper_xiface_is_null(xiface))
+		ipd_port = CVMX_PKO3_IPD_PORT_NULL;
+	else
+		ipd_port = cvmx_helper_get_ipd_port(xiface, index);
 
-	i = CVMX_PKO3_SWIZZLE_IPD ^ (ipd_port & (CVMX_PKO3_IPD_NUM_MAX-1));
+	xp = cvmx_helper_ipd_port_to_xport(ipd_port);
+	i = CVMX_PKO3_SWIZZLE_IPD ^ xp.port;
 
 	/* get per-node table */
 	if(__cvmx_pko3_dq_table == NULL)
 		__cvmx_pko3_dq_table_setup();
 
-	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * node;
+	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * xp.node;
+
+	if(debug)
+		cvmx_dprintf("%s: ipd=%#x ix=%#x dq %u cnt %u\n",
+			__FUNCTION__, ipd_port, i, dq_base, dq_count);
 
 	/* Check the IPD port has not already been configured */
 	if(dq_table[i].dq_count > 0 ) {
@@ -169,10 +236,6 @@ int __cvmx_pko3_ipd_dq_register(unsigned interface, unsigned port,
 	dq_table[i].dq_base = dq_base;
 	dq_table[i].dq_count = dq_count;
 
-	if(debug)
-		cvmx_dprintf("%s: ipd=%#x dq %u cnt %u\n",
-			__FUNCTION__, ipd_port, dq_base, dq_count);
-
 	return 0;
 }
 
@@ -181,27 +244,39 @@ int __cvmx_pko3_ipd_dq_register(unsigned interface, unsigned port,
  *
  * Unregister DQs associated with CHAN_E (IPD port)
  */
-int __cvmx_pko3_ipd_dq_unregister(unsigned interface, unsigned port)
+int __cvmx_pko3_ipd_dq_unregister(int xiface, int index)
 {
-	struct cvmx_pko3_dq_s *dq_table;
-	uint16_t ipd_port = cvmx_helper_get_ipd_port(interface, port);
-	unsigned node = cvmx_get_node_num();
+	struct cvmx_pko3_dq *dq_table;
+	uint16_t ipd_port;
 	unsigned i;
+	struct cvmx_xport xp;
+
+        if(__cvmx_helper_xiface_is_null(xiface))
+		ipd_port = CVMX_PKO3_IPD_PORT_NULL;
+	else
+		ipd_port = cvmx_helper_get_ipd_port(xiface, index);
 
-	i = CVMX_PKO3_SWIZZLE_IPD ^ (ipd_port & (CVMX_PKO3_IPD_NUM_MAX-1));
+	xp = cvmx_helper_ipd_port_to_xport(ipd_port);
+	i = CVMX_PKO3_SWIZZLE_IPD ^ xp.port;
 
 	/* get per-node table */
 	if(__cvmx_pko3_dq_table == NULL)
 		__cvmx_pko3_dq_table_setup();
 
 	/* get per-node table */
-	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * node;
+	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * xp.node;
+
+	if (dq_table[i].dq_count == 0) {
+		cvmx_dprintf("%s:ipd=%#x already released\n",
+			__FUNCTION__, ipd_port);
+		return -1;
+	}
 
 	if(debug)
 		cvmx_dprintf("%s:ipd=%#x release dq %u cnt %u\n",
-			__FUNCTION__, ipd_port, 
-			dq_table[i].dq_base, 
-			dq_table[i].dq_count);
+			     __FUNCTION__, ipd_port, 
+			     dq_table[i].dq_base, 
+			     dq_table[i].dq_count);
 
 	dq_table[i].dq_count = 0;
 
@@ -602,11 +677,10 @@ static const struct {
  *
  * Note: this function supports the configuration of node-local unit.
  */
-int cvmx_pko3_pq_config_children(unsigned mac_num, unsigned child_base,
+int cvmx_pko3_pq_config_children(unsigned node, unsigned mac_num,
+			 unsigned child_base,
 			unsigned child_count, int stat_prio_count)
 {
-	unsigned node = cvmx_get_node_num();
-
 	unsigned pq_num;
 	unsigned rr_quantum, rr_count;
 	unsigned child, prio, rr_prio;
@@ -666,7 +740,6 @@ int cvmx_pko3_pq_config_children(unsigned mac_num, unsigned child_base,
 		else if (stat_prio_count > 0)
 			rr_quantum -= CVMX_PKO3_RR_QUANTUM_MIN;
 	} /* for child */
-
 	return 0;
 }
 
@@ -698,11 +771,10 @@ int cvmx_pko3_pq_config_children(unsigned mac_num, unsigned child_base,
  *
  * Note: this function supports the configuration of node-local unit.
  */
-int cvmx_pko3_sq_config_children(unsigned parent_level,
+int cvmx_pko3_sq_config_children(unsigned int node, unsigned parent_level,
 			unsigned parent_queue, unsigned child_base,
 			unsigned child_count, int stat_prio_count)
 {
-	unsigned node = cvmx_get_node_num();
 	unsigned child_level;
 	unsigned rr_quantum, rr_count;
 	unsigned child, prio, rr_prio;
@@ -750,7 +822,7 @@ int cvmx_pko3_sq_config_children(unsigned parent_level,
 		cvmx_dprintf("%s: Parent L%u/SQ%02u child_base %u rr_pri %u\n",
 		__FUNCTION__, parent_level, parent_queue, child_base, rr_prio);
 
-	// Parent is configured with child
+	/* Parent is configured with child */
 
 	for(child = child_base; child < (child_base + child_count); child ++) {
 		if (debug)
@@ -773,3 +845,148 @@ int cvmx_pko3_sq_config_children(unsigned parent_level,
 
 	return 0;
 }
+
+/**
+ * Configure per-port CIR rate limit parameters
+ *
+ * This function configures rate limit at the L1/PQ level,
+ * i.e. for an entire MAC or physical port.
+ *
+ * @param node The OCI node where the target port is located
+ * @param pq_num The L1/PQ queue number for this setting
+ * @param rate_kbips The desired throughput in kilo-bits-per-second
+ * @param burst_size The size of a burst in bytes above 'rate_kbips' allowed
+ *
+ * @return Returns zero if both settings applied within allowed tolerance,
+ * otherwise the error is returned in parts-per-million.
+ * 'rate_bps" error is e negative number, otherwise 'birst_rate' error
+ * is returned as a positive integer.
+ */
+int cvmx_pko3_port_cir_set(unsigned node, unsigned pq_num,
+		unsigned long rate_kbips, unsigned burst_bytes)
+{
+	const unsigned time_wheel_turn = 96; /* S-Clock cycles */
+	const unsigned max_exp = 12;	/* maximum exponent */
+	const unsigned tock_bytes_exp = 3;	/* rate in 8-byte words */
+	unsigned long rate_tocks, burst_tocks;
+	unsigned long long burst_v, rate_v;
+	uint64_t s_clk;
+	unsigned long tclk, min_burst;
+	unsigned div_exp, mant, exp;
+	cvmx_pko_l1_sqx_cir_t sqx_cir;
+	uint64_t tmp, fmax;
+
+	if (debug)
+		cvmx_dprintf("%s: pq=%u rate=%lu kbps, burst=%u bytes\n",
+			__func__, pq_num, rate_kbips, burst_bytes);
+
+	sqx_cir.u64 = 0;
+
+	/* When rate == 0, disable the shaper */
+	if( rate_kbips == 0ULL) {
+		/* Disable shaping */
+		sqx_cir.s.enable = 0;
+		cvmx_write_csr_node(node,
+			CVMX_PKO_L1_SQX_CIR(pq_num), sqx_cir.u64);
+		return 0;
+	}
+
+	/* Convert API args into tocks: PSE native units */
+	rate_tocks = (1000ULL * rate_kbips) >> (3 + tock_bytes_exp);
+	burst_tocks = burst_bytes >> tock_bytes_exp;
+
+	/* Compute time-wheel frequency */
+	s_clk = cvmx_clock_get_rate_node(node, CVMX_CLOCK_SCLK);
+	tclk = s_clk / time_wheel_turn;
+
+	/* Compute largest short-float that fits in register fields */
+	fmax = CVMX_SHOFT_TO_U64((1<<CVMX_SHOFT_MANT_BITS)-1, max_exp);
+
+	/* Find the biggest divider that has the short float fit */
+	for (div_exp = 0; div_exp <= max_exp; div_exp++) {
+		tmp = (rate_tocks << div_exp) / tclk;
+		if (tmp > fmax) {
+			div_exp --;
+			break;
+		}
+	}
+
+	/* XXX-
+	 * Assu,ing the BURST field is the actual satiration value
+	 * for the rate accumulator, while the argument is the 
+	 * delta burst amount to add to the accumulator value
+	 * required to maintain the requested rate.
+	 */
+
+	/* Find the minimum burst size needed for rate */
+	min_burst = (rate_tocks << div_exp) / tclk;
+
+	/* Apply the minimum */
+	burst_tocks += min_burst;
+
+	/* Store common divider */
+	sqx_cir.s.rate_divider_exponent = div_exp;
+
+	/* Calculate the CIR short float */
+	tmp = (rate_tocks << (div_exp + 8)) / tclk;
+	CVMX_SHOFT_FROM_U64(tmp, mant, exp);
+	sqx_cir.s.rate_mantissa = mant;
+	sqx_cir.s.rate_exponent = exp - 8;
+
+	/* Calculate the BURST short float */
+	tmp = (burst_tocks << (8));
+	CVMX_SHOFT_FROM_U64(tmp, mant, exp);
+	sqx_cir.s.burst_mantissa = mant;
+	sqx_cir.s.burst_exponent = exp - 8;
+	/* Enable shaping */
+	sqx_cir.s.enable = 1;
+
+	/* Apply new settings */
+	cvmx_write_csr_node(node, CVMX_PKO_L1_SQX_CIR(pq_num), sqx_cir.u64);
+
+	if (debug)
+		cvmx_dprintf("%s: CIR_RATE=%llu BURST=%llu DIV_EXP=%d\n",
+			__func__,
+			CVMX_SHOFT_TO_U64(sqx_cir.s.rate_mantissa,
+					sqx_cir.s.rate_exponent),
+			CVMX_SHOFT_TO_U64(sqx_cir.s.burst_mantissa,
+					sqx_cir.s.burst_exponent),
+			div_exp);
+
+	/* Validate the resulting rate */
+	tmp = CVMX_SHOFT_TO_U64(sqx_cir.s.rate_mantissa,
+				8 + sqx_cir.s.rate_exponent),
+	rate_v =  ((s_clk / time_wheel_turn) * tmp) >> (div_exp + 8);
+	/* Convert to kbips for comaring with argument */
+	rate_v = (rate_v << (3+tock_bytes_exp)) /1000ULL;
+
+	tmp = CVMX_SHOFT_TO_U64(sqx_cir.s.burst_mantissa,
+				8 + sqx_cir.s.burst_exponent),
+	burst_v = tmp >> 8;
+	/* Convert in additional bytes as in argument */
+	burst_v = (burst_v - min_burst) << tock_bytes_exp;
+	
+	if (debug)
+		cvmx_dprintf("%s: result rate=%'llu kbips burst=%llu bytes\n",
+			__func__,rate_v, burst_v);
+	
+	/* Compute error in parts-per-million */
+	rate_v = abs(rate_v - rate_kbips);
+	burst_v = abs(burst_v - burst_bytes);
+
+	rate_v = rate_v * 1000000 / rate_kbips;
+	burst_v = burst_v * 1000000 / burst_bytes;
+
+	if (debug)
+		cvmx_dprintf("%s: error rate=%llu burst=%llu ppm\n",
+			__func__, rate_v, burst_v);
+
+	/* Allow ~ 100 ppm error for CIR, and 1% for BURST */
+	if (rate_v > 100)
+		return -rate_v;
+	if (burst_v > 1000)
+		return burst_v;
+
+	return 0;
+}
+
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
index 6849f9a..6dcb1d5 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
@@ -39,6 +39,7 @@
 
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/module.h>
+#include <linux/errno.h>
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-fpa3.h>
 #include <asm/octeon/cvmx-clock.h>
@@ -49,11 +50,18 @@
 #include "cvmx.h"
 #include "cvmx-hwpko.h"	/* For legacy support */
 #include "cvmx-pko3.h"
-#include "cvmx-fpa3.h"
+#include "cvmx-fpa.h"
 #include "cvmx-helper-pko3.h"
+#include <errno.h>
 #endif
 
+
 static const int debug = 0;
+#ifdef	__BIG_ENDIAN_BITFIELD
+static const bool __native_le = 0;
+#else
+static const bool __native_le = 1;
+#endif
 
 static int cvmx_pko_setup_macs(int node);
 
@@ -224,7 +232,7 @@ int cvmx_pko_transmit_packet(int dq, cvmx_buf_ptr_pki_t bufptr,
 
 	unsigned port_node;
 	cvmx_pko_send_hdr_t pko_send_hdr;
-	cvmx_pko_query_rtn_s_t pko_status;
+	cvmx_pko_query_rtn_t pko_status;
 	uint64_t words[2];
 
 	port_node = dq >> 14;
@@ -260,7 +268,7 @@ int cvmx_pko_transmit_packet(int dq, cvmx_buf_ptr_pki_t bufptr,
  */
 int cvmx_pko_dq_open(int node, int dq)
 {
-	cvmx_pko_query_rtn_s_t pko_status;
+	cvmx_pko_query_rtn_t pko_status;
 	pko_query_dqstatus_t dqstatus;
 
 	pko_status = __cvmx_pko3_do_dma(node, dq, NULL, 0, CVMX_PKO_DQ_OPEN);
@@ -292,7 +300,7 @@ int cvmx_pko_dq_open(int node, int dq)
  */
 int cvmx_pko3_dq_close(int node, int dq)
 {
-	cvmx_pko_query_rtn_s_t pko_status;
+	cvmx_pko_query_rtn_t pko_status;
 	pko_query_dqstatus_t dqstatus;
 
 	pko_status = __cvmx_pko3_do_dma(node, dq, NULL, 0, CVMX_PKO_DQ_CLOSE);
@@ -343,7 +351,7 @@ void cvmx_pko3_dq_drain(int node, int dq)
  */
 int cvmx_pko3_dq_query(int node, int dq)
 {
-	cvmx_pko_query_rtn_s_t pko_status;
+	cvmx_pko_query_rtn_t pko_status;
 	pko_query_dqstatus_t dqstatus;
 
 	pko_status = __cvmx_pko3_do_dma(node, dq, NULL, 0, CVMX_PKO_DQ_QUERY);
@@ -365,7 +373,8 @@ static struct cvmx_pko3_mac_s {
 	uint8_t fifo_cnt;
 	uint8_t fifo_id;
 	uint8_t pri;
-	//FIXME- MAC speed needs more work to be accurate !
+	uint8_t spd;
+	uint8_t mac_fifo_cnt;
 } cvmx_pko3_mac_table[ CVMX_PKO_MAX_MACS ];
 
 /*
@@ -391,6 +400,7 @@ static int cvmx_pko_setup_macs(int node)
 
 	/* Initialize FIFO allocation table */
 	memset(&fifo_group_cfg, 0, sizeof(fifo_group_cfg));
+	memset(&fifo_group_spd, 0, sizeof(fifo_group_spd));
 
 	/* Initialize all MACs as disabled */
 	for(mac_num = 0; mac_num < CVMX_PKO_MAX_MACS; mac_num++) {
@@ -408,8 +418,7 @@ static int cvmx_pko_setup_macs(int node)
 		if(mode == CVMX_HELPER_INTERFACE_MODE_DISABLED)
 			continue;
 		/*
-		 * ILK returns 8 ports, LOOP 4 ports, NPI ?? ports
-		 * but each of them only uses a single MAC really
+		 * Each of these interfaces has a single MAC really.
 		 */
 		if ((mode == CVMX_HELPER_INTERFACE_MODE_ILK) ||
 			(mode == CVMX_HELPER_INTERFACE_MODE_NPI) ||
@@ -420,31 +429,55 @@ static int cvmx_pko_setup_macs(int node)
 			int i;
 
 			/* convert interface/port to mac number */
-			i = __cvmx_pko_get_mac_num(interface, port);
-			if (i < 0 || i>= CVMX_PKO_MAX_MACS)
+			i = __cvmx_pko3_get_mac_num(interface, port);
+			if (i < 0 || i>= CVMX_PKO_MAX_MACS) {
+				cvmx_dprintf("%s: ERROR: interface %d port %d has no MAC\n",
+					__func__, interface, port);
 				continue;
+			}
 
 			cvmx_pko3_mac_table[i].mac_mode = mode;
 			if(mode == CVMX_HELPER_INTERFACE_MODE_RXAUI) {
-				cvmx_pko3_mac_table[i].fifo_cnt = 4;
+				cvmx_pko3_mac_table[i].fifo_cnt = 2;
 				cvmx_pko3_mac_table[i].pri = 2;
+				cvmx_pko3_mac_table[i].spd = 10;
+				cvmx_pko3_mac_table[i].mac_fifo_cnt = 2;
 			} else if (mode == CVMX_HELPER_INTERFACE_MODE_XAUI) {
 				cvmx_pko3_mac_table[i].fifo_cnt = 4;
-				cvmx_pko3_mac_table[i].pri = 3;
-			} else if (mode == CVMX_HELPER_INTERFACE_MODE_ILK) {
+				cvmx_pko3_mac_table[i].pri = 2;
+				/* DXAUI at 20G, or XAU at 10G */
+				cvmx_pko3_mac_table[i].spd = 20;
+				cvmx_pko3_mac_table[i].mac_fifo_cnt = 4;
+			} else if (mode == CVMX_HELPER_INTERFACE_MODE_XFI) {
+				cvmx_pko3_mac_table[i].fifo_cnt = 4;
+				cvmx_pko3_mac_table[i].pri = 1;
+				cvmx_pko3_mac_table[i].spd = 10;
+				cvmx_pko3_mac_table[i].mac_fifo_cnt = 1;
+			} else if (mode == CVMX_HELPER_INTERFACE_MODE_XLAUI) {
 				cvmx_pko3_mac_table[i].fifo_cnt = 4;
 				cvmx_pko3_mac_table[i].pri = 4;
+				cvmx_pko3_mac_table[i].spd = 40;
+				cvmx_pko3_mac_table[i].mac_fifo_cnt = 4;
+			} else if (mode == CVMX_HELPER_INTERFACE_MODE_ILK) {
+				cvmx_pko3_mac_table[i].fifo_cnt = 4;
+				cvmx_pko3_mac_table[i].pri = 3;
+				/* ILK: 40 Gbps or 20 Gbps */
+				cvmx_pko3_mac_table[i].spd = 40;
+				cvmx_pko3_mac_table[i].mac_fifo_cnt = 4;
 			} else {
 				cvmx_pko3_mac_table[i].fifo_cnt = 1;
 				cvmx_pko3_mac_table[i].pri = 1;
+				cvmx_pko3_mac_table[i].spd = 1;
+				cvmx_pko3_mac_table[i].mac_fifo_cnt = 1;
 			}
 
 			if(debug)
 				cvmx_dprintf("%s: intf %u port %u %s "
-				"mac %02u cnt %u\n",
+					"mac %02u cnt %u spd %u\n",
 				__FUNCTION__, interface, port,
 				cvmx_helper_interface_mode_to_string(mode),
-				i, cvmx_pko3_mac_table[i].fifo_cnt);
+				i, cvmx_pko3_mac_table[i].fifo_cnt,
+				cvmx_pko3_mac_table[i].spd);
 
 		} /* for port */
 	} /* for interface */
@@ -454,7 +487,7 @@ static int cvmx_pko_setup_macs(int node)
 		fifo_count += cvmx_pko3_mac_table[mac_num].fifo_cnt;
 
 	if(debug)
-		cvmx_dprintf("%s: initial FIFO count %u\n",
+		cvmx_dprintf("%s: initially reqyested FIFO count %u\n",
 			__FUNCTION__, fifo_count);
 
 	/* Heuristically trim FIFO count to fit in available number */
@@ -486,7 +519,7 @@ static int cvmx_pko_setup_macs(int node)
 
 	/* Special case for NULL Virtual FIFO */
 	fifo_group_cfg[28 >> 2] = 0;
-	//FIXME- there is no MAC connected to NULL FIFO
+	/* there is no MAC connected to NULL FIFO */
 
 	/* Configure MAC units, and attach a FIFO to each */
 	for(fifo = 0, cnt = 4; cnt > 0; cnt >>= 1 ) {
@@ -496,18 +529,28 @@ static int cvmx_pko_setup_macs(int node)
 			  cvmx_pko3_mac_table[mac_num].fifo_id != 0x1f)
 				continue;
 
+			/* Attach FIFO to MAC */
 			cvmx_pko3_mac_table[mac_num].fifo_id = fifo;
 			g = fifo >> 2;
+			/* Sum speed for FIFO group */
+			fifo_group_spd[g] += cvmx_pko3_mac_table[mac_num].spd;
+
 			if(cnt == 4)
 				fifo_group_cfg[g] = 4; /* 10k,0,0,0 */
 			else if(cnt == 2 && (fifo & 0x3) == 0)
 				fifo_group_cfg[g] = 3; /* 5k,0,5k,0 */
-			else if(cnt == 1 && fifo & 0x2 && fifo_group_cfg[g])
+			else if (cnt == 2 && fifo_group_cfg[g] == 3)
+				/* no change */;
+			else if(cnt == 1 && (fifo & 0x2) && 
+				fifo_group_cfg[g] == 3)
 				fifo_group_cfg[g] = 1; /* 5k,0,2.5k 2.5k*/
-			else
+			else if(cnt == 1 && (fifo & 0x3)==0x3)
+				/* no change */;
+			else if (cnt == 1)
 				fifo_group_cfg[g] = 0; /* 2.5k x 4 */
+			else
+				cvmx_dprintf("%s: internal error\n",__func__);
 
-			fifo_group_spd[g] += cnt * 5;
 			fifo += cnt;
 		}
 	}
@@ -541,9 +584,13 @@ static int cvmx_pko_setup_macs(int node)
 		else
 			pko_ptgfx_cfg.s.rate = 0;	/* 6.25 Gbps */
 
-		if(debug) cvmx_dprintf("%s: fifo group %#x size=%u rate=%d\n",
-			__FUNCTION__, fifo, pko_ptgfx_cfg.s.size,
-			pko_ptgfx_cfg.s.rate);
+		if(debug)
+			cvmx_dprintf("%s: FIFO %#x-%#x size=%u "
+				"speed=%d rate=%d\n",
+				__func__, fifo*4, fifo*4+3,
+				 pko_ptgfx_cfg.s.size,
+				fifo_group_spd[fifo],
+				pko_ptgfx_cfg.s.rate);
 
 		cvmx_write_csr_node(node, CVMX_PKO_PTGFX_CFG(fifo),
 					pko_ptgfx_cfg.u64);
@@ -557,10 +604,11 @@ static int cvmx_pko_setup_macs(int node)
 		cvmx_pko_macx_cfg_t pko_mac_cfg;
 
 		if(debug)
-			cvmx_dprintf("%s: mac#%02u: fifo=%#x cnt=%u\n",
+			cvmx_dprintf("%s: mac#%02u: fifo=%#x cnt=%u speed=%d\n",
 			__FUNCTION__, mac_num,
 			cvmx_pko3_mac_table[mac_num].fifo_id,
-			cvmx_pko3_mac_table[mac_num].fifo_cnt);
+			cvmx_pko3_mac_table[mac_num].fifo_cnt,
+			cvmx_pko3_mac_table[mac_num].spd);
 
 		pko_mac_cfg.u64 =
 			cvmx_read_csr_node(node, CVMX_PKO_MACX_CFG(mac_num));
@@ -574,11 +622,14 @@ static int cvmx_pko_setup_macs(int node)
 	for(mac_num = 0; mac_num < CVMX_PKO_MAX_MACS; mac_num++) {
 		cvmx_pko_mci0_max_credx_t pko_mci0_max_cred;
 		cvmx_pko_mci1_max_credx_t pko_mci1_max_cred;
-		unsigned credit, mac_credit, fifo_req_size, fifo_size;
+		unsigned credit, mac_credit;
+		unsigned fifo_req_size, fifo_size;
+		unsigned mac_fifo_cnt;
 
 		/* FIXME- this section has no basis in HRM, revisit */
 		/* Loosely based on packet/clear78.x */
 		fifo_req_size = cvmx_pko3_mac_table[mac_num].fifo_cnt;
+		mac_fifo_cnt = cvmx_pko3_mac_table[mac_num].mac_fifo_cnt;
 
 		/* Skip unused MACs */
 		if (fifo_req_size == 0)
@@ -604,7 +655,7 @@ static int cvmx_pko_setup_macs(int node)
 				mac_credit = 4 * 1024; /* 4KB fifo */
 				break;
 			default: /* BGX */
-				mac_credit = fifo_req_size * 8 * 1024;
+				mac_credit = mac_fifo_cnt * 8 * 1024;
 				break;
 		} /* switch mac_num */
 
@@ -687,9 +738,8 @@ void cvmx_pko3_get_legacy_port_stats(uint16_t ipd_port,
  *
  * The options supported are the parameters below:
  *
- * @param node The OCI node number of the interface
- * @param interface The physical interface number
- * @param port The physical sub-interface port
+ * @param xiface The physical interface number
+ * @param index The physical sub-interface port
  * @param fcs_enable Enable FCS generation
  * @param pad_enable Enable padding to minimum packet size
  * @param fcs_sop_off Number of bytes at start of packet to exclude from FCS
@@ -701,18 +751,19 @@ void cvmx_pko3_get_legacy_port_stats(uint16_t ipd_port,
  *
  * @return Returns 0 on success, -1 if interface/port is invalid.
  */
-int cvmx_pko3_interface_options(int node, int interface, int port,
+int cvmx_pko3_interface_options(int xiface, int index,
 			bool fcs_enable, bool pad_enable,
 			unsigned fcs_sop_off)
 {
 	int mac_num;
 	cvmx_pko_macx_cfg_t pko_mac_cfg;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 
-	mac_num = __cvmx_pko_get_mac_num(interface, port);
+	mac_num = __cvmx_pko3_get_mac_num(xiface, index);
 	if(mac_num < 0)
 		return -1;
 
-	pko_mac_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKO_MACX_CFG(mac_num));
+	pko_mac_cfg.u64 = cvmx_read_csr_node(xi.node, CVMX_PKO_MACX_CFG(mac_num));
 
 	/* If MAC is not assigned, return an error */
 	if (pko_mac_cfg.s.fifo_num == 0x1f)
@@ -726,7 +777,7 @@ int cvmx_pko3_interface_options(int node, int interface, int port,
 		cvmx_dprintf("%s: PKO_MAC[%u]CFG=%#x\n",__func__,
 		mac_num, (unsigned) pko_mac_cfg.u64);
 
-	cvmx_write_csr_node(node, CVMX_PKO_MACX_CFG(mac_num), pko_mac_cfg.u64);
+	cvmx_write_csr_node(xi.node, CVMX_PKO_MACX_CFG(mac_num), pko_mac_cfg.u64);
 
 	return 0;
 }
@@ -764,6 +815,8 @@ void cvmx_pko3_dq_options(unsigned node, unsigned dq, bool min_pad)
  *
  * Do not use this function when creating a descriptor from a
  * Work Queue Entry.
+ *
+ * The default setting of the 'free_bufs' attribute is 'false'.
  */
 void cvmx_pko3_pdesc_init(cvmx_pko3_pdesc_t *pdesc)
 {
@@ -774,11 +827,15 @@ void cvmx_pko3_pdesc_init(cvmx_pko3_pdesc_t *pdesc)
 	/* Start with HDR_S and HDR_EXT_S in first two words, all 0's */
 	pdesc->num_words = 2;
 
+	pdesc->hdr_s = (void *) &pdesc->word[0];
 	ext_s = (void *) &pdesc->word[1];
 	ext_s->s.subdc4 = CVMX_PKO_SENDSUBDC_EXT;
 
 	pdesc->last_aura = -1;
 	pdesc->jb_aura = -1;
+
+	/* Empty packets, can not decode header offsets (yet) */
+	pdesc->hdr_offsets = 1;
 }
 
 /**
@@ -815,7 +872,7 @@ int cvmx_pko3_pdesc_from_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
 
 
 	/* Verufy the WQE is legit */
-	if (cvmx_unlikely(wqe->word2.pki.software || wqe->pki_wqe_translated)) {
+	if (cvmx_unlikely(wqe->word2.software || wqe->pki_wqe_translated)) {
 		cvmx_dprintf("%s: ERROR: invalid WQE\n", __func__);
 		return -1;
 	}
@@ -825,7 +882,7 @@ int cvmx_pko3_pdesc_from_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
 	pdesc->jb_aura = -1;
 
 	/* 1st word is SEND_HDR_S header */
-	hdr_s = (void *) &pdesc->word[0];
+	hdr_s = pdesc->hdr_s = (void *) &pdesc->word[0];
 	/* 2nd word is the SEND_EXT_S header */
 	ext_s = (void *) &pdesc->word[1];
 	ext_s->s.subdc4 = CVMX_PKO_SENDSUBDC_EXT;
@@ -842,30 +899,27 @@ int cvmx_pko3_pdesc_from_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
 
 	/* Inherit GAURA */
 	pdesc->last_aura =
-	hdr_s->s.aura = wqe->word0.pki.aura;
+	hdr_s->s.aura = wqe->word0.aura;
 
 	/* Get the NODE on which this packet was received */
 	node = pdesc->last_aura >> 10;
 
 	/* Import total packet length */
-	hdr_s->s.total = wqe->word1.cn78xx.len ;
+	hdr_s->s.total = wqe->word1.len ;
 
 	/* Read the PKI_STYLEX_BUF register for this packet style */
         style_buf_reg.u64 = cvmx_read_csr_node(node,
-		CVMX_PKI_STYLEX_BUF(wqe->word0.pki.style));
+		CVMX_PKI_STYLEX_BUF(wqe->word0.style));
 
 	/* mirror PKI endianness state: */
 	hdr_s->s.le = style_buf_reg.s.pkt_lend;
-#if CVMX_ENABLE_PARAMETER_CHECKING
-#ifdef __BIG_ENDIAN_BITFIELD
-	if (hdr_s->s.le)
-#else
-	if (!hdr_s->s.le)
+#if	CVMX_ENABLE_PARAMETER_CHECKING
+	if (hdr_s->s.le != __native_le)
+		cvmx_dprintf("%s: WARNING: "
+			"packet endianness mismatch\n",__func__);
 #endif
-		cvmx_dprintf("%s: WARNING: packet endianness mismatch\n", __func__);
-#endif
-#if 0
-	// WQE fields not used (yet?)
+
+#if 0 // WQE fields not used (yet?)
 		wqe->word0.pki.pknd
 		wqe->word0.pki.channel
 
@@ -875,7 +929,7 @@ int cvmx_pko3_pdesc_from_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
 #endif
 
 	/* Carry-over layer protocol detection from PKI */
-	pdesc->pki_word2 = wqe->word2.pki;
+	pdesc->pki_word2 = wqe->word2;
 
 	/* check if WQE WORD4 is present */
 	if (style_buf_reg.s.wqe_hsz != 0 || style_buf_reg.s.first_skip > 4) {
@@ -894,18 +948,18 @@ int cvmx_pko3_pdesc_from_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
 	pki_bptr = wqe->packet_ptr;
 	buf_s = (void *) &pdesc->word[pdesc->num_words++];
 	buf_s->u64 = 0;
-	buf_s->s.addr = pki_bptr.s_cn78xx.addr;
-	buf_s->s.size = pki_bptr.s_cn78xx.size;
+	buf_s->s.addr = pki_bptr.addr;
+	buf_s->s.size = pki_bptr.size;
 
 	/* use LINK_S if more than one buf present, calculate headroom */
-	if (cvmx_unlikely(wqe->word0.pki.bufs > 1)) {
+	if (cvmx_unlikely(wqe->word0.bufs > 1)) {
 		pdesc->headroom =  (style_buf_reg.s.first_skip) << 3;
 		buf_s->s.subdc3 = CVMX_PKO_SENDSUBDC_LINK;
 	} else {
 		pdesc->headroom =  (1 + style_buf_reg.s.first_skip) << 3;
 		buf_s->s.subdc3 = CVMX_PKO_SENDSUBDC_GATHER;
 	}
-	pdesc->headroom += wqe->word0.pki.apad;
+	pdesc->headroom += wqe->word0.apad;
 
 	return 0;
 }
@@ -930,7 +984,7 @@ static int cvmx_pko3_pdesc_subdc_add(cvmx_pko3_pdesc_t *pdesc,
 	unsigned i;
 
 	/* Simple handling while fitting the command buffer */
-	if (cvmx_likely(pdesc->num_words <= 15)) {
+	if (cvmx_likely(pdesc->num_words <= 15 && pdesc->jump_buf == NULL)) {
 		pdesc->word[ pdesc->num_words ] = subdc;
 		pdesc->num_words ++;
 		return pdesc->num_words;
@@ -939,7 +993,7 @@ static int cvmx_pko3_pdesc_subdc_add(cvmx_pko3_pdesc_t *pdesc,
         /* SEND_JUMP_S broken on Pass1 */
         if(OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_0)) {
                 cvmx_dprintf("%s: ERROR: too many segments\n",__func__);
-                return -__LINE__;
+                return -E2BIG;
         }
 
 	hdr_s = (void *) &pdesc->word[0];
@@ -947,17 +1001,15 @@ static int cvmx_pko3_pdesc_subdc_add(cvmx_pko3_pdesc_t *pdesc,
 
 	/* Allocate jump buffer */
 	if (cvmx_unlikely(pdesc->jump_buf == NULL)) {
-		unsigned pko_gaura, pko_anode, pko_laura;
+		unsigned pko_gaura;
 		unsigned fpa_node = cvmx_get_node_num();
 
 		/* Allocate jump buffer from PKO internal FPA AURA, size=4KiB */
 		pko_gaura = __cvmx_pko3_aura_get(fpa_node);
-		pko_anode = pko_gaura >> 10;
-		pko_laura = pko_gaura & (CVMX_FPA3_AURA_NUM-1);
 
-		pdesc->jump_buf = cvmx_fpa_alloc_aura(pko_anode, pko_laura);
+		pdesc->jump_buf = cvmx_fpa3_alloc_gaura(pko_gaura);
                 if(pdesc->jump_buf == NULL)
-                        return -__LINE__;
+                        return -EINVAL;
 
 		/* Save the JB aura for later */
 		pdesc->jb_aura = pko_gaura;
@@ -968,7 +1020,7 @@ static int cvmx_pko3_pdesc_subdc_add(cvmx_pko3_pdesc_t *pdesc,
 		jump_s = (void *) &pdesc->word[2];
 		jump_s->u64 = 0;
 		jump_s->s.addr = cvmx_ptr_to_phys(pdesc->jump_buf);
-		jump_s->s.i = hdr_s->s.df;	/* force PKO3 to free JB */
+		jump_s->s.i = !hdr_s->s.df;	/* F= ~DF */
 		jump_s->s.size = pdesc->num_words - 2;
 		jump_s->s.subdc3 = CVMX_PKO_SENDSUBDC_JUMP;
 
@@ -983,7 +1035,7 @@ static int cvmx_pko3_pdesc_subdc_add(cvmx_pko3_pdesc_t *pdesc,
 	/* Avoid overrunning jump buffer */
 	if (i >= (jump_buf_size-2)) {
                 cvmx_dprintf("%s: ERROR: too many segments\n",__func__);
-		return -__LINE__;
+		return -E2BIG;
 	}
 
 	pdesc->jump_buf[i] = subdc;
@@ -1010,13 +1062,14 @@ static int cvmx_pko3_pdesc_subdc_add(cvmx_pko3_pdesc_t *pdesc,
  */
 int cvmx_pko3_pdesc_transmit(cvmx_pko3_pdesc_t *pdesc, uint16_t dq)
 {
-        cvmx_pko_query_rtn_s_t pko_status;
+        cvmx_pko_query_rtn_t pko_status;
 	cvmx_pko_send_aura_t aura_s;
 	uint8_t port_node;
 	int rc;
 
 	/* Add last AURA_S for jump_buf, if present */
-	if (cvmx_unlikely(pdesc->jump_buf != NULL)) {
+	if (cvmx_unlikely(pdesc->jump_buf != NULL) &&
+	    (pdesc->last_aura != pdesc->jb_aura)) {
 		/* The last AURA_S subdc refers to the jump_buf itself */
 		aura_s.s.aura = pdesc->jb_aura;
 		aura_s.s.offset = 0;
@@ -1034,6 +1087,7 @@ int cvmx_pko3_pdesc_transmit(cvmx_pko3_pdesc_t *pdesc, uint16_t dq)
 		rc = cvmx_pko3_pdesc_subdc_add(pdesc, pdesc->send_work_s);
 		if (rc < 0)
 			return -1;
+		pdesc->send_work_s = 0ULL;
 	}
 
         /* Derive destination node from dq */
@@ -1072,15 +1126,19 @@ int cvmx_pko3_pdesc_transmit(cvmx_pko3_pdesc_t *pdesc, uint16_t dq)
  * @param p_data Address of the segment first byte (virtual).
  * @param data_bytes Size of the data segment (in bytes).
  * @param gaura A global FPA 'aura' where the packet buffer was allocated from.
- * @param free_buf Cause the PKO to release the buffer on completion.
  *
  * The 'gaura' parameter contaisn the node number where the buffer pool
  * is located, and has only a meaning if the 'free_buf' argument is 'true'.
+ * The buffer being added will be automatically freed upon transmission
+ * along with all other buffers in this descriptor, or not, depending
+ * on the descriptor 'free_bufs' attribute that is set during
+ * descriptor creation, or changed subsequently with a call to
+ * 'cvmx_pko3_pdesc_set_free()'.
  *
  * @return Returns 0 on success, -1 on error.
  */
 int cvmx_pko3_pdesc_buf_append(cvmx_pko3_pdesc_t *pdesc, void *p_data,
-		unsigned data_bytes, unsigned gaura, bool free_buf)
+		unsigned data_bytes, unsigned gaura)
 {
 	cvmx_pko_send_hdr_t *hdr_s;
 	cvmx_pko_buf_ptr_t gather_s;
@@ -1099,11 +1157,11 @@ int cvmx_pko3_pdesc_buf_append(cvmx_pko3_pdesc_t *pdesc, void *p_data,
 
 		/* First mbuf, calculate headroom */
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-                buf_sz = cvmx_fpa_get_aura_buf_size(gaura);
+                buf_sz = cvmx_fpa3_get_aura_buf_size(gaura);
 #endif
 		pdesc->headroom = (unsigned long)p_data & (buf_sz-1);
 		pdesc->last_aura = hdr_s->s.aura = gaura;
-	} else if(pdesc->last_aura != (short) gaura && free_buf) {
+	} else if(pdesc->last_aura != (short) gaura) {
 		aura_s.s.aura = gaura;
 		aura_s.s.offset = 0;
 		aura_s.s.alg = AURAALG_NOP;
@@ -1119,7 +1177,7 @@ int cvmx_pko3_pdesc_buf_append(cvmx_pko3_pdesc_t *pdesc, void *p_data,
 	gather_s.s.addr = cvmx_ptr_to_phys(p_data);
 	gather_s.s.size = data_bytes;
 	hdr_s->s.total += data_bytes;
-	gather_s.s.i = free_buf ^ ~hdr_s->s.df;
+	gather_s.s.i = 0;	/* follow HDR_S[DF] setting */
 	gather_s.s.subdc3 = CVMX_PKO_SENDSUBDC_GATHER;
 
 	rc = cvmx_pko3_pdesc_subdc_add(pdesc, gather_s.u64);
@@ -1173,11 +1231,11 @@ int cvmx_pko3_pdesc_notify_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
 	work_s.s.grp = (group & 0xff) | (node  << 8);
 	work_s.s.tt = tt;
 
-	wqe->word1.cn78xx.rsvd_0 = 0;
-	wqe->word1.cn78xx.rsvd_1 = 0;
-	wqe->word1.cn78xx.tag = tag;
-	wqe->word1.cn78xx.tag_type = tt;
-	wqe->word1.cn78xx.grp = work_s.s.grp;
+	wqe->word1.rsvd_0 = 0;
+	wqe->word1.rsvd_1 = 0;
+	wqe->word1.tag = tag;
+	wqe->word1.tag_type = tt;
+	wqe->word1.grp = work_s.s.grp;
 
 	/* Store in descriptor for now, apply just before LTDMA-ing */
 	pdesc->send_work_s = work_s.u64;
@@ -1273,6 +1331,108 @@ int cvmx_pko3_pdesc_notify_memclr(cvmx_pko3_pdesc_t *pdesc,
 	return rc;
 }
 
+
+/**
+ * @INTERNAL
+ *
+ * Decode packet header and calculate protocol header offsets
+ *
+ * The protocol information and layer offset is derived
+ * from the results if decoding done by the PKI,
+ * and the appropriate PKO fields are filled.
+ *
+ * The function assumes the headers have not been modified
+ * since converted from WQE, and does not (yet) implement
+ * software-based decoding to handle modified or originated
+ * packets correctly.
+ *
+ * FIXME:
+ * Add simple accessors to read the decoded protocol fields.
+ */
+static int cvmx_pko3_pdesc_hdr_offsets(cvmx_pko3_pdesc_t *pdesc)
+{
+	cvmx_pko_send_hdr_t *hdr_s;
+
+	if (pdesc->hdr_offsets)
+		return 0;
+
+	if (!pdesc->pki_word4_present)
+		return -EINVAL;
+
+	pdesc->hdr_s = hdr_s = (void *) &pdesc->word[0];
+
+	/* Match IPv5/IPv6 protocols with/without options */
+	if ((pdesc->pki_word2.lc_hdr_type & 0x1c) 
+		== CVMX_PKI_LTYPE_E_IP4) {
+		hdr_s->s.l3ptr = pdesc->pki_word4.ptr_layer_c;
+
+		/* Match TCP/UDP/SCTP group */
+		if ((pdesc->pki_word2.lf_hdr_type & 0x18) == CVMX_PKI_LTYPE_E_TCP)
+			hdr_s->s.l4ptr = pdesc->pki_word4.ptr_layer_f;
+
+		if (pdesc->pki_word2.lf_hdr_type == CVMX_PKI_LTYPE_E_UDP)
+			pdesc->ckl4_alg = CKL4ALG_UDP;
+		if (pdesc->pki_word2.lf_hdr_type == CVMX_PKI_LTYPE_E_TCP)
+			pdesc->ckl4_alg = CKL4ALG_TCP;
+		if (pdesc->pki_word2.lf_hdr_type == CVMX_PKI_LTYPE_E_SCTP)
+			pdesc->ckl4_alg = CKL4ALG_SCTP;
+	}
+	/* FIXME: consider ARP as L3 too ? what about IPfrag ? */
+
+	pdesc->hdr_offsets = 1;	/* make sure its done once */
+	return 0;
+}
+
+/*
+ * @INTERNAL
+ *
+ * memcpy() a reverse endian memory region.
+ * where both the source and destination are the reverse endianness
+ * with respect to native byte order.
+ */
+static void memcpy_swap(void *dst, const void *src, unsigned bytes)
+{
+	uint8_t *d = dst;
+	const uint8_t *s = src;
+	unsigned i;
+	const unsigned swizzle = 0x7;	/* 64-bit invariant endianness */
+
+	for(i = 0; i < bytes; i++)
+		d[i ^ swizzle] = s[i ^ swizzle];
+}
+
+/*
+ * @INTERNAL
+ *
+ * memcpy() with swizzling, from reverse endianness to native byte order.
+ */
+static void memcpy_from_swap(void *dst, const void *src, unsigned bytes)
+{
+	uint8_t *d = dst;
+	const uint8_t *s = src;
+	unsigned i;
+	const unsigned swizzle = 0x7;	/* 64-bit invariant endianness */
+
+	for(i = 0; i < bytes; i++)
+		d[i] = s[i ^ swizzle];
+}
+
+/*
+ * @INTERNAL
+ *
+ * memcpy() with swizzling, from native byte order to the reverse endianness.
+ */
+static void memcpy_to_swap(void *dst, const void *src, unsigned bytes)
+{
+	uint8_t *d = dst;
+	const uint8_t *s = src;
+	unsigned i;
+	const unsigned swizzle = 0x7;	/* 64-bit invariant endianness */
+
+	for(i = 0; i < bytes; i++)
+		d[i ^ swizzle] = s[i];
+}
+
 /**
  * Prepend a data segment to the packet descriptor
  *
@@ -1286,21 +1446,24 @@ int cvmx_pko3_pdesc_notify_memclr(cvmx_pko3_pdesc_t *pdesc,
  *
  * On success, the function returns the remaining headroom in the buffer.
  *
- * FIXME: Not tested yet.
  */
-int cvmx_pko3_pdesc_prepend(cvmx_pko3_pdesc_t *pdesc,
-	const void *p_data, uint8_t data_bytes)
+int cvmx_pko3_pdesc_hdr_push(cvmx_pko3_pdesc_t *pdesc,
+	const void *p_data, uint8_t data_bytes, uint8_t layer)
 {
 	cvmx_pko_send_hdr_t *hdr_s;
 	cvmx_pko_buf_ptr_t *gather_s;
 	short headroom;
 	void *p;	/* old data location */
 	void *q;	/* new data location */
+	bool endian_swap;
 
-	if ((int)data_bytes < (headroom = pdesc->headroom))
-		return -1;
+	headroom = pdesc->headroom;
+
+	if ((short)data_bytes > headroom)
+		return -ENOSPC;
 
 	hdr_s = (void *)&pdesc->word[0];
+	endian_swap = (hdr_s->s.le != __native_le);
 
 	/* Get GATTHER_S/LINK_S subcommand location */
 	if (cvmx_likely(pdesc->jump_buf == NULL))
@@ -1310,6 +1473,11 @@ int cvmx_pko3_pdesc_prepend(cvmx_pko3_pdesc_t *pdesc,
 		/* With JB, its first word is the first buffer */
 		gather_s = (void *)pdesc->jump_buf;
 
+	/* Verify the subcommand is of the expected type */
+	if (cvmx_unlikely(gather_s->s.subdc3 != CVMX_PKO_SENDSUBDC_LINK &&
+			gather_s->s.subdc3 != CVMX_PKO_SENDSUBDC_GATHER))
+		return -EINVAL;
+
 	/* adjust  address and size values */
 	p = cvmx_phys_to_ptr(gather_s->s.addr);
 	q			= p - data_bytes;
@@ -1319,11 +1487,38 @@ int cvmx_pko3_pdesc_prepend(cvmx_pko3_pdesc_t *pdesc,
 	headroom		-= data_bytes;
 
 	/* Move link pointer if the descriptor is SEND_LINK_S */
-	if (gather_s->s.subdc3 == CVMX_PKO_SENDSUBDC_LINK)
-		memcpy(q-8, p-8, 8);
-	memcpy(q, p_data, data_bytes);
+	if (gather_s->s.subdc3 == CVMX_PKO_SENDSUBDC_LINK) {
+		if (cvmx_likely(!endian_swap))
+			memcpy(q-8, p-8, 8);
+		else
+			memcpy_swap(q-8, p-8, 8);
+	}
 
-	return pdesc->headroom = headroom;
+	if (cvmx_likely(!endian_swap))
+		memcpy(q, p_data, data_bytes);
+	else
+		memcpy_to_swap(q, p_data, data_bytes);
+
+	pdesc->headroom = headroom;
+
+	/* Adjust higher level protocol header offset */
+	cvmx_pko3_pdesc_hdr_offsets(pdesc);
+	if (layer <= 4 ) {
+		pdesc->hdr_s->s.l4ptr += data_bytes;
+	}
+
+	if (layer <= 3) {
+		pdesc->hdr_s->s.l3ptr += data_bytes;
+	}
+
+	if (layer >= 3) {
+		hdr_s->s.ckl3 = 1;
+		hdr_s->s.ckl4 = pdesc->ckl4_alg;
+		/* FIXME: decode L4 alg in case the header was generated */
+		/* FIXME: CKL4 not supported in simulator */
+	}
+
+	return headroom;
 }
 
 
@@ -1336,20 +1531,24 @@ int cvmx_pko3_pdesc_prepend(cvmx_pko3_pdesc_t *pdesc,
  *
  * Returns new packet size, or -1 if the trimmed size exceeds the
  * size of the first data segment.
- *
- * FIXME: Not tested yet.
  */
-int cvmx_pko3_pdesc_trim(cvmx_pko3_pdesc_t *pdesc, unsigned num_bytes)
+int cvmx_pko3_pdesc_hdr_pop(cvmx_pko3_pdesc_t *pdesc,
+		void *hdr_buf, unsigned num_bytes)
 {
 	cvmx_pko_send_hdr_t *hdr_s;
 	cvmx_pko_buf_ptr_t *gather_s;
 	short headroom;
 	void *p;
 	void *q;
+	bool endian_swap;
 
 	headroom = pdesc->headroom;
 
 	hdr_s = (void *)&pdesc->word[0];
+	endian_swap = (hdr_s->s.le != __native_le);
+
+	if (hdr_s->s.total < num_bytes)
+		return -ENOSPC;
 
 	/* Get GATTHER_S/LINK_S subcommand location */
 	if (cvmx_likely(pdesc->jump_buf == NULL))
@@ -1359,9 +1558,14 @@ int cvmx_pko3_pdesc_trim(cvmx_pko3_pdesc_t *pdesc, unsigned num_bytes)
 		/* With JB, its first word is the first buffer */
 		gather_s = (void *)pdesc->jump_buf;
 
+	/* Verify the subcommand is of the expected type */
+	if (cvmx_unlikely(gather_s->s.subdc3 != CVMX_PKO_SENDSUBDC_LINK &&
+			gather_s->s.subdc3 != CVMX_PKO_SENDSUBDC_GATHER))
+		return -EINVAL;
+
 	/* Can't trim more than the content of the first buffer */
 	if (gather_s->s.size < num_bytes)
-		return -1;
+		return -ENOMEM;
 
 	/* adjust  address and size values */
 	p = cvmx_phys_to_ptr(gather_s->s.addr);
@@ -1371,54 +1575,121 @@ int cvmx_pko3_pdesc_trim(cvmx_pko3_pdesc_t *pdesc, unsigned num_bytes)
 	hdr_s->s.total		-= num_bytes;
 	headroom		+= num_bytes;
 
+	if (hdr_buf != NULL) {
+		/* Retreive popped header to user buffer */
+		if (cvmx_likely(!endian_swap)) {
+			memcpy(hdr_buf, p, num_bytes);
+		} else {
+			memcpy_from_swap(hdr_buf, p, num_bytes);
+		}
+	}
+
 	/* Move link pointer if the descriptor is SEND_LINK_S */
-	if (gather_s->s.subdc3 == CVMX_PKO_SENDSUBDC_LINK)
-		memcpy(q-8, p-8, 8);
+	if (gather_s->s.subdc3 == CVMX_PKO_SENDSUBDC_LINK) {
+		if (cvmx_likely(!endian_swap))
+			memcpy(q-8, p-8, 8);
+		else
+			memcpy_swap(q-8, p-8, 8);
+	}
+
+	pdesc->headroom = headroom;
+
+	/* Adjust higher level protocol header offset */
+	cvmx_pko3_pdesc_hdr_offsets(pdesc);
+	if (num_bytes < pdesc->hdr_s->s.l3ptr) {
+		pdesc->hdr_s->s.l3ptr -= num_bytes;
+		pdesc->hdr_s->s.l4ptr -= num_bytes;
+	} else if (num_bytes < pdesc->hdr_s->s.l4ptr) {
+		pdesc->hdr_s->s.l3ptr = 0;
+		pdesc->hdr_s->s.l4ptr -= num_bytes;
+	} else {
+		pdesc->hdr_s->s.l3ptr = 0;
+		pdesc->hdr_s->s.l4ptr = 0;
+		hdr_s->s.ckl4 = CKL4ALG_NONE;
+	}
 
 	return hdr_s->s.total;
 }
 
 /**
- * Decode packet header and calculate protocol header offsets
+ * Peek into some header field of a packet
  *
- * The protocol information and layer offset is derived
- * from the results if decoding done by the PKI,
- * and the appropriate PKO fields are filled.
+ * Will return a number of bytes of packet header data at an arbitrary offset
+ * which must reside within the first packet data buffer.
  *
- * The function assumes the headers have not been modified
- * since converted from WQE, and does not (yet) implement
- * software-based decoding to handle modified or originated
- * packets correctly.
- *
- * FIXME:
- * Add simple accessors to read the decoded protocol fields.
  */
-int cvmx_pko3_pdesc_hdr_offsets(cvmx_pko3_pdesc_t *pdesc)
+int cvmx_pko3_pdesc_hdr_peek(cvmx_pko3_pdesc_t *pdesc,
+		void *hdr_buf, unsigned num_bytes, unsigned offset)
 {
 	cvmx_pko_send_hdr_t *hdr_s;
+	cvmx_pko_buf_ptr_t *gather_s;
+	void *p;
+	bool endian_swap;
 
-	if (!pdesc->pki_word4_present)
-		return -1;
+	hdr_s = (void *)&pdesc->word[0];
+	endian_swap = (hdr_s->s.le != __native_le);
 
-	hdr_s = (void *) &pdesc->word[0];
+	if (hdr_s->s.total < (num_bytes+offset))
+		return -ENOSPC;
 
-	/* Match IPv5/IPv6 protocols with/without options */
-	if ((pdesc->pki_word2.lc_hdr_type & 0x1c) 
-		== CVMX_PKI_LTYPE_E_IP4) {
-		hdr_s->s.l3ptr = pdesc->pki_word4.ptr_layer_c;
+	/* Get GATTHER_S/LINK_S subcommand location */
+	if (cvmx_likely(pdesc->jump_buf == NULL))
+		/* Without JB, first data buf is in 3rd command word */
+		gather_s = (void *)&pdesc->word[2];
+	else
+		/* With JB, its first word is the first buffer */
+		gather_s = (void *)pdesc->jump_buf;
 
-		/* Match TCP/UDP/SCTP group */
-		if ((pdesc->pki_word2.lf_hdr_type & 0x18) == CVMX_PKI_LTYPE_E_TCP)
-			hdr_s->s.l4ptr = pdesc->pki_word4.ptr_layer_f;
+	/* Verify the subcommand is of the expected type */
+	if (cvmx_unlikely(gather_s->s.subdc3 != CVMX_PKO_SENDSUBDC_LINK &&
+			gather_s->s.subdc3 != CVMX_PKO_SENDSUBDC_GATHER))
+		return -EINVAL;
 
-		if (pdesc->pki_word2.lf_hdr_type == CVMX_PKI_LTYPE_E_UDP)
-			pdesc->ckl4_alg = CKL4ALG_UDP;
-		if (pdesc->pki_word2.lf_hdr_type == CVMX_PKI_LTYPE_E_TCP)
-			pdesc->ckl4_alg = CKL4ALG_TCP;
-		if (pdesc->pki_word2.lf_hdr_type == CVMX_PKI_LTYPE_E_SCTP)
-			pdesc->ckl4_alg = CKL4ALG_SCTP;
+	/* Can't peek more than the content of the first buffer */
+	if (gather_s->s.size <= offset)
+		return -ENOMEM;
+	if ((gather_s->s.size-offset) < num_bytes)
+		num_bytes = gather_s->s.size-offset;
+
+	/* adjust address */
+	p = cvmx_phys_to_ptr(gather_s->s.addr) + offset;
+
+	if (hdr_buf == NULL)
+		return -EINVAL;
+
+	/* Copy requested bytes */
+	if (cvmx_likely(!endian_swap)) {
+		memcpy(hdr_buf, p, num_bytes);
+	} else {
+		memcpy_from_swap(hdr_buf, p, num_bytes);
 	}
-	/* FIXME: consider ARP as L3 too ? what about IPfrag ? */
 
-	return 0;
+	return num_bytes;
+}
+
+/**
+ * Set the packet descriptor automatic-free attribute
+ *
+ * Override the 'free_bufs' attribute that was set during
+ * packet descriptor creation, or by an earlier call to
+ * this function.
+ * Setting the 'buf_free" attribute to 'true' will cause
+ * the PKO3 to free all buffers associated with this packet
+ * descriptor to be released upon transmission complete.
+ * Setting this attribute to 'false' allows e.g. using the
+ * same descriptor to transmit a packet out of several ports
+ * with a minimum overhead.
+ */
+void cvmx_pko3_pdesc_set_free(cvmx_pko3_pdesc_t *pdesc, bool free_bufs)
+{
+	cvmx_pko_send_hdr_t *hdr_s;
+	cvmx_pko_buf_ptr_t *jump_s;
+
+	hdr_s = (void *)&pdesc->word[0];
+	hdr_s->s.df = !free_bufs;
+
+	if (cvmx_likely(pdesc->jump_buf == NULL))
+		return;
+	jump_s = (void *) &pdesc->word[2];
+	jump_s->s.i = free_bufs; /* F=free */
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-qlm.c b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
index 7184162..bfd2a66 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-qlm.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2011-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2011-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -42,12 +42,13 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 95250 $<hr>
+ * <hr>$Revision: 96753 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
 #include <asm/octeon/cvmx-bootmem.h>
 #include <asm/octeon/cvmx-helper-jtag.h>
+#include <asm/octeon/cvmx-helper-util.h>
 #include <asm/octeon/cvmx-qlm.h>
 #include <asm/octeon/cvmx-clock.h>
 #include <asm/octeon/cvmx-bgxx-defs.h>
@@ -62,11 +63,13 @@
 #include <asm/arch/cvmx.h>
 #include <asm/arch/cvmx-bootmem.h>
 #include <asm/arch/cvmx-helper-jtag.h>
+#include <asm/arch/cvmx-helper-util.h>
 #include <asm/arch/cvmx-qlm.h>
 #else
 #include "cvmx.h"
 #include "cvmx-bootmem.h"
 #include "cvmx-helper-jtag.h"
+#include "cvmx-helper-util.h"
 #include "cvmx-qlm.h"
 #endif
 
@@ -137,52 +140,67 @@ int cvmx_qlm_get_num(void)
  *
  * @param interface  Interface to look up
  */
-int cvmx_qlm_interface(int interface)
+int cvmx_qlm_interface(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	if (OCTEON_IS_MODEL(OCTEON_CN61XX)) {
-		return (interface == 0) ? 2 : 0;
+		return (xi.interface == 0) ? 2 : 0;
 	} else if (OCTEON_IS_MODEL(OCTEON_CN63XX) || OCTEON_IS_MODEL(OCTEON_CN66XX)) {
-		return 2 - interface;
+		return 2 - xi.interface;
 	} else if (OCTEON_IS_MODEL(OCTEON_CNF71XX)) {
-		if (interface == 0)
+		if (xi.interface == 0)
 			return 0;
 		else
-			cvmx_dprintf("Warning: cvmx_qlm_interface: Invalid interface %d\n", interface);
+			cvmx_dprintf("Warning: cvmx_qlm_interface: Invalid interface %d\n", xi.interface);
 	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		cvmx_bgxx_cmr_global_config_t gconfig;
 		cvmx_gserx_phy_ctl_t phy_ctl;
 		cvmx_gserx_cfg_t gserx_cfg;
 		int qlm;
 
-		gconfig.u64 = cvmx_read_csr(CVMX_BGXX_CMR_GLOBAL_CONFIG(interface));
-		if (gconfig.s.pmux_sds_sel) { /* Only QLM2 * QLM3 present */
-			if (interface < 2)
-				qlm = interface + 2;
-			else
-				qlm = -1;
-		} else { /* QLM0, QLM1, QLM4 - QLM7 are present */
-			if (interface < 2)
-				qlm = interface;
-			else
-				qlm = interface + 2;
-		}
-		/* make sure the QLM is powered up and out of reset */
-		if (qlm != -1) {
-			phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
-			if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
-				return -1;
-			gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
-			if (gserx_cfg.s.bgx)
-				return qlm;
+		if (xi.interface < 6) {
+			gconfig.u64 = cvmx_read_csr_node(xi.node, CVMX_BGXX_CMR_GLOBAL_CONFIG(xi.interface));
+			if (gconfig.s.pmux_sds_sel) { /* Only QLM2 * QLM3 present */
+				if (xi.interface < 2)
+					qlm = xi.interface + 2;
+				else
+					qlm = -1;
+			} else { /* QLM0, QLM1, QLM4 - QLM7 are present */
+				if (xi.interface < 2)
+					qlm = xi.interface;
+				else
+					qlm = xi.interface + 2;
+			}
+			/* make sure the QLM is powered up and out of reset */
+			if (qlm != -1) {
+				phy_ctl.u64 = cvmx_read_csr_node(xi.node, CVMX_GSERX_PHY_CTL(qlm));
+				if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
+					return -1;
+				gserx_cfg.u64 = cvmx_read_csr_node(xi.node, CVMX_GSERX_CFG(qlm));
+				if (gserx_cfg.s.bgx)
+					return qlm;
+			}
+		} else if (xi.interface >= 7) { /* ILK */
+			int qlm;
+			for (qlm = 4; qlm < 8; qlm++) {
+				/* Make sure the QLM is powered and out of reset */
+				phy_ctl.u64 = cvmx_read_csr_node(xi.node, CVMX_GSERX_PHY_CTL(qlm));
+				if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
+					continue;
+				/* Make sure the QLM is in ILK mode */
+				gserx_cfg.u64 = cvmx_read_csr_node(xi.node, CVMX_GSERX_CFG(qlm));
+				if (gserx_cfg.s.ila)
+					return qlm;
+			}
 		}
 		return -1;
 	} else {
 		/* Must be cn68XX */
-		switch (interface) {
+		switch (xi.interface) {
 		case 1:
 			return 0;
 		default:
-			return interface;
+			return xi.interface;
 		}
 	}
 	return -1;
@@ -736,6 +754,40 @@ int cvmx_qlm_get_gbaud_mhz(int qlm)
 		freq = meas_refclock * mpll_multiplier.s.mpll_multiplier;
 		freq = (freq + 500000) / 1000000;
 		return freq;
+	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
+		cvmx_gserx_lane_mode_t lane_mode;
+		if (qlm < 8)
+			return -1;	/* FIXME for OCI */
+		lane_mode.u64 = cvmx_read_csr(CVMX_GSERX_LANE_MODE(qlm));
+		switch (lane_mode.s.lmode)
+		{
+		case 0x0: /* R_25G_REFCLK100 */
+			return 2500;
+		case 0x1: /* R_5G_REFCLK100 */
+			return 5000;
+		case 0x2: /* R_8G_REFCLK100 */
+			return 8000;
+		case 0x3: /* R_125G_REFCLK15625_KX */
+			return 1250;
+		case 0x4: /* R_3125G_REFCLK15625_XAUI */
+			return 3125;
+		case 0x5: /* R_103215G_REFCLK15625_KR */
+			return 10321;
+		case 0x6: /* R_125G_REFCLK15625_SGMII */
+			return 1250;
+		case 0x7: /* R_5G_REFCLK15625_QSGMII */
+			return 5000;
+		case 0x8: /* R_625G_REFCLK15625_RXAUI */
+			return 6250;
+		case 0x9: /* R_25G_REFCLK125 */
+			return 2500;
+		case 0xa: /* R_5G_REFCLK125 */
+			return 5000;
+		case 0xb: /* R_8G_REFCLK125 */
+			return 8000;
+		default:
+			return 0;
+		}
 	}
 	return 0;
 }
@@ -1077,20 +1129,20 @@ static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn6xxx(int qlm)
 	return CVMX_QLM_MODE_DISABLED;
 }
 
-static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn78xx(int qlm)
+enum cvmx_qlm_mode cvmx_qlm_get_mode_cn78xx(int node, int qlm)
 {
 	cvmx_gserx_cfg_t gserx_cfg;
 
 	if (qlm >= 8)
 		return CVMX_QLM_MODE_OCI;
 
-	gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
+	gserx_cfg.u64 = cvmx_read_csr_node(node, CVMX_GSERX_CFG(qlm));
 	if (gserx_cfg.s.pcie) {
 		switch (qlm) {
 		case 0: /* Either PEM0 x4 or PEM0 x8 */
 		{
 			cvmx_pemx_cfg_t pemx_cfg;
-			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(0));
+			pemx_cfg.u64 = cvmx_read_csr_node(node, CVMX_PEMX_CFG(0));
 			if (pemx_cfg.cn78xx.lanes8)
 				return CVMX_QLM_MODE_PCIE_1X8; /* PEM0 x8 */
 			else
@@ -1099,10 +1151,10 @@ static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn78xx(int qlm)
 		case 1: /* Either PEM0 x8 or PEM1 x4 */
 		{
 			cvmx_pemx_cfg_t pemx_cfg;
-			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(0));
+			pemx_cfg.u64 = cvmx_read_csr_node(node, CVMX_PEMX_CFG(0));
 			if (pemx_cfg.cn78xx.lanes8)
 				return CVMX_QLM_MODE_DISABLED; /* PEM0 x8 */
-			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(1));
+			pemx_cfg.u64 = cvmx_read_csr_node(node, CVMX_PEMX_CFG(1));
 			if (pemx_cfg.cn78xx.lanes8 == 0)
 				return CVMX_QLM_MODE_PCIE;     /* PEM1 x4 */
 			else
@@ -1111,7 +1163,7 @@ static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn78xx(int qlm)
 		case 2: /* Either PEM2 x4 or PEM2 x8 */
 		{
 			cvmx_pemx_cfg_t pemx_cfg;
-			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(2));
+			pemx_cfg.u64 = cvmx_read_csr_node(node, CVMX_PEMX_CFG(2));
 			if (pemx_cfg.cn78xx.lanes8)
 				return CVMX_QLM_MODE_PCIE_1X8;  /* PEM2 x8 */
 			else
@@ -1120,13 +1172,13 @@ static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn78xx(int qlm)
 		case 3: /* Either PEM2 x8 or PEM3 x4 */
 		{
 			cvmx_pemx_cfg_t pemx_cfg;
-			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(2));
+			pemx_cfg.u64 = cvmx_read_csr_node(node, CVMX_PEMX_CFG(2));
 			if (pemx_cfg.cn78xx.lanes8)
 				return CVMX_QLM_MODE_DISABLED;  /* PEM2 x8 */
 
-			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(3));
+			pemx_cfg.u64 = cvmx_read_csr_node(node, CVMX_PEMX_CFG(3));
 			if (pemx_cfg.cn78xx.lanes8 == 0) {
-				if (cvmx_read_csr(CVMX_PEMX_QLM(3)) == 0)
+				if (cvmx_read_csr_node(node, CVMX_PEMX_QLM(3)) == 0)
 					return CVMX_QLM_MODE_PCIE; /* PEM3 x4 */
 			}
 			return CVMX_QLM_MODE_DISABLED;  /* PEM2 x8 or uses QLM4 */
@@ -1134,9 +1186,9 @@ static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn78xx(int qlm)
 		case 4: /* PEM3 x4 */
 		{
 			cvmx_pemx_cfg_t pemx_cfg;
-			pemx_cfg.u64 = cvmx_read_csr(CVMX_PEMX_CFG(3));
+			pemx_cfg.u64 = cvmx_read_csr_node(node, CVMX_PEMX_CFG(3));
 			if (pemx_cfg.cn78xx.lanes8 == 0) {
-				if (cvmx_read_csr(CVMX_PEMX_QLM(3)))
+				if (cvmx_read_csr_node(node, CVMX_PEMX_QLM(3)))
 					return CVMX_QLM_MODE_PCIE; /* PEM3 x4 */
 			}
 			return CVMX_QLM_MODE_DISABLED;  /* PEM2 x8 or uses QLM3 */
@@ -1148,7 +1200,7 @@ static enum cvmx_qlm_mode __cvmx_qlm_get_mode_cn78xx(int qlm)
 		return CVMX_QLM_MODE_ILK;
 	} else if (gserx_cfg.s.bgx) {
 		cvmx_gserx_lane_mode_t lane_mode;
-		lane_mode.u64 = cvmx_read_csr(CVMX_GSERX_LANE_MODE(qlm));
+		lane_mode.u64 = cvmx_read_csr_node(node, CVMX_GSERX_LANE_MODE(qlm));
 		switch(lane_mode.s.lmode) {
 		case 0x0: /* R_25G_REFCLK100 */
 		case 0x1: /* R_5G_REFCLK100 */
@@ -1189,7 +1241,7 @@ enum cvmx_qlm_mode cvmx_qlm_get_mode(int qlm)
 	else if (OCTEON_IS_MODEL(OCTEON_CN70XX))
 		return __cvmx_qlm_get_mode_cn70xx(qlm);
 	else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-		return __cvmx_qlm_get_mode_cn78xx(qlm);
+		return cvmx_qlm_get_mode_cn78xx(cvmx_get_node_num(), qlm);
 
 	return CVMX_QLM_MODE_DISABLED;
 }
diff --git a/arch/mips/cavium-octeon/executive/cvmx-sso-resources.c b/arch/mips/cavium-octeon/executive/cvmx-sso-resources.c
new file mode 100644
index 0000000..852950b
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-sso-resources.c
@@ -0,0 +1,107 @@
+/***********************license start***************
+ * Copyright (c) 2014  Cavium Inc. (support@cavium.com). All rights
+ * reserved.
+ *
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *
+ *   * Redistributions in binary form must reproduce the above
+ *     copyright notice, this list of conditions and the following
+ *     disclaimer in the documentation and/or other materials provided
+ *     with the distribution.
+
+ *   * Neither the name of Cavium Inc. nor the names of
+ *     its contributors may be used to endorse or promote products
+ *     derived from this software without specific prior written
+ *     permission.
+
+ * This Software, including technical data, may be subject to U.S. export  control
+ * laws, including the U.S. Export Administration Act and its  associated
+ * regulations, and may be subject to export or import  regulations in other
+ * countries.
+
+ * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+ * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS OR
+ * WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH RESPECT TO
+ * THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY REPRESENTATION OR
+ * DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT DEFECTS, AND CAVIUM
+ * SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES OF TITLE,
+ * MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR PURPOSE, LACK OF
+ * VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET POSSESSION OR
+ * CORRESPONDENCE TO DESCRIPTION. THE ENTIRE  RISK ARISING OUT OF USE OR
+ * PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+ ***********************license end**************************************/
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/octeon.h>
+#include <asm/octeon/cvmx-pow.h>
+#include <asm/octeon/cvmx-global-resources.h>
+#else
+#include "cvmx.h"
+#include "cvmx-pow.h"
+#include "cvmx-global-resources.h"
+#endif
+
+static struct global_resource_tag get_sso_resource_tag(int node)
+{
+	switch(node) {
+	case 0:
+		return cvmx_get_gr_tag('c','v','m','_','s','s','o','_','0','0','.','.','.','.','.','.');
+	case 1:
+		return cvmx_get_gr_tag('c','v','m','_','s','s','o','_','0','1','.','.','.','.','.','.');
+	case 2:
+		return cvmx_get_gr_tag('c','v','m','_','s','s','o','_','0','2','.','.','.','.','.','.');
+	case 3:
+		return cvmx_get_gr_tag('c','v','m','_','s','s','o','_','0','3','.','.','.','.','.','.');
+	default:
+		/* Add a panic?? */
+		return cvmx_get_gr_tag('i','n','v','a','l','i','d','.','.','.','.','.','.','.','.','.');
+	}
+}
+
+int cvmx_sso_allocate_groups(int node, int groups_allocated[], int count)
+{
+	int num_grp;
+	int rv = -1;
+	uint64_t owner = 0;
+	struct global_resource_tag tag = get_sso_resource_tag(node);
+
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
+		num_grp = 256;
+	else if (OCTEON_IS_MODEL(OCTEON_CN68XX))
+		num_grp = 64;
+	else
+		num_grp = 16;
+
+	if (cvmx_create_global_resource_range(tag, num_grp) != 0) {
+		cvmx_dprintf("ERROR: failed to create sso global resource for node=%d\n", node);
+		return -1;
+	}
+
+	if (groups_allocated[0] >= 0) {
+		while (count--) {
+			rv = cvmx_reserve_global_resource_range(tag, owner, groups_allocated[count], 1);
+			if (!rv)
+				return CVMX_RESOURCE_ALREADY_RESERVED;
+		}
+	} else {
+		rv = cvmx_resource_alloc_many(tag, owner, count, groups_allocated);
+	}
+	return rv;
+}
+EXPORT_SYMBOL(cvmx_sso_allocate_groups);
+
+int cvmx_sso_allocate_group(int node)
+{
+	int r;
+	int grp = -1;
+
+	r = cvmx_sso_allocate_groups(node, &grp, 1);
+
+	return r == 0 ? grp : -1;
+}
+EXPORT_SYMBOL(cvmx_sso_allocate_group);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-twsi.c b/arch/mips/cavium-octeon/executive/cvmx-twsi.c
index 4d17302..81aaefe 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-twsi.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-twsi.c
@@ -42,16 +42,19 @@
  *
  * Interface to the TWSI / I2C bus
  *
- * <hr>$Revision: 78551 $<hr>
+ * <hr>$Revision: 96709 $<hr>
  *
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+
 #include <linux/export.h>
 #include <linux/i2c.h>
 
 #include <asm/octeon/octeon.h>
 #include <asm/octeon/cvmx-twsi.h>
-#else
+
+#else /* #ifdef CVMX_BUILD_FOR_LINUX_KERNEL */
+
 #include "cvmx.h"
 #include "cvmx-twsi.h"
 #include "cvmx-csr-db.h"
@@ -65,7 +68,11 @@
 #define twsi_printf(...)
 #define cvmx_csr_db_decode(...)
 #endif /*PRINT_TWSI_CONFIG */
-#endif
+
+#define node_bus_to_i2c_bus(node,bus)	((node << 1) | bus)
+#define i2c_bus_to_node(i2c_bus)	((i2c_bus >> 1) & 0x3)
+
+#endif /* #ifdef CVMX_BUILD_FOR_LINUX_KERNEL */
 
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 struct i2c_adapter *__cvmx_twsix_get_adapter(int twsi_id)
@@ -96,29 +103,36 @@ int cvmx_twsix_unblock(int twsi_id)
 	int i;
 
 	/* Put the bus in low-level mode */
-	old_sw_twsi = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id));
+	old_sw_twsi = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+					 CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1));
 	sw_twsi.u64 = 0;
 	sw_twsi.s.v = 1;
 	sw_twsi.s.op = 6;
 	sw_twsi.s.eop_ia = TWSI_CTL;
 	sw_twsi.s.d = 0x40;	/* ENAB !CE !AAK */
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi.u64);
 	cvmx_wait_usec(10);
-	tws_int.u64 = cvmx_read_csr(CVMX_MIO_TWSX_INT(twsi_id));
+	tws_int.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+					 CVMX_MIO_TWSX_INT(twsi_id & 1));
 	cvmx_wait_usec(10);
 	tws_int.s.scl_ovr = 0;
-	cvmx_write_csr(CVMX_MIO_TWSX_INT(twsi_id), tws_int.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_INT(twsi_id & 1), tws_int.u64);
 	cvmx_wait_usec(10);
 	for (i = 0; i < 9; i++) {
 		tws_int.s.scl_ovr = 1;
-		cvmx_write_csr(CVMX_MIO_TWSX_INT(twsi_id), tws_int.u64);
+		cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+				    CVMX_MIO_TWSX_INT(twsi_id & 1), tws_int.u64);
 		cvmx_wait_usec(10);
 		tws_int.s.scl_ovr = 0;
-		cvmx_write_csr(CVMX_MIO_TWSX_INT(twsi_id), tws_int.u64);
+		cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+				    CVMX_MIO_TWSX_INT(twsi_id & 1), tws_int.u64);
 		cvmx_wait_usec(10);
 	}
 	/* Restore back to high level mode */
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id), old_sw_twsi);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), old_sw_twsi);
 	cvmx_wait_usec(10);
 	return 0;
 }
@@ -141,7 +155,8 @@ int cvmx_twsix_unblock(int twsi_id)
  *         Number of bytes read on success
  *         -1 on failure
  */
-int cvmx_twsix_read_ia(int twsi_id, uint8_t dev_addr, uint16_t internal_addr, int num_bytes, int ia_width_bytes, uint64_t * data)
+int cvmx_twsix_read_ia(int twsi_id, uint8_t dev_addr, uint16_t internal_addr, 
+		       int num_bytes, int ia_width_bytes, uint64_t * data)
 {
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 	struct i2c_adapter *adapter;
@@ -193,7 +208,8 @@ int cvmx_twsix_read_ia(int twsi_id, uint8_t dev_addr, uint16_t internal_addr, in
 	int retry_limit = 5;
 	int count = TWSI_TIMEOUT;
 
-	if (num_bytes < 1 || num_bytes > 8 || !data || ia_width_bytes < 0 || ia_width_bytes > 2)
+	if (num_bytes < 1 || num_bytes > 8 || !data 
+		|| ia_width_bytes < 0 || ia_width_bytes > 2)
 		return -1;
 retry:
 	twsi_ext.u64 = 0;
@@ -212,13 +228,18 @@ retry:
 	if (ia_width_bytes == 2) {
 		sw_twsi_val.s.eia = 1;
 		twsi_ext.s.ia = internal_addr >> 8;
-		cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id), twsi_ext.u64);
+		cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+				    CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id & 1), 
+				    twsi_ext.u64);
 	}
 
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
 	while ((((cvmx_mio_twsx_sw_twsi_t)
-		(sw_twsi_val.u64 = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id)))).s.v)
+		(sw_twsi_val.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+				     CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1)))).s.v)
 	       && --count > 0)
 		cvmx_wait_usec(10);
 	if (count <= 0) {
@@ -230,7 +251,8 @@ retry:
 		return -1;
 	}
 	twsi_printf("Results:\n");
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
 	if (!sw_twsi_val.s.r) {
 		/* Check the reason for the failure.  We may need to retry to handle multi-master
 		 ** configurations.
@@ -242,7 +264,11 @@ retry:
 		    || sw_twsi_val.s.d == 0xB0
 		    || sw_twsi_val.s.d == 0x78
 		    || sw_twsi_val.s.d == 0x80
-		    || sw_twsi_val.s.d == 0x88 || sw_twsi_val.s.d == 0xA0 || sw_twsi_val.s.d == 0xA8 || sw_twsi_val.s.d == 0xB8 || sw_twsi_val.s.d == 0xC8) {
+		    || sw_twsi_val.s.d == 0x88 
+		    || sw_twsi_val.s.d == 0xA0 
+		    || sw_twsi_val.s.d == 0xA8 
+		    || sw_twsi_val.s.d == 0xB8 
+		    || sw_twsi_val.s.d == 0xC8) {
 			if (retry_limit-- > 0) {
 				cvmx_wait_usec(100);
 				goto retry;
@@ -255,7 +281,8 @@ retry:
 
 	if (num_bytes > 4) {
 		*data = (sw_twsi_val.s.d & 0xFFFFFFFF);
-		twsi_ext.u64 = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id));
+		twsi_ext.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+						  CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id & 1));
 		*data |= ((unsigned long long)(twsi_ext.s.d & (0xFFFFFFFF >> (32 - (num_bytes-4) * 8))) << 32);
 	} else {
 		*data = (sw_twsi_val.s.d & (0xFFFFFFFF >> (32 - num_bytes * 8)));
@@ -328,10 +355,13 @@ retry:
 	sw_twsi_val.s.sovr = 1;
 	sw_twsi_val.s.size = num_bytes - 1;
 
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
 	while (((cvmx_mio_twsx_sw_twsi_t)
-		(sw_twsi_val.u64 = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id)))).s.v
+		(sw_twsi_val.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+						      CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1)))).s.v
 	       && --count > 0)
 		cvmx_wait_usec(10);
 	if (count <= 0) {
@@ -343,7 +373,8 @@ retry:
 		return -1;
 	}
 	twsi_printf("Results:\n");
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
 	if (!sw_twsi_val.s.r)
 		if (!sw_twsi_val.s.r) {
 			/* Check the reason for the failure.  We may need to retry to handle multi-master
@@ -356,7 +387,11 @@ retry:
 			    || sw_twsi_val.s.d == 0xB0
 			    || sw_twsi_val.s.d == 0x78
 			    || sw_twsi_val.s.d == 0x80
-			    || sw_twsi_val.s.d == 0x88 || sw_twsi_val.s.d == 0xA0 || sw_twsi_val.s.d == 0xA8 || sw_twsi_val.s.d == 0xB8 || sw_twsi_val.s.d == 0xC8) {
+			    || sw_twsi_val.s.d == 0x88 
+			    || sw_twsi_val.s.d == 0xA0 
+			    || sw_twsi_val.s.d == 0xA8 
+			    || sw_twsi_val.s.d == 0xB8 
+			    || sw_twsi_val.s.d == 0xC8) {
 				if (retry_limit-- > 0) {
 					cvmx_wait_usec(100);
 					goto retry;
@@ -368,7 +403,8 @@ retry:
 
 	if (num_bytes > 4) {
 		*data = (sw_twsi_val.s.d & 0xFFFFFFFF);
-		twsi_ext.u64 = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id));
+		twsi_ext.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+						  CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id & 1));
 		*data |= ((unsigned long long)(twsi_ext.s.d & (0xFFFFFFFF >> (32 - (num_bytes-4) * 8))) << 32);
 	} else {
 		*data = (sw_twsi_val.s.d & (0xFFFFFFFF >> (32 - num_bytes * 8)));
@@ -446,11 +482,16 @@ retry:
 		cvmx_mio_twsx_sw_twsi_ext_t twsi_ext;
 		twsi_ext.u64 = 0;
 		twsi_ext.s.d = data >> 32;
-		cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id), twsi_ext.u64);
+		cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+				    CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id & 1), twsi_ext.u64);
 	}
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
-	while (((cvmx_mio_twsx_sw_twsi_t) (sw_twsi_val.u64 = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id)))).s.v
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
+	while (((cvmx_mio_twsx_sw_twsi_t) 
+		(sw_twsi_val.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+						      CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1)))).s.v
 	       && --count > 0)
 		cvmx_wait_usec(10);
 	if (count <= 0) {
@@ -458,7 +499,8 @@ retry:
 		goto retry;
 	}
 	twsi_printf("Results:\n");
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
 	if (!sw_twsi_val.s.r)
 		return -1;
 
@@ -483,7 +525,8 @@ retry:
  * @return Number of bytes read on success,
  *         -1 on error
  */
-int cvmx_twsix_write_ia(int twsi_id, uint8_t dev_addr, uint16_t internal_addr, int num_bytes, int ia_width_bytes, uint64_t data)
+int cvmx_twsix_write_ia(int twsi_id, uint8_t dev_addr, uint16_t internal_addr, 
+			int num_bytes, int ia_width_bytes, uint64_t data)
 {
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 	struct i2c_adapter *adapter;
@@ -567,14 +610,21 @@ retry:
 	if (num_bytes > 4)
 		twsi_ext.s.d = data >> 32;
 
-	twsi_printf("%s: twsi_id=%x, dev_addr=%x, internal_addr=%x\n\tnum_bytes=%d, ia_width_bytes=%d, data=%lx\n",
-		    __func__, twsi_id, dev_addr, internal_addr, num_bytes, ia_width_bytes, data);
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id), twsi_ext.u64);
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id), twsi_ext.u64);
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	twsi_printf("%s: twsi_id=%x, dev_addr=%x, internal_addr=%x\n"
+			"\tnum_bytes=%d, ia_width_bytes=%d, data=%lx\n",
+			__func__, twsi_id, dev_addr, internal_addr, 
+			num_bytes, ia_width_bytes, data);
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id & 1), twsi_ext.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI_EXT(twsi_id & 1), twsi_ext.u64);
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
 	while (((cvmx_mio_twsx_sw_twsi_t)
-	        (sw_twsi_val.u64 = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id)))).s.v
+	        (sw_twsi_val.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+						      CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1)))).s.v
 	       && --count > 0)
 		cvmx_wait_usec(10);
 	if (count <= 0) {
@@ -587,8 +637,9 @@ retry:
 	}
 
 	twsi_printf("Results:\n");
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
-	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	cvmx_csr_db_decode(cvmx_get_proc_id(), 
+			   CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
+/*	cvmx_csr_db_decode(cvmx_get_proc_id(), CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64); */
 	if (!sw_twsi_val.s.r) {
 		/* Check the reason for the failure.  We may need to retry to handle multi-master
 		 ** configurations.
@@ -600,7 +651,11 @@ retry:
 		    || sw_twsi_val.s.d == 0xB0
 		    || sw_twsi_val.s.d == 0x78
 		    || sw_twsi_val.s.d == 0x80
-		    || sw_twsi_val.s.d == 0x88 || sw_twsi_val.s.d == 0xA0 || sw_twsi_val.s.d == 0xA8 || sw_twsi_val.s.d == 0xB8 || sw_twsi_val.s.d == 0xC8) {
+		    || sw_twsi_val.s.d == 0x88 
+		    || sw_twsi_val.s.d == 0xA0 
+		    || sw_twsi_val.s.d == 0xA8 
+		    || sw_twsi_val.s.d == 0xB8 
+		    || sw_twsi_val.s.d == 0xC8) {
 			if (retry_limit-- > 0) {
 				cvmx_wait_usec(100);
 				goto retry;
@@ -660,10 +715,12 @@ static void cvmx_twsix_write_llc_reg(int twsi_id, uint8_t eop_reg, uint8_t data)
 	sw_twsi_val.s.op = 6;
 	sw_twsi_val.s.eop_ia = eop_reg;
 	sw_twsi_val.s.d = data;
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
 
 	do {
-		tmp.u64 = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id));
+		tmp.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+					     CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1));
 	} while (tmp.s.v != 0);
 }
 
@@ -676,10 +733,12 @@ static uint8_t cvmx_twsix_read_llc_reg(int twsi_id, uint8_t eop_reg)
 	sw_twsi_val.s.op = 6;
 	sw_twsi_val.s.eop_ia = eop_reg;
 	sw_twsi_val.s.r = 1;
-	cvmx_write_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id), sw_twsi_val.u64);
+	cvmx_write_csr_node(i2c_bus_to_node(twsi_id), 
+			    CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1), sw_twsi_val.u64);
 
 	do {
-		tmp.u64 = cvmx_read_csr(CVMX_MIO_TWSX_SW_TWSI(twsi_id));
+		tmp.u64 = cvmx_read_csr_node(i2c_bus_to_node(twsi_id), 
+					     CVMX_MIO_TWSX_SW_TWSI(twsi_id & 1));
 	} while (tmp.s.v != 0);
 
 	return tmp.s.d & 0xff;
diff --git a/arch/mips/cavium-octeon/executive/octeon-model.c b/arch/mips/cavium-octeon/executive/octeon-model.c
index 9b1d3e4..d5f7f94 100644
--- a/arch/mips/cavium-octeon/executive/octeon-model.c
+++ b/arch/mips/cavium-octeon/executive/octeon-model.c
@@ -43,7 +43,7 @@
  * File defining functions for working with different Octeon
  * models.
  *
- * <hr>$Revision: 93822 $<hr>
+ * <hr>$Revision: 95860 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/octeon.h>
@@ -147,10 +147,7 @@ const char *octeon_model_get_string_buffer(uint32_t chip_id, char *buffer)
 		fus3.u64 = cvmx_read_csr(CVMX_L2D_FUS3);
 	fus_dat2.u64 = cvmx_read_csr(CVMX_MIO_FUS_DAT2);
 	fus_dat3.u64 = cvmx_read_csr(CVMX_MIO_FUS_DAT3);
-	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-		num_cores = cvmx_pop(cvmx_read_csr(CVMX_CIU3_FUSE));
-	else
-		num_cores = cvmx_pop(cvmx_read_csr(CVMX_CIU_FUSE));
+	num_cores = cvmx_pop(cvmx_read_csr(CVMX_CIU_FUSE));
 
 	/* Make sure the non existent devices look disabled */
 	switch ((chip_id >> 8) & 0xff) {
@@ -352,7 +349,7 @@ const char *octeon_model_get_string_buffer(uint32_t chip_id, char *buffer)
 				if (fus_dat3.s.nozip)
 					suffix = "SCP";
 
-				if (fus_dat3.s.bar2_en)
+				if (fus_dat3.cn56xx.bar2_en)
 					suffix = "NSPB2";
 			}
 			if (fus3.cn56xx.crip_1024k)
@@ -466,7 +463,7 @@ const char *octeon_model_get_string_buffer(uint32_t chip_id, char *buffer)
 	if (family[0] != '3') {
 		if (OCTEON_IS_OCTEON1PLUS() || OCTEON_IS_OCTEON2()) {
 			int fuse_base = 384 / 8;
-			if (family[0] == '6' || OCTEON_IS_OCTEON3())
+			if (family[0] == '6')
 				fuse_base = 832 / 8;
 			/* Check for model in fuses, overrides normal decode */
 			/* This is _not_ valid for Octeon CN3XXX models */
diff --git a/arch/mips/include/asm/octeon/cvmx-agl-defs.h b/arch/mips/include/asm/octeon/cvmx-agl-defs.h
index e0a11f8..4874fab 100644
--- a/arch/mips/include/asm/octeon/cvmx-agl-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-agl-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1333,6 +1333,7 @@ union cvmx_agl_gmx_bad_reg {
 	struct cvmx_agl_gmx_bad_reg_s         cn68xx;
 	struct cvmx_agl_gmx_bad_reg_s         cn68xxp1;
 	struct cvmx_agl_gmx_bad_reg_cn56xx    cn70xx;
+	struct cvmx_agl_gmx_bad_reg_cn56xx    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_bad_reg cvmx_agl_gmx_bad_reg_t;
 
@@ -1413,6 +1414,7 @@ union cvmx_agl_gmx_bist {
 	struct cvmx_agl_gmx_bist_s            cn68xx;
 	struct cvmx_agl_gmx_bist_s            cn68xxp1;
 	struct cvmx_agl_gmx_bist_s            cn70xx;
+	struct cvmx_agl_gmx_bist_s            cn70xxp1;
 };
 typedef union cvmx_agl_gmx_bist cvmx_agl_gmx_bist_t;
 
@@ -1629,6 +1631,7 @@ union cvmx_agl_gmx_prtx_cfg {
 	struct cvmx_agl_gmx_prtx_cfg_s        cn68xx;
 	struct cvmx_agl_gmx_prtx_cfg_s        cn68xxp1;
 	struct cvmx_agl_gmx_prtx_cfg_s        cn70xx;
+	struct cvmx_agl_gmx_prtx_cfg_s        cn70xxp1;
 };
 typedef union cvmx_agl_gmx_prtx_cfg cvmx_agl_gmx_prtx_cfg_t;
 
@@ -1661,6 +1664,7 @@ union cvmx_agl_gmx_rxx_adr_cam0 {
 	struct cvmx_agl_gmx_rxx_adr_cam0_s    cn68xx;
 	struct cvmx_agl_gmx_rxx_adr_cam0_s    cn68xxp1;
 	struct cvmx_agl_gmx_rxx_adr_cam0_s    cn70xx;
+	struct cvmx_agl_gmx_rxx_adr_cam0_s    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_adr_cam0 cvmx_agl_gmx_rxx_adr_cam0_t;
 
@@ -1693,6 +1697,7 @@ union cvmx_agl_gmx_rxx_adr_cam1 {
 	struct cvmx_agl_gmx_rxx_adr_cam1_s    cn68xx;
 	struct cvmx_agl_gmx_rxx_adr_cam1_s    cn68xxp1;
 	struct cvmx_agl_gmx_rxx_adr_cam1_s    cn70xx;
+	struct cvmx_agl_gmx_rxx_adr_cam1_s    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_adr_cam1 cvmx_agl_gmx_rxx_adr_cam1_t;
 
@@ -1725,6 +1730,7 @@ union cvmx_agl_gmx_rxx_adr_cam2 {
 	struct cvmx_agl_gmx_rxx_adr_cam2_s    cn68xx;
 	struct cvmx_agl_gmx_rxx_adr_cam2_s    cn68xxp1;
 	struct cvmx_agl_gmx_rxx_adr_cam2_s    cn70xx;
+	struct cvmx_agl_gmx_rxx_adr_cam2_s    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_adr_cam2 cvmx_agl_gmx_rxx_adr_cam2_t;
 
@@ -1757,6 +1763,7 @@ union cvmx_agl_gmx_rxx_adr_cam3 {
 	struct cvmx_agl_gmx_rxx_adr_cam3_s    cn68xx;
 	struct cvmx_agl_gmx_rxx_adr_cam3_s    cn68xxp1;
 	struct cvmx_agl_gmx_rxx_adr_cam3_s    cn70xx;
+	struct cvmx_agl_gmx_rxx_adr_cam3_s    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_adr_cam3 cvmx_agl_gmx_rxx_adr_cam3_t;
 
@@ -1789,6 +1796,7 @@ union cvmx_agl_gmx_rxx_adr_cam4 {
 	struct cvmx_agl_gmx_rxx_adr_cam4_s    cn68xx;
 	struct cvmx_agl_gmx_rxx_adr_cam4_s    cn68xxp1;
 	struct cvmx_agl_gmx_rxx_adr_cam4_s    cn70xx;
+	struct cvmx_agl_gmx_rxx_adr_cam4_s    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_adr_cam4 cvmx_agl_gmx_rxx_adr_cam4_t;
 
@@ -1821,6 +1829,7 @@ union cvmx_agl_gmx_rxx_adr_cam5 {
 	struct cvmx_agl_gmx_rxx_adr_cam5_s    cn68xx;
 	struct cvmx_agl_gmx_rxx_adr_cam5_s    cn68xxp1;
 	struct cvmx_agl_gmx_rxx_adr_cam5_s    cn70xx;
+	struct cvmx_agl_gmx_rxx_adr_cam5_s    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_adr_cam5 cvmx_agl_gmx_rxx_adr_cam5_t;
 
@@ -1856,6 +1865,7 @@ union cvmx_agl_gmx_rxx_adr_cam_en {
 	struct cvmx_agl_gmx_rxx_adr_cam_en_s  cn68xx;
 	struct cvmx_agl_gmx_rxx_adr_cam_en_s  cn68xxp1;
 	struct cvmx_agl_gmx_rxx_adr_cam_en_s  cn70xx;
+	struct cvmx_agl_gmx_rxx_adr_cam_en_s  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_adr_cam_en cvmx_agl_gmx_rxx_adr_cam_en_t;
 
@@ -1935,6 +1945,7 @@ union cvmx_agl_gmx_rxx_adr_ctl {
 	struct cvmx_agl_gmx_rxx_adr_ctl_s     cn68xx;
 	struct cvmx_agl_gmx_rxx_adr_ctl_s     cn68xxp1;
 	struct cvmx_agl_gmx_rxx_adr_ctl_s     cn70xx;
+	struct cvmx_agl_gmx_rxx_adr_ctl_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_adr_ctl cvmx_agl_gmx_rxx_adr_ctl_t;
 
@@ -1990,6 +2001,7 @@ union cvmx_agl_gmx_rxx_decision {
 	struct cvmx_agl_gmx_rxx_decision_s    cn68xx;
 	struct cvmx_agl_gmx_rxx_decision_s    cn68xxp1;
 	struct cvmx_agl_gmx_rxx_decision_s    cn70xx;
+	struct cvmx_agl_gmx_rxx_decision_s    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_decision cvmx_agl_gmx_rxx_decision_t;
 
@@ -2070,6 +2082,7 @@ union cvmx_agl_gmx_rxx_frm_chk {
 	struct cvmx_agl_gmx_rxx_frm_chk_s     cn68xx;
 	struct cvmx_agl_gmx_rxx_frm_chk_s     cn68xxp1;
 	struct cvmx_agl_gmx_rxx_frm_chk_s     cn70xx;
+	struct cvmx_agl_gmx_rxx_frm_chk_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_frm_chk cvmx_agl_gmx_rxx_frm_chk_t;
 
@@ -2228,6 +2241,7 @@ union cvmx_agl_gmx_rxx_frm_ctl {
 	struct cvmx_agl_gmx_rxx_frm_ctl_s     cn68xx;
 	struct cvmx_agl_gmx_rxx_frm_ctl_s     cn68xxp1;
 	struct cvmx_agl_gmx_rxx_frm_ctl_s     cn70xx;
+	struct cvmx_agl_gmx_rxx_frm_ctl_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_frm_ctl cvmx_agl_gmx_rxx_frm_ctl_t;
 
@@ -2276,6 +2290,7 @@ union cvmx_agl_gmx_rxx_frm_max {
 	struct cvmx_agl_gmx_rxx_frm_max_s     cn68xx;
 	struct cvmx_agl_gmx_rxx_frm_max_s     cn68xxp1;
 	struct cvmx_agl_gmx_rxx_frm_max_s     cn70xx;
+	struct cvmx_agl_gmx_rxx_frm_max_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_frm_max cvmx_agl_gmx_rxx_frm_max_t;
 
@@ -2317,6 +2332,7 @@ union cvmx_agl_gmx_rxx_frm_min {
 	struct cvmx_agl_gmx_rxx_frm_min_s     cn68xx;
 	struct cvmx_agl_gmx_rxx_frm_min_s     cn68xxp1;
 	struct cvmx_agl_gmx_rxx_frm_min_s     cn70xx;
+	struct cvmx_agl_gmx_rxx_frm_min_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_frm_min cvmx_agl_gmx_rxx_frm_min_t;
 
@@ -2358,6 +2374,7 @@ union cvmx_agl_gmx_rxx_ifg {
 	struct cvmx_agl_gmx_rxx_ifg_s         cn68xx;
 	struct cvmx_agl_gmx_rxx_ifg_s         cn68xxp1;
 	struct cvmx_agl_gmx_rxx_ifg_s         cn70xx;
+	struct cvmx_agl_gmx_rxx_ifg_s         cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_ifg cvmx_agl_gmx_rxx_ifg_t;
 
@@ -2523,6 +2540,7 @@ union cvmx_agl_gmx_rxx_int_en {
 	struct cvmx_agl_gmx_rxx_int_en_cn61xx cn68xx;
 	struct cvmx_agl_gmx_rxx_int_en_cn61xx cn68xxp1;
 	struct cvmx_agl_gmx_rxx_int_en_s      cn70xx;
+	struct cvmx_agl_gmx_rxx_int_en_s      cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_int_en cvmx_agl_gmx_rxx_int_en_t;
 
@@ -2746,6 +2764,7 @@ union cvmx_agl_gmx_rxx_int_reg {
 	struct cvmx_agl_gmx_rxx_int_reg_cn61xx cn68xx;
 	struct cvmx_agl_gmx_rxx_int_reg_cn61xx cn68xxp1;
 	struct cvmx_agl_gmx_rxx_int_reg_s     cn70xx;
+	struct cvmx_agl_gmx_rxx_int_reg_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_int_reg cvmx_agl_gmx_rxx_int_reg_t;
 
@@ -2798,6 +2817,7 @@ union cvmx_agl_gmx_rxx_jabber {
 	struct cvmx_agl_gmx_rxx_jabber_s      cn68xx;
 	struct cvmx_agl_gmx_rxx_jabber_s      cn68xxp1;
 	struct cvmx_agl_gmx_rxx_jabber_s      cn70xx;
+	struct cvmx_agl_gmx_rxx_jabber_s      cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_jabber cvmx_agl_gmx_rxx_jabber_t;
 
@@ -2833,6 +2853,7 @@ union cvmx_agl_gmx_rxx_pause_drop_time {
 	struct cvmx_agl_gmx_rxx_pause_drop_time_s cn68xx;
 	struct cvmx_agl_gmx_rxx_pause_drop_time_s cn68xxp1;
 	struct cvmx_agl_gmx_rxx_pause_drop_time_s cn70xx;
+	struct cvmx_agl_gmx_rxx_pause_drop_time_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_pause_drop_time cvmx_agl_gmx_rxx_pause_drop_time_t;
 
@@ -2872,6 +2893,7 @@ union cvmx_agl_gmx_rxx_rx_inbnd {
 	struct cvmx_agl_gmx_rxx_rx_inbnd_s    cn68xx;
 	struct cvmx_agl_gmx_rxx_rx_inbnd_s    cn68xxp1;
 	struct cvmx_agl_gmx_rxx_rx_inbnd_s    cn70xx;
+	struct cvmx_agl_gmx_rxx_rx_inbnd_s    cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_rx_inbnd cvmx_agl_gmx_rxx_rx_inbnd_t;
 
@@ -2907,6 +2929,7 @@ union cvmx_agl_gmx_rxx_stats_ctl {
 	struct cvmx_agl_gmx_rxx_stats_ctl_s   cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_ctl_s   cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_ctl_s   cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_ctl_s   cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_ctl cvmx_agl_gmx_rxx_stats_ctl_t;
 
@@ -2940,6 +2963,7 @@ union cvmx_agl_gmx_rxx_stats_octs {
 	struct cvmx_agl_gmx_rxx_stats_octs_s  cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_octs_s  cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_octs_s  cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_octs_s  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_octs cvmx_agl_gmx_rxx_stats_octs_t;
 
@@ -2973,6 +2997,7 @@ union cvmx_agl_gmx_rxx_stats_octs_ctl {
 	struct cvmx_agl_gmx_rxx_stats_octs_ctl_s cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_octs_ctl_s cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_octs_ctl_s cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_octs_ctl_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_octs_ctl cvmx_agl_gmx_rxx_stats_octs_ctl_t;
 
@@ -3006,6 +3031,7 @@ union cvmx_agl_gmx_rxx_stats_octs_dmac {
 	struct cvmx_agl_gmx_rxx_stats_octs_dmac_s cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_octs_dmac_s cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_octs_dmac_s cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_octs_dmac_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_octs_dmac cvmx_agl_gmx_rxx_stats_octs_dmac_t;
 
@@ -3039,6 +3065,7 @@ union cvmx_agl_gmx_rxx_stats_octs_drp {
 	struct cvmx_agl_gmx_rxx_stats_octs_drp_s cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_octs_drp_s cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_octs_drp_s cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_octs_drp_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_octs_drp cvmx_agl_gmx_rxx_stats_octs_drp_t;
 
@@ -3071,6 +3098,7 @@ union cvmx_agl_gmx_rxx_stats_pkts {
 	struct cvmx_agl_gmx_rxx_stats_pkts_s  cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_pkts_s  cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_pkts_s  cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_pkts_s  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_pkts cvmx_agl_gmx_rxx_stats_pkts_t;
 
@@ -3102,6 +3130,7 @@ union cvmx_agl_gmx_rxx_stats_pkts_bad {
 	struct cvmx_agl_gmx_rxx_stats_pkts_bad_s cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_pkts_bad_s cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_pkts_bad_s cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_pkts_bad_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_pkts_bad cvmx_agl_gmx_rxx_stats_pkts_bad_t;
 
@@ -3138,6 +3167,7 @@ union cvmx_agl_gmx_rxx_stats_pkts_ctl {
 	struct cvmx_agl_gmx_rxx_stats_pkts_ctl_s cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_pkts_ctl_s cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_pkts_ctl_s cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_pkts_ctl_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_pkts_ctl cvmx_agl_gmx_rxx_stats_pkts_ctl_t;
 
@@ -3174,6 +3204,7 @@ union cvmx_agl_gmx_rxx_stats_pkts_dmac {
 	struct cvmx_agl_gmx_rxx_stats_pkts_dmac_s cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_pkts_dmac_s cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_pkts_dmac_s cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_pkts_dmac_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_pkts_dmac cvmx_agl_gmx_rxx_stats_pkts_dmac_t;
 
@@ -3207,6 +3238,7 @@ union cvmx_agl_gmx_rxx_stats_pkts_drp {
 	struct cvmx_agl_gmx_rxx_stats_pkts_drp_s cn68xx;
 	struct cvmx_agl_gmx_rxx_stats_pkts_drp_s cn68xxp1;
 	struct cvmx_agl_gmx_rxx_stats_pkts_drp_s cn70xx;
+	struct cvmx_agl_gmx_rxx_stats_pkts_drp_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_stats_pkts_drp cvmx_agl_gmx_rxx_stats_pkts_drp_t;
 
@@ -3273,6 +3305,7 @@ union cvmx_agl_gmx_rxx_udd_skp {
 	struct cvmx_agl_gmx_rxx_udd_skp_s     cn68xx;
 	struct cvmx_agl_gmx_rxx_udd_skp_s     cn68xxp1;
 	struct cvmx_agl_gmx_rxx_udd_skp_s     cn70xx;
+	struct cvmx_agl_gmx_rxx_udd_skp_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rxx_udd_skp cvmx_agl_gmx_rxx_udd_skp_t;
 
@@ -3313,6 +3346,7 @@ union cvmx_agl_gmx_rx_bp_dropx {
 	struct cvmx_agl_gmx_rx_bp_dropx_s     cn68xx;
 	struct cvmx_agl_gmx_rx_bp_dropx_s     cn68xxp1;
 	struct cvmx_agl_gmx_rx_bp_dropx_s     cn70xx;
+	struct cvmx_agl_gmx_rx_bp_dropx_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rx_bp_dropx cvmx_agl_gmx_rx_bp_dropx_t;
 
@@ -3348,6 +3382,7 @@ union cvmx_agl_gmx_rx_bp_offx {
 	struct cvmx_agl_gmx_rx_bp_offx_s      cn68xx;
 	struct cvmx_agl_gmx_rx_bp_offx_s      cn68xxp1;
 	struct cvmx_agl_gmx_rx_bp_offx_s      cn70xx;
+	struct cvmx_agl_gmx_rx_bp_offx_s      cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rx_bp_offx cvmx_agl_gmx_rx_bp_offx_t;
 
@@ -3383,6 +3418,7 @@ union cvmx_agl_gmx_rx_bp_onx {
 	struct cvmx_agl_gmx_rx_bp_onx_s       cn68xx;
 	struct cvmx_agl_gmx_rx_bp_onx_s       cn68xxp1;
 	struct cvmx_agl_gmx_rx_bp_onx_s       cn70xx;
+	struct cvmx_agl_gmx_rx_bp_onx_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rx_bp_onx cvmx_agl_gmx_rx_bp_onx_t;
 
@@ -3434,6 +3470,7 @@ union cvmx_agl_gmx_rx_prt_info {
 	struct cvmx_agl_gmx_rx_prt_info_s     cn68xx;
 	struct cvmx_agl_gmx_rx_prt_info_s     cn68xxp1;
 	struct cvmx_agl_gmx_rx_prt_info_cn56xx cn70xx;
+	struct cvmx_agl_gmx_rx_prt_info_cn56xx cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rx_prt_info cvmx_agl_gmx_rx_prt_info_t;
 
@@ -3485,6 +3522,7 @@ union cvmx_agl_gmx_rx_tx_status {
 	struct cvmx_agl_gmx_rx_tx_status_s    cn68xx;
 	struct cvmx_agl_gmx_rx_tx_status_s    cn68xxp1;
 	struct cvmx_agl_gmx_rx_tx_status_cn56xx cn70xx;
+	struct cvmx_agl_gmx_rx_tx_status_cn56xx cn70xxp1;
 };
 typedef union cvmx_agl_gmx_rx_tx_status cvmx_agl_gmx_rx_tx_status_t;
 
@@ -3521,6 +3559,7 @@ union cvmx_agl_gmx_smacx {
 	struct cvmx_agl_gmx_smacx_s           cn68xx;
 	struct cvmx_agl_gmx_smacx_s           cn68xxp1;
 	struct cvmx_agl_gmx_smacx_s           cn70xx;
+	struct cvmx_agl_gmx_smacx_s           cn70xxp1;
 };
 typedef union cvmx_agl_gmx_smacx cvmx_agl_gmx_smacx_t;
 
@@ -3580,6 +3619,7 @@ union cvmx_agl_gmx_stat_bp {
 	struct cvmx_agl_gmx_stat_bp_s         cn68xx;
 	struct cvmx_agl_gmx_stat_bp_s         cn68xxp1;
 	struct cvmx_agl_gmx_stat_bp_s         cn70xx;
+	struct cvmx_agl_gmx_stat_bp_s         cn70xxp1;
 };
 typedef union cvmx_agl_gmx_stat_bp cvmx_agl_gmx_stat_bp_t;
 
@@ -3625,6 +3665,7 @@ union cvmx_agl_gmx_txx_append {
 	struct cvmx_agl_gmx_txx_append_s      cn68xx;
 	struct cvmx_agl_gmx_txx_append_s      cn68xxp1;
 	struct cvmx_agl_gmx_txx_append_s      cn70xx;
+	struct cvmx_agl_gmx_txx_append_s      cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_append cvmx_agl_gmx_txx_append_t;
 
@@ -3668,6 +3709,7 @@ union cvmx_agl_gmx_txx_clk {
 	struct cvmx_agl_gmx_txx_clk_s         cn68xx;
 	struct cvmx_agl_gmx_txx_clk_s         cn68xxp1;
 	struct cvmx_agl_gmx_txx_clk_s         cn70xx;
+	struct cvmx_agl_gmx_txx_clk_s         cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_clk cvmx_agl_gmx_txx_clk_t;
 
@@ -3707,6 +3749,7 @@ union cvmx_agl_gmx_txx_ctl {
 	struct cvmx_agl_gmx_txx_ctl_s         cn68xx;
 	struct cvmx_agl_gmx_txx_ctl_s         cn68xxp1;
 	struct cvmx_agl_gmx_txx_ctl_s         cn70xx;
+	struct cvmx_agl_gmx_txx_ctl_s         cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_ctl cvmx_agl_gmx_txx_ctl_t;
 
@@ -3746,6 +3789,7 @@ union cvmx_agl_gmx_txx_min_pkt {
 	struct cvmx_agl_gmx_txx_min_pkt_s     cn68xx;
 	struct cvmx_agl_gmx_txx_min_pkt_s     cn68xxp1;
 	struct cvmx_agl_gmx_txx_min_pkt_s     cn70xx;
+	struct cvmx_agl_gmx_txx_min_pkt_s     cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_min_pkt cvmx_agl_gmx_txx_min_pkt_t;
 
@@ -3802,6 +3846,7 @@ union cvmx_agl_gmx_txx_pause_pkt_interval {
 	struct cvmx_agl_gmx_txx_pause_pkt_interval_s cn68xx;
 	struct cvmx_agl_gmx_txx_pause_pkt_interval_s cn68xxp1;
 	struct cvmx_agl_gmx_txx_pause_pkt_interval_s cn70xx;
+	struct cvmx_agl_gmx_txx_pause_pkt_interval_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_pause_pkt_interval cvmx_agl_gmx_txx_pause_pkt_interval_t;
 
@@ -3856,6 +3901,7 @@ union cvmx_agl_gmx_txx_pause_pkt_time {
 	struct cvmx_agl_gmx_txx_pause_pkt_time_s cn68xx;
 	struct cvmx_agl_gmx_txx_pause_pkt_time_s cn68xxp1;
 	struct cvmx_agl_gmx_txx_pause_pkt_time_s cn70xx;
+	struct cvmx_agl_gmx_txx_pause_pkt_time_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_pause_pkt_time cvmx_agl_gmx_txx_pause_pkt_time_t;
 
@@ -3891,6 +3937,7 @@ union cvmx_agl_gmx_txx_pause_togo {
 	struct cvmx_agl_gmx_txx_pause_togo_s  cn68xx;
 	struct cvmx_agl_gmx_txx_pause_togo_s  cn68xxp1;
 	struct cvmx_agl_gmx_txx_pause_togo_s  cn70xx;
+	struct cvmx_agl_gmx_txx_pause_togo_s  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_pause_togo cvmx_agl_gmx_txx_pause_togo_t;
 
@@ -3928,6 +3975,7 @@ union cvmx_agl_gmx_txx_pause_zero {
 	struct cvmx_agl_gmx_txx_pause_zero_s  cn68xx;
 	struct cvmx_agl_gmx_txx_pause_zero_s  cn68xxp1;
 	struct cvmx_agl_gmx_txx_pause_zero_s  cn70xx;
+	struct cvmx_agl_gmx_txx_pause_zero_s  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_pause_zero cvmx_agl_gmx_txx_pause_zero_t;
 
@@ -3964,6 +4012,7 @@ union cvmx_agl_gmx_txx_soft_pause {
 	struct cvmx_agl_gmx_txx_soft_pause_s  cn68xx;
 	struct cvmx_agl_gmx_txx_soft_pause_s  cn68xxp1;
 	struct cvmx_agl_gmx_txx_soft_pause_s  cn70xx;
+	struct cvmx_agl_gmx_txx_soft_pause_s  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_soft_pause cvmx_agl_gmx_txx_soft_pause_t;
 
@@ -4003,6 +4052,7 @@ union cvmx_agl_gmx_txx_stat0 {
 	struct cvmx_agl_gmx_txx_stat0_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat0_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat0_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat0_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat0 cvmx_agl_gmx_txx_stat0_t;
 
@@ -4040,6 +4090,7 @@ union cvmx_agl_gmx_txx_stat1 {
 	struct cvmx_agl_gmx_txx_stat1_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat1_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat1_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat1_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat1 cvmx_agl_gmx_txx_stat1_t;
 
@@ -4081,6 +4132,7 @@ union cvmx_agl_gmx_txx_stat2 {
 	struct cvmx_agl_gmx_txx_stat2_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat2_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat2_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat2_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat2 cvmx_agl_gmx_txx_stat2_t;
 
@@ -4119,6 +4171,7 @@ union cvmx_agl_gmx_txx_stat3 {
 	struct cvmx_agl_gmx_txx_stat3_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat3_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat3_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat3_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat3 cvmx_agl_gmx_txx_stat3_t;
 
@@ -4159,6 +4212,7 @@ union cvmx_agl_gmx_txx_stat4 {
 	struct cvmx_agl_gmx_txx_stat4_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat4_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat4_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat4_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat4 cvmx_agl_gmx_txx_stat4_t;
 
@@ -4200,6 +4254,7 @@ union cvmx_agl_gmx_txx_stat5 {
 	struct cvmx_agl_gmx_txx_stat5_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat5_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat5_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat5_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat5 cvmx_agl_gmx_txx_stat5_t;
 
@@ -4241,6 +4296,7 @@ union cvmx_agl_gmx_txx_stat6 {
 	struct cvmx_agl_gmx_txx_stat6_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat6_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat6_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat6_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat6 cvmx_agl_gmx_txx_stat6_t;
 
@@ -4282,6 +4338,7 @@ union cvmx_agl_gmx_txx_stat7 {
 	struct cvmx_agl_gmx_txx_stat7_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat7_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat7_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat7_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat7 cvmx_agl_gmx_txx_stat7_t;
 
@@ -4325,6 +4382,7 @@ union cvmx_agl_gmx_txx_stat8 {
 	struct cvmx_agl_gmx_txx_stat8_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat8_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat8_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat8_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat8 cvmx_agl_gmx_txx_stat8_t;
 
@@ -4363,6 +4421,7 @@ union cvmx_agl_gmx_txx_stat9 {
 	struct cvmx_agl_gmx_txx_stat9_s       cn68xx;
 	struct cvmx_agl_gmx_txx_stat9_s       cn68xxp1;
 	struct cvmx_agl_gmx_txx_stat9_s       cn70xx;
+	struct cvmx_agl_gmx_txx_stat9_s       cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stat9 cvmx_agl_gmx_txx_stat9_t;
 
@@ -4398,6 +4457,7 @@ union cvmx_agl_gmx_txx_stats_ctl {
 	struct cvmx_agl_gmx_txx_stats_ctl_s   cn68xx;
 	struct cvmx_agl_gmx_txx_stats_ctl_s   cn68xxp1;
 	struct cvmx_agl_gmx_txx_stats_ctl_s   cn70xx;
+	struct cvmx_agl_gmx_txx_stats_ctl_s   cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_stats_ctl cvmx_agl_gmx_txx_stats_ctl_t;
 
@@ -4438,6 +4498,7 @@ union cvmx_agl_gmx_txx_thresh {
 	struct cvmx_agl_gmx_txx_thresh_s      cn68xx;
 	struct cvmx_agl_gmx_txx_thresh_s      cn68xxp1;
 	struct cvmx_agl_gmx_txx_thresh_s      cn70xx;
+	struct cvmx_agl_gmx_txx_thresh_s      cn70xxp1;
 };
 typedef union cvmx_agl_gmx_txx_thresh cvmx_agl_gmx_txx_thresh_t;
 
@@ -4485,6 +4546,7 @@ union cvmx_agl_gmx_tx_bp {
 	struct cvmx_agl_gmx_tx_bp_s           cn68xx;
 	struct cvmx_agl_gmx_tx_bp_s           cn68xxp1;
 	struct cvmx_agl_gmx_tx_bp_cn56xx      cn70xx;
+	struct cvmx_agl_gmx_tx_bp_cn56xx      cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_bp cvmx_agl_gmx_tx_bp_t;
 
@@ -4520,6 +4582,7 @@ union cvmx_agl_gmx_tx_col_attempt {
 	struct cvmx_agl_gmx_tx_col_attempt_s  cn68xx;
 	struct cvmx_agl_gmx_tx_col_attempt_s  cn68xxp1;
 	struct cvmx_agl_gmx_tx_col_attempt_s  cn70xx;
+	struct cvmx_agl_gmx_tx_col_attempt_s  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_col_attempt cvmx_agl_gmx_tx_col_attempt_t;
 
@@ -4569,6 +4632,7 @@ union cvmx_agl_gmx_tx_ifg {
 	struct cvmx_agl_gmx_tx_ifg_s          cn68xx;
 	struct cvmx_agl_gmx_tx_ifg_s          cn68xxp1;
 	struct cvmx_agl_gmx_tx_ifg_s          cn70xx;
+	struct cvmx_agl_gmx_tx_ifg_s          cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_ifg cvmx_agl_gmx_tx_ifg_t;
 
@@ -4703,6 +4767,7 @@ union cvmx_agl_gmx_tx_int_en {
 	uint64_t reserved_21_63               : 43;
 #endif
 	} cn70xx;
+	struct cvmx_agl_gmx_tx_int_en_cn70xx  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_int_en cvmx_agl_gmx_tx_int_en_t;
 
@@ -4837,6 +4902,7 @@ union cvmx_agl_gmx_tx_int_reg {
 	uint64_t reserved_21_63               : 43;
 #endif
 	} cn70xx;
+	struct cvmx_agl_gmx_tx_int_reg_cn70xx cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_int_reg cvmx_agl_gmx_tx_int_reg_t;
 
@@ -4872,6 +4938,7 @@ union cvmx_agl_gmx_tx_jam {
 	struct cvmx_agl_gmx_tx_jam_s          cn68xx;
 	struct cvmx_agl_gmx_tx_jam_s          cn68xxp1;
 	struct cvmx_agl_gmx_tx_jam_s          cn70xx;
+	struct cvmx_agl_gmx_tx_jam_s          cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_jam cvmx_agl_gmx_tx_jam_t;
 
@@ -4909,6 +4976,7 @@ union cvmx_agl_gmx_tx_lfsr {
 	struct cvmx_agl_gmx_tx_lfsr_s         cn68xx;
 	struct cvmx_agl_gmx_tx_lfsr_s         cn68xxp1;
 	struct cvmx_agl_gmx_tx_lfsr_s         cn70xx;
+	struct cvmx_agl_gmx_tx_lfsr_s         cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_lfsr cvmx_agl_gmx_tx_lfsr_t;
 
@@ -4972,6 +5040,7 @@ union cvmx_agl_gmx_tx_ovr_bp {
 	struct cvmx_agl_gmx_tx_ovr_bp_s       cn68xx;
 	struct cvmx_agl_gmx_tx_ovr_bp_s       cn68xxp1;
 	struct cvmx_agl_gmx_tx_ovr_bp_cn56xx  cn70xx;
+	struct cvmx_agl_gmx_tx_ovr_bp_cn56xx  cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_ovr_bp cvmx_agl_gmx_tx_ovr_bp_t;
 
@@ -5007,6 +5076,7 @@ union cvmx_agl_gmx_tx_pause_pkt_dmac {
 	struct cvmx_agl_gmx_tx_pause_pkt_dmac_s cn68xx;
 	struct cvmx_agl_gmx_tx_pause_pkt_dmac_s cn68xxp1;
 	struct cvmx_agl_gmx_tx_pause_pkt_dmac_s cn70xx;
+	struct cvmx_agl_gmx_tx_pause_pkt_dmac_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_pause_pkt_dmac cvmx_agl_gmx_tx_pause_pkt_dmac_t;
 
@@ -5042,6 +5112,7 @@ union cvmx_agl_gmx_tx_pause_pkt_type {
 	struct cvmx_agl_gmx_tx_pause_pkt_type_s cn68xx;
 	struct cvmx_agl_gmx_tx_pause_pkt_type_s cn68xxp1;
 	struct cvmx_agl_gmx_tx_pause_pkt_type_s cn70xx;
+	struct cvmx_agl_gmx_tx_pause_pkt_type_s cn70xxp1;
 };
 typedef union cvmx_agl_gmx_tx_pause_pkt_type cvmx_agl_gmx_tx_pause_pkt_type_t;
 
@@ -5068,6 +5139,7 @@ union cvmx_agl_gmx_wol_ctl {
 #endif
 	} s;
 	struct cvmx_agl_gmx_wol_ctl_s         cn70xx;
+	struct cvmx_agl_gmx_wol_ctl_s         cn70xxp1;
 };
 typedef union cvmx_agl_gmx_wol_ctl cvmx_agl_gmx_wol_ctl_t;
 
@@ -5332,6 +5404,7 @@ union cvmx_agl_prtx_ctl {
 	uint64_t drv_byp                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_agl_prtx_ctl_cn70xx       cn70xxp1;
 };
 typedef union cvmx_agl_prtx_ctl cvmx_agl_prtx_ctl_t;
 
diff --git a/arch/mips/include/asm/octeon/cvmx-app-init.h b/arch/mips/include/asm/octeon/cvmx-app-init.h
index b80285f..b4fe073 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-init.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-init.h
@@ -41,7 +41,7 @@
  * @file
  * Header file for simple executive application initialization.  This defines
  * part of the ABI between the bootloader and the application.
- * <hr>$Revision: 88720 $<hr>
+ * <hr>$Revision: 96616 $<hr>
  *
  */
 
@@ -274,6 +274,9 @@ enum cvmx_board_types_enum {
 	CVMX_BOARD_TYPE_EVB7000_INTERPOSER = 55,
 	CVMX_BOARD_TYPE_EVB7000 = 56,
 	CVMX_BOARD_TYPE_EVB7000_SFF = 57,
+	CVMX_BOARD_TYPE_NAS7000_REF = 58,
+	CVMX_BOARD_TYPE_EAP7000_REF = 59,
+	CVMX_BOARD_TYPE_ROUTER7000_REF = 60,
 	CVMX_BOARD_TYPE_MAX,
 	/* NOTE:  256-257 are being used by a customer. */
 
@@ -313,6 +316,7 @@ enum cvmx_board_types_enum {
 	 ** use any numbers in this range. */
 	CVMX_BOARD_TYPE_CUST_PRIVATE_MIN = 20001,
 	CVMX_BOARD_TYPE_UBNT_E100 = 20002,
+	CVMX_BOARD_TYPE_CUST_CLARK = 20003,
 	CVMX_BOARD_TYPE_CUST_PRIVATE_MAX = 30000,
 
 	/* Range for IO modules */
@@ -342,108 +346,110 @@ static inline const char *cvmx_board_type_to_string(enum cvmx_board_types_enum t
 {
 	switch (type) {
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NULL)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SIM)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT3000)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_KODAMA)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIAGARA)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NAC38)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_THUNDER)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_TRANTOR)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH3000)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH3100)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_HIKARI)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CN3010_EVB_HS5)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CN3005_EVB_HS5)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_KBP)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CN3020_EVB_HS5)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT5800)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NICPRO2)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5600)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5601)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5200)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_BBGW_REF)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC_XLE_4G)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT5600)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5201)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT5200)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CB5600)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CB5601)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CB5200)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_GENERIC)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5610)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_LANAI2_A)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_LANAI2_U)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB5600)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB6300)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC_XLE_10G)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_LANAI2_G)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT5810)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC10E)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EP6300C)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB6800)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC4E)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC2E)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB6600)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_REDWING)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC68_4)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC10E_66)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB6100)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7100)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SFF6100)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC4E_66)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SNIC10E)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SNIC10E_61)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_IW_EVB)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CNF71XX_REF)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MOONSHOT)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_INTERPOSER)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_SFF)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MAX)
-
-		    /* Customer boards listed here */
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_DEFINED_MIN)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_WSX16)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_NS0216)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_NB5)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_WMR500)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_ITB101)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_NTE102)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_AGS103)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_GST104)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_GCT105)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_AGS106)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_SGM107)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_GCT108)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_AGS109)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_GCT110)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_AIR_SENDER)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_AIR_RECEIVER)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_ACCTON2_TX)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_ACCTON2_RX)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_WSTRNSNIC_TX)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_WSTRNSNIC_RX)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_ZINWELL)
-
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_DEFINED_MAX)
-
-		    /* Customer private range */
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_PRIVATE_MIN)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_UBNT_E100)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_PRIVATE_MAX)
-
-		    /* Module range */
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_MIN)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_PCIE_RC_4X)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_PCIE_EP_4X)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_SGMII_MARVEL)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_SFPPLUS_BCM)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_SRIO)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_EBB5600_QLM0)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_EBB5600_QLM1)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_EBB5600_QLM2)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_EBB5600_QLM3)
-		    ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_MAX)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SIM)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT3000)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_KODAMA)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIAGARA)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NAC38)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_THUNDER)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_TRANTOR)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH3000)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH3100)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_HIKARI)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CN3010_EVB_HS5)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CN3005_EVB_HS5)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_KBP)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CN3020_EVB_HS5)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT5800)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NICPRO2)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5600)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5601)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5200)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_BBGW_REF)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC_XLE_4G)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT5600)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5201)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT5200)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CB5600)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CB5601)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CB5200)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_GENERIC)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBH5610)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_LANAI2_A)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_LANAI2_U)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB5600)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB6300)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC_XLE_10G)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_LANAI2_G)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBT5810)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC10E)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EP6300C)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB6800)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC4E)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC2E)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB6600)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_REDWING)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC68_4)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC10E_66)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EBB6100)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7100)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SFF6100)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NIC4E_66)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SNIC10E)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_SNIC10E_61)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_IW_EVB)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CNF71XX_REF)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MOONSHOT)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_INTERPOSER)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_SFF)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NAS7000_REF)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EAP7000_REF)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_ROUTER7000_REF)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MAX)
+
+		/* Customer boards listed here */
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_DEFINED_MIN)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_WSX16)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_NS0216)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_NB5)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_WMR500)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_ITB101)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_NTE102)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_AGS103)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_GST104)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_GCT105)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_AGS106)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_SGM107)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_GCT108)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_AGS109)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_GCT110)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_AIR_SENDER)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_AIR_RECEIVER)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_ACCTON2_TX)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_ACCTON2_RX)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_WSTRNSNIC_TX)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_WSTRNSNIC_RX)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_L2_ZINWELL)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_DEFINED_MAX)
+
+		/* Customer private range */
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_PRIVATE_MIN)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_UBNT_E100)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_CLARK)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CUST_PRIVATE_MAX)
+		/* Module range */
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_MIN)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_PCIE_RC_4X)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_PCIE_EP_4X)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_SGMII_MARVEL)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_SFPPLUS_BCM)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_SRIO)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_EBB5600_QLM0)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_EBB5600_QLM1)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_EBB5600_QLM2)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_EBB5600_QLM3)
+		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MODULE_MAX)
 	}
 	return "Unsupported Board";
 }
@@ -453,9 +459,9 @@ static inline const char *cvmx_chip_type_to_string(enum cvmx_chip_types_enum typ
 {
 	switch (type) {
 		ENUM_CHIP_TYPE_CASE(CVMX_CHIP_TYPE_NULL)
-		    ENUM_CHIP_TYPE_CASE(CVMX_CHIP_SIM_TYPE_DEPRECATED)
-		    ENUM_CHIP_TYPE_CASE(CVMX_CHIP_TYPE_OCTEON_SAMPLE)
-		    ENUM_CHIP_TYPE_CASE(CVMX_CHIP_TYPE_MAX)
+		ENUM_CHIP_TYPE_CASE(CVMX_CHIP_SIM_TYPE_DEPRECATED)
+		ENUM_CHIP_TYPE_CASE(CVMX_CHIP_TYPE_OCTEON_SAMPLE)
+		ENUM_CHIP_TYPE_CASE(CVMX_CHIP_TYPE_MAX)
 	}
 	return "Unsupported Chip";
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-ase-defs.h b/arch/mips/include/asm/octeon/cvmx-ase-defs.h
index 144a3c1..9468afc 100644
--- a/arch/mips/include/asm/octeon/cvmx-ase-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ase-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-asxx-defs.h b/arch/mips/include/asm/octeon/cvmx-asxx-defs.h
index 56fb582..7cb9866 100644
--- a/arch/mips/include/asm/octeon/cvmx-asxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-asxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-bch-defs.h b/arch/mips/include/asm/octeon/cvmx-bch-defs.h
index 858a066..3837c93 100644
--- a/arch/mips/include/asm/octeon/cvmx-bch-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-bch-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -141,6 +141,7 @@ union cvmx_bch_bist_result {
 #endif
 	} s;
 	struct cvmx_bch_bist_result_s         cn70xx;
+	struct cvmx_bch_bist_result_s         cn70xxp1;
 };
 typedef union cvmx_bch_bist_result cvmx_bch_bist_result_t;
 
@@ -168,6 +169,7 @@ union cvmx_bch_cmd_buf {
 #endif
 	} s;
 	struct cvmx_bch_cmd_buf_s             cn70xx;
+	struct cvmx_bch_cmd_buf_s             cn70xxp1;
 };
 typedef union cvmx_bch_cmd_buf cvmx_bch_cmd_buf_t;
 
@@ -206,6 +208,7 @@ union cvmx_bch_ctl {
 #endif
 	} s;
 	struct cvmx_bch_ctl_s                 cn70xx;
+	struct cvmx_bch_ctl_s                 cn70xxp1;
 };
 typedef union cvmx_bch_ctl cvmx_bch_ctl_t;
 
@@ -229,6 +232,7 @@ union cvmx_bch_err_cfg {
 #endif
 	} s;
 	struct cvmx_bch_err_cfg_s             cn70xx;
+	struct cvmx_bch_err_cfg_s             cn70xxp1;
 };
 typedef union cvmx_bch_err_cfg cvmx_bch_err_cfg_t;
 
@@ -251,6 +255,7 @@ union cvmx_bch_gen_int {
 #endif
 	} s;
 	struct cvmx_bch_gen_int_s             cn70xx;
+	struct cvmx_bch_gen_int_s             cn70xxp1;
 };
 typedef union cvmx_bch_gen_int cvmx_bch_gen_int_t;
 
@@ -276,6 +281,7 @@ union cvmx_bch_gen_int_en {
 #endif
 	} s;
 	struct cvmx_bch_gen_int_en_s          cn70xx;
+	struct cvmx_bch_gen_int_en_s          cn70xxp1;
 };
 typedef union cvmx_bch_gen_int_en cvmx_bch_gen_int_en_t;
 
diff --git a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
index 11fb314..afb64b8 100644
--- a/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-bgxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1943,30 +1943,32 @@ union cvmx_bgxx_cmrx_config {
 	struct cvmx_bgxx_cmrx_config_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t enable                       : 1;  /**< Logical MAC/PCS Enable. This is the master enable for the LMAC. When clear, all the
+	uint64_t enable                       : 1;  /**< Logical MAC/PCS enable. This is the master enable for the LMAC. When clear, all the
                                                          dedicated BGX context state for the LMAC (state machines, FIFOs, counters, etc.) is reset,
-                                                         and LMAC access to shared BGX resources (SMU/SPU data path, serdes lanes) is disabled.
+                                                         and LMAC access to shared BGX resources (SMU/SPU data path, SerDes lanes) is disabled.
                                                          When set, LMAC operation is enabled, including link bring-up, synchronization, and
-                                                         transmit/receive of of idles and fault sequences. Note that configuration registers for an
+                                                         transmit/receive of idles and fault sequences. Note that configuration registers for an
                                                          LMAC are not reset when this bit is clear, allowing software to program them before
-                                                         setting this bit to enable the LMAC.  This bit together with the LMAC_TYPE is also used
-                                                         to enable the clocking to the GMP and/or blocks of the Super path(SMU and SPU).
-                                                         CMR clocking will be enable when any of the paths are enabled. */
-	uint64_t data_pkt_rx_en               : 1;  /**< Data Packet Receive Enable When ENABLE=1 and DATA_PKT_RX_EN=1, the reception of data
+                                                         setting this bit to enable the LMAC. This bit together with the LMAC_TYPE is also used to
+                                                         enable the clocking to the GMP and/or blocks of the Super path (SMU and SPU). CMR clocking
+                                                         is enabled when any of the paths are enabled. */
+	uint64_t data_pkt_rx_en               : 1;  /**< Data packet receive enable. When ENABLE=1 and DATA_PKT_RX_EN=1, the reception of data
                                                          packets is enabled in the MAC layer. When ENABLE=1 and DATA_PKT_RX_EN=0, the MAC layer
                                                          drops received data and flow control packets. */
-	uint64_t data_pkt_tx_en               : 1;  /**< Data Packet Transmit Enable When ENABLE=1 and DATA_PKT_TX_EN=1, the transmission of data
+	uint64_t data_pkt_tx_en               : 1;  /**< Data packet transmit enable. When ENABLE=1 and DATA_PKT_TX_EN=1, the transmission of data
                                                          packets is enabled in the MAC layer. When ENABLE=1 and DATA_PKT_TX_EN=0, the MAC layer
-                                                         suppresses the transmission of new data and packets for the LMAC */
-	uint64_t int_beat_gen                 : 1;  /**< Internal Beat Generation This bit is used for debug/test purposes and should be clear
+                                                         suppresses the transmission of new data and packets for the LMAC. */
+	uint64_t int_beat_gen                 : 1;  /**< Internal beat generation. This bit is used for debug/test purposes and should be clear
                                                          during normal operation. When set, the LMAC's PCS layer ignores RXVALID and
-                                                         TXREADY/TXCREDIT from the associated serdes lane(s), internally generates fake (idle)
-                                                         RXVALID and TXCREDIT pulses, and suppresses transmission to the serdes */
-	uint64_t mix_en                       : 1;  /**< Managemenet enable. This bit is used by LMACs 0 and 1 only, and should be kept clear for
-                                                         LMACs 2 and 3. Setting it will pipe the LMAC to and from the MIX inteface (LMAC0 to/from
+                                                         TXREADY/TXCREDIT from the associated SerDes lane(s), internally generates fake (idle)
+                                                         RXVALID and TXCREDIT pulses, and suppresses transmission to the SerDes. */
+	uint64_t mix_en                       : 1;  /**< Management enable. This bit is used by LMACs 0 and 1 only, and should be kept clear for
+                                                         LMACs 2 and 3. Setting it will pipe the LMAC to and from the MIX interface (LMAC0 to/from
                                                          MIX0, LMAC1 to/from MIX1). LMAC_TYPE must be 0 (SGMII) then this bit is set. Note that at
                                                          most one BGX can be attached to each of MIX0 and MIX1, i.e. at most one
-                                                         BGX(0..5)_CMR0_CONFIG[MIX_EN] bit and one BGX(0..5)_CMR1_CONFIG[MIX_EN] bit can be set. */
+                                                         BGX(0..5)_CMR0_CONFIG[MIX_EN] bit and one BGX(0..5)_CMR1_CONFIG[MIX_EN] bit can be set.
+                                                         This field must be programmed to its final value before [ENABLE] is set, and must not
+                                                         be changed when [ENABLE]=1. */
 	uint64_t lmac_type                    : 3;  /**< Logical MAC/PCS Type:
                                                            ----------+----------------------------------------------------------
                                                            LMAC_TYPE | Name         Description                NUM_PCS_LANES
@@ -1980,34 +1982,34 @@ union cvmx_bgxx_cmrx_config {
                                                            ----------+----------------------------------------------------------
                                                          NUM_PCS_LANES specifies the number of of PCS lanes that are valid for
                                                          each type. Each valid PCS lane is mapped to a physical serdes lane
-                                                         based on the programming of [LANE_TO_SDS]. */
+                                                         based on the programming of [LANE_TO_SDS].
+                                                         This field must be programmed to its final value before [ENABLE] is set, and must not
+                                                         be changed when [ENABLE]=1. */
 	uint64_t lane_to_sds                  : 8;  /**< PCS Lane to Serdes Mapping.
                                                          This is an array of 2-bit values that map each logical PCS Lane to a
-                                                         physical serdes lane, as follows:
+                                                         physical SerDes lane, as follows:
                                                            ----------+----------------------------------------------------------
                                                            Bits     | Description                     Reset value
                                                            ----------+----------------------------------------------------------
-                                                           <7:6>    | PCS Lane 3 Serdes ID            0x3
-                                                           <5:4>    | PCS Lane 2 Serdes ID            0x2
-                                                           <3:2>    | PCS Lane 1 Serdes ID            0x1
-                                                           <1:0>    | PCS Lane 0 Serdes ID            0x0
+                                                           <7:6>    | PCS Lane 3 SerDes ID            0x3
+                                                           <5:4>    | PCS Lane 2 SerDes ID            0x2
+                                                           <3:2>    | PCS Lane 1 SerDes ID            0x1
+                                                           <1:0>    | PCS Lane 0 SerDes ID            0x0
                                                            ----------+----------------------------------------------------------
-                                                         PCS lanes 0 through NUM_PCS_LANES-1 are valid, where NUM_PCS_LANES is
-                                                         a function of the logical MAC/PCS type (see definition of
-                                                         LMAC_TYPE field in this register). For example, when LMAC_TYPE =
-                                                         RXAUI, then NUM_PCS_LANES = 2, PCS lanes 0 and 1 valid and the
-                                                         associated physical serdes lanes are selected by bits <1:0> and
-                                                         <3:2>, respectively.
-                                                         For 40GBASE-R (LMAC_TYPE = 40G_R), all four PCS lanes are valid, and
-                                                         the PCS lane IDs determine the block distribution order and
-                                                         associated alignment markers on the *transmit* side. This is not
-                                                         necessarily the order in which PCS lanes *receive* data because 802.3
-                                                         allows multi-lane BASE-R receive lanes to be re-ordered. When a
-                                                         lane (called 'service interface' in 802.3ba-2010) has achieved
-                                                         alignment marker lock on the receive side (i.e. the associated
-                                                         MARKER_LOCK bit is set in BR_ALGN_STATUS), then the actual detected
-                                                         RX PCS lane number is recorded in the corresponding LNx_MAPPING
-                                                         field in BR_LANE_MAP. */
+                                                         PCS lanes 0 through NUM_PCS_LANES-1 are valid, where NUM_PCS_LANES is a function of the
+                                                         logical MAC/PCS type. (See definition of LMAC_TYPE.) For example, when LMAC_TYPE = RXAUI,
+                                                         then NUM_PCS_LANES = 2, PCS lanes 0 and 1 valid and the associated physical SerDes lanes
+                                                         are selected by bits <1:0> and <3:2>, respectively.
+                                                         For 40GBASE-R (LMAC_TYPE = 40G_R), all four PCS lanes are valid, and the PCS lane IDs
+                                                         determine the block distribution order and associated alignment markers on the transmit
+                                                         side. This is not necessarily the order in which PCS lanes receive data because 802.3
+                                                         allows multilane BASE-R receive lanes to be reordered. When a lane (called service
+                                                         interface in 802.3ba-2010) has achieved alignment marker lock on the receive side (i.e.
+                                                         the associated BGX(0..5)_SPU(0..3)_BR_ALGN_STATUS[MARKER_LOCK] = 1), then the actual
+                                                         detected RX PCS lane number is recorded in the corresponding
+                                                         BGX(0..5)_SPU(0..3)_BR_LANE_MAP[LNx_MAPPING].
+                                                         This field must be programmed to its final value before [ENABLE] is set, and must not
+                                                         be changed when [ENABLE]=1. */
 #else
 	uint64_t lane_to_sds                  : 8;
 	uint64_t lmac_type                    : 3;
@@ -2032,7 +2034,7 @@ union cvmx_bgxx_cmrx_int {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
 	uint64_t pko_nxc                      : 1;  /**< TX channel out-of-range from PKO interface. Assigned to the LMAC ID based on the lower 2
-                                                         bits of the offending channel */
+                                                         bits of the offending channel. */
 	uint64_t overflw                      : 1;  /**< RX overflow. */
 	uint64_t pause_drp                    : 1;  /**< RX PAUSE packet was dropped due to full RXB FIFO or during partner reset. */
 #else
@@ -2057,10 +2059,10 @@ union cvmx_bgxx_cmrx_prt_cbfc_ctl {
 	struct cvmx_bgxx_cmrx_prt_cbfc_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t phys_bp                      : 16; /**< When BGXn_SMUm_CBFC_CTL[RX_EN] is set and the hardware is backpressuring any LMACs (from
-                                                         either PFC/CBFC PAUSE packets or BGXn_CMR_TX_OVR_BP[TX_CHAN_BP]) and all LMACs indicated
-                                                         by PHYS_BP are backpressured, simulate physical backpressure by deferring all packets on
-                                                         the transmitter. */
+	uint64_t phys_bp                      : 16; /**< When BGX(0..5)_SMU(0..3)_CBFC_CTL[RX_EN] is set and the hardware is backpressuring any
+                                                         LMACs (from either PFC/CBFC PAUSE packets or BGX(0..5)_CMR(0..3)_TX_OVR_BP[TX_CHAN_BP])
+                                                         and all LMACs indicated by PHYS_BP are backpressured, simulate physical backpressure by
+                                                         deferring all packets on the transmitter. */
 	uint64_t reserved_0_15                : 16;
 #else
 	uint64_t reserved_0_15                : 16;
@@ -2089,8 +2091,8 @@ union cvmx_bgxx_cmrx_rx_adr_ctl {
                                                          0x2 = Use the address filter CAM
                                                          0x3 = Reserved */
 	uint64_t bcst_accept                  : 1;  /**< Allow or deny broadcast packets.
-                                                         0 = Reject all broadcast packets
-                                                         1 = Accept all broadcast Packets */
+                                                         0 = Reject all broadcast packets.
+                                                         1 = Accept all broadcast Packets. */
 #else
 	uint64_t bcst_accept                  : 1;
 	uint64_t mcst_mode                    : 2;
@@ -2151,14 +2153,16 @@ union cvmx_bgxx_cmrx_rx_bp_on {
 	struct cvmx_bgxx_cmrx_rx_bp_on_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
-	uint64_t mark                         : 12; /**< High watermark (number of eight-byte cycles to assert backpressure). Each register is for
-                                                         an individual LMAC. MARK must satisfy:
+	uint64_t mark                         : 12; /**< High watermark. Buffer depth in multiple of 16-bytes, at which BGX will
+                                                         assert backpressure for each individual LMAC.  MARK must satisfy:
                                                          BGX(0..5)_CMR(0..3)_RX_BP_OFF[MARK] <= MARK <
                                                          (FIFO_SIZE - BGX(0..5)_CMR(0..3)_RX_BP_DROP[MARK]).
                                                          A value of 0x0 immediately asserts backpressure.
-                                                         The recommended value is 1/4th the size of the per-LMAC RX FIFO_SIZE as determined by
-                                                         GX_CMR_RX_LMACS[LMACS]. For example in SGMII mode with four LMACs of type SGMII where
-                                                         BGX*_CMR*_RX_LMACS[LMACS]=0x4, MARK = 0x100 (the reset value. */
+                                                         The recommended value is 1/4th the size of the per-LMAC RX FIFO_SIZE as
+                                                         determined by BGX(0..5)_CMR_RX_LMACS[LMACS]. For example in SGMII mode with
+                                                         four LMACs of type SGMII, where BGX(0..5)_CMR_RX_LMACS[LMACS]=0x4, there is
+                                                         16 KB of buffering. The recommended 1/4th size of that 16 KB is 4 KB, which
+                                                         in units of 16 bytes gives MARK = 0x100 (the reset value). */
 #else
 	uint64_t mark                         : 12;
 	uint64_t reserved_12_63               : 52;
@@ -2218,7 +2222,7 @@ union cvmx_bgxx_cmrx_rx_id_map {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
 	uint64_t rid                          : 7;  /**< Reassembly ID map for this LMAC. A shared pool of 96 reassembly IDs (RIDs) exists for all
-                                                         MACs. See description of RIDs in .
+                                                         MACs.
                                                          The RID for this LMAC must be constrained such that it does not overlap with any other MAC
                                                          in the system. Its reset value has been chosen such that this condition is satisfied:
                                                          RID reset value = 4*(BGX_ID + 1) + LMAC_ID
@@ -2265,7 +2269,7 @@ union cvmx_bgxx_cmrx_rx_logl_xon {
 	struct cvmx_bgxx_cmrx_rx_logl_xon_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t xon                          : 16; /**< Together with BGX(0..5)_CMR(0..3)_RX_LOGL_XOFF defines type of channel backpressure to
+	uint64_t xon                          : 16; /**< Together with BGX(0..5)_CMR(0..3)_RX_LOGL_XOFF, defines type of channel backpressure to
                                                          apply. Do not write when HiGig2 is enabled. Writing 1 clears the same physical register as
                                                          that which is set by XOFF. An XON value of 1 means only PKI channel BP can cause a
                                                          backpressure on SMU. */
@@ -2286,7 +2290,7 @@ union cvmx_bgxx_cmrx_rx_pause_drop_time {
 	struct cvmx_bgxx_cmrx_rx_pause_drop_time_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t pause_time                   : 16; /**< Time extracted from the dropped PAUSE packet dropped due to RXB FIFO full or during partner reset */
+	uint64_t pause_time                   : 16; /**< Time extracted from the dropped PAUSE packet dropped due to RXB FIFO full or during partner reset. */
 #else
 	uint64_t pause_time                   : 16;
 	uint64_t reserved_16_63               : 48;
@@ -2300,10 +2304,10 @@ typedef union cvmx_bgxx_cmrx_rx_pause_drop_time cvmx_bgxx_cmrx_rx_pause_drop_tim
  * cvmx_bgx#_cmr#_rx_stat0
  *
  * These registers provide a count of received packets that meet the following conditions:
- * are not recognized as PAUSE packets
- * are not dropped due DMAC filtering
- * are not dropped due FIFO full status
- * do not have any other OPCODE (FCS, Length, etc).
+ * * are not recognized as PAUSE packets.
+ * * are not dropped due DMAC filtering.
+ * * are not dropped due FIFO full status.
+ * * do not have any other OPCODE (FCS, Length, etc).
  */
 union cvmx_bgxx_cmrx_rx_stat0 {
 	uint64_t u64;
@@ -2311,7 +2315,7 @@ union cvmx_bgxx_cmrx_rx_stat0 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Count of received packets. CNT will wrap and is cleared if LMAC is disabled with
-                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2333,7 +2337,7 @@ union cvmx_bgxx_cmrx_rx_stat1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Octet count of received packets. CNT will wrap and is cleared if LMAC is disabled with
-                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2347,12 +2351,11 @@ typedef union cvmx_bgxx_cmrx_rx_stat1 cvmx_bgxx_cmrx_rx_stat1_t;
  * cvmx_bgx#_cmr#_rx_stat2
  *
  * These registers provide a count of all packets received that were recognized as flow-control
- * or PAUSE packets. PAUSE packets with any kind of error are counted in BGX*_CMR*_RX_STAT8
- * (error stats register) and does not include those reported in BGX(0..5)_CMR(0..3)_RX_STAT6
- * nor BGX(0..5)_CMR(0..3)_RX_STAT4.
- * Pause packets can be optionally dropped or forwarded based on
- * BGX_SMU_RX_FRM_CTL[CTL_DRP]. This count increments regardless of whether the packet is
- * dropped. PAUSE packets are never counted in BGX*_CMR*_RX_STAT0.
+ * or PAUSE packets. PAUSE packets with any kind of error are counted in
+ * BGX(0..5)_CMR(0..3)_RX_STAT8 (error stats register). Pause packets can be optionally dropped
+ * or forwarded based on BGX(0..5)_SMU(0..3)_RX_FRM_CTL[CTL_DRP]. This count increments
+ * regardless of whether the packet is dropped. PAUSE packets are never counted in
+ * BGX(0..5)_CMR(0..3)_RX_STAT0.
  */
 union cvmx_bgxx_cmrx_rx_stat2 {
 	uint64_t u64;
@@ -2360,7 +2363,7 @@ union cvmx_bgxx_cmrx_rx_stat2 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Count of received PAUSE packets. CNT will wrap and is cleared if LMAC is disabled with
-                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2382,7 +2385,7 @@ union cvmx_bgxx_cmrx_rx_stat3 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Octet count of received PAUSE packets. CNT will wrap and is cleared if LMAC is disabled
-                                                         with BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2397,10 +2400,9 @@ typedef union cvmx_bgxx_cmrx_rx_stat3 cvmx_bgxx_cmrx_rx_stat3_t;
  *
  * These registers provide a count of all packets received that were dropped by the DMAC filter.
  * Packets that match the DMAC are dropped and counted here regardless of whether they were ERR
- * packets, but does not include those reported in BGX(0..5)_CMR(0..3)_RX_STAT6.
- * These packets are never counted in BGX*_CMR*_RX_STAT0. Eight-byte packets as the
- * result of truncation or other means are not be dropped by CN78XX and will never appear in this
- * count.
+ * packets, but does not include those reported in BGX(0..5)_CMR(0..3)_RX_STAT6. These packets
+ * are never counted in BGX(0..5)_CMR(0..3)_RX_STAT0. Eight-byte packets as the result of
+ * truncation or other means are not dropped by CN78XX and will never appear in this count.
  */
 union cvmx_bgxx_cmrx_rx_stat4 {
 	uint64_t u64;
@@ -2408,7 +2410,7 @@ union cvmx_bgxx_cmrx_rx_stat4 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Count of filtered DMAC packets. CNT will wrap and is cleared if LMAC is disabled with
-                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2430,7 +2432,7 @@ union cvmx_bgxx_cmrx_rx_stat5 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Octet count of filtered DMAC packets. CNT will wrap and is cleared if LMAC is disabled
-                                                         with BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2444,9 +2446,9 @@ typedef union cvmx_bgxx_cmrx_rx_stat5 cvmx_bgxx_cmrx_rx_stat5_t;
  * cvmx_bgx#_cmr#_rx_stat6
  *
  * These registers provide a count of all packets received that were dropped due to a full
- * receive FIFO. They do not count any packet that is truncated at the point at the point of
- * overflow and sent on to the PKI. These registers count all entire packets dropped by the FIFO
- * for a given LMAC regardless of DMAC or PAUSE type.
+ * receive FIFO. They do not count any packet that is truncated at the point of overflow and sent
+ * on to the PKI. These registers count all entire packets dropped by the FIFO for a given LMAC
+ * regardless of DMAC or PAUSE type.
  */
 union cvmx_bgxx_cmrx_rx_stat6 {
 	uint64_t u64;
@@ -2454,7 +2456,7 @@ union cvmx_bgxx_cmrx_rx_stat6 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Count of dropped packets. CNT will wrap and is cleared if LMAC is disabled with
-                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2476,7 +2478,7 @@ union cvmx_bgxx_cmrx_rx_stat7 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Octet count of dropped packets. CNT will wrap and is cleared if LMAC is disabled with
-                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2511,7 +2513,7 @@ union cvmx_bgxx_cmrx_rx_stat8 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t cnt                          : 48; /**< Count of error packets. CNT will wrap and is cleared if LMAC is disabled with
-                                                         BGX*_CMR*_CONFIG[ENABLE]=0. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t cnt                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2550,11 +2552,11 @@ union cvmx_bgxx_cmrx_tx_channel {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
 	uint64_t msk                          : 16; /**< Backpressure channel mask. BGX can completely ignore the channel backpressure for channel
-                                                         specified by this field. Any channel in which MSK == 1 never sends backpressure
+                                                         specified by this field. Any channel in which MSK<n> is set never sends backpressure
                                                          information to PKO. */
 	uint64_t dis                          : 16; /**< Credit return backpressure disable. BGX stops returning channel credits for any channel
-                                                         that is backpressured. These bits can be used to override that. DIS == 1 allows channel
-                                                         credits to flow back regardless of the backpressure for that channel. */
+                                                         that is backpressured. These bits can be used to override that. If DIS<n> is set, channel
+                                                         credits may flow back regardless of the backpressure for that channel. */
 #else
 	uint64_t dis                          : 16;
 	uint64_t msk                          : 16;
@@ -2638,9 +2640,9 @@ union cvmx_bgxx_cmrx_tx_stat0 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t xscol                        : 48; /**< Number of packets dropped (never successfully sent) due to excessive collision. Defined by
-                                                         BGX_GMP_GMI_TX_COL_ATTEMPT[LIMIT]. SGMII/1000Base-X half-duplex only.
+                                                         BGX(0..5)_GMP_GMI_TX_COL_ATTEMPT[LIMIT]. SGMII/1000Base-X half-duplex only.
                                                          Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t xscol                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2661,7 +2663,7 @@ union cvmx_bgxx_cmrx_tx_stat1 {
 	uint64_t xsdef                        : 48; /**< Number of packets dropped (never successfully sent) due to excessive deferral.
                                                          SGMII/1000BASE-X half-duplex only.
                                                          Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t xsdef                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2683,8 +2685,8 @@ union cvmx_bgxx_cmrx_tx_stat10 {
                                                          all data transmitted on the wire for the given packet including packet data, pad bytes,
                                                          FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or
                                                          EXTEND cycles.
-                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist4                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2707,7 +2709,7 @@ union cvmx_bgxx_cmrx_tx_stat11 {
                                                          FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or
                                                          EXTEND cycles.
                                                          Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist5                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2729,8 +2731,8 @@ union cvmx_bgxx_cmrx_tx_stat12 {
                                                          all data transmitted on the wire for the given packet including packet data, pad bytes,
                                                          FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or
                                                          EXTEND cycles.
-                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist6                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2752,8 +2754,8 @@ union cvmx_bgxx_cmrx_tx_stat13 {
                                                          transmitted on the wire for the given packet including packet data, pad bytes, FCS bytes,
                                                          PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or EXTEND
                                                          cycles.
-                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist7                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2777,7 +2779,7 @@ union cvmx_bgxx_cmrx_tx_stat14 {
                                                          assumes that the DMAC lies in the first six bytes of the packet as per the 802.3 frame
                                                          definition. If the system requires additional data before the L2 header, the MCST and BCST
                                                          counters may not reflect reality and should be ignored by software. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t bcst                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2801,7 +2803,7 @@ union cvmx_bgxx_cmrx_tx_stat15 {
                                                          assumes that the DMAC lies in the first six bytes of the packet as per the 802.3 frame
                                                          definition. If the system requires additional data before the L2 header, then the MCST and
                                                          BCST counters may not reflect reality and should be ignored by software. Cleared if LMAC
-                                                         is disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         is disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t mcst                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2821,7 +2823,7 @@ union cvmx_bgxx_cmrx_tx_stat16 {
 	uint64_t reserved_48_63               : 16;
 	uint64_t undflw                       : 48; /**< Number of underflow packets.
                                                          Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t undflw                       : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2844,7 +2846,7 @@ union cvmx_bgxx_cmrx_tx_stat17 {
                                                          CTL counts the number of generated PFC frames and does not track the number of generated
                                                          HG2 messages.
                                                          Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t ctl                          : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2863,9 +2865,9 @@ union cvmx_bgxx_cmrx_tx_stat2 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
 	uint64_t mcol                         : 48; /**< Number of packets sent with multiple collisions. Must be less than
-                                                         BGX_GMP_GMI_TX_COL_ATTEMPT[LIMIT]. SGMII/1000BASE-X half-duplex only.
+                                                         BGX(0..5)_GMP_GMI_TX_COL_ATTEMPT[LIMIT]. SGMII/1000BASE-X half-duplex only.
                                                          Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t mcol                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2885,7 +2887,7 @@ union cvmx_bgxx_cmrx_tx_stat3 {
 	uint64_t reserved_48_63               : 16;
 	uint64_t scol                         : 48; /**< Number of packets sent with a single collision. SGMII/1000BASE-X half-duplex only.
                                                          Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t scol                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2909,7 +2911,7 @@ union cvmx_bgxx_cmrx_tx_stat4 {
                                                          bytes, FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE
                                                          byte or EXTEND cycles.
                                                          Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t octs                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2930,7 +2932,7 @@ union cvmx_bgxx_cmrx_tx_stat5 {
 	uint64_t pkts                         : 48; /**< Number of total frames sent on the interface. Does not count octets from frames that were
                                                          truncated due to collisions in half-duplex mode.
                                                          Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t pkts                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2952,8 +2954,8 @@ union cvmx_bgxx_cmrx_tx_stat6 {
                                                          transmitted on the wire for the given packet including packet data, pad bytes, FCS bytes,
                                                          PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or EXTEND
                                                          cycles.
-                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist0                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2975,8 +2977,8 @@ union cvmx_bgxx_cmrx_tx_stat7 {
                                                          transmitted on the wire for the given packet including packet data, pad bytes, FCS bytes,
                                                          PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or EXTEND
                                                          cycles.
-                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist1                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -2998,8 +3000,8 @@ union cvmx_bgxx_cmrx_tx_stat8 {
                                                          data transmitted on the wire for the given packet including packet data, pad bytes, FCS
                                                          bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or EXTEND
                                                          cycles.
-                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist2                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3021,8 +3023,8 @@ union cvmx_bgxx_cmrx_tx_stat9 {
                                                          all data transmitted on the wire for the given packet including packet data, pad bytes,
                                                          FCS bytes, PAUSE bytes, and JAM bytes. The octet counts do not include PREAMBLE byte or
                                                          EXTEND cycles.
-                                                         Not cleared on read; cleared on a write with 0x0.Counters will wrap. Cleared if LMAC is
-                                                         disabled with BGX_CMR_CONFIG[ENABLE]=0. */
+                                                         Not cleared on read; cleared on a write with 0x0. Counters will wrap. Cleared if LMAC is
+                                                         disabled with BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]=0. */
 #else
 	uint64_t hist3                        : 48;
 	uint64_t reserved_48_63               : 16;
@@ -3138,7 +3140,7 @@ typedef union cvmx_bgxx_cmr_chan_msk_or cvmx_bgxx_cmr_chan_msk_or_t;
 /**
  * cvmx_bgx#_cmr_global_config
  *
- * These registers configures the global CMR, PCS, and MAC.
+ * These registers configure the global CMR, PCS, and MAC.
  *
  */
 union cvmx_bgxx_cmr_global_config {
@@ -3162,10 +3164,11 @@ union cvmx_bgxx_cmr_global_config {
                                                          interface. Setting this bit to 0 does not reset the X2P interface. After PKI comes out of
                                                          reset, software should clear CMR_X2P_RESET. */
 	uint64_t bgx_clk_enable               : 1;  /**< The global clock enable for BGX. Setting this bit overrides clock enables set by
-                                                         BGX_CMR_CONFIG[ENABLE] and BGX_CMR_CONFIG[LMAC_TYPE], essentially turning on clocks for
-                                                         the entire BGX. Setting this bit to 0 results in not overriding clock enables set by
-                                                         BGX_CMR_CONFIG[ENABLE] and BGX_CMR_CONFIG[LMAC_TYPE]. */
-	uint64_t pmux_sds_sel                 : 1;  /**< Serdes/QLM output select. Specifies which QLM output is selected as the BGX input, as
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE] and BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE], essentially
+                                                         turning on clocks for the entire BGX. Setting this bit to 0 results in not overriding
+                                                         clock enables set by BGX(0..5)_CMR(0..3)_CONFIG[ENABLE] and
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE]. */
+	uint64_t pmux_sds_sel                 : 1;  /**< SerDes/QLM output select. Specifies which QLM output is selected as the BGX input, as
                                                          follows:
                                                            ------+----------------+----------------
                                                            Block | PMUX_SDS_SEL=0 | PMUX_SDS_SEL=1
@@ -3326,17 +3329,17 @@ union cvmx_bgxx_cmr_rx_adrx_cam {
                                                          any of the four SGMII MACs or the 10G/40G MACs using these register bits.
                                                          A typical configuration is to provide eight CAM entries per LMAC ID, which is configured
                                                          using the following settings:
-                                                         LMAC interface 0: BGX(0..5)_CMR_RX_ADR(0..7)_CAM[ID] = 0x0
-                                                         LMAC interface 1: BGX(0..5)_CMR_RX_ADR(8..15)_CAM[ID] = 0x1
-                                                         LMAC interface 2: BGX(0..5)_CMR_RX_ADR(16..23)_CAM[ID] = 0x2
-                                                         LMAC interface 3: BGX(0..5)_CMR_RX_ADR(24..31)_CAM[ID] = 0x3 */
+                                                         * LMAC interface 0: BGX(0..5)_CMR_RX_ADR(0..7)_CAM[ID] = 0x0.
+                                                         * LMAC interface 1: BGX(0..5)_CMR_RX_ADR(8..15)_CAM[ID] = 0x1.
+                                                         * LMAC interface 2: BGX(0..5)_CMR_RX_ADR(16..23)_CAM[ID] = 0x2.
+                                                         * LMAC interface 3: BGX(0..5)_CMR_RX_ADR(24..31)_CAM[ID] = 0x3. */
 	uint64_t reserved_49_51               : 3;
 	uint64_t en                           : 1;  /**< CAM entry enable for this DMAC address.
                                                          1 = Include this address in the matching algorithm.
                                                          0 = Don't include this address in the matching algorithm. */
 	uint64_t adr                          : 48; /**< DMAC address in the CAM used for matching. The CAM matches against unicast or multicast
-                                                         DMAC addresses. All BGX*_CMR_RX_ADR_CAM(0..31) CSRs can be used in any of the LMAC_TYPE
-                                                         combinations such that any BGX MAC can use any of the 32 common DMAC entries. */
+                                                         DMAC addresses. All BGX(0..5)_CMR_RX_ADR(0..31)_CAM CSRs can be used in any of the
+                                                         LMAC_TYPE combinations such that any BGX MAC can use any of the 32 common DMAC entries. */
 #else
 	uint64_t adr                          : 48;
 	uint64_t en                           : 1;
@@ -3386,12 +3389,12 @@ typedef union cvmx_bgxx_cmr_rx_lmacs cvmx_bgxx_cmr_rx_lmacs_t;
 /**
  * cvmx_bgx#_cmr_rx_ovr_bp
  *
- * BGX_CMR_RX_OVR_BP[EN<0>] must be set to one and BGX_CMR_RX_OVR_BP[BP<0>] must be cleared to
- * zero (to forcibly disable hardware-automatic 802.3 PAUSE packet generation) with the HiGig2
- * Protocol when BGX_SMU_HG2_CONTROL[HG2TX_EN]=0. (The HiGig2 protocol is indicated by
- * BGX_SMU_TX_CTL[HG_EN]=1 and BGX_SMU_RX_UDD_SKP[LEN]=16). Hardware can only auto-generate
- * backpressure through HiGig2 messages (optionally, when BGX_SMU_HG2_CONTROL[HG2TX_EN]=1) with
- * the HiGig2 protocol.
+ * BGX(0..5)_CMR_RX_OVR_BP[EN<0>] must be set to one and BGX(0..5)_CMR_RX_OVR_BP[BP<0>] must be
+ * cleared to zero (to forcibly disable hardware-automatic 802.3 PAUSE packet generation) with
+ * the HiGig2 Protocol when BGX(0..5)_SMU(0..3)_HG2_CONTROL[HG2TX_EN]=0. (The HiGig2 protocol is
+ * indicated by BGX(0..5)_SMU(0..3)_TX_CTL[HG_EN]=1 and BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN]=16).
+ * Hardware can only auto-generate backpressure through HiGig2 messages (optionally, when
+ * BGX(0..5)_SMU(0..3)_HG2_CONTROL[HG2TX_EN]=1) with the HiGig2 protocol.
  */
 union cvmx_bgxx_cmr_rx_ovr_bp {
 	uint64_t u64;
@@ -3420,15 +3423,15 @@ typedef union cvmx_bgxx_cmr_rx_ovr_bp cvmx_bgxx_cmr_rx_ovr_bp_t;
 /**
  * cvmx_bgx#_cmr_tx_lmacs
  *
- * Number of transmit LMACs.
- *
+ * This register sets the number of LMACs allowed on the TX interface. The value is important for
+ * defining the partitioning of the transmit FIFO.
  */
 union cvmx_bgxx_cmr_tx_lmacs {
 	uint64_t u64;
 	struct cvmx_bgxx_cmr_tx_lmacs_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t lmacs                        : 3;  /**< "Number of LMACS: Specifies the number of LMACs that can be enabled.
+	uint64_t lmacs                        : 3;  /**< '"Number of LMACS: Specifies the number of LMACs that can be enabled.
                                                          This determines the logical TX buffer size per LMAC and the maximum
                                                          LMAC ID that can be used:
                                                            ----------+---------------------------------------------------
@@ -3442,9 +3445,9 @@ union cvmx_bgxx_cmr_tx_lmacs {
                                                            4         |   8KB                 3
                                                            5-7       |   reserved
                                                            ----------+---------------------------------------------------
-                                                         Note: The maximum LMAC ID is determined by the smaller of
-                                                         BGX_CMR_RX_LMACS[LMACS] and BGX_CMR_TX_LMACS[LMACS]. The two fields
-                                                         should be set to the same value for normal operation." */
+                                                         NOTE: The maximum LMAC ID is determined by the smaller of BGX(0..5)_CMR_RX_LMACS[LMACS]
+                                                         and BGX(0..5)_CMR_TX_LMACS[LMACS]. The two fields should be set to the same value for
+                                                         normal operation.' */
 #else
 	uint64_t lmacs                        : 3;
 	uint64_t reserved_3_63                : 61;
@@ -3469,10 +3472,10 @@ union cvmx_bgxx_gmp_gmi_prtx_cfg {
 	uint64_t rx_idle                      : 1;  /**< RX machine is idle. */
 	uint64_t reserved_9_11                : 3;
 	uint64_t speed_msb                    : 1;  /**< Link speed MSB [SPEED_MSB:SPEED]
-                                                         10 = 10 Mb/s operation
-                                                         00 = 100 Mb/s operation
-                                                         01 = 1000 Mb/s operation
-                                                         11 = Reserved
+                                                         0x2 = 10 Mb/s operation.
+                                                         0x0 = 100 Mb/s operation.
+                                                         0x1 = 1000 Mb/s operation.
+                                                         0x3 = Reserved.
                                                          (SGMII/1000Base-X only) */
 	uint64_t reserved_4_7                 : 4;
 	uint64_t slottime                     : 1;  /**< Slot time for half-duplex operation
@@ -3483,10 +3486,10 @@ union cvmx_bgxx_gmp_gmi_prtx_cfg {
                                                          0 = half-duplex (collisions/extensions/bursts), 1 = full-duplex.
                                                          (SGMII/1000Base-X only) */
 	uint64_t speed                        : 1;  /**< Link Speed LSB [SPEED_MSB:SPEED]
-                                                         10 = 10 Mb/s operation
-                                                         00 = 100 Mb/s operation
-                                                         01 = 1000 Mb/s operation
-                                                         11 = Reserved
+                                                         0x2 = 10 Mb/s operation.
+                                                         0x0 = 100 Mb/s operation.
+                                                         0x1 = 1000 Mb/s operation.
+                                                         0x3 = Reserved.
                                                          (SGMII/1000Base-X only) */
 	uint64_t reserved_0_0                 : 1;
 #else
@@ -3509,7 +3512,13 @@ typedef union cvmx_bgxx_gmp_gmi_prtx_cfg cvmx_bgxx_gmp_gmi_prtx_cfg_t;
 /**
  * cvmx_bgx#_gmp_gmi_rx#_decision
  *
- * Notes:
+ * This register specifies the byte count used to determine when to accept or to filter a packet.
+ * As each byte in a packet is received by GMI, the L2 byte count is compared against the
+ * BGX(0..5)_GMP_GMI_RX(0..3)_DECISION[CNT]. In normal operation, the L2 header begins after the
+ * PREAMBLE + SFD (BGX(0..5)_GMP_GMI_RX(0..3)_FRM_CTL[PRE_CHK] = 1) and any optional UDD skip
+ * data (BGX(0..5)_GMP_GMI_RX(0..3)_UDD_SKP[LEN]).
+ *
+ * INTERNAL: Notes:
  * As each byte in a packet is received by GMI, the L2 byte count is compared
  * against the BGX_GMP_GMI_RX_DECISION[CNT].  The L2 byte count is the number of bytes
  * from the beginning of the L2 header (DMAC).  In normal operation, the L2
@@ -3578,7 +3587,17 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_frm_chk cvmx_bgxx_gmp_gmi_rxx_frm_chk_t;
 /**
  * cvmx_bgx#_gmp_gmi_rx#_frm_ctl
  *
- * Notes:
+ * This register controls the handling of the frames.
+ * The CTL_BCK/CTL_DRP bits control how the hardware handles incoming PAUSE packets. The most
+ * common modes of operation:
+ * CTL_BCK = 1, CTL_DRP = 1: hardware handles everything
+ * CTL_BCK = 0, CTL_DRP = 0: software sees all PAUSE frames
+ * CTL_BCK = 0, CTL_DRP = 1: all PAUSE frames are completely ignored
+ * These control bits should be set to CTL_BCK = 0,CTL_DRP = 0 in half-duplex mode. Since PAUSE
+ * packets only apply to full duplex operation, any PAUSE packet would constitute an exception
+ * which should be handled by the processing cores. PAUSE packets should not be forwarded.
+ *
+ * INTERNAL: Notes:
  * PRE_STRP
  * When PRE_CHK is set (indicating that the PREAMBLE will be sent), PRE_STRP
  * determines if the PREAMBLE+SFD bytes are thrown away or sent to the Octane
@@ -3587,16 +3606,6 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_frm_chk cvmx_bgxx_gmp_gmi_rxx_frm_chk_t;
  * size when checking against the MIN and MAX bounds.  Furthermore, the bytes
  * are skipped when locating the start of the L2 header for DMAC and Control
  * frame recognition.
- * CTL_BCK/CTL_DRP
- * These bits control how the HW handles incoming PAUSE packets.  Here are
- * the most common modes of operation:
- * CTL_BCK=1,CTL_DRP=1   - HW does it all
- * CTL_BCK=0,CTL_DRP=0   - SW sees all pause frames
- * CTL_BCK=0,CTL_DRP=1   - all pause frames are completely ignored
- * These control bits should be set to CTL_BCK=0,CTL_DRP=0 in halfdup mode.
- * Since PAUSE packets only apply to fulldup operation, any PAUSE packet
- * would constitute an exception which should be handled by the processing
- * cores.  PAUSE packets should not be forwarded.
  */
 union cvmx_bgxx_gmp_gmi_rxx_frm_ctl {
 	uint64_t u64;
@@ -3606,19 +3615,19 @@ union cvmx_bgxx_gmp_gmi_rxx_frm_ctl {
 	uint64_t ptp_mode                     : 1;  /**< Timestamp mode. When PTP_MODE is set, a 64-bit timestamp is prepended to every incoming
                                                          packet.
                                                          The timestamp bytes are added to the packet in such a way as to not modify the packet's
-                                                         receive byte count. This implies that the BGX(0..5)_GMP_GMI_RX(0..3)_RX_JABBER,
-                                                         BGX(0..5)_GMP_GMI_RX(0..3)_RX_DECISION, BGX(0..5)_GMP_GMI_RX(0..3)_UDD_SKP, and
+                                                         receive byte count. This implies that the BGX(0..5)_GMP_GMI_RX(0..3)_JABBER,
+                                                         BGX(0..5)_GMP_GMI_RX(0..3)_DECISION, BGX(0..5)_GMP_GMI_RX(0..3)_UDD_SKP, and
                                                          BGX(0..5)_CMR(0..3)_RX_STAT* do not require any adjustment as they operate on the received
                                                          packet size. When the packet reaches PKI, its size reflects the additional bytes and is
                                                          subject to the following restrictions:
                                                          If PTP_MODE = 1 and PRE_CHK = 1, PRE_STRP must be 1.
                                                          If PTP_MODE = 1
-                                                         PKI_CL(0..3)_PKIND(0..63)_SKIP[FCS_SKIP,INST_SKIP] should be increased by 8.
-                                                         PKI_CL(0..3)_PKIND(0..63)_CFG[HG_EN] should be 0.
-                                                         PKI_FRM_LEN_CHK(0..1)[MAXLEN] should be increased by 8.
-                                                         PKI_FRM_LEN_CHK(0..1)[MINLEN] should be increased by 8.
-                                                         PKI_TAG_INC(0..63)_MASK should be adjusted.
-                                                         This supported in uCode in O78 >>> PIP_PRT_CFGB(0..63)[ALT_SKP_EN] should be 0. */
+                                                         * PKI_CL(0..3)_PKIND(0..63)_SKIP[FCS_SKIP,INST_SKIP] should be increased by 8.
+                                                         * PKI_CL(0..3)_PKIND(0..63)_CFG[HG_EN] should be 0.
+                                                         * PKI_FRM_LEN_CHK(0..1)[MAXLEN] should be increased by 8.
+                                                         * PKI_FRM_LEN_CHK(0..1)[MINLEN] should be increased by 8.
+                                                         * PKI_TAG_INC(0..31)_MASK[EN] should be adjusted.
+                                                         This supported in uCode in CN78XX >>> PIP_PRT_CFGB(0..63)[ALT_SKP_EN] should be 0. */
 	uint64_t reserved_11_11               : 1;
 	uint64_t null_dis                     : 1;  /**< When set, do not modify the MOD bits on NULL ticks due to partial packets. */
 	uint64_t pre_align                    : 1;  /**< When set, PREAMBLE parser aligns the SFD byte regardless of the number of previous
@@ -3697,7 +3706,14 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_ifg cvmx_bgxx_gmp_gmi_rxx_ifg_t;
 /**
  * cvmx_bgx#_gmp_gmi_rx#_int
  *
- * "Notes:
+ * "These registers allow interrupts to be sent to the control processor.
+ * * Exception conditions <10:0> can also set the rcv/opcode in the received packet's work-queue
+ * entry. BGX(0..5)_GMP_GMI_RX(0..3)_FRM_CHK provides a bit mask for configuring which conditions
+ * set the error.
+ * In half duplex operation, the expectation is that collisions will appear as either MINERR or
+ * CAREXT errors.
+ *
+ * INTERNAL: Notes:
  * (2) exception conditions 10:0 can also set the rcv/opcode in the received
  * packet's workQ entry.  The BGX_GMP_GMI_RX_FRM_CHK register provides a bit mask
  * for configuring which conditions set the error.
@@ -3762,14 +3778,13 @@ union cvmx_bgxx_gmp_gmi_rxx_int {
                                                          Does not check the number of PREAMBLE cycles. */
 	uint64_t ovrerr                       : 1;  /**< Internal data aggregation overflow. This interrupt should never assert. SGMII/1000Base-X only. */
 	uint64_t skperr                       : 1;  /**< Skipper error. */
-	uint64_t rcverr                       : 1;  /**< Data-reception error. Frame was received with data-reception error */
-	uint64_t fcserr                       : 1;  /**< FCS/CRC error. Frame was received with FCS/CRC error */
+	uint64_t rcverr                       : 1;  /**< Data-reception error. Frame was received with data-reception error. */
+	uint64_t fcserr                       : 1;  /**< FCS/CRC error. Frame was received with FCS/CRC error. */
 	uint64_t jabber                       : 1;  /**< System-length error: frame was received with length > sys_length.
                                                          An RX Jabber error indicates that a packet was received which is longer than the maximum
                                                          allowed packet as defined by the system. GMI truncates the packet at the JABBER count.
                                                          Failure to do so could lead to system instability. */
-	uint64_t carext                       : 1;  /**< Carrier extend error
-                                                         (SGMII/1000Base-X only) */
+	uint64_t carext                       : 1;  /**< Carrier-extend error. (SGMII/1000Base-X only) */
 	uint64_t minerr                       : 1;  /**< PAUSE frame was received with length < minFrameSize. Frame length checks are typically
                                                          handled in PKI, but PAUSE frames are normally discarded before being inspected by PKI.
                                                          Total frame DA+SA+TL+DATA+PAD+FCS < 64. */
@@ -3826,7 +3841,10 @@ typedef union cvmx_bgxx_gmp_gmi_rxx_jabber cvmx_bgxx_gmp_gmi_rxx_jabber_t;
 /**
  * cvmx_bgx#_gmp_gmi_rx#_udd_skp
  *
- * Notes:
+ * This register specifies the amount of user-defined data (UDD) added before the start of the
+ * L2C data.
+ *
+ * INTERNAL: Notes:
  * (1) The skip bytes are part of the packet and will be sent down the NCB
  * packet interface and will be handled by PKI.
  * (2) The system can determine if the UDD bytes are included in the FCS check
@@ -3853,11 +3871,12 @@ union cvmx_bgxx_gmp_gmi_rxx_udd_skp {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
 	uint64_t fcssel                       : 1;  /**< Include the skip bytes in the FCS calculation.
-                                                         0 = all skip bytes are included in FCS
-                                                         1 = the skip bytes are not included in FCS
-                                                         The skip bytes are part of the packet and are sent through the IOI packet interface and
-                                                         are handled by PKI. The system can determine if the UDD bytes are included in the FCS
-                                                         check by using the FCSSEL field, if the FCS check is enabled. */
+                                                         0 = All skip bytes are included in FCS.
+                                                         1 = The skip bytes are not included in FCS.
+                                                         When BGX(0..5)_GMP_GMI_TX(0..3)_CTL[HG_EN] is set, this field must be 0.
+                                                         The skip bytes are part of the packet and are sent down the NCB packet interface and are
+                                                         handled by PKI. The system can determine if the UDD bytes are included in the FCS check by
+                                                         using the FCSSEL field, if the FCS check is enabled. */
 	uint64_t reserved_7_7                 : 1;
 	uint64_t len                          : 7;  /**< Amount of user-defined data before the start of the L2C data, in bytes.
                                                          Setting to 0 means L2C comes first; maximum value is 64.
@@ -4010,7 +4029,9 @@ typedef union cvmx_bgxx_gmp_gmi_txx_min_pkt cvmx_bgxx_gmp_gmi_txx_min_pkt_t;
 /**
  * cvmx_bgx#_gmp_gmi_tx#_pause_pkt_interval
  *
- * Notes:
+ * This register specifies how often PAUSE packets are sent.
+ *
+ * INTERNAL: Notes:
  * Choosing proper values of BGX_GMP_GMI_TX_PAUSE_PKT_TIME[TIME] and
  * BGX_GMP_GMI_TX_PAUSE_PKT_INTERVAL[INTERVAL] can be challenging to the system
  * designer.  It is suggested that TIME be much greater than INTERVAL and
@@ -4110,13 +4131,13 @@ union cvmx_bgxx_gmp_gmi_txx_sgmii_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_1_63                : 63;
 	uint64_t align                        : 1;  /**< Align the transmission to even cycles: (SGMII/1000BASE-X half-duplex only)
-                                                         Recommended value is: ALIGN = !BGXn_GMP_GMI_TXm_APPEND[PREAMBLE].
+                                                         Recommended value is: ALIGN = !BGX(0..5)_GMP_GMI_TX(0..3)_APPEND[PREAMBLE].
                                                          (See Transmit Conversion to Code groups, Transmit Conversion to Code Groups for a complete
                                                          discussion.)
                                                          0 = Data can be sent on any cycle. In this mode, the interface functions at maximum
                                                          bandwidth. It is possible for the TX PCS machine to drop the first byte of the TX frame.
-                                                         When BGXn_GMP_GMI_TXm_APPEND[PREAMBLE] is set, the first byte is a preamble byte, which
-                                                         can be dropped to compensate for an extended IPG.
+                                                         When BGX(0..5)_GMP_GMI_TX(0..3)_APPEND[PREAMBLE] is set, the first byte is a preamble
+                                                         byte, which can be dropped to compensate for an extended IPG.
                                                          1 = Data is only sent on even cycles. In this mode, there can be bandwidth implications
                                                          when sending odd-byte packets as the IPG can extend an extra cycle. There will be no loss
                                                          of data. */
@@ -4138,8 +4159,8 @@ union cvmx_bgxx_gmp_gmi_txx_slot {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
 	uint64_t slot                         : 10; /**< Slottime (refer to Std 802.3 to set correctly):
-                                                         10/100Mbs: set SLOT to 0x40
-                                                         1000Mbs: set SLOT to 0x200
+                                                         10/100 Mbs: Set SLOT to 0x40.
+                                                         1000 Mbs: Set SLOT to 0x200.
                                                          SGMII/1000Base-X only. */
 #else
 	uint64_t slot                         : 10;
@@ -4215,9 +4236,9 @@ typedef union cvmx_bgxx_gmp_gmi_tx_col_attempt cvmx_bgxx_gmp_gmi_tx_col_attempt_
  * cvmx_bgx#_gmp_gmi_tx_ifg
  *
  * Consider the following when programming IFG1 and IFG2:
- * For 10/100/1000 Mb/s half-duplex systems that require IEEE 802.3 compatibility, IFG1 must be
+ * * For 10/100/1000 Mb/s half-duplex systems that require IEEE 802.3 compatibility, IFG1 must be
  * in the range of 1-8, IFG2 must be in the range of 4-12, and the IFG1 + IFG2 sum must be 12.
- * For 10/100/1000 Mb/s full-duplex systems that require IEEE 802.3 compatibility, IFG1 must be
+ * * For 10/100/1000 Mb/s full-duplex systems that require IEEE 802.3 compatibility, IFG1 must be
  * in the range of 1-11, IFG2 must be in the range of 1-11, and the IFG1 + IFG2 sum must be 12.
  * For all other systems, IFG1 and IFG2 can be any value in the range of 1-15, allowing for a
  * total possible IFG sum of 2-30.
@@ -4336,17 +4357,17 @@ union cvmx_bgxx_gmp_pcs_anx_adv {
 	uint64_t np                           : 1;  /**< Next page capable. This feature is not supported; this field is always 0. */
 	uint64_t reserved_14_14               : 1;
 	uint64_t rem_flt                      : 2;  /**< Remote fault.
-                                                         00 = Link OK, XMIT = DATA
-                                                         01 = Link failure (loss of sync, XMIT !=DATA)
-                                                         10 = Local device offline
-                                                         11 = Auto-Negotiation error; failure to complete Auto-Negotiation. AN error is set if
+                                                         0x0 = Link OK, XMIT = DATA
+                                                         0x1 = Link failure (loss of sync, XMIT !=DATA)
+                                                         0x2 = Local device offline
+                                                         0x3 = Auto-Negotiation error; failure to complete Auto-Negotiation. AN error is set if
                                                          resolution function precludes operation with link partner. */
 	uint64_t reserved_9_11                : 3;
 	uint64_t pause                        : 2;  /**< PAUSE frame flow capability across link, exchanged during Auto-Negotiation as follows:
-                                                         00 = No PAUSE.
-                                                         01 = Symmetric PAUSE.
-                                                         10 = Asymmetric PAUSE.
-                                                         11 = Both symmetric and asymmetric PAUSE to local device. */
+                                                         0x0 = No PAUSE.
+                                                         0x1 = Symmetric PAUSE.
+                                                         0x2 = Asymmetric PAUSE.
+                                                         0x3 = Both symmetric and asymmetric PAUSE to local device. */
 	uint64_t hfd                          : 1;  /**< Half-duplex. When set, local device is half-duplex capable. */
 	uint64_t fd                           : 1;  /**< Full-duplex. When set, local device is full-duplex capable. */
 	uint64_t reserved_0_4                 : 5;
@@ -4407,16 +4428,16 @@ union cvmx_bgxx_gmp_pcs_anx_lp_abil {
                                                          1 = Link partner next page capable. */
 	uint64_t ack                          : 1;  /**< When set, indicates acknowledgement received. */
 	uint64_t rem_flt                      : 2;  /**< Link partner's link status as follows:
-                                                         00 = Link OK.
-                                                         01 = Offline.
-                                                         10 = Link failure.
-                                                         11 = Auto-Negotiation error. */
+                                                         0x0 = Link OK.
+                                                         0x1 = Offline.
+                                                         0x2 = Link failure.
+                                                         0x3 = Auto-Negotiation error. */
 	uint64_t reserved_9_11                : 3;
 	uint64_t pause                        : 2;  /**< Link partner PAUSE setting as follows:
-                                                         00 = No PAUSE.
-                                                         01 = Symmetric PAUSE.
-                                                         10 = Asymmetric PAUSE.
-                                                         11 = Both symmetric and asymmetric PAUSE to local device. */
+                                                         0x0 = No PAUSE.
+                                                         0x1 = Symmetric PAUSE.
+                                                         0x2 = Asymmetric PAUSE.
+                                                         0x3 = Both symmetric and asymmetric PAUSE to local device. */
 	uint64_t hfd                          : 1;  /**< Half-duplex. When set, link partner is half-duplex capable. */
 	uint64_t fd                           : 1;  /**< Full-duplex. When set, link partner is full-duplex capable. */
 	uint64_t reserved_0_4                 : 5;
@@ -4449,15 +4470,15 @@ union cvmx_bgxx_gmp_pcs_anx_results {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_7_63                : 57;
 	uint64_t pause                        : 2;  /**< PAUSE selection ('don't care' for SGMII) as follows:
-                                                         00 = Disable PAUSE, TX and RX.
-                                                         01 = Enable PAUSE frames, RX only.
-                                                         10 = Enable PAUSE frames, TX only.
-                                                         11 = Enable PAUSE frames, TX and RX. */
+                                                         0x0 = Disable PAUSE, TX and RX.
+                                                         0x1 = Enable PAUSE frames, RX only.
+                                                         0x2 = Enable PAUSE frames, TX only.
+                                                         0x3 = Enable PAUSE frames, TX and RX. */
 	uint64_t spd                          : 2;  /**< Link speed selection as follows:
-                                                         00 = 10 Mb/s.
-                                                         01 = 100 Mb/s.
-                                                         10 = 1000 Mb/s.
-                                                         11 = Reserved. */
+                                                         0x0 = 10 Mb/s.
+                                                         0x1 = 100 Mb/s.
+                                                         0x2 = 1000 Mb/s.
+                                                         0x3 = Reserved. */
 	uint64_t an_cpt                       : 1;  /**< Auto-Negotiation completed.
                                                          1 = Auto-Negotiation completed.
                                                          0 = Auto-Negotiation not completed or failed. */
@@ -4554,6 +4575,7 @@ typedef union cvmx_bgxx_gmp_pcs_linkx_timer cvmx_bgxx_gmp_pcs_linkx_timer_t;
 /**
  * cvmx_bgx#_gmp_pcs_misc#_ctl
  *
+ * INTERNAL:
  * SGMII bit [12] is really a misnomer, it is a decode  of pi_qlm_cfg pins to indicate SGMII or
  * 1000Base-X modes.
  * Note: MODE bit
@@ -4573,7 +4595,7 @@ union cvmx_bgxx_gmp_pcs_miscx_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_13_63               : 51;
 	uint64_t sgmii                        : 1;  /**< SGMII mode. 1 = SGMII or 1000BASE-X mode selected, 0 = other mode selected. See
-                                                         GSERx_LANE_MODE[LMODE]. */
+                                                         GSER(0..13)_LANE_MODE[LMODE]. */
 	uint64_t gmxeno                       : 1;  /**< GMI enable override. When set, forces GMI to appear disabled. The enable/disable status of
                                                          GMI is checked only at SOP of every packet. */
 	uint64_t loopbck2                     : 1;  /**< Sets external loopback mode to return RX data back out via the TX data path. 0 = No
@@ -4804,10 +4826,10 @@ union cvmx_bgxx_gmp_pcs_sgmx_an_adv {
 	uint64_t reserved_13_13               : 1;
 	uint64_t dup                          : 1;  /**< Duplex mode: 1 = full duplex, 0 = half duplex */
 	uint64_t speed                        : 2;  /**< Link speed:
-                                                         00 = 10 Mb/s.
-                                                         01 = 100 Mb/s.
-                                                         10 = 1000 Mb/s.
-                                                         11 = Reserved. */
+                                                         0x0 = 10 Mb/s.
+                                                         0x1 = 100 Mb/s.
+                                                         0x2 = 1000 Mb/s.
+                                                         0x3 = Reserved. */
 	uint64_t reserved_1_9                 : 9;
 	uint64_t one                          : 1;  /**< Always set to match TX_CONFIG_REG<0>. */
 #else
@@ -4840,10 +4862,10 @@ union cvmx_bgxx_gmp_pcs_sgmx_lp_adv {
 	uint64_t reserved_13_14               : 2;
 	uint64_t dup                          : 1;  /**< Duplex mode: 1 = Full duplex, 0 = Half duplex */
 	uint64_t speed                        : 2;  /**< Link speed:
-                                                         00 = 10 Mb/s.
-                                                         01 = 100 Mb/s.
-                                                         10 = 1000 Mb/s.
-                                                         11 = Reserved. */
+                                                         0x0 = 10 Mb/s.
+                                                         0x1 = 100 Mb/s.
+                                                         0x2 = 1000 Mb/s.
+                                                         0x3 = Reserved. */
 	uint64_t reserved_1_9                 : 9;
 	uint64_t one                          : 1;  /**< Always set to match TX_CONFIG_REG<0> */
 #else
@@ -4871,7 +4893,7 @@ union cvmx_bgxx_gmp_pcs_txx_states {
 	uint64_t xmit                         : 2;  /**< 0x0 = Undefined.
                                                          0x1 = Config.
                                                          0x2 = Idle.
-                                                         0x3 = Data */
+                                                         0x3 = Data. */
 	uint64_t tx_bad                       : 1;  /**< Transmit state machine in an illegal state. */
 	uint64_t ord_st                       : 4;  /**< Transmit ordered set state-machine state. */
 #else
@@ -4962,8 +4984,9 @@ union cvmx_bgxx_smux_ctrl {
 	struct cvmx_bgxx_smux_ctrl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t tx_idle                      : 1;  /**< TX machine is idle This indication pertains to the framer FSM and ignores the effects on
-                                                         the data-path controls or values which occur when BGX_SMU_TX_CTL[LS_BYP] is set */
+	uint64_t tx_idle                      : 1;  /**< TX machine is idle. This indication pertains to the framer FSM and ignores the effects on
+                                                         the data-path controls or values which occur when BGX(0..5)_SMU(0..3)_TX_CTL[LS_BYP] is
+                                                         set. */
 	uint64_t rx_idle                      : 1;  /**< RX machine is idle. */
 #else
 	uint64_t rx_idle                      : 1;
@@ -5031,14 +5054,12 @@ union cvmx_bgxx_smux_hg2_control {
                                                          when HiGig2 messages are present in the receive stream. This bit is also forwarded to CMR
                                                          so it can generate the required deferring signals to SMU TX and backpressure signals to
                                                          PKO. */
-	uint64_t phys_en                      : 1;  /**< 1 bit physical link pause enable for recevied
-                                                         HiGig2 physical pause message. This bit enables the SMU TX
-                                                         to CMR HG2 deferring counter to be set every time SMU RX
-                                                         receives and filters out a valid physical HG2 message. */
-	uint64_t logl_en                      : 16; /**< 16 bit xof enables for recevied HiGig2 messages
-                                                         or PFC/CBFC packets. This field is NOT used by SMU at all.
-                                                         It is forwarded to CMR without alteration. It appears here
-                                                         for backward compatibility with O68. */
+	uint64_t phys_en                      : 1;  /**< Physical-link PAUSE enable for received HiGig2 physical PAUSE message. This bit enables
+                                                         the SMU TX to CMR HG2 deferring counter to be set every time SMU RX receives and filters
+                                                         out a valid physical HG2 message. */
+	uint64_t logl_en                      : 16; /**< 16-bit XOF enables for received HiGig2 messages or PFC/CBFC packets. This field is NOT
+                                                         used by SMU at all. It is forwarded to CMR without alteration. It appears here for
+                                                         backward compatibility. */
 #else
 	uint64_t logl_en                      : 16;
 	uint64_t phys_en                      : 1;
@@ -5179,7 +5200,7 @@ typedef union cvmx_bgxx_smux_rx_frm_chk cvmx_bgxx_smux_rx_frm_chk_t;
  * CTL_BCK = 1, CTL_DRP = 1: hardware handles everything
  * CTL_BCK = 0, CTL_DRP = 0: software sees all PAUSE frames
  * CTL_BCK = 0, CTL_DRP = 1: all PAUSE frames are completely ignored
- * These control bits should be set to CTL_BCK = 0,CTL_DRP = 0 in half-duplex mode. Since PAUSE
+ * These control bits should be set to CTL_BCK = 0, CTL_DRP = 0 in half-duplex mode. Since PAUSE
  * packets only apply to full duplex operation, any PAUSE packet would constitute an exception
  * which should be handled by the processing cores. PAUSE packets should not be forwarded.
  */
@@ -5197,12 +5218,12 @@ union cvmx_bgxx_smux_rx_frm_ctl {
                                                          size reflects the additional bytes and is subject to the following restrictions:
                                                          If PTP_MODE = 1 and PRE_CHK = 1, PRE_STRP must be 1.
                                                          If PTP_MODE = 1
-                                                         PKI_CL(0..3)_PKIND(0..63)_SKIP[FCS_SKIP,INST_SKIP] should be increased by 8
-                                                         PKI_CL(0..3)_PKIND(0..63)_CFG[HG_EN] should be 0
-                                                         PKI_FRM_LEN_CHK(0..1)[MAXLEN] should be increased by 8
-                                                         PKI_FRM_LEN_CHK(0..1)[MINLEN] should be increased by 8
-                                                         PKI_TAG_INC(0..63)_MASK should be adjusted
-                                                         This supported in uCode in O78 >>> PIP_PRT_CFGB(0..63)[ALT_SKP_EN] should be 0. */
+                                                         * PKI_CL(0..3)_PKIND(0..63)_SKIP[FCS_SKIP,INST_SKIP] should be increased by 8
+                                                         * PKI_CL(0..3)_PKIND(0..63)_CFG[HG_EN] should be 0
+                                                         * PKI_FRM_LEN_CHK(0..1)[MAXLEN] should be increased by 8
+                                                         * PKI_FRM_LEN_CHK(0..1)[MINLEN] should be increased by 8
+                                                         * PKI_TAG_INC(0..31)_MASK should be adjusted
+                                                         This supported in uCode in CN78XX>>> PIP_PRT_CFGB(0..63)[ALT_SKP_EN] should be 0. */
 	uint64_t reserved_6_11                : 6;
 	uint64_t ctl_smac                     : 1;  /**< Control PAUSE frames can match station SMAC. */
 	uint64_t ctl_mcst                     : 1;  /**< Control PAUSE frames can match globally assign multicast address. */
@@ -5409,17 +5430,14 @@ union cvmx_bgxx_smux_tx_ctl {
 	struct cvmx_bgxx_smux_tx_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_31_63               : 33;
-	uint64_t spu_mrk_cnt                  : 20; /**< 40GBASE-R Transmit Marker Interval Count: Specifies the interval
-                                                         (number of 66-bit BASE-R blocks) at which the LMAC transmit logic
-                                                         inserts 40GBASE-R alignment markers. An internal counter in SMU is
-                                                         initialized to this value, counts down for each BASE-R block
-                                                         transmitted by the LMAC, and wraps back to the initial value from 0.
-                                                         The LMAC transmit logic inserts alignment markers for lanes 0, 1, 2
-                                                         and 3, respectively, in the last four BASE-R blocks before the
-                                                         counter wraps (3, 2, 1, 0). The default value corresponds to an
-                                                         alignment marker period of 16363 blocks (exclusive) per lane, as
-                                                         specified in 802.3ba-2010. The default value should always be used
-                                                         for normal operation. */
+	uint64_t spu_mrk_cnt                  : 20; /**< 40GBASE-R transmit marker interval count. Specifies the interval (number of 66-bit BASE-R
+                                                         blocks) at which the LMAC transmit logic inserts 40GBASE-R alignment markers. An internal
+                                                         counter in SMU is initialized to this value, counts down for each BASE-R block transmitted
+                                                         by the LMAC, and wraps back to the initial value from 0. The LMAC transmit logic inserts
+                                                         alignment markers for lanes 0, 1, 2 and 3, respectively, in the last four BASE-R blocks
+                                                         before the counter wraps (3, 2, 1, 0). The default value corresponds to an alignment
+                                                         marker period of 16363 blocks (exclusive) per lane, as specified in 802.3ba-2010. The
+                                                         default value should always be used for normal operation. */
 	uint64_t hg_pause_hgi                 : 2;  /**< HGI field for hardware-generated HiGig PAUSE packets. */
 	uint64_t hg_en                        : 1;  /**< Enable HiGig mode.
                                                          When this field is set and BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] = 12, the interface is in
@@ -5434,9 +5452,9 @@ union cvmx_bgxx_smux_tx_ctl {
                                                          BGX(0..5)_SMU(0..3)_RX_UDD_SKP[FCSSEL] = 0
                                                          BGX(0..5)_SMU(0..3)_RX_UDD_SKP[LEN] = 16
                                                          BGX(0..5)_SMU(0..3)_TX_APPEND[PREAMBLE] = 0
-                                                         BGX(0..5)_SMU(0..3)_SMUX_CBFC_CTL[RX_EN] = 0
+                                                         BGX(0..5)_SMU(0..3)_CBFC_CTL[RX_EN] = 0
                                                          BGX(0..5)_SMU(0..3)_CBFC_CTL[TX_EN] = 0 */
-	uint64_t l2p_bp_conv                  : 1;  /**< If set will cause TX to generate 802.3 pause packets when CMR applies logical backpressure
+	uint64_t l2p_bp_conv                  : 1;  /**< If set, causes TX to generate 802.3 pause packets when CMR applies logical backpressure
                                                          (XOFF), if and only if BGX(0..5)_SMU(0..3)_CBFC_CTL[TX_EN] is clear and
                                                          BGX(0..5)_SMU(0..3)_HG2_CONTROL[HG2TX_EN] is clear. */
 	uint64_t ls_byp                       : 1;  /**< Bypass the link status, as determined by the XGMII receiver, and set the link status of
@@ -5470,10 +5488,10 @@ typedef union cvmx_bgxx_smux_tx_ctl cvmx_bgxx_smux_tx_ctl_t;
  * cvmx_bgx#_smu#_tx_ifg
  *
  * Programming IFG1 and IFG2:
- * For XAUI/RXAUI/10Gbs/40Gbs systems that require IEEE 802.3 compatibility, the IFG1+IFG2 sum
+ * * For XAUI/RXAUI/10Gbs/40Gbs systems that require IEEE 802.3 compatibility, the IFG1+IFG2 sum
  * must be 12.
- * In loopback mode, the IFG1+IFG2 of local and remote parties must match exactly; otherwise one
- * of the two sides' loopback FIFO will overrun: BGX(0..5)_SMU(0..3)_TX_INT[LB_OVRFLW].
+ * * In loopback mode, the IFG1+IFG2 of local and remote parties must match exactly; otherwise
+ * one of the two sides' loopback FIFO will overrun: BGX(0..5)_SMU(0..3)_TX_INT[LB_OVRFLW].
  */
 union cvmx_bgxx_smux_tx_ifg {
 	uint64_t u64;
@@ -5528,8 +5546,8 @@ union cvmx_bgxx_smux_tx_min_pkt {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
 	uint64_t min_size                     : 8;  /**< Min frame in bytes inclusive of FCS, if applied. Padding is only appended when
-                                                         BGX_TX_APPEND[PAD] for the corresponding port is set. When FCS is added to a packet which
-                                                         was padded, the FCS always appears in the 4 octets preceding /T/ or /E/. */
+                                                         BGX(0..5)_SMU(0..3)_TX_APPEND[PAD] for the corresponding port is set. When FCS is added to
+                                                         a packet which was padded, the FCS always appears in the 4 octets preceding /T/ or /E/. */
 #else
 	uint64_t min_size                     : 8;
 	uint64_t reserved_8_63                : 56;
@@ -5550,7 +5568,7 @@ union cvmx_bgxx_smux_tx_pause_pkt_dmac {
 	struct cvmx_bgxx_smux_tx_pause_pkt_dmac_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t dmac                         : 48; /**< The DMAC field, which is placed is outbound PAUSE packets. */
+	uint64_t dmac                         : 48; /**< The DMAC field that is placed in outbound PAUSE packets. */
 #else
 	uint64_t dmac                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -5574,7 +5592,7 @@ union cvmx_bgxx_smux_tx_pause_pkt_interval {
 	uint64_t hg2_intra_en                 : 1;  /**< Allow intrapacket HiGig2 message generation. Relevant only if HiGig2 message generation is enabled. */
 	uint64_t hg2_intra_interval           : 16; /**< Arbitrate for a HiGig2 message, every (INTERVAL*512) bit-times whilst sending regular
                                                          packet data. Relevant only if HiGig2 message generation and HG2_INTRA_EN are both set.
-                                                         Normally, 0 < INTERVAL < BGX_TX_PAUSE_PKT_TIME.
+                                                         Normally, 0 < INTERVAL < BGX(0..5)_SMU(0..3)_TX_PAUSE_PKT_TIME.
                                                          INTERVAL = 0 only sends a single PAUSE packet for each backpressure event. */
 	uint64_t interval                     : 16; /**< Arbitrate for a 802.3 PAUSE packet, HiGig2 message, or PFC/CBFC PAUSE packet every
                                                          (INTERVAL * 512) bit-times.
@@ -5724,7 +5742,7 @@ typedef union cvmx_bgxx_smux_tx_thresh cvmx_bgxx_smux_tx_thresh_t;
  * operations to this register prior to completion of Auto-Negotiation, as indicated by
  * BGX(0..5)_SPU(0..3)_AN_STATUS[AN_COMPLETE], should be followed by a renegotiation in order for
  * the new values to take effect. Renegotiation is initiated by setting
- * BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_RESTART]. Once Auto-Negotiation has completed, software can
+ * BGX(0..5)_SPU(0..3)_AN_STATUS[AN_RESTART]. Once Auto-Negotiation has completed, software can
  * examine this register along with BGX(0..5)_SPU(0..3)_AN_LP_BASE to determine the highest
  * common denominator technology.
  */
@@ -5796,12 +5814,12 @@ union cvmx_bgxx_spux_an_bp_status {
 	uint64_t reserved_9_63                : 55;
 	uint64_t n100g_cr10                   : 1;  /**< 100GBASE-CR10 negotiated; expected to always be 0; 100GBASE-R is not supported. */
 	uint64_t reserved_7_7                 : 1;
-	uint64_t n40g_cr4                     : 1;  /**< 40GBASE-CR4 negotiated */
-	uint64_t n40g_kr4                     : 1;  /**< 40GBASE-KR4 negotiated */
-	uint64_t fec                          : 1;  /**< BASE-R FEC negotiated */
-	uint64_t n10g_kr                      : 1;  /**< 10GBASE-KR negotiated */
-	uint64_t n10g_kx4                     : 1;  /**< 10GBASE-KX4 or CX4 negotiated (XAUI) */
-	uint64_t n1g_kx                       : 1;  /**< 1000BASE-KX negotiated */
+	uint64_t n40g_cr4                     : 1;  /**< 40GBASE-CR4 negotiated. */
+	uint64_t n40g_kr4                     : 1;  /**< 40GBASE-KR4 negotiated. */
+	uint64_t fec                          : 1;  /**< BASE-R FEC negotiated. */
+	uint64_t n10g_kr                      : 1;  /**< 10GBASE-KR negotiated. */
+	uint64_t n10g_kx4                     : 1;  /**< 10GBASE-KX4 or CX4 negotiated (XAUI). */
+	uint64_t n1g_kx                       : 1;  /**< 1000BASE-KX negotiated. */
 	uint64_t bp_an_able                   : 1;  /**< Backplane or BASE-R copper AN Ability; always 1. */
 #else
 	uint64_t bp_an_able                   : 1;
@@ -5828,17 +5846,18 @@ union cvmx_bgxx_spux_an_control {
 	struct cvmx_bgxx_spux_an_control_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t an_reset                     : 1;  /**< Auto-Negotiation reset. Setting this bit or BGXn_SPUm_CONTROL1[RESET] to 1 causes the
-                                                         following to happen:
-                                                         Resets the logical PCS (LPCS)
-                                                         Sets the Std 802.3 PCS, FEC and AN registers for the LPCS to their default states
-                                                         Resets the associated SerDes lanes.
+	uint64_t an_reset                     : 1;  /**< Auto-Negotiation reset. Setting this bit or BGX(0..5)_SPU(0..3)_CONTROL1[RESET] to 1
+                                                         causes the following to happen:
+                                                         * Resets the logical PCS (LPCS)
+                                                         * Sets the Std 802.3 PCS, FEC and AN registers for the LPCS to their default states
+                                                         * Resets the associated SerDes lanes.
                                                          It takes up to 32 coprocessor-clock cycles to reset the LPCS, after which RESET is
                                                          automatically cleared. */
 	uint64_t reserved_14_14               : 1;
 	uint64_t xnp_en                       : 1;  /**< Extended next-page enable. */
-	uint64_t an_en                        : 1;  /**< Auto-Negotiation enable. This bit should not be set when BGX_CMR_CONFIG[LMAC_TYPE] is set
-                                                         to RXAUI; auto-negotiation is not supported in RXAUI mode. */
+	uint64_t an_en                        : 1;  /**< Auto-Negotiation enable. This bit should not be set when
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] is set to RXAUI; auto-negotiation is not supported
+                                                         in RXAUI mode. */
 	uint64_t reserved_10_11               : 2;
 	uint64_t an_restart                   : 1;  /**< Auto-Negotiation restart. Writing a 1 to this bit restarts the Auto-Negotiation process if
                                                          AN_EN is also set. This is a self-clearing bit. */
@@ -5960,17 +5979,18 @@ union cvmx_bgxx_spux_an_status {
 	uint64_t reserved_8_8                 : 1;
 	uint64_t xnp_stat                     : 1;  /**< Extended next-page status. */
 	uint64_t page_rx                      : 1;  /**< Page received. This latching-high bit is set when a new page has been received and stored
-                                                         in BGXn_SPUm_AN_LP_BASE or BGXn_SPUm_AN_LP_XNP; stays set until a 1 is written by
-                                                         software, Auto-Negotiation is disabled or restarted, or next page exchange is initiated.
-                                                         Note that in order to avoid read side effects, this is implemented as a write-1-to-clear
-                                                         bit, rather than latching high read-only as specified in 802.3. */
+                                                         in BGX(0..5)_SPU(0..3)_AN_LP_BASE or BGX(0..5)_SPU(0..3)_AN_LP_XNP; stays set until a 1 is
+                                                         written by software, Auto-Negotiation is disabled or restarted, or next page exchange is
+                                                         initiated. Note that in order to avoid read side effects, this is implemented as a write-1
+                                                         -to-clear bit, rather than latching high read-only as specified in 802.3. */
 	uint64_t an_complete                  : 1;  /**< Auto-Negotiation complete. Set when the Auto-Negotiation process has been completed and
                                                          the link is up and running using the negotiated highest common denominator (HCD)
-                                                         technology. If AN is enabled (BGXn_SPUm_AN_CONTROL[AN_EN] = 1) and this bit is read as a
-                                                         zero, it indicates that the AN process has not been completed, and the contents of
-                                                         BGXn_SPUm_AN_LP_BASE, BGXn_SPUm_AN_XNP_TX, and BGXn_SPUm_AN_LP_XNP are as defined by the
-                                                         current state of the Auto-Negotiation protocol, or as written for manual configuration.
-                                                         This bit is always zero when AN is disabled (BGXn_SPUm_AN_CONTROL[AN_EN] = 0). */
+                                                         technology. If AN is enabled (BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_EN] = 1) and this bit is
+                                                         read as a zero, it indicates that the AN process has not been completed, and the contents
+                                                         of BGX(0..5)_SPU(0..3)_AN_LP_BASE, BGX(0..5)_SPU(0..3)_AN_XNP_TX, and
+                                                         BGX(0..5)_SPU(0..3)_AN_LP_XNP are as defined by the current state of the Auto-Negotiation
+                                                         protocol, or as written for manual configuration. This bit is always zero when AN is
+                                                         disabled (BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_EN] = 0). */
 	uint64_t rmt_flt                      : 1;  /**< Remote fault: Always 0. */
 	uint64_t an_able                      : 1;  /**< Auto-Negotiation ability: Always 1. */
 	uint64_t link_status                  : 1;  /**< Link status. This bit captures the state of the link_status variable as defined in 802.3
@@ -6007,7 +6027,7 @@ typedef union cvmx_bgxx_spux_an_status cvmx_bgxx_spux_an_status_t;
  * next page link code word to be transmitted during auto-negotiation. Next page exchange occurs
  * after the base link code words have been exchanged if either end of the link segment sets the
  * NP bit to 1, indicating that it has at least one next page to send. Once initiated, next page
- * exchange continues until both end of the link segment set their NP bits to 0. See section
+ * exchange continues until both ends of the link segment set their NP bits to 0. See section
  * 802.3 section 73.7.7 for details.
  */
 union cvmx_bgxx_spux_an_xnp_tx {
@@ -6019,13 +6039,13 @@ union cvmx_bgxx_spux_an_xnp_tx {
                                                          code field of the message next page. When MP is clear, this field contains the upper 32
                                                          bits of the 43-bit unformatted code field of the unformatted next page. */
 	uint64_t np                           : 1;  /**< Next page. */
-	uint64_t ack                          : 1;  /**< Ack: Always 0 in this register. */
+	uint64_t ack                          : 1;  /**< Acknowledge: Always 0 in this register. */
 	uint64_t mp                           : 1;  /**< Message page. Set to indicate that this register contains a message next page. Clear to
-                                                         indicate that the register contains anunformatted next page. */
+                                                         indicate that the register contains an unformatted next page. */
 	uint64_t ack2                         : 1;  /**< Acknowledge 2. Indicates that the receiver is able to act on the information (or perform
                                                          the task) defined in the message. */
-	uint64_t toggle                       : 1;  /**< This bit is ignored by hardware. The value of the TOGGLE bit in
-                                                         transmitted next pages is automatically generated by hardware. */
+	uint64_t toggle                       : 1;  /**< This bit is ignored by hardware. The value of the TOGGLE bit in transmitted next pages is
+                                                         automatically generated by hardware. */
 	uint64_t m_u                          : 11; /**< Message/Unformatted code field: When the MP bit is set, this field contains the message
                                                          code field (M) of the message next page. When MP is clear, this field contains the lower
                                                          11 bits of the 43-bit unformatted code field of the unformatted next page. */
@@ -6048,11 +6068,11 @@ typedef union cvmx_bgxx_spux_an_xnp_tx cvmx_bgxx_spux_an_xnp_tx_t;
  * cvmx_bgx#_spu#_br_algn_status
  *
  * This register implements the Std 802.3 multilane BASE-R PCS alignment status 1-4 registers
- * (3.50-3.53). It is valid only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] =
- * 0x4), and always returns 0x0 for all other LPCS types. Std 802.3 bits that are not applicable
- * to 40GBASE-R (e.g. status bits for PCS lanes 19-4) are not implemented and marked as reserved.
- * PCS lanes 3-0 are valid and are mapped to physical SerDes lanes based on the programming of
- * BGXn_CMRm_CONFIG[[LANE_TO_SDS].
+ * (3.50-3.53). It is valid only when the LPCS type is 40GBASE-R
+ * (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x4), and always returns 0x0 for all other LPCS
+ * types. Std 802.3 bits that are not applicable to 40GBASE-R (e.g. status bits for PCS lanes
+ * 19-4) are not implemented and marked as reserved. PCS lanes 3-0 are valid and are mapped to
+ * physical SerDes lanes based on the programming of BGX(0..5)_CMR(0..3)_CONFIG[[LANE_TO_SDS].
  */
 union cvmx_bgxx_spux_br_algn_status {
 	uint64_t u64;
@@ -6084,12 +6104,12 @@ typedef union cvmx_bgxx_spux_br_algn_status cvmx_bgxx_spux_br_algn_status_t;
  * cvmx_bgx#_spu#_br_bip_err_cnt
  *
  * This register implements the Std 802.3 BIP error-counter registers for PCS lanes 0-3
- * (3.200-3.203). It is valid only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] =
- * 0x4), and always returns 0x0 for all other LPCS types. The counters are indexed by the RX PCS
- * lane number based on the Alignment Marker detected on each lane and captured in
- * BGX(0..5)_SPU(0..3)_BR_LANE_MAP. Each counter counts the BIP errors for its PCS lane, and is
- * held at all ones in case of overflow. The counters are reset to all 0s when this register is
- * read by software.
+ * (3.200-3.203). It is valid only when the LPCS type is 40GBASE-R
+ * (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x4), and always returns 0x0 for all other LPCS
+ * types. The counters are indexed by the RX PCS lane number based on the Alignment Marker
+ * detected on each lane and captured in BGX(0..5)_SPU(0..3)_BR_LANE_MAP. Each counter counts the
+ * BIP errors for its PCS lane, and is held at all ones in case of overflow. The counters are
+ * reset to all 0s when this register is read by software.
  * The reset operation takes precedence over the increment operation; if the register is read on
  * the same clock cycle as an increment operation, the counter is reset to all 0s and the
  * increment operation is lost. The counters are writable for test purposes, rather than read-
@@ -6118,17 +6138,18 @@ typedef union cvmx_bgxx_spux_br_bip_err_cnt cvmx_bgxx_spux_br_bip_err_cnt_t;
  * cvmx_bgx#_spu#_br_lane_map
  *
  * This register implements the Std 802.3 lane 0-3 mapping registers (3.400-3.403). It is valid
- * only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x4), and always returns
- * 0x0 for all other LPCS types. The LNx_MAPPING field for each programmed PCS lane (called
- * service interface in 802.3ba-2010) is valid when that lane has achieved alignment marker lock
- * on the receive side (i.e. the associated BGXn_SPUm_BR_ALGN_STATUS[MARKER_LOCK] = 1), and is
- * invalid otherwise. When valid, it returns the actual detected receive PCS lane number based on
- * the received alignment marker contents received on that service interface.
+ * only when the LPCS type is 40GBASE-R (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x4), and always
+ * returns 0x0 for all other LPCS types. The LNx_MAPPING field for each programmed PCS lane
+ * (called service interface in 802.3ba-2010) is valid when that lane has achieved alignment
+ * marker lock on the receive side (i.e. the associated
+ * BGX(0..5)_SPU(0..3)_BR_ALGN_STATUS[MARKER_LOCK] = 1), and is invalid otherwise. When valid, it
+ * returns the actual detected receive PCS lane number based on the received alignment marker
+ * contents received on that service interface.
  * The mapping is flexible because Std 802.3 allows multilane BASE-R receive lanes to be re-
  * ordered. Note that for the transmit side, each PCS lane is mapped to a physical SerDes lane
- * based on the programming of BGXn_CMRm_CONFIG[LANE_TO_SDS]. For the receive side,
- * BGXn_CMRm_CONFIG[LANE_TO_SDS] specifies the service interface to physical SerDes lane mapping,
- * and this register specifies the PCS lane to service interface mapping.
+ * based on the programming of BGX(0..5)_CMR(0..3)_CONFIG[LANE_TO_SDS]. For the receive side,
+ * BGX(0..5)_CMR(0..3)_CONFIG[LANE_TO_SDS] specifies the service interface to physical SerDes
+ * lane mapping, and this register specifies the PCS lane to service interface mapping.
  */
 union cvmx_bgxx_spux_br_lane_map {
 	uint64_t u64;
@@ -6183,14 +6204,16 @@ typedef union cvmx_bgxx_spux_br_pmd_control cvmx_bgxx_spux_br_pmd_control_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_ld_cup
  *
- * This register implements 802.3 MDIO register 1.153 for 10GBASE-R (when LMAC_TYPE = 10G_R in
- * the associated BGX_CMR_CONFIG register) and MDIO registers 1.1300-1.1303 for 40GBASE-R (when
+ * This register implements 802.3 MDIO register 1.153 for 10GBASE-R (when
+ * BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 10G_R)
+ * and MDIO registers 1.1300-1.1303 for 40GBASE-R (when
  * LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. When link training
  * is in progress, each field reflects the contents of the coefficient update field in the
  * associated lane's outgoing training frame. The fields in this register are read/write even
- * though they are specified as read-only in 802.3. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is set,
- * then this register must be updated by software during link training and hardware updates are
- * disabled. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is clear, this register is automatically
+ * though they are specified as read-only in 802.3.
+ * If BGX(0..5)_SPU_DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is set, then this register must be updated
+ * by software during link training and hardware updates are disabled. If
+ * BGX(0..5)_SPU_DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is clear, this register is automatically
  * updated by hardware, and it should not be written by software. The lane fields in this
  * register are indexed by logical PCS lane ID. The lane 0 field (LN0_*) is valid for both
  * 10GBASE-R and 40GBASE-R. The remaining fields (LN1_*, LN2_*, LN3_*) are only valid for
@@ -6221,17 +6244,18 @@ typedef union cvmx_bgxx_spux_br_pmd_ld_cup cvmx_bgxx_spux_br_pmd_ld_cup_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_ld_rep
  *
- * This register implements 802.3 MDIO register 1.154 for 10GBASE-R (when LMAC_TYPE = 10G_R in
- * the associated BGX_CMR_CONFIG register) and MDIO registers 1.1400-1.1403 for 40GBASE-R (when
- * LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. Each field reflects
- * the contents of the status report field in the associated lane's outgoing training frame. The
- * fields in this register are read/write even though they are specified as read-only in 802.3.
- * If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is set, then this register must be updated by software
- * during link training and hardware updates are disabled. If DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN]
- * is clear, this register is automatically updated by hardware, and it should not be written by
- * software. The lane fields in this register are indexed by logical PCS lane ID. The lane 0
- * field (LN0_*) is valid for both 10GBASE-R and 40GBASE-R. The remaining fields (LN1_*, LN2_*,
- * LN3_*) are only valid for 40GBASE-R.
+ * This register implements 802.3 MDIO register 1.154 for 10GBASE-R (when
+ * BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = IOG_R) and MDIO registers 1.1400-1.1403 for 40GBASE-R
+ * (when LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. Each field
+ * reflects the contents of the status report field in the associated lane's outgoing training
+ * frame. The fields in this register are read/write even though they are specified as read-only
+ * in 802.3. If BGX(0..5)_SPU_DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is set, then this register must
+ * be updated by software during link training and hardware updates are disabled. If
+ * BGX(0..5)_SPU_DBG_CONTROL[BR_PMD_TRAIN_SOFT_EN] is clear, this register is automatically
+ * updated by hardware, and it should not be written by software. The lane fields in this
+ * register are indexed by logical PCS lane ID. The lane 0 field (LN0_*) is valid for both
+ * 10GBASE-R and 40GBASE-R. The remaining fields (LN1_*, LN2_*, LN3_*) are only valid for
+ * 40GBASE-R.
  */
 union cvmx_bgxx_spux_br_pmd_ld_rep {
 	uint64_t u64;
@@ -6258,8 +6282,9 @@ typedef union cvmx_bgxx_spux_br_pmd_ld_rep cvmx_bgxx_spux_br_pmd_ld_rep_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_lp_cup
  *
- * This register implements 802.3 MDIO register 1.152 for 10GBASE-R (when LMAC_TYPE = 10G_R in
- * the associated BGX_CMR_CONFIG register) and MDIO registers 1.1100-1.1103 for 40GBASE-R (when
+ * This register implements 802.3 MDIO register 1.152 for 10GBASE-R (when
+ * BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 10G_R)
+ * and MDIO registers 1.1100-1.1103 for 40GBASE-R (when
  * LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. Each field reflects
  * the contents of the coefficient update field in the lane's most recently received training
  * frame. This register should not be written when link training is enabled, i.e. when TRAIN_EN
@@ -6292,8 +6317,9 @@ typedef union cvmx_bgxx_spux_br_pmd_lp_cup cvmx_bgxx_spux_br_pmd_lp_cup_t;
 /**
  * cvmx_bgx#_spu#_br_pmd_lp_rep
  *
- * This register implements 802.3 MDIO register 1.153 for 10GBASE-R (when LMAC_TYPE = 10G_R in
- * the associated BGX_CMR_CONFIG register) and MDIO registers 1.1200-1.1203 for 40GBASE-R (when
+ * This register implements 802.3 MDIO register 1.153 for 10GBASE-R (when
+ * BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 10G_R)
+ * and MDIO registers 1.1200-1.1203 for 40GBASE-R (when
  * LMAC_TYPE = 40G_R). It is automatically cleared at the start of training. Each field reflects
  * the contents of the status report field in the associated lane's most recently received
  * training frame. The lane fields in this register are indexed by logical PCS lane ID. The lane
@@ -6381,7 +6407,7 @@ union cvmx_bgxx_spux_br_status1 {
                                                          state diagram and is defined in Std 802.3 sections 49.2.13.2.2 and 82.2.18.2.2.
                                                          For a multilane logical PCS (i.e. 40GBASE-R), this bit indicates that the receiver has
                                                          both block lock and alignment for all lanes and is identical to
-                                                         BGXn_SPUm_BR_ALGN_STATUS[ALIGND]. */
+                                                         BGX(0..5)_SPU(0..3)_BR_ALGN_STATUS[ALIGND]. */
 #else
 	uint64_t blk_lock                     : 1;
 	uint64_t hi_ber                       : 1;
@@ -6400,8 +6426,8 @@ typedef union cvmx_bgxx_spux_br_status1 cvmx_bgxx_spux_br_status1_t;
  * cvmx_bgx#_spu#_br_status2
  *
  * This register implements a combination of the following Std 802.3 registers:
- * BASE-R PCS status 2 (MDIO address 3.33)
- * BASE-R BER high-order counter (MDIO address 3.44)
+ * * BASE-R PCS status 2 (MDIO address 3.33)
+ * * BASE-R BER high-order counter (MDIO address 3.44)
  * Errored-blocks high-order counter (MDIO address 3.45).
  * Note that the relative locations of some fields have been moved from Std 802.3 in order to
  * make the register layout more software friendly: the BER counter high-order and low-order bits
@@ -6426,7 +6452,7 @@ union cvmx_bgxx_spux_br_status2 {
                                                          increment operation is lost.
                                                          This field is writable for test purposes, rather than read-only as specified in Std 802.3. */
 	uint64_t reserved_38_39               : 2;
-	uint64_t ber_cnt                      : 22; /**< Bit-error-rate counter. This is the BASE-R BER counter as defined by the ber_count
+	uint64_t ber_cnt                      : 22; /**< Bit-error-rate counter. This is the BASE-R BER counter as defined by the BER_COUNT
                                                          variable in Std 802.3 sections 49.2.14.2 and 82.2.18.2.4. The counter is reset to all 0s
                                                          after this register is read by software, and is held at all 1s in case of overflow.
                                                          The reset operation takes precedence over the increment operation: if the register is read
@@ -6436,15 +6462,15 @@ union cvmx_bgxx_spux_br_status2 {
 	uint64_t latched_lock                 : 1;  /**< Latched-block lock.
                                                          1 = 64B/66B receiver for BASE-R has block lock
                                                          0 = No block
-                                                         This is a latching-low version of BGXn_SPUm_BR_STATUS1[BLK_LOCK]; it stays clear until the
-                                                         register is read by software.
+                                                         This is a latching-low version of BGX(0..5)_SPU(0..3)_STATUS1[BLK_LOCK]; it stays clear
+                                                         until the register is read by software.
                                                          Note that in order to avoid read side effects, this is implemented as a write-1-to-set
                                                          bit, rather than latching low read-only as specified in 802.3. */
 	uint64_t latched_ber                  : 1;  /**< Latched-high bit-error rate.
                                                          1 = 64B/66B receiver is detecting a high BER
                                                          0 = Not a high BER
-                                                         This is a latching-high version of BGXn_SPUm_BR_STATUS1[HI_BER]; it stays set until the
-                                                         register is read by software.
+                                                         This is a latching-high version of BGX(0..5)_SPU(0..3)_STATUS1[HI_BER]; it stays set until
+                                                         the register is read by software.
                                                          Note that in order to avoid read side effects, this is implemented as a write-1-to-clear
                                                          bit, rather than latching high read-only as specified in 802.3. */
 	uint64_t reserved_0_13                : 14;
@@ -6544,8 +6570,8 @@ union cvmx_bgxx_spux_bx_status {
 	uint64_t reserved_4_10                : 7;
 	uint64_t lsync                        : 4;  /**< Lane synchronization. BASE-X lane synchronization status for PCS lanes 3-0. Each bit is
                                                          set when the associated lane is code-group synchronized, and clear otherwise. If the PCS
-                                                         type is RXAUI (i.e. the associated BGXn_CMRm_CONFIG[LMAC_TYPE] = RXAUI), then only lanes
-                                                         1-0 are valid. */
+                                                         type is RXAUI (i.e. the associated BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = RXAUI), then
+                                                         only lanes 1-0 are valid. */
 #else
 	uint64_t lsync                        : 4;
 	uint64_t reserved_4_10                : 7;
@@ -6566,11 +6592,11 @@ union cvmx_bgxx_spux_control1 {
 	struct cvmx_bgxx_spux_control1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t reset                        : 1;  /**< Reset. Setting this bit or BGXn_SPUm_AN_CONTROL[AN_RESET] to 1 causes the following to
-                                                         happen:
-                                                         Resets the logical PCS (LPCS)
-                                                         Sets the Std 802.3 PCS, FEC and AN registers for the LPCS to their default states
-                                                         Resets the associated SerDes lanes.
+	uint64_t reset                        : 1;  /**< Reset. Setting this bit or BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_RESET] to 1 causes the
+                                                         following to happen:
+                                                         * Resets the logical PCS (LPCS)
+                                                         * Sets the Std 802.3 PCS, FEC and AN registers for the LPCS to their default states
+                                                         * Resets the associated SerDes lanes.
                                                          It takes up to 32 coprocessor-clock cycles to reset the LPCS, after which RESET is
                                                          automatically cleared. */
 	uint64_t loopbck                      : 1;  /**< TX-to-RX loopback enable. When set, transmit data for each SerDes lane is looped back as
@@ -6578,14 +6604,15 @@ union cvmx_bgxx_spux_control1 {
 	uint64_t spdsel1                      : 1;  /**< Speed select 1: always 1. */
 	uint64_t reserved_12_12               : 1;
 	uint64_t lo_pwr                       : 1;  /**< Low power enable. When set, the LPCS is disabled (overriding the associated
-                                                         BGXn_CMRm_CONFIG[ENABLE]), and the SerDes lanes associated with the LPCS are reset. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[ENABLE]), and the SerDes lanes associated with the LPCS are
+                                                         reset. */
 	uint64_t reserved_7_10                : 4;
 	uint64_t spdsel0                      : 1;  /**< Speed select 0: always 1. */
-	uint64_t spd                          : 4;  /**< "Speed selection:
+	uint64_t spd                          : 4;  /**< "Speed selection.
                                                          Note that this is a read-only field rather than read/write as
-                                                         specified in 802.3. The Logical PCS speed is actually configured by
-                                                         the LMAC_TYPE field in the associated BGX_CMR_CONFIG register in
-                                                         the CMR sub-block. The Read values returned by this field are as
+                                                         specified in 802.3.
+                                                         The LPCS speed is actually configured by the associated
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE]. The read values returned by this field are as
                                                          follows:
                                                            ----------+---------------------------------------------------
                                                            LMAC_TYPE |   Speed       SPD Read Value      Comment
@@ -6622,11 +6649,11 @@ union cvmx_bgxx_spux_control2 {
 	struct cvmx_bgxx_spux_control2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
-	uint64_t pcs_type                     : 3;  /**< "PCS type selection:
+	uint64_t pcs_type                     : 3;  /**< "PCS type selection.
                                                          Note that this is a read-only field rather than read/write as
-                                                         specified in 802.3. The Logical PCS speed is actually configured by
-                                                         the LMAC_TYPE field in the associated BGX_CMR_CONFIG register in
-                                                         the CMR sub-block. The Read values returned by this field are as
+                                                         specified in 802.3.
+                                                         The LPCS speed is actually configured by the associated
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE]. The read values returned by this field are as
                                                          follows:
                                                            ----------+------------------------------------------
                                                            LMAC_TYPE |   PCS_TYPE          Comment
@@ -6656,9 +6683,9 @@ union cvmx_bgxx_spux_fec_abil {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
 	uint64_t err_abil                     : 1;  /**< BASE-R FEC error-indication ability. Always 1 when the LPCS type is BASE-R, i.e.
-                                                         BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x3 or 0x4. Always 0 otherwise. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x3 or 0x4. Always 0 otherwise. */
 	uint64_t fec_abil                     : 1;  /**< BASE-R FEC ability. Always 1 when the LPCS type is BASE-R, i.e.
-                                                         BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x3 or 0x4. Always 0 otherwise. */
+                                                         BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x3 or 0x4. Always 0 otherwise. */
 #else
 	uint64_t fec_abil                     : 1;
 	uint64_t err_abil                     : 1;
@@ -6684,9 +6711,9 @@ union cvmx_bgxx_spux_fec_control {
                                                          for some of the 32 64B/66B blocks belonging to the uncorrectable FEC block. See
                                                          802.3-2008/802.3ba-2010 section 74.7.4.5.1 for more details. */
 	uint64_t fec_en                       : 1;  /**< BASE-R FEC enable. When this bit is set and the LPCS type is BASE-R
-                                                         (BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x4), forward error correction is enabled. FEC is disabled
-                                                         otherwise. Forward error correction is defined in IEEE Std 802.3-2008/802.3ba-2010 Clause
-                                                         74. */
+                                                         (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x4), forward error correction is enabled. FEC is
+                                                         disabled otherwise. Forward error correction is defined in IEEE Std
+                                                         802.3-2008/802.3ba-2010 Clause 74. */
 #else
 	uint64_t fec_en                       : 1;
 	uint64_t err_en                       : 1;
@@ -6700,12 +6727,12 @@ typedef union cvmx_bgxx_spux_fec_control cvmx_bgxx_spux_fec_control_t;
 /**
  * cvmx_bgx#_spu#_fec_corr_blks01
  *
- * This register is valid only when the LPCS type is BASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x3 or
- * 0x4). The FEC corrected-block counters are defined in Std 802.3 section 74.8.4.1. Each
- * corrected-blocks counter increments by 1 for a corrected FEC block, i.e. an FEC block that has
- * been received with invalid parity on the associated PCS lane and has been corrected by the FEC
- * decoder. The counter is reset to all 0s when the register is read, and held at all 1s in case
- * of overflow.
+ * This register is valid only when the LPCS type is BASE-R
+ * (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x3 or 0x4). The FEC corrected-block counters are
+ * defined in Std 802.3 section 74.8.4.1. Each corrected-blocks counter increments by 1 for a
+ * corrected FEC block, i.e. an FEC block that has been received with invalid parity on the
+ * associated PCS lane and has been corrected by the FEC decoder. The counter is reset to all 0s
+ * when the register is read, and held at all 1s in case of overflow.
  * The reset operation takes precedence over the increment operation; if the register is read on
  * the same clock cycle as an increment operation, the counter is reset to all 0s and the
  * increment operation is lost. The counters are writable for test purposes, rather than read-
@@ -6716,13 +6743,13 @@ union cvmx_bgxx_spux_fec_corr_blks01 {
 	struct cvmx_bgxx_spux_fec_corr_blks01_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t ln1_corr_blks                : 32; /**< PCS Lane 1 FEC corrected blocks.
-                                                         For 10GBASE-R, reserved.
-                                                         For 40GBASE-R, correspond to the Std 802.3 FEC_corrected_blocks_counter_1 variable
+                                                         * For 10GBASE-R, reserved.
+                                                         * For 40GBASE-R, correspond to the Std 802.3 FEC_corrected_blocks_counter_1 variable
                                                          (registers 1.302-1.303). */
 	uint64_t ln0_corr_blks                : 32; /**< PCS Lane 0 FEC corrected blocks.
-                                                         For 10GBASE-R, corresponds to the Std 802.3 FEC_corrected_blocks_counter variable
+                                                         * For 10GBASE-R, corresponds to the Std 802.3 FEC_corrected_blocks_counter variable
                                                          (registers 1.172-1.173).
-                                                         For 40GBASE-R, correspond to the Std 802.3 FEC_corrected_blocks_counter_0 variable
+                                                         * For 40GBASE-R, correspond to the Std 802.3 FEC_corrected_blocks_counter_0 variable
                                                          (registers 1.300-1.301). */
 #else
 	uint64_t ln0_corr_blks                : 32;
@@ -6736,12 +6763,12 @@ typedef union cvmx_bgxx_spux_fec_corr_blks01 cvmx_bgxx_spux_fec_corr_blks01_t;
 /**
  * cvmx_bgx#_spu#_fec_corr_blks23
  *
- * This register is valid only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] =
- * 0x4). The FEC corrected-block counters are defined in Std 802.3 section 74.8.4.1. Each
- * corrected-blocks counter increments by 1 for a corrected FEC block, i.e. an FEC block that has
- * been received with invalid parity on the associated PCS lane and has been corrected by the FEC
- * decoder. The counter is reset to all 0s when the register is read, and held at all 1s in case
- * of overflow.
+ * This register is valid only when the LPCS type is 40GBASE-R
+ * (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x4). The FEC corrected-block counters are defined in
+ * Std 802.3 section 74.8.4.1. Each corrected-blocks counter increments by 1 for a corrected FEC
+ * block, i.e. an FEC block that has been received with invalid parity on the associated PCS lane
+ * and has been corrected by the FEC decoder. The counter is reset to all 0s when the register is
+ * read, and held at all 1s in case of overflow.
  * The reset operation takes precedence over the increment operation; if the register is read on
  * the same clock cycle as an increment operation, the counter is reset to all 0s and the
  * increment operation is lost. The counters are writable for test purposes, rather than read-
@@ -6767,12 +6794,12 @@ typedef union cvmx_bgxx_spux_fec_corr_blks23 cvmx_bgxx_spux_fec_corr_blks23_t;
 /**
  * cvmx_bgx#_spu#_fec_uncorr_blks01
  *
- * This register is valid only when the LPCS type is BASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] = 0x3 or
- * 0x4). The FEC corrected-block counters are defined in Std 802.3 section 74.8.4.2. Each
- * uncorrected-blocks counter increments by 1 for an uncorrected FEC block, i.e. an FEC block
- * that has been received with invalid parity on the associated PCS lane and has not been
- * corrected by the FEC decoder. The counter is reset to all 0s when the register is read, and
- * held at all 1s in case of overflow.
+ * This register is valid only when the LPCS type is BASE-R
+ * (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x3 or 0x4). The FEC corrected-block counters are
+ * defined in Std 802.3 section 74.8.4.2. Each uncorrected-blocks counter increments by 1 for an
+ * uncorrected FEC block, i.e. an FEC block that has been received with invalid parity on the
+ * associated PCS lane and has not been corrected by the FEC decoder. The counter is reset to all
+ * 0s when the register is read, and held at all 1s in case of overflow.
  * The reset operation takes precedence over the increment operation; if the register is read on
  * the same clock cycle as an increment operation, the counter is reset to all 0s and the
  * increment operation is lost. The counters are writable for test purposes, rather than read-
@@ -6783,13 +6810,13 @@ union cvmx_bgxx_spux_fec_uncorr_blks01 {
 	struct cvmx_bgxx_spux_fec_uncorr_blks01_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t ln1_uncorr_blks              : 32; /**< PCS Lane 1 FEC corrected blocks.
-                                                         For 10GBASE-R, reserved.
-                                                         For 40GBASE-R, corresponds to the Std 802.3 FEC_uncorrected_blocks_counter_1 variable
+                                                         * For 10GBASE-R, reserved.
+                                                         * For 40GBASE-R, corresponds to the Std 802.3 FEC_uncorrected_blocks_counter_1 variable
                                                          (registers 1.702-1.703). */
 	uint64_t ln0_uncorr_blks              : 32; /**< PCS Lane 0 FEC uncorrected blocks.
-                                                         For 10GBASE-R, corresponds to the Std 802.3 FEC_uncorrected_blocks_counter variable
+                                                         * For 10GBASE-R, corresponds to the Std 802.3 FEC_uncorrected_blocks_counter variable
                                                          (registers 1.174-1.175).
-                                                         For 40GBASE-R, correspond to the Std 802.3 FEC_uncorrected_blocks_counter_0 variable
+                                                         * For 40GBASE-R, correspond to the Std 802.3 FEC_uncorrected_blocks_counter_0 variable
                                                          (registers 1.700-1.701). */
 #else
 	uint64_t ln0_uncorr_blks              : 32;
@@ -6803,12 +6830,12 @@ typedef union cvmx_bgxx_spux_fec_uncorr_blks01 cvmx_bgxx_spux_fec_uncorr_blks01_
 /**
  * cvmx_bgx#_spu#_fec_uncorr_blks23
  *
- * This register is valid only when the LPCS type is 40GBASE-R (BGXn_CMRm_CONFIG[LMAC_TYPE] =
- * 0x4). The FEC uncorrected-block counters are defined in Std 802.3 section 74.8.4.2. Each
- * corrected-blocks counter increments by 1 for an uncorrected FEC block, i.e. an FEC block that
- * has been received with invalid parity on the associated PCS lane and has not been corrected by
- * the FEC decoder. The counter is reset to all 0s when the register is read, and held at all 1s
- * in case of overflow.
+ * This register is valid only when the LPCS type is 40GBASE-R
+ * (BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] = 0x4). The FEC uncorrected-block counters are defined
+ * in Std 802.3 section 74.8.4.2. Each corrected-blocks counter increments by 1 for an
+ * uncorrected FEC block, i.e. an FEC block that has been received with invalid parity on the
+ * associated PCS lane and has not been corrected by the FEC decoder. The counter is reset to all
+ * 0s when the register is read, and held at all 1s in case of overflow.
  * The reset operation takes precedence over the increment operation; if the register is read on
  * the same clock cycle as an increment operation, the counter is reset to all 0s and the
  * increment operation is lost. The counters are writable for test purposes, rather than read-
@@ -6867,24 +6894,24 @@ union cvmx_bgxx_spux_int {
 	uint64_t dbg_sync                     : 1;  /**< Sync failure debug. This interrupt is provided for link problem debugging help. It is set
                                                          as follows based on the LPCS type selected by BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE], and
                                                          whether FEC is enabled or disabled by BGX(0..5)_SPU(0..3)_FEC_CONTROL[FEC_EN]:
-                                                         XAUI or RXAUI: Set when any lane's PCS synchronization state transitions from
+                                                         * XAUI or RXAUI: Set when any lane's PCS synchronization state transitions from
                                                          SYNC_ACQUIRED_1 to SYNC_ACQUIRED_2 (see 802.3-2008 Figure 48-7).
-                                                         10GBASE-R or 40GBASE-R with FEC disabled: Set when sh_invalid_cnt increments to 1 while
+                                                         * 10GBASE-R or 40GBASE-R with FEC disabled: Set when sh_invalid_cnt increments to 1 while
                                                          block_lock is 1 (see 802.3-2008 Figure 49-12 and 802.3ba-2010 Figure 82-20).
-                                                         10GBASE-R or 40GBASE-R with FEC enabled: Set when parity_invalid_cnt increments to 1 while
-                                                         fec_block_lock is 1 (see 802.3-2008 Figure 74-8). */
+                                                         * 10GBASE-R or 40GBASE-R with FEC enabled: Set when parity_invalid_cnt increments to 1
+                                                         while fec_block_lock is 1 (see 802.3-2008 Figure 74-8). */
 	uint64_t algnlos                      : 1;  /**< Loss of lane alignment. Set when lane-to-lane alignment is lost. This is only valid if the
                                                          logical PCS is a multilane type (i.e. XAUI, RXAUI or 40GBASE-R is selected by
                                                          BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE]), and is never set otherwise. */
 	uint64_t synlos                       : 1;  /**< Loss of lane sync. Lane code-group or block synchronization is lost on one or more lanes
                                                          associated with the LMAC/LPCS. Set as follows based on the LPCS type selected by
                                                          BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE], and whether FEC is enabled or disabled by
-                                                         BGX_SPU_FEC_CONTROL[FEC_EN]:
-                                                         XAUI or RXAUI: Set when any lane's PCS synchronization state transitions to LOSS_OF_SYNC
+                                                         BGX(0..5)_SPU(0..3)_FEC_CONTROL[FEC_EN]:
+                                                         * XAUI or RXAUI: Set when any lane's PCS synchronization state transitions to LOSS_OF_SYNC
                                                          (see 802.3-2008 Figure 48-7)
-                                                         10GBASE-R or 40GBASE-R with FEC disabled: set when the block_lock variable is cleared on
+                                                         * 10GBASE-R or 40GBASE-R with FEC disabled: set when the block_lock variable is cleared on
                                                          the 10G lane or any 40G lane (see 802.3-2008 Figure 49-12 and 802.3ba-2010 Figure 82-20).
-                                                         10GBASE-R or 40GBASE-R with FEC enabled: set when the fec_block_lock variable is cleared
+                                                         * 10GBASE-R or 40GBASE-R with FEC enabled: set when the fec_block_lock variable is cleared
                                                          on the 10G lane or any 40G lane (see 802.3-2008 Figure 74-8). */
 	uint64_t bitlckls                     : 1;  /**< Bit lock lost on one or more lanes associated with the LMAC/LPCS. */
 	uint64_t err_blk                      : 1;  /**< Errored block received. Set when an errored BASE-R block is received as described for
@@ -6948,11 +6975,11 @@ typedef union cvmx_bgxx_spux_lpcs_states cvmx_bgxx_spux_lpcs_states_t;
 /**
  * cvmx_bgx#_spu#_misc_control
  *
- * RX logical PCS lane polarity vector [3:0] = XOR_RXPLRT[3:0] ^ [4[RXPLRT]].
- *  TX logical PCS lane polarity vector [3:0] = XOR_TXPLRT[3:0] ^ [4[TXPLRT]].
+ * "* RX logical PCS lane polarity vector [3:0] = XOR_RXPLRT[3:0] ^ [4[RXPLRT]].
+ *  * TX logical PCS lane polarity vector [3:0] = XOR_TXPLRT[3:0] ^ [4[TXPLRT]].
  *  In short, keep RXPLRT and TXPLRT cleared, and use XOR_RXPLRT and XOR_TXPLRT fields to define
  *  the polarity per logical PCS lane. Only bit 0 of vector is used for 10GBASE-R, and only bits
- * - 1:0 of vector are used for RXAUI.
+ * - 1:0 of vector are used for RXAUI."
  */
 union cvmx_bgxx_spux_misc_control {
 	uint64_t u64;
@@ -7048,15 +7075,15 @@ union cvmx_bgxx_spux_status1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
 	uint64_t flt                          : 1;  /**< Fault: 1 = fault condition detected, 0 = no fault condition detected.
-                                                         This bit is a logical OR of
-                                                         BGX(0..5)_SPU(0..3)_STATUS2[XMTFLT, RCVFLT]. */
+                                                         This bit is a logical OR of BGX(0..5)_SPU(0..3)_STATUS2[XMTFLT, RCVFLT]. */
 	uint64_t reserved_3_6                 : 4;
 	uint64_t rcv_lnk                      : 1;  /**< PCS receive link status: 1 = receive link up, 0 = receive link down.
                                                          This is a latching-low bit; it stays clear until the register is read by software.
-                                                         For a BASE-X logical PCS type (in the associated BGXn_CMRm_CONFIG[LMAC_TYPE] = XAUI or
-                                                         RXAUI), this is a latching-low version of BGXn_SPUm_BX_STATUS[ALIGND].
-                                                         For a BASE-R logical PCS type (in the associated BGXn_CMRm_CONFIG[LMAC_TYPE] = 10G_R or
-                                                         40G_R), this is a latching-low version of BGXn_SPUm_BR_STATUS1[RCV_LNK].
+                                                         For a BASE-X logical PCS type (in the associated BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] =
+                                                         XAUI or RXAUI), this is a latching-low version of BGX(0..5)_SPU(0..3)_BX_STATUS[ALIGND].
+                                                         For a BASE-R logical PCS type (in the associated BGX(0..5)_CMR(0..3)_CONFIG[LMAC_TYPE] =
+                                                         10G_R or 40G_R), this is a latching-low version of
+                                                         BGX(0..5)_SPU(0..3)_BR_STATUS1[RCV_LNK].
                                                          Note that in order to avoid read side effects, this is implemented as a write-1-to-set
                                                          bit, rather than latching low read-only as specified in 802.3. */
 	uint64_t lpable                       : 1;  /**< Low-power ability. Always returns 1 to indicate that the LPCS supports low-power mode. */
@@ -7196,12 +7223,13 @@ union cvmx_bgxx_spu_dbg_control {
                                                          0x3 = DBE on ECC bits 1:0 */
 	uint64_t br_pmd_train_soft_en         : 1;  /**< Enable BASE-R PMD software controlled link training. This bit configures the operation
                                                          mode for BASE-R link training for all LMACs and lanes. When this bit is set along with
-                                                         BR_PMD_CONTROL[TRAIN_EN] for a given LMAC, the BASE-R link training protocol for that LMAC
-                                                         is executed under software control, whereby the contents the BR_PMD_LD_CUP and
-                                                         BR_PMD_LD_REP registers are updated by software. When this bit is clear and
-                                                         BR_PMD_CONTROL[TRAIN_EN] is set, the link training protocol is fully automated in
-                                                         hardware, whereby the contents BR_PMD_LD_CUP and BR_PMD_LD_REP registers are automatically
-                                                         updated by hardware. */
+                                                         BGX(0..5)_SPU(0..3)_BR_PMD_CONTROL[TRAIN_EN] for a given LMAC, the BASE-R link training
+                                                         protocol for that LMAC is executed under software control, whereby the contents the
+                                                         BGX(0..5)_SPU(0..3)_BR_PMD_LD_CUP and BGX(0..5)_SPU(0..3)_BR_PMD_LD_REP registers are
+                                                         updated by software. When this bit is clear and
+                                                         BGX(0..5)_SPU(0..3)_BR_PMD_CONTROL[TRAIN_EN] is set, the link training protocol is fully
+                                                         automated in hardware, whereby the contents BGX(0..5)_SPU(0..3)_BR_PMD_LD_CUP and
+                                                         BGX(0..5)_SPU(0..3)_BR_PMD_LD_REP registers are automatically updated by hardware. */
 	uint64_t an_arb_link_chk_en           : 1;  /**< Enable link status checking by Auto-Negotiation arbitration state machine. When Auto-
                                                          Negotiation is enabled (BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_EN] is set), this bit controls
                                                          the behavior of the Auto-Negotiation arbitration state machine when it reaches the AN GOOD
@@ -7213,10 +7241,11 @@ union cvmx_bgxx_spu_dbg_control {
                                                          link_fail_inhibit timer and eventually transition to the AN GOOD or TRANSMIT DISABLE
                                                          state.
                                                          When this bit is clear or the HCD technology does not match LMAC_TYPE, the AN arbitration
-                                                         SM stay in the AN GOOD CHECK state, with the expectation that software will perform the
+                                                         SM stays in the AN GOOD CHECK state, with the expectation that software will perform the
                                                          appropriate actions to complete the Auto-Negotiation protocol, as follows:
-                                                         If this bit is clear and the HCD technology matches LMAC_TYPE, clear AN_EN in AN_CONTROL.
-                                                         Otherwise, disable the LPCS by clearing the BGX(0..5)_CMR(0..3)_CONFIG[ENABLE], clear
+                                                         * If this bit is clear and the HCD technology matches LMAC_TYPE, clear AN_EN in
+                                                         AN_CONTROL.
+                                                         * Otherwise, disable the LPCS by clearing the BGX(0..5)_CMR(0..3)_CONFIG[ENABLE], clear
                                                          BGX(0..5)_SPU(0..3)_AN_CONTROL[AN_EN], reconfigure the LPCS with the correct LMAC_TYPE,
                                                          and re-enable the LPCS by setting BGX(0..5)_CMR(0..3)_CONFIG[ENABLE].
                                                          In both cases, software should implement the link_fail_inhibit timer and verify the link
@@ -7330,23 +7359,23 @@ union cvmx_bgxx_spu_sdsx_states {
 	struct cvmx_bgxx_spu_sdsx_states_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_52_63               : 12;
-	uint64_t am_lock_invld_cnt            : 2;  /**< 40GBASE-R alignment marker lock state machine invalid AM counter */
-	uint64_t am_lock_sm                   : 2;  /**< 40GBASE-R alignment marker lock state machine state */
+	uint64_t am_lock_invld_cnt            : 2;  /**< 40GBASE-R alignment marker lock state machine invalid AM counter. */
+	uint64_t am_lock_sm                   : 2;  /**< 40GBASE-R alignment marker lock state machine state. */
 	uint64_t reserved_45_47               : 3;
-	uint64_t train_sm                     : 3;  /**< Link training state machine state */
-	uint64_t train_code_viol              : 1;  /**< Link training code violation in received control channel */
-	uint64_t train_frame_lock             : 1;  /**< Link training frame lock status */
-	uint64_t train_lock_found_1st_marker  : 1;  /**< Link training lock state machine found first marker flag */
-	uint64_t train_lock_bad_markers       : 3;  /**< Link training lock state machine bad markers counter */
+	uint64_t train_sm                     : 3;  /**< Link training state machine state. */
+	uint64_t train_code_viol              : 1;  /**< Link training code violation in received control channel. */
+	uint64_t train_frame_lock             : 1;  /**< Link training frame lock status. */
+	uint64_t train_lock_found_1st_marker  : 1;  /**< Link training lock state machine found first marker flag. */
+	uint64_t train_lock_bad_markers       : 3;  /**< Link training lock state machine bad markers counter. */
 	uint64_t reserved_35_35               : 1;
-	uint64_t an_arb_sm                    : 3;  /**< Auto-Negotiation arbitration state machine state */
-	uint64_t an_rx_sm                     : 2;  /**< Auto-Negotiation receive state machine state */
+	uint64_t an_arb_sm                    : 3;  /**< Auto-Negotiation arbitration state machine state. */
+	uint64_t an_rx_sm                     : 2;  /**< Auto-Negotiation receive state machine state. */
 	uint64_t reserved_29_29               : 1;
-	uint64_t fec_block_sync               : 1;  /**< FEC block sync status */
-	uint64_t fec_sync_cnt                 : 4;  /**< FEC block sync state machine good/bad parity block counter */
+	uint64_t fec_block_sync               : 1;  /**< FEC block sync status. */
+	uint64_t fec_sync_cnt                 : 4;  /**< FEC block sync state machine good/bad parity block counter. */
 	uint64_t reserved_23_23               : 1;
-	uint64_t br_sh_invld_cnt              : 7;  /**< BASE-R lock state machine invalid sync header counter */
-	uint64_t br_block_lock                : 1;  /**< BASE-R block lock status */
+	uint64_t br_sh_invld_cnt              : 7;  /**< BASE-R lock state machine invalid sync header counter. */
+	uint64_t br_block_lock                : 1;  /**< BASE-R block lock status. */
 	uint64_t br_sh_cnt                    : 11; /**< BASE-R lock state machine sync header counter */
 	uint64_t bx_sync_sm                   : 4;  /**< BASE-X PCS synchronization state machine state */
 #else
diff --git a/arch/mips/include/asm/octeon/cvmx-bootmem.h b/arch/mips/include/asm/octeon/cvmx-bootmem.h
index a247ae99..528a6cd 100644
--- a/arch/mips/include/asm/octeon/cvmx-bootmem.h
+++ b/arch/mips/include/asm/octeon/cvmx-bootmem.h
@@ -42,7 +42,7 @@
  * Simple allocate only memory allocator.  Used to allocate memory at application
  * start time.
  *
- * <hr>$Revision: 94463 $<hr>
+ * <hr>$Revision: 96253 $<hr>
  *
  */
 
@@ -543,6 +543,27 @@ int64_t cvmx_bootmem_phy_mem_list_init(uint64_t mem_size,
 				       cvmx_bootmem_desc_t * desc_buffer);
 
 /**
+ * This function initializes the free memory list used by cvmx_bootmem.
+ * This must be called before any allocations can be done.
+ *
+ * @param nodemask Nodemask - one bit per node (bit0->node0, bit1->node1,...)
+ *
+ * @param mem_size[] Array of memory sizes in MBytes per node ([0]->node0,...)
+ *
+ * @param low_reserved_bytes Number of bytes to reserve (leave out of
+ * free list) at address 0x0.
+ *
+ * @param desc_buffer Buffer for the bootmem descriptor.  This must be
+ *                 a 32 bit addressable address.
+ *
+ * @return 1 on success
+ *         0 on failure
+ */
+int64_t cvmx_bootmem_phy_mem_list_init_multi(uint8_t nodemask,
+				       uint32_t mem_size[],
+				       uint32_t low_reserved_bytes,
+				       cvmx_bootmem_desc_t * desc_buffer);
+/**
  * Locks the bootmem allocator.  This is useful in certain situations
  * where multiple allocations must be made without being interrupted.
  * This should be used with the CVMX_BOOTMEM_FLAG_NO_LOCKING flag.
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
index 631e44d..e83a2a7 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -196,7 +196,58 @@ static inline uint64_t CVMX_CIU_CIB_USBDRDX_RAWX(unsigned long offset, unsigned
 #else
 #define CVMX_CIU_CIB_USBDRDX_RAWX(offset, block_id) (CVMX_ADD_IO_SEG(0x000107000000E800ull) + ((block_id) & 1) * 0x100ull)
 #endif
-#define CVMX_CIU_DINT (CVMX_ADD_IO_SEG(0x0001070000000720ull))
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU_DINT CVMX_CIU_DINT_FUNC()
+static inline uint64_t CVMX_CIU_DINT_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000720ull);
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001010000000180ull);
+			break;
+	}
+	cvmx_warn("CVMX_CIU_DINT not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001070000000720ull);
+}
+#else
+#define CVMX_CIU_DINT CVMX_CIU_DINT_FUNC()
+static inline uint64_t CVMX_CIU_DINT_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000720ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001010000000180ull);
+	}
+	return CVMX_ADD_IO_SEG(0x0001070000000720ull);
+}
+#endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_CIU_EN2_IOX_INT(unsigned long offset)
 {
@@ -365,7 +416,58 @@ static inline uint64_t CVMX_CIU_EN2_PPX_IP4_W1S(unsigned long offset)
 #else
 #define CVMX_CIU_EN2_PPX_IP4_W1S(offset) (CVMX_ADD_IO_SEG(0x000107000000AC00ull) + ((offset) & 15) * 8)
 #endif
-#define CVMX_CIU_FUSE (CVMX_ADD_IO_SEG(0x0001070000000728ull))
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU_FUSE CVMX_CIU_FUSE_FUNC()
+static inline uint64_t CVMX_CIU_FUSE_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000728ull);
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00010100000001A0ull);
+			break;
+	}
+	cvmx_warn("CVMX_CIU_FUSE not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001070000000728ull);
+}
+#else
+#define CVMX_CIU_FUSE CVMX_CIU_FUSE_FUNC()
+static inline uint64_t CVMX_CIU_FUSE_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000728ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x00010100000001A0ull);
+	}
+	return CVMX_ADD_IO_SEG(0x0001070000000728ull);
+}
+#endif
 #define CVMX_CIU_GSTOP (CVMX_ADD_IO_SEG(0x0001070000000710ull))
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_CIU_INT33_SUM0 CVMX_CIU_INT33_SUM0_FUNC()
@@ -839,7 +941,58 @@ static inline uint64_t CVMX_CIU_PP_BIST_STAT_FUNC(void)
 #else
 #define CVMX_CIU_PP_BIST_STAT (CVMX_ADD_IO_SEG(0x00010700000007E0ull))
 #endif
-#define CVMX_CIU_PP_DBG (CVMX_ADD_IO_SEG(0x0001070000000708ull))
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU_PP_DBG CVMX_CIU_PP_DBG_FUNC()
+static inline uint64_t CVMX_CIU_PP_DBG_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000708ull);
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001010000000120ull);
+			break;
+	}
+	cvmx_warn("CVMX_CIU_PP_DBG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001070000000708ull);
+}
+#else
+#define CVMX_CIU_PP_DBG CVMX_CIU_PP_DBG_FUNC()
+static inline uint64_t CVMX_CIU_PP_DBG_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000708ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001010000000120ull);
+	}
+	return CVMX_ADD_IO_SEG(0x0001070000000708ull);
+}
+#endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_CIU_PP_POKEX(unsigned long offset)
 {
@@ -877,14 +1030,14 @@ static inline uint64_t CVMX_CIU_PP_POKEX(unsigned long offset)
 			if ((offset == 0))
 				return CVMX_ADD_IO_SEG(0x0001070000000580ull) + ((offset) & 0) * 8;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 47))
+				return CVMX_ADD_IO_SEG(0x0001010000030000ull) + ((offset) & 63) * 8;
+			break;
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
 				return CVMX_ADD_IO_SEG(0x0001070100100200ull) + ((offset) & 31) * 8;
 			break;
-
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 47))
-				return CVMX_ADD_IO_SEG(0x0001010000030000ull) + ((offset) & 63) * 8;
 	}
 	cvmx_warn("CVMX_CIU_PP_POKEX (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001070000000580ull) + ((offset) & 3) * 8;
@@ -912,25 +1065,93 @@ static inline uint64_t CVMX_CIU_PP_POKEX(unsigned long offset)
 			return CVMX_ADD_IO_SEG(0x0001070000000580ull) + (offset) * 8;
 		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001070000000580ull) + (offset) * 8;
-		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0001070100100200ull) + (offset) * 8;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000030000ull) + (offset) * 8;
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070100100200ull) + (offset) * 8;
 	}
 	return CVMX_ADD_IO_SEG(0x0001070000000580ull) + (offset) * 8;
 }
 #endif
-#define CVMX_CIU_PP_RST (CVMX_ADD_IO_SEG(0x0001070000000700ull))
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_CIU_PP_RST CVMX_CIU_PP_RST_FUNC()
+static inline uint64_t CVMX_CIU_PP_RST_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000700ull);
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001010000000100ull);
+			break;
+	}
+	cvmx_warn("CVMX_CIU_PP_RST not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001070000000700ull);
+}
+#else
+#define CVMX_CIU_PP_RST CVMX_CIU_PP_RST_FUNC()
+static inline uint64_t CVMX_CIU_PP_RST_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000700ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001010000000100ull);
+	}
+	return CVMX_ADD_IO_SEG(0x0001070000000700ull);
+}
+#endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_CIU_PP_RST_PENDING CVMX_CIU_PP_RST_PENDING_FUNC()
 static inline uint64_t CVMX_CIU_PP_RST_PENDING_FUNC(void)
 {
-	if (!(OCTEON_IS_MODEL(OCTEON_CN70XX)))
-		cvmx_warn("CVMX_CIU_PP_RST_PENDING not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001070000000740ull);
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000740ull);
+			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001010000000110ull);
+			break;
+	}
+	cvmx_warn("CVMX_CIU_PP_RST_PENDING not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001010000000110ull);
 }
 #else
-#define CVMX_CIU_PP_RST_PENDING (CVMX_ADD_IO_SEG(0x0001070000000740ull))
+#define CVMX_CIU_PP_RST_PENDING CVMX_CIU_PP_RST_PENDING_FUNC()
+static inline uint64_t CVMX_CIU_PP_RST_PENDING_FUNC(void)
+{
+	switch(cvmx_get_octeon_family()) {
+		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070000000740ull);
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001010000000110ull);
+	}
+	return CVMX_ADD_IO_SEG(0x0001010000000110ull);
+}
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_CIU_QLM0 CVMX_CIU_QLM0_FUNC()
@@ -1260,14 +1481,14 @@ static inline uint64_t CVMX_CIU_WDOGX(unsigned long offset)
 			if ((offset == 0))
 				return CVMX_ADD_IO_SEG(0x0001070000000500ull) + ((offset) & 0) * 8;
 			break;
+		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
+			if ((offset <= 47))
+				return CVMX_ADD_IO_SEG(0x0001010000020000ull) + ((offset) & 63) * 8;
+			break;
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
 			if ((offset <= 31))
 				return CVMX_ADD_IO_SEG(0x0001070100100000ull) + ((offset) & 31) * 8;
 			break;
-
-		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
-			if ((offset <= 47))
-				return CVMX_ADD_IO_SEG(0x0001010000020000ull) + ((offset) & 63) * 8;
 	}
 	cvmx_warn("CVMX_CIU_WDOGX (offset = %lu) not supported on this chip\n", offset);
 	return CVMX_ADD_IO_SEG(0x0001070000000500ull) + ((offset) & 3) * 8;
@@ -1295,10 +1516,10 @@ static inline uint64_t CVMX_CIU_WDOGX(unsigned long offset)
 			return CVMX_ADD_IO_SEG(0x0001070000000500ull) + (offset) * 8;
 		case OCTEON_CN30XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001070000000500ull) + (offset) * 8;
-		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
-			return CVMX_ADD_IO_SEG(0x0001070100100000ull) + (offset) * 8;
 		case OCTEON_CN78XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001010000020000ull) + (offset) * 8;
+		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
+			return CVMX_ADD_IO_SEG(0x0001070100100000ull) + (offset) * 8;
 	}
 	return CVMX_ADD_IO_SEG(0x0001070000000500ull) + (offset) * 8;
 }
@@ -1388,6 +1609,7 @@ union cvmx_ciu_bist {
 	struct cvmx_ciu_bist_s                cn68xx;
 	struct cvmx_ciu_bist_s                cn68xxp1;
 	struct cvmx_ciu_bist_cn52xx           cn70xx;
+	struct cvmx_ciu_bist_cn52xx           cn70xxp1;
 	struct cvmx_ciu_bist_cn61xx           cnf71xx;
 };
 typedef union cvmx_ciu_bist cvmx_ciu_bist_t;
@@ -1973,6 +2195,7 @@ union cvmx_ciu_cib_l2c_enx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_l2c_enx_s         cn70xx;
+	struct cvmx_ciu_cib_l2c_enx_s         cn70xxp1;
 };
 typedef union cvmx_ciu_cib_l2c_enx cvmx_ciu_cib_l2c_enx_t;
 
@@ -2058,6 +2281,7 @@ union cvmx_ciu_cib_l2c_rawx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_l2c_rawx_s        cn70xx;
+	struct cvmx_ciu_cib_l2c_rawx_s        cn70xxp1;
 };
 typedef union cvmx_ciu_cib_l2c_rawx cvmx_ciu_cib_l2c_rawx_t;
 
@@ -2086,6 +2310,7 @@ union cvmx_ciu_cib_lmcx_enx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_lmcx_enx_s        cn70xx;
+	struct cvmx_ciu_cib_lmcx_enx_s        cn70xxp1;
 };
 typedef union cvmx_ciu_cib_lmcx_enx cvmx_ciu_cib_lmcx_enx_t;
 
@@ -2120,6 +2345,7 @@ union cvmx_ciu_cib_lmcx_rawx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_lmcx_rawx_s       cn70xx;
+	struct cvmx_ciu_cib_lmcx_rawx_s       cn70xxp1;
 };
 typedef union cvmx_ciu_cib_lmcx_rawx cvmx_ciu_cib_lmcx_rawx_t;
 
@@ -2156,6 +2382,7 @@ union cvmx_ciu_cib_oclax_enx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_oclax_enx_s       cn70xx;
+	struct cvmx_ciu_cib_oclax_enx_s       cn70xxp1;
 };
 typedef union cvmx_ciu_cib_oclax_enx cvmx_ciu_cib_oclax_enx_t;
 
@@ -2202,6 +2429,7 @@ union cvmx_ciu_cib_oclax_rawx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_oclax_rawx_s      cn70xx;
+	struct cvmx_ciu_cib_oclax_rawx_s      cn70xxp1;
 };
 typedef union cvmx_ciu_cib_oclax_rawx cvmx_ciu_cib_oclax_rawx_t;
 
@@ -2222,6 +2450,7 @@ union cvmx_ciu_cib_rst_enx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_rst_enx_s         cn70xx;
+	struct cvmx_ciu_cib_rst_enx_s         cn70xxp1;
 };
 typedef union cvmx_ciu_cib_rst_enx cvmx_ciu_cib_rst_enx_t;
 
@@ -2244,6 +2473,7 @@ union cvmx_ciu_cib_rst_rawx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_rst_rawx_s        cn70xx;
+	struct cvmx_ciu_cib_rst_rawx_s        cn70xxp1;
 };
 typedef union cvmx_ciu_cib_rst_rawx cvmx_ciu_cib_rst_rawx_t;
 
@@ -2268,6 +2498,7 @@ union cvmx_ciu_cib_sata_enx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_sata_enx_s        cn70xx;
+	struct cvmx_ciu_cib_sata_enx_s        cn70xxp1;
 };
 typedef union cvmx_ciu_cib_sata_enx cvmx_ciu_cib_sata_enx_t;
 
@@ -2309,6 +2540,7 @@ union cvmx_ciu_cib_sata_rawx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_sata_rawx_s       cn70xx;
+	struct cvmx_ciu_cib_sata_rawx_s       cn70xxp1;
 };
 typedef union cvmx_ciu_cib_sata_rawx cvmx_ciu_cib_sata_rawx_t;
 
@@ -2347,6 +2579,7 @@ union cvmx_ciu_cib_usbdrdx_enx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_usbdrdx_enx_s     cn70xx;
+	struct cvmx_ciu_cib_usbdrdx_enx_s     cn70xxp1;
 };
 typedef union cvmx_ciu_cib_usbdrdx_enx cvmx_ciu_cib_usbdrdx_enx_t;
 
@@ -2425,6 +2658,7 @@ union cvmx_ciu_cib_usbdrdx_rawx {
 #endif
 	} s;
 	struct cvmx_ciu_cib_usbdrdx_rawx_s    cn70xx;
+	struct cvmx_ciu_cib_usbdrdx_rawx_s    cn70xxp1;
 };
 typedef union cvmx_ciu_cib_usbdrdx_rawx cvmx_ciu_cib_usbdrdx_rawx_t;
 
@@ -2435,11 +2669,11 @@ union cvmx_ciu_dint {
 	uint64_t u64;
 	struct cvmx_ciu_dint_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_32_63               : 32;
-	uint64_t dint                         : 32; /**< Send DINT pulse to PP vector */
+	uint64_t reserved_48_63               : 16;
+	uint64_t dint                         : 48; /**< Send DINT pulse to PP vector */
 #else
-	uint64_t dint                         : 32;
-	uint64_t reserved_32_63               : 32;
+	uint64_t dint                         : 48;
+	uint64_t reserved_48_63               : 16;
 #endif
 	} s;
 	struct cvmx_ciu_dint_cn30xx {
@@ -2513,9 +2747,19 @@ union cvmx_ciu_dint {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} cn66xx;
-	struct cvmx_ciu_dint_s                cn68xx;
-	struct cvmx_ciu_dint_s                cn68xxp1;
+	struct cvmx_ciu_dint_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t dint                         : 32; /**< Send DINT pulse to PP vector */
+#else
+	uint64_t dint                         : 32;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} cn68xx;
+	struct cvmx_ciu_dint_cn68xx           cn68xxp1;
 	struct cvmx_ciu_dint_cn52xx           cn70xx;
+	struct cvmx_ciu_dint_cn52xx           cn70xxp1;
+	struct cvmx_ciu_dint_s                cn78xx;
 	struct cvmx_ciu_dint_cn52xx           cnf71xx;
 };
 typedef union cvmx_ciu_dint cvmx_ciu_dint_t;
@@ -2588,6 +2832,7 @@ union cvmx_ciu_en2_iox_int {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_iox_int_cn70xx    cn70xxp1;
 	struct cvmx_ciu_en2_iox_int_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -2676,6 +2921,7 @@ union cvmx_ciu_en2_iox_int_w1c {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_iox_int_w1c_cn70xx cn70xxp1;
 	struct cvmx_ciu_en2_iox_int_w1c_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -2764,6 +3010,7 @@ union cvmx_ciu_en2_iox_int_w1s {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_iox_int_w1s_cn70xx cn70xxp1;
 	struct cvmx_ciu_en2_iox_int_w1s_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -2853,6 +3100,7 @@ union cvmx_ciu_en2_ppx_ip2 {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip2_cn70xx    cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip2_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -2941,6 +3189,7 @@ union cvmx_ciu_en2_ppx_ip2_w1c {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip2_w1c_cn70xx cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip2_w1c_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -3029,6 +3278,7 @@ union cvmx_ciu_en2_ppx_ip2_w1s {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip2_w1s_cn70xx cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip2_w1s_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -3118,6 +3368,7 @@ union cvmx_ciu_en2_ppx_ip3 {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip3_cn70xx    cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip3_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -3207,6 +3458,7 @@ union cvmx_ciu_en2_ppx_ip3_w1c {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip3_w1c_cn70xx cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip3_w1c_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -3296,6 +3548,7 @@ union cvmx_ciu_en2_ppx_ip3_w1s {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip3_w1s_cn70xx cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip3_w1s_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -3385,6 +3638,7 @@ union cvmx_ciu_en2_ppx_ip4 {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip4_cn70xx    cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip4_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -3474,6 +3728,7 @@ union cvmx_ciu_en2_ppx_ip4_w1c {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip4_w1c_cn70xx cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip4_w1c_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -3563,6 +3818,7 @@ union cvmx_ciu_en2_ppx_ip4_w1s {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_en2_ppx_ip4_w1s_cn70xx cn70xxp1;
 	struct cvmx_ciu_en2_ppx_ip4_w1s_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -3590,11 +3846,11 @@ union cvmx_ciu_fuse {
 	uint64_t u64;
 	struct cvmx_ciu_fuse_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_32_63               : 32;
-	uint64_t fuse                         : 32; /**< Physical PP is present */
+	uint64_t reserved_48_63               : 16;
+	uint64_t fuse                         : 48; /**< Physical PP is present */
 #else
-	uint64_t fuse                         : 32;
-	uint64_t reserved_32_63               : 32;
+	uint64_t fuse                         : 48;
+	uint64_t reserved_48_63               : 16;
 #endif
 	} s;
 	struct cvmx_ciu_fuse_cn30xx {
@@ -3668,9 +3924,19 @@ union cvmx_ciu_fuse {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} cn66xx;
-	struct cvmx_ciu_fuse_s                cn68xx;
-	struct cvmx_ciu_fuse_s                cn68xxp1;
+	struct cvmx_ciu_fuse_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t fuse                         : 32; /**< Physical PP is present */
+#else
+	uint64_t fuse                         : 32;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} cn68xx;
+	struct cvmx_ciu_fuse_cn68xx           cn68xxp1;
 	struct cvmx_ciu_fuse_cn52xx           cn70xx;
+	struct cvmx_ciu_fuse_cn52xx           cn70xxp1;
+	struct cvmx_ciu_fuse_s                cn78xx;
 	struct cvmx_ciu_fuse_cn52xx           cnf71xx;
 };
 typedef union cvmx_ciu_fuse cvmx_ciu_fuse_t;
@@ -3707,6 +3973,7 @@ union cvmx_ciu_gstop {
 	struct cvmx_ciu_gstop_s               cn68xx;
 	struct cvmx_ciu_gstop_s               cn68xxp1;
 	struct cvmx_ciu_gstop_s               cn70xx;
+	struct cvmx_ciu_gstop_s               cn70xxp1;
 	struct cvmx_ciu_gstop_s               cnf71xx;
 };
 typedef union cvmx_ciu_gstop cvmx_ciu_gstop_t;
@@ -4148,6 +4415,7 @@ union cvmx_ciu_intx_en0 {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en0_cn70xx       cn70xxp1;
 	struct cvmx_ciu_intx_en0_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Boot bus DMA engines Interrupt enable */
@@ -4557,6 +4825,7 @@ union cvmx_ciu_intx_en0_w1c {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en0_w1c_cn70xx   cn70xxp1;
 	struct cvmx_ciu_intx_en0_w1c_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Write 1 to clear Boot bus DMA engines Interrupt
@@ -4968,6 +5237,7 @@ union cvmx_ciu_intx_en0_w1s {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en0_w1s_cn70xx   cn70xxp1;
 	struct cvmx_ciu_intx_en0_w1s_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Write 1 to set Boot bus DMA engines Interrupt
@@ -5529,6 +5799,7 @@ union cvmx_ciu_intx_en1 {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en1_cn70xx       cn70xxp1;
 	struct cvmx_ciu_intx_en1_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< MIO RST interrupt enable */
@@ -6034,6 +6305,7 @@ union cvmx_ciu_intx_en1_w1c {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en1_w1c_cn70xx   cn70xxp1;
 	struct cvmx_ciu_intx_en1_w1c_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< Write 1 to clear MIO RST interrupt enable */
@@ -6540,6 +6812,7 @@ union cvmx_ciu_intx_en1_w1s {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en1_w1s_cn70xx   cn70xxp1;
 	struct cvmx_ciu_intx_en1_w1s_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< Write 1 to set MIO RST interrupt enable */
@@ -6992,6 +7265,7 @@ union cvmx_ciu_intx_en4_0 {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en4_0_cn70xx     cn70xxp1;
 	struct cvmx_ciu_intx_en4_0_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Boot bus DMA engines Interrupt enable */
@@ -7393,6 +7667,7 @@ union cvmx_ciu_intx_en4_0_w1c {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en4_0_w1c_cn70xx cn70xxp1;
 	struct cvmx_ciu_intx_en4_0_w1c_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Write 1 to clear Boot bus DMA engines Interrupt
@@ -7800,6 +8075,7 @@ union cvmx_ciu_intx_en4_0_w1s {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en4_0_w1s_cn70xx cn70xxp1;
 	struct cvmx_ciu_intx_en4_0_w1s_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Write 1 to set Boot bus DMA engines Interrupt
@@ -8312,6 +8588,7 @@ union cvmx_ciu_intx_en4_1 {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en4_1_cn70xx     cn70xxp1;
 	struct cvmx_ciu_intx_en4_1_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< MIO RST interrupt enable */
@@ -8816,6 +9093,7 @@ union cvmx_ciu_intx_en4_1_w1c {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en4_1_w1c_cn70xx cn70xxp1;
 	struct cvmx_ciu_intx_en4_1_w1c_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< Write 1 to clear MIO RST interrupt enable */
@@ -9321,6 +9599,7 @@ union cvmx_ciu_intx_en4_1_w1s {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_en4_1_w1s_cn70xx cn70xxp1;
 	struct cvmx_ciu_intx_en4_1_w1s_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< Write 1 to set MIO RST interrupt enable */
@@ -10126,6 +10405,7 @@ union cvmx_ciu_intx_sum0 {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_sum0_cn70xx      cn70xxp1;
 	struct cvmx_ciu_intx_sum0_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Boot bus DMA engines Interrupt
@@ -10881,6 +11161,7 @@ union cvmx_ciu_intx_sum4 {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_intx_sum4_cn70xx      cn70xxp1;
 	struct cvmx_ciu_intx_sum4_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Boot bus DMA engines Interrupt
@@ -11387,6 +11668,7 @@ union cvmx_ciu_int33_sum0 {
 	uint64_t bootdma                      : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_int33_sum0_cn70xx     cn70xxp1;
 	struct cvmx_ciu_int33_sum0_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bootdma                      : 1;  /**< Boot bus DMA engines Interrupt
@@ -12190,6 +12472,7 @@ union cvmx_ciu_int_sum1 {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_int_sum1_cn70xx       cn70xxp1;
 	struct cvmx_ciu_int_sum1_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< MIO RST interrupt
@@ -12299,6 +12582,7 @@ union cvmx_ciu_intr_slowdown {
 #endif
 	} s;
 	struct cvmx_ciu_intr_slowdown_s       cn70xx;
+	struct cvmx_ciu_intr_slowdown_s       cn70xxp1;
 };
 typedef union cvmx_ciu_intr_slowdown cvmx_ciu_intr_slowdown_t;
 
@@ -12335,6 +12619,7 @@ union cvmx_ciu_mbox_clrx {
 	struct cvmx_ciu_mbox_clrx_s           cn68xx;
 	struct cvmx_ciu_mbox_clrx_s           cn68xxp1;
 	struct cvmx_ciu_mbox_clrx_s           cn70xx;
+	struct cvmx_ciu_mbox_clrx_s           cn70xxp1;
 	struct cvmx_ciu_mbox_clrx_s           cnf71xx;
 };
 typedef union cvmx_ciu_mbox_clrx cvmx_ciu_mbox_clrx_t;
@@ -12372,6 +12657,7 @@ union cvmx_ciu_mbox_setx {
 	struct cvmx_ciu_mbox_setx_s           cn68xx;
 	struct cvmx_ciu_mbox_setx_s           cn68xxp1;
 	struct cvmx_ciu_mbox_setx_s           cn70xx;
+	struct cvmx_ciu_mbox_setx_s           cn70xxp1;
 	struct cvmx_ciu_mbox_setx_s           cnf71xx;
 };
 typedef union cvmx_ciu_mbox_setx cvmx_ciu_mbox_setx_t;
@@ -12464,6 +12750,7 @@ union cvmx_ciu_nmi {
 	struct cvmx_ciu_nmi_s                 cn68xx;
 	struct cvmx_ciu_nmi_s                 cn68xxp1;
 	struct cvmx_ciu_nmi_cn52xx            cn70xx;
+	struct cvmx_ciu_nmi_cn52xx            cn70xxp1;
 	struct cvmx_ciu_nmi_cn52xx            cnf71xx;
 };
 typedef union cvmx_ciu_nmi cvmx_ciu_nmi_t;
@@ -12502,6 +12789,7 @@ union cvmx_ciu_pci_inta {
 	struct cvmx_ciu_pci_inta_s            cn68xx;
 	struct cvmx_ciu_pci_inta_s            cn68xxp1;
 	struct cvmx_ciu_pci_inta_s            cn70xx;
+	struct cvmx_ciu_pci_inta_s            cn70xxp1;
 	struct cvmx_ciu_pci_inta_s            cnf71xx;
 };
 typedef union cvmx_ciu_pci_inta cvmx_ciu_pci_inta_t;
@@ -12532,12 +12820,12 @@ union cvmx_ciu_pp_dbg {
 	uint64_t u64;
 	struct cvmx_ciu_pp_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_32_63               : 32;
-	uint64_t ppdbg                        : 32; /**< Debug[DM] value for each PP
+	uint64_t reserved_48_63               : 16;
+	uint64_t ppdbg                        : 48; /**< Debug[DM] value for each PP
                                                          whether the PP's are in debug mode or not */
 #else
-	uint64_t ppdbg                        : 32;
-	uint64_t reserved_32_63               : 32;
+	uint64_t ppdbg                        : 48;
+	uint64_t reserved_48_63               : 16;
 #endif
 	} s;
 	struct cvmx_ciu_pp_dbg_cn30xx {
@@ -12618,9 +12906,20 @@ union cvmx_ciu_pp_dbg {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} cn66xx;
-	struct cvmx_ciu_pp_dbg_s              cn68xx;
-	struct cvmx_ciu_pp_dbg_s              cn68xxp1;
+	struct cvmx_ciu_pp_dbg_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t ppdbg                        : 32; /**< Debug[DM] value for each PP
+                                                         whether the PP's are in debug mode or not */
+#else
+	uint64_t ppdbg                        : 32;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} cn68xx;
+	struct cvmx_ciu_pp_dbg_cn68xx         cn68xxp1;
 	struct cvmx_ciu_pp_dbg_cn52xx         cn70xx;
+	struct cvmx_ciu_pp_dbg_cn52xx         cn70xxp1;
+	struct cvmx_ciu_pp_dbg_s              cn78xx;
 	struct cvmx_ciu_pp_dbg_cn52xx         cnf71xx;
 };
 typedef union cvmx_ciu_pp_dbg cvmx_ciu_pp_dbg_t;
@@ -12658,6 +12957,20 @@ union cvmx_ciu_pp_pokex {
 	struct cvmx_ciu_pp_pokex_s            cn68xx;
 	struct cvmx_ciu_pp_pokex_s            cn68xxp1;
 	struct cvmx_ciu_pp_pokex_s            cn70xx;
+	struct cvmx_ciu_pp_pokex_s            cn70xxp1;
+	struct cvmx_ciu_pp_pokex_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t poke                         : 1;  /**< Core poke. Writing any value to this register does the following:
+                                                         clears any pending interrupt generated by the associated watchdog
+                                                         resets CIU_WDOG(0..47)[STATE] to 0x0
+                                                         sets CIU_WDOG(0..47)[CNT] to ( CIU_WDOG(0..47)[LEN] << 8).
+                                                         Reading this register returns the associated CIU_WDOG(0..47) register. */
+#else
+	uint64_t poke                         : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} cn78xx;
 	struct cvmx_ciu_pp_pokex_s            cnf71xx;
 };
 typedef union cvmx_ciu_pp_pokex cvmx_ciu_pp_pokex_t;
@@ -12665,27 +12978,23 @@ typedef union cvmx_ciu_pp_pokex cvmx_ciu_pp_pokex_t;
 /**
  * cvmx_ciu_pp_rst
  *
- * Contains the reset control for each PP.  Value of '1' will hold a PP in reset, '0' will
- * release.
- * Resets to all 1's when REMOTE_BOOT is enabled, 0xe otherwise.  Writes to this register should
- * occur
- * only if the CIU_PP_RST_PENDING register is cleared.
- * On 70XX pass 2, RST_PP_POWER register can be statically set and writes to this register will
- * automatically enable/disable power
- * saving when RST_PP_POWER[GATE] is enabled.
+ * This register contains the reset control for each core. A 1 holds a core in reset, 0 release
+ * from reset. It resets to all ones when REMOTE_BOOT is enabled or all ones excluding bit 0 when
+ * REMOTE_BOOT is disabled. Writes to this register should occur only if the CIU_PP_RST_PENDING
+ * register is cleared.
  */
 union cvmx_ciu_pp_rst {
 	uint64_t u64;
 	struct cvmx_ciu_pp_rst_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_32_63               : 32;
-	uint64_t rst                          : 31; /**< PP Rst for PP's 3-1 */
+	uint64_t reserved_48_63               : 16;
+	uint64_t rst                          : 47; /**< PP Rst for PP's 3-1 */
 	uint64_t rst0                         : 1;  /**< PP Rst for PP0
                                                          depends on standalone mode */
 #else
 	uint64_t rst0                         : 1;
-	uint64_t rst                          : 31;
-	uint64_t reserved_32_63               : 32;
+	uint64_t rst                          : 47;
+	uint64_t reserved_48_63               : 16;
 #endif
 	} s;
 	struct cvmx_ciu_pp_rst_cn30xx {
@@ -12778,9 +13087,22 @@ union cvmx_ciu_pp_rst {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} cn66xx;
-	struct cvmx_ciu_pp_rst_s              cn68xx;
-	struct cvmx_ciu_pp_rst_s              cn68xxp1;
+	struct cvmx_ciu_pp_rst_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_32_63               : 32;
+	uint64_t rst                          : 31; /**< PP Rst for PP's 31-1 */
+	uint64_t rst0                         : 1;  /**< PP Rst for PP0
+                                                         depends on standalone mode */
+#else
+	uint64_t rst0                         : 1;
+	uint64_t rst                          : 31;
+	uint64_t reserved_32_63               : 32;
+#endif
+	} cn68xx;
+	struct cvmx_ciu_pp_rst_cn68xx         cn68xxp1;
 	struct cvmx_ciu_pp_rst_cn52xx         cn70xx;
+	struct cvmx_ciu_pp_rst_cn52xx         cn70xxp1;
+	struct cvmx_ciu_pp_rst_s              cn78xx;
 	struct cvmx_ciu_pp_rst_cn52xx         cnf71xx;
 };
 typedef union cvmx_ciu_pp_rst cvmx_ciu_pp_rst_t;
@@ -12788,25 +13110,26 @@ typedef union cvmx_ciu_pp_rst cvmx_ciu_pp_rst_t;
 /**
  * cvmx_ciu_pp_rst_pending
  *
- * This register contains the reset status for each core. A 1 indicated the core is waiting to
- * change it's reset state.
- * On 70XX pass 2, normally a reset change occurs immediately but if RST_PP_POWER[GATE] bit is
- * set and
- * the core is released from reset
- * a delay of 64K core clocks per PP will occur to satisify power management.
+ * This register contains the reset status for each core.
+ *
  */
 union cvmx_ciu_pp_rst_pending {
 	uint64_t u64;
 	struct cvmx_ciu_pp_rst_pending_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t pend                         : 48; /**< Core waiting on reset to deassert complete.  This register always returns zero on 70xx Pass 1. */
+	uint64_t pend                         : 48; /**< Set if corresponding core is waiting to change its reset state. Normally a reset change
+                                                         occurs immediately but if RST_PP_POWER[GATE] bit is set and the core is released from
+                                                         reset a delay of 64K core clocks between each core reset will apply to satisfy power
+                                                         management. */
 #else
 	uint64_t pend                         : 48;
 	uint64_t reserved_48_63               : 16;
 #endif
 	} s;
 	struct cvmx_ciu_pp_rst_pending_s      cn70xx;
+	struct cvmx_ciu_pp_rst_pending_s      cn70xxp1;
+	struct cvmx_ciu_pp_rst_pending_s      cn78xx;
 };
 typedef union cvmx_ciu_pp_rst_pending cvmx_ciu_pp_rst_pending_t;
 
@@ -13453,6 +13776,7 @@ union cvmx_ciu_soft_bist {
 	struct cvmx_ciu_soft_bist_s           cn68xx;
 	struct cvmx_ciu_soft_bist_s           cn68xxp1;
 	struct cvmx_ciu_soft_bist_s           cn70xx;
+	struct cvmx_ciu_soft_bist_s           cn70xxp1;
 	struct cvmx_ciu_soft_bist_s           cnf71xx;
 };
 typedef union cvmx_ciu_soft_bist cvmx_ciu_soft_bist_t;
@@ -14071,6 +14395,7 @@ union cvmx_ciu_sum1_iox_int {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_sum1_iox_int_cn70xx   cn70xxp1;
 	struct cvmx_ciu_sum1_iox_int_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< MIO RST interrupt
@@ -14605,6 +14930,7 @@ union cvmx_ciu_sum1_ppx_ip2 {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_sum1_ppx_ip2_cn70xx   cn70xxp1;
 	struct cvmx_ciu_sum1_ppx_ip2_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< MIO RST interrupt
@@ -15140,6 +15466,7 @@ union cvmx_ciu_sum1_ppx_ip3 {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_sum1_ppx_ip3_cn70xx   cn70xxp1;
 	struct cvmx_ciu_sum1_ppx_ip3_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< MIO RST interrupt
@@ -15675,6 +16002,7 @@ union cvmx_ciu_sum1_ppx_ip4 {
 	uint64_t rst                          : 1;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_sum1_ppx_ip4_cn70xx   cn70xxp1;
 	struct cvmx_ciu_sum1_ppx_ip4_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t rst                          : 1;  /**< MIO RST interrupt
@@ -15866,6 +16194,7 @@ union cvmx_ciu_sum2_iox_int {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_sum2_iox_int_cn70xx   cn70xxp1;
 	struct cvmx_ciu_sum2_iox_int_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -15996,6 +16325,7 @@ union cvmx_ciu_sum2_ppx_ip2 {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_sum2_ppx_ip2_cn70xx   cn70xxp1;
 	struct cvmx_ciu_sum2_ppx_ip2_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -16127,6 +16457,7 @@ union cvmx_ciu_sum2_ppx_ip3 {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_sum2_ppx_ip3_cn70xx   cn70xxp1;
 	struct cvmx_ciu_sum2_ppx_ip3_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -16258,6 +16589,7 @@ union cvmx_ciu_sum2_ppx_ip4 {
 	uint64_t reserved_20_63               : 44;
 #endif
 	} cn70xx;
+	struct cvmx_ciu_sum2_ppx_ip4_cn70xx   cn70xxp1;
 	struct cvmx_ciu_sum2_ppx_ip4_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
@@ -16329,6 +16661,7 @@ union cvmx_ciu_timx {
 	struct cvmx_ciu_timx_s                cn68xx;
 	struct cvmx_ciu_timx_s                cn68xxp1;
 	struct cvmx_ciu_timx_s                cn70xx;
+	struct cvmx_ciu_timx_s                cn70xxp1;
 	struct cvmx_ciu_timx_s                cnf71xx;
 };
 typedef union cvmx_ciu_timx cvmx_ciu_timx_t;
@@ -16361,6 +16694,7 @@ union cvmx_ciu_tim_multi_cast {
 	struct cvmx_ciu_tim_multi_cast_s      cn61xx;
 	struct cvmx_ciu_tim_multi_cast_s      cn66xx;
 	struct cvmx_ciu_tim_multi_cast_s      cn70xx;
+	struct cvmx_ciu_tim_multi_cast_s      cn70xxp1;
 	struct cvmx_ciu_tim_multi_cast_s      cnf71xx;
 };
 typedef union cvmx_ciu_tim_multi_cast cvmx_ciu_tim_multi_cast_t;
@@ -16420,6 +16754,8 @@ union cvmx_ciu_wdogx {
 	struct cvmx_ciu_wdogx_s               cn68xx;
 	struct cvmx_ciu_wdogx_s               cn68xxp1;
 	struct cvmx_ciu_wdogx_s               cn70xx;
+	struct cvmx_ciu_wdogx_s               cn70xxp1;
+	struct cvmx_ciu_wdogx_s               cn78xx;
 	struct cvmx_ciu_wdogx_s               cnf71xx;
 };
 typedef union cvmx_ciu_wdogx cvmx_ciu_wdogx_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu2-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu2-defs.h
index eca97c0..992ca6b 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu2-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu2-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
index 4b5ac3e..73bca84 100644
--- a/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ciu3-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -108,28 +108,6 @@ static inline uint64_t CVMX_CIU3_DESTX_PP_INT(unsigned long offset)
 #define CVMX_CIU3_DESTX_PP_INT(offset) (CVMX_ADD_IO_SEG(0x0001010000200000ull) + ((offset) & 255) * 8)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_CIU3_DINT CVMX_CIU3_DINT_FUNC()
-static inline uint64_t CVMX_CIU3_DINT_FUNC(void)
-{
-	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_CIU3_DINT not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001010000000180ull);
-}
-#else
-#define CVMX_CIU3_DINT (CVMX_ADD_IO_SEG(0x0001010000000180ull))
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_CIU3_FUSE CVMX_CIU3_FUSE_FUNC()
-static inline uint64_t CVMX_CIU3_FUSE_FUNC(void)
-{
-	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_CIU3_FUSE not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x00010100000001A0ull);
-}
-#else
-#define CVMX_CIU3_FUSE (CVMX_ADD_IO_SEG(0x00010100000001A0ull))
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_CIU3_GSTOP CVMX_CIU3_GSTOP_FUNC()
 static inline uint64_t CVMX_CIU3_GSTOP_FUNC(void)
 {
@@ -273,50 +251,6 @@ static inline uint64_t CVMX_CIU3_NMI_FUNC(void)
 #define CVMX_CIU3_NMI (CVMX_ADD_IO_SEG(0x0001010000000160ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_CIU3_PP_DBG CVMX_CIU3_PP_DBG_FUNC()
-static inline uint64_t CVMX_CIU3_PP_DBG_FUNC(void)
-{
-	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_CIU3_PP_DBG not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001010000000120ull);
-}
-#else
-#define CVMX_CIU3_PP_DBG (CVMX_ADD_IO_SEG(0x0001010000000120ull))
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_CIU3_PP_POKEX(unsigned long offset)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 47)))))
-		cvmx_warn("CVMX_CIU3_PP_POKEX(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001010000030000ull) + ((offset) & 63) * 8;
-}
-#else
-#define CVMX_CIU3_PP_POKEX(offset) (CVMX_ADD_IO_SEG(0x0001010000030000ull) + ((offset) & 63) * 8)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_CIU3_PP_RST CVMX_CIU3_PP_RST_FUNC()
-static inline uint64_t CVMX_CIU3_PP_RST_FUNC(void)
-{
-	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_CIU3_PP_RST not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001010000000100ull);
-}
-#else
-#define CVMX_CIU3_PP_RST (CVMX_ADD_IO_SEG(0x0001010000000100ull))
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-#define CVMX_CIU3_PP_RST_PENDING CVMX_CIU3_PP_RST_PENDING_FUNC()
-static inline uint64_t CVMX_CIU3_PP_RST_PENDING_FUNC(void)
-{
-	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
-		cvmx_warn("CVMX_CIU3_PP_RST_PENDING not supported on this chip\n");
-	return CVMX_ADD_IO_SEG(0x0001010000000110ull);
-}
-#else
-#define CVMX_CIU3_PP_RST_PENDING (CVMX_ADD_IO_SEG(0x0001010000000110ull))
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_CIU3_SISCX(unsigned long offset)
 {
 	if (!(
@@ -338,17 +272,6 @@ static inline uint64_t CVMX_CIU3_TIMX(unsigned long offset)
 #else
 #define CVMX_CIU3_TIMX(offset) (CVMX_ADD_IO_SEG(0x0001010000010000ull) + ((offset) & 15) * 8)
 #endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_CIU3_WDOGX(unsigned long offset)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 47)))))
-		cvmx_warn("CVMX_CIU3_WDOGX(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001010000020000ull) + ((offset) & 63) * 8;
-}
-#else
-#define CVMX_CIU3_WDOGX(offset) (CVMX_ADD_IO_SEG(0x0001010000020000ull) + ((offset) & 63) * 8)
-#endif
 
 /**
  * cvmx_ciu3_bist
@@ -414,7 +337,7 @@ union cvmx_ciu3_ctl {
                                                          0x1 = MCD1.
                                                          0x2 = MCD2.
                                                          0x3 = Reserved. */
-	uint64_t iscmem_le                    : 1;  /**< CIU3_ISCMEM_BASE points to a little-endian table. */
+	uint64_t iscmem_le                    : 1;  /**< Reserved. */
 	uint64_t seq_dis                      : 1;  /**< Disable running sequencer only when required to reduce power, and run continuously. For
                                                          diagnostic use only. */
 	uint64_t cclk_dis                     : 1;  /**< Disable power saving conditional clocking. */
@@ -495,42 +418,6 @@ union cvmx_ciu3_destx_pp_int {
 typedef union cvmx_ciu3_destx_pp_int cvmx_ciu3_destx_pp_int_t;
 
 /**
- * cvmx_ciu3_dint
- */
-union cvmx_ciu3_dint {
-	uint64_t u64;
-	struct cvmx_ciu3_dint_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t dint                         : 48; /**< Writing a 1 to a bit sends a DINT pulse to corresponding core vector. */
-#else
-	uint64_t dint                         : 48;
-	uint64_t reserved_48_63               : 16;
-#endif
-	} s;
-	struct cvmx_ciu3_dint_s               cn78xx;
-};
-typedef union cvmx_ciu3_dint cvmx_ciu3_dint_t;
-
-/**
- * cvmx_ciu3_fuse
- */
-union cvmx_ciu3_fuse {
-	uint64_t u64;
-	struct cvmx_ciu3_fuse_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t fuse                         : 48; /**< Each bit set indicates a physical core is present. */
-#else
-	uint64_t fuse                         : 48;
-	uint64_t reserved_48_63               : 16;
-#endif
-	} s;
-	struct cvmx_ciu3_fuse_s               cn78xx;
-};
-typedef union cvmx_ciu3_fuse cvmx_ciu3_fuse_t;
-
-/**
  * cvmx_ciu3_gstop
  */
 union cvmx_ciu3_gstop {
@@ -756,7 +643,8 @@ union cvmx_ciu3_iscx_ctl {
 	uint64_t reserved_3_13                : 11;
 	uint64_t sso                          : 1;  /**< Reserved. INTERNAL: Deprecated. Use SSO delivery. */
 	uint64_t en                           : 1;  /**< Enable interrupt delivery. */
-	uint64_t raw                          : 1;  /**< Interrupt pending before masking. Note read only, must use CIU3_ISC(0..1048575)_W1C/_W1S to toggle. */
+	uint64_t raw                          : 1;  /**< Interrupt pending before masking. Note read only, must use
+                                                         CIU3_ISC(0..1048575)_W1C/CIU3_ISC(0..1048575)_W1S to toggle. */
 #else
 	uint64_t raw                          : 1;
 	uint64_t en                           : 1;
@@ -818,6 +706,9 @@ typedef union cvmx_ciu3_iscx_w1s cvmx_ciu3_iscx_w1s_t;
 
 /**
  * cvmx_ciu3_iscmem_base
+ *
+ * Deprecated.
+ *
  */
 union cvmx_ciu3_iscmem_base {
 	uint64_t u64;
@@ -857,96 +748,6 @@ union cvmx_ciu3_nmi {
 typedef union cvmx_ciu3_nmi cvmx_ciu3_nmi_t;
 
 /**
- * cvmx_ciu3_pp_dbg
- */
-union cvmx_ciu3_pp_dbg {
-	uint64_t u64;
-	struct cvmx_ciu3_pp_dbg_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t ppdbg                        : 48; /**< Debug[DM] value for each core, whether the cores are in debug mode or not. */
-#else
-	uint64_t ppdbg                        : 48;
-	uint64_t reserved_48_63               : 16;
-#endif
-	} s;
-	struct cvmx_ciu3_pp_dbg_s             cn78xx;
-};
-typedef union cvmx_ciu3_pp_dbg cvmx_ciu3_pp_dbg_t;
-
-/**
- * cvmx_ciu3_pp_poke#
- */
-union cvmx_ciu3_pp_pokex {
-	uint64_t u64;
-	struct cvmx_ciu3_pp_pokex_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_1_63                : 63;
-	uint64_t poke                         : 1;  /**< Core poke. Writing any value to this register does the following:
-                                                         clears any pending interrupt generated by the associated watchdog
-                                                         resets CIU3_WDOG(0..47)[STATE] to 0x0
-                                                         sets CIU3_WDOG(0..47)[CNT] to ( CIU3_WDOG(0..47)[LEN] << 8).
-                                                         Reading this register returns the associated CIU3_WDOG(0..47) register. */
-#else
-	uint64_t poke                         : 1;
-	uint64_t reserved_1_63                : 63;
-#endif
-	} s;
-	struct cvmx_ciu3_pp_pokex_s           cn78xx;
-};
-typedef union cvmx_ciu3_pp_pokex cvmx_ciu3_pp_pokex_t;
-
-/**
- * cvmx_ciu3_pp_rst
- *
- * This register contains the reset control for each core. A 1 holds a core in reset, 0 release
- * from reset. It resets to all ones when REMOTE_BOOT is enabled or all ones excluding bit 0 when
- * REMOTE_BOOT is disabled. Writes to this register should occur only if the CIU3_PP_RST_PENDING
- * register is cleared.
- */
-union cvmx_ciu3_pp_rst {
-	uint64_t u64;
-	struct cvmx_ciu3_pp_rst_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t rst                          : 47; /**< Core reset for cores 1 and above. Writing a 1 holds the corresponding core in reset,
-                                                         writing a 0 releases from reset. */
-	uint64_t rst0                         : 1;  /**< Core reset for core 0, depends on standalone mode. */
-#else
-	uint64_t rst0                         : 1;
-	uint64_t rst                          : 47;
-	uint64_t reserved_48_63               : 16;
-#endif
-	} s;
-	struct cvmx_ciu3_pp_rst_s             cn78xx;
-};
-typedef union cvmx_ciu3_pp_rst cvmx_ciu3_pp_rst_t;
-
-/**
- * cvmx_ciu3_pp_rst_pending
- *
- * This register contains the reset status for each core.
- *
- */
-union cvmx_ciu3_pp_rst_pending {
-	uint64_t u64;
-	struct cvmx_ciu3_pp_rst_pending_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
-	uint64_t pend                         : 48; /**< Set if corresponding core is waiting to change its reset state. Normally a reset change
-                                                         occurs immediately but if RST_PP_POWER[GATE] bit is set and the core is released from
-                                                         reset a delay of 64K core clocks between each core reset will apply to satisfy power
-                                                         management. */
-#else
-	uint64_t pend                         : 48;
-	uint64_t reserved_48_63               : 16;
-#endif
-	} s;
-	struct cvmx_ciu3_pp_rst_pending_s     cn78xx;
-};
-typedef union cvmx_ciu3_pp_rst_pending cvmx_ciu3_pp_rst_pending_t;
-
-/**
  * cvmx_ciu3_sisc#
  */
 union cvmx_ciu3_siscx {
@@ -985,39 +786,4 @@ union cvmx_ciu3_timx {
 };
 typedef union cvmx_ciu3_timx cvmx_ciu3_timx_t;
 
-/**
- * cvmx_ciu3_wdog#
- */
-union cvmx_ciu3_wdogx {
-	uint64_t u64;
-	struct cvmx_ciu3_wdogx_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_46_63               : 18;
-	uint64_t gstopen                      : 1;  /**< Global-stop enable. */
-	uint64_t dstop                        : 1;  /**< Debug-stop enable. */
-	uint64_t cnt                          : 24; /**< Number of 1024-cycle intervals until next watchdog expiration. Cleared on write to
-                                                         associated CIU3_PP_POKE(0..47) register. */
-	uint64_t len                          : 16; /**< Watchdog time-expiration length. The most-significant 16 bits of a 24-bit decrementer that
-                                                         decrements every 1024 cycles. Must be set > 0. */
-	uint64_t state                        : 2;  /**< Watchdog state. The number of watchdog time expirations since last core poke. Cleared on
-                                                         write to associated CIU3_PP_POKE(0..47) register. */
-	uint64_t mode                         : 2;  /**< Watchdog mode:
-                                                         0x0 = Off.
-                                                         0x1 = Interrupt only.
-                                                         0x2 = Interrupt + NMI.
-                                                         0x3 = Interrupt + NMI + soft reset. */
-#else
-	uint64_t mode                         : 2;
-	uint64_t state                        : 2;
-	uint64_t len                          : 16;
-	uint64_t cnt                          : 24;
-	uint64_t dstop                        : 1;
-	uint64_t gstopen                      : 1;
-	uint64_t reserved_46_63               : 18;
-#endif
-	} s;
-	struct cvmx_ciu3_wdogx_s              cn78xx;
-};
-typedef union cvmx_ciu3_wdogx cvmx_ciu3_wdogx_t;
-
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-clock.h b/arch/mips/include/asm/octeon/cvmx-clock.h
index 240c7e5..e3033dd 100644
--- a/arch/mips/include/asm/octeon/cvmx-clock.h
+++ b/arch/mips/include/asm/octeon/cvmx-clock.h
@@ -144,6 +144,7 @@ static inline uint64_t cvmx_clock_get_rate(cvmx_clock_t clock)
 		return 0;
 	}
 }
+#define cvmx_clock_get_rate_node(a,b) cvmx_clock_get_rate(b)
 #else
 extern uint64_t cvmx_clock_get_rate(cvmx_clock_t clock);
 extern uint64_t cvmx_clock_get_rate_node(int node, cvmx_clock_t clock);
diff --git a/arch/mips/include/asm/octeon/cvmx-cmd-queue.h b/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
index b7d938e..8e8083f0 100644
--- a/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
+++ b/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
@@ -82,7 +82,7 @@
  * internal cycle counter to completely eliminate any causes of
  * bus traffic.
  *
- * <hr> $Revision: 95258 $ <hr>
+ * <hr> $Revision: 95726 $ <hr>
  */
 
 #ifndef __CVMX_CMD_QUEUE_H__
@@ -334,7 +334,7 @@ static inline uint64_t *__cvmx_cmd_queue_alloc_buffer(int pool)
 {
 	uint64_t *new_buffer;
 	if (octeon_has_feature(OCTEON_FEATURE_FPA3))
-		new_buffer = cvmx_fpa_alloc_aura(0, pool);
+		new_buffer = cvmx_fpa3_alloc_aura(0, pool);
 	else
 		new_buffer = cvmx_fpa1_alloc(pool);
 	return new_buffer;
diff --git a/arch/mips/include/asm/octeon/cvmx-dbg-defs.h b/arch/mips/include/asm/octeon/cvmx-dbg-defs.h
index 2edabc2..0352b2b 100644
--- a/arch/mips/include/asm/octeon/cvmx-dbg-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-dbg-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
index d75cddb..69c32aa 100644
--- a/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-dpi-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -645,6 +645,7 @@ union cvmx_dpi_bist_status {
 	struct cvmx_dpi_bist_status_cn63xx    cn68xx;
 	struct cvmx_dpi_bist_status_cn63xx    cn68xxp1;
 	struct cvmx_dpi_bist_status_cn61xx    cn70xx;
+	struct cvmx_dpi_bist_status_cn61xx    cn70xxp1;
 	struct cvmx_dpi_bist_status_s         cn78xx;
 	struct cvmx_dpi_bist_status_cn61xx    cnf71xx;
 };
@@ -684,6 +685,7 @@ union cvmx_dpi_ctl {
 	struct cvmx_dpi_ctl_s                 cn68xx;
 	struct cvmx_dpi_ctl_s                 cn68xxp1;
 	struct cvmx_dpi_ctl_cn61xx            cn70xx;
+	struct cvmx_dpi_ctl_cn61xx            cn70xxp1;
 	struct cvmx_dpi_ctl_cn61xx            cn78xx;
 	struct cvmx_dpi_ctl_cn61xx            cnf71xx;
 };
@@ -716,6 +718,7 @@ union cvmx_dpi_dmax_counts {
 	struct cvmx_dpi_dmax_counts_s         cn68xx;
 	struct cvmx_dpi_dmax_counts_s         cn68xxp1;
 	struct cvmx_dpi_dmax_counts_s         cn70xx;
+	struct cvmx_dpi_dmax_counts_s         cn70xxp1;
 	struct cvmx_dpi_dmax_counts_s         cn78xx;
 	struct cvmx_dpi_dmax_counts_s         cnf71xx;
 };
@@ -747,6 +750,7 @@ union cvmx_dpi_dmax_dbell {
 	struct cvmx_dpi_dmax_dbell_s          cn68xx;
 	struct cvmx_dpi_dmax_dbell_s          cn68xxp1;
 	struct cvmx_dpi_dmax_dbell_s          cn70xx;
+	struct cvmx_dpi_dmax_dbell_s          cn70xxp1;
 	struct cvmx_dpi_dmax_dbell_s          cn78xx;
 	struct cvmx_dpi_dmax_dbell_s          cnf71xx;
 };
@@ -778,6 +782,7 @@ union cvmx_dpi_dmax_err_rsp_status {
 	struct cvmx_dpi_dmax_err_rsp_status_s cn68xx;
 	struct cvmx_dpi_dmax_err_rsp_status_s cn68xxp1;
 	struct cvmx_dpi_dmax_err_rsp_status_s cn70xx;
+	struct cvmx_dpi_dmax_err_rsp_status_s cn70xxp1;
 	struct cvmx_dpi_dmax_err_rsp_status_s cn78xx;
 	struct cvmx_dpi_dmax_err_rsp_status_s cnf71xx;
 };
@@ -866,6 +871,7 @@ union cvmx_dpi_dmax_ibuff_saddr {
 	} cn68xx;
 	struct cvmx_dpi_dmax_ibuff_saddr_cn68xx cn68xxp1;
 	struct cvmx_dpi_dmax_ibuff_saddr_cn61xx cn70xx;
+	struct cvmx_dpi_dmax_ibuff_saddr_cn61xx cn70xxp1;
 	struct cvmx_dpi_dmax_ibuff_saddr_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t idle                         : 1;  /**< DMA request queue is idle. When asserted, the associated request queue is idle. */
@@ -914,6 +920,7 @@ union cvmx_dpi_dmax_iflight {
 	struct cvmx_dpi_dmax_iflight_s        cn68xx;
 	struct cvmx_dpi_dmax_iflight_s        cn68xxp1;
 	struct cvmx_dpi_dmax_iflight_s        cn70xx;
+	struct cvmx_dpi_dmax_iflight_s        cn70xxp1;
 	struct cvmx_dpi_dmax_iflight_s        cn78xx;
 	struct cvmx_dpi_dmax_iflight_s        cnf71xx;
 };
@@ -962,6 +969,7 @@ union cvmx_dpi_dmax_naddr {
 	} cn68xx;
 	struct cvmx_dpi_dmax_naddr_cn68xx     cn68xxp1;
 	struct cvmx_dpi_dmax_naddr_cn61xx     cn70xx;
+	struct cvmx_dpi_dmax_naddr_cn61xx     cn70xxp1;
 	struct cvmx_dpi_dmax_naddr_s          cn78xx;
 	struct cvmx_dpi_dmax_naddr_cn61xx     cnf71xx;
 };
@@ -989,6 +997,7 @@ union cvmx_dpi_dmax_reqbnk0 {
 	struct cvmx_dpi_dmax_reqbnk0_s        cn68xx;
 	struct cvmx_dpi_dmax_reqbnk0_s        cn68xxp1;
 	struct cvmx_dpi_dmax_reqbnk0_s        cn70xx;
+	struct cvmx_dpi_dmax_reqbnk0_s        cn70xxp1;
 	struct cvmx_dpi_dmax_reqbnk0_s        cn78xx;
 	struct cvmx_dpi_dmax_reqbnk0_s        cnf71xx;
 };
@@ -1016,6 +1025,7 @@ union cvmx_dpi_dmax_reqbnk1 {
 	struct cvmx_dpi_dmax_reqbnk1_s        cn68xx;
 	struct cvmx_dpi_dmax_reqbnk1_s        cn68xxp1;
 	struct cvmx_dpi_dmax_reqbnk1_s        cn70xx;
+	struct cvmx_dpi_dmax_reqbnk1_s        cn70xxp1;
 	struct cvmx_dpi_dmax_reqbnk1_s        cn78xx;
 	struct cvmx_dpi_dmax_reqbnk1_s        cnf71xx;
 };
@@ -1438,6 +1448,7 @@ union cvmx_dpi_dma_control {
 	struct cvmx_dpi_dma_control_cn61xx    cn68xx;
 	struct cvmx_dpi_dma_control_cn63xx    cn68xxp1;
 	struct cvmx_dpi_dma_control_cn61xx    cn70xx;
+	struct cvmx_dpi_dma_control_cn61xx    cn70xxp1;
 	struct cvmx_dpi_dma_control_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
@@ -1539,6 +1550,7 @@ union cvmx_dpi_dma_engx_en {
 	struct cvmx_dpi_dma_engx_en_s         cn68xx;
 	struct cvmx_dpi_dma_engx_en_s         cn68xxp1;
 	struct cvmx_dpi_dma_engx_en_s         cn70xx;
+	struct cvmx_dpi_dma_engx_en_s         cn70xxp1;
 	struct cvmx_dpi_dma_engx_en_s         cn78xx;
 	struct cvmx_dpi_dma_engx_en_s         cnf71xx;
 };
@@ -1572,6 +1584,7 @@ union cvmx_dpi_dma_ppx_cnt {
 	struct cvmx_dpi_dma_ppx_cnt_s         cn61xx;
 	struct cvmx_dpi_dma_ppx_cnt_s         cn68xx;
 	struct cvmx_dpi_dma_ppx_cnt_s         cn70xx;
+	struct cvmx_dpi_dma_ppx_cnt_s         cn70xxp1;
 	struct cvmx_dpi_dma_ppx_cnt_s         cn78xx;
 	struct cvmx_dpi_dma_ppx_cnt_s         cnf71xx;
 };
@@ -1716,6 +1729,7 @@ union cvmx_dpi_engx_buf {
 	struct cvmx_dpi_engx_buf_s            cn68xx;
 	struct cvmx_dpi_engx_buf_s            cn68xxp1;
 	struct cvmx_dpi_engx_buf_s            cn70xx;
+	struct cvmx_dpi_engx_buf_s            cn70xxp1;
 	struct cvmx_dpi_engx_buf_s            cn78xx;
 	struct cvmx_dpi_engx_buf_s            cnf71xx;
 };
@@ -1770,6 +1784,7 @@ union cvmx_dpi_info_reg {
 	struct cvmx_dpi_info_reg_s            cn68xx;
 	struct cvmx_dpi_info_reg_s            cn68xxp1;
 	struct cvmx_dpi_info_reg_s            cn70xx;
+	struct cvmx_dpi_info_reg_s            cn70xxp1;
 	struct cvmx_dpi_info_reg_s            cn78xx;
 	struct cvmx_dpi_info_reg_s            cnf71xx;
 };
@@ -1872,6 +1887,7 @@ union cvmx_dpi_int_en {
 	struct cvmx_dpi_int_en_cn63xx         cn68xx;
 	struct cvmx_dpi_int_en_cn63xx         cn68xxp1;
 	struct cvmx_dpi_int_en_s              cn70xx;
+	struct cvmx_dpi_int_en_s              cn70xxp1;
 	struct cvmx_dpi_int_en_s              cnf71xx;
 };
 typedef union cvmx_dpi_int_en cvmx_dpi_int_en_t;
@@ -2014,6 +2030,7 @@ union cvmx_dpi_int_reg {
 	struct cvmx_dpi_int_reg_cn63xx        cn68xx;
 	struct cvmx_dpi_int_reg_cn63xx        cn68xxp1;
 	struct cvmx_dpi_int_reg_s             cn70xx;
+	struct cvmx_dpi_int_reg_s             cn70xxp1;
 	struct cvmx_dpi_int_reg_s             cn78xx;
 	struct cvmx_dpi_int_reg_s             cnf71xx;
 };
@@ -2042,6 +2059,7 @@ union cvmx_dpi_ncbx_cfg {
 	struct cvmx_dpi_ncbx_cfg_s            cn66xx;
 	struct cvmx_dpi_ncbx_cfg_s            cn68xx;
 	struct cvmx_dpi_ncbx_cfg_s            cn70xx;
+	struct cvmx_dpi_ncbx_cfg_s            cn70xxp1;
 	struct cvmx_dpi_ncbx_cfg_s            cn78xx;
 	struct cvmx_dpi_ncbx_cfg_s            cnf71xx;
 };
@@ -2096,6 +2114,7 @@ union cvmx_dpi_pint_info {
 	struct cvmx_dpi_pint_info_s           cn68xx;
 	struct cvmx_dpi_pint_info_s           cn68xxp1;
 	struct cvmx_dpi_pint_info_s           cn70xx;
+	struct cvmx_dpi_pint_info_s           cn70xxp1;
 	struct cvmx_dpi_pint_info_s           cn78xx;
 	struct cvmx_dpi_pint_info_s           cnf71xx;
 };
@@ -2123,6 +2142,7 @@ union cvmx_dpi_pkt_err_rsp {
 	struct cvmx_dpi_pkt_err_rsp_s         cn68xx;
 	struct cvmx_dpi_pkt_err_rsp_s         cn68xxp1;
 	struct cvmx_dpi_pkt_err_rsp_s         cn70xx;
+	struct cvmx_dpi_pkt_err_rsp_s         cn70xxp1;
 	struct cvmx_dpi_pkt_err_rsp_s         cn78xx;
 	struct cvmx_dpi_pkt_err_rsp_s         cnf71xx;
 };
@@ -2153,6 +2173,7 @@ union cvmx_dpi_req_err_rsp {
 	struct cvmx_dpi_req_err_rsp_s         cn68xx;
 	struct cvmx_dpi_req_err_rsp_s         cn68xxp1;
 	struct cvmx_dpi_req_err_rsp_s         cn70xx;
+	struct cvmx_dpi_req_err_rsp_s         cn70xxp1;
 	struct cvmx_dpi_req_err_rsp_s         cn78xx;
 	struct cvmx_dpi_req_err_rsp_s         cnf71xx;
 };
@@ -2181,6 +2202,7 @@ union cvmx_dpi_req_err_rsp_en {
 	struct cvmx_dpi_req_err_rsp_en_s      cn68xx;
 	struct cvmx_dpi_req_err_rsp_en_s      cn68xxp1;
 	struct cvmx_dpi_req_err_rsp_en_s      cn70xx;
+	struct cvmx_dpi_req_err_rsp_en_s      cn70xxp1;
 	struct cvmx_dpi_req_err_rsp_en_s      cn78xx;
 	struct cvmx_dpi_req_err_rsp_en_s      cnf71xx;
 };
@@ -2212,6 +2234,7 @@ union cvmx_dpi_req_err_rst {
 	struct cvmx_dpi_req_err_rst_s         cn68xx;
 	struct cvmx_dpi_req_err_rst_s         cn68xxp1;
 	struct cvmx_dpi_req_err_rst_s         cn70xx;
+	struct cvmx_dpi_req_err_rst_s         cn70xxp1;
 	struct cvmx_dpi_req_err_rst_s         cn78xx;
 	struct cvmx_dpi_req_err_rst_s         cnf71xx;
 };
@@ -2241,6 +2264,7 @@ union cvmx_dpi_req_err_rst_en {
 	struct cvmx_dpi_req_err_rst_en_s      cn68xx;
 	struct cvmx_dpi_req_err_rst_en_s      cn68xxp1;
 	struct cvmx_dpi_req_err_rst_en_s      cn70xx;
+	struct cvmx_dpi_req_err_rst_en_s      cn70xxp1;
 	struct cvmx_dpi_req_err_rst_en_s      cn78xx;
 	struct cvmx_dpi_req_err_rst_en_s      cnf71xx;
 };
@@ -2283,6 +2307,7 @@ union cvmx_dpi_req_err_skip_comp {
 	struct cvmx_dpi_req_err_skip_comp_s   cn68xx;
 	struct cvmx_dpi_req_err_skip_comp_s   cn68xxp1;
 	struct cvmx_dpi_req_err_skip_comp_s   cn70xx;
+	struct cvmx_dpi_req_err_skip_comp_s   cn70xxp1;
 	struct cvmx_dpi_req_err_skip_comp_s   cn78xx;
 	struct cvmx_dpi_req_err_skip_comp_s   cnf71xx;
 };
@@ -2310,6 +2335,7 @@ union cvmx_dpi_req_gbl_en {
 	struct cvmx_dpi_req_gbl_en_s          cn68xx;
 	struct cvmx_dpi_req_gbl_en_s          cn68xxp1;
 	struct cvmx_dpi_req_gbl_en_s          cn70xx;
+	struct cvmx_dpi_req_gbl_en_s          cn70xxp1;
 	struct cvmx_dpi_req_gbl_en_s          cn78xx;
 	struct cvmx_dpi_req_gbl_en_s          cnf71xx;
 };
@@ -2613,6 +2639,7 @@ union cvmx_dpi_sli_prtx_cfg {
 	uint64_t reserved_25_63               : 39;
 #endif
 	} cn70xx;
+	struct cvmx_dpi_sli_prtx_cfg_cn70xx   cn70xxp1;
 	struct cvmx_dpi_sli_prtx_cfg_cn63xx   cn78xx;
 	struct cvmx_dpi_sli_prtx_cfg_s        cnf71xx;
 };
@@ -2646,6 +2673,7 @@ union cvmx_dpi_sli_prtx_err {
 	struct cvmx_dpi_sli_prtx_err_s        cn68xx;
 	struct cvmx_dpi_sli_prtx_err_s        cn68xxp1;
 	struct cvmx_dpi_sli_prtx_err_s        cn70xx;
+	struct cvmx_dpi_sli_prtx_err_s        cn70xxp1;
 	struct cvmx_dpi_sli_prtx_err_s        cn78xx;
 	struct cvmx_dpi_sli_prtx_err_s        cnf71xx;
 };
@@ -2739,6 +2767,7 @@ union cvmx_dpi_sli_prtx_err_info {
 	struct cvmx_dpi_sli_prtx_err_info_cn61xx cn68xx;
 	struct cvmx_dpi_sli_prtx_err_info_cn61xx cn68xxp1;
 	struct cvmx_dpi_sli_prtx_err_info_cn61xx cn70xx;
+	struct cvmx_dpi_sli_prtx_err_info_cn61xx cn70xxp1;
 	struct cvmx_dpi_sli_prtx_err_info_s   cn78xx;
 	struct cvmx_dpi_sli_prtx_err_info_cn61xx cnf71xx;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa-defs.h b/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
index 015fb2f..2f0e683 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -197,11 +197,11 @@ static inline uint64_t CVMX_FPA_BIST_STATUS_FUNC(void)
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
@@ -224,11 +224,11 @@ static inline uint64_t CVMX_FPA_BIST_STATUS_FUNC(void)
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
@@ -782,6 +782,7 @@ union cvmx_fpa_addr_range_error {
 	struct cvmx_fpa_addr_range_error_cn61xx cn68xx;
 	struct cvmx_fpa_addr_range_error_cn61xx cn68xxp1;
 	struct cvmx_fpa_addr_range_error_cn61xx cn70xx;
+	struct cvmx_fpa_addr_range_error_cn61xx cn70xxp1;
 	struct cvmx_fpa_addr_range_error_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_54_63               : 10;
@@ -867,7 +868,8 @@ union cvmx_fpa_aurax_cnt_add {
 	uint64_t reserved_40_63               : 24;
 	uint64_t cnt                          : 40; /**< The value to be added to FPA_AURA(0..1023)_CNT. The value may alternatively be a 2's
                                                          complement of a value to be subtracted. Subtraction or addition that results in overflow
-                                                         will zero the count, not roll-around. See Aura Quality of Service. */
+                                                         will zero the count, not roll-around, and set either FPA_ERR_INT[CNT_ADD] or
+                                                         FPA_ERR_INT[CNT_SUB]. */
 #else
 	uint64_t cnt                          : 40;
 	uint64_t reserved_40_63               : 24;
@@ -889,7 +891,7 @@ union cvmx_fpa_aurax_cnt_levels {
                                                          PKI_AURA(0..1023)_CFG[ENA_BP] must also be set for backpressure to propagate through PKI. */
 	uint64_t red_ena                      : 1;  /**< Enable RED based on [DROP] and [PASS] levels. If set FPA_GEN_CFG[LVL_DLY] must be nonzero.
                                                          If set, RED is performed on core requests with FPA_ALLOC_LD_S[RED] set, and/or PKI
-                                                         requests if PKI_AURA(0..1023)_CFG[ENA_BP] is set. */
+                                                         requests if PKI_AURA(0..1023)_CFG[ENA_RED] is set. */
 	uint64_t shift                        : 6;  /**< Right shift to apply to FPA_AURA(0..1023)_CNT to result in a 8-bit relative depth to be
                                                          used for [DROP/PASS/LEVEL]. See Aura Counts. */
 	uint64_t bp                           : 8;  /**< Backpressure will be applied if the immediate shifted level is equal to or greater than this value. */
@@ -1076,6 +1078,7 @@ union cvmx_fpa_bist_status {
 	struct cvmx_fpa_bist_status_cn30xx    cn68xx;
 	struct cvmx_fpa_bist_status_cn30xx    cn68xxp1;
 	struct cvmx_fpa_bist_status_cn30xx    cn70xx;
+	struct cvmx_fpa_bist_status_cn30xx    cn70xxp1;
 	struct cvmx_fpa_bist_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_38_63               : 26;
@@ -1199,6 +1202,7 @@ union cvmx_fpa_ctl_status {
 	struct cvmx_fpa_ctl_status_s          cn68xx;
 	struct cvmx_fpa_ctl_status_s          cn68xxp1;
 	struct cvmx_fpa_ctl_status_s          cn70xx;
+	struct cvmx_fpa_ctl_status_s          cn70xxp1;
 	struct cvmx_fpa_ctl_status_s          cnf71xx;
 };
 typedef union cvmx_fpa_ctl_status cvmx_fpa_ctl_status_t;
@@ -1272,14 +1276,14 @@ union cvmx_fpa_err_int {
 	struct cvmx_fpa_err_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t hw_sub                       : 1;  /**< Set when hardware does a subtract to the count that causes the counter to wrap. Throws
+	uint64_t hw_sub                       : 1;  /**< Set when hardware does a subtract to the count that caused the counter to wrap. Throws
                                                          FPA_INTSN_E::FPA_ERR_HW_SUB. */
-	uint64_t hw_add                       : 1;  /**< Set when hardware does an add to the count that causes the counter to wrap. Throws
+	uint64_t hw_add                       : 1;  /**< Set when hardware does an add to the count that caused the counter to wrap. Throws
                                                          FPA_INTSN_E::FPA_ERR_HW_ADD. */
-	uint64_t cnt_sub                      : 1;  /**< Set when a write to FPA_AURA(0..1023)_CNT_ADD does a subtract to the count that causes the
-                                                         counter to wrap. Throws FPA_INTSN_E::FPA_ERR_CNT_SUB. */
-	uint64_t cnt_add                      : 1;  /**< Set when a write to FPA_AURA(0..1023)_CNT_ADD does an add to the count that causes the
-                                                         counter to wrap. Throws FPA_INTSN_E::FPA_ERR_CNT_ADD. */
+	uint64_t cnt_sub                      : 1;  /**< Set when a write to FPA_AURA(0..1023)_CNT_ADD does a subtract to the count that would have
+                                                         caused the counter to wrap, so the count was zeroed. Throws FPA_INTSN_E::FPA_ERR_CNT_SUB. */
+	uint64_t cnt_add                      : 1;  /**< Set when a write to FPA_AURA(0..1023)_CNT_ADD does an add to the count that would have
+                                                         caused the counter to wrap, so the count was zeroed. Throws FPA_INTSN_E::FPA_ERR_CNT_ADD. */
 #else
 	uint64_t cnt_add                      : 1;
 	uint64_t cnt_sub                      : 1;
@@ -1337,6 +1341,7 @@ union cvmx_fpa_fpfx_marks {
 	struct cvmx_fpa_fpfx_marks_s          cn68xx;
 	struct cvmx_fpa_fpfx_marks_s          cn68xxp1;
 	struct cvmx_fpa_fpfx_marks_s          cn70xx;
+	struct cvmx_fpa_fpfx_marks_s          cn70xxp1;
 	struct cvmx_fpa_fpfx_marks_s          cnf71xx;
 };
 typedef union cvmx_fpa_fpfx_marks cvmx_fpa_fpfx_marks_t;
@@ -1383,6 +1388,7 @@ union cvmx_fpa_fpfx_size {
 	struct cvmx_fpa_fpfx_size_s           cn68xx;
 	struct cvmx_fpa_fpfx_size_s           cn68xxp1;
 	struct cvmx_fpa_fpfx_size_s           cn70xx;
+	struct cvmx_fpa_fpfx_size_s           cn70xxp1;
 	struct cvmx_fpa_fpfx_size_s           cnf71xx;
 };
 typedef union cvmx_fpa_fpfx_size cvmx_fpa_fpfx_size_t;
@@ -1432,6 +1438,7 @@ union cvmx_fpa_fpf0_marks {
 	struct cvmx_fpa_fpf0_marks_s          cn68xx;
 	struct cvmx_fpa_fpf0_marks_s          cn68xxp1;
 	struct cvmx_fpa_fpf0_marks_s          cn70xx;
+	struct cvmx_fpa_fpf0_marks_s          cn70xxp1;
 	struct cvmx_fpa_fpf0_marks_s          cnf71xx;
 };
 typedef union cvmx_fpa_fpf0_marks cvmx_fpa_fpf0_marks_t;
@@ -1477,6 +1484,7 @@ union cvmx_fpa_fpf0_size {
 	struct cvmx_fpa_fpf0_size_s           cn68xx;
 	struct cvmx_fpa_fpf0_size_s           cn68xxp1;
 	struct cvmx_fpa_fpf0_size_s           cn70xx;
+	struct cvmx_fpa_fpf0_size_s           cn70xxp1;
 	struct cvmx_fpa_fpf0_size_s           cnf71xx;
 };
 typedef union cvmx_fpa_fpf0_size cvmx_fpa_fpf0_size_t;
@@ -2507,6 +2515,7 @@ union cvmx_fpa_int_enb {
 	} cn68xx;
 	struct cvmx_fpa_int_enb_cn68xx        cn68xxp1;
 	struct cvmx_fpa_int_enb_cn61xx        cn70xx;
+	struct cvmx_fpa_int_enb_cn61xx        cn70xxp1;
 	struct cvmx_fpa_int_enb_cn61xx        cnf71xx;
 };
 typedef union cvmx_fpa_int_enb cvmx_fpa_int_enb_t;
@@ -3084,6 +3093,7 @@ union cvmx_fpa_int_sum {
 	struct cvmx_fpa_int_sum_s             cn68xx;
 	struct cvmx_fpa_int_sum_s             cn68xxp1;
 	struct cvmx_fpa_int_sum_cn61xx        cn70xx;
+	struct cvmx_fpa_int_sum_cn61xx        cn70xxp1;
 	struct cvmx_fpa_int_sum_cn61xx        cnf71xx;
 };
 typedef union cvmx_fpa_int_sum cvmx_fpa_int_sum_t;
@@ -3114,6 +3124,7 @@ union cvmx_fpa_packet_threshold {
 	struct cvmx_fpa_packet_threshold_s    cn68xx;
 	struct cvmx_fpa_packet_threshold_s    cn68xxp1;
 	struct cvmx_fpa_packet_threshold_s    cn70xx;
+	struct cvmx_fpa_packet_threshold_s    cn70xxp1;
 	struct cvmx_fpa_packet_threshold_s    cnf71xx;
 };
 typedef union cvmx_fpa_packet_threshold cvmx_fpa_packet_threshold_t;
@@ -3145,10 +3156,17 @@ union cvmx_fpa_poolx_cfg {
 	struct cvmx_fpa_poolx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_43_63               : 21;
-	uint64_t buf_size                     : 11; /**< Buffer size in cache lines. Only required if [NAT_ALIGN] is set. */
+	uint64_t buf_size                     : 11; /**< Buffer size in 128-byte cache lines. Must be zero if [NAT_ALIGN] is clear. Buffer sizes
+                                                         are supported that are any multiple of 128 bytes in the range of 128 bytes to 128 KB. */
 	uint64_t reserved_31_31               : 1;
-	uint64_t buf_offset                   : 15; /**< Number of cache lines to adjust returning pointers by. This field is sign extended so that
-                                                         two's complement numbers may be used to do subtractions. See Buffer Alignment. */
+	uint64_t buf_offset                   : 15; /**< Number of 128-byte cache lines to offset the stored pointer. This field is sign extended
+                                                         so that two's complement numbers may be used to do subtractions.
+                                                         If [NAT_ALIGN] is clear, the pointer stored in the pool is normally the freed pointer
+                                                         adjusted by [BUF_OFFSET]. [BUF_OFFSET] will normally be zero or negative to adjust the
+                                                         pointer back to the beginning of the buffer.)
+                                                         If [NAT_ALIGN] is set, the pointer stored in the pool is normally [BUF_OFFSET] from the
+                                                         beginning of the buffer. [BUF_OFFSET] will normally be zero or positive to adjust the
+                                                         pointer into the buffer. */
 	uint64_t reserved_5_15                : 11;
 	uint64_t l_type                       : 2;  /**< Type of load to send to L2.
                                                          0x0 = LDD.
@@ -3207,6 +3225,7 @@ union cvmx_fpa_poolx_end_addr {
 	struct cvmx_fpa_poolx_end_addr_cn61xx cn68xx;
 	struct cvmx_fpa_poolx_end_addr_cn61xx cn68xxp1;
 	struct cvmx_fpa_poolx_end_addr_cn61xx cn70xx;
+	struct cvmx_fpa_poolx_end_addr_cn61xx cn70xxp1;
 	struct cvmx_fpa_poolx_end_addr_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
@@ -3395,6 +3414,7 @@ union cvmx_fpa_poolx_start_addr {
 	struct cvmx_fpa_poolx_start_addr_cn61xx cn68xx;
 	struct cvmx_fpa_poolx_start_addr_cn61xx cn68xxp1;
 	struct cvmx_fpa_poolx_start_addr_cn61xx cn70xx;
+	struct cvmx_fpa_poolx_start_addr_cn61xx cn70xxp1;
 	struct cvmx_fpa_poolx_start_addr_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
@@ -3451,6 +3471,7 @@ union cvmx_fpa_poolx_threshold {
 	} cn68xx;
 	struct cvmx_fpa_poolx_threshold_cn68xx cn68xxp1;
 	struct cvmx_fpa_poolx_threshold_cn61xx cn70xx;
+	struct cvmx_fpa_poolx_threshold_cn61xx cn70xxp1;
 	struct cvmx_fpa_poolx_threshold_s     cn78xx;
 	struct cvmx_fpa_poolx_threshold_cn61xx cnf71xx;
 };
@@ -3500,6 +3521,7 @@ union cvmx_fpa_quex_available {
 	struct cvmx_fpa_quex_available_s      cn68xx;
 	struct cvmx_fpa_quex_available_s      cn68xxp1;
 	struct cvmx_fpa_quex_available_cn30xx cn70xx;
+	struct cvmx_fpa_quex_available_cn30xx cn70xxp1;
 	struct cvmx_fpa_quex_available_cn30xx cnf71xx;
 };
 typedef union cvmx_fpa_quex_available cvmx_fpa_quex_available_t;
@@ -3540,6 +3562,7 @@ union cvmx_fpa_quex_page_index {
 	struct cvmx_fpa_quex_page_index_s     cn68xx;
 	struct cvmx_fpa_quex_page_index_s     cn68xxp1;
 	struct cvmx_fpa_quex_page_index_s     cn70xx;
+	struct cvmx_fpa_quex_page_index_s     cn70xxp1;
 	struct cvmx_fpa_quex_page_index_s     cnf71xx;
 };
 typedef union cvmx_fpa_quex_page_index cvmx_fpa_quex_page_index_t;
@@ -3607,6 +3630,7 @@ union cvmx_fpa_que_act {
 	struct cvmx_fpa_que_act_s             cn68xx;
 	struct cvmx_fpa_que_act_s             cn68xxp1;
 	struct cvmx_fpa_que_act_s             cn70xx;
+	struct cvmx_fpa_que_act_s             cn70xxp1;
 	struct cvmx_fpa_que_act_s             cnf71xx;
 };
 typedef union cvmx_fpa_que_act cvmx_fpa_que_act_t;
@@ -3648,6 +3672,7 @@ union cvmx_fpa_que_exp {
 	struct cvmx_fpa_que_exp_s             cn68xx;
 	struct cvmx_fpa_que_exp_s             cn68xxp1;
 	struct cvmx_fpa_que_exp_s             cn70xx;
+	struct cvmx_fpa_que_exp_s             cn70xxp1;
 	struct cvmx_fpa_que_exp_s             cnf71xx;
 };
 typedef union cvmx_fpa_que_exp cvmx_fpa_que_exp_t;
@@ -3830,101 +3855,9 @@ union cvmx_fpa_wqe_threshold {
 	struct cvmx_fpa_wqe_threshold_s       cn68xx;
 	struct cvmx_fpa_wqe_threshold_s       cn68xxp1;
 	struct cvmx_fpa_wqe_threshold_s       cn70xx;
+	struct cvmx_fpa_wqe_threshold_s       cn70xxp1;
 	struct cvmx_fpa_wqe_threshold_s       cnf71xx;
 };
 typedef union cvmx_fpa_wqe_threshold cvmx_fpa_wqe_threshold_t;
 
-/**
- * Structure describing the data format used for stores to the FPA.
- */
-typedef union {
-	uint64_t u64;
-	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t scraddr:8;	/**
-					 * the (64-bit word) location in
-					 * scratchpad to write to (if len != 0)
-					 */
-		uint64_t len:8;		/**
-					 * the number of words in the response
-					 * (0 => no response)
-					 */
-		uint64_t did:8;		/**
-					 * the ID of the device on the
-					 * non-coherent bus
-					 */
-		uint64_t addr:40;	/**
-					 * the address that will appear in the
-					 * first tick on the NCB bus
-					 */
-#else
-		uint64_t addr:40;	/**
-					 * the address that will appear in the
-					 * first tick on the NCB bus
-					 */
-		uint64_t did:8;		/**
-					 * the ID of the device on the
-					 * non-coherent bus
-					 */
-		uint64_t len:8;		/**
-					 * the number of words in the response
-					 * (0 => no response)
-					 */
-		uint64_t scraddr:8;	/**
-					 * the (64-bit word) location in
-					 * scratchpad to write to (if len != 0)
-					 */
-#endif
-	} s;
-	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t scraddr:8;     /**
-					 * the (64-bit word) location in
-					 * scratchpad to write to (if len != 0)
-					 */
-		uint64_t len:8;		/**
-					 * length of return in workds, must be
-					 * one.  If the pool has no availale pts
-					 * in the selected pool then the ptr
-					 * returned for the IOBDMA operation are
-					 * 0s, indicating that the pool does not
-					 * have an adequate number of ptrs to
-					 * satisfy the IOBDMA.
-					 */
-		uint64_t did:8;		/**
-					 * the ID of the device on the
-					 * non-coherent bus
-					 */
-		uint64_t node:4;	/** OCI node number */
-		uint64_t red:1;		/** Perform RED on allocation */
-		uint64_t reserved2:9;   /** Reserved */
-		uint64_t aura:10;	/** Aura number */
-		uint64_t reserved3:16;	/** Reserved */
-#else
-		uint64_t reserved3:16;	/** Reserved */
-		uint64_t aura:10;	/** Aura number */
-		uint64_t reserved2:9;   /** Reserved */
-		uint64_t red:1;		/** Perform RED on allocation */
-		uint64_t node:4;	/** OCI node number */
-		uint64_t did:8;		/**
-					 * the ID of the device on the
-					 * non-coherent bus
-					 */
-		uint64_t len:8;		/**
-					 * length of return in workds, must be
-					 * one.  If the pool has no availale pts
-					 * in the selected pool then the ptr
-					 * returned for the IOBDMA operation are
-					 * 0s, indicating that the pool does not
-					 * have an adequate number of ptrs to
-					 * satisfy the IOBDMA.
-					 */
-		uint64_t scraddr:8;	/**
-					 * the (64-bit word) location in
-					 * scratchpad to write to (if len != 0)
-					 */
-#endif
-	} cn78xx;
-} cvmx_fpa_iobdma_data_t;
-
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa1.h b/arch/mips/include/asm/octeon/cvmx-fpa1.h
index ce06039..700a576 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa1.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa1.h
@@ -53,10 +53,7 @@
 #include <asm/octeon/cvmx-fpa-defs.h>
 #endif
 
-#define CVMX_FPA1_NUM_POOLS      8
-#define CVMX_FPA1_POOL_NAME_LEN  16
-#define CVMX_FPA1_MIN_BLOCK_SIZE 128
-#define CVMX_FPA1_ALIGNMENT      128
+#define CVMX_FPA_NUM_POOLS      8
 
 /**
  * Structure to store FPA pool configuration parameters.
@@ -69,34 +66,6 @@ typedef struct cvmx_fpa_pool_config
 }cvmx_fpa_pool_config_t;
 
 /**
- * Structure describing the current state of a FPA pool.
- */
-typedef struct {
-	char name[CVMX_FPA1_POOL_NAME_LEN];	/** FPA Pool Name */
-	uint64_t size;				/** Size of each block */
-	void *base;				/**
-						 * The base memory address of
-						 * whole block
-						 */
-	uint64_t stack_base;			/**
-						 * Base address of stack of FPA
-						 * pool
-						 */
-	uint64_t starting_element_count;	/**
-						 * The number of elements in the
-						 * pool at creation
-						 */
-	uint64_t max_buffer_cnt;		/**
-						 * Maximum amount of buffers
-						 * that can be held in this
-						 * FPA pool
-						 */
-} cvmx_fpa1_pool_info_t;
-
-extern CVMX_SHARED cvmx_fpa1_pool_info_t
-cvmx_fpa1_pool_info[CVMX_FPA1_NUM_POOLS];
-
-/**
  * Allocate or reserve  the specified fpa pool.
  *
  * @param pool	  FPA pool to allocate/reserve. If -1 it
@@ -133,6 +102,19 @@ static inline void cvmx_fpa1_free(void *ptr, uint64_t pool,
 	cvmx_write_io(newptr.u64, num_cache_lines);
 }
 
+static inline void cvmx_fpa1_free_nosync(void *ptr, uint64_t pool,
+					uint64_t num_cache_lines)
+{
+	cvmx_addr_t newptr;
+	newptr.u64 = cvmx_ptr_to_phys(ptr);
+	newptr.sfilldidspace.didspace =
+		CVMX_ADDR_DIDSPACE(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool));
+	/* Prevent GCC from reordering around free */
+	asm volatile ("":::"memory");
+	/* value written is number of cache lines not written back */
+	cvmx_write_io(newptr.u64, num_cache_lines);
+}
+
 /**
  * Enable the FPA for use. Must be performed after any CSR
  * configuration but before any other FPA functions.
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa3.h b/arch/mips/include/asm/octeon/cvmx-fpa3.h
index c59cbba..c0fe6a0 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa3.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa3.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -68,11 +68,8 @@ extern "C" {
 #endif
 
 #define CVMX_FPA3_AURA_NUM       1024
-#define CVMX_FPA3_MIN_BLOCK_SIZE 128
-#define CVMX_FPA3_ALIGNMENT      128
-#define CVMX_FPA3_POOL_NAME_LEN  16
 #define CVMX_FPA3_NUM_POOLS	64
-#define CVMX_FPA3_AURA_NAME_LEN  16
+#define CVMX_FPA3_AURA_NAME_LEN  32
 
 /**
  * Struct describing load allocate operation addresses for FPA pool.
@@ -80,34 +77,21 @@ extern "C" {
 typedef union {
 	uint64_t u64;
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t reserved1:15;
-		uint64_t io:1;		/** Indicates I/O space */
-		uint64_t did:8;		/**
+		CVMX_BITFIELD_FIELD(uint64_t seg:2,
+		CVMX_BITFIELD_FIELD(uint64_t reserved1:13,
+		CVMX_BITFIELD_FIELD(uint64_t io:1,		/** Indicates I/O space */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		/**
 					 * the ID of the device on the
 					 * non-coherent bus
 					 */
-		uint64_t node:4;	/** OCI node number */
-		uint64_t red:1;		/** Perform RED on allocation */
-		uint64_t reserved2:9;   /** Reserved */
-		uint64_t aura:10;	/** Aura number */
-		uint64_t reserved3:16;	/** Reserved */
-#else
-		uint64_t reserved3:16;	/** Reserved */
-		uint64_t aura:10;	/** Aura number */
-		uint64_t reserved2:9;   /** Reserved */
-		uint64_t red:1;		/** Perform RED on allocation */
-		uint64_t node:4;	/** OCI node number */
-		uint64_t did:8;		/**
-					 * the ID of the device on the
-					 * non-coherent bus
-					 */
-		uint64_t io:1;		/** Indicates I/O space */
-		uint64_t reserved1:15;
-
-#endif
-	} cn78xx;
-} cvmx_fpa_load_data_t;
+		CVMX_BITFIELD_FIELD(uint64_t node:4,	/** OCI node number */
+		CVMX_BITFIELD_FIELD(uint64_t red:1,		/** Perform RED on allocation */
+		CVMX_BITFIELD_FIELD(uint64_t reserved2:9,   /** Reserved */
+		CVMX_BITFIELD_FIELD(uint64_t aura:10,	/** Aura number */
+		CVMX_BITFIELD_FIELD(uint64_t reserved3:16,	/** Reserved */
+		)))))))));
+	};
+} cvmx_fpa3_load_data_t;
 
 /**
  * Struct describing store free operation addresses from FPA pool.
@@ -115,91 +99,43 @@ typedef union {
 typedef union {
 	uint64_t u64;
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t reserved1:15;
-		uint64_t io:1;		/** Indicates I/O space */
-		uint64_t did:8;		/**
+		CVMX_BITFIELD_FIELD(uint64_t seg:2,
+		CVMX_BITFIELD_FIELD(uint64_t reserved1:13,
+		CVMX_BITFIELD_FIELD(uint64_t io:1,		/** Indicates I/O space */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		/**
 					 * the ID of the device on the
 					 * non-coherent bus
 					 */
-		uint64_t node:4;	/** OCI node number */
-		uint64_t reserved2:10;  /** Reserved */
-		uint64_t aura:10;	/** Aura number */
-		uint64_t fabs:1;	/** free absolute */
-		uint64_t reserved3:3;	/** Reserved */
-		uint64_t dwb_count:9;	/**
+		CVMX_BITFIELD_FIELD(uint64_t node:4,	/** OCI node number */
+		CVMX_BITFIELD_FIELD(uint64_t reserved2:10,  /** Reserved */
+		CVMX_BITFIELD_FIELD(uint64_t aura:10,	/** Aura number */
+		CVMX_BITFIELD_FIELD(uint64_t fabs:1,	/** free absolute */
+		CVMX_BITFIELD_FIELD(uint64_t reserved3:3,	/** Reserved */
+		CVMX_BITFIELD_FIELD(uint64_t dwb_count:9,	/**
 					 * Number of cache lines for which the
 					 * hardware should try to execute
 					 * 'don't-write-back' commands.
 					 */
-		uint64_t reserved4:3;	/** Reserved */
-#else
-		uint64_t reserved4:3;	/** Reserved */
-		uint64_t dwb_count:9;	/**
-					 * Number of cache lines for which the
-					 * hardware should try to execute
-					 * 'don't-write-back' commands.
-					 */
-		uint64_t reserved3:3;	/** Reserved */
-		uint64_t fabs:1;	/** free absolute */
-		uint64_t aura:10;	/** Aura number */
-		uint64_t reserved2:10;  /** Reserved */
-		uint64_t node:4;	/** OCI node number */
-		uint64_t did:8;		/**
-					 * the ID of the device on the
-					 * non-coherent bus
-					 */
-		uint64_t io:1;		/** Indicates I/O space */
-		uint64_t reserved1:15;
-#endif
-	} cn78xx;
-} cvmx_fpa_store_addr_t;
-/**
- * Structure describing the current state of a FPA pool.
- */
-typedef struct {
-	char name[CVMX_FPA3_POOL_NAME_LEN];	/** FPA Pool Name */
-	uint64_t size;				/** Size of each block */
-	void *base;				/**
-						 * The base memory address of
-						 * whole block
-						 */
-	uint64_t stack_base;			/**
-						 * Base address of stack of FPA
-						 * pool
-						 */
-	uint64_t starting_element_count;	/**
-						 * The number of elements in the
-						 * pool at creation
-						 */
-	uint64_t max_buffer_cnt;		/**
-						 * Maximum amount of buffers
-						 * that can be held in this
-						 * FPA pool
-						 */
-} cvmx_fpa3_pool_info_t;
+		CVMX_BITFIELD_FIELD(uint64_t reserved4:3,	/** Reserved */
+		)))))))))));
+	};
+} cvmx_fpa3_store_addr_t;
 
-/**
- * Structure which contains information on auras.
- */
-typedef struct {
-	char name[CVMX_FPA3_AURA_NAME_LEN];
-	int pool_num;
-	void *base; /** Base of aura if allocated separately */
-	uint64_t size;
-} cvmx_fpa3_aura_info_t;
+int cvmx_fpa3_allocate_auras(int node, int auras_allocated[], int count);
+int cvmx_fpa3_allocate_aura(int node);
+int cvmx_fpa3_free_auras(int node, int *auras_allocated, int count);
+int cvmx_fpa3_allocate_pools(int node, int pools_allocated[], int count);
+int cvmx_fpa3_free_pools(int node, int *pools_allocated, int count);
 
-/**
- * Current state of all the pools. Use access functions
- * instead of using it directly.
- */
-extern CVMX_SHARED cvmx_fpa3_pool_info_t
-cvmx_fpa3_pool_info[CVMX_MAX_NODES][CVMX_FPA3_NUM_POOLS];
-extern CVMX_SHARED cvmx_fpa3_aura_info_t
-cvmx_fpa3_aura_info[CVMX_MAX_NODES][CVMX_FPA3_AURA_NUM];
+void cvmx_fpa3_pool_set_stack(int node, int pool_id, uint64_t base, uint64_t len);
 
-int cvmx_fpa3_allocate_auras(int node, int auras_allocated[], int count);
-int cvmx_fpa3_free_auras(int node, int *pools_allocated, int count);
+static inline int cvmx_fpa3_arua_to_guara(int node, int laura)
+{
+	return node << 10 | laura;
+}
+
+int cvmx_fpa3_aura_to_pool(int node, int aura_id);
+void* cvmx_fpa3_aura_get_base(int node, int aura_id);
 
 /**
  * Get a new block from the FPA Aura
@@ -208,27 +144,32 @@ int cvmx_fpa3_free_auras(int node, int *pools_allocated, int count);
  * @param aura  - aura to get the block from
  * @return pointer to the block or NULL on failure
  */
-static inline void *cvmx_fpa_alloc_aura(int node, int aura)
+static inline void *cvmx_fpa3_alloc_aura(unsigned int node, unsigned int aura)
 {
 	uint64_t address;
-	cvmx_fpa_load_data_t load_addr;
+	cvmx_fpa3_load_data_t load_addr;
 
 	load_addr.u64 = 0;
-	load_addr.cn78xx.io = 1;
-	load_addr.cn78xx.did = 0x29;    /* Device ID. Indicates FPA. */
-	load_addr.cn78xx.node = node;   /* OCI node number */
-	load_addr.cn78xx.red = 0;       /* Perform RED on allocation.
+	load_addr.seg = CVMX_MIPS_SPACE_XKPHYS;
+	load_addr.io = 1;
+	load_addr.did = 0x29;    /* Device ID. Indicates FPA. */
+	load_addr.node = node;   /* OCI node number */
+	load_addr.red = 0;       /* Perform RED on allocation.
 					 * FIXME to use config option
 					 */
-	load_addr.cn78xx.aura = aura;   /* Aura number */
+	load_addr.aura = aura;   /* Aura number */
 
-	address = cvmx_read_csr((CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-					      load_addr.u64)));
+	address = cvmx_read64_uint64(load_addr.u64);
 	if (!address)
 		return NULL;
 	return cvmx_phys_to_ptr(address);
 }
 
+static inline void *cvmx_fpa3_alloc_gaura(unsigned int gaura)
+{
+	return cvmx_fpa3_alloc_aura(gaura >> 10, gaura & 0x3ff);
+}
+
 /**
  * Free a pointer back to the aura.
  *
@@ -237,21 +178,22 @@ static inline void *cvmx_fpa_alloc_aura(int node, int aura)
  * @param ptr    physical address of block to free.
  * @param num_cache_lines Cache lines to invalidate
  */
-static inline void cvmx_fpa_free_aura(void *ptr, uint64_t node, int aura,
-				      uint64_t num_cache_lines)
+static inline void cvmx_fpa3_free_aura(void *ptr, uint64_t node, int aura,
+				       unsigned int num_cache_lines)
 {
-	cvmx_fpa_store_addr_t newptr;
+	cvmx_fpa3_store_addr_t newptr;
 	cvmx_addr_t newdata;
 
 	newdata.u64 = cvmx_ptr_to_phys(ptr);
 
-	newptr.u64 = 2ull<<62;
-	newptr.cn78xx.io = 1;
-	newptr.cn78xx.did = 0x29;    /* Device id, indicates FPA */
-	newptr.cn78xx.node = node;   /* OCI node number. */
-	newptr.cn78xx.aura = aura;   /* Aura number */
-	newptr.cn78xx.fabs = 0;	/* Free absolute. FIXME to use config option */
-	newptr.cn78xx.dwb_count = num_cache_lines;
+	newptr.u64 = 0;
+	newptr.seg = CVMX_MIPS_SPACE_XKPHYS;
+	newptr.io = 1;
+	newptr.did = 0x29;    /* Device id, indicates FPA */
+	newptr.node = node;   /* OCI node number. */
+	newptr.aura = aura;   /* Aura number */
+	newptr.fabs = 0;	/* Free absolute. FIXME to use config option */
+	newptr.dwb_count = num_cache_lines;
 
 	/*cvmx_dprintf("aura = %d ptr_to_phys(ptr) = 0x%llx newptr.u64 = 0x%llx"
 		     " ptr = %p \n", ptr, aura, (ULL) newptr.u64
@@ -263,6 +205,41 @@ static inline void cvmx_fpa_free_aura(void *ptr, uint64_t node, int aura,
         cvmx_write_io(newptr.u64, newdata.u64);
 }
 
+static inline void cvmx_fpa3_free_gaura(void *ptr, unsigned int gaura,
+				       unsigned int num_cache_lines)
+{
+	cvmx_fpa3_free_aura(ptr, gaura >> 10, gaura & 0x3ff, num_cache_lines);
+}
+
+/**
+ * Free a pointer back to the aura, without flushing the write buffer
+ *
+ * @param node   node number
+ * @param aura   aura number
+ * @param ptr    physical address of block to free.
+ * @param num_cache_lines Cache lines to invalidate
+ */
+static inline void cvmx_fpa3_free_aura_nosync(void *ptr, uint64_t node, int aura,
+					      uint64_t num_cache_lines)
+{
+	cvmx_fpa3_store_addr_t newptr;
+	cvmx_addr_t newdata;
+
+	newdata.u64 = cvmx_ptr_to_phys(ptr);
+
+	newptr.u64 = 0;
+	newptr.seg = CVMX_MIPS_SPACE_XKPHYS;
+	newptr.io = 1;
+	newptr.did = 0x29;    /* Device id, indicates FPA */
+	newptr.node = node;   /* OCI node number. */
+	newptr.aura = aura;   /* Aura number */
+	newptr.fabs = 0;	/* Free absolute. FIXME to use config option */
+	newptr.dwb_count = num_cache_lines;
+	/* Prevent GCC from reordering around free */
+	asm volatile ("":::"memory");
+	cvmx_write_io(newptr.u64, newdata.u64);
+}
+
 static inline void __cvmx_fpa_aura_cfg(int node, int aura, int pool,
 				       int buffers_cnt, int ptr_dis)
 {
@@ -385,8 +362,6 @@ static inline int cvmx_fpa3_config_red_params(int node, int qos_avg_en, int red_
 	return 0;
 }
 
-#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-
 /**
  * Gets the buffer size of the specified AURA,
  * which is a 12-bit quantity, with the upper 2 bits
@@ -395,14 +370,7 @@ static inline int cvmx_fpa3_config_red_params(int node, int qos_avg_en, int red_
  * @param gaura Global aura number
  * @return Returns size of the buffers in the specified aura.
  */
-static inline unsigned cvmx_fpa_get_aura_buf_size(uint16_t gaura)
-{
-	unsigned node = gaura >> 10;
-	unsigned pool;
-
-	pool = cvmx_fpa3_aura_info[node][gaura & ((1<<10)-1)].pool_num;
-	return (cvmx_fpa3_pool_info[node][pool].size);
-}
+unsigned cvmx_fpa3_get_aura_buf_size(uint16_t gaura);
 
 /**
  * This will map auras specified in the auras_index[] array to specified
@@ -415,13 +383,25 @@ static inline unsigned cvmx_fpa_get_aura_buf_size(uint16_t gaura)
 int cvmx_fpa3_assign_auras(int node, int auras_index[], int count,
 			  int pool_index);
 
-static inline int cvmx_fpa3_assign_aura(int node, int aura, int pool_index)
+int cvmx_fpa3_assign_aura(int node, int aura, int pool_index);
+
+static inline void cvmx_fpa3_disable_pool(int node, int pool_num)
 {
-	int auras[1];
+	cvmx_fpa_poolx_cfg_t pool_cfg;
 
-	auras[0] = aura;
-	return cvmx_fpa3_assign_auras(node, auras, 1, pool_index);
+	pool_cfg.u64 = 0;
+	pool_cfg.cn78xx.ena = 0;
+
+	cvmx_write_csr_node(node, CVMX_FPA_POOLX_CFG(pool_num), pool_cfg.u64);
+	cvmx_write_csr_node(node, CVMX_FPA_POOLX_STACK_BASE(pool_num), 0);
+	cvmx_write_csr_node(node, CVMX_FPA_POOLX_STACK_ADDR(pool_num), 0);
+	cvmx_write_csr_node(node, CVMX_FPA_POOLX_STACK_END(pool_num), 0);
 }
-#endif
 
+#ifdef	__cplusplus
+/* *INDENT-OFF* */
+}
+/* *INDENT-ON* */
 #endif
+
+#endif /*  __CVM_FPA3_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-gmxx-defs.h b/arch/mips/include/asm/octeon/cvmx-gmxx-defs.h
index db98f90..0c9b387 100644
--- a/arch/mips/include/asm/octeon/cvmx-gmxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gmxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -5703,6 +5703,7 @@ union cvmx_gmxx_bad_reg {
 	struct cvmx_gmxx_bad_reg_cn52xx       cn68xx;
 	struct cvmx_gmxx_bad_reg_cn52xx       cn68xxp1;
 	struct cvmx_gmxx_bad_reg_cn52xx       cn70xx;
+	struct cvmx_gmxx_bad_reg_cn52xx       cn70xxp1;
 	struct cvmx_gmxx_bad_reg_cn52xx       cnf71xx;
 };
 typedef union cvmx_gmxx_bad_reg cvmx_gmxx_bad_reg_t;
@@ -5847,6 +5848,7 @@ union cvmx_gmxx_bist {
 	struct cvmx_gmxx_bist_s               cn68xx;
 	struct cvmx_gmxx_bist_s               cn68xxp1;
 	struct cvmx_gmxx_bist_s               cn70xx;
+	struct cvmx_gmxx_bist_s               cn70xxp1;
 	struct cvmx_gmxx_bist_s               cnf71xx;
 };
 typedef union cvmx_gmxx_bist cvmx_gmxx_bist_t;
@@ -5995,6 +5997,7 @@ union cvmx_gmxx_clk_en {
 	struct cvmx_gmxx_clk_en_s             cn68xx;
 	struct cvmx_gmxx_clk_en_s             cn68xxp1;
 	struct cvmx_gmxx_clk_en_s             cn70xx;
+	struct cvmx_gmxx_clk_en_s             cn70xxp1;
 	struct cvmx_gmxx_clk_en_s             cnf71xx;
 };
 typedef union cvmx_gmxx_clk_en cvmx_gmxx_clk_en_t;
@@ -6103,6 +6106,7 @@ union cvmx_gmxx_hg2_control {
 	struct cvmx_gmxx_hg2_control_s        cn68xx;
 	struct cvmx_gmxx_hg2_control_s        cn68xxp1;
 	struct cvmx_gmxx_hg2_control_s        cn70xx;
+	struct cvmx_gmxx_hg2_control_s        cn70xxp1;
 	struct cvmx_gmxx_hg2_control_s        cnf71xx;
 };
 typedef union cvmx_gmxx_hg2_control cvmx_gmxx_hg2_control_t;
@@ -6434,6 +6438,7 @@ union cvmx_gmxx_inf_mode {
 	uint64_t reserved_6_63                : 58;
 #endif
 	} cn70xx;
+	struct cvmx_gmxx_inf_mode_cn70xx      cn70xxp1;
 	struct cvmx_gmxx_inf_mode_cn61xx      cnf71xx;
 };
 typedef union cvmx_gmxx_inf_mode cvmx_gmxx_inf_mode_t;
@@ -6492,6 +6497,7 @@ union cvmx_gmxx_nxa_adr {
 	struct cvmx_gmxx_nxa_adr_s            cn68xx;
 	struct cvmx_gmxx_nxa_adr_s            cn68xxp1;
 	struct cvmx_gmxx_nxa_adr_cn30xx       cn70xx;
+	struct cvmx_gmxx_nxa_adr_cn30xx       cn70xxp1;
 	struct cvmx_gmxx_nxa_adr_cn30xx       cnf71xx;
 };
 typedef union cvmx_gmxx_nxa_adr cvmx_gmxx_nxa_adr_t;
@@ -6585,6 +6591,7 @@ union cvmx_gmxx_prtx_cbfc_ctl {
 	struct cvmx_gmxx_prtx_cbfc_ctl_s      cn68xx;
 	struct cvmx_gmxx_prtx_cbfc_ctl_s      cn68xxp1;
 	struct cvmx_gmxx_prtx_cbfc_ctl_s      cn70xx;
+	struct cvmx_gmxx_prtx_cbfc_ctl_s      cn70xxp1;
 	struct cvmx_gmxx_prtx_cbfc_ctl_s      cnf71xx;
 };
 typedef union cvmx_gmxx_prtx_cbfc_ctl cvmx_gmxx_prtx_cbfc_ctl_t;
@@ -6743,6 +6750,7 @@ union cvmx_gmxx_prtx_cfg {
 	struct cvmx_gmxx_prtx_cfg_s           cn68xx;
 	struct cvmx_gmxx_prtx_cfg_s           cn68xxp1;
 	struct cvmx_gmxx_prtx_cfg_cn52xx      cn70xx;
+	struct cvmx_gmxx_prtx_cfg_cn52xx      cn70xxp1;
 	struct cvmx_gmxx_prtx_cfg_cn52xx      cnf71xx;
 };
 typedef union cvmx_gmxx_prtx_cfg cvmx_gmxx_prtx_cfg_t;
@@ -6765,6 +6773,7 @@ union cvmx_gmxx_qsgmii_ctl {
 #endif
 	} s;
 	struct cvmx_gmxx_qsgmii_ctl_s         cn70xx;
+	struct cvmx_gmxx_qsgmii_ctl_s         cn70xxp1;
 };
 typedef union cvmx_gmxx_qsgmii_ctl cvmx_gmxx_qsgmii_ctl_t;
 
@@ -6812,6 +6821,7 @@ union cvmx_gmxx_rxx_adr_cam0 {
 	struct cvmx_gmxx_rxx_adr_cam0_s       cn68xx;
 	struct cvmx_gmxx_rxx_adr_cam0_s       cn68xxp1;
 	struct cvmx_gmxx_rxx_adr_cam0_s       cn70xx;
+	struct cvmx_gmxx_rxx_adr_cam0_s       cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_cam0_s       cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_cam0 cvmx_gmxx_rxx_adr_cam0_t;
@@ -6860,6 +6870,7 @@ union cvmx_gmxx_rxx_adr_cam1 {
 	struct cvmx_gmxx_rxx_adr_cam1_s       cn68xx;
 	struct cvmx_gmxx_rxx_adr_cam1_s       cn68xxp1;
 	struct cvmx_gmxx_rxx_adr_cam1_s       cn70xx;
+	struct cvmx_gmxx_rxx_adr_cam1_s       cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_cam1_s       cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_cam1 cvmx_gmxx_rxx_adr_cam1_t;
@@ -6908,6 +6919,7 @@ union cvmx_gmxx_rxx_adr_cam2 {
 	struct cvmx_gmxx_rxx_adr_cam2_s       cn68xx;
 	struct cvmx_gmxx_rxx_adr_cam2_s       cn68xxp1;
 	struct cvmx_gmxx_rxx_adr_cam2_s       cn70xx;
+	struct cvmx_gmxx_rxx_adr_cam2_s       cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_cam2_s       cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_cam2 cvmx_gmxx_rxx_adr_cam2_t;
@@ -6956,6 +6968,7 @@ union cvmx_gmxx_rxx_adr_cam3 {
 	struct cvmx_gmxx_rxx_adr_cam3_s       cn68xx;
 	struct cvmx_gmxx_rxx_adr_cam3_s       cn68xxp1;
 	struct cvmx_gmxx_rxx_adr_cam3_s       cn70xx;
+	struct cvmx_gmxx_rxx_adr_cam3_s       cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_cam3_s       cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_cam3 cvmx_gmxx_rxx_adr_cam3_t;
@@ -7004,6 +7017,7 @@ union cvmx_gmxx_rxx_adr_cam4 {
 	struct cvmx_gmxx_rxx_adr_cam4_s       cn68xx;
 	struct cvmx_gmxx_rxx_adr_cam4_s       cn68xxp1;
 	struct cvmx_gmxx_rxx_adr_cam4_s       cn70xx;
+	struct cvmx_gmxx_rxx_adr_cam4_s       cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_cam4_s       cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_cam4 cvmx_gmxx_rxx_adr_cam4_t;
@@ -7052,6 +7066,7 @@ union cvmx_gmxx_rxx_adr_cam5 {
 	struct cvmx_gmxx_rxx_adr_cam5_s       cn68xx;
 	struct cvmx_gmxx_rxx_adr_cam5_s       cn68xxp1;
 	struct cvmx_gmxx_rxx_adr_cam5_s       cn70xx;
+	struct cvmx_gmxx_rxx_adr_cam5_s       cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_cam5_s       cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_cam5 cvmx_gmxx_rxx_adr_cam5_t;
@@ -7104,6 +7119,7 @@ union cvmx_gmxx_rxx_adr_cam_all_en {
 	struct cvmx_gmxx_rxx_adr_cam_all_en_s cn66xx;
 	struct cvmx_gmxx_rxx_adr_cam_all_en_s cn68xx;
 	struct cvmx_gmxx_rxx_adr_cam_all_en_s cn70xx;
+	struct cvmx_gmxx_rxx_adr_cam_all_en_s cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_cam_all_en_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_cam_all_en cvmx_gmxx_rxx_adr_cam_all_en_t;
@@ -7178,6 +7194,7 @@ union cvmx_gmxx_rxx_adr_cam_en {
 	struct cvmx_gmxx_rxx_adr_cam_en_s     cn68xx;
 	struct cvmx_gmxx_rxx_adr_cam_en_s     cn68xxp1;
 	struct cvmx_gmxx_rxx_adr_cam_en_s     cn70xx;
+	struct cvmx_gmxx_rxx_adr_cam_en_s     cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_cam_en_s     cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_cam_en cvmx_gmxx_rxx_adr_cam_en_t;
@@ -7267,6 +7284,7 @@ union cvmx_gmxx_rxx_adr_ctl {
 	struct cvmx_gmxx_rxx_adr_ctl_s        cn68xx;
 	struct cvmx_gmxx_rxx_adr_ctl_s        cn68xxp1;
 	struct cvmx_gmxx_rxx_adr_ctl_s        cn70xx;
+	struct cvmx_gmxx_rxx_adr_ctl_s        cn70xxp1;
 	struct cvmx_gmxx_rxx_adr_ctl_s        cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_adr_ctl cvmx_gmxx_rxx_adr_ctl_t;
@@ -7328,6 +7346,7 @@ union cvmx_gmxx_rxx_decision {
 	struct cvmx_gmxx_rxx_decision_s       cn68xx;
 	struct cvmx_gmxx_rxx_decision_s       cn68xxp1;
 	struct cvmx_gmxx_rxx_decision_s       cn70xx;
+	struct cvmx_gmxx_rxx_decision_s       cn70xxp1;
 	struct cvmx_gmxx_rxx_decision_s       cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_decision cvmx_gmxx_rxx_decision_t;
@@ -7463,6 +7482,7 @@ union cvmx_gmxx_rxx_frm_chk {
 	struct cvmx_gmxx_rxx_frm_chk_cn61xx   cn68xx;
 	struct cvmx_gmxx_rxx_frm_chk_cn61xx   cn68xxp1;
 	struct cvmx_gmxx_rxx_frm_chk_cn61xx   cn70xx;
+	struct cvmx_gmxx_rxx_frm_chk_cn61xx   cn70xxp1;
 	struct cvmx_gmxx_rxx_frm_chk_cn61xx   cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_frm_chk cvmx_gmxx_rxx_frm_chk_t;
@@ -7858,6 +7878,7 @@ union cvmx_gmxx_rxx_frm_ctl {
 	struct cvmx_gmxx_rxx_frm_ctl_cn61xx   cn68xx;
 	struct cvmx_gmxx_rxx_frm_ctl_cn61xx   cn68xxp1;
 	struct cvmx_gmxx_rxx_frm_ctl_cn61xx   cn70xx;
+	struct cvmx_gmxx_rxx_frm_ctl_cn61xx   cn70xxp1;
 	struct cvmx_gmxx_rxx_frm_ctl_cn61xx   cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_frm_ctl cvmx_gmxx_rxx_frm_ctl_t;
@@ -7981,6 +8002,7 @@ union cvmx_gmxx_rxx_ifg {
 	struct cvmx_gmxx_rxx_ifg_s            cn68xx;
 	struct cvmx_gmxx_rxx_ifg_s            cn68xxp1;
 	struct cvmx_gmxx_rxx_ifg_s            cn70xx;
+	struct cvmx_gmxx_rxx_ifg_s            cn70xxp1;
 	struct cvmx_gmxx_rxx_ifg_s            cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_ifg cvmx_gmxx_rxx_ifg_t;
@@ -8523,6 +8545,7 @@ union cvmx_gmxx_rxx_int_en {
 	uint64_t reserved_30_63               : 34;
 #endif
 	} cn70xx;
+	struct cvmx_gmxx_rxx_int_en_cn70xx    cn70xxp1;
 	struct cvmx_gmxx_rxx_int_en_cn61xx    cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_int_en cvmx_gmxx_rxx_int_en_t;
@@ -9217,6 +9240,7 @@ union cvmx_gmxx_rxx_int_reg {
 	uint64_t reserved_30_63               : 34;
 #endif
 	} cn70xx;
+	struct cvmx_gmxx_rxx_int_reg_cn70xx   cn70xxp1;
 	struct cvmx_gmxx_rxx_int_reg_cn61xx   cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_int_reg cvmx_gmxx_rxx_int_reg_t;
@@ -9271,6 +9295,7 @@ union cvmx_gmxx_rxx_jabber {
 	struct cvmx_gmxx_rxx_jabber_s         cn68xx;
 	struct cvmx_gmxx_rxx_jabber_s         cn68xxp1;
 	struct cvmx_gmxx_rxx_jabber_s         cn70xx;
+	struct cvmx_gmxx_rxx_jabber_s         cn70xxp1;
 	struct cvmx_gmxx_rxx_jabber_s         cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_jabber cvmx_gmxx_rxx_jabber_t;
@@ -9306,6 +9331,7 @@ union cvmx_gmxx_rxx_pause_drop_time {
 	struct cvmx_gmxx_rxx_pause_drop_time_s cn68xx;
 	struct cvmx_gmxx_rxx_pause_drop_time_s cn68xxp1;
 	struct cvmx_gmxx_rxx_pause_drop_time_s cn70xx;
+	struct cvmx_gmxx_rxx_pause_drop_time_s cn70xxp1;
 	struct cvmx_gmxx_rxx_pause_drop_time_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_pause_drop_time cvmx_gmxx_rxx_pause_drop_time_t;
@@ -9389,6 +9415,7 @@ union cvmx_gmxx_rxx_stats_ctl {
 	struct cvmx_gmxx_rxx_stats_ctl_s      cn68xx;
 	struct cvmx_gmxx_rxx_stats_ctl_s      cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_ctl_s      cn70xx;
+	struct cvmx_gmxx_rxx_stats_ctl_s      cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_ctl_s      cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_ctl cvmx_gmxx_rxx_stats_ctl_t;
@@ -9429,6 +9456,7 @@ union cvmx_gmxx_rxx_stats_octs {
 	struct cvmx_gmxx_rxx_stats_octs_s     cn68xx;
 	struct cvmx_gmxx_rxx_stats_octs_s     cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_octs_s     cn70xx;
+	struct cvmx_gmxx_rxx_stats_octs_s     cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_octs_s     cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_octs cvmx_gmxx_rxx_stats_octs_t;
@@ -9469,6 +9497,7 @@ union cvmx_gmxx_rxx_stats_octs_ctl {
 	struct cvmx_gmxx_rxx_stats_octs_ctl_s cn68xx;
 	struct cvmx_gmxx_rxx_stats_octs_ctl_s cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_octs_ctl_s cn70xx;
+	struct cvmx_gmxx_rxx_stats_octs_ctl_s cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_octs_ctl_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_octs_ctl cvmx_gmxx_rxx_stats_octs_ctl_t;
@@ -9509,6 +9538,7 @@ union cvmx_gmxx_rxx_stats_octs_dmac {
 	struct cvmx_gmxx_rxx_stats_octs_dmac_s cn68xx;
 	struct cvmx_gmxx_rxx_stats_octs_dmac_s cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_octs_dmac_s cn70xx;
+	struct cvmx_gmxx_rxx_stats_octs_dmac_s cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_octs_dmac_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_octs_dmac cvmx_gmxx_rxx_stats_octs_dmac_t;
@@ -9549,6 +9579,7 @@ union cvmx_gmxx_rxx_stats_octs_drp {
 	struct cvmx_gmxx_rxx_stats_octs_drp_s cn68xx;
 	struct cvmx_gmxx_rxx_stats_octs_drp_s cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_octs_drp_s cn70xx;
+	struct cvmx_gmxx_rxx_stats_octs_drp_s cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_octs_drp_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_octs_drp cvmx_gmxx_rxx_stats_octs_drp_t;
@@ -9589,6 +9620,7 @@ union cvmx_gmxx_rxx_stats_pkts {
 	struct cvmx_gmxx_rxx_stats_pkts_s     cn68xx;
 	struct cvmx_gmxx_rxx_stats_pkts_s     cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_s     cn70xx;
+	struct cvmx_gmxx_rxx_stats_pkts_s     cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_s     cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_pkts cvmx_gmxx_rxx_stats_pkts_t;
@@ -9628,6 +9660,7 @@ union cvmx_gmxx_rxx_stats_pkts_bad {
 	struct cvmx_gmxx_rxx_stats_pkts_bad_s cn68xx;
 	struct cvmx_gmxx_rxx_stats_pkts_bad_s cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_bad_s cn70xx;
+	struct cvmx_gmxx_rxx_stats_pkts_bad_s cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_bad_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_pkts_bad cvmx_gmxx_rxx_stats_pkts_bad_t;
@@ -9672,6 +9705,7 @@ union cvmx_gmxx_rxx_stats_pkts_ctl {
 	struct cvmx_gmxx_rxx_stats_pkts_ctl_s cn68xx;
 	struct cvmx_gmxx_rxx_stats_pkts_ctl_s cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_ctl_s cn70xx;
+	struct cvmx_gmxx_rxx_stats_pkts_ctl_s cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_ctl_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_pkts_ctl cvmx_gmxx_rxx_stats_pkts_ctl_t;
@@ -9716,6 +9750,7 @@ union cvmx_gmxx_rxx_stats_pkts_dmac {
 	struct cvmx_gmxx_rxx_stats_pkts_dmac_s cn68xx;
 	struct cvmx_gmxx_rxx_stats_pkts_dmac_s cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_dmac_s cn70xx;
+	struct cvmx_gmxx_rxx_stats_pkts_dmac_s cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_dmac_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_pkts_dmac cvmx_gmxx_rxx_stats_pkts_dmac_t;
@@ -9759,6 +9794,7 @@ union cvmx_gmxx_rxx_stats_pkts_drp {
 	struct cvmx_gmxx_rxx_stats_pkts_drp_s cn68xx;
 	struct cvmx_gmxx_rxx_stats_pkts_drp_s cn68xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_drp_s cn70xx;
+	struct cvmx_gmxx_rxx_stats_pkts_drp_s cn70xxp1;
 	struct cvmx_gmxx_rxx_stats_pkts_drp_s cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_stats_pkts_drp cvmx_gmxx_rxx_stats_pkts_drp_t;
@@ -9837,6 +9873,7 @@ union cvmx_gmxx_rxx_udd_skp {
 	struct cvmx_gmxx_rxx_udd_skp_s        cn68xx;
 	struct cvmx_gmxx_rxx_udd_skp_s        cn68xxp1;
 	struct cvmx_gmxx_rxx_udd_skp_s        cn70xx;
+	struct cvmx_gmxx_rxx_udd_skp_s        cn70xxp1;
 	struct cvmx_gmxx_rxx_udd_skp_s        cnf71xx;
 };
 typedef union cvmx_gmxx_rxx_udd_skp cvmx_gmxx_rxx_udd_skp_t;
@@ -9888,6 +9925,7 @@ union cvmx_gmxx_rx_bp_dropx {
 	struct cvmx_gmxx_rx_bp_dropx_s        cn68xx;
 	struct cvmx_gmxx_rx_bp_dropx_s        cn68xxp1;
 	struct cvmx_gmxx_rx_bp_dropx_s        cn70xx;
+	struct cvmx_gmxx_rx_bp_dropx_s        cn70xxp1;
 	struct cvmx_gmxx_rx_bp_dropx_s        cnf71xx;
 };
 typedef union cvmx_gmxx_rx_bp_dropx cvmx_gmxx_rx_bp_dropx_t;
@@ -9931,6 +9969,7 @@ union cvmx_gmxx_rx_bp_offx {
 	struct cvmx_gmxx_rx_bp_offx_s         cn68xx;
 	struct cvmx_gmxx_rx_bp_offx_s         cn68xxp1;
 	struct cvmx_gmxx_rx_bp_offx_s         cn70xx;
+	struct cvmx_gmxx_rx_bp_offx_s         cn70xxp1;
 	struct cvmx_gmxx_rx_bp_offx_s         cnf71xx;
 };
 typedef union cvmx_gmxx_rx_bp_offx cvmx_gmxx_rx_bp_offx_t;
@@ -9997,6 +10036,7 @@ union cvmx_gmxx_rx_bp_onx {
 	struct cvmx_gmxx_rx_bp_onx_s          cn68xx;
 	struct cvmx_gmxx_rx_bp_onx_s          cn68xxp1;
 	struct cvmx_gmxx_rx_bp_onx_cn30xx     cn70xx;
+	struct cvmx_gmxx_rx_bp_onx_cn30xx     cn70xxp1;
 	struct cvmx_gmxx_rx_bp_onx_cn30xx     cnf71xx;
 };
 typedef union cvmx_gmxx_rx_bp_onx cvmx_gmxx_rx_bp_onx_t;
@@ -10041,6 +10081,7 @@ union cvmx_gmxx_rx_hg2_status {
 	struct cvmx_gmxx_rx_hg2_status_s      cn68xx;
 	struct cvmx_gmxx_rx_hg2_status_s      cn68xxp1;
 	struct cvmx_gmxx_rx_hg2_status_s      cn70xx;
+	struct cvmx_gmxx_rx_hg2_status_s      cn70xxp1;
 	struct cvmx_gmxx_rx_hg2_status_s      cnf71xx;
 };
 typedef union cvmx_gmxx_rx_hg2_status cvmx_gmxx_rx_hg2_status_t;
@@ -10167,6 +10208,7 @@ union cvmx_gmxx_rx_prt_info {
 	struct cvmx_gmxx_rx_prt_info_cn52xx   cn68xx;
 	struct cvmx_gmxx_rx_prt_info_cn52xx   cn68xxp1;
 	struct cvmx_gmxx_rx_prt_info_cn52xx   cn70xx;
+	struct cvmx_gmxx_rx_prt_info_cn52xx   cn70xxp1;
 	struct cvmx_gmxx_rx_prt_info_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
@@ -10227,6 +10269,7 @@ union cvmx_gmxx_rx_prts {
 	struct cvmx_gmxx_rx_prts_s            cn68xx;
 	struct cvmx_gmxx_rx_prts_s            cn68xxp1;
 	struct cvmx_gmxx_rx_prts_s            cn70xx;
+	struct cvmx_gmxx_rx_prts_s            cn70xxp1;
 	struct cvmx_gmxx_rx_prts_s            cnf71xx;
 };
 typedef union cvmx_gmxx_rx_prts cvmx_gmxx_rx_prts_t;
@@ -10297,6 +10340,7 @@ union cvmx_gmxx_rx_xaui_bad_col {
 	struct cvmx_gmxx_rx_xaui_bad_col_s    cn68xx;
 	struct cvmx_gmxx_rx_xaui_bad_col_s    cn68xxp1;
 	struct cvmx_gmxx_rx_xaui_bad_col_s    cn70xx;
+	struct cvmx_gmxx_rx_xaui_bad_col_s    cn70xxp1;
 	struct cvmx_gmxx_rx_xaui_bad_col_s    cnf71xx;
 };
 typedef union cvmx_gmxx_rx_xaui_bad_col cvmx_gmxx_rx_xaui_bad_col_t;
@@ -10331,6 +10375,7 @@ union cvmx_gmxx_rx_xaui_ctl {
 	struct cvmx_gmxx_rx_xaui_ctl_s        cn68xx;
 	struct cvmx_gmxx_rx_xaui_ctl_s        cn68xxp1;
 	struct cvmx_gmxx_rx_xaui_ctl_s        cn70xx;
+	struct cvmx_gmxx_rx_xaui_ctl_s        cn70xxp1;
 	struct cvmx_gmxx_rx_xaui_ctl_s        cnf71xx;
 };
 typedef union cvmx_gmxx_rx_xaui_ctl cvmx_gmxx_rx_xaui_ctl_t;
@@ -10362,6 +10407,7 @@ union cvmx_gmxx_rxaui_ctl {
 	struct cvmx_gmxx_rxaui_ctl_s          cn68xx;
 	struct cvmx_gmxx_rxaui_ctl_s          cn68xxp1;
 	struct cvmx_gmxx_rxaui_ctl_s          cn70xx;
+	struct cvmx_gmxx_rxaui_ctl_s          cn70xxp1;
 };
 typedef union cvmx_gmxx_rxaui_ctl cvmx_gmxx_rxaui_ctl_t;
 
@@ -10401,6 +10447,7 @@ union cvmx_gmxx_smacx {
 	struct cvmx_gmxx_smacx_s              cn68xx;
 	struct cvmx_gmxx_smacx_s              cn68xxp1;
 	struct cvmx_gmxx_smacx_s              cn70xx;
+	struct cvmx_gmxx_smacx_s              cn70xxp1;
 	struct cvmx_gmxx_smacx_s              cnf71xx;
 };
 typedef union cvmx_gmxx_smacx cvmx_gmxx_smacx_t;
@@ -10494,6 +10541,7 @@ union cvmx_gmxx_stat_bp {
 	struct cvmx_gmxx_stat_bp_s            cn68xx;
 	struct cvmx_gmxx_stat_bp_s            cn68xxp1;
 	struct cvmx_gmxx_stat_bp_s            cn70xx;
+	struct cvmx_gmxx_stat_bp_s            cn70xxp1;
 	struct cvmx_gmxx_stat_bp_s            cnf71xx;
 };
 typedef union cvmx_gmxx_stat_bp cvmx_gmxx_stat_bp_t;
@@ -10519,6 +10567,7 @@ union cvmx_gmxx_tb_reg {
 	struct cvmx_gmxx_tb_reg_s             cn66xx;
 	struct cvmx_gmxx_tb_reg_s             cn68xx;
 	struct cvmx_gmxx_tb_reg_s             cn70xx;
+	struct cvmx_gmxx_tb_reg_s             cn70xxp1;
 	struct cvmx_gmxx_tb_reg_s             cnf71xx;
 };
 typedef union cvmx_gmxx_tb_reg cvmx_gmxx_tb_reg_t;
@@ -10569,6 +10618,7 @@ union cvmx_gmxx_txx_append {
 	struct cvmx_gmxx_txx_append_s         cn68xx;
 	struct cvmx_gmxx_txx_append_s         cn68xxp1;
 	struct cvmx_gmxx_txx_append_s         cn70xx;
+	struct cvmx_gmxx_txx_append_s         cn70xxp1;
 	struct cvmx_gmxx_txx_append_s         cnf71xx;
 };
 typedef union cvmx_gmxx_txx_append cvmx_gmxx_txx_append_t;
@@ -10596,6 +10646,7 @@ union cvmx_gmxx_txx_bck_crdt {
 #endif
 	} s;
 	struct cvmx_gmxx_txx_bck_crdt_s       cn70xx;
+	struct cvmx_gmxx_txx_bck_crdt_s       cn70xxp1;
 };
 typedef union cvmx_gmxx_txx_bck_crdt cvmx_gmxx_txx_bck_crdt_t;
 
@@ -10638,6 +10689,7 @@ union cvmx_gmxx_txx_burst {
 	struct cvmx_gmxx_txx_burst_s          cn68xx;
 	struct cvmx_gmxx_txx_burst_s          cn68xxp1;
 	struct cvmx_gmxx_txx_burst_s          cn70xx;
+	struct cvmx_gmxx_txx_burst_s          cn70xxp1;
 	struct cvmx_gmxx_txx_burst_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_burst cvmx_gmxx_txx_burst_t;
@@ -10668,6 +10720,7 @@ union cvmx_gmxx_txx_cbfc_xoff {
 	struct cvmx_gmxx_txx_cbfc_xoff_s      cn68xx;
 	struct cvmx_gmxx_txx_cbfc_xoff_s      cn68xxp1;
 	struct cvmx_gmxx_txx_cbfc_xoff_s      cn70xx;
+	struct cvmx_gmxx_txx_cbfc_xoff_s      cn70xxp1;
 	struct cvmx_gmxx_txx_cbfc_xoff_s      cnf71xx;
 };
 typedef union cvmx_gmxx_txx_cbfc_xoff cvmx_gmxx_txx_cbfc_xoff_t;
@@ -10698,6 +10751,7 @@ union cvmx_gmxx_txx_cbfc_xon {
 	struct cvmx_gmxx_txx_cbfc_xon_s       cn68xx;
 	struct cvmx_gmxx_txx_cbfc_xon_s       cn68xxp1;
 	struct cvmx_gmxx_txx_cbfc_xon_s       cn70xx;
+	struct cvmx_gmxx_txx_cbfc_xon_s       cn70xxp1;
 	struct cvmx_gmxx_txx_cbfc_xon_s       cnf71xx;
 };
 typedef union cvmx_gmxx_txx_cbfc_xon cvmx_gmxx_txx_cbfc_xon_t;
@@ -10790,6 +10844,7 @@ union cvmx_gmxx_txx_ctl {
 	struct cvmx_gmxx_txx_ctl_s            cn68xx;
 	struct cvmx_gmxx_txx_ctl_s            cn68xxp1;
 	struct cvmx_gmxx_txx_ctl_s            cn70xx;
+	struct cvmx_gmxx_txx_ctl_s            cn70xxp1;
 	struct cvmx_gmxx_txx_ctl_s            cnf71xx;
 };
 typedef union cvmx_gmxx_txx_ctl cvmx_gmxx_txx_ctl_t;
@@ -10813,6 +10868,7 @@ union cvmx_gmxx_txx_jam_mode {
 #endif
 	} s;
 	struct cvmx_gmxx_txx_jam_mode_s       cn70xx;
+	struct cvmx_gmxx_txx_jam_mode_s       cn70xxp1;
 };
 typedef union cvmx_gmxx_txx_jam_mode cvmx_gmxx_txx_jam_mode_t;
 
@@ -10861,6 +10917,7 @@ union cvmx_gmxx_txx_min_pkt {
 	struct cvmx_gmxx_txx_min_pkt_s        cn68xx;
 	struct cvmx_gmxx_txx_min_pkt_s        cn68xxp1;
 	struct cvmx_gmxx_txx_min_pkt_s        cn70xx;
+	struct cvmx_gmxx_txx_min_pkt_s        cn70xxp1;
 	struct cvmx_gmxx_txx_min_pkt_s        cnf71xx;
 };
 typedef union cvmx_gmxx_txx_min_pkt cvmx_gmxx_txx_min_pkt_t;
@@ -10924,6 +10981,7 @@ union cvmx_gmxx_txx_pause_pkt_interval {
 	struct cvmx_gmxx_txx_pause_pkt_interval_s cn68xx;
 	struct cvmx_gmxx_txx_pause_pkt_interval_s cn68xxp1;
 	struct cvmx_gmxx_txx_pause_pkt_interval_s cn70xx;
+	struct cvmx_gmxx_txx_pause_pkt_interval_s cn70xxp1;
 	struct cvmx_gmxx_txx_pause_pkt_interval_s cnf71xx;
 };
 typedef union cvmx_gmxx_txx_pause_pkt_interval cvmx_gmxx_txx_pause_pkt_interval_t;
@@ -10985,6 +11043,7 @@ union cvmx_gmxx_txx_pause_pkt_time {
 	struct cvmx_gmxx_txx_pause_pkt_time_s cn68xx;
 	struct cvmx_gmxx_txx_pause_pkt_time_s cn68xxp1;
 	struct cvmx_gmxx_txx_pause_pkt_time_s cn70xx;
+	struct cvmx_gmxx_txx_pause_pkt_time_s cn70xxp1;
 	struct cvmx_gmxx_txx_pause_pkt_time_s cnf71xx;
 };
 typedef union cvmx_gmxx_txx_pause_pkt_time cvmx_gmxx_txx_pause_pkt_time_t;
@@ -11037,6 +11096,7 @@ union cvmx_gmxx_txx_pause_togo {
 	struct cvmx_gmxx_txx_pause_togo_s     cn68xx;
 	struct cvmx_gmxx_txx_pause_togo_s     cn68xxp1;
 	struct cvmx_gmxx_txx_pause_togo_s     cn70xx;
+	struct cvmx_gmxx_txx_pause_togo_s     cn70xxp1;
 	struct cvmx_gmxx_txx_pause_togo_s     cnf71xx;
 };
 typedef union cvmx_gmxx_txx_pause_togo cvmx_gmxx_txx_pause_togo_t;
@@ -11078,6 +11138,7 @@ union cvmx_gmxx_txx_pause_zero {
 	struct cvmx_gmxx_txx_pause_zero_s     cn68xx;
 	struct cvmx_gmxx_txx_pause_zero_s     cn68xxp1;
 	struct cvmx_gmxx_txx_pause_zero_s     cn70xx;
+	struct cvmx_gmxx_txx_pause_zero_s     cn70xxp1;
 	struct cvmx_gmxx_txx_pause_zero_s     cnf71xx;
 };
 typedef union cvmx_gmxx_txx_pause_zero cvmx_gmxx_txx_pause_zero_t;
@@ -11176,6 +11237,7 @@ union cvmx_gmxx_txx_sgmii_ctl {
 	struct cvmx_gmxx_txx_sgmii_ctl_s      cn68xx;
 	struct cvmx_gmxx_txx_sgmii_ctl_s      cn68xxp1;
 	struct cvmx_gmxx_txx_sgmii_ctl_s      cn70xx;
+	struct cvmx_gmxx_txx_sgmii_ctl_s      cn70xxp1;
 	struct cvmx_gmxx_txx_sgmii_ctl_s      cnf71xx;
 };
 typedef union cvmx_gmxx_txx_sgmii_ctl cvmx_gmxx_txx_sgmii_ctl_t;
@@ -11218,6 +11280,7 @@ union cvmx_gmxx_txx_slot {
 	struct cvmx_gmxx_txx_slot_s           cn68xx;
 	struct cvmx_gmxx_txx_slot_s           cn68xxp1;
 	struct cvmx_gmxx_txx_slot_s           cn70xx;
+	struct cvmx_gmxx_txx_slot_s           cn70xxp1;
 	struct cvmx_gmxx_txx_slot_s           cnf71xx;
 };
 typedef union cvmx_gmxx_txx_slot cvmx_gmxx_txx_slot_t;
@@ -11257,6 +11320,7 @@ union cvmx_gmxx_txx_soft_pause {
 	struct cvmx_gmxx_txx_soft_pause_s     cn68xx;
 	struct cvmx_gmxx_txx_soft_pause_s     cn68xxp1;
 	struct cvmx_gmxx_txx_soft_pause_s     cn70xx;
+	struct cvmx_gmxx_txx_soft_pause_s     cn70xxp1;
 	struct cvmx_gmxx_txx_soft_pause_s     cnf71xx;
 };
 typedef union cvmx_gmxx_txx_soft_pause cvmx_gmxx_txx_soft_pause_t;
@@ -11305,6 +11369,7 @@ union cvmx_gmxx_txx_stat0 {
 	struct cvmx_gmxx_txx_stat0_s          cn68xx;
 	struct cvmx_gmxx_txx_stat0_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat0_s          cn70xx;
+	struct cvmx_gmxx_txx_stat0_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat0_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat0 cvmx_gmxx_txx_stat0_t;
@@ -11351,6 +11416,7 @@ union cvmx_gmxx_txx_stat1 {
 	struct cvmx_gmxx_txx_stat1_s          cn68xx;
 	struct cvmx_gmxx_txx_stat1_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat1_s          cn70xx;
+	struct cvmx_gmxx_txx_stat1_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat1_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat1 cvmx_gmxx_txx_stat1_t;
@@ -11399,6 +11465,7 @@ union cvmx_gmxx_txx_stat2 {
 	struct cvmx_gmxx_txx_stat2_s          cn68xx;
 	struct cvmx_gmxx_txx_stat2_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat2_s          cn70xx;
+	struct cvmx_gmxx_txx_stat2_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat2_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat2 cvmx_gmxx_txx_stat2_t;
@@ -11444,6 +11511,7 @@ union cvmx_gmxx_txx_stat3 {
 	struct cvmx_gmxx_txx_stat3_s          cn68xx;
 	struct cvmx_gmxx_txx_stat3_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat3_s          cn70xx;
+	struct cvmx_gmxx_txx_stat3_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat3_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat3 cvmx_gmxx_txx_stat3_t;
@@ -11491,6 +11559,7 @@ union cvmx_gmxx_txx_stat4 {
 	struct cvmx_gmxx_txx_stat4_s          cn68xx;
 	struct cvmx_gmxx_txx_stat4_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat4_s          cn70xx;
+	struct cvmx_gmxx_txx_stat4_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat4_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat4 cvmx_gmxx_txx_stat4_t;
@@ -11539,6 +11608,7 @@ union cvmx_gmxx_txx_stat5 {
 	struct cvmx_gmxx_txx_stat5_s          cn68xx;
 	struct cvmx_gmxx_txx_stat5_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat5_s          cn70xx;
+	struct cvmx_gmxx_txx_stat5_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat5_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat5 cvmx_gmxx_txx_stat5_t;
@@ -11587,6 +11657,7 @@ union cvmx_gmxx_txx_stat6 {
 	struct cvmx_gmxx_txx_stat6_s          cn68xx;
 	struct cvmx_gmxx_txx_stat6_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat6_s          cn70xx;
+	struct cvmx_gmxx_txx_stat6_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat6_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat6 cvmx_gmxx_txx_stat6_t;
@@ -11635,6 +11706,7 @@ union cvmx_gmxx_txx_stat7 {
 	struct cvmx_gmxx_txx_stat7_s          cn68xx;
 	struct cvmx_gmxx_txx_stat7_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat7_s          cn70xx;
+	struct cvmx_gmxx_txx_stat7_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat7_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat7 cvmx_gmxx_txx_stat7_t;
@@ -11685,6 +11757,7 @@ union cvmx_gmxx_txx_stat8 {
 	struct cvmx_gmxx_txx_stat8_s          cn68xx;
 	struct cvmx_gmxx_txx_stat8_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat8_s          cn70xx;
+	struct cvmx_gmxx_txx_stat8_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat8_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat8 cvmx_gmxx_txx_stat8_t;
@@ -11733,6 +11806,7 @@ union cvmx_gmxx_txx_stat9 {
 	struct cvmx_gmxx_txx_stat9_s          cn68xx;
 	struct cvmx_gmxx_txx_stat9_s          cn68xxp1;
 	struct cvmx_gmxx_txx_stat9_s          cn70xx;
+	struct cvmx_gmxx_txx_stat9_s          cn70xxp1;
 	struct cvmx_gmxx_txx_stat9_s          cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stat9 cvmx_gmxx_txx_stat9_t;
@@ -11772,6 +11846,7 @@ union cvmx_gmxx_txx_stats_ctl {
 	struct cvmx_gmxx_txx_stats_ctl_s      cn68xx;
 	struct cvmx_gmxx_txx_stats_ctl_s      cn68xxp1;
 	struct cvmx_gmxx_txx_stats_ctl_s      cn70xx;
+	struct cvmx_gmxx_txx_stats_ctl_s      cn70xxp1;
 	struct cvmx_gmxx_txx_stats_ctl_s      cnf71xx;
 };
 typedef union cvmx_gmxx_txx_stats_ctl cvmx_gmxx_txx_stats_ctl_t;
@@ -11849,6 +11924,7 @@ union cvmx_gmxx_txx_thresh {
 	struct cvmx_gmxx_txx_thresh_s         cn68xx;
 	struct cvmx_gmxx_txx_thresh_s         cn68xxp1;
 	struct cvmx_gmxx_txx_thresh_cn38xx    cn70xx;
+	struct cvmx_gmxx_txx_thresh_cn38xx    cn70xxp1;
 	struct cvmx_gmxx_txx_thresh_cn38xx    cnf71xx;
 };
 typedef union cvmx_gmxx_txx_thresh cvmx_gmxx_txx_thresh_t;
@@ -11904,6 +11980,7 @@ union cvmx_gmxx_tx_bp {
 	struct cvmx_gmxx_tx_bp_s              cn68xx;
 	struct cvmx_gmxx_tx_bp_s              cn68xxp1;
 	struct cvmx_gmxx_tx_bp_s              cn70xx;
+	struct cvmx_gmxx_tx_bp_s              cn70xxp1;
 	struct cvmx_gmxx_tx_bp_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
@@ -11976,6 +12053,7 @@ union cvmx_gmxx_tx_col_attempt {
 	struct cvmx_gmxx_tx_col_attempt_s     cn68xx;
 	struct cvmx_gmxx_tx_col_attempt_s     cn68xxp1;
 	struct cvmx_gmxx_tx_col_attempt_s     cn70xx;
+	struct cvmx_gmxx_tx_col_attempt_s     cn70xxp1;
 	struct cvmx_gmxx_tx_col_attempt_s     cnf71xx;
 };
 typedef union cvmx_gmxx_tx_col_attempt cvmx_gmxx_tx_col_attempt_t;
@@ -12036,6 +12114,7 @@ union cvmx_gmxx_tx_corrupt {
 	struct cvmx_gmxx_tx_corrupt_s         cn68xx;
 	struct cvmx_gmxx_tx_corrupt_s         cn68xxp1;
 	struct cvmx_gmxx_tx_corrupt_s         cn70xx;
+	struct cvmx_gmxx_tx_corrupt_s         cn70xxp1;
 	struct cvmx_gmxx_tx_corrupt_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
@@ -12085,6 +12164,7 @@ union cvmx_gmxx_tx_hg2_reg1 {
 	struct cvmx_gmxx_tx_hg2_reg1_s        cn68xx;
 	struct cvmx_gmxx_tx_hg2_reg1_s        cn68xxp1;
 	struct cvmx_gmxx_tx_hg2_reg1_s        cn70xx;
+	struct cvmx_gmxx_tx_hg2_reg1_s        cn70xxp1;
 	struct cvmx_gmxx_tx_hg2_reg1_s        cnf71xx;
 };
 typedef union cvmx_gmxx_tx_hg2_reg1 cvmx_gmxx_tx_hg2_reg1_t;
@@ -12124,6 +12204,7 @@ union cvmx_gmxx_tx_hg2_reg2 {
 	struct cvmx_gmxx_tx_hg2_reg2_s        cn68xx;
 	struct cvmx_gmxx_tx_hg2_reg2_s        cn68xxp1;
 	struct cvmx_gmxx_tx_hg2_reg2_s        cn70xx;
+	struct cvmx_gmxx_tx_hg2_reg2_s        cn70xxp1;
 	struct cvmx_gmxx_tx_hg2_reg2_s        cnf71xx;
 };
 typedef union cvmx_gmxx_tx_hg2_reg2 cvmx_gmxx_tx_hg2_reg2_t;
@@ -12188,6 +12269,7 @@ union cvmx_gmxx_tx_ifg {
 	struct cvmx_gmxx_tx_ifg_s             cn68xx;
 	struct cvmx_gmxx_tx_ifg_s             cn68xxp1;
 	struct cvmx_gmxx_tx_ifg_s             cn70xx;
+	struct cvmx_gmxx_tx_ifg_s             cn70xxp1;
 	struct cvmx_gmxx_tx_ifg_s             cnf71xx;
 };
 typedef union cvmx_gmxx_tx_ifg cvmx_gmxx_tx_ifg_t;
@@ -12415,6 +12497,7 @@ union cvmx_gmxx_tx_int_en {
 	} cn68xx;
 	struct cvmx_gmxx_tx_int_en_cn68xx     cn68xxp1;
 	struct cvmx_gmxx_tx_int_en_s          cn70xx;
+	struct cvmx_gmxx_tx_int_en_s          cn70xxp1;
 	struct cvmx_gmxx_tx_int_en_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
@@ -12680,6 +12763,7 @@ union cvmx_gmxx_tx_int_reg {
 	} cn68xx;
 	struct cvmx_gmxx_tx_int_reg_cn68xx    cn68xxp1;
 	struct cvmx_gmxx_tx_int_reg_s         cn70xx;
+	struct cvmx_gmxx_tx_int_reg_s         cn70xxp1;
 	struct cvmx_gmxx_tx_int_reg_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
@@ -12758,6 +12842,7 @@ union cvmx_gmxx_tx_jam {
 	struct cvmx_gmxx_tx_jam_s             cn68xx;
 	struct cvmx_gmxx_tx_jam_s             cn68xxp1;
 	struct cvmx_gmxx_tx_jam_s             cn70xx;
+	struct cvmx_gmxx_tx_jam_s             cn70xxp1;
 	struct cvmx_gmxx_tx_jam_s             cnf71xx;
 };
 typedef union cvmx_gmxx_tx_jam cvmx_gmxx_tx_jam_t;
@@ -12800,6 +12885,7 @@ union cvmx_gmxx_tx_lfsr {
 	struct cvmx_gmxx_tx_lfsr_s            cn68xx;
 	struct cvmx_gmxx_tx_lfsr_s            cn68xxp1;
 	struct cvmx_gmxx_tx_lfsr_s            cn70xx;
+	struct cvmx_gmxx_tx_lfsr_s            cn70xxp1;
 	struct cvmx_gmxx_tx_lfsr_s            cnf71xx;
 };
 typedef union cvmx_gmxx_tx_lfsr cvmx_gmxx_tx_lfsr_t;
@@ -12895,6 +12981,7 @@ union cvmx_gmxx_tx_ovr_bp {
 	struct cvmx_gmxx_tx_ovr_bp_s          cn68xx;
 	struct cvmx_gmxx_tx_ovr_bp_s          cn68xxp1;
 	struct cvmx_gmxx_tx_ovr_bp_s          cn70xx;
+	struct cvmx_gmxx_tx_ovr_bp_s          cn70xxp1;
 	struct cvmx_gmxx_tx_ovr_bp_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
@@ -12960,6 +13047,7 @@ union cvmx_gmxx_tx_pause_pkt_dmac {
 	struct cvmx_gmxx_tx_pause_pkt_dmac_s  cn68xx;
 	struct cvmx_gmxx_tx_pause_pkt_dmac_s  cn68xxp1;
 	struct cvmx_gmxx_tx_pause_pkt_dmac_s  cn70xx;
+	struct cvmx_gmxx_tx_pause_pkt_dmac_s  cn70xxp1;
 	struct cvmx_gmxx_tx_pause_pkt_dmac_s  cnf71xx;
 };
 typedef union cvmx_gmxx_tx_pause_pkt_dmac cvmx_gmxx_tx_pause_pkt_dmac_t;
@@ -12999,6 +13087,7 @@ union cvmx_gmxx_tx_pause_pkt_type {
 	struct cvmx_gmxx_tx_pause_pkt_type_s  cn68xx;
 	struct cvmx_gmxx_tx_pause_pkt_type_s  cn68xxp1;
 	struct cvmx_gmxx_tx_pause_pkt_type_s  cn70xx;
+	struct cvmx_gmxx_tx_pause_pkt_type_s  cn70xxp1;
 	struct cvmx_gmxx_tx_pause_pkt_type_s  cnf71xx;
 };
 typedef union cvmx_gmxx_tx_pause_pkt_type cvmx_gmxx_tx_pause_pkt_type_t;
@@ -13039,6 +13128,7 @@ union cvmx_gmxx_tx_prts {
 	struct cvmx_gmxx_tx_prts_s            cn68xx;
 	struct cvmx_gmxx_tx_prts_s            cn68xxp1;
 	struct cvmx_gmxx_tx_prts_s            cn70xx;
+	struct cvmx_gmxx_tx_prts_s            cn70xxp1;
 	struct cvmx_gmxx_tx_prts_s            cnf71xx;
 };
 typedef union cvmx_gmxx_tx_prts cvmx_gmxx_tx_prts_t;
@@ -13297,6 +13387,7 @@ union cvmx_gmxx_tx_xaui_ctl {
 	struct cvmx_gmxx_tx_xaui_ctl_s        cn68xx;
 	struct cvmx_gmxx_tx_xaui_ctl_s        cn68xxp1;
 	struct cvmx_gmxx_tx_xaui_ctl_s        cn70xx;
+	struct cvmx_gmxx_tx_xaui_ctl_s        cn70xxp1;
 	struct cvmx_gmxx_tx_xaui_ctl_s        cnf71xx;
 };
 typedef union cvmx_gmxx_tx_xaui_ctl cvmx_gmxx_tx_xaui_ctl_t;
@@ -13324,6 +13415,7 @@ union cvmx_gmxx_wol_ctl {
 #endif
 	} s;
 	struct cvmx_gmxx_wol_ctl_s            cn70xx;
+	struct cvmx_gmxx_wol_ctl_s            cn70xxp1;
 };
 typedef union cvmx_gmxx_wol_ctl cvmx_gmxx_wol_ctl_t;
 
@@ -13362,6 +13454,7 @@ union cvmx_gmxx_xaui_ext_loopback {
 	struct cvmx_gmxx_xaui_ext_loopback_s  cn68xx;
 	struct cvmx_gmxx_xaui_ext_loopback_s  cn68xxp1;
 	struct cvmx_gmxx_xaui_ext_loopback_s  cn70xx;
+	struct cvmx_gmxx_xaui_ext_loopback_s  cn70xxp1;
 	struct cvmx_gmxx_xaui_ext_loopback_s  cnf71xx;
 };
 typedef union cvmx_gmxx_xaui_ext_loopback cvmx_gmxx_xaui_ext_loopback_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-gpio-defs.h b/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
index 9205d3cd..d8b46bd 100644
--- a/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gpio-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -61,11 +61,11 @@ static inline uint64_t CVMX_GPIO_BIT_CFGX(unsigned long offset)
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
@@ -89,11 +89,11 @@ static inline uint64_t CVMX_GPIO_BIT_CFGX(unsigned long offset)
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN56XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN68XX & OCTEON_FAMILY_MASK:
@@ -451,6 +451,7 @@ union cvmx_gpio_bit_cfgx {
 	uint64_t reserved_21_63               : 43;
 #endif
 	} cn70xx;
+	struct cvmx_gpio_bit_cfgx_cn70xx      cn70xxp1;
 	struct cvmx_gpio_bit_cfgx_cn70xx      cn78xx;
 	struct cvmx_gpio_bit_cfgx_cn61xx      cnf71xx;
 };
@@ -507,6 +508,7 @@ union cvmx_gpio_clk_genx {
 	struct cvmx_gpio_clk_genx_s           cn68xx;
 	struct cvmx_gpio_clk_genx_s           cn68xxp1;
 	struct cvmx_gpio_clk_genx_s           cn70xx;
+	struct cvmx_gpio_clk_genx_s           cn70xxp1;
 	struct cvmx_gpio_clk_genx_s           cn78xx;
 	struct cvmx_gpio_clk_genx_s           cnf71xx;
 };
@@ -610,28 +612,19 @@ typedef union cvmx_gpio_clk_qlmx cvmx_gpio_clk_qlmx_t;
  *
  * A QLM can be configured as a clock source. The GPIO block can support up to two unique clocks
  * to send out any GPIO pin as configured by GPIO_BIT_CFG(0..19)[SYNCE_SEL]. The clock can be
- * divided by 2, 4, 8 or 16 of the selected RX lane clock. The following table shows the clock
- * speed output for different modes.
+ * divided by 20, 40, 80 or 160 of the selected RX lane clock.
  */
 union cvmx_gpio_clk_syncex {
 	uint64_t u64;
 	struct cvmx_gpio_clk_syncex_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t div                          : 2;  /**< GPIO internal clock divider setting relative to QLM SERDES CLOCK_SYNCE.
-                                                         The maximum supported GPIO output frequency is 125 MHz.
+	uint64_t div                          : 2;  /**< GPIO internal clock divider setting relative to QLM SERDES CLOCK_SYNCE. The maximum
+                                                         supported GPIO output frequency is 125 MHz.
                                                          0x0 = Divide by 20.
                                                          0x1 = Divide by 40.
                                                          0x2 = Divide by 80.
-                                                         0x3 = Divide by 160.
-                                                         Speed    DIV20   DIV40   DIV80   DIV160
-                                                         [GHz]      [MHz]   [MHz]   [MHz]   [MHz]
-                                                         1.2500   62.50   31.25   15.63    7.81
-                                                         2.5000   125.00  62.50   31.25   15.63
-                                                         3.1250    ---    78.13   39.06   19.53
-                                                         5.0000    ---      125.00  62.50   31.25
-                                                         6.2500    ---      ---     78.13   39.06
-                                                         10.3125   ---      ---     ---     64.45 */
+                                                         0x3 = Divide by 160. */
 	uint64_t lane_sel                     : 2;  /**< Selects which RX lane clock from QLMx to use as the GPIO internal QLMx clock. */
 #else
 	uint64_t lane_sel                     : 2;
@@ -648,9 +641,16 @@ union cvmx_gpio_clk_syncex {
                                                          10 = DLM1
                                                          11 = DLM2 */
 	uint64_t reserved_3_7                 : 5;
-	uint64_t div                          : 1;  /**< Internal clock divider
-                                                         0=DIV2
-                                                         1=DIV4 */
+	uint64_t div                          : 1;  /**< GPIO internal clock divider setting relative to QLM SERDES CLOCK_SYNCE. The maximum
+                                                         supported GPIO output frequency is 125 MHz.
+                                                         0x0 = Divide by 20.
+                                                         0x1 = Divide by 40.
+                                                         Speed    DIV20   DIV40
+                                                         [GHz]    [MHz]   [MHz]
+                                                         1.2500   62.50   31.25
+                                                         2.5000   125.00  62.50
+                                                         3.1250    ---    78.13
+                                                         5.0000    ---    125.00 */
 	uint64_t reserved_1_1                 : 1;
 	uint64_t lane_sel                     : 1;  /**< Selects which RX lane clock from DLMx to use as
                                                          the GPIO internal DLMx clock.  The GPIO block can
@@ -668,25 +668,18 @@ union cvmx_gpio_clk_syncex {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} cn70xx;
+	struct cvmx_gpio_clk_syncex_cn70xx    cn70xxp1;
 	struct cvmx_gpio_clk_syncex_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
 	uint64_t qlm_sel                      : 4;  /**< Selects which QLM(0..7) to select from. */
 	uint64_t reserved_4_7                 : 4;
-	uint64_t div                          : 2;  /**< GPIO internal clock divider setting relative to QLM SERDES CLOCK_SYNCE.
-                                                         The maximum supported GPIO output frequency is 125 MHz.
+	uint64_t div                          : 2;  /**< GPIO internal clock divider setting relative to QLM SERDES CLOCK_SYNCE. The maximum
+                                                         supported GPIO output frequency is 125 MHz.
                                                          0x0 = Divide by 20.
                                                          0x1 = Divide by 40.
                                                          0x2 = Divide by 80.
-                                                         0x3 = Divide by 160.
-                                                         Speed    DIV20   DIV40   DIV80   DIV160
-                                                         [GHz]      [MHz]   [MHz]   [MHz]   [MHz]
-                                                         1.2500   62.50   31.25   15.63    7.81
-                                                         2.5000   125.00  62.50   31.25   15.63
-                                                         3.1250    ---    78.13   39.06   19.53
-                                                         5.0000    ---      125.00  62.50   31.25
-                                                         6.2500    ---      ---     78.13   39.06
-                                                         10.3125   ---      ---     ---     64.45 */
+                                                         0x3 = Divide by 160. */
 	uint64_t lane_sel                     : 2;  /**< Selects which RX lane clock from QLMx to use as the GPIO internal QLMx clock. */
 #else
 	uint64_t lane_sel                     : 2;
@@ -782,6 +775,7 @@ union cvmx_gpio_int_clr {
 	struct cvmx_gpio_int_clr_s            cn68xx;
 	struct cvmx_gpio_int_clr_s            cn68xxp1;
 	struct cvmx_gpio_int_clr_s            cn70xx;
+	struct cvmx_gpio_int_clr_s            cn70xxp1;
 	struct cvmx_gpio_int_clr_s            cnf71xx;
 };
 typedef union cvmx_gpio_int_clr cvmx_gpio_int_clr_t;
@@ -857,6 +851,7 @@ union cvmx_gpio_multi_cast {
 	} s;
 	struct cvmx_gpio_multi_cast_s         cn61xx;
 	struct cvmx_gpio_multi_cast_s         cn70xx;
+	struct cvmx_gpio_multi_cast_s         cn70xxp1;
 	struct cvmx_gpio_multi_cast_s         cn78xx;
 	struct cvmx_gpio_multi_cast_s         cnf71xx;
 };
@@ -880,6 +875,7 @@ union cvmx_gpio_ocla_exten_trig {
 #endif
 	} s;
 	struct cvmx_gpio_ocla_exten_trig_s    cn70xx;
+	struct cvmx_gpio_ocla_exten_trig_s    cn70xxp1;
 	struct cvmx_gpio_ocla_exten_trig_s    cn78xx;
 };
 typedef union cvmx_gpio_ocla_exten_trig cvmx_gpio_ocla_exten_trig_t;
@@ -964,6 +960,7 @@ union cvmx_gpio_rx_dat {
 	struct cvmx_gpio_rx_dat_cn38xx        cn68xx;
 	struct cvmx_gpio_rx_dat_cn38xx        cn68xxp1;
 	struct cvmx_gpio_rx_dat_cn61xx        cn70xx;
+	struct cvmx_gpio_rx_dat_cn61xx        cn70xxp1;
 	struct cvmx_gpio_rx_dat_cn61xx        cn78xx;
 	struct cvmx_gpio_rx_dat_cn61xx        cnf71xx;
 };
@@ -1005,6 +1002,7 @@ union cvmx_gpio_sata_ctl {
 #endif
 	} s;
 	struct cvmx_gpio_sata_ctl_s           cn70xx;
+	struct cvmx_gpio_sata_ctl_s           cn70xxp1;
 };
 typedef union cvmx_gpio_sata_ctl cvmx_gpio_sata_ctl_t;
 
@@ -1088,6 +1086,7 @@ union cvmx_gpio_tx_clr {
 	struct cvmx_gpio_tx_clr_cn38xx        cn68xx;
 	struct cvmx_gpio_tx_clr_cn38xx        cn68xxp1;
 	struct cvmx_gpio_tx_clr_cn61xx        cn70xx;
+	struct cvmx_gpio_tx_clr_cn61xx        cn70xxp1;
 	struct cvmx_gpio_tx_clr_cn61xx        cn78xx;
 	struct cvmx_gpio_tx_clr_cn61xx        cnf71xx;
 };
@@ -1145,6 +1144,7 @@ union cvmx_gpio_tx_set {
 	struct cvmx_gpio_tx_set_cn38xx        cn68xx;
 	struct cvmx_gpio_tx_set_cn38xx        cn68xxp1;
 	struct cvmx_gpio_tx_set_cn61xx        cn70xx;
+	struct cvmx_gpio_tx_set_cn61xx        cn70xxp1;
 	struct cvmx_gpio_tx_set_cn61xx        cn78xx;
 	struct cvmx_gpio_tx_set_cn61xx        cnf71xx;
 };
@@ -1182,6 +1182,7 @@ union cvmx_gpio_usbh_ctl {
 	uint64_t reserved_13_63               : 51;
 #endif
 	} cn70xx;
+	struct cvmx_gpio_usbh_ctl_cn70xx      cn70xxp1;
 	struct cvmx_gpio_usbh_ctl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
@@ -1321,6 +1322,7 @@ union cvmx_gpio_xbit_cfgx {
 	uint64_t reserved_21_63               : 43;
 #endif
 	} cn70xx;
+	struct cvmx_gpio_xbit_cfgx_cn70xx     cn70xxp1;
 	struct cvmx_gpio_xbit_cfgx_cn61xx     cnf71xx;
 };
 typedef union cvmx_gpio_xbit_cfgx cvmx_gpio_xbit_cfgx_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
index ef9aa82..be60cd7 100644
--- a/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-gserx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -86,17 +86,6 @@ static inline uint64_t CVMX_GSERX_BR_RXX_CTL(unsigned long offset, unsigned long
 #define CVMX_GSERX_BR_RXX_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000400ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_BR_RXX_CU(unsigned long offset, unsigned long block_id)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
-		cvmx_warn("CVMX_GSERX_BR_RXX_CU(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x0001180090000408ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
-}
-#else
-#define CVMX_GSERX_BR_RXX_CU(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000408ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_BR_RXX_EER(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -108,17 +97,6 @@ static inline uint64_t CVMX_GSERX_BR_RXX_EER(unsigned long offset, unsigned long
 #define CVMX_GSERX_BR_RXX_EER(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000418ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_BR_RXX_SR(unsigned long offset, unsigned long block_id)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
-		cvmx_warn("CVMX_GSERX_BR_RXX_SR(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x0001180090000410ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
-}
-#else
-#define CVMX_GSERX_BR_RXX_SR(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000410ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_BR_TXX_CTL(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -130,17 +108,6 @@ static inline uint64_t CVMX_GSERX_BR_TXX_CTL(unsigned long offset, unsigned long
 #define CVMX_GSERX_BR_TXX_CTL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000420ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_BR_TXX_CU(unsigned long offset, unsigned long block_id)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
-		cvmx_warn("CVMX_GSERX_BR_TXX_CU(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x0001180090000428ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
-}
-#else
-#define CVMX_GSERX_BR_TXX_CU(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000428ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_BR_TXX_CUR(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -152,17 +119,6 @@ static inline uint64_t CVMX_GSERX_BR_TXX_CUR(unsigned long offset, unsigned long
 #define CVMX_GSERX_BR_TXX_CUR(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000438ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_BR_TXX_SR(unsigned long offset, unsigned long block_id)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
-		cvmx_warn("CVMX_GSERX_BR_TXX_SR(%lu,%lu) is invalid on this chip\n", offset, block_id);
-	return CVMX_ADD_IO_SEG(0x0001180090000430ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128;
-}
-#else
-#define CVMX_GSERX_BR_TXX_SR(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000430ull) + (((offset) & 3) + ((block_id) & 15) * 0x20000ull) * 128)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_CFG(unsigned long block_id)
 {
 	if (!(
@@ -548,6 +504,39 @@ static inline uint64_t CVMX_GSERX_IDDQ_MODE(unsigned long block_id)
 #define CVMX_GSERX_IDDQ_MODE(block_id) (CVMX_ADD_IO_SEG(0x0001180090000018ull) + ((block_id) & 15) * 0x1000000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_LBERT_CFG(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_LBERT_CFG(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904C0020ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_LBERT_CFG(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904C0020ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_LBERT_ECNT(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_LBERT_ECNT(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904C0028ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_LBERT_ECNT(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904C0028ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_LBERT_PAT_CFG(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_LBERT_PAT_CFG(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904C0018ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_LBERT_PAT_CFG(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904C0018ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_LANEX_PX_MODE_0(unsigned long a, unsigned long b, unsigned long c)
 {
 	if (!(
@@ -636,6 +625,61 @@ static inline uint64_t CVMX_GSERX_LANEX_RX_VMA_CTRL(unsigned long offset, unsign
 #define CVMX_GSERX_LANEX_RX_VMA_CTRL(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090440200ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_TX_CFG_0(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_TX_CFG_0(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904400A8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_TX_CFG_0(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904400A8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_TX_CFG_1(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_TX_CFG_1(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904400B0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_TX_CFG_1(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904400B0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_TX_CFG_2(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_TX_CFG_2(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904400B8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_TX_CFG_2(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904400B8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_TX_CFG_3(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_TX_CFG_3(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904400C0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_TX_CFG_3(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904400C0ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_GSERX_LANEX_TX_PRE_EMPHASIS(unsigned long offset, unsigned long block_id)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && (((offset <= 3)) && ((block_id <= 13))))))
+		cvmx_warn("CVMX_GSERX_LANEX_TX_PRE_EMPHASIS(%lu,%lu) is invalid on this chip\n", offset, block_id);
+	return CVMX_ADD_IO_SEG(0x00011800904400C8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576;
+}
+#else
+#define CVMX_GSERX_LANEX_TX_PRE_EMPHASIS(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800904400C8ull) + (((offset) & 3) + ((block_id) & 15) * 0x10ull) * 1048576)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_LANEX_VMA_COARSE_CTRL_0(unsigned long offset, unsigned long block_id)
 {
 	if (!(
@@ -1197,17 +1241,6 @@ static inline uint64_t CVMX_GSERX_REFCLK_SEL(unsigned long block_id)
 #define CVMX_GSERX_REFCLK_SEL(block_id) (CVMX_ADD_IO_SEG(0x0001180090000008ull) + ((block_id) & 15) * 0x1000000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_RXTX_STAT(unsigned long block_id)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 13)))))
-		cvmx_warn("CVMX_GSERX_RXTX_STAT(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x0001180090000140ull) + ((block_id) & 15) * 0x1000000ull;
-}
-#else
-#define CVMX_GSERX_RXTX_STAT(block_id) (CVMX_ADD_IO_SEG(0x0001180090000140ull) + ((block_id) & 15) * 0x1000000ull)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_RX_COAST(unsigned long block_id)
 {
 	if (!(
@@ -1263,17 +1296,6 @@ static inline uint64_t CVMX_GSERX_RX_POLARITY(unsigned long block_id)
 #define CVMX_GSERX_RX_POLARITY(block_id) (CVMX_ADD_IO_SEG(0x0001180090000160ull) + ((block_id) & 15) * 0x1000000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_RX_PSTATE(unsigned long block_id)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 13)))))
-		cvmx_warn("CVMX_GSERX_RX_PSTATE(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x0001180090000128ull) + ((block_id) & 15) * 0x1000000ull;
-}
-#else
-#define CVMX_GSERX_RX_PSTATE(block_id) (CVMX_ADD_IO_SEG(0x0001180090000128ull) + ((block_id) & 15) * 0x1000000ull)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_SATA_CFG(unsigned long block_id)
 {
 	if (!(
@@ -1450,17 +1472,6 @@ static inline uint64_t CVMX_GSERX_SRST(unsigned long block_id)
 #define CVMX_GSERX_SRST(block_id) (CVMX_ADD_IO_SEG(0x0001180090000090ull) + ((block_id) & 15) * 0x1000000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_GSERX_TX_PSTATE(unsigned long block_id)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 13)))))
-		cvmx_warn("CVMX_GSERX_TX_PSTATE(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x0001180090000120ull) + ((block_id) & 15) * 0x1000000ull;
-}
-#else
-#define CVMX_GSERX_TX_PSTATE(block_id) (CVMX_ADD_IO_SEG(0x0001180090000120ull) + ((block_id) & 15) * 0x1000000ull)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_GSERX_TX_VBOOST(unsigned long block_id)
 {
 	if (!(
@@ -1532,13 +1543,13 @@ union cvmx_gserx_br_rxx_ctl {
 	uint64_t rxt_preset                   : 1;  /**< For all link training, this bit determines how to configure the preset bit in the
                                                          coefficient update message that is sent to the far end transmitter. When set, a one time
                                                          request is made that the coefficients be set to a state where equalization is turned off.
-                                                         To perform a preset, set this bit prior to link training. link training needs to be
-                                                         disabled to complete the request and get the rxtrain state machine back to IDLE. Note that
+                                                         To perform a preset, set this bit prior to link training. Link training needs to be
+                                                         disabled to complete the request and get the rxtrain state machine back to idle. Note that
                                                          it is illegal to set both the preset and initialize bits at the same time. For diagnostic
                                                          use only. */
 	uint64_t rxt_initialize               : 1;  /**< For all link training, this bit determines how to configure the initialize bit in the
                                                          coefficient update message that is sent to the far end transmitter of RX training. When
-                                                         set, a request is made that the coefficients be set to its INITIALIZE state. To perform a
+                                                         set, a request is made that the coefficients be set to its INITIALIZE state. To perform an
                                                          initialize prior to link training, set this bit prior to performing link training. Note
                                                          that it is illegal to set both the preset and initialize bits at the same time. Since the
                                                          far end transmitter is required to be initialized prior to starting link training, it is
@@ -1555,26 +1566,6 @@ union cvmx_gserx_br_rxx_ctl {
 typedef union cvmx_gserx_br_rxx_ctl cvmx_gserx_br_rxx_ctl_t;
 
 /**
- * cvmx_gser#_br_rx#_cu
- */
-union cvmx_gserx_br_rxx_cu {
-	uint64_t u64;
-	struct cvmx_gserx_br_rxx_cu_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
-	uint64_t rxt_cu                       : 9;  /**< When RX Base-R Link Training is being performed under software control,
-                                                         (GSER(0..13)_BR_RX(0..3)_CTL[RXT_SWM] is set), this is the coefficient update message to
-                                                         send to the MAC (BGX/OCI). For diagnostic use only. */
-#else
-	uint64_t rxt_cu                       : 9;
-	uint64_t reserved_9_63                : 55;
-#endif
-	} s;
-	struct cvmx_gserx_br_rxx_cu_s         cn78xx;
-};
-typedef union cvmx_gserx_br_rxx_cu cvmx_gserx_br_rxx_cu_t;
-
-/**
  * cvmx_gser#_br_rx#_eer
  *
  * GSER software Base-R RX Link Training equalization evaluation request (EER). A write to
@@ -1593,8 +1584,8 @@ union cvmx_gserx_br_rxx_eer {
 	uint64_t rxt_esv                      : 1;  /**< When performing an equalization request (RXT_EER), this bit, when set, indicates that the
                                                          Equalization Status (RXT_ESM) is valid. When issuing a RXT_EER request, it is expected
                                                          that RXT_ESV will get written to zero so that a valid RXT_ESM can be determined. */
-	uint64_t rxt_esm                      : 14; /**< When performing a equalization request (RXT_EER), this is the equalization status message
-                                                         from the RAW PCS. It is valid with RXT_ESV is set.
+	uint64_t rxt_esm                      : 14; /**< When performing an equalization request (RXT_EER), this is the equalization status message
+                                                         from the RAW PCS. It is valid when RXT_ESV is set.
                                                          <13:6>: Figure of merit. An 8-bit output from the PHY indicating the quality of the
                                                          received data eye. A higher value indicates better link equalization, with 8'd0 indicating
                                                          worst equalization setting and 8'd255 indicating the best equalization setting.
@@ -1619,26 +1610,6 @@ union cvmx_gserx_br_rxx_eer {
 typedef union cvmx_gserx_br_rxx_eer cvmx_gserx_br_rxx_eer_t;
 
 /**
- * cvmx_gser#_br_rx#_sr
- */
-union cvmx_gserx_br_rxx_sr {
-	uint64_t u64;
-	struct cvmx_gserx_br_rxx_sr_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_6_63                : 58;
-	uint64_t rxt_sr                       : 6;  /**< When RX Base-R Link Training is being performed under software control,
-                                                         (GSER(0..13)_BR_RX(0..3)_CTL[RXT_SWM] is set), this is the status report message from the
-                                                         link partner. For diagnostic use only. */
-#else
-	uint64_t rxt_sr                       : 6;
-	uint64_t reserved_6_63                : 58;
-#endif
-	} s;
-	struct cvmx_gserx_br_rxx_sr_s         cn78xx;
-};
-typedef union cvmx_gserx_br_rxx_sr cvmx_gserx_br_rxx_sr_t;
-
-/**
  * cvmx_gser#_br_tx#_ctl
  */
 union cvmx_gserx_br_txx_ctl {
@@ -1658,26 +1629,6 @@ union cvmx_gserx_br_txx_ctl {
 typedef union cvmx_gserx_br_txx_ctl cvmx_gserx_br_txx_ctl_t;
 
 /**
- * cvmx_gser#_br_tx#_cu
- */
-union cvmx_gserx_br_txx_cu {
-	uint64_t u64;
-	struct cvmx_gserx_br_txx_cu_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_9_63                : 55;
-	uint64_t txt_cu                       : 9;  /**< When TX Base-R Link Training is being performed under software control,
-                                                         (GSER(0..13)_BR_TX(0..3)_CTL[TXT_SWM] is set), this is the coefficient update message from
-                                                         the link partner. For diagnostic use only. */
-#else
-	uint64_t txt_cu                       : 9;
-	uint64_t reserved_9_63                : 55;
-#endif
-	} s;
-	struct cvmx_gserx_br_txx_cu_s         cn78xx;
-};
-typedef union cvmx_gserx_br_txx_cu cvmx_gserx_br_txx_cu_t;
-
-/**
  * cvmx_gser#_br_tx#_cur
  */
 union cvmx_gserx_br_txx_cur {
@@ -1688,10 +1639,10 @@ union cvmx_gserx_br_txx_cur {
 	uint64_t txt_cur                      : 14; /**< When TX Base-R Link Training is being performed under software control,
                                                          (GSER_BR_TX(0..3)_CTL.TXT_SWM is set), this is the Coefficient Update to be written to the
                                                          PHY.
-                                                         Bits 13:9: TX_POST<4:0>
-                                                         Bits 8:4: TX_SWING<4:0>
-                                                         Bits 3:0: TX_PRE<4:0>
-                                                         For diagnostic use only. */
+                                                         For diagnostic use only.
+                                                         <13:9> = TX_POST<4:0>.
+                                                         <8:4> = TX_SWING<4:0>.
+                                                         <3:0> = TX_PRE<4:0>. */
 #else
 	uint64_t txt_cur                      : 14;
 	uint64_t reserved_14_63               : 50;
@@ -1702,27 +1653,6 @@ union cvmx_gserx_br_txx_cur {
 typedef union cvmx_gserx_br_txx_cur cvmx_gserx_br_txx_cur_t;
 
 /**
- * cvmx_gser#_br_tx#_sr
- */
-union cvmx_gserx_br_txx_sr {
-	uint64_t u64;
-	struct cvmx_gserx_br_txx_sr_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_6_63                : 58;
-	uint64_t txt_sr                       : 6;  /**< When TX Base-R Link Training is being performed under software control,
-                                                         (GSER(0..13)_BR_TX(0..3)_CTL[TXT_SWM] is set), this is the status report (SR) message to
-                                                         be sent to the link partner. Writing this register causes a new SR message to be sent to
-                                                         the MAC (BGX/OCI) to be forwarded to the link partner. For diagnostic use only. */
-#else
-	uint64_t txt_sr                       : 6;
-	uint64_t reserved_6_63                : 58;
-#endif
-	} s;
-	struct cvmx_gserx_br_txx_sr_s         cn78xx;
-};
-typedef union cvmx_gserx_br_txx_sr cvmx_gserx_br_txx_sr_t;
-
-/**
  * cvmx_gser#_cfg
  */
 union cvmx_gserx_cfg {
@@ -1738,9 +1668,9 @@ union cvmx_gserx_cfg {
                                                          for lanes 2 and 3. For OCI links, this bit has no meaning. */
 	uint64_t bgx                          : 1;  /**< For non-OCI links, indicates the GSER is configured for BGX mode. Only one of the BGX,
                                                          ILA, or PCIE modes can be set at any one time. For OCI links, this bit has no meaning. */
-	uint64_t ila                          : 1;  /**< For non-OCI links, indicates the GSER is configured for ILK/ILA mode. For OCI links
-                                                         this bit will be set.  Only one of the BGX, ILA, or PCIE modes can be set at any
-                                                         one time. For OCI links, this bit has no meaning. */
+	uint64_t ila                          : 1;  /**< For non-OCI links, indicates the GSER is configured for ILK/ILA mode. For OCI links this
+                                                         bit will be set. Only one of the BGX, ILA, or PCIE modes can be set at any one time. For
+                                                         OCI links, this bit has no meaning. */
 	uint64_t pcie                         : 1;  /**< For non-OCI links, indicates the GSER is configured for PCIE mode. Only one of the BGX,
                                                          ILA, or PCIE modes can be set at any one time. For OCI links, this bit has no meaning. */
 #else
@@ -1803,6 +1733,7 @@ union cvmx_gserx_dlmx_loopbk_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_loopbk_en_s    cn70xx;
+	struct cvmx_gserx_dlmx_loopbk_en_s    cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_loopbk_en cvmx_gserx_dlmx_loopbk_en_t;
 
@@ -1836,6 +1767,7 @@ union cvmx_gserx_dlmx_los_bias {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_los_bias_s     cn70xx;
+	struct cvmx_gserx_dlmx_los_bias_s     cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_los_bias cvmx_gserx_dlmx_los_bias_t;
 
@@ -1858,6 +1790,7 @@ union cvmx_gserx_dlmx_los_level {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_los_level_s    cn70xx;
+	struct cvmx_gserx_dlmx_los_level_s    cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_los_level cvmx_gserx_dlmx_los_level_t;
 
@@ -1885,6 +1818,7 @@ union cvmx_gserx_dlmx_misc_status {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_misc_status_s  cn70xx;
+	struct cvmx_gserx_dlmx_misc_status_s  cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_misc_status cvmx_gserx_dlmx_misc_status_t;
 
@@ -1906,6 +1840,7 @@ union cvmx_gserx_dlmx_mpll_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_mpll_en_s      cn70xx;
+	struct cvmx_gserx_dlmx_mpll_en_s      cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_mpll_en cvmx_gserx_dlmx_mpll_en_t;
 
@@ -1929,6 +1864,7 @@ union cvmx_gserx_dlmx_mpll_half_rate {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_mpll_half_rate_s cn70xx;
+	struct cvmx_gserx_dlmx_mpll_half_rate_s cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_mpll_half_rate cvmx_gserx_dlmx_mpll_half_rate_t;
 
@@ -1951,6 +1887,7 @@ union cvmx_gserx_dlmx_mpll_multiplier {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_mpll_multiplier_s cn70xx;
+	struct cvmx_gserx_dlmx_mpll_multiplier_s cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_mpll_multiplier cvmx_gserx_dlmx_mpll_multiplier_t;
 
@@ -1974,6 +1911,7 @@ union cvmx_gserx_dlmx_mpll_status {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_mpll_status_s  cn70xx;
+	struct cvmx_gserx_dlmx_mpll_status_s  cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_mpll_status cvmx_gserx_dlmx_mpll_status_t;
 
@@ -1998,6 +1936,7 @@ union cvmx_gserx_dlmx_phy_reset {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_phy_reset_s    cn70xx;
+	struct cvmx_gserx_dlmx_phy_reset_s    cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_phy_reset cvmx_gserx_dlmx_phy_reset_t;
 
@@ -2021,6 +1960,7 @@ union cvmx_gserx_dlmx_ref_clkdiv2 {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_ref_clkdiv2_s  cn70xx;
+	struct cvmx_gserx_dlmx_ref_clkdiv2_s  cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_ref_clkdiv2 cvmx_gserx_dlmx_ref_clkdiv2_t;
 
@@ -2042,6 +1982,7 @@ union cvmx_gserx_dlmx_ref_ssp_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_ref_ssp_en_s   cn70xx;
+	struct cvmx_gserx_dlmx_ref_ssp_en_s   cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_ref_ssp_en cvmx_gserx_dlmx_ref_ssp_en_t;
 
@@ -2067,6 +2008,7 @@ union cvmx_gserx_dlmx_ref_use_pad {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_ref_use_pad_s  cn70xx;
+	struct cvmx_gserx_dlmx_ref_use_pad_s  cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_ref_use_pad cvmx_gserx_dlmx_ref_use_pad_t;
 
@@ -2091,6 +2033,7 @@ union cvmx_gserx_dlmx_refclk_sel {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_refclk_sel_s   cn70xx;
+	struct cvmx_gserx_dlmx_refclk_sel_s   cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_refclk_sel cvmx_gserx_dlmx_refclk_sel_t;
 
@@ -2116,6 +2059,7 @@ union cvmx_gserx_dlmx_rx_data_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_rx_data_en_s   cn70xx;
+	struct cvmx_gserx_dlmx_rx_data_en_s   cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_rx_data_en cvmx_gserx_dlmx_rx_data_en_t;
 
@@ -2141,6 +2085,7 @@ union cvmx_gserx_dlmx_rx_eq {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_rx_eq_s        cn70xx;
+	struct cvmx_gserx_dlmx_rx_eq_s        cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_rx_eq cvmx_gserx_dlmx_rx_eq_t;
 
@@ -2166,6 +2111,7 @@ union cvmx_gserx_dlmx_rx_los_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_rx_los_en_s    cn70xx;
+	struct cvmx_gserx_dlmx_rx_los_en_s    cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_rx_los_en cvmx_gserx_dlmx_rx_los_en_t;
 
@@ -2191,6 +2137,7 @@ union cvmx_gserx_dlmx_rx_pll_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_rx_pll_en_s    cn70xx;
+	struct cvmx_gserx_dlmx_rx_pll_en_s    cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_rx_pll_en cvmx_gserx_dlmx_rx_pll_en_t;
 
@@ -2224,6 +2171,7 @@ union cvmx_gserx_dlmx_rx_rate {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_rx_rate_s      cn70xx;
+	struct cvmx_gserx_dlmx_rx_rate_s      cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_rx_rate cvmx_gserx_dlmx_rx_rate_t;
 
@@ -2249,6 +2197,7 @@ union cvmx_gserx_dlmx_rx_reset {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_rx_reset_s     cn70xx;
+	struct cvmx_gserx_dlmx_rx_reset_s     cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_rx_reset cvmx_gserx_dlmx_rx_reset_t;
 
@@ -2278,6 +2227,7 @@ union cvmx_gserx_dlmx_rx_status {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_rx_status_s    cn70xx;
+	struct cvmx_gserx_dlmx_rx_status_s    cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_rx_status cvmx_gserx_dlmx_rx_status_t;
 
@@ -2307,6 +2257,7 @@ union cvmx_gserx_dlmx_rx_term_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_rx_term_en_s   cn70xx;
+	struct cvmx_gserx_dlmx_rx_term_en_s   cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_rx_term_en cvmx_gserx_dlmx_rx_term_en_t;
 
@@ -2329,6 +2280,7 @@ union cvmx_gserx_dlmx_test_bypass {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_test_bypass_s  cn70xx;
+	struct cvmx_gserx_dlmx_test_bypass_s  cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_test_bypass cvmx_gserx_dlmx_test_bypass_t;
 
@@ -2350,6 +2302,7 @@ union cvmx_gserx_dlmx_test_powerdown {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_test_powerdown_s cn70xx;
+	struct cvmx_gserx_dlmx_test_powerdown_s cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_test_powerdown cvmx_gserx_dlmx_test_powerdown_t;
 
@@ -2377,6 +2330,7 @@ union cvmx_gserx_dlmx_tx_amplitude {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_amplitude_s cn70xx;
+	struct cvmx_gserx_dlmx_tx_amplitude_s cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_amplitude cvmx_gserx_dlmx_tx_amplitude_t;
 
@@ -2402,6 +2356,7 @@ union cvmx_gserx_dlmx_tx_cm_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_cm_en_s     cn70xx;
+	struct cvmx_gserx_dlmx_tx_cm_en_s     cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_cm_en cvmx_gserx_dlmx_tx_cm_en_t;
 
@@ -2427,6 +2382,7 @@ union cvmx_gserx_dlmx_tx_data_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_data_en_s   cn70xx;
+	struct cvmx_gserx_dlmx_tx_data_en_s   cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_data_en cvmx_gserx_dlmx_tx_data_en_t;
 
@@ -2452,6 +2408,7 @@ union cvmx_gserx_dlmx_tx_en {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_en_s        cn70xx;
+	struct cvmx_gserx_dlmx_tx_en_s        cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_en cvmx_gserx_dlmx_tx_en_t;
 
@@ -2477,6 +2434,7 @@ union cvmx_gserx_dlmx_tx_preemph {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_preemph_s   cn70xx;
+	struct cvmx_gserx_dlmx_tx_preemph_s   cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_preemph cvmx_gserx_dlmx_tx_preemph_t;
 
@@ -2510,6 +2468,7 @@ union cvmx_gserx_dlmx_tx_rate {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_rate_s      cn70xx;
+	struct cvmx_gserx_dlmx_tx_rate_s      cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_rate cvmx_gserx_dlmx_tx_rate_t;
 
@@ -2535,6 +2494,7 @@ union cvmx_gserx_dlmx_tx_reset {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_reset_s     cn70xx;
+	struct cvmx_gserx_dlmx_tx_reset_s     cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_reset cvmx_gserx_dlmx_tx_reset_t;
 
@@ -2570,6 +2530,7 @@ union cvmx_gserx_dlmx_tx_status {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_status_s    cn70xx;
+	struct cvmx_gserx_dlmx_tx_status_s    cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_status cvmx_gserx_dlmx_tx_status_t;
 
@@ -2597,14 +2558,15 @@ union cvmx_gserx_dlmx_tx_term_offset {
 #endif
 	} s;
 	struct cvmx_gserx_dlmx_tx_term_offset_s cn70xx;
+	struct cvmx_gserx_dlmx_tx_term_offset_s cn70xxp1;
 };
 typedef union cvmx_gserx_dlmx_tx_term_offset cvmx_gserx_dlmx_tx_term_offset_t;
 
 /**
  * cvmx_gser#_iddq_mode
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_iddq_mode {
 	uint64_t u64;
@@ -2622,12 +2584,138 @@ union cvmx_gserx_iddq_mode {
 typedef union cvmx_gserx_iddq_mode cvmx_gserx_iddq_mode_t;
 
 /**
+ * cvmx_gser#_lane#_lbert_cfg
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ */
+union cvmx_gserx_lanex_lbert_cfg {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_lbert_cfg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t lbert_pg_err_insert          : 1;  /**< Insert one bit error into the LSB of the LBERT generated
+                                                         stream.  A single write to this bit inserts a single bit
+                                                         error. */
+	uint64_t lbert_pm_sync_start          : 1;  /**< Synchronize the pattern matcher LFSR with the incoming
+                                                         data.  Writing this bit resets the error counter and
+                                                         starts a synchronization of the PM.  There is no need
+                                                         to write this bit back to a zero to run normally. */
+	uint64_t lbert_pg_en                  : 1;  /**< Enable the LBERT pattern generator. */
+	uint64_t lbert_pg_width               : 2;  /**< LBERT pattern generator data width:
+                                                         0x0 = 8-bit data.
+                                                         0x1 = 10-bit data.
+                                                         0x2 = 16-bit data.
+                                                         0x3 = 20-bit data. */
+	uint64_t lbert_pg_mode                : 4;  /**< LBERT pattern generator mode; when changing modes,
+                                                         must be disabled first:
+                                                         0x0 = Disabled.
+                                                         0x1 = lfsr31   X^31 + X^28 + 1.
+                                                         0x2 = lfsr23   X^23 + X^18 + 1.
+                                                         0x3 = lfsr23   X^23 + X^21 + X^16 + X^8 + X^5 + X^2 + 1.
+                                                         0x4 = lfsr16   X^16 + X^5 + X^4 + X^3 + 1.
+                                                         0x5 = lfsr15   X^15 + X^14 + 1.
+                                                         0x6 = lfsr11   X^11 + X^9 + 1.
+                                                         0x7 = lfsr7    X^7 + X^6 + 1.
+                                                         0x8 = Fixed word (PAT0).
+                                                         0x9 = DC-balanced word (PAT0, ~PAT0)
+                                                         0xA = Fixed Pattern (000, PAT0, 3ff, ~PAT0).
+                                                         0xB-F = Reserved. */
+	uint64_t lbert_pm_en                  : 1;  /**< Enable LBERT pattern matcher. */
+	uint64_t lbert_pm_width               : 2;  /**< LBERT pattern matcher data width.
+                                                         0x0 = 8-bit data.
+                                                         0x1 = 10-bit data.
+                                                         0x2 = 16-bit data.
+                                                         0x3 = 20-bit data. */
+	uint64_t lbert_pm_mode                : 4;  /**< LBERT pattern matcher mode; when changing modes,
+                                                         must be disabled first:
+                                                         0x0 = Disabled.
+                                                         0x1 = lfsr31   X^31 + X^28 + 1.
+                                                         0x2 = lfsr23   X^23 + X^18 + 1.
+                                                         0x3 = lfsr23   X^23 + X^21 + X^16 + X^8 + X^5 + X^2 + 1.
+                                                         0x4 = lfsr16   X^16 + X^5 + X^4 + X^3 + 1.
+                                                         0x5 = lfsr15   X^15 + X^14 + 1.
+                                                         0x6 = lfsr11   X^11 + X^9 + 1.
+                                                         0x7 = lfsr7    X^7 + X^6 + 1.
+                                                         0x8 = Fixed word (PAT0).
+                                                         0x9 = DC-balanced word (PAT0, ~PAT0).
+                                                         0xA = Fixed Pattern: (000, PAT0, 3ff, ~PAT0).
+                                                         0xB-F = Reserved. */
+#else
+	uint64_t lbert_pm_mode                : 4;
+	uint64_t lbert_pm_width               : 2;
+	uint64_t lbert_pm_en                  : 1;
+	uint64_t lbert_pg_mode                : 4;
+	uint64_t lbert_pg_width               : 2;
+	uint64_t lbert_pg_en                  : 1;
+	uint64_t lbert_pm_sync_start          : 1;
+	uint64_t lbert_pg_err_insert          : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_lbert_cfg_s   cn78xx;
+};
+typedef union cvmx_gserx_lanex_lbert_cfg cvmx_gserx_lanex_lbert_cfg_t;
+
+/**
+ * cvmx_gser#_lane#_lbert_ecnt
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * The error registers are reset on a read-only when the pattern matcher is enabled.
+ * If the pattern matcher is disabled, the registers return the error count that was
+ * indicated when the pattern matcher was disabled and never reset.
+ */
+union cvmx_gserx_lanex_lbert_ecnt {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_lbert_ecnt_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t lbert_err_ovbit14            : 1;  /**< If this bit is set, multiply LBERT_ERR_CNT by 128.
+                                                         If this bit is set and LBERT_ERR_CNT = 2^15-1, signals
+                                                         overflow of the counter. */
+	uint64_t lbert_err_cnt                : 15; /**< Current error count.
+                                                         If LBERT_ERR_OVBIT14 field is active, then multiply
+                                                         count by 128. */
+#else
+	uint64_t lbert_err_cnt                : 15;
+	uint64_t lbert_err_ovbit14            : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_lbert_ecnt_s  cn78xx;
+};
+typedef union cvmx_gserx_lanex_lbert_ecnt cvmx_gserx_lanex_lbert_ecnt_t;
+
+/**
+ * cvmx_gser#_lane#_lbert_pat_cfg
+ *
+ * These registers are only reset by hardware during chip cold reset.
+ * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ */
+union cvmx_gserx_lanex_lbert_pat_cfg {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_lbert_pat_cfg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_10_63               : 54;
+	uint64_t lbert_pg_pat                 : 10; /**< Programmable 10-bit pattern to be used in the LBERT pattern mode;
+                                                         applies when GSER(0..13)_LANE(0..3)_LBERT_CFG[LBERT_PG_MODE]
+                                                         is equal to 8, 9, or 10. */
+#else
+	uint64_t lbert_pg_pat                 : 10;
+	uint64_t reserved_10_63               : 54;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_lbert_pat_cfg_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_lbert_pat_cfg cvmx_gserx_lanex_lbert_pat_cfg_t;
+
+/**
  * cvmx_gser#_lane#_p#_mode_0
  *
  * These are the RAW PCS per lane settings mode 0 registers. There is one register per
- * lane (0..3) per GSER per GSER_LMODE_E (0..11). Only one entry is used at any given
- * time in a given GSER lane - the one selected by the corresponding
- * GSER(0..13)_LANE_MODE[LMODE].
+ * lane (0..3) per GSER per GSER_LMODE_E (0..11). Only one entry is used at any given time in a
+ * given GSER lane - the one selected by the corresponding GSER(0..13)_LANE_MODE[LMODE].
  * These registers are only reset by hardware during chip cold reset.
  * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
@@ -2745,10 +2833,9 @@ typedef union cvmx_gserx_lanex_px_mode_0 cvmx_gserx_lanex_px_mode_0_t;
 /**
  * cvmx_gser#_lane#_p#_mode_1
  *
- * These are the RAW PCS per lane settings mode 1 registers. There is one register per
- * lane (0..3) per GSER per GSER_LMODE_E (0..11). Only one entry is used at any given
- * time in a given GSER lane - the one selected by the corresponding
- * GSER(0..13)_LANE_MODE[LMODE].
+ * These are the RAW PCS per lane settings mode 1 registers. There is one register per lane
+ * (0..3) per GSER per GSER_LMODE_E (0..11). Only one entry is used at any given time in a given
+ * GSER lane - the one selected by the corresponding GSER(0..13)_LANE_MODE[LMODE].
  * These registers are only reset by hardware during chip cold reset.
  * The values of the CSR fields in these registers do not change during chip warm or soft resets.
  */
@@ -2758,12 +2845,11 @@ union cvmx_gserx_lanex_px_mode_1 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t vma_fine_cfg_sel             : 1;  /**< Recommended settings:
-                                                         1 = Enabled. Fine step adaptation selected (10.3125 Gbps rate).
-                                                         0 = Disabled. Coarse step adaptation selected (rates lower than 10.3125 Gbps). */
-	uint64_t vma_mm                       : 1;  /**< Manual DFE verses adaptive DFE mode.
-                                                         Recommended settings:
-                                                         0 = Adaptive DFE (5 Gbps and higher)
-                                                         1 = Manual DFE, fixed tap (3.125 Gbps and lower). */
+                                                         1 = Enabled. Fine step adaptation selected (10.3125 Gbaud rate).
+                                                         0 = Disabled. Coarse step adaptation selected (rates lower than 10.3125 Gbaud). */
+	uint64_t vma_mm                       : 1;  /**< Manual DFE verses adaptive DFE mode. Recommended settings:
+                                                         0 = Adaptive DFE (5 Gbaud and higher)
+                                                         1 = Manual DFE, fixed tap (3.125 Gbaud and lower). */
 	uint64_t cdr_fgain                    : 4;  /**< CDR frequency gain.
                                                          Recommended settings:
                                                          R_25G_REFCLK100:          0xA
@@ -2808,8 +2894,8 @@ typedef union cvmx_gserx_lanex_px_mode_1 cvmx_gserx_lanex_px_mode_1_t;
  * cvmx_gser#_lane#_rx_ctle_ctrl
  *
  * These are the RAW PCS per-lane RX CTLE control registers.
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_ctle_ctrl {
 	uint64_t u64;
@@ -2817,10 +2903,10 @@ union cvmx_gserx_lanex_rx_ctle_ctrl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t pcs_sds_rx_ctle_bias_ctrl    : 2;  /**< CTLE bias trim bits.
-                                                         - 00: -10%
-                                                         - 01:   0%
-                                                         - 10: +5%
-                                                         - 11: +10%. */
+                                                         0x0 = -10%.
+                                                         0x1 =  0%.
+                                                         0x2 = +5%.
+                                                         0x3 = +10%. */
 	uint64_t pcs_sds_rx_ctle_zero         : 4;  /**< Equalizer peaking control. */
 	uint64_t rx_ctle_pole_ovrrd_en        : 1;  /**< Equalizer pole adjustment override enable. */
 	uint64_t rx_ctle_pole_ovrrd_val       : 4;  /**< Equalizer pole adjustment override value.
@@ -2828,10 +2914,10 @@ union cvmx_gserx_lanex_rx_ctle_ctrl {
                                                          bit 3: Optimize CTLE during training.
                                                          bit 2: Turn off DFE1 for edge samplers.
                                                          bits 1:0:
-                                                         - 00: ~ 5dB of peaking at 4.0 GHz.
-                                                         - 01: ~10dB of peaking at 5.0 GHz.
-                                                         - 10: ~15dB of peaking at 5.5 GHz.
-                                                         - 11: ~20dB of peaking at 6.0 GHz. */
+                                                         0x0 = ~ 5dB of peaking at 4.0 GHz.
+                                                         0x1 = ~10dB of peaking at 5.0 GHz.
+                                                         0x2 = ~15dB of peaking at 5.5 GHz.
+                                                         0x3 = ~20dB of peaking at 6.0 GHz. */
 	uint64_t pcs_sds_rx_ctle_pole_max     : 2;  /**< Maximum pole value (for VMA adaption, not applicable in manual mode). */
 	uint64_t pcs_sds_rx_ctle_pole_min     : 2;  /**< Minimum pole value (for VMA adaption, not applicable in manual mode). */
 	uint64_t pcs_sds_rx_ctle_pole_step    : 1;  /**< Step pole value (for VMA adaption, not applicable in manual mode). */
@@ -2855,8 +2941,8 @@ typedef union cvmx_gserx_lanex_rx_ctle_ctrl cvmx_gserx_lanex_rx_ctle_ctrl_t;
  *
  * These are the RAW PCS per-lane RX precorrelation control registers. These registers are for
  * diagnostic use only.
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_precorr_ctrl {
 	uint64_t u64;
@@ -2866,11 +2952,11 @@ union cvmx_gserx_lanex_rx_precorr_ctrl {
 	uint64_t rx_precorr_disable           : 1;  /**< Disable RX precorrelation calculation. */
 	uint64_t rx_precorr_en_ovrrd_en       : 1;  /**< Override enable for RX precorrelation calculation enable. */
 	uint64_t rx_precorr_en_ovrrd_val      : 1;  /**< Override value for RX precorrelation calculation enable. */
-	uint64_t pcs_sds_rx_precorr_scnt_ctrl : 2;  /**< RX pre-correlation sample counter control.
-                                                         - 00: load max sample counter with 12'1FF.
-                                                         - 01: load max sample counter with 12'3FF.
-                                                         - 10: load max sample counter with 12'7FF.
-                                                         - 11: load max sample counter with 12'FFF. */
+	uint64_t pcs_sds_rx_precorr_scnt_ctrl : 2;  /**< RX precorrelation sample counter control.
+                                                         0x0 = Load max sample counter with 0x1ff.
+                                                         0x1 = Load max sample counter with 0x3ff.
+                                                         0x2 = Load max sample counter with 0x7ff.
+                                                         0x3 = Load max sample counter with 0xfff. */
 #else
 	uint64_t pcs_sds_rx_precorr_scnt_ctrl : 2;
 	uint64_t rx_precorr_en_ovrrd_val      : 1;
@@ -2886,8 +2972,8 @@ typedef union cvmx_gserx_lanex_rx_precorr_ctrl cvmx_gserx_lanex_rx_precorr_ctrl_
 /**
  * cvmx_gser#_lane#_rx_valbbd_ctrl_0
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_valbbd_ctrl_0 {
 	uint64_t u64;
@@ -2925,8 +3011,8 @@ typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_0 cvmx_gserx_lanex_rx_valbbd_ctrl_
 /**
  * cvmx_gser#_lane#_rx_valbbd_ctrl_1
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_valbbd_ctrl_1 {
 	uint64_t u64;
@@ -2972,8 +3058,8 @@ typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_1 cvmx_gserx_lanex_rx_valbbd_ctrl_
 /**
  * cvmx_gser#_lane#_rx_valbbd_ctrl_2
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_valbbd_ctrl_2 {
 	uint64_t u64;
@@ -3025,8 +3111,8 @@ typedef union cvmx_gserx_lanex_rx_valbbd_ctrl_2 cvmx_gserx_lanex_rx_valbbd_ctrl_
  *
  * These are the RAW PCS per-lane RX VMA control registers. These registers are for diagnostic
  * use only.
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lanex_rx_vma_ctrl {
 	uint64_t u64;
@@ -3040,13 +3126,13 @@ union cvmx_gserx_lanex_rx_vma_ctrl {
 	uint64_t rx_fom_div_delta             : 1;  /**< TX figure of merit delta division-mode enable. */
 	uint64_t rx_vna_ctrl_18_16            : 3;  /**< RX VMA loop control. */
 	uint64_t rx_vna_ctrl_9_0              : 10; /**< RX VMA loop control.
-                                                         bits 9:8: Parameter settling wait time.
-                                                         bit 7: Limit CTLE peak to max value.
-                                                         bit 6: Long reach enabled.
-                                                         bit 5: Short reach enabled.
-                                                         bit 4: Training done override enable.
-                                                         bit 3: Training done override value.
-                                                         bits 2:0: VMA clock modulation. */
+                                                         <9:8> = Parameter settling wait time.
+                                                         <7> = Limit CTLE peak to max value.
+                                                         <6> = Long reach enabled.
+                                                         <5> = Short reach enabled.
+                                                         <4> = Training done override enable.
+                                                         <3> = Training done override value.
+                                                         <2:0> = VMA clock modulation. */
 #else
 	uint64_t rx_vna_ctrl_9_0              : 10;
 	uint64_t rx_vna_ctrl_18_16            : 3;
@@ -3061,6 +3147,194 @@ union cvmx_gserx_lanex_rx_vma_ctrl {
 typedef union cvmx_gserx_lanex_rx_vma_ctrl cvmx_gserx_lanex_rx_vma_ctrl_t;
 
 /**
+ * cvmx_gser#_lane#_tx_cfg_0
+ *
+ * These registers are for diagnostic use only. These registers are only reset by hardware during
+ * chip cold reset. The values of the CSR fields in these registers do not change during chip
+ * warm or soft resets.
+ */
+union cvmx_gserx_lanex_tx_cfg_0 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_tx_cfg_0_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t tx_tristate_en_ovrd_val      : 1;  /**< TX termination high-Z enable. */
+	uint64_t tx_chpd_ovrd_val             : 1;  /**< TX lane power down. */
+	uint64_t reserved_10_13               : 4;
+	uint64_t tx_resetn_ovrd_val           : 1;  /**< TX P2S rest. */
+	uint64_t tx_cm_mode                   : 1;  /**< Assert to enable fast Common-Mode charge up. For simulation purposes only. */
+	uint64_t cfg_tx_swing                 : 5;  /**< TX output swing control.
+                                                         Default swing encoding when GSER(0..13)_LANE(0..3)_TX_CFG_1[TX_SWING_OVRRD_EN] is
+                                                         asserted. */
+	uint64_t fast_rdet_mode               : 1;  /**< Assert to enable fast RX Detection. For simulation purposes only. */
+	uint64_t fast_tristate_mode           : 1;  /**< Assert to enable fast Tristate power up. For simulation purposes only. */
+	uint64_t reserved_0_0                 : 1;
+#else
+	uint64_t reserved_0_0                 : 1;
+	uint64_t fast_tristate_mode           : 1;
+	uint64_t fast_rdet_mode               : 1;
+	uint64_t cfg_tx_swing                 : 5;
+	uint64_t tx_cm_mode                   : 1;
+	uint64_t tx_resetn_ovrd_val           : 1;
+	uint64_t reserved_10_13               : 4;
+	uint64_t tx_chpd_ovrd_val             : 1;
+	uint64_t tx_tristate_en_ovrd_val      : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_tx_cfg_0_s    cn78xx;
+};
+typedef union cvmx_gserx_lanex_tx_cfg_0 cvmx_gserx_lanex_tx_cfg_0_t;
+
+/**
+ * cvmx_gser#_lane#_tx_cfg_1
+ *
+ * These registers are for diagnostic use only. These registers are only reset by hardware during
+ * chip cold reset. The values of the CSR fields in these registers do not change during chip
+ * warm or soft resets.
+ */
+union cvmx_gserx_lanex_tx_cfg_1 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_tx_cfg_1_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_15_63               : 49;
+	uint64_t tx_widthsel_ovrd_en          : 1;  /**< Override enable for pcs_sds_txX_widthsel, TX parallel interface width setting. */
+	uint64_t tx_widthsel_ovrd_val         : 2;  /**< Override value for pcs_sds_widthsel, TX parallel interface width setting.
+                                                         0x0 = 8-bit (not supported).
+                                                         0x1 = 10-bit (not supported).
+                                                         0x2 = 16-bit (not supported).
+                                                         0x3 = 20-bit (not supported). */
+	uint64_t tx_vboost_en_ovrrd_en        : 1;  /**< Override enable for pcs_sds_txX_vboost_en, TX  vboost mode enable. */
+	uint64_t tx_turbo_en_ovrrd_en         : 1;  /**< Override enable for pcs_sds_txX_turbo_en, Turbo mode enable. */
+	uint64_t tx_swing_ovrd_en             : 1;  /**< Override enable for pcs_sds_txX_swing, TX swing. */
+	uint64_t tx_premptap_ovrd_val         : 1;  /**< Override enable for pcs_sds_txX_preemptap, preemphasis control. */
+	uint64_t tx_elec_idle_ovrrd_en        : 1;  /**< Override enable for pcs_sds_txX_elec_idle, TX electrical idle. */
+	uint64_t smpl_rate_ovrd_en            : 1;  /**< Override enable for TX Power state machine sample rate. When asserted, the TX sample is
+                                                         specified from SMPL_RATE_OVRD_VAL and the TX Power state machine control signal is
+                                                         ignored. */
+	uint64_t smpl_rate_ovrd_val           : 3;  /**< Specifies the sample rate (strobe assertion) relative to mac_pcs_txX_clk when
+                                                         SMPL_RATE_OVRD_EN is asserted.
+                                                         0x0 = full rate.
+                                                         0x1 = 1/2 data rate.
+                                                         0x2 = 1/4 data rate.
+                                                         0x3 = 1/8 data rate.
+                                                         0x4 = 1/18 data rate.
+                                                         0x5-7 = Reserved. */
+	uint64_t tx_datarate_ovrd_en          : 1;  /**< Override enable for RX Power state machine data rate signal. When set, rx_datarate is
+                                                         specified from TX_DATA_RATE_OVRD_VAL and the RX Power State Machine control signal is
+                                                         ignored. */
+	uint64_t tx_datarate_ovrd_val         : 2;  /**< Specifies the TX data rate when TX_DATARATE_OVRD_EN is asserted.
+                                                         0x0 = full rate.
+                                                         0x1 = 1/2 data rate.
+                                                         0x2 = 1/4 data rate.
+                                                         0x3 = 1/8 data rate. */
+#else
+	uint64_t tx_datarate_ovrd_val         : 2;
+	uint64_t tx_datarate_ovrd_en          : 1;
+	uint64_t smpl_rate_ovrd_val           : 3;
+	uint64_t smpl_rate_ovrd_en            : 1;
+	uint64_t tx_elec_idle_ovrrd_en        : 1;
+	uint64_t tx_premptap_ovrd_val         : 1;
+	uint64_t tx_swing_ovrd_en             : 1;
+	uint64_t tx_turbo_en_ovrrd_en         : 1;
+	uint64_t tx_vboost_en_ovrrd_en        : 1;
+	uint64_t tx_widthsel_ovrd_val         : 2;
+	uint64_t tx_widthsel_ovrd_en          : 1;
+	uint64_t reserved_15_63               : 49;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_tx_cfg_1_s    cn78xx;
+};
+typedef union cvmx_gserx_lanex_tx_cfg_1 cvmx_gserx_lanex_tx_cfg_1_t;
+
+/**
+ * cvmx_gser#_lane#_tx_cfg_2
+ *
+ * These registers are for diagnostic use only. These registers are only reset by hardware during
+ * chip cold reset. The values of the CSR fields in these registers do not change during chip
+ * warm or soft resets.
+ */
+union cvmx_gserx_lanex_tx_cfg_2 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_tx_cfg_2_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_16_63               : 48;
+	uint64_t pcs_sds_tx_dcc_en            : 1;  /**< DCC Enable. */
+	uint64_t reserved_3_14                : 12;
+	uint64_t rcvr_test_ovrd_en            : 1;  /**< Override RX detect disable and test pulse. */
+	uint64_t rcvr_test_ovrd_val           : 1;  /**< Override value for RX detect test pulse; used to create a pulse during which the receiver
+                                                         detect test operation is performed. */
+	uint64_t tx_rx_detect_dis_ovrd_val    : 1;  /**< Override value of RX detect disable. */
+#else
+	uint64_t tx_rx_detect_dis_ovrd_val    : 1;
+	uint64_t rcvr_test_ovrd_val           : 1;
+	uint64_t rcvr_test_ovrd_en            : 1;
+	uint64_t reserved_3_14                : 12;
+	uint64_t pcs_sds_tx_dcc_en            : 1;
+	uint64_t reserved_16_63               : 48;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_tx_cfg_2_s    cn78xx;
+};
+typedef union cvmx_gserx_lanex_tx_cfg_2 cvmx_gserx_lanex_tx_cfg_2_t;
+
+/**
+ * cvmx_gser#_lane#_tx_cfg_3
+ *
+ * These registers are for diagnostic use only. These registers are only reset by hardware during
+ * chip cold reset. The values of the CSR fields in these registers do not change during chip
+ * warm or soft resets.
+ */
+union cvmx_gserx_lanex_tx_cfg_3 {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_tx_cfg_3_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_15_63               : 49;
+	uint64_t cfg_tx_vboost_en             : 1;  /**< Specifies the value of TX VBoost enable when
+                                                         GSER(0..13)_LANE(0..3)_TX_CFG_1[TX_VBOOST_EN_OVRRD_EN] is asserted. */
+	uint64_t reserved_7_13                : 7;
+	uint64_t pcs_sds_tx_gain              : 3;  /**< TX Gain. For debug use only. */
+	uint64_t pcs_sds_tx_srate_sel         : 3;  /**< Reserved. */
+	uint64_t cfg_tx_turbo_en              : 1;  /**< Specifies value ot TX turbo enable when GSER(0..13)_LANE(0..3)_TX_CFG_1[TX_TURBO_EN] is set. */
+#else
+	uint64_t cfg_tx_turbo_en              : 1;
+	uint64_t pcs_sds_tx_srate_sel         : 3;
+	uint64_t pcs_sds_tx_gain              : 3;
+	uint64_t reserved_7_13                : 7;
+	uint64_t cfg_tx_vboost_en             : 1;
+	uint64_t reserved_15_63               : 49;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_tx_cfg_3_s    cn78xx;
+};
+typedef union cvmx_gserx_lanex_tx_cfg_3 cvmx_gserx_lanex_tx_cfg_3_t;
+
+/**
+ * cvmx_gser#_lane#_tx_pre_emphasis
+ *
+ * These registers are for diagnostic use only. These registers are only reset by hardware during
+ * chip cold reset. The values of the CSR fields in these registers do not change during chip
+ * warm or soft resets.
+ */
+union cvmx_gserx_lanex_tx_pre_emphasis {
+	uint64_t u64;
+	struct cvmx_gserx_lanex_tx_pre_emphasis_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_9_63                : 55;
+	uint64_t cfg_tx_premptap              : 9;  /**< Override preemphasis control. Applies when
+                                                         GSER(0..13)_LANE(0..3)_TX_CFG_3[TX_PREMPTAP_OVRD_EN] is asserted.
+                                                         <8:4> = Post-cursor.
+                                                         <3:0> = Pre-cursor. */
+#else
+	uint64_t cfg_tx_premptap              : 9;
+	uint64_t reserved_9_63                : 55;
+#endif
+	} s;
+	struct cvmx_gserx_lanex_tx_pre_emphasis_s cn78xx;
+};
+typedef union cvmx_gserx_lanex_tx_pre_emphasis cvmx_gserx_lanex_tx_pre_emphasis_t;
+
+/**
  * cvmx_gser#_lane#_vma_coarse_ctrl_0
  *
  * These registers are for diagnostic use only.
@@ -3250,8 +3524,8 @@ typedef union cvmx_gserx_lanex_vma_fine_ctrl_2 cvmx_gserx_lanex_vma_fine_ctrl_2_
 /**
  * cvmx_gser#_lane_lpbken
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lane_lpbken {
 	uint64_t u64;
@@ -3260,10 +3534,10 @@ union cvmx_gserx_lane_lpbken {
 	uint64_t reserved_4_63                : 60;
 	uint64_t lpbken                       : 4;  /**< For links that are not in PCIE mode (including all OCI links). When asserted in P0 state,
                                                          allows per lane TX-to-RX serial loopback activation.
-                                                         <3>: Lane 3
-                                                         <2>: Lane 2
-                                                         <1>: Lane 1
-                                                         <0>: Lane 0 */
+                                                         <3>: Lane 3.
+                                                         <2>: Lane 2.
+                                                         <1>: Lane 1.
+                                                         <0>: Lane 0. */
 #else
 	uint64_t lpbken                       : 4;
 	uint64_t reserved_4_63                : 60;
@@ -3276,8 +3550,8 @@ typedef union cvmx_gserx_lane_lpbken cvmx_gserx_lane_lpbken_t;
 /**
  * cvmx_gser#_lane_mode
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lane_mode {
 	uint64_t u64;
@@ -3292,14 +3566,14 @@ union cvmx_gserx_lane_mode {
                                                          0x2: R_8G_REFCLK100
                                                          0x3: R_125G_REFCLK15625_KX (not supported)
                                                          0x4: R_3125G_REFCLK15625_XAUI
-                                                              For XAUI applications.
+                                                         For XAUI applications.
                                                          0x5: R_103125G_REFCLK15625_KR
-                                                              For XFI, XLAUI, KR applications
+                                                         For XFI, XLAUI, KR applications.
                                                          0x6: R_125G_REFCLK15625_SGMII
-                                                              For SGMII applications
+                                                         For SGMII applications.
                                                          0x7: R_5G_REFCLK15625_QSGMII (not supported)
                                                          0x8: R_625G_REFCLK15625_RXAUI
-                                                              For RXAUI, DXAUI applications
+                                                         For RXAUI, DXAUI applications.
                                                          0x9: R_25G_REFCLK125
                                                          0xA: R_5G_REFCLK125
                                                          0xB: R_8G_REFCLK125
@@ -3310,16 +3584,16 @@ union cvmx_gserx_lane_mode {
                                                          particular reference clock.
                                                          It is recommended that the PHY be in reset when reconfiguring the LMODE
                                                          (GSER(0..13)_PHY_CTL[PHY_RESET] is set). If the LMODE is modified when the PHY is out of
-                                                         reset, the GSER(0..13)_RXTX_STAT[LMC] can be used to determine when the PHY has
+                                                         reset, GSER(0..13)_RXTX_STAT[LMC] can be used to determine when the PHY has
                                                          transitioned to the new setting.
                                                          Once the LMODE has been configured, and the PHY is out of reset, the table entries for the
                                                          selected LMODE must be updated to reflect the reference clock speed. Refer to the register
                                                          description and index into the table using the rate and reference speed to obtain the
                                                          recommended values.
-                                                          Write GSER(0..13)_PLL_P(Z)_MODE_0.
-                                                          Write GSER(0..13)_PLL_P(Z)_MODE_1.
-                                                          Write GSER(0..13)_LANE(0..3)_P(Z)_MODE_0.
-                                                          Write GSER(0..13)_LANE(0..3)_P(Z)_MODE_1.
+                                                         Write GSER(0..13)_PLL_P(Z)_MODE_0.
+                                                         Write GSER(0..13)_PLL_P(Z)_MODE_1.
+                                                         Write GSER(0..13)_LANE(0..3)_P(Z)_MODE_0.
+                                                         Write GSER(0..13)_LANE(0..3)_P(Z)_MODE_1.
                                                          where Z equals LMODE. */
 #else
 	uint64_t lmode                        : 4;
@@ -3333,8 +3607,8 @@ typedef union cvmx_gserx_lane_mode cvmx_gserx_lane_mode_t;
 /**
  * cvmx_gser#_lane_poff
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lane_poff {
 	uint64_t u64;
@@ -3343,10 +3617,10 @@ union cvmx_gserx_lane_poff {
 	uint64_t reserved_4_63                : 60;
 	uint64_t lpoff                        : 4;  /**< For links that are not in PCIE mode (including all OCI links), allows for per lane power
                                                          down.
-                                                         <3>: Lane 3
-                                                         <2>: Lane 2
-                                                         <1>: Lane 1
-                                                         <0>: Lane 0 */
+                                                         <3>: Lane 3.
+                                                         <2>: Lane 2.
+                                                         <1>: Lane 1.
+                                                         <0>: Lane 0. */
 #else
 	uint64_t lpoff                        : 4;
 	uint64_t reserved_4_63                : 60;
@@ -3359,8 +3633,8 @@ typedef union cvmx_gserx_lane_poff cvmx_gserx_lane_poff_t;
 /**
  * cvmx_gser#_lane_srst
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_lane_srst {
 	uint64_t u64;
@@ -3403,6 +3677,7 @@ union cvmx_gserx_pcie_pcs_clk_req {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pcs_clk_req_s  cn70xx;
+	struct cvmx_gserx_pcie_pcs_clk_req_s  cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pcs_clk_req cvmx_gserx_pcie_pcs_clk_req_t;
 
@@ -3426,6 +3701,7 @@ union cvmx_gserx_pcie_pipex_txdeemph {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pipex_txdeemph_s cn70xx;
+	struct cvmx_gserx_pcie_pipex_txdeemph_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pipex_txdeemph cvmx_gserx_pcie_pipex_txdeemph_t;
 
@@ -3452,6 +3728,7 @@ union cvmx_gserx_pcie_pipe_com_clk {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pipe_com_clk_s cn70xx;
+	struct cvmx_gserx_pcie_pipe_com_clk_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pipe_com_clk cvmx_gserx_pcie_pipe_com_clk_t;
 
@@ -3473,6 +3750,7 @@ union cvmx_gserx_pcie_pipe_crst {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pipe_crst_s    cn70xx;
+	struct cvmx_gserx_pcie_pipe_crst_s    cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pipe_crst cvmx_gserx_pcie_pipe_crst_t;
 
@@ -3508,6 +3786,7 @@ union cvmx_gserx_pcie_pipe_port_loopbk {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pipe_port_loopbk_s cn70xx;
+	struct cvmx_gserx_pcie_pipe_port_loopbk_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pipe_port_loopbk cvmx_gserx_pcie_pipe_port_loopbk_t;
 
@@ -3542,6 +3821,7 @@ union cvmx_gserx_pcie_pipe_port_sel {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pipe_port_sel_s cn70xx;
+	struct cvmx_gserx_pcie_pipe_port_sel_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pipe_port_sel cvmx_gserx_pcie_pipe_port_sel_t;
 
@@ -3574,6 +3854,7 @@ union cvmx_gserx_pcie_pipe_rst {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pipe_rst_s     cn70xx;
+	struct cvmx_gserx_pcie_pipe_rst_s     cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pipe_rst cvmx_gserx_pcie_pipe_rst_t;
 
@@ -3616,6 +3897,7 @@ union cvmx_gserx_pcie_pipe_rst_sts {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pipe_rst_sts_s cn70xx;
+	struct cvmx_gserx_pcie_pipe_rst_sts_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pipe_rst_sts cvmx_gserx_pcie_pipe_rst_sts_t;
 
@@ -3655,6 +3937,7 @@ union cvmx_gserx_pcie_pipe_status {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_pipe_status_s  cn70xx;
+	struct cvmx_gserx_pcie_pipe_status_s  cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_pipe_status cvmx_gserx_pcie_pipe_status_t;
 
@@ -3678,6 +3961,7 @@ union cvmx_gserx_pcie_tx_deemph_gen1 {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_tx_deemph_gen1_s cn70xx;
+	struct cvmx_gserx_pcie_tx_deemph_gen1_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_tx_deemph_gen1 cvmx_gserx_pcie_tx_deemph_gen1_t;
 
@@ -3701,6 +3985,7 @@ union cvmx_gserx_pcie_tx_deemph_gen2_3p5db {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_tx_deemph_gen2_3p5db_s cn70xx;
+	struct cvmx_gserx_pcie_tx_deemph_gen2_3p5db_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_tx_deemph_gen2_3p5db cvmx_gserx_pcie_tx_deemph_gen2_3p5db_t;
 
@@ -3724,6 +4009,7 @@ union cvmx_gserx_pcie_tx_deemph_gen2_6db {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_tx_deemph_gen2_6db_s cn70xx;
+	struct cvmx_gserx_pcie_tx_deemph_gen2_6db_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_tx_deemph_gen2_6db cvmx_gserx_pcie_tx_deemph_gen2_6db_t;
 
@@ -3747,6 +4033,7 @@ union cvmx_gserx_pcie_tx_swing_full {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_tx_swing_full_s cn70xx;
+	struct cvmx_gserx_pcie_tx_swing_full_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_tx_swing_full cvmx_gserx_pcie_tx_swing_full_t;
 
@@ -3770,6 +4057,7 @@ union cvmx_gserx_pcie_tx_swing_low {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_tx_swing_low_s cn70xx;
+	struct cvmx_gserx_pcie_tx_swing_low_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_tx_swing_low cvmx_gserx_pcie_tx_swing_low_t;
 
@@ -3795,6 +4083,7 @@ union cvmx_gserx_pcie_tx_vboost_lvl {
 #endif
 	} s;
 	struct cvmx_gserx_pcie_tx_vboost_lvl_s cn70xx;
+	struct cvmx_gserx_pcie_tx_vboost_lvl_s cn70xxp1;
 };
 typedef union cvmx_gserx_pcie_tx_vboost_lvl cvmx_gserx_pcie_tx_vboost_lvl_t;
 
@@ -3816,6 +4105,7 @@ union cvmx_gserx_phyx_idcode_hi {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_idcode_hi_s    cn70xx;
+	struct cvmx_gserx_phyx_idcode_hi_s    cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_idcode_hi cvmx_gserx_phyx_idcode_hi_t;
 
@@ -3837,6 +4127,7 @@ union cvmx_gserx_phyx_idcode_lo {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_idcode_lo_s    cn70xx;
+	struct cvmx_gserx_phyx_idcode_lo_s    cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_idcode_lo cvmx_gserx_phyx_idcode_lo_t;
 
@@ -3872,6 +4163,7 @@ union cvmx_gserx_phyx_lane0_loopback {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane0_loopback_s cn70xx;
+	struct cvmx_gserx_phyx_lane0_loopback_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane0_loopback cvmx_gserx_phyx_lane0_loopback_t;
 
@@ -3909,6 +4201,7 @@ union cvmx_gserx_phyx_lane0_rx_lbert_ctl {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane0_rx_lbert_ctl_s cn70xx;
+	struct cvmx_gserx_phyx_lane0_rx_lbert_ctl_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane0_rx_lbert_ctl cvmx_gserx_phyx_lane0_rx_lbert_ctl_t;
 
@@ -3935,6 +4228,7 @@ union cvmx_gserx_phyx_lane0_rx_lbert_err {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane0_rx_lbert_err_s cn70xx;
+	struct cvmx_gserx_phyx_lane0_rx_lbert_err_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane0_rx_lbert_err cvmx_gserx_phyx_lane0_rx_lbert_err_t;
 
@@ -3982,6 +4276,7 @@ union cvmx_gserx_phyx_lane0_rx_ovrd_in_lo {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane0_rx_ovrd_in_lo_s cn70xx;
+	struct cvmx_gserx_phyx_lane0_rx_ovrd_in_lo_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane0_rx_ovrd_in_lo cvmx_gserx_phyx_lane0_rx_ovrd_in_lo_t;
 
@@ -4019,6 +4314,7 @@ union cvmx_gserx_phyx_lane0_tx_lbert_ctl {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane0_tx_lbert_ctl_s cn70xx;
+	struct cvmx_gserx_phyx_lane0_tx_lbert_ctl_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane0_tx_lbert_ctl cvmx_gserx_phyx_lane0_tx_lbert_ctl_t;
 
@@ -4056,6 +4352,7 @@ union cvmx_gserx_phyx_lane0_tx_ovrd_in_hi {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane0_tx_ovrd_in_hi_s cn70xx;
+	struct cvmx_gserx_phyx_lane0_tx_ovrd_in_hi_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane0_tx_ovrd_in_hi cvmx_gserx_phyx_lane0_tx_ovrd_in_hi_t;
 
@@ -4099,6 +4396,7 @@ union cvmx_gserx_phyx_lane0_tx_ovrd_in_lo {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane0_tx_ovrd_in_lo_s cn70xx;
+	struct cvmx_gserx_phyx_lane0_tx_ovrd_in_lo_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane0_tx_ovrd_in_lo cvmx_gserx_phyx_lane0_tx_ovrd_in_lo_t;
 
@@ -4124,6 +4422,7 @@ union cvmx_gserx_phyx_lane0_txdebug {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane0_txdebug_s cn70xx;
+	struct cvmx_gserx_phyx_lane0_txdebug_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane0_txdebug cvmx_gserx_phyx_lane0_txdebug_t;
 
@@ -4159,6 +4458,7 @@ union cvmx_gserx_phyx_lane1_loopback {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_loopback_s cn70xx;
+	struct cvmx_gserx_phyx_lane1_loopback_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane1_loopback cvmx_gserx_phyx_lane1_loopback_t;
 
@@ -4196,6 +4496,7 @@ union cvmx_gserx_phyx_lane1_rx_lbert_ctl {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_rx_lbert_ctl_s cn70xx;
+	struct cvmx_gserx_phyx_lane1_rx_lbert_ctl_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane1_rx_lbert_ctl cvmx_gserx_phyx_lane1_rx_lbert_ctl_t;
 
@@ -4222,6 +4523,7 @@ union cvmx_gserx_phyx_lane1_rx_lbert_err {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_rx_lbert_err_s cn70xx;
+	struct cvmx_gserx_phyx_lane1_rx_lbert_err_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane1_rx_lbert_err cvmx_gserx_phyx_lane1_rx_lbert_err_t;
 
@@ -4269,6 +4571,7 @@ union cvmx_gserx_phyx_lane1_rx_ovrd_in_lo {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_rx_ovrd_in_lo_s cn70xx;
+	struct cvmx_gserx_phyx_lane1_rx_ovrd_in_lo_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane1_rx_ovrd_in_lo cvmx_gserx_phyx_lane1_rx_ovrd_in_lo_t;
 
@@ -4306,6 +4609,7 @@ union cvmx_gserx_phyx_lane1_tx_lbert_ctl {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_tx_lbert_ctl_s cn70xx;
+	struct cvmx_gserx_phyx_lane1_tx_lbert_ctl_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane1_tx_lbert_ctl cvmx_gserx_phyx_lane1_tx_lbert_ctl_t;
 
@@ -4343,6 +4647,7 @@ union cvmx_gserx_phyx_lane1_tx_ovrd_in_hi {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_tx_ovrd_in_hi_s cn70xx;
+	struct cvmx_gserx_phyx_lane1_tx_ovrd_in_hi_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane1_tx_ovrd_in_hi cvmx_gserx_phyx_lane1_tx_ovrd_in_hi_t;
 
@@ -4386,6 +4691,7 @@ union cvmx_gserx_phyx_lane1_tx_ovrd_in_lo {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_tx_ovrd_in_lo_s cn70xx;
+	struct cvmx_gserx_phyx_lane1_tx_ovrd_in_lo_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane1_tx_ovrd_in_lo cvmx_gserx_phyx_lane1_tx_ovrd_in_lo_t;
 
@@ -4411,6 +4717,7 @@ union cvmx_gserx_phyx_lane1_txdebug {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_lane1_txdebug_s cn70xx;
+	struct cvmx_gserx_phyx_lane1_txdebug_s cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_lane1_txdebug cvmx_gserx_phyx_lane1_txdebug_t;
 
@@ -4460,6 +4767,7 @@ union cvmx_gserx_phyx_ovrd_in_lo {
 #endif
 	} s;
 	struct cvmx_gserx_phyx_ovrd_in_lo_s   cn70xx;
+	struct cvmx_gserx_phyx_ovrd_in_lo_s   cn70xxp1;
 };
 typedef union cvmx_gserx_phyx_ovrd_in_lo cvmx_gserx_phyx_ovrd_in_lo_t;
 
@@ -4467,8 +4775,8 @@ typedef union cvmx_gserx_phyx_ovrd_in_lo cvmx_gserx_phyx_ovrd_in_lo_t;
  * cvmx_gser#_phy_ctl
  *
  * This register contains general PHY/PLL control of the RAW PCS.
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_phy_ctl {
 	uint64_t u64;
@@ -4514,9 +4822,9 @@ typedef union cvmx_gserx_pipe_lpbk cvmx_gserx_pipe_lpbk_t;
 /**
  * cvmx_gser#_pll_p#_mode_0
  *
- * These are the RAW PCS PLL global settings mode 0 registers. There is one register per
- * GSER per GSER_LMODE_E (0..11). Only one entry is used at any given time in a given GSER -
- * the one selected by the corresponding GSER(0..13)_LANE_MODE[LMODE].
+ * These are the RAW PCS PLL global settings mode 0 registers.There is one register per GSER per
+ * GSER_LMODE_E(0..11). Only one entry is used at any given time in a given GSER - the one
+ * selected by the corresponding GSER(0..13)_LANE_MODE[LMODE].
  * These registers are only reset by hardware during chip cold reset.
  * The values of the CSR fields in these registers do not change during subsequent chip warm or
  * soft resets.
@@ -4527,7 +4835,7 @@ union cvmx_gserx_pll_px_mode_0 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t pll_icp                      : 4;  /**< PLL charge pump enable.
-                                                         Recommended settings, which is based on the reference clock speed:
+                                                         Recommended settings, which are based on the reference clock speed:
                                                                   100MHz 125MHz 156.25MHz
                                                          1.25G:    0x1    0x1    0x1
                                                          2.5G:     0x4    0x3    0x3
@@ -4570,9 +4878,9 @@ typedef union cvmx_gserx_pll_px_mode_0 cvmx_gserx_pll_px_mode_0_t;
 /**
  * cvmx_gser#_pll_p#_mode_1
  *
- * These are the RAW PCS PLL global settings mode 1 registers. There is one register per
- * GSER per GSER_LMODE_E (0..11). Only one entry is used at any given time in a given GSER -
- * the one selected by the corresponding GSER(0..13)_LANE_MODE[LMODE].
+ * These are the RAW PCS PLL global settings mode 1 registers. There is one register per GSER per
+ * GSER_LMODE_E(0..11). Only one entry is used at any given time in a given GSER - the one
+ * selected by the corresponding GSER(0..13)_LANE_MODE[LMODE].
  * These registers are only reset by hardware during chip cold reset.
  * The values of the CSR fields in this register do not change during subsequent chip warm or
  * soft resets.
@@ -4604,13 +4912,12 @@ union cvmx_gserx_pll_px_mode_1 {
                                                          8.0G:      0x2     0x1    NS
                                                          10.3125G:  NS      NS     0x2
                                                          A 'NS' indicates that the rate is not supported at the specified reference clock. */
-	uint64_t pll_pcie3en                  : 1;  /**< Enable PCIE3 mode.
-                                                         Recommended settings:
-                                                         0 = Any rate other than 8 Gbps.
-                                                         1 = Rate is equal to 8 Gbps. */
+	uint64_t pll_pcie3en                  : 1;  /**< Enable PCIE3 mode. Recommended settings:
+                                                         0 = Any rate other than 8 Gbaud.
+                                                         1 = Rate is equal to 8 Gbaud. */
 	uint64_t pll_opr                      : 1;  /**< PLL op range:
-                                                         0 = Use Ring Oscillator VCO. Recommended for rates 6.25 Gbps and lower.
-                                                         1 = Use LC-tank VCO. Recommended for rates 8 Gbps and higher. */
+                                                         0 = Use Ring Oscillator VCO. Recommended for rates 6.25 Gbaud and lower.
+                                                         1 = Use LC-tank VCO. Recommended for rates 8 Gbaud and higher. */
 	uint64_t pll_div                      : 9;  /**< PLL divider in feedback path which sets the PLL frequency.
                                                          Recommended settings:
                                                                   100MHz 125MHz 156.25MHz
@@ -4678,8 +4985,8 @@ typedef union cvmx_gserx_qlm_stat cvmx_gserx_qlm_stat_t;
  * cvmx_gser#_refclk_sel
  *
  * This register selects the reference clock.
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_refclk_sel {
 	uint64_t u64;
@@ -4709,8 +5016,8 @@ typedef union cvmx_gserx_refclk_sel cvmx_gserx_refclk_sel_t;
 /**
  * cvmx_gser#_rx_coast
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_rx_coast {
 	uint64_t u64;
@@ -4723,10 +5030,10 @@ union cvmx_gserx_rx_coast {
                                                          exit (GSER(0..13)_RX_EIE_DETSTS[EIESTS]). Once the COAST signal deasserts, the CDR is
                                                          allowed to lock. In BGX mode, the BGX MAC can also control the COAST inputs to the PHY to
                                                          allow Auto-Negotiation for backplane Ethernet. For diagnostic use only.
-                                                         <3>: Lane 3
-                                                         <2>: Lane 2
-                                                         <1>: Lane 1
-                                                         <0>: Lane 0 */
+                                                         <3>: Lane 3.
+                                                         <2>: Lane 2.
+                                                         <1>: Lane 1.
+                                                         <0>: Lane 0. */
 #else
 	uint64_t coast                        : 4;
 	uint64_t reserved_4_63                : 60;
@@ -4739,8 +5046,8 @@ typedef union cvmx_gserx_rx_coast cvmx_gserx_rx_coast_t;
 /**
  * cvmx_gser#_rx_eie_deten
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_rx_eie_deten {
 	uint64_t u64;
@@ -4752,10 +5059,10 @@ union cvmx_gserx_rx_eie_deten {
                                                          GSER(0..13)_RX_EIE_DETSTS[EIELTCH] is asserted. EIEDE defaults to the enabled state. Once
                                                          EIE has been detected, EIEDE must be disabled, and then enabled again to perform another
                                                          EIE detection.
-                                                         <3>: Lane 3
-                                                         <2>: Lane 2
-                                                         <1>: Lane 1
-                                                         <0>: Lane 0 */
+                                                         <3>: Lane 3.
+                                                         <2>: Lane 2.
+                                                         <1>: Lane 1.
+                                                         <0>: Lane 0. */
 #else
 	uint64_t eiede                        : 4;
 	uint64_t reserved_4_63                : 60;
@@ -4777,29 +5084,29 @@ union cvmx_gserx_rx_eie_detsts {
                                                          lock. During this time, there may be RX bit errors. These bits will set when the CDR is
                                                          guaranteed to be locked. Note that link training can't start until the lane CDRLOCK is
                                                          set. Software can use CDRLOCK to determine when to expect error free RX data.
-                                                         <11>: Lane 3
-                                                         <10>: Lane 2
-                                                         <9>: Lane 1
-                                                         <8>: Lane 0 */
+                                                         <11>: Lane 3.
+                                                         <10>: Lane 2.
+                                                         <9>: Lane 1.
+                                                         <8>: Lane 0. */
 	uint64_t eiests                       : 4;  /**< When electrical idle exit detection is enabled (GSER(0..13)_RX_EIE_DETEN[EIEDE] is
                                                          asserted), indicates that an electrical idle exit condition (EIE) was detected. For higher
                                                          data rates, the received data needs to have sufficient low frequency content (for example,
-                                                         IDLE symbols) for data transitions to be detected and for EIESTS to stay set accordingly.
+                                                         idle symbols) for data transitions to be detected and for EIESTS to stay set accordingly.
                                                          Under most conditions, EIESTS
                                                          will stay asserted until GSER(0..13)_RX_EIE_DETEN[EIEDE] is deasserted.
-                                                         <7>: Lane 3
-                                                         <6>: Lane 2
-                                                         <5>: Lane 1
-                                                         <4>: Lane 0 */
+                                                         <7>: Lane 3.
+                                                         <6>: Lane 2.
+                                                         <5>: Lane 1.
+                                                         <4>: Lane 0. */
 	uint64_t eieltch                      : 4;  /**< When electrical idle exit detection is enabled (GSER(0..13)_RX_EIE_DETEN[EIEDE] is
-                                                         asserted), indicates that an electrical idle exit condition (EIE) was detected. Once a EIE
-                                                         condition has been detected, the per-lane EIELTCH will stay set until
+                                                         asserted), indicates that an electrical idle exit condition (EIE) was detected. Once an
+                                                         EIE condition has been detected, the per-lane EIELTCH will stay set until
                                                          GSER_RX_EIE_DETEN.EIEDE is deasserted. Note that there may be RX bit errors until CDRLOCK
                                                          is set.
-                                                         <3>: Lane 3
-                                                         <2>: Lane 2
-                                                         <1>: Lane 1
-                                                         <0>: Lane 0 */
+                                                         <3>: Lane 3.
+                                                         <2>: Lane 2.
+                                                         <1>: Lane 1.
+                                                         <0>: Lane 0. */
 #else
 	uint64_t eieltch                      : 4;
 	uint64_t eiests                       : 4;
@@ -4820,22 +5127,22 @@ union cvmx_gserx_rx_eie_filter {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
 	uint64_t eii_filt                     : 16; /**< The GSER uses electrical idle inference to determine when a RX lane has reentered
-                                                         electrical IDLE (EI). The PHY electrical IDLE exit detection supports a minimum pulse
+                                                         electrical idle (EI). The PHY electrical idle exit detection supports a minimum pulse
                                                          width of 400ps, therefore configurations that run faster than 2.5G can indicate EI when
                                                          the serial lines are still driven. For rates faster than 2.5G, it takes 16K * 8 UI of
-                                                         consecutive deasserted GSER(0..13)_RX_EIE_DETSTS[EIESTS] for the GSER to infer EI.
-                                                         In the event of electrical IDLE inference, the following happens:
+                                                         consecutive deasserted GSER(0..13)_RX_EIE_DETSTS[EIESTS] for the GSER to infer EI. In the
+                                                         event of electrical idle inference, the following happens:
                                                          * GSER(0..13)_RX_EIE_DETSTS[CDRLOCK]<lane> is zeroed
                                                          * GSER(0..13)_RX_EIE_DETSTS[EIELTCH]<lane> is zeroed
                                                          * GSER(0..13)_RX_EIE_DETSTS[EIESTS]<lane> is zeroed
                                                          * GSER(0..13)_RX_COAST[COAST]<lane> is asserted to prevent the CDR from trying to lock on
                                                          the incoming data stream.
                                                          * GSER(0..13)_RX_EIE_DETEN[EIEDE]<lane> deasserts for a short period of time, and then is
-                                                         asserted to begin looking for the Electical IDLE Exit condition.
+                                                         asserted to begin looking for the Electrical idle Exit condition.
                                                          Writing this register to a non-zero value causes the electrical idle inference to use the
                                                          EII_FILT count instead of the default settings. Each EII_FILT count represents 20 ns of
                                                          incremental EI inference time.
-                                                         It is not expected that Software will need to use the Electrical Idle Inference logic. */
+                                                         It is not expected that software will need to use the Electrical Idle Inference logic. */
 #else
 	uint64_t eii_filt                     : 16;
 	uint64_t reserved_16_63               : 48;
@@ -4848,8 +5155,8 @@ typedef union cvmx_gserx_rx_eie_filter cvmx_gserx_rx_eie_filter_t;
 /**
  * cvmx_gser#_rx_polarity
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_rx_polarity {
 	uint64_t u64;
@@ -4859,10 +5166,10 @@ union cvmx_gserx_rx_polarity {
 	uint64_t rx_inv                       : 4;  /**< For links that are not in PCIE mode (including all OCI links), control signal to invert
                                                          the polarity of received data. When asserted, the polarity of the received data is
                                                          inverted.
-                                                         <3>: Lane 3
-                                                         <2>: Lane 2
-                                                         <1>: Lane 1
-                                                         <0>: Lane 0 */
+                                                         <3>: Lane 3.
+                                                         <2>: Lane 2.
+                                                         <1>: Lane 1.
+                                                         <0>: Lane 0. */
 #else
 	uint64_t rx_inv                       : 4;
 	uint64_t reserved_4_63                : 60;
@@ -4873,63 +5180,6 @@ union cvmx_gserx_rx_polarity {
 typedef union cvmx_gserx_rx_polarity cvmx_gserx_rx_polarity_t;
 
 /**
- * cvmx_gser#_rx_pstate
- *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
- */
-union cvmx_gserx_rx_pstate {
-	uint64_t u64;
-	struct cvmx_gserx_rx_pstate_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_3_63                : 61;
-	uint64_t rxpstate                     : 3;  /**< For links that are not in PCIE mode (including all OCI links), allows RX lane power state
-                                                         control. For diagnostic use only.
-                                                         0x0 = P0. Active state. All internal clocks in the PHY are operational, the only state
-                                                         where the PHY transmits and receives link data.
-                                                         0x1 = P0s. Standby state. The RX link is disabled.
-                                                         0x2 = P1. low power state. Selected internal clocks in the PHY are turned off.
-                                                         0x3 = P2. Power down state. All clocks in the PHY are turned off.
-                                                         else = Reserved. */
-#else
-	uint64_t rxpstate                     : 3;
-	uint64_t reserved_3_63                : 61;
-#endif
-	} s;
-	struct cvmx_gserx_rx_pstate_s         cn78xx;
-};
-typedef union cvmx_gserx_rx_pstate cvmx_gserx_rx_pstate_t;
-
-/**
- * cvmx_gser#_rxtx_stat
- */
-union cvmx_gserx_rxtx_stat {
-	uint64_t u64;
-	struct cvmx_gserx_rxtx_stat_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_3_63                : 61;
-	uint64_t lmc                          : 1;  /**< For links that are not in PCIE mode (including all OCI links), this bit is set when a
-                                                         write is performed to that changes the value of GSER(0..13)_LANE_MODE when the PHY is out
-                                                         of reset. This bit is clear when the PHY acknowledges the change for all 4 lanes. */
-	uint64_t tpsc                         : 1;  /**< For links that are not in PCIE mode (including all OCI links), this bit is set when a
-                                                         write is performed to that changes the value of GSER(0..13)_TX_PSTATE when the PHY is out
-                                                         of reset. This bit is clear when the PHY acknowledges the change for all 4 lanes. For
-                                                         diagnostic use only. */
-	uint64_t rpsc                         : 1;  /**< For links that are not in PCIE mode (including all OCI links), this bit is set when a
-                                                         write is performed to that changes the value to GSER(0..13)_RX_PSTATE. This bit is clear
-                                                         when the PHY acknowledges the change for all 4 lanes. For diagnostic use only. */
-#else
-	uint64_t rpsc                         : 1;
-	uint64_t tpsc                         : 1;
-	uint64_t lmc                          : 1;
-	uint64_t reserved_3_63                : 61;
-#endif
-	} s;
-	struct cvmx_gserx_rxtx_stat_s         cn78xx;
-};
-typedef union cvmx_gserx_rxtx_stat cvmx_gserx_rxtx_stat_t;
-
-/**
  * cvmx_gser#_sata_cfg
  *
  * SATA Config Enable.
@@ -4947,6 +5197,7 @@ union cvmx_gserx_sata_cfg {
 #endif
 	} s;
 	struct cvmx_gserx_sata_cfg_s          cn70xx;
+	struct cvmx_gserx_sata_cfg_s          cn70xxp1;
 };
 typedef union cvmx_gserx_sata_cfg cvmx_gserx_sata_cfg_t;
 
@@ -4970,6 +5221,7 @@ union cvmx_gserx_sata_lane_rst {
 #endif
 	} s;
 	struct cvmx_gserx_sata_lane_rst_s     cn70xx;
+	struct cvmx_gserx_sata_lane_rst_s     cn70xxp1;
 };
 typedef union cvmx_gserx_sata_lane_rst cvmx_gserx_sata_lane_rst_t;
 
@@ -4993,6 +5245,7 @@ union cvmx_gserx_sata_p0_tx_amp_genx {
 #endif
 	} s;
 	struct cvmx_gserx_sata_p0_tx_amp_genx_s cn70xx;
+	struct cvmx_gserx_sata_p0_tx_amp_genx_s cn70xxp1;
 };
 typedef union cvmx_gserx_sata_p0_tx_amp_genx cvmx_gserx_sata_p0_tx_amp_genx_t;
 
@@ -5016,6 +5269,7 @@ union cvmx_gserx_sata_p0_tx_preemph_genx {
 #endif
 	} s;
 	struct cvmx_gserx_sata_p0_tx_preemph_genx_s cn70xx;
+	struct cvmx_gserx_sata_p0_tx_preemph_genx_s cn70xxp1;
 };
 typedef union cvmx_gserx_sata_p0_tx_preemph_genx cvmx_gserx_sata_p0_tx_preemph_genx_t;
 
@@ -5039,6 +5293,7 @@ union cvmx_gserx_sata_p1_tx_amp_genx {
 #endif
 	} s;
 	struct cvmx_gserx_sata_p1_tx_amp_genx_s cn70xx;
+	struct cvmx_gserx_sata_p1_tx_amp_genx_s cn70xxp1;
 };
 typedef union cvmx_gserx_sata_p1_tx_amp_genx cvmx_gserx_sata_p1_tx_amp_genx_t;
 
@@ -5062,6 +5317,7 @@ union cvmx_gserx_sata_p1_tx_preemph_genx {
 #endif
 	} s;
 	struct cvmx_gserx_sata_p1_tx_preemph_genx_s cn70xx;
+	struct cvmx_gserx_sata_p1_tx_preemph_genx_s cn70xxp1;
 };
 typedef union cvmx_gserx_sata_p1_tx_preemph_genx cvmx_gserx_sata_p1_tx_preemph_genx_t;
 
@@ -5083,6 +5339,7 @@ union cvmx_gserx_sata_ref_ssp_en {
 #endif
 	} s;
 	struct cvmx_gserx_sata_ref_ssp_en_s   cn70xx;
+	struct cvmx_gserx_sata_ref_ssp_en_s   cn70xxp1;
 };
 typedef union cvmx_gserx_sata_ref_ssp_en cvmx_gserx_sata_ref_ssp_en_t;
 
@@ -5110,6 +5367,7 @@ union cvmx_gserx_sata_rx_invert {
 #endif
 	} s;
 	struct cvmx_gserx_sata_rx_invert_s    cn70xx;
+	struct cvmx_gserx_sata_rx_invert_s    cn70xxp1;
 };
 typedef union cvmx_gserx_sata_rx_invert cvmx_gserx_sata_rx_invert_t;
 
@@ -5135,6 +5393,7 @@ union cvmx_gserx_sata_ssc_clk_sel {
 #endif
 	} s;
 	struct cvmx_gserx_sata_ssc_clk_sel_s  cn70xx;
+	struct cvmx_gserx_sata_ssc_clk_sel_s  cn70xxp1;
 };
 typedef union cvmx_gserx_sata_ssc_clk_sel cvmx_gserx_sata_ssc_clk_sel_t;
 
@@ -5159,6 +5418,7 @@ union cvmx_gserx_sata_ssc_en {
 #endif
 	} s;
 	struct cvmx_gserx_sata_ssc_en_s       cn70xx;
+	struct cvmx_gserx_sata_ssc_en_s       cn70xxp1;
 };
 typedef union cvmx_gserx_sata_ssc_en cvmx_gserx_sata_ssc_en_t;
 
@@ -5190,6 +5450,7 @@ union cvmx_gserx_sata_ssc_range {
 #endif
 	} s;
 	struct cvmx_gserx_sata_ssc_range_s    cn70xx;
+	struct cvmx_gserx_sata_ssc_range_s    cn70xxp1;
 };
 typedef union cvmx_gserx_sata_ssc_range cvmx_gserx_sata_ssc_range_t;
 
@@ -5213,6 +5474,7 @@ union cvmx_gserx_sata_status {
 #endif
 	} s;
 	struct cvmx_gserx_sata_status_s       cn70xx;
+	struct cvmx_gserx_sata_status_s       cn70xxp1;
 };
 typedef union cvmx_gserx_sata_status cvmx_gserx_sata_status_t;
 
@@ -5242,14 +5504,15 @@ union cvmx_gserx_sata_tx_invert {
 #endif
 	} s;
 	struct cvmx_gserx_sata_tx_invert_s    cn70xx;
+	struct cvmx_gserx_sata_tx_invert_s    cn70xxp1;
 };
 typedef union cvmx_gserx_sata_tx_invert cvmx_gserx_sata_tx_invert_t;
 
 /**
  * cvmx_gser#_scratch
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_scratch {
 	uint64_t u64;
@@ -5269,49 +5532,48 @@ typedef union cvmx_gserx_scratch cvmx_gserx_scratch_t;
 /**
  * cvmx_gser#_spd
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_spd {
 	uint64_t u64;
 	struct cvmx_gserx_spd_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t spd                          : 4;  /**< For OCI links (i.e. GSER8..13), the hardware loads this CSR field from the
-                                                         OCI_SPD<3:0> pins during chip cold reset. For non-OCI links, this field is not used.
+	uint64_t spd                          : 4;  /**< For OCI links (i.e. GSER8..13), the hardware loads this CSR field from the OCI_SPD<3:0>
+                                                         pins during chip cold reset. For non-OCI links, this field is not used.
                                                          For SPD settings that configure a non-default reference clock, hardware updates the PLL
                                                          settings of the specific lane mode (LMODE) table entry to derive the correct link rate.
-                                                         SPD     REFCLK     Link rate    LMODE
-                                                         0x0:    100 MHz    1.25 Gbps    R_125G_REFCLK15625_KX
-                                                         0x1:    100 MHz    2.5Gbps      R_25G_REFCLK100
-                                                         0x2:    100 MHz    5Gbps        R_5G_REFCLK100
-                                                         0x3:    100 MHz    8Gbps        R_8G_REFCLK100
-                                                         0x4:    125 MHz    1.25Gbps     R_125G_REFCLK15625_KX
-                                                         0x5:    125 MHz    2.5Gbps      R_25G_REFCLK125
-                                                         0x6:    125 MHz    3.125Gbps    R_3125G_REFCLK15625_XAUI
-                                                         0x7:    125 MHz    5Gbps        R_5G_REFCLK125
-                                                         0x8:    125 MHz    6.25Gbps     R_625G_REFCLK15625_RXAUI
-                                                         0x9:    125 MHz    8Gbps        R_8G_REFCLK125
-                                                         0xA:    156.25 MHz 2.5Gbps      R_25G_REFCLK100
-                                                         0xB:    156.25 MHz 3.125Gbps    R_3125G_REFCLK15625_XAUI
-                                                         0xC:    156.25 MHz 5Gbps        R_5G_REFCLK125
-                                                         0xD:    156.25 MHz 6.25Gbps     R_625G_REFCLK15625_RXAUI
-                                                         0xE:    126.25 MHz 10.3125Gbps  R_103125G_REFCLK15625_KR
+                                                         SPD     REFCLK     Link rate      LMODE
+                                                         0x0:    100 MHz    1.25 Gbaud     R_125G_REFCLK15625_KX
+                                                         0x1:    100 MHz    2.5 Gbaud      R_25G_REFCLK100
+                                                         0x2:    100 MHz    5 Gbaud        R_5G_REFCLK100
+                                                         0x3:    100 MHz    8 Gbaud        R_8G_REFCLK100
+                                                         0x4:    125 MHz    1.25 Gbaud     R_125G_REFCLK15625_KX
+                                                         0x5:    125 MHz    2.5 Gbaud      R_25G_REFCLK125
+                                                         0x6:    125 MHz    3.125 Gbaud    R_3125G_REFCLK15625_XAUI
+                                                         0x7:    125 MHz    5 Gbaud        R_5G_REFCLK125
+                                                         0x8:    125 MHz    6.25 Gbaud     R_625G_REFCLK15625_RXAUI
+                                                         0x9:    125 MHz    8 Gbaud        R_8G_REFCLK125
+                                                         0xA:    156.25 MHz 2.5 Gbaud      R_25G_REFCLK100
+                                                         0xB:    156.25 MHz 3.125 Gbaud    R_3125G_REFCLK15625_XAUI
+                                                         0xC:    156.25 MHz 5 Gbaud        R_5G_REFCLK125
+                                                         0xD:    156.25 MHz 6.25 Gbaud     R_625G_REFCLK15625_RXAUI
+                                                         0xE:    156.25 MHz 10.3125 Gbaud  R_103125G_REFCLK15625_KR
                                                          0xF:               SW_MODE
                                                          Note that a value of 0xF is called SW_MODE. The OCI link does not come up configured in
                                                          SW_MODE.
                                                          (Software must do all the OCI GSER configuration to use OCI in the case of SW_MODE.)
                                                          When SPD!=SW_MODE after a chip cold reset, the hardware has initialized the following
-                                                         registers
-                                                         (based on the OCI_SPD selection):
-                                                          o GSER(8..13)_LANE_MODE[LMODE]=Z
-                                                          o GSER(8..13)_PLL_P(Z)_MODE_0
-                                                          o GSER(8..13)_PLL_P(Z)_MODE_1
-                                                          o GSER(8..13)_LANE(0..3)_P(Z)_MODE_0
-                                                          o GSER(8..13)_LANE(0..3)_P(Z)_MODE_1
-                                                          o GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_0
-                                                          o GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_1
-                                                          o GSER(0..13)_LANE(0..3)_RX_VALBBD_CTRL_2
+                                                         registers (based on the OCI_SPD selection):
+                                                          * GSER(8..13)_LANE_MODE[LMODE]=Z
+                                                          * GSER(8..13)_PLL_P(Z)_MODE_0
+                                                          * GSER(8..13)_PLL_P(Z)_MODE_1
+                                                          * GSER(8..13)_LANE(0..3)_P(Z)_MODE_0
+                                                          * GSER(8..13)_LANE(0..3)_P(Z)_MODE_1
+                                                          * GSER(8..13)_LANE(0..3)_RX_VALBBD_CTRL_0
+                                                          * GSER(8..13)_LANE(0..3)_RX_VALBBD_CTRL_1
+                                                          * GSER(8..13)_LANE(0..3)_RX_VALBBD_CTRL_2
                                                          where Z is the LMODE indicated by the prior table. */
 #else
 	uint64_t spd                          : 4;
@@ -5325,8 +5587,8 @@ typedef union cvmx_gserx_spd cvmx_gserx_spd_t;
 /**
  * cvmx_gser#_srst
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_srst {
 	uint64_t u64;
@@ -5345,38 +5607,10 @@ union cvmx_gserx_srst {
 typedef union cvmx_gserx_srst cvmx_gserx_srst_t;
 
 /**
- * cvmx_gser#_tx_pstate
- *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
- */
-union cvmx_gserx_tx_pstate {
-	uint64_t u64;
-	struct cvmx_gserx_tx_pstate_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_3_63                : 61;
-	uint64_t txpstate                     : 3;  /**< For links that are not in PCIE mode (including all OCI links), allows TX lane power state
-                                                         control. For diagnostic use only.
-                                                         0x0 = P0. Active state. All internal clocks in the PHY are operational, the only state
-                                                         where the PHY transmits and receives link data.
-                                                         0x1 = P0s. Standby state. The TX link is disabled.
-                                                         0x2 = P1. Low power state: Selected internal clocks in the PHY are turned off.
-                                                         0x3 = P2. Power down. All clocks in the PHY are turned off.
-                                                         else = Reserved. */
-#else
-	uint64_t txpstate                     : 3;
-	uint64_t reserved_3_63                : 61;
-#endif
-	} s;
-	struct cvmx_gserx_tx_pstate_s         cn78xx;
-};
-typedef union cvmx_gserx_tx_pstate cvmx_gserx_tx_pstate_t;
-
-/**
  * cvmx_gser#_tx_vboost
  *
- * These registers are only reset by hardware during chip cold reset.
- * The values of the CSR fields in these registers do not change during chip warm or soft resets.
+ * These registers are only reset by hardware during chip cold reset. The values of the CSR
+ * fields in these registers do not change during chip warm or soft resets.
  */
 union cvmx_gserx_tx_vboost {
 	uint64_t u64;
@@ -5385,10 +5619,10 @@ union cvmx_gserx_tx_vboost {
 	uint64_t reserved_4_63                : 60;
 	uint64_t vboost                       : 4;  /**< For links that are not in PCIE mode (including all OCI links), boosts the TX Vswing from
                                                          VDD to 1.0 VPPD.
-                                                         <3>: Lane 3
-                                                         <2>: Lane 2
-                                                         <1>: Lane 1
-                                                         <0>: Lane 0 */
+                                                         <3>: Lane 3.
+                                                         <2>: Lane 2.
+                                                         <1>: Lane 1.
+                                                         <0>: Lane 0. */
 #else
 	uint64_t vboost                       : 4;
 	uint64_t reserved_4_63                : 60;
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
index ae370e2..70b614a 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
@@ -48,6 +48,8 @@
 #ifndef __CVMX_HELPER_BGX_H__
 #define __CVMX_HELPER_BGX_H__
 
+#define CVMX_BGX_RX_FIFO_SIZE	(64 * 1024)
+
 extern int __cvmx_helper_bgx_enumerate(int interface);
 
 /**
@@ -103,7 +105,7 @@ extern cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port);
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port, 
+extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
 					    cvmx_helper_link_info_t link_info);
 
 /**
@@ -121,8 +123,8 @@ extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
  *
  * @return Zero on success, negative on failure.
  */
-extern int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port, 
-						      int enable_internal, 
+extern int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port,
+						      int enable_internal,
 						      int enable_external);
 
 /**
@@ -166,7 +168,7 @@ extern cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port);
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port, 
+extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port,
 					   cvmx_helper_link_info_t link_info);
 
 /**
@@ -184,7 +186,28 @@ extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port,
  *
  * @return Zero on success, negative on failure.
  */
-extern int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port, 
-						     int enable_internal, 
+extern int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port,
+						     int enable_internal,
 						     int enable_external);
+/**
+ * @INTERNAL
+ * Configure Priority-Based Flow Control (a.k.a. PFC/CBFC)
+ * on a specific BGX interface/port.
+ */
+extern void __cvmx_helper_bgx_xaui_config_pfc(unsigned node,
+		unsigned interface, unsigned port, bool pfc_enable);
+/**
+ * This function control how the hardware handles incoming PAUSE
+ * packets. The most common modes of operation:
+ * ctl_bck = 1, ctl_drp = 1: hardware handles everything
+ * ctl_bck = 0, ctl_drp = 0: software sees all PAUSE frames
+ * ctl_bck = 0, ctl_drp = 1: all PAUSE frames are completely ignored
+ * @param node		node number.
+ * @param interface	interface number
+ * @param port		port number
+ * @param ctl_bck	1: Forward PAUSE information to TX block
+ * @param ctl_drp	1: Drop control PAUSE frames.
+ */
+extern void cvmx_helper_bgx_rx_pause_ctl(unsigned node, unsigned interface,
+				  unsigned port, unsigned ctl_bck, unsigned ctl_drp);
 #endif
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-board.h b/arch/mips/include/asm/octeon/cvmx-helper-board.h
index 1d744d1..af37ec0 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-board.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-board.h
@@ -43,7 +43,7 @@
  * Helper functions to abstract board specific data about
  * network ports from the rest of the cvmx-helper files.
  *
- * <hr>$Revision: 93549 $<hr>
+ * <hr>$Revision: 96046 $<hr>
  */
 #ifndef __CVMX_HELPER_BOARD_H__
 #define __CVMX_HELPER_BOARD_H__
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
index 8e480a4..c05e19b 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
@@ -62,6 +62,12 @@
 #ifndef __CVMX_HELPER_CFG_H__
 #define __CVMX_HELPER_CFG_H__
 
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+#include <asm/octeon/cvmx-helper-util.h>
+#else
+#include "cvmx-helper-util.h"
+#endif
+
 #define CVMX_HELPER_CFG_MAX_PKO_PORT		128
 #define CVMX_HELPER_CFG_MAX_PIP_BPID       	64
 #define CVMX_HELPER_CFG_MAX_PIP_PKND       	64
@@ -126,6 +132,7 @@ struct cvmx_cfg_port_param {
 	bool sgmii_1000x_mode;		/** 1 = 1000Base-X mode, 0 = SGMII mode */
 	bool agl_rx_clk_delay_bypass;	/** 1 = use rx clock delay bypass for AGL mode */
 	uint8_t agl_rx_clk_skew;	/** AGL rx clock skew setting (default 0) */
+	bool force_link_up;		/** Ignore PHY and always report link up */
 };
 
 /*
@@ -160,23 +167,28 @@ typedef union cvmx_user_static_pko_queue_config
 {
 	struct
 	{
-		int pko_queues_per_port_interface[5];
-		int pko_queues_per_port_loop;
-		int pko_queues_per_port_pci;
+		struct pko_queues_cfg {
+			unsigned
+				queues_per_port:5,
+				qos_enable:1,
+				pfc_enable:1;
+		} pko_cfg_iface[6];
+		struct pko_queues_cfg pko_cfg_loop;
+		struct pko_queues_cfg pko_cfg_npi;
 	} pknd;
 	struct
 	{
-		int pko_ports_per_interface[2];
-		int pko_queues_per_port_interface[2];
-		int pko_queues_per_port_loop;
-		int pko_queues_per_port_pci;
-		int pko_queues_per_port_srio[4];
+		uint8_t pko_ports_per_interface[2];
+		uint8_t pko_queues_per_port_interface[2];
+		uint8_t pko_queues_per_port_loop;
+		uint8_t pko_queues_per_port_pci;
+		uint8_t pko_queues_per_port_srio[4];
 	} non_pknd;
 } cvmx_user_static_pko_queue_config_t;
 
 extern CVMX_SHARED cvmx_user_static_pko_queue_config_t __cvmx_pko_queue_static_config;
 extern CVMX_SHARED struct cvmx_cfg_pko_port_map cvmx_cfg_pko_port_map[CVMX_HELPER_CFG_MAX_PKO_PORT];
-extern CVMX_SHARED struct cvmx_cfg_port_param cvmx_cfg_port [][CVMX_HELPER_CFG_MAX_PORT_PER_IFACE];
+extern CVMX_SHARED struct cvmx_cfg_port_param cvmx_cfg_port [CVMX_MAX_NODES][CVMX_HELPER_MAX_IFACE][CVMX_HELPER_CFG_MAX_PORT_PER_IFACE];
 extern CVMX_SHARED struct cvmx_cfg_pko_port_param cvmx_pko_queue_table[];
 extern CVMX_SHARED int cvmx_enable_helper_flag;
 /*
@@ -292,6 +304,8 @@ extern int __cvmx_helper_cfg_pko_max_engine(void);
  *
  * @param opt is the config option.
  * @return the value set for the option
+ *
+ * LR: only used for DWB in NPI, POW, PKO1
  */
 extern uint64_t cvmx_helper_cfg_opt_get(cvmx_helper_cfg_option_t opt);
 
@@ -305,6 +319,8 @@ extern uint64_t cvmx_helper_cfg_opt_get(cvmx_helper_cfg_option_t opt);
  * Note an option here is a config-time parameter and this means that
  * it has to be set before calling the corresponding setup functions
  * that actually sets the option in hw.
+ *
+ * LR: Not used.
  */
 extern int cvmx_helper_cfg_opt_set(cvmx_helper_cfg_option_t opt, uint64_t val);
 
@@ -380,6 +396,8 @@ extern void cvmx_helper_cfg_store_short_packets_in_wqe(void);
  *
  * @return  0 on success
  *         -1 on failure
+ *
+ * LR: Called ONLY from comfig-parse!
  */
  int cvmx_pko_alloc_iport_and_queues(int interface, int port, int port_cnt,
 				     int queue_cnt);
@@ -473,6 +491,17 @@ extern void cvmx_helper_set_agl_rx_clock_delay_bypass(int interface, int index,
 
 /**
  * @INTERNAL
+ * Forces a link to always return that it is up ignoring the PHY (if present)
+ *
+ * @param interface the interface number
+ * @param index the port's index
+ */
+extern bool cvmx_helper_get_port_force_link_up(int interface, int index);
+extern void cvmx_helper_set_port_force_link_up(int interface, int index,
+					       bool value);
+
+/**
+ * @INTERNAL
  * Return the AGL port rx clock skew, only used
  * if agl_rx_clock_delay_bypass is set.
  *
@@ -482,6 +511,7 @@ extern void cvmx_helper_set_agl_rx_clock_delay_bypass(int interface, int index,
 extern uint8_t cvmx_helper_get_agl_rx_clock_skew(int interface, int index);
 extern void cvmx_helper_set_agl_rx_clock_skew(int interface, int index,
 					      uint8_t value);
+
 /*
  * Initializes cvmx with user specified config info.
  */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-fpa.h b/arch/mips/include/asm/octeon/cvmx-helper-fpa.h
index 76a5f60..ab10b0c 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-fpa.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-fpa.h
@@ -47,6 +47,8 @@
 #ifndef __CVMX_HELPER_H_FPA__
 #define __CVMX_HELPER_H_FPA__
 
+extern int fpa_helper_debug;
+
 /**
  * Allocate memory and initialize the FPA pools using memory
  * from cvmx-bootmem. Sizes of each element in the pools is
@@ -78,8 +80,6 @@ extern int __cvmx_helper_initialize_fpa_pool(int pool, uint64_t buffer_size,
 					     uint64_t buffers,
 					     const char *name);
 
-extern void cvmx_fpa_show_stats(void);
-
 /**
  * Function to create a simple 1:1 pool/aura configuration.
  * Meant to make pool/aura initialization easy for SE apps.
@@ -96,7 +96,7 @@ extern void cvmx_fpa_show_stats(void);
  */
 
 extern int cvmx_helper_fpa_init(int node, int *pool_num, int *aura_id, int block_size,
-				int num_blocks, const char *name, void **buffers);
+				int num_blocks, const char *name, void *buffers);
 
 /**
  * Function to setup and initialize a pool.
@@ -109,7 +109,7 @@ extern int cvmx_helper_fpa_init(int node, int *pool_num, int *aura_id, int block
  * @param name - name to register
  */
 
-extern int cvmx_helper_fpa_init_pool(int node, int mem_node, int *pool_num, int block_size, int num_blocks, const char *name);
+extern int cvmx_helper_fpa3_init_pool(int node, int mem_node, int *pool_num, int block_size, int num_blocks, const char *name);
 
 /**
  * Function to add an aura to an existing pool
@@ -124,7 +124,7 @@ extern int cvmx_helper_fpa_init_pool(int node, int mem_node, int *pool_num, int
  * @return -1 on error, 0 on success with buffers containing allocated memory if passed NULL
  */
 
-extern int cvmx_helper_fpa_add_aura_to_pool(int node, int pool_num, int *aura_id, int num_blocks, void **buffer, const char *name);
+extern int cvmx_helper_fpa3_add_aura_to_pool(int node, int pool_num, int *aura_id, int num_blocks, void *buffer, const char *name);
 
 /**
  * Function to fill a pre-78xx fpa pool with memory
@@ -136,6 +136,14 @@ extern int cvmx_helper_fpa_add_aura_to_pool(int node, int pool_num, int *aura_id
  * @param buffer - buffer to add blocks from
  */
 
-extern int cvmx_helper_fpa_fill_pool(int pool_num, int num_blocks, void **buffer);
+extern int cvmx_helper_fpa_fill_pool(int pool_num, int num_blocks, void *buffer);
+
+extern int cvmx_helper_fpa3_shutdown_pool(int node, int pool_num);
+
+extern int cvmx_helper_fpa3_shutdown_aura(int node, int aura_id);
+
+extern int cvmx_helper_fpa3_shutdown_aura_and_pool(int node, int aura_id);
+
+extern int cvmx_helper_shutdown_fpa_pools(int node);
 
 #endif /* __CVMX_HELPER_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-ilk.h b/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
index 83feed0..4da1c18 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
@@ -91,7 +91,7 @@ void __cvmx_ilk_write_rx_cal_entry(int interface, int channel,
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-extern int __cvmx_helper_ilk_probe(int interface);
+extern int __cvmx_helper_ilk_probe(int xiface);
 
 /**
  * @INTERNAL
@@ -103,7 +103,7 @@ extern int __cvmx_helper_ilk_probe(int interface);
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_ilk_enable(int interface);
+extern int __cvmx_helper_ilk_enable(int xiface);
 
 /**
  * @INTERNAL
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-npi.h b/arch/mips/include/asm/octeon/cvmx-helper-npi.h
index 7bfa3ba..0cb4849 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-npi.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-npi.h
@@ -43,7 +43,7 @@
  * Functions for NPI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 89425 $<hr>
+ * <hr>$Revision: 96176 $<hr>
  */
 #ifndef __CVMX_HELPER_NPI_H__
 #define __CVMX_HELPER_NPI_H__
@@ -59,10 +59,6 @@
  * @return Number of ports on the interface. Zero to disable.
  */
 extern int __cvmx_helper_npi_probe(int interface);
-static inline int __cvmx_helper_npi_enumerate(int interface)
-{
-	return __cvmx_helper_npi_probe(interface);
-}
 
 /**
  * @INTERNAL
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-pki.h b/arch/mips/include/asm/octeon/cvmx-helper-pki.h
index 28716ad..c039bfc 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-pki.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-pki.h
@@ -59,22 +59,96 @@ extern "C" {
 /* *INDENT-ON* */
 #endif
 
-extern struct cvmx_pki_global_config pki_dflt_gblcfg[CVMX_MAX_NODES];
-extern struct cvmx_pki_pool_config pki_dflt_pool[CVMX_MAX_NODES];
-extern struct cvmx_pki_aura_config pki_dflt_aura[CVMX_MAX_NODES];
-extern struct cvmx_pki_sso_grp_config pki_dflt_sso_grp[CVMX_MAX_NODES];
-extern struct cvmx_pki_qpg_config pki_dflt_qpg[CVMX_MAX_NODES];
+/* Modify this if more than 8 ilk channels need to be supported */
+#define CVMX_MAX_PORT_PER_INTERFACE	8
+#define CVMX_MAX_QOS_PRIORITY		64
+
+struct cvmx_pki_qos_schd {
+	bool pool_per_qos;	/* This qos priority will use its own pool, if FALSE use port pool */
+	int pool;		/* pool number to use, if -1 allocated by software */
+	char *pool_name;
+	uint64_t pool_buff_size;/* size of buffer in pool , if this priority is using its own pool*/
+	uint64_t pool_max_buff;	/* number of max buffers allowed in the pool, if this priority is using its own pool*/
+	bool aura_per_qos;	/* This qos priority will use its own aura, if FALSE use port aura */
+	int aura;		/* aura number to use, if -1 allocated by software */
+	char *aura_name;
+	uint64_t aura_buff_cnt;	/* number of buffers in aura, if this priority is using its own aura*/
+	bool sso_grp_per_qos;	/* This qos priority will use its own group, if FALSE use port group */
+	int sso_grp;		/* group number to use, if -1 allocated by software */
+	uint16_t port_add;       /* for BGX super MAC ports which wants to have PFC enabled */
+	unsigned qpg_base;
+};
+
+struct cvmx_pki_prt_schd {
+	int style;              /* If style_per_prt is TRUE in interface schd */
+	bool pool_per_prt; 	/* Port will use its own pool, if FALSE use interface pool */
+	int pool;		/* pool number to use, if -1 allocated by software */
+	char *pool_name;
+	uint64_t pool_buff_size;/*size of buffer in pool , if this port is using its own pool*/
+	uint64_t pool_max_buff;	/* number of max buffers allowed in the pool, if this port is using its own pool*/
+	bool aura_per_prt;	/* port will use its own aura, if FALSE use interface aura */
+	int aura;		/* aura number to use, if -1 allocated by software */
+	char *aura_name;
+	uint64_t aura_buff_cnt;	/* number of buffers in aura, if this pool is using its own aura*/
+	bool sso_grp_per_prt; 	/* port will use its own sso group, if FALSE use interface group*/
+	int sso_grp;		/* sso group number to use, if -1 allocated by software */
+	enum cvmx_pki_qpg_qos qpg_qos;
+	unsigned qpg_base;
+	struct cvmx_pki_qos_schd qos_s[CVMX_MAX_QOS_PRIORITY];
+};
+
+struct cvmx_pki_intf_schd {
+	bool style_per_prt;	/* Every port will use different style/profile */
+	bool style_per_intf;	/* otherwise all ports on this interface will use same style/profile */
+	int style;
+	bool pool_per_intf; 	/* Ports will use either this shared pool or their own pool*/
+	int pool;		/* pool number to use, if -1 allocated by software*/
+	char *pool_name;
+	uint64_t pool_buff_size;
+	uint64_t pool_max_buff;
+	bool aura_per_intf; 	/* Ports will use either this shared aura or their own aura */
+	int aura;		/* aura number to use, if -1 allocated by software*/
+	char *aura_name;
+	uint64_t aura_buff_cnt;
+	bool sso_grp_per_intf;	/* Ports will use either this shared group or their own aura */
+	int sso_grp;		/* sso group number to use, if -1 allocated by software */
+	bool qos_share_aura;	/* All ports share the same aura for respective qos if qpg_qos used*/
+	bool qos_share_grp; 	/* All ports share the same sso group for respective qos if qps qos used*/
+	unsigned qpg_base;
+	struct cvmx_pki_prt_schd prt_s[CVMX_MAX_PORT_PER_INTERFACE];
+};
+
+struct cvmx_pki_global_schd {
+	bool setup_pool;
+	int pool;
+	char *pool_name;
+	uint64_t pool_buff_size;
+	uint64_t pool_max_buff;
+	bool setup_aura;
+	int aura;
+	char *aura_name;
+	uint64_t aura_buff_cnt;
+	bool setup_sso_grp;
+	int sso_grp;
+};
+
+extern CVMX_SHARED bool cvmx_pki_dflt_init[CVMX_MAX_NODES];
+
+extern CVMX_SHARED struct cvmx_pki_pool_config pki_dflt_pool[CVMX_MAX_NODES];
 extern uint64_t style_qpg_base_map[CVMX_MAX_NODES];
-extern struct cvmx_pki_style_config pki_dflt_style[CVMX_MAX_NODES];
-extern struct cvmx_pki_pkind_config pki_dflt_pkind[CVMX_MAX_NODES];
-extern uint64_t pkind_style_map[CVMX_MAX_NODES][CVMX_PKI_NUM_PKIND];
+extern CVMX_SHARED struct cvmx_pki_style_config pki_dflt_style[CVMX_MAX_NODES];
+extern CVMX_SHARED struct cvmx_pki_pkind_config pki_dflt_pkind[CVMX_MAX_NODES];
+extern CVMX_SHARED uint64_t pkind_style_map[CVMX_MAX_NODES][CVMX_PKI_NUM_PKIND];
 
+void cvmx_helper_pki_enable(int node);
 int cvmx_helper_setup_pki_port(int node, int pknd);
-int cvmx_helper_pki_setup_qpg_table(int node, int num_entries, int port_addr[],
-				    uint64_t aura[], uint64_t sso_grp_ok[], uint64_t sso_grp_bad[]);
+int cvmx_helper_pki_setup_qpg_table(int node, int num_entries,
+				    struct cvmx_pki_qpg_config *qpg_cfg);
 void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs);
+int cvmx_helper_pki_get_num_qpg_entry(enum cvmx_pki_qpg_qos qpg_qos);
 int __cvmx_helper_pki_port_setup(int node, int ipd_port);
 int __cvmx_helper_pki_global_setup(int node);
+int __cvmx_helper_pki_install_default_vlan(int node);
 void cvmx_helper_pki_set_dflt_pool(int node, int pool,
 				   int buffer_size, int buffer_count);
 void cvmx_helper_pki_set_dflt_aura(int node, int aura,
@@ -104,6 +178,19 @@ int cvmx_helper_setup_aura_qos(int node, int aura, bool ena_red, bool ena_drop,
 int cvmx_helper_pki_map_aura_chl_bpid(int node, int aura_map[], int aura_cnt,
 				      int chl_map[], int chl_cnt, int bpid);
 void cvmx_helper_pki_set_dflt_pkind_map(int node, int pkind, int style);
+void cvmx_helper_pki_get_dflt_style(int node, struct cvmx_pki_style_config *style_cfg);
+void cvmx_helper_pki_set_dflt_style(int node, struct cvmx_pki_style_config *style_cfg);
+
+
+/* Shutdown complete PKI hardware and software resources */
+void cvmx_helper_pki_shutdown(int node);
+
+int cvmx_helper_pki_set_gbl_schd(int node, struct cvmx_pki_global_schd *gbl_schd);
+
+int cvmx_helper_pki_init_interface(int xiface,
+				   struct cvmx_pki_intf_schd *intf, struct cvmx_pki_global_schd *gbl_schd);
+int cvmx_helper_pki_init_port(int ipd_port, struct cvmx_pki_prt_schd *prtsch);
+void cvmx_helper_pki_no_dflt_init(int node);
 
 #ifdef __cplusplus
 /* *INDENT-OFF* */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-pko3.h b/arch/mips/include/asm/octeon/cvmx-helper-pko3.h
index 76da789a..e1265d9 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-pko3.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-pko3.h
@@ -61,16 +61,26 @@ extern "C" {
  * @return 0 on success.
  *
  */
-extern int cvmx_helper_pko3_init_global(void);
+extern int cvmx_helper_pko3_init_global(unsigned int node);
+int __cvmx_helper_pko3_init_global(unsigned int node, uint16_t gaura);
+
+/** 
+ * Initialize a simple interface with a a given number of
+ * fair or prioritized queues.
+ * This function will assign one channel per sub-interface.
+ */
+int __cvmx_pko3_config_gen_interface(int xiface, uint8_t subif,
+				     uint8_t num_queues, bool prioritized);
 
 /*
- * Conhfigure and initialize PKO3 for an interface
+ * Configure and initialize PKO3 for an interface
  *
  * @param interface is the interface number to configure
  * @return 0 on success.
  *
  */
-extern int cvmx_helper_pko3_init_interface(unsigned interface);
+int cvmx_helper_pko3_init_interface(int xiface);
+int __cvmx_pko3_helper_dqs_activate(int xiface, int index);
 
 /**
  * Uninitialize PKO3 interface
@@ -78,7 +88,7 @@ extern int cvmx_helper_pko3_init_interface(unsigned interface);
  * Release all resources held by PKO for an interface.
  * The shutdown code is the same for all supported interfaces.
  */
-extern int cvmx_helper_pko3_shut_interface(int interface);
+extern int cvmx_helper_pko3_shut_interface(int xiface);
 
 /**
  * Shutdown PKO3
@@ -87,7 +97,7 @@ extern int cvmx_helper_pko3_shut_interface(int interface);
  *
  * Disables the PKO, frees all its buffers.
  */
-extern int cvmx_helper_pko3_shutdown(void);
+extern int cvmx_helper_pko3_shutdown(unsigned int node);
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h b/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
index 81c9e08..0ca6577 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
@@ -43,7 +43,7 @@
  * Functions for RGMII/GMII/MII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 86586 $<hr>
+ * <hr>$Revision: 96176 $<hr>
  */
 #ifndef __CVMX_HELPER_RGMII_H__
 #define __CVMX_HELPER_RGMII_H__
@@ -56,11 +56,7 @@
  *
  * @return Number of RGMII/GMII/MII ports (0-4).
  */
-extern int __cvmx_helper_rgmii_probe(int interface);
-static inline int __cvmx_helper_rgmii_enumerate(int interface)
-{
-	return __cvmx_helper_rgmii_probe(interface);
-}
+extern int __cvmx_helper_rgmii_probe(int xiface);
 
 /**
  * Put an RGMII interface in loopback mode. Internal packets sent
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h b/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
index 6e48669..e3402ef 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 93962 $<hr>
+ * <hr>$Revision: 96415 $<hr>
  */
 #ifndef __CVMX_HELPER_SGMII_H__
 #define __CVMX_HELPER_SGMII_H__
@@ -58,8 +58,8 @@
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-extern int __cvmx_helper_sgmii_probe(int interface);
-extern int __cvmx_helper_sgmii_enumerate(int interface);
+extern int __cvmx_helper_sgmii_probe(int xiface);
+extern int __cvmx_helper_sgmii_enumerate(int xiface);
 
 /**
  * @INTERNAL
@@ -71,7 +71,7 @@ extern int __cvmx_helper_sgmii_enumerate(int interface);
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_sgmii_enable(int interface);
+extern int __cvmx_helper_sgmii_enable(int xiface);
 
 /**
  * @INTERNAL
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-srio.h b/arch/mips/include/asm/octeon/cvmx-helper-srio.h
index aa81feb..b6dc0202 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-srio.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-srio.h
@@ -59,10 +59,6 @@
  * @return Number of ports on the interface. Zero to disable.
  */
 extern int __cvmx_helper_srio_probe(int interface);
-static inline int __cvmx_helper_srio_enumerate(int interface)
-{
-	return __cvmx_helper_srio_probe(interface);
-}
 
 /**
  * @INTERNAL
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-util.h b/arch/mips/include/asm/octeon/cvmx-helper-util.h
index 6476ed4..dca3cfd 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-util.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-util.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2012  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -42,7 +42,7 @@
  *
  * Small helper utilities.
  *
- * <hr>$Revision: 95258 $<hr>
+ * <hr>$Revision: 96774 $<hr>
  */
 
 #ifndef __CVMX_HELPER_UTIL_H__
@@ -51,6 +51,8 @@
 #include "cvmx.h"
 #include "cvmx-mio-defs.h"
 #include "cvmx-helper.h"
+#include "cvmx-fpa1.h"
+#include "cvmx-fpa3.h"
 
 
 typedef char cvmx_pknd_t;
@@ -64,6 +66,83 @@ typedef char cvmx_bpid_t;
 #define CVMX_HELPER_MAX_IFACE		11
 #define CVMX_HELPER_MAX_PORTS		16
 
+
+/* Maximum range for normalized (a.k.a. IPD) port numbers (12-bit field) */
+#define	CVMX_PKO3_IPD_NUM_MAX	0x1000	//FIXME- take it from someplace else ?
+
+#define CVMX_PKO3_IPD_PORT_NULL (CVMX_PKO3_IPD_NUM_MAX-1)
+
+struct cvmx_xport {
+	int node;
+	int port;
+};
+typedef struct cvmx_xport cvmx_xport_t;
+
+static inline struct cvmx_xport cvmx_helper_ipd_port_to_xport(int ipd_port)
+{
+	struct cvmx_xport r;
+	r.port = ipd_port & (CVMX_PKO3_IPD_NUM_MAX - 1);
+	r.node = (ipd_port >> 12) & CVMX_NODE_MASK;
+	return r;
+}
+
+static inline int cvmx_helper_node_to_ipd_port(int node, int index)
+{
+	return (node << 12) + index;
+}
+
+struct cvmx_xiface {
+	int node;
+	int interface;
+};
+typedef struct cvmx_xiface cvmx_xiface_t;
+
+/**
+ * Return node and interface number from XIFACE.
+ *
+ * @param xiface interface with node information
+ *
+ * @return struct that contains node and interface number.
+ */
+static inline struct cvmx_xiface cvmx_helper_xiface_to_node_interface(int xiface)
+{
+	cvmx_xiface_t interface_node;
+	/*
+	 * If the majic number 0xde0000 is not present in the
+	 * interface, then assume it is node 0.
+	 */
+
+	if (((xiface >> 0x8) & 0xff) == 0xde) {
+		interface_node.node = (xiface >> 16) & CVMX_NODE_MASK;
+		interface_node.interface = xiface & 0xff;
+	} else {
+		interface_node.node = cvmx_get_node_num();
+		interface_node.interface = xiface & 0xff;
+	}
+	return interface_node;
+}
+
+/* Used internally only*/
+static inline bool __cvmx_helper_xiface_is_null(int xiface)
+{
+	return (xiface & 0xff) == 0xff;
+}
+
+#define __CVMX_XIFACE_NULL 0xff
+
+/**
+ * Return interface with majic number and node information (XIFACE)
+ *
+ * @param node       node of the interface referred to
+ * @param interface  interface to use.
+ *
+ * @return
+ */
+static inline int cvmx_helper_node_interface_to_xiface(int node, int interface)
+{
+	return ((node & CVMX_NODE_MASK) << 16) | (0xde << 8) | (interface & 0xff);
+}
+
 /**
  * Convert a interface mode into a human readable string
  *
@@ -100,17 +179,7 @@ extern const char *cvmx_helper_get_version(void);
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_setup_gmx(int interface, int num_ports);
-
-/**
- * @INTERNAL
- * Get the number of ipd_ports on an interface.
- *
- * @param interface
- *
- * @return the number of ipd_ports on the interface and -1 for error.
- */
-extern int __cvmx_helper_get_num_ipd_ports(int interface);
+extern int __cvmx_helper_setup_gmx(int xiface, int num_ports);
 
 /**
  * @INTERNAL
@@ -122,55 +191,6 @@ extern int __cvmx_helper_get_num_ipd_ports(int interface);
  */
 extern int __cvmx_helper_get_num_pko_ports(int interface);
 
-/*
- * @INTERNAL
- *
- * @param interface
- * @param port
- * @param link_info
- *
- * @return 0 for success and -1 for failure
- */
-extern int __cvmx_helper_set_link_info(int interface, int port, cvmx_helper_link_info_t link_info);
-
-/**
- * @INTERNAL
- *
- * @param interface
- * @param port
- *
- * @return valid link_info on success or -1 on failure
- */
-extern cvmx_helper_link_info_t __cvmx_helper_get_link_info(int interface, int port);
-
-enum cvmx_pko_padding {
-	CVMX_PKO_PADDING_NONE = 0,
-	CVMX_PKO_PADDING_60 = 1,
-};
-
-/**
- * @INTERNAL
- *
- * @param interface
- * @param num_ipd_ports is the number of ipd_ports on the interface
- * @param has_fcs indicates if PKO does FCS for the ports on this
- * @param pad The padding that PKO should apply.
- * interface.
- *
- * @return 0 for success and -1 for failure
- */
-extern int __cvmx_helper_init_interface(int interface, int num_ipd_ports, int has_fcs, enum cvmx_pko_padding pad);
-
-/**
- * @INTERNAL
- *
- * @param interface
- *
- * @return 0 if PKO does not do FCS and 1 otherwise.
- */
-extern int __cvmx_helper_get_has_fcs(int interface);
-
-extern enum cvmx_pko_padding __cvmx_helper_get_pko_padding(int interface);
 
 /**
  * Returns the IPD port number for a port on the given
@@ -240,95 +260,7 @@ static inline int cvmx_helper_get_last_ipd_port(int interface)
  *
  * @param work   Work queue entry with packet to free
  */
-static inline void cvmx_helper_free_packet_data(cvmx_wqe_t *work)
-{
-	uint64_t number_buffers;
-	uint64_t start_of_buffer;
-	uint64_t next_buffer_ptr;
-	unsigned ncl;
-	cvmx_buf_ptr_t buffer_ptr;
-	cvmx_buf_ptr_pki_t bptr;
-	cvmx_wqe_78xx_t *wqe = (void *) work;
-
-	number_buffers = cvmx_wqe_get_bufs(work);
-
-	buffer_ptr.u64 = work->packet_ptr.u64;
-
-	/* Zero-out WQE WORD3 so that the WQE is freed by cvmx_wqe_free() */
-	work->packet_ptr.u64 = 0;
-
-	if (number_buffers == 0)
-		return;
-
-	/* Interpret PKI-style bufptr unless it has been translated */
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
-	    !wqe->pki_wqe_translated) {
-		bptr.u64 = buffer_ptr.u64;
-		next_buffer_ptr = *(uint64_t *)
-			cvmx_phys_to_ptr(bptr.s_cn78xx.addr - 8);
-		if (!bptr.s_cn78xx.packet_outside_wqe) {
-			buffer_ptr.u64 = next_buffer_ptr;
-			number_buffers--;
-		}
-	} else {
-		start_of_buffer =
-			((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back) << 7;
-		next_buffer_ptr = *(uint64_t *)
-			cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
-		/* Since the number of buffers is not zero, we know this is not a dynamic
-		short packet. We need to check if it is a packet received with
-		IPD_CTL_STATUS[NO_WPTR]. If this is true, we need to free all buffers
-		except for the first one. The caller doesn't expect their WQE pointer
-		to be freed */
-		if (cvmx_ptr_to_phys(work) == start_of_buffer) {
-			buffer_ptr.u64 = next_buffer_ptr;
-			number_buffers--;
-		}
-	}
-	while (number_buffers--) {
-		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
-		    !wqe->pki_wqe_translated) {
-			unsigned aura = cvmx_wqe_get_aura(work);
-			bptr.u64 = buffer_ptr.u64;
-
-			ncl = (bptr.s_cn78xx.size + CVMX_CACHE_LINE_SIZE-1)/
-				CVMX_CACHE_LINE_SIZE;
-
-			/* XXX- assumes the buffer is cache-line aligned */
-			start_of_buffer = (bptr.s_cn78xx.addr >> 7) << 7;
-
-			/* Read pointer to next buffer before we free the current buffer. */
-			next_buffer_ptr = *(uint64_t *)
-				cvmx_phys_to_ptr(bptr.s_cn78xx.addr - 8);
-			/* FPA AURA comes from WQE, includes node */
-			cvmx_fpa_free_aura(cvmx_phys_to_ptr(start_of_buffer),
-				aura >> 10, aura & ((1<<10)-1), ncl);
-		} else {
-			ncl = (buffer_ptr.s.size + CVMX_CACHE_LINE_SIZE-1)/
-				CVMX_CACHE_LINE_SIZE + buffer_ptr.s.back;
-			/* Calculate buffer start using "back" offset,
-			   Remember the back pointer is in cache lines,
-			   not 64bit words */
-			start_of_buffer =
-				((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back)
-					<< 7;
-			/* Read pointer to next buffer before we free
-			the current buffer. */
-			next_buffer_ptr = *(uint64_t *)
-				cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
-			/* FPA pool comes from buf_ptr itself */
-			if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
-				/* FIXME:  Which node is it? */
-				cvmx_fpa_free_aura(cvmx_phys_to_ptr(start_of_buffer), 0, (int)buffer_ptr.s.pool, ncl);
-			else
-				cvmx_fpa1_free(cvmx_phys_to_ptr(start_of_buffer),
-					      buffer_ptr.s.pool, ncl);
-		}
-		buffer_ptr.u64 = next_buffer_ptr;
-	}
-
-}
-
+void cvmx_helper_free_packet_data(cvmx_wqe_t *work);
 
 /**
  * Returns the interface number for an IPD/PKO port number.
@@ -357,7 +289,7 @@ extern int cvmx_helper_get_interface_index_num(int ipd_port);
  *
  * @return port kind on sucicess  and -1 on failure
  */
-extern int cvmx_helper_get_pknd(int interface, int port);
+extern int cvmx_helper_get_pknd(int xiface, int index);
 
 /**
  * Get bpid for a given port in an interface.
@@ -373,8 +305,12 @@ extern int cvmx_helper_get_bpid(int interface, int port);
  * Internal functions.
  */
 extern int __cvmx_helper_post_init_interfaces(void);
-extern void __cvmx_helper_shutdown_interfaces(void);
 extern int cvmx_helper_setup_red(int pass_thresh, int drop_thresh);
 extern void cvmx_helper_show_stats(int port);
 
+/*
+ * Return number of array alements
+ */
+#define	NUM_ELEMENTS(arr) (sizeof(arr)/sizeof((arr)[0]))
+
 #endif /* __CVMX_HELPER_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper.h b/arch/mips/include/asm/octeon/cvmx-helper.h
index dce77b0..6d42364 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper.h
@@ -42,7 +42,7 @@
  *
  * Helper functions for common, but complicated tasks.
  *
- * <hr>$Revision: 95258 $<hr>
+ * <hr>$Revision: 96716 $<hr>
  */
 
 #ifndef __CVMX_HELPER_H__
@@ -61,7 +61,8 @@ extern "C" {
 #endif
 
 /* Max number of GMXX */
-#define CVMX_HELPER_MAX_GMX             (OCTEON_IS_MODEL(OCTEON_CN68XX) ? 5 : 2)
+#define CVMX_HELPER_MAX_GMX             (OCTEON_IS_MODEL(OCTEON_CN78XX) ? 6 \
+					 : (OCTEON_IS_MODEL(OCTEON_CN68XX) ? 5 : 2))
 
 #define CVMX_HELPER_CSR_INIT0           0	/* Do not change as
 						   CVMX_HELPER_WRITE_CSR()
@@ -194,7 +195,8 @@ extern CVMX_SHARED void (*cvmx_override_ipd_port_setup) (int ipd_port);
  * @return 0 on success
  *         -1 on failure
  */
-extern int cvmx_helper_ipd_and_packet_input_enable(void);
+int cvmx_helper_ipd_and_packet_input_enable_node(int node);
+int cvmx_helper_ipd_and_packet_input_enable(void);
 
 /**
  * Initialize and allocate memory for the SSO.
@@ -207,16 +209,30 @@ extern int cvmx_helper_ipd_and_packet_input_enable(void);
 extern int cvmx_helper_initialize_sso(int wqe_entries);
 
 /**
- * Undo the effect of cvmx_helper_initialize_sso().
+ * Initialize and allocate memory for the SSO on a specific node.
+ *
+ * @param wqe_entries The maximum number of work queue entries to be
+ * supported.
  *
- * Warning: since cvmx_bootmem_alloc() memory cannot be freed, the
- * memory allocated by cvmx_helper_initialize_sso() will be leaked.
+ * @return Zero on success, non-zero on failure.
+ */
+extern int cvmx_helper_initialize_sso_node(unsigned node, int wqe_entries);
+
+/**
+ * Undo the effect of cvmx_helper_initialize_sso().
  *
  * @return Zero on success, non-zero on failure.
  */
 extern int cvmx_helper_uninitialize_sso(void);
 
 /**
+ * Undo the effect of cvmx_helper_initialize_sso_node().
+ *
+ * @return Zero on success, non-zero on failure.
+ */
+extern int cvmx_helper_uninitialize_sso_node(unsigned node);
+
+/**
  * Initialize the PIP, IPD, and PKO hardware to support
  * simple priority based queues for the ethernet ports. Each
  * port is configured with a number of priority queues based
@@ -225,7 +241,8 @@ extern int cvmx_helper_uninitialize_sso(void);
  *
  * @return Zero on success, non-zero on failure
  */
-extern int cvmx_helper_initialize_packet_io_global(void);
+int cvmx_helper_initialize_packet_io_global(void);
+int cvmx_helper_initialize_packet_io_node(unsigned int node);
 
 /**
  * Does core local initialization for packet io
@@ -433,6 +450,76 @@ static inline uint8_t cvmx_helper_prio2qos(uint8_t prio)
 	return (prio_map >> ((prio & 0x7) << 2)) & 0x7;
 }
 
+/**
+ * @INTERNAL
+ * Get the number of ipd_ports on an interface.
+ *
+ * @param interface
+ *
+ * @return the number of ipd_ports on the interface and -1 for error.
+ */
+int __cvmx_helper_get_num_ipd_ports(int interface);
+
+enum cvmx_pko_padding __cvmx_helper_get_pko_padding(int xiface);
+
+/**
+ * @INTERNAL
+ *
+ * @param interface
+ * @param num_ipd_ports is the number of ipd_ports on the interface
+ * @param has_fcs indicates if PKO does FCS for the ports on this
+ * @param pad The padding that PKO should apply.
+ * interface.
+ *
+ * @return 0 for success and -1 for failure
+ */
+int __cvmx_helper_init_interface(int interface, int num_ipd_ports, int has_fcs, enum cvmx_pko_padding pad);
+
+void __cvmx_helper_shutdown_interfaces(void);
+
+/*
+ * @INTERNAL
+ * Enable packet input/output from the hardware. This function is
+ * called after all internal setup is complete and IPD is enabled.
+ * After this function completes, packets will be accepted from the
+ * hardware ports. PKO should still be disabled to make sure packets
+ * aren't sent out partially setup hardware.
+ *
+ * @return Zero on success, negative on failure
+ */
+int __cvmx_helper_packet_hardware_enable(int xiface);
+
+/*
+ * @INTERNAL
+ *
+ * @return 0 for success and -1 for failure
+ */
+int __cvmx_helper_set_link_info(int xiface, int index, cvmx_helper_link_info_t link_info);
+
+/**
+ * @INTERNAL
+ *
+ * @param interface
+ * @param port
+ *
+ * @return valid link_info on success or -1 on failure
+ */
+cvmx_helper_link_info_t __cvmx_helper_get_link_info(int interface, int port);
+
+enum cvmx_pko_padding {
+	CVMX_PKO_PADDING_NONE = 0,
+	CVMX_PKO_PADDING_60 = 1,
+};
+
+/**
+ * @INTERNAL
+ *
+ * @param interface
+ *
+ * @return 0 if PKO does not do FCS and 1 otherwise.
+ */
+int __cvmx_helper_get_has_fcs(int interface);
+
 #ifdef  __cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-hna-defs.h b/arch/mips/include/asm/octeon/cvmx-hna-defs.h
index dc853dd..d8de7e6 100644
--- a/arch/mips/include/asm/octeon/cvmx-hna-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-hna-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -606,8 +606,8 @@ typedef union cvmx_hna_control cvmx_hna_control_t;
  * addr[34:32] = 0x0 or 0x1. To read the HNA_DBELL register, a device issues an IOBLD64 directed
  * at the HNA with addr[34:32] = 0x0 or 0x1.
  * If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to the HNA_DBELL register
- * do not take effect. If FUSE[TBD] = 'HNA HPU disable' is blown, reads/writes to the HNA_DBELL
- * register do not take effect.
+ * do not take effect. If the HNA-disable fuse is blown, reads/writes to the HNA_DBELL register
+ * do not take effect.
  */
 union cvmx_hna_dbell {
 	uint64_t u64;
@@ -638,8 +638,8 @@ typedef union cvmx_hna_dbell cvmx_hna_dbell_t;
  * HNA with addr[34:32]=0x6.
  * This register is intended to only be written once (at power-up). Any future writes could cause
  * the HNA and FPA hardware to become unpredictable. If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks
- * disabled), reads/writes to HNA_DIFCTL do not take effect. If FUSE[TBD] = 'HNA HPU disable' is
- * blown, reads/writes to HNA_DIFCTL do not take effect.
+ * disabled), reads/writes to HNA_DIFCTL do not take effect. If the HNA-disable FUSE is blown,
+ * reads/writes to HNA_DIFCTL do not take effect.
  */
 union cvmx_hna_difctl {
 	uint64_t u64;
@@ -684,8 +684,7 @@ typedef union cvmx_hna_difctl cvmx_hna_difctl_t;
  * addr[34:32] = 0x2 or 0x3. To read the HNA_DIFRDPTR register, a device issues an IOBLD64
  * directed at the HNA with addr[34:32] = 0x2 or 0x3.
  * If HNA_CONFIG[HPUCLKDIS]=1 (HNA-HPU clocks disabled), reads/writes to HNA_DIFRDPTR do not take
- * effect. If FUSE[TBD] = 'HNA HPU disable' is blown, reads/writes to HNA_DIFRDPTR do not take
- * effect.
+ * effect. If the HNA-disable fuse is blown, reads/writes to HNA_DIFRDPTR do not take effect.
  */
 union cvmx_hna_difrdptr {
 	uint64_t u64;
diff --git a/arch/mips/include/asm/octeon/cvmx-ila-defs.h b/arch/mips/include/asm/octeon/cvmx-ila-defs.h
index 20d6960..1d94d4c 100644
--- a/arch/mips/include/asm/octeon/cvmx-ila-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ila-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1580,7 +1580,8 @@ union cvmx_ila_txx_cfg1 {
 	uint64_t u64;
 	struct cvmx_ila_txx_cfg1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_43_63               : 21;
+	uint64_t ser_low                      : 4;  /**< Reserved. */
+	uint64_t reserved_43_59               : 17;
 	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes. If 0x0, hardware
                                                          will compute it. Otherwise, SER_LIMIT must be set as follows:
                                                          SER_LIMIT >= 148 + (BAUD / SCLK) * (12 + NUM_LANES)
@@ -1616,7 +1617,8 @@ union cvmx_ila_txx_cfg1 {
 	uint64_t reserved_26_31               : 6;
 	uint64_t pkt_busy                     : 1;
 	uint64_t ser_limit                    : 10;
-	uint64_t reserved_43_63               : 21;
+	uint64_t reserved_43_59               : 17;
+	uint64_t ser_low                      : 4;
 #endif
 	} s;
 	struct cvmx_ila_txx_cfg1_s            cn78xx;
@@ -1654,7 +1656,10 @@ union cvmx_ila_txx_dbg {
 	uint64_t u64;
 	struct cvmx_ila_txx_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_3_63                : 61;
+	uint64_t reserved_29_63               : 35;
+	uint64_t data_rate                    : 13; /**< Reserved. */
+	uint64_t low_delay                    : 6;  /**< Reserved. */
+	uint64_t reserved_3_9                 : 7;
 	uint64_t tx_bad_crc24                 : 1;  /**< Send a control word with bad CRC24. Hardware clears this field once the injection is performed. */
 	uint64_t tx_bad_ctlw2                 : 1;  /**< Send a control word without the control bit set. */
 	uint64_t tx_bad_ctlw1                 : 1;  /**< Send a data word with the control bit set. */
@@ -1662,7 +1667,10 @@ union cvmx_ila_txx_dbg {
 	uint64_t tx_bad_ctlw1                 : 1;
 	uint64_t tx_bad_ctlw2                 : 1;
 	uint64_t tx_bad_crc24                 : 1;
-	uint64_t reserved_3_63                : 61;
+	uint64_t reserved_3_9                 : 7;
+	uint64_t low_delay                    : 6;
+	uint64_t data_rate                    : 13;
+	uint64_t reserved_29_63               : 35;
 #endif
 	} s;
 	struct cvmx_ila_txx_dbg_s             cn78xx;
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
index 8640e8a..732dd40 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -4177,7 +4177,8 @@ union cvmx_ilk_txx_cfg1 {
 	uint64_t u64;
 	struct cvmx_ilk_txx_cfg1_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_53_63               : 11;
+	uint64_t ser_low                      : 4;  /**< Reserved. */
+	uint64_t reserved_53_59               : 7;
 	uint64_t brst_min                     : 5;  /**< Minimum size of a data burst, as a multiple of 32-byte blocks. 0 disables the scheduling
                                                          enhancement. When non-zero, must satisfy:
                                                          (BRST_SHRT*8) <= (BRST_MIN*32) <= (BRST_MAX*64)/2. */
@@ -4229,7 +4230,8 @@ union cvmx_ilk_txx_cfg1 {
 	uint64_t ser_limit                    : 10;
 	uint64_t reserved_43_47               : 5;
 	uint64_t brst_min                     : 5;
-	uint64_t reserved_53_63               : 11;
+	uint64_t reserved_53_59               : 7;
+	uint64_t ser_low                      : 4;
 #endif
 	} s;
 	struct cvmx_ilk_txx_cfg1_cn68xx {
@@ -4367,7 +4369,10 @@ union cvmx_ilk_txx_dbg {
 	uint64_t u64;
 	struct cvmx_ilk_txx_dbg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_3_63                : 61;
+	uint64_t reserved_29_63               : 35;
+	uint64_t data_rate                    : 13; /**< Reserved. */
+	uint64_t low_delay                    : 6;  /**< Reserved. */
+	uint64_t reserved_3_9                 : 7;
 	uint64_t tx_bad_crc24                 : 1;  /**< Send a control word with bad CRC24. Hardware clears this field once the injection is performed. */
 	uint64_t tx_bad_ctlw2                 : 1;  /**< Send a control word without the control bit set. */
 	uint64_t tx_bad_ctlw1                 : 1;  /**< Send a data word with the control bit set. */
@@ -4375,11 +4380,27 @@ union cvmx_ilk_txx_dbg {
 	uint64_t tx_bad_ctlw1                 : 1;
 	uint64_t tx_bad_ctlw2                 : 1;
 	uint64_t tx_bad_crc24                 : 1;
-	uint64_t reserved_3_63                : 61;
+	uint64_t reserved_3_9                 : 7;
+	uint64_t low_delay                    : 6;
+	uint64_t data_rate                    : 13;
+	uint64_t reserved_29_63               : 35;
 #endif
 	} s;
-	struct cvmx_ilk_txx_dbg_s             cn68xx;
-	struct cvmx_ilk_txx_dbg_s             cn68xxp1;
+	struct cvmx_ilk_txx_dbg_cn68xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_3_63                : 61;
+	uint64_t tx_bad_crc24                 : 1;  /**< Send a control word with bad CRC24.  Hardware will clear this
+                                                         field once the injection is performed. */
+	uint64_t tx_bad_ctlw2                 : 1;  /**< Send a control word without the control bit set */
+	uint64_t tx_bad_ctlw1                 : 1;  /**< Send a data word with the control bit set */
+#else
+	uint64_t tx_bad_ctlw1                 : 1;
+	uint64_t tx_bad_ctlw2                 : 1;
+	uint64_t tx_bad_crc24                 : 1;
+	uint64_t reserved_3_63                : 61;
+#endif
+	} cn68xx;
+	struct cvmx_ilk_txx_dbg_cn68xx        cn68xxp1;
 	struct cvmx_ilk_txx_dbg_s             cn78xx;
 };
 typedef union cvmx_ilk_txx_dbg cvmx_ilk_txx_dbg_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk.h b/arch/mips/include/asm/octeon/cvmx-ilk.h
index a037e3f..d4a8afe 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -83,8 +83,7 @@ static inline int CVMX_ILK_QLM_BASE(void) {
 typedef struct {
 	int intf_en:1;
 	int la_mode:1;
-	int reserved:2;		/* unused */
-	int lane_en_mask:12;
+	int reserved:14;		/* unused */
 	int lane_speed:16;
 	/* add more here */
 } cvmx_ilk_intf_t;
@@ -201,11 +200,6 @@ typedef struct cvmx_ilk_LA_mode_struct
 	int ilk_LA_mode_cal_ena;
 } cvmx_ilk_LA_mode_t;
 
-void cvmx_ilk_config_set_LA_mode(int interface, int mode);
-void cvmx_ilk_config_set_LA_mode_cal(int interface, int mode);
-void cvmx_ilk_config_set_max_channels(int interface, unsigned char channels);
-void cvmx_ilk_config_set_lane_mask(int interface, unsigned char mask);
-
 extern CVMX_SHARED cvmx_ilk_LA_mode_t cvmx_ilk_LA_mode[CVMX_NUM_ILK_INTF];
 extern int cvmx_ilk_use_la_mode(int interface, int channel);
 
@@ -217,9 +211,8 @@ extern int cvmx_ilk_rx_set_pknd(int interface, cvmx_ilk_chan_pknd_t * chpknd, un
 extern int cvmx_ilk_enable(int interface);
 extern int cvmx_ilk_disable(int interface);
 extern int cvmx_ilk_get_intf_ena(int interface);
-extern unsigned char cvmx_ilk_get_intf_ln_msk(int interface);
 extern int cvmx_ilk_get_chan_info(int interface, unsigned char **chans, unsigned char *num_chan);
-extern cvmx_ilk_la_nsp_compact_hdr_t cvmx_ilk_enable_la_header(int port, int mode);
+extern cvmx_ilk_la_nsp_compact_hdr_t cvmx_ilk_enable_la_header(int ipd_port, int mode);
 extern void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats);
 extern int cvmx_ilk_cal_setup_rx(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent, int hi_wm, unsigned char cal_ena);
 extern int cvmx_ilk_cal_setup_tx(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent, unsigned char cal_ena);
diff --git a/arch/mips/include/asm/octeon/cvmx-iob-defs.h b/arch/mips/include/asm/octeon/cvmx-iob-defs.h
index 40fc1ba..8ee6633 100644
--- a/arch/mips/include/asm/octeon/cvmx-iob-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-iob-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -514,6 +514,7 @@ union cvmx_iob_bist_status {
 	} cn68xx;
 	struct cvmx_iob_bist_status_cn68xx    cn68xxp1;
 	struct cvmx_iob_bist_status_cn61xx    cn70xx;
+	struct cvmx_iob_bist_status_cn61xx    cn70xxp1;
 	struct cvmx_iob_bist_status_cn61xx    cnf71xx;
 };
 typedef union cvmx_iob_bist_status cvmx_iob_bist_status_t;
@@ -546,6 +547,7 @@ union cvmx_iob_chip_cur_pwr {
 #endif
 	} s;
 	struct cvmx_iob_chip_cur_pwr_s        cn70xx;
+	struct cvmx_iob_chip_cur_pwr_s        cn70xxp1;
 };
 typedef union cvmx_iob_chip_cur_pwr cvmx_iob_chip_cur_pwr_t;
 
@@ -600,6 +602,7 @@ union cvmx_iob_chip_glb_pwr_throttle {
 #endif
 	} s;
 	struct cvmx_iob_chip_glb_pwr_throttle_s cn70xx;
+	struct cvmx_iob_chip_glb_pwr_throttle_s cn70xxp1;
 };
 typedef union cvmx_iob_chip_glb_pwr_throttle cvmx_iob_chip_glb_pwr_throttle_t;
 
@@ -636,6 +639,7 @@ union cvmx_iob_chip_pwr_out {
 #endif
 	} s;
 	struct cvmx_iob_chip_pwr_out_s        cn70xx;
+	struct cvmx_iob_chip_pwr_out_s        cn70xxp1;
 };
 typedef union cvmx_iob_chip_pwr_out cvmx_iob_chip_pwr_out_t;
 
@@ -836,6 +840,7 @@ union cvmx_iob_ctl_status {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} cn70xx;
+	struct cvmx_iob_ctl_status_cn70xx     cn70xxp1;
 	struct cvmx_iob_ctl_status_cn61xx     cnf71xx;
 };
 typedef union cvmx_iob_ctl_status cvmx_iob_ctl_status_t;
@@ -875,6 +880,7 @@ union cvmx_iob_dwb_pri_cnt {
 	struct cvmx_iob_dwb_pri_cnt_s         cn63xxp1;
 	struct cvmx_iob_dwb_pri_cnt_s         cn66xx;
 	struct cvmx_iob_dwb_pri_cnt_s         cn70xx;
+	struct cvmx_iob_dwb_pri_cnt_s         cn70xxp1;
 	struct cvmx_iob_dwb_pri_cnt_s         cnf71xx;
 };
 typedef union cvmx_iob_dwb_pri_cnt cvmx_iob_dwb_pri_cnt_t;
@@ -927,6 +933,7 @@ union cvmx_iob_fau_timeout {
 	struct cvmx_iob_fau_timeout_s         cn68xx;
 	struct cvmx_iob_fau_timeout_s         cn68xxp1;
 	struct cvmx_iob_fau_timeout_s         cn70xx;
+	struct cvmx_iob_fau_timeout_s         cn70xxp1;
 	struct cvmx_iob_fau_timeout_s         cnf71xx;
 };
 typedef union cvmx_iob_fau_timeout cvmx_iob_fau_timeout_t;
@@ -966,6 +973,7 @@ union cvmx_iob_i2c_pri_cnt {
 	struct cvmx_iob_i2c_pri_cnt_s         cn63xxp1;
 	struct cvmx_iob_i2c_pri_cnt_s         cn66xx;
 	struct cvmx_iob_i2c_pri_cnt_s         cn70xx;
+	struct cvmx_iob_i2c_pri_cnt_s         cn70xxp1;
 	struct cvmx_iob_i2c_pri_cnt_s         cnf71xx;
 };
 typedef union cvmx_iob_i2c_pri_cnt cvmx_iob_i2c_pri_cnt_t;
@@ -1011,6 +1019,7 @@ union cvmx_iob_inb_control_match {
 	struct cvmx_iob_inb_control_match_s   cn68xx;
 	struct cvmx_iob_inb_control_match_s   cn68xxp1;
 	struct cvmx_iob_inb_control_match_s   cn70xx;
+	struct cvmx_iob_inb_control_match_s   cn70xxp1;
 	struct cvmx_iob_inb_control_match_s   cnf71xx;
 };
 typedef union cvmx_iob_inb_control_match cvmx_iob_inb_control_match_t;
@@ -1056,6 +1065,7 @@ union cvmx_iob_inb_control_match_enb {
 	struct cvmx_iob_inb_control_match_enb_s cn68xx;
 	struct cvmx_iob_inb_control_match_enb_s cn68xxp1;
 	struct cvmx_iob_inb_control_match_enb_s cn70xx;
+	struct cvmx_iob_inb_control_match_enb_s cn70xxp1;
 	struct cvmx_iob_inb_control_match_enb_s cnf71xx;
 };
 typedef union cvmx_iob_inb_control_match_enb cvmx_iob_inb_control_match_enb_t;
@@ -1093,6 +1103,7 @@ union cvmx_iob_inb_data_match {
 	struct cvmx_iob_inb_data_match_s      cn68xx;
 	struct cvmx_iob_inb_data_match_s      cn68xxp1;
 	struct cvmx_iob_inb_data_match_s      cn70xx;
+	struct cvmx_iob_inb_data_match_s      cn70xxp1;
 	struct cvmx_iob_inb_data_match_s      cnf71xx;
 };
 typedef union cvmx_iob_inb_data_match cvmx_iob_inb_data_match_t;
@@ -1130,6 +1141,7 @@ union cvmx_iob_inb_data_match_enb {
 	struct cvmx_iob_inb_data_match_enb_s  cn68xx;
 	struct cvmx_iob_inb_data_match_enb_s  cn68xxp1;
 	struct cvmx_iob_inb_data_match_enb_s  cn70xx;
+	struct cvmx_iob_inb_data_match_enb_s  cn70xxp1;
 	struct cvmx_iob_inb_data_match_enb_s  cnf71xx;
 };
 typedef union cvmx_iob_inb_data_match_enb cvmx_iob_inb_data_match_enb_t;
@@ -1257,6 +1269,7 @@ union cvmx_iob_int_enb {
 	} cn68xx;
 	struct cvmx_iob_int_enb_cn68xx        cn68xxp1;
 	struct cvmx_iob_int_enb_s             cn70xx;
+	struct cvmx_iob_int_enb_s             cn70xxp1;
 	struct cvmx_iob_int_enb_cn50xx        cnf71xx;
 };
 typedef union cvmx_iob_int_enb cvmx_iob_int_enb_t;
@@ -1414,6 +1427,7 @@ union cvmx_iob_int_sum {
 	} cn68xx;
 	struct cvmx_iob_int_sum_cn68xx        cn68xxp1;
 	struct cvmx_iob_int_sum_s             cn70xx;
+	struct cvmx_iob_int_sum_s             cn70xxp1;
 	struct cvmx_iob_int_sum_cn50xx        cnf71xx;
 };
 typedef union cvmx_iob_int_sum cvmx_iob_int_sum_t;
@@ -1453,6 +1467,7 @@ union cvmx_iob_n2c_l2c_pri_cnt {
 	struct cvmx_iob_n2c_l2c_pri_cnt_s     cn63xxp1;
 	struct cvmx_iob_n2c_l2c_pri_cnt_s     cn66xx;
 	struct cvmx_iob_n2c_l2c_pri_cnt_s     cn70xx;
+	struct cvmx_iob_n2c_l2c_pri_cnt_s     cn70xxp1;
 	struct cvmx_iob_n2c_l2c_pri_cnt_s     cnf71xx;
 };
 typedef union cvmx_iob_n2c_l2c_pri_cnt cvmx_iob_n2c_l2c_pri_cnt_t;
@@ -1493,6 +1508,7 @@ union cvmx_iob_n2c_rsp_pri_cnt {
 	struct cvmx_iob_n2c_rsp_pri_cnt_s     cn63xxp1;
 	struct cvmx_iob_n2c_rsp_pri_cnt_s     cn66xx;
 	struct cvmx_iob_n2c_rsp_pri_cnt_s     cn70xx;
+	struct cvmx_iob_n2c_rsp_pri_cnt_s     cn70xxp1;
 	struct cvmx_iob_n2c_rsp_pri_cnt_s     cnf71xx;
 };
 typedef union cvmx_iob_n2c_rsp_pri_cnt cvmx_iob_n2c_rsp_pri_cnt_t;
@@ -1534,6 +1550,7 @@ union cvmx_iob_outb_com_pri_cnt {
 	struct cvmx_iob_outb_com_pri_cnt_s    cn68xx;
 	struct cvmx_iob_outb_com_pri_cnt_s    cn68xxp1;
 	struct cvmx_iob_outb_com_pri_cnt_s    cn70xx;
+	struct cvmx_iob_outb_com_pri_cnt_s    cn70xxp1;
 	struct cvmx_iob_outb_com_pri_cnt_s    cnf71xx;
 };
 typedef union cvmx_iob_outb_com_pri_cnt cvmx_iob_outb_com_pri_cnt_t;
@@ -1579,6 +1596,7 @@ union cvmx_iob_outb_control_match {
 	struct cvmx_iob_outb_control_match_s  cn68xx;
 	struct cvmx_iob_outb_control_match_s  cn68xxp1;
 	struct cvmx_iob_outb_control_match_s  cn70xx;
+	struct cvmx_iob_outb_control_match_s  cn70xxp1;
 	struct cvmx_iob_outb_control_match_s  cnf71xx;
 };
 typedef union cvmx_iob_outb_control_match cvmx_iob_outb_control_match_t;
@@ -1624,6 +1642,7 @@ union cvmx_iob_outb_control_match_enb {
 	struct cvmx_iob_outb_control_match_enb_s cn68xx;
 	struct cvmx_iob_outb_control_match_enb_s cn68xxp1;
 	struct cvmx_iob_outb_control_match_enb_s cn70xx;
+	struct cvmx_iob_outb_control_match_enb_s cn70xxp1;
 	struct cvmx_iob_outb_control_match_enb_s cnf71xx;
 };
 typedef union cvmx_iob_outb_control_match_enb cvmx_iob_outb_control_match_enb_t;
@@ -1661,6 +1680,7 @@ union cvmx_iob_outb_data_match {
 	struct cvmx_iob_outb_data_match_s     cn68xx;
 	struct cvmx_iob_outb_data_match_s     cn68xxp1;
 	struct cvmx_iob_outb_data_match_s     cn70xx;
+	struct cvmx_iob_outb_data_match_s     cn70xxp1;
 	struct cvmx_iob_outb_data_match_s     cnf71xx;
 };
 typedef union cvmx_iob_outb_data_match cvmx_iob_outb_data_match_t;
@@ -1698,6 +1718,7 @@ union cvmx_iob_outb_data_match_enb {
 	struct cvmx_iob_outb_data_match_enb_s cn68xx;
 	struct cvmx_iob_outb_data_match_enb_s cn68xxp1;
 	struct cvmx_iob_outb_data_match_enb_s cn70xx;
+	struct cvmx_iob_outb_data_match_enb_s cn70xxp1;
 	struct cvmx_iob_outb_data_match_enb_s cnf71xx;
 };
 typedef union cvmx_iob_outb_data_match_enb cvmx_iob_outb_data_match_enb_t;
@@ -1739,6 +1760,7 @@ union cvmx_iob_outb_fpa_pri_cnt {
 	struct cvmx_iob_outb_fpa_pri_cnt_s    cn68xx;
 	struct cvmx_iob_outb_fpa_pri_cnt_s    cn68xxp1;
 	struct cvmx_iob_outb_fpa_pri_cnt_s    cn70xx;
+	struct cvmx_iob_outb_fpa_pri_cnt_s    cn70xxp1;
 	struct cvmx_iob_outb_fpa_pri_cnt_s    cnf71xx;
 };
 typedef union cvmx_iob_outb_fpa_pri_cnt cvmx_iob_outb_fpa_pri_cnt_t;
@@ -1780,6 +1802,7 @@ union cvmx_iob_outb_req_pri_cnt {
 	struct cvmx_iob_outb_req_pri_cnt_s    cn68xx;
 	struct cvmx_iob_outb_req_pri_cnt_s    cn68xxp1;
 	struct cvmx_iob_outb_req_pri_cnt_s    cn70xx;
+	struct cvmx_iob_outb_req_pri_cnt_s    cn70xxp1;
 	struct cvmx_iob_outb_req_pri_cnt_s    cnf71xx;
 };
 typedef union cvmx_iob_outb_req_pri_cnt cvmx_iob_outb_req_pri_cnt_t;
@@ -1819,6 +1842,7 @@ union cvmx_iob_p2c_req_pri_cnt {
 	struct cvmx_iob_p2c_req_pri_cnt_s     cn63xxp1;
 	struct cvmx_iob_p2c_req_pri_cnt_s     cn66xx;
 	struct cvmx_iob_p2c_req_pri_cnt_s     cn70xx;
+	struct cvmx_iob_p2c_req_pri_cnt_s     cn70xxp1;
 	struct cvmx_iob_p2c_req_pri_cnt_s     cnf71xx;
 };
 typedef union cvmx_iob_p2c_req_pri_cnt cvmx_iob_p2c_req_pri_cnt_t;
@@ -1872,6 +1896,7 @@ union cvmx_iob_pkt_err {
 	struct cvmx_iob_pkt_err_s             cn63xxp1;
 	struct cvmx_iob_pkt_err_s             cn66xx;
 	struct cvmx_iob_pkt_err_s             cn70xx;
+	struct cvmx_iob_pkt_err_s             cn70xxp1;
 	struct cvmx_iob_pkt_err_s             cnf71xx;
 };
 typedef union cvmx_iob_pkt_err cvmx_iob_pkt_err_t;
@@ -1894,6 +1919,7 @@ union cvmx_iob_pp_bist_status {
 #endif
 	} s;
 	struct cvmx_iob_pp_bist_status_s      cn70xx;
+	struct cvmx_iob_pp_bist_status_s      cn70xxp1;
 };
 typedef union cvmx_iob_pp_bist_status cvmx_iob_pp_bist_status_t;
 
@@ -1956,6 +1982,7 @@ union cvmx_iob_to_cmb_credits {
 	} cn68xx;
 	struct cvmx_iob_to_cmb_credits_cn68xx cn68xxp1;
 	struct cvmx_iob_to_cmb_credits_cn52xx cn70xx;
+	struct cvmx_iob_to_cmb_credits_cn52xx cn70xxp1;
 	struct cvmx_iob_to_cmb_credits_cn52xx cnf71xx;
 };
 typedef union cvmx_iob_to_cmb_credits cvmx_iob_to_cmb_credits_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-iobn-defs.h b/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
index 9fdab1f..164c268 100644
--- a/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-iobn-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -265,8 +265,8 @@ union cvmx_iobn_chip_cur_pwr {
                                                          reduce power. The hardware generally uses a CURRENT_POWER_SETTING value that is as large
                                                          as possible (in order to maximize performance) subject to the following constraints (in
                                                          priority order):
-                                                         * PWR_MIN <= CURRENT_POWER_SETTING <=PWR_MAX
-                                                         * Power limits from the PWR_SETTING feedback control system
+                                                         * PWR_MIN <= CURRENT_POWER_SETTING <= PWR_MAX.
+                                                         * Power limits from the PWR_SETTING feedback control system.
                                                          In the case of the CPU cores, CURRENT_POWER_SETTING effectively limits the CP0
                                                          PowThrottle[POWLIM] value: effective POWLIM = MINIMUM(CURRENT_POWER_SETTING,
                                                          PowThrottle[POWLIM]) */
@@ -304,7 +304,7 @@ union cvmx_iobn_chip_glb_pwr_throttle {
                                                          CURRENT_POWER_SETTING value. The power consumed by the chip (estimated currently by the
                                                          AVG_CHIP_POWER value) is an indirect output of the PWR_SETTING feedback control system.
                                                          PWR_SETTING is not used by the hardware when PWR_MIN equals PWR_MAX. PWR_MIN and PWR_MAX
-                                                         threshold requirements always supercede PWR_SETTING limits. (For maximum PWR_SETTING
+                                                         threshold requirements always supersede PWR_SETTING limits. (For maximum PWR_SETTING
                                                          feedback control freedom, set PWR_MIN=0 and PWR_MAX=0xff.)
                                                          PWR_SETTING equal to 0 forces the chip to consume near minimum power. Increasing
                                                          PWR_SETTING value from 0 to 0xFFFF increases the power that the chip is allowed to consume
@@ -385,29 +385,29 @@ union cvmx_iobn_credits {
 	struct cvmx_iobn_credits_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_62_63               : 2;
-	uint64_t ncb3_wr_crd                  : 6;  /**< "NCB3 write credit. The NCB# can have 32 writes in flight to the L2; this is the number to
-                                                         decrease the 32 by." */
+	uint64_t ncb3_wr_crd                  : 6;  /**< NCB3 write credit. Each NCB can have 32 writes in flight to the L2; this is the number to
+                                                         decrease the 32 by. */
 	uint64_t reserved_54_55               : 2;
-	uint64_t ncb3_rd_crd                  : 6;  /**< "NCB3 read credit. The NCB# can have 32 reads in flight to the L2; this is the number to
-                                                         decrease the 32 by." */
+	uint64_t ncb3_rd_crd                  : 6;  /**< NCB3 read credit. Each NCB can have 32 reads in flight to the L2; this is the number to
+                                                         decrease the 32 by. */
 	uint64_t reserved_46_47               : 2;
-	uint64_t ncb2_wr_crd                  : 6;  /**< "NCB2 write credit. The NCB# can have 32 writes in flight to the L2; this is the number to
-                                                         decrease the 32 by." */
+	uint64_t ncb2_wr_crd                  : 6;  /**< NCB2 write credit. Each NCB can have 32 writes in flight to the L2; this is the number to
+                                                         decrease the 32 by. */
 	uint64_t reserved_38_39               : 2;
-	uint64_t ncb2_rd_crd                  : 6;  /**< "NCB2 read credit. The NCB# can have 32 reads in flight to the L2; this is the number to
-                                                         decrease the 32 by." */
+	uint64_t ncb2_rd_crd                  : 6;  /**< NCB2 read credit. Each NCB can have 32 reads in flight to the L2; this is the number to
+                                                         decrease the 32 by. */
 	uint64_t reserved_30_31               : 2;
-	uint64_t ncb1_wr_crd                  : 6;  /**< "NCB1 write credit. The NCB# can have 32 writes in flight to the L2; this is the number to
-                                                         decrease the 32 by." */
+	uint64_t ncb1_wr_crd                  : 6;  /**< NCB1 write credit. Each NCB can have 32 writes in flight to the L2; this is the number to
+                                                         decrease the 32 by. */
 	uint64_t reserved_22_23               : 2;
-	uint64_t ncb1_rd_crd                  : 6;  /**< "NCB1 read credit. The NCB# can have 32 reads in flight to the L2; this is the number to
-                                                         decrease the 32 by." */
+	uint64_t ncb1_rd_crd                  : 6;  /**< NCB1 read credit. Each NCB can have 32 reads in flight to the L2; this is the number to
+                                                         decrease the 32 by. */
 	uint64_t reserved_14_15               : 2;
-	uint64_t ncb0_wr_crd                  : 6;  /**< "NCB0 write credit. The NCB# can have 32 writes in flight to the L2; this is the number to
-                                                         decrease the 32 by." */
+	uint64_t ncb0_wr_crd                  : 6;  /**< NCB0 write credit. Each NCB can have 32 writes in flight to the L2; this is the number to
+                                                         decrease the 32 by. */
 	uint64_t reserved_6_7                 : 2;
-	uint64_t ncb0_rd_crd                  : 6;  /**< "NCB0 read credit. The NCB# can have 32 reads in flight to the L2; this is the number to
-                                                         decrease the 32 by." */
+	uint64_t ncb0_rd_crd                  : 6;  /**< NCB0 read credit. Each NCB can have 32 reads in flight to the L2; this is the number to
+                                                         decrease the 32 by. */
 #else
 	uint64_t ncb0_rd_crd                  : 6;
 	uint64_t reserved_6_7                 : 2;
@@ -442,41 +442,41 @@ union cvmx_iobn_ecc {
 	struct cvmx_iobn_ecc_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_58_63               : 6;
-	uint64_t ioc3_ecc                     : 1;  /**< When set, core-to-NCB transfers have ECC generated and checked. */
+	uint64_t ioc3_ecc                     : 1;  /**< When set, disable core-to-NCB transfer ECC correction. */
 	uint64_t ioc3_fs                      : 2;  /**< Used to flip the syndrome for core-to-NCB transfers. */
-	uint64_t ioc2_ecc                     : 1;  /**< When set, core-to-NCB transfers have ECC generated and checked. */
+	uint64_t ioc2_ecc                     : 1;  /**< When set, disable core-to-NCB transfer ECC correction. */
 	uint64_t ioc2_fs                      : 2;  /**< Used to flip the syndrome for core-to-NCB transfers. */
-	uint64_t ioc1_ecc                     : 1;  /**< When set, core-to-NCB transfers have ECC generated and checked. */
+	uint64_t ioc1_ecc                     : 1;  /**< When set, disable core-to-NCB transfer ECC correction. */
 	uint64_t ioc1_fs                      : 2;  /**< Used to flip the syndrome for core-to-NCB transfers. */
-	uint64_t ioc0_ecc                     : 1;  /**< When set, core-to-NCB transfers have ECC generated and checked. */
+	uint64_t ioc0_ecc                     : 1;  /**< When set, disable core-to-NCB transfer ECC correction. */
 	uint64_t ioc0_fs                      : 2;  /**< Used to flip the syndrome for core-to-NCB transfers. */
-	uint64_t ior3_ecc                     : 1;  /**< When set, FILL data from NCB3 has ECC generated and checked. */
+	uint64_t ior3_ecc                     : 1;  /**< When set, disable FILL data from NCB3 ECC correction. */
 	uint64_t ior3_fs                      : 2;  /**< Used to flip the syndrome for FILL data from NCB3. */
-	uint64_t ior2_ecc                     : 1;  /**< When set, FILL data from NCB2 has ECC generated and checked. */
+	uint64_t ior2_ecc                     : 1;  /**< When set, disable FILL data from NCB2 ECC correction. */
 	uint64_t ior2_fs                      : 2;  /**< Used to flip the syndrome for FILL data from NCB2. */
-	uint64_t ior1_ecc                     : 1;  /**< When set, FILL data from NCB1 has ECC generated and checked. */
+	uint64_t ior1_ecc                     : 1;  /**< When set, disable FILL data from NCB1 ECC correction. */
 	uint64_t ior1_fs                      : 2;  /**< Used to flip the syndrome for FILL data from NCB1. */
-	uint64_t ior0_ecc                     : 1;  /**< When set, FILL data from NCB0 has ECC generated and checked. */
+	uint64_t ior0_ecc                     : 1;  /**< When set, disable FILL data from NCB0 ECC correction. */
 	uint64_t ior0_fs                      : 2;  /**< Used to flip the syndrome for FILL data from NCB0. */
-	uint64_t ide_ecc                      : 1;  /**< When set, DWB commands to L2C have ECC generated and checked. */
+	uint64_t ide_ecc                      : 1;  /**< When set, disable DWB command to L2C ECC correction. */
 	uint64_t ide_fs                       : 2;  /**< Used to flip the syndrome for DWB commands to the L2C. */
-	uint64_t xmc0_hp_ecc                  : 1;  /**< When set, NCBI0 high-priority commands to L2C have ECC generated and checked. */
+	uint64_t xmc0_hp_ecc                  : 1;  /**< When set, disable NCBI0 high-priority command to L2C ECC correction. */
 	uint64_t xmc0_hp_fs                   : 2;  /**< Used to flip the syndrome for high-priority commands from NCBI0 to L2C. */
-	uint64_t rsd3_ecc                     : 1;  /**< When set, NCBO3 response data has ECC generated and checked. */
+	uint64_t rsd3_ecc                     : 1;  /**< When set, disable NCBO3 response data ECC correction. */
 	uint64_t rsd3_fs                      : 2;  /**< Used to flip the syndrome for NCBO3 response data. */
-	uint64_t rsd2_ecc                     : 1;  /**< When set, NCBO2 response data has ECC generated and checked. */
+	uint64_t rsd2_ecc                     : 1;  /**< When set, disable NCBO2 response data ECC correction. */
 	uint64_t rsd2_fs                      : 2;  /**< Used to flip the syndrome for NCBO2 response data. */
-	uint64_t rsd1_ecc                     : 1;  /**< When set, NCBO1 response data has ECC generated and checked. */
+	uint64_t rsd1_ecc                     : 1;  /**< When set, disable NCBO1 response data ECC correction. */
 	uint64_t rsd1_fs                      : 2;  /**< Used to flip the syndrome for NCBO1 response data. */
-	uint64_t rsd0_ecc                     : 1;  /**< When set, NCBO0 response data have an ECC generated and checked. */
+	uint64_t rsd0_ecc                     : 1;  /**< When set, disable NCBO0 response data ECC correction. */
 	uint64_t rsd0_fs                      : 2;  /**< Used to flip the syndrome for NCBO0 response data. */
-	uint64_t xmc3_ecc                     : 1;  /**< When set, NCBI0 commands to L2C have ECC generated and checked. */
+	uint64_t xmc3_ecc                     : 1;  /**< When set, disable NCBI3 to L2C ECC correction. */
 	uint64_t xmc3_fs                      : 2;  /**< Used to flip the syndrome for commands from NCBI0 to the L2C. */
-	uint64_t xmc2_ecc                     : 1;  /**< When set, NCBI0 commands to L2C have ECC generated and checked. */
+	uint64_t xmc2_ecc                     : 1;  /**< When set, disable NCBI2 to L2C ECC correction. */
 	uint64_t xmc2_fs                      : 2;  /**< Used to flip the syndrome for commands from NCBI0 to the L2C. */
-	uint64_t xmc1_ecc                     : 1;  /**< When set, NCBI0 commands to L2C have ECC generated and checked. */
+	uint64_t xmc1_ecc                     : 1;  /**< When set, disable NCBI1 command L2C ECC correction. */
 	uint64_t xmc1_fs                      : 2;  /**< Used to flip the syndrome for commands from NCBI0 to the L2C. */
-	uint64_t xmc0_ecc                     : 1;  /**< When set, NCBI0 commands to L2C have ECC generated and checked. */
+	uint64_t xmc0_ecc                     : 1;  /**< When set, disable NCBI0 command L2C ECC correction. */
 	uint64_t xmc0_fs                      : 2;  /**< Used to flip the syndrome for commands from NCBI0 to the L2C. */
 	uint64_t xmd3_ecc                     : 1;  /**< When set, NCBI3 data to L2C has ECC generated and checked. */
 	uint64_t xmd2_ecc                     : 1;  /**< When set, NCBI2 data to L2C has ECC generated and checked. */
@@ -545,12 +545,12 @@ union cvmx_iobn_gbl_dll {
 	uint64_t pdl_rclk_refclk              : 1;  /**< Synchronized pdl_rclk_refclk from global core-clock DLL cmb0 phase detectors. */
 	uint64_t pd_pos_rclk_refclk           : 1;  /**< Synchronized pd_pos_rclk_refclk from global core-clock DLL cmb0 phase detectors. */
 	uint64_t dll_fsm_state_a              : 3;  /**< State for the global core-clock DLL, from the positive edge of refclk.
-                                                         0x0 = TMD_IDLE
-                                                         0x1 = TMD_STATE1
-                                                         0x2 = TMD_STATE2
-                                                         0x3 = TMD_STATE3
-                                                         0x4 = TMD_STATE4
-                                                         0x5 = TMD_LOCKED */
+                                                         0x0 = TMD_IDLE.
+                                                         0x1 = TMD_STATE1.
+                                                         0x2 = TMD_STATE2.
+                                                         0x3 = TMD_STATE3.
+                                                         0x4 = TMD_STATE4.
+                                                         0x5 = TMD_LOCKED. */
 	uint64_t dll_lock                     : 1;  /**< The dll_lock signal from global core-clock DLL, from the positive edge of refclk. */
 	uint64_t dll_clk_invert_out           : 1;  /**< The clk_invert setting from the global core-clock DLL, from the negative edge of refclk. */
 	uint64_t dll_setting                  : 12; /**< The global core-clock DLL, from the negative edge of refclk. */
diff --git a/arch/mips/include/asm/octeon/cvmx-iobp-defs.h b/arch/mips/include/asm/octeon/cvmx-iobp-defs.h
index bddc995..ad0918f 100644
--- a/arch/mips/include/asm/octeon/cvmx-iobp-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-iobp-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-ipd-defs.h b/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
index 75583c0..e2642a1 100644
--- a/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ipd-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -632,6 +632,7 @@ union cvmx_ipd_1st_mbuff_skip {
 	struct cvmx_ipd_1st_mbuff_skip_s      cn68xx;
 	struct cvmx_ipd_1st_mbuff_skip_s      cn68xxp1;
 	struct cvmx_ipd_1st_mbuff_skip_s      cn70xx;
+	struct cvmx_ipd_1st_mbuff_skip_s      cn70xxp1;
 	struct cvmx_ipd_1st_mbuff_skip_s      cnf71xx;
 };
 typedef union cvmx_ipd_1st_mbuff_skip cvmx_ipd_1st_mbuff_skip_t;
@@ -671,6 +672,7 @@ union cvmx_ipd_1st_next_ptr_back {
 	struct cvmx_ipd_1st_next_ptr_back_s   cn68xx;
 	struct cvmx_ipd_1st_next_ptr_back_s   cn68xxp1;
 	struct cvmx_ipd_1st_next_ptr_back_s   cn70xx;
+	struct cvmx_ipd_1st_next_ptr_back_s   cn70xxp1;
 	struct cvmx_ipd_1st_next_ptr_back_s   cnf71xx;
 };
 typedef union cvmx_ipd_1st_next_ptr_back cvmx_ipd_1st_next_ptr_back_t;
@@ -710,6 +712,7 @@ union cvmx_ipd_2nd_next_ptr_back {
 	struct cvmx_ipd_2nd_next_ptr_back_s   cn68xx;
 	struct cvmx_ipd_2nd_next_ptr_back_s   cn68xxp1;
 	struct cvmx_ipd_2nd_next_ptr_back_s   cn70xx;
+	struct cvmx_ipd_2nd_next_ptr_back_s   cn70xxp1;
 	struct cvmx_ipd_2nd_next_ptr_back_s   cnf71xx;
 };
 typedef union cvmx_ipd_2nd_next_ptr_back cvmx_ipd_2nd_next_ptr_back_t;
@@ -873,6 +876,7 @@ union cvmx_ipd_bist_status {
 	struct cvmx_ipd_bist_status_s         cn68xx;
 	struct cvmx_ipd_bist_status_s         cn68xxp1;
 	struct cvmx_ipd_bist_status_cn52xx    cn70xx;
+	struct cvmx_ipd_bist_status_cn52xx    cn70xxp1;
 	struct cvmx_ipd_bist_status_cn52xx    cnf71xx;
 };
 typedef union cvmx_ipd_bist_status cvmx_ipd_bist_status_t;
@@ -956,6 +960,7 @@ union cvmx_ipd_bp_prt_red_end {
 	struct cvmx_ipd_bp_prt_red_end_cn63xx cn63xxp1;
 	struct cvmx_ipd_bp_prt_red_end_s      cn66xx;
 	struct cvmx_ipd_bp_prt_red_end_s      cn70xx;
+	struct cvmx_ipd_bp_prt_red_end_s      cn70xxp1;
 	struct cvmx_ipd_bp_prt_red_end_s      cnf71xx;
 };
 typedef union cvmx_ipd_bp_prt_red_end cvmx_ipd_bp_prt_red_end_t;
@@ -1052,6 +1057,7 @@ union cvmx_ipd_clk_count {
 	struct cvmx_ipd_clk_count_s           cn68xx;
 	struct cvmx_ipd_clk_count_s           cn68xxp1;
 	struct cvmx_ipd_clk_count_s           cn70xx;
+	struct cvmx_ipd_clk_count_s           cn70xxp1;
 	struct cvmx_ipd_clk_count_s           cnf71xx;
 };
 typedef union cvmx_ipd_clk_count cvmx_ipd_clk_count_t;
@@ -1575,6 +1581,7 @@ union cvmx_ipd_ctl_status {
 	struct cvmx_ipd_ctl_status_s          cn68xx;
 	struct cvmx_ipd_ctl_status_s          cn68xxp1;
 	struct cvmx_ipd_ctl_status_s          cn70xx;
+	struct cvmx_ipd_ctl_status_s          cn70xxp1;
 	struct cvmx_ipd_ctl_status_s          cnf71xx;
 };
 typedef union cvmx_ipd_ctl_status cvmx_ipd_ctl_status_t;
@@ -1938,6 +1945,7 @@ union cvmx_ipd_int_enb {
 	struct cvmx_ipd_int_enb_s             cn68xx;
 	struct cvmx_ipd_int_enb_s             cn68xxp1;
 	struct cvmx_ipd_int_enb_cn52xx        cn70xx;
+	struct cvmx_ipd_int_enb_cn52xx        cn70xxp1;
 	struct cvmx_ipd_int_enb_cn52xx        cnf71xx;
 };
 typedef union cvmx_ipd_int_enb cvmx_ipd_int_enb_t;
@@ -2143,6 +2151,7 @@ union cvmx_ipd_int_sum {
 	struct cvmx_ipd_int_sum_s             cn68xx;
 	struct cvmx_ipd_int_sum_s             cn68xxp1;
 	struct cvmx_ipd_int_sum_cn52xx        cn70xx;
+	struct cvmx_ipd_int_sum_cn52xx        cn70xxp1;
 	struct cvmx_ipd_int_sum_cn52xx        cnf71xx;
 };
 typedef union cvmx_ipd_int_sum cvmx_ipd_int_sum_t;
@@ -2235,6 +2244,7 @@ union cvmx_ipd_not_1st_mbuff_skip {
 	struct cvmx_ipd_not_1st_mbuff_skip_s  cn68xx;
 	struct cvmx_ipd_not_1st_mbuff_skip_s  cn68xxp1;
 	struct cvmx_ipd_not_1st_mbuff_skip_s  cn70xx;
+	struct cvmx_ipd_not_1st_mbuff_skip_s  cn70xxp1;
 	struct cvmx_ipd_not_1st_mbuff_skip_s  cnf71xx;
 };
 typedef union cvmx_ipd_not_1st_mbuff_skip cvmx_ipd_not_1st_mbuff_skip_t;
@@ -2314,6 +2324,7 @@ union cvmx_ipd_packet_mbuff_size {
 	struct cvmx_ipd_packet_mbuff_size_s   cn68xx;
 	struct cvmx_ipd_packet_mbuff_size_s   cn68xxp1;
 	struct cvmx_ipd_packet_mbuff_size_s   cn70xx;
+	struct cvmx_ipd_packet_mbuff_size_s   cn70xxp1;
 	struct cvmx_ipd_packet_mbuff_size_s   cnf71xx;
 };
 typedef union cvmx_ipd_packet_mbuff_size cvmx_ipd_packet_mbuff_size_t;
@@ -2377,6 +2388,7 @@ union cvmx_ipd_pkt_ptr_valid {
 	struct cvmx_ipd_pkt_ptr_valid_s       cn63xxp1;
 	struct cvmx_ipd_pkt_ptr_valid_s       cn66xx;
 	struct cvmx_ipd_pkt_ptr_valid_s       cn70xx;
+	struct cvmx_ipd_pkt_ptr_valid_s       cn70xxp1;
 	struct cvmx_ipd_pkt_ptr_valid_s       cnf71xx;
 };
 typedef union cvmx_ipd_pkt_ptr_valid cvmx_ipd_pkt_ptr_valid_t;
@@ -2424,6 +2436,7 @@ union cvmx_ipd_portx_bp_page_cnt {
 	struct cvmx_ipd_portx_bp_page_cnt_s   cn63xxp1;
 	struct cvmx_ipd_portx_bp_page_cnt_s   cn66xx;
 	struct cvmx_ipd_portx_bp_page_cnt_s   cn70xx;
+	struct cvmx_ipd_portx_bp_page_cnt_s   cn70xxp1;
 	struct cvmx_ipd_portx_bp_page_cnt_s   cnf71xx;
 };
 typedef union cvmx_ipd_portx_bp_page_cnt cvmx_ipd_portx_bp_page_cnt_t;
@@ -2465,6 +2478,7 @@ union cvmx_ipd_portx_bp_page_cnt2 {
 	struct cvmx_ipd_portx_bp_page_cnt2_s  cn63xxp1;
 	struct cvmx_ipd_portx_bp_page_cnt2_s  cn66xx;
 	struct cvmx_ipd_portx_bp_page_cnt2_s  cn70xx;
+	struct cvmx_ipd_portx_bp_page_cnt2_s  cn70xxp1;
 	struct cvmx_ipd_portx_bp_page_cnt2_s  cnf71xx;
 };
 typedef union cvmx_ipd_portx_bp_page_cnt2 cvmx_ipd_portx_bp_page_cnt2_t;
@@ -2502,6 +2516,7 @@ union cvmx_ipd_portx_bp_page_cnt3 {
 	struct cvmx_ipd_portx_bp_page_cnt3_s  cn63xxp1;
 	struct cvmx_ipd_portx_bp_page_cnt3_s  cn66xx;
 	struct cvmx_ipd_portx_bp_page_cnt3_s  cn70xx;
+	struct cvmx_ipd_portx_bp_page_cnt3_s  cn70xxp1;
 	struct cvmx_ipd_portx_bp_page_cnt3_s  cnf71xx;
 };
 typedef union cvmx_ipd_portx_bp_page_cnt3 cvmx_ipd_portx_bp_page_cnt3_t;
@@ -2533,6 +2548,7 @@ union cvmx_ipd_port_bp_counters2_pairx {
 	struct cvmx_ipd_port_bp_counters2_pairx_s cn63xxp1;
 	struct cvmx_ipd_port_bp_counters2_pairx_s cn66xx;
 	struct cvmx_ipd_port_bp_counters2_pairx_s cn70xx;
+	struct cvmx_ipd_port_bp_counters2_pairx_s cn70xxp1;
 	struct cvmx_ipd_port_bp_counters2_pairx_s cnf71xx;
 };
 typedef union cvmx_ipd_port_bp_counters2_pairx cvmx_ipd_port_bp_counters2_pairx_t;
@@ -2560,6 +2576,7 @@ union cvmx_ipd_port_bp_counters3_pairx {
 	struct cvmx_ipd_port_bp_counters3_pairx_s cn63xxp1;
 	struct cvmx_ipd_port_bp_counters3_pairx_s cn66xx;
 	struct cvmx_ipd_port_bp_counters3_pairx_s cn70xx;
+	struct cvmx_ipd_port_bp_counters3_pairx_s cn70xxp1;
 	struct cvmx_ipd_port_bp_counters3_pairx_s cnf71xx;
 };
 typedef union cvmx_ipd_port_bp_counters3_pairx cvmx_ipd_port_bp_counters3_pairx_t;
@@ -2585,6 +2602,7 @@ union cvmx_ipd_port_bp_counters4_pairx {
 	struct cvmx_ipd_port_bp_counters4_pairx_s cn61xx;
 	struct cvmx_ipd_port_bp_counters4_pairx_s cn66xx;
 	struct cvmx_ipd_port_bp_counters4_pairx_s cn70xx;
+	struct cvmx_ipd_port_bp_counters4_pairx_s cn70xxp1;
 	struct cvmx_ipd_port_bp_counters4_pairx_s cnf71xx;
 };
 typedef union cvmx_ipd_port_bp_counters4_pairx cvmx_ipd_port_bp_counters4_pairx_t;
@@ -2623,6 +2641,7 @@ union cvmx_ipd_port_bp_counters_pairx {
 	struct cvmx_ipd_port_bp_counters_pairx_s cn63xxp1;
 	struct cvmx_ipd_port_bp_counters_pairx_s cn66xx;
 	struct cvmx_ipd_port_bp_counters_pairx_s cn70xx;
+	struct cvmx_ipd_port_bp_counters_pairx_s cn70xxp1;
 	struct cvmx_ipd_port_bp_counters_pairx_s cnf71xx;
 };
 typedef union cvmx_ipd_port_bp_counters_pairx cvmx_ipd_port_bp_counters_pairx_t;
@@ -2701,6 +2720,7 @@ union cvmx_ipd_port_qos_x_cnt {
 	struct cvmx_ipd_port_qos_x_cnt_s      cn68xx;
 	struct cvmx_ipd_port_qos_x_cnt_s      cn68xxp1;
 	struct cvmx_ipd_port_qos_x_cnt_s      cn70xx;
+	struct cvmx_ipd_port_qos_x_cnt_s      cn70xxp1;
 	struct cvmx_ipd_port_qos_x_cnt_s      cnf71xx;
 };
 typedef union cvmx_ipd_port_qos_x_cnt cvmx_ipd_port_qos_x_cnt_t;
@@ -2734,6 +2754,7 @@ union cvmx_ipd_port_qos_intx {
 	struct cvmx_ipd_port_qos_intx_s       cn68xx;
 	struct cvmx_ipd_port_qos_intx_s       cn68xxp1;
 	struct cvmx_ipd_port_qos_intx_s       cn70xx;
+	struct cvmx_ipd_port_qos_intx_s       cn70xxp1;
 	struct cvmx_ipd_port_qos_intx_s       cnf71xx;
 };
 typedef union cvmx_ipd_port_qos_intx cvmx_ipd_port_qos_intx_t;
@@ -2764,6 +2785,7 @@ union cvmx_ipd_port_qos_int_enbx {
 	struct cvmx_ipd_port_qos_int_enbx_s   cn68xx;
 	struct cvmx_ipd_port_qos_int_enbx_s   cn68xxp1;
 	struct cvmx_ipd_port_qos_int_enbx_s   cn70xx;
+	struct cvmx_ipd_port_qos_int_enbx_s   cn70xxp1;
 	struct cvmx_ipd_port_qos_int_enbx_s   cnf71xx;
 };
 typedef union cvmx_ipd_port_qos_int_enbx cvmx_ipd_port_qos_int_enbx_t;
@@ -2841,6 +2863,7 @@ union cvmx_ipd_prc_hold_ptr_fifo_ctl {
 	struct cvmx_ipd_prc_hold_ptr_fifo_ctl_s cn63xxp1;
 	struct cvmx_ipd_prc_hold_ptr_fifo_ctl_s cn66xx;
 	struct cvmx_ipd_prc_hold_ptr_fifo_ctl_s cn70xx;
+	struct cvmx_ipd_prc_hold_ptr_fifo_ctl_s cn70xxp1;
 	struct cvmx_ipd_prc_hold_ptr_fifo_ctl_s cnf71xx;
 };
 typedef union cvmx_ipd_prc_hold_ptr_fifo_ctl cvmx_ipd_prc_hold_ptr_fifo_ctl_t;
@@ -2892,6 +2915,7 @@ union cvmx_ipd_prc_port_ptr_fifo_ctl {
 	struct cvmx_ipd_prc_port_ptr_fifo_ctl_s cn63xxp1;
 	struct cvmx_ipd_prc_port_ptr_fifo_ctl_s cn66xx;
 	struct cvmx_ipd_prc_port_ptr_fifo_ctl_s cn70xx;
+	struct cvmx_ipd_prc_port_ptr_fifo_ctl_s cn70xxp1;
 	struct cvmx_ipd_prc_port_ptr_fifo_ctl_s cnf71xx;
 };
 typedef union cvmx_ipd_prc_port_ptr_fifo_ctl cvmx_ipd_prc_port_ptr_fifo_ctl_t;
@@ -2952,6 +2976,7 @@ union cvmx_ipd_ptr_count {
 	struct cvmx_ipd_ptr_count_s           cn68xx;
 	struct cvmx_ipd_ptr_count_s           cn68xxp1;
 	struct cvmx_ipd_ptr_count_s           cn70xx;
+	struct cvmx_ipd_ptr_count_s           cn70xxp1;
 	struct cvmx_ipd_ptr_count_s           cnf71xx;
 };
 typedef union cvmx_ipd_ptr_count cvmx_ipd_ptr_count_t;
@@ -3012,6 +3037,7 @@ union cvmx_ipd_pwp_ptr_fifo_ctl {
 	struct cvmx_ipd_pwp_ptr_fifo_ctl_s    cn63xxp1;
 	struct cvmx_ipd_pwp_ptr_fifo_ctl_s    cn66xx;
 	struct cvmx_ipd_pwp_ptr_fifo_ctl_s    cn70xx;
+	struct cvmx_ipd_pwp_ptr_fifo_ctl_s    cn70xxp1;
 	struct cvmx_ipd_pwp_ptr_fifo_ctl_s    cnf71xx;
 };
 typedef union cvmx_ipd_pwp_ptr_fifo_ctl cvmx_ipd_pwp_ptr_fifo_ctl_t;
@@ -3054,6 +3080,7 @@ union cvmx_ipd_qosx_red_marks {
 	struct cvmx_ipd_qosx_red_marks_s      cn68xx;
 	struct cvmx_ipd_qosx_red_marks_s      cn68xxp1;
 	struct cvmx_ipd_qosx_red_marks_s      cn70xx;
+	struct cvmx_ipd_qosx_red_marks_s      cn70xxp1;
 	struct cvmx_ipd_qosx_red_marks_s      cnf71xx;
 };
 typedef union cvmx_ipd_qosx_red_marks cvmx_ipd_qosx_red_marks_t;
@@ -3093,6 +3120,7 @@ union cvmx_ipd_que0_free_page_cnt {
 	struct cvmx_ipd_que0_free_page_cnt_s  cn68xx;
 	struct cvmx_ipd_que0_free_page_cnt_s  cn68xxp1;
 	struct cvmx_ipd_que0_free_page_cnt_s  cn70xx;
+	struct cvmx_ipd_que0_free_page_cnt_s  cn70xxp1;
 	struct cvmx_ipd_que0_free_page_cnt_s  cnf71xx;
 };
 typedef union cvmx_ipd_que0_free_page_cnt cvmx_ipd_que0_free_page_cnt_t;
@@ -3202,6 +3230,7 @@ union cvmx_ipd_red_port_enable {
 	struct cvmx_ipd_red_port_enable_s     cn63xxp1;
 	struct cvmx_ipd_red_port_enable_s     cn66xx;
 	struct cvmx_ipd_red_port_enable_s     cn70xx;
+	struct cvmx_ipd_red_port_enable_s     cn70xxp1;
 	struct cvmx_ipd_red_port_enable_s     cnf71xx;
 };
 typedef union cvmx_ipd_red_port_enable cvmx_ipd_red_port_enable_t;
@@ -3254,6 +3283,7 @@ union cvmx_ipd_red_port_enable2 {
 	struct cvmx_ipd_red_port_enable2_cn63xx cn63xxp1;
 	struct cvmx_ipd_red_port_enable2_s    cn66xx;
 	struct cvmx_ipd_red_port_enable2_s    cn70xx;
+	struct cvmx_ipd_red_port_enable2_s    cn70xxp1;
 	struct cvmx_ipd_red_port_enable2_s    cnf71xx;
 };
 typedef union cvmx_ipd_red_port_enable2 cvmx_ipd_red_port_enable2_t;
@@ -3328,6 +3358,7 @@ union cvmx_ipd_red_quex_param {
 	struct cvmx_ipd_red_quex_param_s      cn68xx;
 	struct cvmx_ipd_red_quex_param_s      cn68xxp1;
 	struct cvmx_ipd_red_quex_param_s      cn70xx;
+	struct cvmx_ipd_red_quex_param_s      cn70xxp1;
 	struct cvmx_ipd_red_quex_param_s      cnf71xx;
 };
 typedef union cvmx_ipd_red_quex_param cvmx_ipd_red_quex_param_t;
@@ -3414,6 +3445,7 @@ union cvmx_ipd_sub_port_bp_page_cnt {
 	struct cvmx_ipd_sub_port_bp_page_cnt_s cn68xx;
 	struct cvmx_ipd_sub_port_bp_page_cnt_s cn68xxp1;
 	struct cvmx_ipd_sub_port_bp_page_cnt_s cn70xx;
+	struct cvmx_ipd_sub_port_bp_page_cnt_s cn70xxp1;
 	struct cvmx_ipd_sub_port_bp_page_cnt_s cnf71xx;
 };
 typedef union cvmx_ipd_sub_port_bp_page_cnt cvmx_ipd_sub_port_bp_page_cnt_t;
@@ -3479,6 +3511,7 @@ union cvmx_ipd_sub_port_fcs {
 	struct cvmx_ipd_sub_port_fcs_s        cn63xxp1;
 	struct cvmx_ipd_sub_port_fcs_s        cn66xx;
 	struct cvmx_ipd_sub_port_fcs_s        cn70xx;
+	struct cvmx_ipd_sub_port_fcs_s        cn70xxp1;
 	struct cvmx_ipd_sub_port_fcs_s        cnf71xx;
 };
 typedef union cvmx_ipd_sub_port_fcs cvmx_ipd_sub_port_fcs_t;
@@ -3515,6 +3548,7 @@ union cvmx_ipd_sub_port_qos_cnt {
 	struct cvmx_ipd_sub_port_qos_cnt_s    cn68xx;
 	struct cvmx_ipd_sub_port_qos_cnt_s    cn68xxp1;
 	struct cvmx_ipd_sub_port_qos_cnt_s    cn70xx;
+	struct cvmx_ipd_sub_port_qos_cnt_s    cn70xxp1;
 	struct cvmx_ipd_sub_port_qos_cnt_s    cnf71xx;
 };
 typedef union cvmx_ipd_sub_port_qos_cnt cvmx_ipd_sub_port_qos_cnt_t;
@@ -3556,6 +3590,7 @@ union cvmx_ipd_wqe_fpa_queue {
 	struct cvmx_ipd_wqe_fpa_queue_s       cn68xx;
 	struct cvmx_ipd_wqe_fpa_queue_s       cn68xxp1;
 	struct cvmx_ipd_wqe_fpa_queue_s       cn70xx;
+	struct cvmx_ipd_wqe_fpa_queue_s       cn70xxp1;
 	struct cvmx_ipd_wqe_fpa_queue_s       cnf71xx;
 };
 typedef union cvmx_ipd_wqe_fpa_queue cvmx_ipd_wqe_fpa_queue_t;
@@ -3594,6 +3629,7 @@ union cvmx_ipd_wqe_ptr_valid {
 	struct cvmx_ipd_wqe_ptr_valid_s       cn63xxp1;
 	struct cvmx_ipd_wqe_ptr_valid_s       cn66xx;
 	struct cvmx_ipd_wqe_ptr_valid_s       cn70xx;
+	struct cvmx_ipd_wqe_ptr_valid_s       cn70xxp1;
 	struct cvmx_ipd_wqe_ptr_valid_s       cnf71xx;
 };
 typedef union cvmx_ipd_wqe_ptr_valid cvmx_ipd_wqe_ptr_valid_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-l2c-defs.h b/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
index 270ced1..2540ece 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2c-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1580,6 +1580,7 @@ union cvmx_l2c_big_ctl {
 	uint64_t reserved_8_63                : 56;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_big_ctl_cn70xx        cn70xxp1;
 	struct cvmx_l2c_big_ctl_cn70xx        cn78xx;
 	struct cvmx_l2c_big_ctl_cn61xx        cnf71xx;
 };
@@ -2319,6 +2320,7 @@ union cvmx_l2c_cbcx_bist_status {
 	uint64_t reserved_34_63               : 30;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_cbcx_bist_status_cn70xx cn70xxp1;
 	struct cvmx_l2c_cbcx_bist_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_37_63               : 27;
@@ -2381,11 +2383,13 @@ union cvmx_l2c_cbcx_holeerr {
 	uint64_t holerd                       : 1;  /**< Logged information is for a HOLERD error. */
 	uint64_t holewr                       : 1;  /**< Logged information is for a HOLEWR error. */
 	uint64_t reserved_59_61               : 3;
-	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. */
+	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. INTERNAL: If CMD[7]==1, use XMC_CMD_E to
+                                                         decode CMD[6:0]. If CMD[7:5]==0, use OCI_MREQ_CMD_E to decode CMD[4:0]. If CMD[7:5]==1,
+                                                         use OCI_MFWD_CMD_E to decode CMD[4:0]. If CMD[7:5]==2, use OCI_MRSP_CMD_E to decode
+                                                         CMD[4:0]. */
 	uint64_t source                       : 7;  /**< XMC 'source' of request causing error. If SOURCE<6>==0, then SOURCE<5:0> is PPID, else
                                                          SOURCE<3:0> is BUSID of the IOB which made the request. */
-	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error.
-                                                         For HOLE* errors, is the NODE the request is directed to. */
+	uint64_t node                         : 4;  /**< OCI Node of XMC request causing error.For HOLE* errors, is the NODE the request is directed to. */
 	uint64_t addr                         : 40; /**< XMC address causing the error. This field is the physical address after hole removal and
                                                          index aliasing (if enabled). (The hole is between DR0 and DR1. Remove the hole by
                                                          subtracting 256MB from all L2/DRAM physical addresses >= 512 MB.) */
@@ -2457,6 +2461,7 @@ union cvmx_l2c_cbcx_int {
 	uint64_t reserved_4_63                : 60;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_cbcx_int_cn70xx       cn70xxp1;
 	struct cvmx_l2c_cbcx_int_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
@@ -2515,6 +2520,7 @@ union cvmx_l2c_cbcx_iocerr {
 #endif
 	} s;
 	struct cvmx_l2c_cbcx_iocerr_s         cn70xx;
+	struct cvmx_l2c_cbcx_iocerr_s         cn70xxp1;
 	struct cvmx_l2c_cbcx_iocerr_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_0_63                : 64;
@@ -2539,7 +2545,7 @@ union cvmx_l2c_cbcx_iodisocierr {
 	struct cvmx_l2c_cbcx_iodisocierr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_59_63               : 5;
-	uint64_t cmd                          : 7;  /**< Encoding of XMC command. */
+	uint64_t cmd                          : 7;  /**< Encoding of XMC command.  INTERNAL: Enumerated with XMC_CMD_E. */
 	uint64_t ppvid                        : 6;  /**< CMB source PPVID. */
 	uint64_t node                         : 2;  /**< Destination node ID. */
 	uint64_t did                          : 8;  /**< Destination device ID. */
@@ -2580,7 +2586,7 @@ union cvmx_l2c_cbcx_miberr {
                                                          0x1 = Error from MXB_VC_MRD, MXB_VC_MPD VCs.
                                                          0x2 = Error from MXB_VC_IRM VC.
                                                          0x3 = Error from MXB_VC_IPM VC. */
-	uint64_t mibnum                       : 1;  /**< Indicates the CBC that had the error. */
+	uint64_t mibnum                       : 1;  /**< Indicates the MIB bus that had the error. */
 #else
 	uint64_t mibnum                       : 1;
 	uint64_t memid                        : 2;
@@ -2629,6 +2635,7 @@ union cvmx_l2c_cbcx_rsderr {
 #endif
 	} s;
 	struct cvmx_l2c_cbcx_rsderr_s         cn70xx;
+	struct cvmx_l2c_cbcx_rsderr_s         cn70xxp1;
 	struct cvmx_l2c_cbcx_rsderr_s         cn78xx;
 };
 typedef union cvmx_l2c_cbcx_rsderr cvmx_l2c_cbcx_rsderr_t;
@@ -3339,6 +3346,7 @@ union cvmx_l2c_cop0_adr {
 #endif
 	} s;
 	struct cvmx_l2c_cop0_adr_s            cn70xx;
+	struct cvmx_l2c_cop0_adr_s            cn70xxp1;
 	struct cvmx_l2c_cop0_adr_s            cn78xx;
 };
 typedef union cvmx_l2c_cop0_adr cvmx_l2c_cop0_adr_t;
@@ -3359,6 +3367,7 @@ union cvmx_l2c_cop0_dat {
 #endif
 	} s;
 	struct cvmx_l2c_cop0_dat_s            cn70xx;
+	struct cvmx_l2c_cop0_dat_s            cn70xxp1;
 	struct cvmx_l2c_cop0_dat_s            cn78xx;
 };
 typedef union cvmx_l2c_cop0_dat cvmx_l2c_cop0_dat_t;
@@ -3853,6 +3862,7 @@ union cvmx_l2c_ctl {
 	uint64_t reserved_32_63               : 32;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_ctl_cn70xx            cn70xxp1;
 	struct cvmx_l2c_ctl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
@@ -3876,7 +3886,8 @@ union cvmx_l2c_ctl {
 	uint64_t disldwb                      : 1;  /**< Suppresses the DWB functionality of any received LDWB, effectively turning them into LDTs. */
 	uint64_t dissblkdty                   : 1;  /**< Disable bandwidth optimization between L2 and LMC and MOB which only transfers modified
                                                          sub-blocks when possible. In an OCI system all nodes must use the same setting of
-                                                         DISSBLKDTY or operation is undefined. */
+                                                         DISSBLKDTY or operation is undefined.
+                                                         INTERNAL: PASS2: DISSBLKDTY should reset to 0, once verif supports it. */
 	uint64_t disecc                       : 1;  /**< Tag and data ECC disable. */
 	uint64_t disidxalias                  : 1;  /**< Index alias disable. */
 #else
@@ -4586,6 +4597,7 @@ union cvmx_l2c_ecc_ctl {
 	uint64_t reserved_10_63               : 54;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_ecc_ctl_cn70xx        cn70xxp1;
 	struct cvmx_l2c_ecc_ctl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
@@ -5448,6 +5460,7 @@ union cvmx_l2c_invx_pfc {
 #endif
 	} s;
 	struct cvmx_l2c_invx_pfc_s            cn70xx;
+	struct cvmx_l2c_invx_pfc_s            cn70xxp1;
 	struct cvmx_l2c_invx_pfc_s            cn78xx;
 };
 typedef union cvmx_l2c_invx_pfc cvmx_l2c_invx_pfc_t;
@@ -5474,6 +5487,7 @@ union cvmx_l2c_iocx_pfc {
 	struct cvmx_l2c_iocx_pfc_s            cn68xx;
 	struct cvmx_l2c_iocx_pfc_s            cn68xxp1;
 	struct cvmx_l2c_iocx_pfc_s            cn70xx;
+	struct cvmx_l2c_iocx_pfc_s            cn70xxp1;
 	struct cvmx_l2c_iocx_pfc_s            cn78xx;
 	struct cvmx_l2c_iocx_pfc_s            cnf71xx;
 };
@@ -5501,6 +5515,7 @@ union cvmx_l2c_iorx_pfc {
 	struct cvmx_l2c_iorx_pfc_s            cn68xx;
 	struct cvmx_l2c_iorx_pfc_s            cn68xxp1;
 	struct cvmx_l2c_iorx_pfc_s            cn70xx;
+	struct cvmx_l2c_iorx_pfc_s            cn70xxp1;
 	struct cvmx_l2c_iorx_pfc_s            cn78xx;
 	struct cvmx_l2c_iorx_pfc_s            cnf71xx;
 };
@@ -6055,6 +6070,7 @@ union cvmx_l2c_mcix_bist_status {
 #endif
 	} s;
 	struct cvmx_l2c_mcix_bist_status_s    cn70xx;
+	struct cvmx_l2c_mcix_bist_status_s    cn70xxp1;
 	struct cvmx_l2c_mcix_bist_status_s    cn78xx;
 };
 typedef union cvmx_l2c_mcix_bist_status cvmx_l2c_mcix_bist_status_t;
@@ -6099,6 +6115,7 @@ union cvmx_l2c_mcix_err {
 #endif
 	} s;
 	struct cvmx_l2c_mcix_err_s            cn70xx;
+	struct cvmx_l2c_mcix_err_s            cn70xxp1;
 	struct cvmx_l2c_mcix_err_s            cn78xx;
 };
 typedef union cvmx_l2c_mcix_err cvmx_l2c_mcix_err_t;
@@ -6123,6 +6140,7 @@ union cvmx_l2c_mcix_int {
 #endif
 	} s;
 	struct cvmx_l2c_mcix_int_s            cn70xx;
+	struct cvmx_l2c_mcix_int_s            cn70xxp1;
 	struct cvmx_l2c_mcix_int_s            cn78xx;
 };
 typedef union cvmx_l2c_mcix_int cvmx_l2c_mcix_int_t;
@@ -6136,35 +6154,32 @@ union cvmx_l2c_oci_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_30_63               : 34;
 	uint64_t lock_local_cas               : 1;  /**< When set, L2 CAS operations to remote addresses which miss at the requester will be
-                                                         performed
-                                                         locally (if possible) on the requesting node. Default operation will instead send the CAS
-                                                         request
-                                                         to be performed on the home node. For STC ops LOCK_LOCAL_STC. */
+                                                         performed locally (if possible) on the requesting node. Default operation will instead
+                                                         send the CAS request to be performed on the home node. For STC ops LOCK_LOCAL_STC. */
 	uint64_t lock_local_stc               : 1;  /**< When set, L2 STC operations to remote addresses which miss at the requester will be
-                                                         performed
-                                                         locally (if possible) on the requesting node. Default operation will instead send the STC
-                                                         request
-                                                         to be performed on the home node. For CAS ops LOCK_LOCAL_CAS. */
+                                                         performed locally (if possible) on the requesting node. Default operation will instead
+                                                         send the STC request to be performed on the home node. For CAS ops LOCK_LOCAL_CAS. */
 	uint64_t lock_local_pp                : 1;  /**< When clear, L2 atomic operations (excluding CAS/STC) pp initiated requests to remote
-                                                         addresses
-                                                         which miss at the requester will send the atomic request to be performed on the home node.
-                                                         Default operation will instead  be performed locally on the requesting node.
+                                                         addresses which miss at the requester will send the atomic request to be performed on the
+                                                         home node. Default operation will instead  be performed locally on the requesting node.
                                                          For request initiated by IOB & for STC & CAS ops, see
                                                          LOCK_LOCAL_IOB/LOCK_LOCAL_STC/LOCK_LOCAL_CAS. */
-	uint64_t lngtolen                     : 5;  /**< Selects the bit in the counter for the long timeout value (timeout used when SHTO bit is
+	uint64_t lngtolen                     : 5;  /**< Selects the bit in the counter for the long timeout value (timeout used when [SHTO] is
                                                          clear). Values supported are between 11 and 29 (for a timeout values between 2^11 and
                                                          2^29). Actual timeout is between 1x and 2x this interval. For example if LNGTOLEN = 28
                                                          (the reset value), the timeout is between 256M and 512M core clocks. Note: a value of 0
                                                          disables this timer. */
-	uint64_t shtolen                      : 5;  /**< Selects the bit in the counter for the short timeout value (timeout used when SHTO bit is
+	uint64_t shtolen                      : 5;  /**< Selects the bit in the counter for the short timeout value (timeout used when [SHTO] is
                                                          set). Values supported are between 9 and 29 (for a timeout values between 2^9 and 2^29).
                                                          Actual timeout is between 1x and 2x this interval. For example if SHTOLEN = 14 (the reset
                                                          value), the timeout is between 16K and 32K core clocks. Note: a value of 0 disables this
                                                          timer. */
 	uint64_t shtoioen                     : 1;  /**< When set, any PP issues any of an IO load, acking store, IOBDMA, LMTDMA, acking IOBADDR,
                                                          or acking LMTST to a node that doesn't exist (existence defined by the ENAOCI bits), then
-                                                         the hardware sets the SHTO CSR field. */
-	uint64_t shtoen                       : 3;  /**< When set, if the corresponding OCI link is down, the hardware sets the SHTO CSR field. */
+                                                         the hardware sets [SHTO]. */
+	uint64_t shtoen                       : 3;  /**< When set, if the corresponding OCI link is down, the hardware sets [SHTO].
+                                                         See OCX_COM_LINK(0..2)_CTL for a description of what events can contribute to the
+                                                         link_down condition. */
 	uint64_t shto                         : 1;  /**< Use short timeout intervals. When set, core uses SDIDTTO for both DID and commit counter
                                                          timeouts, rather than DIDTTO/DIDTTO2. Similarly, L2C will use short instead of long
                                                          timeout. */
@@ -6182,11 +6197,9 @@ union cvmx_l2c_oci_ctl {
                                                          exclusive response (PEMD). Note that an incorrect assumption only causes an extra tag
                                                          write to be done upon receiving the response. */
 	uint64_t lock_local_iob               : 1;  /**< When set, L2 atomic operations (excluding CAS/STC) initiated by IOB to remote addresses
-                                                         which miss at the requester will be performed locally on the requesting node. When clear
-                                                         the
-                                                         operation will instead send the atomic request to be performed on the home node.
-                                                         For request initiated by PP & for STC & CAS ops see
-                                                         LOCK_LOCAL_PP/LOCK_LOCAL_STC/LOCK_LOCAL_CAS.
+                                                         which miss at the requester are performed locally on the requesting node. When clear the
+                                                         operation instead sends the atomic request to be performed on the home node. For request
+                                                         initiated by PP & for STC & CAS ops see LOCK_LOCAL_PP/LOCK_LOCAL_STC/LOCK_LOCAL_CAS.
                                                          Default is set to 1 (local locks). */
 	uint64_t iofrcl                       : 1;  /**< When set, L2C services all I/O read and write operations on the local node, regardless of
                                                          the value of the node ID bits in the physical address. During normal operation this bit is
@@ -6200,7 +6213,8 @@ union cvmx_l2c_oci_ctl {
                                                          ultimately discarded. RDDISOCI/WRDISOCI/IORDDISOCI/IOWRDISOCI interrupts occur if and only
                                                          if the corresponding ENAOCI[node] bit is clear. References to the local node (configured
                                                          via OCX_COM_NODE[ID]) ignore the value of ENAOCI[node] because no OCI processing is
-                                                         required. */
+                                                         required. Similarly, all I/O references ignore the value of ENAOCI when
+                                                         L2C_OCI_CTL[IOFRCL] is set. */
 #else
 	uint64_t enaoci                       : 4;
 	uint64_t gksegnode                    : 2;
@@ -6723,6 +6737,7 @@ union cvmx_l2c_qos_iobx {
 	struct cvmx_l2c_qos_iobx_s            cn68xx;
 	struct cvmx_l2c_qos_iobx_s            cn68xxp1;
 	struct cvmx_l2c_qos_iobx_s            cn70xx;
+	struct cvmx_l2c_qos_iobx_s            cn70xxp1;
 	struct cvmx_l2c_qos_iobx_s            cn78xx;
 	struct cvmx_l2c_qos_iobx_cn61xx       cnf71xx;
 };
@@ -6761,6 +6776,7 @@ union cvmx_l2c_qos_ppx {
 	struct cvmx_l2c_qos_ppx_s             cn68xx;
 	struct cvmx_l2c_qos_ppx_s             cn68xxp1;
 	struct cvmx_l2c_qos_ppx_s             cn70xx;
+	struct cvmx_l2c_qos_ppx_s             cn70xxp1;
 	struct cvmx_l2c_qos_ppx_s             cn78xx;
 	struct cvmx_l2c_qos_ppx_cn61xx        cnf71xx;
 };
@@ -6816,6 +6832,7 @@ union cvmx_l2c_qos_wgt {
 	struct cvmx_l2c_qos_wgt_s             cn68xx;
 	struct cvmx_l2c_qos_wgt_s             cn68xxp1;
 	struct cvmx_l2c_qos_wgt_s             cn70xx;
+	struct cvmx_l2c_qos_wgt_s             cn70xxp1;
 	struct cvmx_l2c_qos_wgt_s             cn78xx;
 	struct cvmx_l2c_qos_wgt_cn61xx        cnf71xx;
 };
@@ -6843,6 +6860,7 @@ union cvmx_l2c_rscx_pfc {
 	struct cvmx_l2c_rscx_pfc_s            cn68xx;
 	struct cvmx_l2c_rscx_pfc_s            cn68xxp1;
 	struct cvmx_l2c_rscx_pfc_s            cn70xx;
+	struct cvmx_l2c_rscx_pfc_s            cn70xxp1;
 	struct cvmx_l2c_rscx_pfc_s            cn78xx;
 	struct cvmx_l2c_rscx_pfc_s            cnf71xx;
 };
@@ -6870,6 +6888,7 @@ union cvmx_l2c_rsdx_pfc {
 	struct cvmx_l2c_rsdx_pfc_s            cn68xx;
 	struct cvmx_l2c_rsdx_pfc_s            cn68xxp1;
 	struct cvmx_l2c_rsdx_pfc_s            cn70xx;
+	struct cvmx_l2c_rsdx_pfc_s            cn70xxp1;
 	struct cvmx_l2c_rsdx_pfc_s            cn78xx;
 	struct cvmx_l2c_rsdx_pfc_s            cnf71xx;
 };
@@ -7159,6 +7178,7 @@ union cvmx_l2c_tadx_dll {
 	uint64_t reserved_16_63               : 48;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_tadx_dll_cn70xx       cn70xxp1;
 	struct cvmx_l2c_tadx_dll_s            cn78xx;
 };
 typedef union cvmx_l2c_tadx_dll cvmx_l2c_tadx_dll_t;
@@ -7259,7 +7279,10 @@ union cvmx_l2c_tadx_err {
 	uint64_t bigrd                        : 1;  /**< Logged information is for a BIGRD error. */
 	uint64_t bigwr                        : 1;  /**< Logged information is for a BIGWR error. */
 	uint64_t reserved_59_61               : 3;
-	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. */
+	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. INTERNAL: If CMD[7]==1, use XMC_CMD_E to
+                                                         decode CMD[6:0]. If CMD[7:5]==0, use OCI_MREQ_CMD_E to decode CMD[4:0]. If CMD[7:5]==1,
+                                                         use OCI_MFWD_CMD_E to decode CMD[4:0]. If CMD[7:5]==2, use OCI_MRSP_CMD_E to decode
+                                                         CMD[4:0]. */
 	uint64_t source                       : 7;  /**< XMC source of request causing error. If SOURCE<6>==0, then SOURCE<5:0> is PPID, else
                                                          SOURCE<3:0> is BUSID of the IOB which made the request. If CMD[7]==0, this field is
                                                          unpredictable. */
@@ -7306,6 +7329,7 @@ union cvmx_l2c_tadx_err {
 	uint64_t bigrd                        : 1;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_tadx_err_cn70xx       cn70xxp1;
 	struct cvmx_l2c_tadx_err_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t bigrd                        : 1;  /**< Logged information is for a BIGRD error. */
@@ -7313,7 +7337,10 @@ union cvmx_l2c_tadx_err {
 	uint64_t rddisoci                     : 1;  /**< Logged information is for a RDDISOCI error. */
 	uint64_t wrdisoci                     : 1;  /**< Logged information is for a WRDISOCI error. */
 	uint64_t reserved_59_59               : 1;
-	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. */
+	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. INTERNAL: If CMD[7]==1, use XMC_CMD_E to
+                                                         decode CMD[6:0]. If CMD[7:5]==0, use OCI_MREQ_CMD_E to decode CMD[4:0]. If CMD[7:5]==1,
+                                                         use OCI_MFWD_CMD_E to decode CMD[4:0]. If CMD[7:5]==2, use OCI_MRSP_CMD_E to decode
+                                                         CMD[4:0]. */
 	uint64_t source                       : 7;  /**< XMC source of request causing error. If SOURCE<6>==0, then SOURCE<5:0> is PPID, else
                                                          SOURCE<3:0> is BUSID of the IOB which made the request. If CMD[7]==0, this field is
                                                          unpredictable. */
@@ -7449,8 +7476,8 @@ union cvmx_l2c_tadx_int {
                                                          L2C_TAD(0..7)_ERR for for logged information. */
 	uint64_t rddisoci                     : 1;  /**< Illegal read operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. Note
                                                          RDDISOCI interrupts can occur during normal operation as the cores are allowed to prefetch
-                                                         to nonexistent memory locations. Therefore, RDDISOCI is for informational purposes
-                                                         only. See L2C_TAD(0..7)_ERR for for logged information. */
+                                                         to nonexistent memory locations. Therefore, RDDISOCI is for informational purposes only.
+                                                         See L2C_TAD(0..7)_ERR for logged information. */
 	uint64_t rtgdbe                       : 1;  /**< RTG double-bit error. */
 	uint64_t rtgsbe                       : 1;  /**< RTG single-bit error. */
 	uint64_t reserved_18_31               : 14;
@@ -7460,11 +7487,10 @@ union cvmx_l2c_tadx_int {
                                                          capture info from the lowest LFB number that timed out. */
 	uint64_t reserved_15_16               : 2;
 	uint64_t bigrd                        : 1;  /**< Read reference past L2C_BIG_CTL[MAXDRAM] occurred. BIGRD interrupts can occur during
-                                                         normal operation as the cores are allowed to prefetch to nonexistent memory
-                                                         locations. Therefore, BIGRD is for informational purposes only. See L2C_TAD(0..7)_ERR for
-                                                         logged information. */
-	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. See L2C_TAD(0..7)_ERR for for logged
+                                                         normal operation as the cores are allowed to prefetch to nonexistent memory locations.
+                                                         Therefore, BIGRD is for informational purposes only. See L2C_TAD(0..7)_ERR for logged
                                                          information. */
+	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. See L2C_TAD(0..7)_ERR for logged information. */
 	uint64_t holerd                       : 1;  /**< Read reference to 256MB hole occurred. */
 	uint64_t holewr                       : 1;  /**< Write reference to 256MB hole occurred. */
 	uint64_t reserved_2_10                : 9;
@@ -7589,6 +7615,7 @@ union cvmx_l2c_tadx_int {
 	uint64_t reserved_34_63               : 30;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_tadx_int_cn70xx       cn70xxp1;
 	struct cvmx_l2c_tadx_int_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
@@ -7596,8 +7623,8 @@ union cvmx_l2c_tadx_int {
                                                          L2C_TAD(0..7)_ERR for for logged information. */
 	uint64_t rddisoci                     : 1;  /**< Illegal read operation to a remote node with L2C_OCI_CTL[ENAOCI][node] clear. Note
                                                          RDDISOCI interrupts can occur during normal operation as the cores are allowed to prefetch
-                                                         to nonexistent memory locations. Therefore, RDDISOCI is for informational purposes
-                                                         only. See L2C_TAD(0..7)_ERR for for logged information. */
+                                                         to nonexistent memory locations. Therefore, RDDISOCI is for informational purposes only.
+                                                         See L2C_TAD(0..7)_ERR for logged information. */
 	uint64_t rtgdbe                       : 1;  /**< RTG double-bit error. */
 	uint64_t rtgsbe                       : 1;  /**< RTG single-bit error. */
 	uint64_t reserved_18_31               : 14;
@@ -7605,14 +7632,13 @@ union cvmx_l2c_tadx_int {
                                                          occurs L2C_TAD(0..7)_TIMEOUT is loaded. L2C_TAD(0..7)_TIMEOUT is loaded with info from the
                                                          first LFB that timed out. if multiple LFB timed out simultaneously, then the it will
                                                          capture info from the lowest LFB number that timed out. */
-	uint64_t wrdislmc                     : 1;  /**< Illegal write to disabled LMC error. A DRAM write arrived before the LMC was enabled. */
-	uint64_t rddislmc                     : 1;  /**< Illegal read to disabled LMC error. A DRAM read arrived before the LMC was enabled. */
+	uint64_t wrdislmc                     : 1;  /**< Illegal write to disabled LMC error. A DRAM write arrived before LMC was enabled. */
+	uint64_t rddislmc                     : 1;  /**< Illegal read to disabled LMC error. A DRAM read arrived before LMC was enabled. */
 	uint64_t bigrd                        : 1;  /**< Read reference past L2C_BIG_CTL[MAXDRAM] occurred. BIGRD interrupts can occur during
-                                                         normal operation as the cores are allowed to prefetch to nonexistent memory
-                                                         locations. Therefore, BIGRD is for informational purposes only. See L2C_TAD(0..7)_ERR for
-                                                         logged information. */
-	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. See L2C_TAD(0..7)_ERR for for logged
+                                                         normal operation as the cores are allowed to prefetch to nonexistent memory locations.
+                                                         Therefore, BIGRD is for informational purposes only. See L2C_TAD(0..7)_ERR for logged
                                                          information. */
+	uint64_t bigwr                        : 1;  /**< Write reference past L2C_BIG_CTL[MAXDRAM] occurred. See L2C_TAD(0..7)_ERR for logged information. */
 	uint64_t reserved_11_12               : 2;
 	uint64_t noway                        : 1;  /**< No way was available for allocation. L2C sets NOWAY during its processing of a transaction
                                                          whenever it needed/wanted to allocate a WAY in the L2 cache, but was unable to. When this
@@ -7673,6 +7699,7 @@ union cvmx_l2c_tadx_pfcx {
 #endif
 	} s;
 	struct cvmx_l2c_tadx_pfcx_s           cn70xx;
+	struct cvmx_l2c_tadx_pfcx_s           cn70xxp1;
 	struct cvmx_l2c_tadx_pfcx_s           cn78xx;
 };
 typedef union cvmx_l2c_tadx_pfcx cvmx_l2c_tadx_pfcx_t;
@@ -7807,6 +7834,7 @@ union cvmx_l2c_tadx_prf {
 	struct cvmx_l2c_tadx_prf_s            cn68xx;
 	struct cvmx_l2c_tadx_prf_s            cn68xxp1;
 	struct cvmx_l2c_tadx_prf_s            cn70xx;
+	struct cvmx_l2c_tadx_prf_s            cn70xxp1;
 	struct cvmx_l2c_tadx_prf_s            cn78xx;
 	struct cvmx_l2c_tadx_prf_s            cnf71xx;
 };
@@ -7899,14 +7927,14 @@ union cvmx_l2c_tadx_tag {
 	uint64_t sblkdty                      : 4;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_tadx_tag_cn70xx       cn70xxp1;
 	struct cvmx_l2c_tadx_tag_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t sblkdty                      : 4;  /**< Sub-block dirty bits. Ignored/loaded with 0 for RTG accesses. If TS is Invalid (0) SBLKDTY
                                                          must be 0 or operation is undefined. */
 	uint64_t reserved_58_59               : 2;
-	uint64_t businfo                      : 9;  /**< The bus information bits.  Ignored/loaded with 0 for RTG accesses. */
-	uint64_t ecc                          : 7;  /**< The tag ECC. This field is undefined if L2C_CTL[DISECC] is not 1 when the LTGL2I reads the
-                                                         tags. */
+	uint64_t businfo                      : 9;  /**< The bus information bits. Ignored/loaded with 0 for RTG accesses. */
+	uint64_t ecc                          : 7;  /**< The tag ECC. This field is undefined if L2C_CTL[DISECC] is not 1 when the LTGL2I reads the tags. */
 	uint64_t tag                          : 22; /**< The tag. TAG[39:20] is the corresponding bits from the L2C+LMC internal L2/DRAM byte
                                                          address. TAG[41:40] is the OCI node of the address. The RTG must always have the
                                                          TAG[41:40] == to the current node or operation is undefined. */
@@ -7942,12 +7970,11 @@ typedef union cvmx_l2c_tadx_tag cvmx_l2c_tadx_tag_t;
 /**
  * cvmx_l2c_tad#_timeout
  *
- * This register records error information for an LFBTO (LFB TimeOut). The first LFBTO
- * error will lock the register until the logged error type s cleared. If multiple
- * LFBs timed out simultaneously, then this will contain the information form the
- * lowest LFB number that has timed-out. The address can be for the original transaction address
- * or the replacement address (if both could have timed out, then the transaction address will
- * be here).
+ * This register records error information for an LFBTO (LFB TimeOut). The first LFBTO error will
+ * lock the register until the logged error type s cleared. If multiple LFBs timed out
+ * simultaneously, then this will contain the information form the lowest LFB number that has
+ * timed-out. The address can be for the original transaction address or the replacement address
+ * (if both could have timed out, then the transaction address will be here).
  */
 union cvmx_l2c_tadx_timeout {
 	uint64_t u64;
@@ -7958,20 +7985,19 @@ union cvmx_l2c_tadx_timeout {
                                                          then both could have timed out, but info captured is from the original LFB. */
 	uint64_t reserved_57_61               : 5;
 	uint64_t lfbnum                       : 5;  /**< The LFB number of the entry that timed out, and have its info captures in this register. */
-	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error. */
-	uint64_t node                         : 4;  /**< Home Node of the address causing the error. Similar the ADDR below, this can be the
-                                                         request address
-                                                         (if INFOLFB is set), else it is the replacement address (if INFOLFB is clear & INFOVAB is
-                                                         set). */
+	uint64_t cmd                          : 8;  /**< Encoding of XMC or OCI command causing error.
+                                                         INTERNAL: If CMD[7]==1, use XMC_CMD_E to decode CMD[6:0]. If CMD[7:5]==0, use
+                                                         OCI_MREQ_CMD_E to
+                                                         decode CMD[4:0]. If CMD[7:5]==1, use OCI_MFWD_CMD_E to decode CMD[4:0]. If CMD[7:5]==2,
+                                                         use OCI_MRSP_CMD_E to decode CMD[4:0]. */
+	uint64_t node                         : 4;  /**< Home node of the address causing the error. Similar the ADDR below, this can be the
+                                                         request address (if INFOLFB is set), else it is the replacement address (if INFOLFB is
+                                                         clear & INFOVAB is set). */
 	uint64_t addr                         : 33; /**< Cache line address causing the error. This can be either the request address or the
-                                                         replacement
-                                                         (if INFOLFB is set), else it is the replacement address (if INFOLFB is clear & INFOVAB is
-                                                         set).
-                                                         This address is a physical address. L2C performs hole removal and index aliasing (if
-                                                         enabled)
-                                                         on the written address and uses that for the command. This hole-removed/index-aliased
-                                                         address
-                                                         is what is returned on a read of L2C_XMC_CMD. */
+                                                         replacement (if INFOLFB is set), else it is the replacement address (if INFOLFB is clear &
+                                                         INFOVAB is set). This address is a physical address. L2C performs hole removal and index
+                                                         aliasing (if enabled) on the written address and uses that for the command. This hole-
+                                                         removed/index-aliased address is what is returned on a read of L2C_XMC_CMD. */
 	uint64_t reserved_0_6                 : 7;
 #else
 	uint64_t reserved_0_6                 : 7;
@@ -7999,16 +8025,16 @@ union cvmx_l2c_tadx_timetwo {
 	struct cvmx_l2c_tadx_timetwo_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_33_63               : 31;
-	uint64_t sid                          : 4;  /**< Source id of the original request, that is 'source' of request. This is only valid if
-                                                         the request is a local request (valid if  L2C_TAD(0..7)_TIMEOUT[CMD] is an  XMC request
-                                                         and not relevant if it is an OCI request). */
+	uint64_t sid                          : 4;  /**< Source id of the original request, that is 'source' of request. This is only valid if the
+                                                         request is a local request (valid if L2C_TAD(0..7)_TIMEOUT[CMD] is an XMC request and not
+                                                         relevant if it is an OCI request). */
 	uint64_t busid                        : 4;  /**< Busid of the original request, that is 'source' of request. */
-	uint64_t vabst                        : 3;  /**< this is the LFB internal state if INFOLFB is set, else will contain VAB internal state if
+	uint64_t vabst                        : 3;  /**< This is the LFB internal state if INFOLFB is set, else will contain VAB internal state if
                                                          INFOVAB is set. */
-	uint64_t lfbst                        : 14; /**< this is the LFB internal state if INFOLFB is set, else will contain VAB internal state if
+	uint64_t lfbst                        : 14; /**< This is the LFB internal state if INFOLFB is set, else will contain VAB internal state if
                                                          INFOVAB is set. */
 	uint64_t tocnt                        : 8;  /**< This is a running count of the LFB that has timed out ... the count will saturate at 0xFF.
-                                                         Will clear when the  LFBTO interrupt is cleared. */
+                                                         Will clear when the LFBTO interrupt is cleared. */
 #else
 	uint64_t tocnt                        : 8;
 	uint64_t lfbst                        : 14;
@@ -8027,7 +8053,7 @@ typedef union cvmx_l2c_tadx_timetwo cvmx_l2c_tadx_timetwo_t;
  *
  * On CN78XX, MAXLFB, EXLRQ, EXRRQ, EXFWD, EXVIC refer to half-TAD LFBs/VABs. Therefore, even
  * though there are 24 LFBs/VABs in a full TAD, the number applies to both halves.
- * * If MAXLFB is written to 0 or 13-15 operation is undefined. (CN78XX pass 1.0)
+ * * If MAXLFB is written to 0 or 13-15 operation is undefined. (CN78XX pass 1.0).
  * * If MAXLFB is != 0, VBF_THRESH should be less than MAXLFB.
  * * If MAXVBF is != 0, VBF_THRESH should be less than MAXVBF.
  * * If MAXLFB != 0, EXLRQ + EXRRQ + EXFWD + EXVIC must be less than or equal to MAXLFB - 3.
@@ -8037,7 +8063,8 @@ union cvmx_l2c_tad_ctl {
 	struct cvmx_l2c_tad_ctl_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t disrstp                      : 1;  /**< When set, if the L2 receives an RSTP XMC command, it treats it as a STP. */
+	uint64_t disrstp                      : 1;  /**< When set, if the L2 receives an RSTP XMC command, it treats it as a STP.
+                                                         INTERNAL: PASS2: DISRSTP should reset to 0, once verif supports it. */
 	uint64_t wtlmcwrdn                    : 1;  /**< Be more conservative with LFB done relative to LMC writes. */
 	uint64_t wtinvdn                      : 1;  /**< Be more conservative with LFB done relative to invalidates. */
 	uint64_t wtfilldn                     : 1;  /**< Be more conservative with LFB done relative to fills. */
@@ -8086,6 +8113,7 @@ union cvmx_l2c_tad_ctl {
 	uint64_t reserved_11_63               : 53;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_tad_ctl_cn70xx        cn70xxp1;
 	struct cvmx_l2c_tad_ctl_s             cn78xx;
 };
 typedef union cvmx_l2c_tad_ctl cvmx_l2c_tad_ctl_t;
@@ -8109,6 +8137,7 @@ union cvmx_l2c_tbfx_bist_status {
 #endif
 	} s;
 	struct cvmx_l2c_tbfx_bist_status_s    cn70xx;
+	struct cvmx_l2c_tbfx_bist_status_s    cn70xxp1;
 	struct cvmx_l2c_tbfx_bist_status_s    cn78xx;
 };
 typedef union cvmx_l2c_tbfx_bist_status cvmx_l2c_tbfx_bist_status_t;
@@ -8128,6 +8157,7 @@ union cvmx_l2c_tdtx_bist_status {
 #endif
 	} s;
 	struct cvmx_l2c_tdtx_bist_status_s    cn70xx;
+	struct cvmx_l2c_tdtx_bist_status_s    cn70xxp1;
 	struct cvmx_l2c_tdtx_bist_status_s    cn78xx;
 };
 typedef union cvmx_l2c_tdtx_bist_status cvmx_l2c_tdtx_bist_status_t;
@@ -8174,6 +8204,7 @@ union cvmx_l2c_tqdx_err {
 #endif
 	} s;
 	struct cvmx_l2c_tqdx_err_s            cn70xx;
+	struct cvmx_l2c_tqdx_err_s            cn70xxp1;
 	struct cvmx_l2c_tqdx_err_s            cn78xx;
 };
 typedef union cvmx_l2c_tqdx_err cvmx_l2c_tqdx_err_t;
@@ -8185,7 +8216,8 @@ union cvmx_l2c_ttgx_bist_status {
 	uint64_t u64;
 	struct cvmx_l2c_ttgx_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_48_63               : 16;
+	uint64_t reserved_50_63               : 14;
+	uint64_t xmdmskfl                     : 2;  /**< BIST failure status for RSTP XMDMSK memories. */
 	uint64_t rtgfl                        : 16; /**< BIST failure status for RTG ways. */
 	uint64_t reserved_18_31               : 14;
 	uint64_t lrulfbfl                     : 1;  /**< Reserved, always zero. */
@@ -8197,10 +8229,28 @@ union cvmx_l2c_ttgx_bist_status {
 	uint64_t lrulfbfl                     : 1;
 	uint64_t reserved_18_31               : 14;
 	uint64_t rtgfl                        : 16;
-	uint64_t reserved_48_63               : 16;
+	uint64_t xmdmskfl                     : 2;
+	uint64_t reserved_50_63               : 14;
 #endif
 	} s;
-	struct cvmx_l2c_ttgx_bist_status_s    cn70xx;
+	struct cvmx_l2c_ttgx_bist_status_cn70xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_48_63               : 16;
+	uint64_t rtgfl                        : 16; /**< Always zero for 70xx. */
+	uint64_t reserved_18_31               : 14;
+	uint64_t lrulfbfl                     : 1;  /**< BIST failure status for LRULFB memory */
+	uint64_t lrufl                        : 1;  /**< BIST failure status for tag LRU */
+	uint64_t tagfl                        : 16; /**< BIST failure status for TAG ways. */
+#else
+	uint64_t tagfl                        : 16;
+	uint64_t lrufl                        : 1;
+	uint64_t lrulfbfl                     : 1;
+	uint64_t reserved_18_31               : 14;
+	uint64_t rtgfl                        : 16;
+	uint64_t reserved_48_63               : 16;
+#endif
+	} cn70xx;
+	struct cvmx_l2c_ttgx_bist_status_cn70xx cn70xxp1;
 	struct cvmx_l2c_ttgx_bist_status_s    cn78xx;
 };
 typedef union cvmx_l2c_ttgx_bist_status cvmx_l2c_ttgx_bist_status_t;
@@ -8257,6 +8307,7 @@ union cvmx_l2c_ttgx_err {
 	uint64_t tagdbe                       : 1;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_ttgx_err_cn70xx       cn70xxp1;
 	struct cvmx_l2c_ttgx_err_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t tagdbe                       : 1;  /**< Information refers to a double-bit TAG ECC error. */
@@ -8657,6 +8708,7 @@ union cvmx_l2c_wpar_iobx {
 	uint64_t reserved_4_63                : 60;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_wpar_iobx_cn70xx      cn70xxp1;
 	struct cvmx_l2c_wpar_iobx_s           cn78xx;
 	struct cvmx_l2c_wpar_iobx_s           cnf71xx;
 };
@@ -8699,6 +8751,7 @@ union cvmx_l2c_wpar_ppx {
 	uint64_t reserved_4_63                : 60;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_wpar_ppx_cn70xx       cn70xxp1;
 	struct cvmx_l2c_wpar_ppx_s            cn78xx;
 	struct cvmx_l2c_wpar_ppx_s            cnf71xx;
 };
@@ -8726,6 +8779,7 @@ union cvmx_l2c_xmcx_pfc {
 	struct cvmx_l2c_xmcx_pfc_s            cn68xx;
 	struct cvmx_l2c_xmcx_pfc_s            cn68xxp1;
 	struct cvmx_l2c_xmcx_pfc_s            cn70xx;
+	struct cvmx_l2c_xmcx_pfc_s            cn70xxp1;
 	struct cvmx_l2c_xmcx_pfc_s            cn78xx;
 	struct cvmx_l2c_xmcx_pfc_s            cnf71xx;
 };
@@ -8823,6 +8877,7 @@ union cvmx_l2c_xmc_cmd {
 	uint64_t inuse                        : 1;
 #endif
 	} cn70xx;
+	struct cvmx_l2c_xmc_cmd_cn70xx        cn70xxp1;
 	struct cvmx_l2c_xmc_cmd_cn70xx        cn78xx;
 	struct cvmx_l2c_xmc_cmd_cn61xx        cnf71xx;
 };
@@ -8850,6 +8905,7 @@ union cvmx_l2c_xmdx_pfc {
 	struct cvmx_l2c_xmdx_pfc_s            cn68xx;
 	struct cvmx_l2c_xmdx_pfc_s            cn68xxp1;
 	struct cvmx_l2c_xmdx_pfc_s            cn70xx;
+	struct cvmx_l2c_xmdx_pfc_s            cn70xxp1;
 	struct cvmx_l2c_xmdx_pfc_s            cn78xx;
 	struct cvmx_l2c_xmdx_pfc_s            cnf71xx;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-l2d-defs.h b/arch/mips/include/asm/octeon/cvmx-l2d-defs.h
index 73d4f1c..b3126cd 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2d-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2d-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-l2t-defs.h b/arch/mips/include/asm/octeon/cvmx-l2t-defs.h
index 21dea30..8aaa3df 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2t-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2t-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-lapx-defs.h b/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
index cbcc374..27f0052 100644
--- a/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lapx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -660,6 +660,9 @@ typedef union cvmx_lapx_lab_datax cvmx_lapx_lab_datax_t;
 
 /**
  * cvmx_lap#_lab_err_st
+ *
+ * This register is for diagnostic use only.
+ *
  */
 union cvmx_lapx_lab_err_st {
 	uint64_t u64;
@@ -668,7 +671,7 @@ union cvmx_lapx_lab_err_st {
 	uint64_t reserved_26_63               : 38;
 	uint64_t fsyn                         : 10; /**< Syndrome of last LAB data ram ECC error. Latched when LAP(0..1)_GEN_INT[LAB_SBE] or [LAB_DBE] set */
 	uint64_t reserved_10_15               : 6;
-	uint64_t fadr                         : 10; /**< Address of last LAB data ram ECC error. Latched when LAP(0..1)_GEN_INT[LAB_SBE] or [LAB_DBE] set. */
+	uint64_t fadr                         : 10; /**< Reserved. */
 #else
 	uint64_t fadr                         : 10;
 	uint64_t reserved_10_15               : 6;
@@ -893,13 +896,13 @@ union cvmx_lapx_xid_pos {
                                                          the non-application specific fields in the Interlaken LA header. See Transaction ID
                                                          Packing. */
 	uint64_t reserved_26_31               : 6;
-	uint64_t rtn_wd                       : 4;  /**< Extract transaction tag from this 64 bit word number of the return packet; typically the
+	uint64_t rtn_wd                       : 4;  /**< Extract transaction tag from this 64-bit word number of the return packet; typically the
                                                          same value as [REQ_WD]. Word 0 is the Interlaken control word, word 1 is the first word of
                                                          payload. */
 	uint64_t rtn_lsb                      : 6;  /**< Extract transaction tag value's LSB into this LSB of the of request packet; typically the
                                                          same value as [REQ_LSB]. */
 	uint64_t reserved_10_15               : 6;
-	uint64_t req_wd                       : 4;  /**< Insert transaction tag into this 64 bit word number of the request packet. Word 0 is the
+	uint64_t req_wd                       : 4;  /**< Insert transaction tag into this 64-bit word number of the request packet. Word 0 is the
                                                          Interlaken control word, word 1 is the first word of payload. */
 	uint64_t req_lsb                      : 6;  /**< Insert transaction tag value's LSB into this LSB of the of request packet. */
 #else
diff --git a/arch/mips/include/asm/octeon/cvmx-lbk-defs.h b/arch/mips/include/asm/octeon/cvmx-lbk-defs.h
index 7f82745..0114201 100644
--- a/arch/mips/include/asm/octeon/cvmx-lbk-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lbk-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-led-defs.h b/arch/mips/include/asm/octeon/cvmx-led-defs.h
index f9b8a17..c2c178f 100644
--- a/arch/mips/include/asm/octeon/cvmx-led-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-led-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
index 4e0e93b..d09bd07 100644
--- a/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-lmcx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -618,11 +618,11 @@ static inline uint64_t CVMX_LMCX_ECC_SYND(unsigned long block_id)
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -649,11 +649,11 @@ static inline uint64_t CVMX_LMCX_ECC_SYND(unsigned long block_id)
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180088000038ull) + (block_id) * 0x60000000ull;
@@ -686,11 +686,11 @@ static inline uint64_t CVMX_LMCX_FADR(unsigned long block_id)
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			if ((block_id == 0))
@@ -717,11 +717,11 @@ static inline uint64_t CVMX_LMCX_FADR(unsigned long block_id)
 		case OCTEON_CN50XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN38XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN31XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN70XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN52XX & OCTEON_FAMILY_MASK:
-		case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
+		case OCTEON_CN58XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
 		case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
 			return CVMX_ADD_IO_SEG(0x0001180088000020ull) + (block_id) * 0x60000000ull;
@@ -1659,6 +1659,7 @@ union cvmx_lmcx_bist_ctl {
 	uint64_t reserved_4_63                : 60;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_bist_ctl_cn70xx      cn70xxp1;
 	struct cvmx_lmcx_bist_ctl_cn70xx      cn78xx;
 };
 typedef union cvmx_lmcx_bist_ctl cvmx_lmcx_bist_ctl_t;
@@ -1800,6 +1801,7 @@ union cvmx_lmcx_char_ctl {
 	struct cvmx_lmcx_char_ctl_cn61xx      cn68xx;
 	struct cvmx_lmcx_char_ctl_cn63xx      cn68xxp1;
 	struct cvmx_lmcx_char_ctl_s           cn70xx;
+	struct cvmx_lmcx_char_ctl_s           cn70xxp1;
 	struct cvmx_lmcx_char_ctl_s           cn78xx;
 	struct cvmx_lmcx_char_ctl_cn61xx      cnf71xx;
 };
@@ -1823,6 +1825,7 @@ union cvmx_lmcx_char_dq_err_count {
 #endif
 	} s;
 	struct cvmx_lmcx_char_dq_err_count_s  cn70xx;
+	struct cvmx_lmcx_char_dq_err_count_s  cn70xxp1;
 	struct cvmx_lmcx_char_dq_err_count_s  cn78xx;
 };
 typedef union cvmx_lmcx_char_dq_err_count cvmx_lmcx_char_dq_err_count_t;
@@ -1849,6 +1852,7 @@ union cvmx_lmcx_char_mask0 {
 	struct cvmx_lmcx_char_mask0_s         cn68xx;
 	struct cvmx_lmcx_char_mask0_s         cn68xxp1;
 	struct cvmx_lmcx_char_mask0_s         cn70xx;
+	struct cvmx_lmcx_char_mask0_s         cn70xxp1;
 	struct cvmx_lmcx_char_mask0_s         cn78xx;
 	struct cvmx_lmcx_char_mask0_s         cnf71xx;
 };
@@ -1878,6 +1882,7 @@ union cvmx_lmcx_char_mask1 {
 	struct cvmx_lmcx_char_mask1_s         cn68xx;
 	struct cvmx_lmcx_char_mask1_s         cn68xxp1;
 	struct cvmx_lmcx_char_mask1_s         cn70xx;
+	struct cvmx_lmcx_char_mask1_s         cn70xxp1;
 	struct cvmx_lmcx_char_mask1_s         cn78xx;
 	struct cvmx_lmcx_char_mask1_s         cnf71xx;
 };
@@ -1905,6 +1910,7 @@ union cvmx_lmcx_char_mask2 {
 	struct cvmx_lmcx_char_mask2_s         cn68xx;
 	struct cvmx_lmcx_char_mask2_s         cn68xxp1;
 	struct cvmx_lmcx_char_mask2_s         cn70xx;
+	struct cvmx_lmcx_char_mask2_s         cn70xxp1;
 	struct cvmx_lmcx_char_mask2_s         cn78xx;
 	struct cvmx_lmcx_char_mask2_s         cnf71xx;
 };
@@ -1934,6 +1940,7 @@ union cvmx_lmcx_char_mask3 {
 	struct cvmx_lmcx_char_mask3_s         cn68xx;
 	struct cvmx_lmcx_char_mask3_s         cn68xxp1;
 	struct cvmx_lmcx_char_mask3_s         cn70xx;
+	struct cvmx_lmcx_char_mask3_s         cn70xxp1;
 	struct cvmx_lmcx_char_mask3_s         cn78xx;
 	struct cvmx_lmcx_char_mask3_s         cnf71xx;
 };
@@ -2067,6 +2074,7 @@ union cvmx_lmcx_char_mask4 {
 	uint64_t reserved_45_63               : 19;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_char_mask4_cn70xx    cn70xxp1;
 	struct cvmx_lmcx_char_mask4_s         cn78xx;
 	struct cvmx_lmcx_char_mask4_cn61xx    cnf71xx;
 };
@@ -2186,7 +2194,8 @@ union cvmx_lmcx_comp_ctl2 {
 	uint64_t reserved_51_63               : 13;
 	uint64_t rclk_char_mode               : 1;  /**< Reserved. INTERNAL: Select RCLK characterization mode. */
 	uint64_t reserved_40_49               : 10;
-	uint64_t ptune_offset                 : 4;  /**< Ptune offset value. */
+	uint64_t ptune_offset                 : 4;  /**< Ptune offset value. This is a signed value where the MSB is a sign bit, with zero
+                                                         indicating addition and one indicating subtraction. */
 	uint64_t reserved_12_35               : 24;
 	uint64_t cmd_ctl                      : 4;  /**< Drive strength control for CMD/A/RESET_L drivers
                                                          0001 = 24 ohm
@@ -2305,11 +2314,13 @@ union cvmx_lmcx_comp_ctl2 {
                                                          compensation impedance on P-pullup. */
 	uint64_t ddr__ntune                   : 5;  /**< DDR NCTL from compensation circuit. The encoded value provides debug information for the
                                                          compensation impedance on N-pulldown. */
-	uint64_t ptune_offset                 : 4;  /**< Ptune offset value. */
-	uint64_t ntune_offset                 : 4;  /**< Ntune offset value. */
+	uint64_t ptune_offset                 : 4;  /**< Ptune offset value. This is a signed value where the MSB is a sign bit, with zero
+                                                         indicating addition and one indicating subtraction. */
+	uint64_t ntune_offset                 : 4;  /**< Ntune offset value. This is a signed value where the MSB is a sign bit, with zero
+                                                         indicating addition and one indicating subtraction. */
 	uint64_t m180                         : 1;  /**< Reserved; must be zero. INTERNAL: Cap impedance at 180 ohm, instead of 240 ohm. */
 	uint64_t byp                          : 1;  /**< Bypass mode. When set, PTUNE,NTUNE are the compensation setting. When clear,
-                                                         DDR_PTUNE,DDR_NTUNE are the compensation setting. */
+                                                         DDR__PTUNE,DDR__NTUNE are the compensation setting. */
 	uint64_t ptune                        : 5;  /**< PCTL impedance control in bypass mode. */
 	uint64_t ntune                        : 5;  /**< NCTL impedance control in bypass mode. */
 	uint64_t rodt_ctl                     : 4;  /**< RODT NCTL impedance control bits. This field controls ODT values during a memory read.
@@ -2347,7 +2358,7 @@ union cvmx_lmcx_comp_ctl2 {
                                                          0x2 = 26 ohm. 0x6 = 48 ohm.
                                                          0x3 = 30 ohm. 0x7 = 68 ohm.
                                                          0x8-0xF = Reserved. */
-	uint64_t ck_ctl                       : 4;  /**< "Drive strength control for DDR_CK_*_P/DDR_DIMM*_CS*_L/DDR_DIMM*_ODT_* /DDR#_DIMM*_CKE*
+	uint64_t ck_ctl                       : 4;  /**< "Drive strength control for DDR_CK_*_P/DDRCS*_L/DDR_ODT_* /DDR_CKE*
                                                          drivers.
                                                          In DDR3 mode:
                                                          0x1 = 24 ohm. 0x5 = 40 ohm.
@@ -2383,6 +2394,7 @@ union cvmx_lmcx_comp_ctl2 {
 	uint64_t reserved_51_63               : 13;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_comp_ctl2_cn70xx     cn70xxp1;
 	struct cvmx_lmcx_comp_ctl2_cn70xx     cn78xx;
 	struct cvmx_lmcx_comp_ctl2_cn61xx     cnf71xx;
 };
@@ -2400,34 +2412,6 @@ typedef union cvmx_lmcx_comp_ctl2 cvmx_lmcx_comp_ctl2_t;
  * * Prior to the self-refresh exit sequence, LMC(0..3)_MODEREG_PARAMS0 should be reprogrammed
  * (if needed) to the appropriate values.
  * See LMC Initialization Sequence for the LMC bring-up sequence.
- * LMC Initialization Sequence:
- * 1. SW must ensure there are no pending DRAM transactions and that the DDR PLL and the DLL have
- * been initialized.
- * 2. Write LMC*_COMP_CTL2, LMC*_CONTROL, LMC*_WODT_MASK, LMC*_DUAL_MEMCFG, LMC*_TIMING_PARAMS0,
- * LMC*_TIMING_PARAMS1, LMC*_MODEREG_PARAMS0, LMC*_MODEREG_PARAMS1, LMC*_RESET_CTL (with
- * DDR3RST=0), LMC*_CONFIG with appropriate values, if necessary.
- * 3. Wait 200us, then write LMC*_RESET_CTL[DDR3RST] = 1.
- * 4. Initialize all ranks at once by writing LMC*_CONFIG[RANKMASK][n] = 1,
- * LMC*_SEQ_CTL[SEQ_SEL]= 6, LMC*_SEQ_CTL[INIT_START] = 1, where n is a valid rank index for the
- * specific board configuration.
- * 5. for each rank n to be write-leveled [
- * if auto write-leveling is desired [
- * write LMC*_CONFIG[RANKMASK][n] = 1, LMC*_WLEVEL_CTL appropriately, LMC*_SEQ_CTL[SEQ_SEL]=6,
- * and LMC*_CONFIG[INIT_START]= 1
- * wait until LMC*_WLEVEL_RANKn[STATUS] = 3
- * ] else [
- * write LMC*_WLEVEL_RANKn with appropriate values
- * ]
- * ]
- * 6. for each rank n to be read-leveled [
- * if auto read-leveling is desired [
- * write LMC*_CONFIG[RANKMASK][n] = 1, LMC*_RLEVEL_CTL appropriately, LMC*_SEQ_CTL[SEQ_SEL] = 1,
- * and LMC*_CONFIG[INIT_START] = 1
- * wait until LMC*_RLEVEL_RANKn[STATUS] = 3
- * ] else [
- * write LMC*_RLEVEL_RANKn with appropriate values
- * ]
- * ]
  */
 union cvmx_lmcx_config {
 	uint64_t u64;
@@ -3597,24 +3581,28 @@ union cvmx_lmcx_config {
 	uint64_t reserved_63_63               : 1;
 	uint64_t bg2_enable                   : 1;  /**< BG2 pin is active for DDR4 mode. Only has an effect when LMC(0..0)_CONFIG[MODEDDR4] = 1.
                                                          Typically only cleared for DDR4 *16 devices, where there is no BG2 pin on the device. */
-	uint64_t mode_x4dev                   : 1;  /**< Always reads as 0 for 70xx devices, there is no x4 device support. */
-	uint64_t mode32b                      : 1;  /**< Always reads as 1 for 70xx devices, only 32b mode is supported. */
+	uint64_t mode_x4dev                   : 1;  /**< Always reads as 0 for CN70XX devices, there is no x4 device support. */
+	uint64_t mode32b                      : 1;  /**< Always reads as 1 for CN70XX devices, only 32b mode is supported. */
 	uint64_t scrz                         : 1;  /**< Hide LMC(0..0)_SCRAMBLE_CFG0 and LMC(0..0)_SCRAMBLE_CFG1 when set. */
-	uint64_t early_unload_d1_r1           : 1;  /**< When set, unload the PHY silo one cycle early for Rank 3 reads.
-                                                         The recommended EARLY_UNLOAD_D1_R1 value is 0. */
-	uint64_t early_unload_d1_r0           : 1;  /**< When set, unload the PHY silo one cycle early for Rank 2 reads.
-                                                         The recommended EARLY_UNLOAD_D1_RO value is 0. */
-	uint64_t early_unload_d0_r1           : 1;  /**< When set, unload the PHY silo one cycle early for Rank 1 reads.
-                                                         The recommended EARLY_UNLOAD_D0_R1 value is 0. */
-	uint64_t early_unload_d0_r0           : 1;  /**< When set, unload the PHY silo one cycle early for Rank 0 reads.
-                                                         The recommended EARLY_UNLOAD_D0_R0 value is 0. */
+	uint64_t early_unload_d1_r1           : 1;  /**< Reserved, MBZ.  INTERNAL:  When set, unload the PHY silo one cycle early for
+                                                         Rank 3 reads. The recommended EARLY_UNLOAD_D1_R1 value is 0.  Not used in
+                                                         CN70XX/CN71XX. */
+	uint64_t early_unload_d1_r0           : 1;  /**< Reserved, MBZ.  INTERNAL:  When set, unload the PHY silo one cycle early for
+                                                         Rank 2 reads.  The recommended EARLY_UNLOAD_D1_RO value is 0.  Not used in
+                                                         CN70XX/CN71XX. */
+	uint64_t early_unload_d0_r1           : 1;  /**< Reserved, MBZ.  INTERNAL:  When set, unload the PHY silo one cycle early for
+                                                         Rank 1 reads.  The recommended EARLY_UNLOAD_D0_R1 value is 0. */
+	uint64_t early_unload_d0_r0           : 1;  /**< Reserved, MBZ.  INTERNAL:  When set, unload the PHY silo one cycle early for
+                                                         Rank 0 reads.  The recommended EARLY_UNLOAD_D0_R0 value is 0. */
 	uint64_t init_status                  : 4;  /**< Indicates status of initialization. INIT_STATUS[n] = 1 implies rank n has been
                                                          initialized.
                                                          Software must set necessary RANKMASK bits before executing the initialization sequence
                                                          using LMC(0..0)_SEQ_CTL. If the rank has been selected for init with the RANKMASK bits,
                                                          the INIT_STATUS bits will be set after successful initialization and after self-refresh
                                                          exit. INIT_STATUS determines the chip-selects that assert during refresh, ZQCS, precharge
-                                                         power-down entry/exit, and self-refresh entry SEQ_SEL's. */
+                                                         power-down entry/exit, and self-refresh entry SEQ_SEL's.  For CN70XX/CN71XX, only bits
+                                                         <1:0>
+                                                         corresponding to 2 ranks should ever be set. */
 	uint64_t mirrmask                     : 4;  /**< "Mask determining which ranks are address-mirrored.
                                                          MIRRMASK<n> = 1 means Rank n addresses are mirrored for
                                                          0 <= n <= 3.
@@ -3623,7 +3611,7 @@ union cvmx_lmcx_config {
                                                          DDR#_A<8> is swapped with DDR#_A<7>;
                                                          DDR#_A<6> is swapped with DDR#_A<5>;
                                                          DDR#_A<4> is swapped with DDR#_A<3>.
-                                                         For 70xx, MIRRMASK<3:2> MBZ.
+                                                         For CN70XX/CN71XX, MIRRMASK<3:2> MBZ.
                                                          When RANK_ENA = 0, MIRRMASK<1> MBZ."
                                                          INTERNAL:
                                                          In DDR4, a mirrored read/write operation has the following differences:
@@ -3633,7 +3621,7 @@ union cvmx_lmcx_config {
                                                          DDR#_A<8> is swapped with DDR#_A<7>;
                                                          DDR#_A<6> is swapped with DDR#_A<5>;
                                                          DDR#_A<4> is swapped with DDR#_A<3>.
-                                                         For 70xx, MIRRMASK<3:2> MBZ.
+                                                         For CN70XX, MIRRMASK<3:2> MBZ.
                                                          When RANK_ENA = 0, MIRRMASK<1> MBZ." */
 	uint64_t rankmask                     : 4;  /**< Mask to select rank to be leveled/initialized. To write-level/read-level/initialize rank
                                                          i, set RANKMASK< i>
@@ -3644,12 +3632,13 @@ union cvmx_lmcx_config {
                                                          RANKMASK<3> = MBZ          MBZ
                                                          For read/write leveling, each rank has to be leveled separately, so RANKMASK should only
                                                          have one bit set. RANKMASK is not used during self-refresh entry/exit and precharge power-
-                                                         down entry/exit instruction sequences. For 70xx, RANKMASK<3:2> MBZ.  When RANK_ENA = 0,
+                                                         down entry/exit instruction sequences. For CN70XX/CN71XX, RANKMASK<3:2> MBZ.  When
+                                                         RANK_ENA = 0,
                                                          RANKMASK<1> MBZ. */
 	uint64_t rank_ena                     : 1;  /**< "RANK enable (for use with dual-rank DIMMs).
-                                                         For dual-rank DIMMs, the RANK_ENA bit will enable the drive of the DDR#_DIMM*_CS*_L and
+                                                         * For dual-rank DIMMs, the RANK_ENA bit will enable the drive of the DDR_CS*_L and
                                                          ODT_<1:0> pins differently based on the (PBANK_LSB - 1) address bit.
-                                                         Write 0 for SINGLE ranked DIMMs." */
+                                                         * Write 0 for SINGLE ranked DIMMs." */
 	uint64_t sref_with_dll                : 1;  /**< Self-refresh entry/exit write mode registers. When set, self-refresh entry sequence writes
                                                          MR2 and MR1 (in this order, in all ranks), and self-refresh exit sequence writes MR1, MR0,
                                                          MR2, and MR3 (in this order, for all ranks). The write operations occur before self-
@@ -3709,11 +3698,12 @@ union cvmx_lmcx_config {
                                                          ROW address. The processor's memory address<34:7> needs to be translated to DRAM addresses
                                                          (bnk,row,col,rank and DIMM) and that is a function of the following:
                                                          Datapath width (32)
-                                                         \# banks (8)
-                                                         \# column bits of the memory part--specified indirectly by this register.
-                                                         \# row bits of the memory part--specified indirectly by PBANK_LSB
-                                                         \# ranks in a DIMM--specified by RANK_ENA
-                                                         \# DIMMs in the system by the register below (PBANK_LSB).
+                                                         * Datapath width (64).
+                                                         * Number of banks (8).
+                                                         * Number of  column bits of the memory part--specified indirectly by this register.
+                                                         * Number of row bits of the memory part--specified indirectly by PBANK_LSB.
+                                                         * Number of ranks in a DIMM--specified by RANK_ENA.
+                                                         * Number of DIMMs in the system by the register below (PBANK_LSB).
                                                          Col Address starts from mem_addr[2] for 32b (4Bytes) DQ width. ROW_LSB is mem_adr[14] for
                                                          32b mode. Therefore, the ROW_LSB parameter should be set to 000 (32b).
                                                          Decoding for row_lsb:
@@ -3729,11 +3719,11 @@ union cvmx_lmcx_config {
                                                          Refer to Cache-block Read Transaction Example." */
 	uint64_t ecc_ena                      : 1;  /**< ECC enable. When set, enables the 8b ECC check/correct logic. Should be 1 when used with
                                                          DIMMs with ECC; 0, otherwise.
-                                                         When this mode is turned on, DQ<71:64> on write operations contains the ECC code generated
+                                                         When this mode is turned on, DQ<35:32> on write operations contains the ECC code generated
                                                          for the 64 bits of data which will be written in the memory. Later on read operations,
                                                          will be used to check for single-bit error (which will be auto-corrected) and double-bit
                                                          error (which will be reported).
-                                                         When not turned on, DQ<71:64> are driven to 0. Please refer to SEC_ERR, DED_ERR,
+                                                         When not turned on, DQ<35:32> are driven to 0. Please refer to SEC_ERR, DED_ERR,
                                                          LMC(0..0)_FADR, and LMC(0..0)_ECC_SYND registers for diagnostics information when there is
                                                          an error. */
 	uint64_t reserved_0_0                 : 1;
@@ -3764,6 +3754,7 @@ union cvmx_lmcx_config {
 	uint64_t reserved_63_63               : 1;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_config_cn70xx        cn70xxp1;
 	struct cvmx_lmcx_config_cn70xx        cn78xx;
 	struct cvmx_lmcx_config_cn61xx        cnf71xx;
 };
@@ -4175,6 +4166,7 @@ union cvmx_lmcx_control {
 	} cn68xx;
 	struct cvmx_lmcx_control_cn68xx       cn68xxp1;
 	struct cvmx_lmcx_control_s            cn70xx;
+	struct cvmx_lmcx_control_s            cn70xxp1;
 	struct cvmx_lmcx_control_s            cn78xx;
 	struct cvmx_lmcx_control_cn66xx       cnf71xx;
 };
@@ -5050,6 +5042,7 @@ union cvmx_lmcx_dclk_cnt {
 	struct cvmx_lmcx_dclk_cnt_s           cn68xx;
 	struct cvmx_lmcx_dclk_cnt_s           cn68xxp1;
 	struct cvmx_lmcx_dclk_cnt_s           cn70xx;
+	struct cvmx_lmcx_dclk_cnt_s           cn70xxp1;
 	struct cvmx_lmcx_dclk_cnt_s           cn78xx;
 	struct cvmx_lmcx_dclk_cnt_s           cnf71xx;
 };
@@ -5423,6 +5416,7 @@ union cvmx_lmcx_ddr4_dimm_ctl {
 #endif
 	} s;
 	struct cvmx_lmcx_ddr4_dimm_ctl_s      cn70xx;
+	struct cvmx_lmcx_ddr4_dimm_ctl_s      cn70xxp1;
 	struct cvmx_lmcx_ddr4_dimm_ctl_s      cn78xx;
 };
 typedef union cvmx_lmcx_ddr4_dimm_ctl cvmx_lmcx_ddr4_dimm_ctl_t;
@@ -5549,7 +5543,7 @@ union cvmx_lmcx_ddr_pll_ctl {
 	struct cvmx_lmcx_ddr_pll_ctl_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_31_63               : 33;
-	uint64_t phy_dcok                     : 1;  /**< Set to power up PHY logic after setting LMC#_DDR_PLL_CTL[DDR4_MODE]. */
+	uint64_t phy_dcok                     : 1;  /**< Set to power up PHY logic after setting LMC(0..0)_DDR_PLL_CTL[DDR4_MODE]. */
 	uint64_t ddr4_mode                    : 1;  /**< DDR4 mode select (0 for DDR3). */
 	uint64_t pll_fbslip                   : 1;  /**< PLL FBSLIP indication. */
 	uint64_t pll_lock                     : 1;  /**< PLL LOCK indication. */
@@ -5564,22 +5558,17 @@ union cvmx_lmcx_ddr_pll_ctl {
                                                          jtg_test_mode) by about 160 microseconds to ensure that lock is achieved. */
 	uint64_t ddr_div_reset                : 1;  /**< DDR postscalar divider reset. */
 	uint64_t ddr_ps_en                    : 4;  /**< DDR postscalar divide ratio. Determines the LMC CK speed.
-                                                         0x0 = divide LMC PLL by 1.
-                                                         0x1 = divide LMC PLL by 2.
-                                                         0x2 = divide LMC PLL by 3.
-                                                         0x3 = divide LMC PLL by 4.
-                                                         0x4 = divide LMC PLL by 5.
-                                                         0x5 = divide LMC PLL by 6.
-                                                         0x6 = divide LMC PLL by 7.
-                                                         0x7 = divide LMC PLL by 8.
-                                                         0x8 = divide LMC PLL by 10
-                                                         0x9 = divide LMC PLL by 12.
-                                                         0xa = RSVD
-                                                         0xb = RSVD
-                                                         0xc = RSVD
-                                                         0xd = RSVD
-                                                         0xe = RSVD
-                                                         0xf = RSVD
+                                                         0x0 = Divide LMC PLL by 1.
+                                                         0x1 = Divide LMC PLL by 2.
+                                                         0x2 = Divide LMC PLL by 3.
+                                                         0x3 = Divide LMC PLL by 4.
+                                                         0x4 = Divide LMC PLL by 5.
+                                                         0x5 = Divide LMC PLL by 6.
+                                                         0x6 = Divide LMC PLL by 7.
+                                                         0x7 = Divide LMC PLL by 8.
+                                                         0x8 = Divide LMC PLL by 10.
+                                                         0x9 = Divide LMC PLL by 12.
+                                                         0xA-0xF = Reserved.
                                                          DDR_PS_EN is not used when DDR_DIV_RESET = 1 */
 	uint64_t reserved_8_17                : 10;
 	uint64_t reset_n                      : 1;  /**< PLL reset */
@@ -5601,6 +5590,7 @@ union cvmx_lmcx_ddr_pll_ctl {
 	uint64_t reserved_31_63               : 33;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_ddr_pll_ctl_cn70xx   cn70xxp1;
 	struct cvmx_lmcx_ddr_pll_ctl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_44_63               : 20;
@@ -5761,6 +5751,7 @@ union cvmx_lmcx_dimmx_ddr4_params0 {
 #endif
 	} s;
 	struct cvmx_lmcx_dimmx_ddr4_params0_s cn70xx;
+	struct cvmx_lmcx_dimmx_ddr4_params0_s cn70xxp1;
 	struct cvmx_lmcx_dimmx_ddr4_params0_s cn78xx;
 };
 typedef union cvmx_lmcx_dimmx_ddr4_params0 cvmx_lmcx_dimmx_ddr4_params0_t;
@@ -5787,6 +5778,7 @@ union cvmx_lmcx_dimmx_ddr4_params1 {
 #endif
 	} s;
 	struct cvmx_lmcx_dimmx_ddr4_params1_s cn70xx;
+	struct cvmx_lmcx_dimmx_ddr4_params1_s cn70xxp1;
 	struct cvmx_lmcx_dimmx_ddr4_params1_s cn78xx;
 };
 typedef union cvmx_lmcx_dimmx_ddr4_params1 cvmx_lmcx_dimmx_ddr4_params1_t;
@@ -5847,6 +5839,7 @@ union cvmx_lmcx_dimmx_params {
 	struct cvmx_lmcx_dimmx_params_s       cn68xx;
 	struct cvmx_lmcx_dimmx_params_s       cn68xxp1;
 	struct cvmx_lmcx_dimmx_params_s       cn70xx;
+	struct cvmx_lmcx_dimmx_params_s       cn70xxp1;
 	struct cvmx_lmcx_dimmx_params_s       cn78xx;
 	struct cvmx_lmcx_dimmx_params_s       cnf71xx;
 };
@@ -5903,6 +5896,7 @@ union cvmx_lmcx_dimm_ctl {
 	struct cvmx_lmcx_dimm_ctl_s           cn68xx;
 	struct cvmx_lmcx_dimm_ctl_s           cn68xxp1;
 	struct cvmx_lmcx_dimm_ctl_s           cn70xx;
+	struct cvmx_lmcx_dimm_ctl_s           cn70xxp1;
 	struct cvmx_lmcx_dimm_ctl_s           cn78xx;
 	struct cvmx_lmcx_dimm_ctl_s           cnf71xx;
 };
@@ -6038,19 +6032,19 @@ union cvmx_lmcx_dll_ctl2 {
                                                          (DRESET -OR- core-clock reset). */
 	uint64_t quad_dll_ena                 : 1;  /**< DLL enable. */
 	uint64_t byp_sel                      : 4;  /**< Reserved; must be zero. INTERNAL: Bypass select.
-                                                         0000 = no byte.
-                                                         0001 = byte 0.
+                                                         0x0 = no byte.
+                                                         0x1 = byte 0.
                                                          - ...
-                                                         1001 = byte 8.
-                                                         1010 = all bytes.
-                                                         1011-1111 = Reserved. */
+                                                         0x9 = byte 8.
+                                                         0xA = all bytes.
+                                                         0xB-0xF = Reserved. */
 	uint64_t byp_setting                  : 9;  /**< Reserved; must be zero. INTERNAL: Bypass setting.
-                                                         DDR3-1600: 00100010.
-                                                         DDR3-1333: 00110010.
-                                                         DDR3-1066: 01001011.
-                                                         DDR3-800  : 01110101.
-                                                         DDR3-667  : 10010110.
-                                                         DDR3-600  : 10101100. */
+                                                         DDR3-1600: 0x22.
+                                                         DDR3-1333: 0x32.
+                                                         DDR3-1066: 0x4B.
+                                                         DDR3-800  : 0x75.
+                                                         DDR3-667  : 0x96.
+                                                         DDR3-600  : 0xAC. */
 #else
 	uint64_t byp_setting                  : 9;
 	uint64_t byp_sel                      : 4;
@@ -6061,6 +6055,7 @@ union cvmx_lmcx_dll_ctl2 {
 	uint64_t reserved_17_63               : 47;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_dll_ctl2_cn70xx      cn70xxp1;
 	struct cvmx_lmcx_dll_ctl2_cn70xx      cn78xx;
 	struct cvmx_lmcx_dll_ctl2_cn61xx      cnf71xx;
 };
@@ -6261,6 +6256,7 @@ union cvmx_lmcx_dll_ctl3 {
 	uint64_t reserved_44_63               : 20;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_dll_ctl3_cn70xx      cn70xxp1;
 	struct cvmx_lmcx_dll_ctl3_cn70xx      cn78xx;
 	struct cvmx_lmcx_dll_ctl3_cn61xx      cnf71xx;
 };
@@ -6356,6 +6352,7 @@ union cvmx_lmcx_dual_memcfg {
 	uint64_t reserved_19_63               : 45;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_dual_memcfg_cn70xx   cn70xxp1;
 	struct cvmx_lmcx_dual_memcfg_cn70xx   cn78xx;
 	struct cvmx_lmcx_dual_memcfg_cn61xx   cnf71xx;
 };
@@ -6453,6 +6450,7 @@ union cvmx_lmcx_ecc_synd {
 	struct cvmx_lmcx_ecc_synd_s           cn68xx;
 	struct cvmx_lmcx_ecc_synd_s           cn68xxp1;
 	struct cvmx_lmcx_ecc_synd_s           cn70xx;
+	struct cvmx_lmcx_ecc_synd_s           cn70xxp1;
 	struct cvmx_lmcx_ecc_synd_s           cn78xx;
 	struct cvmx_lmcx_ecc_synd_s           cnf71xx;
 };
@@ -6565,21 +6563,21 @@ union cvmx_lmcx_ext_config {
 	struct cvmx_lmcx_ext_config_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_21_63               : 43;
-	uint64_t vrefint_seq_deskew           : 1;  /**< Personality bit to change the operation of what is normally the internal
-                                                         vref training sequence into the deskew training sequence. */
+	uint64_t vrefint_seq_deskew           : 1;  /**< Personality bit to change the operation of what is normally the internal Vref training
+                                                         sequence into the deskew training sequence. */
 	uint64_t read_ena_bprch               : 1;  /**< Enable pad receiver one cycle longer than normal during read operations. */
 	uint64_t read_ena_fprch               : 1;  /**< Enable pad receiver starting one cycle earlier than normal during read operations. */
 	uint64_t slot_ctl_reset_force         : 1;  /**< Write 1 to reset the slot-control override for all slot-control registers. After writing a
                                                          1 to this bit, slot-control registers will update with changes made to other timing-
                                                          control registers. This is a one-shot operation; it automatically returns to 0 after a
                                                          write to 1. */
-	uint64_t ref_int_lsbs                 : 9;  /**< These are the 9 LSBs for the refresh interval value, default to 0, but can be set to
-                                                         a non-zero value to get a more precise refresh interval. */
+	uint64_t ref_int_lsbs                 : 9;  /**< Refresh-interval value least-significant bits. The default is 0x0; but it can be set to a
+                                                         non-zero value to get a more precise refresh interval. */
 	uint64_t drive_ena_bprch              : 1;  /**< Drive DQx for one cycle longer than normal during write operations. */
 	uint64_t drive_ena_fprch              : 1;  /**< Drive DQX starting one cycle earlier than normal during write operations. */
 	uint64_t dlcram_flip_synd             : 2;  /**< Reserved. INTERNAL: DLC RAM flip syndrome control bits. */
 	uint64_t dlcram_cor_dis               : 1;  /**< Reserved. INTERNAL: DLC RAM correction disable control. */
-	uint64_t dlc_nxm_rd                   : 1;  /**< When set, enable NXM events for DLC reads.  Default is disabled, but
+	uint64_t dlc_nxm_rd                   : 1;  /**< When set, enable NXM events for HFA read operations. INTERNAL: Default is disabled, but
                                                          could be useful for debug of DLC/DFA accesses. */
 	uint64_t l2c_nxm_rd                   : 1;  /**< When set, enable NXM events for L2C read operations. INTERNAL: Default is disabled as L2C
                                                          NXM read operations are possible and expected during normal operation. */
@@ -6600,6 +6598,7 @@ union cvmx_lmcx_ext_config {
 	uint64_t reserved_21_63               : 43;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_ext_config_cn70xx    cn70xxp1;
 	struct cvmx_lmcx_ext_config_s         cn78xx;
 };
 typedef union cvmx_lmcx_ext_config cvmx_lmcx_ext_config_t;
@@ -6693,7 +6692,8 @@ union cvmx_lmcx_fadr {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_40_63               : 24;
 	uint64_t fill_order                   : 2;  /**< Fill order for failing transaction. */
-	uint64_t fdimm                        : 1;  /**< Failing DIMM number. */
+	uint64_t fdimm                        : 1;  /**< Failing DIMM number. CN70XX/CN71XX only supports one DIMM, so this bit will always
+                                                         return a 0. */
 	uint64_t fbunk                        : 1;  /**< Failing rank number. */
 	uint64_t fbank                        : 4;  /**< Failing bank number. Bits <3:0>. */
 	uint64_t frow                         : 18; /**< Failing row address. Bits <17:0>. */
@@ -6710,6 +6710,7 @@ union cvmx_lmcx_fadr {
 	uint64_t reserved_40_63               : 24;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_fadr_cn70xx          cn70xxp1;
 	struct cvmx_lmcx_fadr_cn70xx          cn78xx;
 	struct cvmx_lmcx_fadr_cn61xx          cnf71xx;
 };
@@ -6739,6 +6740,7 @@ union cvmx_lmcx_ifb_cnt {
 	struct cvmx_lmcx_ifb_cnt_s            cn68xx;
 	struct cvmx_lmcx_ifb_cnt_s            cn68xxp1;
 	struct cvmx_lmcx_ifb_cnt_s            cn70xx;
+	struct cvmx_lmcx_ifb_cnt_s            cn70xxp1;
 	struct cvmx_lmcx_ifb_cnt_s            cn78xx;
 	struct cvmx_lmcx_ifb_cnt_s            cnf71xx;
 };
@@ -6902,6 +6904,7 @@ union cvmx_lmcx_int {
 	struct cvmx_lmcx_int_cn61xx           cn68xx;
 	struct cvmx_lmcx_int_cn61xx           cn68xxp1;
 	struct cvmx_lmcx_int_s                cn70xx;
+	struct cvmx_lmcx_int_s                cn70xxp1;
 	struct cvmx_lmcx_int_s                cn78xx;
 	struct cvmx_lmcx_int_cn61xx           cnf71xx;
 };
@@ -6969,6 +6972,7 @@ union cvmx_lmcx_int_en {
 	struct cvmx_lmcx_int_en_cn61xx        cn68xx;
 	struct cvmx_lmcx_int_en_cn61xx        cn68xxp1;
 	struct cvmx_lmcx_int_en_s             cn70xx;
+	struct cvmx_lmcx_int_en_s             cn70xxp1;
 	struct cvmx_lmcx_int_en_s             cn78xx;
 	struct cvmx_lmcx_int_en_cn61xx        cnf71xx;
 };
@@ -7618,6 +7622,7 @@ union cvmx_lmcx_modereg_params0 {
 	struct cvmx_lmcx_modereg_params0_s    cn68xx;
 	struct cvmx_lmcx_modereg_params0_s    cn68xxp1;
 	struct cvmx_lmcx_modereg_params0_s    cn70xx;
+	struct cvmx_lmcx_modereg_params0_s    cn70xxp1;
 	struct cvmx_lmcx_modereg_params0_s    cn78xx;
 	struct cvmx_lmcx_modereg_params0_s    cnf71xx;
 };
@@ -7825,6 +7830,7 @@ union cvmx_lmcx_modereg_params1 {
 	struct cvmx_lmcx_modereg_params1_s    cn68xx;
 	struct cvmx_lmcx_modereg_params1_s    cn68xxp1;
 	struct cvmx_lmcx_modereg_params1_s    cn70xx;
+	struct cvmx_lmcx_modereg_params1_s    cn70xxp1;
 	struct cvmx_lmcx_modereg_params1_s    cn78xx;
 	struct cvmx_lmcx_modereg_params1_s    cnf71xx;
 };
@@ -7872,6 +7878,37 @@ union cvmx_lmcx_modereg_params2 {
 #endif
 	} s;
 	struct cvmx_lmcx_modereg_params2_s    cn70xx;
+	struct cvmx_lmcx_modereg_params2_cn70xxp1 {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_40_63               : 24;
+	uint64_t vref_range_11                : 1;  /**< VREF range for rank 3.  Not used in CN70XX/CN71XX. */
+	uint64_t vref_value_11                : 6;  /**< VREF value for rank 3.  Not used in CN70XX/CN71XX. */
+	uint64_t rtt_park_11                  : 3;  /**< RTT park value for rank 3.  Not used in CN70XX/CN71XX. */
+	uint64_t vref_range_10                : 1;  /**< VREF range for rank 2.  Not used in CN70XX/CN71XX. */
+	uint64_t vref_value_10                : 6;  /**< VREF value for rank 2.  Not used in CN70XX/CN71XX. */
+	uint64_t rtt_park_10                  : 3;  /**< RTT park value for rank 2.  Not used in CN70XX/CN71XX. */
+	uint64_t vref_range_01                : 1;  /**< VREF range for rank 1. */
+	uint64_t vref_value_01                : 6;  /**< VREF value for rank 1. */
+	uint64_t rtt_park_01                  : 3;  /**< RTT park value for rank 1. */
+	uint64_t vref_range_00                : 1;  /**< VREF range for rank 0. */
+	uint64_t vref_value_00                : 6;  /**< VREF value for rank 0. */
+	uint64_t rtt_park_00                  : 3;  /**< RTT park value for rank 0. */
+#else
+	uint64_t rtt_park_00                  : 3;
+	uint64_t vref_value_00                : 6;
+	uint64_t vref_range_00                : 1;
+	uint64_t rtt_park_01                  : 3;
+	uint64_t vref_value_01                : 6;
+	uint64_t vref_range_01                : 1;
+	uint64_t rtt_park_10                  : 3;
+	uint64_t vref_value_10                : 6;
+	uint64_t vref_range_10                : 1;
+	uint64_t rtt_park_11                  : 3;
+	uint64_t vref_value_11                : 6;
+	uint64_t vref_range_11                : 1;
+	uint64_t reserved_40_63               : 24;
+#endif
+	} cn70xxp1;
 	struct cvmx_lmcx_modereg_params2_s    cn78xx;
 };
 typedef union cvmx_lmcx_modereg_params2 cvmx_lmcx_modereg_params2_t;
@@ -7939,6 +7976,7 @@ union cvmx_lmcx_modereg_params3 {
 #endif
 	} s;
 	struct cvmx_lmcx_modereg_params3_s    cn70xx;
+	struct cvmx_lmcx_modereg_params3_s    cn70xxp1;
 	struct cvmx_lmcx_modereg_params3_s    cn78xx;
 };
 typedef union cvmx_lmcx_modereg_params3 cvmx_lmcx_modereg_params3_t;
@@ -7960,6 +7998,7 @@ union cvmx_lmcx_mpr_data0 {
 #endif
 	} s;
 	struct cvmx_lmcx_mpr_data0_s          cn70xx;
+	struct cvmx_lmcx_mpr_data0_s          cn70xxp1;
 	struct cvmx_lmcx_mpr_data0_s          cn78xx;
 };
 typedef union cvmx_lmcx_mpr_data0 cvmx_lmcx_mpr_data0_t;
@@ -7981,6 +8020,7 @@ union cvmx_lmcx_mpr_data1 {
 #endif
 	} s;
 	struct cvmx_lmcx_mpr_data1_s          cn70xx;
+	struct cvmx_lmcx_mpr_data1_s          cn70xxp1;
 	struct cvmx_lmcx_mpr_data1_s          cn78xx;
 };
 typedef union cvmx_lmcx_mpr_data1 cvmx_lmcx_mpr_data1_t;
@@ -8004,6 +8044,7 @@ union cvmx_lmcx_mpr_data2 {
 #endif
 	} s;
 	struct cvmx_lmcx_mpr_data2_s          cn70xx;
+	struct cvmx_lmcx_mpr_data2_s          cn70xxp1;
 	struct cvmx_lmcx_mpr_data2_s          cn78xx;
 };
 typedef union cvmx_lmcx_mpr_data2 cvmx_lmcx_mpr_data2_t;
@@ -8081,7 +8122,9 @@ union cvmx_lmcx_mr_mpr_ctl {
                                                          the corresponding DRAM device is enabled for the PDA MR write operation.
                                                          Bit<23> corresponds to the lowest order, *4 device, and bit<40> corresponds to the highest
                                                          order *4 device, for a total of up to 18 devices. */
-	uint64_t mr_wr_rank                   : 2;  /**< Selects the DRAM rank for either MRW or MPR sequences. */
+	uint64_t mr_wr_rank                   : 2;  /**< Selects the DRAM rank for either MRW or MPR sequences.  For CN70XX/CN71XX, this must be
+                                                         set
+                                                         to either 0 or 1. */
 	uint64_t mr_wr_sel                    : 3;  /**< Selects which MR to write with the MR write sequence.
                                                          Which pins to drive and how to drive them is automatically controlled through the DDR3/4
                                                          mode setting. Bits<19:18> are also used to select the MPR page for an MPR sequence.
@@ -8103,6 +8146,7 @@ union cvmx_lmcx_mr_mpr_ctl {
 	uint64_t reserved_52_63               : 12;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_mr_mpr_ctl_cn70xx    cn70xxp1;
 	struct cvmx_lmcx_mr_mpr_ctl_s         cn78xx;
 };
 typedef union cvmx_lmcx_mr_mpr_ctl cvmx_lmcx_mr_mpr_ctl_t;
@@ -8111,7 +8155,25 @@ typedef union cvmx_lmcx_mr_mpr_ctl cvmx_lmcx_mr_mpr_ctl_t;
  * cvmx_lmc#_nxm
  *
  * Following is the decoding for mem_msb/rank:
- *
+ * 0x0: mem_msb = mem_adr[25].
+ * 0x1: mem_msb = mem_adr[26].
+ * 0x2: mem_msb = mem_adr[27].
+ * 0x3: mem_msb = mem_adr[28].
+ * 0x4: mem_msb = mem_adr[29].
+ * 0x5: mem_msb = mem_adr[30].
+ * 0x6: mem_msb = mem_adr[31].
+ * 0x7: mem_msb = mem_adr[32].
+ * 0x8: mem_msb = mem_adr[33].
+ * 0x9: mem_msb = mem_adr[34].
+ * 0xA: mem_msb = mem_adr[35].
+ * 0xB: mem_msb = mem_adr[36].
+ * 0xC-0xF = Reserved.
+ *
+ * For example, for a DIMM made of Samsung's K4B1G0846C-ZCF7 1Gb (16M * 8 bit * 8 bank) DDR3
+ * parts, the column address width = 10; so with 10b of col, 3b of bus, 3b of bank, row_lsb = 16.
+ * Therefore, row = mem_adr[29:16] and mem_msb = 4.
+ * Note also that addresses greater than the max defined space (pbank_msb) are also treated as
+ * NXM accesses.
  */
 union cvmx_lmcx_nxm {
 	uint64_t u64;
@@ -8180,8 +8242,8 @@ union cvmx_lmcx_nxm {
 	struct cvmx_lmcx_nxm_cn70xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_24_63               : 40;
-	uint64_t mem_msb_d1_r1                : 4;  /**< Max row MSB for DIMM1, RANK1/DIMM1 in single ranked. */
-	uint64_t mem_msb_d1_r0                : 4;  /**< Max row MSB for DIMM1, RANK0. */
+	uint64_t mem_msb_d1_r1                : 4;  /**< Reserved.  INTERNAL: Max row MSB for DIMM1, RANK1/DIMM1 in single ranked. */
+	uint64_t mem_msb_d1_r0                : 4;  /**< Reserved.  INTERNAL: Max row MSB for DIMM1, RANK0. */
 	uint64_t mem_msb_d0_r1                : 4;  /**< Max row MSB for DIMM0, RANK1/DIMM0 in single ranked. */
 	uint64_t mem_msb_d0_r0                : 4;  /**< Max row MSB for DIMM0, RANK0. */
 	uint64_t reserved_4_7                 : 4;
@@ -8202,6 +8264,7 @@ union cvmx_lmcx_nxm {
 	uint64_t reserved_24_63               : 40;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_nxm_cn70xx           cn70xxp1;
 	struct cvmx_lmcx_nxm_cn70xx           cn78xx;
 	struct cvmx_lmcx_nxm_s                cnf71xx;
 };
@@ -8236,6 +8299,7 @@ union cvmx_lmcx_nxm_fadr {
 #endif
 	} s;
 	struct cvmx_lmcx_nxm_fadr_s           cn70xx;
+	struct cvmx_lmcx_nxm_fadr_s           cn70xxp1;
 	struct cvmx_lmcx_nxm_fadr_s           cn78xx;
 };
 typedef union cvmx_lmcx_nxm_fadr cvmx_lmcx_nxm_fadr_t;
@@ -8265,6 +8329,7 @@ union cvmx_lmcx_ops_cnt {
 	struct cvmx_lmcx_ops_cnt_s            cn68xx;
 	struct cvmx_lmcx_ops_cnt_s            cn68xxp1;
 	struct cvmx_lmcx_ops_cnt_s            cn70xx;
+	struct cvmx_lmcx_ops_cnt_s            cn70xxp1;
 	struct cvmx_lmcx_ops_cnt_s            cn78xx;
 	struct cvmx_lmcx_ops_cnt_s            cnf71xx;
 };
@@ -8497,6 +8562,7 @@ union cvmx_lmcx_phy_ctl {
 	struct cvmx_lmcx_phy_ctl_cn61xx       cn68xx;
 	struct cvmx_lmcx_phy_ctl_cn61xx       cn68xxp1;
 	struct cvmx_lmcx_phy_ctl_s            cn70xx;
+	struct cvmx_lmcx_phy_ctl_s            cn70xxp1;
 	struct cvmx_lmcx_phy_ctl_s            cn78xx;
 	struct cvmx_lmcx_phy_ctl_cn61xx       cnf71xx;
 };
@@ -8877,6 +8943,7 @@ union cvmx_lmcx_reset_ctl {
 	struct cvmx_lmcx_reset_ctl_s          cn68xx;
 	struct cvmx_lmcx_reset_ctl_s          cn68xxp1;
 	struct cvmx_lmcx_reset_ctl_s          cn70xx;
+	struct cvmx_lmcx_reset_ctl_s          cn70xxp1;
 	struct cvmx_lmcx_reset_ctl_s          cn78xx;
 	struct cvmx_lmcx_reset_ctl_s          cnf71xx;
 };
@@ -9008,6 +9075,7 @@ union cvmx_lmcx_rlevel_ctl {
 	struct cvmx_lmcx_rlevel_ctl_cn61xx    cn68xx;
 	struct cvmx_lmcx_rlevel_ctl_cn61xx    cn68xxp1;
 	struct cvmx_lmcx_rlevel_ctl_s         cn70xx;
+	struct cvmx_lmcx_rlevel_ctl_s         cn70xxp1;
 	struct cvmx_lmcx_rlevel_ctl_s         cn78xx;
 	struct cvmx_lmcx_rlevel_ctl_cn61xx    cnf71xx;
 };
@@ -9043,6 +9111,7 @@ union cvmx_lmcx_rlevel_dbg {
 	struct cvmx_lmcx_rlevel_dbg_s         cn68xx;
 	struct cvmx_lmcx_rlevel_dbg_s         cn68xxp1;
 	struct cvmx_lmcx_rlevel_dbg_s         cn70xx;
+	struct cvmx_lmcx_rlevel_dbg_s         cn70xxp1;
 	struct cvmx_lmcx_rlevel_dbg_s         cn78xx;
 	struct cvmx_lmcx_rlevel_dbg_s         cnf71xx;
 };
@@ -9115,6 +9184,7 @@ union cvmx_lmcx_rlevel_rankx {
 	struct cvmx_lmcx_rlevel_rankx_s       cn68xx;
 	struct cvmx_lmcx_rlevel_rankx_s       cn68xxp1;
 	struct cvmx_lmcx_rlevel_rankx_s       cn70xx;
+	struct cvmx_lmcx_rlevel_rankx_s       cn70xxp1;
 	struct cvmx_lmcx_rlevel_rankx_s       cn78xx;
 	struct cvmx_lmcx_rlevel_rankx_s       cnf71xx;
 };
@@ -9310,6 +9380,7 @@ union cvmx_lmcx_rodt_mask {
 	uint64_t reserved_28_63               : 36;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_rodt_mask_cn70xx     cn70xxp1;
 	struct cvmx_lmcx_rodt_mask_cn70xx     cn78xx;
 	struct cvmx_lmcx_rodt_mask_s          cnf71xx;
 };
@@ -9333,6 +9404,7 @@ union cvmx_lmcx_scramble_cfg0 {
 	struct cvmx_lmcx_scramble_cfg0_s      cn61xx;
 	struct cvmx_lmcx_scramble_cfg0_s      cn66xx;
 	struct cvmx_lmcx_scramble_cfg0_s      cn70xx;
+	struct cvmx_lmcx_scramble_cfg0_s      cn70xxp1;
 	struct cvmx_lmcx_scramble_cfg0_s      cn78xx;
 	struct cvmx_lmcx_scramble_cfg0_s      cnf71xx;
 };
@@ -9356,6 +9428,7 @@ union cvmx_lmcx_scramble_cfg1 {
 	struct cvmx_lmcx_scramble_cfg1_s      cn61xx;
 	struct cvmx_lmcx_scramble_cfg1_s      cn66xx;
 	struct cvmx_lmcx_scramble_cfg1_s      cn70xx;
+	struct cvmx_lmcx_scramble_cfg1_s      cn70xxp1;
 	struct cvmx_lmcx_scramble_cfg1_s      cn78xx;
 	struct cvmx_lmcx_scramble_cfg1_s      cnf71xx;
 };
@@ -9439,6 +9512,7 @@ union cvmx_lmcx_scrambled_fadr {
 	uint64_t reserved_40_63               : 24;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_scrambled_fadr_cn70xx cn70xxp1;
 	struct cvmx_lmcx_scrambled_fadr_cn70xx cn78xx;
 	struct cvmx_lmcx_scrambled_fadr_cn61xx cnf71xx;
 };
@@ -9460,11 +9534,7 @@ union cvmx_lmcx_seq_ctl {
 	uint64_t seq_sel                      : 4;  /**< Selects the sequence that LMC runs after a 0->1 transition on INIT_START.
                                                          0x0 = Power-up/initialization:
                                                          LMC(0..3)_CONFIG[RANKMASK] selects participating ranks (should be all ranks with attached
-                                                         DRAM). DDR*_DIMM*_CKE* signals are activated (if not already active). RDIMM register
-                                                         control words 0-15 are written to LMC(0..3)_CONFIG[RANKMASK]-selected RDIMMs when
-                                                         LMC(0..3)_CONTROL[RDIMM_ENA] = 1 and corresponding LMC(0..3)_DIMM_CTL[DIMM*_WMASK] bits
-                                                         are set. (Refer to LMC(0..3)_DIMM(0..1)_PARAMS and LMC(0..3)_DIMM_CTL descriptions for
-                                                         more details.)
+                                                         DRAM). DDR_CKE* signals are activated (if not already active).
                                                          The DRAM registers MR0, MR1, MR2, and MR3 are written in the selected ranks.
                                                          0x1 = Read-leveling:
                                                          LMC(0..3)_CONFIG[RANKMASK] selects the rank to be read-leveled. MR3 written in the
@@ -9472,24 +9542,52 @@ union cvmx_lmcx_seq_ctl {
                                                          0x2 = Self-refresh entry:
                                                          LMC(0..3)_CONFIG[INIT_STATUS] selects the participating ranks (should be all ranks with
                                                          attached DRAM). MR1 and MR2 are written in the selected ranks if
-                                                         LMC(0..3)_CONFIG[SREF_WITH_DLL] = 1. DDR*_DIMM*_CKE* signals de-activated.
+                                                         LMC(0..3)_CONFIG[SREF_WITH_DLL] = 1. DDR_CKE* signals de-activated.
                                                          0x3 = Self-refresh exit:
                                                          LMC(0..3)_CONFIG[RANKMASK] must be set to indicate participating ranks (should be all
-                                                         ranks with attached DRAM). DDR*_DIMM*_CKE* signals activated. MR0, MR1, MR2, and MR3 are
+                                                         ranks with attached DRAM). DDR_CKE* signals activated. MR0, MR1, MR2, and MR3 are
                                                          written in the participating ranks if LMC(0..3)_CONFIG[SREF_WITH_DLL] = 1.
                                                          LMC(0..3)_CONFIG[INIT_STATUS] is updated for ranks that are selected.
                                                          0x6 = Write-leveling:
-                                                         LMC(0..3)_CONFIG[RANKMASK] selects the rank to be write-leveled.
-                                                         LMC(0..3)_CONFIG[INIT_STATUS] must indicate all ranks with attached DRAM. MR1 and MR2
-                                                         written in the LMC(0..3)_CONFIG[INIT_STATUS]-selected ranks.
-                                                         0x7 = Initialize RCW:
-                                                         LMC(0..3)_CONFIG[RANKMASK] selects participating ranks (should be all ranks with attached
-                                                         DRAM). In DDR3 mode, RDIMM register control words 0-15 are written to
-                                                         LMC(0..3)_CONFIG[RANKMASK]-selected RDIMMs when LMC(0..3)_CONTROL[RDIMM_ENA] = 1 and
-                                                         corresponding LMC(0..3)_DIMM_CTL[DIMM*_WMASK] bits are set. (Refer to
-                                                         LMC(0..3)_DIMM(0..1)_PARAMS and LMC(0..3)_DIMM_CTL descriptions for more details.) */
-	uint64_t init_start                   : 1;  /**< A 0->1 transition starts the DDR memory sequence that is selected by SEQ_SEL. This
-                                                         register is a one-shot and clears itself each time it is set. */
+                                                         RANKMASK selects the rank to be write-leveled.
+                                                         INIT_STATUS must indicate all ranks with attached DRAM.
+                                                         MR1 and MR2 written to INIT_STATUS-selected ranks.
+                                                         0x7 = Init RCW
+                                                         RANKMASK selects participating ranks (should be all ranks with attached DRAM).
+                                                         In DDR3 mode, RDIMM register control words 0-15 will be written to RANKMASK-selected
+                                                         RDIMMs when LMC(0..3)_CONTROL[RDIMM_ENA]=1 and corresponding
+                                                         LMC(0..3)_DIMM_CTL[DIMM*_WMASK]
+                                                         bits are set. (Refer to LMC(0..3)_DIMM(0..1)_PARAMS and LMC(0..3)_DIMM_CTL descriptions
+                                                         below for more details.)  In DDR4 mode, additionally register control words RC1x-RCBx
+                                                         will be written if selected by LMC(0..3)_DDR4_DIMM_CTL[DIMM*_WMASK].  See
+                                                         LMC(0..3)_DIMM(0..1)_DDR4_PARAMS0 and LMC(0..3)_DIMM(0..1)_DDR4_PARAMS1 for the values
+                                                         that are written to the DDR4 RCWs.
+                                                         0x8 = MRW
+                                                         Mode Register Write sequence.
+                                                         0x9 = MPR
+                                                         MPR register read or write sequence.
+                                                         0xa = VREFINT
+                                                         Vref internal training sequence, also used as deskew training sequence when
+                                                         LMC(0..3)_EXT_CONFIG[VREFINT_SEQ_DESKEW] is set.
+                                                         0xb = Offset Training
+                                                         Offset training sequence.
+                                                         Self-refresh entry SEQ_SEL's may also be automatically
+                                                         generated by hardware upon a chip warm or soft reset
+                                                         sequence when LMC*_RESET_CTL[DDR3PWARM,DDR3PSOFT] are set.
+                                                         LMC writes the LMC*_MODEREG_PARAMS0 and LMC*_MODEREG_PARAMS1 CSR field values
+                                                         to the Mode registers in the DRAM parts (i.e. MR0, MR1, MR2, and MR3) as part of some of
+                                                         these sequences.
+                                                         Refer to the LMC*_MODEREG_PARAMS0 and LMC*_MODEREG_PARAMS1 descriptions for more details.
+                                                         If there are two consecutive power-up/init's without
+                                                         a DRESET assertion between them, LMC asserts DDR_CKE* as part of
+                                                         the first power-up/init, and continues to assert DDR_CKE*
+                                                         through the remainder of the first and the second power-up/init.
+                                                         If DDR_CKE* deactivation and reactivation is needed for
+                                                         a second power-up/init, a DRESET assertion is required
+                                                         between the first and the second. */
+	uint64_t init_start                   : 1;  /**< A 0->1 transition starts the DDR memory sequence that is selected by
+                                                         LMC(0..3)_SEQ_CTL[SEQ_SEL].
+                                                         This register is a one-shot and clears itself each time it is set. */
 #else
 	uint64_t init_start                   : 1;
 	uint64_t seq_sel                      : 4;
@@ -9498,6 +9596,7 @@ union cvmx_lmcx_seq_ctl {
 #endif
 	} s;
 	struct cvmx_lmcx_seq_ctl_s            cn70xx;
+	struct cvmx_lmcx_seq_ctl_s            cn70xxp1;
 	struct cvmx_lmcx_seq_ctl_s            cn78xx;
 };
 typedef union cvmx_lmcx_seq_ctl cvmx_lmcx_seq_ctl_t;
@@ -9507,21 +9606,35 @@ typedef union cvmx_lmcx_seq_ctl cvmx_lmcx_seq_ctl_t;
  *
  * This register is an assortment of control fields needed by the memory controller. If software
  * has not previously written to this register (since the last DRESET), hardware updates the
- * fields in this register to the minimum allowed value when any of LMC(0..3)_RLEVEL_RANK(0..3),
- * LMC(0..3)_WLEVEL_RANK(0..3), LMC(0..3)_CONTROL, and LMC(0..3)_MODEREG_PARAMS0 registers
+ * fields in th
+ * LMC(0..3)_WLEVEL_RANK(0..1), LMC(0..3)_CONTROL, and LMC(0..3)_MODEREG_PARAMS0 registers
  * change. Ideally, only read this register after LMC has been initialized and
- * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
- * The interpretation of the fields in this register depends on LMC(0)_CONFIG[DDR2T]:
- * * If LMC(0..3)_CONFIG[DDR2T]=1, (FieldValue + 4) is the minimum CK cycles between when the
- * DRAM part registers CAS commands of the 1
- * st and 2
- * nd types from different cache blocks.
- * If LMC(0..3)_CONFIG[DDR2T]=0, (FieldValue + 3) is the minimum CK cycles between when the DRAM
- * part registers CAS commands of the 1
- * st and 2
- * nd types from different cache blocks. FieldValue = 0 is always illegal in this case.
- * The hardware-calculated minimums for these fields are shown in LMC(0)_SLOT_CTL0 Hardware-
- * Calculated Minimums.
+ * LMC(0..3)_RLEVEL_RANK(0..1), LMC(0..3)_WLEVEL_RANK(0..1) have valid data.
+ * The field value is the minimum CK cycles between when the DRAM
+ * part registers CAS commands of the first and second types from different cache blocks.
+ *
+ * "*_S_INIT" fields are DDR3 timing or DDR4 short timing parameters
+ * "*_L_INIT" fields are DDR4 long timing parameters
+ *
+ * The hardware-calculated minimums are:
+ * min R2R_S_INIT = 4
+ * min R2W_S_INIT = 8 + (RL + MaxRdSkew) (WL + MinWrSkew) + LMC*_CONTROL[BPRCH]
+ * min W2R_S_INIT = 5 + LMC*_TIMING_PARAMS1[TWTR] + WL
+ * min W2W_S_INIT = 4
+ * min R2R_L_INIT = LMC*_MODEREG_PARAMS3[TCCD_L] (decoded)
+ * min R2W_L_INIT = 8 + (RL + MaxRdSkew) (WL + MinWrSkew) + LMC*_CONTROL[BPRCH]
+ * min W2R_L_INIT = 5 + LMC*_TIMING_PARAMS2[TWTR_L] + WL
+ * min W2W_L_INIT = LMC*_MODEREG_PARAMS3[TCCD_L] (decoded)
+ * where
+ * RL        = CL  + AL (LMC*_MODEREG_PARAMS0[CL] selects CL, LMC*_MODEREG_PARAMS0[AL] selects
+ * AL)
+ * WL        = CWL + AL (LMC*_MODEREG_PARAMS0[CWL] selects CWL)
+ * MaxRdSkew = max(LMC*_RLEVEL_RANKi[BYTEj]/4) + 1
+ * (max is across all ranks i (0..3) and bytes j (0..8))
+ * MinWrSkew = min(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX]
+ * (min is across all ranks i (0..3) and bytes j (0..8))
+ *
+ * R2W_INIT has 1 CK cycle built in for OCTEON-internal ODT settling/channel turnaround time.
  */
 union cvmx_lmcx_slot_ctl0 {
 	uint64_t u64;
@@ -9589,6 +9702,7 @@ union cvmx_lmcx_slot_ctl0 {
 	struct cvmx_lmcx_slot_ctl0_cn61xx     cn68xx;
 	struct cvmx_lmcx_slot_ctl0_cn61xx     cn68xxp1;
 	struct cvmx_lmcx_slot_ctl0_s          cn70xx;
+	struct cvmx_lmcx_slot_ctl0_s          cn70xxp1;
 	struct cvmx_lmcx_slot_ctl0_s          cn78xx;
 	struct cvmx_lmcx_slot_ctl0_cn61xx     cnf71xx;
 };
@@ -9599,21 +9713,33 @@ typedef union cvmx_lmcx_slot_ctl0 cvmx_lmcx_slot_ctl0_t;
  *
  * This register is an assortment of control fields needed by the memory controller. If software
  * has not previously written to this register (since the last DRESET), hardware updates the
- * fields in this register to the minimum allowed value when any of LMC(0..3)_RLEVEL_RANK(0..3),
- * LMC(0..3)_WLEVEL_RANK(0..3), LMC(0..3)_CONTROL and LMC(0..3)_MODEREG_PARAMS0 CSRs change.
+ * fields in this register to the minimum allowed value when any of LMC(0..3)_RLEVEL_RANK(0..1),
+ * LMC(0..3)_WLEVEL_RANK(0..1), LMC(0..3)_CONTROL and LMC(0..3)_MODEREG_PARAMS0 CSRs change.
  * Ideally, only read this register after LMC has been initialized and
- * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
- * The interpretation of the fields in this CSR depends on LMC(0)_CONFIG[DDR2T]:
- * * If LMC(0..3)_CONFIG[DDR2T]=1, (FieldValue + 4) is the minimum CK cycles between when the
- * DRAM part registers CAS commands of the 1
- * st and 2
- * nd types from different cache blocks.
- * If LMC(0..3)_CONFIG[DDR2T]=0, (FieldValue + 3) is the minimum CK cycles between when the DRAM
- * part registers CAS commands of the 1
- * st and 2
- * nd types from different cache blocks. FieldValue = 0 is always illegal in this case.
- * The hardware-calculated minimums for these fields are shown in LMC(0)_SLOT_CTL1 Hardware-
- * Calculated Minimums.
+ * LMC(0..3)_RLEVEL_RANK(0..1), LMC(0..3)_WLEVEL_RANK(0..1) have valid data.
+ * The field value is the minimum CK cycles between when the DRAM
+ * part registers CAS commands of the first and second types from different cache blocks.
+ *
+ * The hardware-calculated minimums are:
+ * min R2R_XRANK_INIT = 5 + MaxRdSkew MinRdSkew + LMC*_CONTROL[RODT_BPRCH]
+ * min R2W_XRANK_INIT = 8 + (RL + MaxRdSkew) - (WL + MinWrSkew) + LMC*_CONTROL[BPRCH]
+ * min W2R_XRANK_INIT = 6 + MaxWrSkew + LMC*_CONTROL[FPRCH2]
+ * min W2W_XRANK_INIT = 7 + MaxWrSkew - MinWrSkew
+ * where
+ * RL        = CL  + AL (LMC*_MODEREG_PARAMS0[CL] selects CL, LMC*_MODEREG_PARAMS0[AL] selects
+ * AL)
+ * WL        = CWL + AL (LMC*_MODEREG_PARAMS0[CWL] selects CWL)
+ * MinRdSkew = min(LMC*_RLEVEL_RANKi[BYTEj]/4)                              (min is across all
+ * ranks i (0..3) and bytes j (0..8))
+ * MaxRdSkew = max(LMC*_RLEVEL_RANKi[BYTEj]/4) + 1                          (max is across all
+ * ranks i (0..3) and bytes j (0..8))
+ * MinWrSkew = min(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX]     (min is across all
+ * ranks i (0..3) and bytes j (0..8))
+ * MaxWrSkew = max(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX] + 1 (max is across all
+ * ranks i (0..3) and bytes j (0..8))
+ * R2W_XRANK_INIT has 1 extra CK cycle built in for OCTEON-internal ODT settling/channel
+ * turnaround time.
+ * W2R_XRANK_INIT has 1 extra CK cycle built in for channel turnaround time.
  */
 union cvmx_lmcx_slot_ctl1 {
 	uint64_t u64;
@@ -9647,6 +9773,7 @@ union cvmx_lmcx_slot_ctl1 {
 	struct cvmx_lmcx_slot_ctl1_s          cn68xx;
 	struct cvmx_lmcx_slot_ctl1_s          cn68xxp1;
 	struct cvmx_lmcx_slot_ctl1_s          cn70xx;
+	struct cvmx_lmcx_slot_ctl1_s          cn70xxp1;
 	struct cvmx_lmcx_slot_ctl1_s          cn78xx;
 	struct cvmx_lmcx_slot_ctl1_s          cnf71xx;
 };
@@ -9657,20 +9784,35 @@ typedef union cvmx_lmcx_slot_ctl1 cvmx_lmcx_slot_ctl1_t;
  *
  * This register is an assortment of control fields needed by the memory controller. If software
  * has not previously written to this register (since the last DRESET), hardware updates the
- * fields in this register to the minimum allowed value when any of LMC(0..3)_RLEVEL_RANK(0..3),
- * LMC(0..3)_WLEVEL_RANK(0..3), LMC(0..3)_CONTROL and LMC(0..3)_MODEREG_PARAMS0 CSRs change.
- * Ideally, only read this register after LMC has been initialized and
- * LMC(0..3)_RLEVEL_RANK(0..3), LMC(0..3)_WLEVEL_RANK(0..3) have valid data.
- * The interpretation of the fields in this CSR depends on LMC(0)_CONFIG[DDR2T]:
- * * If LMC(0..3)_CONFIG[DDR2T] = 1, (FieldValue + 4) is the minimum CK cycles between when the
- * DRAM part registers CAS commands of the 1
- * st and 2
- * nd types from different cache blocks.
- * If LMC(0..3)_CONFIG[DDR2T] = 0, (FieldValue + 3) is the minimum CK cycles between when the
- * DRAM part registers CAS commands of the 1
- * st and 2
- * nd types from different cache blocks. FieldValue = 0 is always illegal in this case.
- * The hardware-calculated minimums for these fields are shown in LMC Registers.
+ * fields in this register to the minimum allowed value when any of LMC(0..3)_RLEVEL_RANK(0..1),
+ * LMC(0..3)_WLEVEL_RANK(0..1)LMC*_WLEVEL_RANKn, LMC*_CONTROL and LMC*_MODEREG_PARAMS0 CSRs
+ * change. Ideally, only read this register after LMC has been initialized and LMC*_RLEVEL_RANKn,
+ * LMC*_WLEVEL_RANKn have valid data.
+ *
+ * The field value is the minimum CK cycles between when the DRAM
+ * part registers CAS commands of the first and second types from different cache blocks.
+ *
+ * The hardware-calculated minimums are:
+ * min R2R_XDIMM_INIT = 6 + MaxRdSkew MinRdSkew + LMC*_CONTROL[RODT_BPRCH]
+ * min R2W_XDIMM_INIT = 9 + (RL + MaxRdSkew) - (WL + MinWrSkew) + LMC*_CONTROL[BPRCH]
+ * min W2R_XDIMM_INIT = 6 + MaxWrSkew + LMC*_CONTROL[FPRCH2]
+ * min W2W_XDIMM_INIT = 8 + MaxWrSkew - MinWrSkew
+ * where
+ * RL        = CL  + AL (LMC*_MODEREG_PARAMS0[CL] selects CL, LMC*_MODEREG_PARAMS0[AL] selects
+ * AL)
+ * WL        = CWL + AL (LMC*_MODEREG_PARAMS0[CWL] selects CWL)
+ * MinRdSkew = min(LMC*_RLEVEL_RANKi[BYTEj]/4)                              (min is across all
+ * ranks i (0..3) and bytes j (0..8))
+ * MaxRdSkew = max(LMC*_RLEVEL_RANKi[BYTEj]/4) + 1                          (max is across all
+ * ranks i (0..3) and bytes j (0..8))
+ * MinWrSkew = min(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX]     (min is across all
+ * ranks i (0..3) and bytes j (0..8))
+ * MaxWrSkew = max(LMC*_WLEVEL_RANKi[BYTEj]/8) LMC*_CONFIG[EARLY_DQX] + 1 (max is across all
+ * ranks i (0..3) and bytes j (0..8))
+ * R2W_XDIMM_INIT has 2 extra CK cycles built in for OCTEON-internal ODT settling/channel
+ * turnaround time.
+ * R2R_XDIMM_INIT, W2R_XRANK_INIT, W2W_XDIMM_INIT have 1 extra CK cycle built in for channel
+ * turnaround time.
  */
 union cvmx_lmcx_slot_ctl2 {
 	uint64_t u64;
@@ -9704,6 +9846,7 @@ union cvmx_lmcx_slot_ctl2 {
 	struct cvmx_lmcx_slot_ctl2_s          cn68xx;
 	struct cvmx_lmcx_slot_ctl2_s          cn68xxp1;
 	struct cvmx_lmcx_slot_ctl2_s          cn70xx;
+	struct cvmx_lmcx_slot_ctl2_s          cn70xxp1;
 	struct cvmx_lmcx_slot_ctl2_s          cn78xx;
 	struct cvmx_lmcx_slot_ctl2_s          cnf71xx;
 };
@@ -9942,6 +10085,7 @@ union cvmx_lmcx_timing_params0 {
 	uint64_t reserved_48_63               : 16;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_timing_params0_cn70xx cn70xxp1;
 	struct cvmx_lmcx_timing_params0_cn70xx cn78xx;
 	struct cvmx_lmcx_timing_params0_cn61xx cnf71xx;
 };
@@ -10221,47 +10365,47 @@ union cvmx_lmcx_timing_params1 {
                                                          where TRRD is from the JEDEC DDR3 spec, and TCYC(ns) is the DDR clock frequency (not data
                                                          rate).
                                                          TYP = max(4nCK, 10 ns)
-                                                         - 000: reserved
-                                                         - 001: 2 TCYC
+                                                         0x0 = reserved
+                                                         0x1 = 2 TCYC
                                                          - ...
-                                                         - 110: 7 TCYC
-                                                         - 111: 8 TCYC
+                                                         0x6 = 7 TCYC
+                                                         0x7 = 8 TCYC
                                                          For DDR4, this is the TRRD_S parameter. */
 	uint64_t trfc                         : 7;  /**< Indicates TRFC constraints. Set this field as follows:
                                                          RNDUP[TRFC(ns) / (8 * TCYC(ns))]
                                                          where TRFC is from the JEDEC DDR3 spec, and TCYC(ns) is the DDR clock frequency (not data
                                                          rate).
                                                          TYP = 90-350 ns
-                                                         - 0000000: reserved
-                                                         - 0000001: 8 TCYC
-                                                         - 0000010: 16 TCYC
-                                                         - 0000011: 24 TCYC
-                                                         - 0000100: 32 TCYC
+                                                         0x0 = reserved.
+                                                         0x1 = 8 TCYC.
+                                                         0x2 = 16 TCYC.
+                                                         0x3 = 24 TCYC.
+                                                         0x4 = 32 TCYC.
                                                          - ...
-                                                         - 1111110: 1008 TCYC
-                                                         - 1111111: 1016 TCYC */
+                                                         0x7E = 1008 TCYC.
+                                                         0x7F = 1016 TCYC. */
 	uint64_t twtr                         : 4;  /**< Indicates TWTR constraints. Set this field as follows:
                                                          RNDUP[TWTR(ns) / TCYC(ns)] - 1
                                                          where TWTR is from the JEDEC DDR3 spec, and TCYC(ns) is the DDR clock frequency (not data
                                                          rate).
                                                          TYP = max(4nCK, 7.5 ns)
                                                          For DDR4, this CSR field represents TWTR_S.
-                                                         - 0000: reserved
-                                                         - 0001: 2
+                                                         0x0 = reserved.
+                                                         0x1 = 2.
                                                          - ...
-                                                         - 0111: 8
-                                                         - 1000-1111: reserved */
+                                                         0x7 = 8.
+                                                         0x8-0xF = reserved. */
 	uint64_t trcd                         : 4;  /**< Indicates TRCD constraints. Set this field as follows:
                                                          RNDUP[TRCD(ns) / TCYC(ns)]
                                                          where TRCD is from the JEDEC DDR3 spec, and TCYC(ns) is the DDR clock frequency (not data
                                                          rate).
                                                          TYP = 10-15 ns
-                                                         - 0000: reserved
-                                                         - 0001: 2 (2 is the smallest value allowed)
-                                                         - 0002: 2
+                                                         0x0 = reserved.
+                                                         0x1 = 2 (2 is the smallest value allowed).
+                                                         0x2 = 2.
                                                          - ...
-                                                         - 1110: 14
-                                                         - 1010-1111: reserved
+                                                         0xE = 14.
+                                                         0xA-0xF = reserved.
                                                          In 2T mode, make this register TRCD - 1, not going below 2. */
 	uint64_t tras                         : 6;  /**< Indicates TRAS constraints. Set TRAS (CSR field) as follows:
                                                          RNDUP[TRAS(ns)/TCYC(ns)] - 1,
@@ -10292,6 +10436,7 @@ union cvmx_lmcx_timing_params1 {
 	uint64_t reserved_49_63               : 15;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_timing_params1_cn70xx cn70xxp1;
 	struct cvmx_lmcx_timing_params1_cn70xx cn78xx;
 	struct cvmx_lmcx_timing_params1_cn61xx cnf71xx;
 };
@@ -10340,6 +10485,7 @@ union cvmx_lmcx_timing_params2 {
 #endif
 	} s;
 	struct cvmx_lmcx_timing_params2_s     cn70xx;
+	struct cvmx_lmcx_timing_params2_s     cn70xxp1;
 	struct cvmx_lmcx_timing_params2_s     cn78xx;
 };
 typedef union cvmx_lmcx_timing_params2 cvmx_lmcx_timing_params2_t;
@@ -10463,6 +10609,7 @@ union cvmx_lmcx_wlevel_ctl {
 	struct cvmx_lmcx_wlevel_ctl_s         cn68xx;
 	struct cvmx_lmcx_wlevel_ctl_s         cn68xxp1;
 	struct cvmx_lmcx_wlevel_ctl_s         cn70xx;
+	struct cvmx_lmcx_wlevel_ctl_s         cn70xxp1;
 	struct cvmx_lmcx_wlevel_ctl_s         cn78xx;
 	struct cvmx_lmcx_wlevel_ctl_s         cnf71xx;
 };
@@ -10508,6 +10655,7 @@ union cvmx_lmcx_wlevel_dbg {
 	struct cvmx_lmcx_wlevel_dbg_s         cn68xx;
 	struct cvmx_lmcx_wlevel_dbg_s         cn68xxp1;
 	struct cvmx_lmcx_wlevel_dbg_s         cn70xx;
+	struct cvmx_lmcx_wlevel_dbg_s         cn70xxp1;
 	struct cvmx_lmcx_wlevel_dbg_s         cn78xx;
 	struct cvmx_lmcx_wlevel_dbg_s         cnf71xx;
 };
@@ -10597,6 +10745,7 @@ union cvmx_lmcx_wlevel_rankx {
 	struct cvmx_lmcx_wlevel_rankx_s       cn68xx;
 	struct cvmx_lmcx_wlevel_rankx_s       cn68xxp1;
 	struct cvmx_lmcx_wlevel_rankx_s       cn70xx;
+	struct cvmx_lmcx_wlevel_rankx_s       cn70xxp1;
 	struct cvmx_lmcx_wlevel_rankx_s       cn78xx;
 	struct cvmx_lmcx_wlevel_rankx_s       cnf71xx;
 };
@@ -10809,6 +10958,7 @@ union cvmx_lmcx_wodt_mask {
 	uint64_t reserved_28_63               : 36;
 #endif
 	} cn70xx;
+	struct cvmx_lmcx_wodt_mask_cn70xx     cn70xxp1;
 	struct cvmx_lmcx_wodt_mask_cn70xx     cn78xx;
 	struct cvmx_lmcx_wodt_mask_s          cnf71xx;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-mio-defs.h b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
index 642c573..f5831f7 100644
--- a/arch/mips/include/asm/octeon/cvmx-mio-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mio-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -2239,6 +2239,7 @@ union cvmx_mio_boot_bist_stat {
 	uint64_t reserved_14_63               : 50;
 #endif
 	} cn70xx;
+	struct cvmx_mio_boot_bist_stat_cn70xx cn70xxp1;
 	struct cvmx_mio_boot_bist_stat_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_8_63                : 56;
@@ -2311,6 +2312,7 @@ union cvmx_mio_boot_comp {
 	uint64_t reserved_11_63               : 53;
 #endif
 	} cn70xx;
+	struct cvmx_mio_boot_comp_cn70xx      cn70xxp1;
 	struct cvmx_mio_boot_comp_cn70xx      cn78xx;
 	struct cvmx_mio_boot_comp_cn61xx      cnf71xx;
 };
@@ -2350,6 +2352,7 @@ union cvmx_mio_boot_ctl {
 #endif
 	} s;
 	struct cvmx_mio_boot_ctl_s            cn70xx;
+	struct cvmx_mio_boot_ctl_s            cn70xxp1;
 };
 typedef union cvmx_mio_boot_ctl cvmx_mio_boot_ctl_t;
 
@@ -2624,6 +2627,7 @@ union cvmx_mio_boot_err {
 	struct cvmx_mio_boot_err_s            cn68xx;
 	struct cvmx_mio_boot_err_s            cn68xxp1;
 	struct cvmx_mio_boot_err_s            cn70xx;
+	struct cvmx_mio_boot_err_s            cn70xxp1;
 	struct cvmx_mio_boot_err_s            cn78xx;
 	struct cvmx_mio_boot_err_s            cnf71xx;
 };
@@ -2666,6 +2670,7 @@ union cvmx_mio_boot_int {
 	struct cvmx_mio_boot_int_s            cn68xx;
 	struct cvmx_mio_boot_int_s            cn68xxp1;
 	struct cvmx_mio_boot_int_s            cn70xx;
+	struct cvmx_mio_boot_int_s            cn70xxp1;
 	struct cvmx_mio_boot_int_s            cnf71xx;
 };
 typedef union cvmx_mio_boot_int cvmx_mio_boot_int_t;
@@ -2710,6 +2715,7 @@ union cvmx_mio_boot_loc_adr {
 	struct cvmx_mio_boot_loc_adr_s        cn68xx;
 	struct cvmx_mio_boot_loc_adr_s        cn68xxp1;
 	struct cvmx_mio_boot_loc_adr_s        cn70xx;
+	struct cvmx_mio_boot_loc_adr_s        cn70xxp1;
 	struct cvmx_mio_boot_loc_adr_s        cn78xx;
 	struct cvmx_mio_boot_loc_adr_s        cnf71xx;
 };
@@ -2757,6 +2763,7 @@ union cvmx_mio_boot_loc_cfgx {
 	struct cvmx_mio_boot_loc_cfgx_s       cn68xx;
 	struct cvmx_mio_boot_loc_cfgx_s       cn68xxp1;
 	struct cvmx_mio_boot_loc_cfgx_s       cn70xx;
+	struct cvmx_mio_boot_loc_cfgx_s       cn70xxp1;
 	struct cvmx_mio_boot_loc_cfgx_s       cn78xx;
 	struct cvmx_mio_boot_loc_cfgx_s       cnf71xx;
 };
@@ -2795,6 +2802,7 @@ union cvmx_mio_boot_loc_dat {
 	struct cvmx_mio_boot_loc_dat_s        cn68xx;
 	struct cvmx_mio_boot_loc_dat_s        cn68xxp1;
 	struct cvmx_mio_boot_loc_dat_s        cn70xx;
+	struct cvmx_mio_boot_loc_dat_s        cn70xxp1;
 	struct cvmx_mio_boot_loc_dat_s        cn78xx;
 	struct cvmx_mio_boot_loc_dat_s        cnf71xx;
 };
@@ -2933,6 +2941,7 @@ union cvmx_mio_boot_pin_defs {
 	uint64_t reserved_33_63               : 31;
 #endif
 	} cn70xx;
+	struct cvmx_mio_boot_pin_defs_cn70xx  cn70xxp1;
 	struct cvmx_mio_boot_pin_defs_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_54_63               : 10;
@@ -3115,6 +3124,7 @@ union cvmx_mio_boot_reg_cfgx {
 	struct cvmx_mio_boot_reg_cfgx_s       cn68xx;
 	struct cvmx_mio_boot_reg_cfgx_s       cn68xxp1;
 	struct cvmx_mio_boot_reg_cfgx_s       cn70xx;
+	struct cvmx_mio_boot_reg_cfgx_s       cn70xxp1;
 	struct cvmx_mio_boot_reg_cfgx_s       cn78xx;
 	struct cvmx_mio_boot_reg_cfgx_s       cnf71xx;
 };
@@ -3207,6 +3217,7 @@ union cvmx_mio_boot_reg_timx {
 	struct cvmx_mio_boot_reg_timx_s       cn68xx;
 	struct cvmx_mio_boot_reg_timx_s       cn68xxp1;
 	struct cvmx_mio_boot_reg_timx_s       cn70xx;
+	struct cvmx_mio_boot_reg_timx_s       cn70xxp1;
 	struct cvmx_mio_boot_reg_timx_s       cn78xx;
 	struct cvmx_mio_boot_reg_timx_s       cnf71xx;
 };
@@ -3267,6 +3278,7 @@ union cvmx_mio_boot_thr {
 	struct cvmx_mio_boot_thr_s            cn68xx;
 	struct cvmx_mio_boot_thr_s            cn68xxp1;
 	struct cvmx_mio_boot_thr_s            cn70xx;
+	struct cvmx_mio_boot_thr_s            cn70xxp1;
 	struct cvmx_mio_boot_thr_s            cn78xx;
 	struct cvmx_mio_boot_thr_s            cnf71xx;
 };
@@ -3280,8 +3292,8 @@ union cvmx_mio_emm_access_wdog {
 	struct cvmx_mio_emm_access_wdog_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t clk_cnt                      : 32; /**< Number of SCLKs to allow for a DMA operation to complete before hardware will halt the
-                                                         operation.
+	uint64_t clk_cnt                      : 32; /**< Number of SCLKs to allow for a DMA store operation to complete before hardware will halt
+                                                         the operation.
                                                          Hardware will inject and error on the next 512-byte block boundary.   The pending DMA
                                                          operation can be resumed or terminated. A value of zero disables timer. */
 #else
@@ -3311,6 +3323,7 @@ union cvmx_mio_emm_buf_dat {
 	} s;
 	struct cvmx_mio_emm_buf_dat_s         cn61xx;
 	struct cvmx_mio_emm_buf_dat_s         cn70xx;
+	struct cvmx_mio_emm_buf_dat_s         cn70xxp1;
 	struct cvmx_mio_emm_buf_dat_s         cn78xx;
 	struct cvmx_mio_emm_buf_dat_s         cnf71xx;
 };
@@ -3343,6 +3356,7 @@ union cvmx_mio_emm_buf_idx {
 	} s;
 	struct cvmx_mio_emm_buf_idx_s         cn61xx;
 	struct cvmx_mio_emm_buf_idx_s         cn70xx;
+	struct cvmx_mio_emm_buf_idx_s         cn70xxp1;
 	struct cvmx_mio_emm_buf_idx_s         cn78xx;
 	struct cvmx_mio_emm_buf_idx_s         cnf71xx;
 };
@@ -3393,6 +3407,7 @@ union cvmx_mio_emm_cfg {
 	} s;
 	struct cvmx_mio_emm_cfg_s             cn61xx;
 	struct cvmx_mio_emm_cfg_s             cn70xx;
+	struct cvmx_mio_emm_cfg_s             cn70xxp1;
 	struct cvmx_mio_emm_cfg_s             cn78xx;
 	struct cvmx_mio_emm_cfg_s             cnf71xx;
 };
@@ -3500,6 +3515,7 @@ union cvmx_mio_emm_cmd {
 #endif
 	} cn61xx;
 	struct cvmx_mio_emm_cmd_cn61xx        cn70xx;
+	struct cvmx_mio_emm_cmd_cn61xx        cn70xxp1;
 	struct cvmx_mio_emm_cmd_s             cn78xx;
 	struct cvmx_mio_emm_cmd_cn61xx        cnf71xx;
 };
@@ -3599,6 +3615,7 @@ union cvmx_mio_emm_dma {
 #endif
 	} cn61xx;
 	struct cvmx_mio_emm_dma_cn61xx        cn70xx;
+	struct cvmx_mio_emm_dma_cn61xx        cn70xxp1;
 	struct cvmx_mio_emm_dma_s             cn78xx;
 	struct cvmx_mio_emm_dma_cn61xx        cnf71xx;
 };
@@ -3628,8 +3645,8 @@ typedef union cvmx_mio_emm_dma_adr cvmx_mio_emm_dma_adr_t;
 /**
  * cvmx_mio_emm_dma_cfg
  *
- * This register controls the internal DMA engine used with the eMMC/SD flash controller.
- * Sixty-four-bit operations must be used to access this register.
+ * This register controls the internal DMA engine used with the eMMC/SD flash controller. Sixty-
+ * four-bit operations must be used to access this register.
  */
 union cvmx_mio_emm_dma_cfg {
 	uint64_t u64;
@@ -3667,9 +3684,8 @@ typedef union cvmx_mio_emm_dma_cfg cvmx_mio_emm_dma_cfg_t;
  * cvmx_mio_emm_dma_fifo_adr
  *
  * This register specifies the internal address that is loaded into the eMMC internal DMA FIFO.
- * The FIFO is used to
- * queue up operations for the MIO_EMM_DMA_CFG/MIO_EMM_DMA_ADR when the DMA completes
- * successfully.
+ * The FIFO is used to queue up operations for the MIO_EMM_DMA_CFG/MIO_EMM_DMA_ADR when the DMA
+ * completes successfully.
  */
 union cvmx_mio_emm_dma_fifo_adr {
 	uint64_t u64;
@@ -3697,17 +3713,16 @@ union cvmx_mio_emm_dma_fifo_cfg {
 	struct cvmx_mio_emm_dma_fifo_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_17_63               : 47;
-	uint64_t clr                          : 1;  /**< DMA FIFO Clear.  When set erases all commands in the DMA FIFO.  Must be zero for normal operation. */
+	uint64_t clr                          : 1;  /**< DMA FIFO Clear. When set erases all commands in the DMA FIFO. Must be zero for normal operation. */
 	uint64_t reserved_13_15               : 3;
-	uint64_t int_lvl                      : 5;  /**< Interrupt threshold that specifes the number of entries remaining in the DMA FIFO.  A
-                                                         value of 16 or more
-                                                         disables the interrupt.  See MIO_EMM_DMA_INT[FIFO]. */
+	uint64_t int_lvl                      : 5;  /**< Interrupt threshold that specifies the number of entries remaining in the DMA FIFO. A
+                                                         value of 16 or more disables the interrupt. See MIO_EMM_DMA_INT[FIFO]. */
 	uint64_t reserved_5_7                 : 3;
-	uint64_t count                        : 5;  /**< Number of entries in the DMA FIFO.  This count is incremented by writes to the
-                                                         MIO_EMM_DMA_FIFO_CMD register and
-                                                         decremented each time the internal DMA engine completes the previous command successfully.
-                                                         Up to 16 entries
-                                                         can be placed in the FIFO.  Entries written to a full FIFO will be ignored. */
+	uint64_t count                        : 5;  /**< Number of entries in the DMA FIFO. This count is incremented by writes to the
+                                                         MIO_EMM_DMA_FIFO_CMD register and decremented each time the internal DMA engine completes
+                                                         the previous command successfully.
+                                                         Up to 16 entries can be placed in the FIFO. Entries written to a full FIFO will be
+                                                         ignored. */
 #else
 	uint64_t count                        : 5;
 	uint64_t reserved_5_7                 : 3;
@@ -3726,11 +3741,10 @@ typedef union cvmx_mio_emm_dma_fifo_cfg cvmx_mio_emm_dma_fifo_cfg_t;
  *
  * This register specifies a command that is loaded into the eMMC internal DMA FIFO.  The FIFO is
  * used to queue up operations for the MIO_EMM_DMA_CFG/MIO_EMM_DMA_ADR when the DMA completes
- * successfully.  Writes to this register store both the MIO_EMM_DMA_FIFO_CMD and the
+ * successfully. Writes to this register store both the MIO_EMM_DMA_FIFO_CMD and the
  * MIO_EMM_DMA_FIFO_ADR contents into the FIFO and increment the MIO_DMA_FIFO_CFG[COUNT] field.
- * Note:  This register has a similar format to the MIO_EMM_DMA_CFG register
- * with the exception that the EN and CLR fields are absent.  These are supported in the
- * MIO_EMM_DMA_FIFO_CFG.
+ * Note: This register has a similar format to the MIO_EMM_DMA_CFG register with the exception
+ * that the EN and CLR fields are absent. These are supported in the MIO_EMM_DMA_FIFO_CFG.
  */
 union cvmx_mio_emm_dma_fifo_cmd {
 	uint64_t u64;
@@ -3773,7 +3787,7 @@ union cvmx_mio_emm_dma_int {
 	struct cvmx_mio_emm_dma_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
-	uint64_t fifo                         : 1;  /**< Internal DMA FIFO has dropped to level specified by MIO_DMA_FIFO_CFG[INT_LVL].  Throws
+	uint64_t fifo                         : 1;  /**< Internal DMA FIFO has dropped to level specified by MIO_DMA_FIFO_CFG[INT_LVL]. Throws
                                                          MIO_EMM_INTSN_E::MIO_EMM_DMA_FIFO. */
 	uint64_t done                         : 1;  /**< Internal DMA engine request completion interrupt. Throws
                                                          MIO_EMM_INTSN_E::MIO_EMM_DMA_DONE. */
@@ -3823,6 +3837,7 @@ union cvmx_mio_emm_int {
 	} s;
 	struct cvmx_mio_emm_int_s             cn61xx;
 	struct cvmx_mio_emm_int_s             cn70xx;
+	struct cvmx_mio_emm_int_s             cn70xxp1;
 	struct cvmx_mio_emm_int_s             cn78xx;
 	struct cvmx_mio_emm_int_s             cnf71xx;
 };
@@ -3861,6 +3876,7 @@ union cvmx_mio_emm_int_en {
 	} s;
 	struct cvmx_mio_emm_int_en_s          cn61xx;
 	struct cvmx_mio_emm_int_en_s          cn70xx;
+	struct cvmx_mio_emm_int_en_s          cn70xxp1;
 	struct cvmx_mio_emm_int_en_s          cnf71xx;
 };
 typedef union cvmx_mio_emm_int_en cvmx_mio_emm_int_en_t;
@@ -3909,6 +3925,7 @@ union cvmx_mio_emm_modex {
 	} s;
 	struct cvmx_mio_emm_modex_s           cn61xx;
 	struct cvmx_mio_emm_modex_s           cn70xx;
+	struct cvmx_mio_emm_modex_s           cn70xxp1;
 	struct cvmx_mio_emm_modex_s           cn78xx;
 	struct cvmx_mio_emm_modex_s           cnf71xx;
 };
@@ -3932,6 +3949,7 @@ union cvmx_mio_emm_rca {
 	} s;
 	struct cvmx_mio_emm_rca_s             cn61xx;
 	struct cvmx_mio_emm_rca_s             cn70xx;
+	struct cvmx_mio_emm_rca_s             cn70xxp1;
 	struct cvmx_mio_emm_rca_s             cn78xx;
 	struct cvmx_mio_emm_rca_s             cnf71xx;
 };
@@ -3960,6 +3978,7 @@ union cvmx_mio_emm_rsp_hi {
 	} s;
 	struct cvmx_mio_emm_rsp_hi_s          cn61xx;
 	struct cvmx_mio_emm_rsp_hi_s          cn70xx;
+	struct cvmx_mio_emm_rsp_hi_s          cn70xxp1;
 	struct cvmx_mio_emm_rsp_hi_s          cn78xx;
 	struct cvmx_mio_emm_rsp_hi_s          cnf71xx;
 };
@@ -4020,6 +4039,7 @@ union cvmx_mio_emm_rsp_lo {
 	} s;
 	struct cvmx_mio_emm_rsp_lo_s          cn61xx;
 	struct cvmx_mio_emm_rsp_lo_s          cn70xx;
+	struct cvmx_mio_emm_rsp_lo_s          cn70xxp1;
 	struct cvmx_mio_emm_rsp_lo_s          cn78xx;
 	struct cvmx_mio_emm_rsp_lo_s          cnf71xx;
 };
@@ -4048,7 +4068,7 @@ union cvmx_mio_emm_rsp_sts {
                                                          SW can terminate the transfer by writing MIO_EMM_DMA[DMA_VAL]=1
                                                          and MIO_EMM_DMA[DAT_NULL]=1.   HW will clear DMA_PEND and
                                                          perform the DMA operation. */
-	uint64_t acc_timeout                  : 1;  /**< The DMA store operation took longer than MIO_EMM_ACCESS_WDOG[CLK_CNT] sclks to complete.
+	uint64_t acc_timeout                  : 1;  /**< The DMA store operation took longer than MIO_EMM_ACCESS_WDOG[CLK_CNT] SCLKs to complete.
                                                          Valid when DMA_PEND=1. */
 	uint64_t reserved_29_54               : 26;
 	uint64_t dbuf_err                     : 1;  /**< For CMD_TYPE=1, indicates a DMA read data arrived from card
@@ -4187,6 +4207,7 @@ union cvmx_mio_emm_rsp_sts {
 #endif
 	} cn61xx;
 	struct cvmx_mio_emm_rsp_sts_cn61xx    cn70xx;
+	struct cvmx_mio_emm_rsp_sts_cn61xx    cn70xxp1;
 	struct cvmx_mio_emm_rsp_sts_s         cn78xx;
 	struct cvmx_mio_emm_rsp_sts_cn61xx    cnf71xx;
 };
@@ -4214,6 +4235,7 @@ union cvmx_mio_emm_sample {
 	} s;
 	struct cvmx_mio_emm_sample_s          cn61xx;
 	struct cvmx_mio_emm_sample_s          cn70xx;
+	struct cvmx_mio_emm_sample_s          cn70xxp1;
 	struct cvmx_mio_emm_sample_s          cn78xx;
 	struct cvmx_mio_emm_sample_s          cnf71xx;
 };
@@ -4236,6 +4258,7 @@ union cvmx_mio_emm_sts_mask {
 	} s;
 	struct cvmx_mio_emm_sts_mask_s        cn61xx;
 	struct cvmx_mio_emm_sts_mask_s        cn70xx;
+	struct cvmx_mio_emm_sts_mask_s        cn70xxp1;
 	struct cvmx_mio_emm_sts_mask_s        cn78xx;
 	struct cvmx_mio_emm_sts_mask_s        cnf71xx;
 };
@@ -4305,6 +4328,7 @@ union cvmx_mio_emm_switch {
 	} s;
 	struct cvmx_mio_emm_switch_s          cn61xx;
 	struct cvmx_mio_emm_switch_s          cn70xx;
+	struct cvmx_mio_emm_switch_s          cn70xxp1;
 	struct cvmx_mio_emm_switch_s          cn78xx;
 	struct cvmx_mio_emm_switch_s          cnf71xx;
 };
@@ -4330,6 +4354,7 @@ union cvmx_mio_emm_wdog {
 	} s;
 	struct cvmx_mio_emm_wdog_s            cn61xx;
 	struct cvmx_mio_emm_wdog_s            cn70xx;
+	struct cvmx_mio_emm_wdog_s            cn70xxp1;
 	struct cvmx_mio_emm_wdog_s            cn78xx;
 	struct cvmx_mio_emm_wdog_s            cnf71xx;
 };
@@ -4366,6 +4391,7 @@ union cvmx_mio_fus_bnk_datx {
 	struct cvmx_mio_fus_bnk_datx_s        cn68xx;
 	struct cvmx_mio_fus_bnk_datx_s        cn68xxp1;
 	struct cvmx_mio_fus_bnk_datx_s        cn70xx;
+	struct cvmx_mio_fus_bnk_datx_s        cn70xxp1;
 	struct cvmx_mio_fus_bnk_datx_s        cn78xx;
 	struct cvmx_mio_fus_bnk_datx_s        cnf71xx;
 };
@@ -4403,6 +4429,7 @@ union cvmx_mio_fus_dat0 {
 	struct cvmx_mio_fus_dat0_s            cn68xx;
 	struct cvmx_mio_fus_dat0_s            cn68xxp1;
 	struct cvmx_mio_fus_dat0_s            cn70xx;
+	struct cvmx_mio_fus_dat0_s            cn70xxp1;
 	struct cvmx_mio_fus_dat0_s            cn78xx;
 	struct cvmx_mio_fus_dat0_s            cnf71xx;
 };
@@ -4440,6 +4467,7 @@ union cvmx_mio_fus_dat1 {
 	struct cvmx_mio_fus_dat1_s            cn68xx;
 	struct cvmx_mio_fus_dat1_s            cn68xxp1;
 	struct cvmx_mio_fus_dat1_s            cn70xx;
+	struct cvmx_mio_fus_dat1_s            cn70xxp1;
 	struct cvmx_mio_fus_dat1_s            cn78xx;
 	struct cvmx_mio_fus_dat1_s            cnf71xx;
 };
@@ -4890,6 +4918,7 @@ union cvmx_mio_fus_dat2 {
 	uint64_t reserved_48_63               : 16;
 #endif
 	} cn70xx;
+	struct cvmx_mio_fus_dat2_cn70xx       cn70xxp1;
 	struct cvmx_mio_fus_dat2_cn70xx       cn78xx;
 	struct cvmx_mio_fus_dat2_cn61xx       cnf71xx;
 };
@@ -4915,8 +4944,7 @@ union cvmx_mio_fus_dat3 {
 	uint64_t l2c_crip                     : 3;  /**< Fuse information - L2C Cripple (1/8, 1/4, 1/2) */
 	uint64_t pll_div4                     : 1;  /**< Fuse information - PLL DIV4 mode
                                                          (laser fuse only) */
-	uint64_t reserved_29_30               : 2;
-	uint64_t bar2_en                      : 1;  /**< Fuse information - BAR2 Present (when blown '1') */
+	uint64_t reserved_28_30               : 3;
 	uint64_t efus_lck                     : 1;  /**< Fuse information - efuse lockdown */
 	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore */
 	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable */
@@ -4928,8 +4956,7 @@ union cvmx_mio_fus_dat3 {
 	uint64_t nozip                        : 1;
 	uint64_t efus_ign                     : 1;
 	uint64_t efus_lck                     : 1;
-	uint64_t bar2_en                      : 1;
-	uint64_t reserved_29_30               : 2;
+	uint64_t reserved_28_30               : 3;
 	uint64_t pll_div4                     : 1;
 	uint64_t l2c_crip                     : 3;
 	uint64_t pll_half_dis                 : 1;
@@ -5127,7 +5154,7 @@ union cvmx_mio_fus_dat3 {
                                                          4-7 -- illegal */
 	uint64_t reserved_31_31               : 1;
 	uint64_t zip_info                     : 2;  /**< Fuse information - Zip information */
-	uint64_t bar2_en                      : 1;  /**< Fuse information - BAR2 present (when blown `1') */
+	uint64_t bar2_sz_conf                 : 1;  /**< Fuse information - When 0, BAR2 size conforms to PCIE specification. */
 	uint64_t efus_lck                     : 1;  /**< Fuse information - efuse lockdown */
 	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore */
 	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable */
@@ -5142,7 +5169,7 @@ union cvmx_mio_fus_dat3 {
 	uint64_t nozip                        : 1;
 	uint64_t efus_ign                     : 1;
 	uint64_t efus_lck                     : 1;
-	uint64_t bar2_en                      : 1;
+	uint64_t bar2_sz_conf                 : 1;
 	uint64_t zip_info                     : 2;
 	uint64_t reserved_31_31               : 1;
 	uint64_t l2c_crip                     : 3;
@@ -5156,6 +5183,7 @@ union cvmx_mio_fus_dat3 {
 	uint64_t ema0                         : 6;
 #endif
 	} cn70xx;
+	struct cvmx_mio_fus_dat3_cn70xx       cn70xxp1;
 	struct cvmx_mio_fus_dat3_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t ema0                         : 6;  /**< Fuse information - EMA0. INTERNAL: dflt value is 0x02. Soft or hard blow of these fuses
@@ -5175,7 +5203,7 @@ union cvmx_mio_fus_dat3 {
                                                          0x4-0x7 = Reserved */
 	uint64_t reserved_31_31               : 1;
 	uint64_t zip_info                     : 2;  /**< Fuse information - Zip information. */
-	uint64_t bar2_en                      : 1;  /**< Fuse information - BAR2 present (when blown `1'). */
+	uint64_t bar2_sz_conf                 : 1;  /**< Fuse information - When 0, BAR2 size conforms to PCIE specification. */
 	uint64_t efus_lck                     : 1;  /**< Fuse information - efuse lockdown. */
 	uint64_t efus_ign                     : 1;  /**< Fuse information - efuse ignore. */
 	uint64_t nozip                        : 1;  /**< Fuse information - ZIP disable. */
@@ -5196,7 +5224,7 @@ union cvmx_mio_fus_dat3 {
 	uint64_t nozip                        : 1;
 	uint64_t efus_ign                     : 1;
 	uint64_t efus_lck                     : 1;
-	uint64_t bar2_en                      : 1;
+	uint64_t bar2_sz_conf                 : 1;
 	uint64_t zip_info                     : 2;
 	uint64_t reserved_31_31               : 1;
 	uint64_t l2c_crip                     : 3;
@@ -5245,6 +5273,7 @@ union cvmx_mio_fus_dat4 {
 #endif
 	} s;
 	struct cvmx_mio_fus_dat4_s            cn70xx;
+	struct cvmx_mio_fus_dat4_s            cn70xxp1;
 	struct cvmx_mio_fus_dat4_s            cn78xx;
 };
 typedef union cvmx_mio_fus_dat4 cvmx_mio_fus_dat4_t;
@@ -5312,6 +5341,7 @@ union cvmx_mio_fus_int {
 #endif
 	} s;
 	struct cvmx_mio_fus_int_s             cn70xx;
+	struct cvmx_mio_fus_int_s             cn70xxp1;
 	struct cvmx_mio_fus_int_s             cn78xx;
 };
 typedef union cvmx_mio_fus_int cvmx_mio_fus_int_t;
@@ -5341,6 +5371,7 @@ union cvmx_mio_fus_pdf {
 	struct cvmx_mio_fus_pdf_s             cn68xx;
 	struct cvmx_mio_fus_pdf_s             cn68xxp1;
 	struct cvmx_mio_fus_pdf_s             cn70xx;
+	struct cvmx_mio_fus_pdf_s             cn70xxp1;
 	struct cvmx_mio_fus_pdf_s             cn78xx;
 	struct cvmx_mio_fus_pdf_s             cnf71xx;
 };
@@ -5497,6 +5528,7 @@ union cvmx_mio_fus_pll {
 	uint64_t reserved_15_63               : 49;
 #endif
 	} cn70xx;
+	struct cvmx_mio_fus_pll_cn70xx        cn70xxp1;
 	struct cvmx_mio_fus_pll_cn70xx        cn78xx;
 	struct cvmx_mio_fus_pll_cn61xx        cnf71xx;
 };
@@ -5584,6 +5616,7 @@ union cvmx_mio_fus_prog {
 	uint64_t reserved_2_63                : 62;
 #endif
 	} cn70xx;
+	struct cvmx_mio_fus_prog_cn70xx       cn70xxp1;
 	struct cvmx_mio_fus_prog_cn70xx       cn78xx;
 	struct cvmx_mio_fus_prog_cn61xx       cnf71xx;
 };
@@ -5714,6 +5747,7 @@ union cvmx_mio_fus_prog_times {
 	uint64_t reserved_35_63               : 29;
 #endif
 	} cn70xx;
+	struct cvmx_mio_fus_prog_times_cn70xx cn70xxp1;
 	struct cvmx_mio_fus_prog_times_cn70xx cn78xx;
 	struct cvmx_mio_fus_prog_times_cn61xx cnf71xx;
 };
@@ -5816,6 +5850,7 @@ union cvmx_mio_fus_rcmd {
 	struct cvmx_mio_fus_rcmd_cn52xx       cn68xx;
 	struct cvmx_mio_fus_rcmd_cn52xx       cn68xxp1;
 	struct cvmx_mio_fus_rcmd_s            cn70xx;
+	struct cvmx_mio_fus_rcmd_s            cn70xxp1;
 	struct cvmx_mio_fus_rcmd_s            cn78xx;
 	struct cvmx_mio_fus_rcmd_cn52xx       cnf71xx;
 };
@@ -5926,6 +5961,7 @@ union cvmx_mio_fus_read_times {
 	uint64_t reserved_32_63               : 32;
 #endif
 	} cn70xx;
+	struct cvmx_mio_fus_read_times_cn70xx cn70xxp1;
 	struct cvmx_mio_fus_read_times_cn70xx cn78xx;
 	struct cvmx_mio_fus_read_times_cn61xx cnf71xx;
 };
@@ -6027,6 +6063,7 @@ union cvmx_mio_fus_rpr_datx {
 #endif
 	} s;
 	struct cvmx_mio_fus_rpr_datx_s        cn70xx;
+	struct cvmx_mio_fus_rpr_datx_s        cn70xxp1;
 	struct cvmx_mio_fus_rpr_datx_s        cn78xx;
 };
 typedef union cvmx_mio_fus_rpr_datx cvmx_mio_fus_rpr_datx_t;
@@ -6059,6 +6096,7 @@ union cvmx_mio_fus_soft_repair {
 #endif
 	} s;
 	struct cvmx_mio_fus_soft_repair_s     cn70xx;
+	struct cvmx_mio_fus_soft_repair_s     cn70xxp1;
 	struct cvmx_mio_fus_soft_repair_s     cn78xx;
 };
 typedef union cvmx_mio_fus_soft_repair cvmx_mio_fus_soft_repair_t;
@@ -6184,6 +6222,7 @@ union cvmx_mio_fus_tgg {
 	struct cvmx_mio_fus_tgg_s             cn61xx;
 	struct cvmx_mio_fus_tgg_s             cn66xx;
 	struct cvmx_mio_fus_tgg_s             cn70xx;
+	struct cvmx_mio_fus_tgg_s             cn70xxp1;
 	struct cvmx_mio_fus_tgg_s             cn78xx;
 	struct cvmx_mio_fus_tgg_s             cnf71xx;
 };
@@ -6273,6 +6312,7 @@ union cvmx_mio_fus_wadr {
 	uint64_t reserved_6_63                : 58;
 #endif
 	} cn70xx;
+	struct cvmx_mio_fus_wadr_cn70xx       cn70xxp1;
 	struct cvmx_mio_fus_wadr_cn70xx       cn78xx;
 	struct cvmx_mio_fus_wadr_cn61xx       cnf71xx;
 };
@@ -6325,6 +6365,7 @@ union cvmx_mio_gpio_comp {
 	uint64_t reserved_11_63               : 53;
 #endif
 	} cn70xx;
+	struct cvmx_mio_gpio_comp_cn70xx      cn70xxp1;
 	struct cvmx_mio_gpio_comp_cn61xx      cnf71xx;
 };
 typedef union cvmx_mio_gpio_comp cvmx_mio_gpio_comp_t;
@@ -6370,6 +6411,7 @@ union cvmx_mio_ndf_dma_cfg {
 	struct cvmx_mio_ndf_dma_cfg_s         cn68xx;
 	struct cvmx_mio_ndf_dma_cfg_s         cn68xxp1;
 	struct cvmx_mio_ndf_dma_cfg_s         cn70xx;
+	struct cvmx_mio_ndf_dma_cfg_s         cn70xxp1;
 	struct cvmx_mio_ndf_dma_cfg_s         cnf71xx;
 };
 typedef union cvmx_mio_ndf_dma_cfg cvmx_mio_ndf_dma_cfg_t;
@@ -6399,6 +6441,7 @@ union cvmx_mio_ndf_dma_int {
 	struct cvmx_mio_ndf_dma_int_s         cn68xx;
 	struct cvmx_mio_ndf_dma_int_s         cn68xxp1;
 	struct cvmx_mio_ndf_dma_int_s         cn70xx;
+	struct cvmx_mio_ndf_dma_int_s         cn70xxp1;
 	struct cvmx_mio_ndf_dma_int_s         cnf71xx;
 };
 typedef union cvmx_mio_ndf_dma_int cvmx_mio_ndf_dma_int_t;
@@ -6428,6 +6471,7 @@ union cvmx_mio_ndf_dma_int_en {
 	struct cvmx_mio_ndf_dma_int_en_s      cn68xx;
 	struct cvmx_mio_ndf_dma_int_en_s      cn68xxp1;
 	struct cvmx_mio_ndf_dma_int_en_s      cn70xx;
+	struct cvmx_mio_ndf_dma_int_en_s      cn70xxp1;
 	struct cvmx_mio_ndf_dma_int_en_s      cnf71xx;
 };
 typedef union cvmx_mio_ndf_dma_int_en cvmx_mio_ndf_dma_int_en_t;
@@ -6491,6 +6535,7 @@ union cvmx_mio_ptp_ckout_hi_incr {
 	struct cvmx_mio_ptp_ckout_hi_incr_s   cn66xx;
 	struct cvmx_mio_ptp_ckout_hi_incr_s   cn68xx;
 	struct cvmx_mio_ptp_ckout_hi_incr_s   cn70xx;
+	struct cvmx_mio_ptp_ckout_hi_incr_s   cn70xxp1;
 	struct cvmx_mio_ptp_ckout_hi_incr_s   cn78xx;
 	struct cvmx_mio_ptp_ckout_hi_incr_s   cnf71xx;
 };
@@ -6517,6 +6562,7 @@ union cvmx_mio_ptp_ckout_lo_incr {
 	struct cvmx_mio_ptp_ckout_lo_incr_s   cn66xx;
 	struct cvmx_mio_ptp_ckout_lo_incr_s   cn68xx;
 	struct cvmx_mio_ptp_ckout_lo_incr_s   cn70xx;
+	struct cvmx_mio_ptp_ckout_lo_incr_s   cn70xxp1;
 	struct cvmx_mio_ptp_ckout_lo_incr_s   cn78xx;
 	struct cvmx_mio_ptp_ckout_lo_incr_s   cnf71xx;
 };
@@ -6542,6 +6588,7 @@ union cvmx_mio_ptp_ckout_thresh_hi {
 	struct cvmx_mio_ptp_ckout_thresh_hi_s cn66xx;
 	struct cvmx_mio_ptp_ckout_thresh_hi_s cn68xx;
 	struct cvmx_mio_ptp_ckout_thresh_hi_s cn70xx;
+	struct cvmx_mio_ptp_ckout_thresh_hi_s cn70xxp1;
 	struct cvmx_mio_ptp_ckout_thresh_hi_s cn78xx;
 	struct cvmx_mio_ptp_ckout_thresh_hi_s cnf71xx;
 };
@@ -6568,6 +6615,7 @@ union cvmx_mio_ptp_ckout_thresh_lo {
 	struct cvmx_mio_ptp_ckout_thresh_lo_s cn66xx;
 	struct cvmx_mio_ptp_ckout_thresh_lo_s cn68xx;
 	struct cvmx_mio_ptp_ckout_thresh_lo_s cn70xx;
+	struct cvmx_mio_ptp_ckout_thresh_lo_s cn70xxp1;
 	struct cvmx_mio_ptp_ckout_thresh_lo_s cn78xx;
 	struct cvmx_mio_ptp_ckout_thresh_lo_s cnf71xx;
 };
@@ -6906,6 +6954,7 @@ union cvmx_mio_ptp_clock_cfg {
 	uint64_t reserved_42_63               : 22;
 #endif
 	} cn70xx;
+	struct cvmx_mio_ptp_clock_cfg_cn70xx  cn70xxp1;
 	struct cvmx_mio_ptp_clock_cfg_cn70xx  cn78xx;
 	struct cvmx_mio_ptp_clock_cfg_s       cnf71xx;
 };
@@ -6935,6 +6984,7 @@ union cvmx_mio_ptp_clock_comp {
 	struct cvmx_mio_ptp_clock_comp_s      cn68xx;
 	struct cvmx_mio_ptp_clock_comp_s      cn68xxp1;
 	struct cvmx_mio_ptp_clock_comp_s      cn70xx;
+	struct cvmx_mio_ptp_clock_comp_s      cn70xxp1;
 	struct cvmx_mio_ptp_clock_comp_s      cn78xx;
 	struct cvmx_mio_ptp_clock_comp_s      cnf71xx;
 };
@@ -6963,6 +7013,7 @@ union cvmx_mio_ptp_clock_hi {
 	struct cvmx_mio_ptp_clock_hi_s        cn68xx;
 	struct cvmx_mio_ptp_clock_hi_s        cn68xxp1;
 	struct cvmx_mio_ptp_clock_hi_s        cn70xx;
+	struct cvmx_mio_ptp_clock_hi_s        cn70xxp1;
 	struct cvmx_mio_ptp_clock_hi_s        cn78xx;
 	struct cvmx_mio_ptp_clock_hi_s        cnf71xx;
 };
@@ -6992,6 +7043,7 @@ union cvmx_mio_ptp_clock_lo {
 	struct cvmx_mio_ptp_clock_lo_s        cn68xx;
 	struct cvmx_mio_ptp_clock_lo_s        cn68xxp1;
 	struct cvmx_mio_ptp_clock_lo_s        cn70xx;
+	struct cvmx_mio_ptp_clock_lo_s        cn70xxp1;
 	struct cvmx_mio_ptp_clock_lo_s        cn78xx;
 	struct cvmx_mio_ptp_clock_lo_s        cnf71xx;
 };
@@ -7084,6 +7136,7 @@ union cvmx_mio_ptp_evt_cnt {
 	struct cvmx_mio_ptp_evt_cnt_s         cn68xx;
 	struct cvmx_mio_ptp_evt_cnt_s         cn68xxp1;
 	struct cvmx_mio_ptp_evt_cnt_s         cn70xx;
+	struct cvmx_mio_ptp_evt_cnt_s         cn70xxp1;
 	struct cvmx_mio_ptp_evt_cnt_s         cn78xx;
 	struct cvmx_mio_ptp_evt_cnt_s         cnf71xx;
 };
@@ -7158,6 +7211,7 @@ union cvmx_mio_ptp_pps_hi_incr {
 	struct cvmx_mio_ptp_pps_hi_incr_s     cn66xx;
 	struct cvmx_mio_ptp_pps_hi_incr_s     cn68xx;
 	struct cvmx_mio_ptp_pps_hi_incr_s     cn70xx;
+	struct cvmx_mio_ptp_pps_hi_incr_s     cn70xxp1;
 	struct cvmx_mio_ptp_pps_hi_incr_s     cn78xx;
 	struct cvmx_mio_ptp_pps_hi_incr_s     cnf71xx;
 };
@@ -7184,6 +7238,7 @@ union cvmx_mio_ptp_pps_lo_incr {
 	struct cvmx_mio_ptp_pps_lo_incr_s     cn66xx;
 	struct cvmx_mio_ptp_pps_lo_incr_s     cn68xx;
 	struct cvmx_mio_ptp_pps_lo_incr_s     cn70xx;
+	struct cvmx_mio_ptp_pps_lo_incr_s     cn70xxp1;
 	struct cvmx_mio_ptp_pps_lo_incr_s     cn78xx;
 	struct cvmx_mio_ptp_pps_lo_incr_s     cnf71xx;
 };
@@ -7209,6 +7264,7 @@ union cvmx_mio_ptp_pps_thresh_hi {
 	struct cvmx_mio_ptp_pps_thresh_hi_s   cn66xx;
 	struct cvmx_mio_ptp_pps_thresh_hi_s   cn68xx;
 	struct cvmx_mio_ptp_pps_thresh_hi_s   cn70xx;
+	struct cvmx_mio_ptp_pps_thresh_hi_s   cn70xxp1;
 	struct cvmx_mio_ptp_pps_thresh_hi_s   cn78xx;
 	struct cvmx_mio_ptp_pps_thresh_hi_s   cnf71xx;
 };
@@ -7235,6 +7291,7 @@ union cvmx_mio_ptp_pps_thresh_lo {
 	struct cvmx_mio_ptp_pps_thresh_lo_s   cn66xx;
 	struct cvmx_mio_ptp_pps_thresh_lo_s   cn68xx;
 	struct cvmx_mio_ptp_pps_thresh_lo_s   cn70xx;
+	struct cvmx_mio_ptp_pps_thresh_lo_s   cn70xxp1;
 	struct cvmx_mio_ptp_pps_thresh_lo_s   cn78xx;
 	struct cvmx_mio_ptp_pps_thresh_lo_s   cnf71xx;
 };
@@ -7262,6 +7319,7 @@ union cvmx_mio_ptp_timestamp {
 	struct cvmx_mio_ptp_timestamp_s       cn68xx;
 	struct cvmx_mio_ptp_timestamp_s       cn68xxp1;
 	struct cvmx_mio_ptp_timestamp_s       cn70xx;
+	struct cvmx_mio_ptp_timestamp_s       cn70xxp1;
 	struct cvmx_mio_ptp_timestamp_s       cn78xx;
 	struct cvmx_mio_ptp_timestamp_s       cnf71xx;
 };
@@ -8821,6 +8879,7 @@ union cvmx_mio_twsx_int {
 	struct cvmx_mio_twsx_int_s            cn68xx;
 	struct cvmx_mio_twsx_int_s            cn68xxp1;
 	struct cvmx_mio_twsx_int_s            cn70xx;
+	struct cvmx_mio_twsx_int_s            cn70xxp1;
 	struct cvmx_mio_twsx_int_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
@@ -8983,6 +9042,7 @@ union cvmx_mio_twsx_sw_twsi {
 	struct cvmx_mio_twsx_sw_twsi_s        cn68xx;
 	struct cvmx_mio_twsx_sw_twsi_s        cn68xxp1;
 	struct cvmx_mio_twsx_sw_twsi_s        cn70xx;
+	struct cvmx_mio_twsx_sw_twsi_s        cn70xxp1;
 	struct cvmx_mio_twsx_sw_twsi_s        cn78xx;
 	struct cvmx_mio_twsx_sw_twsi_s        cnf71xx;
 };
@@ -9029,6 +9089,7 @@ union cvmx_mio_twsx_sw_twsi_ext {
 	struct cvmx_mio_twsx_sw_twsi_ext_s    cn68xx;
 	struct cvmx_mio_twsx_sw_twsi_ext_s    cn68xxp1;
 	struct cvmx_mio_twsx_sw_twsi_ext_s    cn70xx;
+	struct cvmx_mio_twsx_sw_twsi_ext_s    cn70xxp1;
 	struct cvmx_mio_twsx_sw_twsi_ext_s    cn78xx;
 	struct cvmx_mio_twsx_sw_twsi_ext_s    cnf71xx;
 };
@@ -9088,6 +9149,7 @@ union cvmx_mio_twsx_twsi_sw {
 	struct cvmx_mio_twsx_twsi_sw_cn30xx   cn68xx;
 	struct cvmx_mio_twsx_twsi_sw_cn30xx   cn68xxp1;
 	struct cvmx_mio_twsx_twsi_sw_cn30xx   cn70xx;
+	struct cvmx_mio_twsx_twsi_sw_cn30xx   cn70xxp1;
 	struct cvmx_mio_twsx_twsi_sw_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t v                            : 2;  /**< Valid bits. These bits are not directly writable. They are set to 11 on any write
@@ -9146,6 +9208,7 @@ union cvmx_mio_uartx_dlh {
 	struct cvmx_mio_uartx_dlh_s           cn68xx;
 	struct cvmx_mio_uartx_dlh_s           cn68xxp1;
 	struct cvmx_mio_uartx_dlh_s           cn70xx;
+	struct cvmx_mio_uartx_dlh_s           cn70xxp1;
 	struct cvmx_mio_uartx_dlh_s           cn78xx;
 	struct cvmx_mio_uartx_dlh_s           cnf71xx;
 };
@@ -9194,6 +9257,7 @@ union cvmx_mio_uartx_dll {
 	struct cvmx_mio_uartx_dll_s           cn68xx;
 	struct cvmx_mio_uartx_dll_s           cn68xxp1;
 	struct cvmx_mio_uartx_dll_s           cn70xx;
+	struct cvmx_mio_uartx_dll_s           cn70xxp1;
 	struct cvmx_mio_uartx_dll_s           cn78xx;
 	struct cvmx_mio_uartx_dll_s           cnf71xx;
 };
@@ -9239,6 +9303,7 @@ union cvmx_mio_uartx_far {
 	struct cvmx_mio_uartx_far_s           cn68xx;
 	struct cvmx_mio_uartx_far_s           cn68xxp1;
 	struct cvmx_mio_uartx_far_s           cn70xx;
+	struct cvmx_mio_uartx_far_s           cn70xxp1;
 	struct cvmx_mio_uartx_far_s           cn78xx;
 	struct cvmx_mio_uartx_far_s           cnf71xx;
 };
@@ -9291,6 +9356,7 @@ union cvmx_mio_uartx_fcr {
 	struct cvmx_mio_uartx_fcr_s           cn68xx;
 	struct cvmx_mio_uartx_fcr_s           cn68xxp1;
 	struct cvmx_mio_uartx_fcr_s           cn70xx;
+	struct cvmx_mio_uartx_fcr_s           cn70xxp1;
 	struct cvmx_mio_uartx_fcr_s           cn78xx;
 	struct cvmx_mio_uartx_fcr_s           cnf71xx;
 };
@@ -9333,6 +9399,7 @@ union cvmx_mio_uartx_htx {
 	struct cvmx_mio_uartx_htx_s           cn68xx;
 	struct cvmx_mio_uartx_htx_s           cn68xxp1;
 	struct cvmx_mio_uartx_htx_s           cn70xx;
+	struct cvmx_mio_uartx_htx_s           cn70xxp1;
 	struct cvmx_mio_uartx_htx_s           cn78xx;
 	struct cvmx_mio_uartx_htx_s           cnf71xx;
 };
@@ -9344,9 +9411,9 @@ typedef cvmx_mio_uartx_htx_t cvmx_uart_htx_t;
  *
  * The interrupt-enable register is a read/write register that contains four bits that enable the
  * generation of interrupts:
- * * enable received data available interrupt (ERBFI)
- * * enable transmitter holding register empty interrupt (ETBEI)
- * * enable receiver line status interrupt (ELSI)
+ * * enable received data available interrupt (ERBFI).
+ * * enable transmitter holding register empty interrupt (ETBEI).
+ * * enable receiver line status interrupt (ELSI).
  * enable modem status interrupt (EDSSI).
  * The IER also contains the enable bit for the programmable transmit holding register empty
  * (THRE) interrupt mode (PTIME).
@@ -9390,6 +9457,7 @@ union cvmx_mio_uartx_ier {
 	struct cvmx_mio_uartx_ier_s           cn68xx;
 	struct cvmx_mio_uartx_ier_s           cn68xxp1;
 	struct cvmx_mio_uartx_ier_s           cn70xx;
+	struct cvmx_mio_uartx_ier_s           cn70xxp1;
 	struct cvmx_mio_uartx_ier_s           cn78xx;
 	struct cvmx_mio_uartx_ier_s           cnf71xx;
 };
@@ -9435,6 +9503,7 @@ union cvmx_mio_uartx_iir {
 	struct cvmx_mio_uartx_iir_s           cn68xx;
 	struct cvmx_mio_uartx_iir_s           cn68xxp1;
 	struct cvmx_mio_uartx_iir_s           cn70xx;
+	struct cvmx_mio_uartx_iir_s           cn70xxp1;
 	struct cvmx_mio_uartx_iir_s           cn78xx;
 	struct cvmx_mio_uartx_iir_s           cnf71xx;
 };
@@ -9488,6 +9557,7 @@ union cvmx_mio_uartx_lcr {
 	struct cvmx_mio_uartx_lcr_s           cn68xx;
 	struct cvmx_mio_uartx_lcr_s           cn68xxp1;
 	struct cvmx_mio_uartx_lcr_s           cn70xx;
+	struct cvmx_mio_uartx_lcr_s           cn70xxp1;
 	struct cvmx_mio_uartx_lcr_s           cn78xx;
 	struct cvmx_mio_uartx_lcr_s           cnf71xx;
 };
@@ -9543,6 +9613,7 @@ union cvmx_mio_uartx_lsr {
 	struct cvmx_mio_uartx_lsr_s           cn68xx;
 	struct cvmx_mio_uartx_lsr_s           cn68xxp1;
 	struct cvmx_mio_uartx_lsr_s           cn70xx;
+	struct cvmx_mio_uartx_lsr_s           cn70xxp1;
 	struct cvmx_mio_uartx_lsr_s           cn78xx;
 	struct cvmx_mio_uartx_lsr_s           cnf71xx;
 };
@@ -9595,6 +9666,7 @@ union cvmx_mio_uartx_mcr {
 	struct cvmx_mio_uartx_mcr_s           cn68xx;
 	struct cvmx_mio_uartx_mcr_s           cn68xxp1;
 	struct cvmx_mio_uartx_mcr_s           cn70xx;
+	struct cvmx_mio_uartx_mcr_s           cn70xxp1;
 	struct cvmx_mio_uartx_mcr_s           cn78xx;
 	struct cvmx_mio_uartx_mcr_s           cnf71xx;
 };
@@ -9650,6 +9722,7 @@ union cvmx_mio_uartx_msr {
 	struct cvmx_mio_uartx_msr_s           cn68xx;
 	struct cvmx_mio_uartx_msr_s           cn68xxp1;
 	struct cvmx_mio_uartx_msr_s           cn70xx;
+	struct cvmx_mio_uartx_msr_s           cn70xxp1;
 	struct cvmx_mio_uartx_msr_s           cn78xx;
 	struct cvmx_mio_uartx_msr_s           cnf71xx;
 };
@@ -9692,6 +9765,7 @@ union cvmx_mio_uartx_rbr {
 	struct cvmx_mio_uartx_rbr_s           cn68xx;
 	struct cvmx_mio_uartx_rbr_s           cn68xxp1;
 	struct cvmx_mio_uartx_rbr_s           cn70xx;
+	struct cvmx_mio_uartx_rbr_s           cn70xxp1;
 	struct cvmx_mio_uartx_rbr_s           cn78xx;
 	struct cvmx_mio_uartx_rbr_s           cnf71xx;
 };
@@ -9733,6 +9807,7 @@ union cvmx_mio_uartx_rfl {
 	struct cvmx_mio_uartx_rfl_s           cn68xx;
 	struct cvmx_mio_uartx_rfl_s           cn68xxp1;
 	struct cvmx_mio_uartx_rfl_s           cn70xx;
+	struct cvmx_mio_uartx_rfl_s           cn70xxp1;
 	struct cvmx_mio_uartx_rfl_s           cn78xx;
 	struct cvmx_mio_uartx_rfl_s           cnf71xx;
 };
@@ -9778,6 +9853,7 @@ union cvmx_mio_uartx_rfw {
 	struct cvmx_mio_uartx_rfw_s           cn68xx;
 	struct cvmx_mio_uartx_rfw_s           cn68xxp1;
 	struct cvmx_mio_uartx_rfw_s           cn70xx;
+	struct cvmx_mio_uartx_rfw_s           cn70xxp1;
 	struct cvmx_mio_uartx_rfw_s           cn78xx;
 	struct cvmx_mio_uartx_rfw_s           cnf71xx;
 };
@@ -9820,6 +9896,7 @@ union cvmx_mio_uartx_sbcr {
 	struct cvmx_mio_uartx_sbcr_s          cn68xx;
 	struct cvmx_mio_uartx_sbcr_s          cn68xxp1;
 	struct cvmx_mio_uartx_sbcr_s          cn70xx;
+	struct cvmx_mio_uartx_sbcr_s          cn70xxp1;
 	struct cvmx_mio_uartx_sbcr_s          cn78xx;
 	struct cvmx_mio_uartx_sbcr_s          cnf71xx;
 };
@@ -9861,6 +9938,7 @@ union cvmx_mio_uartx_scr {
 	struct cvmx_mio_uartx_scr_s           cn68xx;
 	struct cvmx_mio_uartx_scr_s           cn68xxp1;
 	struct cvmx_mio_uartx_scr_s           cn70xx;
+	struct cvmx_mio_uartx_scr_s           cn70xxp1;
 	struct cvmx_mio_uartx_scr_s           cn78xx;
 	struct cvmx_mio_uartx_scr_s           cnf71xx;
 };
@@ -9904,6 +9982,7 @@ union cvmx_mio_uartx_sfe {
 	struct cvmx_mio_uartx_sfe_s           cn68xx;
 	struct cvmx_mio_uartx_sfe_s           cn68xxp1;
 	struct cvmx_mio_uartx_sfe_s           cn70xx;
+	struct cvmx_mio_uartx_sfe_s           cn70xxp1;
 	struct cvmx_mio_uartx_sfe_s           cn78xx;
 	struct cvmx_mio_uartx_sfe_s           cnf71xx;
 };
@@ -9949,6 +10028,7 @@ union cvmx_mio_uartx_srr {
 	struct cvmx_mio_uartx_srr_s           cn68xx;
 	struct cvmx_mio_uartx_srr_s           cn68xxp1;
 	struct cvmx_mio_uartx_srr_s           cn70xx;
+	struct cvmx_mio_uartx_srr_s           cn70xxp1;
 	struct cvmx_mio_uartx_srr_s           cn78xx;
 	struct cvmx_mio_uartx_srr_s           cnf71xx;
 };
@@ -9992,6 +10072,7 @@ union cvmx_mio_uartx_srt {
 	struct cvmx_mio_uartx_srt_s           cn68xx;
 	struct cvmx_mio_uartx_srt_s           cn68xxp1;
 	struct cvmx_mio_uartx_srt_s           cn70xx;
+	struct cvmx_mio_uartx_srt_s           cn70xxp1;
 	struct cvmx_mio_uartx_srt_s           cn78xx;
 	struct cvmx_mio_uartx_srt_s           cnf71xx;
 };
@@ -10034,6 +10115,7 @@ union cvmx_mio_uartx_srts {
 	struct cvmx_mio_uartx_srts_s          cn68xx;
 	struct cvmx_mio_uartx_srts_s          cn68xxp1;
 	struct cvmx_mio_uartx_srts_s          cn70xx;
+	struct cvmx_mio_uartx_srts_s          cn70xxp1;
 	struct cvmx_mio_uartx_srts_s          cn78xx;
 	struct cvmx_mio_uartx_srts_s          cnf71xx;
 };
@@ -10077,6 +10159,7 @@ union cvmx_mio_uartx_stt {
 	struct cvmx_mio_uartx_stt_s           cn68xx;
 	struct cvmx_mio_uartx_stt_s           cn68xxp1;
 	struct cvmx_mio_uartx_stt_s           cn70xx;
+	struct cvmx_mio_uartx_stt_s           cn70xxp1;
 	struct cvmx_mio_uartx_stt_s           cn78xx;
 	struct cvmx_mio_uartx_stt_s           cnf71xx;
 };
@@ -10118,6 +10201,7 @@ union cvmx_mio_uartx_tfl {
 	struct cvmx_mio_uartx_tfl_s           cn68xx;
 	struct cvmx_mio_uartx_tfl_s           cn68xxp1;
 	struct cvmx_mio_uartx_tfl_s           cn70xx;
+	struct cvmx_mio_uartx_tfl_s           cn70xxp1;
 	struct cvmx_mio_uartx_tfl_s           cn78xx;
 	struct cvmx_mio_uartx_tfl_s           cnf71xx;
 };
@@ -10159,6 +10243,7 @@ union cvmx_mio_uartx_tfr {
 	struct cvmx_mio_uartx_tfr_s           cn68xx;
 	struct cvmx_mio_uartx_tfr_s           cn68xxp1;
 	struct cvmx_mio_uartx_tfr_s           cn70xx;
+	struct cvmx_mio_uartx_tfr_s           cn70xxp1;
 	struct cvmx_mio_uartx_tfr_s           cn78xx;
 	struct cvmx_mio_uartx_tfr_s           cnf71xx;
 };
@@ -10201,6 +10286,7 @@ union cvmx_mio_uartx_thr {
 	struct cvmx_mio_uartx_thr_s           cn68xx;
 	struct cvmx_mio_uartx_thr_s           cn68xxp1;
 	struct cvmx_mio_uartx_thr_s           cn70xx;
+	struct cvmx_mio_uartx_thr_s           cn70xxp1;
 	struct cvmx_mio_uartx_thr_s           cn78xx;
 	struct cvmx_mio_uartx_thr_s           cnf71xx;
 };
@@ -10250,6 +10336,7 @@ union cvmx_mio_uartx_usr {
 	struct cvmx_mio_uartx_usr_s           cn68xx;
 	struct cvmx_mio_uartx_usr_s           cn68xxp1;
 	struct cvmx_mio_uartx_usr_s           cn70xx;
+	struct cvmx_mio_uartx_usr_s           cn70xxp1;
 	struct cvmx_mio_uartx_usr_s           cn78xx;
 	struct cvmx_mio_uartx_usr_s           cnf71xx;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-mixx-defs.h b/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
index 5eb183f..d9119a2 100644
--- a/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mixx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -307,7 +307,7 @@ static inline uint64_t CVMX_MIXX_TSTAMP(unsigned long offset)
  * cvmx_mix#_bist
  *
  * This register contains the BIST status for the MIX memories: 0 = pass or never run, 1 = fail.
- * To read this register, a device issues an IOBLD64 instruction directed at the MIO.
+ *
  */
 union cvmx_mixx_bist {
 	uint64_t u64;
@@ -369,8 +369,11 @@ typedef union cvmx_mixx_bist cvmx_mixx_bist_t;
 /**
  * cvmx_mix#_ctl
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_CTL = MIX Control Register
+ *
+ * Description:
+ *  NOTE: To write to the MIX_CTL register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_CTL register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_ctl {
 	uint64_t u64;
@@ -378,9 +381,9 @@ union cvmx_mixx_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
 	uint64_t ts_thresh                    : 4;  /**< TimeStamp interrupt threshold. When the number of pending Timestamp interrupts
-                                                         (MIX(0..1)_TSCTL[TSCNT] is greater than
+                                                         (MIX(0..1)_TSCTL[TSCNT]) is greater than
                                                          MIX(0..1)_CTL[TS_THRESH], then a programmable TimeStamp interrupt is issued (see
-                                                         MIX(0..1)_INTR[TS].
+                                                         MIX(0..1)_INTR[TS]).
                                                          For CN78XX, since the implementation only supports four outstanding timestamp interrupts,
                                                          this field should only be programmed from [0..3]. */
 	uint64_t crc_strip                    : 1;  /**< Hardware CRC strip enable. When enabled, the last 4 bytes (CRC) of the ingress packet are
@@ -388,8 +391,8 @@ union cvmx_mixx_ctl {
                                                          for all I-Ring buffer entries associated with a given ingress packet will be 4 bytes less
                                                          (so that the final 4B hardware CRC packet data is not processed by software). */
 	uint64_t busy                         : 1;  /**< MIX busy status bit. MIX asserts busy status any time there are:
-                                                         L2/DRAM read operations in-flight
-                                                         L2/DRAM write operations in-flight
+                                                         * L2/DRAM read operations in-flight.
+                                                         * L2/DRAM write operations in-flight.
                                                          After EN = 0, the MIX eventually completes any 'in-flight' transactions, at which point
                                                          the BUSY deasserts. */
 	uint64_t en                           : 1;  /**< MIX enable bit. When EN = 0, MIX no longer arbitrates for any new L2/DRAM read/write
@@ -397,40 +400,38 @@ union cvmx_mixx_ctl {
 	uint64_t reset                        : 1;  /**< MIX soft reset. When software writes a 1 to this field, the MIX logic executes a soft
                                                          reset.
                                                          During a soft reset, CSR accesses are not affected. However, the values of the fields are
-                                                         affected by soft reset (except
-                                                         MIX(0..1)_CTL[RESET] itself).
+                                                         affected by soft reset (except MIX(0..1)_CTL[RESET] itself).
                                                          After power-on, the MIX-BGX are held in reset until RESET is written to 0. Software must
-                                                         also perform a MIX(0..1)_CTL CSR read after this write to ensure the soft reset de-
-                                                         assertion has had sufficient time to propagate to all MIO-MIX internal logic before any
-                                                         subsequent MIX CSR accesses are issued.
+                                                         also perform a MIX(0..1)_CTL CSR read after this write to ensure the soft reset
+                                                         deassertion has had sufficient time to propagate to all MIO-MIX internal logic before
+                                                         any subsequent MIX CSR accesses are issued.
                                                          The intended 'soft reset' sequence is:
-                                                         Write EN = 0 (to prevent any NEW transactions from being started)
-                                                         Wait for BUSY = 0 (to indicate that all in-flight transactions have completed)
-                                                         Write RESET = 1, followed by a MIX(0..1)_CTL register read and wait for the result.
-                                                         Re-initialize the MIX just as would be done for a hard reset.
+                                                         * Write EN = 0 (to prevent any NEW transactions from being started).
+                                                         * Wait for BUSY = 0 (to indicate that all in-flight transactions have completed).
+                                                         * Write RESET = 1, followed by a MIX(0..1)_CTL register read and wait for the result.
+                                                         * Re-initialize the MIX just as would be done for a hard reset.
                                                          Once the MIX has been soft-reset, please refer to MIX Bring-up Sequence, MIX Bring-up
-                                                         Sequence to complete the MIX re-initialization sequence.
-                                                         Please also refer to MIX Block Reset on MIX block reset. */
+                                                         Sequence to complete the MIX re-initialization sequence. */
 	uint64_t lendian                      : 1;  /**< Packet little-endian mode enable.
-                                                         0 = big-endian mode
-                                                         1 = little-endian mode
                                                          When the mode is set, MIX byte-swaps packet data load/store operations at the MIX/IOB
-                                                         boundary. */
+                                                         boundary.
+                                                         0 = Big-endian mode.
+                                                         1 = Little-endian mode. */
 	uint64_t nbtarb                       : 1;  /**< MIX CB-request arbitration mode. When cleared to 0, the arbiter is fixed priority with the
                                                          following priority scheme:
-                                                         Highest Priority:  I-Ring Packet Write Request
-                                                         O-Ring Packet Read Request
-                                                         I-Ring Entry Write Request
-                                                         I-Ring Entry Read Request
-                                                         O-Ring Entry Read Request
+                                                         * I-Ring packet write request. (Highest Priority.)
+                                                         * O-Ring packet read request.
+                                                         * I-Ring entry write request.
+                                                         * I-Ring entry read request.
+                                                         * O-Ring entry read request.
                                                          When set to 1, the arbiter is round robin. */
 	uint64_t mrq_hwm                      : 2;  /**< MIX CB-request FIFO programmable high watermark.
                                                          The MRQ contains 16 CB-requests which are CSR read/write requests. If the MRQ backs up
                                                          with HWM entries, then new CB-requests are stalled.
-                                                         [0]: HWM = 11
-                                                         [1]: HWM = 10
-                                                         [2]: HWM = 9
-                                                         [3]: HWM = 8 */
+                                                         0x0 = HWM is 11.
+                                                         0x1 = HWM is 10.
+                                                         0x2 = HWM is 9.
+                                                         0x3 = HWM is 8. */
 #else
 	uint64_t mrq_hwm                      : 2;
 	uint64_t nbtarb                       : 1;
@@ -671,8 +672,11 @@ typedef union cvmx_mixx_intena cvmx_mixx_intena_t;
 /**
  * cvmx_mix#_ircnt
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_IRCNT = MIX I-Ring Pending Packet Counter
+ *
+ * Description:
+ *  NOTE: To write to the MIX_IRCNT register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_IRCNT register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_ircnt {
 	uint64_t u64;
@@ -680,7 +684,7 @@ union cvmx_mixx_ircnt {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_20_63               : 44;
 	uint64_t ircnt                        : 20; /**< Pending number of I-Ring packets.
-                                                         Whenever hardware writes a completion code of Done, Trunc, CRCErr or Err, it increments
+                                                         Whenever hardware writes a completion code of DONE, TRUNC, CRCERR or ERR, it increments
                                                          the IRCNT (to indicate to software the number of pending Input packets in system memory).
                                                          The hardware guarantees that the completion code write is always visible in system memory
                                                          before it increments the IRCNT.
@@ -713,8 +717,11 @@ typedef union cvmx_mixx_ircnt cvmx_mixx_ircnt_t;
 /**
  * cvmx_mix#_irhwm
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_IRHWM = MIX I-Ring High-Water Mark Threshold Register
+ *
+ * Description:
+ *  NOTE: To write to the MIX_IHWM register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_IHWM register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_irhwm {
 	uint64_t u64;
@@ -729,8 +736,7 @@ union cvmx_mixx_irhwm {
                                                          This programmable mechanism is provided as a means to backpressure input traffic early
                                                          enough so that packets are not dropped by CN78XX. */
 	uint64_t irhwm                        : 20; /**< I-Ring entry high-watermark threshold. Used to determine when the number of inbound
-                                                         packets in system memory
-                                                         (MIX(0..1)_IRCNT[IRCNT]) exceeds this IRHWM threshold. */
+                                                         packets in system memory (MIX(0..1)_IRCNT[IRCNT]) exceeds this IRHWM threshold. */
 #else
 	uint64_t irhwm                        : 20;
 	uint64_t ibplwm                       : 20;
@@ -754,8 +760,11 @@ typedef union cvmx_mixx_irhwm cvmx_mixx_irhwm_t;
 /**
  * cvmx_mix#_iring1
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_IRING1 = MIX Inbound Ring Register \#1
+ *
+ * Description:
+ *  NOTE: To write to the MIX_IRING1 register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_IRING1 register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_iring1 {
 	uint64_t u64;
@@ -837,8 +846,11 @@ typedef union cvmx_mixx_iring1 cvmx_mixx_iring1_t;
 /**
  * cvmx_mix#_iring2
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_IRING2 = MIX Inbound Ring Register \#2
+ *
+ * Description:
+ *  NOTE: To write to the MIX_IRING2 register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_IRING2 register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_iring2 {
 	uint64_t u64;
@@ -852,9 +864,7 @@ union cvmx_mixx_iring2 {
                                                          This field is read-only to software. */
 	uint64_t reserved_20_31               : 12;
 	uint64_t idbell                       : 20; /**< Represents the cumulative total of pending inbound ring (I-Ring) buffer entries. Each
-                                                         I-Ring buffer entry contains:
-                                                         an L2/DRAM byte pointer along with a
-                                                         a Byte Length.
+                                                         I-Ring buffer entry contains an L2/DRAM byte pointer and a byte Length.
                                                          After software inserts a new entry into the I-Ring buffer, it 'rings the doorbell for the
                                                          inbound ring.' When the MIX hardware receives the doorbell ring, it advances the doorbell
                                                          count for the I-Ring.
@@ -884,9 +894,8 @@ typedef union cvmx_mixx_iring2 cvmx_mixx_iring2_t;
 /**
  * cvmx_mix#_isr
  *
- * This register provides a summary of the MIX interrupt bits. To write to this register, a
- * device issues an IOBST instruction directed at the MIO. To read this register, a device issues
- * an IOBLD64 instruction directed at the MIO.
+ * This register provides a summary of the MIX interrupt bits.
+ *
  */
 union cvmx_mixx_isr {
 	uint64_t u64;
@@ -902,7 +911,7 @@ union cvmx_mixx_isr {
                                                          hardware reports the underflow condition.
                                                          The MIX(0..1)_ORCNT[IOCNT] will clamp to zero.
                                                          If an ORUN underflow condition is detected, the integrity of the MIX hardware state has
-                                                         been compromised. To recover, Software must issue a software reset sequence. (See
+                                                         been compromised. To recover, software must issue a software reset sequence. (See
                                                          MIX(0..1)_CTL[RESET.] */
 	uint64_t irun                         : 1;  /**< I-ring packet count underflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_IRUN. If
                                                          software writes a larger value than what is currently in the MIX(0..1)_IRCNT[IRCNT], then
@@ -922,34 +931,35 @@ union cvmx_mixx_isr {
                                                          programmable threshold (ORHWM), this bit is set and the interrupt is generated. To service
                                                          this interrupt, the ORCNT must first be lowered below the ORHWM before the W1C to this
                                                          field. */
-	uint64_t idblovf                      : 1;  /**< "Inbound doorbell (IDBELL) overflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_IDBLOVF.
+	uint64_t idblovf                      : 1;  /**< Inbound doorbell (IDBELL) overflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_IDBLOVF.
                                                          If software attempts to write to the MIX(0..1)_IRING2[IDBELL] with a value greater than
-                                                         the remaining number of I-Ring buffer entries
-                                                         (MIX(0..1)_REMCNT[IREMCNT]), then the following occurs:
-                                                         The MIX(0..1)_IRING2[IDBELL] write is IGNORED
-                                                         IDBLOVF is set and the interrupt is generated.
-                                                         Software should keep track of the \# of I-Ring entries in use (i.e. the cumulative number
+                                                         the remaining number of I-Ring buffer entries (MIX(0..1)_REMCNT[IREMCNT]), then the
+                                                         following occurs:
+                                                         * The MIX(0..1)_IRING2[IDBELL] write is IGNORED.
+                                                         * IDBLOVF is set and the interrupt is generated.
+                                                         Software should keep track of the number of I-Ring entries in use (i.e. the cumulative
+                                                         number
                                                          of IDBELL write operations), and ensure that future IDBELL write operations don't exceed
                                                          the size of the I-Ring Buffer (MIX(0..1)_IRING2[ISIZE]). Software must reclaim I-Ring
-                                                         entries by keeping track of the number of IRing entries, and writing to the
+                                                         entries by keeping track of the number of I-Ring entries, and writing to the
                                                          MIX(0..1)_IRCNT[IRCNT].
-                                                         The MIX(0..1)_IRCNT[IRCNT] register represents the total number of packets (not IRing
+                                                         The MIX(0..1)_IRCNT[IRCNT] register represents the total number of packets (not I-Ring
                                                          entries) and software must further keep track of the number of I-Ring entries associated
                                                          with each packet as they are processed.
-                                                         There is no recovery from an IDBLOVF Interrupt. If it occurs, it is an indication that
-                                                         software has overwritten the I-Ring buffer, and the only recourse is a hardware reset." */
+                                                         If an IDBLOVF occurs, it is an indication that software has overwritten the I-Ring buffer,
+                                                         and the only recourse for recovery is a hardware reset. */
 	uint64_t odblovf                      : 1;  /**< Outbound doorbell (ODBELL) overflow detected. Throws MIX_INTSN_E::MIX(0..1)_INT_ODBLOVF.
                                                          If software attempts to write to MIX(0..1)_ORING2[ODBELL] with a value greater than the
-                                                         remaining number of O-Ring buffer entries
-                                                         (MIX(0..1)_REMCNT[OREMCNT]), then the following occurs:
-                                                         The MIX(0..1)_IRING2[ODBELL] write operation is IGNORED
-                                                         ODBLOVF is set and the interrupt is generated.
+                                                         remaining number of O-Ring buffer entries (MIX(0..1)_REMCNT[OREMCNT]), then the following
+                                                         occurs:
+                                                         * The MIX(0..1)_IRING2[ODBELL] write operation is IGNORED.
+                                                         * ODBLOVF is set and the interrupt is generated.
                                                          Software should keep track of the number of I-Ring entries in use (i.e. the cumulative
                                                          number of ODBELL write operations), and ensure that future ODBELL write operations don't
                                                          exceed the size of the O-Ring buffer (MIX(0..1)_ORING2[OSIZE]). Software must reclaim
                                                          O-Ring entries by writing to MIX(0..1)_ORCNT[ORCNT].
-                                                         There is no recovery from an ODBLOVF Interrupt. If it occurs, it is an indication that
-                                                         software has overwritten the O-Ring buffer, and the only recourse is a hardware reset. */
+                                                         If an ODBLOVF occurs, it is an indication that software has overwritten the O-Ring buffer,
+                                                         and the only recourse for recovery is a hardware reset. */
 #else
 	uint64_t odblovf                      : 1;
 	uint64_t idblovf                      : 1;
@@ -1080,8 +1090,11 @@ typedef union cvmx_mixx_isr cvmx_mixx_isr_t;
 /**
  * cvmx_mix#_orcnt
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_ORCNT = MIX O-Ring Packets Sent Counter
+ *
+ * Description:
+ *  NOTE: To write to the MIX_ORCNT register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_ORCNT register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_orcnt {
 	uint64_t u64;
@@ -1120,8 +1133,11 @@ typedef union cvmx_mixx_orcnt cvmx_mixx_orcnt_t;
 /**
  * cvmx_mix#_orhwm
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_ORHWM = MIX O-Ring High-Water Mark Threshold Register
+ *
+ * Description:
+ *  NOTE: To write to the MIX_ORHWM register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_ORHWM register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_orhwm {
 	uint64_t u64;
@@ -1153,8 +1169,11 @@ typedef union cvmx_mixx_orhwm cvmx_mixx_orhwm_t;
 /**
  * cvmx_mix#_oring1
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_ORING1 = MIX Outbound Ring Register \#1
+ *
+ * Description:
+ *  NOTE: To write to the MIX_ORING1 register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_ORING1 register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_oring1 {
 	uint64_t u64;
@@ -1236,8 +1255,11 @@ typedef union cvmx_mixx_oring1 cvmx_mixx_oring1_t;
 /**
  * cvmx_mix#_oring2
  *
- * To write to this register, a device issues an IOBST instruction directed at the MIO. To read
- * this register, a device issues an IOBLD64 instruction directed at the MIO.
+ * MIX_ORING2 = MIX Outbound Ring Register \#2
+ *
+ * Description:
+ *  NOTE: To write to the MIX_ORING2 register, a device would issue an IOBST directed at the MIO.
+ *        To read the MIX_ORING2 register, a device would issue an IOBLD64 directed at the MIO.
  */
 union cvmx_mixx_oring2 {
 	uint64_t u64;
@@ -1251,9 +1273,7 @@ union cvmx_mixx_oring2 {
                                                          This field is read-only to software. */
 	uint64_t reserved_20_31               : 12;
 	uint64_t odbell                       : 20; /**< Represents the cumulative total of pending outbound ring (O-Ring) buffer entries. Each
-                                                         O-Ring buffer entry contains:
-                                                         an L2/DRAM byte pointer along with a
-                                                         a byte length.
+                                                         O-Ring buffer entry contains an L2/DRAM byte pointer and a byte length.
                                                          After software inserts new entries into the O-Ring Buffer, it 'rings the doorbell with the
                                                          count of the newly inserted entries.' When the MIX hardware receives the doorbell ring, it
                                                          increments the current doorbell count by the CSR write value.
@@ -1284,7 +1304,7 @@ typedef union cvmx_mixx_oring2 cvmx_mixx_oring2_t;
  * cvmx_mix#_remcnt
  *
  * This register contains the MIX ring buffer remainder counts (useful for hardware debug only).
- * To read this register, a device issues an IOBLD64 directed at the MIO.
+ *
  */
 union cvmx_mixx_remcnt {
 	uint64_t u64;
@@ -1336,13 +1356,18 @@ typedef union cvmx_mixx_remcnt cvmx_mixx_remcnt_t;
  * to determine the number pending timestamp interrupts ([TSCNT]), the number outstanding
  * timestamp requests in flight ([TSTOT]), and the number of available timestamp entries (TSAVL)
  * in the timestamp FIFO.
+ *
  * Writing to this register advances the MIX(0..1)_TSTAMP FIFO head pointer by 1 and decrements
  * the [TSCNT, TSTOT] pending counts by 1. For example, if software reads [TSCNT] = 2 (two
  * pending timestamp interrupts), it would immediately issue this sequence:
- * a MIX(0..1)_TSTAMP[TSTAMP] read operation followed by MIX(0..1)_TSCTL write operation (i.e. it
+ *
+ * 1. a MIX(0..1)_TSTAMP[TSTAMP] read operation followed by MIX(0..1)_TSCTL write operation (i.e.
+ * it
  * gets the timestamp value, pops the timestamp FIFO, and decrements pending counts by 1).
- * a MIX(0..1)_TSTAMP[TSTAMP] read operation followed by MIX(0..1)_TSCTL write operation.
- * Note for Software: A MIX(0..1)_TSCTL write operation is ignored when
+ *
+ * 2. a MIX(0..1)_TSTAMP[TSTAMP] read operation followed by MIX(0..1)_TSCTL write operation.
+ *
+ * Note for software: A MIX(0..1)_TSCTL write operation is ignored when
  * MIX(0..1)_TSCTL[TSCNT] = 0 (i.e., TimeStamp FIFO empty).
  */
 union cvmx_mixx_tsctl {
diff --git a/arch/mips/include/asm/octeon/cvmx-mpi-defs.h b/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
index e3b6de1..96d3cdf 100644
--- a/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-mpi-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -510,6 +510,7 @@ union cvmx_mpi_cfg {
 	uint64_t reserved_29_63               : 35;
 #endif
 	} cn70xx;
+	struct cvmx_mpi_cfg_cn70xx            cn70xxp1;
 	struct cvmx_mpi_cfg_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_29_63               : 35;
@@ -603,6 +604,7 @@ union cvmx_mpi_datx {
 	struct cvmx_mpi_datx_s                cn61xx;
 	struct cvmx_mpi_datx_s                cn66xx;
 	struct cvmx_mpi_datx_s                cn70xx;
+	struct cvmx_mpi_datx_s                cn70xxp1;
 	struct cvmx_mpi_datx_s                cn78xx;
 	struct cvmx_mpi_datx_s                cnf71xx;
 };
@@ -648,6 +650,7 @@ union cvmx_mpi_sts {
 	struct cvmx_mpi_sts_cn30xx            cn61xx;
 	struct cvmx_mpi_sts_cn30xx            cn66xx;
 	struct cvmx_mpi_sts_cn30xx            cn70xx;
+	struct cvmx_mpi_sts_cn30xx            cn70xxp1;
 	struct cvmx_mpi_sts_s                 cn78xx;
 	struct cvmx_mpi_sts_cn30xx            cnf71xx;
 };
@@ -724,6 +727,7 @@ union cvmx_mpi_tx {
 	} cn61xx;
 	struct cvmx_mpi_tx_s                  cn66xx;
 	struct cvmx_mpi_tx_s                  cn70xx;
+	struct cvmx_mpi_tx_s                  cn70xxp1;
 	struct cvmx_mpi_tx_s                  cn78xx;
 	struct cvmx_mpi_tx_cn61xx             cnf71xx;
 };
@@ -745,6 +749,7 @@ union cvmx_mpi_wide_dat {
 #endif
 	} s;
 	struct cvmx_mpi_wide_dat_s            cn70xx;
+	struct cvmx_mpi_wide_dat_s            cn70xxp1;
 	struct cvmx_mpi_wide_dat_s            cn78xx;
 };
 typedef union cvmx_mpi_wide_dat cvmx_mpi_wide_dat_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-ndf-defs.h b/arch/mips/include/asm/octeon/cvmx-ndf-defs.h
index b160bfc..e1f3859 100644
--- a/arch/mips/include/asm/octeon/cvmx-ndf-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ndf-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -180,6 +180,7 @@ union cvmx_ndf_bt_pg_info {
 	struct cvmx_ndf_bt_pg_info_s          cn68xx;
 	struct cvmx_ndf_bt_pg_info_s          cn68xxp1;
 	struct cvmx_ndf_bt_pg_info_s          cn70xx;
+	struct cvmx_ndf_bt_pg_info_s          cn70xxp1;
 };
 typedef union cvmx_ndf_bt_pg_info cvmx_ndf_bt_pg_info_t;
 
@@ -210,6 +211,7 @@ union cvmx_ndf_cmd {
 	struct cvmx_ndf_cmd_s                 cn68xx;
 	struct cvmx_ndf_cmd_s                 cn68xxp1;
 	struct cvmx_ndf_cmd_s                 cn70xx;
+	struct cvmx_ndf_cmd_s                 cn70xxp1;
 };
 typedef union cvmx_ndf_cmd cvmx_ndf_cmd_t;
 
@@ -262,6 +264,7 @@ union cvmx_ndf_drbell {
 	struct cvmx_ndf_drbell_s              cn68xx;
 	struct cvmx_ndf_drbell_s              cn68xxp1;
 	struct cvmx_ndf_drbell_s              cn70xx;
+	struct cvmx_ndf_drbell_s              cn70xxp1;
 };
 typedef union cvmx_ndf_drbell cvmx_ndf_drbell_t;
 
@@ -297,6 +300,7 @@ union cvmx_ndf_ecc_cnt {
 	struct cvmx_ndf_ecc_cnt_s             cn68xx;
 	struct cvmx_ndf_ecc_cnt_s             cn68xxp1;
 	struct cvmx_ndf_ecc_cnt_s             cn70xx;
+	struct cvmx_ndf_ecc_cnt_s             cn70xxp1;
 };
 typedef union cvmx_ndf_ecc_cnt cvmx_ndf_ecc_cnt_t;
 
@@ -340,6 +344,7 @@ union cvmx_ndf_int {
 	struct cvmx_ndf_int_s                 cn68xx;
 	struct cvmx_ndf_int_s                 cn68xxp1;
 	struct cvmx_ndf_int_s                 cn70xx;
+	struct cvmx_ndf_int_s                 cn70xxp1;
 };
 typedef union cvmx_ndf_int cvmx_ndf_int_t;
 
@@ -380,6 +385,7 @@ union cvmx_ndf_int_en {
 	struct cvmx_ndf_int_en_s              cn68xx;
 	struct cvmx_ndf_int_en_s              cn68xxp1;
 	struct cvmx_ndf_int_en_s              cn70xx;
+	struct cvmx_ndf_int_en_s              cn70xxp1;
 };
 typedef union cvmx_ndf_int_en cvmx_ndf_int_en_t;
 
@@ -509,6 +515,7 @@ union cvmx_ndf_misc {
 	struct cvmx_ndf_misc_s                cn68xx;
 	struct cvmx_ndf_misc_s                cn68xxp1;
 	struct cvmx_ndf_misc_s                cn70xx;
+	struct cvmx_ndf_misc_s                cn70xxp1;
 };
 typedef union cvmx_ndf_misc cvmx_ndf_misc_t;
 
@@ -551,6 +558,7 @@ union cvmx_ndf_st_reg {
 	struct cvmx_ndf_st_reg_s              cn68xx;
 	struct cvmx_ndf_st_reg_s              cn68xxp1;
 	struct cvmx_ndf_st_reg_s              cn70xx;
+	struct cvmx_ndf_st_reg_s              cn70xxp1;
 };
 typedef union cvmx_ndf_st_reg cvmx_ndf_st_reg_t;
 
diff --git a/arch/mips/include/asm/octeon/cvmx-npei-defs.h b/arch/mips/include/asm/octeon/cvmx-npei-defs.h
index f8fed4b..ff41270 100644
--- a/arch/mips/include/asm/octeon/cvmx-npei-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-npei-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-npi-defs.h b/arch/mips/include/asm/octeon/cvmx-npi-defs.h
index eda66ff..853a40d 100644
--- a/arch/mips/include/asm/octeon/cvmx-npi-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-npi-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
index 27c81d3..0478782 100644
--- a/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-oclax-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -431,6 +431,7 @@ union cvmx_oclax_bist_result {
 #endif
 	} s;
 	struct cvmx_oclax_bist_result_s       cn70xx;
+	struct cvmx_oclax_bist_result_s       cn70xxp1;
 	struct cvmx_oclax_bist_result_s       cn78xx;
 };
 typedef union cvmx_oclax_bist_result cvmx_oclax_bist_result_t;
@@ -446,13 +447,13 @@ union cvmx_oclax_cdhx_ctl {
 	uint64_t dup                          : 1;  /**< Retain duplicates in the data stream. */
 	uint64_t dis_stamp                    : 1;  /**< Remove time stamps from data stream. */
 	uint64_t cap_ctl                      : 4;  /**< Minterms that will cause data to be captured. These minterms are the four inputs to a 4-1
-                                                         mux selected by PLA1 and 0. The output is thus calulated from the equation:
-                                                         fsmcap0 = OCLA(0..4)_FSM(0)_STATE[state0][CAP].
-                                                         fsmcap1 = OCLA(0..4)_FSM(1)_STATE[state1][CAP].
-                                                         out = (    (<3> & fsmcap0 & fsmcap0)
-                                                         || (<2> & fsmcap1 & !fsmcap0)
-                                                         || (<1> & !fsmcap1 & fsmcap0)
-                                                         || (<0> & !fsmcap1 & !fsmcap0)).
+                                                         mux selected by PLA1 and 0. The output is thus calculated from the equation:
+                                                           fsmcap0 = OCLA(0..4)_FSM(0)_STATE[state0][CAP].
+                                                           fsmcap1 = OCLA(0..4)_FSM(1)_STATE[state1][CAP].
+                                                           out = (   (<3> & fsmcap0 & fsmcap0)
+                                                         _        || (<2> & fsmcap1 & !fsmcap0)
+                                                         _        || (<1> & !fsmcap1 & fsmcap0)
+                                                         _        || (<0> & !fsmcap1 & !fsmcap0)).
                                                          Common examples:
                                                          0x0 = No capture.
                                                          0x2 = Capture when fsmcap0 requests capture.
@@ -468,6 +469,7 @@ union cvmx_oclax_cdhx_ctl {
 #endif
 	} s;
 	struct cvmx_oclax_cdhx_ctl_s          cn70xx;
+	struct cvmx_oclax_cdhx_ctl_s          cn70xxp1;
 	struct cvmx_oclax_cdhx_ctl_s          cn78xx;
 };
 typedef union cvmx_oclax_cdhx_ctl cvmx_oclax_cdhx_ctl_t;
@@ -489,6 +491,7 @@ union cvmx_oclax_const {
 #endif
 	} s;
 	struct cvmx_oclax_const_s             cn70xx;
+	struct cvmx_oclax_const_s             cn70xxp1;
 	struct cvmx_oclax_const_s             cn78xx;
 };
 typedef union cvmx_oclax_const cvmx_oclax_const_t;
@@ -508,6 +511,7 @@ union cvmx_oclax_datx {
 #endif
 	} s;
 	struct cvmx_oclax_datx_s              cn70xx;
+	struct cvmx_oclax_datx_s              cn70xxp1;
 	struct cvmx_oclax_datx_s              cn78xx;
 };
 typedef union cvmx_oclax_datx cvmx_oclax_datx_t;
@@ -519,15 +523,15 @@ union cvmx_oclax_dat_pop {
 	uint64_t u64;
 	struct cvmx_oclax_dat_pop_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t valid                        : 1;  /**< Valid entry. Indicates the FIFO contains data, and equivalent to OCLA(0..4)_FIFO_DEPTH[DEPTH] != 0. */
-	uint64_t trig                         : 1;  /**< Internal trigger set. Equivalent to OCLA(0..4)_STATE_INT[TRIG]. */
-	uint64_t wmark                        : 1;  /**< Internal buffer watermark reached. Equivalent to OCLA(0..4)_STATE_INT[WMARK]. */
+	uint64_t valid                        : 1;  /**< Valid entry. Indicates the FIFO contains data, and equivalent to OCLA()_FIFO_DEPTH[DEPTH] != 0. */
+	uint64_t trig                         : 1;  /**< Internal trigger set. Equivalent to OCLA()_STATE_INT[TRIG]. */
+	uint64_t wmark                        : 1;  /**< Internal buffer watermark reached. Equivalent to OCLA()_STATE_INT[WMARK]. */
 	uint64_t reserved_38_60               : 23;
 	uint64_t entry                        : 38; /**< Captured entry. If VALID is set, has read side effect of unloading data by decrementing
-                                                         OCLA(0..4)_FIFO_DEPTH[DEPTH]. Data is in the format described by OCLA_CAP_DAT_S or
+                                                         OCLA()_FIFO_DEPTH[DEPTH]. Data is in the format described by OCLA_CAP_DAT_S or
                                                          OCLA_CAP_CTL_S.
                                                          Note that unloading data will cause that data not to be sent to memory, therefore
-                                                         OCLA(0..4)_DAT_POP should not be read when OCLA(0..4)_FIFO_LIMIT[DDR] != all-ones. */
+                                                         OCLA()_DAT_POP should not be read when OCLA()_FIFO_LIMIT[DDR] != all-ones. */
 #else
 	uint64_t entry                        : 38;
 	uint64_t reserved_38_60               : 23;
@@ -537,6 +541,7 @@ union cvmx_oclax_dat_pop {
 #endif
 	} s;
 	struct cvmx_oclax_dat_pop_s           cn70xx;
+	struct cvmx_oclax_dat_pop_s           cn70xxp1;
 	struct cvmx_oclax_dat_pop_s           cn78xx;
 };
 typedef union cvmx_oclax_dat_pop cvmx_oclax_dat_pop_t;
@@ -556,6 +561,7 @@ union cvmx_oclax_fifo_depth {
 #endif
 	} s;
 	struct cvmx_oclax_fifo_depth_s        cn70xx;
+	struct cvmx_oclax_fifo_depth_s        cn70xxp1;
 	struct cvmx_oclax_fifo_depth_s        cn78xx;
 };
 typedef union cvmx_oclax_fifo_depth cvmx_oclax_fifo_depth_t;
@@ -567,17 +573,17 @@ union cvmx_oclax_fifo_limit {
 	uint64_t u64;
 	struct cvmx_oclax_fifo_limit_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t overfull                     : 16; /**< Stop level. When OCLA(0..4)_FIFO_DEPTH > OVERFULL, stop capturing and set
-                                                         OCLA(0..4)_STATE_INT[OVERFULL]. This should be set to no more than
-                                                         OCLA(0..4)_CONST[DAT_SIZE] minus 26 when using DDR capture to insure that overflow can be
+	uint64_t overfull                     : 16; /**< Stop level. When OCLA()_FIFO_DEPTH > [OVERFULL], stop capturing and set
+                                                         OCLA()_STATE_INT[OVERFULL]. This should be set to no more than
+                                                         OCLA()_CONST[DAT_SIZE] minus 26 when using DDR capture to insure that overflow can be
                                                          detected. */
-	uint64_t ddr                          : 16; /**< DDR level. When OCLA(0..4)_FIFO_DEPTH > DDR, FIFO entries will be removed, packed into a
+	uint64_t ddr                          : 16; /**< DDR level. When OCLA()_FIFO_DEPTH > [DDR], FIFO entries will be removed, packed into a
                                                          cache line, and overflowed to DDR/L2. All-ones disables overflow to DDR/L2. If non-zero
                                                          must be at least 28. */
-	uint64_t bp                           : 16; /**< Backpressure level. When OCLA(0..4)_FIFO_DEPTH > BP, OCLA will signal backpressure to
+	uint64_t bp                           : 16; /**< Backpressure level. When OCLA()_FIFO_DEPTH > [BP], OCLA will signal backpressure to
                                                          coprocessors. All-ones disables indicating backpressure. */
-	uint64_t wmark                        : 16; /**< Interrupt watermark level. When OCLA(0..4)_FIFO_DEPTH > WMARK OCLA will set
-                                                         OCLA(0..4)_STATE_INT[WMARK] interrupt. All-ones disables setting the interrupt. */
+	uint64_t wmark                        : 16; /**< Interrupt watermark level. When OCLA()_FIFO_DEPTH > [WMARK], OCLA will set
+                                                         OCLA()_STATE_INT[WMARK] interrupt. All-ones disables setting the interrupt. */
 #else
 	uint64_t wmark                        : 16;
 	uint64_t bp                           : 16;
@@ -586,6 +592,7 @@ union cvmx_oclax_fifo_limit {
 #endif
 	} s;
 	struct cvmx_oclax_fifo_limit_s        cn70xx;
+	struct cvmx_oclax_fifo_limit_s        cn70xxp1;
 	struct cvmx_oclax_fifo_limit_s        cn78xx;
 };
 typedef union cvmx_oclax_fifo_limit cvmx_oclax_fifo_limit_t;
@@ -605,6 +612,7 @@ union cvmx_oclax_fifo_tail {
 #endif
 	} s;
 	struct cvmx_oclax_fifo_tail_s         cn70xx;
+	struct cvmx_oclax_fifo_tail_s         cn70xxp1;
 	struct cvmx_oclax_fifo_tail_s         cn78xx;
 };
 typedef union cvmx_oclax_fifo_tail cvmx_oclax_fifo_tail_t;
@@ -619,8 +627,8 @@ union cvmx_oclax_fifo_trig {
 	uint64_t reserved_32_63               : 32;
 	uint64_t limit                        : 16; /**< Post-trigger number of entries to collect before stopping collection. If zero, collection
                                                          will never stop, which may be desirable when overflowing to DDR/L2. Must be <
-                                                         OCLA(0..4)_CONST[DAT_SIZE] - 5. */
-	uint64_t cnt                          : 16; /**< Number of entries collected since trigger. Cleared when OCLA(0..4)_STATE_INT[TRIG] clear. */
+                                                         OCLA()_CONST[DAT_SIZE] - 5. */
+	uint64_t cnt                          : 16; /**< Number of entries collected since trigger. Cleared when OCLA()_STATE_INT[TRIG] clear. */
 #else
 	uint64_t cnt                          : 16;
 	uint64_t limit                        : 16;
@@ -628,6 +636,7 @@ union cvmx_oclax_fifo_trig {
 #endif
 	} s;
 	struct cvmx_oclax_fifo_trig_s         cn70xx;
+	struct cvmx_oclax_fifo_trig_s         cn70xxp1;
 	struct cvmx_oclax_fifo_trig_s         cn78xx;
 };
 typedef union cvmx_oclax_fifo_trig cvmx_oclax_fifo_trig_t;
@@ -640,13 +649,14 @@ union cvmx_oclax_fifo_wrap {
 	struct cvmx_oclax_fifo_wrap_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t wraps                        : 32; /**< Number of times FIFO has wrapped since trigger. Cleared when OCLA(0..4)_STATE_INT[TRIG] clear. */
+	uint64_t wraps                        : 32; /**< Number of times FIFO has wrapped since trigger. Cleared when OCLA()_STATE_INT[TRIG] clear. */
 #else
 	uint64_t wraps                        : 32;
 	uint64_t reserved_32_63               : 32;
 #endif
 	} s;
 	struct cvmx_oclax_fifo_wrap_s         cn70xx;
+	struct cvmx_oclax_fifo_wrap_s         cn70xxp1;
 	struct cvmx_oclax_fifo_wrap_s         cn78xx;
 };
 typedef union cvmx_oclax_fifo_wrap cvmx_oclax_fifo_wrap_t;
@@ -676,6 +686,7 @@ union cvmx_oclax_fsmx_andx_ix {
 #endif
 	} s;
 	struct cvmx_oclax_fsmx_andx_ix_s      cn70xx;
+	struct cvmx_oclax_fsmx_andx_ix_s      cn70xxp1;
 	struct cvmx_oclax_fsmx_andx_ix_s      cn78xx;
 };
 typedef union cvmx_oclax_fsmx_andx_ix cvmx_oclax_fsmx_andx_ix_t;
@@ -695,6 +706,7 @@ union cvmx_oclax_fsmx_orx {
 #endif
 	} s;
 	struct cvmx_oclax_fsmx_orx_s          cn70xx;
+	struct cvmx_oclax_fsmx_orx_s          cn70xxp1;
 	struct cvmx_oclax_fsmx_orx_s          cn78xx;
 };
 typedef union cvmx_oclax_fsmx_orx cvmx_oclax_fsmx_orx_t;
@@ -736,6 +748,7 @@ union cvmx_oclax_fsmx_statex {
 #endif
 	} s;
 	struct cvmx_oclax_fsmx_statex_s       cn70xx;
+	struct cvmx_oclax_fsmx_statex_s       cn70xxp1;
 	struct cvmx_oclax_fsmx_statex_s       cn78xx;
 };
 typedef union cvmx_oclax_fsmx_statex cvmx_oclax_fsmx_statex_t;
@@ -751,7 +764,7 @@ union cvmx_oclax_gen_ctl {
 	uint64_t exten                        : 1;  /**< Enable external triggering.
                                                          0 = External triggering ignored.
                                                          1 = When the external trigger pin selected with GPIO_OCLA_EXTEN_TRIG is high it will cause
-                                                         triggerring and set OCLA(0..4)_STATE_SET[TRIG]. The external device must de-assert the
+                                                         triggerring and set OCLA()_STATE_SET[TRIG]. The external device must de-assert the
                                                          signal to release the trigger (it is not edge sensitive.) */
 	uint64_t den                          : 1;  /**< Enable data bus and counter clocking. When set, the OCLA inbound data bus may be used and
                                                          counters may increment. When clear, the bus is always zero and internal flops may be clock
@@ -767,6 +780,7 @@ union cvmx_oclax_gen_ctl {
 #endif
 	} s;
 	struct cvmx_oclax_gen_ctl_s           cn70xx;
+	struct cvmx_oclax_gen_ctl_s           cn70xxp1;
 	struct cvmx_oclax_gen_ctl_s           cn78xx;
 };
 typedef union cvmx_oclax_gen_ctl cvmx_oclax_gen_ctl_t;
@@ -787,6 +801,7 @@ union cvmx_oclax_matx_count {
 #endif
 	} s;
 	struct cvmx_oclax_matx_count_s        cn70xx;
+	struct cvmx_oclax_matx_count_s        cn70xxp1;
 	struct cvmx_oclax_matx_count_s        cn78xx;
 };
 typedef union cvmx_oclax_matx_count cvmx_oclax_matx_count_t;
@@ -801,9 +816,9 @@ union cvmx_oclax_matx_ctl {
 	uint64_t reserved_8_63                : 56;
 	uint64_t fsm_ctr                      : 1;  /**< What output matcher provides to FSM:
                                                          0 = FSM receives raw match signal, asserting only in those cycles with matches.
-                                                         1 = FSM receives OCLA(0..4)_MAT(0..3)_COUNT >= OCLA(0..4)_MAT(0..3)_THRESH. */
-	uint64_t inc_match                    : 1;  /**< Increment OCLA(0..4)_MAT(0..3)_COUNT counter automatically on each match. */
-	uint64_t shift                        : 6;  /**< Right rotation amount to apply to data loaded into OCLA(0..4)_MAT(0..3)_VALUE(0..1)
+                                                         1 = FSM receives OCLA()_MAT()_COUNT >= OCLA()_MAT()_THRESH. */
+	uint64_t inc_match                    : 1;  /**< Increment OCLA()_MAT()_COUNT counter automatically on each match. */
+	uint64_t shift                        : 6;  /**< Right rotation amount to apply to data loaded into OCLA()_MAT()_VALUE()
                                                          register when FSM requests a value load. */
 #else
 	uint64_t shift                        : 6;
@@ -813,6 +828,7 @@ union cvmx_oclax_matx_ctl {
 #endif
 	} s;
 	struct cvmx_oclax_matx_ctl_s          cn70xx;
+	struct cvmx_oclax_matx_ctl_s          cn70xxp1;
 	struct cvmx_oclax_matx_ctl_s          cn78xx;
 };
 typedef union cvmx_oclax_matx_ctl cvmx_oclax_matx_ctl_t;
@@ -825,7 +841,7 @@ union cvmx_oclax_matx_maskx {
 	struct cvmx_oclax_matx_maskx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t mask                         : 36; /**< Bitmask of which bits in OCLA(0..4)_MAT(0..3)_VALUE(0..1) are to be compared.
+	uint64_t mask                         : 36; /**< Bitmask of which bits in OCLA()_MAT()_VALUE() are to be compared.
                                                          0 = Do not compare bit.
                                                          1 = Compare bit. */
 #else
@@ -834,6 +850,7 @@ union cvmx_oclax_matx_maskx {
 #endif
 	} s;
 	struct cvmx_oclax_matx_maskx_s        cn70xx;
+	struct cvmx_oclax_matx_maskx_s        cn70xxp1;
 	struct cvmx_oclax_matx_maskx_s        cn78xx;
 };
 typedef union cvmx_oclax_matx_maskx cvmx_oclax_matx_maskx_t;
@@ -846,14 +863,15 @@ union cvmx_oclax_matx_thresh {
 	struct cvmx_oclax_matx_thresh_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t thresh                       : 32; /**< Counter threshold value. Compared against OCLA(0..4)_MAT(0..3)_COUNT to assert matcher
-                                                         output, and set OCLA(0..4)_STATE_INT[OVFL]. */
+	uint64_t thresh                       : 32; /**< Counter threshold value. Compared against OCLA()_MAT()_COUNT to assert matcher
+                                                         output, and set OCLA()_STATE_INT[OVFL]. */
 #else
 	uint64_t thresh                       : 32;
 	uint64_t reserved_32_63               : 32;
 #endif
 	} s;
 	struct cvmx_oclax_matx_thresh_s       cn70xx;
+	struct cvmx_oclax_matx_thresh_s       cn70xxp1;
 	struct cvmx_oclax_matx_thresh_s       cn78xx;
 };
 typedef union cvmx_oclax_matx_thresh cvmx_oclax_matx_thresh_t;
@@ -866,14 +884,15 @@ union cvmx_oclax_matx_valuex {
 	struct cvmx_oclax_matx_valuex_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t mask                         : 36; /**< Data value to compare against when corresponding bits of OCLA(0..4)_MAT(0..3)_MASK(0..1)
-                                                         are set. Value may be updated with OCLA(0..4)_FSM(0..1)_STATE(0..15)[SET_VAL]. */
+	uint64_t mask                         : 36; /**< Data value to compare against when corresponding bits of OCLA()_MAT()_MASK()
+                                                         are set. Value may be updated with OCLA()_FSM()_STATE()[SET_VAL]. */
 #else
 	uint64_t mask                         : 36;
 	uint64_t reserved_36_63               : 28;
 #endif
 	} s;
 	struct cvmx_oclax_matx_valuex_s       cn70xx;
+	struct cvmx_oclax_matx_valuex_s       cn70xxp1;
 	struct cvmx_oclax_matx_valuex_s       cn78xx;
 };
 typedef union cvmx_oclax_matx_valuex cvmx_oclax_matx_valuex_t;
@@ -893,6 +912,7 @@ union cvmx_oclax_rawx {
 #endif
 	} s;
 	struct cvmx_oclax_rawx_s              cn70xx;
+	struct cvmx_oclax_rawx_s              cn70xxp1;
 	struct cvmx_oclax_rawx_s              cn78xx;
 };
 typedef union cvmx_oclax_rawx cvmx_oclax_rawx_t;
@@ -912,6 +932,7 @@ union cvmx_oclax_sft_rst {
 #endif
 	} s;
 	struct cvmx_oclax_sft_rst_s           cn70xx;
+	struct cvmx_oclax_sft_rst_s           cn70xxp1;
 	struct cvmx_oclax_sft_rst_s           cn78xx;
 };
 typedef union cvmx_oclax_sft_rst cvmx_oclax_sft_rst_t;
@@ -933,6 +954,7 @@ union cvmx_oclax_stack_base {
 #endif
 	} s;
 	struct cvmx_oclax_stack_base_s        cn70xx;
+	struct cvmx_oclax_stack_base_s        cn70xxp1;
 	struct cvmx_oclax_stack_base_s        cn78xx;
 };
 typedef union cvmx_oclax_stack_base cvmx_oclax_stack_base_t;
@@ -946,8 +968,8 @@ union cvmx_oclax_stack_cur {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
 	uint64_t ptr                          : 35; /**< Next address to write for overflow stack. This address must be on the local node in a OCI
-                                                         system. During initialization this must be between OCLA(0..4)_STACK_BASE and
-                                                         OCLA(0..4)_STACK_TOP. */
+                                                         system. During initialization this must be between OCLA()_STACK_BASE and
+                                                         OCLA()_STACK_TOP. */
 	uint64_t reserved_0_6                 : 7;
 #else
 	uint64_t reserved_0_6                 : 7;
@@ -956,6 +978,7 @@ union cvmx_oclax_stack_cur {
 #endif
 	} s;
 	struct cvmx_oclax_stack_cur_s         cn70xx;
+	struct cvmx_oclax_stack_cur_s         cn70xxp1;
 	struct cvmx_oclax_stack_cur_s         cn78xx;
 };
 typedef union cvmx_oclax_stack_cur cvmx_oclax_stack_cur_t;
@@ -975,6 +998,7 @@ union cvmx_oclax_stack_store_cnt {
 #endif
 	} s;
 	struct cvmx_oclax_stack_store_cnt_s   cn70xx;
+	struct cvmx_oclax_stack_store_cnt_s   cn70xxp1;
 	struct cvmx_oclax_stack_store_cnt_s   cn78xx;
 };
 typedef union cvmx_oclax_stack_store_cnt cvmx_oclax_stack_store_cnt_t;
@@ -997,6 +1021,7 @@ union cvmx_oclax_stack_top {
 #endif
 	} s;
 	struct cvmx_oclax_stack_top_s         cn70xx;
+	struct cvmx_oclax_stack_top_s         cn70xxp1;
 	struct cvmx_oclax_stack_top_s         cn78xx;
 };
 typedef union cvmx_oclax_stack_top cvmx_oclax_stack_top_t;
@@ -1009,14 +1034,15 @@ union cvmx_oclax_stack_wrap {
 	struct cvmx_oclax_stack_wrap_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t wraps                        : 32; /**< Number of times stack has been reset to OCLA(0..4)_STACK_BASE since trigger. Cleared when
-                                                         OCLA(0..4)_STATE_INT[TRIG] clear. */
+	uint64_t wraps                        : 32; /**< Number of times stack has been reset to OCLA()_STACK_BASE since trigger. Cleared when
+                                                         OCLA()_STATE_INT[TRIG] clear. */
 #else
 	uint64_t wraps                        : 32;
 	uint64_t reserved_32_63               : 32;
 #endif
 	} s;
 	struct cvmx_oclax_stack_wrap_s        cn70xx;
+	struct cvmx_oclax_stack_wrap_s        cn70xxp1;
 	struct cvmx_oclax_stack_wrap_s        cn78xx;
 };
 typedef union cvmx_oclax_stack_wrap cvmx_oclax_stack_wrap_t;
@@ -1036,6 +1062,7 @@ union cvmx_oclax_stagex {
 #endif
 	} s;
 	struct cvmx_oclax_stagex_s            cn70xx;
+	struct cvmx_oclax_stagex_s            cn70xxp1;
 	struct cvmx_oclax_stagex_s            cn78xx;
 };
 typedef union cvmx_oclax_stagex cvmx_oclax_stagex_t;
@@ -1050,30 +1077,30 @@ union cvmx_oclax_state_int {
 	uint64_t fsm1_state                   : 4;  /**< FSM1 current state. */
 	uint64_t fsm0_state                   : 4;  /**< FSM0 current state. */
 	uint64_t reserved_36_55               : 20;
-	uint64_t fsm1_rst                     : 1;  /**< FSM1 hold in state zero. Writing one to OCLA(0..4)_STATE_SET[FSM1_RST] sets this bit and
-                                                         holds FSM1 in state zero, writing one to OCLA(0..4)_STATE_INT[FSM1_RST] removes the hold. */
-	uint64_t fsm0_rst                     : 1;  /**< FSM0 hold in state zero. Writing one to OCLA(0..4)_STATE_SET[FSM0_RST] sets this bit and
-                                                         holds FSM0 in state zero, writing one to OCLA(0..4)_STATE_INT[FSM0_RST] removes the hold. */
+	uint64_t fsm1_rst                     : 1;  /**< FSM1 hold in state zero. Writing one to OCLA()_STATE_SET[FSM1_RST] sets this bit and
+                                                         holds FSM1 in state zero, writing one to OCLA()_STATE_INT[FSM1_RST] removes the hold. */
+	uint64_t fsm0_rst                     : 1;  /**< FSM0 hold in state zero. Writing one to OCLA()_STATE_SET[FSM0_RST] sets this bit and
+                                                         holds FSM0 in state zero, writing one to OCLA()_STATE_INT[FSM0_RST] removes the hold. */
 	uint64_t fsm1_ena                     : 1;  /**< FSM1 sequencing enabled. */
 	uint64_t fsm0_ena                     : 1;  /**< FSM0 sequencing enabled. */
 	uint64_t reserved_19_31               : 13;
-	uint64_t ddrfull                      : 1;  /**< DDR buffer wrapped. Asserted when OCLA(0..4)_STACK_CUR has wrapped and been re-initialized
-                                                         to OCLA(0..4)_STACK_BASE. */
-	uint64_t wmark                        : 1;  /**< Internal buffer watermark reached. Asserted when OCLA(0..4)_FIFO_DEPTH >
-                                                         OCLA(0..4)_FIFO_LIMIT[WMARK]. */
-	uint64_t overfull                     : 1;  /**< Capture ended due to FIFO overflow. Asserted when OCLA(0..4)_FIFO_DEPTH >
-                                                         OCLA(0..4)_FIFO_LIMIT[OVERFULL]. */
-	uint64_t trigfull                     : 1;  /**< Capture ended due to buffer full. Asserted when OCLA(0..4)_FIFO_TRIG[LIMIT] >=
-                                                         OCLA(0..4)_FIFO_TRIG[COUNT]. */
+	uint64_t ddrfull                      : 1;  /**< DDR buffer wrapped. Asserted when OCLA()_STACK_CUR has wrapped and been re-initialized
+                                                         to OCLA()_STACK_BASE. */
+	uint64_t wmark                        : 1;  /**< Internal buffer watermark reached. Asserted when OCLA()_FIFO_DEPTH >
+                                                         OCLA()_FIFO_LIMIT[WMARK]. */
+	uint64_t overfull                     : 1;  /**< Capture ended due to FIFO overflow. Asserted when OCLA()_FIFO_DEPTH >
+                                                         OCLA()_FIFO_LIMIT[OVERFULL]. */
+	uint64_t trigfull                     : 1;  /**< Capture ended due to buffer full. Asserted when OCLA()_FIFO_TRIG[LIMIT] >=
+                                                         OCLA()_FIFO_TRIG[CNT]. */
 	uint64_t captured                     : 1;  /**< Capture started. Asserted when the first capture is made. Informational only; often masked. */
 	uint64_t fsm1_int                     : 1;  /**< FSM1 interrupt requested. */
 	uint64_t fsm0_int                     : 1;  /**< FSM0 interrupt requested. */
 	uint64_t mcd                          : 3;  /**< Multichip Debug (MCD0..2) set. Asserted on MCD received from another coprocessor or code,
-                                                         or FSM MCD request or W1S to OCLA(0..4)_STATE_SET[MCD]. */
-	uint64_t trig                         : 1;  /**< Internal trigger set. Asserted on FSM internal trigger request or W1S to OCLA(0..4)_STATE_SET[TRIG] */
+                                                         or FSM MCD request or W1S to OCLA()_STATE_SET[MCD]. */
+	uint64_t trig                         : 1;  /**< Internal trigger set. Asserted on FSM internal trigger request or W1S to OCLA()_STATE_SET[TRIG]. */
 	uint64_t reserved_4_7                 : 4;
-	uint64_t ovfl                         : 4;  /**< Match counter has overflowed. Asserted when OCLA(0..4)_MAT(0..3)_COUNT >=
-                                                         OCLA(0..4)_MAT(0..3)_THRESH. Informational only; often masked. Writing 1 clears the
+	uint64_t ovfl                         : 4;  /**< Match counter has overflowed. Asserted when OCLA()_MAT()_COUNT >=
+                                                         OCLA()_MAT()_THRESH. Informational only; often masked. Writing 1 clears the
                                                          counter, not just the interrupt. */
 #else
 	uint64_t ovfl                         : 4;
@@ -1098,6 +1125,7 @@ union cvmx_oclax_state_int {
 #endif
 	} s;
 	struct cvmx_oclax_state_int_s         cn70xx;
+	struct cvmx_oclax_state_int_s         cn70xxp1;
 	struct cvmx_oclax_state_int_s         cn78xx;
 };
 typedef union cvmx_oclax_state_int cvmx_oclax_state_int_t;
@@ -1105,32 +1133,32 @@ typedef union cvmx_oclax_state_int cvmx_oclax_state_int_t;
 /**
  * cvmx_ocla#_state_set
  *
- * This register reads identically to OCLA(0..4)_STATE_INT, but allows R/W1S instead of R/W1C access.
+ * This register reads identically to OCLA()_STATE_INT, but allows R/W1S instead of R/W1C access.
  *
  */
 union cvmx_oclax_state_set {
 	uint64_t u64;
 	struct cvmx_oclax_state_set_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t fsm1_state                   : 4;  /**< See OCLA(0..4)_STATE_INT[FSM1_STATE]. */
-	uint64_t fsm0_state                   : 4;  /**< See OCLA(0..4)_STATE_INT[FSM0_STATE]. */
+	uint64_t fsm1_state                   : 4;  /**< See OCLA()_STATE_INT[FSM1_STATE]. */
+	uint64_t fsm0_state                   : 4;  /**< See OCLA()_STATE_INT[FSM0_STATE]. */
 	uint64_t reserved_36_55               : 20;
-	uint64_t fsm1_rst                     : 1;  /**< See OCLA(0..4)_STATE_INT[FSM1_RST]. */
-	uint64_t fsm0_rst                     : 1;  /**< See OCLA(0..4)_STATE_INT[FSM0_RST]. */
-	uint64_t fsm1_ena                     : 1;  /**< See OCLA(0..4)_STATE_INT[FSM1_ENA]. */
-	uint64_t fsm0_ena                     : 1;  /**< See OCLA(0..4)_STATE_INT[FSM0_ENA]. */
+	uint64_t fsm1_rst                     : 1;  /**< See OCLA()_STATE_INT[FSM1_RST]. */
+	uint64_t fsm0_rst                     : 1;  /**< See OCLA()_STATE_INT[FSM0_RST]. */
+	uint64_t fsm1_ena                     : 1;  /**< See OCLA()_STATE_INT[FSM1_ENA]. */
+	uint64_t fsm0_ena                     : 1;  /**< See OCLA()_STATE_INT[FSM0_ENA]. */
 	uint64_t reserved_19_31               : 13;
-	uint64_t ddrfull                      : 1;  /**< See OCLA(0..4)_STATE_INT[DDRFULL]. */
-	uint64_t wmark                        : 1;  /**< See OCLA(0..4)_STATE_INT[WMARK]. */
-	uint64_t overfull                     : 1;  /**< See OCLA(0..4)_STATE_INT[OVERFULL]. */
-	uint64_t trigfull                     : 1;  /**< See OCLA(0..4)_STATE_INT[TRIGFULL]. */
-	uint64_t captured                     : 1;  /**< See OCLA(0..4)_STATE_INT[CAPTURED]. */
-	uint64_t fsm1_int                     : 1;  /**< See OCLA(0..4)_STATE_INT[FSM1_INT]. */
-	uint64_t fsm0_int                     : 1;  /**< See OCLA(0..4)_STATE_INT[FSM0_INT]. */
-	uint64_t mcd                          : 3;  /**< See OCLA(0..4)_STATE_INT[MCD]. */
-	uint64_t trig                         : 1;  /**< See OCLA(0..4)_STATE_INT[TRIG]. */
+	uint64_t ddrfull                      : 1;  /**< See OCLA()_STATE_INT[DDRFULL]. */
+	uint64_t wmark                        : 1;  /**< See OCLA()_STATE_INT[WMARK]. */
+	uint64_t overfull                     : 1;  /**< See OCLA()_STATE_INT[OVERFULL]. */
+	uint64_t trigfull                     : 1;  /**< See OCLA()_STATE_INT[TRIGFULL]. */
+	uint64_t captured                     : 1;  /**< See OCLA()_STATE_INT[CAPTURED]. */
+	uint64_t fsm1_int                     : 1;  /**< See OCLA()_STATE_INT[FSM1_INT]. */
+	uint64_t fsm0_int                     : 1;  /**< See OCLA()_STATE_INT[FSM0_INT]. */
+	uint64_t mcd                          : 3;  /**< See OCLA()_STATE_INT[MCD]. */
+	uint64_t trig                         : 1;  /**< See OCLA()_STATE_INT[TRIG]. */
 	uint64_t reserved_4_7                 : 4;
-	uint64_t ovfl                         : 4;  /**< See OCLA(0..4)_STATE_INT[OVFL]. */
+	uint64_t ovfl                         : 4;  /**< See OCLA()_STATE_INT[OVFL]. */
 #else
 	uint64_t ovfl                         : 4;
 	uint64_t reserved_4_7                 : 4;
@@ -1154,6 +1182,7 @@ union cvmx_oclax_state_set {
 #endif
 	} s;
 	struct cvmx_oclax_state_set_s         cn70xx;
+	struct cvmx_oclax_state_set_s         cn70xxp1;
 	struct cvmx_oclax_state_set_s         cn78xx;
 };
 typedef union cvmx_oclax_state_set cvmx_oclax_state_set_t;
@@ -1173,6 +1202,7 @@ union cvmx_oclax_time {
 #endif
 	} s;
 	struct cvmx_oclax_time_s              cn70xx;
+	struct cvmx_oclax_time_s              cn70xxp1;
 	struct cvmx_oclax_time_s              cn78xx;
 };
 typedef union cvmx_oclax_time cvmx_oclax_time_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-ocx-defs.h b/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
index e3438e2..db39020 100644
--- a/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-ocx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -846,24 +846,25 @@ union cvmx_ocx_com_bist_status {
 	struct cvmx_ocx_com_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_36_63               : 28;
-	uint64_t status                       : 36; /**< 35:34   - Link 2 VC4/VC2         RX FIFOs
-                                                          - 33:32   - Link 2 VC10/VC8/VC6    RX FIFOs
-                                                          - 31:30   - Link 1 VC4/VC2         RX FIFOs
-                                                          - 29:28   - Link 1 VC10/VC8/VC6    RX FIFOs
-                                                          - 27:26   - Link 0 VC4/VC2         RX FIFOs
-                                                          - 25:24   - Link 0 VC10/VC8/VC6    RX FIFOs
-                                                          - 23:22   - Link 2 VC12            RX FIFOs
-                                                          - 21:20   - Link 2 VC1/VC0         RX FIFOs
-                                                          - 19:18   - Link 2 VC5/VC3         RX FIFOs
-                                                          - 17:16   - Link 2 VC11/VC9/VC7    RX FIFOs
-                                                          - 15:14   - Link 1 VC12            RX FIFOs
-                                                          - 13:12   - Link 1 VC1/VC0         RX FIFOs
-                                                          - 11:10   - Link 1 VC5/VC3         RX FIFOs
-                                                         - 9:8   - Link 1 VC11/VC9/VC7    RX FIFOs
-                                                         - 7:6   - Link 0 VC12            RX FIFOs
-                                                         - 5:4   - Link 0 VC1/VC0         RX FIFOs
-                                                         - 3:2   - Link 0 VC5/VC3         RX FIFOs
-                                                         - 1:0   - Link 0 VC11/VC9/VC7    RX FIFOs */
+	uint64_t status                       : 36; /**< RX FIFO status for:
+                                                         <35:34> = Link 2 VC4/VC2.
+                                                         <33:32> = Link 2 VC10/VC8/VC6.
+                                                         <31:30> = Link 1 VC4/VC2.
+                                                         <29:28> = Link 1 VC10/VC8/VC6.
+                                                         <27:26> = Link 0 VC4/VC2.
+                                                         <25:24> = Link 0 VC10/VC8/VC6.
+                                                         <23:22> = Link 2 VC12.
+                                                         <21:20> = Link 2 VC1/VC0.
+                                                         <19:18> = Link 2 VC5/VC3.
+                                                         <17:16> = Link 2 VC11/VC9/VC7.
+                                                         <15:14> = Link 1 VC12.
+                                                         <13:12> = Link 1 VC1/VC0.
+                                                         <11:10> = Link 1 VC5/VC3.
+                                                         <9:8>   = Link 1 VC11/VC9/VC7.
+                                                         <7:6>   = Link 0 VC12.
+                                                         <5:4>   = Link 0 VC1/VC0.
+                                                         <3:2>   = Link 0 VC5/VC3.
+                                                         <1:0>   = Link 0 VC11/VC9/VC7. */
 #else
 	uint64_t status                       : 36;
 	uint64_t reserved_36_63               : 28;
@@ -882,10 +883,10 @@ union cvmx_ocx_com_dual_sort {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_2_63                : 62;
 	uint64_t sort                         : 2;  /**< Sorting procedure for multiple links to same node:
-                                                         00 = All to lowest link number.
-                                                         01 = Split by top/bottom L2C buses. (top to lowest link number).
-                                                         10 = IOC 1st, IOR 2nd, Mem VCs to either based on most room in TX FIFOs.
-                                                         11 = Illegal */
+                                                         0x0 = All to lowest link number.
+                                                         0x1 = Split by top/bottom L2C buses. (top to lowest link number).
+                                                         0x2 = IOC 1st, IOR 2nd, Mem VCs to either based on most room in TX FIFOs.
+                                                         0x3 = Illegal. */
 #else
 	uint64_t sort                         : 2;
 	uint64_t reserved_2_63                : 62;
@@ -903,18 +904,18 @@ union cvmx_ocx_com_int {
 	struct cvmx_ocx_com_int_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_55_63               : 9;
-	uint64_t io_badid                     : 1;  /**< I/O request or response cannot be sent because a link was not found with a packet Node ID
+	uint64_t io_badid                     : 1;  /**< I/O request or response cannot be sent because a link was not found with a packet node ID
                                                          matching the OCX_COM_LINK(0..2)_CTL[ID]
                                                          with OCX_COM_LINK(0..2)_CTL[VALID] bit set. Transaction has been dropped. */
-	uint64_t mem_badid                    : 1;  /**< Memory request or response cannot be send because a link was not found with a packet Node
+	uint64_t mem_badid                    : 1;  /**< Memory request or response cannot be sent because a link was not found with a packet node
                                                          ID matching the OCX_COM_LINK(0..2)_CTL[ID]
                                                          with OCX_COM_LINK(0..2)_CTL[VALID] bit set. Transaction has been dropped. */
 	uint64_t copr_badid                   : 1;  /**< Scheduler add work or buffer pool return cannot be sent because a link was not found with
-                                                         a Node ID matching the
+                                                         a node ID matching the
                                                          OCX_COM_LINK(0..2)_CTL[ID] with OCX_COM_LINK(0..2)_CTL[VALID] bit set.  Transaction has
                                                          been dropped. */
 	uint64_t win_req_badid                : 1;  /**< Window request specified in SLI_WIN_RD_ADDR, SLI_WIN_WR_ADDR, OCX_WIN_CMD or OCX_PP_CMD
-                                                         cannot be sent because a link was not found with a request Node ID matching the
+                                                         cannot be sent because a link was not found with a request node ID matching the
                                                          OCX_COM_LINK(0..2)_CTL[ID]
                                                          with OCX_COM_LINK(0..2)_CTL[VALID] bit set.  Transaction has been dropped. */
 	uint64_t win_req_tout                 : 1;  /**< Window or core request was dropped because it could not be send during the period
@@ -945,6 +946,19 @@ typedef union cvmx_ocx_com_int cvmx_ocx_com_int_t;
 
 /**
  * cvmx_ocx_com_link#_ctl
+ *
+ * This register controls link operations.  In addition, the combination of some of
+ * these conditions are used to generate the link_down status used by the L2C_OCI_CTL[SHTOEN] and
+ * as a reset condition controlled by RST_OCX[RST_LINK].  This link_down status is true when one
+ * of the following occurs:
+ *
+ * * Link is not initialized (see [UP]).
+ * * Retry Counter expired (see OCX_COM_LINK_TIMER and OCX_COM_LINK(0..2)_INT[STOP].
+ * * Receive REINIT request from Link Partner (see [REINIT]).
+ * * Detected Uncorrectable ECC error while reading the Transmit FIFOs (see
+ * OCX_COM_LINK(0..2)_INT[TXFIFO_DBE]).
+ * * Detected Uncorrectable ECC error while reading the Replay Buffer (see
+ * OCX_COM_LINK(0..2)_INT[REPLAY_DBE]).
  */
 union cvmx_ocx_com_linkx_ctl {
 	uint64_t u64;
@@ -954,15 +968,17 @@ union cvmx_ocx_com_linkx_ctl {
 	uint64_t loopback                     : 1;  /**< Reserved. INTERNAL: Diagnostic data loopback.Set to force outgoing link to inbound port.
                                                          All data and link credits are returned and appear to come from link partner. Typically
                                                          SerDes should be disabled during this operation. */
-	uint64_t reinit                       : 1;  /**< Reinitialize Link. Setting bit forces link back into init state and also sets DROP bit.
-                                                         Bit must be cleared for link to operate normally. */
+	uint64_t reinit                       : 1;  /**< Reinitialize link. Setting this bit forces link back into init state and sets the DROP
+                                                         bit.
+                                                         Setting the bit also causes the link to transmit a REINIT request to the link partner.
+                                                         This bit must be cleared for link to operate normally. */
 	uint64_t gate                         : 1;  /**< Enable clock gating on this link to save power. */
 	uint64_t auto_clr                     : 1;  /**< Automatically clear DROP bit if link partner has cleared other side. Typically disabled if
                                                          software wishes to manage deassertion of DROP. */
 	uint64_t drop                         : 1;  /**< Drop all requests on given link. Typically set by hardware when link has failed or been
                                                          reinitialized. Cleared by software once pending link traffic is removed. (See
-                                                         OCX_TLK[0..2]_FIFO[0..13]_CNT.) */
-	uint64_t up                           : 1;  /**< Link is operating normally. */
+                                                         OCX_TLK(0..2)_FIFO(0..13)_CNT.) */
+	uint64_t up                           : 1;  /**< Link is operating normally and exchanging control information. */
 	uint64_t valid                        : 1;  /**< Link has valid lanes and is exchanging information. This bit will never be set if
                                                          OCX_LNK(0..2)_CFG[QLM_SELECT] is zero. */
 	uint64_t id                           : 2;  /**< This ID is used to sort traffic by link. If more than one link has the same value, the
@@ -997,7 +1013,9 @@ union cvmx_ocx_com_linkx_int {
 	uint64_t bad_word                     : 1;  /**< Illegal word decoded on at least one lane of link. */
 	uint64_t align_fail                   : 1;  /**< Link lanes failed to align. */
 	uint64_t align_done                   : 1;  /**< Link lane alignment is complete. */
-	uint64_t up                           : 1;  /**< Link is fully initialized and ready to pass traffic. */
+	uint64_t up                           : 1;  /**< Link initialization is complete and is ready to pass traffic. Note this state occurs some
+                                                         time after the link starts exchanging information as indicated in
+                                                         OCX_COM_LINK(0..2)_CTL[UP]. */
 	uint64_t stop                         : 1;  /**< Link has stopped operating. Link retry count has reached threshold specified in
                                                          OCX_COM_LINK_TIMER; outgoing traffic has been dropped and an initialization request has
                                                          been reissued. */
@@ -1060,19 +1078,19 @@ union cvmx_ocx_com_node {
 	struct cvmx_ocx_com_node_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t fixed_pin                    : 1;  /**< The current value of the OCI_FIXED_ID pin. */
+	uint64_t fixed_pin                    : 1;  /**< The current value of the OCI_FIXED_NODE pin. */
 	uint64_t fixed                        : 1;  /**< ID Valid associated with the chip. This register is used by the link initialization
                                                          software to help assign IDs and is transmitted over OCI. The FIXED field set during a cold
-                                                         reset to the value of the OCI_FIXED_ID pin. The value is also readable in the
-                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT[2]] for each lane. The FIXED field of the link partner
-                                                         can be examined by locally reading the OCX_LNE(0..23)_STS_MSG[RX_META_DAT[2]] on each
+                                                         reset to the value of the OCI_FIXED_NODE pin. The value is also readable in the
+                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT<2>] for each lane. The FIXED field of the link partner
+                                                         can be examined by locally reading the OCX_LNE(0..23)_STS_MSG[RX_META_DAT<2>] on each
                                                          valid lane or remotely reading the OCX_COM_NODE[FIXED] on the link partner. */
 	uint64_t id                           : 2;  /**< Node ID associated with the chip. This register is used by the rest of the chip to
                                                          determine what traffic is transmitted over OCI. The value should not match the
                                                          OCX_COM_LINK(0..2)_CTL[ID] of any active link. The ID field is set during a cold reset to
                                                          the value of the OCI_NODE_ID pins. The value is also readable in the
-                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT[1:0]] for each lane. The ID field of the link partner
-                                                         can be examined by locally reading the OCX_LNE(0..23)_STS_MSG[RX_META_DAT[1:0]] on each
+                                                         OCX_LNE(0..23)_STS_MSG[TX_META_DAT<1:0>] for each lane. The ID field of the link partner
+                                                         can be examined by locally reading the OCX_LNE(0..23)_STS_MSG[RX_META_DAT<1:0>] on each
                                                          valid lane or remotely reading the OCX_COM_NODE[ID] on the link partner. */
 #else
 	uint64_t id                           : 2;
@@ -1167,7 +1185,7 @@ union cvmx_ocx_frcx_stat2 {
 	struct cvmx_ocx_frcx_stat2_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_21_63               : 43;
-	uint64_t align_done                   : 21; /**< Indicates the number of attempt at alignment that succeeded. */
+	uint64_t align_done                   : 21; /**< Indicates the number of attempts at alignment that succeeded. */
 #else
 	uint64_t align_done                   : 21;
 	uint64_t reserved_21_63               : 43;
@@ -1185,7 +1203,7 @@ union cvmx_ocx_frcx_stat3 {
 	struct cvmx_ocx_frcx_stat3_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_21_63               : 43;
-	uint64_t align_fail                   : 21; /**< Indicates the number of attempt at alignment that failed. */
+	uint64_t align_fail                   : 21; /**< Indicates the number of attempts at alignment that failed. */
 #else
 	uint64_t align_fail                   : 21;
 	uint64_t reserved_21_63               : 43;
@@ -1204,7 +1222,7 @@ union cvmx_ocx_lnex_bad_cnt {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
 	uint64_t tx_bad_crc32                 : 1;  /**< Send 1 diagnostic word with bad CRC32 to the selected lane.
-                                                         Note: injects just once. */
+                                                         Injects just once. */
 	uint64_t tx_bad_6467_cnt              : 5;  /**< Send N bad 64B/67B code words on selected lane. */
 	uint64_t tx_bad_sync_cnt              : 3;  /**< Send N bad sync words on selected lane. */
 	uint64_t tx_bad_scram_cnt             : 3;  /**< Send N bad scram state on selected lane. */
@@ -1256,8 +1274,8 @@ union cvmx_ocx_lnex_int {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_10_63               : 54;
 	uint64_t disp_err                     : 1;  /**< RX disparity error encountered. */
-	uint64_t bad_64b67b                   : 1;  /**< Bad 64B/67B codeword encountered. Once the bad word reaches link, as
-                                                         denoted by OCX_COM_LINK(0..2)_INT[BAD_WORD], a retry handshake is initiated. */
+	uint64_t bad_64b67b                   : 1;  /**< Bad 64B/67B codeword encountered. Once the bad word reaches the link, as denoted by
+                                                         OCX_COM_LINK(0..2)_INT[BAD_WORD], a retry handshake is initiated. */
 	uint64_t stat_cnt_ovfl                : 1;  /**< RX lane statistic counter overflow. */
 	uint64_t stat_msg                     : 1;  /**< Status bits for the link or a lane transitioned from a 1 (healthy) to a 0 (problem). */
 	uint64_t dskew_fifo_ovfl              : 1;  /**< RX deskew FIFO overflow occurred. */
@@ -1329,7 +1347,7 @@ union cvmx_ocx_lnex_stat00 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t ser_lock_loss_cnt            : 18; /**< Number of times the lane lost clock-data-recovery. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t ser_lock_loss_cnt            : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1348,7 +1366,7 @@ union cvmx_ocx_lnex_stat01 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t bdry_sync_loss_cnt           : 18; /**< Number of times a lane lost word boundary synchronization. Saturates. Interrupt on
-                                                         saturation if OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         saturation if OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t bdry_sync_loss_cnt           : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1367,7 +1385,7 @@ union cvmx_ocx_lnex_stat02 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t syncw_bad_cnt                : 18; /**< Number of bad synchronization words. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t syncw_bad_cnt                : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1386,7 +1404,7 @@ union cvmx_ocx_lnex_stat03 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t syncw_good_cnt               : 18; /**< Number of good synchronization words. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t syncw_good_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1405,7 +1423,7 @@ union cvmx_ocx_lnex_stat04 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t bad_64b67b_cnt               : 18; /**< Number of bad 64B/67B words, meaning bit 65 or 64 has been corrupted. Saturates. Interrupt
-                                                         on saturation if OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         on saturation if OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t bad_64b67b_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1424,7 +1442,7 @@ union cvmx_ocx_lnex_stat05 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_27_63               : 37;
 	uint64_t data_word_cnt                : 27; /**< Number of data words received. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t data_word_cnt                : 27;
 	uint64_t reserved_27_63               : 37;
@@ -1443,7 +1461,7 @@ union cvmx_ocx_lnex_stat06 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_27_63               : 37;
 	uint64_t cntl_word_cnt                : 27; /**< Number of control words received. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t cntl_word_cnt                : 27;
 	uint64_t reserved_27_63               : 37;
@@ -1462,7 +1480,7 @@ union cvmx_ocx_lnex_stat07 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t unkwn_word_cnt               : 18; /**< Number of unknown control words. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t unkwn_word_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1482,7 +1500,7 @@ union cvmx_ocx_lnex_stat08 {
 	uint64_t reserved_18_63               : 46;
 	uint64_t scrm_sync_loss_cnt           : 18; /**< Number of times scrambler synchronization was lost (due to either 4 consecutive bad sync
                                                          words or 3 consecutive scrambler state mismatches). Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t scrm_sync_loss_cnt           : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1501,7 +1519,7 @@ union cvmx_ocx_lnex_stat09 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t scrm_match_cnt               : 18; /**< Number of scrambler state matches received. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t scrm_match_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1520,7 +1538,7 @@ union cvmx_ocx_lnex_stat10 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t skipw_good_cnt               : 18; /**< Number of good skip words. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t skipw_good_cnt               : 18;
 	uint64_t reserved_18_63               : 46;
@@ -1539,7 +1557,7 @@ union cvmx_ocx_lnex_stat11 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_27_63               : 37;
 	uint64_t crc32_err_cnt                : 27; /**< Number of errors in the lane CRC. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t crc32_err_cnt                : 27;
 	uint64_t reserved_27_63               : 37;
@@ -1558,7 +1576,7 @@ union cvmx_ocx_lnex_stat12 {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_27_63               : 37;
 	uint64_t crc32_match_cnt              : 27; /**< Number of CRC32 matches received. Saturates. Interrupt on saturation if
-                                                         OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+                                                         OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t crc32_match_cnt              : 27;
 	uint64_t reserved_27_63               : 37;
@@ -1576,8 +1594,8 @@ union cvmx_ocx_lnex_stat13 {
 	struct cvmx_ocx_lnex_stat13_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t trn_bad_cnt                  : 16; /**< Number of training frames received with an invalid control channel.
-                                                         Saturates. Interrupt on saturation if OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+	uint64_t trn_bad_cnt                  : 16; /**< Number of training frames received with an invalid control channel. Saturates. Interrupt
+                                                         on saturation if OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t trn_bad_cnt                  : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1595,8 +1613,8 @@ union cvmx_ocx_lnex_stat14 {
 	struct cvmx_ocx_lnex_stat14_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t trn_prbs_bad_cnt             : 16; /**< Number of training frames received with a bad PRBS pattern.
-                                                         Saturates. Interrupt on saturation if OCX_LNEx_INT_EN[STAT_CNT_OVFL] is set. */
+	uint64_t trn_prbs_bad_cnt             : 16; /**< Number of training frames received with a bad PRBS pattern. Saturates. Interrupt on
+                                                         saturation if OCX_LNE(0..23)_INT_EN[STAT_CNT_OVFL] is set. */
 #else
 	uint64_t trn_prbs_bad_cnt             : 16;
 	uint64_t reserved_16_63               : 48;
@@ -1671,19 +1689,21 @@ union cvmx_ocx_lnex_trn_ld {
 	uint64_t u64;
 	struct cvmx_ocx_lnex_trn_ld_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_49_63               : 15;
-	uint64_t ld_cu_val                    : 1;  /**< Local device coefficient update field valid */
-	uint64_t ld_cu_dat                    : 16; /**< Local device coefficient update field data */
+	uint64_t lp_manual                    : 1;  /**< Allow software to manually manipulate local device CU/SR by ignoring hardware update. */
+	uint64_t reserved_49_62               : 14;
+	uint64_t ld_cu_val                    : 1;  /**< Local device coefficient update field valid. */
+	uint64_t ld_cu_dat                    : 16; /**< Local device coefficient update field data. */
 	uint64_t reserved_17_31               : 15;
-	uint64_t ld_sr_val                    : 1;  /**< Local device status report field valid */
-	uint64_t ld_sr_dat                    : 16; /**< Local device status report field data */
+	uint64_t ld_sr_val                    : 1;  /**< Local device status report field valid. */
+	uint64_t ld_sr_dat                    : 16; /**< Local device status report field data. */
 #else
 	uint64_t ld_sr_dat                    : 16;
 	uint64_t ld_sr_val                    : 1;
 	uint64_t reserved_17_31               : 15;
 	uint64_t ld_cu_dat                    : 16;
 	uint64_t ld_cu_val                    : 1;
-	uint64_t reserved_49_63               : 15;
+	uint64_t reserved_49_62               : 14;
+	uint64_t lp_manual                    : 1;
 #endif
 	} s;
 	struct cvmx_ocx_lnex_trn_ld_s         cn78xx;
@@ -1697,21 +1717,19 @@ union cvmx_ocx_lnex_trn_lp {
 	uint64_t u64;
 	struct cvmx_ocx_lnex_trn_lp_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t lp_manual                    : 1;  /**< Allow software to manually manipulate local device CU/SR by ignoring hardware updated. */
-	uint64_t reserved_49_62               : 14;
-	uint64_t lp_cu_val                    : 1;  /**< Link partner coefficient update field valid */
-	uint64_t lp_cu_dat                    : 16; /**< Link partner coefficient update field data */
+	uint64_t reserved_49_63               : 15;
+	uint64_t lp_cu_val                    : 1;  /**< Link partner coefficient update field valid. */
+	uint64_t lp_cu_dat                    : 16; /**< Link partner coefficient update field data. */
 	uint64_t reserved_17_31               : 15;
-	uint64_t lp_sr_val                    : 1;  /**< Link partner status report field valid */
-	uint64_t lp_sr_dat                    : 16; /**< Link partner status report field data */
+	uint64_t lp_sr_val                    : 1;  /**< Link partner status report field valid. */
+	uint64_t lp_sr_dat                    : 16; /**< Link partner status report field data. */
 #else
 	uint64_t lp_sr_dat                    : 16;
 	uint64_t lp_sr_val                    : 1;
 	uint64_t reserved_17_31               : 15;
 	uint64_t lp_cu_dat                    : 16;
 	uint64_t lp_cu_val                    : 1;
-	uint64_t reserved_49_62               : 14;
-	uint64_t lp_manual                    : 1;
+	uint64_t reserved_49_63               : 15;
 #endif
 	} s;
 	struct cvmx_ocx_lnex_trn_lp_s         cn78xx;
@@ -1730,11 +1748,11 @@ union cvmx_ocx_lne_dbg {
                                                          OCX_QLM(0..5)_CFG[SER_LANE_BAD]. For diagnostic use only. */
 	uint64_t reserved_38_39               : 2;
 	uint64_t frc_stats_ena                : 1;  /**< Enable FRC statistic counters. */
-	uint64_t rx_dis_psh_skip              : 1;  /**< When RX_DIS_PSH_SKIP=0, skip words are de-stripped. When RX_DIS_PSH_SKIP=1, skip words are
+	uint64_t rx_dis_psh_skip              : 1;  /**< When RX_DIS_PSH_SKIP=0, skip words are destripped. When RX_DIS_PSH_SKIP=1, skip words are
                                                          discarded in the lane logic. If the lane is in internal loopback mode, RX_DIS_PSH_SKIP is
                                                          ignored and skip words are always discarded in the lane logic. */
-	uint64_t rx_mfrm_len                  : 2;  /**< The quantity of data received on each lane including one sync word, scrambler state, diag
-                                                         word, zero or more skip words, and the data payload.
+	uint64_t rx_mfrm_len                  : 2;  /**< The quantity of data received on each lane including one sync word, scrambler state,
+                                                         diagnostic word, zero or more skip words, and the data payload.
                                                          0x0 = 2048 words.
                                                          0x1 = 1024 words.
                                                          0x2 = 512 words.
@@ -1743,11 +1761,11 @@ union cvmx_ocx_lne_dbg {
                                                          to all open channels. */
 	uint64_t rx_dis_scram                 : 1;  /**< Disable lane scrambler. */
 	uint64_t reserved_5_31                : 27;
-	uint64_t tx_lane_rev                  : 1;  /**< TX lane reversal. When enabled, lane de-striping is performed from the most significant
+	uint64_t tx_lane_rev                  : 1;  /**< TX lane reversal. When enabled, lane destriping is performed from the most significant
                                                          lane enabled to least significant lane enabled QLM_SELECT must be zero before changing
                                                          LANE_REV. */
-	uint64_t tx_mfrm_len                  : 2;  /**< The quantity of data sent on each lane including one sync word, scrambler state, diag
-                                                         word, zero or more skip words, and the data payload.
+	uint64_t tx_mfrm_len                  : 2;  /**< The quantity of data sent on each lane including one sync word, scrambler state,
+                                                         diagnostic word, zero or more skip words, and the data payload.
                                                          0x0 = 2048 words.
                                                          0x1 = 1024 words.
                                                          0x2 = 512 words.
@@ -1782,51 +1800,51 @@ union cvmx_ocx_lnkx_cfg {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_54_63               : 10;
 	uint64_t qlm_manual                   : 6;  /**< QLM manual mask, where each bit corresponds to a QLM. A link automatically selects a QLM
-                                                         unless either:
-                                                         QLM_MANUAL[QLM] is set
-                                                         QLM is not eligible for the link
-                                                         QLM_MANUAL<0> = LNE(0..3) = QLM0.
-                                                         QLM_MANUAL<1> = LNE(7..4) = QLM1.
-                                                         QLM_MANUAL<2> = LNE(11..8) = QLM2.
-                                                         QLM_MANUAL<3> = LNE(15..12) = QLM3.
-                                                         QLM_MANUAL<4> = LNE(19..16) = QLM4.
-                                                         QLM_MANUAL<5> = LNE(23..23) = QLM5.
-                                                         LINK 0 may not select QLM4, QLM5.
-                                                         LINK 1 may not select QLM0, QLM1, QLM4, QLM5.
-                                                         LINK 2 may not select QLM0, QLM1.
-                                                         During a cold reset, this field is initialized to 0x3f when pi_oci_spd == 0xf.
-                                                         During a cold reset, this field is initialized to 0x0  when pi_oci_spd != 0xf.
+                                                         unless either QLM_MANUAL[QLM] is set or a QLM is not eligible for the link.
+                                                         _ QLM_MANUAL<0> = LNE(0..3) = QLM0.
+                                                         _ QLM_MANUAL<1> = LNE(7..4) = QLM1.
+                                                         _ QLM_MANUAL<2> = LNE(11..8) = QLM2.
+                                                         _ QLM_MANUAL<3> = LNE(15..12) = QLM3.
+                                                         _ QLM_MANUAL<4> = LNE(19..16) = QLM4.
+                                                         _ QLM_MANUAL<5> = LNE(23..23) = QLM5.
+                                                         _ LINK 0 may not select QLM4, QLM5.
+                                                         _ LINK 1 may not select QLM0, QLM1, QLM4, QLM5.
+                                                         _ LINK 2 may not select QLM0, QLM1.
+                                                         During a cold reset, this field is initialized to 0x3F when OCI_SPD<3:0> == 0xF.
+                                                         During a cold reset, this field is initialized to 0x0 when OCI_SPD<3:0> != 0xF.
                                                          This field is not modified by hardware at any other time.
                                                          This field is not affected by soft or warm reset. */
 	uint64_t reserved_38_47               : 10;
 	uint64_t qlm_select                   : 6;  /**< QLM select mask, where each bit corresponds to a QLM. A link will transmit/receive data
                                                          using only the selected QLMs. A link is enabled if any QLM is selected. The same QLM
                                                          should not be selected for multiple links.
-                                                         NOTE: LANE_REV has no effect on this mapping.
-                                                         QLM_SELECT<0> = LNE(0..3) = QLM0.
-                                                         QLM_SELECT<1> = LNE(7..4) = QLM1.
-                                                         QLM_SELECT<2> = LNE(11..8) = QLM2.
-                                                         QLM_SELECT<3> = LNE(15..12) = QLM3.
-                                                         QLM_SELECT<4> = LNE(19..16) = QLM4.
-                                                         QLM_SELECT<5> = LNE(23..23) = QLM5.
-                                                         LINK 0 may not select QLM4, QLM5.
-                                                         LINK 1 may not select QLM0, QLM1, QLM4, QLM5.
-                                                         LINK 2 may not select QLM0, QLM1.
-                                                         LINK 2 may not select QLM2 or QLM3 when LINK1 selects any QLM.
-                                                         LINK 0 may not select QLM2 or QLM3 when LINK1 selects any QLM.
-                                                         LINK 0 automatically selects QLM0 when QLM_MANUAL[0]=0
-                                                         LINK 0 automatically selects QLM1 when QLM_MANUAL[1]=0
-                                                         LINK 0 automatically selects QLM2 when QLM_MANUAL[2]=0 and OCX_QLM2_CFG.SER_LOCAL=0
-                                                         LINK 1 automatically selects QLM2 when QLM_MANUAL[2]=0 and OCX_QLM2_CFG.SER_LOCAL=1
-                                                         LINK 1 automatically selects QLM3 when QLM_MANUAL[3]=0 and OCX_QLM3_CFG.SER_LOCAL=1
-                                                         LINK 2 automatically selects QLM3 when QLM_MANUAL[3]=0 and OCX_QLM3_CFG.SER_LOCAL=0
-                                                         LINK 3 automatically selects QLM4 when QLM_MANUAL[4]=0
-                                                         LINK 3 automatically selects QLM5 when QLM_MANUAL[5]=0
-                                                         NOTE: A link with QLM_SELECT = 000000 is invalid and will never exchange traffic with the
-                                                         link partner */
-	uint64_t reserved_10_31               : 22;
+                                                         LANE_REV has no effect on this mapping.
+                                                         _ QLM_SELECT<0> = LNE(0..3) = QLM0.
+                                                         _ QLM_SELECT<1> = LNE(7..4) = QLM1.
+                                                         _ QLM_SELECT<2> = LNE(11..8) = QLM2.
+                                                         _ QLM_SELECT<3> = LNE(15..12) = QLM3.
+                                                         _ QLM_SELECT<4> = LNE(19..16) = QLM4.
+                                                         _ QLM_SELECT<5> = LNE(23..23) = QLM5.
+                                                         _ LINK 0 may not select QLM4, QLM5.
+                                                         _ LINK 1 may not select QLM0, QLM1, QLM4, QLM5.
+                                                         _ LINK 2 may not select QLM0, QLM1.
+                                                         _ LINK 2 may not select QLM2 or QLM3 when LINK1 selects any QLM.
+                                                         _ LINK 0 may not select QLM2 or QLM3 when LINK1 selects any QLM.
+                                                         _ LINK 0 automatically selects QLM0 when QLM_MANUAL<0>=0.
+                                                         _ LINK 0 automatically selects QLM1 when QLM_MANUAL<1>=0.
+                                                         _ LINK 0 automatically selects QLM2 when QLM_MANUAL<2>=0 and OCX_QLM2_CFG.SER_LOCAL=0.
+                                                         _ LINK 1 automatically selects QLM2 when QLM_MANUAL<2>=0 and OCX_QLM2_CFG.SER_LOCAL=1.
+                                                         _ LINK 1 automatically selects QLM3 when QLM_MANUAL<3>=0 and OCX_QLM3_CFG.SER_LOCAL=1.
+                                                         _ LINK 2 automatically selects QLM3 when QLM_MANUAL<3>=0 and OCX_QLM3_CFG.SER_LOCAL=0.
+                                                         _ LINK 3 automatically selects QLM4 when QLM_MANUAL<4>=0.
+                                                         _ LINK 3 automatically selects QLM5 when QLM_MANUAL<5>=0.
+                                                         A link with QLM_SELECT = 000000 is invalid and will never exchange traffic with the
+                                                         link partner. */
+	uint64_t reserved_29_31               : 3;
+	uint64_t data_rate                    : 13; /**< Reserved. */
+	uint64_t low_delay                    : 6;  /**< Reserved. */
 	uint64_t lane_align_dis               : 1;  /**< Disable the RX lane alignment. */
-	uint64_t lane_rev                     : 1;  /**< RX lane reversal.   When enabled, lane de-striping is performed from the most significant
+	uint64_t lane_rev                     : 1;  /**< RX lane reversal.   When enabled, lane destriping is performed from the most significant
                                                          lane enabled to least significant lane enabled QLM_SELECT must be zero before changing
                                                          LANE_REV. */
 	uint64_t reserved_0_7                 : 8;
@@ -1834,7 +1852,9 @@ union cvmx_ocx_lnkx_cfg {
 	uint64_t reserved_0_7                 : 8;
 	uint64_t lane_rev                     : 1;
 	uint64_t lane_align_dis               : 1;
-	uint64_t reserved_10_31               : 22;
+	uint64_t low_delay                    : 6;
+	uint64_t data_rate                    : 13;
+	uint64_t reserved_29_31               : 3;
 	uint64_t qlm_select                   : 6;
 	uint64_t reserved_38_47               : 10;
 	uint64_t qlm_manual                   : 6;
@@ -1860,27 +1880,27 @@ union cvmx_ocx_pp_cmd {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t wr_mask                      : 8;  /**< Mask for the data to be written. When a bit is 1, the corresponding byte will be written.
                                                          The values of this field must be contiguous and for 1, 2, 4, or 8 byte operations and
-                                                         aligned to operation size. A Value of 0 will produce unpredictable results. Field is
+                                                         aligned to operation size. A value of 0 will produce unpredictable results. Field is
                                                          ignored during a read (LD_OP=1). */
 	uint64_t reserved_51_55               : 5;
 	uint64_t ld_cmd                       : 2;  /**< The load command sent with the read:
-                                                         0x0 = Load 1-bytes
-                                                         0x1 = Load 2-bytes
-                                                         0x2 = Load 4-bytes
-                                                         0x3 = Load 8-bytes */
+                                                         0x0 = Load 1-bytes.
+                                                         0x1 = Load 2-bytes.
+                                                         0x2 = Load 4-bytes.
+                                                         0x3 = Load 8-bytes. */
 	uint64_t ld_op                        : 1;  /**< Operation Type 0=Store 1=Load operation. */
-	uint64_t addr                         : 48; /**< The address used in both the load and store operations
-                                                         <47:40> = NCB_ID
-                                                         <39:38> = 0, Not used
-                                                         <37:36> = OCI_ID
-                                                         <35:0> = Address
+	uint64_t addr                         : 48; /**< The address used in both the load and store operations:
+                                                         <47:40> = NCB_ID.
+                                                         <39:38> = 0, Not used.
+                                                         <37:36> = OCI_ID.
+                                                         <35:0> = Address.
                                                          When <47:43> == SLI & <42:40> == 0 bits <39:0> are:
-                                                         <39:38> = 0, Not used
-                                                         <37:36> = OCI_ID
-                                                         <35:32> = 0, Not used
-                                                         <31:24> = RSL_ID
-                                                         <23:0> = RSL register offset
-                                                         Note: <2:0> are ignored in a store operation */
+                                                         <39:38> = 0, Not used.
+                                                         <37:36> = OCI_ID.
+                                                         <35:32> = 0, Not used.
+                                                         <31:24> = RSL_ID.
+                                                         <23:0> = RSL register offset.
+                                                         <2:0> are ignored in a store operation. */
 #else
 	uint64_t addr                         : 48;
 	uint64_t ld_op                        : 1;
@@ -1896,7 +1916,7 @@ typedef union cvmx_ocx_pp_cmd cvmx_ocx_pp_cmd_t;
 /**
  * cvmx_ocx_pp_rd_data
  *
- * This register is the read response data associated with core command. Reads all 1s until
+ * This register is the read response data associated with core command. Reads all-ones until
  * response is received.
  * This register has the same bit fields as OCX_WIN_RD_DATA.
  */
@@ -1904,7 +1924,7 @@ union cvmx_ocx_pp_rd_data {
 	uint64_t u64;
 	struct cvmx_ocx_pp_rd_data_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t data                         : 64; /**< Read Response Data */
+	uint64_t data                         : 64; /**< Read response data. */
 #else
 	uint64_t data                         : 64;
 #endif
@@ -1940,9 +1960,12 @@ union cvmx_ocx_qlmx_cfg {
 	uint64_t u64;
 	struct cvmx_ocx_qlmx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_42_63               : 22;
-	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes. */
-	uint64_t reserved_26_31               : 6;
+	uint64_t ser_low                      : 4;  /**< Reserved. */
+	uint64_t reserved_42_59               : 18;
+	uint64_t ser_limit                    : 10; /**< Reduce latency by limiting the amount of data in flight for each SerDes. For diagnostic
+                                                         use only.  Removed in pass 2. */
+	uint64_t crd_dis                      : 1;  /**< For diagnostic use only. */
+	uint64_t reserved_26_30               : 5;
 	uint64_t timer_dis                    : 1;  /**< Disable bad lane timer. A timer counts core clocks (RCLKs) when any enabled lane is not
                                                          ready, i.e. not in the scrambler sync state. If this timer expires before all enabled
                                                          lanes can be made ready, then any lane which is not ready is disabled via
@@ -1962,21 +1985,21 @@ union cvmx_ocx_qlmx_cfg {
                                                          0 = TX without inversion.
                                                          1 = TX with inversion. */
 	uint64_t reserved_1_2                 : 2;
-	uint64_t ser_local                    : 1;  /**< Auto initialization may set OCX_LNK0_CFG[QLM_SELECT<2>] = 1 only if
+	uint64_t ser_local                    : 1;  /**< _ Auto initialization may set OCX_LNK0_CFG[QLM_SELECT<2>] = 1 only if
                                                          OCX_QLM2_CFG[SER_LOCAL] = 0.
-                                                         Auto initialization may set OCX_LNK1_CFG[QLM_SELECT<2>] = 1 only if
+                                                         _ Auto initialization may set OCX_LNK1_CFG[QLM_SELECT<2>] = 1 only if
                                                          OCX_QLM2_CFG[SER_LOCAL] = 1.
-                                                         Auto initialization may set OCX_LNK1_CFG[QLM_SELECT<3>] = 1 only if
+                                                         _ Auto initialization may set OCX_LNK1_CFG[QLM_SELECT<3>] = 1 only if
                                                          OCX_QLM3_CFG[SER_LOCAL] = 1.
-                                                         Auto initialization may set OCX_LNK2_CFG[QLM_SELECT<3>] = 1 only if
+                                                         _ Auto initialization may set OCX_LNK2_CFG[QLM_SELECT<3>] = 1 only if
                                                          OCX_QLM3_CFG[SER_LOCAL] = 0.
-                                                         QLM0/1 can only participate in LNK0; therefore
+                                                         _ QLM0/1 can only participate in LNK0; therefore
                                                          OCX_QLM0/1_CFG[SER_LOCAL] has no effect.
-                                                         QLM4/5 can only participate in LNK2; therefore
+                                                         _ QLM4/5 can only participate in LNK2; therefore
                                                          OCX_QLM4/5_CFG[SER_LOCAL] has no effect.
                                                          During a cold reset, initialized as follows:
-                                                         OCX_QLM2_CFG.SER_LOCAL = pi_oci2_link1
-                                                         OCX_QLM3_CFG.SER_LOCAL = pi_oci3_link1
+                                                         _ OCX_QLM2_CFG.SER_LOCAL = pi_oci2_link1.
+                                                         _ OCX_QLM3_CFG.SER_LOCAL = pi_oci3_link1.
                                                          The combo of pi_oci2_link1=1 and pi_oci3_link1=0 is illegal.
                                                          The combo of OCX_QLM2_CFG.SER_LOCAL=1 and OCX_QLM3_CFG.SER_LOCAL=0 is illegal. */
 #else
@@ -1991,9 +2014,11 @@ union cvmx_ocx_qlmx_cfg {
 	uint64_t ser_lane_ready               : 4;
 	uint64_t trn_ena                      : 1;
 	uint64_t timer_dis                    : 1;
-	uint64_t reserved_26_31               : 6;
+	uint64_t reserved_26_30               : 5;
+	uint64_t crd_dis                      : 1;
 	uint64_t ser_limit                    : 10;
-	uint64_t reserved_42_63               : 22;
+	uint64_t reserved_42_59               : 18;
+	uint64_t ser_low                      : 4;
 #endif
 	} s;
 	struct cvmx_ocx_qlmx_cfg_s            cn78xx;
@@ -2077,11 +2102,11 @@ union cvmx_ocx_rlkx_enables {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
 	uint64_t mcd                          : 1;  /**< Master enable for all inbound MCD bits. This bit must be enabled by software. once any
-                                                         Authentik validation has occured and before any MCD traffic is generated. MCD traffic is
+                                                         Authentik validation has occurred and before any MCD traffic is generated. MCD traffic is
                                                          typically controlled by the OCX_TLK(0..2)_MCD_CTL register. */
 	uint64_t m_req                        : 1;  /**< Master enable for all inbound memory requests. This bit is typically set at reset but is
                                                          cleared when operating in Authentik mode and must be enabled by software. */
-	uint64_t io_req                       : 1;  /**< Master enable for all inbound I/O Requests. This bit is typically set at reset but is
+	uint64_t io_req                       : 1;  /**< Master enable for all inbound I/O requests. This bit is typically set at reset but is
                                                          cleared when operating in Authentik mode and must be enabled by software. */
 	uint64_t fwd                          : 1;  /**< Master enable for all inbound forward commands. This bit is typically set at reset but is
                                                          cleared when operating in Authentik mode and must be enabled by software. */
@@ -2175,8 +2200,8 @@ union cvmx_ocx_tlkx_bist_status {
 	struct cvmx_ocx_tlkx_bist_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_15_63               : 49;
-	uint64_t status                       : 15; /**< "14:13 - REPLAY Memories BIST Status [1:0]
-                                                         - 12:0  - TX_FIFO[12:0] by Link VC#" */
+	uint64_t status                       : 15; /**< <14:13> = REPLAY Memories BIST Status <1:0>.
+                                                         <12:0> = TX_FIFO[12:0] by Link VC number. */
 #else
 	uint64_t status                       : 15;
 	uint64_t reserved_15_63               : 49;
@@ -2276,6 +2301,7 @@ typedef union cvmx_ocx_tlkx_lnk_vcx_cnt cvmx_ocx_tlkx_lnk_vcx_cnt_t;
  *
  * This register controls which MCD bits are transported via the link. For proper operation
  * only one link must be enabled in both directions between each pair of link partners.
+ *
  * INTERNAL: If N chips are connected over OCX, N-1 links should have MCD enabled.
  * A single "central" chip should connect all MCD buses and have a single MCD enabled link
  * to each of the other chips.  No MCD enabled links should connect between chips that don't
@@ -2325,8 +2351,8 @@ union cvmx_ocx_tlkx_stat_ctl {
 	uint64_t clear                        : 1;  /**< Setting this bit clears all OCX_TLK(a)_STAT_*CNT, OCX_TLK(a)_STAT_*CMD,
                                                          OCX_TLK(a)_STAT_*PKT and OCX_TLK(0..2)_STAT_*CON registers. */
 	uint64_t enable                       : 1;  /**< This bit controls the capture of statistics to the OCX_TLK(a)_STAT_*CNT,
-                                                         OCX_TLK(a)_STAT_*CMD, OCX_TLK(a)_STAT_*PKT and OCX_TLK(a)_STAT_*CON registers. When set
-                                                         traffic will increment the corresponding registers. When cleared traffic will be ignored. */
+                                                         OCX_TLK(a)_STAT_*CMD, OCX_TLK(a)_STAT_*PKT and OCX_TLK(a)_STAT_*CON registers. When set,
+                                                         traffic will increment the corresponding registers. When cleared, traffic will be ignored. */
 #else
 	uint64_t enable                       : 1;
 	uint64_t clear                        : 1;
@@ -2344,7 +2370,8 @@ union cvmx_ocx_tlkx_stat_data_cnt {
 	uint64_t u64;
 	struct cvmx_ocx_tlkx_stat_data_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t count                        : 64; /**< Number of data blocks transferred over the OCI Link while OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+	uint64_t count                        : 64; /**< Number of data blocks transferred over the OCI Link while OCX_TLK(0..2)_STAT_CTL[ENABLE]
+                                                         has been set. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2361,7 +2388,7 @@ union cvmx_ocx_tlkx_stat_err_cnt {
 	struct cvmx_ocx_tlkx_stat_err_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t count                        : 64; /**< Number of blocks received with an error over the OCI link while
-                                                         OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+                                                         OCX_TLK(0..2)_STAT_CTL[ENABLE] has been set. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2377,7 +2404,8 @@ union cvmx_ocx_tlkx_stat_idle_cnt {
 	uint64_t u64;
 	struct cvmx_ocx_tlkx_stat_idle_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t count                        : 64; /**< Number of idle blocks transferred over the OCI link while OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+	uint64_t count                        : 64; /**< Number of idle blocks transferred over the OCI link while OCX_TLK(0..2)_STAT_CTL[ENABLE]
+                                                         has been set. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2394,7 +2422,7 @@ union cvmx_ocx_tlkx_stat_matx_cnt {
 	struct cvmx_ocx_tlkx_stat_matx_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t count                        : 64; /**< Number of packets that have matched OCX_TLK(a)_STAT_MATCH0 and have been transferred over
-                                                         the OCI Link while OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+                                                         the OCI Link while OCX_TLK(0..2)_STAT_CTL[ENABLE] has been set. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2410,17 +2438,20 @@ union cvmx_ocx_tlkx_stat_matchx {
 	uint64_t u64;
 	struct cvmx_ocx_tlkx_stat_matchx_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_20_63               : 44;
-	uint64_t mask                         : 10; /**< Setting these bits mask (really matches) the corresponding bit comparison for each packet. */
-	uint64_t vc                           : 4;  /**< "These bits are compared against the link VC \# for each packet sent over the link. If both
-                                                         the unmasked VC and CMD bits match, then OCX_TLK(a)_STAT_MAT(b)_CNT is incremented." */
-	uint64_t cmd                          : 6;  /**< These bits are compared against the command for each packet sent over the link. If both
-                                                         the unmasked VC and CMD bits match then OCX_TLK(a)_STAT_MAT(b)_CNT is incremented. */
+	uint64_t reserved_25_63               : 39;
+	uint64_t mask                         : 9;  /**< Setting these bits mask (really matches) the corresponding bit comparison for each packet. */
+	uint64_t reserved_9_15                : 7;
+	uint64_t cmd                          : 5;  /**< These bits are compared against the command for each packet sent over the link. If both
+                                                         the unmasked VC and CMD bits match then OCX_TLK(0..2)_STAT_MAT(0..3)_CNT is incremented. */
+	uint64_t vc                           : 4;  /**< These bits are compared against the link VC number for each packet sent over the link. If
+                                                         both the unmasked VC and CMD bits match, then OCX_TLK(0..2)_STAT_MAT(0..3)_CNT is
+                                                         incremented. */
 #else
-	uint64_t cmd                          : 6;
 	uint64_t vc                           : 4;
-	uint64_t mask                         : 10;
-	uint64_t reserved_20_63               : 44;
+	uint64_t cmd                          : 5;
+	uint64_t reserved_9_15                : 7;
+	uint64_t mask                         : 9;
+	uint64_t reserved_25_63               : 39;
 #endif
 	} s;
 	struct cvmx_ocx_tlkx_stat_matchx_s    cn78xx;
@@ -2434,7 +2465,7 @@ union cvmx_ocx_tlkx_stat_retry_cnt {
 	uint64_t u64;
 	struct cvmx_ocx_tlkx_stat_retry_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t count                        : 64; /**< Number of data blocks repeated over the OCI link while OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+	uint64_t count                        : 64; /**< Number of data blocks repeated over the OCI link while OCX_TLK(0..2)_STAT_CTL[ENABLE] has been set. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2451,7 +2482,7 @@ union cvmx_ocx_tlkx_stat_sync_cnt {
 	struct cvmx_ocx_tlkx_stat_sync_cnt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t count                        : 64; /**< Number of sync (control) blocks transferred over the OCI link while
-                                                         OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+                                                         OCX_TLK(0..2)_STAT_CTL[ENABLE] has been set. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2468,8 +2499,8 @@ union cvmx_ocx_tlkx_stat_vcx_cmd {
 	struct cvmx_ocx_tlkx_stat_vcx_cmd_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t count                        : 64; /**< Number of commands on this VC that have been transfered over the OCI link while
-                                                         OCX_TLK(a)_STAT_CTL[ENABLE] has been set. For VCs 6 thru 13 the number of commands is
-                                                         equal to the number of packets. */
+                                                         OCX_TLK(0..2)_STAT_CTL[ENABLE] has been set. For VCs 6 through 13 the number of commands
+                                                         is equal to the number of packets. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2485,9 +2516,10 @@ union cvmx_ocx_tlkx_stat_vcx_con {
 	uint64_t u64;
 	struct cvmx_ocx_tlkx_stat_vcx_con_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t count                        : 64; /**< Number of conflicts on this VC while OCX_TLK(a)_STAT_CTL[ENABLE] has been set. A conflict
-                                                         is indicated when a VC has one or more packets to send and no link credits are available.
-                                                         VC13 does not require credits so no conflicts are ever indicated (ie. reads 0). */
+	uint64_t count                        : 64; /**< Number of conflicts on this VC while OCX_TLK(0..2)_STAT_CTL[ENABLE] has been set. A
+                                                         conflict is indicated when a VC has one or more packets to send and no link credits are
+                                                         available. VC13 does not require credits so no conflicts are ever indicated (i.e. reads
+                                                         0). */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2504,7 +2536,7 @@ union cvmx_ocx_tlkx_stat_vcx_pkt {
 	struct cvmx_ocx_tlkx_stat_vcx_pkt_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t count                        : 64; /**< Number of packets on this VC that have been transferred over the OCI link while
-                                                         OCX_TLK(a)_STAT_CTL[ENABLE] has been set. */
+                                                         OCX_TLK(0..2)_STAT_CTL[ENABLE] has been set. */
 #else
 	uint64_t count                        : 64;
 #endif
@@ -2528,14 +2560,14 @@ union cvmx_ocx_tlkx_status {
 	uint64_t ackcnt                       : 7;  /**< Number of ACKs waiting to be transmitted. */
 	uint64_t reserved_9_15                : 7;
 	uint64_t drop                         : 1;  /**< Link is dropping all requests. */
-	uint64_t sm                           : 6;  /**< Block State Machine:
+	uint64_t sm                           : 6;  /**< Block state machine:
                                                          Bit<2>: Req / Ack (Init or retry only).
                                                          Bit<3>: Init.
                                                          Bit<4>: Run.
                                                          Bit<5>: Retry.
                                                          Bit<6>: Replay.
                                                          Bit<7>: Replay Pending. */
-	uint64_t cnt                          : 2;  /**< Block Subcount. Should always increment 0,1,2,3,0.. except during TX PHY stall. */
+	uint64_t cnt                          : 2;  /**< Block subcount. Should always increment 0,1,2,3,0.. except during TX PHY stall. */
 #else
 	uint64_t cnt                          : 2;
 	uint64_t sm                           : 6;
@@ -2568,27 +2600,27 @@ union cvmx_ocx_win_cmd {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t wr_mask                      : 8;  /**< Mask for the data to be written. When a bit is 1, the corresponding byte will be written.
                                                          The values of this field must be contiguous and for 1, 2, 4, or 8 byte operations and
-                                                         aligned to operation size. A Value of 0 will produce unpredictable results. Field is
+                                                         aligned to operation size. A value of 0 will produce unpredictable results. Field is
                                                          ignored during a read (LD_OP=1). */
 	uint64_t reserved_51_55               : 5;
 	uint64_t ld_cmd                       : 2;  /**< The load command sent with the read:
-                                                         0x0 = Load 1-bytes
-                                                         0x1 = Load 2-bytes
-                                                         0x2 = Load 4-bytes
-                                                         0x3 = Load 8-bytes */
+                                                         0x0 = Load 1-bytes.
+                                                         0x1 = Load 2-bytes.
+                                                         0x2 = Load 4-bytes.
+                                                         0x3 = Load 8-bytes. */
 	uint64_t ld_op                        : 1;  /**< Operation Type 0=Store 1=Load operation. */
-	uint64_t addr                         : 48; /**< The address used in both the load and store operations
-                                                         <47:40> = NCB_ID
-                                                         <39:38> = 0, Not used
-                                                         <37:36> = OCI_ID
-                                                         <35:0> = Address
+	uint64_t addr                         : 48; /**< The address used in both the load and store operations:
+                                                         <47:40> = NCB_ID.
+                                                         <39:38> = 0, Not used.
+                                                         <37:36> = OCI_ID.
+                                                         <35:0> = Address.
                                                          When <47:43> == SLI & <42:40> == 0 bits <39:0> are:
-                                                         <39:38> = 0, Not used
-                                                         <37:36> = OCI_ID
-                                                         <35:32> = 0, Not used
-                                                         <31:24> = RSL_ID
-                                                         <23:0> = RSL register offset
-                                                         Note: <2:0> are ignored in a store operation */
+                                                         <39:38> = 0, Not used.
+                                                         <37:36> = OCI_ID.
+                                                         <35:32> = 0, Not used.
+                                                         <31:24> = RSL_ID.
+                                                         <23:0> = RSL register offset.
+                                                         <2:0> are ignored in a store operation. */
 #else
 	uint64_t addr                         : 48;
 	uint64_t ld_op                        : 1;
@@ -2605,13 +2637,13 @@ typedef union cvmx_ocx_win_cmd cvmx_ocx_win_cmd_t;
  * cvmx_ocx_win_rd_data
  *
  * For diagnostic use only. This register is the read response data associated with window
- * command. Reads all 1s until response is received.
+ * command. Reads all-ones until response is received.
  */
 union cvmx_ocx_win_rd_data {
 	uint64_t u64;
 	struct cvmx_ocx_win_rd_data_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t data                         : 64; /**< Read Response Data */
+	uint64_t data                         : 64; /**< Read response data. */
 #else
 	uint64_t data                         : 64;
 #endif
@@ -2631,9 +2663,11 @@ union cvmx_ocx_win_timer {
 	struct cvmx_ocx_win_timer_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_16_63               : 48;
-	uint64_t tout                         : 16; /**< Bits <1:0> must be all ones. */
+	uint64_t tout                         : 14; /**< Number of core clocks times four. */
+	uint64_t tout1                        : 2;  /**< Reserved as all-ones. */
 #else
-	uint64_t tout                         : 16;
+	uint64_t tout1                        : 2;
+	uint64_t tout                         : 14;
 	uint64_t reserved_16_63               : 48;
 #endif
 	} s;
diff --git a/arch/mips/include/asm/octeon/cvmx-osm-defs.h b/arch/mips/include/asm/octeon/cvmx-osm-defs.h
index bb4c364..720d3c2 100644
--- a/arch/mips/include/asm/octeon/cvmx-osm-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-osm-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-packet.h b/arch/mips/include/asm/octeon/cvmx-packet.h
index fb9e3af..5e628f0 100644
--- a/arch/mips/include/asm/octeon/cvmx-packet.h
+++ b/arch/mips/include/asm/octeon/cvmx-packet.h
@@ -42,7 +42,7 @@
  *
  * Packet buffer defines.
  *
- * <hr>$Revision: 93476 $<hr>
+ * <hr>$Revision: 95816 $<hr>
  *
  */
 
@@ -55,6 +55,21 @@ extern "C" {
 /* *INDENT-ON* */
 #endif
 
+union cvmx_buf_ptr_pki {
+	uint64_t u64;
+	struct {
+		CVMX_BITFIELD_FIELD(uint64_t size:16,
+		/**< The size of the segment pointed to by addr (in bytes) */
+		CVMX_BITFIELD_FIELD(uint64_t packet_outside_wqe:1,
+		/**< sets is packet is not stored in same buffer as WQE*/
+		CVMX_BITFIELD_FIELD(uint64_t rsvd0:5,
+		CVMX_BITFIELD_FIELD(uint64_t addr:42,	/**< Pointer to the first byte of the data, NOT buffer */
+		))));
+	};
+};
+
+typedef union cvmx_buf_ptr_pki cvmx_buf_ptr_pki_t;
+
 /**
  * This structure defines a buffer pointer on Octeon
  */
@@ -82,48 +97,10 @@ union cvmx_buf_ptr {
 		uint64_t i:1;
 #endif
 	} s;
-#if 0
-	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t size:16;
-		/**< The size of the segment pointed to by addr (in bytes) */
-		uint64_t packet_outside_wqe:1;
-		/**< sets is packet is not stored in same buffer as WQE*/
-		uint64_t rsvd0:5;
-		uint64_t addr:42;
-		/**< Pointer to the first byte of the data, NOT buffer */
-#else
-		uint64_t addr:42;
-		uint64_t rsvd0:5;
-		uint64_t packet_outside_wqe:1;
-		uint64_t size:16;
-#endif
-	} s_cn78xx;
-#endif
 };
 
 typedef union cvmx_buf_ptr cvmx_buf_ptr_t;
 
-typedef	union {
-	uint64_t u64;
-	struct cvmx_buf_ptr_pki_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t size:16;
-		/**< The size of the segment pointed to by addr (in bytes) */
-		uint64_t packet_outside_wqe:1;
-		/**< sets is packet is not stored in same buffer as WQE*/
-		uint64_t rsvd0:5;
-		uint64_t addr:42;
-		/**< Pointer to the first byte of the data, NOT buffer */
-#else
-		uint64_t addr:42;
-		uint64_t rsvd0:5;
-		uint64_t packet_outside_wqe:1;
-		uint64_t size:16;
-#endif
-	} s_cn78xx;
-} cvmx_buf_ptr_pki_t;
-
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-pci-defs.h b/arch/mips/include/asm/octeon/cvmx-pci-defs.h
index d75607e..e8032b1 100644
--- a/arch/mips/include/asm/octeon/cvmx-pci-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pci-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
index bc3054d..3c5734f 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepvfx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1155,12 +1155,12 @@ union cvmx_pcieepvfx_cfg030 {
                                                          reported only in the PF. */
 	uint32_t i_flr                        : 1;  /**< Initiate function level reset (not supported). */
 	uint32_t mrrs                         : 3;  /**< Max read request size.
-                                                         0x0 = 128 B.
-                                                         0x1 = 256 B.
-                                                         0x2 = 512 B.
-                                                         0x3 = 1024 B.
-                                                         0x4 = 2048 B.
-                                                         0x5 = 4096 B. */
+                                                         0x0 = 128 bytes.
+                                                         0x1 = 256 bytes.
+                                                         0x2 = 512 bytes.
+                                                         0x3 = 1024 bytes.
+                                                         0x4 = 2048 bytes.
+                                                         0x5 = 4096 bytes. */
 	uint32_t ns_en                        : 1;  /**< Enable no snoop. */
 	uint32_t ap_en                        : 1;  /**< AUX power PM enable. */
 	uint32_t pf_en                        : 1;  /**< Phantom function enable. */
@@ -1224,8 +1224,13 @@ union cvmx_pcieepvfx_cfg031 {
                                                          configuration. */
 	uint32_t aslpms                       : 2;  /**< Active state link PM support. The default value is the value that software specifies
                                                          during hardware configuration. */
-	uint32_t mlw                          : 6;  /**< Maximum link width. The default value is the value that software specifies during hardware
-                                                         configuration (*1, *4, *8, *16). */
+	uint32_t mlw                          : 6;  /**< Maximum link width.
+                                                         The reset value of this field is determined by the value read from the PEM
+                                                         csr PEM(0..3)_CFG[LANES8].
+                                                         PEM(0..2)_CFG.LANES8       RST_VALUE     NOTE
+                                                           0                          0x4           4 lanes
+                                                           1                          0x8           8 lanes
+                                                         This field is writable through PEM(0..3)_CFG_WR. */
 	uint32_t mls                          : 4;  /**< Maximum link speed.The reset value of this field is controlled by the value read from
                                                          PEM(0..3)_CFG[MD].
                                                          PEM*_CFG
@@ -2284,9 +2289,11 @@ union cvmx_pcieepvfx_cfg463 {
                                                          PCIEEPVF(0..3)_CFG463[FCLTOV] will override the FC latency timer value that the core
                                                          calculates according to the PCIe specification. */
 	uint32_t reserved_29_30               : 2;
-	uint32_t fcltov                       : 13; /**< FC latency timer override value. When you set
-                                                         PCIEEPVF(0..3)_CFG463[FCLTOE], the value in this field will override the FC latency timer
-                                                         value that the core calculates according to the PCIe specification. */
+	uint32_t fcltov                       : 13; /**< FC latency timer override value. When you set PCIEEPVF(0..3)_CFG463[FCLTOE], the value in
+                                                         this
+                                                         field will override the FC latency timer value that the core calculates according to the
+                                                         PCIe
+                                                         specification. */
 	uint32_t reserved_3_15                : 13;
 	uint32_t rqne                         : 1;  /**< Received queue not empty. Indicates there is data in one or more of the receive buffers. */
 	uint32_t trbne                        : 1;  /**< Transmit retry buffer not empty. Indicates that there is data in the transmit retry buffer. */
diff --git a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
index d4c1521..7003b9b 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcieepx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -4237,6 +4237,7 @@ union cvmx_pcieepx_cfg000 {
 	struct cvmx_pcieepx_cfg000_s          cn68xx;
 	struct cvmx_pcieepx_cfg000_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg000_s          cn70xx;
+	struct cvmx_pcieepx_cfg000_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg000_s          cn78xx;
 	struct cvmx_pcieepx_cfg000_s          cnf71xx;
 };
@@ -4324,6 +4325,7 @@ union cvmx_pcieepx_cfg001 {
 	struct cvmx_pcieepx_cfg001_s          cn68xx;
 	struct cvmx_pcieepx_cfg001_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg001_s          cn70xx;
+	struct cvmx_pcieepx_cfg001_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg001_s          cn78xx;
 	struct cvmx_pcieepx_cfg001_s          cnf71xx;
 };
@@ -4365,6 +4367,7 @@ union cvmx_pcieepx_cfg002 {
 	struct cvmx_pcieepx_cfg002_s          cn68xx;
 	struct cvmx_pcieepx_cfg002_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg002_s          cn70xx;
+	struct cvmx_pcieepx_cfg002_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg002_s          cn78xx;
 	struct cvmx_pcieepx_cfg002_s          cnf71xx;
 };
@@ -4415,6 +4418,7 @@ union cvmx_pcieepx_cfg003 {
 	struct cvmx_pcieepx_cfg003_s          cn68xx;
 	struct cvmx_pcieepx_cfg003_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg003_s          cn70xx;
+	struct cvmx_pcieepx_cfg003_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg003_s          cn78xx;
 	struct cvmx_pcieepx_cfg003_s          cnf71xx;
 };
@@ -4430,8 +4434,7 @@ union cvmx_pcieepx_cfg004 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg004_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t lbab                         : 18; /**< Lower bits of the BAR 0 base address */
-	uint32_t reserved_4_13                : 10;
+	uint32_t reserved_4_31                : 28;
 	uint32_t pf                           : 1;  /**< Prefetchable
                                                          This field is writable through PEM(0..1)_CFG_WR.
                                                          However, the application must not change this field. */
@@ -4449,23 +4452,70 @@ union cvmx_pcieepx_cfg004 {
 	uint32_t mspc                         : 1;
 	uint32_t typ                          : 2;
 	uint32_t pf                           : 1;
+	uint32_t reserved_4_31                : 28;
+#endif
+	} s;
+	struct cvmx_pcieepx_cfg004_cn52xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t lbab                         : 18; /**< Lower bits of the BAR 0 base address */
+	uint32_t reserved_4_13                : 10;
+	uint32_t pf                           : 1;  /**< Prefetchable
+                                                         This field is writable through PESC(0..1)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t typ                          : 2;  /**< BAR type
+                                                            o 00 = 32-bit BAR
+                                                            o 10 = 64-bit BAR
+                                                         This field is writable through PESC(0..1)_CFG_WR.
+                                                         However, the application must not change this field. */
+	uint32_t mspc                         : 1;  /**< Memory Space Indicator
+                                                            o 0 = BAR 0 is a memory BAR
+                                                            o 1 = BAR 0 is an I/O BAR
+                                                         This field is writable through PESC(0..1)_CFG_WR.
+                                                         However, the application must not change this field. */
+#else
+	uint32_t mspc                         : 1;
+	uint32_t typ                          : 2;
+	uint32_t pf                           : 1;
 	uint32_t reserved_4_13                : 10;
 	uint32_t lbab                         : 18;
 #endif
-	} s;
-	struct cvmx_pcieepx_cfg004_s          cn52xx;
-	struct cvmx_pcieepx_cfg004_s          cn52xxp1;
-	struct cvmx_pcieepx_cfg004_s          cn56xx;
-	struct cvmx_pcieepx_cfg004_s          cn56xxp1;
-	struct cvmx_pcieepx_cfg004_s          cn61xx;
-	struct cvmx_pcieepx_cfg004_s          cn63xx;
-	struct cvmx_pcieepx_cfg004_s          cn63xxp1;
-	struct cvmx_pcieepx_cfg004_s          cn66xx;
-	struct cvmx_pcieepx_cfg004_s          cn68xx;
-	struct cvmx_pcieepx_cfg004_s          cn68xxp1;
-	struct cvmx_pcieepx_cfg004_s          cn70xx;
-	struct cvmx_pcieepx_cfg004_s          cn78xx;
-	struct cvmx_pcieepx_cfg004_s          cnf71xx;
+	} cn52xx;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn52xxp1;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn56xx;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn56xxp1;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn61xx;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn63xx;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn63xxp1;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn66xx;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn68xx;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn68xxp1;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn70xx;
+	struct cvmx_pcieepx_cfg004_cn52xx     cn70xxp1;
+	struct cvmx_pcieepx_cfg004_cn78xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint32_t lbab                         : 17; /**< Lower bits of the BAR 0 base address. */
+	uint32_t reserved_4_14                : 11;
+	uint32_t pf                           : 1;  /**< Prefetchable. This field is writable through PEM(0..3)_CFG_WR. However, the application
+                                                         must not change this field. */
+	uint32_t typ                          : 2;  /**< BAR type.
+                                                         0x0 = 32-bit BAR.
+                                                         0x2 = 64-bit BAR.
+                                                         This field is writable through PEM(0..3)_CFG_WR. However, the application must not change
+                                                         this field. */
+	uint32_t mspc                         : 1;  /**< Memory space indicator.
+                                                         0 = BAR 0 is a memory BAR.
+                                                         1 = BAR 0 is an I/O BAR.
+                                                         This field is writable through PEM(0..3)_CFG_WR. However, the application must not change
+                                                         this field. */
+#else
+	uint32_t mspc                         : 1;
+	uint32_t typ                          : 2;
+	uint32_t pf                           : 1;
+	uint32_t reserved_4_14                : 11;
+	uint32_t lbab                         : 17;
+#endif
+	} cn78xx;
+	struct cvmx_pcieepx_cfg004_cn52xx     cnf71xx;
 };
 typedef union cvmx_pcieepx_cfg004 cvmx_pcieepx_cfg004_t;
 
@@ -4503,6 +4553,7 @@ union cvmx_pcieepx_cfg004_mask {
 	struct cvmx_pcieepx_cfg004_mask_s     cn68xx;
 	struct cvmx_pcieepx_cfg004_mask_s     cn68xxp1;
 	struct cvmx_pcieepx_cfg004_mask_s     cn70xx;
+	struct cvmx_pcieepx_cfg004_mask_s     cn70xxp1;
 	struct cvmx_pcieepx_cfg004_mask_s     cn78xx;
 	struct cvmx_pcieepx_cfg004_mask_s     cnf71xx;
 };
@@ -4534,6 +4585,7 @@ union cvmx_pcieepx_cfg005 {
 	struct cvmx_pcieepx_cfg005_s          cn68xx;
 	struct cvmx_pcieepx_cfg005_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg005_s          cn70xx;
+	struct cvmx_pcieepx_cfg005_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg005_s          cn78xx;
 	struct cvmx_pcieepx_cfg005_s          cnf71xx;
 };
@@ -4565,6 +4617,7 @@ union cvmx_pcieepx_cfg005_mask {
 	struct cvmx_pcieepx_cfg005_mask_s     cn68xx;
 	struct cvmx_pcieepx_cfg005_mask_s     cn68xxp1;
 	struct cvmx_pcieepx_cfg005_mask_s     cn70xx;
+	struct cvmx_pcieepx_cfg005_mask_s     cn70xxp1;
 	struct cvmx_pcieepx_cfg005_mask_s     cn78xx;
 	struct cvmx_pcieepx_cfg005_mask_s     cnf71xx;
 };
@@ -4614,6 +4667,7 @@ union cvmx_pcieepx_cfg006 {
 	struct cvmx_pcieepx_cfg006_s          cn68xx;
 	struct cvmx_pcieepx_cfg006_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg006_s          cn70xx;
+	struct cvmx_pcieepx_cfg006_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg006_s          cn78xx;
 	struct cvmx_pcieepx_cfg006_s          cnf71xx;
 };
@@ -4653,6 +4707,7 @@ union cvmx_pcieepx_cfg006_mask {
 	struct cvmx_pcieepx_cfg006_mask_s     cn68xx;
 	struct cvmx_pcieepx_cfg006_mask_s     cn68xxp1;
 	struct cvmx_pcieepx_cfg006_mask_s     cn70xx;
+	struct cvmx_pcieepx_cfg006_mask_s     cn70xxp1;
 	struct cvmx_pcieepx_cfg006_mask_s     cn78xx;
 	struct cvmx_pcieepx_cfg006_mask_s     cnf71xx;
 };
@@ -4684,6 +4739,7 @@ union cvmx_pcieepx_cfg007 {
 	struct cvmx_pcieepx_cfg007_s          cn68xx;
 	struct cvmx_pcieepx_cfg007_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg007_s          cn70xx;
+	struct cvmx_pcieepx_cfg007_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg007_s          cn78xx;
 	struct cvmx_pcieepx_cfg007_s          cnf71xx;
 };
@@ -4715,6 +4771,7 @@ union cvmx_pcieepx_cfg007_mask {
 	struct cvmx_pcieepx_cfg007_mask_s     cn68xx;
 	struct cvmx_pcieepx_cfg007_mask_s     cn68xxp1;
 	struct cvmx_pcieepx_cfg007_mask_s     cn70xx;
+	struct cvmx_pcieepx_cfg007_mask_s     cn70xxp1;
 	struct cvmx_pcieepx_cfg007_mask_s     cn78xx;
 	struct cvmx_pcieepx_cfg007_mask_s     cnf71xx;
 };
@@ -4786,6 +4843,7 @@ union cvmx_pcieepx_cfg008 {
 	struct cvmx_pcieepx_cfg008_cn52xx     cn68xx;
 	struct cvmx_pcieepx_cfg008_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg008_s          cn70xx;
+	struct cvmx_pcieepx_cfg008_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg008_s          cn78xx;
 	struct cvmx_pcieepx_cfg008_cn52xx     cnf71xx;
 };
@@ -4825,6 +4883,7 @@ union cvmx_pcieepx_cfg008_mask {
 	struct cvmx_pcieepx_cfg008_mask_s     cn68xx;
 	struct cvmx_pcieepx_cfg008_mask_s     cn68xxp1;
 	struct cvmx_pcieepx_cfg008_mask_s     cn70xx;
+	struct cvmx_pcieepx_cfg008_mask_s     cn70xxp1;
 	struct cvmx_pcieepx_cfg008_mask_s     cn78xx;
 	struct cvmx_pcieepx_cfg008_mask_s     cnf71xx;
 };
@@ -4878,6 +4937,7 @@ union cvmx_pcieepx_cfg009 {
 	uint32_t ubab                         : 32;
 #endif
 	} cn70xx;
+	struct cvmx_pcieepx_cfg009_cn70xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg009_cn70xx     cn78xx;
 	struct cvmx_pcieepx_cfg009_cn61xx     cnf71xx;
 };
@@ -4909,6 +4969,7 @@ union cvmx_pcieepx_cfg009_mask {
 	struct cvmx_pcieepx_cfg009_mask_s     cn68xx;
 	struct cvmx_pcieepx_cfg009_mask_s     cn68xxp1;
 	struct cvmx_pcieepx_cfg009_mask_s     cn70xx;
+	struct cvmx_pcieepx_cfg009_mask_s     cn70xxp1;
 	struct cvmx_pcieepx_cfg009_mask_s     cn78xx;
 	struct cvmx_pcieepx_cfg009_mask_s     cnf71xx;
 };
@@ -4941,6 +5002,7 @@ union cvmx_pcieepx_cfg010 {
 	struct cvmx_pcieepx_cfg010_s          cn68xx;
 	struct cvmx_pcieepx_cfg010_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg010_s          cn70xx;
+	struct cvmx_pcieepx_cfg010_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg010_s          cn78xx;
 	struct cvmx_pcieepx_cfg010_s          cnf71xx;
 };
@@ -4977,6 +5039,7 @@ union cvmx_pcieepx_cfg011 {
 	struct cvmx_pcieepx_cfg011_s          cn68xx;
 	struct cvmx_pcieepx_cfg011_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg011_s          cn70xx;
+	struct cvmx_pcieepx_cfg011_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg011_s          cn78xx;
 	struct cvmx_pcieepx_cfg011_s          cnf71xx;
 };
@@ -5012,6 +5075,7 @@ union cvmx_pcieepx_cfg012 {
 	struct cvmx_pcieepx_cfg012_s          cn68xx;
 	struct cvmx_pcieepx_cfg012_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg012_s          cn70xx;
+	struct cvmx_pcieepx_cfg012_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg012_s          cn78xx;
 	struct cvmx_pcieepx_cfg012_s          cnf71xx;
 };
@@ -5051,6 +5115,7 @@ union cvmx_pcieepx_cfg012_mask {
 	struct cvmx_pcieepx_cfg012_mask_s     cn68xx;
 	struct cvmx_pcieepx_cfg012_mask_s     cn68xxp1;
 	struct cvmx_pcieepx_cfg012_mask_s     cn70xx;
+	struct cvmx_pcieepx_cfg012_mask_s     cn70xxp1;
 	struct cvmx_pcieepx_cfg012_mask_s     cn78xx;
 	struct cvmx_pcieepx_cfg012_mask_s     cnf71xx;
 };
@@ -5087,6 +5152,7 @@ union cvmx_pcieepx_cfg013 {
 	struct cvmx_pcieepx_cfg013_s          cn68xx;
 	struct cvmx_pcieepx_cfg013_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg013_s          cn70xx;
+	struct cvmx_pcieepx_cfg013_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg013_s          cn78xx;
 	struct cvmx_pcieepx_cfg013_s          cnf71xx;
 };
@@ -5129,6 +5195,7 @@ union cvmx_pcieepx_cfg015 {
 	struct cvmx_pcieepx_cfg015_s          cn68xx;
 	struct cvmx_pcieepx_cfg015_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg015_s          cn70xx;
+	struct cvmx_pcieepx_cfg015_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg015_s          cn78xx;
 	struct cvmx_pcieepx_cfg015_s          cnf71xx;
 };
@@ -5193,6 +5260,7 @@ union cvmx_pcieepx_cfg016 {
 	struct cvmx_pcieepx_cfg016_s          cn68xx;
 	struct cvmx_pcieepx_cfg016_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg016_s          cn70xx;
+	struct cvmx_pcieepx_cfg016_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg016_s          cn78xx;
 	struct cvmx_pcieepx_cfg016_s          cnf71xx;
 };
@@ -5257,6 +5325,7 @@ union cvmx_pcieepx_cfg017 {
 	struct cvmx_pcieepx_cfg017_s          cn68xx;
 	struct cvmx_pcieepx_cfg017_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg017_s          cn70xx;
+	struct cvmx_pcieepx_cfg017_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg017_s          cn78xx;
 	struct cvmx_pcieepx_cfg017_s          cnf71xx;
 };
@@ -5338,6 +5407,7 @@ union cvmx_pcieepx_cfg020 {
 	struct cvmx_pcieepx_cfg020_s          cn68xx;
 	struct cvmx_pcieepx_cfg020_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg020_s          cn70xx;
+	struct cvmx_pcieepx_cfg020_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg020_s          cn78xx;
 	struct cvmx_pcieepx_cfg020_s          cnf71xx;
 };
@@ -5371,6 +5441,7 @@ union cvmx_pcieepx_cfg021 {
 	struct cvmx_pcieepx_cfg021_s          cn68xx;
 	struct cvmx_pcieepx_cfg021_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg021_s          cn70xx;
+	struct cvmx_pcieepx_cfg021_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg021_s          cn78xx;
 	struct cvmx_pcieepx_cfg021_s          cnf71xx;
 };
@@ -5402,6 +5473,7 @@ union cvmx_pcieepx_cfg022 {
 	struct cvmx_pcieepx_cfg022_s          cn68xx;
 	struct cvmx_pcieepx_cfg022_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg022_s          cn70xx;
+	struct cvmx_pcieepx_cfg022_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg022_s          cn78xx;
 	struct cvmx_pcieepx_cfg022_s          cnf71xx;
 };
@@ -5437,6 +5509,7 @@ union cvmx_pcieepx_cfg023 {
 	struct cvmx_pcieepx_cfg023_s          cn68xx;
 	struct cvmx_pcieepx_cfg023_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg023_s          cn70xx;
+	struct cvmx_pcieepx_cfg023_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg023_s          cn78xx;
 	struct cvmx_pcieepx_cfg023_s          cnf71xx;
 };
@@ -5459,6 +5532,7 @@ union cvmx_pcieepx_cfg024 {
 #endif
 	} s;
 	struct cvmx_pcieepx_cfg024_s          cn70xx;
+	struct cvmx_pcieepx_cfg024_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg024_s          cn78xx;
 };
 typedef union cvmx_pcieepx_cfg024 cvmx_pcieepx_cfg024_t;
@@ -5479,6 +5553,7 @@ union cvmx_pcieepx_cfg025 {
 #endif
 	} s;
 	struct cvmx_pcieepx_cfg025_s          cn70xx;
+	struct cvmx_pcieepx_cfg025_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg025_s          cn78xx;
 };
 typedef union cvmx_pcieepx_cfg025 cvmx_pcieepx_cfg025_t;
@@ -5529,6 +5604,7 @@ union cvmx_pcieepx_cfg028 {
 	struct cvmx_pcieepx_cfg028_s          cn68xx;
 	struct cvmx_pcieepx_cfg028_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg028_s          cn70xx;
+	struct cvmx_pcieepx_cfg028_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg028_s          cn78xx;
 	struct cvmx_pcieepx_cfg028_s          cnf71xx;
 };
@@ -5677,6 +5753,7 @@ union cvmx_pcieepx_cfg029 {
 	struct cvmx_pcieepx_cfg029_cn66xx     cn68xx;
 	struct cvmx_pcieepx_cfg029_cn66xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg029_cn61xx     cn70xx;
+	struct cvmx_pcieepx_cfg029_cn61xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg029_cn61xx     cn78xx;
 	struct cvmx_pcieepx_cfg029_cn61xx     cnf71xx;
 };
@@ -5883,6 +5960,7 @@ union cvmx_pcieepx_cfg030 {
 	struct cvmx_pcieepx_cfg030_s          cn68xx;
 	struct cvmx_pcieepx_cfg030_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg030_s          cn70xx;
+	struct cvmx_pcieepx_cfg030_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg030_s          cn78xx;
 	struct cvmx_pcieepx_cfg030_s          cnf71xx;
 };
@@ -6011,6 +6089,7 @@ union cvmx_pcieepx_cfg031 {
 	struct cvmx_pcieepx_cfg031_s          cn68xx;
 	struct cvmx_pcieepx_cfg031_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg031_s          cn70xx;
+	struct cvmx_pcieepx_cfg031_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg031_s          cn78xx;
 	struct cvmx_pcieepx_cfg031_s          cnf71xx;
 };
@@ -6220,6 +6299,7 @@ union cvmx_pcieepx_cfg032 {
 #endif
 	} cn68xxp1;
 	struct cvmx_pcieepx_cfg032_s          cn70xx;
+	struct cvmx_pcieepx_cfg032_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg032_s          cn78xx;
 	struct cvmx_pcieepx_cfg032_s          cnf71xx;
 };
@@ -6465,6 +6545,7 @@ union cvmx_pcieepx_cfg037 {
 	struct cvmx_pcieepx_cfg037_cn61xx     cn68xx;
 	struct cvmx_pcieepx_cfg037_cn61xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg037_cn61xx     cn70xx;
+	struct cvmx_pcieepx_cfg037_cn61xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg037_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
@@ -6645,6 +6726,7 @@ union cvmx_pcieepx_cfg038 {
 	struct cvmx_pcieepx_cfg038_cn61xx     cn68xx;
 	struct cvmx_pcieepx_cfg038_cn61xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg038_cn61xx     cn70xx;
+	struct cvmx_pcieepx_cfg038_cn61xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg038_s          cn78xx;
 	struct cvmx_pcieepx_cfg038_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
@@ -6737,6 +6819,7 @@ union cvmx_pcieepx_cfg039 {
 	struct cvmx_pcieepx_cfg039_s          cn68xx;
 	struct cvmx_pcieepx_cfg039_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg039_s          cn70xx;
+	struct cvmx_pcieepx_cfg039_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg039_s          cn78xx;
 	struct cvmx_pcieepx_cfg039_s          cnf71xx;
 };
@@ -6956,6 +7039,7 @@ union cvmx_pcieepx_cfg040 {
 	struct cvmx_pcieepx_cfg040_cn61xx     cn68xx;
 	struct cvmx_pcieepx_cfg040_cn61xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg040_cn61xx     cn70xx;
+	struct cvmx_pcieepx_cfg040_cn61xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg040_s          cn78xx;
 	struct cvmx_pcieepx_cfg040_cn61xx     cnf71xx;
 };
@@ -7126,6 +7210,7 @@ union cvmx_pcieepx_cfg064 {
 	struct cvmx_pcieepx_cfg064_s          cn68xx;
 	struct cvmx_pcieepx_cfg064_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg064_s          cn70xx;
+	struct cvmx_pcieepx_cfg064_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg064_s          cn78xx;
 	struct cvmx_pcieepx_cfg064_s          cnf71xx;
 };
@@ -7301,6 +7386,7 @@ union cvmx_pcieepx_cfg065 {
 	uint32_t reserved_25_31               : 7;
 #endif
 	} cn70xx;
+	struct cvmx_pcieepx_cfg065_cn70xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg065_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
@@ -7554,6 +7640,7 @@ union cvmx_pcieepx_cfg066 {
 	uint32_t reserved_25_31               : 7;
 #endif
 	} cn70xx;
+	struct cvmx_pcieepx_cfg066_cn70xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg066_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
@@ -7807,6 +7894,7 @@ union cvmx_pcieepx_cfg067 {
 	uint32_t reserved_25_31               : 7;
 #endif
 	} cn70xx;
+	struct cvmx_pcieepx_cfg067_cn70xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg067_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
@@ -7956,6 +8044,7 @@ union cvmx_pcieepx_cfg068 {
 	struct cvmx_pcieepx_cfg068_cn52xx     cn68xx;
 	struct cvmx_pcieepx_cfg068_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg068_s          cn70xx;
+	struct cvmx_pcieepx_cfg068_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg068_s          cn78xx;
 	struct cvmx_pcieepx_cfg068_s          cnf71xx;
 };
@@ -8027,6 +8116,7 @@ union cvmx_pcieepx_cfg069 {
 	struct cvmx_pcieepx_cfg069_cn52xx     cn68xx;
 	struct cvmx_pcieepx_cfg069_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg069_s          cn70xx;
+	struct cvmx_pcieepx_cfg069_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg069_s          cn78xx;
 	struct cvmx_pcieepx_cfg069_s          cnf71xx;
 };
@@ -8088,6 +8178,7 @@ union cvmx_pcieepx_cfg070 {
 	struct cvmx_pcieepx_cfg070_cn52xx     cn68xx;
 	struct cvmx_pcieepx_cfg070_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg070_cn52xx     cn70xx;
+	struct cvmx_pcieepx_cfg070_cn52xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg070_s          cn78xx;
 	struct cvmx_pcieepx_cfg070_cn52xx     cnf71xx;
 };
@@ -8119,6 +8210,7 @@ union cvmx_pcieepx_cfg071 {
 	struct cvmx_pcieepx_cfg071_s          cn68xx;
 	struct cvmx_pcieepx_cfg071_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg071_s          cn70xx;
+	struct cvmx_pcieepx_cfg071_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg071_s          cn78xx;
 	struct cvmx_pcieepx_cfg071_s          cnf71xx;
 };
@@ -8150,6 +8242,7 @@ union cvmx_pcieepx_cfg072 {
 	struct cvmx_pcieepx_cfg072_s          cn68xx;
 	struct cvmx_pcieepx_cfg072_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg072_s          cn70xx;
+	struct cvmx_pcieepx_cfg072_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg072_s          cn78xx;
 	struct cvmx_pcieepx_cfg072_s          cnf71xx;
 };
@@ -8181,6 +8274,7 @@ union cvmx_pcieepx_cfg073 {
 	struct cvmx_pcieepx_cfg073_s          cn68xx;
 	struct cvmx_pcieepx_cfg073_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg073_s          cn70xx;
+	struct cvmx_pcieepx_cfg073_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg073_s          cn78xx;
 	struct cvmx_pcieepx_cfg073_s          cnf71xx;
 };
@@ -8212,6 +8306,7 @@ union cvmx_pcieepx_cfg074 {
 	struct cvmx_pcieepx_cfg074_s          cn68xx;
 	struct cvmx_pcieepx_cfg074_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg074_s          cn70xx;
+	struct cvmx_pcieepx_cfg074_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg074_s          cn78xx;
 	struct cvmx_pcieepx_cfg074_s          cnf71xx;
 };
@@ -8266,6 +8361,7 @@ union cvmx_pcieepx_cfg082 {
 	uint32_t nco                          : 12;
 #endif
 	} cn70xx;
+	struct cvmx_pcieepx_cfg082_cn70xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg082_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t nco                          : 12; /**< Next capability offset. Points to the secondary PCI Express capabilities by default. */
@@ -8315,6 +8411,7 @@ union cvmx_pcieepx_cfg083 {
 	uint32_t reserved_26_31               : 6;
 #endif
 	} cn70xx;
+	struct cvmx_pcieepx_cfg083_cn70xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg083_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_23_31               : 9;
@@ -8357,8 +8454,7 @@ union cvmx_pcieepx_cfg084 {
                                                          but will accept values as large as 0x15 (2TB) */
 	uint32_t nrbar                        : 3;  /**< Number of Resizable BARs */
 	uint32_t reserved_3_4                 : 2;
-	uint32_t rbari                        : 3;  /**< BAR Index
-                                                         Points to the BAR located at offset 0x18 (BAR2) */
+	uint32_t rbari                        : 3;  /**< BAR Index. Points to BAR2. */
 #else
 	uint32_t rbari                        : 3;
 	uint32_t reserved_3_4                 : 2;
@@ -8368,6 +8464,7 @@ union cvmx_pcieepx_cfg084 {
 #endif
 	} s;
 	struct cvmx_pcieepx_cfg084_s          cn70xx;
+	struct cvmx_pcieepx_cfg084_s          cn70xxp1;
 };
 typedef union cvmx_pcieepx_cfg084 cvmx_pcieepx_cfg084_t;
 
@@ -8797,8 +8894,8 @@ union cvmx_pcieepx_cfg103 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg103_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t lbab                         : 18; /**< Lower bits of the VF BAR 0 base address. */
-	uint32_t reserved_4_13                : 10;
+	uint32_t lbab                         : 17; /**< Lower bits of the VF BAR 0 base address. */
+	uint32_t reserved_4_14                : 11;
 	uint32_t pf                           : 1;  /**< Prefetchable. */
 	uint32_t typ                          : 2;  /**< BAR type
                                                          0x0 = 32-bit BAR.
@@ -8810,8 +8907,8 @@ union cvmx_pcieepx_cfg103 {
 	uint32_t mspc                         : 1;
 	uint32_t typ                          : 2;
 	uint32_t pf                           : 1;
-	uint32_t reserved_4_13                : 10;
-	uint32_t lbab                         : 18;
+	uint32_t reserved_4_14                : 11;
+	uint32_t lbab                         : 17;
 #endif
 	} s;
 	struct cvmx_pcieepx_cfg103_s          cn78xx;
@@ -8998,7 +9095,7 @@ union cvmx_pcieepx_cfg112 {
                                                          values as large as 0x19 (32TB). */
 	uint32_t nrbar                        : 3;  /**< Number of resizable BARs */
 	uint32_t reserved_3_4                 : 2;
-	uint32_t rbari                        : 3;  /**< BAR Index. Points to the BAR located at offset 0x18 (BAR2). */
+	uint32_t rbari                        : 3;  /**< BAR Index. Points to BAR2. */
 #else
 	uint32_t rbari                        : 3;
 	uint32_t reserved_3_4                 : 2;
@@ -9053,6 +9150,7 @@ union cvmx_pcieepx_cfg448 {
 	struct cvmx_pcieepx_cfg448_s          cn68xx;
 	struct cvmx_pcieepx_cfg448_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg448_s          cn70xx;
+	struct cvmx_pcieepx_cfg448_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg448_s          cn78xx;
 	struct cvmx_pcieepx_cfg448_s          cnf71xx;
 };
@@ -9095,6 +9193,7 @@ union cvmx_pcieepx_cfg449 {
 	struct cvmx_pcieepx_cfg449_s          cn68xx;
 	struct cvmx_pcieepx_cfg449_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg449_s          cn70xx;
+	struct cvmx_pcieepx_cfg449_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg449_s          cn78xx;
 	struct cvmx_pcieepx_cfg449_s          cnf71xx;
 };
@@ -9266,6 +9365,7 @@ union cvmx_pcieepx_cfg450 {
 	struct cvmx_pcieepx_cfg450_cn52xx     cn68xx;
 	struct cvmx_pcieepx_cfg450_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg450_s          cn70xx;
+	struct cvmx_pcieepx_cfg450_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg450_cn52xx     cn78xx;
 	struct cvmx_pcieepx_cfg450_cn52xx     cnf71xx;
 };
@@ -9389,6 +9489,7 @@ union cvmx_pcieepx_cfg451 {
 	struct cvmx_pcieepx_cfg451_s          cn68xx;
 	struct cvmx_pcieepx_cfg451_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg451_s          cn70xx;
+	struct cvmx_pcieepx_cfg451_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg451_s          cn78xx;
 	struct cvmx_pcieepx_cfg451_s          cnf71xx;
 };
@@ -9669,6 +9770,7 @@ union cvmx_pcieepx_cfg452 {
 	uint32_t reserved_22_31               : 10;
 #endif
 	} cn70xx;
+	struct cvmx_pcieepx_cfg452_cn70xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg452_cn70xx     cn78xx;
 	struct cvmx_pcieepx_cfg452_cn61xx     cnf71xx;
 };
@@ -9716,6 +9818,7 @@ union cvmx_pcieepx_cfg453 {
 	struct cvmx_pcieepx_cfg453_s          cn68xx;
 	struct cvmx_pcieepx_cfg453_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg453_s          cn70xx;
+	struct cvmx_pcieepx_cfg453_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg453_s          cn78xx;
 	struct cvmx_pcieepx_cfg453_s          cnf71xx;
 };
@@ -9837,6 +9940,7 @@ union cvmx_pcieepx_cfg454 {
 	uint32_t reserved_24_31               : 8;
 #endif
 	} cn70xx;
+	struct cvmx_pcieepx_cfg454_cn70xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg454_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_29_31               : 3;
@@ -9925,6 +10029,7 @@ union cvmx_pcieepx_cfg455 {
 	struct cvmx_pcieepx_cfg455_s          cn68xx;
 	struct cvmx_pcieepx_cfg455_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg455_s          cn70xx;
+	struct cvmx_pcieepx_cfg455_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg455_s          cn78xx;
 	struct cvmx_pcieepx_cfg455_s          cnf71xx;
 };
@@ -9974,6 +10079,7 @@ union cvmx_pcieepx_cfg456 {
 	struct cvmx_pcieepx_cfg456_s          cn68xx;
 	struct cvmx_pcieepx_cfg456_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg456_s          cn70xx;
+	struct cvmx_pcieepx_cfg456_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg456_s          cn78xx;
 	struct cvmx_pcieepx_cfg456_s          cnf71xx;
 };
@@ -10005,6 +10111,7 @@ union cvmx_pcieepx_cfg458 {
 	struct cvmx_pcieepx_cfg458_s          cn68xx;
 	struct cvmx_pcieepx_cfg458_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg458_s          cn70xx;
+	struct cvmx_pcieepx_cfg458_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg458_s          cn78xx;
 	struct cvmx_pcieepx_cfg458_s          cnf71xx;
 };
@@ -10036,6 +10143,7 @@ union cvmx_pcieepx_cfg459 {
 	struct cvmx_pcieepx_cfg459_s          cn68xx;
 	struct cvmx_pcieepx_cfg459_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg459_s          cn70xx;
+	struct cvmx_pcieepx_cfg459_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg459_s          cn78xx;
 	struct cvmx_pcieepx_cfg459_s          cnf71xx;
 };
@@ -10075,6 +10183,7 @@ union cvmx_pcieepx_cfg460 {
 	struct cvmx_pcieepx_cfg460_s          cn68xx;
 	struct cvmx_pcieepx_cfg460_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg460_s          cn70xx;
+	struct cvmx_pcieepx_cfg460_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg460_s          cn78xx;
 	struct cvmx_pcieepx_cfg460_s          cnf71xx;
 };
@@ -10114,6 +10223,7 @@ union cvmx_pcieepx_cfg461 {
 	struct cvmx_pcieepx_cfg461_s          cn68xx;
 	struct cvmx_pcieepx_cfg461_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg461_s          cn70xx;
+	struct cvmx_pcieepx_cfg461_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg461_s          cn78xx;
 	struct cvmx_pcieepx_cfg461_s          cnf71xx;
 };
@@ -10153,6 +10263,7 @@ union cvmx_pcieepx_cfg462 {
 	struct cvmx_pcieepx_cfg462_s          cn68xx;
 	struct cvmx_pcieepx_cfg462_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg462_s          cn70xx;
+	struct cvmx_pcieepx_cfg462_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg462_s          cn78xx;
 	struct cvmx_pcieepx_cfg462_s          cnf71xx;
 };
@@ -10224,6 +10335,7 @@ union cvmx_pcieepx_cfg463 {
 	struct cvmx_pcieepx_cfg463_cn52xx     cn68xx;
 	struct cvmx_pcieepx_cfg463_cn52xx     cn68xxp1;
 	struct cvmx_pcieepx_cfg463_cn52xx     cn70xx;
+	struct cvmx_pcieepx_cfg463_cn52xx     cn70xxp1;
 	struct cvmx_pcieepx_cfg463_s          cn78xx;
 	struct cvmx_pcieepx_cfg463_cn52xx     cnf71xx;
 };
@@ -10261,6 +10373,7 @@ union cvmx_pcieepx_cfg464 {
 	struct cvmx_pcieepx_cfg464_s          cn68xx;
 	struct cvmx_pcieepx_cfg464_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg464_s          cn70xx;
+	struct cvmx_pcieepx_cfg464_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg464_s          cn78xx;
 	struct cvmx_pcieepx_cfg464_s          cnf71xx;
 };
@@ -10298,6 +10411,7 @@ union cvmx_pcieepx_cfg465 {
 	struct cvmx_pcieepx_cfg465_s          cn68xx;
 	struct cvmx_pcieepx_cfg465_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg465_s          cn70xx;
+	struct cvmx_pcieepx_cfg465_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg465_s          cn78xx;
 	struct cvmx_pcieepx_cfg465_s          cnf71xx;
 };
@@ -10371,6 +10485,7 @@ union cvmx_pcieepx_cfg466 {
 	struct cvmx_pcieepx_cfg466_s          cn68xx;
 	struct cvmx_pcieepx_cfg466_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg466_s          cn70xx;
+	struct cvmx_pcieepx_cfg466_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg466_s          cn78xx;
 	struct cvmx_pcieepx_cfg466_s          cnf71xx;
 };
@@ -10426,6 +10541,7 @@ union cvmx_pcieepx_cfg467 {
 	struct cvmx_pcieepx_cfg467_s          cn68xx;
 	struct cvmx_pcieepx_cfg467_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg467_s          cn70xx;
+	struct cvmx_pcieepx_cfg467_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg467_s          cn78xx;
 	struct cvmx_pcieepx_cfg467_s          cnf71xx;
 };
@@ -10481,6 +10597,7 @@ union cvmx_pcieepx_cfg468 {
 	struct cvmx_pcieepx_cfg468_s          cn68xx;
 	struct cvmx_pcieepx_cfg468_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg468_s          cn70xx;
+	struct cvmx_pcieepx_cfg468_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg468_s          cn78xx;
 	struct cvmx_pcieepx_cfg468_s          cnf71xx;
 };
@@ -10526,6 +10643,7 @@ union cvmx_pcieepx_cfg490 {
 	struct cvmx_pcieepx_cfg490_s          cn68xx;
 	struct cvmx_pcieepx_cfg490_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg490_s          cn70xx;
+	struct cvmx_pcieepx_cfg490_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg490_s          cnf71xx;
 };
 typedef union cvmx_pcieepx_cfg490 cvmx_pcieepx_cfg490_t;
@@ -10570,6 +10688,7 @@ union cvmx_pcieepx_cfg491 {
 	struct cvmx_pcieepx_cfg491_s          cn68xx;
 	struct cvmx_pcieepx_cfg491_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg491_s          cn70xx;
+	struct cvmx_pcieepx_cfg491_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg491_s          cnf71xx;
 };
 typedef union cvmx_pcieepx_cfg491 cvmx_pcieepx_cfg491_t;
@@ -10614,6 +10733,7 @@ union cvmx_pcieepx_cfg492 {
 	struct cvmx_pcieepx_cfg492_s          cn68xx;
 	struct cvmx_pcieepx_cfg492_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg492_s          cn70xx;
+	struct cvmx_pcieepx_cfg492_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg492_s          cnf71xx;
 };
 typedef union cvmx_pcieepx_cfg492 cvmx_pcieepx_cfg492_t;
@@ -10672,6 +10792,7 @@ union cvmx_pcieepx_cfg515 {
 	struct cvmx_pcieepx_cfg515_s          cn68xx;
 	struct cvmx_pcieepx_cfg515_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg515_s          cn70xx;
+	struct cvmx_pcieepx_cfg515_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg515_s          cn78xx;
 	struct cvmx_pcieepx_cfg515_s          cnf71xx;
 };
@@ -10703,6 +10824,7 @@ union cvmx_pcieepx_cfg516 {
 	struct cvmx_pcieepx_cfg516_s          cn68xx;
 	struct cvmx_pcieepx_cfg516_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg516_s          cn70xx;
+	struct cvmx_pcieepx_cfg516_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg516_s          cn78xx;
 	struct cvmx_pcieepx_cfg516_s          cnf71xx;
 };
@@ -10734,6 +10856,7 @@ union cvmx_pcieepx_cfg517 {
 	struct cvmx_pcieepx_cfg517_s          cn68xx;
 	struct cvmx_pcieepx_cfg517_s          cn68xxp1;
 	struct cvmx_pcieepx_cfg517_s          cn70xx;
+	struct cvmx_pcieepx_cfg517_s          cn70xxp1;
 	struct cvmx_pcieepx_cfg517_s          cn78xx;
 	struct cvmx_pcieepx_cfg517_s          cnf71xx;
 };
@@ -10791,7 +10914,9 @@ union cvmx_pcieepx_cfg554 {
 	uint32_t u32;
 	struct cvmx_pcieepx_cfg554_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t reserved_24_31               : 8;
+	uint32_t reserved_25_31               : 7;
+	uint32_t iif                          : 1;  /**< Include initial FOM. Include, or not, the FOM feedback from the initial preset evaluation
+                                                         performed in the EQ Master, when finding the highest FOM among all preset evaluations. */
 	uint32_t prv                          : 16; /**< Preset request vector. Requesting of presets during the initial part of the EQ master
                                                          phase. Encoding scheme as follows:
                                                          Bit [15:0] = 0x0: No preset is requested and evaluated in the EQ master phase
@@ -10827,7 +10952,7 @@ union cvmx_pcieepx_cfg554 {
                                                          * Equalization phase 3 successful status bit is not set in the Link Status Register
                                                          * Equalization phase 3 complete status bit is set in the Link Status Register */
 	uint32_t fm                           : 4;  /**< Feedback mode.
-                                                         0 = Direction of change.
+                                                         0 = Direction of change (not supported).
                                                          1 = Figure of merit.
                                                          2-15 = Reserved. */
 #else
@@ -10836,7 +10961,8 @@ union cvmx_pcieepx_cfg554 {
 	uint32_t p23td                        : 1;
 	uint32_t reserved_6_7                 : 2;
 	uint32_t prv                          : 16;
-	uint32_t reserved_24_31               : 8;
+	uint32_t iif                          : 1;
+	uint32_t reserved_25_31               : 7;
 #endif
 	} s;
 	struct cvmx_pcieepx_cfg554_s          cn78xx;
diff --git a/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h b/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
index f51083f..60d82f2 100644
--- a/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pciercx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -3746,6 +3746,7 @@ union cvmx_pciercx_cfg000 {
 	struct cvmx_pciercx_cfg000_s          cn68xx;
 	struct cvmx_pciercx_cfg000_s          cn68xxp1;
 	struct cvmx_pciercx_cfg000_s          cn70xx;
+	struct cvmx_pciercx_cfg000_s          cn70xxp1;
 	struct cvmx_pciercx_cfg000_s          cn78xx;
 	struct cvmx_pciercx_cfg000_s          cnf71xx;
 };
@@ -3833,6 +3834,7 @@ union cvmx_pciercx_cfg001 {
 	struct cvmx_pciercx_cfg001_s          cn68xx;
 	struct cvmx_pciercx_cfg001_s          cn68xxp1;
 	struct cvmx_pciercx_cfg001_s          cn70xx;
+	struct cvmx_pciercx_cfg001_s          cn70xxp1;
 	struct cvmx_pciercx_cfg001_s          cn78xx;
 	struct cvmx_pciercx_cfg001_s          cnf71xx;
 };
@@ -3874,6 +3876,7 @@ union cvmx_pciercx_cfg002 {
 	struct cvmx_pciercx_cfg002_s          cn68xx;
 	struct cvmx_pciercx_cfg002_s          cn68xxp1;
 	struct cvmx_pciercx_cfg002_s          cn70xx;
+	struct cvmx_pciercx_cfg002_s          cn70xxp1;
 	struct cvmx_pciercx_cfg002_s          cn78xx;
 	struct cvmx_pciercx_cfg002_s          cnf71xx;
 };
@@ -3922,6 +3925,7 @@ union cvmx_pciercx_cfg003 {
 	struct cvmx_pciercx_cfg003_s          cn68xx;
 	struct cvmx_pciercx_cfg003_s          cn68xxp1;
 	struct cvmx_pciercx_cfg003_s          cn70xx;
+	struct cvmx_pciercx_cfg003_s          cn70xxp1;
 	struct cvmx_pciercx_cfg003_s          cn78xx;
 	struct cvmx_pciercx_cfg003_s          cnf71xx;
 };
@@ -3953,6 +3957,7 @@ union cvmx_pciercx_cfg004 {
 	struct cvmx_pciercx_cfg004_s          cn68xx;
 	struct cvmx_pciercx_cfg004_s          cn68xxp1;
 	struct cvmx_pciercx_cfg004_s          cn70xx;
+	struct cvmx_pciercx_cfg004_s          cn70xxp1;
 	struct cvmx_pciercx_cfg004_s          cn78xx;
 	struct cvmx_pciercx_cfg004_s          cnf71xx;
 };
@@ -3984,6 +3989,7 @@ union cvmx_pciercx_cfg005 {
 	struct cvmx_pciercx_cfg005_s          cn68xx;
 	struct cvmx_pciercx_cfg005_s          cn68xxp1;
 	struct cvmx_pciercx_cfg005_s          cn70xx;
+	struct cvmx_pciercx_cfg005_s          cn70xxp1;
 	struct cvmx_pciercx_cfg005_s          cn78xx;
 	struct cvmx_pciercx_cfg005_s          cnf71xx;
 };
@@ -4022,6 +4028,7 @@ union cvmx_pciercx_cfg006 {
 	struct cvmx_pciercx_cfg006_s          cn68xx;
 	struct cvmx_pciercx_cfg006_s          cn68xxp1;
 	struct cvmx_pciercx_cfg006_s          cn70xx;
+	struct cvmx_pciercx_cfg006_s          cn70xxp1;
 	struct cvmx_pciercx_cfg006_s          cn78xx;
 	struct cvmx_pciercx_cfg006_s          cnf71xx;
 };
@@ -4095,6 +4102,7 @@ union cvmx_pciercx_cfg007 {
 	struct cvmx_pciercx_cfg007_s          cn68xx;
 	struct cvmx_pciercx_cfg007_s          cn68xxp1;
 	struct cvmx_pciercx_cfg007_s          cn70xx;
+	struct cvmx_pciercx_cfg007_s          cn70xxp1;
 	struct cvmx_pciercx_cfg007_s          cn78xx;
 	struct cvmx_pciercx_cfg007_s          cnf71xx;
 };
@@ -4132,6 +4140,7 @@ union cvmx_pciercx_cfg008 {
 	struct cvmx_pciercx_cfg008_s          cn68xx;
 	struct cvmx_pciercx_cfg008_s          cn68xxp1;
 	struct cvmx_pciercx_cfg008_s          cn70xx;
+	struct cvmx_pciercx_cfg008_s          cn70xxp1;
 	struct cvmx_pciercx_cfg008_s          cn78xx;
 	struct cvmx_pciercx_cfg008_s          cnf71xx;
 };
@@ -4182,6 +4191,7 @@ union cvmx_pciercx_cfg009 {
 	struct cvmx_pciercx_cfg009_s          cn68xx;
 	struct cvmx_pciercx_cfg009_s          cn68xxp1;
 	struct cvmx_pciercx_cfg009_s          cn70xx;
+	struct cvmx_pciercx_cfg009_s          cn70xxp1;
 	struct cvmx_pciercx_cfg009_s          cn78xx;
 	struct cvmx_pciercx_cfg009_s          cnf71xx;
 };
@@ -4215,6 +4225,7 @@ union cvmx_pciercx_cfg010 {
 	struct cvmx_pciercx_cfg010_s          cn68xx;
 	struct cvmx_pciercx_cfg010_s          cn68xxp1;
 	struct cvmx_pciercx_cfg010_s          cn70xx;
+	struct cvmx_pciercx_cfg010_s          cn70xxp1;
 	struct cvmx_pciercx_cfg010_s          cn78xx;
 	struct cvmx_pciercx_cfg010_s          cnf71xx;
 };
@@ -4248,6 +4259,7 @@ union cvmx_pciercx_cfg011 {
 	struct cvmx_pciercx_cfg011_s          cn68xx;
 	struct cvmx_pciercx_cfg011_s          cn68xxp1;
 	struct cvmx_pciercx_cfg011_s          cn70xx;
+	struct cvmx_pciercx_cfg011_s          cn70xxp1;
 	struct cvmx_pciercx_cfg011_s          cn78xx;
 	struct cvmx_pciercx_cfg011_s          cnf71xx;
 };
@@ -4283,6 +4295,7 @@ union cvmx_pciercx_cfg012 {
 	struct cvmx_pciercx_cfg012_s          cn68xx;
 	struct cvmx_pciercx_cfg012_s          cn68xxp1;
 	struct cvmx_pciercx_cfg012_s          cn70xx;
+	struct cvmx_pciercx_cfg012_s          cn70xxp1;
 	struct cvmx_pciercx_cfg012_s          cn78xx;
 	struct cvmx_pciercx_cfg012_s          cnf71xx;
 };
@@ -4319,6 +4332,7 @@ union cvmx_pciercx_cfg013 {
 	struct cvmx_pciercx_cfg013_s          cn68xx;
 	struct cvmx_pciercx_cfg013_s          cn68xxp1;
 	struct cvmx_pciercx_cfg013_s          cn70xx;
+	struct cvmx_pciercx_cfg013_s          cn70xxp1;
 	struct cvmx_pciercx_cfg013_s          cn78xx;
 	struct cvmx_pciercx_cfg013_s          cnf71xx;
 };
@@ -4350,6 +4364,7 @@ union cvmx_pciercx_cfg014 {
 	struct cvmx_pciercx_cfg014_s          cn68xx;
 	struct cvmx_pciercx_cfg014_s          cn68xxp1;
 	struct cvmx_pciercx_cfg014_s          cn70xx;
+	struct cvmx_pciercx_cfg014_s          cn70xxp1;
 	struct cvmx_pciercx_cfg014_s          cn78xx;
 	struct cvmx_pciercx_cfg014_s          cnf71xx;
 };
@@ -4426,6 +4441,7 @@ union cvmx_pciercx_cfg015 {
 	struct cvmx_pciercx_cfg015_s          cn68xx;
 	struct cvmx_pciercx_cfg015_s          cn68xxp1;
 	struct cvmx_pciercx_cfg015_s          cn70xx;
+	struct cvmx_pciercx_cfg015_s          cn70xxp1;
 	struct cvmx_pciercx_cfg015_s          cn78xx;
 	struct cvmx_pciercx_cfg015_s          cnf71xx;
 };
@@ -4492,6 +4508,7 @@ union cvmx_pciercx_cfg016 {
 	struct cvmx_pciercx_cfg016_s          cn68xx;
 	struct cvmx_pciercx_cfg016_s          cn68xxp1;
 	struct cvmx_pciercx_cfg016_s          cn70xx;
+	struct cvmx_pciercx_cfg016_s          cn70xxp1;
 	struct cvmx_pciercx_cfg016_s          cn78xx;
 	struct cvmx_pciercx_cfg016_s          cnf71xx;
 };
@@ -4556,6 +4573,7 @@ union cvmx_pciercx_cfg017 {
 	struct cvmx_pciercx_cfg017_s          cn68xx;
 	struct cvmx_pciercx_cfg017_s          cn68xxp1;
 	struct cvmx_pciercx_cfg017_s          cn70xx;
+	struct cvmx_pciercx_cfg017_s          cn70xxp1;
 	struct cvmx_pciercx_cfg017_s          cn78xx;
 	struct cvmx_pciercx_cfg017_s          cnf71xx;
 };
@@ -4643,6 +4661,7 @@ union cvmx_pciercx_cfg020 {
 	struct cvmx_pciercx_cfg020_s          cn68xx;
 	struct cvmx_pciercx_cfg020_s          cn68xxp1;
 	struct cvmx_pciercx_cfg020_cn61xx     cn70xx;
+	struct cvmx_pciercx_cfg020_cn61xx     cn70xxp1;
 	struct cvmx_pciercx_cfg020_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_25_31               : 7;
@@ -4703,6 +4722,7 @@ union cvmx_pciercx_cfg021 {
 	struct cvmx_pciercx_cfg021_s          cn68xx;
 	struct cvmx_pciercx_cfg021_s          cn68xxp1;
 	struct cvmx_pciercx_cfg021_s          cn70xx;
+	struct cvmx_pciercx_cfg021_s          cn70xxp1;
 	struct cvmx_pciercx_cfg021_s          cn78xx;
 	struct cvmx_pciercx_cfg021_s          cnf71xx;
 };
@@ -4734,6 +4754,7 @@ union cvmx_pciercx_cfg022 {
 	struct cvmx_pciercx_cfg022_s          cn68xx;
 	struct cvmx_pciercx_cfg022_s          cn68xxp1;
 	struct cvmx_pciercx_cfg022_s          cn70xx;
+	struct cvmx_pciercx_cfg022_s          cn70xxp1;
 	struct cvmx_pciercx_cfg022_s          cn78xx;
 	struct cvmx_pciercx_cfg022_s          cnf71xx;
 };
@@ -4769,6 +4790,7 @@ union cvmx_pciercx_cfg023 {
 	struct cvmx_pciercx_cfg023_s          cn68xx;
 	struct cvmx_pciercx_cfg023_s          cn68xxp1;
 	struct cvmx_pciercx_cfg023_s          cn70xx;
+	struct cvmx_pciercx_cfg023_s          cn70xxp1;
 	struct cvmx_pciercx_cfg023_s          cn78xx;
 	struct cvmx_pciercx_cfg023_s          cnf71xx;
 };
@@ -4820,6 +4842,7 @@ union cvmx_pciercx_cfg028 {
 	struct cvmx_pciercx_cfg028_s          cn68xx;
 	struct cvmx_pciercx_cfg028_s          cn68xxp1;
 	struct cvmx_pciercx_cfg028_s          cn70xx;
+	struct cvmx_pciercx_cfg028_s          cn70xxp1;
 	struct cvmx_pciercx_cfg028_s          cn78xx;
 	struct cvmx_pciercx_cfg028_s          cnf71xx;
 };
@@ -4884,6 +4907,7 @@ union cvmx_pciercx_cfg029 {
 	struct cvmx_pciercx_cfg029_s          cn68xx;
 	struct cvmx_pciercx_cfg029_s          cn68xxp1;
 	struct cvmx_pciercx_cfg029_s          cn70xx;
+	struct cvmx_pciercx_cfg029_s          cn70xxp1;
 	struct cvmx_pciercx_cfg029_s          cn78xx;
 	struct cvmx_pciercx_cfg029_s          cnf71xx;
 };
@@ -5000,6 +5024,7 @@ union cvmx_pciercx_cfg030 {
 	struct cvmx_pciercx_cfg030_s          cn68xx;
 	struct cvmx_pciercx_cfg030_s          cn68xxp1;
 	struct cvmx_pciercx_cfg030_s          cn70xx;
+	struct cvmx_pciercx_cfg030_s          cn70xxp1;
 	struct cvmx_pciercx_cfg030_s          cn78xx;
 	struct cvmx_pciercx_cfg030_s          cnf71xx;
 };
@@ -5130,6 +5155,7 @@ union cvmx_pciercx_cfg031 {
 	struct cvmx_pciercx_cfg031_s          cn68xx;
 	struct cvmx_pciercx_cfg031_cn52xx     cn68xxp1;
 	struct cvmx_pciercx_cfg031_s          cn70xx;
+	struct cvmx_pciercx_cfg031_s          cn70xxp1;
 	struct cvmx_pciercx_cfg031_s          cn78xx;
 	struct cvmx_pciercx_cfg031_s          cnf71xx;
 };
@@ -5232,6 +5258,7 @@ union cvmx_pciercx_cfg032 {
 	struct cvmx_pciercx_cfg032_s          cn68xx;
 	struct cvmx_pciercx_cfg032_s          cn68xxp1;
 	struct cvmx_pciercx_cfg032_s          cn70xx;
+	struct cvmx_pciercx_cfg032_s          cn70xxp1;
 	struct cvmx_pciercx_cfg032_s          cn78xx;
 	struct cvmx_pciercx_cfg032_s          cnf71xx;
 };
@@ -5295,6 +5322,7 @@ union cvmx_pciercx_cfg033 {
 	struct cvmx_pciercx_cfg033_s          cn68xx;
 	struct cvmx_pciercx_cfg033_s          cn68xxp1;
 	struct cvmx_pciercx_cfg033_s          cn70xx;
+	struct cvmx_pciercx_cfg033_s          cn70xxp1;
 	struct cvmx_pciercx_cfg033_s          cn78xx;
 	struct cvmx_pciercx_cfg033_s          cnf71xx;
 };
@@ -5368,6 +5396,7 @@ union cvmx_pciercx_cfg034 {
 	struct cvmx_pciercx_cfg034_s          cn68xx;
 	struct cvmx_pciercx_cfg034_s          cn68xxp1;
 	struct cvmx_pciercx_cfg034_s          cn70xx;
+	struct cvmx_pciercx_cfg034_s          cn70xxp1;
 	struct cvmx_pciercx_cfg034_s          cn78xx;
 	struct cvmx_pciercx_cfg034_s          cnf71xx;
 };
@@ -5415,6 +5444,7 @@ union cvmx_pciercx_cfg035 {
 	struct cvmx_pciercx_cfg035_s          cn68xx;
 	struct cvmx_pciercx_cfg035_s          cn68xxp1;
 	struct cvmx_pciercx_cfg035_s          cn70xx;
+	struct cvmx_pciercx_cfg035_s          cn70xxp1;
 	struct cvmx_pciercx_cfg035_s          cn78xx;
 	struct cvmx_pciercx_cfg035_s          cnf71xx;
 };
@@ -5452,6 +5482,7 @@ union cvmx_pciercx_cfg036 {
 	struct cvmx_pciercx_cfg036_s          cn68xx;
 	struct cvmx_pciercx_cfg036_s          cn68xxp1;
 	struct cvmx_pciercx_cfg036_s          cn70xx;
+	struct cvmx_pciercx_cfg036_s          cn70xxp1;
 	struct cvmx_pciercx_cfg036_s          cn78xx;
 	struct cvmx_pciercx_cfg036_s          cnf71xx;
 };
@@ -5604,6 +5635,7 @@ union cvmx_pciercx_cfg037 {
 	struct cvmx_pciercx_cfg037_cn66xx     cn68xx;
 	struct cvmx_pciercx_cfg037_cn66xx     cn68xxp1;
 	struct cvmx_pciercx_cfg037_cn61xx     cn70xx;
+	struct cvmx_pciercx_cfg037_cn61xx     cn70xxp1;
 	struct cvmx_pciercx_cfg037_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_24_31               : 8;
@@ -5802,6 +5834,7 @@ union cvmx_pciercx_cfg038 {
 	struct cvmx_pciercx_cfg038_cn61xx     cn68xx;
 	struct cvmx_pciercx_cfg038_cn61xx     cn68xxp1;
 	struct cvmx_pciercx_cfg038_cn61xx     cn70xx;
+	struct cvmx_pciercx_cfg038_cn61xx     cn70xxp1;
 	struct cvmx_pciercx_cfg038_s          cn78xx;
 	struct cvmx_pciercx_cfg038_cnf71xx {
 #ifdef __BIG_ENDIAN_BITFIELD
@@ -5902,6 +5935,7 @@ union cvmx_pciercx_cfg039 {
 	struct cvmx_pciercx_cfg039_s          cn68xx;
 	struct cvmx_pciercx_cfg039_s          cn68xxp1;
 	struct cvmx_pciercx_cfg039_s          cn70xx;
+	struct cvmx_pciercx_cfg039_s          cn70xxp1;
 	struct cvmx_pciercx_cfg039_s          cn78xx;
 	struct cvmx_pciercx_cfg039_s          cnf71xx;
 };
@@ -6129,6 +6163,7 @@ union cvmx_pciercx_cfg040 {
 	struct cvmx_pciercx_cfg040_cn61xx     cn68xx;
 	struct cvmx_pciercx_cfg040_cn61xx     cn68xxp1;
 	struct cvmx_pciercx_cfg040_cn61xx     cn70xx;
+	struct cvmx_pciercx_cfg040_cn61xx     cn70xxp1;
 	struct cvmx_pciercx_cfg040_s          cn78xx;
 	struct cvmx_pciercx_cfg040_cn61xx     cnf71xx;
 };
@@ -6160,6 +6195,7 @@ union cvmx_pciercx_cfg041 {
 	struct cvmx_pciercx_cfg041_s          cn68xx;
 	struct cvmx_pciercx_cfg041_s          cn68xxp1;
 	struct cvmx_pciercx_cfg041_s          cn70xx;
+	struct cvmx_pciercx_cfg041_s          cn70xxp1;
 	struct cvmx_pciercx_cfg041_s          cn78xx;
 	struct cvmx_pciercx_cfg041_s          cnf71xx;
 };
@@ -6191,6 +6227,7 @@ union cvmx_pciercx_cfg042 {
 	struct cvmx_pciercx_cfg042_s          cn68xx;
 	struct cvmx_pciercx_cfg042_s          cn68xxp1;
 	struct cvmx_pciercx_cfg042_s          cn70xx;
+	struct cvmx_pciercx_cfg042_s          cn70xxp1;
 	struct cvmx_pciercx_cfg042_s          cn78xx;
 	struct cvmx_pciercx_cfg042_s          cnf71xx;
 };
@@ -6313,6 +6350,7 @@ union cvmx_pciercx_cfg064 {
 	struct cvmx_pciercx_cfg064_s          cn68xx;
 	struct cvmx_pciercx_cfg064_s          cn68xxp1;
 	struct cvmx_pciercx_cfg064_s          cn70xx;
+	struct cvmx_pciercx_cfg064_s          cn70xxp1;
 	struct cvmx_pciercx_cfg064_s          cn78xx;
 	struct cvmx_pciercx_cfg064_s          cnf71xx;
 };
@@ -6488,6 +6526,7 @@ union cvmx_pciercx_cfg065 {
 	uint32_t reserved_25_31               : 7;
 #endif
 	} cn70xx;
+	struct cvmx_pciercx_cfg065_cn70xx     cn70xxp1;
 	struct cvmx_pciercx_cfg065_s          cn78xx;
 	struct cvmx_pciercx_cfg065_cn70xx     cnf71xx;
 };
@@ -6663,6 +6702,7 @@ union cvmx_pciercx_cfg066 {
 	uint32_t reserved_25_31               : 7;
 #endif
 	} cn70xx;
+	struct cvmx_pciercx_cfg066_cn70xx     cn70xxp1;
 	struct cvmx_pciercx_cfg066_s          cn78xx;
 	struct cvmx_pciercx_cfg066_cn70xx     cnf71xx;
 };
@@ -6834,6 +6874,7 @@ union cvmx_pciercx_cfg067 {
 	uint32_t reserved_25_31               : 7;
 #endif
 	} cn70xx;
+	struct cvmx_pciercx_cfg067_cn70xx     cn70xxp1;
 	struct cvmx_pciercx_cfg067_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_26_31               : 6;
@@ -6943,6 +6984,7 @@ union cvmx_pciercx_cfg068 {
 	struct cvmx_pciercx_cfg068_cn52xx     cn68xx;
 	struct cvmx_pciercx_cfg068_cn52xx     cn68xxp1;
 	struct cvmx_pciercx_cfg068_s          cn70xx;
+	struct cvmx_pciercx_cfg068_s          cn70xxp1;
 	struct cvmx_pciercx_cfg068_s          cn78xx;
 	struct cvmx_pciercx_cfg068_s          cnf71xx;
 };
@@ -7014,6 +7056,7 @@ union cvmx_pciercx_cfg069 {
 	struct cvmx_pciercx_cfg069_cn52xx     cn68xx;
 	struct cvmx_pciercx_cfg069_cn52xx     cn68xxp1;
 	struct cvmx_pciercx_cfg069_s          cn70xx;
+	struct cvmx_pciercx_cfg069_s          cn70xxp1;
 	struct cvmx_pciercx_cfg069_s          cn78xx;
 	struct cvmx_pciercx_cfg069_s          cnf71xx;
 };
@@ -7075,6 +7118,7 @@ union cvmx_pciercx_cfg070 {
 	struct cvmx_pciercx_cfg070_cn52xx     cn68xx;
 	struct cvmx_pciercx_cfg070_cn52xx     cn68xxp1;
 	struct cvmx_pciercx_cfg070_cn52xx     cn70xx;
+	struct cvmx_pciercx_cfg070_cn52xx     cn70xxp1;
 	struct cvmx_pciercx_cfg070_s          cn78xx;
 	struct cvmx_pciercx_cfg070_cn52xx     cnf71xx;
 };
@@ -7106,6 +7150,7 @@ union cvmx_pciercx_cfg071 {
 	struct cvmx_pciercx_cfg071_s          cn68xx;
 	struct cvmx_pciercx_cfg071_s          cn68xxp1;
 	struct cvmx_pciercx_cfg071_s          cn70xx;
+	struct cvmx_pciercx_cfg071_s          cn70xxp1;
 	struct cvmx_pciercx_cfg071_s          cn78xx;
 	struct cvmx_pciercx_cfg071_s          cnf71xx;
 };
@@ -7137,6 +7182,7 @@ union cvmx_pciercx_cfg072 {
 	struct cvmx_pciercx_cfg072_s          cn68xx;
 	struct cvmx_pciercx_cfg072_s          cn68xxp1;
 	struct cvmx_pciercx_cfg072_s          cn70xx;
+	struct cvmx_pciercx_cfg072_s          cn70xxp1;
 	struct cvmx_pciercx_cfg072_s          cn78xx;
 	struct cvmx_pciercx_cfg072_s          cnf71xx;
 };
@@ -7168,6 +7214,7 @@ union cvmx_pciercx_cfg073 {
 	struct cvmx_pciercx_cfg073_s          cn68xx;
 	struct cvmx_pciercx_cfg073_s          cn68xxp1;
 	struct cvmx_pciercx_cfg073_s          cn70xx;
+	struct cvmx_pciercx_cfg073_s          cn70xxp1;
 	struct cvmx_pciercx_cfg073_s          cn78xx;
 	struct cvmx_pciercx_cfg073_s          cnf71xx;
 };
@@ -7199,6 +7246,7 @@ union cvmx_pciercx_cfg074 {
 	struct cvmx_pciercx_cfg074_s          cn68xx;
 	struct cvmx_pciercx_cfg074_s          cn68xxp1;
 	struct cvmx_pciercx_cfg074_s          cn70xx;
+	struct cvmx_pciercx_cfg074_s          cn70xxp1;
 	struct cvmx_pciercx_cfg074_s          cn78xx;
 	struct cvmx_pciercx_cfg074_s          cnf71xx;
 };
@@ -7236,6 +7284,7 @@ union cvmx_pciercx_cfg075 {
 	struct cvmx_pciercx_cfg075_s          cn68xx;
 	struct cvmx_pciercx_cfg075_s          cn68xxp1;
 	struct cvmx_pciercx_cfg075_s          cn70xx;
+	struct cvmx_pciercx_cfg075_s          cn70xxp1;
 	struct cvmx_pciercx_cfg075_s          cn78xx;
 	struct cvmx_pciercx_cfg075_s          cnf71xx;
 };
@@ -7284,6 +7333,7 @@ union cvmx_pciercx_cfg076 {
 	struct cvmx_pciercx_cfg076_s          cn68xx;
 	struct cvmx_pciercx_cfg076_s          cn68xxp1;
 	struct cvmx_pciercx_cfg076_s          cn70xx;
+	struct cvmx_pciercx_cfg076_s          cn70xxp1;
 	struct cvmx_pciercx_cfg076_s          cn78xx;
 	struct cvmx_pciercx_cfg076_s          cnf71xx;
 };
@@ -7317,6 +7367,7 @@ union cvmx_pciercx_cfg077 {
 	struct cvmx_pciercx_cfg077_s          cn68xx;
 	struct cvmx_pciercx_cfg077_s          cn68xxp1;
 	struct cvmx_pciercx_cfg077_s          cn70xx;
+	struct cvmx_pciercx_cfg077_s          cn70xxp1;
 	struct cvmx_pciercx_cfg077_s          cn78xx;
 	struct cvmx_pciercx_cfg077_s          cnf71xx;
 };
@@ -7627,6 +7678,7 @@ union cvmx_pciercx_cfg448 {
 	struct cvmx_pciercx_cfg448_s          cn68xx;
 	struct cvmx_pciercx_cfg448_s          cn68xxp1;
 	struct cvmx_pciercx_cfg448_s          cn70xx;
+	struct cvmx_pciercx_cfg448_s          cn70xxp1;
 	struct cvmx_pciercx_cfg448_s          cn78xx;
 	struct cvmx_pciercx_cfg448_s          cnf71xx;
 };
@@ -7669,6 +7721,7 @@ union cvmx_pciercx_cfg449 {
 	struct cvmx_pciercx_cfg449_s          cn68xx;
 	struct cvmx_pciercx_cfg449_s          cn68xxp1;
 	struct cvmx_pciercx_cfg449_s          cn70xx;
+	struct cvmx_pciercx_cfg449_s          cn70xxp1;
 	struct cvmx_pciercx_cfg449_s          cn78xx;
 	struct cvmx_pciercx_cfg449_s          cnf71xx;
 };
@@ -7838,6 +7891,7 @@ union cvmx_pciercx_cfg450 {
 	struct cvmx_pciercx_cfg450_cn52xx     cn68xx;
 	struct cvmx_pciercx_cfg450_cn52xx     cn68xxp1;
 	struct cvmx_pciercx_cfg450_s          cn70xx;
+	struct cvmx_pciercx_cfg450_s          cn70xxp1;
 	struct cvmx_pciercx_cfg450_cn52xx     cn78xx;
 	struct cvmx_pciercx_cfg450_cn52xx     cnf71xx;
 };
@@ -7961,6 +8015,7 @@ union cvmx_pciercx_cfg451 {
 	struct cvmx_pciercx_cfg451_s          cn68xx;
 	struct cvmx_pciercx_cfg451_s          cn68xxp1;
 	struct cvmx_pciercx_cfg451_s          cn70xx;
+	struct cvmx_pciercx_cfg451_s          cn70xxp1;
 	struct cvmx_pciercx_cfg451_s          cn78xx;
 	struct cvmx_pciercx_cfg451_s          cnf71xx;
 };
@@ -8233,6 +8288,7 @@ union cvmx_pciercx_cfg452 {
 	uint32_t reserved_22_31               : 10;
 #endif
 	} cn70xx;
+	struct cvmx_pciercx_cfg452_cn70xx     cn70xxp1;
 	struct cvmx_pciercx_cfg452_cn70xx     cn78xx;
 	struct cvmx_pciercx_cfg452_cn61xx     cnf71xx;
 };
@@ -8280,6 +8336,7 @@ union cvmx_pciercx_cfg453 {
 	struct cvmx_pciercx_cfg453_s          cn68xx;
 	struct cvmx_pciercx_cfg453_s          cn68xxp1;
 	struct cvmx_pciercx_cfg453_s          cn70xx;
+	struct cvmx_pciercx_cfg453_s          cn70xxp1;
 	struct cvmx_pciercx_cfg453_s          cn78xx;
 	struct cvmx_pciercx_cfg453_s          cnf71xx;
 };
@@ -8401,6 +8458,7 @@ union cvmx_pciercx_cfg454 {
 	uint32_t reserved_24_31               : 8;
 #endif
 	} cn70xx;
+	struct cvmx_pciercx_cfg454_cn70xx     cn70xxp1;
 	struct cvmx_pciercx_cfg454_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint32_t reserved_29_31               : 3;
@@ -8489,6 +8547,7 @@ union cvmx_pciercx_cfg455 {
 	struct cvmx_pciercx_cfg455_s          cn68xx;
 	struct cvmx_pciercx_cfg455_s          cn68xxp1;
 	struct cvmx_pciercx_cfg455_s          cn70xx;
+	struct cvmx_pciercx_cfg455_s          cn70xxp1;
 	struct cvmx_pciercx_cfg455_s          cn78xx;
 	struct cvmx_pciercx_cfg455_s          cnf71xx;
 };
@@ -8538,6 +8597,7 @@ union cvmx_pciercx_cfg456 {
 	struct cvmx_pciercx_cfg456_s          cn68xx;
 	struct cvmx_pciercx_cfg456_cn52xx     cn68xxp1;
 	struct cvmx_pciercx_cfg456_s          cn70xx;
+	struct cvmx_pciercx_cfg456_s          cn70xxp1;
 	struct cvmx_pciercx_cfg456_s          cn78xx;
 	struct cvmx_pciercx_cfg456_s          cnf71xx;
 };
@@ -8569,6 +8629,7 @@ union cvmx_pciercx_cfg458 {
 	struct cvmx_pciercx_cfg458_s          cn68xx;
 	struct cvmx_pciercx_cfg458_s          cn68xxp1;
 	struct cvmx_pciercx_cfg458_s          cn70xx;
+	struct cvmx_pciercx_cfg458_s          cn70xxp1;
 	struct cvmx_pciercx_cfg458_s          cn78xx;
 	struct cvmx_pciercx_cfg458_s          cnf71xx;
 };
@@ -8600,6 +8661,7 @@ union cvmx_pciercx_cfg459 {
 	struct cvmx_pciercx_cfg459_s          cn68xx;
 	struct cvmx_pciercx_cfg459_s          cn68xxp1;
 	struct cvmx_pciercx_cfg459_s          cn70xx;
+	struct cvmx_pciercx_cfg459_s          cn70xxp1;
 	struct cvmx_pciercx_cfg459_s          cn78xx;
 	struct cvmx_pciercx_cfg459_s          cnf71xx;
 };
@@ -8639,6 +8701,7 @@ union cvmx_pciercx_cfg460 {
 	struct cvmx_pciercx_cfg460_s          cn68xx;
 	struct cvmx_pciercx_cfg460_s          cn68xxp1;
 	struct cvmx_pciercx_cfg460_s          cn70xx;
+	struct cvmx_pciercx_cfg460_s          cn70xxp1;
 	struct cvmx_pciercx_cfg460_s          cn78xx;
 	struct cvmx_pciercx_cfg460_s          cnf71xx;
 };
@@ -8678,6 +8741,7 @@ union cvmx_pciercx_cfg461 {
 	struct cvmx_pciercx_cfg461_s          cn68xx;
 	struct cvmx_pciercx_cfg461_s          cn68xxp1;
 	struct cvmx_pciercx_cfg461_s          cn70xx;
+	struct cvmx_pciercx_cfg461_s          cn70xxp1;
 	struct cvmx_pciercx_cfg461_s          cn78xx;
 	struct cvmx_pciercx_cfg461_s          cnf71xx;
 };
@@ -8717,6 +8781,7 @@ union cvmx_pciercx_cfg462 {
 	struct cvmx_pciercx_cfg462_s          cn68xx;
 	struct cvmx_pciercx_cfg462_s          cn68xxp1;
 	struct cvmx_pciercx_cfg462_s          cn70xx;
+	struct cvmx_pciercx_cfg462_s          cn70xxp1;
 	struct cvmx_pciercx_cfg462_s          cn78xx;
 	struct cvmx_pciercx_cfg462_s          cnf71xx;
 };
@@ -8788,6 +8853,7 @@ union cvmx_pciercx_cfg463 {
 	struct cvmx_pciercx_cfg463_cn52xx     cn68xx;
 	struct cvmx_pciercx_cfg463_cn52xx     cn68xxp1;
 	struct cvmx_pciercx_cfg463_cn52xx     cn70xx;
+	struct cvmx_pciercx_cfg463_cn52xx     cn70xxp1;
 	struct cvmx_pciercx_cfg463_s          cn78xx;
 	struct cvmx_pciercx_cfg463_cn52xx     cnf71xx;
 };
@@ -8825,6 +8891,7 @@ union cvmx_pciercx_cfg464 {
 	struct cvmx_pciercx_cfg464_s          cn68xx;
 	struct cvmx_pciercx_cfg464_s          cn68xxp1;
 	struct cvmx_pciercx_cfg464_s          cn70xx;
+	struct cvmx_pciercx_cfg464_s          cn70xxp1;
 	struct cvmx_pciercx_cfg464_s          cn78xx;
 	struct cvmx_pciercx_cfg464_s          cnf71xx;
 };
@@ -8862,6 +8929,7 @@ union cvmx_pciercx_cfg465 {
 	struct cvmx_pciercx_cfg465_s          cn68xx;
 	struct cvmx_pciercx_cfg465_s          cn68xxp1;
 	struct cvmx_pciercx_cfg465_s          cn70xx;
+	struct cvmx_pciercx_cfg465_s          cn70xxp1;
 	struct cvmx_pciercx_cfg465_s          cn78xx;
 	struct cvmx_pciercx_cfg465_s          cnf71xx;
 };
@@ -8935,6 +9003,7 @@ union cvmx_pciercx_cfg466 {
 	struct cvmx_pciercx_cfg466_s          cn68xx;
 	struct cvmx_pciercx_cfg466_s          cn68xxp1;
 	struct cvmx_pciercx_cfg466_s          cn70xx;
+	struct cvmx_pciercx_cfg466_s          cn70xxp1;
 	struct cvmx_pciercx_cfg466_s          cn78xx;
 	struct cvmx_pciercx_cfg466_s          cnf71xx;
 };
@@ -8990,6 +9059,7 @@ union cvmx_pciercx_cfg467 {
 	struct cvmx_pciercx_cfg467_s          cn68xx;
 	struct cvmx_pciercx_cfg467_s          cn68xxp1;
 	struct cvmx_pciercx_cfg467_s          cn70xx;
+	struct cvmx_pciercx_cfg467_s          cn70xxp1;
 	struct cvmx_pciercx_cfg467_s          cn78xx;
 	struct cvmx_pciercx_cfg467_s          cnf71xx;
 };
@@ -9045,6 +9115,7 @@ union cvmx_pciercx_cfg468 {
 	struct cvmx_pciercx_cfg468_s          cn68xx;
 	struct cvmx_pciercx_cfg468_s          cn68xxp1;
 	struct cvmx_pciercx_cfg468_s          cn70xx;
+	struct cvmx_pciercx_cfg468_s          cn70xxp1;
 	struct cvmx_pciercx_cfg468_s          cn78xx;
 	struct cvmx_pciercx_cfg468_s          cnf71xx;
 };
@@ -9090,6 +9161,7 @@ union cvmx_pciercx_cfg490 {
 	struct cvmx_pciercx_cfg490_s          cn68xx;
 	struct cvmx_pciercx_cfg490_s          cn68xxp1;
 	struct cvmx_pciercx_cfg490_s          cn70xx;
+	struct cvmx_pciercx_cfg490_s          cn70xxp1;
 	struct cvmx_pciercx_cfg490_s          cnf71xx;
 };
 typedef union cvmx_pciercx_cfg490 cvmx_pciercx_cfg490_t;
@@ -9134,6 +9206,7 @@ union cvmx_pciercx_cfg491 {
 	struct cvmx_pciercx_cfg491_s          cn68xx;
 	struct cvmx_pciercx_cfg491_s          cn68xxp1;
 	struct cvmx_pciercx_cfg491_s          cn70xx;
+	struct cvmx_pciercx_cfg491_s          cn70xxp1;
 	struct cvmx_pciercx_cfg491_s          cnf71xx;
 };
 typedef union cvmx_pciercx_cfg491 cvmx_pciercx_cfg491_t;
@@ -9178,6 +9251,7 @@ union cvmx_pciercx_cfg492 {
 	struct cvmx_pciercx_cfg492_s          cn68xx;
 	struct cvmx_pciercx_cfg492_s          cn68xxp1;
 	struct cvmx_pciercx_cfg492_s          cn70xx;
+	struct cvmx_pciercx_cfg492_s          cn70xxp1;
 	struct cvmx_pciercx_cfg492_s          cnf71xx;
 };
 typedef union cvmx_pciercx_cfg492 cvmx_pciercx_cfg492_t;
@@ -9236,6 +9310,7 @@ union cvmx_pciercx_cfg515 {
 	struct cvmx_pciercx_cfg515_s          cn68xx;
 	struct cvmx_pciercx_cfg515_s          cn68xxp1;
 	struct cvmx_pciercx_cfg515_s          cn70xx;
+	struct cvmx_pciercx_cfg515_s          cn70xxp1;
 	struct cvmx_pciercx_cfg515_s          cn78xx;
 	struct cvmx_pciercx_cfg515_s          cnf71xx;
 };
@@ -9267,6 +9342,7 @@ union cvmx_pciercx_cfg516 {
 	struct cvmx_pciercx_cfg516_s          cn68xx;
 	struct cvmx_pciercx_cfg516_s          cn68xxp1;
 	struct cvmx_pciercx_cfg516_s          cn70xx;
+	struct cvmx_pciercx_cfg516_s          cn70xxp1;
 	struct cvmx_pciercx_cfg516_s          cn78xx;
 	struct cvmx_pciercx_cfg516_s          cnf71xx;
 };
@@ -9298,6 +9374,7 @@ union cvmx_pciercx_cfg517 {
 	struct cvmx_pciercx_cfg517_s          cn68xx;
 	struct cvmx_pciercx_cfg517_s          cn68xxp1;
 	struct cvmx_pciercx_cfg517_s          cn70xx;
+	struct cvmx_pciercx_cfg517_s          cn70xxp1;
 	struct cvmx_pciercx_cfg517_s          cn78xx;
 	struct cvmx_pciercx_cfg517_s          cnf71xx;
 };
@@ -9355,7 +9432,9 @@ union cvmx_pciercx_cfg554 {
 	uint32_t u32;
 	struct cvmx_pciercx_cfg554_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint32_t reserved_24_31               : 8;
+	uint32_t reserved_25_31               : 7;
+	uint32_t iif                          : 1;  /**< Include initial FOM. Include, or not, the FOM feedback from the initial preset evaluation
+                                                         performed in the EQ Master, when finding the highest FOM among all preset evaluations. */
 	uint32_t prv                          : 16; /**< Preset request vector. Requesting of presets during the initial part of the EQ master
                                                          phase. Encoding scheme as follows:
                                                          Bit [15:0] = 0x0: No preset is requested and evaluated in the EQ master phase
@@ -9391,7 +9470,7 @@ union cvmx_pciercx_cfg554 {
                                                          * Equalization Phase 3 Successful status bit is not set in the link Status Register
                                                          * Equalization Phase 3 Complete status bit is set in the link Status Register */
 	uint32_t fm                           : 4;  /**< Feedback mode.
-                                                         0 = Direction of change.
+                                                         0 = Direction of change (not supported).
                                                          1 = Figure of merit.
                                                          2-15 = Reserved. */
 #else
@@ -9400,7 +9479,8 @@ union cvmx_pciercx_cfg554 {
 	uint32_t p23td                        : 1;
 	uint32_t reserved_6_7                 : 2;
 	uint32_t prv                          : 16;
-	uint32_t reserved_24_31               : 8;
+	uint32_t iif                          : 1;
+	uint32_t reserved_25_31               : 7;
 #endif
 	} s;
 	struct cvmx_pciercx_cfg554_s          cn78xx;
diff --git a/arch/mips/include/asm/octeon/cvmx-pcsx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcsx-defs.h
index d504dbe..e4b3750 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcsx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcsx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -951,6 +951,7 @@ union cvmx_pcsx_anx_adv_reg {
 	struct cvmx_pcsx_anx_adv_reg_s        cn68xx;
 	struct cvmx_pcsx_anx_adv_reg_s        cn68xxp1;
 	struct cvmx_pcsx_anx_adv_reg_s        cn70xx;
+	struct cvmx_pcsx_anx_adv_reg_s        cn70xxp1;
 	struct cvmx_pcsx_anx_adv_reg_s        cnf71xx;
 };
 typedef union cvmx_pcsx_anx_adv_reg cvmx_pcsx_anx_adv_reg_t;
@@ -991,6 +992,7 @@ union cvmx_pcsx_anx_ext_st_reg {
 	struct cvmx_pcsx_anx_ext_st_reg_s     cn68xx;
 	struct cvmx_pcsx_anx_ext_st_reg_s     cn68xxp1;
 	struct cvmx_pcsx_anx_ext_st_reg_s     cn70xx;
+	struct cvmx_pcsx_anx_ext_st_reg_s     cn70xxp1;
 	struct cvmx_pcsx_anx_ext_st_reg_s     cnf71xx;
 };
 typedef union cvmx_pcsx_anx_ext_st_reg cvmx_pcsx_anx_ext_st_reg_t;
@@ -1045,6 +1047,7 @@ union cvmx_pcsx_anx_lp_abil_reg {
 	struct cvmx_pcsx_anx_lp_abil_reg_s    cn68xx;
 	struct cvmx_pcsx_anx_lp_abil_reg_s    cn68xxp1;
 	struct cvmx_pcsx_anx_lp_abil_reg_s    cn70xx;
+	struct cvmx_pcsx_anx_lp_abil_reg_s    cn70xxp1;
 	struct cvmx_pcsx_anx_lp_abil_reg_s    cnf71xx;
 };
 typedef union cvmx_pcsx_anx_lp_abil_reg cvmx_pcsx_anx_lp_abil_reg_t;
@@ -1094,6 +1097,7 @@ union cvmx_pcsx_anx_results_reg {
 	struct cvmx_pcsx_anx_results_reg_s    cn68xx;
 	struct cvmx_pcsx_anx_results_reg_s    cn68xxp1;
 	struct cvmx_pcsx_anx_results_reg_s    cn70xx;
+	struct cvmx_pcsx_anx_results_reg_s    cn70xxp1;
 	struct cvmx_pcsx_anx_results_reg_s    cnf71xx;
 };
 typedef union cvmx_pcsx_anx_results_reg cvmx_pcsx_anx_results_reg_t;
@@ -1180,6 +1184,7 @@ union cvmx_pcsx_intx_en_reg {
 	struct cvmx_pcsx_intx_en_reg_s        cn68xx;
 	struct cvmx_pcsx_intx_en_reg_s        cn68xxp1;
 	struct cvmx_pcsx_intx_en_reg_s        cn70xx;
+	struct cvmx_pcsx_intx_en_reg_s        cn70xxp1;
 	struct cvmx_pcsx_intx_en_reg_s        cnf71xx;
 };
 typedef union cvmx_pcsx_intx_en_reg cvmx_pcsx_intx_en_reg_t;
@@ -1296,6 +1301,7 @@ union cvmx_pcsx_intx_reg {
 	struct cvmx_pcsx_intx_reg_s           cn68xx;
 	struct cvmx_pcsx_intx_reg_s           cn68xxp1;
 	struct cvmx_pcsx_intx_reg_s           cn70xx;
+	struct cvmx_pcsx_intx_reg_s           cn70xxp1;
 	struct cvmx_pcsx_intx_reg_s           cnf71xx;
 };
 typedef union cvmx_pcsx_intx_reg cvmx_pcsx_intx_reg_t;
@@ -1331,6 +1337,7 @@ union cvmx_pcsx_linkx_timer_count_reg {
 	struct cvmx_pcsx_linkx_timer_count_reg_s cn68xx;
 	struct cvmx_pcsx_linkx_timer_count_reg_s cn68xxp1;
 	struct cvmx_pcsx_linkx_timer_count_reg_s cn70xx;
+	struct cvmx_pcsx_linkx_timer_count_reg_s cn70xxp1;
 	struct cvmx_pcsx_linkx_timer_count_reg_s cnf71xx;
 };
 typedef union cvmx_pcsx_linkx_timer_count_reg cvmx_pcsx_linkx_timer_count_reg_t;
@@ -1376,6 +1383,7 @@ union cvmx_pcsx_log_anlx_reg {
 	struct cvmx_pcsx_log_anlx_reg_s       cn68xx;
 	struct cvmx_pcsx_log_anlx_reg_s       cn68xxp1;
 	struct cvmx_pcsx_log_anlx_reg_s       cn70xx;
+	struct cvmx_pcsx_log_anlx_reg_s       cn70xxp1;
 	struct cvmx_pcsx_log_anlx_reg_s       cnf71xx;
 };
 typedef union cvmx_pcsx_log_anlx_reg cvmx_pcsx_log_anlx_reg_t;
@@ -1402,6 +1410,7 @@ union cvmx_pcsx_mac_crdt_cntx_reg {
 #endif
 	} s;
 	struct cvmx_pcsx_mac_crdt_cntx_reg_s  cn70xx;
+	struct cvmx_pcsx_mac_crdt_cntx_reg_s  cn70xxp1;
 };
 typedef union cvmx_pcsx_mac_crdt_cntx_reg cvmx_pcsx_mac_crdt_cntx_reg_t;
 
@@ -1514,6 +1523,7 @@ union cvmx_pcsx_miscx_ctl_reg {
 	uint64_t reserved_12_63               : 52;
 #endif
 	} cn70xx;
+	struct cvmx_pcsx_miscx_ctl_reg_cn70xx cn70xxp1;
 	struct cvmx_pcsx_miscx_ctl_reg_s      cnf71xx;
 };
 typedef union cvmx_pcsx_miscx_ctl_reg cvmx_pcsx_miscx_ctl_reg_t;
@@ -1592,6 +1602,7 @@ union cvmx_pcsx_mrx_control_reg {
 	struct cvmx_pcsx_mrx_control_reg_s    cn68xx;
 	struct cvmx_pcsx_mrx_control_reg_s    cn68xxp1;
 	struct cvmx_pcsx_mrx_control_reg_s    cn70xx;
+	struct cvmx_pcsx_mrx_control_reg_s    cn70xxp1;
 	struct cvmx_pcsx_mrx_control_reg_s    cnf71xx;
 };
 typedef union cvmx_pcsx_mrx_control_reg cvmx_pcsx_mrx_control_reg_t;
@@ -1668,6 +1679,7 @@ union cvmx_pcsx_mrx_status_reg {
 	struct cvmx_pcsx_mrx_status_reg_s     cn68xx;
 	struct cvmx_pcsx_mrx_status_reg_s     cn68xxp1;
 	struct cvmx_pcsx_mrx_status_reg_s     cn70xx;
+	struct cvmx_pcsx_mrx_status_reg_s     cn70xxp1;
 	struct cvmx_pcsx_mrx_status_reg_s     cnf71xx;
 };
 typedef union cvmx_pcsx_mrx_status_reg cvmx_pcsx_mrx_status_reg_t;
@@ -1710,6 +1722,7 @@ union cvmx_pcsx_rxx_states_reg {
 	struct cvmx_pcsx_rxx_states_reg_s     cn68xx;
 	struct cvmx_pcsx_rxx_states_reg_s     cn68xxp1;
 	struct cvmx_pcsx_rxx_states_reg_s     cn70xx;
+	struct cvmx_pcsx_rxx_states_reg_s     cn70xxp1;
 	struct cvmx_pcsx_rxx_states_reg_s     cnf71xx;
 };
 typedef union cvmx_pcsx_rxx_states_reg cvmx_pcsx_rxx_states_reg_t;
@@ -1747,6 +1760,7 @@ union cvmx_pcsx_rxx_sync_reg {
 	struct cvmx_pcsx_rxx_sync_reg_s       cn68xx;
 	struct cvmx_pcsx_rxx_sync_reg_s       cn68xxp1;
 	struct cvmx_pcsx_rxx_sync_reg_s       cn70xx;
+	struct cvmx_pcsx_rxx_sync_reg_s       cn70xxp1;
 	struct cvmx_pcsx_rxx_sync_reg_s       cnf71xx;
 };
 typedef union cvmx_pcsx_rxx_sync_reg cvmx_pcsx_rxx_sync_reg_t;
@@ -1774,6 +1788,7 @@ union cvmx_pcsx_serdes_crdt_cntx_reg {
 #endif
 	} s;
 	struct cvmx_pcsx_serdes_crdt_cntx_reg_s cn70xx;
+	struct cvmx_pcsx_serdes_crdt_cntx_reg_s cn70xxp1;
 };
 typedef union cvmx_pcsx_serdes_crdt_cntx_reg cvmx_pcsx_serdes_crdt_cntx_reg_t;
 
@@ -1825,6 +1840,7 @@ union cvmx_pcsx_sgmx_an_adv_reg {
 	struct cvmx_pcsx_sgmx_an_adv_reg_s    cn68xx;
 	struct cvmx_pcsx_sgmx_an_adv_reg_s    cn68xxp1;
 	struct cvmx_pcsx_sgmx_an_adv_reg_s    cn70xx;
+	struct cvmx_pcsx_sgmx_an_adv_reg_s    cn70xxp1;
 	struct cvmx_pcsx_sgmx_an_adv_reg_s    cnf71xx;
 };
 typedef union cvmx_pcsx_sgmx_an_adv_reg cvmx_pcsx_sgmx_an_adv_reg_t;
@@ -1871,6 +1887,7 @@ union cvmx_pcsx_sgmx_lp_adv_reg {
 	struct cvmx_pcsx_sgmx_lp_adv_reg_s    cn68xx;
 	struct cvmx_pcsx_sgmx_lp_adv_reg_s    cn68xxp1;
 	struct cvmx_pcsx_sgmx_lp_adv_reg_s    cn70xx;
+	struct cvmx_pcsx_sgmx_lp_adv_reg_s    cn70xxp1;
 	struct cvmx_pcsx_sgmx_lp_adv_reg_s    cnf71xx;
 };
 typedef union cvmx_pcsx_sgmx_lp_adv_reg cvmx_pcsx_sgmx_lp_adv_reg_t;
@@ -1907,6 +1924,7 @@ union cvmx_pcsx_txx_states_reg {
 	struct cvmx_pcsx_txx_states_reg_s     cn68xx;
 	struct cvmx_pcsx_txx_states_reg_s     cn68xxp1;
 	struct cvmx_pcsx_txx_states_reg_s     cn70xx;
+	struct cvmx_pcsx_txx_states_reg_s     cn70xxp1;
 	struct cvmx_pcsx_txx_states_reg_s     cnf71xx;
 };
 typedef union cvmx_pcsx_txx_states_reg cvmx_pcsx_txx_states_reg_t;
@@ -1950,6 +1968,7 @@ union cvmx_pcsx_tx_rxx_polarity_reg {
 	struct cvmx_pcsx_tx_rxx_polarity_reg_s cn68xx;
 	struct cvmx_pcsx_tx_rxx_polarity_reg_s cn68xxp1;
 	struct cvmx_pcsx_tx_rxx_polarity_reg_s cn70xx;
+	struct cvmx_pcsx_tx_rxx_polarity_reg_s cn70xxp1;
 	struct cvmx_pcsx_tx_rxx_polarity_reg_s cnf71xx;
 };
 typedef union cvmx_pcsx_tx_rxx_polarity_reg cvmx_pcsx_tx_rxx_polarity_reg_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h b/arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h
index d880b3d..d3e594f 100644
--- a/arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pcsxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -734,6 +734,7 @@ union cvmx_pcsxx_10gbx_status_reg {
 	struct cvmx_pcsxx_10gbx_status_reg_s  cn68xx;
 	struct cvmx_pcsxx_10gbx_status_reg_s  cn68xxp1;
 	struct cvmx_pcsxx_10gbx_status_reg_s  cn70xx;
+	struct cvmx_pcsxx_10gbx_status_reg_s  cn70xxp1;
 };
 typedef union cvmx_pcsxx_10gbx_status_reg cvmx_pcsxx_10gbx_status_reg_t;
 
@@ -766,6 +767,7 @@ union cvmx_pcsxx_bist_status_reg {
 	struct cvmx_pcsxx_bist_status_reg_s   cn68xx;
 	struct cvmx_pcsxx_bist_status_reg_s   cn68xxp1;
 	struct cvmx_pcsxx_bist_status_reg_s   cn70xx;
+	struct cvmx_pcsxx_bist_status_reg_s   cn70xxp1;
 };
 typedef union cvmx_pcsxx_bist_status_reg cvmx_pcsxx_bist_status_reg_t;
 
@@ -803,6 +805,7 @@ union cvmx_pcsxx_bit_lock_status_reg {
 	struct cvmx_pcsxx_bit_lock_status_reg_s cn68xx;
 	struct cvmx_pcsxx_bit_lock_status_reg_s cn68xxp1;
 	struct cvmx_pcsxx_bit_lock_status_reg_s cn70xx;
+	struct cvmx_pcsxx_bit_lock_status_reg_s cn70xxp1;
 };
 typedef union cvmx_pcsxx_bit_lock_status_reg cvmx_pcsxx_bit_lock_status_reg_t;
 
@@ -865,6 +868,7 @@ union cvmx_pcsxx_control1_reg {
 	struct cvmx_pcsxx_control1_reg_s      cn68xx;
 	struct cvmx_pcsxx_control1_reg_s      cn68xxp1;
 	struct cvmx_pcsxx_control1_reg_s      cn70xx;
+	struct cvmx_pcsxx_control1_reg_s      cn70xxp1;
 };
 typedef union cvmx_pcsxx_control1_reg cvmx_pcsxx_control1_reg_t;
 
@@ -896,6 +900,7 @@ union cvmx_pcsxx_control2_reg {
 	struct cvmx_pcsxx_control2_reg_s      cn68xx;
 	struct cvmx_pcsxx_control2_reg_s      cn68xxp1;
 	struct cvmx_pcsxx_control2_reg_s      cn70xx;
+	struct cvmx_pcsxx_control2_reg_s      cn70xxp1;
 };
 typedef union cvmx_pcsxx_control2_reg cvmx_pcsxx_control2_reg_t;
 
@@ -957,6 +962,7 @@ union cvmx_pcsxx_int_en_reg {
 	struct cvmx_pcsxx_int_en_reg_s        cn68xx;
 	struct cvmx_pcsxx_int_en_reg_s        cn68xxp1;
 	struct cvmx_pcsxx_int_en_reg_s        cn70xx;
+	struct cvmx_pcsxx_int_en_reg_s        cn70xxp1;
 };
 typedef union cvmx_pcsxx_int_en_reg cvmx_pcsxx_int_en_reg_t;
 
@@ -1025,6 +1031,7 @@ union cvmx_pcsxx_int_reg {
 	struct cvmx_pcsxx_int_reg_s           cn68xx;
 	struct cvmx_pcsxx_int_reg_s           cn68xxp1;
 	struct cvmx_pcsxx_int_reg_s           cn70xx;
+	struct cvmx_pcsxx_int_reg_s           cn70xxp1;
 };
 typedef union cvmx_pcsxx_int_reg cvmx_pcsxx_int_reg_t;
 
@@ -1080,6 +1087,7 @@ union cvmx_pcsxx_log_anl_reg {
 	struct cvmx_pcsxx_log_anl_reg_s       cn68xx;
 	struct cvmx_pcsxx_log_anl_reg_s       cn68xxp1;
 	struct cvmx_pcsxx_log_anl_reg_s       cn70xx;
+	struct cvmx_pcsxx_log_anl_reg_s       cn70xxp1;
 };
 typedef union cvmx_pcsxx_log_anl_reg cvmx_pcsxx_log_anl_reg_t;
 
@@ -1121,6 +1129,7 @@ union cvmx_pcsxx_misc_ctl_reg {
 	struct cvmx_pcsxx_misc_ctl_reg_s      cn68xx;
 	struct cvmx_pcsxx_misc_ctl_reg_s      cn68xxp1;
 	struct cvmx_pcsxx_misc_ctl_reg_s      cn70xx;
+	struct cvmx_pcsxx_misc_ctl_reg_s      cn70xxp1;
 };
 typedef union cvmx_pcsxx_misc_ctl_reg cvmx_pcsxx_misc_ctl_reg_t;
 
@@ -1158,6 +1167,7 @@ union cvmx_pcsxx_rx_sync_states_reg {
 	struct cvmx_pcsxx_rx_sync_states_reg_s cn68xx;
 	struct cvmx_pcsxx_rx_sync_states_reg_s cn68xxp1;
 	struct cvmx_pcsxx_rx_sync_states_reg_s cn70xx;
+	struct cvmx_pcsxx_rx_sync_states_reg_s cn70xxp1;
 };
 typedef union cvmx_pcsxx_rx_sync_states_reg cvmx_pcsxx_rx_sync_states_reg_t;
 
@@ -1183,6 +1193,7 @@ union cvmx_pcsxx_serdes_crdt_cnt_reg {
 #endif
 	} s;
 	struct cvmx_pcsxx_serdes_crdt_cnt_reg_s cn70xx;
+	struct cvmx_pcsxx_serdes_crdt_cnt_reg_s cn70xxp1;
 };
 typedef union cvmx_pcsxx_serdes_crdt_cnt_reg cvmx_pcsxx_serdes_crdt_cnt_reg_t;
 
@@ -1216,6 +1227,7 @@ union cvmx_pcsxx_spd_abil_reg {
 	struct cvmx_pcsxx_spd_abil_reg_s      cn68xx;
 	struct cvmx_pcsxx_spd_abil_reg_s      cn68xxp1;
 	struct cvmx_pcsxx_spd_abil_reg_s      cn70xx;
+	struct cvmx_pcsxx_spd_abil_reg_s      cn70xxp1;
 };
 typedef union cvmx_pcsxx_spd_abil_reg cvmx_pcsxx_spd_abil_reg_t;
 
@@ -1258,6 +1270,7 @@ union cvmx_pcsxx_status1_reg {
 	struct cvmx_pcsxx_status1_reg_s       cn68xx;
 	struct cvmx_pcsxx_status1_reg_s       cn68xxp1;
 	struct cvmx_pcsxx_status1_reg_s       cn70xx;
+	struct cvmx_pcsxx_status1_reg_s       cn70xxp1;
 };
 typedef union cvmx_pcsxx_status1_reg cvmx_pcsxx_status1_reg_t;
 
@@ -1305,6 +1318,7 @@ union cvmx_pcsxx_status2_reg {
 	struct cvmx_pcsxx_status2_reg_s       cn68xx;
 	struct cvmx_pcsxx_status2_reg_s       cn68xxp1;
 	struct cvmx_pcsxx_status2_reg_s       cn70xx;
+	struct cvmx_pcsxx_status2_reg_s       cn70xxp1;
 };
 typedef union cvmx_pcsxx_status2_reg cvmx_pcsxx_status2_reg_t;
 
@@ -1353,6 +1367,7 @@ union cvmx_pcsxx_tx_rx_polarity_reg {
 	struct cvmx_pcsxx_tx_rx_polarity_reg_s cn68xx;
 	struct cvmx_pcsxx_tx_rx_polarity_reg_s cn68xxp1;
 	struct cvmx_pcsxx_tx_rx_polarity_reg_s cn70xx;
+	struct cvmx_pcsxx_tx_rx_polarity_reg_s cn70xxp1;
 };
 typedef union cvmx_pcsxx_tx_rx_polarity_reg cvmx_pcsxx_tx_rx_polarity_reg_t;
 
@@ -1423,6 +1438,7 @@ union cvmx_pcsxx_tx_rx_states_reg {
 	struct cvmx_pcsxx_tx_rx_states_reg_s  cn68xx;
 	struct cvmx_pcsxx_tx_rx_states_reg_s  cn68xxp1;
 	struct cvmx_pcsxx_tx_rx_states_reg_s  cn70xx;
+	struct cvmx_pcsxx_tx_rx_states_reg_s  cn70xxp1;
 };
 typedef union cvmx_pcsxx_tx_rx_states_reg cvmx_pcsxx_tx_rx_states_reg_t;
 
diff --git a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
index a24e051..e1f3e83 100644
--- a/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pemx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -842,6 +842,7 @@ union cvmx_pemx_bar1_indexx {
 	struct cvmx_pemx_bar1_indexx_cn61xx   cn68xx;
 	struct cvmx_pemx_bar1_indexx_cn61xx   cn68xxp1;
 	struct cvmx_pemx_bar1_indexx_s        cn70xx;
+	struct cvmx_pemx_bar1_indexx_s        cn70xxp1;
 	struct cvmx_pemx_bar1_indexx_s        cn78xx;
 	struct cvmx_pemx_bar1_indexx_cn61xx   cnf71xx;
 };
@@ -883,6 +884,7 @@ union cvmx_pemx_bar2_mask {
 	struct cvmx_pemx_bar2_mask_cn61xx     cn68xx;
 	struct cvmx_pemx_bar2_mask_cn61xx     cn68xxp1;
 	struct cvmx_pemx_bar2_mask_cn61xx     cn70xx;
+	struct cvmx_pemx_bar2_mask_cn61xx     cn70xxp1;
 	struct cvmx_pemx_bar2_mask_s          cn78xx;
 	struct cvmx_pemx_bar2_mask_cn61xx     cnf71xx;
 };
@@ -924,6 +926,7 @@ union cvmx_pemx_bar_ctl {
 	struct cvmx_pemx_bar_ctl_s            cn68xx;
 	struct cvmx_pemx_bar_ctl_s            cn68xxp1;
 	struct cvmx_pemx_bar_ctl_s            cn70xx;
+	struct cvmx_pemx_bar_ctl_s            cn70xxp1;
 	struct cvmx_pemx_bar_ctl_s            cn78xx;
 	struct cvmx_pemx_bar_ctl_s            cnf71xx;
 };
@@ -1029,6 +1032,7 @@ union cvmx_pemx_bist_status {
 	uint64_t reserved_6_63                : 58;
 #endif
 	} cn70xx;
+	struct cvmx_pemx_bist_status_cn70xx   cn70xxp1;
 	struct cvmx_pemx_bist_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_26_63               : 38;
@@ -1182,6 +1186,7 @@ union cvmx_pemx_bist_status2 {
 	uint64_t reserved_14_63               : 50;
 #endif
 	} cn70xx;
+	struct cvmx_pemx_bist_status2_cn70xx  cn70xxp1;
 	struct cvmx_pemx_bist_status2_cn61xx  cnf71xx;
 };
 typedef union cvmx_pemx_bist_status2 cvmx_pemx_bist_status2_t;
@@ -1197,11 +1202,14 @@ union cvmx_pemx_cfg {
 	struct cvmx_pemx_cfg_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t laneswap                     : 1;  /**< This field overwrites the signal setting for lane swapping. When set, lane swapping is
+	uint64_t laneswap                     : 1;  /**< This field enables overwriting the value for lane swapping. The reset value is captured on
+                                                         cold reset by the pin straps (see PEM(0..3)_STRAP.PILANESWAP). When set, lane swapping is
                                                          performed to/from the SerDes. When clear, no lane swapping is performed. */
 	uint64_t reserved_2_3                 : 2;
-	uint64_t md                           : 2;  /**< This field overwrites the signal settings for speed. Root complex configuration when the
-                                                         MD field is changed.
+	uint64_t md                           : 2;  /**< This field enables overwriting the value for speed. The reset value is captured on cold
+                                                         reset by the pin straps (see PEM(0..3)_STRAP.PIMODE). For a root complex configuration
+                                                         that is not running at Gen3 speed, the HOSTMD bit of this register must be set when this
+                                                         field is changed.
                                                          0x0 = Gen1 speed.
                                                          0x1 = Gen2 speed.
                                                          0x2 = Gen3 speed.
@@ -1246,21 +1254,28 @@ union cvmx_pemx_cfg {
 	uint64_t reserved_5_63                : 59;
 #endif
 	} cn70xx;
+	struct cvmx_pemx_cfg_cn70xx           cn70xxp1;
 	struct cvmx_pemx_cfg_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_5_63                : 59;
-	uint64_t laneswap                     : 1;  /**< This field overwrites the signal setting for lane swapping. When set, lane swapping is
+	uint64_t laneswap                     : 1;  /**< This field enables overwriting the value for lane swapping. The reset value is captured on
+                                                         cold reset by the pin straps (see PEM(0..3)_STRAP.PILANESWAP). When set, lane swapping is
                                                          performed to/from the SerDes. When clear, no lane swapping is performed. */
-	uint64_t lanes8                       : 1;  /**< This field overwrites the signal setting for number of lanes.
-                                                         When set, the PEM is configured for a maximum of 8 lanes. When clear, the PEM is
-                                                         configured for a maximum of 4 lanes. This value is used to set the maximum link width
-                                                         field in the core's link capabilities register (CFG031) to indicate the maximum number of
-                                                         lanes supported. Note that less lanes than the specified maximum can be configured for use
-                                                         via the core's link control register (CFG032) negotiated link width field. */
-	uint64_t hostmd                       : 1;  /**< This field overwrites the signal settings for host mode. When set, the PEM is configured
-                                                         to be a root complex. When clear, the PEM is configured to be an end point. */
-	uint64_t md                           : 2;  /**< This field overwrites the signal settings for speed. Root complex configuration when the
-                                                         MD field is changed.
+	uint64_t lanes8                       : 1;  /**< This field enables overwriting the value for the maximum number of lanes. The reset value
+                                                         is captured on cold reset by the pin straps (see PEM(0..3)_STRAP.PILANES8). When set, the
+                                                         PEM is configured for a maximum of 8 lanes. When clear, the PEM is configured for a
+                                                         maximum of 4 lanes. This value is used to set the maximum link width field in the core's
+                                                         link capabilities register (CFG031) to indicate the maximum number of lanes
+                                                         supported. Note that less lanes than the specified maximum can be configured for use via
+                                                         the core's link control register (CFG032) negotiated link width field. */
+	uint64_t hostmd                       : 1;  /**< This field enables overwriting the value for host mode. The reset value is captured on
+                                                         cold reset by the pin straps (see PEM(0..3)_STRAP.PIMODE). When set, the PEM is configured
+                                                         to be a root complex.
+                                                         When clear, the PEM is configured to be an end point. */
+	uint64_t md                           : 2;  /**< This field enables overwriting the value for speed. The reset value is captured on cold
+                                                         reset by the pin straps (see PEM(0..3)_STRAP.PIMODE). For a root complex configuration
+                                                         that is not running at Gen3 speed, the HOSTMD bit of this register must be set when this
+                                                         field is changed.
                                                          0x0 = Gen1 speed.
                                                          0x1 = Gen2 speed.
                                                          0x2 = Gen3 speed.
@@ -1301,6 +1316,7 @@ union cvmx_pemx_cfg_rd {
 	struct cvmx_pemx_cfg_rd_s             cn68xx;
 	struct cvmx_pemx_cfg_rd_s             cn68xxp1;
 	struct cvmx_pemx_cfg_rd_s             cn70xx;
+	struct cvmx_pemx_cfg_rd_s             cn70xxp1;
 	struct cvmx_pemx_cfg_rd_s             cn78xx;
 	struct cvmx_pemx_cfg_rd_s             cnf71xx;
 };
@@ -1332,6 +1348,7 @@ union cvmx_pemx_cfg_wr {
 	struct cvmx_pemx_cfg_wr_s             cn68xx;
 	struct cvmx_pemx_cfg_wr_s             cn68xxp1;
 	struct cvmx_pemx_cfg_wr_s             cn70xx;
+	struct cvmx_pemx_cfg_wr_s             cn70xxp1;
 	struct cvmx_pemx_cfg_wr_s             cn78xx;
 	struct cvmx_pemx_cfg_wr_s             cnf71xx;
 };
@@ -1357,6 +1374,7 @@ union cvmx_pemx_clk_en {
 #endif
 	} s;
 	struct cvmx_pemx_clk_en_s             cn70xx;
+	struct cvmx_pemx_clk_en_s             cn70xxp1;
 	struct cvmx_pemx_clk_en_s             cn78xx;
 };
 typedef union cvmx_pemx_clk_en cvmx_pemx_clk_en_t;
@@ -1393,6 +1411,7 @@ union cvmx_pemx_cpl_lut_valid {
 	struct cvmx_pemx_cpl_lut_valid_cn61xx cn68xx;
 	struct cvmx_pemx_cpl_lut_valid_cn61xx cn68xxp1;
 	struct cvmx_pemx_cpl_lut_valid_cn61xx cn70xx;
+	struct cvmx_pemx_cpl_lut_valid_cn61xx cn70xxp1;
 	struct cvmx_pemx_cpl_lut_valid_s      cn78xx;
 	struct cvmx_pemx_cpl_lut_valid_cn61xx cnf71xx;
 };
@@ -1535,6 +1554,7 @@ union cvmx_pemx_ctl_status {
 	struct cvmx_pemx_ctl_status_cn61xx    cn68xx;
 	struct cvmx_pemx_ctl_status_cn61xx    cn68xxp1;
 	struct cvmx_pemx_ctl_status_s         cn70xx;
+	struct cvmx_pemx_ctl_status_s         cn70xxp1;
 	struct cvmx_pemx_ctl_status_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_51_63               : 13;
@@ -2031,6 +2051,7 @@ union cvmx_pemx_dbg_info {
 	uint64_t reserved_46_63               : 18;
 #endif
 	} cn70xx;
+	struct cvmx_pemx_dbg_info_cn70xx      cn70xxp1;
 	struct cvmx_pemx_dbg_info_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_58_63               : 6;
@@ -2067,7 +2088,7 @@ union cvmx_pemx_dbg_info {
 	uint64_t ramtlp                       : 1;  /**< Received a malformed TLP. radm_mlf_tlp_err */
 	uint64_t rarwdns                      : 1;  /**< Received a request which device does not support. radm_rcvd_ur_req */
 	uint64_t caar                         : 1;  /**< Completer aborted a request. This bit is never set because CN78XX does not generate
-                                                         completer aborts. radm_rcvd_ca_req */
+                                                         completer aborts. */
 	uint64_t racca                        : 1;  /**< Received a completion with CA status. radm_rcvd_cpl_ca */
 	uint64_t racur                        : 1;  /**< Received a completion with UR status. radm_rcvd_cpl_ur */
 	uint64_t rauc                         : 1;  /**< Received an unexpected completion. radm_unexp_cpl_err */
@@ -2348,6 +2369,7 @@ union cvmx_pemx_dbg_info_en {
 	struct cvmx_pemx_dbg_info_en_cn61xx   cn68xx;
 	struct cvmx_pemx_dbg_info_en_cn61xx   cn68xxp1;
 	struct cvmx_pemx_dbg_info_en_s        cn70xx;
+	struct cvmx_pemx_dbg_info_en_s        cn70xxp1;
 	struct cvmx_pemx_dbg_info_en_cn61xx   cnf71xx;
 };
 typedef union cvmx_pemx_dbg_info_en cvmx_pemx_dbg_info_en_t;
@@ -2412,6 +2434,7 @@ union cvmx_pemx_diag_status {
 	uint64_t reserved_6_63                : 58;
 #endif
 	} cn70xx;
+	struct cvmx_pemx_diag_status_cn70xx   cn70xxp1;
 	struct cvmx_pemx_diag_status_s        cn78xx;
 	struct cvmx_pemx_diag_status_cn61xx   cnf71xx;
 };
@@ -2467,6 +2490,7 @@ union cvmx_pemx_ecc_ena {
 	uint64_t reserved_6_63                : 58;
 #endif
 	} cn70xx;
+	struct cvmx_pemx_ecc_ena_cn70xx       cn70xxp1;
 	struct cvmx_pemx_ecc_ena_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_35_63               : 29;
@@ -2553,6 +2577,7 @@ union cvmx_pemx_ecc_synd_ctrl {
 	uint64_t reserved_12_63               : 52;
 #endif
 	} cn70xx;
+	struct cvmx_pemx_ecc_synd_ctrl_cn70xx cn70xxp1;
 	struct cvmx_pemx_ecc_synd_ctrl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_38_63               : 26;
@@ -2622,6 +2647,7 @@ union cvmx_pemx_inb_read_credits {
 	struct cvmx_pemx_inb_read_credits_cn61xx cn66xx;
 	struct cvmx_pemx_inb_read_credits_cn61xx cn68xx;
 	struct cvmx_pemx_inb_read_credits_cn61xx cn70xx;
+	struct cvmx_pemx_inb_read_credits_cn61xx cn70xxp1;
 	struct cvmx_pemx_inb_read_credits_s   cn78xx;
 	struct cvmx_pemx_inb_read_credits_cn61xx cnf71xx;
 };
@@ -2691,6 +2717,7 @@ union cvmx_pemx_int_enb {
 	struct cvmx_pemx_int_enb_s            cn68xx;
 	struct cvmx_pemx_int_enb_s            cn68xxp1;
 	struct cvmx_pemx_int_enb_s            cn70xx;
+	struct cvmx_pemx_int_enb_s            cn70xxp1;
 	struct cvmx_pemx_int_enb_s            cnf71xx;
 };
 typedef union cvmx_pemx_int_enb cvmx_pemx_int_enb_t;
@@ -2759,6 +2786,7 @@ union cvmx_pemx_int_enb_int {
 	struct cvmx_pemx_int_enb_int_s        cn68xx;
 	struct cvmx_pemx_int_enb_int_s        cn68xxp1;
 	struct cvmx_pemx_int_enb_int_s        cn70xx;
+	struct cvmx_pemx_int_enb_int_s        cn70xxp1;
 	struct cvmx_pemx_int_enb_int_s        cnf71xx;
 };
 typedef union cvmx_pemx_int_enb_int cvmx_pemx_int_enb_int_t;
@@ -2773,10 +2801,10 @@ union cvmx_pemx_int_sum {
 	uint64_t u64;
 	struct cvmx_pemx_int_sum_s {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. */
-	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. */
-	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. */
-	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. */
+	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. This is a level sensitive interrupt. */
+	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. This is a level sensitive interrupt. */
+	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. This is a level sensitive interrupt. */
+	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. This is a level sensitive interrupt. */
 	uint64_t reserved_14_59               : 46;
 	uint64_t crs_dr                       : 1;  /**< Had a CRS Timeout when Retries were disabled. */
 	uint64_t crs_er                       : 1;  /**< Had a CRS Timeout when Retries were enabled. */
@@ -2871,12 +2899,13 @@ union cvmx_pemx_int_sum {
 	struct cvmx_pemx_int_sum_cn61xx       cn68xx;
 	struct cvmx_pemx_int_sum_cn61xx       cn68xxp1;
 	struct cvmx_pemx_int_sum_cn61xx       cn70xx;
+	struct cvmx_pemx_int_sum_cn61xx       cn70xxp1;
 	struct cvmx_pemx_int_sum_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. */
-	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. */
-	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. */
-	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. */
+	uint64_t intd                         : 1;  /**< The PCIe controller received an INTD. This is a level sensitive interrupt. */
+	uint64_t intc                         : 1;  /**< The PCIe controller received an INTC. This is a level sensitive interrupt. */
+	uint64_t intb                         : 1;  /**< The PCIe controller received an INTB. This is a level sensitive interrupt. */
+	uint64_t inta                         : 1;  /**< The PCIe controller received an INTA. This is a level sensitive interrupt. */
 	uint64_t reserved_14_59               : 46;
 	uint64_t crs_dr                       : 1;  /**< Had a CRS timeout when retries were disabled. */
 	uint64_t crs_er                       : 1;  /**< Had a CRS timeout when retries were enabled. */
@@ -2889,9 +2918,10 @@ union cvmx_pemx_int_sum {
 	uint64_t up_b2                        : 1;  /**< Received P-TLP for BAR2 when BAR2 is disabled. */
 	uint64_t up_b1                        : 1;  /**< Received P-TLP for BAR1 when BAR1 index valid is not set. */
 	uint64_t reserved_3_3                 : 1;
-	uint64_t pmei                         : 1;  /**< PME interrupt. (cfg_pme_int) */
-	uint64_t se                           : 1;  /**< System error, RC DEode Only.  (cfg_sys_err_rc) */
-	uint64_t aeri                         : 1;  /**< Advanced error reporting interrupt, RC mode only. (cfg_aer_rc_err_int). */
+	uint64_t pmei                         : 1;  /**< PME interrupt (cfg_pme_int). This is a level sensitive interrupt. */
+	uint64_t se                           : 1;  /**< System error, RC mode only.  (cfg_sys_err_rc) */
+	uint64_t aeri                         : 1;  /**< Advanced error reporting interrupt, RC mode only (cfg_aer_rc_err_int).
+                                                         This is a level sensitive interrupt. */
 #else
 	uint64_t aeri                         : 1;
 	uint64_t se                           : 1;
@@ -2940,6 +2970,7 @@ union cvmx_pemx_on {
 #endif
 	} s;
 	struct cvmx_pemx_on_s                 cn70xx;
+	struct cvmx_pemx_on_s                 cn70xxp1;
 	struct cvmx_pemx_on_s                 cn78xx;
 };
 typedef union cvmx_pemx_on cvmx_pemx_on_t;
@@ -2969,6 +3000,7 @@ union cvmx_pemx_p2n_bar0_start {
 	struct cvmx_pemx_p2n_bar0_start_s     cn68xx;
 	struct cvmx_pemx_p2n_bar0_start_s     cn68xxp1;
 	struct cvmx_pemx_p2n_bar0_start_s     cn70xx;
+	struct cvmx_pemx_p2n_bar0_start_s     cn70xxp1;
 	struct cvmx_pemx_p2n_bar0_start_s     cn78xx;
 	struct cvmx_pemx_p2n_bar0_start_s     cnf71xx;
 };
@@ -2999,6 +3031,7 @@ union cvmx_pemx_p2n_bar1_start {
 	struct cvmx_pemx_p2n_bar1_start_s     cn68xx;
 	struct cvmx_pemx_p2n_bar1_start_s     cn68xxp1;
 	struct cvmx_pemx_p2n_bar1_start_s     cn70xx;
+	struct cvmx_pemx_p2n_bar1_start_s     cn70xxp1;
 	struct cvmx_pemx_p2n_bar1_start_s     cn78xx;
 	struct cvmx_pemx_p2n_bar1_start_s     cnf71xx;
 };
@@ -3035,6 +3068,7 @@ union cvmx_pemx_p2n_bar2_start {
 	struct cvmx_pemx_p2n_bar2_start_cn61xx cn68xx;
 	struct cvmx_pemx_p2n_bar2_start_cn61xx cn68xxp1;
 	struct cvmx_pemx_p2n_bar2_start_cn61xx cn70xx;
+	struct cvmx_pemx_p2n_bar2_start_cn61xx cn70xxp1;
 	struct cvmx_pemx_p2n_bar2_start_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t addr                         : 19; /**< The starting address of the 2^45 BAR2 address space. */
@@ -3169,6 +3203,7 @@ union cvmx_pemx_spi_ctl {
 #endif
 	} s;
 	struct cvmx_pemx_spi_ctl_s            cn70xx;
+	struct cvmx_pemx_spi_ctl_s            cn70xxp1;
 	struct cvmx_pemx_spi_ctl_s            cn78xx;
 };
 typedef union cvmx_pemx_spi_ctl cvmx_pemx_spi_ctl_t;
@@ -3197,6 +3232,7 @@ union cvmx_pemx_spi_data {
 #endif
 	} s;
 	struct cvmx_pemx_spi_data_s           cn70xx;
+	struct cvmx_pemx_spi_data_s           cn70xxp1;
 	struct cvmx_pemx_spi_data_s           cn78xx;
 };
 typedef union cvmx_pemx_spi_data cvmx_pemx_spi_data_t;
@@ -3212,7 +3248,8 @@ union cvmx_pemx_strap {
 	struct cvmx_pemx_strap_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin. When set, lane swapping is performed to/from the
+	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin, which is captured on chip cold reset. It is not
+                                                         affected by any other reset.  When set, lane swapping is performed to/from the
                                                          SerDes. When clear, no lane swapping is performed. */
 	uint64_t reserved_0_2                 : 3;
 #else
@@ -3232,14 +3269,18 @@ union cvmx_pemx_strap {
 	uint64_t reserved_4_63                : 60;
 #endif
 	} cn70xx;
+	struct cvmx_pemx_strap_cn70xx         cn70xxp1;
 	struct cvmx_pemx_strap_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_4_63                : 60;
-	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin. When set, lane swapping is performed to/from the
+	uint64_t pilaneswap                   : 1;  /**< The value of the pi_select_laneswap pin, which is captured on chip cold reset. It is not
+                                                         affected by any other reset.  When set, lane swapping is performed to/from the
                                                          SerDes. When clear, no lane swapping is performed. */
-	uint64_t pilanes8                     : 1;  /**< The value of the pi_select_8lanes pin. When set, the PEM is configured for a maximum of
+	uint64_t pilanes8                     : 1;  /**< The value of the pi_select_8lanes pin, which is captured on chip cold reset. It is not
+                                                         affected by any other reset.  When set, the PEM is configured for a maximum of
                                                          8-lanes, When clear, the PEM is configured for a maximum of 4-lanes. */
-	uint64_t pimode                       : 2;  /**< The value of the pi_select_mode[1:0] pins:
+	uint64_t pimode                       : 2;  /**< The value of the pi_select_mode[1:0] pins, which are captured on chip cold reset. They are
+                                                         not affected by any other reset.
                                                          0x0 = EP mode, Gen1 speed.
                                                          0x1 = EP mode, Gen2 speed.
                                                          0x2 = EP mode, Gen3 speed.
@@ -3319,6 +3360,7 @@ union cvmx_pemx_tlp_credits {
 	struct cvmx_pemx_tlp_credits_s        cn68xx;
 	struct cvmx_pemx_tlp_credits_s        cn68xxp1;
 	struct cvmx_pemx_tlp_credits_cn61xx   cn70xx;
+	struct cvmx_pemx_tlp_credits_cn61xx   cn70xxp1;
 	struct cvmx_pemx_tlp_credits_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
diff --git a/arch/mips/include/asm/octeon/cvmx-pescx-defs.h b/arch/mips/include/asm/octeon/cvmx-pescx-defs.h
index 58f27d4..0aaa881 100644
--- a/arch/mips/include/asm/octeon/cvmx-pescx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pescx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-pexp-defs.h b/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
index f9eede7..f0ffd92 100644
--- a/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pexp-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-pip-defs.h b/arch/mips/include/asm/octeon/cvmx-pip-defs.h
index e50242c..bd5437f 100644
--- a/arch/mips/include/asm/octeon/cvmx-pip-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pip-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1117,6 +1117,7 @@ union cvmx_pip_alt_skip_cfgx {
 	struct cvmx_pip_alt_skip_cfgx_s       cn66xx;
 	struct cvmx_pip_alt_skip_cfgx_s       cn68xx;
 	struct cvmx_pip_alt_skip_cfgx_s       cn70xx;
+	struct cvmx_pip_alt_skip_cfgx_s       cn70xxp1;
 	struct cvmx_pip_alt_skip_cfgx_s       cnf71xx;
 };
 typedef union cvmx_pip_alt_skip_cfgx cvmx_pip_alt_skip_cfgx_t;
@@ -1164,6 +1165,7 @@ union cvmx_pip_bck_prs {
 	struct cvmx_pip_bck_prs_s             cn68xx;
 	struct cvmx_pip_bck_prs_s             cn68xxp1;
 	struct cvmx_pip_bck_prs_s             cn70xx;
+	struct cvmx_pip_bck_prs_s             cn70xxp1;
 	struct cvmx_pip_bck_prs_s             cnf71xx;
 };
 typedef union cvmx_pip_bck_prs cvmx_pip_bck_prs_t;
@@ -1235,6 +1237,7 @@ union cvmx_pip_bist_status {
 	struct cvmx_pip_bist_status_s         cn68xx;
 	struct cvmx_pip_bist_status_cn61xx    cn68xxp1;
 	struct cvmx_pip_bist_status_cn61xx    cn70xx;
+	struct cvmx_pip_bist_status_cn61xx    cn70xxp1;
 	struct cvmx_pip_bist_status_cn61xx    cnf71xx;
 };
 typedef union cvmx_pip_bist_status cvmx_pip_bist_status_t;
@@ -1274,6 +1277,7 @@ union cvmx_pip_bsel_ext_cfgx {
 	struct cvmx_pip_bsel_ext_cfgx_s       cn61xx;
 	struct cvmx_pip_bsel_ext_cfgx_s       cn68xx;
 	struct cvmx_pip_bsel_ext_cfgx_s       cn70xx;
+	struct cvmx_pip_bsel_ext_cfgx_s       cn70xxp1;
 	struct cvmx_pip_bsel_ext_cfgx_s       cnf71xx;
 };
 typedef union cvmx_pip_bsel_ext_cfgx cvmx_pip_bsel_ext_cfgx_t;
@@ -1342,6 +1346,7 @@ union cvmx_pip_bsel_ext_posx {
 	struct cvmx_pip_bsel_ext_posx_s       cn61xx;
 	struct cvmx_pip_bsel_ext_posx_s       cn68xx;
 	struct cvmx_pip_bsel_ext_posx_s       cn70xx;
+	struct cvmx_pip_bsel_ext_posx_s       cn70xxp1;
 	struct cvmx_pip_bsel_ext_posx_s       cnf71xx;
 };
 typedef union cvmx_pip_bsel_ext_posx cvmx_pip_bsel_ext_posx_t;
@@ -1414,6 +1419,7 @@ union cvmx_pip_bsel_tbl_entx {
 	} cn61xx;
 	struct cvmx_pip_bsel_tbl_entx_s       cn68xx;
 	struct cvmx_pip_bsel_tbl_entx_cn61xx  cn70xx;
+	struct cvmx_pip_bsel_tbl_entx_cn61xx  cn70xxp1;
 	struct cvmx_pip_bsel_tbl_entx_cn61xx  cnf71xx;
 };
 typedef union cvmx_pip_bsel_tbl_entx cvmx_pip_bsel_tbl_entx_t;
@@ -1441,6 +1447,7 @@ union cvmx_pip_clken {
 	struct cvmx_pip_clken_s               cn68xx;
 	struct cvmx_pip_clken_s               cn68xxp1;
 	struct cvmx_pip_clken_s               cn70xx;
+	struct cvmx_pip_clken_s               cn70xxp1;
 	struct cvmx_pip_clken_s               cnf71xx;
 };
 typedef union cvmx_pip_clken cvmx_pip_clken_t;
@@ -1568,6 +1575,7 @@ union cvmx_pip_dec_ipsecx {
 	struct cvmx_pip_dec_ipsecx_s          cn68xx;
 	struct cvmx_pip_dec_ipsecx_s          cn68xxp1;
 	struct cvmx_pip_dec_ipsecx_s          cn70xx;
+	struct cvmx_pip_dec_ipsecx_s          cn70xxp1;
 	struct cvmx_pip_dec_ipsecx_s          cnf71xx;
 };
 typedef union cvmx_pip_dec_ipsecx cvmx_pip_dec_ipsecx_t;
@@ -1625,6 +1633,7 @@ union cvmx_pip_dsa_src_grp {
 	struct cvmx_pip_dsa_src_grp_s         cn68xx;
 	struct cvmx_pip_dsa_src_grp_s         cn68xxp1;
 	struct cvmx_pip_dsa_src_grp_s         cn70xx;
+	struct cvmx_pip_dsa_src_grp_s         cn70xxp1;
 	struct cvmx_pip_dsa_src_grp_s         cnf71xx;
 };
 typedef union cvmx_pip_dsa_src_grp cvmx_pip_dsa_src_grp_t;
@@ -1682,6 +1691,7 @@ union cvmx_pip_dsa_vid_grp {
 	struct cvmx_pip_dsa_vid_grp_s         cn68xx;
 	struct cvmx_pip_dsa_vid_grp_s         cn68xxp1;
 	struct cvmx_pip_dsa_vid_grp_s         cn70xx;
+	struct cvmx_pip_dsa_vid_grp_s         cn70xxp1;
 	struct cvmx_pip_dsa_vid_grp_s         cnf71xx;
 };
 typedef union cvmx_pip_dsa_vid_grp cvmx_pip_dsa_vid_grp_t;
@@ -1741,6 +1751,7 @@ union cvmx_pip_frm_len_chkx {
 	struct cvmx_pip_frm_len_chkx_s        cn68xx;
 	struct cvmx_pip_frm_len_chkx_s        cn68xxp1;
 	struct cvmx_pip_frm_len_chkx_s        cn70xx;
+	struct cvmx_pip_frm_len_chkx_s        cn70xxp1;
 	struct cvmx_pip_frm_len_chkx_s        cnf71xx;
 };
 typedef union cvmx_pip_frm_len_chkx cvmx_pip_frm_len_chkx_t;
@@ -1803,6 +1814,7 @@ union cvmx_pip_gbl_cfg {
 	struct cvmx_pip_gbl_cfg_s             cn68xx;
 	struct cvmx_pip_gbl_cfg_s             cn68xxp1;
 	struct cvmx_pip_gbl_cfg_s             cn70xx;
+	struct cvmx_pip_gbl_cfg_s             cn70xxp1;
 	struct cvmx_pip_gbl_cfg_s             cnf71xx;
 };
 typedef union cvmx_pip_gbl_cfg cvmx_pip_gbl_cfg_t;
@@ -2257,6 +2269,7 @@ union cvmx_pip_gbl_ctl {
 #endif
 	} cn68xxp1;
 	struct cvmx_pip_gbl_ctl_cn61xx        cn70xx;
+	struct cvmx_pip_gbl_ctl_cn61xx        cn70xxp1;
 	struct cvmx_pip_gbl_ctl_cn61xx        cnf71xx;
 };
 typedef union cvmx_pip_gbl_ctl cvmx_pip_gbl_ctl_t;
@@ -2303,6 +2316,7 @@ union cvmx_pip_hg_pri_qos {
 	struct cvmx_pip_hg_pri_qos_s          cn63xxp1;
 	struct cvmx_pip_hg_pri_qos_s          cn66xx;
 	struct cvmx_pip_hg_pri_qos_s          cn70xx;
+	struct cvmx_pip_hg_pri_qos_s          cn70xxp1;
 	struct cvmx_pip_hg_pri_qos_s          cnf71xx;
 };
 typedef union cvmx_pip_hg_pri_qos cvmx_pip_hg_pri_qos_t;
@@ -2517,6 +2531,7 @@ union cvmx_pip_int_en {
 	struct cvmx_pip_int_en_s              cn68xx;
 	struct cvmx_pip_int_en_s              cn68xxp1;
 	struct cvmx_pip_int_en_s              cn70xx;
+	struct cvmx_pip_int_en_s              cn70xxp1;
 	struct cvmx_pip_int_en_s              cnf71xx;
 };
 typedef union cvmx_pip_int_en cvmx_pip_int_en_t;
@@ -2751,6 +2766,7 @@ union cvmx_pip_int_reg {
 	struct cvmx_pip_int_reg_s             cn68xx;
 	struct cvmx_pip_int_reg_s             cn68xxp1;
 	struct cvmx_pip_int_reg_s             cn70xx;
+	struct cvmx_pip_int_reg_s             cn70xxp1;
 	struct cvmx_pip_int_reg_s             cnf71xx;
 };
 typedef union cvmx_pip_int_reg cvmx_pip_int_reg_t;
@@ -2799,6 +2815,7 @@ union cvmx_pip_ip_offset {
 	struct cvmx_pip_ip_offset_s           cn68xx;
 	struct cvmx_pip_ip_offset_s           cn68xxp1;
 	struct cvmx_pip_ip_offset_s           cn70xx;
+	struct cvmx_pip_ip_offset_s           cn70xxp1;
 	struct cvmx_pip_ip_offset_s           cnf71xx;
 };
 typedef union cvmx_pip_ip_offset cvmx_pip_ip_offset_t;
@@ -3562,6 +3579,7 @@ union cvmx_pip_prt_cfgx {
 	} cn68xx;
 	struct cvmx_pip_prt_cfgx_cn68xx       cn68xxp1;
 	struct cvmx_pip_prt_cfgx_cn52xx       cn70xx;
+	struct cvmx_pip_prt_cfgx_cn52xx       cn70xxp1;
 	struct cvmx_pip_prt_cfgx_cn52xx       cnf71xx;
 };
 typedef union cvmx_pip_prt_cfgx cvmx_pip_prt_cfgx_t;
@@ -3705,6 +3723,7 @@ union cvmx_pip_prt_cfgbx {
 #endif
 	} cn68xxp1;
 	struct cvmx_pip_prt_cfgbx_cn61xx      cn70xx;
+	struct cvmx_pip_prt_cfgbx_cn61xx      cn70xxp1;
 	struct cvmx_pip_prt_cfgbx_cn61xx      cnf71xx;
 };
 typedef union cvmx_pip_prt_cfgbx cvmx_pip_prt_cfgbx_t;
@@ -4045,6 +4064,7 @@ union cvmx_pip_prt_tagx {
 	struct cvmx_pip_prt_tagx_s            cn68xx;
 	struct cvmx_pip_prt_tagx_s            cn68xxp1;
 	struct cvmx_pip_prt_tagx_cn50xx       cn70xx;
+	struct cvmx_pip_prt_tagx_cn50xx       cn70xxp1;
 	struct cvmx_pip_prt_tagx_cn50xx       cnf71xx;
 };
 typedef union cvmx_pip_prt_tagx cvmx_pip_prt_tagx_t;
@@ -4082,6 +4102,7 @@ union cvmx_pip_qos_diffx {
 	struct cvmx_pip_qos_diffx_s           cn63xxp1;
 	struct cvmx_pip_qos_diffx_s           cn66xx;
 	struct cvmx_pip_qos_diffx_s           cn70xx;
+	struct cvmx_pip_qos_diffx_s           cn70xxp1;
 	struct cvmx_pip_qos_diffx_s           cnf71xx;
 };
 typedef union cvmx_pip_qos_diffx cvmx_pip_qos_diffx_t;
@@ -4134,6 +4155,7 @@ union cvmx_pip_qos_vlanx {
 	struct cvmx_pip_qos_vlanx_s           cn63xxp1;
 	struct cvmx_pip_qos_vlanx_s           cn66xx;
 	struct cvmx_pip_qos_vlanx_s           cn70xx;
+	struct cvmx_pip_qos_vlanx_s           cn70xxp1;
 	struct cvmx_pip_qos_vlanx_s           cnf71xx;
 };
 typedef union cvmx_pip_qos_vlanx cvmx_pip_qos_vlanx_t;
@@ -4301,6 +4323,7 @@ union cvmx_pip_qos_watchx {
 	uint64_t reserved_48_63               : 16;
 #endif
 	} cn70xx;
+	struct cvmx_pip_qos_watchx_cn70xx     cn70xxp1;
 	struct cvmx_pip_qos_watchx_cn50xx     cnf71xx;
 };
 typedef union cvmx_pip_qos_watchx cvmx_pip_qos_watchx_t;
@@ -4341,6 +4364,7 @@ union cvmx_pip_raw_word {
 	struct cvmx_pip_raw_word_s            cn68xx;
 	struct cvmx_pip_raw_word_s            cn68xxp1;
 	struct cvmx_pip_raw_word_s            cn70xx;
+	struct cvmx_pip_raw_word_s            cn70xxp1;
 	struct cvmx_pip_raw_word_s            cnf71xx;
 };
 typedef union cvmx_pip_raw_word cvmx_pip_raw_word_t;
@@ -4379,6 +4403,7 @@ union cvmx_pip_sft_rst {
 	struct cvmx_pip_sft_rst_s             cn68xx;
 	struct cvmx_pip_sft_rst_s             cn68xxp1;
 	struct cvmx_pip_sft_rst_s             cn70xx;
+	struct cvmx_pip_sft_rst_s             cn70xxp1;
 	struct cvmx_pip_sft_rst_s             cnf71xx;
 };
 typedef union cvmx_pip_sft_rst cvmx_pip_sft_rst_t;
@@ -4480,6 +4505,7 @@ union cvmx_pip_stat0_prtx {
 	struct cvmx_pip_stat0_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat0_prtx_s          cn66xx;
 	struct cvmx_pip_stat0_prtx_s          cn70xx;
+	struct cvmx_pip_stat0_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat0_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat0_prtx cvmx_pip_stat0_prtx_t;
@@ -4556,6 +4582,7 @@ union cvmx_pip_stat10_prtx {
 	struct cvmx_pip_stat10_prtx_s         cn63xxp1;
 	struct cvmx_pip_stat10_prtx_s         cn66xx;
 	struct cvmx_pip_stat10_prtx_s         cn70xx;
+	struct cvmx_pip_stat10_prtx_s         cn70xxp1;
 	struct cvmx_pip_stat10_prtx_s         cnf71xx;
 };
 typedef union cvmx_pip_stat10_prtx cvmx_pip_stat10_prtx_t;
@@ -4644,6 +4671,7 @@ union cvmx_pip_stat11_prtx {
 	struct cvmx_pip_stat11_prtx_s         cn63xxp1;
 	struct cvmx_pip_stat11_prtx_s         cn66xx;
 	struct cvmx_pip_stat11_prtx_s         cn70xx;
+	struct cvmx_pip_stat11_prtx_s         cn70xxp1;
 	struct cvmx_pip_stat11_prtx_s         cnf71xx;
 };
 typedef union cvmx_pip_stat11_prtx cvmx_pip_stat11_prtx_t;
@@ -4703,6 +4731,7 @@ union cvmx_pip_stat1_prtx {
 	struct cvmx_pip_stat1_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat1_prtx_s          cn66xx;
 	struct cvmx_pip_stat1_prtx_s          cn70xx;
+	struct cvmx_pip_stat1_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat1_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat1_prtx cvmx_pip_stat1_prtx_t;
@@ -4764,6 +4793,7 @@ union cvmx_pip_stat2_prtx {
 	struct cvmx_pip_stat2_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat2_prtx_s          cn66xx;
 	struct cvmx_pip_stat2_prtx_s          cn70xx;
+	struct cvmx_pip_stat2_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat2_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat2_prtx cvmx_pip_stat2_prtx_t;
@@ -4835,6 +4865,7 @@ union cvmx_pip_stat3_prtx {
 	struct cvmx_pip_stat3_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat3_prtx_s          cn66xx;
 	struct cvmx_pip_stat3_prtx_s          cn70xx;
+	struct cvmx_pip_stat3_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat3_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat3_prtx cvmx_pip_stat3_prtx_t;
@@ -4894,6 +4925,7 @@ union cvmx_pip_stat4_prtx {
 	struct cvmx_pip_stat4_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat4_prtx_s          cn66xx;
 	struct cvmx_pip_stat4_prtx_s          cn70xx;
+	struct cvmx_pip_stat4_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat4_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat4_prtx cvmx_pip_stat4_prtx_t;
@@ -4953,6 +4985,7 @@ union cvmx_pip_stat5_prtx {
 	struct cvmx_pip_stat5_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat5_prtx_s          cn66xx;
 	struct cvmx_pip_stat5_prtx_s          cn70xx;
+	struct cvmx_pip_stat5_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat5_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat5_prtx cvmx_pip_stat5_prtx_t;
@@ -5012,6 +5045,7 @@ union cvmx_pip_stat6_prtx {
 	struct cvmx_pip_stat6_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat6_prtx_s          cn66xx;
 	struct cvmx_pip_stat6_prtx_s          cn70xx;
+	struct cvmx_pip_stat6_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat6_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat6_prtx cvmx_pip_stat6_prtx_t;
@@ -5075,6 +5109,7 @@ union cvmx_pip_stat7_prtx {
 	struct cvmx_pip_stat7_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat7_prtx_s          cn66xx;
 	struct cvmx_pip_stat7_prtx_s          cn70xx;
+	struct cvmx_pip_stat7_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat7_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat7_prtx cvmx_pip_stat7_prtx_t;
@@ -5138,6 +5173,7 @@ union cvmx_pip_stat8_prtx {
 	struct cvmx_pip_stat8_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat8_prtx_s          cn66xx;
 	struct cvmx_pip_stat8_prtx_s          cn70xx;
+	struct cvmx_pip_stat8_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat8_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat8_prtx cvmx_pip_stat8_prtx_t;
@@ -5202,6 +5238,7 @@ union cvmx_pip_stat9_prtx {
 	struct cvmx_pip_stat9_prtx_s          cn63xxp1;
 	struct cvmx_pip_stat9_prtx_s          cn66xx;
 	struct cvmx_pip_stat9_prtx_s          cn70xx;
+	struct cvmx_pip_stat9_prtx_s          cn70xxp1;
 	struct cvmx_pip_stat9_prtx_s          cnf71xx;
 };
 typedef union cvmx_pip_stat9_prtx cvmx_pip_stat9_prtx_t;
@@ -5261,6 +5298,7 @@ union cvmx_pip_stat_ctl {
 	struct cvmx_pip_stat_ctl_s            cn68xx;
 	struct cvmx_pip_stat_ctl_s            cn68xxp1;
 	struct cvmx_pip_stat_ctl_cn30xx       cn70xx;
+	struct cvmx_pip_stat_ctl_cn30xx       cn70xxp1;
 	struct cvmx_pip_stat_ctl_cn30xx       cnf71xx;
 };
 typedef union cvmx_pip_stat_ctl cvmx_pip_stat_ctl_t;
@@ -5302,6 +5340,7 @@ union cvmx_pip_stat_inb_errsx {
 	struct cvmx_pip_stat_inb_errsx_s      cn63xxp1;
 	struct cvmx_pip_stat_inb_errsx_s      cn66xx;
 	struct cvmx_pip_stat_inb_errsx_s      cn70xx;
+	struct cvmx_pip_stat_inb_errsx_s      cn70xxp1;
 	struct cvmx_pip_stat_inb_errsx_s      cnf71xx;
 };
 typedef union cvmx_pip_stat_inb_errsx cvmx_pip_stat_inb_errsx_t;
@@ -5372,6 +5411,7 @@ union cvmx_pip_stat_inb_octsx {
 	struct cvmx_pip_stat_inb_octsx_s      cn63xxp1;
 	struct cvmx_pip_stat_inb_octsx_s      cn66xx;
 	struct cvmx_pip_stat_inb_octsx_s      cn70xx;
+	struct cvmx_pip_stat_inb_octsx_s      cn70xxp1;
 	struct cvmx_pip_stat_inb_octsx_s      cnf71xx;
 };
 typedef union cvmx_pip_stat_inb_octsx cvmx_pip_stat_inb_octsx_t;
@@ -5442,6 +5482,7 @@ union cvmx_pip_stat_inb_pktsx {
 	struct cvmx_pip_stat_inb_pktsx_s      cn63xxp1;
 	struct cvmx_pip_stat_inb_pktsx_s      cn66xx;
 	struct cvmx_pip_stat_inb_pktsx_s      cn70xx;
+	struct cvmx_pip_stat_inb_pktsx_s      cn70xxp1;
 	struct cvmx_pip_stat_inb_pktsx_s      cnf71xx;
 };
 typedef union cvmx_pip_stat_inb_pktsx cvmx_pip_stat_inb_pktsx_t;
@@ -5539,6 +5580,7 @@ union cvmx_pip_tag_incx {
 	struct cvmx_pip_tag_incx_s            cn68xx;
 	struct cvmx_pip_tag_incx_s            cn68xxp1;
 	struct cvmx_pip_tag_incx_s            cn70xx;
+	struct cvmx_pip_tag_incx_s            cn70xxp1;
 	struct cvmx_pip_tag_incx_s            cnf71xx;
 };
 typedef union cvmx_pip_tag_incx cvmx_pip_tag_incx_t;
@@ -5580,6 +5622,7 @@ union cvmx_pip_tag_mask {
 	struct cvmx_pip_tag_mask_s            cn68xx;
 	struct cvmx_pip_tag_mask_s            cn68xxp1;
 	struct cvmx_pip_tag_mask_s            cn70xx;
+	struct cvmx_pip_tag_mask_s            cn70xxp1;
 	struct cvmx_pip_tag_mask_s            cnf71xx;
 };
 typedef union cvmx_pip_tag_mask cvmx_pip_tag_mask_t;
@@ -5621,6 +5664,7 @@ union cvmx_pip_tag_secret {
 	struct cvmx_pip_tag_secret_s          cn68xx;
 	struct cvmx_pip_tag_secret_s          cn68xxp1;
 	struct cvmx_pip_tag_secret_s          cn70xx;
+	struct cvmx_pip_tag_secret_s          cn70xxp1;
 	struct cvmx_pip_tag_secret_s          cnf71xx;
 };
 typedef union cvmx_pip_tag_secret cvmx_pip_tag_secret_t;
@@ -5662,6 +5706,7 @@ union cvmx_pip_todo_entry {
 	struct cvmx_pip_todo_entry_s          cn68xx;
 	struct cvmx_pip_todo_entry_s          cn68xxp1;
 	struct cvmx_pip_todo_entry_s          cn70xx;
+	struct cvmx_pip_todo_entry_s          cn70xxp1;
 	struct cvmx_pip_todo_entry_s          cnf71xx;
 };
 typedef union cvmx_pip_todo_entry cvmx_pip_todo_entry_t;
@@ -5693,6 +5738,7 @@ union cvmx_pip_vlan_etypesx {
 	struct cvmx_pip_vlan_etypesx_s        cn66xx;
 	struct cvmx_pip_vlan_etypesx_s        cn68xx;
 	struct cvmx_pip_vlan_etypesx_s        cn70xx;
+	struct cvmx_pip_vlan_etypesx_s        cn70xxp1;
 	struct cvmx_pip_vlan_etypesx_s        cnf71xx;
 };
 typedef union cvmx_pip_vlan_etypesx cvmx_pip_vlan_etypesx_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-pip.h b/arch/mips/include/asm/octeon/cvmx-pip.h
index dd1a6d8..6805d28 100644
--- a/arch/mips/include/asm/octeon/cvmx-pip.h
+++ b/arch/mips/include/asm/octeon/cvmx-pip.h
@@ -42,7 +42,7 @@
  *
  * Interface to the hardware Packet Input Processing unit.
  *
- * <hr>$Revision: 95258 $<hr>
+ * <hr>$Revision: 96703 $<hr>
  */
 
 #ifndef __CVMX_PIP_H__
@@ -290,18 +290,17 @@ typedef union {
 /**
  * Configure an ethernet input port
  *
- * @param port_num Port number to configure
+ * @param ipd_port Port number to configure
  * @param port_cfg Port hardware configuration
  * @param port_tag_cfg
  *                 Port POW tagging configuration
  */
-static inline void cvmx_pip_config_port(uint64_t port_num, cvmx_pip_prt_cfgx_t port_cfg, cvmx_pip_prt_tagx_t port_tag_cfg)
+static inline void cvmx_pip_config_port(uint64_t ipd_port, cvmx_pip_prt_cfgx_t port_cfg, cvmx_pip_prt_tagx_t port_tag_cfg)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		int node = cvmx_get_node_num();
 		struct cvmx_pki_port_config pki_prt_cfg;
 
-		cvmx_pki_get_port_config(node, port_num, &pki_prt_cfg);
+		cvmx_pki_get_port_config(ipd_port, &pki_prt_cfg);
 		if (port_cfg.s.ih_pri || port_cfg.s.pad_len || port_cfg.s.vlan_len)
 			cvmx_dprintf("Warning: 78xx: use different config for this option\n");
 		pki_prt_cfg.style_cfg.parm_cfg.minmax_sel = port_cfg.s.len_chk_sel;
@@ -339,20 +338,20 @@ static inline void cvmx_pip_config_port(uint64_t port_num, cvmx_pip_prt_cfgx_t p
 			pki_prt_cfg.pkind_cfg.initial_parse_mode = CVMX_PKI_PARSE_NOTHING;
 
 		/* This is only for backward compatibility, not all the parameters are supported in 78xx */
-		cvmx_pki_config_port(node, port_num, &pki_prt_cfg);
+		cvmx_pki_config_port(ipd_port, &pki_prt_cfg);
 	}
 
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		int interface, index, pknd;
 
-		interface = cvmx_helper_get_interface_num(port_num);
-		index = cvmx_helper_get_interface_index_num(port_num);
+		interface = cvmx_helper_get_interface_num(ipd_port);
+		index = cvmx_helper_get_interface_index_num(ipd_port);
 		pknd = cvmx_helper_get_pknd(interface, index);
 
-		port_num = pknd;	/* overload port_num with pknd */
+		ipd_port = pknd;	/* overload port_num with pknd */
 	}
-	cvmx_write_csr(CVMX_PIP_PRT_CFGX(port_num), port_cfg.u64);
-	cvmx_write_csr(CVMX_PIP_PRT_TAGX(port_num), port_tag_cfg.u64);
+	cvmx_write_csr(CVMX_PIP_PRT_CFGX(ipd_port), port_cfg.u64);
+	cvmx_write_csr(CVMX_PIP_PRT_TAGX(ipd_port), port_tag_cfg.u64);
 }
 
 /**
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-defs.h b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
index 7062c55..e56c157 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1484,8 +1484,6 @@ union cvmx_pki_clx_pcamx_actionx {
                                                          For TERMs through Ethertypes only)
                                                          0x7 = Skip further LA-LC parsing; start LD parsing.
                                                          For TERMs through L3FLAGS only)
-                                                         0x3F = Skip further LA-LF parsing; start LG parsing.
-                                                         For TERMs through IL3FLAGS only)
                                                          0x7F = Skip all parsing; no further packet inspection.
                                                          For TERMs through L3FLAGS only)
                                                          For example an Ethertype match action that wishes to resume with additional Ethertype
@@ -1498,8 +1496,9 @@ union cvmx_pki_clx_pcamx_actionx {
                                                          style (may wrap around through 256). See Styles. Must be zero for invalid entries. */
 	uint64_t pf                           : 3;  /**< Parse flag to set. Specifies the parse flag to set when entry matches, see PCAM actions
                                                          may also specify setting one of four user flags in the generated work queue entry,
-                                                         WQE[PF1] through WQE[PF4]. These flags are not used by hardware; they indicate to software
-                                                         that exceptional handling may be required, such as the presence of an encrypted packet.:
+                                                         WQE[PF1] through WQE[PF4]. These flags are not used by hardware; they are intended to
+                                                         indicate to software that exceptional handling may be required, such as the presence of an
+                                                         encrypted packet.:
                                                          0x0 = no change.
                                                          0x1 = Set WQE[PF1].
                                                          0x2 = Set WQE[PF2].
@@ -1850,7 +1849,7 @@ union cvmx_pki_clx_stylex_alg {
 	uint64_t tag_vs1                      : 1;  /**< When VLAN stacking is parsed, include second (network order) VLAN in tuple tag generation. */
 	uint64_t tag_vs0                      : 1;  /**< When VLAN stacking is parsed, include first (network order) VLAN in tuple tag generation. */
 	uint64_t tag_vlan                     : 1;  /**< Reserved. */
-	uint64_t tag_mpls0                    : 1;  /**< When a MPLS label is parsed, include the top label in tag generation. */
+	uint64_t tag_mpls0                    : 1;  /**< Reserved. */
 	uint64_t tag_prt                      : 1;  /**< Include interface port in tag hash. */
 	uint64_t wqe_vs                       : 1;  /**< Which VLAN to put into WQE[VLPTR] when VLAN stacking.
                                                          0 = Use the first (in network order) VLAN or DSA VID.
@@ -3500,7 +3499,7 @@ union cvmx_pki_stylex_tag_mask {
 	uint64_t reserved_16_63               : 48;
 	uint64_t mask                         : 16; /**< When set, each bit excludes corresponding bit of the tuple computed tag from being
                                                          included in the final tag. PKI_CL(0..3)_STYLE(0..63)_CFG2 [TAG_MASKEN] must be set. Does
-                                                         not affect tags from packets with a PKI_INST_HDR_S when PKI_INST_HDR[UTAG] is set */
+                                                         not affect tags from packets with a PKI_INST_HDR_S when PKI_INST_HDR[UTAG] is set. */
 #else
 	uint64_t mask                         : 16;
 	uint64_t reserved_16_63               : 48;
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-resources.h b/arch/mips/include/asm/octeon/cvmx-pki-resources.h
index a1ff50c..e77792c 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-resources.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-resources.h
@@ -64,7 +64,7 @@ extern "C" {
 		 number and in range, it will try to allocate specified style.
  * @return 	 style number on success, -1 on failure.
  */
-int cvmx_pki_alloc_style(int node, int style);
+int cvmx_pki_style_alloc(int node, int style);
 
 /**
  * This function allocates/reserves a cluster group from per node
@@ -74,7 +74,7 @@ int cvmx_pki_alloc_style(int node, int style);
                         allocate any available cluster group.
  * @return 	 	cluster group number or -1 on failure
  */
-int cvmx_pki_alloc_cluster_group(int node, int cl_grp);
+int cvmx_pki_cluster_grp_alloc(int node, int cl_grp);
 
 /**
  * This function allocates/reserves a cluster from per node
@@ -84,7 +84,7 @@ int cvmx_pki_alloc_cluster_group(int node, int cl_grp);
                         allocate any available clusters.
  * @param num_clusters	number of clusters that will be allocated
  */
-int cvmx_pki_alloc_clusters(int node, int num_clusters, uint64_t *cluster_mask);
+int cvmx_pki_cluster_alloc(int node, int num_clusters, uint64_t *cluster_mask);
 
 
 /**
@@ -96,7 +96,7 @@ int cvmx_pki_alloc_clusters(int node, int num_clusters, uint64_t *cluster_mask);
  * @param cluster_mask  mask of clusters from which pcam entry is needed.
  * @return 	 	pcam entry of -1 on failure
  */
-int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_mask);
+int cvmx_pki_pcam_entry_alloc(int node, int index, int bank, uint64_t cluster_mask);
 
 /**
  * This function allocates/reserves QPG table entries per node.
@@ -108,7 +108,7 @@ int cvmx_pki_pcam_alloc_entry(int node, int index, int bank, uint64_t cluster_ma
                         from base offset.
  * @return 	 	qpg table base offset number on success, -1 on failure.
  */
-int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count );
+int cvmx_pki_qpg_entry_alloc(int node, int base_offset, int count);
 
 /**
  * This function frees a style from pool of global styles per node.
@@ -116,7 +116,7 @@ int cvmx_pki_alloc_qpg_entry(int node, int base_offset, int count );
  * @param style	 style to free
  * @return 	 0 on success, -1 on failure.
  */
-int cvmx_pki_free_style(int node, int style);
+int cvmx_pki_style_free(int node, int style);
 
 
 /**
@@ -126,7 +126,7 @@ int cvmx_pki_free_style(int node, int style);
    @param cl_grp	cluster group to free
  * @return 	 	0 on success or -1 on failure
  */
-int cvmx_pki_free_cluster_group(int node, int cl_grp);
+int cvmx_pki_cluster_grp(int node, int cl_grp);
 
 /**
  * This function frees  clusters  from per node
@@ -135,7 +135,7 @@ int cvmx_pki_free_cluster_group(int node, int cl_grp);
  * @param cluster_mask  mask of clusters need freeing
  * @return 	 	0 on success or -1 on failure
  */
-int cvmx_pki_free_clusters(int node, uint64_t cluster_mask);
+int cvmx_pki_cluster_free(int node, uint64_t cluster_mask);
 
 /**
  * This function frees a pcam entry from node
@@ -145,7 +145,13 @@ int cvmx_pki_free_clusters(int node, uint64_t cluster_mask);
  * @param cluster_mask  mask of clusters from which pcam entry is freed.
  * @return 	 	0 on success OR -1 on failure
  */
-int cvmx_pki_pcam_free_entry(int node, int index, int bank, uint64_t cluster_mask);
+int cvmx_pki_pcam_entry_free(int node, int index, int bank, uint64_t cluster_mask);
+
+/**
+ * This function frees all the PKI software resources
+ * (clusters, styles, qpg_entry, pcam_entry etc) for the specified node
+ */
+void __cvmx_pki_global_rsrc_free(int node);
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
diff --git a/arch/mips/include/asm/octeon/cvmx-pki.h b/arch/mips/include/asm/octeon/cvmx-pki.h
index 826333a..b8cd740 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki.h
@@ -68,17 +68,15 @@ extern "C" {
 #define CVMX_PKI_NUM_AURA		(1024)
 #define CVMX_PKI_NUM_BPID		(1024)
 #define CVMX_PKI_NUM_PKIND		(64)
-#define CVMX_PKI_NUM_INTERNAL_STYLES    (256)
-#define CVMX_PKI_NUM_FINAL_STYLES	(64)
+#define CVMX_PKI_NUM_INTERNAL_STYLE     (256)
+#define CVMX_PKI_NUM_FINAL_STYLE 	(64)
 #define CVMX_PKI_NUM_QPG_ENTRY		(2048)
-#define CVMX_PKI_NUM_LTYPES		(32)
-#define CVMX_PKI_NUM_CLUSTERS		(4)
+#define CVMX_PKI_NUM_LTYPE		(32)
+#define CVMX_PKI_NUM_CLUSTER		(4)
 #define CVMX_PKI_NUM_CLUSTER_GROUP      (4)
 #define CVMX_PKI_NUM_PCAM_BANK		(2)
 #define CVMX_PKI_NUM_PCAM_ENTRY		(192)
-#define CVMX_PKI_NUM_QPG_STYLE_INDEX	(8)
 #define CVMX_PKI_NUM_FRAME_CHECK	(2)
-#define CVMX_PKI_NUM_CHANNELS		(4096)
 #define CVMX_PKI_NUM_BPID		(1024)
 #define CVMX_PKI_NUM_SSO_GROUP		(256)
 #define CVMX_PKI_NUM_BELTYPE		(32)
@@ -87,17 +85,12 @@ extern "C" {
 #define CVMX_PKI_CLUSTER_ALL		(0xf)
 
 #ifdef CVMX_SUPPORT_SEPARATE_CLUSTER_CONFIG
-#define CVMX_PKI_TOTAL_PCAM_ENTRY	((CVMX_PKI_NUM_CLUSTERS) * (CVMX_PKI_NUM_PCAM_BANK) *\
+#define CVMX_PKI_TOTAL_PCAM_ENTRY	((CVMX_PKI_NUM_CLUSTER) * (CVMX_PKI_NUM_PCAM_BANK) *\
 						(CVMX_PKI_NUM_PCAM_ENTRY))
 #else
 #define CVMX_PKI_TOTAL_PCAM_ENTRY	(CVMX_PKI_NUM_PCAM_BANK * CVMX_PKI_NUM_PCAM_ENTRY)
 #endif
 
-#define CVMX_PKI_MAX_NAME               (16)
-#define CVMX_PKI_NOT_ASSIGNED		(-88)
-
-
-
 enum cvmx_pki_pkind_parse_mode {
 	CVMX_PKI_PARSE_LA_TO_LG = 0,	/* parse LA(L2) to LG */
 	CVMX_PKI_PARSE_LB_TO_LG = 1,	/* parse LB(custom) to LG */
@@ -241,34 +234,14 @@ struct cvmx_pki_pkind_parse {
 				At most one of FULC_EN, DSA_EN or HG_EN may be set. */
 };
 
-struct cvmx_pki_cluster_grp_config {
-	int grp_num;
-	uint64_t cluster_mask; /* bit mask of cluster assigned to this cluster group */
-};
-
-struct cvmx_pki_sso_grp_config {
-	int sso_grp_num;
-	int priority;
-	int weight;
-	int affinity;
-	uint64_t core_mask;
-	uint8_t core_mask_set;
-};
-
 struct cvmx_pki_pool_config {
 	int pool_num;
 	uint64_t buffer_size;
 	uint64_t buffer_count;
 };
 
-struct cvmx_pki_aura_config {
-	int aura_num;
-	int pool_num;
-	int buffer_count;
-};
-
 struct cvmx_pki_qpg_config {
-	int  base_offset;
+	int  qpg_base;
 	int  port_add;
 	int  aura;
 	int  grp_ok;
@@ -309,7 +282,7 @@ struct cvmx_pki_style_parm {
 	bool qpg_dis_padd;	/**< Disable computing port adder by QPG algorithm. */
 	bool qpg_dis_grp;       /**< Disable computing group by QPG algorithm. */
 	bool qpg_dis_aura;      /**< Disable computing aura by QPG algorithm. */
-	uint8_t qpg_base;	/**< Base index into PKI_QPG_TBL(0..2047)*/
+	uint16_t qpg_base;	/**< Base index into PKI_QPG_TBL(0..2047)*/
 	enum cvmx_pki_qpg_qos	qpg_qos;	/**< Algorithm to select QoS field in QPG calculation */
 	uint8_t			qpg_port_sh;	/**< MSB to take from port number in QPG calculation
 							0 = Exclude port number from QPG.
@@ -414,9 +387,9 @@ struct cvmx_pki_pkind_config {
 
 struct cvmx_pki_port_config {
 	struct cvmx_pki_pkind_config pkind_cfg;		/**< Parameters can be configure per pkind */
-	struct cvmx_pki_style_config style_cfg;           /**< Parameters are configured per style, style is a profile
-						     which can be applied to multiple ports which have same configuration
-						     and packet processing */
+	struct cvmx_pki_style_config style_cfg;		/**< Parameters are configured per style, style is a profile
+							which can be applied to multiple ports which have same configuration
+							and packet processing */
 };
 
 struct cvmx_pki_global_parse {
@@ -904,7 +877,9 @@ void cvmx_pki_disable(int node);
  *                            determine how the incoming packet is processed.
  * @param pkind_cfg	      struct conatining pkind configuration need to be written to hw
  */
-int cvmx_pki_write_pkind(int node, int pkind, struct cvmx_pki_pkind_config *pkind_cfg);
+int cvmx_pki_set_pkind_config(int node, int pkind, struct cvmx_pki_pkind_config *pkind_cfg);
+
+int cvmx_pki_get_pkind_config(int node, int pkind, struct cvmx_pki_pkind_config *pkind_cfg);
 
 /**
  * This function writes/configures parameters associated with tag configuration in hardware.
@@ -923,7 +898,7 @@ void cvmx_pki_write_tag_config(int node, int style, uint64_t cluster_mask,
  * @param cluster_mask	      Mask of clusters to configure the style for.
  * @param style_cfg	      parameters to configure for style passed in struct.
  */
-void cvmx_pki_write_style(int node, uint64_t style, uint64_t cluster_mask,
+void cvmx_pki_set_style_config(int node, uint64_t style, uint64_t cluster_mask,
 			    struct cvmx_pki_style_config *style_cfg);
 
 /**
@@ -1054,11 +1029,12 @@ void cvmx_pki_endis_fcs_check(int node, int pknd, bool fcs_chk, bool fcs_strip);
 void cvmx_pki_set_max_frm_len(int node, int port, uint32_t max_size);
 void cvmx_pki_get_style_config(int node, int style, uint64_t cl_mask,
 			       struct cvmx_pki_style_config *style_cfg);
-void cvmx_pki_config_port(int node, int ipd_port, struct cvmx_pki_port_config *port_cfg);
-void cvmx_pki_get_port_config(int node, int ipd_port, struct cvmx_pki_port_config *port_cfg);
+void cvmx_pki_config_port(int ipd_port, struct cvmx_pki_port_config *port_cfg);
+void cvmx_pki_get_port_config(int ipd_port, struct cvmx_pki_port_config *port_cfg);
 void cvmx_pki_reset(int node);
 int cvmx_pki_get_pkind_style(int node, int pkind);
 void __cvmx_pki_free_ptr(int node);
+void cvmx_pki_show_qpg_entries(int node, uint16_t num_entry);
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
diff --git a/arch/mips/include/asm/octeon/cvmx-pko-defs.h b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
index c5f6238..ca1927e 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -113,10 +113,10 @@ static inline uint64_t CVMX_PKO_DQX_BYTES(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKO_DQX_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000C8ull) + ((offset) & 1023) * 512;
+	return CVMX_ADD_IO_SEG(0x00015400000000D8ull) + ((offset) & 1023) * 512;
 }
 #else
-#define CVMX_PKO_DQX_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000C8ull) + ((offset) & 1023) * 512)
+#define CVMX_PKO_DQX_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000D8ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_DQX_CIR(unsigned long offset)
@@ -135,10 +135,10 @@ static inline uint64_t CVMX_PKO_DQX_DROPPED_BYTES(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKO_DQX_DROPPED_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000D8ull) + ((offset) & 1023) * 512;
+	return CVMX_ADD_IO_SEG(0x00015400000000C8ull) + ((offset) & 1023) * 512;
 }
 #else
-#define CVMX_PKO_DQX_DROPPED_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000D8ull) + ((offset) & 1023) * 512)
+#define CVMX_PKO_DQX_DROPPED_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000C8ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_DQX_DROPPED_PACKETS(unsigned long offset)
@@ -146,10 +146,10 @@ static inline uint64_t CVMX_PKO_DQX_DROPPED_PACKETS(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKO_DQX_DROPPED_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000D0ull) + ((offset) & 1023) * 512;
+	return CVMX_ADD_IO_SEG(0x00015400000000C0ull) + ((offset) & 1023) * 512;
 }
 #else
-#define CVMX_PKO_DQX_DROPPED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000D0ull) + ((offset) & 1023) * 512)
+#define CVMX_PKO_DQX_DROPPED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000C0ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_DQX_FIFO(unsigned long offset)
@@ -168,10 +168,10 @@ static inline uint64_t CVMX_PKO_DQX_PACKETS(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 1023)))))
 		cvmx_warn("CVMX_PKO_DQX_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000C0ull) + ((offset) & 1023) * 512;
+	return CVMX_ADD_IO_SEG(0x00015400000000D0ull) + ((offset) & 1023) * 512;
 }
 #else
-#define CVMX_PKO_DQX_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000C0ull) + ((offset) & 1023) * 512)
+#define CVMX_PKO_DQX_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000D0ull) + ((offset) & 1023) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_DQX_PICK(unsigned long offset)
@@ -399,10 +399,10 @@ static inline uint64_t CVMX_PKO_L1_SQX_DROPPED_BYTES(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PKO_L1_SQX_DROPPED_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000B8ull) + ((offset) & 31) * 512;
+	return CVMX_ADD_IO_SEG(0x0001540000000088ull) + ((offset) & 31) * 512;
 }
 #else
-#define CVMX_PKO_L1_SQX_DROPPED_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000B8ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_L1_SQX_DROPPED_BYTES(offset) (CVMX_ADD_IO_SEG(0x0001540000000088ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_DROPPED_PACKETS(unsigned long offset)
@@ -410,10 +410,10 @@ static inline uint64_t CVMX_PKO_L1_SQX_DROPPED_PACKETS(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PKO_L1_SQX_DROPPED_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000B0ull) + ((offset) & 31) * 512;
+	return CVMX_ADD_IO_SEG(0x0001540000000080ull) + ((offset) & 31) * 512;
 }
 #else
-#define CVMX_PKO_L1_SQX_DROPPED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000B0ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_L1_SQX_DROPPED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000080ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_GREEN(unsigned long offset)
@@ -432,10 +432,10 @@ static inline uint64_t CVMX_PKO_L1_SQX_GREEN_BYTES(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PKO_L1_SQX_GREEN_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000088ull) + ((offset) & 31) * 512;
+	return CVMX_ADD_IO_SEG(0x00015400000000B8ull) + ((offset) & 31) * 512;
 }
 #else
-#define CVMX_PKO_L1_SQX_GREEN_BYTES(offset) (CVMX_ADD_IO_SEG(0x0001540000000088ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_L1_SQX_GREEN_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000B8ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_GREEN_PACKETS(unsigned long offset)
@@ -443,10 +443,10 @@ static inline uint64_t CVMX_PKO_L1_SQX_GREEN_PACKETS(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PKO_L1_SQX_GREEN_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000080ull) + ((offset) & 31) * 512;
+	return CVMX_ADD_IO_SEG(0x00015400000000B0ull) + ((offset) & 31) * 512;
 }
 #else
-#define CVMX_PKO_L1_SQX_GREEN_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000080ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_L1_SQX_GREEN_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000B0ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_LINK(unsigned long offset)
@@ -471,17 +471,6 @@ static inline uint64_t CVMX_PKO_L1_SQX_PICK(unsigned long offset)
 #define CVMX_PKO_L1_SQX_PICK(offset) (CVMX_ADD_IO_SEG(0x0001540000080070ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_PKO_L1_SQX_PIR(unsigned long offset)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
-		cvmx_warn("CVMX_PKO_L1_SQX_PIR(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000020ull) + ((offset) & 31) * 512;
-}
-#else
-#define CVMX_PKO_L1_SQX_PIR(offset) (CVMX_ADD_IO_SEG(0x0001540000000020ull) + ((offset) & 31) * 512)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_RED(unsigned long offset)
 {
 	if (!(
@@ -498,10 +487,10 @@ static inline uint64_t CVMX_PKO_L1_SQX_RED_BYTES(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PKO_L1_SQX_RED_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000A8ull) + ((offset) & 31) * 512;
+	return CVMX_ADD_IO_SEG(0x0001540000000098ull) + ((offset) & 31) * 512;
 }
 #else
-#define CVMX_PKO_L1_SQX_RED_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000A8ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_L1_SQX_RED_BYTES(offset) (CVMX_ADD_IO_SEG(0x0001540000000098ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_RED_PACKETS(unsigned long offset)
@@ -509,10 +498,21 @@ static inline uint64_t CVMX_PKO_L1_SQX_RED_PACKETS(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PKO_L1_SQX_RED_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x00015400000000A0ull) + ((offset) & 31) * 512;
+	return CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512;
+}
+#else
+#define CVMX_PKO_L1_SQX_RED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512)
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+static inline uint64_t CVMX_PKO_L1_SQX_SCHEDULE(unsigned long offset)
+{
+	if (!(
+	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
+		cvmx_warn("CVMX_PKO_L1_SQX_SCHEDULE(%lu) is invalid on this chip\n", offset);
+	return CVMX_ADD_IO_SEG(0x0001540000000008ull) + ((offset) & 31) * 512;
 }
 #else
-#define CVMX_PKO_L1_SQX_RED_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000A0ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_L1_SQX_SCHEDULE(offset) (CVMX_ADD_IO_SEG(0x0001540000000008ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_SHAPE(unsigned long offset)
@@ -575,10 +575,10 @@ static inline uint64_t CVMX_PKO_L1_SQX_YELLOW_BYTES(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PKO_L1_SQX_YELLOW_BYTES(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000098ull) + ((offset) & 31) * 512;
+	return CVMX_ADD_IO_SEG(0x00015400000000A8ull) + ((offset) & 31) * 512;
 }
 #else
-#define CVMX_PKO_L1_SQX_YELLOW_BYTES(offset) (CVMX_ADD_IO_SEG(0x0001540000000098ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_L1_SQX_YELLOW_BYTES(offset) (CVMX_ADD_IO_SEG(0x00015400000000A8ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_PKO_L1_SQX_YELLOW_PACKETS(unsigned long offset)
@@ -586,10 +586,10 @@ static inline uint64_t CVMX_PKO_L1_SQX_YELLOW_PACKETS(unsigned long offset)
 	if (!(
 	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((offset <= 31)))))
 		cvmx_warn("CVMX_PKO_L1_SQX_YELLOW_PACKETS(%lu) is invalid on this chip\n", offset);
-	return CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512;
+	return CVMX_ADD_IO_SEG(0x00015400000000A0ull) + ((offset) & 31) * 512;
 }
 #else
-#define CVMX_PKO_L1_SQX_YELLOW_PACKETS(offset) (CVMX_ADD_IO_SEG(0x0001540000000090ull) + ((offset) & 31) * 512)
+#define CVMX_PKO_L1_SQX_YELLOW_PACKETS(offset) (CVMX_ADD_IO_SEG(0x00015400000000A0ull) + ((offset) & 31) * 512)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_L1_SQ_CSR_BUS_DEBUG CVMX_PKO_L1_SQ_CSR_BUS_DEBUG_FUNC()
@@ -2159,6 +2159,17 @@ static inline uint64_t CVMX_PKO_PEB_MAX_LINK_ERR_INFO_FUNC(void)
 #define CVMX_PKO_PEB_MAX_LINK_ERR_INFO (CVMX_ADD_IO_SEG(0x0001540000900C48ull))
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
+#define CVMX_PKO_PEB_NCB_CFG CVMX_PKO_PEB_NCB_CFG_FUNC()
+static inline uint64_t CVMX_PKO_PEB_NCB_CFG_FUNC(void)
+{
+	if (!(OCTEON_IS_MODEL(OCTEON_CN78XX)))
+		cvmx_warn("CVMX_PKO_PEB_NCB_CFG not supported on this chip\n");
+	return CVMX_ADD_IO_SEG(0x0001540000900308ull);
+}
+#else
+#define CVMX_PKO_PEB_NCB_CFG (CVMX_ADD_IO_SEG(0x0001540000900308ull))
+#endif
+#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 #define CVMX_PKO_PEB_PAD_ERR_INFO CVMX_PKO_PEB_PAD_ERR_INFO_FUNC()
 static inline uint64_t CVMX_PKO_PEB_PAD_ERR_INFO_FUNC(void)
 {
@@ -3087,7 +3098,10 @@ union cvmx_pko_dpfi_fpa_aura {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
 	uint64_t node                         : 2;  /**< Node number of current chip, to ensure that the aura is on the local node. */
-	uint64_t laura                        : 10; /**< Local aura to use for PKO command buffering. Must be on local OCI node. */
+	uint64_t laura                        : 10; /**< Local aura to use for PKO command buffering. Must be on local OCI node.
+                                                         The FPA aura selected by LAURA must select an FPA pool whose
+                                                         FPA_POOL(0..63)_CFG[NAT_ALIGN]=1, and
+                                                         (FPA_POOL(0..63)_CFG[BUF_SIZE] - FPA_POOL(0..63)_CFG[BUF_OFFSET]) >= 4 KB/128. */
 #else
 	uint64_t laura                        : 10;
 	uint64_t node                         : 2;
@@ -3346,7 +3360,7 @@ typedef union cvmx_pko_dqx_pick cvmx_pko_dqx_pick_t;
 /**
  * cvmx_pko_dq#_pir
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
  *
  */
 union cvmx_pko_dqx_pir {
@@ -3448,7 +3462,17 @@ union cvmx_pko_dqx_schedule {
                                                          SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
                                                          PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
                                                          the shaper at the next level. */
-	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
+	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
+                                                         integer).
+                                                         The packet size used in all DWRR calculations is:
+                                                            (PKO_Ln_SQm_SHAPE[LENGTH_DISABLE] ? 0 : (PKO_SEND_HDR_S[TOTAL] + CALCPAD)) +
+                                                            PKO_SEND_EXT_S[SHAPECHG] +
+                                                            PKO_Ln_SQm_SHAPE[ADJUST]
+                                                         where n and m correspond to this PKO_Ln_SQm_SCHEDULE CSR. CALCPAD is zero when
+                                                         PKO_PDM_DQd_MINPAD[MINPAD] is clear or when PKO_PDM_CFG[TOTAL]>=PKO_PDM_CFG[MINLEN],
+                                                         else CALCPAD=PKO_PDM_CFG[MINLEN]-PKO_SEND_HDR_S[TOTAL], where d is the DQ the packet used.
+                                                         PKO_SEND_EXT_S[SHAPECHG] is zero when a PKO_SEND_EXT_S is not present in the send
+                                                         descriptor. */
 #else
 	uint64_t rr_quantum                   : 24;
 	uint64_t prio                         : 4;
@@ -3495,7 +3519,7 @@ typedef union cvmx_pko_dqx_shape cvmx_pko_dqx_shape_t;
 /**
  * cvmx_pko_dq#_shape_state
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SHAPE_STATE.
  *
  */
 union cvmx_pko_dqx_shape_state {
@@ -3536,7 +3560,7 @@ union cvmx_pko_dqx_sw_xoff {
 	uint64_t reserved_4_63                : 60;
 	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
 	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
-                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
                                                          until the path has drained." */
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
@@ -3978,48 +4002,6 @@ union cvmx_pko_l1_sqx_pick {
 typedef union cvmx_pko_l1_sqx_pick cvmx_pko_l1_sqx_pick_t;
 
 /**
- * cvmx_pko_l1_sq#_pir
- *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
- *
- */
-union cvmx_pko_l1_sqx_pir {
-	uint64_t u64;
-	struct cvmx_pko_l1_sqx_pir_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_41_63               : 23;
-	uint64_t burst_exponent               : 4;  /**< Burst exponent. The burst limit is specified as 1.BURST_MANTISSA << BURST_EXPONENT. */
-	uint64_t burst_mantissa               : 8;  /**< Burst mantissa. The burst limit is specified as 1.BURST_MANTISSA << BURST_EXPONENT. */
-	uint64_t reserved_17_28               : 12;
-	uint64_t rate_divider_exponent        : 4;  /**< Rate divider exponent. This 4-bit base-2 exponent is used to divide the credit rate by
-                                                         specifying the number of time-wheel turns required before the accumulator is increased.
-                                                         The rate count = (1 << RATE_DIVIDER_EXPONENT). The supported range for
-                                                         RATE_DIVIDER_EXPONENT is 0 to 12. Programmed values greater than 12 are treated as 12.
-                                                         Note that for the L1-SQs, a time-wheel turn is 96 clocks (SCLK). For the other levels a
-                                                         time-wheel turn is 768 clocks (SCLK).
-                                                         For L1_SQ: RATE = (SCLK_FREQUENCY / 96) * (1.RATE_MANTISSA << RATE_EXPONENT) /
-                                                         (1 <<RATE_DIVIDER_EXPONENT)
-                                                         For L[5:2]_SQ: RATE = (SCLK_FREQUENCY / 768) * (1.RATE_MANTISSA << RATE_EXPONENT) /
-                                                         (1 << RATE_DIVIDER_EXPONENT) */
-	uint64_t rate_exponent                : 4;  /**< Rate exponent. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
-	uint64_t rate_mantissa                : 8;  /**< Rate mantissa. The rate is specified as 1.RATE_MANTISSA << RATE_EXPONENT. */
-	uint64_t enable                       : 1;  /**< Enable. Enables CIR shaping. */
-#else
-	uint64_t enable                       : 1;
-	uint64_t rate_mantissa                : 8;
-	uint64_t rate_exponent                : 4;
-	uint64_t rate_divider_exponent        : 4;
-	uint64_t reserved_17_28               : 12;
-	uint64_t burst_mantissa               : 8;
-	uint64_t burst_exponent               : 4;
-	uint64_t reserved_41_63               : 23;
-#endif
-	} s;
-	struct cvmx_pko_l1_sqx_pir_s          cn78xx;
-};
-typedef union cvmx_pko_l1_sqx_pir cvmx_pko_l1_sqx_pir_t;
-
-/**
  * cvmx_pko_l1_sq#_red
  *
  * This register has the same bit fields as PKO_L1_SQ(0..31)_YELLOW.
@@ -4087,6 +4069,24 @@ union cvmx_pko_l1_sqx_red_packets {
 typedef union cvmx_pko_l1_sqx_red_packets cvmx_pko_l1_sqx_red_packets_t;
 
 /**
+ * cvmx_pko_l1_sq#_schedule
+ */
+union cvmx_pko_l1_sqx_schedule {
+	uint64_t u64;
+	struct cvmx_pko_l1_sqx_schedule_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t dummy                        : 40; /**< Reserved. */
+	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
+#else
+	uint64_t rr_quantum                   : 24;
+	uint64_t dummy                        : 40;
+#endif
+	} s;
+	struct cvmx_pko_l1_sqx_schedule_s     cn78xx;
+};
+typedef union cvmx_pko_l1_sqx_schedule cvmx_pko_l1_sqx_schedule_t;
+
+/**
  * cvmx_pko_l1_sq#_shape
  */
 union cvmx_pko_l1_sqx_shape {
@@ -4115,17 +4115,17 @@ union cvmx_pko_l1_sqx_shape_state {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
 	uint64_t tw_timestamp                 : 6;  /**< Time-wheel timestamp. Debug access to the live time-wheel timestamp. */
-	uint64_t color                        : 2;  /**< Shaper color status. Debug access to the live shaper state.
+	uint64_t reserved_53_53               : 1;
+	uint64_t color                        : 1;  /**< Shaper color status. Debug access to the live shaper state.
                                                          0x0 = Green - operating in 'committed' range
-                                                         0x1 = Yellow - operating in 'excess/peak' range
-                                                         0x2 = Red - operating in 'oversubscribed' range
-                                                         0x3 = Reserved */
-	uint64_t pir_accum                    : 26; /**< Peak information rate accumulator. Debug access to the live PIR accumulator. */
+                                                         0x1 = Red - operating in 'oversubscribed' range or inactive */
+	uint64_t reserved_26_51               : 26;
 	uint64_t cir_accum                    : 26; /**< Committed information rate accumulator. Debug access to the live CIR accumulator. */
 #else
 	uint64_t cir_accum                    : 26;
-	uint64_t pir_accum                    : 26;
-	uint64_t color                        : 2;
+	uint64_t reserved_26_51               : 26;
+	uint64_t color                        : 1;
+	uint64_t reserved_53_53               : 1;
 	uint64_t tw_timestamp                 : 6;
 	uint64_t reserved_60_63               : 4;
 #endif
@@ -4144,7 +4144,7 @@ union cvmx_pko_l1_sqx_sw_xoff {
 	uint64_t reserved_4_63                : 60;
 	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
 	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
-                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
                                                          until the path has drained." */
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
@@ -4455,7 +4455,7 @@ typedef union cvmx_pko_l2_sqx_pick cvmx_pko_l2_sqx_pick_t;
 /**
  * cvmx_pko_l2_sq#_pir
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
  *
  */
 union cvmx_pko_l2_sqx_pir {
@@ -4573,7 +4573,17 @@ union cvmx_pko_l2_sqx_schedule {
                                                          SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
                                                          PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
                                                          the shaper at the next level. */
-	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
+	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
+                                                         integer).
+                                                         The packet size used in all DWRR calculations is:
+                                                            (PKO_Ln_SQm_SHAPE[LENGTH_DISABLE] ? 0 : (PKO_SEND_HDR_S[TOTAL] + CALCPAD)) +
+                                                            PKO_SEND_EXT_S[SHAPECHG] +
+                                                            PKO_Ln_SQm_SHAPE[ADJUST]
+                                                         where n and m correspond to this PKO_Ln_SQm_SCHEDULE CSR. CALCPAD is zero when
+                                                         PKO_PDM_DQd_MINPAD[MINPAD] is clear or when PKO_PDM_CFG[TOTAL]>=PKO_PDM_CFG[MINLEN],
+                                                         else CALCPAD=PKO_PDM_CFG[MINLEN]-PKO_SEND_HDR_S[TOTAL], where d is the DQ the packet used.
+                                                         PKO_SEND_EXT_S[SHAPECHG] is zero when a PKO_SEND_EXT_S is not present in the send
+                                                         descriptor. */
 #else
 	uint64_t rr_quantum                   : 24;
 	uint64_t prio                         : 4;
@@ -4593,7 +4603,7 @@ union cvmx_pko_l2_sqx_shape {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_25_63               : 39;
 	uint64_t length_disable               : 1;  /**< Length disable. Disables the use of packet lengths in shaping calculations such that only
-                                                         the value of PKO_L2_SQ(0..511)_SHAPE[ADJUST]. */
+                                                         the values of PKO_L2_SQ(0..511)_SHAPE[ADJUST] and PKO_SEND_EXT_S[SHAPECHG] are used. */
 	uint64_t reserved_13_23               : 11;
 	uint64_t yellow_disable               : 1;  /**< Disable yellow transitions. Disables green-to-yellow packet color marking transitions when set. */
 	uint64_t red_disable                  : 1;  /**< Disable red transitions. Disables green-to-red and yellow-to-red packet color marking
@@ -4622,9 +4632,6 @@ typedef union cvmx_pko_l2_sqx_shape cvmx_pko_l2_sqx_shape_t;
 
 /**
  * cvmx_pko_l2_sq#_shape_state
- *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
- *
  */
 union cvmx_pko_l2_sqx_shape_state {
 	uint64_t u64;
@@ -4664,7 +4671,7 @@ union cvmx_pko_l2_sqx_sw_xoff {
 	uint64_t reserved_4_63                : 60;
 	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
 	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
-                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
                                                          until the path has drained." */
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
@@ -4952,7 +4959,7 @@ typedef union cvmx_pko_l3_sqx_pick cvmx_pko_l3_sqx_pick_t;
 /**
  * cvmx_pko_l3_sq#_pir
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
  *
  */
 union cvmx_pko_l3_sqx_pir {
@@ -5077,7 +5084,17 @@ union cvmx_pko_l3_sqx_schedule {
                                                          SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
                                                          PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
                                                          the shaper at the next level. */
-	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
+	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
+                                                         integer).
+                                                         The packet size used in all DWRR calculations is:
+                                                            (PKO_Ln_SQm_SHAPE[LENGTH_DISABLE] ? 0 : (PKO_SEND_HDR_S[TOTAL] + CALCPAD)) +
+                                                            PKO_SEND_EXT_S[SHAPECHG] +
+                                                            PKO_Ln_SQm_SHAPE[ADJUST]
+                                                         where n and m correspond to this PKO_Ln_SQm_SCHEDULE CSR. CALCPAD is zero when
+                                                         PKO_PDM_DQd_MINPAD[MINPAD] is clear or when PKO_PDM_CFG[TOTAL]>=PKO_PDM_CFG[MINLEN],
+                                                         else CALCPAD=PKO_PDM_CFG[MINLEN]-PKO_SEND_HDR_S[TOTAL], where d is the DQ the packet used.
+                                                         PKO_SEND_EXT_S[SHAPECHG] is zero when a PKO_SEND_EXT_S is not present in the send
+                                                         descriptor. */
 #else
 	uint64_t rr_quantum                   : 24;
 	uint64_t prio                         : 4;
@@ -5121,7 +5138,7 @@ typedef union cvmx_pko_l3_sqx_shape cvmx_pko_l3_sqx_shape_t;
 /**
  * cvmx_pko_l3_sq#_shape_state
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SHAPE_STATE.
  *
  */
 union cvmx_pko_l3_sqx_shape_state {
@@ -5162,7 +5179,7 @@ union cvmx_pko_l3_sqx_sw_xoff {
 	uint64_t reserved_4_63                : 60;
 	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
 	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
-                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
                                                          until the path has drained." */
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
@@ -5408,7 +5425,7 @@ typedef union cvmx_pko_l4_sqx_pick cvmx_pko_l4_sqx_pick_t;
 /**
  * cvmx_pko_l4_sq#_pir
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
  *
  */
 union cvmx_pko_l4_sqx_pir {
@@ -5530,7 +5547,17 @@ union cvmx_pko_l4_sqx_schedule {
                                                          SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
                                                          PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
                                                          the shaper at the next level. */
-	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
+	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
+                                                         integer).
+                                                         The packet size used in all DWRR calculations is:
+                                                            (PKO_Ln_SQm_SHAPE[LENGTH_DISABLE] ? 0 : (PKO_SEND_HDR_S[TOTAL] + CALCPAD)) +
+                                                            PKO_SEND_EXT_S[SHAPECHG] +
+                                                            PKO_Ln_SQm_SHAPE[ADJUST]
+                                                         where n and m correspond to this PKO_Ln_SQm_SCHEDULE CSR. CALCPAD is zero when
+                                                         PKO_PDM_DQd_MINPAD[MINPAD] is clear or when PKO_PDM_CFG[TOTAL]>=PKO_PDM_CFG[MINLEN],
+                                                         else CALCPAD=PKO_PDM_CFG[MINLEN]-PKO_SEND_HDR_S[TOTAL], where d is the DQ the packet used.
+                                                         PKO_SEND_EXT_S[SHAPECHG] is zero when a PKO_SEND_EXT_S is not present in the send
+                                                         descriptor. */
 #else
 	uint64_t rr_quantum                   : 24;
 	uint64_t prio                         : 4;
@@ -5577,7 +5604,7 @@ typedef union cvmx_pko_l4_sqx_shape cvmx_pko_l4_sqx_shape_t;
 /**
  * cvmx_pko_l4_sq#_shape_state
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SHAPE_STATE.
  *
  */
 union cvmx_pko_l4_sqx_shape_state {
@@ -5618,7 +5645,7 @@ union cvmx_pko_l4_sqx_sw_xoff {
 	uint64_t reserved_4_63                : 60;
 	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
 	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
-                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
                                                          until the path has drained." */
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
@@ -5867,7 +5894,7 @@ typedef union cvmx_pko_l5_sqx_pick cvmx_pko_l5_sqx_pick_t;
 /**
  * cvmx_pko_l5_sq#_pir
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_PIR.
+ * This register has the same bit fields as PKO_L1_SQ(0..31)_CIR.
  *
  */
 union cvmx_pko_l5_sqx_pir {
@@ -5992,7 +6019,17 @@ union cvmx_pko_l5_sqx_schedule {
                                                          SQ is a static queue or not: If PRIO equals PKO_*_SQn_TOPOLOGY[RR_PRIO], where
                                                          PKO_*_TOPOLOGY[PARENT] for this SQ equals n, then this is a round-robin child queue into
                                                          the shaper at the next level. */
-	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned integer). */
+	uint64_t rr_quantum                   : 24; /**< Round-robin (DWRR) quantum. The deficit-weighted round-robin quantum (24-bit unsigned
+                                                         integer).
+                                                         The packet size used in all DWRR calculations is:
+                                                            (PKO_Ln_SQm_SHAPE[LENGTH_DISABLE] ? 0 : (PKO_SEND_HDR_S[TOTAL] + CALCPAD)) +
+                                                            PKO_SEND_EXT_S[SHAPECHG] +
+                                                            PKO_Ln_SQm_SHAPE[ADJUST]
+                                                         where n and m correspond to this PKO_Ln_SQm_SCHEDULE CSR. CALCPAD is zero when
+                                                         PKO_PDM_DQd_MINPAD[MINPAD] is clear or when PKO_PDM_CFG[TOTAL]>=PKO_PDM_CFG[MINLEN],
+                                                         else CALCPAD=PKO_PDM_CFG[MINLEN]-PKO_SEND_HDR_S[TOTAL], where d is the DQ the packet used.
+                                                         PKO_SEND_EXT_S[SHAPECHG] is zero when a PKO_SEND_EXT_S is not present in the send
+                                                         descriptor. */
 #else
 	uint64_t rr_quantum                   : 24;
 	uint64_t prio                         : 4;
@@ -6036,7 +6073,7 @@ typedef union cvmx_pko_l5_sqx_shape cvmx_pko_l5_sqx_shape_t;
 /**
  * cvmx_pko_l5_sq#_shape_state
  *
- * This register has the same bit fields as PKO_L1_SQ(0..31)_SHAPE_STATE.
+ * This register has the same bit fields as PKO_L2_SQ(0..511)_SHAPE_STATE.
  *
  */
 union cvmx_pko_l5_sqx_shape_state {
@@ -6077,7 +6114,7 @@ union cvmx_pko_l5_sqx_sw_xoff {
 	uint64_t reserved_4_63                : 60;
 	uint64_t drain_irq                    : 1;  /**< Drain IRQ. Enables an interrupt that fires when the drain operation has completed. */
 	uint64_t drain_null_link              : 1;  /**< "Drain null link. Conditions the drain path to drain through the null link (i.e. link
-                                                         \#28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
+                                                         28). As such, channel credits, HW_XOFF, and shaping are disabled on the draining path
                                                          until the path has drained." */
 	uint64_t drain                        : 1;  /**< Drain. This control activates a drain path through the PSE that starts at this node and
                                                          ends at the SQ1 level. The drain path is prioritized over other paths through PSE and can
@@ -6488,6 +6525,7 @@ union cvmx_pko_mem_count0 {
 	struct cvmx_pko_mem_count0_s          cn68xx;
 	struct cvmx_pko_mem_count0_s          cn68xxp1;
 	struct cvmx_pko_mem_count0_s          cn70xx;
+	struct cvmx_pko_mem_count0_s          cn70xxp1;
 	struct cvmx_pko_mem_count0_s          cnf71xx;
 };
 typedef union cvmx_pko_mem_count0 cvmx_pko_mem_count0_t;
@@ -6531,6 +6569,7 @@ union cvmx_pko_mem_count1 {
 	struct cvmx_pko_mem_count1_s          cn68xx;
 	struct cvmx_pko_mem_count1_s          cn68xxp1;
 	struct cvmx_pko_mem_count1_s          cn70xx;
+	struct cvmx_pko_mem_count1_s          cn70xxp1;
 	struct cvmx_pko_mem_count1_s          cnf71xx;
 };
 typedef union cvmx_pko_mem_count1 cvmx_pko_mem_count1_t;
@@ -6576,6 +6615,7 @@ union cvmx_pko_mem_debug0 {
 	struct cvmx_pko_mem_debug0_s          cn68xx;
 	struct cvmx_pko_mem_debug0_s          cn68xxp1;
 	struct cvmx_pko_mem_debug0_s          cn70xx;
+	struct cvmx_pko_mem_debug0_s          cn70xxp1;
 	struct cvmx_pko_mem_debug0_s          cnf71xx;
 };
 typedef union cvmx_pko_mem_debug0 cvmx_pko_mem_debug0_t;
@@ -6623,6 +6663,7 @@ union cvmx_pko_mem_debug1 {
 	struct cvmx_pko_mem_debug1_s          cn68xx;
 	struct cvmx_pko_mem_debug1_s          cn68xxp1;
 	struct cvmx_pko_mem_debug1_s          cn70xx;
+	struct cvmx_pko_mem_debug1_s          cn70xxp1;
 	struct cvmx_pko_mem_debug1_s          cnf71xx;
 };
 typedef union cvmx_pko_mem_debug1 cvmx_pko_mem_debug1_t;
@@ -6686,6 +6727,7 @@ union cvmx_pko_mem_debug10 {
 	struct cvmx_pko_mem_debug10_cn50xx    cn68xx;
 	struct cvmx_pko_mem_debug10_cn50xx    cn68xxp1;
 	struct cvmx_pko_mem_debug10_cn50xx    cn70xx;
+	struct cvmx_pko_mem_debug10_cn50xx    cn70xxp1;
 	struct cvmx_pko_mem_debug10_cn50xx    cnf71xx;
 };
 typedef union cvmx_pko_mem_debug10 cvmx_pko_mem_debug10_t;
@@ -6767,6 +6809,7 @@ union cvmx_pko_mem_debug11 {
 	struct cvmx_pko_mem_debug11_cn50xx    cn68xx;
 	struct cvmx_pko_mem_debug11_cn50xx    cn68xxp1;
 	struct cvmx_pko_mem_debug11_cn50xx    cn70xx;
+	struct cvmx_pko_mem_debug11_cn50xx    cn70xxp1;
 	struct cvmx_pko_mem_debug11_cn50xx    cnf71xx;
 };
 typedef union cvmx_pko_mem_debug11 cvmx_pko_mem_debug11_t;
@@ -6830,6 +6873,7 @@ union cvmx_pko_mem_debug12 {
 	} cn68xx;
 	struct cvmx_pko_mem_debug12_cn68xx    cn68xxp1;
 	struct cvmx_pko_mem_debug12_cn50xx    cn70xx;
+	struct cvmx_pko_mem_debug12_cn50xx    cn70xxp1;
 	struct cvmx_pko_mem_debug12_cn50xx    cnf71xx;
 };
 typedef union cvmx_pko_mem_debug12 cvmx_pko_mem_debug12_t;
@@ -6901,6 +6945,7 @@ union cvmx_pko_mem_debug13 {
 	} cn68xx;
 	struct cvmx_pko_mem_debug13_cn68xx    cn68xxp1;
 	struct cvmx_pko_mem_debug13_cn50xx    cn70xx;
+	struct cvmx_pko_mem_debug13_cn50xx    cn70xxp1;
 	struct cvmx_pko_mem_debug13_cn50xx    cnf71xx;
 };
 typedef union cvmx_pko_mem_debug13 cvmx_pko_mem_debug13_t;
@@ -6949,6 +6994,7 @@ union cvmx_pko_mem_debug14 {
 	struct cvmx_pko_mem_debug14_cn52xx    cn63xxp1;
 	struct cvmx_pko_mem_debug14_cn52xx    cn66xx;
 	struct cvmx_pko_mem_debug14_cn52xx    cn70xx;
+	struct cvmx_pko_mem_debug14_cn52xx    cn70xxp1;
 	struct cvmx_pko_mem_debug14_cn52xx    cnf71xx;
 };
 typedef union cvmx_pko_mem_debug14 cvmx_pko_mem_debug14_t;
@@ -6996,6 +7042,7 @@ union cvmx_pko_mem_debug2 {
 	struct cvmx_pko_mem_debug2_s          cn68xx;
 	struct cvmx_pko_mem_debug2_s          cn68xxp1;
 	struct cvmx_pko_mem_debug2_s          cn70xx;
+	struct cvmx_pko_mem_debug2_s          cn70xxp1;
 	struct cvmx_pko_mem_debug2_s          cnf71xx;
 };
 typedef union cvmx_pko_mem_debug2 cvmx_pko_mem_debug2_t;
@@ -7055,6 +7102,7 @@ union cvmx_pko_mem_debug3 {
 	struct cvmx_pko_mem_debug3_cn50xx     cn68xx;
 	struct cvmx_pko_mem_debug3_cn50xx     cn68xxp1;
 	struct cvmx_pko_mem_debug3_cn50xx     cn70xx;
+	struct cvmx_pko_mem_debug3_cn50xx     cn70xxp1;
 	struct cvmx_pko_mem_debug3_cn50xx     cnf71xx;
 };
 typedef union cvmx_pko_mem_debug3 cvmx_pko_mem_debug3_t;
@@ -7198,6 +7246,7 @@ union cvmx_pko_mem_debug4 {
 	} cn68xx;
 	struct cvmx_pko_mem_debug4_cn68xx     cn68xxp1;
 	struct cvmx_pko_mem_debug4_cn52xx     cn70xx;
+	struct cvmx_pko_mem_debug4_cn52xx     cn70xxp1;
 	struct cvmx_pko_mem_debug4_cn52xx     cnf71xx;
 };
 typedef union cvmx_pko_mem_debug4 cvmx_pko_mem_debug4_t;
@@ -7335,6 +7384,7 @@ union cvmx_pko_mem_debug5 {
 	} cn68xx;
 	struct cvmx_pko_mem_debug5_cn68xx     cn68xxp1;
 	struct cvmx_pko_mem_debug5_cn61xx     cn70xx;
+	struct cvmx_pko_mem_debug5_cn61xx     cn70xxp1;
 	struct cvmx_pko_mem_debug5_cn61xx     cnf71xx;
 };
 typedef union cvmx_pko_mem_debug5 cvmx_pko_mem_debug5_t;
@@ -7492,6 +7542,7 @@ union cvmx_pko_mem_debug6 {
 	uint64_t reserved_37_63               : 27;
 #endif
 	} cn70xx;
+	struct cvmx_pko_mem_debug6_cn70xx     cn70xxp1;
 	struct cvmx_pko_mem_debug6_cn52xx     cnf71xx;
 };
 typedef union cvmx_pko_mem_debug6 cvmx_pko_mem_debug6_t;
@@ -7571,6 +7622,7 @@ union cvmx_pko_mem_debug7 {
 	} cn68xx;
 	struct cvmx_pko_mem_debug7_cn68xx     cn68xxp1;
 	struct cvmx_pko_mem_debug7_cn50xx     cn70xx;
+	struct cvmx_pko_mem_debug7_cn50xx     cn70xxp1;
 	struct cvmx_pko_mem_debug7_cn50xx     cnf71xx;
 };
 typedef union cvmx_pko_mem_debug7 cvmx_pko_mem_debug7_t;
@@ -7720,6 +7772,7 @@ union cvmx_pko_mem_debug8 {
 	} cn68xx;
 	struct cvmx_pko_mem_debug8_cn68xx     cn68xxp1;
 	struct cvmx_pko_mem_debug8_cn61xx     cn70xx;
+	struct cvmx_pko_mem_debug8_cn61xx     cn70xxp1;
 	struct cvmx_pko_mem_debug8_cn61xx     cnf71xx;
 };
 typedef union cvmx_pko_mem_debug8 cvmx_pko_mem_debug8_t;
@@ -7809,6 +7862,7 @@ union cvmx_pko_mem_debug9 {
 	struct cvmx_pko_mem_debug9_cn50xx     cn68xx;
 	struct cvmx_pko_mem_debug9_cn50xx     cn68xxp1;
 	struct cvmx_pko_mem_debug9_cn50xx     cn70xx;
+	struct cvmx_pko_mem_debug9_cn50xx     cn70xxp1;
 	struct cvmx_pko_mem_debug9_cn50xx     cnf71xx;
 };
 typedef union cvmx_pko_mem_debug9 cvmx_pko_mem_debug9_t;
@@ -8110,6 +8164,7 @@ union cvmx_pko_mem_port_ptrs {
 	struct cvmx_pko_mem_port_ptrs_s       cn63xxp1;
 	struct cvmx_pko_mem_port_ptrs_s       cn66xx;
 	struct cvmx_pko_mem_port_ptrs_s       cn70xx;
+	struct cvmx_pko_mem_port_ptrs_s       cn70xxp1;
 	struct cvmx_pko_mem_port_ptrs_s       cnf71xx;
 };
 typedef union cvmx_pko_mem_port_ptrs cvmx_pko_mem_port_ptrs_t;
@@ -8154,6 +8209,7 @@ union cvmx_pko_mem_port_qos {
 	struct cvmx_pko_mem_port_qos_s        cn63xxp1;
 	struct cvmx_pko_mem_port_qos_s        cn66xx;
 	struct cvmx_pko_mem_port_qos_s        cn70xx;
+	struct cvmx_pko_mem_port_qos_s        cn70xxp1;
 	struct cvmx_pko_mem_port_qos_s        cnf71xx;
 };
 typedef union cvmx_pko_mem_port_qos cvmx_pko_mem_port_qos_t;
@@ -8208,6 +8264,7 @@ union cvmx_pko_mem_port_rate0 {
 	struct cvmx_pko_mem_port_rate0_s      cn68xx;
 	struct cvmx_pko_mem_port_rate0_s      cn68xxp1;
 	struct cvmx_pko_mem_port_rate0_cn52xx cn70xx;
+	struct cvmx_pko_mem_port_rate0_cn52xx cn70xxp1;
 	struct cvmx_pko_mem_port_rate0_cn52xx cnf71xx;
 };
 typedef union cvmx_pko_mem_port_rate0 cvmx_pko_mem_port_rate0_t;
@@ -8260,6 +8317,7 @@ union cvmx_pko_mem_port_rate1 {
 	struct cvmx_pko_mem_port_rate1_s      cn68xx;
 	struct cvmx_pko_mem_port_rate1_s      cn68xxp1;
 	struct cvmx_pko_mem_port_rate1_cn52xx cn70xx;
+	struct cvmx_pko_mem_port_rate1_cn52xx cn70xxp1;
 	struct cvmx_pko_mem_port_rate1_cn52xx cnf71xx;
 };
 typedef union cvmx_pko_mem_port_rate1 cvmx_pko_mem_port_rate1_t;
@@ -8323,6 +8381,7 @@ union cvmx_pko_mem_queue_ptrs {
 	struct cvmx_pko_mem_queue_ptrs_s      cn63xxp1;
 	struct cvmx_pko_mem_queue_ptrs_s      cn66xx;
 	struct cvmx_pko_mem_queue_ptrs_s      cn70xx;
+	struct cvmx_pko_mem_queue_ptrs_s      cn70xxp1;
 	struct cvmx_pko_mem_queue_ptrs_s      cnf71xx;
 };
 typedef union cvmx_pko_mem_queue_ptrs cvmx_pko_mem_queue_ptrs_t;
@@ -8373,6 +8432,7 @@ union cvmx_pko_mem_queue_qos {
 	struct cvmx_pko_mem_queue_qos_s       cn63xxp1;
 	struct cvmx_pko_mem_queue_qos_s       cn66xx;
 	struct cvmx_pko_mem_queue_qos_s       cn70xx;
+	struct cvmx_pko_mem_queue_qos_s       cn70xxp1;
 	struct cvmx_pko_mem_queue_qos_s       cnf71xx;
 };
 typedef union cvmx_pko_mem_queue_qos cvmx_pko_mem_queue_qos_t;
@@ -9881,8 +9941,8 @@ union cvmx_pko_pdm_sts {
 	uint64_t cp_sendpkt_err_drop          : 1;  /**< Dropped a send-packet in PDM/CP due to a rule violation. The error code is captured in
                                                          PKO_PDM_STS[CP_SENDPKT_ERR_DROP_CODE]. Throws PKO_INTSN_E::PKO_CP_SENDPKT_ERR_DROP. */
 	uint64_t reserved_1_2                 : 2;
-	uint64_t desc_crc_err                 : 1;  /**< CRC error occurred in a descriptor. (State may have been corrupted.) INTERNAL: Note that
-                                                         this is a pass 2 feature. Throws PKO_INTSN_E::PKO_DESC_CRC_ERR. */
+	uint64_t desc_crc_err                 : 1;  /**< CRC error occurred in a descriptor. (State may have been corrupted.) Throws
+                                                         PKO_INTSN_E::PKO_DESC_CRC_ERR. INTERNAL: Note that this is a pass 2 feature. */
 #else
 	uint64_t desc_crc_err                 : 1;
 	uint64_t reserved_1_2                 : 2;
@@ -9948,9 +10008,9 @@ union cvmx_pko_peb_bist_status {
 	uint64_t send_mem_fifo                : 1;  /**< SEND_MEM_FIFO RAM BIST status. */
 	uint64_t pkt_mrk_ram                  : 1;  /**< PKT_MRK RAM BIST status. */
 	uint64_t peb_st_inf_ram               : 1;  /**< PEB_ST_INF RAM BIST status. */
-	uint64_t peb_sm_jmp_ram               : 1;  /**< PEB_SM_JMP RAM BIST status. */
+	uint64_t reserved_0_0                 : 1;
 #else
-	uint64_t peb_sm_jmp_ram               : 1;
+	uint64_t reserved_0_0                 : 1;
 	uint64_t peb_st_inf_ram               : 1;
 	uint64_t pkt_mrk_ram                  : 1;
 	uint64_t send_mem_fifo                : 1;
@@ -10000,8 +10060,7 @@ union cvmx_pko_peb_ecc_ctl0 {
 	uint64_t pdm_resp_buf_ram_cdis        : 1;  /**< PDM_RESP_BUF_RAM ECC correction disable. */
 	uint64_t pdm_pse_buf_ram_flip         : 2;  /**< PDM_PSE_BUF_RAM flip syndrome bits on write. */
 	uint64_t pdm_pse_buf_ram_cdis         : 1;  /**< PDM_PSE_BUF_RAM ECC correction disable. */
-	uint64_t peb_sm_jmp_ram_flip          : 2;  /**< PEB_SM_JMP_RAM flip syndrome bits on write. */
-	uint64_t peb_sm_jmp_ram_cdis          : 1;  /**< PEB_SM_JMP_RAM ECC correction disable. */
+	uint64_t reserved_46_48               : 3;
 	uint64_t peb_st_inf_ram_flip          : 2;  /**< PEB_ST_INF_RAM flip syndrome bits on write. */
 	uint64_t peb_st_inf_ram_cdis          : 1;  /**< PEB_ST_INF_RAM ECC correction disable. */
 	uint64_t pd_bank3_ram_flip            : 2;  /**< PD_BANK3_RAM flip syndrome bits on write. */
@@ -10065,8 +10124,7 @@ union cvmx_pko_peb_ecc_ctl0 {
 	uint64_t pd_bank3_ram_flip            : 2;
 	uint64_t peb_st_inf_ram_cdis          : 1;
 	uint64_t peb_st_inf_ram_flip          : 2;
-	uint64_t peb_sm_jmp_ram_cdis          : 1;
-	uint64_t peb_sm_jmp_ram_flip          : 2;
+	uint64_t reserved_46_48               : 3;
 	uint64_t pdm_pse_buf_ram_cdis         : 1;
 	uint64_t pdm_pse_buf_ram_flip         : 2;
 	uint64_t pdm_resp_buf_ram_cdis        : 1;
@@ -10120,8 +10178,7 @@ union cvmx_pko_peb_ecc_dbe_sts0 {
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i */
 	uint64_t pdm_pse_buf_ram_dbe          : 1;  /**< Double-bit error for PDM_PSE_BUF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i */
-	uint64_t peb_sm_jmp_ram_dbe           : 1;  /**< Double-bit error for PEB_SM_JMP_RAM. INTERNAL: Instances:
-                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i */
+	uint64_t reserved_58_58               : 1;
 	uint64_t peb_st_inf_ram_dbe           : 1;  /**< Double-bit error for PEB_ST_INF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i */
 	uint64_t pd_bank3_ram_dbe             : 1;  /**< Double-bit error for PD_BANK3_RAM. INTERNAL: Instances:
@@ -10173,7 +10230,7 @@ union cvmx_pko_peb_ecc_dbe_sts0 {
 	uint64_t pd_bank2_ram_dbe             : 1;
 	uint64_t pd_bank3_ram_dbe             : 1;
 	uint64_t peb_st_inf_ram_dbe           : 1;
-	uint64_t peb_sm_jmp_ram_dbe           : 1;
+	uint64_t reserved_58_58               : 1;
 	uint64_t pdm_pse_buf_ram_dbe          : 1;
 	uint64_t pdm_resp_buf_ram_dbe         : 1;
 	uint64_t iobp1_fifo_ram_dbe           : 1;
@@ -10200,7 +10257,6 @@ union cvmx_pko_peb_ecc_dbe_sts_cmb0 {
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i
-                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank3_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank0_i
@@ -10244,8 +10300,7 @@ union cvmx_pko_peb_ecc_sbe_sts0 {
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i */
 	uint64_t pdm_pse_buf_ram_sbe          : 1;  /**< Single-bit error for PDM_PSE_BUF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i */
-	uint64_t peb_sm_jmp_ram_sbe           : 1;  /**< Single-bit error for PEB_SM_JMP_RAM. INTERNAL: Instances:
-                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i */
+	uint64_t reserved_58_58               : 1;
 	uint64_t peb_st_inf_ram_sbe           : 1;  /**< Single-bit error for PEB_ST_INF_RAM. INTERNAL: Instances:
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i */
 	uint64_t pd_bank3_ram_sbe             : 1;  /**< Single-bit error for PD_BANK3_RAM. INTERNAL: Instances:
@@ -10297,7 +10352,7 @@ union cvmx_pko_peb_ecc_sbe_sts0 {
 	uint64_t pd_bank2_ram_sbe             : 1;
 	uint64_t pd_bank3_ram_sbe             : 1;
 	uint64_t peb_st_inf_ram_sbe           : 1;
-	uint64_t peb_sm_jmp_ram_sbe           : 1;
+	uint64_t reserved_58_58               : 1;
 	uint64_t pdm_pse_buf_ram_sbe          : 1;
 	uint64_t pdm_resp_buf_ram_sbe         : 1;
 	uint64_t iobp1_fifo_ram_sbe           : 1;
@@ -10324,7 +10379,6 @@ union cvmx_pko_peb_ecc_sbe_sts_cmb0 {
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_proc_i.pko_peb_iobp1_fifo_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pdm_resp_buf_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_pdm_intf_i.pko_peb_pse_buf_i
-                                                         pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_sm_jmp_uid_mem_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_state_info_mem_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank3_i
                                                          pko_pnr3.pko_pnr3_peb.pko_peb_state_mem_i.pko_peb_pd_mem_bank0_i
@@ -10505,6 +10559,24 @@ union cvmx_pko_peb_max_link_err_info {
 typedef union cvmx_pko_peb_max_link_err_info cvmx_pko_peb_max_link_err_info_t;
 
 /**
+ * cvmx_pko_peb_ncb_cfg
+ */
+union cvmx_pko_peb_ncb_cfg {
+	uint64_t u64;
+	struct cvmx_pko_peb_ncb_cfg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+	uint64_t reserved_1_63                : 63;
+	uint64_t rstp                         : 1;  /**< Reserved. */
+#else
+	uint64_t rstp                         : 1;
+	uint64_t reserved_1_63                : 63;
+#endif
+	} s;
+	struct cvmx_pko_peb_ncb_cfg_s         cn78xx;
+};
+typedef union cvmx_pko_peb_ncb_cfg cvmx_pko_peb_ncb_cfg_t;
+
+/**
  * cvmx_pko_peb_pad_err_info
  */
 union cvmx_pko_peb_pad_err_info {
@@ -13397,6 +13469,7 @@ union cvmx_pko_reg_bist_result {
 	uint64_t reserved_30_63               : 34;
 #endif
 	} cn70xx;
+	struct cvmx_pko_reg_bist_result_cn70xx cn70xxp1;
 	struct cvmx_pko_reg_bist_result_cn52xx cnf71xx;
 };
 typedef union cvmx_pko_reg_bist_result cvmx_pko_reg_bist_result_t;
@@ -13442,6 +13515,7 @@ union cvmx_pko_reg_cmd_buf {
 	struct cvmx_pko_reg_cmd_buf_s         cn68xx;
 	struct cvmx_pko_reg_cmd_buf_s         cn68xxp1;
 	struct cvmx_pko_reg_cmd_buf_s         cn70xx;
+	struct cvmx_pko_reg_cmd_buf_s         cn70xxp1;
 	struct cvmx_pko_reg_cmd_buf_s         cnf71xx;
 };
 typedef union cvmx_pko_reg_cmd_buf cvmx_pko_reg_cmd_buf_t;
@@ -13599,6 +13673,7 @@ union cvmx_pko_reg_debug0 {
 	struct cvmx_pko_reg_debug0_s          cn68xx;
 	struct cvmx_pko_reg_debug0_s          cn68xxp1;
 	struct cvmx_pko_reg_debug0_s          cn70xx;
+	struct cvmx_pko_reg_debug0_s          cn70xxp1;
 	struct cvmx_pko_reg_debug0_s          cnf71xx;
 };
 typedef union cvmx_pko_reg_debug0 cvmx_pko_reg_debug0_t;
@@ -13629,6 +13704,7 @@ union cvmx_pko_reg_debug1 {
 	struct cvmx_pko_reg_debug1_s          cn68xx;
 	struct cvmx_pko_reg_debug1_s          cn68xxp1;
 	struct cvmx_pko_reg_debug1_s          cn70xx;
+	struct cvmx_pko_reg_debug1_s          cn70xxp1;
 	struct cvmx_pko_reg_debug1_s          cnf71xx;
 };
 typedef union cvmx_pko_reg_debug1 cvmx_pko_reg_debug1_t;
@@ -13659,6 +13735,7 @@ union cvmx_pko_reg_debug2 {
 	struct cvmx_pko_reg_debug2_s          cn68xx;
 	struct cvmx_pko_reg_debug2_s          cn68xxp1;
 	struct cvmx_pko_reg_debug2_s          cn70xx;
+	struct cvmx_pko_reg_debug2_s          cn70xxp1;
 	struct cvmx_pko_reg_debug2_s          cnf71xx;
 };
 typedef union cvmx_pko_reg_debug2 cvmx_pko_reg_debug2_t;
@@ -13689,6 +13766,7 @@ union cvmx_pko_reg_debug3 {
 	struct cvmx_pko_reg_debug3_s          cn68xx;
 	struct cvmx_pko_reg_debug3_s          cn68xxp1;
 	struct cvmx_pko_reg_debug3_s          cn70xx;
+	struct cvmx_pko_reg_debug3_s          cn70xxp1;
 	struct cvmx_pko_reg_debug3_s          cnf71xx;
 };
 typedef union cvmx_pko_reg_debug3 cvmx_pko_reg_debug3_t;
@@ -13857,6 +13935,7 @@ union cvmx_pko_reg_engine_inflight {
 	struct cvmx_pko_reg_engine_inflight_s cn68xx;
 	struct cvmx_pko_reg_engine_inflight_s cn68xxp1;
 	struct cvmx_pko_reg_engine_inflight_cn61xx cn70xx;
+	struct cvmx_pko_reg_engine_inflight_cn61xx cn70xxp1;
 	struct cvmx_pko_reg_engine_inflight_cn61xx cnf71xx;
 };
 typedef union cvmx_pko_reg_engine_inflight cvmx_pko_reg_engine_inflight_t;
@@ -14047,6 +14126,7 @@ union cvmx_pko_reg_engine_thresh {
 	struct cvmx_pko_reg_engine_thresh_s   cn68xx;
 	struct cvmx_pko_reg_engine_thresh_s   cn68xxp1;
 	struct cvmx_pko_reg_engine_thresh_cn61xx cn70xx;
+	struct cvmx_pko_reg_engine_thresh_cn61xx cn70xxp1;
 	struct cvmx_pko_reg_engine_thresh_cn61xx cnf71xx;
 };
 typedef union cvmx_pko_reg_engine_thresh cvmx_pko_reg_engine_thresh_t;
@@ -14115,6 +14195,7 @@ union cvmx_pko_reg_error {
 	struct cvmx_pko_reg_error_s           cn68xx;
 	struct cvmx_pko_reg_error_s           cn68xxp1;
 	struct cvmx_pko_reg_error_cn50xx      cn70xx;
+	struct cvmx_pko_reg_error_cn50xx      cn70xxp1;
 	struct cvmx_pko_reg_error_cn50xx      cnf71xx;
 };
 typedef union cvmx_pko_reg_error cvmx_pko_reg_error_t;
@@ -14239,6 +14320,7 @@ union cvmx_pko_reg_flags {
 #endif
 	} cn68xxp1;
 	struct cvmx_pko_reg_flags_cn61xx      cn70xx;
+	struct cvmx_pko_reg_flags_cn61xx      cn70xxp1;
 	struct cvmx_pko_reg_flags_cn61xx      cnf71xx;
 };
 typedef union cvmx_pko_reg_flags cvmx_pko_reg_flags_t;
@@ -14289,6 +14371,7 @@ union cvmx_pko_reg_gmx_port_mode {
 	struct cvmx_pko_reg_gmx_port_mode_s   cn63xxp1;
 	struct cvmx_pko_reg_gmx_port_mode_s   cn66xx;
 	struct cvmx_pko_reg_gmx_port_mode_s   cn70xx;
+	struct cvmx_pko_reg_gmx_port_mode_s   cn70xxp1;
 	struct cvmx_pko_reg_gmx_port_mode_s   cnf71xx;
 };
 typedef union cvmx_pko_reg_gmx_port_mode cvmx_pko_reg_gmx_port_mode_t;
@@ -14357,6 +14440,7 @@ union cvmx_pko_reg_int_mask {
 	struct cvmx_pko_reg_int_mask_s        cn68xx;
 	struct cvmx_pko_reg_int_mask_s        cn68xxp1;
 	struct cvmx_pko_reg_int_mask_cn50xx   cn70xx;
+	struct cvmx_pko_reg_int_mask_cn50xx   cn70xxp1;
 	struct cvmx_pko_reg_int_mask_cn50xx   cnf71xx;
 };
 typedef union cvmx_pko_reg_int_mask cvmx_pko_reg_int_mask_t;
@@ -14530,6 +14614,7 @@ union cvmx_pko_reg_preempt {
 	struct cvmx_pko_reg_preempt_s         cn68xx;
 	struct cvmx_pko_reg_preempt_s         cn68xxp1;
 	struct cvmx_pko_reg_preempt_s         cn70xx;
+	struct cvmx_pko_reg_preempt_s         cn70xxp1;
 	struct cvmx_pko_reg_preempt_s         cnf71xx;
 };
 typedef union cvmx_pko_reg_preempt cvmx_pko_reg_preempt_t;
@@ -14576,6 +14661,7 @@ union cvmx_pko_reg_queue_mode {
 	struct cvmx_pko_reg_queue_mode_s      cn68xx;
 	struct cvmx_pko_reg_queue_mode_s      cn68xxp1;
 	struct cvmx_pko_reg_queue_mode_s      cn70xx;
+	struct cvmx_pko_reg_queue_mode_s      cn70xxp1;
 	struct cvmx_pko_reg_queue_mode_s      cnf71xx;
 };
 typedef union cvmx_pko_reg_queue_mode cvmx_pko_reg_queue_mode_t;
@@ -14623,6 +14709,7 @@ union cvmx_pko_reg_queue_preempt {
 	struct cvmx_pko_reg_queue_preempt_s   cn68xx;
 	struct cvmx_pko_reg_queue_preempt_s   cn68xxp1;
 	struct cvmx_pko_reg_queue_preempt_s   cn70xx;
+	struct cvmx_pko_reg_queue_preempt_s   cn70xxp1;
 	struct cvmx_pko_reg_queue_preempt_s   cnf71xx;
 };
 typedef union cvmx_pko_reg_queue_preempt cvmx_pko_reg_queue_preempt_t;
@@ -14663,6 +14750,7 @@ union cvmx_pko_reg_queue_ptrs1 {
 	struct cvmx_pko_reg_queue_ptrs1_s     cn63xxp1;
 	struct cvmx_pko_reg_queue_ptrs1_s     cn66xx;
 	struct cvmx_pko_reg_queue_ptrs1_s     cn70xx;
+	struct cvmx_pko_reg_queue_ptrs1_s     cn70xxp1;
 	struct cvmx_pko_reg_queue_ptrs1_s     cnf71xx;
 };
 typedef union cvmx_pko_reg_queue_ptrs1 cvmx_pko_reg_queue_ptrs1_t;
@@ -14708,6 +14796,7 @@ union cvmx_pko_reg_read_idx {
 	struct cvmx_pko_reg_read_idx_s        cn68xx;
 	struct cvmx_pko_reg_read_idx_s        cn68xxp1;
 	struct cvmx_pko_reg_read_idx_s        cn70xx;
+	struct cvmx_pko_reg_read_idx_s        cn70xxp1;
 	struct cvmx_pko_reg_read_idx_s        cnf71xx;
 };
 typedef union cvmx_pko_reg_read_idx cvmx_pko_reg_read_idx_t;
@@ -14765,6 +14854,7 @@ union cvmx_pko_reg_timestamp {
 	struct cvmx_pko_reg_timestamp_s       cn68xx;
 	struct cvmx_pko_reg_timestamp_s       cn68xxp1;
 	struct cvmx_pko_reg_timestamp_s       cn70xx;
+	struct cvmx_pko_reg_timestamp_s       cn70xxp1;
 	struct cvmx_pko_reg_timestamp_s       cnf71xx;
 };
 typedef union cvmx_pko_reg_timestamp cvmx_pko_reg_timestamp_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3-queue.h b/arch/mips/include/asm/octeon/cvmx-pko3-queue.h
index 20caa1e..a3202d7 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko3-queue.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko3-queue.h
@@ -52,29 +52,6 @@ extern "C" {
 /* *INDENT-ON* */
 #endif
 
-/* Maximum range for normalized (a.k.a. IPD) port numbers (12-bit field) */
-#define	CVMX_PKO3_IPD_NUM_MAX	0x1000	//FIXME- take it from someplace else ?
-
-/* Maximum number of DQs per CHAN_E (IPD port) is 64, although 8 is typical */
-#define	CVMX_PKO2_IPD_MAX_DQ	(1<<6)
-
-struct cvmx_pko3_dq_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	unsigned	
-			dq_count :6,	/* Number of descriptor queues */
-			dq_base :10;	/* Descriptor queue start number */
-#define	CVMX_PKO3_SWIZZLE_IPD	0x0
-#else
-	unsigned	
-			dq_base :10,	/* Descriptor queue start number */
-			dq_count :6;	/* Number of descriptor queues */
-
-#define	CVMX_PKO3_SWIZZLE_IPD	0x3
-#endif
-};
-
-extern struct cvmx_pko3_dq_s *__cvmx_pko3_dq_table;
-
 /**
  * @INTERNAL
  *
@@ -85,63 +62,17 @@ extern struct cvmx_pko3_dq_s *__cvmx_pko3_dq_table;
  * The table global pointer is stored in core-local variable
  * so that every core will call this function once, on first use.
  */
-extern int __cvmx_pko3_dq_table_setup(void);
+int __cvmx_pko3_dq_table_setup(void);
 
 /*
  * Get the base Descriptor Queue number for an IPD port on the local node
  */
-static inline int cvmx_pko3_get_queue_base(uint16_t ipd_port)
-{
-	struct cvmx_pko3_dq_s *dq_table;
-	int ret = -1;
-	unsigned i;
-	unsigned node;
-
-	/* get per-node table */
-	if(cvmx_unlikely(__cvmx_pko3_dq_table == NULL))
-		__cvmx_pko3_dq_table_setup();
-
-	/* extract node # from portID */
-	node = ipd_port >> 14;
-
-	i = CVMX_PKO3_SWIZZLE_IPD ^ (ipd_port & (CVMX_PKO3_IPD_NUM_MAX-1));
-
-	/* get per-node table */
-	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * node;
-
-	if(dq_table[i].dq_count > 0)
-		ret = dq_table[i].dq_base | (node << 14);
-
-	return ret;
-}
+int cvmx_pko3_get_queue_base(int ipd_port);
 
 /*
  * Get the number of Descriptor Queues assigned for an IPD port
  */
-static inline int cvmx_pko3_get_queue_num(uint16_t ipd_port)
-{
-	struct cvmx_pko3_dq_s *dq_table;
-	int ret = -1;
-	unsigned i;
-	unsigned node;
-
-	/* get per-node table */
-	if(__cvmx_pko3_dq_table == NULL)
-		__cvmx_pko3_dq_table_setup();
-
-	/* extract node # from portID */
-	node = ipd_port >> 14;
-
-	i = CVMX_PKO3_SWIZZLE_IPD ^ (ipd_port & (CVMX_PKO3_IPD_NUM_MAX-1));
-
-	/* get per-node table */
-	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * node;
-
-	if(dq_table[i].dq_count > 0)
-		ret = dq_table[i].dq_count;
-
-	return ret;
-}
+int cvmx_pko3_get_queue_num(int ipd_port);
 
 /*
  * Configure Port Queue and its children Scheduler Queue
@@ -151,6 +82,7 @@ static inline int cvmx_pko3_get_queue_num(uint16_t ipd_port)
  * could be multiple L2 SQs attached to a single L1 PQ, either in a
  * fair round-robin scheduling, or with static and/or round-robin priorities.
  *
+ * @param node is the OCI node location for the queues to be configured
  * @param mac_num is the LMAC number to that is associated with the Port Queue,
  * @param which is identical to the Port Queue number that is configured
  * @param child_base is the number of the first L2 SQ attached to the PQ
@@ -168,7 +100,8 @@ static inline int cvmx_pko3_get_queue_num(uint16_t ipd_port)
  *
  * Note: this function supports the configuration of node-local unit.
  */
-int cvmx_pko3_pq_config_children(unsigned mac_num, unsigned child_base,
+int cvmx_pko3_pq_config_children(unsigned node, unsigned mac_num,
+			unsigned child_base,
 			unsigned child_count, int stat_prio_count);
 
 /*
@@ -181,6 +114,7 @@ int cvmx_pko3_pq_config_children(unsigned mac_num, unsigned child_base,
  * The children can have fair round-robin or priority-based scheduling
  * when multiple children are assigned a single parent.
  *
+ * @param node is the OCI node location for the queues to be configured
  * @param parent_level is the level of the parent queue, 2 to 5.
  * @param parent_queue is the number of the parent Scheduler Queue
  * @param child_base is the number of the first child SQ or DQ to assign to
@@ -199,7 +133,7 @@ int cvmx_pko3_pq_config_children(unsigned mac_num, unsigned child_base,
  *
  * Note: this function supports the configuration of node-local unit.
  */
-int cvmx_pko3_sq_config_children(unsigned parent_level,
+int cvmx_pko3_sq_config_children(unsigned int node, unsigned parent_level,
 			unsigned parent_queue, unsigned child_base,
 			unsigned child_count, int stat_prio_count);
 
@@ -212,8 +146,8 @@ int cvmx_pko3_sq_config_children(unsigned parent_level,
  * by priority) for a given IPD-port, which is either a physical port,
  * or a channel on a channelized interface (i.e. ILK).
  *
- * @param interface is the physical interface number
- * @param port is either a physical port on an interface
+ * @param xiface is the physical interface number
+ * @param index is either a physical port on an interface
  * @param or a channel of an ILK interface
  * @param dq_base is the first Descriptor Queue number in a consecutive range
  * @param dq_count is the number of consecutive Descriptor Queues leading
@@ -227,7 +161,7 @@ int cvmx_pko3_sq_config_children(unsigned parent_level,
  *
  * @returns 0 on success, -1 on failure.
  */
-int __cvmx_pko3_ipd_dq_register(unsigned interface, unsigned port,
+int __cvmx_pko3_ipd_dq_register(int xiface, int index,
 		unsigned dq_base, unsigned dq_count);
 
 
@@ -236,7 +170,7 @@ int __cvmx_pko3_ipd_dq_register(unsigned interface, unsigned port,
  *
  * Unregister DQs associated with CHAN_E (IPD port)
  */
-int __cvmx_pko3_ipd_dq_unregister(unsigned interface, unsigned port);
+int __cvmx_pko3_ipd_dq_unregister(int xiface, int index);
 
 /*
  * Map channel number in PKO 
@@ -254,6 +188,43 @@ int __cvmx_pko3_ipd_dq_unregister(unsigned interface, unsigned port);
 void cvmx_pko3_map_channel(unsigned node,
 	unsigned pq_num, unsigned l2_l3_q_num, uint16_t channel);
 
+extern int cvmx_pko3_port_cir_set(unsigned node, unsigned pq_num,
+		unsigned long rate_kbips, unsigned burst_bytes);
+
+/**
+ * Macros to deal with short floating point numbers,
+ * where unsigned exponent, and an unsigned normalized
+ * mantissa are represented each with a defined field width.
+ *
+ */
+#define	CVMX_SHOFT_MANT_BITS	8
+#define	CVMX_SHOFT_EXP_BITS	4
+
+/**
+ * Convert short-float to an unsigned integer
+ * Note that it will lose precision.
+ */
+#define	CVMX_SHOFT_TO_U64(m,e) \
+	((((1ull<<CVMX_SHOFT_MANT_BITS) | (m)) << (e))>>CVMX_SHOFT_MANT_BITS)
+
+/**
+ * Convert to short-float from an unsigned integer
+ */
+#define	CVMX_SHOFT_FROM_U64(ui,m,e) do { \
+		unsigned long long u; unsigned k;		\
+		k = (1ull << (CVMX_SHOFT_MANT_BITS+1)) -1;		\
+		(e) = 0; u = (ui) << CVMX_SHOFT_MANT_BITS;	\
+		while((u) > k) {				\
+			u >>=1; (e)++;				\
+		}						\
+		(m) = u & (k>>1);				\
+	} while(0);
+
+#define	CVMX_SHOFT_MAX()	CVMX_SHOFT_TO_U64((1<<CVMX_SHOFT_MANT_BITS)-1, \
+						(1<<CVMX_SHOFT_EXP_BITS)-1)
+#define	CVMX_SHOFT_MIN()	CVMX_SHOFT_TO_U64(0, 0)
+
+
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3.h b/arch/mips/include/asm/octeon/cvmx-pko3.h
index 20f32c7..a2a573e 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko3.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko3.h
@@ -89,7 +89,7 @@ enum cvmx_pko_dqop {
 	CVMX_PKO_DQ_QUERY = 3ULL
 };
 
-union cvmx_pko_query_rtn_s {
+union cvmx_pko_query_rtn {
 	uint64_t u64;
 	struct {
 		CVMX_BITFIELD_FIELD(uint64_t dqstatus	: 4,
@@ -99,9 +99,9 @@ union cvmx_pko_query_rtn_s {
 			))));
 	} s;
 };
-typedef union cvmx_pko_query_rtn_s cvmx_pko_query_rtn_s_t;
+typedef union cvmx_pko_query_rtn cvmx_pko_query_rtn_t;
 
-/* PKO_QUERY_RTN_S[DQSTATUS] - cvmx_pko_query_rtn_s_t->s.dqstatus */
+/* PKO_QUERY_RTN_S[DQSTATUS] - cvmx_pko_query_rtn_t->s.dqstatus */
 enum pko_query_dqstatus {
 	PKO_DQSTATUS_PASS = 0,		/* No error */
 	PKO_DQSTATUS_BADSTATE = 0x8,	/* queue was not ready to enqueue */
@@ -323,29 +323,31 @@ static inline uint64_t build_mask(uint64_t bits)
  * This function gets PKO mac num for a interface/port.
  *
  * @param interface is the interface number.
- * @param port is the port number.
+ * @param index is the port number.
  * @return returns mac number if successful or -1 on failure.
  */
-static inline int __cvmx_pko_get_mac_num(int interface, int port)
+static inline int __cvmx_pko3_get_mac_num(int xiface, int index)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	cvmx_helper_interface_mode_t mode;
 	int interface_index;
 
-	mode = cvmx_helper_interface_get_mode(interface);
+	mode = cvmx_helper_interface_get_mode(xiface);
 	switch (mode) {
-		case CVMX_HELPER_INTERFACE_MODE_SGMII:
-		case CVMX_HELPER_INTERFACE_MODE_RXAUI:
-		case CVMX_HELPER_INTERFACE_MODE_XAUI:
-			return (4 + 4 * interface + port);
 		case CVMX_HELPER_INTERFACE_MODE_LOOP:
 			return 0;
 		case CVMX_HELPER_INTERFACE_MODE_NPI:
 			return 1;
 		case CVMX_HELPER_INTERFACE_MODE_ILK:
-			interface_index = (interface - CVMX_ILK_GBL_BASE());
+			interface_index = (xi.interface - CVMX_ILK_GBL_BASE());
+			if (interface_index < 0)
+				return -1;
 			return (2 + interface_index);
 		default:
-			return -1;
+			if (xi.interface >= CVMX_ILK_GBL_BASE())
+				return -1;
+			/* All other modes belong to BGX */
+			return (4 + 4 * xi.interface + index);
 	}
 }
 
@@ -387,12 +389,12 @@ static inline int cvmx_pko_setup_channel_credit_level(int node, int level)
  *
  * NOTE: Internal use only.
  */
-static inline cvmx_pko_query_rtn_s_t 
+static inline cvmx_pko_query_rtn_t 
 __cvmx_pko3_do_dma(uint8_t node, uint16_t dq, uint64_t cmds[],
 	unsigned numwords, enum cvmx_pko_dqop dqop)
 {
 	const unsigned scr_base = CVMX_PKO_LMTLINE * CVMX_CACHE_LINE_SIZE;
-	cvmx_pko_query_rtn_s_t pko_status;
+	cvmx_pko_query_rtn_t pko_status;
 	cvmx_pko_lmtdma_data_t pko_send_dma_data;
 	uint64_t dma_addr;
 	unsigned i, scr_off;
@@ -548,9 +550,8 @@ extern void cvmx_pko3_get_legacy_port_stats(uint16_t ipd_port,
  *
  * The options supported are the parameters below:
  *
- * @param node The OCI node number of the interface
- * @param interface The physical interface number
- * @param port The physical sub-interface port
+ * @param xiface The physical interface number
+ * @param index The physical sub-interface port
  * @param fcs_enable Enable FCS generation
  * @param pad_enable Enable padding to minimum packet size
  * @param fcs_sop_off Number of bytes at start of packet to exclude from FCS
@@ -562,7 +563,7 @@ extern void cvmx_pko3_get_legacy_port_stats(uint16_t ipd_port,
  *
  * @return Returns 0 on success, -1 if interface/port is invalid.
  */
-extern int cvmx_pko3_interface_options(int node, int interface, int port,
+extern int cvmx_pko3_interface_options(int xiface, int index,
 			bool fcs_enable, bool pad_enable,
 			unsigned fcs_sop_off);
 
@@ -581,8 +582,10 @@ typedef struct cvmx_pko3_pdesc_s {
 	unsigned
 		num_words:5,	/**< valid words in word array 2..16 */
 		headroom:10,	/**< free bytes at start of 1st buf */
+		hdr_offsets:1,
 		pki_word4_present : 1;
 	/* PKO3 command buffer: */
+	cvmx_pko_send_hdr_t *hdr_s;
 	uint64_t word[16];	/**< header and subcommands buffer */
 	/* Bookkeeping fields: */
 	uint64_t send_work_s;	/**< SEND_WORK_S must be the very last subdc */
@@ -590,7 +593,7 @@ typedef struct cvmx_pko3_pdesc_s {
 	uint16_t mem_s_ix;	/**< index of first MEM_S subcommand */
 	uint8_t ckl4_alg;	/**< L3/L4 alg to use if recalc is needed */
 	/* Fields saved from WQE for later inspection */
-	cvmx_wqe_word4_t pki_word4;
+	cvmx_pki_wqe_word4_t pki_word4;
 	cvmx_pki_wqe_word2_t pki_word2;
 } cvmx_pko3_pdesc_t;
 
@@ -603,7 +606,14 @@ int cvmx_pko3_pdesc_notify_decrement(cvmx_pko3_pdesc_t *pdesc,
 int cvmx_pko3_pdesc_notify_wqe(cvmx_pko3_pdesc_t *pdesc, cvmx_wqe_78xx_t *wqe,
 	uint8_t node, uint8_t group, uint8_t tt, uint32_t tag);
 int cvmx_pko3_pdesc_buf_append(cvmx_pko3_pdesc_t *pdesc, void *p_data,
-		unsigned data_bytes, unsigned gaura, bool free_buf);
+		unsigned data_bytes, unsigned gaura);
+int cvmx_pko3_pdesc_hdr_push(cvmx_pko3_pdesc_t *pdesc,
+	const void *p_data, uint8_t data_bytes, uint8_t layer);
+int cvmx_pko3_pdesc_hdr_pop(cvmx_pko3_pdesc_t *pdesc,
+		void *hdr_buf, unsigned num_bytes);
+int cvmx_pko3_pdesc_hdr_peek(cvmx_pko3_pdesc_t *pdesc,
+		void *hdr_buf, unsigned num_bytes, unsigned offset);
+void cvmx_pko3_pdesc_set_free(cvmx_pko3_pdesc_t *pdesc, bool free_bufs);
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
diff --git a/arch/mips/include/asm/octeon/cvmx-pow-defs.h b/arch/mips/include/asm/octeon/cvmx-pow-defs.h
index 7617fea..7793fb3 100644
--- a/arch/mips/include/asm/octeon/cvmx-pow-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-pow-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -664,6 +664,7 @@ union cvmx_pow_bist_stat {
 	uint64_t reserved_12_63               : 52;
 #endif
 	} cn70xx;
+	struct cvmx_pow_bist_stat_cn70xx      cn70xxp1;
 	struct cvmx_pow_bist_stat_cn61xx      cnf71xx;
 };
 typedef union cvmx_pow_bist_stat cvmx_pow_bist_stat_t;
@@ -701,6 +702,7 @@ union cvmx_pow_ds_pc {
 	struct cvmx_pow_ds_pc_s               cn63xxp1;
 	struct cvmx_pow_ds_pc_s               cn66xx;
 	struct cvmx_pow_ds_pc_s               cn70xx;
+	struct cvmx_pow_ds_pc_s               cn70xxp1;
 	struct cvmx_pow_ds_pc_s               cnf71xx;
 };
 typedef union cvmx_pow_ds_pc cvmx_pow_ds_pc_t;
@@ -809,6 +811,7 @@ union cvmx_pow_ecc_err {
 	struct cvmx_pow_ecc_err_s             cn63xxp1;
 	struct cvmx_pow_ecc_err_s             cn66xx;
 	struct cvmx_pow_ecc_err_s             cn70xx;
+	struct cvmx_pow_ecc_err_s             cn70xxp1;
 	struct cvmx_pow_ecc_err_s             cnf71xx;
 };
 typedef union cvmx_pow_ecc_err cvmx_pow_ecc_err_t;
@@ -846,6 +849,7 @@ union cvmx_pow_iq_cntx {
 	struct cvmx_pow_iq_cntx_s             cn63xxp1;
 	struct cvmx_pow_iq_cntx_s             cn66xx;
 	struct cvmx_pow_iq_cntx_s             cn70xx;
+	struct cvmx_pow_iq_cntx_s             cn70xxp1;
 	struct cvmx_pow_iq_cntx_s             cnf71xx;
 };
 typedef union cvmx_pow_iq_cntx cvmx_pow_iq_cntx_t;
@@ -883,6 +887,7 @@ union cvmx_pow_iq_com_cnt {
 	struct cvmx_pow_iq_com_cnt_s          cn63xxp1;
 	struct cvmx_pow_iq_com_cnt_s          cn66xx;
 	struct cvmx_pow_iq_com_cnt_s          cn70xx;
+	struct cvmx_pow_iq_com_cnt_s          cn70xxp1;
 	struct cvmx_pow_iq_com_cnt_s          cnf71xx;
 };
 typedef union cvmx_pow_iq_com_cnt cvmx_pow_iq_com_cnt_t;
@@ -914,6 +919,7 @@ union cvmx_pow_iq_int {
 	struct cvmx_pow_iq_int_s              cn63xxp1;
 	struct cvmx_pow_iq_int_s              cn66xx;
 	struct cvmx_pow_iq_int_s              cn70xx;
+	struct cvmx_pow_iq_int_s              cn70xxp1;
 	struct cvmx_pow_iq_int_s              cnf71xx;
 };
 typedef union cvmx_pow_iq_int cvmx_pow_iq_int_t;
@@ -944,6 +950,7 @@ union cvmx_pow_iq_int_en {
 	struct cvmx_pow_iq_int_en_s           cn63xxp1;
 	struct cvmx_pow_iq_int_en_s           cn66xx;
 	struct cvmx_pow_iq_int_en_s           cn70xx;
+	struct cvmx_pow_iq_int_en_s           cn70xxp1;
 	struct cvmx_pow_iq_int_en_s           cnf71xx;
 };
 typedef union cvmx_pow_iq_int_en cvmx_pow_iq_int_en_t;
@@ -974,6 +981,7 @@ union cvmx_pow_iq_thrx {
 	struct cvmx_pow_iq_thrx_s             cn63xxp1;
 	struct cvmx_pow_iq_thrx_s             cn66xx;
 	struct cvmx_pow_iq_thrx_s             cn70xx;
+	struct cvmx_pow_iq_thrx_s             cn70xxp1;
 	struct cvmx_pow_iq_thrx_s             cnf71xx;
 };
 typedef union cvmx_pow_iq_thrx cvmx_pow_iq_thrx_t;
@@ -1043,6 +1051,7 @@ union cvmx_pow_nos_cnt {
 	struct cvmx_pow_nos_cnt_cn63xx        cn63xxp1;
 	struct cvmx_pow_nos_cnt_cn63xx        cn66xx;
 	struct cvmx_pow_nos_cnt_cn52xx        cn70xx;
+	struct cvmx_pow_nos_cnt_cn52xx        cn70xxp1;
 	struct cvmx_pow_nos_cnt_cn52xx        cnf71xx;
 };
 typedef union cvmx_pow_nos_cnt cvmx_pow_nos_cnt_t;
@@ -1112,6 +1121,7 @@ union cvmx_pow_nw_tim {
 	struct cvmx_pow_nw_tim_s              cn63xxp1;
 	struct cvmx_pow_nw_tim_s              cn66xx;
 	struct cvmx_pow_nw_tim_s              cn70xx;
+	struct cvmx_pow_nw_tim_s              cn70xxp1;
 	struct cvmx_pow_nw_tim_s              cnf71xx;
 };
 typedef union cvmx_pow_nw_tim cvmx_pow_nw_tim_t;
@@ -1146,6 +1156,7 @@ union cvmx_pow_pf_rst_msk {
 	struct cvmx_pow_pf_rst_msk_s          cn63xxp1;
 	struct cvmx_pow_pf_rst_msk_s          cn66xx;
 	struct cvmx_pow_pf_rst_msk_s          cn70xx;
+	struct cvmx_pow_pf_rst_msk_s          cn70xxp1;
 	struct cvmx_pow_pf_rst_msk_s          cnf71xx;
 };
 typedef union cvmx_pow_pf_rst_msk cvmx_pow_pf_rst_msk_t;
@@ -1216,6 +1227,7 @@ union cvmx_pow_pp_grp_mskx {
 	struct cvmx_pow_pp_grp_mskx_s         cn63xxp1;
 	struct cvmx_pow_pp_grp_mskx_s         cn66xx;
 	struct cvmx_pow_pp_grp_mskx_s         cn70xx;
+	struct cvmx_pow_pp_grp_mskx_s         cn70xxp1;
 	struct cvmx_pow_pp_grp_mskx_s         cnf71xx;
 };
 typedef union cvmx_pow_pp_grp_mskx cvmx_pow_pp_grp_mskx_t;
@@ -1269,6 +1281,7 @@ union cvmx_pow_qos_rndx {
 	struct cvmx_pow_qos_rndx_s            cn63xxp1;
 	struct cvmx_pow_qos_rndx_s            cn66xx;
 	struct cvmx_pow_qos_rndx_s            cn70xx;
+	struct cvmx_pow_qos_rndx_s            cn70xxp1;
 	struct cvmx_pow_qos_rndx_s            cnf71xx;
 };
 typedef union cvmx_pow_qos_rndx cvmx_pow_qos_rndx_t;
@@ -1422,6 +1435,7 @@ union cvmx_pow_qos_thrx {
 	struct cvmx_pow_qos_thrx_cn63xx       cn63xxp1;
 	struct cvmx_pow_qos_thrx_cn63xx       cn66xx;
 	struct cvmx_pow_qos_thrx_cn52xx       cn70xx;
+	struct cvmx_pow_qos_thrx_cn52xx       cn70xxp1;
 	struct cvmx_pow_qos_thrx_cn52xx       cnf71xx;
 };
 typedef union cvmx_pow_qos_thrx cvmx_pow_qos_thrx_t;
@@ -1459,6 +1473,7 @@ union cvmx_pow_ts_pc {
 	struct cvmx_pow_ts_pc_s               cn63xxp1;
 	struct cvmx_pow_ts_pc_s               cn66xx;
 	struct cvmx_pow_ts_pc_s               cn70xx;
+	struct cvmx_pow_ts_pc_s               cn70xxp1;
 	struct cvmx_pow_ts_pc_s               cnf71xx;
 };
 typedef union cvmx_pow_ts_pc cvmx_pow_ts_pc_t;
@@ -1496,6 +1511,7 @@ union cvmx_pow_wa_com_pc {
 	struct cvmx_pow_wa_com_pc_s           cn63xxp1;
 	struct cvmx_pow_wa_com_pc_s           cn66xx;
 	struct cvmx_pow_wa_com_pc_s           cn70xx;
+	struct cvmx_pow_wa_com_pc_s           cn70xxp1;
 	struct cvmx_pow_wa_com_pc_s           cnf71xx;
 };
 typedef union cvmx_pow_wa_com_pc cvmx_pow_wa_com_pc_t;
@@ -1533,6 +1549,7 @@ union cvmx_pow_wa_pcx {
 	struct cvmx_pow_wa_pcx_s              cn63xxp1;
 	struct cvmx_pow_wa_pcx_s              cn66xx;
 	struct cvmx_pow_wa_pcx_s              cn70xx;
+	struct cvmx_pow_wa_pcx_s              cn70xxp1;
 	struct cvmx_pow_wa_pcx_s              cnf71xx;
 };
 typedef union cvmx_pow_wa_pcx cvmx_pow_wa_pcx_t;
@@ -1594,6 +1611,7 @@ union cvmx_pow_wq_int {
 	struct cvmx_pow_wq_int_s              cn63xxp1;
 	struct cvmx_pow_wq_int_s              cn66xx;
 	struct cvmx_pow_wq_int_s              cn70xx;
+	struct cvmx_pow_wq_int_s              cn70xxp1;
 	struct cvmx_pow_wq_int_s              cnf71xx;
 };
 typedef union cvmx_pow_wq_int cvmx_pow_wq_int_t;
@@ -1764,6 +1782,7 @@ union cvmx_pow_wq_int_cntx {
 	struct cvmx_pow_wq_int_cntx_cn63xx    cn63xxp1;
 	struct cvmx_pow_wq_int_cntx_cn63xx    cn66xx;
 	struct cvmx_pow_wq_int_cntx_cn52xx    cn70xx;
+	struct cvmx_pow_wq_int_cntx_cn52xx    cn70xxp1;
 	struct cvmx_pow_wq_int_cntx_cn52xx    cnf71xx;
 };
 typedef union cvmx_pow_wq_int_cntx cvmx_pow_wq_int_cntx_t;
@@ -1809,6 +1828,7 @@ union cvmx_pow_wq_int_pc {
 	struct cvmx_pow_wq_int_pc_s           cn63xxp1;
 	struct cvmx_pow_wq_int_pc_s           cn66xx;
 	struct cvmx_pow_wq_int_pc_s           cn70xx;
+	struct cvmx_pow_wq_int_pc_s           cn70xxp1;
 	struct cvmx_pow_wq_int_pc_s           cnf71xx;
 };
 typedef union cvmx_pow_wq_int_pc cvmx_pow_wq_int_pc_t;
@@ -1954,6 +1974,7 @@ union cvmx_pow_wq_int_thrx {
 	struct cvmx_pow_wq_int_thrx_cn63xx    cn63xxp1;
 	struct cvmx_pow_wq_int_thrx_cn63xx    cn66xx;
 	struct cvmx_pow_wq_int_thrx_cn52xx    cn70xx;
+	struct cvmx_pow_wq_int_thrx_cn52xx    cn70xxp1;
 	struct cvmx_pow_wq_int_thrx_cn52xx    cnf71xx;
 };
 typedef union cvmx_pow_wq_int_thrx cvmx_pow_wq_int_thrx_t;
@@ -1991,6 +2012,7 @@ union cvmx_pow_ws_pcx {
 	struct cvmx_pow_ws_pcx_s              cn63xxp1;
 	struct cvmx_pow_ws_pcx_s              cn66xx;
 	struct cvmx_pow_ws_pcx_s              cn70xx;
+	struct cvmx_pow_ws_pcx_s              cn70xxp1;
 	struct cvmx_pow_ws_pcx_s              cnf71xx;
 };
 typedef union cvmx_pow_ws_pcx cvmx_pow_ws_pcx_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-pow.h b/arch/mips/include/asm/octeon/cvmx-pow.h
index 2d60178..24b4477 100644
--- a/arch/mips/include/asm/octeon/cvmx-pow.h
+++ b/arch/mips/include/asm/octeon/cvmx-pow.h
@@ -352,194 +352,130 @@ typedef union {
      * Address for new work request loads (did<2:0> == 0)
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,
 					    /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 					    /**< Must be zero */
-		uint64_t is_io:1;	    /**< Must be one */
-		uint64_t did:8;		    /**< the ID of POW -- did<2:0> == 0 in this case */
-		uint64_t reserved_4_39:36;
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,	    /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		    /**< the ID of POW -- did<2:0> == 0 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_4_39:36,
 					    /**< Must be zero */
-		uint64_t wait:1;	    /**< If set, don't return load response until work is available */
-		uint64_t reserved_0_2:3;
+		CVMX_BITFIELD_FIELD(uint64_t wait:1,	    /**< If set, don't return load response until work is available */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_2:3,
 					    /**< Must be zero */
-#else
-		uint64_t reserved_0_2:3;
-		uint64_t wait:1;
-		uint64_t reserved_4_39:36;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		)))))));
 	} swork;
 
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;      /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13; /**< Must be zero */
-		uint64_t is_io:1;           /**< Must be one */
-		uint64_t did:8;             /**< the ID of POW -- did<2:0> == 0 in this case */
-		uint64_t node:4;            /**< OCI Node number */
-		uint64_t reserved_4_35:32;  /**< Must be zero */
-		uint64_t wait:1;            /**< If set, don't return load response until work is available */
-		uint64_t reserved_0_2:3;    /**< Must be zero */
-#else
-		uint64_t reserved_0_2:3;
-		uint64_t wait:1;
-		uint64_t reserved_4_35:36;
-		uint64_t node:4;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,      /**< Mips64 address region. Should be CVMX_IO_SEG */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13, /**< Must be zero */
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,           /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,             /**< the ID of POW -- did<2:0> == 0 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t node:4,            /**< OCI Node number */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_32_35:4,  /**< Must be zero */
+		CVMX_BITFIELD_FIELD(uint64_t indexed:1,  /**< Indexed get_work if set */
+		CVMX_BITFIELD_FIELD(uint64_t grouped:1,  /**< get_work for group specified in index */
+		CVMX_BITFIELD_FIELD(uint64_t rtngrp:1,  /**< Return group and tt in the return if set */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_16_28:13,  /**< Must be zero */
+		CVMX_BITFIELD_FIELD(uint64_t index:12,  /**< mask/grp/index of the request */
+		CVMX_BITFIELD_FIELD(uint64_t wait:1,            /**< If set, don't return load response until work is available */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_2:3,    /**< Must be zero */
+		)))))))))))));
 	} swork_78xx;
 
     /**
      * Address for loads to get POW internal status
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,
 					    /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13;
-					    /**< Must be zero */
-		uint64_t is_io:1;	    /**< Must be one */
-		uint64_t did:8;		    /**< the ID of POW -- did<2:0> == 1 in this case */
-		uint64_t reserved_10_39:30;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 					    /**< Must be zero */
-		uint64_t coreid:4;	    /**< The core id to get status for */
-		uint64_t get_rev:1;	    /**< If set and get_cur is set, return reverse tag-list pointer rather than forward tag-list pointer */
-		uint64_t get_cur:1;	    /**< If set, return current status rather than pending status */
-		uint64_t get_wqp:1;	    /**< If set, get the work-queue pointer rather than tag/type */
-		uint64_t reserved_0_2:3;
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,	    /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		    /**< the ID of POW -- did<2:0> == 1 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_10_39:30,
 					    /**< Must be zero */
-#else
-		uint64_t reserved_0_2:3;
-		uint64_t get_wqp:1;
-		uint64_t get_cur:1;
-		uint64_t get_rev:1;
-		uint64_t coreid:4;
-		uint64_t reserved_10_39:30;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t coreid:4,	    /**< The core id to get status for */
+		CVMX_BITFIELD_FIELD(uint64_t get_rev:1,	    /**< If set and get_cur is set, return reverse tag-list pointer rather than forward tag-list pointer */
+		CVMX_BITFIELD_FIELD(uint64_t get_cur:1,	    /**< If set, return current status rather than pending status */
+		CVMX_BITFIELD_FIELD(uint64_t get_wqp:1,	    /**< If set, get the work-queue pointer rather than tag/type */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_2:3,  /**< Must be zero */
+		))))))))));
 	} sstatus;
 
     /**
      * Address for loads to get 68XX SS0 internal status
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,
 					    /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13;
-					    /**< Must be zero */
-		uint64_t is_io:1;	    /**< Must be one */
-		uint64_t did:8;		    /**< the ID of POW -- did<2:0> == 1 in this case */
-		uint64_t reserved_14_39:26;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 					    /**< Must be zero */
-		uint64_t coreid:5;	    /**< The core id to get status for */
-		uint64_t reserved_6_8:3;
-		uint64_t opcode:3;	    /**< Status operation */
-		uint64_t reserved_0_2:3;
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,	    /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		    /**< the ID of POW -- did<2:0> == 1 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_14_39:26,
 					    /**< Must be zero */
-#else
-		uint64_t reserved_0_2:3;
-		uint64_t opcode:3;
-		uint64_t reserved_6_8:3;
-		uint64_t coreid:5;
-		uint64_t reserved_14_39:26;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t coreid:5,	    /**< The core id to get status for */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_6_8:3,
+		CVMX_BITFIELD_FIELD(uint64_t opcode:3,	    /**< Status operation */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_2:3, /**< Must be zero */
+		)))))))));
 	} sstatus_cn68xx;
 
     /**
      * Address for memory loads to get POW internal state
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,
 					    /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 					    /**< Must be zero */
-		uint64_t is_io:1;	    /**< Must be one */
-		uint64_t did:8;		    /**< the ID of POW -- did<2:0> == 2 in this case */
-		uint64_t reserved_16_39:24;
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,	    /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		    /**< the ID of POW -- did<2:0> == 2 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_16_39:24,
 					    /**< Must be zero */
-		uint64_t index:11;	    /**< POW memory index */
-		uint64_t get_des:1;	    /**< If set, return deschedule information rather than the standard
+		CVMX_BITFIELD_FIELD(uint64_t index:11,	    /**< POW memory index */
+		CVMX_BITFIELD_FIELD(uint64_t get_des:1,	    /**< If set, return deschedule information rather than the standard
                                                 response for work-queue index (invalid if the work-queue entry is not on the
                                                 deschedule list). */
-		uint64_t get_wqp:1;	    /**< If set, get the work-queue pointer rather than tag/type (no effect when get_des set). */
-		uint64_t reserved_0_2:3;
-					    /**< Must be zero */
-#else
-		uint64_t reserved_0_2:3;
-		uint64_t get_wqp:1;
-		uint64_t get_des:1;
-		uint64_t index:11;
-		uint64_t reserved_16_39:24;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t get_wqp:1,	    /**< If set, get the work-queue pointer rather than tag/type (no effect when get_des set). */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_2:3,  /**< Must be zero */
+		)))))))));
 	} smemload;
 
     /**
      * Address for memory loads to get SSO internal state
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,
 					    /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13;
-					    /**< Must be zero */
-		uint64_t is_io:1;	    /**< Must be one */
-		uint64_t did:8;		    /**< the ID of SSO - did<2:0> == 2 in this case */
-		uint64_t reserved_20_39:20;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 					    /**< Must be zero */
-		uint64_t index:11;	    /**< SSO memory index */
-		uint64_t reserved_6_8:3;
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,	    /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		    /**< the ID of SSO - did<2:0> == 2 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_20_39:20,
 					    /**< Must be zero */
-		uint64_t opcode:3;	    /**< Read TAG/WQ pointer/pending tag/next potr */
-		uint64_t reserved_0_2:3;
+		CVMX_BITFIELD_FIELD(uint64_t index:11,	    /**< SSO memory index */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_6_8:3,
 					    /**< Must be zero */
-#else
-		uint64_t reserved_0_2:3;
-		uint64_t opcode:3;
-		uint64_t reserved_3_5:3;
-		uint64_t index:11;
-		uint64_t reserved_20_39:20;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t opcode:3,	    /**< Read TAG/WQ pointer/pending tag/next potr */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_2:3, /**< Must be zero */
+		)))))))));
 	} smemload_cn68xx;
 
     /**
      * Address for index/pointer loads
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,
 					    /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 					    /**< Must be zero */
-		uint64_t is_io:1;	    /**< Must be one */
-		uint64_t did:8;		    /**< the ID of POW -- did<2:0> == 3 in this case */
-		uint64_t reserved_9_39:31;
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,	    /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		    /**< the ID of POW -- did<2:0> == 3 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_9_39:31,
 					    /**< Must be zero */
-		uint64_t qosgrp:4;	    /**< when {get_rmt ==0 AND get_des_get_tail == 0}, this field selects one of
+		CVMX_BITFIELD_FIELD(uint64_t qosgrp:4,	    /**< when {get_rmt ==0 AND get_des_get_tail == 0}, this field selects one of
                                                 eight POW internal-input queues (0-7), one per QOS level; values 8-15 are
                                                 illegal in this case;
                                                 when {get_rmt ==0 AND get_des_get_tail == 1}, this field selects one of
@@ -554,58 +490,35 @@ typedef union {
                                                 - qosgrp = 5, qosgrp = 13:     QOS5
                                                 - qosgrp = 6, qosgrp = 14:     QOS6
                                                 - qosgrp = 7, qosgrp = 15:     QOS7 */
-		uint64_t get_des_get_tail:1;
+		CVMX_BITFIELD_FIELD(uint64_t get_des_get_tail:1,
 					    /**< If set and get_rmt is clear, return deschedule list indexes
                                                 rather than indexes for the specified qos level; if set and get_rmt is set, return
                                                 the tail pointer rather than the head pointer for the specified qos level. */
-		uint64_t get_rmt:1;	    /**< If set, return remote pointers rather than the local indexes for the specified qos level. */
-		uint64_t reserved_0_2:3;
-					    /**< Must be zero */
-#else
-		uint64_t reserved_0_2:3;
-		uint64_t get_rmt:1;
-		uint64_t get_des_get_tail:1;
-		uint64_t qosgrp:4;
-		uint64_t reserved_9_39:31;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t get_rmt:1,	    /**< If set, return remote pointers rather than the local indexes for the specified qos level. */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_2:3,   /**< Must be zero */
+		)))))))));
 	} sindexload;
 
     /**
      * Address for a Index/Pointer loads to get SSO internal state
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,
 					    /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 					    /**< Must be zero */
-		uint64_t is_io:1;	    /**< Must be one */
-		uint64_t did:8;		    /**< the ID of SSO - did<2:0> == 2 in this case */
-		uint64_t reserved_15_39:25;
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,	    /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		    /**< the ID of SSO - did<2:0> == 2 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_15_39:25,
 					    /**< Must be zero */
-		uint64_t qos_grp:6;	    /**< When opcode = IPL_IQ, this field specifies IQ (or QOS).
+		CVMX_BITFIELD_FIELD(uint64_t qos_grp:6,	    /**< When opcode = IPL_IQ, this field specifies IQ (or QOS).
                                                  When opcode = IPL_DESCHED, this field specifies the group.
                                                  This field is reserved for all other opcodes. */
-		uint64_t reserved_6_8:3;
-					    /**< Must be zero */
-		uint64_t opcode:3;	    /**< Read TAG/WQ pointer/pending tag/next potr */
-		uint64_t reserved_0_2:3;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_6_8:3,
 					    /**< Must be zero */
-#else
-		uint64_t reserved_0_2:3;
-		uint64_t opcode:3;
-		uint64_t reserved_3_5:3;
-		uint64_t qos_grp:6;
-		uint64_t reserved_15_39:25;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t opcode:3,	    /**< Read TAG/WQ pointer/pending tag/next potr */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_2:3, /**< Must be zero */
+		)))))))));
 	} sindexload_cn68xx;
 
     /**
@@ -616,22 +529,14 @@ typedef union {
      * entry can ever become available.)
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t mem_region:2;
+		CVMX_BITFIELD_FIELD(uint64_t mem_region:2,
 					    /**< Mips64 address region. Should be CVMX_IO_SEG */
-		uint64_t reserved_49_61:13;
-					    /**< Must be zero */
-		uint64_t is_io:1;	    /**< Must be one */
-		uint64_t did:8;		    /**< the ID of POW -- did<2:0> == 4 in this case */
-		uint64_t reserved_0_39:40;
+		CVMX_BITFIELD_FIELD(uint64_t reserved_49_61:13,
 					    /**< Must be zero */
-#else
-		uint64_t reserved_0_39:40;
-		uint64_t did:8;
-		uint64_t is_io:1;
-		uint64_t reserved_49_61:13;
-		uint64_t mem_region:2;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t is_io:1,	    /**< Must be one */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,		    /**< the ID of POW -- did<2:0> == 4 in this case */
+		CVMX_BITFIELD_FIELD(uint64_t reserved_0_39:40, /**< Must be zero */
+		)))));
 	} snull_rd;
 } cvmx_pow_load_addr_t;
 
@@ -645,8 +550,7 @@ typedef union {
      * Response to new work request loads
      */
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t no_work:1;	    /**< Set when no new work queue entry was returned.
+		CVMX_BITFIELD_FIELD(uint64_t no_work:1,	    /**< Set when no new work queue entry was returned.
                                                 If there was de-scheduled work, the HW will definitely
                                                 return it. When this bit is set, it could mean
                                                 either mean:
@@ -655,14 +559,10 @@ typedef union {
                                                     case can happen, regardless of the wait bit value
                                                     in the original request, when there is work
                                                     in the IQ's that is too deep down the list. */
-		uint64_t reserved_40_62:23;
-					    /**< Must be zero */
-		uint64_t addr:40;	    /**< 36 in O1 -- the work queue pointer */
-#else
-		uint64_t addr:40;
-		uint64_t reserved_40_62:23;
-		uint64_t no_work:1;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t pend_switch:1, /**< cn68XX and above, set if there was a pending tag switch*/
+		CVMX_BITFIELD_FIELD(uint64_t reserved_42_61:20,    /**< Must be zero */
+		CVMX_BITFIELD_FIELD(uint64_t addr:42,	    /**< 36 in O1 -- the work queue pointer */
+		))));
 	} s_work;
 
     /**
@@ -1504,54 +1404,32 @@ typedef union {
 	uint64_t u64;
 
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t scraddr:8;
+		CVMX_BITFIELD_FIELD(uint64_t scraddr:8,
 				    /**< the (64-bit word) location in scratchpad to write to (if len != 0) */
-		uint64_t len:8;
+		CVMX_BITFIELD_FIELD(uint64_t len:8,
 				    /**< the number of words in the response (0 => no response) */
-		uint64_t did:8;
+		CVMX_BITFIELD_FIELD(uint64_t did:8,
 				    /**< the ID of the device on the non-coherent bus */
-		uint64_t unused:36;
-		uint64_t wait:1;
+		CVMX_BITFIELD_FIELD(uint64_t unused:36,
+		CVMX_BITFIELD_FIELD(uint64_t wait:1,
 				    /**< if set, don't return load response until work is available */
-		uint64_t unused2:3;
-#else
-		uint64_t unused2:3;
-		uint64_t wait:1;
-		uint64_t unused:36;
-		uint64_t did:8;
-		uint64_t len:8;
-		uint64_t scraddr:8;
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t unused2:3,
+		))))));
 	} s;
 	struct {
-#ifdef __BIG_ENDIAN_BITFIELD
-		uint64_t scraddr:8;/**< the (64-bit word) location in scratchpad to write to (if len != 0) */
-		uint64_t len:8;    /**< the number of words in the response (0 => no response) */
-		uint64_t did:8;    /**< the ID of the device on the non-coherent bus */
-		uint64_t node:2;   /**< OCI node numbe, should always be local node */
-		uint64_t unused1:4;
-		uint64_t indexed:1;
-		uint64_t grouped:1;
-		uint64_t rtngrp:1;
-		uint64_t unused2:13;
-		uint64_t index_grp_mask:12;
-		uint64_t wait:1;   /**< if set, don't return load response until work is available */
-		uint64_t unused3:3;
-#else
-		uint64_t unused3:3;
-		uint64_t wait:1;   /**< if set, don't return load response until work is available */
-		uint64_t index_grp_mask:12;
-		uint64_t unused2:13;
-		uint64_t rtngrp:1;
-		uint64_t grouped:1;
-		uint64_t indexed:1;
-		uint64_t unused1:4;
-		uint64_t node:2;
-		uint64_t did:8;    /**< the ID of the device on the non-coherent bus */
-		uint64_t len:8;    /**< the number of words in the response (0 => no response) */
-		uint64_t scraddr:8;/**< the (64-bit word) location in scratchpad to write to (if len != 0) */
-#endif
+		CVMX_BITFIELD_FIELD(uint64_t scraddr:8,/**< the (64-bit word) location in scratchpad to write to (if len != 0) */
+		CVMX_BITFIELD_FIELD(uint64_t len:8,    /**< the number of words in the response (0 => no response) */
+		CVMX_BITFIELD_FIELD(uint64_t did:8,    /**< the ID of the device on the non-coherent bus */
+		CVMX_BITFIELD_FIELD(uint64_t node:2,   /**< OCI node numbe, should always be local node */
+		CVMX_BITFIELD_FIELD(uint64_t unused1:4,
+		CVMX_BITFIELD_FIELD(uint64_t indexed:1,
+		CVMX_BITFIELD_FIELD(uint64_t grouped:1,
+		CVMX_BITFIELD_FIELD(uint64_t rtngrp:1,
+		CVMX_BITFIELD_FIELD(uint64_t unused2:13,
+		CVMX_BITFIELD_FIELD(uint64_t index_grp_mask:12,
+		CVMX_BITFIELD_FIELD(uint64_t wait:1,   /**< if set, don't return load response until work is available */
+		CVMX_BITFIELD_FIELD(uint64_t unused3:3,
+		))))))))))));
 	} s_cn78xx;
 } cvmx_pow_iobdma_store_t;
 
@@ -1828,11 +1706,13 @@ static inline void cvmx_pow_work_request_async_nocheck(int scr_addr, cvmx_pow_wa
 }
 
 /**
- * Asynchronous work request.  Work is requested from the POW unit, and should later
+ * Asynchronous work request.  Work is requested from the SSO unit, and should later
  * be checked with function cvmx_pow_work_response_async.
  * This function does NOT wait for previous tag switches to complete,
  * so the caller must ensure that there is not a pending tag switch.
  *
+ * Only works on CN78XX style SSO.
+ *
  * @param scr_addr Scratch memory address that response will be returned to,
  *                  which is either a valid WQE, or a response with the invalid bit set.
  *                  Byte address, must be 8 byte aligned.
@@ -1844,32 +1724,68 @@ static inline void cvmx_sso_work_request_grp_async_nocheck(int scr_addr,
 	cvmx_xgrp_t xgrp, cvmx_pow_wait_t wait)
 {
 	cvmx_pow_iobdma_store_t data;
-	if (CVMX_ENABLE_POW_CHECKS)
+	unsigned int node = cvmx_get_node_num();
+	if (CVMX_ENABLE_POW_CHECKS) {
 		__cvmx_pow_warn_if_pending_switch(__func__);
+		cvmx_warn_if(!octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE), "Not CN78XX");
+	}
 
 	/* scr_addr must be 8 byte aligned */
 	data.u64 = 0;
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		unsigned int node = cvmx_get_node_num();
-		data.s_cn78xx.scraddr = scr_addr >> 3;
-		data.s_cn78xx.len = 1;
-		data.s_cn78xx.did = CVMX_OCT_DID_TAG_SWTAG;
-		data.s_cn78xx.grouped = 1;
-		data.s_cn78xx.index_grp_mask = (node << 8) | xgrp.xgrp ;
-		data.s_cn78xx.wait = wait;
-		data.s_cn78xx.node = node;
-	} else {
-		/* GRP not supported on older chips, ignore it */
-		data.s.scraddr = scr_addr >> 3;
-		data.s.len = 1;
-		data.s.did = CVMX_OCT_DID_TAG_SWTAG;
-		data.s.wait = wait;
-	}
+	data.s_cn78xx.scraddr = scr_addr >> 3;
+	data.s_cn78xx.len = 1;
+	data.s_cn78xx.did = CVMX_OCT_DID_TAG_SWTAG;
+	data.s_cn78xx.grouped = 1;
+	data.s_cn78xx.index_grp_mask = (node << 8) | xgrp.xgrp ;
+	data.s_cn78xx.wait = wait;
+	data.s_cn78xx.node = node;
 
 	cvmx_send_single(data.u64);
 }
 
 /**
+ * Synchronous work request.  Requests work from a specific SSO group.
+ * This function waits for any previous tag switch to complete before
+ * requesting the new work.
+ *
+ * Only works on CN78XX style SSO.
+ *
+ * @param lgrp The local group number (within the SSO of the node of the caller) from which to get the work.
+ * @param wait   When set, call stalls until work becomes avaiable, or times out.
+ *               If not set, returns immediately.
+ *
+ * @return Returns the WQE pointer from SSO. Returns NULL if no work was available.
+ */
+static inline void *cvmx_sso_work_request_grp_sync_nocheck(unsigned int lgrp, cvmx_pow_wait_t wait)
+{
+	cvmx_pow_load_addr_t ptr;
+	cvmx_pow_tag_load_resp_t result;
+	unsigned int node = cvmx_get_node_num() & 3;
+
+	if (CVMX_ENABLE_POW_CHECKS) {
+		__cvmx_pow_warn_if_pending_switch(__func__);
+		cvmx_warn_if(!octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE), "Not CN78XX");
+	}
+
+	ptr.u64 = 0;
+
+	ptr.swork_78xx.mem_region = CVMX_IO_SEG;
+	ptr.swork_78xx.is_io = 1;
+	ptr.swork_78xx.did = CVMX_OCT_DID_TAG_SWTAG;
+	ptr.swork_78xx.node = node;
+	ptr.swork_78xx.grouped = 1;
+	ptr.swork_78xx.index = (lgrp & 0xff) | node << 8;
+	ptr.swork_78xx.wait = wait;
+
+	result.u64 = cvmx_read_csr(ptr.u64);
+
+	if (result.s_work.no_work)
+		return NULL;
+	else
+		return cvmx_phys_to_ptr(result.s_work.addr);
+}
+
+/**
  * Asynchronous work request.  Work is requested from the POW unit, and should later
  * be checked with function cvmx_pow_work_response_async.
  * This function waits for any previous tag switch to complete before
@@ -2436,32 +2352,50 @@ static inline void cvmx_pow_work_submit_node(cvmx_wqe_t * wqp, uint32_t tag, cvm
  *               Each 1 bit in the mask enables the core to accept work from
  *               the corresponding group.
  *               The CN68XX supports 64 groups, earlier models only support
- *               16 groups. The CN78XX in backwards compatibility mode
- *               allows up to 32 groups.
+ *               16 groups.
+ *
+ * The CN78XX in backwards compatibility mode allows up to 32 groups,
+ * so the 'mask' argument has one bit for every of the legacy
+ * groups, and a '1' in the mask causes a total of 8 groups
+ * which share the legacy group numbher and 8 qos levels,
+ * to be enabled for the calling processor core.
+ * A '0' in the mask will disable the current core
+ * from receiving work from the associated group.
  */
 static inline void cvmx_pow_set_group_mask(uint64_t core_num, uint64_t mask)
 {
-
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		const unsigned mask_set = 0;
 		cvmx_sso_ppx_sx_grpmskx_t grp_msk;
-		unsigned node = cvmx_get_node_num();
-		unsigned s, g, xg;
+		unsigned core, node;
+		unsigned rix;	/* Register index */
+		unsigned grp;	/* Legacy group # */
+		unsigned bit;	/* bit index */
+		unsigned xgrp;	/* native group # */
 
 		cvmx_warn_if(mask & (~0xffffffffull),
 			"%s group number range exceeded: %#llx\n",
 			__FUNCTION__, (unsigned long long) mask);
 
-		for(s = 0; s < (CVMX_SSO_NUM_XGRP/64); s ++ ) {
-			grp_msk.s.grp_msk = 0ull;
-			for(g = 0; g < 64; g++) {
-				xg = (s << 6) | g;
-				xg = (xg >> 3) & 0x1f;
-				if(mask & (1ull << xg))
-					grp_msk.s.grp_msk |= 1ull << g;
+		node = cvmx_coremask_core_to_node(core_num);
+		core = cvmx_coremask_core_on_node(core_num);
+	
+		/* 256 groups divided into 4 X 64 bit registers */
+		for (rix = 0; rix < (CVMX_SSO_NUM_XGRP >> 6); rix ++ ) {
+			grp_msk.u64 = 0;
+			for(bit = 0; bit < 64; bit++) {
+				/* 8-bit native XGRP number */
+				xgrp = (rix << 6) | bit;
+				/* Legacy 5-bit group number */
+				grp = (xgrp >> 3) & 0x1f;
+				/* Inspect legacy mask by legacy group */
+				if(mask & (1ull << grp))
+					grp_msk.s.grp_msk |= 1ull << bit;
+				/* Pre-set to all 0's */
 			}
 
 			cvmx_write_csr_node(node,
-				CVMX_SSO_PPX_SX_GRPMSKX(core_num, 0, s),
+				CVMX_SSO_PPX_SX_GRPMSKX(core, mask_set, rix),
 				grp_msk.u64);
 		}
 	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE)) {
@@ -3005,13 +2939,15 @@ static inline uint64_t cvmx_sso_get_total_wqe_count(void)
 
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 	{
-		cvmx_sso_grpx_aq_cnt_t sso_iq_com_cnt;
+		cvmx_sso_grpx_aq_cnt_t aq_cnt;
+		int node = cvmx_get_node_num();
 		int grp = 0;
 		uint64_t cnt = 0;
 
 		for( grp = 0; grp < CVMX_SSO_NUM_XGRP; grp++) {
-			sso_iq_com_cnt.u64 = cvmx_read_csr_node(0,CVMX_SSO_GRPX_AQ_CNT(grp));
-			cnt += sso_iq_com_cnt.u64;
+			aq_cnt.u64 = cvmx_read_csr_node(node,
+					CVMX_SSO_GRPX_AQ_CNT(grp));
+			cnt += aq_cnt.s.aq_cnt;
 		}
 		return cnt;
 	}
@@ -3062,6 +2998,19 @@ extern void cvmx_pow_display(void *buffer, int buffer_size);
  */
 extern int cvmx_pow_get_num_entries(void);
 
+/**
+ * This will allocate count number of SSO groups on the specified node to the
+ * calling application. These groups will be for exclusive use of the application
+ * until they are freed.
+ * @param groups_allocated is an array of length count allocated by
+ *			  the application before invoking the
+ *			  cvmx_sso_allocate_groups.  On return it will
+ *			  contain the index numbers of the groups allocated.
+ * @return 0 on success and -1 on failure.
+ */
+int cvmx_sso_allocate_groups(int node, int groups_allocated[], int count);
+int cvmx_sso_allocate_group(int node);
+
 #ifdef  __cplusplus
 /* *INDENT-OFF* */
 }
diff --git a/arch/mips/include/asm/octeon/cvmx-qlm.h b/arch/mips/include/asm/octeon/cvmx-qlm.h
index 97525df..561205a 100644
--- a/arch/mips/include/asm/octeon/cvmx-qlm.h
+++ b/arch/mips/include/asm/octeon/cvmx-qlm.h
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 93892 $<hr>
+ * <hr>$Revision: 96753 $<hr>
  */
 
 #ifndef __CVMX_QLM_H__
@@ -223,6 +223,7 @@ enum cvmx_pemx_cfg_mode {
  * Read QLM and return mode.
  */
 extern enum cvmx_qlm_mode cvmx_qlm_get_mode(int qlm);
+enum cvmx_qlm_mode cvmx_qlm_get_mode_cn78xx(int node, int qlm);
 extern enum cvmx_qlm_mode cvmx_qlm_get_dlm_mode(int dlm_mode, int interface);
 
 extern void cvmx_qlm_display_registers(int qlm);
diff --git a/arch/mips/include/asm/octeon/cvmx-rnm-defs.h b/arch/mips/include/asm/octeon/cvmx-rnm-defs.h
index 855c175..b1bbfb5 100644
--- a/arch/mips/include/asm/octeon/cvmx-rnm-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-rnm-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -125,6 +125,7 @@ union cvmx_rnm_bist_status {
 	struct cvmx_rnm_bist_status_s         cn68xx;
 	struct cvmx_rnm_bist_status_s         cn68xxp1;
 	struct cvmx_rnm_bist_status_s         cn70xx;
+	struct cvmx_rnm_bist_status_s         cn70xxp1;
 	struct cvmx_rnm_bist_status_s         cn78xx;
 	struct cvmx_rnm_bist_status_s         cnf71xx;
 };
@@ -239,6 +240,7 @@ union cvmx_rnm_ctl_status {
 	struct cvmx_rnm_ctl_status_cn63xx     cn68xx;
 	struct cvmx_rnm_ctl_status_cn63xx     cn68xxp1;
 	struct cvmx_rnm_ctl_status_s          cn70xx;
+	struct cvmx_rnm_ctl_status_s          cn70xxp1;
 	struct cvmx_rnm_ctl_status_s          cn78xx;
 	struct cvmx_rnm_ctl_status_s          cnf71xx;
 };
@@ -266,6 +268,7 @@ union cvmx_rnm_eer_dbg {
 	struct cvmx_rnm_eer_dbg_s             cn68xx;
 	struct cvmx_rnm_eer_dbg_s             cn68xxp1;
 	struct cvmx_rnm_eer_dbg_s             cn70xx;
+	struct cvmx_rnm_eer_dbg_s             cn70xxp1;
 	struct cvmx_rnm_eer_dbg_s             cn78xx;
 	struct cvmx_rnm_eer_dbg_s             cnf71xx;
 };
@@ -295,6 +298,7 @@ union cvmx_rnm_eer_key {
 	struct cvmx_rnm_eer_key_s             cn68xx;
 	struct cvmx_rnm_eer_key_s             cn68xxp1;
 	struct cvmx_rnm_eer_key_s             cn70xx;
+	struct cvmx_rnm_eer_key_s             cn70xxp1;
 	struct cvmx_rnm_eer_key_s             cn78xx;
 	struct cvmx_rnm_eer_key_s             cnf71xx;
 };
@@ -303,8 +307,13 @@ typedef union cvmx_rnm_eer_key cvmx_rnm_eer_key_t;
 /**
  * cvmx_rnm_serial_num
  *
+ * RNM_SERIAL_NUM = RNM's fuse serial number register
+ *
  * The RNM's fuse serial number register
  *
+ * Notes:
+ * Added RNM_SERIAL_NUM in pass 2.0
+ *
  */
 union cvmx_rnm_serial_num {
 	uint64_t u64;
@@ -321,6 +330,7 @@ union cvmx_rnm_serial_num {
 	struct cvmx_rnm_serial_num_s          cn68xx;
 	struct cvmx_rnm_serial_num_s          cn68xxp1;
 	struct cvmx_rnm_serial_num_s          cn70xx;
+	struct cvmx_rnm_serial_num_s          cn70xxp1;
 	struct cvmx_rnm_serial_num_s          cn78xx;
 	struct cvmx_rnm_serial_num_s          cnf71xx;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-rst-defs.h b/arch/mips/include/asm/octeon/cvmx-rst-defs.h
index e996d0b..398c6a9 100644
--- a/arch/mips/include/asm/octeon/cvmx-rst-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-rst-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -201,10 +201,7 @@ union cvmx_rst_boot {
 	uint64_t c_mul                        : 7;  /**< Core-clock multiplier. C_MUL = (core-clock speed) / (ref-clock speed). 'ref-clock speed'
                                                          should always be 50MHz. */
 	uint64_t pnr_mul                      : 6;  /**< Coprocessor-clock multiplier. PNR_MUL = (coprocessor-clock speed) /(ref-clock speed).
-                                                         'ref-clock speed' should always be 50MHz.
-                                                         For PCIe Gen1, the coprocessor-clock speed must be greater than 250MHz; for PCIe Gen2, the
-                                                         coprocessor-clock speed must be greater than 500MHz; for PCIe Gen3, the coprocessor-clock
-                                                         speed must be greater than 800MHz. */
+                                                         'ref-clock speed' should always be 50MHz. */
 	uint64_t reserved_21_23               : 3;
 	uint64_t lboot_oci                    : 3;  /**< Last boot cause mask; resets only with DCOK.
                                                          <20> Warm reset due to OCI Link 2 going down.
@@ -250,6 +247,7 @@ union cvmx_rst_boot {
 #endif
 	} s;
 	struct cvmx_rst_boot_s                cn70xx;
+	struct cvmx_rst_boot_s                cn70xxp1;
 	struct cvmx_rst_boot_s                cn78xx;
 };
 typedef union cvmx_rst_boot cvmx_rst_boot_t;
@@ -278,6 +276,7 @@ union cvmx_rst_cfg {
 #endif
 	} s;
 	struct cvmx_rst_cfg_s                 cn70xx;
+	struct cvmx_rst_cfg_s                 cn70xxp1;
 	struct cvmx_rst_cfg_s                 cn78xx;
 };
 typedef union cvmx_rst_cfg cvmx_rst_cfg_t;
@@ -298,6 +297,7 @@ union cvmx_rst_ckill {
 #endif
 	} s;
 	struct cvmx_rst_ckill_s               cn70xx;
+	struct cvmx_rst_ckill_s               cn70xxp1;
 	struct cvmx_rst_ckill_s               cn78xx;
 };
 typedef union cvmx_rst_ckill cvmx_rst_ckill_t;
@@ -325,10 +325,8 @@ union cvmx_rst_ctlx {
                                                          Note that a link-down or hot-reset event can never cause a warm chip reset when the
                                                          controller is in reset (i.e. can never cause a warm reset when RST_DONE = 0). */
 	uint64_t host_mode                    : 1;  /**< Read-only access to the corresponding PEM(0..3)_CFG[HOSTMD] field indicating PEMn is root
-                                                         complex (host).
-                                                         For controllers 0 and 2 the inital value is determined by straps.  For controllers 1 and 3
-                                                         these field
-                                                         is initially set as host. */
+                                                         complex (host). For controllers 0 and 2  the initial value is determined by straps. For
+                                                         controllers 1 and 3 this field is initially set as host. */
 	uint64_t reserved_4_5                 : 2;
 	uint64_t rst_drv                      : 1;  /**< Controls whether PERST*_L is driven. A warm/soft reset does not change this field. On cold
                                                          reset, this field is initialized as follows:
@@ -369,6 +367,7 @@ union cvmx_rst_ctlx {
 #endif
 	} s;
 	struct cvmx_rst_ctlx_s                cn70xx;
+	struct cvmx_rst_ctlx_s                cn70xxp1;
 	struct cvmx_rst_ctlx_s                cn78xx;
 };
 typedef union cvmx_rst_ctlx cvmx_rst_ctlx_t;
@@ -396,6 +395,7 @@ union cvmx_rst_delay {
 #endif
 	} s;
 	struct cvmx_rst_delay_s               cn70xx;
+	struct cvmx_rst_delay_s               cn70xxp1;
 	struct cvmx_rst_delay_s               cn78xx;
 };
 typedef union cvmx_rst_delay cvmx_rst_delay_t;
@@ -436,6 +436,7 @@ union cvmx_rst_int {
 	uint64_t reserved_11_63               : 53;
 #endif
 	} cn70xx;
+	struct cvmx_rst_int_cn70xx            cn70xxp1;
 	struct cvmx_rst_int_s                 cn78xx;
 };
 typedef union cvmx_rst_int cvmx_rst_int_t;
@@ -449,7 +450,9 @@ union cvmx_rst_ocx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_3_63                : 61;
 	uint64_t rst_link                     : 3;  /**< Controls whether corresponding OCX link going down causes a chip reset. A warm/soft reset
-                                                         does not change this field. On cold reset, this field is initialized to 0. */
+                                                         does not change this field. On cold reset, this field is initialized to 0.  See
+                                                         OCX_COM_LINK(0..2)_CTL
+                                                         for a description of what events can contribute to the link_down condition. */
 #else
 	uint64_t rst_link                     : 3;
 	uint64_t reserved_3_63                : 61;
@@ -488,10 +491,10 @@ union cvmx_rst_pp_power {
 	struct cvmx_rst_pp_power_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_48_63               : 16;
-	uint64_t gate                         : 48; /**< Powerdown enable. When both a bit and the corresponding CIU3_PP_RST bit are set, the core
+	uint64_t gate                         : 48; /**< Powerdown enable. When both a bit and the corresponding CIU_PP_RST bit are set, the core
                                                          has voltage removed to save power. In typical operation these bits are setup during
-                                                         initialization and PP resets are controlled through CIU3_PP_RST. These bits may only be
-                                                         changed when the corresponding core is in reset using CIU3_PP_RST. */
+                                                         initialization and PP resets are controlled through CIU_PP_RST. These bits may only be
+                                                         changed when the corresponding core is in reset using CIU_PP_RST. */
 #else
 	uint64_t gate                         : 48;
 	uint64_t reserved_48_63               : 16;
@@ -506,6 +509,7 @@ union cvmx_rst_pp_power {
 	uint64_t reserved_4_63                : 60;
 #endif
 	} cn70xx;
+	struct cvmx_rst_pp_power_cn70xx       cn70xxp1;
 	struct cvmx_rst_pp_power_s            cn78xx;
 };
 typedef union cvmx_rst_pp_power cvmx_rst_pp_power_t;
@@ -530,6 +534,7 @@ union cvmx_rst_soft_prstx {
 #endif
 	} s;
 	struct cvmx_rst_soft_prstx_s          cn70xx;
+	struct cvmx_rst_soft_prstx_s          cn70xxp1;
 	struct cvmx_rst_soft_prstx_s          cn78xx;
 };
 typedef union cvmx_rst_soft_prstx cvmx_rst_soft_prstx_t;
@@ -550,6 +555,7 @@ union cvmx_rst_soft_rst {
 #endif
 	} s;
 	struct cvmx_rst_soft_rst_s            cn70xx;
+	struct cvmx_rst_soft_rst_s            cn70xxp1;
 	struct cvmx_rst_soft_rst_s            cn78xx;
 };
 typedef union cvmx_rst_soft_rst cvmx_rst_soft_rst_t;
diff --git a/arch/mips/include/asm/octeon/cvmx-sli-defs.h b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
index 86e8dd5..d47e2b3 100644
--- a/arch/mips/include/asm/octeon/cvmx-sli-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sli-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -1640,6 +1640,7 @@ union cvmx_sli_bist_status {
 	uint64_t reserved_31_63               : 33;
 #endif
 	} cn70xx;
+	struct cvmx_sli_bist_status_cn70xx    cn70xxp1;
 	struct cvmx_sli_bist_status_s         cn78xx;
 	struct cvmx_sli_bist_status_cn61xx    cnf71xx;
 };
@@ -1719,11 +1720,12 @@ union cvmx_sli_ctl_portx {
 	struct cvmx_sli_ctl_portx_s           cn68xx;
 	struct cvmx_sli_ctl_portx_s           cn68xxp1;
 	struct cvmx_sli_ctl_portx_s           cn70xx;
+	struct cvmx_sli_ctl_portx_s           cn70xxp1;
 	struct cvmx_sli_ctl_portx_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_18_63               : 46;
 	uint64_t dis_port                     : 1;  /**< When set, the output to the MAC is disabled. This occurs when the MAC reset line
-                                                         transitions from de-asserted to asserted. Writing a 1 to this location clears this
+                                                         transitions from deasserted to asserted. Writing a 1 to this location clears this
                                                          condition when the MAC is no longer in reset and the output to the MAC is at the beginning
                                                          of a transfer. */
 	uint64_t waitl_com                    : 1;  /**< When set to 1, causes the SLI to wait for a commit from the L2C before sending additional
@@ -1769,8 +1771,8 @@ union cvmx_sli_ctl_status {
 	struct cvmx_sli_ctl_status_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_32_63               : 32;
-	uint64_t m2s1_ncbi                    : 4;  /**< Contains the IOBI that traffic from M2S1 is placed on. */
-	uint64_t m2s0_ncbi                    : 4;  /**< Contains the IOBI that traffic from M2S0 is placed on. */
+	uint64_t m2s1_ncbi                    : 4;  /**< Contains the IOBI that traffic from M2S1 is placed on. Values 2-15 are reserved. */
+	uint64_t m2s0_ncbi                    : 4;  /**< Contains the IOBI that traffic from M2S0 is placed on. Values 2-15 are reserved. */
 	uint64_t oci_id                       : 4;  /**< The OCI ID. */
 	uint64_t p1_ntags                     : 6;  /**< Number of tags available for MAC port 1.
                                                          In RC mode, one tag is needed for each outbound TLP that requires a CPL TLP.
@@ -1843,6 +1845,7 @@ union cvmx_sli_ctl_status {
 	struct cvmx_sli_ctl_status_cn63xx     cn68xx;
 	struct cvmx_sli_ctl_status_cn63xx     cn68xxp1;
 	struct cvmx_sli_ctl_status_cn63xx     cn70xx;
+	struct cvmx_sli_ctl_status_cn63xx     cn70xxp1;
 	struct cvmx_sli_ctl_status_s          cn78xx;
 	struct cvmx_sli_ctl_status_cn61xx     cnf71xx;
 };
@@ -1886,6 +1889,7 @@ union cvmx_sli_data_out_cnt {
 	struct cvmx_sli_data_out_cnt_s        cn68xx;
 	struct cvmx_sli_data_out_cnt_s        cn68xxp1;
 	struct cvmx_sli_data_out_cnt_s        cn70xx;
+	struct cvmx_sli_data_out_cnt_s        cn70xxp1;
 	struct cvmx_sli_data_out_cnt_s        cn78xx;
 	struct cvmx_sli_data_out_cnt_s        cnf71xx;
 };
@@ -1996,6 +2000,7 @@ union cvmx_sli_dmax_cnt {
 	struct cvmx_sli_dmax_cnt_s            cn68xx;
 	struct cvmx_sli_dmax_cnt_s            cn68xxp1;
 	struct cvmx_sli_dmax_cnt_s            cn70xx;
+	struct cvmx_sli_dmax_cnt_s            cn70xxp1;
 	struct cvmx_sli_dmax_cnt_s            cn78xx;
 	struct cvmx_sli_dmax_cnt_s            cnf71xx;
 };
@@ -2031,6 +2036,7 @@ union cvmx_sli_dmax_int_level {
 	struct cvmx_sli_dmax_int_level_s      cn68xx;
 	struct cvmx_sli_dmax_int_level_s      cn68xxp1;
 	struct cvmx_sli_dmax_int_level_s      cn70xx;
+	struct cvmx_sli_dmax_int_level_s      cn70xxp1;
 	struct cvmx_sli_dmax_int_level_s      cn78xx;
 	struct cvmx_sli_dmax_int_level_s      cnf71xx;
 };
@@ -2062,6 +2068,7 @@ union cvmx_sli_dmax_tim {
 	struct cvmx_sli_dmax_tim_s            cn68xx;
 	struct cvmx_sli_dmax_tim_s            cn68xxp1;
 	struct cvmx_sli_dmax_tim_s            cn70xx;
+	struct cvmx_sli_dmax_tim_s            cn70xxp1;
 	struct cvmx_sli_dmax_tim_s            cn78xx;
 	struct cvmx_sli_dmax_tim_s            cnf71xx;
 };
@@ -2614,6 +2621,7 @@ union cvmx_sli_int_enb_ciu {
 	uint64_t reserved_61_63               : 3;
 #endif
 	} cn70xx;
+	struct cvmx_sli_int_enb_ciu_cn70xx    cn70xxp1;
 	struct cvmx_sli_int_enb_ciu_cn61xx    cnf71xx;
 };
 typedef union cvmx_sli_int_enb_ciu cvmx_sli_int_enb_ciu_t;
@@ -3219,6 +3227,7 @@ union cvmx_sli_int_enb_portx {
 	uint64_t reserved_61_63               : 3;
 #endif
 	} cn70xx;
+	struct cvmx_sli_int_enb_portx_cn70xx  cn70xxp1;
 	struct cvmx_sli_int_enb_portx_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
@@ -3263,8 +3272,7 @@ union cvmx_sli_int_enb_portx {
 	uint64_t mio_int3                     : 1;  /**< Enables SLI_INT_SUM[MIO_INT3] to generate an interrupt to the MAC core for MSI/INTA. */
 	uint64_t mio_int2                     : 1;  /**< Enables SLI_INT_SUM[MIO_INT2] to generate an interrupt to the MAC core for MSI/INTA. */
 	uint64_t ptime                        : 1;  /**< Enables SLI_INT_SUM[PTIME] to generate an interrupt to the MAC core for MSI/INTA. */
-	uint64_t pcnt                         : 1;  /**< Enables SLI_INT_SUM[4] to generate an
-                                                         interrupt to the PCIE core for MSI/inta. */
+	uint64_t pcnt                         : 1;  /**< Enables SLI_INT_SUM[PCNT] to generate an interrupt to the PCIE core for MSI/INTA. */
 	uint64_t reserved_1_3                 : 3;
 	uint64_t rml_to                       : 1;  /**< Enables SLI_INT_SUM[RML_TO] to generate an interrupt to the PCIE core for MSI/INTA. */
 #else
@@ -4044,6 +4052,7 @@ union cvmx_sli_int_sum {
 	uint64_t reserved_61_63               : 3;
 #endif
 	} cn70xx;
+	struct cvmx_sli_int_sum_cn70xx        cn70xxp1;
 	struct cvmx_sli_int_sum_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
@@ -4206,6 +4215,7 @@ union cvmx_sli_last_win_rdata0 {
 	struct cvmx_sli_last_win_rdata0_s     cn68xx;
 	struct cvmx_sli_last_win_rdata0_s     cn68xxp1;
 	struct cvmx_sli_last_win_rdata0_s     cn70xx;
+	struct cvmx_sli_last_win_rdata0_s     cn70xxp1;
 	struct cvmx_sli_last_win_rdata0_s     cnf71xx;
 };
 typedef union cvmx_sli_last_win_rdata0 cvmx_sli_last_win_rdata0_t;
@@ -4232,6 +4242,7 @@ union cvmx_sli_last_win_rdata1 {
 	struct cvmx_sli_last_win_rdata1_s     cn68xx;
 	struct cvmx_sli_last_win_rdata1_s     cn68xxp1;
 	struct cvmx_sli_last_win_rdata1_s     cn70xx;
+	struct cvmx_sli_last_win_rdata1_s     cn70xxp1;
 	struct cvmx_sli_last_win_rdata1_s     cnf71xx;
 };
 typedef union cvmx_sli_last_win_rdata1 cvmx_sli_last_win_rdata1_t;
@@ -4254,6 +4265,7 @@ union cvmx_sli_last_win_rdata2 {
 	struct cvmx_sli_last_win_rdata2_s     cn61xx;
 	struct cvmx_sli_last_win_rdata2_s     cn66xx;
 	struct cvmx_sli_last_win_rdata2_s     cn70xx;
+	struct cvmx_sli_last_win_rdata2_s     cn70xxp1;
 	struct cvmx_sli_last_win_rdata2_s     cnf71xx;
 };
 typedef union cvmx_sli_last_win_rdata2 cvmx_sli_last_win_rdata2_t;
@@ -4276,6 +4288,7 @@ union cvmx_sli_last_win_rdata3 {
 	struct cvmx_sli_last_win_rdata3_s     cn61xx;
 	struct cvmx_sli_last_win_rdata3_s     cn66xx;
 	struct cvmx_sli_last_win_rdata3_s     cn70xx;
+	struct cvmx_sli_last_win_rdata3_s     cn70xxp1;
 	struct cvmx_sli_last_win_rdata3_s     cnf71xx;
 };
 typedef union cvmx_sli_last_win_rdata3 cvmx_sli_last_win_rdata3_t;
@@ -4358,6 +4371,7 @@ union cvmx_sli_mac_credit_cnt {
 	struct cvmx_sli_mac_credit_cnt_s      cn68xx;
 	struct cvmx_sli_mac_credit_cnt_s      cn68xxp1;
 	struct cvmx_sli_mac_credit_cnt_s      cn70xx;
+	struct cvmx_sli_mac_credit_cnt_s      cn70xxp1;
 	struct cvmx_sli_mac_credit_cnt_s      cn78xx;
 	struct cvmx_sli_mac_credit_cnt_s      cnf71xx;
 };
@@ -4413,6 +4427,7 @@ union cvmx_sli_mac_credit_cnt2 {
 	struct cvmx_sli_mac_credit_cnt2_s     cn61xx;
 	struct cvmx_sli_mac_credit_cnt2_s     cn66xx;
 	struct cvmx_sli_mac_credit_cnt2_s     cn70xx;
+	struct cvmx_sli_mac_credit_cnt2_s     cn70xxp1;
 	struct cvmx_sli_mac_credit_cnt2_s     cn78xx;
 	struct cvmx_sli_mac_credit_cnt2_s     cnf71xx;
 };
@@ -4451,6 +4466,7 @@ union cvmx_sli_mac_number {
 	struct cvmx_sli_mac_number_cn63xx     cn68xx;
 	struct cvmx_sli_mac_number_cn63xx     cn68xxp1;
 	struct cvmx_sli_mac_number_s          cn70xx;
+	struct cvmx_sli_mac_number_s          cn70xxp1;
 	struct cvmx_sli_mac_number_s          cn78xx;
 	struct cvmx_sli_mac_number_s          cnf71xx;
 };
@@ -4488,6 +4504,7 @@ union cvmx_sli_mem_access_ctl {
 	struct cvmx_sli_mem_access_ctl_s      cn68xx;
 	struct cvmx_sli_mem_access_ctl_s      cn68xxp1;
 	struct cvmx_sli_mem_access_ctl_s      cn70xx;
+	struct cvmx_sli_mem_access_ctl_s      cn70xxp1;
 	struct cvmx_sli_mem_access_ctl_s      cn78xx;
 	struct cvmx_sli_mem_access_ctl_s      cnf71xx;
 };
@@ -4633,6 +4650,7 @@ union cvmx_sli_mem_access_subidx {
 	} cn68xx;
 	struct cvmx_sli_mem_access_subidx_cn68xx cn68xxp1;
 	struct cvmx_sli_mem_access_subidx_cn61xx cn70xx;
+	struct cvmx_sli_mem_access_subidx_cn61xx cn70xxp1;
 	struct cvmx_sli_mem_access_subidx_cn61xx cn78xx;
 	struct cvmx_sli_mem_access_subidx_cn61xx cnf71xx;
 };
@@ -4770,6 +4788,7 @@ union cvmx_sli_msi_enb0 {
 	struct cvmx_sli_msi_enb0_s            cn68xx;
 	struct cvmx_sli_msi_enb0_s            cn68xxp1;
 	struct cvmx_sli_msi_enb0_s            cn70xx;
+	struct cvmx_sli_msi_enb0_s            cn70xxp1;
 	struct cvmx_sli_msi_enb0_s            cnf71xx;
 };
 typedef union cvmx_sli_msi_enb0 cvmx_sli_msi_enb0_t;
@@ -4796,6 +4815,7 @@ union cvmx_sli_msi_enb1 {
 	struct cvmx_sli_msi_enb1_s            cn68xx;
 	struct cvmx_sli_msi_enb1_s            cn68xxp1;
 	struct cvmx_sli_msi_enb1_s            cn70xx;
+	struct cvmx_sli_msi_enb1_s            cn70xxp1;
 	struct cvmx_sli_msi_enb1_s            cnf71xx;
 };
 typedef union cvmx_sli_msi_enb1 cvmx_sli_msi_enb1_t;
@@ -4822,6 +4842,7 @@ union cvmx_sli_msi_enb2 {
 	struct cvmx_sli_msi_enb2_s            cn68xx;
 	struct cvmx_sli_msi_enb2_s            cn68xxp1;
 	struct cvmx_sli_msi_enb2_s            cn70xx;
+	struct cvmx_sli_msi_enb2_s            cn70xxp1;
 	struct cvmx_sli_msi_enb2_s            cnf71xx;
 };
 typedef union cvmx_sli_msi_enb2 cvmx_sli_msi_enb2_t;
@@ -4848,6 +4869,7 @@ union cvmx_sli_msi_enb3 {
 	struct cvmx_sli_msi_enb3_s            cn68xx;
 	struct cvmx_sli_msi_enb3_s            cn68xxp1;
 	struct cvmx_sli_msi_enb3_s            cn70xx;
+	struct cvmx_sli_msi_enb3_s            cn70xxp1;
 	struct cvmx_sli_msi_enb3_s            cnf71xx;
 };
 typedef union cvmx_sli_msi_enb3 cvmx_sli_msi_enb3_t;
@@ -4874,6 +4896,7 @@ union cvmx_sli_msi_rcv0 {
 	struct cvmx_sli_msi_rcv0_s            cn68xx;
 	struct cvmx_sli_msi_rcv0_s            cn68xxp1;
 	struct cvmx_sli_msi_rcv0_s            cn70xx;
+	struct cvmx_sli_msi_rcv0_s            cn70xxp1;
 	struct cvmx_sli_msi_rcv0_s            cn78xx;
 	struct cvmx_sli_msi_rcv0_s            cnf71xx;
 };
@@ -4901,6 +4924,7 @@ union cvmx_sli_msi_rcv1 {
 	struct cvmx_sli_msi_rcv1_s            cn68xx;
 	struct cvmx_sli_msi_rcv1_s            cn68xxp1;
 	struct cvmx_sli_msi_rcv1_s            cn70xx;
+	struct cvmx_sli_msi_rcv1_s            cn70xxp1;
 	struct cvmx_sli_msi_rcv1_s            cn78xx;
 	struct cvmx_sli_msi_rcv1_s            cnf71xx;
 };
@@ -4928,6 +4952,7 @@ union cvmx_sli_msi_rcv2 {
 	struct cvmx_sli_msi_rcv2_s            cn68xx;
 	struct cvmx_sli_msi_rcv2_s            cn68xxp1;
 	struct cvmx_sli_msi_rcv2_s            cn70xx;
+	struct cvmx_sli_msi_rcv2_s            cn70xxp1;
 	struct cvmx_sli_msi_rcv2_s            cn78xx;
 	struct cvmx_sli_msi_rcv2_s            cnf71xx;
 };
@@ -4955,6 +4980,7 @@ union cvmx_sli_msi_rcv3 {
 	struct cvmx_sli_msi_rcv3_s            cn68xx;
 	struct cvmx_sli_msi_rcv3_s            cn68xxp1;
 	struct cvmx_sli_msi_rcv3_s            cn70xx;
+	struct cvmx_sli_msi_rcv3_s            cn70xxp1;
 	struct cvmx_sli_msi_rcv3_s            cn78xx;
 	struct cvmx_sli_msi_rcv3_s            cnf71xx;
 };
@@ -4988,6 +5014,7 @@ union cvmx_sli_msi_rd_map {
 	struct cvmx_sli_msi_rd_map_s          cn68xx;
 	struct cvmx_sli_msi_rd_map_s          cn68xxp1;
 	struct cvmx_sli_msi_rd_map_s          cn70xx;
+	struct cvmx_sli_msi_rd_map_s          cn70xxp1;
 	struct cvmx_sli_msi_rd_map_s          cn78xx;
 	struct cvmx_sli_msi_rd_map_s          cnf71xx;
 };
@@ -5017,6 +5044,7 @@ union cvmx_sli_msi_w1c_enb0 {
 	struct cvmx_sli_msi_w1c_enb0_s        cn68xx;
 	struct cvmx_sli_msi_w1c_enb0_s        cn68xxp1;
 	struct cvmx_sli_msi_w1c_enb0_s        cn70xx;
+	struct cvmx_sli_msi_w1c_enb0_s        cn70xxp1;
 	struct cvmx_sli_msi_w1c_enb0_s        cnf71xx;
 };
 typedef union cvmx_sli_msi_w1c_enb0 cvmx_sli_msi_w1c_enb0_t;
@@ -5045,6 +5073,7 @@ union cvmx_sli_msi_w1c_enb1 {
 	struct cvmx_sli_msi_w1c_enb1_s        cn68xx;
 	struct cvmx_sli_msi_w1c_enb1_s        cn68xxp1;
 	struct cvmx_sli_msi_w1c_enb1_s        cn70xx;
+	struct cvmx_sli_msi_w1c_enb1_s        cn70xxp1;
 	struct cvmx_sli_msi_w1c_enb1_s        cnf71xx;
 };
 typedef union cvmx_sli_msi_w1c_enb1 cvmx_sli_msi_w1c_enb1_t;
@@ -5073,6 +5102,7 @@ union cvmx_sli_msi_w1c_enb2 {
 	struct cvmx_sli_msi_w1c_enb2_s        cn68xx;
 	struct cvmx_sli_msi_w1c_enb2_s        cn68xxp1;
 	struct cvmx_sli_msi_w1c_enb2_s        cn70xx;
+	struct cvmx_sli_msi_w1c_enb2_s        cn70xxp1;
 	struct cvmx_sli_msi_w1c_enb2_s        cnf71xx;
 };
 typedef union cvmx_sli_msi_w1c_enb2 cvmx_sli_msi_w1c_enb2_t;
@@ -5101,6 +5131,7 @@ union cvmx_sli_msi_w1c_enb3 {
 	struct cvmx_sli_msi_w1c_enb3_s        cn68xx;
 	struct cvmx_sli_msi_w1c_enb3_s        cn68xxp1;
 	struct cvmx_sli_msi_w1c_enb3_s        cn70xx;
+	struct cvmx_sli_msi_w1c_enb3_s        cn70xxp1;
 	struct cvmx_sli_msi_w1c_enb3_s        cnf71xx;
 };
 typedef union cvmx_sli_msi_w1c_enb3 cvmx_sli_msi_w1c_enb3_t;
@@ -5129,6 +5160,7 @@ union cvmx_sli_msi_w1s_enb0 {
 	struct cvmx_sli_msi_w1s_enb0_s        cn68xx;
 	struct cvmx_sli_msi_w1s_enb0_s        cn68xxp1;
 	struct cvmx_sli_msi_w1s_enb0_s        cn70xx;
+	struct cvmx_sli_msi_w1s_enb0_s        cn70xxp1;
 	struct cvmx_sli_msi_w1s_enb0_s        cnf71xx;
 };
 typedef union cvmx_sli_msi_w1s_enb0 cvmx_sli_msi_w1s_enb0_t;
@@ -5157,6 +5189,7 @@ union cvmx_sli_msi_w1s_enb1 {
 	struct cvmx_sli_msi_w1s_enb1_s        cn68xx;
 	struct cvmx_sli_msi_w1s_enb1_s        cn68xxp1;
 	struct cvmx_sli_msi_w1s_enb1_s        cn70xx;
+	struct cvmx_sli_msi_w1s_enb1_s        cn70xxp1;
 	struct cvmx_sli_msi_w1s_enb1_s        cnf71xx;
 };
 typedef union cvmx_sli_msi_w1s_enb1 cvmx_sli_msi_w1s_enb1_t;
@@ -5185,6 +5218,7 @@ union cvmx_sli_msi_w1s_enb2 {
 	struct cvmx_sli_msi_w1s_enb2_s        cn68xx;
 	struct cvmx_sli_msi_w1s_enb2_s        cn68xxp1;
 	struct cvmx_sli_msi_w1s_enb2_s        cn70xx;
+	struct cvmx_sli_msi_w1s_enb2_s        cn70xxp1;
 	struct cvmx_sli_msi_w1s_enb2_s        cnf71xx;
 };
 typedef union cvmx_sli_msi_w1s_enb2 cvmx_sli_msi_w1s_enb2_t;
@@ -5213,6 +5247,7 @@ union cvmx_sli_msi_w1s_enb3 {
 	struct cvmx_sli_msi_w1s_enb3_s        cn68xx;
 	struct cvmx_sli_msi_w1s_enb3_s        cn68xxp1;
 	struct cvmx_sli_msi_w1s_enb3_s        cn70xx;
+	struct cvmx_sli_msi_w1s_enb3_s        cn70xxp1;
 	struct cvmx_sli_msi_w1s_enb3_s        cnf71xx;
 };
 typedef union cvmx_sli_msi_w1s_enb3 cvmx_sli_msi_w1s_enb3_t;
@@ -5248,6 +5283,7 @@ union cvmx_sli_msi_wr_map {
 	struct cvmx_sli_msi_wr_map_s          cn68xx;
 	struct cvmx_sli_msi_wr_map_s          cn68xxp1;
 	struct cvmx_sli_msi_wr_map_s          cn70xx;
+	struct cvmx_sli_msi_wr_map_s          cn70xxp1;
 	struct cvmx_sli_msi_wr_map_s          cn78xx;
 	struct cvmx_sli_msi_wr_map_s          cnf71xx;
 };
@@ -5428,6 +5464,7 @@ union cvmx_sli_pcie_msi_rcv {
 	struct cvmx_sli_pcie_msi_rcv_s        cn68xx;
 	struct cvmx_sli_pcie_msi_rcv_s        cn68xxp1;
 	struct cvmx_sli_pcie_msi_rcv_s        cn70xx;
+	struct cvmx_sli_pcie_msi_rcv_s        cn70xxp1;
 	struct cvmx_sli_pcie_msi_rcv_s        cn78xx;
 	struct cvmx_sli_pcie_msi_rcv_s        cnf71xx;
 };
@@ -5463,6 +5500,7 @@ union cvmx_sli_pcie_msi_rcv_b1 {
 	struct cvmx_sli_pcie_msi_rcv_b1_s     cn68xx;
 	struct cvmx_sli_pcie_msi_rcv_b1_s     cn68xxp1;
 	struct cvmx_sli_pcie_msi_rcv_b1_s     cn70xx;
+	struct cvmx_sli_pcie_msi_rcv_b1_s     cn70xxp1;
 	struct cvmx_sli_pcie_msi_rcv_b1_s     cn78xx;
 	struct cvmx_sli_pcie_msi_rcv_b1_s     cnf71xx;
 };
@@ -5498,6 +5536,7 @@ union cvmx_sli_pcie_msi_rcv_b2 {
 	struct cvmx_sli_pcie_msi_rcv_b2_s     cn68xx;
 	struct cvmx_sli_pcie_msi_rcv_b2_s     cn68xxp1;
 	struct cvmx_sli_pcie_msi_rcv_b2_s     cn70xx;
+	struct cvmx_sli_pcie_msi_rcv_b2_s     cn70xxp1;
 	struct cvmx_sli_pcie_msi_rcv_b2_s     cn78xx;
 	struct cvmx_sli_pcie_msi_rcv_b2_s     cnf71xx;
 };
@@ -5533,6 +5572,7 @@ union cvmx_sli_pcie_msi_rcv_b3 {
 	struct cvmx_sli_pcie_msi_rcv_b3_s     cn68xx;
 	struct cvmx_sli_pcie_msi_rcv_b3_s     cn68xxp1;
 	struct cvmx_sli_pcie_msi_rcv_b3_s     cn70xx;
+	struct cvmx_sli_pcie_msi_rcv_b3_s     cn70xxp1;
 	struct cvmx_sli_pcie_msi_rcv_b3_s     cn78xx;
 	struct cvmx_sli_pcie_msi_rcv_b3_s     cnf71xx;
 };
@@ -5607,6 +5647,7 @@ union cvmx_sli_pktx_cnts {
 	struct cvmx_sli_pktx_cnts_cn61xx      cn68xx;
 	struct cvmx_sli_pktx_cnts_cn61xx      cn68xxp1;
 	struct cvmx_sli_pktx_cnts_cn61xx      cn70xx;
+	struct cvmx_sli_pktx_cnts_cn61xx      cn70xxp1;
 	struct cvmx_sli_pktx_cnts_s           cn78xx;
 	struct cvmx_sli_pktx_cnts_cn61xx      cnf71xx;
 };
@@ -5646,6 +5687,7 @@ union cvmx_sli_pktx_in_bp {
 	struct cvmx_sli_pktx_in_bp_s          cn63xxp1;
 	struct cvmx_sli_pktx_in_bp_s          cn66xx;
 	struct cvmx_sli_pktx_in_bp_s          cn70xx;
+	struct cvmx_sli_pktx_in_bp_s          cn70xxp1;
 	struct cvmx_sli_pktx_in_bp_s          cnf71xx;
 };
 typedef union cvmx_sli_pktx_in_bp cvmx_sli_pktx_in_bp_t;
@@ -5771,6 +5813,7 @@ union cvmx_sli_pktx_instr_baddr {
 	struct cvmx_sli_pktx_instr_baddr_s    cn68xx;
 	struct cvmx_sli_pktx_instr_baddr_s    cn68xxp1;
 	struct cvmx_sli_pktx_instr_baddr_s    cn70xx;
+	struct cvmx_sli_pktx_instr_baddr_s    cn70xxp1;
 	struct cvmx_sli_pktx_instr_baddr_s    cn78xx;
 	struct cvmx_sli_pktx_instr_baddr_s    cnf71xx;
 };
@@ -5804,6 +5847,7 @@ union cvmx_sli_pktx_instr_baoff_dbell {
 	struct cvmx_sli_pktx_instr_baoff_dbell_s cn68xx;
 	struct cvmx_sli_pktx_instr_baoff_dbell_s cn68xxp1;
 	struct cvmx_sli_pktx_instr_baoff_dbell_s cn70xx;
+	struct cvmx_sli_pktx_instr_baoff_dbell_s cn70xxp1;
 	struct cvmx_sli_pktx_instr_baoff_dbell_s cn78xx;
 	struct cvmx_sli_pktx_instr_baoff_dbell_s cnf71xx;
 };
@@ -5839,6 +5883,7 @@ union cvmx_sli_pktx_instr_fifo_rsize {
 	struct cvmx_sli_pktx_instr_fifo_rsize_s cn68xx;
 	struct cvmx_sli_pktx_instr_fifo_rsize_s cn68xxp1;
 	struct cvmx_sli_pktx_instr_fifo_rsize_s cn70xx;
+	struct cvmx_sli_pktx_instr_fifo_rsize_s cn70xxp1;
 	struct cvmx_sli_pktx_instr_fifo_rsize_s cn78xx;
 	struct cvmx_sli_pktx_instr_fifo_rsize_s cnf71xx;
 };
@@ -5992,6 +6037,7 @@ union cvmx_sli_pktx_instr_header {
 	struct cvmx_sli_pktx_instr_header_s   cn68xx;
 	struct cvmx_sli_pktx_instr_header_cn61xx cn68xxp1;
 	struct cvmx_sli_pktx_instr_header_cn61xx cn70xx;
+	struct cvmx_sli_pktx_instr_header_cn61xx cn70xxp1;
 	struct cvmx_sli_pktx_instr_header_cn61xx cnf71xx;
 };
 typedef union cvmx_sli_pktx_instr_header cvmx_sli_pktx_instr_header_t;
@@ -6048,6 +6094,7 @@ union cvmx_sli_pktx_out_size {
 	struct cvmx_sli_pktx_out_size_s       cn68xx;
 	struct cvmx_sli_pktx_out_size_s       cn68xxp1;
 	struct cvmx_sli_pktx_out_size_s       cn70xx;
+	struct cvmx_sli_pktx_out_size_s       cn70xxp1;
 	struct cvmx_sli_pktx_out_size_s       cn78xx;
 	struct cvmx_sli_pktx_out_size_s       cnf71xx;
 };
@@ -6105,12 +6152,10 @@ union cvmx_sli_pktx_output_control {
                                                          becomes ADDRTYPE<0> in DPI/SLI reads that fetch buffer/info pairs from packet output ring
                                                          (from address SLI_PKTx_SLIST_BADDR+ in MAC memory space.) ADDRTYPE<0> is the relaxed-order
                                                          attribute for PCIe. */
-	uint64_t enb                          : 1;  /**< Packet input enable. When ENB=1, packet input ring is enabled.
-                                                         When the ring is in reset, caused by a failing read associated with the ring, the ring
-                                                         being put into
-                                                         reset by writing the reset bit assocaited with a ring, a FLR or the MAC the ring is
-                                                         associated with
-                                                         being in reset, will cause this bit to clear and be able to be set againg till the reset
+	uint64_t enb                          : 1;  /**< Packet input enable. When ENB=1, packet input ring is enabled. When the ring is in reset,
+                                                         caused by a failing read associated with the ring, the ring being put into reset by
+                                                         writing the reset bit associated with a ring, a FLR or the MAC the ring is associated with
+                                                         being in reset, will cause this bit to clear and be able to be set again till the reset
                                                          condition is removed. */
 #else
 	uint64_t enb                          : 1;
@@ -6156,6 +6201,7 @@ union cvmx_sli_pktx_slist_baddr {
 	struct cvmx_sli_pktx_slist_baddr_s    cn68xx;
 	struct cvmx_sli_pktx_slist_baddr_s    cn68xxp1;
 	struct cvmx_sli_pktx_slist_baddr_s    cn70xx;
+	struct cvmx_sli_pktx_slist_baddr_s    cn70xxp1;
 	struct cvmx_sli_pktx_slist_baddr_s    cn78xx;
 	struct cvmx_sli_pktx_slist_baddr_s    cnf71xx;
 };
@@ -6193,6 +6239,7 @@ union cvmx_sli_pktx_slist_baoff_dbell {
 	struct cvmx_sli_pktx_slist_baoff_dbell_s cn68xx;
 	struct cvmx_sli_pktx_slist_baoff_dbell_s cn68xxp1;
 	struct cvmx_sli_pktx_slist_baoff_dbell_s cn70xx;
+	struct cvmx_sli_pktx_slist_baoff_dbell_s cn70xxp1;
 	struct cvmx_sli_pktx_slist_baoff_dbell_s cn78xx;
 	struct cvmx_sli_pktx_slist_baoff_dbell_s cnf71xx;
 };
@@ -6223,6 +6270,7 @@ union cvmx_sli_pktx_slist_fifo_rsize {
 	struct cvmx_sli_pktx_slist_fifo_rsize_s cn68xx;
 	struct cvmx_sli_pktx_slist_fifo_rsize_s cn68xxp1;
 	struct cvmx_sli_pktx_slist_fifo_rsize_s cn70xx;
+	struct cvmx_sli_pktx_slist_fifo_rsize_s cn70xxp1;
 	struct cvmx_sli_pktx_slist_fifo_rsize_s cn78xx;
 	struct cvmx_sli_pktx_slist_fifo_rsize_s cnf71xx;
 };
@@ -6281,13 +6329,12 @@ union cvmx_sli_pkt_cnt_int {
 	struct cvmx_sli_pkt_cnt_int_cn61xx    cn68xx;
 	struct cvmx_sli_pkt_cnt_int_cn61xx    cn68xxp1;
 	struct cvmx_sli_pkt_cnt_int_cn61xx    cn70xx;
+	struct cvmx_sli_pkt_cnt_int_cn61xx    cn70xxp1;
 	struct cvmx_sli_pkt_cnt_int_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t ring                         : 64; /**< Output ring packet counter interrupt bits
-                                                         SLI sets RING<i> whenever
-                                                         SLI_PKT(0..63)_CNTS[CNT] > SLI_PKT_INT_LEVELS[CNT].
-                                                         SLI_PKT_CNT_INT_ENB[RING<i>] is the corresponding
-                                                         enable. */
+	uint64_t ring                         : 64; /**< Output ring packet counter interrupt bits SLI sets RING<i> whenever
+                                                         SLI_PKT(0..63)_CNTS[CNT] > SLI_PKT(0..63)_INT_LEVELS[CNT]. SLI_PKT_CNT_INT_ENB[RING<i>] is
+                                                         the corresponding enable. */
 #else
 	uint64_t ring                         : 64;
 #endif
@@ -6324,6 +6371,7 @@ union cvmx_sli_pkt_cnt_int_enb {
 	struct cvmx_sli_pkt_cnt_int_enb_s     cn68xx;
 	struct cvmx_sli_pkt_cnt_int_enb_s     cn68xxp1;
 	struct cvmx_sli_pkt_cnt_int_enb_s     cn70xx;
+	struct cvmx_sli_pkt_cnt_int_enb_s     cn70xxp1;
 	struct cvmx_sli_pkt_cnt_int_enb_s     cnf71xx;
 };
 typedef union cvmx_sli_pkt_cnt_int_enb cvmx_sli_pkt_cnt_int_enb_t;
@@ -6360,6 +6408,7 @@ union cvmx_sli_pkt_ctl {
 	struct cvmx_sli_pkt_ctl_s             cn68xx;
 	struct cvmx_sli_pkt_ctl_s             cn68xxp1;
 	struct cvmx_sli_pkt_ctl_s             cn70xx;
+	struct cvmx_sli_pkt_ctl_s             cn70xxp1;
 	struct cvmx_sli_pkt_ctl_s             cnf71xx;
 };
 typedef union cvmx_sli_pkt_ctl cvmx_sli_pkt_ctl_t;
@@ -6394,6 +6443,7 @@ union cvmx_sli_pkt_data_out_es {
 	struct cvmx_sli_pkt_data_out_es_s     cn68xx;
 	struct cvmx_sli_pkt_data_out_es_s     cn68xxp1;
 	struct cvmx_sli_pkt_data_out_es_s     cn70xx;
+	struct cvmx_sli_pkt_data_out_es_s     cn70xxp1;
 	struct cvmx_sli_pkt_data_out_es_s     cnf71xx;
 };
 typedef union cvmx_sli_pkt_data_out_es cvmx_sli_pkt_data_out_es_t;
@@ -6430,6 +6480,7 @@ union cvmx_sli_pkt_data_out_ns {
 	struct cvmx_sli_pkt_data_out_ns_s     cn68xx;
 	struct cvmx_sli_pkt_data_out_ns_s     cn68xxp1;
 	struct cvmx_sli_pkt_data_out_ns_s     cn70xx;
+	struct cvmx_sli_pkt_data_out_ns_s     cn70xxp1;
 	struct cvmx_sli_pkt_data_out_ns_s     cnf71xx;
 };
 typedef union cvmx_sli_pkt_data_out_ns cvmx_sli_pkt_data_out_ns_t;
@@ -6466,6 +6517,7 @@ union cvmx_sli_pkt_data_out_ror {
 	struct cvmx_sli_pkt_data_out_ror_s    cn68xx;
 	struct cvmx_sli_pkt_data_out_ror_s    cn68xxp1;
 	struct cvmx_sli_pkt_data_out_ror_s    cn70xx;
+	struct cvmx_sli_pkt_data_out_ror_s    cn70xxp1;
 	struct cvmx_sli_pkt_data_out_ror_s    cnf71xx;
 };
 typedef union cvmx_sli_pkt_data_out_ror cvmx_sli_pkt_data_out_ror_t;
@@ -6505,6 +6557,7 @@ union cvmx_sli_pkt_dpaddr {
 	struct cvmx_sli_pkt_dpaddr_s          cn68xx;
 	struct cvmx_sli_pkt_dpaddr_s          cn68xxp1;
 	struct cvmx_sli_pkt_dpaddr_s          cn70xx;
+	struct cvmx_sli_pkt_dpaddr_s          cn70xxp1;
 	struct cvmx_sli_pkt_dpaddr_s          cnf71xx;
 };
 typedef union cvmx_sli_pkt_dpaddr cvmx_sli_pkt_dpaddr_t;
@@ -6536,6 +6589,7 @@ union cvmx_sli_pkt_in_bp {
 	struct cvmx_sli_pkt_in_bp_s           cn63xxp1;
 	struct cvmx_sli_pkt_in_bp_s           cn66xx;
 	struct cvmx_sli_pkt_in_bp_s           cn70xx;
+	struct cvmx_sli_pkt_in_bp_s           cn70xxp1;
 	struct cvmx_sli_pkt_in_bp_s           cnf71xx;
 };
 typedef union cvmx_sli_pkt_in_bp cvmx_sli_pkt_in_bp_t;
@@ -6588,6 +6642,7 @@ union cvmx_sli_pkt_in_donex_cnts {
 	struct cvmx_sli_pkt_in_donex_cnts_cn61xx cn68xx;
 	struct cvmx_sli_pkt_in_donex_cnts_cn61xx cn68xxp1;
 	struct cvmx_sli_pkt_in_donex_cnts_cn61xx cn70xx;
+	struct cvmx_sli_pkt_in_donex_cnts_cn61xx cn70xxp1;
 	struct cvmx_sli_pkt_in_donex_cnts_s   cn78xx;
 	struct cvmx_sli_pkt_in_donex_cnts_cn61xx cnf71xx;
 };
@@ -6619,6 +6674,7 @@ union cvmx_sli_pkt_in_instr_counts {
 	struct cvmx_sli_pkt_in_instr_counts_s cn68xx;
 	struct cvmx_sli_pkt_in_instr_counts_s cn68xxp1;
 	struct cvmx_sli_pkt_in_instr_counts_s cn70xx;
+	struct cvmx_sli_pkt_in_instr_counts_s cn70xxp1;
 	struct cvmx_sli_pkt_in_instr_counts_s cn78xx;
 	struct cvmx_sli_pkt_in_instr_counts_s cnf71xx;
 };
@@ -6673,6 +6729,7 @@ union cvmx_sli_pkt_in_pcie_port {
 	struct cvmx_sli_pkt_in_pcie_port_s    cn68xx;
 	struct cvmx_sli_pkt_in_pcie_port_s    cn68xxp1;
 	struct cvmx_sli_pkt_in_pcie_port_s    cn70xx;
+	struct cvmx_sli_pkt_in_pcie_port_s    cn70xxp1;
 	struct cvmx_sli_pkt_in_pcie_port_s    cnf71xx;
 };
 typedef union cvmx_sli_pkt_in_pcie_port cvmx_sli_pkt_in_pcie_port_t;
@@ -6865,6 +6922,7 @@ union cvmx_sli_pkt_input_control {
 	struct cvmx_sli_pkt_input_control_s   cn68xx;
 	struct cvmx_sli_pkt_input_control_s   cn68xxp1;
 	struct cvmx_sli_pkt_input_control_s   cn70xx;
+	struct cvmx_sli_pkt_input_control_s   cn70xxp1;
 	struct cvmx_sli_pkt_input_control_s   cnf71xx;
 };
 typedef union cvmx_sli_pkt_input_control cvmx_sli_pkt_input_control_t;
@@ -6872,9 +6930,8 @@ typedef union cvmx_sli_pkt_input_control cvmx_sli_pkt_input_control_t;
 /**
  * cvmx_sli_pkt_instr_enb
  *
- * ""This register enables the instruction fetch for a packet ring. This is the PF version also
- * see SLI_PKT#_INPUT_CONTROL[ENB]." The bit cooresponding to the ring in reset will be
- * cleared."
+ * This register enables the instruction fetch for a packet ring. This is the PF version; also
+ * see SLI_PKT(0..63)_INPUT_CONTROL[ENB].
  */
 union cvmx_sli_pkt_instr_enb {
 	uint64_t u64;
@@ -6900,6 +6957,7 @@ union cvmx_sli_pkt_instr_enb {
 	struct cvmx_sli_pkt_instr_enb_cn61xx  cn68xx;
 	struct cvmx_sli_pkt_instr_enb_cn61xx  cn68xxp1;
 	struct cvmx_sli_pkt_instr_enb_cn61xx  cn70xx;
+	struct cvmx_sli_pkt_instr_enb_cn61xx  cn70xxp1;
 	struct cvmx_sli_pkt_instr_enb_s       cn78xx;
 	struct cvmx_sli_pkt_instr_enb_cn61xx  cnf71xx;
 };
@@ -6937,6 +6995,7 @@ union cvmx_sli_pkt_instr_rd_size {
 	struct cvmx_sli_pkt_instr_rd_size_s   cn68xx;
 	struct cvmx_sli_pkt_instr_rd_size_s   cn68xxp1;
 	struct cvmx_sli_pkt_instr_rd_size_s   cn70xx;
+	struct cvmx_sli_pkt_instr_rd_size_s   cn70xxp1;
 	struct cvmx_sli_pkt_instr_rd_size_s   cnf71xx;
 };
 typedef union cvmx_sli_pkt_instr_rd_size cvmx_sli_pkt_instr_rd_size_t;
@@ -6966,6 +7025,7 @@ union cvmx_sli_pkt_instr_size {
 	struct cvmx_sli_pkt_instr_size_s      cn68xx;
 	struct cvmx_sli_pkt_instr_size_s      cn68xxp1;
 	struct cvmx_sli_pkt_instr_size_s      cn70xx;
+	struct cvmx_sli_pkt_instr_size_s      cn70xxp1;
 	struct cvmx_sli_pkt_instr_size_s      cnf71xx;
 };
 typedef union cvmx_sli_pkt_instr_size cvmx_sli_pkt_instr_size_t;
@@ -7021,6 +7081,7 @@ union cvmx_sli_pkt_int_levels {
 	struct cvmx_sli_pkt_int_levels_s      cn68xx;
 	struct cvmx_sli_pkt_int_levels_s      cn68xxp1;
 	struct cvmx_sli_pkt_int_levels_s      cn70xx;
+	struct cvmx_sli_pkt_int_levels_s      cn70xxp1;
 	struct cvmx_sli_pkt_int_levels_s      cnf71xx;
 };
 typedef union cvmx_sli_pkt_int_levels cvmx_sli_pkt_int_levels_t;
@@ -7050,6 +7111,7 @@ union cvmx_sli_pkt_iptr {
 	struct cvmx_sli_pkt_iptr_s            cn68xx;
 	struct cvmx_sli_pkt_iptr_s            cn68xxp1;
 	struct cvmx_sli_pkt_iptr_s            cn70xx;
+	struct cvmx_sli_pkt_iptr_s            cn70xxp1;
 	struct cvmx_sli_pkt_iptr_s            cnf71xx;
 };
 typedef union cvmx_sli_pkt_iptr cvmx_sli_pkt_iptr_t;
@@ -7264,6 +7326,7 @@ union cvmx_sli_pkt_out_bmode {
 	struct cvmx_sli_pkt_out_bmode_s       cn68xx;
 	struct cvmx_sli_pkt_out_bmode_s       cn68xxp1;
 	struct cvmx_sli_pkt_out_bmode_s       cn70xx;
+	struct cvmx_sli_pkt_out_bmode_s       cn70xxp1;
 	struct cvmx_sli_pkt_out_bmode_s       cnf71xx;
 };
 typedef union cvmx_sli_pkt_out_bmode cvmx_sli_pkt_out_bmode_t;
@@ -7304,8 +7367,8 @@ typedef union cvmx_sli_pkt_out_bp_en cvmx_sli_pkt_out_bp_en_t;
 /**
  * cvmx_sli_pkt_out_enb
  *
- * "This register enables the output packet engines.  This is the PF version. Also see
- * SLI_PKT#_INPUT_CONTROL[ENB]. The bit corresponding to the ring in reset will be cleared."
+ * This register enables the output packet engines. This is the PF version; also see
+ * SLI_PKT(0..63)_OUTPUT_CONTROL[ENB].
  */
 union cvmx_sli_pkt_out_enb {
 	uint64_t u64;
@@ -7337,6 +7400,7 @@ union cvmx_sli_pkt_out_enb {
 	struct cvmx_sli_pkt_out_enb_cn61xx    cn68xx;
 	struct cvmx_sli_pkt_out_enb_cn61xx    cn68xxp1;
 	struct cvmx_sli_pkt_out_enb_cn61xx    cn70xx;
+	struct cvmx_sli_pkt_out_enb_cn61xx    cn70xxp1;
 	struct cvmx_sli_pkt_out_enb_s         cn78xx;
 	struct cvmx_sli_pkt_out_enb_cn61xx    cnf71xx;
 };
@@ -7368,6 +7432,7 @@ union cvmx_sli_pkt_output_wmark {
 	struct cvmx_sli_pkt_output_wmark_s    cn68xx;
 	struct cvmx_sli_pkt_output_wmark_s    cn68xxp1;
 	struct cvmx_sli_pkt_output_wmark_s    cn70xx;
+	struct cvmx_sli_pkt_output_wmark_s    cn70xxp1;
 	struct cvmx_sli_pkt_output_wmark_s    cn78xx;
 	struct cvmx_sli_pkt_output_wmark_s    cnf71xx;
 };
@@ -7399,6 +7464,7 @@ union cvmx_sli_pkt_pcie_port {
 	struct cvmx_sli_pkt_pcie_port_s       cn68xx;
 	struct cvmx_sli_pkt_pcie_port_s       cn68xxp1;
 	struct cvmx_sli_pkt_pcie_port_s       cn70xx;
+	struct cvmx_sli_pkt_pcie_port_s       cn70xxp1;
 	struct cvmx_sli_pkt_pcie_port_s       cnf71xx;
 };
 typedef union cvmx_sli_pkt_pcie_port cvmx_sli_pkt_pcie_port_t;
@@ -7429,6 +7495,7 @@ union cvmx_sli_pkt_port_in_rst {
 	struct cvmx_sli_pkt_port_in_rst_s     cn68xx;
 	struct cvmx_sli_pkt_port_in_rst_s     cn68xxp1;
 	struct cvmx_sli_pkt_port_in_rst_s     cn70xx;
+	struct cvmx_sli_pkt_port_in_rst_s     cn70xxp1;
 	struct cvmx_sli_pkt_port_in_rst_s     cnf71xx;
 };
 typedef union cvmx_sli_pkt_port_in_rst cvmx_sli_pkt_port_in_rst_t;
@@ -7481,6 +7548,7 @@ union cvmx_sli_pkt_slist_es {
 	struct cvmx_sli_pkt_slist_es_s        cn68xx;
 	struct cvmx_sli_pkt_slist_es_s        cn68xxp1;
 	struct cvmx_sli_pkt_slist_es_s        cn70xx;
+	struct cvmx_sli_pkt_slist_es_s        cn70xxp1;
 	struct cvmx_sli_pkt_slist_es_s        cnf71xx;
 };
 typedef union cvmx_sli_pkt_slist_es cvmx_sli_pkt_slist_es_t;
@@ -7516,6 +7584,7 @@ union cvmx_sli_pkt_slist_ns {
 	struct cvmx_sli_pkt_slist_ns_s        cn68xx;
 	struct cvmx_sli_pkt_slist_ns_s        cn68xxp1;
 	struct cvmx_sli_pkt_slist_ns_s        cn70xx;
+	struct cvmx_sli_pkt_slist_ns_s        cn70xxp1;
 	struct cvmx_sli_pkt_slist_ns_s        cnf71xx;
 };
 typedef union cvmx_sli_pkt_slist_ns cvmx_sli_pkt_slist_ns_t;
@@ -7551,6 +7620,7 @@ union cvmx_sli_pkt_slist_ror {
 	struct cvmx_sli_pkt_slist_ror_s       cn68xx;
 	struct cvmx_sli_pkt_slist_ror_s       cn68xxp1;
 	struct cvmx_sli_pkt_slist_ror_s       cn70xx;
+	struct cvmx_sli_pkt_slist_ror_s       cn70xxp1;
 	struct cvmx_sli_pkt_slist_ror_s       cnf71xx;
 };
 typedef union cvmx_sli_pkt_slist_ror cvmx_sli_pkt_slist_ror_t;
@@ -7589,11 +7659,12 @@ union cvmx_sli_pkt_time_int {
 	struct cvmx_sli_pkt_time_int_cn61xx   cn68xx;
 	struct cvmx_sli_pkt_time_int_cn61xx   cn68xxp1;
 	struct cvmx_sli_pkt_time_int_cn61xx   cn70xx;
+	struct cvmx_sli_pkt_time_int_cn61xx   cn70xxp1;
 	struct cvmx_sli_pkt_time_int_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t ring                         : 64; /**< Output ring packet timer interrupt bits SLI sets RING<i> whenever
-                                                         SLI_PKT(0..63)_CNTS[TIMER] >
-                                                         SLI_PKT_INT_LEVELS[TIME]. SLI_PKT_TIME_INT_ENB[RING<i>] is the corresponding enable. */
+                                                         SLI_PKT(0..63)_CNTS[TIMER] > SLI_PKT_INT_LEVELS[TIME]. SLI_PKT_TIME_INT_ENB[RING<i>] is
+                                                         the corresponding enable. */
 #else
 	uint64_t ring                         : 64;
 #endif
@@ -7630,6 +7701,7 @@ union cvmx_sli_pkt_time_int_enb {
 	struct cvmx_sli_pkt_time_int_enb_s    cn68xx;
 	struct cvmx_sli_pkt_time_int_enb_s    cn68xxp1;
 	struct cvmx_sli_pkt_time_int_enb_s    cn70xx;
+	struct cvmx_sli_pkt_time_int_enb_s    cn70xxp1;
 	struct cvmx_sli_pkt_time_int_enb_s    cnf71xx;
 };
 typedef union cvmx_sli_pkt_time_int_enb cvmx_sli_pkt_time_int_enb_t;
@@ -7699,7 +7771,7 @@ typedef union cvmx_sli_portx_pkind cvmx_sli_portx_pkind_t;
  * cvmx_sli_s2m_port#_ctl
  *
  * These registers contain control for access from SLI to a MAC port. Write operations to these
- * registers are not ordered with write/read operations to the MAC Memory space. To ensure that a
+ * registers are not ordered with write/read operations to the MAC memory space. To ensure that a
  * write operation has completed, read the register before making an access (i.e. MAC memory
  * space) that requires the value of this register to be updated.
  */
@@ -7771,6 +7843,7 @@ union cvmx_sli_s2m_portx_ctl {
 	struct cvmx_sli_s2m_portx_ctl_cn61xx  cn68xx;
 	struct cvmx_sli_s2m_portx_ctl_cn61xx  cn68xxp1;
 	struct cvmx_sli_s2m_portx_ctl_cn61xx  cn70xx;
+	struct cvmx_sli_s2m_portx_ctl_cn61xx  cn70xxp1;
 	struct cvmx_sli_s2m_portx_ctl_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_6_63                : 58;
@@ -7826,6 +7899,7 @@ union cvmx_sli_scratch_1 {
 	struct cvmx_sli_scratch_1_s           cn68xx;
 	struct cvmx_sli_scratch_1_s           cn68xxp1;
 	struct cvmx_sli_scratch_1_s           cn70xx;
+	struct cvmx_sli_scratch_1_s           cn70xxp1;
 	struct cvmx_sli_scratch_1_s           cn78xx;
 	struct cvmx_sli_scratch_1_s           cnf71xx;
 };
@@ -7853,6 +7927,7 @@ union cvmx_sli_scratch_2 {
 	struct cvmx_sli_scratch_2_s           cn68xx;
 	struct cvmx_sli_scratch_2_s           cn68xxp1;
 	struct cvmx_sli_scratch_2_s           cn70xx;
+	struct cvmx_sli_scratch_2_s           cn70xxp1;
 	struct cvmx_sli_scratch_2_s           cn78xx;
 	struct cvmx_sli_scratch_2_s           cnf71xx;
 };
@@ -7886,6 +7961,7 @@ union cvmx_sli_state1 {
 	struct cvmx_sli_state1_s              cn68xx;
 	struct cvmx_sli_state1_s              cn68xxp1;
 	struct cvmx_sli_state1_s              cn70xx;
+	struct cvmx_sli_state1_s              cn70xxp1;
 	struct cvmx_sli_state1_s              cn78xx;
 	struct cvmx_sli_state1_s              cnf71xx;
 };
@@ -7933,6 +8009,7 @@ union cvmx_sli_state2 {
 	struct cvmx_sli_state2_cn61xx         cn68xx;
 	struct cvmx_sli_state2_cn61xx         cn68xxp1;
 	struct cvmx_sli_state2_cn61xx         cn70xx;
+	struct cvmx_sli_state2_cn61xx         cn70xxp1;
 	struct cvmx_sli_state2_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_57_63               : 7;
@@ -7994,6 +8071,7 @@ union cvmx_sli_state3 {
 	struct cvmx_sli_state3_cn61xx         cn68xx;
 	struct cvmx_sli_state3_cn61xx         cn68xxp1;
 	struct cvmx_sli_state3_cn61xx         cn70xx;
+	struct cvmx_sli_state3_cn61xx         cn70xxp1;
 	struct cvmx_sli_state3_cn78xx {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_60_63               : 4;
@@ -8062,10 +8140,11 @@ typedef union cvmx_sli_tx_pipe cvmx_sli_tx_pipe_t;
 /**
  * cvmx_sli_win_rd_addr
  *
- * This register contains the address to be read when the SLI_WIN_RD_DATA register is read. This
- * register should NOT be used to read SLI_* registers.
+ * When the LSB of this CSR is written, the address in this CSR will be read. The data returned
+ * from this read will be placed in the WIN_RD_DATA CSR. This CSR should NOT be used to read
+ * SLI_* registers.
  * If SLI_S2M_PORT(0..3)_CTL[LCL_NODE] the MAC that it is set for will not be able to write
- * RD_ADDR[37:36] which will always be written with the chips OCI-ID.
+ * SLI_WIN_RD_ADDR[37:36] which will always be written with the chips OCI-ID.
  */
 union cvmx_sli_win_rd_addr {
 	uint64_t u64;
@@ -8098,6 +8177,7 @@ union cvmx_sli_win_rd_addr {
 	struct cvmx_sli_win_rd_addr_s         cn68xx;
 	struct cvmx_sli_win_rd_addr_s         cn68xxp1;
 	struct cvmx_sli_win_rd_addr_s         cn70xx;
+	struct cvmx_sli_win_rd_addr_s         cn70xxp1;
 	struct cvmx_sli_win_rd_addr_s         cn78xx;
 	struct cvmx_sli_win_rd_addr_s         cnf71xx;
 };
@@ -8106,8 +8186,8 @@ typedef union cvmx_sli_win_rd_addr cvmx_sli_win_rd_addr_t;
 /**
  * cvmx_sli_win_rd_data
  *
- * This register contains the address to be read when the SLI_WIN_RD_DATA register is read.
- *
+ * This CSR holds the data returned when a read operation is started by the writing of the
+ * SLI_WIN_RD_ADDR CSR.
  */
 union cvmx_sli_win_rd_data {
 	uint64_t u64;
@@ -8125,6 +8205,7 @@ union cvmx_sli_win_rd_data {
 	struct cvmx_sli_win_rd_data_s         cn68xx;
 	struct cvmx_sli_win_rd_data_s         cn68xxp1;
 	struct cvmx_sli_win_rd_data_s         cn70xx;
+	struct cvmx_sli_win_rd_data_s         cn70xxp1;
 	struct cvmx_sli_win_rd_data_s         cn78xx;
 	struct cvmx_sli_win_rd_data_s         cnf71xx;
 };
@@ -8175,6 +8256,7 @@ union cvmx_sli_win_wr_addr {
 	struct cvmx_sli_win_wr_addr_s         cn68xx;
 	struct cvmx_sli_win_wr_addr_s         cn68xxp1;
 	struct cvmx_sli_win_wr_addr_s         cn70xx;
+	struct cvmx_sli_win_wr_addr_s         cn70xxp1;
 	struct cvmx_sli_win_wr_addr_s         cn78xx;
 	struct cvmx_sli_win_wr_addr_s         cnf71xx;
 };
@@ -8205,6 +8287,7 @@ union cvmx_sli_win_wr_data {
 	struct cvmx_sli_win_wr_data_s         cn68xx;
 	struct cvmx_sli_win_wr_data_s         cn68xxp1;
 	struct cvmx_sli_win_wr_data_s         cn70xx;
+	struct cvmx_sli_win_wr_data_s         cn70xxp1;
 	struct cvmx_sli_win_wr_data_s         cn78xx;
 	struct cvmx_sli_win_wr_data_s         cnf71xx;
 };
@@ -8238,6 +8321,7 @@ union cvmx_sli_win_wr_mask {
 	struct cvmx_sli_win_wr_mask_s         cn68xx;
 	struct cvmx_sli_win_wr_mask_s         cn68xxp1;
 	struct cvmx_sli_win_wr_mask_s         cn70xx;
+	struct cvmx_sli_win_wr_mask_s         cn70xxp1;
 	struct cvmx_sli_win_wr_mask_s         cn78xx;
 	struct cvmx_sli_win_wr_mask_s         cnf71xx;
 };
@@ -8285,6 +8369,7 @@ union cvmx_sli_window_ctl {
 	struct cvmx_sli_window_ctl_cn61xx     cn68xx;
 	struct cvmx_sli_window_ctl_cn61xx     cn68xxp1;
 	struct cvmx_sli_window_ctl_cn61xx     cn70xx;
+	struct cvmx_sli_window_ctl_cn61xx     cn70xxp1;
 	struct cvmx_sli_window_ctl_s          cn78xx;
 	struct cvmx_sli_window_ctl_cn61xx     cnf71xx;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-smix-defs.h b/arch/mips/include/asm/octeon/cvmx-smix-defs.h
index 9405d86..5583676 100644
--- a/arch/mips/include/asm/octeon/cvmx-smix-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-smix-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -439,6 +439,7 @@ union cvmx_smix_clk {
 	struct cvmx_smix_clk_s                cn68xx;
 	struct cvmx_smix_clk_s                cn68xxp1;
 	struct cvmx_smix_clk_s                cn70xx;
+	struct cvmx_smix_clk_s                cn70xxp1;
 	struct cvmx_smix_clk_s                cn78xx;
 	struct cvmx_smix_clk_s                cnf71xx;
 };
@@ -514,6 +515,7 @@ union cvmx_smix_cmd {
 	struct cvmx_smix_cmd_s                cn68xx;
 	struct cvmx_smix_cmd_s                cn68xxp1;
 	struct cvmx_smix_cmd_s                cn70xx;
+	struct cvmx_smix_cmd_s                cn70xxp1;
 	struct cvmx_smix_cmd_s                cn78xx;
 	struct cvmx_smix_cmd_s                cnf71xx;
 };
@@ -556,6 +558,7 @@ union cvmx_smix_en {
 	struct cvmx_smix_en_s                 cn68xx;
 	struct cvmx_smix_en_s                 cn68xxp1;
 	struct cvmx_smix_en_s                 cn70xx;
+	struct cvmx_smix_en_s                 cn70xxp1;
 	struct cvmx_smix_en_s                 cn78xx;
 	struct cvmx_smix_en_s                 cnf71xx;
 };
@@ -600,6 +603,7 @@ union cvmx_smix_rd_dat {
 	struct cvmx_smix_rd_dat_s             cn68xx;
 	struct cvmx_smix_rd_dat_s             cn68xxp1;
 	struct cvmx_smix_rd_dat_s             cn70xx;
+	struct cvmx_smix_rd_dat_s             cn70xxp1;
 	struct cvmx_smix_rd_dat_s             cn78xx;
 	struct cvmx_smix_rd_dat_s             cnf71xx;
 };
@@ -644,6 +648,7 @@ union cvmx_smix_wr_dat {
 	struct cvmx_smix_wr_dat_s             cn68xx;
 	struct cvmx_smix_wr_dat_s             cn68xxp1;
 	struct cvmx_smix_wr_dat_s             cn70xx;
+	struct cvmx_smix_wr_dat_s             cn70xxp1;
 	struct cvmx_smix_wr_dat_s             cn78xx;
 	struct cvmx_smix_wr_dat_s             cnf71xx;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-spxx-defs.h b/arch/mips/include/asm/octeon/cvmx-spxx-defs.h
index 0f246a7..11f2cb1 100644
--- a/arch/mips/include/asm/octeon/cvmx-spxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-spxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h b/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
index 4355cfb..f382a85 100644
--- a/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sriomaintx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-sriox-defs.h b/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
index 6fff67c..9415497 100644
--- a/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sriox-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-srxx-defs.h b/arch/mips/include/asm/octeon/cvmx-srxx-defs.h
index af7a998..ffae2d0 100644
--- a/arch/mips/include/asm/octeon/cvmx-srxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-srxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-sso-defs.h b/arch/mips/include/asm/octeon/cvmx-sso-defs.h
index c4b1e73..6119efc 100644
--- a/arch/mips/include/asm/octeon/cvmx-sso-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-sso-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -427,17 +427,6 @@ static inline uint64_t CVMX_SSO_GRPX_INT_THR(unsigned long block_id)
 #define CVMX_SSO_GRPX_INT_THR(block_id) (CVMX_ADD_IO_SEG(0x0001670020000500ull) + ((block_id) & 255) * 0x10000ull)
 #endif
 #if CVMX_ENABLE_CSR_ADDRESS_CHECKING
-static inline uint64_t CVMX_SSO_GRPX_PREF(unsigned long block_id)
-{
-	if (!(
-	      (OCTEON_IS_MODEL(OCTEON_CN78XX) && ((block_id <= 255)))))
-		cvmx_warn("CVMX_SSO_GRPX_PREF(%lu) is invalid on this chip\n", block_id);
-	return CVMX_ADD_IO_SEG(0x0001670020000300ull) + ((block_id) & 255) * 0x10000ull;
-}
-#else
-#define CVMX_SSO_GRPX_PREF(block_id) (CVMX_ADD_IO_SEG(0x0001670020000300ull) + ((block_id) & 255) * 0x10000ull)
-#endif
-#if CVMX_ENABLE_CSR_ADDRESS_CHECKING
 static inline uint64_t CVMX_SSO_GRPX_PRI(unsigned long block_id)
 {
 	if (!(
@@ -1320,7 +1309,7 @@ union cvmx_sso_aw_cfg {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_9_63                : 55;
 	uint64_t ldt_short                    : 1;  /**< Use LDT to bypass L2 allocations when reading short form work. */
-	uint64_t reserved_7_7                 : 1;
+	uint64_t lol                          : 1;  /**< Reserved. */
 	uint64_t xaq_alloc_dis                : 1;  /**< Disable FPA alloc requests to fill the SSO page cache. Also all existing cached free
                                                          buffers will be returned to FPA and will not be cached. */
 	uint64_t ocla_bp                      : 1;  /**< OCLA backpressure enable. When OCLA FIFOs are near full, allow OCLA to backpressure AW pipeline. */
@@ -1339,7 +1328,7 @@ union cvmx_sso_aw_cfg {
 	uint64_t xaq_byp_dis                  : 1;
 	uint64_t ocla_bp                      : 1;
 	uint64_t xaq_alloc_dis                : 1;
-	uint64_t reserved_7_7                 : 1;
+	uint64_t lol                          : 1;
 	uint64_t ldt_short                    : 1;
 	uint64_t reserved_9_63                : 55;
 #endif
@@ -2142,22 +2131,19 @@ union cvmx_sso_err2 {
 	uint64_t iop                          : 13; /**< Illegal operation errors. Throws SSO_INTSN_E::SSO_ERR2_IOP<n>:
                                                          <12> = Received command before SSO_RESET[BUSY] cleared.
                                                          <11> = Received SWTAG/GET_WORK/etc from node other than the local node.
-                                                         <10> = Received SWTAG/SWTAG_FULL/SWTAG_DESCHED/UPD_WQP_GRP/ALLOC_WE/CLR_NSCHED/PREP_WORK
-                                                         from work slot with PREP_WORK pending
+                                                         <10> = Reserved.
                                                          <9> = Received illegal opcode.
-                                                         <8> = Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP_GRP/GET_WORK/PREP_WORK/ALLOC_WE
-                                                         from work slot with CLR_NSCHED pending.
+                                                         <8> = Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP_GRP/GET_WORK/ALLOC_WE from work
+                                                         slot with CLR_NSCHED pending.
                                                          <7> = Received CLR_NSCHED from work slot with SWTAG_DESCH/DESCH/CLR_NSCHED pending.
-                                                         <6> = Received
-                                                         SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP_GRP/GET_WORK/PREP_WORK/ALLOC_WE/CLR_NSCHED from
-                                                         work slot with ALLOC_WE pending.
-                                                         <5> = Received
-                                                         SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP_GRP/GET_WORK/PREP_WORK/ALLOC_WE/CLR_NSCHED from
-                                                         work slot with GET_WORK pending.
+                                                         <6> = Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP_GRP/GET_WORK/ALLOC_WE/CLR_NSCHED
+                                                         from work slot with ALLOC_WE pending.
+                                                         <5> = Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP_GRP/GET_WORK/ALLOC_WE/CLR_NSCHED
+                                                         from work slot with GET_WORK pending.
                                                          <4> = Received SWTAG_FULL/SWTAG_DESCH with tag specified as UNTAGGED.
                                                          <3> = Received SWTAG/SWTAG_FULL/SWTAG_DESCH with tag specified as EMPTY.
-                                                         <2> = Received SWTAG/SWTAG_FULL/SWTAG_DESCH/GET_WORK/PREP_WORK from work slot with pending
-                                                         tag switch to ORDERED or ATOMIC.
+                                                         <2> = Received SWTAG/SWTAG_FULL/SWTAG_DESCH/GET_WORK from work slot with pending tag
+                                                         switch to ORDERED or ATOMIC.
                                                          <1> = Received SWTAG/SWTAG_DESCH/DESCH/UPD_WQP_GRP from work slot in UNTAGGED state.
                                                          <0> = Received SWTAG/SWTAG_FULL/SWTAG_DESCH/DESCH/UPD_WQP_GRP from work slot in EMPTY
                                                          state. */
@@ -2562,28 +2548,6 @@ union cvmx_sso_grpx_int_thr {
 typedef union cvmx_sso_grpx_int_thr cvmx_sso_grpx_int_thr_t;
 
 /**
- * cvmx_sso_grp#_pref
- *
- * Controls the prefetching for each group.
- *
- */
-union cvmx_sso_grpx_pref {
-	uint64_t u64;
-	struct cvmx_sso_grpx_pref_s {
-#ifdef __BIG_ENDIAN_BITFIELD
-	uint64_t reserved_4_63                : 60;
-	uint64_t clines                       : 4;  /**< Number of cache lines starting at the work queue pointer to prefetch into L1 Dcache, when
-                                                         work is fetched with PREP_WORK. Zero disables prefetching. */
-#else
-	uint64_t clines                       : 4;
-	uint64_t reserved_4_63                : 60;
-#endif
-	} s;
-	struct cvmx_sso_grpx_pref_s           cn78xx;
-};
-typedef union cvmx_sso_grpx_pref cvmx_sso_grpx_pref_t;
-
-/**
  * cvmx_sso_grp#_pri
  *
  * Controls the priority and group affinity arbitration for each group.
@@ -4043,21 +4007,13 @@ union cvmx_sso_sl_ppx_pendtag {
 	uint64_t pend_nosched_clr             : 1;  /**< Set when there is a pending CLR_NSCHED. */
 	uint64_t pend_desched                 : 1;  /**< Set when there is a pending DESCHED or SWTAG_DESCHED. */
 	uint64_t pend_alloc_we                : 1;  /**< Set when there is a pending ALLOC_WE. */
-	uint64_t reserved_56_56               : 1;
-	uint64_t prep_index                   : 12; /**< The index when PREPPED is set. */
-	uint64_t prepped                      : 1;  /**< Set when there is PREP_WORK available. */
-	uint64_t pend_prep                    : 1;  /**< Set when there is a PREP_WORK pending. */
-	uint64_t reserved_34_41               : 8;
+	uint64_t reserved_34_56               : 23;
 	uint64_t pend_tt                      : 2;  /**< The tag type when PEND_SWITCH is set. */
 	uint64_t pend_tag                     : 32; /**< The tag when PEND_SWITCH is set. */
 #else
 	uint64_t pend_tag                     : 32;
 	uint64_t pend_tt                      : 2;
-	uint64_t reserved_34_41               : 8;
-	uint64_t pend_prep                    : 1;
-	uint64_t prepped                      : 1;
-	uint64_t prep_index                   : 12;
-	uint64_t reserved_56_56               : 1;
+	uint64_t reserved_34_56               : 23;
 	uint64_t pend_alloc_we                : 1;
 	uint64_t pend_desched                 : 1;
 	uint64_t pend_nosched_clr             : 1;
@@ -4655,7 +4611,7 @@ union cvmx_sso_ws_cfg {
                                                          <49> Work-slot RAM access. (arbr.)
                                                          <48> Work-slot pushes to AQ, CQ, DQ. (arbq.) */
 	uint64_t reserved_5_47                : 43;
-	uint64_t disable_pw                   : 1;  /**< Disable PREP_WORK operations and treat as a NOP. For diagnostic use only. */
+	uint64_t disable_pw                   : 1;  /**< Reserved. */
 	uint64_t arbc_step_en                 : 1;  /**< Enable single-stepping WS CAM arbiter, twice per 16 clocks. For diagnostic use only. */
 	uint64_t ncbo_step_en                 : 1;  /**< Enable single-stepping commands from NCBO, once per 32 clocks. For diagnostic use only. */
 	uint64_t soc_ccam_dis                 : 1;  /**< Disable power saving SOC conditional CAM. */
@@ -4711,7 +4667,8 @@ union cvmx_sso_xaqx_head_next {
 	struct cvmx_sso_xaqx_head_next_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
-	uint64_t ptr                          : 35; /**< Pointer. For peak performance, all XAQ buffers should reside on the local node's memory. */
+	uint64_t ptr                          : 35; /**< Pointer, divided by 128 bytes. For peak performance, all XAQ buffers should reside on the
+                                                         local node's memory. */
 	uint64_t reserved_0_6                 : 7;
 #else
 	uint64_t reserved_0_6                 : 7;
@@ -4736,7 +4693,8 @@ union cvmx_sso_xaqx_head_ptr {
 	struct cvmx_sso_xaqx_head_ptr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
-	uint64_t ptr                          : 35; /**< Pointer. For peak performance, all XAQ buffers should reside on the local node's memory. */
+	uint64_t ptr                          : 35; /**< Pointer, divided by 128 bytes. For peak performance, all XAQ buffers should reside on the
+                                                         local node's memory. */
 	uint64_t reserved_5_6                 : 2;
 	uint64_t cl                           : 5;  /**< Cache line number in buffer. Cache line zero contains the next pointer. */
 #else
@@ -4762,7 +4720,8 @@ union cvmx_sso_xaqx_tail_next {
 	struct cvmx_sso_xaqx_tail_next_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
-	uint64_t ptr                          : 35; /**< Pointer. For peak performance, all XAQ buffers should reside on the local node's memory. */
+	uint64_t ptr                          : 35; /**< Pointer, divided by 128 bytes. For peak performance, all XAQ buffers should reside on the
+                                                         local node's memory. */
 	uint64_t reserved_0_6                 : 7;
 #else
 	uint64_t reserved_0_6                 : 7;
@@ -4785,7 +4744,8 @@ union cvmx_sso_xaqx_tail_ptr {
 	struct cvmx_sso_xaqx_tail_ptr_s {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_42_63               : 22;
-	uint64_t ptr                          : 35; /**< Pointer. For peak performance, all XAQ buffers should reside on the local node's memory. */
+	uint64_t ptr                          : 35; /**< Pointer, divided by 128 bytes. For peak performance, all XAQ buffers should reside on the
+                                                         local node's memory. */
 	uint64_t reserved_5_6                 : 2;
 	uint64_t cl                           : 5;  /**< Cache line number in buffer. Cache line zero contains the next pointer. */
 #else
@@ -4808,7 +4768,9 @@ union cvmx_sso_xaq_aura {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t reserved_12_63               : 52;
 	uint64_t node                         : 2;  /**< Node number of current chip, to ensure that the aura is on the local node. */
-	uint64_t laura                        : 10; /**< FPA local-node aura to use for SSO XAQ allocations and frees. */
+	uint64_t laura                        : 10; /**< FPA local-node aura to use for SSO XAQ allocations and frees. The FPA aura selected by
+                                                         LAURA must select a pool with FPA_POOL(0..63)_CFG[NAT_ALIGN]=1, and
+                                                         (FPA_POOL(0..63)_CFG[BUF_SIZE] - FPA_POOL(0..63)_CFG[BUF_OFFSET]) >= 4 KB / 128. */
 #else
 	uint64_t laura                        : 10;
 	uint64_t node                         : 2;
diff --git a/arch/mips/include/asm/octeon/cvmx-stxx-defs.h b/arch/mips/include/asm/octeon/cvmx-stxx-defs.h
index 9499bdb..d27ccd0 100644
--- a/arch/mips/include/asm/octeon/cvmx-stxx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-stxx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h b/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
index 14a0b9a..dff90bc 100644
--- a/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-uctlx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -392,10 +392,8 @@ static inline uint64_t CVMX_UCTLX_UPHY_PORTX_CTL_STATUS(unsigned long offset, un
 /**
  * cvmx_uctl#_bist_status
  *
- * Accessible by: always
- * Reset by: IOI reset (srst_n)
- * Results from BIST runs of USBH's memories.
- * Wait for NDONE==0, then look at defect indication.
+ * This register indicates the results from the built-in self-test (BIST) runs of USBH memories.
+ * A 0 indicates pass or never run, a 1 indicates fail. This register can be reset by IOI reset.
  */
 union cvmx_uctlx_bist_status {
 	uint64_t u64;
@@ -629,9 +627,8 @@ typedef union cvmx_uctlx_clk_rst_ctl cvmx_uctlx_clk_rst_ctl_t;
 /**
  * cvmx_uctl#_ctl
  *
- * Accessible by: always
- * Reset by: IOI reset (srst_n)
- * This register controls clocks, resets, power, and BIST for the USB.
+ * This register controls clocks, resets, power, and BIST. This register can be reset by IOI reset.
+ *
  */
 union cvmx_uctlx_ctl {
 	uint64_t u64;
@@ -639,48 +636,48 @@ union cvmx_uctlx_ctl {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t clear_bist                   : 1;  /**< BIST fast-clear mode select. A BIST run with this bit set clears all entries in USBH RAMs
                                                          to 0x0.
-                                                         There are 2 major modes of BIST: full and clear. Full BIST is run by the BIST state
+                                                         There are two major modes of BIST: full and clear. Full BIST is run by the BIST state
                                                          machine when CLEAR_BIST is deasserted during BIST. Clear BIST is run if CLEAR_BIST is
                                                          asserted during BIST.
                                                          To avoid race conditions, software must first perform a CSR write operation that puts the
                                                          CLEAR_BIST setting into the correct state and then perform another CSR write operation to
                                                          set the BIST trigger (keeping the CLEAR_BIST state constant).
                                                          CLEAR BIST completion is indicated by UCTL(0)_BIST_STATUS[NDONE]. A BIST clear operation
-                                                         takes almost 2,000 host-controller-clock cycles for the largest RAM. */
+                                                         takes almost 2,000 controller-clock cycles for the largest RAM. */
 	uint64_t start_bist                   : 1;  /**< Rising edge starts BIST on the memories in USBH.
-                                                         To run BIST, both the host-controller clock must be configured and enabled, and should be
+                                                         To run BIST, the controller clock must be both configured and enabled, and should be
                                                          configured to the maximum available frequency given the available coprocessor clock and
                                                          dividers.
                                                          Also, the UCTL, UAHC, and UPHY should be held in software- initiated reset (using
                                                          UPHY_RST, UAHC_RST, UCTL_RST) until BIST is complete.
                                                          BIST defect status can be checked after FULL BIST completion, both of which are indicated
-                                                         in UCTL(0)_BIST_STATUS. The full BIST run takes almost 80,000 host-controller-clock cycles
-                                                         for the largest RAM. */
-	uint64_t ref_clk_sel                  : 2;  /**< Reference clock select. Choose reference clock source for the SuperSpeed and HighSpeed PLL
-                                                         blocks.
+                                                         in UCTL(0)_BIST_STATUS. The full BIST run takes almost 80,000 controller-clock cycles for
+                                                         the largest RAM. */
+	uint64_t ref_clk_sel                  : 2;  /**< Reference clock select. Choose reference-clock source for the SuperSpeed and high-speed
+                                                         PLL blocks.
                                                          0x0 = Reference clock source for both PLLs come from the USB pads.
-                                                         0x1 = Reserved
+                                                         0x1 = Reserved.
                                                          0x2 = Reserved.
                                                          0x3 = Reserved.
                                                          This value can be changed only during UPHY_RST.
-                                                         Note: If REF_CLK_SEL = 0x0, then the reference clock input cannot be spread-spectrum.
+                                                         If REF_CLK_SEL = 0x0, then the reference clock input cannot be spread-spectrum.
                                                          INTERNAL: For the 0x1 selection, reference clock source for SuperSpeed PLL is from the USB
                                                          pads, reference clock source for HighSpeed PLL is PLL_REF_CLK. But in 78xx, PLL_REF_CLK
                                                          cannot be routed to USB without violating jitter requirements */
-	uint64_t ssc_en                       : 1;  /**< Enables spread-spectrum clock production in the SuperSpeed function.
-                                                         If the input reference clock for the SuperSpeed PLL is already spread-spectrum,
-                                                         then do not enable this function. The clocks sourced to the SuperSpeed function
-                                                         must have spread-spectrum to be compliant with the USB specification.
-                                                         The HighSpeed PLL cannot support a spread-spectrum input, so REF_CLK_SEL = 0x0
-                                                         must enable this feature.
+	uint64_t ssc_en                       : 1;  /**< Spread-spectrum clock enable. Enables spread-spectrum clock production in the SuperSpeed
+                                                         function. If the input reference clock for the SuperSpeed PLL is already spread-spectrum,
+                                                         then do not enable this feature. The clocks sourced to the SuperSpeed function must have
+                                                         spread-spectrum to be compliant with the USB specification.
+                                                         The high-speed PLL cannot support a spread-spectrum input, so REF_CLK_SEL = 0x0 must
+                                                         enable this feature.
                                                          This value may only be changed during UPHY_RST. */
 	uint64_t ssc_range                    : 3;  /**< Spread-spectrum clock range. Selects the range of spread-spectrum modulation when SSC_EN
-                                                         is asserted and the PHY is spreading the SS transmit clocks.
+                                                         is asserted and the PHY is spreading the SuperSpeed transmit clocks.
                                                          Applies a fixed offset to the phase accumulator.
-                                                         0x0 = -4980 ppm downspread of clock
-                                                         0x1 = -4492 ppm
-                                                         0x2 = -4003 ppm
-                                                         0x3-0x7 = reserved
+                                                         0x0 = -4980 ppm downspread of clock.
+                                                         0x1 = -4492 ppm.
+                                                         0x2 = -4003 ppm.
+                                                         0x3-0x7 = reserved.
                                                          All of these settings are within the USB 3.0 specification. The amount of EMI emission
                                                          reduction might decrease as the SSC_RANGE increases; therefore, the SSC_RANGE settings can
                                                          be registered to enable the amount of spreading to be adjusted on a per-application basis.
@@ -691,92 +688,93 @@ union cvmx_uctlx_ctl {
                                                          [52:47]: 2's complement push amount
                                                          Must leave at reset value of 0x0.
                                                          This value may only be changed during UPHY_RST. */
-	uint64_t mpll_multiplier              : 7;  /**< Multiplies the reference clock to a frequency suitable for intended operating speed.
-                                                         Must leave at reset value of 0x0.
-                                                         This value may only be changed during UPHY_RST.
-                                                         This value is superceded by the REF_CLK_FSEL<5:3> selection. */
+	uint64_t mpll_multiplier              : 7;  /**< Multiplies the reference clock to a frequency suitable for intended operating speed. Must
+                                                         leave at reset value of 0x0. This value may only be changed during UPHY_RST.
+                                                         This value is superseded by the REF_CLK_FSEL<5:3> selection. */
 	uint64_t ref_ssp_en                   : 1;  /**< Enables reference clock to the prescaler for SuperSpeed function. This should always be
                                                          enabled since this output clock is used to drive the UAHC suspend-mode clock during low-
                                                          power states.
                                                          This value can be changed only during UPHY_RST or during low-power states.
                                                          The reference clock must be running and stable before UPHY_RST is deasserted and before
                                                          REF_SSP_EN is asserted. */
-	uint64_t ref_clk_div2                 : 1;  /**< Divides the reference clock by 2 before feeding it into the REF_CLK_FSEL divider.
-                                                         Must leave at reset value of 0x0.
+	uint64_t ref_clk_div2                 : 1;  /**< Divides the reference clock by 2 before feeding it into the REF_CLK_FSEL divider. Must
+                                                         leave at reset value of 0x0.
                                                          This value can be changed only during UPHY_RST. */
-	uint64_t ref_clk_fsel                 : 6;  /**< Selects the reference clock frequency for the SuperSpeed and HighSpeed PLL blocks. The
+	uint64_t ref_clk_fsel                 : 6;  /**< Selects the reference clock frequency for the SuperSpeed and high-speed PLL blocks. The
                                                          legal values are as follows:
-                                                         0x27 = External reference clock 100 MHz
+                                                         0x27 = External reference clock 100 MHz.
                                                          All other values are reserved.
                                                          This value may only be changed during UPHY_RST.
-                                                         INTERNAL: 0x2A = External reference clock 24 MHz
-                                                                   0x31 = External reference clock 20 MHz
-                                                                   0x38 = External reference clock 19.2 MHz */
+                                                         INTERNAL: 0x2A = External reference clock 24 MHz.
+                                                         0x31 = External reference clock 20 MHz.
+                                                         0x38 = External reference clock 19.2 MHz. */
 	uint64_t reserved_31_31               : 1;
-	uint64_t h_clk_en                     : 1;  /**< Host-controller-clock enable. When set to 1, the host-controller clock is generated. This
-                                                         also enables access to UCTL registers 0x30-0xF8. */
-	uint64_t h_clk_byp_sel                : 1;  /**< Select the bypass input to the host-controller-clock divider.
-                                                         0 = Use the divided coprocessor clock from the H_CLKDIV divider
-                                                         1 = Use the bypass clock from the GPIO pins
-                                                         This signal is just a multiplexer-select signal; it does not enable the host-controller
-                                                         clock. You must still set H_CLKDIV_EN separately. H_CLK_BYP_SEL select should not be
-                                                         changed unless H_CLKDIV_EN is disabled.
-                                                         The bypass clock can be selected and running even if the host-controller-clock dividers
-                                                         are not running.
+	uint64_t h_clk_en                     : 1;  /**< Controller-clock enable. When set to 1, the controller clock is generated. This also
+                                                         enables access to UCTL registers 0x30-0xF8. */
+	uint64_t h_clk_byp_sel                : 1;  /**< Select the bypass input to the controller-clock divider.
+                                                         0 = Use the divided coprocessor clock from the H_CLKDIV divider.
+                                                         1 = Use the bypass clock from the GPIO pins.
+                                                         This signal is just a multiplexer-select signal; it does not enable the controller clock.
+                                                         You must still set H_CLKDIV_EN separately. H_CLK_BYP_SEL select should not be changed
+                                                         unless H_CLKDIV_EN is disabled.
+                                                         The bypass clock can be selected and running even if the controller-clock dividers are not
+                                                         running.
                                                          INTERNAL: Generally bypass is only used for scan purposes. */
-	uint64_t h_clkdiv_rst                 : 1;  /**< Host-controller-clock divider reset. Divided clocks are not generated while the divider is
+	uint64_t h_clkdiv_rst                 : 1;  /**< Controller-clock divider reset. Divided clocks are not generated while the divider is
                                                          being reset.
                                                          This also resets the suspend-clock divider. */
 	uint64_t reserved_27_27               : 1;
-	uint64_t h_clkdiv_sel                 : 3;  /**< The hclk frequency is sclk frequency divided by H_CLKDIV_SEL.
-                                                         The host-controller-clock frequency must be at or below 300MHz.
-                                                         The host-controller-clock frequency must be at or above 150MHz for full-rate USB3
-                                                         operation.
-                                                         The host-controller-clock frequency must be at or above 125MHz for any USB3
-                                                         functionality.
-                                                         The host-controller-clock frequency must be at or above 90MHz for full-rate USB2
-                                                         operation
-                                                         The host-controller-clock frequency must be at or above 62.5MHz for any USB2 operation.
-                                                         This field can be changed only when H_CLKDIV_RST = 1.
+	uint64_t h_clkdiv_sel                 : 3;  /**< Controller clock-frequency-divider select. The controller-clock frequency is the
+                                                         coprocessor-clock frequency divided by H_CLKDIV_SEL and must be at or below 300 MHz.
                                                          The divider values are the following:
-                                                         0x0 = divide by 1 0x4 = divide by 8
-                                                         0x1 = divide by 2 0x5 = divide by 16
-                                                         0x2 = divide by 4 0x6 = divide by 24
-                                                         0x3 = divide by 6 0x7 = divide by 32
-                                                         INTERNAL: 150MHz is from the maximum of:
-                                                         INTERNAL:   Synopsys DWC_usb3 Databook v2.50a, table A-16, row 1, col 12.
-                                                         INTERNAL:   Synopsys DWC_usb3 Databook v2.50a, table A-17, row 7, col 9.
-                                                         INTERNAL:   Synopsys DWC_usb3 Databook v2.50a, table A-16, row 7, col 9.
-                                                         INTERNAL: HOST2>62.5MHz in HOST mode is from Synopsys DWC_usb3 Databook v2.50a,
-                                                         INTERNAL:   section A.12.5, 3rd bullet in Note on page 894.
-                                                         INTERNAL: HOST2>90MHz was arrived at from some math: 62.5MHz +
-                                                         INTERNAL:   (diff between row 1 and 2, col 12 of table A-16). */
+                                                         0x0 = divide by 1.
+                                                         0x1 = divide by 2.
+                                                         0x2 = divide by 4.
+                                                         0x3 = divide by 6.
+                                                         0x4 = divide by 8.
+                                                         0x5 = divide by 16.
+                                                         0x6 = divide by 24.
+                                                         0x7 = divide by 32.
+                                                         For USB3:
+                                                         * The controller-clock frequency must be at or above 125 MHz for any USB3 operation.
+                                                         * The controller-clock frequency must be at or above
+                                                         150 MHz for full-rate USB3 operation.
+                                                         For USB2:
+                                                         * The controller-clock frequency must be at or above 62.5 MHz for any USB2 operation.
+                                                         * The controller-clock frequency must be at or above
+                                                         90 MHz for full-rate USB2 operation.
+                                                         This field can be changed only when H_CLKDIV_RST = 1.
+                                                         INTERNAL: 150MHz is from the maximum of Synopsys DWC_usb3 Databook v2.50a, table A-16, row
+                                                         1, col 12. Synopsys DWC_usb3 Databook v2.50a, table A-17, row 7, col 9. Synopsys DWC_usb3
+                                                         Databook v2.50a, table A-16, row 7, col 9. HOST2>62.5MHz in HOST mode is from Synopsys
+                                                         DWC_usb3 Databook v2.50a, section A.12.5, 3rd bullet in Note on page 894. HOST2>90MHz was
+                                                         arrived at from some math: 62.5MHz + (diff between row 1 and 2, col 12 of table A-16). */
 	uint64_t reserved_22_23               : 2;
 	uint64_t usb3_port_perm_attach        : 1;  /**< Indicates this port is permanently attached. This is a strap signal; it should be modified
                                                          only when UPHY_RST is asserted. */
 	uint64_t usb2_port_perm_attach        : 1;  /**< Indicates this port is permanently attached. This is a strap signal; it should be modified
                                                          only when UPHY_RST is asserted. */
 	uint64_t reserved_19_19               : 1;
-	uint64_t usb3_port_disable            : 1;  /**< Disables the USB3 (SS) portion of this PHY. When set to 1, this signal stops reporting
-                                                         connect/disconnect events on the port and keeps the port in disabled state. This could be
-                                                         used for security reasons where hardware can disable a port regardless of whether xHCI
-                                                         driver enables a port or not.
+	uint64_t usb3_port_disable            : 1;  /**< Disables the USB3 (SuperSpeed) portion of this PHY. When set to 1, this signal stops
+                                                         reporting connect/disconnect events on the port and keeps the port in disabled state. This
+                                                         could be used for security reasons where hardware can disable a port regardless of whether
+                                                         xHCI driver enables a port or not.
                                                          UAHC(0)_HCSPARAMS1[MAXPORTS] is not affected by this signal.
                                                          This is a strap signal; it should be modified only when UPHY_RST is asserted. */
 	uint64_t reserved_17_17               : 1;
-	uint64_t usb2_port_disable            : 1;  /**< Disables USB2 (HS/FS/LS) portion of this PHY. When set to 1, this signal stops reporting
-                                                         connect/disconnect events on the port and keeps the port in disabled state. This could be
-                                                         used for security reasons where hardware can disable a port regardless of whether xHCI
-                                                         driver enables a port or not.
+	uint64_t usb2_port_disable            : 1;  /**< Disables USB2 (high-speed/full-speed/low-speed) portion of this PHY. When set to 1, this
+                                                         signal stops reporting connect/disconnect events on the port and keeps the port in
+                                                         disabled state. This could be used for security reasons where hardware can disable a port
+                                                         regardless of whether xHCI driver enables a port or not.
                                                          UAHC(0)_HCSPARAMS1[MAXPORTS] is not affected by this signal.
                                                          This is a strap signal; it should only be modified when UPHY_RST is asserted.
                                                          If Port0 is required to be disabled, ensure that the utmi_clk[0] is running at the normal
                                                          speed. Also, all the enabled USB2.0 ports should have the same clock frequency as Port0. */
 	uint64_t reserved_15_15               : 1;
-	uint64_t ss_power_en                  : 1;  /**< PHY SS block power enable.
+	uint64_t ss_power_en                  : 1;  /**< PHY SuperSpeed block power enable.
                                                          This is a strap signal; it should only be modified when UPHY_RST is asserted. */
 	uint64_t reserved_13_13               : 1;
-	uint64_t hs_power_en                  : 1;  /**< PHY HS block power enable.
+	uint64_t hs_power_en                  : 1;  /**< PHY high-speed block power enable.
                                                          This is a strap signal; it should only be modified when UPHY_RST is asserted. */
 	uint64_t reserved_5_11                : 7;
 	uint64_t csclk_en                     : 1;  /**< Turns on the USB UCTL interface clock (coprocessor clock). This enables access to UAHC
@@ -789,8 +787,8 @@ union cvmx_uctlx_ctl {
 	uint64_t uctl_rst                     : 1;  /**< Software reset; resets UCTL; active-high.
                                                          Resets UAHC DMA and register shims. Resets UCTL RSL registers 0x30-0xF8.
                                                          Does not reset UCTL RSL registers 0x0-0x28.
-                                                         UCTL RSL registers starting from 0x30 can be accessed only after the host-controller clock
-                                                         is active and UCTL_RST is deasserted.
+                                                         UCTL RSL registers starting from 0x30 can be accessed only after the controller clock is
+                                                         active and UCTL_RST is deasserted.
                                                          INTERNAL: Note that soft-resetting the UCTL while it is active may cause violations of
                                                          RSL, NCB, and CIB protocols. */
 #else
@@ -837,7 +835,6 @@ typedef union cvmx_uctlx_ctl cvmx_uctlx_ctl_t;
  * cvmx_uctl#_ecc
  *
  * Accessible by: only when H_CLKDIV_EN
- * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
  * This register can be used to disable ECC correction, insert ECC errors, and debug ECC
  * failures.
  * * The ECC_ERR* fields are captured when there are no outstanding ECC errors indicated in
@@ -852,6 +849,7 @@ typedef union cvmx_uctlx_ctl cvmx_uctlx_ctl_t;
  * 0x1 = SBE on bit[0]
  * 0x2 = SBE on bit[1]
  * 0x3 = DBE on bit[1:0]
+ * This register can be reset by IOI reset or with UCTL(0)_CTL[UCTL_RESET].
  */
 union cvmx_uctlx_ecc {
 	uint64_t u64;
@@ -1053,10 +1051,9 @@ typedef union cvmx_uctlx_erto_ctl cvmx_uctlx_erto_ctl_t;
  * cvmx_uctl#_host_cfg
  *
  * Accessible by: only when H_CLKDIV_EN
- * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
- * This register allows configuration of various host controller (UAHC) features.
- * Most of these are strap signals and should only be modified while the controller is not
- * running.
+ * This register allows configuration of various host controller (UAHC) features. Most of these
+ * are strap signals and should be modified only while the controller is not running.
+ * This register can be reset by IOI reset or with UCTL(0)_CTL[UCTL_RESET].
  */
 union cvmx_uctlx_host_cfg {
 	uint64_t u64;
@@ -1067,7 +1064,7 @@ union cvmx_uctlx_host_cfg {
                                                          set by the Set LTV command. */
 	uint64_t reserved_38_47               : 10;
 	uint64_t fla                          : 6;  /**< High-speed jitter adjustment. Indicates the correction required to accommodate mac3 clock
-                                                         and utmi clock jitter to measure 125us duration. With FLA tied to 0x0, the high speed
+                                                         and utmi clock jitter to measure 125us duration. With FLA tied to 0x0, the high-speed
                                                          125us micro-frame is counted for 123933ns. The value needs to be programmed in terms of
                                                          high-speed bit times in a 30 MHz cycle. Default value that needs to be driven is 0x20
                                                          (assuming 30 MHz perfect clock).
@@ -1087,7 +1084,7 @@ union cvmx_uctlx_host_cfg {
                                                          OCI_ACTIVE_HIGH_EN.
                                                          This is a strap signal; it should only be modified when UAHC is in reset (soft-reset
                                                          okay). */
-	uint64_t oci_active_high_en           : 1;  /**< Overcurrent sense selection. The off-chip sense (high/low) is converted to match the host-
+	uint64_t oci_active_high_en           : 1;  /**< Overcurrent sense selection. The off-chip sense (high/low) is converted to match the
                                                          controller's active-high sense.
                                                          1 = Overcurrent indication from off-chip source is active-high.
                                                          0 = Overcurrent indication from off-chip source is active-low.
@@ -1098,14 +1095,14 @@ union cvmx_uctlx_host_cfg {
                                                          1 = UAHC(0)_HCCPARAMS[PPC] reports port-power-control feature is available. PPC output
                                                          from UAHC is taken to the GPIO signals and sense-converted based on PPC_ACTIVE_HIGH_EN.
                                                          The MIO GPIO multiplexer must be programmed accordingly.
-                                                         This is a strap signal; it should only be modified when UAHC is in reset (soft-reset
-                                                         okay). */
+                                                         This is a strap signal; it should only be modified when either the UCTL_CTL[UAHC] or
+                                                         UAHC_GCTL[CoreSoftReset] is asserted. */
 	uint64_t ppc_active_high_en           : 1;  /**< Port power control sense selection. The active-high port-power-control output to off-chip
                                                          source is converted to match the off-chip sense.
                                                          1 = Port-power control to off-chip source is active-high.
                                                          0 = Port-power control to off-chip source is active-low.
-                                                         This is a strap signal; it should only be modified when UAHC is in reset (soft reset
-                                                         okay). */
+                                                         This is a strap signal; it should only be modified when either the UCTL_CTL[UAHC] or
+                                                         UAHC_GCTL[CoreSoftReset] is asserted. */
 	uint64_t reserved_0_23                : 24;
 #else
 	uint64_t reserved_0_23                : 24;
@@ -1244,10 +1241,9 @@ typedef union cvmx_uctlx_int_reg cvmx_uctlx_int_reg_t;
 /**
  * cvmx_uctl#_intstat
  *
- * Accessible by: always
- * Reset by: IOI reset (srst_n)
  * This register provides a summary of different bits of RSL interrupts. DBEs are detected and
- * SBE are corrected. For debugging output for ECC DBEs/SBEs, see UCTL(0)_ECC.
+ * SBE are corrected. For debugging output for ECC DBEs/SBEs, see UCTL(0)_ECC. This register can
+ * be reset by IOI reset.
  */
 union cvmx_uctlx_intstat {
 	uint64_t u64;
@@ -1412,9 +1408,8 @@ typedef union cvmx_uctlx_orto_ctl cvmx_uctlx_orto_ctl_t;
  * cvmx_uctl#_port#_cfg_hs
  *
  * Accessible by: only when H_CLKDIV_EN
- * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
- * This register controls configuration and test controls for the portX PHY.
- * INTERNAL: All these settings are for HS functionality, connect on DVDD power domain.
+ * This register controls configuration and test controls for the high-speed port 0 PHY. This
+ * register can be reset by IOI reset or UCTL(0)_CTL[UCTL_RST].
  */
 union cvmx_uctlx_portx_cfg_hs {
 	uint64_t u64;
@@ -1427,40 +1422,41 @@ union cvmx_uctlx_portx_cfg_hs {
                                                          threshold voltage level, while a negative binary bit setting change results in a -1.5%
                                                          incremental change in the threshold voltage level. */
 	uint64_t sq_rx_tune                   : 3;  /**< Squelch threshold adjustment. Adjusts the voltage level for the threshold used to detect
-                                                         valid HS data.
+                                                         valid high-speed data.
                                                          A positive binary bit setting change results in a -5% incremental change in threshold
                                                          voltage level, while a negative binary bit setting change results in a +5% incremental
                                                          change in threshold voltage level. */
-	uint64_t tx_fsls_tune                 : 4;  /**< LS/FS source impedance adjustment. Adjusts the low- and full-speed single-ended source
-                                                         impedance while driving high. This parameter control is encoded in thermometer code.
+	uint64_t tx_fsls_tune                 : 4;  /**< Low-speed/full-speed source impedance adjustment. Adjusts the low- and full-speed single-
+                                                         ended source impedance while driving high. This parameter control is encoded in
+                                                         thermometer code.
                                                          A positive thermometer code change results in a -2.5% incremental change in source
                                                          impedance. A negative thermometer code change results in +2.5% incremental change in
                                                          source impedance. Any non-thermometer code setting (that is, 0x9) is not supported and
                                                          reserved. */
 	uint64_t reserved_46_47               : 2;
 	uint64_t tx_hs_xv_tune                : 2;  /**< Transmitter high-speed crossover adjustment. This bus adjusts the voltage at which the DP0
-                                                         and DM0 signals cross while transmitting in HS mode.
-                                                         11 = default setting
-                                                         10 = +15 mV
-                                                         01 = -15 mV
-                                                         00 = reserved */
+                                                         and DM0 signals cross while transmitting in high-speed mode.
+                                                         0x3 = default setting.
+                                                         0x2 = +15 mV.
+                                                         0x1 = -15 mV.
+                                                         0x0 = reserved. */
 	uint64_t tx_preemp_amp_tune           : 2;  /**< High-speed transmitter pre-emphasis current control. Controls the amount of current
                                                          sourced to DP0 and DM0 after a J-to-K or K-to-J transition. The high-speed transmitter
-                                                         pre-emphasis current is defined in terms of unit amounts. One unit amount is approximately
-                                                         600 A and is defined as 1* pre-emphasis current.
-                                                         0x3 = high-speed TX pre-emphasis circuit sources 3* pre-emphasis current.
-                                                         0x2 = high-speed TX pre-emphasis circuit sources 2* pre-emphasis current.
-                                                         0x1 = high-speed TX pre-emphasis circuit sources 1* pre-emphasis current.
-                                                         0x0 = high-speed TX pre-emphasis is disabled (design default).
+                                                         preemphasis current is defined in terms of unit amounts. One unit amount is approximately
+                                                         600 A and is defined as 1* preemphasis current.
+                                                         0x3 = High-speed TX preemphasis circuit sources 3* preemphasis current.
+                                                         0x2 = High-speed TX preemphasis circuit sources 2* preemphasis current.
+                                                         0x1 = High-speed TX preemphasis circuit sources 1* preemphasis current.
+                                                         0x0 = High-speed TX preemphasis is disabled.
                                                          If these signals are not used, set them to 0x0. */
 	uint64_t reserved_41_41               : 1;
-	uint64_t tx_preemp_pulse_tune         : 1;  /**< High-speed transmitter pre-emphasis duration control. Controls the duration for which the
-                                                         high-speed pre-emphasis current is sourced onto DP0 or DM0. The high-speed transmitter
-                                                         pre-emphasis duration is defined in terms of unit amounts. One unit of pre-emphasis
-                                                         duration is approximately 580 ps and is defined as 1* pre-emphasis duration. This signal
-                                                         is valid only if either TX_PREEMP_AMP_TUNE0[1] or TX_PREEMP_AMP_TUNE0[0] is set to 1.
-                                                         1 = 1*, short pre-emphasis current duration
-                                                         0 = 2*, long pre-emphasis current duration (design default)
+	uint64_t tx_preemp_pulse_tune         : 1;  /**< High-speed transmitter preemphasis duration control. Controls the duration for which the
+                                                         high-speed preemphasis current is sourced onto DP0 or DM0. The high-speed transmitter
+                                                         preemphasis duration is defined in terms of unit amounts. One unit of preemphasis duration
+                                                         is approximately 580 ps and is defined as 1* preemphasis duration. This signal is valid
+                                                         only if either TX_PREEMP_AMP_TUNE0[1] or TX_PREEMP_AMP_TUNE0[0] is set to 1.
+                                                         1 = 1*, short preemphasis current duration
+                                                         0 = 2*, long preemphasis current duration (design default)
                                                          If this signal is not used, set it to 0. */
 	uint64_t tx_res_tune                  : 2;  /**< USB source-impedance adjustment. Some applications require additional devices to be added
                                                          on the USB, such as a series switch, which can add significant series resistance. This bus
@@ -1472,21 +1468,21 @@ union cvmx_uctlx_portx_cfg_hs {
                                                          Any setting other than the default can result in source-impedance variation across
                                                          process, voltage, and temperature conditions that does not meet USB 2.0 specification
                                                          limits. If this bus is not used, leave it at the default setting. */
-	uint64_t tx_rise_tune                 : 2;  /**< HS transmitter rise-/fall-time adjustment. Adjusts the rise/fall times of the high-speed
-                                                         waveform. A positive binary bit setting change results in a -4% incremental change in the
-                                                         high-speed rise/fall time. A negative binary bit setting change results in a +4%
-                                                         incremental change in the HS rise/fall time. */
+	uint64_t tx_rise_tune                 : 2;  /**< High-speed transmitter rise-/fall-time adjustment. Adjusts the rise/fall times of the
+                                                         high-speed waveform. A positive binary bit setting change results in a -4% incremental
+                                                         change in the high-speed rise/fall time. A negative binary bit setting change results in a
+                                                         +4% incremental change in the high-speed rise/fall time. */
 	uint64_t tx_vref_tune                 : 4;  /**< High-speed DC voltage-level adjustment. Adjusts the high-speed DC level voltage.
-                                                         A positive binary bit setting change results in a +1.25% incremental change in high-speed
-                                                         DC voltage level, while a negative binary bit setting change results in a -1.25%
-                                                         incremental change in HighSpeed DC voltage level.
+                                                         A positive binary-bit-setting change results in a +1.25% incremental change in high-speed
+                                                         DC voltage level, while a negative binary-bit-setting change results in a -1.25%
+                                                         incremental change in high-speed DC voltage level.
                                                          The default bit setting is intended to create a HighSpeed transmit
                                                          DC level of approximately 400mV. */
 	uint64_t reserved_4_31                : 28;
 	uint64_t vatest_enable                : 2;  /**< Analog test-pin select. Enables analog test voltages to be placed on the ID0 pin.
-                                                         0x0 = test functionality disabled
-                                                         0x1 = test functionality enabled
-                                                         0x2, 0x3 = reserved, invalid settings
+                                                         0x0 = test functionality disabled.
+                                                         0x1 = test functionality enabled.
+                                                         0x2, 0x3 = reserved, invalid settings.
                                                          See also the PHY databook for details on how to select which analog test voltage. */
 	uint64_t loopback_enable              : 1;  /**< Places the high-speed PHY in loopback mode, which concurrently enables high-speed receive
                                                          and transmit logic. */
@@ -1523,9 +1519,8 @@ typedef union cvmx_uctlx_portx_cfg_hs cvmx_uctlx_portx_cfg_hs_t;
  * cvmx_uctl#_port#_cfg_ss
  *
  * Accessible by: only when H_CLKDIV_EN
- * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
- * This register controls configuration and test controls for the portX PHY.
- * INTERNAL: All these settings are for HS functionality, connect on DVDD power domain.
+ * This register controls configuration and test controls for the SS port 0 PHY.
+ * This register can be reset by IOI reset or with UCTL(0)_CTL[UCTL_RESET].
  */
 union cvmx_uctlx_portx_cfg_ss {
 	uint64_t u64;
@@ -1533,27 +1528,27 @@ union cvmx_uctlx_portx_cfg_ss {
 #ifdef __BIG_ENDIAN_BITFIELD
 	uint64_t tx_vboost_lvl                : 3;  /**< TX voltage-boost level. Sets the boosted transmit launch amplitude (mVppd). The default
                                                          bit setting is intended to set the launch amplitude to approximately 1,008 mVppd. A
-                                                         single, positive binary bit setting change results in a +156 mVppd change in the Tx launch
+                                                         single, positive binary bit setting change results in a +156 mVppd change in the TX launch
                                                          amplitude.
-                                                         A single, negative binary bit setting change results in a -156 mVppd change in the Tx
+                                                         A single, negative binary bit setting change results in a -156 mVppd change in the TX
                                                          launch amplitude. All settings more than one binary bit change should not be used.
-                                                         0x3 = 0.844 V launch amplitude
-                                                         0x4 = 1.008 V launch amplitude
-                                                         0x5 = 1.156 V launch amplitude
+                                                         0x3 = 0.844 V launch amplitude.
+                                                         0x4 = 1.008 V launch amplitude.
+                                                         0x5 = 1.156 V launch amplitude.
                                                          All others values are invalid. */
 	uint64_t los_bias                     : 3;  /**< Loss-of-signal detector threshold-level control. A positive, binary bit setting change
                                                          results in a +15 mVp incremental change in the LOS threshold.
                                                          A negative binary bit setting change results in a -15 mVp incremental change in the LOS
                                                          threshold. The 0x0 setting is reserved and must not be used. The default 0x5 setting
                                                          corresponds to approximately 105 mVp.
-                                                         0x0 = invalid
-                                                         0x1 = 45 mV
-                                                         0x2 = 60 mV
-                                                         0x3 = 75 mV
-                                                         0x4 = 90 mV
-                                                         0x5 = 105 mV (default)
-                                                         0x6 = 120 mV
-                                                         0x7 = 135 mV */
+                                                         0x0 = invalid.
+                                                         0x1 = 45 mV.
+                                                         0x2 = 60 mV.
+                                                         0x3 = 75 mV.
+                                                         0x4 = 90 mV.
+                                                         0x5 = 105 mV (default).
+                                                         0x6 = 120 mV.
+                                                         0x7 = 135 mV. */
 	uint64_t lane0_ext_pclk_req           : 1;  /**< When asserted, this signal enables the pipe0_pclk output regardless of power state (along
                                                          with the associated increase in power consumption). You can use this input to enable
                                                          pipe0_pclk in the P3 state without going through a complete boot sequence. */
@@ -1565,9 +1560,9 @@ union cvmx_uctlx_portx_cfg_ss {
                                                          clock cycles equal to the value of pcs_rx_los_mask_val<9:0>. This control filters out
                                                          short, non-compliant LFPS glitches sent by a noncompliant host.
                                                          For normal operation, set to a targeted mask interval of 10us (value = 10us / Tref_clk).
-                                                         If the UCTL(0)_CTL[REF_CLK_DIV2] is used, then (value = 10us / (2 * Tref_clk)).
-                                                         These equations are based on the SuperSpeed reference clock frequency.
-                                                         The value of PCS_RX_LOS_MASK_VAL should be as follows:
+                                                         If the UCTL(0)_CTL[REF_CLK_DIV2] is used, then
+                                                         (value = 10us / (2 * Tref_clk)). These equations are based on the SuperSpeed reference
+                                                         clock frequency. The value of PCS_RX_LOS_MASK_VAL should be as follows:
                                                              Frequency DIV2 LOS_MASK
                                                               200  MHz    1    0x3E8
                                                               125  MHz    0    0x4E2
@@ -1585,13 +1580,12 @@ union cvmx_uctlx_portx_cfg_ss {
                                                                24  MHz    0    0x0F0
                                                                20  MHz    0    0x0C8
                                                                19.2MHz    0    0x0C0
-                                                         Setting this bus to 0x0 disables masking.
-                                                         The value should be defined when the PHY is in reset. Changing this value during operation
-                                                         might disrupt normal operation of the link. */
-	uint64_t pcs_tx_deemph_3p5db          : 6;  /**< Fine-tune transmitter driver de-emphasis when set to 3.5db.
-                                                         This static value sets the Tx driver de-emphasis value when pipeP_tx_deemph[1:0] is set to
-                                                         0x1 (according to the PIPE3 specification). The values for transmit de-emphasis are
-                                                         derived from the following equation:
+                                                         Setting this bus to 0x0 disables masking. The value should be defined when the PHY is in
+                                                         reset. Changing this value during operation might disrupt normal operation of the link. */
+	uint64_t pcs_tx_deemph_3p5db          : 6;  /**< Fine-tune transmitter driver deemphasis when set to 3.5db.
+                                                         This static value sets the TX driver deemphasis value when pipeP_tx_deemph[1:0] is set to
+                                                         0x1 (according to the PIPE3 specification). The values for transmit deemphasis are derived
+                                                         from the following equation:
                                                          TX de-emphasis (db) =
                                                          20 * log_base_10((128 - 2 * pcs_tx_deemph)/128)
                                                          In general, the parameter controls are static signals to be set prior to taking the PHY
@@ -1599,11 +1593,11 @@ union cvmx_uctlx_portx_cfg_ss {
                                                          purposes. In this case, changes to the transmitter to reflect the current value occur only
                                                          after the pipeP_tx_deemph[1:0] input changes.
                                                          INTERNAL: Default value is package dependant. */
-	uint64_t pcs_tx_deemph_6db            : 6;  /**< Fine-tune transmitter driver de-emphasis when set to 6db.
-                                                         This static value sets the Tx driver de-emphasis value when pipeP_tx_deemph[1:0] is set to
+	uint64_t pcs_tx_deemph_6db            : 6;  /**< Fine-tune transmitter driver deemphasis when set to 6db.
+                                                         This static value sets the TX driver deemphasis value when pipeP_tx_deemph[1:0] is set to
                                                          0x2 (according to the PIPE3 specification). This bus is provided for completeness and as a
-                                                         second potential launch amplitude. The values for transmit de-emphasis are derived from
-                                                         the following equation:
+                                                         second potential launch amplitude. The values for transmit deemphasis are derived from the
+                                                         following equation:
                                                          TX de-emphasis (db) =
                                                          20 * log_base_10((128 - 2 * pcs_tx_deemph)/128)
                                                          In general, the parameter controls are static signals to be set prior to taking the PHY
@@ -1653,8 +1647,11 @@ typedef union cvmx_uctlx_portx_cfg_ss cvmx_uctlx_portx_cfg_ss_t;
  * cvmx_uctl#_port#_cr_dbg_cfg
  *
  * Accessible by: only when H_CLKDIV_EN
- * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
- * This register allows indirect access to the configuration and test controls for the portX PHY.
+ *
+ * This register allows indirect access to the configuration and test controls for the port 0
+ * PHY. For directions to access the PHY registers indirectly through the CR interface, refer to
+ * UPHY Registers.
+ * This register can be reset by IOI reset or with UCTL(0)_CTL[UCTL_RESET].
  *
  * To access the PHY registers indirectly through the CR interface, the HCLK must be running,
  * UCTL_RST must be deasserted, and UPHY_RST must be deasserted. Software is responsible for
@@ -1739,9 +1736,9 @@ typedef union cvmx_uctlx_portx_cr_dbg_cfg cvmx_uctlx_portx_cr_dbg_cfg_t;
  * cvmx_uctl#_port#_cr_dbg_status
  *
  * Accessible by: only when H_CLKDIV_EN
- * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
- * This register allows indirect access to the configuration and test controls for the portX PHY.
- * For usage, see above description in CR_DBG_CFG.
+ * This register allows indirect access to the configuration and test controls for the port 0
+ * PHY. For directions for usage, refer to UPHY Registers.
+ * This register can be reset by IOI reset or with UCTL(0)_CTL[UCTL_RESET].
  */
 union cvmx_uctlx_portx_cr_dbg_status {
 	uint64_t u64;
@@ -1793,11 +1790,11 @@ typedef union cvmx_uctlx_ppaf_wm cvmx_uctlx_ppaf_wm_t;
  * cvmx_uctl#_shim_cfg
  *
  * Accessible by: only when H_CLKDIV_EN
- * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
  * This register allows configuration of various shim (UCTL) features. The fields XS_NCB_OOB_*
  * are captured when there are no outstanding OOB errors indicated in INTSTAT and a new OOB error
  * arrives. The fields XS_BAD_DMA_* are captured when there are no outstanding DMA errors
  * indicated in INTSTAT and a new DMA error arrives.
+ * This register can be reset by IOI reset or with UCTL(0)_CTL[UCTL_RESET].
  */
 union cvmx_uctlx_shim_cfg {
 	uint64_t u64;
@@ -1850,9 +1847,8 @@ typedef union cvmx_uctlx_shim_cfg cvmx_uctlx_shim_cfg_t;
 /**
  * cvmx_uctl#_spare0
  *
- * Accessible by: always
- * Reset by: IOI reset (srst_n)
- * This register is spare.
+ * This register is a spare register. This register can be reset by IOI reset.
+ *
  */
 union cvmx_uctlx_spare0 {
 	uint64_t u64;
@@ -1871,8 +1867,7 @@ typedef union cvmx_uctlx_spare0 cvmx_uctlx_spare0_t;
  * cvmx_uctl#_spare1
  *
  * Accessible by: only when H_CLKDIV_EN
- * Reset by: IOI reset (srst_n) or UCTL(0)_CTL[UCTL_RST]
- * This register is spare.
+ * This register can be reset by IOI reset or with UCTL(0)_CTL[UCTL_RESET].
  */
 union cvmx_uctlx_spare1 {
 	uint64_t u64;
diff --git a/arch/mips/include/asm/octeon/cvmx-usbcx-defs.h b/arch/mips/include/asm/octeon/cvmx-usbcx-defs.h
index c7e8a4a..d705c57 100644
--- a/arch/mips/include/asm/octeon/cvmx-usbcx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-usbcx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-usbnx-defs.h b/arch/mips/include/asm/octeon/cvmx-usbnx-defs.h
index bd5b4f2..d98e97a 100644
--- a/arch/mips/include/asm/octeon/cvmx-usbnx-defs.h
+++ b/arch/mips/include/asm/octeon/cvmx-usbnx-defs.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
diff --git a/arch/mips/include/asm/octeon/cvmx-wqe.h b/arch/mips/include/asm/octeon/cvmx-wqe.h
index 3db30b0..168fbb3 100644
--- a/arch/mips/include/asm/octeon/cvmx-wqe.h
+++ b/arch/mips/include/asm/octeon/cvmx-wqe.h
@@ -51,9 +51,6 @@
  * This file must not depend on any other header files, except for cvmx.h!!!
  *
  *
- * <hr>$Revision: 95258 $<hr>
- *
- *
  */
 
 #ifndef __CVMX_WQE_H__
@@ -61,8 +58,6 @@
 
 #include "cvmx-pki-defs.h"
 #include "cvmx-pip-defs.h"
-#include "cvmx-fpa3.h"
-#include "cvmx-fpa1.h"
 
 #ifdef	__cplusplus
 /* *INDENT-OFF* */
@@ -177,7 +172,7 @@ typedef union {
 
 	};
 #endif
-} cvmx_wqe_word4_t;
+} cvmx_pki_wqe_word4_t;
 
 /**
  * HW decode / err_code in work queue entry
@@ -728,7 +723,7 @@ typedef union {
 		uint64_t software:1;
 	};
 #endif
-}cvmx_pki_wqe_word2_t;
+} cvmx_pki_wqe_word2_t;
 
 typedef union {
 	uint64_t u64;
@@ -816,7 +811,7 @@ typedef union {
 } cvmx_pki_wqe_word0_t;
 
 /* Use reserved bit, set by HW to 0, to indicate buf_ptr legacy translation*/
-#define	pki_wqe_translated word0.pki.rsvd_1
+#define	pki_wqe_translated word0.rsvd_1
 
 typedef union {
 	uint64_t u64;
@@ -835,102 +830,72 @@ typedef union {
 
 typedef union {
 	uint64_t u64;
-#ifdef __BIG_ENDIAN_BITFIELD
 	struct {
-		uint64_t len:16;
-		uint64_t varies:14;
+		CVMX_BITFIELD_FIELD(uint64_t len:16,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_0:2,
+		CVMX_BITFIELD_FIELD(uint64_t rsvd_1:2,
 		/**
-		 * the type of the tag (ORDERED, ATOMIC, NULL)
+		 * the group that the work queue entry will be scheduled to
 		 */
-		cvmx_pow_tag_type_t tag_type:2;
-		uint64_t tag:32;
+		CVMX_BITFIELD_FIELD(uint64_t grp:10,
+		CVMX_BITFIELD_FIELD(cvmx_pow_tag_type_t tag_type:2,
+		CVMX_BITFIELD_FIELD(uint64_t tag:32,
+		))))));
 	};
+} cvmx_pki_wqe_word1_t;
+
+typedef union {
+	uint64_t u64;
 	struct {
-		uint64_t len:16;
-		uint64_t rsvd_0:2;
-		uint64_t rsvd_1:2;
+		CVMX_BITFIELD_FIELD(uint64_t len:16,
+		CVMX_BITFIELD_FIELD(uint64_t varies:14,
 		/**
-		 * the group that the work queue entry will be scheduled to
+		 * the type of the tag (ORDERED, ATOMIC, NULL)
 		 */
-		uint64_t grp:10;
-		cvmx_pow_tag_type_t tag_type:2;
-		uint64_t tag:32;
-	} cn78xx;
+		CVMX_BITFIELD_FIELD(cvmx_pow_tag_type_t tag_type:2,
+		CVMX_BITFIELD_FIELD(uint64_t tag:32,
+		))));
+	};
+	cvmx_pki_wqe_word1_t cn78xx;
 	struct {
-		uint64_t len:16;
-		uint64_t zero_0:1;
+		CVMX_BITFIELD_FIELD(uint64_t len:16,
+		CVMX_BITFIELD_FIELD(uint64_t zero_0:1,
 		/**
 		 * HW sets this to what it thought the priority of the input packet was
 		 */
-		uint64_t qos:3;
+		CVMX_BITFIELD_FIELD(uint64_t qos:3,
 
-		uint64_t zero_1:1;
+		CVMX_BITFIELD_FIELD(uint64_t zero_1:1,
 		/**
 		 * the group that the work queue entry will be scheduled to
 		 */
-		uint64_t grp:6;
-		uint64_t zero_2:3;
-		cvmx_pow_tag_type_t tag_type:2;
-		uint64_t tag:32;
+		CVMX_BITFIELD_FIELD(uint64_t grp:6,
+		CVMX_BITFIELD_FIELD(uint64_t zero_2:3,
+		CVMX_BITFIELD_FIELD(cvmx_pow_tag_type_t tag_type:2,
+		CVMX_BITFIELD_FIELD(uint64_t tag:32,
+		))))))));
 	} cn68xx;
 	struct {
-		uint64_t len:16;
+		CVMX_BITFIELD_FIELD(uint64_t len:16,
 		/**
 		 * HW sets this to input physical port
 		 */
-		uint64_t ipprt:6;
+		CVMX_BITFIELD_FIELD(uint64_t ipprt:6,
 
 		/**
 		 * HW sets this to what it thought the priority of the input packet was
 		 */
-		uint64_t qos:3;
+		CVMX_BITFIELD_FIELD(uint64_t qos:3,
 
 		/**
 		 * the group that the work queue entry will be scheduled to
 		 */
-		uint64_t grp:4;
-		uint64_t zero_2:1;
-		cvmx_pow_tag_type_t tag_type:2;
-		uint64_t tag:32;
+		CVMX_BITFIELD_FIELD(uint64_t grp:4,
+		CVMX_BITFIELD_FIELD(uint64_t zero_2:1,
+		CVMX_BITFIELD_FIELD(cvmx_pow_tag_type_t tag_type:2,
+		CVMX_BITFIELD_FIELD(uint64_t tag:32,
+		)))))));
 	} cn38xx;
-#else
-	struct {
-		uint64_t tag:32;
-		cvmx_pow_tag_type_t tag_type:2;
-		uint64_t varies:14;
-		uint64_t len:16;
-	};
-	struct {
-		uint64_t tag:32;
-		cvmx_pow_tag_type_t tag_type:2;
-		/**
-		 * the group that the work queue entry will be scheduled to
-		 */
-		uint64_t grp:10;
-		uint64_t rsvd_1:2;
-		uint64_t rsvd_0:2;
-		uint64_t len:16;
-	} cn78xx;
-	struct {
-		uint64_t tag:32;
-		cvmx_pow_tag_type_t tag_type:2;
-		uint64_t zero_2:3;
-		uint64_t grp:6;
-		uint64_t zero_1:1;
-		uint64_t qos:3;
-		uint64_t zero_0:1;
-		uint64_t len:16;
-	} cn68xx;
-	struct {
-		uint64_t tag:32;
-		cvmx_pow_tag_type_t tag_type:2;
-		uint64_t zero_2:1;
-		uint64_t grp:4;
-		uint64_t qos:3;
-		uint64_t ipprt:6;
-		uint64_t len:16;
-	} cn38xx;
-#endif
 } cvmx_wqe_word1_t;
 
 /**
@@ -995,44 +960,43 @@ typedef struct cvmx_wqe_s {
  * must be 8-byte aligned
  */
 typedef struct {
+	/*****************************************************************
+	 * WORD 0
+	 *  HW WRITE: the following 64 bits are filled by HW when a packet arrives
+	 */
+	cvmx_pki_wqe_word0_t word0;
 
-    /*****************************************************************
-	* WORD 0
-	*  HW WRITE: the following 64 bits are filled by HW when a packet arrives
-    */
-
-	cvmx_wqe_word0_t word0;
+	/*****************************************************************
+	 * WORD 1
+	 *  HW WRITE: the following 64 bits are filled by HW when a packet arrives
+	 */
 
-    /*****************************************************************
-	* WORD 1
-	*  HW WRITE: the following 64 bits are filled by HW when a packet arrives
-    */
+	cvmx_pki_wqe_word1_t word1;
 
-	cvmx_wqe_word1_t word1;
-    /**
+	/**
 	 * WORD 2
 	 *   HW WRITE: the following 64-bits are filled in by hardware when a packet arrives
 	 *   This indicates a variety of status and error conditions.
-     */
-	cvmx_wqe_word2_t word2;
+	 */
+	cvmx_pki_wqe_word2_t word2;
 
-    /**
+	/**
 	 * Pointer to the first segment of the packet.
          * WORD 3
-     */
+	 */
 	cvmx_buf_ptr_pki_t packet_ptr;
 
-    /**
+	/**
          * WORD 4
          *   HW WRITE: the following 64-bits are filled in by hardware when a packet arrives
 	 *   contains a byte pointer to the start of Layer A/B/C/D/E/F/G relative of start of packet
-     */
+	 */
 
-	cvmx_wqe_word4_t word4;
+	cvmx_pki_wqe_word4_t word4;
 
-    /**
+	/**
          * WORD 5/6/7 may be extended here if WQE_HSZ is set to !0
-     */
+	 */
 
 } CVMX_CACHE_LINE_ALIGNED cvmx_wqe_78xx_t;
 
@@ -1052,13 +1016,13 @@ static inline int cvmx_wqe_get_port(cvmx_wqe_t *work)
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		/* In 78xx wqe entry has channel number not port*/
 		port = work->word0.pki.channel;
-		/* For BGX interfaces (0x8xx - 0xdff) the 4 LSBs indicate
+		/* For BGX interfaces (0x800 - 0xdff) the 4 LSBs indicate
 		 * the PFC channel, must be cleared to normalize to "ipd"
 		 */
 		if (port & 0x800)
 			port &= 0xff0;
 		/* Node number is in AURA field, make it part of port # */
-		port |= (work->word0.pki.aura >> 10) << 14;
+		port |= (work->word0.pki.aura >> 10) << 12;
 	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		port = work->word2.s_cn68xx.port;
 	else
@@ -1083,7 +1047,8 @@ static inline int cvmx_wqe_get_grp(cvmx_wqe_t *work)
 	int grp;
 
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
-		grp = work->word1.cn78xx.grp;
+		/* legacy: GRP[0..2] :=QOS */
+		grp = (0xff & work->word1.cn78xx.grp) >> 3;
 	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		grp = work->word1.cn68xx.grp;
 	else
@@ -1092,7 +1057,7 @@ static inline int cvmx_wqe_get_grp(cvmx_wqe_t *work)
 	return grp;
 }
 
-static inline void cvmx_wqe_set_grp(cvmx_wqe_t *work, int grp)
+static inline void cvmx_wqe_set_xgrp(cvmx_wqe_t *work, int grp)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		work->word1.cn78xx.grp = grp;
@@ -1102,13 +1067,41 @@ static inline void cvmx_wqe_set_grp(cvmx_wqe_t *work, int grp)
 		work->word1.cn38xx.grp = grp;
 }
 
+static inline int cvmx_wqe_get_xgrp(cvmx_wqe_t *work)
+{
+	int grp;
+
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		grp = work->word1.cn78xx.grp;
+	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
+		grp = work->word1.cn68xx.grp;
+	else
+		grp = work->word1.cn38xx.grp;
+
+	return grp;
+}
+
+static inline void cvmx_wqe_set_grp(cvmx_wqe_t *work, int grp)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		unsigned node = cvmx_get_node_num();
+		/* legacy: GRP[0..2] :=QOS */
+		work->word1.cn78xx.grp = grp << 3;
+		work->word1.cn78xx.grp |= node;
+	} if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
+		work->word1.cn68xx.grp = grp;
+	else
+		work->word1.cn38xx.grp = grp;
+}
+
 static inline int cvmx_wqe_get_qos(cvmx_wqe_t *work)
 {
 	int qos;
 
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
-		qos = work->word1.cn78xx.grp & 0x7; /* convention */
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		/* legacy: GRP[0..2] :=QOS */
+		qos = work->word1.cn78xx.grp & 0x7;
+	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		qos = work->word1.cn68xx.qos;
 	else
 		qos = work->word1.cn38xx.qos;
@@ -1118,7 +1111,11 @@ static inline int cvmx_wqe_get_qos(cvmx_wqe_t *work)
 
 static inline void cvmx_wqe_set_qos(cvmx_wqe_t *work, int qos)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		/* legacy: GRP[0..2] :=QOS */
+		work->word1.cn78xx.grp &= ~0x7;
+		work->word1.cn78xx.grp |= qos & 0x7;
+	} else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		work->word1.cn68xx.qos = qos;
 	else
 		work->word1.cn38xx.qos = qos;
@@ -1157,10 +1154,10 @@ static inline void cvmx_wqe_set_len(cvmx_wqe_t *work, int len)
 static inline int cvmx_wqe_get_rcv_err(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		cvmx_wqe_78xx_t* wqe = (void*)work;
-		if (wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_RE ||
-				  wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_LA)
-			return(wqe->word2.pki.err_code);
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		if (wqe->word2.err_level == CVMX_PKI_ERRLEV_E_RE ||
+		    wqe->word2.err_level == CVMX_PKI_ERRLEV_E_LA)
+			return(wqe->word2.err_code);
 	}
 	else if (work->word2.snoip.rcv_error)
 		return (work->word2.snoip.err_code);
@@ -1197,26 +1194,50 @@ static inline void cvmx_wqe_set_tt(cvmx_wqe_t *work, int tt)
 	}
 }
 
-static inline int cvmx_wqe_get_unused8(cvmx_wqe_t *work)
+static inline uint8_t cvmx_wqe_get_unused8(cvmx_wqe_t *work)
 {
-	int len;
+	uint8_t bits;
 
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
-		len = work->word0.pip.cn68xx.unused1;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		{
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		bits = wqe->word2.rsvd_0;
+		}
+	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
+		bits = work->word0.pip.cn68xx.unused1;
 	else
-		len = work->word0.pip.cn38xx.unused;
+		bits = work->word0.pip.cn38xx.unused;
 
-	return len;
+	return bits;
 }
 
-static inline void cvmx_wqe_set_unused8(cvmx_wqe_t *work, int v)
+static inline void cvmx_wqe_set_unused8(cvmx_wqe_t *work, uint8_t v)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		{
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		wqe->word2.rsvd_0 = v;
+		}
+	else if (octeon_has_feature(OCTEON_FEATURE_CN68XX_WQE))
 		work->word0.pip.cn68xx.unused1 = v;
 	else
 		work->word0.pip.cn38xx.unused = v;
 }
 
+static inline uint8_t cvmx_wqe_get_user_flags(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		return work->word0.pki.rsvd_2;
+	else
+		return 0;
+}
+
+static inline void cvmx_wqe_set_user_flags(cvmx_wqe_t *work, uint8_t v)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
+		work->word0.pki.rsvd_2 = v;
+}
+
 static inline int cvmx_wqe_get_channel(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
@@ -1263,13 +1284,18 @@ static inline void cvmx_wqe_set_style(cvmx_wqe_t *work, int style)
 		work->word0.pki.style = style;
 }
 
-static inline int cvmx_wqe_is_ip(cvmx_wqe_t *work)
+/**
+ * Return non-zero if the packet Layer-3 protocol is either IPv4 or IPv6.
+ *
+ */
+static inline int cvmx_wqe_is_l3_ip(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		cvmx_wqe_78xx_t* wqe = (void *)work;
-		if((wqe->word2.pki.lc_hdr_type & 0x1c) == CVMX_PKI_LTYPE_E_IP4)
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		/* Match all 4 values for v4/v6 with.without options */
+		if((wqe->word2.lc_hdr_type & 0x1c) == CVMX_PKI_LTYPE_E_IP4)
 			return 1;
-		if((wqe->word2.pki.le_hdr_type & 0x1c) == CVMX_PKI_LTYPE_E_IP4)
+		if((wqe->word2.le_hdr_type & 0x1c) == CVMX_PKI_LTYPE_E_IP4)
 			return 1;
 		return 0;
 	} else
@@ -1277,13 +1303,14 @@ static inline int cvmx_wqe_is_ip(cvmx_wqe_t *work)
 
 }
 
-static inline int cvmx_wqe_is_ipv4(cvmx_wqe_t *work)
+static inline int cvmx_wqe_is_l3_ipv4(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		if((wqe->word2.pki.lc_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP4)
+		/* Match 2 values - with/wotuout options */
+		if((wqe->word2.lc_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP4)
 			return 1;
-		if((wqe->word2.pki.le_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP4)
+		if((wqe->word2.le_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP4)
 			return 1;
 		return 0;
 	} else
@@ -1294,13 +1321,14 @@ static inline int cvmx_wqe_is_ipv4(cvmx_wqe_t *work)
 
 }
 
-static inline int cvmx_wqe_is_ipv6(cvmx_wqe_t *work)
+static inline int cvmx_wqe_is_l3_ipv6(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		if((wqe->word2.pki.lc_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP6)
+		/* Match 2 values - with/wotuout options */
+		if((wqe->word2.lc_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP6)
 			return 1;
-		if((wqe->word2.pki.le_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP6)
+		if((wqe->word2.le_hdr_type & 0x1e) == CVMX_PKI_LTYPE_E_IP6)
 			return 1;
 		return 0;
 	} else
@@ -1310,11 +1338,32 @@ static inline int cvmx_wqe_is_ipv6(cvmx_wqe_t *work)
 			);
 }
 
+/**
+ * Return true if an IP packet has a Layer-4 protocol
+ * as TCP or UDP. and is not fragmented.
+ */
+static inline bool cvmx_wqe_is_l4_udp_or_tcp(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		if (wqe->word2.lf_hdr_type  == CVMX_PKI_LTYPE_E_TCP)
+			return true;
+		if (wqe->word2.lf_hdr_type  == CVMX_PKI_LTYPE_E_UDP)
+			return true;
+		return false;
+	} else {
+		if (work->word2.s_cn38xx.not_IP)
+			return false;
+		return (work->word2.s_cn38xx.tcp_or_udp != 0);
+	}
+}
+
+
 static inline int cvmx_wqe_is_l2_bcast(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		return (wqe->word2.pki.is_l2_bcast);
+		return (wqe->word2.is_l2_bcast);
 	} else
 		return (work->word2.s_cn38xx.is_bcast);
 }
@@ -1323,7 +1372,7 @@ static inline int cvmx_wqe_is_l2_mcast(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		return (wqe->word2.pki.is_l2_mcast);
+		return (wqe->word2.is_l2_mcast);
 	} else
 		return (work->word2.s_cn38xx.is_mcast);
 }
@@ -1332,7 +1381,7 @@ static inline int cvmx_wqe_is_l3_bcast(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		return (wqe->word2.pki.is_l3_bcast);
+		return (wqe->word2.is_l3_bcast);
 	} else
 		cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
 }
@@ -1341,7 +1390,7 @@ static inline int cvmx_wqe_is_l3_mcast(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)){
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		return (wqe->word2.pki.is_l3_mcast);
+		return (wqe->word2.is_l3_mcast);
 	} else
 		cvmx_dprintf("%s: ERROR: not supported for model\n",__func__);
 }
@@ -1359,9 +1408,9 @@ static inline int cvmx_wqe_is_ip_exception(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		if (wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_LC)
+		if (wqe->word2.err_level == CVMX_PKI_ERRLEV_E_LC)
 			return 1;
-		if (wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_LE)
+		if (wqe->word2.err_level == CVMX_PKI_ERRLEV_E_LE)
 			return 1;
 		else
 			return 0;
@@ -1369,11 +1418,11 @@ static inline int cvmx_wqe_is_ip_exception(cvmx_wqe_t *work)
 		return work->word2.s.IP_exc;
 }
 
-static inline int cvmx_wqe_is_L4_error(cvmx_wqe_t *work)
+static inline int cvmx_wqe_is_l4_error(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		if (wqe->word2.pki.err_level == CVMX_PKI_ERRLEV_E_LF)
+		if (wqe->word2.err_level == CVMX_PKI_ERRLEV_E_LF)
 			return 1;
 		else
 			return 0;
@@ -1385,7 +1434,7 @@ static inline int cvmx_wqe_is_vlan(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-			return wqe->word2.pki.vlan_valid;
+			return wqe->word2.vlan_valid;
 	} else
 		return work->word2.s.vlan_valid;
 }
@@ -1394,7 +1443,7 @@ static inline int cvmx_wqe_is_vlan_stacked(cvmx_wqe_t *work)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		return wqe->word2.pki.vlan_stacked;
+		return wqe->word2.vlan_stacked;
 	} else
 		return work->word2.s.vlan_stacked;
 }
@@ -1402,18 +1451,6 @@ static inline int cvmx_wqe_is_vlan_stacked(cvmx_wqe_t *work)
 /**
  * @INTERNAL
  *
- * Retreive WQE pool number from PIP/IPD register
- */
-static inline unsigned __cvmx_ipd_wqe_pool(void)
-{
-        cvmx_ipd_wqe_fpa_queue_t wqe_pool;
-        wqe_pool.u64 = cvmx_read_csr(CVMX_IPD_WQE_FPA_QUEUE);
-        return wqe_pool.s.wqe_pool;
-}
-
-/**
- * @INTERNAL
- *
  * Extract NO_WPTR mode from PIP/IPD register
  */
 static inline int __cvmx_ipd_mode_no_wptr(void)
@@ -1439,110 +1476,7 @@ static inline int __cvmx_ipd_mode_no_wptr(void)
  * If the packet data is only found inside the work queue entry,
  * a standard buffer pointer structure is created for it.
  */
-static inline cvmx_buf_ptr_t cvmx_wqe_get_packet_ptr(cvmx_wqe_t *work)
-{
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		cvmx_wqe_78xx_t * wqe = (void *) work;
-		cvmx_buf_ptr_t optr, lptr;
-		cvmx_buf_ptr_pki_t nptr;
-		unsigned pool, bufs;
-
-		/* In case of repeated calls of this function */
-		if (wqe->pki_wqe_translated) {
-			optr.u64 = wqe->packet_ptr.u64;
-			return optr;
-		}
-
-		bufs = wqe->word0.pki.bufs;
-		pool = wqe->word0.pki.aura;
-		nptr.u64 = wqe->packet_ptr.u64;
-
-		optr.u64=0;
-		optr.s.pool = pool;
-		optr.s.addr = nptr.s_cn78xx.addr;
-		optr.s.size = nptr.s_cn78xx.size;
-
-		/* Calculate the "back" offset */
-		if (!nptr.s_cn78xx.packet_outside_wqe)
-			optr.s.back = (nptr.s_cn78xx.addr-cvmx_ptr_to_phys(wqe))
-				>> 7;
-		else
-			optr.s.back = 0; //XXX assume <128, get actual pool sz
-
-		lptr = optr;
-
-		/* Follow pointer and convert all linked pointers */
-		while (bufs > 1) {
-			void * vptr;
-
-			vptr = cvmx_phys_to_ptr(lptr.s.addr);
-
-			memcpy(&nptr, vptr - 8, 8);
-
-			lptr.u64=0;
-			lptr.s.pool = pool;
-			lptr.s.addr = nptr.s_cn78xx.addr;
-			lptr.s.size = nptr.s_cn78xx.size;
-			lptr.s.back = 0;	//XXX- not guarangeed !!
-
-			memcpy(vptr-8, &lptr, 8);
-			bufs --;
-		}
-		/* Store translated bufptr in WQE, and set indicator */
-		wqe->pki_wqe_translated = 1;
-		wqe->packet_ptr.u64 = optr.u64;
-		return optr;
-
-	} else {
-		cvmx_buf_ptr_t bptr;
-
-		if ( work->word2.s.bufs > 0)
-			return work->packet_ptr;
-
-		/* data is only in WQE, convert it into a buf_ptr */
-		bptr.u64 = 0;
-		bptr.s.size = cvmx_wqe_get_len(work);
-		bptr.s.pool = __cvmx_ipd_wqe_pool();
-		bptr.s.addr = cvmx_ptr_to_phys(work) + 32;
-
-		/* For CN68XX it could be NO_WPTR or Dynamic-Short cause */
-		if (__cvmx_ipd_mode_no_wptr()) {
-			/* Packet pool is hardwired to 0 in relevant SoCs */
-			bptr.s.pool = 0;
-		}
-
-		/* FIXME- RAWFULL case not handled yet */
-
-		if (work->word2.s_cn38xx.not_IP ||
-		    work->word2.s_cn38xx.rcv_error) {
-			/* Adjust data offset for non-IP packets */
-                        union cvmx_pip_gbl_cfg pip_gbl_cfg;
-                        pip_gbl_cfg.u64 = cvmx_read_csr(CVMX_PIP_GBL_CFG);
-                        bptr.s.addr += pip_gbl_cfg.s.nip_shf;
-		} else {
-			/* Adjust data start address for IP protocols */
-                        union cvmx_pip_ip_offset pip_ip_offset;
-                        pip_ip_offset.u64 = cvmx_read_csr(CVMX_PIP_IP_OFFSET);
-                        bptr.s.addr += (pip_ip_offset.s.offset << 3) -
-				work->word2.s.ip_offset;
-                        bptr.s.addr += (work->word2.s.is_v6 ^ 1) << 2;
-		}
-
-		/* Calculate the "back" offset in 64-bit words */
-		bptr.s.back = (bptr.s.addr -cvmx_ptr_to_phys(work)) >> 7;
-
-		/* Store the new buffer pointer back into WQE */
-		work->packet_ptr = bptr;
-
-		/* Adjust word2.bufs so that _free_data() handles it
-		 * in the same way as PKO
-		 */
-		work->word2.s.bufs = 1;
-
-		/* Returned the synthetic buffer_pointer */
-		return bptr;
-	}
-}
+cvmx_buf_ptr_t cvmx_wqe_get_packet_ptr(cvmx_wqe_t *work);
 
 static inline int cvmx_wqe_get_bufs(cvmx_wqe_t *work)
 {
@@ -1551,9 +1485,11 @@ static inline int cvmx_wqe_get_bufs(cvmx_wqe_t *work)
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 		bufs = work->word0.pki.bufs;
 	else {
+#ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 		/* Adjust for packet-in-WQE cases */
 		if(work->word2.s_cn38xx.bufs == 0)
 			(void) cvmx_wqe_get_packet_ptr(work);
+#endif
 		bufs = work->word2.s_cn38xx.bufs;
 	}
 
@@ -1570,162 +1506,245 @@ static inline int cvmx_wqe_get_bufs(cvmx_wqe_t *work)
  * It can also follow a call to cvmx_helper_free_packet_data()
  * to release the WQE after associated data was released.
  */
-static inline void cvmx_wqe_free(cvmx_wqe_t *work)
+void cvmx_wqe_free(cvmx_wqe_t *work);
+
+/**
+ * Check if a work entry has been intiated by software
+ *
+ */
+static inline bool cvmx_wqe_is_soft(cvmx_wqe_t *work)
 {
-	unsigned ncl;
-	unsigned pool;
-	uint64_t paddr;
-	cvmx_wqe_78xx_t * wqe = (void *) work;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		return wqe->word2.software;
+	} else
+		return work->word2.s.software;
+}
 
-	/* Free native untranslated 78xx WQE */
-	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE) &&
-		!wqe->pki_wqe_translated) {
-		cvmx_buf_ptr_pki_t bptr;
+/**
+ * Allocate a work-queue entry for delivering software-initiated
+ * event notifications.
+ * The application data is copied into the work-queue entry,
+ * if the space is sufficient.
+ */
+extern cvmx_wqe_t * cvmx_wqe_soft_create(void *data_p, unsigned data_sz);
 
-		bptr = wqe->packet_ptr;
 
-		/* Do nothing if the first packet buffer shares WQE buffer */
-		if (!bptr.s_cn78xx.packet_outside_wqe)
-			return;
-	} else {
-		/* determine if packet is inside WQE the old way */
-		if (cvmx_wqe_get_bufs(work) > 0) {
-			/* Check if the first data buffer is inside WQE */
-			paddr = (work->packet_ptr.s.addr >> 7) -
-				work->packet_ptr.s.back;
-			paddr = paddr << 7;
-
-			/* do not free WQE if contains first data buffer */
-			if (paddr == cvmx_ptr_to_phys(work))
-				return;
-		}
+/**
+ * @INTERNAL
+ *
+ * Extract the native PKI-specific buffer pointer from WQE.
+ *
+ * NOTE: Provisional, may be superceded.
+ */
+static inline cvmx_buf_ptr_pki_t cvmx_wqe_get_pki_pkt_ptr(cvmx_wqe_t *work)
+{
+	cvmx_wqe_78xx_t * wqe = (void *) work;
+	if (!octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_buf_ptr_pki_t x = {0};
+		return x;
 	}
+	return wqe->packet_ptr;
+}
 
-	/* At this point it is clear the WQE needs to be freed */
+/**
+ * Set the buffer segment count for a packet.
+ *
+ * @return Returns the actual resulting value in the WQE fielda
+ *
+ */ 
+static inline unsigned cvmx_wqe_set_bufs(cvmx_wqe_t *work, unsigned bufs)
+{
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		unsigned node, laura;
-		/* First buffer outside WQE, but WQE comes from the same AURA */
-		node = wqe->word0.pki.aura >> 10;
-		laura = wqe->word0.pki.aura & ((1<<10)-1);
+		work->word0.pki.bufs = bufs;
+	} else {
+		work->word2.s.bufs = bufs;
+	}
 
-		/* Only a few words have been touched, not entire buf */
-		ncl = 1;
+	return cvmx_wqe_get_bufs(work);
+}
 
-		cvmx_fpa_free_aura(work, node, laura, ncl);
+/**
+ * Get the offset of Layer-3 header,
+ * only supported when Layer-3 protocol is IPv4 or IPv6.
+ *
+ * @return Returns the offset, or 0 if the offset is not known or unsupported.
+ *
+ * FIXME: Assuming word4 is present.
+ */
+static inline unsigned cvmx_wqe_get_l3_offset(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		/* Match 4 values: IPv4/v6 w/wo options */
+	        if ((wqe->word2.lc_hdr_type & 0x1c) == CVMX_PKI_LTYPE_E_IP4)
+			return wqe->word4.ptr_layer_c;
 	} else {
-		/* Determine FPA pool the WQE buffer belongs to */
-		if (__cvmx_ipd_mode_no_wptr()) {
-			pool = 0 ; /* Hardwired packet FPA pool */
-			ncl = (cvmx_wqe_get_len(work) + 127) >> 7;
-			ncl += 4;
-		} else {
-			pool = __cvmx_ipd_wqe_pool();
-			ncl = 1;
-		}
-
-		cvmx_fpa1_free(work, pool, ncl);
+		return work->word2.s.ip_offset;
 	}
+	return 0;
 }
 
 /**
- * Check if a work entry has been intiated by software
+ * Set the offset of Layer-3 header in a packet.
+ * Typically used when an IP packet is generated by software
+ * or when the Layer-2 header length is modified, and
+ * a subsequent recalculation of checksums is anticipated.
+ *
+ * @return Returns the actual value of the work entry offset field.
  *
+ * FIXME: Assuming word4 is present.
  */
-static inline bool cvmx_wqe_is_soft(cvmx_wqe_t *work)
+static inline unsigned cvmx_wqe_set_l3_offset(cvmx_wqe_t *work, unsigned ip_off)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		cvmx_wqe_78xx_t* wqe = (void *)work;
-		return wqe->word2.pki.software;
-	} else
-		return work->word2.s.software;
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		/* Match 4 values: IPv4/v6 w/wo options */
+	        if ((wqe->word2.lc_hdr_type & 0x1c) == CVMX_PKI_LTYPE_E_IP4)
+			wqe->word4.ptr_layer_c = ip_off;
+	} else {
+		work->word2.s.ip_offset = ip_off;
+	}
+
+	return cvmx_wqe_get_l3_offset(work);
 }
 
-#if 0  /* What is this for?  there are no users.  Move to .c file if needed. */
 /**
- * Allocate a work-queue entry for delivering software-initiated
- * event notifications (as opposed to packet data).
- * The application data is copied into the work-queue entry,
- * if the space is sufficient.
+ * Set the indication that the packet contains a IPv4 Layer-3 * header.
+ * Use 'cvmx_wqe_set_l3_ipv6()' if the protocol is IPv6.
+ * When 'set' is false, the call will result in an indication
+ * that the Layer-3 protocol is neither IPv4 nor IPv6.
+ *
+ * FIXME: Add IPV4_OPT handling based on L3 header length.
  */
-static inline cvmx_wqe_t * cvmx_wqe_soft_create(void *data_p, unsigned data_sz)
+static inline void cvmx_wqe_set_l3_ipv4(cvmx_wqe_t *work, bool set)
 {
-	cvmx_wqe_t *work = NULL;
-	unsigned pool = 0, gaura = 0;
-	unsigned buf_sz = 128;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		if (set)
+			wqe->word2.lc_hdr_type = CVMX_PKI_LTYPE_E_IP4;
+		else
+			wqe->word2.lc_hdr_type = CVMX_PKI_LTYPE_E_NONE;
+	} else {
+		work->word2.s.not_IP = !set;
+		if (set)
+			work->word2.s_cn38xx.is_v6 = 0;
+	}
+}
 
+/**
+ * Set packet Layer-3 protocol to IPv6.
+ *
+ * FIXME: Add IPV6_OPT handling based on presence of extended headers.
+ */
+static inline void cvmx_wqe_set_l3_ipv6(cvmx_wqe_t *work, bool set)
+{
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		cvmx_pki_qpg_tblx_t qpg_tbl;
-		unsigned node = cvmx_get_node_num();
+		cvmx_wqe_78xx_t* wqe = (void *)work;
+		if (set)
+			wqe->word2.lc_hdr_type = CVMX_PKI_LTYPE_E_IP6;
+		else
+			wqe->word2.lc_hdr_type = CVMX_PKI_LTYPE_E_NONE;
+	} else {
+		work->word2.s_cn38xx.not_IP = !set;
+		if(set)
+			work->word2.s_cn38xx.is_v6 = 1;
+	}
 
-		/* Use PKI default AURA for these work entries */
-		qpg_tbl.u64 = cvmx_read_csr_node(node, CVMX_PKI_QPG_TBLX(0));
-		gaura = qpg_tbl.s.laura;
-		gaura |= node << 10;
+}
 
-		/* Check if WQE space is large enough */
-#ifndef	CVMX_BUILD_FOR_LINUX_KERNEL
-		buf_sz = cvmx_fpa_get_aura_buf_size(gaura);
-#endif
-		buf_sz -= sizeof(cvmx_wqe_78xx_t);
-		if(buf_sz >= data_sz)
-			work = cvmx_fpa_alloc_aura(node, gaura & ((1<<10)-1));
+/**
+ * Set a packet Layer-4 protocol type to UDP.
+ */
+static inline void cvmx_wqe_set_l4_udp(cvmx_wqe_t *work, bool set)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		if (set)
+			wqe->word2.lf_hdr_type  = CVMX_PKI_LTYPE_E_UDP;
+		else
+			wqe->word2.lf_hdr_type  = CVMX_PKI_LTYPE_E_NONE;
 	} else {
-		pool = __cvmx_ipd_wqe_pool();
-#ifndef	CVMX_BUILD_FOR_LINUX_KERNEL
-		buf_sz = cvmx_fpa_get_block_size(pool);
-#endif
-		buf_sz -= offsetof(cvmx_wqe_t, packet_data);
-		if(buf_sz >= data_sz)
-			work = cvmx_fpa1_alloc(pool);
+		if (!work->word2.s_cn38xx.not_IP)
+			work->word2.s_cn38xx.tcp_or_udp = set;
 	}
+}
 
-	if(work == NULL)
-		return work;
-
-	work->word0.u64 = 0;
-	work->word1.u64 = 0;
-	work->word2.u64 = 0;
+/**
+ * Set a packet Layer-4 protocol type to TCP.
+ *
+ */
+static inline void cvmx_wqe_set_l4_tcp(cvmx_wqe_t *work, bool set)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		if (set)
+			wqe->word2.lf_hdr_type  = CVMX_PKI_LTYPE_E_TCP;
+		else
+			wqe->word2.lf_hdr_type  = CVMX_PKI_LTYPE_E_NONE;
+	} else {
+		if (!work->word2.s_cn38xx.not_IP)
+			work->word2.s_cn38xx.tcp_or_udp = set;
+	}
+}
 
+/**
+ * Set the "software" flag in a work entry.
+ */
+static inline void cvmx_wqe_set_soft(cvmx_wqe_t *work, bool set)
+{
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_wqe_78xx_t* wqe = (void *)work;
-		wqe->word2.pki.software = 1;
-		wqe->word0.pki.aura = gaura;
-		wqe->packet_ptr.u64 = 0;
-		if (data_sz > 0) {
-			wqe->word0.pki.bufs = 1;
-			wqe->packet_ptr.s_cn78xx.size = data_sz;
-			wqe->packet_ptr.s_cn78xx.addr = cvmx_ptr_to_phys(wqe+1);
-			memcpy(wqe+1, data_p, data_sz);
-		}
+		wqe->word2.software = set;
 	} else {
-		work->word2.s.software = 1;
-		work->packet_ptr.u64 = 0;
-		work->packet_ptr.s.pool = pool;
-		if (data_sz > 0) {
-			work->packet_ptr.s.size = data_sz;
-			work->packet_ptr.s.addr =
-				cvmx_ptr_to_phys(&work->packet_data);
-			memcpy(&work->packet_data, data_p, data_sz);
-		}
+		work->word2.s.software = set;
 	}
+}
 
-	cvmx_wqe_set_len(work, data_sz);
+/**
+ * Return true if the packet is an IP fragment.
+ */
+static inline bool  cvmx_wqe_is_l3_frag(cvmx_wqe_t *work)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		return (wqe->word2.is_frag != 0);
+	} else {
+		if (!work->word2.s_cn38xx.not_IP)
+			return (work->word2.s.is_frag != 0);
+		else
+			return false;
+	}
+}
 
-	return work;
+/**
+ * Set the indicator that the packet is an fragmented IP packet.
+ */
+static inline void cvmx_wqe_set_l3_frag(cvmx_wqe_t *work, bool set)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		wqe->word2.is_frag = set;
+	} else {
+		if (!work->word2.s_cn38xx.not_IP)
+			work->word2.s.is_frag = set;
+	}
 }
-#endif
 
 /**
- * @INTERNAL
- *
- * Extract the native PKI-specific buffer pointer from WQE.
- *
- * NOTE: Provisional, may be superceded.
+ * Return true if the packet Layer-3 protocol is ARP.
  */
-static inline cvmx_buf_ptr_pki_t cvmx_wqe_get_pki_pkt_ptr(cvmx_wqe_t *work)
+static inline bool cvmx_wqe_is_l3_arp(cvmx_wqe_t *work) 
 {
-	cvmx_wqe_78xx_t * wqe = (void *) work;
-	return wqe->packet_ptr;
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		cvmx_wqe_78xx_t *wqe = (void *)work;
+		return (wqe->word2.lc_hdr_type  == CVMX_PKI_LTYPE_E_ARP);
+	} else {
+		if (work->word2.s_cn38xx.not_IP)
+			return (work->word2.snoip.is_arp != 0);
+		else
+			return false;
+	}
 }
 
 #ifdef	__cplusplus
diff --git a/arch/mips/include/asm/octeon/cvmx.h b/arch/mips/include/asm/octeon/cvmx.h
index 2664705..0f980a8c 100644
--- a/arch/mips/include/asm/octeon/cvmx.h
+++ b/arch/mips/include/asm/octeon/cvmx.h
@@ -85,10 +85,10 @@ static inline unsigned int cvmx_get_node_num(void)
 	return (core_num >> CVMX_NODE_NO_SHIFT) & CVMX_NODE_MASK;
 }
 
-#include "cvmx-packet.h"
 #include "cvmx-sysinfo.h"
 
 #include "cvmx-address.h"
+#include "cvmx-packet.h"
 
 #include <asm/octeon/octeon-model.h>
 #include "cvmx-csr-enums.h"
@@ -285,12 +285,12 @@ static inline void cvmx_write_csr_node(uint64_t node, uint64_t csr_addr,
 				       uint64_t val)
 {
 	uint64_t node_addr;
-
+	uint64_t composite_csr_addr;
 	node_addr = (node & CVMX_NODE_MASK) << CVMX_NODE_IO_SHIFT;
 
-	csr_addr = (csr_addr & ~CVMX_NODE_IO_MASK) | node_addr;
+	composite_csr_addr = (csr_addr & ~CVMX_NODE_IO_MASK) | node_addr;
 
-	cvmx_write64_uint64(csr_addr, val);
+	cvmx_write64_uint64(composite_csr_addr, val);
 	if (((csr_addr >> 40) & 0x7ffff) == (0x118)) {
 		cvmx_read64_uint64(CVMX_MIO_BOOT_BIST_STAT | node_addr);
 	}
@@ -435,7 +435,7 @@ extern uint64_t octeon_get_clock_rate(void);
  * 2) Check if ("type".s."field" "op" "value")
  * 3) If #2 isn't true loop to #1 unless too much time has passed.
  */
-#define CVMX_WAIT_FOR_FIELD64(address, type, field, op, value, timeout_usec)\
+#define CVMX_WAIT_FOR_FIELD64_NODE(node, address, type, field, op, value, timeout_usec) \
     (									\
 {									\
 	int result;							\
@@ -444,7 +444,7 @@ extern uint64_t octeon_get_clock_rate(void);
 			octeon_get_clock_rate() / 1000000;		\
 		type c;							\
 		while (1) {						\
-			c.u64 = cvmx_read_csr(address);			\
+			c.u64 = cvmx_read_csr_node(node, address);	\
 			if ((c.s.field) op(value)) {			\
 				result = 0;				\
 				break;					\
@@ -458,16 +458,17 @@ extern uint64_t octeon_get_clock_rate(void);
 	result;								\
 })
 
+
+
 /***************************************************************************/
+#define CVMX_WAIT_FOR_FIELD64(address, type, field, op, value, timeout_usec) \
+	CVMX_WAIT_FOR_FIELD64_NODE(0, address, type, field, op, value, timeout_usec)
 
 /* Return the number of cores available in the chip */
 static inline uint32_t cvmx_octeon_num_cores(void)
 {
 	u64 ciu_fuse;
-	if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-		ciu_fuse = cvmx_read_csr(CVMX_CIU3_FUSE);
-	else
-		ciu_fuse = cvmx_read_csr(CVMX_CIU_FUSE) & 0xffffffffull;
+	ciu_fuse = cvmx_read_csr(CVMX_CIU_FUSE);
 	return cvmx_dpop(ciu_fuse);
 }
 
diff --git a/arch/mips/include/asm/octeon/octeon-model.h b/arch/mips/include/asm/octeon/octeon-model.h
index 9515f30..f0c18f6 100644
--- a/arch/mips/include/asm/octeon/octeon-model.h
+++ b/arch/mips/include/asm/octeon/octeon-model.h
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2003-2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -43,7 +43,7 @@
  * File defining different Octeon model IDs and macros to
  * compare them.
  *
- * <hr>$Revision: 92253 $<hr>
+ * <hr>$Revision: 95942 $<hr>
  */
 
 #ifndef __OCTEON_MODEL_H__
@@ -100,16 +100,22 @@ extern "C" {
  */
 
 #define OCTEON_CN70XX_PASS1_0   0x000d9600
+#define OCTEON_CN70XX_PASS1_1   0x000d9601
+
+#define OCTEON_CN70XX_PASS2_0   0x000d9608
 
 #define OCTEON_CN70XX           (OCTEON_CN70XX_PASS1_0 | OM_IGNORE_REVISION)
 #define OCTEON_CN70XX_PASS1_X   (OCTEON_CN70XX_PASS1_0 | OM_IGNORE_MINOR_REVISION)
+#define OCTEON_CN70XX_PASS2_X   (OCTEON_CN70XX_PASS2_0 | OM_IGNORE_MINOR_REVISION)
 
 #define OCTEON_CN71XX		OCTEON_CN70XX
 
 #define OCTEON_CN78XX_PASS1_0   0x000d9500
+#define OCTEON_CN78XX_PASS2_0   0x000d9508
 
 #define OCTEON_CN78XX           (OCTEON_CN78XX_PASS1_0 | OM_IGNORE_REVISION)
 #define OCTEON_CN78XX_PASS1_X   (OCTEON_CN78XX_PASS1_0 | OM_IGNORE_MINOR_REVISION)
+#define OCTEON_CN78XX_PASS2_X   (OCTEON_CN78XX_PASS2_0 | OM_IGNORE_MINOR_REVISION)
 
 /*
  * CNF7XXX models with new revision encoding
diff --git a/drivers/net/ethernet/octeon/ethernet.c b/drivers/net/ethernet/octeon/ethernet.c
index aee934d..69da1dc 100644
--- a/drivers/net/ethernet/octeon/ethernet.c
+++ b/drivers/net/ethernet/octeon/ethernet.c
@@ -866,7 +866,7 @@ static int cvm_oct_probe(struct platform_device *pdev)
 		}
 	}
 
-	cvmx_helper_ipd_and_packet_input_enable();
+	cvmx_helper_ipd_and_packet_input_enable_node(0);
 
 	/* Initialize the FAU used for counting packet buffers that
 	 * need to be freed.
-- 
2.6.2

