From 837b6bd079cf62743af754fbc6d9b438611318a6 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Sun, 2 Mar 2014 13:46:59 -0800
Subject: [PATCH 566/974] MIPS: OCTEON: Update S.E. to r99468.

Signed-off-by: David Daney <david.daney@cavium.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/cavium-octeon/executive/cvmx-bch.c       |  43 +---
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c |  36 ++-
 .../mips/cavium-octeon/executive/cvmx-helper-pki.c |  20 +-
 .../cavium-octeon/executive/cvmx-helper-pko3.c     |  28 ++-
 .../cavium-octeon/executive/cvmx-helper-sgmii.c    |   9 +-
 .../cavium-octeon/executive/cvmx-helper-srio.c     |   4 +-
 .../cavium-octeon/executive/cvmx-helper-util.c     |  25 +-
 .../cavium-octeon/executive/cvmx-helper-xaui.c     |   6 +-
 .../cavium-octeon/executive/cvmx-pki-resources.c   |   2 +
 arch/mips/cavium-octeon/executive/cvmx-pko3.c      |   6 +-
 arch/mips/include/asm/octeon/cvmx-app-init.h       |   4 +-
 arch/mips/include/asm/octeon/cvmx-cmd-queue.h      |   5 +-
 .../include/asm/octeon/cvmx-global-resources.h     |   1 +
 arch/mips/include/asm/octeon/cvmx-pki.h            |  56 ++++-
 arch/mips/include/asm/octeon/cvmx-pko3.h           | 256 +++++++++++++++------
 arch/mips/include/asm/octeon/cvmx-wqe.h            |   4 +-
 16 files changed, 346 insertions(+), 159 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-bch.c b/arch/mips/cavium-octeon/executive/cvmx-bch.c
index 5e2b3f4..c90a78d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-bch.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-bch.c
@@ -53,11 +53,7 @@
 # include <asm/octeon/cvmx-fpa1.h>
 # include <asm/octeon/cvmx-helper-fpa.h>
 # include <asm/octeon/cvmx-cmd-queue.h>
-#include <linux/kernel.h>
-#include <linux/slab.h>
-
 #elif defined(CVMX_BUILD_FOR_UBOOT)
-
 # include <common.h>
 # include <asm/arch/cvmx.h>
 # include <asm/arch/cvmx-bch-defs.h>
@@ -90,7 +86,6 @@ CVMX_SHARED cvmx_bch_app_config_t bch_config = {
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 extern int cvm_oct_mem_fill_fpa(int pool, int elements);
 extern int cvm_oct_alloc_fpa_pool(int pool, int size);
-static uint8_t *bounce_buff;
 #endif
 
 /**
@@ -108,7 +103,6 @@ int cvmx_bch_initialize(void)
 
 	/* Initialize FPA pool for BCH pool buffers */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	int i;
 	bch_pool = CVMX_FPA_OUTPUT_BUFFER_POOL;
 	bch_pool_size = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE;
 
@@ -121,11 +115,7 @@ int cvmx_bch_initialize(void)
 		pr_err("cvm_oct_alloc_fpa_pool(%d, %lld)\n", bch_pool, bch_pool_size);
 		return -ENOMEM;
 	}
-
-	for (i = 0; i < 16; i++) {
-		cvmx_fpa1_free(kmalloc(bch_pool_size, GFP_KERNEL), bch_pool, 0);
-	}
-	bounce_buff = cvmx_fpa1_alloc(bch_pool);
+	cvm_oct_mem_fill_fpa(bch_pool, 128);
 #else
 	bch_pool = (int)cvmx_fpa_get_bch_pool();
 	bch_pool_size = cvmx_fpa_get_bch_pool_block_size();
@@ -180,7 +170,6 @@ EXPORT_SYMBOL(cvmx_bch_initialize);
 int cvmx_bch_shutdown(void)
 {
 	cvmx_bch_ctl_t bch_ctl;
-	int bch_pool;
 
 	debug("%s: ENTER\n", __func__);
 	bch_ctl.u64 = cvmx_read_csr(CVMX_BCH_CTL);
@@ -188,26 +177,8 @@ int cvmx_bch_shutdown(void)
 	cvmx_write_csr(CVMX_BCH_CTL, bch_ctl.u64);
 	cvmx_wait(4);
 
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	bch_pool = CVMX_FPA_OUTPUT_BUFFER_POOL;
-#else
-	bch_pool = (int)cvmx_fpa_get_bch_pool();
-#endif
 	cvmx_cmd_queue_shutdown(CVMX_CMD_QUEUE_BCH);
 
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	/* FIXME: BCH cleanup in SE : AJ */
-	{
-		int i;
-		for (i = 0; i < 16; i++) {
-			kfree(cvmx_fpa1_alloc(bch_pool));
-		}
-		cvmx_fpa1_free(bounce_buff, bch_pool, 0);
-	}
-#else
-	cvmx_fpa_shutdown_pool(bch_pool);
-#endif
-	/* AJ: Fix for FPA3 */
 	return 0;
 }
 EXPORT_SYMBOL(cvmx_bch_shutdown);
@@ -257,14 +228,6 @@ int cvmx_bch_encode(const void *block, uint16_t block_size,
 
 	debug("%s(%p, %u, %u, %p, %p) ENTRY\n", __func__, block, block_size,
 	      ecc_level, ecc, response);
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	/* there was a problem when the first argument is used directly
-	 * despite of the fact it was 8-byte aligned (maybe not proper
-	 * cvmx_prt_to_phys), so we copy data to dedicated 'bounce_buff'
-	 * and set command.s.iword.prt to cvmx_ptr_to_phys((void *)bounce_buff)
-	 */
-	memcpy(bounce_buff, block, block_size);
-#endif
 	memset(&result, 0, sizeof(result));
 	memset(&command, 0, sizeof(command));
 	command.s.cword.ecc_gen = CVMX_BCH_INST_ECC_GENERATION;
@@ -272,11 +235,7 @@ int cvmx_bch_encode(const void *block, uint16_t block_size,
 	command.s.cword.size = block_size;
 
 	command.s.oword.ptr = cvmx_ptr_to_phys(ecc);
-#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	command.s.iword.ptr = cvmx_ptr_to_phys((void *)bounce_buff);
-#else
 	command.s.iword.ptr = cvmx_ptr_to_phys((void *)block);
-#endif
 	command.s.resp.ptr = cvmx_ptr_to_phys((void *)response);
 	debug("Command: cword: 0x%llx, oword: 0x%llx, iword: 0x%llx, resp: 0x%llx\n",
 	      command.u64[0], command.u64[1], command.u64[2], command.u64[3]);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
index 03e4eec..33e79f2 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -108,10 +108,8 @@ static void __cvmx_bgx_common_init(int xiface)
 	cvmx_bgxx_cmrx_config_t	cmr_config;
 	cvmx_bgxx_cmr_rx_lmacs_t bgx_cmr_rx_lmacs;
 	cvmx_bgxx_cmr_tx_lmacs_t bgx_cmr_tx_lmacs;
-	cvmx_bgxx_cmrx_rx_bp_on_t bgx_rx_bp_on;
 	cvmx_helper_interface_mode_t mode;
 	int num_ports;
-        int num_chl = 16; /*modify it to 64 for xlaui and xaui*/
 	int index;
 	int lmac_type = 0;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
@@ -168,6 +166,20 @@ static void __cvmx_bgx_common_init(int xiface)
 	bgx_cmr_tx_lmacs.s.lmacs = num_ports;
 	cvmx_write_csr_node(node, CVMX_BGXX_CMR_TX_LMACS(interface), bgx_cmr_tx_lmacs.u64);
 
+}
+
+static void __cvmx_bgx_common_init_pknd(int xiface)
+{
+	int num_ports;
+	int index;
+	int num_chl = 16; /*modify it to 64 for xlaui and xaui*/
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
+	int node = xi.node;
+	cvmx_bgxx_cmrx_rx_bp_on_t bgx_rx_bp_on;
+
+	num_ports = cvmx_helper_ports_on_interface(xiface);
+
 	/* Modify bp_on mark, depending on number of LMACS on that interface
 	and write it for every port */
 	bgx_rx_bp_on.u64 = 0;
@@ -208,6 +220,7 @@ static void __cvmx_bgx_common_init(int xiface)
  */
 int __cvmx_helper_bgx_probe(int xiface)
 {
+	__cvmx_bgx_common_init(xiface);	
 	return __cvmx_helper_bgx_enumerate(xiface);
 }
 
@@ -309,6 +322,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init(int xiface, int num_ports)
 	int node = xi.node;
 
 	__cvmx_bgx_common_init(xiface);
+	__cvmx_bgx_common_init_pknd(xiface);
 
 	for (index = 0; index < num_ports; index++) {
 		int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
@@ -663,6 +677,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 				 cvmx_helper_link_info_t link_info)
 {
+	cvmx_bgxx_cmrx_config_t cmr_config;
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
@@ -673,11 +688,17 @@ int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
 
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 	if (link_info.s.link_up) {
+		cmr_config.s.enable = 1;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
 		__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
 	} else {
 		cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
 
+		cmr_config.s.enable = 0;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 		gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 
 		/* Disable autonegotiation only when MAC mode. */
@@ -1092,6 +1113,7 @@ int __cvmx_helper_bgx_xaui_enable(int xiface)
 	int node = xi.node;
 
 	__cvmx_bgx_common_init(xiface);
+	__cvmx_bgx_common_init_pknd(xiface);
 	for (index = 0; index < num_ports; index++) {
 		int res = __cvmx_helper_bgx_xaui_init(index, xiface);
 		if (res == -1) {
@@ -1317,6 +1339,7 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 	cvmx_bgxx_cmrx_config_t cmr_config0;
 	cvmx_bgxx_gmp_gmi_txx_append_t gmp_txx_append;
 	cvmx_bgxx_gmp_gmi_txx_min_pkt_t gmp_min_pkt;
+	cvmx_bgxx_smux_tx_min_pkt_t smu_min_pkt;
 	cvmx_bgxx_smux_tx_append_t  smu_tx_append;
 
 	cmr_config0.u64 = cvmx_read_csr_node(node,
@@ -1334,7 +1357,8 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 
 	if (cmr_config.s.lmac_type == 0) {
 		gmp_min_pkt.u64 = 0;
-		gmp_min_pkt.s.min_size = 0x40;
+		/* per HRM Sec 34.3.4.4 */
+		gmp_min_pkt.s.min_size = 59;
 		cvmx_write_csr_node(node,
                         CVMX_BGXX_GMP_GMI_TXX_MIN_PKT(index, interface),
 			gmp_min_pkt.u64);
@@ -1346,6 +1370,12 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 			CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface),
 			gmp_txx_append.u64);
 	} else {
+		smu_min_pkt.u64 = 0;
+		/* HRM Sec 33.3.4.3 should read 64 */
+		 smu_min_pkt.s.min_size = 0x40;
+		cvmx_write_csr_node(node,
+                        CVMX_BGXX_SMUX_TX_MIN_PKT(index, interface),
+			smu_min_pkt.u64);
 		smu_tx_append.u64 = cvmx_read_csr_node(node,
 			CVMX_BGXX_SMUX_TX_APPEND(index, interface));
 		smu_tx_append.s.fcs_c = fcs_enable;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
index 30fdce6..7b2b4ca 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
@@ -283,6 +283,19 @@ int __cvmx_helper_pki_install_default_vlan(int node)
 	int bank;
 	uint64_t cl_mask = CVMX_PKI_CLUSTER_ALL;
 
+	if (OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X)) {
+		/* PKI-20858 */
+		int i;
+		for (i = 0; i < 4; i++) {
+			union cvmx_pki_clx_ecc_ctl ecc_ctl;
+			ecc_ctl.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_ECC_CTL(i));
+			ecc_ctl.s.pcam_en = 0;
+			ecc_ctl.s.pcam0_cdis = 1;
+			ecc_ctl.s.pcam1_cdis = 1;
+			cvmx_write_csr_node(node, CVMX_PKI_CLX_ECC_CTL(i), ecc_ctl.u64);
+		}
+	}
+
 	for (field = CVMX_PKI_PCAM_TERM_E_ETHTYPE0; field < CVMX_PKI_PCAM_TERM_E_ETHTYPE2; field++) {
 		bank = field & 0x01;
 
@@ -350,13 +363,10 @@ int __cvmx_helper_pki_global_setup(int node)
 	/* Setup the packet pools*/
 	__cvmx_helper_pki_setup_fpa_pools(node);
 #endif
-	/* __cvmx_helper_setup_global_cfg(node);*/ /* vinita_to_do */
 	/*set up default cluster*/
 	__cvmx_helper_setup_pki_cluster_groups(node);
 	//__cvmx_helper_pki_setup_sso_groups(node);
 	__cvmx_helper_setup_pki_qpg_table(node);
-	/* __cvmx_helper_setup_pki_pcam_table(node); *//* vinita_to_do */
-	/*set up default vlan */
 	return 0;
 }
 
@@ -482,7 +492,9 @@ void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs
                     cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pknd, cluster), pkind_cfg.u64);
                     cluster++;
                 }
-                cluster =0;
+                /* make sure fcs_strip and fcs_check is also enable/disable for the style used by that port*/
+                cvmx_pki_endis_fcs_check(node, pknd, has_fcs, has_fcs);
+                cluster = 0;
 	}
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
index 2579d2a..eb80686 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
@@ -79,8 +79,17 @@
  * be rarely used.
  */
 #ifndef CVMX_PKO3_POOL_BUFFERS
+#ifdef CVMX_PKO3_DQ_MAX_DEPTH
+/* Assume worst case of 16 words per command per DQ */
+#define CVMX_PKO3_POOL_BUFFERS (CVMX_PKO3_DQ_MAX_DEPTH*16/511*1024);
+#else
 #define CVMX_PKO3_POOL_BUFFERS (1024*4+1024)
 #endif
+#endif
+/* Simulator has limited memory, use fewer buffers */
+#ifndef	CVMX_PKO3_POOL_BUFS_SIM
+#define CVMX_PKO3_POOL_BUFS_SIM (1024*4+1024)
+#endif
 
 /* channels are present at L2 queue level by default */
 static const int cvmx_pko_default_channel_level = 0;
@@ -161,11 +170,14 @@ static int __cvmx_pko3_config_memory(unsigned node)
                         __func__, pool, block_size);
 	}
 
-	if (aura_num != pool) {
-		/* XXX- temporary - learn buffer count from SSO */
-		unsigned int cvmx_sso_entries = 0;
+	/* Simulator has limited memory */
+	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM)
+		buf_count = CVMX_PKO3_POOL_BUFS_SIM;
+	else
 		buf_count = CVMX_PKO3_POOL_BUFFERS;
-		buf_count += cvmx_sso_entries * 4 * 9 / CVMX_PKO3_POOL_BUFFER_SIZE;
+
+	if (aura_num != pool) {
+
 		cvmx_dprintf("%s: creating aura %u with %u buffers\n",
 			__func__, aura_num, buf_count);
 
@@ -935,12 +947,8 @@ int cvmx_helper_pko3_init_interface(int xiface)
 		res = __cvmx_pko3_helper_dqs_activate(xiface,
 			subif, pad_enable);
 #else
-		if (mode == CVMX_HELPER_INTERFACE_MODE_ILK)
-			res = __cvmx_pko3_helper_dqs_activate(xiface,
-				subif, pad_enable);
-		else
-			res = __cvmx_pko3_helper_dqs_activate(xiface,
-				subif, false);
+		/* PAD=false on all interfaces, it is broken */
+		res = __cvmx_pko3_helper_dqs_activate(xiface, subif, false);
 #endif
 		if (res < 0)
 			goto __cfg_error;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
index 29c2522..74c90e3 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 97202 $<hr>
+ * <hr>$Revision: 99347 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -213,7 +213,9 @@ static int __cvmx_helper_sgmii_hardware_init_link(int interface, int index)
 	 * Write PCS*_MR*_CONTROL_REG[RST_AN]=1 to ensure a fresh
 	 * sgmii negotiation starts.
 	 */
-	control_reg.s.an_en = 1;
+	phy_mode = cvmx_helper_get_mac_phy_mode(interface, index);
+	control_reg.s.an_en = !phy_mode;
+
 	/* Force a PCS reset by powering down the PCS interface */
 	control_reg.s.pwr_dn = 1;
 	cvmx_write_csr(CVMX_PCSX_MRX_CONTROL_REG(index, interface),
@@ -228,7 +230,6 @@ static int __cvmx_helper_sgmii_hardware_init_link(int interface, int index)
 		       control_reg.u64);
 
 	/* The Cortina PHY runs in 1000base-X mode */
-	phy_mode = cvmx_helper_get_mac_phy_mode(interface, index);
 	mode_1000x = cvmx_helper_get_1000x_mode(interface, index);
 	pcsx_miscx_ctl_reg.u64 =
 		cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
@@ -703,7 +704,7 @@ int __cvmx_helper_sgmii_link_set(int ipd_port,
 
 		pcsx_miscx_ctl_reg.u64 = cvmx_read_csr(CVMX_PCSX_MISCX_CTL_REG(index, interface));
 
-		/* Disable autonegotiation only when MAC mode. */
+		/* Disable autonegotiation only when MAC mode is enabled. */
 		if (pcsx_miscx_ctl_reg.s.mac_phy == 0) {
 			union cvmx_pcsx_mrx_control_reg control_reg;
 			control_reg.u64 = cvmx_read_csr(CVMX_PCSX_MRX_CONTROL_REG(index, interface));
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c b/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
index c0b8483..8ba5a07 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
@@ -127,8 +127,10 @@ int __cvmx_helper_srio_probe(int xiface)
  *
  * @return Zero on success, negative on failure
  */
-int __cvmx_helper_srio_enable(int interface)
+int __cvmx_helper_srio_enable(int xiface)
 {
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface;
 	int num_ports = cvmx_helper_ports_on_interface(interface);
 	int index;
 	cvmx_sriomaintx_core_enables_t sriomaintx_core_enables;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
index 68bbd1e..210c680 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
@@ -396,7 +396,9 @@ cvmx_buf_ptr_t cvmx_wqe_get_packet_ptr(cvmx_wqe_t *work)
 			optr.s.back = (nptr.addr-cvmx_ptr_to_phys(wqe))
 				>> 7;
 		else
-			optr.s.back = 0; //XXX assume <128, get actual pool sz
+                        optr.s.back = 0; /*((nptr.addr - pki_dflt_style[0].parm_cfg.first_skip) >> 7) << 7*/;
+
+ //XXX assume <128, get actual pool sz
 
 		lptr = optr;
 
@@ -419,7 +421,7 @@ cvmx_buf_ptr_t cvmx_wqe_get_packet_ptr(cvmx_wqe_t *work)
 			lptr.s.pool = pool;
 			lptr.s.addr = nptr.addr;
 			lptr.s.size = nptr.size;
-			lptr.s.back = 0;	//XXX- not guarangeed !!
+                        lptr.s.back = 0; //((nptr.addr - pki_dflt_style[0].parm_cfg.later_skip) >> 7) << 7;;	//XXX- not guarangeed !!
 
 			memcpy(vptr-8, &lptr, 8);
 			bufs --;
@@ -651,7 +653,6 @@ void cvmx_helper_setup_legacy_red(int pass_thresh, int drop_thresh)
 	buf_cnt = cvmx_fpa_get_packet_pool_buffer_count();
 	pass_thresh = buf_cnt - pass_thresh;
 	drop_thresh = buf_cnt - drop_thresh;
-
 	/* Map aura to bpid 0*/
 	bpid = 0;
 	cvmx_pki_write_aura_bpid(node, aura, bpid);
@@ -659,11 +660,10 @@ void cvmx_helper_setup_legacy_red(int pass_thresh, int drop_thresh)
 	ena_bp = 0;
 	/* enable RED */
 	ena_red = 1;
-	ena_drop = 1;
 	/* This will enable RED on all interfaces since
 	they all have packet buffer coming from  same aura */
-	cvmx_helper_setup_aura_qos(node, aura, ena_red, pass_thresh,
-				   drop_thresh, ena_bp, 0, ena_drop);
+        cvmx_helper_setup_aura_qos(node, aura, ena_red, ena_drop, pass_thresh,
+				   drop_thresh, ena_bp, 0);
 }
 
 /**
@@ -918,6 +918,7 @@ int cvmx_helper_get_bpid(int interface, int port)
 }
 EXPORT_SYMBOL(cvmx_helper_get_bpid);
 
+
 /**
  * Display interface statistics.
  *
@@ -934,16 +935,10 @@ void cvmx_helper_show_stats(int port)
 	if (octeon_has_feature(OCTEON_FEATURE_ILK))
 		__cvmx_helper_ilk_show_stats();
 
-	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		unsigned int node = cvmx_get_node_num();
-		cvmx_pki_get_port_stats(node, port, (struct cvmx_pki_port_stats *)&status);
-		cvmx_dprintf("port %d: the number of packets - pki: %d\n",
+        /* PIP stats */
+	cvmx_pip_get_port_stats(port, 0, &status);
+	cvmx_dprintf("port %d: the number of packets - ipd: %d\n",
 			     port, (int)status.packets);
-	} else { /* PIP stats */
-		cvmx_pip_get_port_stats(port, 0, &status);
-		cvmx_dprintf("port %d: the number of packets - ipd: %d\n",
-			     port, (int)status.packets);
-	}
 
 	/* PKO stats */
 	cvmx_pko_get_port_status(port, 0, &pko_status);
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
index 5231d73..e399902 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 96589 $<hr>
+ * <hr>$Revision: 99228 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -163,8 +163,6 @@ int __cvmx_helper_xaui_probe(int xiface)
 	mode.s.en = 1;
 	cvmx_write_csr(CVMX_GMXX_INF_MODE(interface), mode.u64);
 
-	__cvmx_helper_setup_gmx(interface, 1);
-
 	if (!OCTEON_IS_MODEL(OCTEON_CN68XX) && !OCTEON_IS_MODEL(OCTEON_CN70XX)) {
 		/*
 		 * Setup PKO to support 16 ports for HiGig2 virtual
@@ -358,6 +356,8 @@ int __cvmx_helper_xaui_enable(int xiface)
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
 
+	__cvmx_helper_setup_gmx(interface, 1);
+
 	/* Setup PKND and BPID */
 	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		union cvmx_gmxx_bpid_msk bpid_msk;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
index 8d2df9f..5ab9abd 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
@@ -372,10 +372,12 @@ void __cvmx_pki_global_rsrc_free(int node)
 		cvmx_dprintf("pki-rsrc:ERROR Failed to release all styles\n");
 	}
 
+#if 0
 	cnt = CVMX_PKI_NUM_CLUSTER;
 	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_CLUSTERS(node), 0, cnt) == -1) {
 		cvmx_dprintf("pki-rsrc:ERROR Failed to release all clusters\n");
 	}
+#endif
 
 	cnt = CVMX_PKI_NUM_FINAL_STYLE;
 	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_STYLE(node), 0, cnt) == -1) {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
index 8934e77..44a941d 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
@@ -67,6 +67,8 @@ static const bool __native_le = 1;
 	if(debug)		\
 	cvmx_dprintf("%s=%#llx\n",#reg,(long long)cvmx_read_csr_node(node,reg))
 
+int32_t __cvmx_pko3_dq_depth[1024];
+
 static int cvmx_pko_setup_macs(int node);
 
 /*
@@ -772,9 +774,7 @@ static int cvmx_pko_setup_macs(int node)
 		cvmx_write_csr_node(node, CVMX_PKO_MCI0_MAX_CREDX(mac_num),
 					pko_mci0_max_cred.u64);
 
-		/* XXX this is the latest HW recommended formula XXX */
-		tmp = (mac_credit + skid_credit) / 16; 
-		/* but we use this one for now, due to simulator */
+		/* The original CSR formula is the correct one after all */
 		tmp = (mac_credit) / 16;
 		pko_mci1_max_cred.u64 = 0;
 		pko_mci1_max_cred.s.max_cred_lim = tmp;
diff --git a/arch/mips/include/asm/octeon/cvmx-app-init.h b/arch/mips/include/asm/octeon/cvmx-app-init.h
index 7445005..e00c98f 100644
--- a/arch/mips/include/asm/octeon/cvmx-app-init.h
+++ b/arch/mips/include/asm/octeon/cvmx-app-init.h
@@ -41,7 +41,7 @@
  * @file
  * Header file for simple executive application initialization.  This defines
  * part of the ABI between the bootloader and the application.
- * <hr>$Revision: 98685 $<hr>
+ * <hr>$Revision: 99261 $<hr>
  *
  */
 
@@ -271,7 +271,6 @@ enum cvmx_board_types_enum {
 	CVMX_BOARD_TYPE_IW_EVB = 52,
 	CVMX_BOARD_TYPE_CNF71XX_REF = 53,
 	CVMX_BOARD_TYPE_MOONSHOT = 54,
-	CVMX_BOARD_TYPE_EVB7000_INTERPOSER = 55,
 	CVMX_BOARD_TYPE_EVB7000 = 56,
 	CVMX_BOARD_TYPE_EVB7000_SFF = 57,
 	CVMX_BOARD_TYPE_NAS7000_REF = 58,
@@ -404,7 +403,6 @@ static inline const char *cvmx_board_type_to_string(enum cvmx_board_types_enum t
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_IW_EVB)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_CNF71XX_REF)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_MOONSHOT)
-		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_INTERPOSER)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_EVB7000_SFF)
 		ENUM_BRD_TYPE_CASE(CVMX_BOARD_TYPE_NAS7000_REF)
diff --git a/arch/mips/include/asm/octeon/cvmx-cmd-queue.h b/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
index 1b14997..d6314d7 100644
--- a/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
+++ b/arch/mips/include/asm/octeon/cvmx-cmd-queue.h
@@ -82,7 +82,7 @@
  * internal cycle counter to completely eliminate any causes of
  * bus traffic.
  *
- * <hr> $Revision: 97196 $ <hr>
+ * <hr> $Revision: 99270 $ <hr>
  */
 
 #ifndef __CVMX_CMD_QUEUE_H__
@@ -429,6 +429,9 @@ cvmx_cmd_queue_write(cvmx_cmd_queue_id_t queue_id, int use_locking,
 	/* All updates are complete. Release the lock and return */
 	if (cvmx_likely(use_locking))
 		__cvmx_cmd_queue_unlock(qptr);
+#ifdef __U_BOOT__
+	CVMX_SYNCWS;
+#endif
 	return CVMX_CMD_QUEUE_SUCCESS;
 }
 
diff --git a/arch/mips/include/asm/octeon/cvmx-global-resources.h b/arch/mips/include/asm/octeon/cvmx-global-resources.h
index 3d5eeb6..c28e8dd 100644
--- a/arch/mips/include/asm/octeon/cvmx-global-resources.h
+++ b/arch/mips/include/asm/octeon/cvmx-global-resources.h
@@ -11,6 +11,7 @@
 #define CVMX_GR_TAG_PKO_IPORTS cvmx_get_gr_tag('c','v','m','_','p','k','o','_','i','p','o','r','t','.','.','.')
 #define CVMX_GR_TAG_FPA        cvmx_get_gr_tag('c','v','m','_','f','p','a','.','.','.','.','.','.','.','.','.')
 #define CVMX_GR_TAG_FAU        cvmx_get_gr_tag('c','v','m','_','f','a','u','.','.','.','.','.','.','.','.','.')
+#define CVMX_GR_TAG_TIM(n)     cvmx_get_gr_tag('c','v','m','_','t','i','m','_',(n)+'0','.','.','.','.','.','.','.')
 #define CVMX_GR_TAG_CLUSTERS(x)	    cvmx_get_gr_tag('c','v','m','_','c','l','u','s','t','e','r','_',(x+'0'),'.','.','.')
 #define CVMX_GR_TAG_CLUSTER_GRP(x)  cvmx_get_gr_tag('c','v','m','_','c','l','g','r','p','_',(x+'0'),'.','.','.','.','.')
 #define CVMX_GR_TAG_STYLE(x)        cvmx_get_gr_tag('c','v','m','_','s','t','y','l','e','_',(x+'0'),'.','.','.','.','.')
diff --git a/arch/mips/include/asm/octeon/cvmx-pki.h b/arch/mips/include/asm/octeon/cvmx-pki.h
index d521dfa..eaf6424 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki.h
@@ -709,6 +709,13 @@ static inline void cvmx_pki_enable_backpressure(int node)
 	cvmx_write_csr_node(node, CVMX_PKI_BUF_CTL, pki_buf_ctl.u64);
 }
 
+#define READCORRECT(cnt, node, value, addr)          \
+{       cnt = 0;    \
+        while(value >= (1ull << 48) && cnt++ < 20) \
+                value = cvmx_read_csr_node(node, addr); \
+        if (cnt >= 20)  \
+                cvmx_dprintf("count stuck for 0x%llx\n", addr);    }
+
 
 /**
  * Get the statistics counters for a port.
@@ -834,7 +841,7 @@ static inline void cvmx_pki_clear_port_stats(int node, uint64_t port)
         cvmx_write_csr_node(node, CVMX_PKI_PKNDX_INB_STAT2(pknd), pki_pknd_inb_stat2.u64);
 
 }
-      
+
 
 /**
  * Get the status counters for index from PKI.
@@ -872,30 +879,77 @@ static inline void cvmx_pki_get_stats(int node, int index, struct cvmx_pki_port_
 	cvmx_pki_pkndx_inb_stat0_t pki_pknd_inb_stat0;
 	cvmx_pki_pkndx_inb_stat1_t pki_pknd_inb_stat1;
 	cvmx_pki_pkndx_inb_stat2_t pki_pknd_inb_stat2;
+        int cnt;
 
 	stat0.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT0(index));
+        READCORRECT(cnt, node, stat0.u64, CVMX_PKI_STATX_STAT0(index));
+
 	stat1.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT1(index));
+        READCORRECT(cnt, node, stat1.u64, CVMX_PKI_STATX_STAT1(index));
+
 	stat2.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT2(index));
+        READCORRECT(cnt, node, stat2.u64, CVMX_PKI_STATX_STAT2(index));
+
 	stat3.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT3(index));
+        READCORRECT(cnt, node, stat3.u64, CVMX_PKI_STATX_STAT3(index));
+
 	stat4.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT4(index));
+        READCORRECT(cnt, node, stat4.u64, CVMX_PKI_STATX_STAT4(index));
+
 	stat5.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT5(index));
+        READCORRECT(cnt, node, stat5.u64, CVMX_PKI_STATX_STAT5(index));
+
 	stat6.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT6(index));
+        READCORRECT(cnt, node, stat6.u64, CVMX_PKI_STATX_STAT6(index));
+
 	stat7.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT7(index));
+        READCORRECT(cnt, node, stat7.u64, CVMX_PKI_STATX_STAT7(index));
+
 	stat8.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT8(index));
+        READCORRECT(cnt, node, stat8.u64, CVMX_PKI_STATX_STAT8(index));
+
 	stat9.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT9(index));
+        READCORRECT(cnt, node, stat9.u64, CVMX_PKI_STATX_STAT9(index));
+
 	stat10.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT10(index));
+        READCORRECT(cnt, node, stat10.u64, CVMX_PKI_STATX_STAT10(index));
+
 	stat11.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT11(index));
+        READCORRECT(cnt, node, stat11.u64, CVMX_PKI_STATX_STAT11(index));
+
 	stat14.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT14(index));
+        READCORRECT(cnt, node, stat14.u64, CVMX_PKI_STATX_STAT14(index));
+
 	stat15.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT15(index));
+        READCORRECT(cnt, node, stat15.u64, CVMX_PKI_STATX_STAT15(index));
+
 	stat16.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT16(index));
+        READCORRECT(cnt, node, stat16.u64, CVMX_PKI_STATX_STAT16(index));
+
 	stat17.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_STAT17(index));
+        READCORRECT(cnt, node, stat17.u64, CVMX_PKI_STATX_STAT17(index));
+
 	hist0.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST0(index));
+        READCORRECT(cnt, node, hist0.u64, CVMX_PKI_STATX_HIST0(index));
+
 	hist1.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST1(index));
+        READCORRECT(cnt, node, hist1.u64, CVMX_PKI_STATX_HIST1(index));
+
 	hist2.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST2(index));
+        READCORRECT(cnt, node, hist2.u64, CVMX_PKI_STATX_HIST2(index));
+
 	hist3.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST3(index));
+        READCORRECT(cnt, node, hist3.u64, CVMX_PKI_STATX_HIST3(index));
+
 	hist4.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST4(index));
+        READCORRECT(cnt, node, hist4.u64, CVMX_PKI_STATX_HIST4(index));
+
 	hist5.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST5(index));
+        READCORRECT(cnt, node, hist5.u64, CVMX_PKI_STATX_HIST5(index));
+
 	hist6.u64 = cvmx_read_csr_node(node, CVMX_PKI_STATX_HIST6(index));
+        READCORRECT(cnt, node, hist6.u64, CVMX_PKI_STATX_HIST6(index));
+
 	pki_pknd_inb_stat0.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKNDX_INB_STAT0(index));
 	pki_pknd_inb_stat1.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKNDX_INB_STAT1(index));
 	pki_pknd_inb_stat2.u64 = cvmx_read_csr_node(node, CVMX_PKI_PKNDX_INB_STAT2(index));
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3.h b/arch/mips/include/asm/octeon/cvmx-pko3.h
index 5ca85e4..cff2e6a 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko3.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko3.h
@@ -58,16 +58,21 @@ extern "C" {
 #include <asm/octeon/cvmx-pko3-queue.h>
 #include <asm/octeon/cvmx-ilk.h>
 #include <asm/octeon/cvmx-scratch.h>
+#include <asm/octeon/cvmx-atomic.h>
 #else
 #include "cvmx-pko-defs.h"
 #include "cvmx-pko3-queue.h"
 #include "cvmx-helper.h"
 #include "cvmx-ilk.h"
 #include "cvmx-scratch.h"
+#include "cvmx-atomic.h"
 #endif
 
-#define	__USE_LMTST		/* Temporary work-around */
-#define	__CHECK_FPA	(48*64)	/* Temporary work-around */
+/* Use full LMTDMA when PARAMETER_CHECKINS is enabled */
+#undef	CVMX_ENABLE_PARAMETER_CHECKING
+#define	CVMX_ENABLE_PARAMETER_CHECKING 0
+
+#define	CVMX_PKO3_DQ_MAX_DEPTH	(48*256)
 
 /* dwords are from 1-16 */
 /* scratch line for LMT operations */
@@ -307,6 +312,9 @@ union cvmx_pko_lmtdma_data {
 };
 typedef union cvmx_pko_lmtdma_data cvmx_pko_lmtdma_data_t;
 
+/* per-core DQ depth cached value */
+extern int32_t __cvmx_pko3_dq_depth[1024];
+
 extern int cvmx_pko3_internal_buffer_count(unsigned node);
 
 /*
@@ -375,6 +383,120 @@ static inline int cvmx_pko_setup_channel_credit_level(int node, int level)
 
 }
 
+/**
+ * @INTERNAL
+ *
+ * Get address for LMTDMA/LMTST data buffer
+ *
+ */
+static inline unsigned
+cvmx_pko3_lmtdma_scr_base(void)
+{
+	return CVMX_PKO_LMTLINE * CVMX_CACHE_LINE_SIZE;
+}
+
+/*
+ * @INTERNAL  
+ * Deliver PKO SEND commands via CVMSEG LM and LMTDMA/LMTTST.
+ * The command should be already stored in the address
+ * returned by 'cvmx_pko3_lmtdma_bufaddr()'.
+ *
+ * @param node is the destination node
+ * @param dq is the destonation descriptor queue.
+ * @param numworkds is the number of outgoing words
+ * @return the PKO3 native query result structure.
+ *
+ * <numwords> must be between 1 and 15 for CVMX_PKO_DQ_SEND command
+ *
+ * NOTE: Internal use only.
+ */
+static inline cvmx_pko_query_rtn_t 
+__cvmx_pko3_lmtdma(uint8_t node, uint16_t dq, unsigned numwords)
+{
+	const enum cvmx_pko_dqop dqop = CVMX_PKO_DQ_SEND;
+	cvmx_pko_query_rtn_t pko_status;
+	cvmx_pko_lmtdma_data_t pko_send_dma_data;
+	uint64_t dma_addr;
+	unsigned scr_base = cvmx_pko3_lmtdma_scr_base();
+	unsigned scr_off;
+
+	pko_status.u64 = 0;
+
+	/* LMTDMA address offset is (nWords-1) */
+	dma_addr = 0xffffffffffffa400ull; 
+	dma_addr += (numwords - 1) << 3;
+
+#ifdef	CVMX_PKO3_DQ_MAX_DEPTH
+	/* If cached depth exceeds limit, check the real depth */
+	if (cvmx_unlikely(__cvmx_pko3_dq_depth[dq] > CVMX_PKO3_DQ_MAX_DEPTH)) {
+		cvmx_pko_dqx_wm_cnt_t wm_cnt;
+		wm_cnt.u64 = cvmx_read_csr_node(node,CVMX_PKO_DQX_WM_CNT(dq));
+		__cvmx_pko3_dq_depth[dq] = pko_status.s.depth = wm_cnt.s.count;
+
+		if (pko_status.s.depth > CVMX_PKO3_DQ_MAX_DEPTH) {
+			pko_status.s.dqop = dqop;
+			pko_status.s.dqstatus = PKO_DQSTATUS_NOFPABUF;
+			return pko_status;
+		}
+	}
+#endif	/* CVMX_PKO3_DQ_MAX_DEPTH */
+
+	if (cvmx_unlikely(numwords < 1 || numwords > 15)) {
+		cvmx_dprintf("%s: ERROR: Internal error\n",
+				__FUNCTION__);
+		pko_status.u64 = ~0ull;
+		return pko_status;
+	}
+
+	scr_off = scr_base + numwords * sizeof(uint64_t);
+	pko_send_dma_data.u64 = 0;
+
+	if (CVMX_ENABLE_PARAMETER_CHECKING) {
+		/* Request one return word */
+		pko_send_dma_data.s.rtnlen = 1;
+
+		/* Write all-ones into the return area */
+		cvmx_scratch_write64(scr_off, ~0ull);
+	} else {
+		/* Do not expext a return word */
+		pko_send_dma_data.s.rtnlen = 0;
+	}
+
+	/* build store data for DMA */
+	pko_send_dma_data.s.scraddr = scr_off >> 3;
+	pko_send_dma_data.s.did = 0x51;
+	pko_send_dma_data.s.node = node;
+	pko_send_dma_data.s.dqop = dqop;
+	pko_send_dma_data.s.dq = dq;
+
+	/* Push all data into CVMSEG LM */
+	CVMX_SYNCWS;
+
+	/* issue PKO DMA */
+	cvmx_write64_uint64(dma_addr, pko_send_dma_data.u64);
+
+	if (cvmx_unlikely(pko_send_dma_data.s.rtnlen)) {
+		/* Wait for completion */
+		CVMX_SYNCIOBDMA;
+
+		/* Retreive real result */
+		pko_status.u64 = cvmx_scratch_read64(scr_off);
+#ifdef	CVMX_PKO3_DQ_MAX_DEPTH
+		__cvmx_pko3_dq_depth[dq] = pko_status.s.depth;
+#endif	/* CVMX_PKO3_DQ_MAX_DEPTH */
+	} else {
+		/* Fake positive result */
+		pko_status.s.dqop = dqop;
+		pko_status.s.dqstatus = PKO_DQSTATUS_PASS;
+#ifdef	CVMX_PKO3_DQ_MAX_DEPTH
+		__cvmx_pko3_dq_depth[dq] += 48;
+#endif	/* CVMX_PKO3_DQ_MAX_DEPTH */
+	}
+
+	return pko_status;
+}
+
+
 /*
  * @INTERNAL  
  * Sends PKO descriptor commands via CVMSEG LM and LMTDMA.
@@ -400,6 +522,8 @@ __cvmx_pko3_do_dma(uint8_t node, uint16_t dq, uint64_t cmds[],
 	uint64_t dma_addr;
 	unsigned i, scr_off;
 
+	pko_status.u64 = 0;
+
 	/* With 0 data to send, this is an IOBDMA, else LMTDMA operation */
 	if(numwords == 0) {
 		dma_addr = 0xffffffffffffa200ull;
@@ -409,21 +533,17 @@ __cvmx_pko3_do_dma(uint8_t node, uint16_t dq, uint64_t cmds[],
 		dma_addr += (numwords - 1) << 3;
 	}
 
-#ifdef	__CHECK_FPA	/* Temporary work-around */
-	if (dqop == CVMX_PKO_DQ_SEND) {
-		static int64_t cached_buf_count = 0;
-		if (cached_buf_count > 0) {
-			cached_buf_count -= numwords+1;
-		} else {
-		cached_buf_count = cvmx_pko3_internal_buffer_count(node);
-		if ( cached_buf_count <= __CHECK_FPA) {
-			/* Return same error as if the chip would work right */
-			pko_status.u64 = 0;
+#ifdef	CVMX_PKO3_DQ_MAX_DEPTH
+	if (cvmx_unlikely(__cvmx_pko3_dq_depth[dq] > CVMX_PKO3_DQ_MAX_DEPTH) &&
+	    dqop == CVMX_PKO_DQ_SEND) {
+		cvmx_pko_dqx_wm_cnt_t wm_cnt;
+		wm_cnt.u64 = cvmx_read_csr_node(node,CVMX_PKO_DQX_WM_CNT(dq));
+		__cvmx_pko3_dq_depth[dq] = pko_status.s.depth = wm_cnt.s.count;
+
+		if (pko_status.s.depth > CVMX_PKO3_DQ_MAX_DEPTH) {
 			pko_status.s.dqop = dqop;
 			pko_status.s.dqstatus = PKO_DQSTATUS_NOFPABUF;
 			return pko_status;
-			}
-		cached_buf_count *= ((4096/8)-1)/48;
 		}
 	}
 #endif
@@ -443,19 +563,15 @@ __cvmx_pko3_do_dma(uint8_t node, uint16_t dq, uint64_t cmds[],
 
 	pko_send_dma_data.u64 = 0;
 
-#ifndef	__USE_LMTST
-	/* Request one return word */
-	pko_send_dma_data.s.rtnlen = 1;
-
-	/* Write all-ones into the return area */
-	cvmx_scratch_write64(scr_off, ~0ull);
-
-#else	/* Temporary work-around */
-	if (dqop != CVMX_PKO_DQ_SEND) {
+	if (dqop != CVMX_PKO_DQ_SEND || CVMX_ENABLE_PARAMETER_CHECKING) {
+		/* Request one return word */
 		pko_send_dma_data.s.rtnlen = 1;
+		/* Write all-ones into the return area */
 		cvmx_scratch_write64(scr_off, ~0ull);
+	} else {
+		/* Do not expext a return word */
+		pko_send_dma_data.s.rtnlen = 0;
 	}
-#endif
 
 	/* build store data for DMA */
 	pko_send_dma_data.s.scraddr = scr_off >> 3;
@@ -465,92 +581,98 @@ __cvmx_pko3_do_dma(uint8_t node, uint16_t dq, uint64_t cmds[],
 	pko_send_dma_data.s.dq = dq;
 
 	/* Push all data into CVMSEG LM */
-	CVMX_SYNCW;
+	CVMX_SYNCWS;
 
 	/* issue PKO DMA */
 	cvmx_write64_uint64(dma_addr, pko_send_dma_data.u64);
 
-#ifndef	__USE_LMTST
-	/* Wait for completion */
-	CVMX_SYNCIOBDMA;
-
-	/* Retreive result */
-	pko_status.u64 = cvmx_scratch_read64(scr_off);
-#else	/* Temporary work-around */
 	if (pko_send_dma_data.s.rtnlen) {
 		/* Wait for completion */
 		CVMX_SYNCIOBDMA;
 
 		/* Retreive real result */
 		pko_status.u64 = cvmx_scratch_read64(scr_off);
+#ifdef	CVMX_PKO3_DQ_MAX_DEPTH
+		__cvmx_pko3_dq_depth[dq] = pko_status.s.depth;
+#endif	/* CVMX_PKO3_DQ_MAX_DEPTH */
 	} else {
 		/* Fake positive result */
-		pko_status.u64 = 0;
-		pko_status.s.depth = 1;
 		pko_status.s.dqop = dqop;
 		pko_status.s.dqstatus = PKO_DQSTATUS_PASS;
+#ifdef	CVMX_PKO3_DQ_MAX_DEPTH
+		__cvmx_pko3_dq_depth[dq] += 48;
+#endif	/* CVMX_PKO3_DQ_MAX_DEPTH */
 	}
-#endif
+
 	return pko_status;
 }
 
+
 /*
- * Transmit simple packets through pko
+ * Transmit packets through PKO, simplified API
  *
  * @INTERNAL
  *
  * @param dq is a global destination queue number 
- * @param bptr specifies packet data virtual address
- * @param len is the total packet len of the packet in bufptr.
+ * @param pki_ptr specifies packet first linked pointer as returned from
+ * 'cvmx_wqe_get_pki_pkt_ptr()'.
+ * @param len is the total number of bytes in the packet.
  * @param gaura is the aura to free packet buffers after trasnmit.
+ * @param pCounter is an address of a 64-bit counter to atomically
+ * decrement when packet transmission is complete.
  *
  * @return returns 0 if successful and -1 on failure.
  *
- * This function is a short-cut, and is only useful for sending
- * very simple packets that are all contained in a single buffer,
- * do not require any type of completion notification.
- * The virtual address pointer to packet data may be pointing
- * to a buffer obtained from FPA, in which case the 'gaura'
- * argument should contain the global AURA number where the buffer
- * should be freed on completion. If the buffer does not need to be
- * freed by PKO, specify 'gaura' as -1.
- * Other features such as L3/L4 checksum calculation are not
- * available via this function.
  *
  * NOTE: This is a provisional API, and is subject to change.
  */
 static inline int
-cvmx_pko3_xmit_simple(int dq, void * bptr, unsigned len, int gaura)
+cvmx_pko3_xmit_link_buf(int dq,cvmx_buf_ptr_pki_t pki_ptr,
+	unsigned len, int gaura, uint64_t *pCounter)
 {
 	cvmx_pko_query_rtn_t pko_status;
-	cvmx_pko_send_hdr_t *hdr_s;
-	cvmx_pko_buf_ptr_t *gtr_s;
-	unsigned node;
-	uint64_t cmd[2];	/* minimal command: 2 words exactly */
+	cvmx_pko_send_hdr_t hdr_s;
+	cvmx_pko_buf_ptr_t gtr_s;
+	unsigned node, nwords;
+	unsigned scr_base = cvmx_pko3_lmtdma_scr_base();
 
 	/* Separa global DQ# into node and local DQ */
 	node = dq >> 10;
 	dq &= (1 << 10)-1;
 
-	/* Setup command word pointers */
-	hdr_s = (void *)&cmd[0];
-	gtr_s = (void *)&cmd[1];
-
 	/* Fill in header */
-	hdr_s->u64 = 0;
-	hdr_s->s.total = len;
-	hdr_s->s.df = (gaura < 0);
-	hdr_s->s.ii = 1;
-	hdr_s->s.aura = (gaura >= 0)? gaura: 0;
+	hdr_s.u64 = 0;
+	hdr_s.s.total = len;
+	hdr_s.s.df = (gaura < 0);
+	hdr_s.s.ii = 1;
+	hdr_s.s.aura = (gaura >= 0)? gaura: 0;
 
 	/* Fill in gather */
-	gtr_s->u64 = 0;
-	gtr_s->s.subdc3 = CVMX_PKO_SENDSUBDC_GATHER;
-	gtr_s->s.addr = cvmx_ptr_to_phys(bptr);
-	gtr_s->s.size = len;
+	gtr_s.u64 = 0;
+	gtr_s.s.subdc3 = CVMX_PKO_SENDSUBDC_LINK;
+	gtr_s.s.addr = pki_ptr.addr;
+	gtr_s.s.size = pki_ptr.size;
+
+	/* Setup command word pointers */
+	cvmx_scratch_write64(scr_base+sizeof(uint64_t)*0, hdr_s.u64);
+	cvmx_scratch_write64(scr_base+sizeof(uint64_t)*1, gtr_s.u64);
+	nwords = 2;
+
+	/* Conditionally setup an atomic decrement counter */
+	if (pCounter != NULL) {
+		cvmx_pko_send_mem_t mem_s = {.s={
+			.subdc4 = CVMX_PKO_SENDSUBDC_MEM,
+			.dsz = MEMDSZ_B64, .alg = MEMALG_SUB,
+			.offset = 1,
+			}};
+		mem_s.s.addr = cvmx_ptr_to_phys(CASTPTR(void,pCounter));
+		cvmx_scratch_write64(
+			scr_base + sizeof(uint64_t) * nwords++,
+			mem_s.u64);
+	}
 
 	/* Do LMTDMA */
-	pko_status = __cvmx_pko3_do_dma(node, dq, cmd, 2, CVMX_PKO_DQ_SEND);
+	pko_status = __cvmx_pko3_lmtdma(node, dq, nwords);
 
 	if (cvmx_likely(pko_status.s.dqstatus == PKO_DQSTATUS_PASS))
 		return 0;
diff --git a/arch/mips/include/asm/octeon/cvmx-wqe.h b/arch/mips/include/asm/octeon/cvmx-wqe.h
index 85a17bd..785c7db 100644
--- a/arch/mips/include/asm/octeon/cvmx-wqe.h
+++ b/arch/mips/include/asm/octeon/cvmx-wqe.h
@@ -1572,11 +1572,11 @@ static inline unsigned cvmx_wqe_set_bufs(cvmx_wqe_t *work, unsigned bufs)
 {
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		work->word0.pki.bufs = bufs;
+		return work->word0.pki.bufs;
 	} else {
 		work->word2.s.bufs = bufs;
+		return work->word2.s.bufs;
 	}
-
-	return cvmx_wqe_get_bufs(work);
 }
 
 /**
-- 
2.6.2

