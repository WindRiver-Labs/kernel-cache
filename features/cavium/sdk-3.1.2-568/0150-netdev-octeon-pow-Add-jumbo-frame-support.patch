From 8c6cb961649f164979b8c8081aa61ad17289b69a Mon Sep 17 00:00:00 2001
From: Carlos Munoz <cmunoz@caviumnetworks.com>
Date: Mon, 5 Oct 2015 15:28:51 -0700
Subject: [PATCH 150/184] netdev: octeon-pow: Add jumbo frame support.

Signed-off-by: Carlos Munoz <cmunoz@caviumnetworks.com>
[Original patch taken from octeon-linux-kernel-patches-SDK-3.1.2-release]
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/net/ethernet/octeon/octeon-pow-ethernet.c | 278 +++++++++++++++-------
 1 file changed, 186 insertions(+), 92 deletions(-)

diff --git a/drivers/net/ethernet/octeon/octeon-pow-ethernet.c b/drivers/net/ethernet/octeon/octeon-pow-ethernet.c
index 8a6fd40..99de7c4 100644
--- a/drivers/net/ethernet/octeon/octeon-pow-ethernet.c
+++ b/drivers/net/ethernet/octeon/octeon-pow-ethernet.c
@@ -38,6 +38,15 @@
 
 #define DEV_NAME "octeon-pow-ethernet"
 
+/* Packet pointers come in two flavors depending on whether pki or pid/ipd are
+ * used.
+ */
+union octeon_packet_ptr {
+	uint64_t		u64;
+	union cvmx_buf_ptr	pip_packet_ptr;
+	union cvmx_buf_ptr_pki	pki_packet_ptr;
+};
+
 static int receive_group = -1;
 module_param(receive_group, int, 0444);
 MODULE_PARM_DESC(receive_group,
@@ -133,56 +142,197 @@ void *work_to_skb(void *work)
  * Given a packet data address, return a pointer to the
  * beginning of the packet buffer.
  */
-static void *get_buffer_ptr(union cvmx_buf_ptr packet_ptr)
+static void *get_buffer_ptr(union octeon_packet_ptr packet_ptr)
 {
-	return phys_to_virt(((packet_ptr.s.addr >> 7) -
-			     packet_ptr.s.back) << 7);
+	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
+		ulong	buf_ptr;
+
+		buf_ptr = round_down((ulong)packet_ptr.pki_packet_ptr.addr,
+				     128ul);
+		buf_ptr -= 8 * 16;
+		return (void *)buf_ptr;
+	} else {
+		return phys_to_virt(((packet_ptr.pip_packet_ptr.s.addr >> 7) -
+				     packet_ptr.pip_packet_ptr.s.back) << 7);
+	}
 }
 
-uint64_t oct_get_packet_ptr(cvmx_wqe_t *work)
+static union octeon_packet_ptr octeon_get_first_packet_ptr(cvmx_wqe_t *work)
 {
+	union octeon_packet_ptr	packet_ptr;
+
 	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		return cvmx_wqe_get_pki_pkt_ptr(work).u64;
+		packet_ptr.u64 = cvmx_wqe_get_pki_pkt_ptr(work).u64;
 	} else {
 		if ((work->word2.s.bufs > 0) || (work->word2.s.software))
-		    return work->packet_ptr.s.addr;
-		return (cvmx_ptr_to_phys(work) + 32);
+			packet_ptr.u64 = work->packet_ptr.u64;
+		else
+			packet_ptr.u64 = cvmx_ptr_to_phys(work) + 32;
 	}
+
+	return packet_ptr;
+}
+
+static union octeon_packet_ptr
+octeon_get_next_packet_ptr(union octeon_packet_ptr packet_ptr)
+{
+	uint64_t	addr;
+
+	if (octeon_has_feature(OCTEON_FEATURE_PKI))
+		addr = packet_ptr.pki_packet_ptr.addr - 8;
+	else
+		addr = packet_ptr.pip_packet_ptr.s.addr - 8;
+
+	return *(union octeon_packet_ptr *)phys_to_virt(addr);
 }
 
 static int octeon_pow_free_work(cvmx_wqe_t *work)
 {
-	int segments = cvmx_wqe_get_bufs(work);
+	union octeon_packet_ptr	segment_ptr;
+	union octeon_packet_ptr	next_ptr;
+	int			segments;
 
-	if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
-		/* FIXME */
-		int segments = cvmx_wqe_get_bufs(work);
-		if (segments > 1) pr_warn(DEV_NAME " WARNING: segments > 1 not yet supported.\n");
+	segments = cvmx_wqe_get_bufs(work);
 
-		cvmx_fpa_free(work_to_skb(work), cvmx_wqe_get_aura(work), 0);
-	} else {
-		union cvmx_buf_ptr segment_ptr = work->packet_ptr;
-
-		while (segments--) {
-			union cvmx_buf_ptr next_ptr =
-				*(union cvmx_buf_ptr *)phys_to_virt(segment_ptr.s.addr - 8);
-			if (unlikely(!segment_ptr.s.i))
-				cvmx_fpa_free(get_buffer_ptr(segment_ptr),
-					     segment_ptr.s.pool, 0);
-			segment_ptr = next_ptr;
-		}
+	segment_ptr = octeon_get_first_packet_ptr(work);
+	while (segments--) {
+		next_ptr = octeon_get_next_packet_ptr(segment_ptr);
+		cvmx_fpa_free(get_buffer_ptr(segment_ptr),
+			      cvmx_wqe_get_aura(work), 0);
+		segment_ptr = next_ptr;
+	}
+
+	if (!octeon_has_feature(OCTEON_FEATURE_PKI))
 		cvmx_fpa_free(work, fpa_wqe_pool, 0);
+
+	return 0;
+}
+
+static int octeon_packet_ptr_init(void *packet_ptr, void *data, int len)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		union cvmx_buf_ptr_pki	*pki_packet_ptr;
+
+		pki_packet_ptr = packet_ptr;
+		pki_packet_ptr->u64 = 0;
+		pki_packet_ptr->addr = virt_to_phys(data);
+		pki_packet_ptr->packet_outside_wqe = 0;
+		pki_packet_ptr->size = len;
+	} else {
+		union cvmx_buf_ptr	*pip_packet_ptr;
+
+		pip_packet_ptr = packet_ptr;
+		pip_packet_ptr->u64 = 0;
+		pip_packet_ptr->s.addr = virt_to_phys(data);
+		pip_packet_ptr->s.pool = fpa_packet_pool;
+		pip_packet_ptr->s.size = fpa_packet_pool_size -
+			sizeof(pip_packet_ptr);
+		pip_packet_ptr->s.back = (data - packet_ptr) >> 7;
 	}
 
 	return 0;
 }
 
+static cvmx_wqe_t *octeon_skb_to_fpa_buf(struct net_device *dev,
+					 struct sk_buff *skb)
+{
+	cvmx_wqe_t	*work;
+	int		len = skb->len;
+	int		first_segment;
+	int		num_segments;
+	int		segment_len;
+	void		*packet_ptr;
+	void		*prev_packet_ptr = NULL;
+	void		*data_ptr = skb->data;
+
+	/* Get a work queue entry */
+	work = cvmx_fpa_alloc(fpa_wqe_pool);
+	if (unlikely(work == NULL)) {
+		DEBUGPRINT("%s: Failed to allocate a work queue entry\n",
+			   dev->name);
+		return NULL;
+	}
+
+	/* The first 128 bytes of each fpa buffer store information used by the
+	 * octeon3-ethernet driver that must be preserved.
+	 */
+	if (octeon_has_feature(OCTEON_FEATURE_FPA3))
+		work = (void *)work + 128;
+
+	memset(work, 0, sizeof(*work));
+
+	/* Copy all the skb data to fpa buffers */
+	first_segment = 1;
+	num_segments = 0;
+	cvmx_wqe_set_bufs(work, 0);
+	while (len > 0) {
+		void	*copy_location;
+
+		/* Get a packet buffer. On octeon III the wqe and packet data
+		 * share the same fpa buffer.
+		 */
+		if (octeon_has_feature(OCTEON_FEATURE_PKI) && first_segment) {
+			packet_ptr = (void *)work + sizeof(*work);
+			segment_len = fpa_packet_pool_size - 128 -
+				sizeof(*work);
+		} else {
+			packet_ptr = cvmx_fpa_alloc(fpa_packet_pool);
+			if (unlikely(packet_ptr == NULL)) {
+				DEBUGPRINT("%s: Failed to allocate a fpa buf\n",
+					   dev->name);
+				goto error;
+			}
+
+			segment_len = fpa_packet_pool_size;
+			if (octeon_has_feature(OCTEON_FEATURE_FPA3)) {
+				packet_ptr = (void *)packet_ptr + 128;
+				segment_len = fpa_packet_pool_size - 128;
+			}
+		}
+
+		/* We need to leave 8 bytes for the next pointer */
+		copy_location = packet_ptr + sizeof(uint64_t);
+		segment_len -= sizeof(uint64_t);
+		if (segment_len > len)
+			segment_len = len;
+		octeon_pow_copy_to(copy_location, data_ptr, segment_len);
+
+		octeon_packet_ptr_init(packet_ptr, copy_location,
+				       segment_len);
+
+		if (first_segment) {
+			if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+				cvmx_wqe_78xx_t *wqe = (cvmx_wqe_78xx_t *)work;
+
+				wqe->packet_ptr.u64 = *(uint64_t *)packet_ptr;
+				wqe->pki_errata20776 = 1;
+			} else {
+				work->packet_ptr.u64 = *(uint64_t *)packet_ptr;
+			}
+
+			first_segment = 0;
+		} else
+			*(uint64_t *)prev_packet_ptr = *(uint64_t *)packet_ptr;
+
+		num_segments++;
+		cvmx_wqe_set_bufs(work, num_segments);
+		len -= segment_len;
+		data_ptr += segment_len;
+		prev_packet_ptr = packet_ptr;
+	}
+
+	return work;
+
+ error:
+	octeon_pow_free_work(work);
+	return NULL;
+}
+
 static int octeon_pow_xmit(struct sk_buff *skb, struct net_device *dev)
 {
 	struct octeon_pow *priv;
 	cvmx_wqe_t *work = NULL;
 	void *packet_buffer = NULL;
-	void *copy_location;
 	u64 send_group_mask;
 	int send_group;
 
@@ -209,52 +359,14 @@ static int octeon_pow_xmit(struct sk_buff *skb, struct net_device *dev)
 		if (likely((send_group_mask & (1ULL << send_group)) == 0))
 			continue;
 
-		/* Get a work queue entry */
-		work = cvmx_fpa_alloc(fpa_wqe_pool) +
-			(octeon_has_feature(OCTEON_FEATURE_FPA3) ? 0x80 : 0);
-		if (unlikely(work == NULL)) {
-			DEBUGPRINT("%s: Failed to allocate a work queue entry\n",
-				   dev->name);
-			goto fail;
-		}
-
-		/* Get a packet buffer */
-		if (octeon_has_feature(OCTEON_FEATURE_PKI))
-			/* octeon3-ethernet uses a different fpa/packet system */
-			packet_buffer = ((void*)work) + 0x80;
-		else
-			packet_buffer = cvmx_fpa_alloc(fpa_packet_pool);
-		if (unlikely(packet_buffer == NULL)) {
-			DEBUGPRINT("%s: Failed to allocate a packet buffer\n",
-				   dev->name);
-			goto fail;
-		}
-
-		/* Calculate where we need to copy the data to. We
-		 * need to leave 8 bytes for a next pointer
-		 * (unused). Then we need to align the IP packet src
-		 * and dest into the same 64bit word.
-		 */
-		copy_location = packet_buffer + sizeof(uint64_t) + 6;
-
-		/* Fail if the packet won't fit in a single buffer */
-		if (unlikely
-		    (copy_location + skb->len >
-		     packet_buffer + fpa_packet_pool_size)) {
-			DEBUGPRINT("%s: Packet too large for FPA buffer\n",
-				   dev->name);
+		work = octeon_skb_to_fpa_buf(dev, skb);
+		if (work == NULL)
 			goto fail;
-		}
-
-		octeon_pow_copy_to(copy_location, skb->data, skb->len);
 
 		/* Fill in some of the work queue fields. We may need
 		 * to add more if the software at the other end needs
 		 * them.
 		 */
-		work->word0.u64 = 0;
-		work->word2.u64 = 0;	/* Default to zero. Sets of zero later
-					   are commented out */
 #if 0
 		work->hw_chksum = skb->csum;
 #endif
@@ -266,27 +378,8 @@ static int octeon_pow_xmit(struct sk_buff *skb, struct net_device *dev)
 		cvmx_wqe_set_tt(work, 2);
 		cvmx_wqe_set_tag(work, 0);
 
-		cvmx_wqe_set_bufs(work, 1);
-		cvmx_wqe_set_aura(work, fpa_wqe_pool);
-
-		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-			/* We use a 78xx format wqe where necessary */
-			union cvmx_buf_ptr_pki pki_ptr;
-			cvmx_wqe_78xx_t *wqe = (cvmx_wqe_78xx_t*) work;
-			pki_ptr.u64 = 0;
-			pki_ptr.addr = virt_to_phys(copy_location);
-			pki_ptr.packet_outside_wqe = 0;
-			pki_ptr.size = skb->len;
-			wqe->packet_ptr.u64 = pki_ptr.u64;
-			/* Mark errata as handled to prevent additional byteswap */
-			wqe->pki_errata20776 = 1;
-		} else {
-			work->packet_ptr.u64 = 0;
-			work->packet_ptr.s.addr = virt_to_phys(copy_location);
-			work->packet_ptr.s.pool = fpa_packet_pool;
-			work->packet_ptr.s.size = fpa_packet_pool_size;
-			work->packet_ptr.s.back = (copy_location - packet_buffer) >> 7;
-		}
+		cvmx_wqe_set_aura(work, fpa_packet_pool);
+
 		if (skb->protocol == htons(ETH_P_IP)) {
 			cvmx_wqe_set_l3_offset(work, 14);
 			cvmx_wqe_set_l4_udp(work, ip_hdr(skb)->protocol == IPPROTO_UDP);
@@ -356,10 +449,6 @@ static int octeon_pow_xmit(struct sk_buff *skb, struct net_device *dev)
 	return NETDEV_TX_OK;
 
 fail:
-	if (work)
-		cvmx_fpa_free(work_to_skb(work), fpa_wqe_pool, 0);
-	if (packet_buffer && !octeon_has_feature(OCTEON_FEATURE_PKI))
-		cvmx_fpa_free(packet_buffer, fpa_packet_pool, 0);
 	dev->stats.tx_dropped++;
 	dev_kfree_skb(skb);
 	return NETDEV_TX_OK;
@@ -517,11 +606,16 @@ static irqreturn_t octeon_pow_interrupt(int cpl, void *dev_id)
 		 * stored the work entry. This is untested
 		 */
 		if (unlikely(cvmx_wqe_get_bufs(work) == 0)) {
-			int len = cvmx_wqe_get_len(work);
+			union octeon_packet_ptr	packet_ptr;
+			uint64_t		addr;
+			int			len = cvmx_wqe_get_len(work);
+
 			DEBUGPRINT("%s: Received a work with work->word2.s.bufs=0, untested\n",
 				   dev->name);
+			packet_ptr = octeon_get_first_packet_ptr(work);
+			addr = packet_ptr.pip_packet_ptr.s.addr;
 			octeon_pow_copy_from(skb_put(skb, len),
-					     phys_to_virt(oct_get_packet_ptr(work)), len);
+					     phys_to_virt(addr), len);
 		} else {
 			if (octeon_has_feature(OCTEON_FEATURE_PKI)) {
 				octeon_pow_pki_rx(work, skb);
-- 
1.9.1

