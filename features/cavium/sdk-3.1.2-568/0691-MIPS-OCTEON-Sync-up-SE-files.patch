From 5abca7b83c3388864129f86414f644d53b35faa9 Mon Sep 17 00:00:00 2001
From: Vinita Gupta <vgupta@caviumnetworks.com>
Date: Fri, 25 Jul 2014 18:05:50 -0700
Subject: [PATCH 691/974] MIPS:OCTEON: Sync up SE files

Signed-off-by: Vinita Gupta <vgupta@caviumnetworks.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c | 640 ++++++++++++++-------
 arch/mips/include/asm/octeon/cvmx-helper-bgx.h     |   5 +-
 2 files changed, 429 insertions(+), 216 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
index 29fd6e3..5e27fe9 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -112,12 +112,15 @@ void cvmx_helper_bgx_disable(int xipd_port)
 	cvmx_bgxx_cmrx_config_t cmr_config;
 
 	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
-	cmr_config.s.enable = 0;
+	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_0) || index)
+		cmr_config.s.enable = 0;
 	cmr_config.s.data_pkt_tx_en = 0;
 	cmr_config.s.data_pkt_rx_en = 0;
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 }
 
+
+
 /**
  * @INTERNAL
  * Configure the bgx mac.
@@ -174,6 +177,8 @@ static void __cvmx_helper_bgx_common_init(int xiface)
 		cmr_config.u64 =
 			cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 		cmr_config.s.enable = 0;
+		cmr_config.s.data_pkt_tx_en = 0;
+		cmr_config.s.data_pkt_rx_en = 0;
 		cmr_config.s.lmac_type = lmac_type;
 		cmr_config.s.lane_to_sds = ((lane_to_sds == 1) ? index
 					     : ((lane_to_sds == 0)
@@ -191,36 +196,38 @@ static void __cvmx_helper_bgx_common_init(int xiface)
 
 }
 
-static void __cvmx_helper_bgx_common_init_pknd(int xiface, int index)
+static void __cvmx_bgx_common_init_pknd(int xiface, int index)
 {
-	cvmx_bgxx_cmrx_rx_bp_on_t bgx_rx_bp_on;
-	cvmx_bgxx_cmrx_rx_id_map_t cmr_rx_id_map;
-        cvmx_bgxx_cmr_chan_msk_and_t chan_msk_and;
-	cvmx_bgxx_cmr_chan_msk_or_t chan_msk_or;
+	int num_ports;
 	int num_chl = 16; /*modify it to 64 for xlaui and xaui*/
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
 	int node = xi.node;
-	int pknd = cvmx_helper_get_pknd(xiface, index);
-	int num_ports = cvmx_helper_ports_on_interface(xiface);
+	int pknd;
+	cvmx_bgxx_cmrx_rx_bp_on_t bgx_rx_bp_on;
+	cvmx_bgxx_cmrx_rx_id_map_t cmr_rx_id_map;
+	cvmx_bgxx_cmr_chan_msk_and_t chan_msk_and;
+	cvmx_bgxx_cmr_chan_msk_or_t chan_msk_or;
 
+	num_ports = cvmx_helper_ports_on_interface(xiface);
 	/* Modify bp_on mark, depending on number of LMACS on that interface
 	and write it for every port */
 	bgx_rx_bp_on.u64 = 0;
 	bgx_rx_bp_on.s.mark = (CVMX_BGX_RX_FIFO_SIZE / (num_ports * 4 * 16));
 
 	/* Setup pkind */
+	pknd = cvmx_helper_get_pknd(xiface, index);
 	cmr_rx_id_map.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_RX_ID_MAP(index, interface));
 	cmr_rx_id_map.s.pknd = pknd;
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_ID_MAP(index, interface),
-			       cmr_rx_id_map.u64);
-        /* Set backpressure channel mask AND/OR registers */
-        chan_msk_and.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(interface));
-        chan_msk_or.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(interface));
-        chan_msk_and.s.msk_and |= ((1 << num_chl) - 1) << (16 * index);
-        chan_msk_or.s.msk_or |= ((1 << num_chl) - 1) << (16 * index);
-        cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(interface), chan_msk_and.u64);
-        cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(interface), chan_msk_or.u64);
+			    cmr_rx_id_map.u64);
+	/* Set backpressure channel mask AND/OR registers */
+	chan_msk_and.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(interface));
+	chan_msk_or.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(interface));
+	chan_msk_and.s.msk_and |= ((1 << num_chl) - 1) << (16 * index);
+	chan_msk_or.s.msk_or |= ((1 << num_chl) - 1) << (16 * index);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_AND(interface), chan_msk_and.u64);
+	cvmx_write_csr_node(node, CVMX_BGXX_CMR_CHAN_MSK_OR(interface), chan_msk_or.u64);
 	/* set rx back pressure (bp_on) on value */
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_RX_BP_ON(index, interface), bgx_rx_bp_on.u64);
 }
@@ -237,9 +244,10 @@ static void __cvmx_helper_bgx_common_init_pknd(int xiface, int index)
  */
 int __cvmx_helper_bgx_probe(int xiface)
 {
-	__cvmx_helper_bgx_common_init(xiface);	
+	__cvmx_helper_bgx_common_init(xiface);
 	return __cvmx_helper_bgx_enumerate(xiface);
 }
+EXPORT_SYMBOL(__cvmx_helper_bgx_probe);
 
 /**
  * @INTERNAL
@@ -250,68 +258,31 @@ int __cvmx_helper_bgx_probe(int xiface)
  *
  * @return Zero on success, negative on failure
  */
-static int __cvmx_helper_bgx_sgmii_init(int xiface, int index)
+static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int xiface, int index)
 {
-	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
-	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
-	cvmx_bgxx_gmp_pcs_linkx_timer_t gmp_timer;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
 	int node = xi.node;
 	const uint64_t clock_mhz = cvmx_clock_get_rate_node(node, CVMX_CLOCK_SCLK) / 1000000;
-	int phy_mode, mode_1000x;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+	cvmx_bgxx_gmp_pcs_linkx_timer_t gmp_timer;
 
 	if (!cvmx_helper_is_port_valid(interface, index))
 		return 0;
 
-	/* Take PCS through a reset sequence */
-	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
-		gmp_control.s.reset = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
-		       					     gmp_control.u64);
-
-		/* Wait until GMP_PCS_MRX_CONTROL[reset] comes out of reset */
-		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
-				cvmx_bgxx_gmp_pcs_mrx_control_t, reset, ==, 0, 10000)) {
-			cvmx_dprintf("SGMII%d: Timeout waiting for port %d to finish reset\n", interface, index);
-			return -1;
-		}
-	}
-
-	/* Write GMP_PCS_MR*_CONTROL[RST_AN]=1 to ensure a fresh SGMII
-	   negotiation starts. */
-	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
-	gmp_control.s.rst_an = 1;
-	gmp_control.s.an_en = 1;
-	gmp_control.s.pwr_dn = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
-		       gmp_control.u64);
-
-	phy_mode = cvmx_helper_get_mac_phy_mode(xiface, index);
-	mode_1000x = cvmx_helper_get_1000x_mode(xiface, index);
-
+	/*
+	 * Write PCS*_LINK*_TIMER_COUNT_REG[COUNT] with the
+	 * appropriate value. 1000BASE-X specifies a 10ms
+	 * interval. SGMII specifies a 1.6ms interval.
+	 */
 	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
-	gmp_misc_ctl.s.mac_phy = phy_mode;
-	gmp_misc_ctl.s.mode = mode_1000x;
+	/* Adjust the MAC mode if requested by device tree */
+	gmp_misc_ctl.s.mac_phy =
+		cvmx_helper_get_mac_phy_mode(xiface, index);
+	gmp_misc_ctl.s.mode =
+		cvmx_helper_get_1000x_mode(xiface, index);
 	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
 
-	if (phy_mode)
-		/* In PHY mode we can't query the link status so we just
-		   assume that the link is up */
-		return 0;
-
-	/* Wait for GMP_PCS_MRX_CONTROL[an_cpt] to be set, indicating that
-	   SGMII autonegotiation is complete. In MAC mode this isn't an
-	   ethernet link, but a link between OCTEON and PHY. */
-
-	if ((cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) &&
-	     CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_STATUS(index, interface),
-				   cvmx_bgxx_gmp_pcs_mrx_status_t, an_cpt,
-				   ==, 1, 10000)) {
-		cvmx_dprintf("SGMII%d: Port %d link timeout\n", interface, index);
-		return -1;
-	}
-
 	gmp_timer.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, interface));
 	if (gmp_misc_ctl.s.mode)
 		/* 1000BASE-X */
@@ -319,6 +290,7 @@ static int __cvmx_helper_bgx_sgmii_init(int xiface, int index)
 	else
 		/* SGMII */
 		gmp_timer.s.count = (1600ull * clock_mhz) >> 10;
+
 	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_LINKX_TIMER(index, interface), gmp_timer.u64);
 
 	/*
@@ -357,6 +329,49 @@ static int __cvmx_helper_bgx_sgmii_init(int xiface, int index)
 
 /**
  * @INTERNAL
+ * Bring up the SGMII interface to be ready for packet I/O but
+ * leave I/O disabled using the GMX override. This function
+ * follows the bringup documented in 10.6.3 of the manual.
+ *
+ * @param interface Interface to bringup
+ * @param num_ports Number of ports on the interface
+ *
+ * @return Zero on success, negative on failure
+ */
+static int __cvmx_helper_bgx_sgmii_hardware_init(int xiface, int num_ports)
+{
+	int index;
+	int do_link_set = 1;
+
+	for (index = 0; index < num_ports; index++) {
+		int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
+
+		__cvmx_helper_bgx_port_init(xipd_port, 0);
+
+		if (!cvmx_helper_is_port_valid(xiface, index))
+			continue;
+
+
+#ifdef CVMX_BUILD_FOR_LINUX_KERNEL
+		/*
+		 * Linux kernel driver will call ....link_set with the
+		 * proper link state. In the simulator there is no
+		 * link state polling and hence it is set from
+		 * here.
+		 */
+		if (!(cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM))
+			do_link_set = 0;
+#endif
+		if (do_link_set)
+			__cvmx_helper_bgx_sgmii_link_set(xipd_port,
+					__cvmx_helper_bgx_sgmii_link_get(xipd_port));
+	}
+
+	return 0;
+}
+
+/**
+ * @INTERNAL
  * Bringup and enable a SGMII interface. After this call packet
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled. This is used by interfaces using
@@ -366,56 +381,86 @@ static int __cvmx_helper_bgx_sgmii_init(int xiface, int index)
  *
  * @return Zero on success, negative on failure
  */
-int __cvmx_helper_bgx_sgmii_enable_port(int xiface, int index)
+int __cvmx_helper_bgx_sgmii_enable(int xiface)
 {
-	cvmx_bgxx_gmp_gmi_txx_append_t gmp_txx_append;
-	cvmx_bgxx_gmp_gmi_txx_sgmii_ctl_t gmp_sgmii_ctl;
-	cvmx_bgxx_gmp_gmi_txx_thresh_t gmi_tx_thresh;
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
-	int interface = xi.interface;
-	int node = xi.node;
-
-	__cvmx_helper_bgx_common_init_pknd(xiface, index);
-
-	/* Set TX Threshold */
-	gmp_txx_append.u64 = cvmx_read_csr_node(node,
-					CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface));
-	gmi_tx_thresh.u64 = 0;
-	gmi_tx_thresh.s.cnt = 0x20;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_THRESH(index, interface),
-			    gmi_tx_thresh.u64);
-
-	gmp_sgmii_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface));
-	gmp_sgmii_ctl.s.align = gmp_txx_append.s.preamble ? 0 : 1;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface),
-				gmp_sgmii_ctl.u64);
+	int num_ports;
 
+	num_ports = cvmx_helper_ports_on_interface(xiface);
+	__cvmx_helper_bgx_sgmii_hardware_init(xiface, num_ports);
 
 	return 0;
 }
 
-int __cvmx_helper_bgx_sgmii_enable(int xiface)
+/**
+ * @INTERNAL
+ * Initialize the SERTES link for the first time or after a loss
+ * of link.
+ *
+ * @param interface Interface to init
+ * @param index     Index of prot on the interface
+ *
+ * @return Zero on success, negative on failure
+ */
+static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
 {
+	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+	int phy_mode, mode_1000x;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	int interface = xi.interface;
 	int node = xi.node;
-	int num_ports;
-	int index;
 
-	num_ports = cvmx_helper_ports_on_interface(xiface);
-	__cvmx_helper_bgx_common_init(xiface);
+	if (!cvmx_helper_is_port_valid(xiface, index))
+		return 0;
 
-	for (index = 0; index < num_ports; index++) {
-		cvmx_bgxx_cmrx_config_t cmr_config;
+	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	/* Take PCS through a reset sequence */
+	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
+		gmp_control.s.reset = 1;
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+		       					     gmp_control.u64);
 
-		__cvmx_helper_bgx_sgmii_init(xiface, index);
-		__cvmx_helper_bgx_sgmii_enable_port(xiface, index);
+		/* Wait until GMP_PCS_MRX_CONTROL[reset] comes out of reset */
+		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+				cvmx_bgxx_gmp_pcs_mrx_control_t, reset, ==, 0, 10000)) {
+			cvmx_dprintf("SGMII%d: Timeout waiting for port %d to finish reset\n", interface, index);
+			return -1;
+		}
+	}
 
-		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
-		cmr_config.s.enable = 1;
-		cmr_config.s.data_pkt_tx_en = 1;
-		cmr_config.s.data_pkt_rx_en = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	/* Write GMP_PCS_MR*_CONTROL[RST_AN]=1 to ensure a fresh SGMII
+	   negotiation starts. */
+	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	gmp_control.s.rst_an = 1;
+	gmp_control.s.an_en = 1;
+	gmp_control.s.pwr_dn = 0;
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface),
+		       gmp_control.u64);
+
+
+	phy_mode = cvmx_helper_get_mac_phy_mode(xiface, index);
+	mode_1000x = cvmx_helper_get_1000x_mode(xiface, index);
+
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_misc_ctl.s.mac_phy = phy_mode;
+	gmp_misc_ctl.s.mode = mode_1000x;
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+
+	if (phy_mode)
+		/* In PHY mode we can't query the link status so we just
+		   assume that the link is up */
+		return 0;
+
+	/* Wait for GMP_PCS_MRX_CONTROL[an_cpt] to be set, indicating that
+	   SGMII autonegotiation is complete. In MAC mode this isn't an
+	   ethernet link, but a link between OCTEON and PHY. */
+
+	if ((cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) &&
+	     CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_PCS_MRX_STATUS(index, interface),
+				   cvmx_bgxx_gmp_pcs_mrx_status_t, an_cpt,
+				   ==, 1, 10000)) {
+		cvmx_dprintf("SGMII%d: Port %d link timeout\n", interface, index);
+		return -1;
 	}
 
 	return 0;
@@ -432,10 +477,11 @@ int __cvmx_helper_bgx_sgmii_enable(int xiface)
  *
  * @return Zero on success, negative on failure
  */
-static int __cvmx_helper_bgx_sgmii_speed(int xiface, int index,
-					 cvmx_helper_link_info_t link_info)
+static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int xiface,
+							    int index,
+							    cvmx_helper_link_info_t link_info)
 {
-	int is_enabled;
+	int is_enabled = 1;
 	cvmx_bgxx_cmrx_config_t cmr_config;
 	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_miscx_ctl;
 	cvmx_bgxx_gmp_gmi_prtx_cfg_t gmp_prtx_cfg;
@@ -446,19 +492,22 @@ static int __cvmx_helper_bgx_sgmii_speed(int xiface, int index,
 	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
 
-	/* Disable GMX before we make any changes. Remember the enable state */
-	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
-	is_enabled = cmr_config.s.enable;
-	cmr_config.s.enable = 0;
-	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	/* Errata bgx-22429*/
+	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X) || index) {
+		/* Disable GMX before we make any changes. Remember the enable state */
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+		is_enabled = cmr_config.s.enable;
+		cmr_config.s.enable = 0;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+	}
 
 	/* Wait for GMX to be idle */
 	if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
 				  cvmx_bgxx_gmp_gmi_prtx_cfg_t, rx_idle, ==, 1, 10000) ||
 	    CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface),
 				  cvmx_bgxx_gmp_gmi_prtx_cfg_t, tx_idle, ==, 1, 10000)) {
-		cvmx_dprintf("SGMII%d: Timeout waiting for port %d to be idle\n",
-			     interface, index);
+		cvmx_dprintf("SGMII%d:%d: Timeout waiting for port %d to be idle\n",
+			     node, interface, index);
 		return -1;
 	}
 
@@ -527,8 +576,13 @@ static int __cvmx_helper_bgx_sgmii_speed(int xiface, int index,
 	/* Read GMX CFG again to make sure the config completed */
 	cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_PRTX_CFG(index, interface));
 
-	/* Restore the enabled / disabled state */
-	cmr_config.s.enable = is_enabled;
+	/* Restore the enabled/disabled state */
+	/* bgx-22429 */
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+	if (!OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X) || index)
+		cmr_config.s.enable = is_enabled;
+	cmr_config.s.data_pkt_tx_en = 1;
+	cmr_config.s.data_pkt_rx_en = 1;
 	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 
 	return 0;
@@ -558,7 +612,6 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
 	int speed = 1000;
-	int qlm = cvmx_qlm_interface(xiface);
 
 	result.u64 = 0;
 
@@ -573,7 +626,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 		return result;
 	}
 
-	speed = cvmx_qlm_get_gbaud_mhz(qlm) * 8 / 10;
+	speed = cvmx_qlm_get_gbaud_mhz(0) * 8 / 10;
 
 	gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
 	if (gmp_control.s.loopbck1) {
@@ -600,6 +653,42 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 	return result;
 }
 
+int cvmx_helper_bgx_errata_22429(int xipd_port, int link_up)
+{
+	cvmx_bgxx_cmrx_config_t cmr_config;
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
+	int num_ports = cvmx_helper_ports_on_interface(xiface);
+
+	/* Errata does not apply for only 1 LMAC */
+	if (num_ports == 1 || !OCTEON_IS_MODEL(OCTEON_CN78XX_PASS1_X))
+		return 0;
+
+	/* Errata BGX-22429 */
+	if (link_up) {
+		if (!index) /*does not apply for port 0*/
+			return 0;
+		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(0, interface));
+		if (!cmr_config.s.enable) {
+			cmr_config.s.enable = 1;
+			cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(0, interface), cmr_config.u64);
+		}
+	} else {
+		if (index) /*does not apply to port 1-3 */
+			return 0;
+		while (--num_ports) {
+			cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(num_ports, interface));
+			if (cmr_config.s.enable)
+				return -1;
+		}
+	}
+	return 0;
+}
+
 /**
  * @INTERNAL
  * Configure an IPD/PKO port for the specified link state. This
@@ -617,63 +706,54 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port)
 int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 				 cvmx_helper_link_info_t link_info)
 {
-	int xiface = cvmx_helper_get_interface_num(xipd_port);
-	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
-	int index = cvmx_helper_get_interface_index_num(xp.port);
-	int status;
-
-	if (!cvmx_helper_is_port_valid(xiface, index))
-		return 0;
-
-	status = __cvmx_helper_bgx_sgmii_init(xiface, index);
-	if (status == 0)
-		return __cvmx_helper_bgx_sgmii_speed(xiface, index, link_info);
-	return 0;
-}
-
-/**
- * @INTERNAL
- * Configure a port for internal and/or external loopback. Internal loopback
- * causes packets sent by the port to be received by Octeon. External loopback
- * causes packets received from the wire to sent out again. This is used by
- * interfaces using the bgx mac.
- *
- * @param ipd_port IPD/PKO port to loopback.
- * @param enable_internal
- *                 Non zero if you want internal loopback
- * @param enable_external
- *                 Non zero if you want external loopback
- *
- * @return Zero on success, negative on failure.
- */
-int __cvmx_helper_bgx_sgmii_configure_loopback(int xipd_port, int enable_internal,
-					   int enable_external)
-{
+	cvmx_bgxx_cmrx_config_t cmr_config;
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
 	int interface = xi.interface;
 	int node = xi.node;
 	int index = cvmx_helper_get_interface_index_num(xp.port);
-	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_mrx_control;
-	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
 
 	if (!cvmx_helper_is_port_valid(xiface, index))
 		return 0;
 
-	gmp_mrx_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
-	gmp_mrx_control.s.loopbck1 = enable_internal;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_mrx_control.u64);
+	cvmx_helper_bgx_errata_22429(xipd_port, link_info.s.link_up);
 
-	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
-	gmp_misc_ctl.s.loopbck2 = enable_external;
-	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+	if (link_info.s.link_up) {
+		cmr_config.s.enable = 1;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+		__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
+	} else {
+		cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+		cmr_config.s.data_pkt_tx_en = 0;
+		cmr_config.s.data_pkt_rx_en = 0;
+		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+		gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
 
-	__cvmx_helper_bgx_sgmii_init(xiface, index);
+		/* Disable autonegotiation only when MAC mode. */
+		if (gmp_misc_ctl.s.mac_phy == 0) {
+			cvmx_bgxx_gmp_pcs_mrx_control_t gmp_control;
 
-	return 0;
+			gmp_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+			gmp_control.s.an_en = 0;
+			cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_control.u64);
+			cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+		}
+		/*
+		 * Use GMXENO to force the link down it will get
+		 * reenabled later...
+		 */
+		gmp_misc_ctl.s.gmxeno = 1;
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface),
+			       gmp_misc_ctl.u64);
+		cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+		return 0;
+	}
+	return __cvmx_helper_bgx_sgmii_hardware_init_link_speed(xiface, index, link_info);
 }
 
+
 /**
  * @INTERNAL
  * Bringup XAUI interface. After this call packet I/O should be
@@ -700,6 +780,7 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	int node = xi.node;
 	int use_auto_neg = 0;
 	int use_training = 0;
+	int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
 
 	mode = cvmx_helper_interface_get_mode(xiface);
 
@@ -723,20 +804,21 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		spu_control1.s.reset = 1;
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
 
-		/* Wait for PCS to come out of reset */
+		/* 1. Wait for PCS to come out of reset */
 		if (CVMX_WAIT_FOR_FIELD64_NODE(node, CVMX_BGXX_SPUX_CONTROL1(index, interface),
 				cvmx_bgxx_spux_control1_t, reset, ==, 0, 10000)) {
-			cvmx_dprintf("BGX%d: SPU stuck in reset\n", interface);
+			cvmx_dprintf("BGX%d:%d: SPU stuck in reset\n", node, interface);
 			return -1;
 		}
 
-		/* 1. Write BGX(0..5)_CMR(0..3)_CONFIG[ENABLE] to 0,
+		/* 2. Write BGX(0..5)_CMR(0..3)_CONFIG[ENABLE] to 0,
 		      BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 1 and
 		      BGX(0..5)_SPU(0..3)_MISC_CONTROL[RX_PACKET_DIS] = 1. */
-		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
-		cmr_config.s.enable = 0;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
-
+		if (!cvmx_helper_bgx_errata_22429(xipd_port, 0)) {
+			cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+			cmr_config.s.enable = 0;
+			cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+		}
 		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface));
 		spu_control1.s.lo_pwr = 1;
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
@@ -745,7 +827,7 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		spu_misc_control.s.rx_packet_dis = 1;
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
 
-		/* 2. At this point, it may be appropriate to disable all BGX and SMU/SPU
+		/* 3. At this point, it may be appropriate to disable all BGX and SMU/SPU
 		    interrupts, as a number of them will occur during bring-up of the Link.
 		    - zero BGX(0..5)_SMU(0..3)_RX_INT
 		    - zero BGX(0..5)_SMU(0..3)_TX_INT
@@ -757,14 +839,15 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_INT(index, interface),
 			cvmx_read_csr_node(node, CVMX_BGXX_SPUX_INT(index, interface)));
 
-		/* 3. Configure the BGX LMAC. */
-		/* 3a. Configure the LMAC type (40GBASE-R/10GBASE-R/RXAUI/XAUI) and
+		/* 4. Configure the BGX LMAC. */
+		/* 4a. Configure the LMAC type (40GBASE-R/10GBASE-R/RXAUI/XAUI) and
 		     SerDes selection in the BGX(0..5)_CMR(0..3)_CONFIG register, but keep
 		     the ENABLE, DATA_PKT_TX_EN and DATA_PKT_RX_EN bits clear. */
 		/* Already done in bgx_setup_one_time */
 
-		/* 3b. Write BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 1 and
+		/* 4b. Write BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 1 and
 		     BGX(0..5)_SPU(0..3)_MISC_CONTROL[RX_PACKET_DIS] = 1. */
+		/* FIXME it is already dine in step 2 */
 		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface));
 		spu_control1.s.lo_pwr = 1;
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
@@ -773,11 +856,11 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		spu_misc_control.s.rx_packet_dis = 1;
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
 
-		/* 3c. Initialize the selected SerDes lane(s) in the QLM. See Section
+		/* 4b. Initialize the selected SerDes lane(s) in the QLM. See Section
 		      28.1.2.2 in the GSER chapter. */
 		/* Already done in QLM setup */
 
-		/* 3d. For 10GBASE-KR or 40GBASE-KR, enable link training by writing
+		/* 4c. For 10GBASE-KR or 40GBASE-KR, enable link training by writing
 		     BGX(0..5)_SPU(0..3)_BR_PMD_CONTROL[TRAIN_EN] = 1. */
 		if (use_training) {
 			cvmx_bgxx_spux_br_pmd_control_t spu_br_pmd_control;
@@ -788,7 +871,7 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		}
 	}
 
-	/* 3e. Program all other relevant BGX configuration while
+	/* 4d. Program all other relevant BGX configuration while
 	       BGX(0..5)_CMR(0..3)_CONFIG[ENABLE] = 0. This includes all things
 	       described in this chapter. */
 	/* Always add FCS to PAUSE frames */
@@ -796,7 +879,7 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	smu_tx_append.s.fcs_d = 1;
 	cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_APPEND(index, interface), smu_tx_append.u64);
 
-	/* 3f. If Forward Error Correction is desired for 10GBASE-R or 40GBASE-R,
+	/* 4e. If Forward Error Correction is desired for 10GBASE-R or 40GBASE-R,
 	       enable it by writing BGX(0..5)_SPU(0..3)_FEC_CONTROL[FEC_EN] = 1. */
 	if (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM) {
 		/* FEC is optional for 10GBASE-KR, 40GBASE-KR4, and XLAUI. We're going
@@ -805,7 +888,7 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		spu_fec_control.s.fec_en = 0;
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_BR_PMD_CONTROL(index, interface), spu_fec_control.u64);
 
-		/* 3g. If Auto-Negotiation is desired, configure and enable
+		/* 4f. If Auto-Negotiation is desired, configure and enable
 		      Auto-Negotiation as described in Section 33.6.2. */
 		spu_an_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_AN_CONTROL(index, interface));
 		spu_an_control.s.an_en = use_auto_neg;
@@ -837,6 +920,7 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 
 		/* 3h. Set BGX(0..5)_CMR(0..3)_CONFIG[ENABLE] = 1 and
 		    BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 0 to enable the LMAC. */
+		cvmx_helper_bgx_errata_22429(xipd_port, 1);
 		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
 		cmr_config.s.enable = 1;
 		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
@@ -846,7 +930,7 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
 	}
 
-	/* 4b. Set the polarity and lane swapping of the QLM SerDes. Refer to
+	/* 4g. Set the polarity and lane swapping of the QLM SerDes. Refer to
 	   Section 33.4.1, BGX(0..5)_SPU(0..3)_MISC_CONTROL[XOR_TXPLRT,XOR_RXPLRT]
 	   and BGX(0..5)_SPU(0..3)_MISC_CONTROL[TXPLRT,RXPLRT]. */
 
@@ -865,6 +949,150 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	return 0;
 }
 
+int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres)
+{
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
+	int lmac_type = 0;
+	int lane_to_sds = 0;
+	cvmx_helper_interface_mode_t mode;
+	cvmx_bgxx_cmrx_config_t cmr_config;
+
+	mode = cvmx_helper_interface_get_mode(xiface);
+	switch (mode) {
+	case CVMX_HELPER_INTERFACE_MODE_SGMII:
+		lmac_type = 0;
+		lane_to_sds = 1;
+		break;
+	case CVMX_HELPER_INTERFACE_MODE_XAUI:
+		lmac_type = 1;
+		lane_to_sds = 0xe4;
+		break;
+	case CVMX_HELPER_INTERFACE_MODE_RXAUI:
+		lmac_type = 2;
+		break;
+	case CVMX_HELPER_INTERFACE_MODE_XFI:
+	case CVMX_HELPER_INTERFACE_MODE_10G_KR:
+		lmac_type = 3;
+		lane_to_sds = 1;
+		break;
+	case CVMX_HELPER_INTERFACE_MODE_XLAUI:
+	case CVMX_HELPER_INTERFACE_MODE_40G_KR4:
+		lmac_type = 4;
+		lane_to_sds = 0xe4;
+		break;
+	default:
+		break;
+	}
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.s.enable = 0;
+	cmr_config.s.data_pkt_tx_en = 0;
+	cmr_config.s.data_pkt_rx_en = 0;
+	cmr_config.s.lmac_type = lmac_type;
+	cmr_config.s.lane_to_sds = ((lane_to_sds == 1) ? index
+	: ((lane_to_sds == 0)
+			? (index ? 0xe : 4) : lane_to_sds));
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
+	__cvmx_bgx_common_init_pknd(xiface, index);
+
+	if (mode == CVMX_HELPER_INTERFACE_MODE_SGMII) {
+		cvmx_bgxx_gmp_gmi_txx_thresh_t gmi_tx_thresh;
+		cvmx_bgxx_gmp_gmi_txx_append_t gmp_txx_append;
+		cvmx_bgxx_gmp_gmi_txx_sgmii_ctl_t gmp_sgmii_ctl;
+
+		/* Set TX Threshold */
+		gmi_tx_thresh.u64 = 0;
+		gmi_tx_thresh.s.cnt = 0x20;
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_THRESH(index, interface),
+				    gmi_tx_thresh.u64);
+		__cvmx_helper_bgx_sgmii_hardware_init_one_time(interface, index);
+		gmp_txx_append.u64 = cvmx_read_csr_node(node,
+					CVMX_BGXX_GMP_GMI_TXX_APPEND(index, interface));
+		gmp_sgmii_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface));
+		gmp_sgmii_ctl.s.align = gmp_txx_append.s.preamble ? 0 : 1;
+		cvmx_write_csr_node(node, CVMX_BGXX_GMP_GMI_TXX_SGMII_CTL(index, interface),
+			    gmp_sgmii_ctl.u64);
+
+	} else {
+		int res;
+		cvmx_bgxx_smux_tx_thresh_t smu_tx_thresh;
+
+		smu_tx_thresh.u64 = 0;
+		/* Hopefully big enough to avoid underrun, but not too
+		* big to adversly effect shaping.
+		*/
+		smu_tx_thresh.s.cnt = 0x100;
+		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_THRESH(index, interface),
+				    smu_tx_thresh.u64);
+		/* Set disparity for RXAUI interface as described in the
+		Marvell RXAUI Interface specification. */
+		if (mode == CVMX_HELPER_INTERFACE_MODE_RXAUI && phy_pres) {
+			cvmx_bgxx_spux_misc_control_t misc_control;
+			misc_control.u64 = cvmx_read_csr_node(node,
+					CVMX_BGXX_SPUX_MISC_CONTROL(index, interface));
+			misc_control.s.intlv_rdisp = 1;
+			cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface),
+					    misc_control.u64);
+		}
+		res = __cvmx_helper_bgx_xaui_init(index, xiface);
+		if (res == -1) {
+			cvmx_dprintf("Failed to enable XAUI for %d:BGX(%d,%d)\n", node, interface, index);
+			return res;
+		}
+	}
+	return 0;
+}
+EXPORT_SYMBOL(__cvmx_helper_bgx_port_init);
+
+
+/**
+ * @INTERNAL
+ * Configure a port for internal and/or external loopback. Internal loopback
+ * causes packets sent by the port to be received by Octeon. External loopback
+ * causes packets received from the wire to sent out again. This is used by
+ * interfaces using the bgx mac.
+ *
+ * @param ipd_port IPD/PKO port to loopback.
+ * @param enable_internal
+ *                 Non zero if you want internal loopback
+ * @param enable_external
+ *                 Non zero if you want external loopback
+ *
+ * @return Zero on success, negative on failure.
+ */
+int __cvmx_helper_bgx_sgmii_configure_loopback(int xipd_port, int enable_internal,
+					   int enable_external)
+{
+	int xiface = cvmx_helper_get_interface_num(xipd_port);
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	struct cvmx_xport xp = cvmx_helper_ipd_port_to_xport(xipd_port);
+	int interface = xi.interface;
+	int node = xi.node;
+	int index = cvmx_helper_get_interface_index_num(xp.port);
+	cvmx_bgxx_gmp_pcs_mrx_control_t gmp_mrx_control;
+	cvmx_bgxx_gmp_pcs_miscx_ctl_t gmp_misc_ctl;
+
+	if (!cvmx_helper_is_port_valid(xiface, index))
+		return 0;
+
+	gmp_mrx_control.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface));
+	gmp_mrx_control.s.loopbck1 = enable_internal;
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MRX_CONTROL(index, interface), gmp_mrx_control.u64);
+
+	gmp_misc_ctl.u64 = cvmx_read_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface));
+	gmp_misc_ctl.s.loopbck2 = enable_external;
+	cvmx_write_csr_node(node, CVMX_BGXX_GMP_PCS_MISCX_CTL(index, interface), gmp_misc_ctl.u64);
+
+	__cvmx_helper_bgx_sgmii_hardware_init_link(xiface, index);
+
+	return 0;
+}
+
 static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 {
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
@@ -874,6 +1102,7 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 	cvmx_bgxx_spux_status2_t spu_status2;
 	cvmx_bgxx_spux_int_t spu_int;
 	cvmx_bgxx_spux_misc_control_t spu_misc_control;
+	cvmx_bgxx_cmrx_config_t cmr_config;
 	cvmx_helper_interface_mode_t mode;
 	int use_training = 0;
 
@@ -1007,13 +1236,16 @@ static int __cvmx_helper_bgx_xaui_link_init(int index, int xiface)
 	spu_misc_control.s.rx_packet_dis = 0;
 	cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface), spu_misc_control.u64);
 
+	cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
+	cmr_config.s.data_pkt_tx_en = 1;
+	cmr_config.s.data_pkt_rx_en = 1;
+	cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
+
 	return 0;
 }
 
 int __cvmx_helper_bgx_xaui_enable(int xiface)
 {
-	cvmx_bgxx_smux_tx_thresh_t smu_tx_thresh;
-	cvmx_bgxx_cmrx_config_t cmr_config;
 	int index;
 	int num_ports = cvmx_helper_ports_on_interface(xiface);
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
@@ -1023,44 +1255,24 @@ int __cvmx_helper_bgx_xaui_enable(int xiface)
 
 	mode = cvmx_helper_interface_get_mode(xiface);
 
-	__cvmx_helper_bgx_common_init(xiface);
-
 	for (index = 0; index < num_ports; index++) {
-		int res = __cvmx_helper_bgx_xaui_init(index, xiface);
-		__cvmx_helper_bgx_common_init_pknd(xiface, index);
-		if (res == -1) {
-			cvmx_dprintf("Failed to enable XAUI for BGX(%d,%d)\n", interface, index);
-			return res;
-		}
+		int res;
+		int xipd_port = cvmx_helper_get_ipd_port(xiface, index);
+		int phy_pres;
 
-		smu_tx_thresh.u64 = 0;
-		/* Hopefully big enough to avoid underrun, but not too
-		 * big to adversly effect shaping.
-		 */
-		smu_tx_thresh.s.cnt = 0x100;
-		cvmx_write_csr_node(node, CVMX_BGXX_SMUX_TX_THRESH(index, interface),
-					smu_tx_thresh.u64);
 		/* Set disparity for RXAUI interface as described in the
 		Marvell RXAUI Interface specification. */
-		if (mode == CVMX_HELPER_INTERFACE_MODE_RXAUI) {
-			if (cvmx_helper_get_port_phy_present(xiface, index)) {
-				cvmx_bgxx_spux_misc_control_t misc_control;
-				misc_control.u64 = cvmx_read_csr_node(node,
-						CVMX_BGXX_SPUX_MISC_CONTROL(index, interface));
-				misc_control.s.intlv_rdisp = 1;
-				cvmx_write_csr_node(node, CVMX_BGXX_SPUX_MISC_CONTROL(index, interface),
-						misc_control.u64);
-			}
-		}
+		if (mode == CVMX_HELPER_INTERFACE_MODE_RXAUI &&
+				  (cvmx_helper_get_port_phy_present(xiface, index)))
+			phy_pres = 1;
+		else
+			phy_pres = 0;
+		if (__cvmx_helper_bgx_port_init(xipd_port, phy_pres))
+			return -1;
 
-		cmr_config.u64 = cvmx_read_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface));
-		cmr_config.s.enable = 1;
-		cmr_config.s.data_pkt_tx_en = 1;
-		cmr_config.s.data_pkt_rx_en = 1;
-		cvmx_write_csr_node(node, CVMX_BGXX_CMRX_CONFIG(index, interface), cmr_config.u64);
 		res = __cvmx_helper_bgx_xaui_link_init(index, xiface);
 		if (res == -1) {
-			cvmx_dprintf("Failed to get BGX(%d,%d) link\n", interface, index);
+			cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", node, interface, index);
 			continue;
 		}
 	}
@@ -1112,7 +1324,7 @@ cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port)
 		int res;
 		res = __cvmx_helper_bgx_xaui_link_init(index, xiface);
 		if (res == -1) {
-			/*cvmx_dprintf("Failed to get BGX(%d,%d) link\n", interface, index); */
+			cvmx_dprintf("Failed to get %d:BGX(%d,%d) link\n", node, interface, index);
 			return result;
 		}
 	}
@@ -1279,8 +1491,8 @@ void cvmx_helper_bgx_tx_options(unsigned node,
 	/* Temp: initial mode setting is only applied to LMAC(0), use that */
 	if (cmr_config0.s.lmac_type != cmr_config.s.lmac_type) {
 		cvmx_dprintf("WARNING: %s: "
-			"BGX(%d).CMR(0).LMAC_TYPE != BGX(%d).CMR(%d).LMAC_TYPE\n",
-			__func__, interface, interface, index);
+			"%d:BGX(%d).CMR(0).LMAC_TYPE != BGX(%d).CMR(%d).LMAC_TYPE\n",
+			__func__, node, interface, interface, index);
 		cmr_config.s.lmac_type = cmr_config0.s.lmac_type;
 	}
 
@@ -1324,8 +1536,8 @@ void cvmx_helper_bgx_tx_options(unsigned node,
  * 		    0 = Force reject all multicast packets
  * 		    1 = Force accept all multicast packets
  * 		    2 = use the address filter CAM.
- * @param mac       mac address for the ipd_port		    
- */ 		    
+ * @param mac       mac address for the ipd_port
+ */
 void cvmx_helper_bgx_set_mac(int xipd_port, int bcst, int mcst, uint64_t mac)
 {
 	int xiface = cvmx_helper_get_interface_num(xipd_port);
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
index 85793fd..062d8de 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
@@ -253,7 +253,8 @@ extern void cvmx_helper_bgx_tx_options(unsigned node,
  * 		    0 = Force reject all multicast packets
  * 		    1 = Force accept all multicast packets
  * 		    2 = use the address filter CAM.
- * @param mac       mac address for the ipd_port		    
- */ 		    
+ * @param mac       mac address for the ipd_port
+ */
 extern void cvmx_helper_bgx_set_mac(int xipd_port, int bcst, int mcst, uint64_t mac);
+extern int __cvmx_helper_bgx_port_init(int xipd_port, int phy_pres);
 #endif
-- 
2.6.2

