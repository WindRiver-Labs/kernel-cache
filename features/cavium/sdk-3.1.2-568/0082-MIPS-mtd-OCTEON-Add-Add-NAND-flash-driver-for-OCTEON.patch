From 72eb4a213690658a5c0d5abc353247f08240fc32 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Tue, 30 Oct 2012 12:23:01 -0700
Subject: [PATCH 082/974] MIPS/mtd/OCTEON: Add Add NAND flash driver for
 OCTEON.

The OCTEON NAND hardware is so different, we have to make a
couple of changes to core code too.

Signed-off-by: David Daney <david.daney@cavium.com>
Signed-off-by: Leonid Rosenboim <lrosenboim@caviumnetworks.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/cavium-octeon/Makefile              |    3 +-
 arch/mips/cavium-octeon/executive/Makefile    |    1 +
 arch/mips/cavium-octeon/executive/cvmx-nand.c | 1803 +++++++++++++++++++++++++
 arch/mips/cavium-octeon/octeon-nand.c         |  450 ++++++
 arch/mips/include/asm/octeon/cvmx-nand.h      |  689 ++++++++++
 arch/mips/include/asm/octeon/cvmx-ndf-defs.h  |  278 ++++
 drivers/mtd/nand/nand_base.c                  |   11 +
 7 files changed, 3234 insertions(+), 1 deletion(-)
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-nand.c
 create mode 100644 arch/mips/cavium-octeon/octeon-nand.c
 create mode 100644 arch/mips/include/asm/octeon/cvmx-nand.h
 create mode 100644 arch/mips/include/asm/octeon/cvmx-ndf-defs.h

diff --git a/arch/mips/cavium-octeon/Makefile b/arch/mips/cavium-octeon/Makefile
index a507be7..3cdd7a2 100644
--- a/arch/mips/cavium-octeon/Makefile
+++ b/arch/mips/cavium-octeon/Makefile
@@ -6,7 +6,7 @@
 # License.  See the file "COPYING" in the main directory of this archive
 # for more details.
 #
-# Copyright (C) 2005-2009 Cavium Networks
+# Copyright (C) 2005-2012 Cavium, Inc.
 #
 
 CFLAGS_octeon-platform.o = -I$(src)/../../../scripts/dtc/libfdt
@@ -22,6 +22,7 @@ obj-y += executive/
 obj-$(CONFIG_SMP)		      += smp.o
 obj-$(CONFIG_OCTEON_ILM)	      += oct_ilm.o
 obj-$(CONFIG_SYSFS)                   += octeon-power-throttle.o
+obj-$(CONFIG_CAVIUM_OCTEON_NAND)	+= octeon-nand.o
 
 DTS_FILES = octeon_3xxx.dts octeon_68xx.dts
 DTB_FILES = $(patsubst %.dts, %.dtb, $(DTS_FILES))
diff --git a/arch/mips/cavium-octeon/executive/Makefile b/arch/mips/cavium-octeon/executive/Makefile
index b6d6e84..b873f98 100644
--- a/arch/mips/cavium-octeon/executive/Makefile
+++ b/arch/mips/cavium-octeon/executive/Makefile
@@ -17,3 +17,4 @@ obj-y += cvmx-pko.o cvmx-spi.o cvmx-cmd-queue.o \
 	cvmx-interrupt-decodes.o cvmx-interrupt-rsl.o
 
 obj-y += cvmx-helper-errata.o cvmx-helper-jtag.o
+obj-$(CONFIG_CAVIUM_OCTEON_NAND)	+= cvmx-nand.o
diff --git a/arch/mips/cavium-octeon/executive/cvmx-nand.c b/arch/mips/cavium-octeon/executive/cvmx-nand.c
new file mode 100644
index 0000000..da3cc9a
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-nand.c
@@ -0,0 +1,1803 @@
+/***********************license start***************
+ * Author: Cavium Inc.
+ *
+ * Contact: support@cavium.com
+ * This file is part of the OCTEON SDK
+ *
+ * Copyright (c) 2003-2010 Cavium Inc.
+ *
+ * This file is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License, Version 2, as
+ * published by the Free Software Foundation.
+ *
+ * This file is distributed in the hope that it will be useful, but
+ * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
+ * NONINFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this file; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
+ * or visit http://www.gnu.org/licenses/.
+ *
+ * This file may also be available under a different license from Cavium.
+ * Contact Cavium Inc. for more information
+ ***********************license end**************************************/
+
+/*
+ *
+ * Interface to the NAND flash controller.
+ * See cvmx-nand.h for usage documentation and notes.
+ *
+ */
+
+#include <linux/export.h>
+#include <linux/delay.h>
+
+#include <asm/octeon/octeon.h>
+#include <asm/octeon/cvmx-nand.h>
+#include <asm/octeon/cvmx-ndf-defs.h>
+#include <asm/octeon/cvmx-bootmem.h>
+
+#define cvmx_unlikely unlikely
+#define cvmx_likely likely
+#define cvmx_le32_to_cpu le32_to_cpu
+#define cvmx_le16_to_cpu le16_to_cpu
+#ifndef CVMX_SHARED
+#define CVMX_SHARED
+#endif
+#define WATCHDOG_RESET()
+
+#define NAND_COMMAND_READ_ID            0x90
+#define NAND_COMMAND_READ_PARAM_PAGE    0xec
+#define NAND_COMMAND_RESET              0xff
+#define NAND_COMMAND_STATUS             0x70
+#define NAND_COMMAND_READ               0x00
+#define NAND_COMMAND_READ_FIN           0x30
+#define NAND_COMMAND_ERASE              0x60
+#define NAND_COMMAND_ERASE_FIN          0xd0
+#define NAND_COMMAND_PROGRAM            0x80
+#define NAND_COMMAND_PROGRAM_FIN        0x10
+#define NAND_TIMEOUT_USECS_READ         100000
+#define NAND_TIMEOUT_USECS_WRITE        1000000
+#define NAND_TIMEOUT_USECS_BLOCK_ERASE  1000000
+
+#define CVMX_NAND_ROUNDUP(_Dividend, _Divisor) (((_Dividend)+((_Divisor)-1))/(_Divisor))
+
+/* Structure to store the parameters that we care about that
+** describe the ONFI speed modes.  This is used to configure
+** the flash timing to match what is reported in the
+** parameter page of the ONFI flash chip. */
+typedef struct {
+	int twp;
+	int twh;
+	int twc;
+	int tclh;
+	int tals;
+} onfi_speed_mode_desc_t;
+static const onfi_speed_mode_desc_t onfi_speed_modes[] = {
+
+	{50, 30, 100, 20, 50},	/* Mode 0 */
+	{25, 15, 45, 10, 25},	/* Mode 1 */
+	{17, 15, 35, 10, 15},	/* Mode 2 */
+	{15, 10, 30, 5, 10},	/* Mode 3 */
+	{12, 10, 25, 5, 10},	/* Mode 4, requires EDO timings */
+	{10, 7, 20, 5, 10},	/* Mode 5, requries EDO timings */
+	{10, 10, 25, 5, 12},	/* Mode 6, requires EDO timings */
+};
+
+typedef enum {
+	CVMX_NAND_STATE_16BIT = 1 << 0,
+} cvmx_nand_state_flags_t;
+
+/**
+ * Structure used to store data about the NAND devices hooked
+ * to the bootbus.
+ */
+typedef struct {
+	int page_size;
+	int oob_size;
+	int pages_per_block;
+	int blocks;
+	int tim_mult;
+	int tim_par[8];
+	int clen[4];
+	int alen[4];
+	int rdn[4];
+	int wrn[2];
+	int onfi_timing;
+	cvmx_nand_state_flags_t flags;
+} cvmx_nand_state_t;
+
+/**
+ * Array indexed by bootbus chip select with information
+ * about NAND devices.
+ */
+
+#ifdef USE_DATA_IN_TEXT
+static uint8_t cvmx_nand_buffer[CVMX_NAND_MAX_PAGE_AND_OOB_SIZE] __attribute__ ((aligned(8))) __attribute__ ((section(".data_in_text")));
+static cvmx_nand_state_t cvmx_nand_state[8] __attribute__ ((section(".data_in_text")));
+static cvmx_nand_state_t cvmx_nand_default __attribute__ ((section(".data_in_text")));
+static cvmx_nand_initialize_flags_t cvmx_nand_flags __attribute__ ((section(".data_in_text")));
+static int debug_indent __attribute__ ((section(".data_in_text")));
+#else
+static CVMX_SHARED cvmx_nand_state_t cvmx_nand_state[8];
+static CVMX_SHARED cvmx_nand_state_t cvmx_nand_default;
+static CVMX_SHARED cvmx_nand_initialize_flags_t cvmx_nand_flags;
+static CVMX_SHARED uint8_t *cvmx_nand_buffer;
+static int debug_indent;
+#endif
+
+static CVMX_SHARED const char *cvmx_nand_opcode_labels[] = {
+	"NOP",			/* 0 */
+	"Timing",		/* 1 */
+	"Wait",			/* 2 */
+	"Chip Enable / Disable",	/* 3 */
+	"CLE",			/* 4 */
+	"ALE",			/* 5 */
+	"6 - Unknown",		/* 6 */
+	"7 - Unknown",		/* 7 */
+	"Write",		/* 8 */
+	"Read",			/* 9 */
+	"Read EDO",		/* 10 */
+	"Wait Status",		/* 11 */
+	"12 - Unknown",		/* 12 */
+	"13 - Unknown",		/* 13 */
+	"14 - Unknown",		/* 14 */
+	"Bus Aquire / Release"	/* 15 */
+};
+
+#define ULL unsigned long long
+/* This macro logs out whenever a function is called if debugging is on */
+#define CVMX_NAND_LOG_CALLED() \
+	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
+		cvmx_dprintf("%*s%s: called\n", 2*debug_indent++, "", __func__);
+
+/* This macro logs out each function parameter if debugging is on */
+#define CVMX_NAND_LOG_PARAM(format, param) \
+	do {								\
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
+			cvmx_dprintf("%*s%s: param %s = " format "\n", 2*debug_indent, "", __func__, #param, param); \
+	} while(0)
+
+/* This macro logs out when a function returns a value */
+#define CVMX_NAND_RETURN(v)                                              \
+	do {								\
+		typeof(v) r = v;					\
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
+			cvmx_dprintf("%*s%s: returned %s(%d)\n", 2*--debug_indent, "", __func__, #v, r); \
+		return r;						\
+	} while (0)
+
+/* This macro logs out when a function doesn't return a value */
+#define CVMX_NAND_RETURN_NOTHING()                                      \
+	do {								\
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) \
+			cvmx_dprintf("%*s%s: returned\n", 2*--debug_indent, "", __func__); \
+		return;							\
+	} while (0)
+
+/* Compute the CRC for the ONFI parameter page.  Adapted from sample code
+** in the specification.
+*/
+static uint16_t __onfi_parameter_crc_compute(uint8_t *data)
+{
+	const int order = 16;	/* Order of the CRC-16 */
+	unsigned long i, j, c, bit;
+	unsigned long crc = 0x4F4E;	/* Initialize the shift register with 0x4F4E */
+	unsigned long crcmask = ((((unsigned long)1 << (order - 1)) - 1) << 1) | 1;
+	unsigned long crchighbit = (unsigned long)1 << (order - 1);
+
+	for (i = 0; i < 254; i++) {
+		c = (unsigned long)data[i];
+		for (j = 0x80; j; j >>= 1) {
+			bit = crc & crchighbit;
+			crc <<= 1;
+			if (c & j)
+				bit ^= crchighbit;
+			if (bit)
+				crc ^= 0x8005;
+		}
+		crc &= crcmask;
+	}
+	return crc;
+}
+
+/**
+ * Validate the ONFI parameter page and return a pointer to
+ * the config values.
+ *
+ * @param_page: Pointer to the raw NAND data returned after a parameter page read. It will
+ *                   contain at least 4 copies of the parameter structure.
+ *
+ * Returns Pointer to a validated paramter page, or NULL if one couldn't be found.
+ */
+static cvmx_nand_onfi_param_page_t *__cvmx_nand_onfi_process(cvmx_nand_onfi_param_page_t param_page[4])
+{
+	int index;
+
+	for (index = 0; index < 4; index++) {
+		uint16_t crc = __onfi_parameter_crc_compute((void *)&param_page[index]);
+		if (crc == cvmx_le16_to_cpu(param_page[index].crc))
+			break;
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+			cvmx_dprintf("%s: Paramter page %d is corrupt. (Expected CRC: 0x%04x, computed: 0x%04x)\n", __func__, index, cvmx_le16_to_cpu(param_page[index].crc), crc);
+	}
+
+	if (index == 4) {
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+			cvmx_dprintf("%s: All parameter pages fail CRC check.  Checking to see if any look sane.\n", __func__);
+
+		if (!memcmp(param_page, param_page + 1, 256)) {
+			/* First and second copies match, now check some values */
+			if (param_page[0].pages_per_block != 0 && param_page[0].pages_per_block != 0xFFFFFFFF
+			    && param_page[0].page_data_bytes != 0 && param_page[0].page_data_bytes != 0xFFFFFFFF
+			    && param_page[0].page_spare_bytes != 0 && param_page[0].page_spare_bytes != 0xFFFF
+			    && param_page[0].blocks_per_lun != 0 && param_page[0].blocks_per_lun != 0xFFFFFFFF
+			    && param_page[0].timing_mode != 0 && param_page[0].timing_mode != 0xFFFF) {
+				/* Looks like we have enough values to use */
+				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+					cvmx_dprintf("%s: Page 0 looks sane, using even though CRC fails.\n", __func__);
+				index = 0;
+			}
+		}
+	}
+
+	if (index == 4) {
+		cvmx_dprintf("%s: WARNING: ONFI part but no valid ONFI parameter pages found.\n", __func__);
+		return NULL;
+	}
+
+	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
+		cvmx_dprintf("%*sONFI Information (from copy %d in param page)\n", 2 * debug_indent, "", index);
+		debug_indent++;
+		cvmx_dprintf("%*sonfi = %c%c%c%c\n", 2 * debug_indent, "", param_page[index].onfi[0], param_page[index].onfi[1],
+			     param_page[index].onfi[2], param_page[index].onfi[3]);
+		cvmx_dprintf("%*srevision_number = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].revision_number));
+		cvmx_dprintf("%*sfeatures = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].features));
+		cvmx_dprintf("%*soptional_commands = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].optional_commands));
+
+		cvmx_dprintf("%*smanufacturer = %12.12s\n", 2 * debug_indent, "", param_page[index].manufacturer);
+		cvmx_dprintf("%*smodel = %20.20s\n", 2 * debug_indent, "", param_page[index].model);
+		cvmx_dprintf("%*sjedec_id = 0x%x\n", 2 * debug_indent, "", param_page[index].jedec_id);
+		cvmx_dprintf("%*sdate_code = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].date_code));
+
+		cvmx_dprintf("%*spage_data_bytes = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].page_data_bytes));
+		cvmx_dprintf("%*spage_spare_bytes = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].page_spare_bytes));
+		cvmx_dprintf("%*spartial_page_data_bytes = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].partial_page_data_bytes));
+		cvmx_dprintf("%*spartial_page_spare_bytes = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].partial_page_spare_bytes));
+		cvmx_dprintf("%*spages_per_block = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].pages_per_block));
+		cvmx_dprintf("%*sblocks_per_lun = %u\n", 2 * debug_indent, "", (int)cvmx_le32_to_cpu(param_page[index].blocks_per_lun));
+		cvmx_dprintf("%*snumber_lun = %u\n", 2 * debug_indent, "", param_page[index].number_lun);
+		cvmx_dprintf("%*saddress_cycles = 0x%x\n", 2 * debug_indent, "", param_page[index].address_cycles);
+		cvmx_dprintf("%*sbits_per_cell = %u\n", 2 * debug_indent, "", param_page[index].bits_per_cell);
+		cvmx_dprintf("%*sbad_block_per_lun = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].bad_block_per_lun));
+		cvmx_dprintf("%*sblock_endurance = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].block_endurance));
+		cvmx_dprintf("%*sgood_blocks = %u\n", 2 * debug_indent, "", param_page[index].good_blocks);
+		cvmx_dprintf("%*sgood_block_endurance = %u\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].good_block_endurance));
+		cvmx_dprintf("%*sprograms_per_page = %u\n", 2 * debug_indent, "", param_page[index].programs_per_page);
+		cvmx_dprintf("%*spartial_program_attrib = 0x%x\n", 2 * debug_indent, "", param_page[index].partial_program_attrib);
+		cvmx_dprintf("%*sbits_ecc = %u\n", 2 * debug_indent, "", param_page[index].bits_ecc);
+		cvmx_dprintf("%*sinterleaved_address_bits = 0x%x\n", 2 * debug_indent, "", param_page[index].interleaved_address_bits);
+		cvmx_dprintf("%*sinterleaved_attrib = 0x%x\n", 2 * debug_indent, "", param_page[index].interleaved_attrib);
+
+		cvmx_dprintf("%*spin_capacitance = %u\n", 2 * debug_indent, "", param_page[index].pin_capacitance);
+		cvmx_dprintf("%*stiming_mode = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].timing_mode));
+		cvmx_dprintf("%*scache_timing_mode = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].cache_timing_mode));
+		cvmx_dprintf("%*st_prog = %d us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_prog));
+		cvmx_dprintf("%*st_bers = %u us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_bers));
+		cvmx_dprintf("%*st_r = %u us\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_r));
+		cvmx_dprintf("%*st_ccs = %u ns\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].t_ccs));
+		cvmx_dprintf("%*svendor_revision = 0x%x\n", 2 * debug_indent, "", cvmx_le16_to_cpu(param_page[index].vendor_revision));
+		/* uint8_t vendor_specific[88];    */ /**< Byte 166-253: Vendor specific */
+		cvmx_dprintf("%*scrc = 0x%x\n", 2 * debug_indent, "", param_page[index].crc);
+		debug_indent--;
+	}
+	return param_page + index;
+}
+
+void __set_onfi_timing_mode(int *tim_par, int clocks_us, int mode)
+{
+	const onfi_speed_mode_desc_t *mp = &onfi_speed_modes[mode];	/* use shorter name to fill in timing array */
+	int margin;
+	int pulse_adjust;
+
+	if (mode > 6) {
+		cvmx_dprintf("%s: invalid ONFI timing mode: %d\n", __func__, mode);
+		return;
+	}
+
+	/* Adjust the read/write pulse duty cycle to make it more even.  The cycle time
+	 ** requirement is longer than the sum of the high low times, so we exend both the high
+	 ** and low times to meet the cycle time requirement.
+	 */
+	pulse_adjust = ((mp->twc - mp->twh - mp->twp) / 2 + 1) * clocks_us;
+
+	/* Add a small margin to all timings. */
+	margin = 2 * clocks_us;
+	/* Update timing parameters based on supported mode */
+	tim_par[1] = CVMX_NAND_ROUNDUP(mp->twp * clocks_us + margin + pulse_adjust, 1000);	/* Twp, WE# pulse width */
+	tim_par[2] = CVMX_NAND_ROUNDUP(max(mp->twh, mp->twc - mp->twp) * clocks_us + margin + pulse_adjust, 1000);	/* Tw, WE# pulse width high */
+	tim_par[3] = CVMX_NAND_ROUNDUP(mp->tclh * clocks_us + margin, 1000);	/* Tclh, CLE hold time */
+	tim_par[4] = CVMX_NAND_ROUNDUP(mp->tals * clocks_us + margin, 1000);	/* Tals, ALE setup time */
+	tim_par[5] = tim_par[3];	/* Talh, ALE hold time */
+	tim_par[6] = tim_par[1];	/* Trp, RE# pulse width */
+	tim_par[7] = tim_par[2];	/* Treh, RE# high hold time */
+
+}
+
+/* Internal helper function to set chip configuration to use default values */
+static void __set_chip_defaults(int chip, int clocks_us)
+{
+	if (!cvmx_nand_default.page_size)
+		return;
+	cvmx_nand_state[chip].page_size = cvmx_nand_default.page_size;	/* NAND page size in bytes */
+	cvmx_nand_state[chip].oob_size = cvmx_nand_default.oob_size;	/* NAND OOB (spare) size in bytes (per page) */
+	cvmx_nand_state[chip].pages_per_block = cvmx_nand_default.pages_per_block;
+	cvmx_nand_state[chip].blocks = cvmx_nand_default.blocks;
+	cvmx_nand_state[chip].onfi_timing = cvmx_nand_default.onfi_timing;
+	__set_onfi_timing_mode(cvmx_nand_state[chip].tim_par, clocks_us, cvmx_nand_state[chip].onfi_timing);
+	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
+
+		cvmx_dprintf("%s: Using default NAND parameters.\n", __func__);
+		cvmx_dprintf("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, blocks: %d, timing mode: %d\n",
+			     __func__, cvmx_nand_state[chip].page_size, cvmx_nand_state[chip].oob_size, cvmx_nand_state[chip].pages_per_block,
+			     cvmx_nand_state[chip].blocks, cvmx_nand_state[chip].onfi_timing);
+	}
+}
+
+/* Do the proper wait for the ready/busy signal.  First wait
+** for busy to be valid, then wait for busy to de-assert.
+*/
+static int __wait_for_busy_done(int chip)
+{
+	cvmx_nand_cmd_t cmd;
+
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.wait.two = 2;
+	cmd.wait.r_b = 0;
+	cmd.wait.n = 2;
+
+	/* Wait for RB to be valied (tWB).
+	 ** Use 5 * tWC as proxy.  In some modes this is
+	 ** much longer than required, but does not affect performance
+	 ** since we will wait much longer for busy to de-assert.
+	 */
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	cmd.wait.r_b = 1;	/* Now wait for busy to be de-asserted */
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+
+/**
+ * Called to initialize the NAND controller for use. Note that
+ * you must be running out of L2 or memory and not NAND before
+ * calling this function.
+ * When probing for NAND chips, this function attempts to autoconfigure based on the NAND parts detected.
+ * It currently supports autodetection for ONFI parts (with valid parameter pages), and some Samsung NAND
+ * parts (decoding ID bits.)  If autoconfiguration fails, the defaults set with __set_chip_defaults()
+ * prior to calling cvmx_nand_initialize() are used.
+ * If defaults are set and the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is provided, the defaults are used
+ * for all chips in the active_chips mask.
+ *
+ * @flags:  Optional initialization flags
+ *               If the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is passed, chips are not probed,
+ *               and the default parameters (if set with cvmx_nand_set_defaults) are used for all chips
+ *               in the active_chips mask.
+ * @active_chips:
+ *               Each bit in this parameter represents a chip select that might
+ *               contain NAND flash. Any chip select present in this bitmask may
+ *               be connected to NAND. It is normally safe to pass 0xff here and
+ *               let the API probe all 8 chip selects.
+ *
+ * Returns Zero on success, a negative cvmx_nand_status error code on failure
+ */
+cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags, int active_chips)
+{
+	int chip;
+	int start_chip;
+	int stop_chip;
+	uint64_t clocks_us;
+	union cvmx_ndf_misc ndf_misc;
+	uint8_t nand_id_buffer[16];
+
+	cvmx_nand_flags = flags;
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("0x%x", flags);
+
+	memset(&cvmx_nand_state, 0, sizeof(cvmx_nand_state));
+
+#ifndef USE_DATA_IN_TEXT
+	/* cvmx_nand_buffer is statically allocated in the TEXT_IN_DATA case */
+	if (!cvmx_nand_buffer)
+		cvmx_nand_buffer = cvmx_bootmem_alloc_named_flags(CVMX_NAND_MAX_PAGE_AND_OOB_SIZE, 128, "__nand_buffer", CVMX_BOOTMEM_FLAG_END_ALLOC);
+
+	if (!cvmx_nand_buffer) {
+		const cvmx_bootmem_named_block_desc_t *block_desc = cvmx_bootmem_find_named_block("__nand_buffer");
+		if (block_desc)
+			cvmx_nand_buffer = cvmx_phys_to_ptr(block_desc->base_addr);
+	}
+
+	if (!cvmx_nand_buffer)
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+#endif
+
+	/* Disable boot mode and reset the fifo */
+	ndf_misc.u64 = cvmx_read_csr(CVMX_NDF_MISC);
+	ndf_misc.s.rd_cmd = 0;
+	ndf_misc.s.bt_dma = 0;
+	ndf_misc.s.bt_dis = 1;
+	ndf_misc.s.ex_dis = 0;
+	ndf_misc.s.rst_ff = 1;
+	cvmx_write_csr(CVMX_NDF_MISC, ndf_misc.u64);
+	cvmx_read_csr(CVMX_NDF_MISC);
+
+	/* Bring the fifo out of reset */
+	udelay(1);
+	ndf_misc.s.rst_ff = 0;
+	cvmx_write_csr(CVMX_NDF_MISC, ndf_misc.u64);
+	cvmx_read_csr(CVMX_NDF_MISC);
+	udelay(1);
+
+	/* Clear the ECC counter */
+	/* cvmx_write_csr(CVMX_NDF_ECC_CNT, cvmx_read_csr(CVMX_NDF_ECC_CNT)); */
+
+	/* Clear the interrupt state */
+	cvmx_write_csr(CVMX_NDF_INT, cvmx_read_csr(CVMX_NDF_INT));
+	cvmx_write_csr(CVMX_NDF_INT_EN, 0);
+	cvmx_write_csr(CVMX_MIO_NDF_DMA_INT, cvmx_read_csr(CVMX_MIO_NDF_DMA_INT));
+	cvmx_write_csr(CVMX_MIO_NDF_DMA_INT_EN, 0);
+
+	/* The simulator crashes if you access non existant devices. Assume
+	   only chip select 1 is connected to NAND */
+	if (cvmx_sysinfo_get()->board_type == CVMX_BOARD_TYPE_SIM) {
+		start_chip = 1;
+		stop_chip = 2;
+	} else {
+		start_chip = 0;
+		stop_chip = 8;
+	}
+
+	/* Figure out how many clocks are in one microsecond, rounding up */
+	clocks_us = CVMX_NAND_ROUNDUP(octeon_get_io_clock_rate(), 1000000);
+
+	/* If the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is set, then
+	 ** use the supplied default values to configured the chips in the
+	 ** active_chips mask */
+	if (cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE) {
+		if (cvmx_nand_default.page_size) {
+			for (chip = start_chip; chip < stop_chip; chip++) {
+				/* Skip chip selects that the caller didn't supply in the active chip bits */
+				if (((1 << chip) & active_chips) == 0)
+					continue;
+				__set_chip_defaults(chip, clocks_us);
+			}
+		}
+		CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+	}
+
+	/* Probe and see what NAND flash we can find */
+	for (chip = start_chip; chip < stop_chip; chip++) {
+		union cvmx_mio_boot_reg_cfgx mio_boot_reg_cfg;
+		cvmx_nand_onfi_param_page_t *onfi_param_page;
+		int probe_failed;
+		int width_16;
+
+		/* Skip chip selects that the caller didn't supply in the active chip bits */
+		if (((1 << chip) & active_chips) == 0)
+			continue;
+
+		mio_boot_reg_cfg.u64 = cvmx_read_csr(CVMX_MIO_BOOT_REG_CFGX(chip));
+		/* Enabled regions can't be connected to NAND flash */
+		if (mio_boot_reg_cfg.s.en)
+			continue;
+
+		/* Start out with some sane, but slow, defaults */
+		cvmx_nand_state[chip].page_size = 0;
+		cvmx_nand_state[chip].oob_size = 64;
+		cvmx_nand_state[chip].pages_per_block = 64;
+		cvmx_nand_state[chip].blocks = 100;
+
+		/* Set timing mode to ONFI mode 0 for initial accesses */
+		__set_onfi_timing_mode(cvmx_nand_state[chip].tim_par, clocks_us, 0);
+
+		/* Put the index of which timing parameter to use.  The indexes are into the tim_par
+		 ** which match the indexes of the 8 timing parameters that the hardware supports.
+		 ** Index 0 is not software controlled, and is fixed by hardware. */
+		cvmx_nand_state[chip].clen[0] = 0;	/* Command doesn't need to be held before WE */
+		cvmx_nand_state[chip].clen[1] = 1;	/* Twp, WE# pulse width */
+		cvmx_nand_state[chip].clen[2] = 3;	/* Tclh, CLE hold time */
+		cvmx_nand_state[chip].clen[3] = 1;
+
+		cvmx_nand_state[chip].alen[0] = 4;	/* Tals, ALE setup time */
+		cvmx_nand_state[chip].alen[1] = 1;	/* Twp, WE# pulse width */
+		cvmx_nand_state[chip].alen[2] = 2;	/* Twh, WE# pulse width high */
+		cvmx_nand_state[chip].alen[3] = 5;	/* Talh, ALE hold time */
+
+		cvmx_nand_state[chip].rdn[0] = 0;
+		cvmx_nand_state[chip].rdn[1] = 6;	/* Trp, RE# pulse width */
+		cvmx_nand_state[chip].rdn[2] = 7;	/* Treh, RE# high hold time */
+		cvmx_nand_state[chip].rdn[3] = 0;
+
+		cvmx_nand_state[chip].wrn[0] = 1;	/* Twp, WE# pulse width */
+		cvmx_nand_state[chip].wrn[1] = 2;	/* Twh, WE# pulse width high */
+
+		/* Probe and see if we get an answer.  Read more than required, as in
+		 ** 16 bit mode only every other byte is valid.
+		 ** Here we probe twice, once in 8 bit mode, and once in 16 bit mode to autodetect
+		 ** the width.
+		 */
+		probe_failed = 1;
+		for (width_16 = 0; width_16 <= 1 && probe_failed; width_16++) {
+			probe_failed = 0;
+
+			if (width_16)
+				cvmx_nand_state[chip].flags |= CVMX_NAND_STATE_16BIT;
+			memset(cvmx_nand_buffer, 0xff, 16);
+			if (cvmx_nand_read_id(chip, 0x0, cvmx_ptr_to_phys(cvmx_nand_buffer), 16) < 16) {
+				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+					cvmx_dprintf("%s: Failed to probe chip %d\n", __func__, chip);
+				probe_failed = 1;
+
+			}
+			if (*(uint32_t *) cvmx_nand_buffer == 0xffffffff || *(uint32_t *) cvmx_nand_buffer == 0x0) {
+				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+					cvmx_dprintf("%s: Probe returned nothing for chip %d\n", __func__, chip);
+				probe_failed = 1;
+			}
+		}
+		/* Neither 8 or 16 bit mode worked, so go on to next chip select */
+		if (probe_failed)
+			continue;
+
+		/* Save copy of ID for later use */
+		memcpy(nand_id_buffer, cvmx_nand_buffer, sizeof(nand_id_buffer));
+
+		if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+			cvmx_dprintf("%s: NAND chip %d has ID 0x%08llx\n", __func__, chip, (unsigned long long int)*(uint64_t *) cvmx_nand_buffer);
+		/* Read more than required, as in 16 bit mode only every other byte is valid. */
+		if (cvmx_nand_read_id(chip, 0x20, cvmx_ptr_to_phys(cvmx_nand_buffer), 8) < 8) {
+			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+				cvmx_dprintf("%s: Failed to probe chip %d\n", __func__, chip);
+			continue;
+		}
+
+		if (((cvmx_nand_buffer[0] == 'O') && (cvmx_nand_buffer[1] == 'N') && (cvmx_nand_buffer[2] == 'F') && (cvmx_nand_buffer[3] == 'I'))) {
+			/* We have an ONFI part, so read the parameter page */
+
+			cvmx_nand_read_param_page(chip, cvmx_ptr_to_phys(cvmx_nand_buffer), 2048);
+			onfi_param_page = __cvmx_nand_onfi_process((cvmx_nand_onfi_param_page_t *) cvmx_nand_buffer);
+			if (onfi_param_page) {
+				/* ONFI NAND parts are described by a parameter page.  Here we extract the configuration values
+				 ** from the parameter page that we need to access the chip. */
+				cvmx_nand_state[chip].page_size = cvmx_le32_to_cpu(onfi_param_page->page_data_bytes);
+				cvmx_nand_state[chip].oob_size = cvmx_le16_to_cpu(onfi_param_page->page_spare_bytes);
+				cvmx_nand_state[chip].pages_per_block = cvmx_le32_to_cpu(onfi_param_page->pages_per_block);
+				cvmx_nand_state[chip].blocks = cvmx_le32_to_cpu(onfi_param_page->blocks_per_lun) * onfi_param_page->number_lun;
+
+				if (cvmx_le16_to_cpu(onfi_param_page->timing_mode) <= 0x3f) {
+					int mode_mask = cvmx_le16_to_cpu(onfi_param_page->timing_mode);
+					int mode = 0;
+					int i;
+					for (i = 0; i < 6; i++) {
+						if (mode_mask & (1 << i))
+							mode = i;
+					}
+					cvmx_nand_state[chip].onfi_timing = mode;
+				} else {
+					cvmx_dprintf("%s: Invalid timing mode (%d) in ONFI parameter page, ignoring\n", __func__, cvmx_nand_state[chip].onfi_timing);
+					cvmx_nand_state[chip].onfi_timing = 0;
+
+				}
+				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+					cvmx_dprintf("%s: Using ONFI timing mode: %d\n", __func__, cvmx_nand_state[chip].onfi_timing);
+				__set_onfi_timing_mode(cvmx_nand_state[chip].tim_par, clocks_us, cvmx_nand_state[chip].onfi_timing);
+				if (cvmx_nand_state[chip].page_size + cvmx_nand_state[chip].oob_size > CVMX_NAND_MAX_PAGE_AND_OOB_SIZE) {
+					cvmx_dprintf("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
+						     __func__, cvmx_nand_state[chip].page_size, cvmx_nand_state[chip].oob_size, CVMX_NAND_MAX_PAGE_AND_OOB_SIZE);
+					return CVMX_NAND_ERROR;
+				}
+				/* We have completed setup for this ONFI chip, so go on to next chip. */
+				continue;
+			} else {
+				/* Parameter page is not valid */
+				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+					cvmx_dprintf("%s: ONFI paramater page missing or invalid.\n", __func__);
+
+			}
+
+		} else {
+			/* We have a non-ONFI part. */
+			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+				cvmx_dprintf("%s: Chip %d doesn't support ONFI.\n", __func__, chip);
+
+			if (nand_id_buffer[0] == 0xEC) {
+				/* We have a Samsung part, so decode part info from ID bytes */
+				uint64_t nand_size_bits = (64 * 1024 * 1024ULL) << ((nand_id_buffer[4] & 0x70) >> 4);	/* Plane size */
+				cvmx_nand_state[chip].page_size = 1024 << (nand_id_buffer[3] & 0x3);	/* NAND page size in bytes */
+				/* NAND OOB (spare) size in bytes (per page) */
+				cvmx_nand_state[chip].oob_size = (cvmx_nand_state[chip].page_size / 512) * ((nand_id_buffer[3] & 4) ? 16 : 8);
+				cvmx_nand_state[chip].pages_per_block = (0x10000 << ((nand_id_buffer[3] & 0x30) >> 4)) / cvmx_nand_state[chip].page_size;
+
+				nand_size_bits *= 1 << ((nand_id_buffer[4] & 0xc) >> 2);
+
+				cvmx_nand_state[chip].oob_size = cvmx_nand_state[chip].page_size / 64;
+				if (nand_id_buffer[3] & 0x4)
+					cvmx_nand_state[chip].oob_size *= 2;
+
+				cvmx_nand_state[chip].blocks = nand_size_bits / (8ULL * cvmx_nand_state[chip].page_size * cvmx_nand_state[chip].pages_per_block);
+				switch (nand_id_buffer[1]) {
+				case 0xD3:	/* K9F8G08U0M */
+				case 0xDC:	/* K9F4G08U0B */
+					cvmx_nand_state[chip].onfi_timing = 6;
+					break;
+				default:
+					cvmx_nand_state[chip].onfi_timing = 2;
+					break;
+				}
+
+				if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG)) {
+					cvmx_dprintf("%s: Samsung NAND chip detected, using parameters decoded from ID bytes.\n", __func__);
+					cvmx_dprintf("%s: Defaults: page size: %d, OOB size: %d, pages per block %d, part size: %d MBytes, timing mode: %d\n",
+						     __func__, cvmx_nand_state[chip].page_size, cvmx_nand_state[chip].oob_size, cvmx_nand_state[chip].pages_per_block,
+						     (int)(nand_size_bits / (8 * 1024 * 1024)), cvmx_nand_state[chip].onfi_timing);
+				}
+
+				__set_onfi_timing_mode(cvmx_nand_state[chip].tim_par, clocks_us, cvmx_nand_state[chip].onfi_timing);
+				if (cvmx_nand_state[chip].page_size + cvmx_nand_state[chip].oob_size > CVMX_NAND_MAX_PAGE_AND_OOB_SIZE) {
+					cvmx_dprintf("%s: ERROR: Page size (%d) + OOB size (%d) is greater than max size (%d)\n",
+						     __func__, cvmx_nand_state[chip].page_size, cvmx_nand_state[chip].oob_size, CVMX_NAND_MAX_PAGE_AND_OOB_SIZE);
+					return CVMX_NAND_ERROR;
+				}
+
+				/* We have completed setup for this Samsung chip, so go on to next chip. */
+				continue;
+
+			}
+
+		}
+
+		/*  We were not able to automatically identify the NAND chip parameters.  If default values were configured,
+		 ** use them. */
+		if (cvmx_nand_default.page_size) {
+			__set_chip_defaults(chip, clocks_us);
+		} else {
+
+			if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+				cvmx_dprintf("%s: Unable to determine NAND parameters, and no defaults supplied.\n", __func__);
+		}
+	}
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+EXPORT_SYMBOL(cvmx_nand_initialize);
+
+/**
+ * Call to shutdown the NAND controller after all transactions
+ * are done. In most setups this will never be called.
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+cvmx_nand_status_t cvmx_nand_shutdown(void)
+{
+	CVMX_NAND_LOG_CALLED();
+	memset(&cvmx_nand_state, 0, sizeof(cvmx_nand_state));
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+
+/**
+ * Returns a bitmask representing the chip selects that are
+ * connected to NAND chips. This can be called after the
+ * initialize to determine the actual number of NAND chips
+ * found. Each bit in the response coresponds to a chip select.
+ *
+ * Returns Zero if no NAND chips were found. Otherwise a bit is set for
+ *         each chip select (1<<chip).
+ */
+int cvmx_nand_get_active_chips(void)
+{
+	int chip;
+	int result = 0;
+	for (chip = 0; chip < 8; chip++) {
+		if (cvmx_nand_state[chip].page_size)
+			result |= 1 << chip;
+	}
+	return result;
+}
+EXPORT_SYMBOL(cvmx_nand_get_active_chips);
+
+/**
+ * Override the timing parameters for a NAND chip
+ *
+ * @chip:     Chip select to override
+ * @tim_mult:
+ * @tim_par:
+ * @clen:
+ * @alen:
+ * @rdn:
+ * @wrn:
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+cvmx_nand_status_t cvmx_nand_set_timing(int chip, int tim_mult, int tim_par[8], int clen[4], int alen[4], int rdn[4], int wrn[2])
+{
+	int i;
+	CVMX_NAND_LOG_CALLED();
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!cvmx_nand_state[chip].page_size)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	cvmx_nand_state[chip].tim_mult = tim_mult;
+	for (i = 0; i < 8; i++)
+		cvmx_nand_state[chip].tim_par[i] = tim_par[i];
+	for (i = 0; i < 4; i++)
+		cvmx_nand_state[chip].clen[i] = clen[i];
+	for (i = 0; i < 4; i++)
+		cvmx_nand_state[chip].alen[i] = alen[i];
+	for (i = 0; i < 4; i++)
+		cvmx_nand_state[chip].rdn[i] = rdn[i];
+	for (i = 0; i < 2; i++)
+		cvmx_nand_state[chip].wrn[i] = wrn[i];
+
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+
+/**
+ * @INTERNAL
+ * Get the number of free bytes in the NAND command queue
+ *
+ * Returns Number of bytes in queue
+ */
+static inline int __cvmx_nand_get_free_cmd_bytes(void)
+{
+	union cvmx_ndf_misc ndf_misc;
+	CVMX_NAND_LOG_CALLED();
+	ndf_misc.u64 = cvmx_read_csr(CVMX_NDF_MISC);
+	CVMX_NAND_RETURN((int)ndf_misc.s.fr_byt);
+}
+
+/**
+ * Submit a command to the NAND command queue. Generally this
+ * will not be used directly. Instead most programs will use the other
+ * higher level NAND functions.
+ *
+ * @cmd:    Command to submit
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+cvmx_nand_status_t cvmx_nand_submit(cvmx_nand_cmd_t cmd)
+{
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) cmd.u64[0]);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) cmd.u64[1]);
+	CVMX_NAND_LOG_PARAM("%s", cvmx_nand_opcode_labels[cmd.s.op_code]);
+	switch (cmd.s.op_code) {
+		/* All these commands fit in one 64bit word */
+	case 0:		/* NOP */
+	case 1:		/* Timing */
+	case 2:		/* WAIT */
+	case 3:		/* Chip Enable/Disable */
+	case 4:		/* CLE */
+	case 8:		/* Write */
+	case 9:		/* Read */
+	case 10:		/* Read EDO */
+	case 15:		/* Bus Aquire/Release */
+		if (__cvmx_nand_get_free_cmd_bytes() < 8)
+			CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+		cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
+		CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+
+	case 5:		/* ALE commands take either one or two 64bit words */
+		if (cmd.ale.adr_byte_num < 5) {
+			if (__cvmx_nand_get_free_cmd_bytes() < 8)
+				CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+			cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
+			CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+		} else {
+			if (__cvmx_nand_get_free_cmd_bytes() < 16)
+				CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+			cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
+			cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[0]);
+			CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+		}
+
+	case 11:		/* Wait status commands take two 64bit words */
+		if (__cvmx_nand_get_free_cmd_bytes() < 16)
+			CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+		cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[1]);
+		cvmx_write_csr(CVMX_NDF_CMD, cmd.u64[0]);
+		CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+
+	default:
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	}
+}
+
+/**
+ * @INTERNAL
+ * Get the number of bits required to encode the column bits. This
+ * does not include padding to align on a byte boundary.
+ *
+ * @chip:   NAND chip to get data for
+ *
+ * Returns Number of column bits
+ */
+static inline int __cvmx_nand_get_column_bits(int chip)
+{
+	return cvmx_pop(cvmx_nand_state[chip].page_size - 1);
+}
+
+/**
+ * @INTERNAL
+ * Get the number of bits required to encode the row bits. This
+ * does not include padding to align on a byte boundary.
+ *
+ * @chip:   NAND chip to get data for
+ *
+ * Returns Number of row bits
+ */
+static inline int __cvmx_nand_get_row_bits(int chip)
+{
+	return cvmx_pop(cvmx_nand_state[chip].blocks - 1) + cvmx_pop(cvmx_nand_state[chip].pages_per_block - 1);
+}
+
+/**
+ * @INTERNAL
+ * Get the number of address cycles required for this NAND part.
+ * This include column bits, padding, page bits, and block bits.
+ *
+ * @chip:   NAND chip to get data for
+ *
+ * Returns Number of address cycles on the bus
+ */
+static inline int __cvmx_nand_get_address_cycles(int chip)
+{
+	int address_bits = ((__cvmx_nand_get_column_bits(chip) + 7) >> 3) << 3;
+	address_bits += ((__cvmx_nand_get_row_bits(chip) + 7) >> 3) << 3;
+	return (address_bits + 7) >> 3;
+}
+
+/**
+ * @INTERNAL
+ * Build the set of command common to most transactions
+ * @chip:      NAND chip to program
+ * @cmd_data:  NAND command for CLE cycle 1
+ * @num_address_cycles:
+ *                  Number of address cycles to put on the bus
+ * @nand_address:
+ *                  Data to be put on the bus. It is translated according to
+ *                  the rules in the file information section.
+ *
+ * @cmd_data2: If non zero, adds a second CLE cycle used by a number of NAND
+ *                  transactions.
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+static inline cvmx_nand_status_t __cvmx_nand_build_pre_cmd(int chip, int cmd_data, int num_address_cycles, uint64_t nand_address, int cmd_data2)
+{
+	cvmx_nand_status_t result;
+	cvmx_nand_cmd_t cmd;
+
+	CVMX_NAND_LOG_CALLED();
+
+	/* Send timing parameters */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.set_tm_par.one = 1;
+	cmd.set_tm_par.tim_mult = cvmx_nand_state[chip].tim_mult;
+	/* tim_par[0] unused */
+	cmd.set_tm_par.tim_par1 = cvmx_nand_state[chip].tim_par[1];
+	cmd.set_tm_par.tim_par2 = cvmx_nand_state[chip].tim_par[2];
+	cmd.set_tm_par.tim_par3 = cvmx_nand_state[chip].tim_par[3];
+	cmd.set_tm_par.tim_par4 = cvmx_nand_state[chip].tim_par[4];
+	cmd.set_tm_par.tim_par5 = cvmx_nand_state[chip].tim_par[5];
+	cmd.set_tm_par.tim_par6 = cvmx_nand_state[chip].tim_par[6];
+	cmd.set_tm_par.tim_par7 = cvmx_nand_state[chip].tim_par[7];
+	result = cvmx_nand_submit(cmd);
+	if (result)
+		CVMX_NAND_RETURN(result);
+
+	/* Send bus select */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.bus_acq.fifteen = 15;
+	cmd.bus_acq.one = 1;
+	result = cvmx_nand_submit(cmd);
+	if (result)
+		CVMX_NAND_RETURN(result);
+
+	/* Send chip select */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.chip_en.chip = chip;
+	cmd.chip_en.one = 1;
+	cmd.chip_en.three = 3;
+	cmd.chip_en.width = (cvmx_nand_state[chip].flags & CVMX_NAND_STATE_16BIT) ? 2 : 1;
+	result = cvmx_nand_submit(cmd);
+	if (result)
+		CVMX_NAND_RETURN(result);
+
+	/* Send wait, fixed time
+	 ** This meets chip enable to command latch enable timing.
+	 ** This is tCS - tCLS from the ONFI spec.
+	 ** Use tWP as a proxy, as this is adequate for
+	 ** all ONFI 1.0 timing modes. */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.wait.two = 2;
+	cmd.wait.n = 1;
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* Send CLE */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.cle.cmd_data = cmd_data;
+	cmd.cle.clen1 = cvmx_nand_state[chip].clen[0];
+	cmd.cle.clen2 = cvmx_nand_state[chip].clen[1];
+	cmd.cle.clen3 = cvmx_nand_state[chip].clen[2];
+	cmd.cle.four = 4;
+	result = cvmx_nand_submit(cmd);
+	if (result)
+		CVMX_NAND_RETURN(result);
+
+	/* Send ALE */
+	if (num_address_cycles) {
+		memset(&cmd, 0, sizeof(cmd));
+		cmd.ale.adr_byte_num = num_address_cycles;
+		if (num_address_cycles < __cvmx_nand_get_address_cycles(chip)) {
+			cmd.ale.adr_bytes_l = nand_address;
+			cmd.ale.adr_bytes_h = nand_address >> 32;
+		} else {
+			int column_bits = __cvmx_nand_get_column_bits(chip);
+			int column_shift = ((column_bits + 7) >> 3) << 3;
+			int column = nand_address & (cvmx_nand_state[chip].page_size - 1);
+			int row = nand_address >> column_bits;
+			cmd.ale.adr_bytes_l = column + (row << column_shift);
+			cmd.ale.adr_bytes_h = row >> (32 - column_shift);
+		}
+		cmd.ale.alen1 = cvmx_nand_state[chip].alen[0];
+		cmd.ale.alen2 = cvmx_nand_state[chip].alen[1];
+		cmd.ale.alen3 = cvmx_nand_state[chip].alen[2];
+		cmd.ale.alen4 = cvmx_nand_state[chip].alen[3];
+		cmd.ale.five = 5;
+		result = cvmx_nand_submit(cmd);
+		if (result)
+			CVMX_NAND_RETURN(result);
+	}
+
+	/* Send CLE 2 */
+	if (cmd_data2) {
+		memset(&cmd, 0, sizeof(cmd));
+		cmd.cle.cmd_data = cmd_data2;
+		cmd.cle.clen1 = cvmx_nand_state[chip].clen[0];
+		cmd.cle.clen2 = cvmx_nand_state[chip].clen[1];
+		cmd.cle.clen3 = cvmx_nand_state[chip].clen[2];
+		cmd.cle.four = 4;
+		result = cvmx_nand_submit(cmd);
+		if (result)
+			CVMX_NAND_RETURN(result);
+	}
+
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+
+/**
+ * @INTERNAL
+ * Build the set of command common to most transactions
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+static inline cvmx_nand_status_t __cvmx_nand_build_post_cmd(void)
+{
+	cvmx_nand_status_t result;
+	cvmx_nand_cmd_t cmd;
+
+	CVMX_NAND_LOG_CALLED();
+
+	/* Send chip deselect */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.chip_dis.three = 3;
+	result = cvmx_nand_submit(cmd);
+	if (result)
+		CVMX_NAND_RETURN(result);
+
+	/* Send bus release */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.bus_rel.fifteen = 15;
+	result = cvmx_nand_submit(cmd);
+	if (result)
+		CVMX_NAND_RETURN(result);
+
+	/* Ring the doorbell */
+	cvmx_write_csr(CVMX_NDF_DRBELL, 1);
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+
+/**
+ * @INTERNAL
+ * Setup the NAND DMA engine for a transfer
+ *
+ * @chip:     Chip select for NAND flash
+ * @is_write: Non zero if this is a write
+ * @buffer_address:
+ *                 Physical memory address to DMA to/from
+ * @buffer_length:
+ *                 Length of the DMA in bytes
+ */
+static inline void __cvmx_nand_setup_dma(int chip, int is_write, uint64_t buffer_address, int buffer_length)
+{
+	union cvmx_mio_ndf_dma_cfg ndf_dma_cfg;
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+	CVMX_NAND_LOG_PARAM("%d", is_write);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) buffer_address);
+	CVMX_NAND_LOG_PARAM("%d", buffer_length);
+	ndf_dma_cfg.u64 = 0;
+	ndf_dma_cfg.s.en = 1;
+	ndf_dma_cfg.s.rw = is_write;	/* One means DMA reads from memory and writes to flash */
+	ndf_dma_cfg.s.clr = 0;
+	ndf_dma_cfg.s.size = ((buffer_length + 7) >> 3) - 1;
+	ndf_dma_cfg.s.adr = buffer_address;
+	CVMX_SYNCWS;
+	cvmx_write_csr(CVMX_MIO_NDF_DMA_CFG, ndf_dma_cfg.u64);
+	CVMX_NAND_RETURN_NOTHING();
+}
+
+/**
+ * Dump a buffer out in hex for debug
+ *
+ * @buffer_address:
+ *               Starting physical address
+ * @buffer_length:
+ *               Number of bytes to display
+ */
+static void __cvmx_nand_hex_dump(uint64_t buffer_address, int buffer_length)
+{
+	uint8_t *buffer = cvmx_phys_to_ptr(buffer_address);
+	int offset = 0;
+	while (offset < buffer_length) {
+		int i;
+		cvmx_dprintf("%*s%04x:", 2 * debug_indent, "", offset);
+		for (i = 0; i < 32; i++) {
+			if ((i & 3) == 0)
+				cvmx_dprintf(" ");
+			if (offset + i < buffer_length)
+				cvmx_dprintf("%02x", 0xff & buffer[offset + i]);
+			else
+				cvmx_dprintf("  ");
+		}
+		cvmx_dprintf("\n");
+		offset += 32;
+	}
+}
+
+/**
+ * @INTERNAL
+ * Perform a low level NAND read command
+ *
+ * @chip:   Chip to read from
+ * @nand_command1:
+ *               First command cycle value
+ * @address_cycles:
+ *               Number of address cycles after comand 1
+ * @nand_address:
+ *               NAND address to use for address cycles
+ * @nand_command2:
+ *               NAND command cycle 2 if not zero
+ * @buffer_address:
+ *               Physical address to DMA into
+ * @buffer_length:
+ *               Length of the transfer in bytes
+ *
+ * Returns Number of bytes transfered or a negative error code
+ */
+static inline int __cvmx_nand_low_level_read(int chip, int nand_command1, int address_cycles, uint64_t nand_address, int nand_command2, uint64_t buffer_address, int buffer_length)
+{
+	cvmx_nand_cmd_t cmd;
+	union cvmx_mio_ndf_dma_cfg ndf_dma_cfg;
+	int bytes;
+
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+	CVMX_NAND_LOG_PARAM("0x%x", nand_command1);
+	CVMX_NAND_LOG_PARAM("%d", address_cycles);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) nand_address);
+	CVMX_NAND_LOG_PARAM("0x%x", nand_command2);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) buffer_address);
+	CVMX_NAND_LOG_PARAM("%d", buffer_length);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_address)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (buffer_address & 7)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (buffer_length & 7)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_length)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	/* Build the command and address cycles */
+	if (__cvmx_nand_build_pre_cmd(chip, nand_command1, address_cycles, nand_address, nand_command2))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* Send WAIT.  This waits for some time, then
+	 ** waits for busy to be de-asserted. */
+	if (__wait_for_busy_done(chip))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* Wait for tRR after busy de-asserts.
+	 ** Use 2* tALS as proxy.  This is overkill in
+	 ** the slow modes, but not bad in the faster ones. */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.wait.two = 2;
+	cmd.wait.n = 4;
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* Send READ */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.rd.data_bytes = buffer_length;
+	if (cvmx_nand_state[chip].onfi_timing >= 4)
+		cmd.rd.nine = 10;	/* READ_EDO command is required for ONFI timing modes 4 and 5 */
+	else
+		cmd.rd.nine = 9;
+	cmd.rd.rdn1 = cvmx_nand_state[chip].rdn[0];
+	cmd.rd.rdn2 = cvmx_nand_state[chip].rdn[1];
+	cmd.rd.rdn3 = cvmx_nand_state[chip].rdn[2];
+	cmd.rd.rdn4 = cvmx_nand_state[chip].rdn[3];
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	__cvmx_nand_setup_dma(chip, 0, buffer_address, buffer_length);
+
+	if (__cvmx_nand_build_post_cmd())
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+	WATCHDOG_RESET();
+	/* Wait for the DMA to complete */
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_NDF_DMA_CFG, union cvmx_mio_ndf_dma_cfg, en, ==, 0, NAND_TIMEOUT_USECS_READ)) {
+		WATCHDOG_RESET();
+		CVMX_NAND_RETURN(CVMX_NAND_TIMEOUT);
+	}
+	/* Return the number of bytes transfered */
+	ndf_dma_cfg.u64 = cvmx_read_csr(CVMX_MIO_NDF_DMA_CFG);
+	bytes = ndf_dma_cfg.s.adr - buffer_address;
+
+	if (cvmx_unlikely(cvmx_nand_flags & CVMX_NAND_INITIALIZE_FLAGS_DEBUG))
+		__cvmx_nand_hex_dump(buffer_address, bytes);
+
+	CVMX_NAND_RETURN(bytes);
+}
+
+/**
+ * Read a page from NAND. If the buffer has room, the out of band
+ * data will be included.
+ *
+ * @chip:   Chip select for NAND flash
+ * @nand_address:
+ *               Location in NAND to read. See description in file comment
+ * @buffer_address:
+ *               Physical address to store the result at
+ * @buffer_length:
+ *               Number of bytes to read
+ *
+ * Returns Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ */
+int cvmx_nand_page_read(int chip, uint64_t nand_address, uint64_t buffer_address, int buffer_length)
+{
+	int bytes;
+
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) nand_address);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) buffer_address);
+	CVMX_NAND_LOG_PARAM("%d", buffer_length);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!cvmx_nand_state[chip].page_size)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_address)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (buffer_address & 7)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (buffer_length & 7)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_length)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	/* For 16 bit mode, addresses within a page are word address, rather than byte addresses */
+	if (cvmx_nand_state[chip].flags & CVMX_NAND_STATE_16BIT)
+		nand_address = (nand_address & ~(cvmx_nand_state[chip].page_size - 1)) | ((nand_address & (cvmx_nand_state[chip].page_size - 1)) >> 1);
+
+	bytes = __cvmx_nand_low_level_read(chip, NAND_COMMAND_READ, __cvmx_nand_get_address_cycles(chip), nand_address, NAND_COMMAND_READ_FIN, buffer_address, buffer_length);
+	CVMX_NAND_RETURN(bytes);
+}
+
+EXPORT_SYMBOL(cvmx_nand_page_read);
+
+/**
+ * Write a page to NAND. The buffer must contain the entire page
+ * including the out of band data.
+ *
+ * @chip:   Chip select for NAND flash
+ * @nand_address:
+ *               Location in NAND to write. See description in file comment
+ * @buffer_address:
+ *               Physical address to read the data from
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address, uint64_t buffer_address)
+{
+	cvmx_nand_cmd_t cmd;
+	int buffer_length;
+
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) nand_address);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) buffer_address);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!cvmx_nand_state[chip].page_size)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_address)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (buffer_address & 7)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	/* For 16 bit mode, addresses within a page are word address, rather than byte addresses */
+	if (cvmx_nand_state[chip].flags & CVMX_NAND_STATE_16BIT)
+		nand_address = (nand_address & ~(cvmx_nand_state[chip].page_size - 1)) | ((nand_address & (cvmx_nand_state[chip].page_size - 1)) >> 1);
+
+	buffer_length = cvmx_nand_state[chip].page_size + cvmx_nand_state[chip].oob_size;
+
+	/* The NAND DMA engine always does transfers in 8 byte blocks, so round the buffer size down
+	 ** to a multiple of 8, otherwise we will transfer too much data to the NAND chip.
+	 ** Note this prevents the last few bytes of the OOB being written.  If these bytes
+	 ** need to be written, then this check needs to be removed, but this will result in
+	 ** extra write cycles beyond the end of the OOB. */
+	buffer_length &= ~0x7;
+
+	/* Build the command and address cycles */
+	if (__cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_PROGRAM, __cvmx_nand_get_address_cycles(chip), nand_address, 0))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* Send WRITE */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.wr.data_bytes = buffer_length;
+	cmd.wr.eight = 8;
+	cmd.wr.wrn1 = cvmx_nand_state[chip].wrn[0];
+	cmd.wr.wrn2 = cvmx_nand_state[chip].wrn[1];
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* Send WRITE command */
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.cle.cmd_data = NAND_COMMAND_PROGRAM_FIN;
+	cmd.cle.clen1 = cvmx_nand_state[chip].clen[0];
+	cmd.cle.clen2 = cvmx_nand_state[chip].clen[1];
+	cmd.cle.clen3 = cvmx_nand_state[chip].clen[2];
+	cmd.cle.four = 4;
+	if (cvmx_nand_submit(cmd))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	__cvmx_nand_setup_dma(chip, 1, buffer_address, buffer_length);
+
+	/* WAIT for R_B to signal program is complete  */
+	if (__wait_for_busy_done(chip))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	if (__cvmx_nand_build_post_cmd())
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* Wait for the DMA to complete */
+	WATCHDOG_RESET();
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_MIO_NDF_DMA_CFG, union cvmx_mio_ndf_dma_cfg, en, ==, 0, NAND_TIMEOUT_USECS_WRITE)) {
+		WATCHDOG_RESET();
+		CVMX_NAND_RETURN(CVMX_NAND_TIMEOUT);
+	}
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+EXPORT_SYMBOL(cvmx_nand_page_write);
+
+/**
+ * Erase a NAND block. A single block contains multiple pages.
+ *
+ * @chip:   Chip select for NAND flash
+ * @nand_address:
+ *               Location in NAND to erase. See description in file comment
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+cvmx_nand_status_t cvmx_nand_block_erase(int chip, uint64_t nand_address)
+{
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) nand_address);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!cvmx_nand_state[chip].page_size)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	/* Build the command and address cycles */
+	if (__cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_ERASE,
+				      (__cvmx_nand_get_row_bits(chip) + 7) >> 3, nand_address >> __cvmx_nand_get_column_bits(chip), NAND_COMMAND_ERASE_FIN))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* WAIT for R_B to signal erase is complete  */
+	if (__wait_for_busy_done(chip))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	if (__cvmx_nand_build_post_cmd())
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* Wait for the command queue to be idle, which means the wait is done */
+	WATCHDOG_RESET();
+	if (CVMX_WAIT_FOR_FIELD64(CVMX_NDF_ST_REG, union cvmx_ndf_st_reg, exe_idle, ==, 1, NAND_TIMEOUT_USECS_BLOCK_ERASE)) {
+		WATCHDOG_RESET();
+		CVMX_NAND_RETURN(CVMX_NAND_TIMEOUT);
+	}
+
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+EXPORT_SYMBOL(cvmx_nand_block_erase);
+
+/* Some reads (read ID, read parameter page) only use the low 8 bits of the bus
+** in 16 bit mode.  We remove the unused bytes so that the data we present to the
+** caller is as expected (same as 8 bit mode.)
+*/
+static void __cvmx_nand_fixup_16bit_id_reads(uint8_t *buf, int buffer_length)
+{
+	/* Decimate data, taking only every other byte. */
+	int i;
+	for (i = 0; i < buffer_length / 2; i++)
+		buf[i] = buf[2 * i + 1];
+}
+
+/**
+ * Read the NAND ID information
+ *
+ * @chip:   Chip select for NAND flash
+ * @nand_address:
+ *               NAND address to read ID from. Usually this is either 0x0 or 0x20.
+ * @buffer_address:
+ *               Physical address to store data in
+ * @buffer_length:
+ *               Length of the buffer. Usually this is 4-8 bytes.  For 16 bit mode, this must be twice
+ *               as large as the actual expected data.
+ *
+ * Returns Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ */
+int cvmx_nand_read_id(int chip, uint64_t nand_address, uint64_t buffer_address, int buffer_length)
+{
+	int bytes;
+
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) nand_address);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) buffer_address);
+	CVMX_NAND_LOG_PARAM("%d", buffer_length);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_address)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (buffer_address & 7)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_length)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	bytes = __cvmx_nand_low_level_read(chip, NAND_COMMAND_READ_ID, 1, nand_address, 0, buffer_address, buffer_length);
+	if (cvmx_nand_state[chip].flags & CVMX_NAND_STATE_16BIT)
+		__cvmx_nand_fixup_16bit_id_reads(cvmx_phys_to_ptr(buffer_address), buffer_length);
+
+	CVMX_NAND_RETURN(bytes);
+}
+
+EXPORT_SYMBOL(cvmx_nand_read_id);
+
+/**
+ * Read the NAND parameter page
+ *
+ * @chip:   Chip select for NAND flash
+ * @buffer_address:
+ *               Physical address to store data in
+ * @buffer_length:
+ *               Length of the buffer.  Usually 1024 bytes for 8 bit, 2048 for 16 bit mode.
+ *
+ * Returns Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ */
+int cvmx_nand_read_param_page(int chip, uint64_t buffer_address, int buffer_length)
+{
+	int bytes;
+
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+	CVMX_NAND_LOG_PARAM("0x%llx", (ULL) buffer_address);
+	CVMX_NAND_LOG_PARAM("%d", buffer_length);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_address)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (buffer_address & 7)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (buffer_length & 7)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!buffer_length)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	bytes = __cvmx_nand_low_level_read(chip, NAND_COMMAND_READ_PARAM_PAGE, 1, 0x0, 0, buffer_address, buffer_length);
+	if (cvmx_nand_state[chip].flags & CVMX_NAND_STATE_16BIT)
+		__cvmx_nand_fixup_16bit_id_reads(cvmx_phys_to_ptr(buffer_address), buffer_length);
+	CVMX_NAND_RETURN(bytes);
+}
+
+/**
+ * Get the status of the NAND flash
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns NAND status or a negative cvmx_nand_status_t error code on failure
+ */
+int cvmx_nand_get_status(int chip)
+{
+	int status;
+	int offset = !!(cvmx_nand_state[chip].flags & CVMX_NAND_STATE_16BIT);	/* Normalize flag to 0/1 */
+
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	*((uint8_t *) cvmx_nand_buffer + offset) = 0xff;
+	status = __cvmx_nand_low_level_read(chip, NAND_COMMAND_STATUS, 0, 0, 0, cvmx_ptr_to_phys(cvmx_nand_buffer), 8);
+	if (status > 0)
+		status = *((uint8_t *) cvmx_nand_buffer + offset);
+
+	CVMX_NAND_RETURN(status);
+}
+EXPORT_SYMBOL(cvmx_nand_get_status);
+
+/**
+ * Get the page size, excluding out of band data. This  function
+ * will return zero for chip selects not connected to NAND.
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns Page size in bytes or a negative cvmx_nand_status_t error code on failure
+ */
+int cvmx_nand_get_page_size(int chip)
+{
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	CVMX_NAND_RETURN(cvmx_nand_state[chip].page_size);
+}
+
+/**
+ * Get the OOB size.
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns OOB in bytes or a negative cvmx_nand_status_t error code on failure
+ */
+int cvmx_nand_get_oob_size(int chip)
+{
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	CVMX_NAND_RETURN(cvmx_nand_state[chip].oob_size);
+}
+
+/**
+ * Get the number of pages per NAND block
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns Number of pages in each block or a negative cvmx_nand_status_t error
+ *         code on failure
+ */
+int cvmx_nand_get_pages_per_block(int chip)
+{
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	CVMX_NAND_RETURN(cvmx_nand_state[chip].pages_per_block);
+}
+
+/**
+ * Get the number of blocks in the NAND flash
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns Number of blocks or a negative cvmx_nand_status_t error code on failure
+ */
+int cvmx_nand_get_blocks(int chip)
+{
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	CVMX_NAND_RETURN(cvmx_nand_state[chip].blocks);
+}
+
+/**
+ * Reset the NAND flash
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+cvmx_nand_status_t cvmx_nand_reset(int chip)
+{
+	CVMX_NAND_LOG_CALLED();
+	CVMX_NAND_LOG_PARAM("%d", chip);
+
+	if ((chip < 0) || (chip > 7))
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+	if (!cvmx_nand_state[chip].page_size)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	if (__cvmx_nand_build_pre_cmd(chip, NAND_COMMAND_RESET, 0, 0, 0))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	/* WAIT for R_B to signal reset is complete  */
+	if (__wait_for_busy_done(chip))
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	if (__cvmx_nand_build_post_cmd())
+		CVMX_NAND_RETURN(CVMX_NAND_NO_MEMORY);
+
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
+EXPORT_SYMBOL(cvmx_nand_reset);
+
+/**
+ * This function computes the Octeon specific ECC data used by the NAND boot
+ * feature.
+ *
+ * @block:  pointer to 256 bytes of data
+ * @eccp:   pointer to where 8 bytes of ECC data will be stored
+ */
+void cvmx_nand_compute_boot_ecc(unsigned char *block, unsigned char *eccp)
+{
+	unsigned char pd0, pd1, pd2;
+	int i, j;
+
+	pd0 = pd1 = pd2 = 0;
+
+	for (i = 0; i < 256; i++)	/* PD0<0> */
+		pd0 ^= (block[i] ^ (block[i] >> 2) ^ (block[i] >> 4) ^ (block[i] >> 6)) & 1;
+	for (i = 0; i < 256; i++)	/* PD0<1> */
+		pd0 ^= ((block[i] ^ (block[i] >> 1) ^ (block[i] >> 4) ^ (block[i] >> 5)) & 1) << 1;
+	for (i = 0; i < 256; i++)	/* PD0<2> */
+		pd0 ^= ((block[i] ^ (block[i] >> 1) ^ (block[i] >> 2) ^ (block[i] >> 3)) & 1) << 2;
+	for (i = 0; i < 128; i++)	/* PD0<3> */
+		pd0 ^= ((block[2 * i] ^ (block[2 * i] >> 1) ^ (block[2 * i] >> 2) ^
+			 (block[2 * i] >> 3) ^ (block[2 * i] >> 4) ^ (block[2 * i] >> 5) ^ (block[2 * i] >> 6) ^ (block[2 * i] >> 7)) & 1) << 3;
+	for (i = 0; i < 64; i++)	/* PD0<4> */
+		for (j = 0; j < 2; j++)
+			pd0 ^= ((block[4 * i + j] ^ (block[4 * i + j] >> 1) ^ (block[4 * i + j] >> 2) ^
+				 (block[4 * i + j] >> 3) ^ (block[4 * i + j] >> 4) ^ (block[4 * i + j] >> 5) ^ (block[4 * i + j] >> 6) ^ (block[4 * i + j] >> 7)) & 1) << 4;
+	for (i = 0; i < 32; i++)	/* PD0<5> */
+		for (j = 0; j < 4; j++)
+			pd0 ^= ((block[8 * i + j] ^ (block[8 * i + j] >> 1) ^ (block[8 * i + j] >> 2) ^
+				 (block[8 * i + j] >> 3) ^ (block[8 * i + j] >> 4) ^ (block[8 * i + j] >> 5) ^ (block[8 * i + j] >> 6) ^ (block[8 * i + j] >> 7)) & 1) << 5;
+	for (i = 0; i < 16; i++)	/* PD0<6> */
+		for (j = 0; j < 8; j++)
+			pd0 ^= ((block[16 * i + j] ^ (block[16 * i + j] >> 1) ^ (block[16 * i + j] >> 2) ^
+				 (block[16 * i + j] >> 3) ^ (block[16 * i + j] >> 4) ^ (block[16 * i + j] >> 5) ^ (block[16 * i + j] >> 6) ^ (block[16 * i + j] >> 7)) & 1) << 6;
+	for (i = 0; i < 8; i++)	/* PD0<7> */
+		for (j = 0; j < 16; j++)
+			pd0 ^= ((block[32 * i + j] ^ (block[32 * i + j] >> 1) ^ (block[32 * i + j] >> 2) ^
+				 (block[32 * i + j] >> 3) ^ (block[32 * i + j] >> 4) ^ (block[32 * i + j] >> 5) ^ (block[32 * i + j] >> 6) ^ (block[32 * i + j] >> 7)) & 1) << 7;
+	for (i = 0; i < 4; i++)	/* PD1<0> */
+		for (j = 0; j < 32; j++)
+			pd1 ^= ((block[64 * i + j] ^ (block[64 * i + j] >> 1) ^ (block[64 * i + j] >> 2) ^
+				 (block[64 * i + j] >> 3) ^ (block[64 * i + j] >> 4) ^ (block[64 * i + j] >> 5) ^ (block[64 * i + j] >> 6) ^ (block[64 * i + j] >> 7)) & 1) << 0;
+	for (i = 0; i < 2; i++)	/* PD1<1> */
+		for (j = 0; j < 64; j++)
+			pd1 ^= ((block[128 * i + j] ^ (block[128 * i + j] >> 1) ^ (block[128 * i + j] >> 2) ^
+				 (block[128 * i + j] >> 3) ^ (block[128 * i + j] >> 4) ^ (block[128 * i + j] >> 5) ^
+				 (block[128 * i + j] >> 6) ^ (block[128 * i + j] >> 7)) & 1) << 1;
+	for (i = 0; i < 128; i++)	/* PD1<2> */
+		pd1 ^= ((block[i] ^ (block[i] >> 1) ^ (block[i] >> 2) ^ (block[i] >> 3) ^ (block[i] >> 4) ^ (block[i] >> 5) ^ (block[i] >> 6) ^ (block[i] >> 7)) & 1) << 2;
+	/* PD1<3> */
+	/* PD1<4> */
+	for (i = 0; i < 256; i++)	/* PD1<5> */
+		pd1 ^= (((block[i] >> 1) ^ (block[i] >> 3) ^ (block[i] >> 5) ^ (block[i] >> 7)) & 1) << 5;
+	for (i = 0; i < 256; i++)	/* PD1<6> */
+		pd1 ^= (((block[i] >> 2) ^ (block[i] >> 3) ^ (block[i] >> 6) ^ (block[i] >> 7)) & 1) << 6;
+	for (i = 0; i < 256; i++)	/* PD1<7> */
+		pd1 ^= (((block[i] >> 4) ^ (block[i] >> 5) ^ (block[i] >> 6) ^ (block[i] >> 7)) & 1) << 7;
+	for (i = 0; i < 128; i++)	/* PD2<0> */
+		pd2 ^= ((block[2 * i + 1] ^ (block[2 * i + 1] >> 1) ^ (block[2 * i + 1] >> 2) ^
+			 (block[2 * i + 1] >> 3) ^ (block[2 * i + 1] >> 4) ^ (block[2 * i + 1] >> 5) ^ (block[2 * i + 1] >> 6) ^ (block[2 * i + 1] >> 7)) & 1) << 0;
+	for (i = 0; i < 64; i++)	/* PD2<1> */
+		for (j = 2; j < 4; j++)
+			pd2 ^= ((block[4 * i + j] ^ (block[4 * i + j] >> 1) ^ (block[4 * i + j] >> 2) ^
+				 (block[4 * i + j] >> 3) ^ (block[4 * i + j] >> 4) ^ (block[4 * i + j] >> 5) ^ (block[4 * i + j] >> 6) ^ (block[4 * i + j] >> 7)) & 1) << 1;
+	for (i = 0; i < 32; i++)	/* PD2<2> */
+		for (j = 4; j < 8; j++)
+			pd2 ^= ((block[8 * i + j] ^ (block[8 * i + j] >> 1) ^ (block[8 * i + j] >> 2) ^
+				 (block[8 * i + j] >> 3) ^ (block[8 * i + j] >> 4) ^ (block[8 * i + j] >> 5) ^ (block[8 * i + j] >> 6) ^ (block[8 * i + j] >> 7)) & 1) << 2;
+	for (i = 0; i < 16; i++)	/* PD2<3> */
+		for (j = 8; j < 16; j++)
+			pd2 ^= ((block[16 * i + j] ^ (block[16 * i + j] >> 1) ^ (block[16 * i + j] >> 2) ^
+				 (block[16 * i + j] >> 3) ^ (block[16 * i + j] >> 4) ^ (block[16 * i + j] >> 5) ^ (block[16 * i + j] >> 6) ^ (block[16 * i + j] >> 7)) & 1) << 3;
+	for (i = 0; i < 8; i++)	/* PD2<4> */
+		for (j = 16; j < 32; j++)
+			pd2 ^= ((block[32 * i + j] ^ (block[32 * i + j] >> 1) ^ (block[32 * i + j] >> 2) ^
+				 (block[32 * i + j] >> 3) ^ (block[32 * i + j] >> 4) ^ (block[32 * i + j] >> 5) ^ (block[32 * i + j] >> 6) ^ (block[32 * i + j] >> 7)) & 1) << 4;
+	for (i = 0; i < 4; i++)	/* PD2<5> */
+		for (j = 32; j < 64; j++)
+			pd2 ^= ((block[64 * i + j] ^ (block[64 * i + j] >> 1) ^ (block[64 * i + j] >> 2) ^
+				 (block[64 * i + j] >> 3) ^ (block[64 * i + j] >> 4) ^ (block[64 * i + j] >> 5) ^ (block[64 * i + j] >> 6) ^ (block[64 * i + j] >> 7)) & 1) << 5;
+	for (i = 0; i < 2; i++)	/* PD2<6> */
+		for (j = 64; j < 128; j++)
+			pd2 ^= ((block[128 * i + j] ^ (block[128 * i + j] >> 1) ^ (block[128 * i + j] >> 2) ^
+				 (block[128 * i + j] >> 3) ^ (block[128 * i + j] >> 4) ^ (block[128 * i + j] >> 5) ^
+				 (block[128 * i + j] >> 6) ^ (block[128 * i + j] >> 7)) & 1) << 6;
+	for (i = 128; i < 256; i++)	/* PD2<7> */
+		pd2 ^= ((block[i] ^ (block[i] >> 1) ^ (block[i] >> 2) ^ (block[i] >> 3) ^ (block[i] >> 4) ^ (block[i] >> 5) ^ (block[i] >> 6) ^ (block[i] >> 7)) & 1) << 7;
+
+	eccp[0] = pd0;
+	eccp[1] = pd1;
+	eccp[2] = pd2;
+}
+
+/**
+ * Check an Octeon ECC block, fixing errors if possible
+ *
+ * @block:  Pointer to block to check
+ *
+ * Returns Zero if block has no errors, one if errors were corrected, two
+ *         if the errors could not be corrected.
+ */
+int cvmx_nand_correct_boot_ecc(uint8_t *block)
+{
+	unsigned char pd0, pd1, pd2;
+	int i, j;
+	unsigned char xorpd0, xorpd1, xorpd2;
+	int xor_num;
+	unsigned int check;
+
+	asm volatile ("pref 0,0(%0);pref 0,128(%0);pref 0,256(%0)\n"::"r" (block));
+
+	pd0 = pd1 = pd2 = 0;
+
+	for (i = 0; i < 256; i++)	/* PD0<0> */
+		pd0 ^= (block[i] ^ (block[i] >> 2) ^ (block[i] >> 4) ^ (block[i] >> 6)) & 1;
+	for (i = 0; i < 256; i++)	/* PD0<1> */
+		pd0 ^= ((block[i] ^ (block[i] >> 1) ^ (block[i] >> 4) ^ (block[i] >> 5)) & 1) << 1;
+	for (i = 0; i < 256; i++)	/* PD0<2> */
+		pd0 ^= ((block[i] ^ (block[i] >> 1) ^ (block[i] >> 2) ^ (block[i] >> 3)) & 1) << 2;
+	for (i = 0; i < 128; i++)	/* PD0<3> */
+		pd0 ^= ((block[2 * i] ^ (block[2 * i] >> 1) ^ (block[2 * i] >> 2) ^
+			 (block[2 * i] >> 3) ^ (block[2 * i] >> 4) ^ (block[2 * i] >> 5) ^ (block[2 * i] >> 6) ^ (block[2 * i] >> 7)) & 1) << 3;
+	for (i = 0; i < 64; i++)	/* PD0<4> */
+		for (j = 0; j < 2; j++)
+			pd0 ^= ((block[4 * i + j] ^ (block[4 * i + j] >> 1) ^ (block[4 * i + j] >> 2) ^
+				 (block[4 * i + j] >> 3) ^ (block[4 * i + j] >> 4) ^ (block[4 * i + j] >> 5) ^ (block[4 * i + j] >> 6) ^ (block[4 * i + j] >> 7)) & 1) << 4;
+	for (i = 0; i < 32; i++)	/* PD0<5> */
+		for (j = 0; j < 4; j++)
+			pd0 ^= ((block[8 * i + j] ^ (block[8 * i + j] >> 1) ^ (block[8 * i + j] >> 2) ^
+				 (block[8 * i + j] >> 3) ^ (block[8 * i + j] >> 4) ^ (block[8 * i + j] >> 5) ^ (block[8 * i + j] >> 6) ^ (block[8 * i + j] >> 7)) & 1) << 5;
+	for (i = 0; i < 16; i++)	/* PD0<6> */
+		for (j = 0; j < 8; j++)
+			pd0 ^= ((block[16 * i + j] ^ (block[16 * i + j] >> 1) ^ (block[16 * i + j] >> 2) ^
+				 (block[16 * i + j] >> 3) ^ (block[16 * i + j] >> 4) ^ (block[16 * i + j] >> 5) ^ (block[16 * i + j] >> 6) ^ (block[16 * i + j] >> 7)) & 1) << 6;
+	for (i = 0; i < 8; i++)	/* PD0<7> */
+		for (j = 0; j < 16; j++)
+			pd0 ^= ((block[32 * i + j] ^ (block[32 * i + j] >> 1) ^ (block[32 * i + j] >> 2) ^
+				 (block[32 * i + j] >> 3) ^ (block[32 * i + j] >> 4) ^ (block[32 * i + j] >> 5) ^ (block[32 * i + j] >> 6) ^ (block[32 * i + j] >> 7)) & 1) << 7;
+	for (i = 0; i < 4; i++)	/* PD1<0> */
+		for (j = 0; j < 32; j++)
+			pd1 ^= ((block[64 * i + j] ^ (block[64 * i + j] >> 1) ^ (block[64 * i + j] >> 2) ^
+				 (block[64 * i + j] >> 3) ^ (block[64 * i + j] >> 4) ^ (block[64 * i + j] >> 5) ^ (block[64 * i + j] >> 6) ^ (block[64 * i + j] >> 7)) & 1) << 0;
+	for (i = 0; i < 2; i++)	/* PD1<1> */
+		for (j = 0; j < 64; j++)
+			pd1 ^= ((block[128 * i + j] ^ (block[128 * i + j] >> 1) ^ (block[128 * i + j] >> 2) ^
+				 (block[128 * i + j] >> 3) ^ (block[128 * i + j] >> 4) ^ (block[128 * i + j] >> 5) ^
+				 (block[128 * i + j] >> 6) ^ (block[128 * i + j] >> 7)) & 1) << 1;
+	for (i = 0; i < 128; i++)	/* PD1<2> */
+		pd1 ^= ((block[i] ^ (block[i] >> 1) ^ (block[i] >> 2) ^ (block[i] >> 3) ^ (block[i] >> 4) ^ (block[i] >> 5) ^ (block[i] >> 6) ^ (block[i] >> 7)) & 1) << 2;
+	/* PD1<3> */
+	/* PD1<4> */
+	for (i = 0; i < 256; i++)	/* PD1<5> */
+		pd1 ^= (((block[i] >> 1) ^ (block[i] >> 3) ^ (block[i] >> 5) ^ (block[i] >> 7)) & 1) << 5;
+	for (i = 0; i < 256; i++)	/* PD1<6> */
+		pd1 ^= (((block[i] >> 2) ^ (block[i] >> 3) ^ (block[i] >> 6) ^ (block[i] >> 7)) & 1) << 6;
+	for (i = 0; i < 256; i++)	/* PD1<7> */
+		pd1 ^= (((block[i] >> 4) ^ (block[i] >> 5) ^ (block[i] >> 6) ^ (block[i] >> 7)) & 1) << 7;
+	for (i = 0; i < 128; i++)	/* PD2<0> */
+		pd2 ^= ((block[2 * i + 1] ^ (block[2 * i + 1] >> 1) ^ (block[2 * i + 1] >> 2) ^
+			 (block[2 * i + 1] >> 3) ^ (block[2 * i + 1] >> 4) ^ (block[2 * i + 1] >> 5) ^ (block[2 * i + 1] >> 6) ^ (block[2 * i + 1] >> 7)) & 1) << 0;
+	for (i = 0; i < 64; i++)	/* PD2<1> */
+		for (j = 2; j < 4; j++)
+			pd2 ^= ((block[4 * i + j] ^ (block[4 * i + j] >> 1) ^ (block[4 * i + j] >> 2) ^
+				 (block[4 * i + j] >> 3) ^ (block[4 * i + j] >> 4) ^ (block[4 * i + j] >> 5) ^ (block[4 * i + j] >> 6) ^ (block[4 * i + j] >> 7)) & 1) << 1;
+	for (i = 0; i < 32; i++)	/* PD2<2> */
+		for (j = 4; j < 8; j++)
+			pd2 ^= ((block[8 * i + j] ^ (block[8 * i + j] >> 1) ^ (block[8 * i + j] >> 2) ^
+				 (block[8 * i + j] >> 3) ^ (block[8 * i + j] >> 4) ^ (block[8 * i + j] >> 5) ^ (block[8 * i + j] >> 6) ^ (block[8 * i + j] >> 7)) & 1) << 2;
+	for (i = 0; i < 16; i++)	/* PD2<3> */
+		for (j = 8; j < 16; j++)
+			pd2 ^= ((block[16 * i + j] ^ (block[16 * i + j] >> 1) ^ (block[16 * i + j] >> 2) ^
+				 (block[16 * i + j] >> 3) ^ (block[16 * i + j] >> 4) ^ (block[16 * i + j] >> 5) ^ (block[16 * i + j] >> 6) ^ (block[16 * i + j] >> 7)) & 1) << 3;
+	for (i = 0; i < 8; i++)	/* PD2<4> */
+		for (j = 16; j < 32; j++)
+			pd2 ^= ((block[32 * i + j] ^ (block[32 * i + j] >> 1) ^ (block[32 * i + j] >> 2) ^
+				 (block[32 * i + j] >> 3) ^ (block[32 * i + j] >> 4) ^ (block[32 * i + j] >> 5) ^ (block[32 * i + j] >> 6) ^ (block[32 * i + j] >> 7)) & 1) << 4;
+	for (i = 0; i < 4; i++)	/* PD2<5> */
+		for (j = 32; j < 64; j++)
+			pd2 ^= ((block[64 * i + j] ^ (block[64 * i + j] >> 1) ^ (block[64 * i + j] >> 2) ^
+				 (block[64 * i + j] >> 3) ^ (block[64 * i + j] >> 4) ^ (block[64 * i + j] >> 5) ^ (block[64 * i + j] >> 6) ^ (block[64 * i + j] >> 7)) & 1) << 5;
+	for (i = 0; i < 2; i++)	/* PD2<6> */
+		for (j = 64; j < 128; j++)
+			pd2 ^= ((block[128 * i + j] ^ (block[128 * i + j] >> 1) ^ (block[128 * i + j] >> 2) ^
+				 (block[128 * i + j] >> 3) ^ (block[128 * i + j] >> 4) ^ (block[128 * i + j] >> 5) ^
+				 (block[128 * i + j] >> 6) ^ (block[128 * i + j] >> 7)) & 1) << 6;
+	for (i = 128; i < 256; i++)	/* PD2<7> */
+		pd2 ^= ((block[i] ^ (block[i] >> 1) ^ (block[i] >> 2) ^ (block[i] >> 3) ^ (block[i] >> 4) ^ (block[i] >> 5) ^ (block[i] >> 6) ^ (block[i] >> 7)) & 1) << 7;
+
+	xorpd0 = pd0 ^ block[256];
+	xorpd1 = pd1 ^ block[257];
+	xorpd2 = pd2 ^ block[258];
+
+	xor_num = __builtin_popcount((xorpd0 << 16) | (xorpd1 << 8) | xorpd2);
+	check = (((xorpd1 & 7) << 8) | xorpd0) ^ ((xorpd2 << 3) | (xorpd1 >> 5));
+
+	if (xor_num == 0)
+		return 0;
+	else if ((xor_num > 1) && (check != 0x7FF))
+		return 2;
+
+	if (check == 0x7FF) {
+		/* Correct the error */
+		block[xorpd2] ^= 1 << (xorpd1 >> 5);
+	}
+
+	return 1;
+}
+
+cvmx_nand_status_t cvmx_nand_set_defaults(int page_size, int oob_size, int pages_per_block, int blocks, int onfi_timing_mode)
+{
+	if (!page_size || !oob_size || !pages_per_block || !blocks || onfi_timing_mode > 5)
+		CVMX_NAND_RETURN(CVMX_NAND_INVALID_PARAM);
+
+	cvmx_nand_default.page_size = page_size;
+	cvmx_nand_default.oob_size = oob_size;
+	cvmx_nand_default.pages_per_block = pages_per_block;
+	cvmx_nand_default.blocks = blocks;
+	cvmx_nand_default.onfi_timing = onfi_timing_mode;
+
+	CVMX_NAND_RETURN(CVMX_NAND_SUCCESS);
+}
diff --git a/arch/mips/cavium-octeon/octeon-nand.c b/arch/mips/cavium-octeon/octeon-nand.c
new file mode 100644
index 0000000..8caf655
--- /dev/null
+++ b/arch/mips/cavium-octeon/octeon-nand.c
@@ -0,0 +1,450 @@
+/**
+ * Driver for the Octeon NAND flash controller introduced in CN52XX pass 2.
+ *
+ * LICENSE:
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2008 - 2012 Cavium, Inc.
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <linux/of.h>
+
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/cvmx-nand.h>
+#include <asm/octeon/octeon.h>
+
+#define DRIVER_NAME "octeon-nand"
+
+#define DEBUG_INIT		(1<<0)
+#define DEBUG_READ		(1<<1)
+#define DEBUG_READ_BUFFER	(1<<2)
+#define DEBUG_WRITE		(1<<3)
+#define DEBUG_WRITE_BUFFER	(1<<4)
+#define DEBUG_CONTROL		(1<<5)
+#define DEBUG_SELECT		(1<<6)
+#define DEBUG_ALL		-1
+
+#define MAX_NAND_NAME_LEN       20
+
+static const char *part_probes[] = { "cmdlinepart", NULL };
+
+#define DEV_DBG(_level, _dev, _format, _arg...)	do {			\
+	if (unlikely(debug & (_level)))					\
+		dev_info((_dev) , "%s " _format , __func__, ## _arg);	\
+	} while (0)
+
+static int debug;
+module_param(debug, int, 0644);
+MODULE_PARM_DESC(debug, "Debug bit field. -1 will turn on all debugging.");
+
+
+struct octeon_nand {
+	struct mtd_info mtd;
+	struct nand_chip nand;
+	/* Temporary location to store read data, must be 64 bit aligned */
+	uint8_t data[NAND_MAX_PAGESIZE + NAND_MAX_OOBSIZE];
+	int data_len;		/* Number of byte in the data buffer */
+	int data_index;		/* Current read index. Equal to data_len when
+					all data has been read */
+	int selected_chip;	/* Currently selected NAND chip */
+	int selected_page;	/* Last page chosen by SEQIN for PROGRAM */
+	struct device *dev;	/* Pointer to the device */
+};
+
+static struct octeon_nand *octeon_nand_open_mtd[8];
+
+/*
+ * Read a single byte from the temporary buffer. Used after READID
+ * to get the NAND information.
+ */
+static uint8_t octeon_nand_read_byte(struct mtd_info *mtd)
+{
+	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
+
+	if (priv->data_index < priv->data_len) {
+		DEV_DBG(DEBUG_READ, priv->dev, "read of 0x%02x\n",
+			0xff & priv->data[priv->data_index]);
+		return priv->data[priv->data_index++];
+	} else {
+		dev_err(priv->dev, "No data to read\n");
+		return 0xff;
+	}
+}
+
+/*
+ * Read two bytes from the temporary buffer. Used after READID to
+ * get the NAND information on 16 bit devices.
+ *
+ */
+static uint16_t octeon_nand_read_word(struct mtd_info *mtd)
+{
+	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
+
+	if (priv->data_index + 1 < priv->data_len) {
+		uint16_t result = le16_to_cpup((uint16_t *)(priv->data +
+			priv->data_index));
+		priv->data_index += 2;
+		DEV_DBG(DEBUG_READ, priv->dev, "read of 0x%04x\n",
+			0xffff & result);
+		return result;
+	} else {
+		dev_err(priv->dev, "No data to read\n");
+		return 0xff;
+	}
+	return 0;
+}
+
+/*
+ * Since we have a write page, I don't think this can ever be
+ * called.
+ */
+static void octeon_nand_write_buf(struct mtd_info *mtd, const uint8_t *buf,
+				int len)
+{
+	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
+
+	DEV_DBG(DEBUG_WRITE_BUFFER, priv->dev, "len=%d\n", len);
+
+	memcpy(priv->data + priv->data_index, buf, len);
+	priv->data_index += len;
+	priv->data_len += len;
+	/* Linux sometimes thinks there is less OOB data than the chip really
+		has. Make sure all OOB is set to 0xff */
+	memset(priv->data + priv->data_index, 0xff,
+		sizeof(priv->data) - priv->data_index);
+}
+
+/*
+ * Read a number of pending bytes from the temporary buffer. Used
+ * to get page and OOB data.
+ */
+static void octeon_nand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
+
+	DEV_DBG(DEBUG_READ_BUFFER, priv->dev, "len=%d\n", len);
+
+	if (len <= priv->data_len - priv->data_index) {
+		memcpy(buf, priv->data + priv->data_index, len);
+		priv->data_index += len;
+	} else {
+		dev_err(priv->dev,
+			"Not enough data for read of %d bytes\n", len);
+		priv->data_len = 0;
+	}
+}
+
+#ifdef	__DEPRECATED_API
+/*
+ * Verify the supplied buffer matches the data we last read
+ */
+static int octeon_nand_verify_buf(struct mtd_info *mtd, const uint8_t *buf,
+				int len)
+{
+	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
+
+	if (memcmp(buf, priv->data, len)) {
+		dev_err(priv->dev, "Write verify failed\n");
+		return -EFAULT;
+	} else
+		return 0;
+}
+#endif
+/*
+ * Select which NAND chip we are working on. A chip of -1
+ * represents that no chip should be selected.
+ */
+static void octeon_nand_select_chip(struct mtd_info *mtd, int chip)
+{
+	/* We don't need to do anything here */
+}
+
+/*
+ * Issue a NAND command to the chip. Almost all work is done here.
+ */
+static void octeon_nand_cmdfunc(struct mtd_info *mtd, unsigned command,
+				int column, int page_addr)
+{
+	struct octeon_nand *priv = container_of(mtd, struct octeon_nand, mtd);
+	struct nand_chip *nand = &priv->nand;
+	int status;
+
+	switch (command) {
+	case NAND_CMD_READID:
+		DEV_DBG(DEBUG_CONTROL, priv->dev, "READID\n");
+		priv->data_index = 0;
+		/*
+		 * Read length must be a multiple of 8, so read a
+		 * little more than we require.
+		 */
+		priv->data_len = cvmx_nand_read_id(priv->selected_chip, 0,
+						virt_to_phys(priv->data), 16);
+		if (priv->data_len < 16) {
+			dev_err(priv->dev, "READID failed with %d\n",
+				priv->data_len);
+			priv->data_len = 0;
+		}
+		break;
+
+	case NAND_CMD_READOOB:
+		DEV_DBG(DEBUG_CONTROL, priv->dev,
+			"READOOB page_addr=0x%x\n", page_addr);
+		priv->data_index = 8;
+		/*
+		 * Read length must be a multiple of 8, so we start
+		 * reading 8 bytes from the end of page.
+		 */
+		priv->data_len = cvmx_nand_page_read(priv->selected_chip,
+					(page_addr << nand->page_shift) +
+					(1 << nand->page_shift) - priv->data_index,
+					virt_to_phys(priv->data),
+					mtd->oobsize + priv->data_index);
+		if (priv->data_len < mtd->oobsize + priv->data_index) {
+			dev_err(priv->dev, "READOOB failed with %d\n",
+				priv->data_len);
+			priv->data_len = 0;
+		}
+		break;
+
+	case NAND_CMD_READ0:
+		DEV_DBG(DEBUG_CONTROL, priv->dev,
+			"READ0 page_addr=0x%x\n", page_addr);
+		priv->data_index = 0;
+		/* Here mtd->oobsize _must_ already be a multiple of 8 */
+		priv->data_len = cvmx_nand_page_read(priv->selected_chip,
+					column +
+					(page_addr << nand->page_shift),
+					virt_to_phys(priv->data),
+					(1 << nand->page_shift) +
+					mtd->oobsize);
+		if (priv->data_len < (1 << nand->page_shift) + mtd->oobsize) {
+			dev_err(priv->dev, "READ0 failed with %d\n",
+				priv->data_len);
+			priv->data_len = 0;
+		}
+		break;
+
+	case NAND_CMD_ERASE1:
+		DEV_DBG(DEBUG_CONTROL, priv->dev,
+			"ERASE1 page_addr=0x%x\n", page_addr);
+		if (cvmx_nand_block_erase(priv->selected_chip,
+			page_addr << nand->page_shift)) {
+			dev_err(priv->dev, "ERASE1 failed\n");
+		}
+		break;
+
+	case NAND_CMD_ERASE2:
+		/* We do all erase processing in the first command, so ignore
+			this one */
+		break;
+
+	case NAND_CMD_STATUS:
+		DEV_DBG(DEBUG_CONTROL, priv->dev, "STATUS\n");
+		priv->data_index = 0;
+		priv->data_len = 2;
+		priv->data[0] = cvmx_nand_get_status(priv->selected_chip);
+		priv->data[1] = priv->data[0];
+		break;
+
+	case NAND_CMD_SEQIN:
+		DEV_DBG(DEBUG_CONTROL, priv->dev,
+			"SEQIN column=%d page_addr=0x%x\n", column, page_addr);
+		/* If we don't seem to be doing sequential writes then erase
+			all data assuming it is old */
+		if (priv->data_index != column)
+			memset(priv->data, 0xff, sizeof(priv->data));
+		priv->data_index = column;
+		priv->data_len = column;
+		priv->selected_page = page_addr;
+		break;
+
+	case NAND_CMD_PAGEPROG:
+		DEV_DBG(DEBUG_CONTROL, priv->dev, "PAGEPROG\n");
+		status = cvmx_nand_page_write(priv->selected_chip,
+			priv->selected_page << nand->page_shift,
+			virt_to_phys(priv->data));
+		if (status)
+			dev_err(priv->dev, "PAGEPROG failed with %d\n",	status);
+		break;
+
+	case NAND_CMD_RESET:
+		DEV_DBG(DEBUG_CONTROL, priv->dev, "RESET\n");
+		priv->data_index = 0;
+		priv->data_len = 0;
+		memset(priv->data, 0xff, sizeof(priv->data));
+		status = cvmx_nand_reset(priv->selected_chip);
+		if (status)
+			dev_err(priv->dev, "RESET failed with %d\n", status);
+		break;
+
+	default:
+		dev_err(priv->dev, "Unsupported command 0x%x\n", command);
+		break;
+	}
+}
+
+/*
+ * Determine what NAND devices are available
+ */
+static int octeon_nand_probe(struct platform_device *pdev)
+{
+	struct octeon_nand *priv;
+	struct device_node *child_node;
+	int rv;
+	int chip;
+	int active_chips = 0;
+	char *name;
+	int chip_num = 0; /* Count of detected chips, used for device naming */
+
+	DEV_DBG(DEBUG_INIT, &pdev->dev, "called\n");
+
+	for_each_child_of_node(pdev->dev.of_node, child_node) {
+		u32 reg;
+		rv = of_property_read_u32(child_node, "reg", &reg);
+		if (rv)
+			continue;
+		active_chips |= (1 << reg);
+	}
+	if (!active_chips)
+		return -ENODEV;
+
+#if 0
+	/*
+	 * Optionally set defaults to be used for NAND chips that aren't
+	 * recognized by cvmx_nand_initialize()
+	 */
+	cvmx_nand_set_defaults(2048, 64, 64, 2048, 2);
+#endif
+	cvmx_nand_initialize(0 /*CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE */,
+			     active_chips);
+
+	for (chip = 0; chip < 8; chip++) {
+		/* Skip chip selects that don't have NAND */
+		if ((active_chips & (1 << chip)) == 0)
+			continue;
+
+		/*
+		 * Allocate and initialize mtd_info, nand_chip and private
+		 * structures
+		 */
+		priv = devm_kzalloc(&pdev->dev,
+				    sizeof(struct octeon_nand), GFP_KERNEL);
+		if (!priv) {
+			dev_err(&pdev->dev, "Unable to allocate structures\n");
+			return -ENOMEM;
+		}
+		name = devm_kzalloc(&pdev->dev, MAX_NAND_NAME_LEN, GFP_KERNEL);
+		if (!name) {
+			dev_err(&pdev->dev, "Unable to allocate structures\n");
+			return -ENOMEM;
+		}
+
+		priv->mtd.owner = THIS_MODULE;
+		priv->mtd.priv = &priv->nand;
+		memset(priv->data, 0xff, sizeof(priv->data));
+		priv->dev = &pdev->dev;
+		priv->selected_chip = chip;
+
+		priv->nand.ecc.mode = NAND_ECC_SOFT;
+
+		/* We always identify chips as 8 bit, as the Octeon NAND
+		 * layer makes both 8 and 16 bit look the same.
+		 * We never set the 16 bit buswidth option.
+		 */
+
+		priv->nand.read_byte = octeon_nand_read_byte;
+		priv->nand.read_word = octeon_nand_read_word;
+		priv->nand.write_buf = octeon_nand_write_buf;
+		priv->nand.read_buf = octeon_nand_read_buf;
+#ifdef	__DEPRECATED_API
+		priv->nand.verify_buf = octeon_nand_verify_buf;
+#endif
+		priv->nand.select_chip = octeon_nand_select_chip;
+		priv->nand.cmdfunc = octeon_nand_cmdfunc;
+
+		if (nand_scan(&priv->mtd, 1) != 0) {
+			dev_err(&pdev->dev, "NAND scan failed\n");
+			return -ENXIO;
+		}
+
+		/* We need to override the name, as the default names
+		 * have spaces in them, and this prevents the passing
+		 * of partitioning information on the kernel command line.
+		 */
+		snprintf(name, MAX_NAND_NAME_LEN, "octeon_nand%d", chip_num);
+		priv->mtd.name = name;
+		priv->mtd.dev.parent = &pdev->dev;
+
+		mtd_device_parse_register(&priv->mtd, part_probes,
+					  NULL, NULL, 0);
+
+		octeon_nand_open_mtd[chip] = priv;
+		chip_num++;
+	}
+	return 0;
+}
+
+/*
+ * Called when the driver is unloaded. It must clean up all
+ * created devices.
+ */
+static int octeon_nand_remove(struct platform_device *pdev)
+{
+	struct octeon_nand *priv;
+	int chip;
+
+	DEV_DBG(DEBUG_INIT, &pdev->dev, "called\n");
+	for (chip = 0; chip < 8; chip++) {
+		priv = octeon_nand_open_mtd[chip];
+		if (priv) {
+			mtd_device_unregister(&priv->mtd);
+			octeon_nand_open_mtd[chip] = NULL;
+		}
+	}
+	return 0;
+}
+
+static struct of_device_id octeon_nand_match[] = {
+	{
+		.compatible = "cavium,octeon-5230-nand",
+	},
+	{},
+};
+
+static struct platform_driver octeon_nand_driver = {
+	.probe = octeon_nand_probe,
+	.remove = octeon_nand_remove,
+	.driver = {
+		.owner = THIS_MODULE,
+		.name = DRIVER_NAME,
+		.of_match_table = octeon_nand_match,
+	},
+};
+
+static int __init octeon_nand_driver_init(void)
+{
+	return platform_driver_register(&octeon_nand_driver);
+}
+/*
+ * We need to call octeon_nand_driver_init late enough that the MTD
+ * core is already registered.  If built into the kernel , use a late
+ * initcall.
+ */
+late_initcall(octeon_nand_driver_init);
+
+static void __exit octeon_nand_driver_exit(void)
+{
+	platform_driver_unregister(&octeon_nand_driver);
+}
+module_exit(octeon_nand_driver_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cavium Inc. <support@cavium.com>");
+MODULE_DESCRIPTION("Cavium Inc. OCTEON NAND driver.");
diff --git a/arch/mips/include/asm/octeon/cvmx-nand.h b/arch/mips/include/asm/octeon/cvmx-nand.h
new file mode 100644
index 0000000..4c4bb85
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-nand.h
@@ -0,0 +1,689 @@
+/***********************license start***************
+ * Author: Cavium Inc.
+ *
+ * Contact: support@cavium.com
+ * This file is part of the OCTEON SDK
+ *
+ * Copyright (c) 2003-2010 Cavium Inc.
+ *
+ * This file is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License, Version 2, as
+ * published by the Free Software Foundation.
+ *
+ * This file is distributed in the hope that it will be useful, but
+ * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
+ * NONINFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this file; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
+ * or visit http://www.gnu.org/licenses/.
+ *
+ * This file may also be available under a different license from Cavium.
+ * Contact Cavium Inc. for more information
+ ***********************license end**************************************/
+
+/**
+ * @file
+ *
+ * This header defines the CVMX interface to the NAND flash controller. The
+ * basic operations common to all NAND devices are supported by this API, but
+ * many more advanced functions are not support. The low level hardware supports
+ * all types of transactions, but this API only implements the must commonly
+ * used operations. This API performs no locking, so it is the responsibility of
+ * the caller to make sure only one thread of execution is accessing the NAND
+ * controller at a time. Most applications should not use this API directly but
+ * instead use a flash logical layer supplied through a secondary system. For
+ * example, the Linux MTD layer provides a driver for running JFFS2 on top of
+ * NAND flash.
+ *
+ * <h2>Selecting the NAND Chip</h2>
+ *
+ * Octeon's NAND controller assumes a single NAND chip is connected to a boot
+ * bus chip select. Throughout this API, NAND chips are referred to by the chip
+ * select they are connected to (0-7). Chip select 0 will only be a NAND chip
+ * when you are booting from NAND flash.
+ *
+ * <h2>NAND Addressing</h2>
+ *
+ * Various functions in cvmx-nand use addresses to index into NAND flash. All
+ * functions us a uniform address translation scheme to map the passed address
+ * into a NAND block, page, and column. In NAND flash a page represents the
+ * basic unit of reads and writes. Each page contains a power of two number of
+ * bytes and some number of extra out of band (OOB) bytes. A fixed number of
+ * pages fit into each NAND block. Here is the mapping of bits in the cvmx-nand
+ * address to the NAND hardware:
+ * <pre>
+ * 63     56      48      40      32      24      16       8      0
+ * +-------+-------+-------+-------+-------+-------+-------+------+
+ * |                                 64 bit cvmx-nand nand_address|
+ * +------------------------------------------------+----+--------+
+ * |                                          block |page| column |
+ * +-------+-------+-------+-------+-------+--------+----+--------+
+ * 63     56      48      40      32      24      16       8      0
+ * </pre>
+ * Basically the block, page, and column addresses are packet together. Before
+ * being sent out the NAND pins for addressing the column is padded out to an
+ * even number of bytes. This means that column address are 2 bytes, or 2
+ * address cycles, for page sizes between 512 and 65536 bytes. Page sizes
+ * between 128KB and 16MB would use 3 column address cycles. NAND device
+ * normally either have 32 or 64 pages per block, needing either 5 or 6 address
+ * bits respectively. This means you have 10 bits for block address using 4
+ * address cycles, or 18 for 5 address cycles. Using the cvmx-nand addressing
+ * scheme, it is not possible to directly index the OOB data. Instead you can
+ * access it by reading or writing more data than the normal page size would
+ * allow. Logically the OOB data is appended onto the the page data. For
+ * example, this means that a read of 65 bytes from a column address of 0x7ff
+ * would yield byte 2047 of the page and then 64 bytes of OOB data.
+ *
+ */
+
+#ifndef __CVMX_NAND_H__
+#define __CVMX_NAND_H__
+
+
+/* Maxium PAGE + OOB size supported.  This is used to size
+** buffers, some that must be statically allocated. */
+#define CVMX_NAND_MAX_PAGE_AND_OOB_SIZE      (4096 + 256)
+
+/* Block size for boot ECC */
+#define CVMX_NAND_BOOT_ECC_BLOCK_SIZE    (256)
+/* ECC bytes for each block */
+#define CVMX_NAND_BOOT_ECC_ECC_SIZE      (8)
+
+/**
+ * Flags to be passed to the initialize function
+ */
+typedef enum {
+	CVMX_NAND_INITIALIZE_FLAGS_16BIT = 1 << 0,
+	CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE = 1 << 1,
+	CVMX_NAND_INITIALIZE_FLAGS_DEBUG = 1 << 15,
+} cvmx_nand_initialize_flags_t;
+
+/**
+ * Return codes from NAND functions
+ */
+typedef enum {
+	CVMX_NAND_SUCCESS = 0,
+	CVMX_NAND_NO_MEMORY = -1,
+	CVMX_NAND_BUSY = -2,
+	CVMX_NAND_INVALID_PARAM = -3,
+	CVMX_NAND_TIMEOUT = -4,
+	CVMX_NAND_ERROR = -5,
+	CVMX_NAND_NO_DEVICE = -6,
+} cvmx_nand_status_t;
+
+/**
+ * NAND NOP command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_4_63:60;
+	uint64_t zero:4;
+} cvmx_nand_cmd_nop_t;
+
+/**
+ * NAND SET_TM_PAR command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t tim_par7:8;
+	uint64_t tim_par6:8;
+	uint64_t tim_par5:8;
+	uint64_t tim_par4:8;
+	uint64_t tim_par3:8;
+	uint64_t tim_par2:8;
+	uint64_t tim_par1:8;
+	uint64_t tim_mult:4;
+	uint64_t one:4;
+} cvmx_nand_cmd_set_tm_par_t;
+
+/**
+ * NAND WAIT command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_11_63:53;
+	uint64_t n:3;
+	uint64_t reserved_5_7:3;
+	uint64_t r_b:1;
+	uint64_t two:4;
+} cvmx_nand_cmd_wait_t;
+
+/**
+ * NAND CHIP_EN command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_10_63:54;
+	uint64_t width:2;
+	uint64_t one:1;
+	uint64_t chip:3;
+	uint64_t three:4;
+} cvmx_nand_cmd_chip_en_t;
+
+/**
+ * NAND CHIP_DIS command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_4_63:60;
+	uint64_t three:4;
+} cvmx_nand_cmd_chip_dis_t;
+
+/**
+ * NAND CLE command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_25_63:39;
+	uint64_t clen3:3;
+	uint64_t clen2:3;
+	uint64_t clen1:3;
+	uint64_t cmd_data:8;
+	uint64_t reserved_4_7:4;
+	uint64_t four:4;
+} cvmx_nand_cmd_cle_t;
+
+/**
+ * NAND ALE command definition
+ */
+typedef struct {
+	uint64_t reserved_96_127:32;
+	uint64_t adr_bytes_h:32;
+	uint64_t adr_bytes_l:32;
+	uint64_t reserved_28_31:4;
+	uint64_t alen4:3;
+	uint64_t alen3:3;
+	uint64_t alen2:3;
+	uint64_t alen1:3;
+	uint64_t reserved_12_15:4;
+	uint64_t adr_byte_num:4;
+	uint64_t reserved_4_7:4;
+	uint64_t five:4;
+} cvmx_nand_cmd_ale_t;
+
+/**
+ * NAND WR command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_31_63:34;
+	uint64_t wrn2:3;
+	uint64_t wrn1:3;
+	uint64_t reserved_20_24:4;
+	uint64_t data_bytes:16;
+	uint64_t eight:4;
+} cvmx_nand_cmd_wr_t;
+
+/**
+ * NAND RD command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_32_63:32;
+	uint64_t rdn4:3;
+	uint64_t rdn3:3;
+	uint64_t rdn2:3;
+	uint64_t rdn1:3;
+	uint64_t data_bytes:16;
+	uint64_t nine:4;
+} cvmx_nand_cmd_rd_t;
+
+/**
+ * NAND RD_EDO command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_32_63:32;
+	uint64_t rdn4:3;
+	uint64_t rdn3:3;
+	uint64_t rdn2:3;
+	uint64_t rdn1:3;
+	uint64_t data_bytes:16;
+	uint64_t ten:4;
+} cvmx_nand_cmd_rd_edo_t;
+
+/**
+ * NAND WAIT_STATUS command definition
+ */
+typedef struct {
+	uint64_t rdn4:3;
+	uint64_t rdn3:3;
+	uint64_t rdn2:3;
+	uint64_t rdn1:3;
+	uint64_t comp_byte:8;
+	uint64_t and_mask:8;
+	uint64_t nine:4;
+	uint64_t reserved_28_95:64;
+	uint64_t clen4:3;
+	uint64_t clen3:3;
+	uint64_t clen2:3;
+	uint64_t clen1:3;
+	uint64_t data:8;
+	uint64_t reserved_4_7:4;
+	uint64_t eleven:4;
+} cvmx_nand_cmd_wait_status_t;
+
+/**
+ * NAND WAIT_STATUS_ALE command definition
+ */
+typedef struct {
+	uint64_t rdn4:3;
+	uint64_t rdn3:3;
+	uint64_t rdn2:3;
+	uint64_t rdn1:3;
+	uint64_t comp_byte:8;
+	uint64_t and_mask:8;
+	uint64_t nine:4;
+	uint64_t adr_bytes:32;
+	uint64_t reserved_60_63:4;
+	uint64_t alen4:3;
+	uint64_t alen3:3;
+	uint64_t alen2:3;
+	uint64_t alen1:3;
+	uint64_t reserved_44_47:4;
+	uint64_t adr_byte_num:4;
+	uint64_t five:4;
+	uint64_t reserved_25_31:7;
+	uint64_t clen3:3;
+	uint64_t clen2:3;
+	uint64_t clen1:3;
+	uint64_t data:8;
+	uint64_t reserved_4_7:4;
+	uint64_t eleven:4;
+} cvmx_nand_cmd_wait_status_ale_t;
+
+/**
+ * NAND BUS_ACQ command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_8_63:56;
+	uint64_t one:4;
+	uint64_t fifteen:4;
+} cvmx_nand_cmd_bus_acq_t;
+
+/**
+ * NAND BUS_REL command definition
+ */
+typedef struct {
+	uint64_t reserved_64_127:64;
+	uint64_t reserved_8_63:56;
+	uint64_t zero:4;
+	uint64_t fifteen:4;
+} cvmx_nand_cmd_bus_rel_t;
+
+/**
+ * NAND command union of all possible commands
+ */
+typedef union {
+	uint64_t u64[2];
+	cvmx_nand_cmd_nop_t nop;
+	cvmx_nand_cmd_set_tm_par_t set_tm_par;
+	cvmx_nand_cmd_wait_t wait;
+	cvmx_nand_cmd_chip_en_t chip_en;
+	cvmx_nand_cmd_chip_dis_t chip_dis;
+	cvmx_nand_cmd_cle_t cle;
+	cvmx_nand_cmd_ale_t ale;
+	cvmx_nand_cmd_rd_t rd;
+	cvmx_nand_cmd_rd_edo_t rd_edo;
+	cvmx_nand_cmd_wr_t wr;
+	cvmx_nand_cmd_wait_status_t wait_status;
+	cvmx_nand_cmd_wait_status_ale_t wait_status_ale;
+	cvmx_nand_cmd_bus_acq_t bus_acq;
+	cvmx_nand_cmd_bus_rel_t bus_rel;
+	struct {
+		uint64_t reserved_64_127:64;
+		uint64_t reserved_4_63:60;
+		uint64_t op_code:4;
+	} s;
+} cvmx_nand_cmd_t;
+
+typedef struct __attribute__ ((packed)) {
+	char onfi[4];		    /**< Bytes 0-3: The ASCII characters 'O', 'N', 'F', 'I' */
+	uint16_t revision_number;
+				    /**< Bytes 4-5: ONFI revision number
+                                        - 2-15 Reserved (0)
+                                        - 1    1 = supports ONFI version 1.0
+                                        - 0    Reserved (0) */
+	uint16_t features;	    /**< Bytes 6-7: Features supported
+                                        - 5-15    Reserved (0)
+                                        - 4       1 = supports odd to even page Copyback
+                                        - 3       1 = supports interleaved operations
+                                        - 2       1 = supports non-sequential page programming
+                                        - 1       1 = supports multiple LUN operations
+                                        - 0       1 = supports 16-bit data bus width */
+	uint16_t optional_commands;
+				    /**< Bytes 8-9: Optional commands supported
+                                        - 6-15   Reserved (0)
+                                        - 5      1 = supports Read Unique ID
+                                        - 4      1 = supports Copyback
+                                        - 3      1 = supports Read Status Enhanced
+                                        - 2      1 = supports Get Features and Set Features
+                                        - 1      1 = supports Read Cache commands
+                                        - 0      1 = supports Page Cache Program command */
+	uint8_t reserved_10_31[22];
+				    /**< Bytes 10-31: Reserved */
+
+	char manufacturer[12];
+				    /**< Bytes 32-43: Device manufacturer (12 ASCII characters) */
+	char model[20];		    /**< Bytes 40-63: Device model (20 ASCII characters) */
+	uint8_t jedec_id;	    /**< Byte 64: JEDEC manufacturer ID */
+	uint16_t date_code;	    /**< Byte 65-66: Date code */
+	uint8_t reserved_67_79[13];
+				    /**< Bytes 67-79: Reserved */
+
+	uint32_t page_data_bytes;
+				    /**< Bytes 80-83: Number of data bytes per page */
+	uint16_t page_spare_bytes;
+				    /**< Bytes 84-85: Number of spare bytes per page */
+	uint32_t partial_page_data_bytes;
+				      /**< Bytes 86-89: Number of data bytes per partial page */
+	uint16_t partial_page_spare_bytes;
+				       /**< Bytes 90-91: Number of spare bytes per partial page */
+	uint32_t pages_per_block;
+				    /**< Bytes 92-95: Number of pages per block */
+	uint32_t blocks_per_lun;
+				    /**< Bytes 96-99: Number of blocks per logical unit (LUN) */
+	uint8_t number_lun;	    /**< Byte 100: Number of logical units (LUNs) */
+	uint8_t address_cycles;
+				    /**< Byte 101: Number of address cycles
+                                        - 4-7     Column address cycles
+                                        - 0-3     Row address cycles */
+	uint8_t bits_per_cell;
+				    /**< Byte 102: Number of bits per cell */
+	uint16_t bad_block_per_lun;
+				    /**< Bytes 103-104: Bad blocks maximum per LUN */
+	uint16_t block_endurance;
+				    /**< Bytes 105-106: Block endurance */
+	uint8_t good_blocks;	    /**< Byte 107: Guaranteed valid blocks at beginning of target */
+	uint16_t good_block_endurance;
+				    /**< Bytes 108-109: Block endurance for guaranteed valid blocks */
+	uint8_t programs_per_page;
+				    /**< Byte 110: Number of programs per page */
+	uint8_t partial_program_attrib;
+				    /**< Byte 111: Partial programming attributes
+                                        - 5-7    Reserved
+                                        - 4      1 = partial page layout is partial page data followed by partial page spare
+                                        - 1-3    Reserved
+                                        - 0      1 = partial page programming has constraints */
+	uint8_t bits_ecc;	    /**< Byte 112: Number of bits ECC correctability */
+	uint8_t interleaved_address_bits;
+					/**< Byte 113: Number of interleaved address bits
+                                            - 4-7    Reserved (0)
+                                            - 0-3    Number of interleaved address bits */
+	uint8_t interleaved_attrib;
+				    /**< Byte 114: Interleaved operation attributes
+                                        - 4-7    Reserved (0)
+                                        - 3      Address restrictions for program cache
+                                        - 2      1 = program cache supported
+                                        - 1      1 = no block address restrictions
+                                        - 0      Overlapped / concurrent interleaving support */
+	uint8_t reserved_115_127[13];
+				    /**< Bytes 115-127: Reserved (0) */
+
+	uint8_t pin_capacitance;
+				    /**< Byte 128: I/O pin capacitance */
+	uint16_t timing_mode;
+				    /**< Byte 129-130: Timing mode support
+                                        - 6-15   Reserved (0)
+                                        - 5      1 = supports timing mode 5
+                                        - 4      1 = supports timing mode 4
+                                        - 3      1 = supports timing mode 3
+                                        - 2      1 = supports timing mode 2
+                                        - 1      1 = supports timing mode 1
+                                        - 0      1 = supports timing mode 0, shall be 1 */
+	uint16_t cache_timing_mode;
+				    /**< Byte 131-132: Program cache timing mode support
+                                        - 6-15   Reserved (0)
+                                        - 5      1 = supports timing mode 5
+                                        - 4      1 = supports timing mode 4
+                                        - 3      1 = supports timing mode 3
+                                        - 2      1 = supports timing mode 2
+                                        - 1      1 = supports timing mode 1
+                                        - 0      1 = supports timing mode 0 */
+	uint16_t t_prog;	    /**< Byte 133-134: Maximum page program time (us) */
+	uint16_t t_bers;	    /**< Byte 135-136: Maximum block erase time (us) */
+	uint16_t t_r;		    /**< Byte 137-148: Maximum page read time (us) */
+	uint16_t t_ccs;		    /**< Byte 139-140: Minimum change column setup time (ns) */
+	uint8_t reserved_141_163[23];
+				    /**< Byte 141-163: Reserved (0) */
+
+	uint16_t vendor_revision;
+				    /**< Byte 164-165: Vendor specific Revision number */
+	uint8_t vendor_specific[88];
+				    /**< Byte 166-253: Vendor specific */
+	uint16_t crc;		    /**< Byte 254-255: Integrity CRC */
+} cvmx_nand_onfi_param_page_t;
+
+/**
+ * Called to initialize the NAND controller for use. Note that
+ * you must be running out of L2 or memory and not NAND before
+ * calling this function.
+ * When probing for NAND chips, this function attempts to autoconfigure based on the NAND parts detected.
+ * It currently supports autodetection for ONFI parts (with valid parameter pages), and some Samsung NAND
+ * parts (decoding ID bits.)  If autoconfiguration fails, the defaults set with __set_chip_defaults()
+ * prior to calling cvmx_nand_initialize() are used.
+ * If defaults are set and the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is provided, the defaults are used
+ * for all chips in the active_chips mask.
+ *
+ * @flags:  Optional initialization flags
+ *               If the CVMX_NAND_INITIALIZE_FLAGS_DONT_PROBE flag is passed, chips are not probed,
+ *               and the default parameters (if set with cvmx_nand_set_defaults) are used for all chips
+ *               in the active_chips mask.
+ * @active_chips:
+ *               Each bit in this parameter represents a chip select that might
+ *               contain NAND flash. Any chip select present in this bitmask may
+ *               be connected to NAND. It is normally safe to pass 0xff here and
+ *               let the API probe all 8 chip selects.
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern cvmx_nand_status_t cvmx_nand_initialize(cvmx_nand_initialize_flags_t flags, int active_chips);
+
+/**
+ * This function may be called before cvmx_nand_initialize to set default values that will be used
+ * for NAND chips that do not identify themselves in a way that allows autoconfiguration. (ONFI chip with
+ * missing parameter page, for example.)
+ * The parameters set by this function will be used by _all_ non-autoconfigured NAND chips.
+ *
+ *
+ *   NOTE:  This function signature is _NOT_ stable, and will change in the future as required to support
+ *          various NAND chips.
+ *
+ * @page_size: page size in bytes
+ * @oob_size:  Out of band size in bytes (per page)
+ * @pages_per_block:
+ *                  number of pages per block
+ * @blocks:    Total number of blocks in device
+ * @onfi_timing_mode:
+ *                  ONFI timing mode
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern cvmx_nand_status_t cvmx_nand_set_defaults(int page_size, int oob_size, int pages_per_block, int blocks, int onfi_timing_mode);
+
+/**
+ * Call to shutdown the NAND controller after all transactions
+ * are done. In most setups this will never be called.
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern cvmx_nand_status_t cvmx_nand_shutdown(void);
+
+/**
+ * Returns a bitmask representing the chip selects that are
+ * connected to NAND chips. This can be called after the
+ * initialize to determine the actual number of NAND chips
+ * found. Each bit in the response coresponds to a chip select.
+ *
+ * Returns Zero if no NAND chips were found. Otherwise a bit is set for
+ *         each chip select (1<<chip).
+ */
+extern int cvmx_nand_get_active_chips(void);
+
+/**
+ * Override the timing parameters for a NAND chip
+ *
+ * @chip:     Chip select to override
+ * @tim_mult:
+ * @tim_par:
+ * @clen:
+ * @alen:
+ * @rdn:
+ * @wrn:
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern cvmx_nand_status_t cvmx_nand_set_timing(int chip, int tim_mult, int tim_par[7], int clen[4], int alen[4], int rdn[4], int wrn[2]);
+
+/**
+ * Submit a command to the NAND command queue. Generally this
+ * will not be used directly. Instead most programs will use the other
+ * higher level NAND functions.
+ *
+ * @cmd:    Command to submit
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern cvmx_nand_status_t cvmx_nand_submit(cvmx_nand_cmd_t cmd);
+
+/**
+ * Read a page from NAND. If the buffer has room, the out of band
+ * data will be included.
+ *
+ * @chip:   Chip select for NAND flash
+ * @nand_address:
+ *               Location in NAND to read. See description in file comment
+ * @buffer_address:
+ *               Physical address to store the result at
+ * @buffer_length:
+ *               Number of bytes to read
+ *
+ * Returns Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern int cvmx_nand_page_read(int chip, uint64_t nand_address, uint64_t buffer_address, int buffer_length);
+
+/**
+ * Write a page to NAND. The buffer must contain the entire page
+ * including the out of band data.
+ *
+ * @chip:   Chip select for NAND flash
+ * @nand_address:
+ *               Location in NAND to write. See description in file comment
+ * @buffer_address:
+ *               Physical address to read the data from
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern cvmx_nand_status_t cvmx_nand_page_write(int chip, uint64_t nand_address, uint64_t buffer_address);
+
+/**
+ * Erase a NAND block. A single block contains multiple pages.
+ *
+ * @chip:   Chip select for NAND flash
+ * @nand_address:
+ *               Location in NAND to erase. See description in file comment
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern cvmx_nand_status_t cvmx_nand_block_erase(int chip, uint64_t nand_address);
+
+/**
+ * Read the NAND ID information
+ *
+ * @chip:   Chip select for NAND flash
+ * @nand_address:
+ *               NAND address to read ID from. Usually this is either 0x0 or 0x20.
+ * @buffer_address:
+ *               Physical address to store data in
+ * @buffer_length:
+ *               Length of the buffer. Usually this is 4 bytes
+ *
+ * Returns Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern int cvmx_nand_read_id(int chip, uint64_t nand_address, uint64_t buffer_address, int buffer_length);
+
+/**
+ * Read the NAND parameter page
+ *
+ * @chip:   Chip select for NAND flash
+ * @buffer_address:
+ *               Physical address to store data in
+ * @buffer_length:
+ *               Length of the buffer. Usually this is 4 bytes
+ *
+ * Returns Bytes read on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern int cvmx_nand_read_param_page(int chip, uint64_t buffer_address, int buffer_length);
+
+/**
+ * Get the status of the NAND flash
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns NAND status or a negative cvmx_nand_status_t error code on failure
+ */
+extern int cvmx_nand_get_status(int chip);
+
+/**
+ * Get the page size, excluding out of band data. This  function
+ * will return zero for chip selects not connected to NAND.
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns Page size in bytes or a negative cvmx_nand_status_t error code on failure
+ */
+extern int cvmx_nand_get_page_size(int chip);
+
+/**
+ * Get the OOB size.
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns OOB in bytes or a negative cvmx_nand_status_t error code on failure
+ */
+extern int cvmx_nand_get_oob_size(int chip);
+
+/**
+ * Get the number of pages per NAND block
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns Numboer of pages in each block or a negative cvmx_nand_status_t error code on failure
+ */
+extern int cvmx_nand_get_pages_per_block(int chip);
+
+/**
+ * Get the number of blocks in the NAND flash
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns Number of blocks or a negative cvmx_nand_status_t error code on failure
+ */
+extern int cvmx_nand_get_blocks(int chip);
+
+/**
+ * Reset the NAND flash
+ *
+ * @chip:   Chip select for NAND flash
+ *
+ * Returns Zero on success, a negative cvmx_nand_status_t error code on failure
+ */
+extern cvmx_nand_status_t cvmx_nand_reset(int chip);
+
+/**
+ * This function computes the Octeon specific ECC data used by the NAND boot
+ * feature.
+ *
+ * @block:  pointer to 256 bytes of data
+ * @eccp:   pointer to where 8 bytes of ECC data will be stored
+ */
+extern void cvmx_nand_compute_boot_ecc(unsigned char *block, unsigned char *eccp);
+
+extern int cvmx_nand_correct_boot_ecc(uint8_t *block);
+
+#endif /* __CVMX_NAND_H__ */
diff --git a/arch/mips/include/asm/octeon/cvmx-ndf-defs.h b/arch/mips/include/asm/octeon/cvmx-ndf-defs.h
new file mode 100644
index 0000000..35a1c7f
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-ndf-defs.h
@@ -0,0 +1,278 @@
+/***********************license start***************
+ * Author: Cavium Inc.
+ *
+ * Contact: support@cavium.com
+ * This file is part of the OCTEON SDK
+ *
+ * Copyright (c) 2003-2012 Cavium Inc.
+ *
+ * This file is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License, Version 2, as
+ * published by the Free Software Foundation.
+ *
+ * This file is distributed in the hope that it will be useful, but
+ * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
+ * NONINFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this file; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
+ * or visit http://www.gnu.org/licenses/.
+ *
+ * This file may also be available under a different license from Cavium.
+ * Contact Cavium Inc. for more information
+ ***********************license end**************************************/
+
+#ifndef __CVMX_NDF_DEFS_H__
+#define __CVMX_NDF_DEFS_H__
+
+#define CVMX_NDF_BT_PG_INFO (CVMX_ADD_IO_SEG(0x0001070001000018ull))
+#define CVMX_NDF_CMD (CVMX_ADD_IO_SEG(0x0001070001000000ull))
+#define CVMX_NDF_DRBELL (CVMX_ADD_IO_SEG(0x0001070001000030ull))
+#define CVMX_NDF_ECC_CNT (CVMX_ADD_IO_SEG(0x0001070001000010ull))
+#define CVMX_NDF_INT (CVMX_ADD_IO_SEG(0x0001070001000020ull))
+#define CVMX_NDF_INT_EN (CVMX_ADD_IO_SEG(0x0001070001000028ull))
+#define CVMX_NDF_MISC (CVMX_ADD_IO_SEG(0x0001070001000008ull))
+#define CVMX_NDF_ST_REG (CVMX_ADD_IO_SEG(0x0001070001000038ull))
+
+union cvmx_ndf_bt_pg_info {
+	uint64_t u64;
+	struct cvmx_ndf_bt_pg_info_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_11_63:53;
+		uint64_t t_mult:4;
+		uint64_t adr_cyc:4;
+		uint64_t size:3;
+#else
+		uint64_t size:3;
+		uint64_t adr_cyc:4;
+		uint64_t t_mult:4;
+		uint64_t reserved_11_63:53;
+#endif
+	} s;
+	struct cvmx_ndf_bt_pg_info_s cn52xx;
+	struct cvmx_ndf_bt_pg_info_s cn63xx;
+	struct cvmx_ndf_bt_pg_info_s cn63xxp1;
+	struct cvmx_ndf_bt_pg_info_s cn66xx;
+	struct cvmx_ndf_bt_pg_info_s cn68xx;
+	struct cvmx_ndf_bt_pg_info_s cn68xxp1;
+};
+
+union cvmx_ndf_cmd {
+	uint64_t u64;
+	struct cvmx_ndf_cmd_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t nf_cmd:64;
+#else
+		uint64_t nf_cmd:64;
+#endif
+	} s;
+	struct cvmx_ndf_cmd_s cn52xx;
+	struct cvmx_ndf_cmd_s cn63xx;
+	struct cvmx_ndf_cmd_s cn63xxp1;
+	struct cvmx_ndf_cmd_s cn66xx;
+	struct cvmx_ndf_cmd_s cn68xx;
+	struct cvmx_ndf_cmd_s cn68xxp1;
+};
+
+union cvmx_ndf_drbell {
+	uint64_t u64;
+	struct cvmx_ndf_drbell_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_8_63:56;
+		uint64_t cnt:8;
+#else
+		uint64_t cnt:8;
+		uint64_t reserved_8_63:56;
+#endif
+	} s;
+	struct cvmx_ndf_drbell_s cn52xx;
+	struct cvmx_ndf_drbell_s cn63xx;
+	struct cvmx_ndf_drbell_s cn63xxp1;
+	struct cvmx_ndf_drbell_s cn66xx;
+	struct cvmx_ndf_drbell_s cn68xx;
+	struct cvmx_ndf_drbell_s cn68xxp1;
+};
+
+union cvmx_ndf_ecc_cnt {
+	uint64_t u64;
+	struct cvmx_ndf_ecc_cnt_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_32_63:32;
+		uint64_t xor_ecc:24;
+		uint64_t ecc_err:8;
+#else
+		uint64_t ecc_err:8;
+		uint64_t xor_ecc:24;
+		uint64_t reserved_32_63:32;
+#endif
+	} s;
+	struct cvmx_ndf_ecc_cnt_s cn52xx;
+	struct cvmx_ndf_ecc_cnt_s cn63xx;
+	struct cvmx_ndf_ecc_cnt_s cn63xxp1;
+	struct cvmx_ndf_ecc_cnt_s cn66xx;
+	struct cvmx_ndf_ecc_cnt_s cn68xx;
+	struct cvmx_ndf_ecc_cnt_s cn68xxp1;
+};
+
+union cvmx_ndf_int {
+	uint64_t u64;
+	struct cvmx_ndf_int_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_7_63:57;
+		uint64_t ovrf:1;
+		uint64_t ecc_mult:1;
+		uint64_t ecc_1bit:1;
+		uint64_t sm_bad:1;
+		uint64_t wdog:1;
+		uint64_t full:1;
+		uint64_t empty:1;
+#else
+		uint64_t empty:1;
+		uint64_t full:1;
+		uint64_t wdog:1;
+		uint64_t sm_bad:1;
+		uint64_t ecc_1bit:1;
+		uint64_t ecc_mult:1;
+		uint64_t ovrf:1;
+		uint64_t reserved_7_63:57;
+#endif
+	} s;
+	struct cvmx_ndf_int_s cn52xx;
+	struct cvmx_ndf_int_s cn63xx;
+	struct cvmx_ndf_int_s cn63xxp1;
+	struct cvmx_ndf_int_s cn66xx;
+	struct cvmx_ndf_int_s cn68xx;
+	struct cvmx_ndf_int_s cn68xxp1;
+};
+
+union cvmx_ndf_int_en {
+	uint64_t u64;
+	struct cvmx_ndf_int_en_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_7_63:57;
+		uint64_t ovrf:1;
+		uint64_t ecc_mult:1;
+		uint64_t ecc_1bit:1;
+		uint64_t sm_bad:1;
+		uint64_t wdog:1;
+		uint64_t full:1;
+		uint64_t empty:1;
+#else
+		uint64_t empty:1;
+		uint64_t full:1;
+		uint64_t wdog:1;
+		uint64_t sm_bad:1;
+		uint64_t ecc_1bit:1;
+		uint64_t ecc_mult:1;
+		uint64_t ovrf:1;
+		uint64_t reserved_7_63:57;
+#endif
+	} s;
+	struct cvmx_ndf_int_en_s cn52xx;
+	struct cvmx_ndf_int_en_s cn63xx;
+	struct cvmx_ndf_int_en_s cn63xxp1;
+	struct cvmx_ndf_int_en_s cn66xx;
+	struct cvmx_ndf_int_en_s cn68xx;
+	struct cvmx_ndf_int_en_s cn68xxp1;
+};
+
+union cvmx_ndf_misc {
+	uint64_t u64;
+	struct cvmx_ndf_misc_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_28_63:36;
+		uint64_t mb_dis:1;
+		uint64_t nbr_hwm:3;
+		uint64_t wait_cnt:6;
+		uint64_t fr_byt:11;
+		uint64_t rd_done:1;
+		uint64_t rd_val:1;
+		uint64_t rd_cmd:1;
+		uint64_t bt_dma:1;
+		uint64_t bt_dis:1;
+		uint64_t ex_dis:1;
+		uint64_t rst_ff:1;
+#else
+		uint64_t rst_ff:1;
+		uint64_t ex_dis:1;
+		uint64_t bt_dis:1;
+		uint64_t bt_dma:1;
+		uint64_t rd_cmd:1;
+		uint64_t rd_val:1;
+		uint64_t rd_done:1;
+		uint64_t fr_byt:11;
+		uint64_t wait_cnt:6;
+		uint64_t nbr_hwm:3;
+		uint64_t mb_dis:1;
+		uint64_t reserved_28_63:36;
+#endif
+	} s;
+	struct cvmx_ndf_misc_cn52xx {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_27_63:37;
+		uint64_t nbr_hwm:3;
+		uint64_t wait_cnt:6;
+		uint64_t fr_byt:11;
+		uint64_t rd_done:1;
+		uint64_t rd_val:1;
+		uint64_t rd_cmd:1;
+		uint64_t bt_dma:1;
+		uint64_t bt_dis:1;
+		uint64_t ex_dis:1;
+		uint64_t rst_ff:1;
+#else
+		uint64_t rst_ff:1;
+		uint64_t ex_dis:1;
+		uint64_t bt_dis:1;
+		uint64_t bt_dma:1;
+		uint64_t rd_cmd:1;
+		uint64_t rd_val:1;
+		uint64_t rd_done:1;
+		uint64_t fr_byt:11;
+		uint64_t wait_cnt:6;
+		uint64_t nbr_hwm:3;
+		uint64_t reserved_27_63:37;
+#endif
+	} cn52xx;
+	struct cvmx_ndf_misc_s cn63xx;
+	struct cvmx_ndf_misc_s cn63xxp1;
+	struct cvmx_ndf_misc_s cn66xx;
+	struct cvmx_ndf_misc_s cn68xx;
+	struct cvmx_ndf_misc_s cn68xxp1;
+};
+
+union cvmx_ndf_st_reg {
+	uint64_t u64;
+	struct cvmx_ndf_st_reg_s {
+#ifdef __BIG_ENDIAN_BITFIELD
+		uint64_t reserved_16_63:48;
+		uint64_t exe_idle:1;
+		uint64_t exe_sm:4;
+		uint64_t bt_sm:4;
+		uint64_t rd_ff_bad:1;
+		uint64_t rd_ff:2;
+		uint64_t main_bad:1;
+		uint64_t main_sm:3;
+#else
+		uint64_t main_sm:3;
+		uint64_t main_bad:1;
+		uint64_t rd_ff:2;
+		uint64_t rd_ff_bad:1;
+		uint64_t bt_sm:4;
+		uint64_t exe_sm:4;
+		uint64_t exe_idle:1;
+		uint64_t reserved_16_63:48;
+#endif
+	} s;
+	struct cvmx_ndf_st_reg_s cn52xx;
+	struct cvmx_ndf_st_reg_s cn63xx;
+	struct cvmx_ndf_st_reg_s cn63xxp1;
+	struct cvmx_ndf_st_reg_s cn66xx;
+	struct cvmx_ndf_st_reg_s cn68xx;
+	struct cvmx_ndf_st_reg_s cn68xxp1;
+};
+
+#endif
diff --git a/drivers/mtd/nand/nand_base.c b/drivers/mtd/nand/nand_base.c
index b787dce..49cf8ba 100644
--- a/drivers/mtd/nand/nand_base.c
+++ b/drivers/mtd/nand/nand_base.c
@@ -3322,6 +3322,17 @@ ident_done:
 			break;
 	}
 
+#ifdef  CONFIG_CAVIUM_OCTEON_NAND
+        /*
+        * For Octeon, we treat all parts as 8 bit.  Force chip options
+        * to 8 bit when called with 8 bit busw
+        * XXX- there must be a cleaner way to do this XXX
+        */
+	chip->options &= ~( NAND_BUSWIDTH_16 | 
+			NAND_BUSWIDTH_AUTO | NAND_SUBPAGE_READ ) ;
+	busw = 0;
+#endif
+
 	if (chip->options & NAND_BUSWIDTH_AUTO) {
 		WARN_ON(chip->options & NAND_BUSWIDTH_16);
 		chip->options |= busw;
-- 
2.6.2

