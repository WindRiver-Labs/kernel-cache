From d15764c38876e97ac2284c8807cee4471ce60e12 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Sat, 5 Jul 2014 18:05:50 -0700
Subject: [PATCH 752/974] MIPS: OCTEON: Update S.E. to r107316

Signed-off-by: David Daney <david.daney@cavium.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 arch/mips/cavium-octeon/executive/cvmx-bootmem.c   |  14 +-
 arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c |   6 +-
 .../cavium-octeon/executive/cvmx-debug-remote.c    |   2 +-
 .../mips/cavium-octeon/executive/cvmx-debug-uart.c |  21 +-
 arch/mips/cavium-octeon/executive/cvmx-debug.c     |  21 +-
 .../cavium-octeon/executive/cvmx-fpa-resource.c    |  26 +-
 .../executive/cvmx-global-resources.c              |  16 ++
 .../mips/cavium-octeon/executive/cvmx-helper-agl.c |   4 +-
 .../mips/cavium-octeon/executive/cvmx-helper-bgx.c |  31 +-
 .../cavium-octeon/executive/cvmx-helper-board.c    |   4 +-
 .../mips/cavium-octeon/executive/cvmx-helper-cfg.c |  41 +--
 .../mips/cavium-octeon/executive/cvmx-helper-ilk.c | 115 ++++----
 .../mips/cavium-octeon/executive/cvmx-helper-npi.c |   4 +-
 .../mips/cavium-octeon/executive/cvmx-helper-pki.c |  94 +++---
 .../mips/cavium-octeon/executive/cvmx-helper-pko.c |   6 +-
 .../cavium-octeon/executive/cvmx-helper-pko3.c     |  11 +-
 .../cavium-octeon/executive/cvmx-helper-rgmii.c    |   6 +-
 .../cavium-octeon/executive/cvmx-helper-sgmii.c    |   6 +-
 .../cavium-octeon/executive/cvmx-helper-srio.c     |   4 +-
 .../cavium-octeon/executive/cvmx-helper-util.c     |   7 +-
 .../cavium-octeon/executive/cvmx-helper-xaui.c     |   7 +-
 arch/mips/cavium-octeon/executive/cvmx-helper.c    |  31 +-
 arch/mips/cavium-octeon/executive/cvmx-ilk.c       | 315 +++++++++++----------
 arch/mips/cavium-octeon/executive/cvmx-ipd.c       |  10 +-
 arch/mips/cavium-octeon/executive/cvmx-osm.c       |   4 +-
 arch/mips/cavium-octeon/executive/cvmx-pcie.c      |  11 +-
 .../cavium-octeon/executive/cvmx-pki-resources.c   |  66 ++++-
 arch/mips/cavium-octeon/executive/cvmx-pki.c       |  10 +-
 arch/mips/cavium-octeon/executive/cvmx-pko.c       |   6 +-
 .../mips/cavium-octeon/executive/cvmx-pko3-queue.c |  42 +--
 arch/mips/cavium-octeon/executive/cvmx-pko3.c      |  44 +--
 arch/mips/cavium-octeon/executive/cvmx-qlm.c       |   8 +-
 arch/mips/cavium-octeon/executive/cvmx-srio.c      |   4 +-
 arch/mips/cavium-octeon/executive/cvmx-twsi.c      |   3 -
 arch/mips/cavium-octeon/executive/cvmx-usb.c       |   2 +-
 arch/mips/include/asm/octeon/cvmx-atomic.h         |  69 +++--
 arch/mips/include/asm/octeon/cvmx-coremask.h       |  12 +-
 arch/mips/include/asm/octeon/cvmx-fpa.h            |   8 +-
 arch/mips/include/asm/octeon/cvmx-fpa3.h           |  82 ++++--
 .../include/asm/octeon/cvmx-global-resources.h     |   1 +
 arch/mips/include/asm/octeon/cvmx-helper-agl.h     |   2 +-
 arch/mips/include/asm/octeon/cvmx-helper-bgx.h     |  40 +--
 arch/mips/include/asm/octeon/cvmx-helper-cfg.h     |   6 +-
 arch/mips/include/asm/octeon/cvmx-helper-ilk.h     |   4 +-
 arch/mips/include/asm/octeon/cvmx-helper-npi.h     |   6 +-
 arch/mips/include/asm/octeon/cvmx-helper-pki.h     |  19 +-
 arch/mips/include/asm/octeon/cvmx-helper-rgmii.h   |   8 +-
 arch/mips/include/asm/octeon/cvmx-helper-sgmii.h   |   6 +-
 arch/mips/include/asm/octeon/cvmx-helper-srio.h    |   8 +-
 arch/mips/include/asm/octeon/cvmx-helper-util.h    |   8 +-
 arch/mips/include/asm/octeon/cvmx-helper-xaui.h    |  12 +-
 arch/mips/include/asm/octeon/cvmx-helper.h         |  44 ++-
 arch/mips/include/asm/octeon/cvmx-hwfau.h          |   3 +-
 arch/mips/include/asm/octeon/cvmx-hwpko.h          |   6 +-
 arch/mips/include/asm/octeon/cvmx-ilk.h            |   4 +-
 arch/mips/include/asm/octeon/cvmx-l2c.h            |   5 +-
 arch/mips/include/asm/octeon/cvmx-pip.h            |  10 +-
 arch/mips/include/asm/octeon/cvmx-pki-resources.h  |  20 ++
 arch/mips/include/asm/octeon/cvmx-pki.h            |  14 +-
 arch/mips/include/asm/octeon/cvmx-pko3.h           |  11 +-
 arch/mips/include/asm/octeon/cvmx-pow.h            |   4 +-
 arch/mips/include/asm/octeon/cvmx-qlm.h            |  16 +-
 arch/mips/include/asm/octeon/cvmx-spinlock.h       |  36 +--
 arch/mips/include/asm/octeon/cvmx-uart.h           |   4 +-
 arch/mips/include/asm/octeon/cvmx-usb.h            |   2 +-
 arch/mips/include/asm/octeon/octeon-boot-info.h    |   1 -
 arch/mips/include/asm/octeon/octeon-feature.h      |   2 +-
 arch/mips/include/asm/octeon/octeon-model.h        |   6 +-
 68 files changed, 867 insertions(+), 614 deletions(-)

diff --git a/arch/mips/cavium-octeon/executive/cvmx-bootmem.c b/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
index 86b61db..23441ec 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-bootmem.c
@@ -43,7 +43,7 @@
  * Simple allocate only memory allocator.  Used to allocate memory at
  * application start time.
  *
- * <hr>$Revision: 104081 $<hr>
+ * <hr>$Revision: 106450 $<hr>
  *
  */
 
@@ -648,10 +648,20 @@ int cvmx_bootmem_free_named(const char *name)
 }
 #endif
 
+/**
+ * Find a named block with flags
+ *
+ * @param name is the block name
+ * @param flags indicates the need to use locking during search
+ * @return pointer to named block descriptor
+ *
+ * Note: this function returns a pointer to a static structure,
+ * and is therefore not re-entrant.
+ * Making this function re-entrant will break backward compatibility.
+ */
 const cvmx_bootmem_named_block_desc_t *
 __cvmx_bootmem_find_named_block_flags(const char *name, uint32_t flags)
 {
-	/* FIXME: Returning a single static object is probably a bad thing */
 	static cvmx_bootmem_named_block_desc_t desc;
 	uint64_t named_addr = cvmx_bootmem_phy_named_block_find(name, flags);
 	if (named_addr) {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c b/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
index c213b22..781c3fd 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-cmd-queue.c
@@ -43,7 +43,7 @@
  * Support functions for managing command queues used for
  * various hardware blocks.
  *
- * <hr>$Revision: 103822 $<hr>
+ * <hr>$Revision: 106435 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <linux/export.h>
@@ -262,7 +262,7 @@ int cvmx_cmd_queue_length(cvmx_cmd_queue_id_t queue_id)
 	switch ((cvmx_cmd_queue_id_t) (queue_id & 0xff0000)) {
 	case CVMX_CMD_QUEUE_PKO_BASE:
 		/*
-		 * FIXME: Need atomic lock on
+		 * Really need atomic lock on
 		 * CVMX_PKO_REG_READ_IDX. Right now we are normally
 		 * called with the queue lock, so that is a SLIGHT
 		 * amount of protection.
@@ -284,7 +284,7 @@ int cvmx_cmd_queue_length(cvmx_cmd_queue_id_t queue_id)
 	case CVMX_CMD_QUEUE_DFA:
 	case CVMX_CMD_QUEUE_HNA:
 	case CVMX_CMD_QUEUE_RAID:
-		/* FIXME: Implement other lengths */
+		/* Still need to implement other lengths */
 		return 0;
 	case CVMX_CMD_QUEUE_DMA_BASE:
 		if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-debug-remote.c b/arch/mips/cavium-octeon/executive/cvmx-debug-remote.c
index 43dc232..ebaed84 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-debug-remote.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-debug-remote.c
@@ -71,7 +71,7 @@ static int cvmx_debug_remote_mem_wait_for_resume(volatile cvmx_debug_core_contex
 
 static void cvmx_debug_memory_change_core(int oldcore, int newcore)
 {
-	/* FIXME, this should change the core on the host side too. */
+	/* This should cause the host gdb to change the core but there is no way to signal to it, the core has changed. */
 }
 
 cvmx_debug_comm_t cvmx_debug_remote_comm = {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-debug-uart.c b/arch/mips/cavium-octeon/executive/cvmx-debug-uart.c
index 54441c6..5832e74 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-debug-uart.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-debug-uart.c
@@ -64,6 +64,8 @@ int cvmx_debug_uart = 1;
 
 #ifdef CVMX_BUILD_FOR_TOOLCHAIN
 #pragma weak cvmx_uart_enable_intr
+#pragma weak cvmx_uart_mask_intr_on_core
+#pragma weak cvmx_uart_unmask_intr_on_core
 int cvmx_debug_uart = 1;
 #endif
 
@@ -227,16 +229,15 @@ static int cvmx_debug_uart_putpacket(char *packet)
 static void cvmx_debug_uart_change_core(int oldcore, int newcore)
 {
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
-	cvmx_ciu_intx0_t irq_control;
-
-	irq_control.u64 = cvmx_read_csr(CVMX_CIU_INTX_EN0(newcore * 2));
-	irq_control.s.uart |= (1u << cvmx_debug_uart);
-	cvmx_write_csr(CVMX_CIU_INTX_EN0(newcore * 2), irq_control.u64);
-
-	/* Disable interrupts to this core since he is about to die */
-	irq_control.u64 = cvmx_read_csr(CVMX_CIU_INTX_EN0(oldcore * 2));
-	irq_control.s.uart &= ~(1u << cvmx_debug_uart);
-	cvmx_write_csr(CVMX_CIU_INTX_EN0(oldcore * 2), irq_control.u64);
+	/* Change which core controls the uart interrupt.  */
+# ifdef CVMX_BUILD_FOR_TOOLCHAIN
+	if (cvmx_uart_mask_intr_on_core)
+# endif
+	  cvmx_uart_unmask_intr_on_core(cvmx_debug_uart, newcore);
+# ifdef CVMX_BUILD_FOR_TOOLCHAIN
+	if (cvmx_uart_mask_intr_on_core)
+# endif
+	  cvmx_uart_mask_intr_on_core(cvmx_debug_uart, oldcore);
 #endif
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-debug.c b/arch/mips/cavium-octeon/executive/cvmx-debug.c
index 756599c..ccf8a73 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-debug.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-debug.c
@@ -490,15 +490,12 @@ static int cvmx_debug_putcorepacket(char *buf, int core)
 	if (core < 10) {
 		packet[6] = ' ';
 		packet[7] = core + '0';
-	} else if (core < 20) {
-		packet[6] = '1';
-		packet[7] = core - 10 + '0';
-	} else if (core < 30) {
-		packet[6] = '2';
-		packet[7] = core - 20 + '0';
+	} else if (core < 100) {
+		packet[6] = (core / 10) + '0';
+		packet[7] = (core % 10) + '0';
 	} else {
-		packet[6] = '3';
-		packet[7] = core - 30 + '0';
+		packet[6] = '?';
+		packet[7] = '?';
 	}
 	return cvmx_debug_putpacket_noformat(packet);
 }
@@ -737,7 +734,7 @@ static cvmx_debug_command_t cvmx_debug_process_packet(const char *packet)
 
 			/* The focus core must be in the active_cores mask */
 			if ((state.active_cores & (1ull << state.focus_core)) == 0) {
-				cvmx_debug_putpacket_noformat("!Focus core was added to the masked.");
+				cvmx_debug_putpacket_noformat("!Focus core was added to the mask.");
 				state.active_cores |= 1ull << state.focus_core;
 			}
 
@@ -1327,9 +1324,9 @@ static int cvmx_debug_event_loop(cvmx_debug_register_t * debug_reg, volatile cvm
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 			cvmx_coremask_t cm = CVMX_COREMASK_EMPTY;
 
-			/* FIXME: Debugger is limited at 64 cores */
+			/* Note: Debugger is limited at 64 cores */
 			cvmx_coremask_set64(&cm, state.handler_cores);
-			/* FIXME, this should a sync not based on cvmx_coremask_barrier_sync.  */
+			/* This should a sync not based on cvmx_coremask_barrier_sync.  */
 			/* Sync up.  */
 			cvmx_coremask_barrier_sync(&cm);
 #endif
@@ -1624,7 +1621,7 @@ void cvmx_debug_finish(void)
 	if (state.ever_been_in_debug)
 		cvmx_debug_putcorepacket("finished.", coreid);
 
-	/* FIXME: Debugger is limited at 64 cores */
+	/* Note: The Debugger is limited at 64 cores */
 	cvmx_coremask_set64(&cm, state.core_finished);
 
 	/* Notify the debugger if all cores have completed the program */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c b/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
index 6f9d6c4..6dc06ce 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-fpa-resource.c
@@ -247,10 +247,10 @@ int cvmx_fpa1_release_pool(cvmx_fpa1_pool_t pool)
 		cvmx_free_global_resource_range_multiple(tag, &pool, 1);
 }
 
-/* 
- * FIXME:
- * An easier way to acheive the same would be to
- * query the block size of a "pool"
+/**
+ * Query if an FPA pool is available for reservation
+ * using global resources
+ * @note This function is no longer in use, and will be removed in a future release
  */
 int cvmx_fpa1_is_pool_available(cvmx_fpa1_pool_t pool)
 {
@@ -260,11 +260,14 @@ int cvmx_fpa1_is_pool_available(cvmx_fpa1_pool_t pool)
 	return 1;
 }
 
+/**
+ * @INTERNAL
+ *
+ * This function is no longer in use, and will be removed in a future release
+ */
 int cvmx_fpa3_is_pool_available(int node, int lpool)
 {
 	cvmx_fpa3_pool_t pool;
-	if (lpool < 0)
-		return 1;
 
 	pool = cvmx_fpa3_reserve_pool(node, lpool);
 
@@ -275,13 +278,15 @@ int cvmx_fpa3_is_pool_available(int node, int lpool)
 	return 1;
 }
 
+/**
+ * @INTERNAL
+ *
+ * This function is no longer in use, and will be removed in a future release
+ */
 int cvmx_fpa3_is_aura_available(int node, int laura)
 {
 	cvmx_fpa3_gaura_t aura;
 
-	if (laura < 0)
-		return 1;
-
 	aura = cvmx_fpa3_reserve_aura(node, laura);
 
 	if (!__cvmx_fpa3_aura_valid(aura))
@@ -293,9 +298,10 @@ int cvmx_fpa3_is_aura_available(int node, int laura)
 
 /**
  * Return if aura/pool is already reserved
- * @param node - node of fpa to check, -1 for current node
  * @param pool_num - pool to check (aura for o78+)
  * @return 0 if reserved, 1 if available
+ *
+ * @note This function is no longer in use, and will be removed in a future release
  */
 int cvmx_fpa_is_pool_available(int pool_num)
 {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-global-resources.c b/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
index 7d3f0f6..364b0b6 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-global-resources.c
@@ -482,6 +482,10 @@ int cvmx_free_global_resource_range_with_base(struct global_resource_tag tag,
 	uint64_t addr = cvmx_get_global_resource(tag,1);
 	int rv;
 
+	/* Resource was not created, nothing to release */
+	if (addr == 0)
+		return 0;
+
 	__cvmx_global_resource_lock();
 	rv = cvmx_range_free_with_base(addr, base, nelements);
 	__cvmx_global_resource_unlock();
@@ -494,6 +498,10 @@ int cvmx_free_global_resource_range_multiple(struct global_resource_tag tag,
 	uint64_t addr = cvmx_get_global_resource(tag,1);
 	int rv;
 
+	/* Resource was not created, nothing to release */
+	if (addr == 0)
+		return 0;
+
 	__cvmx_global_resource_lock();
 	rv = cvmx_range_free_mutiple(addr, bases, nelements);
 	__cvmx_global_resource_unlock();
@@ -506,6 +514,10 @@ int cvmx_free_global_resource_range_with_owner(struct global_resource_tag tag,
 	uint64_t addr = cvmx_get_global_resource(tag,1);
 	int rv;
 
+	/* Resource was not created, nothing to release */
+	if (addr == 0)
+		return 0;
+
 	__cvmx_global_resource_lock();
 	rv = cvmx_range_free_with_owner(addr, owner);
 	__cvmx_global_resource_unlock();
@@ -560,6 +572,10 @@ uint64_t cvmx_get_global_resource_owner(struct global_resource_tag tag, int base
 {
 	uint64_t addr = cvmx_get_global_resource(tag, 1);
 
+	/* Resource was not created, return "available" special owner code */
+	if (addr == 0)
+		return -88LL;
+
 	return cvmx_range_get_owner(addr, base);
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c b/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
index 1d43c49..93e19ca 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-agl.c
@@ -76,7 +76,7 @@ int __cvmx_helper_agl_enumerate(int xiface)
  * @INTERNAL
  * Convert interface to port to assess CSRs.
  *
- * @param interface  Interface to probe
+ * @param xiface  Interface to probe
  * @return  The port corresponding to the interface
  */
 int cvmx_helper_agl_get_port(int xiface)
@@ -129,7 +129,7 @@ int __cvmx_helper_agl_probe(int interface)
 	/* MII clocks counts are based on the 125Mhz reference, so our
 	 * delays need to be scaled to match the core clock rate. The
 	 * "+1" is to make sure rounding always waits a little too
-	 * long. FIXME.
+	 * long.
 	 */
 	clock_scale = cvmx_clock_get_rate(CVMX_CLOCK_CORE) / 125000000 + 1;
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
index b1b6694..08d15c5 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-bgx.c
@@ -80,7 +80,6 @@ int __cvmx_helper_bgx_enumerate(int xiface)
 
 	mode = cvmx_qlm_get_mode_cn78xx(node, qlm);
 	if (mode == CVMX_QLM_MODE_SGMII) {
-	/* FIXME: Check here if SGMII is a MIX interface */
 		return 4;
 	} else if (mode == CVMX_QLM_MODE_XAUI
 		   || mode == CVMX_QLM_MODE_XLAUI
@@ -99,7 +98,7 @@ int __cvmx_helper_bgx_enumerate(int xiface)
  * @INTERNAL
  * Disable the BGX port
  *
- * @param  IPD port of the BGX interface to disable
+ * @param xipd_port IPD port of the BGX interface to disable
  */
 void cvmx_helper_bgx_disable(int xipd_port)
 {
@@ -125,9 +124,8 @@ void cvmx_helper_bgx_disable(int xipd_port)
  * @INTERNAL
  * Configure the bgx mac.
  *
- * @param interface Interface to bring up
- *
- * @param mode      Mode to configure the bgx mac as
+ * @param xiface Interface to bring up
+ * @param index  port on interface to bring up
  */
 static void __cvmx_bgx_common_init(int xiface, int index)
 {
@@ -236,7 +234,7 @@ static void __cvmx_bgx_common_init_pknd(int xiface, int index)
  * connected to it. The SGMII interface should still be down after
  * this call. This is used by interfaces using the bgx mac.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
@@ -255,7 +253,7 @@ EXPORT_SYMBOL(__cvmx_helper_bgx_probe);
  * @INTERNAL
  * Perform initialization required only once for an SGMII port.
  *
- * @param interface Interface to init
+ * @param xiface Interface to init
  * @param index     Index of prot on the interface
  *
  * @return Zero on success, negative on failure
@@ -335,7 +333,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_one_time(int xiface, int index)
  * leave I/O disabled using the GMX override. This function
  * follows the bringup documented in 10.6.3 of the manual.
  *
- * @param interface Interface to bringup
+ * @param xiface Interface to bringup
  * @param num_ports Number of ports on the interface
  *
  * @return Zero on success, negative on failure
@@ -379,7 +377,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init(int xiface, int num_ports)
  * enabled but PKO disabled. This is used by interfaces using
  * the bgx mac.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
@@ -398,7 +396,7 @@ int __cvmx_helper_bgx_sgmii_enable(int xiface)
  * Initialize the SERTES link for the first time or after a loss
  * of link.
  *
- * @param interface Interface to init
+ * @param xiface Interface to init
  * @param index     Index of prot on the interface
  *
  * @return Zero on success, negative on failure
@@ -473,7 +471,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link(int xiface, int index)
  * Configure an SGMII link to the specified speed after the SERTES
  * link is up.
  *
- * @param interface Interface to init
+ * @param xiface Interface to init
  * @param index     Index of prot on the interface
  * @param link_info Link state to configure
  *
@@ -600,7 +598,7 @@ static int __cvmx_helper_bgx_sgmii_hardware_init_link_speed(int xiface,
  * the last call to cvmx_helper_link_set(). This is used by
  * interfaces using the bgx mac.
  *
- * @param ipd_port IPD/PKO port to query
+ * @param xipd_port IPD/PKO port to query
  *
  * @return Link state
  */
@@ -702,7 +700,7 @@ int cvmx_helper_bgx_errata_22429(int xipd_port, int link_up)
  * cvmx_helper_link_autoconf() instead. This is used by interfaces
  * using the bgx mac.
  *
- * @param ipd_port  IPD/PKO port to configure
+ * @param xipd_port  IPD/PKO port to configure
  * @param link_info The new link state
  *
  * @return Zero on success, negative on failure
@@ -763,7 +761,8 @@ int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
  * Bringup XAUI interface. After this call packet I/O should be
  * fully functional.
  *
- * @param interface Interface to bring up
+ * @param index port on interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
@@ -791,7 +790,6 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 	if (mode == CVMX_HELPER_INTERFACE_MODE_10G_KR
 	    || mode == CVMX_HELPER_INTERFACE_MODE_40G_KR4) {
 		use_training = 1;
-		/* FIXME: disabled as it currently doesn't work */
 		use_auto_neg = 0;
 	}
 
@@ -851,7 +849,6 @@ static int __cvmx_helper_bgx_xaui_init(int index, int xiface)
 
 		/* 4b. Write BGX(0..5)_SPU(0..3)_CONTROL1[LO_PWR] = 1 and
 		     BGX(0..5)_SPU(0..3)_MISC_CONTROL[RX_PACKET_DIS] = 1. */
-		/* FIXME it is already dine in step 2 */
 		spu_control1.u64 = cvmx_read_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface));
 		spu_control1.s.lo_pwr = 1;
 		cvmx_write_csr_node(node, CVMX_BGXX_SPUX_CONTROL1(index, interface), spu_control1.u64);
@@ -1029,7 +1026,7 @@ EXPORT_SYMBOL(__cvmx_helper_bgx_port_init);
  * causes packets received from the wire to sent out again. This is used by
  * interfaces using the bgx mac.
  *
- * @param ipd_port IPD/PKO port to loopback.
+ * @param xipd_port IPD/PKO port to loopback.
  * @param enable_internal
  *                 Non zero if you want internal loopback
  * @param enable_external
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
index 1c49350..2465fd2 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-board.c
@@ -159,7 +159,7 @@ static void cvmx_retry_i2c_write(int twsi_id, uint8_t dev_addr,
  * Returns the Ethernet node offset in the device tree
  *
  * @param     fdt_addr - pointer to flat device tree in memory
- * @param     alias    - offset of alias in device tree
+ * @param     aliases    - offset of alias in device tree
  * @param     ipd_port - ipd port number to look up
  *
  * @returns   offset of Ethernet node if >= 0, error if -1
@@ -1211,7 +1211,7 @@ int __get_phy_info_from_dt(cvmx_phy_info_t *phy_info, int ipd_port)
  * This function outputs the cvmx_phy_info_t data structure for the specified
  * port.
  *
- * @param - phy_info - phy info data structure
+ * @param phy_info - phy info data structure
  * @param ipd_port - port to get phy info for
  *
  * @return 0 for success, -1 if info not available
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
index a1cc29e..fdba105 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-cfg.c
@@ -652,7 +652,7 @@ int __cvmx_helper_cfg_pko_port_eid(int pko_port)
 #define IPD2PKO_CACHE_Y(ipd_port)	(ipd_port) >> 8
 #define IPD2PKO_CACHE_X(ipd_port)	(ipd_port) & 0xff
 
-inline int __cvmx_helper_cfg_ipd2pko_cachex(int ipd_port)
+static inline int __cvmx_helper_cfg_ipd2pko_cachex(int ipd_port)
 {
 	int ipd_x = IPD2PKO_CACHE_X(ipd_port);
 	if (ipd_port & 0x800)
@@ -790,7 +790,7 @@ static int cvmx_helper_cfg_init_pko_iports_and_queues_using_static_config(void)
 /**
  * Returns if port is valid for a given interface
  *
- * @param interface  interface to check
+ * @param xiface  interface to check
  * @param index      port index in the interface
  *
  * @return status of the port present or not.
@@ -1016,26 +1016,31 @@ int __cvmx_helper_init_port_config_data(void)
 		cvmx_printf("%s:\n",__func__);
 
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
+		int node;
 		/* PKO3: only needs BPID, PKND to be setup,
 		 * while the rest of PKO3 init is done in cvmx-helper-pko3.c
 		 */
-		for (i = 0; i < cvmx_helper_get_number_of_interfaces(); i++) {
-			n = cvmx_helper_interface_enumerate(i);
-			if (cvmx_helper_interface_get_mode(i) !=
-				CVMX_HELPER_INTERFACE_MODE_NPI) {
-				for (j = 0; j < n; j++) {
-					cvmx_cfg_port[0][i][j].ccpp_pknd = pknd++;
-					cvmx_cfg_port[0][i][j].ccpp_bpid = bpid++;
-				}
-			} else {
-				for (j = 0; j < n; j++) {
-					cvmx_cfg_port[0][i][j].ccpp_pknd = pknd;
-					cvmx_cfg_port[0][i][j].ccpp_bpid = bpid;
+		for (node = 0; node < CVMX_MAX_NODES; node++) {
+			pknd = 0;
+			bpid = 0;
+			for (i = 0; i < cvmx_helper_get_number_of_interfaces(); i++) {
+				n = cvmx_helper_interface_enumerate(i);
+				if (cvmx_helper_interface_get_mode(i) !=
+					CVMX_HELPER_INTERFACE_MODE_NPI) {
+					for (j = 0; j < n; j++) {
+						cvmx_cfg_port[node][i][j].ccpp_pknd = pknd++;
+						cvmx_cfg_port[node][i][j].ccpp_bpid = bpid++;
+					}
+				} else {
+					for (j = 0; j < n; j++) {
+						cvmx_cfg_port[node][i][j].ccpp_pknd = pknd;
+						cvmx_cfg_port[node][i][j].ccpp_bpid = bpid;
+					}
+					pknd++;
+					bpid++;
 				}
-				pknd++;
-				bpid++;
-			}
-		} /* for i=0 */
+			} /* for i=0 */
+		}
 		cvmx_helper_cfg_assert(pknd <= CVMX_HELPER_CFG_MAX_PIP_PKND);
 		cvmx_helper_cfg_assert(bpid <= CVMX_HELPER_CFG_MAX_PIP_BPID);
 	} else if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
index edce8bd..7ac0e5e 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-ilk.c
@@ -74,7 +74,7 @@ int __cvmx_helper_ilk_enumerate(int xiface)
 {
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	xi.interface -= CVMX_ILK_GBL_BASE();
-	return cvmx_ilk_chans[xi.interface];
+	return cvmx_ilk_chans[xi.node][xi.interface];
 }
 
 /**
@@ -85,19 +85,21 @@ int __cvmx_helper_ilk_enumerate(int xiface)
  * entry is assigned a different pko pipe while in the xoff state, the old pko 
  * pipe will stay in the xoff state even when no longer used by ilk.
  *
- * @param interface Interface whose calendar are to be initialized.
+ * @param intf Interface whose calendar are to be initialized.
  */
-void __cvmx_ilk_init_cal_cn78xx(int interface)
+void __cvmx_ilk_init_cal_cn78xx(int intf)
 {
 	cvmx_ilk_txx_cal_entryx_t	tx_entry;
 	cvmx_ilk_rxx_cal_entryx_t	rx_entry;
 	int				i;
+	int node = (intf >> 4) & 0xf;
+	int interface = (intf & 0xf);
 
 	/* Initialize all tx calendar entries to off */
 	tx_entry.u64 = 0;
 	tx_entry.s.ctl = XOFF;
 	for (i = 0; i < CVMX_ILK_MAX_CAL_IDX; i++) {
-		cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(i, interface),
+		cvmx_write_csr_node(node, CVMX_ILK_TXX_CAL_ENTRYX(i, interface),
 			       tx_entry.u64);
 	}
 
@@ -105,7 +107,7 @@ void __cvmx_ilk_init_cal_cn78xx(int interface)
 	rx_entry.u64 = 0;
 	rx_entry.s.ctl = XOFF;
 	for (i = 0; i < CVMX_ILK_MAX_CAL_IDX; i++) {
-		cvmx_write_csr(CVMX_ILK_RXX_CAL_ENTRYX(i, interface),
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_CAL_ENTRYX(i, interface),
 			       rx_entry.u64);
 	}
 }
@@ -285,7 +287,7 @@ void __cvmx_ilk_write_tx_cal_entry_cn68xx(int interface,
 	cvmx_write_csr(CVMX_ILK_TXX_MEM_CAL1(interface), tx_cal1.u64);
 }
 
-void __cvmx_ilk_write_tx_cal_entry_cn78xx(int interface,
+void __cvmx_ilk_write_tx_cal_entry_cn78xx(int intf,
 					  int channel,
 					  unsigned char bpid)
 {
@@ -293,18 +295,20 @@ void __cvmx_ilk_write_tx_cal_entry_cn78xx(int interface,
 	int calender_16_block = channel / 15;
 	int calender_16_index = channel % 15 + 1;
 	int index = calender_16_block * 16 + calender_16_index;
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
 	/* Program the link status on first channel */
 	if (calender_16_index == 1) {
 		tx_cal.u64 = 0;
 		tx_cal.s.ctl = 1;
-		cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(index - 1, interface),
+		cvmx_write_csr_node(node, CVMX_ILK_TXX_CAL_ENTRYX(index - 1, interface),
 				tx_cal.u64);
 	}
 	tx_cal.u64 = 0;
 	tx_cal.s.ctl = 0;
 	tx_cal.s.channel = channel;
-	cvmx_write_csr(CVMX_ILK_TXX_CAL_ENTRYX(index, interface), tx_cal.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_TXX_CAL_ENTRYX(index, interface), tx_cal.u64);
 }
 	
 /**
@@ -325,7 +329,7 @@ void __cvmx_ilk_write_tx_cal_entry(int			interface,
 		__cvmx_ilk_write_tx_cal_entry_cn78xx(interface, channel, bpid);
 }
 
-void __cvmx_ilk_write_rx_cal_entry_cn78xx(int interface,
+void __cvmx_ilk_write_rx_cal_entry_cn78xx(int intf,
 					  int channel,
 					  unsigned char bpid)
 {
@@ -333,18 +337,20 @@ void __cvmx_ilk_write_rx_cal_entry_cn78xx(int interface,
 	int calender_16_block = channel / 15;
 	int calender_16_index = channel % 15 + 1;
 	int index = calender_16_block * 16 + calender_16_index;
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
 	/* Program the link status on first channel */
 	if (calender_16_index == 1) {
 		rx_cal.u64 = 0;
 		rx_cal.s.ctl = 1;
-		cvmx_write_csr(CVMX_ILK_RXX_CAL_ENTRYX(index - 1, interface),
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_CAL_ENTRYX(index - 1, interface),
 				rx_cal.u64);
 	}
 	rx_cal.u64 = 0;
 	rx_cal.s.ctl = 0;
 	rx_cal.s.channel = channel;
-	cvmx_write_csr(CVMX_ILK_RXX_CAL_ENTRYX(index, interface), rx_cal.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_CAL_ENTRYX(index, interface), rx_cal.u64);
 }
 
 void __cvmx_ilk_write_rx_cal_entry_cn68xx(int interface,
@@ -457,7 +463,7 @@ void __cvmx_ilk_write_rx_cal_entry(int			interface,
  * connected to it. The ILK interface should still be down
  * after this call.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
@@ -475,11 +481,12 @@ int __cvmx_helper_ilk_probe(int xiface)
 		return 0;
 
 	/* the configuration should be done only once */
-	if (cvmx_ilk_get_intf_ena(interface))
-		return cvmx_ilk_chans[interface];
+	if (cvmx_ilk_get_intf_ena(xiface))
+		return cvmx_ilk_chans[xi.node][interface];
 
 	/* configure lanes and enable the link */
-	res = cvmx_ilk_start_interface(interface, cvmx_ilk_lane_mask[interface]);
+	res = cvmx_ilk_start_interface(((xi.node << 4) | interface),
+			cvmx_ilk_lane_mask[xi.node][interface]);
 	if (res < 0)
 		return 0;
 
@@ -498,8 +505,10 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 	int enable_rx_cal = 1;
 	int interface;
 	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int intf;
 
 	interface = xi.interface - CVMX_ILK_GBL_BASE();
+	intf = (xi.node << 4) | interface;
 	if (interface >= CVMX_NUM_ILK_INTF)
 		return 0;
 
@@ -517,7 +526,7 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 			return 0;
 		}
 
-		res = cvmx_ilk_set_pipe(interface, pipe_base, cvmx_ilk_chans[interface]);
+		res = cvmx_ilk_set_pipe(xiface, pipe_base, cvmx_ilk_chans[0][interface]);
 		if (res < 0)
 			return 0;
 
@@ -536,19 +545,19 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 
 		memset(pch, 0, CVMX_ILK_MAX_CHANS * sizeof(cvmx_ilk_pipe_chan_t));
 		tmp = pch;
-		for (j = 0; j < cvmx_ilk_chans[interface]; j++) {
+		for (j = 0; j < cvmx_ilk_chans[0][interface]; j++) {
 			tmp->pipe = i++;
 			tmp->chan = cvmx_ilk_chan_map[interface][j];
 			tmp++;
 		}
-		res = cvmx_ilk_tx_set_channel(interface, pch, cvmx_ilk_chans[interface]);
+		res = cvmx_ilk_tx_set_channel(interface, pch, cvmx_ilk_chans[0][interface]);
 		if (res < 0) {
 			res = 0;
 			goto err_free_pch;
 		}
-		pipe_base += cvmx_ilk_chans[interface];
+		pipe_base += cvmx_ilk_chans[0][interface];
 	} else if (OCTEON_IS_MODEL(OCTEON_CN78XX))
-		pipe_base = pknd_base + cvmx_ilk_chans[interface];
+		pipe_base = pknd_base + cvmx_ilk_chans[xi.node][interface];
 
 	i = pknd_base;
 	if (chpknd == NULL) {
@@ -559,7 +568,7 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 		    cvmx_bootmem_alloc(CVMX_ILK_MAX_PKNDS * sizeof(cvmx_ilk_chan_pknd_t), sizeof(cvmx_ilk_chan_pknd_t));
 #endif
 		if (chpknd == NULL) {
-			pipe_base -= cvmx_ilk_chans[interface];
+			pipe_base -= cvmx_ilk_chans[xi.node][interface];
 			res = 0;
 			goto err_free_pch;
 		}
@@ -567,19 +576,19 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 
 	memset(chpknd, 0, CVMX_ILK_MAX_PKNDS * sizeof(cvmx_ilk_chan_pknd_t));
 	tmp1 = chpknd;
-	for (j = 0; j < cvmx_ilk_chans[interface]; j++) {
+	for (j = 0; j < cvmx_ilk_chans[xi.node][interface]; j++) {
 		tmp1->chan = cvmx_ilk_chan_map[interface][j];
 		tmp1->pknd = i++;
 		tmp1++;
 	}
 
-	res = cvmx_ilk_rx_set_pknd(interface, chpknd, cvmx_ilk_chans[interface]);
+	res = cvmx_ilk_rx_set_pknd(xiface, chpknd, cvmx_ilk_chans[xi.node][interface]);
 	if (res < 0) {
-		pipe_base -= cvmx_ilk_chans[interface];
+		pipe_base -= cvmx_ilk_chans[xi.node][interface];
 		res = 0;
 		goto err_free_chpknd;
 	}
-	pknd_base += cvmx_ilk_chans[interface];
+	pknd_base += cvmx_ilk_chans[xi.node][interface];
 
 	/* Set up tx calendar */
 	if (calent == NULL) {
@@ -590,8 +599,8 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 		    cvmx_bootmem_alloc(CVMX_ILK_MAX_PIPES * sizeof(cvmx_ilk_cal_entry_t), sizeof(cvmx_ilk_cal_entry_t));
 #endif
 		if (calent == NULL) {
-			pipe_base -= cvmx_ilk_chans[interface];
-			pknd_base -= cvmx_ilk_chans[interface];
+			pipe_base -= cvmx_ilk_chans[xi.node][interface];
+			pknd_base -= cvmx_ilk_chans[xi.node][interface];
 			res = 0;
 			goto err_free_chpknd;
 		}
@@ -600,16 +609,16 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 	memset(calent, 0, CVMX_ILK_MAX_PIPES * sizeof(cvmx_ilk_cal_entry_t));
 	tmp1 = chpknd;
 	tmp2 = calent;
-	for (j = 0; j < cvmx_ilk_chans[interface]; j++) {
+	for (j = 0; j < cvmx_ilk_chans[xi.node][interface]; j++) {
 		tmp2->pipe_bpid = tmp1->pknd;
 		tmp2->ent_ctrl = PIPE_BPID;
 		tmp1++;
 		tmp2++;
 	}
-	res = cvmx_ilk_cal_setup_tx(interface, cvmx_ilk_chans[interface], calent, 1);
+	res = cvmx_ilk_cal_setup_tx(intf, cvmx_ilk_chans[xi.node][interface], calent, 1);
 	if (res < 0) {
-		pipe_base -= cvmx_ilk_chans[interface];
-		pknd_base -= cvmx_ilk_chans[interface];
+		pipe_base -= cvmx_ilk_chans[xi.node][interface];
+		pknd_base -= cvmx_ilk_chans[xi.node][interface];
 		res = 0;
 		goto err_free_calent;
 	}
@@ -620,7 +629,7 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 		memset(calent, 0, CVMX_ILK_MAX_PIPES * sizeof(cvmx_ilk_cal_entry_t));
 		tmp = pch;
 		tmp2 = calent;
-		for (j = 0; j < cvmx_ilk_chans[interface]; j++) {
+		for (j = 0; j < cvmx_ilk_chans[0][interface]; j++) {
 			tmp2->pipe_bpid = tmp->pipe;
 			tmp2->ent_ctrl = PIPE_BPID;
 			tmp++;
@@ -634,10 +643,10 @@ static int __cvmx_helper_ilk_init_port(int xiface)
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 		enable_rx_cal = 1;
 	}
-	res = cvmx_ilk_cal_setup_rx(interface, cvmx_ilk_chans[interface], calent, CVMX_ILK_RX_FIFO_WM, enable_rx_cal);
+	res = cvmx_ilk_cal_setup_rx(intf, cvmx_ilk_chans[xi.node][interface], calent, CVMX_ILK_RX_FIFO_WM, enable_rx_cal);
 	if (res < 0) {
-		pipe_base -= cvmx_ilk_chans[interface];
-		pknd_base -= cvmx_ilk_chans[interface];
+		pipe_base -= cvmx_ilk_chans[xi.node][interface];
+		pknd_base -= cvmx_ilk_chans[xi.node][interface];
 		res = 0;
 		goto err_free_calent;
 	}
@@ -673,17 +682,16 @@ out:
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
 int __cvmx_helper_ilk_enable(int xiface)
 {
-	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
 	if (__cvmx_helper_ilk_init_port(xiface) < 0)
 		return -1;
 
-	return cvmx_ilk_enable(xi.interface - CVMX_ILK_GBL_BASE());
+	return cvmx_ilk_enable(xiface);
 }
 
 /**
@@ -705,6 +713,7 @@ cvmx_helper_link_info_t __cvmx_helper_ilk_link_get(int ipd_port)
 	cvmx_ilk_rxx_int_t ilk_rxx_int;
 	int lane_mask = 0;
 	int i;
+	int node = xi.node;
 
 	result.u64 = 0;
 	interface = xi.interface - CVMX_ILK_GBL_BASE();
@@ -715,19 +724,19 @@ retry:
 		goto fail;
 
 	/* Read RX config and status bits */
-	ilk_rxx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG1(interface));
-	ilk_rxx_int.u64 = cvmx_read_csr(CVMX_ILK_RXX_INT(interface));
+	ilk_rxx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG1(interface));
+	ilk_rxx_int.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_INT(interface));
 
 	if (ilk_rxx_cfg1.s.rx_bdry_lock_ena == 0) {
 		/* Clear the boundary lock status bit */
 		ilk_rxx_int.u64 = 0;
 		ilk_rxx_int.s.word_sync_done = 1;
-		cvmx_write_csr(CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
 
 		/* We need to start looking for word boundary lock */
-		ilk_rxx_cfg1.s.rx_bdry_lock_ena = cvmx_ilk_lane_mask[interface];
+		ilk_rxx_cfg1.s.rx_bdry_lock_ena = cvmx_ilk_lane_mask[node][interface];
 		ilk_rxx_cfg1.s.rx_align_ena = 0;
-		cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 		//cvmx_dprintf("ILK%d: Looking for word boundary lock\n", interface);
 		goto retry;
 	}
@@ -738,10 +747,10 @@ retry:
 			ilk_rxx_int.u64 = 0;
 			ilk_rxx_int.s.lane_align_fail = 1;
 			ilk_rxx_int.s.lane_align_done = 1;
-			cvmx_write_csr(CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
+			cvmx_write_csr_node(node, CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
 
 			ilk_rxx_cfg1.s.rx_align_ena = 1;
-			cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
+			cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 			//printf("ILK%d: Looking for lane alignment\n", interface);
 			goto retry;
 		}
@@ -751,7 +760,7 @@ retry:
 	if (ilk_rxx_int.s.lane_align_fail) {
 		ilk_rxx_cfg1.s.rx_bdry_lock_ena = 0;
 		ilk_rxx_cfg1.s.rx_align_ena = 0;
-		cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 		//cvmx_dprintf("ILK%d: Lane alignment failed\n", interface);
 		goto fail;
 	}
@@ -761,10 +770,10 @@ retry:
 	if (ilk_rxx_cfg1.s.pkt_ena == 0 && ilk_rxx_int.s.lane_align_done) {
 		cvmx_ilk_txx_cfg1_t ilk_txx_cfg1;
 
-		ilk_txx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG1(interface));
-		ilk_rxx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG1(interface));
+		ilk_txx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG1(interface));
+		ilk_rxx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG1(interface));
 		ilk_rxx_cfg1.s.pkt_ena = ilk_txx_cfg1.s.pkt_ena;
-		cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 
 		if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 			/*
@@ -781,12 +790,12 @@ retry:
 			 */
 			cvmx_write_csr(CVMX_ILK_RXX_INT_EN(interface), 0x1e2);
 		}
-		/* FIXME: Enable ILK interrupts for 78xx */
+		/* Need to enable ILK interrupts for 78xx */
 
 		for (i = 0; i < CVMX_ILK_MAX_LANES(); i++) {
 			if ((1 << i) & lane_mask) {
 				/* clear pending interrupts, before enabling. */
-				cvmx_write_csr(CVMX_ILK_RX_LNEX_INT(i), 0x1ff);
+				cvmx_write_csr_node(node, CVMX_ILK_RX_LNEX_INT(i), 0x1ff);
 				/* Enable bad_64b67b, bdry_sync_loss, crc32_err, dskew_fifo_ovfl,
 				   scrm_sync_loss, serdes_lock_loss, stat_msg, ukwn_cntl_word */
 				if (OCTEON_IS_MODEL(OCTEON_CN68XX))
@@ -812,14 +821,14 @@ fail:
 	if (ilk_rxx_cfg1.s.pkt_ena) {
 		/* Disable the interface */
 		ilk_rxx_cfg1.s.pkt_ena = 0;
-		cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 
 		/* Disable error interrupts */
 		for (i = 0; i < CVMX_ILK_MAX_LANES(); i++) {
 			/* Disable bad_64b67b, bdry_sync_loss, crc32_err, dskew_fifo_ovfl,
 			   scrm_sync_loss, serdes_lock_loss, stat_msg, ukwn_cntl_word */
 			if ((1 << i) & lane_mask) {
-				cvmx_write_csr(CVMX_ILK_RX_LNEX_INT(i), 0x1ff);
+				cvmx_write_csr_node(node, CVMX_ILK_RX_LNEX_INT(i), 0x1ff);
 				if (OCTEON_IS_MODEL(OCTEON_CN68XX))
 					cvmx_write_csr(CVMX_ILK_RX_LNEX_INT_EN(i), ~0x1ff);
 			}
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c b/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
index ad74f7b..5465c10 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-npi.c
@@ -43,7 +43,7 @@
  * Functions for NPI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 99993 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -104,7 +104,7 @@ int __cvmx_helper_npi_probe(int interface)
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
index 553b042..c69c2bf 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pki.c
@@ -66,7 +66,7 @@
 #include "cvmx-global-resources.h"
 #endif
 
-static CVMX_SHARED int pki_helper_debug = 0;
+static CVMX_SHARED int pki_helper_debug;
 
 CVMX_SHARED bool cvmx_pki_dflt_init[CVMX_MAX_NODES] = {[0 ... CVMX_MAX_NODES-1] = 1};
 
@@ -217,7 +217,7 @@ int __cvmx_helper_pki_install_dflt_vlan(int node)
 		pcam_action.style_add = 0;
 		pcam_action.pointer_advance = 4;
 		cvmx_pki_pcam_write_entry(node, index, cl_mask,
-			pcam_input, pcam_action);/*vinita_to_do, cluster_mask*/
+			pcam_input, pcam_action);/*cluster_mask in pass2*/
 
 		index = cvmx_pki_pcam_entry_alloc(node,
 			CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
@@ -228,7 +228,7 @@ int __cvmx_helper_pki_install_dflt_vlan(int node)
 		}
 		pcam_input.data = 0x88a80000;
 		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input,
-			pcam_action);/*vinita_to_do, cluster_mask*/
+			pcam_action);
 
 		index = cvmx_pki_pcam_entry_alloc(node,
 			CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
@@ -239,7 +239,7 @@ int __cvmx_helper_pki_install_dflt_vlan(int node)
 		}
 		pcam_input.data = 0x92000000;
 		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input,
-			pcam_action);/*vinita_to_do, cluster_mask*/
+			pcam_action);/* cluster_mask in pass2*/
 
 		index = cvmx_pki_pcam_entry_alloc(node,
 			CVMX_PKI_FIND_AVAL_ENTRY, bank, cl_mask);
@@ -250,7 +250,7 @@ int __cvmx_helper_pki_install_dflt_vlan(int node)
 		}
 		pcam_input.data = 0x91000000;
 		cvmx_pki_pcam_write_entry(node, index, cl_mask, pcam_input,
-			pcam_action);/*vinita_to_do, cluster_mask*/
+			pcam_action);
 	}
 	return 0;
 }
@@ -538,7 +538,7 @@ void cvmx_helper_pki_enable(int node)
 int cvmx_helper_pki_port_shutdown(int ipd_port)
 {
 	/* remove pcam entries */
-	/* vinita_to_do implemet later */
+	/* implemet if needed */
 	/* __cvmx_pki_port_rsrc_free(node); */
 	return 0;
 }
@@ -573,7 +573,7 @@ int cvmx_helper_pki_get_num_qpg_entry(enum cvmx_pki_qpg_qos qpg_qos)
 		return 1;
 	else if (qpg_qos == CVMX_PKI_QPG_QOS_VLAN || qpg_qos == CVMX_PKI_QPG_QOS_MPLS)
 		return 8;
-	else if (qpg_qos == CVMX_PKI_QPG_QOS_DSA_SRC) /*vinita_to_do for higig2*/
+	else if (qpg_qos == CVMX_PKI_QPG_QOS_DSA_SRC)
 		return 32;
 	else if (qpg_qos == CVMX_PKI_QPG_QOS_DIFFSERV || qpg_qos == CVMX_PKI_QPG_QOS_HIGIG)
 		return 64;
@@ -595,7 +595,7 @@ int cvmx_helper_pki_set_qpg_entry(int node, struct cvmx_pki_qpg_config *qpg_cfg)
 
 	offset = cvmx_pki_qpg_entry_alloc(node, qpg_cfg->qpg_base, 1);
 	if (pki_helper_debug)
-		cvmx_dprintf("at offset %d \n", offset);
+		cvmx_dprintf("pki-helper:set qpg entry at offset %d \n", offset);
 	if (offset == CVMX_RESOURCE_ALREADY_RESERVED) {
 		cvmx_dprintf("INFO:setup_qpg_table: offset %d already reserved\n", qpg_cfg->qpg_base);
 		return CVMX_RESOURCE_ALREADY_RESERVED;
@@ -623,6 +623,8 @@ int cvmx_helper_pki_set_qpg_entry(int node, struct cvmx_pki_qpg_config *qpg_cfg)
  * @param ena_drop      enable tail drop.
  *			1:enable 0:disable
  * @return Zero on success. Negative on failure
+ * @note the 'node' and 'aura' arguments may be combined in the future
+ * to use a compaund cvmx_fpa3_gaura_t structure argument.
  */
 int cvmx_helper_setup_aura_qos(int node, int aura, bool ena_red, bool ena_drop,
 			       uint64_t pass_thresh, uint64_t drop_thresh,
@@ -630,7 +632,6 @@ int cvmx_helper_setup_aura_qos(int node, int aura, bool ena_red, bool ena_drop,
 {
 	cvmx_fpa3_gaura_t gaura;
 
-	/* FIXME: change upper-layer arguments to new handle types */
 	gaura = __cvmx_fpa3_gaura(node, aura);
 
 	ena_red = ena_red | ena_drop;
@@ -708,7 +709,7 @@ int __cvmx_helper_pki_qos_rsrcs(int node, struct cvmx_pki_qos_schd *qossch)
 	/* Reserve pool resources */
 	if (qossch->pool_per_qos && qossch->pool_num < 0) {
 		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper:qos: setup pool %d buff_size %d blocks %d\n",
+			cvmx_dprintf("pki-helper:qos-rsrc: setup pool %d buff_size %d blocks %d\n",
 				     qossch->pool_num, (int)qossch->pool_buff_size, (int)qossch->pool_max_buff);
 
 		qossch->_pool = cvmx_fpa3_setup_fill_pool(node,
@@ -729,7 +730,7 @@ int __cvmx_helper_pki_qos_rsrcs(int node, struct cvmx_pki_qos_schd *qossch)
 	/* Reserve aura resources */
 	if (qossch->aura_per_qos && qossch->aura_num < 0) {
 		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper:qos setup aura %d pool %d blocks %d\n",
+			cvmx_dprintf("pki-helper:qos-rsrc: setup aura %d pool %d blocks %d\n",
 				     qossch->aura_num, qossch->pool_num,
 				     (int)qossch->aura_buff_cnt);
 
@@ -753,12 +754,12 @@ int __cvmx_helper_pki_qos_rsrcs(int node, struct cvmx_pki_qos_schd *qossch)
 	if (qossch->sso_grp_per_qos && qossch->sso_grp < 0) {
 		rs = cvmx_sso_allocate_group(node);
 		if (rs < 0) {
-			cvmx_dprintf("pki-helper:qos ERROR: sso grp not available\n");
+			cvmx_dprintf("pki-helper:qos-rsrc: ERROR: sso grp not available\n");
 			return rs;
 		}
 		qossch->sso_grp = rs;
 		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper:qos: sso grp alloced is %d\n", qossch->sso_grp);
+			cvmx_dprintf("pki-helper:qos-rsrc: sso grp alloced is %d\n", qossch->sso_grp);
 	}
 #endif /* CVMX_BUILD_FOR_LINUX_KERNEL */
 	return 0;
@@ -772,7 +773,7 @@ int __cvmx_helper_pki_port_rsrcs(int node, struct cvmx_pki_prt_schd *prtsch)
 	/* Reserve pool resources */
 	if (prtsch->pool_per_prt && prtsch->pool_num < 0) {
 		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper:port setup pool %d buff_size %d blocks %d\n",
+			cvmx_dprintf("pki-helper:port-rsrc: setup pool %d buff_size %d blocks %d\n",
 				     prtsch->pool_num, (int)prtsch->pool_buff_size, (int)prtsch->pool_max_buff);
 
 		prtsch->_pool = cvmx_fpa3_setup_fill_pool(node,
@@ -791,7 +792,7 @@ int __cvmx_helper_pki_port_rsrcs(int node, struct cvmx_pki_prt_schd *prtsch)
 	/* Reserve aura resources */
 	if (prtsch->aura_per_prt && prtsch->aura_num < 0) {
 		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper:port setup aura %d pool %d blocks %d\n",
+			cvmx_dprintf("pki-helper:port-rsrc; setup aura %d pool %d blocks %d\n",
 				     prtsch->aura_num, prtsch->pool_num, (int)prtsch->aura_buff_cnt);
 		prtsch->_aura = cvmx_fpa3_set_aura_for_pool(prtsch->_pool,
 			prtsch->aura_num, prtsch->aura_name,
@@ -803,7 +804,6 @@ int __cvmx_helper_pki_port_rsrcs(int node, struct cvmx_pki_prt_schd *prtsch)
 				__func__, prtsch->aura_num);
 			return -1;
 		}
-
 		prtsch->aura_num = prtsch->_aura.laura;
 
 		if (pki_helper_debug)
@@ -813,12 +813,12 @@ int __cvmx_helper_pki_port_rsrcs(int node, struct cvmx_pki_prt_schd *prtsch)
 	if (prtsch->sso_grp_per_prt && prtsch->sso_grp < 0) {
 		rs = cvmx_sso_allocate_group(node);
 		if (rs < 0) {
-			cvmx_dprintf("pki-helper:port:ERROR: sso grp not available\n");
+			cvmx_printf("ERROR: %s: sso grp not available\n", __func__);
 			return rs;
 		}
 		prtsch->sso_grp = rs;
 		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper:port: sso grp alloced is %d\n", prtsch->sso_grp);
+			cvmx_dprintf("pki-helper:port-rsrc: sso grp alloced is %d\n", prtsch->sso_grp);
 	}
 #endif /* CVMX_BUILD_FOR_LINUX_KERNEL */
 	return 0;
@@ -831,7 +831,7 @@ int __cvmx_helper_pki_intf_rsrcs(int node, struct cvmx_pki_intf_schd *intf)
 
 	if (intf->pool_per_intf && intf->pool_num < 0) {
 		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper:intf: setup pool %d buff_size %d blocks %d\n",
+			cvmx_dprintf("pki-helper:intf-rsrc: setup pool %d buff_size %d blocks %d\n",
 				     intf->pool_num, (int)intf->pool_buff_size, (int)intf->pool_max_buff);
 		intf->_pool = cvmx_fpa3_setup_fill_pool(node, intf->pool_num,
 			intf->pool_name, intf->pool_buff_size,
@@ -850,7 +850,7 @@ int __cvmx_helper_pki_intf_rsrcs(int node, struct cvmx_pki_intf_schd *intf)
 	}
 	if (intf->aura_per_intf && intf->aura_num < 0) {
 		if (pki_helper_debug)
-			cvmx_dprintf("pki-helper:intf: setup aura %d pool %d blocks %d\n",
+			cvmx_dprintf("pki-helper:intf-rsrc: setup aura %d pool %d blocks %d\n",
 			     intf->aura_num, intf->pool_num, (int)intf->aura_buff_cnt);
 		intf->_aura = cvmx_fpa3_set_aura_for_pool(intf->_pool,
 			intf->aura_num, intf->aura_name,
@@ -872,7 +872,7 @@ int __cvmx_helper_pki_intf_rsrcs(int node, struct cvmx_pki_intf_schd *intf)
 	if (intf->sso_grp_per_intf && intf->sso_grp < 0) {
 		rs = cvmx_sso_allocate_group(node);
 		if (rs < 0) {
-			cvmx_dprintf("pki-helper:intf:ERROR: sso grp not available\n");
+			cvmx_printf("ERROR: %s: sso grp not available\n", __func__);
 			return rs;
 		}
 		intf->sso_grp = rs;
@@ -976,7 +976,7 @@ int cvmx_helper_pki_set_gbl_schd(int node, struct cvmx_pki_global_schd *gblsch)
 	if (gblsch->setup_sso_grp) {
 		rs = cvmx_sso_allocate_group(node);
 		if (rs < 0) {
-			cvmx_dprintf("pki-helper:gbl ERROR: sso grp not available\n");
+			cvmx_dprintf("pki-helper:gbl: ERROR: sso grp not available\n");
 			return rs;
 		}
 		gblsch->sso_grp = rs;
@@ -1020,12 +1020,12 @@ int cvmx_helper_pki_init_port(int ipd_port, struct cvmx_pki_prt_schd *prtsch)
 	if (prtsch->qpg_base < 0) {
 		rs = cvmx_pki_qpg_entry_alloc(xp.node, prtsch->qpg_base, num_qos);
 		if (rs < 0) {
-			cvmx_dprintf("pki-helper:port:ERROR: qpg entries not available\n");
+			cvmx_dprintf("pki-helper:port%d:ERROR: qpg entries not available\n", ipd_port);
 			return CVMX_RESOURCE_ALLOC_FAILED;
 		}
 		prtsch->qpg_base = rs;
 		if (pki_helper_debug)
-			cvmx_dprintf("port %d qpg_base %d allocated\n",
+			cvmx_dprintf("pki-helper:port-init: to port %d, qpg_base %d allocated\n",
 				ipd_port, prtsch->qpg_base);
 	}
 
@@ -1051,7 +1051,7 @@ int cvmx_helper_pki_init_port(int ipd_port, struct cvmx_pki_prt_schd *prtsch)
 			qpg_cfg.grp_bad = qossch->sso_grp;
 			cvmx_pki_write_qpg_entry(xp.node, prtsch->qpg_base + qos, &qpg_cfg);
 			if (pki_helper_debug)
-				cvmx_dprintf("port %d qos %d has port_add %d aura %d grp %d\n",
+				cvmx_dprintf("pki-helper:port-init: port %d qos %d has port_add %d aura %d grp %d\n",
 				ipd_port, qos, qossch->port_add,
 				qossch->aura_num, qossch->sso_grp);
 		}
@@ -1071,7 +1071,7 @@ int cvmx_helper_pki_init_port(int ipd_port, struct cvmx_pki_prt_schd *prtsch)
 		} else {
 			prtsch->style = rs;
 			if (pki_helper_debug)
-				cvmx_dprintf("port %d has style %d\n",
+				cvmx_dprintf("pki-helper:port-init: port %d has style %d\n",
 					ipd_port, prtsch->style);
 			style_cfg = pki_dflt_style[xp.node];
 			style_cfg.parm_cfg.qpg_qos = prtsch->qpg_qos;
@@ -1095,9 +1095,9 @@ EXPORT_SYMBOL(cvmx_helper_pki_init_port);
  * This function sets up scheduling parameters (pool, aura, sso group etc)
  * of an interface (all ports/channels on that interface).
  * @param xiface        interface number with node.
- * @param intf_sch      pointer to struct containing interface
+ * @param intfsch      pointer to struct containing interface
  *                      scheduling parameters.
- * @param gbl_sch       pointer to struct containing global scheduling parameters
+ * @param gblsch       pointer to struct containing global scheduling parameters
  *                      (can be NULL if not used)
  */
 int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *intfsch,
@@ -1127,17 +1127,20 @@ int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *
 	has_fcs = __cvmx_helper_get_has_fcs(xiface);
 	memset(&qpg_cfg, 0, sizeof(qpg_cfg));
 
+	if (pki_helper_debug)
+		cvmx_dprintf("pki-helper:intf-init:intf%d initialize\n", xiface);
+
 	if (!intfsch->pool_per_intf) {
 		if (gblsch != NULL) {
 			intfsch->_pool = gblsch->_pool;
 			intfsch->pool_num = gblsch->pool_num;
 		} else {
-			cvmx_dprintf("ERROR: global scheduling is in use but is NULL\n");
+			cvmx_dprintf("ERROR:pki-helper:intf-init:intf%d: global scheduling is in use but is NULL\n", xiface);
 			return -1;
 		}
 	} else {
 		if (intfsch == NULL) {
-			cvmx_dprintf("ERROR: interface scheduling pointer is NULL\n");
+			cvmx_dprintf("ERROR:pki-helper:intf-init:intf%d: interface scheduling pointer is NULL\n", xiface);
 			return -1;
 		}
 		mbuff_size = intfsch->pool_buff_size;
@@ -1179,12 +1182,15 @@ int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *
 
 		/* Port is using qpg qos to schedule packets to differnet aura or sso group */
 		num_qos = cvmx_helper_pki_get_num_qpg_entry(prtsch->qpg_qos);
+		if (pki_helper_debug)
+			cvmx_dprintf("pki-helper:intf-init:intf%d: port %d used qpg_qos=%d\n",
+				     xiface, port, prtsch->qpg_qos);
 
 		/* All ports will share the aura from port 0 for the respective qos */
 		/* Port 0 should never have this set to TRUE **/
 		if (intfsch->qos_share_aura && (port != 0)) {
 			if (pki_helper_debug)
-				cvmx_dprintf("All ports will share same aura for all qos\n");
+				cvmx_dprintf("pki-helper:intf-init:intf%d All ports will share same aura for all qos\n", xiface);
 			for (qos = 0; qos < num_qos; qos++) {
 				qossch = &prtsch->qos_s[qos];
 				prtsch->qpg_qos = intfsch->prt_s[0].qpg_qos;
@@ -1199,7 +1205,7 @@ int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *
 		}
 		if (intfsch->qos_share_grp && (port != 0)) {
 			if (pki_helper_debug)
-				cvmx_dprintf("All ports will share same sso group for all qos\n");
+				cvmx_dprintf("pki-helper:intf-init:intf%d: All ports will share same sso group for all qos\n",xiface);
 			for (qos = 0; qos < num_qos; qos++) {
 				qossch = &prtsch->qos_s[qos];
 				qossch->sso_grp_per_qos =
@@ -1214,8 +1220,8 @@ int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *
 				qossch->pool_num = prtsch->pool_num;
 				qossch->_pool = prtsch->_pool;
 				if (pki_helper_debug)
-					cvmx_dprintf("qos %d pool %d\n",
-						qos, prtsch->pool_num);
+					cvmx_dprintf("pki-helper:intf-init:intf%d: qos %d has pool %d\n",
+						xiface, qos, prtsch->pool_num);
 			} else if (qossch->pool_buff_size < mbuff_size ||
 				    !mbuff_size)
 				mbuff_size = qossch->pool_buff_size;
@@ -1261,7 +1267,7 @@ int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *
 				port_shift = __cvmx_helper_pki_port_shift(xiface, intfsch->prt_s[0].qpg_qos);
 				if (pki_helper_debug) {
 					cvmx_dprintf("pki-helper: num qpg entry needed %d\n", (int)num_entry);
-					cvmx_dprintf("pki-helper:port_msb= %d port_shift=%d\n", port_msb, port_shift);
+					cvmx_dprintf("pki-helper:port_msb=%d port_shift=%d\n", port_msb, port_shift);
 				}
 				num_entry = num_qos;
 				for (port = 0; port < num_ports; port++) {
@@ -1344,7 +1350,7 @@ int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *
 				return -1;
 			}
 			mbuff_size = gblsch->pool_buff_size;
-			cvmx_dprintf("interface %d is using global pool\n", xiface);
+			cvmx_dprintf("interface %d on node %d is using global pool\n", xi.interface, xi.node);
 		}
 		/* Allocate style here and map it to all ports on interface */
 		rs = cvmx_pki_style_alloc(xi.node, intfsch->style);
@@ -1380,7 +1386,7 @@ int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *
 			pknd_cfg.fcs_pres = has_fcs;
 			cvmx_pki_write_pkind_config(xi.node, pknd, &pknd_cfg);
 		}
-	} else if (intfsch->style_per_prt) {
+	} else {
 		port_msb = 0;
 		port_shift = 0;
 		for (port = 0; port < num_ports; port++) {
@@ -1408,7 +1414,7 @@ int cvmx_helper_pki_init_interface(const int xiface, struct cvmx_pki_intf_schd *
 /**
  * This function gets all the PKI parameters related to that
  * particular port from hardware.
- * @param ipd_port	ipd port number to get parameter of
+ * @param ipd_port	ipd port number with node to get parameter of
  * @param port_cfg	pointer to structure where to store read parameters
  */
 void cvmx_pki_get_port_config(int ipd_port, struct cvmx_pki_port_config *port_cfg)
@@ -1434,7 +1440,7 @@ EXPORT_SYMBOL(cvmx_pki_get_port_config);
 /**
  * This function sets all the PKI parameters related to that
  * particular port in hardware.
- * @param ipd_port	ipd port number to get parameter of
+ * @param ipd_port	ipd port number with node to get parameter of
  * @param port_cfg	pointer to structure containing port parameters
  */
 void cvmx_pki_set_port_config(int ipd_port, struct cvmx_pki_port_config *port_cfg)
@@ -1630,7 +1636,6 @@ void cvmx_pki_dump_wqe(const cvmx_wqe_78xx_t *wqp)
  * Modifies maximum frame length to check.
  * It modifies the global frame length set used by this port, any other
  * port using the same set will get affected too.
- * @param node		node number
  * @param ipd_port	ipd port for which to modify max len.
  * @param max_size	maximum frame length
  */
@@ -1663,9 +1668,10 @@ void cvmx_pki_set_max_frm_len(int ipd_port, uint32_t max_size)
 /**
  * This function sets up all th eports of particular interface
  * for chosen fcs mode. (only use for backward compatibility).
- * New application can control it via init_interfcae calls.
+ * New application can control it via init_interface calls.
  * @param node		node number.
- * @param interfcae	interfcae number.
+ * @param interface	interface number.
+ * @param nports	number of ports
  * @param has_fcs	1 -- enable fcs check and fcs strip.
  *			0 -- disable fcs check.
  */
@@ -1679,7 +1685,7 @@ void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs
 	for (index = 0; index < nports; index++) {
 		pknd = cvmx_helper_get_pknd(interface, index);
 		while (cluster < CVMX_PKI_NUM_CLUSTER) {
-			/*vinita_to_do; find the cluster in use*/
+			/*find the cluster in use pass2*/
 			pkind_cfg.u64 = cvmx_read_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pknd, cluster));
 			pkind_cfg.s.fcs_pres = has_fcs;
 			cvmx_write_csr_node(node, CVMX_PKI_CLX_PKINDX_CFG(pknd, cluster), pkind_cfg.u64);
@@ -1696,7 +1702,7 @@ void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs
  * either in same buffer as wqe OR it can go in separate buffer. If used the later mode,
  * make sure software allocate enough buffers to now have wqe separate from packet data.
  * @param node			node number.
- * @param pkt_outside_wqe.	0 = The packet link pointer will be at word [FIRST_SKIP]
+ * @param pkt_outside_wqe	0 = The packet link pointer will be at word [FIRST_SKIP]
  *				immediately followed by packet data, in the same buffer
  *				as the work queue entry.
  *				1 = The packet link pointer will be at word [FIRST_SKIP] in a new
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pko.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pko.c
index 5643c4f..83acbbf 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pko.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pko.c
@@ -42,7 +42,7 @@
  *
  * Helper Functions for the PKO
  *
- * $Id: cvmx-helper-pko.c 103836 2014-09-03 02:00:52Z lrosenboim $
+ * $Id: cvmx-helper-pko.c 106468 2014-10-21 23:17:45Z lrosenboim $
  */
 
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
@@ -143,7 +143,7 @@ static int cvmx_helper_pko_pool_init(void)
 			"pool %d already initialized\n",
 			__func__, pool);
 #endif
-		/* FIXME: Should check available buffer count */
+		/* It is up to the app to have sufficient buffer count */
 		return pool;
 	}
 
@@ -201,7 +201,7 @@ int cvmx_helper_pko_init(void)
  *
  * @return Zero on success, negative on failure
  *
- * FIXME: This is for PKO1 only.
+ * @note This is for PKO1/PKO2, and is not used for PKO3.
  */
 int __cvmx_helper_interface_setup_pko(int interface)
 {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
index a2bab6c..51537dd 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-pko3.c
@@ -276,9 +276,6 @@ static int __cvmx_pko3_config_ilk_interface(int xiface,
 		/* map channels to l2 queues */
 		cvmx_pko3_map_channel(xi.node, l1_q_num, l2_q_num+i, ipd_port);
 
-		//FIXME- can not convert it to a loop because
-		// of CVMX_PKO_Lx_QUEUES are enumerated
-
 		l3_q = cvmx_pko_alloc_queues(xi.node, CVMX_PKO_L3_QUEUES,
 			res_owner, -1, 1);
 		if(l3_q < 0) goto _fail;
@@ -322,8 +319,8 @@ static int __cvmx_pko3_config_ilk_interface(int xiface,
 /** Initialize a channelized port
  * This is intended for LOOP and NPI interfaces which have one MAC
  * per interface and need a channel per subinterface (e.g. ring).
- *
- * FIXME: Consider merging this function with the ILK configuration code
+ * This function is somewhat similar to __cvmx_pko3_config_ilk_interface()
+ * but are kept separate for easier maintenance.
  */
 static int __cvmx_pko3_config_chan_interface( int xiface, unsigned num_chans,
 	uint8_t num_queues, bool prioritized)
@@ -828,10 +825,8 @@ EXPORT_SYMBOL(__cvmx_pko3_helper_dqs_activate);
 
 /** Configure and initialize PKO3 for an interface
  *
- * @param node
- * @param interface is the interface number to configure
+ * @param xiface is the interface number to configure
  * @return 0 on success.
- *
  */
 int cvmx_helper_pko3_init_interface(int xiface)
 {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
index 0e85399..3992f6e 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-rgmii.c
@@ -43,7 +43,7 @@
  * Functions for RGMII/GMII/MII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 96596 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -71,7 +71,7 @@
  * @INTERNAL
  * Probe RGMII ports and determine the number present
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of RGMII/GMII/MII ports (0-4).
  */
@@ -147,7 +147,7 @@ void cvmx_helper_rgmii_internal_loopback(int port)
  * Configure all of the ASX, GMX, and PKO regsiters required
  * to get RGMII to function on the supplied interface.
  *
- * @param interface PKO Interface to configure (0 or 1)
+ * @param xiface PKO Interface to configure (0 or 1)
  *
  * @return Zero on success
  */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
index 7832f55..af86375 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-sgmii.c
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 105303 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -486,7 +486,7 @@ int __cvmx_helper_sgmii_enumerate(int xiface)
  * connected to it. The SGMII interface should still be down after
  * this call.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
@@ -532,7 +532,7 @@ int __cvmx_helper_sgmii_probe(int xiface)
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c b/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
index 8ba5a07..add1b92 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-srio.c
@@ -70,7 +70,7 @@
  * connected to it. The SRIO interface should still be down
  * after this call.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
@@ -123,7 +123,7 @@ int __cvmx_helper_srio_probe(int xiface)
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
index 0649216..c8df383 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-util.c
@@ -783,7 +783,7 @@ EXPORT_SYMBOL(cvmx_helper_setup_red);
  * ports. These setting apply to almost all configurations of all
  * chips.
  *
- * @param interface Interface to configure
+ * @param xiface Interface to configure
  * @param num_ports Number of ports on the interface
  *
  * @return Zero on success, negative on failure
@@ -963,8 +963,11 @@ int cvmx_helper_get_ipd_port(int xiface, int index)
 			return ipd_port + index;
 		else if (port_map[xi.interface].type == LB)
 			return ipd_port + index;
-		else
+		else {
+			cvmx_dprintf("ERROR: %s: interface %u:%u bad mode\n",
+				__func__, xi.node, xi.interface);
 			return -1;
+		}
 
 	} else if (cvmx_helper_interface_get_mode(xiface) == CVMX_HELPER_INTERFACE_MODE_AGL) {
 		return 24;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
index d1a01d4..0ad39c1 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper-xaui.c
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 105303 $<hr>
+ * <hr>$Revision: 106932 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -77,7 +77,6 @@ int __cvmx_helper_xaui_enumerate(int xiface)
 		if (qlm_mode == CVMX_QLM_MODE_RXAUI)
 			return 1;
 		return 0;
-		/* FIXME for higig2 */
 	}
 	/* If HiGig2 is enabled return 16 ports, otherwise return 1 port */
 	gmx_hg2_control.u64 = cvmx_read_csr(CVMX_GMXX_HG2_CONTROL(interface));
@@ -93,7 +92,7 @@ int __cvmx_helper_xaui_enumerate(int xiface)
  * connected to it. The XAUI interface should still be down
  * after this call.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
@@ -345,7 +344,7 @@ int __cvmx_helper_xaui_link_init(int interface)
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-helper.c b/arch/mips/cavium-octeon/executive/cvmx-helper.c
index b219e16..1903eed 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-helper.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-helper.c
@@ -57,6 +57,7 @@
 #include <asm/octeon/cvmx-pip-defs.h>
 #include <asm/octeon/cvmx-asxx-defs.h>
 #include <asm/octeon/cvmx-gmxx-defs.h>
+#include <asm/octeon/cvmx-gserx-defs.h>
 #include <asm/octeon/cvmx-smix-defs.h>
 #include <asm/octeon/cvmx-dbg-defs.h>
 #include <asm/octeon/cvmx-sso-defs.h>
@@ -605,7 +606,7 @@ cvmx_helper_link_info_t __cvmx_helper_get_link_info(int xiface, int port)
 /**
  * Returns if FCS is enabled for the specified interface and port
  *
- * @param interface - interface to check
+ * @param xiface - interface to check
  *
  * @return zero if FCS is not used, otherwise FCS is used.
  */
@@ -804,7 +805,15 @@ static cvmx_helper_interface_mode_t __cvmx_get_mode_cn78xx(int xiface)
 				iface_node_ops[xi.node][xi.interface] = &iface_ops_dis;
 		}
 	} else if (xi.interface == 8) { /* DPI */
-		iface_node_ops[xi.node][xi.interface] = &iface_ops_npi;
+		int qlm = 0;
+		for (qlm = 0; qlm < 5; qlm++) {
+			/* if GSERX_CFG[pcie] == 1, then enable npi */
+			if (cvmx_read_csr_node(xi.node, CVMX_GSERX_CFG(qlm)) & 0x1) {
+				iface_node_ops[xi.node][xi.interface] = &iface_ops_npi;
+				return iface_node_ops[xi.node][xi.interface]->mode;
+			}
+		}
+		iface_node_ops[xi.node][xi.interface] = &iface_ops_dis;
 	} else if (xi.interface == 9) { /* LOOP */
 		iface_node_ops[xi.node][xi.interface] = &iface_ops_loop;
 	} else
@@ -1153,7 +1162,7 @@ EXPORT_SYMBOL(cvmx_helper_interface_get_mode);
  * Determine the actual number of hardware ports connected to an
  * interface. It doesn't setup the ports or enable them.
  *
- * @param interface Interface to enumerate
+ * @param xiface Interface to enumerate
  *
  * @return The number of ports on the interface, negative on failure
  */
@@ -1177,7 +1186,7 @@ EXPORT_SYMBOL(cvmx_helper_interface_enumerate);
  * interface_port_count[interface] correctly. Final hardware setup of
  * the ports will be performed later.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Zero on success, negative on failure
  */
@@ -1453,9 +1462,7 @@ int __cvmx_helper_backpressure_is_misaligned(void)
  * hardware ports. PKO should still be disabled to make sure packets
  * aren't sent out partially setup hardware.
  *
- * @param interface Interface to enable
- * @param iflags Interface flags
- * @param pflags Array of flags, one per port on the interface
+ * @param xiface Interface to enable
  *
  * @return Zero on success, negative on failure
  */
@@ -1514,10 +1521,6 @@ int cvmx_helper_ipd_and_packet_input_enable_node(int node)
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		; // cvmx_pko_enable_78xx(0); already enabled
 	} else {
-		/* FIXME:
-		 * 		 This call was in cvmx-pko.c,
-		 * 		 not sure if this is right either
-		 */
 #ifdef CVMX_BUILD_FOR_STANDALONE
 		__cvmx_install_gmx_error_handler_for_xaui();
 #endif
@@ -1610,7 +1613,6 @@ int cvmx_helper_initialize_packet_io_node(unsigned int node)
 
 	/* PKO3 init precedes that of interfaces */
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
-		//FIXME- ILK needs this config data for now - must fix!
 		__cvmx_helper_init_port_config_data();
 		result = cvmx_helper_pko3_init_global(node);
 	}
@@ -1630,7 +1632,7 @@ int cvmx_helper_initialize_packet_io_node(unsigned int node)
 			    cvmx_helper_ports_on_interface(interface),
 			    cvmx_helper_interface_mode_to_string(cvmx_helper_interface_get_mode(interface)));
 
-		result |= __cvmx_helper_ipd_setup_interface(interface);/* vinita_to_do separate pki */
+		result |= __cvmx_helper_ipd_setup_interface(interface);
 		if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE))
 			result |= cvmx_helper_pko3_init_interface(cvmx_helper_node_interface_to_xiface(node, interface));
 		else
@@ -1839,7 +1841,6 @@ static int __cvmx_helper_shutdown_packet_io_global_cn78xx(int node)
 			for (index = 0; index < num_ports; index++) {
 				if (!cvmx_helper_is_port_valid(interface, index))
 					continue;
-		//FIXME: Move this code to cvmx-bgxx.c
 				/* Disable GMX before we make any changes. Remember the enable state */
 				cmr_config.u64 = cvmx_read_csr(CVMX_BGXX_CMRX_CONFIG(index, interface));
 				cmr_config.s.enable = 0;
@@ -2503,7 +2504,7 @@ void cvmx_helper_setup_simulator_io_buffer_counts(int node, int num_packet_buffe
 void *cvmx_helper_mem_alloc(int node, uint64_t alloc_size, uint64_t align)
 {
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
-	return kmalloc(alloc_size, GFP_NOIO | GFP_DMA); //FIXME alignment
+	return kmalloc(alloc_size, GFP_NOIO | GFP_DMA);
 #else
 	return cvmx_phys_to_ptr(cvmx_bootmem_phy_alloc_range(alloc_size, align,
 							     cvmx_addr_on_node(node, 0ull),
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ilk.c b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
index ed103a0..31ee940 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ilk.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ilk.c
@@ -75,15 +75,21 @@
  * cvmx_ilk_lane_mask[CVMX_NUM_ILK_INTF] = {0xff, 0x0} and
  * cvmx_ilk_chans[CVMX_NUM_ILK_INTF] = {8, 0}
  */
-CVMX_SHARED unsigned short cvmx_ilk_lane_mask[CVMX_NUM_ILK_INTF] = {0x000f, 0x00f0};
+CVMX_SHARED unsigned short cvmx_ilk_lane_mask[CVMX_MAX_NODES][CVMX_NUM_ILK_INTF] =
+	{[0 ... CVMX_MAX_NODES - 1] =
+ 		{0x000f, 0x00f0}
+	};
 
-CVMX_SHARED unsigned char cvmx_ilk_chans[CVMX_NUM_ILK_INTF] = {8,8};
+CVMX_SHARED unsigned char cvmx_ilk_chans[CVMX_MAX_NODES][CVMX_NUM_ILK_INTF] =
+	{[0 ... CVMX_MAX_NODES - 1] =
+		 {8,8}
+	};
 
 unsigned char cvmx_ilk_chan_map[CVMX_NUM_ILK_INTF][CVMX_ILK_MAX_CHANS] = { {0, 1, 2, 3, 4, 5, 6, 7},
 {0, 1, 2, 3, 4, 5, 6, 7}
 };
 
-static cvmx_ilk_intf_t cvmx_ilk_intf_cfg[CVMX_NUM_ILK_INTF];
+static cvmx_ilk_intf_t cvmx_ilk_intf_cfg[CVMX_MAX_NODES][CVMX_NUM_ILK_INTF];
 
 CVMX_SHARED cvmx_ilk_LA_mode_t cvmx_ilk_LA_mode[CVMX_NUM_ILK_INTF] = {{0, 0},
 									{0, 0}};
@@ -152,6 +158,8 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 	cvmx_ilk_ser_cfg_t ilk_ser_cfg;
+	int node = (interface >> 4) & 0xf;
+	interface &= 0xf;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -165,8 +173,8 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	/* check conflicts between 2 ilk interfaces. 1 lane can be assigned to 1
 	 * interface only */
 	other_intf = !interface;
-	if (cvmx_ilk_lane_mask[other_intf] & lane_mask) {
-		cvmx_dprintf("ILK%d: %s: lane assignment conflict\n", interface, __func__);
+	if (cvmx_ilk_lane_mask[node][other_intf] & lane_mask) {
+		cvmx_dprintf("ILK%d:%d: %s: lane assignment conflict\n", node, interface, __func__);
 		return res;
 	}
 
@@ -206,12 +214,12 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 			cvmx_gserx_phy_ctl_t phy_ctl;
 
 			/* Make sure QLM is powered and out of reset */
-			phy_ctl.u64 = cvmx_read_csr(CVMX_GSERX_PHY_CTL(qlm));
+			phy_ctl.u64 = cvmx_read_csr_node(node, CVMX_GSERX_PHY_CTL(qlm));
 			if (phy_ctl.s.phy_pd || phy_ctl.s.phy_reset)
 				continue;
 
 			/* Make sure QLM is in ILK mode */
-			gserx_cfg.u64 = cvmx_read_csr(CVMX_GSERX_CFG(qlm));
+			gserx_cfg.u64 = cvmx_read_csr_node(node, CVMX_GSERX_CFG(qlm));
 			if (gserx_cfg.s.ila)
 				lane_mask_all |= ((1 << 4) - 1) << (4 * (qlm - 4));	
 		}
@@ -223,7 +231,7 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	}
 
 	/* power up the serdes */
-	ilk_ser_cfg.u64 = cvmx_read_csr(CVMX_ILK_SER_CFG);
+	ilk_ser_cfg.u64 = cvmx_read_csr_node(node, CVMX_ILK_SER_CFG);
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		if (ilk_ser_cfg.cn68xx.ser_pwrup == 0) {
 			ilk_ser_cfg.cn68xx.ser_rxpol_auto = 1;
@@ -240,7 +248,7 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 		ilk_ser_cfg.cn78xx.ser_txpol = 0;
 		ilk_ser_cfg.cn78xx.ser_reset_n = 0xffff;
 	}
-	cvmx_write_csr(CVMX_ILK_SER_CFG, ilk_ser_cfg.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_SER_CFG, ilk_ser_cfg.u64);
 
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX_PASS2_X)
 	    && (cvmx_sysinfo_get()->board_type != CVMX_BOARD_TYPE_SIM)) {
@@ -282,7 +290,7 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 	}
 
 	/* Initialize all calendar entries to xoff state */
-	__cvmx_ilk_init_cal(interface);
+	__cvmx_ilk_init_cal((node << 4) | interface);
 
 	/* Enable ILK LA mode if configured. */
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
@@ -298,24 +306,24 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 			ilk_rxx_cfg1.s.la_mode = 1;
 			cvmx_write_csr(CVMX_ILK_TXX_CFG1(interface), ilk_txx_cfg1.u64);
 			cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
-			cvmx_ilk_intf_cfg[interface].la_mode = 1;	/* Enable look-aside mode */
+			cvmx_ilk_intf_cfg[node][interface].la_mode = 1;	/* Enable look-aside mode */
 		} else
-			cvmx_ilk_intf_cfg[interface].la_mode = 0;	/* Disable look-aside mode */
+			cvmx_ilk_intf_cfg[node][interface].la_mode = 0;	/* Disable look-aside mode */
 	}
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		cvmx_ilk_intf_cfg[interface].la_mode = 0;
+		cvmx_ilk_intf_cfg[node][interface].la_mode = 0;
 	}
 
 	/* configure the lane enable of the interface */
-	ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
-	ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+	ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
+	ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 	ilk_txx_cfg0.s.lane_ena = ilk_rxx_cfg0.s.lane_ena = lane_mask;
-	cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
-	cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 
 	/* write to local cache. for lane speed, if interface 0 has 8 lanes,
 	 * assume both qlms have the same speed */
-	cvmx_ilk_intf_cfg[interface].intf_en = 1;
+	cvmx_ilk_intf_cfg[node][interface].intf_en = 1;
 	res = 0;
 
 	return res;
@@ -324,7 +332,7 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
 /**
  * set pipe group base and length for the interface
  *
- * @param interface The identifier of the packet interface to configure and
+ * @param xiface    The identifier of the packet interface to configure and
  *                  use as a ILK interface. cn68xx has 2 interfaces: ilk0 and
  *                  ilk1.
  *
@@ -333,10 +341,12 @@ int cvmx_ilk_start_interface(int interface, unsigned short lane_mask)
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_set_pipe(int interface, int pipe_base, unsigned int pipe_len)
+int cvmx_ilk_set_pipe(int xiface, int pipe_base, unsigned int pipe_len)
 {
 	int res = -1;
 	cvmx_ilk_txx_pipe_t ilk_txx_pipe;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface - CVMX_ILK_GBL_BASE();
 
 	if (!(OCTEON_IS_MODEL(OCTEON_CN68XX)))
 		return res;
@@ -345,10 +355,10 @@ int cvmx_ilk_set_pipe(int interface, int pipe_base, unsigned int pipe_len)
 		return res;
 
 	/* set them in ilk tx section */
-	ilk_txx_pipe.u64 = cvmx_read_csr(CVMX_ILK_TXX_PIPE(interface));
+	ilk_txx_pipe.u64 = cvmx_read_csr_node(xi.node, CVMX_ILK_TXX_PIPE(interface));
 	ilk_txx_pipe.s.base = pipe_base;
 	ilk_txx_pipe.s.nump = pipe_len;
-	cvmx_write_csr(CVMX_ILK_TXX_PIPE(interface), ilk_txx_pipe.u64);
+	cvmx_write_csr_node(xi.node, CVMX_ILK_TXX_PIPE(interface), ilk_txx_pipe.u64);
 	res = 0;
 
 	return res;
@@ -413,7 +423,7 @@ int cvmx_ilk_tx_set_channel(int interface, cvmx_ilk_pipe_chan_t * pch, unsigned
 /**
  * set pkind for rx
  *
- * @param interface The identifier of the packet interface to configure and
+ * @param xiface    The identifier of the packet interface to configure and
  *                  use as a ILK interface. cn68xx has 2 interfaces: ilk0 and
  *                  ilk1.
  *
@@ -422,11 +432,13 @@ int cvmx_ilk_tx_set_channel(int interface, cvmx_ilk_pipe_chan_t * pch, unsigned
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_rx_set_pknd(int interface, cvmx_ilk_chan_pknd_t * chpknd, unsigned int num_pknd)
+int cvmx_ilk_rx_set_pknd(int xiface, cvmx_ilk_chan_pknd_t * chpknd, unsigned int num_pknd)
 {
 	int res = -1;
 	cvmx_ilk_rxf_idx_pmap_t ilk_rxf_idx_pmap;
 	unsigned int i;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface - CVMX_ILK_GBL_BASE();
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -454,7 +466,7 @@ int cvmx_ilk_rx_set_pknd(int interface, cvmx_ilk_chan_pknd_t * chpknd, unsigned
 			cvmx_write_csr(CVMX_ILK_RXF_MEM_PMAP, chpknd->pknd);
 		}
 		if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-			cvmx_write_csr(CVMX_ILK_RXX_CHAX(chpknd->chan, interface), chpknd->pknd);
+			cvmx_write_csr_node(xi.node, CVMX_ILK_RXX_CHAX(chpknd->chan, interface), chpknd->pknd);
 		}
 		chpknd++;
 	}
@@ -464,7 +476,7 @@ int cvmx_ilk_rx_set_pknd(int interface, cvmx_ilk_chan_pknd_t * chpknd, unsigned
 /**
  * configure calendar for rx
  *
- * @param interface The identifier of the packet interface to configure and
+ * @param intf The identifier of the packet interface to configure and
  *                  use as a ILK interface. cn68xx has 2 interfaces: ilk0 and
  *                  ilk1.
  *
@@ -473,11 +485,13 @@ int cvmx_ilk_rx_set_pknd(int interface, cvmx_ilk_chan_pknd_t * chpknd, unsigned
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent)
+int cvmx_ilk_rx_cal_conf(int intf, int cal_depth, cvmx_ilk_cal_entry_t * pent)
 {
 	int res = -1, i;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 	int num_entries;
+	int node = (intf >> 4) & 0xf; 
+	int interface = intf & 0xf;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -520,23 +534,23 @@ int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+		ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 		/* 
 		 * Make sure cal_ena is 0 for programming the calender table,
 		 * as per Errata ILK-19398
 		 */
 		ilk_rxx_cfg0.s.cal_ena = 0;
-		cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 
 		for (i = 0; i < cal_depth; i++) {
-				__cvmx_ilk_write_rx_cal_entry(interface, i,
+				__cvmx_ilk_write_rx_cal_entry(intf, i,
 							      pent[i].pipe_bpid);
 		}
 
-		ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+		ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 		num_entries = 1 + cal_depth + (cal_depth - 1) / 15;
 		ilk_rxx_cfg0.s.cal_depth = num_entries;
-		cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 	}
 
 	return 0;
@@ -545,7 +559,7 @@ int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 /**
  * set high water mark for rx
  *
- * @param interface The identifier of the packet interface to configure and
+ * @param intf      The identifier of the packet interface to configure and
  *                  use as a ILK interface. cn68xx has 2 interfaces: ilk0 and
  *                  ilk1.
  *
@@ -553,10 +567,12 @@ int cvmx_ilk_rx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_rx_set_hwm(int interface, int hi_wm)
+int cvmx_ilk_rx_set_hwm(int intf, int hi_wm)
 {
 	int res = -1;
 	cvmx_ilk_rxx_cfg1_t ilk_rxx_cfg1;
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -568,9 +584,9 @@ int cvmx_ilk_rx_set_hwm(int interface, int hi_wm)
 		return res;
 
 	/* set the hwm */
-	ilk_rxx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG1(interface));
+	ilk_rxx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG1(interface));
 	ilk_rxx_cfg1.s.rx_fifo_hwm = hi_wm;
-	cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 	res = 0;
 
 	return res;
@@ -579,7 +595,7 @@ int cvmx_ilk_rx_set_hwm(int interface, int hi_wm)
 /**
  * enable calendar for rx
  *
- * @param interface The identifier of the packet interface to configure and
+ * @param intf      The identifier of the packet interface to configure and
  *                  use as a ILK interface. cn68xx has 2 interfaces: ilk0 and
  *                  ilk1.
  *
@@ -587,10 +603,12 @@ int cvmx_ilk_rx_set_hwm(int interface, int hi_wm)
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_rx_cal_ena(int interface, unsigned char cal_ena)
+int cvmx_ilk_rx_cal_ena(int intf, unsigned char cal_ena)
 {
 	int res = -1;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -602,10 +620,10 @@ int cvmx_ilk_rx_cal_ena(int interface, unsigned char cal_ena)
 		return 0;
 
 	/* set the enable */
-	ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+	ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 	ilk_rxx_cfg0.s.cal_ena = cal_ena;
-	cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
-	cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
+	cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 	res = 0;
 
 	return res;
@@ -614,7 +632,7 @@ int cvmx_ilk_rx_cal_ena(int interface, unsigned char cal_ena)
 /**
  * set up calendar for rx
  *
- * @param interface The identifier of the packet interface to configure and
+ * @param intf      The identifier of the packet interface to configure and
  *                  use as a ILK interface. cn68xx has 2 interfaces: ilk0 and
  *                  ilk1.
  *
@@ -625,25 +643,22 @@ int cvmx_ilk_rx_cal_ena(int interface, unsigned char cal_ena)
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_cal_setup_rx(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent, int hi_wm, unsigned char cal_ena)
+int cvmx_ilk_cal_setup_rx(int intf, int cal_depth, cvmx_ilk_cal_entry_t * pent, int hi_wm, unsigned char cal_ena)
 {
 	int res = -1;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
-	if (interface >= CVMX_NUM_ILK_INTF)
-		return res;
-
-	res = cvmx_ilk_rx_cal_conf(interface, cal_depth, pent);
+	res = cvmx_ilk_rx_cal_conf(intf, cal_depth, pent);
 	if (res < 0)
 		return res;
 
-	res = cvmx_ilk_rx_set_hwm(interface, hi_wm);
+	res = cvmx_ilk_rx_set_hwm(intf, hi_wm);
 	if (res < 0)
 		return res;
 
-	res = cvmx_ilk_rx_cal_ena(interface, cal_ena);
+	res = cvmx_ilk_rx_cal_ena(intf, cal_ena);
 	return res;
 }
 
@@ -661,11 +676,13 @@ EXPORT_SYMBOL(cvmx_ilk_cal_setup_rx);
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent)
+int cvmx_ilk_tx_cal_conf(int intf, int cal_depth, cvmx_ilk_cal_entry_t * pent)
 {
 	int res = -1, i;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 	int num_entries;
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -699,25 +716,25 @@ int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+		ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 		/* 
 		 * Make sure cal_ena is 0 for programming the calender table,
 		 * as per Errata ILK-19398
 		 */
 		ilk_txx_cfg0.s.cal_ena = 0;
-		cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 
 		for (i = 0; i < cal_depth; i++) {
-			__cvmx_ilk_write_tx_cal_entry(interface, i,
+			__cvmx_ilk_write_tx_cal_entry(intf, i,
 						      pent[i].pipe_bpid);
 			pent++;
 		}
 
-		ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+		ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 		num_entries = 1 + cal_depth + (cal_depth - 1) / 15;
 		/* cal_depth[2:0] needs to be zero, round up */
 		ilk_txx_cfg0.s.cal_depth = (num_entries + 7) & 0x1f8;
-		cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 	}
 
 	return 0;
@@ -734,10 +751,12 @@ int cvmx_ilk_tx_cal_conf(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pe
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_tx_cal_ena(int interface, unsigned char cal_ena)
+int cvmx_ilk_tx_cal_ena(int intf, unsigned char cal_ena)
 {
 	int res = -1;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -746,10 +765,10 @@ int cvmx_ilk_tx_cal_ena(int interface, unsigned char cal_ena)
 		return res;
 
 	/* set the enable */
-	ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+	ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 	ilk_txx_cfg0.s.cal_ena = cal_ena;
-	cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
-	cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+	cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+	cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 	res = 0;
 
 	return res;
@@ -758,7 +777,7 @@ int cvmx_ilk_tx_cal_ena(int interface, unsigned char cal_ena)
 /**
  * set up calendar for tx
  *
- * @param interface The identifier of the packet interface to configure and
+ * @param intf      The identifier of the packet interface to configure and
  *                  use as a ILK interface. cn68xx has 2 interfaces: ilk0 and
  *                  ilk1.
  *
@@ -768,21 +787,18 @@ int cvmx_ilk_tx_cal_ena(int interface, unsigned char cal_ena)
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_cal_setup_tx(int interface, int cal_depth, cvmx_ilk_cal_entry_t * pent, unsigned char cal_ena)
+int cvmx_ilk_cal_setup_tx(int intf, int cal_depth, cvmx_ilk_cal_entry_t * pent, unsigned char cal_ena)
 {
 	int res = -1;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
 
-	if (interface >= CVMX_NUM_ILK_INTF)
-		return res;
-
-	res = cvmx_ilk_tx_cal_conf(interface, cal_depth, pent);
+	res = cvmx_ilk_tx_cal_conf(intf, cal_depth, pent);
 	if (res < 0)
 		return res;
 
-	res = cvmx_ilk_tx_cal_ena(interface, cal_ena);
+	res = cvmx_ilk_tx_cal_ena(intf, cal_ena);
 	return res;
 }
 
@@ -790,7 +806,7 @@ EXPORT_SYMBOL(cvmx_ilk_cal_setup_tx);
 
 //#define CVMX_ILK_STATS_ENA 1
 #ifdef CVMX_ILK_STATS_ENA
-static void cvmx_ilk_reg_dump_rx(int interface)
+static void cvmx_ilk_reg_dump_rx(int intf)
 {
 	int i;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
@@ -806,36 +822,38 @@ static void cvmx_ilk_reg_dump_rx(int interface)
 	cvmx_ilk_rxx_idx_cal_t ilk_rxx_idx_cal;
 	cvmx_ilk_rxx_mem_cal0_t ilk_rxx_mem_cal0;
 	cvmx_ilk_rxx_mem_cal1_t ilk_rxx_mem_cal1;
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
-	ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+	ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 	cvmx_dprintf("ilk rxx cfg0: 0x%16lx\n", ilk_rxx_cfg0.u64);
 
-	ilk_rxx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG1(interface));
+	ilk_rxx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG1(interface));
 	cvmx_dprintf("ilk rxx cfg1: 0x%16lx\n", ilk_rxx_cfg1.u64);
 
-	ilk_rxx_int.u64 = cvmx_read_csr(CVMX_ILK_RXX_INT(interface));
+	ilk_rxx_int.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_INT(interface));
 	cvmx_dprintf("ilk rxx int: 0x%16lx\n", ilk_rxx_int.u64);
-	cvmx_write_csr(CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
 
-	ilk_rxx_jabber.u64 = cvmx_read_csr(CVMX_ILK_RXX_JABBER(interface));
+	ilk_rxx_jabber.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_JABBER(interface));
 	cvmx_dprintf("ilk rxx jabber: 0x%16lx\n", ilk_rxx_jabber.u64);
 
 #define LNE_NUM_DBG 4
 	for (i = 0; i < LNE_NUM_DBG; i++) {
-		ilk_rx_lnex_cfg.u64 = cvmx_read_csr(CVMX_ILK_RX_LNEX_CFG(i));
+		ilk_rx_lnex_cfg.u64 = cvmx_read_csr_node(node, CVMX_ILK_RX_LNEX_CFG(i));
 		cvmx_dprintf("ilk rx lnex cfg lane: %d  0x%16lx\n", i, ilk_rx_lnex_cfg.u64);
 	}
 
 	for (i = 0; i < LNE_NUM_DBG; i++) {
-		ilk_rx_lnex_int.u64 = cvmx_read_csr(CVMX_ILK_RX_LNEX_INT(i));
+		ilk_rx_lnex_int.u64 = cvmx_read_csr_node(node, CVMX_ILK_RX_LNEX_INT(i));
 		cvmx_dprintf("ilk rx lnex int lane: %d  0x%16lx\n", i, ilk_rx_lnex_int.u64);
-		cvmx_write_csr(CVMX_ILK_RX_LNEX_INT(i), ilk_rx_lnex_int.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RX_LNEX_INT(i), ilk_rx_lnex_int.u64);
 	}
 
-	ilk_gbl_cfg.u64 = cvmx_read_csr(CVMX_ILK_GBL_CFG);
+	ilk_gbl_cfg.u64 = cvmx_read_csr_node(node, CVMX_ILK_GBL_CFG);
 	cvmx_dprintf("ilk gbl cfg: 0x%16lx\n", ilk_gbl_cfg.u64);
 
-	ilk_ser_cfg.u64 = cvmx_read_csr(CVMX_ILK_SER_CFG);
+	ilk_ser_cfg.u64 = cvmx_read_csr_node(node, CVMX_ILK_SER_CFG);
 	cvmx_dprintf("ilk ser cfg: 0x%16lx\n", ilk_ser_cfg.u64);
 
 #define CHAN_NUM_DBG 8
@@ -853,7 +871,7 @@ static void cvmx_ilk_reg_dump_rx(int interface)
 		cvmx_ilk_rxx_chax_t rxx_chax;
 
 		for (i = 0; i < CHAN_NUM_DBG; i++) {
-			rxx_chax.u64 = cvmx_read_csr(CVMX_ILK_RXX_CHAX(i, interface));
+			rxx_chax.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CHAX(i, interface));
 			cvmx_dprintf("ilk chan: %d  pki chan: 0x%x\n", i, rxx_chax.s.port_kind);
 		}
 	}
@@ -877,7 +895,7 @@ static void cvmx_ilk_reg_dump_rx(int interface)
 		cvmx_ilk_rxx_cal_entryx_t rxx_cal_entryx;
 
 		for (i = 0; i < CAL_NUM_DBG; i++) {
-			rxx_cal_entryx.u64 = cvmx_read_csr(CVMX_ILK_RXX_CAL_ENTRYX(i, interface));
+			rxx_cal_entryx.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CAL_ENTRYX(i, interface));
 			cvmx_dprintf("ilk rxx cal idx: %d\n", i);
 			cvmx_dprintf("ilk rxx cal ctl: 0x%x\n", rxx_cal_entryx.s.ctl);
 			cvmx_dprintf("ilk rxx cal pko chan: 0x%x\n", rxx_cal_entryx.s.channel);
@@ -885,7 +903,7 @@ static void cvmx_ilk_reg_dump_rx(int interface)
 	}
 }
 
-static void cvmx_ilk_reg_dump_tx(int interface)
+static void cvmx_ilk_reg_dump_tx(int intf)
 {
 	int i;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
@@ -897,11 +915,13 @@ static void cvmx_ilk_reg_dump_tx(int interface)
 	cvmx_ilk_txx_idx_cal_t ilk_txx_idx_cal;
 	cvmx_ilk_txx_mem_cal0_t ilk_txx_mem_cal0;
 	cvmx_ilk_txx_mem_cal1_t ilk_txx_mem_cal1;
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
-	ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+	ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 	cvmx_dprintf("ilk txx cfg0: 0x%16lx\n", ilk_txx_cfg0.u64);
 
-	ilk_txx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG1(interface));
+	ilk_txx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG1(interface));
 	cvmx_dprintf("ilk txx cfg1: 0x%16lx\n", ilk_txx_cfg1.u64);
 
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
@@ -918,7 +938,7 @@ static void cvmx_ilk_reg_dump_tx(int interface)
 		}
 	}
 
-	ilk_txx_int.u64 = cvmx_read_csr(CVMX_ILK_TXX_INT(interface));
+	ilk_txx_int.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_INT(interface));
 	cvmx_dprintf("ilk txx int: 0x%16lx\n", ilk_txx_int.u64);
 
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
@@ -939,7 +959,7 @@ static void cvmx_ilk_reg_dump_tx(int interface)
 		cvmx_ilk_txx_cal_entryx_t txx_cal_entryx;
 
 		for (i = 0; i < CAL_NUM_DBG; i++) {
-			txx_cal_entryx.u64 = cvmx_read_csr(CVMX_ILK_TXX_CAL_ENTRYX(i, interface));
+			txx_cal_entryx.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CAL_ENTRYX(i, interface));
 			cvmx_dprintf("ilk txx cal idx: %d\n", i);
 			cvmx_dprintf("ilk txx cal ctl: 0x%x\n", txx_cal_entryx.s.ctl);
 			cvmx_dprintf("ilk txx cal pki chan: 0x%x\n", txx_cal_entryx.s.channel);
@@ -969,7 +989,7 @@ void cvmx_ilk_runtime_status(int interface)
 
 	cvmx_dprintf("\nilk run-time status: interface: %d\n", interface);
 
-	ilk_txx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG1(interface));
+	ilk_txx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG1(interface));
 	cvmx_dprintf("\nilk txx cfg1: 0x%16lx\n", ilk_txx_cfg1.u64);
 	if (ilk_txx_cfg1.s.rx_link_fc)
 		cvmx_dprintf("link flow control received\n");
@@ -985,21 +1005,21 @@ void cvmx_ilk_runtime_status(int interface)
 		cvmx_ilk_txx_cha_xonx_t txx_cha_xonx;
 
 		for (i = 0; i < 4; i++) {
-			txx_cha_xonx.u64 = cvmx_read_csr(CVMX_ILK_TXX_CHA_XONX(i, interface));
+			txx_cha_xonx.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CHA_XONX(i, interface));
 			cvmx_dprintf("\nilk txx cha xon: 0x%16lx\n", txx_cha_xonx.u64);
 		}
 	}
 
-	ilk_rxx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG1(interface));
+	ilk_rxx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG1(interface));
 	cvmx_dprintf("\nilk rxx cfg1: 0x%16lx\n", ilk_rxx_cfg1.u64);
 	cvmx_dprintf("rx fifo count: %d\n", ilk_rxx_cfg1.s.rx_fifo_cnt);
 
-	ilk_rxx_int.u64 = cvmx_read_csr(CVMX_ILK_RXX_INT(interface));
+	ilk_rxx_int.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_INT(interface));
 	cvmx_dprintf("\nilk rxx int: 0x%16lx\n", ilk_rxx_int.u64);
 	if (ilk_rxx_int.s.pkt_drop_rxf)
 		cvmx_dprintf("rx fifo packet drop\n");
 	if (ilk_rxx_int.u64)
-		cvmx_write_csr(CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_RXX_INT(interface), ilk_rxx_int.u64);
 
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		ilk_rxx_flow_ctl0.u64 = cvmx_read_csr(CVMX_ILK_RXX_FLOW_CTL0(interface));
@@ -1013,29 +1033,29 @@ void cvmx_ilk_runtime_status(int interface)
 		cvmx_ilk_rxx_cha_xonx_t rxx_cha_xonx;
 
 		for (i = 0; i < 4; i++) {
-			rxx_cha_xonx.u64 = cvmx_read_csr(CVMX_ILK_RXX_CHA_XONX(i, interface));
+			rxx_cha_xonx.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CHA_XONX(i, interface));
 			cvmx_dprintf("\nilk rxx cha xon: 0x%16lx\n", rxx_cha_xonx.u64);
 		}
 	}
 
-	ilk_gbl_int.u64 = cvmx_read_csr(CVMX_ILK_GBL_INT);
+	ilk_gbl_int.u64 = cvmx_read_csr_node(node, CVMX_ILK_GBL_INT);
 	cvmx_dprintf("\nilk gbl int: 0x%16lx\n", ilk_gbl_int.u64);
 	if (ilk_gbl_int.s.rxf_push_full)
 		cvmx_dprintf("rx fifo overflow\n");
 	if (ilk_gbl_int.u64)
-		cvmx_write_csr(CVMX_ILK_GBL_INT, ilk_gbl_int.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_GBL_INT, ilk_gbl_int.u64);
 }
 #endif
 
 /**
  * enable interface
  *
- * @param interface The identifier of the packet interface to enable. cn68xx
+ * @param xiface    The identifier of the packet interface to enable. cn68xx
  *                  has 2 interfaces: ilk0 and ilk1.
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_enable(int interface)
+int cvmx_ilk_enable(int xiface)
 {
 	int res = -1;
 	int retry_count = 0;
@@ -1046,6 +1066,9 @@ int cvmx_ilk_enable(int interface)
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 #endif
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int node = xi.node;
+	int interface = xi.interface - CVMX_ILK_GBL_BASE();
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -1058,14 +1081,14 @@ int cvmx_ilk_enable(int interface)
 #ifdef CVMX_ILK_STATS_ENA
 	cvmx_dprintf("\n");
 	cvmx_dprintf("<<<< ILK%d: Before enabling ilk\n", interface);
-	cvmx_ilk_reg_dump_rx(interface);
-	cvmx_ilk_reg_dump_tx(interface);
+	cvmx_ilk_reg_dump_rx(intf);
+	cvmx_ilk_reg_dump_tx(intf);
 #endif
 
 	/* RX packet will be enabled only if link is up */
 
 	/* TX side */
-	ilk_txx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG1(interface));
+	ilk_txx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG1(interface));
 	ilk_txx_cfg1.s.pkt_ena = 1;
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 		if (cvmx_ilk_use_la_mode(interface, 0)) {
@@ -1073,19 +1096,19 @@ int cvmx_ilk_enable(int interface)
 			ilk_txx_cfg1.s.tx_link_fc_jam = 1;
 		}
 	}
-	cvmx_write_csr(CVMX_ILK_TXX_CFG1(interface), ilk_txx_cfg1.u64);
-	cvmx_read_csr(CVMX_ILK_TXX_CFG1(interface));
+	cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG1(interface), ilk_txx_cfg1.u64);
+	cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG1(interface));
 
 #ifdef CVMX_ILK_STATS_ENA
 	/* RX side stats */
-	ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+	ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 	ilk_rxx_cfg0.s.lnk_stats_ena = 1;
-	cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 
 	/* TX side stats */
-	ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+	ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 	ilk_txx_cfg0.s.lnk_stats_ena = 1;
-	cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 #endif
 
 retry:
@@ -1094,12 +1117,12 @@ retry:
 		goto out;
 
 	/* Make sure the link is up, so that packets can be sent. */
-	result = __cvmx_helper_ilk_link_get(cvmx_helper_get_ipd_port(interface + CVMX_ILK_GBL_BASE(), 0));
+	result = __cvmx_helper_ilk_link_get(cvmx_helper_get_ipd_port((interface + CVMX_ILK_GBL_BASE()), 0));
 
 	/* Small delay before another retry. */
 	cvmx_wait_usec(100);
 
-	ilk_rxx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG1(interface));
+	ilk_rxx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG1(interface));
 	if (ilk_rxx_cfg1.s.pkt_ena == 0)
 		goto retry;
 
@@ -1107,8 +1130,8 @@ out:
 
 #ifdef CVMX_ILK_STATS_ENA
 	cvmx_dprintf(">>>> ILK%d: After ILK is enabled\n", interface);
-	cvmx_ilk_reg_dump_rx(interface);
-	cvmx_ilk_reg_dump_tx(interface);
+	cvmx_ilk_reg_dump_rx(intf);
+	cvmx_ilk_reg_dump_tx(intf);
 #endif
 
 	if (result.s.link_up)
@@ -1120,12 +1143,12 @@ out:
 /**
  * Disable interface
  *
- * @param interface The identifier of the packet interface to disable. cn68xx
+ * @param intf      The identifier of the packet interface to disable. cn68xx
  *                  has 2 interfaces: ilk0 and ilk1.
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_disable(int interface)
+int cvmx_ilk_disable(int intf)
 {
 	int res = -1;
 	cvmx_ilk_txx_cfg1_t ilk_txx_cfg1;
@@ -1134,6 +1157,8 @@ int cvmx_ilk_disable(int interface)
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 #endif
+	int node = (intf >> 4) & 0xf;
+	int interface = intf & 0xf;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -1142,25 +1167,25 @@ int cvmx_ilk_disable(int interface)
 		return res;
 
 	/* TX side */
-	ilk_txx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG1(interface));
+	ilk_txx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG1(interface));
 	ilk_txx_cfg1.s.pkt_ena = 0;
-	cvmx_write_csr(CVMX_ILK_TXX_CFG1(interface), ilk_txx_cfg1.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG1(interface), ilk_txx_cfg1.u64);
 
 	/* RX side */
-	ilk_rxx_cfg1.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG1(interface));
+	ilk_rxx_cfg1.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG1(interface));
 	ilk_rxx_cfg1.s.pkt_ena = 0;
-	cvmx_write_csr(CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG1(interface), ilk_rxx_cfg1.u64);
 
 #ifdef CVMX_ILK_STATS_ENA
 	/* RX side stats */
-	ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+	ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 	ilk_rxx_cfg0.s.lnk_stats_ena = 0;
-	cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 
 	/* RX side stats */
-	ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+	ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 	ilk_txx_cfg0.s.lnk_stats_ena = 0;
-	cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 #endif
 
 	return 0;
@@ -1174,9 +1199,11 @@ int cvmx_ilk_disable(int interface)
  *
  * @return Zero, not enabled; One, enabled.
  */
-int cvmx_ilk_get_intf_ena(int interface)
+int cvmx_ilk_get_intf_ena(int xiface)
 {
-	return cvmx_ilk_intf_cfg[interface].intf_en;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int interface = xi.interface - CVMX_ILK_GBL_BASE();
+	return cvmx_ilk_intf_cfg[xi.node][interface].intf_en;
 }
 
 /**
@@ -1192,7 +1219,7 @@ int cvmx_ilk_get_intf_ena(int interface)
 int cvmx_ilk_get_chan_info(int interface, unsigned char **chans, unsigned char *num_chan)
 {
 	*chans = cvmx_ilk_chan_map[interface];
-	*num_chan = cvmx_ilk_chans[interface];
+	*num_chan = cvmx_ilk_chans[0][interface];
 
 	return 0;
 }
@@ -1202,7 +1229,7 @@ int cvmx_ilk_get_chan_info(int interface, unsigned char **chans, unsigned char *
  * For normal ILK mode, enable CRC and skip = 0.
  * For ILK LA mode, disable CRC and set skip to size of ILK header.
  *
- * @param port   IPD port of the ILK header
+ * @param ipd_port   IPD port of the ILK header
  * @param mode   If set, enable LA mode in ILK header, else disable
  *
  * @return ILK header
@@ -1303,6 +1330,7 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 	cvmx_ilk_txx_idx_stat1_t ilk_txx_idx_stat1;
 	cvmx_ilk_txx_mem_stat0_t ilk_txx_mem_stat0;
 	cvmx_ilk_txx_mem_stat1_t ilk_txx_mem_stat1;
+	int node = 0;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return;
@@ -1338,8 +1366,8 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 			if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
 				cvmx_ilk_rxx_pkt_cntx_t rxx_pkt_cntx;
 				cvmx_ilk_rxx_byte_cntx_t rxx_byte_cntx;
-				rxx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_PKT_CNTX(*chan_list, interface));
-				rxx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_BYTE_CNTX(*chan_list, interface));
+				rxx_pkt_cntx.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_PKT_CNTX(*chan_list, interface));
+				rxx_byte_cntx.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_BYTE_CNTX(*chan_list, interface));
 				cvmx_dprintf("ILK%d Channel%d Rx: %llu packets %llu bytes\n", interface,
 					     *chan_list, 
 					     (unsigned long long)rxx_pkt_cntx.s.rx_pkt,
@@ -1368,8 +1396,8 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 				cvmx_ilk_txx_pkt_cntx_t txx_pkt_cntx;
 				cvmx_ilk_txx_byte_cntx_t txx_byte_cntx;
 
-				txx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_PKT_CNTX(*chan_list, interface));
-				txx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_BYTE_CNTX(*chan_list, interface));
+				txx_pkt_cntx.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_PKT_CNTX(*chan_list, interface));
+				txx_byte_cntx.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_BYTE_CNTX(*chan_list, interface));
 				cvmx_dprintf("ILK%d Channel%d Tx: %llu packets %llu bytes\n", interface,
 					     *chan_list,
 					     (unsigned long long)txx_pkt_cntx.s.tx_pkt,
@@ -1424,14 +1452,14 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
 			cvmx_ilk_txx_pkt_cntx_t txx_pkt_cntx;
 			cvmx_ilk_txx_byte_cntx_t txx_byte_cntx;
 
-			rxx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_PKT_CNTX(i, interface));
-			rxx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_RXX_BYTE_CNTX(i, interface));
+			rxx_pkt_cntx.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_PKT_CNTX(i, interface));
+			rxx_byte_cntx.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_BYTE_CNTX(i, interface));
 			cvmx_dprintf("ILK%d Channel%d Rx: %llu packets %llu bytes\n", interface,
 				     i, (unsigned long long)rxx_pkt_cntx.s.rx_pkt,
 				     (unsigned long long)rxx_byte_cntx.s.rx_bytes);
 
-			txx_pkt_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_PKT_CNTX(i, interface));
-			txx_byte_cntx.u64 = cvmx_read_csr(CVMX_ILK_TXX_BYTE_CNTX(i, interface));
+			txx_pkt_cntx.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_PKT_CNTX(i, interface));
+			txx_byte_cntx.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_BYTE_CNTX(i, interface));
 			cvmx_dprintf("ILK%d Channel%d Tx: %llu packets %llu bytes\n", interface,
 				     i, (unsigned long long)txx_pkt_cntx.s.tx_pkt,
 				     (unsigned long long)txx_byte_cntx.s.tx_bytes);
@@ -1451,11 +1479,14 @@ void cvmx_ilk_show_stats(int interface, cvmx_ilk_stats_ctrl_t * pstats)
  *
  * @return Zero on success, negative on failure.
  */
-int cvmx_ilk_lpbk(int interface, cvmx_ilk_lpbk_ena_t enable, cvmx_ilk_lpbk_mode_t mode)
+int cvmx_ilk_lpbk(int xiface, cvmx_ilk_lpbk_ena_t enable, cvmx_ilk_lpbk_mode_t mode)
 {
 	int res = -1;
 	cvmx_ilk_txx_cfg0_t ilk_txx_cfg0;
 	cvmx_ilk_rxx_cfg0_t ilk_rxx_cfg0;
+	struct cvmx_xiface xi = cvmx_helper_xiface_to_node_interface(xiface);
+	int node = xi.node;
+	int interface = xi.interface - CVMX_ILK_GBL_BASE();;
 
 	if (!octeon_has_feature(OCTEON_FEATURE_ILK))
 		return res;
@@ -1466,20 +1497,20 @@ int cvmx_ilk_lpbk(int interface, cvmx_ilk_lpbk_ena_t enable, cvmx_ilk_lpbk_mode_
 	/* internal loopback. only 1 type of loopback can be on at 1 time */
 	if (mode == CVMX_ILK_LPBK_INT) {
 		if (enable == CVMX_ILK_LPBK_ENA) {
-			ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+			ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 			ilk_txx_cfg0.s.ext_lpbk = CVMX_ILK_LPBK_DISA;
 			ilk_txx_cfg0.s.ext_lpbk_fc = CVMX_ILK_LPBK_DISA;
-			cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+			cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 
-			ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+			ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 			ilk_rxx_cfg0.s.ext_lpbk = CVMX_ILK_LPBK_DISA;
 			ilk_rxx_cfg0.s.ext_lpbk_fc = CVMX_ILK_LPBK_DISA;
-			cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
+			cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 		}
 
-		ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+		ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 		ilk_txx_cfg0.s.int_lpbk = enable;
-		cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 
 		res = 0;
 		return res;
@@ -1487,20 +1518,20 @@ int cvmx_ilk_lpbk(int interface, cvmx_ilk_lpbk_ena_t enable, cvmx_ilk_lpbk_mode_
 
 	/* external loopback. only 1 type of loopback can be on at 1 time */
 	if (enable == CVMX_ILK_LPBK_ENA) {
-		ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+		ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 		ilk_txx_cfg0.s.int_lpbk = CVMX_ILK_LPBK_DISA;
-		cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+		cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 	}
 
-	ilk_txx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_TXX_CFG0(interface));
+	ilk_txx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_TXX_CFG0(interface));
 	ilk_txx_cfg0.s.ext_lpbk = enable;
 	ilk_txx_cfg0.s.ext_lpbk_fc = enable;
-	cvmx_write_csr(CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_TXX_CFG0(interface), ilk_txx_cfg0.u64);
 
-	ilk_rxx_cfg0.u64 = cvmx_read_csr(CVMX_ILK_RXX_CFG0(interface));
+	ilk_rxx_cfg0.u64 = cvmx_read_csr_node(node, CVMX_ILK_RXX_CFG0(interface));
 	ilk_rxx_cfg0.s.ext_lpbk = enable;
 	ilk_rxx_cfg0.s.ext_lpbk_fc = enable;
-	cvmx_write_csr(CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
+	cvmx_write_csr_node(node, CVMX_ILK_RXX_CFG0(interface), ilk_rxx_cfg0.u64);
 
 	res = 0;
 	return res;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-ipd.c b/arch/mips/cavium-octeon/executive/cvmx-ipd.c
index 7bdb397..8ad426c 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-ipd.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-ipd.c
@@ -85,7 +85,6 @@ CVMX_SHARED cvmx_ipd_config_t cvmx_ipd_cfg = {.first_mbuf_skip = 184,
 					};
 EXPORT_SYMBOL(cvmx_ipd_cfg);
 
-/* FIXME- review these values, convert to params ? */
 #define IPD_RED_AVG_DLY	1000
 #define IPD_RED_PRB_DLY	1000
 
@@ -438,6 +437,14 @@ void cvmx_ipd_config(uint64_t mbuff_size,
 	cvmx_ipd_wqe_fpa_queue_t wqe_pool;
 	cvmx_ipd_ctl_status_t ipd_ctl_reg;
 
+	/* Enforce 1st skip minimum if WQE shares the buffer with packet */
+	if (octeon_has_feature(OCTEON_FEATURE_NO_WPTR)) {
+		union cvmx_ipd_ctl_status ctl_status;
+		ctl_status.u64 = cvmx_read_csr(CVMX_IPD_CTL_STATUS);
+		if (ctl_status.s.no_wptr != 0 && first_mbuff_skip < 16)
+			first_mbuff_skip = 16;
+	}
+
 	first_skip.u64 = 0;
 	first_skip.s.skip_sz = first_mbuff_skip;
 	cvmx_write_csr(CVMX_IPD_1ST_MBUFF_SKIP, first_skip.u64);
@@ -525,7 +532,6 @@ int cvmx_ipd_setup_red(int pass_thresh, int drop_thresh)
 	int interface;
 	int port;
 
-	/*vinita_to_do modify for 78xx*/
 	if (octeon_has_feature(OCTEON_FEATURE_PKI))
 		return -1;
 	/*
diff --git a/arch/mips/cavium-octeon/executive/cvmx-osm.c b/arch/mips/cavium-octeon/executive/cvmx-osm.c
index e604e66..6209cce 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-osm.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-osm.c
@@ -151,9 +151,9 @@ EXPORT_SYMBOL(cvmx_osm_reserve_banks);
 /**
  * Release consecutive banks in OSM
  *
- * @param start_bank_num - starting bank number 
+ * @param start_bank_num - starting bank number
  * @param num_banks - number of banks
- * @param bank_assign - bank owner
+ * @param bank_owner - bank owner
  * @return 0 on success non zero on failure
  *
  */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pcie.c b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
index e73b40b..bfe0b3b 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pcie.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pcie.c
@@ -42,7 +42,7 @@
  *
  * Interface to PCIe as a host(RC) or target(EP)
  *
- * <hr>$Revision: 104992 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -186,6 +186,7 @@ uint64_t cvmx_pcie_get_mem_size(int pcie_port)
  * @INTERNAL
  * Initialize the RC config space CSRs
  *
+ * @param node      node
  * @param pcie_port PCIe port to initialize
  */
 static void __cvmx_pcie_rc_initialize_config_space(int node, int pcie_port)
@@ -384,7 +385,7 @@ static void __cvmx_pcie_rc_initialize_config_space(int node, int pcie_port)
 	}
 
 	if (OCTEON_IS_MODEL(OCTEON_CN78XX)) {
-		int qlm = pcie_port; /* FIXME */
+		int qlm = pcie_port;
 		int speed = cvmx_qlm_get_gbaud_mhz(qlm);
 		cvmx_pemx_cfg_t pem_cfg;
 		cvmx_pciercx_cfg040_t cfg040;
@@ -474,7 +475,7 @@ static void __cvmx_pcie_rc_initialize_config_space(int node, int pcie_port)
 		cfg092.s.l6urph = 2;
 		cfg092.s.l6utp = 7;
 		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG092(pcie_port), cfg092.u32);
-		/* FIXME: Disable phase 2 and phase 3 equalization */
+		/* Disable phase 2 and phase 3 equalization */
 		cfg548.u32 = CVMX_PCIE_CFGX_READ(pcie_port, CVMX_PCIERCX_CFG548(pcie_port));
 		cfg548.s.ep2p3d = 1;
 		CVMX_PCIE_CFGX_WRITE(pcie_port, CVMX_PCIERCX_CFG548(pcie_port), cfg548.u32);
@@ -999,6 +1000,7 @@ retry:
  * port from reset to a link up state. Software can then begin
  * configuring the rest of the link.
  *
+ * @param node	    node
  * @param pcie_port PCIe port to initialize
  *
  * @return Zero on success
@@ -1087,7 +1089,7 @@ static int __cvmx_pcie_rc_initialize_link_gen2(int node, int pcie_port)
 		} while (pciercx_cfg032.s.ls != 3);
 
 		pem_cfg.u64 = CVMX_READ_CSR(CVMX_PEMX_CFG(pcie_port));
-		low_qlm = pcie_port;  /* FIXME */
+		low_qlm = pcie_port;
 		high_qlm = (pem_cfg.cn78xx.lanes8) ? low_qlm+1 : low_qlm;
 
 		/* Toggle cfg_rx_dll_locken_ovvrd_en and rx_resetn_ovrrd_en across
@@ -1739,6 +1741,7 @@ int cvmx_pcie_rc_shutdown(int pcie_port)
  * @INTERNAL
  * Build a PCIe config space request address for a device
  *
+ * @param node	    node
  * @param pcie_port PCIe port to access
  * @param bus       Sub bus
  * @param dev       Device ID
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
index 5138aaf..10a18f3 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki-resources.c
@@ -298,7 +298,7 @@ int cvmx_pki_pcam_entry_alloc(int node, int index, int bank, uint64_t cluster_ma
 		}
 	}
 	index = rs;
-	/*vinita to_do , implement cluster handle, for now assume
+	/* implement cluster handle for pass2, for now assume
 	all clusters will have same base index*/
 	return index;
 }
@@ -417,6 +417,11 @@ void __cvmx_pki_global_rsrc_free(int node)
 		cvmx_printf("ERROR pki-rsrc:Failed to release all qpg entries\n");
 	}
 
+	cnt = CVMX_PKI_NUM_BPID;
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_BPID(node), 0, cnt) == -1) {
+		cvmx_printf("ERROR pki-rsrc:Failed to release all bpids\n");
+	}
+
 	cnt = CVMX_PKI_NUM_PCAM_ENTRY;
 	for (cluster = 0; cluster < CVMX_PKI_NUM_CLUSTER; cluster++) {
 		for (bank = 0; bank < CVMX_PKI_NUM_PCAM_BANK; bank++) {
@@ -428,3 +433,62 @@ void __cvmx_pki_global_rsrc_free(int node)
 	}
 
 }
+
+/**
+ * This function allocates/reserves a bpid from pool of global bpid per node.
+ * @param node	node to allocate bpid from.
+ * @param bpid	bpid  to allocate, if -1 it will be allocated
+ *		first available boid from bpid resource. If index is positive
+ *		number and in range, it will try to allocate specified bpid.
+ * @return 	bpid number on success,
+ *		-1 on alloc failure.
+ *		-2 on resource already reserved.
+ */
+int cvmx_pki_bpid_alloc(int node, int bpid)
+{
+	int rs;
+
+	if (cvmx_create_global_resource_range(CVMX_GR_TAG_BPID(node), CVMX_PKI_NUM_BPID)) {
+		cvmx_printf("ERROR: Failed to create bpid global resource\n");
+		return -1;
+	}
+	if (bpid >= 0) {
+		rs = cvmx_reserve_global_resource_range(CVMX_GR_TAG_BPID(node),
+				bpid, bpid, 1);
+		if (rs == -1) {
+			cvmx_dprintf("INFO: bpid %d is already reserved\n", (int)bpid);
+			return CVMX_RESOURCE_ALREADY_RESERVED;
+		}
+	} else {
+		rs = cvmx_allocate_global_resource_range(CVMX_GR_TAG_BPID(node), bpid, 1, 1);
+		if (rs == -1) {
+			cvmx_printf("ERROR: Failed to allocate bpid\n");
+			return CVMX_RESOURCE_ALLOC_FAILED;
+		}
+		if (rs == 0) { /* don't use bpid 0 */
+			rs = cvmx_allocate_global_resource_range(CVMX_GR_TAG_BPID(node), bpid, 1, 1);
+			if (rs == -1) {
+				cvmx_printf("ERROR: Failed to allocate bpid\n");
+				return CVMX_RESOURCE_ALLOC_FAILED;
+			}
+		}
+	}
+	bpid = rs;
+	return bpid;
+}
+
+/**
+ * This function frees a bpid from pool of global bpid per node.
+ * @param node	 node to free bpid from.
+ * @param bpid	 bpid to free
+ * @return 	 0 on success, -1 on failure or
+ */
+int cvmx_pki_bpid_free(int node, int bpid)
+{
+	if (cvmx_free_global_resource_range_with_base(CVMX_GR_TAG_BPID(node), bpid, 1) == -1) {
+		cvmx_printf("ERROR Failed to release bpid %d\n", (int)bpid);
+		return -1;
+	}
+	return 0;
+}
+
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pki.c b/arch/mips/cavium-octeon/executive/cvmx-pki.c
index a2bb7a3..574bf69 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pki.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pki.c
@@ -415,7 +415,7 @@ void cvmx_pki_read_tag_config(int node, int style, uint64_t cluster_mask,
 	tag_cfg->tag_fields.mpls_label = style_alg_reg.s.tag_mpls0;
 	tag_cfg->tag_fields.input_port = style_alg_reg.s.tag_prt;
 
-	/** vinita_to_do get mask tag*/
+	/** TO_DO get mask tag*/
 }
 
  /** This function writes/configures parameters associated with tag configuration in hardware.
@@ -462,7 +462,7 @@ void cvmx_pki_write_tag_config(int node, int style, uint64_t cluster_mask,
 			style_alg_reg.s.tag_prt = tag_cfg->tag_fields.input_port;
 			cvmx_write_csr_node(node, CVMX_PKI_CLX_STYLEX_ALG(style, cluster), style_alg_reg.u64);
 
-			/* vinita_to_do add mask tag */
+			/* TO_DO add mask tag */
 		}
 		cluster++;
 	}
@@ -727,7 +727,7 @@ int cvmx_pki_pcam_write_entry(int node, int index, uint64_t cluster_mask,
  *			1-enable 0-disable
  * @param ena_drop	Enable/disable tail drop when max drop level exceeds
  *			1-enable 0-disable
- * @param ena_red	Enable/Disable asserting backpressure on bpid when
+ * @param ena_bp 	Enable/Disable asserting backpressure on bpid when
  *			max DROP level exceeds.
  *			1-enable 0-disable
  */
@@ -819,7 +819,7 @@ int cvmx_pki_get_pkind_style(int node, int pkind)
  * make sure software allocate enough buffers to now have wqe separate from packet data.
  * @param node		node number.
  * @param style		style to configure.
- * @param pkt_outside_wqe.	0 = The packet link pointer will be at word [FIRST_SKIP]
+ * @param pkt_outside_wqe	0 = The packet link pointer will be at word [FIRST_SKIP]
  *				immediately followed by packet data, in the same buffer
  *				as the work queue entry.
  *				1 = The packet link pointer will be at word [FIRST_SKIP] in a new
@@ -951,6 +951,7 @@ void cvmx_pki_dis_frame_len_chk(int node, int pknd)
  * This function shows the qpg table entries,
  * read directly from hardware.
  * @param node	node number
+ * @param num_entry number of entries to show
  */
 void cvmx_pki_show_qpg_entries(int node, uint16_t num_entry)
 {
@@ -1047,6 +1048,7 @@ void cvmx_pki_show_valid_pcam_entries(int node)
  * This function shows the pkind attributes in readable format,
  * read directly from hardware.
  * @param node    node number
+ * @param pkind   pkind info to print
  */
 void cvmx_pki_show_pkind_attributes(int node, int pkind)
 {
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko.c b/arch/mips/cavium-octeon/executive/cvmx-pko.c
index 2e5ac5a..e5a68f2 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko.c
@@ -603,7 +603,7 @@ cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue,
 			port, base_queue, (base_queue+num_queues-1),
 			priority[0],priority[1], priority[2], priority[3]);
 
-	/* FIXME: the need to handle ILLEGAL_PID port argument
+	/* The need to handle ILLEGAL_PID port argument
 	 * is obsolete now, the code here can be simplified.
 	 */
 
@@ -783,7 +783,7 @@ cvmx_pko_return_value_t cvmx_pko_config_port(int port, int base_queue,
  * Configure queues for an internal port.
  * @INTERNAL
  * @param pko_port PKO internal port number
- * FIXME: for PKO2 only, equivalent to cvmx_pko_config_port()
+ * @note this is the PKO2 equivalent to cvmx_pko_config_port()
  */
 static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port, int base_queue,
 				       int num_queues,
@@ -931,7 +931,7 @@ static cvmx_pko_return_value_t cvmx_pko2_config_port(short ipd_port, int base_qu
 		cvmx_write_csr(CVMX_PKO_MEM_IQUEUE_PTRS, config.u64);
 	}
 
-// FIXME: detect errors
+	/* Error detection is resirable here */
 	return 0;
 }
 
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
index e1f7192..587861c 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3-queue.c
@@ -65,8 +65,7 @@
 static int debug = 0;	/* 1 for basic, 2 for detailed trace */
 
 /* Minimum MTU assumed for shaping configuration */
-static unsigned __pko3_min_mtu = 9080;
-/* FIXME: The above could be made a per-port config param */
+static unsigned __pko3_min_mtu = 9080;	/* Could be per-port in the future */
 
 struct cvmx_pko3_dq {
 #ifdef __BIG_ENDIAN_BITFIELD
@@ -108,7 +107,7 @@ int cvmx_pko3_get_queue_base(int ipd_port)
 	dq_table = __cvmx_pko3_dq_table + CVMX_PKO3_IPD_NUM_MAX * xp.node;
 
 	if(dq_table[i].dq_count > 0)
-		ret = cvmx_helper_node_to_ipd_port(xp.node, dq_table[i].dq_base);
+		ret = xp.node << 10 | dq_table[i].dq_base;
 
 	return ret;
 }
@@ -187,12 +186,12 @@ int __cvmx_pko3_dq_table_setup(void)
  * by priority) for a given IPD-port, which is either a physical port,
  * or a channel on a channelized interface (i.e. ILK).
  *
- * @param interface is the physical interface number
- * @param port is either a physical port on an interface
- * @param or a channel of an ILK interface
+ * @param xiface is the physical interface number
+ * @param index is either a physical port on an interface
+ *        or a channel of an ILK interface
  * @param dq_base is the first Descriptor Queue number in a consecutive range
  * @param dq_count is the number of consecutive Descriptor Queues leading
- * @param the same channel or port.
+ *        the same channel or port.
  *
  * Only a consecurive range of Descriptor Queues can be associated with any
  * given channel/port, and usually they are ordered from most to least
@@ -212,8 +211,17 @@ int __cvmx_pko3_ipd_dq_register(int xiface, int index,
 
         if(__cvmx_helper_xiface_is_null(xiface))
 		ipd_port = CVMX_PKO3_IPD_PORT_NULL;
-	else
-		ipd_port = cvmx_helper_get_ipd_port(xiface, index);
+	else {
+		int p;
+		p = cvmx_helper_get_ipd_port(xiface, index);
+		if (p < 0) {
+			cvmx_dprintf("ERROR: %s: xiface %#x has no IPD port\n",
+			__func__, xiface);
+			return -1;
+		}
+		ipd_port = p;
+	}
+
 
 	xp = cvmx_helper_ipd_port_to_xport(ipd_port);
 	i = CVMX_PKO3_SWIZZLE_IPD ^ xp.port;
@@ -393,7 +401,6 @@ void cvmx_pko3_map_channel(unsigned node,
  * @param child_base is the first child queue number in the static prioriy childs.
  * @param child_rr_prio is the round robin childs priority.
  * @param mac_num is the mac number of the mac that will be tied to this port_queue.
- * @return returns none.
  */
 static void cvmx_pko_configure_port_queue(int node, int port_queue,
 					 int child_base, int child_rr_prio,
@@ -461,7 +468,6 @@ static void cvmx_pko_configure_l2_queue(int node, int queue, int parent_queue,
  * @param rr_quantum is this queue's round robin quantum value.
  * @param child_base is the first child queue number in the static prioriy childs.
  * @param child_rr_prio is the round robin childs priority.
- * @return returns none.
  */
 static void cvmx_pko_configure_l3_queue(int node, int queue, int parent_queue,
 					       int prio, int rr_quantum,
@@ -510,7 +516,6 @@ static void cvmx_pko_configure_l3_queue(int node, int queue, int parent_queue,
  * @param rr_quantum is this queue's round robin quantum value.
  * @param child_base is the first child queue number in the static prioriy childs.
  * @param child_rr_prio is the round robin childs priority.
- * @return returns none.
  */
 static void cvmx_pko_configure_l4_queue(int node, int queue, int parent_queue,
 					       int prio, int rr_quantum,
@@ -558,7 +563,6 @@ static void cvmx_pko_configure_l4_queue(int node, int queue, int parent_queue,
  * @param rr_quantum is this queue's round robin quantum value.
  * @param child_base is the first child queue number in the static prioriy childs.
  * @param child_rr_prio is the round robin childs priority.
- * @return returns none.
  */
 static void cvmx_pko_configure_l5_queue(int node, int queue, int parent_queue,
 					       int prio, int rr_quantum,
@@ -606,7 +610,6 @@ static void cvmx_pko_configure_l5_queue(int node, int queue, int parent_queue,
  * @param rr_quantum is this queue's round robin quantum value.
  * @param child_base is the first child queue number in the static prioriy childs.
  * @param child_rr_prio is the round robin childs priority.
- * @return returns none.
  */
 static void cvmx_pko_configure_dq(int node, int dq, int parent_queue,
 				int prio, int rr_quantum,
@@ -698,6 +701,7 @@ static const struct {
  * could be multiple L2 SQs attached to a single L1 PQ, either in a
  * fair round-robin scheduling, or with static and/or round-robin priorities.
  *
+ * @param node on which to operate
  * @param mac_num is the LMAC number to that is associated with the Port Queue,
  * @param which is identical to the Port Queue number that is configured
  * @param child_base is the number of the first L2 SQ attached to the PQ
@@ -792,10 +796,10 @@ int cvmx_pko3_pq_config_children(unsigned node, unsigned mac_num,
  * The children can have fair round-robin or priority-based scheduling
  * when multiple children are assigned a single parent.
  *
+ * @param node on which to operate
  * @param parent_level is the level of the parent queue, 2 to 5.
  * @param parent_queue is the number of the parent Scheduler Queue
  * @param child_base is the number of the first child SQ or DQ to assign to
- * @param parent
  * @param child_count is the number of consecutive children to assign
  * @param stat_prio_count is the priority setting for the children L2 SQs
  *
@@ -896,7 +900,7 @@ int cvmx_pko3_sq_config_children(unsigned int node, unsigned parent_level,
  *
  * @param tclk is the time-wheel clock for the specific shaper
  * @param reg is a pointer to a register structure
- * @param rate_kips is the requested bit rate in kilobits/sec
+ * @param rate_kbips is the requested bit rate in kilobits/sec
  * @param burst_bytes is the size of maximum burst in bytes
  *
  * @return A negative number means the transfer rate could
@@ -1047,7 +1051,7 @@ static int cvmx_pko3_shaper_rate_compute(unsigned long tclk,
  * @param node The OCI node where the target port is located
  * @param pq_num The L1/PQ queue number for this setting
  * @param rate_kbips The desired throughput in kilo-bits-per-second
- * @param burst_size The size of a burst in bytes, at least MTU
+ * @param burst_bytes The size of a burst in bytes, at least MTU
  *
  * @return Returns zero if both settings applied within allowed tolerance,
  * otherwise the error is returned in parts-per-million.
@@ -1106,7 +1110,7 @@ int cvmx_pko3_port_cir_set(unsigned node, unsigned pq_num,
  * @param node The OCI node where the target port is located
  * @param dq_num The descriptor queue number for this setting
  * @param rate_kbips The desired throughput in kilo-bits-per-second
- * @param burst_size The size of a burst in bytes, at least MTU
+ * @param burst_bytes The size of a burst in bytes, at least MTU
  *
  * @return Returns zero if both settings applied within allowed tolerance,
  * otherwise the error is returned in parts-per-million.
@@ -1173,7 +1177,7 @@ int cvmx_pko3_dq_cir_set(unsigned node, unsigned dq_num,
  * @param node The OCI node where the target port is located
  * @param dq_num The descriptor queue number for this setting
  * @param rate_kbips The desired throughput in kilo-bits-per-second
- * @param burst_size The size of a burst in bytes, at least MTU
+ * @param burst_bytes The size of a burst in bytes, at least MTU
  *
  * @return Returns zero if both settings applied within allowed tolerance,
  * otherwise the error is returned in parts-per-million.
diff --git a/arch/mips/cavium-octeon/executive/cvmx-pko3.c b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
index b421905..6bab962 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-pko3.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-pko3.c
@@ -1,5 +1,5 @@
 /***********************license start***************
- * Copyright (c) 2003-2013  Cavium Inc. (support@cavium.com). All rights
+ * Copyright (c) 2014  Cavium Inc. (support@cavium.com). All rights
  * reserved.
  *
  *
@@ -333,7 +333,7 @@ int cvmx_pko3_hw_disable(int node)
 	return 0;
 }
 
- /** Open configured descriptor queues before queueing packets into them.
+/** Open configured descriptor queues before queueing packets into them.
  *
  * @param node is to specify the node to which this configuration is applied.
  * @param dq is the descriptor queue number to be opened.
@@ -364,7 +364,7 @@ int cvmx_pko_dq_open(int node, int dq)
 }
 
 
- /*
+/**
  * Close a descriptor queue
  *
  * @param node is to specify the node to which this configuration is applied.
@@ -406,6 +406,9 @@ int cvmx_pko3_dq_close(int node, int dq)
  * Before closing a DQ, this call will drain all pending traffic
  * on the DQ to the NULL MAC, which will circumvent any traffic
  * shaping and flow control to quickly reclaim all packet buffers.
+ *
+ * @param node is to specify the node to which this configuration is applied.
+ * @param dq is the descriptor queue number to be drained.
  */
 void cvmx_pko3_dq_drain(int node, int dq)
 {
@@ -718,8 +721,6 @@ static int cvmx_pko_setup_macs(int node)
 		unsigned mac_fifo_cnt;
 		unsigned tmp;
 
-		/* FIXME- this section has no basis in HRM, revisit */
-		/* Loosely based on packet/clear78.x */
 		pko_fifo_cnt = cvmx_pko3_mac_table[mac_num].fifo_cnt;
 		mac_fifo_cnt = cvmx_pko3_mac_table[mac_num].mac_fifo_cnt;
 
@@ -734,7 +735,6 @@ static int cvmx_pko_setup_macs(int node)
 		fifo_size = (2 * 1024) + (1024 / 2); /* 2.5KiB */
 		fifo_credit = pko_fifo_cnt * fifo_size;
 
-		/* FIXME- This code is chip-dependent, not portable! */
 		switch (mac_num) {
 			case 0: /* loopback */
 				mac_credit = 4096; /* From HRM Sec 13.0 */
@@ -926,6 +926,10 @@ EXPORT_SYMBOL(cvmx_pko3_interface_options);
  * The `min_pad` parameter must be in agreement with the interface-level
  * padding option for all descriptor queues assigned to that particular
  * interface/port.
+ *
+ * @param node on which to operate
+ * @param dq descriptor queue to set
+ * @param min_pad minimum padding to set for dq
  */
 void cvmx_pko3_dq_options(unsigned node, unsigned dq, bool min_pad)
 {
@@ -1360,8 +1364,8 @@ int cvmx_pko3_pdesc_transmit(cvmx_pko3_pdesc_t *pdesc, uint16_t dq)
 	}
 
         /* Derive destination node from dq */
-        port_node = dq >> 14;
-        dq &= (1<<10)-1;
+	port_node = dq >> 10;
+	dq &= (1<<10)-1;
 
         /* Send the PKO3 command into the Descriptor Queue */
         pko_status = __cvmx_pko3_do_dma(port_node, dq,
@@ -1383,10 +1387,15 @@ int cvmx_pko3_pdesc_transmit(cvmx_pko3_pdesc_t *pdesc, uint16_t dq)
 int cvmx_pko3_pdesc_append_free(cvmx_pko3_pdesc_t *pdesc, uint64_t addr,
 			     unsigned gaura)
 {
+	cvmx_pko_send_hdr_t *hdr_s;
 	cvmx_pko_send_free_t free_s;
 	cvmx_pko_send_aura_t aura_s;
 
-	if (pdesc->last_aura != (short) gaura) {	
+	hdr_s = (void *) &pdesc->word[0];
+
+	if (pdesc->last_aura == -1) {
+		pdesc->last_aura = hdr_s->s.aura = gaura;
+	} else if (pdesc->last_aura != (short) gaura) {
 		aura_s.s.aura = gaura;
 		aura_s.s.offset = 0;
 		aura_s.s.alg = AURAALG_NOP;
@@ -1399,8 +1408,6 @@ int cvmx_pko3_pdesc_append_free(cvmx_pko3_pdesc_t *pdesc, uint64_t addr,
 	free_s.u64 = 0;
 	free_s.s.subdc4 = CVMX_PKO_SENDSUBDC_FREE;
 	free_s.s.addr = addr;
-	if (pdesc->last_aura == -1)
-		pdesc->last_aura = gaura;
 
 	return cvmx_pko3_pdesc_subdc_add(pdesc, free_s.u64);
 }
@@ -1497,8 +1504,9 @@ int cvmx_pko3_pdesc_buf_append(cvmx_pko3_pdesc_t *pdesc, void *p_data,
  * @param wqe Work Queue Entry in a model-native format.
  * @param node The OCI node of the SSO where the WQE will be delivered.
  * @param group The SSO group where the WQE is delivered.
- * @param tt The SSO Tag Type for the WQE. If tt is not NULL, WQE should
- * contain a valid tag value for the work entry.
+ * @param tt The SSO Tag Type for the WQE. If tt is not NULL, tag should be a
+ * valid tag value.
+ * @param tag Valid tag value to assign to WQE
  *
  * @return Returns 0 on success, -1 on error.
  *
@@ -1599,7 +1607,7 @@ int cvmx_pko3_pdesc_notify_decrement(cvmx_pko3_pdesc_t *pdesc,
  * Clearing of a single byte is requested by this function.
  *
  * @param pdesc Packet Descriptor.
- * @param p_counter A pointer to a byte location.
+ * @param p_mem A pointer to a byte location.
  *
  * @return Returns 0 on success, -1 on failure.
  */
@@ -1644,8 +1652,8 @@ int cvmx_pko3_pdesc_notify_memclr(cvmx_pko3_pdesc_t *pdesc,
  * software-based decoding to handle modified or originated
  * packets correctly.
  *
- * FIXME:
- * Add simple accessors to read the decoded protocol fields.
+ * @note
+ * Need to add simple accessors to read the decoded protocol fields.
  */
 static int cvmx_pko3_pdesc_hdr_offsets(cvmx_pko3_pdesc_t *pdesc)
 {
@@ -1675,7 +1683,7 @@ static int cvmx_pko3_pdesc_hdr_offsets(cvmx_pko3_pdesc_t *pdesc)
 		if (pdesc->pki_word2.lf_hdr_type == CVMX_PKI_LTYPE_E_SCTP)
 			pdesc->ckl4_alg = CKL4ALG_SCTP;
 	}
-	/* FIXME: consider ARP as L3 too ? what about IPfrag ? */
+	/* May need to add logic for ARP, IPfrag packets here */
 
 	pdesc->hdr_offsets = 1;	/* make sure its done once */
 	return 0;
@@ -1812,8 +1820,6 @@ int cvmx_pko3_pdesc_hdr_push(cvmx_pko3_pdesc_t *pdesc,
 	if (layer >= 3) {
 		hdr_s->s.ckl3 = 1;
 		hdr_s->s.ckl4 = pdesc->ckl4_alg;
-		/* FIXME: decode L4 alg in case the header was generated */
-		/* FIXME: CKL4 not supported in simulator */
 	}
 
 	return headroom;
diff --git a/arch/mips/cavium-octeon/executive/cvmx-qlm.c b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
index c36ed9f..8fc247b 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-qlm.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-qlm.c
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 105514 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 #ifdef CVMX_BUILD_FOR_LINUX_KERNEL
 #include <asm/octeon/cvmx.h>
@@ -157,7 +157,9 @@ int cvmx_qlm_get_num(void)
 /**
  * Return the qlm number based on the interface
  *
- * @param interface  Interface to look up
+ * @param xiface  interface to look up
+ *
+ * @return 0 on success other on failure
  */
 int cvmx_qlm_interface(int xiface)
 {
@@ -225,6 +227,8 @@ int cvmx_qlm_interface(int xiface)
 /**
  * Return number of lanes for a given qlm
  *
+ * @param qlm    QLM to examine
+ *
  * @return  Number of lanes
  */
 int cvmx_qlm_get_lanes(int qlm)
diff --git a/arch/mips/cavium-octeon/executive/cvmx-srio.c b/arch/mips/cavium-octeon/executive/cvmx-srio.c
index 4b0553b..3bf4b7f 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-srio.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-srio.c
@@ -745,7 +745,7 @@ int cvmx_srio_initialize(int srio_port, cvmx_srio_initialize_flags_t flags)
 	sli_mem_access_ctl.s.timer = 127;	/* Wait up to 127 cycles for more data */
 	cvmx_write_csr(CVMX_PEXP_SLI_MEM_ACCESS_CTL, sli_mem_access_ctl.u64);
 
-	/* FIXME: Disable sending a link request when the SRIO link is
+	/* Disable sending a link request when the SRIO link is
 	   brought up. For unknown reasons this code causes issues with some SRIO
 	   devices. As we currently don't support hotplug in software, this code
 	   should never be needed.  Without link down/up events, the ACKs should
@@ -1479,7 +1479,7 @@ uint64_t cvmx_srio_physical_map(int srio_port, cvmx_srio_write_mode_t write_op,
 	needed_subid.s.port = srio_port;
 	needed_subid.s.nmerge = 0;
 
-	/* FIXME: We might want to use the device ID swapping modes so the device
+	/* We might want to use the device ID swapping modes so the device
 	   ID is part of the lower address bits. This would allow many more
 	   devices to share S2M_TYPE indexes. This would require "base+size-1"
 	   to fit in bits [17:0] or bits[25:0] for 8 bits of device ID */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-twsi.c b/arch/mips/cavium-octeon/executive/cvmx-twsi.c
index d750e4d..81aaefe 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-twsi.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-twsi.c
@@ -412,7 +412,6 @@ retry:
 	return num_bytes;
 #endif
 }
-EXPORT_SYMBOL(cvmx_twsix_read);
 
 /**
  * Perform a twsi write operation to a 7 bit device address.
@@ -508,7 +507,6 @@ retry:
 	return 0;
 #endif
 }
-EXPORT_SYMBOL(cvmx_twsix_write);
 
 /**
  * Write 1-8 bytes to a TWSI device using an internal address.
@@ -680,7 +678,6 @@ retry:
 	return num_bytes;
 #endif
 }
-EXPORT_SYMBOL(cvmx_twsix_write_ia);
 
 #ifndef CVMX_BUILD_FOR_LINUX_KERNEL
 /* Controller command patterns */
diff --git a/arch/mips/cavium-octeon/executive/cvmx-usb.c b/arch/mips/cavium-octeon/executive/cvmx-usb.c
index 79558be..da6940a 100644
--- a/arch/mips/cavium-octeon/executive/cvmx-usb.c
+++ b/arch/mips/cavium-octeon/executive/cvmx-usb.c
@@ -2400,7 +2400,7 @@ static int __cvmx_usb_submit_transaction(cvmx_usb_internal_state_t * usb,
 	transaction->buffer = buffer;
 	transaction->buffer_length = buffer_length;
 	transaction->control_header = control_header;
-	transaction->iso_start_frame = iso_start_frame;	// FIXME: This is not used, implement it
+	transaction->iso_start_frame = iso_start_frame;	// This is not used, need to implement it.
 	transaction->iso_number_packets = iso_number_packets;
 	transaction->iso_packets = iso_packets;
 	transaction->callback = callback;
diff --git a/arch/mips/include/asm/octeon/cvmx-atomic.h b/arch/mips/include/asm/octeon/cvmx-atomic.h
index f4bfb75..11de3e8 100644
--- a/arch/mips/include/asm/octeon/cvmx-atomic.h
+++ b/arch/mips/include/asm/octeon/cvmx-atomic.h
@@ -42,7 +42,7 @@
  *
  * This file provides atomic operations
  *
- * <hr>$Revision: 73845 $<hr>
+ * <hr>$Revision: 106271 $<hr>
  *
  *
  */
@@ -82,11 +82,12 @@ static inline void cvmx_atomic_add32_nosync(int32_t * ptr, int32_t incr)
 	if (OCTEON_IS_MODEL(OCTEON_CN3XXX)) {
 		uint32_t tmp;
 
-		__asm__ __volatile__(".set noreorder         \n"
+		__asm__ __volatile__(".set push         \n"
+				     ".set noreorder         \n"
 				     "1: ll   %[tmp], %[val] \n"
 				     "   addu %[tmp], %[inc] \n"
 				     "   sc   %[tmp], %[val] \n"
-				     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp)
+				     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp)
 				     :[inc] "r"(incr)
 				     :"memory");
 	} else {
@@ -161,11 +162,12 @@ static inline void cvmx_atomic_add64_nosync(int64_t * ptr, int64_t incr)
 #else
 	if (OCTEON_IS_MODEL(OCTEON_CN3XXX)) {
 		uint64_t tmp;
-		__asm__ __volatile__(".set noreorder         \n"
+		__asm__ __volatile__(".set push         \n"
+				     ".set noreorder         \n"
 				     "1: lld  %[tmp], %[val] \n"
 				     "   daddu %[tmp], %[inc] \n"
 				     "   scd  %[tmp], %[val] \n"
-				     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp)
+				     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp)
 				     :[inc] "r"(incr)
 				     :"memory");
 	} else {
@@ -234,14 +236,15 @@ static inline uint32_t cvmx_atomic_compare_and_store32_nosync(uint32_t * ptr, ui
 {
 	uint32_t tmp, ret;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "1: ll   %[tmp], %[val] \n"
 			     "   li   %[ret], 0     \n"
 			     "   bne  %[tmp], %[old], 2f \n"
 			     "   move %[tmp], %[new_val] \n"
 			     "   sc   %[tmp], %[val] \n"
 			     "   beqz %[tmp], 1b     \n"
-			     "   li   %[ret], 1      \n" "2: nop               \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
+			     "   li   %[ret], 1      \n" "2: nop               \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
 			     :[old] "r"(old_val),[new_val] "r"(new_val)
 			     :"memory");
 
@@ -287,14 +290,15 @@ static inline uint64_t cvmx_atomic_compare_and_store64_nosync(uint64_t * ptr, ui
 {
 	uint64_t tmp, ret;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "1: lld  %[tmp], %[val] \n"
 			     "   li   %[ret], 0     \n"
 			     "   bne  %[tmp], %[old], 2f \n"
 			     "   move %[tmp], %[new_val] \n"
 			     "   scd  %[tmp], %[val] \n"
 			     "   beqz %[tmp], 1b     \n"
-			     "   li   %[ret], 1      \n" "2: nop               \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
+			     "   li   %[ret], 1      \n" "2: nop               \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
 			     :[old] "r"(old_val),[new_val] "r"(new_val)
 			     :"memory");
 
@@ -356,12 +360,13 @@ static inline int64_t cvmx_atomic_fetch_and_add64_nosync(int64_t * ptr, int64_t
 #else
 	{
 		uint64_t tmp;
-		__asm__ __volatile__(".set noreorder          \n"
+		__asm__ __volatile__(".set push         \n"
+				     ".set noreorder         \n"
 				     "1: lld   %[tmp], %[val] \n"
 				     "   move  %[ret], %[tmp] \n"
 				     "   daddu %[tmp], %[inc] \n"
 				     "   scd   %[tmp], %[val] \n"
-				     "   beqz  %[tmp], 1b     \n" "   nop                  \n" ".set reorder            \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
+				     "   beqz  %[tmp], 1b     \n" "   nop                  \n" ".set pop            \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
 				     :[inc] "r"(incr)
 				     :"memory");
 	}
@@ -425,12 +430,13 @@ static inline int32_t cvmx_atomic_fetch_and_add32_nosync(int32_t * ptr, int32_t
 	{
 		uint32_t tmp;
 
-		__asm__ __volatile__(".set noreorder         \n"
+		__asm__ __volatile__(".set push         \n"
+				     ".set noreorder         \n"
 				     "1: ll   %[tmp], %[val] \n"
 				     "   move %[ret], %[tmp] \n"
 				     "   addu %[tmp], %[inc] \n"
 				     "   sc   %[tmp], %[val] \n"
-				     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
+				     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
 				     :[inc] "r"(incr)
 				     :"memory");
 	}
@@ -477,12 +483,13 @@ static inline uint64_t cvmx_atomic_fetch_and_bset64_nosync(uint64_t * ptr, uint6
 {
 	uint64_t tmp, ret;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "1: lld  %[tmp], %[val] \n"
 			     "   move %[ret], %[tmp] \n"
 			     "   or   %[tmp], %[msk] \n"
 			     "   scd  %[tmp], %[val] \n"
-			     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
+			     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
 			     :[msk] "r"(mask)
 			     :"memory");
 
@@ -506,12 +513,13 @@ static inline uint32_t cvmx_atomic_fetch_and_bset32_nosync(uint32_t * ptr, uint3
 {
 	uint32_t tmp, ret;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "1: ll   %[tmp], %[val] \n"
 			     "   move %[ret], %[tmp] \n"
 			     "   or   %[tmp], %[msk] \n"
 			     "   sc   %[tmp], %[val] \n"
-			     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
+			     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
 			     :[msk] "r"(mask)
 			     :"memory");
 
@@ -535,13 +543,14 @@ static inline uint64_t cvmx_atomic_fetch_and_bclr64_nosync(uint64_t * ptr, uint6
 {
 	uint64_t tmp, ret;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "   nor  %[msk], 0      \n"
 			     "1: lld  %[tmp], %[val] \n"
 			     "   move %[ret], %[tmp] \n"
 			     "   and  %[tmp], %[msk] \n"
 			     "   scd  %[tmp], %[val] \n"
-			     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret),[msk] "+r"(mask)
+			     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret),[msk] "+r"(mask)
 			     ::"memory");
 
 	return (ret);
@@ -564,13 +573,14 @@ static inline uint32_t cvmx_atomic_fetch_and_bclr32_nosync(uint32_t * ptr, uint3
 {
 	uint32_t tmp, ret;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "   nor  %[msk], 0      \n"
 			     "1: ll   %[tmp], %[val] \n"
 			     "   move %[ret], %[tmp] \n"
 			     "   and  %[tmp], %[msk] \n"
 			     "   sc   %[tmp], %[val] \n"
-			     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret),[msk] "+r"(mask)
+			     "   beqz %[tmp], 1b     \n" "   nop                 \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret),[msk] "+r"(mask)
 			     ::"memory");
 
 	return (ret);
@@ -608,13 +618,17 @@ static inline uint64_t cvmx_atomic_swap64_nosync(uint64_t * ptr, uint64_t new_va
 #else
 	{
 		uint64_t tmp;
-		__asm__ __volatile__(".set noreorder         \n"
+		__asm__ __volatile__(".set push         \n"
+				     ".set noreorder         \n"
 				     "1: lld  %[ret], %[val] \n"
 				     "   move %[tmp], %[new_val] \n"
 				     "   scd  %[tmp], %[val] \n"
-				     "   beqz %[tmp],  1b    \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
-				     :[new_val] "r"(new_val)
-				     :"memory");
+				     "   beqz %[tmp],  1b    \n"
+				     "     nop                 \n"
+				     ".set pop           \n"
+				     : [val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
+				     : [new_val] "r"(new_val)
+				     : "memory");
 	}
 #endif
 
@@ -654,11 +668,12 @@ static inline uint32_t cvmx_atomic_swap32_nosync(uint32_t * ptr, uint32_t new_va
 	{
 		uint32_t tmp;
 
-		__asm__ __volatile__(".set noreorder         \n"
+		__asm__ __volatile__(".set push         \n"
+				     ".set noreorder         \n"
 				     "1: ll   %[ret], %[val] \n"
 				     "   move %[tmp], %[new_val] \n"
 				     "   sc   %[tmp], %[val] \n"
-				     "   beqz %[tmp],  1b    \n" "   nop                 \n" ".set reorder           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
+				     "   beqz %[tmp],  1b    \n" "   nop                 \n" ".set pop           \n":[val] "+m"(*ptr),[tmp] "=&r"(tmp),[ret] "=&r"(ret)
 				     :[new_val] "r"(new_val)
 				     :"memory");
 	}
diff --git a/arch/mips/include/asm/octeon/cvmx-coremask.h b/arch/mips/include/asm/octeon/cvmx-coremask.h
index bfb65ba..0d24935 100644
--- a/arch/mips/include/asm/octeon/cvmx-coremask.h
+++ b/arch/mips/include/asm/octeon/cvmx-coremask.h
@@ -60,7 +60,7 @@
  * provide future compatibility if more cores are added to future processors
  * or more nodes are supported.
  *
- * <hr>$Revision: 104294 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  *
  */
 
@@ -292,7 +292,6 @@ static inline int cvmx_coremask_clear_core(cvmx_coremask_t *pcm, int core)
  * Clear ``current core'' from the coremask.
  *
  * @param pcm is the pointer to the coremask.
- * @param core
  * @return 0.
  */
 static inline int cvmx_coremask_clear_self(cvmx_coremask_t *pcm)
@@ -322,7 +321,6 @@ static inline int cvmx_coremask_toggle_core(cvmx_coremask_t *pcm, int core)
  * Toggle ``current core'' in the coremask.
  *
  * @param pcm is the pointer to the coremask.
- * @param core
  * @return 0.
  */
 static inline int cvmx_coremask_toggle_self(cvmx_coremask_t *pcm)
@@ -385,7 +383,7 @@ static inline uint64_t cvmx_coremask_get64_node(const cvmx_coremask_t *pcm,
  *
  * @param[in] pcm - pointer to coremask
  * @return 32-bit coremask for the first node
- * @DEPRECATED This function is to maintain compatibility with older
+ * @deprecated This function is to maintain compatibility with older
  *             SDK applications and may disappear at some point.
  * This function is not compatible with the CN78XX or any other
  * Octeon device with more than 32 cores.
@@ -758,8 +756,8 @@ static inline int cvmx_coremask_is_subset(const cvmx_coremask_t *main,
 /**
  * Returns if one coremask intersects another coremask
  *
- * @param main - main coremask to test
- * @param subset - subset coremask to test
+ * @param c1 - main coremask to test
+ * @param c2 - subset coremask to test
  *
  * @return 1 if coremask c1 intersects coremask c2, 0 if they are exclusive
  */
@@ -777,7 +775,7 @@ static inline int cvmx_coremask_intersects(const cvmx_coremask_t *c1,
 /**
  * Masks a single node of a coremask
  *
- * @param pcm[inout] - coremask to mask
+ * @param[inout] pcm - coremask to mask
  * @param node       - node number to mask against
  */
 static inline void cvmx_coremask_mask_node(cvmx_coremask_t *pcm, int node)
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa.h b/arch/mips/include/asm/octeon/cvmx-fpa.h
index a6adbbd..9910c23 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa.h
@@ -42,7 +42,7 @@
  *
  * Interface to the hardware Free Pool Allocator.
  *
- * <hr>$Revision: 104152 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  *
  */
 
@@ -83,10 +83,10 @@ typedef struct cvmx_fpa_pool_config cvmx_fpa_pool_config_t;
 /**
  * Return the name of the pool
  *
- * @param pool   Pool to get the name of
+ * @param pool_num   Pool to get the name of
  * @return The name
  */
-const char *cvmx_fpa_get_name(int pool);
+const char *cvmx_fpa_get_name(int pool_num);
 
 /**
  * Return the base of the pool
@@ -136,7 +136,7 @@ static inline void cvmx_fpa_disable(void)
 
 /**
  * @INTERNAL
- * @OBSOLETE
+ * @deprecated OBSOLETE
  *
  * Kept for transition assistance only
  */
diff --git a/arch/mips/include/asm/octeon/cvmx-fpa3.h b/arch/mips/include/asm/octeon/cvmx-fpa3.h
index 224b756..b786bdb 100644
--- a/arch/mips/include/asm/octeon/cvmx-fpa3.h
+++ b/arch/mips/include/asm/octeon/cvmx-fpa3.h
@@ -42,7 +42,7 @@
  *
  * Interface to the CN78XX Free Pool Allocator, a.k.a. FPA3
  *
- * <hr>$Revision: 104195 $<hr>
+ * <hr>$Revision: 106689 $<hr>
  *
  */
 
@@ -243,6 +243,29 @@ enum cvmx_fpa3_pool_alignment_e {
 #define	CVMX_FPA3_AURAX_LIMIT_MAX               ((1ull<<40)-1)
 
 /**
+ * Get the FPA3 POOL underneath FPA3 AURA, containing all its buffers
+ *
+ * @INTERNAL
+ */
+static inline cvmx_fpa3_pool_t
+cvmx_fpa3_aura_to_pool(cvmx_fpa3_gaura_t aura)
+{
+	cvmx_fpa3_pool_t pool;
+	cvmx_fpa_aurax_pool_t aurax_pool;
+
+	if (CVMX_ENABLE_PARAMETER_CHECKING) {
+		if (!__cvmx_fpa3_aura_valid(aura))
+			return CVMX_FPA3_INVALID_POOL;
+	}
+
+	aurax_pool.u64 = cvmx_read_csr_node(aura.node,
+		CVMX_FPA_AURAX_POOL(aura.laura));
+
+	pool = __cvmx_fpa3_pool(aura.node, aurax_pool.s.pool);
+	return pool;
+}
+
+/**
  * Get a new block from the FPA pool
  *
  * @INTERNAL
@@ -437,29 +460,6 @@ static inline int cvmx_fpa3_config_red_params(unsigned node, int qos_avg_en,
 	return 0;
 }
 
-/**
- * Get the FPA3 POOL underneath FPA3 AURA, containing all its buffers
- *
- * @INTERNAL
- */
-static inline cvmx_fpa3_pool_t
-cvmx_fpa3_aura_to_pool(cvmx_fpa3_gaura_t aura)
-{
-	cvmx_fpa3_pool_t pool;
-	cvmx_fpa_aurax_pool_t aurax_pool;
-
-	if (CVMX_ENABLE_PARAMETER_CHECKING) {
-		if (!__cvmx_fpa3_aura_valid(aura))
-			return CVMX_FPA3_INVALID_POOL;
-	}
-
-	aurax_pool.u64 = cvmx_read_csr_node(aura.node,
-		CVMX_FPA_AURAX_POOL(aura.laura));
-
-	pool = __cvmx_fpa3_pool(aura.node, aurax_pool.s.pool);
-	return pool;
-}
-
 
 /**
  * Gets the buffer size of the specified pool,
@@ -488,7 +488,8 @@ static inline int cvmx_fpa3_get_aura_buf_size(cvmx_fpa3_gaura_t aura)
 /**
  * Return the number of available buffers in an AURA
  *
- * FIXME: Add <limit>-<count> limitation.
+ * @param aura to receive count for
+ * @return available buffer count
  */
 static inline long long cvmx_fpa3_get_available(cvmx_fpa3_gaura_t aura)
 {
@@ -515,6 +516,8 @@ static inline long long cvmx_fpa3_get_available(cvmx_fpa3_gaura_t aura)
 	limit_reg.u64 = cvmx_read_csr_node(aura.node,
 		CVMX_FPA_AURAX_CNT_LIMIT(aura.laura));
 
+	if (limit_reg.cn78xx.limit < cnt_reg.cn78xx.cnt) return 0;
+
 	/* Calculate AURA-based buffer allowance */
 	ret = limit_reg.cn78xx.limit -
 		cnt_reg.cn78xx.cnt;
@@ -529,13 +532,12 @@ static inline long long cvmx_fpa3_get_available(cvmx_fpa3_gaura_t aura)
 /**
  * Configure the QoS parameters of an FPA3 AURA
  *
- * @para aura is the FPA3 AURA handle
+ * @param aura is the FPA3 AURA handle
  * @param ena_bp enables backpressure when outstanding count exceeds 'bp_thresh'
- * @param ena_red enables random early discard when outstanding count
- * exceeds 'pass_thresh'
+ * @param ena_red enables random early discard when outstanding count exceeds 'pass_thresh'
  * @param pass_thresh is the maximum count to invoke flow control
  * @param drop_thresh is the count threshold to begin dropping packets
- * @para, bp_thresh is the back-pressure threshold
+ * @param bp_thresh is the back-pressure threshold
  *
  */
 static inline void cvmx_fpa3_setup_aura_qos(cvmx_fpa3_gaura_t aura, bool ena_red,
@@ -595,10 +597,32 @@ extern cvmx_fpa3_pool_t cvmx_fpa3_setup_fill_pool(
 	int node, int desired_pool, const char *name,
 	unsigned block_size, unsigned num_blocks, void *buffer);
 
+/**
+ * Function to attach an aura to an existing pool
+ *
+ * @param node - configure fpa on this node
+ * @param pool - configured pool to attach aura to
+ * @param desired_aura - pointer to aura to use, set to -1 to allocate
+ * @param name - name to register
+ * @param block_size - size of buffers to use
+ * @param num_blocks - number of blocks to allocate
+ *
+ * @return configured gaura on success, CVMX_FPA3_INVALID_GAURA on failure
+ */
 extern cvmx_fpa3_gaura_t cvmx_fpa3_set_aura_for_pool
 	(cvmx_fpa3_pool_t pool, int desired_aura,
 	const char *name, unsigned block_size, unsigned num_blocks);
 
+
+/**
+ * Function to setup and initialize a pool.
+ *
+ * @param node - configure fpa on this node
+ * @param desired_aura - aura to use, -1 for dynamic allocation
+ * @param name - name to register
+ * @param block_size - size of buffers in pool
+ * @param num_blocks - max number of buffers allowed
+ */
 extern cvmx_fpa3_gaura_t cvmx_fpa3_setup_aura_and_pool(
 		int node, int desired_aura,
 		const char *name, void *buffer,
diff --git a/arch/mips/include/asm/octeon/cvmx-global-resources.h b/arch/mips/include/asm/octeon/cvmx-global-resources.h
index b730b1f..60440f4 100644
--- a/arch/mips/include/asm/octeon/cvmx-global-resources.h
+++ b/arch/mips/include/asm/octeon/cvmx-global-resources.h
@@ -16,6 +16,7 @@
 #define CVMX_GR_TAG_CLUSTER_GRP(x)  cvmx_get_gr_tag('c','v','m','_','c','l','g','r','p','_',(x+'0'),'.','.','.','.','.')
 #define CVMX_GR_TAG_STYLE(x)        cvmx_get_gr_tag('c','v','m','_','s','t','y','l','e','_',(x+'0'),'.','.','.','.','.')
 #define CVMX_GR_TAG_QPG_ENTRY(x)    cvmx_get_gr_tag('c','v','m','_','q','p','g','e','t','_',(x+'0'),'.','.','.','.','.')
+#define CVMX_GR_TAG_BPID(x)         cvmx_get_gr_tag('c','v','m','_','b','p','i','d','s','_',(x+'0'),'.','.','.','.','.')
 #define CVMX_GR_TAG_PCAM(x,y,z) \
 	cvmx_get_gr_tag('c','v','m','_','p','c','a','m','_',(x+'0'),(y+'0'),(z+'0'),'.','.','.','.')
 
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-agl.h b/arch/mips/include/asm/octeon/cvmx-helper-agl.h
index 8de7465..cc12c14 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-agl.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-agl.h
@@ -69,7 +69,7 @@ extern "C" {
 
 extern int __cvmx_helper_agl_enumerate(int interface);
 
-extern int cvmx_helper_agl_get_port(int interface);
+extern int cvmx_helper_agl_get_port(int xiface);
 
 /**
  * @INTERNAL
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
index 062d8de..393689d 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-bgx.h
@@ -50,13 +50,13 @@
 
 #define CVMX_BGX_RX_FIFO_SIZE	(64 * 1024)
 
-extern int __cvmx_helper_bgx_enumerate(int interface);
+extern int __cvmx_helper_bgx_enumerate(int xiface);
 
 /**
  * @INTERNAL
  * Disable the BGX port
  *
- * @param  IPD port of the BGX interface to disable
+ * @param xipd_port IPD port of the BGX interface to disable
  */
 extern void cvmx_helper_bgx_disable(int xipd_port);
 
@@ -66,11 +66,11 @@ extern void cvmx_helper_bgx_disable(int xipd_port);
  * connected to it. The SGMII/XAUI interface should still be down after
  * this call. This is used by interfaces using the bgx mac.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-extern int __cvmx_helper_bgx_probe(int interface);
+extern int __cvmx_helper_bgx_probe(int xiface);
 
 /**
  * @INTERNAL
@@ -79,11 +79,11 @@ extern int __cvmx_helper_bgx_probe(int interface);
  * enabled but PKO disabled. This is used by interfaces using the
  * bgx mac.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_bgx_sgmii_enable(int interface);
+extern int __cvmx_helper_bgx_sgmii_enable(int xiface);
 
 /**
  * @INTERNAL
@@ -93,11 +93,11 @@ extern int __cvmx_helper_bgx_sgmii_enable(int interface);
  * the last call to cvmx_helper_link_set(). This is used by
  * interfaces using the bgx mac.
  *
- * @param ipd_port IPD/PKO port to query
+ * @param xipd_port IPD/PKO port to query
  *
  * @return Link state
  */
-extern cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port);
+extern cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int xipd_port);
 
 /**
  * @INTERNAL
@@ -108,12 +108,12 @@ extern cvmx_helper_link_info_t __cvmx_helper_bgx_sgmii_link_get(int ipd_port);
  * cvmx_helper_link_autoconf() instead. This is used by interfaces
  * using the bgx mac.
  *
- * @param ipd_port  IPD/PKO port to configure
+ * @param xipd_port  IPD/PKO port to configure
  * @param link_info The new link state
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
+extern int __cvmx_helper_bgx_sgmii_link_set(int xipd_port,
 					    cvmx_helper_link_info_t link_info);
 
 /**
@@ -123,7 +123,7 @@ extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
  * causes packets received from the wire to sent out again. This is used by
  * interfaces using the bgx mac.
  *
- * @param ipd_port IPD/PKO port to loopback.
+ * @param xipd_port IPD/PKO port to loopback.
  * @param enable_internal
  *                 Non zero if you want internal loopback
  * @param enable_external
@@ -131,7 +131,7 @@ extern int __cvmx_helper_bgx_sgmii_link_set(int ipd_port,
  *
  * @return Zero on success, negative on failure.
  */
-extern int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port,
+extern int __cvmx_helper_bgx_sgmii_configure_loopback(int xipd_port,
 						      int enable_internal,
 						      int enable_external);
 
@@ -142,11 +142,11 @@ extern int __cvmx_helper_bgx_sgmii_configure_loopback(int ipd_port,
  * enabled but PKO disabled. This is used by interfaces using the
  * bgx mac.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_bgx_xaui_enable(int interface);
+extern int __cvmx_helper_bgx_xaui_enable(int xiface);
 
 /**
  * @INTERNAL
@@ -156,11 +156,11 @@ extern int __cvmx_helper_bgx_xaui_enable(int interface);
  * the last call to cvmx_helper_link_set(). This is used by
  * interfaces using the bgx mac.
  *
- * @param ipd_port IPD/PKO port to query
+ * @param xipd_port IPD/PKO port to query
  *
  * @return Link state
  */
-extern cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port);
+extern cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int xipd_port);
 
 /**
  * @INTERNAL
@@ -171,12 +171,12 @@ extern cvmx_helper_link_info_t __cvmx_helper_bgx_xaui_link_get(int ipd_port);
  * cvmx_helper_link_autoconf() instead. This is used by interfaces
  * using the bgx mac.
  *
- * @param ipd_port  IPD/PKO port to configure
+ * @param xipd_port  IPD/PKO port to configure
  * @param link_info The new link state
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port,
+extern int __cvmx_helper_bgx_xaui_link_set(int xipd_port,
 					   cvmx_helper_link_info_t link_info);
 
 /**
@@ -186,7 +186,7 @@ extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port,
  * causes packets received from the wire to sent out again. This is used by
  * interfaces using the bgx mac.
  *
- * @param ipd_port IPD/PKO port to loopback.
+ * @param xipd_port IPD/PKO port to loopback.
  * @param enable_internal
  *                 Non zero if you want internal loopback
  * @param enable_external
@@ -194,7 +194,7 @@ extern int __cvmx_helper_bgx_xaui_link_set(int ipd_port,
  *
  * @return Zero on success, negative on failure.
  */
-extern int __cvmx_helper_bgx_xaui_configure_loopback(int ipd_port,
+extern int __cvmx_helper_bgx_xaui_configure_loopback(int xipd_port,
 						     int enable_internal,
 						     int enable_external);
 /**
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
index 5e69df0..71422b9e 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-cfg.h
@@ -436,12 +436,12 @@ void cvmx_pko_queue_free_all(void);
 /**
  * Returns if port is valid for a given interface
  *
- * @param interface  interface to check
+ * @param xiface     interface to check
  * @param index      port index in the interface
  *
  * @return status of the port present or not.
  */
-int cvmx_helper_is_port_valid(int interface, int index);
+int cvmx_helper_is_port_valid(int xiface, int index);
 
 /**
  * Set whether or not a port is valid
@@ -502,7 +502,7 @@ extern void cvmx_helper_set_port_force_link_up(int interface, int index,
  * @INTERNAL
  * Return true if PHY is present to the passed xiface
  *
- * @param interface the interface number
+ * @param xiface the interface number
  * @param index the port's index
  */
 extern bool cvmx_helper_get_port_phy_present(int xiface, int index);
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-ilk.h b/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
index 4da1c18..7697c63 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-ilk.h
@@ -87,7 +87,7 @@ void __cvmx_ilk_write_rx_cal_entry(int interface, int channel,
  * connected to it. The ILK interface should still be down after
  * this call.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
@@ -99,7 +99,7 @@ extern int __cvmx_helper_ilk_probe(int xiface);
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-npi.h b/arch/mips/include/asm/octeon/cvmx-helper-npi.h
index 0cb4849..af82489 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-npi.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-npi.h
@@ -43,7 +43,7 @@
  * Functions for NPI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 96176 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 #ifndef __CVMX_HELPER_NPI_H__
 #define __CVMX_HELPER_NPI_H__
@@ -66,11 +66,11 @@ extern int __cvmx_helper_npi_probe(int interface);
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_npi_enable(int interface);
+extern int __cvmx_helper_npi_enable(int xiface);
 
 /**
  * Sets the number of pipe used by SLI packet output in the variable,
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-pki.h b/arch/mips/include/asm/octeon/cvmx-helper-pki.h
index e1278da..2944031 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-pki.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-pki.h
@@ -87,7 +87,7 @@ struct cvmx_pki_prt_schd {
 	cvmx_fpa3_pool_t _pool;	/* FPA3 POOL handle */
 	cvmx_fpa3_gaura_t _aura;/* FPA3 AURA handle */
 	bool cfg_port;          /* Set to 1 if this port on the interface is not used */
-	int style;              /* If style_per_prt is TRUE in interface schd */
+	int style;              /* If port is using its own style and not interface style */
 	bool pool_per_prt; 	/* Port will use its own pool, if FALSE use interface pool */
 	int pool_num;		/* pool number to use, if -1 allocated by sdk otherwise software should alloc it*/
 	char *pool_name;
@@ -108,8 +108,7 @@ struct cvmx_pki_prt_schd {
 struct cvmx_pki_intf_schd {
 	cvmx_fpa3_pool_t _pool;	/* FPA3 POOL handle */
 	cvmx_fpa3_gaura_t _aura;/* FPA3 AURA handle */
-	bool style_per_prt;	/* Every port will use different style/profile */
-	bool style_per_intf;	/* otherwise all ports on this interface will use same style/profile */
+	bool style_per_intf;	/* 1: all ports on this interface will use same style; 0:ports on this intf will use their own style */
 	int style;              /* style number to use, if -1 allocated by sdk otherwise software should alloc it*/
 	bool pool_per_intf; 	/* Ports will use either this shared pool or their own pool*/
 	int pool_num;		/* pool number to use, if -1 allocated by sdk otherwise software should alloc it*/
@@ -258,9 +257,9 @@ int cvmx_helper_pki_init_port(int ipd_port, struct cvmx_pki_prt_schd *prtsch);
  * This function sets up scheduling parameters (pool, aura, sso group etc)
  * of an interface (all ports/channels on that interface).
  * @param xiface        interface number with node.
- * @param intf_sch      pointer to struct containing interface
+ * @param intfsch      pointer to struct containing interface
  *                      scheduling parameters.
- * @param gbl_sch       pointer to struct containing global scheduling parameters
+ * @param gblsch       pointer to struct containing global scheduling parameters
  *                      (can be NULL if not used)
  */
 int cvmx_helper_pki_init_interface(const int xiface,
@@ -293,18 +292,18 @@ void cvmx_pki_show_port_config(int ipd_port);
  * Modifies maximum frame length to check.
  * It modifies the global frame length set used by this port, any other
  * port using the same set will get affected too.
- * @param node		node number
  * @param ipd_port	ipd port for which to modify max len.
  * @param max_size	maximum frame length
  */
 void cvmx_pki_set_max_frm_len(int ipd_port, uint32_t max_size);
 
 /**
- * This function sets up all th eports of particular interface
+ * This function sets up all the ports of particular interface
  * for chosen fcs mode. (only use for backward compatibility).
- * New application can control it via init_interfcae calls.
+ * New application can control it via init_interface calls.
  * @param node          node number.
- * @param interfcae     interfcae number.
+ * @param interface     interface number.
+ * @param nports        number of ports
  * @param has_fcs       1 -- enable fcs check and fcs strip.
  *                      0 -- disable fcs check.
  */
@@ -315,7 +314,7 @@ void cvmx_helper_pki_set_fcs_op(int node, int interface, int nports, int has_fcs
  * either in same buffer as wqe OR it can go in separate buffer. If used the later mode,
  * make sure software allocate enough buffers to now have wqe separate from packet data.
  * @param node	                node number.
- * @param pkt_outside_wqe.	0 = The packet link pointer will be at word [FIRST_SKIP]
+ * @param pkt_outside_wqe	0 = The packet link pointer will be at word [FIRST_SKIP]
  *				    immediately followed by packet data, in the same buffer
  *				    as the work queue entry.
  *				1 = The packet link pointer will be at word [FIRST_SKIP] in a new
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h b/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
index 0ca6577..7bf73fe 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-rgmii.h
@@ -43,7 +43,7 @@
  * Functions for RGMII/GMII/MII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 96176 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 #ifndef __CVMX_HELPER_RGMII_H__
 #define __CVMX_HELPER_RGMII_H__
@@ -52,7 +52,7 @@
  * @INTERNAL
  * Probe RGMII ports and determine the number present
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of RGMII/GMII/MII ports (0-4).
  */
@@ -72,11 +72,11 @@ extern void cvmx_helper_rgmii_internal_loopback(int port);
  * Configure all of the ASX, GMX, and PKO regsiters required
  * to get RGMII to function on the supplied interface.
  *
- * @param interface PKO Interface to configure (0 or 1)
+ * @param xiface PKO Interface to configure (0 or 1)
  *
  * @return Zero on success
  */
-extern int __cvmx_helper_rgmii_enable(int interface);
+extern int __cvmx_helper_rgmii_enable(int xiface);
 
 /**
  * @INTERNAL
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h b/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
index e3402ef..82caef5 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-sgmii.h
@@ -43,7 +43,7 @@
  * Functions for SGMII initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 96415 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 #ifndef __CVMX_HELPER_SGMII_H__
 #define __CVMX_HELPER_SGMII_H__
@@ -54,7 +54,7 @@
  * connected to it. The SGMII interface should still be down after
  * this call.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
@@ -67,7 +67,7 @@ extern int __cvmx_helper_sgmii_enumerate(int xiface);
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-srio.h b/arch/mips/include/asm/octeon/cvmx-helper-srio.h
index b6dc0202..7bcf2be 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-srio.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-srio.h
@@ -54,11 +54,11 @@
  * connected to it. The SRIO interface should still be down after
  * this call.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-extern int __cvmx_helper_srio_probe(int interface);
+extern int __cvmx_helper_srio_probe(int xiface);
 
 /**
  * @INTERNAL
@@ -66,11 +66,11 @@ extern int __cvmx_helper_srio_probe(int interface);
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_srio_enable(int interface);
+extern int __cvmx_helper_srio_enable(int xiface);
 
 /**
  * @INTERNAL
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-util.h b/arch/mips/include/asm/octeon/cvmx-helper-util.h
index 1d607e9..49420ed 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-util.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-util.h
@@ -42,7 +42,7 @@
  *
  * Small helper utilities.
  *
- * <hr>$Revision: 104282 $<hr>
+ * <hr>$Revision: 106932 $<hr>
  */
 
 #ifndef __CVMX_HELPER_UTIL_H__
@@ -284,7 +284,7 @@ extern const char *cvmx_helper_get_version(void);
  * ports. These setting apply to almost all configurations of all
  * chips.
  *
- * @param interface Interface to configure
+ * @param xiface Interface to configure
  * @param num_ports Number of ports on the interface
  *
  * @return Zero on success, negative on failure
@@ -394,8 +394,8 @@ extern int cvmx_helper_get_interface_index_num(int ipd_port);
 /**
  * Get port kind for a given port in an interface.
  *
- * @param interface  Interface
- * @param port       index of the port in the interface
+ * @param xiface  Interface
+ * @param index   index of the port in the interface
  *
  * @return port kind on sucicess  and -1 on failure
  */
diff --git a/arch/mips/include/asm/octeon/cvmx-helper-xaui.h b/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
index d4464e7..cf01529 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper-xaui.h
@@ -43,7 +43,7 @@
  * Functions for XAUI initialization, configuration,
  * and monitoring.
  *
- * <hr>$Revision: 94200 $<hr>
+ * <hr>$Revision: 106932 $<hr>
  */
 #ifndef __CVMX_HELPER_XAUI_H__
 #define __CVMX_HELPER_XAUI_H__
@@ -54,12 +54,12 @@
  * connected to it. The XAUI interface should still be down
  * after this call.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Number of ports on the interface. Zero to disable.
  */
-extern int __cvmx_helper_xaui_probe(int interface);
-extern int __cvmx_helper_xaui_enumerate(int interface);
+extern int __cvmx_helper_xaui_probe(int xiface);
+extern int __cvmx_helper_xaui_enumerate(int xiface);
 
 /**
  * @INTERNAL
@@ -67,11 +67,11 @@ extern int __cvmx_helper_xaui_enumerate(int interface);
  * I/O should be fully functional. This is called with IPD
  * enabled but PKO disabled.
  *
- * @param interface Interface to bring up
+ * @param xiface Interface to bring up
  *
  * @return Zero on success, negative on failure
  */
-extern int __cvmx_helper_xaui_enable(int interface);
+extern int __cvmx_helper_xaui_enable(int xiface);
 
 /**
  * @INTERNAL
diff --git a/arch/mips/include/asm/octeon/cvmx-helper.h b/arch/mips/include/asm/octeon/cvmx-helper.h
index 9ec1372..b23777a 100644
--- a/arch/mips/include/asm/octeon/cvmx-helper.h
+++ b/arch/mips/include/asm/octeon/cvmx-helper.h
@@ -42,7 +42,7 @@
  *
  * Helper functions for common, but complicated tasks.
  *
- * <hr>$Revision: 101694 $<hr>
+ * <hr>$Revision: 106932 $<hr>
  */
 
 #ifndef __CVMX_HELPER_H__
@@ -213,6 +213,7 @@ extern int cvmx_helper_initialize_sso(int wqe_entries);
 /**
  * Initialize and allocate memory for the SSO on a specific node.
  *
+ * @param node Node SSO to initialize
  * @param wqe_entries The maximum number of work queue entries to be
  * supported.
  *
@@ -230,6 +231,8 @@ extern int cvmx_helper_uninitialize_sso(void);
 /**
  * Undo the effect of cvmx_helper_initialize_sso_node().
  *
+ * @param node Node SSO to initialize
+ *
  * @return Zero on success, non-zero on failure.
  */
 extern int cvmx_helper_uninitialize_sso_node(unsigned node);
@@ -244,6 +247,17 @@ extern int cvmx_helper_uninitialize_sso_node(unsigned node);
  * @return Zero on success, non-zero on failure
  */
 int cvmx_helper_initialize_packet_io_global(void);
+/**
+ * Initialize the PIP, IPD, and PKO hardware to support
+ * simple priority based queues for the ethernet ports. Each
+ * port is configured with a number of priority queues based
+ * on CVMX_PKO_QUEUES_PER_PORT_* where each queue is lower
+ * priority than the previous.
+ *
+ * @param node Node on which to initialize packet io hardware
+ *
+ * @return Zero on success, non-zero on failure
+ */
 int cvmx_helper_initialize_packet_io_node(unsigned int node);
 
 /**
@@ -300,12 +314,12 @@ extern int cvmx_helper_get_number_of_interfaces(void);
  * chip and configuration, this function returns an enumeration
  * of the type of packet I/O supported by an interface.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Mode of the interface. Unknown or unsupported interfaces return
  *         DISABLED.
  */
-extern cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int interface);
+extern cvmx_helper_interface_mode_t cvmx_helper_interface_get_mode(int xiface);
 
 /**
  * Auto configure an IPD/PKO port link state and speed. This
@@ -351,21 +365,21 @@ extern int cvmx_helper_link_set(int ipd_port, cvmx_helper_link_info_t link_info)
  * interface_port_count[interface] correctly. Final hardware setup of
  * the ports will be performed later.
  *
- * @param interface Interface to probe
+ * @param xiface Interface to probe
  *
  * @return Zero on success, negative on failure
  */
-extern int cvmx_helper_interface_probe(int interface);
+extern int cvmx_helper_interface_probe(int xiface);
 
 /**
  * Determine the actual number of hardware ports connected to an
  * interface. It doesn't setup the ports or enable them.
  *
- * @param interface Interface to enumerate
+ * @param xiface Interface to enumerate
  *
  * @return Zero on success, negative on failure
  */
-extern int cvmx_helper_interface_enumerate(int interface);
+extern int cvmx_helper_interface_enumerate(int xiface);
 
 /**
  * Configure a port for internal and/or external loopback. Internal loopback
@@ -456,18 +470,18 @@ static inline uint8_t cvmx_helper_prio2qos(uint8_t prio)
  * @INTERNAL
  * Get the number of ipd_ports on an interface.
  *
- * @param interface
+ * @param xiface
  *
  * @return the number of ipd_ports on the interface and -1 for error.
  */
-int __cvmx_helper_get_num_ipd_ports(int interface);
+int __cvmx_helper_get_num_ipd_ports(int xiface);
 
 enum cvmx_pko_padding __cvmx_helper_get_pko_padding(int xiface);
 
 /**
  * @INTERNAL
  *
- * @param interface
+ * @param xiface
  * @param num_ipd_ports is the number of ipd_ports on the interface
  * @param has_fcs indicates if PKO does FCS for the ports on this
  * @param pad The padding that PKO should apply.
@@ -475,7 +489,7 @@ enum cvmx_pko_padding __cvmx_helper_get_pko_padding(int xiface);
  *
  * @return 0 for success and -1 for failure
  */
-int __cvmx_helper_init_interface(int interface, int num_ipd_ports, int has_fcs, enum cvmx_pko_padding pad);
+int __cvmx_helper_init_interface(int xiface, int num_ipd_ports, int has_fcs, enum cvmx_pko_padding pad);
 
 void __cvmx_helper_shutdown_interfaces(void);
 
@@ -501,12 +515,12 @@ int __cvmx_helper_set_link_info(int xiface, int index, cvmx_helper_link_info_t l
 /**
  * @INTERNAL
  *
- * @param interface
+ * @param xiface
  * @param port
  *
  * @return valid link_info on success or -1 on failure
  */
-cvmx_helper_link_info_t __cvmx_helper_get_link_info(int interface, int port);
+cvmx_helper_link_info_t __cvmx_helper_get_link_info(int xiface, int port);
 
 enum cvmx_pko_padding {
 	CVMX_PKO_PADDING_NONE = 0,
@@ -516,11 +530,11 @@ enum cvmx_pko_padding {
 /**
  * @INTERNAL
  *
- * @param interface
+ * @param xiface
  *
  * @return 0 if PKO does not do FCS and 1 otherwise.
  */
-int __cvmx_helper_get_has_fcs(int interface);
+int __cvmx_helper_get_has_fcs(int xiface);
 
 void *cvmx_helper_mem_alloc(int node, uint64_t alloc_size, uint64_t align);
 void cvmx_helper_mem_free(void *buffer, uint64_t size);
diff --git a/arch/mips/include/asm/octeon/cvmx-hwfau.h b/arch/mips/include/asm/octeon/cvmx-hwfau.h
index cb2a068..8471c8a 100644
--- a/arch/mips/include/asm/octeon/cvmx-hwfau.h
+++ b/arch/mips/include/asm/octeon/cvmx-hwfau.h
@@ -1,3 +1,4 @@
+
 /***********************license start***************
  * Copyright (c) 2003-2010  Cavium Inc. (support@cavium.com). All rights
  * reserved.
@@ -630,7 +631,7 @@ extern int cvmx_fau16_alloc(int reserve);
 extern int cvmx_fau8_alloc(int reserve);
 
 /** Frees the specified FAU register.
- *  @param Base address of register to release.
+ *  @param address Base address of register to release.
  *  @return 0 on success; -1 on failure
  */
 extern int cvmx_fau_free(int address);
diff --git a/arch/mips/include/asm/octeon/cvmx-hwpko.h b/arch/mips/include/asm/octeon/cvmx-hwpko.h
index f5d93b0..eaa946c 100644
--- a/arch/mips/include/asm/octeon/cvmx-hwpko.h
+++ b/arch/mips/include/asm/octeon/cvmx-hwpko.h
@@ -473,12 +473,12 @@ extern int cvmx_pko_get_num_queues(int port);
  * @param pool	fpa pool number yo use
  * @param buffer_size	buffer size of pool
  * @param buffer_count	number of buufers to allocate to pool
+ *
+ * @note the caller is responsable for setting up the pool with
+ * an appropriate buffer size and sufficient buffer count.
  */
 void cvmx_pko_set_cmd_que_pool_config(int64_t pool, uint64_t buffer_size,
 					   uint64_t buffer_count);
-//FIXME- reconsider:
-// Helper should setup the pool, then call PKO (pko_init?) with the
-// pool number to use.
 
 /**
  * Get the status counters for a port.
diff --git a/arch/mips/include/asm/octeon/cvmx-ilk.h b/arch/mips/include/asm/octeon/cvmx-ilk.h
index 1c3243b..6b96f6a 100644
--- a/arch/mips/include/asm/octeon/cvmx-ilk.h
+++ b/arch/mips/include/asm/octeon/cvmx-ilk.h
@@ -96,7 +96,7 @@ static inline int CVMX_ILK_MAX_LANES(void) {
 		return 16;
 	return -1;
 }
-extern CVMX_SHARED unsigned short cvmx_ilk_lane_mask[CVMX_NUM_ILK_INTF];
+extern CVMX_SHARED unsigned short cvmx_ilk_lane_mask[CVMX_MAX_NODES][CVMX_NUM_ILK_INTF];
 
 typedef struct {
 	unsigned int pipe;
@@ -107,7 +107,7 @@ typedef struct {
 /* Max number of channels allowed */
 #define CVMX_ILK_MAX_CHANS 8
 
-extern CVMX_SHARED unsigned char cvmx_ilk_chans[CVMX_NUM_ILK_INTF];
+extern CVMX_SHARED unsigned char cvmx_ilk_chans[CVMX_MAX_NODES][CVMX_NUM_ILK_INTF];
 extern unsigned char cvmx_ilk_chan_map[CVMX_NUM_ILK_INTF][CVMX_ILK_MAX_CHANS];
 
 typedef struct {
diff --git a/arch/mips/include/asm/octeon/cvmx-l2c.h b/arch/mips/include/asm/octeon/cvmx-l2c.h
index 7e107d0..bee0b31 100644
--- a/arch/mips/include/asm/octeon/cvmx-l2c.h
+++ b/arch/mips/include/asm/octeon/cvmx-l2c.h
@@ -43,7 +43,7 @@
  * Interface to the Level 2 Cache (L2C) control, measurement, and debugging
  * facilities.
  *
- * <hr>$Revision: 105520 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  *
  */
 
@@ -534,7 +534,7 @@ int cvmx_l2c_vrt_assign_virtid(int virtid, uint32_t coremask);
  * Remove a virt id assigned to a set of cores. Update the virtid mask and
  * virtid stored for each core.
  *
- * @param coremask  the group of cores whose virtual id is removed.
+ * @param virtid  Remove the specified Virtualization machine ID.
  */
 void cvmx_l2c_vrt_remove_virtid(int virtid);
 
@@ -543,7 +543,6 @@ void cvmx_l2c_vrt_remove_virtid(int virtid);
  *
  * @param start_addr   Starting address of memory region
  * @param size         Size of the memory to protect
- * @param virtid_mask  Virtual ID to use
  * @param mode         Allow/Disallow write access
  *                        = 0,  Allow write access by virtid
  *                        = 1,  Disallow write access by virtid
diff --git a/arch/mips/include/asm/octeon/cvmx-pip.h b/arch/mips/include/asm/octeon/cvmx-pip.h
index 6797430..f3d6266 100644
--- a/arch/mips/include/asm/octeon/cvmx-pip.h
+++ b/arch/mips/include/asm/octeon/cvmx-pip.h
@@ -42,7 +42,7 @@
  *
  * Interface to the hardware Packet Input Processing unit.
  *
- * <hr>$Revision: 103836 $<hr>
+ * <hr>$Revision: 106447 $<hr>
  */
 
 #ifndef __CVMX_PIP_H__
@@ -666,9 +666,7 @@ static inline void cvmx_pip_config_port(uint64_t ipd_port, cvmx_pip_prt_cfgx_t p
  */
 static inline void cvmx_pip_config_vlan_qos(uint64_t vlan_priority, uint64_t qos)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		/* FIXME for 68xx. */
-	} else {
+	if (!octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		cvmx_pip_qos_vlanx_t pip_qos_vlanx;
 		pip_qos_vlanx.u64 = 0;
 		pip_qos_vlanx.s.qos = qos;
@@ -684,9 +682,7 @@ static inline void cvmx_pip_config_vlan_qos(uint64_t vlan_priority, uint64_t qos
  */
 static inline void cvmx_pip_config_diffserv_qos(uint64_t diffserv, uint64_t qos)
 {
-	if (octeon_has_feature(OCTEON_FEATURE_PKND)) {
-		/* FIXME for 68xx. */
-	} else {
+	if (!octeon_has_feature(OCTEON_FEATURE_PKND)) {
 		cvmx_pip_qos_diffx_t pip_qos_diffx;
 		pip_qos_diffx.u64 = 0;
 		pip_qos_diffx.s.qos = qos;
diff --git a/arch/mips/include/asm/octeon/cvmx-pki-resources.h b/arch/mips/include/asm/octeon/cvmx-pki-resources.h
index edb3dd0..e716c6c 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki-resources.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki-resources.h
@@ -161,6 +161,26 @@ int cvmx_pki_cluster_free(int node, uint64_t cluster_mask);
 int cvmx_pki_pcam_entry_free(int node, int index, int bank, uint64_t cluster_mask);
 
 /**
+ * This function allocates/reserves a bpid from pool of global bpid per node.
+ * @param node	node to allocate bpid from.
+ * @param bpid	bpid  to allocate, if -1 it will be allocated
+ *		first available boid from bpid resource. If index is positive
+ *		number and in range, it will try to allocate specified bpid.
+ * @return 	bpid number on success,
+ *		-1 on alloc failure.
+ *		-2 on resource already reserved.
+ */
+int cvmx_pki_bpid_alloc(int node, int bpid);
+
+/**
+ * This function frees a bpid from pool of global bpid per node.
+ * @param node	 node to free bpid from.
+ * @param bpid	 bpid to free
+ * @return 	 0 on success, -1 on failure or
+ */
+int cvmx_pki_bpid_free(int node, int bpid);
+
+/**
  * This function frees all the PKI software resources
  * (clusters, styles, qpg_entry, pcam_entry etc) for the specified node
  */
diff --git a/arch/mips/include/asm/octeon/cvmx-pki.h b/arch/mips/include/asm/octeon/cvmx-pki.h
index 09d55b6..9985673 100644
--- a/arch/mips/include/asm/octeon/cvmx-pki.h
+++ b/arch/mips/include/asm/octeon/cvmx-pki.h
@@ -618,6 +618,7 @@ struct cvmx_pki_port_stats {
  * Number of clusters assign to that group determines how many engine can work
  * in parallel to process the packet. Eack cluster can process x MPPS.
  *
+ * @param node		node
  * @param cluster_group Group to attach clusters to
  * @param cluster_mask  It is the mask of clusters which needs to be assigned to group.
  * to that group
@@ -727,7 +728,7 @@ static inline void cvmx_pki_enable_backpressure(int node)
  * Get the statistics counters for a port.
  *
  * @param node	   node number
- * @param port_num Port number (ipd_port) to get statistics for.
+ * @param port Port number (ipd_port) to get statistics for.
  *		   Make sure PKI_STATS_CTL:mode is set to 0 for
  *		   collecting per port/pkind stats.
  *
@@ -1005,7 +1006,7 @@ static inline void cvmx_pki_get_stats(int node, int index, struct cvmx_pki_port_
  * Get the statistics counters for a port.
  *
  * @param node	   node number
- * @param port_num Port number (ipd_port) to get statistics for.
+ * @param port Port number (ipd_port) to get statistics for.
  *		   Make sure PKI_STATS_CTL:mode is set to 0 for
  *		   collecting per port/pkind stats.
  * @param status   Where to put the results.
@@ -1023,7 +1024,7 @@ static inline void cvmx_pki_get_port_stats(int node, uint64_t port, struct cvmx_
  * Get the statistics counters for a flow represented by style in PKI.
  *
  * @param node	   node number
- * @param style	   style number to get statistics for.
+ * @param style_num   style number to get statistics for.
  *		   Make sure PKI_STATS_CTL:mode is set to 1 for
  *		   collecting per style/flow stats.
  * @param status   Where to put the results.
@@ -1198,7 +1199,7 @@ int cvmx_pki_write_aura_bpid(int node, int aura, int bpid);
  *                  1-enable 0-disable
  * @param ena_drop  Enable/disable tail drop when max drop level exceeds
  *                  1-enable 0-disable
- * @param ena_red   Enable/Disable asserting backpressure on bpid when
+ * @param ena_bp    Enable/Disable asserting backpressure on bpid when
  *                  max DROP level exceeds.
  *                  1-enable 0-disable
  */
@@ -1218,7 +1219,7 @@ int cvmx_pki_get_pkind_style(int node, int pkind);
  * make sure software allocate enough buffers to now have wqe separate from packet data.
  * @param node	              node number.
  * @param style		      style to configure.
- * @param pkt_outside_wqe.	0 = The packet link pointer will be at word [FIRST_SKIP]
+ * @param pkt_outside_wqe	0 = The packet link pointer will be at word [FIRST_SKIP]
  *				    immediately followed by packet data, in the same buffer
  *				    as the work queue entry.
  *				1 = The packet link pointer will be at word [FIRST_SKIP] in a new
@@ -1270,6 +1271,7 @@ void cvmx_pki_endis_fcs_check(int node, int pknd, bool fcs_chk, bool fcs_strip);
  * This function shows the qpg table entries,
  * read directly from hardware.
  * @param node    node number
+ * @param num_entry number of entries to print
  */
 void cvmx_pki_show_qpg_entries(int node, uint16_t num_entry);
 
@@ -1291,6 +1293,7 @@ void cvmx_pki_show_valid_pcam_entries(int node);
  * This function shows the pkind attributes in readable format,
  * read directly from hardware.
  * @param node    node number
+ * @param pkind   pkind number to print
  */
 void cvmx_pki_show_pkind_attributes(int node, int pkind);
 
@@ -1303,6 +1306,7 @@ void cvmx_pki_show_pkind_attributes(int node, int pkind);
  * PKI.
  * WARNING: It is very important that PKI be
  * reset soon after a call to this function.
+ * @param node	              node number.
  */
 void __cvmx_pki_free_ptr(int node);
 
diff --git a/arch/mips/include/asm/octeon/cvmx-pko3.h b/arch/mips/include/asm/octeon/cvmx-pko3.h
index e020067..fdd7427 100644
--- a/arch/mips/include/asm/octeon/cvmx-pko3.h
+++ b/arch/mips/include/asm/octeon/cvmx-pko3.h
@@ -74,9 +74,10 @@ extern "C" {
 
 #define	CVMX_PKO3_DQ_MAX_DEPTH	(48*256)
 
-/* dwords are from 1-16 */
+/* dwords count from 1-16 */
 /* scratch line for LMT operations */
-#define CVMX_PKO_LMTLINE 2ull	//FIXME- should go somewhere else ?
+/* Should be unique wrt other uses of CVMSEG, e.g. IOBDMA */
+#define CVMX_PKO_LMTLINE 2ull
 
 enum {
 	CVMX_PKO_PORT_QUEUES = 0,
@@ -202,9 +203,9 @@ union cvmx_pko_send_free {
 	uint64_t u64;
 	struct {
                 CVMX_BITFIELD_FIELD(uint64_t rsvd_48_63 : 16,
-                CVMX_BITFIELD_FIELD(uint64_t subdc4 	: 4, /* NODE+LAURA */
-                CVMX_BITFIELD_FIELD(uint64_t ns 	: 2,
-                CVMX_BITFIELD_FIELD(uint64_t addr 	: 42,
+                CVMX_BITFIELD_FIELD(uint64_t subdc4	: 4, /* 0x9 */
+                CVMX_BITFIELD_FIELD(uint64_t rsvd	: 2,
+                CVMX_BITFIELD_FIELD(uint64_t addr	: 42,
 			))));
 	} s;
 };
diff --git a/arch/mips/include/asm/octeon/cvmx-pow.h b/arch/mips/include/asm/octeon/cvmx-pow.h
index 7bafbd6..12c6ec6 100644
--- a/arch/mips/include/asm/octeon/cvmx-pow.h
+++ b/arch/mips/include/asm/octeon/cvmx-pow.h
@@ -1654,7 +1654,7 @@ static inline cvmx_pow_tag_info_t cvmx_pow_get_current_tag(void)
 		cvmx_sso_sl_ppx_tag_t sl_ppx_tag;
 		cvmx_xgrp_t xgrp;
 		int node = cvmx_get_node_num();
-		int core = cvmx_get_core_num();
+		int core = cvmx_get_local_core_num();
 		sl_ppx_tag.u64 = cvmx_read_csr_node(node, CVMX_SSO_SL_PPX_TAG(core));
 		result.index = sl_ppx_tag.s.index;
 		result.tag_type = sl_ppx_tag.s.tt;
@@ -1707,7 +1707,7 @@ static inline cvmx_wqe_t *cvmx_pow_get_current_wqp(void)
 	if (octeon_has_feature(OCTEON_FEATURE_CN78XX_WQE)) {
 		cvmx_sso_sl_ppx_wqp_t sso_wqp;
 		int node = cvmx_get_node_num();
-		int core = cvmx_get_core_num();
+		int core = cvmx_get_local_core_num();
 		sso_wqp.u64 = cvmx_read_csr_node(node, CVMX_SSO_SL_PPX_WQP(core));
 		if (sso_wqp.s.wqp)
 			return (cvmx_wqe_t *) cvmx_phys_to_ptr(sso_wqp.s.wqp);
diff --git a/arch/mips/include/asm/octeon/cvmx-qlm.h b/arch/mips/include/asm/octeon/cvmx-qlm.h
index 59d28f8..ee98a73 100644
--- a/arch/mips/include/asm/octeon/cvmx-qlm.h
+++ b/arch/mips/include/asm/octeon/cvmx-qlm.h
@@ -42,7 +42,7 @@
  *
  * Helper utilities for qlm.
  *
- * <hr>$Revision: 102508 $<hr>
+ * <hr>$Revision: 107037 $<hr>
  */
 
 #ifndef __CVMX_QLM_H__
@@ -83,13 +83,15 @@ extern int cvmx_qlm_get_num(void);
 /**
  * Return the qlm number based on the interface
  *
- * @param interface  Interface to look up
+ * @param xiface  Interface to look up
  */
-extern int cvmx_qlm_interface(int interface);
+extern int cvmx_qlm_interface(int xiface);
 
 /**
  * Return number of lanes for a given qlm
  * 
+ * @param qlm QLM block to query
+ *
  * @return  Number of lanes
  */
 extern int cvmx_qlm_get_lanes(int qlm);
@@ -160,6 +162,14 @@ extern void __cvmx_qlm_pcie_cfg_rxd_set_tweak(int qlm, int lane);
  * @return Speed in Mhz
  */
 extern int cvmx_qlm_get_gbaud_mhz(int qlm);
+/**
+ * Get the speed (Gbaud) of the QLM in Mhz on specific node.
+ *
+ * @param node   Target QLM node
+ * @param qlm    QLM to examine
+ *
+ * @return Speed in Mhz
+ */
 extern int cvmx_qlm_get_gbaud_mhz_node(int node, int qlm);
 
 enum cvmx_qlm_mode {
diff --git a/arch/mips/include/asm/octeon/cvmx-spinlock.h b/arch/mips/include/asm/octeon/cvmx-spinlock.h
index 56beb3e..5d1d439 100644
--- a/arch/mips/include/asm/octeon/cvmx-spinlock.h
+++ b/arch/mips/include/asm/octeon/cvmx-spinlock.h
@@ -42,7 +42,7 @@
  *
  * Implementation of spinlocks.
  *
- * <hr>$Revision: 77315 $<hr>
+ * <hr>$Revision: 107108 $<hr>
  */
 
 #ifndef __CVMX_SPINLOCK_H__
@@ -102,7 +102,7 @@ static inline void cvmx_spinlock_init(cvmx_spinlock_t * lock)
 static inline void cvmx_spinlock_unlock(cvmx_spinlock_t * lock)
 {
 	CVMX_SYNCWS;
-	lock->value = 0;
+	lock->value = CVMX_SPINLOCK_UNLOCKED_VAL;
 	CVMX_SYNCWS;
 }
 
@@ -122,7 +122,8 @@ static inline unsigned int cvmx_spinlock_trylock(cvmx_spinlock_t * lock)
 {
 	unsigned int tmp;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "1: ll   %[tmp], %[val] \n"
 			     "   bnez %[tmp], 2f     \n"  /* if lock held, fail immediately */
 			     "    li   %[tmp], 1     \n"
@@ -130,7 +131,7 @@ static inline unsigned int cvmx_spinlock_trylock(cvmx_spinlock_t * lock)
 			     "   beqz %[tmp], 1b     \n"
 			     "    li   %[tmp], 0     \n"
 			     "2:                     \n"
-			     ".set reorder           \n"
+			     ".set pop           \n"
 			     :[val] "+m"(lock->value),[tmp] "=&r"(tmp)
 			     ::"memory");
 
@@ -146,14 +147,15 @@ static inline void cvmx_spinlock_lock(cvmx_spinlock_t * lock)
 {
 	unsigned int tmp;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "1: ll   %[tmp], %[val] \n"
 			     "   bnez %[tmp], 1b     \n"
 			     "    li   %[tmp], 1     \n"
 			     "   sc   %[tmp], %[val] \n"
 			     "   beqz %[tmp], 1b     \n"
 			     "    nop                \n"
-			     ".set reorder           \n"
+			     ".set pop           \n"
 			     :[val] "+m"(lock->value),[tmp] "=&r"(tmp)
 			     ::"memory");
 
@@ -180,7 +182,8 @@ static inline void cvmx_spinlock_bit_lock(uint32_t * word)
 	unsigned int tmp;
 	unsigned int sav;
 
-	__asm__ __volatile__(".set noreorder         \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     ".set noat              \n"
 			     "1: ll    %[tmp], %[val]  \n"
 			     "   bbit1 %[tmp], 31, 1b  \n"
@@ -189,8 +192,7 @@ static inline void cvmx_spinlock_bit_lock(uint32_t * word)
 			     "   sc    %[tmp], %[val] \n"
 			     "   beqz  %[tmp], 1b     \n"
 			     "    nop                \n"
-			     ".set at              \n"
-			     ".set reorder           \n"
+			     ".set pop              \n"
 			     :[val] "+m"(*word),[tmp] "=&r"(tmp),[sav] "=&r"(sav)
 			     ::"memory");
 
@@ -211,7 +213,8 @@ static inline unsigned int cvmx_spinlock_bit_trylock(uint32_t * word)
 {
 	unsigned int tmp;
 
-	__asm__ __volatile__(".set noreorder           \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     ".set noat                \n"
 			     "1: ll    %[tmp], %[val]  \n"
 			     "    bbit1 %[tmp], 31, 2f \n" /* if lock held, fail immediately */
@@ -221,8 +224,7 @@ static inline unsigned int cvmx_spinlock_bit_trylock(uint32_t * word)
 			     "   beqz  %[tmp], 1b      \n"
 			     "    li    %[tmp], 0      \n"
 			     "2:                       \n"
-			     ".set at                  \n"
-			     ".set reorder             \n"
+			     ".set pop                  \n"
 			     :[val] "+m"(*word),[tmp] "=&r"(tmp)
 			     ::"memory");
 
@@ -303,7 +305,8 @@ static inline void cvmx_spinlock_rec_unlock(cvmx_spinlock_rec_t * lock)
 	}
 #endif
 
-	__asm__ __volatile__(".set  noreorder                 \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "     addi  %[tmp], %[pid], 0x80 \n"
 			     "     sw    %[tmp], %[lid]       # set lid to invalid value\n"
 			     CVMX_SYNCWS_STR
@@ -317,7 +320,7 @@ static inline void cvmx_spinlock_rec_unlock(cvmx_spinlock_rec_t * lock)
 			     "     sw   %[pid], %[lid]        # set lid to pid, only if lock still held\n"
 			     "2:                         \n"
 			     CVMX_SYNCWS_STR
-			     ".set  reorder                   \n"
+			     ".set  pop                   \n"
 			     :[res] "=&r"(result),[tmp] "=&r"(temp),[val] "+m"(lock->value),[lid] "+m"(lock->core_num)
 			     :[pid] "r"(core_num)
 			     :"memory");
@@ -359,7 +362,8 @@ static inline void cvmx_spinlock_rec_lock(cvmx_spinlock_rec_t * lock)
 
 	core_num = cvmx_get_core_num();
 
-	__asm__ __volatile__(".set  noreorder              \n"
+	__asm__ __volatile__(".set push         \n"
+			     ".set noreorder         \n"
 			     "1: ll   %[tmp], %[val]       # load the count\n"
 			     "   bnez %[tmp], 2f           # if count!=zero branch to 2\n"
 			     "    addu %[tmp], %[tmp], 1   \n"
@@ -375,7 +379,7 @@ static inline void cvmx_spinlock_rec_lock(cvmx_spinlock_rec_t * lock)
 			     "   sw   %[tmp], %[val]       # update the count\n"
 			     "3: sw   %[pid], %[lid]       # store the core_num\n"
 			     CVMX_SYNCWS_STR
-			     ".set  reorder                \n"
+			     ".set  pop                \n"
 			     :[tmp] "=&r"(tmp),[val] "+m"(lock->value),[lid] "+m"(lock->core_num)
 			     :[pid] "r"(core_num)
 			     :"memory");
diff --git a/arch/mips/include/asm/octeon/cvmx-uart.h b/arch/mips/include/asm/octeon/cvmx-uart.h
index ae049d3..f973e13 100644
--- a/arch/mips/include/asm/octeon/cvmx-uart.h
+++ b/arch/mips/include/asm/octeon/cvmx-uart.h
@@ -42,7 +42,7 @@
  *
  * interface to the serial port UART hardware
  *
- * <hr>$Revision: 88249 $<hr>
+ * <hr>$Revision: 106907 $<hr>
  *
  */
 
@@ -64,6 +64,8 @@ extern "C" {
 typedef void (*cvmx_uart_intr_handler_t) (int, uint64_t[]);
 
 extern void cvmx_uart_enable_intr(int, cvmx_uart_intr_handler_t);
+extern void cvmx_uart_unmask_intr_on_core(int, int);
+extern void cvmx_uart_mask_intr_on_core(int, int);
 extern int cvmx_uart_setup2(int, int, int);
 extern int cvmx_uart_setup(int);
 
diff --git a/arch/mips/include/asm/octeon/cvmx-usb.h b/arch/mips/include/asm/octeon/cvmx-usb.h
index 44121cc..ed1f340 100644
--- a/arch/mips/include/asm/octeon/cvmx-usb.h
+++ b/arch/mips/include/asm/octeon/cvmx-usb.h
@@ -516,7 +516,7 @@ typedef enum {
 	CVMX_USB_COMPLETE_SUCCESS,
 				    /**< The transaction / operation finished without any errors */
 	CVMX_USB_COMPLETE_SHORT,
-				    /**< FIXME: This is currently not implemented */
+				    /**< This is currently not implemented */
 	CVMX_USB_COMPLETE_CANCEL,
 				    /**< The transaction was canceled while in flight by a user call to cvmx_usb_cancel* */
 	CVMX_USB_COMPLETE_ERROR,
diff --git a/arch/mips/include/asm/octeon/octeon-boot-info.h b/arch/mips/include/asm/octeon/octeon-boot-info.h
index c0c6df5..4233d11 100644
--- a/arch/mips/include/asm/octeon/octeon-boot-info.h
+++ b/arch/mips/include/asm/octeon/octeon-boot-info.h
@@ -122,7 +122,6 @@ typedef struct  boot_init_vector boot_init_vector_t;
 #undef GD_TMP_STR_SIZE
 #define GD_TMP_STR_SIZE 32
 
-/* FIXME: This structure is not endianness-neutral */
 /* This structure is deprecated, use sysinfo instead */
 struct linux_app_global_data {
 #if	_MIPS_SZPTR == 32
diff --git a/arch/mips/include/asm/octeon/octeon-feature.h b/arch/mips/include/asm/octeon/octeon-feature.h
index ddb9825..c41c1b8 100644
--- a/arch/mips/include/asm/octeon/octeon-feature.h
+++ b/arch/mips/include/asm/octeon/octeon-feature.h
@@ -437,7 +437,7 @@ static inline int octeon_has_feature_OCTEON_FEATURE_MULTICAST_TIMER(void)
 
 static inline int octeon_has_feature_OCTEON_FEATURE_MULTINODE(void)
 {
-	return (OCTEON_IS_MODEL(OCTEON_CN78XX));
+	return OCTEON_IS_MODEL(OCTEON_CN78XX);
 }
 
 static inline int octeon_has_feature_OCTEON_FEATURE_CN78XX_WQE(void)
diff --git a/arch/mips/include/asm/octeon/octeon-model.h b/arch/mips/include/asm/octeon/octeon-model.h
index fb4f50a..171ba80 100644
--- a/arch/mips/include/asm/octeon/octeon-model.h
+++ b/arch/mips/include/asm/octeon/octeon-model.h
@@ -43,7 +43,7 @@
  * File defining different Octeon model IDs and macros to
  * compare them.
  *
- * <hr>$Revision: 103698 $<hr>
+ * <hr>$Revision: 107196 $<hr>
  */
 
 #ifndef __OCTEON_MODEL_H__
@@ -99,6 +99,10 @@ extern "C" {
  * CN7XXX models with new revision encoding
  */
 
+#define OCTEON_CN73XX_PASS1_0   0x000d9700
+#define OCTEON_CN73XX           (OCTEON_CN73XX_PASS1_0 | OM_IGNORE_REVISION)
+#define OCTEON_CN73XX_PASS1_X   (OCTEON_CN73XX_PASS1_0 | OM_IGNORE_MINOR_REVISION)
+
 #define OCTEON_CN70XX_PASS1_0   0x000d9600
 #define OCTEON_CN70XX_PASS1_1   0x000d9601
 #define OCTEON_CN70XX_PASS1_2   0x000d9602
-- 
2.6.2

