From 4c378e3f1386d9bb2dfaac0421f80dab861404db Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Sat, 22 Feb 2014 13:46:59 -0800
Subject: [PATCH 553/974] netdev: octeon3-ethernet: Move FCS and padding to
 BGX.

Since the PKO has problems with padding, move this to BGX and remove
the padding workarounds from the transmit code.

Signed-off-by: David Daney <david.daney@cavium.com>
[Original patch taken from Cavium SDK 3.1.2-568]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
---
 drivers/net/ethernet/octeon/octeon-bgx-port.c  | 44 ++++++++++++++++++++++++++
 drivers/net/ethernet/octeon/octeon3-ethernet.c | 30 +++---------------
 2 files changed, 48 insertions(+), 26 deletions(-)

diff --git a/drivers/net/ethernet/octeon/octeon-bgx-port.c b/drivers/net/ethernet/octeon/octeon-bgx-port.c
index c572c4f..727dc9c 100644
--- a/drivers/net/ethernet/octeon/octeon-bgx-port.c
+++ b/drivers/net/ethernet/octeon/octeon-bgx-port.c
@@ -203,10 +203,54 @@ static void bgx_port_adjust_link(struct net_device *netdev)
 
 int bgx_port_enable(struct net_device *netdev)
 {
+	union cvmx_bgxx_cmrx_config cfg;
 	struct bgx_port_priv *priv = bgx_port_netdev2priv(netdev);
 
 	cvmx_helper_set_1000x_mode(priv->xiface, priv->index, false);
 	cvmx_helper_set_mac_phy_mode(priv->xiface, priv->index, false);
+
+	cfg.u64 = cvmx_read_csr_node(priv->numa_node, CVMX_BGXX_CMRX_CONFIG(priv->index, priv->bgx_interface));
+	if (cfg.s.lmac_type == 0) {
+		/* 1G */
+		union cvmx_bgxx_gmp_gmi_txx_append tx_append;
+		union cvmx_bgxx_gmp_gmi_txx_min_pkt min_pkt;
+
+		tx_append.u64 = cvmx_read_csr_node(priv->numa_node,
+						   CVMX_BGXX_GMP_GMI_TXX_APPEND(priv->index, priv->bgx_interface));
+		tx_append.s.fcs = 1;
+		tx_append.s.pad = 1;
+
+		cvmx_write_csr_node(priv->numa_node,
+				    CVMX_BGXX_GMP_GMI_TXX_APPEND(priv->index, priv->bgx_interface),
+				    tx_append.u64);
+
+		min_pkt.u64 = 0;
+		min_pkt.s.min_size = 60 - 1; /* packets are padded to MIN_SIZE + 1 in SGMII */
+		cvmx_write_csr_node(priv->numa_node,
+				    CVMX_BGXX_GMP_GMI_TXX_MIN_PKT(priv->index, priv->bgx_interface),
+				    min_pkt.u64);
+	} else {
+		/* 10G or higher */
+		union cvmx_bgxx_smux_tx_append tx_append;
+		union cvmx_bgxx_smux_tx_min_pkt min_pkt;
+
+		tx_append.u64 = cvmx_read_csr_node(priv->numa_node,
+						   CVMX_BGXX_SMUX_TX_APPEND(priv->index, priv->bgx_interface));
+		tx_append.s.fcs_d = 1;
+		tx_append.s.pad = 1;
+
+		cvmx_write_csr_node(priv->numa_node,
+				    CVMX_BGXX_SMUX_TX_APPEND(priv->index, priv->bgx_interface),
+				    tx_append.u64);
+
+		min_pkt.u64 = 0;
+		min_pkt.s.min_size = 60;/* packets are padded to MIN_SIZE in non-SGMII */
+		cvmx_write_csr_node(priv->numa_node,
+				    CVMX_BGXX_SMUX_TX_MIN_PKT(priv->index, priv->bgx_interface),
+				    min_pkt.u64);
+
+	}
+
 	if (priv->phy_np == NULL) {
 		netif_carrier_on(netdev);
 		return 0;
diff --git a/drivers/net/ethernet/octeon/octeon3-ethernet.c b/drivers/net/ethernet/octeon/octeon3-ethernet.c
index 03e3efc..c8a862b 100644
--- a/drivers/net/ethernet/octeon/octeon3-ethernet.c
+++ b/drivers/net/ethernet/octeon/octeon3-ethernet.c
@@ -95,7 +95,6 @@ struct octeon3_ethernet_node {
 	struct task_struct *tx_complete_task;
 	struct kthread_worker tx_complete_worker;
 	struct kthread_work tx_complete_work;
-	u8 *sixty_zeros;
 };
 
 static int num_packet_buffers = 512;
@@ -291,11 +290,6 @@ static int octeon3_eth_global_init(unsigned int node)
 		goto done;
 
 	nd->numa_node = node;
-	nd->sixty_zeros = kzalloc_node(ETH_ZLEN, GFP_KERNEL, node);
-	if (!nd->sixty_zeros) {
-		rv = -ENOMEM;
-		goto done;
-	}
 	for (i = 0; i < 1024; i++) {
 		cvmx_write_csr_node(node, CVMX_FPA_AURAX_CNT(i), 0x100000000ull);
 		cvmx_write_csr_node(node, CVMX_FPA_AURAX_CNT_LIMIT(i), 0xfffffffffull);
@@ -603,9 +597,8 @@ static int octeon3_eth_ndo_init(struct net_device *netdev)
 	if (r < 0)
 		return -ENODEV;
 
-	r = cvmx_pko3_interface_options(priv->xiface, priv->port_index,
-					__cvmx_helper_get_has_fcs(priv->xiface),
-					__cvmx_helper_get_pko_padding(priv->xiface), 0);
+	/* Padding and FCS are done in BGX */
+	r = cvmx_pko3_interface_options(priv->xiface, priv->port_index, false, false, 0);
 	if (r)
 		return -ENODEV;
 
@@ -806,17 +799,9 @@ static int octeon3_eth_ndo_start_xmit(struct sk_buff *skb, struct net_device *ne
 	int frag_count;
 	int head_len, i;
 	u64 dma_addr;
-	int zero_pad;
 	void **work;
 
-	/* PKO-20715, must manually pad. */
-	if (skb->len < ETH_ZLEN) {
-		zero_pad = ETH_ZLEN - skb->len;
-		frag_count = 1;
-	} else {
-		zero_pad = 0;
-		frag_count = 0;
-	}
+	frag_count = 0;
 	if (skb_has_frag_list(skb))
 		skb_walk_frags(skb, skb_tmp)
 			frag_count++;
@@ -852,7 +837,7 @@ static int octeon3_eth_ndo_start_xmit(struct sk_buff *skb, struct net_device *ne
 #endif
 /* broken in sim */	send_hdr.s.n2 = 1; /* Don't allocate to L2 */
 	send_hdr.s.df = 1; /* Don't automatically free to FPA */
-	send_hdr.s.total = skb->len + zero_pad;
+	send_hdr.s.total = skb->len;
 
 #ifndef BROKEN_SIMULATOR_CSUM
 	switch (skb->protocol) {
@@ -916,13 +901,6 @@ static int octeon3_eth_ndo_start_xmit(struct sk_buff *skb, struct net_device *ne
 		scr_off += sizeof(buf_ptr);
 	}
 
-	if (zero_pad) {
-		buf_ptr.s.addr = virt_to_phys(octeon3_eth_node[priv->numa_node].sixty_zeros);
-		buf_ptr.s.size = zero_pad;
-		cvmx_scratch_write64(scr_off, buf_ptr.u64);
-		scr_off += sizeof(buf_ptr);
-	}
-
 	/* Subtract 1 from the tx_backlog. */
 	send_mem.u64 = 0;
 	send_mem.s.subdc4 = CVMX_PKO_SENDSUBDC_MEM;
-- 
2.6.2

