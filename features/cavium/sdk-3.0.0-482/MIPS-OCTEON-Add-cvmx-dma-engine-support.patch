From 6493612d507d6cded1efd294e69b87800bf28a82 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Fri, 19 Oct 2012 14:27:44 -0700
Subject: [PATCH 202/337] MIPS: OCTEON: Add cvmx-dma-engine support.

Based On SDK 3.0.0-482

To be used by sRIO.

Signed-off-by: David Daney <david.daney@cavium.com>
Signed-off-by: Corey Minyard <cminyard@mvista.com>
Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/cavium-octeon/executive/Makefile         |    1 +
 .../mips/cavium-octeon/executive/cvmx-dma-engine.c |  470 ++++++++++++++++++++
 arch/mips/include/asm/octeon/cvmx-dma-engine.h     |  340 ++++++++++++++
 3 files changed, 811 insertions(+), 0 deletions(-)
 create mode 100644 arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
 create mode 100644 arch/mips/include/asm/octeon/cvmx-dma-engine.h

diff --git a/arch/mips/cavium-octeon/executive/Makefile b/arch/mips/cavium-octeon/executive/Makefile
index 1a49a79..211ff9c 100644
--- a/arch/mips/cavium-octeon/executive/Makefile
+++ b/arch/mips/cavium-octeon/executive/Makefile
@@ -25,3 +25,4 @@ obj-y += cvmx-interrupt-decodes.o cvmx-interrupt-rsl.o
 obj-y += cvmx-helper-errata.o cvmx-helper-jtag.o
 
 obj-$(CONFIG_USB_OCTEON_HCD) += cvmx-usb.o
+obj-$(CONFIG_CAVIUM_OCTEON_RAPIDIO) += cvmx-dma-engine.o
diff --git a/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c b/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
new file mode 100644
index 0000000..b46e5a1
--- /dev/null
+++ b/arch/mips/cavium-octeon/executive/cvmx-dma-engine.c
@@ -0,0 +1,470 @@
+/***********************license start***************
+ * Author: Cavium Inc.
+ *
+ * Contact: support@cavium.com
+ * This file is part of the OCTEON SDK
+ *
+ * Copyright (c) 2003-2010 Cavium Inc.
+ *
+ * This file is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License, Version 2, as
+ * published by the Free Software Foundation.
+ *
+ * This file is distributed in the hope that it will be useful, but
+ * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
+ * NONINFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this file; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
+ * or visit http://www.gnu.org/licenses/.
+ *
+ * This file may also be available under a different license from Cavium.
+ * Contact Cavium Inc. for more information
+ ***********************license end**************************************/
+
+/*
+ * Interface to the PCI / PCIe DMA engines. These are only avialable
+ * on chips with PCI / PCIe.
+ *
+ */
+#include <linux/export.h>
+
+#include <asm/octeon/cvmx.h>
+#include <asm/octeon/octeon-model.h>
+#include <asm/octeon/cvmx-config.h>
+#include <asm/octeon/cvmx-cmd-queue.h>
+#include <asm/octeon/cvmx-dma-engine.h>
+#include <asm/octeon/octeon-feature.h>
+#include <asm/octeon/cvmx-npi-defs.h>
+#include <asm/octeon/cvmx-npei-defs.h>
+#include <asm/octeon/cvmx-dpi-defs.h>
+#include <asm/octeon/cvmx-pexp-defs.h>
+#include <asm/octeon/cvmx-helper-cfg.h>
+
+
+/**
+ * Return the number of DMA engimes supported by this chip
+ *
+ * Returns Number of DMA engines
+ */
+int cvmx_dma_engine_get_num(void)
+{
+	if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
+		if (OCTEON_IS_MODEL(OCTEON_CN52XX_PASS1_X))
+			return 4;
+		else
+			return 5;
+	} else if (octeon_has_feature(OCTEON_FEATURE_PCIE))
+		return 8;
+	else
+		return 2;
+}
+
+/**
+ * Initialize the DMA engines for use
+ *
+ * Returns Zero on success, negative on failure
+ */
+int cvmx_dma_engine_initialize(void)
+{
+	int engine;
+
+	for (engine = 0; engine < cvmx_dma_engine_get_num(); engine++) {
+		cvmx_cmd_queue_result_t result;
+		result = cvmx_cmd_queue_initialize(CVMX_CMD_QUEUE_DMA(engine), 0, CVMX_FPA_OUTPUT_BUFFER_POOL, CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE);
+		if (result != CVMX_CMD_QUEUE_SUCCESS)
+			return -1;
+		if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
+			union cvmx_npei_dmax_ibuff_saddr dmax_ibuff_saddr;
+			dmax_ibuff_saddr.u64 = 0;
+			dmax_ibuff_saddr.s.saddr = cvmx_ptr_to_phys(cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_DMA(engine))) >> 7;
+			cvmx_write_csr(CVMX_PEXP_NPEI_DMAX_IBUFF_SADDR(engine), dmax_ibuff_saddr.u64);
+		} else if (octeon_has_feature(OCTEON_FEATURE_PCIE)) {
+			union cvmx_dpi_dmax_ibuff_saddr dpi_dmax_ibuff_saddr;
+			dpi_dmax_ibuff_saddr.u64 = 0;
+			dpi_dmax_ibuff_saddr.s.csize = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE / 8;
+			dpi_dmax_ibuff_saddr.s.saddr = cvmx_ptr_to_phys(cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_DMA(engine))) >> 7;
+			cvmx_write_csr(CVMX_DPI_DMAX_IBUFF_SADDR(engine), dpi_dmax_ibuff_saddr.u64);
+		} else {
+			uint64_t address = cvmx_ptr_to_phys(cvmx_cmd_queue_buffer(CVMX_CMD_QUEUE_DMA(engine)));
+			if (engine)
+				cvmx_write_csr(CVMX_NPI_HIGHP_IBUFF_SADDR, address);
+			else
+				cvmx_write_csr(CVMX_NPI_LOWP_IBUFF_SADDR, address);
+		}
+	}
+
+	if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
+		union cvmx_npei_dma_control dma_control;
+		dma_control.u64 = 0;
+		if (cvmx_dma_engine_get_num() >= 5)
+			dma_control.s.dma4_enb = 1;
+		dma_control.s.dma3_enb = 1;
+		dma_control.s.dma2_enb = 1;
+		dma_control.s.dma1_enb = 1;
+		dma_control.s.dma0_enb = 1;
+		dma_control.s.o_mode = 1;	/* Pull NS and RO from this register, not the pointers */
+		//dma_control.s.dwb_denb = 1;
+		//dma_control.s.dwb_ichk = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE/128;
+		dma_control.s.fpa_que = CVMX_FPA_OUTPUT_BUFFER_POOL;
+		dma_control.s.csize = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE / 8;
+		cvmx_write_csr(CVMX_PEXP_NPEI_DMA_CONTROL, dma_control.u64);
+		/* As a workaround for errata PCIE-811 we only allow a single
+		   outstanding DMA read over PCIe at a time. This limits performance,
+		   but works in all cases. If you need higher performance, remove
+		   this code and implement the more complicated workaround documented
+		   in the errata. This only affects CN56XX pass 2.0 chips */
+		if (OCTEON_IS_MODEL(OCTEON_CN56XX_PASS2_0)) {
+			union cvmx_npei_dma_pcie_req_num pcie_req_num;
+			pcie_req_num.u64 = cvmx_read_csr(CVMX_PEXP_NPEI_DMA_PCIE_REQ_NUM);
+			pcie_req_num.s.dma_cnt = 1;
+			cvmx_write_csr(CVMX_PEXP_NPEI_DMA_PCIE_REQ_NUM, pcie_req_num.u64);
+		}
+	} else if (octeon_has_feature(OCTEON_FEATURE_PCIE)) {
+		union cvmx_dpi_engx_buf dpi_engx_buf;
+		union cvmx_dpi_dma_engx_en dpi_dma_engx_en;
+		union cvmx_dpi_dma_control dma_control;
+		union cvmx_dpi_ctl dpi_ctl;
+
+		/* Based on Errata DPI-15368 workaround, set DPI_CTL[EN], before
+		   DPI_DMA_CONTROL[PKT_EN*] are set. */
+		dpi_ctl.u64 = cvmx_read_csr(CVMX_DPI_CTL);
+		dpi_ctl.s.en = 1;
+		cvmx_write_csr(CVMX_DPI_CTL, dpi_ctl.u64);
+
+		/* Give engine 0-4 1KB, and 5 3KB. This gives the packet engines better
+		   performance. Total must not exceed 8KB */
+		dpi_engx_buf.u64 = 0;
+		dpi_engx_buf.s.blks = 2;
+		cvmx_write_csr(CVMX_DPI_ENGX_BUF(0), dpi_engx_buf.u64);
+		cvmx_write_csr(CVMX_DPI_ENGX_BUF(1), dpi_engx_buf.u64);
+		cvmx_write_csr(CVMX_DPI_ENGX_BUF(2), dpi_engx_buf.u64);
+		cvmx_write_csr(CVMX_DPI_ENGX_BUF(3), dpi_engx_buf.u64);
+		cvmx_write_csr(CVMX_DPI_ENGX_BUF(4), dpi_engx_buf.u64);
+		dpi_engx_buf.s.blks = 6;
+		cvmx_write_csr(CVMX_DPI_ENGX_BUF(5), dpi_engx_buf.u64);
+
+		dma_control.u64 = cvmx_read_csr(CVMX_DPI_DMA_CONTROL);
+		dma_control.s.pkt_hp = 1;
+		dma_control.s.pkt_en = 1;
+		dma_control.s.dma_enb = 0x1f;
+		dma_control.s.dwb_denb = cvmx_helper_cfg_opt_get(CVMX_HELPER_CFG_OPT_USE_DWB);
+		dma_control.s.dwb_ichk = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE / 128;
+		dma_control.s.fpa_que = CVMX_FPA_OUTPUT_BUFFER_POOL;
+		dma_control.s.o_mode = 1;
+		cvmx_write_csr(CVMX_DPI_DMA_CONTROL, dma_control.u64);
+		/* When dma_control[pkt_en] = 1, engine 5 is used for packets and is not
+		   available for DMA. */
+		dpi_dma_engx_en.u64 = cvmx_read_csr(CVMX_DPI_DMA_ENGX_EN(5));
+		dpi_dma_engx_en.s.qen = 0;
+		cvmx_write_csr(CVMX_DPI_DMA_ENGX_EN(5), dpi_dma_engx_en.u64);
+	} else {
+		union cvmx_npi_dma_control dma_control;
+		dma_control.u64 = 0;
+		//dma_control.s.dwb_denb = 1;
+		//dma_control.s.dwb_ichk = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE/128;
+		dma_control.s.o_add1 = 1;
+		dma_control.s.fpa_que = CVMX_FPA_OUTPUT_BUFFER_POOL;
+		dma_control.s.hp_enb = 1;
+		dma_control.s.lp_enb = 1;
+		dma_control.s.csize = CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE / 8;
+		cvmx_write_csr(CVMX_NPI_DMA_CONTROL, dma_control.u64);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(cvmx_dma_engine_initialize);
+
+/**
+ * Shutdown all DMA engines. The engines must be idle when this
+ * function is called.
+ *
+ * Returns Zero on success, negative on failure
+ */
+int cvmx_dma_engine_shutdown(void)
+{
+	int engine;
+
+	for (engine = 0; engine < cvmx_dma_engine_get_num(); engine++) {
+		if (cvmx_cmd_queue_length(CVMX_CMD_QUEUE_DMA(engine))) {
+			cvmx_dprintf("ERROR: cvmx_dma_engine_shutdown: Engine not idle.\n");
+			return -1;
+		}
+	}
+
+	if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
+		union cvmx_npei_dma_control dma_control;
+		dma_control.u64 = cvmx_read_csr(CVMX_PEXP_NPEI_DMA_CONTROL);
+		if (cvmx_dma_engine_get_num() >= 5)
+			dma_control.s.dma4_enb = 0;
+		dma_control.s.dma3_enb = 0;
+		dma_control.s.dma2_enb = 0;
+		dma_control.s.dma1_enb = 0;
+		dma_control.s.dma0_enb = 0;
+		cvmx_write_csr(CVMX_PEXP_NPEI_DMA_CONTROL, dma_control.u64);
+		/* Make sure the disable completes */
+		cvmx_read_csr(CVMX_PEXP_NPEI_DMA_CONTROL);
+	} else if (octeon_has_feature(OCTEON_FEATURE_PCIE)) {
+		union cvmx_dpi_dma_control dma_control;
+		dma_control.u64 = cvmx_read_csr(CVMX_DPI_DMA_CONTROL);
+		dma_control.s.dma_enb = 0;
+		cvmx_write_csr(CVMX_DPI_DMA_CONTROL, dma_control.u64);
+		/* Make sure the disable completes */
+		cvmx_read_csr(CVMX_DPI_DMA_CONTROL);
+	} else {
+		union cvmx_npi_dma_control dma_control;
+		dma_control.u64 = cvmx_read_csr(CVMX_NPI_DMA_CONTROL);
+		dma_control.s.hp_enb = 0;
+		dma_control.s.lp_enb = 0;
+		cvmx_write_csr(CVMX_NPI_DMA_CONTROL, dma_control.u64);
+		/* Make sure the disable completes */
+		cvmx_read_csr(CVMX_NPI_DMA_CONTROL);
+	}
+
+	for (engine = 0; engine < cvmx_dma_engine_get_num(); engine++) {
+		cvmx_cmd_queue_shutdown(CVMX_CMD_QUEUE_DMA(engine));
+		if (octeon_has_feature(OCTEON_FEATURE_NPEI))
+			cvmx_write_csr(CVMX_PEXP_NPEI_DMAX_IBUFF_SADDR(engine), 0);
+		else if (octeon_has_feature(OCTEON_FEATURE_PCIE))
+			cvmx_write_csr(CVMX_DPI_DMAX_IBUFF_SADDR(engine), 0);
+		else {
+			if (engine)
+				cvmx_write_csr(CVMX_NPI_HIGHP_IBUFF_SADDR, 0);
+			else
+				cvmx_write_csr(CVMX_NPI_LOWP_IBUFF_SADDR, 0);
+		}
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(cvmx_dma_engine_shutdown);
+
+/**
+ * Submit a series of DMA command to the DMA engines.
+ *
+ * @engine:  Engine to submit to (0 to cvmx_dma_engine_get_num()-1)
+ * @header:  Command header
+ * @num_buffers:
+ *                The number of data pointers
+ * @buffers: Command data pointers
+ *
+ * Returns Zero on success, negative on failure
+ */
+int cvmx_dma_engine_submit(int engine, cvmx_dma_engine_header_t header, int num_buffers, cvmx_dma_engine_buffer_t buffers[])
+{
+	cvmx_cmd_queue_result_t result;
+	int cmd_count = 1;
+	uint64_t cmds[num_buffers + 1];
+
+	if (OCTEON_IS_MODEL(OCTEON_CN56XX_PASS1_X)) {
+		/* Check for Errata PCIe-604 */
+		if ((header.s.nfst > 11) || (header.s.nlst > 11) || (header.s.nfst + header.s.nlst > 15)) {
+			cvmx_dprintf("DMA engine submit too large\n");
+			return -1;
+		}
+	}
+
+	cmds[0] = header.u64;
+	while (num_buffers--) {
+		cmds[cmd_count++] = buffers->u64;
+		buffers++;
+	}
+
+	/* Due to errata PCIE-13315, it is necessary to have the queue lock while we
+	   ring the doorbell for the DMA engines. This prevents doorbells from
+	   possibly arriving out of order with respect to the command queue
+	   entries */
+	__cvmx_cmd_queue_lock(CVMX_CMD_QUEUE_DMA(engine), __cvmx_cmd_queue_get_state(CVMX_CMD_QUEUE_DMA(engine)));
+	result = cvmx_cmd_queue_write(CVMX_CMD_QUEUE_DMA(engine), 0, cmd_count, cmds);
+	/* This SYNCWS is needed since the command queue didn't do locking, which
+	   normally implies the SYNCWS. This one makes sure the command queue
+	   updates make it to L2 before we ring the doorbell */
+	CVMX_SYNCWS;
+	/* A syncw isn't needed here since the command queue did one as part of the queue unlock */
+	if (likely(result == CVMX_CMD_QUEUE_SUCCESS)) {
+		if (octeon_has_feature(OCTEON_FEATURE_NPEI)) {
+			/* DMA doorbells are 32bit writes in little endian space. This means we need to xor the address with 4 */
+			cvmx_write64_uint32(CVMX_PEXP_NPEI_DMAX_DBELL(engine) ^ 4, cmd_count);
+		} else if (octeon_has_feature(OCTEON_FEATURE_PCIE))
+			cvmx_write_csr(CVMX_DPI_DMAX_DBELL(engine), cmd_count);
+		else {
+			if (engine)
+				cvmx_write_csr(CVMX_NPI_HIGHP_DBELL, cmd_count);
+			else
+				cvmx_write_csr(CVMX_NPI_LOWP_DBELL, cmd_count);
+		}
+	}
+	/* Here is the unlock for the above errata workaround */
+	__cvmx_cmd_queue_unlock(__cvmx_cmd_queue_get_state(CVMX_CMD_QUEUE_DMA(engine)));
+	return result;
+}
+
+/**
+ * @INTERNAL
+ * Function used by cvmx_dma_engine_transfer() to build the
+ * internal address list.
+ *
+ * @buffers: Location to store the list
+ * @address: Address to build list for
+ * @size:    Length of the memory pointed to by address
+ *
+ * Returns Number of internal pointer chunks created
+ */
+static inline int __cvmx_dma_engine_build_internal_pointers(cvmx_dma_engine_buffer_t * buffers, uint64_t address, int size)
+{
+	int segments = 0;
+	while (size) {
+		/* Each internal chunk can contain a maximum of 8191 bytes */
+		int chunk = size;
+		if (chunk > 8191)
+			chunk = 8191;
+		buffers[segments].u64 = 0;
+		buffers[segments].internal.size = chunk;
+		buffers[segments].internal.addr = address;
+		address += chunk;
+		size -= chunk;
+		segments++;
+	}
+	return segments;
+}
+
+/**
+ * Function used by cvmx_dma_engine_transfer() to build the PCI / PCIe address
+ * list.
+ * @buffers: Location to store the list
+ * @address: Address to build list for
+ * @size:    Length of the memory pointed to by address
+ *
+ * Returns Number of PCI / PCIe address chunks created. The number of words used
+ *         will be segments + (segments-1)/4 + 1.
+ */
+static inline int __cvmx_dma_engine_build_external_pointers(cvmx_dma_engine_buffer_t * buffers, uint64_t address, int size)
+{
+	const int MAX_SIZE = 65535;
+	int segments = 0;
+	while (size) {
+		/* Each block of 4 PCI / PCIe pointers uses one dword for lengths followed by
+		   up to 4 addresses. This then repeats if more data is needed */
+		buffers[0].u64 = 0;
+		if (size <= MAX_SIZE) {
+			/* Only one more segment needed */
+			buffers[0].pcie_length.len0 = size;
+			buffers[1].u64 = address;
+			segments++;
+			break;
+		} else if (size <= MAX_SIZE * 2) {
+			/* Two more segments needed */
+			buffers[0].pcie_length.len0 = MAX_SIZE;
+			buffers[0].pcie_length.len1 = size - MAX_SIZE;
+			buffers[1].u64 = address;
+			address += MAX_SIZE;
+			buffers[2].u64 = address;
+			segments += 2;
+			break;
+		} else if (size <= MAX_SIZE * 3) {
+			/* Three more segments needed */
+			buffers[0].pcie_length.len0 = MAX_SIZE;
+			buffers[0].pcie_length.len1 = MAX_SIZE;
+			buffers[0].pcie_length.len2 = size - MAX_SIZE * 2;
+			buffers[1].u64 = address;
+			address += MAX_SIZE;
+			buffers[2].u64 = address;
+			address += MAX_SIZE;
+			buffers[3].u64 = address;
+			segments += 3;
+			break;
+		} else if (size <= MAX_SIZE * 4) {
+			/* Four more segments needed */
+			buffers[0].pcie_length.len0 = MAX_SIZE;
+			buffers[0].pcie_length.len1 = MAX_SIZE;
+			buffers[0].pcie_length.len2 = MAX_SIZE;
+			buffers[0].pcie_length.len3 = size - MAX_SIZE * 3;
+			buffers[1].u64 = address;
+			address += MAX_SIZE;
+			buffers[2].u64 = address;
+			address += MAX_SIZE;
+			buffers[3].u64 = address;
+			address += MAX_SIZE;
+			buffers[4].u64 = address;
+			segments += 4;
+			break;
+		} else {
+			/* Five or more segments are needed */
+			buffers[0].pcie_length.len0 = MAX_SIZE;
+			buffers[0].pcie_length.len1 = MAX_SIZE;
+			buffers[0].pcie_length.len2 = MAX_SIZE;
+			buffers[0].pcie_length.len3 = MAX_SIZE;
+			buffers[1].u64 = address;
+			address += MAX_SIZE;
+			buffers[2].u64 = address;
+			address += MAX_SIZE;
+			buffers[3].u64 = address;
+			address += MAX_SIZE;
+			buffers[4].u64 = address;
+			address += MAX_SIZE;
+			size -= MAX_SIZE * 4;
+			buffers += 5;
+			segments += 4;
+		}
+	}
+	return segments;
+}
+
+/**
+ * Build the first and last pointers based on a DMA engine header
+ * and submit them to the engine. The purpose of this function is
+ * to simplify the building of DMA engine commands by automatically
+ * converting a simple address and size into the apropriate internal
+ * or PCI / PCIe address list. This function does not support gather lists,
+ * so you will need to build your own lists in that case.
+ *
+ * @engine: Engine to submit to (0 to cvmx_dma_engine_get_num()-1)
+ * @header: DMA Command header. Note that the nfst and nlst fields do not
+ *               need to be filled in. All other fields must be set properly.
+ * @first_address:
+ *               Address to use for the first pointers. In the case of INTERNAL,
+ *               INBOUND, and OUTBOUND this is an Octeon memory address. In the
+ *               case of EXTERNAL, this is the source PCI / PCIe address.
+ * @last_address:
+ *               Address to use for the last pointers. In the case of EXTERNAL,
+ *               INBOUND, and OUTBOUND this is a PCI / PCIe address. In the
+ *               case of INTERNAL, this is the Octeon memory destination address.
+ * @size:   Size of the transfer to perform.
+ *
+ * Returns Zero on success, negative on failure
+ */
+int cvmx_dma_engine_transfer(int engine, cvmx_dma_engine_header_t header, uint64_t first_address, uint64_t last_address, int size)
+{
+	cvmx_dma_engine_buffer_t buffers[32];
+	int words = 0;
+
+	switch (header.s.type) {
+	case CVMX_DMA_ENGINE_TRANSFER_INTERNAL:
+		header.s.nfst = __cvmx_dma_engine_build_internal_pointers(buffers, first_address, size);
+		words += header.s.nfst;
+		header.s.nlst = __cvmx_dma_engine_build_internal_pointers(buffers + words, last_address, size);
+		words += header.s.nlst;
+		break;
+	case CVMX_DMA_ENGINE_TRANSFER_INBOUND:
+	case CVMX_DMA_ENGINE_TRANSFER_OUTBOUND:
+		header.s.nfst = __cvmx_dma_engine_build_internal_pointers(buffers, first_address, size);
+		words += header.s.nfst;
+		header.s.nlst = __cvmx_dma_engine_build_external_pointers(buffers + words, last_address, size);
+		words += header.s.nlst + ((header.s.nlst - 1) >> 2) + 1;
+		break;
+	case CVMX_DMA_ENGINE_TRANSFER_EXTERNAL:
+		header.s.nfst = __cvmx_dma_engine_build_external_pointers(buffers, first_address, size);
+		words += header.s.nfst + ((header.s.nfst - 1) >> 2) + 1;
+		header.s.nlst = __cvmx_dma_engine_build_external_pointers(buffers + words, last_address, size);
+		words += header.s.nlst + ((header.s.nlst - 1) >> 2) + 1;
+		break;
+	default:
+		return -1;
+	}
+	return cvmx_dma_engine_submit(engine, header, words, buffers);
+}
+
+EXPORT_SYMBOL(cvmx_dma_engine_transfer);
diff --git a/arch/mips/include/asm/octeon/cvmx-dma-engine.h b/arch/mips/include/asm/octeon/cvmx-dma-engine.h
new file mode 100644
index 0000000..7c0885a
--- /dev/null
+++ b/arch/mips/include/asm/octeon/cvmx-dma-engine.h
@@ -0,0 +1,340 @@
+/***********************license start***************
+ * Author: Cavium Inc.
+ *
+ * Contact: support@cavium.com
+ * This file is part of the OCTEON SDK
+ *
+ * Copyright (c) 2003-2010 Cavium Inc.
+ *
+ * This file is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License, Version 2, as
+ * published by the Free Software Foundation.
+ *
+ * This file is distributed in the hope that it will be useful, but
+ * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
+ * NONINFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this file; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
+ * or visit http://www.gnu.org/licenses/.
+ *
+ * This file may also be available under a different license from Cavium.
+ * Contact Cavium Inc. for more information
+ ***********************license end**************************************/
+
+/*
+ * Interface to the PCI / PCIe DMA engines. These are only avialable
+ * on chips with PCI / PCIe.
+ *
+ */
+
+#ifndef __CVMX_DMA_ENGINES_H__
+#define __CVMX_DMA_ENGINES_H__
+
+#include <asm/octeon/cvmx-dpi-defs.h>
+
+typedef enum {
+	CVMX_DMA_ENGINE_TRANSFER_OUTBOUND = 0,
+	/**< OUTBOUND (read from L2/DRAM, write into PCI / PCIe memory space) */
+	CVMX_DMA_ENGINE_TRANSFER_INBOUND = 1,
+	/**< INBOUND (read from PCI / PCIe memory space, write into L2/DRAM) */
+	CVMX_DMA_ENGINE_TRANSFER_INTERNAL = 2,
+	/**< INTERNAL-ONLY (read from L2/DRAM, write into L2/DRAM). Only available on chips with PCIe */
+	CVMX_DMA_ENGINE_TRANSFER_EXTERNAL = 3,
+	/**< EXTERNAL-ONLY (read from PCIe memory space, write into PCIe memory space). Only available on chips with PCIe */
+} cvmx_dma_engine_transfer_t;
+
+typedef union {
+	uint64_t u64;
+	struct {
+		uint64_t reserved_60_63:4;
+		/**< Must be zero */
+		uint64_t fport:2;   /**< First port. FPort indicates the physical PCIe port used for the
+				       PCIe memory space pointers in the FIRST POINTERS block in the
+				       EXTERNAL-ONLY case. Must be zero in the OUTBOUND, INBOUND and
+				       INTERNAL-ONLY cases. Must be zero on chips with PCI */
+		uint64_t lport:2;   /**< Last port. LPort indicates the physical PCIe port used for the
+				       PCIe memory space pointers in the LAST POINTERS block in the
+				       OUTBOUND, INBOUND, and EXTERNAL-ONLY cases. Must be zero in the
+				       INTERNAL-ONLY case. Must be zero on chips with PCI */
+		cvmx_dma_engine_transfer_t type:2;
+		/**< Type ­ A given PCI DMA transfer is either OUTBOUND (read from L2/DRAM,
+		   write into PCI / PCIe memory space), INBOUND (read from PCI / PCIe memory space, write
+		   into L2/DRAM), INTERNAL-ONLY (read from L2/DRAM, write into L2/DRAM), or
+		   EXTERNAL-ONLY (read from PCIe memory space, write into PCIe memory space). */
+		uint64_t wqp:1;	    /**< Work-queue pointer. When WQP = 1, PTR (if non-zero) is a pointer to a
+				       work-queue entry that is submitted by the hardware after completing the DMA;
+				       when WQP = 0, PTR (if non-zero) is a pointer to a byte in local memory that
+				       is written to 0 by the hardware after completing the DMA. */
+		uint64_t c:1;	    /**< C ­ Counter. 1 = use counter 1, 0 = use counter 0.
+				       The C bit selects between the two counters (NPEI_DMA_CNTS[DMA0,DMA1])
+				       that can optionally be updated after an OUTBOUND or EXTERNAL-ONLY
+				       transfer, and also selects between the two forced-interrupt bits
+				       (NPEI_INT_SUMn[DMA0_FI, DMA1_FI]) that can optionally be set after an
+				       OUTBOUND or EXTERNAL-ONLY transfer. C must be zero for INBOUND or
+				       INTERNAL-ONLY transfers. */
+		uint64_t ca:1;	    /**< CA ­ Counter add.
+				       When CA = 1, the hardware updates the selected counter after it completes the
+				       PCI DMA OUTBOUND or EXTERNAL-ONLY Instruction.
+				       - If C = 0, PCIE_DMA_CNT0 is updated
+				       - If C = 1, PCIE_DMA_CNT1 is updated.
+				       Note that this update may indirectly cause
+				       NPEI_INT_SUM[DCNT0,DCNT1,DTIME0,DTIME1] to become set (depending
+				       on the NPEI_DMA*_INT_LEVEL settings), so may cause interrupts to occur on a
+				       remote PCI host.
+				       - If NPEI_DMA_CONTROL[O_ADD1] = 1, the counter is updated by 1.
+				       - If NPEI_DMA_CONTROL[O_ADD1] = 0, the counter is updated by the total
+				       bytes in the transfer.
+				       When CA = 0, the hardware does not update any counters.
+				       For an INBOUND or INTERNAL-ONLY PCI DMA transfer, CA must never be
+				       set, and the hardware never adds to the counters. */
+		uint64_t fi:1;	    /**< FI ­ Force interrupt.
+				       When FI is set for an OUTBOUND or EXTERNAL-ONLY transfer, the hardware
+				       sets a forced interrupt bit after it completes the PCI DMA Instruction. If C = 0,
+				       NPEI_INT_SUMn[DMA0_FI] is set, else NPEI_INT_SUMn[DMA1_FI] is set. For
+				       an INBOUND or INTERNAL-ONLY PCI DMA operation, FI must never be set,
+				       and the hardware never generates interrupts. */
+		uint64_t ii:1;	    /**< II­ Ignore the I bit (i.e. the I bit of the PCI DMA instruction local pointer).
+				       For OUTBOUND transfers when II = 1, ignore the I bit and the FL bit in the
+				       DMA HDR alone determines whether the hardware frees any/all of the local
+				       buffers in the FIRST POINTERS area:
+				       - when FL = 1, the hardware frees the local buffer when II=1.
+				       - when FL = 0, the hardware does not free the local buffer when II=1.
+				       For OUTBOUND transfers when II = 0, the I bit in the local pointer selects
+				       whether local buffers are freed on a pointer-by-pointer basis:
+				       - when (FL  I) is true, the hardware frees the local buffer when II=0.
+				       For INBOUND, INTERNAL-ONLY, and EXTERNAL-ONLY PCI DMA transfers,
+				       II must never be set, and local buffers are never freed. */
+		uint64_t fl:1;	    /**< FL ­ Free local buffer.
+				       When FL = 1, for an OUTBOUND operation, it indicates that the local buffers in
+				       the FIRST BUFFERS area should be freed.
+				       If II = 1, the FL bit alone indicates whether the local buffer should be freed:
+				       - when FL = 1, the hardware frees the local buffer when II=1.
+				       - when FL = 0, the hardware does not free the local buffer when II=1.
+				       If II = 0, the I bit in the local pointer (refer to Section 9.5.2) determines whether
+				       the local buffer is freed:
+				       - when (FL  I) is true, the hardware frees the local buffer when II=0.
+				       For an INBOUND, INTERNAL-ONLY, or EXTERNAL-ONLY PCI DMA transfer,
+				       FL must never be set, and local buffers are never freed. */
+		uint64_t nlst:4;    /**< NLST ­ Number Last pointers.
+				       The number of pointers in the LAST POINTERS area.
+				       In the INBOUND, OUTBOUND, and EXTERNAL-ONLY cases, the LAST
+				       POINTERS area contains PCI components, and the number of 64-bit words
+				       required in the LAST POINTERS area is:
+				       - HDR.NLST + ((HDR.NLST + 3)/4) where the division removes the fraction.
+				       In the INTERNAL-ONLY case, the LAST POINTERS area contains local
+				       pointers, and the number of 64-bit words required in the LAST POINTERS area is:
+				       - HDR.NLST
+				       Note that the sum of the number of 64-bit words in the LAST POINTERS and
+				       FIRST POINTERS area must never exceed 31. */
+		uint64_t nfst:4;    /**< NFST ­ Number First pointers.
+				       The number of pointers in the FIRST POINTERS area.
+				       In the INBOUND, OUTBOUND, and INTERNAL-ONLY cases, the FIRST
+				       POINTERS area contains local pointers, and the number of 64-bit words required
+				       in the FIRST POINTERS area is:
+				       - HDR.NFST
+				       In the EXTERNAL-ONLY case, the FIRST POINTERS area contains PCI
+				       components, and the number of 64-bit words required in the FIRST POINTERS
+				       area is:
+				       - HDR.NFST + ((HDR.NFST + 3)/4) where the division removes the fraction. */
+		uint64_t addr:40;   /**< PTR ­ Pointer, either a work-queue-entry pointer (when WQP = 1) or a local
+				       memory pointer (WQP = 0).
+				       When WQP = 1 and PTR  0x0, the hardware inserts the work-queue entry
+				       indicated by PTR into a POW input queue after the PCI DMA operation is
+				       complete. (Section 5.4 describes the work queue entry requirements in this
+				       case.) When WQP = 1, PTR<2:0> must be 0x0.
+				       When WQP = 0 and PTR  0x0, the hardware writes the single byte in local
+				       memory indicated by PTR to 0x0 after the PCI DMA operation is complete.
+				       NPEI_DMA_CONTROL[B0_LEND] selects the endian-ness of PTR in this
+				       case.
+				       When PTR = 0x0, the hardware performs no operation after the PCI DMA
+				       operation is complete. */
+	} s;
+} cvmx_dma_engine_header_t;
+
+typedef union {
+	uint64_t u64;
+	struct {
+		uint64_t i:1;	    /**< I ­ Invert free.
+				       This bit gives the software the ability to free buffers independently for an
+				       OUTBOUND PCI DMA transfer. I is not used by the hardware when II is set. I
+				       must not be set, and buffers are never freed, for INBOUND, INTERNAL-ONLY,
+				       and EXTERNAL-ONLY PCI DMA transfers. */
+		uint64_t back:4;    /**< Back ­ Backup amount.
+				       Allows the start of a buffer that is to be freed during an OUTBOUND transfer to
+				       be different from the ptr value. Back specifies the amount to subtract from the
+				       pointer to reach the start when freeing a buffer.
+				       The address that is the start of the buffer being freed is:
+				       - Buffer start address = ((ptr >> 7) - Back) << 7.
+				       Back is only used by the hardware when the buffer corresponding to ptr is freed.
+				       Back must be 0x0, and buffers are never freed, for INBOUND, INTERNAL-ONLY,
+				       and EXTERNAL-ONLY PCI DMA transfers. */
+		uint64_t pool:3;    /**< Pool ­ Free pool.
+				       Specifies which pool (of the eight hardware-managed FPA free pools) receives the
+				       buffer associated with ptr when freed during an OUTBOUND transfer.
+				       Pool is only used when the buffer corresponding to ptr is freed. Pool must be 0x0,
+				       and buffers are never freed, for INBOUND, INTERNAL-ONLY, and EXTERNAL-ONLY
+				       PCI DMA transfers. */
+		uint64_t f:1;	    /**< F ­ Full-block writes are allowed.
+				       When set, the hardware is permitted to write all the bytes in the cache blocks
+				       covered by ptr, ptr + Size - 1. This can improve memory system performance
+				       when the write misses in the L2 cache.
+				       F can only be set for local pointers that can be written to:
+				       - The local pointers in the FIRST POINTERS area that are write pointers for
+				       INBOUND transfers.
+				       - The local pointers in the LAST POINTERS area that are always write
+				       pointers (when present for INTERNAL-ONLY transfers).
+				       F must not be set for local pointers that are not written to:
+				       - The local pointers in the FIRST POINTERS area for OUTBOUND and
+				       INTERNAL-ONLY transfers. */
+		uint64_t a:1;	    /**< A ­ Allocate L2.
+				       This is a hint to the hardware that the cache blocks should be allocated in the L2
+				       cache (if they were not already). */
+		uint64_t l:1;	    /**< L ­ Little-endian.
+				       When L is set, the data at ptr is in little-endian format rather than big-endian. */
+		uint64_t size:13;   /**< Size ­ Size in bytes of the contiguous space specified by ptr. A Size value of 0 is
+				       illegal. Note that the sum of the sizes in the FIRST POINTERS area must always
+				       exactly equal the sum of the sizes/lengths in the LAST POINTERS area:
+				       - In the OUTBOUND and INBOUND cases, the HDR.NFST size fields in the
+				       local pointers in the FIRST POINTERS area must exactly equal the lengths
+				       of the HDR.NLST fragments in the PCI components in the LAST POINTERS
+				       area.
+				       - In the INTERNAL-ONLY case, the HDR.NFST size fields in the local
+				       pointers in the FIRST POINTERS area must equal the HDR.NLST size
+				       fields in the local pointers in the LAST POINTERS area. */
+		uint64_t reserved_36_39:4;
+		/**< Must be zero */
+		uint64_t addr:36;   /**< L2/DRAM byte pointer. Points to where the packet data starts.
+				       Ptr can be any byte alignment. Note that ptr is interpreted as a big-endian byte
+				       pointer when L is clear, a little-endian byte pointer when L is set. */
+	} internal;
+	struct {
+		uint64_t len0:16;   /**< Length of PCI / PCIe memory for address 0 */
+		uint64_t len1:16;   /**< Length of PCI / PCIe memory for address 1 */
+		uint64_t len2:16;   /**< Length of PCI / PCIe memory for address 2 */
+		uint64_t len3:16;   /**< Length of PCI / PCIe memory for address 3 */
+	} pcie_length;
+} cvmx_dma_engine_buffer_t;
+
+/**
+ * Initialize the DMA engines for use
+ *
+ * Returns Zero on success, negative on failure
+ */
+int cvmx_dma_engine_initialize(void);
+
+/**
+ * Shutdown all DMA engines. The engeines must be idle when this
+ * function is called.
+ *
+ * Returns Zero on success, negative on failure
+ */
+int cvmx_dma_engine_shutdown(void);
+
+/**
+ * Return the number of DMA engimes supported by this chip
+ *
+ * Returns Number of DMA engines
+ */
+int cvmx_dma_engine_get_num(void);
+
+/**
+ * Submit a series of DMA command to the DMA engines.
+ *
+ * @engine:  Engine to submit to (0 to cvmx_dma_engine_get_num()-1)
+ * @header:  Command header
+ * @num_buffers:
+ *                The number of data pointers
+ * @buffers: Command data pointers
+ *
+ * Returns Zero on success, negative on failure
+ */
+int cvmx_dma_engine_submit(int engine, cvmx_dma_engine_header_t header, int num_buffers, cvmx_dma_engine_buffer_t buffers[]);
+
+/**
+ * Build the first and last pointers based on a DMA engine header
+ * and submit them to the engine. The purpose of this function is
+ * to simplify the building of DMA engine commands by automatically
+ * converting a simple address and size into the apropriate internal
+ * or PCI / PCIe address list. This function does not support gather lists,
+ * so you will need to build your own lists in that case.
+ *
+ * @engine: Engine to submit to (0 to cvmx_dma_engine_get_num()-1)
+ * @header: DMA Command header. Note that the nfst and nlst fields do not
+ *               need to be filled in. All other fields must be set properly.
+ * @first_address:
+ *               Address to use for the first pointers. In the case of INTERNAL,
+ *               INBOUND, and OUTBOUND this is an Octeon memory address. In the
+ *               case of EXTERNAL, this is the source PCI / PCIe address.
+ * @last_address:
+ *               Address to use for the last pointers. In the case of EXTERNAL,
+ *               INBOUND, and OUTBOUND this is a PCI / PCIe address. In the
+ *               case of INTERNAL, this is the Octeon memory destination address.
+ * @size:   Size of the transfer to perform.
+ *
+ * Returns Zero on success, negative on failure
+ */
+int cvmx_dma_engine_transfer(int engine, cvmx_dma_engine_header_t header, uint64_t first_address, uint64_t last_address, int size);
+
+/**
+ * Simplified interface to the DMA engines to emulate memcpy()
+ *
+ * @engine: Engine to submit to (0 to cvmx_dma_engine_get_num()-1)
+ * @dest:   Pointer to the destination memory. cvmx_ptr_to_phys() will be
+ *               used to turn this into a physical address. It cannot be a local
+ *               or CVMX_SHARED block.
+ * @source: Pointer to the source memory.
+ *               cvmx_ptr_to_phys() will be used to turn this
+ *               into a physical address. It cannot be a local
+ *               or CVMX_SHARED block.
+ * @length: Number of bytes to copy
+ *
+ * Returns Zero on success, negative on failure
+ */
+static inline int cvmx_dma_engine_memcpy(int engine, void *dest, void *source, int length) {
+	cvmx_dma_engine_header_t header;
+	header.u64 = 0;
+	header.s.type = CVMX_DMA_ENGINE_TRANSFER_INTERNAL;
+	return cvmx_dma_engine_transfer(engine, header, cvmx_ptr_to_phys(source), cvmx_ptr_to_phys(dest), length);
+}
+
+#if 0
+/**
+ * Simplified interface to the DMA engines to emulate memcpy()
+ * When dici_mode is enabled, send zero byte.
+ *
+ * @engine: Engine to submit to (0 to cvmx_dma_engine_get_num()-1)
+ * @dest:   Pointer to the destination memory. cvmx_ptr_to_phys() will be
+ *               used to turn this into a physical address. It cannot be a local
+ *               or CVMX_SHARED block.
+ * @source: Pointer to the source memory.
+ *               cvmx_ptr_to_phys() will be used to turn this
+ *               into a physical address. It cannot be a local
+ *               or CVMX_SHARED block.
+ * @length: Number of bytes to copy
+ * @core:   core number for zero byte write
+ *
+ * Returns Zero on success, negative on failure
+ */
+static inline int cvmx_dma_engine_memcpy_zero_byte(int engine, void *dest, void *source, int length, int core) {
+	cvmx_dma_engine_header_t header;
+	header.u64 = 0;
+	header.s.type = CVMX_DMA_ENGINE_TRANSFER_INTERNAL;
+	/* If dici_mode is set, DPI increments the DPI_DMA_PPn_CNT[CNT], where the
+	   value of core n is PTR<5:0>-1 when WQP=0 and PTR != 0 && PTR < 64. */
+	if (octeon_has_feature(OCTEON_FEATURE_DICI_MODE)) {
+		cvmx_dpi_dma_control_t dma_control;
+		dma_control.u64 = cvmx_read_csr(CVMX_DPI_DMA_CONTROL);
+		if (dma_control.s.dici_mode) {
+			header.s.wqp = 0;	// local memory pointer
+			header.s.addr = core + 1;
+		}
+	}
+	return cvmx_dma_engine_transfer(engine, header, cvmx_ptr_to_phys(source), cvmx_ptr_to_phys(dest), length);
+}
+#endif
+
+#endif /* __CVMX_CMD_QUEUE_H__ */
-- 
1.7.5.4

