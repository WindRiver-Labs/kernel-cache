From 9c40c5330bee50b8ab4c0a00f377312d80471391 Mon Sep 17 00:00:00 2001
From: Yang Wei <Wei.Yang@windriver.com>
Date: Mon, 4 Aug 2014 14:16:22 +0800
Subject: [PATCH 16/20] mmc:octeon-mmc:Backport mmc features from SDK3.1.0-P3

Source: Cavium SDK 3.1.0-P3

It includes:
1) Scatter-Gather DMA fix in the eMMC driver
2) (N-1) eMMC block fix
3) eMMC driver DDR support

Signed-off-by: Yang Wei <Wei.Yang@windriver.com>
---
 drivers/mmc/host/octeon_mmc.c |  645 ++++++++++++++++++++++++++---------------
 1 files changed, 410 insertions(+), 235 deletions(-)

diff --git a/drivers/mmc/host/octeon_mmc.c b/drivers/mmc/host/octeon_mmc.c
index 200321c..26aaa00 100644
--- a/drivers/mmc/host/octeon_mmc.c
+++ b/drivers/mmc/host/octeon_mmc.c
@@ -37,8 +37,7 @@
 #define OCTEON_MAX_MMC			4
 
 #define OCT_MIO_NDF_DMA_CFG		0x00
-#define OCT_MIO_NDF_DMA_INT		0x08
-#define OCT_MIO_NDF_DMA_INT_EN		0x10
+#define OCT_MIO_EMM_DMA_ADR		0x08
 
 #define OCT_MIO_EMM_CFG			0x00
 #define OCT_MIO_EMM_SWITCH		0x48
@@ -57,13 +56,16 @@
 #define OCT_MIO_EMM_BUF_DAT		0xe8
 
 struct octeon_mmc_host {
-	spinlock_t		lock;
 	u64	base;
 	u64	ndf_base;
 	u64	emm_cfg;
+	u64	n_minus_one;  /* OCTEON II workaround location */
 	int	last_slot;
 
+	struct semaphore mmc_serializer;
 	struct mmc_request	*current_req;
+	unsigned int		linear_buf_size;
+	void			*linear_buf;
 	struct sg_mapping_iter smi;
 	int sg_idx;
 	bool dma_active;
@@ -72,13 +74,17 @@ struct octeon_mmc_host {
 	int global_pwr_gpio;
 	bool global_pwr_gpio_low;
 	bool dma_err_pending;
+	bool need_bootbus_lock;
+	bool big_dma_addr;
+	bool need_irq_handler_lock;
+	spinlock_t irq_handler_lock;
 
 	struct octeon_mmc_slot	*slot[OCTEON_MAX_MMC];
 };
 
 struct octeon_mmc_slot {
-	struct mmc_host         *mmc;
-	struct octeon_mmc_host	*host;
+	struct mmc_host         *mmc;	/* slot-level mmc_core object */
+	struct octeon_mmc_host	*host;	/* common hw for all 4 slots */
 
 	unsigned int		clock;
 	unsigned int		sclock;
@@ -99,28 +105,42 @@ struct octeon_mmc_slot {
 	bool			pwr_gpio_low;
 };
 
-static int limit_max_blk = -1;
-module_param(limit_max_blk, int, S_IRUGO);
+static int bb_size = 1 << 18;
+module_param(bb_size, int, S_IRUGO);
 MODULE_PARM_DESC(limit_max_blk,
-		 "Set an upper limit on the number of blocks in a single transfer.");
-
-static int force_no_multi;
-module_param(force_no_multi, int, S_IRUGO);
-MODULE_PARM_DESC(force_no_multi,
-		 "Force the interface to emulate multi-block transfers as a series of single block transfres.");
+		 "Size of DMA linearizing buffer (max transfer size).");
+ 
+static int ddr = 2;
+module_param(ddr, int, S_IRUGO);
+MODULE_PARM_DESC(ddr,
+		 "enable DoubleDataRate clocking:"
+		 " 0=no, 1=always, 2=at spi-max-frequency/2");
+
+#if 0
+#define octeon_mmc_dbg trace_printk
+#else
+static inline void octeon_mmc_dbg(const char *s, ...) { }
+#endif
 
 
-static void octeon_mmc_acquire_bus(void)
+static void octeon_mmc_acquire_bus(struct octeon_mmc_host *host)
 {
-	down(&octeon_bootbus_sem);
-	/* On cn70XX switch the mmc unit onto the bus. */
-	if (OCTEON_IS_MODEL(OCTEON_CN70XX))
-		cvmx_write_csr(CVMX_MIO_BOOT_CTL, 0);
+	if (host->need_bootbus_lock) {
+		down(&octeon_bootbus_sem);
+		/* On cn70XX switch the mmc unit onto the bus. */
+		if (OCTEON_IS_MODEL(OCTEON_CN70XX))
+			cvmx_write_csr(CVMX_MIO_BOOT_CTL, 0);
+	} else {
+		down(&host->mmc_serializer);
+	}
 }
 
-static void octeon_mmc_release_bus(void)
+static void octeon_mmc_release_bus(struct octeon_mmc_host *host)
 {
-	up(&octeon_bootbus_sem);
+	if (host->need_bootbus_lock)
+		up(&octeon_bootbus_sem);
+	else
+		up(&host->mmc_serializer);
 }
 
 struct octeon_mmc_cr_type {
@@ -211,6 +231,81 @@ struct octeon_mmc_cr_mods {
 	u8 rtype_xor;
 };
 
+static inline void *phys_to_ptr(u64 address)
+{
+	return (void *)(address | (1ull<<63)); /* XKPHYS */
+}
+
+/**
+ * Lock a single line into L2. The line is zeroed before locking
+ * to make sure no dram accesses are made.
+ *
+ * @addr   Physical address to lock
+ */
+static void l2c_lock_line(u64 addr)
+{
+	char *addr_ptr = phys_to_ptr(addr);
+	asm volatile (
+		"cache 31, %[line]"	/* Unlock the line */
+		:: [line] "m" (*addr_ptr));
+}
+
+/**
+ * Locks a memory region in the L2 cache
+ *
+ * @start - start address to begin locking
+ * @len - length in bytes to lock
+ */
+static void l2c_lock_mem_region(u64 start, u64 len)
+{
+	u64 end;
+
+	/* Round start/end to cache line boundaries */
+	end = ALIGN(start + len - 1, CVMX_CACHE_LINE_SIZE);
+	start = ALIGN(start, CVMX_CACHE_LINE_SIZE);
+
+	while (start <= end) {
+		l2c_lock_line(start);
+		start += CVMX_CACHE_LINE_SIZE;
+	}
+	asm volatile("sync");
+}
+
+/**
+ * Unlock a single line in the L2 cache.
+ *
+ * @addr	Physical address to unlock
+ *
+ * Return Zero on success
+ */
+static void l2c_unlock_line(u64 addr)
+{
+	char *addr_ptr = phys_to_ptr(addr);
+	asm volatile (
+		"cache 23, %[line]"	/* Unlock the line */
+		:: [line] "m" (*addr_ptr));
+}
+
+/**
+ * Unlock a memory region in the L2 cache
+ *
+ * @start - start address to unlock
+ * @len - length to unlock in bytes
+ */
+static void l2c_unlock_mem_region(u64 start, u64 len)
+{
+	u64 end;
+
+	/* Round start/end to cache line boundaries */
+	end = ALIGN(start + len - 1, CVMX_CACHE_LINE_SIZE);
+	start = ALIGN(start, CVMX_CACHE_LINE_SIZE);
+
+	while (start <= end) {
+		l2c_unlock_line(start);
+		start += CVMX_CACHE_LINE_SIZE;
+	}
+}
+
 static struct octeon_mmc_cr_mods octeon_mmc_get_cr_mods(struct mmc_command *cmd)
 {
 	struct octeon_mmc_cr_type *cr;
@@ -271,29 +366,6 @@ static unsigned int octeon_mmc_timeout_to_wdog(struct octeon_mmc_slot *slot,
 	return (unsigned int)(bt / 1000000000);
 }
 
-static void octeon_mmc_dma_next(struct octeon_mmc_host	*host)
-{
-	struct scatterlist *sg;
-	struct mmc_data *data;
-	union cvmx_mio_ndf_dma_cfg dma_cfg;
-
-	data = host->current_req->data;
-	sg = data->sg + host->sg_idx;
-
-	dma_cfg.u64 = 0;
-	dma_cfg.s.en = 1;
-	dma_cfg.s.rw = (data->flags & MMC_DATA_WRITE) ? 1 : 0;
-#ifdef __LITTLE_ENDIAN
-	dma_cfg.s.endian = 1;
-#endif
-	dma_cfg.s.size = (sg->length / 8) - 1;
-	dma_cfg.s.adr = sg_phys(sg);
-
-	host->sg_idx++;
-
-	cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_CFG, dma_cfg.u64);
-}
-
 static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 {
 	struct octeon_mmc_host *host = dev_id;
@@ -301,64 +373,72 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 	struct mmc_request	*req;
 	bool host_done;
 	union cvmx_mio_emm_rsp_sts rsp_sts;
-	unsigned long flags;
+	unsigned long flags = 0;
 
-	spin_lock_irqsave(&host->lock, flags);
+	if (host->need_irq_handler_lock)
+		spin_lock_irqsave(&host->irq_handler_lock, flags);
 	emm_int.u64 = cvmx_read_csr(host->base + OCT_MIO_EMM_INT);
 	req = host->current_req;
 	cvmx_write_csr(host->base + OCT_MIO_EMM_INT, emm_int.u64);
 
-	pr_debug("Got interrupt: EMM_INT = 0x%llx\n", emm_int.u64);
+	octeon_mmc_dbg("Got interrupt: EMM_INT = 0x%llx\n", emm_int.u64);
 
-	if (!req) {
-		spin_unlock_irqrestore(&host->lock, flags);
+	if (!req)
 		goto out;
-	}
 
 	rsp_sts.u64 = cvmx_read_csr(host->base + OCT_MIO_EMM_RSP_STS);
-	pr_debug("octeon_mmc_interrupt  MIO_EMM_RSP_STS 0x%llx\n", rsp_sts.u64);
+	octeon_mmc_dbg("octeon_mmc_interrupt  MIO_EMM_RSP_STS 0x%llx\n", rsp_sts.u64);
 
 	if (host->dma_err_pending) {
 		host->current_req = NULL;
+		host->dma_err_pending = false;
 		req->done(req);
 		host_done = true;
 		goto no_req_done;
 	}
 
-	if (!host->dma_active && emm_int.s.buf_done && req->cmd->data &&
-	    ((rsp_sts.u64 >> 7) & 3) == 1) {
-		/* Read */
-		int dbuf = rsp_sts.s.dbuf;
-		struct sg_mapping_iter *smi = &host->smi;
-		unsigned int bytes_xfered = 0;
-		u64 dat = 0;
-		int shift = -1;
-
-		/* Auto inc from offset zero */
-		cvmx_write_csr(host->base + OCT_MIO_EMM_BUF_IDX, (u64)(0x10000 | (dbuf << 6)));
-
-		for (;;) {
-			if (smi->consumed >= smi->length) {
-				if (!sg_miter_next(smi))
-					break;
-				smi->consumed = 0;
-			}
-			if (shift < 0) {
-				dat = cvmx_read_csr(host->base + OCT_MIO_EMM_BUF_DAT);
-				shift = 56;
-			}
 
-			while (smi->consumed < smi->length && shift >= 0) {
-				*(u8 *)(smi->addr) = (dat >> shift) & 0xff;
-				bytes_xfered++;
-				smi->addr++;
-				smi->consumed++;
-				shift -= 8;
+	if (!host->dma_active && emm_int.s.buf_done && req->data) {
+		unsigned int type = (rsp_sts.u64 >> 7) & 3;
+		if (type == 1) {
+			/* Read */
+			int dbuf = rsp_sts.s.dbuf;
+			struct sg_mapping_iter *smi = &host->smi;
+			unsigned int data_len = req->data->blksz * req->data->blocks;
+			unsigned int bytes_xfered;
+			u64 dat = 0;
+			int shift = -1;
+
+			/* Auto inc from offset zero */
+			cvmx_write_csr(host->base + OCT_MIO_EMM_BUF_IDX, (u64)(0x10000 | (dbuf << 6)));
+
+ 			for (bytes_xfered = 0; bytes_xfered < data_len;) {
+				if (smi->consumed >= smi->length) {
+					if (!sg_miter_next(smi))
+						break;
+					smi->consumed = 0;
+				}
+				if (shift < 0) {
+					dat = cvmx_read_csr(host->base + OCT_MIO_EMM_BUF_DAT);
+					shift = 56;
+				}
+
+				while (smi->consumed < smi->length && shift >= 0) {
+					((u8 *)(smi->addr))[smi->consumed] = (dat >> shift) & 0xff;
+					bytes_xfered++;
+					smi->consumed++;
+					shift -= 8;
+				}
 			}
+			sg_miter_stop(smi);
+			req->data->bytes_xfered = bytes_xfered;
+			req->data->error = 0;
+		} else if (type == 2) {
+			/* write */
+			req->data->bytes_xfered = req->data->blksz * req->data->blocks;
+			req->data->error = 0;
+
 		}
-		sg_miter_stop(smi);
-		req->cmd->data->bytes_xfered = bytes_xfered;
-		req->cmd->data->error = 0;
 	}
 	host_done = emm_int.s.cmd_done || emm_int.s.dma_done ||
 		emm_int.s.cmd_err || emm_int.s.dma_err;
@@ -374,9 +454,14 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 			req->cmd->error = 0;
 		}
 
-		if (host->dma_active && req->cmd->data) {
-			req->cmd->data->error = 0;
-			req->cmd->data->bytes_xfered = req->cmd->data->blocks * req->cmd->data->blksz;
+		if (host->dma_active && req->data) {
+			req->data->error = 0;
+			req->data->bytes_xfered = req->data->blocks * req->data->blksz;
+			if (!(req->data->flags & MMC_DATA_WRITE) && req->data->sg_len > 1) {
+				size_t r = sg_copy_from_buffer(req->data->sg, req->data->sg_len,
+						   host->linear_buf, req->data->bytes_xfered);
+				WARN_ON(r != req->data->bytes_xfered);
+			}
 		}
 		if (rsp_sts.s.rsp_val) {
 			u64 rsp_hi;
@@ -398,17 +483,16 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 				req->cmd->resp[0] = (rsp_hi >> 32) & 0xffffffff;
 				break;
 			default:
-				pr_debug("octeon_mmc_interrupt unhandled rsp_val %d\n",
-					 rsp_sts.s.rsp_type);
+				octeon_mmc_dbg("octeon_mmc_interrupt unhandled rsp_val %d\n",
+					       rsp_sts.s.rsp_type);
 				break;
 			}
-			pr_debug("octeon_mmc_interrupt  resp %08x %08x %08x %08x\n",
-				 req->cmd->resp[0], req->cmd->resp[1],
-				 req->cmd->resp[2], req->cmd->resp[3]);
+			octeon_mmc_dbg("octeon_mmc_interrupt  resp %08x %08x %08x %08x\n",
+				       req->cmd->resp[0], req->cmd->resp[1],
+				       req->cmd->resp[2], req->cmd->resp[3]);
 		}
 		if (emm_int.s.dma_err && rsp_sts.s.dma_pend) {
 			/* Try to clean up failed DMA */
-			union cvmx_mio_ndf_dma_cfg dma_cfg;
 			union cvmx_mio_emm_dma emm_dma;
 			emm_dma.u64 = cvmx_read_csr(host->base + OCT_MIO_EMM_DMA);
 			emm_dma.s.dma_val = 1;
@@ -416,10 +500,6 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 			emm_dma.s.bus_id = rsp_sts.s.bus_id;
 			cvmx_write_csr(host->base + OCT_MIO_EMM_DMA,
 				       emm_dma.u64);
-			dma_cfg.u64 = 0;
-			dma_cfg.s.en = 1;
-			dma_cfg.s.clr = 1;
-			cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_CFG, dma_cfg.u64);
 			host->dma_err_pending = true;
 			host_done = false;
 			goto no_req_done;
@@ -429,10 +509,15 @@ static irqreturn_t octeon_mmc_interrupt(int irq, void *dev_id)
 		req->done(req);
 	}
 no_req_done:
-	spin_unlock_irqrestore(&host->lock, flags);
+	if (host->n_minus_one) {
+		l2c_unlock_mem_region(host->n_minus_one, 512);
+		host->n_minus_one = 0;
+	}
 	if (host_done)
-		octeon_mmc_release_bus();
+		octeon_mmc_release_bus(host);
 out:
+	if (host->need_irq_handler_lock)
+		spin_unlock_irqrestore(&host->irq_handler_lock, flags);
 	return IRQ_RETVAL(emm_int.u64 != 0);
 }
 
@@ -443,13 +528,14 @@ static void octeon_mmc_switch_to(struct octeon_mmc_slot	*slot)
 	union cvmx_mio_emm_switch sw;
 	union cvmx_mio_emm_sample samp;
 
-	if (host->last_slot < 0 || slot->bus_id == host->last_slot)
+	if (slot->bus_id == host->last_slot)
 		goto out;
 
-	old_slot = host->slot[host->last_slot];
-	old_slot->cached_switch = cvmx_read_csr(host->base + OCT_MIO_EMM_SWITCH);
-	old_slot->cached_rca = cvmx_read_csr(host->base + OCT_MIO_EMM_RCA);
-
+	if (host->last_slot >= 0) {
+		old_slot = host->slot[host->last_slot];
+		old_slot->cached_switch = cvmx_read_csr(host->base + OCT_MIO_EMM_SWITCH);
+		old_slot->cached_rca = cvmx_read_csr(host->base + OCT_MIO_EMM_RCA);
+	}
 	cvmx_write_csr(host->base + OCT_MIO_EMM_RCA, slot->cached_rca);
 	sw.u64 = slot->cached_switch;
 	sw.s.bus_id = 0;
@@ -459,7 +545,7 @@ static void octeon_mmc_switch_to(struct octeon_mmc_slot	*slot)
 
 	samp.u64 = 0;
 	samp.s.cmd_cnt = slot->cmd_cnt;
-	samp.s.cmd_cnt = slot->cmd_cnt;
+	samp.s.dat_cnt = slot->dat_cnt;
 	cvmx_write_csr(host->base + OCT_MIO_EMM_SAMPLE, samp.u64);
 out:
 	host->last_slot = slot->bus_id;
@@ -474,7 +560,7 @@ static void octeon_mmc_dma_request(struct mmc_host *mmc,
 	struct mmc_data *data;
 	union cvmx_mio_emm_int emm_int;
 	union cvmx_mio_emm_dma emm_dma;
-	unsigned long flags;
+	union cvmx_mio_ndf_dma_cfg dma_cfg;
 
 	cmd = mrq->cmd;
 	if (mrq->data == NULL || mrq->data->sg == NULL || !mrq->data->sg_len ||
@@ -491,7 +577,7 @@ static void octeon_mmc_dma_request(struct mmc_host *mmc,
 	host = slot->host;
 
 	/* Only a single user of the bootbus at a time. */
-	octeon_mmc_acquire_bus();
+	octeon_mmc_acquire_bus(host);
 
 	octeon_mmc_switch_to(slot);
 
@@ -500,28 +586,55 @@ static void octeon_mmc_dma_request(struct mmc_host *mmc,
 	if (data->timeout_ns) {
 		cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 			       octeon_mmc_timeout_to_wdog(slot, data->timeout_ns));
-		pr_debug("OCT_MIO_EMM_WDOG %llu\n",
-			 cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
+		octeon_mmc_dbg("OCT_MIO_EMM_WDOG %llu\n",
+			       cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
 	}
 
-	spin_lock_irqsave(&host->lock, flags);
 	WARN_ON(host->current_req);
 	host->current_req = mrq;
 
 	host->sg_idx = 0;
 
-	/* Clear any pending irqs */
-	cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_INT, 1);
+	WARN_ON(data->blksz * data->blocks > host->linear_buf_size);
+
+	if ((data->flags & MMC_DATA_WRITE) && data->sg_len > 1) {
+		size_t r = sg_copy_to_buffer(data->sg, data->sg_len,
+			 host->linear_buf, data->blksz * data->blocks);
+		WARN_ON(data->blksz * data->blocks != r);
+	}
+
+	dma_cfg.u64 = 0;
+	dma_cfg.s.en = 1;
+	dma_cfg.s.rw = (data->flags & MMC_DATA_WRITE) ? 1 : 0;
+#ifdef __LITTLE_ENDIAN
+	dma_cfg.s.endian = 1;
+#endif
+	dma_cfg.s.size = ((data->blksz * data->blocks) / 8) - 1;
+	if (!host->big_dma_addr) {
+		if (data->sg_len > 1)
+			dma_cfg.s.adr = virt_to_phys(host->linear_buf);
+		else
+			dma_cfg.s.adr = sg_phys(data->sg);
+	}
+	cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_CFG, dma_cfg.u64);
+	octeon_mmc_dbg("MIO_NDF_DMA_CFG: %016llx\n", (unsigned long long)dma_cfg.u64);
+	if (host->big_dma_addr) {
+		u64 addr;
+		if (data->sg_len > 1)
+			addr = virt_to_phys(host->linear_buf);
+		else
+			addr = sg_phys(data->sg);
+		cvmx_write_csr(host->ndf_base + OCT_MIO_EMM_DMA_ADR, addr);
+		octeon_mmc_dbg("MIO_EMM_DMA_ADR: %016llx\n", (unsigned long long)addr);
+	}
 
-	octeon_mmc_dma_next(host);
 	emm_dma.u64 = 0;
 	emm_dma.s.bus_id = slot->bus_id;
 	emm_dma.s.dma_val = 1;
 	emm_dma.s.sector = mmc_card_blockaddr(mmc->card) ? 1 : 0;
 	emm_dma.s.rw = (data->flags & MMC_DATA_WRITE) ? 1 : 0;
-	if (!force_no_multi &&
-	    (mmc_card_mmc(mmc->card) ||	(mmc_card_sd(mmc->card) &&
-					 (mmc->card->scr.cmds & SD_SCR_CMD23_SUPPORT))))
+	if (mmc_card_mmc(mmc->card) ||
+	    (mmc_card_sd(mmc->card) && (mmc->card->scr.cmds & SD_SCR_CMD23_SUPPORT)))
 		emm_dma.s.multi = 1;
 	emm_dma.s.block_cnt = data->blocks;
 	emm_dma.s.card_addr = cmd->arg;
@@ -535,12 +648,19 @@ static void octeon_mmc_dma_request(struct mmc_host *mmc,
 	cvmx_write_csr(host->base + OCT_MIO_EMM_INT_EN, emm_int.u64);
 	host->dma_active = true;
 
-	spin_unlock_irqrestore(&host->lock, flags);
+	if ((OCTEON_IS_MODEL(OCTEON_CN6XXX) || OCTEON_IS_MODEL(OCTEON_CNF7XXX)) &&
+	    cmd->opcode == MMC_WRITE_MULTIPLE_BLOCK &&
+	    (data->blksz * data->blocks) > 1024) {
+		host->n_minus_one = dma_cfg.s.adr + (data->blksz * data->blocks) - 1024;
+		l2c_lock_mem_region(host->n_minus_one, 512);
+	}
 
-	cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0xe4f90080ull);
-	cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0);
+	if (mmc->card && mmc_card_sd(mmc->card))
+		cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0x00b00000ull);
+	else
+		cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0xe4f90080ull);
 	cvmx_write_csr(host->base + OCT_MIO_EMM_DMA, emm_dma.u64);
-	pr_debug("Send the dma command: %llx\n", emm_dma.u64);
+	octeon_mmc_dbg("MIO_EMM_DMA: %llx\n", emm_dma.u64);
 }
 
 static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
@@ -551,7 +671,6 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	union cvmx_mio_emm_int emm_int;
 	union cvmx_mio_emm_cmd emm_cmd;
 	struct octeon_mmc_cr_mods mods;
-	unsigned long flags;
 
 	cmd = mrq->cmd;
 
@@ -566,11 +685,10 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	host = slot->host;
 
 	/* Only a single user of the bootbus at a time. */
-	octeon_mmc_acquire_bus();
+	octeon_mmc_acquire_bus(host);
 
 	octeon_mmc_switch_to(slot);
 
-	spin_lock_irqsave(&host->lock, flags);
 	WARN_ON(host->current_req);
 	host->current_req = mrq;
 
@@ -578,24 +696,23 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	emm_int.s.cmd_done = 1;
 	emm_int.s.cmd_err = 1;
 	if (cmd->data) {
-		pr_debug("command has data\n");
-		cmd->error = -EINPROGRESS;
+		octeon_mmc_dbg("command has data\n");
 		if (cmd->data->flags & MMC_DATA_READ) {
-			emm_int.s.buf_done = 1;
-			sg_miter_start(&host->smi, mrq->cmd->data->sg,
-				       mrq->cmd->data->sg_len, SG_MITER_ATOMIC | SG_MITER_TO_SG);
-		} else {
+			sg_miter_start(&host->smi, mrq->data->sg,
++				       mrq->data->sg_len, SG_MITER_ATOMIC | SG_MITER_TO_SG);
+	} else {
 			struct sg_mapping_iter *smi = &host->smi;
-			unsigned int bytes_xfered = 0;
+			unsigned int data_len = mrq->data->blksz * mrq->data->blocks;
+			unsigned int bytes_xfered;
 			u64 dat = 0;
 			int shift = 56;
 			/* Copy data to the xmit buffer before issuing the command */
-			sg_miter_start(smi, mrq->cmd->data->sg,
-				       mrq->cmd->data->sg_len, SG_MITER_TO_SG);
+			sg_miter_start(smi, mrq->data->sg,
+				       mrq->data->sg_len, SG_MITER_FROM_SG);
 			/* Auto inc from offset zero, dbuf zero */
 			cvmx_write_csr(host->base + OCT_MIO_EMM_BUF_IDX, 0x10000ull);
 
-			for (;;) {
+			for (bytes_xfered = 0; bytes_xfered < data_len;) {
 				if (smi->consumed >= smi->length) {
 					if (!sg_miter_next(smi))
 						break;
@@ -603,9 +720,8 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 				}
 
 				while (smi->consumed < smi->length && shift >= 0) {
-					dat |= (u64)(*(u8 *)(smi->addr)) << shift;
+					dat |= (u64)(((u8 *)(smi->addr))[smi->consumed]) << shift;
 					bytes_xfered++;
-					smi->addr++;
 					smi->consumed++;
 					shift -= 8;
 				}
@@ -616,26 +732,23 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 				}
 			}
 			sg_miter_stop(smi);
-			cmd->data->bytes_xfered = bytes_xfered;
-			cmd->data->error = 0;
 		}
 		if (cmd->data->timeout_ns) {
 			cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 				       octeon_mmc_timeout_to_wdog(slot, cmd->data->timeout_ns));
-			pr_debug("OCT_MIO_EMM_WDOG %llu\n",
-				 cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
+			octeon_mmc_dbg("OCT_MIO_EMM_WDOG %llu\n",
+				       cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
 		}
 	} else {
 		cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 			       ((u64)slot->clock * 850ull) / 1000ull);
-		pr_debug("OCT_MIO_EMM_WDOG %llu\n",
-			 cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
+		octeon_mmc_dbg("OCT_MIO_EMM_WDOG %llu\n",
+			       cvmx_read_csr(host->base + OCT_MIO_EMM_WDOG));
 	}
 	/* Clear the bit. */
 	cvmx_write_csr(host->base + OCT_MIO_EMM_INT, emm_int.u64);
 	cvmx_write_csr(host->base + OCT_MIO_EMM_INT_EN, emm_int.u64);
 	host->dma_active = false;
-	spin_unlock_irqrestore(&host->lock, flags);
 
 	emm_cmd.u64 = 0;
 	emm_cmd.s.cmd_val = 1;
@@ -648,7 +761,7 @@ static void octeon_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	emm_cmd.s.arg = cmd->arg;
 	cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0);
 	cvmx_write_csr(host->base + OCT_MIO_EMM_CMD, emm_cmd.u64);
-	pr_debug("Send the command: %llx\n", emm_cmd.u64);
+	octeon_mmc_dbg("MIO_EMM_CMD: %llx\n", emm_cmd.u64);
 }
 
 static void octeon_mmc_reset_bus(struct octeon_mmc_slot *slot, int preserve)
@@ -663,15 +776,6 @@ static void octeon_mmc_reset_bus(struct octeon_mmc_slot *slot, int preserve)
 		wdog = cvmx_read_csr(slot->host->base + OCT_MIO_EMM_WDOG);
 	}
 
-	/* Reset the bus */
-	emm_cfg.u64 &= ~0xfull;
-	cvmx_write_csr(slot->host->base + OCT_MIO_EMM_CFG, emm_cfg.u64);
-	msleep(10);  /* Wait 10ms */
-	emm_cfg.u64 |= 1 << slot->bus_id;
-	cvmx_write_csr(slot->host->base + OCT_MIO_EMM_CFG, emm_cfg.u64);
-
-	msleep(10);
-
 	/* Restore switch settings */
 	if (preserve) {
 		emm_switch.s.switch_exe = 0;
@@ -698,6 +802,7 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 	struct octeon_mmc_host	*host;
 	int bus_width;
 	int clock;
+	bool ddr_clock;
 	int hs_timing;
 	int power_class = 10;
 	int clk_period;
@@ -709,17 +814,17 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 	host = slot->host;
 
 	/* Only a single user of the bootbus at a time. */
-	octeon_mmc_acquire_bus();
+	octeon_mmc_acquire_bus(host);
 
 	octeon_mmc_switch_to(slot);
 
-	pr_debug("Calling set_ios: slot: clk = 0x%x, bus_width = %d\n",
-		 slot->clock, slot->bus_width);
-	pr_debug("Calling set_ios: ios: clk = 0x%x, vdd = %u, bus_width = %u, power_mode = %u, timing = %u\n",
-		 ios->clock, ios->vdd, ios->bus_width, ios->power_mode,
-		 ios->timing);
-	pr_debug("Calling set_ios: mmc: caps = 0x%lx, bus_width = %d\n",
-		 mmc->caps, mmc->ios.bus_width);
+	octeon_mmc_dbg("Calling set_ios: slot: clk = 0x%x, bus_width = %d\n",
+		       slot->clock, slot->bus_width);
+	octeon_mmc_dbg("Calling set_ios: ios: clk = 0x%x, vdd = %u, bus_width = %u, power_mode = %u, timing = %u\n",
+		       ios->clock, ios->vdd, ios->bus_width, ios->power_mode,
+		       ios->timing);
+	octeon_mmc_dbg("Calling set_ios: mmc: caps = 0x%x, bus_width = %d\n",
+		       mmc->caps, mmc->ios.bus_width);
 
 	/*
 	 * Reset the chip on each power off
@@ -746,11 +851,17 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		bus_width = 0;
 		break;
 	default:
-		pr_debug("unknown bus width %d\n", ios->bus_width);
+		octeon_mmc_dbg("unknown bus width %d\n", ios->bus_width);
 		bus_width = 0;
 		break;
 	}
+
 	hs_timing = (ios->timing == MMC_TIMING_MMC_HS);
+	ddr_clock = (bus_width && ios->timing >= MMC_TIMING_UHS_DDR50);
+
+	if (ddr_clock)
+		bus_width |= 4;
+
 	if (ios->clock) {
 		slot->clock = ios->clock;
 		slot->bus_width = bus_width;
@@ -758,10 +869,14 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		clock = slot->clock;
 
 		if (clock > 52000000)
-			clock = 50000000;
+			clock = 52000000;
 
 		clk_period = (octeon_get_io_clock_rate() + clock - 1) / (2 * clock);
 
+		/* until clock-renengotiate-on-CRC is in */
+		if (ddr_clock && ddr > 1)
+			clk_period *= 2;
+
 		emm_switch.u64 = 0;
 		emm_switch.s.hs_timing = hs_timing;
 		emm_switch.s.bus_width = bus_width;
@@ -770,16 +885,16 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		emm_switch.s.clk_lo = clk_period;
 
 		if (!octeon_mmc_switch_val_changed(slot, emm_switch.u64)) {
-			pr_debug("No change from 0x%llx mio_emm_switch, returning.\n",
-				 emm_switch.u64);
+			octeon_mmc_dbg("No change from 0x%llx mio_emm_switch, returning.\n",
+				       emm_switch.u64);
 			goto out;
 		}
 
-		pr_debug("Writing 0x%llx to mio_emm_wdog\n",
-			 ((u64)clock * 850ull) / 1000ull);
+		octeon_mmc_dbg("Writing 0x%llx to mio_emm_wdog\n",
+			       ((u64)clock * 850ull) / 1000ull);
 		cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 			       ((u64)clock * 850ull) / 1000ull);
-		pr_debug("Writing 0x%llx to mio_emm_switch\n", emm_switch.u64);
+		octeon_mmc_dbg("Writing 0x%llx to mio_emm_switch\n", emm_switch.u64);
 
 		cvmx_write_csr(host->base + OCT_MIO_EMM_SWITCH, emm_switch.u64);
 		emm_switch.s.bus_id = slot->bus_id;
@@ -794,13 +909,13 @@ static void octeon_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		} while (timeout-- > 0);
 
 		if (timeout <= 0) {
-			pr_debug("%s: switch command timed out, status=0x%llx\n",
-				 __func__, emm_sts.u64);
+			octeon_mmc_dbg("switch command timed out, status=0x%llx\n",
+				       emm_sts.u64);
 			goto out;
 		}
 	}
 out:
-	octeon_mmc_release_bus();
+	octeon_mmc_release_bus(host);
 }
 
 static int octeon_mmc_get_ro(struct mmc_host *mmc)
@@ -875,6 +990,7 @@ static int octeon_mmc_initlowlevel(struct octeon_mmc_slot *slot,
 	cvmx_write_csr(host->base + OCT_MIO_EMM_WDOG,
 		       ((u64)slot->clock * 850ull) / 1000ull);
 	cvmx_write_csr(host->base + OCT_MIO_EMM_STS_MASK, 0xe4f90080ull);
+	cvmx_write_csr(host->base + OCT_MIO_EMM_RCA, 1);
 
 	return 0;
 }
@@ -942,8 +1058,8 @@ static int __devinit octeon_init_slot(struct octeon_mmc_host *host, int id,
 				gpio_free(slot->cd_gpio);
 			return ret;
 		}
-		pr_debug("%s: Shutting off power to slot %d via gpio %d\n",
-			 DRV_NAME, slot->bus_id, slot->pwr_gpio);
+		octeon_mmc_dbg("%s: Shutting off power to slot %d via gpio %d\n",
+			       DRV_NAME, slot->bus_id, slot->pwr_gpio);
 		gpio_direction_output(slot->pwr_gpio,
 				      slot->pwr_gpio_low);
 	}
@@ -955,19 +1071,30 @@ static int __devinit octeon_init_slot(struct octeon_mmc_host *host, int id,
 	mmc->f_max = max_freq;
 	mmc->caps = MMC_CAP_MMC_HIGHSPEED | MMC_CAP_SD_HIGHSPEED |
 		    MMC_CAP_8_BIT_DATA | MMC_CAP_4_BIT_DATA |
-		    MMC_CAP_ERASE | MMC_CAP_CMD23;
+		    MMC_CAP_ERASE;
 	mmc->ocr_avail = MMC_VDD_27_28 | MMC_VDD_28_29 | MMC_VDD_29_30 |
 			 MMC_VDD_30_31 | MMC_VDD_31_32 | MMC_VDD_32_33 |
 			 MMC_VDD_33_34 | MMC_VDD_34_35 | MMC_VDD_35_36;
 
-	mmc->max_segs = 1;
-	mmc->max_seg_size = (1 << 23) - 8;
-	mmc->max_req_size = mmc->max_seg_size;
+	/* post-sdk23 caps */
+	mmc->caps |=
+		((mmc->f_max >= 12000000) * MMC_CAP_UHS_SDR12) |
+		((mmc->f_max >= 25000000) * MMC_CAP_UHS_SDR25) |
+		((mmc->f_max >= 50000000) * MMC_CAP_UHS_SDR50) |
+		MMC_CAP_CMD23;
+
+	if (host->global_pwr_gpio >= 0)
+		mmc->caps |= MMC_CAP_POWER_OFF_CARD;
+
+	/* "1.8v" capability is actually 1.8-or-3.3v */
+	if (ddr)
+		mmc->caps |= MMC_CAP_UHS_DDR50 | MMC_CAP_1_8V_DDR;
+
+	mmc->max_segs = 64;
+	mmc->max_seg_size = host->linear_buf_size;
+	mmc->max_req_size = host->linear_buf_size;
 	mmc->max_blk_size = 512;
 	mmc->max_blk_count = mmc->max_req_size / 512;
-	if (limit_max_blk >= 1)
-		mmc->max_blk_count = min_t(unsigned int, limit_max_blk, mmc->max_blk_count);
-
 
 	slot->clock = mmc->f_min;
 	slot->sclock = octeon_get_io_clock_rate();
@@ -978,19 +1105,20 @@ static int __devinit octeon_init_slot(struct octeon_mmc_host *host, int id,
 
 	slot->bus_width = bus_width;
 	slot->bus_id = id;
+	slot->cached_rca = 1;
 
 	/* Only a single user of the bootbus at a time. */
-	octeon_mmc_acquire_bus();
+	octeon_mmc_acquire_bus(host);
+	host->slot[id] = slot;
 
 	octeon_mmc_switch_to(slot);
 	/* Initialize MMC Block. */
 	octeon_mmc_initlowlevel(slot, bus_width);
 
-	octeon_mmc_release_bus();
+	octeon_mmc_release_bus(host);
 
-	host->slot[id] = slot;
 	ret = mmc_add_host(mmc);
-	pr_debug("mmc_add_host returned %d\n", ret);
+	octeon_mmc_dbg("mmc_add_host returned %d\n", ret);
 
 	return 0;
 }
@@ -1000,74 +1128,110 @@ static int __devinit octeon_mmc_probe(struct platform_device *pdev)
 	union cvmx_mio_emm_cfg emm_cfg;
 	struct octeon_mmc_host *host;
 	struct resource	*res;
-	int mmc_irq, dma_irq;
+	void __iomem *base;
+	int mmc_irq[9];
+	int i;
 	int ret = 0;
 	struct device_node *node = pdev->dev.of_node;
 	int found = 0;
 	enum of_gpio_flags f;
-
-	mmc_irq = platform_get_irq(pdev, 0);
-	if (mmc_irq < 0)
-		return mmc_irq;
-
-	dma_irq = platform_get_irq(pdev, 1);
-	if (dma_irq < 0)
-		return dma_irq;
+	bool cn78xx_style;
+	u64 t;
 
 	host = devm_kzalloc(&pdev->dev, sizeof(*host), GFP_KERNEL);
 	if (!host) {
 		dev_err(&pdev->dev, "devm_kzalloc failed\n");
-		ret = -ENOMEM;
-		goto err;
+		return -ENOMEM;
 	}
+	spin_lock_init(&host->irq_handler_lock);
+	sema_init(&host->mmc_serializer, 1);
+
+	cn78xx_style = of_device_is_compatible(node, "cavium,octeon-7890-mmc");
+	if (cn78xx_style) {
+		host->need_bootbus_lock = false;
+		host->big_dma_addr = true;
+		host->need_irq_handler_lock = true;
+		/*
+		 * First seven are the EMM_INT bits 0..6, then two for
+		 * the EMM_DMA_INT bits
+		 */
+		for (i = 0; i < 9; i++) {
+			mmc_irq[i] = platform_get_irq(pdev, i);
+			if (mmc_irq[i] < 0)
+				return mmc_irq[i];
+		}
+	} else {
+		host->need_bootbus_lock = true;
+		host->big_dma_addr = false;
+		host->need_irq_handler_lock = false;
+		/* First one is EMM second NDF_DMA */
+		for (i = 0; i < 2; i++) {
+			mmc_irq[i] = platform_get_irq(pdev, i);
+			if (mmc_irq[i] < 0)
+				return mmc_irq[i];
+		}
+ 	}
 	host->last_slot = -1;
 
+	if (bb_size < 512 || bb_size >= (1 << 24))
+		bb_size = 1 << 18;
+	host->linear_buf_size = bb_size;
+	host->linear_buf = devm_kzalloc(&pdev->dev, host->linear_buf_size, GFP_KERNEL);
+
+	if (!host->linear_buf) {
+		dev_err(&pdev->dev, "devm_kzalloc failed\n");
+		return -ENOMEM;
+	}
+
 	host->pdev = pdev;
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	if (!res) {
-		dev_err(&pdev->dev, "Platform resource is missing\n");
-		ret = -ENXIO;
-		goto err;
-	}
-	if (!devm_request_mem_region(&pdev->dev, res->start, resource_size(res),
-				     res->name)) {
-		dev_err(&pdev->dev, "request_mem_region 0 failed\n");
-		goto err;
+		dev_err(&pdev->dev, "Platform resource[0] is missing\n");
+		return -ENXIO;
 	}
 
-	host->base = (u64)devm_ioremap(&pdev->dev, res->start,
-				       resource_size(res));
-	if (!host->base) {
-		dev_err(&pdev->dev, "Platform resource0 is missing\n");
-		ret = -EINVAL;
-		goto err;
-	}
+	base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(base))
+		return PTR_ERR(base);
+	host->base = (u64)base;
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 1);
 	if (!res) {
-		dev_err(&pdev->dev, "Platform resource1 is missing\n");
+		dev_err(&pdev->dev, "Platform resource[1] is missing\n");
 		ret = -EINVAL;
 		goto err;
 	}
-	if (!devm_request_mem_region(&pdev->dev, res->start, resource_size(res),
-				     res->name)) {
-		dev_err(&pdev->dev, "request_mem_region 1 failed\n");
-		goto err;
-	}
-	host->ndf_base = (u64)devm_ioremap(&pdev->dev, res->start,
-					   resource_size(res));
-	if (!host->ndf_base) {
-		dev_err(&pdev->dev, "Platform resource0 is missing\n");
-		ret = -EINVAL;
+	base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(base)) {
+		ret = PTR_ERR(base);
 		goto err;
 	}
 
-	ret = devm_request_irq(&pdev->dev, mmc_irq, octeon_mmc_interrupt,
-			       0, DRV_NAME, host);
-	if (ret < 0) {
-		dev_err(&pdev->dev, "Error: devm_request_irq %d\n", mmc_irq);
-		goto err;
+	host->ndf_base = (u64)base;
+	/*
+	 * Clear out any pending interrupts that may be left over from
+	 * bootloader.
+	 */
+	t = cvmx_read_csr(host->base + OCT_MIO_EMM_INT);
+	cvmx_write_csr(host->base + OCT_MIO_EMM_INT, t);
+	if (cn78xx_style) {
+		/* Only CMD_DONE, DMA_DONE, CMD_ERR, DMA_ERR */
+		for (i = 1; i <= 4; i++) {
+			ret = devm_request_irq(&pdev->dev, mmc_irq[i], octeon_mmc_interrupt,
+					       0, DRV_NAME, host);
+			if (ret < 0) {
+				dev_err(&pdev->dev, "Error: devm_request_irq %d\n", mmc_irq[i]);
+				goto err;
+			}
+		}
+	} else {
+		ret = devm_request_irq(&pdev->dev, mmc_irq[0], octeon_mmc_interrupt,
+				       0, DRV_NAME, host);
+		if (ret < 0) {
+			dev_err(&pdev->dev, "Error: devm_request_irq %d\n", mmc_irq[0]);
+			goto err;
+		}
 	}
 
 	ret = of_get_named_gpio_flags(node, "power-gpios", 0, &f);
@@ -1090,8 +1254,6 @@ static int __devinit octeon_mmc_probe(struct platform_device *pdev)
 				      !host->global_pwr_gpio_low);
 	}
 
-	spin_lock_init(&host->lock);
-
 	platform_set_drvdata(pdev, host);
 
 	node = of_get_next_child(pdev->dev.of_node, NULL);
@@ -1147,7 +1309,7 @@ static int __devinit octeon_mmc_probe(struct platform_device *pdev)
 			ret = octeon_init_slot(host, slot, bus_width, max_freq,
 					       ro_gpio, cd_gpio, pwr_gpio,
 					       ro_low, cd_low, pwr_low, cmd_skew, dat_skew);
-			pr_debug("init slot %d, ret = %d\n", slot, ret);
+			octeon_mmc_dbg("init slot %d, ret = %d\n", slot, ret);
 			if (ret)
 				goto err;
 		}
@@ -1173,23 +1335,28 @@ err:
 
 static int __devexit octeon_mmc_remove(struct platform_device *pdev)
 {
-	union cvmx_mio_ndf_dma_int ndf_dma_int;
 	union cvmx_mio_ndf_dma_cfg ndf_dma_cfg;
 	struct octeon_mmc_host *host = platform_get_drvdata(pdev);
+	struct octeon_mmc_slot *slot;
+
+	platform_set_drvdata(pdev, NULL);
 
 	if (host) {
 		int i;
+
+		/* quench all users */
+		for (i = 0; i < OCTEON_MAX_MMC; i++) {
+			slot = host->slot[i];
+			if (slot)
+				mmc_remove_host(slot->mmc);
+		}
+
 		/* Reset bus_id */
 		ndf_dma_cfg.u64 = cvmx_read_csr(host->ndf_base + OCT_MIO_NDF_DMA_CFG);
 		ndf_dma_cfg.s.en = 0;
 		cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_CFG,
 			       ndf_dma_cfg.u64);
 
-		/* Disable the interrupt */
-		ndf_dma_int.u64 = 0;
-		cvmx_write_csr(host->ndf_base + OCT_MIO_NDF_DMA_INT,
-			       ndf_dma_int.u64);
-
 		for (i = 0; i < OCTEON_MAX_MMC; i++) {
 			struct octeon_mmc_slot *slot;
 			slot = host->slot[i];
@@ -1212,9 +1379,14 @@ static int __devexit octeon_mmc_remove(struct platform_device *pdev)
 						host->global_pwr_gpio_low);
 			gpio_free(host->global_pwr_gpio);
 		}
-	}
 
-	platform_set_drvdata(pdev, NULL);
+		for (i = 0; i < OCTEON_MAX_MMC; i++) {
+			slot = host->slot[i];
+			if (slot)
+				mmc_free_host(slot->mmc);
+		}
+
+	}
 	return 0;
 }
 
@@ -1222,6 +1394,9 @@ static struct of_device_id octeon_mmc_match[] = {
 	{
 		.compatible = "cavium,octeon-6130-mmc",
 	},
+	{
+		.compatible = "cavium,octeon-7890-mmc",
+	},
 	{},
 };
 MODULE_DEVICE_TABLE(of, octeon_mmc_match);
@@ -1240,10 +1415,10 @@ static int __init octeon_mmc_init(void)
 {
 	int ret;
 
-	pr_debug("calling octeon_mmc_init\n");
+	octeon_mmc_dbg("calling octeon_mmc_init\n");
 
 	ret = platform_driver_register(&octeon_mmc_driver);
-	pr_debug("driver probe returned %d\n", ret);
+	octeon_mmc_dbg("driver probe returned %d\n", ret);
 
 	if (ret)
 		pr_err("%s: Failed to register driver\n", DRV_NAME);
-- 
1.7.5.4

