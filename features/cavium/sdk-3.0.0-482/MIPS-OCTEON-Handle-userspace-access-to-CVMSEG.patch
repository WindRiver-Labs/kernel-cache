From 9c09ee86200f029f31eeaeffd0ad8a39e29a8310 Mon Sep 17 00:00:00 2001
From: David Daney <ddaney@caviumnetworks.com>
Date: Fri, 14 May 2010 14:25:12 -0700
Subject: [PATCH 188/337] MIPS: OCTEON: Handle userspace access to CVMSEG

Based On SDK 3.0.0-482

'Fault in' access to CVMSEG.

Signed-off-by: David Daney <ddaney@caviumnetworks.com>
Signed-off-by: Corey Minyard <cminyard@mvista.com>
Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/kernel/unaligned.c |   43 ++++++++++++++++++++++++++++++++++++++++++
 1 files changed, 43 insertions(+), 0 deletions(-)

diff --git a/arch/mips/kernel/unaligned.c b/arch/mips/kernel/unaligned.c
index 554f4f7..5e41592 100644
--- a/arch/mips/kernel/unaligned.c
+++ b/arch/mips/kernel/unaligned.c
@@ -514,6 +514,49 @@ asmlinkage void do_ade(struct pt_regs *regs)
 	unsigned int __user *pc;
 	mm_segment_t seg;
 
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) && (CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE > 0)
+	/*
+	 * Allows tasks to access CVMSEG addresses. These are special
+	 * addresses into the Octeon L1 Cache that can be used as fast
+	 * scratch memory. By default access to this memory is
+	 * disabled so we don't have to save it on context
+	 * switch. When a userspace task references one of these
+	 * addresses, we enable the region and size it to match the
+	 * app.
+	 */
+	const unsigned long CVMSEG_BASE	= 0xffffffffffff8000ul;
+	const unsigned long CVMSEG_IO	= 0xffffffffffffa200ul;
+	u64 cvmmemctl			= __read_64bit_c0_register($11, 7);
+	unsigned long cvmseg_size	= (cvmmemctl & 0x3f) * 128;
+
+	if ((regs->cp0_badvaddr == CVMSEG_IO) ||
+	    ((regs->cp0_badvaddr >= CVMSEG_BASE) &&
+	     (regs->cp0_badvaddr < CVMSEG_BASE + cvmseg_size))) {
+		preempt_disable();
+		cvmmemctl = __read_64bit_c0_register($11, 7);
+		/* Make sure all async operations are done */
+		asm volatile ("synciobdma" ::: "memory");
+		/* Enable userspace access to CVMSEG */
+		cvmmemctl |= 1 << 6;
+		__write_64bit_c0_register($11, 7, cvmmemctl);
+# ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		/*
+		 * Restore the processes CVMSEG data. Leave off the
+		 * last 8 bytes since the kernel stores the thread
+		 * pointer there.
+		 */
+		memcpy((void *)CVMSEG_BASE, current->thread.cvmseg.cvmseg,
+		       cvmseg_size - 8);
+# else
+		/* Restore the processes CVMSEG data */
+		memcpy((void *)CVMSEG_BASE, current->thread.cvmseg.cvmseg,
+		       cvmseg_size);
+# endif
+		preempt_enable();
+		return;
+	}
+#endif
+
 	perf_sw_event(PERF_COUNT_SW_ALIGNMENT_FAULTS,
 			1, regs, regs->cp0_badvaddr);
 	trace_trap_entry(regs, CAUSE_EXCCODE(regs->cp0_cause));
-- 
1.7.5.4

