From 11858e89f29ff9ca47c6b7a0516d932c4cd332d3 Mon Sep 17 00:00:00 2001
From: Rajeev Surampally <rsurampally@cavium.com>
Date: Thu, 22 Nov 2012 15:16:56 -0800
Subject: [PATCH 256/337] netdev: octeon-ethernet: Ethernet driver changes to
 work with new SE

Based On SDK 3.0.0-482

1) Removal of cvmx-config dep.
2) Integrate cvmx-fpa-alloc-pool and release to ethernet-mem.
3) Integrate ipd and pko code.
4) Other changes.

Signed-off-by: Rajeev Surampally <rsurampally@cavium.com>
Signed-off-by: Corey Minyard <cminyard@mvista.com>
Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 drivers/net/ethernet/octeon/ethernet-defines.h |   14 +++-
 drivers/net/ethernet/octeon/ethernet-mem.c     |   19 +++--
 drivers/net/ethernet/octeon/ethernet-napi.c    |    9 +-
 drivers/net/ethernet/octeon/ethernet-rx.c      |    1 +
 drivers/net/ethernet/octeon/ethernet-tx.c      |   13 ++--
 drivers/net/ethernet/octeon/ethernet.c         |  101 ++++++++++++++++--------
 drivers/net/ethernet/octeon/octeon-ethernet.h  |    6 +-
 7 files changed, 109 insertions(+), 54 deletions(-)

diff --git a/drivers/net/ethernet/octeon/ethernet-defines.h b/drivers/net/ethernet/octeon/ethernet-defines.h
index 96109a1..4856e784 100644
--- a/drivers/net/ethernet/octeon/ethernet-defines.h
+++ b/drivers/net/ethernet/octeon/ethernet-defines.h
@@ -59,10 +59,18 @@
 #ifndef __ETHERNET_DEFINES_H__
 #define __ETHERNET_DEFINES_H__
 
-#include <asm/octeon/cvmx-config.h>
+#define OCTEON_ETHERNET_VERSION "2.0"
 
+/* FAU */
+#define FAU_REG_END (2048)
 
-#define OCTEON_ETHERNET_VERSION "2.0"
+/* FPA defines */
+#define FPA_WQE_POOL_SIZE (1 * CVMX_CACHE_LINE_SIZE)
+#define FPA_PACKET_POOL_SIZE (16 * CVMX_CACHE_LINE_SIZE)
+#define FPA_OUTPUT_BUFFER_POOL_SIZE (8 * CVMX_CACHE_LINE_SIZE)
+
+/* TODO: replace this */
+#define CVMX_SCR_SCRATCH (0)
 
 #ifndef CONFIG_CAVIUM_RESERVE32
 #define CONFIG_CAVIUM_RESERVE32 0
@@ -97,7 +105,7 @@
 /* Maximum number of SKBs to try to free per xmit packet. */
 #define MAX_OUT_QUEUE_DEPTH 1000
 
-#define FAU_NUM_PACKET_BUFFERS_TO_FREE (CVMX_FAU_REG_END - sizeof(u32))
+#define FAU_NUM_PACKET_BUFFERS_TO_FREE (FAU_REG_END - sizeof(u32))
 
 #define TOTAL_NUMBER_OF_PORTS       (CVMX_PIP_NUM_INPUT_PORTS+1)
 
diff --git a/drivers/net/ethernet/octeon/ethernet-mem.c b/drivers/net/ethernet/octeon/ethernet-mem.c
index 19f6034..dbaf7fc 100644
--- a/drivers/net/ethernet/octeon/ethernet-mem.c
+++ b/drivers/net/ethernet/octeon/ethernet-mem.c
@@ -237,6 +237,12 @@ int cvm_oct_alloc_fpa_pool(int pool, int size)
 				goto out;
 			}
 		}
+		/* reserve/alloc fpa pool */
+		pool = cvmx_fpa_alloc_pool(pool);
+		if (pool < 0) {
+			ret = -EINVAL;
+			goto out;
+		}
 	} else {
 		/* Find an established pool */
 		for (i = 0; i < ARRAY_SIZE(cvm_oct_pools); i++)
@@ -247,12 +253,8 @@ int cvm_oct_alloc_fpa_pool(int pool, int size)
 				goto out;
 			}
 
-		/* Find an empty pool */
-		for (i = 0; i < ARRAY_SIZE(cvm_oct_pools); i++)
-			if (cvm_oct_pools[i].pool == -1) {
-				pool = i;
-				break;
-			}
+		/* Alloc fpa pool */
+		pool = cvmx_fpa_alloc_pool(pool);
 		if (pool < 0) {
 			/* No empties. */
 			ret = -EINVAL;
@@ -280,6 +282,7 @@ int cvm_oct_alloc_fpa_pool(int pool, int size)
 		if (!cvm_oct_pools[pool].kmem) {
 			ret = -ENOMEM;
 			cvm_oct_pools[pool].pool = -1;
+			cvmx_fpa_release_pool(pool);
 			goto out;
 		}
 	}
@@ -312,6 +315,10 @@ int cvm_oct_release_fpa_pool(int pool)
 		goto out;
 	}
 	cvm_oct_pools[pool].users--;
+
+	if (cvm_oct_pools[pool].users == 0)
+		cvmx_fpa_release_pool(pool);
+
 	ret = 0;
 out:
 	spin_unlock(&cvm_oct_pools_lock);
diff --git a/drivers/net/ethernet/octeon/ethernet-napi.c b/drivers/net/ethernet/octeon/ethernet-napi.c
index 165f30d..af467b8 100644
--- a/drivers/net/ethernet/octeon/ethernet-napi.c
+++ b/drivers/net/ethernet/octeon/ethernet-napi.c
@@ -56,6 +56,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 	bool		packet_copied;
 
 	char		*p = (char *)cvm_oct_by_pkind;
+
 	/* Prefetch cvm_oct_device since we know we need it soon */
 	prefetch(&p[0]);
 	prefetch(&p[SMP_CACHE_BYTES]);
@@ -168,7 +169,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			}
 			dev_kfree_skb_any(skb);
 
-			cvmx_fpa_free(work, CVMX_FPA_WQE_POOL, DONT_WRITEBACK(1));
+			cvmx_fpa_free(work, wqe_pool, DONT_WRITEBACK(1));
 
 			/* We are done with this one, adjust the queue
 			 * depth.
@@ -239,7 +240,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 					 * one: int segment_size =
 					 * segment_ptr.s.size;
 					 */
-					segment_size = CVMX_FPA_PACKET_POOL_SIZE -
+					segment_size = FPA_PACKET_POOL_SIZE -
 						(packet_ptr.s.addr - (((packet_ptr.s.addr >> 7) - packet_ptr.s.back) << 7));
 					if (segment_size > packet_len)
 						segment_size = packet_len;
@@ -312,7 +313,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			 * one: int segment_size =
 			 * segment_ptr.s.size;
 			 */
-					int segment_size = CVMX_FPA_PACKET_POOL_SIZE -
+					int segment_size = FPA_PACKET_POOL_SIZE -
 						(segment_ptr.s.addr - (((segment_ptr.s.addr >> 7) - segment_ptr.s.back) << 7));
 					/* Don't copy more than what
 					 * is left in the packet.
@@ -398,7 +399,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
 					      packets_to_replace);
 
-			cvmx_fpa_free(work, CVMX_FPA_WQE_POOL,
+			cvmx_fpa_free(work, wqe_pool,
 				      DONT_WRITEBACK(1));
 		} else {
 			cvm_oct_free_work(work);
diff --git a/drivers/net/ethernet/octeon/ethernet-rx.c b/drivers/net/ethernet/octeon/ethernet-rx.c
index e19c092..743ad19 100644
--- a/drivers/net/ethernet/octeon/ethernet-rx.c
+++ b/drivers/net/ethernet/octeon/ethernet-rx.c
@@ -53,6 +53,7 @@
 #include <asm/octeon/cvmx-fau.h>
 #include <asm/octeon/cvmx-pow.h>
 #include <asm/octeon/cvmx-pip.h>
+#include <asm/octeon/cvmx-ipd.h>
 #include <asm/octeon/cvmx-srio.h>
 #include <asm/octeon/cvmx-scratch.h>
 
diff --git a/drivers/net/ethernet/octeon/ethernet-tx.c b/drivers/net/ethernet/octeon/ethernet-tx.c
index dfdacbb..698a628 100644
--- a/drivers/net/ethernet/octeon/ethernet-tx.c
+++ b/drivers/net/ethernet/octeon/ethernet-tx.c
@@ -42,6 +42,7 @@
 
 #include <asm/octeon/cvmx-wqe.h>
 #include <asm/octeon/cvmx-fau.h>
+#include <asm/octeon/cvmx-ipd.h>
 #include <asm/octeon/cvmx-pip.h>
 #include <asm/octeon/cvmx-pko.h>
 #include <asm/octeon/cvmx-helper.h>
@@ -70,7 +71,7 @@ static bool cvm_oct_skb_ok_for_reuse(struct sk_buff *skb)
 	if (unlikely(fpa_head - skb->head < sizeof(void *)))
 		return false;
 
-	if (unlikely((skb_end_pointer(skb) - fpa_head) < CVMX_FPA_PACKET_POOL_SIZE))
+	if (unlikely((skb_end_pointer(skb) - fpa_head) < FPA_PACKET_POOL_SIZE))
 		return false;
 
 	if (unlikely(skb_shared(skb)) ||
@@ -90,7 +91,7 @@ static void cvm_oct_skb_prepare_for_reuse(struct sk_buff *skb)
 	skb_frag_list_init(skb);
 
 	/* The check also resets all the fields. */
-	r = skb_recycle_check(skb, CVMX_FPA_PACKET_POOL_SIZE);
+	r = skb_recycle_check(skb, FPA_PACKET_POOL_SIZE);
 	WARN(!r, "SKB recycle logic fail\n");
 
 	*(struct sk_buff **)(fpa_head - sizeof(void *)) = skb;
@@ -251,7 +252,7 @@ int cvm_oct_xmit(struct sk_buff *skb, struct net_device *dev)
 		u64 *hw_buffer_list;
 		bool can_do_reuse = true;
 
-		work = cvmx_fpa_alloc(CVMX_FPA_WQE_POOL);
+		work = cvmx_fpa_alloc(wqe_pool);
 		if (unlikely(!work)) {
 			netdev_err(dev, "Failed WQE allocate\n");
 			queue_type = QUEUE_DROP;
@@ -289,7 +290,7 @@ int cvm_oct_xmit(struct sk_buff *skb, struct net_device *dev)
 		hw_buffer.s.addr = virt_to_phys(hw_buffer_list);
 		hw_buffer.s.size = i;
 		hw_buffer.s.back = 0;
-		hw_buffer.s.pool = CVMX_FPA_WQE_POOL;
+		hw_buffer.s.pool = wqe_pool;
 		buffers_being_recycled = i;
 		pko_command.s.segs = hw_buffer.s.size;
 		pko_command.s.gather = 1;
@@ -390,7 +391,7 @@ dont_put_skbuff_in_hw:
 
 	if (queue_type == QUEUE_WQE) {
 		if (!work) {
-			work = cvmx_fpa_alloc(CVMX_FPA_WQE_POOL);
+			work = cvmx_fpa_alloc(wqe_pool);
 			if (unlikely(!work)) {
 				netdev_err(dev, "Failed WQE allocate\n");
 				queue_type = QUEUE_DROP;
@@ -434,7 +435,7 @@ dont_put_skbuff_in_hw:
 							  priv->tx_queue[qos].queue, pko_command, hw_buffer,
 							  word2, CVMX_PKO_LOCK_CMD_QUEUE))) {
 				queue_type = QUEUE_DROP;
-				cvmx_fpa_free(work, CVMX_FPA_WQE_POOL, DONT_WRITEBACK(1));
+				cvmx_fpa_free(work, wqe_pool, DONT_WRITEBACK(1));
 				netdev_err(dev, "Failed to send the packet with wqe\n");
 		}
 	} else {
diff --git a/drivers/net/ethernet/octeon/ethernet.c b/drivers/net/ethernet/octeon/ethernet.c
index 45c874b..d6bf83f 100644
--- a/drivers/net/ethernet/octeon/ethernet.c
+++ b/drivers/net/ethernet/octeon/ethernet.c
@@ -82,6 +82,17 @@ int rx_napi_weight = 32;
 module_param(rx_napi_weight, int, 0444);
 MODULE_PARM_DESC(rx_napi_weight, "The NAPI WEIGHT parameter.");
 
+/* internal ports count for each port in a interface */
+int iport_count = 1;
+/* pko queue count for each port in a interface */
+int queues_count = 1;
+/* packet pool */
+int packet_pool = 0;
+/* wqe pool */
+int wqe_pool = -1;
+/* output pool */
+int output_pool = -1;
+
 /**
  * cvm_oct_poll_queue - Workqueue for polling operations.
  */
@@ -152,33 +163,59 @@ static int cvm_oct_num_output_buffers;
 
 static __devinit int cvm_oct_configure_common_hw(void)
 {
+
 	/* Setup the FPA */
 	cvmx_fpa_enable();
 
-	if (cvm_oct_alloc_fpa_pool(CVMX_FPA_PACKET_POOL,
-				   CVMX_FPA_PACKET_POOL_SIZE) < 0) {
-		pr_err("cvm_oct_alloc_fpa_pool(CVMX_FPA_PACKET_POOL, CVMX_FPA_PACKET_POOL_SIZE) failed.\n");
+	/* allocate packet pool */
+	packet_pool = cvm_oct_alloc_fpa_pool(packet_pool, FPA_PACKET_POOL_SIZE);
+	if (packet_pool < 0) {
+		pr_err("cvm_oct_alloc_fpa_pool(FPA_PACKET_POOL, FPA_PACKET_POOL_SIZE) failed.\n");
 		return -ENOMEM;
 	}
-	cvm_oct_mem_fill_fpa(CVMX_FPA_PACKET_POOL, num_packet_buffers);
+	cvm_oct_mem_fill_fpa(packet_pool, num_packet_buffers);
 
-	if (cvm_oct_alloc_fpa_pool(CVMX_FPA_WQE_POOL,
-				   CVMX_FPA_WQE_POOL_SIZE) < 0) {
-		pr_err("cvm_oct_alloc_fpa_pool(CVMX_FPA_WQE_POOL, CVMX_FPA_WQE_POOL_SIZE) failed.\n");
+	/* communicate packet pool number to ipd */
+	cvmx_ipd_set_packet_pool_config(packet_pool, FPA_PACKET_POOL_SIZE,
+					num_packet_buffers);
+
+	/* allocate wqe pool */
+	wqe_pool = cvm_oct_alloc_fpa_pool(-1, FPA_WQE_POOL_SIZE);
+	if (wqe_pool < 0) {
+		pr_err("cvm_oct_alloc_fpa_pool(FPA_WQE_POOL, FPA_WQE_POOL_SIZE) failed.\n");
 		return -ENOMEM;;
 	}
-	cvm_oct_mem_fill_fpa(CVMX_FPA_WQE_POOL, num_packet_buffers);
-
-	if (CVMX_FPA_OUTPUT_BUFFER_POOL != CVMX_FPA_PACKET_POOL) {
-		cvm_oct_num_output_buffers = 128;
-		if (cvm_oct_alloc_fpa_pool(CVMX_FPA_OUTPUT_BUFFER_POOL,
-					   CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE) < 0) {
-			pr_err("cvm_oct_alloc_fpa_pool(CVMX_FPA_OUTPUT_BUFFER_POOL, CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE) failed.\n");
-			return -ENOMEM;;
-		}
-		cvm_oct_mem_fill_fpa(CVMX_FPA_OUTPUT_BUFFER_POOL,
-				     cvm_oct_num_output_buffers);
+	cvm_oct_mem_fill_fpa(wqe_pool, num_packet_buffers);
+
+	/* communicate wqe pool to ipd */
+	cvmx_ipd_set_wqe_pool_config(wqe_pool, FPA_WQE_POOL_SIZE,
+				     num_packet_buffers);
+
+#ifdef USE_PACKET_POOL_FOR_OUTPUT_BUFFERS
+	output_pool = packet_pool;
+
+	/* communicate output pool no. to pko */
+	cvmx_pko_set_cmd_que_pool_config(output_pool,
+					 FPA_PACKET_POOL_SIZE,
+					 num_packet_buffers);
+#else
+	/* alloc fpa pool for output buffers */
+	cvm_oct_num_output_buffers = 128;
+	output_pool = cvm_oct_alloc_fpa_pool(-1, FPA_OUTPUT_BUFFER_POOL_SIZE);
+	if (output_pool < 0) {
+		pr_err("cvm_oct_alloc_fpa_pool(FPA_OUTPUT_BUFFER_POOL, FPA_OUTPUT_BUFFER_POOL_SIZE) failed.\n");
+		return -ENOMEM;;
 	}
+	cvm_oct_mem_fill_fpa(output_pool, cvm_oct_num_output_buffers);
+
+	/* communicate output pool no. to pko */
+	cvmx_pko_set_cmd_que_pool_config(output_pool,
+					 FPA_OUTPUT_BUFFER_POOL_SIZE,
+					 cvm_oct_num_output_buffers);
+#endif
+
+	/* more configuration needs to be done, so enable ipd seperately */
+	cvmx_ipd_cfg.ipd_enable = 0;
 
 	cvmx_helper_initialize_packet_io_global();
 
@@ -218,10 +255,10 @@ int cvm_oct_free_work(void *work_queue_entry)
 		if (!segment_ptr.s.i)
 			cvmx_fpa_free(cvm_oct_get_buffer_ptr(segment_ptr),
 				      segment_ptr.s.pool,
-				      DONT_WRITEBACK(CVMX_FPA_PACKET_POOL_SIZE / 128));
+				      DONT_WRITEBACK(FPA_PACKET_POOL_SIZE / 128));
 		segment_ptr = next_ptr;
 	}
-	cvmx_fpa_free(work, CVMX_FPA_WQE_POOL, DONT_WRITEBACK(1));
+	cvmx_fpa_free(work, wqe_pool, DONT_WRITEBACK(1));
 
 	return 0;
 }
@@ -775,9 +812,7 @@ static int __devinit cvm_oct_probe(struct platform_device *pdev)
 			}
 
 			/* Cache the fact that there may be multiple queues */
-			priv->tx_multiple_queues =
-				(CVMX_PKO_QUEUES_PER_PORT_INTERFACE0 > 1) ||
-				(CVMX_PKO_QUEUES_PER_PORT_INTERFACE1 > 1);
+			priv->tx_multiple_queues = (queues_count > 1);
 
 			switch (priv->imode) {
 			/* These types don't support ports to IPD/PKO */
@@ -845,7 +880,7 @@ static int __devinit cvm_oct_probe(struct platform_device *pdev)
 				 * own MAX_OUT_QUEUE_DEPTH worth of
 				 * WQE to track the transmit skbs.
 				 */
-				cvm_oct_mem_fill_fpa(CVMX_FPA_WQE_POOL,
+				cvm_oct_mem_fill_fpa(wqe_pool,
 						     PER_DEVICE_EXTRA_WQE);
 				num_devices_extra_wqe++;
 				queue_delayed_work(cvm_oct_poll_queue,
@@ -913,18 +948,18 @@ static int __devexit cvm_oct_remove(struct platform_device *pdev)
 	destroy_workqueue(cvm_oct_poll_queue);
 
 	/* Free the HW pools */
-	cvm_oct_mem_empty_fpa(CVMX_FPA_PACKET_POOL, num_packet_buffers);
-	cvm_oct_release_fpa_pool(CVMX_FPA_PACKET_POOL);
+	cvm_oct_mem_empty_fpa(packet_pool, num_packet_buffers);
+	cvm_oct_release_fpa_pool(packet_pool);
 
-	cvm_oct_mem_empty_fpa(CVMX_FPA_WQE_POOL,
+	cvm_oct_mem_empty_fpa(wqe_pool,
 			      num_packet_buffers + num_devices_extra_wqe * PER_DEVICE_EXTRA_WQE);
-	cvm_oct_release_fpa_pool(CVMX_FPA_WQE_POOL);
+	cvm_oct_release_fpa_pool(wqe_pool);
 
-	if (CVMX_FPA_OUTPUT_BUFFER_POOL != CVMX_FPA_PACKET_POOL) {
-		cvm_oct_mem_empty_fpa(CVMX_FPA_OUTPUT_BUFFER_POOL,
-				      cvm_oct_num_output_buffers);
-		cvm_oct_release_fpa_pool(CVMX_FPA_OUTPUT_BUFFER_POOL);
-	}
+#ifndef USE_PACKET_POOL_FOR_OUTPUT_BUFFERS
+	cvm_oct_mem_empty_fpa(output_pool,
+				cvm_oct_num_output_buffers);
+	cvm_oct_release_fpa_pool(output_pool);
+#endif
 	cvm_oct_mem_cleanup();
 
 	return 0;
diff --git a/drivers/net/ethernet/octeon/octeon-ethernet.h b/drivers/net/ethernet/octeon/octeon-ethernet.h
index 39d2503..568789e 100644
--- a/drivers/net/ethernet/octeon/octeon-ethernet.h
+++ b/drivers/net/ethernet/octeon/octeon-ethernet.h
@@ -138,6 +138,9 @@ void cvm_oct_mem_cleanup(void);
 
 extern const struct ethtool_ops cvm_oct_ethtool_ops;
 
+extern int packet_pool;
+extern int wqe_pool;
+extern int output_pool;
 extern int always_use_pow;
 extern int pow_send_group;
 extern int pow_receive_group;
@@ -163,8 +166,7 @@ static inline void cvm_oct_rx_refill_pool(int fill_threshold)
 	if (number_to_free > fill_threshold) {
 		cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
 				      -number_to_free);
-		num_freed = cvm_oct_mem_fill_fpa(CVMX_FPA_PACKET_POOL,
-						 number_to_free);
+		num_freed = cvm_oct_mem_fill_fpa(packet_pool, number_to_free);
 		if (num_freed != number_to_free) {
 			cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
 					number_to_free - num_freed);
-- 
1.7.5.4

