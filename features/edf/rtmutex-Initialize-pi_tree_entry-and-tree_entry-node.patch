From b3f1b33096028bf8b4791d958b5f2f9f86a65899 Mon Sep 17 00:00:00 2001
From: Xufeng Zhang <xufeng.zhang@windriver.com>
Date: Tue, 22 Jan 2013 10:12:10 +0800
Subject: [PATCH] rtmutex: Initialize pi_tree_entry and tree_entry nodes
 before use them

From git://github.com/jlelli/sched-deadline.git:sched-dl-V5, upstream
commit 1cbceeb01 "rtmutex: turn the plist into an rb-tree." turn the
pi-chains from plist to rb-tree in the rt_mutex code, however, it removes the
plist node initialize code from task_blocks_on_rt_mutex() without adding
rb-tree node intialization code, so kernel gpf oops happens like below caused
by pthread_mutexattr_setprotocol() API while doing pi-futex or rb-rutex test:
  general protection fault: 0000 [#2] PREEMPT SMP
  RIP: 0010:[<ffffffff82326c1b>]  [<ffffffff82326c1b>] rb_erase+0x2b/0x310
  RSP: 0018:ffff8800781ddb58  EFLAGS: 00010082
  RAX: f0758b4ce86d8b4c RBX: ffff8800781ddc20 RCX: 0000000000000000
  RDX: f0758b4ce86d8b4c RSI: ffff880077673888 RDI: ffff8800781ddc38
  RBP: ffff8800781ddb68 R08: 0000000000000000 R09: f970000000000000
  R10: 0000000000000001 R11: 0000000000000001 R12: ffff880077673888
  R13: ffff880077673100 R14: 0000000000000001 R15: ffff880078293100
  FS:  00000000006d0880(0063) GS:ffff88007f380000(0000) knlGS:0000000000000000
  CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
  CR2: 00007fb11a41ae78 CR3: 00000000785f1000 CR4: 00000000000407e0
  DR0: ffffffff82f44af4 DR1: 0000000000000000 DR2: 0000000000000000
  DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000600
  Process tst-robustpi3 (pid: 1068, threadinfo ffff8800781dc000, task ffff880078293100)
  Call Trace:
   [<ffffffff820959b8>] rt_mutex_dequeue_pi+0x48/0x80
   [<ffffffff82095ffb>] task_blocks_on_rt_mutex+0x12b/0x180
   [<ffffffff826ee1c7>] rt_mutex_slowlock+0x87/0x170
   [<ffffffff820926b9>] ? futex_lock_pi_atomic+0xb9/0x130
   [<ffffffff820961cf>] rt_mutex_timed_lock+0x3f/0x50
   [<ffffffff820942bc>] futex_lock_pi.isra.18+0x2ac/0x3b0
   [<ffffffff8205f210>] ? update_rmtp+0x70/0x70
   [<ffffffff8205ff84>] ? hrtimer_start_range_ns+0x14/0x20
   [<ffffffff82094dac>] do_futex+0x52c/0xaa0
   [<ffffffff826f2c79>] ? sub_preempt_count+0xa9/0xe0
   [<ffffffff826eea8a>] ? _raw_spin_unlock_irqrestore+0x2a/0x60
   [<ffffffff8206e1fd>] ? wake_up_new_task+0xfd/0x1c0
   [<ffffffff826f2c79>] ? sub_preempt_count+0xa9/0xe0
   [<ffffffff82095462>] sys_futex+0x142/0x1a0
   [<ffffffff82063cbe>] ? msa_kernel+0x8e/0xb0
   [<ffffffff826f673b>] system_call_fastpath+0x1a/0x1f

We can fix this problem by calling RB_CLEAR_NODE() to initialize pi_tree_entry and tree_entry
nodes in task_blocks_on_rt_mutex() just like debug_rt_mutex_init_waiter() does.

Signed-off-by: Xufeng Zhang <xufeng.zhang@windriver.com>
---
 kernel/rtmutex.c |    2 ++
 1 file changed, 2 insertions(+)

diff --git a/kernel/rtmutex.c b/kernel/rtmutex.c
index 7187c50..968fb03 100644
--- a/kernel/rtmutex.c
+++ b/kernel/rtmutex.c
@@ -501,6 +501,8 @@ static int task_blocks_on_rt_mutex(struct rt_mutex *lock,
 	__rt_mutex_adjust_prio(task);
 	waiter->task = task;
 	waiter->lock = lock;
+	RB_CLEAR_NODE(&waiter->pi_tree_entry);
+	RB_CLEAR_NODE(&waiter->tree_entry);
 	
 	/* Get the top priority waiter on the lock */
 	if (rt_mutex_has_waiters(lock))
-- 
1.7.9.7

