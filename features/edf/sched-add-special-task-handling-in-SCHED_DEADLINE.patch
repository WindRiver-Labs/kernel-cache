From 06b0d01e1f572009607a1623c5df1f7d86ebc52b Mon Sep 17 00:00:00 2001
From: Raistlin <raistlin@linux.it>
Date: Thu, 27 May 2010 19:22:20 -0700
Subject: [PATCH 11/15] sched: add special task handling in SCHED_DEADLINE.

taked from:
git://gitorious.org/sched_deadline/linux-deadline.git sched-dl
commit 8a4aa0af06e5e9d68dbf3bd764433a628b32b431

There sometimes is the need of executing a task as if it would
have the maximum possible priority in the entire system, i.e.,
whenever it gets ready it must run! This is for example the case
for some maintainance kernel thread like migration and watchdog.

Since SCHED_DEADLINE is now the highest priority scheduling class
these tasks have to be handled therein, but it is not obvious how
to choose a runtime and a deadline that guarantee what explained
above. Therefore, we need a mean of recognizing special tasks inside
the -deadline class and always run them as soon as possible, without
any kind of runtime and bandwidth limitation.

This patch:
 - adds the internal flag DL_SPECIAL, which identify a special
   system task that need absolute prioritization among every other
   task;
 - ensures that special tasks are always enqueued at the top of their
   runqueue, so that they always preempt everyone else and, on the
   contrary, are not preempted by anyone but other special tasks;
 - disables runtime and bandwidth checking for such tasks, hoping
   that the interference they cause is small and small enough.

Integrated-by: Liming Wang <liming.wang@windriver>
---
 include/linux/sched.h |    6 +++++
 kernel/sched.c        |   54 ++++++++++++++++++++++++++++++++++++++++++++----
 kernel/sched_dl.c     |   20 ++++++++++++++++-
 kernel/softlockup.c   |    4 +--
 4 files changed, 74 insertions(+), 10 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index eae9eb3..acd3e0f 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1268,9 +1268,14 @@ struct sched_rt_entity {
  *  @DL_THROTTLED  tells us that the last instance exhausted the runtime
  *                 and that the task is waiting for a replenishment to
  *                 be performed at the next firing of dl_timer.
+ *  @DL_SPECIAL    tells us that the task has to be considered one of the
+ *                 maximum priority tasks in the system. This means it
+ *                 always inserted at the top of the runqueue, and that
+ *                 it is not subject to runtime and bandwidth limitations.
  */
 #define DL_NEW			0x00010000
 #define DL_THROTTLED		0x00020000
+#define DL_SPECIAL		0x00040000
 
 struct sched_dl_entity {
 	struct rb_node	rb_node;
@@ -2104,6 +2109,7 @@ extern int sched_setscheduler_nocheck(struct task_struct *, int,
 extern int sched_setscheduler_ex(struct task_struct *, int,
 				 struct sched_param *,
 				 struct sched_param_ex *);
+extern void setscheduler_dl_special(struct task_struct *);
 extern struct task_struct *idle_task(int cpu);
 extern struct task_struct *curr_task(int cpu);
 extern void set_curr_task(int cpu, struct task_struct *p);
diff --git a/kernel/sched.c b/kernel/sched.c
index e3bd864..5c7f8dc 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -4589,6 +4589,40 @@ __setscheduler(struct rq *rq, struct task_struct *p, int policy, int prio)
 }
 
 /*
+ * These functions make the task one of the highest priority task in
+ * the system. This means it will always run as soon as it gets ready,
+ * and it won't be preempted by any other task, independently from their
+ * scheduling policy, deadline, priority, etc. (provided they're not
+ * special tasks as well).
+ */
+static void __setscheduler_dl_special(struct rq *rq,struct task_struct *p)
+{
+	p->dl.dl_runtime = 0;
+	p->dl.dl_deadline = 0;
+	p->dl.flags = DL_SPECIAL;
+	p->dl.flags |= DL_NEW;
+
+	__setscheduler(rq, p, SCHED_DEADLINE, MAX_RT_PRIO-1);
+}
+
+void setscheduler_dl_special(struct task_struct *p)
+{
+	struct sched_param param;
+	struct sched_param_ex param_ex;
+
+	param.sched_priority = 0;
+
+	param_ex.sched_priority = MAX_RT_PRIO-1;
+	param_ex.sched_runtime = ns_to_timespec(0);
+	param_ex.sched_deadline = ns_to_timespec(0);
+	param_ex.sched_flags = DL_SPECIAL;
+	param_ex.sched_flags |= DL_NEW;
+
+	sched_setscheduler_ex(current, SCHED_DEADLINE, &param, &param_ex);
+}
+EXPORT_SYMBOL(setscheduler_dl_special);
+
+/*
  * This function initializes the sched_dl_entity of a newly becoming
  * SCHED_DEADLINE task.
  *
@@ -4625,9 +4659,19 @@ __getparam_dl(struct task_struct *p, struct sched_param_ex *param_ex)
  * than the runtime.
  */
 static bool
-__checkparam_dl(struct sched_param_ex *prm)
+__checkparam_dl(struct sched_param_ex *prm, bool kthread)
 {
-	return prm && timespec_to_ns(&prm->sched_deadline) != 0 &&
+	if (!prm)
+		return false;
+
+	if (prm->sched_flags & DL_SPECIAL) {
+		if (kthread)
+			return true;
+		else
+			return false;
+	}
+
+	return timespec_to_ns(&prm->sched_deadline) != 0 &&
 	       timespec_to_ns(&prm->sched_deadline) <= MAX_SCHED_DEADLINE &&
 	       timespec_to_ns(&prm->sched_deadline) >=
 	       timespec_to_ns(&prm->sched_runtime);
@@ -4687,7 +4731,7 @@ recheck:
 	    (p->mm && param->sched_priority > MAX_USER_RT_PRIO-1) ||
 	    (!p->mm && param->sched_priority > MAX_RT_PRIO-1))
 		return -EINVAL;
-	if ((dl_policy(policy) && !__checkparam_dl(param_ex)) ||
+	if ((dl_policy(policy) && !__checkparam_dl(param_ex, !p->mm)) ||
 	    (rt_policy(policy) != (param->sched_priority != 0)))
 		return -EINVAL;
 
@@ -5966,7 +6010,7 @@ void sched_idle_next(void)
 	 */
 	raw_spin_lock_irqsave(&rq->lock, flags);
 
-	__setscheduler(rq, p, SCHED_FIFO, MAX_RT_PRIO-1);
+	__setscheduler_dl_special(rq, p);
 
 	update_rq_clock(rq);
 	activate_task(rq, p, 0);
@@ -6261,7 +6305,7 @@ migration_call(struct notifier_block *nfb, unsigned long action, void *hcpu)
 		kthread_bind(p, cpu);
 		/* Must be high prio: stop_machine expects to yield to it. */
 		rq = task_rq_lock(p, &flags);
-		__setscheduler(rq, p, SCHED_FIFO, MAX_RT_PRIO-1);
+		__setscheduler_dl_special(rq, p);
 		task_rq_unlock(rq, &flags);
 		get_task_struct(p);
 		cpu_rq(cpu)->migration_thread = p;
diff --git a/kernel/sched_dl.c b/kernel/sched_dl.c
index 2e703ca..b8f954f 100644
--- a/kernel/sched_dl.c
+++ b/kernel/sched_dl.c
@@ -345,7 +345,15 @@ int dl_runtime_exceeded(struct rq *rq, struct sched_dl_entity *dl_se)
 	int dmiss = dl_time_before(dl_se->deadline, rq->clock);
 	int rorun = dl_se->runtime <= 0;
 
-	if (dl_se->flags & DL_NEW || (!rorun && !dmiss))
+	/*
+	 * No need for checking if it's time to enforce the
+	 * bandwidth for the tasks that are:
+	 *  - maximum priority (DL_SPECIAL),
+	 *  - starting a new instance (DL_NEW),
+	 *  - or not overrunning nor missing a deadline.
+	 */
+	if (dl_se->flags & DL_SPECIAL ||
+	    dl_se->flags & DL_NEW || (!rorun && !dmiss))
 		return 0;
 
 	/*
@@ -437,7 +445,15 @@ static void enqueue_dl_entity(struct sched_dl_entity *dl_se)
 	while (*link) {
 		parent = *link;
 		entry = rb_entry(parent, struct sched_dl_entity, rb_node);
-		if (dl_time_before(dl_se->deadline, entry->deadline))
+
+		/*
+		 * We treat a special task as if it's deadline would
+		 * always be earlier than any other task in the runqueue
+		 * (it will likely become the leftmost).
+		 */
+		if (dl_se->flags & DL_SPECIAL ||
+		    (dl_time_before(dl_se->deadline, entry->deadline) &&
+		     !(entry->flags & DL_SPECIAL)))
 			link = &parent->rb_left;
 		else {
 			link = &parent->rb_right;
diff --git a/kernel/softlockup.c b/kernel/softlockup.c
index 4b493f6..70177b2 100644
--- a/kernel/softlockup.c
+++ b/kernel/softlockup.c
@@ -185,9 +185,7 @@ void softlockup_tick(void)
  */
 static int watchdog(void *__bind_cpu)
 {
-	struct sched_param param = { .sched_priority = MAX_RT_PRIO-1 };
-
-	sched_setscheduler(current, SCHED_FIFO, &param);
+	setscheduler_dl_special(current);
 
 	/* initialize timestamp */
 	__touch_softlockup_watchdog();
-- 
1.6.5.2

