From 98a9461e01c00b6a4de95d45c23154c0b1fee781 Mon Sep 17 00:00:00 2001
From: Limeng <Meng.Li@windriver.com>
Date: Wed, 11 Oct 2017 13:47:00 +0800
Subject: [PATCH 19/29] Revert "crypto: dpaa2-caam - set FLC[SDL] at context
 setup"

This reverts commit 40553a40b7afec856b614f2e138d763455d27171.

At first, dpaa2-caam patches are from nxp-sdk-2.0 that is based on
kernel4.1. But in kernel4.8, there is a obvious changing on crypto
software architecture, so modify code to pass compilation, but this
feature is not verified.
Now, there is an open source sdk that is based on kernel4.4. In
kernel4.4, crypto software architecture is almost the same with
kernel4.8, so we get dpaa2-caam patches from open source sdk, and
revert patches from nxp-sdk-2.0.

Signed-off-by: Meng Li <Meng.Li@windriver.com>
---
 drivers/crypto/dpaa2-caam/dpaa2-caam.c |   21 ++++++---------------
 1 files changed, 6 insertions(+), 15 deletions(-)

diff --git a/drivers/crypto/dpaa2-caam/dpaa2-caam.c b/drivers/crypto/dpaa2-caam/dpaa2-caam.c
index 1ef4d24..40ea214 100644
--- a/drivers/crypto/dpaa2-caam/dpaa2-caam.c
+++ b/drivers/crypto/dpaa2-caam/dpaa2-caam.c
@@ -395,7 +395,6 @@ static int aead_set_sh_desc(struct crypto_aead *aead)
 	append_seq_store(desc, ctx->authsize, LDST_CLASS_2_CCB |
 			 LDST_SRCDST_BYTE_CONTEXT);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -468,7 +467,6 @@ static int aead_set_sh_desc(struct crypto_aead *aead)
 	append_seq_fifo_load(desc, ctx->authsize, FIFOLD_CLASS_CLASS2 |
 			     FIFOLD_TYPE_LAST2 | FIFOLD_TYPE_ICV);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -567,7 +565,6 @@ static int aead_set_sh_desc(struct crypto_aead *aead)
 	append_seq_store(desc, ctx->authsize, LDST_CLASS_2_CCB |
 			 LDST_SRCDST_BYTE_CONTEXT);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -674,7 +671,6 @@ int gen_split_key(struct device *dev, u8 *key_out, int split_key_len,
 	append_fifo_store(desc, dma_addr_out, split_key_len,
 			  LDST_CLASS_2_CCB | FIFOST_TYPE_SPLIT_KEK);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) + desc_bytes(desc),
 				 DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, flc_dma)) {
@@ -1282,7 +1278,6 @@ static int gcm_set_sh_desc(struct crypto_aead *aead)
 	append_seq_store(desc, ctx->authsize, LDST_CLASS_1_CCB |
 			 LDST_SRCDST_BYTE_CONTEXT);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -1380,7 +1375,6 @@ static int gcm_set_sh_desc(struct crypto_aead *aead)
 	append_seq_fifo_load(desc, ctx->authsize, FIFOLD_CLASS_CLASS1 |
 			     FIFOLD_TYPE_ICV | FIFOLD_TYPE_LAST1);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -1532,7 +1526,6 @@ static int ablkcipher_setkey(struct crypto_ablkcipher *ablkcipher,
 	/* Perform operation */
 	ablkcipher_append_src_dst(desc);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -1597,7 +1590,6 @@ static int ablkcipher_setkey(struct crypto_ablkcipher *ablkcipher,
 	/* Perform operation */
 	ablkcipher_append_src_dst(desc);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -1677,7 +1669,6 @@ static int ablkcipher_setkey(struct crypto_ablkcipher *ablkcipher,
 	/* Perform operation */
 	ablkcipher_append_src_dst(desc);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -3267,7 +3258,6 @@ static int hash_digest_key(struct caam_hash_ctx *ctx, const u8 *key_in,
 	append_seq_store(desc, digestsize, LDST_CLASS_2_CCB |
 			 LDST_SRCDST_BYTE_CONTEXT);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) + desc_bytes(desc),
 				 DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, flc_dma)) {
@@ -3358,7 +3348,6 @@ static int ahash_set_sh_desc(struct crypto_ahash *ahash)
 	/* Load data and write to result or context */
 	ahash_append_load_str(desc, ctx->ctx_len);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) +
 				  desc_bytes(desc), DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -3380,7 +3369,6 @@ static int ahash_set_sh_desc(struct crypto_ahash *ahash)
 	ahash_data_to_out(desc, have_key | ctx->alg_type, OP_ALG_AS_INIT,
 			  ctx->ctx_len, ctx);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) + desc_bytes(desc),
 				  DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -3401,7 +3389,6 @@ static int ahash_set_sh_desc(struct crypto_ahash *ahash)
 	ahash_ctx_data_to_out(desc, have_key | ctx->alg_type,
 			      OP_ALG_AS_FINALIZE, digestsize, ctx);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) + desc_bytes(desc),
 				  DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -3422,7 +3409,6 @@ static int ahash_set_sh_desc(struct crypto_ahash *ahash)
 	ahash_ctx_data_to_out(desc, have_key | ctx->alg_type,
 			      OP_ALG_AS_FINALIZE, digestsize, ctx);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) + desc_bytes(desc),
 				  DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -3443,7 +3429,6 @@ static int ahash_set_sh_desc(struct crypto_ahash *ahash)
 	ahash_data_to_out(desc, have_key | ctx->alg_type, OP_ALG_AS_INITFINAL,
 			  digestsize, ctx);
 
-	flc->flc[1] = desc_len(desc); /* SDL */
 	*flc_dma = dma_map_single(dev, flc, sizeof(flc->flc) + desc_bytes(desc),
 				  DMA_TO_DEVICE);
 	if (dma_mapping_error(dev, *flc_dma)) {
@@ -5314,6 +5299,12 @@ int dpaa2_caam_enqueue(struct device *dev, struct caam_request *req)
 	dpaa2_fd_set_len(&fd, req->fd_flt[1].len);
 	dpaa2_fd_set_flc(&fd, req->flc_dma);
 
+	req->flc->flc[1] = desc_len(req->flc->sh_desc); /* SDL */
+	dma_sync_single_for_device(dev, req->flc_dma,
+				   sizeof(req->flc->flc) +
+				   desc_bytes(req->flc->sh_desc),
+				   DMA_TO_DEVICE);
+
 	for (i = 0; i < 100000; i++) {
 		/* TODO: priority hard-coded to zero */
 		err = dpaa2_io_service_enqueue_fq(NULL,
-- 
1.7.5.4

