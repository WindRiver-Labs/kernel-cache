From d8a1bb904bfe39c9ed8f725c5c140c54b7f935b5 Mon Sep 17 00:00:00 2001
From: Paolo Bonzini <pbonzini@redhat.com>
Date: Wed, 13 Jun 2012 16:56:33 +0200
Subject: [PATCH] virtio-scsi: release sg_lock after add_buf

commit bce750b1633927be3eecf821f4d17975c3ba5b6a upstream.

We do not need the sglist after calling virtqueue_add_buf.  Hence we
can "pipeline" the locked operations and start preparing the sglist
for the next request while we kick the virtqueue.

Together with the previous two patches, this improves performance as
follows.  For a simple "if=/dev/sda of=/dev/null bs=128M iflag=direct"
(the source being a 10G disk, residing entirely in the host buffer cache),
the additional locking does not cause any penalty with only one dd
process, but 2 simultaneous I/O operations improve their times by 3%:

               number of simultaneous dd
                   1               2
 ----------------------------------------
 current        5.9958s        10.2640s
 patched        5.9531s         9.8663s

(Times are best of 10).

Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
Signed-off-by: James Bottomley <JBottomley@Parallels.com>
Signed-off-by: Paul Barrette <paul.barrette@windriver.com>

diff --git a/drivers/scsi/virtio_scsi.c b/drivers/scsi/virtio_scsi.c
index 653bd77..1c147ef 100644
--- a/drivers/scsi/virtio_scsi.c
+++ b/drivers/scsi/virtio_scsi.c
@@ -281,11 +281,11 @@ static int virtscsi_kick_cmd(struct virtio_scsi *vscsi, struct virtio_scsi_vq *v
 
 	spin_lock(&vq->vq_lock);
 	ret = virtqueue_add_buf(vq->vq, vscsi->sg, out_num, in_num, cmd, gfp);
+	spin_unlock(&vscsi->sg_lock);
 	if (ret >= 0)
 		ret = virtqueue_kick_prepare(vq->vq);
 
-	spin_unlock(&vq->vq_lock);
-	spin_unlock_irqrestore(&vscsi->sg_lock, flags);
+	spin_unlock_irqrestore(&vq->vq_lock, flags);
 
 	if (ret > 0)
 		virtqueue_notify(vq->vq);
-- 
1.7.9.5

